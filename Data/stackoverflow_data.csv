,AuthorId,Q_id,Title,Abstract,Views,Answers,Cites,Tags_n,Tags,Date,CR_Date,LA_Date,Abstract_clean,Title_clean
0,47937,589462,What are benefits of serving static HTML and generating content with AJAX/JSON?,"<p><a href=""https://urbantastic-blog.tumblr.com/post/81336210/tech-tuesday-the-fiddly-bits/amp"" rel=""nofollow noreferrer"">https://urbantastic-blog.tumblr.com/post/81336210/tech-tuesday-the-fiddly-bits/amp</a></p>
<p>Heath from Urbantastic writes about his HTML generation system:</p>
<blockquote>
<p>All the HTML in Urbantastic is completely static.  All dynamic data is sent via AJAX in JSON format and then combined with the HTML using Javascript.  Put another way, the server software for Urbantastic produces and consumes JSON exclusively.  HTML, CSS, Javascript, and images are all sent via a different service (a vanilla Nginx server).</p>
</blockquote>
<p>I think this is an interesting model as it separates presentation from data physically. I am not an expert in architecture but it seems like there would be a jump in efficiency and stability.</p>
<p>However, the following concerns me:</p>
<hr />
<ul>
<li><p>[subjective] Clojure is extremely powerful; Javascript is not. Writing all the content generation on a language created for another goals will create some pain (imagine writing Javascript-type code in CSS). Unless he has a macro-system for generating Javascript, Heath is probably up to constant switching between JavaScript and Clojure. He'll also have a lot of JS code; probably a lot more than Clojure. That might not be good in terms of power, rapid development, succinctness and all the things we are looking at when switching to LISP-based langauges.</p>
</li>
<li><p>[performance] I am not sure on this but rendering everything on user's machine might lag.</p>
</li>
<li><p>[accessibility] If you have JS disabled you can't use site at all.</p>
</li>
<li><p>[accessibility#2] i suspect that a lot of dynamic data filling with JavaScript will create cross-browser issues.</p>
</li>
</ul>
<p>Can anyone comment? I'd be interested in reading your opinions on this type of architecture.</p>
<p>References:</p>
<ol>
<li><a href=""http://news.ycombinator.com/item?id=494147"" rel=""nofollow noreferrer"">Link</a> to discussion on HN.</li>
<li><a href=""http://www.reddit.com/r/programming/comments/806xt/why_urbantastic_chose_clojure_couchdb/"" rel=""nofollow noreferrer"">Link</a> to discussion on /r/programming.</li>
</ol>
",4009,3,6,5,javascript;json;separation-of-concerns;web-architecture;static-html,2009-02-26 09:03:05,2009-02-26 09:03:05,2022-08-26 15:49:14, heath from urbantastic writes about his html generation system  all the html in urbantastic is completely static   all dynamic data is sent via ajax in json format and then combined with the html using javascript   put another way  the server software for urbantastic produces and consumes json exclusively   html  css  javascript  and images are all sent via a different service  a vanilla nginx server   i think this is an interesting model as it separates presentation from data physically  i am not an expert in architecture but it seems like there would be a jump in efficiency and stability  however  the following concerns me   subjective  clojure is extremely powerful  javascript is not  writing all the content generation on a language created for another goals will create some pain  imagine writing javascript type code in css   unless he has a macro system for generating javascript  heath is probably up to constant switching between javascript and clojure  he ll also have a lot of js code  probably a lot more than clojure  that might not be good in terms of power  rapid development  succinctness and all the things we are looking at when switching to lisp based langauges   performance  i am not sure on this but rendering everything on user s machine might lag   accessibility  if you have js disabled you can t use site at all   accessibility   i suspect that a lot of dynamic data filling with javascript will create cross browser issues  can anyone comment  i d be interested in reading your opinions on this type of architecture  references ,what are benefits of serving static html and generating content with ajax json 
1,135982,40824547,Docker image running a Mac OS X installation,"<p>I am using Docker for Mac and wish to create Docker image running a Mac El Capitan with my development env. </p>

<p>I am not finding any resources on this. All I see is Linux installations.</p>

<p>On Linux I saw things as simple as:</p>

<pre><code>FROM sciensa2/docker-java8
RUN apt-get update
RUN apt-get install -y wget unzip libgtk2.0-0:amd64 libxtst6
</code></pre>

<p>But what would be the FROM value for OS X to install and run other software?</p>
",65032,4,42,3,macos;docker;osx-elcapitan,2016-11-27 02:21:23,2016-11-27 02:21:23,2022-08-26 14:48:12,i am using docker for mac and wish to create docker image running a mac el capitan with my development env   i am not finding any resources on this  all i see is linux installations  on linux i saw things as simple as  but what would be the from value for os x to install and run other software ,docker image running a mac os x installation
2,265119,38775954,sudo: docker-compose: command not found,"<p>I am trying to run docker-compose using sudo.</p>

<p>I have both docker and docker-compose installed on Ubuntu 16.01.</p>

<p>Due to an error while trying to download compose using curl, I ended up installing it using pip.</p>

<p>Docker version 1.12.0, build 8eab29e
docker-compose version 1.8.0, build 94f7016</p>

<p>Yet, when I try to run docker-compose with sudo I get the following (using sudo with docker is fine)</p>

<pre><code>sudo: docker-compose: command not found
</code></pre>

<p>I suppose there are differing definitions of what 'installed' means. I have been using docker-compose on the same computer that claims it is not installed.</p>

<pre><code>$ dpkg -s docker-compose
dpkg-query: package 'docker-compose' is not installed and no information is available
Use dpkg --info (= dpkg-deb --info) to examine archive files,
and dpkg --contents (= dpkg-deb --contents) to list their contents.


$ whereis docker-compose
docker-compose: /home/user/.local/bin/docker-compose

$ pip show --files docker-compose
---
Metadata-Version: 2.0
Name: docker-compose
Version: 1.8.0
Summary: Multi-container orchestration for Docker
Home-page: https://www.docker.com/
Author: Docker, Inc.
Author-email: UNKNOWN
Installer: pip
License: Apache License 2.0
Location: /home/anton/.local/lib/python2.7/site-packages
Requires: six, jsonschema, enum34, cached-property, websocket-client, docker-py, requests, docopt, dockerpty, PyYAML, texttable
Classifiers:
  Development Status :: 5 - Production/Stable
  Environment :: Console
  Intended Audience :: Developers
  License :: OSI Approved :: Apache Software License
  Programming Language :: Python :: 2
  Programming Language :: Python :: 2.7
  Programming Language :: Python :: 3
  Programming Language :: Python :: 3.4
Files:
  ../../../bin/docker-compose
  compose/GITSHA
  compose/__init__.py
  compose/__init__.pyc
  compose/__main__.py
  compose/__main__.pyc
  compose/bundle.py
  compose/bundle.pyc
  compose/cli/__init__.py
  compose/cli/__init__.pyc
  compose/cli/colors.py
  compose/cli/colors.pyc
  compose/cli/command.py
  compose/cli/command.pyc
  compose/cli/docker_client.py
  compose/cli/docker_client.pyc
  compose/cli/docopt_command.py
  compose/cli/docopt_command.pyc
  compose/cli/errors.py
  compose/cli/errors.pyc
  compose/cli/formatter.py
  compose/cli/formatter.pyc
  compose/cli/log_printer.py
  compose/cli/log_printer.pyc
  compose/cli/main.py
  compose/cli/main.pyc
  compose/cli/signals.py
  compose/cli/signals.pyc
  compose/cli/utils.py
  compose/cli/utils.pyc
  compose/cli/verbose_proxy.py
  compose/cli/verbose_proxy.pyc
  compose/config/__init__.py
  compose/config/__init__.pyc
  compose/config/config.py
  compose/config/config.pyc
  compose/config/config_schema_v1.json
  compose/config/config_schema_v2.0.json
  compose/config/environment.py
  compose/config/environment.pyc
  compose/config/errors.py
  compose/config/errors.pyc
  compose/config/interpolation.py
  compose/config/interpolation.pyc
  compose/config/serialize.py
  compose/config/serialize.pyc
  compose/config/sort_services.py
  compose/config/sort_services.pyc
  compose/config/types.py
  compose/config/types.pyc
  compose/config/validation.py
  compose/config/validation.pyc
  compose/const.py
  compose/const.pyc
  compose/container.py
  compose/container.pyc
  compose/errors.py
  compose/errors.pyc
  compose/network.py
  compose/network.pyc
  compose/parallel.py
  compose/parallel.pyc
  compose/progress_stream.py
  compose/progress_stream.pyc
  compose/project.py
  compose/project.pyc
  compose/service.py
  compose/service.pyc
  compose/state.py
  compose/state.pyc
  compose/utils.py
  compose/utils.pyc
  compose/volume.py
  compose/volume.pyc
  docker_compose-1.8.0.dist-info/DESCRIPTION.rst
  docker_compose-1.8.0.dist-info/INSTALLER
  docker_compose-1.8.0.dist-info/METADATA
  docker_compose-1.8.0.dist-info/RECORD
  docker_compose-1.8.0.dist-info/WHEEL
  docker_compose-1.8.0.dist-info/entry_points.txt
  docker_compose-1.8.0.dist-info/metadata.json
  docker_compose-1.8.0.dist-info/pbr.json
  docker_compose-1.8.0.dist-info/top_level.txt
Entry-points:
  [console_scripts]
  docker-compose=compose.cli.main:main
</code></pre>

<p>I have tried the following - but still get the same error:</p>

<pre><code>$ chmod +x /home/username/.local/bin/docker-compose
$ chmod +x /home/username/.local/lib/python2.7/site-packages
</code></pre>
",195775,9,90,4,linux;ubuntu;docker;docker-compose,2016-08-04 22:34:28,2016-08-04 22:34:28,2022-08-26 05:26:35,i am trying to run docker compose using sudo  i have both docker and docker compose installed on ubuntu    due to an error while trying to download compose using curl  i ended up installing it using pip  yet  when i try to run docker compose with sudo i get the following  using sudo with docker is fine  i suppose there are differing definitions of what  installed  means  i have been using docker compose on the same computer that claims it is not installed  i have tried the following   but still get the same error ,sudo  docker compose  command not found
3,19074,422767,Will .net 2.0 and 3.5 run side by side?,"<p>We're a development shop that still does most of our development in .net 2.0.  We're starting to think about using some of the new things in 3.5 (LINQ, etc) and there are some other software packages we're looking at that need WPF and so on.</p>

<p>We'd like to get 3.5 up and running on our test server, but without wrecking any of the 2.0 sites we already have running (and we'd like them to keep running under 2.0).  Are there any hidden issues I should know about, or can I just install 3.5 on our Server 2003 machine and be good to go?</p>

<p>(The specific concern being that despite Microsoft claiming the .net 2.0 components are the same in 3.5, that they actually changed something game-breaking.)</p>

<p>Update:  Bolstered on by everyone's comments here and other reading, we decided to bite the bullet and install 3.5 on the server ""just to see what happens.""</p>

<p>On running the install program, we discovered (to our not inconsiderable surprise) that .net 3.5 had been installed back in August - and none of us had known about it.</p>

<p>Which, really, is about as seamless an upgrade as you can ask for.</p>

<p>Thanks, everybody!</p>
",2909,9,7,2,.net;configuration,2009-01-08 02:30:29,2009-01-08 02:30:29,2022-08-26 00:23:36,we re a development shop that still does most of our development in  net     we re starting to think about using some of the new things in    linq  etc  and there are some other software packages we re looking at that need wpf and so on  we d like to get   up and running on our test server  but without wrecking any of the   sites we already have running  and we d like them to keep running under      are there any hidden issues i should know about  or can i just install   on our server  machine and be good to go   the specific concern being that despite microsoft claiming the  net   components are the same in    that they actually changed something game breaking   update   bolstered on by everyone s comments here and other reading  we decided to bite the bullet and install   on the server just to see what happens  on running the install program  we discovered  to our not inconsiderable surprise  that  net   had been installed back in august   and none of us had known about it  which  really  is about as seamless an upgrade as you can ask for  thanks  everybody ,will  net   and   run side by side 
4,11198313,73470356,Filter with two id of the same value CPT UI(taxanomies),"<p>I have a special link with a filter, so I filter things with slugs through the link, for example</p>
<pre><code>mydomain.com/filter/?technology=angular&amp;category=software-development
</code></pre>
<p>and it shows the chosen jobs</p>
<p>Now, I want to show jobs with different id's but with the same slug, like here:</p>
<pre><code>mydomain.com/filter/?bullhorn_id=2979,2090
</code></pre>
<p>I tried this variation</p>
<pre><code>https://itds.pl/filter/?bullhorn_id=2979&amp;bullhorn_id=2903
</code></pre>
<p>and it's not working
With one ID it works perfectly
Could please someone help me? I'm not good in PHP
here is part of a code that generates link</p>
<pre><code> if(isset($_GET['bullhorn_id'])){
                        $bullhorn = explode(',',$_GET['bullhorn_id']);
                        if(count($bullhorn)&gt;=0){                                
                            for($p=0;$p&lt;count($bullhorn);$p++){                                  
                                $filter[] = array( 'taxonomy' =&gt; 'bullhorn_id', 'field' =&gt; 'slug', 'terms' =&gt; $bullhorn[$p]  );
                            } 
                        }
                        else{
                            $filter[] = array( 'taxonomy' =&gt; 'bullhorn_id', 'field' =&gt; 'slug', 'terms' =&gt; $_GET['bullhorn_id']  );
                        }
                    }
</code></pre>
<p>Oh and BTW it's taxonomy, and the costume template for the page
The QUERY is in the function and looks like this:</p>
<pre><code>     // Filter for search query
    if(isset($_REQUEST['input_keyword']) &amp;&amp; $_REQUEST['input_keyword']!=''){
        $arg['s'] = $_REQUEST['input_keyword'];
    }
    
    // Set meta query with argument
    if(isset($_REQUEST['location']) &amp;&amp; $_REQUEST['location']!=''){
        $filter[] = array (
                'taxonomy' =&gt; 'location',
                'field' =&gt; 'slug',
                'terms' =&gt; $_REQUEST['location']
            );
    }
    if(isset($_REQUEST['technology']) &amp;&amp; $_REQUEST['technology']!=''){
        $filter[] = array (
                'taxonomy' =&gt; 'technology',
                'field' =&gt; 'slug',
                'terms' =&gt; $_REQUEST['technology']
            );
    }
    if(isset($_REQUEST['product_category']) &amp;&amp; $_REQUEST['product_category']!=''){
        $filter[] = array (
                'taxonomy' =&gt; 'product_cat',
                'field' =&gt; 'slug',
                'terms' =&gt; $_REQUEST['product_category']
            );
    }
    if(isset($_REQUEST['employment_type']) &amp;&amp; $_REQUEST['employment_type']!=''){
        $filter[] = array (
                'taxonomy' =&gt; 'employment_type',
                'field' =&gt; 'slug',
                'terms' =&gt; $_REQUEST['employment_type']
            );
    }
    if(isset($_REQUEST['seniority']) &amp;&amp; $_REQUEST['seniority']!=''){
        $filter[] = array (
                'taxonomy' =&gt; 'seniority',
                'field' =&gt; 'slug',
                'terms' =&gt; $_REQUEST['seniority']
            );
    }
    if(isset($_REQUEST['type_of_work']) &amp;&amp; $_REQUEST['type_of_work']!=''){
        $filter[] = array (
                'taxonomy' =&gt; 'type_of_work',
                'field' =&gt; 'slug',
                'terms' =&gt; $_REQUEST['type_of_work']
            );
    }
    if(isset($_REQUEST['language']) &amp;&amp; $_REQUEST['language']!=''){
        $filter[] = array (
                'taxonomy' =&gt; 'language',
                'field' =&gt; 'slug',
                'terms' =&gt; $_REQUEST['language']
            );
    }
    if(isset($_REQUEST['skills']) &amp;&amp; $_REQUEST['skills']!=''){
        $filter[] = array (
                'taxonomy' =&gt; 'skills',
                'field' =&gt; 'slug',
                'terms' =&gt; $_REQUEST['skills']
            );
    }
if(isset($_REQUEST['bullhorn_id']) &amp;&amp; $_REQUEST['bullhorn_id']!=''){
        $filter[] = array (
                'taxonomy' =&gt; 'bullhorn_id',
                'field' =&gt; 'slug',
                'terms' =&gt; $_REQUEST['bullhorn_id']
            );
    }
    if(isset($_REQUEST['hot_offer']) &amp;&amp; $_REQUEST['hot_offer']!=''){
        $filter[] = array (
                'taxonomy' =&gt; 'hot_offer',
                'field' =&gt; 'slug',
                'terms' =&gt; $_REQUEST['hot_offer']
            );
    }
    if( !empty($filter) &amp;&amp; count($filter)&gt;1 ){
        $arg['tax_query'] = $filter;   
    }
          
  
    if(isset($_REQUEST['max_price']) &amp;&amp; $_REQUEST['max_price']!=''){
      
  
             $filtermeta[] = array(
                'key' =&gt; 'maximum_price',
                'value' =&gt; array(trim($_REQUEST['max_price']), 1000000),
                'compare' =&gt; 'BETWEEN',
                'type' =&gt; 'numeric'
            );      
    }

    if( !empty($filtermeta) &amp;&amp; count($filtermeta)&gt;1 ){
        $arg['meta_query'] = $filtermeta;   
    }



 
</code></pre>
",31,2,0,4,php;wordpress;filter;custom-taxonomy,2022-08-24 12:04:10,2022-08-24 12:04:10,2022-08-25 14:57:27,i have a special link with a filter  so i filter things with slugs through the link  for example and it shows the chosen jobs now  i want to show jobs with different id s but with the same slug  like here  i tried this variation,filter with two id of the same value cpt ui taxanomies 
5,280698,4137077,C and assembly project suggestion needed for class on low-level software,"<p>I have a class on low-level programming which requires a final project (syllabus at the end). It is basically a piece of software that puts to use all you learned.</p>
<p>I had a few ideas, like designing my own <a href=""https://en.wikipedia.org/wiki/Roguelike"" rel=""nofollow noreferrer"">Roguelike</a> (should be kind of like <a href=""https://en.wikipedia.org/wiki/NetHack"" rel=""nofollow noreferrer"">NetHack</a>, only single-player), but I'd like some suggestions on alternatives. It needn't be a game; it can be anything. The time frame is a month and a half, and I have other projects, etc. so it shouldn't be <em>too</em> time-consuming to implement.</p>
<p>Requirements:</p>
<ul>
<li>Use, at least, four I/O devices, one of which should be the mouse or serial port</li>
<li>Some of those devices should use interrupts, others should use polling</li>
<li>Languages: C and Assembly (mandatorily, else there is a penalization)</li>
<li>Implement state machines</li>
</ul>
<p>The peripherals we were lectured on were:</p>
<ul>
<li>Graphics card - Graphical mode</li>
<li>Graphics card - Text mode</li>
<li>Mouse</li>
<li>Keyboard</li>
<li>Real Time Counter</li>
<li>On-board Speaker (via timers 0 and 2)</li>
<li>Serial port</li>
</ul>
<p>This is the abridged syllabus:</p>
<blockquote>
<p>Input/Output peripherals and their
operation Direct mapping in a process
address space Access to peripherals in
polled mode and by interrupt Processor
interrupts in the IA-32 architecture
and the interrupt controller. Writing
interrupt service routines in Assembly
and in C Study of some typical
personal computer peripherals, such as
keyboard, mouse, graphics card, real
time clock, timer, loudspeaker and
serial port.</p>
<p>Programming in the C programming
language: main differences with
respect to  C++ language; structured
programming in C.  Memory layout of a
process. Function calls: mechanisms,
parameter passing, storage of local
variables and return values. Combined
programming in C and the IA-32
processor family assembly. Creation
and use of libraries. Static linking
of object code.</p>
<p>Use of software development tools:
gcc, make, gdb, ar, prof, diff, patch
and SVN</p>
</blockquote>
",2836,5,5,3,c;assembly;project,2010-11-09 20:20:52,2010-11-09 20:20:52,2022-08-25 14:13:22,i have a class on low level programming which requires a final project  syllabus at the end   it is basically a piece of software that puts to use all you learned  i had a few ideas  like designing my own   should be kind of like   only single player   but i d like some suggestions on alternatives  it needn t be a game  it can be anything  the time frame is a month and a half  and i have other projects  etc  so it shouldn t be too time consuming to implement  requirements  the peripherals we were lectured on were  this is the abridged syllabus ,c and assembly project suggestion needed for class on low level software
6,13321451,73475379,Image too big for processing when converting large (1.3 GB) DNG file to PNG using python,"<p>I need to convert a DNG file to PNG using python. I found a post here how to convert DNG: <a href=""https://stackoverflow.com/questions/47969587/opencv-python-open-dng-format"">Opencv Python open dng format</a></p>
<p>The code I tried:</p>
<pre><code>#open dng and convert
import rawpy
import imageio
import os

os.chdir(r'C:\Path\to\dir')
path = r'path\to\file'

with rawpy.imread(path) as raw:
    rgb = raw.postprocess()

rgb_img.save('image.png')
</code></pre>
<p>However, it spits out the following errors:</p>
<pre><code>line 13, in &lt;module&gt;
    rgb = raw.postprocess()
  File &quot;rawpy\_rawpy.pyx&quot;, line 887, in rawpy._rawpy.RawPy.postprocess
  File &quot;rawpy\_rawpy.pyx&quot;, line 790, in rawpy._rawpy.RawPy.dcraw_process
  File &quot;rawpy\_rawpy.pyx&quot;, line 438, in rawpy._rawpy.RawPy.ensure_unpack
  File &quot;rawpy\_rawpy.pyx&quot;, line 432, in rawpy._rawpy.RawPy.unpack
  File &quot;rawpy\_rawpy.pyx&quot;, line 936, in rawpy._rawpy.RawPy.handle_error
rawpy._rawpy.LibRawTooBigError: b'Image too big for processing'
</code></pre>
<p>Is there either an alternative to convert the DNG files, or a way to bypass this error?</p>
<p>Info from exiftool:</p>
<pre><code>ExifTool Version Number         : 11.88

File Name                       : DSCF0001.DNG

Directory                       : .

File Size                       : 1313 MB

File Modification Date/Time     : 2022:08:24 12:06:31+01:00

File Access Date/Time           : 2022:08:25 08:17:15+01:00

File Inode Change Date/Time     : 2022:08:24 15:19:04+01:00

File Permissions                : rwxrwxrwx

File Type                       : DNG

File Type Extension             : dng

MIME Type                       : image/x-adobe-dng

Exif Byte Order                 : Little-endian (Intel, II)

Make                            : FUJIFILM

Camera Model Name               : GFX 100

Preview Image Start             : 115208860

Orientation                     : Horizontal (normal)

Rows Per Strip                  : 3000

Preview Image Length            : 3011337

Software                        : FUJIFILM Pixel Shift Combiner 1.2.0.2 (Real Color + High Resolution mode)

Modify Date                     : 2022:08:24 12:06:29

Artist                          : 

Subfile Type                    : Full-resolution image

Image Width                     : 23296

Image Height                    : 17472

Bits Per Sample                 : 16 16 16

Compression                     : JPEG

Photometric Interpretation      : Linear Raw

Samples Per Pixel               : 3

Planar Configuration            : Chunky

Tile Width                      : 128

Tile Length                     : 96

Tile Offsets                    : (Binary data 341026 bytes, use -b option to extract)

Tile Byte Counts                : (Binary data 198743 bytes, use -b option to extract)

Black Level                     : 256 255 256

White Level                     : 65535 65535 65535

Default Scale                   : 1 1

Default Crop Origin             : 16 12

Default Crop Size               : 23264 17448

Anti Alias Strength             : 1

Best Quality Scale              : 1

Opcode List 3                   : WarpRectilinear, FixVignetteRadial

Rating                          : 0

Copyright                       : 

Exposure Time                   : 1/125

F Number                        : 8.0

Exposure Program                : Manual

ISO                             : 100

Sensitivity Type                : Standard Output Sensitivity

Standard Output Sensitivity     : 100

Exif Version                    : 0230

Date/Time Original              : 2019:03:10 00:44:16

Create Date                     : 2019:03:10 00:44:16

Shutter Speed Value             : 1/125

Aperture Value                  : 8.0

Brightness Value                : 8.57

Exposure Compensation           : 0

Max Aperture Value              : 2.0

Metering Mode                   : Multi-segment

Light Source                    : Unknown

Flash                           : No Flash

Focal Length                    : 110.0 mm

Version                         : 0130

Internal Serial Number          : 

Quality                         : NORMAL

White Balance                   : Auto

Saturation                      : 0 (normal)

White Balance Fine Tune         : Red +0, Blue +0

Noise Reduction                 : 0 (normal)

Fuji Flash Mode                 : Manual

Flash Exposure Comp             : 0

Focus Mode                      : Manual

AF Mode                         : No

Focus Pixel                     : 2001 1501

AF-S Priority                   : Release

AF-C Priority                   : Release

Focus Mode 2                    : AF-M

AF Area Mode                    : Single Point

AF Area Point Size              : n/a

AF Area Zone Size               : n/a

AF-C Setting                    : Set 1 (multi-purpose)

AF-C Tracking Sensitivity       : 2

AF-C Speed Tracking Sensitivity : 0

AF-C Zone Area Switching        : Auto

Slow Sync                       : Off

Picture Mode                    : Manual

Exposure Count                  : 1

Shadow Tone                     : 0 (normal)

Highlight Tone                  : 0 (normal)

Lens Modulation Optimizer       : On

Grain Effect                    : Off

Color Chrome Effect             : Off

Crop Mode                       : n/a

Color Chrome FX Blue            : Off

Shutter Type                    : Electronic

Auto Bracketing                 : Unknown (6)

Sequence Number                 : 1

Drive Mode                      : Single

Drive Speed                     : n/a

Blur Warning                    : None

Focus Warning                   : Good

Exposure Warning                : Good

Dynamic Range                   : Standard

Film Mode                       : F0/Standard (Provia)

Dynamic Range Setting           : Manual

Development Dynamic Range       : 100

Min Focal Length                : 110

Max Focal Length                : 110

Max Aperture At Min Focal       : 2

Max Aperture At Max Focal       : 2

Image Stabilization             : Sensor-shift; Off; 0

Image Generation                : Original Image

Image Count                     : 34

Flicker Reduction               : Off (0x0002)

Faces Detected                  : 0

Num Face Elements               : 0

Color Space                     : Uncalibrated

Focal Plane X Resolution        : 5320

Focal Plane Y Resolution        : 5320

Focal Plane Resolution Unit     : cm

File Source                     : Digital Camera

Scene Type                      : Directly photographed

Custom Rendered                 : Normal

Exposure Mode                   : Auto

Focal Length In 35mm Format     : 87 mm

Scene Capture Type              : Standard

Sharpness                       : Unknown (3)

Subject Distance Range          : Unknown (48)

Serial Number                   : 

Lens Info                       : 110mm f/2

Lens Make                       : FUJIFILM

Lens Model                      : GF110mmF2 R LM WR

Lens Serial Number              : 

DNG Version                     : 1.4.0.0

DNG Backward Version            : 1.1.0.0

Unique Camera Model             : FUJIFILM GFX 100

Color Matrix 1                  : 1.7191 -1.1 0.1278 -0.3574 1.1733 0.2076 -0.0002 0.0497 0.654

Color Matrix 2                  : 1.6212 -0.8423 -0.1583 -0.4336 1.2583 0.1937 -0.0195 0.0726 0.6199

Analog Balance                  : 1 1 1

As Shot Neutral                 : 0.5644 1 0.5153

Baseline Exposure               : -0.01

Baseline Noise                  : 1

Baseline Sharpness              : 1.33

Linear Response Limit           : 1

Camera Serial Number            : 

DNG Lens Info                   : 110mm f/2

Shadow Scale                    : 1

DNG Private Data                : (Binary data 114927728 bytes, use -b option to extract)

Calibration Illuminant 1        : Standard Light A

Calibration Illuminant 2        : D65

Aperture                        : 8.0

Image Size                      : 23296x17472

Megapixels                      : 407.0

Preview Image                   : (Binary data 3011337 bytes, use -b option to extract)

Scale Factor To 35 mm Equivalent: 0.8

Shutter Speed                   : 1/125

Circle Of Confusion             : 0.038 mm

Field Of View                   : 23.4 deg

Focal Length                    : 110.0 mm (35 mm equivalent: 87.0 mm)

Hyperfocal Distance             : 39.81 m

Light Value                     : 13.0
</code></pre>
",54,1,1,4,python;image;dng;rawpy,2022-08-24 17:55:06,2022-08-24 17:55:06,2022-08-25 11:37:53,i need to convert a dng file to png using python  i found a post here how to convert dng   the code i tried  however  it spits out the following errors  is there either an alternative to convert the dng files  or a way to bypass this error  info from exiftool ,image too big for processing when converting large    gb  dng file to png using python
7,73070,793100,Globally catch exceptions in a WPF application?,"<p>We have a WPF application where parts of it may throw exceptions at runtime. I'd like to globally catch any unhandled exceptions and log them, but otherwise continue program execution as if nothing happened (kinda like VB's <code>On Error Resume Next</code>).</p>
<p>Is this possible in C#? And if so, where exactly would I need to put the exception handling code?</p>
<p>Currently I can't see any single point where I could wrap a <code>try</code>/<code>catch</code> around and which would catch all exceptions that could occur. Even then, I would have left whatever has been executed because of the catch. Or am I thinking in horribly wrong directions here?</p>
<p><strong>ETA:</strong> Because many people below pointed it out: The application is not for controlling nuclear power plants. If it crashes, it's not that big a deal, but it throws random exceptions that are mostly UI-related that are a nuisance in the context where it would be used. There were (and probably still are) a few of those and since it uses a plugin architecture and may be extended by others (also students in that case; so <em>no</em> experienced developers that are able to write completely error-free code).</p>
<p>As for the exceptions that get caught: I do log them to a log file, including the complete stack trace. That was the whole point of that exercise. Just to counter those people  that were taking my analogy to VB's OERN too literally.</p>
<p>I know that blindly ignoring certain classes of errors is dangerous and might corrupt my application instance. As said before, this program isn't mission-critical for anyone. No-one in their right mind would bet the survival of the human civilization on it. It's simply a little tool for testing certain design approaches wrt. software engineering.</p>
<p>For the immediate use of the application there are not many things that can happen on an exception:</p>
<ul>
<li>No exception handling – error dialog and application exit. Experiment has to be repeated, though likely with another subject. No errors have been logged, which is unfortunate.</li>
<li>Generic exception handling – benign error trapped, no harm done. This should be the common case judged from all errors we were seeing during development. Ignoring this kind of errors should have no immediate consequences; the core data structures are tested well enough that they will easily survive this.</li>
<li>Generic exception handling – serious error trapped, possibly crash at a later point. This may happen rarely. We've never seen it so far. The error is logged anyway and a crash might be inevitable. So this is conceptually similar to the very first case, except that we have a stack trace. And in the majority of cases the user won't even notice.</li>
</ul>
<p>As for the experiment data generated by the program: A serious error would at worst just cause no data to be recorded. Subtle changes that change the result of the experiment ever so slightly are pretty unlikely. And even in that case, if the results seem dubious the error was logged; one can still throw away that data point if it's a total outlier.</p>
<p>To summarize: Yes, I consider myself still at least partially sane and I don't consider a global exception handling routine which leaves the program running to be necessarily totally evil. As said twice before, such a decision might be valid, depending on the application. In this case it was judged a valid decision and not total and utter bullshit. <strong>For any other application that decision might look different.</strong> But please don't accuse me or the other people who worked on that project to potentially blow up the world just because we're ignoring errors.</p>
<p>Side note: There is exactly one user for that application. It's not something like Windows or Office that gets used by millions where the cost of having exceptions bubble to the user at all would be very different in the first place already.</p>
",126886,6,273,3,c#;wpf;exception,2009-04-27 14:16:34,2009-04-27 14:16:34,2022-08-25 11:25:49,we have a wpf application where parts of it may throw exceptions at runtime  i d like to globally catch any unhandled exceptions and log them  but otherwise continue program execution as if nothing happened  kinda like vb s on error resume next   is this possible in c   and if so  where exactly would i need to put the exception handling code  currently i can t see any single point where i could wrap a try catch around and which would catch all exceptions that could occur  even then  i would have left whatever has been executed because of the catch  or am i thinking in horribly wrong directions here  eta  because many people below pointed it out  the application is not for controlling nuclear power plants  if it crashes  it s not that big a deal  but it throws random exceptions that are mostly ui related that are a nuisance in the context where it would be used  there were  and probably still are  a few of those and since it uses a plugin architecture and may be extended by others  also students in that case  so no experienced developers that are able to write completely error free code   as for the exceptions that get caught  i do log them to a log file  including the complete stack trace  that was the whole point of that exercise  just to counter those people  that were taking my analogy to vb s oern too literally  i know that blindly ignoring certain classes of errors is dangerous and might corrupt my application instance  as said before  this program isn t mission critical for anyone  no one in their right mind would bet the survival of the human civilization on it  it s simply a little tool for testing certain design approaches wrt  software engineering  for the immediate use of the application there are not many things that can happen on an exception  as for the experiment data generated by the program  a serious error would at worst just cause no data to be recorded  subtle changes that change the result of the experiment ever so slightly are pretty unlikely  and even in that case  if the results seem dubious the error was logged  one can still throw away that data point if it s a total outlier  to summarize  yes  i consider myself still at least partially sane and i don t consider a global exception handling routine which leaves the program running to be necessarily totally evil  as said twice before  such a decision might be valid  depending on the application  in this case it was judged a valid decision and not total and utter bullshit  for any other application that decision might look different  but please don t accuse me or the other people who worked on that project to potentially blow up the world just because we re ignoring errors  side note  there is exactly one user for that application  it s not something like windows or office that gets used by millions where the cost of having exceptions bubble to the user at all would be very different in the first place already ,globally catch exceptions in a wpf application 
8,13998296,73482248,Does Jenkins essentially function like a package manager for your software product?,"<p>I'm a relatively new IT Ops guy in a software (web) development company. Recently I deployed a virtual machine on OpenStack, because some developer needs it, and then I installed their  application (written by our developers, not third party application) on that newly deployed server using Jenkins.</p>
<p>So basically, what I did was to install an application automatically on a server using Jenkins. This feels like installing a software on a Linux PC using a package manager like APT in Ubuntu, where everything is handled automatically by the package manager.</p>
<p>So, is the purpose of Jenkins to function like some automatic software installer? Is Jenkins essentially a package manager?</p>
",11,0,0,5,jenkins;continuous-integration;continuous-deployment;packaging;continuous-delivery,2022-08-25 08:23:44,2022-08-25 08:23:44,2022-08-25 08:23:44,i m a relatively new it ops guy in a software  web  development company  recently i deployed a virtual machine on openstack  because some developer needs it  and then i installed their  application  written by our developers  not third party application  on that newly deployed server using jenkins  so basically  what i did was to install an application automatically on a server using jenkins  this feels like installing a software on a linux pc using a package manager like apt in ubuntu  where everything is handled automatically by the package manager  so  is the purpose of jenkins to function like some automatic software installer  is jenkins essentially a package manager ,does jenkins essentially function like a package manager for your software product 
9,8153581,73466213,Laravel Vite issue when runing npm run dev,"<p>I'm using Laravel 9. When I try to run <code>npm install</code>, then run <code>npm run dev</code>, the error below shows up.</p>
<pre><code>VITE v3.0.9  ready in 648 ms

  ➜  Local:   http://127.0.0.1:5173/
  ➜  Network: use --host to expose

  LARAVEL v9.26.0  plugin v0.5.4

  ➜  APP_URL: http://127.0.0.1:8000
C:\Software Project\Web Development\AdminPanel\node_modules\esbuild\lib\main.js:1356
        return callback(new Error(error), null);
                        ^

Error: The service was stopped: write EPIPE
    at C:\Software Project\Web Development\AdminPanel\node_modules\esbuild\lib\main.js:1356:25    
    at C:\Software Project\Web Development\AdminPanel\node_modules\esbuild\lib\main.js:678:9      
    at afterClose (C:\Software Project\Web Development\AdminPanel\node_modules\esbuild\lib\main.js:656:7)
    at C:\Software Project\Web Development\AdminPanel\node_modules\esbuild\lib\main.js:2075:11    
    at onwriteError (node:internal/streams/writable:417:3)
    at processTicksAndRejections (node:internal/process/task_queues:85:21)
</code></pre>
",54,0,0,5,php;laravel;npm;vite;laravel-vite,2022-08-24 03:26:46,2022-08-24 03:26:46,2022-08-25 01:35:45,i m using laravel   when i try to run npm install  then run npm run dev  the error below shows up ,laravel vite issue when runing npm run dev
10,19839770,73477364,Date/Time formatting issue while webscraping to CSV file,"<p>I'm learning python and software development...</p>
<p>I've been scraping data (date/time, interest rate) every minute since July from a website and appending it to a CSV file. Today I went to chart the data using jupyter notebook, pandas..etc</p>
<p>I sliced off the 'AM/PM' string characters and used the <code>pandas.to_datetime</code> method on the date/time column to properly format it and .</p>
<pre><code>data['date/time'] = data['date/time'].str[0:14].map(pandas.to_datetime)
</code></pre>
<p>However, it appears that the date/time data was at first interpreted by python/jupyter/pandas following the ddmmyy convention but then changed at the start of a new month to being interpreted to mmddyy. On the 13th of the month the interpretation changed back to ddmmyy.</p>
<p>For example:</p>
<p>The CSV file shows the following string value within the respective cell:</p>
<pre><code>31/07/22 23:59PM
01/08/22 00:00AM
...
12/08/22 23:59PM
13/08/22 00:00AM
</code></pre>
<p>However, the pandas dataframe, after using the 'to_datetime' method shows:</p>
<pre><code>2022-07-31 23:59:00
2022-01-08 00:00:00
...
2022-12-08 23:59:00
2022-08-13 00:00:00 
</code></pre>
<p>I've been trying to figure out:
Why this happened?
How can I avoid this moving forward?
How can I fix this so that I may chart/plot the time series data properly?</p>
<p><em><strong>Update</strong></em>It looks like the issue occurs while filtering from a larger CSV file into the CSV file I'm working with.</p>
",27,1,0,4,python;pandas;csv;jupyter-notebook,2022-08-24 20:26:42,2022-08-24 20:26:42,2022-08-24 22:55:15,i m learning python and software development    i ve been scraping data  date time  interest rate  every minute since july from a website and appending it to a csv file  today i went to chart the data using jupyter notebook  pandas  etc i sliced off the  am pm  string characters and used the pandas to_datetime method on the date time column to properly format it and   however  it appears that the date time data was at first interpreted by python jupyter pandas following the ddmmyy convention but then changed at the start of a new month to being interpreted to mmddyy  on the th of the month the interpretation changed back to ddmmyy  for example  the csv file shows the following string value within the respective cell  however  the pandas dataframe  after using the  to_datetime  method shows  updateit looks like the issue occurs while filtering from a larger csv file into the csv file i m working with ,date time formatting issue while webscraping to csv file
11,10508062,73475721,Extract full text from different tags and outside them,"<p>I want to extract all text information from the already scrapped readme files from github. There is text between Html tags but there is also a lot of text outside (between) tags. Tags are different because those are different readmes so the authors do not follow any particular rules. I want to extract text from tags but also the rest outside any tag.
<br>
The example:</p>
<pre><code>&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;img alt=&quot;Black Hat Rust logo&quot; src=&quot;./black_hat_rust_cover.png&quot; height=&quot;300&quot; /&gt;&lt;/a&gt; &lt;h1 align=&quot;center&quot;&gt;Black Hat Rust&lt;/h1&gt; &lt;h3 align=&quot;center&quot;&gt;Applied offensive security with the Rust programming language&lt;/h3&gt; &lt;h3 align=&quot;center&quot;&gt; &lt;a href=&quot; the book now!&lt;/a&gt; &lt;/h3&gt; &lt;/p&gt; While the [Rust Book]( does an excellent job teaching **What is** Rust, a book about **Why** and **How** to Rust was missing. ## Summary Whether in movies or mainstream media, hackers are often romanticized: they are painted as black magic wizards, nasty criminals, or, in the worst cases, as thieves with a hood and a crowbar. In reality, the spectrum of the profile of the attackers is extremely large, from the bored teenager exploring the internet to sovereign State's armies as well as the unhappy former employee. What are the motivations of the attackers? How can they break seemingly so easily into any network? What do they do to their victims? We will put on our black hat and explore the world of offensive security, whether it be cyber attacks, cybercrimes, or cyberwar. Scanners, exploits, phishing toolkit, implants... From theory to practice, we will explore the arcane of offensive security and build our own offensive tools with the Rust programming language, Stack Overflow's most loved language for five years in a row. Which programming language allows to craft shellcodes, build servers, create phishing pages? Before Rust, none! Rust is the long-awaited one-size-fits-all programming language meeting all those requirements thanks to its unparalleled guarantees and feature set. Here is why. &lt;!-- The security programming field is defined by its extremely large scope (from shellcodes to servers and web apps). Rust is the long-awaited one-size-fits-all programming language meeting all those requirements thanks to its unparalleled guarantees and feature set. Here is why. Rust is turning a new page in the history of programming languages by providing unparalleled guarantees and features, whether it be for defensive or offensive security. I will venture to say that Rust is the long awaited one-size-fits-all programming language. Here is why. --&gt; Free Updates and DRM Free, of course :) ## Who this book is for This is NOT a 1000th tutorial about sqlmap and Metasploit, nor will it teach you the fundamentals of programming. Instead, it's a from-theory-to-practice guide and you may enjoy it if any of the following: - You keep screaming &quot;show me the code!&quot; when reading about cyber attacks and malwares - You are a developer and want to learn security - You are a security engineer and want to learn Rust programming - You want to learn real-world and idiomatic rust practices - You believe that the best defense is thinking like an attacker - You learn by building and love to look under the hood - You value simplicity and pragmatism - You develop your own tools and exploits with Python, Ruby, C, Java... - You want to learn real-world offensive security, not just pentesting - You want to start making money with bug bounty programs - You prefer getting things done over analysis paralysis But I repeat, this book is NOT a computer science book. &lt;h3&gt; &lt;a href=&quot; the book now!&lt;/a&gt; &lt;/h3&gt; ## Table of contents #### 1 - Introduction ### Part I: Reconnaissance #### 2 - Multi-threaded attack surface discovery How to perform effective reconnaissance? In this chapter, we will build a multi-threaded scanner in order to automate the mapping of the target. #### 3 - Going full speed with async Unfortunately, when a program spends most of its time in I/O operations, multi-threading is not a panacea. We will learn how async makes Rust code really, really fast and refactor our scanner to async code. #### 4 - Adding modules with Trait objects We will add more heterogeneous modules to our scanner and will learn how Rust's type system helps create properly designed large software projects. #### 5 - Crawling the web for OSINT Leveraging all we learned previously, we will build an extremely fast web crawler to help us find the needles in the haystack the web is. ### Part II: Exploitation #### 6 - Finding vulnerabilities Once the external reconnaissance performed, it's time to find entry points. In this chapter we will learn how automated fuzzing can help us to find vulnerabilities that can be exploited to then gain access to our target's systems. #### 7 - Exploit development Rust may not be as fast as python when it comes to iterating on quick scripts such as exploits, but as we will see, its powerful type and modules system make it nonetheless a weapon of choice. #### 8 - Writing shellcodes in Rust Shellcode development is an ungrateful task. Writing assembly by hand is definitely not sexy. Fortunately for us, Rust, one more time, got our back! In this chapter we will learn how to write shellcodes in plain Rust with no_std. #### 9 - Phishing with WebAssembly When they can't find exploitable hardware or software vulnerability, attackers usually fall back to what is often the weakest link in the chain: Humans. Again, Rust comes handy and will let us create advanced phishing pages by compiling to WebAssembly. ### Part III: Implant development #### 10 - A modern RAT A RAT (for Remote Access Tool), also known as implant or beacon, is a kind of software used to perform offensive operations on a target's machines. In this chapter we will build our own RAT communicating to a remote server and database. #### 11 - Securing communications with end-to-end encryption The consequences of our own infrastructure being compromised or seized can be disastrous. We will add end-to-end encryption to our RAT's communication in order to secure its communications and avoid leaving traces on our servers. #### 12 - Going multi-platforms Today's computing landscape is extremely fragmented. From Windows to macOS, we can't target only one Operating System to ensure the success of our operations. In this section we will see how Rust's ecosystem is extremely useful when it comes to cross-compilation. #### 13 - Turning into a worm to increase reach Once the initial targets compromised, we will capitalize on Rust's excellent reusability to incorporate some parts of our initial scanner to turn our RAT into a worm and reach more targets only accessible from the target's internal network. #### 14 Conclusion Now it's **your** turn to get things done! &lt;h3&gt; &lt;a href=&quot; the book now!&lt;/a&gt; &lt;/h3&gt; ## FAQ ### Can I pay with PayPal, Apple Pay or Google Pay? Yes! You can now buy Black Hat Rust with PayPal, Apple Pay or Google Pay. [Go Here to proceed]( &lt;!-- ### The book is too expensive! Black Hat Rust is designed to save you a lot of time in your learning journey of Rust and offensive security. The maths are simple: if the book saves you 20 hours, and you are paid 25$ / hour, you just saved 25 * 18 = 450$ Of course, I expect that the book will save you even more time! --&gt; ### What to do if I don't have a VAT number? A European VAT number is optional, and you can skip the field or leave it empty if asked. &lt;!-- ## Getting started **Knowledge has no value if you don't practice!** Where to start? I've got you covered! I've extracted the security scanner we build in the book from chapters 2, 3, 4, and 7 into [phaser]( an automated attack surface mapper and vulnerability scanner. You can then contribute to your first Rust security project or participate in your first bug bounty program. --&gt; ## Community Hey! Welcome you to the Black Hat Rustaceans gang! If you think something in the book or the code can be improved, please [open an issue]( Pull requests are also welcome :) ## Newsletter Want to stay updated? I'll write you once a week about avoiding complexity, hacking, and entrepreneurship. ** *I hate spam even more than you do. I'll never share your email, and you can unsubscribe at anytime. Also, there is no tracking or ads.* ## Changelog You'll find all the updates in the Changelog:
</code></pre>
<p>And I want to extract all text so:</p>
<pre><code>While the [Rust Book]( does an excellent job teaching **What is** Rust, a book about **Why** and **How** to Rust was missing. ## Summary Whether in movies or mainstream media, hackers are often romanticized: they are painted as black magic wizards, nasty criminals, or, in the worst cases, as thieves with a hood and a crowbar. In reality, the spectrum of the profile of the attackers is extremely large, from the bored teenager exploring the internet to sovereign State's armies as well as the unhappy former employee. What are the motivations of the attackers? How can they break seemingly so easily into any network? What do they do to their victims? We will put on our black hat and explore the world of offensive security, whether it be cyber attacks, cybercrimes, or cyberwar. Scanners, exploits, phishing toolkit, implants... From theory to practice, we will explore the arcane of offensive security and build our own offensive tools with the Rust programming language, Stack Overflow's most loved language for five years in a row. Which programming language allows to craft shellcodes, build servers, create phishing pages? Before Rust, none! Rust is the long-awaited one-size-fits-all programming language meeting all those requirements thanks to its unparalleled guarantees and feature set. Here is why. The security programming field is defined by its extremely large scope (from shellcodes to servers and web apps). Rust is the long-awaited one-size-fits-all programming language meeting all those requirements thanks to its unparalleled guarantees and feature set. Here is why. Rust is turning a new page in the history of programming languages by providing unparalleled guarantees and features, whether it be for defensive or offensive security. I will venture to say that Rust is the long awaited one-size-fits-all programming language. Here is why. --&gt; Free Updates and DRM Free, of course :)
</code></pre>
<p>and so on ....
I've tried BeatifulSoup with get_text() or just soup.text</p>
<pre><code>def preprocess(text_all):
    soup = BeautifulSoup(text_all,&quot;lxml&quot;)
    #text =soup.get_text() doesn't work
    text = ''.join(soup.text) #doesn't work either
    
    # fetch only alphabetic characters
    #text = re.sub(&quot;[^a-zA-Z]&quot;, &quot; &quot;, text)

    # split text into tokens to remove whitespaces
    tokens = text.split()

    return &quot; &quot;.join(tokens)

</code></pre>
<p>but it doesn't work and I get only text within tags :</p>
<pre><code>Black Hat Rust Applied offensive security with the Rust programming language FAQ Can I pay with PayPal Apple Pay or Google Pay Yes You can now buy Black Hat Rust with PayPal Apple Pay or Google Pay Go Here to proceed What to do if I don t have a VAT number A European VAT number is optional and you can skip the field or leave it empty if asked Community Hey Welcome you to the Black Hat Rustaceans gang If you think something in the book or the code can be improved please open an issue Pull requests are also welcome Newsletter Want to stay updated I ll write you once a week about avoiding complexity hacking and entrepreneurship I hate spam even more than you do I ll never share your email and you can unsubscribe at anytime Also there is no tracking or ads Changelog You ll find all the updates in the Changelog
</code></pre>
",44,1,0,2,python;beautifulsoup,2022-08-24 18:16:43,2022-08-24 18:16:43,2022-08-24 19:58:46,and i want to extract all text so  but it doesn t work and i get only text within tags  ,extract full text from different tags and outside them
12,12893491,73444314,@stripe/stripe-react-native payment-sheet (Save card data),"<p><a href=""https://i.stack.imgur.com/cfq8a.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/cfq8a.png"" alt=""stripe payment sheet"" /></a></p>
<p>i am trying to integrate payment sheet with customer(stripe customer id) and save card option(as shown in image) and the customer was linked with payment but <strong>Save this card for future powdur payments</strong> option was not showing. i can't understand why that's not showing? if any buddy have idea about this then pls tell..</p>
<p>server-side Code</p>
<p><em><strong>createCustomer</strong></em></p>
<pre><code>exports.handler = async (event) =&gt; {
  console.log(JSON.stringify(event.arguments));
  const customer = await stripe.customers.create({
    name: event.arguments?.input?.name,
    email: event.arguments.input?.email,
    payment_method: 'pm_card_visa',
    invoice_settings: {
      default_payment_method: 'pm_card_visa',
    },
  });
  console.log('Customer Data', JSON.stringify(customer));
  return {
    id: customer.id ?? 'Default',
  };
};
</code></pre>
<p><em><strong>createPaymentIntent</strong></em></p>
<pre><code>exports.handler = async (event) =&gt; {
  console.log('Event', JSON.stringify(event.arguments.input));
  try {
    const paymentIntent = await stripe.paymentIntents.create({ ...event.arguments.input });
    console.log(paymentIntent.client_secret);
    return {
      clientSecret: paymentIntent.client_secret,
    };
  } catch (error) {
    console.log(JSON.stringify(error));
    return {
      error: error.message,
    };
  }
};

/** createIntent data
 * description: 'Software development services',
    customer: customerId,
    shipping: {
      name: 'Jenny Rosen',
      address: {
        line1: '510 Townsend St',
        postal_code: '98140',
        city: 'San Francisco',
        state: 'CA',
        country: 'US',
      },
    },
    amount: 1099,
    currency: 'usd',
    payment_method_types: ['card'],
 */
</code></pre>
",38,1,0,3,react-native;stripe-payments;stripe-apps,2022-08-22 14:26:01,2022-08-22 14:26:01,2022-08-24 16:15:02, i am trying to integrate payment sheet with customer stripe customer id  and save card option as shown in image  and the customer was linked with payment but save this card for future powdur payments option was not showing  i can t understand why that s not showing  if any buddy have idea about this then pls tell   server side code createcustomer createpaymentintent, stripe stripe react native payment sheet  save card data 
13,15305701,73469835,array of objects from a different component in react not mapping in list,"<p>I am mapping an array of objects I imported from a different component but I get the error</p>
<blockquote>
<p>Warning: Each child in a list should have a unique &quot;key&quot; prop.</p>
</blockquote>
<p>with the following error details</p>
<blockquote>
<p>Check the top-level render call using . See <a href=""https://reactjs.org/link/warning-keys"" rel=""nofollow noreferrer"">https://reactjs.org/link/warning-keys</a> for more information.
at li
at Heading2
at div
at div
at Home (webpack-internal:///./pages/index.jsx:27:17)
at Layout (webpack-internal:///./components/Layout.jsx:16:19)
at $29383e587d62412a$export$9f8ac96af4b1b2ae (/home/kimmoramicky/Desktop/fts_portfolio/node_modules/@react-aria/ssr/dist/main.js:42:28)
at MyApp (webpack-internal:///./pages/_app.tsx:28:18)
at StyleRegistry (/home/kimmoramicky/Desktop/fts_portfolio/node_modules/styled-jsx/dist/index/index.js:671:34)
at AppContainer (/home/kimmoramicky/Desktop/fts_portfolio/node_modules/next/dist/server/render.js:404:29)
at AppContainerWithIsomorphicFiberStructure (/home/kimmoramicky/Desktop/fts_portfolio/node_modules/next/dist/server/render.js:433:57)
at div
at Body (/home/kimmoramicky/Desktop/fts_portfolio/node_modules/next/dist/server/render.js:690:21)</p>
</blockquote>
<p>Following is the component containing the array
Menu.jsx</p>
<pre><code>export const mainDetails = [
    {
        heading: 'CUSTOM SOFTWARE DEVELOPMENT',
        list: ['- Solutions tailored to specitic business needs', '- Domain experience', '- Technical excellence', '- Process visibility', '- Constraint management framework', '- Non-functional requirements match']
      },
      {
        heading: 'DEVELOPMENT TEAM AUGMENTATION',
        list: ['- Solutions tailored to specitic business needs', '- Domain experience', '- Technical excellence', '- Process visibility', '- Constraint management framework', '- Non-functional requirements match']
      },
      {
        heading: 'IT CONSULTING AND DIGITAL ADVISORY',
        list: ['- Solutions tailored to specitic business needs', '- Domain experience', '- Technical excellence', '- Process visibility', '- Constraint management framework', '- Non-functional requirements match']
      },
      {
        heading: 'SOFTWARE RE-ENGINEERING AND SUPPORT',
        list: ['- Solutions tailored to specitic business needs', '- Domain experience', '- Technical excellence', '- Process visibility', '- Constraint management framework', '- Non-functional requirements match']
      }
]
</code></pre>
<p>Following is the component containing the mapping of the array
Heading.jsx</p>
<pre><code>import React from 'react'
import Link from 'next/link'
import {mainDetails} from './Menus'

const Heading2 = () =&gt; {
  return (
    &lt;main&gt;
      {mainDetails.map(detail =&gt; (
        &lt;div className=&quot;card&quot;&gt;  
          &lt;div className='done'&gt;
            &lt;div&gt;
              &lt;h5 className='font-normal pl-8 text-[#E54416] pb-4 text-lg'&gt;{detail.heading}&lt;/h5&gt;
              &lt;ul&gt;{detail.list.map(listItems=&gt;(
                &lt;li&gt;{listItems}&lt;/li&gt;
              ))}
              &lt;/ul&gt;
            &lt;/div&gt;
          &lt;/div&gt;
      &lt;/div&gt;
      ))}
      
      
    &lt;/main&gt;
  )
}

export default Heading2
</code></pre>
<p>Also, when I add the key prop to the list like this <code>&lt;ul&gt;{detail.list.map(listItems, i =&gt;(&lt;li key={i}&gt;{listItems}&lt;/li&gt;))}</code>, I get a new error saying <em><strong>listItems is undefined</strong></em></p>
",23,1,0,2,javascript;reactjs,2022-08-24 11:26:54,2022-08-24 11:26:54,2022-08-24 11:43:13,i am mapping an array of objects i imported from a different component but i get the error warning  each child in a list should have a unique  key  prop  with the following error details also  when i add the key prop to the list like this  lt ul gt  detail list map listitems  i   gt   lt li key  i  gt  listitems  lt  li gt      i get a new error saying listitems is undefined,array of objects from a different component in react not mapping in list
14,13448373,73446907,How to temporarily remove commit/commits and get it back afterwards,"<p>Here is an example that explains the scenario that I'm facing -
I have a feature branch Branch-A. It has got a commit SHA-1000.This is followed by multiple new commits.Now I create a new branch called Branch-B from Branch-A.</p>
<p>The commit SHA-1000 is reverted in Branch-A and In Branch-B new changes had been introduced.</p>
<p>Finally when the Branch-B is merged back with Branch-A, the code of SHA-1000 will not be there in the resultant code but I want it back.</p>
<p>I understand that I can always revert the commit with which I had removed the commit SHA-1000. But it not possible for me to anticipate such a scenario and keep tract of changes. So how is these kind of scenarios handled in software development ?</p>
",36,1,0,2,git;github,2022-08-22 17:39:03,2022-08-22 17:39:03,2022-08-22 20:30:26,the commit sha  is reverted in branch a and in branch b new changes had been introduced  finally when the branch b is merged back with branch a  the code of sha  will not be there in the resultant code but i want it back  i understand that i can always revert the commit with which i had removed the commit sha   but it not possible for me to anticipate such a scenario and keep tract of changes  so how is these kind of scenarios handled in software development  ,how to temporarily remove commit commits and get it back afterwards
15,4000905,73447101,Ruby on Rails on Docker - Bundler seems to install different version of gem,"<p>I'm trying to setup a legacy Rails 5.2 app over Docker. The output of <code>bundle install</code> suggests that it's installing the correct version of <code>rake (13.0.6)</code> but when I try to run the container, it gives me the following error:</p>
<pre><code>/usr/local/bundle/bin/rake:23:in `load': cannot load such file -- /usr/local/bundle/gems/rake-13.0.6/exe/rake (LoadError)   from /usr/local/bundle/bin/rake:23:in `
'
</code></pre>
<p>Here's my Dockerfile:</p>
<pre><code>FROM ruby:2.6.0

# change to the application's directory
WORKDIR /application/testapp

COPY ./testapp/Gemfile /application/testapp/Gemfile
COPY ./testapp/Gemfile.lock /application/testapp/Gemfile.lock

# Setting env up
ARG RAILS_ENV
ENV RAILS_ENV=$RAILS_ENV
ENV RAKE_ENV=$RAILS_ENV
ENV RACK_ENV=$RAILS_ENV

# install gems and JavaScript runtime
RUN apt-get update &amp;&amp; apt-get --fix-broken install -y install software-properties-common git \
    &amp;&amp; apt-add-repository 'deb http://security.debian.org/debian-security stretch/updates main' \
    # &amp;&amp; echo 'deb http://ftp.de.debian.org/debian sid main' &gt;&gt; '/etc/apt/sources.list' \
    &amp;&amp; apt-get update \
    &amp;&amp; apt-get -o Dpkg::Options::=&quot;--force-overwrite&quot; --fix-broken install -y build-essential nodejs patch ruby-dev zlib1g-dev liblzma-dev zlibc zlib1g zlib1g-dev libxslt-dev libpq-dev openjdk-8-jdk \
    &amp;&amp; bundle check || bundle install \
    &amp;&amp; curl -sL https://deb.nodesource.com/setup_10.x | bash -
    
# copy application code
COPY . /application

# Add a script to be executed every time the container starts.
COPY ./testapp_system/docker/development/docker-entrypoint.sh /usr/bin/
RUN chmod +x /usr/bin/docker-entrypoint.sh
ENTRYPOINT [&quot;docker-entrypoint.sh&quot;]

EXPOSE 3000

# Start the main process.
CMD [&quot;rails&quot;, &quot;server&quot;, &quot;-b&quot;, &quot;0.0.0.0&quot;, &quot;-p&quot;, &quot;3000&quot;]
</code></pre>
<p>Here's the part of Docker image build process that mentions the rake bundle:</p>
<pre><code>...
Fetching https://github.com/sinatra/sinatra.git
Fetching rake 13.0.6
Installing rake 13.0.6
Fetching concurrent-ruby 1.1.10
Installing concurrent-ruby 1.1.10
Fetching i18n 1.12.0
Installing i18n 1.12.0
Fetching minitest 5.16.2
Installing minitest 5.16.2
Fetching thread_safe 0.3.6
Installing thread_safe 0.3.6
Fetching tzinfo 1.2.10
Installing tzinfo 1.2.10
Fetching activesupport 5.2.8.1
Installing activesupport 5.2.8.1
...
</code></pre>
<p>But then in the Docker entrypoint file (<code>docker-entrypoint.sh</code>) if I try to list the gems in the directory <code>/usr/local/bundle/gems</code>, here's what I'm able to see:</p>
<pre><code>...
drwxr-sr-x   3 root staff  4096 Aug  2 15:43 rack-test-1.1.0
drwxr-sr-x   2 root staff  4096 Aug  2 15:43 rails-5.2.3
drwxr-sr-x   4 root staff  4096 Aug  2 15:43 rails-dom-testing-2.0.3
drwxr-sr-x   4 root staff  4096 Aug  2 15:43 rails-html-sanitizer-1.3.0
drwxr-sr-x   3 root staff  4096 Aug  2 15:43 rails_event_store-0.42.0
drwxr-sr-x   4 root staff  4096 Aug  2 15:43 rails_event_store_active_record-0.42.0
drwxr-sr-x   4 root staff  4096 Aug  2 15:43 railties-5.2.3
drwxr-sr-x   4 root staff  4096 Aug  2 15:43 rainbow-3.0.0
drwxr-sr-x   7 root staff  4096 Aug  2 15:43 rake-13.0.0
drwxr-sr-x   5 root staff  4096 Aug  2 15:43 rb-fsevent-0.10.3
drwxr-sr-x   4 root staff  4096 Aug  2 15:43 rb-inotify-0.10.0
drwxr-sr-x   4 root staff  4096 Aug  2 15:43 recaptcha-5.2.1
drwxr-sr-x   3 root staff  4096 Aug  2 15:43 redis-4.1.3
drwxr-sr-x   4 root staff  4096 Aug  2 15:43 redis-namespace-1.7.0
drwxr-sr-x   4 root staff  4096 Aug  2 15:43 regexp_parser-1.6.0
drwxr-sr-x   4 root staff  4096 Aug  2 15:43 request_store-1.5.0
...
</code></pre>
<p>Here's the ouput of gem env:</p>
<pre><code>RubyGems Environment:
  - RUBYGEMS VERSION: 3.0.1
  - RUBY VERSION: 2.6.0 (2018-12-25 patchlevel 0) [x86_64-linux]
  - INSTALLATION DIRECTORY: /usr/local/bundle
  - USER INSTALLATION DIRECTORY: /root/.gem/ruby/2.6.0
  - RUBY EXECUTABLE: /usr/local/bin/ruby
  - GIT EXECUTABLE: /usr/bin/git
  - EXECUTABLE DIRECTORY: /usr/local/bundle/bin
  - SPEC CACHE DIRECTORY: /root/.gem/specs
  - SYSTEM CONFIGURATION DIRECTORY: /usr/local/etc
  - RUBYGEMS PLATFORMS:
    - ruby
    - x86_64-linux
  - GEM PATHS:
     - /usr/local/bundle
     - /root/.gem/ruby/2.6.0
     - /usr/local/lib/ruby/gems/2.6.0
  - GEM CONFIGURATION:
     - :update_sources =&gt; true
     - :verbose =&gt; true
     - :backtrace =&gt; false
     - :bulk_threshold =&gt; 1000
     - &quot;install&quot; =&gt; &quot;--no-document&quot;
     - &quot;update&quot; =&gt; &quot;--no-document&quot;
  - REMOTE SOURCES:
     - https://rubygems.org/
</code></pre>
<p>Am I looking at the wrong directory? Why is it giving the error?</p>
",17,0,0,5,ruby-on-rails;docker;rubygems;rake;bundler,2022-08-22 17:53:21,2022-08-22 17:53:21,2022-08-22 17:53:21,i m trying to setup a legacy rails   app over docker  the output of bundle install suggests that it s installing the correct version of rake      but when i try to run the container  it gives me the following error  here s my dockerfile  here s the part of docker image build process that mentions the rake bundle  but then in the docker entrypoint file  docker entrypoint sh  if i try to list the gems in the directory  usr local bundle gems  here s what i m able to see  here s the ouput of gem env  am i looking at the wrong directory  why is it giving the error ,ruby on rails on docker   bundler seems to install different version of gem
16,108350,35146260,How do I install Git for Windows software to a specific directory?,"<p>I have just downloaded the latest Git for Windows installer, v2.4.  It appears to <em>want</em> to install to the standard Windows ""Program files"" (with-spaces-in-name) directory.  </p>

<p>Since I have all my development code in a folder called (<em>simply</em>) ""<code>/bin</code>"" -- I want to see if there's a command line option or parameter to change the install directory.</p>

<p>In my case, these days I use a environment variable such as <code>GIT_HOME</code> for important software like git; so it would be useful if there was a way to apply that to things like git commands, etc once I have the program installed.</p>

<p><em>possibly</em> related:</p>

<ul>
<li><a href=""https://stackoverflow.com/questions/18288723/how-do-i-change-the-directory-in-git-bash-with-git-for-windows"">How do I change the directory in Git Bash with Git for Windows?</a></li>
</ul>

<p>I also came across a few questions asking: ""<em>whereis</em> <code>git</code>"".  That's answered above, however I take that as an indicator that others may want git somewhere else too.</p>
",8701,2,10,3,windows;git;bash,2016-02-02 08:10:30,2016-02-02 08:10:30,2022-08-22 00:32:34,i have just downloaded the latest git for windows installer  v    it appears to want to install to the standard windows program files  with spaces in name  directory    since i have all my development code in a folder called  simply   bin    i want to see if there s a command line option or parameter to change the install directory  in my case  these days i use a environment variable such as git_home for important software like git  so it would be useful if there was a way to apply that to things like git commands  etc once i have the program installed  possibly related  i also came across a few questions asking  whereis git   that s answered above  however i take that as an indicator that others may want git somewhere else too ,how do i install git for windows software to a specific directory 
17,1580892,25855293,How to install CDT to Eclipse Luna,"<p>I am trying to install the C/C++ development tools for Eclipse Luna.</p>

<p>Taking reference from this page <a href=""http://www.eclipse.org/cdt/downloads.php"" rel=""nofollow noreferrer"">here</a>, I navigated to Help> Install New Software> and placed <code>http://download.eclipse.org/tools/cdt/releases/8.4</code>
in the ""Works with"" section. </p>

<p>I got the options for C/C++ Development Tools and C/C++ Development Tools SDK which I downloaded and restarted Eclipse. However, on restarting eclipse I cannot find any place/interface to create C programs or files. The tools are showing up in the installed softwares list(screen attached). </p>

<p>I have also installed MinGw as instructed <a href=""https://www3.ntu.edu.sg/home/ehchua/programming/howto/Cygwin_HowTo.html#mingw"" rel=""nofollow noreferrer"">here</a>. </p>

<p>Have I missed any step? How can I start C development in Luna. Please advice.<img src=""https://i.stack.imgur.com/o7oep.png"" alt=""enter image description here""></p>
",14661,4,6,3,c;eclipse;eclipse-cdt,2014-09-15 22:16:52,2014-09-15 22:16:52,2022-08-19 19:00:25,i am trying to install the c c   development tools for eclipse luna  i got the options for c c   development tools and c c   development tools sdk which i downloaded and restarted eclipse  however  on restarting eclipse i cannot find any place interface to create c programs or files  the tools are showing up in the installed softwares list screen attached    i have also installed mingw as instructed    have i missed any step  how can i start c development in luna  please advice ,how to install cdt to eclipse luna
19,10543310,73411155,Flatten a list inside list of tuples,"<p>I have the following list of tuples.</p>
<pre class=""lang-py prettyprint-override""><code>lst = 
    [
        ('LexisNexis', ['IT Services and IT Consulting ', ' New York City, NY']),
        ('AbacusNext', ['IT Services and IT Consulting ', ' La Jolla, California']), 
        ('Aderant', ['Software Development ', ' Atlanta, GA']),
        ('Anaqua', ['Software Development ', ' Boston, MA']),
        ('Thomson Reuters Elite', ['Software Development ', ' Eagan, Minnesota']),
        ('Litify', ['Software Development ', ' Brooklyn, New York'])
    ]
</code></pre>
<p>I want to flatten the lists in each tuple to be part of the tuples of <code>lst</code>.
I found this <a href=""https://stackoverflow.com/q/952914/10543310"">How do I make a flat list out of a list of lists?</a> but have no idea how to make it adequate to my case.</p>
",43,2,1,3,python;list;tuples,2022-08-19 05:03:22,2022-08-19 05:03:22,2022-08-19 05:17:19,i have the following list of tuples ,flatten a list inside list of tuples
20,19793156,73402079,Which Qt (pyside6) modules can I use for drawing modules can I use for 2D vector drawing and particle animation?,"<p>I am developing my degree work that consists of developing a <strong>GUI</strong> for the modeling of numerical methods, to simulate the behavior of the soil, the logic (backend) of the software is already implemented in python, my idea is to use <strong>pyside6</strong> for the development of the interface However, I have some doubts that I would like some of you to clarify or guide me. 1) I need to be able to make vectorial drawings (lines, areas, points) to be able to select and modify them, something similar to AutoCad but very basic, what modules could they use, from what I have been able to read could be <em>QPainter, qt quick, Qt Data Visualization, QGraphics</em>* But I don't know where to start, I'm a bit lost. It would be like the area marked with 1 in the following image:</p>
<p><a href=""https://i.stack.imgur.com/R79Oi.png"" rel=""nofollow noreferrer"">example image</a></p>
<p>With the above, the initial model (areas) must be drawn, but later I must show the results, which are many points (each area has many points) in movement with which module could I perform these animations, something similar to what appears in this gif:</p>
<p><a href=""https://i.stack.imgur.com/UenG2.gif"" rel=""nofollow noreferrer"">particle motion</a></p>
<p>I would be grateful if you could guide me, if I was not clear about something, I will gladly expand my comment</p>
<p>a greeting</p>
",36,0,-1,4,python;qt;user-interface;pyside6,2022-08-18 14:12:47,2022-08-18 14:12:47,2022-08-18 15:28:48,i am developing my degree work that consists of developing a gui for the modeling of numerical methods  to simulate the behavior of the soil  the logic  backend  of the software is already implemented in python  my idea is to use pyside for the development of the interface however  i have some doubts that i would like some of you to clarify or guide me    i need to be able to make vectorial drawings  lines  areas  points  to be able to select and modify them  something similar to autocad but very basic  what modules could they use  from what i have been able to read could be qpainter  qt quick  qt data visualization  qgraphics  but i don t know where to start  i m a bit lost  it would be like the area marked with  in the following image   with the above  the initial model  areas  must be drawn  but later i must show the results  which are many points  each area has many points  in movement with which module could i perform these animations  something similar to what appears in this gif   i would be grateful if you could guide me  if i was not clear about something  i will gladly expand my comment a greeting,which qt  pyside  modules can i use for drawing modules can i use for d vector drawing and particle animation 
21,337522,4205130,What is duck typing?,"<p>What does <em><a href=""http://en.wikipedia.org/wiki/Duck_typing"" rel=""noreferrer"">duck typing</a></em> mean in software development?</p>
",167593,19,553,2,programming-languages;duck-typing,2010-11-17 16:03:34,2010-11-17 16:03:34,2022-08-18 12:47:52,what does  mean in software development ,what is duck typing 
22,14335655,73366092,Debug connection drops between Android Studio and iOS simulator (iPhone 13),"<p>I bought an old Mac so that I could build my Flutter app for iOS. But even when I just start a new Flutter project and try to run the demo app on my iOS simulator, the app keeps crashing, and this is the only output I get:</p>
<pre><code>Launching lib/main.dart on iPhone 13 in debug mode...
Running Xcode build...
Xcode build done.                                           48.5s
Error waiting for a debug connection: The log reader failed unexpectedly
Error launching application on iPhone 13.
</code></pre>
<p>If I close the app on the simulator and open it again, it actually runs fine! So there is nothing wrong with the building or the code, it seems... But still, the connection drops. Why?</p>
<p>When I ran <code>flutter attach</code>, I got this output:</p>
<pre><code>Syncing files to device iPhone 13...                               12.8s

Flutter run key commands.
r Hot reload. 🔥🔥🔥
R Hot restart.
h List all available interactive commands.
d Detach (terminate &quot;flutter run&quot; but leave application running).
c Clear the screen
q Quit (terminate the application on the device).

💪 Running with sound null safety 💪

An Observatory debugger and profiler on iPhone 13 is available at: http://127.0.0.1:61007/KV20anKK53k=/
The Flutter DevTools debugger and profiler on iPhone 13 is available at:
http://127.0.0.1:9100?uri=http://127.0.0.1:61007/KV20anKK53k=/
Lost connection to device.

</code></pre>
<p>I have tried <code>flutter clean</code> and &quot;Invalidate caches and restart&quot; as well as <code>pub upgrade</code> and <code>pod update</code> but nothing works.</p>
<p>Any tips?</p>
<h2>Flutter doctor</h2>
<p>This is my <code>flutter doctor</code> output:</p>
<pre><code>[✓] Flutter (Channel stable, 3.0.5, on macOS 11.6.7 20G630 darwin-x64, locale en-US)
    • Flutter version 3.0.5 at /Users/karolinahagegard/Development/flutter
    • Upstream repository https://github.com/flutter/flutter.git
    • Framework revision f1875d570e (5 weeks ago), 2022-07-13 11:24:16 -0700
    • Engine revision e85ea0e79c
    • Dart version 2.17.6
    • DevTools version 2.12.2

[✓] Android toolchain - develop for Android devices (Android SDK version 33.0.0)
    • Android SDK at /Users/karolinahagegard/Library/Android/sdk
    • Platform android-33, build-tools 33.0.0
    • Java binary at: /Applications/Android Studio.app/Contents/jre/Contents/Home/bin/java
    • Java version OpenJDK Runtime Environment (build 11.0.12+0-b1504.28-7817840)
    • All Android licenses accepted.

[✓] Xcode - develop for iOS and macOS (Xcode 13.2.1)
    • Xcode at /Applications/Xcode.app/Contents/Developer
    • CocoaPods version 1.11.3

[✓] Chrome - develop for the web
    • Chrome at /Applications/Google Chrome.app/Contents/MacOS/Google Chrome

[✓] Android Studio (version 2021.2)
    • Android Studio at /Applications/Android Studio.app/Contents
    • Flutter plugin can be installed from:
      🔨 https://plugins.jetbrains.com/plugin/9212-flutter
    • Dart plugin can be installed from:
      🔨 https://plugins.jetbrains.com/plugin/6351-dart
    • Java version OpenJDK Runtime Environment (build 11.0.12+0-b1504.28-7817840)

[✓] Connected device (3 available)
    • iPhone 13 (mobile) • 4EA7D6B9-5026-4FE8-8904-0A48B7B3253C • ios            •
      com.apple.CoreSimulator.SimRuntime.iOS-15-2 (simulator)
    • macOS (desktop)    • macos                                • darwin-x64     • macOS 11.6.7 20G630 darwin-x64
    • Chrome (web)       • chrome                               • web-javascript • Google Chrome 104.0.5112.79

[✓] HTTP Host Availability
    • All required HTTP hosts are available

• No issues found!
</code></pre>
<h2>Mac specs</h2>
<p>Some info about the computer:</p>
<pre><code>Hardware Overview:

  Model Name:   MacBook Pro
  Model Identifier: MacBookPro11,1
  Processor Name:   Dual-Core Intel Core i5
  Processor Speed:  2,6 GHz
  Number of Processors: 1
  Total Number of Cores:    2
  L2 Cache (per Core):  256 KB
  L3 Cache: 3 MB
  Hyper-Threading Technology:   Enabled
  Memory:   8 GB
  System Firmware Version:  433.120.6.0.0
  SMC Version (system): 2.16f68
</code></pre>
<pre><code>System Software Overview:

  System Version:   macOS 11.6.7 (20G630)
  Kernel Version:   Darwin 20.6.0
  Boot Volume:  Untitled
  Boot Mode:    Normal
  Secure Virtual Memory:    Enabled
  System Integrity Protection:  Enabled
  Time since boot:  19 days 2:45
</code></pre>
",27,1,0,2,android-studio;ios-simulator,2022-08-15 23:23:44,2022-08-15 23:23:44,2022-08-18 11:34:09,i bought an old mac so that i could build my flutter app for ios  but even when i just start a new flutter project and try to run the demo app on my ios simulator  the app keeps crashing  and this is the only output i get  if i close the app on the simulator and open it again  it actually runs fine  so there is nothing wrong with the building or the code  it seems    but still  the connection drops  why  when i ran flutter attach  i got this output  i have tried flutter clean and  invalidate caches and restart  as well as pub upgrade and pod update but nothing works  any tips  this is my flutter doctor output  some info about the computer ,debug connection drops between android studio and ios simulator  iphone  
23,2737181,55261518,What IFC versions are supported in Autodesk Forge?,"<p>We are working on an integration of an external software with Autodesk Forge. Following openBIM, we want to focus on model data in IFC format. Question is (and I was not able to find this answer online) which IFC versions are supported in the Forge ecosystem? Would one have to be careful with using e.g. only IFC 2x3 or is IFC 4 Add4 also supported? The documentation at <a href=""https://forge.autodesk.com/en/docs/model-derivative/v2/developers_guide/supported-translations/"" rel=""nofollow noreferrer"">https://forge.autodesk.com/en/docs/model-derivative/v2/developers_guide/supported-translations/</a> only generally mentions the IFC support, but no versions ... which would be a necessary information IMHO, as the format is still in active development.</p>
",388,1,2,3,autodesk-forge;autodesk-viewer;autodesk-model-derivative,2019-03-20 15:09:12,2019-03-20 15:09:12,2022-08-18 05:14:43,we are working on an integration of an external software with autodesk forge  following openbim  we want to focus on model data in ifc format  question is  and i was not able to find this answer online  which ifc versions are supported in the forge ecosystem  would one have to be careful with using e g  only ifc x or is ifc  add also supported  the documentation at  only generally mentions the ifc support  but no versions     which would be a necessary information imho  as the format is still in active development ,what ifc versions are supported in autodesk forge 
24,19558150,73394250,What&#39;s the best programming pattern in Flutter?,"<p>I've been working as a Jr. Developer with Flutter for 4 months in a local software development company. I'm on the cross-platform apps part, since I came here they taught me to work with the BLoC pattern, so based on your experience, I would like you to recommend the best practices for working with this language, thanks in advance.</p>
",32,0,-2,4,flutter;design-patterns;cross-platform;bloc,2022-08-17 22:55:52,2022-08-17 22:55:52,2022-08-17 22:55:52,i ve been working as a jr  developer with flutter for  months in a local software development company  i m on the cross platform apps part  since i came here they taught me to work with the bloc pattern  so based on your experience  i would like you to recommend the best practices for working with this language  thanks in advance ,what   s the best programming pattern in flutter 
25,4507231,73372708,Add existing local PyCharm Python project to an initiated but empty GitHub repository?,"<p>I'm trying to follow the PyCharm instructions on linking a local Python PyCharm project with a GitHub repository. The instructions take the user through the steps necessary to create and initiate a GitHub repository from the comfort of PyCharm. It then goes into checking in your code etc.</p>
<p>Unfortunately, I've done things a little bit differently, causing a bit of a roadblock.</p>
<p>I created a GitHub repository online, adding the readme and license data. This puts me out of sync with the PyCharm instructions (that step could have been done within PyCharm). So, my question is, how do I synch a PyCharm project up with an existing but otherwise empty GitHub repository?</p>
<p><strong>Edit #1</strong>
In response to some of the comments (thanks for your time and attention), I want to know how to do this <em>only</em> through PyCharm due to the mixed experience in my team. This work is for several users who aren't going to be computer-savvy. There is me (the software engineer/scientist) and several medical doctors. The med doctors will edit text files while I do the actual development. I'd rather they did everything through PyCharm for reasons of technical consistency (different machines, text encoding, you name it).</p>
<p>This is also why this question is not a duplicate.</p>
",27,0,0,3,python;github;pycharm,2022-08-16 13:42:54,2022-08-16 13:42:54,2022-08-17 20:50:47,i m trying to follow the pycharm instructions on linking a local python pycharm project with a github repository  the instructions take the user through the steps necessary to create and initiate a github repository from the comfort of pycharm  it then goes into checking in your code etc  unfortunately  i ve done things a little bit differently  causing a bit of a roadblock  i created a github repository online  adding the readme and license data  this puts me out of sync with the pycharm instructions  that step could have been done within pycharm   so  my question is  how do i synch a pycharm project up with an existing but otherwise empty github repository  this is also why this question is not a duplicate ,add existing local pycharm python project to an initiated but empty github repository 
26,19354086,73390182,What are some common industry practices and patterns involving files that are useful to know about?,"<p>As programmers, we often work with specific types of files and I have found that many simple and useful practices and patterns exist that involve the use of a certain type of file. This can range from the usage of <code>.toml</code> or <code>.ini</code> files to store configuration details for a piece of software to how <code>makefiles</code> are used to automate building C and C++ programs, or how we make use of <code>.yaml</code> files to configure CI/CD or even the extremely simple example of including a <code>requirements.txt</code> file in python source code for others to install dependencies.</p>
<p>From my experience, often having knowledge of these practices involving files can be very useful in giving one a clearer image of the ever evolving field as a whole. As this provides us with more knowledge of common industry practices, some of which may be very eye-opening (eg: Build Automation comes in very many forms across different development platforms and often we may see shell-scripts used for automating builds rather than third party tooling).</p>
<p>Due to the often simple nature of these practices it can be easily explained at the surface level in manageable chunks. An anecdote from my experience would be when I stored an API key as a constant in my source code, and was told to instead make use of a .env file and read from it.</p>
<p>As such my question to you all is:</p>
<p><strong>What are some common practices involving files do you make use of or that you think new programmers should be aware of?</strong></p>
<p><strong>What file formats do you often see used for certain tasks like configuration, automation, etc?</strong></p>
",16,0,1,2,file;design-patterns,2022-08-17 17:24:17,2022-08-17 17:24:17,2022-08-17 17:24:17,as programmers  we often work with specific types of files and i have found that many simple and useful practices and patterns exist that involve the use of a certain type of file  this can range from the usage of  toml or  ini files to store configuration details for a piece of software to how makefiles are used to automate building c and c   programs  or how we make use of  yaml files to configure ci cd or even the extremely simple example of including a requirements txt file in python source code for others to install dependencies  from my experience  often having knowledge of these practices involving files can be very useful in giving one a clearer image of the ever evolving field as a whole  as this provides us with more knowledge of common industry practices  some of which may be very eye opening  eg  build automation comes in very many forms across different development platforms and often we may see shell scripts used for automating builds rather than third party tooling   due to the often simple nature of these practices it can be easily explained at the surface level in manageable chunks  an anecdote from my experience would be when i stored an api key as a constant in my source code  and was told to instead make use of a  env file and read from it  as such my question to you all is  what are some common practices involving files do you make use of or that you think new programmers should be aware of  what file formats do you often see used for certain tasks like configuration  automation  etc ,what are some common industry practices and patterns involving files that are useful to know about 
27,17287794,73386739,How to fix R on centos8,"<p>Today, i want open R on linux:</p>
<pre><code>$R
bash: R: command not found...
</code></pre>
<p>and then I remember I installed R using dnf:</p>
<pre><code>$dnf list|grep R-core
Repository libnvidia-container is listed more than once in the configuration
Repository libnvidia-container-experimental is listed more than once in the configuration
R-core.x86_64                                                     4.1.3-1.el8                                                tuna                  
R-core-devel.x86_64                                               4.1.3-1.el8                                                tuna                  
</code></pre>
<p>It looks like I installed R, so I'm trying to find the location of R:</p>
<pre><code>$which R
/usr/bin/which: no R in (/home/data/sym/software/metawrap/bin/:/home/data/sym/software/ncbi-blast-2.12.0+/bin/:/usr/bin:/home/data/sym/software/FastQC:/usr/condabin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/root/software:/home/data/sym//.aspera/connect/bin/)
</code></pre>
<p>I think I may have accidentally deleted some files of R, which made R unable to run, so I tried to reinstall R, and met error, I tried to solve error, and met more error:</p>
<pre><code>$dnf install R
Repository libnvidia-container is listed more than once in the configuration
Repository libnvidia-container-experimental is listed more than once in the configuration
Last metadata expiration check: 1:59:20 ago on Wed 17 Aug 2022 04:09:30 PM CST.
Error:
 Problem: package R-4.1.3-1.el8.x86_64 requires R-devel = 4.1.3-1.el8, but none of the providers can be installed
  - package R-devel-4.1.3-1.el8.x86_64 requires R-core-devel = 4.1.3-1.el8, but none of the providers can be installed
  - conflicting requests
  - nothing provides openblas-devel needed by R-core-devel-4.1.3-1.el8.x86_64
  - nothing provides tcl-devel needed by R-core-devel-4.1.3-1.el8.x86_64
  - nothing provides texinfo-tex needed by R-core-devel-4.1.3-1.el8.x86_64
(try to add '--skip-broken' to skip uninstallable packages or '--nobest' to use not only best candidate packages)

$ dnf install R --skip-broken
Repository libnvidia-container is listed more than once in the configuration
Repository libnvidia-container-experimental is listed more than once in the configuration
Last metadata expiration check: 2:04:58 ago on Wed 17 Aug 2022 04:09:30 PM CST.
Dependencies resolved.
Nothing to do.
Complete!

$dnf install -y epel-release
Repository libnvidia-container is listed more than once in the configuration
Repository libnvidia-container-experimental is listed more than once in the configuration
Last metadata expiration check: 2:02:01 ago on Wed 17 Aug 2022 04:09:30 PM CST.
Package epel-release-8-16.el8.noarch is already installed.
Dependencies resolved.
Nothing to do.
Complete!

$ dnf install openblas-devel
Repository libnvidia-container is listed more than once in the configuration
Repository libnvidia-container-experimental is listed more than once in the configuration
Last metadata expiration check: 2:01:16 ago on Wed 17 Aug 2022 04:09:30 PM CST.
No match for argument: openblas-devel
Error: Unable to find a match: openblas-devel

$ dnf config-manager --set-enabled PowerTools
Repository libnvidia-container is listed more than once in the configuration
Repository libnvidia-container-experimental is listed more than once in the configuration
Error: No matching repo to modify: PowerTools.

$ dnf grouplist
Repository libnvidia-container is listed more than once in the configuration
Repository libnvidia-container-experimental is listed more than once in the configuration
Last metadata expiration check: 2:06:29 ago on Wed 17 Aug 2022 04:09:30 PM CST.
Available Environment Groups:
   Server
   Workstation
   KDE Plasma Workspaces
   Virtualization Host
Installed Environment Groups:
   Server with GUI
Installed Groups:
   Container Management
   Development Tools
   Headless Management
Available Groups:
   Fedora Packager
   Xfce
   .NET Core Development
   Graphical Administration Tools
   Network Servers
   RPM Development Tools
   Scientific Support
   Security Tools
   Smart Card Support
   System Tools

$ dnf repolist
Repository libnvidia-container is listed more than once in the configuration
Repository libnvidia-container-experimental is listed more than once in the configuration
repo id                                                        repo name
1                                                              1
2                                                              2
3                                                              3
4                                                              4
5                                                              5
docker                                                         docker
elrepo                                                         ELRepo.org Community Enterprise Linux Repository - el8
libnvidia-container                                            libnvidia-container
libnvidia-container-experimental                               libnvidia-container-experimental
mo                                                             mo
nvidia-container-runtime                                       nvidia-container-runtime
tuna                                                           tuna
</code></pre>
<p>And i tried to install all the missing dependencies:</p>
<pre><code>$dnf install openblas
Last metadata expiration check: 3:21:34 ago on Wed 17 Aug 2022 04:09:30 PM CST.
Error:
 Problem: cannot install the best candidate for the job
  - nothing provides libgfortran.so.5()(64bit) needed by openblas-0.3.15-3.el8.x86_64
  - nothing provides libgfortran.so.5(GFORTRAN_8)(64bit) needed by openblas-0.3.15-3.el8.x86_64
(try to add '--skip-broken' to skip uninstallable packages or '--nobest' to use not only best candidate packages)

$dnf search libgfortran
Last metadata expiration check: 3:25:22 ago on Wed 17 Aug 2022 04:09:30 PM CST.
============================================================ Name Matched: libgfortran ========================================
compat-libgfortran-48.i686 : Compatibility Fortran runtime library version 4.8.5
compat-libgfortran-48.x86_64 : Compatibility Fortran runtime library version 4.8.5

$dnf install compat-libgfortran-48.x86_64
Last metadata expiration check: 3:26:34 ago on Wed 17 Aug 2022 04:09:30 PM CST.
Error:
 Problem: conflicting requests
  - nothing provides libquadmath.so.0()(64bit) needed by compat-libgfortran-48-4.8.5-36.1.el8.x86_64
  - nothing provides libquadmath.so.0(QUADMATH_1.0)(64bit) needed by compat-libgfortran-48-4.8.5-36.1.el8.x86_64
(try to add '--skip-broken' to skip uninstallable packages or '--nobest' to use not only best candidate packages)

$dnf search libquadmath
Last metadata expiration check: 3:29:24 ago on Wed 17 Aug 2022 04:09:30 PM CST.
============================================================ Name Matched: libquadmath ========================================
gcc-toolset-10-libquadmath-devel.i686 : GCC 10 __float128 support
gcc-toolset-10-libquadmath-devel.x86_64 : GCC 10 __float128 support
gcc-toolset-11-libquadmath-devel.i686 : GCC 11 __float128 support
gcc-toolset-11-libquadmath-devel.x86_64 : GCC 11 __float128 support
gcc-toolset-9-libquadmath-devel.i686 : GCC 9 __float128 support
gcc-toolset-9-libquadmath-devel.x86_64 : GCC 9 __float128 support
libquadmath-devel.i686 : GCC __float128 support
libquadmath-devel.x86_64 : GCC __float128 support
</code></pre>
<p>So, what exactly is the problem?</p>
",35,0,0,3,r;centos8;dnf,2022-08-17 13:19:01,2022-08-17 13:19:01,2022-08-17 14:57:02,today  i want open r on linux  and then i remember i installed r using dnf  it looks like i installed r  so i m trying to find the location of r  i think i may have accidentally deleted some files of r  which made r unable to run  so i tried to reinstall r  and met error  i tried to solve error  and met more error  and i tried to install all the missing dependencies  so  what exactly is the problem ,how to fix r on centos
28,6326455,72982683,How to link KSP DLL to Certificate,"<p>I want to sign HLKX files using a certificate for which the private key is not available on the local system.</p>
<p>I created a custom Key Storage Provider (basically a shell for testing purposes) based on the code sample for a KSP DLL in &quot;Cryptographic Provider Development Kit&quot; and I'm able to register it and it is shown in the enumeration of KSPs available on the system.</p>
<p>I'm using the sign function that is shown as an example at:
<a href=""https://docs.microsoft.com/en-us/windows-hardware/test/hlk/user/hlk-signing-with-an-hsm"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/windows-hardware/test/hlk/user/hlk-signing-with-an-hsm</a>
in a C# application.</p>
<p>The custom KSP dll is supposed to handle all the sign commands and connect to a backend that allows using the private key which is stored in a HSM behind an additional software layer that is limiting key access to certain users.</p>
<p>When I'm running the application the signing fails due to the missing private key. So, I need to somehow link the certificate (being it the certificate in a file or imported to the system's certificate store) to the KSP causing the calls for signing hashes etc. to end up in the KSP's API, but I couldn't find any suitable information on how to either:
a) Add the reference to the KSP to the C# signing call
or
b) Import the certificate to the certificate store with it referencing the KSP so that it will be used automatically if the certificate is used for signing.</p>
<p>So, how can I do either a) or b) or what other way is there to manually handle this? The signing application is just using C# because that's the only sort-of sample for this use case that I could find from Microsoft. If there would be a sample in C/C++ that would be fine, too. I guess the problem would be the same in case of using a CSP instead of KSP but unfortunately many posts are massively mixing the two.</p>
",21,1,0,1,microsoft-key-storage-provider,2022-07-14 18:02:32,2022-07-14 18:02:32,2022-08-17 14:36:12,i want to sign hlkx files using a certificate for which the private key is not available on the local system  i created a custom key storage provider  basically a shell for testing purposes  based on the code sample for a ksp dll in  cryptographic provider development kit  and i m able to register it and it is shown in the enumeration of ksps available on the system  the custom ksp dll is supposed to handle all the sign commands and connect to a backend that allows using the private key which is stored in a hsm behind an additional software layer that is limiting key access to certain users  so  how can i do either a  or b  or what other way is there to manually handle this  the signing application is just using c  because that s the only sort of sample for this use case that i could find from microsoft  if there would be a sample in c c   that would be fine  too  i guess the problem would be the same in case of using a csp instead of ksp but unfortunately many posts are massively mixing the two ,how to link ksp dll to certificate
30,13203841,73368130,R: Package Installation Requires &quot;Java SE Development Kit 11&quot;?,"<p>I am trying to follow the tutorial here: <a href=""https://cran.r-project.org/web/packages/r5r/vignettes/intro_to_r5r.html"" rel=""nofollow noreferrer"">https://cran.r-project.org/web/packages/r5r/vignettes/intro_to_r5r.html</a></p>
<pre><code>options(java.parameters = '-Xmx2G')
install.packages('r5r')

library(r5r)
library(sf)
library(data.table)
library(ggplot2)
library(mapview)
mapviewOptions(platform = 'leafgl')

data_path &lt;- system.file(&quot;extdata/poa&quot;, package = &quot;r5r&quot;)
poi &lt;- fread(file.path(data_path, &quot;poa_points_of_interest.csv&quot;))
points &lt;- fread(file.path(data_path, &quot;poa_hexgrid.csv&quot;))
points &lt;- points[ c(sample(1:nrow(points), 10, replace=TRUE)), ]
</code></pre>
<p>Everything seems to work up to here (I had to install a 64 bit version of Java) - the following line produces an error:</p>
<pre><code>r5r_core &lt;- setup_r5(data_path = data_path, verbose = FALSE)

Error in setup_r5(data_path = data_path, verbose = FALSE) : 
  This package requires the Java SE Development Kit 11.
Please update your Java installation. The jdk 11 can be downloaded from either:
  - openjdk: https://jdk.java.net/java-se-ri/11
  - oracle: https://www.oracle.com/java/technologies/javase-jdk11-downloads.html
</code></pre>
<p>I had followed the instructions by downloading the updates from this website <a href=""https://jdk.java.net/java-se-ri/11"" rel=""nofollow noreferrer"">https://jdk.java.net/java-se-ri/11</a> :</p>
<p><a href=""https://i.stack.imgur.com/Secjk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Secjk.png"" alt=""enter image description here"" /></a></p>
<p>But I am still getting the same error.</p>
<p>I consulted this website (<a href=""https://rdrr.io/cran/installr/man/install.java.html"" rel=""nofollow noreferrer"">https://rdrr.io/cran/installr/man/install.java.html</a>) and tried to install this a different way:</p>
<pre><code>library(installr)

# does the &quot;path&quot; argument in install.jdk() need to be changed?

&gt; install.jdk(
version = 11,
page_with_download_url = &quot;http://jdk.java.net/java-se-ri/&quot;,
path = &quot;C:/java&quot;)

trying URL 'https://download.java.net/openjdk/jdk11/ri/openjdk-11+28_windows-x64_bin.zip'
Content type 'application/zip' length 187396683 bytes (178.7 MB)
downloaded 178.7 MB
</code></pre>
<p>But the same error persists when I try to run the code:</p>
<pre><code>r5r_core &lt;- setup_r5(data_path = data_path, verbose = FALSE)

Error in setup_r5(data_path = data_path, verbose = FALSE) : 
  This package requires the Java SE Development Kit 11.
Please update your Java installation. The jdk 11 can be downloaded from either:
  - openjdk: https://jdk.java.net/java-se-ri/11
  - oracle: https://www.oracle.com/java/technologies/javase-jdk11-downloads.html
</code></pre>
<p><strong>Can someone please show me what I am doing wrong? Am I supposed to be doing something with the Java SE Development Kit that I downloaded? Am I supposed to be copy/paste these files somewhere special?</strong></p>
<p>Thanks!</p>
<p>Notes:</p>
<pre><code>&gt; find.java &lt;- function() {
     for (root in c(&quot;HLM&quot;, &quot;HCU&quot;)) for (key in c(&quot;Software\\JavaSoft\\Java Runtime Environment&quot;, 
                                                 &quot;Software\\JavaSoft\\Java Development Kit&quot;)) {
         hive &lt;- try(utils::readRegistry(key, root, 2), 
                     silent = TRUE)
         if (!inherits(hive, &quot;try-error&quot;)) 
             return(hive)
     }
     hive
}

&gt; find.java()

$BrowserJavaVersion
[1] &quot;11.341.2&quot;

$CurrentVersion
[1] &quot;1.8&quot;

$`1.8`
$`1.8`$JavaHome
[1] &quot;C:\\Program Files\\Java\\jre1.8.0_341&quot;

$`1.8`$MicroVersion
[1] &quot;0&quot;

$`1.8`$RuntimeLib
[1] &quot;C:\\Program Files\\Java\\jre1.8.0_341\\bin\\server\\jvm.dll&quot;


$`1.8.0_341`
$`1.8.0_341`$JavaHome
[1] &quot;C:\\Program Files\\Java\\jre1.8.0_341&quot;

$`1.8.0_341`$MicroVersion
[1] &quot;0&quot;

$`1.8.0_341`$RuntimeLib
[1] &quot;C:\\Program Files\\Java\\jre1.8.0_341\\bin\\server\\jvm.dll&quot;

$`1.8.0_341`$MSI
[1] &quot;&lt;subkey&gt;

&gt; Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_341\\bin\\server\\jvm.dll')



&gt; .libPaths()
[1] &quot;C:/Users/me/OneDrive/Documents/R/win-library/4.1&quot; &quot;C:/Program Files/R/R-4.1.3/library&quot; 

&gt; sessionInfo()
R version 4.1.3 (2022-03-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 22000)

Matrix products: default

locale:
[1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252    LC_MONETARY=English_Canada.1252
[4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252   

  &gt; getwd()
[1] &quot;C:/Users/me/OneDrive/Documents&quot;
</code></pre>
<p>Links consulted:</p>
<ul>
<li><a href=""https://www.r-statistics.com/2012/08/how-to-load-the-rjava-package-after-the-error-java_home-cannot-be-determined-from-the-registry/"" rel=""nofollow noreferrer"">https://www.r-statistics.com/2012/08/how-to-load-the-rjava-package-after-the-error-java_home-cannot-be-determined-from-the-registry/</a></li>
<li><a href=""https://rdrr.io/cran/installr/man/install.java.html"" rel=""nofollow noreferrer"">https://rdrr.io/cran/installr/man/install.java.html</a></li>
</ul>
",35,0,0,3,java;r;installation,2022-08-16 05:21:11,2022-08-16 05:21:11,2022-08-16 05:21:11,i am trying to follow the tutorial here   everything seems to work up to here  i had to install a  bit version of java    the following line produces an error  i had followed the instructions by downloading the updates from this website     but i am still getting the same error  i consulted this website    and tried to install this a different way  but the same error persists when i try to run the code  can someone please show me what i am doing wrong  am i supposed to be doing something with the java se development kit that i downloaded  am i supposed to be copy paste these files somewhere special  thanks  notes  links consulted ,r  package installation requires  java se development kit   
32,1830955,17436024,Adapting the git-flow model for pre-production environments,"<p>I am thinking of extending the git-flow model for my current workplace, due to a particular scenario. But my scenario is so common that I'm surprised no-one's done this before with the git-flow model, and this makes me think I've missed an obvious problem. My question is: Is my proposed extension flawed?</p>
<p>The scenario: I have a number of development teams who develop from a common codebase, and we push out releases through several (permanent) environments: first to the systems integration environment (SIT), then to the UAT environment, then to pre-prod, and finally to production. This is strictly sequential, although any release candidate may fail in any environment, and so not make it any further. Thus each later environment is simply a slower-moving version of the previous environment.</p>
<p>We are introducing git for source control, we need a workflow, and git-flow looks like a good start.</p>
<p>We asked ourselves how to capture (i.e. how to know) what's in each environment at any time. The git-flow model seems to have essentially two core states: <code>main</code> and <code>develop</code>. They have an &quot;infinite lifespan&quot;. Other branches are just <a href=""http://nvie.com/posts/a-successful-git-branching-model/"" rel=""nofollow noreferrer"">&quot;supporting branches&quot;</a> with a &quot;limited life time&quot;. They exist only to allow development and to go from development to production (via a temporary release state). The git-flow model is based around going from development to release.</p>
<p>However, this doesn't map logically onto our scenario, with its multi-stage release sequence. I'm fine with the <code>develop</code> branch, of course. And the <code>main</code> branch clearly does map to our production environment. The <a href=""http://nvie.com/posts/a-successful-git-branching-model/"" rel=""nofollow noreferrer"">original git-flow description</a> says this about <code>main</code>:</p>
<blockquote>
<p>Therefore, each time when changes are merged back into main, this is a new
production release <em>by definition</em>. We tend to be very strict at this, so that
theoretically, we could use a Git hook script to automatically build and roll-out
our software to our production servers everytime there was a commit on main.</p>
</blockquote>
<p>Since <code>main</code> is a continuous record of production, it seems consistent that we should <em>extend the git-flow model</em> to have corresponding branches for SIT, UAT, and pre-prod. After all, they are permanent environments, with strict release procedures. They just change a bit quicker than production.</p>
<p>These additional, permanent, branches sit between <code>develop</code> and <code>main</code>, just as their corresponding environments do.</p>
<p>This now means it's easy to track releases to each environment, and the state of each environment. And merges for each are easier, too: the SIT branch requires a merge from <code>develop</code>, the UAT branch requires a merge from the SIT branch, the pre-prod branch requires a merge from the UAT branch, and finally the <code>main</code> branch (for production) requires a merge from the pre-prod branch. Each later branch is simply a slower-moving version of the previous branch.</p>
<p>Have I missed something?</p>
",11891,1,20,4,git;deployment;release-management;git-flow,2013-07-03 00:20:13,2013-07-03 00:20:13,2022-08-15 17:53:13,i am thinking of extending the git flow model for my current workplace  due to a particular scenario  but my scenario is so common that i m surprised no one s done this before with the git flow model  and this makes me think i ve missed an obvious problem  my question is  is my proposed extension flawed  the scenario  i have a number of development teams who develop from a common codebase  and we push out releases through several  permanent  environments  first to the systems integration environment  sit   then to the uat environment  then to pre prod  and finally to production  this is strictly sequential  although any release candidate may fail in any environment  and so not make it any further  thus each later environment is simply a slower moving version of the previous environment  we are introducing git for source control  we need a workflow  and git flow looks like a good start  we asked ourselves how to capture  i e  how to know  what s in each environment at any time  the git flow model seems to have essentially two core states  main and develop  they have an  infinite lifespan   other branches are just  with a  limited life time   they exist only to allow development and to go from development to production  via a temporary release state   the git flow model is based around going from development to release  however  this doesn t map logically onto our scenario  with its multi stage release sequence  i m fine with the develop branch  of course  and the main branch clearly does map to our production environment  the  says this about main  since main is a continuous record of production  it seems consistent that we should extend the git flow model to have corresponding branches for sit  uat  and pre prod  after all  they are permanent environments  with strict release procedures  they just change a bit quicker than production  these additional  permanent  branches sit between develop and main  just as their corresponding environments do  this now means it s easy to track releases to each environment  and the state of each environment  and merges for each are easier  too  the sit branch requires a merge from develop  the uat branch requires a merge from the sit branch  the pre prod branch requires a merge from the uat branch  and finally the main branch  for production  requires a merge from the pre prod branch  each later branch is simply a slower moving version of the previous branch  have i missed something ,adapting the git flow model for pre production environments
33,15365513,72519240,How to get Nokia S30+&#39;s MRE vxp file to run on nokia 225?,"<h1>The setup</h1>
<p>Ok let's me talk a bit about the setup:</p>
<p>I have installed Visual Studio 2008 (the edition that let you try for 90 days), MRE SDK 3.0 from <a href=""https://github.com/UstadMobile/ustadmobile-mre/issues/2"" rel=""nofollow noreferrer"">this Github issue</a>, <a href=""https://download.informer.com/win-1195143593-719db346-6cf10103/arm-2011.09-69-arm-none-eabi.exe"" rel=""nofollow noreferrer"">Sourcery Codebench Lite for ARM EABI</a> and also ARM Realview Development suite 3.1 (but it requires license, and I am too lazy to cr@ck it, also I prefer the open source GCC to that commercial software). I set the compiler to Sourcery Codebench's GCC.</p>
<p>I can compile and run <code>vxp</code> file on Mediatek's emulator without any problem.</p>
<h1>The problem</h1>
<p>After compile for ARM platform, here's the output in <code>[project_dir]\arm</code>:
<a href=""https://i.stack.imgur.com/OtnMw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/OtnMw.png"" alt=""vxp"" /></a></p>
<p>I tried copying the <code>Default.vxp</code> to my Nokia 255's SD card, then open that file on my phone, but the phone said <code>Can't open this app at the moment</code>.</p>
<p>I also try creating an <code>appmanager</code> folder on my SD card, then my phone's internal storage, then copy the <code>vxp</code> file there, but in the app list, there is still no app other than stock apps, and the <code>vxp</code> file still not run.</p>
<h1>Other vxp files</h1>
<p>I downloaded some <code>vxp</code> files from <code>http://shifat100.xtgem.com/</code>, put to my SD card and run from it. Some will work, for example the Asphalt 6 Game, but some won't, for example the Gold rush game, they yelt <code>Can't open this app at the moment</code>.</p>
<p>I checked the format of the Asphalt 6 game 's <code>vxp</code> with the <code>file</code> command, and it said <code>data</code>. But I check my <code>Default.vxp</code>, it was ELF. I think this is the problem, but don't know how to convert/pack ELF to vxp.</p>
<p>Using binwalk with the Asphalt 6 game 's <code>vxp</code>, I get 2 zlib compressed files and 2 GIFs, which are icons of the game. The two compressed files, after unpack, one contain many names, for example</p>
<pre><code>splash_320x240.bsprite
splash_menu_320x240_200k.bsprite
splash_menu_split_320x240_200k.bsprite
splash_title.bsprite
hollywood_320x240_200k.bsprite
new.png
font_small.bsprite
font_large.bsprite
interface_font.bsprite
copter.bsprite
car_tourist.bsprite
cars_fx.bsprite
cars_shadow.bsprite
</code></pre>
<p>so I think this is the resource file. The other might contain code, I found some exception strings in it, for example</p>
<pre><code>Unknown signal
Invalid Operation
Divide By Zero
Overflow
Underflow
Inexact Result
: Heap memory corrupted
Abnormal termination
Arithmetic exception:
Illegal instruction
Interrupt received
Illegal address
Termination request
Stack overflow
Redirect: can't open:
Out of heap memory
User-defined signal 1
User-defined signal 2
Pure virtual fn called
C++ library exception
</code></pre>
<p>and some (maybe) S30+ platform APIs, for example</p>
<pre><code>vm_get_mre_modules
vm_get_mre_total_mem_size
vm_get_mre_version
</code></pre>
<p>So what might be the problem? Screen resolution? I changed it but still not work. SDK version? I also tried all 3 version, but no luck. File format? Compiler difference? (Note that I'm using GCC while most tutorial left on the internet suggest using RVCS) I don't know.</p>
<p>Any ideas? Thanks!</p>
<p>If you need to get any files, tell me and I will put it here.</p>
",376,1,1,2,c++;nokia,2022-06-06 17:33:32,2022-06-06 17:33:32,2022-08-15 16:21:08,ok let s me talk a bit about the setup  i have installed visual studio   the edition that let you try for  days   mre sdk   from    and also arm realview development suite    but it requires license  and i am too lazy to cr ck it  also i prefer the open source gcc to that commercial software   i set the compiler to sourcery codebench s gcc  i can compile and run vxp file on mediatek s emulator without any problem  i tried copying the default vxp to my nokia  s sd card  then open that file on my phone  but the phone said can t open this app at the moment  i also try creating an appmanager folder on my sd card  then my phone s internal storage  then copy the vxp file there  but in the app list  there is still no app other than stock apps  and the vxp file still not run  i downloaded some vxp files from http   shifat xtgem com   put to my sd card and run from it  some will work  for example the asphalt  game  but some won t  for example the gold rush game  they yelt can t open this app at the moment  i checked the format of the asphalt  game  s vxp with the file command  and it said data  but i check my default vxp  it was elf  i think this is the problem  but don t know how to convert pack elf to vxp  using binwalk with the asphalt  game  s vxp  i get  zlib compressed files and  gifs  which are icons of the game  the two compressed files  after unpack  one contain many names  for example so i think this is the resource file  the other might contain code  i found some exception strings in it  for example and some  maybe  s  platform apis  for example so what might be the problem  screen resolution  i changed it but still not work  sdk version  i also tried all  version  but no luck  file format  compiler difference   note that i m using gcc while most tutorial left on the internet suggest using rvcs  i don t know  any ideas  thanks  if you need to get any files  tell me and i will put it here ,how to get nokia s    s mre vxp file to run on nokia  
34,1540505,24569863,Git setup. Cloning repositories from live server to local server,"<p>I am new to Git and have been trying to get it implemented into my workplace environment as we currently have no VC. I have run through the tutorials online and on the website and have an understanding of how it works, the commands, etc.
The only issue I am having is actually getting it implemented onto our every day work cycle and how it would work over our development and live servers.</p>

<p>Our setup is as follows:</p>

<p>We have a local server running in the office where we build and create the projects. At the moment, once these projects are ready, we zip up the project, create a new domain on our live server, then upload the files, extract, change config etc. Git is installed on both the local server and the live server.</p>

<p>Now to implement Git into our workflow, this is how I have imagined the process to be:</p>

<ol>
<li>A new repository is created on the live server for the new project.</li>
<li>The repository is cloned (or branched?) onto our local server from the live server</li>
<li>Each developer can branch and work on their individual branch on the local server. Branches are committed to the local clone.</li>
<li>Once the site is complete, the repository is pushed to the live server.</li>
</ol>

<p>Am I correct in thinking the above process is what I need to be doing?
We could have this completely wrong and I thought posting a question here may help to give clarity as to how I should be using Git. I can see it's an extremely useful bit of software and want to start using it as soon as possible due to the number of developers we have in the office!</p>

<p>Thanks</p>
",668,2,2,4,git;server;clone;git-clone,2014-07-04 11:26:56,2014-07-04 11:26:56,2022-08-15 10:23:57,our setup is as follows  we have a local server running in the office where we build and create the projects  at the moment  once these projects are ready  we zip up the project  create a new domain on our live server  then upload the files  extract  change config etc  git is installed on both the local server and the live server  now to implement git into our workflow  this is how i have imagined the process to be  thanks,git setup  cloning repositories from live server to local server
35,15992156,67719637,How to Map json file in React,"<blockquote>
<p>I map to json file in react js file i get an error:</p>
</blockquote>
<pre><code>const CompanyList = () =&gt; {
    const { REACT_APP_API_ENDPOINT } = process.env;
    const [company, setCompany] = useState([]);
    const getCompanyData= async () =&gt; {
        const response = await fetch(`${REACT_APP_API_ENDPOINT}/getCompanyList`, {
            headers: { 'Content-Type': 'application/json' }
        })
        const content = await response.json();
        console.log(content);
        setCompany(content);
    };
    useEffect(() =&gt; {
        getCompanyData();
    },[]);

    return (
        &lt;div&gt;
            &lt;h1&gt;List of Companies&lt;/h1&gt;
            {company.map((user) =&gt; (
        &lt;div className=&quot;user&quot;&gt;{user.companyId}&lt;/div&gt;
      ))}
        &lt;/div&gt;
    );
};
export default CompanyList;
</code></pre>
<blockquote>
<p>I get error this line {user.companyId}
Property 'companyId' does not exist on type 'never'.ts(2339)</p>
</blockquote>
<p>This is my json data
(11) [{…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}]
0: {companyId: 1, companyName: &quot;COS Software Solutions PVT LTD&quot;, companyDescription: &quot;Agile Development Company&quot;}
1: {companyId: 2, companyName: &quot;CTS&quot;, companyDescription: &quot;Software Development Company&quot;}
2: {companyId: 4, companyName: &quot;TCS&quot;, companyDescription: &quot;Consultancy Services&quot;}
3: {companyId: 5, companyName: &quot;HP&quot;, companyDescription: &quot;Manufacturing Company&quot;}
4: {companyId: 6, companyName: &quot;Cogito&quot;, companyDescription: &quot;Software&quot;}
5: {companyId: 7, companyName: &quot;Google&quot;, companyDescription: &quot;Software Development Company&quot;}
6: {companyId: 8, companyName: &quot;AxisBank&quot;, companyDescription: &quot;Financial based company&quot;}
7: {companyId: 9, companyName: &quot;makessoft&quot;, companyDescription: &quot;softwaredevelopment company&quot;}
8: {companyId: 10, companyName: &quot;LG&quot;, companyDescription: &quot;manufacturing company&quot;}
9: {companyId: 11, companyName: &quot;SoftMake&quot;, companyDescription: &quot;IT Company&quot;}</p>
<p>How to I bind user.CompanyId, user.CompanyName and user.CompanyDescription in any html element.</p>
",479,2,0,1,reactjs,2021-05-27 12:44:19,2021-05-27 12:44:19,2022-08-14 14:18:43,i map to json file in react js file i get an error  how to i bind user companyid  user companyname and user companydescription in any html element ,how to map json file in react
36,17626780,72253461,Rails 7 I can&#39;t get the confirmation message to show before record is successfully deleted,"<p>In my Rails 7 application, I'm trying to show a confirmation message when the user presses a &quot;Delete&quot; button. However, when the button is pressed, it's deleting the record straight away without showing the confirmation prompt. I'm using devise to create the routes - I've been trying to look into this and it seems like there was some kind of broken functionality with devise and/or Turbo that is breaking the confirmation dialog box?</p>
<p>Here is what I started with:</p>
<pre><code>&lt;%= button_to 'Delete', @friend, method: :delete, data: { confirm: 'Are you sure?' }, class: &quot;btn btn-danger mx-1&quot; %&gt;
</code></pre>
<p>This is deleting the record just fine, it's just not showing the confirmation. Here are some other lines I've tried that I believe was supposed to just work since Turbo is supposed to come installed with Rails 7 if I understand correctly:</p>
<pre><code>&lt;%= button_to 'Delete', @friend, method: :delete, data: {turbo_method: :delete, turbo_confirm: 'Are you sure?'}, class: &quot;btn btn-danger mx-1&quot; %&gt;
</code></pre>
<pre><code>&lt;%= button_to 'Delete', @friend, method: :delete, data: { turbo_confirm: 'Are you sure?' }, class: &quot;btn btn-danger mx-1&quot; %&gt;
</code></pre>
<p>I then tried to create a Stimulus class named friend_controller.js and put it in the friends/app/controllers folder:</p>
<pre><code>import { Controller } from &quot;@hotwired/stimulus&quot;

export default class extends Controller {
  delete(event) {
    let confirmed = confirm(&quot;Are you sure?&quot;)

    if (!confirmed) {
      event.preventDefault()
    }
  }
}
</code></pre>
<p>And updated my button accordingly:</p>
<pre><code>&lt;div class=&quot;d-flex&quot; data-controller=&quot;friends&quot;&gt;
    &lt;%= button_to &quot;Delete&quot;, @friend, method: :delete, data: { action: &quot;click-&gt;friend#delete&quot; } %&gt;
&lt;/div&gt;
</code></pre>
<p>Every option is deleting the record perfectly, just not showing the confirmation message.</p>
<p>I'm trying to follow a YouTube tutorial to build this as my first Ruby app, but that video is from 2020 and so was using Rails 6. I'm in a college program to learn software development, so I thought I'd challenge myself to also update it to the current version and, well, I'm challenged. This is the last thing I need to figure out before I'm done with this tutorial.</p>
<p>In the other questions I've seen they haven't needed to post the Gemfile or the generated devise friends_controller.rb, but if I need to post them here I will, just let me know.</p>
<p>Thank you very much for any help you can provide!</p>
<p>Edit: -----</p>
<p>Here is what I think was asked for (the generated HTML). I got this by opening up my page, right-clicking, choosing &quot;Inspect&quot; and finding the HTML section for the button in question:</p>
<pre class=""lang-rb prettyprint-override""><code>&lt;form class=&quot;button_to&quot; method=&quot;post&quot; action=&quot;/friends/1&quot;&gt;
  &lt;input type=&quot;hidden&quot; name=&quot;_method&quot; value=&quot;delete&quot; autocomplete=&quot;off&quot;&gt;
  &lt;button data-action=&quot;click-&gt;friend#delete&quot; class=&quot;btn btn-danger mx-1&quot; type=&quot;submit&quot;&gt;Delete&lt;/button&gt;
  &lt;input type=&quot;hidden&quot; name=&quot;authenticity_token&quot; value=&quot;(long line of random letters)&quot; autocomplete=&quot;off&quot;&gt;
&lt;/form&gt;

</code></pre>
<p>I removed the actual authenticity token because I think those are supposed to be kept secret. I know it's just a sample project but I'm not sure if that is something unique to my computer. Thank you for being patient with me while I'm learning!</p>
",363,2,2,2,devise;ruby-on-rails-7,2022-05-16 04:48:01,2022-05-16 04:48:01,2022-08-14 08:40:00,in my rails  application  i m trying to show a confirmation message when the user presses a  delete  button  however  when the button is pressed  it s deleting the record straight away without showing the confirmation prompt  i m using devise to create the routes   i ve been trying to look into this and it seems like there was some kind of broken functionality with devise and or turbo that is breaking the confirmation dialog box  here is what i started with  this is deleting the record just fine  it s just not showing the confirmation  here are some other lines i ve tried that i believe was supposed to just work since turbo is supposed to come installed with rails  if i understand correctly  i then tried to create a stimulus class named friend_controller js and put it in the friends app controllers folder  and updated my button accordingly  every option is deleting the record perfectly  just not showing the confirmation message  i m trying to follow a youtube tutorial to build this as my first ruby app  but that video is from  and so was using rails   i m in a college program to learn software development  so i thought i d challenge myself to also update it to the current version and  well  i m challenged  this is the last thing i need to figure out before i m done with this tutorial  in the other questions i ve seen they haven t needed to post the gemfile or the generated devise friends_controller rb  but if i need to post them here i will  just let me know  thank you very much for any help you can provide  edit        here is what i think was asked for  the generated html   i got this by opening up my page  right clicking  choosing  inspect  and finding the html section for the button in question  i removed the actual authenticity token because i think those are supposed to be kept secret  i know it s just a sample project but i m not sure if that is something unique to my computer  thank you for being patient with me while i m learning ,rails  i can   t get the confirmation message to show before record is successfully deleted
37,19739692,73314645,Classes in Java - main function,"<p>I'm a new student of software development and my first homework is to find what was missing in some code. Searching, I found that the main function, <em>public static void main(String[] args) {</em>. It's mandatory when classes are what we're talking about.</p>
<p>But I'm getting errors and I don't know why. I could use some help right now.</p>
<p>Also, where can I find a course or web page where I can learn about Java? I want to learn, but I don't know where to start, because the professor drop us classes without even knowing what's the difference between public and private.</p>
<p>I'm letting the code and the errors I got down here.</p>
<pre><code>class Operaciones {

    private int num1;
    private int num2;

    public static void main(String[] args) {

        public int getNum1() {
            return num1;
        }

        public void setNum1(int num1) {
            this.num1 = num1;
        }

        public int getNum2() {
            return num2;
        }

        public void setNum2(int num2) {
            this.num2 = num2;
        }

        public int sumar() {
            return num1 + num2;
        }

        public int restar() {
            return num1 - num2;
        }

        public int multiplicar() {
            return num1 * num2;
        }

    }
}
</code></pre>
<p><a href=""https://i.stack.imgur.com/34v3R.png"" rel=""nofollow noreferrer"">Errors</a></p>
",74,1,0,2,java;class,2022-08-11 05:30:52,2022-08-11 05:30:52,2022-08-13 13:07:44,i m a new student of software development and my first homework is to find what was missing in some code  searching  i found that the main function  public static void main string   args     it s mandatory when classes are what we re talking about  but i m getting errors and i don t know why  i could use some help right now  also  where can i find a course or web page where i can learn about java  i want to learn  but i don t know where to start  because the professor drop us classes without even knowing what s the difference between public and private  i m letting the code and the errors i got down here  ,classes in java   main function
38,15396020,70422784,How can I fix the issue &quot;rc.exe not found&quot; in Visual Studio 2022? &quot;,"<p>Premise: I'm completely new to Fortran programming and to the Visual Studio environment.</p>
<p>I've created a very simple Fortran project in Microsoft Visual Studio Community 2022 (the source file is a .f90 file).
The code is the following one:</p>
<pre><code>program Sum_Main
    
    double precision :: a,b,c
    
    a = 100.d0
    b = 60.0d0
    c = a+b
    
    write(6,'(f8.2)') c
    
end program Sum_Main

</code></pre>
<p>I'm in debug mode and when I compile the project everything is ok. But when I press &quot;Build solution&quot;, I get the error: &quot;rc.exe not found&quot;.</p>
<p><a href=""https://i.stack.imgur.com/0Rhsu.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0Rhsu.png"" alt=""enter image description here"" /></a></p>
<p>How can I solve?</p>
<p>Here the Intel software development kits I've installed:
<a href=""https://i.stack.imgur.com/UWydK.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/UWydK.png"" alt=""enter image description here"" /></a></p>
",445,1,1,5,visual-studio;fortran;intel-fortran;visual-studio-2022;intel-oneapi,2021-12-20 15:46:24,2021-12-20 15:46:24,2022-08-13 01:53:58,premise  i m completely new to fortran programming and to the visual studio environment  i m in debug mode and when i compile the project everything is ok  but when i press  build solution   i get the error   rc exe not found    how can i solve ,how can i fix the issue  rc exe not found  in visual studio    
39,4507231,73336524,"How to manage Conda, Python, and dependencies within GitHub?","<p>I am seeking some assistance in software project management. I want to take my project and store it remotely in GitHub, so I can clone the environment and work on it across multiple offices, each with a desktop PC, without moving a laptop back and forth. My knowledge and experience in software project management are a bit old, so as much detail as possible is always welcomed.</p>
<p>I have python code (several classes in corresponding class files), with the main python file executed from a Linux terminal, and the code calls a number of external programs:</p>
<ul>
<li>Gromacs</li>
<li>Modeller</li>
<li>Several Python packages (new or with specific versions)</li>
</ul>
<p>I've installed all the external programs/dependencies within a Conda environment.</p>
<p>I am the only person working on the project, but as mentioned above, I will need access to the working and development environment across several machines (not all at once). Is there any way I can &quot;wrap&quot; everything up, conda environment, code, etc., add it to a GitHub repository and clone as and when to each machine?</p>
<p>I would appreciate people's thoughts on how to manage this software project.</p>
",23,0,0,5,python;github;version-control;conda;software-design,2022-08-12 18:31:22,2022-08-12 18:31:22,2022-08-12 18:31:22,i am seeking some assistance in software project management  i want to take my project and store it remotely in github  so i can clone the environment and work on it across multiple offices  each with a desktop pc  without moving a laptop back and forth  my knowledge and experience in software project management are a bit old  so as much detail as possible is always welcomed  i have python code  several classes in corresponding class files   with the main python file executed from a linux terminal  and the code calls a number of external programs  i ve installed all the external programs dependencies within a conda environment  i am the only person working on the project  but as mentioned above  i will need access to the working and development environment across several machines  not all at once   is there any way i can  wrap  everything up  conda environment  code  etc   add it to a github repository and clone as and when to each machine  i would appreciate people s thoughts on how to manage this software project ,how to manage conda  python  and dependencies within github 
40,14632909,72046624,Firebase Tools and Java 11,"<p>This question falls somewhere between Firebase Tools, MacOS and Java. Probably 75% Java, 20% Firebase Tools and 5% MacOS.</p>
<p>Starting with v10.5, firebase-tools started stating that 'Support for Java version &lt;= 10 will be dropped soon in firebase-tools@11. Please upgrade to Java version 11 or above to continue using the emulators.'</p>
<p>I run macOS v11.6.5 on a Macbook Pro from mid-2014. When I go to <a href=""https://www.java.com/en/download/"" rel=""noreferrer"">Java's Downloads page</a>, it recommends Java 'Version 8 Update 331'. Not Java 11.</p>
<p>Information on downloading Java 11 seems to be scarce. Oracle's <a href=""https://www.oracle.com/java/technologies/javase/products-doc-jdk11certconfig.html"" rel=""noreferrer"">page of certified configurations</a> includes MacOS 11, but I can't find anywhere obvious where Java 11 can be readily downloaded.</p>
<p>A big part of the problem seems to be the terminology used. If I run <code>java -version</code>, I get:</p>
<pre><code>java version &quot;1.8.0_331&quot;
Java(TM) SE Runtime Environment (build 1.8.0_331-b09)
Java HotSpot(TM) 64-Bit Server VM (build 25.331-b09, mixed mode)
</code></pre>
<p>Okay, I have build 1.8 of the Java Runtime Environment, aka the JRE if you are a Java enthusiast. <a href=""https://github.com/firebase/firebase-tools/pull/4347/commits/9c2029cd0ed650a0403fb73ffe5bb1a8b989597f#diff-a1ad4cf0c9fac1cb8905b5f41ced4ca7dab42af061d383305738cc514a7923f3R442"" rel=""noreferrer"">That</a> is apparently what is triggering the warning in Firebase Tools.</p>
<p>There is also a Java product out there called 'Java SE 11'. The product itself is ambiguous, but the <a href=""https://www.oracle.com/a/tech/docs/11-0-15-1-checksum.html"" rel=""noreferrer"">checksums</a> all say 'SDK'. (A Software Development Kit: a thing that enables developers to develop Java programs. The name doesn't imply a Runtime Environment: a thing that enables Java to run on an operating system.) There is <a href=""https://java.tutorials24x7.com/blog/how-to-install-java-11-on-mac"" rel=""noreferrer"">an article</a> out there which claims that, if you <a href=""https://www.oracle.com/java/technologies/downloads/#java11"" rel=""noreferrer"">install Java SE 11</a> and run <code>java -version</code>, it will spit out <code>java version &quot;11.0.7&quot;</code>. That will probably satisfy Firebase Tools.</p>
<p>But <a href=""https://www.oracle.com/java/technologies/javase/11-relnote-issues.html"" rel=""noreferrer"">Oracle's release notes</a> say: 'In Windows and macOS, installing the JDK in previous releases optionally installed a JRE. In JDK 11, this is no longer an option.' No longer an option... as in now you implicitly get JRE 11 with SDK 11? Or as in the SDK and JRE are now fully divorced, and the JRE must be ferreted out of its hiding like a wild beast?</p>
<p>UPDATE 6/5/22: Java's checksums page now says 'JDK', and I guess that is better than 'SDK' because it implies 'Java Development Kit', which <a href=""https://en.wikipedia.org/wiki/Java_Development_Kit"" rel=""noreferrer"">this Wikipedia article</a> claims to include both a JRE ('java') and SDK (most of the other files).</p>
",2981,4,13,3,java;macos;firebase-tools,2022-04-28 18:41:25,2022-04-28 18:41:25,2022-08-12 17:53:35,this question falls somewhere between firebase tools  macos and java  probably   java    firebase tools and   macos  starting with v   firebase tools started stating that  support for java version  lt    will be dropped soon in firebase tools   please upgrade to java version  or above to continue using the emulators   i run macos v   on a macbook pro from mid   when i go to   it recommends java  version  update    not java   information on downloading java  seems to be scarce  oracle s  includes macos   but i can t find anywhere obvious where java  can be readily downloaded  a big part of the problem seems to be the terminology used  if i run java  version  i get  okay  i have build   of the java runtime environment  aka the jre if you are a java enthusiast   is apparently what is triggering the warning in firebase tools  there is also a java product out there called  java se    the product itself is ambiguous  but the  all say  sdk    a software development kit  a thing that enables developers to develop java programs  the name doesn t imply a runtime environment  a thing that enables java to run on an operating system   there is  out there which claims that  if you  and run java  version  it will spit out java version       that will probably satisfy firebase tools  but  say   in windows and macos  installing the jdk in previous releases optionally installed a jre  in jdk   this is no longer an option   no longer an option    as in now you implicitly get jre  with sdk   or as in the sdk and jre are now fully divorced  and the jre must be ferreted out of its hiding like a wild beast  update     java s checksums page now says  jdk   and i guess that is better than  sdk  because it implies  java development kit   which  claims to include both a jre   java   and sdk  most of the other files  ,firebase tools and java 
41,8401294,73333104,What does a software architect do that an engineer doesn&#39;t?,"<p>I see a bunch of people mentioning the term &quot;SOFTWARE ARCHITECT, SOLUTION ARCHITECT&quot; when assigning their role in a particular company. And, usually, this position always appears at the top in profiles that apparently the person in question has a very interesting background in the development world.</p>
<p>A day ago, I had seen a very rich thread about the difference in the practice of a SOFTWARE ENGINEER and an ARCHITECT.</p>
<p>Without taking into account seniority: (junior, full, senior, staff) etc...
What are the main differences in the performances of these two professionals in your experiences?</p>
<p>Do you know any software architects and, if so, what do they do differently or that an engineer doesn't?</p>
",27,0,-2,2,architecture;software-design,2022-08-12 13:59:32,2022-08-12 13:59:32,2022-08-12 13:59:32,i see a bunch of people mentioning the term  software architect  solution architect  when assigning their role in a particular company  and  usually  this position always appears at the top in profiles that apparently the person in question has a very interesting background in the development world  a day ago  i had seen a very rich thread about the difference in the practice of a software engineer and an architect  do you know any software architects and  if so  what do they do differently or that an engineer doesn t ,what does a software architect do that an engineer doesn   t 
42,15198995,73326798,Can i use two networks at the same time?,"<p>I am developing a program that makes a request to a private IP address, to fetch data, which I can access only by being connected to that network.</p>
<p>And I have a database that is behind a vpn (other private IP), and I need to send that previous data to that database.</p>
<p>My computer is windows 10 and has two network cards, I can successfully connect to each network independently.</p>
<p>But the question is how can I make my computer stay connected to both networks at the same time and the described process works.</p>
<p>I appreciate if anyone can provide me with information on whether this is possible at the operating system configuration level. Or should it be something software development as such?</p>
",15,0,0,2,windows;network-interface,2022-08-11 23:56:13,2022-08-11 23:56:13,2022-08-11 23:56:13,i am developing a program that makes a request to a private ip address  to fetch data  which i can access only by being connected to that network  and i have a database that is behind a vpn  other private ip   and i need to send that previous data to that database  my computer is windows  and has two network cards  i can successfully connect to each network independently  but the question is how can i make my computer stay connected to both networks at the same time and the described process works  i appreciate if anyone can provide me with information on whether this is possible at the operating system configuration level  or should it be something software development as such ,can i use two networks at the same time 
43,19743260,73321051,How do I get a response from Git into my make?,"<p>I'm trying to get Git's hash for my code into make.  I'm using the following command to run Git from the shell command:</p>
<pre><code>MODULE_HASH:=$(shell git describe --long --dirty --always)
</code></pre>
<p>The variable MODULE_HASH is blank after the line runs.  To find the problem, I added some debug lines to the make file:</p>
<pre><code>$(info SHELL = $(SHELL))
$(info PATH = $(shell cd))
$(info version = $(shell git --version))
MODULE_HASH:=$(shell git describe --long --dirty --always)
$(info MODULE_HASH = $(MODULE_HASH))
</code></pre>
<p>The output for these lines are:</p>
<pre><code>SHELL = cmd.exe
PATH = C:\Projects\WIFi_Module\wifi_module_wiced_sdk
version = 
MODULE_HASH = 
</code></pre>
<p>This shows that the shell is executing cmd but git is either not executing or make is not getting the response from git.  If I open cmd and run the git command from the path, it works. I copied the shell line from another make file where it works. What am I doing wrong?</p>
<p>I checked the version of the make executable.  The output doesn't list a version so I copied the output below:</p>
<pre><code>C:\Projects\WIFi_Module\wifi_module_wiced_sdk&gt;make --version
GNU Make Development-Git-29cd1e9699d1101444920827b412191e0f92e1e1
Built for Windows32
Copyright (C) 1988-2012 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
</code></pre>
",31,0,1,3,windows;git;shell,2022-08-11 15:57:51,2022-08-11 15:57:51,2022-08-11 16:05:58,i m trying to get git s hash for my code into make   i m using the following command to run git from the shell command  the variable module_hash is blank after the line runs   to find the problem  i added some debug lines to the make file  the output for these lines are  this shows that the shell is executing cmd but git is either not executing or make is not getting the response from git   if i open cmd and run the git command from the path  it works  i copied the shell line from another make file where it works  what am i doing wrong  i checked the version of the make executable   the output doesn t list a version so i copied the output below ,how do i get a response from git into my make 
44,8124514,72101043,Exposing Prometheus metrics in Laravel 9,"<p>It looks like there's loads of composer plugins to do this but nothing in active development with commits since the release of Laravel 9. Is there a popular go-to option for this?</p>
<p>(Almost posted this in software recommendations - let me know if that's a more appropriate place for it.)</p>
",255,1,1,4,laravel;prometheus;monitoring;metrics,2022-05-03 17:34:13,2022-05-03 17:34:13,2022-08-11 15:10:02,it looks like there s loads of composer plugins to do this but nothing in active development with commits since the release of laravel   is there a popular go to option for this   almost posted this in software recommendations   let me know if that s a more appropriate place for it  ,exposing prometheus metrics in laravel 
45,13070350,73319222,Convert Expo App to a Software Development Kit,"<p>Can I turn my Expo React Native App to an SDK that can be integrated on other social media apps? If yes, can you please lead me into how to do that?</p>
",10,0,-1,5,javascript;node.js;react-native;sdk;expo,2022-08-11 13:34:22,2022-08-11 13:34:22,2022-08-11 13:34:22,can i turn my expo react native app to an sdk that can be integrated on other social media apps  if yes  can you please lead me into how to do that ,convert expo app to a software development kit
46,4706711,73303507,What values are returned for callerID once I issue AT+VCID=2 AT command?,"<p>Many modems such as <a href=""https://support.usr.com/support/5631/5631-ug/generic.htm"" rel=""nofollow noreferrer"">USRobotics</a> or <a href=""https://www.thinkpenguin.com/files/CX930xx-manual.pdf"" rel=""nofollow noreferrer"">Conexant CX930xx</a> need to issue the following command so I can retrieve the incomming call phone number (caller Id):</p>
<pre><code>AT+VCID=1
</code></pre>
<p>But according to the manuals above will recieve the callerId in formatted form. But I can also issue:</p>
<pre><code>AT+VCID=2
</code></pre>
<p>For unformatted form. But in the latter case what output should I expect compared to the formatted form. As far as I know formatted form will return:</p>
<pre><code>RING\r\n
DATE=XXX\r\n
TIME=XXX\r\n
NMBR=XXX\r\n
NAME=XXXX\r\n
\r\n
</code></pre>
<p>(Above ANY Newline is represented with \r\n and not with the text's newline)</p>
<p>But what output should I expect at unformatted form (via issuing <code>AT+VCID=2</code>)?</p>
<p>I want to emulate incomming calls from a modem using an arduino or a programm that uses a virtual serial port so I can have a development tool for software that Uses modem for callerId applications.</p>
<p>What I want to emulate is a Conexant CX930xx series modem using an arduino cause I have no actual modem in my hands right now.</p>
",31,0,1,3,at-command;modem;caller-id,2022-08-10 12:03:33,2022-08-10 12:03:33,2022-08-11 10:06:46,many modems such as  or  need to issue the following command so i can retrieve the incomming call phone number  caller id   but according to the manuals above will recieve the callerid in formatted form  but i can also issue  for unformatted form  but in the latter case what output should i expect compared to the formatted form  as far as i know formatted form will return   above any newline is represented with  r n and not with the text s newline  but what output should i expect at unformatted form  via issuing at vcid    i want to emulate incomming calls from a modem using an arduino or a programm that uses a virtual serial port so i can have a development tool for software that uses modem for callerid applications  what i want to emulate is a conexant cxxx series modem using an arduino cause i have no actual modem in my hands right now ,what values are returned for callerid once i issue at vcid  at command 
47,11295630,66946774,Call to CreateProcess failed. Error code: 2 (TensorFlow),"<p>When trying to use the GPU enabled tensorflow, I run into some error messages that seem to limit my ability to run my GPU despite many success messages in the log (see below). In terms of software, I am using an Anaconda Lite environment. In terms of hardware, I have an RTX 2080 gpu. Below are the packages installed on my environment.</p>
<p>I am using this tensorflow approved dependency combination:
<a href=""https://i.stack.imgur.com/N0g9j.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/N0g9j.png"" alt=""enter image description here"" /></a></p>
<p>Here is the important installs, but I attached the entire conda list below.</p>
<ul>
<li>TensorFlow-GPU 2.4.0</li>
<li>Cudnn 8.0.5</li>
<li>Cudatoolkit 11.0.3</li>
</ul>
<pre><code>absl-py                   0.12.0                   pypi_0    pypi
astunparse                1.6.3                    pypi_0    pypi
ca-certificates           2020.12.5            h5b45459_0    conda-forge
cachetools                4.2.1                    pypi_0    pypi
certifi                   2020.12.5        py37h03978a9_1    conda-forge
chardet                   4.0.0                    pypi_0    pypi
cudatoolkit               11.0.3               h3f58a73_8    conda-forge
cudnn                     8.0.5.39             hfe7f257_1    conda-forge
cycler                    0.10.0                   pypi_0    pypi
filetype                  1.0.7                    pypi_0    pypi
flatbuffers               1.12                     pypi_0    pypi
gast                      0.3.3                    pypi_0    pypi
google-auth               1.28.0                   pypi_0    pypi
google-auth-oauthlib      0.4.4                    pypi_0    pypi
google-pasta              0.2.0                    pypi_0    pypi
grpcio                    1.32.0                   pypi_0    pypi
h5py                      2.10.0                   pypi_0    pypi
idna                      2.10                     pypi_0    pypi
imageai                   2.1.6                    pypi_0    pypi
importlib-metadata        3.10.0                   pypi_0    pypi
keras                     2.4.3                    pypi_0    pypi
keras-preprocessing       1.1.2                    pypi_0    pypi
keras-resnet              0.2.0                    pypi_0    pypi
kiwisolver                1.3.1                    pypi_0    pypi
markdown                  3.3.4                    pypi_0    pypi
matplotlib                3.3.2                    pypi_0    pypi
numpy                     1.19.3                   pypi_0    pypi
oauthlib                  3.1.0                    pypi_0    pypi
opencv-python             4.5.1.48                 pypi_0    pypi
openssl                   1.1.1k               h8ffe710_0    conda-forge
opt-einsum                3.3.0                    pypi_0    pypi
pillow                    7.0.0                    pypi_0    pypi
pip                       21.0.1           py37haa95532_0
protobuf                  3.15.7                   pypi_0    pypi
pyasn1                    0.4.8                    pypi_0    pypi
pyasn1-modules            0.2.8                    pypi_0    pypi
pyparsing                 2.4.7                    pypi_0    pypi
python                    3.7.6                h60c2a47_2
python-dateutil           2.8.1                    pypi_0    pypi
python_abi                3.7                     1_cp37m    conda-forge
pyyaml                    5.4.1                    pypi_0    pypi
requests                  2.25.1                   pypi_0    pypi
requests-oauthlib         1.3.0                    pypi_0    pypi
rsa                       4.7.2                    pypi_0    pypi
scipy                     1.4.1                    pypi_0    pypi
setuptools                52.0.0           py37haa95532_0
six                       1.15.0                   pypi_0    pypi
sqlite                    3.35.3               h2bbff1b_0
tensorboard               2.4.1                    pypi_0    pypi
tensorboard-plugin-wit    1.8.0                    pypi_0    pypi
tensorflow                2.4.0                    pypi_0    pypi
tensorflow-estimator      2.4.0                    pypi_0    pypi
tensorflow-gpu            2.4.0                    pypi_0    pypi
termcolor                 1.1.0                    pypi_0    pypi
typing-extensions         3.7.4.3                  pypi_0    pypi
urllib3                   1.26.4                   pypi_0    pypi
vc                        14.2                 h21ff451_1
vs2015_runtime            14.27.29016          h5e58377_2
werkzeug                  1.0.1                    pypi_0    pypi
wheel                     0.36.2             pyhd3eb1b0_0
wincertstore              0.2                      py37_0
wrapt                     1.12.1                   pypi_0    pypi
zipp                      3.4.1                    pypi_0    pypi
</code></pre>
<p>When executing code related to the ImageAI python package, I run into the following print outs. Note: there are alot of successful DLL loads, however, there are three important points of failure to note.</p>
<ul>
<li>Couldn't invoke ptxas.exe --version</li>
<li>Call to CreateProcess failed. Error code: 2</li>
<li>Not creating XLA devices, tf_xla_enable_xla_devices not set</li>
</ul>
<p>Ptas:
Tried to follow some other threads and came to the conclusion that this feature appears to be in development. <a href=""https://stackoverflow.com/questions/66623541/tensorflow-2-4-1-couldnt-invoke-ptxas-exe"">Tensorflow 2.4.1 - Couldn&#39;t invoke ptxas.exe</a></p>
<p>CreateProcess:
I have found threads with this error, but none in relation to tensorflow.</p>
<p>tf_xla_enable_xla_devices:
This is a error that is OK to ignore, per this thread: <a href=""https://github.com/tensorflow/tensorflow/issues/44683"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/issues/44683</a></p>
<p>Attached is the entire logging when a tensorflow script is called.</p>
<pre><code>error:2021-04-04 19:16:49.100399: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll

error:2021-04-04 19:16:50.654630: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set

error:2021-04-04 19:16:50.655534: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll

error:2021-04-04 19:16:50.685778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.23GiB/s
2021-04-04 19:16:50.685800: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll

error:2021-04-04 19:16:50.696485: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-04-04 19:16:50.696504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll

error:2021-04-04 19:16:50.700890: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll

error:2021-04-04 19:16:50.702964: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll

error:2021-04-04 19:16:50.711373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll

error:2021-04-04 19:16:50.714875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll

error:2021-04-04 19:16:50.716294: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll

error:2021-04-04 19:16:50.716353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0

error:2021-04-04 19:16:50.716572: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-04-04 19:16:50.716942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 computeCapability: 7.5
coreClock: 1.71GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.23GiB/s
2021-04-04 19:16:50.716955: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll

error:2021-04-04 19:16:50.716962: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-04-04 19:16:50.716968: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2021-04-04 19:16:50.716975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2021-04-04 19:16:50.716979: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2021-04-04 19:16:50.716983: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2021-04-04 19:16:50.716988: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2021-04-04 19:16:50.716992: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2021-04-04 19:16:50.717021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0

error:2021-04-04 19:16:51.182297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-04-04 19:16:51.182316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0
2021-04-04 19:16:51.182320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N

error:2021-04-04 19:16:51.182515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6599 MB memory) -&gt; physical GPU (device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:01:00.0, compute capability: 7.5)

error:2021-04-04 19:16:51.184721: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set

error:2021-04-04 19:16:52.512582: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)

error:2021-04-04 19:16:52.527832: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll

error:2021-04-04 19:16:53.360829: E tensorflow/core/platform/windows/subprocess.cc:283] Call to CreateProcess failed. Error code: 2
2021-04-04 19:16:53.360847: W tensorflow/stream_executor/gpu/asm_compiler.cc:55] Couldn't invoke ptxas.exe --version

error:2021-04-04 19:16:53.369627: E tensorflow/core/platform/windows/subprocess.cc:283] Call to CreateProcess failed. Error code: 2

error:2021-04-04 19:16:53.369929: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.

error:2021-04-04 19:16:53.375630: E tensorflow/core/platform/windows/subprocess.cc:283] Call to CreateProcess failed. Error code: 2

error:2021-04-04 19:16:53.381209: E tensorflow/core/platform/windows/subprocess.cc:283] Call to CreateProcess failed. Error code: 2

error:2021-04-04 19:16:53.386810: E tensorflow/core/platform/windows/subprocess.cc:283] Call to CreateProcess failed. Error code: 2

error:2021-04-04 19:16:53.391792: E tensorflow/core/platform/windows/subprocess.cc:283] Call to CreateProcess failed. Error code: 2

error:2021-04-04 19:16:53.396262: E tensorflow/core/platform/windows/subprocess.cc:283] Call to CreateProcess failed. Error code: 2

error:2021-04-04 19:16:53.401723: E tensorflow/core/platform/windows/subprocess.cc:283] Call to CreateProcess failed. Error code: 2

There is a whole bunch more of the same print out that I have omitted.
</code></pre>
",3088,2,2,2,python;tensorflow,2021-04-05 02:37:32,2021-04-05 02:37:32,2022-08-11 02:40:38,when trying to use the gpu enabled tensorflow  i run into some error messages that seem to limit my ability to run my gpu despite many success messages in the log  see below   in terms of software  i am using an anaconda lite environment  in terms of hardware  i have an rtx  gpu  below are the packages installed on my environment  here is the important installs  but i attached the entire conda list below  when executing code related to the imageai python package  i run into the following print outs  note  there are alot of successful dll loads  however  there are three important points of failure to note  attached is the entire logging when a tensorflow script is called ,call to createprocess failed  error code    tensorflow 
48,12477062,73296262,Have to restart the Next.js dev server to view any changes,"<p>First off, another question, <a href=""https://stackoverflow.com/questions/71649994/why-do-i-have-to-restart-the-next-js-dev-server-to-see-changes"">#71649994</a>, pretty much asks the same question, except that while they only say it happens for one of their projects, in my case it happens for every project that I've ever created, and in that question's case, there was no solution, so I thought I'd ask again and add additional details.</p>
<p>In my case, fast reloading, or even just hot-reloading/rebuilding the page and refreshing when I update my code, just does not work at all. Nothing happens when I change my code. When I create a basic next app using <code>npx create-next-app@latest</code>, and then run the dev server using <code>npm run dev</code>, updating files like <code>pages/index.js</code> does not do anything, including basic changes like changing the page title tag. There is no output in the terminal from the server in response to me saving the file.</p>
<p>I've experienced this on two separate computers, both with TypeScript and with normal JavaScript. One computer runs Windows 10, the other Windows 11, but for both my development environment is WSL2 Ubuntu, and I am using VScode.</p>
<p>There is a slight difference between my experience on some projects. On the typescript project, modifying CSS files (not CSS modules) that I've imported globally did actually seem to work with fast refresh, including terminal output as well as a loading icon on the page indicating the fast refresh took place. However, when following the process above to create the default JS project, no aspect of fast refresh seems to work. No change seems to trigger a refresh or response, and refreshing the page does not do anything.</p>
<p>To clarify, when I run <code>npm run dev</code>, <code>npx next dev</code> or <code>yarn dev</code>, the initial build runs just fine. I also have no issues with the typescript compiler or sass compilers, meaning that when I run <code>tsc *.ts --watch</code> in a directory, it always compiles TypeScript code into JS without a hitch when I modify those files, and the case is the same when I am working with <code>.scss</code> files.</p>
<p>I can also start a production server with <code>npm run start</code>, again without a hitch.</p>
<p>Versions of some of the software I'm running:</p>
<ul>
<li>next 12.2.4</li>
<li>vscode 1.70.0</li>
<li>Ubuntu 20.04.3 LTS</li>
</ul>
<p><strong>package.json</strong></p>
<pre><code>{
  &quot;name&quot;: &quot;js_web&quot;,
  &quot;version&quot;: &quot;0.1.0&quot;,
  &quot;private&quot;: true,
  &quot;scripts&quot;: {
    &quot;dev&quot;: &quot;next dev&quot;,
    &quot;build&quot;: &quot;next build&quot;,
    &quot;start&quot;: &quot;next start&quot;,
    &quot;lint&quot;: &quot;next lint&quot;
  },
  &quot;dependencies&quot;: {
    &quot;next&quot;: &quot;12.2.4&quot;,
    &quot;npm&quot;: &quot;^8.16.0&quot;,
    &quot;react&quot;: &quot;18.2.0&quot;,
    &quot;react-dom&quot;: &quot;18.2.0&quot;
  },
  &quot;devDependencies&quot;: {
    &quot;eslint&quot;: &quot;8.21.0&quot;,
    &quot;eslint-config-next&quot;: &quot;12.2.4&quot;
  }
}
</code></pre>
<p><strong>next.config.js</strong></p>
<pre><code>/** @type {import('next').NextConfig} */
const nextConfig = {
  reactStrictMode: true,
  swcMinify: true,
}

module.exports = nextConfig
</code></pre>
<hr />
<p>It's hard to say whether it could be related or not, but I've also had issues with getting EACCESS/permissions errors when trying to install npm packages globally, which has required me to use <code>sudo</code> to get them to actually install. Since I've experienced this issue and the NextJS issue on both computers, could this point to an issue with the way I've configured things on both machines, leading to the NextJS issue?</p>
<p>Does anyone with a similar setup not experience this issue? Are there any additional details that I could investigate to try and identify the issue?</p>
<p>Finally, is it possible to enable additional debug output, if it could be helpful?</p>
",79,1,2,5,javascript;node.js;npm;next.js;wsl-2,2022-08-09 21:00:30,2022-08-09 21:00:30,2022-08-10 22:03:52,first off  another question    pretty much asks the same question  except that while they only say it happens for one of their projects  in my case it happens for every project that i ve ever created  and in that question s case  there was no solution  so i thought i d ask again and add additional details  in my case  fast reloading  or even just hot reloading rebuilding the page and refreshing when i update my code  just does not work at all  nothing happens when i change my code  when i create a basic next app using npx create next app latest  and then run the dev server using npm run dev  updating files like pages index js does not do anything  including basic changes like changing the page title tag  there is no output in the terminal from the server in response to me saving the file  i ve experienced this on two separate computers  both with typescript and with normal javascript  one computer runs windows   the other windows   but for both my development environment is wsl ubuntu  and i am using vscode  there is a slight difference between my experience on some projects  on the typescript project  modifying css files  not css modules  that i ve imported globally did actually seem to work with fast refresh  including terminal output as well as a loading icon on the page indicating the fast refresh took place  however  when following the process above to create the default js project  no aspect of fast refresh seems to work  no change seems to trigger a refresh or response  and refreshing the page does not do anything  to clarify  when i run npm run dev  npx next dev or yarn dev  the initial build runs just fine  i also have no issues with the typescript compiler or sass compilers  meaning that when i run tsc   ts   watch in a directory  it always compiles typescript code into js without a hitch when i modify those files  and the case is the same when i am working with  scss files  i can also start a production server with npm run start  again without a hitch  versions of some of the software i m running  package json next config js it s hard to say whether it could be related or not  but i ve also had issues with getting eaccess permissions errors when trying to install npm packages globally  which has required me to use sudo to get them to actually install  since i ve experienced this issue and the nextjs issue on both computers  could this point to an issue with the way i ve configured things on both machines  leading to the nextjs issue  does anyone with a similar setup not experience this issue  are there any additional details that i could investigate to try and identify the issue  finally  is it possible to enable additional debug output  if it could be helpful ,have to restart the next js dev server to view any changes
49,6456107,63600971,No ExecutorFactory found to execute the application in Flink 1.11.1,"<p>first of all I have read this <a href=""https://stackoverflow.com/questions/63032060/upgraded-flink-from-1-10-to-1-11-met-error-no-executorfactory-found-to-execute"">post</a> about the same issue and tried to follow the same solution that works for him (create a new quickstart with mvn and migrate the code there) and is not working eighter when out-of-the-box of IntelliJ.</p>
<p>Here is my pom.xml mixed with my dependencies from the other pom.xml. What am I doing wrong?</p>
<pre><code>&lt;!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
&quot;License&quot;); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
&quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
--&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.test&lt;/groupId&gt;
    &lt;artifactId&gt;job&lt;/artifactId&gt;
    &lt;version&gt;1&lt;/version&gt;
    &lt;packaging&gt;jar&lt;/packaging&gt;

    &lt;name&gt;funnel-cep-analytics&lt;/name&gt;

    &lt;properties&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
        &lt;flink.version&gt;1.11.0&lt;/flink.version&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
        &lt;scala.binary.version&gt;2.11&lt;/scala.binary.version&gt;
        &lt;maven.compiler.source&gt;${java.version}&lt;/maven.compiler.source&gt;
        &lt;maven.compiler.target&gt;${java.version}&lt;/maven.compiler.target&gt;
        &lt;log4j.version&gt;2.12.1&lt;/log4j.version&gt;
    &lt;/properties&gt;

    &lt;repositories&gt;
        &lt;repository&gt;
            &lt;id&gt;apache.snapshots&lt;/id&gt;
            &lt;name&gt;Apache Development Snapshot Repository&lt;/name&gt;
            &lt;url&gt;https://repository.apache.org/content/repositories/snapshots/&lt;/url&gt;
            &lt;releases&gt;
                &lt;enabled&gt;false&lt;/enabled&gt;
            &lt;/releases&gt;
            &lt;snapshots&gt;
                &lt;enabled&gt;true&lt;/enabled&gt;
            &lt;/snapshots&gt;
        &lt;/repository&gt;
    &lt;/repositories&gt;

    &lt;dependencies&gt;
        &lt;!-- Apache Flink dependencies --&gt;
        &lt;!-- These dependencies are provided, because they should not be packaged into the JAR file. --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-java&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-streaming-java_${scala.binary.version}&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-clients_${scala.binary.version}&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
            &lt;scope&gt;provided&lt;/scope&gt;
        &lt;/dependency&gt;

        &lt;!-- Add connector dependencies here. They must be in the default scope (compile). --&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-runtime-web_${scala.binary.version}&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- Add connector dependencies here. They must be in the default scope (compile). --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-hadoop-fs&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-core --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-connector-filesystem_2.11&lt;/artifactId&gt;
            &lt;version&gt;1.11.0&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- https://mvnrepository.com/artifact/org.apache.flink/flink-metrics-prometheus --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-metrics-prometheus_2.12&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
        &lt;/dependency&gt;


        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-connector-rabbitmq_${scala.binary.version}&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.postgresql&lt;/groupId&gt;
            &lt;artifactId&gt;postgresql&lt;/artifactId&gt;
            &lt;version&gt;9.4-1201-jdbc41&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- https://mvnrepository.com/artifact/org.apache.flink/flink-connector-redis --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.bahir&lt;/groupId&gt;
            &lt;artifactId&gt;flink-connector-redis_2.11&lt;/artifactId&gt;
            &lt;version&gt;1.1-SNAPSHOT&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- https://mvnrepository.com/artifact/com.google.code.gson/gson --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;
            &lt;artifactId&gt;gson&lt;/artifactId&gt;
            &lt;version&gt;2.8.6&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-cep_2.11&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- https://mvnrepository.com/artifact/org.apache.flink/flink-test-utils --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-test-utils_2.11&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-runtime_2.11&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
            &lt;scope&gt;test&lt;/scope&gt;
            &lt;classifier&gt;tests&lt;/classifier&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-streaming-java_2.11&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
            &lt;scope&gt;test&lt;/scope&gt;
            &lt;classifier&gt;tests&lt;/classifier&gt;
        &lt;/dependency&gt;

        &lt;!-- Add logging framework, to produce console output when running in the IDE. --&gt;
        &lt;!-- These dependencies are excluded from the application JAR by default. --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;junit&lt;/groupId&gt;
            &lt;artifactId&gt;junit&lt;/artifactId&gt;
            &lt;version&gt;4.13&lt;/version&gt;
            &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-test-utils-junit&lt;/artifactId&gt;
            &lt;version&gt;1.8.0&lt;/version&gt;
            &lt;scope&gt;compile&lt;/scope&gt;
        &lt;/dependency&gt;

        &lt;!-- Add logging framework, to produce console output when running in the IDE. --&gt;
        &lt;!-- These dependencies are excluded from the application JAR by default. --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
            &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt;
            &lt;version&gt;${log4j.version}&lt;/version&gt;
            &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
            &lt;artifactId&gt;log4j-api&lt;/artifactId&gt;
            &lt;version&gt;${log4j.version}&lt;/version&gt;
            &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
            &lt;artifactId&gt;log4j-core&lt;/artifactId&gt;
            &lt;version&gt;${log4j.version}&lt;/version&gt;
            &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;

            &lt;!-- Java Compiler --&gt;
            &lt;!-- Java Compiler --&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.1&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;source&gt;9&lt;/source&gt;
                    &lt;target&gt;9&lt;/target&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;

            &lt;!-- We use the maven-shade plugin to create a fat jar that contains all necessary dependencies. --&gt;
            &lt;!-- Change the value of &lt;mainClass&gt;...&lt;/mainClass&gt; if your program entry point changes. --&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.1.1&lt;/version&gt;
                &lt;executions&gt;
                    &lt;!-- Run shade goal on package phase --&gt;
                    &lt;execution&gt;
                        &lt;phase&gt;package&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;shade&lt;/goal&gt;
                        &lt;/goals&gt;
                        &lt;configuration&gt;
                            &lt;artifactSet&gt;
                                &lt;excludes&gt;
                                    &lt;exclude&gt;org.apache.flink:force-shading&lt;/exclude&gt;
                                    &lt;exclude&gt;com.google.code.findbugs:jsr305&lt;/exclude&gt;
                                &lt;/excludes&gt;
                            &lt;/artifactSet&gt;
                            &lt;filters&gt;
                                &lt;filter&gt;
                                    &lt;!-- Do not copy the signatures in the META-INF folder.
                                    Otherwise, this might cause SecurityExceptions when using the JAR. --&gt;
                                    &lt;artifact&gt;*:*&lt;/artifact&gt;
                                    &lt;excludes&gt;
                                        &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt;
                                        &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt;
                                        &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt;
                                    &lt;/excludes&gt;
                                &lt;/filter&gt;
                            &lt;/filters&gt;
                            &lt;transformers&gt;
                                &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt;
                                    &lt;mainClass&gt;path.StreamingJob&lt;/mainClass&gt;
                                &lt;/transformer&gt;
                            &lt;/transformers&gt;
                        &lt;/configuration&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;

        &lt;pluginManagement&gt;
            &lt;plugins&gt;

                &lt;!-- This improves the out-of-the-box experience in Eclipse by resolving some warnings. --&gt;
                &lt;plugin&gt;
                    &lt;groupId&gt;org.eclipse.m2e&lt;/groupId&gt;
                    &lt;artifactId&gt;lifecycle-mapping&lt;/artifactId&gt;
                    &lt;version&gt;1.0.0&lt;/version&gt;
                    &lt;configuration&gt;
                        &lt;lifecycleMappingMetadata&gt;
                            &lt;pluginExecutions&gt;
                                &lt;pluginExecution&gt;
                                    &lt;pluginExecutionFilter&gt;
                                        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                                        &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;
                                        &lt;versionRange&gt;[3.1.1,)&lt;/versionRange&gt;
                                        &lt;goals&gt;
                                            &lt;goal&gt;shade&lt;/goal&gt;
                                        &lt;/goals&gt;
                                    &lt;/pluginExecutionFilter&gt;
                                    &lt;action&gt;
                                        &lt;ignore/&gt;
                                    &lt;/action&gt;
                                &lt;/pluginExecution&gt;
                                &lt;pluginExecution&gt;
                                    &lt;pluginExecutionFilter&gt;
                                        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                                        &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                                        &lt;versionRange&gt;[3.1,)&lt;/versionRange&gt;
                                        &lt;goals&gt;
                                            &lt;goal&gt;testCompile&lt;/goal&gt;
                                            &lt;goal&gt;compile&lt;/goal&gt;
                                        &lt;/goals&gt;
                                    &lt;/pluginExecutionFilter&gt;
                                    &lt;action&gt;
                                        &lt;ignore/&gt;
                                    &lt;/action&gt;
                                &lt;/pluginExecution&gt;
                            &lt;/pluginExecutions&gt;
                        &lt;/lifecycleMappingMetadata&gt;
                    &lt;/configuration&gt;
                &lt;/plugin&gt;
            &lt;/plugins&gt;
        &lt;/pluginManagement&gt;
    &lt;/build&gt;

    &lt;profiles&gt;
        &lt;profile&gt;
            &lt;id&gt;add-dependencies-for-IDEA&lt;/id&gt;
            &lt;activation&gt;
                &lt;property&gt;
                    &lt;name&gt;idea.version&lt;/name&gt;
                &lt;/property&gt;
            &lt;/activation&gt;
            &lt;dependencies&gt;
                &lt;dependency&gt;
                    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
                    &lt;artifactId&gt;flink-java&lt;/artifactId&gt;
                    &lt;version&gt;${flink.version}&lt;/version&gt;
                    &lt;scope&gt;compile&lt;/scope&gt;
                &lt;/dependency&gt;
                &lt;dependency&gt;
                    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
                    &lt;artifactId&gt;flink-streaming-java_${scala.binary.version}&lt;/artifactId&gt;
                    &lt;version&gt;${flink.version}&lt;/version&gt;
                    &lt;scope&gt;compile&lt;/scope&gt;
                &lt;/dependency&gt;
                &lt;dependency&gt;
                    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
                    &lt;artifactId&gt;flink-clients_${scala.binary.version}&lt;/artifactId&gt;
                    &lt;version&gt;${flink.version}&lt;/version&gt;
                    &lt;scope&gt;compile&lt;/scope&gt;
                &lt;/dependency&gt;
            &lt;/dependencies&gt;
        &lt;/profile&gt;
    &lt;/profiles&gt;
&lt;/project&gt;

</code></pre>
<p>and the error here when running out from IntelliJ:</p>
<pre><code>java.lang.IllegalStateException: No ExecutorFactory found to execute the application.
        at org.apache.flink.core.execution.DefaultExecutorServiceLoader.getExecutorFactory(DefaultExecutorServiceLoader.java:84) ~[cep-1.5.0.jar:?]
        at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1803) ~[cep-1.5.0.jar:?]
        at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1713) ~[cep-1.5.0.jar:?]
        at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:74) ~[cep-1.5.0.jar:?]
        at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1699) ~[job.jar:?]
        at com.test.job.StreamingJob.runCEP(StreamingJob.java:122) ~[job.jar:?]
        at com.test.job.StreamingJob.init(StreamingJob.java:107) ~[job.jar:?]
        at com.test.job.StreamingJob.main(StreamingJob.java:64) [job.jar:?]
</code></pre>
",5934,10,5,3,apache-flink;flink-streaming;flink-cep,2020-08-26 18:34:44,2020-08-26 18:34:44,2022-08-10 18:16:21,first of all i have read this  about the same issue and tried to follow the same solution that works for him  create a new quickstart with mvn and migrate the code there  and is not working eighter when out of the box of intellij  here is my pom xml mixed with my dependencies from the other pom xml  what am i doing wrong  and the error here when running out from intellij ,no executorfactory found to execute the application in flink   
50,19687982,73302317,How to join 2 collections if the ID types in 1st collection is ObjectId and the foreign key type is string in mongodb,"<p>I have 2 collections,1st is:</p>
<pre><code>{
        &quot;_id&quot; : ObjectId(&quot;62eb5713ac2dccfb0a75d6c0&quot;),
        &quot;title&quot; : &quot;Agile Web Development with Rails&quot;,
        &quot;categoryId&quot; : ObjectId(&quot;62eb5713ac2dccfb0a75d6bf&quot;),
        &quot;subtitle&quot; : &quot;Dive into ES6 and the Future of JavaScript&quot;,
        &quot;author&quot; : &quot;Sam Ruby, Dave Thomas, David Heinemeier Hansson&quot;,
        &quot;published&quot; : 2010,
        &quot;publisher&quot; : &quot;O'Reilly Media&quot;,
        &quot;isActive&quot; : true,
        &quot;isDelete&quot; : false,
        &quot;__v&quot; : 0
}
{
        &quot;_id&quot; : ObjectId(&quot;62eb5777ac2dccfb0a75d6c3&quot;),
        &quot;title&quot; : &quot;Eloquent JavaScript, Third Edition&quot;,
        &quot;categoryId&quot; : ObjectId(&quot;62eb5777ac2dccfb0a75d6c2&quot;),
        &quot;subtitle&quot; : &quot;A Modern Introduction to Programming&quot;,
        &quot;author&quot; : &quot;Marijn Haverbeke&quot;,
        &quot;published&quot; : 2018,
        &quot;publisher&quot; : &quot;No Starch Press&quot;,
        &quot;isActive&quot; : true,
        &quot;isDelete&quot; : false,
        &quot;__v&quot; : 0
}
{
        &quot;_id&quot; : ObjectId(&quot;62eb5aa0e45707fec304e115&quot;),
        &quot;title&quot; : &quot;Eloquent JavaScript, Third Edition&quot;,
        &quot;categoryId&quot; : ObjectId(&quot;62eb41f088b1bc88e8a416db&quot;),
        &quot;subtitle&quot; : &quot;A Modern Introduction to Programming&quot;,
        &quot;author&quot; : &quot;Marijn Haverbeke&quot;,
        &quot;published&quot; : 2018,
        &quot;publisher&quot; : &quot;No Starch Press&quot;,
        &quot;isActive&quot; : true,
        &quot;isDelete&quot; : false,
        &quot;__v&quot; : 0
}
{
        &quot;_id&quot; : ObjectId(&quot;62ebaf20de65e74cd055565a&quot;),
        &quot;title&quot; : &quot;Rethinking Productivity in Software Engineering&quot;,
        &quot;categoryId&quot; : ObjectId(&quot;62eb420b88b1bc88e8a416df&quot;),
        &quot;subtitle&quot; : &quot;Everything you neeed to know about Gi&quot;,
        &quot;author&quot; : &quot;Caitlin Sadowski, Thomas Zimmermann&quot;,
        &quot;published&quot; : 2019,
        &quot;publisher&quot; : &quot;Apress&quot;,
        &quot;isActive&quot; : true,
        &quot;isDelete&quot; : false,
        &quot;__v&quot; : 0
}
{
        &quot;_id&quot; : ObjectId(&quot;62f08a12e0346e06e4bb7b06&quot;),
        &quot;categoryId&quot; : ObjectId(&quot;62f08a12e0346e06e4bb7b05&quot;),
        &quot;isActive&quot; : true,
        &quot;isDelete&quot; : false,
        &quot;__v&quot; : 0
}
</code></pre>
<p>2nd collection is:</p>
<pre><code>{
        &quot;_id&quot; : ObjectId(&quot;62f3377166def37dee13f400&quot;),
        &quot;book_id&quot; : &quot;62eb5713ac2dccfb0a75d6c0&quot;,
        &quot;description&quot; : &quot;for Agile Web...&quot;
}
{
        &quot;_id&quot; : ObjectId(&quot;62f3383566def37dee13f401&quot;),
        &quot;book_id&quot; : &quot;62ebaf20de65e74cd055565a&quot;,
        &quot;description&quot; : &quot;for Rethinking Productivity...&quot;
}
{
        &quot;_id&quot; : ObjectId(&quot;62f3388666def37dee13f402&quot;),
        &quot;book_id&quot; : &quot;62eb5aa0e45707fec304e115&quot;,
        &quot;description&quot; : &quot;for Eloquent JavaScript...&quot;
}
</code></pre>
<p>I want to join 2 collections by use of aggregate $lookup,$match,$and,$ecpr,$eq and get the data in Mongo compass by using 'pipe line from text'. My code is:</p>
<pre><code>[{$lookup:
({
  from: &quot;books&quot;,
  let: {
    &quot;bkid&quot;: new mongoose.Types.ObjectId('book_id')
  },
  pipeline: [{
    $match: {
      $and: {
        $expr: {
          $eq: ['$_id', '$$bkid']
        }
      }
    }
  }],
 as: &quot;res&quot;
})
}]
</code></pre>
<p>What is wrong here why its not showing output?
I am doing this code in Mongodbaggregation -&gt; CREATE -&gt; Pipeline for Text.
Thanks in advance.</p>
",16,1,0,2,mongodb;lookup,2022-08-10 10:28:30,2022-08-10 10:28:30,2022-08-10 14:58:50,i have  collections st is  nd collection is  i want to join  collections by use of aggregate  lookup  match  and  ecpr  eq and get the data in mongo compass by using  pipe line from text   my code is ,how to join  collections if the id types in st collection is objectid and the foreign key type is string in mongodb
51,962583,29360699,How to automate source control with Oracle database,"<p>I work in an Oracle instance that has hundreds of schemas and multiple developers. We have a development instance where developers can integrate their work before test or production.</p>

<p>We want to have source control for all the DDL run in this integrated development database. Currently this is done through a product Red Gate which we run manually after we make a change to the database. Redgate finds the changes between what is in the schema and what was last checked into source control and makes a script of the differences and puts this into source control. </p>

<p>The problem however is of course that running regdate can take some time and people run it infrequently or not at all for small changes. Also redgate will only look in one schema at a time and it would be VERY time consuming to manually run it against all schemas to guarantee that they are up to date. However if the source controlled code cannot be relied upon it becomes less useful...</p>

<p>What would seem to be ideal would be to have some software that could periodically (even once a day), or when triggered by DDL being run, update the source control (preferably github as this is used by other teams) from all the schemas. </p>

<p>I cannot seem to see any existing software which can be simply used to do this.  </p>

<p>Is there a problem with doing this? (there is no need to address multiple developers overwriting each others work on the same day as we have this covered in a separate process) Is anyone doing this?  Can anyone recommend a way to do this?  </p>
",6848,5,5,4,sql;plsql;oracle11g;oracle12c,2015-03-31 07:37:00,2015-03-31 07:37:00,2022-08-10 08:52:44,i work in an oracle instance that has hundreds of schemas and multiple developers  we have a development instance where developers can integrate their work before test or production  we want to have source control for all the ddl run in this integrated development database  currently this is done through a product red gate which we run manually after we make a change to the database  redgate finds the changes between what is in the schema and what was last checked into source control and makes a script of the differences and puts this into source control   the problem however is of course that running regdate can take some time and people run it infrequently or not at all for small changes  also redgate will only look in one schema at a time and it would be very time consuming to manually run it against all schemas to guarantee that they are up to date  however if the source controlled code cannot be relied upon it becomes less useful    what would seem to be ideal would be to have some software that could periodically  even once a day   or when triggered by ddl being run  update the source control  preferably github as this is used by other teams  from all the schemas   i cannot seem to see any existing software which can be simply used to do this    is there a problem with doing this   there is no need to address multiple developers overwriting each others work on the same day as we have this covered in a separate process  is anyone doing this   can anyone recommend a way to do this   ,how to automate source control with oracle database
52,2708519,73299856,Problem installing PyCharm on Raspberry Pi Desktop for Mac,"<p>I am trying to install the <strong>Pycharm community edition</strong>. I have read the other <strong>stackoverflow</strong> articles on problems installing <strong>Pycharm</strong>, but I have not found any of the other fixes (installing <strong>Java, Fuse...</strong>) have resolved my problem, so I have created this new posting.</p>
<p>I have failed in installing <strong>PyCharm</strong> using these two different methods:</p>
<p><strong>A) Jetbrains Toolbox</strong> Download.</p>
<ol>
<li>Downloaded <strong>jetbrains-toolbox-1.25.12627.tar.gz</strong> to  <strong>/opt</strong> from the JetBrain's website.</li>
<li>Extracted <strong>/opt/jetbrains-toolbox-1.25.12627</strong> from the tarball.</li>
<li>This contained one executable file: <strong>/opt/jetbrains-toolbox-1.25.12627/jetbrains-toolbox</strong></li>
<li>I verified this file exists and its permissions:</li>
</ol>
<blockquote>
<pre><code>% ls -l /opt/jetbrains-toolbox-1.25.12627/jetbrains-toolbox

-rwxr-xr-x 1 root root 66043880 Jul 27 06:27 /opt/jetbrains-toolbox1.25.12627/jetbrains-toolbox
</code></pre>
</blockquote>
<ol start=""5"">
<li>I tried to run the executable:</li>
</ol>
<blockquote>
<pre><code>% sudo /opt/jetbrains-toolbox-1.25.12627/jetbrains-toolbox
</code></pre>
</blockquote>
<ol start=""6"">
<li>But this failed with this error:</li>
</ol>
<blockquote>
<pre><code>sudo: unable to execute /opt/jetbrains-toolbox-1.25.12627/jetbrains-toolbox: No such file or directory
</code></pre>
</blockquote>
<p>Since I have verified that the file does exist and has execute permissions, I believe that perhaps there is a problem with the downloaded file, so I checked it's characteristics.</p>
<blockquote>
<p><code>% file /opt/jetbrains-toolbox-1.25.12627/jetbrains-toolbox</code></p>
<pre><code>/opt/jetbrains-toolbox-1.25.12627/jetbrains-toolbox: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.18, stripped
</code></pre>
</blockquote>
<p>As I mentioned, I have installed fuse and the libfuse2 library, and that did not fix this problem.I will describe my environment further below, and perhaps it is a mismatch to the executable?</p>
<p><strong>B) Pycharm</strong> Download</p>
<ol>
<li><p>Downloaded <strong>pycharm-community-2022.2.tar.gz</strong> to  <strong>/opt</strong> from the JetBrain's website.</p>
</li>
<li><p>Extracted <strong>/opt/pycharm-community-2022.2</strong> from the tarball.</p>
</li>
<li><p>This extract contained the following shell script as expected: <strong>/opt/pycharm-community-2022.2/bin/pycharm.sh</strong></p>
</li>
<li><p>I verified this file exists and its permissions:</p>
</li>
</ol>
<blockquote>
<pre><code>% ls -ld /opt/pycharm-community-2022.2/
drwxr-xr-x 8 root root 4096 Aug  9 13:32 /opt/pycharm-community-2022.2/

% ls -ld /opt/pycharm-community-2022.2/bin
drwxr-xr-x 3 root root 4096 Aug  9 15:52 /opt/pycharm-community-2022.2/bin

% ls -ld /opt/pycharm-community-2022.2/bin/pycharm.sh
-rwxr-xr-x 1 root root 9846 Aug  9 13:32 /opt/pycharm-community-2022.2/bin/pycharm.sh
</code></pre>
</blockquote>
<ol start=""5"">
<li>I tried to run the executable:</li>
</ol>
<blockquote>
<pre><code>% sudo /opt/pycharm-community-2022.2/bin/pycharm.sh
</code></pre>
</blockquote>
<ol start=""6"">
<li>But this failed with this error:</li>
</ol>
<blockquote>
<pre><code>/opt/pycharm-community-2022.2/bin/pycharm.sh: 188: exec: /opt/pycharm-community-2022.2/jbr/bin/java: not found
</code></pre>
</blockquote>
<ol start=""7"">
<li>I checked the permissions and file type on /<strong>opt/pycharm-community-2022.2/jbr/bin/java</strong> as well:</li>
</ol>
<blockquote>
<pre><code>% ls -l /opt/pycharm-community-2022.2/jbr/bin/java
-rwxr-xr-x 1 root root 12856 Aug  9 13:32 /opt/pycharm-community-2022.2/jbr/bin/java

% file /opt/pycharm-community-2022.2/jbr/bin/java
/opt/pycharm-community-2022.2/jbr/bin/java: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.32, BuildID[sha1]=7d7f5d43d41f83ace745f2c2b059858897d11a4d, not stripped
</code></pre>
</blockquote>
<p><strong>Development Environment:</strong>
I don't understand what the problem is but it may be my environment.</p>
<p>I have successfully installed this software on my Raspberry Pi 400 without any problems.</p>
<p>I am trying to duplicate my Raspberry Pi 400 environment in a VirtualBox VM running on my MacBookPro.  I've installed the Raspberry Pi Desktop for Mac in the VirtualBox VM
Below I have pasted the <strong>lscpu</strong> output.  I am guessing the problem may lie in the fact the actual raspberry pi 400 is a <strong>64 bit ARM architecture</strong>, and the VM is reporting a <strong>x86_64 architecture</strong></p>
<p>If this is indeed the case, is there something wrong with how my <strong>Raspberry Pi Desktop for Mac</strong> got installed? How can I fix this problem?</p>
",23,0,-1,5,raspberry-pi;architecture;pycharm;virtualbox;raspbian,2022-08-10 05:00:45,2022-08-10 05:00:45,2022-08-10 05:00:45,i am trying to install the pycharm community edition  i have read the other stackoverflow articles on problems installing pycharm  but i have not found any of the other fixes  installing java  fuse     have resolved my problem  so i have created this new posting  i have failed in installing pycharm using these two different methods  a  jetbrains toolbox download  since i have verified that the file does exist and has execute permissions  i believe that perhaps there is a problem with the downloaded file  so i checked it s characteristics    file  opt jetbrains toolbox    jetbrains toolbox as i mentioned  i have installed fuse and the libfuse library  and that did not fix this problem i will describe my environment further below  and perhaps it is a mismatch to the executable  b  pycharm download downloaded pycharm community   tar gz to   opt from the jetbrain s website  extracted  opt pycharm community   from the tarball  this extract contained the following shell script as expected   opt pycharm community   bin pycharm sh i verified this file exists and its permissions  i have successfully installed this software on my raspberry pi  without any problems  if this is indeed the case  is there something wrong with how my raspberry pi desktop for mac got installed  how can i fix this problem ,problem installing pycharm on raspberry pi desktop for mac
53,1315009,57452441,What code-repository should the Dockerfile get committed to?,"<h1>Long story short</h1>

<p>Where should I commit the Dockerfile? In the project codebase or in the devops codebase?</p>

<p>Reasoning details:</p>

<h2>Without docker and without CI</h2>

<p>In the ancient times, when developing a complex application with multiple code-bases, one normally wanted to have one repo per project and have all the passwords, credentials and dev/test/pre/prod configurations separated from the code.</p>

<pre><code>+-----------------------------------------------------------------------+
|                                                                       |
|  +---------+       +---------+       +---------+       +---------+    |
|  |  app-1  |       |  app-2  |       |  app-3  |       |  app-4  |    |
|  +---------+       +---------+       +---------+       +---------+    |
|                                                                       |
|                            +----+                                     |
|                            |    |\                                    |
|                            |    +-+                                   |
|                            | conf |                                   |
|                            | files|                                   |
|                            +------+                                   |
|                                                                       |
+-----------------------------------------------------------------------+
</code></pre>

<p>In the old-ancient times one sysadmin installed the software in the server and then later copied the config files. Back in the 90's usually the sysop had those files in a directory of his own, shared only with the boss.</p>

<h2>With CI but still without docker</h2>

<p>Later we improved the cycle: in Continuos development/integration environments, ""the system"" itself needs to be able to clone all those repos and be able to ""build"" the applications and configure them to be ready to be run. Then copy the build into the servers and configure them accordingly.</p>

<p>This enables all the developers to trigger deploys at production, still not compromising the secret keys.</p>

<p>Before containers, typically the companies had an extra ""devops"" (AKA CI repo) where we had all those config files organized and know by an script. The CI server (pre-docker) knows all the source-code repos, knows the destination-network-topology, has the passwords to the cloud, and copies/builds/deploys everything in its destination and also configures it, making unnecessary the human intervention provided the servers are up and running.</p>

<pre><code>+-----------------------------------------------------------------------+
|                                                                       |
|  +---------+       +---------+       +---------+       +---------+    |
|  |  app-1  |       |  app-2  |       |  app-3  |       |  app-4  |    |
|  +---------+       +---------+       +---------+       +---------+    |
|                                                                       |
|                          +----------------+                           |
|                          |     devops     |                           |
|                          +----------------+                           |
|                          | config-1-devel |                           |
|                          | config-1-pre   |                           |
|                          | config-1-prod  |                           |
|                          | config-2-devel |                           |
|                          |      [...]     |                           |
|                          | config-4-prod  |                           |
|                          +----------------+                           |
|                                                                       |
+-----------------------------------------------------------------------+
</code></pre>

<h2>CI with Docker</h2>

<p>When it comes to make docker play a role in the equation, I wonder if the correct place to have the Dockerfile is inside the application CVS repository or in the devops repository.</p>

<h2>Will the Dockerfile go into the app code-base?</h2>

<p>Unless we do an open-source code that needs to run in many platforms, usually the companies establish a target platform and the coders ""know"" the target system will be an Ubuntu, or a CentOs or so beforehand.</p>

<p>On the other hand it is now that the coders themselves touch the Dockerfile as one moe source-code file. This pushes us to think that the Dockerfile fits in each code-base as the app and the system it runs in will be -probably- coupled by needing certain requirements.</p>

<pre><code>+-----------------------------------------------------------------------+
|                                                                       |
| +-------------+   +-------------+   +-------------+   +-------------+ |
| |    app-1    |   |    app-2    |   |    app-3    |   |    app-4    | |
| +-------------+   +-------------+   +-------------+   +-------------+ |
| |Dockerfile-1 |   |Dockerfile-2 |   |Dockerfile-3 |   |Dockerfile-4 | |   
| +-------------+   +-------------+   +-------------+   +-------------+ |
|                                                                       |
|                          +----------------+                           |
|                          |     devops     |                           |
|                          +----------------+                           |
|                          | config-1-devel |                           |
|                          | config-1-pre   |                           |
|                          | config-1-prod  |                           |
|                          | config-2-devel |                           |
|                          |      [...]     |                           |
|                          | config-4-prod  |                           |
|                          +----------------+                           |
|                                                                       |
+-----------------------------------------------------------------------+
</code></pre>

<h2>Or will the Dockerfile go into the devops code-base (AKA the CI server code-base)?</h2>

<p>But also it seems the programmer should do the very same lines of code, for example if he is coding a web application, despite it is run under an apache, an nginx or a caddy server... so the ""decission"" of the runtime seems it should be coded into the devops code-base:</p>

<pre><code>+-----------------------------------------------------------------------+
|                                                                       |
| +-------------+   +-------------+   +-------------+   +-------------+ |
| |    app-1    |   |    app-2    |   |    app-3    |   |    app-4    | |
| +-------------+   +-------------+   +-------------+   +-------------+ |
|                                                                       |
|                          +----------------+                           |
|                          |     devops     |                           |
|                          +----------------+                           |
|                          | Dockerfile-1   |                           |
|                          | Dockerfile-2   |                           |
|                          | Dockerfile-3   |                           |
|                          | Dockerfile-4   |                           |
|                          +----------------+                           |
|                          | config-1-devel |                           |
|                          | config-1-pre   |                           |
|                          | config-1-prod  |                           |
|                          | config-2-devel |                           |
|                          |      [...]     |                           |
|                          | config-4-prod  |                           |
|                          +----------------+                           |
|                                                                       |
+-----------------------------------------------------------------------+
</code></pre>

<p>In the team we can't clarify the proper way and I've searched but I am unable to find documentation that demonstrates if the different Dockerfiles should be committed into the app repos or in the devops repo (AKA CI repo).</p>

<p>Where should I commit them?</p>
",1001,2,1,4,version-control;architecture;dockerfile;devops,2019-08-11 21:16:10,2019-08-11 21:16:10,2022-08-09 17:50:58,where should i commit the dockerfile  in the project codebase or in the devops codebase  reasoning details  in the ancient times  when developing a complex application with multiple code bases  one normally wanted to have one repo per project and have all the passwords  credentials and dev test pre prod configurations separated from the code  in the old ancient times one sysadmin installed the software in the server and then later copied the config files  back in the  s usually the sysop had those files in a directory of his own  shared only with the boss  later we improved the cycle  in continuos development integration environments  the system itself needs to be able to clone all those repos and be able to build the applications and configure them to be ready to be run  then copy the build into the servers and configure them accordingly  this enables all the developers to trigger deploys at production  still not compromising the secret keys  before containers  typically the companies had an extra devops  aka ci repo  where we had all those config files organized and know by an script  the ci server  pre docker  knows all the source code repos  knows the destination network topology  has the passwords to the cloud  and copies builds deploys everything in its destination and also configures it  making unnecessary the human intervention provided the servers are up and running  when it comes to make docker play a role in the equation  i wonder if the correct place to have the dockerfile is inside the application cvs repository or in the devops repository  unless we do an open source code that needs to run in many platforms  usually the companies establish a target platform and the coders know the target system will be an ubuntu  or a centos or so beforehand  on the other hand it is now that the coders themselves touch the dockerfile as one moe source code file  this pushes us to think that the dockerfile fits in each code base as the app and the system it runs in will be  probably  coupled by needing certain requirements  but also it seems the programmer should do the very same lines of code  for example if he is coding a web application  despite it is run under an apache  an nginx or a caddy server    so the decission of the runtime seems it should be coded into the devops code base  in the team we can t clarify the proper way and i ve searched but i am unable to find documentation that demonstrates if the different dockerfiles should be committed into the app repos or in the devops repo  aka ci repo   where should i commit them ,what code repository should the dockerfile get committed to 
54,781970,73292132,Is there a way to migrate a Cloud9 instance to a regular EC2 instance?,"<p>I have a Cloud9 EC2 instance running on Linux 2 AMI. The nice thing about the Cloud9 instance is that all the software packages I want (Rails) are installed and I didn't have to configure or install anything on the instance. Of course the instance shuts down when I'm not working in the environment. When I'm done developing, is there a way to migrate my development environment into a production environment? Or do I have to start a new EC2 instance, configure it (pain ITA), update it, lock it down, and download code from a repo? Or is there an AMI that is similar to what Cloud9 runs?</p>
",21,0,0,4,amazon-web-services;amazon-ec2;aws-cloud9;aws-codestar,2022-08-09 15:50:04,2022-08-09 15:50:04,2022-08-09 16:31:26,i have a cloud ec instance running on linux  ami  the nice thing about the cloud instance is that all the software packages i want  rails  are installed and i didn t have to configure or install anything on the instance  of course the instance shuts down when i m not working in the environment  when i m done developing  is there a way to migrate my development environment into a production environment  or do i have to start a new ec instance  configure it  pain ita   update it  lock it down  and download code from a repo  or is there an ami that is similar to what cloud runs ,is there a way to migrate a cloud instance to a regular ec instance 
55,10395384,73283929,How can I use Kinect 360 with Windows?,"<p>I am trying to connect Kinect 360 with Windows.</p>
<p>What I try:<br />
I try to connect it with Windows 10 (64-bit) and Windows 8.1 (64-bit) (both ware host OS).</p>
<ol>
<li>I downloaded and Installed the Software Development Kit (SDK).</li>
<li>I downloaded and installed the Kinect for Windows SDK v1.8.</li>
<li>I downloaded and installed the Kinect for Windows Developer Toolkit v1.8.</li>
<li>Then, I plug the Kinect 360 in the electric power and connect it with my Lap Top using the USB 3. I am using a power supply adapter cable for Xbox 360 Kinect Sensor (see the picture below).
<a href=""https://i.stack.imgur.com/FF1PZ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/FF1PZ.png"" alt=""enter image description here"" /></a></li>
</ol>
<p>As a result, no new hardware ware listed in the Device Manager like no new microphone, no new camera, no new unknown devices.</p>
<p>BTW I am not sure if the Kinect hardware is working at all. I don't know how to check it - there aren't any lighting lights on it. I did some research, but I didn't see any lights on working Kinect 360 on youtube videos. So I don't know how to test whether the Kinect is working (without connecting it with XBOX).</p>
<p>I want to connect the Kinect sensor with the PC machine because I need to do some tests. If there are other solutions with another OS (like Linux-based or MAC OS), I can try it too.</p>
",13,0,0,3,windows;kinect;kinect-sdk,2022-08-08 23:56:37,2022-08-08 23:56:37,2022-08-08 23:56:37,i am trying to connect kinect  with windows  as a result  no new hardware ware listed in the device manager like no new microphone  no new camera  no new unknown devices  btw i am not sure if the kinect hardware is working at all  i don t know how to check it   there aren t any lighting lights on it  i did some research  but i didn t see any lights on working kinect  on youtube videos  so i don t know how to test whether the kinect is working  without connecting it with xbox   i want to connect the kinect sensor with the pc machine because i need to do some tests  if there are other solutions with another os  like linux based or mac os   i can try it too ,how can i use kinect  with windows 
56,19147128,73211687,Having trouble populating a drop down list within a gridview,"<p>as the title states I am currently having trouble populating a drop down list that is contained within a gridview. At first glance this seems like a relatively simple problem and I have populated many gridviews and many drop down lists in the past, however this one is being a real pain. I am relatively new to software development so any  help regarding this issue regardless of simplicity would be greatly appreciated. Below I have detailed the problem more explicitly and copied any relevant code, if there is anything I have missed I would be more than happy to supply it.</p>
<p>As stated before I have a drop down list (ddlPartEquipmentNew) within a gridview control (GridView3). So far there is one item in the ddl &quot;---SELECT---&quot; that I added as a ListItem in the aspx page.  I am trying to populate the gridview with data from my database that corresponds to a value that is currently stored in a variable on the page. I have tested my query and can confirm that it returns the appropriate values in SSMS and it looks like</p>
<p>SELECT EquipmentType FROM Equipment WHERE Agreement = @Agreement</p>
<p>Below I have posted The aspx code of the gridview and drop down.</p>
<pre><code>&lt;asp:GridView ID=&quot;GridView3&quot; runat=&quot;server&quot;
    EmptyDataText=&quot;No Claimed Parts&quot; AutoGenerateColumns=&quot;False&quot;
    ShowHeaderWhenEmpty=&quot;True&quot; DataKeyNames=&quot;RecID&quot;
    ShowFooter=&quot;True&quot; DataSourceID=&quot;SqlDataSource5&quot; Width=&quot;95%&quot;&gt;

&lt;EmptyDataTemplate&gt;
    &lt;asp:DropDownList ID=&quot;ddlPartEquipmentNew&quot; runat=&quot;server&quot; DataSourceID=&quot;SqlDataSourcePartEquipment&quot; DataValueField=&quot;EquipmentType&quot; DataTextField=&quot;EquipmentType&quot;
        AppendDataBoundItems=&quot;True&quot; Width=&quot;270px&quot; Height=&quot;20px&quot; Style=&quot;margin-left: 70px;&quot;&gt;
        &lt;asp:ListItem Value=&quot;0&quot;&gt;---SELECT---&lt;/asp:ListItem&gt;
    &lt;/asp:DropDownList&gt;
    &lt;asp:DropDownList ID=&quot;ddlPartNew&quot; runat=&quot;server&quot; DataSourceID=&quot;SqlDataSourcePart&quot; DataValueField=&quot;RecID&quot;
        DataTextField=&quot;description&quot; AppendDataBoundItems=&quot;True&quot; Width=&quot;270px&quot;  Height=&quot;20px&quot;
        style=&quot;margin-left: 70px; margin-right: 110px&quot;&gt;
        &lt;asp:ListItem Value=&quot;0&quot;&gt;---SELECT---&lt;/asp:ListItem&gt;
    &lt;/asp:DropDownList&gt;
    &lt;asp:textbox ID=&quot;txtUnitPriceNew&quot; runat=&quot;server&quot; Width=&quot;95px&quot;/&gt;
    &lt;asp:textbox ID=&quot;txtTaxNew&quot; runat=&quot;server&quot; Width=&quot;95px&quot; text=&quot;0&quot;/&gt;
    &lt;asp:Button ID=&quot;InsertDetail&quot; runat=&quot;server&quot; CommandName=&quot;InsertDetail&quot; Height=&quot;25px&quot; Text=&quot;Add Detail&quot; Width=&quot;85px&quot; /&gt;
&lt;/EmptyDataTemplate&gt;

&lt;AlternatingRowStyle BackColor=&quot;#CCCCCC&quot; /&gt;
    &lt;Columns&gt;
        &lt;asp:CommandField ShowEditButton=&quot;True&quot; footertext=&quot;Add --&gt;&quot; ShowDeleteButton=&quot;True&quot; HeaderStyle-Width=&quot;70px&quot;/&gt;
        &lt;asp:BoundField DataField=&quot;RecID&quot; HeaderText=&quot;RecID&quot; SortExpression=&quot;RecID&quot; ReadOnly=&quot;True&quot; Visible=&quot;False&quot; /&gt;

        &lt;asp:TemplateField HeaderText=&quot;Parts Description&quot; ItemStyle-HorizontalAlign=&quot;center&quot;&gt;
            &lt;ItemTemplate&gt;
                &lt;asp:label ID=&quot;lblDescriptionAdd&quot; Text='&lt;%# Bind(&quot;PartFailed&quot;) %&gt;' runat=&quot;server&quot;/&gt;
            &lt;/ItemTemplate&gt;
            &lt;EditItemTemplate&gt;
                &lt;asp:DropDownList ID=&quot;ddlPartEquipmentEdit&quot; runat=&quot;server&quot; DataValueField=&quot;Agreement&quot; DataTextField=&quot;EquipmentType&quot;
                    AppendDataBoundItems=&quot;True&quot; Width=&quot;270px&quot; Height=&quot;20px&quot; Style=&quot;margin-left: 70px;&quot;&gt;
                    &lt;asp:ListItem Value=&quot;0&quot;&gt;---SELECT---&lt;/asp:ListItem&gt;
                &lt;/asp:DropDownList&gt;
                &lt;asp:DropDownList ID=&quot;ddlPartEdit&quot; runat=&quot;server&quot; DataSourceID=&quot;SqlDataSourcePart&quot; DataValueField=&quot;RecID&quot; DataTextField=&quot;description&quot; SelectedValue='&lt;%# Eval(&quot;RepairID&quot;)%&gt;' AppendDataBoundItems=&quot;True&quot; Width=&quot;270px&quot;/&gt;
            &lt;/EditItemTemplate&gt;
            &lt;FooterTemplate&gt;
                &lt;asp:DropDownList ID=&quot;ddlPartEquipmentInsert&quot; runat=&quot;server&quot; DataValueField=&quot;Agreement&quot; DataTextField=&quot;EquipmentType&quot;
                    AppendDataBoundItems=&quot;True&quot; Width=&quot;270px&quot; Height=&quot;20px&quot; Style=&quot;margin-left: 70px;&quot;&gt;
                    &lt;asp:ListItem Value=&quot;0&quot;&gt;---SELECT---&lt;/asp:ListItem&gt;
                &lt;/asp:DropDownList&gt;
                &lt;asp:DropDownList ID=&quot;ddlPartInsert&quot; runat=&quot;server&quot; DataSourceID=&quot;SqlDataSourcePart&quot; DataValueField=&quot;RecID&quot; DataTextField=&quot;description&quot; AppendDataBoundItems=&quot;True&quot; Width=&quot;270px&quot;&gt;
                    &lt;asp:ListItem Value=&quot;0&quot;&gt;---SELECT---&lt;/asp:ListItem&gt;
                &lt;/asp:DropDownList&gt;
            &lt;/FooterTemplate&gt;
        &lt;/asp:TemplateField&gt;

        &lt;asp:TemplateField HeaderText=&quot;Part Cost Requested&quot; ItemStyle-HorizontalAlign=&quot;center&quot; HeaderStyle-Width=&quot;100px&quot;&gt;
            &lt;ItemTemplate&gt;
                &lt;asp:label ID=&quot;lblUnitPrice&quot; Text='&lt;%# Bind(&quot;PartCost&quot;, &quot;{0:C}&quot;) %&gt;' runat=&quot;server&quot; Enabled=&quot;False&quot;/&gt;
            &lt;/ItemTemplate&gt;
            &lt;EditItemTemplate&gt;
                &lt;asp:textbox ID=&quot;txtUnitPriceEdit&quot; Text='&lt;%# Bind(&quot;PartCost&quot;) %&gt;' Enabled=&quot;true&quot; runat=&quot;server&quot;/&gt;
            &lt;/EditItemTemplate&gt;
            &lt;FooterTemplate&gt;
                &lt;asp:textbox ID=&quot;txtUnitPriceInsert&quot; Text='&lt;%# Bind(&quot;PartCost&quot;) %&gt;' runat=&quot;server&quot; style=&quot;width: 100%; box-sizing: border-box;&quot;/&gt;
            &lt;/FooterTemplate&gt;
        &lt;/asp:TemplateField&gt;

        &lt;asp:TemplateField HeaderText=&quot;Tax&quot; ItemStyle-HorizontalAlign=&quot;Center&quot; HeaderStyle-Width=&quot;100px&quot;&gt;
            &lt;ItemTemplate&gt;
                &lt;asp:LinkButton ID=&quot;lbTaxTotal&quot; Text='&lt;%# Bind(&quot;Tax&quot;, &quot;{0:C}&quot;)%&gt;' runat=&quot;server&quot; CommandArgument=&quot;Part&quot; OnClick=&quot;lblTaxTotal_Click&quot;/&gt;
                &lt;asp:HiddenField ID=&quot;hidPartGST&quot; runat=&quot;server&quot; Value='&lt;%# Bind(&quot;GST&quot;)%&gt;' /&gt;
                &lt;asp:HiddenField ID=&quot;hidPartPST&quot; runat=&quot;server&quot; Value='&lt;%# Bind(&quot;PST&quot;)%&gt;' /&gt;
                &lt;asp:HiddenField ID=&quot;hidPartQST&quot; runat=&quot;server&quot; Value='&lt;%# Bind(&quot;QST&quot;)%&gt;' /&gt;
                &lt;asp:HiddenField ID=&quot;hidPartHST&quot; runat=&quot;server&quot; Value='&lt;%# Bind(&quot;HST&quot;)%&gt;' /&gt;
            &lt;/ItemTemplate&gt;
            &lt;EditItemTemplate&gt;
                &lt;asp:textbox ID=&quot;lblTaxTotalEdit&quot; Text='&lt;%# Bind(&quot;Tax&quot;)%&gt;' Enabled=&quot;true&quot; runat=&quot;server&quot;/&gt;
            &lt;/EditItemTemplate&gt;
            &lt;FooterTemplate&gt;
                &lt;asp:textbox ID=&quot;txtTaxTotalInsert&quot; Text=&quot;0&quot; runat=&quot;server&quot; Enabled=&quot;true&quot; style=&quot;width: 100%; box-sizing: border-box;&quot;/&gt;
            &lt;/FooterTemplate&gt;
        &lt;/asp:TemplateField&gt;

        &lt;asp:TemplateField HeaderText=&quot;Insert New&quot; HeaderStyle-Width=&quot;85px&quot;&gt;
            &lt;ItemTemplate&gt;
                &lt;asp:Label ID=&quot;lblEmpty&quot; Text=&quot;&quot; runat=&quot;server&quot; Width=&quot;75px&quot;/&gt;
            &lt;/ItemTemplate&gt;
            &lt;FooterTemplate&gt;
                &lt;asp:Button ID=&quot;Insert&quot; runat=&quot;server&quot; CommandName=&quot;InsertNewDetail&quot; Height=&quot;22px&quot; Text=&quot;Insert&quot; style=&quot;width: 100%; box-sizing: border-box;&quot; /&gt;
            &lt;/FooterTemplate&gt;
        &lt;/asp:TemplateField&gt;
        &lt;/Columns&gt;
        &lt;HeaderStyle BackColor=&quot;#336699&quot; ForeColor=&quot;White&quot; /&gt;
    &lt;/asp:GridView&gt;
</code></pre>
<p>In order to populate the drop down list I have associated it with an asp:SqlDataSource control below.</p>
<pre><code>&lt;asp:SqlDataSource ID=&quot;SqlDataSourcePartEquipment&quot; runat=&quot;server&quot; ConnectionString=&quot;&lt;%$ ConnectionStrings:WarrantyConnectionString %&gt;&quot; 
    SelectCommand=&quot;SELECT EquipmentType FROM Equipment WHERE Agreement = @Agreement&quot;&gt;
&lt;/asp:SqlDataSource&gt;
</code></pre>
<p>In the vb.net code behind I have declared the parameter in the page load event as seen below</p>
<pre><code>Protected Sub Page_Load(ByVal sender As Object, ByVal e As System.EventArgs) Handles Me.Load
    'Decrypt et get params
    MaintainScrollPositionOnPostBack = True
    hashtableParams = RedirectionHandler.EncryptedRequest(Request.QueryString(&quot;data&quot;))
    'SqlDataSourcePartEquipment.SelectParameters.Add(&quot;@Agreement&quot;, hashtableParams(&quot;agreementNumber&quot;))
    'If Page.IsPostBack Then
    'Dim wcICausedPostBack As WebControl = CType(GetControlThatCausedPostBack(TryCast(sender, Page)), WebControl)
    'Dim indx As Integer = wcICausedPostBack.TabIndex
    'Dim ctrl = _
    'From control In wcICausedPostBack.Parent.Controls.OfType(Of WebControl)() _
    'Where control.TabIndex &gt; indx _
    'Select control
    'ctrl.DefaultIfEmpty(wcICausedPostBack).First().Focus()
    'End If

    'Dim SClaimID As String = CType(Session.Item(&quot;SClaimID&quot;), String)
    If Not IsPostBack Then
        Dim agreement As String = hashtableParams(&quot;agreementNumber&quot;)
        Dim claimID As String

        If hashtableParams.Count &gt; 0 AndAlso Not IsNothing(hashtableParams(&quot;claimID&quot;)) Then
            claimID = hashtableParams(&quot;claimID&quot;)
            Session(&quot;ClaimID&quot;) = claimID
        Else
            claimID = CType(Session.Item(&quot;ClaimID&quot;), String)
        End If

        Me.txtAgreement.Text = agreement
        Me.txtOtherInvoice.Text = &quot;I'm Working&quot;

        If Not String.IsNullOrEmpty(claimID) Then
            objCn.Open()
            objSelectCmd.Connection = objCn
            objSelectCmd.CommandText = &quot;Select * From Claim Where ClaimNumber = @ClaimID&quot;
            objSelectCmd.Parameters.Add(&quot;ClaimID&quot;, SqlDbType.Int).Value = claimID

            objSelectCmd.Connection = objCn
            objDa.SelectCommand = objSelectCmd
            objDa.Fill(objDs, &quot;Claim&quot;)
            objDataTable = objDs.Tables(&quot;Claim&quot;)
            objCurrentRow = objDataTable.Rows(0)
            Me.txtAgreement.Text = objCurrentRow(&quot;Agreement&quot;).ToString
            Me.txtServicerNumber.Text = objCurrentRow(&quot;AccountNumber&quot;).ToString
            'Me.txtCNumber.Text = objCurrentRow(&quot;AccountNumber&quot;).ToString
            Me.lblClaimNumber.Text = objCurrentRow(&quot;ClaimNumber&quot;).ToString
            lblCreationDate.Text = Convert.ToDateTime(objCurrentRow(&quot;CreateDate&quot;).ToString).ToShortDateString
            Me.txtProblem.Text = objCurrentRow(&quot;ProblemDescription&quot;).ToString
            Me.txtSubmitDate.Text = Convert.ToDateTime(objCurrentRow(&quot;ReceivedDate&quot;).ToString).ToShortDateString
            Me.txtWorkPerformed.Text = objCurrentRow(&quot;WorkPerformed&quot;).ToString
            Me.txtServiceDate.Text = Convert.ToDateTime(objCurrentRow(&quot;FailDate&quot;).ToString).ToShortDateString
            Me.txtWorkInvoice.Text = objCurrentRow(&quot;WorkInvoice&quot;).ToString
            Me.txtOtherInvoice.Text = objCurrentRow(&quot;OtherInvoice&quot;).ToString
            Me.lblClaimStatus.Text = objCurrentRow(&quot;Status&quot;).ToString
            SqlDataSourcePartEquipment.SelectParameters.Add(&quot;@Agreement&quot;, hashtableParams(agreementNumber))
</code></pre>
<p>(There is much more code in the Page_load() event, and if required I can supply it)
When I execute this code and navigate to the web form in question I receive an exception error &quot;Must declare the scalar variable &quot;@Agreement&quot;. To my knowledge I am declaring the @Agreement variable in the last line of what I posted of the Page_Load event. I have also used the &quot;agreement&quot; variable seen earlier in the page load event and when I use that, I don't receive the exception error but my drop down still isn't populated.</p>
<p>Whats confusing me so much is that every variable or control that stores the value I need for my parameter either populates nothing to my drop down or I receive the exception mentioned above.</p>
<p>If anyone has an idea as to why this could be happening I would greatly appreciate some input here as I am at a loss as to what to do.</p>
",74,1,0,4,asp.net;sql-server;vb.net;gridview,2022-08-02 20:48:34,2022-08-02 20:48:34,2022-08-07 05:29:15,as the title states i am currently having trouble populating a drop down list that is contained within a gridview  at first glance this seems like a relatively simple problem and i have populated many gridviews and many drop down lists in the past  however this one is being a real pain  i am relatively new to software development so any  help regarding this issue regardless of simplicity would be greatly appreciated  below i have detailed the problem more explicitly and copied any relevant code  if there is anything i have missed i would be more than happy to supply it  as stated before i have a drop down list  ddlpartequipmentnew  within a gridview control  gridview   so far there is one item in the ddl     select     that i added as a listitem in the aspx page   i am trying to populate the gridview with data from my database that corresponds to a value that is currently stored in a variable on the page  i have tested my query and can confirm that it returns the appropriate values in ssms and it looks like select equipmenttype from equipment where agreement    agreement below i have posted the aspx code of the gridview and drop down  in order to populate the drop down list i have associated it with an asp sqldatasource control below  in the vb net code behind i have declared the parameter in the page load event as seen below whats confusing me so much is that every variable or control that stores the value i need for my parameter either populates nothing to my drop down or i receive the exception mentioned above  if anyone has an idea as to why this could be happening i would greatly appreciate some input here as i am at a loss as to what to do ,having trouble populating a drop down list within a gridview
58,12073621,57960603,E: Unable to locate package openjdk-11-jdk,"<p>I try to create docker image:</p>
<p>It is my Dockerfile:</p>
<pre><code>FROM maven:3-jdk-11

# Common files and utils for build
RUN apt-get update &amp;&amp; apt-get install -y make fakeroot rpm dpkg-dev apt-utils wget unzip
RUN apt-get install -y -q software-properties-common desktop-file-utils

# Then Wine with all deps
RUN dpkg --add-architecture i386 &amp;&amp; apt-get update
RUN apt-get install -y --install-recommends wine
RUN apt-cache search openjdk
RUN apt-get install -y openjdk-11-jdk
RUN apt install -y openjfx11 libopenjfx-java libopenjfx-jni
RUN apt-get install -y --install-recommends wine32

ENV JAVA_HOME /usr/lib/jvm/java-11-openjdk-amd64
ENV JAVAFX_HOME /usr/share/java/openjfx11

# And we ready to play with our code
ARG SRCDIR=.
ARG DSTDIR=/usr/src/CryptoStock
ARG CACHEDIR=./cache

# Subject to be used here but should be command line, sic!
# ADD ${CACHEDIR} /root/.m2
# ADD ${SRCDIR} /mnt/src

RUN mkdir -p /root/.m2/repository
COPY settings.xml /root/.m2/settings.xml
COPY settings-security.xml /root/.m2/settings-security.xml
COPY jdk11-build-in-docker.sh ${DSTDIR}/jdk11-build-in-docker.sh

COPY ./static/. ${DSTDIR}/static
COPY ./3rdparty/. ${DSTDIR}/3rdparty
COPY ./winjdk11/. ${DSTDIR}/winjdk

ENV SOURCES /usr/src/CryptoStock
ENV OUTSIDE /mnt/src

RUN dpkg -l '*openjfx*'
RUN dpkg -l '*jdk*'

WORKDIR ${DSTDIR}

CMD [ &quot;sh&quot;, &quot;/usr/src/CryptoStock/jdk11-build-in-docker.sh&quot; ]
</code></pre>
<p>When I try to build I don't to watch java 11:</p>
<pre><code>Step 6/27 : RUN apt-cache search openjdk
 ---&gt; Running in e03b4c69fa69
jtreg - Regression Test Harness for the OpenJDK platform
openjdk-8-dbg - Java runtime based on OpenJDK (debugging symbols)
openjdk-8-demo - Java runtime based on OpenJDK (demos and examples)
openjdk-8-doc - OpenJDK Development Kit (JDK) documentation
openjdk-8-jdk - OpenJDK Development Kit (JDK)
openjdk-8-jdk-headless - OpenJDK Development Kit (JDK) (headless)
openjdk-8-jre - OpenJDK Java runtime, using Hotspot JIT
openjdk-8-jre-headless - OpenJDK Java runtime, using Hotspot JIT (headless)
openjdk-8-jre-zero - Alternative JVM for OpenJDK, using Zero/Shark
openjdk-8-source - OpenJDK Development Kit (JDK) source files
openjdk-8-jre-dcevm - Alternative VM for OpenJDK 8 with enhanced class redefinition
uwsgi-plugin-jvm-openjdk-8 - Java plugin for uWSGI (OpenJDK 8)
uwsgi-plugin-jwsgi-openjdk-8 - JWSGI plugin for uWSGI (OpenJDK 8)
uwsgi-plugin-ring-openjdk-8 - Closure/Ring plugin for uWSGI (OpenJDK 8)
uwsgi-plugin-servlet-openjdk-8 - JWSGI plugin for uWSGI (OpenJDK 8)
Removing intermediate container e03b4c69fa69
 ---&gt; 1fae3b35c58b
Step 7/27 : RUN apt-get install -y openjdk-11-jdk
 ---&gt; Running in 288fb5247ce6
Reading package lists...
Building dependency tree...
Reading state information...
E: Unable to locate package openjdk-11-jdk
The command '/bin/sh -c apt-get install -y openjdk-11-jdk' returned a non-zero code: 100
</code></pre>
<p>There is only java 8, there is no java 11.</p>
",12806,1,6,4,maven;docker;debian;java-11,2019-09-16 19:01:59,2019-09-16 19:01:59,2022-08-06 11:15:16,i try to create docker image  it is my dockerfile  when i try to build i don t to watch java   there is only java   there is no java  ,e  unable to locate package openjdk  jdk
59,13058445,73236850,How do I solve Cake is NOT able to connect to the database on IIS Server running CakePHP 1.3.17,"<p>I have setup the CakePHP framework version 1.3.17 on IIS server precisely IIS version 10.0.19041.1
all is well, as i can see the index.php page, however it is not able to connect to a MYSQL 8 database, see  database.php configuration settings. How do i check to see what the actual error is and also how do I resolve the connection issue</p>
<pre><code>&lt;?php
/**
 * This is core configuration file.
 *
 * Use it to configure core behaviour ofCake.
 *
 * PHP versions 4 and 5
 *
 * CakePHP(tm) : Rapid Development Framework (http://cakephp.org)
 * Copyright 2005-2012, Cake Software Foundation, Inc. (http://cakefoundation.org)
 *
 * Licensed under The MIT License
 * Redistributions of files must retain the above copyright notice.
 *
 * @copyright     Copyright 2005-2012, Cake Software Foundation, Inc. (http://cakefoundation.org)
 * @link          http://cakephp.org CakePHP(tm) Project
 * @package       cake
 * @subpackage    cake.app.config
 * @since         CakePHP(tm) v 0.2.9
 * @license       MIT License (http://www.opensource.org/licenses/mit-license.php)
 */
/**
 * In this file you set up your database connection details.
 *
 * @package       cake
 * @subpackage    cake.config
 */
/**
 * Database configuration class.
 * You can specify multiple configurations for production, development and testing.
 *
 * driver =&gt; The name of a supported driver; valid options are as follows:
 *      mysql       - MySQL 4 &amp; 5,
 *      mysqli      - MySQL 4 &amp; 5 Improved Interface (PHP5 only),
 *      sqlite      - SQLite (PHP5 only),
 *      postgres    - PostgreSQL 7 and higher,
 *      mssql       - Microsoft SQL Server 2000 and higher,
 *      db2         - IBM DB2, Cloudscape, and Apache Derby (http://php.net/ibm-db2)
 *      oracle      - Oracle 8 and higher
 *      firebird    - Firebird/Interbase
 *      sybase      - Sybase ASE
 *      adodb-[drivername]  - ADOdb interface wrapper (see below),
 *      odbc        - ODBC DBO driver
 *
 * You can add custom database drivers (or override existing drivers) by adding the
 * appropriate file to app/models/datasources/dbo.  Drivers should be named 'dbo_x.php',
 * where 'x' is the name of the database.
 *
 * persistent =&gt; true / false
 * Determines whether or not the database should use a persistent connection
 *
 * connect =&gt;
 * ADOdb set the connect to one of these
 *  (http://phplens.com/adodb/supported.databases.html) and
 *  append it '|p' for persistent connection. (mssql|p for example, or just mssql for not persistent)
 * For all other databases, this setting is deprecated.
 *
 * host =&gt;
 * the host you connect to the database.  To add a socket or port number, use 'port' =&gt; #
 *
 * prefix =&gt;
 * Uses the given prefix for all the tables in this database.  This setting can be overridden
 * on a per-table basis with the Model::$tablePrefix property.
 *
 * schema =&gt;
 * For Postgres and DB2, specifies which schema you would like to use the tables in. Postgres defaults to
 * 'public', DB2 defaults to empty.
 *
 * encoding =&gt;
 * For MySQL, MySQLi, Postgres and DB2, specifies the character encoding to use when connecting to the
 * database.  Uses database default.
 *
 */
class DATABASE_CONFIG {

    var $default = array(
        'driver' =&gt; 'mysql',
        'persistent' =&gt; false,
        'host' =&gt; 'localhost',
        'port' =&gt; '3306',
        'login' =&gt; 'username',
        'password' =&gt; 'mypassword',
        'database' =&gt; 'mydatabasename',
        'prefix' =&gt; '',
        'cacheMetadata' =&gt; false,
        'encoding' =&gt; 'utf8'
    );
}
</code></pre>
<p>Here's a print screen of what is displayed, when the application is accessed on a browser via http://localhost</p>
<p><a href=""https://i.stack.imgur.com/k5CEk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/k5CEk.png"" alt=""enter image description here"" /></a></p>
",54,1,2,5,php;mysql;iis;cakephp;cakephp-1.3,2022-08-04 16:29:13,2022-08-04 16:29:13,2022-08-05 14:33:38,here s a print screen of what is displayed  when the application is accessed on a browser via http   localhost ,how do i solve cake is not able to connect to the database on iis server running cakephp   
60,4450471,73239705,The controller for path &#39;xxx&#39; was not found or does not implement IController,"<p>My company has a web application that implements both OData (System.Data.Services.DataService) and WebAPI endpoints to allow another application to communicate with it. We have one customer who recently upgraded a working system to the latest release and started having problems with the OData part of the interface, where the WebAPI endpoints are working just fine. Their system is using HTTP. We have many other customers running the same version of the software without issue, so I believe there is some system configuration issue on the customer's server that is causing the issue, but I have been unable to figure out what it is. The exception occurs in the server's code:</p>
<pre><code>Message=The controller for path '/RemoteDataService.svc/Users()' was not found or does not implement IController.
Relative Path=/RemoteDataService.svc/Users()?$filter=((lDeleted%20eq%200)%20and%20(lActive%20ne%200))%20and%20(nUserUID%20eq%20guid'915f9722-3175-4e4d-a571-4a478e8e5172')&amp;$top=1&amp;$select=cFirstName,cLastName
Source=System.Web.Mvc
Stack=   at System.Web.Mvc.DefaultControllerFactory.GetControllerInstance(RequestContext requestContext, Type controllerType) at System.Web.Mvc.MvcHandler.ProcessRequestInit(HttpContextBase httpContext, IController&amp; controller, IControllerFactory&amp; factory) at System.Web.Mvc.MvcHandler.BeginProcessRequest(HttpContextBase httpContext, AsyncCallback callback, Object state) at System.Web.HttpApplication.CallHandlerExecutionStep.System.Web.HttpApplication.IExecutionStep.Execute() at System.Web.HttpApplication.ExecuteStepImpl(IExecutionStep step) at System.Web.HttpApplication.ExecuteStep(IExecutionStep step, Boolean&amp; completedSynchronously)
</code></pre>
<p>Since this application works on literally hundreds of other systems, it is not a matter of a wrong namespace, or misspelled controller name, or failure to implement an interface as I have seen other posts suggest regarding apps under development. So my question is, are there settings in IIS or the file system or network or somewhere else that could potentially cause this exception to occur? Any guidance would be appreciated!</p>
",52,1,1,3,iis;odata;wcf-data-services,2022-08-04 19:57:25,2022-08-04 19:57:25,2022-08-05 10:21:54,my company has a web application that implements both odata  system data services dataservice  and webapi endpoints to allow another application to communicate with it  we have one customer who recently upgraded a working system to the latest release and started having problems with the odata part of the interface  where the webapi endpoints are working just fine  their system is using http  we have many other customers running the same version of the software without issue  so i believe there is some system configuration issue on the customer s server that is causing the issue  but i have been unable to figure out what it is  the exception occurs in the server s code  since this application works on literally hundreds of other systems  it is not a matter of a wrong namespace  or misspelled controller name  or failure to implement an interface as i have seen other posts suggest regarding apps under development  so my question is  are there settings in iis or the file system or network or somewhere else that could potentially cause this exception to occur  any guidance would be appreciated ,the controller for path    xxx    was not found or does not implement icontroller
61,5403466,73241555,Including sysinfoapi.h or fileapi.h causes &quot;No Target Architecture&quot; errors?,"<p>I have a project that compiles fine under MSYS/Mingw. However, it fails under Visual Studio.</p>
<p>If I try to include the either <code>sysinfoapi.h</code> or <code>fileapi.h</code> I get a slew of errors in Visual Studio. No such errors occur in MSYS.</p>
<p><a href=""https://i.stack.imgur.com/m59nd.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/m59nd.png"" alt=""An image of the errors"" /></a></p>
<p>I do have two copies of the Windows Software Development Kit, versions 10.1.22000.194 and 10.1.17763.132 both installed. (Some forums discussing the topic mention missing SDK can cause similar issues)</p>
",33,0,0,2,windows;visual-studio,2022-08-04 22:50:31,2022-08-04 22:50:31,2022-08-04 22:50:31,i have a project that compiles fine under msys mingw  however  it fails under visual studio  if i try to include the either sysinfoapi h or fileapi h i get a slew of errors in visual studio  no such errors occur in msys   i do have two copies of the windows software development kit  versions     and     both installed   some forums discussing the topic mention missing sdk can cause similar issues ,including sysinfoapi h or fileapi h causes  no target architecture  errors 
62,5800969,73206830,docker.errors.DockerException: Error while fetching server API version or Permission denied error,"<p>I am exploring <a href=""https://marclamberti.com/blog/how-to-use-dockeroperator-apache-airflow/"" rel=""nofollow noreferrer"">How to use the DockerOperator in Apache Airflow</a> tutorial. I have managed to set up airflow using docker-compose and able to access the <code>docker_dag</code> mentioned in the tutorial in my airflow browser. Here is the code for same.</p>
<pre><code>from airflow import DAG
from airflow.operators.bash_operator import BashOperator
from datetime import datetime, timedelta
from airflow.operators.docker_operator import DockerOperator
default_args = {
'owner'                 : 'airflow',
'description'           : 'Use of the DockerOperator',
'depend_on_past'        : False,
'start_date'            : datetime(2018, 1, 3),
'email_on_failure'      : False,
'email_on_retry'        : False,
'retries'               : 1,
'retry_delay'           : timedelta(minutes=5)
}
with DAG('docker_dag', default_args=default_args, schedule_interval=&quot;5 * * * *&quot;, catchup=False) as dag:
    t1 = BashOperator(
    task_id='print_current_date',
    bash_command='date'
    )
    t2 = DockerOperator(
    task_id='docker_command',
    image='centos:latest',
    api_version='auto',
    auto_remove=True,
    command=&quot;/bin/sleep 30&quot;,
    docker_url=&quot;unix://var/run/docker.sock&quot;,
    network_mode=&quot;bridge&quot;
    )
    t3 = BashOperator(
    task_id='print_hello',
    bash_command='echo &quot;hello world&quot;'
    )
    t1 &gt;&gt; t2 &gt;&gt; t3
</code></pre>
<p>I am getting error while executing tast t2 (DockerOperator) below.</p>
<pre><code>Traceback (most recent call last):
  File &quot;/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py&quot;, line 366, in execute
    self.cli = self._get_cli()
  File &quot;/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py&quot;, line 397, in _get_cli
    base_url=self.docker_url, version=self.api_version, tls=tls_config, timeout=self.timeout
  File &quot;/home/airflow/.local/lib/python3.7/site-packages/docker/api/client.py&quot;, line 197, in __init__
    self._version = self._retrieve_server_version()
  File &quot;/home/airflow/.local/lib/python3.7/site-packages/docker/api/client.py&quot;, line 222, in _retrieve_server_version
    f'Error while fetching server API version: {e}'
docker.errors.DockerException: Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))
[2022-08-02, 09:02:50 UTC] {taskinstance.py:1420} INFO - Marking task as FAILED. dag_id=docker_dag, task_id=docker_command, execution_date=20220802T085747, start_date=20220802T090250, end_date=20220802T090250
[2022-08-02, 09:02:50 UTC] {standard_task_runner.py:97} ERROR - Failed to execute job 78 for task docker_command (Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory')); 2516)
</code></pre>
<p>I tried many answer on github issues list and stackover like changing the  docker.sock file permission, restarting the docker and rebuilding docker images to run in new containers.</p>
<p>Sharing docker-compose file for the reference:</p>
<pre><code># Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# &quot;License&quot;); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#

# Basic Airflow cluster configuration for CeleryExecutor with Redis and PostgreSQL.
#
# WARNING: This configuration is for local development. Do not use it in a production deployment.
#
# This configuration supports basic configuration using environment variables or an .env file
# The following variables are supported:
#
# AIRFLOW_IMAGE_NAME           - Docker image name used to run Airflow.
#                                Default: apache/airflow:2.3.3
# AIRFLOW_UID                  - User ID in Airflow containers
#                                Default: 50000
# Those configurations are useful mostly in case of standalone testing/running Airflow in test/try-out mode
#
# _AIRFLOW_WWW_USER_USERNAME   - Username for the administrator account (if requested).
#                                Default: airflow
# _AIRFLOW_WWW_USER_PASSWORD   - Password for the administrator account (if requested).
#                                Default: airflow
# _PIP_ADDITIONAL_REQUIREMENTS - Additional PIP requirements to add when starting all containers.
#                                Default: ''
#
# Feel free to modify this file to suit your needs.
---
version: '3'
x-airflow-common:
  &amp;airflow-common
  # In order to add custom dependencies or upgrade provider packages you can use your extended image.
  # Comment the image line, place your Dockerfile in the directory where you placed the docker-compose.yaml
  # and uncomment the &quot;build&quot; line below, Then run `docker-compose build` to build the images.
  image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:2.3.3}
  # build: .
  environment:
    &amp;airflow-common-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    # For backward compatibility, with Airflow &lt;2.3
    # AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    # AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
    # AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
    AIRFLOW__CORE__FERNET_KEY: ''
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'true'
    AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth'
    _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
  user: &quot;${AIRFLOW_UID:-50000}:0&quot;
  depends_on:
    &amp;airflow-common-depends-on
    # redis:
    #   condition: service_healthy
    postgres:
      condition: service_healthy

services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: [&quot;CMD&quot;, &quot;pg_isready&quot;, &quot;-U&quot;, &quot;airflow&quot;]
      interval: 5s
      retries: 5
    restart: always

  # redis:
  #   image: redis:latest
  #   expose:
  #     - 6379
  #   healthcheck:
  #     test: [&quot;CMD&quot;, &quot;redis-cli&quot;, &quot;ping&quot;]
  #     interval: 5s
  #     timeout: 30s
  #     retries: 50
  #   restart: always

  airflow-webserver:
    &lt;&lt;: *airflow-common
    command: webserver
    ports:
      - 8080:8080
    healthcheck:
      test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;--fail&quot;, &quot;http://localhost:8080/health&quot;]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
    depends_on:
      &lt;&lt;: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-scheduler:
    &lt;&lt;: *airflow-common
    command: scheduler
    healthcheck:
      test: [&quot;CMD-SHELL&quot;, 'airflow jobs check --job-type SchedulerJob --hostname &quot;$${HOSTNAME}&quot;']
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
    depends_on:
      &lt;&lt;: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  # airflow-worker:
  #   &lt;&lt;: *airflow-common
  #   command: celery worker
  #   healthcheck:
  #     test:
  #       - &quot;CMD-SHELL&quot;
  #       - 'celery --app airflow.executors.celery_executor.app inspect ping -d &quot;celery@$${HOSTNAME}&quot;'
  #     interval: 10s
  #     timeout: 10s
  #     retries: 5
  #   environment:
  #     &lt;&lt;: *airflow-common-env
  #     # Required to handle warm shutdown of the celery workers properly
  #     # See https://airflow.apache.org/docs/docker-stack/entrypoint.html#signal-propagation
  #     DUMB_INIT_SETSID: &quot;0&quot;
  #   restart: always
  #   depends_on:
  #     &lt;&lt;: *airflow-common-depends-on
  #     airflow-init:
  #       condition: service_completed_successfully

  airflow-triggerer:
    &lt;&lt;: *airflow-common
    command: triggerer
    healthcheck:
      test: [&quot;CMD-SHELL&quot;, 'airflow jobs check --job-type TriggererJob --hostname &quot;$${HOSTNAME}&quot;']
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
    depends_on:
      &lt;&lt;: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-init:
    &lt;&lt;: *airflow-common
    entrypoint: /bin/bash
    # yamllint disable rule:line-length
    command:
      - -c
      - |
        function ver() {
          printf &quot;%04d%04d%04d%04d&quot; $${1//./ }
        }
        airflow_version=$$(AIRFLOW__LOGGING__LOGGING_LEVEL=INFO &amp;&amp; gosu airflow airflow version)
        airflow_version_comparable=$$(ver $${airflow_version})
        min_airflow_version=2.2.0
        min_airflow_version_comparable=$$(ver $${min_airflow_version})
        if (( airflow_version_comparable &lt; min_airflow_version_comparable )); then
          echo
          echo -e &quot;\033[1;31mERROR!!!: Too old Airflow version $${airflow_version}!\e[0m&quot;
          echo &quot;The minimum Airflow version supported: $${min_airflow_version}. Only use this or higher!&quot;
          echo
          exit 1
        fi
        if [[ -z &quot;${AIRFLOW_UID}&quot; ]]; then
          echo
          echo -e &quot;\033[1;33mWARNING!!!: AIRFLOW_UID not set!\e[0m&quot;
          echo &quot;If you are on Linux, you SHOULD follow the instructions below to set &quot;
          echo &quot;AIRFLOW_UID environment variable, otherwise files will be owned by root.&quot;
          echo &quot;For other operating systems you can get rid of the warning with manually created .env file:&quot;
          echo &quot;    See: https://airflow.apache.org/docs/apache-airflow/stable/start/docker.html#setting-the-right-airflow-user&quot;
          echo
        fi
        one_meg=1048576
        mem_available=$$(($$(getconf _PHYS_PAGES) * $$(getconf PAGE_SIZE) / one_meg))
        cpus_available=$$(grep -cE 'cpu[0-9]+' /proc/stat)
        disk_available=$$(df / | tail -1 | awk '{print $$4}')
        warning_resources=&quot;false&quot;
        if (( mem_available &lt; 4000 )) ; then
          echo
          echo -e &quot;\033[1;33mWARNING!!!: Not enough memory available for Docker.\e[0m&quot;
          echo &quot;At least 4GB of memory required. You have $$(numfmt --to iec $$((mem_available * one_meg)))&quot;
          echo
          warning_resources=&quot;true&quot;
        fi
        if (( cpus_available &lt; 2 )); then
          echo
          echo -e &quot;\033[1;33mWARNING!!!: Not enough CPUS available for Docker.\e[0m&quot;
          echo &quot;At least 2 CPUs recommended. You have $${cpus_available}&quot;
          echo
          warning_resources=&quot;true&quot;
        fi
        if (( disk_available &lt; one_meg * 10 )); then
          echo
          echo -e &quot;\033[1;33mWARNING!!!: Not enough Disk space available for Docker.\e[0m&quot;
          echo &quot;At least 10 GBs recommended. You have $$(numfmt --to iec $$((disk_available * 1024 )))&quot;
          echo
          warning_resources=&quot;true&quot;
        fi
        if [[ $${warning_resources} == &quot;true&quot; ]]; then
          echo
          echo -e &quot;\033[1;33mWARNING!!!: You have not enough resources to run Airflow (see above)!\e[0m&quot;
          echo &quot;Please follow the instructions to increase amount of resources available:&quot;
          echo &quot;   https://airflow.apache.org/docs/apache-airflow/stable/start/docker.html#before-you-begin&quot;
          echo
        fi
        mkdir -p /sources/logs /sources/dags /sources/plugins
        chown -R &quot;${AIRFLOW_UID}:0&quot; /sources/{logs,dags,plugins}
        exec /entrypoint airflow version
    # yamllint enable rule:line-length
    environment:
      &lt;&lt;: *airflow-common-env
      _AIRFLOW_DB_UPGRADE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}
      _PIP_ADDITIONAL_REQUIREMENTS: ''
    user: &quot;0:0&quot;
    volumes:
      - .:/sources

  airflow-cli:
    &lt;&lt;: *airflow-common
    profiles:
      - debug
    environment:
      &lt;&lt;: *airflow-common-env
      CONNECTION_CHECK_MAX_COUNT: &quot;0&quot;
    # Workaround for entrypoint issue. See: https://github.com/apache/airflow/issues/16252
    command:
      - bash
      - -c
      - airflow

  # You can enable flower by adding &quot;--profile flower&quot; option e.g. docker-compose --profile flower up
  # or by explicitly targeted on the command line e.g. docker-compose up flower.
  # See: https://docs.docker.com/compose/profiles/
  # flower:
  #   &lt;&lt;: *airflow-common
  #   command: celery flower
  #   profiles:
  #     - flower
  #   ports:
  #     - 5555:5555
  #   healthcheck:
  #     test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;--fail&quot;, &quot;http://localhost:5555/&quot;]
  #     interval: 10s
  #     timeout: 10s
  #     retries: 5
  #   restart: always
  #   depends_on:
  #     &lt;&lt;: *airflow-common-depends-on
  #     airflow-init:
  #       condition: service_completed_successfully

volumes:
  postgres-db-volume:
</code></pre>
<p>Can anyone help me here ?</p>
",117,1,0,4,docker;docker-compose;airflow;dockeroperator,2022-08-02 14:32:37,2022-08-02 14:32:37,2022-08-04 11:54:25,i am exploring  tutorial  i have managed to set up airflow using docker compose and able to access the docker_dag mentioned in the tutorial in my airflow browser  here is the code for same  i am getting error while executing tast t  dockeroperator  below  i tried many answer on github issues list and stackover like changing the  docker sock file permission  restarting the docker and rebuilding docker images to run in new containers  sharing docker compose file for the reference  can anyone help me here  ,docker errors dockerexception  error while fetching server api version or permission denied error
63,5581091,66539450,Does vscode-dev-containers work with non-Docker containers like LXC?,"<p>In the website of visualstudio at the following link:</p>
<p><a href=""https://code.visualstudio.com/docs/remote/remote-overview"" rel=""nofollow noreferrer"">https://code.visualstudio.com/docs/remote/remote-overview</a></p>
<p>the website says that <strong>VS Code Remote Development</strong> can connect in 3 ways:</p>
<ul>
<li>Remote SSH</li>
<li>Remote - Containers</li>
<li>Remote - WSL</li>
</ul>
<p>In the link about <a href=""https://code.visualstudio.com/docs/remote/containers"" rel=""nofollow noreferrer"">Containers</a> the page says:</p>
<blockquote>
<p>Linux: Docker CE/EE 18.06+ and Docker Compose 1.21+. (The Ubuntu snap package is not supported.)</p>
</blockquote>
<p>But also says:</p>
<blockquote>
<p>Other glibc based Linux containers may work if they have needed Linux prerequisites.</p>
</blockquote>
<p>So it is unclear if the extension works with non-Docker containers.</p>
<p>Is it possible to use this extension to develop software inside LXC containers(locally or remotely)?</p>
",752,2,0,3,visual-studio-code;lxc;vscode-remote,2021-03-09 03:18:52,2021-03-09 03:18:52,2022-08-04 08:08:25,in the website of visualstudio at the following link   the website says that vs code remote development can connect in  ways  in the link about  the page says  linux  docker ce ee    and docker compose      the ubuntu snap package is not supported   but also says  other glibc based linux containers may work if they have needed linux prerequisites  so it is unclear if the extension works with non docker containers  is it possible to use this extension to develop software inside lxc containers locally or remotely  ,does vscode dev containers work with non docker containers like lxc 
64,13058445,73223215,How do I resolve Cannot use &#39;Object&#39; as class name as it is reserved in C:\projectfolder\ckphp-demo\cake\libs\object.php on line 33,"<p>In working on a new cakephp application I get the error message Cannot use 'Object' as class name as it is reserved in C:\projectfolder\ckphp-demo\cake\libs\object.php on line 33.</p>
<p>The project is a legacy web application using cakePHP 1.3.17 with php version PHP 7.4.28 on developement server. see below code for object.php</p>
<p>line 33 is where class Object { starts</p>
<pre><code>&lt;?php
/**
 * Object class, allowing __construct and __destruct in PHP4.
 *
 * Also includes methods for logging and the special method RequestAction,
 * to call other Controllers' Actions from anywhere.
 *
 * PHP versions 4 and 5
 *
 * CakePHP(tm) : Rapid Development Framework (http://cakephp.org)
 * Copyright 2005-2012, Cake Software Foundation, Inc. (http://cakefoundation.org)
 *
 * Licensed under The MIT License
 * Redistributions of files must retain the above copyright notice.
 *
 * @copyright     Copyright 2005-2012, Cake Software Foundation, Inc. (http://cakefoundation.org)
 * @link          http://cakephp.org CakePHP(tm) Project
 * @package       cake
 * @subpackage    cake.cake.libs
 * @since         CakePHP(tm) v 0.2.9
 * @license       MIT License (http://www.opensource.org/licenses/mit-license.php)
 */

/**
 * Object class, allowing __construct and __destruct in PHP4.
 *
 * Also includes methods for logging and the special method RequestAction,
 * to call other Controllers' Actions from anywhere.
 *
 * @package cake
 * @subpackage cake.cake.libs
 */
class Object {

/**
 * A hack to support __construct() on PHP 4
 * Hint: descendant classes have no PHP4 class_name() constructors,
 * so this constructor gets called first and calls the top-layer __construct()
 * which (if present) should call parent::__construct()
 *
 * @return Object
 */
    function Object() {
        $args = func_get_args();
        if (method_exists($this, '__destruct')) {
            register_shutdown_function (array(&amp;$this, '__destruct'));
        }
        call_user_func_array(array(&amp;$this, '__construct'), $args);
    }

/**
 * Class constructor, overridden in descendant classes.
 */
    function __construct() {
    }

/**
 * Object-to-string conversion.
 * Each class can override this method as necessary.
 *
 * @return string The name of this class
 * @access public
 */
    function toString() {
        $class = get_class($this);
        return $class;
    }

/**
 * Calls a controller's method from any location. Can be used to connect controllers together
 * or tie plugins into a main application. requestAction can be used to return rendered views
 * or fetch the return value from controller actions.
 *
 * @param mixed $url String or array-based url.
 * @param array $extra if array includes the key &quot;return&quot; it sets the AutoRender to true.
 * @return mixed Boolean true or false on success/failure, or contents
 *    of rendered action if 'return' is set in $extra.
 * @access public
 */
    function requestAction($url, $extra = array()) {
        if (empty($url)) {
            return false;
        }
        if (!class_exists('dispatcher')) {
            require CAKE . 'dispatcher.php';
        }
        if (in_array('return', $extra, true)) {
            $extra = array_merge($extra, array('return' =&gt; 0, 'autoRender' =&gt; 1));
        }
        if (is_array($url) &amp;&amp; !isset($extra['url'])) {
            $extra['url'] = array();
        }
        $params = array_merge(array('autoRender' =&gt; 0, 'return' =&gt; 1, 'bare' =&gt; 1, 'requested' =&gt; 1), $extra);
        $dispatcher = new Dispatcher;
        return $dispatcher-&gt;dispatch($url, $params);
    }

/**
 * Calls a method on this object with the given parameters. Provides an OO wrapper
 * for `call_user_func_array`
 *
 * @param string $method  Name of the method to call
 * @param array $params  Parameter list to use when calling $method
 * @return mixed  Returns the result of the method call
 * @access public
 */
    function dispatchMethod($method, $params = array()) {
        switch (count($params)) {
            case 0:
                return $this-&gt;{$method}();
            case 1:
                return $this-&gt;{$method}($params[0]);
            case 2:
                return $this-&gt;{$method}($params[0], $params[1]);
            case 3:
                return $this-&gt;{$method}($params[0], $params[1], $params[2]);
            case 4:
                return $this-&gt;{$method}($params[0], $params[1], $params[2], $params[3]);
            case 5:
                return $this-&gt;{$method}($params[0], $params[1], $params[2], $params[3], $params[4]);
            default:
                return call_user_func_array(array(&amp;$this, $method), $params);
            break;
        }
    }

/**
 * Stop execution of the current script.  Wraps exit() making 
 * testing easier.
 *
 * @param $status see http://php.net/exit for values
 * @return void
 * @access public
 */
    function _stop($status = 0) {
        exit($status);
    }

/**
 * Convience method to write a message to CakeLog.  See CakeLog::write()
 * for more information on writing to logs.
 *
 * @param string $msg Log message
 * @param integer $type Error type constant. Defined in app/config/core.php.
 * @return boolean Success of log write
 * @access public
 */
    function log($msg, $type = LOG_ERROR) {
        if (!class_exists('CakeLog')) {
            require LIBS . 'cake_log.php';
        }
        if (!is_string($msg)) {
            $msg = print_r($msg, true);
        }
        return CakeLog::write($type, $msg);
    }

/**
 * Allows setting of multiple properties of the object in a single line of code.  Will only set 
 * properties that are part of a class declaration.
 *
 * @param array $properties An associative array containing properties and corresponding values.
 * @return void
 * @access protected
 */
    function _set($properties = array()) {
        if (is_array($properties) &amp;&amp; !empty($properties)) {
            $vars = get_object_vars($this);
            foreach ($properties as $key =&gt; $val) {
                if (array_key_exists($key, $vars)) {
                    $this-&gt;{$key} = $val;
                }
            }
        }
    }

/**
 * Used to report user friendly errors.
 * If there is a file app/error.php or app/app_error.php this file will be loaded
 * error.php is the AppError class it should extend ErrorHandler class.
 *
 * @param string $method Method to be called in the error class (AppError or ErrorHandler classes)
 * @param array $messages Message that is to be displayed by the error class
 * @return error message
 * @access public
 */
    function cakeError($method, $messages = array()) {
        if (!class_exists('ErrorHandler')) {
            App::import('Core', 'Error');

            if (file_exists(APP . 'error.php')) {
                include_once (APP . 'error.php');
            } elseif (file_exists(APP . 'app_error.php')) {
                include_once (APP . 'app_error.php');
            }
        }

        if (class_exists('AppError')) {
            $error = new AppError($method, $messages);
        } else {
            $error = new ErrorHandler($method, $messages);
        }
        return $error;
    }

/**
 * Checks for a persistent class file, if found file is opened and true returned
 * If file is not found a file is created and false returned
 * If used in other locations of the model you should choose a unique name for the persistent file
 * There are many uses for this method, see manual for examples
 *
 * @param string $name name of the class to persist
 * @param string $object the object to persist
 * @return boolean Success
 * @access protected
 * @todo add examples to manual
 */
    function _persist($name, $return = null, &amp;$object, $type = null) {
        $file = CACHE . 'persistent' . DS . strtolower($name) . '.php';
        if ($return === null) {
            if (!file_exists($file)) {
                return false;
            } else {
                return true;
            }
        }

        if (!file_exists($file)) {
            $this-&gt;_savePersistent($name, $object);
            return false;
        } else {
            $this-&gt;__openPersistent($name, $type);
            return true;
        }
    }

/**
 * You should choose a unique name for the persistent file
 *
 * There are many uses for this method, see manual for examples
 *
 * @param string $name name used for object to cache
 * @param object $object the object to persist
 * @return boolean true on save, throws error if file can not be created
 * @access protected
 */
    function _savePersistent($name, &amp;$object) {
        $file = 'persistent' . DS . strtolower($name) . '.php';
        $objectArray = array(&amp;$object);
        $data = str_replace('\\', '\\\\', serialize($objectArray));
        $data = '&lt;?php $' . $name . ' = \'' . str_replace('\'', '\\\'', $data) . '\' ?&gt;';
        $duration = '+999 days';
        if (Configure::read() &gt;= 1) {
            $duration = '+10 seconds';
        }
        cache($file, $data, $duration);
    }

/**
 * Open the persistent class file for reading
 * Used by Object::_persist()
 *
 * @param string $name Name of persisted class
 * @param string $type Type of persistance (e.g: registry)
 * @return void
 * @access private
 */
    function __openPersistent($name, $type = null) {
        $file = CACHE . 'persistent' . DS . strtolower($name) . '.php';
        include($file);

        switch ($type) {
            case 'registry':
                $vars = unserialize(${$name});
                foreach ($vars['0'] as $key =&gt; $value) {
                    if (strpos($key, '_behavior') !== false) {
                        App::import('Behavior', Inflector::classify(substr($key, 0, -9)));
                    } else {
                        App::import('Model', Inflector::camelize($key));
                    }
                    unset ($value);
                }
                unset($vars);
                $vars = unserialize(${$name});
                foreach ($vars['0'] as $key =&gt; $value) {
                    ClassRegistry::addObject($key, $value);
                    unset ($value);
                }
                unset($vars);
            break;
            default:
                $vars = unserialize(${$name});
                $this-&gt;{$name} = $vars['0'];
                unset($vars);
            break;
        }
    }
}
</code></pre>
",30,0,1,3,php;cakephp;cakephp-1.3,2022-08-03 17:24:36,2022-08-03 17:24:36,2022-08-03 17:24:36,in working on a new cakephp application i get the error message cannot use  object  as class name as it is reserved in c  projectfolder ckphp demo cake libs object php on line   the project is a legacy web application using cakephp    with php version php    on developement server  see below code for object php line  is where class object   starts,how do i resolve cannot use    object    as class name as it is reserved in c  projectfolder ckphp demo cake libs object php on line 
65,5649639,73221194,How to show install directory of a chocolatey installed package?,"<p>How to show install directory of a chocolatey installed package :</p>
<pre><code>&gt; choco info -l pgadmin4
Chocolatey v1.1.0
pgadmin4 6.11
 Title: pgAdmin 4 | Published: 08/07/2022
 Number of Downloads: n/a | Downloads for this version: n/a
 Package url
 Chocolatey Package Source: https://github.com/coldacid/chocolatey-packages/
 Tags: pgadmin4 pgadmin postgres postgresql admin
 Software Site: https://www.pgadmin.org/
 Software License: http://www.pgadmin.org/licence/
 Software Source: https://git.postgresql.org/gitweb/?p=pgadmin4.git
 Mailing List: https://www.pgadmin.org/support/list/
 Issues: https://redmine.postgresql.org/projects/pgadmin4
 Summary: pgAdmin
 Description: pgAdmin is the most popular and feature rich Open Source administration and development platform for PostgreSQL, the most advanced Open Source database in the world.

  pgAdmin is designed to answer the needs of all users, from writing simple SQL queries to developing complex databases. The graphical interface supports all PostgreSQL features and makes administration easy. The application also includes a syntax highlighting SQL editor, a server-side code editor, an SQL/batch/shell job scheduling agent, support for the Slony-I replication engine and much more. Server connection may be made using TCP/IP or Unix Domain Sockets (on *nix platforms), and may be SSL encrypted for security. No additional drivers are required to communicate with the database server.

1 packages installed.
</code></pre>
<p>The application install dir is not shown.</p>
",17,0,0,2,package;chocolatey,2022-08-03 14:47:10,2022-08-03 14:47:10,2022-08-03 14:47:10,how to show install directory of a chocolatey installed package   the application install dir is not shown ,how to show install directory of a chocolatey installed package 
66,8729613,72984923,"STM32F746 - SD Card CRC failing in 4-bit mode, but working fine in 1-bit mode","<p>Recently, I bought a Nucleo-144 development board for the STM32F746. For the project I'm working on, I need to get consistent &gt;3 MB/s write speeds to the SD card. Using STM32CubeIDE, I've been able to get SD 1-bit mode working with FatFS in both polling and DMA modes at full speed. However, switching to SD 4-bit mode, I start getting lots of IO errors relating to bad data CRCs while reading.</p>
<h2>Details</h2>
<p>In SD 4-bit polling mode, I can't even get a single block read to process correctly. Calling <code>f_mount</code> returns an IO error, and debugging it further reveals that the first call to <code>HAL_SD_ReadBlocks</code>, reading sector 0, fails with the error code <code>SDMMC_ERROR_DATA_CRC_FAIL</code>:</p>
<p><a href=""https://i.stack.imgur.com/gpnCO.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/gpnCO.png"" alt=""first read error, including stack trace"" /></a></p>
<p>Inspecting the 512 byte data buffer it's read to from the card reveals that data is at least partially intact containing some strings you'd expect to see in the first sector:</p>
<p><a href=""https://i.stack.imgur.com/PvJac.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/PvJac.png"" alt=""corrupted data buffer"" /></a></p>
<p>Importantly, <strong>this buffer is corrupted in the exact same manner</strong> between each run of the software. If it was some kind of electrical interference problem, I'd expect to see different bytes being corrupted, but I don't. The buffer is identical between runs. Switching back to 1-bit mode and inspecting the data buffer, it's clearly in a lot better shape. The 4-bit buffer clearly has a lot of corrupted bits and bits that are missing entirely, offsetting everything. 4-bit mode is reading mostly junk, but consistently the same junk.</p>
<h2>What I've Tried</h2>
<ol>
<li>Polling and DMA mode.
<ul>
<li>Both fail in a similar manner, although it's harder to debug DMA.</li>
</ul>
</li>
<li>Decreasing the SDMMCCLK clock divider all the way down to 255, the highest divider (and lowest clock speed) it'll go.
<ul>
<li>On my older, cheaper, Lexar SD card read/writes in this mode work flawlessly (albeit very slowly).</li>
<li>On my newer, more expensive, Samsung SD card read/writes still fail with a <code>SDMMC_ERROR_DATA_CRC_FAIL</code> error. The data buffer appears much more intact, but it's clearly still garbage data.</li>
</ul>
</li>
<li>Transfers with GPIO pull-ups applied to all SD pins (except clock) as well as without pull-ups.
<ul>
<li>No change, at least as far as I could tell.</li>
</ul>
</li>
<li>Using multiple different SD cards.
<ul>
<li>Specifically, a Lexar &quot;300x&quot; 32 GB card and a Samsung &quot;EVO Plus&quot; 128 GB card.</li>
<li>As mentioned previously, decreasing the clock speed allowed one of my two cards to work.</li>
<li>However, my higher quality card still fails on the first read even at the minimum speed.</li>
</ul>
</li>
</ol>
<h2>Wiring</h2>
<p>Not sure how relevant this is, but figured I'd include it for sake of completion. This is how I have my SD card connected while prototyping. All of the cables are the same length, but perhaps they're interfering with each other even over such a short distance? I'm also using an Adafruit SD card breakout adapter for testing.</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th><strong>SD Card</strong></th>
<th><strong>GPIO Pin</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>CLK</td>
<td>PC12</td>
</tr>
<tr>
<td>D0</td>
<td>PC8</td>
</tr>
<tr>
<td>CMD</td>
<td>PD2</td>
</tr>
<tr>
<td>D3</td>
<td>PC11</td>
</tr>
<tr>
<td>D1</td>
<td>PC9</td>
</tr>
<tr>
<td>D2</td>
<td>PC10</td>
</tr>
</tbody>
</table>
</div>
<p><a href=""https://i.stack.imgur.com/qmDhI.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qmDhI.jpg"" alt=""SD card connected to microcontroller"" /></a></p>
<h2>Summary</h2>
<p>It appears that with some cards, even at lower clock speeds, IO errors are incredibly common in SD 4-bit mode only. At higher clock speeds, all cards I'm able to test with start having IO errors in 4-bit mode. In SD 1-bit mode, however, even at the maximum clock speed I'm able to read and write fine.</p>
<p>I'd like to take advantage of the 4-bit mode for faster speeds. What am I doing wrong? Is it something electrical, like for example needing stronger pull-up resistors or shorter wires? Thanks, I really appreciate it!</p>
",49,1,2,4,embedded;storage;stm32;hardware,2022-07-14 21:06:34,2022-07-14 21:06:34,2022-08-03 13:34:21,recently  i bought a nucleo  development board for the stmf  for the project i m working on  i need to get consistent  gt  mb s write speeds to the sd card  using stmcubeide  i ve been able to get sd  bit mode working with fatfs in both polling and dma modes at full speed  however  switching to sd  bit mode  i start getting lots of io errors relating to bad data crcs while reading  in sd  bit polling mode  i can t even get a single block read to process correctly  calling f_mount returns an io error  and debugging it further reveals that the first call to hal_sd_readblocks  reading sector   fails with the error code sdmmc_error_data_crc_fail   inspecting the  byte data buffer it s read to from the card reveals that data is at least partially intact containing some strings you d expect to see in the first sector   importantly  this buffer is corrupted in the exact same manner between each run of the software  if it was some kind of electrical interference problem  i d expect to see different bytes being corrupted  but i don t  the buffer is identical between runs  switching back to  bit mode and inspecting the data buffer  it s clearly in a lot better shape  the  bit buffer clearly has a lot of corrupted bits and bits that are missing entirely  offsetting everything   bit mode is reading mostly junk  but consistently the same junk  not sure how relevant this is  but figured i d include it for sake of completion  this is how i have my sd card connected while prototyping  all of the cables are the same length  but perhaps they re interfering with each other even over such a short distance  i m also using an adafruit sd card breakout adapter for testing   it appears that with some cards  even at lower clock speeds  io errors are incredibly common in sd  bit mode only  at higher clock speeds  all cards i m able to test with start having io errors in  bit mode  in sd  bit mode  however  even at the maximum clock speed i m able to read and write fine  i d like to take advantage of the  bit mode for faster speeds  what am i doing wrong  is it something electrical  like for example needing stronger pull up resistors or shorter wires  thanks  i really appreciate it ,stmf   sd card crc failing in  bit mode  but working fine in  bit mode
67,4745249,73218495,web app application service deployed on docker container yields redirected POST curls,"<p>I am a bit new to full-stack web development &amp; networking.</p>
<p>I have built an full-stack application with a PostgreSQL DB interfacing with a restful C++ Backend that is acting as a application server, and a React frontend that interfaces with the backend through POST requests/responses.</p>
<p>Essentially, I've done all my development on some host machine, where it works perfectly, and I am trying to containerize my entire application into one docker container for deployment (I am aware that it could be argued to separate my application into 3 docker containers, one for backend, frontend, and DB, but I want it in ONE docker container). I have been adding to this docker image: <a href=""https://catalog.redhat.com/software/containers/ubi7/ubi/5c3592dcd70cc534b3a37814?container-tabs=overview"" rel=""nofollow noreferrer"">https://catalog.redhat.com/software/containers/ubi7/ubi/5c3592dcd70cc534b3a37814?container-tabs=overview</a></p>
<p>The issue I am running into is that the frontend is not interfacing with the backend within the container. On my host machine, generally I can test if the backend service is working when I perform a curl</p>
<pre><code>curl -X POST -H &quot;Content-Type: application/json&quot; -d @Input.json http://localhost:8080/resource
</code></pre>
<p>Some data, which is the response json, will be printed to stdout on success 100% of the time when running on the host</p>
<p>I've only ever tested my application on the host just via localhost for development, and the C++ backend service I only set options for the port to be at 8080. I am using the restbed library: <a href=""https://github.com/Corvusoft/restbed"" rel=""nofollow noreferrer"">https://github.com/Corvusoft/restbed</a></p>
<p>The backend does not register receiving any requests.</p>
<p>The issue is that performing the curl within the container yields the following:</p>
<pre><code>&lt;HTML&gt;
&lt;HEAD&gt;&lt;TITLE&gt;Redirection&lt;/TITLE&gt;&lt;/HEAD&gt;
&lt;BODY&gt;&lt;H1&gt;Redirect&lt;/H1&gt;&lt;/BODY&gt;
</code></pre>
",11,1,0,5,docker;rest;http;networking;service,2022-08-03 11:22:57,2022-08-03 11:22:57,2022-08-03 11:42:43,i am a bit new to full stack web development  amp  networking  i have built an full stack application with a postgresql db interfacing with a restful c   backend that is acting as a application server  and a react frontend that interfaces with the backend through post requests responses  essentially  i ve done all my development on some host machine  where it works perfectly  and i am trying to containerize my entire application into one docker container for deployment  i am aware that it could be argued to separate my application into  docker containers  one for backend  frontend  and db  but i want it in one docker container   i have been adding to this docker image   the issue i am running into is that the frontend is not interfacing with the backend within the container  on my host machine  generally i can test if the backend service is working when i perform a curl some data  which is the response json  will be printed to stdout on success   of the time when running on the host i ve only ever tested my application on the host just via localhost for development  and the c   backend service i only set options for the port to be at   i am using the restbed library   the backend does not register receiving any requests  the issue is that performing the curl within the container yields the following ,web app application service deployed on docker container yields redirected post curls
68,19631493,73204899,Why does my python script on raspberry pi crash after running for a while?,"<p><a href=""https://i.stack.imgur.com/TZZAf.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/TZZAf.png"" alt=""Last timestamp + syslog"" /></a>Goodmorning everybody!</p>
<p>My name is Joey and I have a serious problem that I can't solve. The problem is that my python script stops running after some hours. To give a little background, I'm building an automatic grow tent to grow house plants like Philodendrons, Syngoniums, Monstera's etc. I'm a mechanical engineering student so I'm very new to python and raspberry. I only worked with arduino for some small projects. So please assume I know nothing and if you can, please explain like you're talking to a child ;)</p>
<p>So there are 5 main components used in the tent:</p>
<ul>
<li>Grow light</li>
<li>Humidifier</li>
<li>Floor heating</li>
<li>Fans</li>
<li>Exhaust fan (refresh air)</li>
</ul>
<p>I'm using a SCD30 seeed sensor for measuring temperature, humidity and CO2.</p>
<p>Now to the coding. The plan was using SSH on the Pi so I could acces it by my laptop. This worked. Then I started writing the code on my laptop with VScode, PIGPIO and the sensor library. This all works as well. In the code I redirect the output to the tent_data.txt where I can see timestamps, temp, humidity, co2 and which devices are on/off in the tent. The idea was putting this data in an grafana dashboard and everything would be good.</p>
<p>Now to the problem! For some reason the code turns off after some hours. It seems pretty random when it does but it seems to be more like after 6-8 hours. So maybe something with memory? I tried ps aux | grep joes_kweektent but it says that it isn&quot;t running anymore. So it doesn't give an error so I don't know where to start. I can also see the timestamps stopping so I know it isn't printing anymore. At the link drive there are two pictures, stoppedhere and syslog. At that moment the code stopped at 0:37 at night, I also screenshotted the syslog. I tried /var/log/messages but it says nothing. I've been searching on the internet for days now for a solution but I can't find any explanation. Maybe there is a voltage drop and it crashes? Maybe the sensor can't read fast enough and it crashes? Maybe the memory is to full (see unable to watch large file picture in link)? Maybe it's something I'm totally unaware of since I'm so new?</p>
<p>I really really really hope someone can help me out! If you ever need help with CAD software or need a part created for you i will help you out! If you live in the Netherlands I can send you a plant or something! :) Thanks in advance everyone!</p>
<p>Links:</p>
<p>Seeed SCD30 sensor: <a href=""https://nl.rs-online.com/web/p/sensor-development-tools/1887076?cm_mmc=NL-PLA-DS3A-_-google-_-CSS_NL_NL_Raspberry_Pi_%26_Arduino_%26_Development_Tools_Whoop-_-(NL:Whoop!)+Sensor+Development+Tools-_-1887076&amp;matchtype=&amp;aud-772940708119:pla-332152890415&amp;gclid=CjwKCAjwlqOXBhBqEiwA-hhitP9bEsrxwcjAy3F_GZi7MO1z3RYx9YcS4o_q_tcqsTvrNEhNVDNG_hoC89cQAvD_BwE&amp;gclsrc=aw.ds"" rel=""nofollow noreferrer"">https://nl.rs-online.com/web/p/sensor-development-tools/1887076?cm_mmc=NL-PLA-DS3A-_-google-_-CSS_NL_NL_Raspberry_Pi_%26_Arduino_%26_Development_Tools_Whoop-_-(NL:Whoop!)+Sensor+Development+Tools-_-1887076&amp;matchtype=&amp;aud-772940708119:pla-332152890415&amp;gclid=CjwKCAjwlqOXBhBqEiwA-hhitP9bEsrxwcjAy3F_GZi7MO1z3RYx9YcS4o_q_tcqsTvrNEhNVDNG_hoC89cQAvD_BwE&amp;gclsrc=aw.ds</a></p>
<p>Code and some pictures:
<a href=""https://drive.google.com/drive/folders/1qbOtcluAanKll6cTUWEDwjfUR-fYzdG2?usp=sharing"" rel=""nofollow noreferrer"">https://drive.google.com/drive/folders/1qbOtcluAanKll6cTUWEDwjfUR-fYzdG2?usp=sharing</a></p>
<pre><code># Imports
import adafruit_scd30
import board
import time
import busio
import datetime
import kweekparameters
import RPi.GPIO as GPIO
import sys



# Setup

# Sensor
i2c = busio.I2C(board.SCL, board.SDA, frequency=50000)
scd = adafruit_scd30.SCD30(board.I2C())

# Opstart-bericht
print (&quot;Joe's Kweektent© by Joey Slager&quot;)
time.sleep(2)

# Hardware pinnen
ventilatorenPin = 5
bevochtigerPin = 16
kweeklichtPin = 20
buisVentilatorPin = 19
vloerVerwarmingPin = 26

# Zet de GPIO op board pin layout
GPIO.setmode(GPIO.BCM)

# Pin setup
GPIO.setup(ventilatorenPin, GPIO.OUT)
GPIO.setup(bevochtigerPin, GPIO.OUT)
GPIO.setup(kweeklichtPin, GPIO.OUT)
GPIO.setup(buisVentilatorPin, GPIO.OUT)
GPIO.setup(vloerVerwarmingPin, GPIO.OUT)

# Dict om de booleans te vertalen naar aan/uit
aan_uit = {True: &quot;Uit&quot;, False: &quot;Aan&quot;}



# Loop

while True:    

    # Huidige tijd
    tijd = datetime.datetime.now()

    # Als er data beschikbaar is print dan de waardes
    if scd.data_available:

        # Aangeven dat data naar tent_data.txt moet
        sys.stdout = open('/home/joeyslager/Joes_Kweektent/tent_data.txt', 'a')

        # Variabelen voor parameters
        temperatuur = scd.temperature
        luchtvochtigheid = scd.relative_humidity
        koolstofDioxide = scd.CO2

        # Prints
        print(&quot;---------------------------------------------&quot;)

        print(f&quot;Tijd:                 {tijd.strftime('%X')}&quot;)
        print(f&quot;Temperatuur:          {temperatuur:0.2f} °C&quot;)
        print(f&quot;Luchtvochtigheid:     {luchtvochtigheid:0.1f}%&quot;)
        print(f&quot;CO2:                  {koolstofDioxide:0.0f} PPM&quot;)

        print(&quot;---------------------------------------------&quot;)
       
        print(f&quot;Kweeklicht:           {aan_uit[GPIO.input(kweeklichtPin)]}&quot;)
        print(f&quot;Bevochtiger:          {aan_uit[GPIO.input(bevochtigerPin)]}&quot;)
        print(f&quot;Ventilatoren:         {aan_uit[GPIO.input(ventilatorenPin)]}&quot;)
        print(f&quot;Buisventilator:       {aan_uit[GPIO.input(buisVentilatorPin)]}&quot;)
        print(f&quot;Vloerverwarming:      {aan_uit[GPIO.input(vloerVerwarmingPin)]}&quot;)
        
        print(&quot;---------------------------------------------&quot;)    

        sys.stdout.close()

    time.sleep(0.5)

    # Test (true = false)
    #GPIO.output(ventilatorenPin, True)
    #GPIO.output(bevochtigerPin, True)
    #GPIO.output(kweeklichtPin, True)
    #GPIO.output(buisVentilatorPin, True)
    #GPIO.output(vloerVerwarmingPin, True)

    # Variabelen voor parameters
    temperatuur = scd.temperature
    luchtvochtigheid = scd.relative_humidity
    koolstofDioxide = scd.CO2
    
    # Kweeklicht
    kweeklichtAan = bool(tijd.hour &gt;= kweekparameters.kweekLichtStart and tijd.hour &lt; kweekparameters.kweekLichtEind)

    if kweeklichtAan:
        GPIO.output(kweeklichtPin, False)
    else:
        GPIO.output(kweeklichtPin, True)

        

        
    # Ventilatoren
    ventilatorAan = bool(tijd.hour &gt;= kweekparameters.ventilatorStart1 and tijd.hour &lt; kweekparameters.ventilatorEind1
                    or tijd.hour &gt;= kweekparameters.ventilatorStart2 and tijd.hour &lt; kweekparameters.ventilatorEind2)

    if ventilatorAan:
        GPIO.output(ventilatorenPin, False)
    else:
        GPIO.output(ventilatorenPin, True)
    
       
    # Temperatuur
    if temperatuur &lt; kweekparameters.minimumTemperatuur:
        GPIO.output(vloerVerwarmingPin, False)

    elif temperatuur &gt; kweekparameters.minimumTemperatuur:
        GPIO.output(vloerVerwarmingPin, True)

    if temperatuur &gt; kweekparameters.maximumTemperatuur:
        GPIO.output(buisVentilatorPin, False)

    elif temperatuur &lt; kweekparameters.maximumTemperatuur:
        GPIO.output(buisVentilatorPin, True)


    # Luchtvochtigheid
    if luchtvochtigheid &lt; kweekparameters.minimumLuchtvochtigheid:
        GPIO.output(bevochtigerPin, False)

    elif luchtvochtigheid &gt; kweekparameters.minimumLuchtvochtigheid:
        GPIO.output(bevochtigerPin, True)

    # CO2
</code></pre>
",86,1,2,5,python;linux;visual-studio-code;raspberry-pi;sensors,2022-08-02 12:13:32,2022-08-02 12:13:32,2022-08-03 10:07:03,goodmorning everybody  my name is joey and i have a serious problem that i can t solve  the problem is that my python script stops running after some hours  to give a little background  i m building an automatic grow tent to grow house plants like philodendrons  syngoniums  monstera s etc  i m a mechanical engineering student so i m very new to python and raspberry  i only worked with arduino for some small projects  so please assume i know nothing and if you can  please explain like you re talking to a child    so there are  main components used in the tent  i m using a scd seeed sensor for measuring temperature  humidity and co  now to the coding  the plan was using ssh on the pi so i could acces it by my laptop  this worked  then i started writing the code on my laptop with vscode  pigpio and the sensor library  this all works as well  in the code i redirect the output to the tent_data txt where i can see timestamps  temp  humidity  co and which devices are on off in the tent  the idea was putting this data in an grafana dashboard and everything would be good  now to the problem  for some reason the code turns off after some hours  it seems pretty random when it does but it seems to be more like after   hours  so maybe something with memory  i tried ps aux   grep joes_kweektent but it says that it isn t running anymore  so it doesn t give an error so i don t know where to start  i can also see the timestamps stopping so i know it isn t printing anymore  at the link drive there are two pictures  stoppedhere and syslog  at that moment the code stopped at   at night  i also screenshotted the syslog  i tried  var log messages but it says nothing  i ve been searching on the internet for days now for a solution but i can t find any explanation  maybe there is a voltage drop and it crashes  maybe the sensor can t read fast enough and it crashes  maybe the memory is to full  see unable to watch large file picture in link   maybe it s something i m totally unaware of since i m so new  i really really really hope someone can help me out  if you ever need help with cad software or need a part created for you i will help you out  if you live in the netherlands i can send you a plant or something     thanks in advance everyone  links  seeed scd sensor  ,why does my python script on raspberry pi crash after running for a while 
69,3147833,72940914,Cite in github readme Markdown,"<p>I'm trying to get a publication on JOSS (journal open source software) and they require the paper written in markdown on github. I'm struggling in understanding how i can add the citation. So I included a file named paper.bib in my github main folder. In the Readme.md i wrote</p>
<pre><code>---
title: 'CREDO: a friendly Customizable, REproducible, DOcker file generator'
tags:
  - Docker 
  - Reproducibility
  - Docker generator
  - User Iinterface 
authors:
  - name: Simone Alessandri'
    equal-contrib: 1 
    affiliation: 1
  - name: Rabellino Sergio
    equal-contrib: 2 
    affiliation: 2
  - name: Sandro Contaldo
    equal-contrib: 3 
    affiliation: 2
  - name: Maria Ratto
    equal-contrib: 3
    affiliation: 4
  - name: Gabriele Piacenti 
    equal-contrib: 3
    affiliation: 5
  - name: Qi Wang
    equal-contrib: 3 
    affiliation: 3
  - name: Marco Beccuti
    equal-contrib: 4
    affiliation: 2
  - name: Raffaele Adolfo Calogero
    equal-contrib: 4 
    affiliation: 4
  - name: Luca Alessandri
    equal-contrib: 5 
    affiliation: &quot;3,4&quot;
  - name: Author with no affiliation
    corresponding: true
    affiliation: 3
affiliations:
 - name: Politechnic of Turin, Torino, Italy
   index: 1
 - name: Department of Computer Science, University of Torino, Torino
   index: 2
 - name: Department of Pathology, Boston Children's Hospital, Harvard Medical School, Boston, MA, USA
   index: 3
 - name: Department of Molecular Biotechnology and Health Sciences, University of Torino, Torino
   index: 4
 - name: Molecular Biotechnology Center &amp; Department of Life Sciences and Systems Biology, University of Turin, Torino, Italy
   index: 5
date: 11 July 2022
bibliography: paper.bib
aas-doi: 
aas-journal: JOSS The Journal of Open Source Software
---
</code></pre>
<p>Is this enough to load the citations? Here is my bib file.</p>
<pre><code>@inproceedings{uno,
  title={Reproducible bioinformatics project: a community for reproducible bioinformatics analysis pipelines},
  author={N. Kulkarni , L. Alessandri, R. Panero, M. Arigoni, M. Olivero, G. Ferrero, et al},
  booktitle={BMC Bioinformatic},
  pages={vol. 19 Suppl 10:349, 2018, doi:10.1186/s12859-018-2296-x},
  doi={10.1186/s12859-018-2296-x}
  }
  
  
@inproceedings{due,
  title={https://docs.docker.com/engine/}
  }
  
  
@inproceedings{tre,
  title={Containers in Bioinformatics: Applications, Practical Considerations, and Best Practices in Molecular Pathology},
  author={S. Kadri, A. Sboner, A. Sigaras and S. Roy},
  booktitle={J Mol Diagn., 2022},
  doi={10.1016/j.jmoldx.2022.01.006}
  }
  
  
@inproceedings{quattro,
  title={https://cran.r-project.org/}
  }
  
  
@inproceedings{cinque,
  title={https://www.python.org/}
  }
  
  
@inproceedings{sei,
  title={Using R and Bioconductor in Clinical Genomics and Transcriptomics},
  author={J.L. Sepulveda. },
  booktitle={J Mol Diagn vol. 22},
  doi={10.1016/j.jmoldx.2019.08.006}
  }
  
  
@inproceedings{sette,
  title={Sparsely-connected autoencoder (SCA) for single cell RNAseq data mining},
  author={L. Alessandri, F. Cordero, M. Beccuti, N. Licheri, M. Arigoni, M. Olivero, et al },
  booktitle={NPJ Syst Biol Appl. vol. 7},
  doi={10.1038/s41540-020-00162-6}
  }
  
  
@inproceedings{otto,
  title={Sparsely Connected Autoencoders: A Multi-Purpose Tool for Single Cell omics Analysis},
  author={L. Alessandri, M.L. Ratto, S.G. Contaldo, M. Beccuti, F. Cordero, M. Arigoni, et al},
  booktitle={nt J Mol Sci., vol. 22},
  doi={10.3390/ijms222312755}
  }
  
  
@inproceedings{nove,
  title={rCASC: reproducible classification analysis of single-cell sequencing data},
  author={L. Alessandri, F. Cordero, M. Beccuti, M. Arigoni, M. Olivero, G. Romano, et al},
  booktitle={Gigascience, vol. 8},
  doi={10.1093/gigascience/giz105}
  }
  
  
@inproceedings{dieci,
  title={https://docs.conda.io/en/latest/}
  }
    

@inproceedings{undici,
  title={https://bioconda.github.io/}
  }

  
@inproceedings{dodici,
  title={Orchestrating high-throughput genomic analysis with Bioconductor},
  author={W. Huber, V.J. Carey, R. Gentleman, S. Anders, M. Carlson, B.S. Carvalho, et al},
  booktitle={Nat Methods, vol. 12},
  doi={10.1038/nmeth.3252}
  }

  
@inproceedings{tredici,
  title={Bioconductor: open software development for computational biology and bioinformatics},
  author={R.C. Gentleman, V.J. Carey, D.M. Bates, B. Bolstad, M. Dettling, S. Dudoit, et al},
  booktitle={Genome Biol., vol. 5},
  doi={10.1186/gb-2004-5-10-r80}
  }
       
       
@inproceedings{quattordici,
  title={https://github.com/}
  }
        
        
@inproceedings{quindici,
  title={https://uwekorn.com/2021/03/01/deploying-conda-environments-in-docker-how-to-do-it-right.html}
  }
       
       
@inproceedings{sedici,
  title={https://pythonspeed.com/articles/activate-conda-dockerfile/}
  }
       
       
@inproceedings{diciassette,
  title={https://biocontainers.pro/}
  }
</code></pre>
<p>In the text, how can i cite the first paper? I tried \cite{uno} as suggested from other questions but is not working. Here is the link to the repository <a href=""https://github.com/alessandriLuca/CREDO_paper"" rel=""nofollow noreferrer"">https://github.com/alessandriLuca/CREDO_paper</a></p>
",55,1,0,5,github;markdown;quote;bibtex;citations,2022-07-11 18:22:10,2022-07-11 18:22:10,2022-08-02 15:04:26,i m trying to get a publication on joss  journal open source software  and they require the paper written in markdown on github  i m struggling in understanding how i can add the citation  so i included a file named paper bib in my github main folder  in the readme md i wrote is this enough to load the citations  here is my bib file  in the text  how can i cite the first paper  i tried  cite uno  as suggested from other questions but is not working  here is the link to the repository ,cite in github readme markdown
70,417501,73199047,How do I link with the IOKit framework on macOS 12.4?,"<p>I am working on a C project with its own make-based build system.  The project tries to interact with the SCSI subsystem through the IOKit framework.  I am developing for arm64 macOS 12.4.  The IT staff at our institute has set up this computer for software development, though I don't know exactly what this entails.  Compiling and executing simple C programs seems to work fine.</p>
<p>Now, when linking the project, I get an error that the IOKit framework is not found.</p>
<pre><code>ld: framework not found IOKit
fatal error: /Library/Developer/CommandLineTools/usr/bin/libtool: internal link edit command failed
smake: *** Code 1 (Operation not permitted) from command line for target '../../../../../libs/arm64-darwin-clang/pic/libmakestate.dylib'.
smake: The following command caused the error:
echo &quot;  ==&gt; LINKING dynamic library \&quot;../../../../../libs/arm64-darwin-clang/pic/libmakestate.dylib\&quot;&quot;; libtool -dynamic -o ../../../../../libs/arm64-darwin-clang/pic/libmakestate.dylib -L../../../../../libs/arm64-darwin-clang/pic -L/usr/local/lib -framework IOKit -framework CoreFoundation -install_name /opt/schily/lib/libmakestate.dylib  `echo OBJ/arm64-darwin-clang/pic/ld_file.o OBJ/arm64-darwin-clang/pic/lock.o    | cat`  -lc  
</code></pre>
<p>Are there any additional options I have to supply to get access to the IOKit framework?  A solution that is not specific to the particular macOS version in use would be best.</p>
<p>I have found <a href=""https://stackoverflow.com/questions/17542092/iokit-not-found"">an old question</a> on a similar topic, but it seems to concern very old versions of macOS and I'm not sure if it is relevant.  Also, I do not have permissions to move system files around on this computer.</p>
<p>Please bear with me, I'm not at all experienced in macOS development and am just trying to get this code to work.  If you need any additional information, do not hesitate to ask.</p>
",50,1,0,3,macos;arm64;iokit,2022-08-01 23:06:48,2022-08-01 23:06:48,2022-08-02 00:17:59,i am working on a c project with its own make based build system   the project tries to interact with the scsi subsystem through the iokit framework   i am developing for arm macos     the it staff at our institute has set up this computer for software development  though i don t know exactly what this entails   compiling and executing simple c programs seems to work fine  now  when linking the project  i get an error that the iokit framework is not found  are there any additional options i have to supply to get access to the iokit framework   a solution that is not specific to the particular macos version in use would be best  i have found  on a similar topic  but it seems to concern very old versions of macos and i m not sure if it is relevant   also  i do not have permissions to move system files around on this computer  please bear with me  i m not at all experienced in macos development and am just trying to get this code to work   if you need any additional information  do not hesitate to ask ,how do i link with the iokit framework on macos   
71,19147128,73198425,Having difficulty populating a DropDownList within a GridView,"<p>As the title states I am having a lot of difficulty populating a drop down list that is within a gridview on my web form.  I feel like this process should be relatively straight forward as I have populated many gridviews and drop down lists in the past without a hitch. Below, I have detailed what I have tried and will post any associated code. I am relatively new to software development and any help in solving this problem would be greatly appreciated.</p>
<p>To start I have added a drop down list to the gridview in question. Code below.</p>
<pre><code>&lt;asp:GridView ID=&quot;GridView3&quot; runat=&quot;server&quot;
    EmptyDataText=&quot;No Claimed Parts&quot; AutoGenerateColumns=&quot;False&quot;
    ShowHeaderWhenEmpty=&quot;True&quot; DataKeyNames=&quot;RecID&quot;
    ShowFooter=&quot;True&quot; DataSourceID=&quot;SqlDataSource5&quot; Width=&quot;95%&quot;&gt;

&lt;EmptyDataTemplate&gt;
    &lt;asp:DropDownList ID=&quot;ddlPartEquipmentNew&quot; runat=&quot;server&quot; DataSourceID=&quot;SqlDataSourcePartEquipment&quot; DataValueField=&quot;EquipmentType&quot; DataTextField=&quot;EquipmentType&quot;
        AppendDataBoundItems=&quot;True&quot; Width=&quot;270px&quot; Height=&quot;20px&quot; Style=&quot;margin-left: 70px;&quot;&gt;
        &lt;asp:ListItem Value=&quot;0&quot;&gt;---SELECT---&lt;/asp:ListItem&gt;
    &lt;/asp:DropDownList&gt;
    &lt;asp:DropDownList ID=&quot;ddlPartNew&quot; runat=&quot;server&quot; DataSourceID=&quot;SqlDataSourcePart&quot; DataValueField=&quot;RecID&quot;
        DataTextField=&quot;description&quot; AppendDataBoundItems=&quot;True&quot; Width=&quot;270px&quot;  Height=&quot;20px&quot;
        style=&quot;margin-left: 70px; margin-right: 110px&quot;&gt;
        &lt;asp:ListItem Value=&quot;0&quot;&gt;---SELECT---&lt;/asp:ListItem&gt;
    &lt;/asp:DropDownList&gt;
    &lt;asp:textbox ID=&quot;txtUnitPriceNew&quot; runat=&quot;server&quot; Width=&quot;95px&quot;/&gt;
    &lt;asp:textbox ID=&quot;txtTaxNew&quot; runat=&quot;server&quot; Width=&quot;95px&quot; text=&quot;0&quot;/&gt;
    &lt;asp:Button ID=&quot;InsertDetail&quot; runat=&quot;server&quot; CommandName=&quot;InsertDetail&quot; Height=&quot;25px&quot; Text=&quot;Add Detail&quot; Width=&quot;85px&quot; /&gt;
&lt;/EmptyDataTemplate&gt;

&lt;AlternatingRowStyle BackColor=&quot;#CCCCCC&quot; /&gt;
    &lt;Columns&gt;
        &lt;asp:CommandField ShowEditButton=&quot;True&quot; footertext=&quot;Add --&gt;&quot; ShowDeleteButton=&quot;True&quot; HeaderStyle-Width=&quot;70px&quot;/&gt;
        &lt;asp:BoundField DataField=&quot;RecID&quot; HeaderText=&quot;RecID&quot; SortExpression=&quot;RecID&quot; ReadOnly=&quot;True&quot; Visible=&quot;False&quot; /&gt;

        &lt;asp:TemplateField HeaderText=&quot;Parts Description&quot; ItemStyle-HorizontalAlign=&quot;center&quot;&gt;
            &lt;ItemTemplate&gt;
                &lt;asp:label ID=&quot;lblDescriptionAdd&quot; Text='&lt;%# Bind(&quot;PartFailed&quot;) %&gt;' runat=&quot;server&quot;/&gt;
            &lt;/ItemTemplate&gt;
            &lt;EditItemTemplate&gt;
                &lt;asp:DropDownList ID=&quot;ddlPartEquipmentEdit&quot; runat=&quot;server&quot; DataValueField=&quot;Agreement&quot; DataTextField=&quot;EquipmentType&quot;
                    AppendDataBoundItems=&quot;True&quot; Width=&quot;270px&quot; Height=&quot;20px&quot; Style=&quot;margin-left: 70px;&quot;&gt;
                    &lt;asp:ListItem Value=&quot;0&quot;&gt;---SELECT---&lt;/asp:ListItem&gt;
                &lt;/asp:DropDownList&gt;
                &lt;asp:DropDownList ID=&quot;ddlPartEdit&quot; runat=&quot;server&quot; DataSourceID=&quot;SqlDataSourcePart&quot; DataValueField=&quot;RecID&quot; DataTextField=&quot;description&quot; SelectedValue='&lt;%# Eval(&quot;RepairID&quot;)%&gt;' AppendDataBoundItems=&quot;True&quot; Width=&quot;270px&quot;/&gt;
            &lt;/EditItemTemplate&gt;
            &lt;FooterTemplate&gt;
                &lt;asp:DropDownList ID=&quot;ddlPartEquipmentInsert&quot; runat=&quot;server&quot; DataValueField=&quot;Agreement&quot; DataTextField=&quot;EquipmentType&quot;
                    AppendDataBoundItems=&quot;True&quot; Width=&quot;270px&quot; Height=&quot;20px&quot; Style=&quot;margin-left: 70px;&quot;&gt;
                    &lt;asp:ListItem Value=&quot;0&quot;&gt;---SELECT---&lt;/asp:ListItem&gt;
                &lt;/asp:DropDownList&gt;
                &lt;asp:DropDownList ID=&quot;ddlPartInsert&quot; runat=&quot;server&quot; DataSourceID=&quot;SqlDataSourcePart&quot; DataValueField=&quot;RecID&quot; DataTextField=&quot;description&quot; AppendDataBoundItems=&quot;True&quot; Width=&quot;270px&quot;&gt;
                    &lt;asp:ListItem Value=&quot;0&quot;&gt;---SELECT---&lt;/asp:ListItem&gt;
                &lt;/asp:DropDownList&gt;
            &lt;/FooterTemplate&gt;
        &lt;/asp:TemplateField&gt;

        &lt;asp:TemplateField HeaderText=&quot;Part Cost Requested&quot; ItemStyle-HorizontalAlign=&quot;center&quot; HeaderStyle-Width=&quot;100px&quot;&gt;
            &lt;ItemTemplate&gt;
                &lt;asp:label ID=&quot;lblUnitPrice&quot; Text='&lt;%# Bind(&quot;PartCost&quot;, &quot;{0:C}&quot;) %&gt;' runat=&quot;server&quot; Enabled=&quot;False&quot;/&gt;
            &lt;/ItemTemplate&gt;
            &lt;EditItemTemplate&gt;
                &lt;asp:textbox ID=&quot;txtUnitPriceEdit&quot; Text='&lt;%# Bind(&quot;PartCost&quot;) %&gt;' Enabled=&quot;true&quot; runat=&quot;server&quot;/&gt;
            &lt;/EditItemTemplate&gt;
            &lt;FooterTemplate&gt;
                &lt;asp:textbox ID=&quot;txtUnitPriceInsert&quot; Text='&lt;%# Bind(&quot;PartCost&quot;) %&gt;' runat=&quot;server&quot; style=&quot;width: 100%; box-sizing: border-box;&quot;/&gt;
            &lt;/FooterTemplate&gt;
        &lt;/asp:TemplateField&gt;

        &lt;asp:TemplateField HeaderText=&quot;Tax&quot; ItemStyle-HorizontalAlign=&quot;Center&quot; HeaderStyle-Width=&quot;100px&quot;&gt;
            &lt;ItemTemplate&gt;
                &lt;asp:LinkButton ID=&quot;lbTaxTotal&quot; Text='&lt;%# Bind(&quot;Tax&quot;, &quot;{0:C}&quot;)%&gt;' runat=&quot;server&quot; CommandArgument=&quot;Part&quot; OnClick=&quot;lblTaxTotal_Click&quot;/&gt;
                &lt;asp:HiddenField ID=&quot;hidPartGST&quot; runat=&quot;server&quot; Value='&lt;%# Bind(&quot;GST&quot;)%&gt;' /&gt;
                &lt;asp:HiddenField ID=&quot;hidPartPST&quot; runat=&quot;server&quot; Value='&lt;%# Bind(&quot;PST&quot;)%&gt;' /&gt;
                &lt;asp:HiddenField ID=&quot;hidPartQST&quot; runat=&quot;server&quot; Value='&lt;%# Bind(&quot;QST&quot;)%&gt;' /&gt;
                &lt;asp:HiddenField ID=&quot;hidPartHST&quot; runat=&quot;server&quot; Value='&lt;%# Bind(&quot;HST&quot;)%&gt;' /&gt;
            &lt;/ItemTemplate&gt;
            &lt;EditItemTemplate&gt;
                &lt;asp:textbox ID=&quot;lblTaxTotalEdit&quot; Text='&lt;%# Bind(&quot;Tax&quot;)%&gt;' Enabled=&quot;true&quot; runat=&quot;server&quot;/&gt;
            &lt;/EditItemTemplate&gt;
            &lt;FooterTemplate&gt;
                &lt;asp:textbox ID=&quot;txtTaxTotalInsert&quot; Text=&quot;0&quot; runat=&quot;server&quot; Enabled=&quot;true&quot; style=&quot;width: 100%; box-sizing: border-box;&quot;/&gt;
            &lt;/FooterTemplate&gt;
        &lt;/asp:TemplateField&gt;

        &lt;asp:TemplateField HeaderText=&quot;Insert New&quot; HeaderStyle-Width=&quot;85px&quot;&gt;
            &lt;ItemTemplate&gt;
                &lt;asp:Label ID=&quot;lblEmpty&quot; Text=&quot;&quot; runat=&quot;server&quot; Width=&quot;75px&quot;/&gt;
            &lt;/ItemTemplate&gt;
            &lt;FooterTemplate&gt;
                &lt;asp:Button ID=&quot;Insert&quot; runat=&quot;server&quot; CommandName=&quot;InsertNewDetail&quot; Height=&quot;22px&quot; Text=&quot;Insert&quot; style=&quot;width: 100%; box-sizing: border-box;&quot; /&gt;
            &lt;/FooterTemplate&gt;
        &lt;/asp:TemplateField&gt;
        &lt;/Columns&gt;
        &lt;HeaderStyle BackColor=&quot;#336699&quot; ForeColor=&quot;White&quot; /&gt;
    &lt;/asp:GridView&gt;
</code></pre>
<p>In the above code, the gridview is declared and there are a series of controls within the gridview. The control in question is &quot;ddlPartEquipmentNew&quot; (technically I am having the same problem with the 2 other drop downs labeled &quot;ddlPartEquipmentEdit&quot; and &quot;ddlPartEquipmentInsert&quot; respectively, however we can ignore those at the moment.)</p>
<p>For whatever reason I cannot seem to figure out how to bind this ddl to the appropriate values I have in my database.</p>
<p>Below I will go into detail on what I have tried and the various outputs I have gotten.</p>
<p>One of the first things I have tried was to create a GetData() Function and then call that function in the gridviews OnDataBound() event, however when doing this, though I don't receive an error, the drop down has no values other than the default &quot;---SELECT---&quot; I setup in the aspx code above.</p>
<p>Below I have attached the code for the GetData() function and code for the OnDataBound() procedure.</p>
<p>GetData()</p>
<pre><code>Private Function GetEquipmentData(query As String) As DataSet
    Dim conString As SqlConnection = objCn
    Dim cmd As New SqlCommand(query)
    Using conString
        Using sda As New SqlDataAdapter()
            cmd.Connection = conString
            sda.SelectCommand = cmd
            Using ds As New DataSet()
                sda.Fill(ds, txtAgreement.Text)
                Return ds
            End Using
        End Using
    End Using
End Function
</code></pre>
<p>OnDataBound()</p>
<pre><code>Protected Sub GridView3_DataBound(sender As Object, e As EventArgs) Handles GridView3.DataBound
    Dim partRequestedTotal As Decimal = Decimal.Zero
    Dim partTotal As Decimal = Decimal.Zero
    Dim gv As GridView = sender
    If gv.EditIndex = -1 Then
        For Each row As GridViewRow In gv.Rows
            If row.RowType = DataControlRowType.DataRow Then
                Dim lblAmount As Label = row.FindControl(&quot;lblUnitPrice&quot;)
                Dim lblAmountRequested As Label = row.FindControl(&quot;lblUnitPrice&quot;)
                Dim ddlPartEquipmentNew As DropDownList = row.FindControl(&quot;ddlPartEquipmentNew&quot;)

                ddlPartEquipmentNew.DataSource = GetEquipmentData(&quot;SELECT EquipmentType FROM Equipment WHERE Agreement = @Agreement&quot;)
                ddlPartEquipmentNew.DataTextField = &quot;EquipmentType&quot;
                ddlPartEquipmentNew.DataValueField = &quot;EquipmentType&quot;
                ddlPartEquipmentNew.DataBind()

                'Dim lblMarkup As Label = row.FindControl(&quot;lblMarkup&quot;)

                Dim partRequested As Decimal = Decimal.Parse(lblAmountRequested.Text, NumberStyles.Currency)
                'Convert.ToDecimal(lblAmountRequested.Text.Replace(&quot;$&quot;, &quot;&quot;))
                Dim partValue As Decimal = Decimal.Parse(lblAmount.Text, NumberStyles.Currency)
                'Convert.ToDecimal(lblAmount.Text.Replace(&quot;$&quot;, &quot;&quot;))
                'Dim markupValue As Decimal = Decimal.Parse(lblMarkup.Text, NumberStyles.Currency)
                'Convert.ToDecimal(lblMarkup.Text.Replace(&quot;$&quot;, &quot;&quot;))
                'partTotal = partValue + partTotal + markupValue
                partRequestedTotal = partRequestedTotal + partRequested
            End If
        Next
        'txtPartsTotal.Text = partTotal.ToString
        txtPartsRequested.Text = partRequestedTotal.ToString(&quot;N2&quot;)
        If GridView3.Rows.Count &gt; 0 Or GridView1.Rows.Count &gt; 0 Then
            calculateTotalTax()
            calculateTotal()
        Else
            txtTax.Text = &quot;0&quot;
            Me.txtGrandTotal.Text = &quot;0&quot;
        End If
    End If

End Sub
</code></pre>
<p>With this attempt at binding the drop down list I receive no errors however the drop down in question remains empty.</p>
<p>I have also tried to create a databind event for the drop down list specifically and in the OnDataBind() event for the control I reference the procedure I created, however when I do this I get an exception error stating that I have a connection to the database that has not been closed, or a timeout exception.</p>
<p>Below is the code for the ddl databind event</p>
<pre><code>    Protected Sub DDLPartEquipmentNew_DataBind(sender As Object, e As EventArgs)
    Dim ddlPartEquipmentNew As DropDownList = sender
    Using con As New SqlConnection(ConfigurationManager.ConnectionStrings(&quot;WarrantyConnectionString&quot;).ToString)

        Using cmd As New SqlCommand(&quot;SELECT EquipmentType FROM Equipment WHERE Agreement = @Agreement&quot;)
            cmd.Parameters.Add(&quot;@Agreement&quot;, SqlDbType.Int).Value = txtAgreement.Text
            cmd.CommandType = CommandType.Text
            con.Open()
            cmd.Connection = con
            ddlPartEquipmentNew.DataSource = cmd.ExecuteReader()
            ddlPartEquipmentNew.DataBind()
            con.Close()
        End Using

    End Using
End Sub
</code></pre>
<p>As a last note on the situation I am having, the other drop down controls in this gridview are populated using an asp:SqlDataSource control which I have also tried, the issue I run into using a datasource in the aspx page is that my query requires a variable and so far I have not found a way to declare that variable in the code behind to avoid the exception &quot;Must declare Scalar Variable @Agreement&quot;. The especially weird part about this exception is that in the stack trace it is popping this exception inside the databind event for a different gridview.</p>
<p>Query in question: SELECT EquipmentType FROM Equipment WHERE Agreement = @Agreement</p>
<p>Relatively simple, or at least I would think so. Any help someone would be able to offer on this problem would be greatly appreciated as I am at a loss as to how to populate this drop down, let alone any other drop down lists I may have to add to the page.</p>
",71,0,0,3,asp.net;sql-server;vb.net,2022-08-01 22:03:50,2022-08-01 22:03:50,2022-08-01 22:03:50,as the title states i am having a lot of difficulty populating a drop down list that is within a gridview on my web form   i feel like this process should be relatively straight forward as i have populated many gridviews and drop down lists in the past without a hitch  below  i have detailed what i have tried and will post any associated code  i am relatively new to software development and any help in solving this problem would be greatly appreciated  to start i have added a drop down list to the gridview in question  code below  in the above code  the gridview is declared and there are a series of controls within the gridview  the control in question is  ddlpartequipmentnew   technically i am having the same problem with the  other drop downs labeled  ddlpartequipmentedit  and  ddlpartequipmentinsert  respectively  however we can ignore those at the moment   for whatever reason i cannot seem to figure out how to bind this ddl to the appropriate values i have in my database  below i will go into detail on what i have tried and the various outputs i have gotten  one of the first things i have tried was to create a getdata   function and then call that function in the gridviews ondatabound   event  however when doing this  though i don t receive an error  the drop down has no values other than the default     select     i setup in the aspx code above  below i have attached the code for the getdata   function and code for the ondatabound   procedure  getdata   ondatabound   with this attempt at binding the drop down list i receive no errors however the drop down in question remains empty  i have also tried to create a databind event for the drop down list specifically and in the ondatabind   event for the control i reference the procedure i created  however when i do this i get an exception error stating that i have a connection to the database that has not been closed  or a timeout exception  below is the code for the ddl databind event as a last note on the situation i am having  the other drop down controls in this gridview are populated using an asp sqldatasource control which i have also tried  the issue i run into using a datasource in the aspx page is that my query requires a variable and so far i have not found a way to declare that variable in the code behind to avoid the exception  must declare scalar variable  agreement   the especially weird part about this exception is that in the stack trace it is popping this exception inside the databind event for a different gridview  query in question  select equipmenttype from equipment where agreement    agreement relatively simple  or at least i would think so  any help someone would be able to offer on this problem would be greatly appreciated as i am at a loss as to how to populate this drop down  let alone any other drop down lists i may have to add to the page ,having difficulty populating a dropdownlist within a gridview
72,12983521,60646690,cronjob in docker container cannot connect to other container,"<p>I want to use cronjob to run a script, which is to fetch data from news api and feed it into postegres which is located in other container.</p>
<p>so the simplified architecture is</p>
<pre><code> app(in container) -&gt; postegres(in container)
</code></pre>
<p>the cronjob script is inside app, and it will fetch data and then send to postegres.</p>
<p>in my crontab is</p>
<pre><code>* * * * * cd /tourMamaRoot/tourMama/cronjob &amp;&amp; fetch_news.py &gt;&gt; /var/log/cron.log 2&gt;&amp;1
</code></pre>
<p>i can run it successfully by manually run the script, but when i put it in crontab , it shows the error.</p>
<pre><code> File &quot;/usr/local/lib/python3.6/dist-packages/django/db/backends/base/base.py&quot;, line 195, in connect
    self.connection = self.get_new_connection(conn_params)
  File &quot;/usr/local/lib/python3.6/dist-packages/django/db/backends/postgresql/base.py&quot;, line 178, in get_new_connection
    connection = Database.connect(**conn_params)
  File &quot;/usr/local/lib/python3.6/dist-packages/psycopg2/__init__.py&quot;, line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
django.db.utils.OperationalError: could not connect to server: No such file or directory
    Is the server running locally and accepting
    connections on Unix domain socket &quot;/var/run/postgresql/.s.PGSQL.5432&quot;?
</code></pre>
<p>seems it only look for database locally if use crontab, how can i set it to put data into other container like i manually run the script?</p>
<h1>Info:</h1>
<p>my docker container for app is Ubuntu version 18.04 , and the following is my docker file for app</p>
<pre><code>FROM ubuntu:18.04
MAINTAINER Eson

ENV PYTHONUNBUFFERED 1
ENV DEBIAN_FRONTEND=noninteractive

EXPOSE 8000

# Setup directory structure
RUN mkdir /tourMamaRoot
WORKDIR /tourMamaRoot/tourMama/

COPY tourMama/requirements/base.txt /tourMamaRoot/base.txt
COPY tourMama/requirements/dev.txt /tourMamaRoot/requirements.txt

# install Python 3
RUN apt-get update &amp;&amp; apt-get install -y \
        software-properties-common
RUN add-apt-repository ppa:deadsnakes/ppa
RUN apt-get update &amp;&amp; apt-get install -y \
    python3.7 \
    python3-pip
RUN python3.7 -m pip install pip
RUN apt-get update &amp;&amp; apt-get install -y \
    python3-distutils \
    python3-setuptools

# install Postgresql
RUN apt-get -y install wget ca-certificates
RUN wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | apt-key add -
RUN sh -c echo deb http://apt.postgresql.org/pub/repos/apt/ `lsb_release -cs`-pgdg main &gt;&gt; /etc/apt/sources.list.d/pgdg.list
RUN apt-get update
RUN apt-get install -y postgresql postgresql-contrib

# Install some dep
RUN apt-get install net-tools
RUN apt-get install -y libpq-dev python-dev

RUN pip3 install -r /tourMamaRoot/requirements.txt

# Copy application
COPY ./tourMama/ /tourMamaRoot/tourMama/
</code></pre>
<p>docker compose file:</p>
<pre><code>version: '3'

services:
  app:
    build:
      # current directory
      # if for dev, need to have Dockerfile.dev in folder
      dockerfile: docker/dev/Dockerfile
      context: .
    ports:
      #host to image
      - &quot;8000:8000&quot;
    volumes:
      # map directory to image, which means if something changed in
      # current directory, it will automatically reflect on image,
      # don't need to restart docker to get the changes into effect
      - ./tourMama:/tourMamaRoot/tourMama
    command: &gt;
      sh -c &quot;python3 manage.py wait_for_db &amp;&amp;
             python3 manage.py makemigrations &amp;&amp;
             python3 manage.py migrate &amp;&amp;
             python3 manage.py runserver 0.0.0.0:8000 &amp;&amp;
             sh initial_all.sh&quot;
    environment:
      - DB_HOST=db
      - DB_NAME=app
      - DB_USER=postgres
      - DB_PASS=supersecretpassword

    depends_on:
      - db
      - redis

  db:
    image: postgres:11-alpine
    ports:
      #host to image
      - &quot;5432:5432&quot;
    environment:
      - POSTGRES_DB=app
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=supersecretpassword

  redis:
    image: redis:5.0.5-alpine
    ports:
      #host to image
      - &quot;6379:6379&quot;

#    command: [&quot;redis-server&quot;, &quot;--appendonly&quot;, &quot;yes&quot;]
#    hostname: redis
#    networks:
#      - redis-net
#    volumes:
#      - redis-data:/data
</code></pre>
<p>and my cronjob script is:</p>
<pre><code>import os
import sys
import django
from django.db import IntegrityError
from newsapi.newsapi_client import NewsApiClient
sys.path.append(&quot;../&quot;)
os.environ.setdefault(&quot;DJANGO_SETTINGS_MODULE&quot;, &quot;tourMama.settings&quot;)
django.setup()
from news.models import News
from tourMama_app.models import Category
from config.script import categorization_loader

load_category = categorization_loader.load_category_data(&quot;catagorization.yml&quot;)
categories = list(load_category.keys())
countries = [&quot;us&quot;, &quot;gb&quot;]

# Init
newsapi = NewsApiClient(api_key='secret')

for category in categories:
    for country in countries:
        category_lower = category.lower()
        category_obj = Category.objects.filter(
            category=category,
        ).get()

        top_headlines = newsapi.get_top_headlines(q='',
                                                  # sources=object'bbc-news,the-verge',
                                                  category=category_lower,
                                                  language='en',
                                                  page_size=100,
                                                  country=country
                                                  )

        for article in top_headlines.get(&quot;articles&quot;):
            try:
                News.objects.create(
                    source=article[&quot;source&quot;].get(&quot;name&quot;) if article[&quot;source&quot;] else None,
                    title=article.get(&quot;title&quot;),
                    author=article.get(&quot;author&quot;),
                    description=article.get(&quot;description&quot;),
                    url=article.get(&quot;url&quot;),
                    urlToImage=article.get(&quot;urlToImage&quot;),
                    published_at=article.get(&quot;publishedAt&quot;),
                    content=article.get(&quot;content&quot;),
                    category=category_obj
                )

            except IntegrityError:
                print(&quot;data already exist&quot;)

            else:
                print(&quot;data insert successfully&quot;)
</code></pre>
<p>and if needed, my django setting file is as following:</p>
<pre><code>&quot;&quot;&quot;
Django settings for tourMama project.

Generated by 'django-admin startproject' using Django 2.2.1.

For more information on this file, see
https://docs.djangoproject.com/en/2.2/topics/settings/

For the full list of settings and their values, see
https://docs.djangoproject.com/en/2.2/ref/settings/
&quot;&quot;&quot;

import os

# Build paths inside the project like this: os.path.join(BASE_DIR, ...)
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
TEMPLATE_DIR = os.path.join(BASE_DIR,&quot;templates&quot;)

# Quick-start development settings - unsuitable for production
# See https://docs.djangoproject.com/en/2.2/howto/deployment/checklist/

# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = 'd084cm20*x*&amp;s&amp;w)vq+7*teea540yny+fyi^dh57nxiff&amp;a#25'

# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = True

COMPRESS_ENABLED = False
COMPRESS_CSS_HASHING_METHOD = 'content'
COMPRESS_FILTERS = {
    'css':[
        'compressor.filters.css_default.CssAbsoluteFilter',
        'compressor.filters.cssmin.rCSSMinFilter',
    ],
    'js':[
        'compressor.filters.jsmin.JSMinFilter',
    ]
}
HTML_MINIFY = False
KEEP_COMMENTS_ON_MINIFYING = False

ALLOWED_HOSTS = ['0.0.0.0', &quot;127.0.0.1&quot;]


# Application definition

INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    'channels',
    'bootstrap3',
    'tourMama_app',
    'account',
    'posts',
    'group',
    'news',
    'statistics',
    'compressor',
]

AUTH_USER_MODEL = &quot;account.UserProfile&quot;

MIDDLEWARE = [
    'django.middleware.gzip.GZipMiddleware',
    'htmlmin.middleware.HtmlMinifyMiddleware',
    'htmlmin.middleware.MarkRequestMiddleware',

    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]

ROOT_URLCONF = 'tourMama.urls'

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [TEMPLATE_DIR,],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.debug',
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages'   ,
            ],
        },
    },
]

WSGI_APPLICATION = 'tourMama.wsgi.application'
ASGI_APPLICATION = 'tourMama.routing.application'

# https://stackoverflow.com/questions/56480472/cannot-connect-to-redis-container-from-app-container/56480746#56480746
CHANNEL_LAYERS = {
    'default': {
        'BACKEND': 'channels_redis.core.RedisChannelLayer',
        'CONFIG': {
            &quot;hosts&quot;: [('redis', 6379)],
        },
    },
}


# Database
# https://docs.djangoproject.com/en/2.2/ref/settings/#databases

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'HOST': os.environ.get('DB_HOST'),
        'NAME': os.environ.get('DB_NAME'),
        'USER': os.environ.get('DB_USER'),
        'PASSWORD': os.environ.get('DB_PASS')
    }
}


# Password validation
# https://docs.djangoproject.com/en/2.2/ref/settings/#auth-password-validators

AUTH_PASSWORD_VALIDATORS = [
    {
        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
    },
]

STATICFILES_FINDERS = (
    'django.contrib.staticfiles.finders.FileSystemFinder',
    'django.contrib.staticfiles.finders.AppDirectoriesFinder',
    # other finders..
    'compressor.finders.CompressorFinder',
)

CACHES = {
    'default': {
        'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache',
        'LOCATION': '127.0.0.1:11211',
    }
}

# Internationalization
# https://docs.djangoproject.com/en/2.2/topics/i18n/

LANGUAGE_CODE = 'en-us'

TIME_ZONE = 'UTC'

USE_I18N = True

USE_L10N = True

USE_TZ = True


# Static files (CSS, JavaScript, Images)
# https://docs.djangoproject.com/en/2.2/howto/static-files/


STATIC_URL = '/static/'
STATICFILES_DIRS = [os.path.join(BASE_DIR, 'static'),]
STATIC_ROOT = os.path.join(BASE_DIR,&quot;static_root&quot;)

MEDIA_URL = '/media/'
MEDIA_ROOT = os.path.join(BASE_DIR, 'media')

LOGIN_REDIRECT_URL = &quot;home:index&quot;
LOGOUT_REDIRECT_URL = &quot;home:index&quot;
</code></pre>
",825,1,2,3,django;docker;cron,2020-03-12 04:08:02,2020-03-12 04:08:02,2022-08-01 17:50:57,i want to use cronjob to run a script  which is to fetch data from news api and feed it into postegres which is located in other container  so the simplified architecture is the cronjob script is inside app  and it will fetch data and then send to postegres  in my crontab is i can run it successfully by manually run the script  but when i put it in crontab   it shows the error  seems it only look for database locally if use crontab  how can i set it to put data into other container like i manually run the script  my docker container for app is ubuntu version     and the following is my docker file for app docker compose file  and my cronjob script is  and if needed  my django setting file is as following ,cronjob in docker container cannot connect to other container
73,1578031,73188379,Angular dynamic environment.ts for embedded/packaged application,"<p>I'm building a Golang based server/solution that will be installed and run by customers. The frontend/UI is being developed and uses the environment.ts settings are part of Angular. This works fine for local development, and static environments of the server we deploy for testing ( such as staging-001.company.com ) but means we need to run ng build and modify the builds for each environment.</p>
<p>The idea is customers would run the service as a container or os service and configure it via the environment or config file, such as BASE_URL=http://app.mycompany.com, it is not hosted by us in the end state.</p>
<p>How can Angular's environment become dynamic? The UI is served, but it cannot hit the API with these environment settings being hard coded.</p>
<p>Ideally, I'm wondering how I could use a os.env to configure the built JS base settings. The user hits the service on <a href=""http://app.mycompany.com"" rel=""nofollow noreferrer"">http://app.mycompany.com</a> which also has /rest/api/${blah}, but the JS cannot connect as it might have http://localhost:8080/rest/api as the baseUrl for Angular.</p>
<p>Angular seems great as its a single page app and serving the dist folder is simple enough, but doesn't seem like it can work for an embedded system, customer run/self-hosted software for example. There must be a way to do this...</p>
",33,0,0,5,angular;go;variables;dynamic;production-environment,2022-08-01 05:43:01,2022-08-01 05:43:01,2022-08-01 05:43:01,i m building a golang based server solution that will be installed and run by customers  the frontend ui is being developed and uses the environment ts settings are part of angular  this works fine for local development  and static environments of the server we deploy for testing   such as staging  company com   but means we need to run ng build and modify the builds for each environment  the idea is customers would run the service as a container or os service and configure it via the environment or config file  such as base_url http   app mycompany com  it is not hosted by us in the end state  how can angular s environment become dynamic  the ui is served  but it cannot hit the api with these environment settings being hard coded  ideally  i m wondering how i could use a os env to configure the built js base settings  the user hits the service on  which also has  rest api   blah   but the js cannot connect as it might have http   localhost  rest api as the baseurl for angular  angular seems great as its a single page app and serving the dist folder is simple enough  but doesn t seem like it can work for an embedded system  customer run self hosted software for example  there must be a way to do this   ,angular dynamic environment ts for embedded packaged application
74,19252041,73172890,How to bind UWP Control&#39;s Methods to a Method or Command in MVVM,"<p>I am completely new to MVVM and I am creating an UWP app for keeping track of my software development, I am still learning.</p>
<p>So what I want to make is:</p>
<p>An app that contains single page -&gt;</p>
<p>In MainPage.xaml I have something like this:</p>
<pre><code>&lt;!--MainPage Content--&gt;
&lt;Grid&gt;
    &lt;!--For SearchBox--&gt;
    &lt;AutoSuggestBox x:Name=&quot;SearchBox&quot;/&gt;

    &lt;!--For Adding Item--&gt;
    &lt;AppBarButton x:Name=&quot;AddAppButton&quot;/&gt;

    &lt;!--Listview that contains main data--&gt;
    &lt;ListView x:Name=&quot;AppsListView&quot;/&gt;

    &lt;!--This is DataTemplate of listview--&gt;
    &lt;DataTemplate&gt;
        &lt;Grid&gt;
            &lt;!--Icon of App--&gt;
            &lt;Image/&gt;
            &lt;!--Name of App--&gt;
            &lt;TextBlock/&gt;
            &lt;!--For Editing Item--&gt;
            &lt;AppBarButton/&gt;
            &lt;!--For Deleting Item--&gt;
            &lt;AppBarButton/&gt;
        &lt;/Grid&gt;
    &lt;/DataTemplate&gt;
&lt;/Grid&gt;
</code></pre>
<p>In Model I have something like this:</p>
<pre><code>public class DevApp
{
    public string name { get; set; } // For App Name
    public string Iconsource { get; set; } // For App Icon
    public ICommand EditCommand; // For Edit AppBarButton
    public ICommand DeleteCommand; // For Delete AppBarButton
}
</code></pre>
<p>In ViewModel, something like :</p>
<pre><code>public class ViewModel
{
    // For ItemSource of ListView
    public ObservableCollection&lt;DevApp&gt; DevApps = new ObservableCollection&lt;DevApp&gt;();

    // For Add AppBarButton
    public ICommand AddCommand;
}
</code></pre>
<p>Now this is me first time trying to create a neat and clean Mvvm app.
Now I have this question:</p>
<blockquote>
<ol>
<li>I know how to bind command to button or AppBarButton but how am I supposed to bind a Methods of a Xaml Control such as Listview's SelectionChanged() or AutoSuggestBox's TextChanged() Methods to ViewModel ?</li>
<li>How can I Load Data from save file ? As there is no InitializeComponent() in ViewModel like in CodeBehind to start from, where shall I pull LoadData() method which loads data to ListView ? ( my viewmodel is bind to view using &lt;MainPage.DataContext&gt; and I wanna keep code behind completely empty. )</li>
<li>Where shall I put Data class that can manage load save and edit data to savefile.</li>
<li>How shall I distribute responsibilities among classes ?<br />
I have seen people using mvvm and they create files like:<br />
services, helpers, contracts, behaviours, etc.<br />
and I have seen same thing in Windows Community Toolkit Sample App
Is it required for Mvvm.
And what are services and helpers.</li>
<li>Shall I really use Mvvm for this ?<br />
I tried using Mvvm in this just for curiosity but like<br />
ITS BEEN 1 MONTH I AM MAKKING THIS APP! but it gets messed up again and again,<br />
If I used Code Behind it would have been done in few days.
BY time now I realize that Mvvm is good at data bind in complex apps but<br />
When it comes to simple things like a simple app with listview, I think code-behind<br />
is better and it keeps things simple.</li>
</ol>
</blockquote>
<p>Please answer these questions I am really struggling in making this app.</p>
",26,1,1,4,c#;xaml;mvvm;uwp,2022-07-30 07:36:27,2022-07-30 07:36:27,2022-08-01 05:07:27,i am completely new to mvvm and i am creating an uwp app for keeping track of my software development  i am still learning  so what i want to make is  an app that contains single page   gt  in mainpage xaml i have something like this  in model i have something like this  in viewmodel  something like   please answer these questions i am really struggling in making this app ,how to bind uwp control   s methods to a method or command in mvvm
75,972253,22421140,how to set supervisor to run a shell script,"<p>Setting up a <code>Dockerfile</code> to install node prereqs and then set up supervisor in order to run the final <code>npm install</code> command. Running Docker in CoreOS under VirtualBox.</p>

<p>I have a <code>Dockerfile</code> that sets everything up correctly:</p>

<pre><code>FROM ubuntu
MAINTAINER &lt;&lt;Me&gt;&gt;

# Install docker basics
RUN echo ""deb http://archive.ubuntu.com/ubuntu precise main universe"" &gt; /etc/apt/sources.list
RUN apt-get update
RUN apt-get upgrade -y

# Install dependencies and nodejs
RUN apt-get update
RUN apt-get install -y python-software-properties python g++ make
RUN add-apt-repository ppa:chris-lea/node.js
RUN apt-get update
RUN apt-get install -y nodejs

# Install git
RUN apt-get install -y git

# Install supervisor
RUN apt-get install -y supervisor
RUN mkdir -p /var/log/supervisor

# Add supervisor config file
ADD ./etc/supervisord.conf /etc/supervisor/conf.d/supervisord.conf

# Bundle app source
ADD . /src

# create supervisord user
RUN /usr/sbin/useradd --create-home --home-dir /usr/local/nonroot --shell /bin/bash nonroot
RUN chown -R nonroot: /src

# set install script to executable
RUN /bin/chmod +x /src/etc/install.sh

#set up .env file
RUN echo ""NODE_ENV=development\nPORT=5000\nRIAK_SERVERS={SERVER}"" &gt; /src/.env

#expose the correct port
EXPOSE 5000

# start supervisord when container launches
CMD [""/usr/bin/supervisord""]
</code></pre>

<p>And then I want to set up supervisord to launch one of a few possible processes, including an installation shell script that I've confirmed to work correctly, <code>install.sh</code>, which is located in the application's <code>/etc</code> directory:</p>

<pre><code>#!/bin/bash
cd /src; npm install
export PATH=$PATH:node_modules/.bin
</code></pre>

<p>However, I'm very new to supervisor syntax, and I can't get it to launch the shell script correctly. This is what I have in my <code>supervisord.conf</code> file:</p>

<pre><code>[supervisord]
nodaemon=true

[program:install]
command=install.sh
directory=/src/etc/
user=nonroot
</code></pre>

<p>When I run the <code>Dockerfile</code>, everything runs correctly, but when I launch the image, I get the following:</p>

<pre><code>2014-03-15 07:39:56,854 CRIT Supervisor running as root (no user in config file)
2014-03-15 07:39:56,856 WARN Included extra file ""/etc/supervisor/conf.d/supervisord.conf"" during parsing
2014-03-15 07:39:56,913 INFO RPC interface 'supervisor' initialized
2014-03-15 07:39:56,913 WARN cElementTree not installed, using slower XML parser for XML-RPC
2014-03-15 07:39:56,914 CRIT Server 'unix_http_server' running without any HTTP authentication checking
2014-03-15 07:39:56,915 INFO supervisord started with pid 1
2014-03-15 07:39:57,918 INFO spawnerr: can't find command 'install.sh'
2014-03-15 07:39:58,920 INFO spawnerr: can't find command 'install.sh'
</code></pre>

<p>Clearly, I have not set up supervisor correctly to run this shell script -- is there part of the syntax that I'm screwing up?</p>
",42576,4,16,4,node.js;bash;docker;supervisord,2014-03-15 09:51:40,2014-03-15 09:51:40,2022-07-31 17:40:38,setting up a dockerfile to install node prereqs and then set up supervisor in order to run the final npm install command  running docker in coreos under virtualbox  i have a dockerfile that sets everything up correctly  and then i want to set up supervisord to launch one of a few possible processes  including an installation shell script that i ve confirmed to work correctly  install sh  which is located in the application s  etc directory  however  i m very new to supervisor syntax  and i can t get it to launch the shell script correctly  this is what i have in my supervisord conf file  when i run the dockerfile  everything runs correctly  but when i launch the image  i get the following  clearly  i have not set up supervisor correctly to run this shell script    is there part of the syntax that i m screwing up ,how to set supervisor to run a shell script
76,11809424,64228879,Unable to install DFINITY Canister SDK on Ubuntu,"<p>I'm following the steps found <a href=""https://sdk.dfinity.org/docs/quickstart/quickstart.html#download-and-install"" rel=""nofollow noreferrer"">here</a> to install <code>DFINITY Canister SDK</code>.<br />
When I run the below command, directory <code>dfx</code> (under <code>/bin</code>) is not created and subsequently the <code>dfx</code> command is not recognized:</p>
<pre class=""lang-bsh prettyprint-override""><code>adel@adel-VirtualBox:~$ sh -ci &quot;$(curl -fsSL https://sdk.dfinity.org/install.sh)&quot;

info: Executing DFINITY SDK install script, commit: dd2134837704e0daca074dd3fe09ee4ff6ebbf97

 DFINITY SDK 
 Please READ the following license: 

DFINITY Foundation -- All rights reserved. This is an ALPHA version
of the DFINITY Canister Software Development Kit (SDK). Permission is hereby granted
to use AS IS and only subject to the Alpha DFINITY Canister SDK License Agreement which
can be found here [https://sdk.dfinity.org/sdk-license-agreement.txt]. It comes with NO WARRANTY.


Do you agree and wish to install the DFINITY ALPHA SDK [y/N]?
y

info: Version found: 0.6.10
info: Creating uninstall script in ~/.cache/dfinity
info: uninstall path=/home/adel/.cache/dfinity/uninstall.sh
info: Checking for latest release...
Will install in: /home/adel/bin
info: Installed /home/adel/bin/dfx

adel@adel-VirtualBox:~$ dfx --version

Command 'dfx' not found, did you mean:

  command 'fx' from snap fx (11.1.0)
  command 'dfix' from snap dfix (0.3.5)
  command 'dx' from deb dx (1:4.4.4-12build2)
  command 'dex' from deb dex (0.8.0-2)
  command 'dfc' from deb dfc (3.1.1-1)
  command 'df' from deb coreutils (8.30-3ubuntu2)

See 'snap info &lt;snapname&gt;' for additional versions.

adel@adel-VirtualBox:~$ cd /bin
adel@adel-VirtualBox:/bin$ cd dfx
bash: cd: dfx: No such file or directory
</code></pre>
<p>Below is my Ubuntu version:</p>
<pre class=""lang-bsh prettyprint-override""><code>adel@adel-VirtualBox:~$ lsb_release -a

No LSB modules are available.
Distributor ID: Ubuntu
Description:    Ubuntu 20.04.1 LTS
Release:    20.04
Codename:   focal
</code></pre>
",2292,5,2,2,ubuntu;dfinity,2020-10-06 18:21:31,2020-10-06 18:21:31,2022-07-30 00:08:46,below is my ubuntu version ,unable to install dfinity canister sdk on ubuntu
77,360593,11292217,Run django app via nginx+uwsgi in a subpath,"<p>I want to run a simple test project in a subdirectory alias on our development server. The basic setup is an nginx with a location that passes everything in a subdirectory to the wsgi application.</p>

<p>Django obviously does not understand that it runs in an subdirectory alias, which completely destroys URL generation and parsing.<br>
I could not find any prefix-like setting in the docs and my google fu also did not help that much... so I'm asking here instead.</p>

<p>The only thing I did find was the setting FORCE_SCRIPT_NAME which at least fixes the URL generation. (see: <a href=""http://docs.webfaction.com/software/django/config.html#mounting-a-django-application-on-a-subpath"">http://docs.webfaction.com/software/django/config.html#mounting-a-django-application-on-a-subpath</a>)<br>
Sadly this does not fix the urlconf parsing, even though the mentioned site suggests that.</p>

<p>Is it possible to run a django application in a subdirectory alias and if so, how?</p>

<p>nginx config:</p>

<pre><code>server {
        location /fancyprojectname/static {
                alias /srv/fancyprojectname/static;
        }

        location /fancyprojectname/ {
                uwsgi_pass unix://var/run/uwsgi/app/fancyprojectname/socket;
                include uwsgi_params;
        }
}
</code></pre>

<p><strong>Edit</strong></p>

<p>So, setting ""uwsgi_param SCRIPT_NAME /fancyprojectname;"" in the nginx location makes FORCE_SCRIPT_NAME unnecessary - sadly the URL matching still does not work.</p>

<pre><code>from django.conf.urls import patterns, include, url

# Uncomment the next two lines to enable the admin:
from django.contrib import admin
admin.autodiscover()

urlpatterns = patterns('',
    # Uncomment the admin/doc line below to enable admin documentation:
    # url(r'^admin/doc/', include('django.contrib.admindocs.urls')),

    # Uncomment the next line to enable the admin:
    url(r'^admin/', include(admin.site.urls)),
)
</code></pre>

<p>What I think what is happening: As the admin regex starts with ""^admin"" and the actual URL is ""fancyprojectname/admin/"", Django can't match the URLs correctly, even though the SCRIPT_NAME is set.</p>

<p><strong>The solution</strong></p>

<p>So, it was indeed a problem with SCRIPT_NAME.</p>

<p>The <a href=""http://www.python.org/dev/peps/pep-0333/"">WSGI specification</a> says the following:</p>

<blockquote>
  <p>SCRIPT_NAME
      The initial portion of the request URL's ""path"" that corresponds to the application object, so that the application knows its virtual
  ""location"". This may be an empty string, if the application
  corresponds to the ""root"" of the server.  </p>
  
  <p>PATH_INFO
  The remainder of the request URL's ""path"", designating the virtual ""location"" of the request's target within the application. This may be
  an empty string, if the request URL targets the application root and
  does not have a trailing slash.</p>
</blockquote>

<p>Nginx does not set SCRIPT_NAME automatically, so this needs to be set in any case. Afterwards PATH_INFO is wrong, because in the default setup Nginx sets this to $document_uri, which would be the full URL.</p>

<p>""uwsgi_modifier1 30;"" tells Nginx to set UWSGI_MODIFIER_MANAGE_PATH_INFO, which in turn tells UWSGI to strip off the SCRIPT_NAME of the PATH_INFO.</p>

<p>The combination of these settings seem to work, as Django can now generate AND match URLs correctly.</p>
",10783,4,19,2,django;nginx,2012-07-02 13:53:33,2012-07-02 13:53:33,2022-07-29 14:06:15,i want to run a simple test project in a subdirectory alias on our development server  the basic setup is an nginx with a location that passes everything in a subdirectory to the wsgi application  is it possible to run a django application in a subdirectory alias and if so  how  nginx config  edit so  setting uwsgi_param script_name  fancyprojectname  in the nginx location makes force_script_name unnecessary   sadly the url matching still does not work  what i think what is happening  as the admin regex starts with  admin and the actual url is fancyprojectname admin   django can t match the urls correctly  even though the script_name is set  the solution so  it was indeed a problem with script_name  the  says the following  nginx does not set script_name automatically  so this needs to be set in any case  afterwards path_info is wrong  because in the default setup nginx sets this to  document_uri  which would be the full url  uwsgi_modifier   tells nginx to set uwsgi_modifier_manage_path_info  which in turn tells uwsgi to strip off the script_name of the path_info  the combination of these settings seem to work  as django can now generate and match urls correctly ,run django app via nginx uwsgi in a subpath
78,18173162,73144829,Cannot push .net MAUI app to iPhone from Windows Computer - ApplicationVerificationFailed,"<p>Up until this week I have been using Xamarin.Forms for my mobile development.  I got a request for a simple app and I thought I would take this opportunity to use .net MAUI.  Things were going fine and I tried the app on Windows, on Android and then attempted to try it on iPhone.  I cannot get Visual Studio 2022 17.3.0 Preview 2.0 to install the app on the iPhone.</p>
<p>I have a paid Apple Developer account and I can install and run my Xamarin.Forms apps on an iPhone just fine.  For my Xamarin.Forms app I use Automatic Provisioning for bundle signing.</p>
<p>I can't even get the blank .net MAUI app to install on the iPhone.  I tried the default values of Bundle Signing (Scheme = Manual, Signing Identity = Developer (automatic)).  I have tried Automatic Provisioning (configuring Automatic Provisioning game me a green check mark).  Every time I push that little green play button I get ApplicationVerificationFailed (A valid provisioning profile for this executable was not found).</p>
<p>Visual Studio 2022 17.3.0 Preview 2.0 on Windows 11 64-bit.<br />
iPhone 11 Pro Max - software version 15.5 (plugged directly into the Windows machine)</p>
<p>Did .net MAUI devolve from Xamarin.Forms in this capability or am I missing something?</p>
<p>Thanks</p>
",102,2,1,4,ios;.net;visual-studio-2022;maui,2022-07-28 00:28:52,2022-07-28 00:28:52,2022-07-29 05:57:21,up until this week i have been using xamarin forms for my mobile development   i got a request for a simple app and i thought i would take this opportunity to use  net maui   things were going fine and i tried the app on windows  on android and then attempted to try it on iphone   i cannot get visual studio     preview   to install the app on the iphone  i have a paid apple developer account and i can install and run my xamarin forms apps on an iphone just fine   for my xamarin forms app i use automatic provisioning for bundle signing  i can t even get the blank  net maui app to install on the iphone   i tried the default values of bundle signing  scheme   manual  signing identity   developer  automatic     i have tried automatic provisioning  configuring automatic provisioning game me a green check mark    every time i push that little green play button i get applicationverificationfailed  a valid provisioning profile for this executable was not found   did  net maui devolve from xamarin forms in this capability or am i missing something  thanks,cannot push  net maui app to iphone from windows computer   applicationverificationfailed
79,19414577,73105957,STM32 Memory Dump and Extracting Secret Key,"<p>I am quite new at embedded development and started with a STM32F429 board to improve myself.</p>
<p>I have just developed a basic Caesar encryption application for my board. It is working well, and defined the secret key as &quot;3&quot;. Now I would like to extract this super secret(!) key from my device.</p>
<ol>
<li>How can I do it? Should I dump the memory or firmware of my device, and how?</li>
<li>May you suggest me any software for this proccess? (Not ST Utility or STM softwares please. Because I would like to try gained experiences on other devices as well.)</li>
</ol>
<p>Thanks!</p>
",62,1,0,4,memory;embedded;stm32;reverse-engineering,2022-07-25 11:13:20,2022-07-25 11:13:20,2022-07-29 00:20:47,i am quite new at embedded development and started with a stmf board to improve myself  i have just developed a basic caesar encryption application for my board  it is working well  and defined the secret key as     now i would like to extract this super secret    key from my device  thanks ,stm memory dump and extracting secret key
80,10554257,73148727,Apache Beam multi language &quot;java.lang.UnsupportedOperationException: The transform beam:transform:external:v1 is currently not supported.&quot; error,"<p>I am trying to use Apache Beam multi language explained in <a href=""https://beam.apache.org/documentation/sdks/java-multi-language-pipelines/"" rel=""nofollow noreferrer"">https://beam.apache.org/documentation/sdks/java-multi-language-pipelines/</a>.
However when I run the same code showed in the tutorial(can be found here <a href=""https://github.com/apache/beam/blob/master/examples/multi-language/src/main/java/org/apache/beam/examples/multilanguage/PythonDataframeWordCount.java"" rel=""nofollow noreferrer"">https://github.com/apache/beam/blob/master/examples/multi-language/src/main/java/org/apache/beam/examples/multilanguage/PythonDataframeWordCount.java</a>), I get the error when backend is Flink.</p>
<p>I ran the code with the command.</p>
<pre><code>mvn compile -e exec:java -Dexec.mainClass=org.apache.beam.examples.WordCountPythonExternal -Dexec.args=&quot;--runner=FlinkRunner --inputFile=./data/sample.txt --output=./results/counts2&quot; -Pflink-runner
</code></pre>
<pre><code>java.lang.UnsupportedOperationException: The transform beam:transform:external:v1 is currently not supported.
        at org.apache.beam.runners.flink.FlinkBatchPipelineTranslator.visitPrimitiveTransform(FlinkBatchPipelineTranslator.java:99)
        at org.apache.beam.sdk.runners.TransformHierarchy$Node.visit(TransformHierarchy.java:593)
        at org.apache.beam.sdk.runners.TransformHierarchy$Node.visit(TransformHierarchy.java:585)
        at org.apache.beam.sdk.runners.TransformHierarchy$Node.visit(TransformHierarchy.java:585)
        at org.apache.beam.sdk.runners.TransformHierarchy$Node.access$500(TransformHierarchy.java:240)
        at org.apache.beam.sdk.runners.TransformHierarchy.visit(TransformHierarchy.java:214)
        at org.apache.beam.sdk.Pipeline.traverseTopologically(Pipeline.java:469)
        at org.apache.beam.runners.flink.FlinkPipelineTranslator.translate(FlinkPipelineTranslator.java:38)
        at org.apache.beam.runners.flink.FlinkBatchPipelineTranslator.translate(FlinkBatchPipelineTranslator.java:54)
        at org.apache.beam.runners.flink.FlinkPipelineExecutionEnvironment.translate(FlinkPipelineExecutionEnvironment.java:115)
        at org.apache.beam.runners.flink.FlinkRunner.run(FlinkRunner.java:104)
        at org.apache.beam.sdk.Pipeline.run(Pipeline.java:323)
        at org.apache.beam.sdk.Pipeline.run(Pipeline.java:309)
        at org.apache.beam.examples.WordCountPythonExternal.runWordCount(WordCountPythonExternal.java:174)
        at org.apache.beam.examples.WordCountPythonExternal.main(WordCountPythonExternal.java:181)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.base/java.lang.reflect.Method.invoke(Method.java:566)
        at org.codehaus.mojo.exec.ExecJavaMojo$1.run(ExecJavaMojo.java:282)
        at java.base/java.lang.Thread.run(Thread.java:829)
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 7.205 s
[INFO] Finished at: 2022-07-28T07:02:16+00:00
[INFO] Final Memory: 44M/188M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.6.0:java (default-cli) on project word-count-beam: An exception occured while executing the Java class. The transform beam:transform:external:v1 is currently not supported. -&gt; [Help 1]
org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.6.0:java (default-cli) on project word-count-beam: An exception occured while executing the Java class. The transform beam:transform:external:v1 is currently not supported.
        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:216)
        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)
        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)
        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116)
        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80)
        at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)
        at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:120)
        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:355)
        at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:155)
        at org.apache.maven.cli.MavenCli.execute(MavenCli.java:584)
        at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:216)
        at org.apache.maven.cli.MavenCli.main(MavenCli.java:160)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.base/java.lang.reflect.Method.invoke(Method.java:566)
        at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)
        at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)
        at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)
        at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)
Caused by: org.apache.maven.plugin.MojoExecutionException: An exception occured while executing the Java class. The transform beam:transform:external:v1 is currently not supported.
        at org.codehaus.mojo.exec.ExecJavaMojo.execute(ExecJavaMojo.java:339)
        at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:132)
        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:208)
        ... 19 more
Caused by: java.lang.UnsupportedOperationException: The transform beam:transform:external:v1 is currently not supported.
        at org.apache.beam.runners.flink.FlinkBatchPipelineTranslator.visitPrimitiveTransform(FlinkBatchPipelineTranslator.java:99)
        at org.apache.beam.sdk.runners.TransformHierarchy$Node.visit(TransformHierarchy.java:593)
        at org.apache.beam.sdk.runners.TransformHierarchy$Node.visit(TransformHierarchy.java:585)
        at org.apache.beam.sdk.runners.TransformHierarchy$Node.visit(TransformHierarchy.java:585)
        at org.apache.beam.sdk.runners.TransformHierarchy$Node.access$500(TransformHierarchy.java:240)
        at org.apache.beam.sdk.runners.TransformHierarchy.visit(TransformHierarchy.java:214)
        at org.apache.beam.sdk.Pipeline.traverseTopologically(Pipeline.java:469)
        at org.apache.beam.runners.flink.FlinkPipelineTranslator.translate(FlinkPipelineTranslator.java:38)
        at org.apache.beam.runners.flink.FlinkBatchPipelineTranslator.translate(FlinkBatchPipelineTranslator.java:54)
        at org.apache.beam.runners.flink.FlinkPipelineExecutionEnvironment.translate(FlinkPipelineExecutionEnvironment.java:115)
        at org.apache.beam.runners.flink.FlinkRunner.run(FlinkRunner.java:104)
        at org.apache.beam.sdk.Pipeline.run(Pipeline.java:323)
        at org.apache.beam.sdk.Pipeline.run(Pipeline.java:309)
        at org.apache.beam.examples.WordCountPythonExternal.runWordCount(WordCountPythonExternal.java:174)
        at org.apache.beam.examples.WordCountPythonExternal.main(WordCountPythonExternal.java:181)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.base/java.lang.reflect.Method.invoke(Method.java:566)
        at org.codehaus.mojo.exec.ExecJavaMojo$1.run(ExecJavaMojo.java:282)
        at java.base/java.lang.Thread.run(Thread.java:829)
[ERROR] 
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException
</code></pre>
<p>When backend is Direct Runner, system shows trace below. Then stucks there. I ran the code using below command
I ran the code with the command.</p>
<pre><code>mvn compile -e exec:java -Dexec.mainClass=org.apache.beam.examples.WordCountPythonExternal -Dexec.args=&quot;--inputFile=./data/sample.txt --output=./results/counts2&quot; -Pdirect-runner
</code></pre>
<pre><code>Warning: JAVA_HOME environment variable is not set.
[INFO] Error stacktraces are turned on.
[INFO] Scanning for projects...
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building word-count-beam 0.1
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ word-count-beam ---
[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!
[INFO] skip non existing resourceDirectory /home/ubuntu/beam_projs/tmp_exp/word-count-beam/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.7.0:compile (default-compile) @ word-count-beam ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- exec-maven-plugin:1.6.0:java (default-cli) @ word-count-beam ---
Jul 28, 2022 7:04:20 AM org.apache.beam.sdk.extensions.python.PythonService start
INFO: Running bootstrap command [python3, /tmp/bootstrap_beam_venv8817961971129663193.py]
/tmp/bootstrap_beam_venv8817961971129663193.py:69: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  return distutils.version.StrictVersion(s)
/tmp/bootstrap_beam_venv8817961971129663193.py:71: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  return distutils.version.StrictVersion('0.0')
Jul 28, 2022 7:04:20 AM org.apache.beam.sdk.extensions.python.PythonService start
INFO: /home/ubuntu/.apache_beam/cache/venvs/py-3.8-beam-2.40.0-da39a3ee5e6b4b0d3255bfef95601890afd80709/bin/python
Jul 28, 2022 7:04:20 AM org.apache.beam.sdk.extensions.python.PythonService start
INFO: Starting python service with arguments [/home/ubuntu/.apache_beam/cache/venvs/py-3.8-beam-2.40.0-da39a3ee5e6b4b0d3255bfef95601890afd80709/bin/python, -m, apache_beam.runners.portability.expansion_service_main, --port, 39435, --fully_qualified_name_glob, *]
INFO:root:Default Python SDK image for environment is apache/beam_python3.8_sdk:2.40.0
INFO:root:No image given, using default Python SDK image
INFO:root:Default Python SDK image for environment is apache/beam_python3.8_sdk:2.40.0
INFO:root:Python SDK container image set to &quot;apache/beam_python3.8_sdk:2.40.0&quot; for Docker environment
INFO:__main__:Listening for expansion requests at 39435
INFO:root:Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.
INFO:__main__:Shutting down expansion service.
</code></pre>
<p>What could be the reason for that any help is appreciated. My aim is to make system work Flink backend, direct runner experimentation is just for seeing whether problem is related to backend.
You can find my pom.xml file below</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!--
    Licensed to the Apache Software Foundation (ASF) under one or more
    contributor license agreements.  See the NOTICE file distributed with
    this work for additional information regarding copyright ownership.
    The ASF licenses this file to You under the Apache License, Version 2.0
    (the &quot;License&quot;); you may not use this file except in compliance with
    the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.
--&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

  &lt;groupId&gt;org.example&lt;/groupId&gt;
  &lt;artifactId&gt;word-count-beam&lt;/artifactId&gt;
  &lt;version&gt;0.1&lt;/version&gt;

  &lt;packaging&gt;jar&lt;/packaging&gt;

  &lt;properties&gt;
    &lt;beam.version&gt;2.40.0&lt;/beam.version&gt;

    &lt;bigquery.version&gt;v2-rev20211129-1.32.1&lt;/bigquery.version&gt;
    &lt;google-api-client.version&gt;1.32.1&lt;/google-api-client.version&gt;
    &lt;guava.version&gt;31.1-jre&lt;/guava.version&gt;
    &lt;hamcrest.version&gt;2.1&lt;/hamcrest.version&gt;
    &lt;jackson.version&gt;2.13.0&lt;/jackson.version&gt;
    &lt;joda.version&gt;2.10.10&lt;/joda.version&gt;
    &lt;junit.version&gt;4.13.1&lt;/junit.version&gt;
    &lt;libraries-bom.version&gt;25.2.0&lt;/libraries-bom.version&gt;
    &lt;maven-compiler-plugin.version&gt;3.7.0&lt;/maven-compiler-plugin.version&gt;
    &lt;maven-exec-plugin.version&gt;1.6.0&lt;/maven-exec-plugin.version&gt;
    &lt;maven-jar-plugin.version&gt;3.0.2&lt;/maven-jar-plugin.version&gt;
    &lt;maven-shade-plugin.version&gt;3.1.0&lt;/maven-shade-plugin.version&gt;
    &lt;mockito.version&gt;3.7.7&lt;/mockito.version&gt;
    &lt;pubsub.version&gt;v1-rev20211130-1.32.1&lt;/pubsub.version&gt;
    &lt;slf4j.version&gt;1.7.30&lt;/slf4j.version&gt;
    &lt;spark.version&gt;2.4.8&lt;/spark.version&gt;
    &lt;hadoop.version&gt;2.10.1&lt;/hadoop.version&gt;
    &lt;maven-surefire-plugin.version&gt;3.0.0-M5&lt;/maven-surefire-plugin.version&gt;
    &lt;nemo.version&gt;0.1&lt;/nemo.version&gt;
    &lt;flink.artifact.name&gt;beam-runners-flink-1.15&lt;/flink.artifact.name&gt;
  &lt;/properties&gt;

  &lt;repositories&gt;
    &lt;repository&gt;
      &lt;id&gt;apache.snapshots&lt;/id&gt;
      &lt;name&gt;Apache Development Snapshot Repository&lt;/name&gt;
      &lt;url&gt;https://repository.apache.org/content/repositories/snapshots/&lt;/url&gt;
      &lt;releases&gt;
        &lt;enabled&gt;false&lt;/enabled&gt;
      &lt;/releases&gt;
      &lt;snapshots&gt;
        &lt;enabled&gt;true&lt;/enabled&gt;
      &lt;/snapshots&gt;
    &lt;/repository&gt;
  &lt;/repositories&gt;

  &lt;build&gt;
    &lt;plugins&gt;
      &lt;plugin&gt;
        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
        &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
        &lt;version&gt;${maven-compiler-plugin.version}&lt;/version&gt;
        &lt;configuration&gt;
        &lt;!--
          &lt;source&gt;1.8&lt;/source&gt;
          &lt;target&gt;1.8&lt;/target&gt;
          --&gt;
          &lt;release&gt;11&lt;/release&gt;  &lt;!--or &lt;release&gt;10&lt;/release&gt;--&gt;
        &lt;/configuration&gt;
      &lt;/plugin&gt;

      &lt;plugin&gt;
        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
        &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;
        &lt;version&gt;${maven-surefire-plugin.version}&lt;/version&gt;
        &lt;configuration&gt;
          &lt;parallel&gt;all&lt;/parallel&gt;
          &lt;threadCount&gt;4&lt;/threadCount&gt;
          &lt;redirectTestOutputToFile&gt;true&lt;/redirectTestOutputToFile&gt;
        &lt;/configuration&gt;
        &lt;dependencies&gt;
          &lt;dependency&gt;
            &lt;groupId&gt;org.apache.maven.surefire&lt;/groupId&gt;
            &lt;artifactId&gt;surefire-junit47&lt;/artifactId&gt;
            &lt;version&gt;${maven-surefire-plugin.version}&lt;/version&gt;
          &lt;/dependency&gt;
        &lt;/dependencies&gt;
      &lt;/plugin&gt;

      &lt;!-- Ensure that the Maven jar plugin runs before the Maven
        shade plugin by listing the plugin higher within the file. --&gt;
      &lt;plugin&gt;
        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
        &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;
        &lt;version&gt;${maven-jar-plugin.version}&lt;/version&gt;
      &lt;/plugin&gt;

      &lt;!--
        Configures `mvn package` to produce a bundled jar (&quot;fat jar&quot;) for runners
        that require this for job submission to a cluster.
      --&gt;
      &lt;plugin&gt;
        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
        &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;
        &lt;version&gt;${maven-shade-plugin.version}&lt;/version&gt;
        &lt;executions&gt;
          &lt;execution&gt;
            &lt;phase&gt;package&lt;/phase&gt;
            &lt;goals&gt;
              &lt;goal&gt;shade&lt;/goal&gt;
            &lt;/goals&gt;
            &lt;configuration&gt;
              &lt;finalName&gt;${project.artifactId}-bundled-${project.version}&lt;/finalName&gt;
              &lt;filters&gt;
                &lt;filter&gt;
                  &lt;artifact&gt;*:*&lt;/artifact&gt;
                  &lt;excludes&gt;
                    &lt;exclude&gt;META-INF/LICENSE&lt;/exclude&gt;
                    &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt;
                    &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt;
                    &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt;
                  &lt;/excludes&gt;
                &lt;/filter&gt;
              &lt;/filters&gt;
              &lt;transformers&gt;
                &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer&quot;/&gt;
                &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.AppendingTransformer&quot;&gt;
                  &lt;resource&gt;reference.conf&lt;/resource&gt;
                &lt;/transformer&gt;
              &lt;/transformers&gt;
            &lt;/configuration&gt;
          &lt;/execution&gt;
        &lt;/executions&gt;
      &lt;/plugin&gt;
    &lt;/plugins&gt;

    &lt;pluginManagement&gt;
      &lt;plugins&gt;
        &lt;plugin&gt;
          &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;
          &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt;
          &lt;version&gt;${maven-exec-plugin.version}&lt;/version&gt;
          &lt;configuration&gt;
            &lt;cleanupDaemonThreads&gt;false&lt;/cleanupDaemonThreads&gt;
          &lt;/configuration&gt;
          &lt;executions&gt;
              &lt;execution&gt;
                  &lt;id&gt;run-selenium&lt;/id&gt;
                  &lt;phase&gt;integration-test&lt;/phase&gt;
                  &lt;goals&gt;&lt;goal&gt;java&lt;/goal&gt;&lt;/goals&gt;
              &lt;/execution&gt;
          &lt;/executions&gt;
        &lt;/plugin&gt;
      &lt;/plugins&gt;
    &lt;/pluginManagement&gt;
  &lt;/build&gt;

  &lt;profiles&gt;
    &lt;profile&gt;
      &lt;id&gt;direct-runner&lt;/id&gt;
      &lt;activation&gt;
        &lt;activeByDefault&gt;true&lt;/activeByDefault&gt;
      &lt;/activation&gt;
      &lt;!-- Makes the DirectRunner available when running a pipeline. --&gt;
      &lt;dependencies&gt;
        &lt;dependency&gt;
          &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;
          &lt;artifactId&gt;beam-runners-direct-java&lt;/artifactId&gt;
          &lt;version&gt;${beam.version}&lt;/version&gt;
          &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;
      &lt;/dependencies&gt;
    &lt;/profile&gt;

   &lt;profile&gt;
      &lt;id&gt;portable-runner&lt;/id&gt;
      &lt;activation&gt;
        &lt;activeByDefault&gt;true&lt;/activeByDefault&gt;
      &lt;/activation&gt;
      &lt;!-- Makes the PortableRunner available when running a pipeline. --&gt;
      &lt;dependencies&gt;
        &lt;dependency&gt;
          &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;
          &lt;artifactId&gt;beam-runners-portability-java&lt;/artifactId&gt;
          &lt;version&gt;${beam.version}&lt;/version&gt;
          &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;
      &lt;/dependencies&gt;
    &lt;/profile&gt;

    &lt;profile&gt;
      &lt;id&gt;dataflow-runner&lt;/id&gt;
      &lt;!-- Makes the DataflowRunner available when running a pipeline. --&gt;
      &lt;dependencies&gt;
        &lt;dependency&gt;
          &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;
          &lt;artifactId&gt;beam-runners-google-cloud-dataflow-java&lt;/artifactId&gt;
          &lt;version&gt;${beam.version}&lt;/version&gt;
          &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;
      &lt;/dependencies&gt;
    &lt;/profile&gt;

    &lt;profile&gt;
      &lt;id&gt;flink-runner&lt;/id&gt;
      &lt;!-- Makes the FlinkRunner available when running a pipeline. --&gt;
      &lt;dependencies&gt;
        &lt;dependency&gt;
          &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;
          &lt;!-- Please see the Flink Runner page for an up-to-date list
               of supported Flink versions and their artifact names:
               https://beam.apache.org/documentation/runners/flink/ --&gt;
          &lt;artifactId&gt;${flink.artifact.name}&lt;/artifactId&gt;
          &lt;version&gt;${beam.version}&lt;/version&gt;
          &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;
      &lt;/dependencies&gt;
    &lt;/profile&gt;

    &lt;profile&gt;
      &lt;id&gt;spark-runner&lt;/id&gt;
      &lt;!-- Makes the SparkRunner available when running a pipeline. Additionally,
           overrides some Spark dependencies to Beam-compatible versions. --&gt;
      &lt;properties&gt;
        &lt;netty.version&gt;4.1.17.Final&lt;/netty.version&gt;
      &lt;/properties&gt;
      &lt;dependencies&gt;
        &lt;dependency&gt;
          &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;
          &lt;artifactId&gt;beam-runners-spark&lt;/artifactId&gt;
          &lt;version&gt;${beam.version}&lt;/version&gt;
          &lt;scope&gt;runtime&lt;/scope&gt;
          &lt;exclusions&gt;
            &lt;exclusion&gt;
              &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
              &lt;artifactId&gt;jul-to-slf4j&lt;/artifactId&gt;
            &lt;/exclusion&gt;
          &lt;/exclusions&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
          &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;
          &lt;artifactId&gt;beam-sdks-java-io-hadoop-file-system&lt;/artifactId&gt;
          &lt;version&gt;${beam.version}&lt;/version&gt;
          &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
          &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
          &lt;artifactId&gt;spark-streaming_2.11&lt;/artifactId&gt;
          &lt;version&gt;${spark.version}&lt;/version&gt;
          &lt;scope&gt;runtime&lt;/scope&gt;
          &lt;exclusions&gt;
            &lt;exclusion&gt;
              &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
              &lt;artifactId&gt;jul-to-slf4j&lt;/artifactId&gt;
            &lt;/exclusion&gt;
          &lt;/exclusions&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
          &lt;groupId&gt;com.fasterxml.jackson.module&lt;/groupId&gt;
          &lt;artifactId&gt;jackson-module-scala_2.11&lt;/artifactId&gt;
          &lt;version&gt;${jackson.version}&lt;/version&gt;
          &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;!-- [BEAM-3519] GCP IO exposes netty on its API surface, causing conflicts with runners --&gt;
        &lt;dependency&gt;
          &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;
          &lt;artifactId&gt;beam-sdks-java-io-google-cloud-platform&lt;/artifactId&gt;
          &lt;version&gt;${beam.version}&lt;/version&gt;
          &lt;exclusions&gt;
            &lt;exclusion&gt;
              &lt;groupId&gt;io.grpc&lt;/groupId&gt;
              &lt;artifactId&gt;grpc-netty&lt;/artifactId&gt;
            &lt;/exclusion&gt;
            &lt;exclusion&gt;
              &lt;groupId&gt;io.netty&lt;/groupId&gt;
              &lt;artifactId&gt;netty-handler&lt;/artifactId&gt;
            &lt;/exclusion&gt;
          &lt;/exclusions&gt;
        &lt;/dependency&gt;
      &lt;/dependencies&gt;
    &lt;/profile&gt;
    &lt;profile&gt;
      &lt;id&gt;samza-runner&lt;/id&gt;
      &lt;dependencies&gt;
        &lt;dependency&gt;
          &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;
          &lt;artifactId&gt;beam-runners-samza&lt;/artifactId&gt;
          &lt;version&gt;${beam.version}&lt;/version&gt;
          &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;
      &lt;/dependencies&gt;
    &lt;/profile&gt;
    &lt;profile&gt;
      &lt;id&gt;twister2-runner&lt;/id&gt;
      &lt;dependencies&gt;
        &lt;dependency&gt;
          &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;
          &lt;artifactId&gt;beam-runners-twister2&lt;/artifactId&gt;
          &lt;version&gt;${beam.version}&lt;/version&gt;
          &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;
      &lt;/dependencies&gt;
    &lt;/profile&gt;
    &lt;profile&gt;
      &lt;id&gt;nemo-runner&lt;/id&gt;
      &lt;dependencies&gt;
        &lt;dependency&gt;
          &lt;groupId&gt;org.apache.nemo&lt;/groupId&gt;
          &lt;artifactId&gt;nemo-compiler-frontend-beam&lt;/artifactId&gt;
          &lt;version&gt;${nemo.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
          &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
          &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt;
          &lt;version&gt;${hadoop.version}&lt;/version&gt;
          &lt;exclusions&gt;
            &lt;exclusion&gt;
              &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
              &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;
            &lt;/exclusion&gt;
            &lt;exclusion&gt;
              &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
              &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;
            &lt;/exclusion&gt;
          &lt;/exclusions&gt;
        &lt;/dependency&gt;
      &lt;/dependencies&gt;
    &lt;/profile&gt;

    &lt;profile&gt;
      &lt;id&gt;jet-runner&lt;/id&gt;
      &lt;dependencies&gt;
        &lt;dependency&gt;
          &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;
          &lt;artifactId&gt;beam-runners-jet&lt;/artifactId&gt;
          &lt;version&gt;${beam.version}&lt;/version&gt;
          &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;
      &lt;/dependencies&gt;
    &lt;/profile&gt;

  &lt;/profiles&gt;

  &lt;dependencies&gt;
    &lt;!-- Adds a dependency on the Beam SDK. --&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;
      &lt;artifactId&gt;beam-sdks-java-core&lt;/artifactId&gt;
      &lt;version&gt;${beam.version}&lt;/version&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
      &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;
      &lt;artifactId&gt;beam-sdks-java-extensions-python&lt;/artifactId&gt;
      &lt;version&gt;${beam.version}&lt;/version&gt;
    &lt;/dependency&gt;
        &lt;!-- Thanks for using https://jar-download.com --&gt;

    &lt;!-- https://mvnrepository.com/artifact/org.apache.beam/beam-sdks-java-extensions-protobuf --&gt;
  &lt;dependency&gt;
      &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;
      &lt;artifactId&gt;beam-sdks-java-extensions-protobuf&lt;/artifactId&gt;
      &lt;version&gt;${beam.version}&lt;/version&gt;
  &lt;/dependency&gt;

    &lt;!-- Adds a dependency on the Beam Google Cloud Platform IO module. --&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;
      &lt;artifactId&gt;beam-sdks-java-io-google-cloud-platform&lt;/artifactId&gt;
      &lt;version&gt;${beam.version}&lt;/version&gt;
    &lt;/dependency&gt;


    &lt;dependency&gt;
      &lt;groupId&gt;com.google.api-client&lt;/groupId&gt;
      &lt;artifactId&gt;google-api-client&lt;/artifactId&gt;
      &lt;version&gt;${google-api-client.version}&lt;/version&gt;
      &lt;exclusions&gt;
        &lt;!-- Exclude an old version of guava that is being pulled
             in by a transitive dependency of google-api-client --&gt;
        &lt;exclusion&gt;
          &lt;groupId&gt;com.google.guava&lt;/groupId&gt;
          &lt;artifactId&gt;guava-jdk5&lt;/artifactId&gt;
        &lt;/exclusion&gt;
      &lt;/exclusions&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
      &lt;groupId&gt;com.google.apis&lt;/groupId&gt;
      &lt;artifactId&gt;google-api-services-bigquery&lt;/artifactId&gt;
      &lt;version&gt;${bigquery.version}&lt;/version&gt;
      &lt;exclusions&gt;
        &lt;!-- Exclude an old version of guava that is being pulled
             in by a transitive dependency of google-api-client --&gt;
        &lt;exclusion&gt;
          &lt;groupId&gt;com.google.guava&lt;/groupId&gt;
          &lt;artifactId&gt;guava-jdk5&lt;/artifactId&gt;
        &lt;/exclusion&gt;
      &lt;/exclusions&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
      &lt;groupId&gt;com.google.http-client&lt;/groupId&gt;
      &lt;artifactId&gt;google-http-client&lt;/artifactId&gt;
      &lt;exclusions&gt;
        &lt;!-- Exclude an old version of guava that is being pulled
             in by a transitive dependency of google-api-client --&gt;
        &lt;exclusion&gt;
          &lt;groupId&gt;com.google.guava&lt;/groupId&gt;
          &lt;artifactId&gt;guava-jdk5&lt;/artifactId&gt;
        &lt;/exclusion&gt;
      &lt;/exclusions&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
      &lt;groupId&gt;com.google.apis&lt;/groupId&gt;
      &lt;artifactId&gt;google-api-services-pubsub&lt;/artifactId&gt;
      &lt;version&gt;${pubsub.version}&lt;/version&gt;
      &lt;exclusions&gt;
        &lt;!-- Exclude an old version of guava that is being pulled
             in by a transitive dependency of google-api-client --&gt;
        &lt;exclusion&gt;
          &lt;groupId&gt;com.google.guava&lt;/groupId&gt;
          &lt;artifactId&gt;guava-jdk5&lt;/artifactId&gt;
        &lt;/exclusion&gt;
      &lt;/exclusions&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
      &lt;groupId&gt;joda-time&lt;/groupId&gt;
      &lt;artifactId&gt;joda-time&lt;/artifactId&gt;
      &lt;version&gt;${joda.version}&lt;/version&gt;
    &lt;/dependency&gt;

    &lt;!-- Add slf4j API frontend binding with JUL backend --&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
      &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;
      &lt;version&gt;${slf4j.version}&lt;/version&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
      &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
      &lt;artifactId&gt;slf4j-jdk14&lt;/artifactId&gt;
      &lt;version&gt;${slf4j.version}&lt;/version&gt;
      &lt;!-- When loaded at runtime this will wire up slf4j to the JUL backend --&gt;
      &lt;scope&gt;runtime&lt;/scope&gt;
    &lt;/dependency&gt;

    &lt;!-- Hamcrest and JUnit are required dependencies of PAssert,
         which is used in the main code of DebuggingWordCount example. --&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.hamcrest&lt;/groupId&gt;
      &lt;artifactId&gt;hamcrest-core&lt;/artifactId&gt;
      &lt;version&gt;${hamcrest.version}&lt;/version&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
      &lt;groupId&gt;org.hamcrest&lt;/groupId&gt;
      &lt;artifactId&gt;hamcrest-library&lt;/artifactId&gt;
      &lt;version&gt;${hamcrest.version}&lt;/version&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
      &lt;groupId&gt;junit&lt;/groupId&gt;
      &lt;artifactId&gt;junit&lt;/artifactId&gt;
      &lt;version&gt;${junit.version}&lt;/version&gt;
    &lt;/dependency&gt;

    &lt;!-- The DirectRunner is needed for unit tests. --&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;
      &lt;artifactId&gt;beam-runners-direct-java&lt;/artifactId&gt;
      &lt;version&gt;${beam.version}&lt;/version&gt;
      &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
      &lt;groupId&gt;org.mockito&lt;/groupId&gt;
      &lt;artifactId&gt;mockito-core&lt;/artifactId&gt;
      &lt;version&gt;${mockito.version}&lt;/version&gt;
      &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;
  &lt;/dependencies&gt;

  &lt;dependencyManagement&gt;
    &lt;dependencies&gt;
      &lt;dependency&gt;
        &lt;groupId&gt;com.google.guava&lt;/groupId&gt;
        &lt;artifactId&gt;guava&lt;/artifactId&gt;
        &lt;version&gt;${guava.version}&lt;/version&gt;  &lt;!-- &quot;-jre&quot; for Java 8 or higher --&gt;
      &lt;/dependency&gt;
      &lt;!-- GCP libraries BOM sets the version for google http client --&gt;
      &lt;dependency&gt;
        &lt;groupId&gt;com.google.cloud&lt;/groupId&gt;
        &lt;artifactId&gt;libraries-bom&lt;/artifactId&gt;
        &lt;version&gt;${libraries-bom.version}&lt;/version&gt;
        &lt;type&gt;pom&lt;/type&gt;
        &lt;scope&gt;import&lt;/scope&gt;
      &lt;/dependency&gt;
    &lt;/dependencies&gt;
  &lt;/dependencyManagement&gt;
&lt;/project&gt;

</code></pre>
",46,1,1,3,maven;streaming;apache-beam,2022-07-28 10:17:54,2022-07-28 10:17:54,2022-07-28 20:45:58,i ran the code with the command ,apache beam multi language  java lang unsupportedoperationexception  the transform beam transform external v is currently not supported   error
81,6389484,73140897,"Production deployable, scalable and managed solution from Heroku","<p>I explored most of the options available in Heroku and none of them has a feasible and managed plan for Django based eCommerce web application. We basically don't want to manage the infrastructure and configurations, but would like to focus on coding and deploy it on a managed solution that is feasible to us.</p>
<p>Currently we have the following software stack on a development server and we would like to find a Heroku managed solution, yet scalable and production deployable.</p>
<ol>
<li>Linux OS</li>
<li>Postgres</li>
<li>Python 3.10</li>
<li>Django latest ( with and without REST APIs)</li>
<li>Vue.js</li>
<li>Gunicorn</li>
<li>Nginx</li>
<li>Let's Encrypt or any SSL</li>
<li>Redis</li>
<li>Celery</li>
<li>Github</li>
<li>Jenkins CI/CD (the code is automatically deployed on the development server by running a Jenkins job)</li>
<li>Integrated API: Stripe, Twilio, Google and etc.</li>
</ol>
<p>I would appreciate it if any one is using a managed server plan either from Heroku or Digital ocean so that we would like to explore that option and see if it is feasible to us. Sorry for missing my question earlier.</p>
<p>Best regards</p>
",19,0,0,2,django;heroku,2022-07-27 18:41:49,2022-07-27 18:41:49,2022-07-28 03:25:54,i explored most of the options available in heroku and none of them has a feasible and managed plan for django based ecommerce web application  we basically don t want to manage the infrastructure and configurations  but would like to focus on coding and deploy it on a managed solution that is feasible to us  currently we have the following software stack on a development server and we would like to find a heroku managed solution  yet scalable and production deployable  i would appreciate it if any one is using a managed server plan either from heroku or digital ocean so that we would like to explore that option and see if it is feasible to us  sorry for missing my question earlier  best regards,production deployable  scalable and managed solution from heroku
82,14960684,73142441,Compare multiple numbers in an array,"<p>I have this problem and I'm stuck. I'm a beginner in software development.</p>
<p>You get a list of N students and a list of grades for each student. Every student gets coins. A student which has bigger grade than his neighbors from list earns more coins than them. Find the coins which every student must receive. I have to give students coins which has bigger grade.</p>
<p>Data input</p>
<pre><code>3
Ionel
Mihai
Elena
9
10
8
</code></pre>
<p>Data output</p>
<pre><code>Ionel 1
Mihai 3
Elena 1.
</code></pre>
<p>Here is my code.</p>
<pre><code>          static void Main(string[] args)
        {
            int number = Convert.ToInt32(Console.ReadLine());
            string[] studentsList = FillArray(number);
            int[] studentsGrades = ConvertList(FillArray(number));
            PrintResult(studentsList, GetCoins(studentsGrades));

        }

        static string[] FillArray(int number)  // filling array with names of students
        {
            string[] result = new string[number];
            for (int i = 0; i &lt; number; i++)
            {
                result[i] = Console.ReadLine();
            }
            return result;
        }

        static int[] ConvertList(string[] array)
        {
            int[] result = new int[array.Length];
            for (int i = 0; i &lt; array.Length; i++)
            {
                result[i] = Convert.ToInt32(array[i]);
            }

            return result;
        }
        static int[] GetGrades(int number) // give grades of each student
        {
            int[] result = new int[number];
            for (int i = 0; i &lt; number; i++)
            {
                result[i] = Convert.ToInt32(Console.ReadLine());
            }
            return result;
        }
        static int[] GetCoins(int[] input) // this is the method where I'm stuck.
{
        int[] coins = new int[input.Length];
        for (int i = 0; i &lt; coins.Length; i++)
        {
            coins[i] = 1;
        }

        for (int i = 0; i &lt; input.Length; i++)
        {
            if (i &gt; 0 &amp;&amp; (input[i] &gt; input[i - 1]))
            {
                if (coins[i] &lt;= coins[i - 1])
                {
                    coins[i] = coins[i - 1] + 1;
                }
            }
            if (i &lt; input.Length - 1 &amp;&amp; input[i] &gt; input[i + 1])
            {
                if (coins[i] == coins[i + 1])
                {
                    coins[i]++;
                }
                if (i &gt; 0 &amp;&amp; input[i] &gt; input[i-1])
                {
                    coins[i - 1]++;
                }
            }
        }
        return coins;
    }



        static void PrintResult(string[] array, int[] array2)  // print the final result
        {
            for (int i = 0; i &lt; array.Length; i++)
            {
                array[i] += &quot; &quot; + array2[i];
            }

            foreach (string student in array)
            {
                Console.WriteLine(student);
            }
        }
    }
}
</code></pre>
<p>The program displays</p>
<pre><code>    Ionel 1
    Mihai 2
    Elena 1.
  // this is wrong.
</code></pre>
<p>The correct answer is</p>
<pre><code>    Ionel 1
    Mihai 3
    Elena 1
   // the correct answer
</code></pre>
<p>I'm not sure, but the problem is at the <em><strong>GetCoins</strong></em> method. Please help.
Thanks!</p>
",64,0,0,2,c#;arrays,2022-07-27 20:43:01,2022-07-27 20:43:01,2022-07-27 22:21:39,i have this problem and i m stuck  i m a beginner in software development  you get a list of n students and a list of grades for each student  every student gets coins  a student which has bigger grade than his neighbors from list earns more coins than them  find the coins which every student must receive  i have to give students coins which has bigger grade  data input data output here is my code  the program displays the correct answer is,compare multiple numbers in an array
83,9039104,73076346,Read txt file to pandas df with specific lineterminator (row) symbol,"<p>I have a huge txt file (over 90 000 lines) that I want to read as a single column in a pandas df and I have a specific symbol to mark the end of each line / row i.d. <code>‡</code>.</p>
<p>So far, I have tried : <code>df = pd.read_csv(fic, sep='\t', lineterminator='‡', header = None, encoding=&quot;utf-8&quot;)</code></p>
<p>The output is indeed a df, but it skips to the line (3 932) as if the first ‡ exists there. This is not at all the case, as there are many (&gt; 2 000) ‡ before.</p>
<p>The desired output would be something like :</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>Index</th>
<th>Text_initial</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Lorem ipsum dolor sit amet, consectetur adipiscing elit.<br>Ut enim ad minim veniam. ‡<br></td>
</tr>
<tr>
<td>2</td>
<td>Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.<br>Sunt in culpa qui officia deserunt mollit anim id est laborum. ‡</td>
</tr>
</tbody>
</table>
</div>
<p>etc... <br/>
and not something like :</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>Index</th>
<th>Text_initial</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Lorem ipsum dolor sit amet, consectetur adipiscing elit.<br>Ut enim ad minim veniam. <strong>‡</strong><br> S<strong>ed do eiusmod tempor incididunt ut labore et dolore magna aliqua.<br>Sunt in culpa qui officia deserunt mollit anim id est laborum.</strong> <strong>‡</strong> Lorem donec massa sapien faucibus et molestie ac feugiat. Volutpat sed cras ornare arcu dui vivamus arcu. Cras sed felis eget velit aliquet sagittis id consectetur. <strong>‡</strong><br/>Viverra vitae congue eu consequat ac felis. Consectetur adipiscing elit duis tristique sollicitudin. Sem et tortor consequat id. <strong>‡</strong> <br/>Sed blandit libero volutpat sed cras ornare arcu dui vivamus. Fermentum odio eu feugiat pretium nibh ipsum consequat. Consequat mauris nunc congue nisi vitae suscipit tellus mauris. <strong>‡</strong> <br/>Morbi non arcu risus quis varius quam quisque id. Velit egestas dui id ornare. <br/> ......</td>
</tr>
<tr>
<td>2</td>
<td>Pharetra magna ac placerat vestibulum lectus. ‡ <br> Nec feugiat nisl pretium fusce id velit ut. ‡ <br>Amet justo donec enim diam vulputate ut pharetra. ‡ <br>Nibh venenatis cras sed felis eget velit aliquet sagittis id. ‡</td>
</tr>
</tbody>
</table>
</div>
<p>etc... <br/></p>
<p>The ‡ symbol exists <em>only</em> to mark the end of the line/row and the file is encoded in <code>utf-8</code>.</p>
<p>Any suggestions on how to correctly read the txt file to a df and the reason why the output atm is not &quot;correct&quot; ?</p>
<p>Example from the real file :</p>
<pre><code>PART I Item 1.
Business General 3D Systems Corporation (3D Systems or the Company or we or us) is a holding company incorporated in Delaware in 1993 that markets our products and services through subsidiaries in North America and South America (collectively referred to as Americas) , Europe and the Middle East (collectively referred to as EMEA) and the Asia Pacific region (APAC) .
We provide comprehensive 3D printing solutions, including 3Dprinters, materials, software, on demand manufacturing services and digital design tools.
Our solutions support advanced applications in a wide range of industries and key verticals including healthcare, aerospace, automotive and durable goods.
Our precision healthcare capabilities include simulation, Virtual Surgical Planning (VSP) , and printing of medical and dental devices, anatomical models, and surgical guides and instruments. 
We have over 30 years of experience and expertise which have proven vital to our development of end-to-end solutions that enable customers to optimize product designs, transform workflows, bring innovative products to market and drive new business models.
Customers can use our 3D solutions to design and manufacture complex and unique parts, eliminate expensivetooling, produce parts locally or in small batches and reduce lead times and time to market. ‡ 
A growing number of customers are shifting from prototyping applications to also using 3D printing for production.
We believe this shift will be further driven by our continued advancement and innovation of 3D printing solutions that improve durability, repeatability, productivity and total cost of operations. ‡
</code></pre>
",36,1,2,3,pandas;dataframe;txt,2022-07-22 10:03:36,2022-07-22 10:03:36,2022-07-27 20:48:17,i have a huge txt file  over   lines  that i want to read as a single column in a pandas df and i have a specific symbol to mark the end of each line   row i d     so far  i have tried   df   pd read_csv fic  sep   t   lineterminator      header   none  encoding  utf    the output is indeed a df  but it skips to the line     as if the first   exists there  this is not at all the case  as there are many   gt       before  the desired output would be something like   etc     the   symbol exists only to mark the end of the line row and the file is encoded in utf   any suggestions on how to correctly read the txt file to a df and the reason why the output atm is not  correct    example from the real file  ,read txt file to pandas df with specific lineterminator  row  symbol
84,1940485,73076232,Best practice for communication between different modules in python,"<p>I revisited the development of an application in python I wrote 5 years ago  (It was my first interesting project/application in python 2.7, and as I revisit it now I am struggling to make heads or tails). The application had the following units/modules:</p>
<ul>
<li>got data from a camera (Data Aquisition module - DAQ)</li>
<li>processed the data and determined whether motor should be moved (Control)</li>
<li>Moved an actuator (Actuator)</li>
<li>displayed the data and activated switches on several tk windows. (Display)</li>
</ul>
<p>Back then (in python 2.7) I developed separate modules for each unit mentioned above. Different threads were spawned for each unit I used a Queue to pass the image data, and the control commands between the Control and the Actuator module.</p>
<p>As the options (and the buzzwords) for Interprocess Communication have multiplied, I was hoping to get an idea of which concepts should I look into. e.g. in 3.10 there is the asyncio with concepts like Coroutines and Tasks, Synchronization Primitives, Subprocesses, Queues.</p>
<p>My main goal is to be able to write separate units that run independently, so that (in theory) it is easier to debug the unit (or even write unit tests).</p>
<hr />
<p><strong>UPDATE</strong>:</p>
<p>As it was mentioned in the comment, what I am describing is communication between threads of the same process, therefore the IPC tag might not be appropriate. I will elaborate below why I chose the IPC tag.</p>
<p>Although I previously developed the software with a single process and communication between the different threads, I recall that this was not optimal because of GIL. GIL imposed sleeping on the Data Acquisition thread at random intervals which made the data collection random at high sampling rates (the application could work adequately because of the low requirements).</p>
<p>Ideally, I would like to investigate a scheme where I could have a separate process collecting data. To my understanding different processes run on different processors and therefore should not be affected by GIL.</p>
",43,1,0,4,python;multithreading;ipc;modular,2022-07-22 09:53:52,2022-07-22 09:53:52,2022-07-27 19:20:30,i revisited the development of an application in python i wrote  years ago   it was my first interesting project application in python    and as i revisit it now i am struggling to make heads or tails   the application had the following units modules  back then  in python    i developed separate modules for each unit mentioned above  different threads were spawned for each unit i used a queue to pass the image data  and the control commands between the control and the actuator module  as the options  and the buzzwords  for interprocess communication have multiplied  i was hoping to get an idea of which concepts should i look into  e g  in   there is the asyncio with concepts like coroutines and tasks  synchronization primitives  subprocesses  queues  my main goal is to be able to write separate units that run independently  so that  in theory  it is easier to debug the unit  or even write unit tests   update  as it was mentioned in the comment  what i am describing is communication between threads of the same process  therefore the ipc tag might not be appropriate  i will elaborate below why i chose the ipc tag  although i previously developed the software with a single process and communication between the different threads  i recall that this was not optimal because of gil  gil imposed sleeping on the data acquisition thread at random intervals which made the data collection random at high sampling rates  the application could work adequately because of the low requirements   ideally  i would like to investigate a scheme where i could have a separate process collecting data  to my understanding different processes run on different processors and therefore should not be affected by gil ,best practice for communication between different modules in python
85,5485232,70638525,VS Code debugging as root user,"<p>I have VS Code running on macOS connecting to a linux box where I am doing Go development. I am connecting via a user that has sudo privileges on the linux host. The root account is disabled on the remote host.</p>
<p>The application I am writing needs to run with root privileges. Is there a way to set vscode to elevate privileges when debugging the application? Or do I need to enable the root account for software development purposes?</p>
",866,3,0,1,visual-studio-code,2022-01-09 06:50:11,2022-01-09 06:50:11,2022-07-27 01:30:05,i have vs code running on macos connecting to a linux box where i am doing go development  i am connecting via a user that has sudo privileges on the linux host  the root account is disabled on the remote host  the application i am writing needs to run with root privileges  is there a way to set vscode to elevate privileges when debugging the application  or do i need to enable the root account for software development purposes ,vs code debugging as root user
86,38264,482341,How much effort do you spend(or should spend) on security for none web-centric applications?,"<p>Suppose the app you are working on is specially designed for a customer to meet a particular 'in-house' need, such as data processing of payroll information.  This application will not be distributed publicly and will reside on internal networks only.  (Theoretically the internal network should remain 100% secure.)    How much effort should a developer spend on IA in this case?  Lets say the database is SQL, would you worry about preventing an SQL injection attack in this situation?</p>

<p>I would love to hear some feedback from developers who work on none web-centric (I can't think of a better term right now, though none web-centric is not completely right.  Its more like none distributed or none public or something along those lines.) type programs and how much effort do they put into security.</p>

<p><strong>As an addendum, how would you justify this need to a manager type?</strong></p>

<p>I am currently doing a case study of the necessity of IA for 'in house' software development so any answer would be greatly appreciated.</p>
",176,5,4,1,security,2009-01-27 06:50:29,2009-01-27 06:50:29,2022-07-27 00:11:53,suppose the app you are working on is specially designed for a customer to meet a particular  in house  need  such as data processing of payroll information   this application will not be distributed publicly and will reside on internal networks only    theoretically the internal network should remain   secure      how much effort should a developer spend on ia in this case   lets say the database is sql  would you worry about preventing an sql injection attack in this situation  i would love to hear some feedback from developers who work on none web centric  i can t think of a better term right now  though none web centric is not completely right   its more like none distributed or none public or something along those lines   type programs and how much effort do they put into security  as an addendum  how would you justify this need to a manager type  i am currently doing a case study of the necessity of ia for  in house  software development so any answer would be greatly appreciated ,how much effort do you spend or should spend  on security for none web centric applications 
87,1170116,73129444,Is it possible to develop and debug R applications running in a Docker container through Visual Studio Code?,"<p>I am looking to create a better R software development life cycle for some <a href=""https://shiny.rstudio.com/"" rel=""nofollow noreferrer"">Shiny</a> data analytics apps.</p>
<p>The first phase was to deploy the applications to AWS ECS and to build and test the docker image locally after development.</p>
<p>But we are still having issues with differences in the development environment and the docker environment.</p>
<p>The production base image is <code>rocker/shiny-verse</code>.  I was looking into having the developer use <code>rocker/rstudio</code> locally to develop in, which is a possibility, but the Visual Studio Code experience will be a native app (instead of a browser) and would actually be debugging in the same container environment as it would run.</p>
<p>I can do this with .NET applications running in a container and debugging from VSCode, but I haven't seen a way to do this with R.</p>
<p>Is this possible, and if so, how?</p>
",19,0,0,3,r;docker;visual-studio-code,2022-07-26 23:32:07,2022-07-26 23:32:07,2022-07-26 23:32:07,i am looking to create a better r software development life cycle for some  data analytics apps  the first phase was to deploy the applications to aws ecs and to build and test the docker image locally after development  but we are still having issues with differences in the development environment and the docker environment  the production base image is rocker shiny verse   i was looking into having the developer use rocker rstudio locally to develop in  which is a possibility  but the visual studio code experience will be a native app  instead of a browser  and would actually be debugging in the same container environment as it would run  i can do this with  net applications running in a container and debugging from vscode  but i haven t seen a way to do this with r  is this possible  and if so  how ,is it possible to develop and debug r applications running in a docker container through visual studio code 
88,1057413,13423919,Computing N Grams using Python,"<p>I needed to compute the Unigrams,  BiGrams and Trigrams for a text file containing text like: </p>

<p>""Cystic fibrosis affects 30,000 children and young adults in the US alone
Inhaling the mists of salt water can reduce the pus and infection that fills the airways of cystic fibrosis sufferers, although side effects include a nasty coughing fit and a harsh taste. 
That's the conclusion of two studies published in this week's issue of The New England Journal of Medicine.""</p>

<p>I started in Python and used the following code:</p>

<pre><code>#!/usr/bin/env python
# File: n-gram.py
def N_Gram(N,text):
NList = []                      # start with an empty list
if N&gt; 1:
    space = "" "" * (N-1)         # add N - 1 spaces
    text = space + text + space # add both in front and back
# append the slices [i:i+N] to NList
for i in range( len(text) - (N - 1) ):
    NList.append(text[i:i+N])
return NList                    # return the list
# test code
for i in range(5):
print N_Gram(i+1,""text"")
# more test code
nList = N_Gram(7,""Here is a lot of text to print"")
for ngram in iter(nList):
print '""' + ngram + '""'
</code></pre>

<p><a href=""http://www.daniweb.com/software-development/python/threads/39109/generating-n-grams-from-a-word"" rel=""noreferrer"">http://www.daniweb.com/software-development/python/threads/39109/generating-n-grams-from-a-word</a></p>

<p>But it works for all the n-grams within a word, when I want it from between words as in CYSTIC and FIBROSIS or CYSTIC FIBROSIS. Can someone help me out as to how I can get this done? </p>
",94052,8,32,4,python;nlp;nltk;n-gram,2012-11-16 22:26:35,2012-11-16 22:26:35,2022-07-26 18:48:47,i needed to compute the unigrams   bigrams and trigrams for a text file containing text like   i started in python and used the following code   but it works for all the n grams within a word  when i want it from between words as in cystic and fibrosis or cystic fibrosis  can someone help me out as to how i can get this done  ,computing n grams using python
89,19596601,73101108,"Telemetry data through python socket, without stopping execution of the program","<p>I'm building photovoltaic motorized solar trackers. They're controlled by Raspberry Pi's running python script. RPI's are connected to my public openVPN server for remote control and continuous software development. That's working fine. Recently a passionate customer asked me for some sort of telemetry data for his tracker - let's say, it's current orientation, measured wind speed etc.. By being new to python, I'm really struggling with this part.</p>
<p>I've decided to use socket approach from guides like <a href=""https://www.geeksforgeeks.org/socket-programming-python/"" rel=""nofollow noreferrer"">this</a>. Python script listens on a socket, and my openVPN server, which is also web server, connects to it using PHP fsockopen. Python sends telemetry data, PHP makes it user friendly and displays it on the web. Everything so far works, however I don't know how to design my python script around it.</p>
<p>The problem is, that my script has to run continuously, and socket.accept() halts it's execution, waiting for a connection. Didn't find any obvious solution on the web. Would multi-threading work for this? Sounds a bit like overkill.</p>
<p>Is there a way to run socket listening asynchronously? Like, for example, pigpio callback's which I'm using abundantly?</p>
<p>Or alternatively, is there a better way to accomplish my goal?</p>
<p>I tried with remote accessing status file that my script is maintaining, but that proved to be extremely involved with setup and prone to errors when the file was being written.</p>
<p>I also tried running the second script. Problem is, then I have no access to relevant data, or I need to read beforementioned status file, and that leads to the same problems as above.</p>
<p>Relevant bit of code is literally only this:</p>
<pre><code># Main loop
try:
    while True:
        
        # Telemetry
        conn, addr = S.accept()
        conn.send(data.encode())
        conn.close()
</code></pre>
<p>Best regards.</p>
",34,1,0,3,python;sockets;raspberry-pi,2022-07-24 21:45:44,2022-07-24 21:45:44,2022-07-26 14:21:41,i m building photovoltaic motorized solar trackers  they re controlled by raspberry pi s running python script  rpi s are connected to my public openvpn server for remote control and continuous software development  that s working fine  recently a passionate customer asked me for some sort of telemetry data for his tracker   let s say  it s current orientation  measured wind speed etc   by being new to python  i m really struggling with this part  i ve decided to use socket approach from guides like   python script listens on a socket  and my openvpn server  which is also web server  connects to it using php fsockopen  python sends telemetry data  php makes it user friendly and displays it on the web  everything so far works  however i don t know how to design my python script around it  the problem is  that my script has to run continuously  and socket accept   halts it s execution  waiting for a connection  didn t find any obvious solution on the web  would multi threading work for this  sounds a bit like overkill  is there a way to run socket listening asynchronously  like  for example  pigpio callback s which i m using abundantly  or alternatively  is there a better way to accomplish my goal  i tried with remote accessing status file that my script is maintaining  but that proved to be extremely involved with setup and prone to errors when the file was being written  i also tried running the second script  problem is  then i have no access to relevant data  or i need to read beforementioned status file  and that leads to the same problems as above  relevant bit of code is literally only this  best regards ,telemetry data through python socket  without stopping execution of the program
90,1743860,9056507,Output Include Paths and CMake,"<p>I would like to force CMake to provide verbosity in terms of include paths (<code>-I...</code>). Consider current output:</p>

<pre><code>/D/Software/MinGW/bin/g++.exe -DQT_DEBUG -fmessage-length=0 -mfpmath=sse -msse2 -fopenmp -g3 -gdwarf-2 @CMakeFiles/go.dir/includes_CXX.rsp   -o CMakeFiles/go.dir/main.cpp.obj -c /D/Users/Haroogan/Development/Workspace/New2/main.cpp
</code></pre>

<p>Everywhere, instead of showing a list of include paths, it rather shows <code>@CMakeFiles/go.dir/includes_CXX.rsp</code>. Indeed, this file contains include paths.</p>

<p>How can I force CMake or Make or whatever to output include paths?</p>
",3373,3,3,4,path;include;makefile;cmake,2012-01-29 22:34:49,2012-01-29 22:34:49,2022-07-26 13:16:22,i would like to force cmake to provide verbosity in terms of include paths   i      consider current output  everywhere  instead of showing a list of include paths  it rather shows  cmakefiles go dir includes_cxx rsp  indeed  this file contains include paths  how can i force cmake or make or whatever to output include paths ,output include paths and cmake
91,3427866,73117200,Oracle Hierarchy - How to get a particular level record in a query?,"<p>We have the following structure for Organizations.</p>
<pre><code>create table orgs (
    org_id number
  , org_name varchar2(250)
  , org_type varchar2(10)
  , parent_org_id number 
)
/

insert into orgs values ( 1, 'President', 'PRES', null );
insert into orgs values ( 2, 'Information Technology Department', 'DEP', 1 );
insert into orgs values ( 3, 'Software Development Division', 'DIV', 2 );
insert into orgs values ( 4, 'Database Unit', 'UNIT', 3 );
insert into orgs values ( 5, 'Developer Unit', 'UNIT', 3 );
insert into orgs values ( 6, 'Infrastracture Department', 'DEP', 1 );
insert into orgs values ( 7, 'Security Division', 'DIV', 6 );
insert into orgs values ( 8, 'System Admintrator Division', 'UNIT', 7 );


  select level, org_id, org_name, org_type
    from orgs
 connect
      by 
   prior org_id = parent_org_id
   start
    with parent_org_id is null
</code></pre>
<p>Query returns the result</p>
<p><a href=""https://i.stack.imgur.com/hNZQ7.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hNZQ7.png"" alt=""enter image description here"" /></a></p>
<p>What I'm trying to do is let's say I need to get the Department (Information Technology Department) of org_id 4 (Database Unit), how should I build the query for that?</p>
<p>Currently we built a function that returns the department id which basically loops until it reaches the DEP parent. But it has a performance issue.</p>
",39,2,1,3,sql;oracle;hierarchy,2022-07-26 05:41:09,2022-07-26 05:41:09,2022-07-26 11:34:19,we have the following structure for organizations  query returns the result  what i m trying to do is let s say i need to get the department  information technology department  of org_id   database unit   how should i build the query for that  currently we built a function that returns the department id which basically loops until it reaches the dep parent  but it has a performance issue ,oracle hierarchy   how to get a particular level record in a query 
92,1796399,71836582,Which development board/kit supports camera parallel interface?,"<p>I need to interface qvga camera sensor which has parallel interface so, I am looking for any suitable development kit/board for 'vga/qvga camera parallel interface' which supports less complexity in hardware/software.</p>
<p>Please suggest if any. Thanks.</p>
",15,0,0,2,camera;vga,2022-04-12 06:06:21,2022-04-12 06:06:21,2022-07-26 10:35:27,i need to interface qvga camera sensor which has parallel interface so  i am looking for any suitable development kit board for  vga qvga camera parallel interface  which supports less complexity in hardware software  please suggest if any  thanks ,which development board kit supports camera parallel interface 
93,1494951,73114614,How to depoly an openzeppelin contract wizard smart contract from React frontend,"<p>I am creating a dApp where users can configure a couple of smart contracts for an ERC20 token and a governor contract. I have the contracts wizard printing the contract and stored in a variable. I am wondering what the best way is to then deploy both smart contracts using the users metamask. I have seen implementations where you use hd-wallet-provider to use their seed phrase, but I am wondering if there is a way to deploy the two contracts from the variable they're stored in and simply sign the transaction with metamask. Any ideas? All ideas are welcome as I'm new to solidity development (14 year software engineer).</p>
<p>Thanks!</p>
",27,0,0,5,javascript;reactjs;solidity;smartcontracts;openzeppelin,2022-07-25 22:46:36,2022-07-25 22:46:36,2022-07-25 22:46:36,i am creating a dapp where users can configure a couple of smart contracts for an erc token and a governor contract  i have the contracts wizard printing the contract and stored in a variable  i am wondering what the best way is to then deploy both smart contracts using the users metamask  i have seen implementations where you use hd wallet provider to use their seed phrase  but i am wondering if there is a way to deploy the two contracts from the variable they re stored in and simply sign the transaction with metamask  any ideas  all ideas are welcome as i m new to solidity development   year software engineer   thanks ,how to depoly an openzeppelin contract wizard smart contract from react frontend
94,3009846,73109752,Search multiple words while ignoring the word order in Fuse (Javascript fuzzy search),"<p>how can i match multiple words in <a href=""https://github.com/krisk/Fuse"" rel=""nofollow noreferrer"">fuse</a> while ignoring anything in between and also ignoring the word-order?</p>
<p>for the following example (pseudo-code) the algorithm should match the all items in the <code>possibleResults</code>-array for the search-term <code>team lead</code>.</p>
<pre><code>const options = {}
const possibleResults = ['lead', 'team lead', 'lead of software development team']
const fuse = new Fuse(possibleResults, options)
fuse.search('team lead')
</code></pre>
<p>i've tried it with the following options:</p>
<pre><code>{
threshold: 0, // the lower the more exact
ignoreLocation: true, // ignores how &quot;far&quot; result is
findAllMatches: true,
};
</code></pre>
<p>but without success. as far as i know Fuse now always sets <code>tokenize: true</code> per default. so that's not helping ...</p>
",15,1,1,3,javascript;search;fuse,2022-07-25 16:06:23,2022-07-25 16:06:23,2022-07-25 16:11:44,how can i match multiple words in  while ignoring anything in between and also ignoring the word order  for the following example  pseudo code  the algorithm should match the all items in the possibleresults array for the search term team lead  i ve tried it with the following options  but without success  as far as i know fuse now always sets tokenize  true per default  so that s not helping    ,search multiple words while ignoring the word order in fuse  javascript fuzzy search 
95,1248535,73099819,"How does the Unix Philosophy deal with the overhead of the OS starting processes, opening files, managing pipelines, etc.?","<p>I read the article on the Unix Philosophy in Wikipedia and I love that philosophy! As I understand it, the Unix approach to software development is to create generalized, independent tools that have stdin as input and stdout as output and the tools are assembled using shell operators such as &quot;pipe&quot; and &quot;cat&quot;. Do I understand correctly?</p>
<p>I am trying to apply that software development approach on my Windows machine. But I am finding that the performance is terrible. I think it's due to the overhead of the OS starting processes, opening files, managing pipelines, etc..</p>
<p>For example, I created a couple simple awk scripts (append and footnote) which I connected using pipes and type (Window's version of cat):</p>
<pre><code>(type compiler-books.txt) | ((awk -f append -v filename=&quot;economics-books.txt&quot;) | (awk -f footnote))
</code></pre>
<p>I placed that in a batch file. I ran the batch file. I timed it to see its performance. It took nearly half a second! Half a second to run a couple trivial awk scripts on two tiny input files (compiler-books.txt and economics-books.txt)!</p>
<p>How do you deal with the overhead of the OS starting processes, opening files, managing pipelines, etc.?</p>
<p>Below are my awk scripts and the tiny input files (compiler-books.txt and economics-books.txt)</p>
<p>Here is the &quot;append&quot; awk script:</p>
<pre><code>BEGIN {FS=&quot;\t&quot;; OFS=&quot;\t&quot;}
      { print }
END   {
        while ((getline &lt; filename) &gt; 0)
           print
      }
</code></pre>
<p>Here is the &quot;footnote&quot; awk script:</p>
<pre><code>BEGIN   {FS=&quot;\t&quot;; OFS=&quot;\t&quot;}
NR==1   { print; author_list=$2 }
NR&gt;1    { print; author_list=author_list &quot;, &quot; $2 }
END     { print author_list}
</code></pre>
<p>Here is the tab-delimited compiler-books.txt file:</p>
<pre><code>Compilers Principles, Techniques, Tools Alfred V. Aho, Ravi Sethi, Jeffrey Ullman   Addison-Wesley  1986
Introduction to Compiling Techniques    J. P. Bennett   McGraw-Hill 1996
</code></pre>
<p>Here is tab-delimited economics-books.txt file:</p>
<pre><code>Economic Facts and Fallacies    Thomas Sowell   Basic Books 2011
Economics in One Lesson Henry Hazlitt   Harper &amp; Brothers   1946 
</code></pre>
",30,0,-1,1,unix,2022-07-24 18:41:40,2022-07-24 18:41:40,2022-07-24 19:13:07,i read the article on the unix philosophy in wikipedia and i love that philosophy  as i understand it  the unix approach to software development is to create generalized  independent tools that have stdin as input and stdout as output and the tools are assembled using shell operators such as  pipe  and  cat   do i understand correctly  i am trying to apply that software development approach on my windows machine  but i am finding that the performance is terrible  i think it s due to the overhead of the os starting processes  opening files  managing pipelines  etc   for example  i created a couple simple awk scripts  append and footnote  which i connected using pipes and type  window s version of cat   i placed that in a batch file  i ran the batch file  i timed it to see its performance  it took nearly half a second  half a second to run a couple trivial awk scripts on two tiny input files  compiler books txt and economics books txt   how do you deal with the overhead of the os starting processes  opening files  managing pipelines  etc   below are my awk scripts and the tiny input files  compiler books txt and economics books txt  here is the  append  awk script  here is the  footnote  awk script  here is the tab delimited compiler books txt file  here is tab delimited economics books txt file ,how does the unix philosophy deal with the overhead of the os starting processes  opening files  managing pipelines  etc  
96,51496,2020163,What&#39;s the best(easiest) way to transfer data on C/C++,"<p>Currently I'm working on a C/C++ cross-platform client/server software. I'm very experienced developer when it comes to low level socket development.
The problem with Berkley sockets/Winsock, is that you always have to make some kind of parser to get things right on the receiver side. I mean, you have to interpret data, and concatenate packets in order to transmit correctly. (packets often get sliced) </p>

<p>Have in mind that the communication is going to be bidirectional. Is pure socket the best way to transmit data nowadays? Would you recommend SOAP, Webservices or another kind of encapsulation to this application? </p>
",588,4,0,5,c++;c;web-services;sockets;soap,2010-01-07 14:19:51,2010-01-07 14:19:51,2022-07-24 15:36:02,have in mind that the communication is going to be bidirectional  is pure socket the best way to transmit data nowadays  would you recommend soap  webservices or another kind of encapsulation to this application  ,what   s the best easiest  way to transfer data on c c  
97,958110,57182694,"C++ compile-time / runtime options and parameters, how to handle?","<p>What is the proper way to handle compile-time and runtime options in a generic library? What is good practice for large software in which there are simply too many options for the user to bother about most of them?</p>

<p>Suppose the task is to write a large library to perform calculations on a number of datasets at the same time. There are numerous ways to perform these calculations, and the library must be be highly configurable. Typically, there are options relative to how the calculation is performed as a whole. Then, each dataset has its own set of calculation options. Finally, each calculation has a number of tuning parameters, which must be set as well.</p>

<p>The library itself is generic, but each application which uses that library will use a particular kind of dataset, for which tuning parameters will take on a certain value. Since they will not change throughout the life of the application, I make them known at application <strong>compile-time</strong>. The way I would implement these tuning parameters in the library is through a <code>Traits</code> class, which contains the tuning parameters as <code>static const</code> elements. Calibration of their final value is part of the development of the application.</p>

<p>The datasets will of course change depending on what the user feeds to the application, and therefore a number of <strong>runtime</strong> options must be provided as well (with intelligent defaults). Calibration of their default value is also part of the development of the application. I would implement these options as a <code>Config</code> class which contains these options, and can be changed on application startup (e.g. parsing a config text file). It gets passed to the constructor of a lot of the classes in the library. Each class then calls the <code>Config::get_x</code> for their specific option <code>x</code>.</p>

<p>The thing I don't really like about this design, is that both <code>Traits</code> and <code>Config</code> classes break encapsulation. Some options relate to some parts of the library. Most of the time, however, they don't. And having them suddenly next to each other annoys me, because they affect separate things in the code, which are often in different abstraction layers.</p>

<p>One solution I was thinking about, is using multiple public inheritance for these different parts. A class which needs to know an option then casts the <code>Config</code> object or calls the relevant <code>Trait</code> parent to access it. Also, this passing along of <code>Config</code> to every class that needs it (or whose members need it) is very inelegant. Maybe <code>Config</code> should be a singleton?</p>
",1052,1,1,4,c++;c++11;runtime;compile-time,2019-07-24 15:14:26,2019-07-24 15:14:26,2022-07-23 05:54:49,what is the proper way to handle compile time and runtime options in a generic library  what is good practice for large software in which there are simply too many options for the user to bother about most of them  suppose the task is to write a large library to perform calculations on a number of datasets at the same time  there are numerous ways to perform these calculations  and the library must be be highly configurable  typically  there are options relative to how the calculation is performed as a whole  then  each dataset has its own set of calculation options  finally  each calculation has a number of tuning parameters  which must be set as well  the library itself is generic  but each application which uses that library will use a particular kind of dataset  for which tuning parameters will take on a certain value  since they will not change throughout the life of the application  i make them known at application compile time  the way i would implement these tuning parameters in the library is through a traits class  which contains the tuning parameters as static const elements  calibration of their final value is part of the development of the application  the datasets will of course change depending on what the user feeds to the application  and therefore a number of runtime options must be provided as well  with intelligent defaults   calibration of their default value is also part of the development of the application  i would implement these options as a config class which contains these options  and can be changed on application startup  e g  parsing a config text file   it gets passed to the constructor of a lot of the classes in the library  each class then calls the config  get_x for their specific option x  the thing i don t really like about this design  is that both traits and config classes break encapsulation  some options relate to some parts of the library  most of the time  however  they don t  and having them suddenly next to each other annoys me  because they affect separate things in the code  which are often in different abstraction layers  one solution i was thinking about  is using multiple public inheritance for these different parts  a class which needs to know an option then casts the config object or calls the relevant trait parent to access it  also  this passing along of config to every class that needs it  or whose members need it  is very inelegant  maybe config should be a singleton ,c   compile time   runtime options and parameters  how to handle 
98,19445689,73086568,Why does &#39;React App&#39; button (that activates useState function) crashes after some uses?,"<p>I was working in an exercise from Full Stack Open. The task was to create a button that displays a random &quot;anecdote&quot; from an array full of strings that they give you. The exercise gets more complicated, they ask you to create an array with votes for each &quot;anecdote&quot; (which I called &quot;initialVotes&quot;), and have a button that adds a vote (they also ask you to display the one with the highest value).</p>
<p>Now, I'm giving every detail of the exercise as I didn't realize it could crash after I finished everything. The issue is weird, everything &quot;works fine&quot;, until you click the &quot;next anecdote&quot; button a few times, then it stops working (the amount of times you can use it before it crashes changes everytime you reload the page, which makes it even weirder imo). If you use the &quot;add vote&quot; button, it MIGHT work again (can't even think why).</p>
<p>This is the code:</p>
<pre><code>import { useState } from 'react'
import React from 'react'

const firstIndex = Math.floor(Math.random() * 7)

const App = () =&gt; {

  const anecdotes = [
    'If it hurts, do it more often.',
    'Adding manpower to a late software project makes it later!',
    'The first 90 percent of the code accounts for the first 10 percent of the development time...The remaining 10 percent of the code accounts for the other 90 percent of the development time.',
    'Any fool can write code that a computer can understand. Good programmers write code that humans can understand.',
    'Premature optimization is the root of all evil.',
    'Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it.',
    'Programming without an extremely heavy use of console.log is same as if a doctor would refuse to use x-rays or blood tests when diagnosing patients.'
  ]

  const [selected, setSelected] = useState(firstIndex)

  const newIndex = Math.floor(Math.random() * 7)

  // We could use: const initialVotes(Uint8Array)
  const n = 7  // arbitrary length
  const initialVotes = Array(n).fill(0)

  const [votes, setVotes] = useState(initialVotes)

  const addVote = (index) =&gt; {
    const vote = votes[index] + 1
    setVotes([
      ...votes.slice(0, index),
      vote,
      ...votes.slice(index + 1, n)
    ])
  }

  const mostVotes = Math.max(...votes);
  const mvIndex = votes.indexOf(mostVotes)

  console.log(newIndex)
  console.log(anecdotes[selected])

  return (
    &lt;React.Fragment&gt;
      &lt;h1&gt;Anecdote of the day&lt;/h1&gt;
      &lt;h4&gt;{anecdotes[selected]}&lt;/h4&gt;
      &lt;p&gt;has {votes[selected]} votes&lt;/p&gt;
      &lt;button type=&quot;button&quot; onClick={() =&gt; addVote(selected)}&gt;vote&lt;/button&gt;
      &lt;button type=&quot;button&quot; onClick={() =&gt; setSelected(newIndex)}&gt;next anecdote&lt;/button&gt;
      &lt;h1&gt;Anecdote with most votes&lt;/h1&gt;
      &lt;p&gt;The anecdote with most votes is: &lt;mark&gt;{anecdotes[mvIndex]}&lt;/mark&gt;&lt;/p&gt;
      &lt;p&gt;With &quot;{mostVotes}&quot; votes&lt;/p&gt;
    &lt;/React.Fragment&gt;
  )
}

export default App
</code></pre>
",17,1,1,5,javascript;reactjs;arrays;button;crash,2022-07-23 01:17:40,2022-07-23 01:17:40,2022-07-23 01:26:08,i was working in an exercise from full stack open  the task was to create a button that displays a random  anecdote  from an array full of strings that they give you  the exercise gets more complicated  they ask you to create an array with votes for each  anecdote   which i called  initialvotes    and have a button that adds a vote  they also ask you to display the one with the highest value   now  i m giving every detail of the exercise as i didn t realize it could crash after i finished everything  the issue is weird  everything  works fine   until you click the  next anecdote  button a few times  then it stops working  the amount of times you can use it before it crashes changes everytime you reload the page  which makes it even weirder imo   if you use the  add vote  button  it might work again  can t even think why   this is the code ,why does    react app    button  that activates usestate function  crashes after some uses 
99,19604398,73086577,JavaScript ToDo List Help- Priority and Date,"<p>Hey everyone I'm in school for software development and working on a project to make a todo list. I'm still learning and fairly new to coding still. I have completed my todo list to filter items and add/delete them to a list. But was looking to add a date and priority to the list and was wondering if I could get some help from the community. Thanks in advance.</p>
<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>//Selectors
var todoInput = document.querySelector("".todo-input"");
var dateInput = document.querySelector("".todo-date"");
var todoButton = document.querySelector("".todo-button"");
var todoList = document.querySelector("".todo-list"");
var filterOption = document.querySelector("".filter-todo"");

//Event Listener
todoButton.addEventListener(""click"", addTodo);
todoList.addEventListener(""click"", deleteCheck);
filterOption.addEventListener(""click"", filterTodo);

//Functions

// Add ToDo Function
function addTodo(e) {
  // Prevent form from submitting
  e.preventDefault();
  // Todo Div
  var todoDiv = document.createElement(""div"");
  todoDiv.classList.add(""todo"");

  // Create Li
  var newTodo = document.createElement(""li"");
  newTodo.innerText = todoInput.value;
  // Here is where to make input value append to list
  newTodo.classList.add(""todo-item"");
  todoDiv.appendChild(newTodo);

  // // Date Scroll
  // var newDate = document.createElement(""input class=input input-date type=date"")
  // newDate.classList.add("""")

  // Completed Button
  var completedButton = document.createElement(""button"");
  completedButton.innerHTML = '&lt;i class=""fas fa-check""&gt;&lt;/i&gt;';
  completedButton.classList.add(""complete-btn"");
  todoDiv.appendChild(completedButton);

  // Delete Button
  var trashButton = document.createElement(""button"");
  trashButton.innerHTML = '&lt;i class=""fas fa-trash""&gt;&lt;/i&gt;';
  trashButton.classList.add(""trash-btn"");
  todoDiv.appendChild(trashButton);

  // Append to List
  todoList.appendChild(todoDiv);
  // Clear Input Value
  todoInput.value = """";
}

function deleteCheck(e) {
  var item = e.target;
  // Delete Todo
  if (item.classList[0] === ""trash-btn"") {
    var todo = item.parentElement;
    // Animation
    todo.classList.add(""fall"");
    todo.addEventListener(""transitionend"", function () {
      todo.remove(); // Use this function to remove element after the transition
    });
  }

  // Check Todo
  if (item.classList[0] === ""complete-btn"") {
    var todo = item.parentElement;
    todo.classList.toggle(""completed"");
  }
}

function filterTodo(e) {
  var todos = todoList.childNodes;
  todos.forEach(function (todo) {
    switch (e.target.value) {
      case ""all"":
        todo.style.display = ""flex"";
        break;
      case ""completed"":
        if (todo.classList.contains(""completed"")) {
          todo.style.display = ""flex"";
        } else {
          todo.style.display = ""none"";
        }
        break;
      case ""pending"":
        if (!todo.classList.contains(""completed"")) {
          // add ! to check if it does not have the ""completed""
          todo.style.display = ""flex"";
        } else {
          todo.style.display = ""none"";
        }
        break;
    } // reads value from the html div select values: all, completed &amp;pending
  });
}</code></pre>
<pre class=""snippet-code-css lang-css prettyprint-override""><code>/* EVERY PAGE STYLING STARTS HERE */

@import url(""https://fonts.googleapis.com/css2?family=Roboto+Slab&amp;display=swap"");

@media (max-width: 700px) {
  .text h1 {
    font-size: 20px;
  }
  .nav_links ul li {
    display: block;
  }
  body {
    background-image: linear-gradient(rgba(4, 9, 30, 0.7), rgba(4, 9, 30, 0.7)),
      url(./images/qap3_back.jpg);
  }
}

* {
  padding: 0;
  margin: 0;
  box-sizing: border-box;
  font-family: ""Roboto Slab"", serif;
  list-style: none;
  text-decoration: none;
  scroll-behavior: smooth;
}

body {
  min-height: 100vh;
  /* vh means viewport- percentage length based on the browsers default viewport size */
  width: 100%;
  /* background-image: linear-gradient(120deg, #84fab0 0%, #8fd3f4 100%); */
  background-image: linear-gradient(rgba(4, 9, 30, 0.7), rgba(4, 9, 30, 0.7)),
    url(./images/qap3_back.jpg);
  background-position: center;
  background-size: cover;
}

.logo {
  display: grid;
  grid-row-start: 1;
  grid-row-end: 2;
  grid-column-start: 1;
  grid-column-end: 2;
  justify-content: left;
}

nav {
  display: flex;
  padding: 2% 6%;
  justify-content: space-between;
  align-items: center;
}

nav img {
  width: 150px;
}

.nav_links {
  flex: 1;
  text-align: right;
}

.nav_links ul li {
  list-style: none;
  display: inline-block;
  padding: 8px 12px;
  position: relative;
}

.nav_links ul li a {
  color: rgb(248, 248, 248);
  font-weight: bold;
  text-decoration: none;
  font-size: 1rem;
  font-family: ""Roboto Slab"", serif;
}

.nav_links ul li::after {
  content: """";
  width: 0%;
  height: 2px;
  background: #13707c;
  display: block;
  margin: auto;
  transition: 0.5s;
}

.nav_links ul li:hover::after {
  width: 100%;
}

/* Start of TODO List */

.list-container {
  background-image: linear-gradient(120deg, #84fab0 0%, #8fd3f4 100%);
}

header h1 {
  color: #f7f7f7;
}

header {
  font-size: 2.5rem;
}

header,
form {
  min-height: 20vh;
  display: flex;
  justify-content: center;
  align-items: center;
}

form input,
form button {
  padding: 0.5rem;
  font-size: 2rem;
  border: none;
  background: #fff;
}

form button {
  color: #13707c;
  cursor: pointer;
  background: #fff;
  transition: all 0.3s ease;
}

form button:hover {
  background: #13707c;
  color: #fff;
}

.todo-container {
  display: flex;
  justify-content: center;
  align-items: center;
}

.todo-list {
  min-width: 30%;
  list-style: none;
}

.todo {
  margin: 0.5rem;
  background: #fff;
  color: black;
  font-size: 1.5rem;
  display: flex;
  justify-content: space-between;
  align-items: center;
  transition: all 0.5s ease;
}

.todo li {
  flex: 1;
}

.trash-btn,
.complete-btn {
  background: #13707c;
  color: #fff;
  border: none;
  padding: 1rem;
  cursor: pointer;
  font-size: 1rem;
}

.complete-btn {
  background: #4db1be;
}

.todo-item {
  padding: 0rem 0.5rem;
}

/* Needed to add this because clicking icon wouldnt avtivate click function */
.fa-trash,
.fa-check {
  pointer-events: none;
}

/* complete-btn */
.completed {
  text-decoration: line-through;
  opacity: 0.7;
}

.fall {
  transform: translateY(8rem) rotateZ(20deg);
  opacity: 0;
}

/* Cant style select button so must remove styles and do some tricks */
select {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  outline: none;
  border: none;
}

.select {
  margin: 1rem;
  position: relative;
  overflow: hidden;
}

select {
  color: #13707c;
  width: 10rem;
  cursor: pointer;
  padding: 1rem;
}

.select::after {
  content: ""\25BC"";
  position: absolute;
  background: #13707c;
  top: 0;
  right: 0;
  padding: 1rem;
  pointer-events: none;
  transition: all 0.3 ease;
}

.select:hover::after {
  background: #fff;
  color: #13707c;
}</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;!DOCTYPE html&gt;
&lt;html lang=""en""&gt;
  3
  &lt;head&gt;
    &lt;meta charset=""UTF-8"" /&gt;
    &lt;meta http-equiv=""X-UA-Compatible"" content=""IE=edge"" /&gt;
    &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1.0"" /&gt;
    &lt;title&gt;QAP3-MARK HANNEM&lt;/title&gt;
    &lt;link rel=""stylesheet"" href=""./todo.css"" /&gt;
    &lt;link
      rel=""stylesheet""
      href=""https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css""
      integrity=""sha512-KfkfwYDsLkIlwQp6LFnl8zNdLGxu9YAA1QvwINks4PhcElQSvqcyVLLD9aMhXd13uQjoXtEKNosOWaZqXgel0g==""
      crossorigin=""anonymous""
      referrerpolicy=""no-referrer""
    /&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;section class=""header""&gt;
      &lt;nav&gt;
        &lt;a href=""index.html""
          &gt;&lt;img src=""./images/garybluenew.png"" class=""logo""
        /&gt;&lt;/a&gt;
        &lt;div class=""nav_links""&gt;
          &lt;ul&gt;
            &lt;li&gt;&lt;a href=""./index.html""&gt;HOME&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=""#""&gt;ABOUT&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=""#""&gt;BLOG&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=""#""&gt;RECIPES&lt;/a&gt;&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/div&gt;
      &lt;/nav&gt;
    &lt;/section&gt;
    &lt;!-- Start of TODO List --&gt;
    &lt;section class=""list-container""&gt;
      &lt;header&gt;
        &lt;h1&gt;ToDo List&lt;/h1&gt;
      &lt;/header&gt;
      &lt;form&gt;
        &lt;input type=""text"" class=""todo-input"" /&gt;
        &lt;input type=""date"" class=""date-input"" /&gt;
        &lt;div class=""priority""&gt;
          &lt;select name=""priority"" class=""check_pty""&gt;
            &lt;option value=""low""&gt;Low&lt;/option&gt;
            &lt;option value=""med""&gt;Med&lt;/option&gt;
            &lt;option value=""high""&gt;High&lt;/option&gt;
          &lt;/select&gt;
        &lt;/div&gt;
        &lt;button class=""todo-button"" type=""submit""&gt;
          &lt;i class=""fas fa-plus-square""&gt;&lt;/i&gt;
        &lt;/button&gt;
        &lt;div class=""select""&gt;
          &lt;select name=""todos"" class=""filter-todo""&gt;
            &lt;option value=""all""&gt;All&lt;/option&gt;
            &lt;option value=""completed""&gt;Completed&lt;/option&gt;
            &lt;option value=""pending""&gt;Pending&lt;/option&gt;
          &lt;/select&gt;
        &lt;/div&gt;
      &lt;/form&gt;
      &lt;div class=""todo-container""&gt;
        &lt;ul class=""todo-list""&gt;&lt;/ul&gt;
      &lt;/div&gt;
      &lt;script src=""./todo.js""&gt;&lt;/script&gt;
    &lt;/section&gt;
  &lt;/body&gt;
&lt;/html&gt;</code></pre>
</div>
</div>
</p>
",34,0,-4,3,javascript;html;css,2022-07-23 01:18:36,2022-07-23 01:18:36,2022-07-23 01:24:34,hey everyone i m in school for software development and working on a project to make a todo list  i m still learning and fairly new to coding still  i have completed my todo list to filter items and add delete them to a list  but was looking to add a date and priority to the list and was wondering if i could get some help from the community  thanks in advance ,javascript todo list help  priority and date
100,19444907,72994852,Turning JSON into a hierarchy tree,"<p>I'm parsing JSON data into a tree to build a hierarchy structure, and I was wondering if someone could please help me.</p>
<p>Here is a sample of the JSON:</p>
<pre><code>{&quot;businessModelInfo&quot;:{&quot;52ff2dd1e4b0b193ed664d41&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:2,&quot;description&quot;:&quot;Platform for the security monitoring, detection &amp; prevention of unauthorized access, misuse &amp; modification to the enterprise network&quot;},&quot;id&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;name&quot;:&quot;Network Security&quot;},&quot;52ff2df2e4b0b193ed664d43&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:212,&quot;description&quot;:&quot;Application security testing, vulnerability assessment &amp; runtime application protection&quot;},&quot;id&quot;:&quot;52ff2df2e4b0b193ed664d43&quot;,&quot;name&quot;:&quot;Application Security&quot;},&quot;52ff2e04e4b0b193ed664d45&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:55,&quot;description&quot;:&quot;Identity &amp; Access Management (IAM) solution for the user login, authentication and authorization&quot;},&quot;id&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;name&quot;:&quot;IAM&quot;},&quot;52ff2e04e4b0b193ed664d46&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:65,&quot;description&quot;:&quot;Companies that provide a platform for OAuth, SAML or XML based identity federation or SSO&quot;},&quot;id&quot;:&quot;52ff2e04e4b0b193ed664d46&quot;,&quot;name&quot;:&quot;Federated Identity Management&quot;},&quot;52ff2e13e4b0b193ed664d47&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:177,&quot;description&quot;:&quot;Technologies, policies &amp; controls deployed to protect data, applications, and the associated infrastructure of cloud computing&quot;},&quot;id&quot;:&quot;52ff2e13e4b0b193ed664d47&quot;,&quot;name&quot;:&quot;Cloud Security&quot;},&quot;52ff2e3de4b0b193ed664d4a&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:30,&quot;description&quot;:&quot;Companies that provide a platform for the cyber security of the enterprise owned endpoint devices&quot;},&quot;id&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;name&quot;:&quot;Endpoint Security&quot;},&quot;53295f48e4b07f1af3220cb0&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:124,&quot;description&quot;:&quot;Security for access to enterprise network &amp; data by a non-company device&quot;},&quot;id&quot;:&quot;53295f48e4b07f1af3220cb0&quot;,&quot;name&quot;:&quot;BYOD Security&quot;},&quot;532ffec7e4b09e548233984f&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:5,&quot;description&quot;:&quot;Companies that provide an integrated Network Intrusion Detection System (NIDS) for network security of SMB/SME or remote office&quot;},&quot;id&quot;:&quot;532ffec7e4b09e548233984f&quot;,&quot;name&quot;:&quot;NIDS&quot;},&quot;533008efe4b09e54823398bf&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:8,&quot;description&quot;:&quot;Companies that provide a platform to prevent cyber intrusion in the enterprise network&quot;},&quot;id&quot;:&quot;533008efe4b09e54823398bf&quot;,&quot;name&quot;:&quot;NIPS&quot;},&quot;53301ec6e4b09e54823399b4&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:33,&quot;description&quot;:&quot;Solution for detecting various cyber threats on enterprise owned and managed endpoint devices&quot;},&quot;id&quot;:&quot;53301ec6e4b09e54823399b4&quot;,&quot;name&quot;:&quot;Threat Detection&quot;},&quot;53303049e4b09e5482339a5b&quot;:{&quot;parentId&quot;:&quot;52ff2df2e4b0b193ed664d43&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:213,&quot;description&quot;:&quot;Companies that provide a vulnerability assessment platform for application modules, libraries &amp; code&quot;},&quot;id&quot;:&quot;53303049e4b09e5482339a5b&quot;,&quot;name&quot;:&quot;Vulnerability Assessment&quot;},&quot;53303451e4b09e5482339a76&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:13,&quot;description&quot;:&quot;Companies that provide incident response solution for enterprise network from cyber attacks&quot;},&quot;id&quot;:&quot;53303451e4b09e5482339a76&quot;,&quot;name&quot;:&quot;Network Incident Response&quot;},&quot;53306594e4b09e5482339b74&quot;:{&quot;parentId&quot;:&quot;53295f48e4b07f1af3220cb0&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:134,&quot;description&quot;:&quot;Companies that provide solution for the assessment of device status, application installed and vulnerabilities detected over BYOD devices&quot;},&quot;id&quot;:&quot;53306594e4b09e5482339b74&quot;,&quot;name&quot;:&quot;Vulnerability Assessment&quot;},&quot;533065b0e4b09e5482339b75&quot;:{&quot;parentId&quot;:&quot;53295f48e4b07f1af3220cb0&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:132,&quot;description&quot;:&quot;Solution for the detection &amp; remediation of malware including virus over BYOD devices&quot;},&quot;id&quot;:&quot;533065b0e4b09e5482339b75&quot;,&quot;name&quot;:&quot;Anti Malware&quot;},&quot;5330665de4b09e5482339b78&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:31,&quot;description&quot;:&quot;Unified threat management including threat response, vulnerability assessment and patch management&quot;},&quot;id&quot;:&quot;5330665de4b09e5482339b78&quot;,&quot;name&quot;:&quot;Endpoint UTM&quot;},&quot;5330677ae4b09e5482339b7a&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:36,&quot;description&quot;:&quot;Endpoint security for the protection against malware including computer viruses, worms, trojan horses, ransomware, spyware, adware, and scareware&quot;},&quot;id&quot;:&quot;5330677ae4b09e5482339b7a&quot;,&quot;name&quot;:&quot;Anti Malware&quot;},&quot;533067dfe4b09e5482339b7b&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:45,&quot;description&quot;:&quot;Companies that provide a whitelisting based execution of pre-determined and vetted application on endpoint&quot;},&quot;id&quot;:&quot;533067dfe4b09e5482339b7b&quot;,&quot;name&quot;:&quot;Application Whitelisting&quot;},&quot;5330697de4b09e5482339b7d&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:44,&quot;description&quot;:&quot;Companies that provide a solution to assess the vulnerability of endpoint system&quot;},&quot;id&quot;:&quot;5330697de4b09e5482339b7d&quot;,&quot;name&quot;:&quot;Vulnerability Assessment&quot;},&quot;533aabf1e4b02eaca1338cad&quot;:{&quot;parentId&quot;:&quot;52ff2df2e4b0b193ed664d43&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:226,&quot;description&quot;:&quot;Platform for crowdsourced testing of enterprise application for security bugs and exploits&quot;},&quot;id&quot;:&quot;533aabf1e4b02eaca1338cad&quot;,&quot;name&quot;:&quot;Crowdsourced Security Testing&quot;},&quot;53438e8ae4b03bb69fb23bd5&quot;:{&quot;parentId&quot;:&quot;53295f48e4b07f1af3220cb0&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:133,&quot;description&quot;:&quot;Companies that provide a mobile network access control for BYOD devices&quot;},&quot;id&quot;:&quot;53438e8ae4b03bb69fb23bd5&quot;,&quot;name&quot;:&quot;Mobile NAC&quot;},&quot;5344f426e4b092ee736cf843&quot;:{&quot;parentId&quot;:&quot;52ff2e13e4b0b193ed664d47&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:182,&quot;description&quot;:&quot;Companies that provide a security solution for a cloud-based application and software&quot;},&quot;id&quot;:&quot;5344f426e4b092ee736cf843&quot;,&quot;name&quot;:&quot;Cloud Application Security&quot;},&quot;53463741e4b092ee736cfc82&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:3,&quot;description&quot;:&quot;Companies that provide an unified threat management solution for network security of SMB/SME or remote office&quot;},&quot;id&quot;:&quot;53463741e4b092ee736cfc82&quot;,&quot;name&quot;:&quot;Network UTM&quot;},&quot;534d01afe4b059431aef8956&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:136,&quot;description&quot;:&quot;Companies that provide a solution for the protection of data at rest, in use &amp; in-transit from unauthorized access &amp; modification&quot;},&quot;id&quot;:&quot;534d01afe4b059431aef8956&quot;,&quot;name&quot;:&quot;Data Security&quot;},&quot;53564831e4b0411aaf48b159&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:200,&quot;description&quot;:&quot;Companies that provide security of websites and web services from an internet wide attack&quot;},&quot;id&quot;:&quot;53564831e4b0411aaf48b159&quot;,&quot;name&quot;:&quot;Website Security&quot;},&quot;5357acb3e4b095b7a9fcd924&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:14,&quot;description&quot;:&quot;Companies that provide Virtual Private Network (VPN) for a secure remote access to the interent.&quot;},&quot;id&quot;:&quot;5357acb3e4b095b7a9fcd924&quot;,&quot;name&quot;:&quot;VPN&quot;},&quot;535928bce4b048998cb752d9&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:187,&quot;description&quot;:&quot;Security of users against fraud, identity theft, payment fraud &amp; phone fraud&quot;},&quot;id&quot;:&quot;535928bce4b048998cb752d9&quot;,&quot;name&quot;:&quot;Anti Fraud&quot;},&quot;535de22ce4b0735cb1b3e164&quot;:{&quot;parentId&quot;:&quot;535928bce4b048998cb752d9&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:188,&quot;description&quot;:&quot;Solution to detect and prevent digital identity theft&quot;},&quot;id&quot;:&quot;535de22ce4b0735cb1b3e164&quot;,&quot;name&quot;:&quot;Identity Theft&quot;},&quot;535e6460e4b0b029c534b1d3&quot;:{&quot;parentId&quot;:&quot;532ffec7e4b09e548233984f&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:7,&quot;description&quot;:&quot;Companies that provide a decoy based intrusion detection and deception solution&quot;},&quot;id&quot;:&quot;535e6460e4b0b029c534b1d3&quot;,&quot;name&quot;:&quot;Honeypot&quot;},&quot;53639ca0e4b0c0a1efec7cc5&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:234,&quot;description&quot;:&quot;Actionable, processed, aggregated, relevant &amp; evidence-based knowledge of existing &amp; new threats &amp; vulnerabilities&quot;},&quot;id&quot;:&quot;53639ca0e4b0c0a1efec7cc5&quot;,&quot;name&quot;:&quot;Threat Intelligence&quot;},&quot;53639ca0e4b0c0a1efec7cc6&quot;:{&quot;parentId&quot;:&quot;53639ca0e4b0c0a1efec7cc5&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:236,&quot;description&quot;:&quot;Companies that provide a collaboration platform for updating, managing and sharing cyber threat intelligence to enterprises&quot;},&quot;id&quot;:&quot;53639ca0e4b0c0a1efec7cc6&quot;,&quot;name&quot;:&quot;Enterprise Collaboration&quot;},&quot;5363a93de4b0bacf25f2ce00&quot;:{&quot;parentId&quot;:&quot;534d01afe4b059431aef8956&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:159,&quot;description&quot;:&quot;Companies that provide Hardware Security Module (HSM) or HSM grade security to manage digital keys and perform cryptoprocessing&quot;},&quot;id&quot;:&quot;5363a93de4b0bacf25f2ce00&quot;,&quot;name&quot;:&quot;Hardware Security Module (HSM)&quot;},&quot;536cb875e4b0bb23233efcbd&quot;:{&quot;parentId&quot;:&quot;53639ca0e4b0c0a1efec7cc5&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:235,&quot;description&quot;:&quot;Companies that provide a platform and services which delivers threat intelligence feed&quot;},&quot;id&quot;:&quot;536cb875e4b0bb23233efcbd&quot;,&quot;name&quot;:&quot;Platform &amp; Services&quot;},&quot;5371bca1e4b022d05fc6c31f&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:243,&quot;description&quot;:&quot;Companies that provide a secure gateway and encryption of email communication system&quot;},&quot;id&quot;:&quot;5371bca1e4b022d05fc6c31f&quot;,&quot;name&quot;:&quot;Email Security&quot;},&quot;5371e43be4b022d05fc6c47b&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:49,&quot;description&quot;:&quot;Companies that provide protection &amp; control of a single Internet-connected endpoint from intruders&quot;},&quot;id&quot;:&quot;5371e43be4b022d05fc6c47b&quot;,&quot;name&quot;:&quot;Secure Gateway&quot;},&quot;53720cc7e4b022d05fc6c6a1&quot;:{&quot;parentId&quot;:&quot;53564831e4b0411aaf48b159&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:202,&quot;description&quot;:&quot;Companies that provide a platform for monitoring, vulnerability assessment &amp; audit of websites&quot;},&quot;id&quot;:&quot;53720cc7e4b022d05fc6c6a1&quot;,&quot;name&quot;:&quot;Web Vulnerability Assessment&quot;},&quot;5373251ae4b0595dbe736774&quot;:{&quot;parentId&quot;:&quot;534d01afe4b059431aef8956&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:153,&quot;description&quot;:&quot;Companies that provide a platform for big data security by classifying and enforcing access control&quot;},&quot;id&quot;:&quot;5373251ae4b0595dbe736774&quot;,&quot;name&quot;:&quot;Big Data Security&quot;},&quot;537329bfe4b0595dbe736785&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:96,&quot;description&quot;:&quot;Companies that provide a secure platform to generate and manage  secure password&quot;},&quot;id&quot;:&quot;537329bfe4b0595dbe736785&quot;,&quot;name&quot;:&quot;Password Manager&quot;},&quot;53734e55e4b071174050713b&quot;:{&quot;parentId&quot;:&quot;535928bce4b048998cb752d9&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:194,&quot;description&quot;:&quot;Companies that provide a solution to detect, prevent and protect against phone fraud&quot;},&quot;id&quot;:&quot;53734e55e4b071174050713b&quot;,&quot;name&quot;:&quot;Phone Fraud&quot;},&quot;53748c18e4b085ec4f4d312f&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:46,&quot;description&quot;:&quot;Companies that provide a solution to secure endpoint by virtualizing and isolating the browsing activity for preventing web-based attacks&quot;},&quot;id&quot;:&quot;53748c18e4b085ec4f4d312f&quot;,&quot;name&quot;:&quot;Threat Isolation&quot;},&quot;5374be82e4b085ec4f4d342a&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:74,&quot;description&quot;:&quot;Companies that provide a biometrics-based IAM solution&quot;},&quot;id&quot;:&quot;5374be82e4b085ec4f4d342a&quot;,&quot;name&quot;:&quot;Biometrics&quot;},&quot;5374e1cae4b085ec4f4d3595&quot;:{&quot;parentId&quot;:&quot;53564831e4b0411aaf48b159&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:203,&quot;description&quot;:&quot;Solution which provide real time reputation of a domain to prevent or block cyber threat&quot;},&quot;id&quot;:&quot;5374e1cae4b085ec4f4d3595&quot;,&quot;name&quot;:&quot;Reputation Monitoring&quot;},&quot;5375f10be4b035e7ab6e9547&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:106,&quot;description&quot;:&quot;Companies that provide a platform for IAM governance and access intelligence&quot;},&quot;id&quot;:&quot;5375f10be4b035e7ab6e9547&quot;,&quot;name&quot;:&quot;Intelligence &amp; Governance&quot;},&quot;53ccd374e4b0c99052489339&quot;:{&quot;parentId&quot;:&quot;53564831e4b0411aaf48b159&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:204,&quot;description&quot;:&quot;Companies that provide a platform for the detection of cyber threats in a website&quot;},&quot;id&quot;:&quot;53ccd374e4b0c99052489339&quot;,&quot;name&quot;:&quot;Threat Detection&quot;},&quot;53ff40d8e4b0785237e38b7c&quot;:{&quot;parentId&quot;:&quot;53564831e4b0411aaf48b159&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:205,&quot;description&quot;:&quot;Companies that detect and protect against DDoS attacks including layer 3,4 &amp; 7&quot;},&quot;id&quot;:&quot;53ff40d8e4b0785237e38b7c&quot;,&quot;name&quot;:&quot;DDoS Mitigation&quot;},&quot;54071895e4b0fd800eb0005b&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:259,&quot;description&quot;:&quot;Companies that provide cybersecurity for Operations technology such as IACS &amp; SCADA systems&quot;},&quot;id&quot;:&quot;54071895e4b0fd800eb0005b&quot;,&quot;name&quot;:&quot;Industrial Security&quot;},&quot;5412f794e4b0ff6e2b21fcd6&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:254,&quot;description&quot;:&quot;Security to protect data, identities, devices, IP and servers in the IOT&quot;},&quot;id&quot;:&quot;5412f794e4b0ff6e2b21fcd6&quot;,&quot;name&quot;:&quot;IoT Security&quot;},&quot;545cd365e4b0a2f443016b44&quot;:{&quot;parentId&quot;:&quot;53295f48e4b07f1af3220cb0&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:125,&quot;description&quot;:&quot;Companies that provide Enterprise Mobility Management (EMM) including MDM, MAM, IAM and/or enterprise app store.&quot;},&quot;id&quot;:&quot;545cd365e4b0a2f443016b44&quot;,&quot;name&quot;:&quot;EMM&quot;},&quot;55129e45e4b0fb7fb6ee3dc8&quot;:{&quot;parentId&quot;:&quot;53639ca0e4b0c0a1efec7cc5&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:240,&quot;description&quot;:&quot;Platform which assess and delivers quantitative score of an enterprise security and risk posture&quot;},&quot;id&quot;:&quot;55129e45e4b0fb7fb6ee3dc8&quot;,&quot;name&quot;:&quot;Security &amp; Risk Scorecards&quot;},&quot;55c49718e4b055e17db8dd86&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:34,&quot;description&quot;:&quot;Platform to detect and respond to cyber threat on endpoint devices&quot;},&quot;id&quot;:&quot;55c49718e4b055e17db8dd86&quot;,&quot;name&quot;:&quot;Incident Detection &amp; Response&quot;},&quot;55d5799ce4b0ccb9ba3e7e20&quot;:{&quot;parentId&quot;:&quot;5371bca1e4b022d05fc6c31f&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:244,&quot;description&quot;:&quot;Companies that provide a Secure Email Gateway (SEG) that prevents malicious or rogue email and attachment based on enterprise policy&quot;},&quot;id&quot;:&quot;55d5799ce4b0ccb9ba3e7e20&quot;,&quot;name&quot;:&quot;SEG&quot;},&quot;55d57fe4e4b0ccb9ba3e7f0c&quot;:{&quot;parentId&quot;:&quot;5371bca1e4b022d05fc6c31f&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:250,&quot;description&quot;:&quot;Companies that provide anti-spam, email validation and email abuse detection platform&quot;},&quot;id&quot;:&quot;55d57fe4e4b0ccb9ba3e7f0c&quot;,&quot;name&quot;:&quot;Anti-Spam&quot;},&quot;55d58156e4b0ccb9ba3e7f2d&quot;:{&quot;parentId&quot;:&quot;5371bca1e4b022d05fc6c31f&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:245,&quot;description&quot;:&quot;Companies that provide a solution to encrypt email communication and access control over mail&quot;},&quot;id&quot;:&quot;55d58156e4b0ccb9ba3e7f2d&quot;,&quot;name&quot;:&quot;Email Encryption&quot;},&quot;55d5a577e4b0ccb9ba3e8283&quot;:{&quot;parentId&quot;:&quot;53303049e4b09e5482339a5b&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:221,&quot;description&quot;:&quot;Companies that provide a vulnerability assessment of open source modules, libraries and 3rd party application modules&quot;},&quot;id&quot;:&quot;55d5a577e4b0ccb9ba3e8283&quot;,&quot;name&quot;:&quot;Open Source Component&quot;},&quot;55d5a970e4b0ccb9ba3e8364&quot;:{&quot;parentId&quot;:&quot;53564831e4b0411aaf48b159&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:206,&quot;description&quot;:&quot;Security solution to prevent web scraping &amp; malware execution through network of bots remotely controlled by C&amp;C&quot;},&quot;id&quot;:&quot;55d5a970e4b0ccb9ba3e8364&quot;,&quot;name&quot;:&quot;Botnet Protection&quot;},&quot;55d5b9bee4b045fa07677822&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:59,&quot;description&quot;:&quot;Companies that provide a solution for the creation, management, control and security of privileged accounts and secrets&quot;},&quot;id&quot;:&quot;55d5b9bee4b045fa07677822&quot;,&quot;name&quot;:&quot;Privileged IAM&quot;},&quot;55dc20fae4b068a5fe11694a&quot;:{&quot;parentId&quot;:&quot;53564831e4b0411aaf48b159&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:208,&quot;description&quot;:&quot;Companies that provide a digital certificate for validation of SSL implementation and trusted information exchange&quot;},&quot;id&quot;:&quot;55dc20fae4b068a5fe11694a&quot;,&quot;name&quot;:&quot;Digital Certificate&quot;},&quot;55e830d9e4b00337fcf9357f&quot;:{&quot;parentId&quot;:&quot;53639ca0e4b0c0a1efec7cc5&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:239,&quot;description&quot;:&quot;Platform &amp; service which monitors entire web including dark web for detecting cyber threat and data breach&quot;},&quot;id&quot;:&quot;55e830d9e4b00337fcf9357f&quot;,&quot;name&quot;:&quot;Dark Net Monitoring&quot;},&quot;55ed82d7e4b0126850c78a4e&quot;:{&quot;parentId&quot;:&quot;52ff2df2e4b0b193ed664d43&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:222,&quot;description&quot;:&quot;Companies that provide a Runtime Application Self-Protection (RASP) solution to protect application by identifying and blocking attacks during runtime&quot;},&quot;id&quot;:&quot;55ed82d7e4b0126850c78a4e&quot;,&quot;name&quot;:&quot;RASP&quot;},&quot;560cf14be4b0e484a84b59a4&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:12,&quot;description&quot;:&quot;Companies that provide the security of DNS system/server/software&quot;},&quot;id&quot;:&quot;560cf14be4b0e484a84b59a4&quot;,&quot;name&quot;:&quot;DNS Security&quot;},&quot;5640ffcce4b0920113c70ff5&quot;:{&quot;parentId&quot;:&quot;52ff2e13e4b0b193ed664d47&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:180,&quot;description&quot;:&quot;Companies that provide Cloud Access Security Broker (CASB) tools that act as security gateways for data security, visibility, threat protection and compliance across cloud services&quot;},&quot;id&quot;:&quot;5640ffcce4b0920113c70ff5&quot;,&quot;name&quot;:&quot;CASB&quot;},&quot;564b1801e4b06b8515d7c77e&quot;:{&quot;parentId&quot;:&quot;5412f794e4b0ff6e2b21fcd6&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:255,&quot;description&quot;:&quot;Companies that provide a platform to detect cyber threats and anomalous behavior in IoT infrastructure and application&quot;},&quot;id&quot;:&quot;564b1801e4b06b8515d7c77e&quot;,&quot;name&quot;:&quot;Anomaly Detection&quot;},&quot;5657edefe4b0442049273784&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:275,&quot;description&quot;:&quot;Security &amp; hardening of the servers to prevent unauthorized access &amp; vulnerability attack&quot;},&quot;id&quot;:&quot;5657edefe4b0442049273784&quot;,&quot;name&quot;:&quot;Server Security&quot;},&quot;566015afe4b04c3365bfb798&quot;:{&quot;parentId&quot;:&quot;534d01afe4b059431aef8956&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:155,&quot;description&quot;:&quot;Companies that provide Digital Rights Management (DRM) of enterprise document and software&quot;},&quot;id&quot;:&quot;566015afe4b04c3365bfb798&quot;,&quot;name&quot;:&quot;Enterprise DRM&quot;},&quot;56607831e4b031f08d379f19&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:1,&quot;description&quot;:&quot;Platform that provide security across enterprise including data, infrastructure, access &amp; employs intelligence &amp; analytics&quot;},&quot;id&quot;:&quot;56607831e4b031f08d379f19&quot;,&quot;name&quot;:&quot;Suite&quot;},&quot;5660842ae4b031f08d379f29&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:107,&quot;description&quot;:&quot;Analytics of security information, event &amp; system for threat prevention, detection, mitigation across enterprise&quot;},&quot;id&quot;:&quot;5660842ae4b031f08d379f29&quot;,&quot;name&quot;:&quot;Security Analytics&quot;},&quot;566085cfe4b031f08d379f2a&quot;:{&quot;parentId&quot;:&quot;5660842ae4b031f08d379f29&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:118,&quot;description&quot;:&quot;Companies that provide analytics based solutions for threat detection at enterprise IT level&quot;},&quot;id&quot;:&quot;566085cfe4b031f08d379f2a&quot;,&quot;name&quot;:&quot;Threat Detection&quot;},&quot;566085cfe4b031f08d379f2b&quot;:{&quot;parentId&quot;:&quot;5660842ae4b031f08d379f29&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:110,&quot;description&quot;:&quot;Companies that provide a assessment and management of the enterprise-wide cyber-risk and vulnerabilities present&quot;},&quot;id&quot;:&quot;566085cfe4b031f08d379f2b&quot;,&quot;name&quot;:&quot;Cyber Risk &amp; Vulnerability Assessment&quot;},&quot;5660938ee4b031f08d379f32&quot;:{&quot;parentId&quot;:&quot;5660842ae4b031f08d379f29&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:108,&quot;description&quot;:&quot;Companies that provide a platform for Security Information and Event Management (SIEM)&quot;},&quot;id&quot;:&quot;5660938ee4b031f08d379f32&quot;,&quot;name&quot;:&quot;SIEM&quot;},&quot;5662bfeee4b05dae5f69796c&quot;:{&quot;parentId&quot;:&quot;534d01afe4b059431aef8956&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:156,&quot;description&quot;:&quot;Companies that provide a platform for Data Loss Prevention (DLP) and unauthorized exfiltration outside the enterprise&quot;},&quot;id&quot;:&quot;5662bfeee4b05dae5f69796c&quot;,&quot;name&quot;:&quot;Data Loss Prevention (DLP)&quot;},&quot;56646606e4b05dae5f697ec1&quot;:{&quot;parentId&quot;:&quot;5660842ae4b031f08d379f29&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:122,&quot;description&quot;:&quot;Companies that provide a cyber forensics platform to analyze previously captured data packets and reverse engineer&quot;},&quot;id&quot;:&quot;56646606e4b05dae5f697ec1&quot;,&quot;name&quot;:&quot;Cyber Forensics&quot;},&quot;56646bf4e4b05dae5f697ed1&quot;:{&quot;parentId&quot;:&quot;532ffec7e4b09e548233984f&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:6,&quot;description&quot;:&quot;Companies that provide a real time intrusion detection based on network activity and bandwidth pattern&quot;},&quot;id&quot;:&quot;56646bf4e4b05dae5f697ed1&quot;,&quot;name&quot;:&quot;Network Traffic Analytics&quot;},&quot;56648cd6e4b05dae5f697f90&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:274,&quot;description&quot;:&quot;Companies that provide a solution for the access control, auditing, encryption, integrity controls and secure backup of a database&quot;},&quot;id&quot;:&quot;56648cd6e4b05dae5f697f90&quot;,&quot;name&quot;:&quot;Database Security&quot;},&quot;566509f2e4b0a6e97ece0ceb&quot;:{&quot;parentId&quot;:&quot;52ff2e13e4b0b193ed664d47&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:178,&quot;description&quot;:&quot;Security for virtual infrastructure such as public/private cloud, VM Server, Workload, Hypervisor, Container&quot;},&quot;id&quot;:&quot;566509f2e4b0a6e97ece0ceb&quot;,&quot;name&quot;:&quot;Cloud Infrastructure Security&quot;},&quot;56650ac9e4b030508478a794&quot;:{&quot;parentId&quot;:&quot;52ff2e13e4b0b193ed664d47&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:184,&quot;description&quot;:&quot;Companies that provide cyber security solution for the virtualised software containers&quot;},&quot;id&quot;:&quot;56650ac9e4b030508478a794&quot;,&quot;name&quot;:&quot;Container Security&quot;},&quot;566584ace4b017eeb445a7fb&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:9,&quot;description&quot;:&quot;Companies that provide solutions which filters traffic between two or more networks based on security rules&quot;},&quot;id&quot;:&quot;566584ace4b017eeb445a7fb&quot;,&quot;name&quot;:&quot;Firewall&quot;},&quot;5666b3cce4b0e5adf67b82d0&quot;:{&quot;parentId&quot;:&quot;566085cfe4b031f08d379f2a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:119,&quot;description&quot;:&quot;Companies that provide security analytics like UEBA to detect threat initiated or already present inside enterprise network&quot;},&quot;id&quot;:&quot;5666b3cce4b0e5adf67b82d0&quot;,&quot;name&quot;:&quot;Insider Threat Detection&quot;},&quot;5667c368e4b0716ca7d54d6d&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:92,&quot;description&quot;:&quot;Companies that provide modules &amp; technology solution for the implementation and management of IAM  system&quot;},&quot;id&quot;:&quot;5667c368e4b0716ca7d54d6d&quot;,&quot;name&quot;:&quot;Technology&quot;},&quot;56690a78e4b0a29d350871ba&quot;:{&quot;parentId&quot;:&quot;53295f48e4b07f1af3220cb0&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:126,&quot;description&quot;:&quot;Companies that provide Mobile Device Management (MDM) software that allows IT administrators to control, secure and enforce policies on smartphones, tablets and other endpoints.&quot;},&quot;id&quot;:&quot;56690a78e4b0a29d350871ba&quot;,&quot;name&quot;:&quot;MDM&quot;},&quot;56690a78e4b0a29d350871bb&quot;:{&quot;parentId&quot;:&quot;53295f48e4b07f1af3220cb0&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:128,&quot;description&quot;:&quot;Mobile Application Management (MAM) solution by whitelisting, application catalogue &amp; arbitrary injecting encryption code in app&quot;},&quot;id&quot;:&quot;56690a78e4b0a29d350871bb&quot;,&quot;name&quot;:&quot;MAM&quot;},&quot;56690a78e4b0a29d350871bc&quot;:{&quot;parentId&quot;:&quot;56690a78e4b0a29d350871ba&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:127,&quot;description&quot;:&quot;MDM solution which employs separate encrypted containers for personal &amp; workspace on single device&quot;},&quot;id&quot;:&quot;56690a78e4b0a29d350871bc&quot;,&quot;name&quot;:&quot;Workspace Containerization&quot;},&quot;56690ca0e4b09e473de73598&quot;:{&quot;parentId&quot;:&quot;56690a78e4b0a29d350871bb&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:131,&quot;description&quot;:&quot;Companies that provide a layer of security wrapping over apps to protect against attacks &amp; data theft&quot;},&quot;id&quot;:&quot;56690ca0e4b09e473de73598&quot;,&quot;name&quot;:&quot;Application Wrapping&quot;},&quot;56690ca0e4b09e473de73599&quot;:{&quot;parentId&quot;:&quot;56690a78e4b0a29d350871bb&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:130,&quot;description&quot;:&quot;Companies that analyze and manage apps based on profiling as per enterprise policies&quot;},&quot;id&quot;:&quot;56690ca0e4b09e473de73599&quot;,&quot;name&quot;:&quot;Application Profiling&quot;},&quot;56690ca0e4b09e473de7359a&quot;:{&quot;parentId&quot;:&quot;56690a78e4b0a29d350871bb&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:129,&quot;description&quot;:&quot;Solution for the remote access to app on a BYOD device running over a secure virtual mobile infrastructure (VMI)&quot;},&quot;id&quot;:&quot;56690ca0e4b09e473de7359a&quot;,&quot;name&quot;:&quot;Application Virtualization&quot;},&quot;566936b9e4b0ccc692309dc3&quot;:{&quot;parentId&quot;:&quot;5660842ae4b031f08d379f29&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:121,&quot;description&quot;:&quot;Platform or service to respond &amp; mitigate already detected threat incident in enterprise&quot;},&quot;id&quot;:&quot;566936b9e4b0ccc692309dc3&quot;,&quot;name&quot;:&quot;Incident Response&quot;},&quot;566dbff1e4b0ac980bffaee1&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d46&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:66,&quot;description&quot;:&quot;Companies that provide a Single Sign-On (SSO) solution to log in  on web &amp; mobile sites and applications&quot;},&quot;id&quot;:&quot;566dbff1e4b0ac980bffaee1&quot;,&quot;name&quot;:&quot;SSO&quot;},&quot;566ecc97e4b087555e724e26&quot;:{&quot;parentId&quot;:&quot;5412f794e4b0ff6e2b21fcd6&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:257,&quot;description&quot;:&quot;Companies that provide an embedded hardware or a software development kit for the IoT security&quot;},&quot;id&quot;:&quot;566ecc97e4b087555e724e26&quot;,&quot;name&quot;:&quot;Embeddable IoT Security&quot;},&quot;568eb20fe4b04d1ab768d5a7&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:56,&quot;description&quot;:&quot;Companies that provide a unified identity and access management solution&quot;},&quot;id&quot;:&quot;568eb20fe4b04d1ab768d5a7&quot;,&quot;name&quot;:&quot;Unified IAM&quot;},&quot;56a9b573e4b0079795f189f1&quot;:{&quot;parentId&quot;:&quot;52ff2df2e4b0b193ed664d43&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:225,&quot;description&quot;:&quot;Security of API &amp; API servers from attacks like denial of services, heartbleed, logjam, poodle etc&quot;},&quot;id&quot;:&quot;56a9b573e4b0079795f189f1&quot;,&quot;name&quot;:&quot;API Security&quot;},&quot;56bd9b65e4b0167a5f0ba8d8&quot;:{&quot;parentId&quot;:&quot;535de22ce4b0735cb1b3e164&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:191,&quot;description&quot;:&quot;Companies that provide a solution to verify ID document digitally to prevent cyber fraud&quot;},&quot;id&quot;:&quot;56bd9b65e4b0167a5f0ba8d8&quot;,&quot;name&quot;:&quot;ID Document Verification&quot;},&quot;56d97b2ce4b096207eeba95e&quot;:{&quot;parentId&quot;:&quot;54071895e4b0fd800eb0005b&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:260,&quot;description&quot;:&quot;Companies that provide vulnerability assessment of industrial cybersecurity posture&quot;},&quot;id&quot;:&quot;56d97b2ce4b096207eeba95e&quot;,&quot;name&quot;:&quot;Vulnerability Assessment&quot;},&quot;56d98df2e4b064ac7d89fe9f&quot;:{&quot;parentId&quot;:&quot;54071895e4b0fd800eb0005b&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:261,&quot;description&quot;:&quot;Companies that provide a platform to detect cyber threats in the operational technology network including ICS &amp; SCADA systems&quot;},&quot;id&quot;:&quot;56d98df2e4b064ac7d89fe9f&quot;,&quot;name&quot;:&quot;Threat Detection&quot;},&quot;56d9b8d2e4b064ac7d8a0a46&quot;:{&quot;parentId&quot;:&quot;54071895e4b0fd800eb0005b&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:262,&quot;description&quot;:&quot;Companies that provide a solution to prevent cyber attacks on industrial systems including OT network, ICS/SCADA systems&quot;},&quot;id&quot;:&quot;56d9b8d2e4b064ac7d8a0a46&quot;,&quot;name&quot;:&quot;Threat Prevention&quot;},&quot;570b68d5e4b0b544cd006a5e&quot;:{&quot;parentId&quot;:&quot;5657edefe4b0442049273784&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:276,&quot;description&quot;:&quot;Companies that provide security solution for operating system of server&quot;},&quot;id&quot;:&quot;570b68d5e4b0b544cd006a5e&quot;,&quot;name&quot;:&quot;OS Security&quot;},&quot;571742c7e4b0aafdf9f3a700&quot;:{&quot;parentId&quot;:&quot;5374be82e4b085ec4f4d342a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:77,&quot;description&quot;:&quot;Companies that provide an authentication platform based on innate human features like a fingerprint, iris pattern etc.&quot;},&quot;id&quot;:&quot;571742c7e4b0aafdf9f3a700&quot;,&quot;name&quot;:&quot;Physiological&quot;},&quot;571742c7e4b0aafdf9f3a701&quot;:{&quot;parentId&quot;:&quot;5374be82e4b085ec4f4d342a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:75,&quot;description&quot;:&quot;Companies that provide an authentication platform based on identifying and confirming measurable patterns in human activities&quot;},&quot;id&quot;:&quot;571742c7e4b0aafdf9f3a701&quot;,&quot;name&quot;:&quot;Behavioral&quot;},&quot;5732f379e4b0bd8b59fc4788&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:25,&quot;description&quot;:&quot;Companies that provide Network Access Control (NAC) solution for controlled access to the internal network&quot;},&quot;id&quot;:&quot;5732f379e4b0bd8b59fc4788&quot;,&quot;name&quot;:&quot;Network Access Control&quot;},&quot;574fdd9ae4b0f0e47ea4f63d&quot;:{&quot;parentId&quot;:&quot;534d01afe4b059431aef8956&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:160,&quot;description&quot;:&quot;Companies that provide a solution for data security and privacy by tokenization and obfuscation&quot;},&quot;id&quot;:&quot;574fdd9ae4b0f0e47ea4f63d&quot;,&quot;name&quot;:&quot;Data Masking&quot;},&quot;575ab8f7e4b0cb636486739f&quot;:{&quot;parentId&quot;:&quot;534d01afe4b059431aef8956&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:137,&quot;description&quot;:&quot;Companies that provide security of data stored or moving through cloud-based storage&quot;},&quot;id&quot;:&quot;575ab8f7e4b0cb636486739f&quot;,&quot;name&quot;:&quot;Cloud Data Security&quot;},&quot;57763800e4b038d315f6c6a2&quot;:{&quot;parentId&quot;:&quot;534d01afe4b059431aef8956&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:162,&quot;description&quot;:&quot;Companies that provide a software to erase &amp; destroy data stored in digital storage system to prevent unauthorized access&quot;},&quot;id&quot;:&quot;57763800e4b038d315f6c6a2&quot;,&quot;name&quot;:&quot;Data Shredding&quot;},&quot;57835e1fe4b05105dcebe4c4&quot;:{&quot;parentId&quot;:&quot;53639ca0e4b0c0a1efec7cc5&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:242,&quot;description&quot;:&quot;Companies that provide a platform for cybersecurity professionals and companies to discuss and share knowledge&quot;},&quot;id&quot;:&quot;57835e1fe4b05105dcebe4c4&quot;,&quot;name&quot;:&quot;Professional Community&quot;}
</code></pre>
<p>Have some code that will build the tree in the order that I am looking for:</p>
<pre><code>import json

data = json.load(open('x.json'))

class Node:
    def __init__(self, dct):
        self.id = dct['id']
        self.name = dct['name']
        self.parent = dct['parentId']
        self.children = []

def insert( tree, node ):
    if tree.id == node.parent:
        tree.children.append( node )
        return True
    for n in tree.children:
        if insert( n, node ):
            return True

def traverse( tree, pfx='' ):
    pfx = tree.name if not pfx else ' '.join((pfx, '&gt;', tree.name))
    print( pfx )
    for n in tree.children:
        traverse( n, pfx )

tree = Node(
    {
        'id': &quot;52ff2cfce4b0b193ed664d1a&quot;,
        'name': 'Cybersecurity',
        'parentId': None
    }
)
for k,v in data['businessModelInfo'].items():
    if not insert( tree, Node(v) ):
        print( v, &quot;location not found&quot; )

traverse( tree )
</code></pre>
<p>New Edit:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th style=""text-align: center;"">Parent</th>
<th style=""text-align: center;"">Child</th>
<th style=""text-align: center;"">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style=""text-align: center;"">Ad Blocker</td>
<td style=""text-align: center;"">Adblock Tester</td>
<td style=""text-align: center;"">Description</td>
</tr>
<tr>
<td style=""text-align: center;"">Industry Specific</td>
<td style=""text-align: center;"">Automotive</td>
<td style=""text-align: center;"">Description</td>
</tr>
<tr>
<td style=""text-align: center;"">Anti Phishing</td>
<td style=""text-align: center;"">BEC Detection</td>
<td style=""text-align: center;"">Description</td>
</tr>
</tbody>
</table>
</div>",106,2,2,3,python;json;web-scraping,2022-07-15 16:34:27,2022-07-15 16:34:27,2022-07-22 19:31:45,i m parsing json data into a tree to build a hierarchy structure  and i was wondering if someone could please help me  here is a sample of the json  have some code that will build the tree in the order that i am looking for  new edit ,turning json into a hierarchy tree
101,651174,73073417,GCP structure for local environment,"<p>Under <strong>Naming Developer Environments</strong>, it suggests to have a separate GCP project for each environment:</p>
<blockquote>
<p>Cloud-based software projects should employ multiple environments. These environments typically have names like <code>dev</code>, <code>qa</code>, <code>staging</code>, and <code>prod</code>. It's vital that these environments be completely isolated from one another, and they typically have very different operator-access permissions.</p>
</blockquote>
<blockquote>
<p>Using multiple <a href=""https://cloud.google.com/resource-manager/docs/creating-managing-projects"" rel=""nofollow noreferrer"">Cloud projects</a> suits these requirements perfectly as the projects provide complete isolation of code and data, and operator permissions can be managed separately.</p>
</blockquote>
<p>Does this mean, for example, that all local development should have one shared and separate project to connect to? For example, if someone is devloping on a laptop, their credentials should point to the <code>dev</code> environment, no matter how many developers are locally developing? Would there be any downside of having local <code>dev</code> point to the same one that <code>staging</code> points to?</p>
",68,0,-1,1,google-cloud-platform,2022-07-22 01:45:25,2022-07-22 01:45:25,2022-07-22 01:45:25,under naming developer environments  it suggests to have a separate gcp project for each environment  cloud based software projects should employ multiple environments  these environments typically have names like dev  qa  staging  and prod  it s vital that these environments be completely isolated from one another  and they typically have very different operator access permissions  using multiple  suits these requirements perfectly as the projects provide complete isolation of code and data  and operator permissions can be managed separately  does this mean  for example  that all local development should have one shared and separate project to connect to  for example  if someone is devloping on a laptop  their credentials should point to the dev environment  no matter how many developers are locally developing  would there be any downside of having local dev point to the same one that staging points to ,gcp structure for local environment
102,116268,11487390,&quot;No Disk&quot; error using GDAL from C#/.NET,"<p>I am using <a href=""http://vbkto.dyndns.org/sdk/"" rel=""noreferrer"">Tamas Szekeres</a> builds of <a href=""http://trac.osgeo.org/gdal/wiki/GdalOgrInCsharp"" rel=""noreferrer"">GDAL</a> including the C# bindings in a desktop GIS application using C# and .net 4.0</p>

<p>I am including the entire GDAL distribution in a sub-directory of my executable with the following folder structure: </p>

<pre><code>\Plugins\GDAL
\Plugins\GDAL\gdal
\Plugins\GDAL\gdal-data
\Plugins\GDAL\proj
</code></pre>

<p>We are using EPSG:4326, and the software is built using 32-bit target since the GDAL C# API is using <a href=""http://en.wikipedia.org/wiki/Platform_Invocation_Services"" rel=""noreferrer"">p/invoke</a> to the 32-bit libraries (could try 64 bit since Tamas provides these, haven't gotten around to it yet).</p>

<p>When I run my application I get the following error</p>

<p><img src=""https://i.stack.imgur.com/6EKzZ.png"" alt=""enter image description here""></p>

<p>This error typically happens when software <a href=""http://support.microsoft.com/kb/330137"" rel=""noreferrer"">tries to access a device</a> that is no longer attached, such as a removable drive. It is not possible to ""catch"" this exception because it pops up a system dialog.</p>

<p>After dismissing the dialog using any of the buttons, the software continues to execute as designed.</p>

<p>The error occurs the first time I call the following method</p>

<pre><code>OSGeo.OSR.CoordinateTransformation.TransformPoint(double[] inout);
</code></pre>

<h2>The strange stuff:</h2>

<ul>
<li>The error occurs on one, and only one computer (so far)</li>
<li>I've run this software in several other computers both 32 and 64 bit without problems</li>
<li>The error does not ocurr on the first run after compiling the GDAL shim library I am using, <em>it only occurrs on each subsequent run</em></li>
<li>it happens regardless of release, or debug builds</li>
<li>it happens regardless of whether the debugger is attached or not</li>
<li>it happens regardless of whether I turn on or off Gdal.UseExceptions or Osr.UseExceptions();</li>
<li><strong>disabling removable drives causes the bug to disappear.</strong> This is not what I consider a real solution as I will not be able to ask a customer to do this.</li>
</ul>

<p>I have tried the following:</p>

<ul>
<li>catching the error</li>
<li>changing GDAL directories and environment settings</li>
<li>changing computers and operating systems: this worked</li>
<li>used SysInternals ProcMon to trace what files are being opened with no luck, they all appear to be files that exist</li>
<li>I re-built the computer in question when the hard drive failed, to no avail.</li>
<li>""cleaning"" the registry using <a href=""http://www.piriform.com/CCLEANER"" rel=""noreferrer"">CCleaner</a></li>
<li>files in GDAL Directory are unchanged on execution</li>
</ul>

<h2>Assumptions</h2>

<ul>
<li>Error is happening in unmanaged code</li>
<li><strong>During GDAL initialization, some path is referring to a drive on the computer that is no longer attached</strong>.</li>
<li><strong>I am also working on the assumption this is limited to a computer configuration error</strong></li>
</ul>

<h2>Configuration</h2>

<ul>
<li>Windows 7 Pro</li>
<li>Intel Core i7 920 @ 2,67GHz</li>
<li>12.0 GB RAM</li>
<li>64-bit OS</li>
<li>Drive C: 120 GB SSD with OS, development (Visual Studio 10), etc</li>
<li>Drive D: 1 TB WD 10,000k with data, not being accessed for data. </li>
</ul>

<h2>The Question</h2>

<p>I either need a direction to trap the error, or a tool or technique that will allow me to figure out what is causing it. I don't want to release the software with the possibility that some systems will have this behaviour.</p>
",796,5,14,5,c#;.net;windows;gis;gdal,2012-07-15 00:05:25,2012-07-15 00:05:25,2022-07-21 20:06:26,i am using  builds of  including the c  bindings in a desktop gis application using c  and  net   i am including the entire gdal distribution in a sub directory of my executable with the following folder structure   we are using epsg   and the software is built using  bit target since the gdal c  api is using  to the  bit libraries  could try  bit since tamas provides these  haven t gotten around to it yet   when i run my application i get the following error  this error typically happens when software  that is no longer attached  such as a removable drive  it is not possible to catch this exception because it pops up a system dialog  after dismissing the dialog using any of the buttons  the software continues to execute as designed  the error occurs the first time i call the following method i have tried the following  i either need a direction to trap the error  or a tool or technique that will allow me to figure out what is causing it  i don t want to release the software with the possibility that some systems will have this behaviour , no disk  error using gdal from c   net
103,10834788,63798865,Unable to start Apache Superset due to failed PostgresDB connection using Docker,"<p>I am trying to install Superset using Docker. However, following the instructions, I am encountering an issue where the database connection is refused. I check the logs, the container responsible for database service is up and running but when I checked its logs, I see the following FATAL message:</p>
<pre><code>2020-09-08 17:19:36.863 UTC [33] FATAL:  database &quot;test&quot; does not exist
</code></pre>
<p><a href=""https://superset.incubator.apache.org/installation.html#start-with-docker"" rel=""nofollow noreferrer"">This</a> is how I attempt to install Superset.</p>
<p>Following is the error I face when I run the command, <code>sudo docker-compose up</code>:</p>
<pre><code>superset_app             | ERROR:flask_appbuilder.security.sqla.manager:DB Creation and initialization failed: (psycopg2.OperationalError) could not connect to server: No route to host
superset_app             |  Is the server running on host &quot;db&quot; (172.18.0.3) and accepting
superset_app             |  TCP/IP connections on port 5432?
superset_app             | 
superset_app             | (Background on this error at: http://sqlalche.me/e/13/e3q8)

</code></pre>
<p>The same error appears in other services as well.</p>
<p><a href=""https://github.com/apache/incubator-superset/blob/master/docker-compose.yml"" rel=""nofollow noreferrer"">docker-compose.yml</a>:</p>
<pre><code>#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the &quot;License&quot;); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
x-superset-build: &amp;superset-build
  args:
    NPM_BUILD_CMD: build-dev
  context: ./
  dockerfile: Dockerfile-dev
x-superset-depends-on: &amp;superset-depends-on
  - db
  - redis
x-superset-volumes: &amp;superset-volumes
  # /app/pythonpath_docker will be appended to the PYTHONPATH in the final container
  - ./docker/docker-init.sh:/app/docker-init.sh
  - ./docker/pythonpath_dev:/app/pythonpath
  - ./superset:/app/superset
  - ./superset-frontend:/app/superset-frontend
  - superset_home:/app/superset_home

version: &quot;3.7&quot;
services:
  redis:
    image: redis:3.2
    container_name: superset_cache
    restart: unless-stopped
    ports:
      - &quot;127.0.0.1:6379:6379&quot;
    volumes:
      - redis:/data

  db:
    env_file: docker/.env
    image: postgres:10
    container_name: superset_db
    restart: unless-stopped
    ports:
      - &quot;127.0.0.1:5432:5432&quot;
    volumes:
      - db_home:/var/lib/postgresql/data

  superset:
    env_file: docker/.env
    build: *superset-build
    container_name: superset_app
    command: [&quot;flask&quot;, &quot;run&quot;, &quot;-p&quot;, &quot;8088&quot;, &quot;--with-threads&quot;, &quot;--reload&quot;, &quot;--debugger&quot;, &quot;--host=0.0.0.0&quot;]
    restart: unless-stopped
    ports:
      - 8088:8088
    depends_on: *superset-depends-on
    volumes: *superset-volumes

  superset-init:
    build: *superset-build
    container_name: superset_init
    command: [&quot;/app/docker-init.sh&quot;]
    env_file: docker/.env
    depends_on: *superset-depends-on
    volumes: *superset-volumes

  superset-node:
    image: node:12
    container_name: superset_node
    command: [&quot;bash&quot;, &quot;-c&quot;, &quot;cd /app/superset-frontend &amp;&amp; npm install -f --no-optional --global webpack webpack-cli &amp;&amp; npm install -f --no-optional &amp;&amp; npm run dev&quot;]
    env_file: docker/.env
    depends_on: *superset-depends-on
    volumes: *superset-volumes

  superset-worker:
    build: *superset-build
    container_name: superset_worker
    command: [&quot;celery&quot;, &quot;worker&quot;, &quot;--app=superset.tasks.celery_app:app&quot;, &quot;-Ofair&quot;, &quot;-l&quot;, &quot;INFO&quot;]
    env_file: docker/.env
    restart: unless-stopped
    depends_on: *superset-depends-on
    volumes: *superset-volumes

  superset-tests-worker:
    build: *superset-build
    container_name: superset_tests_worker
    command: [&quot;celery&quot;, &quot;worker&quot;, &quot;--app=superset.tasks.celery_app:app&quot;, &quot;-Ofair&quot;, &quot;-l&quot;, &quot;INFO&quot;]
    env_file: docker/.env
    environment:
      DATABASE_HOST: localhost
      DATABASE_DB: test
      REDIS_CELERY_DB: 2
      REDIS_RESULTS_DB: 3
      REDIS_HOST: localhost
    network_mode: host
    depends_on: *superset-depends-on
    volumes: *superset-volumes

volumes:
  superset_home:
    external: false
  db_home:
    external: false
  redis:
    external: false
</code></pre>
<p><a href=""https://github.com/apache/incubator-superset/blob/master/docker/.env"" rel=""nofollow noreferrer"">.env file</a>:</p>
<pre><code>#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the &quot;License&quot;); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
COMPOSE_PROJECT_NAME=superset

# database configurations (do not modify)
DATABASE_DB=superset
DATABASE_HOST=db
DATABASE_PASSWORD=superset
DATABASE_USER=superset

# database engine specific environment variables
# change the below if you prefers another database engine
DATABASE_PORT=5432
DATABASE_DIALECT=postgresql
POSTGRES_DB=superset
POSTGRES_USER=superset
POSTGRES_PASSWORD=superset
#MYSQL_DATABASE=superset
#MYSQL_USER=superset
#MYSQL_PASSWORD=superset
#MYSQL_RANDOM_ROOT_PASSWORD=yes

# Add the mapped in /app/pythonpath_docker which allows devs to override stuff
PYTHONPATH=/app/pythonpath:/app/pythonpath_docker
REDIS_HOST=redis
REDIS_PORT=6379

FLASK_ENV=development
SUPERSET_ENV=development
SUPERSET_LOAD_EXAMPLES=yes
</code></pre>
<p>I tried to work out this issue from any of the solutions presented in the <a href=""https://github.com/apache/incubator-superset/issues/8880"" rel=""nofollow noreferrer"">official repository</a> but in vain.
How do I resolve this issue and complete the installation?</p>
",2722,1,3,5,python-3.x;postgresql;docker;docker-compose;apache-superset,2020-09-08 20:29:17,2020-09-08 20:29:17,2022-07-21 19:13:51,i am trying to install superset using docker  however  following the instructions  i am encountering an issue where the database connection is refused  i check the logs  the container responsible for database service is up and running but when i checked its logs  i see the following fatal message   is how i attempt to install superset  following is the error i face when i run the command  sudo docker compose up  the same error appears in other services as well     ,unable to start apache superset due to failed postgresdb connection using docker
104,10375974,73064734,Node.JS net.Socket/TCP Server Remote Address issue,"<p>I am doing game development, and have set up an TCP server for handling the server side of the game. I am trying to obtain the players IP serverside, and i currently use the net.Socket remoteAddress feature, but it gives <code>::ffff:</code> before the IPv4, and i am only looking to get the pure IPv4. How  can i properly obtain this?</p>
<p>I'm currently using the following code in the server software to obtain IP:</p>
<pre><code>const connectedClientIP = socket.remoteAddress;
</code></pre>
",17,0,0,4,javascript;node.js;tcp;tcplistener,2022-07-21 13:42:48,2022-07-21 13:42:48,2022-07-21 13:42:48,i am doing game development  and have set up an tcp server for handling the server side of the game  i am trying to obtain the players ip serverside  and i currently use the net socket remoteaddress feature  but it gives   ffff  before the ipv  and i am only looking to get the pure ipv  how  can i properly obtain this  i m currently using the following code in the server software to obtain ip ,node js net socket tcp server remote address issue
105,19500329,73052352,Sort backend or frontend for multiple results on a screen,"<p>New to programming and software development.
The front end has a screen that has 2 panes. Right pane has Name, height, weight and age in a table form. Left pane lists these column names.
If a user clicks on Name on the left side, the table on right has to be sorted in ascending order based on Name. If the user clicks on any other options, table has to be sorted based on that value in descending order.</p>
<p>There 72000 rows in total. Data comes from a single View in the backend in json format.</p>
<p>Should the sorting be done on the backend or should the front end do it?
What are the common ways of achieving this ?
Which is more efficient ?</p>
<p>Front end - React
Backend- MySQL</p>
",49,1,-1,5,mysql;reactjs;architecture;frontend;backend,2022-07-20 16:16:18,2022-07-20 16:16:18,2022-07-21 05:35:30,there  rows in total  data comes from a single view in the backend in json format ,sort backend or frontend for multiple results on a screen
106,293518,35272533,Flattening deeply nested array of objects,"<p>I got following data structure, which is an array of accounts objects, where some accounts are being parents to its children accounts, which in turn can be parents to other accounts etc.:   </p>

<pre class=""lang-js prettyprint-override""><code>[{
  ""id"": ""acc.1260446672222.11"",
  ""type"": ""EXPENSES_FOLDER"",
  ""name"": ""Expense Group"",
  ""balance"": 3418.11,
  ""children"": [{
    ""id"": ""acc.1260446672238.27"",
    ""type"": ""EXPENSE"",
    ""name"": ""Advertising, Promotion and Entertainment Account"",
    ""balance"": 0,
    ""children"": []
  }, {
    ""id"": ""acc.9a2492ba-0d82-4f4a-a1b4-14868f1e1a39"",
    ""type"": ""EXPENSES_FOLDER"",
    ""name"": ""Premises Costs"",
    ""balance"": 0,
    ""children"": [{
      ""id"": ""acc.287ba5b6-5536-428b-950f-d71d2af73ccc"",
      ""type"": ""EXPENSE"",
      ""name"": ""Use of Home - Gas"",
      ""balance"": 0,
      ""children"": [

      ]
    }, {
      ""id"": ""acc.7091ee15-3f02-4bd1-94e5-5918cf986969"",
      ""type"": ""EXPENSE"",
      ""name"": ""Hire of Venue, Studios, Teaching Rooms"",
      ""balance"": 0,
      ""children"": [

      ]
    }]
  }, {
    ""id"": ""acc.827ec446-edeb-4f2b-8032-d306292d2d83"",
    ""type"": ""EXPENSES_FOLDER"",
    ""name"": ""Administrative Expenses"",
    ""balance"": 558.61,
    ""children"": [{
      ""id"": ""acc.0ed5fc81-7734-4452-86a9-db22a6b0f8e8"",
      ""type"": ""EXPENSE"",
      ""name"": ""Bank Charges"",
      ""balance"": 15,
      ""children"": [

      ]
    }, {
      ""id"": ""acc.e2cdb2c0-8565-4991-a35a-d4596b0ddf45"",
      ""type"": ""EXPENSE"",
      ""name"": ""Software &amp; Computer Peripherals"",
      ""balance"": 417.13,
      ""children"": [

      ]
    }, {
      ""id"": ""acc.96d5d00e-43f4-4d3a-b97b-fdf258c65514"",
      ""type"": ""EXPENSE"",
      ""name"": ""Printing, photocopying etc"",
      ""balance"": 55.93,
      ""children"": [

      ]
    }, {
      ""id"": ""acc.494dd64a-4fb3-42b8-be3e-8f3b59a2ef59"",
      ""type"": ""EXPENSE"",
      ""name"": ""Artists Administration Service"",
      ""balance"": 0,
      ""children"": [

      ]
    }, {
      ""id"": ""acc.1260446672238.35"",
      ""type"": ""EXPENSE"",
      ""name"": ""Stationery"",
      ""balance"": 0,
      ""children"": [

      ]
    }, {
      ""id"": ""acc.96d89d0d-5465-488b-b37f-d41ca114c5e6"",
      ""type"": ""EXPENSE"",
      ""name"": ""Mobile Telephone"",
      ""balance"": 41.19,
      ""children"": [

      ]
    }, {
      ""id"": ""acc.1260446672238.33"",
      ""type"": ""EXPENSE"",
      ""name"": ""Home Telephone"",
      ""balance"": 0,
      ""children"": [

      ]
    }, {
      ""id"": ""acc.1260446672238.38"",
      ""type"": ""EXPENSE"",
      ""name"": ""Postage/delivery"",
      ""balance"": 29.36,
      ""children"": [

      ]
    }]
  }, {
    ""id"": ""acc.b9c9bbc7-43df-472e-9ac8-c7c76f08f49a"",
    ""type"": ""EXPENSES_FOLDER"",
    ""name"": ""Instruments, Equipment Maintenance etc"",
    ""balance"": 1002.48,
    ""children"": [{
      ""id"": ""acc.1260446672238.32"",
      ""type"": ""OTHER_EXPENSES"",
      ""name"": ""Instrument Insurance"",
      ""balance"": 157.48,
      ""children"": [

      ]
    }, {
      ""id"": ""acc.2a1cca15-2868-4770-a3e7-d43a6268c6a1"",
      ""type"": ""EXPENSE"",
      ""name"": ""Instrument Repairs &amp; Maintenance"",
      ""balance"": 845,
      ""children"": [

      ]
    }, {
      ""id"": ""acc.a908aee0-84fb-450a-916b-4cec25265aef"",
      ""type"": ""EXPENSE"",
      ""name"": ""Accessories &amp; Replacement Parts"",
      ""balance"": 0,
      ""children"": [

      ]
    }]
  }, {
    ""id"": ""acc.a42cdd86-0d9e-4f3f-af0d-7c4525374731"",
    ""type"": ""EXPENSES_FOLDER"",
    ""name"": ""Motor Vehicle"",
    ""balance"": 0,
    ""children"": [{
      ""id"": ""acc.cb325e7e-0ce4-4c78-9cb4-20659df733a6"",
      ""type"": ""EXPENSE"",
      ""name"": ""Fuel and Oil"",
      ""balance"": 0,
      ""children"": [

      ]
    }]
  }, {
    ""id"": ""acc.4bdd9e26-ce64-4e7f-b46a-82ec9de06ded"",
    ""type"": ""EXPENSES_FOLDER"",
    ""name"": ""Other Travel"",
    ""balance"": 132.1,
    ""children"": [{
      ""id"": ""acc.77dd2142-f2de-4a2c-9247-061d0661bc0a"",
      ""type"": ""EXPENSE"",
      ""name"": ""Taxis"",
      ""balance"": 24.5,
      ""children"": [

      ]
    }, {
      ""id"": ""acc.2b54abdd-7ef5-43cd-bdb9-c8c981b59ff2"",
      ""type"": ""EXPENSE"",
      ""name"": ""Public Transport"",
      ""balance"": 107.6,
      ""children"": [

      ]
    }]
  }, {
    ""id"": ""acc.e4695b70-31fa-4e23-afd0-97335dcd5b9e"",
    ""type"": ""EXPENSE"",
    ""name"": ""Subsitence"",
    ""balance"": 0,
    ""children"": [

    ]
  }, {
    ""id"": ""acc.02d222bf-4dff-4308-afe9-69b93f412ada"",
    ""type"": ""EXPENSE"",
    ""name"": ""Hotel and Accomodation"",
    ""balance"": 0,
    ""children"": [

    ]
  }, {
    ""id"": ""acc.d61cd5b4-2c80-4ab8-93d0-9d5726bd253b"",
    ""type"": ""EXPENSES_FOLDER"",
    ""name"": ""Fees and Commission Paid"",
    ""balance"": 0,
    ""children"": [{
      ""id"": ""acc.1262189019758.7"",
      ""type"": ""EXPENSE"",
      ""name"": ""Pupils exam entry fees"",
      ""balance"": 0,
      ""children"": [

      ]
    }, {
      ""id"": ""acc.a7d7efd3-d0da-4704-babb-079b6077f3fe"",
      ""type"": ""EXPENSE"",
      ""name"": ""Audition, competition entry fees"",
      ""balance"": 0,
      ""children"": [

      ]
    }, {
      ""id"": ""acc.3b91ee4e-40a8-46d8-aa05-3afa5974b3ef"",
      ""type"": ""EXPENSE"",
      ""name"": ""Deputies, Other Musicians"",
      ""balance"": 0,
      ""children"": [

      ]
    }]
  }, {
    ""id"": ""acc.250d6872-6023-4599-a0b6-b7159eebbfa1"",
    ""type"": ""EXPENSES_FOLDER"",
    ""name"": ""Other Professional Expenses"",
    ""balance"": 1739.42,
    ""children"": [{
      ""id"": ""acc.b7315228-f85a-4ffb-9199-d1128a409e5f"",
      ""type"": ""EXPENSE"",
      ""name"": ""Promotion &amp; Publicity"",
      ""balance"": 138.6,
      ""children"": [

      ]
    }, {
      ""id"": ""acc.69ca2005-d7a0-448b-b70c-dafb128a48ae"",
      ""type"": ""EXPENSE"",
      ""name"": ""Other Expenses"",
      ""balance"": 364.5,
      ""children"": [

      ]
    }, {
      ""id"": ""acc.dcd999d2-4e18-41be-b9cc-218d4034b88e"",
      ""type"": ""EXPENSE"",
      ""name"": ""Office Equipment, Furniture"",
      ""balance"": 0,
      ""children"": [

      ]
    }, {
      ""id"": ""acc.e0460706-d5c9-4c40-9d1e-0d2058864b92"",
      ""type"": ""EXPENSE"",
      ""name"": ""CDs, Dowloads etc"",
      ""balance"": 67.57,
      ""children"": [

      ]
    }, {
      ""id"": ""acc.1866df79-9e44-459a-a978-727904987469"",
      ""type"": ""EXPENSE"",
      ""name"": ""Professional Books, Magazines"",
      ""balance"": 104.01,
      ""children"": [

      ]
    }, {
      ""id"": ""acc.24c1651d-e7ae-48bc-a32d-311427e0fcea"",
      ""type"": ""EXPENSE"",
      ""name"": ""Professional Associations"",
      ""balance"": 272.17,
      ""children"": [

      ]
    }, {
      ""id"": ""acc.289ab0ac-b9d3-435e-ac82-9da9702b7d4b"",
      ""type"": ""EXPENSE"",
      ""name"": ""Tuition"",
      ""balance"": 470,
      ""children"": [

      ]
    }, {
      ""id"": ""acc.f24cf99b-6291-4b9f-821e-425f4909d4e1"",
      ""type"": ""EXPENSE"",
      ""name"": ""Scores, Manuscript Paper etc"",
      ""balance"": 215.32,
      ""children"": [

      ]
    }, {
      ""id"": ""acc.1af95953-56f0-455e-9d0a-7c4e0477cf0d"",
      ""type"": ""EXPENSE"",
      ""name"": ""Performance Clothing"",
      ""balance"": 0,
      ""children"": [

      ]
    }, {
      ""id"": ""acc.c0585577-535a-4ae2-a02b-e5b249f67c67"",
      ""type"": ""EXPENSE"",
      ""name"": ""Concerts, Shows etc"",
      ""balance"": 107.25,
      ""children"": [

      ]
    }]
  }, {
    ""id"": ""acc.1260446672222.24"",
    ""type"": ""ADMIN"",
    ""name"": ""Administrative Expenses"",
    ""balance"": 0,
    ""children"": [

    ]
  }, {
    ""id"": ""acc.1260446672238.26"",
    ""type"": ""TRAVEL"",
    ""name"": ""Travel and Subsistence Account"",
    ""balance"": -14.5,
    ""children"": [

    ]
  }, {
    ""id"": ""acc.1260446672238.28"",
    ""type"": ""LEGAL"",
    ""name"": ""Legal and Professional Costs Account"",
    ""balance"": 0,
    ""children"": [

    ]
  }, {
    ""id"": ""acc.1260446672238.36"",
    ""type"": ""OTHER_EXPENSES"",
    ""name"": ""Rent/Rates"",
    ""balance"": 0,
    ""children"": [

    ]
  }, {
    ""id"": ""acc.1262191376548.37"",
    ""type"": ""EXPENSE"",
    ""name"": ""Research"",
    ""balance"": 0,
    ""children"": [

    ]
  }, {
    ""id"": ""acc.1262191388329.38"",
    ""type"": ""EXPENSE"",
    ""name"": ""Professional Development"",
    ""balance"": 0,
    ""children"": [

    ]
  }, {
    ""id"": ""acc.1262192291558.52"",
    ""type"": ""EXPENSE"",
    ""name"": ""Professional Presentation"",
    ""balance"": 0,
    ""children"": [

    ]
  }, {
    ""id"": ""acc.1262193596634.72"",
    ""type"": ""EXPENSE"",
    ""name"": ""Subscriptions"",
    ""balance"": 0,
    ""children"": [

    ]
  }, {
    ""id"": ""acc.1262265941130.16"",
    ""type"": ""EXPENSE"",
    ""name"": ""Piano accompaniment"",
    ""balance"": 0,
    ""children"": [

    ]
  }, {
    ""id"": ""acc.1267370824329.1"",
    ""type"": ""EXPENSE"",
    ""name"": ""Cost of Sales"",
    ""balance"": 0,
    ""children"": [

    ]
  }]
}]
</code></pre>

<p>What I need is to flatten this array to have a flat list of accounts. What's the way to proceed with that in <strong>Vanilla JavaScript</strong>. (I also got access to <code>lodash</code> methods in my project).</p>
",19484,6,10,3,javascript;arrays;lodash,2016-02-08 16:53:21,2016-02-08 16:53:21,2022-07-21 02:57:51,i got following data structure  which is an array of accounts objects  where some accounts are being parents to its children accounts  which in turn can be parents to other accounts etc      what i need is to flatten this array to have a flat list of accounts  what s the way to proceed with that in vanilla javascript   i also got access to lodash methods in my project  ,flattening deeply nested array of objects
108,7738515,73048143,Permanently adding a file path to sys.path in Python and module usage,"<p>I am aware of
<a href=""https://stackoverflow.com/questions/12257747/permanently-adding-a-file-path-to-sys-path-in-python"">Permanently adding a file path to sys.path in Python</a>
and I have a specific follow-up question to this matter. I was uncertain if I should ask it from within (as it is many years old).</p>
<p>I followed the answer, even so, I have not successfully implemented the PYTHONPATH variant of it (Not sure what I am doing wrong). Likewise, I have also read the aforementioned documentation, still I have some issues as described below.</p>
<p>The part</p>
<blockquote>
<p>There are a few ways. One of the simplest is to create a my-paths.pth file (as described &gt;here). This is just a file with the extension .pth that you put into your system &gt;site-&gt;packages directory. On each line of the file you put one directory name, so you can &gt;put a line in there with /path/to/the/ and it will add that directory to the path.</p>
</blockquote>
<p>was helpful to me, so far, as I am now able to add specific paths to my</p>
<pre><code>/usr/lib/python3/dist-packages
</code></pre>
<p>o all my python3 interpreters will find them. I also added an</p>
<pre><code>myPackagesPython3.pth
</code></pre>
<p>in that folder. All paths therein specified show up when I execute</p>
<pre><code>print(sys.path)
</code></pre>
<p><strong>BUT</strong> whenever I try to incorporate something like</p>
<pre><code>from subFunctions import cameraSetup
</code></pre>
<p>I am unable to load in the functions defined within</p>
<pre><code>cameraSetup.py
</code></pre>
<p>My desired working structure would be to have some Project A within a init.py, someSubfolder --&gt; within a init.py and someFunctions.py</p>
<p>Then refer to <em>Project A</em> via</p>
<pre><code>.pth
</code></pre>
<p>and use some variation of</p>
<pre><code>import someFunction
</code></pre>
<p>Any Information as to why it seems to fail would be greatly appreciated, I am relatively new to python programming, and I am still trying to get a handle on it.</p>
<p>A bit of Background (to whom it may concern):
We are working with very particular cameras and their home-brewed software to get them to run. So, we are trying to separate the camera stream set up (Project A) from our actual development in the field of machine vision (Project B-ZZZ). So far, whenever I change the core files from Project A (new functions, knobs to regulate, UI, etc.) I hard copy the same file into all my other working directories (as I have looked into relative pathing within python but so far, always stopped again due to time constraints). This is of course bad practice, and it must be solvable.</p>
<p>I am grateful for any and all advice.</p>
",25,0,0,3,python;python-3.x;sys.path,2022-07-20 11:17:30,2022-07-20 11:17:30,2022-07-20 11:17:30,i followed the answer  even so  i have not successfully implemented the pythonpath variant of it  not sure what i am doing wrong   likewise  i have also read the aforementioned documentation  still i have some issues as described below  the part there are a few ways  one of the simplest is to create a my paths pth file  as described  gt here   this is just a file with the extension  pth that you put into your system  gt site  gt packages directory  on each line of the file you put one directory name  so you can  gt put a line in there with  path to the  and it will add that directory to the path  was helpful to me  so far  as i am now able to add specific paths to my o all my python interpreters will find them  i also added an in that folder  all paths therein specified show up when i execute but whenever i try to incorporate something like i am unable to load in the functions defined within my desired working structure would be to have some project a within a init py  somesubfolder    gt  within a init py and somefunctions py then refer to project a via and use some variation of any information as to why it seems to fail would be greatly appreciated  i am relatively new to python programming  and i am still trying to get a handle on it  i am grateful for any and all advice ,permanently adding a file path to sys path in python and module usage
109,6702806,45046234,Black Screen with Android Emulator,"<p>I am a newbie to android development and am running Ubuntu Linux with an AMD cpu. I installed Android Studio, JDK, SDK, etc, and have been trying to run the emulator. However, whenever I try launching the emulator, it stays a black screen. The message I repeatedly get in terminal is </p>

<blockquote>
  <p>WARN - run.EmulatorConnectionListener - Emulator not ready yet, dev.bootcomplete = null</p>
</blockquote>

<p>I have tried waiting for a while, I have tried updating it, I have tried different APIs, I have tried setting emulated performance to software, and everything else I could find online. Help would be greatly appreciated!</p>

<p>Specs:
Ubuntu 16.04 LTS
Android Studio 2.3.3
Radeon R9 270x 4gb
AMD FX4100
32g ram
SVM is enabled in BIOS </p>
",7918,1,0,3,android;android-emulator;android-studio-2.3,2017-07-12 02:57:22,2017-07-12 02:57:22,2022-07-20 05:00:45,i am a newbie to android development and am running ubuntu linux with an amd cpu  i installed android studio  jdk  sdk  etc  and have been trying to run the emulator  however  whenever i try launching the emulator  it stays a black screen  the message i repeatedly get in terminal is  warn   run emulatorconnectionlistener   emulator not ready yet  dev bootcomplete   null i have tried waiting for a while  i have tried updating it  i have tried different apis  i have tried setting emulated performance to software  and everything else i could find online  help would be greatly appreciated ,black screen with android emulator
110,1508243,36459934,Any reason for if(function() == TRUE) in C,"<p><strong>The Question:</strong>
Does doing <code>if(SomeFunction() == TRUE)</code> instead of doing <code>if(SomeFunction())</code> protect against some type of coding error?  I'm trying to understand if this is protecting from some hidden land-mine, or if it's the result of someone writing code who didn't quite understand how expressions are evaluated.  I understand that if done right, both of these things evaluate the same.  Just like <code>if(value == 42)</code> and <code>if(42 == value)</code> evaluate the same - still, some prefer the 2nd version because it produces a compiler error if someone typo's the == and writes = instead.</p>

<p><strong>Background:</strong>
I've inherited some embedded software that was written 4 or 5 years ago by people who don't work here anymore.  I'm in the middle of some refactoring to get rid of multi-hundred line functions and global variables and all that jazz, so this thing is readable and we can maintain it going forward.  The code is c for a pic microprocessor.  This may or may not be relevant.  The code has all sorts of weird stuff in it that screams ""didn't know what they were doing"" but there's a particular pattern (anti-pattern?) in here that I'm trying to understand whether or not there's a good reason for</p>

<p><strong>The Pattern:</strong>
There are a lot of if statements in here that take the form</p>

<pre><code>if(SomeFunction() == TRUE){
  . . .
}
</code></pre>

<p>Where SomeFunction() is defined as</p>

<pre><code>BOOLEAN SomeFunction(void){
  . . .
  if(value == 3)
    return(FALSE);
  else
    return(TRUE);
}
</code></pre>

<p>Let's ignore the weird way that SomeFunction returns TRUE or FALSE from the body of an if statement, and the weird way that they made 'return' look like a function invocation.</p>

<p>It seems like this breaks the normal values that c considers 'true' and 'false'  Like, they really want to make sure the value returned is equal to whatever is defined as TRUE.  It's almost like they're making three states - TRUE, FALSE, and 'something else'  And they don't want the 'if' statement to be taken if 'something else' is returned.</p>

<p>My gut feeling is that this is a weird anti-pattern but I want to give these guys the benefit of the doubt.  For example I recognize that <code>if(31 == variable)</code> looks a little strange but it's written that way so if you typo the == you don't accidently assign 31 to variable.  Were the guys that wrote this protecting against a similar problem, or is this just nonsense.</p>

<p><strong>Additional Info</strong></p>

<ul>
<li>When I wrote this question, I was under the impression that stdbool was not available, but I see now that it's provided by the IDE, just not used in this project.  This tilts me more towards ""No good reason for doing this.""</li>
<li>It looks like BOOLEAN is defined as <code>typedef enum _BOOLEAN { FALSE = 0, TRUE } BOOLEAN;</code></li>
<li>The development environment in question here is MPLAB 8.6</li>
</ul>
",9587,4,9,4,c;embedded;microchip;mplab,2016-04-06 21:53:17,2016-04-06 21:53:17,2022-07-19 17:42:35,where somefunction   is defined as let s ignore the weird way that somefunction returns true or false from the body of an if statement  and the weird way that they made  return  look like a function invocation  it seems like this breaks the normal values that c considers  true  and  false   like  they really want to make sure the value returned is equal to whatever is defined as true   it s almost like they re making three states   true  false  and  something else   and they don t want the  if  statement to be taken if  something else  is returned  my gut feeling is that this is a weird anti pattern but i want to give these guys the benefit of the doubt   for example i recognize that if     variable  looks a little strange but it s written that way so if you typo the    you don t accidently assign  to variable   were the guys that wrote this protecting against a similar problem  or is this just nonsense  additional info,any reason for if function      true  in c
111,6362238,71429836,Where can I find the default template for the Expander control?,"<p>I need to modify the template of the Expander control (move the chevron icon to the left), but I could not find it.</p>
<p>Per <a href=""https://docs.microsoft.com/en-us/windows/winui/api/microsoft.ui.xaml.controls.expander?view=winui-3.0#control-style-and-template"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/windows/winui/api/microsoft.ui.xaml.controls.expander?view=winui-3.0#control-style-and-template</a></p>
<blockquote>
<p>The default style, template, and resources that define the look of the control are included in the generic.xaml file. For design purposes, generic.xaml is available in the (Program Files)\Windows Kits\10\DesignTime\CommonConfiguration\Neutral\UAP\ \Generic folder from a Windows Software Development Kit (SDK) installation. Styles and resources from different versions of the SDK might have different values.</p>
</blockquote>
<p>The generic.xaml in that location does not have the default template of the Expander control.</p>
<p>I also looked in the generic.xaml from <code>%Users%\myuser\.nuget\packages\microsoft.windowsappsdk\1.0.0\lib\net5.0-windows10.0.18362.0\Microsoft.WinUI\Themes\generic.xaml</code></p>
<p>So confusing. Back in the old WPF\UWP days I could just do Edit Template in Visual Studio, but with WinUI, that's not available...</p>
",258,1,1,1,winui-3,2022-03-10 21:35:52,2022-03-10 21:35:52,2022-07-19 17:22:58,i need to modify the template of the expander control  move the chevron icon to the left   but i could not find it  per  the default style  template  and resources that define the look of the control are included in the generic xaml file  for design purposes  generic xaml is available in the  program files  windows kits  designtime commonconfiguration neutral uap   generic folder from a windows software development kit  sdk  installation  styles and resources from different versions of the sdk might have different values  the generic xaml in that location does not have the default template of the expander control  i also looked in the generic xaml from  users  myuser  nuget packages microsoft windowsappsdk    lib net  windows    microsoft winui themes generic xaml so confusing  back in the old wpf uwp days i could just do edit template in visual studio  but with winui  that s not available   ,where can i find the default template for the expander control 
112,2618034,44717964,Compile Error: Object library feature not supported Outlook.Application,"<p>I have been tasked with fixing an issue in VB on an Microsoft Access system and I can't figure it out. This issue only occurs on one of the 5 PC's running the software. 
I have tried </p>

<ul>
<li>Removing Outlook &amp; Access and re-installing it.</li>
<li>Removing the Microsoft Access Application and re-installing it.</li>
<li>Changed the code to match an answer I have found on another site.</li>
</ul>

<p>This code brings up an error
<a href=""https://i.stack.imgur.com/e8RTB.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/e8RTB.png"" alt=""enter image description here""></a>
The code is as follows.</p>

<pre><code>    Dim objOutlook As Outlook.Application
    Dim objMailItem As MailItem
    Dim db As DAO.Database

    'Create email object and send attachment

    Set objOutlook = DetectOutlook()
    If objOutlook Is Nothing Then
        Set objOutlook = New Outlook.Application
    End If
</code></pre>

<p>I tried changing it to this as recommended on another site.</p>

<pre><code>    Dim objOutlook As Object
    Dim objMailItem As MailItem
    Dim db As DAO.Database

    'Create email object and send attachment

   If GetObject(, ""Outlook.Application"") = True Then    'Outlook was already running
        Set objOutlook = GetObject(, ""Outlook.Application"")    'Bind to existing instance of Outlook
    Else    'Could not get instance of Outlook, so create a new one
        Set objOutlook = New Outlook.Application
    End If
</code></pre>

<p>This code change just ended up forcing Access to shutdown when it was run. 
I am new to VB and Access Development so maybe this is a simple fix, if you require any further information please ask. Its 2016 Microsoft FYI.
Thank you in advance</p>
",7282,6,8,3,vba;ms-access;outlook,2017-06-23 12:32:04,2017-06-23 12:32:04,2022-07-19 12:52:52,i tried changing it to this as recommended on another site ,compile error  object library feature not supported outlook application
113,0,404097,Power off an USB device in software on Windows,"<p>I would like to power cycle an USB device through software on Windows.</p>

<p>I am doing development on a small USB power microcontroller. This chip will revert to native behavior on a power cycle and allow a code download.  Since my code will crash the device when things go wrong -- making it ignore all USB commands -- I have to physically unplug the device from the system.  </p>

<p>I want to do development remotely, and not have to be physically present.   </p>

<p>So far I have tried using ""devcon"" to disable portions of the USB stack. While this takes the hubs into D3 (should be powered off!), there is still power being supplied to the device.  </p>

<p>Are there any preexisting solutions or SetupAPI tricks that might help?</p>
",63707,5,32,5,windows;winapi;embedded;usb;microcontroller,2008-12-31 23:42:35,2008-12-31 23:42:35,2022-07-19 00:02:20,i would like to power cycle an usb device through software on windows  i am doing development on a small usb power microcontroller  this chip will revert to native behavior on a power cycle and allow a code download   since my code will crash the device when things go wrong    making it ignore all usb commands    i have to physically unplug the device from the system    i want to do development remotely  and not have to be physically present     so far i have tried using devcon to disable portions of the usb stack  while this takes the hubs into d  should be powered off    there is still power being supplied to the device    are there any preexisting solutions or setupapi tricks that might help ,power off an usb device in software on windows
114,15641268,73019812,Microsoft GDK GameInput C# Calls in .Net 6 - Modern Controller Input,"<p>Microsoft GameInput is an API that is part of the Microsoft Game Development Kit (GDK) first released in 2021-06-24 <a href=""https://github.com/microsoft/GDK/releases/tag/June_2021"" rel=""nofollow noreferrer"">June 2021 GDK Public Release</a></p>
<p>The most recent release is the <a href=""https://github.com/microsoft/GDK/releases/tag/June_2022_Update_1"" rel=""nofollow noreferrer"">June 2022 Release</a></p>
<p>GameInput is the API that exposes input devices and is used to build interactivity.</p>
<p><a href=""https://docs.microsoft.com/en-us/gaming/gdk/_content/gc/input/overviews/input-overview"" rel=""nofollow noreferrer"">Microsoft Documentation</a> says (Under Getting Started):</p>
<blockquote>
<p>GameInput is the recommended API for all new code, regardless of the target platform, because it provides support across all Microsoft platforms (including earlier versions of Windows), and provides superior performance versus legacy APIs.</p>
</blockquote>
<p>And also says:</p>
<blockquote>
<p>GameInput is available on all Windows platforms—PC, Xbox, HoloLens, IoT, and others—and is callable from GDK, Win32, and Universal Windows Platform (UWP) applications. Most importantly, it's available on earlier versions of Windows all the way back to Windows 7 via a redistributable installer package. This enables a single input codebase to be used across the entire Microsoft ecosystem, with no platform/version special-casing required.</p>
</blockquote>
<p>Which all sounds very impressive indeed.</p>
<p>But I am a C# developer, looking to port an older application from .Net Framework v 4.5.2 which has been out of support for <a href=""https://devblogs.microsoft.com/dotnet/net-framework-4-5-2-4-6-4-6-1-will-reach-end-of-support-on-april-26-2022/"" rel=""nofollow noreferrer"">several months now</a>.</p>
<blockquote>
<p>.NET Framework 4.5.2, 4.6, and 4.6.1 will reach end of support* on April 26, 2022. After this date, we will no longer provide updates including security fixes or technical support for these versions.</p>
</blockquote>
<p>Previously using <a href=""http://sharpdx.org/wiki/class-library-api/xinput/"" rel=""nofollow noreferrer"">SharpDX.XInput</a> that was last updated <a href=""https://www.nuget.org/packages/SharpDX.XInput"" rel=""nofollow noreferrer"">2018-08-24</a>, migrating away from SharpDX.XInput is also on the cards too.</p>
<p>Given that Microsoft is recommending GameInput as the API set for all new code regardless of the target platform, is it reasonable to expect in the foreseeable future that there will be official C# bindings for the GameInput API set, in particular for Windows Server which our current application is expected to support.</p>
<p>Alternatives to GameInput is the <a href=""https://docs.microsoft.com/en-us/uwp/api/Windows.Gaming.Input?view=winrt-10240"" rel=""nofollow noreferrer"">Windows.Gaming.Input</a> namespace of APIs, which look similar but are also different, and part of the UWP/WinRT suite of functions. That said, XInput isn't being deprecated at least yet, the <a href=""https://docs.microsoft.com/en-us/windows/win32/xinput/xinput-versions"" rel=""nofollow noreferrer"">documentation</a> for XInput Versions says that XInput v1.4 is shipped with Windows 10 directly, and inspecting the SharpDX source reveals that it first tries v1.4 via LoadLibrary (Link omitted, lack of reputation to post more), if failing falling back to v1.3 and if that fails, falling back to v9.1.0</p>
<p>For C# developers doing new code-work is there an expectation of bindings to GameInput being provided, or are we to utilize Windows.Gaming.Input or XInput instead through interop?</p>
<p>For us, it's imperative that the software work on Windows Server 2019 and up, and Windows 10 IoT 2019 LTSC (v1809) and up. Dropping support for Windows 7 is also on the to-do list as part of the upgrade from the older framework which is why we were using it for so long.</p>
",51,0,0,5,c#;.net;windows;uwp;game-development,2022-07-18 12:05:52,2022-07-18 12:05:52,2022-07-18 12:08:10,microsoft gameinput is an api that is part of the microsoft game development kit  gdk  first released in     the most recent release is the  gameinput is the api that exposes input devices and is used to build interactivity   says  under getting started   gameinput is the recommended api for all new code  regardless of the target platform  because it provides support across all microsoft platforms  including earlier versions of windows   and provides superior performance versus legacy apis  and also says  gameinput is available on all windows platforms pc  xbox  hololens  iot  and others and is callable from gdk  win  and universal windows platform  uwp  applications  most importantly  it s available on earlier versions of windows all the way back to windows  via a redistributable installer package  this enables a single input codebase to be used across the entire microsoft ecosystem  with no platform version special casing required  which all sounds very impressive indeed  but i am a c  developer  looking to port an older application from  net framework v    which has been out of support for    net framework        and    will reach end of support  on april     after this date  we will no longer provide updates including security fixes or technical support for these versions  previously using  that was last updated   migrating away from sharpdx xinput is also on the cards too  given that microsoft is recommending gameinput as the api set for all new code regardless of the target platform  is it reasonable to expect in the foreseeable future that there will be official c  bindings for the gameinput api set  in particular for windows server which our current application is expected to support  alternatives to gameinput is the  namespace of apis  which look similar but are also different  and part of the uwp winrt suite of functions  that said  xinput isn t being deprecated at least yet  the  for xinput versions says that xinput v  is shipped with windows  directly  and inspecting the sharpdx source reveals that it first tries v  via loadlibrary  link omitted  lack of reputation to post more   if failing falling back to v  and if that fails  falling back to v   for c  developers doing new code work is there an expectation of bindings to gameinput being provided  or are we to utilize windows gaming input or xinput instead through interop  for us  it s imperative that the software work on windows server  and up  and windows  iot  ltsc  v  and up  dropping support for windows  is also on the to do list as part of the upgrade from the older framework which is why we were using it for so long ,microsoft gdk gameinput c  calls in  net    modern controller input
115,19558445,72998549,XCode ld: library not found for -lrealsense2.2.50.0 clang: error: linker command failed with exit code 1 (use -v to see invocation),"<p>Iam quite new to this community. Take me as a noob in software development ( Help would be appreciated )
Iam running intel based 16 inch mac. with MacOs Monterey 12.4 version and Xcode Version 13.4.1 (13F100)</p>
<p>Facing a problem with Xcode for C++ development, i will attach the screen shot with this. when building it shows that library not found for <strong>ld: library not found for -lrealsense2.2.50.0 clang: error: linker command failed with exit code 1 (use -v to see invocation)</strong> it was showing the same with the <a href=""https://github.com/OpenKinect/libfreenect2"" rel=""nofollow noreferrer"">libfreenect2</a> driver as well.
<strong>Things i tried</strong></p>
<ol>
<li>I tried changing the name of the driver according to the name asked and added it even though it did not work.</li>
<li>Tried deleting the files from the derived directories and restarting everything</li>
<li>Creating a new project.</li>
<li>Building my own binary files using the SDK from <a href=""https://lightbuzz.com/realsense-macos/"" rel=""nofollow noreferrer"">link</a>.</li>
</ol>
<p>and lot other stuff on google, it didnt work. but when i run a cmake build with the given examples it works amazingly fine. but not when i wanted to develope my own project using the same code.</p>
<p><strong>PLEASE DIRECT ME</strong> MAY BE A COURSE TOWARDS LEARNING XCODE.. anything.
<a href=""https://i.stack.imgur.com/lHmTE.png"" rel=""nofollow noreferrer"">This is the code iam running</a>
<a href=""https://i.stack.imgur.com/fzac0.png"" rel=""nofollow noreferrer"">And this is the error am getting</a></p>
",28,0,0,5,c++;xcode;intel;point-cloud-library;realsense,2022-07-15 21:57:46,2022-07-15 21:57:46,2022-07-16 13:27:44,and lot other stuff on google  it didnt work  but when i run a cmake build with the given examples it works amazingly fine  but not when i wanted to develope my own project using the same code ,xcode ld  library not found for  lrealsense    clang  error  linker command failed with exit code   use  v to see invocation 
116,11690158,56731373,VSCode v1.35 - RuntimeError: CMake must be installed to build the following extensions: dlib,"<p>I have already installed CMake by <code>pip install cmake</code> in my VS Code 1.35 and trying to install <code>face_recognition</code> but it still give me a RuntimeError. I'm using 'Python 3.7.3, x32'</p>

<p>I also tried to install the <code>dlib</code> by <code>pip install dlib</code> since it is one of the reason why I can't install <code>face_recognition</code>.</p>

<pre><code>C:\Users\user&gt;python -m pip install cmake
Requirement already satisfied: cmake in c:\users\user\appdata\roaming\python\python37\site-packages (3.14.4)

C:\Users\user&gt;python -m pip install dlib
Collecting dlib
  Using cached https://files.pythonhosted.org/packages/05/57/e8a8caa3c89a27f80bc78da39c423e2553f482a3705adc619176a3a24b36/dlib-19.17.0.tar.gz
Installing collected packages: dlib
  Running setup.py install for dlib ... error
    ERROR: Complete output from command 'C:\Python\Python37\python.exe' -u -c 'import setuptools, tokenize;__file__='""'""'C:\\Users\\user\\AppData\\Local\\Temp\\pip-install-24vk6act\\dlib\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\user\AppData\Local\Temp\pip-record-yf2kdjpx\install-record.txt' --single-version-externally-managed --compile:
    ERROR: running install
    running build
    running build_py
    package init file 'dlib\__init__.py' not found (or not a regular file)
    running build_ext
    Traceback (most recent call last):
      File ""C:\Users\user\AppData\Local\Temp\pip-install-24vk6act\dlib\setup.py"", line 120, in get_cmake_version
        out = subprocess.check_output(['cmake', '--version'])
      File ""C:\Python\Python37\lib\subprocess.py"", line 395, in check_output
        **kwargs).stdout
      File ""C:\Python\Python37\lib\subprocess.py"", line 472, in run
        with Popen(*popenargs, **kwargs) as process:
      File ""C:\Python\Python37\lib\subprocess.py"", line 775, in __init__
        restore_signals, start_new_session)
      File ""C:\Python\Python37\lib\subprocess.py"", line 1178, in _execute_child
        startupinfo)
    FileNotFoundError: [WinError 2] The system cannot find the file specified

    During handling of the above exception, another exception occurred:

    Traceback (most recent call last):
      File ""&lt;string&gt;"", line 1, in &lt;module&gt;
      File ""C:\Users\user\AppData\Local\Temp\pip-install-24vk6act\dlib\setup.py"", line 261, in &lt;module&gt;
        'Topic :: Software Development',
      File ""C:\Users\user\AppData\Roaming\Python\Python37\site-packages\setuptools\__init__.py"", line 145, in setup
        return distutils.core.setup(**attrs)
      File ""C:\Python\Python37\lib\distutils\core.py"", line 148, in setup
        dist.run_commands()
      File ""C:\Python\Python37\lib\distutils\dist.py"", line 966, in run_commands
        self.run_command(cmd)
      File ""C:\Python\Python37\lib\distutils\dist.py"", line 985, in run_command
        cmd_obj.run()
      File ""C:\Users\user\AppData\Roaming\Python\Python37\site-packages\setuptools\command\install.py"", line 61, in run
        return orig.install.run(self)
      File ""C:\Python\Python37\lib\distutils\command\install.py"", line 545, in run
        self.run_command('build')
      File ""C:\Python\Python37\lib\distutils\cmd.py"", line 313, in run_command
        self.distribution.run_command(command)
      File ""C:\Python\Python37\lib\distutils\dist.py"", line 985, in run_command
        cmd_obj.run()
      File ""C:\Python\Python37\lib\distutils\command\build.py"", line 135, in run
        self.run_command(cmd_name)
      File ""C:\Python\Python37\lib\distutils\cmd.py"", line 313, in run_command
        self.distribution.run_command(command)
      File ""C:\Python\Python37\lib\distutils\dist.py"", line 985, in run_command
        cmd_obj.run()
      File ""C:\Users\user\AppData\Local\Temp\pip-install-24vk6act\dlib\setup.py"", line 129, in run
        cmake_version = self.get_cmake_version()
      File ""C:\Users\user\AppData\Local\Temp\pip-install-24vk6act\dlib\setup.py"", line 125, in get_cmake_version
        ""\n*******************************************************************\n"")
    RuntimeError:
    *******************************************************************
     CMake must be installed to build the following extensions: dlib
    *******************************************************************

    ----------------------------------------
ERROR: Command ""'C:\Python\Python37\python.exe' -u -c 'import setuptools, tokenize;__file__='""'""'C:\\Users\\user\\AppData\\Local\\Temp\\pip-install-24vk6act\\dlib\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\user\AppData\Local\Temp\pip-record-yf2kdjpx\install-record.txt' --single-version-externally-managed --compile"" failed with error code 1 in C:\Users\user\AppData\Local\Temp\pip-install-24vk6act\dlib\
</code></pre>

<p>I'm hoping that somebody can help me with this. I'm new and really a beginner in using python and tried different suggestions from other questions. Hope that somebody will notice my question. Thank you!</p>
",47820,4,10,4,python;opencv;cmake;dlib,2019-06-24 10:05:13,2019-06-24 10:05:13,2022-07-16 10:53:34,i have already installed cmake by pip install cmake in my vs code   and trying to install face_recognition but it still give me a runtimeerror  i m using  python     x  i also tried to install the dlib by pip install dlib since it is one of the reason why i can t install face_recognition  i m hoping that somebody can help me with this  i m new and really a beginner in using python and tried different suggestions from other questions  hope that somebody will notice my question  thank you ,vscode v    runtimeerror  cmake must be installed to build the following extensions  dlib
117,1766575,61418553,MongoDB (Mongoose) `findByIdAndDelete` not deleting (testing with Postman),"<p>I've got my Mongoose code in a separate <code>model.js</code> file, while Express code for handling http requests is in <code>app.js</code>. I'm just practising creating APIs and testing them on Postman, for an imaginary wiki article site. The api I'm struggling to get it to work is deleting one article. (Note: for the sake of brevity, I've only included the code in question, i.e. <code>app.delete('/articles/:id' ....</code> from <code>app.js</code>, and the static method it calls from <code>model.js</code> - <code>deleteOneArticleFromDB(articleID)</code></p>

<p><code>app.js</code>:</p>

<pre class=""lang-js prettyprint-override""><code>const express = require('express');
const bodyParser = require('body-parser');
const model = require('./model');

const app = express();

app.use(bodyParser.urlencoded({ extended: true }));

app.delete('/articles/:id', async (req, res) =&gt; {
    const articleID = req.params.id;
    console.log(`req.params.id: ${req.params.id}`);
    try {
        const response = await model.DBUtility.deleteOneArticleFromDB(articleID);
        res.status(200).json({message: response, app: 'wiki-api'});
    } catch (err) {
        res.json({message: err, app: 'wiki-api'});
    }
});

const port = 3000;
app.listen(port, () =&gt; {
    console.log(`Server started on port ${port}`);
});
</code></pre>

<p><code>model.js</code>:</p>

<pre class=""lang-js prettyprint-override""><code>const mongoose = require('mongoose');

mongoose.connect('mongodb://localhost:27017/wikiDB', {useNewUrlParser: true, useUnifiedTopology: true, useFindAndModify: false });

const articleSchema = new mongoose.Schema({
    title: String,
    content: String
});

const Article = mongoose.model('Article', articleSchema);

class DBUtility {

    static deleteOneArticleFromDB(articleID) {
        return new Promise((resolve, reject) =&gt; {
            Article.findByIdAndDelete(articleID, (err) =&gt; {
                if (err) {
                    reject(err);
                } else {
                    resolve(`Deleted article ${articleID} successfully`);
                }
            });
        });
    }
}

exports.DBUtility = DBUtility;
</code></pre>

<p>I have 5 articles (5 documents) in my Database:</p>

<pre class=""lang-js prettyprint-override""><code>{
    ""_id"" : ""5c139771d79ac8eac11e754a"",
    ""title"" : ""API"",
    ""content"" : ""API stands for Application Programming Interface. It is a set of subroutine definitions, communication protocols, and tools for building software. In general terms, it is a set of clearly defined methods of communication among various components. A good API makes it easier to develop a computer program by providing all the building blocks, which are then put together by the programmer.""
}

/* 2 */
{
    ""_id"" : ""5c1398aad79ac8eac11e7561"",
    ""title"" : ""Bootstrap"",
    ""content"" : ""This is a framework developed by Twitter that contains pre-made front-end templates for web design""
}

/* 3 */
{
    ""_id"" : ""5c1398ecd79ac8eac11e7567"",
    ""title"" : ""DOM"",
    ""content"" : ""The Document Object Model is like an API for interacting with our HTML""
}

/* 4 */
{
    ""_id"" : ""5ea2c188fa57aa1b6453eda5"",
    ""title"" : ""Node JS"",
    ""content"" : ""Node.js is an open-source, cross-platform, JavaScript runtime environment that executes JavaScript code outside of a web browser. Node.js lets developers use JavaScript to write command line tools and for server-side scripting—running scripts server-side to produce dynamic web page content before the page is sent to the user's web browser. Consequently, Node.js represents a \""JavaScript everywhere\"" paradigm,[6] unifying web-application development around a single programming language, rather than different languages for server- and client-side scripts."",
    ""__v"" : 0
}

/* 5 */
{
    ""_id"" : ""5ea2d5304e19b11e0013a86a"",
    ""title"" : ""EJS"",
    ""content"" : ""EJS is a simple templating language that lets you generate HTML markup with plain JavaScript. No religiousness about how to organize things. No reinvention of iteration and control-flow. It's just plain JavaScript"",
    ""__v"" : 0
}
</code></pre>

<p>I'm trying to delete the last article (document) with title <code>EJS</code>. So in Postman I run the http request as follows:</p>

<p><a href=""https://i.stack.imgur.com/YMZJ4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/YMZJ4.png"" alt=""enter image description here""></a></p>

<p>As you can see, I get a success response. However, when I check my database, the document is still there (I have clicked refresh several times and also tested it with a GET request to return all articles, which showed the article is still there):
<a href=""https://i.stack.imgur.com/mEruF.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/mEruF.png"" alt=""enter image description here""></a></p>

<p>Here's the terminal output: </p>

<pre><code>[nodemon] starting `node app.js`
Server started on port 3000
req.params.id: 5ea2d5304e19b11e0013a86a
</code></pre>

<p>I've been on this for two days. I've checked all previous SO posts with similar titles to mine, but I couldn't see one that applies to my issue. I don't understand where I'm going wrong!! Any help would be really appreciated.</p>

<p><strong>UPDATE</strong></p>

<p>As per the solution below by Mohammed Yousry, I realised that I added the <code>_id</code> field manually using strings, as I was following along to a tutorial. Hence not allowing MongoDB to create the <code>_id</code> field instead, as an <code>ObjectId</code>. Therefore, my <code>_id</code> field was of type String rather than ObjectId. So to resolve this, I deleted all documents from the database and re-added them, using POSTMAN with the POST method I created - for creating/adding a new article document to the database, providing only the <code>title</code> and <code>content</code> fields in the request body. Hence allowing MongoDB to create the <code>_id</code> field instead, for each article document. Now in the database the <code>_id</code> field is of type <code>ObjectId</code>. This still hasn't resolved my issue fully, but it's one step further. Still working on reaching a solution. Please refer to the discussions below in the solution section.</p>

<p><a href=""https://i.stack.imgur.com/BorgC.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BorgC.png"" alt=""enter image description here""></a> </p>
",5972,3,1,4,node.js;mongodb;express;mongoose,2020-04-25 01:46:42,2020-04-25 01:46:42,2022-07-16 08:19:07,i ve got my mongoose code in a separate model js file  while express code for handling http requests is in app js  i m just practising creating apis and testing them on postman  for an imaginary wiki article site  the api i m struggling to get it to work is deleting one article   note  for the sake of brevity  i ve only included the code in question  i e  app delete   articles  id       from app js  and the static method it calls from model js   deleteonearticlefromdb articleid  app js  model js  i have  articles   documents  in my database  i m trying to delete the last article  document  with title ejs  so in postman i run the http request as follows   here s the terminal output   i ve been on this for two days  i ve checked all previous so posts with similar titles to mine  but i couldn t see one that applies to my issue  i don t understand where i m going wrong   any help would be really appreciated  update as per the solution below by mohammed yousry  i realised that i added the _id field manually using strings  as i was following along to a tutorial  hence not allowing mongodb to create the _id field instead  as an objectid  therefore  my _id field was of type string rather than objectid  so to resolve this  i deleted all documents from the database and re added them  using postman with the post method i created   for creating adding a new article document to the database  providing only the title and content fields in the request body  hence allowing mongodb to create the _id field instead  for each article document  now in the database the _id field is of type objectid  this still hasn t resolved my issue fully  but it s one step further  still working on reaching a solution  please refer to the discussions below in the solution section   ,mongodb  mongoose   findbyidanddelete  not deleting  testing with postman 
118,8842005,47135404,How can I able to display the JSON data in an inner array by using vueJS?,"<p>My vueJS code is:</p>

<pre><code>&lt;script&gt;
  new Vue({
    el: '#feed' ,
    data: {
      data: [],
    },
    mounted() {
      this.$nextTick(function() {
        var self = this;
        var id = window.location.href.split('=').pop();
        console.log(id);
        $.ajax({
          url: ""https://n2s.herokuapp.com/api/post/get/5"",
          method: ""GET"",
          dataType: ""JSON"",
          success: function (e) {
            if (e.status == 1) {
              self.data = e.data;
              console.log(e.data)
            } else {
              console.log('Error occurred');
            }
          }, error: function(){
            console.log('Error occurred');
          }
        });
      });
    },
  })
&lt;/script&gt;
</code></pre>

<p>This is my html code to display values</p>

<pre><code>&lt;div class=""m-single-article"" id=""feed""&gt;
  &lt;p&gt;{{details.bussinessName}}&lt;/p&gt; //already printed
  &lt;p&gt;{{details.pid}}&lt;/p&gt; //already printed
  &lt;p&gt;{{details.inventory}}&lt;/p&gt; //////NOT PRINTING
  &lt;p&gt;{{details.sub_category}}&lt;/p&gt; ////// NOT PRINTING
&lt;/div&gt;
</code></pre>

<p>I AM ABLE TO PRINT ALL THE DATA expect INVENTORY AND SUBCATEGORY. please</p>

<p>The url will provide the json data as:</p>

<pre><code>{""status"": true, ""data"": {""pid"": 10, ""bussinessName"": ""Ey technology"", ""services"": ""1, 3, 4, 2"", ""inventory"": [""specs"", ""Eye Testing"", ""Lens"", ""Doctors""], ""workHr"": ""Monday :9:00AM to 5:00PM,Thuesday :9:00AM to 5:00PM,Wednesday :9:00AM to 5:00PM,Tuesday : 9:00AM to 5:00PM,Friday :9:00AM to 5:00PM,Saturday :9:00AM to 5:00PM,Sunday :9:00AM to 5:00PM"", ""description"": ""Good technology company for software"", ""category"": 1, ""sub_category"": [""Homeo pathy"", ""Web development""], ""lat"": 9.5274336, ""lon"": 76.8224309, ""contactName"": ""simon"", ""contactEmail"": ""simon@gmail.com"", ""contactOfficeAddress"": ""korno solutions"", ""contactNumber"": ""1236547859"", ""contactOfficeNumber"": ""858547896"", ""state"": ""Canada"", ""city"": ""Oranto"", ""place"": ""Orania"", ""pincode"": 895621, ""referer"": 24, ""link"": 24, ""views"": 0, ""package"": 1, ""listing_pic"": ""default"", ""website"": ""www.ey.com""}}
</code></pre>

<p>By trying this I am not able to display the values of inventory [] and subcategory []. Can anybody please help me to solve my issue. </p>

<p>Also I am getting services as 1,2,3,4. Is there any way to map to the another json data giving name of the services. <a href=""https://n2s.herokuapp.com/api/post/get_all_services/"" rel=""nofollow noreferrer"">https://n2s.herokuapp.com/api/post/get_all_services/</a></p>
",69,1,0,4,javascript;jquery;vue.js;vue-component,2017-11-06 13:01:11,2017-11-06 13:01:11,2022-07-16 05:44:14,my vuejs code is  this is my html code to display values i am able to print all the data expect inventory and subcategory  please the url will provide the json data as  by trying this i am not able to display the values of inventory    and subcategory     can anybody please help me to solve my issue   also i am getting services as      is there any way to map to the another json data giving name of the services  ,how can i able to display the json data in an inner array by using vuejs 
119,6790340,47258092,How to display the workHr that comes as json data in table format using vue js?,"<p>My json data is</p>

<pre><code>{""status"": true, ""data"": {""pid"": 10, ""bussinessName"": ""Ey technology"", ""services"": ""1, 3, 4, 2"", ""inventory"": [""specs"", ""Eye Testing"", ""Lens"", ""Doctors""], ""workHr"": ""Monday :9:00AM to 5:00PM,Thuesday :9:00AM to 5:00PM,Wednesday :9:00AM to 5:00PM,Tuesday : 9:00AM to 5:00PM,Friday :9:00AM to 5:00PM,Saturday :9:00AM to 5:00PM,Sunday :9:00AM to 5:00PM"", ""description"": ""Good technology company for software"", ""category"": 1, ""sub_category"": [""Homeo pathy"", ""Web development""], ""lat"": 9.5274336, ""lon"": 76.8224309, ""contactName"": ""simon"", ""contactEmail"": ""simon@gmail.com"", ""contactOfficeAddress"": ""college of Eng"", ""contactNumber"": ""1236547859"", ""contactOfficeNumber"": ""8947123658"", ""state"": ""Kerala"", ""city"": ""Koy"", ""place"": ""Kly"", ""pincode"": 686514, ""referer"": 24, ""link"": 24, ""views"": 0, ""package"": 1, ""listing_pic"": ""default"", ""website"": ""www.ey.com""}}
</code></pre>

<hr>

<p>Currently I am displaying data as</p>

<pre><code> &lt;p&gt;&lt;i class=""fa fa-map-marker"" aria-hidden=""true""&gt;&lt;/I&gt;{{data.place}}, {{data.city}}, {{data.pincode}}&lt;/p&gt;&lt;br&gt;
</code></pre>

<p>I need to display {{data.workHr}} in the form of a table</p>

<p>My table is as</p>

<pre><code> &lt;table class=""table""&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Sunday&lt;/th&gt;
      &lt;th&gt;Monday&lt;/th&gt;
      &lt;th&gt;Tuesday&lt;/th&gt;
      &lt;th&gt;Wednesday&lt;/th&gt;
      &lt;th&gt;Thursday&lt;/th&gt;
      &lt;th&gt;Friday&lt;/th&gt;
      &lt;th&gt;Saturday&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;

      &lt;td&gt;&lt;/td&gt;
       &lt;td&gt;&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
         &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
           &lt;td&gt;&lt;/td&gt;
            &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
</code></pre>

<p>I need to display the corresponding working hours that come from json data under each day? Can please anybody help me to solve the issue??</p>
",602,3,3,2,javascript;vue.js,2017-11-13 08:12:43,2017-11-13 08:12:43,2022-07-15 23:52:34,my json data is currently i am displaying data as i need to display   data workhr   in the form of a table my table is as i need to display the corresponding working hours that come from json data under each day  can please anybody help me to solve the issue  ,how to display the workhr that comes as json data in table format using vue js 
120,19444907,72996583,Truncated JSON into a hierarchy,"<p>I need help working with some JSON data that I'm trying to build into a hierarchy. Can someone please help me?</p>
<p>JSON Sample:</p>
<pre><code>{&quot;businessModelInfo&quot;:{&quot;52ff2dd1e4b0b193ed664d41&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:2,&quot;description&quot;:&quot;Platform for the security monitoring, detection &amp; prevention of unauthorized access, misuse &amp; modification to the enterprise network&quot;},&quot;id&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;name&quot;:&quot;Network Security&quot;},&quot;52ff2df2e4b0b193ed664d43&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:212,&quot;description&quot;:&quot;Application security testing, vulnerability assessment &amp; runtime application protection&quot;},&quot;id&quot;:&quot;52ff2df2e4b0b193ed664d43&quot;,&quot;name&quot;:&quot;Application Security&quot;},&quot;52ff2e04e4b0b193ed664d45&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:55,&quot;description&quot;:&quot;Identity &amp; Access Management (IAM) solution for the user login, authentication and authorization&quot;},&quot;id&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;name&quot;:&quot;IAM&quot;},&quot;52ff2e04e4b0b193ed664d46&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:65,&quot;description&quot;:&quot;Companies that provide a platform for OAuth, SAML or XML based identity federation or SSO&quot;},&quot;id&quot;:&quot;52ff2e04e4b0b193ed664d46&quot;,&quot;name&quot;:&quot;Federated Identity Management&quot;},&quot;52ff2e13e4b0b193ed664d47&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:177,&quot;description&quot;:&quot;Technologies, policies &amp; controls deployed to protect data, applications, and the associated infrastructure of cloud computing&quot;},&quot;id&quot;:&quot;52ff2e13e4b0b193ed664d47&quot;,&quot;name&quot;:&quot;Cloud Security&quot;},&quot;52ff2e3de4b0b193ed664d4a&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:30,&quot;description&quot;:&quot;Companies that provide a platform for the cyber security of the enterprise owned endpoint devices&quot;},&quot;id&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;name&quot;:&quot;Endpoint Security&quot;},&quot;53295f48e4b07f1af3220cb0&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:124,&quot;description&quot;:&quot;Security for access to enterprise network &amp; data by a non-company device&quot;},&quot;id&quot;:&quot;53295f48e4b07f1af3220cb0&quot;,&quot;name&quot;:&quot;BYOD Security&quot;},&quot;532ffec7e4b09e548233984f&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:5,&quot;description&quot;:&quot;Companies that provide an integrated Network Intrusion Detection System (NIDS) for network security of SMB/SME or remote office&quot;},&quot;id&quot;:&quot;532ffec7e4b09e548233984f&quot;,&quot;name&quot;:&quot;NIDS&quot;},&quot;533008efe4b09e54823398bf&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:8,&quot;description&quot;:&quot;Companies that provide a platform to prevent cyber intrusion in the enterprise network&quot;},&quot;id&quot;:&quot;533008efe4b09e54823398bf&quot;,&quot;name&quot;:&quot;NIPS&quot;},&quot;53301ec6e4b09e54823399b4&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:33,&quot;description&quot;:&quot;Solution for detecting various cyber threats on enterprise owned and managed endpoint devices&quot;},&quot;id&quot;:&quot;53301ec6e4b09e54823399b4&quot;,&quot;name&quot;:&quot;Threat Detection&quot;},&quot;53303049e4b09e5482339a5b&quot;:{&quot;parentId&quot;:&quot;52ff2df2e4b0b193ed664d43&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:213,&quot;description&quot;:&quot;Companies that provide a vulnerability assessment platform for application modules, libraries &amp; code&quot;},&quot;id&quot;:&quot;53303049e4b09e5482339a5b&quot;,&quot;name&quot;:&quot;Vulnerability Assessment&quot;},&quot;53303451e4b09e5482339a76&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:13,&quot;description&quot;:&quot;Companies that provide incident response solution for enterprise network from cyber attacks&quot;},&quot;id&quot;:&quot;53303451e4b09e5482339a76&quot;,&quot;name&quot;:&quot;Network Incident Response&quot;},&quot;53306594e4b09e5482339b74&quot;:{&quot;parentId&quot;:&quot;53295f48e4b07f1af3220cb0&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:134,&quot;description&quot;:&quot;Companies that provide solution for the assessment of device status, application installed and vulnerabilities detected over BYOD devices&quot;},&quot;id&quot;:&quot;53306594e4b09e5482339b74&quot;,&quot;name&quot;:&quot;Vulnerability Assessment&quot;},&quot;533065b0e4b09e5482339b75&quot;:{&quot;parentId&quot;:&quot;53295f48e4b07f1af3220cb0&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:132,&quot;description&quot;:&quot;Solution for the detection &amp; remediation of malware including virus over BYOD devices&quot;},&quot;id&quot;:&quot;533065b0e4b09e5482339b75&quot;,&quot;name&quot;:&quot;Anti Malware&quot;},&quot;5330665de4b09e5482339b78&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:31,&quot;description&quot;:&quot;Unified threat management including threat response, vulnerability assessment and patch management&quot;},&quot;id&quot;:&quot;5330665de4b09e5482339b78&quot;,&quot;name&quot;:&quot;Endpoint UTM&quot;},&quot;5330677ae4b09e5482339b7a&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:36,&quot;description&quot;:&quot;Endpoint security for the protection against malware including computer viruses, worms, trojan horses, ransomware, spyware, adware, and scareware&quot;},&quot;id&quot;:&quot;5330677ae4b09e5482339b7a&quot;,&quot;name&quot;:&quot;Anti Malware&quot;},&quot;533067dfe4b09e5482339b7b&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:45,&quot;description&quot;:&quot;Companies that provide a whitelisting based execution of pre-determined and vetted application on endpoint&quot;},&quot;id&quot;:&quot;533067dfe4b09e5482339b7b&quot;,&quot;name&quot;:&quot;Application Whitelisting&quot;},&quot;5330697de4b09e5482339b7d&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:44,&quot;description&quot;:&quot;Companies that provide a solution to assess the vulnerability of endpoint system&quot;},&quot;id&quot;:&quot;5330697de4b09e5482339b7d&quot;,&quot;name&quot;:&quot;Vulnerability Assessment&quot;},&quot;533aabf1e4b02eaca1338cad&quot;:{&quot;parentId&quot;:&quot;52ff2df2e4b0b193ed664d43&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:226,&quot;description&quot;:&quot;Platform for crowdsourced testing of enterprise application for security bugs and exploits&quot;},&quot;id&quot;:&quot;533aabf1e4b02eaca1338cad&quot;,&quot;name&quot;:&quot;Crowdsourced Security Testing&quot;},&quot;53438e8ae4b03bb69fb23bd5&quot;:{&quot;parentId&quot;:&quot;53295f48e4b07f1af3220cb0&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:133,&quot;description&quot;:&quot;Companies that provide a mobile network access control for BYOD devices&quot;},&quot;id&quot;:&quot;53438e8ae4b03bb69fb23bd5&quot;,&quot;name&quot;:&quot;Mobile NAC&quot;},&quot;5344f426e4b092ee736cf843&quot;:{&quot;parentId&quot;:&quot;52ff2e13e4b0b193ed664d47&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:182,&quot;description&quot;:&quot;Companies that provide a security solution for a cloud-based application and software&quot;},&quot;id&quot;:&quot;5344f426e4b092ee736cf843&quot;,&quot;name&quot;:&quot;Cloud Application Security&quot;},&quot;53463741e4b092ee736cfc82&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:3,&quot;description&quot;:&quot;Companies that provide an unified threat management solution for network security of SMB/SME or remote office&quot;},&quot;id&quot;:&quot;53463741e4b092ee736cfc82&quot;,&quot;name&quot;:&quot;Network UTM&quot;},&quot;534d01afe4b059431aef8956&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:136,&quot;description&quot;:&quot;Companies that provide a solution for the protection of data at rest, in use &amp; in-transit from unauthorized access &amp; modification&quot;},&quot;id&quot;:&quot;534d01afe4b059431aef8956&quot;,&quot;name&quot;:&quot;Data Security&quot;},&quot;53564831e4b0411aaf48b159&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:200,&quot;description&quot;:&quot;Companies that provide security of websites and web services from an internet wide attack&quot;},&quot;id&quot;:&quot;53564831e4b0411aaf48b159&quot;,&quot;name&quot;:&quot;Website Security&quot;},&quot;5357acb3e4b095b7a9fcd924&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:14,&quot;description&quot;:&quot;Companies that provide Virtual Private Network (VPN) for a secure remote access to the interent.&quot;},&quot;id&quot;:&quot;5357acb3e4b095b7a9fcd924&quot;,&quot;name&quot;:&quot;VPN&quot;},&quot;535928bce4b048998cb752d9&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:187,&quot;description&quot;:&quot;Security of users against fraud, identity theft, payment fraud &amp; phone fraud&quot;},&quot;id&quot;:&quot;535928bce4b048998cb752d9&quot;,&quot;name&quot;:&quot;Anti Fraud&quot;},&quot;535de22ce4b0735cb1b3e164&quot;:{&quot;parentId&quot;:&quot;535928bce4b048998cb752d9&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:188,&quot;description&quot;:&quot;Solution to detect and prevent digital identity theft&quot;},&quot;id&quot;:&quot;535de22ce4b0735cb1b3e164&quot;,&quot;name&quot;:&quot;Identity Theft&quot;},&quot;535e6460e4b0b029c534b1d3&quot;:{&quot;parentId&quot;:&quot;532ffec7e4b09e548233984f&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:7,&quot;description&quot;:&quot;Companies that provide a decoy based intrusion detection and deception solution&quot;},&quot;id&quot;:&quot;535e6460e4b0b029c534b1d3&quot;,&quot;name&quot;:&quot;Honeypot&quot;},&quot;53639ca0e4b0c0a1efec7cc5&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:234,&quot;description&quot;:&quot;Actionable, processed, aggregated, relevant &amp; evidence-based knowledge of existing &amp; new threats &amp; vulnerabilities&quot;},&quot;id&quot;:&quot;53639ca0e4b0c0a1efec7cc5&quot;,&quot;name&quot;:&quot;Threat Intelligence&quot;},&quot;53639ca0e4b0c0a1efec7cc6&quot;:{&quot;parentId&quot;:&quot;53639ca0e4b0c0a1efec7cc5&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:236,&quot;description&quot;:&quot;Companies that provide a collaboration platform for updating, managing and sharing cyber threat intelligence to enterprises&quot;},&quot;id&quot;:&quot;53639ca0e4b0c0a1efec7cc6&quot;,&quot;name&quot;:&quot;Enterprise Collaboration&quot;},&quot;5363a93de4b0bacf25f2ce00&quot;:{&quot;parentId&quot;:&quot;534d01afe4b059431aef8956&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:159,&quot;description&quot;:&quot;Companies that provide Hardware Security Module (HSM) or HSM grade security to manage digital keys and perform cryptoprocessing&quot;},&quot;id&quot;:&quot;5363a93de4b0bacf25f2ce00&quot;,&quot;name&quot;:&quot;Hardware Security Module (HSM)&quot;},&quot;536cb875e4b0bb23233efcbd&quot;:{&quot;parentId&quot;:&quot;53639ca0e4b0c0a1efec7cc5&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:235,&quot;description&quot;:&quot;Companies that provide a platform and services which delivers threat intelligence feed&quot;},&quot;id&quot;:&quot;536cb875e4b0bb23233efcbd&quot;,&quot;name&quot;:&quot;Platform &amp; Services&quot;},&quot;5371bca1e4b022d05fc6c31f&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:243,&quot;description&quot;:&quot;Companies that provide a secure gateway and encryption of email communication system&quot;},&quot;id&quot;:&quot;5371bca1e4b022d05fc6c31f&quot;,&quot;name&quot;:&quot;Email Security&quot;},&quot;5371e43be4b022d05fc6c47b&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:49,&quot;description&quot;:&quot;Companies that provide protection &amp; control of a single Internet-connected endpoint from intruders&quot;},&quot;id&quot;:&quot;5371e43be4b022d05fc6c47b&quot;,&quot;name&quot;:&quot;Secure Gateway&quot;},&quot;53720cc7e4b022d05fc6c6a1&quot;:{&quot;parentId&quot;:&quot;53564831e4b0411aaf48b159&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:202,&quot;description&quot;:&quot;Companies that provide a platform for monitoring, vulnerability assessment &amp; audit of websites&quot;},&quot;id&quot;:&quot;53720cc7e4b022d05fc6c6a1&quot;,&quot;name&quot;:&quot;Web Vulnerability Assessment&quot;},&quot;5373251ae4b0595dbe736774&quot;:{&quot;parentId&quot;:&quot;534d01afe4b059431aef8956&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:153,&quot;description&quot;:&quot;Companies that provide a platform for big data security by classifying and enforcing access control&quot;},&quot;id&quot;:&quot;5373251ae4b0595dbe736774&quot;,&quot;name&quot;:&quot;Big Data Security&quot;},&quot;537329bfe4b0595dbe736785&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:96,&quot;description&quot;:&quot;Companies that provide a secure platform to generate and manage  secure password&quot;},&quot;id&quot;:&quot;537329bfe4b0595dbe736785&quot;,&quot;name&quot;:&quot;Password Manager&quot;},&quot;53734e55e4b071174050713b&quot;:{&quot;parentId&quot;:&quot;535928bce4b048998cb752d9&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:194,&quot;description&quot;:&quot;Companies that provide a solution to detect, prevent and protect against phone fraud&quot;},&quot;id&quot;:&quot;53734e55e4b071174050713b&quot;,&quot;name&quot;:&quot;Phone Fraud&quot;},&quot;53748c18e4b085ec4f4d312f&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:46,&quot;description&quot;:&quot;Companies that provide a solution to secure endpoint by virtualizing and isolating the browsing activity for preventing web-based attacks&quot;},&quot;id&quot;:&quot;53748c18e4b085ec4f4d312f&quot;,&quot;name&quot;:&quot;Threat Isolation&quot;},&quot;5374be82e4b085ec4f4d342a&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:74,&quot;description&quot;:&quot;Companies that provide a biometrics-based IAM solution&quot;},&quot;id&quot;:&quot;5374be82e4b085ec4f4d342a&quot;,&quot;name&quot;:&quot;Biometrics&quot;},&quot;5374e1cae4b085ec4f4d3595&quot;:{&quot;parentId&quot;:&quot;53564831e4b0411aaf48b159&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:203,&quot;description&quot;:&quot;Solution which provide real time reputation of a domain to prevent or block cyber threat&quot;},&quot;id&quot;:&quot;5374e1cae4b085ec4f4d3595&quot;,&quot;name&quot;:&quot;Reputation Monitoring&quot;},&quot;5375f10be4b035e7ab6e9547&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:106,&quot;description&quot;:&quot;Companies that provide a platform for IAM governance and access intelligence&quot;},&quot;id&quot;:&quot;5375f10be4b035e7ab6e9547&quot;,&quot;name&quot;:&quot;Intelligence &amp; Governance&quot;},&quot;53ccd374e4b0c99052489339&quot;:{&quot;parentId&quot;:&quot;53564831e4b0411aaf48b159&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:204,&quot;description&quot;:&quot;Companies that provide a platform for the detection of cyber threats in a website&quot;},&quot;id&quot;:&quot;53ccd374e4b0c99052489339&quot;,&quot;name&quot;:&quot;Threat Detection&quot;},&quot;53ff40d8e4b0785237e38b7c&quot;:{&quot;parentId&quot;:&quot;53564831e4b0411aaf48b159&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:205,&quot;description&quot;:&quot;Companies that detect and protect against DDoS attacks including layer 3,4 &amp; 7&quot;},&quot;id&quot;:&quot;53ff40d8e4b0785237e38b7c&quot;,&quot;name&quot;:&quot;DDoS Mitigation&quot;},&quot;54071895e4b0fd800eb0005b&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:259,&quot;description&quot;:&quot;Companies that provide cybersecurity for Operations technology such as IACS &amp; SCADA systems&quot;},&quot;id&quot;:&quot;54071895e4b0fd800eb0005b&quot;,&quot;name&quot;:&quot;Industrial Security&quot;},&quot;5412f794e4b0ff6e2b21fcd6&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:254,&quot;description&quot;:&quot;Security to protect data, identities, devices, IP and servers in the IOT&quot;},&quot;id&quot;:&quot;5412f794e4b0ff6e2b21fcd6&quot;,&quot;name&quot;:&quot;IoT Security&quot;},&quot;545cd365e4b0a2f443016b44&quot;:{&quot;parentId&quot;:&quot;53295f48e4b07f1af3220cb0&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:125,&quot;description&quot;:&quot;Companies that provide Enterprise Mobility Management (EMM) including MDM, MAM, IAM and/or enterprise app store.&quot;},&quot;id&quot;:&quot;545cd365e4b0a2f443016b44&quot;,&quot;name&quot;:&quot;EMM&quot;},&quot;55129e45e4b0fb7fb6ee3dc8&quot;:{&quot;parentId&quot;:&quot;53639ca0e4b0c0a1efec7cc5&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:240,&quot;description&quot;:&quot;Platform which assess and delivers quantitative score of an enterprise security and risk posture&quot;},&quot;id&quot;:&quot;55129e45e4b0fb7fb6ee3dc8&quot;,&quot;name&quot;:&quot;Security &amp; Risk Scorecards&quot;},&quot;55c49718e4b055e17db8dd86&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:34,&quot;description&quot;:&quot;Platform to detect and respond to cyber threat on endpoint devices&quot;},&quot;id&quot;:&quot;55c49718e4b055e17db8dd86&quot;,&quot;name&quot;:&quot;Incident Detection &amp; Response&quot;},&quot;55d5799ce4b0ccb9ba3e7e20&quot;:{&quot;parentId&quot;:&quot;5371bca1e4b022d05fc6c31f&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:244,&quot;description&quot;:&quot;Companies that provide a Secure Email Gateway (SEG) that prevents malicious or rogue email and attachment based on enterprise policy&quot;},&quot;id&quot;:&quot;55d5799ce4b0ccb9ba3e7e20&quot;,&quot;name&quot;:&quot;SEG&quot;},&quot;55d57fe4e4b0ccb9ba3e7f0c&quot;:{&quot;parentId&quot;:&quot;5371bca1e4b022d05fc6c31f&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:250,&quot;description&quot;:&quot;Companies that provide anti-spam, email validation and email abuse detection platform&quot;},&quot;id&quot;:&quot;55d57fe4e4b0ccb9ba3e7f0c&quot;,&quot;name&quot;:&quot;Anti-Spam&quot;},&quot;55d58156e4b0ccb9ba3e7f2d&quot;:{&quot;parentId&quot;:&quot;5371bca1e4b022d05fc6c31f&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:245,&quot;description&quot;:&quot;Companies that provide a solution to encrypt email communication and access control over mail&quot;},&quot;id&quot;:&quot;55d58156e4b0ccb9ba3e7f2d&quot;,&quot;name&quot;:&quot;Email Encryption&quot;},&quot;55d5a577e4b0ccb9ba3e8283&quot;:{&quot;parentId&quot;:&quot;53303049e4b09e5482339a5b&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:221,&quot;description&quot;:&quot;Companies that provide a vulnerability assessment of open source modules, libraries and 3rd party application modules&quot;},&quot;id&quot;:&quot;55d5a577e4b0ccb9ba3e8283&quot;,&quot;name&quot;:&quot;Open Source Component&quot;},&quot;55d5a970e4b0ccb9ba3e8364&quot;:{&quot;parentId&quot;:&quot;53564831e4b0411aaf48b159&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:206,&quot;description&quot;:&quot;Security solution to prevent web scraping &amp; malware execution through network of bots remotely controlled by C&amp;C&quot;},&quot;id&quot;:&quot;55d5a970e4b0ccb9ba3e8364&quot;,&quot;name&quot;:&quot;Botnet Protection&quot;},&quot;55d5b9bee4b045fa07677822&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:59,&quot;description&quot;:&quot;Companies that provide a solution for the creation, management, control and security of privileged accounts and secrets&quot;},&quot;id&quot;:&quot;55d5b9bee4b045fa07677822&quot;,&quot;name&quot;:&quot;Privileged IAM&quot;},&quot;55dc20fae4b068a5fe11694a&quot;:{&quot;parentId&quot;:&quot;53564831e4b0411aaf48b159&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:208,&quot;description&quot;:&quot;Companies that provide a digital certificate for validation of SSL implementation and trusted information exchange&quot;},&quot;id&quot;:&quot;55dc20fae4b068a5fe11694a&quot;,&quot;name&quot;:&quot;Digital Certificate&quot;},&quot;55e830d9e4b00337fcf9357f&quot;:{&quot;parentId&quot;:&quot;53639ca0e4b0c0a1efec7cc5&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:239,&quot;description&quot;:&quot;Platform &amp; service which monitors entire web including dark web for detecting cyber threat and data breach&quot;},&quot;id&quot;:&quot;55e830d9e4b00337fcf9357f&quot;,&quot;name&quot;:&quot;Dark Net Monitoring&quot;},&quot;55ed82d7e4b0126850c78a4e&quot;:{&quot;parentId&quot;:&quot;52ff2df2e4b0b193ed664d43&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:222,&quot;description&quot;:&quot;Companies that provide a Runtime Application Self-Protection (RASP) solution to protect application by identifying and blocking attacks during runtime&quot;},&quot;id&quot;:&quot;55ed82d7e4b0126850c78a4e&quot;,&quot;name&quot;:&quot;RASP&quot;},&quot;560cf14be4b0e484a84b59a4&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:12,&quot;description&quot;:&quot;Companies that provide the security of DNS system/server/software&quot;},&quot;id&quot;:&quot;560cf14be4b0e484a84b59a4&quot;,&quot;name&quot;:&quot;DNS Security&quot;},&quot;5640ffcce4b0920113c70ff5&quot;:{&quot;parentId&quot;:&quot;52ff2e13e4b0b193ed664d47&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:180,&quot;description&quot;:&quot;Companies that provide Cloud Access Security Broker (CASB) tools that act as security gateways for data security, visibility, threat protection and compliance across cloud services&quot;},&quot;id&quot;:&quot;5640ffcce4b0920113c70ff5&quot;,&quot;name&quot;:&quot;CASB&quot;},&quot;564b1801e4b06b8515d7c77e&quot;:{&quot;parentId&quot;:&quot;5412f794e4b0ff6e2b21fcd6&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:255,&quot;description&quot;:&quot;Companies that provide a platform to detect cyber threats and anomalous behavior in IoT infrastructure and application&quot;},&quot;id&quot;:&quot;564b1801e4b06b8515d7c77e&quot;,&quot;name&quot;:&quot;Anomaly Detection&quot;},&quot;5657edefe4b0442049273784&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:275,&quot;description&quot;:&quot;Security &amp; hardening of the servers to prevent unauthorized access &amp; vulnerability attack&quot;},&quot;id&quot;:&quot;5657edefe4b0442049273784&quot;,&quot;name&quot;:&quot;Server Security&quot;},&quot;566015afe4b04c3365bfb798&quot;:{&quot;parentId&quot;:&quot;534d01afe4b059431aef8956&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:155,&quot;description&quot;:&quot;Companies that provide Digital Rights Management (DRM) of enterprise document and software&quot;},&quot;id&quot;:&quot;566015afe4b04c3365bfb798&quot;,&quot;name&quot;:&quot;Enterprise DRM&quot;},&quot;56607831e4b031f08d379f19&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:1,&quot;description&quot;:&quot;Platform that provide security across enterprise including data, infrastructure, access &amp; employs intelligence &amp; analytics&quot;},&quot;id&quot;:&quot;56607831e4b031f08d379f19&quot;,&quot;name&quot;:&quot;Suite&quot;},&quot;5660842ae4b031f08d379f29&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:107,&quot;description&quot;:&quot;Analytics of security information, event &amp; system for threat prevention, detection, mitigation across enterprise&quot;},&quot;id&quot;:&quot;5660842ae4b031f08d379f29&quot;,&quot;name&quot;:&quot;Security Analytics&quot;},&quot;566085cfe4b031f08d379f2a&quot;:{&quot;parentId&quot;:&quot;5660842ae4b031f08d379f29&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:118,&quot;description&quot;:&quot;Companies that provide analytics based solutions for threat detection at enterprise IT level&quot;},&quot;id&quot;:&quot;566085cfe4b031f08d379f2a&quot;,&quot;name&quot;:&quot;Threat Detection&quot;},&quot;566085cfe4b031f08d379f2b&quot;:{&quot;parentId&quot;:&quot;5660842ae4b031f08d379f29&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:110,&quot;description&quot;:&quot;Companies that provide a assessment and management of the enterprise-wide cyber-risk and vulnerabilities present&quot;},&quot;id&quot;:&quot;566085cfe4b031f08d379f2b&quot;,&quot;name&quot;:&quot;Cyber Risk &amp; Vulnerability Assessment&quot;},&quot;5660938ee4b031f08d379f32&quot;:{&quot;parentId&quot;:&quot;5660842ae4b031f08d379f29&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:108,&quot;description&quot;:&quot;Companies that provide a platform for Security Information and Event Management (SIEM)&quot;},&quot;id&quot;:&quot;5660938ee4b031f08d379f32&quot;,&quot;name&quot;:&quot;SIEM&quot;},&quot;5662bfeee4b05dae5f69796c&quot;:{&quot;parentId&quot;:&quot;534d01afe4b059431aef8956&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:156,&quot;description&quot;:&quot;Companies that provide a platform for Data Loss Prevention (DLP) and unauthorized exfiltration outside the enterprise&quot;},&quot;id&quot;:&quot;5662bfeee4b05dae5f69796c&quot;,&quot;name&quot;:&quot;Data Loss Prevention (DLP)&quot;},&quot;56646606e4b05dae5f697ec1&quot;:{&quot;parentId&quot;:&quot;5660842ae4b031f08d379f29&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:122,&quot;description&quot;:&quot;Companies that provide a cyber forensics platform to analyze previously captured data packets and reverse engineer&quot;},&quot;id&quot;:&quot;56646606e4b05dae5f697ec1&quot;,&quot;name&quot;:&quot;Cyber Forensics&quot;},&quot;56646bf4e4b05dae5f697ed1&quot;:{&quot;parentId&quot;:&quot;532ffec7e4b09e548233984f&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:6,&quot;description&quot;:&quot;Companies that provide a real time intrusion detection based on network activity and bandwidth pattern&quot;},&quot;id&quot;:&quot;56646bf4e4b05dae5f697ed1&quot;,&quot;name&quot;:&quot;Network Traffic Analytics&quot;},&quot;56648cd6e4b05dae5f697f90&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:274,&quot;description&quot;:&quot;Companies that provide a solution for the access control, auditing, encryption, integrity controls and secure backup of a database&quot;},&quot;id&quot;:&quot;56648cd6e4b05dae5f697f90&quot;,&quot;name&quot;:&quot;Database Security&quot;},&quot;566509f2e4b0a6e97ece0ceb&quot;:{&quot;parentId&quot;:&quot;52ff2e13e4b0b193ed664d47&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:178,&quot;description&quot;:&quot;Security for virtual infrastructure such as public/private cloud, VM Server, Workload, Hypervisor, Container&quot;},&quot;id&quot;:&quot;566509f2e4b0a6e97ece0ceb&quot;,&quot;name&quot;:&quot;Cloud Infrastructure Security&quot;},&quot;56650ac9e4b030508478a794&quot;:{&quot;parentId&quot;:&quot;52ff2e13e4b0b193ed664d47&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:184,&quot;description&quot;:&quot;Companies that provide cyber security solution for the virtualised software containers&quot;},&quot;id&quot;:&quot;56650ac9e4b030508478a794&quot;,&quot;name&quot;:&quot;Container Security&quot;},&quot;566584ace4b017eeb445a7fb&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:9,&quot;description&quot;:&quot;Companies that provide solutions which filters traffic between two or more networks based on security rules&quot;},&quot;id&quot;:&quot;566584ace4b017eeb445a7fb&quot;,&quot;name&quot;:&quot;Firewall&quot;},&quot;5666b3cce4b0e5adf67b82d0&quot;:{&quot;parentId&quot;:&quot;566085cfe4b031f08d379f2a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:119,&quot;description&quot;:&quot;Companies that provide security analytics like UEBA to detect threat initiated or already present inside enterprise network&quot;},&quot;id&quot;:&quot;5666b3cce4b0e5adf67b82d0&quot;,&quot;name&quot;:&quot;Insider Threat Detection&quot;},&quot;5667c368e4b0716ca7d54d6d&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:92,&quot;description&quot;:&quot;Companies that provide modules &amp; technology solution for the implementation and management of IAM  system&quot;},&quot;id&quot;:&quot;5667c368e4b0716ca7d54d6d&quot;,&quot;name&quot;:&quot;Technology&quot;},&quot;56690a78e4b0a29d350871ba&quot;:{&quot;parentId&quot;:&quot;53295f48e4b07f1af3220cb0&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:126,&quot;description&quot;:&quot;Companies that provide Mobile Device Management (MDM) software that allows IT administrators to control, secure and enforce policies on smartphones, tablets and other endpoints.&quot;},&quot;id&quot;:&quot;56690a78e4b0a29d350871ba&quot;,&quot;name&quot;:&quot;MDM&quot;},&quot;56690a78e4b0a29d350871bb&quot;:{&quot;parentId&quot;:&quot;53295f48e4b07f1af3220cb0&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:128,&quot;description&quot;:&quot;Mobile Application Management (MAM) solution by whitelisting, application catalogue &amp; arbitrary injecting encryption code in app&quot;},&quot;id&quot;:&quot;56690a78e4b0a29d350871bb&quot;,&quot;name&quot;:&quot;MAM&quot;},&quot;56690a78e4b0a29d350871bc&quot;:{&quot;parentId&quot;:&quot;56690a78e4b0a29d350871ba&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:127,&quot;description&quot;:&quot;MDM solution which employs separate encrypted containers for personal &amp; workspace on single device&quot;},&quot;id&quot;:&quot;56690a78e4b0a29d350871bc&quot;,&quot;name&quot;:&quot;Workspace Containerization&quot;},&quot;56690ca0e4b09e473de73598&quot;:{&quot;parentId&quot;:&quot;56690a78e4b0a29d350871bb&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:131,&quot;description&quot;:&quot;Companies that provide a layer of security wrapping over apps to protect against attacks &amp; data theft&quot;},&quot;id&quot;:&quot;56690ca0e4b09e473de73598&quot;,&quot;name&quot;:&quot;Application Wrapping&quot;},&quot;56690ca0e4b09e473de73599&quot;:{&quot;parentId&quot;:&quot;56690a78e4b0a29d350871bb&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:130,&quot;description&quot;:&quot;Companies that analyze and manage apps based on profiling as per enterprise policies&quot;},&quot;id&quot;:&quot;56690ca0e4b09e473de73599&quot;,&quot;name&quot;:&quot;Application Profiling&quot;},&quot;56690ca0e4b09e473de7359a&quot;:{&quot;parentId&quot;:&quot;56690a78e4b0a29d350871bb&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:129,&quot;description&quot;:&quot;Solution for the remote access to app on a BYOD device running over a secure virtual mobile infrastructure (VMI)&quot;},&quot;id&quot;:&quot;56690ca0e4b09e473de7359a&quot;,&quot;name&quot;:&quot;Application Virtualization&quot;},&quot;566936b9e4b0ccc692309dc3&quot;:{&quot;parentId&quot;:&quot;5660842ae4b031f08d379f29&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:121,&quot;description&quot;:&quot;Platform or service to respond &amp; mitigate already detected threat incident in enterprise&quot;},&quot;id&quot;:&quot;566936b9e4b0ccc692309dc3&quot;,&quot;name&quot;:&quot;Incident Response&quot;},&quot;566dbff1e4b0ac980bffaee1&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d46&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:66,&quot;description&quot;:&quot;Companies that provide a Single Sign-On (SSO) solution to log in  on web &amp; mobile sites and applications&quot;},&quot;id&quot;:&quot;566dbff1e4b0ac980bffaee1&quot;,&quot;name&quot;:&quot;SSO&quot;},&quot;566ecc97e4b087555e724e26&quot;:{&quot;parentId&quot;:&quot;5412f794e4b0ff6e2b21fcd6&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:257,&quot;description&quot;:&quot;Companies that provide an embedded hardware or a software development kit for the IoT security&quot;},&quot;id&quot;:&quot;566ecc97e4b087555e724e26&quot;,&quot;name&quot;:&quot;Embeddable IoT Security&quot;},&quot;568eb20fe4b04d1ab768d5a7&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:56,&quot;description&quot;:&quot;Companies that provide a unified identity and access management solution&quot;},&quot;id&quot;:&quot;568eb20fe4b04d1ab768d5a7&quot;,&quot;name&quot;:&quot;Unified IAM&quot;},&quot;56a9b573e4b0079795f189f1&quot;:{&quot;parentId&quot;:&quot;52ff2df2e4b0b193ed664d43&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:225,&quot;description&quot;:&quot;Security of API &amp; API servers from attacks like denial of services, heartbleed, logjam, poodle etc&quot;},&quot;id&quot;:&quot;56a9b573e4b0079795f189f1&quot;,&quot;name&quot;:&quot;API Security&quot;},&quot;56bd9b65e4b0167a5f0ba8d8&quot;:{&quot;parentId&quot;:&quot;535de22ce4b0735cb1b3e164&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:191,&quot;description&quot;:&quot;Companies that provide a solution to verify ID document digitally to prevent cyber fraud&quot;},&quot;id&quot;:&quot;56bd9b65e4b0167a5f0ba8d8&quot;,&quot;name&quot;:&quot;ID Document Verification&quot;},&quot;56d97b2ce4b096207eeba95e&quot;:{&quot;parentId&quot;:&quot;54071895e4b0fd800eb0005b&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:260,&quot;description&quot;:&quot;Companies that provide vulnerability assessment of industrial cybersecurity posture&quot;},&quot;id&quot;:&quot;56d97b2ce4b096207eeba95e&quot;,&quot;name&quot;:&quot;Vulnerability Assessment&quot;},&quot;56d98df2e4b064ac7d89fe9f&quot;:{&quot;parentId&quot;:&quot;54071895e4b0fd800eb0005b&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:261,&quot;description&quot;:&quot;Companies that provide a platform to detect cyber threats in the operational technology network including ICS &amp; SCADA systems&quot;},&quot;id&quot;:&quot;56d98df2e4b064ac7d89fe9f&quot;,&quot;name&quot;:&quot;Threat Detection&quot;},&quot;56d9b8d2e4b064ac7d8a0a46&quot;:{&quot;parentId&quot;:&quot;54071895e4b0fd800eb0005b&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:262,&quot;description&quot;:&quot;Companies that provide a solution to prevent cyber attacks on industrial systems including OT network, ICS/SCADA systems&quot;},&quot;id&quot;:&quot;56d9b8d2e4b064ac7d8a0a46&quot;,&quot;name&quot;:&quot;Threat Prevention&quot;},&quot;570b68d5e4b0b544cd006a5e&quot;:{&quot;parentId&quot;:&quot;5657edefe4b0442049273784&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:276,&quot;description&quot;:&quot;Companies that provide security solution for operating system of server&quot;},&quot;id&quot;:&quot;570b68d5e4b0b544cd006a5e&quot;,&quot;name&quot;:&quot;OS Security&quot;},&quot;571742c7e4b0aafdf9f3a700&quot;:{&quot;parentId&quot;:&quot;5374be82e4b085ec4f4d342a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:77,&quot;description&quot;:&quot;Companies that provide an authentication platform based on innate human features like a fingerprint, iris pattern etc.&quot;},&quot;id&quot;:&quot;571742c7e4b0aafdf9f3a700&quot;,&quot;name&quot;:&quot;Physiological&quot;},&quot;571742c7e4b0aafdf9f3a701&quot;:{&quot;parentId&quot;:&quot;5374be82e4b085ec4f4d342a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:75,&quot;description&quot;:&quot;Companies that provide an authentication platform based on identifying and confirming measurable patterns in human activities&quot;},&quot;id&quot;:&quot;571742c7e4b0aafdf9f3a701&quot;,&quot;name&quot;:&quot;Behavioral&quot;},&quot;5732f379e4b0bd8b59fc4788&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:25,&quot;description&quot;:&quot;Companies that provide Network Access Control (NAC) solution for controlled access to the internal network&quot;},&quot;id&quot;:&quot;5732f379e4b0bd8b59fc4788&quot;,&quot;name&quot;:&quot;Network Access Control&quot;}
</code></pre>
<p>Code:</p>
<pre><code>import json

data = json.load(open('test.json'))

class NodeInfo:
    def __init__(self, dct) -&gt; None:
        self.position = dct['position']
        self.description = dct['description']

class Node:
    def __init__(self, dct):
        self.id = dct['id']
        self.name = dct['name']
        self.parent = dct['parentId']
        if 'nodeInfo' in dct:
            self.node_info = NodeInfo(dct['nodeInfo'])
        self.children = []

def insert(tree, node):
    if tree.id == node.parent:
        tree.children.append(node)
        return True
    for n in tree.children:
        if insert(n, node):
            return True

def traverse(tree, pfx=''):
    if not pfx:
        pfx = tree.name
    else:
        if tree.children:
            pfx = ' '.join((pfx, '&gt;', tree.name))
        else:
            pfx = ' '.join((pfx, '&gt;', tree.name, '//',
                           tree.node_info.description))
    print(pfx)
    for n in tree.children:
        traverse(n, pfx)

tree = Node(
    {
        'id': &quot;52ff2cfce4b0b193ed664d1a&quot;,
        'name': 'Cybersecurity',
        'parentId': None
    }
)
for k, v in data['businessModelInfo'].items():
    if not insert(tree, Node(v)):
        print(v, &quot;location not found&quot;)

traverse(tree)
</code></pre>
<p>Output Sample:</p>
<pre><code>Cybersecurity &gt; Network Security
Cybersecurity &gt; Network Security &gt; NIDS
Cybersecurity &gt; Network Security &gt; NIDS &gt; Honeypot // Companies that provide a decoy based intrusion detection and deception solution
Cybersecurity &gt; Network Security &gt; NIDS &gt; Network Traffic Analytics // Companies that provide a real time intrusion detection based on network activity and bandwidth pattern
Cybersecurity &gt; Network Security &gt; NIPS // Companies that provide a platform to prevent cyber intrusion in the enterprise network
Cybersecurity &gt; Network Security &gt; Network Incident Response // Companies that provide incident response solution for enterprise network from cyber attacks
Cybersecurity &gt; Network Security &gt; Network UTM // Companies that provide an unified threat management solution for network security of SMB/SME or remote office
Cybersecurity &gt; Network Security &gt; VPN
Cybersecurity &gt; Network Security &gt; VPN &gt; Business VPN // Companies that provide Virtual Private Network (VPN) solutions for businesses for uses such as online business activities, business security, and data protection, secure business communication etc.
</code></pre>
<p>This output is really close, and has most of the descriptions, but it is missing some descriptions that I am looking for each line. I would like to have the description for each child node at the end of the tree.</p>
<p>Desired output:</p>
<pre><code>    Cybersecurity &gt; Network Security // Platform for the security monitoring, detection &amp; prevention of unauthorized access, misuse &amp; modification to the enterprise network
    Cybersecurity &gt; Network Security &gt; NIDS // Companies that provide an integrated Network Intrusion Detection System (NIDS) for network security of SMB/SME or remote office
    Cybersecurity &gt; Network Security &gt; NIDS &gt; Honeypot // Companies that provide a decoy based intrusion detection and deception solution
    Cybersecurity &gt; Network Security &gt; NIDS &gt; Network Traffic Analytics // Companies that provide a real time intrusion detection based on network activity and bandwidth pattern
    Cybersecurity &gt; Network Security &gt; NIPS // Companies that provide a platform to prevent cyber intrusion in the enterprise network
</code></pre>
",26,0,0,2,python;json,2022-07-15 18:46:46,2022-07-15 18:46:46,2022-07-15 18:46:46,i need help working with some json data that i m trying to build into a hierarchy  can someone please help me  json sample  code  output sample  this output is really close  and has most of the descriptions  but it is missing some descriptions that i am looking for each line  i would like to have the description for each child node at the end of the tree  desired output ,truncated json into a hierarchy
121,19444907,72986434,Parsing JSON to build a hierarchy,"<p>I'm trying to parse JSON data to build hierarchy categories and print them to a csv. I was hoping that someone could please help me.</p>
<p>JSON Data:</p>
<pre><code>{&quot;businessModelInfo&quot;:{&quot;52ff2dd1e4b0b193ed664d41&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:2,&quot;description&quot;:&quot;Platform for the security monitoring, detection &amp; prevention of unauthorized access, misuse &amp; modification to the enterprise network&quot;},&quot;id&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;name&quot;:&quot;Network Security&quot;},&quot;52ff2df2e4b0b193ed664d43&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:212,&quot;description&quot;:&quot;Application security testing, vulnerability assessment &amp; runtime application protection&quot;},&quot;id&quot;:&quot;52ff2df2e4b0b193ed664d43&quot;,&quot;name&quot;:&quot;Application Security&quot;},&quot;52ff2e04e4b0b193ed664d45&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:55,&quot;description&quot;:&quot;Identity &amp; Access Management (IAM) solution for the user login, authentication and authorization&quot;},&quot;id&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;name&quot;:&quot;IAM&quot;},&quot;52ff2e04e4b0b193ed664d46&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:65,&quot;description&quot;:&quot;Companies that provide a platform for OAuth, SAML or XML based identity federation or SSO&quot;},&quot;id&quot;:&quot;52ff2e04e4b0b193ed664d46&quot;,&quot;name&quot;:&quot;Federated Identity Management&quot;},&quot;52ff2e13e4b0b193ed664d47&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:177,&quot;description&quot;:&quot;Technologies, policies &amp; controls deployed to protect data, applications, and the associated infrastructure of cloud computing&quot;},&quot;id&quot;:&quot;52ff2e13e4b0b193ed664d47&quot;,&quot;name&quot;:&quot;Cloud Security&quot;},&quot;52ff2e3de4b0b193ed664d4a&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:30,&quot;description&quot;:&quot;Companies that provide a platform for the cyber security of the enterprise owned endpoint devices&quot;},&quot;id&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;name&quot;:&quot;Endpoint Security&quot;},&quot;53295f48e4b07f1af3220cb0&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:124,&quot;description&quot;:&quot;Security for access to enterprise network &amp; data by a non-company device&quot;},&quot;id&quot;:&quot;53295f48e4b07f1af3220cb0&quot;,&quot;name&quot;:&quot;BYOD Security&quot;},&quot;532ffec7e4b09e548233984f&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:5,&quot;description&quot;:&quot;Companies that provide an integrated Network Intrusion Detection System (NIDS) for network security of SMB/SME or remote office&quot;},&quot;id&quot;:&quot;532ffec7e4b09e548233984f&quot;,&quot;name&quot;:&quot;NIDS&quot;},&quot;533008efe4b09e54823398bf&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:8,&quot;description&quot;:&quot;Companies that provide a platform to prevent cyber intrusion in the enterprise network&quot;},&quot;id&quot;:&quot;533008efe4b09e54823398bf&quot;,&quot;name&quot;:&quot;NIPS&quot;},&quot;53301ec6e4b09e54823399b4&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:33,&quot;description&quot;:&quot;Solution for detecting various cyber threats on enterprise owned and managed endpoint devices&quot;},&quot;id&quot;:&quot;53301ec6e4b09e54823399b4&quot;,&quot;name&quot;:&quot;Threat Detection&quot;},&quot;53303049e4b09e5482339a5b&quot;:{&quot;parentId&quot;:&quot;52ff2df2e4b0b193ed664d43&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:213,&quot;description&quot;:&quot;Companies that provide a vulnerability assessment platform for application modules, libraries &amp; code&quot;},&quot;id&quot;:&quot;53303049e4b09e5482339a5b&quot;,&quot;name&quot;:&quot;Vulnerability Assessment&quot;},&quot;53303451e4b09e5482339a76&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:13,&quot;description&quot;:&quot;Companies that provide incident response solution for enterprise network from cyber attacks&quot;},&quot;id&quot;:&quot;53303451e4b09e5482339a76&quot;,&quot;name&quot;:&quot;Network Incident Response&quot;},&quot;53306594e4b09e5482339b74&quot;:{&quot;parentId&quot;:&quot;53295f48e4b07f1af3220cb0&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:134,&quot;description&quot;:&quot;Companies that provide solution for the assessment of device status, application installed and vulnerabilities detected over BYOD devices&quot;},&quot;id&quot;:&quot;53306594e4b09e5482339b74&quot;,&quot;name&quot;:&quot;Vulnerability Assessment&quot;},&quot;533065b0e4b09e5482339b75&quot;:{&quot;parentId&quot;:&quot;53295f48e4b07f1af3220cb0&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:132,&quot;description&quot;:&quot;Solution for the detection &amp; remediation of malware including virus over BYOD devices&quot;},&quot;id&quot;:&quot;533065b0e4b09e5482339b75&quot;,&quot;name&quot;:&quot;Anti Malware&quot;},&quot;5330665de4b09e5482339b78&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:31,&quot;description&quot;:&quot;Unified threat management including threat response, vulnerability assessment and patch management&quot;},&quot;id&quot;:&quot;5330665de4b09e5482339b78&quot;,&quot;name&quot;:&quot;Endpoint UTM&quot;},&quot;5330677ae4b09e5482339b7a&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:36,&quot;description&quot;:&quot;Endpoint security for the protection against malware including computer viruses, worms, trojan horses, ransomware, spyware, adware, and scareware&quot;},&quot;id&quot;:&quot;5330677ae4b09e5482339b7a&quot;,&quot;name&quot;:&quot;Anti Malware&quot;},&quot;533067dfe4b09e5482339b7b&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:45,&quot;description&quot;:&quot;Companies that provide a whitelisting based execution of pre-determined and vetted application on endpoint&quot;},&quot;id&quot;:&quot;533067dfe4b09e5482339b7b&quot;,&quot;name&quot;:&quot;Application Whitelisting&quot;},&quot;5330697de4b09e5482339b7d&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:44,&quot;description&quot;:&quot;Companies that provide a solution to assess the vulnerability of endpoint system&quot;},&quot;id&quot;:&quot;5330697de4b09e5482339b7d&quot;,&quot;name&quot;:&quot;Vulnerability Assessment&quot;},&quot;533aabf1e4b02eaca1338cad&quot;:{&quot;parentId&quot;:&quot;52ff2df2e4b0b193ed664d43&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:226,&quot;description&quot;:&quot;Platform for crowdsourced testing of enterprise application for security bugs and exploits&quot;},&quot;id&quot;:&quot;533aabf1e4b02eaca1338cad&quot;,&quot;name&quot;:&quot;Crowdsourced Security Testing&quot;},&quot;53438e8ae4b03bb69fb23bd5&quot;:{&quot;parentId&quot;:&quot;53295f48e4b07f1af3220cb0&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:133,&quot;description&quot;:&quot;Companies that provide a mobile network access control for BYOD devices&quot;},&quot;id&quot;:&quot;53438e8ae4b03bb69fb23bd5&quot;,&quot;name&quot;:&quot;Mobile NAC&quot;},&quot;5344f426e4b092ee736cf843&quot;:{&quot;parentId&quot;:&quot;52ff2e13e4b0b193ed664d47&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:182,&quot;description&quot;:&quot;Companies that provide a security solution for a cloud-based application and software&quot;},&quot;id&quot;:&quot;5344f426e4b092ee736cf843&quot;,&quot;name&quot;:&quot;Cloud Application Security&quot;},&quot;53463741e4b092ee736cfc82&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:3,&quot;description&quot;:&quot;Companies that provide an unified threat management solution for network security of SMB/SME or remote office&quot;},&quot;id&quot;:&quot;53463741e4b092ee736cfc82&quot;,&quot;name&quot;:&quot;Network UTM&quot;},&quot;534d01afe4b059431aef8956&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:136,&quot;description&quot;:&quot;Companies that provide a solution for the protection of data at rest, in use &amp; in-transit from unauthorized access &amp; modification&quot;},&quot;id&quot;:&quot;534d01afe4b059431aef8956&quot;,&quot;name&quot;:&quot;Data Security&quot;},&quot;53564831e4b0411aaf48b159&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:200,&quot;description&quot;:&quot;Companies that provide security of websites and web services from an internet wide attack&quot;},&quot;id&quot;:&quot;53564831e4b0411aaf48b159&quot;,&quot;name&quot;:&quot;Website Security&quot;},&quot;5357acb3e4b095b7a9fcd924&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:14,&quot;description&quot;:&quot;Companies that provide Virtual Private Network (VPN) for a secure remote access to the interent.&quot;},&quot;id&quot;:&quot;5357acb3e4b095b7a9fcd924&quot;,&quot;name&quot;:&quot;VPN&quot;},&quot;535928bce4b048998cb752d9&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:187,&quot;description&quot;:&quot;Security of users against fraud, identity theft, payment fraud &amp; phone fraud&quot;},&quot;id&quot;:&quot;535928bce4b048998cb752d9&quot;,&quot;name&quot;:&quot;Anti Fraud&quot;},&quot;535de22ce4b0735cb1b3e164&quot;:{&quot;parentId&quot;:&quot;535928bce4b048998cb752d9&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:188,&quot;description&quot;:&quot;Solution to detect and prevent digital identity theft&quot;},&quot;id&quot;:&quot;535de22ce4b0735cb1b3e164&quot;,&quot;name&quot;:&quot;Identity Theft&quot;},&quot;535e6460e4b0b029c534b1d3&quot;:{&quot;parentId&quot;:&quot;532ffec7e4b09e548233984f&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:7,&quot;description&quot;:&quot;Companies that provide a decoy based intrusion detection and deception solution&quot;},&quot;id&quot;:&quot;535e6460e4b0b029c534b1d3&quot;,&quot;name&quot;:&quot;Honeypot&quot;},&quot;53639ca0e4b0c0a1efec7cc5&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:234,&quot;description&quot;:&quot;Actionable, processed, aggregated, relevant &amp; evidence-based knowledge of existing &amp; new threats &amp; vulnerabilities&quot;},&quot;id&quot;:&quot;53639ca0e4b0c0a1efec7cc5&quot;,&quot;name&quot;:&quot;Threat Intelligence&quot;},&quot;53639ca0e4b0c0a1efec7cc6&quot;:{&quot;parentId&quot;:&quot;53639ca0e4b0c0a1efec7cc5&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:236,&quot;description&quot;:&quot;Companies that provide a collaboration platform for updating, managing and sharing cyber threat intelligence to enterprises&quot;},&quot;id&quot;:&quot;53639ca0e4b0c0a1efec7cc6&quot;,&quot;name&quot;:&quot;Enterprise Collaboration&quot;},&quot;5363a93de4b0bacf25f2ce00&quot;:{&quot;parentId&quot;:&quot;534d01afe4b059431aef8956&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:159,&quot;description&quot;:&quot;Companies that provide Hardware Security Module (HSM) or HSM grade security to manage digital keys and perform cryptoprocessing&quot;},&quot;id&quot;:&quot;5363a93de4b0bacf25f2ce00&quot;,&quot;name&quot;:&quot;Hardware Security Module (HSM)&quot;},&quot;536cb875e4b0bb23233efcbd&quot;:{&quot;parentId&quot;:&quot;53639ca0e4b0c0a1efec7cc5&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:235,&quot;description&quot;:&quot;Companies that provide a platform and services which delivers threat intelligence feed&quot;},&quot;id&quot;:&quot;536cb875e4b0bb23233efcbd&quot;,&quot;name&quot;:&quot;Platform &amp; Services&quot;},&quot;5371bca1e4b022d05fc6c31f&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:243,&quot;description&quot;:&quot;Companies that provide a secure gateway and encryption of email communication system&quot;},&quot;id&quot;:&quot;5371bca1e4b022d05fc6c31f&quot;,&quot;name&quot;:&quot;Email Security&quot;},&quot;5371e43be4b022d05fc6c47b&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:49,&quot;description&quot;:&quot;Companies that provide protection &amp; control of a single Internet-connected endpoint from intruders&quot;},&quot;id&quot;:&quot;5371e43be4b022d05fc6c47b&quot;,&quot;name&quot;:&quot;Secure Gateway&quot;},&quot;53720cc7e4b022d05fc6c6a1&quot;:{&quot;parentId&quot;:&quot;53564831e4b0411aaf48b159&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:202,&quot;description&quot;:&quot;Companies that provide a platform for monitoring, vulnerability assessment &amp; audit of websites&quot;},&quot;id&quot;:&quot;53720cc7e4b022d05fc6c6a1&quot;,&quot;name&quot;:&quot;Web Vulnerability Assessment&quot;},&quot;5373251ae4b0595dbe736774&quot;:{&quot;parentId&quot;:&quot;534d01afe4b059431aef8956&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:153,&quot;description&quot;:&quot;Companies that provide a platform for big data security by classifying and enforcing access control&quot;},&quot;id&quot;:&quot;5373251ae4b0595dbe736774&quot;,&quot;name&quot;:&quot;Big Data Security&quot;},&quot;537329bfe4b0595dbe736785&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:96,&quot;description&quot;:&quot;Companies that provide a secure platform to generate and manage  secure password&quot;},&quot;id&quot;:&quot;537329bfe4b0595dbe736785&quot;,&quot;name&quot;:&quot;Password Manager&quot;},&quot;53734e55e4b071174050713b&quot;:{&quot;parentId&quot;:&quot;535928bce4b048998cb752d9&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:194,&quot;description&quot;:&quot;Companies that provide a solution to detect, prevent and protect against phone fraud&quot;},&quot;id&quot;:&quot;53734e55e4b071174050713b&quot;,&quot;name&quot;:&quot;Phone Fraud&quot;},&quot;53748c18e4b085ec4f4d312f&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:46,&quot;description&quot;:&quot;Companies that provide a solution to secure endpoint by virtualizing and isolating the browsing activity for preventing web-based attacks&quot;},&quot;id&quot;:&quot;53748c18e4b085ec4f4d312f&quot;,&quot;name&quot;:&quot;Threat Isolation&quot;},&quot;5374be82e4b085ec4f4d342a&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:74,&quot;description&quot;:&quot;Companies that provide a biometrics-based IAM solution&quot;},&quot;id&quot;:&quot;5374be82e4b085ec4f4d342a&quot;,&quot;name&quot;:&quot;Biometrics&quot;},&quot;5374e1cae4b085ec4f4d3595&quot;:{&quot;parentId&quot;:&quot;53564831e4b0411aaf48b159&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:203,&quot;description&quot;:&quot;Solution which provide real time reputation of a domain to prevent or block cyber threat&quot;},&quot;id&quot;:&quot;5374e1cae4b085ec4f4d3595&quot;,&quot;name&quot;:&quot;Reputation Monitoring&quot;},&quot;5375f10be4b035e7ab6e9547&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:106,&quot;description&quot;:&quot;Companies that provide a platform for IAM governance and access intelligence&quot;},&quot;id&quot;:&quot;5375f10be4b035e7ab6e9547&quot;,&quot;name&quot;:&quot;Intelligence &amp; Governance&quot;},&quot;53ccd374e4b0c99052489339&quot;:{&quot;parentId&quot;:&quot;53564831e4b0411aaf48b159&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:204,&quot;description&quot;:&quot;Companies that provide a platform for the detection of cyber threats in a website&quot;},&quot;id&quot;:&quot;53ccd374e4b0c99052489339&quot;,&quot;name&quot;:&quot;Threat Detection&quot;},&quot;53ff40d8e4b0785237e38b7c&quot;:{&quot;parentId&quot;:&quot;53564831e4b0411aaf48b159&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:205,&quot;description&quot;:&quot;Companies that detect and protect against DDoS attacks including layer 3,4 &amp; 7&quot;},&quot;id&quot;:&quot;53ff40d8e4b0785237e38b7c&quot;,&quot;name&quot;:&quot;DDoS Mitigation&quot;},&quot;54071895e4b0fd800eb0005b&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:259,&quot;description&quot;:&quot;Companies that provide cybersecurity for Operations technology such as IACS &amp; SCADA systems&quot;},&quot;id&quot;:&quot;54071895e4b0fd800eb0005b&quot;,&quot;name&quot;:&quot;Industrial Security&quot;},&quot;5412f794e4b0ff6e2b21fcd6&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:254,&quot;description&quot;:&quot;Security to protect data, identities, devices, IP and servers in the IOT&quot;},&quot;id&quot;:&quot;5412f794e4b0ff6e2b21fcd6&quot;,&quot;name&quot;:&quot;IoT Security&quot;},&quot;545cd365e4b0a2f443016b44&quot;:{&quot;parentId&quot;:&quot;53295f48e4b07f1af3220cb0&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:125,&quot;description&quot;:&quot;Companies that provide Enterprise Mobility Management (EMM) including MDM, MAM, IAM and/or enterprise app store.&quot;},&quot;id&quot;:&quot;545cd365e4b0a2f443016b44&quot;,&quot;name&quot;:&quot;EMM&quot;},&quot;55129e45e4b0fb7fb6ee3dc8&quot;:{&quot;parentId&quot;:&quot;53639ca0e4b0c0a1efec7cc5&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:240,&quot;description&quot;:&quot;Platform which assess and delivers quantitative score of an enterprise security and risk posture&quot;},&quot;id&quot;:&quot;55129e45e4b0fb7fb6ee3dc8&quot;,&quot;name&quot;:&quot;Security &amp; Risk Scorecards&quot;},&quot;55c49718e4b055e17db8dd86&quot;:{&quot;parentId&quot;:&quot;52ff2e3de4b0b193ed664d4a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:34,&quot;description&quot;:&quot;Platform to detect and respond to cyber threat on endpoint devices&quot;},&quot;id&quot;:&quot;55c49718e4b055e17db8dd86&quot;,&quot;name&quot;:&quot;Incident Detection &amp; Response&quot;},&quot;55d5799ce4b0ccb9ba3e7e20&quot;:{&quot;parentId&quot;:&quot;5371bca1e4b022d05fc6c31f&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:244,&quot;description&quot;:&quot;Companies that provide a Secure Email Gateway (SEG) that prevents malicious or rogue email and attachment based on enterprise policy&quot;},&quot;id&quot;:&quot;55d5799ce4b0ccb9ba3e7e20&quot;,&quot;name&quot;:&quot;SEG&quot;},&quot;55d57fe4e4b0ccb9ba3e7f0c&quot;:{&quot;parentId&quot;:&quot;5371bca1e4b022d05fc6c31f&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:250,&quot;description&quot;:&quot;Companies that provide anti-spam, email validation and email abuse detection platform&quot;},&quot;id&quot;:&quot;55d57fe4e4b0ccb9ba3e7f0c&quot;,&quot;name&quot;:&quot;Anti-Spam&quot;},&quot;55d58156e4b0ccb9ba3e7f2d&quot;:{&quot;parentId&quot;:&quot;5371bca1e4b022d05fc6c31f&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:245,&quot;description&quot;:&quot;Companies that provide a solution to encrypt email communication and access control over mail&quot;},&quot;id&quot;:&quot;55d58156e4b0ccb9ba3e7f2d&quot;,&quot;name&quot;:&quot;Email Encryption&quot;},&quot;55d5a577e4b0ccb9ba3e8283&quot;:{&quot;parentId&quot;:&quot;53303049e4b09e5482339a5b&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:221,&quot;description&quot;:&quot;Companies that provide a vulnerability assessment of open source modules, libraries and 3rd party application modules&quot;},&quot;id&quot;:&quot;55d5a577e4b0ccb9ba3e8283&quot;,&quot;name&quot;:&quot;Open Source Component&quot;},&quot;55d5a970e4b0ccb9ba3e8364&quot;:{&quot;parentId&quot;:&quot;53564831e4b0411aaf48b159&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:206,&quot;description&quot;:&quot;Security solution to prevent web scraping &amp; malware execution through network of bots remotely controlled by C&amp;C&quot;},&quot;id&quot;:&quot;55d5a970e4b0ccb9ba3e8364&quot;,&quot;name&quot;:&quot;Botnet Protection&quot;},&quot;55d5b9bee4b045fa07677822&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:59,&quot;description&quot;:&quot;Companies that provide a solution for the creation, management, control and security of privileged accounts and secrets&quot;},&quot;id&quot;:&quot;55d5b9bee4b045fa07677822&quot;,&quot;name&quot;:&quot;Privileged IAM&quot;},&quot;55dc20fae4b068a5fe11694a&quot;:{&quot;parentId&quot;:&quot;53564831e4b0411aaf48b159&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:208,&quot;description&quot;:&quot;Companies that provide a digital certificate for validation of SSL implementation and trusted information exchange&quot;},&quot;id&quot;:&quot;55dc20fae4b068a5fe11694a&quot;,&quot;name&quot;:&quot;Digital Certificate&quot;},&quot;55e830d9e4b00337fcf9357f&quot;:{&quot;parentId&quot;:&quot;53639ca0e4b0c0a1efec7cc5&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:239,&quot;description&quot;:&quot;Platform &amp; service which monitors entire web including dark web for detecting cyber threat and data breach&quot;},&quot;id&quot;:&quot;55e830d9e4b00337fcf9357f&quot;,&quot;name&quot;:&quot;Dark Net Monitoring&quot;},&quot;55ed82d7e4b0126850c78a4e&quot;:{&quot;parentId&quot;:&quot;52ff2df2e4b0b193ed664d43&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:222,&quot;description&quot;:&quot;Companies that provide a Runtime Application Self-Protection (RASP) solution to protect application by identifying and blocking attacks during runtime&quot;},&quot;id&quot;:&quot;55ed82d7e4b0126850c78a4e&quot;,&quot;name&quot;:&quot;RASP&quot;},&quot;560cf14be4b0e484a84b59a4&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:12,&quot;description&quot;:&quot;Companies that provide the security of DNS system/server/software&quot;},&quot;id&quot;:&quot;560cf14be4b0e484a84b59a4&quot;,&quot;name&quot;:&quot;DNS Security&quot;},&quot;5640ffcce4b0920113c70ff5&quot;:{&quot;parentId&quot;:&quot;52ff2e13e4b0b193ed664d47&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:180,&quot;description&quot;:&quot;Companies that provide Cloud Access Security Broker (CASB) tools that act as security gateways for data security, visibility, threat protection and compliance across cloud services&quot;},&quot;id&quot;:&quot;5640ffcce4b0920113c70ff5&quot;,&quot;name&quot;:&quot;CASB&quot;},&quot;564b1801e4b06b8515d7c77e&quot;:{&quot;parentId&quot;:&quot;5412f794e4b0ff6e2b21fcd6&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:255,&quot;description&quot;:&quot;Companies that provide a platform to detect cyber threats and anomalous behavior in IoT infrastructure and application&quot;},&quot;id&quot;:&quot;564b1801e4b06b8515d7c77e&quot;,&quot;name&quot;:&quot;Anomaly Detection&quot;},&quot;5657edefe4b0442049273784&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:275,&quot;description&quot;:&quot;Security &amp; hardening of the servers to prevent unauthorized access &amp; vulnerability attack&quot;},&quot;id&quot;:&quot;5657edefe4b0442049273784&quot;,&quot;name&quot;:&quot;Server Security&quot;},&quot;566015afe4b04c3365bfb798&quot;:{&quot;parentId&quot;:&quot;534d01afe4b059431aef8956&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:155,&quot;description&quot;:&quot;Companies that provide Digital Rights Management (DRM) of enterprise document and software&quot;},&quot;id&quot;:&quot;566015afe4b04c3365bfb798&quot;,&quot;name&quot;:&quot;Enterprise DRM&quot;},&quot;56607831e4b031f08d379f19&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:1,&quot;description&quot;:&quot;Platform that provide security across enterprise including data, infrastructure, access &amp; employs intelligence &amp; analytics&quot;},&quot;id&quot;:&quot;56607831e4b031f08d379f19&quot;,&quot;name&quot;:&quot;Suite&quot;},&quot;5660842ae4b031f08d379f29&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:107,&quot;description&quot;:&quot;Analytics of security information, event &amp; system for threat prevention, detection, mitigation across enterprise&quot;},&quot;id&quot;:&quot;5660842ae4b031f08d379f29&quot;,&quot;name&quot;:&quot;Security Analytics&quot;},&quot;566085cfe4b031f08d379f2a&quot;:{&quot;parentId&quot;:&quot;5660842ae4b031f08d379f29&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:118,&quot;description&quot;:&quot;Companies that provide analytics based solutions for threat detection at enterprise IT level&quot;},&quot;id&quot;:&quot;566085cfe4b031f08d379f2a&quot;,&quot;name&quot;:&quot;Threat Detection&quot;},&quot;566085cfe4b031f08d379f2b&quot;:{&quot;parentId&quot;:&quot;5660842ae4b031f08d379f29&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:110,&quot;description&quot;:&quot;Companies that provide a assessment and management of the enterprise-wide cyber-risk and vulnerabilities present&quot;},&quot;id&quot;:&quot;566085cfe4b031f08d379f2b&quot;,&quot;name&quot;:&quot;Cyber Risk &amp; Vulnerability Assessment&quot;},&quot;5660938ee4b031f08d379f32&quot;:{&quot;parentId&quot;:&quot;5660842ae4b031f08d379f29&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:108,&quot;description&quot;:&quot;Companies that provide a platform for Security Information and Event Management (SIEM)&quot;},&quot;id&quot;:&quot;5660938ee4b031f08d379f32&quot;,&quot;name&quot;:&quot;SIEM&quot;},&quot;5662bfeee4b05dae5f69796c&quot;:{&quot;parentId&quot;:&quot;534d01afe4b059431aef8956&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:156,&quot;description&quot;:&quot;Companies that provide a platform for Data Loss Prevention (DLP) and unauthorized exfiltration outside the enterprise&quot;},&quot;id&quot;:&quot;5662bfeee4b05dae5f69796c&quot;,&quot;name&quot;:&quot;Data Loss Prevention (DLP)&quot;},&quot;56646606e4b05dae5f697ec1&quot;:{&quot;parentId&quot;:&quot;5660842ae4b031f08d379f29&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:122,&quot;description&quot;:&quot;Companies that provide a cyber forensics platform to analyze previously captured data packets and reverse engineer&quot;},&quot;id&quot;:&quot;56646606e4b05dae5f697ec1&quot;,&quot;name&quot;:&quot;Cyber Forensics&quot;},&quot;56646bf4e4b05dae5f697ed1&quot;:{&quot;parentId&quot;:&quot;532ffec7e4b09e548233984f&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:6,&quot;description&quot;:&quot;Companies that provide a real time intrusion detection based on network activity and bandwidth pattern&quot;},&quot;id&quot;:&quot;56646bf4e4b05dae5f697ed1&quot;,&quot;name&quot;:&quot;Network Traffic Analytics&quot;},&quot;56648cd6e4b05dae5f697f90&quot;:{&quot;parentId&quot;:&quot;52ff2cfce4b0b193ed664d1a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:274,&quot;description&quot;:&quot;Companies that provide a solution for the access control, auditing, encryption, integrity controls and secure backup of a database&quot;},&quot;id&quot;:&quot;56648cd6e4b05dae5f697f90&quot;,&quot;name&quot;:&quot;Database Security&quot;},&quot;566509f2e4b0a6e97ece0ceb&quot;:{&quot;parentId&quot;:&quot;52ff2e13e4b0b193ed664d47&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:178,&quot;description&quot;:&quot;Security for virtual infrastructure such as public/private cloud, VM Server, Workload, Hypervisor, Container&quot;},&quot;id&quot;:&quot;566509f2e4b0a6e97ece0ceb&quot;,&quot;name&quot;:&quot;Cloud Infrastructure Security&quot;},&quot;56650ac9e4b030508478a794&quot;:{&quot;parentId&quot;:&quot;52ff2e13e4b0b193ed664d47&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:184,&quot;description&quot;:&quot;Companies that provide cyber security solution for the virtualised software containers&quot;},&quot;id&quot;:&quot;56650ac9e4b030508478a794&quot;,&quot;name&quot;:&quot;Container Security&quot;},&quot;566584ace4b017eeb445a7fb&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:9,&quot;description&quot;:&quot;Companies that provide solutions which filters traffic between two or more networks based on security rules&quot;},&quot;id&quot;:&quot;566584ace4b017eeb445a7fb&quot;,&quot;name&quot;:&quot;Firewall&quot;},&quot;5666b3cce4b0e5adf67b82d0&quot;:{&quot;parentId&quot;:&quot;566085cfe4b031f08d379f2a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:119,&quot;description&quot;:&quot;Companies that provide security analytics like UEBA to detect threat initiated or already present inside enterprise network&quot;},&quot;id&quot;:&quot;5666b3cce4b0e5adf67b82d0&quot;,&quot;name&quot;:&quot;Insider Threat Detection&quot;},&quot;5667c368e4b0716ca7d54d6d&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:92,&quot;description&quot;:&quot;Companies that provide modules &amp; technology solution for the implementation and management of IAM  system&quot;},&quot;id&quot;:&quot;5667c368e4b0716ca7d54d6d&quot;,&quot;name&quot;:&quot;Technology&quot;},&quot;56690a78e4b0a29d350871ba&quot;:{&quot;parentId&quot;:&quot;53295f48e4b07f1af3220cb0&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:126,&quot;description&quot;:&quot;Companies that provide Mobile Device Management (MDM) software that allows IT administrators to control, secure and enforce policies on smartphones, tablets and other endpoints.&quot;},&quot;id&quot;:&quot;56690a78e4b0a29d350871ba&quot;,&quot;name&quot;:&quot;MDM&quot;},&quot;56690a78e4b0a29d350871bb&quot;:{&quot;parentId&quot;:&quot;53295f48e4b07f1af3220cb0&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:128,&quot;description&quot;:&quot;Mobile Application Management (MAM) solution by whitelisting, application catalogue &amp; arbitrary injecting encryption code in app&quot;},&quot;id&quot;:&quot;56690a78e4b0a29d350871bb&quot;,&quot;name&quot;:&quot;MAM&quot;},&quot;56690a78e4b0a29d350871bc&quot;:{&quot;parentId&quot;:&quot;56690a78e4b0a29d350871ba&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:127,&quot;description&quot;:&quot;MDM solution which employs separate encrypted containers for personal &amp; workspace on single device&quot;},&quot;id&quot;:&quot;56690a78e4b0a29d350871bc&quot;,&quot;name&quot;:&quot;Workspace Containerization&quot;},&quot;56690ca0e4b09e473de73598&quot;:{&quot;parentId&quot;:&quot;56690a78e4b0a29d350871bb&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:131,&quot;description&quot;:&quot;Companies that provide a layer of security wrapping over apps to protect against attacks &amp; data theft&quot;},&quot;id&quot;:&quot;56690ca0e4b09e473de73598&quot;,&quot;name&quot;:&quot;Application Wrapping&quot;},&quot;56690ca0e4b09e473de73599&quot;:{&quot;parentId&quot;:&quot;56690a78e4b0a29d350871bb&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:130,&quot;description&quot;:&quot;Companies that analyze and manage apps based on profiling as per enterprise policies&quot;},&quot;id&quot;:&quot;56690ca0e4b09e473de73599&quot;,&quot;name&quot;:&quot;Application Profiling&quot;},&quot;56690ca0e4b09e473de7359a&quot;:{&quot;parentId&quot;:&quot;56690a78e4b0a29d350871bb&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:129,&quot;description&quot;:&quot;Solution for the remote access to app on a BYOD device running over a secure virtual mobile infrastructure (VMI)&quot;},&quot;id&quot;:&quot;56690ca0e4b09e473de7359a&quot;,&quot;name&quot;:&quot;Application Virtualization&quot;},&quot;566936b9e4b0ccc692309dc3&quot;:{&quot;parentId&quot;:&quot;5660842ae4b031f08d379f29&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:121,&quot;description&quot;:&quot;Platform or service to respond &amp; mitigate already detected threat incident in enterprise&quot;},&quot;id&quot;:&quot;566936b9e4b0ccc692309dc3&quot;,&quot;name&quot;:&quot;Incident Response&quot;},&quot;566dbff1e4b0ac980bffaee1&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d46&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:66,&quot;description&quot;:&quot;Companies that provide a Single Sign-On (SSO) solution to log in  on web &amp; mobile sites and applications&quot;},&quot;id&quot;:&quot;566dbff1e4b0ac980bffaee1&quot;,&quot;name&quot;:&quot;SSO&quot;},&quot;566ecc97e4b087555e724e26&quot;:{&quot;parentId&quot;:&quot;5412f794e4b0ff6e2b21fcd6&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:257,&quot;description&quot;:&quot;Companies that provide an embedded hardware or a software development kit for the IoT security&quot;},&quot;id&quot;:&quot;566ecc97e4b087555e724e26&quot;,&quot;name&quot;:&quot;Embeddable IoT Security&quot;},&quot;568eb20fe4b04d1ab768d5a7&quot;:{&quot;parentId&quot;:&quot;52ff2e04e4b0b193ed664d45&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:56,&quot;description&quot;:&quot;Companies that provide a unified identity and access management solution&quot;},&quot;id&quot;:&quot;568eb20fe4b04d1ab768d5a7&quot;,&quot;name&quot;:&quot;Unified IAM&quot;},&quot;56a9b573e4b0079795f189f1&quot;:{&quot;parentId&quot;:&quot;52ff2df2e4b0b193ed664d43&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:225,&quot;description&quot;:&quot;Security of API &amp; API servers from attacks like denial of services, heartbleed, logjam, poodle etc&quot;},&quot;id&quot;:&quot;56a9b573e4b0079795f189f1&quot;,&quot;name&quot;:&quot;API Security&quot;},&quot;56bd9b65e4b0167a5f0ba8d8&quot;:{&quot;parentId&quot;:&quot;535de22ce4b0735cb1b3e164&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:191,&quot;description&quot;:&quot;Companies that provide a solution to verify ID document digitally to prevent cyber fraud&quot;},&quot;id&quot;:&quot;56bd9b65e4b0167a5f0ba8d8&quot;,&quot;name&quot;:&quot;ID Document Verification&quot;},&quot;56d97b2ce4b096207eeba95e&quot;:{&quot;parentId&quot;:&quot;54071895e4b0fd800eb0005b&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:260,&quot;description&quot;:&quot;Companies that provide vulnerability assessment of industrial cybersecurity posture&quot;},&quot;id&quot;:&quot;56d97b2ce4b096207eeba95e&quot;,&quot;name&quot;:&quot;Vulnerability Assessment&quot;},&quot;56d98df2e4b064ac7d89fe9f&quot;:{&quot;parentId&quot;:&quot;54071895e4b0fd800eb0005b&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:261,&quot;description&quot;:&quot;Companies that provide a platform to detect cyber threats in the operational technology network including ICS &amp; SCADA systems&quot;},&quot;id&quot;:&quot;56d98df2e4b064ac7d89fe9f&quot;,&quot;name&quot;:&quot;Threat Detection&quot;},&quot;56d9b8d2e4b064ac7d8a0a46&quot;:{&quot;parentId&quot;:&quot;54071895e4b0fd800eb0005b&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:262,&quot;description&quot;:&quot;Companies that provide a solution to prevent cyber attacks on industrial systems including OT network, ICS/SCADA systems&quot;},&quot;id&quot;:&quot;56d9b8d2e4b064ac7d8a0a46&quot;,&quot;name&quot;:&quot;Threat Prevention&quot;},&quot;570b68d5e4b0b544cd006a5e&quot;:{&quot;parentId&quot;:&quot;5657edefe4b0442049273784&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:276,&quot;description&quot;:&quot;Companies that provide security solution for operating system of server&quot;},&quot;id&quot;:&quot;570b68d5e4b0b544cd006a5e&quot;,&quot;name&quot;:&quot;OS Security&quot;},&quot;571742c7e4b0aafdf9f3a700&quot;:{&quot;parentId&quot;:&quot;5374be82e4b085ec4f4d342a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:77,&quot;description&quot;:&quot;Companies that provide an authentication platform based on innate human features like a fingerprint, iris pattern etc.&quot;},&quot;id&quot;:&quot;571742c7e4b0aafdf9f3a700&quot;,&quot;name&quot;:&quot;Physiological&quot;},&quot;571742c7e4b0aafdf9f3a701&quot;:{&quot;parentId&quot;:&quot;5374be82e4b085ec4f4d342a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:75,&quot;description&quot;:&quot;Companies that provide an authentication platform based on identifying and confirming measurable patterns in human activities&quot;},&quot;id&quot;:&quot;571742c7e4b0aafdf9f3a701&quot;,&quot;name&quot;:&quot;Behavioral&quot;},&quot;5732f379e4b0bd8b59fc4788&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:25,&quot;description&quot;:&quot;Companies that provide Network Access Control (NAC) solution for controlled access to the internal network&quot;},&quot;id&quot;:&quot;5732f379e4b0bd8b59fc4788&quot;,&quot;name&quot;:&quot;Network Access Control&quot;},&quot;574fdd9ae4b0f0e47ea4f63d&quot;:{&quot;parentId&quot;:&quot;534d01afe4b059431aef8956&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:160,&quot;description&quot;:&quot;Companies that provide a solution for data security and privacy by tokenization and obfuscation&quot;},&quot;id&quot;:&quot;574fdd9ae4b0f0e47ea4f63d&quot;,&quot;name&quot;:&quot;Data Masking&quot;},&quot;575ab8f7e4b0cb636486739f&quot;:{&quot;parentId&quot;:&quot;534d01afe4b059431aef8956&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:137,&quot;description&quot;:&quot;Companies that provide security of data stored or moving through cloud-based storage&quot;},&quot;id&quot;:&quot;575ab8f7e4b0cb636486739f&quot;,&quot;name&quot;:&quot;Cloud Data Security&quot;},&quot;57763800e4b038d315f6c6a2&quot;:{&quot;parentId&quot;:&quot;534d01afe4b059431aef8956&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:162,&quot;description&quot;:&quot;Companies that provide a software to erase &amp; destroy data stored in digital storage system to prevent unauthorized access&quot;},&quot;id&quot;:&quot;57763800e4b038d315f6c6a2&quot;,&quot;name&quot;:&quot;Data Shredding&quot;},&quot;57835e1fe4b05105dcebe4c4&quot;:{&quot;parentId&quot;:&quot;53639ca0e4b0c0a1efec7cc5&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:242,&quot;description&quot;:&quot;Companies that provide a platform for cybersecurity professionals and companies to discuss and share knowledge&quot;},&quot;id&quot;:&quot;57835e1fe4b05105dcebe4c4&quot;,&quot;name&quot;:&quot;Professional Community&quot;},&quot;578c659be4b026bca5a71887&quot;:{&quot;parentId&quot;:&quot;53295f48e4b07f1af3220cb0&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:135,&quot;description&quot;:&quot;Companies that provide a software tools to perform digital forensics of mobile devices&quot;},&quot;id&quot;:&quot;578c659be4b026bca5a71887&quot;,&quot;name&quot;:&quot;Mobile Forensics&quot;},&quot;57cf9938e4b05893635e6100&quot;:{&quot;parentId&quot;:&quot;52ff2dd1e4b0b193ed664d41&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:26,&quot;description&quot;:&quot;Companies that provide a Secure Web Gateway (SEG) to defend enterprise users from the Internet-borne threats&quot;},&quot;id&quot;:&quot;57cf9938e4b05893635e6100&quot;,&quot;name&quot;:&quot;SWG&quot;},&quot;57e51eb4e4b0e6e088ef96bb&quot;:{&quot;parentId&quot;:&quot;5330677ae4b09e5482339b7a&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:37,&quot;description&quot;:&quot;Companies that provide an endpoint software to prevent, detect and remove malicious infections on end point devices&quot;},&quot;id&quot;:&quot;57e51eb4e4b0e6e088ef96bb&quot;,&quot;name&quot;:&quot;Antivirus&quot;},&quot;57e8ed37e4b03287ee8979a2&quot;:{&quot;parentId&quot;:&quot;53303049e4b09e5482339a5b&quot;,&quot;nodeInfo&quot;:{&quot;position&quot;:216,&quot;description&quot;:&quot;Companies that provide a Static Application Security Testing (SAST) platform&quot;},&quot;id&quot;:&quot;57e8ed37e4b03287ee8979a2&quot;,&quot;name&quot;:&quot;SAST&quot;}
</code></pre>
<p>I am able to print out all the names, ids, and parentIds with the following code:</p>
<pre><code>with open(r'C:\Users\UserName\CodeProjects\project_one\test.json') as f:
    data = json.loads(f.read())    
    idkeys = re.findall(&quot;'id': '(.*?)', 'name'&quot;, str(data))

  for idkey in idkeys:
    name = &quot;Name: &quot; + data['businessModelInfo'][idkey]['name']
    idd = &quot;id: &quot; + data['businessModelInfo'][idkey]['id']
    parent = &quot;Parent: &quot; + data['businessModelInfo'][idkey]['parentId']
    print(name)
    print(idd)
    print(parent)
</code></pre>
<p>I think I need to do a for loop to match the parentIds with their children Ids, but I have no idea where to begin.</p>
<p>Example desired output:</p>
<pre><code>Cybersecurity &gt; Network Security &gt; Network UTM
Cybersecurity &gt; Network Security &gt; Secure Access Service Edge as a convergence (SASE)
Cybersecurity &gt; Network Security &gt; NIDS
Cybersecurity &gt; Network Security &gt; NIDS &gt; Network Traffic Analytics
Cybersecurity &gt; Network Security &gt; NIDS &gt; Network Traffic Analytics
Cybersecurity &gt; Network Security &gt; NIDS &gt; Honeypot
Cybersecurity &gt; Network Security &gt; VPN &gt; Business VPN
Cybersecurity &gt; Network Security &gt; VPN &gt; Personal VPN
Cybersecurity &gt; Network Security &gt; VPN &gt; Personal VPN &gt; Decentralized VPN
Cybersecurity &gt; Network Security &gt; VPN &gt; Whitelabel VPN
</code></pre>
<p>Thanks!</p>
",35,1,0,3,python;json;web-scraping,2022-07-14 23:40:53,2022-07-14 23:40:53,2022-07-15 00:08:31,i m trying to parse json data to build hierarchy categories and print them to a csv  i was hoping that someone could please help me  json data  i am able to print out all the names  ids  and parentids with the following code  i think i need to do a for loop to match the parentids with their children ids  but i have no idea where to begin  example desired output  thanks ,parsing json to build a hierarchy
122,17147344,72979205,Redux returning error message when returning new value from action creator,"<p>I am currently working on a trial app where I allow users to vote on the best anecdote and when a user votes, the action creator should return a new sorted array of objects. However, i keep getting this error message:</p>
<pre><code>An immer producer returned a new value *and* modified its draft. Either return a new value *or* modify the draft.
</code></pre>
<p>I am kind of confused with this error message because I do not see where I have modified the original state because I would assume <strong>filter</strong> and <strong>map</strong> would not mess with the state. Where am i wrong? Here is my code:</p>
<pre><code>import _, { sortBy } from 'underscore';
import { createSlice, current } from '@reduxjs/toolkit';

const anecdotesAtStart = [
  'If it hurts, do it more often',
  'Adding manpower to a late software project makes it later!',
  'The first 90 percent of the code accounts for the first 90 percent of the development time...The remaining 10 percent of the code accounts for the other 90 percent of the development time.',
  'Any fool can write code that a computer can understand. Good programmers write code that humans can understand.',
  'Premature optimization is the root of all evil.',
  'Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it.'
]

const getId = () =&gt; (100000 * Math.random()).toFixed(0)

const asObject = (anecdote) =&gt; {
  return {
    content: anecdote,
    id: getId(),
    votes: 0
  }
}

const initialState = anecdotesAtStart.map(asObject)

const anecdoteSlice = createSlice({
  name: 'anecdote',
  initialState,
  reducers: {
    createNotification(state, action) {
      return action.payload;
    },
    increaseVote(state, action) {
      const currentArray = state.filter(obj =&gt; obj.id === action.payload)
      const newState = state.map(obj =&gt; {
      // 👇️ if id equals 2 replace object
      if (obj.id === currentArray[0].id) {
        currentArray[0].votes += 1
        return currentArray[0]
      }
      // 👇️ otherwise return object as is
      return obj;
    });
      const sortedArray = _.sortBy(newState, 'votes')
      return sortedArray
    },
    createAnecdote(state, action) {
      const newAnecdote = action.payload
      const initializedAnecdote = asObject(newAnecdote)
      const updatedAnecdotes = state.concat(initializedAnecdote)
      return updatedAnecdotes;
    },

  }})

export const { createNotification, increaseVote, createAnecdote} = anecdoteSlice.actions
export default anecdoteSlice.reducer
</code></pre>
<p>I believe the error is occurring in <strong>increaseVote</strong>:</p>
<pre><code>increaseVote(state, action) {
      const currentArray = state.filter(obj =&gt; obj.id === action.payload)
      const newState = state.map(obj =&gt; {
      // 👇️ if id equals 2 replace object
      if (obj.id === currentArray[0].id) {
        currentArray[0].votes += 1
        return currentArray[0]
      }
      // 👇️ otherwise return object as is
      return obj;
    });
      const sortedArray = _.sortBy(newState, 'votes')
      return sortedArray
    },
</code></pre>
",29,1,0,3,javascript;reactjs;redux,2022-07-14 13:43:13,2022-07-14 13:43:13,2022-07-14 13:56:48,i am currently working on a trial app where i allow users to vote on the best anecdote and when a user votes  the action creator should return a new sorted array of objects  however  i keep getting this error message  i am kind of confused with this error message because i do not see where i have modified the original state because i would assume filter and map would not mess with the state  where am i wrong  here is my code  i believe the error is occurring in increasevote ,redux returning error message when returning new value from action creator
123,650492,5663482,MySQL query to show difference between development and production schema,"<p>I would like to have a query using the schema database in MySQL<br>
 that shows the difference between the columns, triggers and stored procedures between two database schema's: production and development.</p>

<p><strong>Query, not tools</strong><br>
I've seen <a href=""https://stackoverflow.com/questions/225772/compare-two-mysql-databases"">Compare two MySQL databases</a><br>
Which lists the tools that can perform this task, but I would like to know is if there is a <strong>query</strong> that can perform this task.<br>
Please only suggest queries, <strong>I really do not want to know about tools, command line hacks or such.</strong></p>

<p>I am looking to see if the production database and development database are out of sync.<br>
And which fields, procedures etc where added or changed, so I can update the production database if I roll out a new update of the client software that uses the database.</p>

<p>I'm using MySQL 5.1 latest version.</p>
",4642,6,14,3,mysql;schema;information-schema,2011-04-14 15:49:23,2011-04-14 15:49:23,2022-07-14 06:54:38,i m using mysql   latest version ,mysql query to show difference between development and production schema
124,19546018,72974658,gunicorn slower than flask Werkzeug,"<p>I have just learned flask and have encountered a problem which has not been solved for two days.I have a barebone flask like this:</p>
<pre><code>from flask import Flask, jsonify, request
from prediction import run_ecg, run_get_ecg
from service_streamer import ThreadedStreamer
from flask_cors import cross_origin, CORS


app = Flask(__name__)
CORS(app, supports_credentials=True)
CORS(app, resources=r'/*')

@app.route('/test', methods=['GET', 'POST', 'HEAD'])
@cross_origin(supports_credentials=True)
@cross_origin(origins=&quot;*&quot;)
@cross_origin(methods=['GET', 'POST', 'HEAD'])
def test():
    content = request.json
    time.sleep(2) 
    return jsonify({&quot;result&quot;:content})
if __name__ == &quot;__main__&quot;:
    app.run(host=&quot;0.0.0.0&quot;, port=5050)
</code></pre>
<p>Test the following：
flask development server</p>
<pre><code>Server Software:        Werkzeug/2.1.2
Server Hostname:        47.110.32.83
Server Port:            5050

Document Path:          /get_ecg
Document Length:        81 bytes

Concurrency Level:      10
Time taken for tests:   24.098 seconds
Complete requests:      100
Failed requests:        0
Total transferred:      27800 bytes
Total body sent:        23700
HTML transferred:       8100 bytes
Requests per second:    4.15 [#/sec] (mean)
Time per request:       2409.803 [ms] (mean)
Time per request:       240.980 [ms] (mean, across all concurrent requests)
Transfer rate:          1.13 [Kbytes/sec] received
                        0.96 kb/s sent
                        2.09 kb/s total
</code></pre>
<p>gunicorn</p>
<pre><code>Server Software:        gunicorn
Server Hostname:        47.110.32.83
Server Port:            5051

Document Path:          /get_ecg
Document Length:        81 bytes

Concurrency Level:      10
Time taken for tests:   52.290 seconds
Complete requests:      100
Failed requests:        0
Total transferred:      25800 bytes
Total body sent:        23700
HTML transferred:       8100 bytes
Requests per second:    1.91 [#/sec] (mean)
Time per request:       5229.022 [ms] (mean)
Time per request:       522.902 [ms] (mean, across all concurrent requests)
Transfer rate:          0.48 [Kbytes/sec] received
                        0.44 kb/s sent
                        0.92 kb/s total
</code></pre>
<pre><code>#flask development server
python app.py
#gunicorn
gunicorn -w 4 -b:5051 app:app
#ab
ab -r -c 10 -n 100 -p test.json -T application/json http://xx.xx.xx.xx:5050/test
</code></pre>
<p>Why is Gunicorn slower than Flask development server?
Did I do something wrong?
I would appreciate it if you could answer my questions.</p>
",55,1,1,1,python,2022-07-14 05:50:43,2022-07-14 05:50:43,2022-07-14 05:59:02,i have just learned flask and have encountered a problem which has not been solved for two days i have a barebone flask like this  gunicorn,gunicorn slower than flask werkzeug
125,9313492,72971244,Publish Code Builds/Releases on a Git Branch,"<p>I am the sole developer on a corporate repository. It is hosted on BitBucket, which I don't believe to have the <code>Releases</code> feature I've seen on GitHub. I'm looking to make a first release of the software, but users don't need access to the code, just an executable. (It's not a security risk, just a convenience factor - no point in copying down 50 development files used for building.)</p>
<p>I've heard that Bitbucket has a Downloads feature, but I don't see that's it's enabled in my repo. I am currently thinking through maintaining a <code>Stable</code> branch that contains only the two files users will need.</p>
<ol>
<li>How can I structure this new branch and maintain it in the future? (new <code>.gitignore</code>? Local merges, best practices with tagging, etc.)</li>
<li>Is the <code>Stable</code> branch approach misguided? Do I need to just point to an external storage?<br />
2.1 The binaries to be published are plenty small enough for git (~<code>5MB</code>).<br />
2.2  Additionally, the repo is also comparatively small (~<code>100MB</code>), so copying it isn't unreasonable, just unnecessary.</li>
</ol>
",21,0,0,3,git;bitbucket;release,2022-07-13 21:49:49,2022-07-13 21:49:49,2022-07-13 21:49:49,i am the sole developer on a corporate repository  it is hosted on bitbucket  which i don t believe to have the releases feature i ve seen on github  i m looking to make a first release of the software  but users don t need access to the code  just an executable   it s not a security risk  just a convenience factor   no point in copying down  development files used for building   i ve heard that bitbucket has a downloads feature  but i don t see that s it s enabled in my repo  i am currently thinking through maintaining a stable branch that contains only the two files users will need ,publish code builds releases on a git branch
126,4601149,41401515,Visual Studio toolchain in Eclipse for C++,"<p>I have Eclipse Neon.2 installed for Java, however, I am working on a project that involves JNI so I have had to set up Eclipse for C++. To do this I downloaded the <code>Development Tools for C++</code> under <code>Help -&gt; Install New Software</code>. My problem is there are no available <code>toolchains</code> available for my C++ project.</p>

<p>Several websites and YouTube videos have suggested that there is a Microsoft Visual C++ toolchain available, such as this <a href=""https://stackoverflow.com/questions/10046271/visual-studio-toolchain-plugin-in-eclipse-indigo"">SO question</a> and this <a href=""https://www.youtube.com/watch?v=eBV1uoKqDZo"" rel=""nofollow noreferrer"">video</a>, but I have had no success.</p>

<p>Is there a setup stage or plugin I could have missed that is causing it not to be listed?</p>

<p><em>Setup</em><br>
Windows 10<br>
Eclipse Neon.2<br>
Microsoft Visual Studio Enterprise 2017 RC</p>
",5920,3,5,4,c++;eclipse;eclipse-plugin;toolchain,2016-12-30 21:15:01,2016-12-30 21:15:01,2022-07-13 15:04:46,i have eclipse neon  installed for java  however  i am working on a project that involves jni so i have had to set up eclipse for c    to do this i downloaded the development tools for c   under help   gt  install new software  my problem is there are no available toolchains available for my c   project  several websites and youtube videos have suggested that there is a microsoft visual c   toolchain available  such as this  and this   but i have had no success  is there a setup stage or plugin i could have missed that is causing it not to be listed ,visual studio toolchain in eclipse for c  
127,1512564,72196449,semantic-ui-react elements all have error &quot;cannot be used as a JSX component&quot;,"<p>I have a React app in typescript that uses semantic-ui-react but will no longer compile due to all of the SUR elements having an error &quot;cannot be used as a JSX component.&quot; This app has been in use for around 2 years, and today started throwing this compile error.</p>
<p>Things I have tried:</p>
<ol>
<li>Remove yarn lock and node_modules and reinstall dependencies</li>
<li>Downgrading/Upgrading react, react-dom, react-scripts and their @types</li>
<li>Downgrading/Upgrading semantic-ui-react package</li>
<li>Pulled last known good working package.json from repo and reinstalled dependencies</li>
</ol>
<p>I am using a yarn mono-repo setup where this is one of the apps.</p>
<p>Any help appreciated!</p>
<pre><code>TypeScript error in /Users/lerxstrulz/projects/test/web/src/components/MyMenu/index.tsx(18,8):
'Menu' cannot be used as a JSX component.
  Its instance type 'Component&lt;MenuProps, any, any&gt;' is not a valid JSX element.  TS2786

    17 |     return (
  &gt; 18 |       &lt;Menu&gt;
       |        ^
    19 |         &lt;Menu.Item&gt;This is a menu item&lt;/Menu.Item&gt;
       |          
</code></pre>
<p>Sample code:</p>
<pre><code>import React from 'react';
import {Menu, Icon} from 'semantic-ui-react';

export const MyMenu = () =&gt; {
  const MenuItems = () =&gt; {
    return (
      &lt;Menu&gt; &lt;-- this is throwing the error (as well as ALL SUR elements)
        &lt;Menu.Item&gt;This is a menu item&lt;/Menu.Item&gt;
      &lt;/Menu&gt;
    )
  }
}
</code></pre>
<p>Here is my package.json:</p>
<pre><code>{
  &quot;name&quot;: &quot;app&quot;,
  &quot;version&quot;: &quot;2.0.10&quot;,
  &quot;private&quot;: true,
  &quot;dependencies&quot;: {
    &quot;@stripe/react-stripe-js&quot;: &quot;^1.1.2&quot;,
    &quot;@stripe/stripe-js&quot;: &quot;^1.7.0&quot;,
    &quot;@tinymce/tinymce-react&quot;: &quot;^3.6.0&quot;,
    &quot;agora-rtc-sdk-ng&quot;: &quot;^4.x&quot;,
    &quot;axios&quot;: &quot;^0.19.2&quot;,
    &quot;bad-words&quot;: &quot;^3.0.3&quot;,
    &quot;emoji-picker-react&quot;: &quot;^3.2.3&quot;,
    &quot;env-cmd&quot;: &quot;^10.1.0&quot;,
    &quot;file-saver&quot;: &quot;^2.0.2&quot;,
    &quot;firebase&quot;: &quot;^9.0.1&quot;,
    &quot;html-to-react&quot;: &quot;^1.4.3&quot;,
    &quot;joi&quot;: &quot;^17.4.2&quot;,
    &quot;lodash&quot;: &quot;^4.17.15&quot;,
    &quot;logrocket&quot;: &quot;^1.0.14&quot;,
    &quot;luxon&quot;: &quot;^2.0.2&quot;,
    &quot;nosleep.js&quot;: &quot;^0.12.0&quot;,
    &quot;react&quot;: &quot;^16.13.1&quot;,
    &quot;react-add-to-calendar&quot;: &quot;^0.1.5&quot;,
    &quot;react-app-polyfill&quot;: &quot;^1.0.6&quot;,
    &quot;react-countdown&quot;: &quot;^2.2.1&quot;,
    &quot;react-datepicker&quot;: &quot;^2.16.0&quot;,
    &quot;react-device-detect&quot;: &quot;^2.0.1&quot;,
    &quot;react-dom&quot;: &quot;^16.13.1&quot;,
    &quot;react-dropzone&quot;: &quot;^11.0.1&quot;,
    &quot;react-easy-crop&quot;: &quot;^3.3.0&quot;,
    &quot;react-emoji-render&quot;: &quot;^1.2.4&quot;,
    &quot;react-google-charts&quot;: &quot;^3.0.15&quot;,
    &quot;react-google-login&quot;: &quot;^5.2.2&quot;,
    &quot;react-google-recaptcha&quot;: &quot;^2.1.0&quot;,
    &quot;react-helmet&quot;: &quot;^6.1.0&quot;,
    &quot;react-input-mask&quot;: &quot;^2.0.4&quot;,
    &quot;react-intl&quot;: &quot;^5.20.7&quot;,
    &quot;react-multi-carousel&quot;: &quot;^2.8.0&quot;,
    &quot;react-number-format&quot;: &quot;^4.4.1&quot;,
    &quot;react-password-strength-bar&quot;: &quot;^0.3.2&quot;,
    &quot;react-paypal-button-v2&quot;: &quot;^2.6.2&quot;,
    &quot;react-phone-input-2&quot;: &quot;^2.13.8&quot;,
    &quot;react-player&quot;: &quot;^2.10.0&quot;,
    &quot;react-router-dom&quot;: &quot;^6.1.1&quot;,
    &quot;react-scripts&quot;: &quot;^3.4.1&quot;,
    &quot;react-scroll&quot;: &quot;^1.7.16&quot;,
    &quot;react-sortable-hoc&quot;: &quot;^1.11.0&quot;,
    &quot;react-text-transition&quot;: &quot;^1.3.0&quot;,
    &quot;react-textarea-autosize&quot;: &quot;^8.0.1&quot;,
    &quot;react-to-print&quot;: &quot;^2.9.0&quot;,
    &quot;react-toastify&quot;: &quot;^6.0.8&quot;,
    &quot;screenfull&quot;: &quot;^5.0.2&quot;,
    &quot;semantic-ui-css&quot;: &quot;^2.4.1&quot;,
    &quot;semantic-ui-react&quot;: &quot;^2.0.3&quot;,
    &quot;styled-components&quot;: &quot;^5.1.1&quot;,
    &quot;xlsx&quot;: &quot;^0.16.1&quot;
  },
  &quot;scripts&quot;: {
    &quot;start&quot;: &quot;REACT_APP_STAGE=development react-scripts start&quot;,
    &quot;start:ssl&quot;: &quot;HTTPS=true yarn start&quot;,
    &quot;demo&quot;: &quot;REACT_APP_STAGE=demo react-scripts start&quot;,
    &quot;build&quot;: &quot;rm -rf build &amp;&amp; react-scripts build&quot;        
  },
  &quot;eslintConfig&quot;: {
    &quot;extends&quot;: &quot;react-app&quot;
  },
  &quot;browserslist&quot;: {
    &quot;production&quot;: [
      &quot;&gt;0.2%&quot;,
      &quot;not dead&quot;,
      &quot;not op_mini all&quot;
    ],
    &quot;development&quot;: [
      &quot;last 1 chrome version&quot;,
      &quot;last 1 firefox version&quot;,
      &quot;last 1 safari version&quot;
    ]
  },
  &quot;devDependencies&quot;: {
    &quot;@types/luxon&quot;: &quot;^2.0.3&quot;,
    &quot;@types/node&quot;: &quot;^16.7.13&quot;,
    &quot;@types/react&quot;: &quot;^17.0.20&quot;,
    &quot;@types/react-dom&quot;: &quot;^17.0.9&quot;,
    &quot;@types/react-easy-crop&quot;: &quot;^2.0.0&quot;,
    &quot;@types/styled-components&quot;: &quot;^5.1.14&quot;,
    &quot;@welldone-software/why-did-you-render&quot;: &quot;^6.2.0&quot;,
    &quot;cypress&quot;: &quot;^5.6.0&quot;,
    &quot;husky&quot;: &quot;^4.3.0&quot;,
    &quot;prettier&quot;: &quot;^2.1.2&quot;,
    &quot;pretty-quick&quot;: &quot;^3.1.0&quot;,
    &quot;semantic-ui-less&quot;: &quot;^2.4.1&quot;,
    &quot;source-map-explorer&quot;: &quot;^2.5.2&quot;,
    &quot;typescript&quot;: &quot;^4.4.2&quot;
  },
  &quot;husky&quot;: {
    &quot;hooks&quot;: {
      &quot;pre-commit&quot;: &quot;pretty-quick --staged&quot;
    }
  }
}
</code></pre>
",265,1,1,4,reactjs;typescript;jsx;semantic-ui-react,2022-05-11 09:39:03,2022-05-11 09:39:03,2022-07-13 14:49:29,i have a react app in typescript that uses semantic ui react but will no longer compile due to all of the sur elements having an error  cannot be used as a jsx component   this app has been in use for around  years  and today started throwing this compile error  things i have tried  i am using a yarn mono repo setup where this is one of the apps  any help appreciated  sample code  here is my package json ,semantic ui react elements all have error  cannot be used as a jsx component 
128,7133935,72961770,How do I reference a Java logging.properties file path in a distributed Gradle project?,"<p>I have a Java Gradle application that logs correctly during development, but does not work correctly when it is distributed.</p>
<p>When I run the program in my IDE (IntelliJ if that is relevant) the logging is formatted correctly, however, when I run &quot;./gradlew distZip&quot; and use the distributed software on our production server it does not create a log file and looses the logging.properties configuration it should have.</p>
<p>The logger pulls input from my logging.properties into LogManager, creates a handler with a simple formatter (configured in logging.properties), and adds the handler to the logger:</p>
<pre><code>LogManager.getLogManager().readConfiguration(
    new FileInputStream(&quot;./src/main/java/logging/logging.properties&quot;));
FileHandler handler = new FileHandler(&quot;myLog.log&quot;, FILE_SIZE, 4, true);
handler.setFormatter(new SimpleFormatter());
logger.addHandler(handler);
</code></pre>
<p>When I run this in IntelliJ I get a set of output files: myLog.log.x and log entries in those files match the properties I created:</p>
<pre><code>[2022-07-12 09:26:32] [INFO] APPLICATION: Setting up application 
[2022-07-12 09:26:32] [INFO] Starting server on port: 8080
[2022-07-12 09:26:32] [INFO] Updating data from API 
...
</code></pre>
<p>When I run the bat file from the distribution it logs to the terminal and gives an IO error:</p>
<pre><code>Jul 12, 2022 12:53:09 PM logging.ApplicationLogger getLogger
SEVERE: .\src\main\java\logging\logging.properties (The system cannot find the path 
specified)
</code></pre>
<p>I think this makes sense, since the distributed bat file doesn't know about the development file structure. What I don't know, is how to compensate for whatever &quot;./gradlew distZip&quot; does to the file structure. I tried adding the logging.properties file to the distribution as an additional file, but that didn't work.</p>
<p>How do I reference my logging.properties file so that it is found by my distribution?</p>
",6,1,0,4,java;gradle;logging;software-distribution,2022-07-13 09:23:21,2022-07-13 09:23:21,2022-07-13 09:23:21,i have a java gradle application that logs correctly during development  but does not work correctly when it is distributed  when i run the program in my ide  intellij if that is relevant  the logging is formatted correctly  however  when i run    gradlew distzip  and use the distributed software on our production server it does not create a log file and looses the logging properties configuration it should have  the logger pulls input from my logging properties into logmanager  creates a handler with a simple formatter  configured in logging properties   and adds the handler to the logger  when i run this in intellij i get a set of output files  mylog log x and log entries in those files match the properties i created  when i run the bat file from the distribution it logs to the terminal and gives an io error  i think this makes sense  since the distributed bat file doesn t know about the development file structure  what i don t know  is how to compensate for whatever    gradlew distzip  does to the file structure  i tried adding the logging properties file to the distribution as an additional file  but that didn t work  how do i reference my logging properties file so that it is found by my distribution ,how do i reference a java logging properties file path in a distributed gradle project 
129,17896546,72956147,Text not centered within Badge component,"<p>Text within the Badge component will not center (see attached images). I have tried Badge in react-native-paper and react-navigation bottom tab. Both display properly on some simulator devices however not on a physical iPhone 13 Pro Max I am testing on.</p>
<p><a href=""https://i.stack.imgur.com/vOrLV.jpg"" rel=""nofollow noreferrer"">react-native-paper demo app</a> <a href=""https://i.stack.imgur.com/eviAR.jpg"" rel=""nofollow noreferrer"">my app with react-navigation bottom tab badge</a><a href=""https://i.stack.imgur.com/mG2gG.jpg"" rel=""nofollow noreferrer"">my app using react-native-paper badge</a></p>
<h3>Code sample</h3>
<p>Here is a snippet from my app using react-native-paper</p>
<pre><code>        &lt;View style={{flexDirection: 'column'}}&gt;
          &lt;View style={{alignContent: 'center'}}&gt;
            &lt;Badge&gt;{count[0]}&lt;/Badge&gt;
          &lt;/View&gt;
          &lt;View&gt;
          &lt;/View&gt;
        &lt;/View&gt;
</code></pre>
<h3>What have you tried</h3>
<p>I have tried to adjust with styling the Badge component. As well as adjusting styling of the Views containing the Badge However nothing seems to help.</p>
<p>It does behave as desired on iOS and Android simulators.</p>
<h3>Your Environment</h3>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>software</th>
<th>version</th>
</tr>
</thead>
</table>
</div>
<p>Development environment:
OS: macOS 12.4
CPU: (10) arm64 Apple M1 Max
react: 17.0.2
react-native: 0.68.1
react-native-paper 4.12.2
react-native-vector-icons: 9.1.0
node v18.4.0
npm 8.12.1</p>
<p>Device info with the issue:
iPhone 13 Pro Max
iOS ver 15.5</p>
",25,0,0,2,react-navigation;react-native-paper,2022-07-12 20:20:34,2022-07-12 20:20:34,2022-07-12 20:20:34,text within the badge component will not center  see attached images   i have tried badge in react native paper and react navigation bottom tab  both display properly on some simulator devices however not on a physical iphone  pro max i am testing on    here is a snippet from my app using react native paper i have tried to adjust with styling the badge component  as well as adjusting styling of the views containing the badge however nothing seems to help  it does behave as desired on ios and android simulators ,text not centered within badge component
130,3300313,48877368,Dabeng OrgChart Format Array,"<p>i have Output Like this from data.php, iam use <a href=""https://github.com/dabeng/OrgChart"" rel=""nofollow noreferrer"">https://github.com/dabeng/OrgChart</a></p>

<pre><code>[
{""title"":""306"",""relationship"":""30"",""name"":""HARDWARE &amp; "",""parentid"":""30""},
{""title"":""296"",""relationship"":""476"",""name"":""IT  DOCUMENTATION"",""parentid"":""476""},
{""title"":""596"",""relationship"":""30"",""name"":""MAGANG MIS DEPARTMENT"",""parentid"":""30""},
{""title"":""345"",""relationship"":""30"",""name"":""NETWORK SYSTEM STAFF"",""parentid"":""30""},
{""title"":""184"",""relationship"":""476"",""name"":""PROGRAM ANALYST"",""parentid"":""476""},
{""title"":""46"",""relationship"":""476"",""name"":""PROGRAMMER"",""parentid"":""476""},
{""title"":""476"",""relationship"":""30"",""name"":""SOFTWARE DEVELOPMENT "",""parentid"":""30""},
{""title"":""580"",""relationship"":""30"",""name"":""SYSTEM &amp; NETWORK S"",""parentid"":""30""},
{""title"":""604"",""relationship"":""580"",""name"":""SYSTEM &amp; SECURITY "",""parentid"":""580""},
{""title"":""48"",""relationship"":""306"",""name"":""TECHNICAL SUPPORT"",""parentid"":""306""}
]
</code></pre>

<p>from this ajax</p>

<pre><code>    $('#chart-container').orgchart({
        'data' : 'data.php',
        'nodeContent': 'title',
        'nodeId': 'id',
        'exportButton': true,
        'exportFilename': 'MyOrgChart'
    });
</code></pre>

<p>But This Not Working ? thks</p>

<p><a href=""https://i.stack.imgur.com/DO1id.png"" rel=""nofollow noreferrer"">Yapp This the result </a></p>
",610,3,0,5,php;jquery;mysql;ajax;orgchart,2018-02-20 05:21:32,2018-02-20 05:21:32,2022-07-11 20:43:15,i have output like this from data php  iam use  from this ajax but this not working   thks ,dabeng orgchart format array
131,0,25156880,MODX - Is there some sort of team enviroment or support?,"<p>And colleague and me are going to start a new project for which we want to use MODX. We are both almost new to MODX. </p>

<p>However, we want to use 'proper' team development, that is having own installations on our machines and a commons installation on a server that reflects the current state of development. We work on our specific tasks and pass these changes to the common version only once we the task is done and tested. Versioning should also be available.</p>

<p>Since MODX saves it content into a DB (did I get that right?) using standard versioning software (git, svn, etc.) does not seem so handy? Searching the internet also did not bring up answers yet. </p>

<p>Working on the same DB at the same time does not seem right. Neither does porting the DB changes manually.</p>

<p>How do you do that? Is there some plugins or a standard approach I did not find yet? We also considered using MODX-Cloud. Would that be a solution?</p>

<p>Thanks in advance ...</p>
",158,3,1,5,repository;installation;versioning;modx;modx-revolution,2014-08-06 12:35:18,2014-08-06 12:35:18,2022-07-11 20:00:00,and colleague and me are going to start a new project for which we want to use modx  we are both almost new to modx   however  we want to use  proper  team development  that is having own installations on our machines and a commons installation on a server that reflects the current state of development  we work on our specific tasks and pass these changes to the common version only once we the task is done and tested  versioning should also be available  since modx saves it content into a db  did i get that right   using standard versioning software  git  svn  etc   does not seem so handy  searching the internet also did not bring up answers yet   working on the same db at the same time does not seem right  neither does porting the db changes manually  how do you do that  is there some plugins or a standard approach i did not find yet  we also considered using modx cloud  would that be a solution  thanks in advance    ,modx   is there some sort of team enviroment or support 
132,945871,72931371,Using autotools with a fresh Debian install,"<p>ALL,</p>
<p>I just installed a fresh copy of Debian in order to test my software under this distro.</p>
<p>I installed and configured Git, installed build-essentials package, installed all necessary dependencies and cloned the code.</p>
<p>My main development machine is running Gentoo and my project is using Autotools.</p>
<p>In order to regenerate the configure + makefile I googled and found <a href=""https://thoughtbot.com/blog/the-magic-behind-configure-make-make-install"" rel=""nofollow noreferrer"">this tutorial</a>.</p>
<p>However when I tried to run aclocal, I got <code>Command not found</code>.</p>
<p>I then tried to install <code>autotools-dev</code>, but that didn't fix it - I still receive the same error after running <code>aclocal</code>.</p>
<p>What package do I need to install? Is autotools-dev not enough? Should I even have this package?</p>
<p>I'm not really familiar with Debian distro, so hoping someone will help.</p>
<p>TIA!!</p>
<p>EDIT:</p>
<p>Moreover, the project was made on Gentoo with Anjuta in 2015 and so all those files needs to be regenerated anyway.</p>
",29,0,0,2,debian;autotools,2022-07-10 22:37:36,2022-07-10 22:37:36,2022-07-10 23:25:43,all  i just installed a fresh copy of debian in order to test my software under this distro  i installed and configured git  installed build essentials package  installed all necessary dependencies and cloned the code  my main development machine is running gentoo and my project is using autotools  in order to regenerate the configure   makefile i googled and found   however when i tried to run aclocal  i got command not found  i then tried to install autotools dev  but that didn t fix it   i still receive the same error after running aclocal  what package do i need to install  is autotools dev not enough  should i even have this package  i m not really familiar with debian distro  so hoping someone will help  tia   edit  moreover  the project was made on gentoo with anjuta in  and so all those files needs to be regenerated anyway ,using autotools with a fresh debian install
133,12108441,72848628,Why am I getting 6 high severity vulnerabilities on using create-react-app?,"<blockquote>
<p><strong>This is what I have got!!</strong></p>
</blockquote>
<pre class=""lang-bash prettyprint-override""><code>PS C:\My Files\Software Development\netflix-clone&gt; npx create-react-app ./
npm WARN config global `--global`, `--local` are deprecated. Use `--location=global` instead.

Creating a new React app in C:\My Files\Software Development\netflix-clone.

npm WARN config global `--global`, `--local` are deprecated. Use `--location=global` instead.
Installing packages. This might take a couple of minutes.
Installing react, react-dom, and react-scripts with cra-template...

npm WARN config global `--global`, `--local` are deprecated. Use `--location=global` instead.

added 1392 packages in 11m

194 packages are looking for funding
  run `npm fund` for details

Initialized a git repository.

Installing template dependencies using npm...
npm WARN config global `--global`, `--local` are deprecated. Use `--location=global` instead.
npm WARN deprecated source-map-resolve@0.6.0: See https://github.com/lydell/source-map-resolve#deprecated

added 52 packages in 9s

194 packages are looking for funding
  run `npm fund` for details
Removing template package using npm...

npm WARN config global `--global`, `--local` are deprecated. Use `--location=global` instead.

removed 1 package, and audited 1444 packages in 6s

194 packages are looking for funding
  run `npm fund` for details

6 high severity vulnerabilities

To address all issues (including breaking changes), run:
  npm audit fix --force

Run `npm audit` for details.

Created git commit.

Success! Created netflix-clone at C:\My Files\Software Development\netflix-clone
Inside that directory, you can run several commands:

  npm start
    Starts the development server.

  npm run build
    Bundles the app into static files for production.

  npm test
    Starts the test runner.

  npm run eject
    Removes this tool and copies build dependencies, configuration files
    and scripts into the app directory. If you do this, you can’t go back!

We suggest that you begin by typing:

  cd C:\My Files\Software Development\netflix-clone
  npm start

Happy hacking!
PS C:\My Files\Software Development\netflix-clone&gt;
</code></pre>
<p>This is what <code>npm audit</code> tells!</p>
<pre class=""lang-bash prettyprint-override""><code>PS C:\My Files\Software Development\netflix-clone&gt; npm audit
npm WARN config global `--global`, `--local` are deprecated. Use `--location=global` instead.
# npm audit report

nth-check  &lt;2.0.1
Severity: high
Inefficient Regular Expression Complexity in nth-check - https://github.com/advisories/GHSA-rp65-9cf3-cjxr
fix available via `npm audit fix --force`
Will install react-scripts@2.1.3, which is a breaking change
node_modules/svgo/node_modules/nth-check
  css-select  &lt;=3.1.0
  Depends on vulnerable versions of nth-check
  node_modules/svgo/node_modules/css-select
    svgo  1.0.0 - 1.3.2
    Depends on vulnerable versions of css-select
    node_modules/svgo
      @svgr/plugin-svgo  &lt;=5.5.0
      Depends on vulnerable versions of svgo
      node_modules/@svgr/plugin-svgo
        @svgr/webpack  4.0.0 - 5.5.0
        Depends on vulnerable versions of @svgr/plugin-svgo
        node_modules/@svgr/webpack
          react-scripts  &gt;=2.1.4
          Depends on vulnerable versions of @svgr/webpack
          node_modules/react-scripts

6 high severity vulnerabilities

To address all issues (including breaking changes), run:
  npm audit fix --force
PS C:\My Files\Software Development\netflix-clone&gt;
</code></pre>
<p>Here is what <code>npm audit fix</code> does!</p>
<pre class=""lang-bash prettyprint-override""><code>PS C:\My Files\Software Development\netflix-clone&gt; npm audit fix
npm WARN config global `--global`, `--local` are deprecated. Use `--location=global` instead.

up to date, audited 1444 packages in 6s

194 packages are looking for funding
  run `npm fund` for details

# npm audit report

nth-check  &lt;2.0.1
Severity: high
Inefficient Regular Expression Complexity in nth-check - https://github.com/advisories/GHSA-rp65-9cf3-cjxr
fix available via `npm audit fix --force`
Will install react-scripts@2.1.3, which is a breaking change
node_modules/svgo/node_modules/nth-check
  css-select  &lt;=3.1.0
  Depends on vulnerable versions of nth-check
  node_modules/svgo/node_modules/css-select
    svgo  1.0.0 - 1.3.2
    Depends on vulnerable versions of css-select
    node_modules/svgo
      @svgr/plugin-svgo  &lt;=5.5.0
      Depends on vulnerable versions of svgo
      node_modules/@svgr/plugin-svgo
        @svgr/webpack  4.0.0 - 5.5.0
        Depends on vulnerable versions of @svgr/plugin-svgo
        node_modules/@svgr/webpack
          react-scripts  &gt;=2.1.4
          Depends on vulnerable versions of @svgr/webpack
          node_modules/react-scripts

6 high severity vulnerabilities

To address all issues (including breaking changes), run:
  npm audit fix --force
PS C:\My Files\Software Development\netflix-clone&gt;
</code></pre>
<p>On running <code>npm audit fix --force</code>, i end up getting even more number of vulnerabilities!</p>
<p>Thank You!!</p>
",3054,1,4,2,reactjs;create-react-app,2022-07-03 20:36:32,2022-07-03 20:36:32,2022-07-10 13:00:45,this is what i have got   this is what npm audit tells  here is what npm audit fix does  on running npm audit fix   force  i end up getting even more number of vulnerabilities  thank you  ,why am i getting  high severity vulnerabilities on using create react app 
134,17644242,72921799,python3 manage.py makemigrations not working,"<p>I can successfully run git clone 'my repository'</p>
<p>I can run 'pip3 install -r requirements.txt'; from the correct directory 'server'</p>
<p>When I run the command 'python3 manage.py makemigrations'; nothing happens.</p>
<p>When I run 'python3 -m pip show django', I get the following:</p>
<p>Name: Django
Version: 3.2.14
Summary: A high-level Python Web framework that encourages rapid development and clean, pragmatic design.
Home-page: <a href=""https://www.djangoproject.com/"" rel=""nofollow noreferrer"">https://www.djangoproject.com/</a>
Author: Django Software Foundation
Author-email: foundation@djangoproject.com
License: BSD-3-Clause
Location: /home/theia/.local/lib/python3.6/site-packages
Requires: asgiref, pytz, sqlparse
Required-by:</p>
<p><strong>My requirements.txt file:</strong></p>
<pre><code>\\\
requests
Django
# changed to 20.1.0 to get rid of error
gunicorn==20.1.0
Pillow==8.0.1
ibm-cloud-sdk-core==3.10.0
ibm-watson==5.2.2
ibmcloudant==0.0.34
\\\
</code></pre>
<p><strong>my manage.py file:</strong></p>
<pre><code>\\\
#!/usr/bin/env python
&quot;&quot;&quot;Django's command-line utility for administrative tasks.&quot;&quot;&quot;
import os
import sys


def main():
    &quot;&quot;&quot;Run administrative tasks.&quot;&quot;&quot;
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'djangobackend.settings')
    try:
        from django.core.management import execute_from_command_line
    except ImportError as exc:
        raise ImportError(
            &quot;Couldn't import Django. Are you sure it's installed and &quot;
            &quot;available on your PYTHONPATH environment variable? Did you &quot;
            &quot;forget to activate a virtual environment?&quot;
        ) from exc
    execute_from_command_line(sys.argv)


    if __name__ == '__main__':
         main()
\\\
</code></pre>
<p>If I run <strong>'python manage.py makemigrations'</strong>, I get the following error:</p>
<p>File &quot;manage.py&quot;, line 17
) from exc
^
SyntaxError: invalid syntax</p>
<p>If I run 'python3 manage.py makemigrations', nothing happens.</p>
<p>My version of python is 2.7.17</p>
<p>I am working in a virtual lab through Skills Network Labs as part of the Coursera Full Stack Course (Theia; the lab is deleted at sign off), 'I run the command ps -ef | grep runserver', and get this:</p>
<p>theia       2018     279  0 13:22 pts/0    00:00:00 grep --color=auto runserver</p>
<p>so I don't think 'killing' the server would work.</p>
<p>INSTALLED_APPS is present in my settings.py folder.</p>
<p>I only have the single project running.</p>
<p>Ideas? I'm kind of new, so if you say, add such and such, can you be specific? same for command; thank you.</p>
",27,0,0,3,python-3.x;manage.py;makemigrations,2022-07-09 16:35:13,2022-07-09 16:35:13,2022-07-09 16:35:13,i can successfully run git clone  my repository  i can run  pip install  r requirements txt   from the correct directory  server  when i run the command  python manage py makemigrations   nothing happens  when i run  python  m pip show django   i get the following  my requirements txt file  my manage py file  if i run  python manage py makemigrations   i get the following error  if i run  python manage py makemigrations   nothing happens  my version of python is    i am working in a virtual lab through skills network labs as part of the coursera full stack course  theia  the lab is deleted at sign off    i run the command ps  ef   grep runserver   and get this  theia                 pts        grep   color auto runserver so i don t think  killing  the server would work  installed_apps is present in my settings py folder  i only have the single project running  ideas  i m kind of new  so if you say  add such and such  can you be specific  same for command  thank you ,python manage py makemigrations not working
135,19515991,72921221,Software modeling methodology for component-based development,"<p>for my studies I am supposed to evaluate a software modeling methodology for component-based development. The only requirements I have are that UML should be used and that the specification functional views should be described using OCL.</p>
<p>Are there any methodologies that are particularly suitable here? I am currently a bit overwhelmed by the possible methodologies and have not yet been able to find a suitable one. I hope you can help me. Thanks alot in advance!</p>
",30,0,0,3,components;modeling;ocl,2022-07-09 15:05:23,2022-07-09 15:05:23,2022-07-09 15:05:23,for my studies i am supposed to evaluate a software modeling methodology for component based development  the only requirements i have are that uml should be used and that the specification functional views should be described using ocl  are there any methodologies that are particularly suitable here  i am currently a bit overwhelmed by the possible methodologies and have not yet been able to find a suitable one  i hope you can help me  thanks alot in advance ,software modeling methodology for component based development
136,799921,72914024,vscode not starting debugger (flask),"<p>This is new behavior, but I don't know what I changed (if anything), although I'm not sure what the Date below indicates as I didn't take any action to update vscode.</p>
<p>I've been using vscode just fine to debug my flask applications for over a year. Today when I tried to start a new debug session, nothing happens. This means there's no flask process set in the Run and Debug window, and no Python debug terminal started.</p>
<p>The Date might be consistent with when things stopped working for me, though, as I was trying to start debugging with a different repo than I'd been working with.</p>
<p>UPDATE: downgrade to 1.68.1 did not resolve the problem.</p>
<pre><code>Version: 1.69.0 (user setup)
Commit: 92d25e35d9bf1a6b16f7d0758f25d48ace11e5b9
Date: 2022-07-07T05:28:36.503Z
Electron: 18.3.5
Chromium: 100.0.4896.160
Node.js: 16.13.2
V8: 10.0.139.17-electron.0
OS: Windows_NT x64 10.0.19043
</code></pre>
<p>I looked at <a href=""https://github.com/microsoft/vscode/wiki/Terminal-Issues#creating-great-terminal-issues"" rel=""nofollow noreferrer"">https://github.com/microsoft/vscode/wiki/Terminal-Issues#creating-great-terminal-issues</a> and started tracing using <code>code --log trace</code>. I think this is the relevant trace logs.</p>
<pre><code>[2022-07-08 11:49:18.223] [renderer1] [trace] CommandService#executeCommand workbench.action.debug.start
[2022-07-08 11:49:18.262] [renderer1] [trace] Error while resolving configuration file 'vscode-userdata:/c%3A/Users/lking/AppData/Roaming/Code/User/tasks.json': Unable to read file 'vscode-userdata:/c:/Users/lking/AppData/Roaming/Code/User/tasks.json' (Error: Unable to resolve nonexistent file 'vscode-userdata:/c:/Users/lking/AppData/Roaming/Code/User/tasks.json')
[2022-07-08 11:49:18.273] [renderer1] [trace] Error while resolving configuration file 'file:///c%3A/Users/lking/Documents/Lou%27s%20Software/projects/rrwebapp/rrwebapp/.vscode/tasks.json': Unable to read file 'c:\Users\lking\Documents\Lou's Software\projects\rrwebapp\rrwebapp\.vscode\tasks.json' (Error: Unable to resolve nonexistent file 'c:\Users\lking\Documents\Lou's Software\projects\rrwebapp\rrwebapp\.vscode\tasks.json')
[2022-07-08 11:49:18.373] [renderer1] [trace] onWillActivateByEvent:  onDebugResolve
[2022-07-08 11:49:18.373] [renderer1] [trace] onWillActivateByEvent:  onDebugResolve:python
[2022-07-08 11:49:18.696] [renderer1] [trace] [History stack global-default]: notifyNavigation() (editor: log:rendererLog, event: edit)
[2022-07-08 11:49:18.697] [renderer1] [trace] [History stack global-default]: notifyNavigation() not ignoring (editor: log:rendererLog, event: edit)
[2022-07-08 11:49:18.697] [renderer1] [trace] [History stack global-default]: onSelectionAwareEditorNavigation() (editor: log:rendererLog, event: edit)
[2022-07-08 11:49:18.697] [renderer1] [trace] [History stack global-default]: replace() (editor: log:rendererLog, event: &lt;none&gt;)
[2022-07-08 11:49:18.698] [renderer1] [trace] [History stack global-default]: index: 1, navigating: false
- group: 0, editor: file:///c%3A/Users/lking/Documents/Lou%27s%20Software/projects/rrwebapp/rrwebapp/.vscode/launch.json, selection: line: 28-28, col:  22-22
- group: 0, editor: log:rendererLog, selection: line: 1-1, col:  1-1
</code></pre>
<p>I've confirmed <code>tasks.json</code> doesn't exist in either folder, but checking crashplan (my backup system) I don't think this has existed, at least not recently.</p>
<p>I hope someone has some ideas, as I'm stymied.</p>
<p>launch.json:</p>
<pre><code>{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    &quot;version&quot;: &quot;0.2.0&quot;,
    &quot;configurations&quot;: [
        {
            &quot;name&quot;: &quot;Python: Flask&quot;,
            &quot;type&quot;: &quot;python&quot;,
            &quot;request&quot;: &quot;launch&quot;,
            &quot;module&quot;: &quot;flask&quot;,
            &quot;justMyCode&quot;: false,
            &quot;env&quot;: {
                &quot;FLASK_APP&quot;: &quot;run.py&quot;,
                // normally development, production for test of applogging
                &quot;FLASK_ENV&quot;: &quot;development&quot;
            },
            &quot;args&quot;: [
                &quot;run&quot;,
                &quot;--no-debugger&quot;
            ],
            &quot;jinja&quot;: true,
            // &quot;cwd&quot;: &quot;${workspaceFolder}/..&quot;
        },
        {
            &quot;name&quot;: &quot;Launch Chrome&quot;,
            &quot;request&quot;: &quot;launch&quot;,
            &quot;type&quot;: &quot;chrome&quot;,
            &quot;url&quot;: &quot;http://dev.localhost:5000&quot;,
            // &quot;webRoot&quot;: &quot;${workspaceFolder}&quot;
            &quot;webRoot&quot;: &quot;${workspaceFolder}/rrwebapp&quot;
        },
        {
            &quot;name&quot;: &quot;Python: Current File&quot;,
            &quot;type&quot;: &quot;python&quot;,
            &quot;request&quot;: &quot;launch&quot;,
            &quot;program&quot;: &quot;${file}&quot;,
            &quot;console&quot;: &quot;integratedTerminal&quot;,
            &quot;justMyCode&quot;: false,
        },
        {
            &quot;name&quot;: &quot;Python: Celery&quot;,
            &quot;type&quot;: &quot;python&quot;,
            &quot;request&quot;: &quot;launch&quot;,
            &quot;module&quot;: &quot;celery&quot;,
            &quot;console&quot;: &quot;integratedTerminal&quot;,
            &quot;env&quot;: {
                // https://github.com/celery/celery/issues/4081#issuecomment-349535810
                &quot;FORKED_BY_MULTIPROCESSING&quot;: &quot;1&quot;
            },
            &quot;args&quot;: [
                &quot;-A&quot;,
                &quot;rrwebapp.celery&quot;,
                &quot;worker&quot;,
                &quot;-c2&quot;,
                &quot;-l&quot;,
                &quot;info&quot;,
                &quot;-n&quot;,
                &quot;celery@localhost&quot;,
                // may not be needed, see https://stackoverflow.com/a/54488640/799921 and https://github.com/Microsoft/ptvsd/issues/1046
                // &quot;-P&quot;,
                // &quot;solo&quot;,
            ]
        },
        {
            &quot;name&quot;: &quot;Python: Celery longtask (results analysis)&quot;,
            &quot;type&quot;: &quot;python&quot;,
            &quot;request&quot;: &quot;launch&quot;,
            &quot;module&quot;: &quot;celery&quot;,
            &quot;console&quot;: &quot;integratedTerminal&quot;,
            &quot;env&quot;: {
                // https://github.com/celery/celery/issues/4081#issuecomment-349535810
                &quot;FORKED_BY_MULTIPROCESSING&quot;: &quot;1&quot;
            },
            &quot;args&quot;: [
                &quot;-A&quot;,
                &quot;rrwebapp.celery&quot;,
                &quot;worker&quot;,
                &quot;-c2&quot;,
                &quot;-l&quot;,
                &quot;info&quot;,
                &quot;-Q&quot;,
                &quot;longtask&quot;,
                &quot;-n&quot;,
                &quot;celerylongtask@localhost&quot;,
                // may not be needed, see https://stackoverflow.com/a/54488640/799921 and https://github.com/Microsoft/ptvsd/issues/1046
                // &quot;-P&quot;,
                // &quot;solo&quot;,
            ]
        },
    ]
}
</code></pre>
",26,1,0,1,vscode-debugger,2022-07-08 18:56:58,2022-07-08 18:56:58,2022-07-08 22:23:06,this is new behavior  but i don t know what i changed  if anything   although i m not sure what the date below indicates as i didn t take any action to update vscode  i ve been using vscode just fine to debug my flask applications for over a year  today when i tried to start a new debug session  nothing happens  this means there s no flask process set in the run and debug window  and no python debug terminal started  the date might be consistent with when things stopped working for me  though  as i was trying to start debugging with a different repo than i d been working with  update  downgrade to    did not resolve the problem  i looked at  and started tracing using code   log trace  i think this is the relevant trace logs  i ve confirmed tasks json doesn t exist in either folder  but checking crashplan  my backup system  i don t think this has existed  at least not recently  i hope someone has some ideas  as i m stymied  launch json ,vscode not starting debugger  flask 
137,339736,3514398,Android java.net.UnknownHostException: Host is unresolved,"<p>This code doesn't work:</p>

<pre><code>URL         url   = new URL( xmlPath );
InputSource input = new InputSource( url.openStream() );
</code></pre>

<p>all the time, resulting in an UnknownHostException, even when the host exists, has been hit successfully using the same code if from a different development host (machine), and also from a browser.</p>

<p>I'm probably out of line asking this question again, a repeat of <a href=""https://stackoverflow.com/questions/3293659/android-java-net-unknownhostexception-host-is-unresolved-strategy-question"">Android java.net.UnknownHostException: Host is unresolved (strategy question)</a>. The forum software would not allow me to comment on the unsatisfactory answer to that question (in order to solicit more attention to the solution I ultimately found). Perhaps I'm not popular enough yet to be given that privilege. In the meantime, I'm essentially re-posting the question and a different answer.</p>

<p>Basically, I accept that maybe the Android device has a hard time with DNS under certain circumstances, but I've tried, for example the anddev.org example of how to use the SAX parser, and it worked on one machine I have and not on another.</p>

<p>Edit:
As noted, I know a working answer and will post it.</p>

<p>I am a) asking a question (that's already been asked and unsuccessfully answered) and b) answering it for the benefit of those for whom my answer will be useful.</p>
",77158,18,51,1,android,2010-08-18 19:36:57,2010-08-18 19:36:57,2022-07-08 21:52:03,this code doesn t work  all the time  resulting in an unknownhostexception  even when the host exists  has been hit successfully using the same code if from a different development host  machine   and also from a browser  i m probably out of line asking this question again  a repeat of   the forum software would not allow me to comment on the unsatisfactory answer to that question  in order to solicit more attention to the solution i ultimately found   perhaps i m not popular enough yet to be given that privilege  in the meantime  i m essentially re posting the question and a different answer  basically  i accept that maybe the android device has a hard time with dns under certain circumstances  but i ve tried  for example the anddev org example of how to use the sax parser  and it worked on one machine i have and not on another  i am a  asking a question  that s already been asked and unsuccessfully answered  and b  answering it for the benefit of those for whom my answer will be useful ,android java net unknownhostexception  host is unresolved
138,1854369,72833853,Oculus Developer Hub hangs on &quot;Installing...&quot; for everything under the Downloads category,"<p>Prior to today, everything was working fine and I was able to deploy from Unity to specifically an APK. I wasn't able to operate in &quot;Play&quot; mode so I tried updating the Oculus Platform SDK, which proceeded to hang in &quot;Installing...&quot; forever, leading to my current predicament.</p>
<p>What happens:</p>
<ol>
<li><p>I hit &quot;download&quot; on anything inside the Downloads section of the Oculus Developer Hub</p>
</li>
<li><p>It hangs saying &quot;Installing...&quot; for hours and does nothing.</p>
</li>
</ol>
<p>Also, when I try to change my ADB Path in Oculus Developer Hub, it &quot;fails&quot; and asks me to try again, but the new value is present every time.</p>
<p>I've tried installing/uninstalling both ODH and Oculus software. I've tried changing the ADB path. I've tried installing and adding JRE and NDK to the path. I'm running out of options here. Does anyone have any advice? This is blocking me from doing development work in Unity.</p>
",145,1,1,3,virtual-reality;oculus;oculusquest,2022-07-01 22:28:10,2022-07-01 22:28:10,2022-07-08 17:40:36,prior to today  everything was working fine and i was able to deploy from unity to specifically an apk  i wasn t able to operate in  play  mode so i tried updating the oculus platform sdk  which proceeded to hang in  installing     forever  leading to my current predicament  what happens  i hit  download  on anything inside the downloads section of the oculus developer hub it hangs saying  installing     for hours and does nothing  also  when i try to change my adb path in oculus developer hub  it  fails  and asks me to try again  but the new value is present every time  i ve tried installing uninstalling both odh and oculus software  i ve tried changing the adb path  i ve tried installing and adding jre and ndk to the path  i m running out of options here  does anyone have any advice  this is blocking me from doing development work in unity ,oculus developer hub hangs on  installing     for everything under the downloads category
139,19313861,72885344,How to parse json file in flutter?,"<p>Below is the json I have to parse.</p>
<pre><code>[
  &quot;http://activepeersai.computing.dcu.ie/feedback_participant/114&quot;,
  &quot;http://activepeersai.computing.dcu.ie/peerLearningPrompter/4&quot;,
  &quot;{\&quot;0\&quot;:{\&quot;feedback_id\&quot;:114,\&quot;timer_used\&quot;:1,\&quot;timer\&quot;:10.0,\&quot;question1\&quot;:\&quot;How to break ice with strangers (in social gathering &amp; in formal events) ?\&quot;,\&quot;question2\&quot;:\&quot;How to build networking (with those from different age, culture, education background, language\\u2026)(in university &amp; in workplace) ?\&quot;,\&quot;question3\&quot;:\&quot;\&quot;,\&quot;question4\&quot;:\&quot;\&quot;,\&quot;question5\&quot;:\&quot;\&quot;,\&quot;question6\&quot;:\&quot;\&quot;,\&quot;question7\&quot;:\&quot;\&quot;,\&quot;question8\&quot;:\&quot;\&quot;,\&quot;question9\&quot;:\&quot;\&quot;,\&quot;question10\&quot;:\&quot;\&quot;},\&quot;1\&quot;:{\&quot;feedback_id\&quot;:115,\&quot;timer_used\&quot;:1,\&quot;timer\&quot;:10.0,\&quot;question1\&quot;:\&quot;How to deal with difficult teammates (dominating \\/ debater character \\/ negative \\/ lack of confidence \\/ free rider\\u2026) ?\&quot;,\&quot;question2\&quot;:\&quot;How to build mutual trust with teammates ?\&quot;,\&quot;question3\&quot;:\&quot;\&quot;,\&quot;question4\&quot;:\&quot;\&quot;,\&quot;question5\&quot;:\&quot;\&quot;,\&quot;question6\&quot;:\&quot;\&quot;,\&quot;question7\&quot;:\&quot;\&quot;,\&quot;question8\&quot;:\&quot;\&quot;,\&quot;question9\&quot;:\&quot;\&quot;,\&quot;question10\&quot;:\&quot;\&quot;}}&quot;,
  &quot;{\&quot;id\&quot;:{\&quot;0\&quot;:1,\&quot;1\&quot;:2,\&quot;2\&quot;:3,\&quot;3\&quot;:4,\&quot;4\&quot;:5,\&quot;5\&quot;:6,\&quot;6\&quot;:7,\&quot;7\&quot;:8,\&quot;8\&quot;:9,\&quot;9\&quot;:10,\&quot;10\&quot;:11,\&quot;11\&quot;:12,\&quot;12\&quot;:13,\&quot;13\&quot;:14,\&quot;14\&quot;:15,\&quot;15\&quot;:16,\&quot;16\&quot;:17,\&quot;17\&quot;:18,\&quot;18\&quot;:19,\&quot;19\&quot;:20,\&quot;20\&quot;:21,\&quot;21\&quot;:22,\&quot;22\&quot;:23,\&quot;23\&quot;:24,\&quot;24\&quot;:25,\&quot;25\&quot;:26,\&quot;26\&quot;:27,\&quot;27\&quot;:28,\&quot;28\&quot;:29,\&quot;29\&quot;:30,\&quot;30\&quot;:31,\&quot;31\&quot;:32,\&quot;32\&quot;:33,\&quot;33\&quot;:34,\&quot;34\&quot;:35,\&quot;35\&quot;:40,\&quot;36\&quot;:41,\&quot;37\&quot;:42,\&quot;38\&quot;:43,\&quot;39\&quot;:44,\&quot;40\&quot;:45,\&quot;41\&quot;:46,\&quot;42\&quot;:47,\&quot;43\&quot;:48,\&quot;44\&quot;:49,\&quot;45\&quot;:50,\&quot;46\&quot;:51,\&quot;47\&quot;:52,\&quot;48\&quot;:53,\&quot;49\&quot;:54,\&quot;50\&quot;:55,\&quot;51\&quot;:56,\&quot;52\&quot;:57,\&quot;53\&quot;:58,\&quot;54\&quot;:59,\&quot;55\&quot;:60,\&quot;56\&quot;:61,\&quot;57\&quot;:62,\&quot;58\&quot;:63,\&quot;59\&quot;:36,\&quot;60\&quot;:37,\&quot;61\&quot;:38,\&quot;62\&quot;:39},\&quot;name\&quot;:{\&quot;0\&quot;:\&quot;Why did the sharer choose this skill as the most confident skill and why did the learner wants to improve this skill?\&quot;,\&quot;1\&quot;:\&quot;Can you share another situation whereby using this skill made a very big difference to the outcome? What did you do? What was the result? What might have happened if this skill wasn't brought to the situation?\&quot;,\&quot;2\&quot;:\&quot;What advice do you have to give to others about becoming better at using this skill in their work and in their lives generally?\&quot;,\&quot;3\&quot;:\&quot;What can hold people back from being better at this skill? How can you encourage them to overcome these challenges?\&quot;,\&quot;4\&quot;:\&quot;What would be the outcome if this session\\/series was a huge success? How would we know if this happened?\&quot;,\&quot;5\&quot;:\&quot;What is working for you now? What is stopping you from moving forward?\&quot;,\&quot;6\&quot;:\&quot;What do your role models do that you would love to learn\\/incorporate as habits\\/adopt as a mindset?\&quot;,\&quot;7\&quot;:\&quot;\\\&quot;What got you here won't get you there.\\\&quot; What is your reaction to that statement? What actions have got you to this point that may not serve you if you move forward? What new behaviours do you need to adopt?\&quot;,\&quot;8\&quot;:\&quot;What would be the outcome if this session\\/series was a huge success? How would we know if this happened?\&quot;,\&quot;9\&quot;:\&quot;If you had all the time, people, money, resources that you might possibly need, what would you do differently? Does that energise you, frighten you or a bit of both?\&quot;,\&quot;10\&quot;:\&quot;What do you think you need to do get a better result (or closer to your goal)?\&quot;,\&quot;11\&quot;:\&quot;What is the worst that could happen and how could you handle it? What is the best that could happen and how could you handle it?\&quot;,\&quot;12\&quot;:\&quot;What have been the most impactful decisions that you've made in your career? What led to making those decisions? Were you aware of the impact those decisions would have? What would you say to others in a similar position?\&quot;,\&quot;13\&quot;:\&quot;What habits have stood you in good stead? Are there things that you do regularly, daily or very often that have made a big different over time?\&quot;,\&quot;14\&quot;:\&quot;Can you share an experience that was transformational for you, taught you a long-lasting lesson or was particularly memorable for its benefits and challenges?\&quot;,\&quot;15\&quot;:\&quot;How do you think experience affects somebody's perspective, way of making decisions or their feelings about taking risks?\&quot;,\&quot;16\&quot;:\&quot;Can you describe your target market for your business or who might your ideal employer be?\&quot;,\&quot;17\&quot;:\&quot;Can you share details of a project that you worked on recently? Why were you or your business chosen to work with this client\\/employer? What were the success and challenges along the way?\&quot;,\&quot;18\&quot;:\&quot;What makes you\\/your product\\/your service different to others? Why would a client or employer choose what you do over others?\&quot;,\&quot;19\&quot;:\&quot;What might I be able to do to help you?\&quot;,\&quot;20\&quot;:\&quot;What is the key problem that you are facing currently?\&quot;,\&quot;21\&quot;:\&quot;If that problem was solved, what impact would it have?\&quot;,\&quot;22\&quot;:\&quot;In order to get to that outcome, what do we need to do, what resources need to be invested and any other changes to be made?\&quot;,\&quot;23\&quot;:\&quot;Is there a willingness to take that action to get towards that outcome?\&quot;,\&quot;24\&quot;:\&quot;What assumptions are being made? How likely are each one to happen? What would be the impact of those assumptions happening or not happening?\&quot;,\&quot;25\&quot;:\&quot;What application of the SCAMPER technique could be useful to help get another perspective?\\n*SCAMPER is an acronym formed from the abbreviation of: Substitute, Combine, Adapt, Modify (Also magnify and minify), Put to another use, Eliminate and Reverse.\&quot;,\&quot;26\&quot;:\&quot;If we had double the budget, half the time and were living in another country trying to make this happen, how might we think differently?\&quot;,\&quot;27\&quot;:\&quot;If any idea generated already in this discussion was to become a reality, what would be the impact on e year later in terms of benefits, ongoing coasts, sustained behavioural change and a launchpad for further growth?\&quot;,\&quot;28\&quot;:\&quot;Leadership\&quot;,\&quot;29\&quot;:\&quot;Communication\&quot;,\&quot;30\&quot;:\&quot;Adaptability\&quot;,\&quot;31\&quot;:\&quot;Team Work\&quot;,\&quot;32\&quot;:\&quot;Problem Solving\&quot;,\&quot;33\&quot;:\&quot;Conflict Management\&quot;,\&quot;34\&quot;:\&quot;Productivity\&quot;,\&quot;35\&quot;:\&quot;How would you describe good\\/effective communication? Please share an example of a time that you've seen it in action and an example of when you saw that good communication skills were clearly lacking.\&quot;,\&quot;36\&quot;:\&quot;How have you handled working under someone you felt was not good at communicating?\&quot;,\&quot;37\&quot;:\&quot;If you're trying to get your point across or convince somebody that your idea is the right one, what do you do?\&quot;,\&quot;38\&quot;:\&quot;Who do you think is a good communicator and why? What can we learn from them?\&quot;,\&quot;39\&quot;:\&quot;Talk about a time that you needed to adapt to a new situation. What did you find difficult and how did you work through that? How can somebody prepare to be more adaptable in future situations?\&quot;,\&quot;40\&quot;:\&quot;When you're in a situation where it feels like you have no control over it (i.e. a new manager, starting in a new job, government-led changes etc), what do you do to focus on what you can do?\&quot;,\&quot;41\&quot;:\&quot;How do you handle having multiple priorities at the same time?\&quot;,\&quot;42\&quot;:\&quot;How do you adjust to different work settings? For example, working with different teams, switching between logic and creativity, learning new processes, tools or technologies?\&quot;,\&quot;43\&quot;:\&quot;How do you feel about working in a team? What do you think are the key things that need to happen to make good teamwork?\&quot;,\&quot;44\&quot;:\&quot;What has been your experience of working in teams where there were problems? Did these arise due to strong personalities, somebody not sharing the workload, miscommunication, the wrong support or technology systems etc?\&quot;,\&quot;45\&quot;:\&quot;How do you keep a team motivated? Share your story about a rewarding team experience.\&quot;,\&quot;46\&quot;:\&quot;When you're in a team situation, what role do you usually play?\&quot;,\&quot;47\&quot;:\&quot;Describe a situation where you had to solve a problem. What did you do? what was the result? What might you have done differently?\&quot;,\&quot;48\&quot;:\&quot;What steps do you take before making a decision on how to solve a problem, and why?\&quot;,\&quot;49\&quot;:\&quot;Give an example of a situation in which you saw an opportunity in a potential problem. What did you do? What was the outcome?\&quot;,\&quot;50\&quot;:\&quot;Can you tell me about a situation where you overcame a problem using a creative solution?\&quot;,\&quot;51\&quot;:\&quot;Have you ever had a team member who kept raising objections on projects? How did you (or would you) manage them?\&quot;,\&quot;52\&quot;:\&quot;You have noticed that a team member is aggressive or arrogant toward the rest of the team. How would you approach this person?\&quot;,\&quot;53\&quot;:\&quot;What would you do if your manager gave you negative feedback on the way you approached a problem? How do give negative\\/constructive feedback to others?\&quot;,\&quot;54\&quot;:\&quot;How could you use a situation with conflict to have a better relationship with all involved?\&quot;,\&quot;55\&quot;:\&quot;How would you describe a typical working day in your current role? How you manage importance versus urgency? How do you maintain a work-life balance also?\&quot;,\&quot;56\&quot;:\&quot;If you have your day planned out to achieve a goal, how do you manage distractions or other things that can happen along the way?\&quot;,\&quot;57\&quot;:\&quot;What do you think very productive people do differently than others?\&quot;,\&quot;58\&quot;:\&quot;What holds people back from being more productive? How can people turn those around so that by doing the opposite, they can become more productive?\&quot;,\&quot;59\&quot;:\&quot;Have you ever had a team member who kept raising objections on projects? How did you (or would you) manage them?\&quot;,\&quot;60\&quot;:\&quot;How do you describe your leadership style?\&quot;,\&quot;61\&quot;:\&quot;What was a difficult decision you had to make as a leader, and how did you come to that decision?\&quot;,\&quot;62\&quot;:\&quot;What are the most important attributes of successful leaders today? Who do you think is a good leader and why?\&quot;},\&quot;session_type_id\&quot;:{\&quot;0\&quot;:1.0,\&quot;1\&quot;:1.0,\&quot;2\&quot;:1.0,\&quot;3\&quot;:1.0,\&quot;4\&quot;:2.0,\&quot;5\&quot;:2.0,\&quot;6\&quot;:2.0,\&quot;7\&quot;:2.0,\&quot;8\&quot;:3.0,\&quot;9\&quot;:3.0,\&quot;10\&quot;:3.0,\&quot;11\&quot;:3.0,\&quot;12\&quot;:4.0,\&quot;13\&quot;:4.0,\&quot;14\&quot;:4.0,\&quot;15\&quot;:4.0,\&quot;16\&quot;:5.0,\&quot;17\&quot;:5.0,\&quot;18\&quot;:5.0,\&quot;19\&quot;:5.0,\&quot;20\&quot;:6.0,\&quot;21\&quot;:6.0,\&quot;22\&quot;:6.0,\&quot;23\&quot;:6.0,\&quot;24\&quot;:7.0,\&quot;25\&quot;:7.0,\&quot;26\&quot;:7.0,\&quot;27\&quot;:7.0,\&quot;28\&quot;:8.0,\&quot;29\&quot;:8.0,\&quot;30\&quot;:8.0,\&quot;31\&quot;:8.0,\&quot;32\&quot;:8.0,\&quot;33\&quot;:8.0,\&quot;34\&quot;:8.0,\&quot;35\&quot;:null,\&quot;36\&quot;:null,\&quot;37\&quot;:null,\&quot;38\&quot;:null,\&quot;39\&quot;:null,\&quot;40\&quot;:null,\&quot;41\&quot;:null,\&quot;42\&quot;:null,\&quot;43\&quot;:null,\&quot;44\&quot;:null,\&quot;45\&quot;:null,\&quot;46\&quot;:null,\&quot;47\&quot;:null,\&quot;48\&quot;:null,\&quot;49\&quot;:null,\&quot;50\&quot;:null,\&quot;51\&quot;:null,\&quot;52\&quot;:null,\&quot;53\&quot;:null,\&quot;54\&quot;:null,\&quot;55\&quot;:null,\&quot;56\&quot;:null,\&quot;57\&quot;:null,\&quot;58\&quot;:null,\&quot;59\&quot;:null,\&quot;60\&quot;:null,\&quot;61\&quot;:null,\&quot;62\&quot;:null},\&quot;session_type_name\&quot;:{\&quot;0\&quot;:\&quot;Learning and Development\&quot;,\&quot;1\&quot;:\&quot;Learning and Development\&quot;,\&quot;2\&quot;:\&quot;Learning and Development\&quot;,\&quot;3\&quot;:\&quot;Learning and Development\&quot;,\&quot;4\&quot;:\&quot;Mentoring\&quot;,\&quot;5\&quot;:\&quot;Mentoring\&quot;,\&quot;6\&quot;:\&quot;Mentoring\&quot;,\&quot;7\&quot;:\&quot;Mentoring\&quot;,\&quot;8\&quot;:\&quot;Coaching\&quot;,\&quot;9\&quot;:\&quot;Coaching\&quot;,\&quot;10\&quot;:\&quot;Coaching\&quot;,\&quot;11\&quot;:\&quot;Coaching\&quot;,\&quot;12\&quot;:\&quot;Experience Sharing\&quot;,\&quot;13\&quot;:\&quot;Experience Sharing\&quot;,\&quot;14\&quot;:\&quot;Experience Sharing\&quot;,\&quot;15\&quot;:\&quot;Experience Sharing\&quot;,\&quot;16\&quot;:\&quot;Networking\&quot;,\&quot;17\&quot;:\&quot;Networking\&quot;,\&quot;18\&quot;:\&quot;Networking\&quot;,\&quot;19\&quot;:\&quot;Networking\&quot;,\&quot;20\&quot;:\&quot;Establishing Buy-In\&quot;,\&quot;21\&quot;:\&quot;Establishing Buy-In\&quot;,\&quot;22\&quot;:\&quot;Establishing Buy-In\&quot;,\&quot;23\&quot;:\&quot;Establishing Buy-In\&quot;,\&quot;24\&quot;:\&quot;Idea Exploration\&quot;,\&quot;25\&quot;:\&quot;Idea Exploration\&quot;,\&quot;26\&quot;:\&quot;Idea Exploration\&quot;,\&quot;27\&quot;:\&quot;Idea Exploration\&quot;,\&quot;28\&quot;:\&quot;Seven Soft Skills\&quot;,\&quot;29\&quot;:\&quot;Seven Soft Skills\&quot;,\&quot;30\&quot;:\&quot;Seven Soft Skills\&quot;,\&quot;31\&quot;:\&quot;Seven Soft Skills\&quot;,\&quot;32\&quot;:\&quot;Seven Soft Skills\&quot;,\&quot;33\&quot;:\&quot;Seven Soft Skills\&quot;,\&quot;34\&quot;:\&quot;Seven Soft Skills\&quot;,\&quot;35\&quot;:null,\&quot;36\&quot;:null,\&quot;37\&quot;:null,\&quot;38\&quot;:null,\&quot;39\&quot;:null,\&quot;40\&quot;:null,\&quot;41\&quot;:null,\&quot;42\&quot;:null,\&quot;43\&quot;:null,\&quot;44\&quot;:null,\&quot;45\&quot;:null,\&quot;46\&quot;:null,\&quot;47\&quot;:null,\&quot;48\&quot;:null,\&quot;49\&quot;:null,\&quot;50\&quot;:null,\&quot;51\&quot;:null,\&quot;52\&quot;:null,\&quot;53\&quot;:null,\&quot;54\&quot;:null,\&quot;55\&quot;:null,\&quot;56\&quot;:null,\&quot;57\&quot;:null,\&quot;58\&quot;:null,\&quot;59\&quot;:null,\&quot;60\&quot;:null,\&quot;61\&quot;:null,\&quot;62\&quot;:null},\&quot;parent_id\&quot;:{\&quot;0\&quot;:null,\&quot;1\&quot;:null,\&quot;2\&quot;:null,\&quot;3\&quot;:null,\&quot;4\&quot;:null,\&quot;5\&quot;:null,\&quot;6\&quot;:null,\&quot;7\&quot;:null,\&quot;8\&quot;:null,\&quot;9\&quot;:null,\&quot;10\&quot;:null,\&quot;11\&quot;:null,\&quot;12\&quot;:null,\&quot;13\&quot;:null,\&quot;14\&quot;:null,\&quot;15\&quot;:null,\&quot;16\&quot;:null,\&quot;17\&quot;:null,\&quot;18\&quot;:null,\&quot;19\&quot;:null,\&quot;20\&quot;:null,\&quot;21\&quot;:null,\&quot;22\&quot;:null,\&quot;23\&quot;:null,\&quot;24\&quot;:null,\&quot;25\&quot;:null,\&quot;26\&quot;:null,\&quot;27\&quot;:null,\&quot;28\&quot;:null,\&quot;29\&quot;:null,\&quot;30\&quot;:null,\&quot;31\&quot;:null,\&quot;32\&quot;:null,\&quot;33\&quot;:null,\&quot;34\&quot;:null,\&quot;35\&quot;:30.0,\&quot;36\&quot;:30.0,\&quot;37\&quot;:30.0,\&quot;38\&quot;:30.0,\&quot;39\&quot;:31.0,\&quot;40\&quot;:31.0,\&quot;41\&quot;:31.0,\&quot;42\&quot;:31.0,\&quot;43\&quot;:32.0,\&quot;44\&quot;:32.0,\&quot;45\&quot;:32.0,\&quot;46\&quot;:32.0,\&quot;47\&quot;:33.0,\&quot;48\&quot;:33.0,\&quot;49\&quot;:33.0,\&quot;50\&quot;:33.0,\&quot;51\&quot;:34.0,\&quot;52\&quot;:34.0,\&quot;53\&quot;:34.0,\&quot;54\&quot;:34.0,\&quot;55\&quot;:35.0,\&quot;56\&quot;:35.0,\&quot;57\&quot;:35.0,\&quot;58\&quot;:35.0,\&quot;59\&quot;:29.0,\&quot;60\&quot;:29.0,\&quot;61\&quot;:29.0,\&quot;62\&quot;:29.0}}&quot;
]
</code></pre>
<p>We can forget about the 4th line for now.
I'll tell you a bit about my app. The app can have 2 rounds, each round having a maximum of 10 questions, each question will have a timer for 3 minutes. Now I need to get these questions(3rd line) from this json and display in the app.</p>
<p>The below list is what I'll have to update.</p>
<pre><code>import 'package:activepeers_app_internship/models/questions.dart';
 List&lt;Question&gt; sample_data = [
   Question(id: 1,
    question: &quot;Flutter is an open-source UI software development kit created by ______&quot;,
    ),
   Question(
    id: 2,
    question: &quot;When google release Flutter.&quot;,
),
  Question(
    id: 3,
    question: &quot;A memory location that holds a single letter or number.&quot;,
  ),
  Question(
    id: 4,
    question: &quot;What command do you use to output data to the screen?&quot;,
  ),
];
</code></pre>
<p>Can you tell me how to get those questions here as I don't know how to.</p>
",57,1,1,2,json;flutter,2022-07-06 17:28:50,2022-07-06 17:28:50,2022-07-06 23:34:01,below is the json i have to parse  the below list is what i ll have to update  can you tell me how to get those questions here as i don t know how to ,how to parse json file in flutter 
140,14421655,68273278,Assertion Error when producing ScatterText Visualisation,"<p>I'm new to scattertext and have written the code which should produce an interactive html visualisation.</p>
<pre class=""lang-py prettyprint-override""><code>import spacy
import pandas as pd
import scattertext as st


twitterData = pd.read_csv(&quot;stock_data.csv&quot;)
twitterData.dtypes

nlp = spacy.load(&quot;en_core_web_sm&quot;)
corpus = st.CorpusFromPandas(
    twitterData, category_col=&quot;Sentiment&quot;, text_col=&quot;Text&quot;, nlp=nlp
).build()

sent = st.produce_scattertext_explorer(
    corpus,
    category=&quot;1&quot;,
    category_name=&quot;Positive&quot;,
    not_category_name=&quot;Negative&quot;,
    width_in_pixels=1000,
)

open(&quot;StockMarketSentiment.html&quot;, &quot;wb&quot;).write(html.encode(&quot;utf-8&quot;))
</code></pre>
<p>However, the code that I have written, following a template online, throws an assertion error and as I'm a newbie at software development i'm struggling to understand where Im going wrong.</p>
<pre><code>Traceback (most recent call last):
  File &quot;/Users/lukeashton/PycharmProjects/Project/venv/Visualiser.py&quot;, line 15, in &lt;module&gt;
    sent = st.produce_scattertext_explorer(corpus,
  File &quot;/Users/lukeashton/PycharmProjects/Project/venv/lib/python3.8/site-packages/scattertext/__init__.py&quot;, line 594, in produce_scattertext_explorer
    scatter_chart_data = scatter_chart_explorer.to_dict(
  File &quot;/Users/lukeashton/PycharmProjects/Project/venv/lib/python3.8/site-packages/scattertext/ScatterChartExplorer.py&quot;, line 115, in to_dict
    json_data = ScatterChart.to_dict(self,
  File &quot;/Users/lukeashton/PycharmProjects/Project/venv/lib/python3.8/site-packages/scattertext/ScatterChart.py&quot;, line 276, in to_dict
    assert category in all_categories
AssertionError
Process finished with exit code 1
</code></pre>
<p>Appreciate it may be hard to offer advice with such limited info but the code &amp; error details are below if anyone can spot anything!</p>
",244,2,1,5,python;python-3.x;data-visualization;scatter-plot;scatter3d,2021-07-06 18:23:20,2021-07-06 18:23:20,2022-07-06 23:09:12,i m new to scattertext and have written the code which should produce an interactive html visualisation  however  the code that i have written  following a template online  throws an assertion error and as i m a newbie at software development i m struggling to understand where im going wrong  appreciate it may be hard to offer advice with such limited info but the code  amp  error details are below if anyone can spot anything ,assertion error when producing scattertext visualisation
141,3173230,72883356,Is it possible to use FyTest in Microsoft Visual Studio without CMake?,"<p>I am developing on an old legacy code in Fortran, and I am trying to implement unit testing to enable a more secure development environment. From all the options given in the Fortran Wiki on <a href=""https://fortranwiki.org/fortran/show/Unit+testing+frameworks"" rel=""nofollow noreferrer"">this page</a>, I evaluated FyTest would be the most suitable one.</p>
<p>However, to automatically run the tests, it needs a CMake build instruction, which currently I don't have installed on the company computer (I could ask for its necessity, but that is a long and tiresome process I am trying to avoid). The company software for development is Microsoft Visual Studio (version 2010). Is there a way &quot;native&quot; to Visual Studio for running FyTest? I noticed that creating a project in Visual Studio creates a &quot;solution file&quot; (<code>.sln</code>), but I don't know if it is possible to adapt it to do the same work as CMake would do...</p>
",58,1,1,3,visual-studio;cmake;fortran,2022-07-06 15:11:56,2022-07-06 15:11:56,2022-07-06 16:52:56,i am developing on an old legacy code in fortran  and i am trying to implement unit testing to enable a more secure development environment  from all the options given in the fortran wiki on   i evaluated fytest would be the most suitable one  however  to automatically run the tests  it needs a cmake build instruction  which currently i don t have installed on the company computer  i could ask for its necessity  but that is a long and tiresome process i am trying to avoid   the company software for development is microsoft visual studio  version    is there a way  native  to visual studio for running fytest  i noticed that creating a project in visual studio creates a  solution file    sln   but i don t know if it is possible to adapt it to do the same work as cmake would do   ,is it possible to use fytest in microsoft visual studio without cmake 
142,15124,479042,Does anyone know of a successful implementation of the Blackboard pattern?,"<p>I've been interested in the <a href=""http://en.wikipedia.org/wiki/Blackboard_system"" rel=""noreferrer"">Blackboard pattern</a> for years (especially back when I was studying AI), however I still haven't been able to find a good implementation of it outside of academia, although it seems a very useful pattern for the current trends in software development, I can't think of any big framework built around the pattern.</p>

<p>Does anyone here know of success or failure stories related to this pattern?</p>

<p><strong>Note:</strong> Other links</p>

<ul>
<li><a
href=""http://www.vico.org/pages/PatronsDisseny/Pattern%20Blackboard/"" rel=""noreferrer"">external link 1</a></li>
<li><a
href=""http://chat.carleton.ca/~narthorn/project/patterns/BlackboardPattern-display.html"" rel=""noreferrer"">external link 2</a></li>
</ul>

<p><strong>Edit:</strong> Now I'm wondering if the pattern might have use as a pattern for a mashup-able ecosystem or something like that</p>

<p><strong>Edit:</strong> After investigating some more I found an interesting <a href=""http://www.hillside.net/plop/2008/papers/PLoP2008_09_Ortega-Arjona+Fernandez.pdf"" rel=""noreferrer"">paper</a> which proposes stuff like Wikipedia is a Blackboard however it depends on Humans as agents. That just led me to realize StackOverflow is pretty much a Blackboard system, with us as agents, sharing our expert knowledge about the  undetermined problems set on the board... anyways its some food for thought.</p>
",8029,5,21,2,design-patterns;blackboard,2009-01-26 09:32:56,2009-01-26 09:32:56,2022-07-06 14:02:19,i ve been interested in the  for years  especially back when i was studying ai   however i still haven t been able to find a good implementation of it outside of academia  although it seems a very useful pattern for the current trends in software development  i can t think of any big framework built around the pattern  does anyone here know of success or failure stories related to this pattern  note  other links edit  now i m wondering if the pattern might have use as a pattern for a mashup able ecosystem or something like that edit  after investigating some more i found an interesting  which proposes stuff like wikipedia is a blackboard however it depends on humans as agents  that just led me to realize stackoverflow is pretty much a blackboard system  with us as agents  sharing our expert knowledge about the  undetermined problems set on the board    anyways its some food for thought ,does anyone know of a successful implementation of the blackboard pattern 
143,11787461,72220815,Automate Edge/Chrome Web Browser via VBA without Selenium or External Installations,"<p>Currently for my team of 6 people, 5 of which have no programming/development knowledge, we are using a web automation for filling out a web form in Internet Explorer via VBA and Excel macros. The benefit of the current methodology is that no one on my team has to install any external software/packages when running the automation, since it only requires Microsoft Office Excel VBA.</p>
<p>Are there are solutions for utilizing the existing code for either Microsoft Edge or Chrome without having to install additional software/packages?</p>
",1331,1,0,3,excel;vba;selenium,2022-05-12 21:57:31,2022-05-12 21:57:31,2022-07-06 03:12:26,currently for my team of  people   of which have no programming development knowledge  we are using a web automation for filling out a web form in internet explorer via vba and excel macros  the benefit of the current methodology is that no one on my team has to install any external software packages when running the automation  since it only requires microsoft office excel vba  are there are solutions for utilizing the existing code for either microsoft edge or chrome without having to install additional software packages ,automate edge chrome web browser via vba without selenium or external installations
144,14346231,72858168,creating a development container for multiple pc,"<p>I want to create an image that contains all the dependencies needed for development like Java Maven, Node, etc., I want to create that image and then deploy it in different PCs at the same time.</p>
<p>I wanted to know if this is possible to do it by using Docker and if you could share with me some guide or information on how to do it, because I want to create an image that contains the dependencies but I want those different to have the software in the image but still remain unique like having their own configuration. I only want the image to deploy a fast environment to program, thanks in advance.</p>
",41,1,0,3,docker;kubernetes;development-environment,2022-07-04 17:16:34,2022-07-04 17:16:34,2022-07-05 08:05:40,i want to create an image that contains all the dependencies needed for development like java maven  node  etc   i want to create that image and then deploy it in different pcs at the same time  i wanted to know if this is possible to do it by using docker and if you could share with me some guide or information on how to do it  because i want to create an image that contains the dependencies but i want those different to have the software in the image but still remain unique like having their own configuration  i only want the image to deploy a fast environment to program  thanks in advance ,creating a development container for multiple pc
145,12355520,72862509,Airflow docker compose stuck,"<p>I am trying to run Airflow on my local machine. I am using docker compose file from official Apache Airflow webstiste <a href=""https://airflow.apache.org/docs/apache-airflow/2.0.1/docker-compose.yaml"" rel=""nofollow noreferrer"">https://airflow.apache.org/docs/apache-airflow/2.0.1/docker-compose.yaml</a></p>
<pre><code># Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# &quot;License&quot;); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#

# Basic Airflow cluster configuration for CeleryExecutor with Redis and PostgreSQL.
#
# WARNING: This configuration is for local development. Do not use it in a production deployment.
#
# This configuration supports basic configuration using environment variables or an .env file
# The following variables are supported:
#
# AIRFLOW_IMAGE_NAME           - Docker image name used to run Airflow.
#                                Default: apache/airflow:2.3.2
# AIRFLOW_UID                  - User ID in Airflow containers
#                                Default: 50000
# Those configurations are useful mostly in case of standalone testing/running Airflow in test/try-out mode
#
# _AIRFLOW_WWW_USER_USERNAME   - Username for the administrator account (if requested).
#                                Default: airflow
# _AIRFLOW_WWW_USER_PASSWORD   - Password for the administrator account (if requested).
#                                Default: airflow
# _PIP_ADDITIONAL_REQUIREMENTS - Additional PIP requirements to add when starting all containers.
#                                Default: ''
#
# Feel free to modify this file to suit your needs.
---
version: '3'
x-airflow-common:
  &amp;airflow-common
  # In order to add custom dependencies or upgrade provider packages you can use your extended image.
  # Comment the image line, place your Dockerfile in the directory where you placed the docker-compose.yaml
  # and uncomment the &quot;build&quot; line below, Then run `docker-compose build` to build the images.
  image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:2.3.2}
  # build: .
  environment:
    &amp;airflow-common-env
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    # For backward compatibility, with Airflow &lt;2.3
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
    AIRFLOW__CORE__FERNET_KEY: ''
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'true'
    AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth'
    _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
  user: &quot;${AIRFLOW_UID:-50000}:0&quot;
  depends_on:
    &amp;airflow-common-depends-on
    redis:
      condition: service_healthy
    postgres:
      condition: service_healthy

services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: [&quot;CMD&quot;, &quot;pg_isready&quot;, &quot;-U&quot;, &quot;airflow&quot;]
      interval: 5s
      retries: 5
    restart: always

  redis:
    image: redis:latest
    expose:
      - 6379
    healthcheck:
      test: [&quot;CMD&quot;, &quot;redis-cli&quot;, &quot;ping&quot;]
      interval: 5s
      timeout: 30s
      retries: 50
    restart: always

  airflow-webserver:
    &lt;&lt;: *airflow-common
    command: webserver
    ports:
      - 8080:8080
    healthcheck:
      test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;--fail&quot;, &quot;http://localhost:8080/health&quot;]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
    depends_on:
      &lt;&lt;: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-scheduler:
    &lt;&lt;: *airflow-common
    command: scheduler
    healthcheck:
      test: [&quot;CMD-SHELL&quot;, 'airflow jobs check --job-type SchedulerJob --hostname &quot;$${HOSTNAME}&quot;']
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
    depends_on:
      &lt;&lt;: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-worker:
    &lt;&lt;: *airflow-common
    command: celery worker
    healthcheck:
      test:
        - &quot;CMD-SHELL&quot;
        - 'celery --app airflow.executors.celery_executor.app inspect ping -d &quot;celery@$${HOSTNAME}&quot;'
      interval: 10s
      timeout: 10s
      retries: 5
    environment:
      &lt;&lt;: *airflow-common-env
      # Required to handle warm shutdown of the celery workers properly
      # See https://airflow.apache.org/docs/docker-stack/entrypoint.html#signal-propagation
      DUMB_INIT_SETSID: &quot;0&quot;
    restart: always
    depends_on:
      &lt;&lt;: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-triggerer:
    &lt;&lt;: *airflow-common
    command: triggerer
    healthcheck:
      test: [&quot;CMD-SHELL&quot;, 'airflow jobs check --job-type TriggererJob --hostname &quot;$${HOSTNAME}&quot;']
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
    depends_on:
      &lt;&lt;: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-init:
    &lt;&lt;: *airflow-common
    entrypoint: /bin/bash
    # yamllint disable rule:line-length
    command:
      - -c
      - |
        function ver() {
          printf &quot;%04d%04d%04d%04d&quot; $${1//./ }
        }
        airflow_version=$$(gosu airflow airflow version)
        airflow_version_comparable=$$(ver $${airflow_version})
        min_airflow_version=2.2.0
        min_airflow_version_comparable=$$(ver $${min_airflow_version})
        if (( airflow_version_comparable &lt; min_airflow_version_comparable )); then
          echo
          echo -e &quot;\033[1;31mERROR!!!: Too old Airflow version $${airflow_version}!\e[0m&quot;
          echo &quot;The minimum Airflow version supported: $${min_airflow_version}. Only use this or higher!&quot;
          echo
          exit 1
        fi
        if [[ -z &quot;${AIRFLOW_UID}&quot; ]]; then
          echo
          echo -e &quot;\033[1;33mWARNING!!!: AIRFLOW_UID not set!\e[0m&quot;
          echo &quot;If you are on Linux, you SHOULD follow the instructions below to set &quot;
          echo &quot;AIRFLOW_UID environment variable, otherwise files will be owned by root.&quot;
          echo &quot;For other operating systems you can get rid of the warning with manually created .env file:&quot;
          echo &quot;    See: https://airflow.apache.org/docs/apache-airflow/stable/start/docker.html#setting-the-right-airflow-user&quot;
          echo
        fi
        one_meg=1048576
        mem_available=$$(($$(getconf _PHYS_PAGES) * $$(getconf PAGE_SIZE) / one_meg))
        cpus_available=$$(grep -cE 'cpu[0-9]+' /proc/stat)
        disk_available=$$(df / | tail -1 | awk '{print $$4}')
        warning_resources=&quot;false&quot;
        if (( mem_available &lt; 4000 )) ; then
          echo
          echo -e &quot;\033[1;33mWARNING!!!: Not enough memory available for Docker.\e[0m&quot;
          echo &quot;At least 4GB of memory required. You have $$(numfmt --to iec $$((mem_available * one_meg)))&quot;
          echo
          warning_resources=&quot;true&quot;
        fi
        if (( cpus_available &lt; 2 )); then
          echo
          echo -e &quot;\033[1;33mWARNING!!!: Not enough CPUS available for Docker.\e[0m&quot;
          echo &quot;At least 2 CPUs recommended. You have $${cpus_available}&quot;
          echo
          warning_resources=&quot;true&quot;
        fi
        if (( disk_available &lt; one_meg * 10 )); then
          echo
          echo -e &quot;\033[1;33mWARNING!!!: Not enough Disk space available for Docker.\e[0m&quot;
          echo &quot;At least 10 GBs recommended. You have $$(numfmt --to iec $$((disk_available * 1024 )))&quot;
          echo
          warning_resources=&quot;true&quot;
        fi
        if [[ $${warning_resources} == &quot;true&quot; ]]; then
          echo
          echo -e &quot;\033[1;33mWARNING!!!: You have not enough resources to run Airflow (see above)!\e[0m&quot;
          echo &quot;Please follow the instructions to increase amount of resources available:&quot;
          echo &quot;   https://airflow.apache.org/docs/apache-airflow/stable/start/docker.html#before-you-begin&quot;
          echo
        fi
        mkdir -p /sources/logs /sources/dags /sources/plugins
        chown -R &quot;${AIRFLOW_UID}:0&quot; /sources/{logs,dags,plugins}
        exec /entrypoint airflow version
    # yamllint enable rule:line-length
    environment:
      &lt;&lt;: *airflow-common-env
      _AIRFLOW_DB_UPGRADE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}
      _PIP_ADDITIONAL_REQUIREMENTS: ''
    user: &quot;0:0&quot;
    volumes:
      - .:/sources

  airflow-cli:
    &lt;&lt;: *airflow-common
    profiles:
      - debug
    environment:
      &lt;&lt;: *airflow-common-env
      CONNECTION_CHECK_MAX_COUNT: &quot;0&quot;
    # Workaround for entrypoint issue. See: https://github.com/apache/airflow/issues/16252
    command:
      - bash
      - -c
      - airflow

  # You can enable flower by adding &quot;--profile flower&quot; option e.g. docker-compose --profile flower up
  # or by explicitly targeted on the command line e.g. docker-compose up flower.
  # See: https://docs.docker.com/compose/profiles/
  flower:
    &lt;&lt;: *airflow-common
    command: celery flower
    profiles:
      - flower
    ports:
      - 5555:5555
    healthcheck:
      test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;--fail&quot;, &quot;http://localhost:5555/&quot;]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
    depends_on:
      &lt;&lt;: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

volumes:
  postgres-db-volume:
</code></pre>
<p>Unfortunately when trying to run docker-compose file execution stuck on the following line and run it again and again:</p>
<pre><code>airflow-webserver_1  | 127.0.0.1 - - [04/Jul/2022:22:21:52 +0000] &quot;GET /health HTTP/1.1&quot; 200 187 &quot;-&quot; &quot;curl/7.74.0&quot;
airflow-webserver_1  | 127.0.0.1 - - [04/Jul/2022:22:22:02 +0000] &quot;GET /health HTTP/1.1&quot; 200 187 &quot;-&quot; &quot;curl/7.74.0&quot;
airflow-webserver_1  | 127.0.0.1 - - [04/Jul/2022:22:22:12 +0000] &quot;GET /health HTTP/1.1&quot; 200 187 &quot;-&quot; &quot;curl/7.74.0&quot;
airflow-webserver_1  | 127.0.0.1 - - [04/Jul/2022:22:22:23 +0000] &quot;GET /health HTTP/1.1&quot; 200 187 &quot;-&quot; &quot;curl/7.74.0&quot;
airflow-webserver_1  | 127.0.0.1 - - [04/Jul/2022:22:22:33 +0000] &quot;GET /health HTTP/1.1&quot; 200 187 &quot;-&quot; &quot;curl/7.74.0&quot;
airflow-webserver_1  | 127.0.0.1 - - [04/Jul/2022:22:22:43 +0000] &quot;GET /health HTTP/1.1&quot; 200 187 &quot;-&quot; &quot;curl/7.74.0&quot;
airflow-webserver_1  | 127.0.0.1 - - [04/Jul/2022:22:22:53 +0000] &quot;GET /health HTTP/1.1&quot; 200 187 &quot;-&quot; &quot;curl/7.74.0&quot;
airflow-webserver_1  | 127.0.0.1 - - [04/Jul/2022:22:23:03 +0000] &quot;GET /health HTTP/1.1&quot; 200 187 &quot;-&quot; &quot;curl/7.74.0&quot;
airflow-webserver_1  | 127.0.0.1 - - [04/Jul/2022:22:23:13 +0000] &quot;GET /health HTTP/1.1&quot; 200 187 &quot;-&quot; &quot;curl/7.74.0&quot;
airflow-webserver_1  | 127.0.0.1 - - [04/Jul/2022:22:23:24 +0000] &quot;GET /health HTTP/1.1&quot; 200 187 &quot;-&quot; &quot;curl/7.74.0&quot;
airflow-webserver_1  | 127.0.0.1 - - [04/Jul/2022:22:23:34 +0000] &quot;GET /health HTTP/1.1&quot; 200 187 &quot;-&quot; &quot;curl/7.74.0&quot;
airflow-webserver_1  | 127.0.0.1 - - [04/Jul/2022:22:23:44 +0000] &quot;GET /health HTTP/1.1&quot; 200 187 &quot;-&quot; &quot;curl/7.74.0&quot;
airflow-webserver_1  | 127.0.0.1 - - [04/Jul/2022:22:23:54 +0000] &quot;GET /health HTTP/1.1&quot; 200 187 &quot;-&quot; &quot;curl/7.74.0&quot;
airflow-scheduler_1  | [2022-07-04 22:24:04,122] {scheduler_job.py:1221} INFO - Resetting orphaned tasks for active dag runs
airflow-webserver_1  | 127.0.0.1 - - [04/Jul/2022:22:24:04 +0000] &quot;GET /health HTTP/1.1&quot; 200 187 &quot;-&quot; &quot;curl/7.74.0&quot;
airflow-webserver_1  | 127.0.0.1 - - [04/Jul/2022:22:24:14 +0000] &quot;GET /health HTTP/1.1&quot; 200 187 &quot;-&quot; &quot;curl/7.74.0&quot;
airflow-webserver_1  | 127.0.0.1 - - [04/Jul/2022:22:24:24 +0000] &quot;GET /health HTTP/1.1&quot; 200 187 &quot;-&quot; &quot;curl/7.74.0&quot;
airflow-webserver_1  | 127.0.0.1 - - [04/Jul/2022:22:24:35 +0000] &quot;GET /health HTTP/1.1&quot; 200 187 &quot;-&quot; &quot;curl/7.74.0&quot;
airflow-webserver_1  | 127.0.0.1 - - [04/Jul/2022:22:24:45 +0000] &quot;GET /health HTTP/1.1&quot; 200 187 &quot;-&quot; &quot;curl/7.74.0&quot;

</code></pre>
<p>Do you know what this line means? What could be the potential issue?</p>
<p>I am running this on Ubuntu 22.04 LTS.</p>
",165,0,0,2,docker-compose;airflow,2022-07-05 01:28:38,2022-07-05 01:28:38,2022-07-05 01:28:38,i am trying to run airflow on my local machine  i am using docker compose file from official apache airflow webstiste  unfortunately when trying to run docker compose file execution stuck on the following line and run it again and again  do you know what this line means  what could be the potential issue  i am running this on ubuntu   lts ,airflow docker compose stuck
146,1846562,72838226,Is it really safe that running `UPDATE t SET v=v-1 WHERE id= ? and v&gt;0` without pessimistic row locking? (MySQL/Postgres/Oracle),"<h3>Overview</h3>
<p>Assume that there is a table which controls stock amount information.</p>
<pre><code>CREATE TABLE products(
    id INTEGER PRIMARY KEY,
    remaining_amount INTEGER NOT NULL
);
INSERT INTO products(id, remaining_amount) VALUES (1, 1);
</code></pre>
<p>Now, user A and B try to take the last stock at the same time.</p>
<pre><code>A/B: UPDATE products
     SET remaining_amount = remaining_amount - 1
     WHERE id = 1 and remaining_amount &gt; 0;
</code></pre>
<p>The questions are:</p>
<ul>
<li>Could <code>remaining_amount</code> never be negative values? Do we need any explicit pessimistic row locking?</li>
<li>Which transaction level should I use: <code>READ COMMITTED</code>, <code>REPEATABLE READ</code>, <code>SERIALIZABLE</code> or <code>READ UNCOMMITTED</code>(only for MySQL)?</li>
<li>Does it yield different conclusion with different RDBMS?</li>
</ul>
<h3>Related Information</h3>
<ul>
<li><a href=""https://dba.stackexchange.com/questions/175228/mysql-innodb-is-single-update-statement-with-where-transaction-safe/175247#175247"">(mysql innodb) Is single update statement with &quot;where&quot; transaction safe?</a>
<ul>
<li>This question concludes that explicit pessimistic row locking is required for MySQL.</li>
</ul>
</li>
<li>My Twitter friend RDBMS geek says that:
<ul>
<li>Oracle tries to achieve write consistency; if the target row has been changed, the consecutive UPDATE query is automatically rolled back and it retries with implicit pessimistic row locking. He says that it is described in this book: <a href=""https://www.amazon.co.jp/dp/1430262982/ref=cm_sw_r_apa_gl_i_1Y35BV7X7HMDSXB38YV1_0"" rel=""nofollow noreferrer"">Amazon | Expert Oracle Database Architecture | Kyte, Thomas, Kuhn, Darl | Software Development</a></li>
<li>PostgreSQL has immutable rows and then the old rows are treated as <em>dead tuple</em>; so the latter updates will never be applied.</li>
</ul>
</li>
</ul>
",305,2,-1,5,mysql;sql;postgresql;oracle;mvcc,2022-07-02 13:09:08,2022-07-02 13:09:08,2022-07-03 13:53:11,assume that there is a table which controls stock amount information  now  user a and b try to take the last stock at the same time  the questions are ,is it really safe that running  update t set v v  where id    and v gt   without pessimistic row locking   mysql postgres oracle 
147,14073182,72794710,Using Ajax GET to download compressed JSON files,"<p><strong>Background.</strong></p>
<p>I'm tasked with debugging some <code>PHP</code> and <code>JavaScript</code> code designed to pull static, <code>gzip</code>'ed JSON files from the host server, and manipulate the resulting JSON object's parameters.</p>
<p>Apologies in advance for my misuse of terminology. I have some experience with software development, but very little with web/server development (and almost none with <code>PHP</code>/<code>JavaScript</code>).</p>
<hr />
<p><strong>Code.</strong></p>
<p>To &quot;pull&quot; the <code>.json.gz</code> file from the host server, jQuery's Ajax function is used:</p>
<pre><code>function myJsonReader() {
    var myJsonFileUrl = getUrl();
    
    function doFunStuffWithJsonFile(jsonObject) {
        // Fun things happen
    }

    $.ajax({
        url: myJsonFileUrl,
        type: &quot;GET&quot;,
        dataType: &quot;json&quot;, 
        success: doFunStuffWithJsonFile,
        error: function(jqxhr, status, exception) {
            console.log(&quot;Exception &quot; + exception);
             alert('Failure:', exception);
             
        }
    }); 

}
</code></pre>
<p>Server-side, we have an <code>index.php</code> file, the first few lines of which are:</p>
<pre><code>&lt;?php
  header('Accept-Encoding: gzip');
  header('Content-Encoding: gzip');
?&gt;

&lt;html&gt;
&lt;head&gt;
... some HTML code
</code></pre>
<hr />
<p>The Ajax <code>GET</code> request fails. I know the file exists, and I'm passing the absolute path. Moreover, I'm able to read the compressed file if I use <code>dataType: &quot;text&quot;</code>, but that, of course, returns &quot;garbage&quot;:</p>
<pre><code>����%^��0��jN�L/��8�?@��x���351�g��+��~���ׯ���/߿�7���^��di9�y;jY��6�$K�=��4��QTMB�^or��M�P��̡�*}��G�t��K!#�8�Z@[d�9�#����R��N�����y��Պ�������;9�T����B+��VM�#��.:�&lt;ĩ�F�PZ��Ȕl[K̔N[� GȡĚ�.5;P6�H��jeͮ��&lt;�e&quot;&quot;�h�-!�&gt;��S�E��Q�m�H�.ڌSAyc�S�MsFHF�K]�H)/ry`�6.��&amp;��-ME���s�����GA��@�rJ�.����)��kR�Vi�6��h�K-`��������
</code></pre>
<p>If I check the XHR response using:</p>
<pre><code>error: function(xhr, status, error) {
        console.log(xhr.responseText);
        }
</code></pre>
<p>I also <a href=""https://pastebin.com/69b0uP9J"" rel=""nofollow noreferrer"">get garbage</a>.</p>
<p>The file is a valid JSON file, readable by Vim with it's built-in <code>gunzip</code> capabilities. Moreover, this code was previously able to read these gzipped JSON files without issue using an Ajax call and without the use of external libraries, until some unknown change is presumed to have been made (being messy and mostly undocumented, it hasn't been possible to track down that change).</p>
<p>It is not possible to simply unzip all files we wish to read with this function, nor is it possible to make use of external libraries (e.g. <code>zlib</code>), unfortunately.</p>
<hr />
<p>Several sources suggest this is should be relatively straight-forward (e.g. <a href=""https://stackoverflow.com/questions/14858583/how-to-have-a-browser-gunzip-an-ajax-fetched-gziped-text-file"">this StackOverflow post</a>, <a href=""https://stackoverflow.com/questions/15768047/loading-gzip-json-file-using-ajax"">and this one</a>). Sadly, it isn't clear to me what I'm missing.</p>
<hr />
<p><strong>Edit.</strong></p>
<p>After re-loading the page, I check the <code>Network</code> tab in Chrome's Inspector. I see the <code>Fetch/XHR</code> request for my JSON file. The headers for which include the following:</p>
<pre><code>Requested Method: GET
Content-Type: application/x-gzip
Accept: application/json, text/javascript, */*; q=0.01
Accept-Encoding: gzip, deflate
Status Code: 200 OK
</code></pre>
<p>Which, to my untrained eye, seems to be properly configured for accepting compressed files.</p>
",147,2,2,5,javascript;php;jquery;json;ajax,2022-06-29 04:10:10,2022-06-29 04:10:10,2022-07-03 11:23:23,background  i m tasked with debugging some php and javascript code designed to pull static  gzip ed json files from the host server  and manipulate the resulting json object s parameters  apologies in advance for my misuse of terminology  i have some experience with software development  but very little with web server development  and almost none with php javascript   code  to  pull  the  json gz file from the host server  jquery s ajax function is used  server side  we have an index php file  the first few lines of which are  the ajax get request fails  i know the file exists  and i m passing the absolute path  moreover  i m able to read the compressed file if i use datatype   text   but that  of course  returns  garbage   if i check the xhr response using  i also   the file is a valid json file  readable by vim with it s built in gunzip capabilities  moreover  this code was previously able to read these gzipped json files without issue using an ajax call and without the use of external libraries  until some unknown change is presumed to have been made  being messy and mostly undocumented  it hasn t been possible to track down that change   it is not possible to simply unzip all files we wish to read with this function  nor is it possible to make use of external libraries  e g  zlib   unfortunately  several sources suggest this is should be relatively straight forward  e g       sadly  it isn t clear to me what i m missing  edit  after re loading the page  i check the network tab in chrome s inspector  i see the fetch xhr request for my json file  the headers for which include the following  which  to my untrained eye  seems to be properly configured for accepting compressed files ,using ajax get to download compressed json files
148,14020542,71419988,Visual Studio Code Live server injects a white div to the bottom of the HTML page,"<p><a href=""https://i.stack.imgur.com/ciyJv.png"" rel=""nofollow noreferrer"">https://i.stack.imgur.com/ciyJv.png</a> - White DIV on the website.</p>
<p><a href=""https://i.stack.imgur.com/wHwJX.png"" rel=""nofollow noreferrer"">https://i.stack.imgur.com/wHwJX.png</a> - White DIV code.</p>
<p><a href=""https://i.stack.imgur.com/ZraZI.png"" rel=""nofollow noreferrer"">https://i.stack.imgur.com/ZraZI.png</a> - No such code in HTML.</p>
<p>The white DIV is injected by live server AND it goes over to the website hosted by DNS.</p>
<p><a href=""https://www.kristotanak.ee"" rel=""nofollow noreferrer"">https://www.kristotanak.ee</a></p>
<p>How do I get rid of it? I am a 16 year old student studying software development soo please don't bully me.</p>
",123,2,0,3,javascript;html;css,2022-03-10 08:59:25,2022-03-10 08:59:25,2022-07-03 07:29:04,   white div on the website     white div code     no such code in html  the white div is injected by live server and it goes over to the website hosted by dns   how do i get rid of it  i am a  year old student studying software development soo please don t bully me ,visual studio code live server injects a white div to the bottom of the html page
149,10367330,72836974,Flutter Dev: &quot;Visual Studio not installed; this is necessary for Windows development&quot; Error Although Already Installed Visual Studio,"<p><strong>Problem Statement:</strong>
Although I've installed &quot;Visual Studio&quot; software &amp; &quot;Desktop development with C++&quot; workload, I'm still getting the below error when executing &quot;flutter doctor.&quot;
<a href=""https://i.stack.imgur.com/B3Tou.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/B3Tou.png"" alt=""enter image description here"" /></a></p>
<p><strong>[Checkpoints]</strong></p>
<ol>
<li>I've installed *all workloads for &quot;Desktop &amp; Mobile&quot; including all optional ones as well
<a href=""https://i.stack.imgur.com/6DoOn.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/6DoOn.png"" alt=""enter image description here"" /></a></li>
<li>I've tried using &quot;Visual Studio Developer Command Prompt&quot; instead, however, I'm still seeing the same result
<a href=""https://i.stack.imgur.com/JfYky.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/JfYky.png"" alt=""enter image description here"" /></a></li>
<li>I'm using a Windows 11 device/64 bit</li>
<li>I've tried uninstalling, then re-installing everything</li>
</ol>
<p><strong>Question:</strong>
Why is this happening? Is it because I'm using a device that I bought in Japan?</p>
",71,0,0,1,flutter,2022-07-02 09:34:02,2022-07-02 09:34:02,2022-07-02 09:44:59, checkpoints ,flutter dev   visual studio not installed  this is necessary for windows development  error although already installed visual studio
150,11659424,72832091,What is the &quot;proper&quot; way to write out &quot;command line/command-line&quot; in the context of documentation?,"<p>I was proofreading a README file and noticed inconsistent spelling of a phrase spelled two ways: &quot;command line&quot; and &quot;command-line&quot;. I went looking for a conclusive answer and did not find much (see <a href=""http://www.techwr-l.com/archives/0711/techwhirl-0711-00735.html"" rel=""nofollow noreferrer"">this archived exchange</a> and <a href=""https://docs.microsoft.com/en-us/style-guide/a-z-word-list-term-collections/c/command-line"" rel=""nofollow noreferrer"">this Microsoft style guide page</a>). I concluded that it probably doesn't matter and that &quot;command line&quot; seems to be more common, but now I'm curious; has anyone else run into this issue? If you're an industry professional that documents your code, were you ever provided an answer?</p>
<p>Side note: I was debating whether or not to ask this here, as it's certainly more of a code-adjacent question, but considering that if you're writing code, you <em>should</em> be writing documentation as well, I figured it would fit the criteria of &quot;a practical, answerable problem that is unique to software development&quot; stated <a href=""https://stackoverflow.com/help/on-topic"">here</a>. If this is not the case, do let me know-- thanks!</p>
",25,2,0,1,readme,2022-07-01 19:17:33,2022-07-01 19:17:33,2022-07-01 19:22:55,i was proofreading a readme file and noticed inconsistent spelling of a phrase spelled two ways   command line  and  command line   i went looking for a conclusive answer and did not find much  see  and    i concluded that it probably doesn t matter and that  command line  seems to be more common  but now i m curious  has anyone else run into this issue  if you re an industry professional that documents your code  were you ever provided an answer  side note  i was debating whether or not to ask this here  as it s certainly more of a code adjacent question  but considering that if you re writing code  you should be writing documentation as well  i figured it would fit the criteria of  a practical  answerable problem that is unique to software development  stated   if this is not the case  do let me know   thanks ,what is the  proper  way to write out  command line command line  in the context of documentation 
151,11537079,72781165,linux command: conda Activate | cat myFileName.txt,"<p>I am learning Linux commands and try to use it more in my day to day software development.</p>
<p>I created a <code>conda</code> environment and stored the environment path in a <code>txt</code> file. i.e. <code>myfile.txt</code>. For the next time, I don't need to remember the path to activate the environment. It would be <code>conda activate environment_path</code></p>
<p>I also want not to open the <code>txt</code> file to copy past and get the activation done in one line. So I tried <code>conda activate | cat myFileName.txt</code></p>
<p>But it didn't work. I'm not sure what was wrong. Some helps are appreciated, thank you!</p>
",37,1,0,3,shell;conda;virtual-environment,2022-06-28 08:31:56,2022-06-28 08:31:56,2022-07-01 17:49:06,i am learning linux commands and try to use it more in my day to day software development  i created a conda environment and stored the environment path in a txt file  i e  myfile txt  for the next time  i don t need to remember the path to activate the environment  it would be conda activate environment_path i also want not to open the txt file to copy past and get the activation done in one line  so i tried conda activate   cat myfilename txt but it didn t work  i m not sure what was wrong  some helps are appreciated  thank you ,linux command  conda activate   cat myfilename txt
152,19452366,72816617,After deploying .netcore 3.1 project with AWS CodePipeline response is 502 BadGateway for every request,"<p>I would like to build a CI/CD Pipeline using AWS CodePipeline for C# Web Application. However, I am getting Bad Gateway all the time. The problem lies the deployment I believe. Here is the summary:</p>
<p>.Net Core version: 3.1</p>
<p>Here is my yml file for CodeBuild.</p>
<pre><code>version: 0.2

env:
  variables:
    PROJECT: &lt;Project_name&gt;
    PROJECT_PATH: &lt;Project_path&gt;/&lt;Project_name&gt;
    OUTPUT_PATH: &lt;Project_path&gt;/&lt;Project_name&gt;/bin/Release/netcoreapp3.1
    DOTNET_FRAMEWORK: 3.1
    CODEBUILD_WEBHOOK_TRIGGER: branch/development
    
phases:
  install:
    runtime-versions:
      dotnet: $DOTNET_FRAMEWORK
    
  pre_build:
    commands:
      - curl -o /usr/local/bin/nuget.exe https://dist.nuget.org/win-x86-commandline/latest/nuget.exe
      - mono /usr/local/bin/nuget.exe install stackexchange.redis -Version 2.5.61
      - mono /usr/local/bin/nuget.exe restore &lt;Solution_path&gt;

  build:
    commands: 
       - dotnet build $PROJECT_PATH/$PROJECT.csproj /p:Configuration=Release
       - dotnet publish $PROJECT_PATH/$PROJECT.csproj -o build_output -c release

  post_build:
    commands:
      - ls -l build_output

artifacts:
  files:
    - '**/*'
  name: &lt;project_name&gt;-$(date +%Y-%m-%d)
  base-directory: 'build_output'
  discard-paths: no
</code></pre>
<p>Here is my environment settings:
<a href=""https://i.stack.imgur.com/XCgNa.png"" rel=""nofollow noreferrer"">Software</a>
<a href=""https://i.stack.imgur.com/eMEiO.png"" rel=""nofollow noreferrer"">Other Settings</a></p>
<p>And here is my console output after deploying the application:
<a href=""https://i.stack.imgur.com/mRCHi.png"" rel=""nofollow noreferrer"">Deploy output</a></p>
<p>I also configured Load Balancer. In fact, When I deploy it via Visual Studio, it works. However, If I wanted to deploy it via CI/CD, it would give me BadGateWay error.</p>
<p>Note: I have two instances. Production and Development settings are almost the same. While I deploy Production by Visual Studio, I use CI/CD to deploy Development</p>
",16,0,0,3,.net-core;amazon-elastic-beanstalk;aws-codepipeline,2022-06-30 16:23:14,2022-06-30 16:23:14,2022-06-30 16:23:14,i would like to build a ci cd pipeline using aws codepipeline for c  web application  however  i am getting bad gateway all the time  the problem lies the deployment i believe  here is the summary   net core version    here is my yml file for codebuild  i also configured load balancer  in fact  when i deploy it via visual studio  it works  however  if i wanted to deploy it via ci cd  it would give me badgateway error  note  i have two instances  production and development settings are almost the same  while i deploy production by visual studio  i use ci cd to deploy development,after deploying  netcore   project with aws codepipeline response is  badgateway for every request
153,19432790,72813752,"My game requires a Database, both for official servers and private, but which one should I get?","<p>This is a bit text Heavy, I apologise. There is a TLDR below.</p>
<p><strong>Intro to myself:</strong> I know you all probably heard the same story. Guy wants to make a game etc. Going into it semi blind, and dose not know much of what he's doing. I confess to be somewhat like this.</p>
<p>Next, I'm terrible with terminology, and have a brain like a fish when I comes to long nouns, this is largely due to my (mild) dyslexia, so please forgive me.</p>
<p>I did pre-university computer science at collage some 4 years back. Did some MySQL, some VB.net  (windows forms are fun) and JavaScript. I've been following along loosely since then, but haven't done much since then so am quite rusty.</p>
<p>My level of skills can be called enthusiast at best, and muddle-headedly incompetent at worst. Been dabbling in C# since me and a friend use Unity a lot. To by honest college was a little trauma inducing for me and soured my ability to code (minor fear/stage fright, easily distracted), but to get over that I've decided to head out on my own and make something for myself.</p>
<p>Whether I succeed with the project or not, no matter how big or small the project is, isn't important, just so long as I'm creating something I'm satisfied with and I can progress in my skills and learn, that is all the matters. The rest is just a bonus.</p>
<p>With that in mind, I've formulated a project I hope and believe will retain my interest long enough to get some education in.</p>
<h1>So without further a do, lets get to why I'm here.</h1>
<p>I want to make a space game, a massive space game. Mostly, if not all procedural, but with realistic star counts spanning an entire galaxy. This can range from 1 thousand, to 100 trillion stars (I'd like to go as far as 150t for stress levels then cap at 100), much like it is in real life (Segue 2 - 1k, IC1101 - 100 trillion). Sounds nuts but games like Space Engine have already done this, and that was developed by one person.</p>
<p>Is this practical? I don't really care all that much if this is sort of game is practical or achievable, so long as its realistic-ish on this aspect and a few others. Plus, the thought of &quot;this could work, you just have to be creative and put the effort in&quot; attracts me.</p>
<p>So what's the issue? Why cant I use a normal save file? This issue comes when the game I'm trying to make is somewhat similar to a 4x. Its not exactly, but its close enough to know that there is a lot of information flying around, information that needs to be stored, synced and in some cases processed.</p>
<p>On a small scale, a single home/gaming computer can do this, so having a small single player is fine. However that's not what I want to achieve; The game I would like to create allows multiple people to play over long spans of time, across a galaxy, no matter what size that galaxy is.</p>
<p>This is where I started my research. I need a way to store this information and so I looked up various database engines like PostgreSQL, and others.</p>
<p>I think to myself, for what I'm doing as far as the world map is concerned, for the most part, a standard SQL databased should be fine... right? My confidence started shaking when looking up what game devs are using these day... NoSQL? What on earth is this? Why is google persistent on this? So I looked into it more. I then find out about NewSQL and realise I'm starting to run around in circles. The rabbit hole I did descend.</p>
<p>The flexibility of NoSQL is attractive, but when you see the lack of ACID in terms of fast and reliable queries (if I've read these articles right, I could be wrong), is a massive downside if your trying to look up 1 of a trillion stars or 1 of a quadrillion planets on the map in a fast manner. This is also not taking into account the fact a game is running along side it, sending and creating new data all the time.</p>
<p>Now I could be making a big issue about all this, as my scale of work might me too small to effect even the slow of systems, but how can I really know?</p>
<p>There's also the issue that, I don't know for sure, that somewhere down the line I'll need to create a new datatype for some new feature I create, and go mess things up in my existing test data because the database is old SQL, and you kinda have to deal with a ridged schema. What I need that flexibility to mess around and not worry a table somewhere is going to break, or that I have to bloat the DB with empty or null to non-applicable entries.</p>
<p>Why am I messing around with DB's before the actual game? Well if I cant even create the chess board before I can play chess, there's no point trying to invent chess really... I can make things look pretty later, I need the data first to manipulate.</p>
<p><strong>~~TL:DR:~~</strong></p>
<p>I leu of everything mentioned, I've compiled a small shopping list of a what I'm looking for to store my data:</p>
<p><strong>-</strong> Must allow me to integrate into a single application, so my end users can deploy their own privet servers, in a relatively simple manner. What I mean by this, is more a licensing thing, and the easy of integration/use. Simply dragging up some opensource software and stuff it in pre-packaged with the server could lend me in some issues I believe?</p>
<p><strong>-</strong> It should <strong>not</strong> be a cloud databases service, since for this project, I would like to allow &quot;modding&quot; of private servers.</p>
<p><strong>-</strong> Relatively scalable, nothing amazing, just something simple yet effective. I like the idea to allow my users the choice to deploy the server software on more than one system with the option to either run a new map or chain to an existing as a slave/cluster thingy, for map chunk loading/dynamic load bearing for busy areas of the map.</p>
<p><strong>-</strong> It needs to deal with large-ish amounts of information fast. I'm not expecting a lot of users, but I am expecting large volumes of data per user. Even if that's not the case its better to prepared rather than walk out with your pants down. I don't want to fix problems I can avoid.</p>
<p><strong>-</strong> Forgiving enough to deal with a game development process filled with possible changes in data etc.</p>
<p><strong>-</strong> Reliable data querying. The map, other than stellar drift and celestial orbits, should be relatively static. And it will become an issue if many users on the same map start looking up planets or stars all at the same time.</p>
<p>############</p>
<p>That's all I can think of for now, and will keep updated if I think of anything else.</p>
<p>So far, for all I could know (which I don't) a standard old style SQL could be the ticket and I'm just making work for myself, but with all the new technology out, like NoSQL and NewSQL, its hard to know what will be the better option for my circumstances. My experience with Databases can be pinned down to the classes done on MySQL and the research I've done recently, so I'm not familiar with the performance and abilities of other software.</p>
<p>So right now, my head is spinning, mystified from over research, and would like to know my options in specific databases engines on the market suitable for my situation.</p>
<p>So I take it to you, great people of stack overflow, please put me out my confusion!</p>
",37,0,0,3,database;server;game-development,2022-06-30 12:53:44,2022-06-30 12:53:44,2022-06-30 12:53:44,this is a bit text heavy  i apologise  there is a tldr below  intro to myself  i know you all probably heard the same story  guy wants to make a game etc  going into it semi blind  and dose not know much of what he s doing  i confess to be somewhat like this  next  i m terrible with terminology  and have a brain like a fish when i comes to long nouns  this is largely due to my  mild  dyslexia  so please forgive me  i did pre university computer science at collage some  years back  did some mysql  some vb net   windows forms are fun  and javascript  i ve been following along loosely since then  but haven t done much since then so am quite rusty  my level of skills can be called enthusiast at best  and muddle headedly incompetent at worst  been dabbling in c  since me and a friend use unity a lot  to by honest college was a little trauma inducing for me and soured my ability to code  minor fear stage fright  easily distracted   but to get over that i ve decided to head out on my own and make something for myself  whether i succeed with the project or not  no matter how big or small the project is  isn t important  just so long as i m creating something i m satisfied with and i can progress in my skills and learn  that is all the matters  the rest is just a bonus  with that in mind  i ve formulated a project i hope and believe will retain my interest long enough to get some education in  i want to make a space game  a massive space game  mostly  if not all procedural  but with realistic star counts spanning an entire galaxy  this can range from  thousand  to  trillion stars  i d like to go as far as t for stress levels then cap at    much like it is in real life  segue    k  ic    trillion   sounds nuts but games like space engine have already done this  and that was developed by one person  is this practical  i don t really care all that much if this is sort of game is practical or achievable  so long as its realistic ish on this aspect and a few others  plus  the thought of  this could work  you just have to be creative and put the effort in  attracts me  so what s the issue  why cant i use a normal save file  this issue comes when the game i m trying to make is somewhat similar to a x  its not exactly  but its close enough to know that there is a lot of information flying around  information that needs to be stored  synced and in some cases processed  on a small scale  a single home gaming computer can do this  so having a small single player is fine  however that s not what i want to achieve  the game i would like to create allows multiple people to play over long spans of time  across a galaxy  no matter what size that galaxy is  this is where i started my research  i need a way to store this information and so i looked up various database engines like postgresql  and others  i think to myself  for what i m doing as far as the world map is concerned  for the most part  a standard sql databased should be fine    right  my confidence started shaking when looking up what game devs are using these day    nosql  what on earth is this  why is google persistent on this  so i looked into it more  i then find out about newsql and realise i m starting to run around in circles  the rabbit hole i did descend  the flexibility of nosql is attractive  but when you see the lack of acid in terms of fast and reliable queries  if i ve read these articles right  i could be wrong   is a massive downside if your trying to look up  of a trillion stars or  of a quadrillion planets on the map in a fast manner  this is also not taking into account the fact a game is running along side it  sending and creating new data all the time  now i could be making a big issue about all this  as my scale of work might me too small to effect even the slow of systems  but how can i really know  there s also the issue that  i don t know for sure  that somewhere down the line i ll need to create a new datatype for some new feature i create  and go mess things up in my existing test data because the database is old sql  and you kinda have to deal with a ridged schema  what i need that flexibility to mess around and not worry a table somewhere is going to break  or that i have to bloat the db with empty or null to non applicable entries  why am i messing around with db s before the actual game  well if i cant even create the chess board before i can play chess  there s no point trying to invent chess really    i can make things look pretty later  i need the data first to manipulate    tl dr    i leu of everything mentioned  i ve compiled a small shopping list of a what i m looking for to store my data    must allow me to integrate into a single application  so my end users can deploy their own privet servers  in a relatively simple manner  what i mean by this  is more a licensing thing  and the easy of integration use  simply dragging up some opensource software and stuff it in pre packaged with the server could lend me in some issues i believe    it should not be a cloud databases service  since for this project  i would like to allow  modding  of private servers    relatively scalable  nothing amazing  just something simple yet effective  i like the idea to allow my users the choice to deploy the server software on more than one system with the option to either run a new map or chain to an existing as a slave cluster thingy  for map chunk loading dynamic load bearing for busy areas of the map    it needs to deal with large ish amounts of information fast  i m not expecting a lot of users  but i am expecting large volumes of data per user  even if that s not the case its better to prepared rather than walk out with your pants down  i don t want to fix problems i can avoid    forgiving enough to deal with a game development process filled with possible changes in data etc    reliable data querying  the map  other than stellar drift and celestial orbits  should be relatively static  and it will become an issue if many users on the same map start looking up planets or stars all at the same time               that s all i can think of for now  and will keep updated if i think of anything else  so far  for all i could know  which i don t  a standard old style sql could be the ticket and i m just making work for myself  but with all the new technology out  like nosql and newsql  its hard to know what will be the better option for my circumstances  my experience with databases can be pinned down to the classes done on mysql and the research i ve done recently  so i m not familiar with the performance and abilities of other software  so right now  my head is spinning  mystified from over research  and would like to know my options in specific databases engines on the market suitable for my situation  so i take it to you  great people of stack overflow  please put me out my confusion ,my game requires a database  both for official servers and private  but which one should i get 
154,1270812,11931906,Wait for &quot;return value&quot; from Javascript modal,"<p>OK, I'm by no means a JavaScript guru, and perhaps I'm still thinking in terms of Desktop software development, but this is what I'm trying to achieve :</p>

<ul>
<li>I'm using <a href=""http://twitter.github.com/bootstrap/javascript.html#modals"">Twitter Bootstrap's Modals</a></li>
<li>In some cases, before an action takes place, I want to verify it with a ""Are you sure?"" (Yes/No) Modal Dialog.</li>
</ul>

<p><strong>Question :</strong></p>

<ul>
<li>What should the inner logic be?</li>
</ul>

<p><strong>I mean :</strong></p>

<ul>
<li>User clicks buttonA (which ultimately performs actionA)</li>
<li>I want to launch the modal, wait for the input (either of the 2 buttons - yes/no) and/or pass it to some checking routine before performing(or not) actionA</li>
</ul>

<p>This my HTML code for the modal (should the buttons be - somehow - acting via their <code>onclick</code> javascript routines?) - also note that <code>#confirmMessage</code> is going to be variable.</p>

<pre><code>&lt;div class=""modal fade hide"" id=""confirmAlert""&gt;
    &lt;div class=""modal-header""&gt;
        &lt;button type=""button"" class=""close"" data-dismiss=""modal""&gt;x&lt;/button&gt;
        &lt;h3 id=""confirmTitle""&gt;Are you sure?&lt;/h3&gt;
    &lt;/div&gt;

    &lt;div class=""modal-body""&gt;
        &lt;p id=""confirmMessage""&gt;Body&lt;/p&gt;
    &lt;/div&gt;
    &lt;div class=""modal-footer""&gt;
        &lt;a href=""#"" class=""btn"" data-dismiss=""modal""&gt;Cancel&lt;/a&gt;
        &lt;a href=""#"" class=""btn btn-danger""&gt;Yes&lt;/a&gt;
    &lt;/div&gt;
&lt;/div&gt;
</code></pre>

<hr>

<p><strong>Just an idea:</strong></p>

<ul>
<li>Write a function like <code>checkBeforeExec(message,functionToExec)</code></li>
<li>Set <code>#confirmMessage</code> to message and Yes' href to <code>javascript:functionToExec</code></li>
<li>Makes sense?</li>
</ul>

<hr>

<p>I know it may sound a bit confusing - but I simply do not know what the most javascript-friendly way to do this would be...</p>
",35561,3,17,5,javascript;jquery;html;twitter-bootstrap;modal-dialog,2012-08-13 12:53:41,2012-08-13 12:53:41,2022-06-30 08:15:46,ok  i m by no means a javascript guru  and perhaps i m still thinking in terms of desktop software development  but this is what i m trying to achieve   question   i mean   this my html code for the modal  should the buttons be   somehow   acting via their onclick javascript routines     also note that  confirmmessage is going to be variable  just an idea  i know it may sound a bit confusing   but i simply do not know what the most javascript friendly way to do this would be   ,wait for  return value  from javascript modal
155,19431988,72781537,Jquery Autocomplete custom column filtering not working,"<p>I am trying to create a text dropdown with autocomplete feature to filter the fields.But it's not working properly. The custom filter search function is also calling the previous filter value.Code working for the static data but not for dynamic input text box data.</p>
<p>Here is the HTML code:</p>
<pre><code>&lt;head&gt; 

&lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.js&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt; 

&lt;link href=&quot;https://code.jquery.com/ui/1.10.2/themes/smoothness/jquery-ui.css&quot; rel=&quot;Stylesheet&quot;&gt; 

&lt;script src=&quot;https://code.jquery.com/ui/1.10.2/jquery-ui.js&quot; &gt;&lt;/script&gt; 

&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.datatables.net/1.10.12/css/jquery.dataTables.min.css&quot; /&gt; 

&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.datatables.net/1.10.15/js/jquery.dataTables.min.js&quot;&gt;&lt;/script&gt; 


&lt;script src=&quot;fil2.js&quot;&gt;&lt;/script&gt; 

&lt;link rel=&quot;stylesheet&quot; href=&quot;filter_css.css&quot;&gt; 

&lt;/head&gt; 

&lt;body&gt; 
&lt;table id=&quot;example&quot; class=&quot;display&quot; cellspacing=&quot;0&quot; width=&quot;100%&quot;&gt; 
    &lt;form&gt;
    &lt;thead&gt; 
        
        &lt;tr&gt; 

            &lt;th&gt;Name&lt;/th&gt; 

            &lt;th&gt;Position&lt;/th&gt; 

            &lt;th&gt;Office&lt;/th&gt; 

            &lt;th&gt;Age&lt;/th&gt; 

            &lt;th&gt;Start date&lt;/th&gt; 

            &lt;th&gt;Salary&lt;/th&gt; 

        &lt;/tr&gt; 
        
    &lt;/thead&gt; 

     

    &lt;tbody&gt; 
        
        &lt;tr&gt; 

            &lt;td&gt;&lt;input type=&quot;text&quot; value=&quot;Tiger&quot;&gt;&lt;/td&gt; 

            &lt;td&gt;&lt;input type=&quot;text&quot; value=&quot;System Architect&quot;&gt;&lt;/td&gt; 

            &lt;td&gt;Edinburgh&lt;/td&gt; 

            &lt;td&gt;61&lt;/td&gt; 

            &lt;td&gt;2011/04/25&lt;/td&gt; 

            &lt;td&gt;$320,800&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Garrett Winters&lt;/td&gt; 

            &lt;td&gt;Accountant&lt;/td&gt; 

            &lt;td&gt;Tokyo&lt;/td&gt; 

            &lt;td&gt;63&lt;/td&gt; 

            &lt;td&gt;2011/07/25&lt;/td&gt; 

            &lt;td&gt;$170,750&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Ashton Cox&lt;/td&gt; 

            &lt;td&gt;Junior Technical Author&lt;/td&gt; 

            &lt;td&gt;San Francisco&lt;/td&gt; 

            &lt;td&gt;66&lt;/td&gt; 

            &lt;td&gt;2009/01/12&lt;/td&gt; 

            &lt;td&gt;$86,000&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Cedric Kelly&lt;/td&gt; 

            &lt;td&gt;Senior Javascript Developer&lt;/td&gt; 

            &lt;td&gt;Edinburgh&lt;/td&gt; 

            &lt;td&gt;22&lt;/td&gt; 

            &lt;td&gt;2012/03/29&lt;/td&gt; 

            &lt;td&gt;$433,060&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Airi Satou&lt;/td&gt; 

            &lt;td&gt;Accountant&lt;/td&gt; 

            &lt;td&gt;Tokyo&lt;/td&gt; 

            &lt;td&gt;33&lt;/td&gt; 

            &lt;td&gt;2008/11/28&lt;/td&gt; 

            &lt;td&gt;$162,700&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Brielle Williamson&lt;/td&gt; 

            &lt;td&gt;Integration Specialist&lt;/td&gt; 

            &lt;td&gt;New York&lt;/td&gt; 

            &lt;td&gt;61&lt;/td&gt; 

            &lt;td&gt;2012/12/02&lt;/td&gt; 

            &lt;td&gt;$372,000&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Herrod Chandler&lt;/td&gt; 

            &lt;td&gt;Sales Assistant&lt;/td&gt; 

            &lt;td&gt;San Francisco&lt;/td&gt; 

            &lt;td&gt;59&lt;/td&gt; 

            &lt;td&gt;2012/08/06&lt;/td&gt; 

            &lt;td&gt;$137,500&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Rhona Davidson&lt;/td&gt; 

            &lt;td&gt;Integration Specialist&lt;/td&gt; 

            &lt;td&gt;Tokyo&lt;/td&gt; 

            &lt;td&gt;55&lt;/td&gt; 

            &lt;td&gt;2010/10/14&lt;/td&gt; 

            &lt;td&gt;$327,900&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Colleen Hurst&lt;/td&gt; 

            &lt;td&gt;Javascript Developer&lt;/td&gt; 

            &lt;td&gt;San Francisco&lt;/td&gt; 

            &lt;td&gt;39&lt;/td&gt; 

            &lt;td&gt;2009/09/15&lt;/td&gt; 

            &lt;td&gt;$205,500&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Sonya Frost&lt;/td&gt; 

            &lt;td&gt;Software Engineer&lt;/td&gt; 

            &lt;td&gt;Edinburgh&lt;/td&gt; 

            &lt;td&gt;23&lt;/td&gt; 

            &lt;td&gt;2008/12/13&lt;/td&gt; 

            &lt;td&gt;$103,600&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Jena Gaines&lt;/td&gt; 

            &lt;td&gt;Office Manager&lt;/td&gt; 

            &lt;td&gt;London&lt;/td&gt; 

            &lt;td&gt;30&lt;/td&gt; 

            &lt;td&gt;2008/12/19&lt;/td&gt; 

            &lt;td&gt;$90,560&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Quinn Flynn&lt;/td&gt; 

            &lt;td&gt;Support Lead&lt;/td&gt; 

            &lt;td&gt;Edinburgh&lt;/td&gt; 

            &lt;td&gt;22&lt;/td&gt; 

            &lt;td&gt;2013/03/03&lt;/td&gt; 

            &lt;td&gt;$342,000&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Charde Marshall&lt;/td&gt; 

            &lt;td&gt;Regional Director&lt;/td&gt; 

            &lt;td&gt;San Francisco&lt;/td&gt; 

            &lt;td&gt;36&lt;/td&gt; 

            &lt;td&gt;2008/10/16&lt;/td&gt; 

            &lt;td&gt;$470,600&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Haley Kennedy&lt;/td&gt; 

            &lt;td&gt;Senior Marketing Designer&lt;/td&gt; 

            &lt;td&gt;London&lt;/td&gt; 

            &lt;td&gt;43&lt;/td&gt; 

            &lt;td&gt;2012/12/18&lt;/td&gt; 

            &lt;td&gt;$313,500&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Tatyana Fitzpatrick&lt;/td&gt; 

            &lt;td&gt;Regional Director&lt;/td&gt; 

            &lt;td&gt;London&lt;/td&gt; 

            &lt;td&gt;19&lt;/td&gt; 

            &lt;td&gt;2010/03/17&lt;/td&gt; 

            &lt;td&gt;$385,750&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Michael Silva&lt;/td&gt; 

            &lt;td&gt;Marketing Designer&lt;/td&gt; 

            &lt;td&gt;London&lt;/td&gt; 

            &lt;td&gt;66&lt;/td&gt; 

            &lt;td&gt;2012/11/27&lt;/td&gt; 

            &lt;td&gt;$198,500&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Paul Byrd&lt;/td&gt; 

            &lt;td&gt;Chief Financial Officer (CFO)&lt;/td&gt; 

            &lt;td&gt;New York&lt;/td&gt; 

            &lt;td&gt;64&lt;/td&gt; 

            &lt;td&gt;2010/06/09&lt;/td&gt; 

            &lt;td&gt;$725,000&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Gloria Little&lt;/td&gt; 

            &lt;td&gt;Systems Administrator&lt;/td&gt; 

            &lt;td&gt;New York&lt;/td&gt; 

            &lt;td&gt;59&lt;/td&gt; 

            &lt;td&gt;2009/04/10&lt;/td&gt; 

            &lt;td&gt;$237,500&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Bradley Greer&lt;/td&gt; 

            &lt;td&gt;Software Engineer&lt;/td&gt; 

            &lt;td&gt;London&lt;/td&gt; 

            &lt;td&gt;41&lt;/td&gt; 

            &lt;td&gt;2012/10/13&lt;/td&gt; 

            &lt;td&gt;$132,000&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Dai Rios&lt;/td&gt; 

            &lt;td&gt;Personnel Lead&lt;/td&gt; 

            &lt;td&gt;Edinburgh&lt;/td&gt; 

            &lt;td&gt;35&lt;/td&gt; 

            &lt;td&gt;2012/09/26&lt;/td&gt; 

            &lt;td&gt;$217,500&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Jenette Caldwell&lt;/td&gt; 

            &lt;td&gt;Development Lead&lt;/td&gt; 

            &lt;td&gt;New York&lt;/td&gt; 

            &lt;td&gt;30&lt;/td&gt; 

            &lt;td&gt;2011/09/03&lt;/td&gt; 

            &lt;td&gt;$345,000&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Yuri Berry&lt;/td&gt; 

            &lt;td&gt;Chief Marketing Officer (CMO)&lt;/td&gt; 

            &lt;td&gt;New York&lt;/td&gt; 

            &lt;td&gt;40&lt;/td&gt; 

            &lt;td&gt;2009/06/25&lt;/td&gt; 

            &lt;td&gt;$675,000&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Caesar Vance&lt;/td&gt; 

            &lt;td&gt;Pre-Sales Support&lt;/td&gt; 

            &lt;td&gt;New York&lt;/td&gt; 

            &lt;td&gt;21&lt;/td&gt; 

            &lt;td&gt;2011/12/12&lt;/td&gt; 

            &lt;td&gt;$106,450&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Doris Wilder&lt;/td&gt; 

            &lt;td&gt;Sales Assistant&lt;/td&gt; 

            &lt;td&gt;Sidney&lt;/td&gt; 

            &lt;td&gt;23&lt;/td&gt; 

            &lt;td&gt;2010/09/20&lt;/td&gt; 

            &lt;td&gt;$85,600&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Angelica Ramos&lt;/td&gt; 

            &lt;td&gt;Chief Executive Officer (CEO)&lt;/td&gt; 

            &lt;td&gt;London&lt;/td&gt; 

            &lt;td&gt;47&lt;/td&gt; 

            &lt;td&gt;2009/10/09&lt;/td&gt; 

            &lt;td&gt;$1,200,000&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Gavin Joyce&lt;/td&gt; 

            &lt;td&gt;Developer&lt;/td&gt; 

            &lt;td&gt;Edinburgh&lt;/td&gt; 

            &lt;td&gt;42&lt;/td&gt; 

            &lt;td&gt;2010/12/22&lt;/td&gt; 

            &lt;td&gt;$92,575&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Jennifer Chang&lt;/td&gt; 

            &lt;td&gt;Regional Director&lt;/td&gt; 

            &lt;td&gt;Singapore&lt;/td&gt; 

            &lt;td&gt;28&lt;/td&gt; 

            &lt;td&gt;2010/11/14&lt;/td&gt; 

            &lt;td&gt;$357,650&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Brenden Wagner&lt;/td&gt; 

            &lt;td&gt;Software Engineer&lt;/td&gt; 

            &lt;td&gt;San Francisco&lt;/td&gt; 

            &lt;td&gt;28&lt;/td&gt; 

            &lt;td&gt;2011/06/07&lt;/td&gt; 

            &lt;td&gt;$206,850&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Fiona Green&lt;/td&gt; 

            &lt;td&gt;Chief Operating Officer (COO)&lt;/td&gt; 

            &lt;td&gt;San Francisco&lt;/td&gt; 

            &lt;td&gt;48&lt;/td&gt; 

            &lt;td&gt;2010/03/11&lt;/td&gt; 

            &lt;td&gt;$850,000&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Shou Itou&lt;/td&gt; 

            &lt;td&gt;Regional Marketing&lt;/td&gt; 

            &lt;td&gt;Tokyo&lt;/td&gt; 

            &lt;td&gt;20&lt;/td&gt; 

            &lt;td&gt;2011/08/14&lt;/td&gt; 

            &lt;td&gt;$163,000&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Michelle House&lt;/td&gt; 

            &lt;td&gt;Integration Specialist&lt;/td&gt; 

            &lt;td&gt;Sidney&lt;/td&gt; 

            &lt;td&gt;37&lt;/td&gt; 

            &lt;td&gt;2011/06/02&lt;/td&gt; 

            &lt;td&gt;$95,400&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Suki Burks&lt;/td&gt; 

            &lt;td&gt;Developer&lt;/td&gt; 

            &lt;td&gt;London&lt;/td&gt; 

            &lt;td&gt;53&lt;/td&gt; 

            &lt;td&gt;2009/10/22&lt;/td&gt; 

            &lt;td&gt;$114,500&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Prescott Bartlett&lt;/td&gt; 

            &lt;td&gt;Technical Author&lt;/td&gt; 

            &lt;td&gt;London&lt;/td&gt; 

            &lt;td&gt;27&lt;/td&gt; 

            &lt;td&gt;2011/05/07&lt;/td&gt; 

            &lt;td&gt;$145,000&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Gavin Cortez&lt;/td&gt; 

            &lt;td&gt;Team Leader&lt;/td&gt; 

            &lt;td&gt;San Francisco&lt;/td&gt; 

            &lt;td&gt;22&lt;/td&gt; 

            &lt;td&gt;2008/10/26&lt;/td&gt; 

            &lt;td&gt;$235,500&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Martena Mccray&lt;/td&gt; 

            &lt;td&gt;Post-Sales support&lt;/td&gt; 

            &lt;td&gt;Edinburgh&lt;/td&gt; 

            &lt;td&gt;46&lt;/td&gt; 

            &lt;td&gt;2011/03/09&lt;/td&gt; 

            &lt;td&gt;$324,050&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Unity Butler&lt;/td&gt; 

            &lt;td&gt;Marketing Designer&lt;/td&gt; 

            &lt;td&gt;San Francisco&lt;/td&gt; 

            &lt;td&gt;47&lt;/td&gt; 

            &lt;td&gt;2009/12/09&lt;/td&gt; 

            &lt;td&gt;$85,675&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Howard Hatfield&lt;/td&gt; 

            &lt;td&gt;Office Manager&lt;/td&gt; 

            &lt;td&gt;San Francisco&lt;/td&gt; 

            &lt;td&gt;51&lt;/td&gt; 

            &lt;td&gt;2008/12/16&lt;/td&gt; 

            &lt;td&gt;$164,500&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Hope Fuentes&lt;/td&gt; 

            &lt;td&gt;Secretary&lt;/td&gt; 

            &lt;td&gt;San Francisco&lt;/td&gt; 

            &lt;td&gt;41&lt;/td&gt; 

            &lt;td&gt;2010/02/12&lt;/td&gt; 

            &lt;td&gt;$109,850&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Vivian Harrell&lt;/td&gt; 

            &lt;td&gt;Financial Controller&lt;/td&gt; 

            &lt;td&gt;San Francisco&lt;/td&gt; 

            &lt;td&gt;62&lt;/td&gt; 

            &lt;td&gt;2009/02/14&lt;/td&gt; 

            &lt;td&gt;$452,500&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Timothy Mooney&lt;/td&gt; 

            &lt;td&gt;Office Manager&lt;/td&gt; 

            &lt;td&gt;London&lt;/td&gt; 

            &lt;td&gt;37&lt;/td&gt; 

            &lt;td&gt;2008/12/11&lt;/td&gt; 

            &lt;td&gt;$136,200&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Jackson Bradshaw&lt;/td&gt; 

            &lt;td&gt;Director&lt;/td&gt; 

            &lt;td&gt;New York&lt;/td&gt; 

            &lt;td&gt;65&lt;/td&gt; 

            &lt;td&gt;2008/09/26&lt;/td&gt; 

            &lt;td&gt;$645,750&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Olivia Liang&lt;/td&gt; 

            &lt;td&gt;Support Engineer&lt;/td&gt; 

            &lt;td&gt;Singapore&lt;/td&gt; 

            &lt;td&gt;64&lt;/td&gt; 

            &lt;td&gt;2011/02/03&lt;/td&gt; 

            &lt;td&gt;$234,500&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Bruno Nash&lt;/td&gt; 

            &lt;td&gt;Software Engineer&lt;/td&gt; 

            &lt;td&gt;London&lt;/td&gt; 

            &lt;td&gt;38&lt;/td&gt; 

            &lt;td&gt;2011/05/03&lt;/td&gt; 

            &lt;td&gt;$163,500&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Sakura Yamamoto&lt;/td&gt; 

            &lt;td&gt;Support Engineer&lt;/td&gt; 

            &lt;td&gt;Tokyo&lt;/td&gt; 

            &lt;td&gt;37&lt;/td&gt; 

            &lt;td&gt;2009/08/19&lt;/td&gt; 

            &lt;td&gt;$139,575&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Thor Walton&lt;/td&gt; 

            &lt;td&gt;Developer&lt;/td&gt; 

            &lt;td&gt;New York&lt;/td&gt; 

            &lt;td&gt;61&lt;/td&gt; 

            &lt;td&gt;2013/08/11&lt;/td&gt; 

            &lt;td&gt;$98,540&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Finn Camacho&lt;/td&gt; 

            &lt;td&gt;Support Engineer&lt;/td&gt; 

            &lt;td&gt;San Francisco&lt;/td&gt; 

            &lt;td&gt;47&lt;/td&gt; 

            &lt;td&gt;2009/07/07&lt;/td&gt; 

            &lt;td&gt;$87,500&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Serge Baldwin&lt;/td&gt; 

            &lt;td&gt;Data Coordinator&lt;/td&gt; 

            &lt;td&gt;Singapore&lt;/td&gt; 

            &lt;td&gt;64&lt;/td&gt; 

            &lt;td&gt;2012/04/09&lt;/td&gt; 

            &lt;td&gt;$138,575&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Zenaida Frank&lt;/td&gt; 

            &lt;td&gt;Software Engineer&lt;/td&gt; 

            &lt;td&gt;New York&lt;/td&gt; 

            &lt;td&gt;63&lt;/td&gt; 

            &lt;td&gt;2010/01/04&lt;/td&gt; 

            &lt;td&gt;$125,250&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Zorita Serrano&lt;/td&gt; 

            &lt;td&gt;Software Engineer&lt;/td&gt; 

            &lt;td&gt;San Francisco&lt;/td&gt; 

            &lt;td&gt;56&lt;/td&gt; 

            &lt;td&gt;2012/06/01&lt;/td&gt; 

            &lt;td&gt;$115,000&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Jennifer Acosta&lt;/td&gt; 

            &lt;td&gt;Junior Javascript Developer&lt;/td&gt; 

            &lt;td&gt;Edinburgh&lt;/td&gt; 

            &lt;td&gt;43&lt;/td&gt; 

            &lt;td&gt;2013/02/01&lt;/td&gt; 

            &lt;td&gt;$75,650&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Cara Stevens&lt;/td&gt; 

            &lt;td&gt;Sales Assistant&lt;/td&gt; 

            &lt;td&gt;New York&lt;/td&gt; 

            &lt;td&gt;46&lt;/td&gt; 

            &lt;td&gt;2011/12/06&lt;/td&gt; 

            &lt;td&gt;$145,600&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Hermione Butler&lt;/td&gt; 

            &lt;td&gt;Regional Director&lt;/td&gt; 

            &lt;td&gt;London&lt;/td&gt; 

            &lt;td&gt;47&lt;/td&gt; 

            &lt;td&gt;2011/03/21&lt;/td&gt; 

            &lt;td&gt;$356,250&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Lael Greer&lt;/td&gt; 

            &lt;td&gt;Systems Administrator&lt;/td&gt; 

            &lt;td&gt;London&lt;/td&gt; 

            &lt;td&gt;21&lt;/td&gt; 

            &lt;td&gt;2009/02/27&lt;/td&gt; 

            &lt;td&gt;$103,500&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Jonas Alexander&lt;/td&gt; 

            &lt;td&gt;Developer&lt;/td&gt; 

            &lt;td&gt;San Francisco&lt;/td&gt; 

            &lt;td&gt;30&lt;/td&gt; 

            &lt;td&gt;2010/07/14&lt;/td&gt; 

            &lt;td&gt;$86,500&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Shad Decker&lt;/td&gt; 

            &lt;td&gt;Regional Director&lt;/td&gt; 

            &lt;td&gt;Edinburgh&lt;/td&gt; 

            &lt;td&gt;51&lt;/td&gt; 

            &lt;td&gt;2008/11/13&lt;/td&gt; 

            &lt;td&gt;$183,000&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Michael Bruce&lt;/td&gt; 

            &lt;td&gt;Javascript Developer&lt;/td&gt; 

            &lt;td&gt;Singapore&lt;/td&gt; 

            &lt;td&gt;29&lt;/td&gt; 

            &lt;td&gt;2011/06/27&lt;/td&gt; 

            &lt;td&gt;$183,000&lt;/td&gt; 

        &lt;/tr&gt; 

        &lt;tr&gt; 

            &lt;td&gt;Donna Snider&lt;/td&gt; 

            &lt;td&gt;Customer Support&lt;/td&gt; 

            &lt;td&gt;New York&lt;/td&gt; 

            &lt;td&gt;27&lt;/td&gt; 

            &lt;td&gt;2011/01/25&lt;/td&gt; 

            &lt;td&gt;$112,000&lt;/td&gt; 

        &lt;/tr&gt; 

    &lt;/tbody&gt; 
    &lt;/form&gt;
&lt;/table&gt; 
</code></pre>
 
<p>Here is the jquery code:</p>
<pre><code>$(document).ready(function(){


$('#example').DataTable({
    initComplete: function () {
        var allcolsData=$('#example').DataTable().columns().data();
        this.api()
        .columns()
        .every(function (){
            var column = this;
            var c_idx=column.index();
            var colData=allcolsData[c_idx];
            $.each(colData,function(i,v){
                    var p=v.split('value=&quot;');
                    if(p.length==1){
                        colData[i]=(p[0]);
                    }
                    else{
                        colData[i]=(p[1].split('&quot;&gt;')[0]);
                    }
            });
            colData=Array.from(new Set(colData)).sort();
            var select = $('&lt;input type=&quot;text&quot; /&gt;').appendTo($(column.header()))
            .autocomplete({
                source: colData,
                minLength: 0,
                scroll: true,
                close: function(event, ui)  {
                // Close event fires when selection options closes
                    $('input')[0].value = &quot;&quot;; // Clear the input field 
                }
            }).focus(function() {
                $(this).autocomplete(&quot;search&quot;, &quot;&quot;);
            })
            .on('autocompleteselect', function (e,ui) {
                
                //console.log(ui.item);
                    var filterValue = $.fn.dataTable.util.escapeRegex(ui.item.value);
                    console.log(filterValue);
                    $.fn.dataTable.ext.search.push(
                    function (settings, data, dataIndex) {
                        console.log(filterValue+new Date($.now()));
                        if(data[c_idx].indexOf(filterValue) != -1){
                            return true;
                        }
                        return false;
                        
                    });
                    column.draw();
                    
                    
            });
            

        });
        
    },
});});
</code></pre>
<p>Here is the codepen link- <a href=""https://codepen.io/prakshu/pen/JjLjdoJ"" rel=""nofollow noreferrer"">https://codepen.io/prakshu/pen/JjLjdoJ</a></p>
<p>Filter autocomplete work fine for first time but not next time.</p>
",37,1,0,4,html;jquery;datatable;jquery-ui-autocomplete,2022-06-28 09:17:37,2022-06-28 09:17:37,2022-06-29 12:10:17,i am trying to create a text dropdown with autocomplete feature to filter the fields but it s not working properly  the custom filter search function is also calling the previous filter value code working for the static data but not for dynamic input text box data  here is the html code  here is the jquery code  here is the codepen link   filter autocomplete work fine for first time but not next time ,jquery autocomplete custom column filtering not working
156,72437,64279211,Is it right to conform Hashable by only taking id into consideration?,"<p>A lot of online example I have came across, when they try to conform to <code>Hashable</code>, they only take <code>id</code> as consideration. For instance <a href=""https://www.raywenderlich.com/8241072-ios-tutorial-collection-view-and-diffable-data-source"" rel=""nofollow noreferrer"">https://www.raywenderlich.com/8241072-ios-tutorial-collection-view-and-diffable-data-source</a> , <a href=""https://medium.com/@JoyceMatos/hashable-protocols-in-swift-baf0cabeaebd"" rel=""nofollow noreferrer"">https://medium.com/@JoyceMatos/hashable-protocols-in-swift-baf0cabeaebd</a> , ...</p>
<pre><code>/// Copyright (c) 2020 Razeware LLC
/// 
/// Permission is hereby granted, free of charge, to any person obtaining a copy
/// of this software and associated documentation files (the &quot;Software&quot;), to deal
/// in the Software without restriction, including without limitation the rights
/// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
/// copies of the Software, and to permit persons to whom the Software is
/// furnished to do so, subject to the following conditions:
/// 
/// The above copyright notice and this permission notice shall be included in
/// all copies or substantial portions of the Software.
/// 
/// Notwithstanding the foregoing, you may not use, copy, modify, merge, publish,
/// distribute, sublicense, create a derivative work, and/or sell copies of the
/// Software in any work that is designed, intended, or marketed for pedagogical or
/// instructional purposes related to programming, coding, application development,
/// or information technology.  Permission for such use, copying, modification,
/// merger, publication, distribution, sublicensing, creation of derivative works,
/// or sale is expressly withheld.
/// 
/// THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
/// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
/// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
/// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
/// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
/// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
/// THE SOFTWARE.

import UIKit

class Video: Hashable {
  var id = UUID()
  var title: String
  var thumbnail: UIImage?
  var lessonCount: Int
  var link: URL?
  
  init(title: String, thumbnail: UIImage? = nil, lessonCount: Int, link: URL?) {
    self.title = title
    self.thumbnail = thumbnail
    self.lessonCount = lessonCount
    self.link = link
  }
  // 1
  func hash(into hasher: inout Hasher) {
    // 2
    hasher.combine(id)
  }
  // 3
  static func == (lhs: Video, rhs: Video) -&gt; Bool {
    lhs.id == rhs.id
  }
}
</code></pre>
<hr />
<p>I was wondering, is that ever a correct way to conform <code>Hashable</code>? I thought we should take all class member variables, into consideration?</p>
<p>For instance, by using only <code>id</code> in <code>func hash</code>/ <code>func ==</code>, will yield the following misbehaviour.</p>
<p>We are going encounter 2 objects with different content, but <code>func ==</code> will return true when comparing 2 objects with different content.</p>
<pre><code>struct Dog: Hashable {
    let id = UUID()
    var name: String
    var age: Int
    
    init(name: String, age: Int) {
        self.name = name
        self.age = age
    }

    func hash(into hasher: inout Hasher) {
        hasher.combine(id)
    }

    static func == (lhs: Dog, rhs: Dog) -&gt; Bool {
        lhs.id == rhs.id
    }
}


var dog0 = Dog(name: &quot;dog&quot;, age: 1)
var dog1 = dog0

/*
 dog0 is -5743610764084706839, dog, 1
 dog1 is -5743610764084706839, dog, 1
 compare dog0 with dog1 is true
 */
print(&quot;dog0 is \(dog0.hashValue), \(dog0.name), \(dog0.age)&quot;)
print(&quot;dog1 is \(dog1.hashValue), \(dog1.name), \(dog1.age)&quot;)
print(&quot;compare dog0 with dog1 is \(dog0 == dog1)&quot;)


dog1.name = &quot;another name&quot;
dog1.age = 9

// Same id, but different content!

/*
 dog0 is -5743610764084706839, dog, 1
 dog1 is -5743610764084706839, another name, 9
 compare dog0 with dog1 is true
 */
print(&quot;dog0 is \(dog0.hashValue), \(dog0.name), \(dog0.age)&quot;)
print(&quot;dog1 is \(dog1.hashValue), \(dog1.name), \(dog1.age)&quot;)
print(&quot;compare dog0 with dog1 is \(dog0 == dog1)&quot;)
</code></pre>
<p>I was wondering, is it right to conform <code>Hashable</code> by only taking <code>id</code> into consideration?</p>
<hr />
<p><strong>p/s</strong></p>
<p>I try to look from other languages like Java, on what is the general advice regarding hash code generation . This is what is being written in their popular Effective Java book.</p>
<blockquote>
<p>Do not be tempted to exclude significant fields from the hash code
computation to improve performance. While the resulting hash function
may run faster, its poor quality may degrade hash tables’ performance
to the point where they become unusable. In particular, the hash
function may be confronted with a large collection of instances that
differ mainly in regions you’ve chosen to ignore. If this happens, the
hash function will map all these instances to a few hash codes, and
programs that should run in linear time will instead run in quadratic
time. This is not just a theoretical problem. Prior to Java 2, the
String hash function used at most sixteen characters evenly spaced
throughout the string, starting with the first character. For large
collections of hierarchical names, such as URLs, this function
displayed exactly the pathological behavior described earlier.</p>
</blockquote>
",2024,6,10,2,swift;hashable,2020-10-09 14:31:57,2020-10-09 14:31:57,2022-06-29 06:42:58,a lot of online example i have came across  when they try to conform to hashable  they only take id as consideration  for instance           i was wondering  is that ever a correct way to conform hashable  i thought we should take all class member variables  into consideration  for instance  by using only id in func hash  func     will yield the following misbehaviour  we are going encounter  objects with different content  but func    will return true when comparing  objects with different content  i was wondering  is it right to conform hashable by only taking id into consideration  p s i try to look from other languages like java  on what is the general advice regarding hash code generation   this is what is being written in their popular effective java book ,is it right to conform hashable by only taking id into consideration 
157,19418962,72760419,Flutter Web requests using http package failing due to CORS,"<h3>Background</h3>
<p>I am using <a href=""https://github.com/features/codespaces"" rel=""nofollow noreferrer"">GitHub Codespaces</a>, which does port forwarding for locally-hosted applications. So when I run <code>flutter run -d web-server --web-hostname 127.0.0. --web-port</code> the localhost URL is mirrored with a <code>githubpreview.dev</code> URL.</p>
<p>On the client side, I have a function to test the connection with the database:</p>
<pre class=""lang-dart prettyprint-override""><code>static Future&lt;bool&gt; testConnection() async {
    http.Response response = await _httpClient.get(
      Uri.parse(baseUrl + 'test'), // requestObject.slug.string
      headers: {
        HttpHeaders.authorizationHeader: 'Bearer 69',
        &quot;Access-Control-Allow-Origin&quot;: &quot;*&quot;,
        &quot;Access-Control-Allow-Credentials&quot;: &quot;true&quot;,
        &quot;Access-Control-Allow-Headers&quot;:
            &quot;Origin,Content-Type,X-Amz-Date,Authorization,X-Api-Key,X-Amz-Security-Token,locale&quot;,
        &quot;Access-Control-Allow-Methods&quot;: &quot;GET, POST, PUT, PATCH, DELETE, OPTIONS&quot;
      },
    );
</code></pre>
<p><code>_httpClient</code> is a wrapper over <code>HttpClient()</code>.
On the server side, I have the function as follows:</p>
<pre class=""lang-js prettyprint-override""><code>export function use_test(request) {
    console.log(`test request:${request.headers.origin}`);
    let options = {
        &quot;headers&quot;:{
            &quot;Access-Control-Allow-Origin&quot;: &quot;*&quot;,
            &quot;Access-Control-Allow-Credentials&quot;: &quot;true&quot;,
            &quot;Access-Control-Allow-Headers&quot;:
                &quot;Origin,Content-Type,X-Amz-Date,Authorization,X-Api-Key,X-Amz-Security-Token,locale&quot;,
            &quot;Access-Control-Allow-Methods&quot;:
                &quot;GET, POST, PUT, PATCH, DELETE, OPTIONS&quot;
          },
        &quot;body&quot;: {
            &quot;payload&quot;: {
                &quot;msg&quot;: request['headers']
            }
        }
    };
    return ok(options);
}
</code></pre>
<h3>Issue</h3>
<p>Whenever <code>testConnection</code> is run, the request is sent successfully, since the server logs the incoming request, but the response sent by the server is not received by the client, failing with an <code>XMLHttpRequestError</code>. Now, I have come across this error many times when writing Flutter Web applications, but this one stumps me. <a href=""https://stackoverflow.com/tags/postman/info"">Postman</a> can receive the data all right, so I'm pretty sure <a href=""https://en.wikipedia.org/wiki/Cross-origin_resource_sharing"" rel=""nofollow noreferrer"">CORS</a> is to blame for this issue.</p>
<h3>Additional Information</h3>
<p>Flutter doctor output:</p>
<pre class=""lang-none prettyprint-override""><code>[✓] Flutter (Channel master, 3.1.0-0.0.pre.1354, on Debian GNU/Linux 11 (bullseye) 5.4.0-1074-azure, locale
    en_US.UTF-8)
    • Flutter version 3.1.0-0.0.pre.1354 on channel master at /workspaces/Lighthouse-Web/flutter
    • Upstream repository https://github.com/flutter/flutter.git
    • Framework revision a30012b275 (3 days ago), 2022-06-22 17:04:07 -0700
    • Engine revision fc08bf45b0
    • Dart version 2.18.0 (build 2.18.0-216.0.dev)
    • DevTools version 2.14.0

[✗] Android toolchain - develop for Android devices
    ✗ Unable to locate Android SDK.
      Install Android Studio from: https://developer.android.com/studio/index.html
      On first launch it will assist you in installing the Android SDK components.
      (or visit https://flutter.dev/docs/get-started/install/linux#android-setup for detailed instructions).
      If the Android SDK has been installed to a custom location, please use
      `flutter config --android-sdk` to update to that location.


[✗] Chrome - develop for the web (Cannot find Chrome executable at google-chrome)
    ! Cannot find Chrome. Try setting CHROME_EXECUTABLE to a Chrome executable.

[✗] Linux toolchain - develop for Linux desktop
    ✗ clang++ is required for Linux development.
      It is likely available from your distribution (e.g.: apt install clang), or can be downloaded from
      https://releases.llvm.org/
    ✗ CMake is required for Linux development.
      It is likely available from your distribution (e.g.: apt install cmake), or can be downloaded from
      https://cmake.org/download/
    ✗ ninja is required for Linux development.
      It is likely available from your distribution (e.g.: apt install ninja-build), or can be downloaded from
      https://github.com/ninja-build/ninja/releases
    ✗ pkg-config is required for Linux development.
      It is likely available from your distribution (e.g.: apt install pkg-config), or can be downloaded from
      https://www.freedesktop.org/wiki/Software/pkg-config/

[!] Android Studio (not installed)
    • Android Studio not found; download from https://developer.android.com/studio/index.html
      (or visit https://flutter.dev/docs/get-started/install/linux#android-setup for detailed instructions).

[✓] Connected device (1 available)
    • Linux (desktop) • linux • linux-x64 • Debian GNU/Linux 11 (bullseye) 5.4.0-1074-azure

[✓] HTTP Host Availability
    • All required HTTP hosts are available

! Doctor found issues in 4 categories.
</code></pre>
<p>How can I fix this issue?</p>
",185,1,-1,4,dart;http;cors;flutter-web,2022-06-26 12:36:09,2022-06-26 12:36:09,2022-06-29 01:45:13,i am using   which does port forwarding for locally hosted applications  so when i run flutter run  d web server   web hostname       web port the localhost url is mirrored with a githubpreview dev url  on the client side  i have a function to test the connection with the database  whenever testconnection is run  the request is sent successfully  since the server logs the incoming request  but the response sent by the server is not received by the client  failing with an xmlhttprequesterror  now  i have come across this error many times when writing flutter web applications  but this one stumps me   can receive the data all right  so i m pretty sure  is to blame for this issue  flutter doctor output  how can i fix this issue ,flutter web requests using http package failing due to cors
158,14340000,72793227,Github Pages will not recognise json file,"<p>I'm quite new to software development, and have only uploaded student projects to GitHub Pages and Heroku previously.</p>
<p>I'm currently working on a commercial project for a friend's band, and thought I'd upload it to GitHub Pages first, and the once we were happy, we could upload it to the webhosting service they have chosen.</p>
<p>The page includes a repertoire section, which is populated from a JSON file. I can import the data fine locally, but it doesn't appear on the live GitHub Pages site.</p>
<p>I think it's because in order to import the file, GitHub thinks I'm using an absolute path.</p>
<pre><code>import data from &quot;/assets/csv/carnaby-repertoire.json&quot; assert { type: &quot;json&quot; };
</code></pre>
<p>However, when I remove the first '/' it doesn't work locally, or live.</p>
<p>Here is a screenshot of my folder structure:
<a href=""https://i.stack.imgur.com/NPiSw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NPiSw.png"" alt=""Here is a screenshot of my folder structure:"" /></a>
Will I have the same problem with other webhosts, or is this just a GitHub thing? I would be really grateful for any advice. Thanks so much!</p>
",32,0,0,3,json;deployment;github-pages,2022-06-29 00:15:40,2022-06-29 00:15:40,2022-06-29 00:15:40,i m quite new to software development  and have only uploaded student projects to github pages and heroku previously  i m currently working on a commercial project for a friend s band  and thought i d upload it to github pages first  and the once we were happy  we could upload it to the webhosting service they have chosen  the page includes a repertoire section  which is populated from a json file  i can import the data fine locally  but it doesn t appear on the live github pages site  i think it s because in order to import the file  github thinks i m using an absolute path  however  when i remove the first     it doesn t work locally  or live ,github pages will not recognise json file
159,6350693,70452051,NestJS cli very slow in Docker container on Windows with Visual Studio Code,"<p>The response from the <code>nest</code> cli command from NestJS (<code>npm i -g @nestjs/cli</code>) in a Docker Development container with Visual Studio Code on Windows 10 is suddenly very slow. At first it works fine but at some point, for instance after deleting a directory in the <code>src</code> folder, the <code>nest</code> command gets very slow.</p>
<p>Example:</p>
<pre><code>node ➜ /workspaces/Servers/terminal-server (master ✗) $ time nest --help

[...]

real    0m44.576s
user    0m6.239s
sys     0m4.407s

</code></pre>
<p>Yarn is used for the package manager. NPM is used to install nest cli globally (<code>npm i -g @nestjs/cli</code>):</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>Software</th>
<th>Version</th>
<th style=""text-align: center;"">Running in container</th>
<th style=""text-align: center;"">Running on W10 host</th>
</tr>
</thead>
<tbody>
<tr>
<td>NPM</td>
<td>8.1.2</td>
<td style=""text-align: center;"">X</td>
<td style=""text-align: center;""></td>
</tr>
<tr>
<td>NodeJS</td>
<td>v16.13.1</td>
<td style=""text-align: center;"">X</td>
<td style=""text-align: center;""></td>
</tr>
<tr>
<td>Yarn</td>
<td>1.22.15</td>
<td style=""text-align: center;"">X</td>
<td style=""text-align: center;""></td>
</tr>
<tr>
<td>Typescript</td>
<td>4.5.2</td>
<td style=""text-align: center;"">X</td>
<td style=""text-align: center;""></td>
</tr>
<tr>
<td>Nest</td>
<td>8.1.6</td>
<td style=""text-align: center;"">X</td>
<td style=""text-align: center;""></td>
</tr>
<tr>
<td>Visual Studio Code</td>
<td>1.63.2</td>
<td style=""text-align: center;""></td>
<td style=""text-align: center;"">X</td>
</tr>
<tr>
<td>Docker Desktop</td>
<td>4.3.1</td>
<td style=""text-align: center;""></td>
<td style=""text-align: center;"">X</td>
</tr>
</tbody>
</table>
</div>
<p>It looks like the line <code>const localCommandLoader = local_binaries_1.loadLocalBinCommandLoader();</code> in <code>/usr/local/share/npm-global/bin/nest</code> is causing the delay.</p>
<p>Edit:
Compiling is also very slow. As you can see, it started at 8:57:20 and finished at 9:00:17. And this is compiling the default scaffolding.</p>
<pre><code>[8:57:20 AM] Starting compilation in watch mode...

[8:59:43 AM] Found 0 errors. Watching for file changes.

[Nest] 5197  - 12/23/2021, 9:00:17 AM     LOG [NestFactory] Starting Nest application...
[Nest] 5197  - 12/23/2021, 9:00:17 AM     LOG [InstanceLoader] AppModule dependencies initialized +67ms
[Nest] 5197  - 12/23/2021, 9:00:17 AM     LOG [RoutesResolver] AppController {/}: +42ms
[Nest] 5197  - 12/23/2021, 9:00:17 AM     LOG [RouterExplorer] Mapped {/, GET} route +8ms
[Nest] 5197  - 12/23/2021, 9:00:17 AM     LOG [NestApplication] Nest application successfully started +8ms
</code></pre>
<p>I did the same on WSL:</p>
<pre><code>[10:03:48 AM] Starting compilation in watch mode...

[10:03:53 AM] Found 0 errors. Watching for file changes.

[Nest] 1998  - 12/23/2021, 10:03:54 AM     LOG [NestFactory] Starting Nest application...
[Nest] 1998  - 12/23/2021, 10:03:54 AM     LOG [InstanceLoader] AppModule dependencies initialized +62ms
[Nest] 1998  - 12/23/2021, 10:03:54 AM     LOG [RoutesResolver] AppController {/}: +14ms
[Nest] 1998  - 12/23/2021, 10:03:54 AM     LOG [RouterExplorer] Mapped {/, GET} route +6ms
[Nest] 1998  - 12/23/2021, 10:03:54 AM     LOG [NestApplication] Nest application successfully started +9ms
</code></pre>
<p>For the Docker image I've selected the <code>Node.js &amp; TypeScript</code> image. Would it be better to just use a plain image and install everything manually?</p>
<p>Or is there a way to get the response time of <code>nest</code> normal again?</p>
",877,1,4,3,docker;visual-studio-code;nestjs,2021-12-22 18:15:54,2021-12-22 18:15:54,2022-06-28 16:31:41,the response from the nest cli command from nestjs  npm i  g  nestjs cli  in a docker development container with visual studio code on windows  is suddenly very slow  at first it works fine but at some point  for instance after deleting a directory in the src folder  the nest command gets very slow  example  yarn is used for the package manager  npm is used to install nest cli globally  npm i  g  nestjs cli   it looks like the line const localcommandloader   local_binaries_ loadlocalbincommandloader    in  usr local share npm global bin nest is causing the delay  i did the same on wsl  for the docker image i ve selected the node js  amp  typescript image  would it be better to just use a plain image and install everything manually  or is there a way to get the response time of nest normal again ,nestjs cli very slow in docker container on windows with visual studio code
160,9170283,72785726,Laravel Model&#39;s custom column name,"<p>I'm developing a new software that will eventually replace an old one, still in production.
The new software needs to access old's DB for specific models that will (in the future, not at this stage) will be replaced to local ones, but I'm developing using a naming scheme in English, and the old DB is in Spanish.</p>
<p>As an example, this is one of the models' class</p>
<pre><code>class Country extends Model
{
    use HasFactory;

    // inherited table

    protected $connection = 'relevamiento';
    protected $table = 'pais';
    public $timestamps = false;

    protected $fillable = [
        'name',
        'code'
    ];

    protected $rules = [
        'name' =&gt; 'required|string:max:255',
        'code' =&gt; 'required|string:max:2'
    ];

    public function getNameAttribute()
    {
        return $this-&gt;nombre;
    }

    public function setNameAttribute($name)
    {
        $this-&gt;nombre = $name;
    }

    public function getCodeAttribute()
    {
        return $this-&gt;codigo31662;
    }

    public function setCodeAttribute($code)
    {
        $this-&gt;codigo31662 = $code;
    }

}
</code></pre>
<p>It works great, until I search by Name:</p>
<pre><code>&gt;&gt;&gt; \App\Models\Country::first()
=&gt; App\Models\Country {#3980
     id: 1,
     nombre: &quot;Argentina&quot;,
     codigo31662: &quot;AR&quot;,
   }

&gt;&gt;&gt; \App\Models\Country::first()-&gt;name
=&gt; &quot;Argentina&quot;

&gt;&gt;&gt; \App\Models\Country::first()-&gt;code
=&gt; &quot;AR&quot;

&gt;&gt;&gt; \App\Models\Country::where('name', 'Uruguay')-&gt;get()
Illuminate\Database\QueryException with message 'SQLSTATE[42S22]: Column not found: 1054 Unknown column 'name' in 'where clause' (SQL: select * from `pais` where `name` = Uruguay)'
&gt;&gt;&gt; 
</code></pre>
<p>Is there a way to stay that the model's name attribute is the 'nombre' column?</p>
<p>The idea is, in the near future, make a migration to pull all the inherited info to local database, with the correct attribute/column's names, and in the mean time make all the related development using them (to make easier the switch in the future).</p>
<p>Thanks</p>
",55,1,0,3,laravel;eloquent;customcolumn,2022-06-28 14:39:01,2022-06-28 14:39:01,2022-06-28 15:01:01,as an example  this is one of the models  class it works great  until i search by name  is there a way to stay that the model s name attribute is the  nombre  column  the idea is  in the near future  make a migration to pull all the inherited info to local database  with the correct attribute column s names  and in the mean time make all the related development using them  to make easier the switch in the future   thanks,laravel model   s custom column name
161,753451,72785336,How to make ts-loader import correctly .web and .native files from a single import?,"<p>In our react app we have shared code between web and mobile (React Native).</p>
<p>Before Typescript it was okay to import it like this:
<code>import {fetchNotificationsSettingsFromLocalStorage} from '../helpers/notificationsSettingsStorage';</code></p>
<p>Even though we have two files at that location with suffixes - <code>notificationsSettingsStorage.native.js</code> and <code>notificationsSettingsStorage.web.js</code>.</p>
<p>Now we added TS-loader and it seems to not being able to resolve those.
How do I fix it?</p>
<p>webpack.config.js:</p>
<pre class=""lang-js prettyprint-override""><code>module.exports = {
  module: {
    rules: [
      {
        test: /\.(js|jsx|web\.js)$/,
        exclude: /node_modules/,
        use: {
          loader: 'babel-loader',
          options: {
            configFile: false,
            presets:
              process.env.WDYR === 'true'
                ? [
                    '@babel/preset-env',
                    [
                      '@babel/preset-react',
                      {
                        runtime: 'automatic',
                        development: true,
                        importSource: '@welldone-software/why-did-you-render',
                      },
                    ],
                  ]
                : [
                    [
                      '@babel/preset-env',
                      {
                        targets: '&gt;0.5%',
                      },
                    ],
                    '@babel/preset-react',
                  ],
            plugins: [
              '@babel/plugin-transform-runtime',
              ['@babel/plugin-proposal-decorators', {legacy: true}],
              '@babel/plugin-proposal-class-properties',
            ],
          },
        },
      },
      {
        test: /\.(ts|tsx)$/,
        exclude: /node_modules/,
        use: {
          loader: 'ts-loader',
        },
      },
      {
        test: /\.html$/,
        use: [
          {
            loader: 'html-loader',
          },
        ],
      },
      {
        test: /\.css$/i,
        use: [
          {
            loader: 'style-loader',
          },
          {
            loader: 'css-loader',
          },
        ],
      },
      {
        test: /\.(woff(2)?|ttf|eot|svg)(\?v=\d+\.\d+\.\d+)?$/,
        exclude: /node_modules/,
        use: [
          {
            loader: 'file-loader',
            options: {
              name: '[name].[ext]',
              outputPath: 'fonts/',
            },
          },
        ],
      },
      {
        test: /\.(png|jpg)(\?v=\d+\.\d+\.\d+)?$/,
        exclude: /node_modules/,
        use: [
          {
            loader: 'file-loader',
            options: {
              name: '[name].[ext]',
              outputPath: 'images/',
            },
          },
        ],
      },
      {
        test: /\.(wav|ogg)$/,
        exclude: /node_modules/,
        use: [
          {
            loader: 'file-loader',
            options: {
              name: '[name].[ext]',
              outputPath: 'sounds/',
            },
          },
        ],
      },
    ],
  },
  resolve: {
    extensions: ['.js', '.ts', '.tsx', '.web.js', '.json', 'css', 'woff', 'ttf', 'eot', 'svg'],
    alias: {
      'react-redux': process.env.WDYR === 'true' ? 'react-redux/lib' : 'react-redux',
    },
  },
};
</code></pre>
",19,0,0,5,reactjs;typescript;react-native;webpack;ts-loader,2022-06-28 14:06:34,2022-06-28 14:06:34,2022-06-28 14:06:34,in our react app we have shared code between web and mobile  react native   even though we have two files at that location with suffixes   notificationssettingsstorage native js and notificationssettingsstorage web js  webpack config js ,how to make ts loader import correctly  web and  native files from a single import 
162,1407658,72785185,Move Visual Studio 2022 to Another Drive after Installation without Reinstalling,"<p>A couple of months back, most probably in November last year, I had to install Microsoft Visual Studio on a drive(D) other than C because my C drive did not have enough space to host the software. Two weeks ago I cleaned up my C drive and now I want to move the Visual Studio installation to the C drive because the C drive is located on an SSD drive, and the other drives are on HDD.</p>
<p><a href=""https://i.stack.imgur.com/UZOfV.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/UZOfV.png"" alt=""ms-vs-2022-installation-current-location"" /></a></p>
<p>The <a href=""https://docs.microsoft.com/en-us/visualstudio/install/change-installation-locations?view=vs-2022"" rel=""nofollow noreferrer"">Microsoft Official Document reference</a> says that I have to reinstall my Visual Studio. But always there are some exceptional experiences for the users other than the official documentation statements.</p>
<p><a href=""https://i.stack.imgur.com/CodjT.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/CodjT.png"" alt=""ms-doc-ref"" /></a></p>
<p>One very important cause for my avoiding this reinstallation is, that I live in such a corner of the globe where 30GB will take me like 3 to 4 days to download. Moreover, it will also hamper regular tasks and the custom settings and tweaks I have applied to my development environment.
That's why I am writing this to avail community help if anyone has ever experienced such an issue and solved it anyhow.</p>
",54,0,1,2,visual-studio;visual-studio-2022,2022-06-28 13:56:17,2022-06-28 13:56:17,2022-06-28 13:56:17,a couple of months back  most probably in november last year  i had to install microsoft visual studio on a drive d  other than c because my c drive did not have enough space to host the software  two weeks ago i cleaned up my c drive and now i want to move the visual studio installation to the c drive because the c drive is located on an ssd drive  and the other drives are on hdd   the  says that i have to reinstall my visual studio  but always there are some exceptional experiences for the users other than the official documentation statements  ,move visual studio  to another drive after installation without reinstalling
163,7381844,72782543,What causes a server to close a TCP/IP connection abruptly with a Reset (RST Flag)?,"<h3>TL;DR</h3>
<p>For quite some time we are facing a weird issue with all of our systems (including Prod!). On a regular basis the TCP-connection to the server is closed abruptly by the server (or to be exact on the way from the server to the client).
This leads to failing requests and is most prominent in file uploads that always fail for bigger files (where bigger is just &gt;100kb).
Additionally the same requests fail much less frequently (but still fail sometimes!) if routed through an nginx reverse proxy.</p>
<h3>Setup</h3>
<p>We (let's call us <em>MyCompany</em>) are developing a software (a Java/Spring Boot service) for <em>CustomerCompany</em>. The software is shipped as a Docker container and hosted either locally, in a private cloud provided by <em>CloudCompany</em> or in two different Azure Kubernetes cluster.
The software communicates with an SAP-system hosted by <em>SAPHostingCompany</em>. There are actually multiple SAP-systems for different stages.</p>
<p>The software communicates (depending on stage/environment) either directly with the SAP-system or through an nginx reverse proxy (hosted on a machine of <em>MyCompany</em>).
The reasoning behind the nginx reverse proxy is that each IP communicating with the SAP-system has to be whitelisted by <em>SAPHostingCompany</em>. Especially for local development this would have been quite cumbersome to maintain.</p>
<h3>The problem</h3>
<p>Starting a few weeks back we noticed that sometimes requests fail (seemingly) randomly. This happens on all stages. <em>Supposedly</em> there were no changes whatsoever conducted that might have caused this change...</p>
<p>While this is quite an annoyance for most requests (that can just be retried if they failed) this completely prevents larger files from being uploaded. Larger meaning just &gt;100kb in this context.</p>
<p>We tried to investigate the problem and noticed in tcpdump that upon failure the server sends a TCP RST packet, thus aborting the connection (admittedly, we cannot be 100% sure whether it's the server itself sending the RST or some intermediate component).
This is sent at different stages within the TCP-connection so there is not one single packet (or packet-combination) that immediately causes the server to close the connection.</p>
<p>Most interestingly, this failure happens far less often (but still does!) in the setup with the intermediate nginx reverse proxy.</p>
<h3>Nginx Reverse proxy</h3>
<p>The nginx config looks like this:</p>
<p><div class=""snippet"" data-lang=""js"" data-hide=""true"" data-console=""false"" data-babel=""false"">
<div class=""snippet-code snippet-currently-hidden"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>events {
worker_connections 1024;
}

http {
log_format combined_with_requesttime '$remote_addr $host $remote_user [$time_local] ""$request"" $status $body_bytes_sent ""$http_referer"" ""$http_user_agent"" $request_time $upstream_response_time $pipe';
log_format combined_with_token '$remote_addr - $remote_user [$time_local] ""$request"" $status $body_bytes_sent ""$http_referer"" ""$http_user_agent"" ""$http_de_comdirect_cif_globalRequestId""';
log_format combined_with_token_host '$remote_addr $host $remote_user [$time_local] ""$request"" $status $body_bytes_sent ""$http_referer"" ""$http_user_agent"" ""$http_de_comdirect_cif_globalRequestId""';
log_format xcombined '$remote_addr - $remote_user [$time_local] ""$request"" $status $body_bytes_sent ""$http_referer"" ""$http_user_agent"" ""$ssl_client_s_dn""';

sendfile    on;
server_tokens on;
types_hash_max_size 1024;
types_hash_bucket_size 512;
server_names_hash_bucket_size 64;
server_names_hash_max_size 512;
keepalive_timeout  65;
tcp_nodelay        on;

client_max_body_size    10m;
client_body_buffer_size 128k;
proxy_redirect          off;
proxy_connect_timeout   90;
proxy_send_timeout      90;
proxy_read_timeout      90;
proxy_buffers           32 4k;
proxy_buffer_size       8k;
proxy_set_header        Host $host;
proxy_set_header        X-Real-IP $remote_addr;
proxy_set_header        X-Forwarded-For $proxy_add_x_forwarded_for;
proxy_headers_hash_bucket_size 64;

server {
    listen                0.0.0.0:8080 default_server;
    server_name           _;
    resolver              127.0.0.11 valid=30s;

    access_log            /dev/stdout combined_with_token_host;
    error_log             /dev/stdout debug;

    underscores_in_headers on; # Fuer Uebertragung der Header an SAP
    large_client_header_buffers 4 16k;
    proxy_buffer_size           16k;
    proxy_buffers               4 16k;
    real_ip_header              &lt;blurred&gt;;
    set_real_ip_from            0.0.0.0/0;

    location /sap1/ {
        rewrite ^ $request_uri;
        rewrite ^/sap1/(.*) $1 break;
        return 400; #if the second rewrite won't match
        proxy_pass            https://SAPHostingCompany.sap1:8043/$uri;
        proxy_read_timeout    130;
        proxy_connect_timeout 90;
        proxy_redirect        off;
        proxy_buffering       off;
        client_max_body_size  30m;
    }

    location /sap2/ {
        rewrite ^ $request_uri;
        rewrite ^/sap2/(.*) $1 break;
        return 400; #if the second rewrite won't match
        proxy_pass            https://SAPHostingCompany.sap2:8043/$uri;
        proxy_read_timeout    130;
        proxy_connect_timeout 90;
        proxy_redirect        off;
        proxy_buffering       off;
        client_max_body_size  50m;
    }

    location /sap3/ {
        rewrite ^ $request_uri;
        rewrite ^/sap3/(.*) $1 break;
        return 400; #if the second rewrite won't match
        proxy_pass            https://SAPHostingCompany.sap3:8043/$uri;
        proxy_read_timeout    130;
        proxy_connect_timeout 90;
        proxy_redirect        off;
        proxy_buffering       off;
        client_max_body_size  50m;
    }
}
}</code></pre>
</div>
</div>
</p>
<p>The server accepts only TLS-secured connections. One difference is the establishment of the TLS-connection:</p>
<p><code>software &lt;-TLS-secured-&gt; SAP</code> vs <code>software &lt;-unsecured-&gt; nginx &lt;-TLS-secured-&gt; SAP</code></p>
<p>Here is an example of a successful request:
<a href=""https://i.stack.imgur.com/OJVNd.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/OJVNd.png"" alt=""Successful tcp dump"" /></a></p>
<p>And here the same request aborted with an RST flag:
<a href=""https://i.stack.imgur.com/nfjpk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/nfjpk.png"" alt=""enter image description here"" /></a></p>
<p>Here the connection is aborted immediately after the client sends a <em>Certificate, Client Key Exchange, Change Ciper Spec, Encrypted Handshake Message</em> but it might fail at any point. For example in most file upload errors ~10-20 data packets are sent successfully before the connection is aborted.</p>
<h3>Conclusion</h3>
<p>We are at a complete loss what else to investigate/how to narrow this down. Unfortunately <em>SAPHostingCompany</em> is not very forthcoming in this bug-hunt :(
We, of course, think it must be some kind of infrastructure problem on their side since the error appeared on all stages/environments simultaneously while they blame us since the nginx-solution seems to work...</p>
<p>So if anybody has a clue as to what might be going on here I would be very grateful.</p>
<h3>Related question</h3>
<p>Upon this quest I stumbled upon <a href=""https://stackoverflow.com/questions/251243/what-causes-a-tcp-ip-reset-rst-flag-to-be-sent"">this</a> question. This user was facing regular RSTs after a constant amount of time (which is not what we are experiencing).
Some of the proposed solutions do sound promising but <em>SAPHostingCompany</em> assures us that none of those apply (again, communication between <em>MyCompany</em> and <em>SAPHostingCompany</em> is quite difficult)...
Unfortunately we lack the required know-how to determine which solutions might actually be feasible to explain and fix our problem.</p>
",92,0,0,4,nginx;tcp;sap;connection-reset,2022-06-28 10:46:43,2022-06-28 10:46:43,2022-06-28 10:46:43,starting a few weeks back we noticed that sometimes requests fail  seemingly  randomly  this happens on all stages  supposedly there were no changes whatsoever conducted that might have caused this change    while this is quite an annoyance for most requests  that can just be retried if they failed  this completely prevents larger files from being uploaded  larger meaning just  gt kb in this context  most interestingly  this failure happens far less often  but still does   in the setup with the intermediate nginx reverse proxy  the nginx config looks like this  the server accepts only tls secured connections  one difference is the establishment of the tls connection  software  lt  tls secured  gt  sap vs software  lt  unsecured  gt  nginx  lt  tls secured  gt  sap here the connection is aborted immediately after the client sends a certificate  client key exchange  change ciper spec  encrypted handshake message but it might fail at any point  for example in most file upload errors    data packets are sent successfully before the connection is aborted  so if anybody has a clue as to what might be going on here i would be very grateful ,what causes a server to close a tcp ip connection abruptly with a reset  rst flag  
164,143397,72767230,"U-Boot: how to load U-Boot from SD card, but have it load its Environment from QSPI Flash?","<p>I'm having some difficulty configuring U-Boot, in particular setting it up so that it can load from an SD card, but access its Environment from QSPI Flash.</p>
<p><em><strong>First of all, is this even possible? Can the U-Boot environment be stored in a different location from where U-Boot was loaded?</strong></em></p>
<p>Currently, I have a U-Boot image running from QSPI Flash on a Xilinx MPSoC ARM64 platform. I'm using Xilinx
PetaLinux however I think I understand how this configures U-Boot &quot;under the hood&quot; so I'll try to refer to
uboot.cfg​ as much as I can.</p>
<p>Along with all the defaults, I have set:</p>
<pre><code>#define CONFIG_ENV_OFFSET 0x2E00000
#define CONFIG_ENV_OVERWRITE 1
#define CONFIG_CMD_ERASEENV 1
</code></pre>
<p>On this particular platform, there is a physical switch to switch the Xilinx first-stage bootloader (and ARM
Trusted Firmware) between QSPI Flash and SD card modes. This platform also requires a so-called &quot;BOOT.BIN&quot;, which
is an aggregation of the u-boot binary, the Xilinx FSBL, ARM Trusted Firmware, an FPGA image and
other things, to be written to QSPI Flash, which I have done. This is all working correctly, and the serial console
looks like this at reset or power-on:</p>
<pre><code>Xilinx Zynq MP First Stage Boot Loader
Release 2021.2   Oct 13 2021  -  07:15:53
NOTICE:  BL31: v2.4(release):xlnx_rebase_v2.4_2021.1_update1-23-g9188496b9
NOTICE:  BL31: Built : 07:41:24, Oct 13 2021


U-Boot 2021.01 (Oct 12 2021 - 09:28:42 +0000)

CPU:   ZynqMP
Silicon: v3
Model: ZynqMP ZCU208 RevA
Board: Xilinx ZynqMP
DRAM:  4 GiB
PMUFW:  v1.1
EL Level:       EL2
Chip ID:        zu48dr
NAND:  0 MiB
MMC:   mmc@ff170000: 0
Loading Environment from SPIFlash... SF: Detected mt25qu02g with page size 512 Bytes, erase size 128 KiB, total 512 MiB
...
</code></pre>
<p>As you can see, U-Boot loads from QSPI Flash and the Environment is also loaded from QSPI Flash. All good.</p>
<p>What I want to do is modify the system so that the First Stage Boot Loader loads U-Boot from the SD card. In my config I
already have <code>CONFIG_ENV_IS_IN_FAT</code> set to 1. When I copy BOOT.BIN to the first, FAT partition on an SD card, and set my
platform's boot mode to &quot;SD Card&quot; via the physical switch, the unit loads U-Boot from the SD card successfully, and the
serial console shows output similar to the above but with:</p>
<pre><code>Loading Environment from FAT... *** Warning - bad CRC, using default environment
</code></pre>
<p>It works, although this warning is expected because there is no Environment saved on the SD card yet.
It does show that the SD card is being checked for the Environment though, so that's good.</p>
<p>Note that this is the <em>same build</em> that I used for the QSPI flash boot earlier, but it's looking for the config on FAT, so I'm currently under the impression that
U-Boot only looks for its Environment based on where it was loaded from, even if other locations are enabled. I also tried in QEMU and it seemed to think that the config came from &quot;nowhere&quot;, but that may be a distraction.</p>
<hr />
<p><em><strong>The issue is that I would like to configure U-Boot to be loaded from the SD card (for ease of upgrade / development), but to use QSPI for its Environment,
so that I can store persistent U-Boot configuration on the board itself.</strong></em></p>
<p>In particular, the MAC address for the board is not readable via software so must be manually configured in U-Boot, and I'd like that to follow around the board, not the SD card. There are a few other options I'd like to set per-board also.</p>
<p>According to the U-Boot documentation I've read, disabling FAT as the default should be achievable by unsetting the
following in <code>u-boot.cfg</code>:</p>
<pre><code>CONFIG_ENV_IS_IN_FAT
CONFIG_SYS_MMC_ENV_DEV
CONFIG_ENV_FAT_DEVICE_AND_PART
CONFIG_ENV_IS_IN_FAT
CONFIG_ENV_FAT_FILE
CONFIG_SYS_MMC_ENV_PART
CONFIG_ENV_FAT_INTERFACE
</code></pre>
<p>Performing the same installation steps as above, to have this new U-Boot loaded from the SD card, results in the
following output:</p>
<pre><code>Xilinx Zynq MP First Stage Boot Loader
Release 2021.2   Oct 13 2021  -  07:15:53
NOTICE:  BL31: v2.4(release):xlnx_rebase_v2.4_2021.1_update1-23-g9188496b9
NOTICE:  BL31: Built : 07:41:24, Oct 13 2021
</code></pre>
<p>And that's it! No more output. There is an LED on the board that goes from red to green, which I think indicates that
the FPGA image within BOOT.BIN has been loaded into the gate array successfully, so I think the earlier boot loader
has found BOOT.BIN. I have no reason therefore to think that U-Boot has not also been loaded, but if it has, it is
generating no output. I tried increasing the debug level of U-Boot to 7 (DEBUG) in the hope of seeing something
from U-Boot, but that makes no difference. It's also not booting Linux, which would normally happen next.</p>
<p>Can anyone shed any light on why making this change might result in this behaviour? Is there some other
configuration option I need to set to ensure that U-Boot can run from the SD card when <code>CONFIG_ENV_IS_IN_FAT</code>
and friends are not set? Or perhaps I can keep <code>CONFIG_ENV_IS_IN_FAT</code> etc. and there's some other way to instruct
U-Boot to use the QSPI Flash for its environment, even though it was loaded from SD card?</p>
<p>Note: I've also enabled ATF debugging, which produces the following output, but it still hangs with no sign of U-Boot:</p>
<pre><code>INFO:    PSCI Power Domain Map:
INFO:      Domain Node : Level 1, parent_node -1, State ON (0x0)
INFO:      Domain Node : Level 0, parent_node 0, State ON (0x0)
INFO:      Domain Node : Level 0, parent_node 0, State ON (0x0)
INFO:      Domain Node : Level 0, parent_node 0, State ON (0x0)
INFO:      CPU Node : MPID 0x0, parent_node 0, State ON (0x0)
INFO:      CPU Node : MPID 0x1, parent_node 0, State ON (0x0)
INFO:      CPU Node : MPID 0x2, parent_node 0, State ON (0x0)
INFO:      CPU Node : MPID 0x3, parent_node 0, State ON (0x0)
Xilinx Zynq MP First Stage Boot Loader
Release 2021.2   Oct 13 2021  -  07:15:53
WARNING: BL31: invalid exception level (3)
NOTICE:  BL31: v2.4(debug):xlnx_rebase_v2.4_2021.1_update1-23-g9188496b9
NOTICE:  BL31: Built : 07:41:24, Oct 13 2021
INFO:    ARM GICv2 driver initialized
INFO:    BL31: Initializing runtime services
INFO:    BL31: PM Service Init Complete: API v1.1
INFO:    BL31: cortex_a53: CPU workaround for 855873 was applied
WARNING: BL31: cortex_a53: CPU workaround for 1530924 was missing!
INFO:    BL31: Preparing for EL3 exit to normal world
INFO:    Entry point address = 0x8000000
INFO:    SPSR = 0x3c9
</code></pre>
",56,1,0,5,arm;embedded;environment;bootloader;u-boot,2022-06-27 08:11:49,2022-06-27 08:11:49,2022-06-28 07:51:01,i m having some difficulty configuring u boot  in particular setting it up so that it can load from an sd card  but access its environment from qspi flash  first of all  is this even possible  can the u boot environment be stored in a different location from where u boot was loaded  along with all the defaults  i have set  as you can see  u boot loads from qspi flash and the environment is also loaded from qspi flash  all good  in particular  the mac address for the board is not readable via software so must be manually configured in u boot  and i d like that to follow around the board  not the sd card  there are a few other options i d like to set per board also  note  i ve also enabled atf debugging  which produces the following output  but it still hangs with no sign of u boot ,u boot  how to load u boot from sd card  but have it load its environment from qspi flash 
165,19429728,72777899,justify-content making a gap on the left side,"<p>At the bottom, button Git and link &quot;10 min read&quot; and the image are in the same  (first two are in the one, the third is for itself).</p>
<p>When i try to justify-content, the gap creates on the left side of button and link. I don't know how all this looks when put on this site, because it's my first time using it, so I'm really sorry.</p>
<p>It's my third day using Html and CSS so have mercy.</p>
<pre><code>&lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot;&gt;
  &lt;head&gt;
    &lt;meta charset=&quot;UTF-8&quot; /&gt;
    &lt;link rel=&quot;stylesheet&quot; href=&quot;style.css&quot; /&gt;
    &lt;title&gt;Practice #1&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;header&gt;
      &lt;img
        class=&quot;logo&quot;
        src=&quot;https://shapingthefuture.co.il/wp-content/uploads/2016/12/envato-logo-small.svg&quot;
        alt=&quot;logo&quot;
      /&gt;
      &lt;div class=&quot;header-right&quot;&gt;
        &lt;button href=&quot;#&quot; class=&quot;sign-in&quot;&gt;Sign in&lt;/button&gt;
        &lt;button href=&quot;#&quot; class=&quot;get-started&quot;&gt;Get started&lt;/button&gt;
      &lt;/div&gt;
    &lt;/header&gt;
    &lt;nav&gt;
      &lt;h1&gt;Quick Code&lt;/h1&gt;
      &lt;a href=&quot;#&quot; class=&quot;nav-link&quot;&gt;📚 Top courses&lt;/a&gt;
      &lt;a href=&quot;#&quot; class=&quot;nav-link&quot;&gt;✍ Submit article&lt;/a&gt;
      &lt;a href=&quot;#&quot; class=&quot;nav-link&quot;&gt;🌏 Web dev&lt;/a&gt;
      &lt;a href=&quot;#&quot; class=&quot;nav-link&quot;&gt;📱 Mobile dev&lt;/a&gt;
      &lt;a href=&quot;#&quot; class=&quot;nav-link&quot;&gt;💻 Programming&lt;/a&gt;
      &lt;a href=&quot;#&quot; class=&quot;nav-link quick&quot;&gt;Quick code&lt;/a&gt;
    &lt;/nav&gt;

    &lt;article&gt;
      &lt;p class=&quot;free-story&quot;&gt;
        You have &lt;strong&gt;1&lt;/strong&gt; free member-only story left this month.
        &lt;a href=&quot;#&quot; class=&quot;for-medium&quot;
          &gt;Sign up for Medium and get an extra one&lt;/a
        &gt;
      &lt;/p&gt;
      &lt;div class=&quot;in-article&quot;&gt;
        &lt;h2&gt;10 Reasons Why You Should Switch to Linux&lt;/h2&gt;
        &lt;p class=&quot;ten-things&quot;&gt;10 Things Linux Can Do That Windows Can't&lt;/p&gt;
        &lt;div class=&quot;samul-social&quot;&gt;
          &lt;div class=&quot;samuel&quot;&gt;
            &lt;img class=&quot;samuel-img&quot;
            src=&quot;https://www.kindpng.com/picc/m/171-1712282_profile-icon-png-profile-icon-vector-png-transparent.png&quot;/
            alt=&quot;samuel-martins&quot;&gt;
            &lt;div class=&quot;to-name&quot;&gt;
              &lt;p&gt;Samuel Martins&lt;/p&gt;
              &lt;button class=&quot;follow&quot;&gt;Follow&lt;/button&gt;
            &lt;/div&gt;
            &lt;p class=&quot;date&quot;&gt;Nov 17 &amp;middot; 6 min read&lt;/p&gt;
          &lt;/div&gt;
          &lt;div class=&quot;social&quot;&gt;
            &lt;a href=&quot;https://twitter.com/&quot; target=&quot;_blank&quot;
              &gt;&lt;img
                class=&quot;icon&quot;
                src=&quot;https://seeklogo.com/images/T/twitter-icon-circle-blue-logo-0902F48837-seeklogo.com.png&quot;
                alt=&quot;twitter-logo&quot;
            /&gt;&lt;/a&gt;
            &lt;a href=&quot;https://rs.linkedin.com/&quot; target=&quot;_blank&quot;
              &gt;&lt;img
                class=&quot;icon&quot;
                src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/LinkedIn_logo_initials.png/640px-LinkedIn_logo_initials.png&quot;
                alt=&quot;linkedin-logo&quot;
            /&gt;&lt;/a&gt;
            &lt;a href=&quot;facebook.com&quot; target=&quot;_blank&quot;&gt;
              &lt;img class=&quot;icon&quot;
              src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Facebook_Logo_%282019%29.png/800px-Facebook_Logo_%282019%29.png&quot;/
              alt=&quot;facebook-logo&quot;/&gt;
            &lt;/a&gt;
            &lt;a href=&quot;index.html&quot;&gt;
              &lt;img
                class=&quot;icon&quot;
                src=&quot;https://static.vecteezy.com/system/resources/thumbnails/005/200/965/small/bookmark-black-color-icon-vector.jpg&quot;
            /&gt;&lt;/a&gt;
          &lt;/div&gt;
        &lt;/div&gt;
        &lt;img
          class=&quot;main-image&quot;
          src=&quot;https://www.uveta.io/categories/blog/windows-vs-linux-appservice-whats-the-difference/windows_linux.png&quot;
          alt=&quot;main-picture&quot;
        /&gt;

        &lt;p class=&quot;counting&quot;&gt;
          This is going to be a pretty straight forward article. I am aware that
          it might get a lot of negative comments from Windows users just from
          reading the title alone. I believe these are the reasons why everyone
          should try using the Linux system.
        &lt;/p&gt;
        &lt;p class=&quot;dots&quot;&gt;&amp;sdot; &amp;sdot; &amp;sdot;&lt;/p&gt;
        &lt;h3&gt;1. You can download the source for Linux&lt;/h3&gt;
        &lt;p class=&quot;counting&quot;&gt;
          I believe in transparency when it comes to the digital world. You can
          go over to
          &lt;a
            href=&quot;https://github.com/torvalds/linux&quot;
            class=&quot;link-in-article&quot;
            target=&quot;_blank&quot;
            &gt;https://github.com/torvalds/linux&lt;/a
          &gt;
          and download over 800k commits for Linux. You will be able to see
          everything that has ever been done on Linux all the way back from its
          inception. Why would anyone even care about the source code? Well, the
          reason you are going to want to care is that there are people who are
          constantly looking at the source for things like bugs and security
          issues, and various other matters.
        &lt;/p&gt;
        &lt;p class=&quot;counting&quot;&gt;
          You can see the ins and outs of the system you are using. With
          Windows, everything is completely closed, which means you are putting
          a hundred percent of your trust into Microsoft developers to check
          their own stuff and make sure it is okay. Even if you do not care
          about the source, know that there are a lot of people who do care, and
          they make your experience better as a result. In addition to the Linux
          kernel being open source, almost all software that you will install
          for your system comes from official repositories, which are also open
          source.
        &lt;/p&gt;

        &lt;h3&gt;2. You can install updates without rebooting your machine&lt;/h3&gt;
        &lt;p class=&quot;counting&quot;&gt;
          This is a game-changer for cloud environments. If you have a windows
          server, you have to upgrade your software then reboot the system
          again. This will result in your users experiencing downtime. With
          Linux, you can update almost anything without a reboot, and for
          kernels version 4.0 and beyond, you can even update the kernel itself.
          Isn’t that amazing? I have never liked the Windows prompt for a reboot
          every time I install or update a piece of software.
        &lt;/p&gt;

        &lt;h3&gt;
          3. You can plug devices in without worrying about finding and
          downloading drivers
        &lt;/h3&gt;
        &lt;p class=&quot;counting&quot;&gt;
          The only time it is not true is with highly specialized devices. How
          is that possible? The whole point of the Linux kernel is to connect
          hardware to software. In the Linux kernel, there have been over 16,000
          unique developers across 1400 companies working on Linux writing their
          drivers into Linux. That way, when people use Linux, it is just
          automatically there. When you look at windows, you have to download
          and install drivers every time you hook something into your computer.
        &lt;/p&gt;
        &lt;h3&gt;4. You can run Linux from a pen drive, CD DVD, or any medium&lt;/h3&gt;
        &lt;p class=&quot;counting&quot;&gt;
          I cannot stress the importance of this. I mean, imagine having your
          whole system on a thumb-drive. You can take your work literally
          anywhere without the risk of losing it. Of course, it works best if
          you have persistence configured during installation into the drive.
          For developers, this can be useful in situations where you are
          required on-site but cannot carry your laptop. Hackers use this trick
          all the to boot Kali live or with persistence because that is
          basically all they need half the time. Another advantage with this
          trick is that you can install multiple distributions in one
          thumb-drive so that you can boot into whichever one you wish at any
          given time.
        &lt;/p&gt;

        &lt;h3&gt;5. You can run the Linux for a long time without rebooting&lt;/h3&gt;
        &lt;p class=&quot;counting&quot;&gt;
          This is possible without degradation of performance because Linux is
          ultra-stable. It has way less memory fragmentation, and it simply does
          not become slower over time. You will still be able to make changes on
          the fly without the need to reboot. You are just simply not going to
          find that kind of up-time on any Windows system. The advantage is that
          you can run a production server for a long time while making any
          changes without system reboot and, therefore, no downtime.
        &lt;/p&gt;

        &lt;h3&gt;6. You could run the Linux on almost any hardware&lt;/h3&gt;
        &lt;p class=&quot;counting&quot;&gt;
          When I say any hardware, I am referring to both different types of
          hardware, as well as hardware from various date ranges. There are
          fully functional Linux installs that are, in some cases, less than
          32MB in size. This means that you can go into that closet, dust off
          that old computer from 1993, and breathe new life into it by
          installing an appropriate Linux system with respect to your space. You
          cannot do that with windows. As Windows gets newer, it becomes more
          resource-intensive, and the minimum requirements go up. Linux has a
          wide range of distributions from which you can pick one that you need
          for your particular application. You can
          &lt;a
            href=&quot;https://blog.coursesity.com/best-kali-linux-tutorials/&quot;
            class=&quot;link-in-article&quot;
            target=&quot;_blank&quot;
            &gt;learn Linux&lt;/a
          &gt;
          to develop your website at low costs, as it can run almost any of the
          major languages.
        &lt;/p&gt;

        &lt;h3&gt;
          7. You can fix broken Linux installs with a live CD DVD or pen drive
        &lt;/h3&gt;
        &lt;p class=&quot;counting&quot;&gt;
          This is not for Linux alone. You can even fix broken windows installs
          with Linux in some cases. The reason this is possible is that the
          Linux kernel runs entirely in memory. So you can use a CD or pen
          driver DVD to load that kernel into memory, and then go into a chroot
          environment on your broken system, and then you can use that broken
          system as if it were functioning. From there, you can take whatever
          action you need to get that system working again. On windows, you have
          to go through the windows system repair wizard. If that does not work,
          you will be required to re-install windows.
        &lt;/p&gt;

        &lt;h3&gt;
          8. You can update all of your software often with a single command
        &lt;/h3&gt;
        &lt;p class=&quot;counting&quot;&gt;
          In a Debian system, it is so easy to update your software and even
          upgrade the entire system if you wish. You need only type apt-get
          update or apt-get update &amp;&amp; apt-get upgrade. On windows, you either
          use the built-in updater for the software, or you go back to the site
          to download a newer version, which may cost you. As a developer, I
          cannot stress the importance of using updated software.
        &lt;/p&gt;

        &lt;h3&gt;9. You can move a hard drive from one Linux machine to another&lt;/h3&gt;
        &lt;p class=&quot;counting&quot;&gt;
          So, the motherboard from my laptop died about a week ago, and I did
          not have enough money to get a new one or an entirely new laptop. I
          had to take my hard drive from the broken laptop and use it on a
          different laptop. Guess what? It worked without re-installation. I
          never lost my data, and I am actually using the other laptop to write
          this article. This is largely made possible by the fact that all the
          drivers in Linux are built-in. Moving a hard drive from one machine to
          another does not affect it. It simply sees all your new hardware and
          re-acclimate to work like it was in the previous machine. On windows,
          not only will it probably not work, but windows will see that you have
          different hardware, and then, suddenly, your copy of Windows becomes
          non-genuine.
        &lt;/p&gt;

        &lt;h3&gt;
          10. You can install software without worrying about viruses and
          malware
        &lt;/h3&gt;
        &lt;p class=&quot;counting&quot;&gt;
          Now, this is not to say that Linux is virus and malware proof. It is
          just to say that it is a lot harder for viruses and malware to get on
          your system. That is due to two things. Number one, it is harder to
          escalate privileges on Linux for just a normal user. Number two, most
          of the software that you download for Linux comes from official
          repositories, and those are guaranteed. Additionally, software on
          Linux does not autorun as they do on windows. This also implies that
          there is no antivirus software needed on Linux, and of course, that
          saves you money.
        &lt;/p&gt;
        &lt;p class=&quot;dots&quot;&gt;&amp;sdot; &amp;sdot; &amp;sdot;&lt;/p&gt;
        &lt;p class=&quot;counting&quot;&gt;
          I am not trying to convince you to switch. You will not lose anything
          by trying it out. Every single reason is basically a comparison to
          Windows. I have used windows before and I slowly grew apart from it
          when I discovered Linux. I have never been worried about not having a
          legal copy of Linux nor the need to buy Linux software. Everything
          about Linux is open-source. Don’t worry about not knowing how to use
          Linux at first. There is a huge community to guide you. In case you
          are wondering where Linux is used in the real world, check out another
          article I wrote on the different places Linux is used.
        &lt;/p&gt;
        &lt;a
          class=&quot;what-is-used-for&quot;
          href=&quot;https://samuel-martins.medium.com/what-is-linux-used-for-6714041a9a0b&quot;
          target=&quot;_blank&quot;
        &gt;
          &lt;div class=&quot;used-for-text&quot;&gt;
            &lt;p class=&quot;what-is&quot;&gt;What Is Linux Used For?&lt;/p&gt;
            &lt;p class=&quot;linux-is&quot;&gt;
              Linux Is Taking Over. It Is Just a Matter of Time
            &lt;/p&gt;
            &lt;p class=&quot;samuel-martins&quot;&gt;samuel.martins.medium.com&lt;/p&gt;
          &lt;/div&gt;
          &lt;img src=&quot;25719.png&quot;/ alt=&quot;linux image&quot; class=&quot;used-for-image&quot;&gt;
        &lt;/a&gt;
      &lt;/div&gt;
    &lt;/article&gt;
    &lt;div class=&quot;developer-box&quot;&gt;
      &lt;p class=&quot;sign-for-developer&quot;&gt;Sign up for Developer Updates&lt;/p&gt;
      &lt;p class=&quot;by-quick-code&quot;&gt;By Quick Code&lt;/p&gt;
      &lt;p class=&quot;receive-updates&quot;&gt;
        Receive weekly updates about new posts on programming, development, data
        science, web development and more
        &lt;a href=&quot;https://medium.com/quick-code/newsletters/developer-updates&quot; class=&quot;receive-updates-link&quot;
          &gt;Take a look.&lt;/a
        &gt;
        &lt;br /&gt;
        &lt;div class=&quot;email&quot;&gt;
        &lt;input type=&quot;text&quot; placeholder=&quot;Your email&quot; class=&quot;input-email&quot;/&gt;
        &lt;button class=&quot;get-this-newsletter&quot;&gt;✉ Get this newsletter&lt;/button&gt;
        &lt;/div&gt;
        &lt;p class=&quot;by-sign-in&quot;&gt;By signing up, you will create a Medium account if you don’t already have one. Review our &lt;a href=&quot;https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=newsletter_v3_promo--------------------------newsletter_v3_promo-----------&quot; class=&quot;privacy-policy&quot;&gt;Privacy Policy&lt;/a&gt; for more information about our privacy practices.&lt;/p&gt;
      &lt;/p&gt;
    &lt;/div&gt;
    &lt;div class=&quot;after-box&quot;&gt;
      &lt;div class=&quot;content&quot;&gt;
        &lt;div class=&quot;more-from-quick-code&quot;&gt;
          &lt;div class=&quot;more-and-follow&quot;&gt;
            &lt;a href=&quot;https://medium.com/quick-code&quot; class=&quot;more-from&quot; target=&quot;_blank&quot;&gt;More from Quick Code
            &lt;/a&gt;
            &lt;button class=&quot;follow-two&quot;&gt;Follow&lt;/button&gt;
           &lt;/div&gt;
          &lt;p class=&quot;find-the-best-tutorials&quot;&gt;Find the best tutorials and courses for the web, mobile, chatbot, AR/VR development, &lt;br&gt; database management, data science, web design and cryptocurrency. Practice in&lt;br&gt; JavaScript, Java, Python, R, Android, Swift, Objective-C, React, Node Js, Ember,&lt;br&gt; C++, SQL &amp; more.&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;top-10-git-gui-clients&quot;&gt;
        &lt;/div&gt;
        &lt;div class=&quot;theme-all&quot;&gt;&lt;/div&gt;
          &lt;a href=&quot;https://medium.com/quick-code/top-10-git-gui-clients-for-developers-b56d702579a6&quot; class=&quot;top-ten-git-gui-clients&quot;&gt;
           &lt;div class=&quot;theme-up&quot;&gt;
            &lt;img src=&quot;https://miro.medium.com/fit/c/176/176/1*1wwrri468OAME5L00uD-jA.jpeg&quot; alt=&quot;Theme Selection&quot;/ class=&quot;theme-logo&quot;&gt;
            &lt;p class=&quot;theme-selection&quot;&gt;Theme Selection&lt;/p&gt;
            &lt;p class=&quot;mid-dot&quot;&gt; &amp;middot; &lt;/p&gt;
            &lt;p class=&quot;theme-date&quot;&gt;Nov 10, 2020&lt;/p&gt;
           &lt;/div&gt;
           &lt;div class=&quot;theme-middle&quot;&gt;
            &lt;div class=&quot;theme-text&quot;&gt;
              &lt;div class=&quot;theme-text-up&quot;&gt;
                &lt;p class=&quot;theme-h&quot;&gt;Top 10+ Git GUI Clients For Developers 👨‍💻&lt;/p&gt;
               &lt;p class=&quot;theme-par&quot;&gt;Hey there.!!🙋‍♂️ Are you looking for the top git GUI client to make it easy to manage your project? Then you are in right place..!! First of all, Git is a popular version control system that helps developers, writers, or anyone...&lt;/p&gt;
              &lt;/div&gt;
              &lt;div class=&quot;theme-bot&quot;&gt;
                &lt;div class=&quot;theme-bot-left&quot;&gt;
                  &lt;a href=&quot;https://medium.com/tag/git&quot; target=&quot;_blank&quot;&gt;&lt;button&gt;Git&lt;/button&gt;&lt;/a&gt;
                  &lt;a href=&quot;https://medium.com/quick-code/top-10-git-gui-clients-for-developers-b56d702579a6?source=post_page-----e037aa748504----0----------------------------&quot;
                  target=&quot;_blank&quot;&gt;10 min read&lt;/a&gt;
                &lt;/div&gt;
                &lt;img src=&quot;bookmark-icon-12326.png&quot;class=&quot;theme-bot-right&quot; /&gt;
             &lt;/div&gt;
            &lt;/div&gt;
             &lt;img src=&quot;https://miro.medium.com/fit/c/101/101/1*Mi1xLQIarZQaBNYReu8Z0g.png&quot;/ class=&quot;theme-pic&quot;&gt;
           &lt;/div&gt;
          &lt;/a&gt;
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>
<pre><code>* {
  padding: 0;
  margin: 0;
  box-sizing: border-box;
}

body {
  font-family: sans-serif;
  width: 1400px;
  margin: auto;
}

button {
  cursor: pointer;
}

header {
  display: flex;
  align-items: center;
  justify-content: space-between;
  margin: 10px 10px;
}

.logo {
  width: 60px;
}

.sign-in {
  font-size: 22px;
  padding: 14px 19px;
  border: 0;
  background-color: white;
  color: #7a6efe;
  margin-right: 10px;
}

.sign-in:hover {
  background-color: #7a6efe;
  color: white;
  border-radius: 5px;
}

.get-started {
  font-size: 22px;
  padding: 12px 17px;
  border: 2px #7a6efe solid;
  background-color: white;
  color: #7a6efe;
  margin-right: 10px;
  border-radius: 5px;
}

.get-started:hover {
  background-color: #7a6efe;
  color: white;
}

nav {
  background-color: #7a6efe;
  display: grid;
  align-items: center;
  font-size: 20px;
  grid-template-columns: repeat(8, 1fr);
  height: 50px;
  margin-bottom: 20px;
}

h1 {
  color: white;
  font-size: 25px;
  padding-left: 20px;
}

.nav-link {
  display: grid;
  text-decoration: none;
  font-size: 14px;
  text-transform: uppercase;
  color: white;
  text-align: center;
  height: 50px;
  align-items: center;
}

.nav-link:hover {
  background-color: white;
  color: #7a6efe;
}

.quick {
  grid-column: 7 / 8;
}

article {
  width: 800px;
  margin: auto;
}

.free-story {
  background-color: #f4f4f4;
  align-self: center;
  font-size: 18px;
  text-align: center;
  margin-bottom: 70px;
  padding-top: 20px;
  padding-bottom: 20px;
  border-radius: 5px;
}

.for-medium {
  color: black;
}

.for.medium:visited {
  color: black;
}

.in-article {
  width: 776px;
  margin: auto;
}

h2 {
  font-size: 55px;
  font-family: Georgia, &quot;Times New Roman&quot;, Times, serif;
  font-weight: normal;
  margin-bottom: 20px;
}

.ten-things {
  font-size: 30px;
  color: #999999;
  margin-bottom: 20px;
}

.samuel {
  display: grid;
  grid-template-columns: 50px 1fr;
  column-gap: 10px;
  row-gap: 0px;
  align-items: center;
  font-size: 14px;
}

.samuel-img {
  width: 50px;
  height: auto;
  grid-row: 1 / 3;
}

.to-name {
  display: flex;
  align-items: center;
  gap: 5px;
}

.date {
  grid-column: 2 / 3;
  padding-bottom: 6px;
}

.follow {
  background-color: white;
  border-radius: 5px;
  border: #7a6efe 1px solid;
  padding: 3px 8px;
  color: #7a6efe;
}

.follow:hover {
  background-color: #7a6efe;
  color: white;
}

.samul-social {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 20px;
}

.social {
  display: flex;
  gap: 10px;
}

.icon {
  width: 30px;
}

.main-image {
  width: 100%;
  margin-bottom: 20px;
}

.counting {
  font-family: Georgia, &quot;Times New Roman&quot;, Times, serif;
  font-size: 20px;
  margin-bottom: 30px;
  line-height: 1.5;
}

h3 {
  margin-bottom: 10px;
  font-weight: 800;
}

.link-in-article {
  color: black;
}

.link-in-article:visited {
  color: black;
}

.dots {
  font-size: 50px;
  text-align: center;
  margin-bottom: 30px;
}

.what-is-used-for {
  display: flex;
  height: 200px;
  justify-content: space-between;
  border: 1px rgb(204, 204, 204) solid;
  text-decoration: none;
  align-items: center;
  margin-bottom: 60px;
  margin-top: 60px;
}

.used-for-text {
  color: black;
  text-decoration: none;
  margin-left: 15px;
}

.used-for-image {
  border-left: 1px rgb(204, 204, 204) solid;
  height: 199px;
}

.what-is {
  color: black;
  font-size: 22px;
  font-weight: bold;
  margin-bottom: 7px;
}

.linux-is {
  color: #999999;
  font-size: 22px;
  margin-bottom: 10px;
}

.samuel-martins {
  color: #999999;
}

.developer-box {
  width: 776px;
  margin: auto;
  background-color: #f5f5f5;
  border-top: #7a6efe 5px solid;
  padding: 45px;
  margin-bottom: 60px;
}

.sign-for-developer {
  font-size: 26px;
  font-weight: bold;
  margin-bottom: 10px;
}

.by-quick-code {
  font-size: 13px;
  margin-bottom: 15px;
}

.receive-updates {
  margin-bottom: 15px;
  font-size: 18px;
  line-height: 1.4;
}

.receive-updates-link {
  color: black;
  text-decoration: none;
  position: relative;
}

.receive-updates-link:after {
  content: &quot;&quot;;

  width: 100%;
  position: absolute;
  left: 0;
  bottom: 1px;

  border-width: 0 0 1px;
  border-style: solid;
}

.email {
  display: flex;
  justify-content: space-between;
  margin-bottom: 30px;
  align-items: center;
  font-family: sohne, &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;
}

.input-email {
  border: 0;
  border-bottom: 1px solid rgb(168, 168, 168);
  background-color: #f1f1f1;
  width: 350px;
  font-size: 17px;
  letter-spacing: 0.5px;
  color: rgb(168, 168, 168);
  padding-bottom: 5px;
}

.input-email:focus {
  outline: none;
  color: rgb(80, 80, 80);
  border-bottom: 1px solid rgb(80, 80, 80);
}

.get-this-newsletter {
  background-color: #7a6efe;
  color: white;
  border: 0;
  padding: 10px 20px;
  font-size: 20px;
  border-radius: 30px;
  font-weight: normal;
}

.get-this-newsletter:hover {
  background-color: #6f61ff;
}

.by-sign-in {
  font-size: 14px;
  line-height: 1.4;
}

.privacy-policy {
  color: black;
}

.privacy-policy:visited {
  color: black;
}

.after-box {
  width: 1200px;
  margin: auto;
  background-color: #f5f5f5;
}

.content {
  width: 776px;
  margin: auto;
  background-color: #f5f5f5;
}

.more-from-quick-code {
  margin-bottom: 30px;
}

.more-and-follow {
  display: flex;
  padding-top: 45px;
  padding-bottom: 12px;
  justify-content: space-between;
  align-items: center;
}

.more-from {
  color: black;
  text-decoration: none;
  font-weight: bold;
  font-size: 22px;
}

.more-from:visited {
  color: black;
}

.follow-two {
  background-color: #7a6efe;
  color: white;
  border: 0;
  padding: 10px 20px;
  font-size: 17px;
  border-radius: 30px;
  font-weight: normal;
}

.follow-two:hover {
  background-color: #6f61ff;
}

.find-the-best-tutorials {
  line-height: 1.4;
  color: #7e7e7e;
}

.top-ten-git-gui-clients {
  text-decoration: none;
  color: black;
}

.theme-up {
  display: flex;
  align-items: center;
  text-decoration: none;
  color: black;
  font-size: 15px;
  margin-bottom: 10px;
}

.theme-logo {
  width: 25px;
  border-radius: 30px;
}

.theme-selection {
  text-decoration: none;
  margin-left: 10px;
}

.mid-dot {
  font-weight: bold;
  margin-left: 10px;
}

.theme-date {
  margin-left: 10px;
  color: #7e7e7e;
}

.theme-middle {
  display: flex;
  align-items: flex-start;
  margin-bottom: 10px;
}

.theme-h {
  font-size: 25px;
  font-weight: 750;
  margin-bottom: 5px;
}

.theme-par {
  font-family: Georgia, &quot;Times New Roman&quot;, Times, serif;
  font-size: 17px;
  line-height: 1.5;
}

.theme-pic {
  width: 130px;
  height: 130px;
}

.theme-text {
  display: grid;
  margin-right: 50px;
}

.theme-bot {
  display: flex;
  justify-content: space-between;
}

.theme-bot-left {
  display: flex;
  margin-left: 0;
}

</code></pre>
",49,1,0,3,html;css;flexbox,2022-06-27 23:22:35,2022-06-27 23:22:35,2022-06-27 23:45:11,at the bottom  button git and link   min read  and the image are in the same   first two are in the one  the third is for itself   when i try to justify content  the gap creates on the left side of button and link  i don t know how all this looks when put on this site  because it s my first time using it  so i m really sorry  it s my third day using html and css so have mercy ,justify content making a gap on the left side
166,17098913,72765550,InvalidOperationException thrown due to model of incompatible type,"<p>I am coding a Web-based movie database application using ASP.NET Core 6.0 MVC. I am trying to add search-by-genre capability (I already have search-by-title) but something I'm doing is causing an &quot;InvalidOperationException&quot;.</p>
<p>This is from the debug console:</p>
<pre><code>-------------------------------------------------------------------
You may only use the Microsoft .NET Core Debugger (vsdbg) with
Visual Studio Code, Visual Studio or Visual Studio for Mac software
to help you develop and test your applications.
-------------------------------------------------------------------
Using launch settings from 'C:\Users\Trevor\source\repos\ASP.NET project_3\MovieDBApp\Properties\launchSettings.json' [Profile 'MovieDBApp']...
info: Microsoft.Hosting.Lifetime[14]
      Now listening on: https://localhost:7167
info: Microsoft.Hosting.Lifetime[14]
      Now listening on: http://localhost:5204
info: Microsoft.Hosting.Lifetime[0]
      Application started. Press Ctrl+C to shut down.
info: Microsoft.Hosting.Lifetime[0]
      Hosting environment: Development
info: Microsoft.Hosting.Lifetime[0]
      Content root path: C:\Users\Trevor\source\repos\ASP.NET project_3\MovieDBApp\
fail: Microsoft.AspNetCore.Diagnostics.DeveloperExceptionPageMiddleware[1]
      An unhandled exception has occurred while executing the request.
      System.InvalidOperationException: The model item passed into the ViewDataDictionary is of type 'System.Collections.Generic.List`1[MovieDBApp.Models.Movie]', but this ViewDataDictionary instance requires a model item of type 'MovieDBApp.Models.MovieGenreViewModel'.
         at Microsoft.AspNetCore.Mvc.ViewFeatures.ViewDataDictionary.EnsureCompatible(Object value)
         at Microsoft.AspNetCore.Mvc.ViewFeatures.ViewDataDictionary..ctor(ViewDataDictionary source, Object model, Type declaredModelType)
         at lambda_method66(Closure , ViewDataDictionary )
         at Microsoft.AspNetCore.Mvc.Razor.RazorPagePropertyActivator.CreateViewDataDictionary(ViewContext context)
         at Microsoft.AspNetCore.Mvc.Razor.RazorPagePropertyActivator.Activate(Object page, ViewContext context)
         at Microsoft.AspNetCore.Mvc.Razor.RazorPageActivator.Activate(IRazorPage page, ViewContext context)
         at Microsoft.AspNetCore.Mvc.Razor.RazorView.RenderPageCoreAsync(IRazorPage page, ViewContext context)
         at Microsoft.AspNetCore.Mvc.Razor.RazorView.RenderPageAsync(IRazorPage page, ViewContext context, Boolean invokeViewStarts)
         at Microsoft.AspNetCore.Mvc.Razor.RazorView.RenderAsync(ViewContext context)
         at Microsoft.AspNetCore.Mvc.ViewFeatures.ViewExecutor.ExecuteAsync(ViewContext viewContext, String contentType, Nullable`1 statusCode)
         at Microsoft.AspNetCore.Mvc.ViewFeatures.ViewExecutor.ExecuteAsync(ViewContext viewContext, String contentType, Nullable`1 statusCode)
         at Microsoft.AspNetCore.Mvc.ViewFeatures.ViewExecutor.ExecuteAsync(ActionContext actionContext, IView view, ViewDataDictionary viewData, ITempDataDictionary tempData, String contentType, Nullable`1 statusCode)
         at Microsoft.AspNetCore.Mvc.ViewFeatures.ViewResultExecutor.ExecuteAsync(ActionContext context, ViewResult result)
         at Microsoft.AspNetCore.Mvc.ViewResult.ExecuteResultAsync(ActionContext context)
         at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.&lt;InvokeNextResultFilterAsync&gt;g__Awaited|30_0[TFilter,TFilterAsync](ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)
         at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.Rethrow(ResultExecutedContextSealed context)
         at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.ResultNext[TFilter,TFilterAsync](State&amp; next, Scope&amp; scope, Object&amp; state, Boolean&amp; isCompleted)
         at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.InvokeResultFilters()
      --- End of stack trace from previous location ---
         at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.&lt;InvokeNextResourceFilter&gt;g__Awaited|25_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)
         at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.Rethrow(ResourceExecutedContextSealed context)
         at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.Next(State&amp; next, Scope&amp; scope, Object&amp; state, Boolean&amp; isCompleted)
         at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.InvokeFilterPipelineAsync()
      --- End of stack trace from previous location ---
         at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.&lt;InvokeAsync&gt;g__Awaited|17_0(ResourceInvoker invoker, Task task, IDisposable scope)
         at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.&lt;InvokeAsync&gt;g__Awaited|17_0(ResourceInvoker invoker, Task task, IDisposable scope)
         at Microsoft.AspNetCore.Routing.EndpointMiddleware.&lt;Invoke&gt;g__AwaitRequestTask|6_0(Endpoint endpoint, Task requestTask, ILogger logger)
         at Microsoft.AspNetCore.Authorization.AuthorizationMiddleware.Invoke(HttpContext context)
         at Microsoft.AspNetCore.Diagnostics.DeveloperExceptionPageMiddleware.Invoke(HttpContext context)
</code></pre>
<p>In my <code>Models</code> directory, I have a file called <code>MovieGenreViewModel.cs</code>:</p>
<pre><code>using Microsoft.AspNetCore.Mvc.Rendering;
using System.Collections.Generic;

namespace MovieDBApp.Models
{
    public class MovieGenreViewModel
    {
        public List&lt;Movie&gt; Movies { get; set; }
        public SelectList Genres { get; set; }
        public string MovieGenre { get; set; }
        public string SearchString { get; set; }
    }
}
</code></pre>
<p>My <code>Index.cshtml</code> looks like this:</p>
<pre><code>@model MovieDBApp.Models.MovieGenreViewModel

@{
    ViewData[&quot;Title&quot;] = &quot;Index&quot;;
}

&lt;h1&gt;Index&lt;/h1&gt;

&lt;p&gt;
    &lt;a asp-action=&quot;Create&quot;&gt;Create New&lt;/a&gt;
&lt;/p&gt;

&lt;form asp-controller=&quot;Movies&quot; asp-action=&quot;Index&quot; method = &quot;get&quot;&gt;
    &lt;p&gt;
        &lt;select asp-for=&quot;MovieGenre&quot; asp-items=&quot;Model.Genres&quot;&gt; 
            &lt;option value=&quot;&quot;&gt;All&lt;/option&gt; 
        &lt;/select&gt; 

        Title: &lt;input type=&quot;text&quot; name=&quot;SearchString&quot;&gt;
        &lt;input type=&quot;submit&quot; value=&quot;Filter&quot; /&gt;
    &lt;/p&gt;
&lt;/form&gt;

&lt;table class=&quot;table&quot;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                @Html.DisplayNameFor(model =&gt; model.Movies[0].Title)
            &lt;/th&gt;
            &lt;th&gt;
                @Html.DisplayNameFor(model =&gt; model.Movies[0].ReleaseDate)
            &lt;/th&gt;
            &lt;th&gt;
                @Html.DisplayNameFor(model =&gt; model.Movies[0].Genre)
            &lt;/th&gt;
            &lt;th&gt;
                @Html.DisplayNameFor(model =&gt; model.Movies[0].Rating)
            &lt;/th&gt;
            &lt;th&gt;
                @Html.DisplayNameFor(model =&gt; model.Movies[0].Runtime)
            &lt;/th&gt;
            &lt;th&gt;&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
@foreach (var item in Model.Movies) {
        &lt;tr&gt;
            &lt;td&gt;
                @Html.DisplayFor(modelItem =&gt; item.Title)
            &lt;/td&gt;
            &lt;td&gt;
                @Html.DisplayFor(modelItem =&gt; item.ReleaseDate)
            &lt;/td&gt;
            &lt;td&gt;
                @Html.DisplayFor(modelItem =&gt; item.Genre)
            &lt;/td&gt;
            &lt;td&gt;
                @Html.DisplayFor(modelItem =&gt; item.Rating)
            &lt;/td&gt;
            &lt;td&gt;
                @Html.DisplayFor(modelItem =&gt; item.Runtime)
            &lt;/td&gt;
            &lt;td&gt;
                &lt;a asp-action=&quot;Edit&quot; asp-route-id=&quot;@item.Id&quot;&gt;Edit&lt;/a&gt; |
                &lt;a asp-action=&quot;Details&quot; asp-route-id=&quot;@item.Id&quot;&gt;Details&lt;/a&gt; |
                &lt;a asp-action=&quot;Delete&quot; asp-route-id=&quot;@item.Id&quot;&gt;Delete&lt;/a&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
}
    &lt;/tbody&gt;
&lt;/table&gt;
</code></pre>
<p>I had to change the first line from</p>
<pre><code>@model IEnumerable&lt;MovieDBApp.Models.Movie&gt;
</code></pre>
<p>to</p>
<pre><code>@model MovieDBApp.Models.MovieGenreViewModel
</code></pre>
<p>to insert the code for the genre search:</p>
<pre><code>&lt;select asp-for=&quot;MovieGenre&quot; asp-items=&quot;Model.Genres&quot;&gt; 
    &lt;option value=&quot;&quot;&gt;All&lt;/option&gt; 
&lt;/select&gt; 
</code></pre>
<p>I changed <code>@Html.DisplayNameFor(model =&gt; model.Title)</code> to <code>@Html.DisplayNameFor(model =&gt; model.Movies[0].Title)</code> (I also changed the successive attributes in the same pattern).</p>
<p>I'm really not sure what the problem is. I tried changing the top line to</p>
<pre><code>@model IEnumerable&lt;MovieDBApp.Models.MovieGenreViewModel&gt;
</code></pre>
<p>but that causes VS Code to give an error saying,</p>
<blockquote>
<p>'IEnumerable' does not contain a definition for 'MovieGenre' and no accessible extension method 'MovieGenre' accepting a first argument of type 'IEnumerable' could be found.</p>
</blockquote>
<p><strong>UPDATE 1</strong> (<code>MoviesController.cs</code>):</p>
<pre><code>namespace MovieDBApp.Controllers
{
    public class MoviesController : Controller
    {
        private readonly MovieDBAppContext _context;

        public MoviesController(MovieDBAppContext context)
        {
            _context = context;
        }

        // GET: Movies
        public async Task&lt;IActionResult&gt; Index(string searchString)
        {
            var movies = from m in _context.Movie select m;

            if (!String.IsNullOrEmpty(searchString))
            {
                movies = movies.Where(s =&gt; s.Title.Contains(searchString));
            }

            return View(await movies.ToListAsync());
        }

        // GET: Movies/Details/5
        public async Task&lt;IActionResult&gt; Details(int? id)
        {
            if (id == null || _context.Movie == null)
            {
                return NotFound();
            }

            var movie = await _context.Movie
                .FirstOrDefaultAsync(m =&gt; m.Id == id);
            if (movie == null)
            {
                return NotFound();
            }

            return View(movie);
        }

        // GET: Movies/Create
        public IActionResult Create()
        {
            return View();
        }

        // POST: Movies/Create
        [HttpPost]
        [ValidateAntiForgeryToken]
        public async Task&lt;IActionResult&gt; Create([Bind(&quot;Id,Title,ReleaseDate,Genre,Rating,Runtime&quot;)] Movie movie)
        {
            if (ModelState.IsValid)
            {
                _context.Add(movie);
                await _context.SaveChangesAsync();
                return RedirectToAction(nameof(Index));
            }
            return View(movie);
        }

        // GET: Movies/Edit/5
        public async Task&lt;IActionResult&gt; Edit(int? id)
        {
            if (id == null || _context.Movie == null)
            {
                return NotFound();
            }

            var movie = await _context.Movie.FindAsync(id);
            if (movie == null)
            {
                return NotFound();
            }
            return View(movie);
        }

        // POST: Movies/Edit/5
        [HttpPost]
        [ValidateAntiForgeryToken]
        public async Task&lt;IActionResult&gt; Edit(int id, [Bind(&quot;Id,Title,ReleaseDate,Genre,Rating,Runtime&quot;)] Movie movie)
        {
            if (id != movie.Id)
            {
                return NotFound();
            }

            if (ModelState.IsValid)
            {
                try
                {
                    _context.Update(movie);
                    await _context.SaveChangesAsync();
                }
                catch (DbUpdateConcurrencyException)
                {
                    if (!MovieExists(movie.Id))
                    {
                        return NotFound();
                    }
                    else
                    {
                        throw;
                    }
                }
                return RedirectToAction(nameof(Index));
            }
            return View(movie);
        }

        // GET: Movies/Delete/5
        public async Task&lt;IActionResult&gt; Delete(int? id)
        {
            if (id == null || _context.Movie == null)
            {
                return NotFound();
            }

            var movie = await _context.Movie
                .FirstOrDefaultAsync(m =&gt; m.Id == id);

            if (movie == null)
            {
                return NotFound();
            }

            return View(movie);
        }

        // POST: Movies/Delete/5
        [HttpPost, ActionName(&quot;Delete&quot;)]
        [ValidateAntiForgeryToken]
        public async Task&lt;IActionResult&gt; DeleteConfirmed(int id)
        {
            if (_context.Movie == null)
            {
                return Problem(&quot;Entity set 'MovieDBAppContext.Movie'  is null.&quot;);
            }

            var movie = await _context.Movie.FindAsync(id);

            if (movie != null)
            {
                _context.Movie.Remove(movie);
            }
            
            await _context.SaveChangesAsync();

            return RedirectToAction(nameof(Index));
        }

        private bool MovieExists(int id)
        {
          return (_context.Movie?.Any(e =&gt; e.Id == id)).GetValueOrDefault();
        }
    }
}
</code></pre>
",65,1,0,5,c#;html;visual-studio-code;asp.net-core-mvc;asp.net-core-6.0,2022-06-27 01:23:56,2022-06-27 01:23:56,2022-06-27 19:17:50,i am coding a web based movie database application using asp net core   mvc  i am trying to add search by genre capability  i already have search by title  but something i m doing is causing an  invalidoperationexception   this is from the debug console  in my models directory  i have a file called moviegenreviewmodel cs  my index cshtml looks like this  i had to change the first line from to to insert the code for the genre search  i changed  html displaynamefor model   gt  model title  to  html displaynamefor model   gt  model movies   title   i also changed the successive attributes in the same pattern   i m really not sure what the problem is  i tried changing the top line to but that causes vs code to give an error saying   ienumerable  does not contain a definition for  moviegenre  and no accessible extension method  moviegenre  accepting a first argument of type  ienumerable  could be found  update   moviescontroller cs  ,invalidoperationexception thrown due to model of incompatible type
167,1112259,72739776,Unable to resolve Flink table API dependency,"<p>I am using IntelliJ IDE for development. I am using below mentioned POM file for dependency management</p>
<pre><code>&lt;!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
&quot;License&quot;); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
&quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
--&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;flink&lt;/groupId&gt;
    &lt;artifactId&gt;flink-reporting&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;packaging&gt;jar&lt;/packaging&gt;

    &lt;name&gt;Flink Quickstart Job&lt;/name&gt;

    &lt;properties&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
        &lt;flink.version&gt;1.15.0&lt;/flink.version&gt;
        &lt;target.java.version&gt;1.8&lt;/target.java.version&gt;
        &lt;scala.binary.version&gt;2.12&lt;/scala.binary.version&gt;
        &lt;maven.compiler.source&gt;${target.java.version}&lt;/maven.compiler.source&gt;
        &lt;maven.compiler.target&gt;${target.java.version}&lt;/maven.compiler.target&gt;
        &lt;log4j.version&gt;2.17.1&lt;/log4j.version&gt;
    &lt;/properties&gt;

    &lt;repositories&gt;
        &lt;repository&gt;
            &lt;id&gt;apache.snapshots&lt;/id&gt;
            &lt;name&gt;Apache Development Snapshot Repository&lt;/name&gt;
            &lt;url&gt;https://repository.apache.org/content/repositories/snapshots/&lt;/url&gt;
            &lt;releases&gt;
                &lt;enabled&gt;false&lt;/enabled&gt;
            &lt;/releases&gt;
            &lt;snapshots&gt;
                &lt;enabled&gt;true&lt;/enabled&gt;
            &lt;/snapshots&gt;
        &lt;/repository&gt;
        &lt;repository&gt;
            &lt;id&gt;central&lt;/id&gt;
            &lt;name&gt;Maven Central&lt;/name&gt;
            &lt;layout&gt;default&lt;/layout&gt;
            &lt;url&gt;https://repo1.maven.org/maven2&lt;/url&gt;
            &lt;snapshots&gt;
                &lt;enabled&gt;false&lt;/enabled&gt;
            &lt;/snapshots&gt;
        &lt;/repository&gt;
    &lt;/repositories&gt;

    &lt;dependencies&gt;
        &lt;!-- Apache Flink dependencies --&gt;
        &lt;!-- These dependencies are provided, because they should not be packaged into the JAR file. --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-streaming-java&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-clients&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- Add connector dependencies here. They must be in the default scope (compile). --&gt;


        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-connector-kafka&lt;/artifactId&gt;
            &lt;version&gt;1.15.0&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
            &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
            &lt;version&gt;3.2.0&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;
            &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;
            &lt;version&gt;2.13.3&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
            &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;
            &lt;version&gt;1.7.26&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-table&lt;/artifactId&gt;
            &lt;version&gt;1.15.0&lt;/version&gt;
            &lt;type&gt;pom&lt;/type&gt;
        &lt;/dependency&gt;


        &lt;!-- Add logging framework, to produce console output when running in the IDE. --&gt;
        &lt;!-- These dependencies are excluded from the application JAR by default. --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
            &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt;
            &lt;version&gt;${log4j.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
            &lt;artifactId&gt;log4j-api&lt;/artifactId&gt;
            &lt;version&gt;${log4j.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
            &lt;artifactId&gt;log4j-core&lt;/artifactId&gt;
            &lt;version&gt;${log4j.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;commons-logging&lt;/groupId&gt;
            &lt;artifactId&gt;commons-logging&lt;/artifactId&gt;
            &lt;version&gt;1.1.1&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.microsoft.azure&lt;/groupId&gt;
            &lt;artifactId&gt;azure-data-lake-store-sdk&lt;/artifactId&gt;
            &lt;version&gt;2.1.5&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
            &lt;artifactId&gt;slf4j-nop&lt;/artifactId&gt;
            &lt;version&gt;1.7.21&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.json&lt;/groupId&gt;
            &lt;artifactId&gt;json&lt;/artifactId&gt;
            &lt;version&gt;20220320&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;

            &lt;!-- Java Compiler --&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.1&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;source&gt;${target.java.version}&lt;/source&gt;
                    &lt;target&gt;${target.java.version}&lt;/target&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;

            &lt;!-- We use the maven-shade plugin to create a fat jar that contains all necessary dependencies. --&gt;
            &lt;!-- Change the value of &lt;mainClass&gt;...&lt;/mainClass&gt; if your program entry point changes. --&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.1.1&lt;/version&gt;
                &lt;executions&gt;
                    &lt;!-- Run shade goal on package phase --&gt;
                    &lt;execution&gt;
                        &lt;phase&gt;package&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;shade&lt;/goal&gt;
                        &lt;/goals&gt;
                        &lt;configuration&gt;
                            &lt;artifactSet&gt;
                                &lt;excludes&gt;
                                    &lt;exclude&gt;org.apache.flink:flink-shaded-force-shading&lt;/exclude&gt;
                                    &lt;exclude&gt;com.google.code.findbugs:jsr305&lt;/exclude&gt;
                                    &lt;exclude&gt;org.slf4j:*&lt;/exclude&gt;
                                    &lt;exclude&gt;org.apache.logging.log4j:*&lt;/exclude&gt;
                                &lt;/excludes&gt;
                            &lt;/artifactSet&gt;
                            &lt;filters&gt;
                                &lt;filter&gt;
                                    &lt;!-- Do not copy the signatures in the META-INF folder.
                                    Otherwise, this might cause SecurityExceptions when using the JAR. --&gt;
                                    &lt;artifact&gt;*:*&lt;/artifact&gt;
                                    &lt;excludes&gt;
                                        &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt;
                                        &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt;
                                        &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt;
                                    &lt;/excludes&gt;
                                &lt;/filter&gt;
                            &lt;/filters&gt;
                            &lt;transformers&gt;
                                &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer&quot;/&gt;
                                &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt;
                                    &lt;mainClass&gt;tableAPI.RelationalTable&lt;/mainClass&gt;
                                &lt;/transformer&gt;
                            &lt;/transformers&gt;
                        &lt;/configuration&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;

        &lt;pluginManagement&gt;
            &lt;plugins&gt;

                &lt;!-- This improves the out-of-the-box experience in Eclipse by resolving some warnings. --&gt;
                &lt;plugin&gt;
                    &lt;groupId&gt;org.eclipse.m2e&lt;/groupId&gt;
                    &lt;artifactId&gt;lifecycle-mapping&lt;/artifactId&gt;
                    &lt;version&gt;1.0.0&lt;/version&gt;
                    &lt;configuration&gt;
                        &lt;lifecycleMappingMetadata&gt;
                            &lt;pluginExecutions&gt;
                                &lt;pluginExecution&gt;
                                    &lt;pluginExecutionFilter&gt;
                                        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                                        &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;
                                        &lt;versionRange&gt;[3.1.1,)&lt;/versionRange&gt;
                                        &lt;goals&gt;
                                            &lt;goal&gt;shade&lt;/goal&gt;
                                        &lt;/goals&gt;
                                    &lt;/pluginExecutionFilter&gt;
                                    &lt;action&gt;
                                        &lt;ignore/&gt;
                                    &lt;/action&gt;
                                &lt;/pluginExecution&gt;
                                &lt;pluginExecution&gt;
                                    &lt;pluginExecutionFilter&gt;
                                        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                                        &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                                        &lt;versionRange&gt;[3.1,)&lt;/versionRange&gt;
                                        &lt;goals&gt;
                                            &lt;goal&gt;testCompile&lt;/goal&gt;
                                            &lt;goal&gt;compile&lt;/goal&gt;
                                        &lt;/goals&gt;
                                    &lt;/pluginExecutionFilter&gt;
                                    &lt;action&gt;
                                        &lt;ignore/&gt;
                                    &lt;/action&gt;
                                &lt;/pluginExecution&gt;
                            &lt;/pluginExecutions&gt;
                        &lt;/lifecycleMappingMetadata&gt;
                    &lt;/configuration&gt;
                &lt;/plugin&gt;
            &lt;/plugins&gt;
        &lt;/pluginManagement&gt;
    &lt;/build&gt;
&lt;/project&gt;
</code></pre>
<p>I am using the following dependency for Flink Table API.</p>
<pre><code>&lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-table&lt;/artifactId&gt;
            &lt;version&gt;1.15.0&lt;/version&gt;
            &lt;type&gt;pom&lt;/type&gt;
        &lt;/dependency&gt;
</code></pre>
<p>While compiling I am not getting any error. But I am not able to resolve the flink table API dependency. Kindly help</p>
",37,2,0,4,maven;apache-flink;maven-2;flink-sql,2022-06-24 09:20:56,2022-06-24 09:20:56,2022-06-27 17:44:24,i am using intellij ide for development  i am using below mentioned pom file for dependency management i am using the following dependency for flink table api  while compiling i am not getting any error  but i am not able to resolve the flink table api dependency  kindly help,unable to resolve flink table api dependency
168,12750005,72770227,ESP32-S3 TensorFlow Lite Model Issues,"<p>I worked with the new ESP32-S3 Development Board and an I2S microphone in order to create a simple voice recognition system. The software and firmware behind this are based on this project: Voice Controlled Robot - Atomic14 <a href=""https://github.com/atomic14/voice-controlled-robot"" rel=""nofollow noreferrer"">https://github.com/atomic14/voice-controlled-robot</a></p>
<p>This project worked flawlessly on the developer kit so I moved forward and created my own board. This schematic is inspired by the design made by Espressif: ESP32-s3 Dev Kit Schematics <a href=""https://dl.espressif.com/dl/SCH_ESP32-S3-DEVKITC-1_V1_20210312C.pdf"" rel=""nofollow noreferrer"">https://dl.espressif.com/dl/SCH_ESP32-S3-DEVKITC-1_V1_20210312C.pdf</a></p>
<p>The flashing works perfectly. I am able to use different code that uses the microphone and record sounds. No issues with programming whatsoever. But when I upload the same code that uses TFLITE (the first provided link), the code uploads, runs, and prints outputs, but the neural network does not process or output anything.</p>
<p><strong>Please note</strong> that there are no differences between the code uploaded to my board and the one uploaded to the dev kit (on which everything works as it should).</p>
<p>There are only small differences between the two boards, but everything else (code-wise) works on my board so I am not sure what hardware issue would affect only the neural network.</p>
<p>The ESP32-s3 used in my design is the same one as the one on the dev kit, the only difference is the 16MB Flash in my design and 8MB Flash in the ESP32-s3 dev kit design (smaller flash memory on the board that works with the nn, compared to larger flash on the board that doesn't work with the nn).</p>
<p>-&gt; Could it be a memory problem caused by an incorrectly used capacitor that could create small differences in the voltage that powers the memory?</p>
<p>My schematics design is attached below
<a href=""https://i.stack.imgur.com/2yZUQ.png"" rel=""nofollow noreferrer"">ESP32-s3 my PCB design for the voice recognition module</a></p>
",92,0,0,5,tensorflow;tensorflow-lite;esp32;voice-recognition;arduino-esp32,2022-06-27 13:01:30,2022-06-27 13:01:30,2022-06-27 13:01:56,i worked with the new esp s development board and an is microphone in order to create a simple voice recognition system  the software and firmware behind this are based on this project  voice controlled robot   atomic  this project worked flawlessly on the developer kit so i moved forward and created my own board  this schematic is inspired by the design made by espressif  esp s dev kit schematics  the flashing works perfectly  i am able to use different code that uses the microphone and record sounds  no issues with programming whatsoever  but when i upload the same code that uses tflite  the first provided link   the code uploads  runs  and prints outputs  but the neural network does not process or output anything  please note that there are no differences between the code uploaded to my board and the one uploaded to the dev kit  on which everything works as it should   there are only small differences between the two boards  but everything else  code wise  works on my board so i am not sure what hardware issue would affect only the neural network  the esp s used in my design is the same one as the one on the dev kit  the only difference is the mb flash in my design and mb flash in the esp s dev kit design  smaller flash memory on the board that works with the nn  compared to larger flash on the board that doesn t work with the nn     gt  could it be a memory problem caused by an incorrectly used capacitor that could create small differences in the voltage that powers the memory ,esp s tensorflow lite model issues
169,18354507,72769008,How to add button at bottom of jquery datatable,"<p>I have a jQuery datatable. I am trying to add a button at the bottom of the datatable opposite to the pagination by replacing the 'Showing 1 of 50 entries&quot; text.</p>
<p>How I can achieve that by modifying the datatable? Please find the code below.</p>
<p>This is where I wanted to add button: <a href=""https://i.stack.imgur.com/qPOaM.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qPOaM.png"" alt=""enter image description here"" /></a></p>
<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>$('#example').DataTable();</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js""&gt;&lt;/script&gt;
&lt;script src=""https://cdn.datatables.net/1.12.1/js/jquery.dataTables.min.js""&gt;&lt;/script&gt;
&lt;link rel=""stylesheet"" href=""https://cdn.datatables.net/1.12.1/css/jquery.dataTables.min.css"" /&gt;
&lt;table id=""example"" class=""display"" style=""width:100%""&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th&gt;Position&lt;/th&gt;
      &lt;th&gt;Office&lt;/th&gt;
      &lt;th&gt;Age&lt;/th&gt;
      &lt;th&gt;Start date&lt;/th&gt;
      &lt;th&gt;Salary&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Tiger Nixon&lt;/td&gt;
      &lt;td&gt;System Architect&lt;/td&gt;
      &lt;td&gt;Edinburgh&lt;/td&gt;
      &lt;td&gt;61&lt;/td&gt;
      &lt;td&gt;2011-04-25&lt;/td&gt;
      &lt;td&gt;$320,800&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Garrett Winters&lt;/td&gt;
      &lt;td&gt;Accountant&lt;/td&gt;
      &lt;td&gt;Tokyo&lt;/td&gt;
      &lt;td&gt;63&lt;/td&gt;
      &lt;td&gt;2011-07-25&lt;/td&gt;
      &lt;td&gt;$170,750&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ashton Cox&lt;/td&gt;
      &lt;td&gt;Junior Technical Author&lt;/td&gt;
      &lt;td&gt;San Francisco&lt;/td&gt;
      &lt;td&gt;66&lt;/td&gt;
      &lt;td&gt;2009-01-12&lt;/td&gt;
      &lt;td&gt;$86,000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Cedric Kelly&lt;/td&gt;
      &lt;td&gt;Senior Javascript Developer&lt;/td&gt;
      &lt;td&gt;Edinburgh&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;2012-03-29&lt;/td&gt;
      &lt;td&gt;$433,060&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Airi Satou&lt;/td&gt;
      &lt;td&gt;Accountant&lt;/td&gt;
      &lt;td&gt;Tokyo&lt;/td&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;2008-11-28&lt;/td&gt;
      &lt;td&gt;$162,700&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Brielle Williamson&lt;/td&gt;
      &lt;td&gt;Integration Specialist&lt;/td&gt;
      &lt;td&gt;New York&lt;/td&gt;
      &lt;td&gt;61&lt;/td&gt;
      &lt;td&gt;2012-12-02&lt;/td&gt;
      &lt;td&gt;$372,000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Herrod Chandler&lt;/td&gt;
      &lt;td&gt;Sales Assistant&lt;/td&gt;
      &lt;td&gt;San Francisco&lt;/td&gt;
      &lt;td&gt;59&lt;/td&gt;
      &lt;td&gt;2012-08-06&lt;/td&gt;
      &lt;td&gt;$137,500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Rhona Davidson&lt;/td&gt;
      &lt;td&gt;Integration Specialist&lt;/td&gt;
      &lt;td&gt;Tokyo&lt;/td&gt;
      &lt;td&gt;55&lt;/td&gt;
      &lt;td&gt;2010-10-14&lt;/td&gt;
      &lt;td&gt;$327,900&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Colleen Hurst&lt;/td&gt;
      &lt;td&gt;Javascript Developer&lt;/td&gt;
      &lt;td&gt;San Francisco&lt;/td&gt;
      &lt;td&gt;39&lt;/td&gt;
      &lt;td&gt;2009-09-15&lt;/td&gt;
      &lt;td&gt;$205,500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Sonya Frost&lt;/td&gt;
      &lt;td&gt;Software Engineer&lt;/td&gt;
      &lt;td&gt;Edinburgh&lt;/td&gt;
      &lt;td&gt;23&lt;/td&gt;
      &lt;td&gt;2008-12-13&lt;/td&gt;
      &lt;td&gt;$103,600&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Jena Gaines&lt;/td&gt;
      &lt;td&gt;Office Manager&lt;/td&gt;
      &lt;td&gt;London&lt;/td&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;2008-12-19&lt;/td&gt;
      &lt;td&gt;$90,560&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Quinn Flynn&lt;/td&gt;
      &lt;td&gt;Support Lead&lt;/td&gt;
      &lt;td&gt;Edinburgh&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;2013-03-03&lt;/td&gt;
      &lt;td&gt;$342,000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Charde Marshall&lt;/td&gt;
      &lt;td&gt;Regional Director&lt;/td&gt;
      &lt;td&gt;San Francisco&lt;/td&gt;
      &lt;td&gt;36&lt;/td&gt;
      &lt;td&gt;2008-10-16&lt;/td&gt;
      &lt;td&gt;$470,600&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Haley Kennedy&lt;/td&gt;
      &lt;td&gt;Senior Marketing Designer&lt;/td&gt;
      &lt;td&gt;London&lt;/td&gt;
      &lt;td&gt;43&lt;/td&gt;
      &lt;td&gt;2012-12-18&lt;/td&gt;
      &lt;td&gt;$313,500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Tatyana Fitzpatrick&lt;/td&gt;
      &lt;td&gt;Regional Director&lt;/td&gt;
      &lt;td&gt;London&lt;/td&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;2010-03-17&lt;/td&gt;
      &lt;td&gt;$385,750&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Michael Silva&lt;/td&gt;
      &lt;td&gt;Marketing Designer&lt;/td&gt;
      &lt;td&gt;London&lt;/td&gt;
      &lt;td&gt;66&lt;/td&gt;
      &lt;td&gt;2012-11-27&lt;/td&gt;
      &lt;td&gt;$198,500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Paul Byrd&lt;/td&gt;
      &lt;td&gt;Chief Financial Officer (CFO)&lt;/td&gt;
      &lt;td&gt;New York&lt;/td&gt;
      &lt;td&gt;64&lt;/td&gt;
      &lt;td&gt;2010-06-09&lt;/td&gt;
      &lt;td&gt;$725,000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Gloria Little&lt;/td&gt;
      &lt;td&gt;Systems Administrator&lt;/td&gt;
      &lt;td&gt;New York&lt;/td&gt;
      &lt;td&gt;59&lt;/td&gt;
      &lt;td&gt;2009-04-10&lt;/td&gt;
      &lt;td&gt;$237,500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Bradley Greer&lt;/td&gt;
      &lt;td&gt;Software Engineer&lt;/td&gt;
      &lt;td&gt;London&lt;/td&gt;
      &lt;td&gt;41&lt;/td&gt;
      &lt;td&gt;2012-10-13&lt;/td&gt;
      &lt;td&gt;$132,000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Dai Rios&lt;/td&gt;
      &lt;td&gt;Personnel Lead&lt;/td&gt;
      &lt;td&gt;Edinburgh&lt;/td&gt;
      &lt;td&gt;35&lt;/td&gt;
      &lt;td&gt;2012-09-26&lt;/td&gt;
      &lt;td&gt;$217,500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Jenette Caldwell&lt;/td&gt;
      &lt;td&gt;Development Lead&lt;/td&gt;
      &lt;td&gt;New York&lt;/td&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;2011-09-03&lt;/td&gt;
      &lt;td&gt;$345,000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Yuri Berry&lt;/td&gt;
      &lt;td&gt;Chief Marketing Officer (CMO)&lt;/td&gt;
      &lt;td&gt;New York&lt;/td&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;2009-06-25&lt;/td&gt;
      &lt;td&gt;$675,000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Caesar Vance&lt;/td&gt;
      &lt;td&gt;Pre-Sales Support&lt;/td&gt;
      &lt;td&gt;New York&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;2011-12-12&lt;/td&gt;
      &lt;td&gt;$106,450&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Doris Wilder&lt;/td&gt;
      &lt;td&gt;Sales Assistant&lt;/td&gt;
      &lt;td&gt;Sydney&lt;/td&gt;
      &lt;td&gt;23&lt;/td&gt;
      &lt;td&gt;2010-09-20&lt;/td&gt;
      &lt;td&gt;$85,600&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Angelica Ramos&lt;/td&gt;
      &lt;td&gt;Chief Executive Officer (CEO)&lt;/td&gt;
      &lt;td&gt;London&lt;/td&gt;
      &lt;td&gt;47&lt;/td&gt;
      &lt;td&gt;2009-10-09&lt;/td&gt;
      &lt;td&gt;$1,200,000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Gavin Joyce&lt;/td&gt;
      &lt;td&gt;Developer&lt;/td&gt;
      &lt;td&gt;Edinburgh&lt;/td&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;2010-12-22&lt;/td&gt;
      &lt;td&gt;$92,575&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Jennifer Chang&lt;/td&gt;
      &lt;td&gt;Regional Director&lt;/td&gt;
      &lt;td&gt;Singapore&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;2010-11-14&lt;/td&gt;
      &lt;td&gt;$357,650&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Brenden Wagner&lt;/td&gt;
      &lt;td&gt;Software Engineer&lt;/td&gt;
      &lt;td&gt;San Francisco&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;2011-06-07&lt;/td&gt;
      &lt;td&gt;$206,850&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Fiona Green&lt;/td&gt;
      &lt;td&gt;Chief Operating Officer (COO)&lt;/td&gt;
      &lt;td&gt;San Francisco&lt;/td&gt;
      &lt;td&gt;48&lt;/td&gt;
      &lt;td&gt;2010-03-11&lt;/td&gt;
      &lt;td&gt;$850,000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Shou Itou&lt;/td&gt;
      &lt;td&gt;Regional Marketing&lt;/td&gt;
      &lt;td&gt;Tokyo&lt;/td&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;2011-08-14&lt;/td&gt;
      &lt;td&gt;$163,000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Michelle House&lt;/td&gt;
      &lt;td&gt;Integration Specialist&lt;/td&gt;
      &lt;td&gt;Sydney&lt;/td&gt;
      &lt;td&gt;37&lt;/td&gt;
      &lt;td&gt;2011-06-02&lt;/td&gt;
      &lt;td&gt;$95,400&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Suki Burks&lt;/td&gt;
      &lt;td&gt;Developer&lt;/td&gt;
      &lt;td&gt;London&lt;/td&gt;
      &lt;td&gt;53&lt;/td&gt;
      &lt;td&gt;2009-10-22&lt;/td&gt;
      &lt;td&gt;$114,500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Prescott Bartlett&lt;/td&gt;
      &lt;td&gt;Technical Author&lt;/td&gt;
      &lt;td&gt;London&lt;/td&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;2011-05-07&lt;/td&gt;
      &lt;td&gt;$145,000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Gavin Cortez&lt;/td&gt;
      &lt;td&gt;Team Leader&lt;/td&gt;
      &lt;td&gt;San Francisco&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;2008-10-26&lt;/td&gt;
      &lt;td&gt;$235,500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Martena Mccray&lt;/td&gt;
      &lt;td&gt;Post-Sales support&lt;/td&gt;
      &lt;td&gt;Edinburgh&lt;/td&gt;
      &lt;td&gt;46&lt;/td&gt;
      &lt;td&gt;2011-03-09&lt;/td&gt;
      &lt;td&gt;$324,050&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Unity Butler&lt;/td&gt;
      &lt;td&gt;Marketing Designer&lt;/td&gt;
      &lt;td&gt;San Francisco&lt;/td&gt;
      &lt;td&gt;47&lt;/td&gt;
      &lt;td&gt;2009-12-09&lt;/td&gt;
      &lt;td&gt;$85,675&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Howard Hatfield&lt;/td&gt;
      &lt;td&gt;Office Manager&lt;/td&gt;
      &lt;td&gt;San Francisco&lt;/td&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;2008-12-16&lt;/td&gt;
      &lt;td&gt;$164,500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Hope Fuentes&lt;/td&gt;
      &lt;td&gt;Secretary&lt;/td&gt;
      &lt;td&gt;San Francisco&lt;/td&gt;
      &lt;td&gt;41&lt;/td&gt;
      &lt;td&gt;2010-02-12&lt;/td&gt;
      &lt;td&gt;$109,850&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Vivian Harrell&lt;/td&gt;
      &lt;td&gt;Financial Controller&lt;/td&gt;
      &lt;td&gt;San Francisco&lt;/td&gt;
      &lt;td&gt;62&lt;/td&gt;
      &lt;td&gt;2009-02-14&lt;/td&gt;
      &lt;td&gt;$452,500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Timothy Mooney&lt;/td&gt;
      &lt;td&gt;Office Manager&lt;/td&gt;
      &lt;td&gt;London&lt;/td&gt;
      &lt;td&gt;37&lt;/td&gt;
      &lt;td&gt;2008-12-11&lt;/td&gt;
      &lt;td&gt;$136,200&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Jackson Bradshaw&lt;/td&gt;
      &lt;td&gt;Director&lt;/td&gt;
      &lt;td&gt;New York&lt;/td&gt;
      &lt;td&gt;65&lt;/td&gt;
      &lt;td&gt;2008-09-26&lt;/td&gt;
      &lt;td&gt;$645,750&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Olivia Liang&lt;/td&gt;
      &lt;td&gt;Support Engineer&lt;/td&gt;
      &lt;td&gt;Singapore&lt;/td&gt;
      &lt;td&gt;64&lt;/td&gt;
      &lt;td&gt;2011-02-03&lt;/td&gt;
      &lt;td&gt;$234,500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Bruno Nash&lt;/td&gt;
      &lt;td&gt;Software Engineer&lt;/td&gt;
      &lt;td&gt;London&lt;/td&gt;
      &lt;td&gt;38&lt;/td&gt;
      &lt;td&gt;2011-05-03&lt;/td&gt;
      &lt;td&gt;$163,500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Sakura Yamamoto&lt;/td&gt;
      &lt;td&gt;Support Engineer&lt;/td&gt;
      &lt;td&gt;Tokyo&lt;/td&gt;
      &lt;td&gt;37&lt;/td&gt;
      &lt;td&gt;2009-08-19&lt;/td&gt;
      &lt;td&gt;$139,575&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Thor Walton&lt;/td&gt;
      &lt;td&gt;Developer&lt;/td&gt;
      &lt;td&gt;New York&lt;/td&gt;
      &lt;td&gt;61&lt;/td&gt;
      &lt;td&gt;2013-08-11&lt;/td&gt;
      &lt;td&gt;$98,540&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Finn Camacho&lt;/td&gt;
      &lt;td&gt;Support Engineer&lt;/td&gt;
      &lt;td&gt;San Francisco&lt;/td&gt;
      &lt;td&gt;47&lt;/td&gt;
      &lt;td&gt;2009-07-07&lt;/td&gt;
      &lt;td&gt;$87,500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Serge Baldwin&lt;/td&gt;
      &lt;td&gt;Data Coordinator&lt;/td&gt;
      &lt;td&gt;Singapore&lt;/td&gt;
      &lt;td&gt;64&lt;/td&gt;
      &lt;td&gt;2012-04-09&lt;/td&gt;
      &lt;td&gt;$138,575&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Zenaida Frank&lt;/td&gt;
      &lt;td&gt;Software Engineer&lt;/td&gt;
      &lt;td&gt;New York&lt;/td&gt;
      &lt;td&gt;63&lt;/td&gt;
      &lt;td&gt;2010-01-04&lt;/td&gt;
      &lt;td&gt;$125,250&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Zorita Serrano&lt;/td&gt;
      &lt;td&gt;Software Engineer&lt;/td&gt;
      &lt;td&gt;San Francisco&lt;/td&gt;
      &lt;td&gt;56&lt;/td&gt;
      &lt;td&gt;2012-06-01&lt;/td&gt;
      &lt;td&gt;$115,000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Jennifer Acosta&lt;/td&gt;
      &lt;td&gt;Junior Javascript Developer&lt;/td&gt;
      &lt;td&gt;Edinburgh&lt;/td&gt;
      &lt;td&gt;43&lt;/td&gt;
      &lt;td&gt;2013-02-01&lt;/td&gt;
      &lt;td&gt;$75,650&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Cara Stevens&lt;/td&gt;
      &lt;td&gt;Sales Assistant&lt;/td&gt;
      &lt;td&gt;New York&lt;/td&gt;
      &lt;td&gt;46&lt;/td&gt;
      &lt;td&gt;2011-12-06&lt;/td&gt;
      &lt;td&gt;$145,600&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Hermione Butler&lt;/td&gt;
      &lt;td&gt;Regional Director&lt;/td&gt;
      &lt;td&gt;London&lt;/td&gt;
      &lt;td&gt;47&lt;/td&gt;
      &lt;td&gt;2011-03-21&lt;/td&gt;
      &lt;td&gt;$356,250&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Lael Greer&lt;/td&gt;
      &lt;td&gt;Systems Administrator&lt;/td&gt;
      &lt;td&gt;London&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;2009-02-27&lt;/td&gt;
      &lt;td&gt;$103,500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Jonas Alexander&lt;/td&gt;
      &lt;td&gt;Developer&lt;/td&gt;
      &lt;td&gt;San Francisco&lt;/td&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;2010-07-14&lt;/td&gt;
      &lt;td&gt;$86,500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Shad Decker&lt;/td&gt;
      &lt;td&gt;Regional Director&lt;/td&gt;
      &lt;td&gt;Edinburgh&lt;/td&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;2008-11-13&lt;/td&gt;
      &lt;td&gt;$183,000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Michael Bruce&lt;/td&gt;
      &lt;td&gt;Javascript Developer&lt;/td&gt;
      &lt;td&gt;Singapore&lt;/td&gt;
      &lt;td&gt;29&lt;/td&gt;
      &lt;td&gt;2011-06-27&lt;/td&gt;
      &lt;td&gt;$183,000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Donna Snider&lt;/td&gt;
      &lt;td&gt;Customer Support&lt;/td&gt;
      &lt;td&gt;New York&lt;/td&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;2011-01-25&lt;/td&gt;
      &lt;td&gt;$112,000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;</code></pre>
</div>
</div>
</p>
",27,1,0,2,jquery;datatable,2022-06-27 11:20:11,2022-06-27 11:20:11,2022-06-27 11:31:21,i have a jquery datatable  i am trying to add a button at the bottom of the datatable opposite to the pagination by replacing the  showing  of  entries  text  how i can achieve that by modifying the datatable  please find the code below  this is where i wanted to add button  ,how to add button at bottom of jquery datatable
170,1112259,72767101,Unable to run flink jar : Multiple factories for identifier &#39;default&#39; that implement,"<p>I was using the below mentioned POM file for writing the flink code</p>
<pre><code>&lt;!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
&quot;License&quot;); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
&quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
--&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;flink&lt;/groupId&gt;
    &lt;artifactId&gt;flink-reporting&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;packaging&gt;jar&lt;/packaging&gt;

    &lt;name&gt;Flink Quickstart Job&lt;/name&gt;

    &lt;properties&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
        &lt;flink.version&gt;1.15.0&lt;/flink.version&gt;
        &lt;target.java.version&gt;1.8&lt;/target.java.version&gt;
        &lt;scala.binary.version&gt;2.12&lt;/scala.binary.version&gt;
        &lt;maven.compiler.source&gt;${target.java.version}&lt;/maven.compiler.source&gt;
        &lt;maven.compiler.target&gt;${target.java.version}&lt;/maven.compiler.target&gt;
        &lt;log4j.version&gt;2.17.1&lt;/log4j.version&gt;
    &lt;/properties&gt;

    &lt;repositories&gt;
        &lt;repository&gt;
            &lt;id&gt;apache.snapshots&lt;/id&gt;
            &lt;name&gt;Apache Development Snapshot Repository&lt;/name&gt;
            &lt;url&gt;https://repository.apache.org/content/repositories/snapshots/&lt;/url&gt;
            &lt;releases&gt;
                &lt;enabled&gt;false&lt;/enabled&gt;
            &lt;/releases&gt;
            &lt;snapshots&gt;
                &lt;enabled&gt;true&lt;/enabled&gt;
            &lt;/snapshots&gt;
        &lt;/repository&gt;
    &lt;/repositories&gt;

    &lt;dependencies&gt;
        &lt;!-- Apache Flink dependencies --&gt;
        &lt;!-- These dependencies are provided, because they should not be packaged into the JAR file. --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-streaming-java&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-clients&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- Add connector dependencies here. They must be in the default scope (compile). --&gt;


        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-connector-kafka&lt;/artifactId&gt;
            &lt;version&gt;1.15.0&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
            &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
            &lt;version&gt;3.2.0&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;
            &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;
            &lt;version&gt;2.13.3&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
            &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;
            &lt;version&gt;1.7.26&lt;/version&gt;
        &lt;/dependency&gt;

&lt;!--        &lt;dependency&gt;--&gt;
&lt;!--            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;--&gt;
&lt;!--            &lt;artifactId&gt;flink-table&lt;/artifactId&gt;--&gt;
&lt;!--            &lt;version&gt;1.15.0&lt;/version&gt;--&gt;
&lt;!--            &lt;type&gt;pom&lt;/type&gt;--&gt;
&lt;!--        &lt;/dependency&gt;--&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-table-api-java-bridge&lt;/artifactId&gt;
            &lt;version&gt;1.15.0&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-table-api-scala-bridge_2.12&lt;/artifactId&gt;
            &lt;version&gt;1.15.0&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-table-runtime&lt;/artifactId&gt;
            &lt;version&gt;1.15.0&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-table-planner_2.12&lt;/artifactId&gt;
            &lt;version&gt;1.15.0&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-connector-files&lt;/artifactId&gt;
            &lt;version&gt;1.15.0&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-csv&lt;/artifactId&gt;
            &lt;version&gt;1.15.0&lt;/version&gt;
        &lt;/dependency&gt;


        &lt;!-- Add logging framework, to produce console output when running in the IDE. --&gt;
        &lt;!-- These dependencies are excluded from the application JAR by default. --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
            &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt;
            &lt;version&gt;${log4j.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
            &lt;artifactId&gt;log4j-api&lt;/artifactId&gt;
            &lt;version&gt;${log4j.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
            &lt;artifactId&gt;log4j-core&lt;/artifactId&gt;
            &lt;version&gt;${log4j.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;commons-logging&lt;/groupId&gt;
            &lt;artifactId&gt;commons-logging&lt;/artifactId&gt;
            &lt;version&gt;1.1.1&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.microsoft.azure&lt;/groupId&gt;
            &lt;artifactId&gt;azure-data-lake-store-sdk&lt;/artifactId&gt;
            &lt;version&gt;2.1.5&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
            &lt;artifactId&gt;slf4j-nop&lt;/artifactId&gt;
            &lt;version&gt;1.7.21&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.json&lt;/groupId&gt;
            &lt;artifactId&gt;json&lt;/artifactId&gt;
            &lt;version&gt;20220320&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;

            &lt;!-- Java Compiler --&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.1&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;source&gt;${target.java.version}&lt;/source&gt;
                    &lt;target&gt;${target.java.version}&lt;/target&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;

            &lt;!-- We use the maven-shade plugin to create a fat jar that contains all necessary dependencies. --&gt;
            &lt;!-- Change the value of &lt;mainClass&gt;...&lt;/mainClass&gt; if your program entry point changes. --&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.1.1&lt;/version&gt;
                &lt;executions&gt;
                    &lt;!-- Run shade goal on package phase --&gt;
                    &lt;execution&gt;
                        &lt;phase&gt;package&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;shade&lt;/goal&gt;
                        &lt;/goals&gt;
                        &lt;configuration&gt;
                            &lt;artifactSet&gt;
                                &lt;excludes&gt;
                                    &lt;exclude&gt;org.apache.flink:flink-shaded-force-shading&lt;/exclude&gt;
                                    &lt;exclude&gt;com.google.code.findbugs:jsr305&lt;/exclude&gt;
                                    &lt;exclude&gt;org.slf4j:*&lt;/exclude&gt;
                                    &lt;exclude&gt;org.apache.logging.log4j:*&lt;/exclude&gt;
                                &lt;/excludes&gt;
                            &lt;/artifactSet&gt;
                            &lt;filters&gt;
                                &lt;filter&gt;
                                    &lt;!-- Do not copy the signatures in the META-INF folder.
                                    Otherwise, this might cause SecurityExceptions when using the JAR. --&gt;
                                    &lt;artifact&gt;*:*&lt;/artifact&gt;
                                    &lt;excludes&gt;
                                        &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt;
                                        &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt;
                                        &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt;
                                    &lt;/excludes&gt;
                                &lt;/filter&gt;
                            &lt;/filters&gt;
                            &lt;transformers&gt;
                                &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer&quot;/&gt;
                                &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt;
                                    &lt;mainClass&gt;tableAPI.GettingStartedTable&lt;/mainClass&gt;
                                &lt;/transformer&gt;
                            &lt;/transformers&gt;
                        &lt;/configuration&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;

        &lt;pluginManagement&gt;
            &lt;plugins&gt;

                &lt;!-- This improves the out-of-the-box experience in Eclipse by resolving some warnings. --&gt;
                &lt;plugin&gt;
                    &lt;groupId&gt;org.eclipse.m2e&lt;/groupId&gt;
                    &lt;artifactId&gt;lifecycle-mapping&lt;/artifactId&gt;
                    &lt;version&gt;1.0.0&lt;/version&gt;
                    &lt;configuration&gt;
                        &lt;lifecycleMappingMetadata&gt;
                            &lt;pluginExecutions&gt;
                                &lt;pluginExecution&gt;
                                    &lt;pluginExecutionFilter&gt;
                                        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                                        &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;
                                        &lt;versionRange&gt;[3.1.1,)&lt;/versionRange&gt;
                                        &lt;goals&gt;
                                            &lt;goal&gt;shade&lt;/goal&gt;
                                        &lt;/goals&gt;
                                    &lt;/pluginExecutionFilter&gt;
                                    &lt;action&gt;
                                        &lt;ignore/&gt;
                                    &lt;/action&gt;
                                &lt;/pluginExecution&gt;
                                &lt;pluginExecution&gt;
                                    &lt;pluginExecutionFilter&gt;
                                        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                                        &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                                        &lt;versionRange&gt;[3.1,)&lt;/versionRange&gt;
                                        &lt;goals&gt;
                                            &lt;goal&gt;testCompile&lt;/goal&gt;
                                            &lt;goal&gt;compile&lt;/goal&gt;
                                        &lt;/goals&gt;
                                    &lt;/pluginExecutionFilter&gt;
                                    &lt;action&gt;
                                        &lt;ignore/&gt;
                                    &lt;/action&gt;
                                &lt;/pluginExecution&gt;
                            &lt;/pluginExecutions&gt;
                        &lt;/lifecycleMappingMetadata&gt;
                    &lt;/configuration&gt;
                &lt;/plugin&gt;
            &lt;/plugins&gt;
        &lt;/pluginManagement&gt;
    &lt;/build&gt;
&lt;/project&gt;
</code></pre>
<p>While running the jar file in flink cluster I am getting the following error.</p>
<pre><code>The program finished with the following exception:

org.apache.flink.client.program.ProgramInvocationException: The main method caused an error: Multiple factories for identifier 'default' that implement 'org.apache.flink.table.delegation.ExecutorFactory' found in the classpath.

Ambiguous factory classes are:

org.apache.flink.table.planner.delegation.DefaultExecutorFactory
org.apache.flink.table.planner.loader.DelegateExecutorFactory
    at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:372)
    at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:222)
    at org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:114)
    at org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:836)
    at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:247)
    at org.apache.flink.client.cli.CliFrontend.parseAndRun(CliFrontend.java:1078)
    at org.apache.flink.client.cli.CliFrontend.lambda$main$10(CliFrontend.java:1156)
    at org.apache.flink.runtime.security.contexts.NoOpSecurityContext.runSecured(NoOpSecurityContext.java:28)
    at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:1156)
Caused by: org.apache.flink.table.api.ValidationException: Multiple factories for identifier 'default' that implement 'org.apache.flink.table.delegation.ExecutorFactory' found in the classpath.

Ambiguous factory classes are:

org.apache.flink.table.planner.delegation.DefaultExecutorFactory
org.apache.flink.table.planner.loader.DelegateExecutorFactory
    at org.apache.flink.table.factories.FactoryUtil.discoverFactory(FactoryUtil.java:553)
    at org.apache.flink.table.api.internal.TableEnvironmentImpl.create(TableEnvironmentImpl.java:276)
    at org.apache.flink.table.api.TableEnvironment.create(TableEnvironment.java:93)
    at tableAPI.GettingStartedTable.main(GettingStartedTable.java:17)
    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.base/java.lang.reflect.Method.invoke(Method.java:566)
    at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:355)
    ... 8 more
</code></pre>
<p>Using flink 1.15. I was able to run the code inside my IDE</p>
",99,1,0,3,apache-flink;flink-streaming;flink-sql,2022-06-27 07:45:24,2022-06-27 07:45:24,2022-06-27 08:43:52,i was using the below mentioned pom file for writing the flink code while running the jar file in flink cluster i am getting the following error  using flink    i was able to run the code inside my ide,unable to run flink jar   multiple factories for identifier    default    that implement
171,17166996,69594471,"Exclude the pipeline file (e.g. Jenkinsfile, bitbucket-pipelines.yml) while pulling from one git repo to another","<p>We develop a web application in PHP + React. The product has on-premise installation. The client can download Docker images or set up a web server for himself. In our company, when a client purchases the software, we give access to the git. All development is done in Bitbucket, and then we do git pull on the server with Gogs and give access to clients to the Gogs repo. We have chosen this method for those clients who do not use containers, but simply configure Nginx or Apache for themselves, because they can be easily updated by doing git pull.</p>
<p>Problem: Bitbucket has bitbucket-piplines.yml, and we don't want it to go to Gogs and clients see it. We put everything that is going on in the pipeline into a script, the script into a container, and the container into a private repository. And inside bitbucket-piplines.yml, a client may only to read something like this: &quot;Take our image from the private register and run the script.&quot; Those. In principle, nothing terrible is written in bitbucket-piplines.yml, but still we would have much more freedom in the CD part, if we didn't have to hide everything.</p>
<p>Question: Is it possible somehow for everything to be the same in Gogs (commits), but excluding the bitbucket-piplines.yml file and maybe something else that we want to exclude?</p>
<p>Or maybe the problem is in the distribution model. I don't have much experience yet ... Please help.</p>
",145,0,0,5,jenkins;continuous-integration;devops;pipeline;bitbucket-pipelines,2021-10-16 12:54:32,2021-10-16 12:54:32,2022-06-27 01:24:32,we develop a web application in php   react  the product has on premise installation  the client can download docker images or set up a web server for himself  in our company  when a client purchases the software  we give access to the git  all development is done in bitbucket  and then we do git pull on the server with gogs and give access to clients to the gogs repo  we have chosen this method for those clients who do not use containers  but simply configure nginx or apache for themselves  because they can be easily updated by doing git pull  problem  bitbucket has bitbucket piplines yml  and we don t want it to go to gogs and clients see it  we put everything that is going on in the pipeline into a script  the script into a container  and the container into a private repository  and inside bitbucket piplines yml  a client may only to read something like this   take our image from the private register and run the script   those  in principle  nothing terrible is written in bitbucket piplines yml  but still we would have much more freedom in the cd part  if we didn t have to hide everything  question  is it possible somehow for everything to be the same in gogs  commits   but excluding the bitbucket piplines yml file and maybe something else that we want to exclude  or maybe the problem is in the distribution model  i don t have much experience yet     please help ,exclude the pipeline file  e g  jenkinsfile  bitbucket pipelines yml  while pulling from one git repo to another
172,761069,72712459,Vue CLI errors trying to deploy vue app with docker,"<p>I have a VUE app I have been developing locally which I am trying to deploy to a remote server for testing.</p>
<p>My dev machine is running Arch with <code>Docker 20.10.17</code></p>
<p>My VUE app has the following <code>Dev.Dockerfile</code> which is used to build it:</p>
<pre><code>FROM node:lts-alpine

WORKDIR /code

COPY package*.json /code/

RUN npm install --location=global @vue/cli

RUN yarn install

COPY . .

# serve application in development
CMD [ &quot;yarn&quot;, &quot;serve&quot; ]
</code></pre>
<p>The relevant service in my <code>docker-compose.yml</code> is:</p>
<pre class=""lang-yaml prettyprint-override""><code>frontend:
  build: 
    context: ./frontend
    dockerfile: dockerfiles/Dev.Dockerfile
  command: yarn serve
  stdin_open: true
  restart: always
  volumes:
    - ./frontend/:/code/
  ports:
    - &quot;8080:8080&quot;

</code></pre>
<p>The VUE service is part of a larger set of services I am setting up with docker-compose.</p>
<p>This seems to be running fine on my local machine (Arch with the latest Docker).</p>
<p>When I try to deploy this to an Ubuntu 20.04 server, however, I run into issues.</p>
<p>The server is running Docker-compose <code>1.29.2</code> and Docker 20.17.1</p>
<p>The build goes fine, but when I try to run <code>docker-compose up</code> I get:</p>
<pre><code>yarn run v1.22.19
$ vue-cli-service serve
/bin/sh: vue-cli-service: not found
</code></pre>
<p>Reading elsewhere on stackoverflow about this issue, I tried installing:</p>
<pre><code>RUN npm install -g @vue/cli-service
</code></pre>
<p>This changes the error to:</p>
<pre><code>yarn run v1.22.19
$ vue-cli-service serve
...
Error: Cannot find module '@vue/cli-plugin-babel'

</code></pre>
<p>I have also tried to explicitly install:</p>
<pre><code>RUN npm install @babel/core @babel/preset-env
RUN npm install @vue/cli-plugin-babel

</code></pre>
<p>The error remains the same.</p>
<p>This is not an issue on my local machine running Arch, only the remote machine running Ubuntu 20. How do I fix this?</p>
<p>MORE INFORMATION.</p>
<p>After experimenting with @amir's answer I have some more information.</p>
<p>On Arch, <code>Docker compose</code> is now a command in Docker and I have been using it without thinking about it. On the Ubuntu server that doesn't work and instead I am using the 'docker-compose' command. I &quot;assumed&quot; these were functionally the same but I think <code>docker-compose</code> is causing the failure.</p>
<p>If I build my <code>frontend</code> service manually with Docker and my <code>Dev.Dockerfile</code> and then run it with Docker it works perfectly. No warnings.</p>
<p>Building with <code>Docker-compose</code> works... but throws a number a warnings:</p>
<pre><code>yarn add v1.22.19
info No lockfile found.
[1/4] Resolving packages...
warning @vue/cli-service &gt; cssnano &gt; cssnano-preset-default &gt; postcss-svgo &gt; svgo &gt; stable@0.1.8: Modern JS already guarantees Array#sort() is a stable sort, so this library is deprecated. See the compatibility table on MDN: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/sort#browser_compatibility
warning @vue/cli &gt; @vue/cli-ui &gt; apollo-server-express &gt; subscriptions-transport-ws@0.9.19: The `subscriptions-transport-ws` package is no longer maintained. We recommend you use `graphql-ws` instead. For help migrating Apollo software to `graphql-ws`, see https://www.apollographql.com/docs/apollo-server/data/subscriptions/#switching-from-subscriptions-transport-ws    For general help using `graphql-ws`, see https://github.com/enisdenjo/graphql-ws/blob/master/README.md
warning @vue/cli &gt; @vue/cli-ui &gt; apollo-server-express &gt; apollo-server-core &gt; subscriptions-transport-ws@0.9.19: The `subscriptions-transport-ws` package is no longer maintained. We recommend you use `graphql-ws` instead. For help migrating Apollo software to `graphql-ws`, see https://www.apollographql.com/docs/apollo-server/data/subscriptions/#switching-from-subscriptions-transport-ws    For general help using `graphql-ws`, see https://github.com/enisdenjo/graphql-ws/blob/master/README.md
warning @vue/cli &gt; @vue/cli-ui &gt; apollo-server-express &gt; graphql-tools@4.0.8: This package has been deprecated and now it only exports makeExecutableSchema.\nAnd it will no longer receive updates.\nWe recommend you to migrate to scoped packages such as @graphql-tools/schema, @graphql-tools/utils and etc.\nCheck out https://www.graphql-tools.com to learn what package you should use instead
warning @vue/cli &gt; @vue/cli-ui &gt; apollo-server-express &gt; apollo-server-core &gt; graphql-tools@4.0.8: This package has been deprecated and now it only exports makeExecutableSchema.\nAnd it will no longer receive updates.\nWe recommend you to migrate to scoped packages such as @graphql-tools/schema, @graphql-tools/utils and etc.\nCheck out https://www.graphql-tools.com to learn what package you should use instead
warning @vue/cli &gt; @vue/cli-ui &gt; apollo-server-express &gt; graphql-tools &gt; uuid@3.4.0: Please upgrade  to version 7 or higher.  Older versions may use Math.random() in certain circumstances, which is known to be problematic.  See https://v8.dev/blog/math-random for details.
warning @vue/cli &gt; vue-codemod &gt; jscodeshift &gt; micromatch &gt; snapdragon &gt; source-map-resolve@0.5.3: See https://github.com/lydell/source-map-resolve#deprecated
warning @vue/cli &gt; @vue/cli-ui &gt; apollo-server-express &gt; apollo-server-core &gt; apollo-cache-control@0.14.0: The functionality provided by the `apollo-cache-control` package is built in to `apollo-server-core` starting with Apollo Server 3. See https://www.apollographql.com/docs/apollo-server/migration/#cachecontrol for details.
warning @vue/cli &gt; @vue/cli-ui &gt; apollo-server-express &gt; apollo-server-core &gt; graphql-extensions@0.15.0: The `graphql-extensions` API has been removed from Apollo Server 3. Use the plugin API instead: https://www.apollographql.com/docs/apollo-server/integrations/plugins/
warning @vue/cli &gt; vue-codemod &gt; jscodeshift &gt; micromatch &gt; snapdragon &gt; source-map-resolve &gt; resolve-url@0.2.1: https://github.com/lydell/resolve-url#deprecated
warning @vue/cli &gt; vue-codemod &gt; jscodeshift &gt; micromatch &gt; snapdragon &gt; source-map-resolve &gt; source-map-url@0.4.1: See https://github.com/lydell/source-map-url#deprecated
warning @vue/cli &gt; vue-codemod &gt; jscodeshift &gt; micromatch &gt; snapdragon &gt; source-map-resolve &gt; urix@0.1.0: Please see https://github.com/lydell/urix#deprecated
warning @vue/cli &gt; @vue/cli-ui &gt; apollo-server-express &gt; apollo-server-core &gt; apollo-tracing@0.15.0: The `apollo-tracing` package is no longer part of Apollo Server 3. See https://www.apollographql.com/docs/apollo-server/migration/#tracing for details


</code></pre>
<p>So it isn't finding the yarn.lock file - which is there - and throwing a number of module errors.</p>
<p>Again, this does not occur on my Arch machine running 'Docker compose' but does on an Ubuntu 20.04 server running <code>docker-compose</code></p>
<p>I did try adding a volume directly to the <code>node_module</code> directory as per @amir's answer but that did not work. I also tried changing the copy location for the Dockerfile as per that answer. No joy.</p>
<p>Ideas? I am really stuck here.</p>
",137,2,0,4,docker;npm;docker-compose;vuejs3,2022-06-22 11:55:45,2022-06-22 11:55:45,2022-06-24 04:55:02,i have a vue app i have been developing locally which i am trying to deploy to a remote server for testing  my dev machine is running arch with docker    my vue app has the following dev dockerfile which is used to build it  the relevant service in my docker compose yml is  the vue service is part of a larger set of services i am setting up with docker compose  this seems to be running fine on my local machine  arch with the latest docker   when i try to deploy this to an ubuntu   server  however  i run into issues  the server is running docker compose    and docker    the build goes fine  but when i try to run docker compose up i get  reading elsewhere on stackoverflow about this issue  i tried installing  this changes the error to  i have also tried to explicitly install  the error remains the same  this is not an issue on my local machine running arch  only the remote machine running ubuntu   how do i fix this  more information  after experimenting with  amir s answer i have some more information  on arch  docker compose is now a command in docker and i have been using it without thinking about it  on the ubuntu server that doesn t work and instead i am using the  docker compose  command  i  assumed  these were functionally the same but i think docker compose is causing the failure  if i build my frontend service manually with docker and my dev dockerfile and then run it with docker it works perfectly  no warnings  building with docker compose works    but throws a number a warnings  so it isn t finding the yarn lock file   which is there   and throwing a number of module errors  again  this does not occur on my arch machine running  docker compose  but does on an ubuntu   server running docker compose i did try adding a volume directly to the node_module directory as per  amir s answer but that did not work  i also tried changing the copy location for the dockerfile as per that answer  no joy  ideas  i am really stuck here ,vue cli errors trying to deploy vue app with docker
173,5108504,55446866,Laravel 5 Server Error 500 Hosting in cpanel,"<p>I have already uploaded my laravel project folder into cpanel hosting. I have followed many examples here but still getting the famous 500 internal error. This is what I have done:</p>

<p>I has separated public folder in my laravel project and put in my public_html folder. I have made the rest of my laravel project into myapp folder.</p>

<p>Into my public_html folder, I have changed this lines:</p>

<pre><code>require __DIR__.'/../myapp/vendor/autoload.php';

/*
|--------------------------------------------------------------------------
| Turn On The Lights
|--------------------------------------------------------------------------
|
| We need to illuminate PHP development, so let us turn on the lights.
| This bootstraps the framework and gets it ready for use, then it
| will load up this application so that we can run it and send
| the responses back to the browser and delight our users.
|
*/

$app = require_once __DIR__.'/../myapp/bootstrap/app.php';
</code></pre>

<p>This is my .env file:</p>

<pre><code>APP_NAME=Driveostle
APP_ENV=local
APP_KEY=base64:xxx
APP_DEBUG=true
APP_LOG_LEVEL=debug
APP_URL=http://www.driveostle.ma
</code></pre>

<p>This is my .htaccess file:</p>

<pre><code>&lt;IfModule mod_rewrite.c&gt;
    &lt;IfModule mod_negotiation.c&gt;
        Options -MultiViews
    &lt;/IfModule&gt;

    RewriteEngine On

    # Redirect Trailing Slashes If Not A Folder...
    RewriteCond %{REQUEST_FILENAME} !-d
    RewriteCond %{REQUEST_URI} (.+)/$
    RewriteRule ^ %1 [L,R=301]

    # Handle Front Controller...
    RewriteCond %{REQUEST_FILENAME} !-d
    RewriteCond %{REQUEST_FILENAME} !-f
    RewriteRule ^ index.php [L]

    # Handle Authorization Header
    RewriteCond %{HTTP:Authorization} .
    RewriteRule .* - [E=HTTP_AUTHORIZATION:%{HTTP:Authorization}]
&lt;/IfModule&gt;

</code></pre>

<p>This is my server.php file:</p>

<pre><code>&lt;?php

/**
 * Laravel - A PHP Framework For Web Artisans
 *
 * @package  Laravel
 * @author   Taylor Otwell &lt;taylor@laravel.com&gt;
 */

$uri = urldecode(
    parse_url($_SERVER['REQUEST_URI'], PHP_URL_PATH)
);

// This file allows us to emulate Apache's ""mod_rewrite"" functionality from the
// built-in PHP web server. This provides a convenient way to test a Laravel
// application without having installed a ""real"" web server software here.
if ($uri !== '/' &amp;&amp; file_exists(__DIR__.'/public'.$uri)) {
    return false;
}

require_once __DIR__.'/public/index.php';
</code></pre>

<p>I still got the HTTP ERROR 500 after typing my domaine name.</p>

<p>After searching here, I have found someone that asked for editing the .htaccess by adding this code:</p>

<pre><code>&lt;IfModule mod_rewrite.c&gt;
   RewriteEngine On 
   RewriteRule ^(.*)$ public/$1 [L]
&lt;/IfModule&gt;
</code></pre>

<p>The error that I obtained was different:</p>

<pre><code>Internal Server Error
The server encountered an internal error or misconfiguration and was unable to complete your request.

Please contact the server administrator at webmaster@driveostle.ma to inform them of the time this error occurred, and the actions you performed just before this error.

More information about this error may be available in the server error log.

Additionally, a 500 Internal Server Error error was encountered while trying to use an ErrorDocument to handle the request.
</code></pre>

<p>Also, my PHP Selector version in Cpanel, I have choose the 7.1 version.</p>

<p>And in my composer.json file:</p>

<pre><code>{
    ""name"": ""laravel/laravel"",
    ""description"": ""The Laravel Framework."",
    ""keywords"": [""framework"", ""laravel""],
    ""license"": ""MIT"",
    ""type"": ""project"",
    ""require"": {
        ""php"": ""&gt;=7.0.0"",
        ""fideloper/proxy"": ""~3.3"",
        ""intervention/image"": ""^2.4"",
        ""laravel/framework"": ""5.5.*"",
        ""laravel/tinker"": ""~1.0"",
        ""mews/purifier"": ""^2.0""
    },
...
</code></pre>

<p>I don't know what is missed in my configuration, It is my first time hosting a laravel website, I hope the elements that I have posted will give you an idea of what I have missed.</p>

<p>If you need any file content, I will post it with pleasure.</p>

<p>Thank you</p>
",5880,3,1,5,laravel;.htaccess;laravel-5;cpanel;web-hosting,2019-04-01 03:55:29,2019-04-01 03:55:29,2022-06-23 03:22:36,i have already uploaded my laravel project folder into cpanel hosting  i have followed many examples here but still getting the famous  internal error  this is what i have done  i has separated public folder in my laravel project and put in my public_html folder  i have made the rest of my laravel project into myapp folder  into my public_html folder  i have changed this lines  this is my  env file  this is my  htaccess file  this is my server php file  i still got the http error  after typing my domaine name  after searching here  i have found someone that asked for editing the  htaccess by adding this code  the error that i obtained was different  also  my php selector version in cpanel  i have choose the   version  and in my composer json file  i don t know what is missed in my configuration  it is my first time hosting a laravel website  i hope the elements that i have posted will give you an idea of what i have missed  if you need any file content  i will post it with pleasure  thank you,laravel  server error  hosting in cpanel
174,1243041,56134577,Import a pyi (type stub file) into a normal python module,"<p>I have a program (like a macro) that runs within a parent program and imports an API module from that program (lets call it <code>foo</code>). The problem is that that module only exists within that program, so I can't do things like run <a href=""https://github.com/NiklasRosenstein/pydoc-markdown"" rel=""noreferrer"">pydocmd</a> outside the software because the script throws a ReferenceError. To aid in my own development I have create a type stub file, <code>foo.pyi</code>, in my project directory. What I would like to do is import that type stub as a normal Python file if the import fails, to provide dummy functions and properties. Something like:</p>

<pre class=""lang-py prettyprint-override""><code>try:
  import foo
except ImportError:
  from . import foo.pyi
</code></pre>

<p>This raises an error, however, as it's trying to import <code>pyi</code> from the <code>foo</code> library that does not exist in the project folder. The only other option I can think of is to have an identical copy of the .pyi file as, say ""dummy_foo.py"" but then I have to maintain two copies of the same file in one repo. I'd rather not do that.</p>
",2140,1,11,5,python;import;python-import;stub;pyi,2019-05-14 19:10:10,2019-05-14 19:10:10,2022-06-22 23:23:11,i have a program  like a macro  that runs within a parent program and imports an api module from that program  lets call it foo   the problem is that that module only exists within that program  so i can t do things like run  outside the software because the script throws a referenceerror  to aid in my own development i have create a type stub file  foo pyi  in my project directory  what i would like to do is import that type stub as a normal python file if the import fails  to provide dummy functions and properties  something like  this raises an error  however  as it s trying to import pyi from the foo library that does not exist in the project folder  the only other option i can think of is to have an identical copy of the  pyi file as  say dummy_foo py but then i have to maintain two copies of the same file in one repo  i d rather not do that ,import a pyi  type stub file  into a normal python module
175,19382407,72719438,How to maximize ffmpeg crop and overlay thousand block in same time?,"<p>I try to encrypt a frame of video to random of 16x16 block. so the result will be like artifact video. but exactly it can be decode back. only the creation that know the decode algorithm. but my problem is ffmpeg encode so slow. 3 minutes video, 854x480 (480p) <a href=""https://www.youtube.com/watch?v=dyRsYk0LyA8"" rel=""nofollow noreferrer"">https://www.youtube.com/watch?v=dyRsYk0LyA8</a>. this example result frame that have been filter <a href=""https://i.ibb.co/0nvLzkK/output-9.jpg"" rel=""nofollow noreferrer"">https://i.ibb.co/0nvLzkK/output-9.jpg</a>. each frame have 1589 block. how to speed up this things? 3 minutes only 24 frame done. the vido have 5000 thousand frame, so for 3 minutes video it takes 10 hours. i dont know why  ffmpeg only take my cpu usage 25%.</p>
<pre><code>const { spawn } = require('child_process');
const fs = require('fs');

function shuffle(array) {
    let currentIndex = array.length,  randomIndex;
  
    // While there remain elements to shuffle.
    while (currentIndex != 0) {
  
      // Pick a remaining element.
      randomIndex = Math.floor(Math.random() * currentIndex);
      currentIndex--;
  
      // And swap it with the current element.
      [array[currentIndex], array[randomIndex]] = [
        array[randomIndex], array[currentIndex]];
    }
  
    return array;
  }

function filter(width, height) {
    const sizeBlock = 16;
    let filterCommands = '';
    let totalBlock = 0;
    const widthLengthBlock = Math.floor(width / sizeBlock);
    const heightLengthBlock = Math.floor(height / sizeBlock);
    let info = [];

    for (let i=0; i &lt; widthLengthBlock; i++) {
        for (let j=0; j &lt; heightLengthBlock; j++) {
            const xPos = i*sizeBlock;
            const yPos = j*sizeBlock;
            filterCommands += `[0]crop=${sizeBlock}:${sizeBlock}:${(xPos)}:${(yPos)}[c${totalBlock}];`;

            info.push({
                id: totalBlock,
                x: xPos,
                y: yPos
            });

            totalBlock += 1;
        }   
    }

    info = shuffle(info);

    for (let i=0; i &lt; info.length; i++) {
        if (i == 0) filterCommands += '[0]';
        if (i != 0) filterCommands += `[o${i}]`;

        filterCommands += `[c${i}]overlay=x=${info[i].x}:y=${info[i].y}`;

        if (i != (info.length - 1)) filterCommands += `[o${i+1}];`;     
    }

    return filterCommands;
}

const query = filter(854, 480);

fs.writeFileSync('filter.txt', query);

const task = spawn('ffmpeg', [
    '-i',
    'C:\\Software Development\\ffmpeg\\blackpink.mp4',
    '-filter_complex_script',
    'C:\\Software Development\\project\\filter.txt',
    '-c:v',
    'libx264',
    '-preset',
    'ultrafast',
    '-pix_fmt',
    'yuv420p',
    '-c:a',
    'libopus',
    '-progress',
    '-',
    'output.mp4',
    '-y'
], {
    cwd: 'C:\\Software Development\\ffmpeg'
});

task.stdout.on('data', data =&gt; { 
    console.log(data.toString())
})
</code></pre>
",30,0,1,2,node.js;ffmpeg,2022-06-22 20:06:49,2022-06-22 20:06:49,2022-06-22 20:30:34,i try to encrypt a frame of video to random of x block  so the result will be like artifact video  but exactly it can be decode back  only the creation that know the decode algorithm  but my problem is ffmpeg encode so slow   minutes video  x  p    this example result frame that have been filter   each frame have  block  how to speed up this things   minutes only  frame done  the vido have  thousand frame  so for  minutes video it takes  hours  i dont know why  ffmpeg only take my cpu usage   ,how to maximize ffmpeg crop and overlay thousand block in same time 
176,1561944,16530853,Relationship between MSVC and .NET framework versions,"<p>This is a rather general question, a result of my confusion about how to compile GDAL using different versions of Microsoft Visual C++ (MSVC) and its C#-bindings. I understand that MSVC is a compiler and there are different versions (MSVC 2003, 2005, 2008, 2010, 2012). I also understand that C# is tied to the .NET framework, which is a software development framework that also comes in different versions (.NET 1.0 to 5.0).</p>
<p>I want to compile GDAL (because I want to use an extension not included in the SDK builds available <a href=""https://www.gisinternals.com/sdk.php"" rel=""nofollow noreferrer"">here</a>) to be used by C# (via its C#-bindings) using VS 2012, which version of MSVC would I have to use? I guess the answer is MSVC 2012 (same .NET framework version), but why actually? The GDAL build would create DLLs. Is the .NET framework not backwards compatible in the sense that I can use DLLs compiled with an older version of MSVC inside a C#-project that uses VS 2012?</p>
<p>Any enlightenment appreciated.</p>
",191,1,0,4,c#;.net;visual-c++;gdal,2013-05-13 23:47:20,2013-05-13 23:47:20,2022-06-21 23:00:11,this is a rather general question  a result of my confusion about how to compile gdal using different versions of microsoft visual c    msvc  and its c  bindings  i understand that msvc is a compiler and there are different versions  msvc            i also understand that c  is tied to the  net framework  which is a software development framework that also comes in different versions   net   to     i want to compile gdal  because i want to use an extension not included in the sdk builds available   to be used by c   via its c  bindings  using vs   which version of msvc would i have to use  i guess the answer is msvc   same  net framework version   but why actually  the gdal build would create dlls  is the  net framework not backwards compatible in the sense that i can use dlls compiled with an older version of msvc inside a c  project that uses vs   any enlightenment appreciated ,relationship between msvc and  net framework versions
177,514149,65345108,How to share a single GPU deep learning server?,"<p>For our development team we want to build a central GPU server for their deep learning / training tasks (with one or more strong GPU(s) instead of mulitple workstations for each team member with their own GPU). I guess this is a common setup, but I am not sure how to make this GPU sharing work for multiple team members simultaneously. We work with Tensorflow/Keras and Python scripts.</p>
<p>My question is: What is the typical approach to let team members train their models on that central server? Just allow them to access via SSH and do network training directly from command line? Or setup a Jupyter Hub server, so that our developers can run code from their browser?</p>
<p>My main question: If there is only one GPU, how can we make sure that multiple users cannot run their code (i.e. train their networks) at the same time? Is there a way to kind of submit training jobs on a central server software and those are executed on the GPU one after the other?</p>
<p>(Sorry if this is not the correct site to ask this question, but which other Stack Exchange site would be better?)</p>
",241,1,2,5,python;tensorflow;server;deep-learning;architecture,2020-12-17 19:00:18,2020-12-17 19:00:18,2022-06-21 19:18:56,for our development team we want to build a central gpu server for their deep learning   training tasks  with one or more strong gpu s  instead of mulitple workstations for each team member with their own gpu   i guess this is a common setup  but i am not sure how to make this gpu sharing work for multiple team members simultaneously  we work with tensorflow keras and python scripts  my question is  what is the typical approach to let team members train their models on that central server  just allow them to access via ssh and do network training directly from command line  or setup a jupyter hub server  so that our developers can run code from their browser  my main question  if there is only one gpu  how can we make sure that multiple users cannot run their code  i e  train their networks  at the same time  is there a way to kind of submit training jobs on a central server software and those are executed on the gpu one after the other   sorry if this is not the correct site to ask this question  but which other stack exchange site would be better  ,how to share a single gpu deep learning server 
178,19382407,72702771,Inconsistent crop and overflay ffmpeg result with drawImage canvas,"<p>i try to encode the video block frame to specific pattern order, then in front-end it decode back to normal. I test it in back-end by decode back with same function, it back to normal. but in front-end with canvas the order of block not in right position. if you look into front-end function. it have same pattern. i try to check output from <code>for</code> generate, it equal to <code>for</code> in backend overlay builder command.<br />
whats wrong with this?</p>
<p>ffmpeg config</p>
<pre><code>const { spawn } = require('child_process');

function hflip(width) {
    const sizeBlock = 16;
    let filterCommands = '';
    const length = Math.floor(width / sizeBlock);

    for (let i=0; i &lt; length; i++) { 
        filterCommands += `[0]crop=${sizeBlock}:480:${(i*sizeBlock)}:0[c${i}];`;
    }
    
    for (let i=0; i &lt; length; i++) {
        if (i == 0) filterCommands += '[0]';
        if (i != 0) filterCommands += `[o${i}]`;
    
        filterCommands += `[c${i}]overlay=x=${(width - sizeBlock)-(i*sizeBlock)}:y=0`;
    
        if (i != (length - 1)) filterCommands += `[o${i+1}];`;
    }

    return filterCommands;
}

const crops = spawn('ffmpeg', [
    '-i',
    'C:/Software Development/project/blackpink.mp4',
    '-filter_complex',
    hflip(854),
    '-c:a',
    'copy',
    '-c:v',
    'libx264',
    '-crf',
    '30',
    '-preset',
    'ultrafast',
    '-pix_fmt',
    'yuv420p',
    'C:/Software Development/project/hflip.mp4',
    '-y'
], {
    cwd: 'C:/Software Development/ffmpeg'
})
</code></pre>
<p>front-end</p>
<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
    &lt;head&gt;&lt;/head&gt;
    &lt;body&gt;
        &lt;button onclick=""play()""&gt;play&lt;/button&gt;
        &lt;script&gt;
            const canvas = document.createElement('canvas');
            document.body.appendChild(canvas)
            const context = canvas.getContext('2d');
            const video = document.createElement('video');
            video.src = 'https://drive.google.com/uc?export=download&amp;id=1Z0aFg_N3kP0SUO_xOFB0UBjTRH6_mSmb&amp;confirm=t'


            function hflip(video) {
                const widthBlock = 16;
                const heightBlock = 480;
                const length = Math.floor(video.videoWidth / widthBlock);

                for (let i=0; i &lt; length; i++) {
                    console.log({
                        cX: (i*widthBlock),
                        oX: (video.videoWidth - widthBlock) - (i*widthBlock)
                    });

                    context.drawImage(video, (i*widthBlock), 0, widthBlock, heightBlock,  (video.videoWidth - widthBlock) - (i*widthBlock), 0, widthBlock, heightBlock)
                }
            }

            video.onloadedmetadata = () =&gt; {
                context.canvas.width = video.videoWidth;
                context.canvas.height = video.videoHeight;
            }

            video.onplay = () =&gt; {
                const updateCanvas = () =&gt; {
                    hflip(video);            

                    video.requestVideoFrameCallback(updateCanvas);
                }

                updateCanvas();
            }

            function play() { video.play() }
        &lt;/script&gt;
    &lt;/body&gt;
&lt;/html&gt;</code></pre>
</div>
</div>
</p>
",21,0,0,4,javascript;canvas;ffmpeg;html5-canvas,2022-06-21 17:42:52,2022-06-21 17:42:52,2022-06-21 17:42:52,ffmpeg config front end,inconsistent crop and overflay ffmpeg result with drawimage canvas
179,519882,72700642,calculating number of test cases for given number of parameters,"<p>I am reading book Embedded Software Development for software critical systems about combinatorial testing.</p>
<p>Suppose if we have 11 parameters that we can configure the operating system, and each parameter had 5 possible values (for a total of 48,828,125 possible tests, were the system to be tested exhaustively).</p>
<p>Note: Here t is the strength&quot; of the testing (all combinations of t of the parameters).</p>
<p>With t = 2 (i.e., all possible combinations of every pair of parameters), there must be at least 5 * 4 = 20 test cases and, For t = 3, there must be at least 5 * 4 * 4 = 80 test cases.</p>
<p>My question is how we author got 5 *4 for t =2 and 5 *4 *4 for t=3? Is there any generic formula present? Kindly help me to understand.</p>
<p>Thanks for your time and help</p>
",21,0,0,3,testing;combinations;combinatorics,2022-06-21 15:18:12,2022-06-21 15:18:12,2022-06-21 15:18:12,i am reading book embedded software development for software critical systems about combinatorial testing  suppose if we have  parameters that we can configure the operating system  and each parameter had  possible values  for a total of    possible tests  were the system to be tested exhaustively   note  here t is the strength  of the testing  all combinations of t of the parameters   with t     i e   all possible combinations of every pair of parameters   there must be at least        test cases and  for t     there must be at least           test cases  my question is how we author got    for t   and      for t   is there any generic formula present  kindly help me to understand  thanks for your time and help,calculating number of test cases for given number of parameters
180,19382407,72700457,how to use crop and overlay properly?,"<p>Is crop and overlay have bug when chain too many? i got inconsistent function. for test, i create horizontal flip builder command. i try to flip the video. but its like something wrong with overlay filter. the filter not overlay in specific location.</p>
<p>let me explain my understanding of crop filter first. crop take 4 parameters: <code>width:height:xPosition:yPosition</code>. in first <code>crop=16:480:0:0</code>. how about if i want to crop 2nd image. is right with this <code>crop=16:480:16:0</code>? or it should <code>crop=16:480:17:0</code> always add 1 after first crop?</p>
<p>and overlay, the first overlay. <code>overlay=x=0:y=0</code>. how about the 2nd overlay and so on? is it right <code>overlay=x=16:y=0</code> or it should <code>overlay=x=17:y=0</code>. always add 1 after first overlay.</p>
<p>i tested it, always theres glitch in video.</p>
<pre><code>const { spawn } = require('child_process');

function hflip(width) {
    let filterCommands = '';
    const length = Math.floor(width / 16);

    for (let i=0; i &lt; length; i++) {
        filterCommands += `[0]crop=16:480:${i*16}:0[c${i}];`;
    }
    
    for (let i=0; i &lt; length; i++) {
        if (i == 0) filterCommands += '[0]';
        if (i != 0) filterCommands += `[o${i}]`;
    
        filterCommands += `[c${i}]overlay=x=${832-(i*16)}:y=0`;
    
        if (i != (length - 1)) filterCommands += `[o${i+1}];`;
    }

    return filterCommands;
}


const crops = spawn('ffmpeg', [
    '-i',
    'C:/Software Development/project/input.mp4',
    '-filter_complex',
    hflip(854),
    '-c:a',
    'copy',
    '-c:v',
    'libx264',
    '-crf',
    '30',
    '-preset',
    'ultrafast',
    'C:/Software Development/project/output.mp4',
    '-y'
], {
    cwd: 'C:/Software Development/ffmpeg'
})
</code></pre>
",22,0,0,1,ffmpeg,2022-06-21 15:03:39,2022-06-21 15:03:39,2022-06-21 15:03:39,is crop and overlay have bug when chain too many  i got inconsistent function  for test  i create horizontal flip builder command  i try to flip the video  but its like something wrong with overlay filter  the filter not overlay in specific location  let me explain my understanding of crop filter first  crop take  parameters  width height xposition yposition  in first crop      how about if i want to crop nd image  is right with this crop      or it should crop     always add  after first crop  and overlay  the first overlay  overlay x  y   how about the nd overlay and so on  is it right overlay x  y  or it should overlay x  y   always add  after first overlay  i tested it  always theres glitch in video ,how to use crop and overlay properly 
181,7787442,72690588,AWS devops engineer question. Which architecture will meet these requirements with the least amount of configuration?,"<p>I have a doubt regarding this question of the AWS devops engineer certification:</p>
<blockquote>
<p>A Devops Engineer is architecting a continuous development strategy for a company's software as a Service web application running on AWS. For application and security reasons, users subscribing to this application are distributed across multiple Application Load Balancers each of which has a dedicated Auto Scaling group fleet of Amazon EC2 instances. The application must trigger a simultaneous deployment to all ALBs, Auto Scaling groups, and EC2 fleets. Which architecture will meet these requirements with the least amount of configuration?</p>
</blockquote>
<blockquote>
<p>A- Create a single AWS Code Pipeline pipeline that deploys the application in in parallel using unique AWS CodeDeploy applications and deployment groups created for each ALB-AutoScaling group pair.</p>
</blockquote>
<blockquote>
<p>B- Create a single AWS CodePipeline pipeline that deploys the application using a single AWS CodeDeplot application and single deployment group.</p>
</blockquote>
<blockquote>
<p>C- Create a single AWS CodePipeline that deploys the application in parallel using a single AWS CodeDeploy application and unique deployment group for each ALB-AUtoscaling group pair</p>
</blockquote>
<blockquote>
<p>D- Create an AWS CodePipeline pipeline for each ALB-Auto Scaling group pair that deploys the application using an AWS CodeDeploy application and deployment group created for the same ALB-Auto scaling group pair</p>
</blockquote>
",34,1,-1,2,amazon-web-services;aws-devops,2022-06-20 20:02:38,2022-06-20 20:02:38,2022-06-20 20:02:38,i have a doubt regarding this question of the aws devops engineer certification  a devops engineer is architecting a continuous development strategy for a company s software as a service web application running on aws  for application and security reasons  users subscribing to this application are distributed across multiple application load balancers each of which has a dedicated auto scaling group fleet of amazon ec instances  the application must trigger a simultaneous deployment to all albs  auto scaling groups  and ec fleets  which architecture will meet these requirements with the least amount of configuration  a  create a single aws code pipeline pipeline that deploys the application in in parallel using unique aws codedeploy applications and deployment groups created for each alb autoscaling group pair  b  create a single aws codepipeline pipeline that deploys the application using a single aws codedeplot application and single deployment group  c  create a single aws codepipeline that deploys the application in parallel using a single aws codedeploy application and unique deployment group for each alb autoscaling group pair d  create an aws codepipeline pipeline for each alb auto scaling group pair that deploys the application using an aws codedeploy application and deployment group created for the same alb auto scaling group pair,aws devops engineer question  which architecture will meet these requirements with the least amount of configuration 
182,5683522,72688902,Problem with connection acquisition when using knex and serverless-offline,"<h1>Setup</h1>
<p>I'm building a serverless application that uses a website frontend. The website sends queries to the API, which connects to the database. The infrastructure is hosted on the AWS, but the problem I have ran into only affected the local development. A key component of this setup is the serverless API, which uses Lambdas for each API route. To ensure that connections to the database are present, I connect to the database and pass that connection to the ORM prior to the execution of the handler, and to ensure that no idle connections remain after completing the query, I destroy them once the handler completes (be it with error or gracefully). The logic behind these is sound, as far as implementation goes.</p>
<h2>Stack</h2>
<p>I am running Serverless with Serverless Offline plugin to develop a Node 14 application locally. The database is a Postgres instance, which I connect to using Objection.JS as ORM. Under the hood, Objection uses Knex to manage the connection, handle query building etc.</p>
<h2>Versions</h2>
<p>The versions of software used.</p>
<ul>
<li>Node 14</li>
<li>knex (2.1.0)</li>
<li>objection (3.0.1)</li>
<li>serverless (2.55.0)</li>
<li>serverless-offline (8.7.0)</li>
</ul>
<h1>Problem</h1>
<p>The problem I have ran into is connections not being available, when running the setup locally using serverless-offline. Despite connecting to the database at the start of the handler, sometimes, the API queries throw an error stating that connection could not be acquired, or that no database is available to a query. This happens intermittently, and sometimes the same API calls execute without any problems.</p>
<p>I have realised that this happens only when multiple API queries are being executed simultaneously, although once again, not always.</p>
<h2>Pseudocode</h2>
<p>The lambda handler in serverless-offline looks something like this:</p>
<pre class=""lang-js prettyprint-override""><code>module.exports.handler = async function() {
  const connection = await connectToDatabase();
  await ORM.databaseConnection.setup(connection);

  // ...

  const results = ORM.executeQuery();

  // ...

  await ORM.databaseConnection.destroy();
  return results;
}
</code></pre>
",93,1,1,5,database-connection;serverless;knex.js;objection.js;serverless-offline,2022-06-20 17:48:12,2022-06-20 17:48:12,2022-06-20 17:48:12,i m building a serverless application that uses a website frontend  the website sends queries to the api  which connects to the database  the infrastructure is hosted on the aws  but the problem i have ran into only affected the local development  a key component of this setup is the serverless api  which uses lambdas for each api route  to ensure that connections to the database are present  i connect to the database and pass that connection to the orm prior to the execution of the handler  and to ensure that no idle connections remain after completing the query  i destroy them once the handler completes  be it with error or gracefully   the logic behind these is sound  as far as implementation goes  i am running serverless with serverless offline plugin to develop a node  application locally  the database is a postgres instance  which i connect to using objection js as orm  under the hood  objection uses knex to manage the connection  handle query building etc  the versions of software used  the problem i have ran into is connections not being available  when running the setup locally using serverless offline  despite connecting to the database at the start of the handler  sometimes  the api queries throw an error stating that connection could not be acquired  or that no database is available to a query  this happens intermittently  and sometimes the same api calls execute without any problems  i have realised that this happens only when multiple api queries are being executed simultaneously  although once again  not always  the lambda handler in serverless offline looks something like this ,problem with connection acquisition when using knex and serverless offline
183,317428,2658518,Windows Aero areas in own C# Applications,"<p>I'm wondering about that many new applications, I think most built in WPF, has this really cool Windows Aero Glass interfaces.</p>

<p>For example Seesmic or the upcoming Firefox 3.7
<a href=""https://i.stack.imgur.com/uGIPu.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/uGIPu.png"" alt=""http://crenk.com/wp-content/uploads/2010/04/firefox3.7.jpg""></a><br>
<sub>(source: <a href=""http://crenk.com/wp-content/uploads/2010/04/firefox3.7.jpg"" rel=""nofollow noreferrer"">crenk.com</a>)</sub>  </p>

<p>Searching in the internet most time it looks like you need a hack to realize this. But seriously: I don't think big software development teams use hacks to roll out their huge used products.</p>

<p>So my question is: <strong>Windows Aero Glass Areas - How to do?</strong></p>

<p>Is it only possible with a hack?</p>

<p>Maybe it's just one property, i don't know. I'm WinForms developer so I never tested out WPF. But my Google search didn't look like It is easier with WPF.</p>
",762,1,3,4,c#;windows;aero;aero-glass,2010-04-17 16:38:12,2010-04-17 16:38:12,2022-06-20 11:21:25,i m wondering about that many new applications  i think most built in wpf  has this really cool windows aero glass interfaces  searching in the internet most time it looks like you need a hack to realize this  but seriously  i don t think big software development teams use hacks to roll out their huge used products  so my question is  windows aero glass areas   how to do  is it only possible with a hack  maybe it s just one property  i don t know  i m winforms developer so i never tested out wpf  but my google search didn t look like it is easier with wpf ,windows aero areas in own c  applications
184,9778881,72673531,How to separate strings into 2D vector?,"<p>This is the file with data that I'm reading from:</p>
<pre class=""lang-none prettyprint-override""><code>MATH201,Discrete Mathematics
CSCI300,Introduction to Algorithms,CSCI200,MATH201
CSCI350,Operating Systems,CSCI300
CSCI101,Introduction to Programming in C++,CSCI100
CSCI100,Introduction to Computer Science
CSCI301,Advanced Programming in C++,CSCI101
CSCI400,Large Software Development,CSCI301,CSCI350
CSCI200,Data Structures,CSCI101
</code></pre>
<p>I have successfully read from the file and stored this information in a 2D Vector, but when I check the size of specific rows using <code>course.info[x].size()</code> it appears that its only counting the strings that have spaces between them. So for example, <code>course.info[2].size()</code> returns 2, whereas I would rather it would return 3. Essentially I want it to count each bit of information that is separated by a comma instead of a space.  If I use <code>while (getline(courses, line, ',')</code> it puts the information separated by a comma in their own row, which is not what I want.</p>
<pre><code>void LoadFile() {
vector&lt;vector&lt;string&gt;&gt; courseInfo;


ifstream courses;
courses.open(&quot;CourseInfo.txt&quot;);

if (!courses.is_open()) {
    cout &lt;&lt; &quot;Error opening file&quot;;
}

if (courses) {
    string line;

    while (getline(courses, line)) {
        courseInfo.push_back(vector&lt;string&gt;());

        stringstream split(line);
        string value;

        while (split &gt;&gt; value) {
            courseInfo.back().push_back(value);
        }
    }
}

for (int i = 0; i &lt; courseInfo.size(); i++) {
    for (int j = 0; j &lt; courseInfo[i].size(); j++)
        std::cout &lt;&lt; courseInfo[i][j] &lt;&lt; ' ';

    std::cout &lt;&lt; '\n';
}
</code></pre>
",60,1,0,2,c++;vector,2022-06-19 03:13:30,2022-06-19 03:13:30,2022-06-20 09:13:15,this is the file with data that i m reading from  i have successfully read from the file and stored this information in a d vector  but when i check the size of specific rows using course info x  size   it appears that its only counting the strings that have spaces between them  so for example  course info   size   returns   whereas i would rather it would return   essentially i want it to count each bit of information that is separated by a comma instead of a space   if i use while  getline courses  line       it puts the information separated by a comma in their own row  which is not what i want ,how to separate strings into d vector 
185,9936452,57478269,How to create basic IFC File in C#,"<p>As per Wiki, The Industry Foundation Classes (IFC) data model is intended to describe architectural, building and construction industry data.</p>

<p>The Industry Foundation Classes (IFC) data model is a neutral and open specification that is not controlled by a single vendor or group of vendors. It is an object oriented file format with a data model developed by buildingSMART (International Alliance for Interoperability, IAI) to facilitate interoperability in the building industry, and is a commonly used format for Building Information Modeling (BIM).</p>

<p>For example One could be developing virtual building model in Revit, then send it to interior team who use ArchiCAD. It might also be sent to engineers who use Tekla. Before the IFC standard file type this would have been a nightmare. As Revit, ArchiCAD, Tekla can talk to each other, but not easily!!!</p>

<p>IFC aims to solve this problem, so that it won't matter so much. IFC file is unified format which can be understood by other CAD Softwares as well.</p>

<p>My Organisation works on one of the CAD Software and they want to export there Models in IFC so that it can be open and viewed in Other software's as well like Revit, ArchiCAD, Tekla.</p>

<p>So Our use case is, we need to create a IFC file of such a model.</p>

<p>So as per this Post, I am planning to use xBim. This link</p>

<p>I am using xBim Library to Create IFC File in C#. As per xBim documentation and Sample Code, I found that, How to create a Simple wall.</p>

<p>Now I want to create a basic Xbim.Ifc4.HvacDomain.IfcPump.</p>

<p>Can someone help me how to create one Xbim.Ifc4.HvacDomain.IfcPump in IFC using xBim C#?</p>

<p>I am new in CAD development and hence I am finding difficulties to understand the IFC. Please do the needful.</p>

<p>I hope this much information will be helpful,enough and clear.</p>

<p>Thanks in advance!!!</p>
",2048,1,0,3,c#;ifc;xbim,2019-08-13 16:00:21,2019-08-13 16:00:21,2022-06-20 01:09:12,as per wiki  the industry foundation classes  ifc  data model is intended to describe architectural  building and construction industry data  the industry foundation classes  ifc  data model is a neutral and open specification that is not controlled by a single vendor or group of vendors  it is an object oriented file format with a data model developed by buildingsmart  international alliance for interoperability  iai  to facilitate interoperability in the building industry  and is a commonly used format for building information modeling  bim   for example one could be developing virtual building model in revit  then send it to interior team who use archicad  it might also be sent to engineers who use tekla  before the ifc standard file type this would have been a nightmare  as revit  archicad  tekla can talk to each other  but not easily    ifc aims to solve this problem  so that it won t matter so much  ifc file is unified format which can be understood by other cad softwares as well  my organisation works on one of the cad software and they want to export there models in ifc so that it can be open and viewed in other software s as well like revit  archicad  tekla  so our use case is  we need to create a ifc file of such a model  so as per this post  i am planning to use xbim  this link i am using xbim library to create ifc file in c   as per xbim documentation and sample code  i found that  how to create a simple wall  now i want to create a basic xbim ifc hvacdomain ifcpump  can someone help me how to create one xbim ifc hvacdomain ifcpump in ifc using xbim c   i am new in cad development and hence i am finding difficulties to understand the ifc  please do the needful  i hope this much information will be helpful enough and clear  thanks in advance   ,how to create basic ifc file in c 
186,19369520,72677642,Unexpected result spawn of stdout,"<p>I try to spawn git process but i got unexpected result. stdout pipe empty. while the stderr pipe only clonning directory info. it should output cloning directory then progress of clonning.</p>
<pre><code>const { spawn } = require('child_process');

const subprocess = spawn('git', ['clone', 'https://github.com/expressjs/express.git'], {
    cwd: 'C:/Software Development/git/bin'
});

subprocess.stdout.on('data', data =&gt; {
    console.log('Body info: \n')
    console.log(data.toString())
});

subprocess.stderr.on('data', data =&gt; {
    console.log('Error info: \n')
    console.log(data.toString())
})
</code></pre>
",13,0,0,3,node.js;child-process;spawn,2022-06-19 17:22:53,2022-06-19 17:22:53,2022-06-19 17:22:53,i try to spawn git process but i got unexpected result  stdout pipe empty  while the stderr pipe only clonning directory info  it should output cloning directory then progress of clonning ,unexpected result spawn of stdout
187,788048,11066958,"In the Model-View-Controller principle, what is the Frontend and what is the Backend?","<p>Wikipedia says: </p>

<blockquote>
  <p>MVC provides front and back ends for the database, the user, and the
  data processing components. The separation of software systems into
  front and back ends simplifies development and separates maintenance.</p>
</blockquote>

<p>I still don't see the link between the model-view-controller principle and the idea of front- and backend. Can the Model with its access to the database be seen as the Backend and the View as the frontend? </p>
",39861,6,29,1,model-view-controller,2012-06-16 23:53:34,2012-06-16 23:53:34,2022-06-18 22:48:14,wikipedia says   i still don t see the link between the model view controller principle and the idea of front  and backend  can the model with its access to the database be seen as the backend and the view as the frontend  ,in the model view controller principle  what is the frontend and what is the backend 
188,186338,72660959,How to handle PropertyChanged events in related classes?,"<p>I'm migrating a legacy application from C to C# (.NET Core 5), and implementing more modern software development practices. The C application had literally all of its data in structures in RAM, all of which were globally available. This is great for simple applications but violates the heck out of the principle of encapsulation. The closest equivalent of doing this in an object-oriented fashion is to make the datastore <code>static</code> (which I don't want to do, for obvious reasons).</p>
<p>The application at hand is highly technical and involves a great deal of math. The previous application calculated a lot of derived values (sometimes repeatedly!) on demand, however this doesn't take advantage of multi-threading or caching.</p>
<p>To demonstrate a simpler yet analogous example, let's say we have a program to manage the costs associated with a baseball team. A team has its own fixed operating costs, as well as one manager (who has a salary), and zero to many players (who also each have salaries).</p>
<p>This is my redesigned data model:</p>
<pre><code>public class Team {
    public int Costs { get; set; }
    public Manager Manager { get; set; }
    public HashSet&lt;Player&gt; Players { get; set; }

    private int _operatingCosts;
    public int OperatingCosts {
        get {
            return this._operatingCosts;
        }
        private set {
            // Note the private setter -- this should only be recalculated within this 
            // method from its own values.
            this._operatingCosts = value;
        }
    }
}
public class Manager {
   public string Name { get; set; }
   public int Salary { get; set; }
}
public class Player {
    public string Name { get; set; }
    public int Salary { get; set; }
}
   
</code></pre>
<p>The C code would have a function that runs and puts its fingers in all of the arrays, finds the appropriate elements, and adds them up. In the rewritten C# code, MOST of these calculations are reasonably simple, so they probably are best implemented as read-only calculated properties.</p>
<pre><code>public class Manager {
    public int MonthlySalary {
        get {
            return this.Salary / 12;
        }
    }
}
</code></pre>
<p>The challenge comes when trying to calculate the total cost of running the team. This might be a complex operation that I don't want to have to run each time, so I'll want to cache a value and only recalculate it when an event fires. We know which variables cause the change, so we can fire the event from within the dependent properties' setters.</p>
<pre><code>public class Team : INotifyPropertyChanged {
    private int _costs;
    public int Costs {
        get {
            return this._costs;
        }
        set {
            this._costs = value;
            NotifyPropertyChanged();    // Fire recalculation on cost change.
        }
    }
    public int Name {
        get; set;    // No INotifyPropertyChanged needed; cached values aren't 
                     // dependent on this.
    }
    private int _totalOperatingCost;
    public int TotalOperatingCost {
        get {
             return this._totalOperatingCost;
        }
        private set {
             this._totalOperatingCost = value;
        }
    }
    protected void RecalculateCosts() {
        this._totalOperatingCost = this.Team.Cost + this.Manager.Salary + this.Players.Sum(p =&gt; p.Salary);
    }
}
</code></pre>
<p>This has been working really well with <code>INotifyPropertyChanged</code> -- I fire a <code>PropertyChanged</code> event on fields that should trigger a recalculation, and the recalculation logic is there and in one place, and all is well.</p>
<p>Now here's the problem: what happens if the manager's salary changes?</p>
<pre><code>public class Manager : INotifyPropertyChanged {
    private int _salary;
    public int Salary {
        get {
            return this._salary;
        }
        set {  
            this._salary = value;
            NotifyParentPropertyChanged();
        }
    }
}
</code></pre>
<p>The <code>Manager</code> class does not contain a reference to the <code>Team</code> to which he belongs. There's a lot of potential for error retaining a backreference from the child bean to the parent when the parent knows about its own children. So if I call <code>NotifyPropertyChanged()</code> here, the <code>Manager</code> will update his own calculations but it has no idea it needs to update on the parent. This is also mostly resolvable using events, but there's a big hitch:</p>
<pre><code>public class Team {
    public string Name { ... }
    private Manager _manager;
    public Manager Manager {
        get {
            return this._manager;
        }
        set {
            if (this._manager is not null) {
                this._manager.PropertyChanged -= ProcessParentPropertyChangedEvent;
            }

            this._manager = value;
            NotifyPropertyChanged();

            if (this._manager is not null) {
                this._manager.PropertyChanged += ProcessParentPropertyChangedEvent;
            }
        }
    }

    public Team() {
        if (this.Manager is not null) {
            this.Manager.PropertyChanged += ProcessParentPropertyChangedEvent;
        }
    }

    public static void ProcessParentPropertyChangedEvent(object sender, EventArgs e) {
        // ^^^^^^ THIS IS A STATIC METHOD, so &quot;this&quot; is unavailable.
        //
        // When called from Manager.Salary, sender.GetType().Name = &quot;Manager&quot; and 
        // e can ONLY carry information from the Manager and knows nothing about 
        // the Team.
        //
        // Literally nothing in this method knows about the current team, or I believe
        // can know about the team to which the manager belongs.          
    }
}
public class Manager {
    private int _salary;
    public int Salary {
        get {
            return this._salary;
        }
        set {
            this._salary = value;
            NotifyParentPropertyChanged();
        }
    }
}
</code></pre>
<p>The event fires properly but because the callback method is <code>static</code>, there's no link to the <code>Team</code> whose <code>Manager</code>'s salary just updated. <code>Player</code> would have a similar problem, there's no way to inform the <code>Team</code> class that a <code>Player</code>'s salary updated since the recalculation would take place within a static method.</p>
<p>Similarly, we could need to add or subtract players from the team as well, which should also force a recalculation of our team costs. I've gone down this road some with <code>INotifyCollectionChanged</code>, but no luck -- we still end up in a static method with no information about where the changes need to be applied to.</p>
<p>I believe my options are as follows:</p>
<p>(1) Include backreferences to parent elements. This seems somewhat straightforward, but there is a lot that can go wrong here, and garbage collection may be one of them. There are probably going to be about a million elements in memory, and I'm not sure how well this would perform by everything basically being in a doubly-connected graph.</p>
<p>(2) I've looked into the Mediator pattern, but I'm not convinced this still solves my problems without a great deal of error-prone accounting. It also requires the <code>Mediator</code> class to be injected into all of my data elements, and requires me to use extensions for base .NET generic collections types -- I don't want to be forced to always use custom types like <code>MyPlayersList</code> or similar, instead of the more common <code>List&lt;Player&gt;</code> -- especially when NOT using the custom list would likely end in a subtle and silent bug when a recalculation just didn't quite pull the right values.</p>
<p>What are my options? Am I forced to carry tons of backreferences throughout the model?</p>
<p>Is there a different model for event handling that I'm not aware of? I've been working with <code>INotifyPropertyChanged</code> because I'm used to it from a WPF context and it's really fast -- 1,000,000 calls in 60 ms on my machine. That said I don't know if there are any other event handling paradigms that exist to handle this type of case.</p>
<p>This seems like way too straightforward an issue to not have appeared and been solved by someone else before. Thanks so much!</p>
",24,0,1,5,c#;.net-core;events;data-modeling;inotifypropertychanged,2022-06-17 17:31:10,2022-06-17 17:31:10,2022-06-17 17:31:10,i m migrating a legacy application from c to c    net core    and implementing more modern software development practices  the c application had literally all of its data in structures in ram  all of which were globally available  this is great for simple applications but violates the heck out of the principle of encapsulation  the closest equivalent of doing this in an object oriented fashion is to make the datastore static  which i don t want to do  for obvious reasons   the application at hand is highly technical and involves a great deal of math  the previous application calculated a lot of derived values  sometimes repeatedly   on demand  however this doesn t take advantage of multi threading or caching  to demonstrate a simpler yet analogous example  let s say we have a program to manage the costs associated with a baseball team  a team has its own fixed operating costs  as well as one manager  who has a salary   and zero to many players  who also each have salaries   this is my redesigned data model  the c code would have a function that runs and puts its fingers in all of the arrays  finds the appropriate elements  and adds them up  in the rewritten c  code  most of these calculations are reasonably simple  so they probably are best implemented as read only calculated properties  the challenge comes when trying to calculate the total cost of running the team  this might be a complex operation that i don t want to have to run each time  so i ll want to cache a value and only recalculate it when an event fires  we know which variables cause the change  so we can fire the event from within the dependent properties  setters  this has been working really well with inotifypropertychanged    i fire a propertychanged event on fields that should trigger a recalculation  and the recalculation logic is there and in one place  and all is well  now here s the problem  what happens if the manager s salary changes  the manager class does not contain a reference to the team to which he belongs  there s a lot of potential for error retaining a backreference from the child bean to the parent when the parent knows about its own children  so if i call notifypropertychanged   here  the manager will update his own calculations but it has no idea it needs to update on the parent  this is also mostly resolvable using events  but there s a big hitch  the event fires properly but because the callback method is static  there s no link to the team whose manager s salary just updated  player would have a similar problem  there s no way to inform the team class that a player s salary updated since the recalculation would take place within a static method  similarly  we could need to add or subtract players from the team as well  which should also force a recalculation of our team costs  i ve gone down this road some with inotifycollectionchanged  but no luck    we still end up in a static method with no information about where the changes need to be applied to  i believe my options are as follows     include backreferences to parent elements  this seems somewhat straightforward  but there is a lot that can go wrong here  and garbage collection may be one of them  there are probably going to be about a million elements in memory  and i m not sure how well this would perform by everything basically being in a doubly connected graph     i ve looked into the mediator pattern  but i m not convinced this still solves my problems without a great deal of error prone accounting  it also requires the mediator class to be injected into all of my data elements  and requires me to use extensions for base  net generic collections types    i don t want to be forced to always use custom types like myplayerslist or similar  instead of the more common list lt player gt     especially when not using the custom list would likely end in a subtle and silent bug when a recalculation just didn t quite pull the right values  what are my options  am i forced to carry tons of backreferences throughout the model  is there a different model for event handling that i m not aware of  i ve been working with inotifypropertychanged because i m used to it from a wpf context and it s really fast       calls in  ms on my machine  that said i don t know if there are any other event handling paradigms that exist to handle this type of case  this seems like way too straightforward an issue to not have appeared and been solved by someone else before  thanks so much ,how to handle propertychanged events in related classes 
189,17944792,72651732,Why doesn&#39;t this async arrow function not work when executed inline?,"<h2>Problem</h2>
<p>Why doesn't the following async arrow function work in Node? It works fine if I define the function and then execute it separately, but not when I do it inline. I know that top-level await and then/catch would suffice. I'm just confused as to why this doesn't work.</p>
<p>See below for code and the error.</p>
<pre><code>const express = require('express')
const mongoose = require('mongoose')

const db = 'file-storage'; const pw = 'fakepassword'

const app = express()

(async () =&gt; {
  await mongoose.connect(
    `mongodb+srv://sailor:${pw}@sm-cluster.yldyivh.mongodb.net/${db}?retryWrites=true&amp;w=majority`
  )
  console.log(`Connected to MongoDB @ ${db}`)
})()

</code></pre>
<h2>The error</h2>
<pre><code>TypeError: Cannot read properties of undefined (reading 'headersSent')

    at headersSent (/Users/sailormetz/Software Development/Javascript/CurrentProjects/file-storage/server/node_modules/finalhandler/index.js:256:21)
    at /Users/sailormetz/Software Development/Javascript/CurrentProjects/file-storage/server/node_modules/finalhandler/index.js:92:17
    at Function.handle (/Users/sailormetz/Software Development/Javascript/CurrentProjects/file-storage/server/node_modules/express/lib/application.js:177:5)
    at app (/Users/sailormetz/Software Development/Javascript/CurrentProjects/file-storage/server/node_modules/express/lib/express.js:39:9)
    at Object.&lt;anonymous&gt; (/Users/sailormetz/Software Development/Javascript/CurrentProjects/file-storage/server/app.js:8:1)
    at Module._compile (node:internal/modules/cjs/loader:1103:14)
    at Object.Module._extensions..js (node:internal/modules/cjs/loader:1155:10)
    at Module.load (node:internal/modules/cjs/loader:981:32)
    at Function.Module._load (node:internal/modules/cjs/loader:822:12)
    at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:77:12)
</code></pre>
",23,0,0,4,javascript;node.js;async-await;arrow-functions,2022-06-16 23:49:21,2022-06-16 23:49:21,2022-06-16 23:49:21,why doesn t the following async arrow function work in node  it works fine if i define the function and then execute it separately  but not when i do it inline  i know that top level await and then catch would suffice  i m just confused as to why this doesn t work  see below for code and the error ,why doesn   t this async arrow function not work when executed inline 
191,19348192,72638792,Python: Extend existing module with separate code,"<p>I'm new to python development and the mindset for Python in general, so I'm still learning the generally accepted practices of the language and infrastructure.  Background on the problem:</p>
<p>I have installed into Windows Python, pip, etc. as well as the module pymeasure, which provides a good start for controlling bench equipment through python.  This module is not equipment comprehensive, however, and I need to develop my own additional scripts within the pymeasure framework to specifically control the equipment I use.  I have created a (very rough) sketch of control code for an Agilent E3647A power supply.  When I located the python script in the module directory (buried far into my userspace folder structure) everything was fine.</p>
<p>I will be developing software as part of a larger group of developers, all of whom will be sharing code through an internal git repository.  Any code we create (not downloaded from git) should be located in the git repository.  Ergo, my E3647A script should be in the repo folder (somewhere).</p>
<p><a href=""https://i.stack.imgur.com/iHFvh.png"" rel=""nofollow noreferrer"">Failed <code>__init__</code> implementation</a></p>
<p>In copy/paste form:</p>
<pre><code>from .agilent8257D import Agilent8257D

from .agilent8722ES import Agilent8722ES

from .agilentE4408B import AgilentE4408B

from .agilentE4980 import AgilentE4980

from .agilent34410A import Agilent34410A

from .agilent34450A import Agilent34450A

from .agilent4156 import Agilent4156

from .agilent33220A import Agilent33220A

from .agilent33500 import Agilent33500

from .agilent33521A import Agilent33521A

from .agilentB1500 import AgilentB1500

from 'C:\Bench_Software\Equipment\Equipment Single Commands\agilentE3647A' import AgilentE3647A
</code></pre>
<p>The above attempt to add a non-local script into <code>__init__</code> fails miserably.</p>
<p>How (if possible) can I specify absolute paths to module scripts, or change my entire Python target for modules to look for multiple directories, split existing modules along pip-downloaded vs. locally-developed code?  Are there any standard code practices to achieve such a thing?</p>
",64,0,0,4,python;version-control;architecture;python-module,2022-06-16 02:13:57,2022-06-16 02:13:57,2022-06-16 12:58:13,i m new to python development and the mindset for python in general  so i m still learning the generally accepted practices of the language and infrastructure   background on the problem  i have installed into windows python  pip  etc  as well as the module pymeasure  which provides a good start for controlling bench equipment through python   this module is not equipment comprehensive  however  and i need to develop my own additional scripts within the pymeasure framework to specifically control the equipment i use   i have created a  very rough  sketch of control code for an agilent ea power supply   when i located the python script in the module directory  buried far into my userspace folder structure  everything was fine  i will be developing software as part of a larger group of developers  all of whom will be sharing code through an internal git repository   any code we create  not downloaded from git  should be located in the git repository   ergo  my ea script should be in the repo folder  somewhere    in copy paste form  the above attempt to add a non local script into __init__ fails miserably  how  if possible  can i specify absolute paths to module scripts  or change my entire python target for modules to look for multiple directories  split existing modules along pip downloaded vs  locally developed code   are there any standard code practices to achieve such a thing ,python  extend existing module with separate code
192,15503033,72624940,Cannot debug Xamarin android app because NDK registry is missing,"<p>Anytime I run the debugger and emulator it just errors with this message.
Multi-device C++ development is enabled.</p>
<p>I'm not sure what to do.</p>
<pre><code>Unable to start debugging.
A required Visual Studio registry value could not be found.
Ensure that support for multi-device C++ development is enabled in Visual Studio setup.

Registry key: Software\Microsoft\VisualStudio\17.0_e34a64fc\Setup\VS\SecondaryInstaller\AndroidNDK
Value name: NDK_HOME
</code></pre>
",50,1,0,5,android;visual-studio;xamarin.android;android-ndk;ms-android-emulator,2022-06-15 04:19:48,2022-06-15 04:19:48,2022-06-16 12:32:30,i m not sure what to do ,cannot debug xamarin android app because ndk registry is missing
193,11645980,72637407,npm start not working for react after changing partition directories in windows,"<p>i recently changed my hard drive partitions and merged them into one partition
now when i am trying to starting react from npm start its giving some error so i have uninstalled and reinstalled node js multiple times like 4 times but nothing worked ,</p>
<p>i have created a new react-redux project with <code>npx create-react-app react-redux</code></p>
<p>here is my command line responses</p>
<pre><code>PS D:\games&amp;software\software\installed\web-development-folder\www\02\react\react-redux&gt; npm start
npm WARN config global `--global`, `--local` are deprecated. Use `--location=global` instead.

&gt; react-redux@0.1.0 start
&gt; react-scripts start

'software\software\installed\web-development-folder\www\02\react\react-redux\node_modules\.bin\' is not recognized as an internal or external command,
operable program or batch file.
node:internal/modules/cjs/loader:936
  throw err;
  ^

Error: Cannot find module 'D:\react-scripts\bin\react-scripts.js'
    at Function.Module._resolveFilename (node:internal/modules/cjs/loader:933:15)
    at Function.Module._load (node:internal/modules/cjs/loader:778:27)
    at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:77:12)
    at node:internal/main/run_main_module:17:47 {
  code: 'MODULE_NOT_FOUND',
  requireStack: []
}
PS D:\games&amp;software\software\installed\web-development-folder\www\02\react\react-redux&gt;
</code></pre>
<p>one strange thing i have noticed is it is checking for modules in <code>'D:\react-scripts\bin\react-scripts.js'</code>
but my project directory is <code>D:\games&amp;software\software\installed\web-development-folder\www\02\react\react-redux</code> i feel like this is the main culprit but not sure , after doing too much research i have came for help so please if anyone know what can i do to solve this help me please .</p>
",44,2,1,2,node.js;reactjs,2022-06-15 23:22:27,2022-06-15 23:22:27,2022-06-16 00:07:04,i have created a new react redux project with npx create react app react redux here is my command line responses,npm start not working for react after changing partition directories in windows
194,19118102,72634863,"CSS Query leaves large gap on the side of Web page, How to fix it?","<p>So I am busy with responsive design, but I am not sure why there is a large gap on the side. I checked the console and the HTML tag shows everything is within the margin and I do not think anything is slipping on the edge to cause such a big gap on the side.</p>
<p>Can someone shed some light? If I missed something that is causing that.</p>
<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>let projects = document.querySelector("".projects"");
let projectList = document.querySelector("".project-list"")
let clickOffImage = document.querySelector("".img-fluid"")
let clickOffnav = document.querySelector("".navbar"")

projects.addEventListener('click', function handleClickOn() {
  if (projects) {
    projectList.style.display = ""block"";
  }
})

clickOffImage.addEventListener('click', function handleClickOff() {
  if (clickOffImage) {
    projectList.style.display = ""none""
  }
})

//variables for card and close
let card = document.querySelector("".card"")
let closeCard = document.querySelector("".close"")

//event listener to close card
closeCard.addEventListener('click', function close() {
  if (closeCard) {
    card.style.display = ""none"";
  }
})

//variables for furnspace card and close
let furnspace = document.querySelector("".furnspace"");
let furnCard = document.querySelector("".furnspace-card"");
let education = document.querySelector("".eHL"");
//event listener to show furnspace card
furnspace.addEventListener('click', function openFCard() {
  if (furnspace) {
    furnCard.style.display = ""block"";
    education.style.paddingTop = ""-50rem"";
  }
})

//variables for card and close
let changingWCard = document.querySelector("".changing-card"")
let changingclose = document.querySelector("".changing-card-close"")


//event listener to close card
changingclose.addEventListener('click', function cWClose() {
  if (changingclose) {
    changingWCard.style.display = ""none"";
  }
})

let cafmCard = document.querySelector("".cafm-card"")
let cafmCardClose = document.querySelector("".cafm-card-close"")

cafmCardClose.addEventListener('click', function cafmClose() {
  if (changingclose) {
    cafmCard.style.display = ""none"";
  }
})

let changing = document.querySelector("".changing-workplace"");
let changingCard = document.querySelector("".changing-card"");
let cafm = document.querySelector("".cafm-card"")

changing.addEventListener('click', function openCCard() {
  if (changing) {
    changingCard.style.display = ""block"";
    cafm.style.display = ""block"";
  }
})

let staffedCard = document.querySelector("".get-staffed-up-card"")
let staffedClose = document.querySelector("".get-staffed-up-close"")

staffedClose.addEventListener('click', function staffClose() {
  if (staffedClose) {
    staffedCard.style.display = ""none"";
  }
})

let staffedUp = document.querySelector("".get-staffed-up"");
let staffCard = document.querySelector("".get-staffed-up-card"");


staffedUp.addEventListener('click', function openCCard() {
  if (staffedUp) {
    staffCard.style.display = ""block"";
  }
})</code></pre>
<pre class=""snippet-code-css lang-css prettyprint-override""><code>@import url(""https://fonts.googleapis.com/css2?family=Oleo+Script+Swash+Caps&amp;display=swap"");
@import url(""https://fonts.googleapis.com/css2?family=Syne&amp;display=swap"");
@import url(""https://fonts.googleapis.com/css2?family=Cinzel&amp;display=swap"");
body {
  box-sizing: border-box;
  font-family: ""Syne"", sans-serif;
  font-size: 20px;
}

:root {
  --darker-color: #22223b;
  --grey-color: #4a4e69;
  --light-color: #9a8c98;
  --lighter-color: #c9ada7;
  --lightest-color: #c9ada7;
  --white-color: #ffffff;
}

.down-arrow {
  width: 1vw;
}

.nav {
  background-color: var(--grey-color) !important;
}

.navbar-brand,
.nav-link {
  color: var(--white-color) !important;
}

.nav-link {
  padding-left: 10rem !important;
}

.down-arrow {
  filter: invert(99%) sepia(89%) saturate(0%) hue-rotate(233deg) brightness(108%) contrast(97%);
}

.project-list {
  position: absolute;
  background-color: var(--darker-color);
  margin-left: 80rem;
  padding-left: 2rem;
  cursor: pointer;
  padding-right: 1rem;
  display: flex;
  display: none;
}

.project-list ul {
  list-style-type: none;
  text-align: justify;
  margin-left: -1rem;
  margin-top: 1rem;
}

.project-item {
  text-decoration: none;
  color: var(--white-color);
  margin-left: -2.3rem;
}

.project-item:hover {
  background-color: var(--grey-color);
  padding-left: 20px;
}

.hero-image {
  padding: 0;
}

.hero-image img {
  width: 100vw;
  object-fit: cover;
  height: auto;
}

.Heading {
  position: absolute;
  margin: 18rem;
  font-weight: bold;
  color: var(--darker-color);
}

.h1,
.h2,
.h3 {
  font-size: 70px;
  font-family: Cinzel, sans-serif;
}

.about-me-container {
  margin-left: 25rem;
}

.head-shot img {
  width: 10vw;
  margin-top: 15rem;
  margin-left: -10rem;
}

.aboutMe {
  position: absolute;
  margin-left: 30rem;
  margin-top: 5rem;
  font-family: Oleo Script Swash Caps;
  color: var(--darker-color);
  border-bottom: 5px solid var(--darker-color);
}

.aboutMe-par {
  margin-left: 10rem;
  margin-top: -15rem;
  width: 50rem;
  text-align: justify;
}

.experience {
  margin-left: -10rem;
}

.eHL {
  position: absolute;
  margin-left: 65rem;
  margin-top: 5rem;
  font-family: Oleo Script Swash Caps;
  color: var(--darker-color);
  border-bottom: 5px solid var(--darker-color);
}

.work-container {
  position: absolute;
  display: flex;
  flex-direction: row;
  margin-left: 50rem;
  margin-top: 15rem;
}

.changing-workplace,
.get-staffed-up {
  margin-left: 5rem;
}

.changing-workplace,
.get-staffed-up,
.furnspace {
  background-color: var(--darker-color);
  color: var(--white-color);
  width: 10rem;
  height: 10rem;
  border-radius: 100%;
  cursor: pointer;
  text-align: center;
}

.changing-workplace p,
.get-staffed-up p,
.furnspace p {
  margin-top: 4rem;
}

.card-text {
  width: 30rem;
  height: 12rem;
  margin-top: 3rem;
}

.card {
  width: 32rem;
  background-color: var(--grey-color);
  color: var(--white-color);
  margin-left: 53rem;
  margin-top: 10rem;
}

.close {
  position: absolute;
  margin-left: 29rem;
  cursor: pointer;
}

.text-muted {
  color: var(--white-color) !important;
}

.furnspace-card,
.get-staffed-up-card {
  position: absolute;
  display: none;
}

.changing-card {
  display: flex;
  flex-direction: row;
  position: absolute;
  width: 35rem;
  height: 22rem;
  margin-top: 9rem;
  margin-left: 32rem;
  display: none;
}

.get-staffed-up-card {
  height: 30rem;
}

.changing-card-close {
  position: absolute;
  margin-left: 32rem;
  cursor: pointer;
}

.get-staffed-up-close {
  position: absolute;
  margin-left: 29rem;
  cursor: pointer;
}

.cafm-card {
  margin-left: 68rem;
}

.text-muted {
  text-decoration: underline;
  font-size: 18px;
}

.download-resume {
  position: absolute;
  margin: 30rem 65rem;
  width: 13rem;
}

a {
  text-decoration: none;
  color: var(--white-color);
}

.download-resume :active {
  background-color: var(--lightest-color);
}

button {
  border: none;
  background-color: var(--darker-color);
  padding: 0.7rem;
  border-radius: 2rem;
}

.education {
  display: flex;
  flex-direction: row;
}

.edu-card {
  margin-left: 5rem;
  padding-top: -2rem;
}

.education-container {
  margin-top: 37rem;
  margin-left: 55rem;
}

.education {
  position: absolute;
  margin-top: 5rem;
  font-family: Oleo Script Swash Caps;
  color: var(--darker-color);
  border-bottom: 5px solid var(--darker-color);
}

.education-contain {
  position: absolute;
  margin-top: 5rem;
  margin-left: -100rem;
  display: grid;
  grid-template-columns: 35rem 35rem 20rem;
}

.codespace-body {
  width: 70rem;
  height: 23rem;
}

.ux-text {
  overflow: scroll;
}

@media (min-width: 576px) {
  .Heading {
    margin: 4em
  }
  .h1,
  .h2,
  .h3 {
    font-size: 1em;
  }
  .aboutMe {
    position: relative;
    text-align: center;
    margin-left: -8em;
    margin-top: 1em;
    border-bottom: 2px solid var(--darker-color);
    width: 5em;
  }
  .aboutMe h1 {
    font-size: 1em;
  }
  .head-shot img {
    margin-left: -12em;
    margin-top: 0.5em;
    display: none;
  }
  .aboutMe-par {
    margin-left: -16em;
    margin-top: 1em;
    text-align: justify;
  }
  .aboutMe-par p {
    font-size: 0.7em;
    width: 30em
  }
  .project-list {
    margin-left: 20em;
    margin-top: -4em;
  }
  .eHL {
    margin-left: 48em;
    margin-top: 1em;
  }
  .eHL h1 {
    font-size: 1em;
  }
  .experience {
    margin-left: -37em;
  }
  .furnspace,
  .changing-workplace,
  .get-staffed-up {
    width: 5em;
    height: 5em;
    margin-top: -7em;
    margin-left: 1em;
  }
  .furnspace p,
  .changing-workplace p,
  .get-staffed-up p {
    font-size: 0.7em;
    margin-top: 3em;
  }
  .download-resume {
    margin: 13em 45em;
  }
  button {
    padding: 0.2em;
  }
  .close,
  .changing-card-close,
  .get-staffed-up-close {
    margin-left: 18em;
    margin-top: 0em;
  }
  .furnspace-card,
  .changing-card,
  .get-staffed-up-card {
    margin-top: 0em;
    margin-left: 3em;
    width: 20em;
    height: 17em;
  }
  .cafm-card {
    margin-top: 18em;
  }
  .card-title {
    margin-top: 0.3em;
    font-size: 0.8em;
  }
  .text-muted {
    font-size: 0.7em;
  }
  .card-text {
    overflow: scroll;
    font-size: 0.8em;
    width: 23em;
  }
  .education {
    border-bottom: 5px solid var(--darker-color);
    z-index: -1;
  }
  .education h1 {
    font-size: 1em;
    margin-top: -14.7em;
    margin-left: -33em;
  }
  .education-contain {
    margin-left: -84em;
    margin-top: -15.7em;
    display: block;
  }
  .codespace-card,
  .ux-card,
  .shaw-card {
    width: 20em;
    height: 17em;
  }
  .ux-card,
  .shaw-card {
    margin-top: 1em;
  }
  .codespace-link {
    font-size: 0.8em;
  }
}</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;!DOCTYPE html&gt;
&lt;html lang=""en""&gt;

&lt;head&gt;
  &lt;meta charset=""UTF-8""&gt;
  &lt;meta http-equiv=""X-UA-Compatible"" content=""IE=edge""&gt;
  &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1.0""&gt;
  &lt;link href=""https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css"" rel=""stylesheet"" integrity=""sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3"" crossorigin=""anonymous""&gt;

  &lt;link rel=""stylesheet"" href=""css/main.css""&gt;
  &lt;link rel=""stylesheet"" href=""css/query.css""&gt;

  &lt;script src=""js/main.js"" defer&gt;&lt;/script&gt;

  &lt;script src=""https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"" integrity=""sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p"" crossorigin=""anonymous""&gt;&lt;/script&gt;
  &lt;title&gt;Sheldon's Digital Resume&lt;/title&gt;
&lt;/head&gt;

&lt;body&gt;
  &lt;header&gt;
    &lt;nav class=""navbar navbar-expand-lg navbar-light bg-light nav""&gt;
      &lt;div class=""container-fluid""&gt;
        &lt;div class=""navbar-brand""&gt;Sheldon Aldridge&lt;/div&gt;
        &lt;button class=""navbar-toggler"" type=""button"" data-bs-toggle=""collapse"" data-bs-target=""#navbarNav"" aria-controls=""navbarNav"" aria-expanded=""false"" aria-label=""Toggle navigation""&gt;
          &lt;span class = ""navbar-toggler-icon""&gt;&lt;/span&gt;
        &lt;/button&gt;
        &lt;div class=""collapse navbar-collapse"" id=""navbarNav""&gt;
          &lt;ul class=""navbar-nav""&gt;
            &lt;li class=""nav-item""&gt;
              &lt;a class=""nav-link active"" aria-current=""page"" href=""#""&gt;Home&lt;/a&gt;
            &lt;/li&gt;
            &lt;li class=""nav-item""&gt;
              &lt;a class=""nav-link"" href=""#aboutme""&gt;About Me&lt;/a&gt;
            &lt;/li&gt;
            &lt;li class=""nav-item""&gt;
              &lt;a class=""nav-link"" href=""#""&gt;Experience&lt;/a&gt;
            &lt;/li&gt;
            &lt;li class=""nav-item""&gt;
              &lt;a class=""nav-link"" href=""#""&gt;Education&lt;/a&gt;
            &lt;/li&gt;
            &lt;li class=""nav-item projects""&gt;
              &lt;a class=""nav-link"" href=""#""&gt;Projects
                &lt;img class = ""down-arrow"" src=""images/icons/down_arrow_icon.png"" alt=""Down_arrow_icon""&gt;
              &lt;/a&gt;
            &lt;/li&gt;
            &lt;li class=""nav-item""&gt;
              &lt;a class=""nav-link"" href=""#""&gt;Contacts&lt;/a&gt;
            &lt;/li&gt;
          &lt;/ul&gt;
        &lt;/div&gt;
    &lt;/nav&gt;

    &lt;div class=""project-list""&gt;
      &lt;ul class=""flex-column""&gt;
        &lt;li class=""project-item ""&gt;Calculator App&lt;/li&gt;
        &lt;li class=""project-item""&gt;Vending Machine App&lt;/li&gt;
        &lt;li class=""project-item""&gt;Landing Page&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/div&gt;

    &lt;div class=""container-fluid hero-image""&gt;
      &lt;div class=""Heading""&gt;
        &lt;h1 class=""h1""&gt;Hi! I'm Sheldon Aldridge&lt;/h1&gt;
        &lt;h1 class=""h2""&gt;Aspiring Front-End&lt;/h1&gt;
        &lt;h1 class=""h3""&gt;Developer&lt;/h1&gt;
      &lt;/div&gt;
      &lt;picture&gt;
        &lt;img class=""img-fluid hero"" src=""../images/Hero-image.jpg"" alt=""Hero-image""&gt;
      &lt;/picture&gt;
    &lt;/div&gt;
  &lt;/header&gt;

  &lt;main&gt;
    &lt;div class=""about-me-container"" id=""aboutme""&gt;
      &lt;div class=""head-shot""&gt;
        &lt;aside class=""aboutMe""&gt;
          &lt;h1&gt;About Me&lt;/h1&gt;
        &lt;/aside&gt;
        &lt;img src=""images/Profile Pic.png"" alt=""Head shot""&gt;
      &lt;/div&gt;
      &lt;div class=""aboutMe-par""&gt;
        &lt;p&gt;
          I am self-motivated and dependable. I am always open to feedback and taking on new challenges to succeed. I am an aspiring front-end developer. I have developed key communication and problem-solving skills. I am not intimidated by ambiguity and can adapt
          where needed.
        &lt;/p&gt;
        &lt;p&gt;
          I spent a few months from October 2021 - January 2022 working as a Junior Developer for a USA company Get Staffed Up. It was a great oppertunity for me to gain experience and the expectations for the industry. When my contract ended, I did a course in
          Front-End Development and have recently received my certification of completetion.
        &lt;/p&gt;
        &lt;p&gt;
          My career goal is to work as a Front-End Developer where I can utilize my skillsets to create functional and aesthetically pleasing websites and user interfaces.
        &lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class=""experience container"" id=""exp""&gt;
      &lt;div class=""eHL""&gt;
        &lt;h1&gt;Experience&lt;/h1&gt;
      &lt;/div&gt;
      &lt;div class=""work-container""&gt;
        &lt;div class=""furnspace""&gt;
          &lt;p&gt;3D Furnspace&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=""changing-workplace""&gt;
          &lt;p&gt;The Changing Workplace&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=""get-staffed-up""&gt;
          &lt;p&gt;Get Staffed Up&lt;/p&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;div class=""download-resume""&gt;
        &lt;button&gt;&lt;a href=""resources/resume/Sheldon Aldridge CV.pdf"" download=""Sheldon Aldridge CV.pdf""&gt;Download Resume&lt;/a&gt;&lt;/button&gt;
      &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class=""card furnspace-card""&gt;
      &lt;div class=""card-body""&gt;
        &lt;div class=""close""&gt;
          &lt;p&gt;X&lt;/p&gt;
        &lt;/div&gt;
        &lt;h5 class=""card-title""&gt;3D Furnspace (January 2014 - November 2017)
        &lt;/h5&gt;
        &lt;h6 class=""card-subtitle mb-2 text-muted""&gt;Tech Support&lt;/h6&gt;
        &lt;p class=""card-text""&gt;In this role I gave technical support for the 3D software called InteriCAD T5. I not only gave technical support for the software, but I also gave training as well. I was also responsible for doing internet speed tests for the building, troubleshoot
          network/internet problems for the tenants that were renting the building.&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class=""card changing-card""&gt;
      &lt;div class=""card-body""&gt;
        &lt;div class=""changing-card-close""&gt;
          &lt;p&gt;X&lt;/p&gt;
        &lt;/div&gt;
        &lt;h5 class=""card-title""&gt;The Changing Workplace (November 2017 - March 2020)&lt;/h5&gt;
        &lt;h6 class=""card-subtitle mb-2 text-muted""&gt;Help Desk&lt;/h6&gt;
        &lt;p class=""card-text""&gt;In this role I responded electronically to clients’ requests via email. I used a ticketing system that would be raised by helpdesk in relation to the clients query I had received via email. I diagnose their issue by doing research with the available
          information and advising the client what the best course of action would be.&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class=""card changing-card cafm-card""&gt;
      &lt;div class=""card-body""&gt;
        &lt;div class=""changing-card-close cafm-card-close""&gt;
          &lt;p&gt;X&lt;/p&gt;
        &lt;/div&gt;
        &lt;h5 class=""card-title""&gt;The Changing Workplace (March 2020 - April 2021)&lt;/h5&gt;
        &lt;h6 class=""card-subtitle mb-2 text-muted""&gt;CAFM Co-ordinator&lt;/h6&gt;
        &lt;p class=""card-text""&gt;In this role I was accountable for managing the data and drawings using the database and AutoCAD software to complete tasks given from the client in a timely manner and taking an analytical approach to implementing the requested changes from the
          client.
        &lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class=""card get-staffed-up-card""&gt;
      &lt;div class=""card-body""&gt;
        &lt;div class=""get-staffed-up-close""&gt;
          &lt;p&gt;X&lt;/p&gt;
        &lt;/div&gt;
        &lt;h5 class=""card-title""&gt;Get Staffed Up (October 2021 - January 2022)
        &lt;/h5&gt;
        &lt;h6 class=""card-subtitle mb-2 text-muted""&gt;Junior Developer&lt;/h6&gt;
        &lt;p class=""card-text""&gt;I worked as a Junior Developer, the main language I used in the time that I worked there was JavaScript.I worked on a project where I worked with 2 different API's one was Big Query in Google and the other was Zoho which is a CRM system. I used
          Javascript to connect the 2 databases, count the rows and compare the rows, if the rows do not match send an email notification. I was also responsible to research and write a procedure for Github for the team, along with anything else the department
          needed research on.
        &lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class=""container education-container"" id=""education""&gt;
      &lt;div class=""education""&gt;
        &lt;h1&gt;Education&lt;/h1&gt;
      &lt;/div&gt;

      &lt;div class=""container education-contain""&gt;

        &lt;!--Codespace--&gt;
        &lt;div class=""card codespace-card""&gt;
          &lt;div class=""card-body codespace-body""&gt;
            &lt;h5 class=""card-title codespace-title""&gt;Code Space Academy (2022)
            &lt;/h5&gt;
            &lt;h6 class=""card-subtitle mb-2 text-muted""&gt;Front End Development&lt;/h6&gt;
            &lt;p class=""card-text codespace-text""&gt;During this course we were taught the following stack HTML5,CSS3,Javascript,Vue Framework, Bootstrap. We were required to build and submit real life projects, such as a To-Do App, Netflix app and an online store website. While building these
              projects we had to utilize everything we have learnt including responsive design.
            &lt;/p&gt;
            &lt;a href=""https://www.codespace.co.za/courses/frontend-web-development/"" class=""card-link codespace-link""&gt;CodeSpace Website&lt;/a&gt;
            &lt;a href=""https://github.com/SheldonAldridge?tab=repositories"" class=""card-link codespace-link""&gt;Github projects&lt;/a&gt;
          &lt;/div&gt;
        &lt;/div&gt;

        &lt;!--Get Smarter--&gt;
        &lt;div class=""card ux-card""&gt;
          &lt;div class=""card-body ux-body""&gt;
            &lt;h5 class=""card-title ux-title""&gt;Get Smarter (2021)&lt;/h5&gt;
            &lt;h6 class=""card-subtitle mb-2 text-muted""&gt;User Experience Designer&lt;/h6&gt;
            &lt;p class=""card-text ux-text""&gt;The User Experience Design online short course enables me to understand how users interact with online content so that I am able to design environments that meet the users evolving needs. I had learned key UX research and design techniques,
              and learned how to work with stakeholders, run user tests, design wireframes, and develop prototypes. I also learned how to analyse current trends in the field. Doing this course help broaden my knowledge and expand my web design knowledge.
            &lt;/p&gt;
            &lt;a href=""https://www.getsmarter.com/products/uct-user-experience-design-online-short-course"" class=""card-link ux-link""&gt;GetSmarter Website&lt;/a&gt;
          &lt;/div&gt;
        &lt;/div&gt;

        &lt;!--Shaw Academy--&gt;
        &lt;div class=""card shaw-card""&gt;
          &lt;div class=""card-body shaw-body""&gt;
            &lt;h5 class=""card-title shaw-title""&gt;Shaw Academy (2020)&lt;/h5&gt;
            &lt;h6 class=""card-subtitle mb-2 text-muted""&gt;Web Design&lt;/h6&gt;
            &lt;p class=""card-text shaw-text""&gt;This course gave the basics of HTML and CSS. I had gained the knowledge of building basic and static website.
            &lt;/p&gt;
            &lt;a href=""https://www.shawacademy.com/courses/"" class=""card-link ux-link""&gt;Shaw Academy Website&lt;/a&gt;
          &lt;/div&gt;
        &lt;/div&gt;


      &lt;/div&gt;
  &lt;/main&gt;

&lt;/body&gt;

&lt;/html&gt;</code></pre>
</div>
</div>
</p>
<p><a href=""https://i.stack.imgur.com/22JpD.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/22JpD.png"" alt=""enter image description here"" /></a></p>
",21,0,0,2,css;margin,2022-06-15 19:32:23,2022-06-15 19:32:23,2022-06-15 19:32:23,so i am busy with responsive design  but i am not sure why there is a large gap on the side  i checked the console and the html tag shows everything is within the margin and i do not think anything is slipping on the edge to cause such a big gap on the side  can someone shed some light  if i missed something that is causing that  ,css query leaves large gap on the side of web page  how to fix it 
195,19291339,72617725,How to run airflow 2.0+ with openlineage and marquez in docker?,"<p>I'm trying to running the DAG in <a href=""https://github.com/MarquezProject/marquez/tree/main/examples/airflow"" rel=""nofollow noreferrer"">this</a> example with airflow 2.0+. I setup an airflow project on docker following <a href=""https://airflow.apache.org/docs/apache-airflow/stable/start/docker.html"" rel=""nofollow noreferrer"">this</a> example, and I want to integrate it with openlieage. I wonder how can I do that? I set environment variables for openlineage in the .env file that looks like below:</p>
<p><a href=""https://i.stack.imgur.com/yMdM9.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yMdM9.png"" alt=""enter image description here"" /></a></p>
<p>I git cloned the marquez repo on github and get marquez running following the <a href=""https://github.com/MarquezProject/marquez"" rel=""nofollow noreferrer"">readme</a>. I suppose openlineage will listen on port 5000, and marquez will listen on port 5000, but when I browse localhost:3000, which is the UI of marquez, it shows no jobs found.</p>
<p>Here is my project directory:
<a href=""https://i.stack.imgur.com/lVU7s.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lVU7s.png"" alt=""enter image description here"" /></a></p>
<p>Here is my yaml file, which is exactly the same as this <a href=""https://airflow.apache.org/docs/apache-airflow/stable/start/docker.html"" rel=""nofollow noreferrer"">link</a>:</p>
<pre><code># Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# &quot;License&quot;); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#

# Basic Airflow cluster configuration for CeleryExecutor with Redis and PostgreSQL.
#
# WARNING: This configuration is for local development. Do not use it in a production deployment.
#
# This configuration supports basic configuration using environment variables or an .env file
# The following variables are supported:
#
# AIRFLOW_IMAGE_NAME           - Docker image name used to run Airflow.
#                                Default: apache/airflow:2.3.2
# AIRFLOW_UID                  - User ID in Airflow containers
#                                Default: 50000
# Those configurations are useful mostly in case of standalone testing/running Airflow in test/try-out mode
#
# _AIRFLOW_WWW_USER_USERNAME   - Username for the administrator account (if requested).
#                                Default: airflow
# _AIRFLOW_WWW_USER_PASSWORD   - Password for the administrator account (if requested).
#                                Default: airflow
# _PIP_ADDITIONAL_REQUIREMENTS - Additional PIP requirements to add when starting all containers.
#                                Default: ''
#
# Feel free to modify this file to suit your needs.
---
version: '3'
x-airflow-common:
  &amp;airflow-common
  # In order to add custom dependencies or upgrade provider packages you can use your extended image.
  # Comment the image line, place your Dockerfile in the directory where you placed the docker-compose.yaml
  # and uncomment the &quot;build&quot; line below, Then run `docker-compose build` to build the images.
  image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:2.3.2}
  # build: .
  environment:
    &amp;airflow-common-env
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    # For backward compatibility, with Airflow &lt;2.3
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
    AIRFLOW__CORE__FERNET_KEY: ''
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'true'
    AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth'
    _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
  user: &quot;${AIRFLOW_UID:-50000}:0&quot;
  depends_on:
    &amp;airflow-common-depends-on
    redis:
      condition: service_healthy
    postgres:
      condition: service_healthy

services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: [&quot;CMD&quot;, &quot;pg_isready&quot;, &quot;-U&quot;, &quot;airflow&quot;]
      interval: 5s
      retries: 5
    restart: always

  redis:
    image: redis:latest
    expose:
      - 6379
    healthcheck:
      test: [&quot;CMD&quot;, &quot;redis-cli&quot;, &quot;ping&quot;]
      interval: 5s
      timeout: 30s
      retries: 50
    restart: always

  airflow-webserver:
    &lt;&lt;: *airflow-common
    command: webserver
    ports:
      - 8080:8080
    healthcheck:
      test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;--fail&quot;, &quot;http://localhost:8080/health&quot;]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
    depends_on:
      &lt;&lt;: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-scheduler:
    &lt;&lt;: *airflow-common
    command: scheduler
    healthcheck:
      test: [&quot;CMD-SHELL&quot;, 'airflow jobs check --job-type SchedulerJob --hostname &quot;$${HOSTNAME}&quot;']
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
    depends_on:
      &lt;&lt;: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-worker:
    &lt;&lt;: *airflow-common
    command: celery worker
    healthcheck:
      test:
        - &quot;CMD-SHELL&quot;
        - 'celery --app airflow.executors.celery_executor.app inspect ping -d &quot;celery@$${HOSTNAME}&quot;'
      interval: 10s
      timeout: 10s
      retries: 5
    environment:
      &lt;&lt;: *airflow-common-env
      # Required to handle warm shutdown of the celery workers properly
      # See https://airflow.apache.org/docs/docker-stack/entrypoint.html#signal-propagation
      DUMB_INIT_SETSID: &quot;0&quot;
    restart: always
    depends_on:
      &lt;&lt;: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-triggerer:
    &lt;&lt;: *airflow-common
    command: triggerer
    healthcheck:
      test: [&quot;CMD-SHELL&quot;, 'airflow jobs check --job-type TriggererJob --hostname &quot;$${HOSTNAME}&quot;']
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
    depends_on:
      &lt;&lt;: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-init:
    &lt;&lt;: *airflow-common
    entrypoint: /bin/bash
    # yamllint disable rule:line-length
    command:
      - -c
      - |
        function ver() {
          printf &quot;%04d%04d%04d%04d&quot; $${1//./ }
        }
        airflow_version=$$(gosu airflow airflow version)
        airflow_version_comparable=$$(ver $${airflow_version})
        min_airflow_version=2.2.0
        min_airflow_version_comparable=$$(ver $${min_airflow_version})
        if (( airflow_version_comparable &lt; min_airflow_version_comparable )); then
          echo
          echo -e &quot;\033[1;31mERROR!!!: Too old Airflow version $${airflow_version}!\e[0m&quot;
          echo &quot;The minimum Airflow version supported: $${min_airflow_version}. Only use this or higher!&quot;
          echo
          exit 1
        fi
        if [[ -z &quot;${AIRFLOW_UID}&quot; ]]; then
          echo
          echo -e &quot;\033[1;33mWARNING!!!: AIRFLOW_UID not set!\e[0m&quot;
          echo &quot;If you are on Linux, you SHOULD follow the instructions below to set &quot;
          echo &quot;AIRFLOW_UID environment variable, otherwise files will be owned by root.&quot;
          echo &quot;For other operating systems you can get rid of the warning with manually created .env file:&quot;
          echo &quot;    See: https://airflow.apache.org/docs/apache-airflow/stable/start/docker.html#setting-the-right-airflow-user&quot;
          echo
        fi
        one_meg=1048576
        mem_available=$$(($$(getconf _PHYS_PAGES) * $$(getconf PAGE_SIZE) / one_meg))
        cpus_available=$$(grep -cE 'cpu[0-9]+' /proc/stat)
        disk_available=$$(df / | tail -1 | awk '{print $$4}')
        warning_resources=&quot;false&quot;
        if (( mem_available &lt; 4000 )) ; then
          echo
          echo -e &quot;\033[1;33mWARNING!!!: Not enough memory available for Docker.\e[0m&quot;
          echo &quot;At least 4GB of memory required. You have $$(numfmt --to iec $$((mem_available * one_meg)))&quot;
          echo
          warning_resources=&quot;true&quot;
        fi
        if (( cpus_available &lt; 2 )); then
          echo
          echo -e &quot;\033[1;33mWARNING!!!: Not enough CPUS available for Docker.\e[0m&quot;
          echo &quot;At least 2 CPUs recommended. You have $${cpus_available}&quot;
          echo
          warning_resources=&quot;true&quot;
        fi
        if (( disk_available &lt; one_meg * 10 )); then
          echo
          echo -e &quot;\033[1;33mWARNING!!!: Not enough Disk space available for Docker.\e[0m&quot;
          echo &quot;At least 10 GBs recommended. You have $$(numfmt --to iec $$((disk_available * 1024 )))&quot;
          echo
          warning_resources=&quot;true&quot;
        fi
        if [[ $${warning_resources} == &quot;true&quot; ]]; then
          echo
          echo -e &quot;\033[1;33mWARNING!!!: You have not enough resources to run Airflow (see above)!\e[0m&quot;
          echo &quot;Please follow the instructions to increase amount of resources available:&quot;
          echo &quot;   https://airflow.apache.org/docs/apache-airflow/stable/start/docker.html#before-you-begin&quot;
          echo
        fi
        mkdir -p /sources/logs /sources/dags /sources/plugins
        chown -R &quot;${AIRFLOW_UID}:0&quot; /sources/{logs,dags,plugins}
        exec /entrypoint airflow version
    # yamllint enable rule:line-length
    environment:
      &lt;&lt;: *airflow-common-env
      _AIRFLOW_DB_UPGRADE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}
      _PIP_ADDITIONAL_REQUIREMENTS: ''
    user: &quot;0:0&quot;
    volumes:
      - .:/sources

  airflow-cli:
    &lt;&lt;: *airflow-common
    profiles:
      - debug
    environment:
      &lt;&lt;: *airflow-common-env
      CONNECTION_CHECK_MAX_COUNT: &quot;0&quot;
    # Workaround for entrypoint issue. See: https://github.com/apache/airflow/issues/16252
    command:
      - bash
      - -c
      - airflow

  # You can enable flower by adding &quot;--profile flower&quot; option e.g. docker-compose --profile flower up
  # or by explicitly targeted on the command line e.g. docker-compose up flower.
  # See: https://docs.docker.com/compose/profiles/
  flower:
    &lt;&lt;: *airflow-common
    command: celery flower
    profiles:
      - flower
    ports:
      - 5555:5555
    healthcheck:
      test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;--fail&quot;, &quot;http://localhost:5555/&quot;]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
    depends_on:
      &lt;&lt;: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

volumes:
  postgres-db-volume:
</code></pre>
<p>and this is my current .env file:
<a href=""https://i.stack.imgur.com/pNAYD.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/pNAYD.png"" alt=""enter image description here"" /></a></p>
<p>error message:</p>
<pre><code>hdee@openlineageDEV:~/airflow-docker$ sudo docker-compose up airflow-init                                                                                                           
WARNING: Found orphan containers (airflow-docker_marquez_1, airflow-
docker_marquez_web_1) for this project. If you removed or renamed this 
service in your compose file, you can run this command with the --
remove-orphans flag to clean it up.airflow-docker_redis_1 is up-to-date                                                                                      
airflow-docker_postgres_1 is up-to-date                                                                                                                                              
Starting airflow-docker_airflow-init_1 ... done                                                                                                                                      
Attaching to airflow-docker_airflow-init_1                                                                                                                                           
airflow-init_1       | The container is run as root user. For security, 
consider using a regular user account.                                                                       
airflow-init_1       | ....................                                                                                                                                          
airflow-init_1       | ERROR! Maximum number of retries (20) reached.                                                                                                                
airflow-init_1       |                                                                                                                                                               
airflow-init_1       | Last check result:                                                                                                                                            
airflow-init_1       | $ airflow db check                                                                                                                                            
airflow-init_1       | [2022-06-15 06:30:30,724] {configuration.py:484} 
ERROR - No module named 'openlineage'                                                                        
airflow-init_1       | Traceback (most recent call last):                                                                                                                            
airflow-init_1       |   File &quot;/home/airflow/.local/lib/python3.6/site-
packages/airflow/configuration.py&quot;, line 482, in getimport                                                    
airflow-init_1       |     return import_string(full_qualified_path)                                                                                                                 
airflow-init_1       |   File &quot;/home/airflow/.local/lib/python3.6/site-
packages/airflow/utils/module_loading.py&quot;, line 32, in import_string                                          
airflow-init_1       |     module = import_module(module_path)                                                                                                                       
airflow-init_1       |   File 
&quot;/usr/local/lib/python3.6/importlib/__init__.py&quot;, line 126, in 
import_module                                                                           
airflow-init_1       |     return _bootstrap._gcd_import(name[level:], 
package, level)                                                                                               
airflow-init_1       |   File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 
994, in _gcd_import                                                                                              
hdee@openlineageDEV:~/airflow-docker$                                                                                                                                                
airflow-init_1       |   File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 
941, in _find_and_load_unlocked                                                                                  
airflow-init_1       |   File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 
219, in _call_with_frames_removed                                                                                
airflow-init_1       |   File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 
994, in _gcd_import                                                                                              
airflow-init_1       |   File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 
971, in _find_and_load                                                                                           
airflow-init_1       |   File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 
953, in _find_and_load_unlocked                                                                                  
airflow-init_1       | ModuleNotFoundError: No module named 
'openlineage'                                                                                                            
airflow-init_1       |                                                                                                                                                               
airflow-init_1       | During handling of the above exception, another 
exception occurred:                                                                                           
airflow-init_1       |                                                                                                                                                               
airflow-init_1       | Traceback (most recent call last):                                                                                                                            
airflow-init_1       |   File &quot;/home/airflow/.local/bin/airflow&quot;, line 
8, in &lt;module&gt;                                                                                                
airflow-init_1       |     sys.exit(main())                                                                                                                                          
airflow-init_1       |   File &quot;/home/airflow/.local/lib/python3.6/site-
packages/airflow/__main__.py&quot;, line 40, in main                                                               
airflow-init_1       |     args.func(args)                                                                                                                                           
airflow-init_1       |   File &quot;/home/airflow/.local/lib/python3.6/site-
packages/airflow/cli/cli_parser.py&quot;, line 47, in command                                                      
airflow-init_1       |     func = import_string(import_path)                                                                                                                         
airflow-init_1       |   File &quot;/home/airflow/.local/lib/python3.6/site-
packages/airflow/utils/module_loading.py&quot;, line 32, in import_string                                          
airflow-init_1       |     module = import_module(module_path)                                                                                                                       
airflow-init_1       |   File 
&quot;/usr/local/lib/python3.6/importlib/__init__.py&quot;, line 126, in 
import_module                                                                           
airflow-init_1       |     return _bootstrap._gcd_import(name[level:], 
package, level)                                                                                               
airflow-init_1       |   File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 
994, in _gcd_import                                                                                              
airflow-init_1       |   File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 
971, in _find_and_load                                                                                           
airflow-init_1       |   File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 
955, in _find_and_load_unlocked                                                                                  
airflow-init_1       |   File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 
665, in _load_unlocked                                                                                           
airflow-init_1       |   File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, 
line 678, in exec_module                                                                                     
airflow-init_1       |   File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 
219, in _call_with_frames_removed                                                                                
airflow-init_1       |   File &quot;/home/airflow/.local/lib/python3.6/site-
packages/airflow/cli/commands/db_command.py&quot;, line 24, in &lt;module&gt;                                            
airflow-init_1       |     from airflow.utils import cli as cli_utils, 
db                                                                                                            
airflow-init_1       |   File &quot;/home/airflow/.local/lib/python3.6/site-
packages/airflow/utils/db.py&quot;, line 27, in &lt;module&gt;                                                           
airflow-init_1       |     from airflow.jobs.base_job import BaseJob  # 
noqa: F401                                                                                                   
airflow-init_1       |   File &quot;/home/airflow/.local/lib/python3.6/site-
packages/airflow/jobs/__init__.py&quot;, line 19, in &lt;module&gt;                                                      
airflow-init_1       |     import airflow.jobs.backfill_job                                                                                                                          
airflow-init_1       |   File &quot;/home/airflow/.local/lib/python3.6/site-
packages/airflow/jobs/backfill_job.py&quot;, line 28, in &lt;module&gt;                                                  
airflow-init_1       |     from airflow import models                                                                                                                                
airflow-init_1       |   File &quot;/home/airflow/.local/lib/python3.6/site-
packages/airflow/models/__init__.py&quot;, line 20, in &lt;module&gt;                                                    
airflow-init_1       |     from airflow.models.baseoperator import 
BaseOperator, BaseOperatorLink                                                                                    
airflow-init_1       |   File &quot;/home/airflow/.local/lib/python3.6/site-
packages/airflow/models/baseoperator.py&quot;, line 206, in &lt;module&gt;                                               
airflow-init_1       |     class BaseOperator(Operator, LoggingMixin, 
TaskMixin, metaclass=BaseOperatorMeta):                                                                        
airflow-init_1       |   File &quot;/home/airflow/.local/lib/python3.6/site-
packages/airflow/models/baseoperator.py&quot;, line 999, in BaseOperator                                           
airflow-init_1       |     def post_execute(self, context: Any, result: 
Any = None):                                                                                                 
airflow-init_1       |   File &quot;/home/airflow/.local/lib/python3.6/site-
packages/airflow/lineage/__init__.py&quot;, line 103, in apply_lineage                                             
airflow-init_1       |     _backend = get_backend()                                                                                                                                  
airflow-init_1       |   File &quot;/home/airflow/.local/lib/python3.6/site-
packages/airflow/lineage/__init__.py&quot;, line 52, in get_backend                                                
airflow-init_1       |     clazz = conf.getimport(&quot;lineage&quot;, &quot;backend&quot;, 
fallback=None)                                                                                               
airflow-init_1       |   File &quot;/home/airflow/.local/lib/python3.6/site-
packages/airflow/configuration.py&quot;, line 486, in getimport                                                    
airflow-init_1       |     f'The object could not be loaded. Please 
check &quot;{key}&quot; key in &quot;{section}&quot; section. '                                                                      
airflow-init_1       | airflow.exceptions.AirflowConfigException: The 
object could not be loaded. Please check &quot;backend&quot; key in &quot;lineage&quot; 
section. Current value: 
&quot;openlineage.lineage_backend.OpenLineageBackend&quot;.                                                                                                                                                       
airflow-init_1       |                                                                                                                                                               
airflow-docker_airflow-init_1 exited with code 1 

</code></pre>
",172,1,0,2,docker;airflow,2022-06-14 16:20:35,2022-06-14 16:20:35,2022-06-15 13:32:41,i m trying to running the dag in  example with airflow     i setup an airflow project on docker following  example  and i want to integrate it with openlieage  i wonder how can i do that  i set environment variables for openlineage in the  env file that looks like below   i git cloned the marquez repo on github and get marquez running following the   i suppose openlineage will listen on port   and marquez will listen on port   but when i browse localhost   which is the ui of marquez  it shows no jobs found  here is my yaml file  which is exactly the same as this   error message ,how to run airflow    with openlineage and marquez in docker 
196,19340590,72624032,Values added by e.parameter cannot be found when searching the column converted to a flat array,"<p>I'm using a training development software that supports JavaScript to capture the user name and record it in a spreadsheet but only if they are not already found in the spreadsheet and as long as the resulting array of users created by the column does not exceed a specific value.</p>
<p>When I test the script by actually running it, it pulls the user name and records it in the next row in column A, but then places undefined in the adjacent columns that hold data at the top.</p>
<p>If I ignore pulling the data from the external app and hard code a value for user name in the script, it adds the value as expected and everything else in the code operates just fine. I'm wondering of the value, when pulled using var userName=e.parameters[UserName] is being recorded as an object versus when I trouble shoot using something like var userName=&quot;Owen&quot; which is recorded as text.</p>
<pre><code>    var SHEET_NAME = &quot;Data&quot;;
    var SCRIPT_PROP = PropertiesService.getScriptProperties(); 
    function testfunc(){
    var doc = SpreadsheetApp.openById(SCRIPT_PROP.getProperty(&quot;key&quot;));
    var sheet = doc.getSheetByName(SHEET_NAME);
    var nextRow = sheet.getLastRow() + 1; // get next row
    //var row = [];
    var userName=e.parameters[UserName];
    Logger.log(userName);
    //Alternate userName for testing var userName=&quot;Owen&quot;;
    //Get values from column a and send them to an array
    var newArray=sheet.getRange('A:A').getValues();
    var sheetData = newArray.flat();
    //test to see if user name can be found in the array
    //this will also return the license count number for the user if user is found
    var userLicense = sheetData.indexOf(userName)-1;
    //determine how many licenses have been used
    var activatedLicenses = sheetData.length-2;
    Logger.log(activatedLicenses);
    //logical test to determine whether to let the user in, add the user, or reject the user
    var licenseLimit=sheet.getRange(2,2).getValue();
    Logger.log(licenseLimit);
    if(userLicense &gt;= -1){
    //let me in
    sheet.getRange(2,4).setValue('True');
    SpreadsheetApp.flush();
    Logger.log(&quot;Let Me In&quot;);
    }else{
    //user does not exist so test to see if licenses are available
    if(activatedLicenses == licenseLimit){
        sheet.getRange(2,3).setValue('True');
        sheet.getRange(2,4).setValue('False');
        SpreadsheetApp.flush();
        Logger.log(&quot;You Can't Come In&quot;)
    }else{
        //Add user to the list
        row.push(userName);
        sheet.getRange(nextRow, 1, 1, row.length).setValues([row]);
        Logger.log(&quot;new user added&quot;)
        sheet.getRange(2,4).setValue('True');
        SpreadsheetApp.flush(); 
    }
    }
    }
</code></pre>
<p>Thoughts? Can I force e.parameters to write to a cell as text?</p>
",19,0,0,1,google-apps-script,2022-06-15 01:26:52,2022-06-15 01:26:52,2022-06-15 01:26:52,i m using a training development software that supports javascript to capture the user name and record it in a spreadsheet but only if they are not already found in the spreadsheet and as long as the resulting array of users created by the column does not exceed a specific value  when i test the script by actually running it  it pulls the user name and records it in the next row in column a  but then places undefined in the adjacent columns that hold data at the top  if i ignore pulling the data from the external app and hard code a value for user name in the script  it adds the value as expected and everything else in the code operates just fine  i m wondering of the value  when pulled using var username e parameters username  is being recorded as an object versus when i trouble shoot using something like var username  owen  which is recorded as text  thoughts  can i force e parameters to write to a cell as text ,values added by e parameter cannot be found when searching the column converted to a flat array
197,1601580,41048002,How to use a python library that is constantly changing in a docker image or new container?,"<p>I organize my code in a python package (usually in a virtual environment like <code>virtualenv</code> and/or <code>conda</code>) and then usually call:</p>
<pre><code>python &lt;path_to/my_project/setup.py&gt; develop
</code></pre>
<p>or</p>
<pre><code>pip install -e &lt;path_to/my_project/setup.py&gt;
</code></pre>
<p>so that I can use the most recent version of my code. Since I develop mostly statistical or machine learning algorithms, I prototype a lot and change my code daily. However, recently the recommended way to run our experiments on the clusters I have access is through docker. I learned about docker and I think I have a rough idea of how to make it work but wanted wasn't quite sure if my solutions was good or if there might be better solutions out there.</p>
<p>The first solution that I thought is having a solution that copied the data in my docker image with:</p>
<pre><code>COPY /path_to/my_project
pip install /path_to/my_project
</code></pre>
<p>and then pip installing it. The issue with this solution is that I have to actually build a new image each time which seems silly and was hoping I could have something better. To do this I was thinking of having a bash file like:</p>
<pre><code>#BASH FILE TO BUILD AND REBUILD MY STUFF
# build the image with the newest version of 
# my project code and it pip installs it and its depedencies
docker build -t image_name .
docker run --rm image_name python run_ML_experiment_file.py 
docker kill current_container #not sure how to do get id of container
docker rmi image_name
</code></pre>
<p>as I said, my intuition tells me this is silly so I was hoping there was a single command way to do this with Docker or with a single Dockerfile. Also, note the command should use <code>-v ~/data/:/data</code> to be able to get the data and some other volume/mount to write to (in the host) when it finishes training.</p>
<p>Another solution that I thought was to have all the python dependencies or other dependencies that my library needs in the Dockerfile (and hence in the image) and then somehow executing in the running container the installation of my library. Maybe with <code>docker exec [OPTIONS] CONTAINER COMMAND</code> as:</p>
<pre><code>docker exec CONTAINER pip install /path_to/my_project
</code></pre>
<p>in the running container. After that then I could run the real experiment I want to run with the same exec command:</p>
<pre><code>docker exec CONTAINER python run_ML_experiment_file.py
</code></pre>
<p>though, I still don't know how to systematically get the container id though (because I probably don't want to look up the container id every time I do this).</p>
<p>Ideally in my head the best conceptual solution would be to simply have the Dockerfile know from the beginning to which file it should mount to (i.e. <code>/path_to/my_project</code>) and then somehow do <code>python [/path_to/my_project] develop</code> inside the image so that it would always be linked to the potentially changing python package/project. That way I can run my experiments with a <strong>single docker command</strong> as in:</p>
<pre><code>docker run --rm -v ~/data/:/data python run_ML_experiment_file.py
</code></pre>
<p>and not have to explicitly update the image myself every time (that includes not having to re install parts of the image that should be static) since its always in sync with the real library. Also, having some other script build a new image from scratch each time is not what I am looking for. Also, It would be nice to be able to avoid writing any bash too if possible.</p>
<hr />
<p>I think I am very close to a good solution. What I will do instead of building a new image each time I will simply run the <code>CMD</code> command to do python develop as follow:</p>
<pre><code># install my library (only when the a container is spun)
CMD python ~/my_tf_proj/setup.py develop
</code></pre>
<p>the advantage is that it will only pip install my library whenever I run a new container. This solves the development issue because re creating a new image takes to long. Though I just realized that if I use the <code>CMD</code> command then I can't run other commands given to my docker run, so I actually mean to run <code>ENTRYPOINT </code>.</p>
<p>Right now the only issue to complete this is that I am having issues using volume because I can't successfully link to <strong>my host project library within the Dockerfile</strong> (which seems to require an absolute path for some reason). I am currently doing doing (which doesn't seem to work):</p>
<pre><code>VOLUME /absolute_path_to/my_tf_proj /my_tf_proj
</code></pre>
<p>why can't I link using the VOLUME command in my Dockerfile? My main intention with using VOLUME is making my library (and other files that are always needed by this image) accessible when the CMD command tries to install my library. Is it possible to just have my library available all the time when a container is initiated?</p>
<p>Ideally I wanted to just have the library be installed automatically when a container is run and if possible, since the most recent version of the library is <strong>always</strong> required, have it install when a container is initialized.</p>
<p>As a reference right now my non-working Dockerfile looks as follow:</p>
<pre><code># This means you derive your docker image from the tensorflow docker image
# FROM gcr.io/tensorflow/tensorflow:latest-devel-gpu
FROM gcr.io/tensorflow/tensorflow
#FROM python
FROM ubuntu

RUN mkdir ~/my_tf_proj/
# mounts my tensorflow lib/proj from host to the container
VOLUME /absolute_path_to/my_tf_proj

#
RUN apt-get update

#
apt-get install vim

#
RUN apt-get install -qy python3
RUN apt-get install -qy python3-pip
RUN pip3 install --upgrade pip

#RUN apt-get install -y python python-dev python-distribute python-pip

# have the dependecies for my tensorflow library
RUN pip3 install numpy
RUN pip3 install keras
RUN pip3 install namespaces
RUN pip3 install pdb

# install my library (only when the a container is spun)
#CMD python ~/my_tf_proj/setup.py develop
ENTRYPOINT python ~/my_tf_proj/setup.py develop
</code></pre>
<hr />
<p>As a side remark:</p>
<p>Also, for some reason it requires me to do <code>RUN apt-get update</code> to be able to even install pip or vim in my container. Do people know why? I wanted to do this because just in case I wanted to attach to the container with a <code>bash</code> terminal, it would be really helpful.</p>
<p>Seems that Docker just forces you to apt install to always have the most recent version of software in the container?</p>
<hr />
<p>Bounty:</p>
<p>what a solution with <code>COPY</code>? and perhaps <code>docker build -f path/Docker .</code>. See: <a href=""https://stackoverflow.com/questions/68840188/how-does-one-build-a-docker-image-from-the-home-user-directory?noredirect=1#comment121660916_68840188"">How does one build a docker image from the home user directory?</a></p>
",2746,5,6,3,python;docker;dockerfile,2016-12-08 22:10:55,2016-12-08 22:10:55,2022-06-14 19:19:59,i organize my code in a python package  usually in a virtual environment like virtualenv and or conda  and then usually call  or so that i can use the most recent version of my code  since i develop mostly statistical or machine learning algorithms  i prototype a lot and change my code daily  however  recently the recommended way to run our experiments on the clusters i have access is through docker  i learned about docker and i think i have a rough idea of how to make it work but wanted wasn t quite sure if my solutions was good or if there might be better solutions out there  the first solution that i thought is having a solution that copied the data in my docker image with  and then pip installing it  the issue with this solution is that i have to actually build a new image each time which seems silly and was hoping i could have something better  to do this i was thinking of having a bash file like  as i said  my intuition tells me this is silly so i was hoping there was a single command way to do this with docker or with a single dockerfile  also  note the command should use  v   data   data to be able to get the data and some other volume mount to write to  in the host  when it finishes training  another solution that i thought was to have all the python dependencies or other dependencies that my library needs in the dockerfile  and hence in the image  and then somehow executing in the running container the installation of my library  maybe with docker exec  options  container command as  in the running container  after that then i could run the real experiment i want to run with the same exec command  though  i still don t know how to systematically get the container id though  because i probably don t want to look up the container id every time i do this   ideally in my head the best conceptual solution would be to simply have the dockerfile know from the beginning to which file it should mount to  i e   path_to my_project  and then somehow do python   path_to my_project  develop inside the image so that it would always be linked to the potentially changing python package project  that way i can run my experiments with a single docker command as in  and not have to explicitly update the image myself every time  that includes not having to re install parts of the image that should be static  since its always in sync with the real library  also  having some other script build a new image from scratch each time is not what i am looking for  also  it would be nice to be able to avoid writing any bash too if possible  i think i am very close to a good solution  what i will do instead of building a new image each time i will simply run the cmd command to do python develop as follow  the advantage is that it will only pip install my library whenever i run a new container  this solves the development issue because re creating a new image takes to long  though i just realized that if i use the cmd command then i can t run other commands given to my docker run  so i actually mean to run entrypoint   right now the only issue to complete this is that i am having issues using volume because i can t successfully link to my host project library within the dockerfile  which seems to require an absolute path for some reason   i am currently doing doing  which doesn t seem to work   why can t i link using the volume command in my dockerfile  my main intention with using volume is making my library  and other files that are always needed by this image  accessible when the cmd command tries to install my library  is it possible to just have my library available all the time when a container is initiated  ideally i wanted to just have the library be installed automatically when a container is run and if possible  since the most recent version of the library is always required  have it install when a container is initialized  as a reference right now my non working dockerfile looks as follow  as a side remark  also  for some reason it requires me to do run apt get update to be able to even install pip or vim in my container  do people know why  i wanted to do this because just in case i wanted to attach to the container with a bash terminal  it would be really helpful  seems that docker just forces you to apt install to always have the most recent version of software in the container  bounty  what a solution with copy  and perhaps docker build  f path docker    see  ,how to use a python library that is constantly changing in a docker image or new container 
198,586464,69869252,"&quot;adb.exe&quot; forward tcp:23915 jdwp:%pid%, &quot;jdb.exe&quot; -connect&quot; handshake failed - connection prematurally closed","<p>I am trying to connect to JDWP process using jdb.exe. It all worked before I have reinstalled my Windows 10 and everything else.</p>
<p>I have a following Batch script:</p>
<pre><code>&quot;adb.exe&quot; shell am force-stop com.rockstar.gta3
&quot;adb.exe&quot; shell am start -D -W -n com.rockstar.gta3/.GTA3
setlocal
for /f &quot;delims=&quot; %%a in ('&quot;adb.exe&quot; shell pidof com.rockstar.gta3') do @set pid=%%a
echo PID=%pid%
&quot;adb.exe&quot; forward tcp:23915 jdwp:%pid%

set VALUE=CurrentVersion

set KEY=&quot;HKLM\SOFTWARE\JavaSoft\JDK&quot;
reg query %KEY% /v %VALUE% 2&gt;nul &amp;&amp; goto JDKisInstalled

set KEY=&quot;HKLM\SOFTWARE\JavaSoft\Java Development Kit&quot;
reg query %KEY% /v %VALUE% 2&gt;nul &amp;&amp; goto JDKisInstalled

echo JDK not installed, path to JDK could not be read from registry.
pause

:JDKisInstalled
set JDK_VERSION=
for /f &quot;tokens=2,*&quot; %%a in ('reg query %KEY% /v %VALUE% ^| findstr %VALUE%') do (
set JDK_VERSION=%%b
)

set JDK_HOME=
for /f &quot;tokens=2,*&quot; %%a in ('reg query %KEY%\%JDK_VERSION% /v JavaHome ^| findstr JavaHome') do (
    set JDK_HOME=%%b
)

echo exit | &quot;%JDK_HOME%\bin\jdb.exe&quot; -connect com.sun.jdi.SocketAttach:hostname=localhost,port=23915
pause
</code></pre>
<p>It worked before. Now after reinstalling Windows 10 I get the following error, while executing jdb.exe:</p>
<pre><code>C:\Users\fastm\Desktop&gt;&quot;adb.exe&quot; shell am force-stop com.rockstar.gta3

C:\Users\fastm\Desktop&gt;&quot;adb.exe&quot; shell am start -D -W -n com.rockstar.gta3/.GTA3
Starting: Intent { cmp=com.rockstar.gta3/.GTA3 }
Status: timeout
Activity: com.rockstar.gta3/.GTA3
WaitTime: 10103
Complete

C:\Users\fastm\Desktop&gt;setlocal

C:\Users\fastm\Desktop&gt;for /F &quot;delims=&quot; %a in ('&quot;adb.exe&quot; shell pidof com.rockstar.gta3') do @set pid=%a

C:\Users\fastm\Desktop&gt;echo PID=13456
PID=13456

C:\Users\fastm\Desktop&gt;&quot;adb.exe&quot; forward tcp:23915 jdwp:13456

C:\Users\fastm\Desktop&gt;set VALUE=CurrentVersion

C:\Users\fastm\Desktop&gt;set KEY=&quot;HKLM\SOFTWARE\JavaSoft\JDK&quot;

C:\Users\fastm\Desktop&gt;reg query &quot;HKLM\SOFTWARE\JavaSoft\JDK&quot; /v CurrentVersion   2&gt;nul  &amp;&amp; goto JDKisInstalled

C:\Users\fastm\Desktop&gt;set KEY=&quot;HKLM\SOFTWARE\JavaSoft\Java Development Kit&quot;

C:\Users\fastm\Desktop&gt;reg query &quot;HKLM\SOFTWARE\JavaSoft\Java Development Kit&quot; /v CurrentVersion   2&gt;nul  &amp;&amp; goto JDKisInstalled

HKEY_LOCAL_MACHINE\SOFTWARE\JavaSoft\Java Development Kit
    CurrentVersion    REG_SZ    1.8


C:\Users\fastm\Desktop&gt;set JDK_VERSION=

C:\Users\fastm\Desktop&gt;for /F &quot;tokens=2,*&quot; %a in ('reg query &quot;HKLM\SOFTWARE\JavaSoft\Java Development Kit&quot; /v CurrentVersion | findstr CurrentVersion') do (set JDK_VERSION=%b )

C:\Users\fastm\Desktop&gt;(set JDK_VERSION=1.8 )

C:\Users\fastm\Desktop&gt;set JDK_HOME=

C:\Users\fastm\Desktop&gt;for /F &quot;tokens=2,*&quot; %a in ('reg query &quot;HKLM\SOFTWARE\JavaSoft\Java Development Kit&quot;\1.8 /v JavaHome | findstr JavaHome') do (set JDK_HOME=%b )

C:\Users\fastm\Desktop&gt;(set JDK_HOME=C:\Program Files\Java\jdk1.8.0_121 )

C:\Users\fastm\Desktop&gt;echo exit   | &quot;C:\Program Files\Java\jdk1.8.0_121\bin\jdb.exe&quot; -connect com.sun.jdi.SocketAttach:hostname=localhost,port=23915
java.io.IOException: handshake failed - connection prematurally closed
        at com.sun.tools.jdi.SocketTransportService.handshake(SocketTransportService.java:136)
        at com.sun.tools.jdi.SocketTransportService.attach(SocketTransportService.java:232)
        at com.sun.tools.jdi.GenericAttachingConnector.attach(GenericAttachingConnector.java:116)
        at com.sun.tools.jdi.SocketAttachingConnector.attach(SocketAttachingConnector.java:90)
        at com.sun.tools.example.debug.tty.VMConnection.attachTarget(VMConnection.java:519)
        at com.sun.tools.example.debug.tty.VMConnection.open(VMConnection.java:328)
        at com.sun.tools.example.debug.tty.Env.init(Env.java:63)
        at com.sun.tools.example.debug.tty.TTY.main(TTY.java:1082)

Fatal error:
Unable to attach to target VM.

C:\Users\fastm\Desktop&gt;pause
</code></pre>
<p>I have tried many different JDK versions 8, 11 and 17 to mention. No luck.
Then I have looked into Java source code for this message.
[https://docs.oracle.com/javase/8/docs/technotes/guides/jpda/jdwp-spec.html][1]
The error comes from function void handshake(Socket s, long timeout) throws IOException</p>
<pre><code>            try {
            n = s.getInputStream().read(b, received, hello.length-received);
        } catch (SocketTimeoutException x) {
            throw new IOException(&quot;handshake timeout&quot;);
        }
        if (n &lt; 0) {
            s.close();
            throw new IOException(&quot;handshake failed - connection prematurally closed&quot;);
        }
        received += n;
</code></pre>
<p>Having analyzed this function it appears that the JDB application should receive a reply &quot;JDWP-Handshake&quot;.</p>
<p>This is specified in the documentation: <a href=""https://docs.oracle.com/javase/8/docs/technotes/guides/jpda/jdwp-spec.html"" rel=""nofollow noreferrer"">https://docs.oracle.com/javase/8/docs/technotes/guides/jpda/jdwp-spec.html</a></p>
<pre><code>The handshake process has the following steps:

The debugger side sends 14 bytes to the VM side, consisting of the 14 ASCII characters of the string &quot;JDWP-Handshake&quot; in the beginning and reply with the same characters.
</code></pre>
<p>However it replied with nothing here.</p>
<p>This makes me think that &quot;adb forward&quot; with JDWP functionality may have a problem on my Windows 10.
Tried adb forward tcp:7000 tcp:7000 and this works, but it's something else.</p>
<p>Does anyone know how to solve this problem?</p>
",149,1,0,3,android;adb;jdb,2021-11-07 03:59:22,2021-11-07 03:59:22,2022-06-14 16:17:37,i am trying to connect to jdwp process using jdb exe  it all worked before i have reinstalled my windows  and everything else  i have a following batch script  it worked before  now after reinstalling windows  i get the following error  while executing jdb exe  having analyzed this function it appears that the jdb application should receive a reply  jdwp handshake   this is specified in the documentation   however it replied with nothing here  does anyone know how to solve this problem , adb exe  forward tcp  jdwp  pid    jdb exe   connect  handshake failed   connection prematurally closed
199,17945,54868988,How to determine which forks on GitHub are ahead?,"<p>Sometimes, the original GitHub repository of a piece of software I'm using, such as <a href=""https://github.com/wummel/linkchecker"" rel=""noreferrer"">linkchecker</a>, is seeing little or no development, while a lot of forks have been created (in this case: 142, at the time of writing).</p>

<p>For each fork, I'd like to know:</p>

<ul>
<li>which branches it has with commits ahead of the original master branch</li>
</ul>

<p>and for each such branch:</p>

<ul>
<li>how many commits it is ahead of the original</li>
<li>how many commits it is behind</li>
</ul>

<p><a href=""https://stackoverflow.com/questions/31671585/github-comparing-across-forks"">GitHub has a web interface for comparing forks</a>, but I don't want to do this manually for each fork, I just want a CSV file with the results for all forks. How can this be scripted? <a href=""https://developer.github.com/v3/repos/forks/"" rel=""noreferrer"">The GitHub API can list the forks</a>, but I can't see how to compare forks with it. Cloning every fork in turn and doing the comparison locally seems a bit crude.</p>
",3746,8,32,2,github;git-fork,2019-02-25 16:59:48,2019-02-25 16:59:48,2022-06-14 12:55:32,sometimes  the original github repository of a piece of software i m using  such as   is seeing little or no development  while a lot of forks have been created  in this case    at the time of writing   for each fork  i d like to know  and for each such branch    but i don t want to do this manually for each fork  i just want a csv file with the results for all forks  how can this be scripted    but i can t see how to compare forks with it  cloning every fork in turn and doing the comparison locally seems a bit crude ,how to determine which forks on github are ahead 
200,13388298,72611979,IEEE Xplore&#39;s Python Software Development Kit returns ImportError: cannot import name &#39;soft_unicode&#39; from &#39;markupsafe&#39;,"<p>I am working on a Plagiarism Detector using Python and NLP and I wanted to build the training set dynamically. Hence I am trying to use the IEEE Xplore's Python Software Development Kit to gather some part of the training data, but when I try to import the SDK I get an Import error.(Exact error: ImportError: cannot import name 'soft_unicode' from 'markupsafe')</p>
<p>I was using the code provided in the <a href=""https://developer.ieee.org/Python_Software_Development_Kit"" rel=""nofollow noreferrer"">documentation</a></p>
<p>The Code(I have replaced the access key and query with placeholders):</p>
<pre><code>import xplore
query = xplore.xploreapi.XPLORE('api_access_key')
query.abstractText('query')
data = query.callAPI()  
</code></pre>
",23,1,1,4,python;nlp;importerror;ieee,2022-06-14 08:36:33,2022-06-14 08:36:33,2022-06-14 08:58:36,i am working on a plagiarism detector using python and nlp and i wanted to build the training set dynamically  hence i am trying to use the ieee xplore s python software development kit to gather some part of the training data  but when i try to import the sdk i get an import error  exact error  importerror  cannot import name  soft_unicode  from  markupsafe   i was using the code provided in the  the code i have replaced the access key and query with placeholders  ,ieee xplore   s python software development kit returns importerror  cannot import name    soft_unicode    from    markupsafe   
201,3760899,72606932,How do I install v8@3.15 on ubuntu?,"<p>I am new to Linux and I am trying to setup a ruby on rails app from work. Now, the Gemfile wants to install therubyracer.</p>
<p>Upon running <code>bundle install</code>, it fails:</p>
<pre><code>Fetching therubyracer 0.12.3
Installing therubyracer 0.12.3 with native extensions
Gem::Ext::BuildError: ERROR: Failed to build gem native extension.

    current directory: /root/.rbenv/versions/2.5.8/lib/ruby/gems/2.5.0/gems/therubyracer-0.12.3/ext/v8
/root/.rbenv/versions/2.5.8/bin/ruby -r ./siteconf20220613-666-1d8cum5.rb extconf.rb --with-v8-dir=/usr/local/opt/v8@3.15
checking for -lpthread... yes
checking for v8.h... no
*** extconf.rb failed ***
Could not create Makefile due to some reason, probably lack of necessary
libraries and/or headers.  Check the mkmf.log file for more details.  You may
need configuration options.

Provided configuration options:
    --with-opt-dir
    --without-opt-dir
    --with-opt-include
    --without-opt-include=${opt-dir}/include
    --with-opt-lib
    --without-opt-lib=${opt-dir}/lib
    --with-make-prog
    --without-make-prog
    --srcdir=.
    --curdir
    --ruby=/root/.rbenv/versions/2.5.8/bin/$(RUBY_BASE_NAME)
    --with-pthreadlib
    --without-pthreadlib
    --enable-debug
    --disable-debug
    --with-v8-dir
    --with-v8-include
    --without-v8-include=${v8-dir}/include
    --with-v8-lib
    --without-v8-lib=${v8-dir}/lib
/root/.rbenv/versions/2.5.8/lib/ruby/gems/2.5.0/gems/libv8-3.16.14.19/ext/libv8/location.rb:50:in `configure': By using --with-system-v8, you have chosen to use the version 
(Libv8::Location::System::NotFoundError)
of V8 found on your system and *not* the one that is bundled with 
the libv8 rubygem. 

However, your system version of v8 could not be located. 

Please make sure your system version of v8 that is compatible 
with 3.16.14.19 installed. You may need to use the 
--with-v8-dir option if it is installed in a non-standard location
    from /root/.rbenv/versions/2.5.8/lib/ruby/gems/2.5.0/gems/libv8-3.16.14.19/lib/libv8.rb:7:in `configure_makefile'
    from extconf.rb:32:in `&lt;main&gt;'

To see why this extension failed to compile, please check the mkmf.log which can be found here:

  /root/.rbenv/versions/2.5.8/lib/ruby/gems/2.5.0/extensions/aarch64-linux/2.5.0/therubyracer-0.12.3/mkmf.log

extconf failed, exit code 1

Gem files will remain installed in /root/.rbenv/versions/2.5.8/lib/ruby/gems/2.5.0/gems/therubyracer-0.12.3 for inspection.
Results logged to /root/.rbenv/versions/2.5.8/lib/ruby/gems/2.5.0/extensions/aarch64-linux/2.5.0/therubyracer-0.12.3/gem_make.out

An error occurred while installing therubyracer (0.12.3), and Bundler cannot continue.
Make sure that `gem install therubyracer -v '0.12.3' --source 'https://rubygems.org/'` succeeds before bundling.
</code></pre>
<p>As it can be seen <code>checking for v8.h... no</code>, it is unable to find <code>v8.h</code> file. This is because it depends on v8 engine and I am not sure how to install it on Ubuntu:18.04.</p>
<p>I am trying to do this setup with a Dockerfile.<br />
Here is my Dockerfile:</p>
<pre><code>FROM ubuntu:18.04

RUN apt update
RUN apt install -y git curl libssl-dev libreadline-dev zlib1g-dev autoconf bison build-essential libyaml-dev libreadline-dev libncurses5-dev libffi-dev libgdbm-dev libpq-dev libcurl4-openssl-dev python software-properties-common
RUN apt update
RUN curl -fsSL https://github.com/rbenv/rbenv-installer/raw/HEAD/bin/rbenv-installer | bash
RUN git clone https://github.com/rbenv/ruby-build.git
ENV PATH=&quot;/root/.rbenv/bin:${PATH}&quot;
RUN rbenv install 2.5.8
ENV PATH=&quot;/root/.rbenv/versions/2.5.8/bin:${PATH}&quot;
RUN eval &quot;$(rbenv init -)&quot;

RUN gem install bundler:1.17.3
RUN bundle config build.therubyracer --with-v8-dir=/usr/local/opt/v8@3.15
RUN bundle config build.libv8 --with-system-v8


COPY . /opt/myapp
WORKDIR /opt/myapp

# RUN bundle install

ENTRYPOINT [&quot;tail&quot;, &quot;-f&quot;, &quot;/dev/null&quot;]
</code></pre>
<p>Upon running <code>docker exec -it my_image</code>, and then <code>bundle install</code>, I get the above error.</p>
<p>Here is my Gemfile:</p>
<pre><code>source &quot;https://rubygems.org&quot;
git_source(:github) do |repo_name|
  repo_name = &quot;#{repo_name}/#{repo_name}&quot; unless repo_name.include?(&quot;/&quot;)
  &quot;https://github.com/#{repo_name}.git&quot;
end
ruby &quot;2.5.8&quot;

gem &quot;oj&quot;

gem &quot;coffee-rails&quot;, &quot;~&gt; 4.2&quot;
gem &quot;loofah&quot;, &quot;~&gt; 2.9.0&quot;
gem &quot;puma&quot;, &quot;~&gt; 5.6.4&quot;
gem &quot;rails&quot;, &quot;~&gt; 5.2.7&quot;
gem &quot;rails-html-sanitizer&quot;, &quot;~&gt; 1.0.4&quot;
gem &quot;sass-rails&quot;, &quot;~&gt; 5.1.0&quot;
gem &quot;turbolinks&quot;, &quot;~&gt; 5&quot;
gem &quot;uglifier&quot;, &quot;&gt;= 1.3.0&quot;

gem &quot;bcrypt&quot;, &quot;~&gt; 3.1.7&quot;
gem &quot;execjs&quot;
gem &quot;jsonapi-serializers&quot;
gem &quot;jwt&quot;
gem &quot;newrelic_rpm&quot;, &quot;~&gt; 6.12&quot;, &quot;&gt;= 6.12.0.367&quot;
gem &quot;rack-cors&quot;, &quot;~&gt; 1.0.4&quot;, require: &quot;rack/cors&quot;
gem &quot;redis&quot;
gem &quot;redis-mutex&quot;
gem &quot;redis-rails&quot;
gem &quot;simple_command&quot;
gem &quot;therubyracer&quot;
gem &quot;will_paginate&quot;, &quot;~&gt; 3.1.7&quot;

# yanked v0.3.5
gem &quot;mimemagic&quot;, github: &quot;mimemagicrb/mimemagic&quot;, ref: &quot;01f92d86d15d85cfd0f20dabd025dcbd36a8a60f&quot;

gem &quot;activeadmin_json_editor&quot;, &quot;~&gt; 0.0.7&quot;
gem &quot;awesome_print&quot;
gem &quot;aws-sdk-cloudwatch&quot;
gem &quot;aws-sdk-sqs&quot;
gem &quot;capistrano-sidekiq&quot;, group: :development
gem &quot;committee&quot;
gem &quot;config&quot;
gem &quot;dotenv-rails&quot;
gem &quot;foreman&quot;
gem &quot;geocoder&quot;, &quot;~&gt; 1.6.1&quot;
gem &quot;high_voltage&quot;
gem &quot;http&quot;, &quot;~&gt; 5.0.1&quot;
gem &quot;jquery-rails&quot;
gem &quot;leaderboard&quot;
gem &quot;materialize-sass&quot;
gem &quot;memory_profiler&quot;
gem &quot;oink&quot;, &quot;~&gt; 0.10.1&quot;
gem &quot;pg&quot;, &quot;~&gt; 0.20&quot;
gem &quot;rspec-core&quot;, &quot;~&gt; 3.7.1&quot;
gem &quot;rswag&quot;
gem &quot;rubocop&quot;, &quot;~&gt; 0.81&quot;, require: false
gem &quot;rubocop-performance&quot;, &quot;~&gt; 1.5.2&quot;, require: false
gem &quot;rubocop-rails&quot;, &quot;~&gt; 2.4.2&quot;, require: false
gem &quot;sidekiq&quot;, &quot;5.2.10&quot;
gem &quot;sidekiq-scheduler&quot;
gem &quot;strong_migrations&quot;
gem &quot;tzinfo-data&quot;, platforms: %i[mingw mswin x64_mingw jruby]

# for ether scan address formatting
gem &quot;digest-sha3&quot;
gem &quot;rlp&quot;

group :development, :test do
  gem &quot;byebug&quot;, platforms: %i[mri mingw x64_mingw]
  gem &quot;capybara&quot;, &quot;~&gt; 2.13&quot;
  gem &quot;selenium-webdriver&quot;
end

group :development do
  gem &quot;letter_opener&quot;, &quot;1.6.0&quot;
  gem &quot;listen&quot;, &quot;&gt;= 3.0.5&quot;, &quot;&lt; 3.2&quot;
  gem &quot;spring&quot;
  gem &quot;spring-watcher-listen&quot;, &quot;~&gt; 2.0.0&quot;
  gem &quot;web-console&quot;, &quot;&gt;= 3.3.0&quot;
end

group :development do
  gem &quot;better_errors&quot;
  gem &quot;capistrano&quot;
  gem &quot;capistrano-bundler&quot;
  gem &quot;capistrano-passenger&quot;, &quot;&gt;= 0.1.1&quot;
  gem &quot;capistrano-rails&quot;
  gem &quot;capistrano-rvm&quot;
  gem &quot;guard-bundler&quot;
  gem &quot;guard-rails&quot;
  gem &quot;guard-rspec&quot;
  gem &quot;rails_layout&quot;
  gem &quot;rb-fchange&quot;, require: false
  gem &quot;rb-fsevent&quot;, require: false
  gem &quot;rb-inotify&quot;, require: false
  gem &quot;rb-readline&quot;
  gem &quot;spring-commands-rspec&quot;
end
group :development, :test do
  gem &quot;factory_bot_rails&quot;
  gem &quot;faker&quot;
  gem &quot;pry&quot;
  gem &quot;rspec-rails&quot;
  gem &quot;webmock&quot;, &quot;~&gt; 3.13.0&quot;
end
group :test do
  gem &quot;database_cleaner&quot;
  gem &quot;launchy&quot;
  gem &quot;rails-controller-testing&quot;
  gem &quot;rspec-sidekiq&quot;
  gem &quot;shoulda-matchers&quot;
  gem &quot;simplecov&quot;, &quot;~&gt; 0.17.1&quot;, require: false
end
gem &quot;pusher&quot;

gem &quot;activeadmin&quot;, &quot;~&gt; 2.9.0&quot;
gem &quot;activeadmin_addons&quot;, &quot;~&gt; 1.7.1&quot;
gem &quot;active_admin_role&quot;, &quot;~&gt; 0.2.2&quot;
gem &quot;audited&quot;, &quot;~&gt; 4.10.0&quot;
gem &quot;carrierwave&quot;, &quot;~&gt; 1.3.2&quot;
gem &quot;devise&quot;, &quot;~&gt; 4.7.1&quot;
gem &quot;fog-aws&quot;, &quot;~&gt; 3.3.0&quot;
gem &quot;mini_magick&quot;
gem &quot;pg_search&quot;, &quot;~&gt; 2.3&quot;, &quot;&gt;= 2.3.2&quot;
gem &quot;rotp&quot;
gem &quot;tinymce-rails&quot;

# dynamodb
gem &quot;dynamoid&quot;

gem &quot;activerecord-import&quot;, &quot;~&gt; 1.0.1&quot;
gem &quot;bootsnap&quot;, require: false
gem &quot;bundler-audit&quot;, &quot;~&gt; 0.7.0.1&quot;
gem &quot;device_detector&quot;
gem &quot;karafka&quot;
gem &quot;phonelib&quot;, &quot;~&gt; 0.6.44&quot;
gem &quot;sentry-rails&quot;
gem &quot;slack-notifier&quot;

group :development do
  gem &quot;brakeman&quot;, &quot;~&gt; 4.10.0&quot;
  gem &quot;bullet&quot;
end

group :development, :test, :staging do
  gem &quot;active_record_query_trace&quot;
end

# parallel rspec
gem &quot;parallel_tests&quot;, group: %i[development test]

# cloudflare
gem &quot;cloudflare-rails&quot;, &quot;~&gt; 2.0.0&quot;, group: %i[production staging testing]

gem &quot;makara&quot;, &quot;~&gt; 0.5.1&quot;

gem &quot;distribute_reads&quot;, &quot;~&gt; 0.3.4&quot;
gem &quot;multiverse&quot;, &quot;~&gt; 0.2.2&quot;
gem &quot;nokogiri&quot;, &quot;&gt;= 1.12.5&quot;

gem &quot;elastic-apm&quot;, group: %i[production staging]

gem &quot;ddtrace&quot;, require: &quot;ddtrace/auto_instrument&quot;

gem &quot;rails_semantic_logger&quot;
</code></pre>
<p>Can someone help me get through this? Help me understand how I can install v8 engine with Docker? I tried <code>apt install libv8-dev</code>. apt is unable to find libv8-dev.</p>
<p>I can install v8@3.15 on mac using brew: <code>brew install v8@3.15</code>.</p>
<p>How can I install v8@3.15 on ubuntu docker?</p>
",144,0,0,5,ruby-on-rails;ruby;docker;rubygems;apt,2022-06-13 20:36:03,2022-06-13 20:36:03,2022-06-13 20:36:03,i am new to linux and i am trying to setup a ruby on rails app from work  now  the gemfile wants to install therubyracer  upon running bundle install  it fails  as it can be seen checking for v h    no  it is unable to find v h file  this is because it depends on v engine and i am not sure how to install it on ubuntu    upon running docker exec  it my_image  and then bundle install  i get the above error  here is my gemfile  can someone help me get through this  help me understand how i can install v engine with docker  i tried apt install libv dev  apt is unable to find libv dev  i can install v   on mac using brew  brew install v    how can i install v   on ubuntu docker ,how do i install v   on ubuntu 
202,19327109,72597593,Ursina Error - AssersionError: !is_empty() at line 1045 of panda/src/pgraph/nodePath.cxx,"<p>I'm trying to make a minecraft clone in Python using Ursina but I have been stuck on one problem when removing water if a block is placed on top of it. Collisions are off for water but rest are and I've been stuck for a long time pls help! I add each block made into an list with all it's data like coords (x, y, z) and remove them from the list when they are deleted. My plan is to compare all the blocks in the list's xyz coords to all the water blocks xyz corrds and if they are the same then the water will be removed and deleted from the list. I've worked on this for a long time but the problem wont go away.</p>
<p>Full error message:</p>
<pre><code>package_folder: C:\Users\dyclo\AppData\Local\Programs\Python\Python310\lib\site-
packages\ursina
asset_folder: C:\Users\dyclo\OneDrive\Documents\VS Code Project\Minecraft Ursina Edition
screen resolution: (1920, 1080)
Known pipe types:
  wglGraphicsPipe
(3 aux display modules not yet loaded.)
:display(error): The application requested harware acceleration, but your OpenGL
:display(error): driver, GDI Generic, only supports software rendering.
:display(error): You need to install a hardware-accelerated OpenGL driver, or,
:display(error): if you actually *want* to use a software renderer, then
:display(error): alter the hardware/software configuration in your Config.prc file.
:display(warning): Unable to load libtinydisplay.dll: Path not found
:display(warning): Unable to load libpandadx8.dll: Path not found
:pnmimage:png(warning): iCCP: known incorrect sRGB profile
:pnmimage:png(warning): iCCP: known incorrect sRGB profile
read obj at: C:\Users\dyclo\OneDrive\Documents\VS Code Project\Minecraft Ursina Edition\assets\block.obj
read obj at: C:\Users\dyclo\OneDrive\Documents\VS Code Project\Minecraft Ursina Edition\assets\arm.obj
info: development mode: True
application successfully started
info: changed aspect ratio: 1.778 -&gt; 1.778
{'x': 0.0, 'y': 0.0, 'z': 7.0, 'position': Vec3(0, 0, 7), 'texture': grass_block.png}
{'x': 0.0, 'y': 1.0, 'z': 7.0, 'position': Vec3(0, 1, 7), 'texture': grass_block.png}
Assertion failed: !is_empty() at line 1045 of panda/src/pgraph/nodePath.cxx
Traceback (most recent call last):
  File &quot;C:\Users\dyclo\AppData\Local\Programs\Python\Python310\lib\site-packages\direct\showbase\EventManager.py&quot;, line 49, in eventLoopTask
    self.doEvents()
  File &quot;C:\Users\dyclo\AppData\Local\Programs\Python\Python310\lib\site-packages\direct\showbase\EventManager.py&quot;, line 43, in doEvents
    processFunc(dequeueFunc())
  File &quot;C:\Users\dyclo\AppData\Local\Programs\Python\Python310\lib\site-packages\direct\showbase\EventManager.py&quot;, line 99, in processEvent
    messenger.send(eventName, paramList)
  File &quot;C:\Users\dyclo\AppData\Local\Programs\Python\Python310\lib\site-packages\direct\showbase\Messenger.py&quot;, line 337, in send
    self.__dispatch(acceptorDict, event, sentArgs, foundWatch)
  File &quot;C:\Users\dyclo\AppData\Local\Programs\Python\Python310\lib\site-packages\direct\showbase\Messenger.py&quot;, line 422, in __dispatch
    result = method (*(extraArgs + sentArgs))
  File &quot;C:\Users\dyclo\AppData\Local\Programs\Python\Python310\lib\site-packages\ursina\main.py&quot;, line 201, in input
    entity.input(key)
  File &quot;C:\Users\dyclo\OneDrive\Documents\VS Code Project\Minecraft Ursina Edition\game.py&quot;, line 189, in input
    'x': self.position.x,
  File &quot;C:\Users\dyclo\AppData\Local\Programs\Python\Python310\lib\site-packages\ursina\entity.py&quot;, line 458, in position
    return Vec3(*self.getPos())
AssertionError: !is_empty() at line 1045 of panda/src/pgraph/nodePath.cxx
:task(error): Exception occurred in PythonTask eventManager
Traceback (most recent call last):
  File &quot;C:\Users\dyclo\OneDrive\Documents\VS Code Project\Minecraft Ursina Edition\game.py&quot;, line 525, in &lt;module&gt;
    app.run()
  File &quot;C:\Users\dyclo\AppData\Local\Programs\Python\Python310\lib\site-packages\ursina\main.py&quot;, line 239, in run
    super().run()
  File &quot;C:\Users\dyclo\AppData\Local\Programs\Python\Python310\lib\site-packages\direct\showbase\ShowBase.py&quot;, line 3328, in run
    self.taskMgr.run()
  File &quot;C:\Users\dyclo\AppData\Local\Programs\Python\Python310\lib\site-packages\direct\task\Task.py&quot;, line 553, in run
    self.step()
  File &quot;C:\Users\dyclo\AppData\Local\Programs\Python\Python310\lib\site-packages\direct\task\Task.py&quot;, line 504, in step
    self.mgr.poll()
  File &quot;C:\Users\dyclo\AppData\Local\Programs\Python\Python310\lib\site-packages\direct\showbase\EventManager.py&quot;, line 49, in eventLoopTask
    self.doEvents()
  File &quot;C:\Users\dyclo\AppData\Local\Programs\Python\Python310\lib\site-packages\direct\showbase\EventManager.py&quot;, line 43, in doEvents
    processFunc(dequeueFunc())
  File &quot;C:\Users\dyclo\AppData\Local\Programs\Python\Python310\lib\site-packages\direct\showbase\EventManager.py&quot;, line 99, in processEvent
    messenger.send(eventName, paramList)
  File &quot;C:\Users\dyclo\AppData\Local\Programs\Python\Python310\lib\site-packages\direct\showbase\Messenger.py&quot;, line 337, in send
    self.__dispatch(acceptorDict, event, sentArgs, foundWatch)
  File &quot;C:\Users\dyclo\AppData\Local\Programs\Python\Python310\lib\site-packages\direct\showbase\Messenger.py&quot;, line 422, in __dispatch
    result = method (*(extraArgs + sentArgs))
  File &quot;C:\Users\dyclo\AppData\Local\Programs\Python\Python310\lib\site-packages\ursina\main.py&quot;, line 201, in input
    entity.input(key)
  File &quot;C:\Users\dyclo\OneDrive\Documents\VS Code Project\Minecraft Ursina Edition\game.py&quot;, line 189, in input
    'x': self.position.x,
  File &quot;C:\Users\dyclo\AppData\Local\Programs\Python\Python310\lib\site-packages\ursina\entity.py&quot;, line 458, in position
    return Vec3(*self.getPos())
AssertionError: !is_empty() at line 1045 of panda/src/pgraph/nodePath.cxx
</code></pre>
<p>All my code:</p>
<pre><code>from ursina import *
from ursina.prefabs.first_person_controller import FirstPersonController
import random


app = Ursina()


punch_sound   = Audio('assets/punch_sound',loop = False, autoplay = False)

block_pick = 1

start_chunk = 13

window.title = 'MINECRAFT: Bad Ursina Edition'
window.borderless = False
window.fullscreen = False
window.exit_button.visible = False
window.fps_counter.enabled = True

voxels = []


grass_texture = load_texture('assets/grass_block.png')
stone_texture = load_texture('assets/stone_block.png')
brick_texture = load_texture('assets/brick_block.png')
dirt_texture = load_texture('assets/dirt_block.png')
sky_texture  = load_texture('assets/skybox.png')
arm_texture  = load_texture('assets/arm_texture.png')
leaves_texture = load_texture('assets/oak_leaves.png')
log_texture = load_texture('assets/oak_log.png')
diamond_ore_texture = load_texture('assets/diamond_ore.png')
coal_ore_texture = load_texture('assets/coal_ore.png')
iron_ore_texture = load_texture('assets/iron_ore.png')
diamond_ore_block_texture = load_texture('assets/diamond_block.png')
coal_ore_block_texture = load_texture('assets/coal_block.png')
iron_ore_block_texture = load_texture('assets/iron_block.png')
oak_planks_texture = load_texture('assets/oak_planks.png')
crafting_table_texture = load_texture('assets/crafting_table.png')
cobblestone_texture = load_texture('assets/cobblestone.png')
sand_texture = load_texture('assets/sand.png')
cactus_texture = load_texture('assets/cactus.png')
water_texture = load_texture('assets/water.png')

def update():
    global block_pick
    global inventory

    if held_keys['left mouse'] or held_keys['right mouse']:
        hand.active()
    else:
        hand.passive()

    if held_keys['1'] and inventory: block_pick = 1
    if held_keys['2'] and inventory: block_pick = 2
    if held_keys['3'] and inventory: block_pick = 3
    if held_keys['4'] and inventory: block_pick = 4
    if held_keys['5'] and inventory: block_pick = 5
    if held_keys['6'] and inventory: block_pick = 6
    if held_keys['7'] and inventory: block_pick = 7
    if held_keys['8'] and inventory: block_pick = 8
    if held_keys['9'] and inventory: block_pick = 9
    if held_keys['1'] and inventory == False: block_pick = 10
    if held_keys['2'] and inventory == False: block_pick = 11
    if held_keys['3'] and inventory == False: block_pick = 12
    if held_keys['4'] and inventory == False: block_pick = 13
    if held_keys['5'] and inventory == False: block_pick = 14
    if held_keys['6'] and inventory == False: block_pick = 15
    if held_keys['7'] and inventory == False: block_pick = 16
    if held_keys['8'] and inventory == False: block_pick = 17
    if held_keys['9'] and inventory == False: block_pick = 18
    if held_keys['0'] and inventory == False: inventory = True

    if block_pick == 1: info.text = &quot;Grass Block&quot;

    if block_pick == 2: info.text = &quot;Stone&quot;

    if block_pick == 3: info.text = &quot;Bricks&quot;

    if block_pick == 4: info.text = &quot;Dirt&quot;

    if block_pick == 5: info.text = &quot;Oak Log&quot;

    if block_pick == 6: info.text = &quot;Leaves&quot;

    if block_pick == 7: info.text = &quot;Oak Planks&quot;

    if block_pick == 8: info.text = &quot;Diamond Ore&quot;
    
    if block_pick == 9: info.text = &quot;Coal Ore&quot;

    if block_pick == 10: info.text = &quot;Iron Ore&quot;

    if block_pick == 11: info.text = 'Crafting Table'

    if block_pick == 12: info.text = 'Cobblestone'
    
    if block_pick == 13: info.text = 'Diamond Block'

    if block_pick == 14: info.text = 'Coal Block'

    if block_pick == 15: info.text = 'Iron Block'

    if block_pick == 16: info.text = 'Sand'

    if block_pick == 17: info.text = 'Cactus'

    if block_pick == 18: info.text = 'Water'


    info.x = -0.1
    info.y = 0.46
    info.background = True
    info.visible = True



class Voxel(Button):
    def __init__(self, position = (0,0,0), texture = grass_texture, collision = True):
        super().__init__(
            parent = scene,
            position = position,
            model = 'assets/block',
            origin_y = 0.5,
            texture = texture,
            collision = collision,
            color = color.color(0,0,random.uniform(0.9,1)),
            scale = 0.5)

        voxels.append({
            'x': self.position.x,
            'y': self.position.y,
            'z': self.position.z,
            'position': self.position,
            'texture': texture
        })

    def input(self,key):
        global inventory
        if key == 'b' and inventory: inventory = False
        if self.hovered:
            if key == 'right mouse down':
                punch_sound.play()
                if block_pick == 1: voxel = Voxel(position = self.position + mouse.normal, texture = grass_texture)
                if block_pick == 2: voxel = Voxel(position = self.position + mouse.normal, texture = stone_texture)
                if block_pick == 3: voxel = Voxel(position = self.position + mouse.normal, texture = brick_texture)
                if block_pick == 4: voxel = Voxel(position = self.position + mouse.normal, texture = dirt_texture)
                if block_pick == 5: voxel = Voxel(position = self.position + mouse.normal, texture = log_texture)
                if block_pick == 6: voxel = Voxel(position = self.position + mouse.normal, texture = leaves_texture)
                if block_pick == 7: voxel = Voxel(position = self.position + mouse.normal, texture = oak_planks_texture)
                if block_pick == 8: voxel = Voxel(position = self.position + mouse.normal, texture = diamond_ore_texture)
                if block_pick == 9: voxel = Voxel(position = self.position + mouse.normal, texture = coal_ore_texture)
                if block_pick == 10: voxel = Voxel(position = self.position + mouse.normal, texture = iron_ore_texture)
                if block_pick == 11: voxel = Voxel(position = self.position + mouse.normal, texture = crafting_table_texture)
                if block_pick == 12: voxel = Voxel(position = self.position + mouse.normal, texture = cobblestone_texture)
                if block_pick == 13: voxel = Voxel(position = self.position + mouse.normal, texture = diamond_ore_block_texture)
                if block_pick == 14: voxel = Voxel(position = self.position + mouse.normal, texture = coal_ore_block_texture)
                if block_pick == 15: voxel = Voxel(position = self.position + mouse.normal, texture = iron_ore_block_texture)
                if block_pick == 16: voxel = Voxel(position = self.position + mouse.normal, texture = sand_texture)
                if block_pick == 17: voxel = Voxel(position = self.position + mouse.normal, texture = cactus_texture)
                if block_pick == 18: voxel = Voxel(position = self.position + mouse.normal, texture = water_texture, collision = False)

                index = voxels.index({
                    'x': self.position.x,
                    'y': self.position.y,
                    'z': self.position.z,
                    'position': self.position,
                    'texture': self.texture
                })

                print(voxels[index])

            if key == 'left mouse down':
                punch_sound.play()
                index = voxels.index({
                    'x': self.position.x,
                    'y': self.position.y,
                    'z': self.position.z,
                    'position': self.position,
                    'texture': self.texture
                })

                print(voxels[index])
                del voxels[index]
                destroy(self)

            for i in range(len(voxels)):
                index = voxels.index({
                    'x': self.position.x,
                    'y': self.position.y,
                    'z': self.position.z,
                    'position': self.position,
                    'texture': self.texture
                })
                if self.texture == &quot;water.png&quot; and Vec3(index.x, index.y, index.z) == i.position:

                    print(voxels[index])
                    del voxels[index]
                    destroy(self)

class Sky(Entity):
    def __init__(self):
        super().__init__(
            parent = scene,
            model = 'sphere',
            texture = sky_texture,
            scale = 300,
            double_sided = True)

class Hand(Entity):
    def __init__(self):
        super().__init__(
            parent = camera.ui,
            model = 'assets/arm',
            texture = 'assets/arm_texture',
            scale = 0.2,
            rotation = Vec3(150,-10,0),
            position = Vec2(0.4,-0.6))

    def active(self):
        self.position = Vec2(0.3,-0.5)

    def passive(self):
        self.position = Vec2(0.4,-0.6)

def spawn_chunk(start_chunk, chunks_spawned):
    if random.uniform(0,8) &gt;= 4:
        print(&quot;Chose plains chunks&quot;)
        if random.uniform(0,8) &gt;= 4:
            y = 1
        else:
            y = 0
        for z in range(13 * chunks_spawned):
            for x in range(13 * chunks_spawned):
                voxel = Voxel(position = (x + start_chunk,0 + y,z))
                if random.uniform(0,16) &gt; 15.5:
                    tree_position_x = x + start_chunk
                    tree_position_y = 0 + y + 1
                    tree_position_z = z
                    tree(tree_position_x, tree_position_y, tree_position_z)

        for z in range(13 * chunks_spawned):
            for x in range(13 * chunks_spawned):
                for y in range(-7):
                    voxel = Voxel(position = (x + start_chunk,-2 + y,z), texture = stone_texture)
                    if random.uniform(0,16) &gt; 15.5:
                        tree_position_x = x + start_chunk
                        tree_position_y = 0 + y + 1
                        tree_position_z = z
                        tree(tree_position_x, tree_position_y, tree_position_z)


        for z in range(13 * chunks_spawned):
            for x in range(13 * chunks_spawned):
                for y in range(-7):
                    voxel = Voxel(position = (x + start_chunk,-2 + y,z), texture = stone_texture)
                    if random.uniform(0,16) &gt; 15.5:
                        tree_position_x = x + start_chunk
                        tree_position_y = 0 + y + 1
                        tree_position_z = z
                        tree(tree_position_x, tree_position_y, tree_position_z)

        for z in range(13 * chunks_spawned):
            for x in range(13 * chunks_spawned):
                voxel = Voxel(position = (x,0 + y,z + start_chunk))
                if random.uniform(0,16) &gt; 15.5:
                    tree_position_x = x + start_chunk
                    tree_position_y = 0 + y + 1
                    tree_position_z = z
                    tree(tree_position_x, tree_position_y, tree_position_z)

        for z in range(13 * chunks_spawned):
            for x in range(13 * chunks_spawned):
                for y in range(-2):
                    voxel = Voxel(position = (x,-1 + y,z + start_chunk), texture = dirt_texture)
                    if random.uniform(0,16) &gt; 15.5:
                        tree_position_x = x + start_chunk
                        tree_position_y = 0 + y + 1
                        tree_position_z = z
                        tree(tree_position_x, tree_position_y, tree_position_z)

        for z in range(13 * chunks_spawned):
            for x in range(13 * chunks_spawned):
                for y in range(-7):
                    voxel = Voxel(position = (x,-2 + y,z + start_chunk), texture = stone_texture)
                    if random.uniform(0,16) &gt; 15.5:
                        tree_position_x = x + start_chunk
                        tree_position_y = 0 + y + 1
                        tree_position_z = z
                        tree(tree_position_x, tree_position_y, tree_position_z)

        if random.uniform(0,8) &gt; 4:
            y = 1
        else:
            y = 0
    
        for z in range(13 * chunks_spawned):
            for x in range(13 * chunks_spawned):
                voxel = Voxel(position = (x + start_chunk,0 + y,z + start_chunk))
                if random.uniform(0,16) &gt; 15.5:
                    tree_position_x = x + start_chunk
                    tree_position_y = 0 + y + 1
                    tree_position_z = z
                    tree(tree_position_x, tree_position_y, tree_position_z)

        for z in range(13 * chunks_spawned):
            for x in range(13 * chunks_spawned):
                for y in range(-2):
                    voxel = Voxel(position = (x + start_chunk,-1 + y,z + start_chunk), texture = dirt_texture)
                    if random.uniform(0,16) &gt; 15.5:
                        tree_position_x = x + start_chunk
                        tree_position_y = 0 + y + 1
                        tree_position_z = z
                        tree(tree_position_x, tree_position_y, tree_position_z)

        for z in range(13 * chunks_spawned):
            for x in range(13 * chunks_spawned):
                for y in range(-7):
                    voxel = Voxel(position = (x + start_chunk,-2 + y,z + start_chunk), texture = stone_texture)
                    if random.uniform(0,16) &gt; 15.5:
                        tree_position_x = x + start_chunk
                        tree_position_y = 0 + y + 1
                        tree_position_z = z
                        tree(tree_position_x, tree_position_y, tree_position_z)
    elif random.uniform(0,8) &lt;= 5:
        print(&quot;Chosse desert&quot;)
        if random.uniform(0,8) &gt;= 4:
            y = 1
        else:
            y = 0
        for z in range(13 * chunks_spawned):
            for x in range(13 * chunks_spawned):
                voxel = Voxel(position = (x + start_chunk,0 + y,z), texture = sand_texture)
                if random.uniform(0,16) &gt; 15.5:
                    cactus_position_x = x + start_chunk
                    cactus_position_y = 0 + y + 1
                    cactus_position_z = z
                    cactus(cactus_position_x, cactus_position_y, cactus_position_z)

        for z in range(13 * chunks_spawned):
            for x in range(13 * chunks_spawned):
                voxel = Voxel(position = (x,0 + y,z + start_chunk), texture = sand_texture)
                if random.uniform(0,16) &gt; 15.5:
                    cactus_position_x = x + start_chunk
                    cactus_position_y = 0 + y + 1
                    cactus_position_z = z
                    cactus(cactus_position_x, cactus_position_y, cactus_position_z)

        if random.uniform(0,8) &gt; 4:
            y = 1
        else:
            y = 0
    
        for z in range(13 * chunks_spawned):
            for x in range(13 * chunks_spawned):
                voxel = Voxel(position = (x + start_chunk,0 + y,z + start_chunk), texture = sand_texture)
                if random.uniform(0,16) &gt; 15.5:
                    cactus_position_x = x + start_chunk
                    cactus_position_y = 0 + y + 1
                    cactus_position_z = z
                    cactus(cactus_position_x, cactus_position_y, cactus_position_z)
    else:
        print(&quot;Chosse stone plains&quot;)
        if random.uniform(0,8) &gt;= 4:
            y = 1
        else:
            y = 0
        for z in range(13 * chunks_spawned):
            for x in range(13 * chunks_spawned):
                voxel = Voxel(position = (x + start_chunk,0 + y,z),texture = stone_texture)

        for z in range(13 * chunks_spawned):
            for x in range(13 * chunks_spawned):
                for y in range(-7):
                    voxel = Voxel(position = (x + start_chunk,-2 + y,z), texture = stone_texture)


        for z in range(13 * chunks_spawned):
            for x in range(13 * chunks_spawned):
                for y in range(-7):
                    voxel = Voxel(position = (x + start_chunk,-2 + y,z), texture = stone_texture)

        for z in range(13 * chunks_spawned):
            for x in range(13 * chunks_spawned):
                voxel = Voxel(position = (x,0 + y,z + start_chunk), texture = stone_texture)


        if random.uniform(0,8) &gt; 4:
            y = 1
        else:
            y = 0
    
        for z in range(13 * chunks_spawned):
            for x in range(13 * chunks_spawned):
                voxel = Voxel(position = (x + start_chunk,0 + y,z + start_chunk), texture = stone_texture)

    print(&quot;Spawned chunks&quot;)

def input(key):
    if key == &quot;m&quot;:
        print(&quot;Quit game. Hope you had fun!&quot;)
        exit()

    if key == &quot;x&quot;:
        global start_chunk
        global chunks_spawned
        spawn_chunk(start_chunk, chunks_spawned)
        chunks_spawned += 1
        start_chunk = start_chunk + 11

    if key == &quot;c&quot;:
        cactus(player.x + 2, player.y, player.z + 2)

    if key == &quot;z&quot;:
        tree(player.x + 2, player.y, player.z + 2)

def tree(tree_position_x, tree_position_y, tree_position_z):
    voxel = Voxel(position = (tree_position_x,tree_position_y,tree_position_z), texture = log_texture)
    voxel = Voxel(position = (tree_position_x,tree_position_y + 1,tree_position_z), texture = log_texture)
    voxel = Voxel(position = (tree_position_x,tree_position_y + 2,tree_position_z), texture = log_texture)
    voxel = Voxel(position = (tree_position_x,tree_position_y + 3,tree_position_z), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x + 1,tree_position_y + 3,tree_position_z), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x + 2,tree_position_y + 3,tree_position_z), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x - 1,tree_position_y + 3,tree_position_z), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x - 2,tree_position_y + 3,tree_position_z), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x,tree_position_y + 3,tree_position_z + 1), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x,tree_position_y + 3,tree_position_z + 2), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x + 1,tree_position_y + 3,tree_position_z + 1), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x + 2,tree_position_y + 3,tree_position_z + 2), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x + 2,tree_position_y + 3,tree_position_z + 1), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x + 1,tree_position_y + 3,tree_position_z + 2), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x,tree_position_y + 3,tree_position_z - 1), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x,tree_position_y + 3,tree_position_z - 2), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x + 1,tree_position_y + 3,tree_position_z - 1), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x + 2,tree_position_y + 3,tree_position_z - 2), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x + 2,tree_position_y + 3,tree_position_z - 1), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x + 1,tree_position_y + 3,tree_position_z - 2), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x - 2,tree_position_y + 3,tree_position_z - 1), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x - 1,tree_position_y + 3,tree_position_z - 2), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x - 2,tree_position_y + 3,tree_position_z + 1), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x - 1,tree_position_y + 3,tree_position_z + 2), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x,tree_position_y + 4,tree_position_z), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x + 1,tree_position_y + 4,tree_position_z), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x - 1,tree_position_y + 4,tree_position_z), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x,tree_position_y + 4,tree_position_z + 1), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x,tree_position_y + 4,tree_position_z - 1), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x + 1,tree_position_y + 4,tree_position_z + 1), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x - 1,tree_position_y + 4,tree_position_z + 1), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x + 1,tree_position_y + 4,tree_position_z + 1), texture = leaves_texture)
    voxel = Voxel(position = (tree_position_x + 1,tree_position_y + 4,tree_position_z - 1), texture = leaves_texture)

def cactus(cactus_position_x, cactus_position_y, cactus_position_z):
    voxel = Voxel(position = (cactus_position_x, cactus_position_y, cactus_position_z), texture = cactus_texture)
    cactus_height = int(random.uniform(2, 8))
    for number in range(0, cactus_height):
        voxel = Voxel(position = (cactus_position_x, cactus_position_y + number, cactus_position_z), texture = cactus_texture)

def texture_update():

    grass_texture = load_texture('assets/grass_block.png')
    stone_texture = load_texture('assets/stone_block.png')
    brick_texture = load_texture('assets/brick_block.png')
    dirt_texture = load_texture('assets/dirt_block.png')
    sky_texture  = load_texture('assets/skybox.png')
    arm_texture  = load_texture('assets/arm_texture.png')
    leaves_texture = load_texture('assets/oak_leaves.png')
    log_texture = load_texture('assets/oak_log.png')
    diamond_ore_texture = load_texture('assets/diamond_ore.png')
    coal_ore_texture = load_texture('assets/coal_ore.png')
    iron_ore_texture = load_texture('assets/iron_ore.png')
    diamond_ore_block_texture = load_texture('assets/diamond_block.png')
    coal_ore_block_texture = load_texture('assets/coal_block.png')
    iron_ore_block_texture = load_texture('assets/iron_block.png')
    oak_planks_texture = load_texture('assets/oak_planks.png')
    crafting_table_texture = load_texture('assets/crafting_table.png')
    cobblestone_texture = load_texture('assets/cobblestone.png')
    sand_texture = load_texture('assets/sand.png')
    cactus_texture = load_texture('assets/cactus.png')
    water_texture = load_texture('assets/water.png')



y = 0
    
for z in range(13):
    for x in range(13):
        voxel = Voxel(position = (x,0 + y,z))
        if random.uniform(0,16) &gt; 15.5:
                tree_position_x = x
                tree_position_y = 0 + y + 1
                tree_position_z = z
                tree(tree_position_x, tree_position_y, tree_position_z)


for z in range(13):
    for x in range(13):
        for y in range(2):
            voxel = Voxel(position = (x,-1,z), texture = dirt_texture)


for z in range(13):
    for x in range(13):
        for y in range(7):
            voxel = Voxel(position = (x,-2,z), texture = stone_texture)



block_pick = 1

global inventory
inventory = True

player = FirstPersonController()
sky = Sky()
hand = Hand()

Text.size = 0.05
Text.default_resolution = 1080 * Text.size
info = Text()

texture_update()

chunks_spawned = 1

app.run()
</code></pre>
<p>Important code:</p>
<pre><code>    for i in range(len(voxels)):
        index = voxels.index({
            'x': self.position.x,
            'y': self.position.y,
            'z': self.position.z,
            'position': self.position,
            'texture': self.texture
        })
        if self.texture == &quot;water.png&quot; and Vec3(index.x, index.y, index.z) == i.position:

            print(voxels[index])
            del voxels[index]
            destroy(self)
</code></pre>
",74,1,0,2,python;ursina,2022-06-13 06:50:42,2022-06-13 06:50:42,2022-06-13 20:09:55,i m trying to make a minecraft clone in python using ursina but i have been stuck on one problem when removing water if a block is placed on top of it  collisions are off for water but rest are and i ve been stuck for a long time pls help  i add each block made into an list with all it s data like coords  x  y  z  and remove them from the list when they are deleted  my plan is to compare all the blocks in the list s xyz coords to all the water blocks xyz corrds and if they are the same then the water will be removed and deleted from the list  i ve worked on this for a long time but the problem wont go away  full error message  all my code  important code ,ursina error   assersionerror   is_empty   at line  of panda src pgraph nodepath cxx
203,10865416,55239297,Could not spawn process for application deploying Django on Cpanel,"<p>I'm never done development in a career as a software programmer 
I'm given this domain name on NameCheap with the server disk. Now I design Django app and trying to deploy on the server but I had problems (stated below)</p>

<pre><code>[ E 2019-03-19 06:23:19.7356 598863/T2n age/Cor/App/Implementation.cpp:221 ]: Could not spawn process for application /home/username/IOT: The application process exited prematurely.
App 644163 output:   File ""/home/username/IOT/passenger_wsgi.py"", line 1, in &lt;module&gt;
App 644163 output:   File ""/home/username/virtualenv/IOT/3.7/lib64/python3.7/imp.py"", line 171, in load_source
</code></pre>

<p><strong>edited:</strong> Read more about the software supporting the WSGI is using Phusion Passenger, you could read more here; www.phusionpassenger.com</p>

<p>this is my passenger_wsgi.py:</p>

<pre><code>from myproject.wsgi import application
</code></pre>

<p>I had tried several tutorials:</p>

<ol>
<li><p><a href=""https://www.youtube.com/watch?v=ffqMZ5IcmSY&amp;ab_channel=iFastNetLtd.InternetServices"" rel=""nofollow noreferrer"">https://www.youtube.com/watch?v=ffqMZ5IcmSY&amp;ab_channel=iFastNetLtd.InternetServices</a></p></li>
<li><p><a href=""https://smartlazycoding.com/django-tutorial/deploy-a-django-website-to-a2-hosting"" rel=""nofollow noreferrer"">https://smartlazycoding.com/django-tutorial/deploy-a-django-website-to-a2-hosting</a></p></li>
<li><p><a href=""https://hostpresto.com/community/tutorials/how-to-setup-a-python-django-website-on-hostpresto/"" rel=""nofollow noreferrer"">https://hostpresto.com/community/tutorials/how-to-setup-a-python-django-website-on-hostpresto/</a></p></li>
<li><p><a href=""https://www.helloworldhost.com/knowledgebase/9/Deploy-Django-App-on-cPanel-HelloWorldHost.html"" rel=""nofollow noreferrer"">https://www.helloworldhost.com/knowledgebase/9/Deploy-Django-App-on-cPanel-HelloWorldHost.html</a></p></li>
<li><p><a href=""https://www.helloworldhost.com/knowledgebase/9/Deploy-Django-App-on-cPanel-HelloWorldHost.html"" rel=""nofollow noreferrer"">https://www.helloworldhost.com/knowledgebase/9/Deploy-Django-App-on-cPanel-HelloWorldHost.html</a></p></li>
<li><p><a href=""https://stackoverflow.com/questions/15625151/how-to-install-django-on-cpanel"">how to install django on cpanel</a></p></li>
</ol>

<p>Very much applicate if you could help </p>
",3618,2,2,4,python;django;passenger;host,2019-03-19 12:54:40,2019-03-19 12:54:40,2022-06-13 14:04:13,edited  read more about the software supporting the wsgi is using phusion passenger  you could read more here  www phusionpassenger com this is my passenger_wsgi py  i had tried several tutorials        very much applicate if you could help ,could not spawn process for application deploying django on cpanel
204,13177525,72489354,How can I debug QEMU with one terminal?,"<p>I am working on a moon rover for Carnegie Mellon University which will be launching next year. Specifically, I am working on a flight computer called the ISIS OBC (On Board Computer) and I am trying to find out how to first run QEMU in a terminal in the background, and then run GDB to connect to the QEMU instance I just backgrounded. I have tried running QEMU in the background with <code>&amp;</code> as well as using the flag <code>-daemonize</code> but this causes QEMU's GDB server to not work at all.</p>
<p>The overarching goal is to be able to debug our flight software in GDB in one terminal window so that I can run it from inside a Docker container mounted on the repository's root. It takes a bit of setup to get be able to debug our code, with a couple of gotchas like incompatibility with newer versions of GCC, so being able to run the CODE and debug it from inside a Docker container (which has all our other development dependencies installed too) is a must.</p>
<p>My current solution was to just run QEMU in another gnome-terminal I initialized in the startup script completely outside of the docker container, but this will not work in Docker for obvious reasons. Here is that code in case the additional context is helpful:</p>
<pre><code>#!/bin/bash
#The goal of the below code is to get the stdout from QEMU piped into GDB. 
#Unfourtunately it appears that QEMU must be started as the FG in its own window so that it will 
#start its GDB server, so an additional window is required. 

my_tty=$(tty)
gnome-terminal -- bash -c './../obc-emulation-resources/obc-qemu/iobc-loader -f sdram build/app.isis-obc-rtos.bin -s sdram -o pmc-mclk -- -serial stdio -monitor none -s -S &gt; /tmp/qemu-gdb; $SHELL' --name=&quot;QEMU-iOBC&quot; --title=&quot;QEMU-iOBC&quot; -p
tail -f /tmp/qemu-gdb &gt; $my_tty&amp;
./third_party/gcc-arm-none-eabi-10.3-2021.07/bin/arm-none-eabi-gdb     -ex='target remote localhost:1234'     -ex='symbol-file build/isis-obc-rtos.elf' 

# Kill any leftover qemu debugging sessions
kill $(ps aux | grep '[i]obc-loader' | awk '{print $2}')

# Delete intermediate file
rm -f /tmp/qemu-gdb

# Get's rid of any extra text that may occur
echo &quot;&quot;
clear
</code></pre>
<p>I would much prefer to run something like this to achieve my goal:</p>
<pre><code>./../obc-emulation-resources/obc-qemu/iobc-loader -f sdram build/app.isis-obc-rtos.bin -s sdram -o pmc-mclk -- -serial stdio -monitor none -s -S &gt; /tmp/qemu-gdb
</code></pre>
<p>rather than what I am running now:</p>
<pre><code>gnome-terminal -- bash -c './../obc-emulation-resources/obc-qemu/iobc-loader -f sdram build/app.isis-obc-rtos.bin -s sdram -o pmc-mclk -- -serial stdio -monitor none -s -S &gt; /tmp/qemu-gdb; $SHELL' --name=&quot;QEMU-iOBC&quot; --title=&quot;QEMU-iOBC&quot; -p
</code></pre>
<p>&quot;iobc-loader&quot; is a wrapper used to run the QEMU command by the way.&quot;app.isis-obc-rtos.bin&quot; is of course the binary I am trying to run and &quot;isis-obc-rtos.elf&quot; contains the symbols used to debug it. Apologies if the answer is obvious, I am a student!</p>
",164,2,3,5,c;gdb;embedded;emulation;qemu,2022-06-03 15:08:09,2022-06-03 15:08:09,2022-06-12 16:55:23,i am working on a moon rover for carnegie mellon university which will be launching next year  specifically  i am working on a flight computer called the isis obc  on board computer  and i am trying to find out how to first run qemu in a terminal in the background  and then run gdb to connect to the qemu instance i just backgrounded  i have tried running qemu in the background with  amp  as well as using the flag  daemonize but this causes qemu s gdb server to not work at all  the overarching goal is to be able to debug our flight software in gdb in one terminal window so that i can run it from inside a docker container mounted on the repository s root  it takes a bit of setup to get be able to debug our code  with a couple of gotchas like incompatibility with newer versions of gcc  so being able to run the code and debug it from inside a docker container  which has all our other development dependencies installed too  is a must  my current solution was to just run qemu in another gnome terminal i initialized in the startup script completely outside of the docker container  but this will not work in docker for obvious reasons  here is that code in case the additional context is helpful  i would much prefer to run something like this to achieve my goal  rather than what i am running now   iobc loader  is a wrapper used to run the qemu command by the way  app isis obc rtos bin  is of course the binary i am trying to run and  isis obc rtos elf  contains the symbols used to debug it  apologies if the answer is obvious  i am a student ,how can i debug qemu with one terminal 
205,2224808,19552586,"Using Weblogic 12c, giving warning Warning Log Management BEA-170011 The LogBroadcaster on this server failed to","<p>I am using weblogic 12c server to deploy my web applications. These were running fine but now it has started showing the following warning : - </p>

<pre><code>&lt;Warning&gt; &lt;Log Management&gt; &lt;BEA-170011&gt; 
&lt;The LogBroadcaster on this server failed to broadcast log messages to the Administration Server. 
The Administration Server may not be running. Message broadcasts to the Administration Server will be disabled.&gt; 
</code></pre>

<p>I am not able to see even home page of my web application. Please help me, I am a java programmer having very limited knowledge in weblogic admin. The full stack trace from console is given below: - </p>

<pre><code>.
.
JAVA Memory arguments: -Xms256m -Xmx512m -XX:CompileThreshold=8000 -XX:PermSize=128m  -XX:MaxPermSize=256m
.
WLS Start Mode=Development
.
CLASSPATH=C:\Oracle\MIDDLE~1\WLSERV~1.1/common/lib/antlr-2.7.7.jar;C:\Oracle\MIDDLE~1\patch_wls1211\profiles\default\sys_manifest_classpath\weblogic_patch.jar;C:\Oracle\MIDDLE~1\patch_oepe101\profiles\default\sys_manifest_classpath\weblogic_patch.jar;C:\Oracle\MIDDLE~1\patch_ocp371\profiles\default\sys_manifest_classpath\weblogic_patch.jar;C:\Oracle\MIDDLE~1\JDK160~1\lib\tools.jar;C:\Oracle\MIDDLE~1\WLSERV~1.1\server\lib\weblogic_sp.jar;C:\Oracle\MIDDLE~1\WLSERV~1.1\server\lib\weblogic.jar;C:\Oracle\MIDDLE~1\modules\features\weblogic.server.modules_12.1.1.0.jar;C:\Oracle\MIDDLE~1\WLSERV~1.1\server\lib\webservices.jar;C:\Oracle\MIDDLE~1\modules\ORGAPA~1.1/lib/ant-all.jar;C:\Oracle\MIDDLE~1\modules\NETSFA~1.0_1/lib/ant-contrib.jar;C:\Oracle\MIDDLE~1\WLSERV~1.1\common\derby\lib\derbyclient.jar;C:\Oracle\MIDDLE~1\WLSERV~1.1\server\lib\xqrl.jar
.
PATH=C:\Oracle\MIDDLE~1\patch_wls1211\profiles\default\native;C:\Oracle\MIDDLE~1\patch_oepe101\profiles\default\native;C:\Oracle\MIDDLE~1\patch_ocp371\profiles\default\native;C:\Oracle\MIDDLE~1\WLSERV~1.1\server\native\win\32;C:\Oracle\MIDDLE~1\WLSERV~1.1\server\bin;C:\Oracle\MIDDLE~1\modules\ORGAPA~1.1\bin;C:\Oracle\MIDDLE~1\JDK160~1\jre\bin;C:\Oracle\MIDDLE~1\JDK160~1\bin;C:\Program Files\Common Files\Microsoft Shared\Windows Live;C:\Program Files (x86)\Common Files\Microsoft Shared\Windows Live;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;c:\Program Files\WIDCOMM\Bluetooth Software\;c:\Program Files\WIDCOMM\Bluetooth Software\syswow64;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files (x86)\Common Files\Roxio Shared\OEM\DLLShared\;C:\Program Files (x86)\Common Files\Roxio Shared\OEM\DLLShared\;C:\Program Files (x86)\Common Files\Roxio Shared\OEM\12.0\DLLShared\;C:\Program Files (x86)\Roxio\OEM\AudioCore\;H:\apache-ant-1.8.2\bin;C:\Program Files\TortoiseSVN\bin;G:\Java Latest sw\apache-maven-3.0.3\bin;C:\Oracle\MIDDLE~1\WLSERV~1.1\server\native\win\32\oci920_8
.
***************************************************
*  To start WebLogic Server, use a username and   *
*  password assigned to an admin-level user.  For *
*  server administration, use the WebLogic Server *
*  console at http:\\hostname:port\console        *
***************************************************
starting weblogic with Java version:
Listening for transport dt_socket at address: 8453
java version ""1.6.0_29""
Java(TM) SE Runtime Environment (build 1.6.0_29-b11)
Java HotSpot(TM) Client VM (build 20.4-b02, mixed mode)
Starting WLS with line:
C:\Oracle\MIDDLE~1\JDK160~1\bin\java -client -Xdebug -Xnoagent -Xrunjdwp:transport=dt_socket,address=8453,server=y,suspend=n -Djava.compiler=NONE  -Xms256m -Xmx512m -XX:CompileThreshold=8000 -XX:PermSize=128m  -XX:MaxPermSize=256m -Dweblogic.Name=AdminServer -Djava.security.policy=C:\Oracle\MIDDLE~1\WLSERV~1.1\server\lib\weblogic.policy  -Xverify:none -Djava.endorsed.dirs=C:\Oracle\MIDDLE~1\JDK160~1/jre/lib/endorsed;C:\Oracle\MIDDLE~1\WLSERV~1.1/endorsed  -ea -da:com.bea... -da:javelin... -da:weblogic... -ea:com.bea.wli... -ea:com.bea.broker... -ea:com.bea.sbconsole... -Dplatform.home=C:\Oracle\MIDDLE~1\WLSERV~1.1 -Dwls.home=C:\Oracle\MIDDLE~1\WLSERV~1.1\server -Dweblogic.home=C:\Oracle\MIDDLE~1\WLSERV~1.1\server   -Dweblogic.management.discover=true  -Dwlw.iterativeDev= -Dwlw.testConsole= -Dwlw.logErrorsToConsole= -Dweblogic.ext.dirs=C:\Oracle\MIDDLE~1\patch_wls1211\profiles\default\sysext_manifest_classpath;C:\Oracle\MIDDLE~1\patch_oepe101\profiles\default\sysext_manifest_classpath;C:\Oracle\MIDDLE~1\patch_ocp371\profiles\default\sysext_manifest_classpath  weblogic.Server
Listening for transport dt_socket at address: 8453
&lt;24 Oct, 2013 2:27:58 AM IST&gt; &lt;Info&gt; &lt;Security&gt; &lt;BEA-090905&gt; &lt;Disabling CryptoJ JCE Provider self-integrity check for better startup performance. To enable this check, specify -Dweblogic.security.allowCryptoJDefaultJCEVerification=true&gt; 
&lt;24 Oct, 2013 2:27:58 AM IST&gt; &lt;Info&gt; &lt;Security&gt; &lt;BEA-090906&gt; &lt;Changing the default Random Number Generator in RSA CryptoJ from ECDRBG to FIPS186PRNG. To disable this change, specify -Dweblogic.security.allowCryptoJDefaultPRNG=true&gt; 
&lt;24 Oct, 2013 2:27:58 AM IST&gt; &lt;Info&gt; &lt;WebLogicServer&gt; &lt;BEA-000377&gt; &lt;Starting WebLogic Server with Java HotSpot(TM) Client VM Version 20.4-b02 from Sun Microsystems Inc..&gt; 
&lt;24 Oct, 2013 2:27:59 AM IST&gt; &lt;Info&gt; &lt;Management&gt; &lt;BEA-141107&gt; &lt;Version: WebLogic Server Temporary Patch for 13340309 Thu Feb 16 18:30:21 IST 2012
WebLogic Server Temporary Patch for 13019800 Mon Jan 16 16:53:54 IST 2012
WebLogic Server Temporary Patch for BUG13391585 Thu Feb 02 10:18:36 IST 2012
WebLogic Server Temporary Patch for 13516712 Mon Jan 30 15:09:33 IST 2012
WebLogic Server Temporary Patch for BUG13641115 Tue Jan 31 11:19:13 IST 2012
WebLogic Server Temporary Patch for BUG13603813 Wed Feb 15 19:34:13 IST 2012
WebLogic Server Temporary Patch for 13424251 Mon Jan 30 14:32:34 IST 2012
WebLogic Server Temporary Patch for 13361720 Mon Jan 30 15:24:05 IST 2012
WebLogic Server Temporary Patch for BUG13421471 Wed Feb 01 11:24:18 IST 2012
WebLogic Server Temporary Patch for BUG13657792 Thu Feb 23 12:57:33 IST 2012
WebLogic Server 12.1.1.0  Wed Dec 7 08:40:57 PST 2011 1445491 &gt; 
&lt;24 Oct, 2013 2:28:03 AM IST&gt; &lt;Notice&gt; &lt;WebLogicServer&gt; &lt;BEA-000365&gt; &lt;Server state changed to STARTING.&gt; 
&lt;24 Oct, 2013 2:28:03 AM IST&gt; &lt;Info&gt; &lt;WorkManager&gt; &lt;BEA-002900&gt; &lt;Initializing self-tuning thread pool.&gt; 
&lt;24 Oct, 2013 2:28:03 AM IST&gt; &lt;Notice&gt; &lt;LoggingService&gt; &lt;BEA-320400&gt; &lt;The log file C:\Oracle\Middleware\user_projects\domains\base_domain\servers\AdminServer\logs\AdminServer.log will be rotated. Reopen the log file if tailing has stopped. This can happen on some platforms, such as Windows.&gt; 
&lt;24 Oct, 2013 2:28:03 AM IST&gt; &lt;Notice&gt; &lt;LoggingService&gt; &lt;BEA-320401&gt; &lt;The log file has been rotated to C:\Oracle\Middleware\user_projects\domains\base_domain\servers\AdminServer\logs\AdminServer.log00188. Log messages will continue to be logged in C:\Oracle\Middleware\user_projects\domains\base_domain\servers\AdminServer\logs\AdminServer.log.&gt; 
&lt;24 Oct, 2013 2:28:03 AM IST&gt; &lt;Notice&gt; &lt;Log Management&gt; &lt;BEA-170019&gt; &lt;The server log file C:\Oracle\Middleware\user_projects\domains\base_domain\servers\AdminServer\logs\AdminServer.log is opened. All server side log events will be written to this file.&gt; 
&lt;24 Oct, 2013 2:28:10 AM IST&gt; &lt;Notice&gt; &lt;Security&gt; &lt;BEA-090082&gt; &lt;Security initializing using security realm myrealm.&gt; 
&lt;24 Oct, 2013 2:28:21 AM IST&gt; &lt;Notice&gt; &lt;WebLogicServer&gt; &lt;BEA-000365&gt; &lt;Server state changed to STANDBY.&gt; 
&lt;24 Oct, 2013 2:28:21 AM IST&gt; &lt;Notice&gt; &lt;WebLogicServer&gt; &lt;BEA-000365&gt; &lt;Server state changed to STARTING.&gt; 
&lt;24 Oct, 2013 2:28:28 AM IST&gt; &lt;Notice&gt; &lt;WebLogicServer&gt; &lt;BEA-000365&gt; &lt;Server state changed to ADMIN.&gt; 
&lt;24 Oct, 2013 2:28:31 AM IST&gt; &lt;Notice&gt; &lt;WebLogicServer&gt; &lt;BEA-000365&gt; &lt;Server state changed to RESUMING.&gt; 
&lt;24 Oct, 2013 2:28:31 AM IST&gt; &lt;Warning&gt; &lt;Server&gt; &lt;BEA-002611&gt; &lt;The hostname ""sandeep-PC"", maps to multiple IP addresses: 192.168.1.3, fe80:0:0:0:14c7:40c0:a13:48cf%12, fe80:0:0:0:30:7de:3f57:fefc%22, 2001:0:5ef5:79fb:30:7de:3f57:fefc.&gt; 
&lt;24 Oct, 2013 2:28:31 AM IST&gt; &lt;Notice&gt; &lt;Server&gt; &lt;BEA-002613&gt; &lt;Channel ""Default[3]"" is now listening on fe80:0:0:0:30:7de:3f57:fefc:7001 for protocols iiop, t3, ldap, snmp, http.&gt; 
&lt;24 Oct, 2013 2:28:31 AM IST&gt; &lt;Notice&gt; &lt;Server&gt; &lt;BEA-002613&gt; &lt;Channel ""Default[2]"" is now listening on fe80:0:0:0:0:5efe:c0a8:103:7001 for protocols iiop, t3, ldap, snmp, http.&gt; 
&lt;24 Oct, 2013 2:28:31 AM IST&gt; &lt;Notice&gt; &lt;Server&gt; &lt;BEA-002613&gt; &lt;Channel ""Default[6]"" is now listening on fe80:0:0:0:420:97be:9c27:f48d:7001 for protocols iiop, t3, ldap, snmp, http.&gt; 
&lt;24 Oct, 2013 2:28:31 AM IST&gt; &lt;Notice&gt; &lt;Server&gt; &lt;BEA-002613&gt; &lt;Channel ""Default[4]"" is now listening on fe80:0:0:0:1d35:404c:e9c6:519d:7001 for protocols iiop, t3, ldap, snmp, http.&gt; 
&lt;24 Oct, 2013 2:28:31 AM IST&gt; &lt;Notice&gt; &lt;Server&gt; &lt;BEA-002613&gt; &lt;Channel ""Default[7]"" is now listening on 127.0.0.1:7001 for protocols iiop, t3, ldap, snmp, http.&gt; 
&lt;24 Oct, 2013 2:28:31 AM IST&gt; &lt;Notice&gt; &lt;Server&gt; &lt;BEA-002613&gt; &lt;Channel ""Default[8]"" is now listening on 0:0:0:0:0:0:0:1:7001 for protocols iiop, t3, ldap, snmp, http.&gt; 
&lt;24 Oct, 2013 2:28:31 AM IST&gt; &lt;Notice&gt; &lt;Server&gt; &lt;BEA-002613&gt; &lt;Channel ""Default[1]"" is now listening on 192.168.1.3:7001 for protocols iiop, t3, ldap, snmp, http.&gt; 
&lt;24 Oct, 2013 2:28:31 AM IST&gt; &lt;Notice&gt; &lt;Server&gt; &lt;BEA-002613&gt; &lt;Channel ""Default"" is now listening on 2001:0:5ef5:79fb:30:7de:3f57:fefc:7001 for protocols iiop, t3, ldap, snmp, http.&gt; 
&lt;24 Oct, 2013 2:28:31 AM IST&gt; &lt;Notice&gt; &lt;Server&gt; &lt;BEA-002613&gt; &lt;Channel ""Default[5]"" is now listening on fe80:0:0:0:14c7:40c0:a13:48cf:7001 for protocols iiop, t3, ldap, snmp, http.&gt; 
&lt;24 Oct, 2013 2:28:31 AM IST&gt; &lt;Notice&gt; &lt;WebLogicServer&gt; &lt;BEA-000331&gt; &lt;Started the WebLogic Server Administration Server ""AdminServer"" for domain ""base_domain"" running in development mode.&gt; 
&lt;24 Oct, 2013 2:28:31 AM IST&gt; &lt;Notice&gt; &lt;WebLogicServer&gt; &lt;BEA-000365&gt; &lt;Server state changed to RUNNING.&gt; 
&lt;24 Oct, 2013 2:28:31 AM IST&gt; &lt;Notice&gt; &lt;WebLogicServer&gt; &lt;BEA-000360&gt; &lt;The server started in RUNNING mode.&gt; 
24 Oct, 2013 2:28:32 AM weblogic.wsee.persistence.StoreCleaner &lt;init&gt;
INFO: StoreCLeaner created for &lt;StoreConnection&gt; : storeName = WseeJaxwsFileStore connectionName = weblogic.wsee.reliability2.store.SourceSequenceStore with interval=600000 msecs, maxObjectLifetime=86400000 msecs maxIdleTimeMillis=-1 msecs with disabled = false
24 Oct, 2013 2:28:32 AM weblogic.wsee.persistence.StoreCleaner startCleanup
INFO: StoreCLeaner starting for &lt;StoreConnection&gt; : storeName = WseeJaxwsFileStore connectionName = weblogic.wsee.reliability2.store.SourceSequenceStore with interval=600000 msecs, maxObjectLifetime=86400000 msecs maxIdleTimeMillis=-1 msecs with disabled = false
24 Oct, 2013 2:28:32 AM weblogic.wsee.persistence.StoreCleaner &lt;init&gt;
INFO: StoreCLeaner created for &lt;StoreConnection&gt; : storeName = WseeJaxwsFileStore connectionName = weblogic.wsee.reliability2.store.DestinationSequenceStore with interval=600000 msecs, maxObjectLifetime=86400000 msecs maxIdleTimeMillis=-1 msecs with disabled = false
24 Oct, 2013 2:28:32 AM weblogic.wsee.persistence.StoreCleaner startCleanup
INFO: StoreCLeaner starting for &lt;StoreConnection&gt; : storeName = WseeJaxwsFileStore connectionName = weblogic.wsee.reliability2.store.DestinationSequenceStore with interval=600000 msecs, maxObjectLifetime=86400000 msecs maxIdleTimeMillis=-1 msecs with disabled = false
&lt;24 Oct, 2013 2:28:33 AM IST&gt; &lt;Warning&gt; &lt;Log Management&gt; &lt;BEA-170011&gt; &lt;The LogBroadcaster on this server failed to broadcast log messages to the Administration Server. The Administration Server may not be running. Message broadcasts to the Administration Server will be disabled.&gt; 
</code></pre>
",8908,2,1,3,java;spring;weblogic,2013-10-24 00:24:25,2013-10-24 00:24:25,2022-06-12 12:02:00,i am using weblogic c server to deploy my web applications  these were running fine but now it has started showing the following warning      i am not able to see even home page of my web application  please help me  i am a java programmer having very limited knowledge in weblogic admin  the full stack trace from console is given below    ,using weblogic c  giving warning warning log management bea  the logbroadcaster on this server failed to
206,16380621,72575024,Using a function directly or by declaring it to a variable,"<p>I'm new to software development and trying to understand the basics of JavaScript. In the code below, if I write iterator.next() instead of charAt in &quot;while&quot;, the result changes. Can you explain this to me why does it only return 1 when I type iterator.next directly?</p>
<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>  const str = '123';
  const iterator = str[Symbol.iterator]()

  let charAt = iterator.next()

  while (!charAt.done) {
    console.log(charAt.value)
    charAt = iterator.next()
    // output: ""1""
    //         ""2""
    //         ""3""
  }</code></pre>
</div>
</div>
</p>
<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>  const str = '123';
  const iterator = str[Symbol.iterator]()

  let charAt = iterator.next()

  while (!iterator.next().done) {
    console.log(charAt.value)
    charAt = iterator.next()
    // output: ""1""
  }</code></pre>
</div>
</div>
</p>
",42,2,-1,1,javascript,2022-06-10 16:20:54,2022-06-10 16:20:54,2022-06-10 16:29:52,i m new to software development and trying to understand the basics of javascript  in the code below  if i write iterator next   instead of charat in  while   the result changes  can you explain this to me why does it only return  when i type iterator next directly ,using a function directly or by declaring it to a variable
207,1727056,17300476,Alerts for Machine Pending &amp; Terminated Status in Autosys,"<p>My company is running Autosys r11.1 SP1, as our enterprise job scheduler, and I find the product to serve its purpose fine.  It has a reputation in house at our company as being ""complex"" and ""not easy to use""; I maintain that as a cross-platform enterprise job scheduler, it's certainly going to be complex, and the of course it will take some time and dedication to master the administration of such a system.</p>

<p>I am not part of the team responsible for administration, however my team is the heaviest user of the product as I run our data warehouse team, and I am trying to prepare some counter arguments against what I believe to be false claims about limitations of the product.  I admittedly know that ""Autosys"" is a suite of software, but I am by no means an expert.  I believe that separate from the actual job scheduler, there is an alerts engine, and also a Workload Control Center, of which we have all three pieces installed.</p>

<p>Currently, if an Autosys job hits Max Run Alarm status, an email alert is generated to our help desk and they are able to take the appropriate action.  This, from my understanding of Autosys' internal data model is an ""Event"" which can happen to a job.</p>

<p>This is different from the various statues which a job can belong to, one at a time, of which I know of;</p>

<ol>
<li>Activated</li>
<li>Inactive</li>
<li>Starting</li>
<li>Running</li>
<li>Success</li>
<li>Failure</li>
<li>On Hold</li>
<li>On Ice</li>
<li>Late to Start</li>
<li>Machine Pending</li>
<li>Terminated</li>
</ol>

<p>In addition to the alerts when a job encounters the Max Run event, our help desk also receives an email alert when a job hits a Failure status or Machine Pending status.</p>

<p>I am being told that it is unable to send out an alert if a job hits the Terminated Status?  I just don't believe this. </p>

<p>I am also told that there is no way to filter the job name before sending any sort of alert.  We currently do not have a true development instance of Autosys, so we use naming conventions to differentiate production versus UAT or Test, and as of now email alerts are generated for all, and we face a constant battle with our help desk trying to get them to understand we don't need tickets created for non-production jobs.</p>

<p>Any guidance or education on the true capabilities of this product would be greatly appreciated!</p>

<p>Chris </p>
",7934,2,0,2,ca;autosys,2013-06-25 17:46:22,2013-06-25 17:46:22,2022-06-10 14:03:25,my company is running autosys r  sp  as our enterprise job scheduler  and i find the product to serve its purpose fine   it has a reputation in house at our company as being complex and not easy to use  i maintain that as a cross platform enterprise job scheduler  it s certainly going to be complex  and the of course it will take some time and dedication to master the administration of such a system  i am not part of the team responsible for administration  however my team is the heaviest user of the product as i run our data warehouse team  and i am trying to prepare some counter arguments against what i believe to be false claims about limitations of the product   i admittedly know that autosys is a suite of software  but i am by no means an expert   i believe that separate from the actual job scheduler  there is an alerts engine  and also a workload control center  of which we have all three pieces installed  currently  if an autosys job hits max run alarm status  an email alert is generated to our help desk and they are able to take the appropriate action   this  from my understanding of autosys  internal data model is an event which can happen to a job  this is different from the various statues which a job can belong to  one at a time  of which i know of  in addition to the alerts when a job encounters the max run event  our help desk also receives an email alert when a job hits a failure status or machine pending status  i am being told that it is unable to send out an alert if a job hits the terminated status   i just don t believe this   i am also told that there is no way to filter the job name before sending any sort of alert   we currently do not have a true development instance of autosys  so we use naming conventions to differentiate production versus uat or test  and as of now email alerts are generated for all  and we face a constant battle with our help desk trying to get them to understand we don t need tickets created for non production jobs  any guidance or education on the true capabilities of this product would be greatly appreciated  chris ,alerts for machine pending  amp  terminated status in autosys
208,19307658,72562110,How to find Pause/Play service or characteristic being sent between 2 devices,"<p>This is my very first post on this wonderful forum.  So please pardon my ignorance.  I am trying to develop a hardware with embedded software that can communicate via BLE.  I am trying to make the hardware control an App to play, pause, volume up, or volume down from certain buttons that are on the hardware piece.  However, the App is on a phone (this could be any App, iTunes, YouTube, etc).  But I am not successful in finding the service&gt;characteristic that will help me in sending it from the hardware piece to the App on the phone to control it according the above commands.<br />
This might be a bigger problem that I am not aware, or it could be something minor that I am missing so please any help or advice is greatly appreciated.  I did visit the Bluetooth.com site and went over the specification multiple times, but being new to the BLE software development, its not easy and very straightforward.  So please if anyone can assist with this matter, I will be very thankful.  I am not expecting anyone to spoon feed me the information, but any advice that can get me on the right tracks will help in great deal.</p>
<p>Thanks once again and hope to hear from someone.</p>
<p>Regards.</p>
",23,1,0,3,android;iphone;bluetooth-lowenergy,2022-06-09 17:29:08,2022-06-09 17:29:08,2022-06-09 17:42:53,thanks once again and hope to hear from someone  regards ,how to find pause play service or characteristic being sent between  devices
209,5500096,72561899,Best Practices: How to help customers who must upgrade TLS in registry on Microsoft systems?,"<p>I am helping with development and support for customers who use software products from my employer aimed at Microsoft systems.  These products include several client products that communicate with several server products.  We have had instances where customers must change their client computer registries to work with TLS 1.2, e.g., through <a href=""https://docs.microsoft.com/en-us/mem/configmgr/core/plan-design/security/enable-tls-1-2-client?WT.mc_id=Portal-Microsoft_Azure_Security#bkmk_"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/mem/configmgr/core/plan-design/security/enable-tls-1-2-client?WT.mc_id=Portal-Microsoft_Azure_Security#bkmk_</a>.  Many customers have policies and customs that make them reluctant to touch their registries.</p>
<p>As a practical matter, it takes time and effort for us to diagnose the problem, for us to inform customers of what they need to do, and for customers to get authorization for whoever at the customer's company is allowed to modify registries to do so.  What are good ways to handle this situation?  One idea is for the automated installer (setup) of our client products to offer to modify the client computer's registry for TLS 1.2 (and TLS 1.3 in the future) as part of installation.  Are there other approaches that people have found useful?</p>
",26,0,0,3,ssl;tls1.2;tls1.3,2022-06-09 17:14:59,2022-06-09 17:14:59,2022-06-09 17:24:15,i am helping with development and support for customers who use software products from my employer aimed at microsoft systems   these products include several client products that communicate with several server products   we have had instances where customers must change their client computer registries to work with tls    e g   through    many customers have policies and customs that make them reluctant to touch their registries  as a practical matter  it takes time and effort for us to diagnose the problem  for us to inform customers of what they need to do  and for customers to get authorization for whoever at the customer s company is allowed to modify registries to do so   what are good ways to handle this situation   one idea is for the automated installer  setup  of our client products to offer to modify the client computer s registry for tls    and tls   in the future  as part of installation   are there other approaches that people have found useful ,best practices  how to help customers who must upgrade tls in registry on microsoft systems 
210,1301863,72354824,Restrict outgoing Twilio SMS messages to Verified Caller IDs,"<p>By default, Twilio <strong>trial</strong> accounts can only send SMS to numbers that are listed as <a href=""https://support.twilio.com/hc/en-us/articles/223180048-Adding-a-Verified-Phone-Number-or-Caller-ID-with-Twilio"" rel=""nofollow noreferrer"">Verified Caller IDs</a> in the Twilio console. These numbers have to be added manually, and require a verification message before they can receive SMS. This is an excellent feature for development, as it prevents accidentally sending SMS to wrong numbers.</p>
<p>My problem, is that I am developing for a client whose account is already out of trial status. I don't want the software in development to be able to send text messages to any number, because there is a risk of sending dev messages to the client's actual customers. However, we need to be able to send to <em>some</em> numbers for testing. Is there any way to turn the trial behavior back on? That is, can we somehow configure Twilio to only allow sending SMS to verfied numbers, even if it is not a trial account?</p>
<p>If this isn't possible, I think I can query the <a href=""https://www.twilio.com/docs/voice/api/outgoing-caller-ids#outgoingcallerids-list-resource"" rel=""nofollow noreferrer"">Outgoing Caller IDs</a> resource from my program to verify the recipient number against the list before sending. However, this puts the responsibility back on my development team, and the possibility for mistakes remains. I'd like to be able to block the behavior at the Twilio level.</p>
",95,1,1,2,twilio;twilio-api,2022-05-24 00:06:05,2022-05-24 00:06:05,2022-06-09 03:38:54,by default  twilio trial accounts can only send sms to numbers that are listed as  in the twilio console  these numbers have to be added manually  and require a verification message before they can receive sms  this is an excellent feature for development  as it prevents accidentally sending sms to wrong numbers  my problem  is that i am developing for a client whose account is already out of trial status  i don t want the software in development to be able to send text messages to any number  because there is a risk of sending dev messages to the client s actual customers  however  we need to be able to send to some numbers for testing  is there any way to turn the trial behavior back on  that is  can we somehow configure twilio to only allow sending sms to verfied numbers  even if it is not a trial account  if this isn t possible  i think i can query the  resource from my program to verify the recipient number against the list before sending  however  this puts the responsibility back on my development team  and the possibility for mistakes remains  i d like to be able to block the behavior at the twilio level ,restrict outgoing twilio sms messages to verified caller ids
211,19298143,72545182,Excel - Find text values from a range in different columns,"<p>I have a table with 5 columns which contain several words (&quot;tags&quot;) but they have been pasted into those columns incorrectly (currently there is no way to fix this).</p>
<p><img src=""https://i.stack.imgur.com/qbhDi.png"" alt=""Image with the Table"" /></p>
<p>There are 5 <strong>groups of tags</strong> and what I need to do is to create 5 new columns (for each group of tags) and create a formula which could look in each column and see which tag is contained in those columns/range. As in this example:</p>
<p><img src=""https://i.stack.imgur.com/dPmEu.png"" alt=""Table with new columns"" /></p>
<p>The group of tags are:</p>
<p><img src=""https://i.stack.imgur.com/TN44p.png"" alt=""Tags Groups"" /></p>
<p>How can I do this? I have been trying with the LOOKUP formulas and COUNTIF but I have not been able to do it... I think it is because they only allow you to look up for one value at the time (and not several values from a range (a group of tags)).</p>
<p>Thanks!</p>
<p>Markdown:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>Column 1</th>
<th>Column 2</th>
<th>Column 3</th>
<th>Column 4</th>
<th>Column 5</th>
<th>Group #1</th>
<th>Group #2</th>
<th>Group #3</th>
<th>Group #4</th>
<th>Group #5</th>
</tr>
</thead>
<tbody>
<tr>
<td>my-product</td>
<td>Company University</td>
<td>non billable</td>
<td>Others</td>
<td>product</td>
<td>product</td>
<td>Others</td>
<td>my-product</td>
<td>Company University</td>
<td>non billable</td>
</tr>
<tr>
<td>content</td>
<td>Partner Software KHG</td>
<td>non billable</td>
<td>partner-product</td>
<td>service</td>
<td>service</td>
<td>content</td>
<td>partner-product</td>
<td>Partner Software</td>
<td>non billable</td>
</tr>
<tr>
<td>app-modernization</td>
<td>non billable</td>
<td>partner-product</td>
<td>Pega</td>
<td>service</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>capture</td>
<td>Partner Caption</td>
<td>non billable</td>
<td>partner-product</td>
<td>service</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>my-product</td>
<td>Company University</td>
<td>non billable</td>
<td>Others</td>
<td>product</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>my-product</td>
<td>Company University</td>
<td>non billable</td>
<td>Others</td>
<td>product</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>capture</td>
<td>my-product</td>
<td>non billable</td>
<td>product</td>
<td>PRODCAPTURE</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>app-modernization</td>
<td>non billable</td>
<td>partner-product</td>
<td>SF</td>
<td>service</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>content</td>
<td>Partner Others</td>
<td>non billable</td>
<td>partner-product</td>
<td>service</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>my-product</td>
<td>Company University</td>
<td>non billable</td>
<td>Others</td>
<td>product</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>my-product</td>
<td>non billable</td>
<td>product</td>
<td>PRODSUITE</td>
<td>robotic-automation</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>app-modernization</td>
<td>Hardware</td>
<td>non billable</td>
<td>product</td>
<td>solution</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>capture</td>
<td>my-product</td>
<td>non billable</td>
<td>product</td>
<td>PRODCAPTURE</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>capture</td>
<td>my-product</td>
<td>non billable</td>
<td>product</td>
<td>PRODCAPTURE</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>my-product</td>
<td>non billable</td>
<td>Others</td>
<td>product</td>
<td>PRODSUITE</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>app-modernization</td>
<td>Customer Communications Management (CCM)</td>
<td>non billable</td>
<td>product</td>
<td>solution</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>my-product</td>
<td>Company University</td>
<td>non billable</td>
<td>Others</td>
<td>product</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>my-product</td>
<td>Company University</td>
<td>non billable</td>
<td>Others</td>
<td>product</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>app-modernization</td>
<td>general</td>
<td>non billable</td>
<td>PRODBRE</td>
<td>service</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>content</td>
<td>Partner Software KHG</td>
<td>non billable</td>
<td>partner-product</td>
<td>service</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>my-product</td>
<td>non billable</td>
<td>Others</td>
<td>product</td>
<td>PRODSUITE</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>All</td>
<td>my-product</td>
<td>non billable</td>
<td>product</td>
<td>PRODSUITE</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>capture</td>
<td>my-product</td>
<td>non billable</td>
<td>product</td>
<td>PRODCAPTURE</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>capture</td>
<td>my-product</td>
<td>non billable</td>
<td>product</td>
<td>PRODCAPTURE</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>content</td>
<td>my-product</td>
<td>non billable</td>
<td>product</td>
<td>PRODCASEMAG</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p>GROUPS OF TAGS</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>Group #1</th>
<th></th>
<th>Group #2</th>
<th></th>
<th>Group #3</th>
<th></th>
<th>Group #4</th>
<th></th>
<th>Group #5</th>
</tr>
</thead>
<tbody>
<tr>
<td>product</td>
<td></td>
<td>app-modernization</td>
<td></td>
<td>my-product</td>
<td></td>
<td>advantice</td>
<td></td>
<td>billable</td>
</tr>
<tr>
<td>service</td>
<td></td>
<td>capture</td>
<td></td>
<td>general</td>
<td></td>
<td>Product UYF</td>
<td></td>
<td>non billable</td>
</tr>
<tr>
<td></td>
<td></td>
<td>content</td>
<td></td>
<td>partner add-on product</td>
<td></td>
<td>Cosmos Software</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>Others</td>
<td></td>
<td>partner-product</td>
<td></td>
<td>UI Development</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>robotic-automation</td>
<td></td>
<td>solution</td>
<td></td>
<td>Customer Custom Application</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Hardware</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Other Services</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>HGMD</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p>Group 4 is longer, but I won't paste it all here...</p>
",44,1,1,2,excel;excel-formula,2022-06-08 14:48:14,2022-06-08 14:48:14,2022-06-08 18:31:16,i have a table with  columns which contain several words   tags   but they have been pasted into those columns incorrectly  currently there is no way to fix this    there are  groups of tags and what i need to do is to create  new columns  for each group of tags  and create a formula which could look in each column and see which tag is contained in those columns range  as in this example   the group of tags are   how can i do this  i have been trying with the lookup formulas and countif but i have not been able to do it    i think it is because they only allow you to look up for one value at the time  and not several values from a range  a group of tags    thanks  markdown  groups of tags group  is longer  but i won t paste it all here   ,excel   find text values from a range in different columns
212,12820956,72546563,Android App No Longer Opens In Simulator Despite Successful Build,"<p>I've recently undertaken a task which requires updating a single iOS Onfido SDK module that's being used in an app that is available both on iOS and Android. What was meant to be a simple update snowballed into multiple npm modules for the expo suite and react itself needing updating. This then affected software core to Android such as <strong>Gradle</strong>, <strong>Kotlin</strong>, etc and required numerous further updates.</p>
<p>Thankfully all of the npm modules and software versions for android have been successfully upgrade to the point that there are no further dependancy issues when building, however we (as expected) began getting code errors in the core Android files such as <strong>app/build.gradle</strong>, <strong>/app/../MainActivity.java</strong> and <strong>/app/../MainApplication.java</strong>.</p>
<p>These were resolved by following the instructions at the following link (among others): <a href=""https://github.com/expo/fyi/blob/main/expo-modules-migration.md"" rel=""nofollow noreferrer"">https://github.com/expo/fyi/blob/main/expo-modules-migration.md</a></p>
<p>However I'm now finding that, although the messaging returns 'Successfully Built' when cleaning and rebuilding / running the app simulator, the app doesn't open at all anymore and doesn't appear in the simulator device. The fact there aren't any errors or hints as to where the issue may be makes me think a line is missing somewhere that actually 'installs' the app.</p>
<p>App development is unfortunately not my primary skill set and I inherited the code base from another developer which doesn't help. I've provided the code for the Android files in question below. Any advice would be greatly appreciated.</p>
<p>MainActivity.java</p>
<pre><code>package host.exp.exponent;
import expo.modules.ReactActivityDelegateWrapper;

import android.os.Bundle;

import com.facebook.react.ReactActivity;
import com.facebook.react.ReactActivityDelegate;
import com.facebook.react.ReactRootView;
import com.swmansion.gesturehandler.react.RNGestureHandlerEnabledRootView;

import expo.modules.ReactActivityDelegateWrapper;

import com.facebook.react.modules.core.PermissionAwareActivity;
import com.facebook.react.modules.core.PermissionListener;


public class MainActivity extends ReactActivity implements PermissionAwareActivity {

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(null);
    }

    /**
     * Returns the name of the main component registered from JavaScript.
     * This is used to schedule rendering of the component.
     */
    @Override
    protected String getMainComponentName() {
        return &quot;main&quot;;
    }

    @Override
    protected ReactActivityDelegate createReactActivityDelegate() {
        return new ReactActivityDelegateWrapper(
            this,
            new ReactActivityDelegate(this, getMainComponentName()) {
                @Override
                protected ReactRootView createRootView() {
                    return new RNGestureHandlerEnabledRootView(MainActivity.this);
                }
            }
        );
    }
}
</code></pre>
<p>MainApplication.java</p>
<pre><code>package host.exp.exponent;

import android.app.Application;
import android.content.Context;
import android.content.res.Configuration;
import androidx.annotation.NonNull;

import com.facebook.react.PackageList;
import com.facebook.react.ReactApplication;
import com.facebook.react.ReactInstanceManager;
import com.facebook.react.ReactNativeHost;
import com.facebook.react.ReactPackage;
import com.facebook.soloader.SoLoader;
import com.google.firebase.analytics.FirebaseAnalytics;

import expo.modules.ApplicationLifecycleDispatcher;
import expo.modules.ReactNativeHostWrapper;

import java.lang.reflect.InvocationTargetException;
import java.util.List;

public class MainApplication extends Application implements ReactApplication {
    private FirebaseAnalytics mFirebaseAnalytics;

    private final ReactNativeHost mReactNativeHost = new ReactNativeHostWrapper(
        this,
        new ReactNativeHost(this) {

        @Override
        public boolean getUseDeveloperSupport() {
            return BuildConfig.DEBUG;
        }

        @Override
        protected List&lt;ReactPackage&gt; getPackages() {
            @SuppressWarnings(&quot;UnnecessaryLocalVariable&quot;)
            List&lt;ReactPackage&gt; packages = new PackageList(this).getPackages();

            return packages;
        }

        @Override
        protected String getJSMainModuleName() {
            return &quot;index&quot;;
        }
    });

    @Override
    public ReactNativeHost getReactNativeHost() {
        return mReactNativeHost;
    }

    @Override
    public void onCreate() {
        super.onCreate();
        SoLoader.init(this, /* native exopackage */ false);
        mFirebaseAnalytics = FirebaseAnalytics.getInstance(this);

        initializeFlipper(this, getReactNativeHost().getReactInstanceManager());
        ApplicationLifecycleDispatcher.onApplicationCreate(this);
    }

    @Override
    public void onConfigurationChanged(@NonNull Configuration newConfig) {
        super.onConfigurationChanged(newConfig);
        ApplicationLifecycleDispatcher.onConfigurationChanged(this, newConfig);
    }

    /**
     * Loads Flipper in React Native templates. Call this in the onCreate method with something like
     * initializeFlipper(this, getReactNativeHost().getReactInstanceManager());
     *
     * @param context
     * @param reactInstanceManager
     */
    private static void initializeFlipper(
            Context context, ReactInstanceManager reactInstanceManager) {
        if (BuildConfig.DEBUG) {
            try {
                /*
                 We use reflection here to pick up the class that initializes Flipper,
                since Flipper library is not available in release mode
                */
                Class&lt;?&gt; aClass = Class.forName(&quot;host.exp.exponent.ReactNativeFlipper&quot;);
                aClass
                    .getMethod(&quot;initializeFlipper&quot;, Context.class, ReactInstanceManager.class)
                    .invoke(null, context, reactInstanceManager);
            } catch (ClassNotFoundException e) {
                e.printStackTrace();
            } catch (NoSuchMethodException e) {
                e.printStackTrace();
            } catch (IllegalAccessException e) {
                e.printStackTrace();
            } catch (InvocationTargetException e) {
                e.printStackTrace();
            }
        }
    }
}

</code></pre>
",51,0,0,5,java;react-native;android-studio;expo;simulator,2022-06-08 16:29:57,2022-06-08 16:29:57,2022-06-08 16:29:57,i ve recently undertaken a task which requires updating a single ios onfido sdk module that s being used in an app that is available both on ios and android  what was meant to be a simple update snowballed into multiple npm modules for the expo suite and react itself needing updating  this then affected software core to android such as gradle  kotlin  etc and required numerous further updates  thankfully all of the npm modules and software versions for android have been successfully upgrade to the point that there are no further dependancy issues when building  however we  as expected  began getting code errors in the core android files such as app build gradle   app    mainactivity java and  app    mainapplication java  these were resolved by following the instructions at the following link  among others    however i m now finding that  although the messaging returns  successfully built  when cleaning and rebuilding   running the app simulator  the app doesn t open at all anymore and doesn t appear in the simulator device  the fact there aren t any errors or hints as to where the issue may be makes me think a line is missing somewhere that actually  installs  the app  app development is unfortunately not my primary skill set and i inherited the code base from another developer which doesn t help  i ve provided the code for the android files in question below  any advice would be greatly appreciated  mainactivity java mainapplication java,android app no longer opens in simulator despite successful build
213,13750009,72523639,ARM Cortex M3 - Add a new interrupt to the end of the vector table?,"<p>I am doing some bare metal C development on an ARM Cortex M3 SoC, and I wanted to check and see if it is possible to add a new user-defined interrupt handler to the NVIC. I am adding my own IRQ with the plan of triggering it via software, either via NVIC_SetPendingIRQ() or via the NVIC-&gt;STIR register. Neither seem to work.</p>
<p>I have added my interrupt vector name to the end of the vector list in the CMSIS startup assembler file, and added the corresponding enum to the system header, and while debugging and executing the function call NVIC_EnableIRQ(), it doesn't correctly update the NVIC-&gt;ISER (Interrupt Set Enable Register). So I guess, the question is, can you even add your own interrupt? There are 256 total interrupts than can be used in the ARM Cortex M3, and I just followed how the others were added so I figured it wouldn't be an issue.</p>
<p>Thank you.</p>
",80,2,1,4,arm;embedded;microcontroller;bare-metal,2022-06-07 00:28:00,2022-06-07 00:28:00,2022-06-07 01:15:55,i am doing some bare metal c development on an arm cortex m soc  and i wanted to check and see if it is possible to add a new user defined interrupt handler to the nvic  i am adding my own irq with the plan of triggering it via software  either via nvic_setpendingirq   or via the nvic  gt stir register  neither seem to work  i have added my interrupt vector name to the end of the vector list in the cmsis startup assembler file  and added the corresponding enum to the system header  and while debugging and executing the function call nvic_enableirq    it doesn t correctly update the nvic  gt iser  interrupt set enable register   so i guess  the question is  can you even add your own interrupt  there are  total interrupts than can be used in the arm cortex m  and i just followed how the others were added so i figured it wouldn t be an issue  thank you ,arm cortex m   add a new interrupt to the end of the vector table 
214,656912,36485175,How do I use Conda in on Homebrew Python system?,"<p>I'm using Homebrew as my package general manager, and am using its Python and pip for software development, along with virtualenvs. For various reasons, I'd like to continue with this structure, but I need some software that is (<a href=""https://stackoverflow.com/a/36426774/656912"">apparently</a>) easier to install using Conda.</p>

<p>Can I continue to use Homebrew+pip+virtualev and add Conda into the mix, ideally inside a virtualenv so that it doesn't affect my system as a whole? If so, how do I set up and use Conda in this way?</p>

<hr>

<p>(Python: 2.7.11 (Homebrew); pip: 8.1.1; setuptools: 20.6.7; OS X: 10.11.4 (x86_64))</p>
",30266,3,16,5,python;pip;virtualenv;homebrew;conda,2016-04-07 22:13:34,2016-04-07 22:13:34,2022-06-06 20:46:12,i m using homebrew as my package general manager  and am using its python and pip for software development  along with virtualenvs  for various reasons  i d like to continue with this structure  but i need some software that is    easier to install using conda  can i continue to use homebrew pip virtualev and add conda into the mix  ideally inside a virtualenv so that it doesn t affect my system as a whole  if so  how do i set up and use conda in this way   python      homebrew   pip      setuptools      os x      x_  ,how do i use conda in on homebrew python system 
215,511804,72516783,Code analysis for using `AutoClosable` without &#39;try&#39;-with-resources statement,"<p>Are there code analysis tools to catch cases of using <code>AutoClosable</code> without 'try'-with-resources statement?</p>
<p>Here is an example of the resource and the right and wrong usage of this resource:</p>
<pre><code>public class TestAutoClosable implements AutoCloseable {


  public void someMethod() {}
    

  @Override
  public void close() {}
}

public class TestAutoClosableTest {

  @Test
  public void rightUsage() {
    try (TestAutoClosable tac = new TestAutoClosable()) {
      tac.someMethod();
    }
  }

  @Test
  public void wrongUsage() {
    new TestAutoClosable().someMethod();
  }
    
}
</code></pre>
<p>IntelliJ IDEA highlights invocation of <code>someMethod()</code> without 'try'-with-resources statement.</p>
<p>At the same time <code>findbugs</code> and <code>pmd</code> code analysers, skip this check and do not fail the building process.</p>
<p>I want this kind of analyses not only in the IDE, when I implement logic, but also to make it part of the building process, to make it more reliable.</p>
<p>Are there any exisisting tools like findbugs/pmd for this purpose?
Probably IntelliJ IDEA has its own maven plugins published cause its code analyser is literally great, but limited.</p>
<p><strong>PS:</strong> guys, who requests closing this issue, please leave a comment, why you think this question is not eligable for stackoverflow.</p>
<p>Specially for you, I quote: <a href=""https://stackoverflow.com/help/on-topic"">What topics can I ask about here?</a></p>
<blockquote>
<p>if your question generally covers…</p>
<p>software tools commonly used by programmers; and is</p>
<p>a practical, answerable problem that is unique to software development</p>
<p>…then you’re in the right place to ask your
question!</p>
</blockquote>
<p>This is a question, that should be solved with a software tool, if such exists. It is not a question about what is your favourite tool or something subjective.</p>
",169,0,0,5,java;intellij-idea;code-analysis;findbugs;static-code-analysis,2022-06-06 14:10:38,2022-06-06 14:10:38,2022-06-06 15:37:46,are there code analysis tools to catch cases of using autoclosable without  try  with resources statement  here is an example of the resource and the right and wrong usage of this resource  intellij idea highlights invocation of somemethod   without  try  with resources statement  at the same time findbugs and pmd code analysers  skip this check and do not fail the building process  i want this kind of analyses not only in the ide  when i implement logic  but also to make it part of the building process  to make it more reliable  ps  guys  who requests closing this issue  please leave a comment  why you think this question is not eligable for stackoverflow  specially for you  i quote   if your question generally covers  software tools commonly used by programmers  and is a practical  answerable problem that is unique to software development this is a question  that should be solved with a software tool  if such exists  it is not a question about what is your favourite tool or something subjective ,code analysis for using  autoclosable  without    try    with resources statement
216,11555141,72512096,Error while using GFortran on Mac: &quot;ld: library not found for -lm&quot;,"<p>When running a python &quot;case&quot; file for a computational/simulation program (used in research) via the command line on my MacBook (Big Sur 11.5) <strong>I get the following error:</strong></p>
<pre><code>ld: library not found for -lm
collect2: error: ld returned 1 exit status
</code></pre>
<p><strong>(1) I don't know how to interpret what this means and would love an explanation. (2) I would appreciate input on how to troubleshoot this problem.</strong> Please note the problem is 100% not in my case file or the software. It <em>has</em> to be a problem with how I've set up things on my Mac.</p>
<p>Since my experience with running programs via the command line is limited, and my Fortran experience nonexistent, please don't assume very much prior knowledge on my part. I truly want a &quot;for dummies&quot; explanation.</p>
<p>The program I'm running has several dependencies, which according to the developer are:</p>
<ul>
<li>Python 3</li>
<li>numpy</li>
<li>scipy (only needed for additional utilities, postprocessor)</li>
<li>matplotlib (only needed for additional utilities)</li>
<li>GNU C (gcc/g++) and Fortran (gfortran) compilers (development headers
must be present)</li>
<li>Xcode and developer tools (OpenMPI support requires that
Fortran-compatible libraries be built)</li>
</ul>
<p>I've done my best to install up-to-date versions of all of the above. But honestly, some of the guides and stackoverflow conversations for working through this stuff is totally Greek to me. Particularly this stuff:</p>
<ul>
<li>&quot;Development headers must be present&quot; NO idea at all what that means.</li>
<li>&quot;OpenMPI support requires Fortran-compatible libraries be built&quot; Again, not sure what that directive indicates I need to do.</li>
</ul>
<p>I'm running the following versions of things:</p>
<ul>
<li>GNU Fortran/GCC: Homebrew GCC 11.3.0</li>
<li>Python: 3.9.13</li>
<li>Open MPI: 4.1.4</li>
</ul>
",78,0,0,5,xcode;macos;gcc;fortran;gfortran,2022-06-06 03:56:34,2022-06-06 03:56:34,2022-06-06 03:56:34,when running a python  case  file for a computational simulation program  used in research  via the command line on my macbook  big sur    i get the following error     i don t know how to interpret what this means and would love an explanation     i would appreciate input on how to troubleshoot this problem  please note the problem is   not in my case file or the software  it has to be a problem with how i ve set up things on my mac  since my experience with running programs via the command line is limited  and my fortran experience nonexistent  please don t assume very much prior knowledge on my part  i truly want a  for dummies  explanation  the program i m running has several dependencies  which according to the developer are  i ve done my best to install up to date versions of all of the above  but honestly  some of the guides and stackoverflow conversations for working through this stuff is totally greek to me  particularly this stuff  i m running the following versions of things ,error while using gfortran on mac   ld  library not found for  lm 
217,19276986,72510431,Does Intel Mac can programing material M1 apps?,"<p>First of all, I know that it is better to buy new electronic devices than old ones.</p>
<p>My intention is to learn to program, including but not limited to programming iOS apps, iPad apps, and MacOS programs.</p>
<p>Currently, I'm deciding between a used, old Intel Mac device (because it's cheaper [?]) and an M1 device to choose between.</p>
<p>I don't have development needs such as games, so the GPU may not be important[?] .</p>
<p><strong>I learn from online search engines that Intel Mac compiled iOS programs require Rosetta Translation on M1 devices? Even the universal binaries need Rosetta Translation?</strong></p>
<p>Frontier developers basically have M1 as a development and testing device, and I didn't search for questions about it.</p>
<p><strong>Ultimately, the only question is, M1 devices run mobile app natively, so does this mobile app have to be compiled by M1 devices?</strong></p>
<p>Of course, I know there is a lot of software out there that may not all be adapted to the arm architecture, but I still want my compiled mobile apps to run on the M1 device without Rosetta Translation.</p>
",43,0,0,4,ios;xcode;macos;ipad,2022-06-05 22:17:55,2022-06-05 22:17:55,2022-06-05 22:17:55,first of all  i know that it is better to buy new electronic devices than old ones  my intention is to learn to program  including but not limited to programming ios apps  ipad apps  and macos programs  currently  i m deciding between a used  old intel mac device  because it s cheaper      and an m device to choose between  i don t have development needs such as games  so the gpu may not be important      i learn from online search engines that intel mac compiled ios programs require rosetta translation on m devices  even the universal binaries need rosetta translation  frontier developers basically have m as a development and testing device  and i didn t search for questions about it  ultimately  the only question is  m devices run mobile app natively  so does this mobile app have to be compiled by m devices  of course  i know there is a lot of software out there that may not all be adapted to the arm architecture  but i still want my compiled mobile apps to run on the m device without rosetta translation ,does intel mac can programing material m apps 
218,7699218,72505699,Hamburger toggle button not working is Bootstrap,"<p>I made header using HTML CSS and Bootstrap on localhost and on localhost the toggle button is working fine but when i push this code on wordpress the toggle button stops working. I took every step possible to make it work. I have tried CDNs in many orders, also putted jquery CDN before the bootstrap CDN but nothing works. I also made all necessary changes which is required like converting data-target to data-bs-target but nothing happens. I also followed this post <a href=""https://stackoverflow.com/questions/50635024/bootstrap-4-navbar-toggler-hamburger-is-button-not-working"">Bootstrap 4 navbar toggler hamburger is button not working</a> but is not working for me. Here is the code....</p>
<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;!DOCTYPE html&gt;
&lt;html lang=""en""&gt;
&lt;head&gt;
  &lt;meta charset=""UTF-8""&gt;
  &lt;meta http-equiv=""X-UA-Compatible"" content=""IE=edge""&gt;
  &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1.0""&gt;
  &lt;title&gt;Header&lt;/title&gt;
  &lt;script src=""https://code.jquery.com/jquery-3.2.1.slim.min.js"" integrity=""sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"" crossorigin=""anonymous""&gt;&lt;/script&gt;
  &lt;script src=""https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"" integrity=""sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"" crossorigin=""anonymous""&gt;&lt;/script&gt;
  &lt;script src=""https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"" integrity=""sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"" crossorigin=""anonymous""&gt;&lt;/script&gt;



  &lt;style&gt;
    * {
      padding: 0px;
      margin: 0px;
      box-sizing: border-box;
    }
    
    li {
      color: rgb(108, 108, 189);
    }
    
    .color {
      color: #EE0000;
    }
    
    .bg-color {
      background-color: #ed5353;
    }
    
    .navbar .navbar-brand img {
      background-color: #212529;
    }
    
    #login:hover {
      background-color: #EE0000;
    }
    
    a.nav-item:hover {
      background-color: #EE0000;
      border-radius: 4px;
    }
  &lt;/style&gt;

&lt;/head&gt;

&lt;body&gt;


  &lt;nav class=""navbar navbar-expand-lg navbar-dark bg-dark justify-content-center""&gt;


    &lt;a class=""navbar-brand text-light mx-5"" href=""#""&gt;&lt;img src=""https://ablore.com/wp-content/uploads/2022/05/logo.png"" style=""width: 150px; background-color: #212529;"" alt=""""&gt;&lt;/a&gt;



    &lt;span class=""justify-content-center text-light d-inline d-md-inline d-lg-none"" style=""margin: auto;""&gt;&lt;i
            class=""fa-solid fa-globe fs-4""&gt;&lt;/i&gt;
          English
    
          &lt;button class=""btn btn-dark mx-4 justify-content-center from-center d-inline d-md-inline d-lg-none"" id=""login""
            type=""submit""&gt;Login&lt;/button&gt;&lt;/span&gt;


    &lt;button class=""navbar-toggler"" type=""button"" data-bs-toggle=""collapse"" data-bs-target=""#navbarNavAltMarkup"" aria-controls=""navbarNavAltMarkup"" aria-expanded=""false"" aria-label=""Toggle navigation""&gt;
          &lt;span class=""navbar-toggler-icon""&gt;&lt;/span&gt;
        &lt;/button&gt;
    &lt;div class=""collapse navbar-collapse"" id=""navbarNavAltMarkup""&gt;
      &lt;div class=""navbar-nav""&gt;
        &lt;a class=""nav-item nav-link active text-light"" href=""#""&gt;Home &lt;span class=""sr-only""&gt;(current)&lt;/span&gt;&lt;/a&gt;


        &lt;div class=""dropdown show""&gt;
          &lt;a class="" dropdown-toggle nav-item nav-link text-light"" style=""text-decoration: none;"" href=""#collapseExample"" data-bs-toggle=""collapse""&gt;
            Services
        &lt;/a&gt;

        &lt;/div&gt;

      &lt;/div&gt;















      &lt;a class=""nav-item nav-link text-light from-center"" href=""#""&gt;Portfolio&lt;/a&gt;
      &lt;a class=""nav-item nav-link text-light"" href=""#""&gt;Insights&lt;/a&gt;

      &lt;div class=""container d-flex"" style=""justify-content: end;""&gt;
        &lt;span class="" text-light d-none d-md-none d-lg-inline""&gt;&lt;i class=""fa-solid fa-globe fs-5""&gt;&lt;/i&gt;
              English
    
              &lt;button class=""btn btn-dark mx-4  d-none d-md-none d-lg-inline"" id=""login"" type=""submit""&gt;Login&lt;/button&gt;&lt;/span&gt;
      &lt;/div&gt;
    &lt;/div&gt;


  &lt;/nav&gt;




  &lt;div class=""collapse position-absolute"" id=""collapseExample""&gt;
    &lt;div class=""card card-body""&gt;

      &lt;div class=""container-fluid""&gt;
        &lt;div class=""row""&gt;
          &lt;div class=""col-md-2 col-sm-6""&gt;&lt;span class=""fs-5 fw-bold""&gt; BRANDING
                  &lt;hr&gt;
                &lt;/span&gt;
            &lt;ul&gt;
              &lt;li&gt;Logo Design&lt;/li&gt;
              &lt;li&gt;Website Design&lt;/li&gt;
              &lt;li&gt;E-commerce Graphics&lt;/li&gt;
              &lt;li&gt;Social Media Graphics&lt;/li&gt;
              &lt;li&gt;Ads Graphics&lt;/li&gt;
              &lt;li&gt;Video Ads&lt;/li&gt;
              &lt;li&gt;Company Profile Design&lt;/li&gt;
              &lt;li&gt;Content Writing&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/div&gt;
          &lt;div class=""col-md-2 col-sm-6""&gt;&lt;span class=""fs-5 fw-bold""&gt; PRODUCT DEVELOPMENT
                  &lt;hr&gt;
                &lt;/span&gt;
            &lt;ul&gt;
              &lt;li&gt;SaaS Development&lt;/li&gt;
              &lt;li&gt;Web Portal Development&lt;/li&gt;
              &lt;li&gt;E-commerce Development&lt;/li&gt;
              &lt;li&gt;Mobile Application Development&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/div&gt;
          &lt;div class=""col-md-2 col-sm-6""&gt; &lt;span class=""fs-5 fw-bold""&gt; SALES
                  &lt;hr&gt;
                &lt;/span&gt;
            &lt;ul&gt;
              &lt;li&gt;Sales Process Development&lt;/li&gt;
              &lt;li&gt;Automated Sales Process&lt;/li&gt;
              &lt;li&gt;Sales Team&lt;/li&gt;
              &lt;li&gt;Tele Caller&lt;/li&gt;
              &lt;li&gt;Customer Support Team&lt;/li&gt;
              &lt;li&gt;Sales Software&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/div&gt;
          &lt;div class=""col-md-2 col-sm-6""&gt;&lt;span class=""fs-5 fw-bold""&gt; MARKETING
                  &lt;hr&gt;
                &lt;/span&gt;
            &lt;ul&gt;
              &lt;li&gt;Social Media Management&lt;/li&gt;
              &lt;li&gt;Paid Media Management&lt;/li&gt;
              &lt;li&gt;Email Marketing&lt;/li&gt;
              &lt;li&gt;Content Marketing&lt;/li&gt;
              &lt;li&gt;Search Engine Optimization&lt;/li&gt;
              &lt;li&gt;Bulk SMS Marketing&lt;/li&gt;
              &lt;li&gt;Bulk WhatsApp Marketing&lt;/li&gt;
              &lt;li&gt;Automated Calls&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/div&gt;

          &lt;div class=""col-md-2 col-sm-6""&gt;&lt;span class=""fs-5 fw-bold""&gt; CLOUDS
                  &lt;hr&gt;
                &lt;/span&gt;
            &lt;ul&gt;
              &lt;li&gt;Development Servers&lt;/li&gt;
              &lt;li&gt;Shared CPU&lt;/li&gt;
              &lt;li&gt;Dedicated CPU&lt;/li&gt;
              &lt;li&gt;Intel Servers&lt;/li&gt;
              &lt;li&gt;AMD Servers&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/div&gt;
          &lt;div class=""col-md-2 col-sm-6""&gt;&lt;span class=""fs-5 fw-bold""&gt; IT INFRASTRUCTURE
                  &lt;hr&gt;
                &lt;/span&gt;
            &lt;ul&gt;
              &lt;li&gt;DevOps Engineer&lt;/li&gt;
              &lt;li&gt;IT Support&lt;/li&gt;
              &lt;li&gt;Product Development&lt;/li&gt;
              &lt;li&gt;Project Infrastructure&lt;/li&gt;
              &lt;li&gt;Product Architecture&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/div&gt;
          &lt;div class=""col-md-2 col-sm-6""&gt;&lt;span class=""fs-5 fw-bold""&gt; ERP SOFTWARE
                  &lt;hr&gt;
                &lt;/span&gt;&lt;/div&gt;
          &lt;div class=""col-md-2 col-sm-6""&gt;&lt;span class=""fs-5 fw-bold""&gt; CRM SOFTWARE
                  &lt;hr&gt;
                &lt;/span&gt;&lt;/div&gt;
          &lt;div class=""col-md-2 col-sm-6""&gt;&lt;span class=""fs-5 fw-bold""&gt; REMOTE SOFTWARE
                  &lt;hr&gt;
                &lt;/span&gt;&lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;

  &lt;script src=""https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js""&gt;&lt;/script&gt;
  &lt;script src=""https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js""&gt;&lt;/script&gt;
  &lt;script src=""https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js""&gt;&lt;/script&gt;

&lt;/body&gt;

&lt;/html&gt;</code></pre>
</div>
</div>
</p>
",60,1,0,4,html;css;twitter-bootstrap;togglebutton,2022-06-05 11:00:44,2022-06-05 11:00:44,2022-06-05 22:05:01,i made header using html css and bootstrap on localhost and on localhost the toggle button is working fine but when i push this code on wordpress the toggle button stops working  i took every step possible to make it work  i have tried cdns in many orders  also putted jquery cdn before the bootstrap cdn but nothing works  i also made all necessary changes which is required like converting data target to data bs target but nothing happens  i also followed this post  but is not working for me  here is the code    ,hamburger toggle button not working is bootstrap
219,3794851,72501856,php pdo_pgsql file present but not recognized,"<p>Running a DigitalOcean droplet on Ubuntu (20.4?)</p>
<p>I have userA with root permission. They are also connected to userA within the postgres db.</p>
<p>Due to the setup for the software I'm using, they require a specific username for the postgresdb. Just so I'm not exposing too much data online, we'll call that userB. That's both a linux and postgres user.</p>
<p>I'm running a php command that basically takes (uname, dbname, pdo, options) as input, and it's currently failing bc it can't locate the pdo file.</p>
<p>I've looked through a few posts. One suggested to uncomment all of the pgsql and pdo_pgsql lines in all of the php.ini files, which i've done, both for production, development, and the generic version of that file.</p>
<p>When I run the command as both userA and userB I get this error.</p>
<pre><code>PHP Warning:  PHP Startup: Unable to load dynamic library 'pdo_pgsql' (tried: /usr/lib/php/20190902/pdo_pgsql (/usr/lib/php/20190902/pdo_pgsql: cannot open shared object file: No such file or directory), /usr/lib/php/20190902/pdo_pgsql.so (/usr/lib/php/20190902/pdo_pgsql.so: undefined symbol: pdo_parse_params)) in Unknown on line 0
</code></pre>
<p>However, pdo_pgsql.so actually does exist in that location. (is it looking for a file just named pdo_pgsql and is instead finding pdo_pgsql.so?)</p>
<p>The php site says to run a</p>
<pre><code>./configure
</code></pre>
<p>command, but it doesn't really say which folder configure is in. It's not a package I can install from cli. (<a href=""https://www.php.net/manual/en/ref.pdo-pgsql.php"" rel=""nofollow noreferrer"">https://www.php.net/manual/en/ref.pdo-pgsql.php</a>)</p>
<p>Other pages say you have to install autoconf first (<a href=""https://unix.stackexchange.com/questions/158960/can-not-run-configure-command-no-such-file-or-directory"">https://unix.stackexchange.com/questions/158960/can-not-run-configure-command-no-such-file-or-directory</a>) however that has not made ./configure an available command for me.</p>
<p>I've also found a post saying that a conf file in apache needs to be updated to show the location of the PDO file, however I'm not yet running a server, I'm just running a php file that populates a pgsql db locally. (<a href=""https://stackoverflow.com/questions/45675974/pgsql-extension-is-not-loading"">pgsql extension is not loading</a>)</p>
<p>Running</p>
<pre><code>php -i | grep PDO
</code></pre>
<p>gives</p>
<pre><code>PHP Warning:  PHP Startup: Unable to load dynamic library 'pdo_pgsql' (tried: /usr/lib/php/20190902/pdo_pgsql (/usr/lib/php/20190902/pdo_pgsql: cannot open shared object file: No such file or directory), /usr/lib/php/20190902/pdo_pgsql.so (/usr/lib/php/20190902/pdo_pgsql.so: undefined symbol: pdo_parse_params)) in Unknown on line 0
PDO
PDO support =&gt; enabled
PDO drivers =&gt; pgsql
PDO Driver for PostgreSQL =&gt; enabled
</code></pre>
<p>Though according to customer service from the API it should be returning</p>
<pre><code>PDO
PDO support =&gt; enabled
PDO drivers =&gt; mysql, odbc, pgsql
PDO Driver for MySQL =&gt; enabled
PDO Driver for ODBC (unixODBC) =&gt; enabled
PDO Driver for PostgreSQL =&gt; enabled
</code></pre>
<p>Though I think they're giving multiple examples of different drivers depending on your db software of choice.</p>
<p>I'm not exactly sure what to do.</p>
<p>Update:</p>
<p>I've tried editing the php.ini file that is being used by php via</p>
<pre><code>php -i | grep ini
</code></pre>
<p>I used</p>
<pre><code>locate pdo_pgsql
</code></pre>
<p>to find the pdo_pgsql and pdo_pgsql.so filepaths. I have tried 4 different edits to the php.ini file. 2 being uncommenting (one at a time) the default pgsql extensions. 2 being different filepaths to the pdo_pgsql files that are found on my system through locate.</p>
<pre><code>**extension=/usr/lib/php/20190902/pdo_pgsql.so**

sudo php file.php

PHP Warning:  PHP Startup: Unable to load dynamic library '/usr/lib/php/20190902/pdo_pgsql.so' (tried: /usr/lib/php/20190902/pdo_pgsql.so (/usr/lib/php/20190902/pdo_pgsql.so: **undefined symbol: pdo_parse_params**), /usr/lib/php/20190902//usr/lib/php/20190902/pdo_pgsql.so.so (/usr/lib/php/20190902//usr/lib/php/20190902/pdo_pgsql.so.so: **cannot open shared object file: No such file or directory**)) in Unknown on line 0

**extension=/var/lib/php/modules/7.4/registry/pdo_pgsql**

sudo php file.php

PHP Warning:  PHP Startup: Unable to load dynamic library '/var/lib/php/modules/7.4/registry/pdo_pgsql' (tried: /var/lib/php/modules/7.4/registry/pdo_pgsql (/var/lib/php/modules/7.4/registry/pdo_pgsql: **file too short**), /usr/lib/php/20190902//var/lib/php/modules/7.4/registry/pdo_pgsql.so (/usr/lib/php/20190902//var/lib/php/modules/7.4/registry/pdo_pgsql.so: **cannot open shared object file: No such file or directory)**) in Unknown on line 0
Could not open input file: file.php

**extension=pgsql**

sudo php file.php

**PHP Warning:  Module 'pgsql' already loaded in Unknown on line 0**
Could not open input file: file.php

**extension=pdo_pgsql**

sudo php file.php

PHP Warning:  PHP Startup: Unable to load dynamic library 'pdo_pgsql' (tried: /usr/lib/php/20190902/pdo_pgsql (/usr/lib/php/20190902/pdo_pgsql: **cannot open shared object file: No such file or directory**), /usr/lib/php/20190902/pdo_pgsql.so (/usr/lib/php/20190902/pdo_pgsql.so: **undefined symbol: pdo_parse_params**)) in Unknown on line 0
Could not open input file: file.php
</code></pre>
<p>output as requested by user below</p>
<pre><code>$ php -v
PHP 7.4.3 (cli) (built: Mar  2 2022 15:36:52) ( NTS )
Copyright (c) The PHP Group
Zend Engine v3.4.0, Copyright (c) Zend Technologies
    with Zend OPcache v7.4.3, Copyright (c), by Zend Technologies

$ dpkg -l|grep pgsql
ii  php-pgsql                       2:7.4+75                           all          PostgreSQL module for PHP [default]
ii  php7.4-pgsql                    7.4.3-4ubuntu2.10                  amd64        PostgreSQL module for PHP

$ dpkg -l|grep php
ii  php-common                      2:75                               all          Common files for PHP packages
ii  php-pgsql                       2:7.4+75                           all          PostgreSQL module for PHP [default]
ii  php7.4-cli                      7.4.3-4ubuntu2.10                  amd64        command-line interpreter for the PHP scripting language
ii  php7.4-common                   7.4.3-4ubuntu2.10                  amd64        documentation, examples and common module for PHP
ii  php7.4-json                     7.4.3-4ubuntu2.10                  amd64        JSON module for PHP
ii  php7.4-opcache                  7.4.3-4ubuntu2.10                  amd64        Zend OpCache module for PHP
ii  php7.4-pgsql                    7.4.3-4ubuntu2.10                  amd64        PostgreSQL module for PHP
ii  php7.4-readline                 7.4.3-4ubuntu2.10                  amd64
</code></pre>
",101,1,0,2,php;postgresql,2022-06-04 20:40:01,2022-06-04 20:40:01,2022-06-04 22:29:59,running a digitalocean droplet on ubuntu      i have usera with root permission  they are also connected to usera within the postgres db  due to the setup for the software i m using  they require a specific username for the postgresdb  just so i m not exposing too much data online  we ll call that userb  that s both a linux and postgres user  i m running a php command that basically takes  uname  dbname  pdo  options  as input  and it s currently failing bc it can t locate the pdo file  i ve looked through a few posts  one suggested to uncomment all of the pgsql and pdo_pgsql lines in all of the php ini files  which i ve done  both for production  development  and the generic version of that file  when i run the command as both usera and userb i get this error  however  pdo_pgsql so actually does exist in that location   is it looking for a file just named pdo_pgsql and is instead finding pdo_pgsql so   the php site says to run a command  but it doesn t really say which folder configure is in  it s not a package i can install from cli     other pages say you have to install autoconf first    however that has not made   configure an available command for me  i ve also found a post saying that a conf file in apache needs to be updated to show the location of the pdo file  however i m not yet running a server  i m just running a php file that populates a pgsql db locally     running gives though according to customer service from the api it should be returning though i think they re giving multiple examples of different drivers depending on your db software of choice  i m not exactly sure what to do  update  i ve tried editing the php ini file that is being used by php via i used to find the pdo_pgsql and pdo_pgsql so filepaths  i have tried  different edits to the php ini file   being uncommenting  one at a time  the default pgsql extensions   being different filepaths to the pdo_pgsql files that are found on my system through locate  output as requested by user below,php pdo_pgsql file present but not recognized
220,2403819,72469867,How to make C functions agnostic to data type,"<p>I have been working on a simple library in C to handle arrays, dynamic arrays and linked lists.  As a starting point I have been working on a function to pop a user defined index from an array.  For starters I am working an an integer array and came upon this solution.</p>
<pre><code>int pop_int_array(int *array, int index, int size) {
    int type = sizeof(int);
    if (index &gt;= size) return 0;
    unsigned char *dst = (unsigned char*) array + index + type;
    memmove(dst, dst + type, type * (size - index - 1));
    return 1;
}

int main(int argc, const char * argv[]) {
    int a[5] = {1, 2, 3, 4, 5};
    pop_int_array(a, 2, 5);
    for (int i = 0; i &lt; 4; i++) {
        printf(&quot;%d\n&quot;, a[i]);
    }
}
</code></pre>
<p>This yields the following output as expected</p>
<pre><code>1
2
4
5
</code></pre>
<p>If I wanted to pop a <code>float</code> array, I would need to create a new function titled <code>pop_float_array</code> that copied all of the contents from <code>pop_int_array</code> but instead of using <code>int type = sizeof(int)</code> I would replace it with <code>int type = sizeof(float)</code>, and of course the array data type would be a <code>float</code> instead of an <code>int</code>.  However, this violates a core principle of software development by repeating the same code several times, where each time would be an implementation for a data type.  In order to get around this I re-wrote the function in the following way where the array is declared as a <code>void</code> data type.  In addition I cast the array to a <code>void *</code> in the main program before or during the process of passing it to the function.</p>
<pre><code>int pop_array(void *array, int index, int size, int type) {
    if (index &gt;= size) return 0;
    unsigned char *dst = (unsigned char*) array + index + type;
    memmove(dst, dst + type, type * (size - index - 1));
    return 1;
}

int main(int argc, const char * argv[]) {
    int a[5] = {1, 2, 3, 4, 5};
    pop_array((void *)a, 2, 5);
    for (int i = 0; i &lt; 4; i++) {
        printf(&quot;%d\n&quot;, a[i]);
    }

    float b[5] = {1.1, 2.2, 3.3, 4.4, 5.5};
    pop_array((void *)a, 2, 5);
    for (int i = 0; i &lt; 4; i++) {
        printf(&quot;%f\n&quot;, a[i]);
    }
}
</code></pre>
<p>As expected this yields</p>
<pre><code>1
2
4
5

1.1
2.2
4.4
5.5
</code></pre>
<p>This allows me to only create and maintain one function.  However, this seems so simple that I am surprised it is not a more widely used technique, or at least that I am aware of in my little experience.  Is there some consequence of writing the function this was or casting the array to a <code>void *</code> that I am not seeing, or is this a legitimate way to make a function type agnostic in C?</p>
",49,1,1,4,arrays;c;pointers;type-conversion,2022-06-02 05:04:37,2022-06-02 05:04:37,2022-06-02 05:17:21,i have been working on a simple library in c to handle arrays  dynamic arrays and linked lists   as a starting point i have been working on a function to pop a user defined index from an array   for starters i am working an an integer array and came upon this solution  this yields the following output as expected if i wanted to pop a float array  i would need to create a new function titled pop_float_array that copied all of the contents from pop_int_array but instead of using int type   sizeof int  i would replace it with int type   sizeof float   and of course the array data type would be a float instead of an int   however  this violates a core principle of software development by repeating the same code several times  where each time would be an implementation for a data type   in order to get around this i re wrote the function in the following way where the array is declared as a void data type   in addition i cast the array to a void   in the main program before or during the process of passing it to the function  as expected this yields this allows me to only create and maintain one function   however  this seems so simple that i am surprised it is not a more widely used technique  or at least that i am aware of in my little experience   is there some consequence of writing the function this was or casting the array to a void   that i am not seeing  or is this a legitimate way to make a function type agnostic in c ,how to make c functions agnostic to data type
221,2210206,72400025,Why/When is it needed to hard refresh a webpage in a browser?,"<h2>Background</h2>
<p>While there are many blogs, stackoverflow questions and answers on the <strong><a href=""https://stackoverflow.com/questions/118884/how-to-force-the-browser-to-reload-cached-css-and-javascript-files"">HOW</a></strong> I have not found a single trace of the <strong>WHY</strong>/<strong>WHEN</strong>! And fair enough most people do know about the why but NOT all people.</p>
<h2>Scenarios</h2>
<ul>
<li>You have been going to the same site.</li>
<li>You are a tester and your development team has release a new version of the web app.</li>
<li>You are an entrepreneur and you have release a new version of your web app.
And one of the following is happening to web url you are loading on your browser:</li>
<li>The web app does not load at all.</li>
<li>The web app starts behaving inconsistently all of a sudden.</li>
<li>New random bugs in loading the page occurs.</li>
</ul>
<h2>Analogy</h2>
<p>While there maybe a lot of reasons behind these issues mentioned above such as a bug in the software, or browser incompatibility with a new component, etc. Before you go and do all the relevant actions to debug or resolve those one of the easiest and fastest resolutions is to: <strong>&quot;HARD PAGE REFRESH&quot;</strong>!</p>
<p>But why? (See below)</p>
",128,1,0,5,javascript;css;web-applications;single-page-application;page-refresh,2022-05-27 06:05:30,2022-05-27 06:05:30,2022-06-02 04:24:50,while there are many blogs  stackoverflow questions and answers on the  i have not found a single trace of the why when  and fair enough most people do know about the why but not all people  while there maybe a lot of reasons behind these issues mentioned above such as a bug in the software  or browser incompatibility with a new component  etc  before you go and do all the relevant actions to debug or resolve those one of the easiest and fastest resolutions is to   hard page refresh   but why   see below ,why when is it needed to hard refresh a webpage in a browser 
222,13738523,72463125,Moving from mockist to more classical TDD in Dart/Flutter,"<p>Firstly, please accept my ignorance - I am quite new to software development.</p>
<p>I have been generally creating a layered architecture for my apps, which might look something like:</p>
<ol>
<li>UI or test</li>
<li>Service (Business Logic)</li>
<li>Repository (translates from data provider to the model)</li>
<li>Data provider (pulls from API, database, etc.)</li>
<li>API, database, etc.</li>
</ol>
<p>At the moment, I create mocks to test Service, Repository and Data provider layers and inject the mocks into the layer being tested.</p>
<p>I want to try testing the behaviour at the Service layer, but only mock either the Data provider or even the API layer. I have only ever seen &quot;mockist&quot;[1] approaches to unit testing Dart/Flutter.</p>
<p>Can anyone advise how to design a more classical TDD approach for Flutter/Dart?</p>
<ol>
<li><a href=""https://martinfowler.com/articles/mocksArentStubs.html"" rel=""nofollow noreferrer"">https://martinfowler.com/articles/mocksArentStubs.html</a> and also <a href=""https://youtu.be/vOO3hulIcsY"" rel=""nofollow noreferrer"">https://youtu.be/vOO3hulIcsY</a></li>
</ol>
",56,0,0,4,flutter;unit-testing;dart;tdd,2022-06-01 16:58:52,2022-06-01 16:58:52,2022-06-01 16:58:52,firstly  please accept my ignorance   i am quite new to software development  i have been generally creating a layered architecture for my apps  which might look something like  at the moment  i create mocks to test service  repository and data provider layers and inject the mocks into the layer being tested  i want to try testing the behaviour at the service layer  but only mock either the data provider or even the api layer  i have only ever seen  mockist    approaches to unit testing dart flutter  can anyone advise how to design a more classical tdd approach for flutter dart ,moving from mockist to more classical tdd in dart flutter
223,16758716,72451786,What would be the equivalent of MethodOrderer in Junit 4 for creating custom order for test execution?,"<p>If I am not mistaken, Junit 5 allows creation of custom method orderers so that the order in which test methods are executed can be custom but I could not find something equivalent to this in Junit 4, there seems to be ways to order tests in alphabetical order or using JVM ordering etc. but nothing that allows for custom execution. Is this something possible?</p>
<p><strong>note:</strong> I am aware of the fact that fixing test order is a bad practice however I am looking into this for research, not software development.</p>
",29,1,0,4,java;junit;junit4;junit5,2022-05-31 20:12:21,2022-05-31 20:12:21,2022-05-31 21:08:49,if i am not mistaken  junit  allows creation of custom method orderers so that the order in which test methods are executed can be custom but i could not find something equivalent to this in junit   there seems to be ways to order tests in alphabetical order or using jvm ordering etc  but nothing that allows for custom execution  is this something possible  note  i am aware of the fact that fixing test order is a bad practice however i am looking into this for research  not software development ,what would be the equivalent of methodorderer in junit  for creating custom order for test execution 
224,47725,1058172,.NET and COM (ActiveX) objects perspective,"<p>We are using a software library from a major US manufacturer. For years the library had mainly two interfaces, a bunch of C API DLLs and a collection of <a href=""https://en.wikipedia.org/wiki/ActiveX"" rel=""nofollow noreferrer"">ActiveX</a> controls which encapsulate the DLL functionality. The ActiveX interface worked pretty well back in the old days of <a href=""https://en.wikipedia.org/wiki/Visual_Basic#Timeline"" rel=""nofollow noreferrer"">Visual Basic 6</a>.</p>
<p>Then .NET appeared with its <a href=""https://en.wikipedia.org/wiki/Component_Object_Model"" rel=""nofollow noreferrer"">COM</a> Interop compatibility interface for the now old ActiveX technology. This had a few pitfalls, like dynamic objects never removed (<a href=""https://href=%22http://addressof.com/blog/archive/2004/03/05/474.aspx"" rel=""nofollow noreferrer"">link</a>) or problems when using multi-threaded applications (cross <a href=""https://en.wikipedia.org/wiki/Component_Object_Model#Threading"" rel=""nofollow noreferrer"">apartment</a> calls, etc.).</p>
<p>Now the manufacturer decided to discontinue the ActiveX interface because &quot;of the growing migration from COM (i.e., ActiveX control) to .NET technology within the Windows®
development community&quot;. What is some more information about that?</p>
<p>Are there plans from Microsoft to drop the COM Interop interface in future .NET releases or are there other huge current and future issues I haven't thought about? Or is this more a matter of taste, like buying a new TV because it looks better?</p>
<p>Also, is there is some kind of ActiveX <a href=""http://en.wikipedia.org/wiki/Rapid_application_development"" rel=""nofollow noreferrer"">RAD</a> replacement, where from the user side I drag and drop a control to my form, set all parameters graphically and are almost done with that?</p>
",751,4,0,3,.net;com;activex,2009-06-29 16:06:42,2009-06-29 16:06:42,2022-05-31 17:19:13,we are using a software library from a major us manufacturer  for years the library had mainly two interfaces  a bunch of c api dlls and a collection of  controls which encapsulate the dll functionality  the activex interface worked pretty well back in the old days of   then  net appeared with its  interop compatibility interface for the now old activex technology  this had a few pitfalls  like dynamic objects never removed    or problems when using multi threaded applications  cross  calls  etc    are there plans from microsoft to drop the com interop interface in future  net releases or are there other huge current and future issues i haven t thought about  or is this more a matter of taste  like buying a new tv because it looks better  also  is there is some kind of activex  replacement  where from the user side i drag and drop a control to my form  set all parameters graphically and are almost done with that , net and com  activex  objects perspective
226,1384039,72431735,C-Bindings removed from Apache Geode Native project,"<p>We use the C-Bindings of the Apache Geode Native client (<a href=""https://github.com/apache/geode-native/tree/44abff89f65f9c1bc72f504f3d57800dd1e48cbc/c-bindings"" rel=""nofollow noreferrer"">state at #44abff89f65f</a>) in one of our products. Unfortunately, we have discovered that the bindings have recently been deleted from the project.</p>
<p><a href=""https://issues.apache.org/jira/browse/GEODE-10058"" rel=""nofollow noreferrer"">https://issues.apache.org/jira/browse/GEODE-10058</a></p>
<p>Looking for the reason oft the removal we’ve only found a comment stating that „the c-bindings layer itself are now defunct, as they are being replaced by a pure C# client“. Since we are using the C-bindings in a pure C application, we are now wondering how to proceed. Actually, we were hoping that the C-bindings would be extended even further in future.</p>
<p>Does someone know if the development of the C-Bindings has really stopped or if they are going to be part of a standalone software/Git project?</p>
<p>Thanks!</p>
",22,0,0,3,client;native;geode,2022-05-30 12:00:59,2022-05-30 12:00:59,2022-05-30 12:22:05,we use the c bindings of the apache geode native client    in one of our products  unfortunately  we have discovered that the bindings have recently been deleted from the project   looking for the reason oft the removal we ve only found a comment stating that  the c bindings layer itself are now defunct  as they are being replaced by a pure c  client   since we are using the c bindings in a pure c application  we are now wondering how to proceed  actually  we were hoping that the c bindings would be extended even further in future  does someone know if the development of the c bindings has really stopped or if they are going to be part of a standalone software git project  thanks ,c bindings removed from apache geode native project
227,1410541,72424341,Converting/compiling Python code to readable C,"<p>I'm writing real-time software in C for a specialized hardware target (with its own C compiler).</p>
<p>Up until now I've used Matlab for the algorithm development and then used Matlab's code generation feature to convert the Matlab code to C, at which point i'd integrate the generated code into the real-time software.</p>
<p>But I'd really like to move away from Matlab to Python for the algorithm development, which means i need a way to convert/compile Python code to <strong>human readable and maintainable</strong> C code. So for example, Cython is not an option, since it produces code which is not human readable, let alone maintainable.</p>
<p>Any ideas?</p>
",46,0,0,3,python;c;code-generation,2022-05-29 17:04:54,2022-05-29 17:04:54,2022-05-29 17:21:54,i m writing real time software in c for a specialized hardware target  with its own c compiler   up until now i ve used matlab for the algorithm development and then used matlab s code generation feature to convert the matlab code to c  at which point i d integrate the generated code into the real time software  but i d really like to move away from matlab to python for the algorithm development  which means i need a way to convert compile python code to human readable and maintainable c code  so for example  cython is not an option  since it produces code which is not human readable  let alone maintainable  any ideas ,converting compiling python code to readable c
228,682986,44201271,datatables select - disable few rows for selection,"<p>I have a datatable with select extension and a button to select all rows, and first cell to select/deselect specific row and the problem is that I can't do any action for few rows. </p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>$(document).ready(function() {
    $('#example').DataTable( {
        select: {
            style: 'multi'
        }
    } );
} );</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;script src=""https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js""&gt;&lt;/script&gt;

&lt;link rel=""stylesheet"" type=""text/css"" href=""https://cdn.datatables.net/v/bs-3.3.7/dt-1.10.15/af-2.2.0/b-1.3.1/b-colvis-1.3.1/b-flash-1.3.1/r-2.1.1/se-1.2.2/datatables.min.css""/&gt;
 
&lt;script type=""text/javascript"" src=""https://cdn.datatables.net/v/bs-3.3.7/dt-1.10.15/af-2.2.0/b-1.3.1/b-colvis-1.3.1/b-flash-1.3.1/r-2.1.1/se-1.2.2/datatables.min.js""&gt;&lt;/script&gt;

&lt;table id=""example"" class=""display"" cellspacing=""0"" width=""100%""&gt;
        &lt;thead&gt;
            &lt;tr&gt;
                &lt;th&gt;Name&lt;/th&gt;
                &lt;th&gt;Position&lt;/th&gt;
                &lt;th&gt;Office&lt;/th&gt;
                &lt;th&gt;Age&lt;/th&gt;
                &lt;th&gt;Start date&lt;/th&gt;
                &lt;th&gt;Salary&lt;/th&gt;
            &lt;/tr&gt;
        &lt;/thead&gt;
        &lt;tfoot&gt;
            &lt;tr&gt;
                &lt;th&gt;Name&lt;/th&gt;
                &lt;th&gt;Position&lt;/th&gt;
                &lt;th&gt;Office&lt;/th&gt;
                &lt;th&gt;Age&lt;/th&gt;
                &lt;th&gt;Start date&lt;/th&gt;
                &lt;th&gt;Salary&lt;/th&gt;
            &lt;/tr&gt;
        &lt;/tfoot&gt;
        &lt;tbody&gt;
            &lt;tr&gt;
                &lt;td&gt;Tiger Nixon&lt;/td&gt;
                &lt;td&gt;System Architect&lt;/td&gt;
                &lt;td&gt;Edinburgh&lt;/td&gt;
                &lt;td&gt;61&lt;/td&gt;
                &lt;td&gt;2011/04/25&lt;/td&gt;
                &lt;td&gt;$320,800&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Garrett Winters&lt;/td&gt;
                &lt;td&gt;Accountant&lt;/td&gt;
                &lt;td&gt;Tokyo&lt;/td&gt;
                &lt;td&gt;63&lt;/td&gt;
                &lt;td&gt;2011/07/25&lt;/td&gt;
                &lt;td&gt;$170,750&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Ashton Cox&lt;/td&gt;
                &lt;td&gt;Junior Technical Author&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;66&lt;/td&gt;
                &lt;td&gt;2009/01/12&lt;/td&gt;
                &lt;td&gt;$86,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Cedric Kelly&lt;/td&gt;
                &lt;td&gt;Senior Javascript Developer&lt;/td&gt;
                &lt;td&gt;Edinburgh&lt;/td&gt;
                &lt;td&gt;22&lt;/td&gt;
                &lt;td&gt;2012/03/29&lt;/td&gt;
                &lt;td&gt;$433,060&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Airi Satou&lt;/td&gt;
                &lt;td&gt;Accountant&lt;/td&gt;
                &lt;td&gt;Tokyo&lt;/td&gt;
                &lt;td&gt;33&lt;/td&gt;
                &lt;td&gt;2008/11/28&lt;/td&gt;
                &lt;td&gt;$162,700&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Brielle Williamson&lt;/td&gt;
                &lt;td&gt;Integration Specialist&lt;/td&gt;
                &lt;td&gt;New York&lt;/td&gt;
                &lt;td&gt;61&lt;/td&gt;
                &lt;td&gt;2012/12/02&lt;/td&gt;
                &lt;td&gt;$372,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Herrod Chandler&lt;/td&gt;
                &lt;td&gt;Sales Assistant&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;59&lt;/td&gt;
                &lt;td&gt;2012/08/06&lt;/td&gt;
                &lt;td&gt;$137,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Rhona Davidson&lt;/td&gt;
                &lt;td&gt;Integration Specialist&lt;/td&gt;
                &lt;td&gt;Tokyo&lt;/td&gt;
                &lt;td&gt;55&lt;/td&gt;
                &lt;td&gt;2010/10/14&lt;/td&gt;
                &lt;td&gt;$327,900&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Colleen Hurst&lt;/td&gt;
                &lt;td&gt;Javascript Developer&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;39&lt;/td&gt;
                &lt;td&gt;2009/09/15&lt;/td&gt;
                &lt;td&gt;$205,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Sonya Frost&lt;/td&gt;
                &lt;td&gt;Software Engineer&lt;/td&gt;
                &lt;td&gt;Edinburgh&lt;/td&gt;
                &lt;td&gt;23&lt;/td&gt;
                &lt;td&gt;2008/12/13&lt;/td&gt;
                &lt;td&gt;$103,600&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Jena Gaines&lt;/td&gt;
                &lt;td&gt;Office Manager&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;30&lt;/td&gt;
                &lt;td&gt;2008/12/19&lt;/td&gt;
                &lt;td&gt;$90,560&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Quinn Flynn&lt;/td&gt;
                &lt;td&gt;Support Lead&lt;/td&gt;
                &lt;td&gt;Edinburgh&lt;/td&gt;
                &lt;td&gt;22&lt;/td&gt;
                &lt;td&gt;2013/03/03&lt;/td&gt;
                &lt;td&gt;$342,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Charde Marshall&lt;/td&gt;
                &lt;td&gt;Regional Director&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;36&lt;/td&gt;
                &lt;td&gt;2008/10/16&lt;/td&gt;
                &lt;td&gt;$470,600&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Haley Kennedy&lt;/td&gt;
                &lt;td&gt;Senior Marketing Designer&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;43&lt;/td&gt;
                &lt;td&gt;2012/12/18&lt;/td&gt;
                &lt;td&gt;$313,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Tatyana Fitzpatrick&lt;/td&gt;
                &lt;td&gt;Regional Director&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;19&lt;/td&gt;
                &lt;td&gt;2010/03/17&lt;/td&gt;
                &lt;td&gt;$385,750&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Michael Silva&lt;/td&gt;
                &lt;td&gt;Marketing Designer&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;66&lt;/td&gt;
                &lt;td&gt;2012/11/27&lt;/td&gt;
                &lt;td&gt;$198,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Paul Byrd&lt;/td&gt;
                &lt;td&gt;Chief Financial Officer (CFO)&lt;/td&gt;
                &lt;td&gt;New York&lt;/td&gt;
                &lt;td&gt;64&lt;/td&gt;
                &lt;td&gt;2010/06/09&lt;/td&gt;
                &lt;td&gt;$725,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Gloria Little&lt;/td&gt;
                &lt;td&gt;Systems Administrator&lt;/td&gt;
                &lt;td&gt;New York&lt;/td&gt;
                &lt;td&gt;59&lt;/td&gt;
                &lt;td&gt;2009/04/10&lt;/td&gt;
                &lt;td&gt;$237,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Bradley Greer&lt;/td&gt;
                &lt;td&gt;Software Engineer&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;41&lt;/td&gt;
                &lt;td&gt;2012/10/13&lt;/td&gt;
                &lt;td&gt;$132,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Dai Rios&lt;/td&gt;
                &lt;td&gt;Personnel Lead&lt;/td&gt;
                &lt;td&gt;Edinburgh&lt;/td&gt;
                &lt;td&gt;35&lt;/td&gt;
                &lt;td&gt;2012/09/26&lt;/td&gt;
                &lt;td&gt;$217,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Jenette Caldwell&lt;/td&gt;
                &lt;td&gt;Development Lead&lt;/td&gt;
                &lt;td&gt;New York&lt;/td&gt;
                &lt;td&gt;30&lt;/td&gt;
                &lt;td&gt;2011/09/03&lt;/td&gt;
                &lt;td&gt;$345,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Yuri Berry&lt;/td&gt;
                &lt;td&gt;Chief Marketing Officer (CMO)&lt;/td&gt;
                &lt;td&gt;New York&lt;/td&gt;
                &lt;td&gt;40&lt;/td&gt;
                &lt;td&gt;2009/06/25&lt;/td&gt;
                &lt;td&gt;$675,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Caesar Vance&lt;/td&gt;
                &lt;td&gt;Pre-Sales Support&lt;/td&gt;
                &lt;td&gt;New York&lt;/td&gt;
                &lt;td&gt;21&lt;/td&gt;
                &lt;td&gt;2011/12/12&lt;/td&gt;
                &lt;td&gt;$106,450&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Doris Wilder&lt;/td&gt;
                &lt;td&gt;Sales Assistant&lt;/td&gt;
                &lt;td&gt;Sidney&lt;/td&gt;
                &lt;td&gt;23&lt;/td&gt;
                &lt;td&gt;2010/09/20&lt;/td&gt;
                &lt;td&gt;$85,600&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Angelica Ramos&lt;/td&gt;
                &lt;td&gt;Chief Executive Officer (CEO)&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;47&lt;/td&gt;
                &lt;td&gt;2009/10/09&lt;/td&gt;
                &lt;td&gt;$1,200,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Gavin Joyce&lt;/td&gt;
                &lt;td&gt;Developer&lt;/td&gt;
                &lt;td&gt;Edinburgh&lt;/td&gt;
                &lt;td&gt;42&lt;/td&gt;
                &lt;td&gt;2010/12/22&lt;/td&gt;
                &lt;td&gt;$92,575&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Jennifer Chang&lt;/td&gt;
                &lt;td&gt;Regional Director&lt;/td&gt;
                &lt;td&gt;Singapore&lt;/td&gt;
                &lt;td&gt;28&lt;/td&gt;
                &lt;td&gt;2010/11/14&lt;/td&gt;
                &lt;td&gt;$357,650&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Brenden Wagner&lt;/td&gt;
                &lt;td&gt;Software Engineer&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;28&lt;/td&gt;
                &lt;td&gt;2011/06/07&lt;/td&gt;
                &lt;td&gt;$206,850&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Fiona Green&lt;/td&gt;
                &lt;td&gt;Chief Operating Officer (COO)&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;48&lt;/td&gt;
                &lt;td&gt;2010/03/11&lt;/td&gt;
                &lt;td&gt;$850,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Shou Itou&lt;/td&gt;
                &lt;td&gt;Regional Marketing&lt;/td&gt;
                &lt;td&gt;Tokyo&lt;/td&gt;
                &lt;td&gt;20&lt;/td&gt;
                &lt;td&gt;2011/08/14&lt;/td&gt;
                &lt;td&gt;$163,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Michelle House&lt;/td&gt;
                &lt;td&gt;Integration Specialist&lt;/td&gt;
                &lt;td&gt;Sidney&lt;/td&gt;
                &lt;td&gt;37&lt;/td&gt;
                &lt;td&gt;2011/06/02&lt;/td&gt;
                &lt;td&gt;$95,400&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Suki Burks&lt;/td&gt;
                &lt;td&gt;Developer&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;53&lt;/td&gt;
                &lt;td&gt;2009/10/22&lt;/td&gt;
                &lt;td&gt;$114,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Prescott Bartlett&lt;/td&gt;
                &lt;td&gt;Technical Author&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;27&lt;/td&gt;
                &lt;td&gt;2011/05/07&lt;/td&gt;
                &lt;td&gt;$145,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Gavin Cortez&lt;/td&gt;
                &lt;td&gt;Team Leader&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;22&lt;/td&gt;
                &lt;td&gt;2008/10/26&lt;/td&gt;
                &lt;td&gt;$235,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Martena Mccray&lt;/td&gt;
                &lt;td&gt;Post-Sales support&lt;/td&gt;
                &lt;td&gt;Edinburgh&lt;/td&gt;
                &lt;td&gt;46&lt;/td&gt;
                &lt;td&gt;2011/03/09&lt;/td&gt;
                &lt;td&gt;$324,050&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Unity Butler&lt;/td&gt;
                &lt;td&gt;Marketing Designer&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;47&lt;/td&gt;
                &lt;td&gt;2009/12/09&lt;/td&gt;
                &lt;td&gt;$85,675&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Howard Hatfield&lt;/td&gt;
                &lt;td&gt;Office Manager&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;51&lt;/td&gt;
                &lt;td&gt;2008/12/16&lt;/td&gt;
                &lt;td&gt;$164,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Hope Fuentes&lt;/td&gt;
                &lt;td&gt;Secretary&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;41&lt;/td&gt;
                &lt;td&gt;2010/02/12&lt;/td&gt;
                &lt;td&gt;$109,850&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Vivian Harrell&lt;/td&gt;
                &lt;td&gt;Financial Controller&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;62&lt;/td&gt;
                &lt;td&gt;2009/02/14&lt;/td&gt;
                &lt;td&gt;$452,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Timothy Mooney&lt;/td&gt;
                &lt;td&gt;Office Manager&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;37&lt;/td&gt;
                &lt;td&gt;2008/12/11&lt;/td&gt;
                &lt;td&gt;$136,200&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Jackson Bradshaw&lt;/td&gt;
                &lt;td&gt;Director&lt;/td&gt;
                &lt;td&gt;New York&lt;/td&gt;
                &lt;td&gt;65&lt;/td&gt;
                &lt;td&gt;2008/09/26&lt;/td&gt;
                &lt;td&gt;$645,750&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Olivia Liang&lt;/td&gt;
                &lt;td&gt;Support Engineer&lt;/td&gt;
                &lt;td&gt;Singapore&lt;/td&gt;
                &lt;td&gt;64&lt;/td&gt;
                &lt;td&gt;2011/02/03&lt;/td&gt;
                &lt;td&gt;$234,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Bruno Nash&lt;/td&gt;
                &lt;td&gt;Software Engineer&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;38&lt;/td&gt;
                &lt;td&gt;2011/05/03&lt;/td&gt;
                &lt;td&gt;$163,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Sakura Yamamoto&lt;/td&gt;
                &lt;td&gt;Support Engineer&lt;/td&gt;
                &lt;td&gt;Tokyo&lt;/td&gt;
                &lt;td&gt;37&lt;/td&gt;
                &lt;td&gt;2009/08/19&lt;/td&gt;
                &lt;td&gt;$139,575&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Thor Walton&lt;/td&gt;
                &lt;td&gt;Developer&lt;/td&gt;
                &lt;td&gt;New York&lt;/td&gt;
                &lt;td&gt;61&lt;/td&gt;
                &lt;td&gt;2013/08/11&lt;/td&gt;
                &lt;td&gt;$98,540&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Finn Camacho&lt;/td&gt;
                &lt;td&gt;Support Engineer&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;47&lt;/td&gt;
                &lt;td&gt;2009/07/07&lt;/td&gt;
                &lt;td&gt;$87,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Serge Baldwin&lt;/td&gt;
                &lt;td&gt;Data Coordinator&lt;/td&gt;
                &lt;td&gt;Singapore&lt;/td&gt;
                &lt;td&gt;64&lt;/td&gt;
                &lt;td&gt;2012/04/09&lt;/td&gt;
                &lt;td&gt;$138,575&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Zenaida Frank&lt;/td&gt;
                &lt;td&gt;Software Engineer&lt;/td&gt;
                &lt;td&gt;New York&lt;/td&gt;
                &lt;td&gt;63&lt;/td&gt;
                &lt;td&gt;2010/01/04&lt;/td&gt;
                &lt;td&gt;$125,250&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Zorita Serrano&lt;/td&gt;
                &lt;td&gt;Software Engineer&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;56&lt;/td&gt;
                &lt;td&gt;2012/06/01&lt;/td&gt;
                &lt;td&gt;$115,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Jennifer Acosta&lt;/td&gt;
                &lt;td&gt;Junior Javascript Developer&lt;/td&gt;
                &lt;td&gt;Edinburgh&lt;/td&gt;
                &lt;td&gt;43&lt;/td&gt;
                &lt;td&gt;2013/02/01&lt;/td&gt;
                &lt;td&gt;$75,650&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Cara Stevens&lt;/td&gt;
                &lt;td&gt;Sales Assistant&lt;/td&gt;
                &lt;td&gt;New York&lt;/td&gt;
                &lt;td&gt;46&lt;/td&gt;
                &lt;td&gt;2011/12/06&lt;/td&gt;
                &lt;td&gt;$145,600&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Hermione Butler&lt;/td&gt;
                &lt;td&gt;Regional Director&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;47&lt;/td&gt;
                &lt;td&gt;2011/03/21&lt;/td&gt;
                &lt;td&gt;$356,250&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Lael Greer&lt;/td&gt;
                &lt;td&gt;Systems Administrator&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;21&lt;/td&gt;
                &lt;td&gt;2009/02/27&lt;/td&gt;
                &lt;td&gt;$103,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Jonas Alexander&lt;/td&gt;
                &lt;td&gt;Developer&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;30&lt;/td&gt;
                &lt;td&gt;2010/07/14&lt;/td&gt;
                &lt;td&gt;$86,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Shad Decker&lt;/td&gt;
                &lt;td&gt;Regional Director&lt;/td&gt;
                &lt;td&gt;Edinburgh&lt;/td&gt;
                &lt;td&gt;51&lt;/td&gt;
                &lt;td&gt;2008/11/13&lt;/td&gt;
                &lt;td&gt;$183,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Michael Bruce&lt;/td&gt;
                &lt;td&gt;Javascript Developer&lt;/td&gt;
                &lt;td&gt;Singapore&lt;/td&gt;
                &lt;td&gt;29&lt;/td&gt;
                &lt;td&gt;2011/06/27&lt;/td&gt;
                &lt;td&gt;$183,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Donna Snider&lt;/td&gt;
                &lt;td&gt;Customer Support&lt;/td&gt;
                &lt;td&gt;New York&lt;/td&gt;
                &lt;td&gt;27&lt;/td&gt;
                &lt;td&gt;2011/01/25&lt;/td&gt;
                &lt;td&gt;$112,000&lt;/td&gt;
            &lt;/tr&gt;
        &lt;/tbody&gt;
    &lt;/table&gt;</code></pre>
</div>
</div>
</p>

<p>Can anybody tell me how to disable row selection for row based on cell data? </p>

<p>Thanks a lot.</p>
",15210,4,5,4,javascript;jquery;datatables;frontend,2017-05-26 15:10:09,2017-05-26 15:10:09,2022-05-29 09:03:13,i have a datatable with select extension and a button to select all rows  and first cell to select deselect specific row and the problem is that i can t do any action for few rows   can anybody tell me how to disable row selection for row based on cell data   thanks a lot ,datatables select   disable few rows for selection
229,7713770,72303767,starting devcontainer contains errors,"<p>I vs code I have a devcontainer. And de containers are running. But if I try to do remote-cointainers%:Rebuild container.</p>
<p>Then I get this errors:</p>
<pre><code>ERROR: Encountered errors while bringing up the project.
[17212 ms] Error: Command failed: docker-compose --project-name webscraper_devcontainer -f c:\xampp\htdocs\webScraper\.devcontainer\docker-compose.yml -f c:\Users\engel\AppData\Roaming\Code\User\globalStorage\ms-vscode-remote.remote-containers\data\docker-compose\docker-compose.devcontainer.containerFeatures-1652959425107.yml up -d
[17212 ms]     at CR (c:\Users\engel\.vscode\extensions\ms-vscode-remote.remote-containers-0.234.0\dist\spec-node\devContainersSpecCLI.js:187:618)
[17212 ms]     at processTicksAndRejections (node:internal/process/task_queues:96:5)
[17212 ms]     at async ER (c:\Users\engel\.vscode\extensions\ms-vscode-remote.remote-containers-0.234.0\dist\spec-node\devContainersSpecCLI.js:183:2075)
[17212 ms]     at async $R (c:\Users\engel\.vscode\extensions\ms-vscode-remote.remote-containers-0.234.0\dist\spec-node\devContainersSpecCLI.js:226:2178)
[17213 ms]     at async Zy (c:\Users\engel\.vscode\extensions\ms-vscode-remote.remote-containers-0.234.0\dist\spec-node\devContainersSpecCLI.js:226:3112)
[17213 ms]     at async BR (c:\Users\engel\.vscode\extensions\ms-vscode-remote.remote-containers-0.234.0\dist\spec-node\devContainersSpecCLI.js:226:12448)
[17213 ms]     at async qR (c:\Users\engel\.vscode\extensions\ms-vscode-remote.remote-containers-0.234.0\dist\spec-node\devContainersSpecCLI.js:226:12204)
[17224 ms] Exit code 1
[17227 ms] Command failed: C:\Users\engel\AppData\Local\Programs\Microsoft VS Code\Code.exe c:\Users\engel\.vscode\extensions\ms-vscode-remote.remote-containers-0.234.0\dist\spec-node\devContainersSpecCLI.js up --user-data-folder c:\Users\engel\AppData\Roaming\Code\User\globalStorage\ms-vscode-remote.remote-containers\data --container-data-folder .vscode-server/data/Machine --container-system-data-folder /var/vscode-server --workspace-folder c:\xampp\htdocs\webScraper --workspace-mount-consistency cached --id-label vsch.local.folder=c:\xampp\htdocs\webScraper --id-label vsch.quality=stable --log-level debug --log-format json --config c:\xampp\htdocs\webScraper\.devcontainer\devcontainer.json --default-user-env-probe loginInteractiveShell --remove-existing-container --mount type=volume,source=vscode,target=/vscode,external=true --skip-post-create --update-remote-user-uid-default on --mount-workspace-git-root true
[17227 ms] Exit code 1
</code></pre>
<p>And this is how my dockerfile looks like:</p>
<pre><code>FROM php:8.1-apache as dev

ENV DEBIAN_FRONTEND=noninteractive
ENV APP_ENV=development

WORKDIR /var/www/html

RUN apt-get update \
  &amp;&amp; apt-get -y install --no-install-recommends apt-utils zip unzip nano ncdu 2&gt;&amp;1 \
    &amp;&amp; apt-get -y install --no-install-recommends python graphviz 2&gt;&amp;1 \
  &amp;&amp; apt-get -y install git iproute2 procps lsb-release \
  &amp;&amp; apt-get install -y -qq software-properties-common \
  &amp;&amp; apt-get install -y -qq wget git lynx ack-grep \
  &amp;&amp; yes | pecl install xdebug \
  &amp;&amp; echo &quot;zend_extension=$(find /usr/local/lib/php/extensions/ -name xdebug.so)&quot; &gt; /usr/local/etc/php/conf.d/xdebug.ini \
    &amp;&amp; apt-get -y install libicu-dev \
    &amp;&amp; docker-php-ext-install intl pdo_mysql opcache \
    &amp;&amp; pecl install apcu &amp;&amp; docker-php-ext-enable apcu \
    &amp;&amp; echo &quot;apc.enable_cli=1&quot; &gt; /usr/local/etc/php/php.ini \
    &amp;&amp; echo &quot;apc.enable=1&quot; &gt; /usr/local/etc/php/php.ini \
  &amp;&amp; echo &quot;post_max_size = 100M&quot; &gt; /usr/local/etc/php/php.ini \
    &amp;&amp; a2enmod rewrite \
  &amp;&amp; apt-get autoremove -y \
  &amp;&amp; apt-get clean -y \
  &amp;&amp; rm -rf /var/lib/apt/lists/*

RUN apt-get update &amp;&amp; apt-get install gnupg2 -y

RUN rm -rf /etc/apache2/sites-enabled \
    &amp;&amp; ln -s /var/www/html/.devcontainer/sites-enabled /etc/apache2/sites-enabled

RUN echo 'alias ll=&quot;ls -la --color=auto&quot;' &gt;&gt; ~/.bashrc &amp;&amp; \
    echo &quot;alias ack='ack-grep'&quot; &gt;&gt; ~/.bashrc

RUN chown www-data:www-data -R ./

ENV DEBIAN_FRONTEND=dialog



</code></pre>
<p>and my docker-compose.yml:</p>
<pre><code>version: '3'
services:
  web:
    container_name: dockeryii
    build:
      context: ..
      dockerfile: dockerfile
      target: dev
    volumes:
      - ../:/var/www/html       
    command: /bin/sh -c &quot;service apache2 start &amp;&amp; while sleep 1000; do :; done&quot;
  db:
    container_name: dockeryiimysql
    image: mysql:latest
    volumes:
      - dockeryiimysql:/var/lib/mysql
    expose:
      - 3306
    environment:
      MYSQL_ALLOW_EMPTY_PASSWORD: 'true'
      MYSQL_DATABASE: sdi      
  phpmyadmin:  
    container_name: dockeryiipma
    image: phpmyadmin:latest
    environment:
      UPLOAD_LIMIT: 300M
      PMA_ARBITRARY: 1
      APACHE_HTTP_PORT_NUMBER: 8080
    ports:
      - 8080:8080
    command: /bin/bash -c &quot;sed -i \&quot;s/80/$$APACHE_HTTP_PORT_NUMBER/g\&quot; /etc/apache2/sites-available/000-default.conf /etc/apache2/ports.conf &amp;&amp; /docker-entrypoint.sh apache2-foreground&quot;

volumes:
  dockeryiimysql: {}
</code></pre>
<p>and my  devcontainer.json:</p>
<pre><code>{
  &quot;name&quot;: &quot;Dockeryii&quot;,
  &quot;dockerComposeFile&quot;: [&quot;docker-compose.yml&quot;],
  &quot;service&quot;: &quot;web&quot;,
  &quot;shutdownAction&quot;: &quot;none&quot;,
  &quot;extensions&quot;: [&quot;felixfbecker.php-debug&quot;,
        &quot;zobo.php-intellisense&quot;,
        &quot;mrmlnc.vscode-apache&quot;],
  &quot;forwardPorts&quot;: [80],
  &quot;workspaceFolder&quot;: &quot;/var/www/html&quot;,
  &quot;settings&quot;: { 
        &quot;php.validate.executablePath&quot;: &quot;/usr/local/bin/php&quot;
    }
}
</code></pre>
<p>So my question is: What I have to change?</p>
<p>Thank you</p>
<p>if I do this:</p>
<pre><code>docker-compose -f C:\xampp\htdocs\webScraper\.devcontainer\docker-compose.yml config
</code></pre>
<p>I just get the output of de file: docker-compose.yml.</p>
",690,2,0,3,docker;docker-compose;vscode-devcontainer,2022-05-19 14:30:42,2022-05-19 14:30:42,2022-05-29 02:57:48,i vs code i have a devcontainer  and de containers are running  but if i try to do remote cointainers  rebuild container  then i get this errors  and this is how my dockerfile looks like  and my docker compose yml  and my  devcontainer json  so my question is  what i have to change  thank you if i do this  i just get the output of de file  docker compose yml ,starting devcontainer contains errors
230,19404,933460,Unique hardware ID in Mac OS X,"<p>Mac OS X development is a fairly new animal for me, and I'm in the process of porting over some software. For software licensing and registration I need to be able to generate some kind of hardware ID. It doesn't have to be anything fancy; Ethernet MAC address, hard drive serial, CPU serial, something like that.</p>

<p>I've got it covered on Windows, but I haven't a clue on Mac. Any idea of what I need to do, or where I can go for information on this would be great! </p>

<p>Edit:</p>

<p>For anybody else that is interested in this, this is the code I ended up using with Qt's QProcess class:</p>

<pre><code>QProcess proc;

QStringList args;
args &lt;&lt; ""-c"" &lt;&lt; ""ioreg -rd1 -c IOPlatformExpertDevice |  awk '/IOPlatformUUID/ { print $3; }'"";
proc.start( ""/bin/bash"", args );
proc.waitForFinished();

QString uID = proc.readAll();
</code></pre>

<p>Note: I'm using C++.</p>
",29801,8,32,4,c++;macos;unique;hardware-id,2009-06-01 06:32:36,2009-06-01 06:32:36,2022-05-28 22:01:59,mac os x development is a fairly new animal for me  and i m in the process of porting over some software  for software licensing and registration i need to be able to generate some kind of hardware id  it doesn t have to be anything fancy  ethernet mac address  hard drive serial  cpu serial  something like that  i ve got it covered on windows  but i haven t a clue on mac  any idea of what i need to do  or where i can go for information on this would be great   edit  for anybody else that is interested in this  this is the code i ended up using with qt s qprocess class  note  i m using c   ,unique hardware id in mac os x
231,8921605,57643853,Using Vimwiki to embed images to a wiki that needs to be transferable between systems,"<p>I am building an internal project wiki for a group software development project. The project wiki is currently powered by VimWiki and I send the HTML files to both the project supervisor and each of the development team on a weekly basis. This keeps our Intellectual property secure and internal, but also organized and up to date. I would like to put diagram images into the wiki itself so that all diagrams and documentation can be accessed together with ease. I am however having trouble making the images transferable between systems. Does vimwiki give a way for image files to be embedded such that they can be transferred between systems? Ideally the solution would make it possible to transfer the output directory of the Vimwiki as a singular entity containing the HTML files and the image files.</p>

<p>I have tried reading the documentation on images in the vimwiki reference document. I have not had luck using local: or file: variants. The wiki reference states that local should convert the image links to a localized location based on the output directory of the HTML files, but it breaks my image when I use it.</p>

<p>I have currently in my file</p>

<p><code>{{file:/images/picture.png}}</code></p>

<p>I expect the system to be able to transfer the file between computers but it registers to an absolute link and also does not include the image directory in the output directory of the vimwikiAll2HTML command.</p>
",2067,1,5,3,image;vim;vim-plugin,2019-08-25 09:48:14,2019-08-25 09:48:14,2022-05-28 12:10:35,i am building an internal project wiki for a group software development project  the project wiki is currently powered by vimwiki and i send the html files to both the project supervisor and each of the development team on a weekly basis  this keeps our intellectual property secure and internal  but also organized and up to date  i would like to put diagram images into the wiki itself so that all diagrams and documentation can be accessed together with ease  i am however having trouble making the images transferable between systems  does vimwiki give a way for image files to be embedded such that they can be transferred between systems  ideally the solution would make it possible to transfer the output directory of the vimwiki as a singular entity containing the html files and the image files  i have tried reading the documentation on images in the vimwiki reference document  i have not had luck using local  or file  variants  the wiki reference states that local should convert the image links to a localized location based on the output directory of the html files  but it breaks my image when i use it  i have currently in my file   file  images picture png   i expect the system to be able to transfer the file between computers but it registers to an absolute link and also does not include the image directory in the output directory of the vimwikiallhtml command ,using vimwiki to embed images to a wiki that needs to be transferable between systems
232,4055864,72378904,Cygwin tftpd cannot drop privileges?,"<p>I am running Cygwin64 on two Win10 machines, one Home and one Pro.  My software uses tftpd to receive a CSV from a network peer.  tftpd is run from init (package sysvinit) with this line:</p>
<pre><code>td:2345:respawn:/usr/sbin/tftpd -vvvvv -L -c -p -u Larry -U 000 -s /tmp
</code></pre>
<p>There is no xinetd running, no xinetd or tftp configuration file that I know of.  On the Win10 Home system, which is my development system, this works.  <strong>On the Win10 Pro system, it fails.  The client times out.  There is no entry in /var/log/messages (syslog-ng).  Windows Application Log says &quot;Cannot drop privileges: operation not permitted&quot;</strong></p>
<p>When I stop init and run that command line in a shell, it works and clients can transfer files in.  But my system needs the respawn management of init.  The pattern was set 12 years ago with Cygwin32 on Win7.  My customer is now updating the PC and we have this glitch.  If I were developing now, I would put the function on a raspi, but this is just a PC change.</p>
<p>Can anyone recommend a configuration to get the execution of tftpd under init under cygwin under Win10 Pro closer to that of the same command line in a user shell?</p>
<p>Edit 1: I also tried suid.  tftpd.exe is owned by the user account, not SYSTEM or whatever cygwin has for root.  Suid does not set permissions in a way that solves the problem.</p>
<p>Edit 2: adding cygdrop to the inittab line does not help.</p>
",38,1,0,5,windows;cygwin;daemon;init;tftp,2022-05-25 16:50:49,2022-05-25 16:50:49,2022-05-27 20:37:24,i am running cygwin on two win machines  one home and one pro   my software uses tftpd to receive a csv from a network peer   tftpd is run from init  package sysvinit  with this line  there is no xinetd running  no xinetd or tftp configuration file that i know of   on the win home system  which is my development system  this works   on the win pro system  it fails   the client times out   there is no entry in  var log messages  syslog ng    windows application log says  cannot drop privileges  operation not permitted  when i stop init and run that command line in a shell  it works and clients can transfer files in   but my system needs the respawn management of init   the pattern was set  years ago with cygwin on win   my customer is now updating the pc and we have this glitch   if i were developing now  i would put the function on a raspi  but this is just a pc change  can anyone recommend a configuration to get the execution of tftpd under init under cygwin under win pro closer to that of the same command line in a user shell  edit   i also tried suid   tftpd exe is owned by the user account  not system or whatever cygwin has for root   suid does not set permissions in a way that solves the problem  edit   adding cygdrop to the inittab line does not help ,cygwin tftpd cannot drop privileges 
233,7173790,72404894,One-hot-encoding multi-byte string values in R,"<p>I collected some data from a survey that asked respondents to rank their preferences for players' profiles:</p>
<pre><code>profile1: Tom, center, pitcher
profile2: Pete, right, hitter
profile3: Clay, left, hitter
profile4: Tom, right, fielder
profile5: Pete, left, fielder
profile6: Clay, center, pitcher
</code></pre>
<p>However, being unfamiliar with this questionnaire development software, the responses I collected are stored as multi-byte string values like the following (for each respondent), which are then read into R:</p>
<pre><code>preferences &lt;- data.frame(pref = c(&quot;1. Pete, right, hitter\n2. Clay, center, pitcher\n3. Tom, right, fielder\n4. Tom, center, pitcher\n5. Clay, left, hitter\n6. Pete, left, fielder&quot;,
&quot;1. Tom, right, fielder\n2. Clay, center, pitcher\n3. Pete, left, fielder\n4. Pete, right, hitter\n5. Tom, center, pitcher\n6. Clay, left, hitter&quot;,
&quot;1. Clay, left, hitter\n2. Tom, center, pitcher\n3. Pete, right, hitter\n4. Pete, left, fielder\n5. Clay, center, pitcher\n6. Tom, right, fielder&quot;))
</code></pre>
<p>I'm wondering if there is any way to map each of a respondent's ranked choices to distinct column values corresponding to players' profiles given above, kind of like one-hot-encoding (OHE), and turn the result into the following format:</p>
<pre><code>df &lt;- data.frame(profile1 = c(4, 5, 2), profile2 = c(1, 4, 3), profile3 = c(5, 6, 1), profile4 = c(3, 1, 6), profile5 = c(6, 3, 4), profile6 = c(2, 2, 5))

df

  profile1 profile2 profile3 profile4 profile5 profile6
1        4        1        5        3        6        2
2        5        4        6        1        3        2
3        2        3        1        6        4        5
</code></pre>
<p>Any suggestions would be appreciated.</p>
",43,3,0,3,r;one-hot-encoding;multibyte,2022-05-27 14:41:23,2022-05-27 14:41:23,2022-05-27 18:40:15,i collected some data from a survey that asked respondents to rank their preferences for players  profiles  however  being unfamiliar with this questionnaire development software  the responses i collected are stored as multi byte string values like the following  for each respondent   which are then read into r  i m wondering if there is any way to map each of a respondent s ranked choices to distinct column values corresponding to players  profiles given above  kind of like one hot encoding  ohe   and turn the result into the following format  any suggestions would be appreciated ,one hot encoding multi byte string values in r
234,5925219,72362507,Serial port writing with an eventhandler in Powershell,"<p>I'm having an issue with a powershell script that I would like to use for configurating a barcode scanner. I've been able to get most working, but I think because I use rather simple writelines, readexisting etc etc I'm not always getting the right answer of the device (the barcode scanner) nor am I sure that I send all lines.</p>
<p>So when I'm searching stackoverflow (or Google for that matter) I'm getting a lot of stuff about the datareceivedhandler etc, but I'm not sure how to get my script and the eventhandler to work. I've never used any eventhandlers in powershell so my ability to understand those are somewhat limited. I know they are a lot used in .net, but from my understanding I cannot literaly copy paste them from a c# code. Can someone help my on the way (I don't need a whole rewritten script, but just :</p>
<ul>
<li>this is how you start the eventhandler datareceived</li>
<li>this is how you do a writeline with above method</li>
<li>this is how you do a readline with above method</li>
</ul>
<p>I'm sorry if the question is out of order, then you may close it off course.</p>
<pre><code>    #requires -version 2
&lt;#
.SYNOPSIS
  &lt;Overview of script&gt;
.DESCRIPTION
  &lt;Brief description of script&gt;
.PARAMETER &lt;Parameter_Name&gt;
    &lt;Brief description of parameter input required. Repeat this attribute if required&gt;
.INPUTS
  &lt;Inputs if any, otherwise state None&gt;
.OUTPUTS
  &lt;Outputs if any, otherwise state None - example: Log file stored in C:\Windows\Temp\&lt;name&gt;.log&gt;
.NOTES
  Version:        1.0
  Author:         &lt;Name&gt;
  Creation Date:  &lt;Date&gt;
  Purpose/Change: Initial script development
  
.EXAMPLE
  &lt;Example goes here. Repeat this attribute for more than one example&gt;
#&gt;

#---------------------------------------------------------[Initialisations]--------------------------------------------------------

#Set Error Action to Silently Continue
$ErrorActionPreference = &quot;SilentlyContinue&quot;

#----------------------------------------------------------[Declarations]----------------------------------------------------------

#Script Version
#$sScriptVersion = &quot;1.0&quot;
#Log File Info
#$ScriptName = &quot;&lt;script_name&gt;.log&quot;


#-----------------------------------------------------------[Functions]------------------------------------------------------------

function PushConfig
{
  try 
  {
    $scanner = (Get-WmiObject Win32_PnPEntity |Where-Object {$_.name -match &quot;Barcode Scanner*&quot; })
    Write-Host &quot;`nScanners gevonden: $(($scanner | Measure-Object).count)&quot; -ForegroundColor DarkMagenta
    if ($scanner)
    {
      $scannerName = $scanner.Name
      #Here I get the com port out of the object
      $posCOM = $ScannerName.IndexOf(&quot;COM&quot;)
      [int]$posCOM = $posCOM + 2
      $COMNummer = $scannerName.Substring($posCOM+1,1)
      $COMPoort = &quot;COM&quot; + $COMNummer
      Write-Host &quot;We found the datalogic barcode scanner on: $COMPoort&quot; -ForegroundColor DarkMagenta
      #opening com port
      $port = New-Object System.IO.Ports.SerialPort $COMPoort,9600,None,8,one
      try
      {
        $port.Open()
      }
      catch
      {
        $port.PortName.ToString() + &quot;is already open&quot;
      }
      if (-not $port.IsOpen)
      {
        Write-Error &quot;COMpoort $COMPoort cannot be opened&quot;;
        Write-Output &quot;Please close the script, and close all programms that might be using the com port&quot;
        $port.Close()
      }
      Write-Host &quot;--------------------------------------------------------------------------------------------------------&quot; -ForegroundColor DarkMagenta
      #scanner geeft teken van leven
      $port.WriteLine(&quot;`$+`$!`r&quot;)#read out software version from scanner
      Start-Sleep -Milliseconds 500
      $output = $port.ReadExisting()
      Write-Host &quot;SOFTWARE versie:  $output&quot; -ForegroundColor DarkMagenta
      Write-Host &quot;--------------------------------------------------------------------------------------------------------&quot; -ForegroundColor DarkMagenta
      $configuratie = Get-Content -path c:\temp\barcode_dl_4500_config.txt
      $port.WriteLine(&quot;`$S`r&quot;)#putting the scanner in service mode
      Write-Host &quot;putting the scanner in service mode&quot; -ForegroundColor DarkMagenta
      Write-Host &quot;--------------------------------------------------------------------------------------------------------&quot; -ForegroundColor DarkMagenta
      $output = $port.ReadExisting()
      Start-Sleep -Milliseconds 2500
      write-host $output -ForegroundColor Red
      Write-Host &quot;--------------------------------------------------------------------------------------------------------&quot; -ForegroundColor DarkMage
      Write-Host &quot;Sending the configuration to the scanner&quot; -ForegroundColor DarkMagenta
      Write-Host &quot;--------------------------------------------------------------------------------------------------------&quot; -ForegroundColor DarkMagenta
      foreach ($line in $configuratie) #Sending the configuration to the scanner
      {
        Write-Host &quot;HOST:`$$line&quot; -ForegroundColor DarkMagenta
        $port.Write(&quot;`$$line`r&quot;)
        $output = $port.ReadExisting()
        Start-Sleep -Milliseconds 80
        Write-Output &quot;DEVICE: $output&quot;
        if ($output -eq &quot;$&gt;`r&quot;)
        {
          write-host &quot;Device OK&quot; -ForegroundColor Green
        }
        else {
          write-host &quot;Device NOK&quot; -ForegroundColor Red
        }
      }
      write-host &quot;HOST: Saving the settings&quot;
      $port.WriteLine(&quot;`$Ar\x0d`r&quot;)#saving settings on barcode scanner
      $output = $port.ReadExisting()
      Write-Host &quot;DEVICE: $output&quot; -ForegroundColor Magenta
      $port.WriteLine(&quot;`$s`r&quot;)#closing service mode
      $output = $port.ReadExisting()
      Write-Host &quot;DEVICE: $output&quot;
      Start-Sleep -Milliseconds 5000
      Write-Host &quot;HOST:Leaving service mode&quot;
      $output = $port.ReadExisting()
      Write-Host &quot;DEVICE: $output&quot;
    }
    $port.Close()
  }
  catch 
  {
      Write-Host &quot;Something has gone wrong &quot; -ForegroundColor Red
      Write-output $_.ScriptStackTracke
      Write-Output $_.Exception.Message
  }  
}

#-----------------------------------------------------------[Execution]------------------------------------------------------------

Start-Transcript -Path C:\temp\Logs\seding_config_scannedl_4500.log -IncludeInvocationHeader
PushConfig
</code></pre>
<p>Stop-Transcript</p>
<p>this is the result I get:</p>
<pre><code>Scanners found: 1
We found the datalogic barcode scanenr on: COM5
--------------------------------------------------------------------------------------------------------
SOFTWARE versie:  WLC4090-BASE-WIRELESS-CHARGER SOFTWARE RELEASE 610116050 BL 38.96fa43e6c 10/Nov/2021
--------------------------------------------------------------------------------------------------------
Putting the scanner in service mode
--------------------------------------------------------------------------------------------------------
$&gt;
--------------------------------------------------------------------------------------------------------
Sending the configuration to the scanner
--------------------------------------------------------------------------------------------------------
HOST:$AE
DEVICE:
Device NOK
HOST:$YF00000000000000000000
DEVICE:
Device NOK
HOST:$M05
DEVICE:
Device NOK
HOST:$CSNOG02
DEVICE:
Device NOK
HOST:$CSLPS03
DEVICE:
Device NOK
HOST:$CSMSD00
DEVICE:
Device NOK
HOST:$CLAGL03
DEVICE:
Device NOK
HOST:$CAB3B01
DEVICE:
Device NOK
HOST:$CBPVO01
DEVICE:
Device NOK
HOST:$As
DEVICE:
Device NOK
HOST:$M47
DEVICE:
Device NOK
HOST:$CIPNR02
DEVICE:
Device NOK
HOST:$CSNOG02
DEVICE:
Device NOK
HOST:$CSLPS03
DEVICE:
Device NOK
HOST:$CI2EN01
DEVICE:
Device NOK
HOST:$CI2L20A
DEVICE:
Device NOK
HOST:$CLADF02
DEVICE:
Device NOK
HOST:$CLADI00
DEVICE:
Device NOK
HOST:$CU2EN01
DEVICE:
Device NOK
HOST:$CU2L102
DEVICE:
Device NOK
HOST:$CLEEN01
DEVICE:
Device NOK
HOST:$CU8AI00
DEVICE:
Device NOK
HOST:$CSMSD00
DEVICE:
Device NOK
HOST:$CLAGL03
DEVICE:
Device NOK
HOST:$CMSCT00
DEVICE:
Device NOK
HOST:$CMSEN01
DEVICE:
Device NOK
HOST:$CPLCT00
DEVICE:
Device NOK
HOST:$CPLEN01
DEVICE:
Device NOK
HOST:$CUSSE00
DEVICE:
Device NOK
HOST:$CI8CE01
DEVICE:
Device NOK
HOST:$CDMDA05
DEVICE:
Device NOK
HOST:$CI8CE00
DEVICE:
Device NOK
HOST:$CABID4A2000
DEVICE:
Device NOK
HOST:$CEBID532000
$&gt;VICE: $&gt;
Device NOK
HOST:$C8BID4D2000
$&gt;VICE: $&gt;
Device NOK
HOST:$C3BID4D2000
DEVICE: $&gt;
Device OK
HOST:$CISID482000
DEVICE:
Device NOK
HOST:$CINID6E2000
$&gt;VICE: $&gt;
Device NOK
HOST:$CC3ID412000
DEVICE: $&gt;
Device OK
HOST:$CP3ID582000
DEVICE: $&gt;
Device OK
HOST:$CI2ID442000
DEVICE: $&gt;
Device OK
HOST:$CS2ID502000
DEVICE: $&gt;
Device OK
HOST:$CF2ID4F2000
DEVICE: $&gt;
Device OK
HOST:$CIAID262000
DEVICE: $&gt;
Device OK
HOST:$CU2ID432000
DEVICE: $&gt;
Device OK
HOST:$CCBID462000
DEVICE: $&gt;
Device OK
HOST:$CACID532000
DEVICE: $&gt;
Device OK
HOST:$CHRID652000
DEVICE: $&gt;
Device OK
HOST:$CC9ID492000
DEVICE: $&gt;
Device OK
HOST:$CC1ID622000
DEVICE: $&gt;
Device OK
HOST:$CC8ID482000
DEVICE: $&gt;
Device OK
HOST:$CU8ID472000
DEVICE: $&gt;
Device OK
HOST:$CMSID562000
DEVICE: $&gt;
Device OK
HOST:$CCFID6D0000
DEVICE: $&gt;
Device OK
HOST:$CI8ID482000
DEVICE: $&gt;
Device OK
HOST:$CM2ID452000
DEVICE: $&gt;
Device OK
HOST:$CCCID592000
DEVICE: $&gt;
Device OK
HOST:$CPLID612000
DEVICE: $&gt;
Device OK
HOST:$CALID6F2000
DEVICE: $&gt;
Device OK
HOST:$CA2ID4A2000
DEVICE: $&gt;
Device OK
HOST:$CA5ID4A2000
DEVICE: $&gt;
Device OK
HOST:$CE2ID532000
DEVICE: $&gt;
Device OK
HOST:$CE5ID532000
DEVICE: $&gt;
Device OK
HOST:$C82ID4D2000
DEVICE: $&gt;
Device OK
HOST:$C85ID4D2000
DEVICE: $&gt;
Device OK
HOST:$C32ID4D2000
DEVICE: $&gt;
Device OK
HOST:$C35ID4D2000
DEVICE: $&gt;
Device OK
HOST:$C4BID472000
DEVICE: $&gt;
Device OK
HOST:$CXBID472000
DEVICE: $&gt;
Device OK
HOST:$CLBID472000
DEVICE: $&gt;
Device OK
HOST:$CDMID632000
DEVICE: $&gt;
Device OK
HOST:$CGBID244100
DEVICE: $&gt;
Device OK
HOST:$CG2ID244200
DEVICE: $&gt;
Device OK
HOST:$CG5ID244300
DEVICE: $&gt;
Device OK
HOST:$CAB3B01
DEVICE: $&gt;
Device OK
HOST:$CBPVO01
DEVICE: $&gt;
Device OK
HOST:$CBCHP02
DEVICE: $&gt;
Device OK
HOST:$As
DEVICE: $&gt;
Device OK
HOST:$AS
DEVICE: $&gt;
Device OK
HOST:$M35
DEVICE: $&gt;
Device OK
HOST:$CSNOG02
DEVICE:
Device NOK
HOST:$CSLPS03
DEVICE:
Device NOK
HOST:$CSMSD00
$&gt;VICE: $&gt;
Device NOK
HOST:$CLAGL03
DEVICE: $&gt;
Device OK
HOST:$AS
DEVICE: $&gt;
Device OK
HOST:$HA05
DEVICE: $&gt;
Device OK
HOST:$HA47
DEVICE:
Device NOK
HOST:$U00000008554C453202F20A0A
DEVICE: $&gt;
Device OK
HOST:$U000800107B0A633D496E74546F537472284F5554
DEVICE:
Device NOK
HOST:$U00180010312E446174614C656E290A443D4F5554
$&gt;VICE: $&gt;
Device NOK
HOST:$U00280010312E446174610A4C3D226320220A0A69
DEVICE: $&gt;
Device OK
HOST:$U003800106628284F5554312E4461746154797065
DEVICE: $&gt;
Device OK
HOST:$U004800103D3D22436F646531323822297C7C284F
DEVICE: $&gt;
Device OK
HOST:$U005800105554312E44617461547970653D3D2249
DEVICE: $&gt;
Device OK
HOST:$U006800105342542229290A7B0A4C3D224820220A
DEVICE: $&gt;
Device OK
HOST:$U007800107D0A6966284F5554312E446174615479
DEVICE: $&gt;
Device OK
HOST:$U0088001070653D3D22436F6465333922290A7B0A
DEVICE: $&gt;
Device OK
HOST:$U00980010653D284F5554312E446174614C656E29
DEVICE: $&gt;
Device OK
HOST:$U00A800102D320A633D496E74546F537472286529
DEVICE: $&gt;
Device OK
HOST:$U00B800100A4F5554312E44617461547970653D22
DEVICE: $&gt;
Device OK
HOST:$U00C80010436F6465313238220A443D4D6964284F
DEVICE: $&gt;
Device OK
HOST:$U00D800105554312E446174612C322C65290A4C3D
DEVICE: $&gt;
Device OK
HOST:$U00E80010224120220A7D0A0A6966284F5554312E
DEVICE: $&gt;
Device OK
HOST:$U00F8001044617461547970653D3D2249326F6635
DEVICE: $&gt;
Device OK
HOST:$U0108001022290A7B0A4C3D224420220A7D0A6966
DEVICE: $&gt;
Device OK
HOST:$U01180010284F5554312E44617461547970653D3D
DEVICE: $&gt;
Device OK
HOST:$U01280010224D5349506C657373657922290A0A7B
DEVICE: $&gt;
Device OK
HOST:$U013800100A0A653D4F5554312E446174614C656E
DEVICE: $&gt;
Device OK
HOST:$U014800102D310A0A633D496E74546F5374722865
DEVICE: $&gt;
Device OK
HOST:$U01580010290A0A4C3D225620220A7D0A6966284F
DEVICE: $&gt;
Device OK
HOST:$U016800105554312E44617461547970653D3D2245
DEVICE: $&gt;
Device OK
HOST:$U01780010414E3822290A7B0A4C3D224D20220A7D
DEVICE: $&gt;
Device OK
HOST:$U018800100A6966284F5554312E44617461547970
DEVICE: $&gt;
Device OK
HOST:$U01980010653D3D2245414E313322290A7B0A4C3D
DEVICE: $&gt;
Device OK
HOST:$U01A80010224D20220A7D0A0A6966284F5554312E
DEVICE: $&gt;
Device OK
HOST:$U01B8001044617461547970653D3D225550434122
DEVICE: $&gt;
Device OK
HOST:$U01C80010290A7B0A4F5554312E44617461547970
DEVICE: $&gt;
Device OK
HOST:$U01D80010653D22436F6465313238220A443D2230
DEVICE: $&gt;
Device OK
HOST:$U01E80010222B4F5554312E446174610A633D496E
DEVICE: $&gt;
Device OK
HOST:$U01F8001074546F537472284F5554312E44617461
DEVICE: $&gt;
Device OK
HOST:$U020800104C656E2B31290A4C3D224D20220A7D0A
DEVICE: $&gt;
Device OK
HOST:$U021800100A6966284F5554312E44617461547970
DEVICE: $&gt;
Device OK
HOST:$U02280010653D3D22446174616D61747269782229
DEVICE: $&gt;
Device OK
HOST:$U023800100A7B0A4C3D226320220A7D0A69662828
DEVICE: $&gt;
Device OK
HOST:$U024800104F5554312E44617461547970653D3D22
DEVICE: $&gt;
Device OK
HOST:$U02580010436F646531323822292626284C656674
DEVICE: $&gt;
Device OK
HOST:$U02680010284F5554312E446174612C32293D3D22
DEVICE: $&gt;
Device OK
HOST:$U027800105C5C5C7838302229290A7B0A653D4F55
DEVICE: $&gt;
Device OK
HOST:$U0288001054312E446174614C656E2D320A633D49
DEVICE: $&gt;
Device OK
HOST:$U029800106E74546F5374722865290A0A4C3D2247
DEVICE: $&gt;
Device OK
HOST:$U02A8001020220A7D0A6966284F5554312E446174
DEVICE: $&gt;
Device OK
HOST:$U02B8001061547970653D3D2245414E3132382229
DEVICE: $&gt;
Device OK
HOST:$U02C800100A7B0A4C3D224720220A7D0A0A4F5554
DEVICE: $&gt;
Device OK
HOST:$U02D80010312E446174613D4C2B632B2220222B44
DEVICE: $&gt;
Device OK
HOST:$U02E800100A446F534C46284F555431290A0A7D0A
DEVICE: $&gt;
Device OK
HOST: saving the settings
DEVICE: $&gt;
DEVICE:
HOST:leaving service mode
$&gt;VICE: $&gt;
Transcript stopped, output file is C:\uz\Logs\naamScript.log
</code></pre>
",28,1,0,2,powershell;eventhandler,2022-05-24 14:57:47,2022-05-24 14:57:47,2022-05-27 15:10:47,i m having an issue with a powershell script that i would like to use for configurating a barcode scanner  i ve been able to get most working  but i think because i use rather simple writelines  readexisting etc etc i m not always getting the right answer of the device  the barcode scanner  nor am i sure that i send all lines  so when i m searching stackoverflow  or google for that matter  i m getting a lot of stuff about the datareceivedhandler etc  but i m not sure how to get my script and the eventhandler to work  i ve never used any eventhandlers in powershell so my ability to understand those are somewhat limited  i know they are a lot used in  net  but from my understanding i cannot literaly copy paste them from a c  code  can someone help my on the way  i don t need a whole rewritten script  but just   i m sorry if the question is out of order  then you may close it off course  stop transcript this is the result i get ,serial port writing with an eventhandler in powershell
235,16348298,72334679,Need help setting up a github repo,"<p>I am an EE student who was able to secure a summer job with a CS professor. He will start working on a development project and asked me to setup a GitHub repo for the same. I have coding experience but my experience with git and other software tools has been very minimal. Attached is a picture of the repository I built for him. He saw the repo and told me to include for CI-CD and Airflow. Now, I found some stuff online to help me with airflow but am stumped at the CI-CD part.</p>
<p>I have watched tutorials and have kind of understood what the continuous integration, delivery/deployment means but I am unsure how it should look in Github.</p>
<p>Shouldn't the current structure take care of the CI-CD process, like integrate all your code in the src folder (see image) and then testing will be done through the scripts in the test folder. Do I need to connect the folders somehow, so when programmers integrate their code, testing automatically runs to validate their work? Or should there be a separate CI-CD folder with subfolders? and if so, what should the subfolders be called?</p>
<p>I realize my question is not a standard posting at stackoverflow, but I will incredibly appreciate if someone could please help me.</p>
<p><a href=""https://i.stack.imgur.com/4dYiE.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/4dYiE.png"" alt=""enter image description here"" /></a></p>
",34,1,0,5,continuous-integration;repository;airflow;cicd;github-ci,2022-05-22 06:49:32,2022-05-22 06:49:32,2022-05-26 23:41:56,i am an ee student who was able to secure a summer job with a cs professor  he will start working on a development project and asked me to setup a github repo for the same  i have coding experience but my experience with git and other software tools has been very minimal  attached is a picture of the repository i built for him  he saw the repo and told me to include for ci cd and airflow  now  i found some stuff online to help me with airflow but am stumped at the ci cd part  i have watched tutorials and have kind of understood what the continuous integration  delivery deployment means but i am unsure how it should look in github  shouldn t the current structure take care of the ci cd process  like integrate all your code in the src folder  see image  and then testing will be done through the scripts in the test folder  do i need to connect the folders somehow  so when programmers integrate their code  testing automatically runs to validate their work  or should there be a separate ci cd folder with subfolders  and if so  what should the subfolders be called  i realize my question is not a standard posting at stackoverflow  but i will incredibly appreciate if someone could please help me  ,need help setting up a github repo
236,2781271,39730398,Cover image with dynamic height CSS,"<p>I am trying to find solution for the problem. 
I have following block </p>

<p><a href=""https://i.stack.imgur.com/KThZ1.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/KThZ1.png"" alt=""enter image description here""></a></p>

<p>As you can image takes more space than content. But in general image looks nice. 
I want to get the same behavior but to crop/cover image according to the text size. Currently this block doesn't have fixed height. So I guess it is impossible to get desired result without fixed height.</p>

<p>My html </p>

<pre><code>&lt;article id=""post-313"" class=""col-md-12 l-post post post--short post-type--post""&gt;
        &lt;div class=""l-post-thumbnail col-md-4 col-xs-12""&gt;
        &lt;div class=""post-thumbnail""&gt;
            &lt;img src=""http://martinsolutionsrd.com/wp-content/uploads/2016/05/para1.png"" alt=""Image for Remove all comments from your project"" class=""post-thumbnail__image""&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=""l-post-description col-md-8 col-xs-12""&gt;
        &lt;div class=""post-description""&gt;
            &lt;div class=""post-title""&gt;
                &lt;h3 class=""post-title__header""&gt;
                    &lt;a class=""post-title__link"" href=""#""&gt;Remove all comments from your project&lt;/a&gt;
                &lt;/h3&gt;
            &lt;/div&gt;
            &lt;div class=""post-meta""&gt;
                &lt;a href=""#"" class=""post-meta__link is-first-item""&gt;
                    &lt;span class=""post-meta__icon fa fa-user""&gt;&lt;/span&gt;
                    CROSP
                &lt;/a&gt;
                &lt;a href=""#"" class=""post-meta__link""&gt;
                    &lt;span class=""post-meta__icon fa fa-calendar""&gt;&lt;/span&gt;
                    June 27, 2016
                &lt;/a&gt;
                &lt;a href=""#"" class=""post-meta__link""&gt;
                    &lt;span class=""post-meta__icon fa fa-comment""&gt;&lt;/span&gt;
                    2
                                            Comments
                                    &lt;/a&gt;
            &lt;/div&gt;
            &lt;div class=""post-content""&gt;
                &lt;p class=""post-content__text""&gt;
                    Sometimes you need to do such weird things like remove all comments from your project.
This may mean that you have reached the highest level of writing code, so no one need comments to understand written in the source files.    Sometimes you need to do such weird things like remove all comments from your project.
This may mean that you have reached the highest level of writing code, so no one need comments to understand written in the source files.
                &lt;/p&gt;
            &lt;/div&gt;
            &lt;div class=""post-footer""&gt;
                &lt;div class=""post-categories""&gt;
                    &lt;div class=""post-categories__links-wrapper""&gt;
                        &lt;span class=""post-categories__icon fa fa-folder-open""&gt;&lt;/span&gt;
                                                    &lt;a href=""http://crosp.net/category/software-development/regex/"" class=""post-categories__link is-last-item""&gt;
                                Regex
                            &lt;/a&gt;
                                            &lt;/div&gt;
                &lt;/div&gt;&lt;!-- Inline block fix width
             --&gt;&lt;div class=""post-more""&gt;
                    &lt;a href=""#"" class=""post-more__button button button--primary""&gt;Read More&lt;/a&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/article&gt;
</code></pre>

<p>My CSS</p>

<pre><code>/* Post module */
.l-post {
  margin-bottom: 1.875em;
  padding: 0 !important; }
  @media only screen and (max-width: 560px) {
    .l-post.post--short {
      padding-right: 0;
      padding-left: 0; } }
  .l-post-thumbnail {
    padding: 0;
    margin: 0; }

/* Post content */
@media only screen and (max-width: 560px) {
  #main-content {
    padding: 0; } }

.l-sidebar {
  margin-bottom: 2.5em; }

.l-header {
  height: 90%;
  width: 100%; }
  @media only screen and (max-width: 560px) {
    .l-header {
      height: 100%; } }
  @media only screen and (min-width: 1440px) {
    .l-header {
      height: 60%; } }
  @media only screen and (min-width: 1600px) {
    .l-header {
      height: 40%; } }
  .l-header-content {
    font-size: 1.6rem;
    display: table;
    width: 100%;
    position: relative; }
    .l-header-content .header-content__wrapper {
      width: 100%;
      height: 100%;
      display: table-cell;
      vertical-align: middle; }

.l-footer {
  position: relative;
  padding: 3rem 0;
  background-color: #081c24; }
  .l-footer .social-icons {
    padding-right: 1.875em;
    text-align: right; }
    @media only screen and (max-width: 992px) {
      .l-footer .social-icons {
        display: block;
        margin: 2rem 0;
        text-align: center; } }
  .l-footer .copyright {
    text-align: left; }
    @media only screen and (max-width: 992px) {
      .l-footer .copyright {
        text-align: center;
        display: block; } }

.l-blog-pagination {
  text-align: center; }

.l-search-form {
  width: 100%; }
  .l-search-form .search-form__input {
    width: 50%; }
    @media only screen and (max-width: 480px) {
      .l-search-form .search-form__input {
        display: block;
        width: 70%;
        margin: 0 auto; } }
  @media only screen and (max-width: 480px) {
    .l-search-form .search-form__submit {
      margin: 0.625em auto;
      display: block; } }

/* Post module */
.post {
  overflow: hidden;
  background-color: #fff;
  border: 1px solid #c8c8c8;
  -moz-box-shadow: 0 2px 5px 0 rgba(0, 0, 0, 0.19), 0 2px 10px 0 rgba(0, 0, 0, 0.19);
  -webkit-box-shadow: 0 2px 5px 0 rgba(0, 0, 0, 0.19), 0 2px 10px 0 rgba(0, 0, 0, 0.19);
  box-shadow: 0 2px 5px 0 rgba(0, 0, 0, 0.19), 0 2px 10px 0 rgba(0, 0, 0, 0.19);
  -webkit-transition: all 0.7s;
  -moz-transition: all 0.7s;
  -o-transition: all 0.7s;
  transition: all 0.7s;
  /* Image submodule */
  /* Title submodule */
  /* Content submodule */
  /* Meta submodule */
  /* Footer submodule */
  /* Description submodule */
  /* Categories submodule */
  /* More submodule */
  /* States */ }
  .post-thumbnail {
    overflow: hidden;
    height: 100%; }
    .post-thumbnail__image {
      max-width: 150%;
      width: 140%;
      height: auto; }
  .post-title {
    display: block;
    margin-bottom: 0.625em;
    margin-top: 0.9375em; }
    .post-title__header {
      color: #52b3d9;
      font-weight: 700; }
    .post-title__link {
      color: #337ab7; }
  .post-content {
    line-height: 1.4; }
  .post-meta {
    margin: 0.5625em 0;
    color: #68c3a3; }
    .post-meta__link {
      white-space: nowrap;
      margin-right: 0.75em;
      color: #797e83; }
      .post-meta__link:hover {
        color: #52b3d9; }
    .post-meta__icon {
      font-size: 1.25em;
      margin-right: 0.2em; }
  .post-footer {
    width: 100%;
    padding: 0;
    margin-top: 1.25em; }
  .post-description {
    padding: 0.3125em 1.5625em 1.5625em 0.625em; }
    @media only screen and (max-width: 560px) {
      .post-description {
        padding-left: 0.3125em;
        padding-right: 0.3125em; } }
  .post-categories {
    margin: 0;
    width: 60%;
    word-wrap: break-word;
    vertical-align: middle;
    display: inline-block; }
    @media only screen and (max-width: 768px) {
      .post-categories {
        width: 100%;
        display: block; } }
    .post-categories__link {
      color: #797e83; }
      .post-categories__link:hover {
        color: #52b3d9; }
      .post-categories__link::after {
        content: ""/""; }
      .post-categories__link.is-last-item::after {
        content: """"; }
    .post-categories__icon {
      display: inline-block;
      color: #797e83;
      margin-right: 0.25em;
      font-size: 1.25em; }
    .post-categories__links-wrapper {
      vertical-align: middle;
      display: inline-block; }
  .post-more {
    margin: 0;
    width: 40%;
    display: inline-block;
    text-align: right; }
    @media only screen and (max-width: 768px) {
      .post-more {
        margin-top: 1.5rem;
        width: 100%;
        display: block;
        text-align: center; } }
  .post:hover {
    -moz-box-shadow: 0 6px 15px 0 rgba(0, 0, 0, 0.19), 0 5px 17px 0 rgba(0, 0, 0, 0.19);
    -webkit-box-shadow: 0 6px 15px 0 rgba(0, 0, 0, 0.19), 0 5px 17px 0 rgba(0, 0, 0, 0.19);
    box-shadow: 0 6px 15px 0 rgba(0, 0, 0, 0.19), 0 5px 17px 0 rgba(0, 0, 0, 0.19); }

/* Post info module used in header mostly */
.post-info {
  text-align: center;
  padding: 1.25em 1.25em; }
  .post-info__header {
    text-align: center;
    font-size: 1.375em;
    color: #f7f7f7;
    background-color: rgba(48, 56, 67, 0.6);
    border: 1px solid #6e6e6e;
    border-radius: 10px;
    padding: 0.45455em 1.13636em;
    display: inline-block;
    -webkit-transition: all 0.7s;
    -moz-transition: all 0.7s;
    -o-transition: all 0.7s;
    transition: all 0.7s; }
    .post-info__header:hover {
      border: 1px solid #52b3d9; }
    @media only screen and (max-width: 560px) {
      .post-info__header {
        padding: 0.45455em 0.68182em; } }
  .post-info__date-link {
    color: #52b3d9; }
    .post-info__date-link:visited, .post-info__date-link:active, .post-info__date-link:focus {
      color: #52b3d9; }
    .post-info__date-link:hover {
      color: #68c3a3; }
  .post-info__category-link {
    color: #52b3d9; }
    .post-info__category-link:visited, .post-info__category-link:active, .post-info__category-link:focus {
      color: #52b3d9; }
    .post-info__category-link:hover {
      color: #68c3a3; }
</code></pre>

<p>You can find working example (open in fullscreen) <a href=""https://jsfiddle.net/CROSP/ux6k02g9/"" rel=""nofollow noreferrer"">JSFiddle</a></p>

<p>I tried to set fixed height, and set image properties to </p>

<pre><code>   &amp;__image {
      width: auto;
      height: 100%;
    }
</code></pre>

<p>But it produces following result. As you can see only top left part is visible. </p>

<p><a href=""https://i.stack.imgur.com/tmpmj.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/tmpmj.png"" alt=""enter image description here""></a></p>

<p>I have only idea to make image absolute and set width and height to 120%, for instance in order to cover image. But I am not really want to make images absolute positions (get of normal flow).</p>

<p>Please suggest the best solution to get desired and nice looking result.</p>

<p>Thanks.</p>

<p><strong>UPDATE</strong></p>

<p>I am not big fan of bootstrap components, so I use only grid. 
I am looking for pure css solution.</p>
",638,3,0,5,html;css;image;twitter-bootstrap;layout,2016-09-27 19:57:53,2016-09-27 19:57:53,2022-05-26 23:32:55, my html  my css you can find working example  open in fullscreen   i tried to set fixed height  and set image properties to  but it produces following result  as you can see only top left part is visible    i have only idea to make image absolute and set width and height to    for instance in order to cover image  but i am not really want to make images absolute positions  get of normal flow   please suggest the best solution to get desired and nice looking result  thanks  update,cover image with dynamic height css
237,18919998,71981461,"IRQ 8 request_irq, Operation not permitted","<p>I'm new to kernel modules development and in my study process, I moved to the interrupts. My task is to write an interrupt handler module for <code>IRQ 8</code>, which will simply count the number of interrupts that occurred on this line and store the value in the <code>kobject</code>. The task sounds relatively easy at a first glance, but I've encountered strange behaviour. I wrote a handler function that simply increments the counter and returns interrupt as handled</p>
<pre><code>static int ir=0;
static irq_handler_t my_handler(int irq_no, void *dev_id, struct pt_regs *regs)
{
    ir++;
    return (irq_handler_t) IRQ_HANDLED;
}
</code></pre>
<p>To hook the interrupt handler I call the <code>request_irq()</code> function inside my <code>__init</code> with the first argument being <code>8</code>, so the <code>IRQ 8</code> (which is reserved by rtc) line interrupts are handled</p>
<pre><code>#define RTC_IRQ 8

[...]

int err;
err = request_irq(RTC_IRQ, (irq_handler_t) my_handler,IRQF_SHARED,&quot;rtc0&quot;,NULL);
if (err != 0)
    return -1;
</code></pre>
<p>With the implementation shown above, loading a kernel module gives me <code>err</code> equal to <code>-22</code>, which is <code>EINVAL</code>. After googling I discovered that for the <code>IRQF_SHARED</code> flag last parameter can't be assigned as <code>NULL</code>. I tried to find a method to obtain <code>rtc-&gt;dev_id</code> within the module, but in some of the examples they just typecasted the handler into <code>(void *)</code> so I tried passing <code>(void *) my_handler</code>. This gives me a flag mismatch warning on <code>insmod</code></p>
<pre><code>genirq: Flags mismatch irq 8. 00000080 (rtc0) vs. 00000000 (rtc0)
</code></pre>
<p>And err value set to <code>-16</code>, what I read from some sources means &quot;busy&quot;. While trying to find a way to obtain a device-id I found out that interrupt is sent by the <code>rtc0</code> device which is &quot;inherited&quot; from the <code>rtc-cmos</code> parent.</p>
<p>There are different controversial clues I found in different sources across the internet on this matter. Some state that the kernel disables rtc after the synchronization of the software clock, but this can't be the case, since the use of <code>sudo bash -c ' echo +20 &gt; /sys/class/rtc/rtc0/wakealarm '</code> and read of <code>/proc/interrupts</code> on the <code>IRQ 8</code> line shows that interrupts are working as intended</p>
<p>Other sources state that all the <code>request_irq</code>s directed to the line must have the <code>IRQF_SHARED</code> flag installed to be able to share the interrupt line. Reading the source file for <code>rtc-cmos</code> gave me nothing since they are setting up interrupts via reading-writing <code>CMOS</code> directly</p>
<p>I spent a lot of time trying to figure out the solution to the problem, but it seems like the RTC interrupts aren't commonly used in a kernel modules development, so finding relevant and recent information on the case is difficult, most of the discussions and examples are related to the implementation when <code>SA_SHIRQ</code>-like flags were used and <code>/drivers/examples</code> folder was present in the kernel source files which is something around kernel version <code>2.6</code>. And both interrupts and rtc kernel implementation were changed since those times</p>
<p>Any hints/suggestions that may help resolve this issue will be greatly appreciated. This is my first StackOverflow question, so if anything in its format is wrong or disturbing you are welcome to point it out in the comments as well</p>
<p>Thanks in advance for any help</p>
",87,1,0,2,linux-kernel;driver,2022-04-23 19:13:23,2022-04-23 19:13:23,2022-05-26 18:43:39,i m new to kernel modules development and in my study process  i moved to the interrupts  my task is to write an interrupt handler module for irq   which will simply count the number of interrupts that occurred on this line and store the value in the kobject  the task sounds relatively easy at a first glance  but i ve encountered strange behaviour  i wrote a handler function that simply increments the counter and returns interrupt as handled to hook the interrupt handler i call the request_irq   function inside my __init with the first argument being   so the irq   which is reserved by rtc  line interrupts are handled with the implementation shown above  loading a kernel module gives me err equal to    which is einval  after googling i discovered that for the irqf_shared flag last parameter can t be assigned as null  i tried to find a method to obtain rtc  gt dev_id within the module  but in some of the examples they just typecasted the handler into  void    so i tried passing  void    my_handler  this gives me a flag mismatch warning on insmod and err value set to    what i read from some sources means  busy   while trying to find a way to obtain a device id i found out that interrupt is sent by the rtc device which is  inherited  from the rtc cmos parent  there are different controversial clues i found in different sources across the internet on this matter  some state that the kernel disables rtc after the synchronization of the software clock  but this can t be the case  since the use of sudo bash  c   echo    gt   sys class rtc rtc wakealarm   and read of  proc interrupts on the irq  line shows that interrupts are working as intended other sources state that all the request_irqs directed to the line must have the irqf_shared flag installed to be able to share the interrupt line  reading the source file for rtc cmos gave me nothing since they are setting up interrupts via reading writing cmos directly i spent a lot of time trying to figure out the solution to the problem  but it seems like the rtc interrupts aren t commonly used in a kernel modules development  so finding relevant and recent information on the case is difficult  most of the discussions and examples are related to the implementation when sa_shirq like flags were used and  drivers examples folder was present in the kernel source files which is something around kernel version    and both interrupts and rtc kernel implementation were changed since those times any hints suggestions that may help resolve this issue will be greatly appreciated  this is my first stackoverflow question  so if anything in its format is wrong or disturbing you are welcome to point it out in the comments as well thanks in advance for any help,irq  request_irq  operation not permitted
238,7713770,72340724,Internal Server Error after login applicatioin,"<p>I am using docker for my yii1 application. And everything works. But after I login on my application. I get this error:</p>
<pre><code>Internal Server Error
The server encountered an internal error or misconfiguration and was unable to complete your request.

Please contact the server administrator at [no address given] to inform them of the time this error occurred, and the actions you performed just before this error.

More information about this error may be available in the server error log.

Apache/2.4.53 (Debian) Server at localhost Port 8082
</code></pre>
<p>So this is my docker-compose fyle:</p>
<pre><code>version: '3'
services:
  web:
    image: nguyenmanhluu/yii1:1.0
    container_name: dockeryiidisc
    ports:
      - &quot;8082:80&quot;
    build: 
      context: ..
      dockerfile: Dockerfile
      target: dev     
    volumes:
      - ./:/var/www/html       
    command: /bin/sh -c &quot;service apache2 start &amp;&amp; while sleep 1000; do :; done&quot;
   
  db:
    container_name: dockeryiimysql
    image: mysql:latest
    volumes:
      - dockeryiimysql:/var/lib/mysql
    ports:
      - &quot;3306:3306&quot;
    environment:
      MYSQL_ALLOW_EMPTY_PASSWORD: 'true'
      MYSQL_DATABASE: sdi      

  phpmyadmin:  
    container_name: dockeryiipma
    image: phpmyadmin:latest
    environment:
      UPLOAD_LIMIT: 300M
      PMA_ARBITRARY: 1
      APACHE_HTTP_PORT_NUMBER: 8080
    ports:
      - 8080:8080
    command: /bin/bash -c &quot;sed -i \&quot;s/80/$$APACHE_HTTP_PORT_NUMBER/g\&quot; /etc/apache2/sites-available/000-default.conf /etc/apache2/ports.conf &amp;&amp; /docker-entrypoint.sh apache2-foreground&quot;

volumes:
  dockeryiimysql: {}

</code></pre>
<p>and my file 000-default.conf</p>
<pre><code>&lt;VirtualHost *:80&gt;
    DocumentRoot /var/www/public

    &lt;Directory /var/www&gt;
            AllowOverride all
            Require all granted
    &lt;/Directory&gt;
    ErrorLog ${APACHE_LOG_DIR}/error.log
    CustomLog ${APACHE_LOG_DIR}/access.log combined
&lt;/VirtualHost&gt;
</code></pre>
<p>and my docker file:</p>
<pre><code>FROM php:8.1-apache as dev

ENV DEBIAN_FRONTEND=noninteractive
ENV APP_ENV=development

WORKDIR /var/www/html

RUN apt-get update \
  &amp;&amp; apt-get -y install --no-install-recommends apt-utils zip unzip nano ncdu 2&gt;&amp;1 \
    &amp;&amp; apt-get -y install --no-install-recommends python graphviz 2&gt;&amp;1 \
  &amp;&amp; apt-get -y install git iproute2 procps lsb-release \
  &amp;&amp; apt-get install -y -qq software-properties-common \
  &amp;&amp; apt-get install -y -qq wget git lynx ack-grep \
  &amp;&amp; yes | pecl install xdebug \
  &amp;&amp; echo &quot;zend_extension=$(find /usr/local/lib/php/extensions/ -name xdebug.so)&quot; &gt; /usr/local/etc/php/conf.d/xdebug.ini \
    &amp;&amp; apt-get -y install libicu-dev \
    &amp;&amp; docker-php-ext-install intl pdo_mysql opcache \
    &amp;&amp; pecl install apcu &amp;&amp; docker-php-ext-enable apcu \
    &amp;&amp; echo &quot;apc.enable_cli=1&quot; &gt; /usr/local/etc/php/php.ini \
    &amp;&amp; echo &quot;apc.enable=1&quot; &gt; /usr/local/etc/php/php.ini \
  &amp;&amp; echo &quot;post_max_size = 100M&quot; &gt; /usr/local/etc/php/php.ini \
    &amp;&amp; a2enmod rewrite \
  &amp;&amp; apt-get autoremove -y \
  &amp;&amp; apt-get clean -y \
  &amp;&amp; rm -rf /var/lib/apt/lists/*

RUN apt-get update &amp;&amp; apt-get install gnupg2 -y

RUN rm -rf /etc/apache2/sites-enabled \
    &amp;&amp; ln -s /var/www/html/.devcontainer/sites-enabled /etc/apache2/sites-enabled

RUN echo 'alias ll=&quot;ls -la --color=auto&quot;' &gt;&gt; ~/.bashrc &amp;&amp; \
    echo &quot;alias ack='ack-grep'&quot; &gt;&gt; ~/.bashrc

RUN chown www-data:www-data -R ./

ENV DEBIAN_FRONTEND=dialog

</code></pre>
<p>my question is: what I have to change?</p>
<p>Where can I access the log files?</p>
<p>I have this:</p>
<pre><code>CONTAINER ID   IMAGE                    COMMAND                  CREATED          STATUS          PORTS                               NAMES
06276923b58b   mysql:latest             &quot;docker-entrypoint.s…&quot;   15 minutes ago   Up 15 minutes   0.0.0.0:3306-&gt;3306/tcp, 33060/tcp   dockeryiimysql
81055c285fdc   nguyenmanhluu/yii1:1.0   &quot;docker-php-entrypoi…&quot;   15 minutes ago   Up 15 minutes   0.0.0.0:8083-&gt;80/tcp                dockeryiidisc
eb7bd150d254   phpmyadmin:latest        &quot;/docker-entrypoint.…&quot;   15 minutes ago   Up 15 minutes   80/tcp, 0.0.0.0:8080-&gt;8080/tcp      dockeryiipma
PS C:\xampp\htdocs\webScraper&gt; docker exec -it 81055c285fdc bash
root@81055c285fdc:/var/www/html#
</code></pre>
<p>And I used the correct host in the file main.php for container name:</p>
<pre><code>'db'=&gt; [
            'pdoClass' =&gt; 'NestedPDO',
            'connectionString' =&gt; 'mysql:host=dockeryiimysql;dbname=sdi',
            'emulatePrepare' =&gt; true,
            'username' =&gt; 'root',
            'password' =&gt; '',
            'charset' =&gt; 'utf8',
            'enableProfiling'=&gt;true,
        ],
</code></pre>
<p>on the phpmyadmin container I found this:</p>
<pre><code>AH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 172.21.0.3. Set the 'ServerName' directive globally to suppress this message
AH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 172.21.0.3. Set the 'ServerName' directive globally to suppress this message
[Mon May 23 07:06:13.275555 2022] [mpm_prefork:notice] [pid 1] AH00163: Apache/2.4.53 (Debian) PHP/8.0.19 configured -- resuming normal operations
[Mon May 23 07:06:13.275613 2022] [core:notice] [pid 1] AH00094: Command line: 'apache2 -D FOREGROUND'
172.21.0.1 - - [23/May/2022:07:06:36 +0000] &quot;GET /index.php?route=/&amp;route=%2F HTTP/1.1&quot; 200 6290 &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 OPR/86.0.4363.59&quot;
172.21.0.1 - - [23/May/2022:07:06:40 +0000] &quot;POST /index.php?route=/ HTTP/1.1&quot; 302 1020 &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 OPR/86.0.4363.59&quot;
172.21.0.1 - - [23/May/2022:07:06:40 +0000] &quot;GET /index.php?route=/&amp;route=%2F HTTP/1.1&quot; 200 18402 &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 OPR/86.0.4363.59&quot;
172.21.0.1 - - [23/May/2022:07:06:40 +0000] &quot;POST /index.php?route=/config/get HTTP/1.1&quot; 200 2471 &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 OPR/86.0.4363.59&quot;
172.21.0.1 - - [23/May/2022:07:06:40 +0000] &quot;POST /index.php?route=/navigation&amp;ajax_request=1 HTTP/1.1&quot; 200 3205 &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 OPR/86.0.4363.59&quot;
172.21.0.1 - - [23/May/2022:07:06:40 +0000] &quot;POST /index.php?route=/version-check HTTP/1.1&quot; 200 1047 &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 OPR/86.0.4363.59&quot;
172.21.0.1 - - [23/May/2022:07:06:40 +0000] &quot;POST /index.php?route=/config/get HTTP/1.1&quot; 200 2573 &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 OPR/86.0.4363.59&quot;
172.21.0.1 - - [23/May/2022:07:06:40 +0000] &quot;POST /index.php?route=/config/set HTTP/1.1&quot; 200 2462 &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 OPR/86.0.4363.59&quot;
172.21.0.1 - - [23/May/2022:07:06:42 +0000] &quot;POST /index.php?route=/navigation&amp;ajax_request=1 HTTP/1.1&quot; 200 3897 &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 OPR/86.0.4363.59&quot;
172.21.0.1 - - [23/May/2022:07:30:35 +0000] &quot;POST /index.php?route=/ HTTP/1.1&quot; 200 2458 &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 OPR/86.0.4363.59&quot;
172.21.0.1 - - [23/May/2022:07:49:14 +0000] &quot;POST /index.php?route=/ HTTP/1.1&quot; 200 2466 &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 OPR/86.0.4363.59&quot;
172.21.0.1 - - [23/May/2022:08:14:59 +0000] &quot;POST /index.php?route=/ HTTP/1.1&quot; 200 3027 &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 OPR/86.0.4363.59&quot;
172.21.0.1 - - [23/May/2022:08:14:59 +0000] &quot;GET /themes/pmahomme/img/s_error.png HTTP/1.1&quot; 200 898 &quot;http://localhost:8080/themes/pmahomme/css/theme.css?v=5.2.0&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 OPR/86.0.4363.59&quot;
</code></pre>
",169,1,0,5,php;docker;docker-compose;yii;yaml,2022-05-22 22:32:36,2022-05-22 22:32:36,2022-05-26 13:55:28,i am using docker for my yii application  and everything works  but after i login on my application  i get this error  so this is my docker compose fyle  and my file  default conf and my docker file  my question is  what i have to change  where can i access the log files  i have this  and i used the correct host in the file main php for container name  on the phpmyadmin container i found this ,internal server error after login applicatioin
239,2670463,28366031,"In C language, what is the best practice to check return value of a function for a branching statement?","<p>I'm trying to have an embedded software development point of view, and I'd like to ask which one is better to go with, and what are the possible advantages and disadvantages?</p>

<pre><code>bool funct(){
   bool retVal = 0;
   //do something
   return retVal;
}

//First Choice
if(funct()){
   //do something
}

//Second Choice
bool retVal = funct();
   if(retVal)
  {
    //do something
  }
</code></pre>
",2679,4,3,3,c;embedded;machine-code,2015-02-06 14:41:23,2015-02-06 14:41:23,2022-05-26 09:35:21,i m trying to have an embedded software development point of view  and i d like to ask which one is better to go with  and what are the possible advantages and disadvantages ,in c language  what is the best practice to check return value of a function for a branching statement 
240,15397144,72371365,Kotlin (add configuration) no Run option,"<p>I've been thinking about moving to Android development. I came from Java so I wanted to learn Kotlin with IntelliJ. I have never used a JetBrains software and I'm trying to follow a tutorial on YouTube.</p>
<p>The thing is none of the tutorials explain how to add a configuration to the project. For them a green arrow pops up when they create this function, but for me there is no run button and IntelliJ tells me I have to add some configuration?</p>
<pre class=""lang-kotlin prettyprint-override""><code>fun main(){
    println(&quot;Hello World&quot;)
}
</code></pre>
<p><a href=""https://i.stack.imgur.com/Ub7kM.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Ub7kM.png"" alt=""Kotlin problem screenshot"" /></a></p>
",75,1,-1,3,kotlin;intellij-idea;jetbrains-ide,2022-05-25 05:26:47,2022-05-25 05:26:47,2022-05-25 12:31:38,i ve been thinking about moving to android development  i came from java so i wanted to learn kotlin with intellij  i have never used a jetbrains software and i m trying to follow a tutorial on youtube  the thing is none of the tutorials explain how to add a configuration to the project  for them a green arrow pops up when they create this function  but for me there is no run button and intellij tells me i have to add some configuration  ,kotlin  add configuration  no run option
241,5311637,69914876,Why Xcode can not attach to some programs?,"<p>i had to reinstall my MacBook Pro. I have installed the newest macOS &amp; Xcode version so</p>
<p>macOS Monterey 12.0.1 (21A559)
and
Version 13.1 (13A1030d)</p>
<p>I'm programming Audio plugins so to test my plugins I'm normally running a DAW (Digital Audio Workstation) in my case I'm working the most of the time with Ableton or Bitwig.</p>
<p>So if I start the debuging process, I get the follow error:
Could not attach to pid XXXXXX
attach failed (Not allowed to attach to process.  Look in the console messages (Console.app), near the debugserver entries, when the attach failed.  The subsystem that denied the attach permission will likely have logged an informative message about why it was denied.)</p>
<p>If I have an eye to the console.app the the following lines:</p>
<blockquote>
<p>[LaunchAttach] (3277) about to task_for_pid(2930)</p>
</blockquote>
<blockquote>
<p>error: [LaunchAttach] MachTask::TaskPortForProcessID
task_for_pid(2930) failed: ::task_for_pid ( target_tport = 0x0203, pid
= 2930, &amp;task ) =&gt; err = 0x00000005 ((os/kern) failure)</p>
</blockquote>
<blockquote>
<p>macOSTaskPolicy: (com.apple.debugserver) may not get the task control
port of (BitwigStudio) (pid: 2930): (BitwigStudio) is hardened,
(BitwigStudio) doesn't have get-task-allow, (com.apple.debugserver) is
a declared debugger(com.apple.debugserver) is not a declared read-only
debugger</p>
</blockquote>
<blockquote>
<p>1 +0.000000 sec [0ccd/0103]: error: ::task_for_pid ( target_tport =
0x0203, pid = 2930, &amp;task ) =&gt; err = 0x00000005 ((os/kern) failure)
err = ::task_for_pid ( target_tport = 0x0203, pid = 2930, &amp;task ) =&gt;
err = 0x00000005 ((os/kern) failure) (0x00000005)</p>
</blockquote>
<p>I have done some research and found this:
<a href=""https://stackoverflow.com/questions/1003066/what-does-get-task-allow-do-in-xcode"">Stackoverflow link about What does get-task-allow do</a></p>
<blockquote>
<p>get-task-allow, when signed into an application, allows other
processes (like the debugger) to attach to your app. Distribution
profiles require that this value be turned off, while development
profiles require this value to be turned on (otherwise Xcode would
never be able to launch and attach to your app).</p>
</blockquote>
<p>So there is nothing I can do to debug my programs with that software. Is that correct? :(</p>
",2331,2,0,4,xcode;macos;debugging;macos-monterey,2021-11-10 16:16:41,2021-11-10 16:16:41,2022-05-24 06:38:25,i had to reinstall my macbook pro  i have installed the newest macos  amp  xcode version so i m programming audio plugins so to test my plugins i m normally running a daw  digital audio workstation  in my case i m working the most of the time with ableton or bitwig  if i have an eye to the console app the the following lines   launchattach     about to task_for_pid   so there is nothing i can do to debug my programs with that software  is that correct    ,why xcode can not attach to some programs 
242,19150869,72299959,Using our own local linux kernel source code on Yocto Project,"<p>We need use our customized linux kernel source code on Yocto Project, is it possible to use our kernel source code with tar file and put it on downloads folder, then use SRC_URI = file://xxx.tar.gz on bb file, let tar file to be the kernel source?  if not, how to do this on our own software project development?</p>
<p>BR,
Jack</p>
",225,2,0,2,linux-kernel;yocto,2022-05-19 09:59:31,2022-05-19 09:59:31,2022-05-23 19:36:04,we need use our customized linux kernel source code on yocto project  is it possible to use our kernel source code with tar file and put it on downloads folder  then use src_uri   file   xxx tar gz on bb file  let tar file to be the kernel source   if not  how to do this on our own software project development ,using our own local linux kernel source code on yocto project
243,846910,24095968,Docker for GUI-based environments?,"<p><strong>Problem</strong></p>

<p>I have a set of client machines that are a part of an enterprise web application. Each machine runs identical software, which is a PyQT-based web client that connects to a server. This client software is updated regularly and I would like to have some configuration/provisioning tool that allows to have the same environment on each machine and hence provide easy deployment and configuration of the software onto each of the clients' machines.</p>

<p>The problem is that I have tried to use Chef, but it takes a lot of effort to actually maintain Chef knowledge and skills (we do not have a dedicated Ops guy) and moreover a Chef recipe can fail if some third party repository <a href=""http://blog.relateiq.com/why-docker-why-not-chef/"">is no longer available</a> (this is a main stopper).</p>

<p>I would like to try Docker to solve the problem, but I <a href=""https://www.docker.io/the_whole_story/"">still do not know</a> if it is possible to set up images/containers that allow for some GUI based software to operate.</p>

<p><strong>Question</strong></p>

<p>Is it possible to use Docker to have a development/production environment for a GUI-based application (PyQt/QT)? If yes, what would be the first steps to approach that?</p>
",35544,9,51,4,docker;qt;vagrant;configuration-management,2014-06-07 12:53:33,2014-06-07 12:53:33,2022-05-23 17:10:18,problem i have a set of client machines that are a part of an enterprise web application  each machine runs identical software  which is a pyqt based web client that connects to a server  this client software is updated regularly and i would like to have some configuration provisioning tool that allows to have the same environment on each machine and hence provide easy deployment and configuration of the software onto each of the clients  machines  the problem is that i have tried to use chef  but it takes a lot of effort to actually maintain chef knowledge and skills  we do not have a dedicated ops guy  and moreover a chef recipe can fail if some third party repository   this is a main stopper   i would like to try docker to solve the problem  but i  if it is possible to set up images containers that allow for some gui based software to operate  question is it possible to use docker to have a development production environment for a gui based application  pyqt qt   if yes  what would be the first steps to approach that ,docker for gui based environments 
244,1573534,72335325,How to send raw json in request body,"<p>In <strong>Flutter</strong> using <strong>retrofit</strong> package
I need to send json raw object as shown in the postman snapshot.</p>
<p><a href=""https://i.stack.imgur.com/vFvIL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/vFvIL.png"" alt=""enter image description here"" /></a></p>
<p>I tried to do it by this method but didn't work</p>
<pre><code>@override
@POST('/profile')
Future&lt;UserModel&gt; updateUser(@Body() UserModel userModel);
</code></pre>
<p>this is the request</p>
<pre><code>╔╣ Request ║ POST ║ http://206.189.57.118/api/user/profile 

╔ Headers ╟ content-type: application/json ╟ Accept: application/json ╟ Authorization: Bearer 8|LMoB1zivD3O89B7Bv3RQi4zLMeAfTZShmClvWYAt ╟ contentType: application/json ╟ responseType: ResponseType.json ╟ followRedirects: true ╟ connectTimeout: 0 ╟ receiveTimeout: 0 

 ╔ Body ╟ gender: Male ╟ dateOfBirth: 856800000 ╟ maritalStatus: ╟ numChildren: 0 ╟ address: Khanyounis ╟ phone: 123456789 ╟ secondaryPhone: 123456789 ╟ secondaryPhoneRelationShip: ╟ telephone: 123456789 ╟ university: Azhar ╟ faculty: Software Engineering ╟ specialization: Web development ╟ image: null 
</code></pre>
",190,1,0,2,flutter;retrofit,2022-05-22 09:37:02,2022-05-22 09:37:02,2022-05-23 06:32:35, i tried to do it by this method but didn t work this is the request,how to send raw json in request body
245,7713770,72336965,running existing yii1 application in docker,"<p>I have a existing yii1 application. And I am using local xampp.</p>
<p>So I try to dockerise the existing yii1 application.</p>
<p>So This is my dockerfile in root folder:</p>
<pre><code>FROM php:8.1-apache as dev

ENV DEBIAN_FRONTEND=noninteractive
ENV APP_ENV=development

WORKDIR /var/www/html

RUN apt-get update \
  &amp;&amp; apt-get -y install --no-install-recommends apt-utils zip unzip nano ncdu 2&gt;&amp;1 \
    &amp;&amp; apt-get -y install --no-install-recommends python graphviz 2&gt;&amp;1 \
  &amp;&amp; apt-get -y install git iproute2 procps lsb-release \
  &amp;&amp; apt-get install -y -qq software-properties-common \
  &amp;&amp; apt-get install -y -qq wget git lynx ack-grep \
  &amp;&amp; yes | pecl install xdebug \
  &amp;&amp; echo &quot;zend_extension=$(find /usr/local/lib/php/extensions/ -name xdebug.so)&quot; &gt; /usr/local/etc/php/conf.d/xdebug.ini \
    &amp;&amp; apt-get -y install libicu-dev \
    &amp;&amp; docker-php-ext-install intl pdo_mysql opcache \
    &amp;&amp; pecl install apcu &amp;&amp; docker-php-ext-enable apcu \
    &amp;&amp; echo &quot;apc.enable_cli=1&quot; &gt; /usr/local/etc/php/php.ini \
    &amp;&amp; echo &quot;apc.enable=1&quot; &gt; /usr/local/etc/php/php.ini \
  &amp;&amp; echo &quot;post_max_size = 100M&quot; &gt; /usr/local/etc/php/php.ini \
    &amp;&amp; a2enmod rewrite \
  &amp;&amp; apt-get autoremove -y \
  &amp;&amp; apt-get clean -y \
  &amp;&amp; rm -rf /var/lib/apt/lists/*

RUN apt-get update &amp;&amp; apt-get install gnupg2 -y

RUN rm -rf /etc/apache2/sites-enabled \
    &amp;&amp; ln -s /var/www/html/.devcontainer/sites-enabled /etc/apache2/sites-enabled

RUN echo 'alias ll=&quot;ls -la --color=auto&quot;' &gt;&gt; ~/.bashrc &amp;&amp; \
    echo &quot;alias ack='ack-grep'&quot; &gt;&gt; ~/.bashrc

RUN chown www-data:www-data -R ./

ENV DEBIAN_FRONTEND=dialog

</code></pre>
<p>and this is my docker-compose.yml file also in root folder:</p>
<pre><code>version: '3'
services:
  web:
    image: nguyenmanhluu/yii1:1.0
    container_name: dockeryiidisc
    ports:
      - &quot;9002:80&quot;
    build: .     
    volumes:
      - ../:/var/www/html       
    command: /bin/sh -c &quot;service apache2 start &amp;&amp; while sleep 1000; do :; done&quot;
   
  db:
    container_name: dockeryiimysql
    image: mysql:latest
    volumes:
      - dockeryiimysql:/var/lib/mysql
    ports:
      - &quot;3306:3306&quot;
    environment:
      MYSQL_ALLOW_EMPTY_PASSWORD: 'true'
      MYSQL_DATABASE: sdi      

  phpmyadmin:  
    container_name: dockeryiipma
    image: phpmyadmin:latest
    environment:
      UPLOAD_LIMIT: 300M
      PMA_ARBITRARY: 1
      APACHE_HTTP_PORT_NUMBER: 8080
    ports:
      - 8080:8080
    command: /bin/bash -c &quot;sed -i \&quot;s/80/$$APACHE_HTTP_PORT_NUMBER/g\&quot; /etc/apache2/sites-available/000-default.conf /etc/apache2/ports.conf &amp;&amp; /docker-entrypoint.sh apache2-foreground&quot;

volumes:
  dockeryiimysql: {}

</code></pre>
<p>So if I go to my root folder and do a docker-compose up. Then I see in docker desktop all three containers are running.</p>
<p>And if I go to: localhost:8080 I see the phpmyadmin database.</p>
<p>But if I go to localhost:9002 I see the startscreen of xampp. And I dont be redirected to the real application.</p>
<p>So what I have to change?</p>
<p>Thank you.</p>
<p>What I mean I will be redirected to: http://localhost:9002/dashboard/</p>
",108,1,0,4,docker;docker-compose;yii;dockerfile,2022-05-22 14:01:58,2022-05-22 14:01:58,2022-05-22 22:17:57,i have a existing yii application  and i am using local xampp  so i try to dockerise the existing yii application  so this is my dockerfile in root folder  and this is my docker compose yml file also in root folder  so if i go to my root folder and do a docker compose up  then i see in docker desktop all three containers are running  and if i go to  localhost  i see the phpmyadmin database  but if i go to localhost  i see the startscreen of xampp  and i dont be redirected to the real application  so what i have to change  thank you  what i mean i will be redirected to  http   localhost  dashboard ,running existing yii application in docker
246,9538424,61672233,Install Eclipse for C/C++ in Ubuntu 20.04 LTS Error/Crash on Run,"<p>I am attempting to install Eclipse for C/C++ manually since the version included in the Ubuntu Software center appears to be for Java development only.  I complete the steps include in the guide linked below.  However when I attempt to launch I receive the below error:</p>

<pre><code>XYZ@ubuntu:~/Downloads$ sudo eclipse
OpenJDK 64-Bit Server VM warning: Ignoring option MaxPermSize; support was removed in 8.0
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.eclipse.osgi.internal.baseadaptor.BaseStorage (file:/opt/eclipse/plugins/org.eclipse.osgi_3.6.2.R36x_v20110210.jar) to method java.net.URLClassLoader.addURL(java.net.URL)
WARNING: Please consider reporting this to the maintainers of org.eclipse.osgi.internal.baseadaptor.BaseStorage
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
</code></pre>

<p>After this warning is displayed Eclipse fails to launch.</p>

<p>Below is the error log entry in Eclipse:</p>

<pre><code>!SESSION 2020-05-07 22:53:03.283 -----------------------------------------------
eclipse.buildId=M20110210-1200
java.version=11.0.7
java.vendor=Ubuntu
BootLoader constants: OS=linux, ARCH=x86_64, WS=gtk, NL=en_US
Framework arguments:  -product org.eclipse.epp.package.linuxtools.product
Command-line arguments:  -os linux -ws gtk -arch x86_64 -product org.eclipse.epp.package.linuxtools.product

!ENTRY org.eclipse.equinox.simpleconfigurator 4 0 2020-05-07 22:53:03.668
!MESSAGE
!STACK 0
org.osgi.framework.BundleException: The bundle ""org.eclipse.equinox.simpleconfigurator_1.0.200.v20100503 [1]"" could not be resolved. Reason: Missing Constraint: Bundle-RequiredExecutionEnvironm&gt;
        at org.eclipse.osgi.framework.internal.core.AbstractBundle.getResolverError(AbstractBundle.java:1317)
        at org.eclipse.osgi.framework.internal.core.AbstractBundle.getResolutionFailureException(AbstractBundle.java:1301)
        at org.eclipse.osgi.framework.internal.core.BundleHost.startWorker(BundleHost.java:319)
        at org.eclipse.osgi.framework.internal.core.AbstractBundle.resume(AbstractBundle.java:374)
        at org.eclipse.osgi.framework.internal.core.Framework.resumeBundle(Framework.java:1067)
        at org.eclipse.osgi.framework.internal.core.StartLevelManager.resumeBundles(StartLevelManager.java:561)
        at org.eclipse.osgi.framework.internal.core.StartLevelManager.resumeBundles(StartLevelManager.java:546)
        at org.eclipse.osgi.framework.internal.core.StartLevelManager.incFWSL(StartLevelManager.java:459)
        at org.eclipse.osgi.framework.internal.core.StartLevelManager.doSetStartLevel(StartLevelManager.java:243)
        at org.eclipse.osgi.framework.internal.core.StartLevelManager.dispatchEvent(StartLevelManager.java:440)
        at org.eclipse.osgi.framework.eventmgr.EventManager.dispatchEvent(EventManager.java:227)
        at org.eclipse.osgi.framework.eventmgr.EventManager$EventThread.run(EventManager.java:337)

!ENTRY org.eclipse.osgi 4 0 2020-05-07 22:53:03.672
!MESSAGE Bundle initial@reference:file:plugins/org.eclipse.equinox.simpleconfigurator_1.0.200.v20100503.jar/ was not resolved.

!ENTRY org.eclipse.osgi 2 0 2020-05-07 22:53:03.679
!MESSAGE The following is a complete list of bundles which are not resolved, see the prior log entry for the root cause if it exists:
!SUBENTRY 1 org.eclipse.osgi 2 0 2020-05-07 22:53:03.679
!MESSAGE Bundle org.eclipse.equinox.simpleconfigurator_1.0.200.v20100503 [1] was not resolved.
!SUBENTRY 2 org.eclipse.equinox.simpleconfigurator 2 0 2020-05-07 22:53:03.679
!MESSAGE Missing Constraint: Bundle-RequiredExecutionEnvironment: CDC-1.1/Foundation-1.1,J2SE-1.4

!ENTRY org.eclipse.osgi 4 0 2020-05-07 22:53:03.680
!MESSAGE Application error
!STACK 1
java.lang.IllegalStateException: Unable to acquire application service. Ensure that the org.eclipse.core.runtime bundle is resolved and started (see config.ini).
        at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:74)
        at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:369)
        at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.base/java.lang.reflect.Method.invoke(Method.java:566)
        at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:620)
        at org.eclipse.equinox.launcher.Main.basicRun(Main.java:575)
        at org.eclipse.equinox.launcher.Main.run(Main.java:1408)
        at org.eclipse.equinox.launcher.Main.main(Main.java:1384)
</code></pre>

<p>Unfortunately I am both unfamiliar with Java and have had little success in finding a solution online.  Any help would be greatly appreciate. </p>

<p>Guide I used:
<a href=""https://linuxconfig.org/eclipse-ide-for-c-c-developers-installation-on-ubuntu-20-04"" rel=""nofollow noreferrer"">https://linuxconfig.org/eclipse-ide-for-c-c-developers-installation-on-ubuntu-20-04</a></p>
",1164,2,0,3,java;eclipse;ubuntu,2020-05-08 07:48:20,2020-05-08 07:48:20,2022-05-22 08:25:20,i am attempting to install eclipse for c c   manually since the version included in the ubuntu software center appears to be for java development only   i complete the steps include in the guide linked below   however when i attempt to launch i receive the below error  after this warning is displayed eclipse fails to launch  below is the error log entry in eclipse  unfortunately i am both unfamiliar with java and have had little success in finding a solution online   any help would be greatly appreciate  ,install eclipse for c c   in ubuntu   lts error crash on run
247,5128087,71273845,usbipd: warning: USB filter &#39;USBPcap&#39; is known to be incompatible with this software; &#39;bind --force&#39; will be required,"<p>I'm attempting to do embedded systems development within a WSL2 Linux (Ubuntu 20.04) and getting the error:</p>
<pre><code>usbipd: warning: USB filter 'USBPcap' is known to be incompatible with this software; 'bind --force' will be required. 
</code></pre>
<p>In powershell, running a <code>usbipd wsl list</code> is when I see the error 'bind --force' will be required (full output below).
I am unsure exactly why this occurs &amp; is required, the --force behavior is not documented / does not appear in a google search.  Example:</p>
<pre><code>PS C:\Users\Hidden&gt; usbipd wsl list
BUSID  DEVICE                                                        STATE
1-3    Logitech USB Input Device, USB Input Device                   Not attached
1-4    Printer XYZ Series, USB Printing Support, USB Mass Stor...    Not attached
1-7    USB Input Device                                              Not attached
1-8    USB Input Device                                              Not attached
1-10   Intel(R) Wireless Bluetooth(R)                                Not attached
1-11   USB 2.0 Webcam Device                                         Not attached
1-12   Realtek USB 2.0 Card Reader                                   Not attached

usbipd: warning: USB filter 'USBPcap' is known to be incompatible with this software; 'bind --force' will be required.
</code></pre>
<p>I'm using the Windows 11, insider stable release channel with all patches applied. WSL1 is slow, the disk bindings are different, it doesn't have WSLG (so I can't run Linux GUI software)</p>
<p>WSL2 has one major drawback - it does not <em>presently</em> support USB devices, that is unless you follow the instructions from Ben McMorran Senior Software Engineer, C++ Team @ Microsoft who writes about USBIPD which exports a USB device from the Windows Host using TCP/IP to the Linux machine here:</p>
<p><a href=""https://devblogs.microsoft.com/commandline/connecting-usb-devices-to-wsl/"" rel=""nofollow noreferrer"">https://devblogs.microsoft.com/commandline/connecting-usb-devices-to-wsl/</a></p>
<p>A google search turns up few if any useful tips/others related to --force.</p>
<p>I thought I'd post this question here to start a discussion for other people experiencing the same pain &amp; frustration feel being required to --force my USB ports.</p>
",1018,3,0,4,embedded;wsl-2;winpcap;windows-11,2022-02-26 05:25:59,2022-02-26 05:25:59,2022-05-22 00:17:19,i m attempting to do embedded systems development within a wsl linux  ubuntu    and getting the error  i m using the windows   insider stable release channel with all patches applied  wsl is slow  the disk bindings are different  it doesn t have wslg  so i can t run linux gui software  wsl has one major drawback   it does not presently support usb devices  that is unless you follow the instructions from ben mcmorran senior software engineer  c   team   microsoft who writes about usbipd which exports a usb device from the windows host using tcp ip to the linux machine here   a google search turns up few if any useful tips others related to   force  i thought i d post this question here to start a discussion for other people experiencing the same pain  amp  frustration feel being required to   force my usb ports ,usbipd  warning  usb filter    usbpcap    is known to be incompatible with this software     bind   force    will be required
248,19165656,72326795,Why is my Bootstrap div Alignment not working?,"<p>I have been trying to make a portfolio website for myself.
But for 'My works' div when I apply the Bootstrap class, I am not getting the result as I am expected to get. The alignment of the div is not in a grid.</p>
<p>Here's how it shows up:</p>
<p><a href=""https://i.stack.imgur.com/532Oj.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/532Oj.jpg"" alt=""enter image description here"" /></a></p>
<p>I am not able to fix this problem.</p>
<p>The HTML code:</p>
<pre><code>  &lt;meta charset=&quot;utf-8&quot;&gt;
  &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt;
  &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;
  &lt;meta name=&quot;description&quot; content=&quot;Responsive Portfolio Template&quot;&gt;
  &lt;meta name=&quot;author&quot; content=&quot;Suvrat Jain&quot;&gt;
  &lt;title&gt;Responsive Bootstrap Template for Portfolio&lt;/title&gt;
  &lt;!-- Bootstrap core CSS --&gt;
  &lt;link href=&quot;//netdna.bootstrapcdn.com/bootstrap/3.0.2/css/bootstrap.min.css&quot; rel=&quot;stylesheet&quot;&gt;
  &lt;link href=&quot;https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css&quot; rel=&quot;stylesheet&quot; integrity=&quot;sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN&quot; crossorigin=&quot;anonymous&quot;&gt;
&lt;/head&gt;

&lt;body&gt;
  &lt;div class=&quot;navbar navbar-inverse navbar-fixed-top&quot; role=&quot;navigation&quot; id=&quot;menu&quot;&gt;
    &lt;div class=&quot;container&quot;&gt;
      &lt;div class=&quot;navbar-header&quot;&gt;
        &lt;button type=&quot;button&quot; class=&quot;navbar-toggle&quot; data-toggle=&quot;collapse&quot; data-target=&quot;.navbar-collapse&quot;&gt;
          &lt;span class=&quot;sr-only&quot;&gt;Toggle navigation&lt;/span&gt;
          &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt;
          &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt;
          &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt;
        &lt;/button&gt;
        &lt;a class=&quot;navbar-brand&quot; href=&quot;#&quot;&gt;&lt;i class=&quot;fa fa-globe&quot;&gt;&lt;/i&gt;&lt;/a&gt;
      &lt;/div&gt;
      &lt;div class=&quot;collapse navbar-collapse&quot;&gt;
        &lt;ul class=&quot;nav navbar-nav&quot;&gt;
          &lt;li&gt;&lt;a href=&quot;#&quot;&gt;Home&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#about&quot;&gt;About&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#portfolio&quot;&gt;Portfolio&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#contact&quot;&gt;Contact&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/div&gt;
      &lt;!--/.nav-collapse --&gt;
    &lt;/div&gt;
  &lt;/div&gt;

  &lt;div class=&quot;container-fluid splash&quot; id=&quot;splash&quot;&gt;
    &lt;div class=&quot;container&quot;&gt;
      &lt;img src=&quot;https://s-media-cache-ak0.pinimg.com/736x/71/9e/59/719e59481d2be40a77ab6c3386fc0a45--photoshop-illustrator-illustrator-tutorials.jpg&quot; alt=&quot;Portrait of Mr. Roboto&quot; class=&quot;profile-image&quot;&gt;
      &lt;h1&gt;HELLO!&lt;/h1&gt;
      &lt;h1 class=&quot;intro-text&quot;&gt;&lt;span class=&quot;lead&quot; id=&quot;typed&quot;&gt;I am a &lt;/span&gt;&lt;/h1&gt;
      &lt;span class=&quot;continue&quot;&gt;&lt;a href=&quot;#about&quot;&gt;&lt;i class=&quot;fa fa-angle-down&quot;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/span&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;!-- About Section --&gt;
  &lt;section class=&quot;success&quot; id=&quot;about&quot;&gt;
    &lt;div class=&quot;container&quot;&gt;
      &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-lg-12 text-center&quot;&gt;
          &lt;h2&gt;About Me&lt;/h2&gt;
          &lt;hr class=&quot;star-light&quot;&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-lg-4 col-lg-offset-2&quot;&gt;
          &lt;p class=&quot;content-text&quot; style=&quot;text-align:justify;&quot;&gt;Hey there! I am a junior software developer based in Mumbai, India. I work with some of the popular front end technologies to create beautiful websites that get noticed. I seek experience to gain more knowledge in the web development field.
          &lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-lg-4&quot;&gt;
          &lt;p class=&quot;content-text&quot;&gt;If you are in need of a beautiful simple website, I'm your guy. I look forward to talking to you soon!&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-lg-8 col-lg-offset-2 text-center contact-button&quot;&gt;
          &lt;a href=&quot;#contact&quot; class=&quot;btn btn-lg btn-outline&quot;&gt;
            &lt;i class=&quot;fa fa-envelope&quot;&gt;&lt;/i&gt; Contact Me
          &lt;/a&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/section&gt;
  
  &lt;div class=&quot;container-fluid portfolio-container-holder content-section&quot; id=&quot;portfolio&quot;&gt;
        &lt;div class=&quot;portfolio-container container&quot;&gt;
            &lt;h1 class=&quot;text-center&quot;&gt;My Portfolio&lt;/h1&gt;
      &lt;hr class=&quot;star-portfolio&quot;&gt;
            &lt;div class=&quot;row&quot;&gt;
                
                &lt;div class=&quot;col-md-6 col-xs-11 col-sm-6 portfolio-card-holder&quot;&gt;
                    &lt;div class=&quot; portfolio-card&quot;&gt;
                        &lt;img src=&quot;https://i.ibb.co/QFX1CKL/8705c160752271.png&quot; alt=&quot;Portfolio&quot; class=&quot;img-responsive portfolio-img&quot;&gt;

                        &lt;div class=&quot;portfolio-img-desc&quot;&gt;
                            &lt;p&gt;Quantum Computing and cryptocurrency&lt;/p&gt;
                        &lt;/div&gt;          
                    &lt;/div&gt;
                &lt;/div&gt;
                
        &lt;div class=&quot;col-md-6 col-xs-11 col-sm-6 portfolio-card-holder&quot;&gt;
                    &lt;div class=&quot; portfolio-card&quot;&gt;
                        &lt;img src=&quot;https://i.ibb.co/GVr9drm/illu-app-modernization-whtbg.png&quot; alt=&quot;Portfolio&quot; class=&quot;img-responsive portfolio-img&quot;&gt;

                        &lt;div class=&quot;portfolio-img-desc&quot;&gt;
                            &lt;p&gt;Logistic Regression in Machine Learning&lt;/p&gt;
                        &lt;/div&gt;          
                    &lt;/div&gt;
                &lt;/div&gt;
        &lt;div class=&quot;col-md-6 col-xs-11 col-sm-6 portfolio-card-holder&quot;&gt;
                    &lt;div class=&quot; portfolio-card&quot;&gt;
                        &lt;img src=&quot;https://i.ibb.co/nwzg94P/0-Yb-Vi-GAYNXI51ek-E.png&quot; alt=&quot;Portfolio&quot; class=&quot;img-responsive portfolio-img&quot;&gt;

                        &lt;div class=&quot;portfolio-img-desc&quot;&gt;
                            &lt;p&gt;Introduction to Computer Vision&lt;/p&gt;
                        &lt;/div&gt;          
                    &lt;/div&gt;
                &lt;/div&gt;
        &lt;div class=&quot;col-md-6 col-xs-11 col-sm-6 portfolio-card-holder&quot;&gt;
                    &lt;div class=&quot; portfolio-card&quot;&gt;
                        &lt;img src=&quot;https://i.ibb.co/5vNfRC9/depositphotos-1245773-stock-photo-simple-math-example.png&quot; alt=&quot;Portfolio&quot; class=&quot;img-responsive portfolio-img&quot;&gt;

                        &lt;div class=&quot;portfolio-img-desc&quot;&gt;
                            &lt;p&gt;Addition of Two Numbers in Python&lt;/p&gt;
                        &lt;/div&gt;          
                    &lt;/div&gt;
                &lt;/div&gt;
                &lt;div class=&quot;col-md-6 col-xs-11 col-sm-6 portfolio-card-holder&quot;&gt;
                    &lt;div class=&quot; portfolio-card&quot;&gt;
                        &lt;img src=&quot;https://i.ibb.co/GVr9drm/illu-app-modernization-whtbg.png&quot; alt=&quot;Portfolio&quot; class=&quot;img-responsive portfolio-img&quot;&gt;

                        &lt;div class=&quot;portfolio-img-desc&quot;&gt;
                            &lt;p&gt;Logistic Regression in Machine Learning&lt;/p&gt;
                        &lt;/div&gt;          
                    &lt;/div&gt;
                &lt;/div&gt;
                &lt;div class=&quot;col-md-6 col-xs-11 col-sm-6 portfolio-card-holder&quot;&gt;
                    &lt;div class=&quot; portfolio-card&quot;&gt;
                        &lt;img src=&quot;https://i.ibb.co/nwzg94P/0-Yb-Vi-GAYNXI51ek-E.png&quot; alt=&quot;Portfolio&quot; class=&quot;img-responsive portfolio-img&quot;&gt;

                        &lt;div class=&quot;portfolio-img-desc&quot;&gt;
                            &lt;p&gt;AI: myths versus reality&lt;/p&gt;
                        &lt;/div&gt;          
                    &lt;/div&gt;
                &lt;/div&gt;
                &lt;div class=&quot;col-md-6 col-xs-11 col-sm-6 portfolio-card-holder&quot;&gt;
                    &lt;div class=&quot; portfolio-card&quot;&gt;
                        &lt;img src=&quot;https://i.ibb.co/nwzg94P/0-Yb-Vi-GAYNXI51ek-E.png&quot; alt=&quot;Portfolio&quot; class=&quot;img-responsive portfolio-img&quot;&gt;

                        &lt;div class=&quot;portfolio-img-desc&quot;&gt;
                            &lt;p&gt;Introduction to Computer Vision&lt;/p&gt;
                        &lt;/div&gt;          
                    &lt;/div&gt;
                &lt;/div&gt;
                
        &lt;div class=&quot;col-md-6 col-xs-11 col-sm-6 portfolio-card-holder&quot;&gt;
                    &lt;div class=&quot; portfolio-card&quot;&gt;
                        &lt;img src=&quot;https://i.ibb.co/nwzg94P/0-Yb-Vi-GAYNXI51ek-E.png&quot; alt=&quot;Portfolio&quot; class=&quot;img-responsive portfolio-img&quot;&gt;

                        &lt;div class=&quot;portfolio-img-desc&quot;&gt;
                            &lt;p&gt;Introduction to Computer Vision&lt;/p&gt;
                        &lt;/div&gt;          
                    &lt;/div&gt;
                &lt;/div&gt;
        
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
  
  &lt;!-- Contact form --&gt;
  &lt;div class=&quot;container-fluid contact-me-container content-section&quot; id=&quot;contact&quot;&gt;
    &lt;div class=&quot;container&quot;&gt;
      &lt;h1 class=&quot;intro-text text-center&quot;&gt;Contact Me&lt;/h1&gt;
      &lt;hr class=&quot;star-light&quot;&gt;
      &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-sm-12 col-md-12&quot;&gt;
          &lt;div class=&quot;form-group&quot;&gt;
            &lt;div class=&quot;input-group&quot;&gt;
              &lt;div class=&quot;input-group-addon&quot;&gt;&lt;i class=&quot;fa fa-user&quot;&gt;&lt;/i&gt;&lt;/div&gt;
              &lt;input type=&quot;text&quot; class=&quot;form-control&quot; id=&quot;name&quot; placeholder=&quot;Name&quot;&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&quot;form-group&quot;&gt;
            &lt;div class=&quot;input-group&quot;&gt;
              &lt;div class=&quot;input-group-addon&quot;&gt;&lt;i class=&quot;fa fa-at&quot;&gt;&lt;/i&gt;&lt;/div&gt;
              &lt;input type=&quot;text&quot; class=&quot;form-control&quot; id=&quot;email&quot; placeholder=&quot;Email ID&quot;&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&quot;form-group&quot;&gt;
            &lt;div class=&quot;input-group&quot;&gt;
              &lt;div class=&quot;input-group-addon&quot;&gt;&lt;i class=&quot;fa fa-phone&quot;&gt;&lt;/i&gt;&lt;/div&gt;
              &lt;input type=&quot;text&quot; class=&quot;form-control&quot; id=&quot;phone&quot; placeholder=&quot;Phone Number&quot;&gt;
            &lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class=&quot;col-sm-12&quot;&gt;
          &lt;textarea class=&quot;form-control&quot; rows=&quot;5&quot; placeholder=&quot;Message&quot;&gt;&lt;/textarea&gt;
        &lt;/div&gt;
      &lt;/div&gt;

      &lt;div class=&quot;text-center&quot;&gt;
        &lt;button class=&quot;btn btn-default submit-button btn-lg btn-primary&quot;&gt;&lt;i class=&quot;fa fa-paper-plane&quot;&gt;&lt;/i&gt; Send&lt;/button&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;!-- Footer --&gt;
  &lt;footer&gt;
    &lt;div class=&quot;container footer-container&quot;&gt;
      &lt;div class=&quot;row footer-row&quot;&gt;
        &lt;div class=&quot;col-xs-12 col-sm-6 col-md-6 text-center&quot;&gt;
          &lt;h4 class=&quot;text-center&quot;&gt;Find me here&lt;/h4&gt;
          &lt;address&gt; &lt;strong&gt;&lt;i class=&quot;fa fa-location-arrow&quot;&gt;&lt;/i&gt; Monsters Inc.&lt;/strong&gt;&lt;br&gt;Lorem ipsum dolor, sir amet,&lt;br&gt;Aurangabad, India 431001&lt;br&gt;&lt;br&gt;&lt;a class=&quot;tel&quot; href=&quot;tel:9999988888&quot; type=&quot;tel&quot;&gt;&lt;i class=&quot;fa fa-mobile&quot;&gt;&lt;/i&gt;&lt;span&gt; +91 &lt;/span&gt;&lt;/a&gt;&lt;/address&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-xs-12 col-md-6 col-sm-6 social-section&quot;&gt;
          &lt;div class=&quot;text-center&quot;&gt;
            &lt;h4 class=&quot;text-center&quot;&gt;Also, I can be found here&lt;/h4&gt;
            &lt;div class=&quot;text-center social-buttons&quot;&gt;

              &lt;a href=&quot;https://www.linkedin.com/in/simplysuvi&quot; class=&quot;btn btn-default btn-lg social-button link-linkedin&quot;&gt;&lt;i class=&quot;fa fa-linkedin&quot;&gt;&lt;/i&gt;
              &lt;/a&gt;
              &lt;a href=&quot;https://instagram.com/simplysuvi&quot; class=&quot;btn btn-default btn-lg social-button link-instagram&quot;&gt;&lt;i class=&quot;fa fa-instagram&quot;&gt;&lt;/i&gt;
              &lt;/a&gt;
            &lt;/div&gt;
            &lt;hr class=&quot;footer-hr&quot;&gt;
            &lt;h4 class=&quot;author&quot;&gt;Made with &lt;i class=&quot;fa fa-heart&quot;&gt;&lt;/i&gt; by &lt;strong&gt;Akshra Dube&lt;/strong&gt;&lt;/h4&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/footer&gt;

  &lt;!-- Bootstrap core JavaScript --&gt;
  &lt;script src=&quot;//code.jquery.com/jquery-1.10.2.min.js&quot;&gt;&lt;/script&gt;
  &lt;script src=&quot;//netdna.bootstrapcdn.com/bootstrap/3.0.2/js/bootstrap.min.js&quot;&gt;&lt;/script&gt;
&lt;/body&gt;

&lt;/html&gt;
</code></pre>
",25,1,0,5,html;twitter-bootstrap;twitter-bootstrap-3;web-development-server;portfolio,2022-05-21 07:59:11,2022-05-21 07:59:11,2022-05-21 18:39:55,here s how it shows up   i am not able to fix this problem  the html code ,why is my bootstrap div alignment not working 
249,18235030,72216820,Creating a Passport.js Config Export File and Import into Index.js,"<p>Although I am pretty new to software development, I have an intermediate understanding of exporting and importing data between files. However, for some reason, when trying to create a config file for Passport.js and trying to import that file into my Index.js file, I hit a brick wall. Something tells me that it could be a rookie mistake, but I'm almost sure that I probably need to move some functions over. Any advice would genuinely do. My code is below for a visual view.</p>
<p>Passport.JS</p>
<pre><code>const passport = require('passport');
const LocalStrategy = require('passport-local').Strategy;
const express = require('express');
const app = express();
const bodyParser = require('body-parser');
const mysql = require('mysql2');
const crypto = require('crypto');
const session = require('express-session');
const SqlDbStore = require('express-mysql-session')(session);
const db = require('./db');

app.use(session({
   key: 'session_cookie_name',
   secret: 'session_cookie_secret',
   store: new SqlDbStore({
   host: 'localhost',
   port: 3306,
   user: 'root',
   password: 'xxxxxxxxxx',
   database: 'xxxxxxxxxx',
   }),
   resave: false,
   saveUninitialized: false,
   cookie:{
       maxAge:1000*60*60*24,
   }
}));
 app.use(passport.initialize());
 app.use(passport.session());
 app.use(bodyParser.json());
 app.use(express.static('public'));
 app.use(express.static(__dirname + '/views'));

 db.connect((err) =&gt; {
     if (!err) {
         console.log(&quot;BD Connected&quot;);
     } else {
         console.log(&quot;BD Conection Failed&quot;);
         console.log(err.message);
     }
  });

 const customFields={
     firstNameField: 'usersFirstName',
     lastNameField: 'usersLastName',
     emailField: 'usersEmail',
     passwordField:'usersPassword',
     confirmPasswordField:'usersConfirmedPassword'
 };
 /*Passport JS*/
 const verifyCallback=(email,password,done)=&gt;{
     connection.query('SELECT * FROM USER WHERE usersEmail= ?', [email], function(error, results, fields) {
         if (error) {
             console.log('query error: ' + error);
             return done(error);
         }

         if(results.length==0) {
              return done(null,false, {message: 'Account is not recognized.'});
         }

         const isValid=validPassword(password, results[0].EncryptHash, results[0].EncryptPassword);
         user={id:results[0].ID, email:results[0].usersEmail, hash:results[0].EncryptHash, password:results[0].EncryptPassword};
         if(isValid) {
             return done(null,user);
         } else {
             return done(null,false, {message: 'Password is incorrect.'});
         }     
     });
 };
 const strategy = new LocalStrategy(customFields, verifyCallback);
 passport.use(strategy);
 passport.serializeUser((user,done)=&gt;{
     console.log(&quot;Inside serialize&quot;);
     done(null, user.id);
 });
 passport.deserializeUser(function(userId, done) {
     console.log('deserializeUser');
     connection.query('SELECT * FROM User WHERE ID = ? ', [userId], function(error, results) {
         done(null, results[0]);
     });
 });
 /*middleware*/
 function validPassword(password, hash, salt){    
     const hashVerify=crypto.pbkdf2Sync(password, salt, 10000, 60, 'sha512').toString(&quot;hex&quot;);
     return hash === hashVerify;
 };
 function genPassword(password) {
     var salt=crypto.randomBytes(32).toString('hex');
     var genhash=crypto.pbkdf2Sync(password, salt, 10000, 60, 'sha512').toString('hex');
     return {salt:salt, hash:genhash}
 };
 function checkAuthentication(req,res,next){
     if(req.isAuthenticated()){
         //req.isAuthenticated() will return true if user is logged in
         next();
     } else {
         res.redirect(&quot;/login&quot;);
     }
 };
</code></pre>
<p>Index.JS</p>
<pre><code>const express = require('express');
const router = express.Router();
const db = require('../config/db');
const passport = require('../config/passport');
const routes = require('')('passport');


router.post('/register', (req, res) =&gt; {
    const firstName = req.body.firstName;
    const lastName = req.body.lastName;
    const email = req.body.email;
    const password = req.body.password;
    const saltHash = genPassword(password);
    const salt = passport.saltHash.salt;
    const hash = passport.saltHash.hash;

    db.query('SELECT * FROM Users WHERE UsersEmail = ? ', [email], (err, results) =&gt; {
        if (err){
            console.log(err)
        } else if (results.length &gt; 0) {
            res.json({ message: 'Email is already registered!' });
        } else {
            db.query('INSERT INTO Users (UsersFirstName, UsersLastName, UsersEmail, UsersPasswordHash, UsersPasswordSalt) VALUES (?, ?, ?, ?, ?)', [firstName, lastName, email, hash, salt], (err, results) =&gt; {
                if (err){
                    console.log(err);
                };
                res.send(results);
            });
        }
    })
});

router.post('/login', passport.authenticate('local'));

module.exports = {router, passport};
</code></pre>
<p>Update:
Question is reposted with more information on <a href=""https://stackoverflow.com/questions/72219826/export-and-import-passport-js-issues"">Export and Import Passport.JS Issues</a>.</p>
",48,1,0,4,javascript;node.js;reactjs;passport.js,2022-05-12 16:49:49,2022-05-12 16:49:49,2022-05-21 17:32:20,although i am pretty new to software development  i have an intermediate understanding of exporting and importing data between files  however  for some reason  when trying to create a config file for passport js and trying to import that file into my index js file  i hit a brick wall  something tells me that it could be a rookie mistake  but i m almost sure that i probably need to move some functions over  any advice would genuinely do  my code is below for a visual view  passport js index js,creating a passport js config export file and import into index js
250,18222676,72273515,Sdist showing error while uploading package to pypi,"<p>I am building a Python Module, and am following <a href=""https://medium.com/@joel.barmettler/how-to-upload-your-python-package-to-pypi-65edc5fe9c56"" rel=""nofollow noreferrer"">this tutorial</a>.
However when I run <code>python setup.py sdist</code>, I get:</p>
<pre class=""lang-sh prettyprint-override""><code>running sdist
running check
warning: sdist: manifest template 'MANIFEST.in' does not exist (using default file list)

error: package directory 'packagename' does not exist
</code></pre>
<p>Here is my directory structure:</p>
<pre><code>packagename  
-setup.py  
-setup.cfg  
-LICENSE  
-README  
-__init__.py   
-(All other files)
</code></pre>
<p>Setup.py file (I have replaced things like package names, authors, urls with placeholders.):</p>
<pre class=""lang-py prettyprint-override""><code>from distutils.core import setup
setup(
  name = 'packagename',
  packages = ['packagename'],
  version = '0.1.1',
  license='MIT',
  description = 'description',
  author = 'authorname',
  author_email = 'someone@somewhere.tld',
  url = 'url',
  download_url = 'url',
  keywords = ['GUI', 'Python', 'Tkinter', 'Simple'],
  classifiers=[
    'Development Status :: 4 - Beta',      # Choose either &quot;3 - Alpha&quot;, &quot;4 - Beta&quot; or &quot;5 - Production/Stable&quot; as the current state of your package
    'Intended Audience :: Developers',
    'Topic :: Software Development :: Build Tools',
    'License :: OSI Approved :: MIT License',
    'Programming Language :: Python :: 3.6',
    'Programming Language :: Python :: 3.7',
    'Programming Language :: Python :: 3.8',
    'Programming Language :: Python :: 3.9',
  ],
)
</code></pre>
",31,1,0,5,python;pip;pypi;setup.py;sdist,2022-05-17 14:48:19,2022-05-17 14:48:19,2022-05-21 15:14:43,here is my directory structure  setup py file  i have replaced things like package names  authors  urls with placeholders   ,sdist showing error while uploading package to pypi
251,8740349,48203021,JTextField render bug if Text-Not-Fitting (JDK 7 till 18),"<h2>JTextField has wrong text render on RIGHT_TO_LEFT component orientation</h2>
<p>We need a <strong>workaround</strong>, since whenever <code>JTextField</code> is filled with text that contains:</p>
<ul>
<li><code>Right to left text</code> like Arabic,</li>
<li><code>Latin numbers</code>,</li>
<li>and <code>Latin text</code>.</li>
</ul>
<p>Then <code>JTextField</code> renders text parts at unexpected locations.</p>
<blockquote>
<p>(It only renders right if the complete text Fits inside the <code>JTextField</code>.)</p>
</blockquote>
<p>The text we use to reproduce is:</p>
<ul>
<li><code>صندوق ۴۰×۳۰ پایه دار وایرنگ میتر تک فاز</code></li>
</ul>
<p><strong>Other info</strong>:</p>
<ul>
<li>Above text is just name of a product, added inside an accounting software we created, but our users have match more render failures than we could reproduce.</li>
<li>We reported at: <a href=""http://bugs.java.com/bugdatabase/view_bug.do?bug_id=JDK-8194733"" rel=""nofollow noreferrer"">JDK-8194733</a></li>
<li>We have no experience with a custom-render in Java to make workaround, but render of entire text not considering the limit, and clipping that, should do the trick.</li>
</ul>
<hr />
<h1>Source code for an executable test case:</h1>
<pre class=""lang-java prettyprint-override""><code>//
// Like you may notice, below code shows simple JTextField, 
// but once you resize the Window smaller than the text Fits,
// then you experience numbers dancing (moving around randomly).
//
// And trying to select parts of text is even more fatal (random parts are rendered).
//
package test;

import java.awt.ComponentOrientation;

public class JavaBug extends javax.swing.JFrame {

    public static void main(String[] args) {
        JavaBug frame = new JavaBug();
        frame.show();
    }
    
    public JavaBug() {
        javax.swing.JTextField textField = new javax.swing.JTextField();
        
        textField.setFont(new java.awt.Font(&quot;Tahoma&quot;, 0, 24)); // NOI18N
        
        // Below is just name of a product, added inside an accounting software.
        textField.setText(&quot;\u0635\u0646\u062F\u0648\u0642 \u06F4\u06F0×\u06F3\u06F0 \u067E\u0627\u06CC\u0647 \u062F\u0627\u0631 \u0648\u0627\u06CC\u0631\u0646\u06AF \u0645\u06CC\u062A\u0631 \u062A\u06A9 \u0641\u0627\u0632&quot;);
        textField.setComponentOrientation(ComponentOrientation.RIGHT_TO_LEFT);
        
        getContentPane().add(textField);
        pack();
        this.setLocationRelativeTo(null); //enusre get showed at screen center
        setDefaultCloseOperation(javax.swing.WindowConstants.EXIT_ON_CLOSE);
    }
}
</code></pre>
<h3>Screen shots</h3>
<p>Just running above code results to:<br />
<img src=""https://i.stack.imgur.com/3VwMg.jpg"" alt=""just run"" /></p>
<p>After resize, to something less:<br />
<img src=""https://i.stack.imgur.com/9BKMv.jpg"" alt=""after resize"" /></p>
<hr />
<p>Development Kit or Runtime version:</p>
<ul>
<li>java version &quot;1.8.0_25&quot;</li>
<li>Java(TM) SE Runtime Environment (build 1.8.0_25-b18)</li>
<li>Java HotSpot(TM) Client VM (build 25.25-b02, mixed mode)</li>
</ul>
",410,1,0,5,java;swing;rendering;custom-controls;jtextfield,2018-01-11 10:54:50,2018-01-11 10:54:50,2022-05-21 11:16:05,we need a workaround  since whenever jtextfield is filled with text that contains  then jtextfield renders text parts at unexpected locations   it only renders right if the complete text fits inside the jtextfield   the text we use to reproduce is  other info  development kit or runtime version ,jtextfield render bug if text not fitting  jdk  till  
252,562532,72320387,Best way to setup Git for multiple parallel and related projects,"<p>I'm currently maintaining multiple git repos that all are related to the same overall project. For simplicity, call them Hardware (HW), Software (SW), and User interface (UI). Since these are separate repos, a new feature that spanns multiple sub-projects must be committed separately in each repo. This makes it difficult to track changes across sub-project borders, and increases overhead work. What is a better git setup to facilitate full-stack development?</p>
<p><strong>Option 1:</strong>
I have considered merging these into a Main repo, with each sub-project in a subfolder:</p>
<pre><code>Main
\- HW
\- SW
\- UI
</code></pre>
<p>This way a single commit can affect all three parts. The only downside I see is that developers that only work on one sub-project must still checkout the full Main repo, then never touch the other folders.</p>
<p><strong>Option 2:</strong>
I have also considered placing the three sub-projects as submodules in the Main project. This would allow a developer to checkout only the required sub-project. However, if I understand correctly, changes that span multiple sub-projects would still have to be committed separately in the submodules, thus loosing the benefit of a Main project. Please correct me if I'm wrong about this part.</p>
<p>So given this project structure and my two suggestions, which is considered the better choice? Or is there a third option that would work even better? I'm currently favoring option 1 to have the more directly connected structure, but any opinions are welcome.</p>
",22,0,0,1,git,2022-05-20 17:14:44,2022-05-20 17:14:44,2022-05-20 17:14:44,i m currently maintaining multiple git repos that all are related to the same overall project  for simplicity  call them hardware  hw   software  sw   and user interface  ui   since these are separate repos  a new feature that spanns multiple sub projects must be committed separately in each repo  this makes it difficult to track changes across sub project borders  and increases overhead work  what is a better git setup to facilitate full stack development  this way a single commit can affect all three parts  the only downside i see is that developers that only work on one sub project must still checkout the full main repo  then never touch the other folders  so given this project structure and my two suggestions  which is considered the better choice  or is there a third option that would work even better  i m currently favoring option  to have the more directly connected structure  but any opinions are welcome ,best way to setup git for multiple parallel and related projects
253,7739532,72311291,Should I refrain from manually specifying serialVersionUID to make an object serializable?,"<p>I am currently experimenting with sending serialized objects over sockets in Java, and I have come across a scenario where I am trying to send an object containing data to a client whose class definition matches the server's other than the client's definition implements an abstract method (the method isn't even declared in the server's class definition).</p>
<p><strong>Client Command class definition</strong></p>
<pre><code>package lol;

import java.io.Serializable;

public abstract class Command implements Serializable
{
    public static final long serialVersionUID = 1;
    public final String[] args;

    public Command(String[] args)
    {
        this.args = args;
    }

    public abstract void execute();
}
</code></pre>
<p><strong>Client Print class definition</strong></p>
<pre><code>package lol;

public class Print extends Command
{
    public Print(String[] args)
    {
        super(args);
    }

    @Override
    public void execute()
    {
        System.out.println(args[0]);
    }
}
</code></pre>
<p><strong>Client main class</strong></p>
<pre><code>package client;

import lol.Command;

import java.io.IOException;
import java.io.ObjectInputStream;
import java.net.Socket;

public class Client
{
    private static Socket s = null;

    public static void main(String[] args) throws IOException, ClassNotFoundException
    {
        s = new Socket(&quot;127.0.0.1&quot;, 1000);
        System.out.println(&quot;[*] Connected to host &quot; + s.getInetAddress());
        ObjectInputStream in = new ObjectInputStream(s.getInputStream());
        Command command = (Command) in.readObject();
        command.execute();
        s.close();
    }
}
</code></pre>
<p><strong>Server Command class definition</strong></p>
<pre><code>package lol;

import java.io.Serializable;

public class Command implements Serializable
{
    public static final long serialVersionUID = 1;
    public final String[] args;

    public Command(String[] args)
    {
        this.args = args;
    }
}
</code></pre>
<p><strong>Server Print class definition</strong></p>
<pre><code>package lol;

public class Print extends Command
{
    public Print(String[] args)
    {
        super(args);
    }
}
</code></pre>
<p><strong>Server main class</strong></p>
<pre><code>package server;

import lol.Command;
import lol.Print;

import java.io.IOException;
import java.io.ObjectOutputStream;
import java.net.ServerSocket;
import java.net.Socket;

public class Server
{
    private static ServerSocket ss = null;

    public static void main(String[] args) throws IOException
    {
        ss = new ServerSocket(1000);
        Socket s = ss.accept();
        ObjectOutputStream out = new ObjectOutputStream(s.getOutputStream());
        out.writeObject(new Print(new String[]{&quot;hi!&quot;}));
        s.close();
        ss.close();
    }
}
</code></pre>
<p>As you can see, there is really no need for me to implement <code>execute()</code> in the server as it will never be called, and the object is instead used to invoke a method on the client, however the class definitions do not match and so I have to set a custom <code>serialVersionUID</code>. Is this a bad practice in the world of software development? If so, what alternatives can I use?</p>
",21,0,0,4,java;sockets;serialization;serialversionuid,2022-05-20 00:31:07,2022-05-20 00:31:07,2022-05-20 00:31:07,i am currently experimenting with sending serialized objects over sockets in java  and i have come across a scenario where i am trying to send an object containing data to a client whose class definition matches the server s other than the client s definition implements an abstract method  the method isn t even declared in the server s class definition   client command class definition client print class definition client main class server command class definition server print class definition server main class as you can see  there is really no need for me to implement execute   in the server as it will never be called  and the object is instead used to invoke a method on the client  however the class definitions do not match and so i have to set a custom serialversionuid  is this a bad practice in the world of software development  if so  what alternatives can i use ,should i refrain from manually specifying serialversionuid to make an object serializable 
254,359298,3735217,Linear feedback shift register?,"<p>Lately I bumped repeatedly into the concept of LFSR, that I find quite interesting because of its links with different fields and also fascinating in itself. It took me some effort to understand, the final help was this really good <a href=""https://web.archive.org/web/20120616135434/http://homepage.mac.com:80/afj/lfsr.html"" rel=""nofollow noreferrer"">page</a>, much better than the (at first) cryptic <a href=""http://en.wikipedia.org/wiki/Linear_feedback_shift_register"" rel=""nofollow noreferrer"">wikipedia entry</a>. So I wanted to write some small code for a program that worked like a LFSR. To be more precise, that somehow showed how a LFSR works. Here's the cleanest thing I could come up with after some lenghtier attempts (Python):</p>
<pre><code>def lfsr(seed, taps):
    sr, xor = seed, 0
    while 1:
        for t in taps:
            xor += int(sr[t-1])
        if xor%2 == 0.0:
            xor = 0
        else:
            xor = 1
        print(xor)
        sr, xor = str(xor) + sr[:-1], 0
        print(sr)
        if sr == seed:
            break

lfsr('11001001', (8,7,6,1))      #example
</code></pre>
<p>I named &quot;xor&quot; the output of the XOR function, not very correct.
However, this is just meant to show how it circles through its possible states, in fact you noticed the register is represented by a string. Not much logical coherence.</p>
<p>This can be easily turned into a nice toy you can watch for hours (at least I could :-)</p>
<pre><code>def lfsr(seed, taps):
    import time
    sr, xor = seed, 0
    while 1:
        for t in taps:
            xor += int(sr[t-1])
        if xor%2 == 0.0:
            xor = 0
        else:
            xor = 1
        print(xor)
        print('')
        time.sleep(0.75)
        sr, xor = str(xor) + sr[:-1], 0
        print(sr)
        print('')
        time.sleep(0.75)
</code></pre>
<p>Then it struck me, what use is this in writing software? I heard it can generate random numbers; is it true? how?
So, it would be nice if someone could:</p>
<ul>
<li>explain how to use such a device in software development</li>
<li>come up with some code, to support the point above or just like mine to show different ways to do it, in any language</li>
</ul>
<p>Also, as theres not much didactic stuff around about this piece of logic and digital circuitry, it would be nice if this could be a place for noobies (like me) to get a better understanding of this <em>thing</em>, or better, to understand what it is and how it can be useful when writing software. Should have made it a community wiki?</p>
<p>That said, if someone feels like golfing... you're welcome.</p>
",26673,10,11,3,python;language-agnostic;digital-logic,2010-09-17 15:16:11,2010-09-17 15:16:11,2022-05-19 22:46:59,lately i bumped repeatedly into the concept of lfsr  that i find quite interesting because of its links with different fields and also fascinating in itself  it took me some effort to understand  the final help was this really good   much better than the  at first  cryptic   so i wanted to write some small code for a program that worked like a lfsr  to be more precise  that somehow showed how a lfsr works  here s the cleanest thing i could come up with after some lenghtier attempts  python   this can be easily turned into a nice toy you can watch for hours  at least i could     also  as theres not much didactic stuff around about this piece of logic and digital circuitry  it would be nice if this could be a place for noobies  like me  to get a better understanding of this thing  or better  to understand what it is and how it can be useful when writing software  should have made it a community wiki  that said  if someone feels like golfing    you re welcome ,linear feedback shift register 
255,6636638,65129883,Drupal Local Development Setup/Environment,"<h1>Background</h1>
<p>I have been developing Drupal Sites for a little over 2 years now and I have noticed that my dev environments are not as user friendly and as simple as I have expected. The current process is we have a git repo where we store all the code, then we have a vagrant box setup as our virtual machine to run our local development in. The issue comes along with the fact of constantly having to go through loop holes of trying to get everything to work well together. Or there will be issues with composer (<em>which is getting real finicky</em>)</p>
<p>For example trying to make sure that my macOS version still supports php. Or to make sure the version of vagrant works with the current version of VirtualBox. The biggest pain comes from trying to set everything up in one simple go. There is always some sort of tweak that has to be made to the local system to make everything congeal. Then the whole blt setup process once I am logged into the vagrant is time consuming as well.</p>
<p>I have also taken a Drupal Acquia Developer course but this course, in here the professor said proposed that we should use <a href=""https://www.acquia.com/drupal/acquia-dev-desktop"" rel=""nofollow noreferrer"">DevDesktop</a>. This process did seem slightly easier but I did not like how it was another &quot;do it the Drupal way&quot;. I understand seeing that this came from the the actual company as the professor software it might be considered best practice but still want to hear more.</p>
<h1>Question</h1>
<p>I have received an email about the <a href=""https://www.acquia.com/blog/getting-started-acquia-cloud-ide-code-editor-service"" rel=""nofollow noreferrer"">Acquia Cloud IDE</a> which does look very interesting but I believe it is another service that we would have to pay for. My question for you all, is what are some of the best practice that you all follow for local development? Are there things I should look into and</p>
<h1>TL;DR</h1>
<p>Background:</p>
<ul>
<li>use acquia site factory for all sites</li>
<li>we deploy from local to dev using blt artifacts</li>
<li>environment is done using a <a href=""https://www.drupalvm.com"" rel=""nofollow noreferrer"">Drupal-VM</a> vagrant box (which gets out of hand and uncontrollable fast when trying to set it all up)</li>
<li>Since we are using lightning core we are told we must use Macs, I would like to make it so this development can be done on any machine.</li>
</ul>
<p><strong>Question</strong></p>
<ul>
<li>Does anyone here use <a href=""https://www.acquia.com/drupal/acquia-dev-desktop"" rel=""nofollow noreferrer"">DevDesktop</a> or <a href=""https://www.acquia.com/blog/getting-started-acquia-cloud-ide-code-editor-service"" rel=""nofollow noreferrer"">Acquia Cloud IDE</a> and have any feedback or pros/cons about these?</li>
<li>Any recommendations or information of what you all currently are implementing?</li>
<li>What are the leading standards?</li>
<li>What technology can I utilize that can be setup or used on any computer regardless of OS? (Hopefully a cost-free solution)</li>
</ul>
",96,2,2,5,drupal;vagrant;virtual-machine;drupal-8;acquia,2020-12-03 18:20:10,2020-12-03 18:20:10,2022-05-19 20:43:50,i have been developing drupal sites for a little over  years now and i have noticed that my dev environments are not as user friendly and as simple as i have expected  the current process is we have a git repo where we store all the code  then we have a vagrant box setup as our virtual machine to run our local development in  the issue comes along with the fact of constantly having to go through loop holes of trying to get everything to work well together  or there will be issues with composer  which is getting real finicky  for example trying to make sure that my macos version still supports php  or to make sure the version of vagrant works with the current version of virtualbox  the biggest pain comes from trying to set everything up in one simple go  there is always some sort of tweak that has to be made to the local system to make everything congeal  then the whole blt setup process once i am logged into the vagrant is time consuming as well  i have also taken a drupal acquia developer course but this course  in here the professor said proposed that we should use   this process did seem slightly easier but i did not like how it was another  do it the drupal way   i understand seeing that this came from the the actual company as the professor software it might be considered best practice but still want to hear more  i have received an email about the  which does look very interesting but i believe it is another service that we would have to pay for  my question for you all  is what are some of the best practice that you all follow for local development  are there things i should look into and background  question,drupal local development setup environment
256,10209198,72302912,Configurable data model - How to not re-invent the wheel?,"<p>So my company decided that it needs some kind of system / service that has the following properties:</p>
<ul>
<li>Uses Java and Spring-Boot as a Back-End</li>
<li>Has an Angular Front-End for and Admin UI</li>
<li>Uses mongoDB for persistence</li>
</ul>
<p>The system should include following functionality:</p>
<p>Users (Experts, Data-Engineers, Developers) should be able to define the data model including dynamic types having a set of properties and relationships via an Admin UI.</p>
<p>The system should support multi-tenancy, meaning that it should integrate multiple clients from different tenants.</p>
<p>It is important, that different clients have different projections of the data when reading, meaning that not all clients are allowed to read all the properties of an entity, but are restricted to what has been configured for them.</p>
<p>There must be some kind of validation for the properties (e.g. if it is of type string it must follow a common pattern, if it is of type enum only certain values are accepted)</p>
<hr />
<p>I did some research and came to the conclusion that there are certain drawbacks with this proposed solution being:</p>
<ul>
<li>using java for handling dynamic types</li>
<li>favoring abstract code instead of an explicit data model violating the &quot;use before re-use principle&quot;</li>
</ul>
<p>I also fear, that we are re-inventing the wheel - meaning that there might be existing solutions for dynamically defining a data model.
I have to take these decisions as a given and try to find a way to still use existing implementations as far as possible.</p>
<p>In the end it will adapt a pattern similar to the EAV model. In my opinion there will be almost no possibility to adapt domain specific language and rules, since it aims to be as abstract as possible. It seems to me that it is a clear case of the inner-platform-effect, meaning that it will be result in a system that is</p>
<blockquote>
<p>&quot;so customizable as to become a replica, and often a poor replica, of
the software development platform they are using&quot;</p>
</blockquote>
<hr />
<p>Nonetheless I have to deliver some kind of implementation which has to move within this frame.</p>
<p>I don't want to re-invent the wheel and create a proprietary solution - so I am thinking about using at least some standard for solving this issue, as for example generating json-schema from the user configuration instead of inventing my own data structures and validation logic.</p>
<p>Has anyone experience with json-schema and dialects or can point me to any other solution that I can adapt to make my life easier without having to come up with a home-made solution?</p>
<p>PS: I am not sure if these design questions belong to SO or any other place, so please let me know if you think I misused SO</p>
",92,0,0,5,java;mongodb;architecture;jsonschema;software-design,2022-05-19 13:27:18,2022-05-19 13:27:18,2022-05-19 13:27:18,so my company decided that it needs some kind of system   service that has the following properties  the system should include following functionality  users  experts  data engineers  developers  should be able to define the data model including dynamic types having a set of properties and relationships via an admin ui  the system should support multi tenancy  meaning that it should integrate multiple clients from different tenants  it is important  that different clients have different projections of the data when reading  meaning that not all clients are allowed to read all the properties of an entity  but are restricted to what has been configured for them  there must be some kind of validation for the properties  e g  if it is of type string it must follow a common pattern  if it is of type enum only certain values are accepted  i did some research and came to the conclusion that there are certain drawbacks with this proposed solution being  in the end it will adapt a pattern similar to the eav model  in my opinion there will be almost no possibility to adapt domain specific language and rules  since it aims to be as abstract as possible  it seems to me that it is a clear case of the inner platform effect  meaning that it will be result in a system that is nonetheless i have to deliver some kind of implementation which has to move within this frame  i don t want to re invent the wheel and create a proprietary solution   so i am thinking about using at least some standard for solving this issue  as for example generating json schema from the user configuration instead of inventing my own data structures and validation logic  has anyone experience with json schema and dialects or can point me to any other solution that i can adapt to make my life easier without having to come up with a home made solution  ps  i am not sure if these design questions belong to so or any other place  so please let me know if you think i misused so,configurable data model   how to not re invent the wheel 
257,3725208,72261911,V4L-Utils &amp; Vitis 2021.2 Build Instructions,"<p>I'm trying to build V4L-Utils using the <a href=""https://xilinx-wiki.atlassian.net/wiki/spaces/A/pages/18842180/V4L-Utils+Libdrm+Build+Instructions"" rel=""nofollow noreferrer"">instructions</a></p>
<p>System:</p>
<ul>
<li>Vitis 2021.2,</li>
<li>Ubuntu 20.04.4 LTS</li>
</ul>
<p>Setup:</p>
<pre><code>~$ source /tools/Xilinx/Vivado/2021.2/settings64.sh
~$ source /home/max/petalinux/2021.2/settings.sh
~$ export INSTALL_PREFIX=/usr
~$ ./configure --prefix=$INSTALL_PREFIX --host=arm-linux-gnueabihf --without-jpeg --with-udevdir=$INSTALL_PREFIX/lib/udev
 
...
compile time options summary
============================
 
    Host OS                    : linux-gnueabihf
    X11                        : yes
    GL                         : yes
    glu                        : yes
    libelf             : no
    libjpeg                    : 
    libudev                    : yes
    pthread                    : yes
    QT version                 : none
    ALSA support               : yes
    SDL support            : no
 
    build dynamic libs         : yes
    build static libs          : yes
 
    gconv                      : no
 
    dynamic libv4l             : yes
    v4l_plugins                : yes
    v4l_wrappers               : yes
    libdvbv5                   : yes
    dvbv5-daemon               : yes
    v4lutils                   : yes
    qv4l2                      : no
    qvidcap                    : no
    v4l2-ctl uses libv4l       : yes
    v4l2-ctl-32                : no
    v4l2-compliance            : yes
    v4l2-compliance uses libv4l: yes
    v4l2-compliance-32         : no
    BPF IR Decoders:           : no
 
~$ make 
...
  CC       libdvbv5_la-dvb-dev.lo
dvb-dev.c:19:10: fatal error: libudev.h: No such file or directory
   19 | #include &lt;libudev.h&gt;
      |          ^~~~~~~~~~~
compilation terminated.
</code></pre>
<p>I can confirm i have the <code>/usr/include/libudev.h</code> on my system...</p>
<p>The instruction is tied to the Xilinx Software Development Kit (SDK), so the question is how to build V4L-Utils with Vitis, if at all possible.</p>
",76,1,0,4,c;compilation;libraries;libudev,2022-05-16 10:38:45,2022-05-16 10:38:45,2022-05-19 13:13:32,i m trying to build vl utils using the  system  setup  i can confirm i have the  usr include libudev h on my system    the instruction is tied to the xilinx software development kit  sdk   so the question is how to build vl utils with vitis  if at all possible ,vl utils  amp  vitis   build instructions
258,107294,72283203,What&#39;s the best way to add a C include path when using `bundle install`?,"<p>As background, I have extensive knowledge of software build systems, Unix (I'm using Debian 11 in this instance) and Python environments, but almost no knowledge of modern Ruby environments.</p>
<p>I'm wanting to write a post in a friend's blog built with Jekyll and so am trying to get his blog building in development mode on my system. I'm wanting to minimise the amount of Ruby stuff I bring in using system packages, so I'm using <code>bundle install --path vendor/bundle</code> to set up the project dependencies, which include the <code>rmagick</code> gem.</p>
<p>I've installed the <code>libmagickcore-6.q16-dev</code> package, which gives me <code>/usr/include/ImageMagick-6/wand/MagickWand.h</code>. However, bundler is unable to install the RMagick 2.16.0 gem.</p>
<p>Looking in <code>vendor/bundle/ruby/2.7.0/extensions/x86_64-linux/2.7.0/rmagick-2.16.0/mkmf.log</code>, this seems to be the failure:</p>
<pre><code>have_header: checking for wand/MagickWand.h... -------------------- no
                                                                                
&quot;x86_64-linux-gnu-gcc -E -I/usr/include/x86_64-linux-gnu/ruby-2.7.0 -I/usr/include/ruby-2.7.0/ruby/backward -I/usr/include/ruby-2.7.0 -I.      conftest.c -o conftest.i&quot;
conftest.c:3:10: fatal error: wand/MagickWand.h: No such file or directory      
    3 | #include &lt;wand/MagickWand.h&gt;                                            
      |          ^~~~~~~~~~~~~~~~~~~
compilation terminated.
</code></pre>
<p>Without doing extensive further investigation, I'm guessing that this is due to the include path being incorrect. This kind of hints at the RMagick gem being broken, since <code>pkg-config</code> does supply this:</p>
<pre><code>$ pkg-config --cflags MagickCore
-fopenmp -DMAGICKCORE_HDRI_ENABLE=0 -DMAGICKCORE_QUANTUM_DEPTH=16 -I/usr/include/x86_64-linux-gnu//ImageMagick-6 -I/usr/include/ImageMagick-6
</code></pre>
<p>I'm not able to upgrade the Gems that he's using, nor even easily test that any changes I might make on my system work on the systems he's using. So to work around this I'd like to get  <code>bundle</code> to add <code>-I /usr/include/ImageMagick-6</code> (or do the moral equivalent).</p>
<p>What's the best way to make this happen? I don't see a <code>bundle</code> command line option for this. Perhaps there's an environment variable I can set?</p>
",26,1,1,2,ruby;rubygems,2022-05-18 07:24:43,2022-05-18 07:24:43,2022-05-18 08:02:45,as background  i have extensive knowledge of software build systems  unix  i m using debian  in this instance  and python environments  but almost no knowledge of modern ruby environments  i m wanting to write a post in a friend s blog built with jekyll and so am trying to get his blog building in development mode on my system  i m wanting to minimise the amount of ruby stuff i bring in using system packages  so i m using bundle install   path vendor bundle to set up the project dependencies  which include the rmagick gem  i ve installed the libmagickcore  q dev package  which gives me  usr include imagemagick  wand magickwand h  however  bundler is unable to install the rmagick    gem  looking in vendor bundle ruby    extensions x_ linux    rmagick    mkmf log  this seems to be the failure  without doing extensive further investigation  i m guessing that this is due to the include path being incorrect  this kind of hints at the rmagick gem being broken  since pkg config does supply this  i m not able to upgrade the gems that he s using  nor even easily test that any changes i might make on my system work on the systems he s using  so to work around this i d like to get  bundle to add  i  usr include imagemagick   or do the moral equivalent   what s the best way to make this happen  i don t see a bundle command line option for this  perhaps there s an environment variable i can set ,what   s the best way to add a c include path when using  bundle install  
259,138965,72281220,VS 2022 Community - Publish end up missing a view,"<p>I am new to software development and isn't very versed in publishing.  I am using visual studio 2022 community edition and is doing a test project.  The project works fine on Local, but when &quot;published to folder&quot; and then copied to web server 1 of the view is missing.</p>
<pre><code>System.InvalidOperationException: The view 'Components/RackDetails/OnRack' was not found. The following locations were searched:
/Pages/Components/Components/RackDetails/OnRack.cshtml
/Pages/Components/RackDetails/OnRack.cshtml
/Pages/Shared/Components/RackDetails/OnRack.cshtml
/Views/Shared/Components/RackDetails/OnRack.cshtml
</code></pre>
<p>Above is the error.</p>
<p>the view is located in /Pages/Components/RackDetails/OnRack.cshtml</p>
<p>It works fine in local so the view exists and is working.  I don't see any error messages when publishing.</p>
<p>Is there a setting somewhere that I am missing that somehow precluded this view from being included?</p>
",35,0,0,1,visual-studio-2022,2022-05-18 01:13:20,2022-05-18 01:13:20,2022-05-18 01:13:20,i am new to software development and isn t very versed in publishing   i am using visual studio  community edition and is doing a test project   the project works fine on local  but when  published to folder  and then copied to web server  of the view is missing  above is the error  the view is located in  pages components rackdetails onrack cshtml it works fine in local so the view exists and is working   i don t see any error messages when publishing  is there a setting somewhere that i am missing that somehow precluded this view from being included ,vs  community   publish end up missing a view
260,17129001,72275942,How to filter out multiple rows in a pandas.DataFrame based on multiple conditions for the same column,"<p>I have an exemplary pd.DataFrame containing codenames of software developed in different development studios:</p>
<pre class=""lang-py prettyprint-override""><code>df = pd.DataFrame({'project_id': [36423, 28564, 96648, 96648, 10042, 68277, 68277, 68277], 'codename': ['banana', 'apple', 'peach', 'peach', 'melon', 'pear', 'pear', 'pear'], 'studio': ['paris', 'amsterdam', 'frankfurt', 'paris', 'london', 'brussel', 'amsterdam', 'sofia']})
</code></pre>
<pre class=""lang-py prettyprint-override""><code>      id codename     studio
0  36423   banana      paris
1  28564    apple  amsterdam
2  96648    peach  frankfurt
3  96648    peach      paris
4  10042    melon     london
5  68277     pear    brussel
6  68277     pear  amsterdam
7  68277     pear      sofia
</code></pre>
<p>What would be the best way to filter out these rows which hold projects developed</p>
<ol>
<li>in at least two different studios?</li>
<li>in two <em>specific</em> studios?</li>
</ol>
<p>The results I am trying to achieve look like as follows:</p>
<p>Which projects are getting developed in at least two different studios:</p>
<pre class=""lang-py prettyprint-override""><code>   project_id codename     studio
0       96648    peach  frankfurt
1       96648    peach      paris
2       68277     pear    brussel
3       68277     pear  amsterdam
4       68277     pear      sofia
</code></pre>
<p>Which projects are getting developed in frankfurt <strong>AND</strong> paris?</p>
<pre class=""lang-py prettyprint-override""><code>   project_id codename     studio
0       96648    peach  frankfurt
1       96648    peach      paris
</code></pre>
<p>Using <code>df.loc[df['studio'].isin(['frankfurt', 'paris'])]</code> for instance does not work, as this function filters out all rows which contain either <code>frankfurt</code> or <code>paris</code> in the column <code>studio</code>. Is there a more elegant way than filtering the dataframe for <code>frankfurt</code> and <code>paris</code> and using the <code>Series.intersection()</code> method? I am running out of Ideas here.</p>
<p>Thanks in advance! :)</p>
",34,2,1,3,python;pandas;dataframe,2022-05-17 17:35:26,2022-05-17 17:35:26,2022-05-17 18:06:10,i have an exemplary pd dataframe containing codenames of software developed in different development studios  what would be the best way to filter out these rows which hold projects developed the results i am trying to achieve look like as follows  which projects are getting developed in at least two different studios  which projects are getting developed in frankfurt and paris  using df loc df  studio   isin   frankfurt    paris     for instance does not work  as this function filters out all rows which contain either frankfurt or paris in the column studio  is there a more elegant way than filtering the dataframe for frankfurt and paris and using the series intersection   method  i am running out of ideas here  thanks in advance    ,how to filter out multiple rows in a pandas dataframe based on multiple conditions for the same column
261,16432585,68350220,KuduSink&lt;MyModel&gt; fails to start,"<p>I'm trying to write a ETL pipeline from kafka to HDFS using flink.
I'm using the bahir KuduSink and a PojoOperationMapper
It throws an exception before starting.  I've included my code, pom, and exception stack trace.
Is there something obvious I'm missing?</p>
<pre><code>package pipeline.poc.model;

import lombok.Data;

@Data
public class MyModel{
    
    private String msgKey;
    private String msgData;
}
</code></pre>
<p>Pipeline mapping</p>
<pre><code>package pipeline.poc;

import org.apache.flink.api.common.functions.MapFunction;
import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.DeserializationFeature;
import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.JsonNode;
import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper;
import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode;


public class MessageMapFunction implements MapFunction&lt;ObjectNode, MyModel&gt; {
    
    /**
     * 
     */
    private static final long serialVersionUID = 1L;
    
    private final ObjectMapper mapper;

    public MessageMapFunction() {
        super();
        mapper = new ObjectMapper();
        mapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);
    }

    @Override
    public MyModel map(ObjectNode value) throws Exception {
        JsonNode msgValue =  value.get(&quot;value&quot;);
        return mapper.convertValue(msgValue, MyModel.class);
    }

}
</code></pre>
<p>The pipeline program</p>
<pre><code>package pipeline.poc;

import java.util.Properties;

import org.apache.flink.api.common.functions.MapFunction;
import org.apache.flink.connectors.kudu.connector.KuduTableInfo;
import org.apache.flink.connectors.kudu.connector.writer.KuduWriterConfig;
import org.apache.flink.connectors.kudu.connector.writer.PojoOperationMapper;
import org.apache.flink.connectors.kudu.connector.writer.AbstractSingleOperationMapper.KuduOperation;
import org.apache.flink.connectors.kudu.streaming.KuduSink;
import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;
import org.apache.flink.streaming.connectors.kafka.KafkaDeserializationSchema;
import org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema;

public class Pipeline {

    private final StreamExecutionEnvironment env;
    private final KuduWriterConfig kuduConfig;
    private final PojoOperationMapper&lt;MyModel&gt; operationMapper;
    private final KuduSink&lt;MyModel&gt; kuduSink;
    private final KafkaDeserializationSchema&lt;ObjectNode&gt; schema;
    private final FlinkKafkaConsumer&lt;ObjectNode&gt; consumer;
    private final String[] columns = {&quot;key&quot;, &quot;value&quot;};
    private final MapFunction&lt;ObjectNode, MyModel&gt; messageMapFunction;

    public static void main(String[] args) {
        
        new Pipeline().run();

    }
    
    Pipeline() {
        env = StreamExecutionEnvironment.getExecutionEnvironment();
        schema = new JSONKeyValueDeserializationSchema(false);
        
        kuduConfig = KuduWriterConfig.Builder
                .setMasters(&quot;localhost:7051,localhost:7151,localhost:7251&quot;)
                .build();
        
        operationMapper = new PojoOperationMapper&lt;&gt; (
                MyModel.class,
                columns, 
                KuduOperation.INSERT);
        
        kuduSink = new KuduSink&lt;&gt;(
                kuduConfig, 
                KuduTableInfo.forTable(&quot;TOYTABLE&quot;), 
                operationMapper);
        
        Properties props = new Properties();
        props.setProperty(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);
        props.setProperty(&quot;group.id&quot;, &quot;pipeline.demo&quot;);
        consumer = new FlinkKafkaConsumer&lt;&gt;(
                &quot;pipeline.demo&quot;, 
                schema, 
                props);
        
        messageMapFunction = new MessageMapFunction();
    }

    public void run() {
        
        DataStream&lt;ObjectNode&gt; dataStream = env.addSource(consumer);
        DataStream&lt;MyModel&gt; messageStream = dataStream.map(messageMapFunction);

//      just printing the mapped stream works
//      messageStream.print();
//      Adding the kuduSink throw an exception
        messageStream.addSink(kuduSink);
        
        
        try {
            env.execute(&quot;Pipeline Demo&quot;);
        } catch (Exception e) {
            e.printStackTrace();
        }

    }

}
</code></pre>
<p>It throw this exception</p>
<pre><code>ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.api.java.ClosureCleaner (file:/Users/smitopher/.m2/repository/org/apache/flink/flink-core/1.13.1/flink-core-1.13.1.jar) to field java.util.Properties.serialVersionUID
WARNING: Please consider reporting this to the maintainers of org.apache.flink.api.java.ClosureCleaner
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
Exception in thread &quot;main&quot; org.apache.flink.api.common.InvalidProgramException: [Ljava.lang.reflect.Field;@1095f122 is not serializable. The object probably contains or references non serializable fields.
    at org.apache.flink.api.java.ClosureCleaner.clean(ClosureCleaner.java:164)
    at org.apache.flink.api.java.ClosureCleaner.clean(ClosureCleaner.java:132)
    at org.apache.flink.api.java.ClosureCleaner.clean(ClosureCleaner.java:132)
    at org.apache.flink.api.java.ClosureCleaner.clean(ClosureCleaner.java:69)
    at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.clean(StreamExecutionEnvironment.java:2053)
    at org.apache.flink.streaming.api.datastream.DataStream.clean(DataStream.java:203)
    at org.apache.flink.streaming.api.datastream.DataStream.addSink(DataStream.java:1243)
    at pipeline.poc.Pipeline.run(Pipeline.java:75)
    at pipeline.poc.Pipeline.main(Pipeline.java:34)
Caused by: java.io.NotSerializableException: java.lang.reflect.Field
    at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1185)
    at java.base/java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1379)
    at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1175)
    at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:349)
    at org.apache.flink.util.InstantiationUtil.serializeObject(InstantiationUtil.java:624)
    at org.apache.flink.api.java.ClosureCleaner.clean(ClosureCleaner.java:143)
    ... 8 more
</code></pre>
<p>pom.xml</p>
<pre><code>&lt;!-- Licensed to the Apache Software Foundation (ASF) under one or more contributor 
    license agreements. See the NOTICE file distributed with this work for additional 
    information regarding copyright ownership. The ASF licenses this file to 
    you under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use 
    this file except in compliance with the License. You may obtain a copy of 
    the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required 
    by applicable law or agreed to in writing, software distributed under the 
    License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS 
    OF ANY KIND, either express or implied. See the License for the specific 
    language governing permissions and limitations under the License. --&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;pipeline.poc&lt;/groupId&gt;
    &lt;artifactId&gt;kafka-flink-pipeline&lt;/artifactId&gt;
    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
    &lt;packaging&gt;jar&lt;/packaging&gt;

    &lt;name&gt;Flink Quickstart Job&lt;/name&gt;

    &lt;properties&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
        &lt;flink.version&gt;1.13.1&lt;/flink.version&gt;
        &lt;target.java.version&gt;11&lt;/target.java.version&gt;
        &lt;scala.binary.version&gt;2.11&lt;/scala.binary.version&gt;
        &lt;maven.compiler.source&gt;${target.java.version}&lt;/maven.compiler.source&gt;
        &lt;maven.compiler.target&gt;${target.java.version}&lt;/maven.compiler.target&gt;
        &lt;log4j.version&gt;2.12.1&lt;/log4j.version&gt;
    &lt;/properties&gt;

    &lt;repositories&gt;
        &lt;repository&gt;
            &lt;id&gt;apache.snapshots&lt;/id&gt;
            &lt;name&gt;Apache Development Snapshot Repository&lt;/name&gt;
            &lt;url&gt;https://repository.apache.org/content/repositories/snapshots/&lt;/url&gt;
            &lt;releases&gt;
                &lt;enabled&gt;false&lt;/enabled&gt;
            &lt;/releases&gt;
            &lt;snapshots&gt;
                &lt;enabled&gt;true&lt;/enabled&gt;
            &lt;/snapshots&gt;
        &lt;/repository&gt;
    &lt;/repositories&gt;

    &lt;dependencies&gt;
        &lt;!-- Apache Flink dependencies --&gt;
        &lt;!-- These dependencies are provided, because they should not be packaged 
            into the JAR file. --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-java&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
            &lt;scope&gt;provided&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-streaming-java_${scala.binary.version}&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
            &lt;scope&gt;provided&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-clients_${scala.binary.version}&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
            &lt;scope&gt;provided&lt;/scope&gt;
        &lt;/dependency&gt;

        &lt;!-- Add connector dependencies here. They must be in the default scope 
            (compile). --&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-connector-kafka_${scala.binary.version}&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- Add logging framework, to produce console output when running in the 
            IDE. --&gt;
        &lt;!-- These dependencies are excluded from the application JAR by default. --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
            &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt;
            &lt;version&gt;${log4j.version}&lt;/version&gt;
            &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
            &lt;artifactId&gt;log4j-api&lt;/artifactId&gt;
            &lt;version&gt;${log4j.version}&lt;/version&gt;
            &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
            &lt;artifactId&gt;log4j-core&lt;/artifactId&gt;
            &lt;version&gt;${log4j.version}&lt;/version&gt;
            &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.bahir&lt;/groupId&gt;
            &lt;artifactId&gt;flink-connector-kudu_2.11&lt;/artifactId&gt;
            &lt;version&gt;1.1-SNAPSHOT&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;version&gt;1.18.20&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;

            &lt;!-- Java Compiler --&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.1&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;source&gt;${target.java.version}&lt;/source&gt;
                    &lt;target&gt;${target.java.version}&lt;/target&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;

            &lt;!-- We use the maven-shade plugin to create a fat jar that contains all 
                necessary dependencies. --&gt;
            &lt;!-- Change the value of &lt;mainClass&gt;...&lt;/mainClass&gt; if your program entry 
                point changes. --&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.1.1&lt;/version&gt;
                &lt;executions&gt;
                    &lt;!-- Run shade goal on package phase --&gt;
                    &lt;execution&gt;
                        &lt;phase&gt;package&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;shade&lt;/goal&gt;
                        &lt;/goals&gt;
                        &lt;configuration&gt;
                            &lt;artifactSet&gt;
                                &lt;excludes&gt;
                                    &lt;exclude&gt;org.apache.flink:force-shading&lt;/exclude&gt;
                                    &lt;exclude&gt;com.google.code.findbugs:jsr305&lt;/exclude&gt;
                                    &lt;exclude&gt;org.slf4j:*&lt;/exclude&gt;
                                    &lt;exclude&gt;org.apache.logging.log4j:*&lt;/exclude&gt;
                                &lt;/excludes&gt;
                            &lt;/artifactSet&gt;
                            &lt;filters&gt;
                                &lt;filter&gt;
                                    &lt;!-- Do not copy the signatures in the META-INF folder. Otherwise, 
                                        this might cause SecurityExceptions when using the JAR. --&gt;
                                    &lt;artifact&gt;*:*&lt;/artifact&gt;
                                    &lt;excludes&gt;
                                        &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt;
                                        &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt;
                                        &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt;
                                    &lt;/excludes&gt;
                                &lt;/filter&gt;
                            &lt;/filters&gt;
                            &lt;transformers&gt;
                                &lt;transformer
                                    implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt;
                                    &lt;mainClass&gt;com.apple.pipeline.poc.StreamingJob&lt;/mainClass&gt;
                                &lt;/transformer&gt;
                            &lt;/transformers&gt;
                        &lt;/configuration&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;

        &lt;pluginManagement&gt;
            &lt;plugins&gt;

                &lt;!-- This improves the out-of-the-box experience in Eclipse by resolving 
                    some warnings. --&gt;
                &lt;plugin&gt;
                    &lt;groupId&gt;org.eclipse.m2e&lt;/groupId&gt;
                    &lt;artifactId&gt;lifecycle-mapping&lt;/artifactId&gt;
                    &lt;version&gt;1.0.0&lt;/version&gt;
                    &lt;configuration&gt;
                        &lt;lifecycleMappingMetadata&gt;
                            &lt;pluginExecutions&gt;
                                &lt;pluginExecution&gt;
                                    &lt;pluginExecutionFilter&gt;
                                        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                                        &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;
                                        &lt;versionRange&gt;[3.1.1,)&lt;/versionRange&gt;
                                        &lt;goals&gt;
                                            &lt;goal&gt;shade&lt;/goal&gt;
                                        &lt;/goals&gt;
                                    &lt;/pluginExecutionFilter&gt;
                                    &lt;action&gt;
                                        &lt;ignore /&gt;
                                    &lt;/action&gt;
                                &lt;/pluginExecution&gt;
                                &lt;pluginExecution&gt;
                                    &lt;pluginExecutionFilter&gt;
                                        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                                        &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                                        &lt;versionRange&gt;[3.1,)&lt;/versionRange&gt;
                                        &lt;goals&gt;
                                            &lt;goal&gt;testCompile&lt;/goal&gt;
                                            &lt;goal&gt;compile&lt;/goal&gt;
                                        &lt;/goals&gt;
                                    &lt;/pluginExecutionFilter&gt;
                                    &lt;action&gt;
                                        &lt;ignore /&gt;
                                    &lt;/action&gt;
                                &lt;/pluginExecution&gt;
                            &lt;/pluginExecutions&gt;
                        &lt;/lifecycleMappingMetadata&gt;
                    &lt;/configuration&gt;
                &lt;/plugin&gt;
            &lt;/plugins&gt;
        &lt;/pluginManagement&gt;
    &lt;/build&gt;
&lt;/project&gt;
</code></pre>
",74,0,1,3,flink-streaming;apache-kudu;apache-bahir,2021-07-12 18:43:03,2021-07-12 18:43:03,2022-05-17 11:17:02,pipeline mapping the pipeline program it throw this exception pom xml,kudusink lt mymodel gt  fails to start
262,5488177,72256338,Eclipse feature and plugin not visible after installing from updatesite,"<p>I made several new E4-based plugins, each defined in a fragment.e4xmi file. The simplest one should just show a test menu in the main menu and a test popup menu.</p>
<p>When running an Eclipse instance from the development IDE, everything works as expected. However, when publishing those plugins and features via a test update site, an end user can install the new plugins using the update site, but the UI is not visible in the Eclipse IDE. In the Help / About Eclipse IDE / Installation Details, the &quot;Installed Software&quot; shows my new plugins, but the features list does not. The Plug-Ins list does show some utility plugins, but none of those contributing to the UI.</p>
<p>Older plugins (not using e4) are visible as expected.</p>
<ol>
<li>Which settings do I have to check?</li>
<li>How can I debug the installation?</li>
</ol>
<p>Thanks in advance.</p>
",21,0,0,3,eclipse;eclipse-plugin;update-site,2022-05-16 11:39:40,2022-05-16 11:39:40,2022-05-16 11:39:40,i made several new e based plugins  each defined in a fragment exmi file  the simplest one should just show a test menu in the main menu and a test popup menu  when running an eclipse instance from the development ide  everything works as expected  however  when publishing those plugins and features via a test update site  an end user can install the new plugins using the update site  but the ui is not visible in the eclipse ide  in the help   about eclipse ide   installation details  the  installed software  shows my new plugins  but the features list does not  the plug ins list does show some utility plugins  but none of those contributing to the ui  older plugins  not using e  are visible as expected  thanks in advance ,eclipse feature and plugin not visible after installing from updatesite
263,19122864,72252716,Trying to put a magnifying glass in my search bar (on the left) and put the &quot;Join&quot; and &quot;Login&quot; side by side (on right side),"<p>For some reason I can't put this magnifying glass in the search bar (path: images/magnifying-glass.png). I also cant get the &quot;Join&quot; and &quot;login&quot; link to go side by side. I also need to lower the gray-ish lines (top and bottom) to look like image below.</p>
<p>It should look like this:</p>
<p><a href=""https://i.stack.imgur.com/YA5ZK.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/YA5ZK.png"" alt=""enter image description here"" /></a></p>
<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-css lang-css prettyprint-override""><code>@import url('https://fonts.googleapis.com/css?family=Poppins');
body {
  font-family: 'Poppins';
}

header&gt;div {
  padding: 0 25px;
  display: flex;
  justify-content: space-between;
  align-items: center;
  border-bottom: 1px solid lightgray;
}

nav {
  width: 600px;
}

nav ul {
  list-style: none;
  display: flex;
  justify-content: space-between;
  align-items: center;
}

nav a {
  text-decoration: none;
  color: black;
}

.blackHeart {
  width: 20px;
  margin-right: 1rem;
}

.searchmenu {
  padding-top: 12.5px;
  padding-bottom: 12.5px;
  display: flex;
  justify-content: space-between;
  align-items: center;
}

.logo {
  width: 50px;
  margin-left: .3rem;
  display: right;
  padding-right: 10px;
}

.topnav,
.searchContainer {
  width: 100%;
}

.topnav input[type=text] {
  padding: 6px;
  font-size: 17px;
  border: none;
}

.topnav .search-container button {
  width: 9%;
  padding: 6px;
  background: red;
  font-size: 17px;
  border: none;
  cursor: pointer;
  color: white;
}

.topnav .search-container button:hover {
  background: black;
}

.search {
  background-color: rgba(211, 211, 211, 0.463);
  width: 78%;
}

.searchmenu ul {
  padding: 0;
  width: 100%;
  display: flex;
  align-items: center;
}

.account {
  list-style: none;
  text-decoration: none;
}

.account_join {
  list-style: none;
  text-decoration: none;
  color: black;
  display: flex;
}

.account_login {
  display: flex;
  list-style: none;
  text-decoration: none;
  color: black;
}

.searchDiv {
  width: 78%;
  display: flex;
  align-items: center;
  border: 1px solid black;
  background-color: rgba(211, 211, 211, 0.463);
}

.icon {
  width: 20px;
  height: 20px;
}

.amazing_section {
  display: flex;
  justify-content: center;
  height: 600px;
  background-color: rgba(232, 217, 217, .3);
  text-align: center;
}

.desc {
  padding-left: 400px;
  padding-right: 400px;
  font-size: 20px;
}

.see_button {
  height: 50px;
  width: 100px;
  background-color: #FB3B49;
  box-shadow: 8px 8px 0 rgba(251, 59, 73, .2);
  border: none;
  cursor: pointer;
  color: white;
}

.amazing_join {
  text-decoration: none;
  color: black;
  padding-left: 40px;
}</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>NPM Clone Nifty Penguin Magic npm Enterprise Products Solutions Resources Docs Support Search Join Log In Build amazing things Essential JavaScript development tools that help you go to market faster and build powerful applications using modern open source
code. See plans Join for free Bring the best of open source to your company npm is the tool used by over 11,000,000 JavaScript developers around the world. Your developers already use it. Your company depends on it. Create an Org and get more out of the
tools your team already knows and loves. Zero configuration Create an org, add your team, and start collaborating. Nothing to configure, set up, or manage. Team management Control who has access to what modules within your team namespace using straightforward
team management capabilities. Familiar features npm Orgs has 100% parity with all the public npm registry features your developers already use. npm audit Enjoy the security auditing features built into the npm client, a zero-friction way to make open
source software safer. Create an Org

&lt;!DOCTYPE html&gt;
&lt;html lang=""en""&gt;

&lt;head&gt;
  &lt;meta charset=""UTF-8""&gt;
  &lt;meta http-equiv=""X-UA-Compatible"" content=""IE=edge""&gt;
  &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1.0""&gt;
  &lt;link rel=""stylesheet"" href=""./style.css""&gt;
  &lt;title&gt;Document&lt;/title&gt;
&lt;/head&gt;
&lt;header&gt;
  &lt;div&gt;
    &lt;div&gt;
      &lt;img class=""blackHeart"" src=""images/black-heart.png"" alt=""black heart"" /&gt;
      &lt;span&gt; Nifty Penguin Magic &lt;/span&gt;
    &lt;/div&gt;
    &lt;nav&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=""#""&gt; npm Enterprise &lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=""#""&gt; Products &lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=""#""&gt; Solutions &lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=""#""&gt; Resources &lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=""#""&gt; Docs &lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=""#""&gt; Support &lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/nav&gt;
  &lt;/div&gt;

  &lt;div class=""searchmenu""&gt;
    &lt;ul&gt;
      &lt;div&gt;
        &lt;img class=""logo"" src=""images/npm-logo.png"" alt=""npm logo""&gt;
      &lt;/div&gt;
      &lt;div class=""topnav""&gt;
        &lt;div class=""search-container""&gt;
          &lt;form&gt;
            &lt;input type=""text"" placeholder=""Search.."" name=""search"" class=""search""&gt;
            &lt;button type=""submit""&gt;Submit&lt;/button&gt;
          &lt;/form&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;a class=""account_join"" href=""#""&gt;Join&lt;/a&gt;
        &lt;a class=""account_login"" href=""#""&gt;Log In&lt;/a&gt;
      &lt;/div&gt;
    &lt;/ul&gt;
  &lt;/div&gt;
&lt;/header&gt;
&lt;section class=""amazing_section""&gt;
  &lt;ul&gt;
    &lt;header style=""font-size: 80px;"" class=""title""&gt; Build amazing things&lt;/header&gt;
    &lt;p class=""desc""&gt;Build amazing things Essential JavaScript development tools that help you go to market faster and build powerful applications using modern open source code. &lt;/p&gt;
    &lt;button type=""submit"" class=""see_button""&gt; See Plans&lt;/button&gt;
    &lt;a class=""amazing_join"" href=""#""&gt;Join For Free&lt;/a&gt;
  &lt;/ul&gt;
&lt;/section&gt;


&lt;body&gt;

&lt;/body&gt;

&lt;/html&gt;</code></pre>
</div>
</div>

Thank you for any help.
P.S this is for a school project I am doing.</p>
",64,1,1,2,html;css,2022-05-16 01:50:53,2022-05-16 01:50:53,2022-05-16 03:20:01,for some reason i can t put this magnifying glass in the search bar  path  images magnifying glass png   i also cant get the  join  and  login  link to go side by side  i also need to lower the gray ish lines  top and bottom  to look like image below  it should look like this  ,trying to put a magnifying glass in my search bar  on the left  and put the  join  and  login  side by side  on right side 
264,19122875,72251927,Django Blog - edit/delete user comments functions help needed pls,"<p>I am quite new to software development and quite new to django and python. I am currently working on a project to develop blog, which needs to have functions for users to edit and delete their own comments.</p>
<p>Whilst I have developed the blog, I am struggling with getting the functions correctly coded and wired up to URLS file.</p>
<p>I have added icons below user comments to either delete or edit their comments.</p>
<p>My question is what is the correct code for creating functions in views file and also how can i correctly wire it up to URL file. I am not sure if I am missing any packages to get the edit/delete functionality developed.</p>
<p>I have enclosed details of my model, views and urls files.
Any guidance/support will be highly appreciated.</p>
<p>Models file</p>
<pre><code>from django.db import models
from django.contrib.auth.models import User
from cloudinary.models import CloudinaryField

STATUS = ((0, &quot;Draft&quot;), (1, &quot;Published&quot;))

class Post(models.Model):
    title = models.CharField(max_length=200, unique=True)
    slug = models.SlugField(max_length=200, unique=True)
    author = models.ForeignKey(User, on_delete=models.CASCADE, related_name=&quot;blog_posts&quot;)
    updated_on = models.DateTimeField(auto_now=True)
    content = models.TextField()
    featured_image = CloudinaryField('image', default='placeholder')
    excerpt = models.TextField(blank=True)
    created_on = models.DateTimeField(auto_now_add=True)
    status = models.IntegerField(choices=STATUS, default=0)
    likes = models.ManyToManyField(User, related_name='blog_likes', blank=True)

    class Meta:
        ordering = ['-created_on']

    def __str__(self):
        return self.title

    def number_of_likes(self):
        return self.likes.count()

class Comment(models.Model):
    
    post = models.ForeignKey(Post, on_delete=models.CASCADE, related_name='comments')
    name = models.CharField(max_length=80)
    body = models.TextField()
    created_on = models.DateTimeField(auto_now_add=True)
    approved = models.BooleanField(default=False)

    class Meta:
        ordering = ['-created_on']

    def __str__(self):
        return f&quot;Comment {self.body} by {self.name}&quot;

</code></pre>
<p>Views file</p>
<pre><code>from django.shortcuts import render, get_object_or_404, reverse
from django.views import generic, View
from django.http import HttpResponseRedirect
from .models import Post
from .forms import CommentForm


class PostList(generic.ListView):
    model = Post
    queryset = Post.objects.filter(status=1).order_by('-created_on')
    template_name = 'index.html'
    paginate_by = 4


class PostDetail(View):

    def get(self, request, slug, *args, **kwargs):
        queryset = Post.objects.filter(status=1)
        post = get_object_or_404(queryset, slug=slug)
        comments = post.comments.filter(approved=True).order_by(&quot;-created_on&quot;)
        liked = False
        if post.likes.filter(id=self.request.user.id).exists():
            liked = True

        return render(
            request,
            &quot;post_detail.html&quot;,
            {
                &quot;post&quot;: post,
                &quot;comments&quot;: comments,
                &quot;commented&quot;: False,
                &quot;liked&quot;: liked,
                &quot;comment_form&quot;: CommentForm()
            },
        )

    def post(self, request, slug, *args, **kwargs):
        queryset = Post.objects.filter(status=1)
        post = get_object_or_404(queryset, slug=slug)
        comments = post.comments.filter(approved=True).order_by(&quot;-created_on&quot;)
        liked = False
        if post.likes.filter(id=self.request.user.id).exists():
            liked = True

        comment_form = CommentForm(data=request.POST)

        if comment_form.is_valid():
            comment_form.instance.email = request.user.email
            comment_form.instance.name = request.user.username
            comment = comment_form.save(commit=False)
            comment.post = post
            comment.save()
        else:
            comment_form = CommentForm()

        return render(
            request,
            &quot;post_detail.html&quot;,
            {
                &quot;post&quot;: post,
                &quot;comments&quot;: comments,
                &quot;commented&quot;: True,
                &quot;liked&quot;: liked,
                &quot;comment_form&quot;: CommentForm()
            },
        )

class PostLike(View):

    def post(self, request, slug):
        post = get_object_or_404(Post, slug=slug)

        if post.likes.filter(id=request.user.id).exists():
            post.likes.remove(request.user)
        else:
            post.likes.add(request.user)

        return HttpResponseRedirect(reverse('post_detail', args=[slug]))

</code></pre>
<p>Urls file</p>
<pre><code>from . import views
from django.urls import path


urlpatterns = [
    path(&quot;&quot;, views.PostList.as_view(), name=&quot;home&quot;),
    path('&lt;slug:slug&gt;/', views.PostDetail.as_view(), name='post_detail'),
    path('like/&lt;slug:slug&gt;', views.PostLike.as_view(), name='post_like'),
]

</code></pre>
",45,1,0,2,python;django,2022-05-15 23:24:24,2022-05-15 23:24:24,2022-05-16 00:08:22,i am quite new to software development and quite new to django and python  i am currently working on a project to develop blog  which needs to have functions for users to edit and delete their own comments  whilst i have developed the blog  i am struggling with getting the functions correctly coded and wired up to urls file  i have added icons below user comments to either delete or edit their comments  my question is what is the correct code for creating functions in views file and also how can i correctly wire it up to url file  i am not sure if i am missing any packages to get the edit delete functionality developed  models file views file urls file,django blog   edit delete user comments functions help needed pls
265,17965276,70951005,"error in MethodChannel, IllegalArgumentException","<p>Im a beginner to Flutter development, actually to the whole Software development domain,</p>
<p>The Flutter application in question is Android only, which needs merely <code>getFilesDir()</code> from the platform, nothing else,</p>
<p>I initially used <code>path_provider</code>, then switched to <code>path_provider_android</code>, and after checking its [sourse-code][https://github.com/flutter/plugins/blob/main/packages/path_provider/path_provider_android/], I tried to use <code>getFilesDir()</code> directly,</p>
<p><code>main.dart</code>:</p>
<pre><code>const platform = MethodChannel(&quot;com.example/persistence&quot;);
privateStoragePath = await platform.invokeMethod(&quot;getPrivateStoragePath&quot;);
</code></pre>
<p><code>MainActivity.kt</code>:</p>
<pre><code>package com.example

import android.content.Context
import android.content.ContextWrapper
import androidx.annotation.NonNull
import io.flutter.embedding.android.FlutterActivity
import io.flutter.embedding.engine.FlutterEngine
import io.flutter.plugin.common.MethodChannel

class MainActivity : FlutterActivity() {
    private val CHANNEL = &quot;com.example/persistence&quot;

    override fun configureFlutterEngine(@NonNull flutterEngine: FlutterEngine) {
        super.configureFlutterEngine(flutterEngine)
        MethodChannel(flutterEngine.dartExecutor.binaryMessenger, CHANNEL).setMethodCallHandler { call, result -&gt;
            if (call.method == &quot;getPrivateStoragePath&quot;) {
                val path = getFilesDir()
                result.success(path)
            } else {
                result.notImplemented()
            }
        }
    }
}

</code></pre>
<p>Errors:</p>
<pre><code>Syncing files to device Android SDK built for x86 64...
E/MethodChannel#com.example/persistence( 4828): Failed to handle method call
E/MethodChannel#com.example/persistence( 4828): java.lang.IllegalArgumentException: Unsupported value: '/data/user/0/com.example.example/files' of type 'class java.io.File'
E/MethodChannel#com.example/persistence( 4828):     at io.flutter.plugin.common.StandardMessageCodec.writeValue(StandardMessageCodec.java:292)
E/MethodChannel#com.example/persistence( 4828):     at io.flutter.plugin.common.StandardMethodCodec.encodeSuccessEnvelope(StandardMethodCodec.java:59)
E/MethodChannel#com.example/persistence( 4828):     at io.flutter.plugin.common.MethodChannel$IncomingMethodCallHandler$1.success(MethodChannel.java:267)
E/MethodChannel#com.example/persistence( 4828):     at com.example.example.MainActivity$configureFlutterEngine$1.onMethodCall(MainActivity.kt:18)
E/MethodChannel#com.example/persistence( 4828):     at io.flutter.plugin.common.MethodChannel$IncomingMethodCallHandler.onMessage(MethodChannel.java:262)
E/MethodChannel#com.example/persistence( 4828):     at io.flutter.embedding.engine.dart.DartMessenger.invokeHandler(DartMessenger.java:178)
E/MethodChannel#com.example/persistence( 4828):     at io.flutter.embedding.engine.dart.DartMessenger.lambda$handleMessageFromDart$0$DartMessenger(DartMessenger.java:206)
E/MethodChannel#com.example/persistence( 4828):     at io.flutter.embedding.engine.dart.-$$Lambda$DartMessenger$6ZD1MYkhaLxyPjtoFDxe45u43DI.run(Unknown Source:12)
E/MethodChannel#com.example/persistence( 4828):     at android.os.Handler.handleCallback(Handler.java:938)
E/MethodChannel#com.example/persistence( 4828):     at android.os.Handler.dispatchMessage(Handler.java:99)
E/MethodChannel#com.example/persistence( 4828):     at android.os.Looper.loop(Looper.java:223)
E/MethodChannel#com.example/persistence( 4828):     at android.app.ActivityThread.main(ActivityThread.java:7656)
E/MethodChannel#com.example/persistence( 4828):     at java.lang.reflect.Method.invoke(Native Method)
E/MethodChannel#com.example/persistence( 4828):     at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:592)
E/MethodChannel#com.example/persistence( 4828):     at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:947)
E/flutter ( 4828): [ERROR:flutter/lib/ui/ui_dart_state.cc(209)] Unhandled Exception: PlatformException(error, Unsupported value: '/data/user/0/com.example.example/files' of type 'class java.io.File', null, java.lang.IllegalArgumentException: Unsupported value: '/data/user/0/com.example.example/files' of type 'class java.io.File'
E/flutter ( 4828):  at io.flutter.plugin.common.StandardMessageCodec.writeValue(StandardMessageCodec.java:292)
E/flutter ( 4828):  at io.flutter.plugin.common.StandardMethodCodec.encodeSuccessEnvelope(StandardMethodCodec.java:59)
E/flutter ( 4828):  at io.flutter.plugin.common.MethodChannel$IncomingMethodCallHandler$1.success(MethodChannel.java:267)
E/flutter ( 4828):  at com.example.example.MainActivity$configureFlutterEngine$1.onMethodCall(MainActivity.kt:18)
E/flutter ( 4828):  at io.flutter.plugin.common.MethodChannel$IncomingMethodCallHandler.onMessage(MethodChannel.java:262)
E/flutter ( 4828):  at io.flutter.embedding.engine.dart.DartMessenger.invokeHandler(DartMessenger.java:178)
E/flutter ( 4828):  at io.flutter.embedding.engine.dart.DartMessenger.lambda$handleMessageFromDart$0$DartMessenger(DartMessenger.java:206)
E/flutter ( 4828):  at io.flutter.embedding.engine.dart.-$$Lambda$DartMessenger$6ZD1MYkhaLxyPjtoFDxe45u43DI.run(Unknown Source:12)
E/flutter ( 4828):  at android.os.Handler.handleCallback(Handler.java:938)
E/flutter ( 4828):  at android.os.Handler.dispatchMessage(Handler.java:99)
E/flutter ( 4828):  at android.os.Looper.loop(Looper.java:223)
E/flutter ( 4828):  at android.app.ActivityThread.main(ActivityThread.java:7656)
E/flutter ( 4828):  at java.lang.reflect.Method.invoke(Native Method)
E/flutter ( 4828):  at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:592)
E/flutter ( 4828):  at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:947)
E/flutter ( 4828): )
E/flutter ( 4828): #0      StandardMethodCodec.decodeEnvelope (package:flutter/src/services/message_codecs.dart:607:7)
E/flutter ( 4828): #1      MethodChannel._invokeMethod (package:flutter/src/services/platform_channel.dart:167:18)
E/flutter ( 4828): &lt;asynchronous suspension&gt;
E/flutter ( 4828): #2      main (package:example/main.dart:24:24)
E/flutter ( 4828): &lt;asynchronous suspension&gt;
E/flutter ( 4828): 
</code></pre>
<p>Thanking you...</p>
",280,1,0,2,android;flutter,2022-02-02 07:47:24,2022-02-02 07:47:24,2022-05-15 09:57:58,im a beginner to flutter development  actually to the whole software development domain  the flutter application in question is android only  which needs merely getfilesdir   from the platform  nothing else  i initially used path_provider  then switched to path_provider_android  and after checking its  sourse code  https   github com flutter plugins blob main packages path_provider path_provider_android    i tried to use getfilesdir   directly  main dart  mainactivity kt  errors  thanking you   ,error in methodchannel  illegalargumentexception
266,5225616,70703882,REACT- Uncaught TypeError: Found non-callable @@iterator,"<p>In react, I have a component that takes in 2 destructured parameters. One of them is an array called <code>points</code>. However, when attempting to call the <code>Math.max(...points)</code>, I get an error stating <code>Uncaught TypeError: Found non-callable @@iterator</code>. I am confused to this as <code>points</code> is definitely an array from where I am calling it. Below is the code where I get my error:</p>
<pre><code>const MostVotesDisplay = ({anecdotes, points}) =&gt;
{
  let max = Math.max(...points)
  if(max === 0)
    return (&lt;div&gt;No votes for any anecdotes yet!&lt;/div&gt;)
  else
    return (
      &lt;div&gt;
        &lt;p&gt;{anecdotes[max]}&lt;/p&gt;
        &lt;p&gt;{points[max]}&lt;/p&gt;
      &lt;/div&gt;
    )
}
</code></pre>
<p>And the following code is where I call my function:</p>
<pre><code>const [points, setPoints] = useState(Array(7).fill(0))
  return (
    &lt;div&gt;
      &lt;h1&gt;Anecdote of the day&lt;/h1&gt;
      &lt;p&gt;{anecdotes[selected]}&lt;/p&gt;
      &lt;p&gt;has {points[selected]} votes&lt;/p&gt;
      &lt;button onClick={() =&gt; vote(selected)}&gt;vote&lt;/button&gt;
      &lt;button onClick={generateAnecdote}&gt;next anecdote&lt;/button&gt;

      &lt;h1&gt;Anecdote with the most votes&lt;/h1&gt;
      &lt;MostVotesDisplay anecdotes={anecdotes} points={points}/&gt;
    &lt;/div&gt;
  )
</code></pre>
<p>I've included my full code for more information:</p>
<pre><code>import React, {useState} from 'react'

const MostVotesDisplay = ({anecdotes, points}) =&gt;
{
  let max = Math.max(...points)
  if(max === 0)
    return (&lt;div&gt;No votes for any anecdotes yet!&lt;/div&gt;)
  else
    return (
      &lt;div&gt;
        &lt;p&gt;{anecdotes[max]}&lt;/p&gt;
        &lt;p&gt;{points[max]}&lt;/p&gt;
      &lt;/div&gt;
    )
}
const App = () =&gt; {
  const anecdotes = [
    'If it hurts, do it more often',
    'Adding manpower to a late software project makes it later!',
    'The first 90 percent of the code accounts for the first 10 percent of the development time...The remaining 10 percent of the code accounts for the other 90 percent of the development time.',
    'Any fool can write code that a computer can understand. Good programmers write code that humans can understand.',
    'Premature optimization is the root of all evil.',
    'Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it.',
    'Programming without an extremely heavy use of console.log is same as if a doctor would refuse to use x-rays or blood tests when diagnosing patients'
  ] 
  const [selected, setSelected] = useState(0)

  const [points, setPoints] = useState(Array(7).fill(0))

  const generateAnecdote = () =&gt; 
  {
    let index = Math.floor(Math.random() * anecdotes.length)

    setSelected(index)
  }

  const vote = (index) =&gt;
  {
    const newPoints = {...points}
    
    newPoints[index]++

    setPoints(newPoints)
  }

  return (
    &lt;div&gt;
      &lt;h1&gt;Anecdote of the day&lt;/h1&gt;
      &lt;p&gt;{anecdotes[selected]}&lt;/p&gt;
      &lt;p&gt;has {points[selected]} votes&lt;/p&gt;
      &lt;button onClick={() =&gt; vote(selected)}&gt;vote&lt;/button&gt;
      &lt;button onClick={generateAnecdote}&gt;next anecdote&lt;/button&gt;

      &lt;h1&gt;Anecdote with the most votes&lt;/h1&gt;
      &lt;MostVotesDisplay anecdotes={anecdotes} points={points}/&gt;
    &lt;/div&gt;
  )
}

export default App
</code></pre>
",2776,3,1,5,arrays;reactjs;typeerror;react-props;use-state,2022-01-14 00:28:19,2022-01-14 00:28:19,2022-05-14 11:49:58,in react  i have a component that takes in  destructured parameters  one of them is an array called points  however  when attempting to call the math max    points   i get an error stating uncaught typeerror  found non callable   iterator  i am confused to this as points is definitely an array from where i am calling it  below is the code where i get my error  and the following code is where i call my function  i ve included my full code for more information ,react  uncaught typeerror  found non callable   iterator
267,2287576,72233756,Inno Setup script not install. Displays error: &quot;Internal error: .Net Framework not found&quot;,"<p>Can anyone shed light on this Inno Setup error that one of my users is getting?</p>
<p><a href=""https://i.stack.imgur.com/3r4Rz.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/3r4Rz.png"" alt=""enter image description here"" /></a></p>
<p>He can install the same software on another computer with no issues. I asked him to supply me with his log file (the installer copies the log to a specific folder with a timestamp in the <code>CurStepChange</code> procedure (when the <code>CurStep = ssDone</code>).</p>
<p>But he could not find any log. I have now asked him to run the installer from a Command Prompt with the <code>/log=&quot;...&quot;</code> switch to see if we can get at the log that way.</p>
<p>His computer is running Windows 11 (this is also my development PC operating system).</p>
<p>Any ideas?</p>
<hr />
<p>Note that the installer does check for the existing of the Framework in the <code>InitializeWizard</code> procedure:</p>
<pre><code>dotNetNeeded := not IsDotNetInstalled(net462, 0);
if (dotNetNeeded) then begin
    if (MsgBox(ExpandConstant('{cm:DotNet_NeedToDownload}'), \
                                        mbConfirmation, MB_OKCANCEL) = IDCANCEL) then begin
        Abort();
    end;
end;
</code></pre>
<hr />
<h3>Update</h3>
<p>I am no Delphi developer, but I thought I would check the public source code for Inno Setup and I found two places where this error is displayed:</p>
<pre><code>function GetDotNetInstallRoot(const RegView: TRegView): String;
var
  K: HKEY;
begin
  if DotNetRoot[RegView] = '' then begin
    if RegOpenKeyExView(RegView, HKEY_LOCAL_MACHINE, 'SOFTWARE\Microsoft\.NETFramework', 0, KEY_QUERY_VALUE, K) = ERROR_SUCCESS then begin
      RegQueryStringValue(K, 'InstallRoot', DotNetRoot[RegView]);
      RegCloseKey(K);
    end;
    if DotNetRoot[RegView] = '' then
      InternalError('.NET Framework not found');
  end;
  Result := DotNetRoot[RegView];
end;

function GetDotNetVersionInstallRoot(const RegView: TRegView; const Version: TDotNetBaseVersion): String;
const
  VersionStrings: array [TDotNetBaseVersion] of String = ('1.1', '2.0', '4.0', '');
var
  K: HKEY;
begin
  if DotNetVersionRoot[RegView, Version] = '' then begin
    GetDotNetInstallRoot(RegView);
    if (Version in [netbase40, netbaseHighestKnown]) and (RegOpenKeyExView(RegView, HKEY_LOCAL_MACHINE, 'SOFTWARE\Microsoft\.NETFramework\Policy\v4.0', 0, KEY_QUERY_VALUE, K) = ERROR_SUCCESS) then begin
      DotNetVersionRoot[RegView, Version] := AddBackslash(DotNetRoot[RegView]) + 'v4.0.30319';
      RegCloseKey(K);
    end else if (Version in [netbase20, netbaseHighestKnown]) and (RegOpenKeyExView(RegView, HKEY_LOCAL_MACHINE, 'SOFTWARE\Microsoft\.NETFramework\Policy\v2.0', 0, KEY_QUERY_VALUE, K) = ERROR_SUCCESS) then begin
      DotNetVersionRoot[RegView, Version] := AddBackslash(DotNetRoot[RegView]) + 'v2.0.50727';
      RegCloseKey(K);
    end else if (Version in [netbase11, netbaseHighestKnown]) and (RegOpenKeyExView(RegView, HKEY_LOCAL_MACHINE, 'SOFTWARE\Microsoft\.NETFramework\Policy\v1.1', 0, KEY_QUERY_VALUE, K) = ERROR_SUCCESS) then begin
      DotNetVersionRoot[RegView, Version] := AddBackslash(DotNetRoot[RegView]) + 'v1.1.4322';
      RegCloseKey(K);
    end;
    if DotNetVersionRoot[RegView, Version] = '' then begin
      if Version &lt;&gt; netbaseHighestKnown then
        InternalError(Format('.NET Framework version %s not found', [VersionStrings[Version]]))
      else
        InternalError('.NET Framework not found');
    end;
  end;
  Result := DotNetVersionRoot[RegView, Version];
end;
</code></pre>
<p>That code is in the <a href=""https://github.com/jrsoftware/issrc/blob/main/Projects/DotNet.pas"" rel=""nofollow noreferrer""><code>DotNet.pas</code></a> file.</p>
<hr />
<p>As a resut of the above location in Inno Setup raising the error, I have asked him to use regedit and verify the existing off:</p>
<pre><code>\HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\.NETFramework\v4.0.30319
</code></pre>
<hr />
<h3>Update</h3>
<p>So he did try the install using the <code>/log</code> switch and as expected, it says:</p>
<pre><code>2022-05-13 14:15:46.196   Fatal exception during installation process (Exception):
                          Internal error: .NET Framework not found.
2022-05-13 14:15:46.196   Exception message:
2022-05-13 14:15:46.196   Message box (OK):
                          Internal error: .NET Framework not found.
2022-05-13 14:15:53.456   User chose OK.
2022-05-13 14:15:53.456   Message box (OK):
                          Setup was not completed.
                          
                          Please correct the problem and run Setup again.
2022-05-13 14:15:59.450   User chose OK.
2022-05-13 14:15:59.450   Rolling back changes.
2022
</code></pre>
<p>I now await his response about the registry key.</p>
<hr />
<p>I can confirm that in his case, whilst all the framework files etc are installed, that the cause of the internal failure is this function:</p>
<pre><code>function GetDotNetInstallRoot(const RegView: TRegView): String;
var
  K: HKEY;
begin
  if DotNetRoot[RegView] = '' then begin
    if RegOpenKeyExView(RegView, HKEY_LOCAL_MACHINE, 'SOFTWARE\Microsoft\.NETFramework', 0, KEY_QUERY_VALUE, K) = ERROR_SUCCESS then begin
      RegQueryStringValue(K, 'InstallRoot', DotNetRoot[RegView]);
      RegCloseKey(K);
    end;
    if DotNetRoot[RegView] = '' then
      InternalError('.NET Framework not found');
  end;
  Result := DotNetRoot[RegView];
end;
</code></pre>
<p>Here does not have the <code>InstallRoot</code> registry value.</p>
",38,0,0,2,inno-setup;pascal,2022-05-13 21:02:26,2022-05-13 21:02:26,2022-05-13 22:58:59,can anyone shed light on this inno setup error that one of my users is getting   he can install the same software on another computer with no issues  i asked him to supply me with his log file  the installer copies the log to a specific folder with a timestamp in the curstepchange procedure  when the curstep   ssdone   but he could not find any log  i have now asked him to run the installer from a command prompt with the  log       switch to see if we can get at the log that way  his computer is running windows   this is also my development pc operating system   any ideas  note that the installer does check for the existing of the framework in the initializewizard procedure  i am no delphi developer  but i thought i would check the public source code for inno setup and i found two places where this error is displayed  that code is in the  file  as a resut of the above location in inno setup raising the error  i have asked him to use regedit and verify the existing off  so he did try the install using the  log switch and as expected  it says  i now await his response about the registry key  i can confirm that in his case  whilst all the framework files etc are installed  that the cause of the internal failure is this function  here does not have the installroot registry value ,inno setup script not install  displays error   internal error   net framework not found 
268,5563976,72205018,wampserver php site only works on local machine (index.htm works on all devices over LAN),"<p>Wampserver PHP 7.4.26 ,  Apache 2.4.51,  mysql 8.0.27</p>
<p>Having looked at other questions on stack overflow I am now able to access index.htm in www folder or www/project1 folder via any device on LAN.</p>
<p>However, index.php only works on local machine. When trying to access index.php on another device over LAN, the following message is indicated:</p>
<p>&quot;This site can’t be reached</p>
<p>localhost refused to connect.</p>
<p>Try:</p>
<p>Checking the connection
ERR_CONNECTION_REFUSED&quot;</p>
<p>Here is httpd-vhosts.conf:</p>
<pre><code>

# Virtual Hosts
#
&lt;VirtualHost *:80&gt;
  ServerName localhost
  ServerAlias localhost
  DocumentRoot &quot;${INSTALL_DIR}/www&quot;
  &lt;Directory &quot;${INSTALL_DIR}/www/&quot;&gt;
    Options +Indexes +Includes +FollowSymLinks +MultiViews
    AllowOverride All
    Require all granted
  &lt;/Directory&gt;
&lt;/VirtualHost&gt;



&lt;VirtualHost *:80&gt;
    ServerName famtree
    ServerAlias www.tree
    DocumentRoot &quot;c:/wamp64/www/tree&quot;
    &lt;Directory  &quot;c:/wamp64/www/tree/&quot;&gt;
        Options +Indexes +Includes +FollowSymLinks +MultiViews
        AllowOverride All
        Require all granted
    &lt;/Directory&gt;
&lt;/VirtualHost&gt;

</code></pre>
<p>Please advise. Thanks.</p>
<p>Update:</p>
<p>An index.php with the following code does work:</p>
<pre><code>    &lt;?php
    // program to tell php version using ftp/sftp client
     phpinfo();
    ?&gt;
</code></pre>
<p>However my website index.php dosent work:</p>
<pre><code>    &lt;?php

/**
 * webtrees: online genealogy
 * Copyright (C) 2022 webtrees development team
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 * GNU General Public License for more details.
 * You should have received a copy of the GNU General Public License
 * along with this program. If not, see &lt;https://www.gnu.org/licenses/&gt;.
 */

declare(strict_types=1);

namespace Fisharebest\Webtrees;

use function is_file;
use function is_string;
use function parse_url;

use const PHP_SAPI;
use const PHP_URL_PATH;

require __DIR__ . '/vendor/autoload.php';

if (PHP_SAPI === 'cli-server') {
    $file = parse_url($_SERVER['REQUEST_URI'], PHP_URL_PATH);
    if (is_string($file) &amp;&amp; is_file($file)) {
        return false;
    }
}

// @see https://github.com/briannesbitt/Carbon/issues/2536
$file = '/vendor/symfony/translation/TranslatorInterface.php';
if (file_exists(__DIR__ . $file) &amp;&amp; !unlink(__DIR__ . $file)) {
    echo 'Please delete the file ' . $file;
    return;
}

$webtrees = new Webtrees();
$webtrees-&gt;bootstrap();

if (PHP_SAPI === 'cli') {
    $webtrees-&gt;cliRequest();
} else {
    $webtrees-&gt;httpRequest();
}

</code></pre>
",62,1,0,4,php;apache;wampserver;lan,2022-05-11 20:07:56,2022-05-11 20:07:56,2022-05-13 21:18:17,wampserver php       apache      mysql    having looked at other questions on stack overflow i am now able to access index htm in www folder or www project folder via any device on lan  however  index php only works on local machine  when trying to access index php on another device over lan  the following message is indicated   this site can t be reached localhost refused to connect  try  here is httpd vhosts conf  please advise  thanks  update  an index php with the following code does work  however my website index php dosent work ,wampserver php site only works on local machine  index htm works on all devices over lan 
269,1647105,72201862,How do I set up bind via webmin to delegate dns lookups for certain subdomains?,"<p>I have several docker containers with some web applications running via docker compose. One of the containers is a custom DNS server with Bind and Webmin installed. Webmin gives a nice web UI allowing me to update Bind DNS configuration without directly modifying the files or SSHing into the container. I have docker setup to lookup DNS in this order:</p>
<ol>
<li>my docker dns server</li>
<li>my companies internal dns server</li>
<li>google dns server</li>
</ol>
<p>I have one master zone file for top level domain &quot;example.com&quot; defined in dns server 1. I added an address for server1.example.com and dns resolves correctly. I want other subdomains to be resolved from my companies internal dns server.</p>
<ul>
<li>server1.example.com - resolves correctly</li>
<li>server2.example.com - this host is not referenced in the zone file for docker dns server. I would like to somehow delegate this to my companies dns server (server 2)</li>
</ul>
<p>The goal is I should be able to do software development for web applications and deploy them on my docker containers. The code makes internal calls to other &quot;example.com&quot; hosts. I want some of those calls to get directed back to other docker containers rather than the real server because I am developing code on both and want to test it end to end.</p>
<p>I don't want to (and can't) modify my companies dns configuration. I am not an expert in bind or dns setup and looking for the simplest solution.</p>
<p>What configuration can achieve this?</p>
",45,1,-1,3,docker;dns;bind,2022-05-11 16:23:32,2022-05-11 16:23:32,2022-05-13 20:53:16,i have several docker containers with some web applications running via docker compose  one of the containers is a custom dns server with bind and webmin installed  webmin gives a nice web ui allowing me to update bind dns configuration without directly modifying the files or sshing into the container  i have docker setup to lookup dns in this order  i have one master zone file for top level domain  example com  defined in dns server   i added an address for server example com and dns resolves correctly  i want other subdomains to be resolved from my companies internal dns server  the goal is i should be able to do software development for web applications and deploy them on my docker containers  the code makes internal calls to other  example com  hosts  i want some of those calls to get directed back to other docker containers rather than the real server because i am developing code on both and want to test it end to end  i don t want to  and can t  modify my companies dns configuration  i am not an expert in bind or dns setup and looking for the simplest solution  what configuration can achieve this ,how do i set up bind via webmin to delegate dns lookups for certain subdomains 
270,24508,225291,"git-upload-pack: command not found, when cloning remote Git repo","<p>I have been using git to keep two copies of my project in sync, one is my local box, the other the test server.
This is an issue which occurs when I log onto our remote development server using ssh;</p>

<pre><code>git clone me@me.mydevbox.com:/home/chris/myproject
Initialized empty Git repository in /tmp/myproject/.git/
Password:
bash: git-upload-pack: command not found
fatal: The remote end hung up unexpectedly
fetch-pack from 'me@me.mydevbox.com:/home/chris/myproject' failed.
</code></pre>

<p>(the file-names have been changed to protect the guilty... !) </p>

<p>Both boxes run Solaris 10 AMD. I have done some digging,  if I add <code>--upload-pack=$(which git-upload-pack)</code> the command works, (and proves that <code>$PATH</code> contains the path to 'git-upload-pack' as per the RTFM solution)  but this is really annoying, plus 'git push' doesn't work, because I don't think there is a <code>--unpack=</code> option.  </p>

<p>Incidentally, all the git commands work fine from my local box, it is the same version of the software (1.5.4.2), installed on the same NFS mount at <code>/usr/local/bin</code>.  </p>

<p>Can anybody help?</p>
",135638,16,177,4,git;version-control;unix;ssh,2008-10-22 14:14:13,2008-10-22 14:14:13,2022-05-13 20:09:41, the file names have been changed to protect the guilty        both boxes run solaris  amd  i have done some digging   if i add   upload pack   which git upload pack  the command works   and proves that  path contains the path to  git upload pack  as per the rtfm solution   but this is really annoying  plus  git push  doesn t work  because i don t think there is a   unpack  option    incidentally  all the git commands work fine from my local box  it is the same version of the software        installed on the same nfs mount at  usr local bin    can anybody help ,git upload pack  command not found  when cloning remote git repo
271,11277878,72225050,Apache/PHP Correct permissions for uploading a binary that runs server side?,"<p>I've prepared a PHP browser interface (like a modem interface) for an embedded system, that is supposed to help manage the core application (uploading a new binary or AppImage) and its configurations (altering contents of text files).</p>
<p>All great during development, because I'm running PHP server from terminal, as the same user that runs the core software. However, on actual machine, this browser interface will be provided by Apache, so its user will be <code>www-data</code> and the core software needs to be run by the user let's say <code>kiwi</code>.</p>
<p>So my question is, how can I handle the permissions correctly so that there's no security issue like adding user <code>www-data</code> to group <code>kiwi</code> (as far as i'm concerned, this is a security issue)?</p>
",31,0,1,4,php;linux;apache;permissions,2022-05-13 09:01:12,2022-05-13 09:01:12,2022-05-13 09:01:12,i ve prepared a php browser interface  like a modem interface  for an embedded system  that is supposed to help manage the core application  uploading a new binary or appimage  and its configurations  altering contents of text files   all great during development  because i m running php server from terminal  as the same user that runs the core software  however  on actual machine  this browser interface will be provided by apache  so its user will be www data and the core software needs to be run by the user let s say kiwi  so my question is  how can i handle the permissions correctly so that there s no security issue like adding user www data to group kiwi  as far as i m concerned  this is a security issue  ,apache php correct permissions for uploading a binary that runs server side 
272,143091,13454841,How to emulate Windows RT,"<p>How can I run Windows RT (the restricted ARM version of Windows 8) in an emulator, for development purposes? This question contains two parts:</p>

<ul>
<li>Obtaining the image: Does an installation image exist (for vendors, in MSDN, ...)? Can I take a snapshot of the Surface RT disk (how?), or can I extract it somehow from recovery data (I don't know how the recovery system works, but there's a function to wipe and reinstall the software on the Surface completely).</li>
<li>Running the image: What can I emulate it on? I've heard about QEMU, but it has the reputation of being slow. Also, the program must emulate the neccessary hardware (Tegra-3).</li>
</ul>
",7417,2,10,4,windows-8;arm;emulation;windows-rt,2012-11-19 15:30:34,2012-11-19 15:30:34,2022-05-12 22:53:44,how can i run windows rt  the restricted arm version of windows   in an emulator  for development purposes  this question contains two parts ,how to emulate windows rt
273,19096747,72206830,How to expand node added to TreeView of hidden Form?,"<p>c# windows forms App-based software is under development.
The problem is that the node I added to the TreeView control is not expanded.</p>
<p>The execution procedure is as follows.</p>
<ol>
<li>Execute winform with Opacity = 0, ShowInTaskbar = false</li>
<li>Add a node to the TreeView control in the winform and then expand the node (TreeView.ExpandAll)</li>
<li>Show winform with system tray icon
Issue: The TreeView control's nodes are shrunk.</li>
</ol>
<p>The solution I found is
After displaying the winform at startup ('Opacity=1') or executing with'ShowInTaskbar=true', adding a node to the TreeView control and expanding it works fine.</p>
<p>I'm new to C#, which keeps using only MFC, but I can't understand this behavior. Is there a more vivid solution?</p>
<p>Thank you very much.</p>
",51,0,0,4,c#;winforms;treeview;expand,2022-05-11 22:46:08,2022-05-11 22:46:08,2022-05-11 22:46:08,the execution procedure is as follows  i m new to c   which keeps using only mfc  but i can t understand this behavior  is there a more vivid solution  thank you very much ,how to expand node added to treeview of hidden form 
274,16503313,72139622,Calling another EXE with C# on Windows fails on target machine,"<p>I have created a Windows shell extension that provides a menu to users when they right-click in File Explorer. This then invokes a small dialogue App.</p>
<p>I'm a novice at software development so there is probably some schoolboy error I'm making but I just can't see it.</p>
<p>For testing purposes I am hard-coding the path to the EXE and ensuring it's present on the VM.</p>
<pre><code> private void CallExteralAddLocation(string sFullPath)
        {
            string sEXE = Path.Combine(Application.StartupPath, &quot;AddLocation.exe&quot;);
            WriteLog(sEXE);
            // during testing, hard-code this path
            sEXE = &quot;C:\\temp\\AddLocation.exe&quot;;

            System.Diagnostics.Process.Start(sEXE, sFullPath);
        }

       
        private void WriteLog(string sText)
        {
            using (StreamWriter sr = new StreamWriter(&quot;C:\\Temp\\ShellExtLog.txt&quot;))
            {
                sr.WriteLine(sText);
                
            }
        }
</code></pre>
<p>It works fine on my host machine but when running on a VM running Windows 10, which is where I am testing it, the dialogue App does not get invoked.</p>
<p>I have checked that I can invoke the <strong>AddLocation.exe</strong> from a command window on the VM and that works as expected. So it looks like it's just not getting called.</p>
<p>As it's a shell extension it's very difficult to debug. I tried using MessageBoxes and writing to the console but those wouldn't work, so I have added the WriteLog so that I have some idea of what it's doing.</p>
<p>This works on the host machine i.e. a log file is created and it shows the path to the EXE, but no log file is created on the VM.</p>
<p>NOTE: When testing on either machine, I'm installing afresh from the application's MSI. Also note that the host is running Windows 11 and the VM is running Windows 10.</p>
<p>So, why does the same code fail to either run the EXE or create a log file on the VM?</p>
",58,1,1,2,c#;shellexecute,2022-05-06 12:58:57,2022-05-06 12:58:57,2022-05-09 12:19:41,i have created a windows shell extension that provides a menu to users when they right click in file explorer  this then invokes a small dialogue app  i m a novice at software development so there is probably some schoolboy error i m making but i just can t see it  for testing purposes i am hard coding the path to the exe and ensuring it s present on the vm  it works fine on my host machine but when running on a vm running windows   which is where i am testing it  the dialogue app does not get invoked  i have checked that i can invoke the addlocation exe from a command window on the vm and that works as expected  so it looks like it s just not getting called  as it s a shell extension it s very difficult to debug  i tried using messageboxes and writing to the console but those wouldn t work  so i have added the writelog so that i have some idea of what it s doing  this works on the host machine i e  a log file is created and it shows the path to the exe  but no log file is created on the vm  note  when testing on either machine  i m installing afresh from the application s msi  also note that the host is running windows  and the vm is running windows   so  why does the same code fail to either run the exe or create a log file on the vm ,calling another exe with c  on windows fails on target machine
275,7275151,42077948,Selecting Different Web Elements,"<p>I am a Software Quality Assurance Engineer and I am trying to create an Automated test for a webpage.</p>
<p><strong>Some background:</strong></p>
<p>The framework of Selenium that my company uses ONLY allows you to use X paths saved as an object then you use pre-existing methods like &quot;click (someobject)&quot; or &quot;enter (someobject)&quot; etc.</p>
<p><strong>Problem:</strong></p>
<p>I'm currently trying to create a test that selects multiple buttons that are on the same class. There are 6 set buttons that I need to be able to select. Now I can do this but using:</p>
<pre><code>`//*[@id=&quot;tenant-details-accordion&quot;]/div[1]/div[2]/div/div[2]/div[1]/div/a
 //*[@id=&quot;tenant-details-accordion&quot;]/div[1]/div[2]/div/div[2]/div[2]/div/a
 //*[@id=&quot;tenant-details-accordion&quot;]/div[1]/div[2]/div/div[2]/div[3]/div/a
 //*[@id=&quot;tenant-details-accordion&quot;]/div[1]/div[2]/div/div[2]/div[4]/div/a
 //*[@id=&quot;tenant-details-accordion&quot;]/div[1]/div[2]/div/div[2]/div[5]/div/a
 //*[@id=&quot;tenant-details-accordion&quot;]/div[1]/div[2]/div/div[2]/div[6]/div/a`
</code></pre>
<p>-However this is only <strong>temporary</strong> because the test will fail later down the road when a button is removed... I have talked to the Development team about adding Unique ID's to each button. But it does not seem like that is a path they want to go down...</p>
<p><strong>Possible Solution:</strong></p>
<ul>
<li><p><strong>Is it possible to narrow the ‘scope’ of Selenium?</strong><br />
For example telling Selenium to look through a specific class instead of the entire page?<br />
-My thought is to have it search for a class, match a specific text, then select Set.</p>
</li>
<li><p><strong>If yes, then also is it possible to combining multiple X path's</strong>
Something like....</p>
<p><code>//div[@class='col-sm-4'].... //div[contains(.,'Birth Date: Set +')]</code></p>
</li>
</ul>
<p>My thought is that I could create an Xpath that narrows what Selenium will actually be looking through.</p>
<ol>
<li><p>Searching for the class</p>
</li>
<li><p>Searching for Text &quot;Birth Date&quot;</p>
</li>
<li><p>Selecting Set Button</p>
</li>
</ol>
<p><strong>Here are some pictures:</strong>
<a href=""https://i.stack.imgur.com/s5v7p.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/s5v7p.png"" alt=""FRONT END"" /></a></p>
<p>Here is some HTML when I inspect the page
<a href=""https://i.stack.imgur.com/hsk5i.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hsk5i.png"" alt=""HTML CODE"" /></a></p>
",130,3,2,4,selenium;xpath;automation;qwebelement,2017-02-06 23:55:37,2017-02-06 23:55:37,2022-05-08 18:54:52,i am a software quality assurance engineer and i am trying to create an automated test for a webpage  some background  the framework of selenium that my company uses only allows you to use x paths saved as an object then you use pre existing methods like  click  someobject   or  enter  someobject   etc  problem  i m currently trying to create a test that selects multiple buttons that are on the same class  there are  set buttons that i need to be able to select  now i can do this but using   however this is only temporary because the test will fail later down the road when a button is removed    i have talked to the development team about adding unique id s to each button  but it does not seem like that is a path they want to go down    possible solution    div  class  col sm          div contains    birth date  set      my thought is that i could create an xpath that narrows what selenium will actually be looking through  searching for the class searching for text  birth date  selecting set button,selecting different web elements
276,2966337,41777981,SerialPort.BaseStream.ReadAsync drops or scrambles bytes when reading from a USB Serial Port,"<p><strong>Edit:</strong> I've added the sending code and an example of the received output I'm getting. </p>

<hr>

<p>I am reading data from a USB ""virtual"" serial port connected to an embedded system. I have written two methods for receiving the data, one synchronous and one asynchronous. The synchronous one works, and the asynchronous one loses or scrambles a little bit of the incoming data. I cannot tell why the second one fails.</p>

<p><strong>The method that works</strong> calls SerialPort.Read with a read timeout set to zero, and it requests everything in the receive buffer. I check the return value to see how many bytes were actually read and then put the data into a circular buffer for use elsewhere.  This method is called by a timer interrupt, and  it works perfectly to receive serial data (typically at rates above 1.6 Mbps with no data loss). However, the polling timer has become a problem for me and I would prefer to receive the data asynchronously wrt the rest of my code.</p>

<p><strong>The method that loses data</strong> awaits ReadAsync on the serial port BaseStream and loops until cancelled. This approach <em>sort of</em> works, but it often returns the leading byte of a packet out of order, loses a single byte fairly frequently (approximately once every few thousand data bytes), and occasionally loses hundreds of sequential bytes from a packet. </p>

<p>It is possible that there are two completely different problems here, because the loss of <em>larger</em> chunks of data loss seem to be correlated with higher data rates and heavier system activity. That particular part of the problem could potentially be due to buffer overruns -- perhaps through a failure of USB handshaking when the USB scheduler encounters a delay -- but the example I am showing here has only a very small amount of data being transferred at 50 msec intervals, and the system is idle except for this test routine. </p>

<p>I have observed that ReadAsync frequently returns the first byte of a packet on one read, and the remainder of the packet on the next read. I believe this is expected behavior because MSDN says that if no data is available for some period of time, ReadAsync will return with the first byte it receives. However, I think this behavior is somehow related to my problem because when a single byte is missing or out of order, it is ""always"" that first byte, with the rest of the packet arriving normally.</p>

<p>When the packets are small, the ""missing"" byte from the front of the packet often (but not always) appears to be delivered in the next read <em>after</em> the remainder of the packet, and this just makes absolutely no sense to me. With larger packets this still happens occasionally, but more often the first byte is just missing when the packets are large.</p>

<p>I've searched far and wide, and have read every SO question I could find on this topic. I found other people with what appears to be a similar problem (ex: <a href=""https://stackoverflow.com/questions/35870794/serialport-basestream-readasync-missing-the-first-byte"">SerialPort.BaseStream.ReadAsync missing the first byte</a>), but nobody with any accepted or even plausible solutions. </p>

<p>Ben Voigt  (<a href=""http://www.sparxeng.com/blog/software/must-use-net-system-io-ports-serialport"" rel=""noreferrer"">http://www.sparxeng.com/blog/software/must-use-net-system-io-ports-serialport</a>) and others who really seem to know serial comms have recommended the use of ReadAsync on the basestream, and Microsoft's IOT team has also recommended this approach, so I have to believe the approach <em>should</em> work. </p>

<p><strong>Question 1:</strong> Why is my code using ReadAsync on a USB Serial BaseStream dropping /scrambling bytes?  </p>

<p><strong>Question 2:</strong> If ReadAsync cannot be made to reliably return all the bytes received bytes in the correct order, can I just put an async wrapper around the traditional SerialPort.Read  and await / loop it so I don't have to poll from a timer? I've read that this is a bad idea, but I've also read that the SerialPort class is internally asynchronous, so perhaps that makes it OK?  Or is my only alternative to put this on a worker thread and just let it spend all its time waiting?</p>

<p>My code is below. I have set <code>serialPort1.ReadTimeout = 0;</code> and <code>serialPort1.BaseStream.ReadTimeout = 0;</code> (and I have tried other durations).
I have enabled RTS and DTR, and since this is a USB_serial port it should handle handshake internally, and it certainly appears to do so when I read synchronously -- but perhaps that's not true when I read from the BaseStream?</p>

<p>Here is the first method:</p>

<pre><code>// this method works perfectly when called from a timer.
// SerialPort.ReadTimeout must be set to zero for this to work.
// It handles incoming bytes reliably at rates above 1.6 Mbps.

private void ReadSerialBytes()
{
    if (!serialPort1.IsOpen)
        return;

    if (serialPort1.BytesToRead &gt; 0)
    {
        var receiveBuffer = new byte[serialPort1.ReadBufferSize];

        var numBytesRead = serialPort1.Read(receiveBuffer, 0, serialPort1.ReadBufferSize);
        var bytesReceived = new byte[numBytesRead];
        Array.Copy(receiveBuffer, bytesReceived, numBytesRead);

        // Here is where I audit the received data.
        // the NewSerialData event handler displays the 
        // data received (as hex bytes) and writes it to disk.
        RaiseEventNewSerialData(bytesReceived);

        // serialInBuffer is a ""thread-safe"" global circular byte buffer 
        // The data in serialInBuffer matches the data audited above.
        serialInBuffer.Enqueue(bytesReceived, 0, numBytesRead);
    }
}
</code></pre>

<p>Here is the second method, <strong>Edited</strong> to remove the tail recursion noted by @Lucero. Now I won't run out of memory :) but the original data loss problem, of course, remains.</p>

<pre><code>// This method is called once after the serial port is opened,
// and it repeats until cancelled. 
// 
// This code ""works"" but periodically drops the first byte of a packet, 
// or returns that byte in the wrong order.
// It occasionally drops several hundred bytes in a row.
private async Task ReadSerialBytesAsync(CancellationToken ct)
{
    while((!ct.IsCancellationRequested) &amp;&amp; (serialPort1.IsOpen))
    {
        try
        {
            serialPort1.BaseStream.ReadTimeout = 0;
            var bytesToRead = 1024;
            var receiveBuffer = new byte[bytesToRead];
            var numBytesRead = await serialPort1.BaseStream.ReadAsync(receiveBuffer, 0, bytesToRead, ct);

            var bytesReceived = new byte[numBytesRead];
            Array.Copy(receiveBuffer, bytesReceived, numBytesRead);

             // Here is where I audit the received data.
             // the NewSerialData event handler displays the 
             // data received (as hex bytes) and writes it to disk.
             RaiseEventNewSerialData(bytesReceived);

            // serialInBuffer is a ""thread-safe"" global circular byte buffer 
            // The data in serialInBuffer matches the data audited above.
            serialInBuffer.Enqueue(receiveBuffer, 0, numBytesRead);
        }
        catch (Exception ex)
        {
            MessageBox.Show(""Error in ReadSerialBytesAsync: "" + ex.ToString());
            throw;
        }
    }
}
</code></pre>

<p>Here is C++ code from the sending system (teensy 3.2 with an ARM chip). 
It sends a sequence of bytes from 00 through FF, repeated every 50 msec. </p>

<pre><code> void SendTestData()
 {
    byte asyncTestBuffer[256] = { 0 };
    for (int i = 0; i &lt; 256; i++)
        asyncTestBuffer[i] = i;

    while(true)
    {
    Serial.write(asyncTestBuffer, sizeof(asyncTestBuffer));
    delay(50);
    }
}
</code></pre>

<p>The traditional synchronous SerialPort.Read (called from a timer) receives each block completely exactly as expected, with no data loss. It looks like this, over and over:</p>

<pre><code>=====
32 msec =&gt; Received 256 bytes 
000102030405060708090A0B0C0D0E0F101112131415161718191A1B1C1D1E1F202122232425262728292A2B2C2D2E2F303132333435363738393A3B3C3D3E3F404142434445464748494A4B4C4D4E4F505152535455565758595A5B5C5D5E5F606162636465666768696A6B6C6D6E6F707172737475767778797A7B7C7D7E7F808182838485868788898A8B8C8D8E8F909192939495969798999A9B9C9D9E9FA0A1A2A3A4A5A6A7A8A9AAABACADAEAFB0B1B2B3B4B5B6B7B8B9BABBBCBDBEBFC0C1C2C3C4C5C6C7C8C9CACBCCCDCECFD0D1D2D3D4D5D6D7D8D9DADBDCDDDEDFE0E1E2E3E4E5E6E7E8E9EAEBECEDEEEFF0F1F2F3F4F5F6F7F8F9FAFBFCFDFEFF
=====
</code></pre>

<p>Now here is what SerialPort.BaseStream.ReadAsync receives. In another version I appended a terminal packet sequence number to prove that when I see a zero followed by another zero, there's not really an entire missing packet between them. Packet sequence numbers were all present, so the leading byte really does seem to be missing or delivered out of order.</p>

<pre><code>7 msec =&gt; Received 255 bytes 
0102030405060708090A0B0C0D0E0F101112131415161718191A1B1C1D1E1F202122232425262728292A2B2C2D2E2F303132333435363738393A3B3C3D3E3F404142434445464748494A4B4C4D4E4F505152535455565758595A5B5C5D5E5F606162636465666768696A6B6C6D6E6F707172737475767778797A7B7C7D7E7F808182838485868788898A8B8C8D8E8F909192939495969798999A9B9C9D9E9FA0A1A2A3A4A5A6A7A8A9AAABACADAEAFB0B1B2B3B4B5B6B7B8B9BABBBCBDBEBFC0C1C2C3C4C5C6C7C8C9CACBCCCDCECFD0D1D2D3D4D5D6D7D8D9DADBDCDDDEDFE0E1E2E3E4E5E6E7E8E9EAEBECEDEEEFF0F1F2F3F4F5F6F7F8F9FAFBFCFDFEFF
=====
5 msec =&gt; Received 1 bytes 
00
=====
55 msec =&gt; Received 1 bytes 
00
=====
4 msec =&gt; Received 255 bytes 
0102030405060708090A0B0C0D0E0F101112131415161718191A1B1C1D1E1F202122232425262728292A2B2C2D2E2F303132333435363738393A3B3C3D3E3F404142434445464748494A4B4C4D4E4F505152535455565758595A5B5C5D5E5F606162636465666768696A6B6C6D6E6F707172737475767778797A7B7C7D7E7F808182838485868788898A8B8C8D8E8F909192939495969798999A9B9C9D9E9FA0A1A2A3A4A5A6A7A8A9AAABACADAEAFB0B1B2B3B4B5B6B7B8B9BABBBCBDBEBFC0C1C2C3C4C5C6C7C8C9CACBCCCDCECFD0D1D2D3D4D5D6D7D8D9DADBDCDDDEDFE0E1E2E3E4E5E6E7E8E9EAEBECEDEEEFF0F1F2F3F4F5F6F7F8F9FAFBFCFDFEFF
=====
42 msec =&gt; Received 1 bytes 
00
=====
5 msec =&gt; Received 255 bytes 
0102030405060708090A0B0C0D0E0F101112131415161718191A1B1C1D1E1F202122232425262728292A2B2C2D2E2F303132333435363738393A3B3C3D3E3F404142434445464748494A4B4C4D4E4F505152535455565758595A5B5C5D5E5F606162636465666768696A6B6C6D6E6F707172737475767778797A7B7C7D7E7F808182838485868788898A8B8C8D8E8F909192939495969798999A9B9C9D9E9FA0A1A2A3A4A5A6A7A8A9AAABACADAEAFB0B1B2B3B4B5B6B7B8B9BABBBCBDBEBFC0C1C2C3C4C5C6C7C8C9CACBCCCDCECFD0D1D2D3D4D5D6D7D8D9DADBDCDDDEDFE0E1E2E3E4E5E6E7E8E9EAEBECEDEEEFF0F1F2F3F4F5F6F7F8F9FAFBFCFDFEFF
=====
68 msec =&gt; Received 1 bytes 
00
=====
7 msec =&gt; Received 255 bytes 
0102030405060708090A0B0C0D0E0F101112131415161718191A1B1C1D1E1F202122232425262728292A2B2C2D2E2F303132333435363738393A3B3C3D3E3F404142434445464748494A4B4C4D4E4F505152535455565758595A5B5C5D5E5F606162636465666768696A6B6C6D6E6F707172737475767778797A7B7C7D7E7F808182838485868788898A8B8C8D8E8F909192939495969798999A9B9C9D9E9FA0A1A2A3A4A5A6A7A8A9AAABACADAEAFB0B1B2B3B4B5B6B7B8B9BABBBCBDBEBFC0C1C2C3C4C5C6C7C8C9CACBCCCDCECFD0D1D2D3D4D5D6D7D8D9DADBDCDDDEDFE0E1E2E3E4E5E6E7E8E9EAEBECEDEEEFF0F1F2F3F4F5F6F7F8F9FAFBFCFDFEFF
=====
31 msec =&gt; Received 255 bytes 
0102030405060708090A0B0C0D0E0F101112131415161718191A1B1C1D1E1F202122232425262728292A2B2C2D2E2F303132333435363738393A3B3C3D3E3F404142434445464748494A4B4C4D4E4F505152535455565758595A5B5C5D5E5F606162636465666768696A6B6C6D6E6F707172737475767778797A7B7C7D7E7F808182838485868788898A8B8C8D8E8F909192939495969798999A9B9C9D9E9FA0A1A2A3A4A5A6A7A8A9AAABACADAEAFB0B1B2B3B4B5B6B7B8B9BABBBCBDBEBFC0C1C2C3C4C5C6C7C8C9CACBCCCDCECFD0D1D2D3D4D5D6D7D8D9DADBDCDDDEDFE0E1E2E3E4E5E6E7E8E9EAEBECEDEEEFF0F1F2F3F4F5F6F7F8F9FAFBFCFDFEFF
=====
9 msec =&gt; Received 1 bytes 
00
=====
33 msec =&gt; Received 1 bytes 
00
=====
10 msec =&gt; Received 255 bytes 
0102030405060708090A0B0C0D0E0F101112131415161718191A1B1C1D1E1F202122232425262728292A2B2C2D2E2F303132333435363738393A3B3C3D3E3F404142434445464748494A4B4C4D4E4F505152535455565758595A5B5C5D5E5F606162636465666768696A6B6C6D6E6F707172737475767778797A7B7C7D7E7F808182838485868788898A8B8C8D8E8F909192939495969798999A9B9C9D9E9FA0A1A2A3A4A5A6A7A8A9AAABACADAEAFB0B1B2B3B4B5B6B7B8B9BABBBCBDBEBFC0C1C2C3C4C5C6C7C8C9CACBCCCDCECFD0D1D2D3D4D5D6D7D8D9DADBDCDDDEDFE0E1E2E3E4E5E6E7E8E9EAEBECEDEEEFF0F1F2F3F4F5F6F7F8F9FAFBFCFDFEFF
=====
55 msec =&gt; Received 255 bytes 
0102030405060708090A0B0C0D0E0F101112131415161718191A1B1C1D1E1F202122232425262728292A2B2C2D2E2F303132333435363738393A3B3C3D3E3F404142434445464748494A4B4C4D4E4F505152535455565758595A5B5C5D5E5F606162636465666768696A6B6C6D6E6F707172737475767778797A7B7C7D7E7F808182838485868788898A8B8C8D8E8F909192939495969798999A9B9C9D9E9FA0A1A2A3A4A5A6A7A8A9AAABACADAEAFB0B1B2B3B4B5B6B7B8B9BABBBCBDBEBFC0C1C2C3C4C5C6C7C8C9CACBCCCDCECFD0D1D2D3D4D5D6D7D8D9DADBDCDDDEDFE0E1E2E3E4E5E6E7E8E9EAEBECEDEEEFF0F1F2F3F4F5F6F7F8F9FAFBFCFDFEFF
=====
12 msec =&gt; Received 1 bytes 
00
=====
12 msec =&gt; Received 1 bytes 
00
=====
15 msec =&gt; Received 255 bytes 
0102030405060708090A0B0C0D0E0F101112131415161718191A1B1C1D1E1F202122232425262728292A2B2C2D2E2F303132333435363738393A3B3C3D3E3F404142434445464748494A4B4C4D4E4F505152535455565758595A5B5C5D5E5F606162636465666768696A6B6C6D6E6F707172737475767778797A7B7C7D7E7F808182838485868788898A8B8C8D8E8F909192939495969798999A9B9C9D9E9FA0A1A2A3A4A5A6A7A8A9AAABACADAEAFB0B1B2B3B4B5B6B7B8B9BABBBCBDBEBFC0C1C2C3C4C5C6C7C8C9CACBCCCDCECFD0D1D2D3D4D5D6D7D8D9DADBDCDDDEDFE0E1E2E3E4E5E6E7E8E9EAEBECEDEEEFF0F1F2F3F4F5F6F7F8F9FAFBFCFDFEFF
=====
68 msec =&gt; Received 255 bytes 
0102030405060708090A0B0C0D0E0F101112131415161718191A1B1C1D1E1F202122232425262728292A2B2C2D2E2F303132333435363738393A3B3C3D3E3F404142434445464748494A4B4C4D4E4F505152535455565758595A5B5C5D5E5F606162636465666768696A6B6C6D6E6F707172737475767778797A7B7C7D7E7F808182838485868788898A8B8C8D8E8F909192939495969798999A9B9C9D9E9FA0A1A2A3A4A5A6A7A8A9AAABACADAEAFB0B1B2B3B4B5B6B7B8B9BABBBCBDBEBFC0C1C2C3C4C5C6C7C8C9CACBCCCDCECFD0D1D2D3D4D5D6D7D8D9DADBDCDDDEDFE0E1E2E3E4E5E6E7E8E9EAEBECEDEEEFF0F1F2F3F4F5F6F7F8F9FAFBFCFDFEFF
=====
16 msec =&gt; Received 1 bytes 
00
=====
14 msec =&gt; Received 256 bytes 
000102030405060708090A0B0C0D0E0F101112131415161718191A1B1C1D1E1F202122232425262728292A2B2C2D2E2F303132333435363738393A3B3C3D3E3F404142434445464748494A4B4C4D4E4F505152535455565758595A5B5C5D5E5F606162636465666768696A6B6C6D6E6F707172737475767778797A7B7C7D7E7F808182838485868788898A8B8C8D8E8F909192939495969798999A9B9C9D9E9FA0A1A2A3A4A5A6A7A8A9AAABACADAEAFB0B1B2B3B4B5B6B7B8B9BABBBCBDBEBFC0C1C2C3C4C5C6C7C8C9CACBCCCDCECFD0D1D2D3D4D5D6D7D8D9DADBDCDDDEDFE0E1E2E3E4E5E6E7E8E9EAEBECEDEEEFF0F1F2F3F4F5F6F7F8F9FAFBFCFDFEFF
=====
</code></pre>

<p>I've spent a couple of weeks tracking down this problem, which originally manifested itself in bizarre behavior from a product under development. I am pretty sure I must be doing something wrong, but I just can't see it, and at this point I am quite desperate for any thoughts or suggestions!</p>
",9743,3,13,3,c#;serial-port;usbserial,2017-01-21 12:00:34,2017-01-21 12:00:34,2022-05-08 16:42:16,edit  i ve added the sending code and an example of the received output i m getting   i am reading data from a usb virtual serial port connected to an embedded system  i have written two methods for receiving the data  one synchronous and one asynchronous  the synchronous one works  and the asynchronous one loses or scrambles a little bit of the incoming data  i cannot tell why the second one fails  the method that works calls serialport read with a read timeout set to zero  and it requests everything in the receive buffer  i check the return value to see how many bytes were actually read and then put the data into a circular buffer for use elsewhere   this method is called by a timer interrupt  and  it works perfectly to receive serial data  typically at rates above   mbps with no data loss   however  the polling timer has become a problem for me and i would prefer to receive the data asynchronously wrt the rest of my code  the method that loses data awaits readasync on the serial port basestream and loops until cancelled  this approach sort of works  but it often returns the leading byte of a packet out of order  loses a single byte fairly frequently  approximately once every few thousand data bytes   and occasionally loses hundreds of sequential bytes from a packet   it is possible that there are two completely different problems here  because the loss of larger chunks of data loss seem to be correlated with higher data rates and heavier system activity  that particular part of the problem could potentially be due to buffer overruns    perhaps through a failure of usb handshaking when the usb scheduler encounters a delay    but the example i am showing here has only a very small amount of data being transferred at  msec intervals  and the system is idle except for this test routine   i have observed that readasync frequently returns the first byte of a packet on one read  and the remainder of the packet on the next read  i believe this is expected behavior because msdn says that if no data is available for some period of time  readasync will return with the first byte it receives  however  i think this behavior is somehow related to my problem because when a single byte is missing or out of order  it is always that first byte  with the rest of the packet arriving normally  when the packets are small  the missing byte from the front of the packet often  but not always  appears to be delivered in the next read after the remainder of the packet  and this just makes absolutely no sense to me  with larger packets this still happens occasionally  but more often the first byte is just missing when the packets are large  i ve searched far and wide  and have read every so question i could find on this topic  i found other people with what appears to be a similar problem  ex     but nobody with any accepted or even plausible solutions   ben voigt     and others who really seem to know serial comms have recommended the use of readasync on the basestream  and microsoft s iot team has also recommended this approach  so i have to believe the approach should work   question   why is my code using readasync on a usb serial basestream dropping  scrambling bytes    question   if readasync cannot be made to reliably return all the bytes received bytes in the correct order  can i just put an async wrapper around the traditional serialport read  and await   loop it so i don t have to poll from a timer  i ve read that this is a bad idea  but i ve also read that the serialport class is internally asynchronous  so perhaps that makes it ok   or is my only alternative to put this on a worker thread and just let it spend all its time waiting  here is the first method  here is the second method  edited to remove the tail recursion noted by  lucero  now i won t run out of memory    but the original data loss problem  of course  remains  the traditional synchronous serialport read  called from a timer  receives each block completely exactly as expected  with no data loss  it looks like this  over and over  now here is what serialport basestream readasync receives  in another version i appended a terminal packet sequence number to prove that when i see a zero followed by another zero  there s not really an entire missing packet between them  packet sequence numbers were all present  so the leading byte really does seem to be missing or delivered out of order  i ve spent a couple of weeks tracking down this problem  which originally manifested itself in bizarre behavior from a product under development  i am pretty sure i must be doing something wrong  but i just can t see it  and at this point i am quite desperate for any thoughts or suggestions ,serialport basestream readasync drops or scrambles bytes when reading from a usb serial port
277,5934625,72158390,How to compare text and select similar sentences in sqlite?,"<p>I'm using NLP to extract sentences containing certain keywords from SEC filings across different years. I store the output via pandas dataframe in sqlite. So far so good.
The problem comes when I want to compare sentences from two different years, say 2022 and 2021.</p>
<p>I've been using the following query:</p>
<p><code>query = &quot;select Nvidia_2022.Research as Research_2022, Nvidia_2021.Research as Research_2021 from Nvidia_2022 join Nvidia_2021 where '%' || Nvidia_2022.Research || '%' like '%' || Nvidia_2021.Research || '%'&quot;</code></p>
<p>This works most of the time for sentences which are exactly the same. Here's the output.</p>
<p><code>['Such license and development arrangements can further enhance the reach of our technology.'</code></p>
<p><code>'Such license and development arrangements can further enhance the reach of our technology.']</code></p>
<p>Sometimes however, sentences differ slightly, like this:</p>
<p><code>['We have invested over $29 billion in research and development since our inception, yielding inventions that are essential to modern computing.'</code></p>
<p><code>'We have invested over $24 billion in research and development since our inception, yielding inventions that are essential to modern computing.']</code></p>
<p>$29 billion vs $24 billion</p>
<p>or there are other differences at the end of the sentences:</p>
<p><code>'Our Compute &amp; Networking segment includes Data Center platforms and systems for AI, HPC, and accelerated computing; Mellanox networking and interconnect solutions; automotive AI Cockpit, autonomous driving development agreements, and autonomous vehicle solutions; cryptocurrency mining processors, or CMP; Jetson for robotics and other embedded platforms; and NVIDIA AI Enterprise and other software.'</code></p>
<p><code>'Our Compute &amp; Networking segment includes Data Center platforms and systems for AI, HPC, and accelerated computing; Mellanox networking and interconnect solutions; automotive AI Cockpit, autonomous driving development agreements, and autonomous vehicle solutions; and Jetson for robotics and other embedded platforms.'</code></p>
<p>My questions:</p>
<p>Is there a way in sqlite or other sql databases to do as much text comparison work as possible, and then pass the most complicated sentences to python to do something like levenshtein_distance or transformers sentence comparison?</p>
<p>Or should I just stop bothering with SQL comparison queries, and get down to heavy lifting in python right away?</p>
<p>I'm trying to utilize as much sql as possible as it tends to be much faster than calculating distances in python.</p>
",52,2,0,4,python;sql;sqlite;sentence-similarity,2022-05-08 08:38:19,2022-05-08 08:38:19,2022-05-08 10:01:42,i ve been using the following query  query    select nvidia_ research as research_  nvidia_ research as research_ from nvidia_ join nvidia_ where        nvidia_ research        like        nvidia_ research         this works most of the time for sentences which are exactly the same  here s the output    such license and development arrangements can further enhance the reach of our technology    such license and development arrangements can further enhance the reach of our technology    sometimes however  sentences differ slightly  like this    we have invested over   billion in research and development since our inception  yielding inventions that are essential to modern computing    we have invested over   billion in research and development since our inception  yielding inventions that are essential to modern computing      billion vs   billion or there are other differences at the end of the sentences   our compute  amp  networking segment includes data center platforms and systems for ai  hpc  and accelerated computing  mellanox networking and interconnect solutions  automotive ai cockpit  autonomous driving development agreements  and autonomous vehicle solutions  cryptocurrency mining processors  or cmp  jetson for robotics and other embedded platforms  and nvidia ai enterprise and other software    our compute  amp  networking segment includes data center platforms and systems for ai  hpc  and accelerated computing  mellanox networking and interconnect solutions  automotive ai cockpit  autonomous driving development agreements  and autonomous vehicle solutions  and jetson for robotics and other embedded platforms   my questions  is there a way in sqlite or other sql databases to do as much text comparison work as possible  and then pass the most complicated sentences to python to do something like levenshtein_distance or transformers sentence comparison  or should i just stop bothering with sql comparison queries  and get down to heavy lifting in python right away  i m trying to utilize as much sql as possible as it tends to be much faster than calculating distances in python ,how to compare text and select similar sentences in sqlite 
278,576311,72145132,How to redirect from one directory to another while protecting from file addition and deletion?,"<p>A program I am using has a directory for Python plugins in the installation path:</p>
<pre><code>C:\Program Files\...\plugins
</code></pre>
<p>This is normally empty.  The software is hard-wired to look for plugins here and nowhere else.</p>
<p>I want to develop plugins.  However, I would prefer to keep the code elsewhere, for example:</p>
<pre><code>D:\...\plugins
</code></pre>
<p>I also want to make sure that software updates do not result in additions or deletions of any kind to my working directory.</p>
<p>I deleted the directory in the install path and replaced it with a symlink to my directory:</p>
<pre><code>mklink /d &quot;C:\Program Files\...\plugins&quot; &quot;D:\...\plugins&quot;
</code></pre>
<p>Now, if I delete the link <code>C:\Program Files\...\plugins</code> my working directory <code>D:\...\plugins</code> is safe, nothing happens to it.  In other words, if I uninstall the software (which would presumably delete the link), my code is safe.</p>
<p>If, however, I add or delete a file in the link (for example, via command line from <code>C:\Program Files\...\plugins</code> my working directory is modified accordingly.</p>
<p>What I am after is a reference from <code>C:\Program Files\...\plugins</code> to <code>D:\...\plugins</code> that will make the software see my code.  However, any installation or update of the software should not be able to delete or add files to my working directory.  The software itself has no such functionality.  In other words, all it does is read this directory to install the plugins.  No writing at all within the application.  If I could redirect it to my directory it would be perfect.  There are no provisions to add a directory to the search path, otherwise this would be the perfect solution.</p>
<p>The only way I have been able to make <code>mklink</code> work is to make each plugin a symlink.  In other words these links:</p>
<pre><code>C:\Program Files\...\plugins\plugin_01
C:\Program Files\...\plugins\plugin_02
C:\Program Files\...\plugins\plugin_03
C:\Program Files\...\plugins\plugin_04
</code></pre>
<p>Are actually individual links to the corresponding development directories:</p>
<pre><code>D:\...\plugins\plugin_01
D:\...\plugins\plugin_02
D:\...\plugins\plugin_03
D:\...\plugins\plugin_04
</code></pre>
<p>This means that if <code>C:\Program Files\...\plugins</code> is deleted or modified by an installation or update nothing whatsoever happens to my codebase.  I tested this and it works.  It carries a bit of a maintenance load in that you have to create a symlink for every project.  Not a huge deal, but it would be nice to be able to achieve the same end result with an approach that automatically covers everything in the development path.</p>
",13,0,0,2,windows;symlink,2022-05-06 20:06:50,2022-05-06 20:06:50,2022-05-06 20:12:25,a program i am using has a directory for python plugins in the installation path  this is normally empty   the software is hard wired to look for plugins here and nowhere else  i want to develop plugins   however  i would prefer to keep the code elsewhere  for example  i also want to make sure that software updates do not result in additions or deletions of any kind to my working directory  i deleted the directory in the install path and replaced it with a symlink to my directory  now  if i delete the link c  program files     plugins my working directory d      plugins is safe  nothing happens to it   in other words  if i uninstall the software  which would presumably delete the link   my code is safe  if  however  i add or delete a file in the link  for example  via command line from c  program files     plugins my working directory is modified accordingly  what i am after is a reference from c  program files     plugins to d      plugins that will make the software see my code   however  any installation or update of the software should not be able to delete or add files to my working directory   the software itself has no such functionality   in other words  all it does is read this directory to install the plugins   no writing at all within the application   if i could redirect it to my directory it would be perfect   there are no provisions to add a directory to the search path  otherwise this would be the perfect solution  the only way i have been able to make mklink work is to make each plugin a symlink   in other words these links  are actually individual links to the corresponding development directories  this means that if c  program files     plugins is deleted or modified by an installation or update nothing whatsoever happens to my codebase   i tested this and it works   it carries a bit of a maintenance load in that you have to create a symlink for every project   not a huge deal  but it would be nice to be able to achieve the same end result with an approach that automatically covers everything in the development path ,how to redirect from one directory to another while protecting from file addition and deletion 
279,19036311,72118171,How do I get the canvas to show behind my HTML so my animated cursor will move over the screen?,"<p>I want the canvas to show behind the website not over it. I have tried using z index and that does not work. I want to be able to see my actual website while moving the cursor over things. So I need the cursor to show on the website. It just blocks out my whole section. How can I get this to work correctly?</p>
<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>const navToggle = document.querySelector('.nav-toggle');
const navLinks = document.querySelectorAll('.nav__link')


navToggle.addEventListener('click', () =&gt; {
    document.body.classList.toggle('nav-open');
});

navLinks.forEach(link =&gt; {
    link.addEventListener('click', () =&gt; {
        document.body.classList.remove('nav-open');
    })
})

// Canvas

const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');
canvas.width = window.innerWidth;
canvas.height = window.innerHeight;
let spots = [];
let hue = 0;

const mouse = {
    x: undefined,
    y: undefined
}

canvas.addEventListener('mousemove', function (event) {
    mouse.x = event.x;
    mouse.y = event.y;
    for (let i = 0; i &lt; 3; i++) {
        spots.push(new Particle());
    }
});

class Particle {
    constructor() {
        this.x = mouse.x;
        this.y = mouse.y;
        this.size = Math.random() * 2 + 0.1;
        this.speedX = Math.random() * 2 - 1;
        this.speedY = Math.random() * 2 - 1;
        this.color = 'hsl(' + hue + ', 100%, 50%)';
    }
    update() {
        this.x += this.speedX;
        this.y += this.speedY;
        if (this.size &gt; 0.1) this.size -= 0.03;
    }
    draw() {
        ctx.fillStyle = this.color;
        ctx.beginPath();
        ctx.arc(this.x, this.y, this.size, 0, Math.PI * 2);
        ctx.fill();
    }
}
function handleParticle() {
    for (let i = 0; i &lt; spots.length; i++) {
        spots[i].update();
        spots[i].draw();
        for (let j = i; j &lt; spots.length; j++) {
            const dx = spots[i].x - spots[j].x;
            const dy = spots[i].y - spots[j].y;
            const distance = Math.sqrt(dx * dx + dy * dy);
            if (distance &lt; 90) {
                ctx.beginPath();
                ctx.strokeStyle = spots[i].color;
                ctx.lineWidth = spots[i].size / 10;
                ctx.moveTo(spots[i].x, spots[i].y);
                ctx.lineTo(spots[j].x, spots[j].y);
                ctx.stroke();
            }
        }
        if (spots[i].size &lt;= 0.3) {
            spots.splice(i, 1); i--;
        }
    }
}
function animate() {
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    handleParticle();
    hue++;
    requestAnimationFrame(animate);
}
window.addEventListener('resize', function () {
    canvas.width = innerWidth;
    canvas.height = innerHeight;
    init();
})
window.addEventListener('mouseout', function () {
    mouse.x = undefined;
    mouse.y = undefined;
})
animate()</code></pre>
<pre class=""snippet-code-css lang-css prettyprint-override""><code>*,
*::before,
*::after {
    box-sizing: border-box;
}

html,
body {
    overflow-x: hidden;
}

body {
    position: relative
}


/* Custom Properties */

:root {
    --ff-primary: 'Source Sans Pro', sans-serif;
    --ff-secondary: 'Source Code Pro', monospace;

    --fw-reg: 300;
    --fw-bold: 900;

    --clr-light: #fff;
    --clr-dark: #303030;
    --clr-accent: #16e0bd;

    --fs-h1: 3rem;
    --fs-h2: 2.25rem;
    --fs-h3: 1.25rem;
    --fs-body: 1rem;

    --bs: 0.25em 0.25em 0.75em rgba(0, 0, 0, .25),
        0.125em 0.125em 0.25em rgba(0, 0, 0, .15);
}

@media (min-width: 800px) {
    :root {
        --fs-h1: 4.5rem;
        --fs-h2: 3.75rem;
        --fs-h3: 1.5rem;
        --fs-body: 1.125rem;
    }
}

/* General styles */

html {
    scroll-behavior: smooth;
}


body {
    background: var(--clr-light);
    color: var(--clr-dark);
    margin: 0;
    font-family: var(--ff-primary);
    font-size: var(--fs-body);
    line-height: 1.6;
}

#canvas {
    width: 100%;
    height: 100%;
    border: 2px solid red;
    z-index: -1;
}

/* #canvas {
    position: absolute;
    left: 0;
    top: 0;
    z-index: -1;
    width: 100%;
    height: 100%;
} */

section {
    padding: 5em 2em;
}

img {
    display: block;
    max-width: 100%;
}

strong {
    font-weight: var(--fw-bold)
}

:focus {
    outline: 3px solid var(--clr-accent);
    outline-offset: 3px;
}

/* Buttons */

.btn {
    display: inline-block;
    padding: .5em 2em;
    background: var(--clr-accent);
    color: var(--clr-dark);
    text-decoration: none;
    cursor: pointer;
    font-size: 15px;
    text-transform: uppercase;
    letter-spacing: 5px;
    font-weight: var(--fw-bold);
    transition: transform 200ms ease-in-out;
    margin: 15px;
    border-radius: 8px;
    border-style: groove;
    border-width: 3px;
    border-color: var(--clr-accent);
}

.btn2 {
    display: inline-block;
    padding: .4em 1em;
    background: var(--clr-accent);
    color: var(--clr-dark);
    text-decoration: none;
    cursor: pointer;
    font-size: 15px;
    text-transform: uppercase;
    letter-spacing: 2px;
    font-weight: var(--fw-bold);
    transition: transform 200ms ease-in-out;
    margin: 15px;
    border-radius: 8px;
    border-style: groove;
    border-width: 3px;
    border-color: var(--clr-accent);
}

.btn2:hover {
    transform: scale(1.2);
}

.btn:hover {
    transform: scale(1.2);
}

/* Typography */

h1,
h2,
h3 {
    line-height: 1;
    margin: 0;
}

h1 {
    font-size: var(--fs-h1)
}

h2 {
    font-size: var(--fs-h2)
}

h3 {
    font-size: var(--fs-h3)
}

.section__title {
    margin-bottom: .25em;
}


.section__title--intro {
    font-weight: var(--fw-reg);
}

.section__title--intro strong {
    display: block;
}

.section__subtitle {
    margin: 0;
    font-size: var(--fs-h3);
}

.section__subtitle--intro,
.section__subtitle--about {
    background: var(--clr-accent);
    padding: .25em 1em;
    font-family: var(--ff-secondary);
    margin-bottom: 1em;
}

.section__subtitle--work {
    color: var(--clr-accent);
    font-weight: var(--fw-bold);
    margin-bottom: 2em;
}


/* header */

header {
    display: flex;
    justify-content: space-between;
    padding: 1em;
}


.logo {
    max-width: 150px;
    z-index: 100;
}

.nav {
    position: fixed;
    background: var(--clr-dark);
    color: var(--clr-light);
    top: 0;
    bottom: 0;
    left: 0;
    right: 0;
    z-index: 100;

    transform: translateX(100%);
    transition: transform 250ms cubic-bezier(.5, 0, .5, 1);
}

.nav__list {
    list-style: none;
    display: flex;
    height: 100%;
    flex-direction: column;
    justify-content: space-evenly;
    align-items: center;
    margin: 0;
    padding: 0;
}

.nav__link {
    color: inherit;
    font-weight: var(--fw-bold);
    font-size: var(--fs-h2);
    text-decoration: none;
}

.nav__link:hover {
    color: var(--clr-accent);
}

.nav-toggle {
    padding: .5em;
    background: transparent;
    border: 0;
    cursor: pointer;
    position: absolute;
    right: 1em;
    top: 1em;
    z-index: 1000;
}

.nav-open .nav {
    transform: translateX(0);
}

.nav-open .nav-toggle {
    position: fixed;
}

.nav-open .hamburger {
    transform: rotate(.625turn);
}

.nav-open .hamburger::before {
    transform: rotate(90deg) translateX(-6px);
}

.nav-open .hamburger::after {
    opacity: 0;
}

.hamburger {
    display: block;
    position: relative;
}

.hamburger,
.hamburger::before,
.hamburger::after {
    background: var(--clr-accent);
    width: 2em;
    height: 3px;
    border-radius: 1em;
    transition: transform 250ms ease-in-out;
}

.hamburger::before,
.hamburger::after {
    content: '';
    position: absolute;
    left: 0;
    right: 0;
}

.hamburger::before {
    top: 6px;
}

.hamburger::after {
    bottom: 6px;
}


/*  Intro section  */

.intro {
    position: relative;
}

.intro__img {
    box-shadow: var(--bs);
    border-radius: 8px;
}

.section__subtitle--intro {
    display: inline-block;
}

@media (min-width: 600px) {
    .intro {
        display: grid;
        width: min-content;
        margin: 0 auto;
        grid-column-gap: 1em;
        grid-template-areas:
            ""img title""
            ""img subtitle"";
        grid-template-columns: min-content max-content;
    }

    .intro__img {
        grid-area: img;
        min-width: 300px;
        position: relative;
        z-index: 2;
    }

    .section__subtitle--intro {
        align-self: start;
        grid-column: -1 / 1;
        grid-row: 2;
        text-align: right;
        position: relative;
        left: -1.5em;
        width: calc(100% + 1.5em);
    }
}



/*  My services section  */

.my-services {
    background-color: var(--clr-dark);
    color: var(--clr-light);
    text-align: center;
    padding-top: 30px;
    padding-bottom: 30px;
}

.section__title--services {
    position: relative;
}

.section__title--services::after {
    content: '';
    display: block;
    width: 2em;
    height: 1px;
    margin: 0.5em auto 1em;
    background: var(--clr-light);
    opacity: 0.25;
}

.service {
    max-width: 500px;
    margin: 0 auto;
}

.service p:hover {
    color: var(--clr-accent);
}


.service p {
    font-family: var(--ff-secondary);
    font-size: 15px;
}

@media (min-width: 800px) {
    .services {
        display: flex;
        max-width: 1000px;
        margin-left: auto;
        margin-right: auto;
    }

    .service+.service {
        margin-left: 2em;
    }
}

.about-me {
    max-width: 1000px;
    margin: 0 auto;
    margin-top: -3%;
    margin-bottom: -3%;
}

.about-me__body {
    font-family: var(--ff-secondary);
    text-align: center;
}

.about-me__img {
    box-shadow: var(--bs);
    border-radius: 8px;
}

@media(min-width: 600px) {
    .about-me {
        display: grid;
        grid-template-columns: 1fr 200px;
        grid-template-areas:
            ""title img""
            ""subtitle img""
            ""text img"";
        grid-column-gap: 2em;
    }

    .section__title--about {
        grid-area: title;
    }

    .section__subtitle--about {
        grid-column: 1 / -1;
        grid-row: 2;
        position: relative;
        left: -1em;
        width: calc(100% + 2em);
        padding-left: 1em;
        padding-right: calc(200px + 4em);
    }

    .about-me__img {
        grid-area: img;
        position: relative;
        z-index: 2;
    }
}

/* My Work */

.my-work {
    background-color: var(--clr-dark);
    color: var(--clr-light);
    text-align: center;
    padding-top: 30px;
    padding-bottom: 40px;
}

.portfolio {
    display: grid;
    margin-left: 50px;
    column-gap: 20px;
    row-gap: 30px;
    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
}


@media(min-width: 200px) {
    .portfolio__item {
        text-align: center;
        padding-right: 50%;

    }
}


@media(min-width: 250px) {
    .portfolio__item {
        text-align: center;
    }
}

@media(min-width: 350px) {
    .portfolio__item {
        text-align: center;
        padding-right: 60px
    }
}


.item-header1,
.item-header2,
.item-header3,
.item-header4,
.item-header5,
.item-header6 {
    text-align: center;
    color: white;
    display: flex;
    justify-content: center;
}

.item-header1:hover,
.item-header2:hover,
.item-header3:hover,
.item-header4:hover,
.item-header5:hover,
.item-header6:hover {
    color: var(--clr-accent);
}

.text1,
.text2,
.text3 {
    opacity: 0;
    position: absolute;
    text-align: center;
    font-weight: var(--fw-bold);
    margin-top: 10%;
    border: solid 2px;
    border-radius: 50%;
    padding: 20px;
    border-color: aqua;
    background-color: var(--clr-dark);
    width: 130px;
    height: 130px;
    font-size: 20px;
    color: var(--clr-accent);

}

.text4,
.text5,
.text6 {
    opacity: 0;
    position: absolute;
    text-align: center;
    font-weight: var(--fw-bold);
    margin-top: 40%;
    border: solid 2px;
    border-radius: 50%;
    padding: 20px;
    border-color: aqua;
    background-color: var(--clr-dark);
    width: 130px;
    height: 130px;
    font-size: 20px;
    color: var(--clr-accent);
}


.text1:hover,
.text2:hover,
.text3:hover,
.text4:hover,
.text5:hover,
.text6:hover {
    transition:
        transform 750ms cubic-bezier(.5, 0, .5, 1),
        opacity 250ms linear;
    opacity: 20;
}

.link {
    text-decoration: none;
    color: var(--clr-accent);
    text-align: center;
}

.text1,
.text4 {
    margin-left: 7%;
}

.text2,
.text5 {
    margin-left: 38%;
}

.text3,
.text6 {
    margin-left: 69%;
}


.portfolio__item {
    overflow: hidden;
    text-decoration: none;
}


.portfolio__img {
    transition:
        transform 750ms cubic-bezier(.5, 0, .5, 1),
        opacity 250ms linear;
    border-radius: 8px;
    border-style: double;
    border-color: var(--clr-accent);
    border-width: 10px;
}

.portfolio__item:focus {
    position: relative;
    z-index: 2;
}


.portfolio__img:hover,
.portfolio__item:focus .portfolio__img {
    opacity: .5;
}

/* footer */

.footer {
    background: #111;
    color: var(--clr-accent);
    text-align: center;
    padding: 2.5em 0;
    font-size: var(--fs-h3);
}

.footer a {
    color: inherit;
    text-decoration: none;
}

.footer__link {
    font-weight: var(--fw-bold);
}

.footer__link:hover,
.social-list__link:hover {
    opacity: .7;
}

.footer__link:hover {
    text-decoration: underline;
}

.social-list {
    list-style: none;
    display: flex;
    justify-content: center;
    margin: 2em 0 0;
    padding: 0;
}

.social-list__item {
    margin: 0 .5em;
}

.social-list__link {
    padding: .5em;
}

/* Individual portfolio item styles */

.portfolio-item-individual {
    padding: 0 2em 2em;
    max-width: 1000px;
    margin: 0 auto;
}

.portfolio-item-individual p {
    max-width: 600px;
    margin-left: auto;
    margin-right: auto;
}</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;!DOCTYPE html&gt;
&lt;html lang=""en""&gt;

&lt;!DOCTYPE html&gt;
&lt;html lang=""en""&gt;

&lt;head&gt;
    &lt;meta charset=""UTF-8""&gt;
    &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1.0""&gt;
    &lt;title&gt;Megan Portfolio Website&lt;/title&gt;
    &lt;link rel=""stylesheet"" href=""https://cdnjs.cloudflare.com/ajax/libs/normalize/7.0.0/normalize.min.css""&gt;
    &lt;link rel=""stylesheet"" href=""https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.css""
        integrity=""sha256-46qynGAkLSFpVbEBog43gvNhfrOj+BmwXdxFgVK/Kvc="" crossorigin=""anonymous"" /&gt;

    &lt;!-- Google Fonts --&gt;
    &lt;link href=""https://fonts.googleapis.com/css?family=Source+Code+Pro:400,900|Source+Sans+Pro:300,900&amp;display=swap""
        rel=""stylesheet""&gt;

    &lt;link rel=""stylesheet"" href=""css/style.css""&gt;

&lt;/head&gt;

&lt;body&gt;

    &lt;!-- Canvas --&gt;

    &lt;section height=90vh&gt;
        &lt;canvas id=""canvas"" width=""100%"" height=""100vh"" z-index=""-1""&gt;
            &lt;header height=10vh z-index=""6""&gt;
            &lt;/header&gt;



            &lt;!-- (anything in here like social icons etc give them higher z-index then 5) --&gt;

            &lt;header&gt;
                &lt;div class=""logo""&gt;
                    &lt;img src=""img/DevMegan2.png"" alt=""""&gt;
                &lt;/div&gt;

                &lt;!-- NAVBAR --&gt;
                &lt;button class=""nav-toggle"" aria-label=""toggle navigation""&gt;
                    &lt;span class=""hamburger""&gt;&lt;/span&gt;
                &lt;/button&gt;
                &lt;nav class=""nav""&gt;
                    &lt;ul class=""nav__list""&gt;
                        &lt;li class=""nav__item""&gt;&lt;a href=""#home"" class=""nav__link""&gt;Home&lt;/a&gt;&lt;/li&gt;
                        &lt;li class=""nav__item""&gt;&lt;a href=""#services"" class=""nav__link""&gt;My Skills&lt;/a&gt;&lt;/li&gt;
                        &lt;li class=""nav__item""&gt;&lt;a href=""#about"" class=""nav__link""&gt;About me&lt;/a&gt;&lt;/li&gt;
                        &lt;li class=""nav__item""&gt;&lt;a href=""#work"" class=""nav__link""&gt;My Work&lt;/a&gt;&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/nav&gt;
            &lt;/header&gt;

            &lt;!-- Introduction --&gt;
            &lt;section class=""intro"" z-index=""1000"" id=""home""&gt;
                &lt;h1 class=""section__title section__title--intro""&gt;
                    Hi, I am &lt;strong&gt;Megan Lynn&lt;/strong&gt;
                &lt;/h1&gt;
                &lt;p class=""section__subtitle section__subtitle--intro""&gt;Full-Stack Developer&lt;/p&gt;
                &lt;img src=""img/me.jpg"" width=""770"" alt=""a picture of Megan smiling"" class=""intro__img""&gt;
            &lt;/section&gt;
        &lt;/canvas&gt;
    &lt;/section&gt;


    &lt;!-- My services --&gt;

    &lt;section class=""my-services"" id=""services""&gt;
        &lt;h2 class=""section__title section__title--services""&gt;My Skills&lt;/h2&gt;
        &lt;div class=""services""&gt;
            &lt;div class=""service""&gt;
                &lt;h3&gt;Programming Languages&lt;/h3&gt;
                &lt;p&gt;Skilled in programming with back-end languages such as Python, C#, and C++. Can manage data
                    held
                    in
                    relational
                    databases using SQL. Have experience in front-end programming with JavaScript, HTML, and
                    CSS.
                &lt;/p&gt;
            &lt;/div&gt; &lt;!-- / service --&gt;

            &lt;div class=""service""&gt;
                &lt;h3&gt;Tools &amp; Technologies&lt;/h3&gt;
                &lt;p&gt;Experienced in the operating systems, Windows, Linux, and macOS. Know how to use
                    shell scripting. Have experience with using frameworks in Visual Studio Code such as, .NET
                    and
                    ASP.NET
                    MVC. Have some experience using React. &lt;/p&gt;
            &lt;/div&gt; &lt;!-- / service --&gt;

            &lt;div class=""service""&gt;
                &lt;h3&gt;Full-Stack Development&lt;/h3&gt;
                &lt;p&gt;Have a variety of different skills and enjoy utilizing the back and front end to create Full
                    Stack applications and programs. Have made projects that connect to a back-end API and
                    database
                &lt;/p&gt;
            &lt;/div&gt; &lt;!-- / service --&gt;
        &lt;/div&gt; &lt;!-- / services --&gt;

        &lt;a href=""#work"" class=""btn""&gt;My Work&lt;/a&gt;
    &lt;/section&gt;


    &lt;!-- About me --&gt;
    &lt;section class=""about-me"" id=""about""&gt;
        &lt;h2 class=""section__title section__title--about""&gt;Who I am&lt;/h2&gt;
        &lt;p class=""section__subtitle section__subtitle--about""&gt;Developer based out of the East Coast, US&lt;/p&gt;

        &lt;div class=""about-me__body""&gt;
            &lt;p&gt;Hello! Thank you for visiting my page! My name is Megan and I am currently a student in college.
                I
                will
                be graduating with my Bachelor's degree in both Computer Science and CIT &amp; Cybersecurity as a
                double
                major
                in December, 2022. I maintain a 4.0 GPA. I am pursuing a career as a Software
                Developer/Engineer.
            &lt;/p&gt;
            &lt;p&gt;I genuinely enjoy programming and solving problems. I am passionate about Software Development. I
                spend
                all of my free time learning as much as I can about it. I am getting better by the day. Practice
                makes
                perfect! I am extremely motivated and I believe anybody can do or solve anything if you really
                put
                your
                mind
                to it!&lt;/p&gt;
        &lt;/div&gt;

        &lt;img src=""img/me2.jpg"" class=""about-me__img""&gt;
    &lt;/section&gt;

    &lt;!-- My Work --&gt;
    &lt;section class=""my-work"" id=""work""&gt;
        &lt;h2 class=""section__title section__title--work""&gt;My Projects&lt;/h2&gt;
        &lt;p class=""section__subtitle section__subtitle--work""&gt;A selection of my range of work&lt;/p&gt;
        &lt;div class=""portfolio""&gt;
            &lt;!-- Portfolio item 01 --&gt;
            &lt;a href=""https://loancalculate.azurewebsites.net/Home/App"" target=""blank"" class=""portfolio__item""&gt;
                &lt;header class=""item-header1""&gt;
                    &lt;h3&gt;Loan Calculator&lt;/h3&gt;
                &lt;/header&gt;
                &lt;img src=""img/LoanCalc.PNG"" height=""300"" width=""400"" alt="""" class=""portfolio__img""&gt;
            &lt;/a&gt;
            &lt;div class=""text1""&gt;&lt;a href=""https://loancalculate.azurewebsites.net/Home/App"" class=""link""
                    target=""_blank""&gt;Open
                    Project&lt;/a&gt;
            &lt;/div&gt;

            &lt;!-- Portfolio item 02 --&gt;
            &lt;a href=""https://github.com/meganlynn21/Palindrome_Checker"" target=""blank"" class=""portfolio__item""&gt;
                &lt;header class=""item-header2""&gt;
                    &lt;h3&gt;Palindrome Checker&lt;/h3&gt;
                &lt;/header&gt;
                &lt;img src=""img/palindrome.png"" height=""300"" width=""400"" alt="""" class=""portfolio__img""&gt;
            &lt;/a&gt;
            &lt;div class=""text2""&gt;&lt;a href=""https://github.com/meganlynn21/Palindrome_Checker"" class=""link""
                    target=""_blank""&gt;Open
                    Project&lt;/a&gt;
            &lt;/div&gt;

            &lt;!-- Portfolio item 03 --&gt;
            &lt;a href=""https://github.com/meganlynn21/Password-Validator"" target=""blank"" class=""portfolio__item""&gt;
                &lt;header class=""item-header3""&gt;
                    &lt;h3&gt;Password Validator&lt;/h3&gt;
                &lt;/header&gt;
                &lt;img src=""img/psswrd-validator.PNG"" height=""300"" width=""400"" alt="""" class=""portfolio__img""&gt;
            &lt;/a&gt;
            &lt;div class=""text3""&gt;&lt;a href=""https://github.com/meganlynn21/Password-Validator"" class=""link""
                    target=""_blank""&gt;Open
                    Project&lt;/a&gt;
            &lt;/div&gt;

            &lt;!-- Portfolio item 04 --&gt;
            &lt;a href=""https://github.com/meganlynn21/Real-Estate-Calculator"" target=""blank"" class=""portfolio__item""&gt;
                &lt;header class=""item-header4""&gt;
                    &lt;h3&gt;Real Estate Calculator&lt;/h3&gt;
                &lt;/header&gt;
                &lt;img src=""img/Real-Estate-Img.PNG"" height=""300"" width=""400"" alt="""" class=""portfolio__img""&gt;
            &lt;/a&gt;
            &lt;div class=""text4""&gt;&lt;a href=""https://github.com/meganlynn21/Real-Estate-Calculator"" class=""link""
                    target=""_blank""&gt;Open
                    Project&lt;/a&gt;
            &lt;/div&gt;

            &lt;!-- Portfolio item 05 --&gt;
            &lt;a href=""https://github.com/meganlynn21/ATM"" target=""blank"" class=""portfolio__item""&gt;
                &lt;header class=""item-header5""&gt;
                    &lt;h3&gt;ATM&lt;/h3&gt;
                &lt;/header&gt;
                &lt;img src=""img/atm.png"" height=""300"" width=""400"" alt="""" class=""portfolio__img""&gt;
            &lt;/a&gt;
            &lt;div class=""text5""&gt;&lt;a href=""https://github.com/meganlynn21/ATM"" class=""link"" target=""_blank""&gt;Open
                    Project&lt;/a&gt;
            &lt;/div&gt;

            &lt;!-- Portfolio item 06 --&gt;
            &lt;a href=""https://github.com/meganlynn21/shopping_list"" target=""blank"" class=""portfolio__item""&gt;
                &lt;header class=""item-header6""&gt;
                    &lt;h3&gt;Shopping List&lt;/h3&gt;
                &lt;/header&gt;
                &lt;img src=""img/shopping-list.png"" height=""300"" width=""400"" alt="""" class=""portfolio__img""&gt;
            &lt;/a&gt;
            &lt;div class=""text6""&gt;&lt;a href=""https://github.com/meganlynn21/shopping_list"" class=""link"" target=""_blank""&gt;Open
                    Project&lt;/a&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/section&gt;


    &lt;!-- Footer --&gt;
    &lt;footer class=""footer""&gt;
        &lt;!-- My email --&gt;
        &lt;a href=""mailto:rosettastone0203@gmail.com"" target=""blank"" class=""footer__link""&gt;@rosettastone0203&lt;/a&gt;
        &lt;ul class=""social-list""&gt;
            &lt;li class=""social-list__item""&gt;&lt;a class=""social-list__link""
                    href=""https://www.linkedin.com/in/megan-keyes-a81146224"" target=""blank""&gt;&lt;i
                        class=""fab fa-linkedin fa-2x""&gt;&lt;/i&gt;&lt;/a&gt;
            &lt;/li&gt;
            &lt;li class=""social-list__item""&gt;&lt;a class=""social-list__link"" href=""https://twitter.com/meganlynn22""
                    target=""blank""&gt; &lt;i class=""fab fa-twitter-square fa-2x""&gt;&lt;/i&gt;&lt;/a&gt;&lt;/li&gt;
            &lt;li class=""social-list__item""&gt;&lt;a class=""social-list__link"" href=""https://github.com/meganlynn21""
                    target=""blank""&gt;&lt;i class=""fab fa-github fa-2x""&gt;&lt;/i&gt;&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/footer&gt;


    &lt;script src=""js/index.js""&gt;&lt;/script&gt;

&lt;/body&gt;

&lt;/html&gt;</code></pre>
</div>
</div>
</p>
",39,1,-1,3,javascript;html;html5-canvas,2022-05-04 22:00:05,2022-05-04 22:00:05,2022-05-06 03:40:08,i want the canvas to show behind the website not over it  i have tried using z index and that does not work  i want to be able to see my actual website while moving the cursor over things  so i need the cursor to show on the website  it just blocks out my whole section  how can i get this to work correctly ,how do i get the canvas to show behind my html so my animated cursor will move over the screen 
280,19002169,72132264,How to calculate co-occurence in python for huge data,"<p>I wanted to calculate the co-occurrence such that it can be used as an edge for the construction of a graph. I have a column skill that consists of the list of skills for each id in the dataset. Now I wanted to calculate cooccurrence and use it as an edge.the data format is</p>
<pre><code>skill

Product Management,RPM,Progress 4GL,IP,CAMEL,Prince2 Foundation,Continuous Integration,GSM(HLR,MSC),Programming,SS7,INAP,ClearCase,SS7 protocol,Software Development,Shell Scripting,GPRS(SGSN,GGSN),MySQL,VOIP,Linux,Agile,SIP,Diameter,Test,Oracle,Software
User Experience,Interaction Design,3D rendering,Event,Team,Graphic Design,Engineering,User Experience Design,Sales,3D Modeling,Product Marketing,Employee Training,business plan,3D,Business Development,Creative Problem Solving,Product Design,renewable energy,Electronics,news paper,Project Management,Product Development,Social Enterprise
</code></pre>
<p>the above is the skills list of two ids in the dataset.</p>
<p>Now I want my output to be in the format of 3 columns which is the source, target, and weight count, and in the next step I can use them for the graph construction.</p>
<pre><code>      Source_elt  Target_elt WeightCount
    
</code></pre>
<p>Can anyone share your insights that would be helpful. My endpoint is that using this weight count I will go further for community detection.</p>
<p>I amusing the following code for the co-occurrence calculation.</p>
<pre><code>document =nested_list

#unique job titles
fnc_names = unique_jobtitle

# Get a list of all of the combinations you have
expanded = [tuple(itertools.combinations(d, 2)) for d in document]
expanded = itertools.chain(*expanded)

# Sort the combinations so that A,B and B,A are treated the same
expanded = [tuple(sorted(d)) for d in expanded]

# count the combinations
c = Counter(expanded)


#initialize NxN matrix with zeros
table =np.zeros((len(fnc_names),len(fnc_names)), dtype=int)

for i, v1 in enumerate(fnc_names):
    for j, v2 in enumerate(fnc_names[i:]):        
        j = j + i 
        table[i, j] = c[v1, v2]
        table[j, i] = c[v1, v2]


df_cooccMatrix = pd.DataFrame(table, index=fnc_names, columns=fnc_names)
df_cooccMatrix.head()
</code></pre>
<p>and later for the weight count</p>
<pre><code>#Assign count as f edge

weight_cout = df_cooccMatrix.stack()
weight_cout = pd.DataFrame(weight_cout.rename_axis(('Source_elt', 'Target_elt')).reset_index(name='WeightCount'))
#weight_cout.sort_values(by=['WeightCount'], inplace=True, ascending=False)
#weight_cout.head(10)
</code></pre>
<p>But when I am calculating weight count I am getting the memory issue</p>
<pre><code>MemoryError: Unable to allocate 6.25 GiB for an array with shape (1678704784,) and data type int32
</code></pre>
<p>so can anyone help me in solving the issue.</p>
<p>Thanks in advance</p>
",47,0,0,4,python;pandas;list;dataframe,2022-05-05 21:50:16,2022-05-05 21:50:16,2022-05-05 22:59:37,i wanted to calculate the co occurrence such that it can be used as an edge for the construction of a graph  i have a column skill that consists of the list of skills for each id in the dataset  now i wanted to calculate cooccurrence and use it as an edge the data format is the above is the skills list of two ids in the dataset  now i want my output to be in the format of  columns which is the source  target  and weight count  and in the next step i can use them for the graph construction  can anyone share your insights that would be helpful  my endpoint is that using this weight count i will go further for community detection  i amusing the following code for the co occurrence calculation  and later for the weight count but when i am calculating weight count i am getting the memory issue so can anyone help me in solving the issue  thanks in advance,how to calculate co occurence in python for huge data
281,1162409,72086061,Claims is empty and user is not Authenticated in HandleRequirement of AuthorizationHandlerContext with Duende identity server,"<p>I am using Asp.net core 6 with Duenda Identity server</p>
<p><strong>Program.cs</strong></p>
<pre><code>var builder = WebApplication.CreateBuilder(args);
ConfigurationManager serviceConfiguration = builder.Configuration;
builder.Services.ConfigureIdentityServer(serviceConfiguration);

services.AddAuthentication(AuthorizePolicy.TokenSchema)
                .AddJwtBearer(AuthorizePolicy.TokenSchema, options =&gt;
                {
                    options.Authority = &quot;https://localhost:5001&quot;;
                    options.TokenValidationParameters = new TokenValidationParameters
                    {
                        ValidateAudience = false
                    };
                });

var app = builder.Build();

app.UseIdentityServer();
app.UseAuthentication();
app.UseAuthorization();
</code></pre>
<p>Now in the handler, the claims are empty. The request has Bearer token in it.</p>
<pre><code>   public class IdentityServerUserClaimHandler : AuthorizationHandler&lt;IdentityServerUserClaimRequirement&gt;
    {
        protected override Task HandleRequirementAsync(AuthorizationHandlerContext context,
            IdentityServerUserClaimRequirement requirement)
        {
            if (context.User.HasClaim(c =&gt; c.Type == requirement.ClaimType &amp;&amp;
                                           c.Value == requirement.ClaimValue))
                context.Succeed(requirement);
            return Task.CompletedTask;
        }
    }
</code></pre>
<p><a href=""https://i.stack.imgur.com/cLmAJ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/cLmAJ.png"" alt=""enter image description here"" /></a></p>
<p>Access token encode from jwt.io</p>
<pre><code>{
  &quot;iss&quot;: &quot;https://localhost:5001&quot;,
  &quot;nbf&quot;: 1651574541,
  &quot;iat&quot;: 1651574541,
  &quot;exp&quot;: 1651574741,
  &quot;scope&quot;: [
    &quot;openid&quot;,
    &quot;profile&quot;,
    &quot;email&quot;
  ],
  &quot;amr&quot;: [
    &quot;pwd&quot;
  ],
  &quot;client_id&quot;: &quot;Falcon_Identity_Server&quot;,
  &quot;sub&quot;: &quot;9717a359-f83b-43b3-97b3-2f04f1148988&quot;,
  &quot;auth_time&quot;: 1651574539,
  &quot;idp&quot;: &quot;local&quot;,
  &quot;http://schemas.xmlsoap.org/ws/2005/05/identity/claims/nameidentifier&quot;: &quot;9717a359-f83b-43b3-97b3-2f04f1148988&quot;,
  &quot;http://schemas.xmlsoap.org/ws/2005/05/identity/claims/name&quot;: &quot;admin@local.com&quot;,
  &quot;http://schemas.xmlsoap.org/ws/2005/05/identity/claims/emailaddress&quot;: &quot;admin@local.com&quot;,
  &quot;AspNet.Identity.SecurityStamp&quot;: &quot;1999ca9c-398d-4ffe-907a-b1f1b5e8cbfe&quot;,
  &quot;identityserver&quot;: &quot;owner&quot;,
  &quot;fb_product&quot;: &quot;owner&quot;,
  &quot;fb_order&quot;: &quot;owner&quot;,
  &quot;fb_payment&quot;: &quot;owner&quot;,
  &quot;sid&quot;: &quot;716EA1A6F89D0A014DDCE43B5B66190F&quot;,
  &quot;jti&quot;: &quot;6417334FFDDB45054A77348952135CE4&quot;
}
</code></pre>
<p><strong>Update</strong></p>
<p>Remove the Token schema, now I have only cookies schema as below</p>
<pre><code>services.AddAuthentication(CookieAuthenticationDefaults.AuthenticationScheme)
                .AddCookie(CookieAuthenticationDefaults.AuthenticationScheme);

app.UseCookiePolicy();
</code></pre>
<p><strong>Logs from Identity server</strong></p>
<pre><code>2022-05-05 18:21:45.905 +10:00 [INF] Starting Duende IdentityServer version 6.1.0-preview.3+6a45df770da336604801bddca593a902f1ccb802 (.NET 6.0.3)
2022-05-05 18:21:45.924 +10:00 [WRN] You do not have a valid license key for the Duende software. This is allowed for development and testing scenarios. If you are running in production you are required to have a licensed version. Please start a conversation with us: https://duendesoftware.com/contact
2022-05-05 18:21:45.931 +10:00 [INF] Using the default authentication scheme Cookies for IdentityServer
2022-05-05 18:21:45.931 +10:00 [DBG] Using Cookies as default ASP.NET Core scheme for authentication
2022-05-05 18:21:45.931 +10:00 [DBG] Using Cookies as default ASP.NET Core scheme for sign-in
2022-05-05 18:21:45.931 +10:00 [DBG] Using Cookies as default ASP.NET Core scheme for sign-out
2022-05-05 18:21:45.931 +10:00 [DBG] Using Identity.Application as default ASP.NET Core scheme for challenge
2022-05-05 18:21:45.931 +10:00 [DBG] Using Cookies as default ASP.NET Core scheme for forbid
2022-05-05 18:21:46.065 +10:00 [WRN] You do not have a valid license key for the Duende software. This is allowed for development and testing scenarios. If you are running in production you are required to have a licensed version. Please start a conversation with us: https://duendesoftware.com/contact
2022-05-05 18:21:46.222 +10:00 [INF] Now listening on: https://localhost:5001
2022-05-05 18:21:46.222 +10:00 [INF] Now listening on: http://localhost:5000
2022-05-05 18:21:46.223 +10:00 [INF] Application started. Press Ctrl+C to shut down.
2022-05-05 18:21:46.224 +10:00 [INF] Hosting environment: Development
2022-05-05 18:21:46.224 +10:00 [INF] Content root path: /Users/san/project/Sample/Falcon-Identity/Falcon-Identity/
2022-05-05 18:21:53.225 +10:00 [DBG] Login Url: /Account/Login
2022-05-05 18:21:53.227 +10:00 [DBG] Login Return Url Parameter: ReturnUrl
2022-05-05 18:21:53.227 +10:00 [DBG] Logout Url: /Account/Logout
2022-05-05 18:21:53.227 +10:00 [DBG] ConsentUrl Url: /consent
2022-05-05 18:21:53.227 +10:00 [DBG] Consent Return Url Parameter: returnUrl
2022-05-05 18:21:53.227 +10:00 [DBG] Error Url: /home/error
2022-05-05 18:21:53.227 +10:00 [DBG] Error Id Parameter: errorId
2022-05-05 18:21:53.273 +10:00 [DBG] CORS request made for path: /.well-known/openid-configuration from origin: https://localhost:5002
2022-05-05 18:21:53.333 +10:00 [DBG] Origin https://localhost:5002 is allowed: true
2022-05-05 18:21:53.334 +10:00 [DBG] CorsPolicyService allowed origin: https://localhost:5002
2022-05-05 18:21:53.346 +10:00 [DBG] Request path /.well-known/openid-configuration matched to endpoint type Discovery
2022-05-05 18:21:53.347 +10:00 [DBG] Endpoint enabled: Discovery, successfully created handler: Duende.IdentityServer.Endpoints.DiscoveryEndpoint
2022-05-05 18:21:53.349 +10:00 [INF] Invoking IdentityServer endpoint: Duende.IdentityServer.Endpoints.DiscoveryEndpoint for /.well-known/openid-configuration
2022-05-05 18:21:53.350 +10:00 [DBG] Start discovery request
2022-05-05 18:21:53.443 +10:00 [INF] Active signing key found with kid C1C7E591CAF7B3C98C7ECACE9B6A6AC3 for alg RS256. Expires in &quot;83.22:18:15&quot;. Retires in &quot;97.22:18:15&quot;
2022-05-05 18:21:53.478 +10:00 [DBG] Retrieve AuthenticationTicket for key E1183024D7FD528A15F9313DD6985CBA9C6E3D0B90C33469371D8C392B9F604B
2022-05-05 18:21:53.479 +10:00 [DBG] No ticket found in store for E1183024D7FD528A15F9313DD6985CBA9C6E3D0B90C33469371D8C392B9F604B
2022-05-05 18:21:53.480 +10:00 [INF] Cookies was not authenticated. Failure message: Identity missing in session store
2022-05-05 18:21:53.481 +10:00 [INF] Cookies was not authenticated. Failure message: Identity missing in session store
2022-05-05 18:21:53.482 +10:00 [INF] Cookies was not authenticated. Failure message: Identity missing in session store
2022-05-05 18:21:53.487 +10:00 [DBG] Request path /connect/authorize matched to endpoint type Authorize
2022-05-05 18:21:53.496 +10:00 [DBG] Endpoint enabled: Authorize, successfully created handler: Duende.IdentityServer.Endpoints.AuthorizeEndpoint
2022-05-05 18:21:53.497 +10:00 [INF] Invoking IdentityServer endpoint: Duende.IdentityServer.Endpoints.AuthorizeEndpoint for /connect/authorize
2022-05-05 18:21:53.498 +10:00 [DBG] Start authorize request
2022-05-05 18:21:53.503 +10:00 [INF] Cookies was not authenticated. Failure message: Identity missing in session store
2022-05-05 18:21:53.505 +10:00 [DBG] No user present in authorize request
2022-05-05 18:21:53.505 +10:00 [DBG] Start authorize request protocol validation
2022-05-05 18:21:53.781 +10:00 [DBG] Falcon_Identity_Server found in database: true
2022-05-05 18:21:53.784 +10:00 [DBG] client configuration validation for client Falcon_Identity_Server succeeded.
2022-05-05 18:21:53.788 +10:00 [DBG] Checking for PKCE parameters
2022-05-05 18:21:53.796 +10:00 [DBG] Calling into custom validator: Duende.IdentityServer.Validation.DefaultCustomAuthorizeRequestValidator
2022-05-05 18:21:53.802 +10:00 [DBG] ValidatedAuthorizeRequest
{&quot;ClientId&quot;:&quot;Falcon_Identity_Server&quot;,&quot;ClientName&quot;:&quot;FalconIdentityServer&quot;,&quot;RedirectUri&quot;:&quot;https://localhost:5002/auth-callback&quot;,&quot;AllowedRedirectUris&quot;:[&quot;http://localhost:4200/assets/silent-renew.html&quot;,&quot;http://localhost:4200/auth-callback&quot;,&quot;https://falconidentity.azurewebsites.net/assets/silent-callback.html&quot;,&quot;https://falconidentity.azurewebsites.net/swagger/oauth2-redirect.html&quot;,&quot;https://localhost:5001/swagger/oauth2-redirect.html&quot;,&quot;https://localhost:5002/assets/silent-callback.html&quot;,&quot;https://localhost:5002/auth-callback&quot;,&quot;https://oauth.pstmn.io/v1/callback&quot;],&quot;SubjectId&quot;:&quot;anonymous&quot;,&quot;ResponseType&quot;:&quot;code&quot;,&quot;ResponseMode&quot;:&quot;query&quot;,&quot;GrantType&quot;:&quot;authorization_code&quot;,&quot;RequestedScopes&quot;:&quot;openid profile email&quot;,&quot;State&quot;:&quot;aa753cd62b164242a2f04591b6bb0679&quot;,&quot;UiLocales&quot;:null,&quot;Nonce&quot;:null,&quot;AuthenticationContextReferenceClasses&quot;:null,&quot;DisplayMode&quot;:null,&quot;PromptMode&quot;:&quot;&quot;,&quot;MaxAge&quot;:null,&quot;LoginHint&quot;:null,&quot;SessionId&quot;:&quot;&quot;,&quot;Raw&quot;:{&quot;client_id&quot;:&quot;Falcon_Identity_Server&quot;,&quot;redirect_uri&quot;:&quot;https://localhost:5002/auth-callback&quot;,&quot;response_type&quot;:&quot;code&quot;,&quot;scope&quot;:&quot;openid profile email&quot;,&quot;state&quot;:&quot;aa753cd62b164242a2f04591b6bb0679&quot;,&quot;code_challenge&quot;:&quot;jD4jnETjtjqswT7vJTTPMpDSegpDpX7L7L3plAueqdI&quot;,&quot;code_challenge_method&quot;:&quot;S256&quot;,&quot;response_mode&quot;:&quot;query&quot;},&quot;$type&quot;:&quot;AuthorizeRequestValidationLog&quot;}
2022-05-05 18:21:53.809 +10:00 [INF] Showing login: User is not authenticated
2022-05-05 18:21:53.814 +10:00 [DBG] Retrieve AuthenticationTicket for key E1183024D7FD528A15F9313DD6985CBA9C6E3D0B90C33469371D8C392B9F604B
2022-05-05 18:21:53.815 +10:00 [DBG] No ticket found in store for E1183024D7FD528A15F9313DD6985CBA9C6E3D0B90C33469371D8C392B9F604B
2022-05-05 18:21:53.815 +10:00 [INF] Cookies was not authenticated. Failure message: Identity missing in session store
2022-05-05 18:21:53.816 +10:00 [INF] Cookies was not authenticated. Failure message: Identity missing in session store
2022-05-05 18:21:53.817 +10:00 [INF] Cookies was not authenticated. Failure message: Identity missing in session store
2022-05-05 18:21:53.875 +10:00 [INF] Cookies was not authenticated. Failure message: Identity missing in session store
2022-05-05 18:21:53.876 +10:00 [DBG] Start authorize request protocol validation
2022-05-05 18:21:53.942 +10:00 [DBG] Falcon_Identity_Server found in database: true
2022-05-05 18:21:53.942 +10:00 [DBG] client configuration validation for client Falcon_Identity_Server succeeded.
2022-05-05 18:21:53.942 +10:00 [DBG] Checking for PKCE parameters
2022-05-05 18:21:53.942 +10:00 [DBG] Calling into custom validator: Duende.IdentityServer.Validation.DefaultCustomAuthorizeRequestValidator
2022-05-05 18:21:54.047 +10:00 [DBG] Falcon_Identity_Server found in database: true
2022-05-05 18:21:54.047 +10:00 [DBG] client configuration validation for client Falcon_Identity_Server succeeded.
2022-05-05 18:22:07.023 +10:00 [DBG] Retrieve AuthenticationTicket for key E1183024D7FD528A15F9313DD6985CBA9C6E3D0B90C33469371D8C392B9F604B
2022-05-05 18:22:07.023 +10:00 [DBG] No ticket found in store for E1183024D7FD528A15F9313DD6985CBA9C6E3D0B90C33469371D8C392B9F604B
2022-05-05 18:22:07.023 +10:00 [INF] Cookies was not authenticated. Failure message: Identity missing in session store
2022-05-05 18:22:07.024 +10:00 [DBG] CORS request made for path: /Account/Login from origin: null but was ignored because path was not for an allowed IdentityServer CORS endpoint
2022-05-05 18:22:07.024 +10:00 [INF] Cookies was not authenticated. Failure message: Identity missing in session store
2022-05-05 18:22:07.025 +10:00 [INF] Cookies was not authenticated. Failure message: Identity missing in session store
2022-05-05 18:22:07.055 +10:00 [INF] Cookies was not authenticated. Failure message: Identity missing in session store
2022-05-05 18:22:07.055 +10:00 [DBG] Start authorize request protocol validation
2022-05-05 18:22:07.199 +10:00 [DBG] Falcon_Identity_Server found in database: true
2022-05-05 18:22:07.199 +10:00 [DBG] client configuration validation for client Falcon_Identity_Server succeeded.
2022-05-05 18:22:07.199 +10:00 [DBG] Checking for PKCE parameters
2022-05-05 18:22:07.199 +10:00 [DBG] Calling into custom validator: Duende.IdentityServer.Validation.DefaultCustomAuthorizeRequestValidator
2022-05-05 18:22:07.466 +10:00 [INF] AuthenticationScheme: Identity.Application signed in.
2022-05-05 18:22:07.477 +10:00 [DBG] Augmenting SignInContext
2022-05-05 18:22:07.478 +10:00 [DBG] Adding idp claim with value: local
2022-05-05 18:22:07.478 +10:00 [DBG] Adding amr claim with value: pwd
2022-05-05 18:22:07.478 +10:00 [DBG] Adding auth_time claim with value: 1651738927
2022-05-05 18:22:07.478 +10:00 [INF] Cookies was not authenticated. Failure message: Identity missing in session store
2022-05-05 18:22:07.479 +10:00 [INF] Cookies was not authenticated. Failure message: Identity missing in session store
2022-05-05 18:22:07.485 +10:00 [DBG] Creating entry in store for AuthenticationTicket, key C1BEC550ECB78D2E76A8FEFA6489CA9648CE9919F78115615A58A4B762D48598, with expiration: &quot;2022-05-19T08:22:07.0000000Z&quot;
2022-05-05 18:22:07.492 +10:00 [INF] AuthenticationScheme: Cookies signed in.
2022-05-05 18:22:07.495 +10:00 [DBG] Retrieve AuthenticationTicket for key C1BEC550ECB78D2E76A8FEFA6489CA9648CE9919F78115615A58A4B762D48598
2022-05-05 18:22:07.496 +10:00 [DBG] Ticket loaded for key: C1BEC550ECB78D2E76A8FEFA6489CA9648CE9919F78115615A58A4B762D48598, with expiration: &quot;2022-05-19T08:22:07.0000000Z&quot;
2022-05-05 18:22:07.499 +10:00 [DBG] Request path /connect/authorize/callback matched to endpoint type Authorize
2022-05-05 18:22:07.499 +10:00 [DBG] Endpoint enabled: Authorize, successfully created handler: Duende.IdentityServer.Endpoints.AuthorizeCallbackEndpoint
2022-05-05 18:22:07.500 +10:00 [INF] Invoking IdentityServer endpoint: Duende.IdentityServer.Endpoints.AuthorizeCallbackEndpoint for /connect/authorize/callback
2022-05-05 18:22:07.501 +10:00 [DBG] Start authorize callback request
2022-05-05 18:22:07.501 +10:00 [DBG] User in authorize request: 9717a359-f83b-43b3-97b3-2f04f1148988
2022-05-05 18:22:07.501 +10:00 [DBG] Start authorize request protocol validation
2022-05-05 18:22:07.758 +10:00 [DBG] Falcon_Identity_Server found in database: true
2022-05-05 18:22:07.758 +10:00 [DBG] client configuration validation for client Falcon_Identity_Server succeeded.
2022-05-05 18:22:07.758 +10:00 [DBG] Checking for PKCE parameters
2022-05-05 18:22:07.758 +10:00 [DBG] Calling into custom validator: Duende.IdentityServer.Validation.DefaultCustomAuthorizeRequestValidator
2022-05-05 18:22:07.763 +10:00 [DBG] ValidatedAuthorizeRequest
{&quot;ClientId&quot;:&quot;Falcon_Identity_Server&quot;,&quot;ClientName&quot;:&quot;FalconIdentityServer&quot;,&quot;RedirectUri&quot;:&quot;https://localhost:5002/auth-callback&quot;,&quot;AllowedRedirectUris&quot;:[&quot;http://localhost:4200/assets/silent-renew.html&quot;,&quot;http://localhost:4200/auth-callback&quot;,&quot;https://falconidentity.azurewebsites.net/assets/silent-callback.html&quot;,&quot;https://falconidentity.azurewebsites.net/swagger/oauth2-redirect.html&quot;,&quot;https://localhost:5001/swagger/oauth2-redirect.html&quot;,&quot;https://localhost:5002/assets/silent-callback.html&quot;,&quot;https://localhost:5002/auth-callback&quot;,&quot;https://oauth.pstmn.io/v1/callback&quot;],&quot;SubjectId&quot;:&quot;9717a359-f83b-43b3-97b3-2f04f1148988&quot;,&quot;ResponseType&quot;:&quot;code&quot;,&quot;ResponseMode&quot;:&quot;query&quot;,&quot;GrantType&quot;:&quot;authorization_code&quot;,&quot;RequestedScopes&quot;:&quot;openid profile email&quot;,&quot;State&quot;:&quot;aa753cd62b164242a2f04591b6bb0679&quot;,&quot;UiLocales&quot;:null,&quot;Nonce&quot;:null,&quot;AuthenticationContextReferenceClasses&quot;:null,&quot;DisplayMode&quot;:null,&quot;PromptMode&quot;:&quot;&quot;,&quot;MaxAge&quot;:null,&quot;LoginHint&quot;:null,&quot;SessionId&quot;:&quot;C179DA1B9A4A6B426EB92E47F7AB9F6A&quot;,&quot;Raw&quot;:{&quot;client_id&quot;:&quot;Falcon_Identity_Server&quot;,&quot;redirect_uri&quot;:&quot;https://localhost:5002/auth-callback&quot;,&quot;response_type&quot;:&quot;code&quot;,&quot;scope&quot;:&quot;openid profile email&quot;,&quot;state&quot;:&quot;aa753cd62b164242a2f04591b6bb0679&quot;,&quot;code_challenge&quot;:&quot;jD4jnETjtjqswT7vJTTPMpDSegpDpX7L7L3plAueqdI&quot;,&quot;code_challenge_method&quot;:&quot;S256&quot;,&quot;response_mode&quot;:&quot;query&quot;},&quot;$type&quot;:&quot;AuthorizeRequestValidationLog&quot;}
2022-05-05 18:22:07.851 +10:00 [DBG] Client is configured to not require consent, no consent is required
2022-05-05 18:22:07.853 +10:00 [DBG] Creating Authorization Code Flow response.
2022-05-05 18:22:07.903 +10:00 [DBG] 3A181978EF26F0DB98A1B2D2509C5ACF958EB7B4450AA81443F5F2C8B6572EDC not found in database
2022-05-05 18:22:08.039 +10:00 [DBG] Authorize endpoint response
{&quot;SubjectId&quot;:&quot;9717a359-f83b-43b3-97b3-2f04f1148988&quot;,&quot;ClientId&quot;:&quot;Falcon_Identity_Server&quot;,&quot;RedirectUri&quot;:&quot;https://localhost:5002/auth-callback&quot;,&quot;State&quot;:&quot;aa753cd62b164242a2f04591b6bb0679&quot;,&quot;Scope&quot;:&quot;openid profile email&quot;,&quot;Error&quot;:null,&quot;ErrorDescription&quot;:null,&quot;$type&quot;:&quot;AuthorizeResponseLog&quot;}
2022-05-05 18:22:08.042 +10:00 [DBG] Augmenting SignInContext
2022-05-05 18:22:08.043 +10:00 [DBG] Renewing AuthenticationTicket for key C1BEC550ECB78D2E76A8FEFA6489CA9648CE9919F78115615A58A4B762D48598, with expiration: &quot;2022-05-19T08:22:07.0000000Z&quot;
2022-05-05 18:22:08.043 +10:00 [INF] AuthenticationScheme: Cookies signed in.
2022-05-05 18:22:08.231 +10:00 [DBG] CORS request made for path: /.well-known/openid-configuration from origin: https://localhost:5002
2022-05-05 18:22:08.244 +10:00 [DBG] Origin https://localhost:5002 is allowed: true
2022-05-05 18:22:08.244 +10:00 [DBG] CorsPolicyService allowed origin: https://localhost:5002
2022-05-05 18:22:08.244 +10:00 [DBG] Request path /.well-known/openid-configuration matched to endpoint type Discovery
2022-05-05 18:22:08.244 +10:00 [DBG] Endpoint enabled: Discovery, successfully created handler: Duende.IdentityServer.Endpoints.DiscoveryEndpoint
2022-05-05 18:22:08.245 +10:00 [INF] Invoking IdentityServer endpoint: Duende.IdentityServer.Endpoints.DiscoveryEndpoint for /.well-known/openid-configuration
2022-05-05 18:22:08.246 +10:00 [DBG] Start discovery request
2022-05-05 18:22:08.247 +10:00 [INF] Active signing key found with kid C1C7E591CAF7B3C98C7ECACE9B6A6AC3 for alg RS256. Expires in &quot;83.22:18:00&quot;. Retires in &quot;97.22:18:00&quot;
2022-05-05 18:22:08.253 +10:00 [DBG] CORS request made for path: /connect/token from origin: https://localhost:5002
2022-05-05 18:22:08.304 +10:00 [DBG] Origin https://localhost:5002 is allowed: true
2022-05-05 18:22:08.304 +10:00 [DBG] CorsPolicyService allowed origin: https://localhost:5002
2022-05-05 18:22:08.305 +10:00 [DBG] Request path /connect/token matched to endpoint type Token
2022-05-05 18:22:08.307 +10:00 [DBG] Endpoint enabled: Token, successfully created handler: Duende.IdentityServer.Endpoints.TokenEndpoint
2022-05-05 18:22:08.308 +10:00 [INF] Invoking IdentityServer endpoint: Duende.IdentityServer.Endpoints.TokenEndpoint for /connect/token
2022-05-05 18:22:08.310 +10:00 [DBG] Start token request.
2022-05-05 18:22:08.311 +10:00 [DBG] Start client validation
2022-05-05 18:22:08.312 +10:00 [DBG] Start parsing Basic Authentication secret
2022-05-05 18:22:08.312 +10:00 [DBG] Start parsing for secret in post body
2022-05-05 18:22:08.312 +10:00 [DBG] client id without secret found
2022-05-05 18:22:08.312 +10:00 [DBG] Parser found secret: PostBodySecretParser
2022-05-05 18:22:08.313 +10:00 [DBG] Secret id found: Falcon_Identity_Server
2022-05-05 18:22:08.564 +10:00 [DBG] Falcon_Identity_Server found in database: true
2022-05-05 18:22:08.565 +10:00 [DBG] client configuration validation for client Falcon_Identity_Server succeeded.
2022-05-05 18:22:08.567 +10:00 [DBG] Public Client - skipping secret validation success
2022-05-05 18:22:08.567 +10:00 [DBG] Client validation success
2022-05-05 18:22:08.578 +10:00 [DBG] Start token request validation
2022-05-05 18:22:08.586 +10:00 [DBG] Start validation of authorization code token request
2022-05-05 18:22:08.613 +10:00 [DBG] 3A181978EF26F0DB98A1B2D2509C5ACF958EB7B4450AA81443F5F2C8B6572EDC found in database: true
2022-05-05 18:22:08.629 +10:00 [DBG] removing 3A181978EF26F0DB98A1B2D2509C5ACF958EB7B4450AA81443F5F2C8B6572EDC persisted grant from database
2022-05-05 18:22:08.649 +10:00 [DBG] Client required a proof key for code exchange. Starting PKCE validation
2022-05-05 18:22:08.654 +10:00 [DBG] Validation of authorization code token request success
2022-05-05 18:22:08.660 +10:00 [INF] Token request validation success, {&quot;ClientId&quot;:&quot;Falcon_Identity_Server&quot;,&quot;ClientName&quot;:&quot;FalconIdentityServer&quot;,&quot;GrantType&quot;:&quot;authorization_code&quot;,&quot;Scopes&quot;:null,&quot;AuthorizationCode&quot;:&quot;****76-1&quot;,&quot;RefreshToken&quot;:&quot;********&quot;,&quot;UserName&quot;:null,&quot;AuthenticationContextReferenceClasses&quot;:null,&quot;Tenant&quot;:null,&quot;IdP&quot;:null,&quot;Raw&quot;:{&quot;client_id&quot;:&quot;Falcon_Identity_Server&quot;,&quot;code&quot;:&quot;01F5B7A646A2C431F5F1329346846EF5BDE4A4A9103C3A2E56CFB2B6BCD61676-1&quot;,&quot;redirect_uri&quot;:&quot;https://localhost:5002/auth-callback&quot;,&quot;code_verifier&quot;:&quot;81c77066c9c1467b9fc4a3552869c834151bd60fa0064f708eafbb1f77a7aea5c46e71b9e5c84e93a3056d8d80ee146b&quot;,&quot;grant_type&quot;:&quot;authorization_code&quot;},&quot;$type&quot;:&quot;TokenRequestValidationLog&quot;}
2022-05-05 18:22:08.792 +10:00 [DBG] Falcon_Identity_Server found in database: true
2022-05-05 18:22:08.792 +10:00 [DBG] client configuration validation for client Falcon_Identity_Server succeeded.
2022-05-05 18:22:08.795 +10:00 [DBG] Getting claims for access token for client: Falcon_Identity_Server
2022-05-05 18:22:08.796 +10:00 [DBG] Getting claims for access token for subject: 9717a359-f83b-43b3-97b3-2f04f1148988
2022-05-05 18:22:08.811 +10:00 [DBG] Claim types from profile service that were filtered: [&quot;sub&quot;]
2022-05-05 18:22:09.011 +10:00 [DBG] Falcon_Identity_Server found in database: true
2022-05-05 18:22:09.011 +10:00 [DBG] client configuration validation for client Falcon_Identity_Server succeeded.
2022-05-05 18:22:09.014 +10:00 [DBG] Getting claims for identity token for subject: 9717a359-f83b-43b3-97b3-2f04f1148988 and client: Falcon_Identity_Server
2022-05-05 18:22:09.014 +10:00 [DBG] In addition to an id_token, an access_token was requested. No claims other than sub are included in the id_token. To obtain more user claims, either use the user info endpoint or set AlwaysIncludeUserClaimsInIdToken on the client configuration.
2022-05-05 18:22:09.017 +10:00 [DBG] Token request success.
2022-05-05 18:22:09.024 +10:00 [DBG] CORS request made for path: /connect/userinfo from origin: https://localhost:5002
2022-05-05 18:22:09.034 +10:00 [DBG] Origin https://localhost:5002 is allowed: true
2022-05-05 18:22:09.034 +10:00 [DBG] CorsPolicyService allowed origin: https://localhost:5002
2022-05-05 18:22:09.034 +10:00 [DBG] Request path /connect/userinfo matched to endpoint type Userinfo
2022-05-05 18:22:09.035 +10:00 [DBG] Endpoint enabled: Userinfo, successfully created handler: Duende.IdentityServer.Endpoints.UserInfoEndpoint
2022-05-05 18:22:09.036 +10:00 [INF] Invoking IdentityServer endpoint: Duende.IdentityServer.Endpoints.UserInfoEndpoint for /connect/userinfo
2022-05-05 18:22:09.037 +10:00 [DBG] Start userinfo request
2022-05-05 18:22:09.038 +10:00 [DBG] Bearer token found in header
2022-05-05 18:22:09.188 +10:00 [DBG] Falcon_Identity_Server found in database: true
2022-05-05 18:22:09.188 +10:00 [DBG] client configuration validation for client Falcon_Identity_Server succeeded.
2022-05-05 18:22:09.311 +10:00 [DBG] Falcon_Identity_Server found in database: true
2022-05-05 18:22:09.311 +10:00 [DBG] client configuration validation for client Falcon_Identity_Server succeeded.
2022-05-05 18:22:09.321 +10:00 [DBG] Calling into custom token validator: Duende.IdentityServer.Validation.DefaultCustomTokenValidator
2022-05-05 18:22:09.322 +10:00 [DBG] Token validation success
{&quot;ClientId&quot;:null,&quot;ClientName&quot;:null,&quot;ValidateLifetime&quot;:true,&quot;AccessTokenType&quot;:&quot;Jwt&quot;,&quot;ExpectedScope&quot;:&quot;openid&quot;,&quot;TokenHandle&quot;:null,&quot;JwtId&quot;:&quot;614C94729DCAAA8A4D821A6CB515CADF&quot;,&quot;Claims&quot;:{&quot;iss&quot;:&quot;https://localhost:5001&quot;,&quot;nbf&quot;:1651738928,&quot;iat&quot;:1651738928,&quot;exp&quot;:1651739128,&quot;scope&quot;:[&quot;openid&quot;,&quot;profile&quot;,&quot;email&quot;],&quot;amr&quot;:&quot;pwd&quot;,&quot;client_id&quot;:&quot;Falcon_Identity_Server&quot;,&quot;sub&quot;:&quot;9717a359-f83b-43b3-97b3-2f04f1148988&quot;,&quot;auth_time&quot;:1651738927,&quot;idp&quot;:&quot;local&quot;,&quot;http://schemas.xmlsoap.org/ws/2005/05/identity/claims/nameidentifier&quot;:&quot;9717a359-f83b-43b3-97b3-2f04f1148988&quot;,&quot;http://schemas.xmlsoap.org/ws/2005/05/identity/claims/name&quot;:&quot;admin@local.com&quot;,&quot;http://schemas.xmlsoap.org/ws/2005/05/identity/claims/emailaddress&quot;:&quot;admin@local.com&quot;,&quot;AspNet.Identity.SecurityStamp&quot;:&quot;1999ca9c-398d-4ffe-907a-b1f1b5e8cbfe&quot;,&quot;identityserver&quot;:&quot;owner&quot;,&quot;fb_product&quot;:&quot;owner&quot;,&quot;fb_order&quot;:&quot;owner&quot;,&quot;fb_payment&quot;:&quot;owner&quot;,&quot;sid&quot;:&quot;C179DA1B9A4A6B426EB92E47F7AB9F6A&quot;,&quot;jti&quot;:&quot;614C94729DCAAA8A4D821A6CB515CADF&quot;},&quot;$type&quot;:&quot;TokenValidationLog&quot;}
2022-05-05 18:22:09.324 +10:00 [DBG] Creating userinfo response
2022-05-05 18:22:09.325 +10:00 [DBG] Scopes in access token: openid profile email
2022-05-05 18:22:09.326 +10:00 [DBG] Requested claim types: 
2022-05-05 18:22:09.381 +10:00 [INF] Profile service returned the following claim types: http://schemas.xmlsoap.org/ws/2005/05/identity/claims/nameidentifier http://schemas.xmlsoap.org/ws/2005/05/identity/claims/name http://schemas.xmlsoap.org/ws/2005/05/identity/claims/emailaddress AspNet.Identity.SecurityStamp sub identityserver fb_product fb_order fb_payment
2022-05-05 18:22:09.381 +10:00 [DBG] End userinfo request
2022-05-05 18:22:09.397 +10:00 [DBG] Retrieve AuthenticationTicket for key C1BEC550ECB78D2E76A8FEFA6489CA9648CE9919F78115615A58A4B762D48598
2022-05-05 18:22:09.398 +10:00 [DBG] Ticket loaded for key: C1BEC550ECB78D2E76A8FEFA6489CA9648CE9919F78115615A58A4B762D48598, with expiration: &quot;2022-05-19T08:22:07.0000000Z&quot;
2022-05-05 18:22:09.398 +10:00 [DBG] Request path /connect/checksession matched to endpoint type Checksession
2022-05-05 18:22:09.399 +10:00 [DBG] Endpoint enabled: Checksession, successfully created handler: Duende.IdentityServer.Endpoints.CheckSessionEndpoint
2022-05-05 18:22:09.399 +10:00 [INF] Invoking IdentityServer endpoint: Duende.IdentityServer.Endpoints.CheckSessionEndpoint for /connect/checksession
2022-05-05 18:22:09.400 +10:00 [DBG] Rendering check session result
2022-05-05 18:22:12.315 +10:00 [DBG] CORS request made for path: /UserManagement/GetAllUsers from origin: https://localhost:5002 but was ignored because path was not for an allowed IdentityServer CORS endpoint
2022-05-05 18:22:12.348 +10:00 [INF] AuthenticationScheme: Identity.Application was challenged.
2022-05-05 18:22:12.352 +10:00 [DBG] CORS request made for path: /Account/Login from origin: https://localhost:5002 but was ignored because path was not for an allowed IdentityServer CORS endpoint
</code></pre>
<p><strong>From above log</strong></p>
<pre><code>2022-05-05 18:21:53.482 +10:00 [INF] Cookies was not authenticated. Failure message: Identity missing in session store
2022-05-05 18:21:53.505 +10:00 [DBG] No user present in authorize request
2022-05-05 18:21:53.479 +10:00 [DBG] No ticket found in store for E1183024D7FD528A15F9313DD6985CBA9C6E3D0B90C33469371D8C392B9F604B
</code></pre>
",461,1,0,5,c#;asp.net;asp.net-core;identityserver4;duende-identity-server,2022-05-02 14:31:59,2022-05-02 14:31:59,2022-05-05 11:37:00,i am using asp net core  with duenda identity server program cs now in the handler  the claims are empty  the request has bearer token in it   access token encode from jwt io update remove the token schema  now i have only cookies schema as below logs from identity server from above log,claims is empty and user is not authenticated in handlerequirement of authorizationhandlercontext with duende identity server
282,1148606,72107116,"Wicked PDF fails on production only, PDF could not be generated!: could not find rake 13.0.6 in any of the sources (Bundler::GemNotFound)","<p>I've been searching all over the internet but couldn't find a working solution.</p>
<p>I have a rails app running on puma and nginx which generates a PDF with no problems on development (Mac OS Monterrey) but in production (Ubuntu 20.04) I'm getting this error:</p>
<pre><code>[4ed5fc46-6ee0-46aa-863d-3cfd79689dd8] RuntimeError (Failed to execute:
[&quot;/usr/share/rvm/gems/ruby-2.6.5/bin/wkhtmltopdf&quot;, &quot;--enable-local-file-access&quot;, &quot;file:////tmp/wicked_pdf20220504-24703-1gzck1m.html&quot;, &quot;/tmp/wicked_pdf_generated_file20220504-24703-1b64d4x.pdf&quot;]
Error: PDF could not be generated!
 Command Error: /usr/share/rvm/rubies/ruby-2.6.5/lib/ruby/site_ruby/2.6.0/bundler/spec_set.rb:91:in `block in materialize': Could not find rake-13.0.6 in any of the sources (Bundler::GemNotFound)
    from /usr/share/rvm/rubies/ruby-2.6.5/lib/ruby/site_ruby/2.6.0/bundler/spec_set.rb:85:in `map!'
    from /usr/share/rvm/rubies/ruby-2.6.5/lib/ruby/site_ruby/2.6.0/bundler/spec_set.rb:85:in `materialize'
    from /usr/share/rvm/rubies/ruby-2.6.5/lib/ruby/site_ruby/2.6.0/bundler/definition.rb:170:in `specs'
    from /usr/share/rvm/rubies/ruby-2.6.5/lib/ruby/site_ruby/2.6.0/bundler/definition.rb:237:in `specs_for'
    from /usr/share/rvm/rubies/ruby-2.6.5/lib/ruby/site_ruby/2.6.0/bundler/definition.rb:226:in `requested_specs'
    from /usr/share/rvm/rubies/ruby-2.6.5/lib/ruby/site_ruby/2.6.0/bundler/runtime.rb:108:in `block in definition_method'
    from /usr/share/rvm/rubies/ruby-2.6.5/lib/ruby/site_ruby/2.6.0/bundler/runtime.rb:20:in `setup'
    from /usr/share/rvm/rubies/ruby-2.6.5/lib/ruby/site_ruby/2.6.0/bundler.rb:107:in `setup'
    from /usr/share/rvm/rubies/ruby-2.6.5/lib/ruby/site_ruby/2.6.0/bundler/setup.rb:20:in `&lt;top (required)&gt;'
    from /usr/share/rvm/rubies/ruby-2.6.5/lib/ruby/site_ruby/2.6.0/rubygems/core_ext/kernel_require.rb:54:in `require'
    from /usr/share/rvm/rubies/ruby-2.6.5/lib/ruby/site_ruby/2.6.0/rubygems/core_ext/kernel_require.rb:54:in `require'
):
[4ed5fc46-6ee0-46aa-863d-3cfd79689dd8]   
[4ed5fc46-6ee0-46aa-863d-3cfd79689dd8] app/controllers/sales_controller.rb:121:in `block in update'
[4ed5fc46-6ee0-46aa-863d-3cfd79689dd8] app/controllers/sales_controller.rb:115:in `update'

</code></pre>
<p>Software versions:
rake-13.0.6 is installed, Wicked_pdf version is 2.6.0, wkhtmltopdf-binary version is 0.12.6.5., Rails version is 6.1.4, Ruby version is 2.6.5.</p>
<p>I'm using rvm, and already reinstalled ruby with same results.</p>
<p>If I run this code in the rails console on the server in production mode it works fine:</p>
<pre><code>pdf = WickedPdf.new.pdf_from_string('&lt;h1&gt;Hello There!&lt;/h1&gt;')
</code></pre>
<p>But, if I run it on the controller like this the problem remains:</p>
<pre><code>def update
    @sale = Sale.find(params[:id])

    respond_to do |format|
      if @sale.update(sale_params)

        pdf = WickedPdf.new.pdf_from_string('&lt;h1&gt;Hello There!&lt;/h1&gt;')
        save_path = Rails.root.join('tmp', &quot;boleta_#{@sale.common_expense.folio}_#{@sale.common_expense.parcel.name.downcase}.pdf&quot;)
        
        File.open(save_path, 'wb') do |file|
          file &lt;&lt; pdf
          @sale.common_expense.file.attach(io: File.open(save_path), filename: &quot;boleta_#{@sale.common_expense.folio}_#{@sale.common_expense.parcel.name.downcase}.pdf&quot;)
          @sale.common_expense.save!
          file.close
        end

        format.html { redirect_to(edit_sale_path(@sale), :notice =&gt; 'Venta actualizada.') }
        format.xml  { head :ok }
      else
        format.html { render :action =&gt; &quot;edit&quot; }
        format.xml  { render :xml =&gt; @sale.errors, :status =&gt; :unprocessable_entity }
      end
    end
end
</code></pre>
<p>My wicked_pdf initializer looks like this:</p>
<pre><code>if Rails.env == 'production'
  WickedPdf.config = {
    exe_path: '/usr/share/rvm/gems/ruby-2.6.5/bin/wkhtmltopdf',
    enable_local_file_access: true
  }
end
</code></pre>
<p>Does anyone know what could be giving the error?</p>
<p>Thanks in advance!</p>
<p><strong>INFO UPDATE</strong></p>
<p>My app was updated from Rails 4.2.</p>
<p>I just installed on the same production server a new rails app with the basics to create a PDF file and it has no issues. I believe it has something to do with the rails update.</p>
",115,0,0,5,ruby-on-rails;ruby;bundle;rake;wicked-pdf,2022-05-04 04:42:01,2022-05-04 04:42:01,2022-05-05 00:36:05,i ve been searching all over the internet but couldn t find a working solution  i have a rails app running on puma and nginx which generates a pdf with no problems on development  mac os monterrey  but in production  ubuntu    i m getting this error  i m using rvm  and already reinstalled ruby with same results  if i run this code in the rails console on the server in production mode it works fine  but  if i run it on the controller like this the problem remains  my wicked_pdf initializer looks like this  does anyone know what could be giving the error  thanks in advance  info update my app was updated from rails    i just installed on the same production server a new rails app with the basics to create a pdf file and it has no issues  i believe it has something to do with the rails update ,wicked pdf fails on production only  pdf could not be generated   could not find rake    in any of the sources  bundler  gemnotfound 
283,8920999,72107691,When should you write an architecture decision record (ADR)?,"<p>Documenting your software architecture through Architecture Decision Records (ADR) seems to be regarded as a best practice in software development.</p>
<p>Influential content on the topic includes the folling:</p>
<ul>
<li><a href=""https://cognitect.com/blog/2011/11/15/documenting-architecture-decisions"" rel=""nofollow noreferrer"">https://cognitect.com/blog/2011/11/15/documenting-architecture-decisions</a></li>
<li><a href=""https://www.thoughtworks.com/radar/techniques/lightweight-architecture-decision-records"" rel=""nofollow noreferrer"">https://www.thoughtworks.com/radar/techniques/lightweight-architecture-decision-records</a></li>
<li><a href=""https://adr.github.io/"" rel=""nofollow noreferrer"">https://adr.github.io/</a></li>
</ul>
<p>The <em>why</em> and <em>how</em> are pretty clear to me. My question is &quot;<em>When</em> should you write an ADR?&quot; Or in slightly different words, &quot;<em>What</em> should you capture in an ADR?&quot;</p>
",99,1,1,2,architecture;documentation,2022-05-04 06:41:51,2022-05-04 06:41:51,2022-05-04 10:00:29,documenting your software architecture through architecture decision records  adr  seems to be regarded as a best practice in software development  influential content on the topic includes the folling  the why and how are pretty clear to me  my question is  when should you write an adr   or in slightly different words   what should you capture in an adr  ,when should you write an architecture decision record  adr  
284,496700,16395704,What is symbolic computation?,"<p>According to <a href=""https://en.wikipedia.org/wiki/Symbolic_computation"" rel=""noreferrer"">wiki</a>:</p>

<blockquote>
  <p>In mathematics and computer science, computer algebra, also called
  symbolic computation or algebraic computation is a scientific area
  that refers to the study and development of algorithms and software
  for manipulating mathematical expressions and other mathematical
  objects</p>
</blockquote>

<p>Does symbolic computation focus on symbol manipulation and computation? Lisp program is written in the form of an AST with atoms as leaves. Lisp is said to be language for symbolic computing. Does it mean that in symbolic computation, it is:</p>

<ul>
<li>all about symbols (symbols are atoms or non-atom expressions in Lisp)</li>
<li>every symbol is assigned a semantic</li>
<li>symbolic computation is a paradigm that orients programmers to focus on working with symbols and semantics (a semantic can be an atom or expression that does something) and the relationships between symbols, as opposed to think that data structure and code are two separated entities.</li>
<li>program design is language design, based on symbol composition/manipulation and semantic assignment.</li>
</ul>

<p>According to <a href=""https://stackoverflow.com/questions/5588962/what-is-the-opposite-to-symbolic-computation"">this question</a>, the opposite of symbolic computation is numeric computation. What's the primary difference between these two? When I work with Octave (I'm studying it), I have to work with numbers a lot and have to guess the meaning of those magic numbers many times. Is this a numerical computation focus?</p>
",21131,5,23,1,symbolic-math,2013-05-06 12:25:29,2013-05-06 12:25:29,2022-05-04 04:01:42,according to   does symbolic computation focus on symbol manipulation and computation  lisp program is written in the form of an ast with atoms as leaves  lisp is said to be language for symbolic computing  does it mean that in symbolic computation  it is  according to   the opposite of symbolic computation is numeric computation  what s the primary difference between these two  when i work with octave  i m studying it   i have to work with numbers a lot and have to guess the meaning of those magic numbers many times  is this a numerical computation focus ,what is symbolic computation 
285,15477915,72105002,Element goes above other element - CSS,"<p>I have a hamburger menu inside my website and if I go inside a specific which I have a card with some other elements inside. But if I open the menu while I'm inside the page with this card element the card goes above the menu for some reason. I tried almost everything but I can't get it right. I can't see where is my mistake with the CSS code...</p>
<p><strong>My react component (html):</strong></p>
<pre><code>import TopNavBarMobileComponent from &quot;../TopNavMobileComponent&quot;;
import github_icon from '../../assets/github_icon.png'
import instagram_icon from '../../assets/instagram_icon.png'
import my_picture from '../../assets/my_picture.jpg'
import '../../css-mobile/AboutMeStyle.css'

function AboutMeMobile() {
    return (
        &lt;div&gt;
            
            &lt;TopNavBarMobileComponent /&gt;

            &lt;div className=&quot;info-card-container&quot;&gt;

            &lt;aside class=&quot;profile-card&quot;&gt;

                &lt;div class=&quot;mask-shadow&quot;&gt;&lt;/div&gt;
                &lt;header&gt;
                    &lt;a href=&quot;https://github.com/georgesepetadelis/&quot;&gt;
                    &lt;img src={my_picture} /&gt;
                    &lt;/a&gt;
                    &lt;h1 className=&quot;name&quot;&gt;GEORGE SEPETADELIS&lt;/h1&gt;
                    &lt;h2&gt;Software engineer&lt;/h2&gt;
                &lt;/header&gt;

                &lt;div class=&quot;profile-bio&quot;&gt;
                    &lt;p&gt;16 y/o and I'm from Greece. I have experience with many programming languages and Frameworks for all mobile platforms like Flutter, React-Native and also native Android and iOS development with Java and Swift. Also I am currently working on Unreal engine and Unity for some big projects. &lt;/p&gt;
                &lt;/div&gt;

                &lt;ul class=&quot;profile-social-links&quot;&gt;
                    &lt;li&gt;
                    &lt;a href=&quot;https://github.com/georgesepetadelis/&quot;&gt;
                        &lt;img src={github_icon} /&gt;
                    &lt;/a&gt;
                    &lt;/li&gt;
                    
                    &lt;li&gt;
                    &lt;a href=&quot;https://www.instagram.com/sepetadelhsss/&quot;&gt;
                        &lt;img src={instagram_icon} /&gt;
                    &lt;/a&gt;
                    &lt;/li&gt;

                    &lt;li&gt;
                    &lt;a href=&quot;https://twitter.com/gsepetadelis&quot;&gt;
                        &lt;img src=&quot;https://s3-us-west-2.amazonaws.com/s.cdpn.io/210284/social-twitter.svg&quot; /&gt;
                    &lt;/a&gt;
                    &lt;/li&gt;
                &lt;/ul&gt;

        &lt;/aside&gt;

            &lt;/div&gt;

        &lt;/div&gt;

    )
}

export default AboutMeMobile;
</code></pre>
<p><strong>My css file:</strong></p>
<pre><code>@import url(https://fonts.googleapis.com/css?family=Open+Sans:400italic,600italic,700italic,800italic,400,600,700,800);

img {
    max-width: 100%;
}

.name {
    margin-top: 7%;
}

.info-card-container {
    z-index: 1;
    margin-top: 15%;
    width: 100%;
    position: absolute;
    display: inline-flex;
    flex-direction: column;
    align-items: center;
}

.profile-card {
    position: relative;
    width: 90%;
    margin-top: 8%;
    padding: 40px 30px 30px;
    background: #fff;
    border: 5px solid rgba(255,255,255,.7);
    text-align: center;
    border-radius: 8px;
    transition: all 200ms ease;
}

.mask-shadow {
    z-index: -1 !important;
    width: 95%;
    height: 12px;
    background: #000;
    bottom: 0;
    left: 0;
    right: 0;
    margin: 0 auto;
    position: absolute;
    border-radius: 4px;
    opacity: 0;
    border-radius: 80px;
    transition: all 400ms ease-in;
}

.mask-shadow {
    opacity: 1;
    box-shadow: 0px 30px 60px -5px rgba(55,55,71,0.3);
    position: absolute;
}

.profile-card header {
    display: block;
    margin-bottom: 10px;
}

.profile-card header a {
    width: 150px;
    height: 150px;
    display: block;
    border-radius: 100%;
    margin: -120px auto 0;
    box-shadow: 0 0 0 5px #3300ff;
}

.profile-card header a img {
    border-radius: 50%;
    width: 150px;
    height: 150px;
}

.profile-card header h1 {
    font-size: 20px;
    color: #444;
    text-transform: uppercase;
    margin-bottom: 5px;
}

.profile-card header h2 {
    font-size: 14px;
    color: #acacac;
    text-transform: uppercase;
    margin: 0;
}

.profile-bio {
    font-size: 14px;
    color:#a5a5a5;
    line-height: 1.7;
    font-style: italic;
    margin-bottom: 30px;
}

.profile-social-links {
    margin:0;
    padding:0;
    list-style: none;
}

.profile-social-links li {
    display: inline-block;
    margin: 0 10px;
}

.profile-social-links li a {
    width: 55px;
    height:55px;
    display:block;
    background:#f1f1f1;
    border-radius:50%;
    -webkit-transition: all 2.75s cubic-bezier(0,.83,.17,1);
    -moz-transition: all 2.75s cubic-bezier(0,.83,.17,1);
    -o-transition: all 2.75s cubic-bezier(0,.83,.17,1);
    transition: all 2.75s cubic-bezier(0,.83,.17,1);
    transform-style: preserve-3d;
}

.profile-social-links li a img {
    width: 35px;
    height: 35px;
    margin: 10px auto 0;
}

.profile-social-links li a:hover {
    background: #ddd;
    transform: scale(1.2);
    -webkit-transform: scale(1.2);
}
</code></pre>
",70,1,1,4,javascript;html;css;reactjs,2022-05-03 23:17:21,2022-05-03 23:17:21,2022-05-03 23:53:39,i have a hamburger menu inside my website and if i go inside a specific which i have a card with some other elements inside  but if i open the menu while i m inside the page with this card element the card goes above the menu for some reason  i tried almost everything but i can t get it right  i can t see where is my mistake with the css code    my react component  html   my css file ,element goes above other element   css
286,19019086,72096300,display result on result page,"<p>i have create quiz app, my question page is working properly but i want to display all wrong answers with their correct answers on the result page .I tried to get answers but give me so many errors. first i want display score then click show review answers to see the result page like this that u show on picture <a href=""https://i.stack.imgur.com/C8rQe.png"" rel=""nofollow noreferrer"">i want like this my score and result page</a></p>
<p>here is my question page</p>
<p>enter code here</p>
<pre><code>import 'package:flutter/material.dart';
import 'package:flutter_svg/flutter_svg.dart';
import 'package:get/get.dart';
import 'package:quiz_app/controllers/profile_controllers.dart';
import 'package:quiz_app/widgets/common_components/appbar.dart';

import 'widgets/pallete.dart';
import 'widgets/rounded_button.dart';

void main() {
  runApp(QuestionSample2());
}

class ChosenModel {
  final int questionNumber;
  final String questionAnswer;

  ChosenModel(this.questionNumber, this.questionAnswer);

  @override
  String toString() {
    return '{questionNumber: ${questionNumber}, questionAnswer: ${questionAnswer}}';
  }
}

class QuestionControl extends GetxController {
  List questions = [
    {
      &quot;id&quot;: 1,
      &quot;question&quot;:
          &quot;Flutter is an open-source UI software development kit created by ______&quot;,
      &quot;options&quot;: ['Apple', 'Google', 'Facebook', 'Microsoft'],
      &quot;answer&quot;: &quot;Google&quot;,
    },
    {
      &quot;id&quot;: 2,
      &quot;question&quot;: &quot;When google release Flutter.&quot;,
      &quot;options&quot;: ['Jun 2017', 'July 2017', 'May 2017', 'May 2018'],
      &quot;answer&quot;: &quot;Jun 2017&quot;,
    },
    {
      &quot;id&quot;: 3,
      &quot;question&quot;: &quot;A memory location that holds a single letter or number.&quot;,
      &quot;options&quot;: ['Double', 'Int', 'Char', 'Word'],
      &quot;answer&quot;: &quot;Char&quot;,
    },
    {
      &quot;id&quot;: 4,
      &quot;question&quot;: &quot;What command do you use to output data to the screen?&quot;,
      &quot;options&quot;: ['Cin', 'Count', 'Cout', 'Output'],
      &quot;answer&quot;: &quot;Output&quot;,
    },
  ].obs;

  List&lt;ChosenModel&gt; chosenAnswers = [];

  RxList groupValue = [-1, 0, 5, 9, 13].obs;
  RxList value = [
    [0, 1, 2, 4],
    [5, 6, 7, 8],
    [9, 10, 11, 12],
    [13, 14, 15, 16]
  ].obs;
  RxInt qnIndex = 1.obs;
}

class QuestionSample2 extends StatelessWidget {
  QuestionSample2({Key? key}) : super(key: key);

  final QuestionControl controller = Get.put(QuestionControl());
  ProfileController _questionController = Get.put(ProfileController());

  @override
  Widget build(BuildContext context) {
    return MaterialApp(
      home: Scaffold(
        backgroundColor: const Color.fromARGB(255, 0, 0, 0),
        appBar: quizeAppbar(),
        body: Padding(
          padding: const EdgeInsets.fromLTRB(5, 15, 5, 10),
          child: Column(
            children: [
              Obx(
                () =&gt; Text(
                    controller.qnIndex.toString() +
                        '/' +
                        controller.questions.length.toString(),
                    style: Theme.of(context)
                        .textTheme
                        .headline4!
                        .copyWith(color: Colors.white)),
              ),
              SizedBox(height: 20),
              SizedBox(
                height: 600.0,
                child: PageView.builder(
                    itemCount: controller.questions.length,
                    onPageChanged: (pageNumber) {
                      controller.qnIndex.value = pageNumber + 1;
                    },
                    itemBuilder: (context, snapshot) {
                      var options = controller.questions[snapshot]['options'];

                      return Container(
                        margin: const EdgeInsets.fromLTRB(10, 0, 10, 0),
                        decoration: BoxDecoration(
                          color: const Color.fromARGB(255, 88, 79, 79),
                          borderRadius: BorderRadius.circular(15),
                        ),
                        child: Column(
                          mainAxisAlignment: MainAxisAlignment.spaceBetween,
                          children: [
                            Spacer(
                              flex: 1,
                            ),
                            Text(
                              controller.questions[snapshot]['question']
                                  .toString(),
                              style: Theme.of(context)
                                  .textTheme
                                  .headline5!
                                  .copyWith(color: Colors.white),
                            ),
                            Spacer(
                              flex: 2,
                            ),
                            Container(
                              height: 400.0,
                              child: ListView.builder(
                                itemCount: 4,
                                itemBuilder: (context, index) =&gt; ButtonBar(
                                  alignment: MainAxisAlignment.center,
                                  children: &lt;Widget&gt;[
                                    Obx(
                                      () =&gt; Container(
                                        width: 300,
                                        padding: const EdgeInsets.all(10),
                                        decoration: BoxDecoration(
                                          border: Border.all(
                                              color: controller.groupValue[
                                                          snapshot] ==
                                                      controller.value[snapshot]
                                                          [index]
                                                  ? kblue
                                                  : Color.fromARGB(
                                                      255, 117, 110, 110),
                                              width: 2),
                                          borderRadius:
                                              BorderRadius.circular(15),
                                        ),
                                        child: RadioListTile&lt;int&gt;(
                                            activeColor: kblue,
                                            title: Row(
                                              children: [
                                                Text(
                                                  options[index].toString(),
                                                  style: Theme.of(context)
                                                      .textTheme
                                                      .headline5!
                                                      .copyWith(
                                                          color: Colors.white),
                                                ),
                                                Spacer(),
                                              ],
                                            ),
                                            controlAffinity:
                                                ListTileControlAffinity
                                                    .trailing,
                                            groupValue:
                                                controller.groupValue[snapshot],
                                            value: controller.value[snapshot]
                                                [index],
                                            onChanged: (newValue) {
                                              controller.groupValue[snapshot] =
                                                  newValue as int;

                                              controller.chosenAnswers.add(
                                                  ChosenModel(
                                                      controller.questions[
                                                              snapshot]['id']
                                                          as int,
                                                      options[index]
                                                          .toString()));
                                              print(controller.chosenAnswers);
                                            }),
                                      ),
                                    ),
                                  ],
                                ),
                              ),
                            ),
                          ],
                        ),
                      );
                    }),
              ),
              Spacer(),
              Obx(
                () =&gt; controller.questions.length == controller.qnIndex.value
                    ? const RoundedButton(
                        buttonName: 'Done',
                        page: '',
                      )
                    : Container(),
              ),
              Spacer(),
            ],
          ),
        ),
      ),
    );
  }
}
</code></pre>
<pre><code>enter code here
</code></pre>
",15,0,0,4,json;flutter;dart;user-interface,2022-05-03 10:52:15,2022-05-03 10:52:15,2022-05-03 10:52:15,i have create quiz app  my question page is working properly but i want to display all wrong answers with their correct answers on the result page  i tried to get answers but give me so many errors  first i want display score then click show review answers to see the result page like this that u show on picture  here is my question page enter code here,display result on result page
287,13861718,72092927,Airflow DAG runs successfully but Tasks fail,"<p>I am trying to run a simple DAG on Airflow running on Docker.</p>
<p>I've got two python scripts, the first one takes in the data using an API call, and the second one pushes the data into google sheets. So I've used <code>t1</code> to execute the first python script and <code>t2</code> to execute the second.</p>
<p>Here is my code:</p>
<pre><code>from airflow import DAG
#from airflow.operators.python import PythonOperator, BashOperator 
from datetime import datetime, timedelta
from airflow.operators.bash_operator import BashOperator
from airflow.utils.dates import days_ago

default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'email': ['airflow@airflow.com'],
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=1)}

with DAG(&quot;ETL_script&quot;,
        description= &quot;DAG for Data retrieval&quot;,
        default_args = default_args,
        start_date= datetime(2022, 1, 1),
        schedule_interval= &quot;@weekly&quot;, 
        catchup = False
        ) as dag:
    t1 = BashOperator(
            task_id = 'extract_data',
            bash_command = '/Users/user.name/Coding Projects/Python_Apps/Docker_Applications/Airflow_Docker_Apps/Python_Scripts/API_extract.py',
            dag=dag,)
    
    t2 = BashOperator(
        task_id = &quot;Insert_into_google_Sheets&quot;,
        bash_command = 'python3 &quot;/Users/user.name/Coding Projects/Python_Apps/Docker_Applications/Airflow_Docker_Apps/Python_Scripts/Google_Sheets_Connection.py&quot;',
        dag=dag,)
    
    t1 &gt;&gt; t2 # Defining the task dependencies
</code></pre>
<p>When I run Bash command on <code>zsh</code> I can run both of the python scripts perfectly but on Airflow, I get this error:</p>
<pre><code>*** Reading local file: /opt/airflow/logs/ETL_script/extract_data/2022-05-02T21:27:56.923195+00:00/1.log
[2022-05-02, 21:27:58 UTC] {taskinstance.py:1043} INFO - Dependencies all met for &lt;TaskInstance: ETL_script.extract_data manual__2022-05-02T21:27:56.923195+00:00 [queued]&gt;
[2022-05-02, 21:27:58 UTC] {taskinstance.py:1043} INFO - Dependencies all met for &lt;TaskInstance: ETL_script.extract_data manual__2022-05-02T21:27:56.923195+00:00 [queued]&gt;
[2022-05-02, 21:27:58 UTC] {taskinstance.py:1249} INFO - 
--------------------------------------------------------------------------------
[2022-05-02, 21:27:58 UTC] {taskinstance.py:1250} INFO - Starting attempt 1 of 2
[2022-05-02, 21:27:58 UTC] {taskinstance.py:1251} INFO - 
--------------------------------------------------------------------------------
[2022-05-02, 21:27:58 UTC] {taskinstance.py:1270} INFO - Executing &lt;Task(BashOperator): extract_data&gt; on 2022-05-02 21:27:56.923195+00:00
[2022-05-02, 21:27:58 UTC] {standard_task_runner.py:52} INFO - Started process 148 to run task
[2022-05-02, 21:27:58 UTC] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'ETL_script', 'extract_data', 'manual__2022-05-02T21:27:56.923195+00:00', '--job-id', '134', '--raw', '--subdir', 'DAGS_FOLDER/ETL_script.py', '--cfg-path', '/tmp/tmpeaprux6w', '--error-file', '/tmp/tmp1hhf5ge7']
[2022-05-02, 21:27:58 UTC] {standard_task_runner.py:80} INFO - Job 134: Subtask extract_data
[2022-05-02, 21:27:58 UTC] {logging_mixin.py:109} INFO - Running &lt;TaskInstance: ETL_script.extract_data manual__2022-05-02T21:27:56.923195+00:00 [running]&gt; on host 4c9d01f48299
[2022-05-02, 21:27:58 UTC] {taskinstance.py:1448} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=***@***.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ETL_script
AIRFLOW_CTX_TASK_ID=extract_data
AIRFLOW_CTX_EXECUTION_DATE=2022-05-02T21:27:56.923195+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-05-02T21:27:56.923195+00:00
[2022-05-02, 21:27:58 UTC] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-05-02, 21:27:58 UTC] {subprocess.py:74} INFO - Running command: ['bash', '-c', '/Users/user.name/Coding Projects/Python_Apps/Docker_Applications/Airflow_Docker_Apps/Python_Scripts/API_extract.py']
[2022-05-02, 21:27:58 UTC] {subprocess.py:85} INFO - Output:
[2022-05-02, 21:27:58 UTC] {subprocess.py:89} INFO - bash: /Users/user.name/Coding: No such file or directory
[2022-05-02, 21:27:58 UTC] {subprocess.py:93} INFO - Command exited with return code 127
[2022-05-02, 21:27:58 UTC] {taskinstance.py:1774} ERROR - Task failed with exception
Traceback (most recent call last):
  File &quot;/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py&quot;, line 188, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 127.
[2022-05-02, 21:27:58 UTC] {taskinstance.py:1288} INFO - Marking task as UP_FOR_RETRY. dag_id=ETL_script, task_id=extract_data, execution_date=20220502T212756, start_date=20220502T212758, end_date=20220502T212758
[2022-05-02, 21:27:58 UTC] {standard_task_runner.py:98} ERROR - Failed to execute job 134 for task extract_data (Bash command failed. The command returned a non-zero exit code 127.; 148)
[2022-05-02, 21:27:58 UTC] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-05-02, 21:27:58 UTC] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check


</code></pre>
<p>So from my understanding the first task <code>t1</code> fails and gives me this error. I think I might've not defined the <code>$PATH</code> correctly and so this gave me this error. This was my first thought but I don't know how to correct it.</p>
<p><strong>Additional Information</strong></p>
<p>Here is what my working directory looks like:</p>
<pre><code>Docker_Applications
├───dags
│   ├───ETL_script.py
│   
│    
├───logs
├───plugins
├───Python_Scripts   
│   ├───API_extract.py
│   ├───Google_Sheets_Connection.py
│  
├───.env
├───docker-compose.yaml
</code></pre>
<p>my <code>echo $PATH</code> is</p>
<pre><code>Projects:/Library/Frameworks/Python.framework/Versions/3.10/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/Frameworks/Python.framework/Versions/3.10/bin
</code></pre>
<p>and my <code>docker-compose.yaml</code> file looks like:</p>
<pre><code># Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# &quot;License&quot;); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#Documentation: https://airflow.apache.org/docs/apache-airflow/stable/start/docker.html#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#

# Basic Airflow cluster configuration for CeleryExecutor with Redis and PostgreSQL.
#
# WARNING: This configuration is for local development. Do not use it in a production deployment.
#
# This configuration supports basic configuration using environment variables or an .env file
# The following variables are supported:
#
# AIRFLOW_IMAGE_NAME           - Docker image name used to run Airflow.
#                                Default: apache/airflow:2.2.5
# AIRFLOW_UID                  - User ID in Airflow containers
#                                Default: 50000
# Those configurations are useful mostly in case of standalone testing/running Airflow in test/try-out mode
#
# _AIRFLOW_WWW_USER_USERNAME   - Username for the administrator account (if requested).
#                                Default: airflow
# _AIRFLOW_WWW_USER_PASSWORD   - Password for the administrator account (if requested).
#                                Default: airflow
# _PIP_ADDITIONAL_REQUIREMENTS - Additional PIP requirements to add when starting all containers.
#                                Default: ''
#
# Feel free to modify this file to suit your needs.
---
version: '3.7'
x-airflow-common:
  &amp;airflow-common
  # In order to add custom dependencies or upgrade provider packages you can use your extended image.
  # Comment the image line, place your Dockerfile in the directory where you placed the docker-compose.yaml
  # and uncomment the &quot;build&quot; line below, Then run `docker-compose build` to build the images.
  image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:2.2.5}
  # build: .
  environment:
    &amp;airflow-common-env
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
    AIRFLOW__CORE__FERNET_KEY: ''
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__API__AUTH_BACKEND: 'airflow.api.auth.backend.basic_auth'
    _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
  user: &quot;${AIRFLOW_UID:-50000}:0&quot;
  depends_on:
    &amp;airflow-common-depends-on
    redis:
      condition: service_healthy
    postgres:
      condition: service_healthy

services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: [&quot;CMD&quot;, &quot;pg_isready&quot;, &quot;-U&quot;, &quot;airflow&quot;]
      interval: 5s
      retries: 5
    restart: always

  redis:
    image: redis:latest
    expose:
      - 6379
    healthcheck:
      test: [&quot;CMD&quot;, &quot;redis-cli&quot;, &quot;ping&quot;]
      interval: 5s
      timeout: 30s
      retries: 50
    restart: always

  airflow-webserver:
    &lt;&lt;: *airflow-common
    command: webserver
    ports:
      - 8080:8080
    healthcheck:
      test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;--fail&quot;, &quot;http://localhost:8080/health&quot;]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
    depends_on:
      &lt;&lt;: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-scheduler:
    &lt;&lt;: *airflow-common
    command: scheduler
    healthcheck:
      test: [&quot;CMD-SHELL&quot;, 'airflow jobs check --job-type SchedulerJob --hostname &quot;$${HOSTNAME}&quot;']
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
    depends_on:
      &lt;&lt;: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-worker:
    &lt;&lt;: *airflow-common
    command: celery worker
    healthcheck:
      test:
        - &quot;CMD-SHELL&quot;
        - 'celery --app airflow.executors.celery_executor.app inspect ping -d &quot;celery@$${HOSTNAME}&quot;'
      interval: 10s
      timeout: 10s
      retries: 5
    environment:
      &lt;&lt;: *airflow-common-env
      # Required to handle warm shutdown of the celery workers properly
      # See https://airflow.apache.org/docs/docker-stack/entrypoint.html#signal-propagation
      DUMB_INIT_SETSID: &quot;0&quot;
    restart: always
    depends_on:
      &lt;&lt;: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-triggerer:
    &lt;&lt;: *airflow-common
    command: triggerer
    healthcheck:
      test: [&quot;CMD-SHELL&quot;, 'airflow jobs check --job-type TriggererJob --hostname &quot;$${HOSTNAME}&quot;']
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
    depends_on:
      &lt;&lt;: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-init:
    &lt;&lt;: *airflow-common
    entrypoint: /bin/bash
    # yamllint disable rule:line-length
    command:
      - -c
      - |
        function ver() {
          printf &quot;%04d%04d%04d%04d&quot; $${1//./ }
        }
        airflow_version=$$(gosu airflow airflow version)
        airflow_version_comparable=$$(ver $${airflow_version})
        min_airflow_version=2.2.0
        min_airflow_version_comparable=$$(ver $${min_airflow_version})
        if (( airflow_version_comparable &lt; min_airflow_version_comparable )); then
          echo
          echo -e &quot;\033[1;31mERROR!!!: Too old Airflow version $${airflow_version}!\e[0m&quot;
          echo &quot;The minimum Airflow version supported: $${min_airflow_version}. Only use this or higher!&quot;
          echo
          exit 1
        fi
        if [[ -z &quot;${AIRFLOW_UID}&quot; ]]; then
          echo
          echo -e &quot;\033[1;33mWARNING!!!: AIRFLOW_UID not set!\e[0m&quot;
          echo &quot;If you are on Linux, you SHOULD follow the instructions below to set &quot;
          echo &quot;AIRFLOW_UID environment variable, otherwise files will be owned by root.&quot;
          echo &quot;For other operating systems you can get rid of the warning with manually created .env file:&quot;
          echo &quot;    See: https://airflow.apache.org/docs/apache-airflow/stable/start/docker.html#setting-the-right-airflow-user&quot;
          echo
        fi
        one_meg=1048576
        mem_available=$$(($$(getconf _PHYS_PAGES) * $$(getconf PAGE_SIZE) / one_meg))
        cpus_available=$$(grep -cE 'cpu[0-9]+' /proc/stat)
        disk_available=$$(df / | tail -1 | awk '{print $$4}')
        warning_resources=&quot;false&quot;
        if (( mem_available &lt; 4000 )) ; then
          echo
          echo -e &quot;\033[1;33mWARNING!!!: Not enough memory available for Docker.\e[0m&quot;
          echo &quot;At least 4GB of memory required. You have $$(numfmt --to iec $$((mem_available * one_meg)))&quot;
          echo
          warning_resources=&quot;true&quot;
        fi
        if (( cpus_available &lt; 2 )); then
          echo
          echo -e &quot;\033[1;33mWARNING!!!: Not enough CPUS available for Docker.\e[0m&quot;
          echo &quot;At least 2 CPUs recommended. You have $${cpus_available}&quot;
          echo
          warning_resources=&quot;true&quot;
        fi
        if (( disk_available &lt; one_meg * 10 )); then
          echo
          echo -e &quot;\033[1;33mWARNING!!!: Not enough Disk space available for Docker.\e[0m&quot;
          echo &quot;At least 10 GBs recommended. You have $$(numfmt --to iec $$((disk_available * 1024 )))&quot;
          echo
          warning_resources=&quot;true&quot;
        fi
        if [[ $${warning_resources} == &quot;true&quot; ]]; then
          echo
          echo -e &quot;\033[1;33mWARNING!!!: You have not enough resources to run Airflow (see above)!\e[0m&quot;
          echo &quot;Please follow the instructions to increase amount of resources available:&quot;
          echo &quot;   https://airflow.apache.org/docs/apache-airflow/stable/start/docker.html#before-you-begin&quot;
          echo
        fi
        mkdir -p /sources/logs /sources/dags /sources/plugins
        chown -R &quot;${AIRFLOW_UID}:0&quot; /sources/{logs,dags,plugins}
        exec /entrypoint airflow version
    # yamllint enable rule:line-length
    environment:
      &lt;&lt;: *airflow-common-env
      _AIRFLOW_DB_UPGRADE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}
    user: &quot;0:0&quot;
    volumes:
      - .:/sources

  airflow-cli:
    &lt;&lt;: *airflow-common
    profiles:
      - debug
    environment:
      &lt;&lt;: *airflow-common-env
      CONNECTION_CHECK_MAX_COUNT: &quot;0&quot;
    # Workaround for entrypoint issue. See: https://github.com/apache/airflow/issues/16252
    command:
      - bash
      - -c
      - airflow

  flower:
    &lt;&lt;: *airflow-common
    command: celery flower
    ports:
      - 5555:5555
    healthcheck:
      test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;--fail&quot;, &quot;http://localhost:5555/&quot;]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
    depends_on:
      &lt;&lt;: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

volumes:
  postgres-db-volume:
</code></pre>
<p>Note: This <code>yaml</code> file is the same as the one from the tutorial on Airflow webpage. Please suggest any changes or best practices because I am still learning!</p>
<p>Thank you so much!!!!</p>
",942,0,0,5,python;docker;etl;zsh;airflow-2.x,2022-05-03 01:12:50,2022-05-03 01:12:50,2022-05-03 01:12:50,i am trying to run a simple dag on airflow running on docker  i ve got two python scripts  the first one takes in the data using an api call  and the second one pushes the data into google sheets  so i ve used t to execute the first python script and t to execute the second  here is my code  when i run bash command on zsh i can run both of the python scripts perfectly but on airflow  i get this error  so from my understanding the first task t fails and gives me this error  i think i might ve not defined the  path correctly and so this gave me this error  this was my first thought but i don t know how to correct it  additional information here is what my working directory looks like  my echo  path is and my docker compose yaml file looks like  note  this yaml file is the same as the one from the tutorial on airflow webpage  please suggest any changes or best practices because i am still learning  thank you so much    ,airflow dag runs successfully but tasks fail
288,5081214,72087495,Developing on a remote machine and Git - Best Practices,"<p>I've been developing software systems that generally end up training large scale models and then evaluating them on a number of remote cloud instances, for the past 6 years. I am using primarily Python and PyTorch as the main two components of my projects.</p>
<p>Recently, I adopted a very strong git commit ethic with proper messaging formats etc, and been using continual integration to develop large open source projects.</p>
<p>What has become increasingly clear is that using Git as a means of 'uploading' code to the cloud is not the best way of syncing my repo, since that leaves a trail of rubbish commit messages etc. I have also tried using something like Pycharm's remote syncing functionality, but unfortunately that means that my code only leaves on a volatile remote machine and a volatile local machine.</p>
<p>I am wondering, is there a proper way to use Git as a syncing agent and a development tracking agent? Is my way of doing things completely stupid here?</p>
<p>Just looking to hear what other people do out there. Thanks for your time and attention.</p>
",23,0,1,4,python;git;pytorch;cloud,2022-05-02 16:33:07,2022-05-02 16:33:07,2022-05-02 16:33:07,i ve been developing software systems that generally end up training large scale models and then evaluating them on a number of remote cloud instances  for the past  years  i am using primarily python and pytorch as the main two components of my projects  recently  i adopted a very strong git commit ethic with proper messaging formats etc  and been using continual integration to develop large open source projects  what has become increasingly clear is that using git as a means of  uploading  code to the cloud is not the best way of syncing my repo  since that leaves a trail of rubbish commit messages etc  i have also tried using something like pycharm s remote syncing functionality  but unfortunately that means that my code only leaves on a volatile remote machine and a volatile local machine  i am wondering  is there a proper way to use git as a syncing agent and a development tracking agent  is my way of doing things completely stupid here  just looking to hear what other people do out there  thanks for your time and attention ,developing on a remote machine and git   best practices
289,2218907,18371741,Git branching strategy integated with testing/QA process,"<p>Our development team has been using the <a href=""http://nvie.com/posts/a-successful-git-branching-model/"" rel=""noreferrer"">GitFlow</a> branching strategy and it has been great !</p>

<p>Recently we recruited a couple testers to improve our software quality. The idea is that every feature should be tested/QA by a tester.</p>

<p>In the past, developers work on features on separate feature branches and merge them back to the <code>develop</code> branch when done. The developer will test his work himself on that <code>feature</code> branch. Now with testers, we start asking this Question</p>

<blockquote>
  <p>On which branch should the tester test   new features ?</p>
</blockquote>

<p>Obviously, there are two options: </p>

<ul>
<li>on the individual feature branch</li>
<li>on the <code>develop</code> branch</li>
</ul>

<h2>Testing On Develop Branch</h2>

<p>Initially, we believed this is the sure way to go because:</p>

<ul>
<li>The feature is tested with all other features merged to the <code>develop</code> branch since it's development started. </li>
<li>Any conflicts can be detected earlier than later</li>
<li>It makes the tester's job easy, he is only dealing with one branch (<code>develop</code>) at all time. He doesn't need to ask the developer about which branch is for which feature ( feature branches are personal branches managed exclusively and freely by relevant developers )</li>
</ul>

<p>The biggest problems with this is:</p>

<ul>
<li><p>The <code>develop</code> branch is polluted with bugs. </p>

<p>When the tester finds bugs or conflicts, he reports them back to the developer, who fixes the issue on the develop branch (the feature branch were abandoned once merged ), and there could be more fixes required afterward. Multiple subsequence commits or merges (if a branch is recreated off <code>develop</code> branch again for fixing the bugs) makes rolling back the feature from the <code>develop</code> branch very difficult if possible. There are multiple features merging to and being fixed on the <code>develop</code> branch at different times. This creates a big issue when we want to create a release with just some of the features in the <code>develop</code> branch </p></li>
</ul>

<h2>Testing On Feature Branch</h2>

<p>So we thought again and decided we should test features on the feature branches. Before we test, we merge the changes from the <code>develop</code> branch to the feature branch ( catch up with the <code>develop</code> branch ). This is good:</p>

<ul>
<li>You still test the feature with other features in the mainstream</li>
<li>Further development ( e.g. bug fix, resolving conflict ) will not pollute the <code>develop</code> branch;</li>
<li>You can easily decide not to release the feature until it is fully tested and approved;</li>
</ul>

<p>However, there are some drawbacks</p>

<ul>
<li>The tester has to do the merging of the code, and if there's any conflict (very likely), he has to ask the developer for help. Our testers specialize in test and are not capable of coding.</li>
<li>a feature could be tested without the existence of another new feature. e.g. Feature A and B are both under test at the same time, the two features are unaware of each other because neither of them has been merged to the <code>develop</code> branch. These means you will have to test against the <code>develop</code> branch again when both of the features are merged to the develop branch anyway. And you have to remember to test this in the future.</li>
<li>If Feature A and B are both tested and approved, but when merged a conflict is identified, both of the developers for both features believe it is not his own fault/job because his feature branch past the test. There is an extra overhead in communication, and sometimes whoever resolving the conflict is frustrated. </li>
</ul>

<hr>

<p>Above is our story. With limited resource, I would like to avoid testing everything everywhere. We are still looking for a better way to cope with this. I would love to hear how other teams handle this kind of situations.</p>
",49451,6,146,3,git;testing;git-flow,2013-08-22 07:31:39,2013-08-22 07:31:39,2022-05-02 16:30:14,our development team has been using the  branching strategy and it has been great   recently we recruited a couple testers to improve our software quality  the idea is that every feature should be tested qa by a tester  in the past  developers work on features on separate feature branches and merge them back to the develop branch when done  the developer will test his work himself on that feature branch  now with testers  we start asking this question on which branch should the tester test   new features   obviously  there are two options   initially  we believed this is the sure way to go because  the biggest problems with this is  the develop branch is polluted with bugs   when the tester finds bugs or conflicts  he reports them back to the developer  who fixes the issue on the develop branch  the feature branch were abandoned once merged    and there could be more fixes required afterward  multiple subsequence commits or merges  if a branch is recreated off develop branch again for fixing the bugs  makes rolling back the feature from the develop branch very difficult if possible  there are multiple features merging to and being fixed on the develop branch at different times  this creates a big issue when we want to create a release with just some of the features in the develop branch  so we thought again and decided we should test features on the feature branches  before we test  we merge the changes from the develop branch to the feature branch   catch up with the develop branch    this is good  however  there are some drawbacks above is our story  with limited resource  i would like to avoid testing everything everywhere  we are still looking for a better way to cope with this  i would love to hear how other teams handle this kind of situations ,git branching strategy integated with testing qa process
290,14304843,72077495,Unable to connect to SQL Server on domain,"<p>I have been trying to connect to the SQL server in my domain for several days. I have a virtual box network with a client and a server. Only the client can’t find the sql server on my server. I followed all the steps to allow my database to comminuqer on port 1433 but nothing changes.</p>
<p>I don’t know what to do, I enabled TCP/IP with port 1433 and allowed connections in my database, as everyone recommends.</p>
<p>I have no server proposal and when I test with ip, I also have a mistake :</p>
<p><a href=""https://i.stack.imgur.com/Z9lwE.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Z9lwE.png"" alt=""client"" /></a></p>
<p>I added a new rule on my server:</p>
<p><a href=""https://i.stack.imgur.com/WU64Q.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/WU64Q.png"" alt=""new_rule"" /></a></p>
<p>The answer may be simple for some but I am not an expert in software development, I hope some will have answers.</p>
<p>Thanks in advance:)</p>
",55,0,0,2,sql-server;virtualbox,2022-05-01 17:17:28,2022-05-01 17:17:28,2022-05-01 21:33:40,i have been trying to connect to the sql server in my domain for several days  i have a virtual box network with a client and a server  only the client can t find the sql server on my server  i followed all the steps to allow my database to comminuqer on port  but nothing changes  i don t know what to do  i enabled tcp ip with port  and allowed connections in my database  as everyone recommends  i have no server proposal and when i test with ip  i also have a mistake    i added a new rule on my server   the answer may be simple for some but i am not an expert in software development  i hope some will have answers  thanks in advance  ,unable to connect to sql server on domain
291,6039980,58346431,Why isn&#39;t Cucumber considered as a testing tool?,"<p>I'm new to Cucumber, and I'm trying to understand the tool. While reading <a href=""https://cucumber.io/docs/guides/overview/"" rel=""nofollow noreferrer"">the documentation</a>, I found that it is defined shortly as <strong>&quot;a tool that supports BDD&quot;</strong>:</p>
<blockquote>
<p>Cucumber is a tool that supports Behaviour-Driven Development(BDD).</p>
</blockquote>
<p>Also it is described as a &quot;validation tool&quot;:</p>
<blockquote>
<p>Cucumber reads executable specifications written in plain text and validates that the software does what those specifications say.</p>
</blockquote>
<p>In the other side, I noticed the excessive use of the word <strong>&quot;test&quot;</strong> on the <a href=""https://cucumber.io/docs/guides/10-minute-tutorial/"" rel=""nofollow noreferrer"">10-minute tutorial</a>.</p>
<p>AFAIK, what does this tool is agile testing, since it is used massively in e2e testing (test basis = Gherkin feature specs + step definitions). However, <a href=""https://cucumber.io/blog/where_should_you_use_bdd/"" rel=""nofollow noreferrer"">the blog</a> says something different:</p>
<blockquote>
<p>Finally, remember that Cucumber is <strong>not a testing tool</strong>. It is a tool for capturing common understanding on how a system should work. A tool that allows you, but doesn't require you, to automate the verification of the behaviour of your system if you find it useful.</p>
</blockquote>
<p>Now if this tool is not really about testing, then what use is it intended for?</p>
",473,1,1,3,testing;cucumber;bdd,2019-10-11 21:05:37,2019-10-11 21:05:37,2022-05-01 20:59:37,i m new to cucumber  and i m trying to understand the tool  while reading   i found that it is defined shortly as  a tool that supports bdd   cucumber is a tool that supports behaviour driven development bdd   also it is described as a  validation tool   cucumber reads executable specifications written in plain text and validates that the software does what those specifications say  in the other side  i noticed the excessive use of the word  test  on the   afaik  what does this tool is agile testing  since it is used massively in ee testing  test basis   gherkin feature specs   step definitions   however   says something different  finally  remember that cucumber is not a testing tool  it is a tool for capturing common understanding on how a system should work  a tool that allows you  but doesn t require you  to automate the verification of the behaviour of your system if you find it useful  now if this tool is not really about testing  then what use is it intended for ,why isn   t cucumber considered as a testing tool 
292,18991101,72061356,"Good habits in software development - what exactly are backing services, in a general definition?","<p>So basically, I'm a web development student who wants to understand deeply the best way to code. In a documentation called &quot;The twelve factor app&quot;, I saw that the 4th factor was &quot;backing services&quot; and what I understood from it was that an ideal application must not differentiate local services from external services and this means that every single service must be an external service, accessible by an URL. I also took a look at the fundamentals behind Docker and my main misunderstanding is: If I have an fully managed app at the same machine or VM, with microsservices architecture using Docker, where each container in isolation does what it is responsible for doing, is this app considered in 4th factor? In other words, is container isolation considered a backing service, or it's not enough and, to be considered a backing service, the service must be in another machine outside localhost and accesible via TCP/IP?</p>
<p>Please, if my question is poorly worded, I would love to receive feedback and orientation, since I'm a beginner.</p>
",26,1,-1,5,docker;web-services;service;cloud;virtual-machine,2022-04-29 19:59:40,2022-04-29 19:59:40,2022-04-29 20:41:17,so basically  i m a web development student who wants to understand deeply the best way to code  in a documentation called  the twelve factor app   i saw that the th factor was  backing services  and what i understood from it was that an ideal application must not differentiate local services from external services and this means that every single service must be an external service  accessible by an url  i also took a look at the fundamentals behind docker and my main misunderstanding is  if i have an fully managed app at the same machine or vm  with microsservices architecture using docker  where each container in isolation does what it is responsible for doing  is this app considered in th factor  in other words  is container isolation considered a backing service  or it s not enough and  to be considered a backing service  the service must be in another machine outside localhost and accesible via tcp ip  please  if my question is poorly worded  i would love to receive feedback and orientation  since i m a beginner ,good habits in software development   what exactly are backing services  in a general definition 
293,16565318,72051593,Cannot properly concat to an array in ReactJS when using useState hook,"<p>I have a button that increments a vote counter whenever it is clicked, however I am having trouble implementing it. When I first click the Vote button, the function incrementVote is run and when I log my results to the console, I find that it prints out an empty array even though I concatenated the array. This problem only occurs for the first click, as subsequent clicks work as expected. Any help would be greatly appreciated.</p>
<pre><code>import logo from './logo.svg';
import './App.css';
import Header from './Header';
import Feedback from './Feedback';
import { useState } from 'react';
import Statistics from './Statistics';
import AnecdoteBtn from './AnecdoteBtn';
import Phrase from './Phrase';
import { useEffect } from 'react';

function App() {
  const anecdotes = [
    'If it hurts, do it more often',
    'Adding manpower to a late software project makes it later!',
    'The first 90 percent of the code accounts for the first 10 percent of the development time...The remaining 10 percent of the code accounts for the other 90 percent of the development time.',
    'Any fool can write code that a computer can understand. Good programmers write code that humans can understand.',
    'Premature optimization is the root of all evil.',
    'Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it.',
    'Programming without an extremely heavy use of console.log is same as if a doctor would refuse to use x-rays or blood tests when diagnosing patients'
  ]

  const [selected, setSelected] = useState();
  const [votes, setVotes] = useState([]);
  const [finalVotes, setFinalVotes] = useState(0);
  const [goodClick, setGoodClick] = useState(0);
  const [badClick, setBadClick] = useState(0);
  const [neutralClick, setNeutralClick] = useState(0);
  const [average, setAverage] = useState(0);


// ----------------------------DOES NOT INCREMENT PROPERLY ON THE FIRST CLICK - AS IT PRINTS OUT AN EMPTY ARRAY---------------------------------------------------//

  const incrementVote = () =&gt; {
    console.log(votes.concat(selected));
    var newArr = votes.concat(selected)
    setVotes(newArr);
    console.log(votes) //Prints out [] even though array is concatenated

    if(votes.includes(selected)){
      let numVotes = votes.filter((v) =&gt; (v === selected));
      setFinalVotes(numVotes.length);
    }
    else {
      setFinalVotes(0);
    }
  }

  const setRandom = () =&gt; {
    setSelected(Math.floor((Math.random() * 7) + 1));
  }

  useEffect(() =&gt; {
    console.log(&quot;selected value has changed!&quot;)
    setFinalVotes(0);
    console.log(&quot;votes array is &quot; + votes)
    console.log(&quot;current selected value is &quot; + selected)

    let numVotes = votes.filter((v) =&gt; (v === selected));
    setFinalVotes(numVotes.length);
  }, [selected]);


  const handleGoodClick = () =&gt; {
    console.log(&quot;good btn clicked&quot;);
    setGoodClick(goodClick + 1);
    setAverage(average + 1);
  }
  const handleBadClick = () =&gt; {
    console.log(&quot;bad btn clicked&quot;);
    setBadClick(badClick + 1);
    setAverage(average - 1);
  }
  const handleNeutralClick = () =&gt; {
    console.log(&quot;neutral btn clicked&quot;);
    setNeutralClick(neutralClick + 1);
    setAverage(average + 0);
  }
   
  return (
    &lt;div className=&quot;App&quot;&gt;
      &lt;Header /&gt;
      &lt;AnecdoteBtn handleClick = {setRandom} handleVoteClick = {incrementVote}/&gt;
      &lt;Phrase index = {selected} anecdotes = {anecdotes} finalVotes = {finalVotes}/&gt;
      &lt;Feedback handleGoodClick = {handleGoodClick} handBadClick = {handleBadClick} handleNeutralClick = {handleNeutralClick}/&gt;
      &lt;Statistics goodClicks = {goodClick} badClicks = {badClick} neutralClicks = {neutralClick} average = {average}/&gt;
    &lt;/div&gt;
  );
}

export default App;
</code></pre>
",40,1,0,2,javascript;reactjs,2022-04-29 03:30:51,2022-04-29 03:30:51,2022-04-29 11:30:08,i have a button that increments a vote counter whenever it is clicked  however i am having trouble implementing it  when i first click the vote button  the function incrementvote is run and when i log my results to the console  i find that it prints out an empty array even though i concatenated the array  this problem only occurs for the first click  as subsequent clicks work as expected  any help would be greatly appreciated ,cannot properly concat to an array in reactjs when using usestate hook
294,17990524,72051175,Problems linking glew and glut with cmake,"<p>I have a C++ project on windows that I am trying to build on Windows using Cmake (Mingw). I need to link glew and glut libraries with my project. This is my CMakeLists.txt file at the top project level.</p>
<pre><code>cmake_minimum_required(VERSION 3.9.1)
project(Pacman)

# message(&quot;${CMAKE_CURRENT_SOURCE_DIR}/Glew/include/glew.h&quot;)

set(CMAKE_PREFIX_PATH &quot;${CMAKE_CURRENT_SOURCE_DIR}/glew-2.2.0&quot;)
set(CMAKE_LIBRARY_PATH &quot;${CMAKE_CURRENT_SOURCE_DIR}/glew-2.2.0/lib/Release/Win32/&quot;)
find_package(GLEW REQUIRED)

set(CMAKE_PREFIX_PATH &quot;${CMAKE_CURRENT_SOURCE_DIR}/freeglut&quot;)
set(CMAKE_LIBRARY_PATH &quot;${CMAKE_CURRENT_SOURCE_DIR}/freeglut/lib&quot;)
find_package(GLUT REQUIRED)

find_path(GLEW_INCLUDE_DIR gl/glew.h)
find_library(GLEW_LIBRARIES NAMES GLEW glew32 glew glew32s)

message(${GLEW_INCLUDE_DIR})
message(${GLEW_LIBRARIES})
message(${GLUT_INCLUDE_DIR})
message(${GLUT_LIBRARY})

include_directories(${GLEW_INCLUDE_DIR})

find_path(GLUT_INCLUDE_DIR GL/glut.h)
find_library(GLUT_LIBRARIES NAMES GLUT freeglut PATH_SUFFIXES lib64)

file(GLOB SOURCES &quot;*.cpp&quot;)

message(${SOURCES})

add_executable(game ${SOURCES})

target_link_libraries(game GLEW::GLEW GLUT::GLUT)
</code></pre>
<p>I used the following glew library and placed it inside my folder directory so I can link it with my own project.
<a href=""https://sourceforge.net/projects/glew/files/glew/2.1.0/"" rel=""nofollow noreferrer"">https://sourceforge.net/projects/glew/files/glew/2.1.0/</a></p>
<p>I used the following freeglut MSVC library and placed it inside my folder directory so I can link it with my project.
<a href=""https://www.transmissionzero.co.uk/files/software/development/GLUT/freeglut-MSVC.zip"" rel=""nofollow noreferrer"">https://www.transmissionzero.co.uk/files/software/development/GLUT/freeglut-MSVC.zip</a></p>
<p>This is my overall folder structure</p>
<p>-&gt; Pacman (this is the parent folder)</p>
<p>--&gt; build</p>
<p>--&gt; freeglut</p>
<p>--&gt; glew-2.2.0</p>
<p>--&gt; other cpp and h files</p>
<p>--&gt; CMakeLists.txt</p>
<p>When I run <strong>cmake -G &quot;MinGW Makefiles&quot; ..</strong> in build folder I get the following output meaning that the libraries were found and linked.</p>
<pre><code>-- The C compiler identification is GNU 11.2.0
-- The CXX compiler identification is GNU 11.2.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: C:/msys64/mingw64/bin/gcc.exe - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: C:/msys64/mingw64/bin/g++.exe - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found GLEW: D:/Daniyal/Semester 2/Pacman/glew-2.2.0/include (found version &quot;2.2.0&quot;) 
-- Found PkgConfig: C:/msys64/mingw64/bin/pkg-config.exe (found version &quot;1.8.0&quot;) 
-- Checking for module 'glut'
--   Package 'glut', required by 'virtual:world', not found
-- Found GLUT: D:/Daniyal/Semester 2/Pacman/freeglut/lib/freeglut.lib  
D:/Daniyal/Semester 2/Pacman/glew-2.2.0/include
D:/Daniyal/Semester 2/Pacman/glew-2.2.0/lib/Release/x64/glew32.lib
D:/Daniyal/Semester 2/Pacman/freeglut/include
D:/Daniyal/Semester 2/Pacman/freeglut/lib/freeglut.lib
D:/Daniyal/Semester 2/Pacman/Board.cppD:/Daniyal/Semester 2/Pacman/Bomb.cppD:/Daniyal/Semester 2/Pacman/Bomberman.cppD:/Daniyal/Semester 2/Pacman/Character.cppD:/Daniyal/Semester 2/Pacman/Ghosts.cppD:/Daniyal/Semester 2/Pacman/Point.cppD:/Daniyal/Semester 2/Pacman/bomber_Pacman.cppD:/Daniyal/Semester 2/Pacman/util.cpp
-- Configuring done
-- Generating done
-- Build files have been written to: D:/Daniyal/Semester 2/Pacman/build
</code></pre>
<p>When I try to <strong>make</strong> the project in the build folder, it gives multiple errors. I am going to copy-paste some of them below.</p>
<pre><code>C:/msys64/mingw64/bin/../lib/gcc/x86_64-w64-mingw32/11.2.0/../../../../x86_64-w64-mingw32/bin/ld.exe: CMakeFiles\game.dir/objects.a(util.cpp.obj):util.cpp:(.text+0x17b4): undefined reference to `glVertex4f'
C:/msys64/mingw64/bin/../lib/gcc/x86_64-w64-mingw32/11.2.0/../../../../x86_64-w64-mingw32/bin/ld.exe: CMakeFiles\game.dir/objects.a(util.cpp.obj):util.cpp:(.text+0x17f6): undefined reference to `glVertex4f'
C:/msys64/mingw64/bin/../lib/gcc/x86_64-w64-mingw32/11.2.0/../../../../x86_64-w64-mingw32/bin/ld.exe: CMakeFiles\game.dir/objects.a(util.cpp.obj):util.cpp:(.text+0x1824): undefined reference to `glVertex4f'
</code></pre>
<p>Can someone guide me? Is there something I am doing wrong while linking (keeping in mind that I am a beginner in cmake).</p>
",44,0,0,2,c++;cmake,2022-04-29 02:15:04,2022-04-29 02:15:04,2022-04-29 02:15:04,i have a c   project on windows that i am trying to build on windows using cmake  mingw   i need to link glew and glut libraries with my project  this is my cmakelists txt file at the top project level  this is my overall folder structure   gt  pacman  this is the parent folder     gt  build    gt  freeglut    gt  glew       gt  other cpp and h files    gt  cmakelists txt when i run cmake  g  mingw makefiles     in build folder i get the following output meaning that the libraries were found and linked  when i try to make the project in the build folder  it gives multiple errors  i am going to copy paste some of them below  can someone guide me  is there something i am doing wrong while linking  keeping in mind that i am a beginner in cmake  ,problems linking glew and glut with cmake
295,18977374,72047038,Software Serial Port through GPIO pins with Python in Raspberry Pi clone,"<p>I have a Python project running on a Raspberry Pi 3 B+ which features among other things a 9bit software serial port. For achieving this I am using the pigpio library with its bit bang functions for reading bytes and waveform generation for writing bytes. This setup performs excelent up to 19200 baud.</p>
<p>Now I have to migrate this project into other platform, and some of the candidates are OrangePi, BananaPi, Odroid and ASUS Tinker Box.</p>
<p>I neither find any similar libraries to the pigpio one for any of these platforms nor any other Python library that allows to do software serial through arbitrary GPIO pins. The pigpio library is tailored for the Raspberry Pi hardware and can't run on those other boards (of course I already tried). Also that library on the rpi requires running the pigpio daemon on the background, which allows tunning the GPIO refresh latency to a microsecond in order to achieve accurate timings for managing the serial port signals. I couldn't also find any analogous tool for the alternative platforms mentioned above.</p>
<p>My question is: Do you know any Python software serial library that could run on any of those platforms? If there is no one, do you know other alternative approach I could follow (even assuming a long development effort) in order to implement software serial through GPIO ports in those platforms?</p>
<p>Thank you.</p>
",224,0,0,5,python;raspberry-pi;serial-port;odroid;orange-pi,2022-04-28 19:14:05,2022-04-28 19:14:05,2022-04-28 19:14:05,i have a python project running on a raspberry pi  b  which features among other things a bit software serial port  for achieving this i am using the pigpio library with its bit bang functions for reading bytes and waveform generation for writing bytes  this setup performs excelent up to  baud  now i have to migrate this project into other platform  and some of the candidates are orangepi  bananapi  odroid and asus tinker box  i neither find any similar libraries to the pigpio one for any of these platforms nor any other python library that allows to do software serial through arbitrary gpio pins  the pigpio library is tailored for the raspberry pi hardware and can t run on those other boards  of course i already tried   also that library on the rpi requires running the pigpio daemon on the background  which allows tunning the gpio refresh latency to a microsecond in order to achieve accurate timings for managing the serial port signals  i couldn t also find any analogous tool for the alternative platforms mentioned above  my question is  do you know any python software serial library that could run on any of those platforms  if there is no one  do you know other alternative approach i could follow  even assuming a long development effort  in order to implement software serial through gpio ports in those platforms  thank you ,software serial port through gpio pins with python in raspberry pi clone
296,846100,7117214,Domdocument saveHTML() adding extra quotes and some other url encoded characters,"<p>I have been using PHP's Domdocument extension for finding image tags with no alt attribute or with empty alt attribute. Here is the html code which I am using for testing purposes:</p>

<pre><code>&lt;span style=""font-weight:bold;""&gt;Blender&lt;/span&gt; is an Open Source 3D modelling and animation software. 
This is a very popular software among hobbyists.&lt;i&gt;Blender&lt;/i&gt; has a vast list of features which include bones and meshing, textures, particle physics etc.
&lt;u&gt;Blender&lt;/u&gt; was originally a proprietary software which was eventually made opensource. 
Blender is known to be difficult to learn because its interface is very intimiding to a newbie. 
But on the other hand, &lt;a href=""http://www.blender.org""&gt;Blender&lt;/a&gt; is so much customizable that you can actually modify your workspace according to your personal preference. 
Also blender interface has been developed in the OpenGL graphics library, so blender looks all the same on all platforms whether you use Windows, Linux, BSD or even Mac. 
3D is a very interesting field to work with but 3D is somewhat tough to start with. You can &lt;a href=""http://www.google.com"""" target=""_blank""&gt;Google&lt;/a&gt; for numerous tutorials on Blender. 
There are quite some awesome websites dedicated to blender development, such as BlenderGuru.com. &lt;img src=""http://www.cochinsquare.com/wp-content/uploads/2010/08/Blender.jpg""&gt;
</code></pre>

<p>And here is the Domdocument code which I was using for searching the IMG tag and adding an alt attribute to it .</p>

<pre><code>$dom=new DOMDocument();
$dom-&gt;loadHTML($content);
$dom-&gt;formatOutput = true;
$imgs = $dom-&gt;getElementsByTagName(""img"");
foreach($imgs as $img){
 $alt = $img-&gt;getAttribute('alt');
 if ($alt == ''){
  $k_alt = $this-&gt;keyword;    
 }else{
  $k_alt = $alt;
 }
 $img-&gt;setAttribute( 'alt' , $k_alt );
}
$html_mod = preg_replace('/^&lt;!DOCTYPE.+?&gt;/', '', str_replace( array('&lt;html&gt;', '&lt;/html&gt;', '&lt;body&gt;', '&lt;/body&gt;'), array('', '', '', ''), $dom-&gt;saveHTML()));
return $html_mod;
</code></pre>

<p>And here is the html in return which I get.</p>

<pre><code>&lt;span style='""font-weight:bold;""'&gt;Blender&lt;/span&gt; is an Open Source 3D modelling and animation software. 
This is a very popular software among hobbyists.&lt;i&gt;Blender&lt;/i&gt; has a vast list of features which include bones and meshing, textures, particle physics etc.
&lt;u&gt;Blender&lt;/u&gt; was originally a proprietary software which was eventually made opensource. 
Blender is known to be difficult to learn because its interface is very intimiding to a newbie. 
But on the other hand, &lt;a href=""""http://www.blender.org""""&gt;Blender&lt;/a&gt; is so much customizable that you can actually modify your workspace according to your personal preference. 
Also blender interface has been developed in the OpenGL graphics library, so blender looks all the same on all platforms whether you use Windows, Linux, BSD or even Mac. 
3D is a very interesting field to work with but 3D is somewhat tough to start with. You can &lt;a href=""""http://www.google.com"""""" target='""_blank""'&gt;Google&lt;/a&gt; for numerous tutorials on Blender. 
There are quite some awesome websites dedicated to blender development, such as BlenderGuru.com. 
&lt;img src=""""http://www.cochinsquare.com/wp-content/uploads/2010/08/Blender.jpg"""" alt=""Blender""&gt;
</code></pre>

<p>Observe the extra quotations (Single as well as Double) in the img src and the anchor tags and in the style attribute of span.</p>

<p>Please help! I want the html to be returned intact with only the new alt attribute added.</p>

<p>Also I would like to mention that I am using PHP 5.3.2 with Suhosin Patch on Ubuntu 10.04</p>
",828,1,1,2,php;domdocument,2011-08-19 08:12:54,2011-08-19 08:12:54,2022-04-28 18:20:45,i have been using php s domdocument extension for finding image tags with no alt attribute or with empty alt attribute  here is the html code which i am using for testing purposes  and here is the domdocument code which i was using for searching the img tag and adding an alt attribute to it   and here is the html in return which i get  observe the extra quotations  single as well as double  in the img src and the anchor tags and in the style attribute of span  please help  i want the html to be returned intact with only the new alt attribute added  also i would like to mention that i am using php    with suhosin patch on ubuntu  ,domdocument savehtml   adding extra quotes and some other url encoded characters
297,4375983,72046163,What&#39;s the difference between prod/non-prod top-level folders and prod/non-prod app lifecycle folders in enterprise organization structure (on GCP),"<p>I am trying to organize an enterprise's organization via Terraform, by implementing good IaC practices. In <a href=""https://medium.com/@wynsen/gcp-folder-hierarchy-group-management-with-terraform-3a870cd5357e"" rel=""nofollow noreferrer"">this article</a> the author suggests an organization structure that will have the following top-level folders</p>
<blockquote>
<p>Top-level Folders</p>
<p>Consider a solution where the Top-level Folders are:</p>
<p>Sandpit</p>
<p>Non-Production</p>
<p>Production</p>
<p>Shared</p>
<p>Subsidiary</p>
</blockquote>
<p>But also leaf-level folders to contain larger or smaller apps that will also be defined with several folders for each environment (dev, prod, etc...)</p>
<blockquote>
<p>Leaf Folders</p>
<p>...</p>
<p>Large applications where multiple squads with different access
requirements are responsible for different components of the software
development life-cycle may warrant a Folder each for Development, SIT,
UAT, Staging &amp; Production. The name of these Folders could contain
both the application &amp; life-cycle.</p>
</blockquote>
<p>These distinctions appear in several other repos and ways to organize enterprise-level infrastructure.</p>
<p>Could you provide an explanation on what warrants such a distinction between top-level and leaf-level prod/non-prod folders? Is there a use-case where we use them simultaneously?</p>
",30,0,0,3,google-cloud-platform;terraform;organization,2022-04-28 18:09:56,2022-04-28 18:09:56,2022-04-28 18:09:56,i am trying to organize an enterprise s organization via terraform  by implementing good iac practices  in  the author suggests an organization structure that will have the following top level folders top level folders consider a solution where the top level folders are  sandpit non production production shared subsidiary but also leaf level folders to contain larger or smaller apps that will also be defined with several folders for each environment  dev  prod  etc     leaf folders     these distinctions appear in several other repos and ways to organize enterprise level infrastructure  could you provide an explanation on what warrants such a distinction between top level and leaf level prod non prod folders  is there a use case where we use them simultaneously ,what   s the difference between prod non prod top level folders and prod non prod app lifecycle folders in enterprise organization structure  on gcp 
298,14941907,72026090,How to add data in Django?,"<p>This is the <strong>Memo text</strong> where User can submit their Memo form. I need to <strong>add(update)</strong> new message this record via Update button in DJANGO.
by the way I used PK and FK db table.</p>
<p>How can I modify it?</p>
<p>Tks.</p>
<p><strong>Error Message :</strong></p>
<p><strong>IntegrityError at /addshowmemo/72/ (1048, &quot;Column 'software_id' cannot be null&quot;)</strong></p>
<blockquote>
<p>Request Method:    POST Request URL:/127.0.0.1/addshowmemo/72/
Django Version:   3.1.5 Exception Type:   IntegrityError Exception Value:
(1048, &quot;Column 'software_id' cannot be null&quot;) Exception
Location: d:\project\python\it\venv\lib\site-packages\django\db\backends\mysql\base.py,
line 78, in execute Python
Executable:   d:\project\python\it\venv\Scripts\python.exe Python
Version:  3.10.2 Python Path:  ['D:\project\python\it',
'c:\Users\tou52\.vscode\extensions\ms-python.python-2022.4.1\pythonFiles\lib\python\debugpy\_vendored\pydevd',
'C:\Users\tou52\AppData\Local\Programs\Python\Python310\python310.zip',
'C:\Users\tou52\AppData\Local\Programs\Python\Python310\DLLs',
'C:\Users\tou52\AppData\Local\Programs\Python\Python310\lib',
'C:\Users\tou52\AppData\Local\Programs\Python\Python310',
'd:\project\python\it\venv',
'd:\project\python\it\venv\lib\site-packages']</p>
</blockquote>
<p><strong>Models：</strong></p>
<pre><code>class Memo(models.Model):
notes = models.TextField()
software = models.ForeignKey(Software, on_delete=models.CASCADE)
timestamp = models.DateTimeField(default=timezone.now)

def __str__(self):
    return self.notes

class Software(models.Model):
STATUS_CHOICES = [
    (0, 'Planning'),
    (1, 'Development'),
    (2, 'Using'),
    (3, 'Obsolete')
]
name = models.CharField(max_length=100, verbose_name=&quot;SysName&quot;)
url = models.CharField(max_length=100, verbose_name=&quot;SysAdd&quot;)
status = models.PositiveIntegerField(default=0, choices=STATUS_CHOICES,  verbose_name=&quot;Status&quot;) 
company = models.ForeignKey(Company, on_delete=models.CASCADE,  verbose_name=&quot;Company&quot;)
team = models.ForeignKey(Team, on_delete=models.DO_NOTHING,  verbose_name=&quot;Team&quot;)
def __str__(self):
    return self.name
</code></pre>
<p><strong>Templates：</strong></p>
<pre><code>&lt;form method=&quot;POST&quot; name=&quot;myform&quot; action=&quot;.&quot; &gt;
{% csrf_token %}
&lt;table class=&quot;table table-striped&quot;&gt;
  &lt;tr&gt;
     &lt;td align=right&gt;Memo：&lt;/td&gt;
      &lt;td&gt;
            &lt;input type=text size=50 name=&quot;Cmemo&quot; value='{{Nmemo.notes}}'&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;tr&gt;
    &lt;td&gt;　&lt;/td&gt;
&lt;td&gt;
    &lt;input type=submit value=&quot;Confirm&quot; class=&quot;btn btn-primary&quot;&gt;||&lt;a href='/showall/' class=&quot;btn btn-warning&quot;&gt;Home&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
</code></pre>


<p><strong>views：</strong></p>
<pre><code>def add_showmemo(request,id=None,logmemo=None):
memos = Memo.objects.all()
if request.method==&quot;POST&quot;:
    Cmemo = request.POST.get('Cmemo')
    Nmemo = Memo(notes=Cmemo)
    Nmemo.save()     
    return redirect(&quot;/showdetail/&quot;)
return render(request, &quot;add_showmemo.html&quot;, locals())
</code></pre>
<p><strong>db database：</strong></p>
<p>Memo db</p>
<pre><code>id/notes/timestamp/software_id
 1/xxx/2022-01-02/32
 2/ooo/2022-01-03/31
 3/yyy/2022-01-04/40
 4/vvv/2022-01-05/1
 5/sss/2022-01-06/2
</code></pre>
<p>SoftWare db</p>
<pre><code>id/name/url/company_id/status/team_id
 1/watch/NA/9/1/8
 2/shoes/NA/10/2/8
 3/pen/NA/10/7/2/8
 4/apple/NA/7/2/9
 5/phone/NA/4/0/6
</code></pre>
",61,1,0,2,python;django,2022-04-27 12:03:13,2022-04-27 12:03:13,2022-04-28 08:51:11,how can i modify it  tks  error message   integrityerror at  addshowmemo       column  software_id  cannot be null   models  templates  views  db database  memo db software db,how to add data in django 
299,8327763,72035146,weird problem. adding 1 to 0 doesnt do anything,"<p>1Okay, i dont even know how to describe this problem but i will try my best. you can find all my code at the bottom</p>
<pre><code> const scores = { 0: 0, 1: 0, 2: 0, 3: 0, 4:0, 5:0, 6:0 }
 const [point, setPoint] = useState(scores)
</code></pre>
<p>so i setstate to an array, later on i am calling it with a button</p>
<pre><code> &lt;button onClick ={()=&gt; setPoint (point[selected] +1 )}&gt;Vote&lt;/button&gt;
 &lt;button onClick={()=&gt; setSelected(Math.floor(Math.random()* anecdotes.length ))}&gt;next anecdotes&lt;/button&gt;
 {scores[selected]}
</code></pre>
<p>at first it should the value at the [selected] to be at 0, but whenever i press on the vote button and add 1, it is still 0. i just wonder if anyone can help with this.</p>
<pre><code>import { useState } from 'react'

const App = () =&gt; {
  const anecdotes = [
    'If it hurts, do it more often',
    'Adding manpower to a late software project makes it later!',
    'The first 90 percent of the code accounts for the first 10 percent of the development time...The remaining 10 percent of the code accounts for the other 90 percent of the development time.',
    'Any fool can write code that a computer can understand. Good programmers write code that humans can understand.',
    'Premature optimization is the root of all evil.',
    'Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it.',
    'Programming without an extremely heavy use of console.log is same as if a doctor would refuse to use x-rays or blood tests when diagnosing patients'
  ]
   
  const [selected, setSelected] = useState(0) 
  const scores = { 0: 0, 1: 0, 2: 0, 3: 0, 4:0, 5:0, 6:0 }
  const [point, setPoint] = useState(scores)
  
  return (
    console.log (selected),
    console.log (point[selected]),
    &lt;div&gt;
      {anecdotes[selected]}
      &lt;br&gt;&lt;/br&gt;
      &lt;button onClick ={()=&gt; setPoint (point[selected] +1 )}&gt;Vote&lt;/button&gt;
      &lt;button onClick={()=&gt; setSelected(Math.floor(Math.random()* anecdotes.length ))}&gt;next anecdotes&lt;/button&gt;
      {point[selected]}

    &lt;/div&gt;
  )
}
/*onst Set = (...[points, selected]) =&gt; {
  points [selected] += 1;
  console.log(points [selected]);
&lt;h1&gt;{points}&lt;/h1&gt;
}*/

export default App
</code></pre>
",62,3,0,2,javascript;reactjs,2022-04-27 23:52:11,2022-04-27 23:52:11,2022-04-28 00:26:54,okay  i dont even know how to describe this problem but i will try my best  you can find all my code at the bottom so i setstate to an array  later on i am calling it with a button at first it should the value at the  selected  to be at   but whenever i press on the vote button and add   it is still   i just wonder if anyone can help with this ,weird problem  adding  to  doesnt do anything
300,18772661,71829311,"VSCode : mvbasic extension on editing Unidata code with MV marks in code, ie CHAR(253), CHAR(254)","<p>I have searched for a setting within the mvbasic extension within VSCode but I may have hit a dead end. I am new to using VSCode with the rocket mvbasic extension and still in the learning process, so please bear with me.</p>
<p>Our development for the most part has always been directly on the server using the editor within it to code and develop on a Unix/Aix platform with Unidata. Some of our code has array assignments with CHAR(253)/CHAR(254) characters within them. See the link to the image that shows how its done. Now I didn't do this code, the original software developer did this many many years ago and we just aren't going to go and change it all.</p>
<p><a href=""https://i.stack.imgur.com/YWOh5.png"" rel=""nofollow noreferrer"">How code looks on actual server</a></p>
<p>The issue is when pulling the code to edit in VSCode, the extension is changing it, and I uploaded it back and didn't pay attention and it was implemented in our production incorrectly, which created a few bugs.</p>
<p>ALIST=&quot;H�V�P�R�M�D&quot;
<a href=""https://i.stack.imgur.com/oBVcV.png"" rel=""nofollow noreferrer"">How code looks in VSCode</a></p>
<p><a href=""https://i.stack.imgur.com/SgBuP.png"" rel=""nofollow noreferrer"">How code looks after uploaded back to server from VSCode</a>
Easy to fix, no biggie, but now to my question.</p>
<p>Does anyone have this issue, or has a direction to point me into that maybe I need to create a setting to keep the characters in the correct ASCII format so that this doesn't happen again by mistake?</p>
",42,1,1,5,unix;ascii;vscode-extensions;mv;unidata,2022-04-11 17:09:29,2022-04-11 17:09:29,2022-04-27 10:17:51,i have searched for a setting within the mvbasic extension within vscode but i may have hit a dead end  i am new to using vscode with the rocket mvbasic extension and still in the learning process  so please bear with me  our development for the most part has always been directly on the server using the editor within it to code and develop on a unix aix platform with unidata  some of our code has array assignments with char   char   characters within them  see the link to the image that shows how its done  now i didn t do this code  the original software developer did this many many years ago and we just aren t going to go and change it all   the issue is when pulling the code to edit in vscode  the extension is changing it  and i uploaded it back and didn t pay attention and it was implemented in our production incorrectly  which created a few bugs  does anyone have this issue  or has a direction to point me into that maybe i need to create a setting to keep the characters in the correct ascii format so that this doesn t happen again by mistake ,vscode   mvbasic extension on editing unidata code with mv marks in code  ie char    char  
301,681671,72023873,Containerized multi-node Kubernetes Distro,"<p>I will be getting VMs at work for installing a Kubernetes cluster. It will be used by the development team; but we need to test the scaling too during development, so single node is not really an option.</p>
<p>I won't have rights to create or re-spawn the VMs from known images. So I need to be able to cleanup a cluster if it gets damaged beyond repair and do it without asking for a VM refresh.</p>
<p>To sandbox ordinary software I would generally use containers. I wanted to do the same for the Kubernetes installation.</p>
<p>I only found kind and k3d. But both are meant to simulate multi-node clusters while using a single node. Whereas I want to have a real multi-node solution that can run in docker or its alternatives.</p>
",27,0,0,4,docker;kubernetes;k3s;k3d,2022-04-27 08:54:34,2022-04-27 08:54:34,2022-04-27 08:54:34,i will be getting vms at work for installing a kubernetes cluster  it will be used by the development team  but we need to test the scaling too during development  so single node is not really an option  i won t have rights to create or re spawn the vms from known images  so i need to be able to cleanup a cluster if it gets damaged beyond repair and do it without asking for a vm refresh  to sandbox ordinary software i would generally use containers  i wanted to do the same for the kubernetes installation  i only found kind and kd  but both are meant to simulate multi node clusters while using a single node  whereas i want to have a real multi node solution that can run in docker or its alternatives ,containerized multi node kubernetes distro
302,18806213,71876491,Do I need this many blocks in my launch.json file?,"<p>I have had this launch.json file look this way for most of the time I have had my project. I am not entirely sure what the file's purpose is or what the specific lines do. I had a compile build fail last night saying that it couldn't find my main file &quot;Planner&quot; even though it was working fine and it broke after pushing my updates to GitHub via the GitHub Desktop program. Anyway, this got me wondering if I really need all of these very similar blocks in my launch.json file, or if I really should only have one. My thought is the others are old variations of where files were? I have worked on this project on several machines and pushed/pulled from GitHub a lot.</p>
<p>Edit:</p>
<p>From the comments I should provide more information. Apologies, the initial post was made at work when I only had GitHub code to reference, and not my IDE. I have a program I have been building in VSCode, who's main class is called &quot;Planner&quot;, file Planner.java. I have been working on this project for a little over six months and have been really teaching myself javaFX, as my AS degree in Computer Science really only covered Java concepts so they kept to the standard Java library. With that, I followed some tutorials and got JavaFX working in VSCode. Last night I made some updates to my program that ran fine. I then pushed it to GitHub, shut my PC down, and was going to be done. I turned back on the PC and went back in to make one last change I had thought of and get an error: &quot;Build failed, do you want to continue? [Source: Debugger for Java (Extension)]&quot;</p>
<p>I guess I am asking two things, tips on understanding the launch.json file,(do I need to write, what seems like the same thing, 5 times to have the code compile and run?) and ideas for what could be causing the error described. Apologies, this is my first time posting here, I use the site a lot by reading others issues and fixing mine, but no experience posting, please let me know if I am asking too broad a question, or not being clear. Details below:</p>
<p><strong>In the Terminal:</strong></p>
<p>Error: Could not find or load main class Planner</p>
<p>Caused by: java.lang.ClassNotFoundException: Planner</p>
<p><strong>In the &quot;Problems:&quot; section of VSCode:</strong></p>
<blockquote>
<p>Project 'SimplePlanner1_52208f3' has no explicit encoding set</p>
</blockquote>
<pre><code>[{
&quot;resource&quot;: &quot;/C:/Users/travi/AppData/Roaming/Code/User/workspaceStorage/fd9ee5418b12f7a629c4aeb2c52147e1/redhat.java/jdt_ws/SimplePlanner1_52208f3/&quot;,
&quot;owner&quot;: &quot;_generated_diagnostic_collection_name_#2&quot;,
&quot;code&quot;: &quot;0&quot;,
&quot;severity&quot;: 4,
&quot;message&quot;: &quot;Project 'SimplePlanner1_52208f3' has no explicit encoding set&quot;,
&quot;source&quot;: &quot;Java&quot;,
&quot;startLineNumber&quot;: 1,
&quot;startColumn&quot;: 1,
&quot;endLineNumber&quot;: 1,
&quot;endColumn&quot;: 1 }]
</code></pre>
<p><strong>launch.json file:</strong></p>
<pre><code>&quot;version&quot;: &quot;0.2.0&quot;,
&quot;configurations&quot;: [
    {
        &quot;type&quot;: &quot;java&quot;,
        &quot;name&quot;: &quot;Launch Planner&quot;,
        &quot;request&quot;: &quot;launch&quot;,
        &quot;vmArgs&quot;: &quot;--module-path \&quot;C:/Users/travi/Documents/Software Development/openjfx-17.0.1_windows-x64_bin-sdk/javafx-sdk-17.0.1/lib\&quot; --add-modules javafx.controls,javafx.fxml&quot;,
        &quot;mainClass&quot;: &quot;Planner&quot;,
        &quot;projectName&quot;: &quot;SimplePlanner1_52208f3&quot;
    },
    {
        &quot;type&quot;: &quot;java&quot;,
        &quot;name&quot;: &quot;Launch Planner&quot;,
        &quot;request&quot;: &quot;launch&quot;,
        &quot;vmArgs&quot;: &quot;--module-path \&quot;C:/Users/travi/Documents/Software Development/openjfx-17.0.1_windows-x64_bin-sdk/javafx-sdk-17.0.1/lib\&quot; --add-modules javafx.controls,javafx.fxml&quot;,
        &quot;mainClass&quot;: &quot;Planner&quot;,
        &quot;projectName&quot;: &quot;SimplePlanner1_cd0129b4&quot;
    },
    {
        &quot;type&quot;: &quot;java&quot;,
        &quot;name&quot;: &quot;Launch Planner&quot;,
        &quot;request&quot;: &quot;launch&quot;,
        &quot;vmArgs&quot;: &quot;--module-path \&quot;C:/Users/travi/Documents/Software Development/openjfx-17.0.1_windows-x64_bin-sdk/javafx-sdk-17.0.1/lib\&quot; --add-modules javafx.controls,javafx.fxml&quot;,
        &quot;mainClass&quot;: &quot;Planner&quot;,
        &quot;projectName&quot;: &quot;SimplePlanner_69fc3f9d&quot;
    },
    {
        &quot;type&quot;: &quot;java&quot;,
        &quot;name&quot;: &quot;Launch Current File&quot;,
        &quot;request&quot;: &quot;launch&quot;,
        &quot;vmArgs&quot;: &quot;--module-path \&quot;C:/Users/travi/Documents/Software Development/openjfx-17.0.1_windows-x64_bin-sdk/javafx-sdk-17.0.1/lib\&quot; --add-modules javafx.controls,javafx.fxml&quot;,
        &quot;mainClass&quot;: &quot;${file}&quot;
    },
    {
        &quot;type&quot;: &quot;java&quot;,
        &quot;name&quot;: &quot;Launch Planner&quot;,
        &quot;request&quot;: &quot;launch&quot;,
        &quot;mainClass&quot;: &quot;Planner&quot;,
        &quot;projectName&quot;: &quot;Engr290-12-5-21-planner-main_478f1ccb&quot;,
        &quot;vmArgs&quot;: &quot;--module-path \&quot;C:/Users/travi/Documents/Software Development/openjfx-17.0.1_windows-x64_bin-sdk/javafx-sdk-17.0.1/lib\&quot; --add-modules javafx.controls,javafx.fxml&quot;
    }
]
}
</code></pre>
<p><strong>Another Edit:</strong></p>
<p>I went in and tried to delete out the block that has the line referencing <strong>SimplePlanner1_52208f3</strong>, and run the code. When running the code and that isn't there, the compiler automatically adds back in the following block of code to my launch.json file. So maybe I am barking up the wrong tree and its a deeper issue?</p>
<pre><code>{
    &quot;type&quot;: &quot;java&quot;,
    &quot;name&quot;: &quot;Launch Planner&quot;,
    &quot;request&quot;: &quot;launch&quot;,
    &quot;mainClass&quot;: &quot;Planner&quot;,
    &quot;projectName&quot;: &quot;SimplePlanner1_52208f3&quot;
},
</code></pre>
",39,1,0,5,java;json;build;compiler-errors;launch,2022-04-14 22:03:17,2022-04-14 22:03:17,2022-04-27 04:12:05,i have had this launch json file look this way for most of the time i have had my project  i am not entirely sure what the file s purpose is or what the specific lines do  i had a compile build fail last night saying that it couldn t find my main file  planner  even though it was working fine and it broke after pushing my updates to github via the github desktop program  anyway  this got me wondering if i really need all of these very similar blocks in my launch json file  or if i really should only have one  my thought is the others are old variations of where files were  i have worked on this project on several machines and pushed pulled from github a lot  edit  from the comments i should provide more information  apologies  the initial post was made at work when i only had github code to reference  and not my ide  i have a program i have been building in vscode  who s main class is called  planner   file planner java  i have been working on this project for a little over six months and have been really teaching myself javafx  as my as degree in computer science really only covered java concepts so they kept to the standard java library  with that  i followed some tutorials and got javafx working in vscode  last night i made some updates to my program that ran fine  i then pushed it to github  shut my pc down  and was going to be done  i turned back on the pc and went back in to make one last change i had thought of and get an error   build failed  do you want to continue   source  debugger for java  extension    i guess i am asking two things  tips on understanding the launch json file  do i need to write  what seems like the same thing   times to have the code compile and run   and ideas for what could be causing the error described  apologies  this is my first time posting here  i use the site a lot by reading others issues and fixing mine  but no experience posting  please let me know if i am asking too broad a question  or not being clear  details below  in the terminal  error  could not find or load main class planner caused by  java lang classnotfoundexception  planner in the  problems   section of vscode  project  simpleplanner_f  has no explicit encoding set launch json file  another edit  i went in and tried to delete out the block that has the line referencing simpleplanner_f  and run the code  when running the code and that isn t there  the compiler automatically adds back in the following block of code to my launch json file  so maybe i am barking up the wrong tree and its a deeper issue ,do i need this many blocks in my launch json file 
303,1778275,72019850,Parentheses around a constant or around a cast expression involving a constant,"<p>From time to time I see this code:</p>
<pre><code>#define X1   (13)
#define X2   ((size_t)13)
</code></pre>
<p>As I understand, the (outer) <code>()</code> are redundant here. Is that correct?</p>
<hr />
<p>UPD: Some software development guidelines may require it.</p>
<p>For example:
MISRA C:2004, Rule 19.4 (required):</p>
<blockquote>
<p>C macros shall only expand to a braced initialiser, a constant, a <strong>parenthesised expression</strong>, a type qualifier, a storage class specifier, or a do-while-zero construct.</p>
</blockquote>
<p>However, MISRA C:2012 has:</p>
<pre><code>#define MY_NULL_2 ( void * ) 0
#define sqrt( x ) ( _BUILTIN_sqrt ( x ) )
</code></pre>
",75,2,1,2,c;parentheses,2022-04-26 22:57:50,2022-04-26 22:57:50,2022-04-27 02:02:07,from time to time i see this code  as i understand  the  outer     are redundant here  is that correct  upd  some software development guidelines may require it  c macros shall only expand to a braced initialiser  a constant  a parenthesised expression  a type qualifier  a storage class specifier  or a do while zero construct  however  misra c  has ,parentheses around a constant or around a cast expression involving a constant
304,18941314,72019217,"puppeteer can&#39;t get element, even element exist in page","<p>I try to upload file, i got unexpected result in this line, puppeteer unable get the element. in debug, the element exists before upload start. i switch different selector case. still null. my use case to get upload progress. the problem in percentageProgress variabel. whats the problem?</p>
<pre><code>const puppeteer = require('puppeteer');

const options = {
    product: 'chrome',
    headless: false, 
    defaultViewport: null, 
    ignoreDefaultArgs: [&quot;--enable-automation&quot;]
};

(async () =&gt; {
    const browser = await puppeteer.launch(options)
    const page = await browser.newPage()
    await page.setUserAgent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36')
    await page.goto('https://zippyshare.com/')
    const el = await page.$(&quot;input[type=file]&quot;)
    await el.uploadFile('F:/Software Development/project/streaming/public/video/download.mp4')

    const percentageProgress = await page.$('#o_1g1jilj6venv1lt216uh8jn7gga &gt; span.perc')

    if (percentageProgress != null) {
        await page.click('#share_button')

        await percentageProgress.evaluate(node =&gt; {
            while(true) {
                const status = node.textContent;
                if (status == '100%') break
            }
    
            console.log('Upload success')
        })
    }
})();
</code></pre>
",37,0,0,2,node.js;puppeteer,2022-04-26 22:02:03,2022-04-26 22:02:03,2022-04-26 22:02:03,i try to upload file  i got unexpected result in this line  puppeteer unable get the element  in debug  the element exists before upload start  i switch different selector case  still null  my use case to get upload progress  the problem in percentageprogress variabel  whats the problem ,puppeteer can   t get element  even element exist in page
305,18931737,72017489,Is there a way to calculate cosine similarity between documents sets in Python?,"<p>I'm trying to calculate cosine similarity between documents sets. I'm using this code and it works very well, but the problem is that it sorts the results in descending order. Is there a way to get the results according to the comparison order of the inserted documents? Or is there another way to do it?
Thanks in advance to everyone.</p>
<p>This is the code that I'm using:</p>
<pre><code>import pandas as pd
import numpy as np
from nltk.corpus import stopwords
import nltk

nltk.download('stopwords')
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics.pairwise import euclidean_distances


documents = ['Machine learning is the study of computer algorithms that improve automatically through experience.\
Machine learning algorithms build a mathematical model based on sample data, known as training data.\
The discipline of machine learning employs various approaches to teach computers to accomplish tasks \
where no fully satisfactory algorithm is available.',
'A software engineer creates programs based on logic for the computer to execute. A software engineer has to be more concerned\
about the correctness of the program in all the cases. Meanwhile, a data scientist is comfortable with uncertainty and variability.\
Developing a machine learning application is more iterative and explorative process than software engineering.',
             'Machine learning involves computers discovering how they can perform tasks without being explicitly programmed to do so. \
It involves computers learning from data provided so that they carry out certain tasks.',
             'Machine learning approaches are traditionally divided into three broad categories, depending on the nature of the &quot;signal&quot;\
or &quot;feedback&quot; available to the learning system: Supervised, Unsupervised and Reinforcement',
             'Software engineering is the systematic application of engineering approaches to the development of software.\
Software engineering is a computing discipline.',
'Machine learning is closely related to computational statistics, which focuses on making predictions using computers.\
The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning.']
documents_df = pd.DataFrame(documents, columns=['documents'])

# removing special characters and stop words from the text
stop_words_l = stopwords.words('english')
documents_df['documents_cleaned'] = documents_df.documents.apply(lambda x: &quot; &quot;.join(
    re.sub(r'[^a-zA-Z]', ' ', w).lower() for w in x.split() if
    re.sub(r'[^a-zA-Z]', ' ', w).lower() not in stop_words_l))

tfidfvectoriser = TfidfVectorizer()
tfidfvectoriser.fit(documents_df.documents_cleaned)
tfidf_vectors = tfidfvectoriser.transform(documents_df.documents_cleaned)

pairwise_similarities = np.dot(tfidf_vectors, tfidf_vectors.T).toarray()
pairwise_differences = euclidean_distances(tfidf_vectors)

def most_similar(doc_id, similarity_matrix, matrix):
    print(similarity_matrix)
    print(f'Document: {documents_df.iloc[doc_id][&quot;documents&quot;]}')
    print('\n')
    print('Similar Documents:')
    if matrix == 'Cosine Similarity':
        similar_ix = np.argsort(similarity_matrix[doc_id])[::-1]
    elif matrix == 'Euclidean Distance':
        similar_ix = np.argsort(similarity_matrix[doc_id])
    for ix in similar_ix:
        if ix == doc_id:
            continue
        print('\n')
        print(f'Document: {documents_df.iloc[ix][&quot;documents&quot;]}')
        print(f'{matrix} : {similarity_matrix[doc_id][ix]}')

most_similar(0, pairwise_similarities, 'Cosine Similarity')
most_similar(0, pairwise_differences, 'Euclidean Distance')

</code></pre>
<p>This is the output:</p>
<p>Document: Machine learning is the study of computer algorithms that improve automatically through experience.Machine learning algorithms build a mathematical model based on sample data, known as training data.The discipline of machine learning employs various approaches to teach computers to accomplish tasks where no fully satisfactory algorithm is available.</p>
<p>Similar Documents:</p>
<p>Document: Machine learning is closely related to computational statistics, which focuses on making predictions using computers.The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning.
Cosine Similarity : 0.22860560787391593</p>
<p>Document: Machine learning involves computers discovering how they can perform tasks without being explicitly programmed to do so. It involves computers learning from data provided so that they carry out certain tasks.
Cosine Similarity : 0.22581304743529423</p>
<p>Document: Machine learning approaches are traditionally divided into three broad categories, depending on the nature of the &quot;signal&quot;or &quot;feedback&quot; available to the learning system: Supervised, Unsupervised and Reinforcement
Cosine Similarity : 0.15314340308039842</p>
<p>Document: A software engineer creates programs based on logic for the computer to execute. A software engineer has to be more concernedabout the correctness of the program in all the cases. Meanwhile, a data scientist is comfortable with uncertainty and variability.Developing a machine learning application is more iterative and explorative process than software engineering.
Cosine Similarity : 0.12407396777398046</p>
<p>Document: Software engineering is the systematic application of engineering approaches to the development of software.Software engineering is a computing discipline.
Cosine Similarity : 0.04978528121489196</p>
",46,1,1,1,python,2022-04-26 19:31:45,2022-04-26 19:31:45,2022-04-26 20:08:35,this is the code that i m using  this is the output  document  machine learning is the study of computer algorithms that improve automatically through experience machine learning algorithms build a mathematical model based on sample data  known as training data the discipline of machine learning employs various approaches to teach computers to accomplish tasks where no fully satisfactory algorithm is available  similar documents ,is there a way to calculate cosine similarity between documents sets in python 
306,14753398,71891210,how can I use vcpkg to install sqlite3 and use in cmakelist.txt?,"<p>I use vcpkg to load sqlite3 for my C++ project.</p>
<h3>for vcpkg,</h3>
<p>I think I integrate it correctly:</p>
<pre><code>PS D:\tool\vcpkg\vcpkg&gt; .\vcpkg.exe integrate install
Applied user-wide integration for this vcpkg root.

All MSBuild C++ projects can now #include any installed libraries.
Linking will be handled automatically.
Installing new libraries will make them instantly available.

CMake projects should use: &quot;-DCMAKE_TOOLCHAIN_FILE=D:/tool/vcpkg/vcpkg/scripts/buildsystems/vcpkg.cmake&quot;
</code></pre>
<p>and I install sqlite3 for example:</p>
<pre><code>PS D:\tool\vcpkg\vcpkg&gt; vcpkg install sqlite3
Computing installation plan...
The following packages will be built and installed:
    sqlite3[core]:x86-windows -&gt; 3.37.2#1
Detecting compiler hash for triplet x86-windows...
-- Automatically setting HTTP(S)_PROXY environment variables to 127.0.0.1:7890
Restored 1 packages from C:\Users\shen\AppData\Local\vcpkg\archives in 168.6 ms. Use --debug to see more details.
Starting package 1/1: sqlite3:x86-windows
Installing package sqlite3[core]:x86-windows...
Elapsed time for package sqlite3:x86-windows: 33.18 ms

Total elapsed time: 5.525 s

The package sqlite3 provides CMake targets:

    find_package(unofficial-sqlite3 CONFIG REQUIRED)
    target_link_libraries(main PRIVATE unofficial::sqlite3::sqlite3)
</code></pre>
<p>about the architecture
my computer is intel core i5-9300H, and it is x64, windows.
but to be on the safe side, i installed all windows architeture version,like this:</p>
<pre><code>PS D:\tool\vcpkg\vcpkg&gt; vcpkg list
jsoncpp:x86-windows                                1.9.5            jsoncpp is an implementation of a JSON reader an...
sqlite3:x64-windows                                3.37.2#1         SQLite is a software library that implements a s...
sqlite3:x64-windows-static                         3.37.2#1         SQLite is a software library that implements a s...
sqlite3:x86-windows                                3.37.2#1         SQLite is a software library that implements a s...
sqlite3:x86-windows-static                         3.37.2#1         SQLite is a software library that implements a s...
vcpkg-cmake-config:x64-windows                     2022-02-06
vcpkg-cmake:x64-windows                            2022-04-07
</code></pre>
<h3>for C++ project, I tried by qtcreater(cmake), visual studio</h3>
<h4>1,qtcreator with CMAKE</h4>
<p>cmakelist.txt</p>
<pre><code>SET(DCMAKE_TOOLCHAIN_FILE &quot;D:/tool/vcpkg/vcpkg/scripts/buildsystems/vcpkg.cmake&quot;)
include(&quot;D:/tool/vcpkg/vcpkg/scripts/buildsystems/vcpkg.cmake&quot;)
if(DEFINED ENV{VCPKG_DEFAULT_TRIPLET} AND NOT DEFINED VCPKG_TARGET_TRIPLET)
    set(VCPKG_TARGET_TRIPLET &quot;$ENV{VCPKG_DEFAULT_TRIPLET}&quot; CACHE STRING &quot;&quot; FORCE)
endif()
...
find_package(unofficial-sqlite3 CONFIG REQUIRED)

</code></pre>
<p>and it told me:</p>
<pre><code>D:\tool\vcpkg\vcpkg\scripts\buildsystems\vcpkg.cmake:816: error: Could not find a package configuration file provided by &quot;unofficial-sqlite3&quot; with any of the following names: unofficial-sqlite3Config.cmake unofficial-sqlite3-config.cmake Add the installation prefix of &quot;unofficial-sqlite3&quot; to CMAKE_PREFIX_PATH or set &quot;unofficial-sqlite3_DIR&quot; to a directory containing one of the above files.  If &quot;unofficial-sqlite3&quot; provides a separate development package or SDK, be sure it has been installed. CMakeLists.txt:23 (find_package)
:-1: error: [Makefile:249: cmake_check_build_system] Error 1
</code></pre>
<p>my full <code>CMakeLists.txt</code> is:</p>
<pre><code>cmake_minimum_required(VERSION 3.5)

SET(CMAKE_TOOLCHAIN_FILE &quot;D:/tool/vcpkg/vcpkg/scripts/buildsystems/vcpkg.cmake&quot;)
include(&quot;D:/tool/vcpkg/vcpkg/scripts/buildsystems/vcpkg.cmake&quot;)
if(DEFINED ENV{VCPKG_DEFAULT_TRIPLET} AND NOT DEFINED VCPKG_TARGET_TRIPLET)
    set(VCPKG_TARGET_TRIPLET &quot;$ENV{VCPKG_DEFAULT_TRIPLET}&quot; CACHE STRING &quot;&quot; FORCE)
endif()

project(untitled VERSION 0.1 LANGUAGES CXX)

set(CMAKE_INCLUDE_CURRENT_DIR ON)

set(CMAKE_AUTOUIC ON)
set(CMAKE_AUTOMOC ON)
set(CMAKE_AUTORCC ON)

set(CMAKE_CXX_STANDARD 11)
set(CMAKE_CXX_STANDARD_REQUIRED ON)

find_package(QT NAMES Qt6 Qt5 COMPONENTS Widgets REQUIRED)
find_package(Qt${QT_VERSION_MAJOR} COMPONENTS Widgets REQUIRED)

find_package(unofficial-sqlite3 CONFIG REQUIRED)


set(PROJECT_SOURCES
        main.cpp
        mainwindow.cpp
        mainwindow.h
        mainwindow.ui
)

if(${QT_VERSION_MAJOR} GREATER_EQUAL 6)
    qt_add_executable(untitled
        MANUAL_FINALIZATION
        ${PROJECT_SOURCES}
    )
# Define target properties for Android with Qt 6 as:
#    set_property(TARGET untitled APPEND PROPERTY QT_ANDROID_PACKAGE_SOURCE_DIR
#                 ${CMAKE_CURRENT_SOURCE_DIR}/android)
# For more information, see https://doc.qt.io/qt-6/qt-add-executable.html#target-creation
else()
    if(ANDROID)
        add_library(untitled SHARED
            ${PROJECT_SOURCES}
        )
# Define properties for Android with Qt 5 after find_package() calls as:
#    set(ANDROID_PACKAGE_SOURCE_DIR &quot;${CMAKE_CURRENT_SOURCE_DIR}/android&quot;)
    else()
        add_executable(untitled
            ${PROJECT_SOURCES}
        )
    endif()
endif()

target_link_libraries(untitled PRIVATE Qt${QT_VERSION_MAJOR}::Widgets sqlite3)

set_target_properties(untitled PROPERTIES
    MACOSX_BUNDLE_GUI_IDENTIFIER my.example.com
    MACOSX_BUNDLE_BUNDLE_VERSION ${PROJECT_VERSION}
    MACOSX_BUNDLE_SHORT_VERSION_STRING ${PROJECT_VERSION_MAJOR}.${PROJECT_VERSION_MINOR}
)

if(QT_VERSION_MAJOR EQUAL 6)
    qt_finalize_executable(untitled)
endif()
</code></pre>
<p>most of above is generated by qtcreator</p>
<p>when I do those above, and stucked by these errors, I think, maybe it is caused by myqtcreator</p>
<p>so I tried with visual studio 2019</p>
<h4>visual studio 2019</h4>
<p>in cmakelist.txt i added those :</p>
<pre><code>SET(DCMAKE_TOOLCHAIN_FILE &quot;D:/tool/vcpkg/vcpkg/scripts/buildsystems/vcpkg.cmake&quot;)
include(&quot;D:/tool/vcpkg/vcpkg/scripts/buildsystems/vcpkg.cmake&quot;)

find_package(unofficial-sqlite3 CONFIG REQUIRED)
</code></pre>
<p>and it told me the same error:</p>
<pre><code>严重性 代码  说明  项目  文件  行   禁止显示状态
错误      CMake Error at D:/tool/vcpkg/vcpkg/scripts/buildsystems/vcpkg.cmake:816 (_find_package):
  Could not find a package configuration file provided by
  &quot;unofficial-sqlite3&quot; with any of the following names:

    unofficial-sqlite3Config.cmake
    unofficial-sqlite3-config.cmake

  Add the installation prefix of &quot;unofficial-sqlite3&quot; to CMAKE_PREFIX_PATH or
  set &quot;unofficial-sqlite3_DIR&quot; to a directory containing one of the above
  files.  If &quot;unofficial-sqlite3&quot; provides a separate development package or
  SDK, be sure it has been installed.       D:/tool/vcpkg/vcpkg/scripts/buildsystems/vcpkg.cmake    816 
</code></pre>
<p>anyone can told me, how can I use the sqlite3 correctly?</p>
<blockquote>
<p>about <code>CMAKE_TOOLCHAIN...</code> and 'DMAKE_TOOLCHAIN...`; any of them I have tried, and even both, but the result is the same.   QwQ</p>
</blockquote>
<blockquote>
<p>about remove <code>include(.../vcpkg.cmake)</code>; i have saw a blog,and it says we need to add this line. but i still try to delete it,and reconfigure, and then, I got the same error</p>
</blockquote>
<pre><code>D:\tool\vcpkg\vcpkg\scripts\buildsystems\vcpkg.cmake:816: error: Could not find a package configuration file provided by &quot;unofficial-sqlite3&quot; with any of the following names: unofficial-sqlite3Config.cmake unofficial-sqlite3-config.cmake Add the installation prefix of &quot;unofficial-sqlite3&quot; to CMAKE_PREFIX_PATH or set &quot;unofficial-sqlite3_DIR&quot; to a directory containing one of the above files.  If &quot;unofficial-sqlite3&quot; provides a separate development package or SDK, be sure it has been installed. CMakeLists.txt:23 (find_package)
</code></pre>
<p>and the error is linked to vcpkg.cmake:</p>
<pre><code>elseif(&quot;${z_vcpkg_find_package_lowercase_package_name}&quot; STREQUAL &quot;grpc&quot; AND EXISTS &quot;${_VCPKG_INSTALLED_DIR}/${VCPKG_TARGET_TRIPLET}/share/grpc&quot;)
        _find_package(gRPC ${z_vcpkg_find_package_ARGN})
    else()
        _find_package(&quot;${z_vcpkg_find_package_package_name}&quot; ${z_vcpkg_find_package_ARGN})             &lt;---- this line
    endif()
</code></pre>
",435,1,0,4,c++;sqlite;cmake;vcpkg,2022-04-16 07:55:53,2022-04-16 07:55:53,2022-04-26 13:26:41,i use vcpkg to load sqlite for my c   project  i think i integrate it correctly  and i install sqlite for example  cmakelist txt and it told me  my full cmakelists txt is  most of above is generated by qtcreator when i do those above  and stucked by these errors  i think  maybe it is caused by myqtcreator so i tried with visual studio  in cmakelist txt i added those   and it told me the same error  anyone can told me  how can i use the sqlite correctly  about cmake_toolchain    and  dmake_toolchain      any of them i have tried  and even both  but the result is the same    qwq about remove include     vcpkg cmake   i have saw a blog and it says we need to add this line  but i still try to delete it and reconfigure  and then  i got the same error and the error is linked to vcpkg cmake ,how can i use vcpkg to install sqlite and use in cmakelist txt 
307,18666740,72004609,Create function to returned the set of rows bases on the input parameter,"<p>I need to create a function where the course category (name) will be used as parameter, and it will return a set of trainings related to it and the number of attendees.</p>
<p>and I don't know where to start. I've done something like these, for the beginning:</p>
<pre><code>CREATE OR ALTER FUNCTION dbo.f_course_cat (@course_cat_name VARCHAR)  
RETURNS table
AS RETURN 
( SELECT
    CASE WHEN @course_cat_name = 'Business' THEN 
    (SELECT course_name, cc.course_category_id
        FROM dbo.course_category CC
        join dbo.course c on c.course_category_id = CC.course_category_id
        WHERE c.course_category_id = 2)
    END
FROM dbo.course_category CC
join dbo.course c on c.course_category_id = CC.course_category_id);
GO
</code></pre>
<p>However, I receive an error:</p>
<blockquote>
<p>Msg 116, Level 16, State 1, Procedure f_course_cat, Line 10 [Batch Start Line 261]<br />
Only one expression can be specified in the select list when the subquery is not introduced with EXISTS.</p>
</blockquote>
<p>I have 3 tables:</p>
<pre class=""lang-sql prettyprint-override""><code>SELECT * FROM course_category
</code></pre>
<pre class=""lang-none prettyprint-override""><code>course_category_id  course_category_name
2                    Business
1                    Development
3                    Finance &amp; Accounting
4                    IT &amp; Software
6                    Marketing
5                    Personal development
</code></pre>
<pre><code>SELECT * FROM course
</code></pre>
<pre class=""lang-none prettyprint-override""><code>course_id   course_name                               course_category_id    
1            Agile Kanban: Kanban for Software Development Teams    4   
2            Successful Negotiation: Master Your Negotiating Skill  5   
3            Customer Service: Soft Skills Fundamentals             5   
4            Git &amp; GitHub - The Practical Guide                     1   
5            React - The Complete Guide                             1   
6            Complete C# Masterclass                                1   
7            Learn Parallel Programming with C# and .NET            1   
8            OAuth 2.0 in Spring Boot Applications                  1   
9            Selenium WebDriver with Docker, Jenkins &amp; AWS          1   
10           Microsoft Power BI - A Complete Introduction           2   
11           Facebook Ads B2B: Advertising+ Facebook Ads for B2B    6   
12           Business Fundamentals: Marketing Strategy              6   
13           Finance for Non Finance Executives                     3   
14           The Complete Introduction To Accounting and Finance    3   
15           Finance 101: Financial Management &amp; DCF Fundamental    3   
16           Practical Finance                                      3   
</code></pre>
<pre class=""lang-sql prettyprint-override""><code>SELECT * FROM training_history
</code></pre>
<pre class=""lang-none prettyprint-override""><code>employee_id course_id   start_date  end_date    training_status_id
1               13      2020-11-17  NULL         2
2               5       2021-06-02  2021-09-03   3
4               7       2020-12-08  2021-06-25   3
3               9       2021-09-08  NULL         1
1               13      2020-11-17  NULL         2
2               5       2021-06-02  2021-09-03   3
4               7       2020-12-08  2021-06-25   3
3               9       2021-09-08  NULL         1
</code></pre>
",47,1,0,3,sql;sql-server;sql-server-2019,2022-04-25 22:13:29,2022-04-25 22:13:29,2022-04-25 23:22:49,i need to create a function where the course category  name  will be used as parameter  and it will return a set of trainings related to it and the number of attendees  and i don t know where to start  i ve done something like these  for the beginning  however  i receive an error  i have  tables ,create function to returned the set of rows bases on the input parameter
308,192936,3010507,Linux tool to send raw data to a TCP server,"<p>I am aware that this is not a direct 'development' question but I need this info to test a development project, so I think someone could've hit similar problem.</p>

<p>I will test a software that runs a TCP server and according to sent commands replies some answers. I will test the software and do not want to write code if it doesn't work well. So I want to send those commands and test drive the server software.</p>

<p>How can I achieve this with a Linux box?</p>
",91787,3,46,2,linux;tcp,2010-06-10 01:39:28,2010-06-10 01:39:28,2022-04-25 11:41:16,i am aware that this is not a direct  development  question but i need this info to test a development project  so i think someone could ve hit similar problem  i will test a software that runs a tcp server and according to sent commands replies some answers  i will test the software and do not want to write code if it doesn t work well  so i want to send those commands and test drive the server software  how can i achieve this with a linux box ,linux tool to send raw data to a tcp server
309,18902877,71993869,How to remove insane gap between my sections,"<p>there is a huge gap between my sections and I have no clue why i have tried adding padding in the form of #me { padding-bottom: 150px; } but i tried with different numbers and i see a difference when making the gap longer but when i try going negitive, it cant really seem to have an affect on whats actually going on.</p>
<p>here is my code for HTML</p>
<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-css lang-css prettyprint-override""><code>.container {
    width: 100%;
    height: 100%;
    background: #12182b;}

    .me-section {
    text-align: left;
    padding-left: 850px; 
    height: 100vh;
    margin-top: 320px;}

 
    .me-section h1 {
    color: #6dffe7;
    font-size: 20px;
    margin: 0px;}

    .about-section {
    text-align: left;
    padding-left: 850px; 
    height: 100vh;
    margin-top: 320px;}

    .about-section h1 {
    color: #6dffe7;
    font-size: 20px;
    padding-top: 150px;}</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code> &lt;div class=""container""&gt;
        &lt;img src=""logo.png"" class=""logo""&gt;

            &lt;div class=""header""&gt;
                &lt;nav class=""navbar""&gt;
                    &lt;ul&gt;
                        &lt;div class=""download-btn""&gt;
                            &lt;li&gt;&lt;a href=""#about"" class=""about-2""&gt;About&lt;/a&gt;&lt;/li&gt;
                            &lt;li&gt;&lt;a href=""#work"" class=""work-3""&gt;Work&lt;/a&gt;&lt;/li&gt;
                            &lt;li&gt;&lt;a href=""#contact"" class=""contact-4""&gt;Contact&lt;/a&gt;&lt;/li&gt;
                            &lt;li&gt;&lt;a href=""Alberto Aday Resume.docx"" class=""btn""&gt;Resume&lt;/a&gt;&lt;/li&gt;
                        &lt;/div&gt;
                    &lt;/ul&gt;
                &lt;/nav&gt;



                &lt;section id=""me""&gt;
                    &lt;div class=""me-section""&gt;
                        &lt;h1 class=""my-name-after""&gt;Hi, my name is&lt;/h1&gt;
                        &lt;h2 class=""header-name""&gt;Alberto Aday.&lt;/h2&gt;
                        &lt;h2 class=""header-rest""&gt;I build on the web.&lt;/h2&gt;
                        &lt;p&gt;I'm an aspiring software engineer. I like to build&lt;br&gt;websites. Back-end development is currently &lt;br&gt;progress.&lt;/p&gt;
                    &lt;/div&gt;
                &lt;/section&gt;



                &lt;section id=""about""&gt;
                    &lt;div class=""about-section""&gt;
                        &lt;h1&gt;About me.&lt;/h1&gt;
                    &lt;/div&gt;
                &lt;/section&gt;



                &lt;section id=""work""&gt;
                    &lt;div class=""work-section""&gt;
                        &lt;h1&gt;Work&lt;/h1&gt;
                    &lt;/div&gt;
               &lt;/section&gt;



                &lt;section id=""contact""&gt;
                    &lt;div class=""contact-section""&gt;
                        &lt;h1&gt;Contact&lt;/h1&gt;
                    &lt;/div&gt;
                &lt;/section&gt;



            &lt;/div&gt;

    </code></pre>
</div>
</div>
</p>
<p><a href=""https://i.stack.imgur.com/gfyXg.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/gfyXg.png"" alt=""example"" /></a></p>
",35,2,1,3,html;css;sections,2022-04-25 05:16:21,2022-04-25 05:16:21,2022-04-25 07:04:21,there is a huge gap between my sections and i have no clue why i have tried adding padding in the form of  me   padding bottom  px    but i tried with different numbers and i see a difference when making the gap longer but when i try going negitive  it cant really seem to have an affect on whats actually going on  here is my code for html ,how to remove insane gap between my sections
310,18228703,71978374,Twilio as a Firebase extention sometimes sends sms messages sometimes not send,"<p><img src=""https://i.stack.imgur.com/AuiY7.png"" alt=""event log"" />
<img src=""https://i.stack.imgur.com/1GBOE.png"" alt=""more detailed event log"" /></p>
<p>I'm developing an iOS app that uses firebase. What I want to do is to send one-time sms to users in case of password change or re-login in their accounts.</p>
<p>for this, I added Twilio to my project from the firebase console, followed the necessary instructions and was able to send the first test message to my own phone.</p>
<p>To do this, it is enough to add the Twilio extension as a firebase extension. I'm not tampering with my Xcode project.It is sufficient to add a document containing the &quot;to&quot; and &quot;body&quot; fields to the &quot;messages&quot; collection.</p>
<p>I upgraded my Twilio account as I needed to send sms to multiple numbers and after that the sms started to be very inconsistent. I don't get error in firebase console. On the Twilio console, it says sms was delivered in a section, and in the error section, I get the error &quot;Error - 11200 HTTP retrieval failure&quot;.</p>
<p>almost only one out of every 10 sms transactions reaches. and Twilio continues to charge my balance even for undelivered sms.
I'm not an expert in software development, but it just doesn't make sense that sending sms is this hard. (like reinventing the wheel). Where exactly is the problem? Is it in the Firebase extension? On the Twilio itself?</p>
<p>note: Twilio is not supported regionally, so there is a usa number starting with +1. and all messages will be forwarded for a different country.</p>
",98,0,0,1,twilio,2022-04-23 12:18:56,2022-04-23 12:18:56,2022-04-25 05:18:32,i m developing an ios app that uses firebase  what i want to do is to send one time sms to users in case of password change or re login in their accounts  for this  i added twilio to my project from the firebase console  followed the necessary instructions and was able to send the first test message to my own phone  to do this  it is enough to add the twilio extension as a firebase extension  i m not tampering with my xcode project it is sufficient to add a document containing the  to  and  body  fields to the  messages  collection  i upgraded my twilio account as i needed to send sms to multiple numbers and after that the sms started to be very inconsistent  i don t get error in firebase console  on the twilio console  it says sms was delivered in a section  and in the error section  i get the error  error    http retrieval failure   note  twilio is not supported regionally  so there is a usa number starting with    and all messages will be forwarded for a different country ,twilio as a firebase extention sometimes sends sms messages sometimes not send
311,507043,46991483,&quot;Windows Kits\10\Redist\ucrt\DLLs&quot; doesn&#39;t exist,"<p>I am trying to build a WebRTC library. It has a bunch of build python scripts one of which is trying to access </p>

<blockquote>
  <p>C:\Program Files (x86)\Windows Kits\10\Redist\ucrt\DLLs\x64</p>
</blockquote>

<p>And copy ucrt Dlls into build directory.It fails there because my <code>Redist</code> directory doesn't have ucrt folder. I tried to uninstall my Windows SDK 10 and reinstall it.But <code>Redist</code> is still empty. Based on <a href=""https://blogs.msdn.microsoft.com/vcblog/2015/03/03/introducing-the-universal-crt/"" rel=""nofollow noreferrer"">this doc</a> by Microsoft:</p>

<blockquote>
  <p>To obtain the binaries for app-local deployment, install the Windows
  Software Development Kit (SDK) for Windows 10.  The binaries will be
  installed to C:\Program Files (x86)\Windows Kits\10\Redist\ucrt.</p>
</blockquote>

<p>But it simply doesn't happen.I also tried to reinstall all the Windows tools and SDK via my VS2015 (Community) installer.</p>

<p>Did Microsoft deprecate the redistributable part of the installation?
How can I solve this?</p>

<p>I installed Windows SDK 10.0.16299.0 . My system is Windows 10 64bit.</p>
",1204,1,3,3,windows;visual-studio;winapi,2017-10-28 18:41:23,2017-10-28 18:41:23,2022-04-24 23:30:02,i am trying to build a webrtc library  it has a bunch of build python scripts one of which is trying to access  c  program files  x  windows kits  redist ucrt dlls x and copy ucrt dlls into build directory it fails there because my redist directory doesn t have ucrt folder  i tried to uninstall my windows sdk  and reinstall it but redist is still empty  based on  by microsoft  but it simply doesn t happen i also tried to reinstall all the windows tools and sdk via my vs  community  installer  i installed windows sdk       my system is windows  bit , windows kits  redist ucrt dlls  doesn   t exist
312,17612995,71953226,Get Hieararchical data as JSON from SQL Server,"<p>I have following table:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>Id</th>
<th>HieararchyId</th>
<th>Name</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>/</td>
<td>MHz</td>
</tr>
<tr>
<td>2</td>
<td>/1/</td>
<td>Finance</td>
</tr>
<tr>
<td>3</td>
<td>/1/</td>
<td>IT</td>
</tr>
<tr>
<td>4</td>
<td>/1/3/</td>
<td>Software Development</td>
</tr>
<tr>
<td>5</td>
<td>/1/3/</td>
<td>QA</td>
</tr>
<tr>
<td>6</td>
<td>/1/2/</td>
<td>Accountant</td>
</tr>
</tbody>
</table>
</div>
<p>and I want to get data for my <a href=""https://mui.com/material-ui/react-tree-view/"" rel=""nofollow noreferrer"">TreeView</a> like:</p>
<pre><code>[
{
  &quot;Id&quot;: 1,
  &quot;HierarchyId&quot;: &quot;/&quot;
  &quot;Name&quot;:&quot;MHz&quot;,
  &quot;Children&quot;:[
     {
        &quot;Id&quot;: 3,
        &quot;HierarchyId&quot;: &quot;/1/&quot;
        &quot;Name&quot;:&quot;IT&quot;,
        &quot;Children&quot;:[
           {
              &quot;Id&quot;: 4,
              &quot;HierarchyId&quot;: &quot;/1/3/&quot;
              &quot;Name&quot;:&quot;Software Development&quot;,
              &quot;Children&quot;:[]
           }
           {
              &quot;Id&quot;: 5,
              &quot;HierarchyId&quot;: &quot;/1/3/&quot;
              &quot;Name&quot;:&quot;QA&quot;,
              &quot;Children&quot;:[]
           }
        ]
     },
     {
        &quot;Id&quot;: 2,
        &quot;HierarchyId&quot;: &quot;/1/&quot;
        &quot;Name&quot;:&quot;Finance&quot;,
        &quot;Children&quot;:[
           {
              &quot;Id&quot;: 6,
              &quot;HierarchyId&quot;: &quot;/1/2/&quot;
              &quot;Name&quot;:&quot;Accountant&quot;,
              &quot;Children&quot;:[]
           }
        ]
     }
   ]
 }
]
</code></pre>
<p>I tried with this: <a href=""https://stackoverflow.com/q/38298659/17612995"">How to generate hierarchical JSON data</a></p>
<p>Got <strong>error</strong>: <a href=""https://stackoverflow.com/a/45230504/17612995"">No more lock classes available from transaction.</a></p>
<p>Or is it better creating recursive function and filling the <code>Tree</code> on <code>client side</code>?</p>
<p><strong>Update</strong></p>
<pre><code>CREATE FUNCTION dbo.GetJson (@departmentId hierarchyid)
RETURNS nvarchar(max)
AS BEGIN
RETURN (
    SELECT
      Id,
      HierarchyId,
      Name,
      children = JSON_QUERY(dbo.GetJson(HierarchyId))
    FROM Departments p
    WHERE p.HierarchyId.IsDescendantOf(@departmentId ) = 1
    FOR JSON PATH
);
END;
</code></pre>
",77,1,2,4,sql;json;sql-server;hierarchy,2022-04-21 13:52:11,2022-04-21 13:52:11,2022-04-24 03:03:56,i have following table  and i want to get data for my  like  i tried with this   got error   or is it better creating recursive function and filling the tree on client side  update,get hieararchical data as json from sql server
313,15903738,70063286,Flutter Unable to instantiate activity ComponentInfo Main Activity,"<p>I'm using vs code (to code) and android studio (to get virtual device).
I just merged and pulled the project I'm working on this morning, and first, have a very long time to wait to build my project. So i stopped all, uninstalled my app from my virtual device, then cleaned and run by &quot;flutter run&quot;. Now I have these errors:</p>
<pre><code>Using hardware rendering with device AOSP on IA Emulator. If you notice graphics artifacts, consider enabling software rendering with
&quot;--enable-software-rendering&quot;.
Launching lib\main.dart on AOSP on IA Emulator in debug mode...
Running Gradle task 'assembleDebug'...                              6,0s
√  Built build\app\outputs\flutter-apk\app-debug.apk.
E/AndroidRuntime(11190): FATAL EXCEPTION: main
E/AndroidRuntime(11190): Process: com.example.coming_soon, PID: 11190
E/AndroidRuntime(11190): java.lang.RuntimeException: Unable to instantiate activity ComponentInfo{com.example.coming_soon/com.example.coming_soon.MainActivity}: java.lang.ClassNotFoundException: Didn't find class &quot;com.example.coming_soon.MainActivity&quot; on path: DexPathList[[zip file &quot;/data/app/com.example.coming_soon-g9Xk6gs-AdO4Khd-H_dR3g==/base.apk&quot;],nativeLibraryDirectories=[/data/app/com.example.coming_soon-g9Xk6gs-AdO4Khd-H_dR3g==/lib/x86, /data/app/com.example.coming_soon-g9Xk6gs-AdO4Khd-H_dR3g==/base.apk!/lib/x86, /system/lib]]
E/AndroidRuntime(11190):        at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2843)
E/AndroidRuntime(11190):        at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3048)
E/AndroidRuntime(11190):        at android.app.servertransaction.LaunchActivityItem.execute(LaunchActivityItem.java:78)
E/AndroidRuntime(11190):        at android.app.servertransaction.TransactionExecutor.executeCallbacks(TransactionExecutor.java:108)
E/AndroidRuntime(11190):        at android.app.servertransaction.TransactionExecutor.execute(TransactionExecutor.java:68)
E/AndroidRuntime(11190):        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1808)
E/AndroidRuntime(11190):        at android.os.Handler.dispatchMessage(Handler.java:106)
E/AndroidRuntime(11190):        at android.os.Looper.loop(Looper.java:193)
E/AndroidRuntime(11190):        at android.app.ActivityThread.main(ActivityThread.java:6669)
E/AndroidRuntime(11190):        at java.lang.reflect.Method.invoke(Native Method)
E/AndroidRuntime(11190):        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:493)
E/AndroidRuntime(11190):        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:858)
E/AndroidRuntime(11190): Caused by: java.lang.ClassNotFoundException: Didn't find class &quot;com.example.coming_soon.MainActivity&quot; on path: DexPathList[[zip file &quot;/data/app/com.example.coming_soon-g9Xk6gs-AdO4Khd-H_dR3g==/base.apk&quot;],nativeLibraryDirectories=[/data/app/com.example.coming_soon-g9Xk6gs-AdO4Khd-H_dR3g==/lib/x86, /data/app/com.example.coming_soon-g9Xk6gs-AdO4Khd-H_dR3g==/base.apk!/lib/x86, /system/lib]]
E/AndroidRuntime(11190):        at dalvik.system.BaseDexClassLoader.findClass(BaseDexClassLoader.java:134)
E/AndroidRuntime(11190):        at java.lang.ClassLoader.loadClass(ClassLoader.java:379)
E/AndroidRuntime(11190):        at java.lang.ClassLoader.loadClass(ClassLoader.java:312)
E/AndroidRuntime(11190):        at android.app.AppComponentFactory.instantiateActivity(AppComponentFactory.java:69)
E/AndroidRuntime(11190):        at androidx.core.app.CoreComponentFactory.instantiateActivity(CoreComponentFactory.java:41)
E/AndroidRuntime(11190):        at android.app.Instrumentation.newActivity(Instrumentation.java:1215)
E/AndroidRuntime(11190):        at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2831)
E/AndroidRuntime(11190):        ... 11 more
</code></pre>
<p>Here is my flutter doctor -v</p>
<pre><code>
[√] Flutter (Channel stable, 2.5.3, on Microsoft Windows [version 10.0.19043.1348], locale fr-FR)
    • Flutter version 2.5.3 at C:\Users\Johanne\Development\sdks\flutter
    • Upstream repository https://github.com/flutter/flutter.git
    • Framework revision 18116933e7 (5 weeks ago), 2021-10-15 10:46:35 -0700
    • Engine revision d3ea636dc5
    • Dart version 2.14.4

[√] Android toolchain - develop for Android devices (Android SDK version 31.0.0)
    • Android SDK at C:\Users\Johanne\AppData\Local\Android\sdk
    • Platform android-31, build-tools 31.0.0
    • Java binary at: C:\Program Files\Android\Android Studio\jre\bin\java
    • Java version OpenJDK Runtime Environment (build 11.0.10+0-b96-7249189)
    • All Android licenses accepted.

[√] Chrome - develop for the web
    • Chrome at C:\Program Files\Google\Chrome\Application\chrome.exe

[√] Android Studio (version 2020.3)
    • Android Studio at C:\Program Files\Android\Android Studio
    • Flutter plugin can be installed from:
       https://plugins.jetbrains.com/plugin/9212-flutter
    • Dart plugin can be installed from:
       https://plugins.jetbrains.com/plugin/6351-dart
    • Java version OpenJDK Runtime Environment (build 11.0.10+0-b96-7249189)

[√] VS Code (version 1.62.2)
    • VS Code at C:\Users\Johanne\AppData\Local\Programs\Microsoft VS Code
    • Flutter extension version 3.28.0

[√] Connected device (3 available)
    • AOSP on IA Emulator (mobile) • emulator-5556 • android-x86    • Android 9 (API 28) (emulator)
    • Chrome (web)                 • chrome        • web-javascript • Google Chrome 95.0.4638.69
    • Edge (web)                   • edge          • web-javascript • Microsoft Edge 95.0.1020.44

• No issues found!

</code></pre>
<p>Here is my android.manifest :</p>
<pre><code>&lt;manifest xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot;
    package=&quot;com.example.coming_soon&quot;&gt;
    &lt;uses-permission android:name=&quot;android.permission.READ_CALENDAR&quot; /&gt;
    &lt;uses-permission android:name=&quot;android.permission.WRITE_CALENDAR&quot; /&gt;
    &lt;uses-permission android:name=&quot;android.permission.VIBRATE&quot; /&gt;   
&lt;application
        android:label=&quot;coming_soon&quot;
        android:icon=&quot;@mipmap/ic_launcher&quot;&gt;
        &lt;activity
            android:name=&quot;.MainActivity&quot;
            android:launchMode=&quot;singleTop&quot;
            android:theme=&quot;@style/LaunchTheme&quot;
            android:configChanges=&quot;orientation|keyboardHidden|keyboard|screenSize|smallestScreenSize|locale|layoutDirection|fontScale|screenLayout|density|uiMode&quot;
            android:hardwareAccelerated=&quot;true&quot;
            android:windowSoftInputMode=&quot;adjustResize&quot;&gt;
            &lt;!-- Specifies an Android theme to apply to this Activity as soon as
                 the Android process has started. This theme is visible to the user
                 while the Flutter UI initializes. After that, this theme continues
                 to determine the Window background behind the Flutter UI. --&gt;
            &lt;meta-data
              android:name=&quot;io.flutter.embedding.android.NormalTheme&quot;
              android:resource=&quot;@style/NormalTheme&quot;
              /&gt;
            &lt;!-- Displays an Android View that continues showing the launch screen
                 Drawable until Flutter paints its first frame, then this splash
                 screen fades out. A splash screen is useful to avoid any visual
                 gap between the end of Android's launch screen and the painting of
                 Flutter's first frame. --&gt;
            &lt;meta-data
              android:name=&quot;io.flutter.embedding.android.SplashScreenDrawable&quot;
              android:resource=&quot;@drawable/launch_background&quot;
              /&gt;
            &lt;intent-filter&gt;
                &lt;action android:name=&quot;android.intent.action.MAIN&quot;/&gt;
                &lt;category android:name=&quot;android.intent.category.LAUNCHER&quot;/&gt;
            &lt;/intent-filter&gt;
        &lt;/activity&gt;
        &lt;!-- Don't delete the meta-data below.
             This is used by the Flutter tool to generate GeneratedPluginRegistrant.java --&gt;
        &lt;meta-data
            android:name=&quot;flutterEmbedding&quot;
            android:value=&quot;2&quot; /&gt;
    &lt;/application&gt;
&lt;/manifest&gt;

</code></pre>
<p>I already searched and found similar issues, but I wasn't able to solve my problem.
I tried to create a MainActivity.java file, but got new errors, so I deleted it.
Did I miss something?</p>
",463,2,1,5,java;android;flutter;visual-studio-code;android-activity,2021-11-22 11:10:03,2021-11-22 11:10:03,2022-04-23 20:38:30,here is my flutter doctor  v here is my android manifest  ,flutter unable to instantiate activity componentinfo main activity
314,9180446,71940237,Unable to run npm install in a gatsby project,"<p>I'm working on a project where I'm unable to run <code>npm install</code> as I'm getting the following error.</p>
<pre><code>npm WARN deprecated axios@0.18.1: Critical security vulnerability fixed in v0.21.1. For more information, see https://github.com/axios/axios/pull/3410
npm WARN deprecated gatsby-image@2.11.0: gatsby-image is now gatsby-plugin-image: https://npm.im/gatsby-plugin-image. This package will no longer receive updates.
npm WARN deprecated @hapi/joi@15.1.1: Switch to 'npm install joi'
npm WARN deprecated babel-eslint@10.1.0: babel-eslint is now @babel/eslint-parser. This package will no longer receive updates.
npm WARN deprecated eslint-loader@2.2.1: This loader has been deprecated. Please use eslint-webpack-plugin
npm WARN deprecated uuid@3.4.0: Please upgrade  to version 7 or higher.  Older versions may use Math.random() in certain circumstances, which is known to be problematic.  See https://v8.dev/blog/math-random for details.
npm WARN deprecated request@2.88.2: request has been deprecated, see https://github.com/request/request/issues/3142
npm WARN deprecated @hapi/hoek@8.5.1: This version has been deprecated and is no longer supported or maintained
npm WARN deprecated @hapi/bourne@1.3.2: This version has been deprecated and is no longer supported or maintained
npm WARN deprecated @hapi/address@2.1.4: Moved to 'npm install @sideway/address'
npm WARN deprecated @hapi/topo@3.1.6: This version has been deprecated and is no longer supported or maintained
npm WARN deprecated gatsby-recipes@0.9.3: gatsby-recipes has been removed from gatsby/gatsby-cli &gt;=4.5.0. Update to gatsby@latest/gatsby-cli@latest to use versions without gatsby-recipes. This package will no longer receive updates.
npm WARN deprecated async-cache@1.1.0: No longer maintained. Use [lru-cache](http://npm.im/lru-cache) version 7.6 or higher, and provide an asynchronous `fetchMethod` option.
npm WARN deprecated chokidar@2.1.8: Chokidar 2 does not receive security updates since 2019. Upgrade to chokidar 3 with 15x fewer dependencies
npm WARN deprecated querystring@0.2.1: The querystring API is considered Legacy. new code should use the URLSearchParams API instead.
npm WARN deprecated har-validator@5.1.5: this library is no longer supported
npm WARN deprecated joi@11.4.0: This version has been deprecated in accordance with the hapi support policy (hapi.im/support). Please upgrade to the latest version to get the best features, bug fixes, and security patches. If you are unable to upgrade at this time, paid support is available for older versions (hapi.im/commercial).
npm WARN deprecated fsevents@1.2.13: fsevents 1 will break on node v14+ and could be using insecure binaries. Upgrade to fsevents 2.
npm WARN deprecated core-js@2.6.12: core-js@&lt;3 is no longer maintained and not recommended for usage due to the number of issues. Please, upgrade your dependencies to the actual version of core-js@3.
npm WARN deprecated hoek@4.2.1: This version has been deprecated in accordance with the hapi support policy (hapi.im/support). Please upgrade to the latest version to get the best features, bug fixes, and security patches. If you are unable to upgrade at this time, paid support is available for older versions (hapi.im/commercial).
npm WARN deprecated topo@2.0.2: This version has been deprecated in accordance with the hapi support policy (hapi.im/support). Please upgrade to the latest version to get the best features, bug fixes, and security patches. If you are unable to upgrade at this time, paid support is available for older versions (hapi.im/commercial).
npm WARN deprecated urix@0.1.0: Please see https://github.com/lydell/urix#deprecated
npm WARN deprecated subscriptions-transport-ws@0.9.19: The `subscriptions-transport-ws` package is no longer maintained. We recommend you use `graphql-ws` instead. For help migrating Apollo software to `graphql-ws`, see https://www.apollographql.com/docs/apollo-server/data/subscriptions/#switching-from-subscriptions-transport-ws    For general help using `graphql-ws`, see https://github.com/enisdenjo/graphql-ws/blob/master/README.md
npm WARN deprecated resolve-url@0.2.1: https://github.com/lydell/resolve-url#deprecated
npm WARN deprecated svgo@1.3.2: This SVGO version is no longer supported. Upgrade to v2.x.x.

&gt; fsevents@1.2.13 install /Users/b_marauder/Downloads/24digital-development/node_modules/watchpack-chokidar2/node_modules/fsevents
&gt; node install.js

  SOLINK_MODULE(target) Release/.node
  CXX(target) Release/obj.target/fse/fsevents.o
  SOLINK_MODULE(target) Release/fse.node

&gt; fsevents@1.2.13 install /Users/b_marauder/Downloads/24digital-development/node_modules/webpack-dev-server/node_modules/fsevents
&gt; node install.js

  SOLINK_MODULE(target) Release/.node
  CXX(target) Release/obj.target/fse/fsevents.o
  SOLINK_MODULE(target) Release/fse.node

&gt; sharp@0.27.2 install /Users/b_marauder/Downloads/24digital-development/node_modules/sharp
&gt; (node install/libvips &amp;&amp; node install/dll-copy &amp;&amp; prebuild-install) || (node-gyp rebuild &amp;&amp; node install/dll-copy)

info sharp Downloading https://github.com/lovell/sharp-libvips/releases/download/v8.10.5/libvips-8.10.5-darwin-arm64v8.tar.br
ERR! sharp Prebuilt libvips 8.10.5 binaries are not yet available for darwin-arm64v8
info sharp Attempting to build from source via node-gyp but this may fail due to the above error
info sharp Please see https://sharp.pixelplumbing.com/install for required dependencies
  CC(target) Release/obj.target/nothing/../node-addon-api/nothing.o
  LIBTOOL-STATIC Release/nothing.a
env: python: No such file or directory
make: *** [Release/nothing.a] Error 127
gyp ERR! build error 
gyp ERR! stack Error: `make` failed with exit code: 2
gyp ERR! stack     at ChildProcess.onExit (/Users/b_marauder/.nvm/versions/node/v14.19.1/lib/node_modules/npm/node_modules/node-gyp/lib/build.js:194:23)
gyp ERR! stack     at ChildProcess.emit (events.js:400:28)
gyp ERR! stack     at Process.ChildProcess._handle.onexit (internal/child_process.js:282:12)
gyp ERR! System Darwin 21.4.0
gyp ERR! command &quot;/Users/b_marauder/.nvm/versions/node/v14.19.1/bin/node&quot; &quot;/Users/b_marauder/.nvm/versions/node/v14.19.1/lib/node_modules/npm/node_modules/node-gyp/bin/node-gyp.js&quot; &quot;rebuild&quot;
gyp ERR! cwd /Users/b_marauder/Downloads/24digital-development/node_modules/sharp
gyp ERR! node -v v14.19.1
gyp ERR! node-gyp -v v5.1.0
gyp ERR! not ok 
npm WARN gatsby-transformer-sharp@2.12.1 requires a peer of gatsby-plugin-sharp@^2.0.0-beta.3 but none is installed. You must install peer dependencies yourself.
npm WARN tsutils@3.21.0 requires a peer of typescript@&gt;=2.8.0 || &gt;= 3.2.0-dev || &gt;= 3.3.0-dev || &gt;= 3.4.0-dev || &gt;= 3.5.0-dev || &gt;= 3.6.0-dev || &gt;= 3.6.0-beta || &gt;= 3.7.0-dev || &gt;= 3.7.0-beta but none is installed. You must install peer dependencies yourself.
npm WARN ts-node@9.1.1 requires a peer of typescript@&gt;=2.7 but none is installed. You must install peer dependencies yourself.

npm ERR! code ELIFECYCLE
npm ERR! errno 1
npm ERR! sharp@0.27.2 install: `(node install/libvips &amp;&amp; node install/dll-copy &amp;&amp; prebuild-install) || (node-gyp rebuild &amp;&amp; node install/dll-copy)`
npm ERR! Exit status 1
npm ERR! 
npm ERR! Failed at the sharp@0.27.2 install script.
npm ERR! This is probably not a problem with npm. There is likely additional logging output above.

npm ERR! A complete log of this run can be found in:
npm ERR!     /Users/b_marauder/.npm/_logs/2022-04-20T12_22_46_264Z-debug.log
</code></pre>
<p>My node version is 14.19.1. Not sure how can I resolve this.</p>
<p>Any help would be great. Thanks!</p>
",543,1,0,5,node.js;macos;npm;npm-install;sharp,2022-04-20 16:06:10,2022-04-20 16:06:10,2022-04-23 17:16:05,i m working on a project where i m unable to run npm install as i m getting the following error  my node version is     not sure how can i resolve this  any help would be great  thanks ,unable to run npm install in a gatsby project
315,4390189,71978926,Airflow tasks stucked in queue v2.1.4,"<p>I have made some good experiences with Airflow in the past, unfortunately only as a user and I was not ressponsible for the setup. Now I want to setup Airflow on my own but I am really struggeling with it because tasks are stucked in the queue after a short period of time.</p>
<p><img src=""https://user-images.githubusercontent.com/27021858/164890739-9473d123-1378-46d3-9238-8a05fca5dfc1.png"" alt=""Bildschirmfoto vom 2022-04-23 12-00-35"" />
<img src=""https://user-images.githubusercontent.com/27021858/164890741-ebc00dc2-4d3c-4c1e-9940-69e9c351d8d1.png"" alt=""Bildschirmfoto vom 2022-04-23 12-00-15"" /></p>
<p>As you can see I am using DockerOperator to run tasks in Docker containers.</p>
<p>This is my Dockerfile:</p>
<pre><code>FROM apache/airflow:2.1.4

RUN pip install --no-cache-dir apache-airflow-providers-docker==2.5.0 boto3==1.21.45 apache-airflow-providers-amazon==3.0.0
</code></pre>
<p>And here is my docker-compose file:</p>
<pre><code># Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# &quot;License&quot;); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#

# Basic Airflow cluster configuration for CeleryExecutor with Redis and PostgreSQL.
#
# WARNING: This configuration is for local development. Do not use it in a production deployment.
#
# This configuration supports basic configuration using environment variables or an .env file
# The following variables are supported:
#
# AIRFLOW_IMAGE_NAME           - Docker image name used to run Airflow.
#                                Default: apache/airflow:master-python3.8
# AIRFLOW_UID                  - User ID in Airflow containers
#                                Default: 50000
# AIRFLOW_GID                  - Group ID in Airflow containers
#                                Default: 50000
#
# Those configurations are useful mostly in case of standalone testing/running Airflow in test/try-out mode
#
# _AIRFLOW_WWW_USER_USERNAME   - Username for the administrator account (if requested).
#                                Default: airflow
# _AIRFLOW_WWW_USER_PASSWORD   - Password for the administrator account (if requested).
#                                Default: airflow
# _PIP_ADDITIONAL_REQUIREMENTS - Additional PIP requirements to add when starting all containers.
#                                Default: ''
#
# Feel free to modify this file to suit your needs.
---
version: '3'
x-airflow-common:
  &amp;airflow-common
  image: airflow_image:latest
  environment:
    &amp;airflow-common-env
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
    AIRFLOW__CORE__FERNET_KEY: ''
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__CORE__ENABLE_XCOM_PICKLING: 'true'
    AIRFLOW__API__AUTH_BACKEND: 'airflow.api.auth.backend.basic_auth'
    AIRFLOW__SCHEDULER__MIN_FILE_PROCESS_INTERVAL: 60
    _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}
    SATELLITE_ARCHIVE_MOUNT: ${SATELLITE_ARCHIVE_MOUNT}
    NWP_ARCHIVE_MOUNT: ${NWP_ARCHIVE_MOUNT}
    ECCODES_DEFINITION_PATH: ${ECCODES_DEFINITION_PATH}
    AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION}

  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
    - /var/run/docker.sock:/var/run/docker.sock
  user: &quot;${AIRFLOW_UID:-50000}:${AIRFLOW_GID:-50000}&quot;
  depends_on:
    redis:
      condition: service_healthy
    postgres:
      condition: service_healthy

services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: [&quot;CMD&quot;, &quot;pg_isready&quot;, &quot;-U&quot;, &quot;airflow&quot;]
      interval: 5s
      retries: 5
    restart: always

  redis:
    image: redis:latest
    ports:
      - 6379:6379
    healthcheck:
      test: [&quot;CMD&quot;, &quot;redis-cli&quot;, &quot;ping&quot;]
      interval: 5s
      timeout: 30s
      retries: 50
    restart: always

  airflow-webserver:
    &lt;&lt;: *airflow-common
    command: webserver
    ports:
      - 8080:8080
    healthcheck:
      test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;--fail&quot;, &quot;http://localhost:8080/health&quot;]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always

  airflow-scheduler:
    &lt;&lt;: *airflow-common
    command: scheduler
    healthcheck:
      test: [&quot;CMD-SHELL&quot;, 'airflow jobs check --job-type SchedulerJob --hostname &quot;$${HOSTNAME}&quot;']
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always

  airflow-worker:
    &lt;&lt;: *airflow-common
    command: celery worker
    healthcheck:
      test: [&quot;CMD-SHELL&quot;, 'celery --app airflow.executors.celery_executor.app inspect ping -d &quot;celery@$${HOSTNAME}&quot;']
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always

  airflow-init:
    &lt;&lt;: *airflow-common
    command: version
    environment:
      &lt;&lt;: *airflow-common-env
      _AIRFLOW_DB_UPGRADE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}

  flower:
    &lt;&lt;: *airflow-common
    command: celery flower
    ports:
      - 5555:5555
    healthcheck:
      test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;--fail&quot;, &quot;http://localhost:5555/&quot;]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always

volumes:
  postgres-db-volume:

</code></pre>
<p>I hope anyone of you is able to help me. Using another task scheduler, all tasks run fine, but the task scheduler does not have features like retries with persisting parameters this is why I want to move to Airflow.</p>
<p>Thanks in advance</p>
<p>PS: As a side effect, the tasks run slower in Airflow. Maybe some of you know why?</p>
",67,0,0,3,docker;airflow;airflow-scheduler,2022-04-23 13:43:00,2022-04-23 13:43:00,2022-04-23 13:43:00,i have made some good experiences with airflow in the past  unfortunately only as a user and i was not ressponsible for the setup  now i want to setup airflow on my own but i am really struggeling with it because tasks are stucked in the queue after a short period of time  as you can see i am using dockeroperator to run tasks in docker containers  this is my dockerfile  and here is my docker compose file  i hope anyone of you is able to help me  using another task scheduler  all tasks run fine  but the task scheduler does not have features like retries with persisting parameters this is why i want to move to airflow  thanks in advance ps  as a side effect  the tasks run slower in airflow  maybe some of you know why ,airflow tasks stucked in queue v  
316,17612995,71977786,Create user defined function for Hierarchical data returning as JSON,"<p>This is <a href=""https://stackoverflow.com/questions/71953226/get-hieararchical-data-as-json-from-sql-server"">a part of this question </a>. I have <code>Departments</code> table which uses <a href=""https://docs.microsoft.com/en-us/sql/t-sql/data-types/hierarchyid-data-type-method-reference?view=sql-server-ver15#:%7E:text=Use%20hierarchyid%20to%20represent%20position,is%20reflected%20in%20the%20values."" rel=""nofollow noreferrer""><code>HierarchyId</code></a> to store hierarchical data.</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>Id</th>
<th>HieararchyId</th>
<th>Name</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>/</td>
<td>MHz</td>
</tr>
<tr>
<td>2</td>
<td>/2/</td>
<td>Finance</td>
</tr>
<tr>
<td>3</td>
<td>/3/</td>
<td>IT</td>
</tr>
<tr>
<td>4</td>
<td>/3/4/</td>
<td>Software Development</td>
</tr>
<tr>
<td>5</td>
<td>/3/5/</td>
<td>QA</td>
</tr>
<tr>
<td>6</td>
<td>/2/6/</td>
<td>Accountant</td>
</tr>
</tbody>
</table>
</div>
<p>I want to get this table as <code>JSON</code> for my <a href=""https://mui.com/material-ui/react-tree-view/"" rel=""nofollow noreferrer"">TreeView</a> on front side.</p>
<p>What I did:</p>
<pre><code>CREATE FUNCTION dbo.GetDepartmentAsJson
    (@departmentId hierarchyid, 
     @IsRoot int)
RETURNS nvarchar(max)
AS
BEGIN
    DECLARE @Json NVARCHAR(MAX) = '{}',
            @Id int,
            @Name varchar(50),
            @Children NVARCHAR(MAX) = '{}',
            @Hierar Hierarchyid

    SET @Json = (SELECT 
                     t.Id, t.HierarchyId, t.Name,
                     children = JSON_QUERY(dbo.GetDepartmentAsJson(t.HierarchyId, 2))
                 FROM Departments t
                 WHERE t.HierarchyId &lt;&gt; @departmentId
                   AND t.HierarchyId.IsDescendantOf(@departmentId) = 1
                 FOR JSON PATH);

    IF (@IsRoot = 1) 
    BEGIN
        SELECT
            @Id = t.Id,
            @Hierar = t.HierarchyId,
            @Name = t.Name
        FROM 
            Departments t
        WHERE 
            t.HierarchyId = @departmentId;

        SET @Json = 
        '{&quot;Id&quot;:&quot;' + CONVERT(varchar(7), @Id) +
        '&quot;,&quot;HierarchyId&quot;:&quot;' + @Hierar.ToString() + 
        '&quot;,&quot;Name&quot;:&quot;' + @Name + 
        '&quot;,&quot;Children&quot;:' + CAST(@Json AS NVARCHAR(MAX)) + '}';
        SET @IsRoot = 2;
    END

    RETURN @Json;
END;
</code></pre>
<p><strong>Result:</strong></p>
<pre><code> {
  &quot;Id&quot;: &quot;1&quot;,
  &quot;HierarchyId&quot;: &quot;/&quot;,
  &quot;Name&quot;: &quot;MHz&quot;,
  &quot;Children&quot;: [
    {
      &quot;Id&quot;: 2,
      &quot;HierarchyId&quot;: &quot;/2/&quot;,
      &quot;Name&quot;: &quot;Finance&quot;,
      &quot;Children&quot;: [
        {
          &quot;Id&quot;: 6,
          &quot;HierarchyId&quot;: &quot;/2/6/&quot;,
          &quot;Name&quot;: &quot;Accountant&quot;
        }
      ]
    },
    /* This should not be listed because already included as a child in Finance */
    {
      &quot;Id&quot;: 6,
      &quot;HierarchyId&quot;: &quot;/2/6/&quot;,
      &quot;Name&quot;: &quot;Accountant&quot;
    },
    {
      &quot;Id&quot;: 3,
      &quot;HierarchyId&quot;: &quot;/3/&quot;,
      &quot;Name&quot;: &quot;IT&quot;,
      &quot;Children&quot;: [
        {
          &quot;Id&quot;: 4,
          &quot;HierarchyId&quot;: &quot;/3/4/&quot;,
          &quot;Name&quot;: &quot;Software Development&quot;
        },
        {
          &quot;Id&quot;: 5,
          &quot;HierarchyId&quot;: &quot;/3/5/&quot;,
          &quot;Name&quot;: &quot;QA&quot;
        }
      ]
    },
    /* They both should not be listed because already included as a child in IT */
    {
      &quot;Id&quot;: 4,
      &quot;HierarchyId&quot;: &quot;/3/4/&quot;,
      &quot;Name&quot;: &quot;Software Development&quot;
    },
    {
      &quot;Id&quot;: 5,
      &quot;HierarchyId&quot;: &quot;/3/5/&quot;,
      &quot;Name&quot;: &quot;QA&quot;
    }
  ]
}
</code></pre>
<p>How can I exclude this child elements which have been already listed in parent element?</p>
",50,1,0,4,sql;json;sql-server;hierarchical-data,2022-04-23 10:42:54,2022-04-23 10:42:54,2022-04-23 11:21:54,this is   i have departments table which uses  to store hierarchical data  i want to get this table as json for my  on front side  what i did  result  how can i exclude this child elements which have been already listed in parent element ,create user defined function for hierarchical data returning as json
317,1841758,41716025,How do I list branches having a common prefix?,"<p>I am using Git to manage the development and releases of some software used internally by my company, and having not used Git much prior to joining this company, am still learning how to use it/ best practice when using it for version management, feature development, etc.</p>

<p>I have reached the point where my local Git repository is now quite cluttered with several branches- I have been creating a new branch for the development of each feature/ fixing of each bug raised, merging that branch with <code>master</code> once the feature is complete/ bug is fixed, and pushing <code>master</code> to the server. The server only has the one branch, <code>master</code> running on it.</p>

<p>I want to 'clean up' my local repository, so that old development branches that I am no longer using no longer show up when I run <code>git branch</code>, or other such commands. But still want to have access to the old branches in case I need to revert/ checkout any old working versions/ compare them to the current version if something breaks, etc</p>

<p>I came across this question on SO: <a href=""https://stackoverflow.com/questions/1307114/how-can-i-archive-git-branches"">How can I archive git branches?</a>, which, as I understand, indicates that I can 'clean up' my local repository by archiving and deleting the old branches. But I'm a bit hesitant to do this before clearing up a few things that I'm unsure about:</p>

<p>If, when I run <code>git branch</code>, I have the following branches on my repository:</p>

<pre><code>master
testFeature
brokenTestFeature
FixedTestFeature
</code></pre>

<p>and I want to 'archive' the <code>testFeature</code> &amp; <code>brokenTestFeature</code> branches, as I understand, I would run:</p>

<pre><code>git tag archive/testFeature testFeature
git tag archive/brokenTestFeature brokenTestFeature
git branch -d testFeature
git branch -d brokenTestFeature
</code></pre>

<p>After doing this, if I then run <code>git branch</code> again, the output should display:</p>

<pre><code>master
FixedTestFeature
</code></pre>

<p>and if I wanted to checkout <code>testFeature</code> again, I could run:</p>

<pre><code>git checkout -b testFeature archive/testFeature
</code></pre>

<p>and the <code>testFeature</code> branch would then be displayed again the next time I ran <code>git branch</code>, with all of its commit history, etc still intact? </p>

<p>If I archived a number of branches, how would I display all of the branches that I have archived, so that I know what branches I have in the archive to <code>checkout</code> if/ when I decide that I need to?</p>
",1487,3,1,1,git,2017-01-18 11:46:16,2017-01-18 11:46:16,2022-04-22 14:12:05,i am using git to manage the development and releases of some software used internally by my company  and having not used git much prior to joining this company  am still learning how to use it  best practice when using it for version management  feature development  etc  i have reached the point where my local git repository is now quite cluttered with several branches  i have been creating a new branch for the development of each feature  fixing of each bug raised  merging that branch with master once the feature is complete  bug is fixed  and pushing master to the server  the server only has the one branch  master running on it  i want to  clean up  my local repository  so that old development branches that i am no longer using no longer show up when i run git branch  or other such commands  but still want to have access to the old branches in case i need to revert  checkout any old working versions  compare them to the current version if something breaks  etc i came across this question on so    which  as i understand  indicates that i can  clean up  my local repository by archiving and deleting the old branches  but i m a bit hesitant to do this before clearing up a few things that i m unsure about  if  when i run git branch  i have the following branches on my repository  and i want to  archive  the testfeature  amp  brokentestfeature branches  as i understand  i would run  after doing this  if i then run git branch again  the output should display  and if i wanted to checkout testfeature again  i could run  and the testfeature branch would then be displayed again the next time i ran git branch  with all of its commit history  etc still intact   if i archived a number of branches  how would i display all of the branches that i have archived  so that i know what branches i have in the archive to checkout if  when i decide that i need to ,how do i list branches having a common prefix 
318,1362322,71962410,Self Signed Cert error in Nuxt trying to generate static site locally,"<p>I'm building a Vue/Nuxt (2) site running against a .NET Web Api. This site is already deployed in a staging capacity and is building and running as a statically generated site on Netlify. Now, I know it's not quite right as my content is not being rendered into the deployed files so effectively it's running as a SPA. Not quite what I saw happening in Dev at the time 5 weeks ago but I didn't think anything of it, I'd fix it later.</p>
<p>I've finally got a chance to work on this project again and proceeded to make the necessary changes so the content should be fetched via my dynamic route builder in nuxt.config.js (existing) and output during build via the asyncData hook in my pages (new).</p>
<p><strong>Nuxt.config</strong></p>
<pre><code>// Generate dynamic page routes
let dynamicRoutes = async () =&gt; {

    console.log( `${ process.env.API_BASE_URL }/page/main/generate` );
    const fetchedConditions = await axios.get( `${ process.env.API_BASE_URL }/page/main/generate` );
    const routesForConditions = fetchedConditions.data.map( ( condition ) =&gt; {
        return {
            route: `/conditions/${ condition.id }/${ condition.urlPath }`,
            payload: condition
        }
    } );

    console.log( `${ process.env.API_BASE_URL }/faq/top/generate?count=10` );
    const fetchedFaqs = await axios.get( `${ process.env.API_BASE_URL }/faq/top/generate?count=10` );
    const routesForFaqs = fetchedFaqs.data.map( ( faq ) =&gt; {
        return {
            route: `/frequently-asked-questions/${ faq.categoryId }/${ faq.id }/${ faq.urlPath }`,
            payload: faq
        }
    } );

    const routes = [ ...routesForConditions, ...routesForFaqs ];

    return routes;

}

export default {
    target: 'static',
    ssr: false,
    generate: {
        crawler: true,
        routes: dynamicRoutes
    },
    server: {
        port: 3001
    }...
</code></pre>
<p><strong>Condition page</strong></p>
<pre><code>async asyncData(ctx) {
    util.debug('Async data call...');
    if (ctx.payload) {
        ctx.store.dispatch(&quot;pages/storePage&quot;, ctx.payload);
        return { condition: ctx.payload };
    } else {
        const pageResponse = await ctx.store.dispatch('pages/getCurrentPage', { pageId: ctx.route.params.id });
        return { condition: pageResponse };
    }
}
</code></pre>
<p>So far so good except now, when I try to generate the site in development i.e. &quot;npm run generate&quot;, the dynamic route generator code cannot reach my local API running as HTTPS and fails with a &quot;Nuxt Fatal Error: self signed certificate&quot;.</p>
<pre><code>https://localhost:5001/api/page/main/generate                                                                                                                                                                   12:06:43

ERROR  self signed certificate                                                                                                                                                                                 12:06:43  

  at TLSSocket.onConnectSecure (node:_tls_wrap:1530:34)
  at TLSSocket.emit (node:events:390:28)
  at TLSSocket._finishInit (node:_tls_wrap:944:8)
  at TLSWrap.ssl.onhandshakedone (node:_tls_wrap:725:12)
</code></pre>
<p>This worked 5 weeks ago and as far as I am aware I have not changed anything that should impact this. No software or packages have been updated (except windows updates perhaps). The API is still using .NET 5.0 and running on Kestrel using the default self signed cert on localhost (which is listed as valid in Windows). I simply added the payload to the routes, added the asyncData hook, and modified the page code accordingly.</p>
<p>I've Googled a few tidbits up but none have resolved the issue and now I'm at a loss. It really shouldn't be this blimmin opaque in 2022.</p>
<p><strong>Tried disabling SSL via a proxy in nuxt.config;</strong></p>
<pre><code>proxy: {
    '/api/': {
        target: process.env.API_BASE_URL,
        secure: !process.env.ENV === 'development'
    }
}
</code></pre>
<p><strong>Tried modifying my Axios plugin to ignore auth;</strong></p>
<pre><code>import https from 'https';

export default function ( { $axios } ) {
    $axios.defaults.httpsAgent = new https.Agent( { rejectUnauthorized: false } );
}
</code></pre>
<p><strong>And a variation of;</strong></p>
<pre><code>import https from 'https';

export default function ( { $axios, store } ) {
    const agent = new https.Agent( {
        rejectUnauthorized: false
    } );
    $axios.onRequest( config =&gt; {
        if ( process.env.dev )
        {
            config.httpsAgent = agent;
        }
    } );
}
</code></pre>
<p>None of these 'worked for other people' solutions is working for me.</p>
<p>Also, the client side apps (public/admin) themselves have no problem working against my API locally, it's only the route builder within nuxt.config or asyncData code which is throwing this error.</p>
<p>Any suggestions would be appreciated. Happy to add other relevant code if needed, just not sure which atm.</p>
",250,0,1,5,vue.js;ssl;https;nuxt.js;asp.net-core-webapi,2022-04-22 04:12:16,2022-04-22 04:12:16,2022-04-22 06:20:02,i m building a vue nuxt    site running against a  net web api  this site is already deployed in a staging capacity and is building and running as a statically generated site on netlify  now  i know it s not quite right as my content is not being rendered into the deployed files so effectively it s running as a spa  not quite what i saw happening in dev at the time  weeks ago but i didn t think anything of it  i d fix it later  i ve finally got a chance to work on this project again and proceeded to make the necessary changes so the content should be fetched via my dynamic route builder in nuxt config js  existing  and output during build via the asyncdata hook in my pages  new   nuxt config condition page so far so good except now  when i try to generate the site in development i e   npm run generate   the dynamic route generator code cannot reach my local api running as https and fails with a  nuxt fatal error  self signed certificate   this worked  weeks ago and as far as i am aware i have not changed anything that should impact this  no software or packages have been updated  except windows updates perhaps   the api is still using  net   and running on kestrel using the default self signed cert on localhost  which is listed as valid in windows   i simply added the payload to the routes  added the asyncdata hook  and modified the page code accordingly  i ve googled a few tidbits up but none have resolved the issue and now i m at a loss  it really shouldn t be this blimmin opaque in   tried disabling ssl via a proxy in nuxt config  tried modifying my axios plugin to ignore auth  and a variation of  none of these  worked for other people  solutions is working for me  also  the client side apps  public admin  themselves have no problem working against my api locally  it s only the route builder within nuxt config or asyncdata code which is throwing this error  any suggestions would be appreciated  happy to add other relevant code if needed  just not sure which atm ,self signed cert error in nuxt trying to generate static site locally
319,5740922,71952090,Calling subroutines in different Fortran modules,"<p>I have been developing a free code for computational thermodynamics in the new Fortran standard for the last 10 years it it works quite well but it is large, more than 60000 lines of code and some 500 subroutines.  The software calculates equilibria, phase diagrams and simulates phase transformations using model parameters read from
assessed databases.</p>
<p>Recently I was asked to provide an encrypted database with this
software and I agreed to try to do that.  The actual encryption is
done by an independent vendor which will also provide a library with routines to decrypt the database.  However, I am obliged to prevent anyone extracting the database parameters from inside my software so I have to provide a small pre-compiled library together with the decryption library to store and calculate with the decrypted model parameters in a way that prevents a programmer to extract the model parameters from my software.</p>
<p>This task required a major reorganizing of my data structures and to extract some subroutines in a special library which will not be part of the free software.  I have managed to modify the data structure and I have extracted a small set of subroutines for the calculations with the decrypted parameters.  However, when reading the model parameters from the encrypted database I must find a place to store these related to the elements and phases selected by the user.  The subroutines to find this place are in the program I want to keep free and develop.  So while reading the encrypted database in the library module I must access a large number of subroutines in the free software.</p>
<p>I will try to explain my problem in a simple way using figure 1 where a main program calls subroutine SUBB inside module MODA.  SUBB calls SUBC which calls SUBC before returning.  This is the way my original code works and it is no problem because all subroutines are inside the same module.</p>
<p>figure 1</p>
<pre><code>module moda
contains
  subroutine suba(ib)
    integer :: ib
    write(*,*)'suba 1:',ib
    ib=5
    call subc(ib)
    write(*,*)'suba 2:',ib
  end subroutine suba
!
  subroutine subb(id)
    integer :: id
    write(*,*)'subb 1:',id
    call suba(id)
    write(*,*)'subb 2:',id
  end subroutine subb
!
  subroutine subc(ie)
    integer :: ie
    write(*,*)'subc 1:',ie
    ie=2 
    write(*,*)'subc 2:',ie
  end subroutine subc
end module moda

program main
  use moda
  integer if
  if=0
  call subb(if)
  write(*,*)'Value: ',if
end program main
</code></pre>
<p>Assume SUBA is the subroutine reading the encrypted database and
storing the model parameters in a secret way.  I have made this into a separate module (and library) in figure 2 which will not be part of the free software.  The library will be compiled independently of the main program.</p>
<p>figure 2</p>
<pre><code>module secret
!  use modb, only: subc   creates compilation error
contains
  subroutine suba(ib)
    integer ib
    ib=5
    call subc(ib)
  end subroutine suba
end module secret
</code></pre>
<p>In figure 3 I separated out the module MODB (as I tried to &quot;use&quot; that for SUBA) and in figure 4 the main program.</p>
<p>Figure 3</p>
<pre><code>module modb
!  use secret, only: suba   creates compilation error
contains
  subroutine subb(id)
    integer :: id
    call suba(id)
  end subroutine subb
  subroutine subc(ie)
    integer :: ie
    ie=2
  end subroutine subc
end module modb
</code></pre>
<p>Figure 4</p>
<pre><code>program main
  use modb
  use secret
  integer if
  if=0
  call subb(ie)
  write(*,*)'Value: ',if
end program main
</code></pre>
<p>All my attempts to link this together fails, either by compilation
errors when I &quot;use&quot; the different modules or that &quot;SUBC_&quot; is an
undefined reference.  I have spent a few weeks to handle the data structure problems, I thought the subroutine calls would be easier. Any hint is welcome.</p>
<p>I understand that &quot;use&quot; between two modules is probably illegal and anyway problematic but I have no idea how to handle this.  I can not make the whole of MODB module part of the SECRET module because I want to keep it as small as possible.  The code is still developing and I cannot maintain separate parts.</p>
<p>But maybe there is an elegant solution.  I understood this &quot;only:&quot;
trying to solve this problem.  Maybe there is some &quot;interface&quot; or
&quot;external&quot; feature I do not know about.</p>
<p>For development I use gfortran, gcc 10.2.0 from MSYS2 on Windows but my software is used on various Linux machines and MacOS.  The current version is available on sundmanbo/opencalphad repository on github.</p>
",91,2,1,1,fortran,2022-04-21 12:29:56,2022-04-21 12:29:56,2022-04-21 13:17:54,this task required a major reorganizing of my data structures and to extract some subroutines in a special library which will not be part of the free software   i have managed to modify the data structure and i have extracted a small set of subroutines for the calculations with the decrypted parameters   however  when reading the model parameters from the encrypted database i must find a place to store these related to the elements and phases selected by the user   the subroutines to find this place are in the program i want to keep free and develop   so while reading the encrypted database in the library module i must access a large number of subroutines in the free software  i will try to explain my problem in a simple way using figure  where a main program calls subroutine subb inside module moda   subb calls subc which calls subc before returning   this is the way my original code works and it is no problem because all subroutines are inside the same module  figure  figure  in figure  i separated out the module modb  as i tried to  use  that for suba  and in figure  the main program  figure  figure  i understand that  use  between two modules is probably illegal and anyway problematic but i have no idea how to handle this   i can not make the whole of modb module part of the secret module because i want to keep it as small as possible   the code is still developing and i cannot maintain separate parts  for development i use gfortran  gcc    from msys on windows but my software is used on various linux machines and macos   the current version is available on sundmanbo opencalphad repository on github ,calling subroutines in different fortran modules
320,12229519,71945294,Periphery and Flask Device or Resource Busy Error,"<p>The programming is displaying web cam footage to a monitor. I am trying to add a webserver to the program via flask. When I try to run the flask app it throws a GPIO device busy error. I had the webserver running separate from this code.</p>
<p><a href=""https://github.com/hall488/lockedin"" rel=""nofollow noreferrer"">https://github.com/hall488/lockedin</a></p>
<p>Terminal Connected to Coral Dev Board</p>
<pre><code>&lt;me/mendel/lockedin$ python3 -m edgetpuvision.detect \
&gt; --source /dev/video1:YUY2:864x480:20/1  \
&gt; --model ${TEST_DATA}/ssd_mobilenet_v2_face_quant_postprocess_edgetpu.tflite
 * Serving Flask app 'edgetpuvision.apps' (lazy loading)
 * Environment: development
 * Debug mode: on
 * Running on all addresses (0.0.0.0)
   WARNING: This is a development server. Do not use it in a production deployme
nt.
 * Running on http://127.0.0.1:3000
 * Running on http://128.46.192.239:3000 (Press CTRL+C to quit)
 * Restarting with stat
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.7/dist-packages/periphery/gpio.py&quot;, line 623, in
_reopen
    fcntl.ioctl(self._chip_fd, CdevGPIO._GPIO_GET_LINEHANDLE_IOCTL, request)
OSError: [Errno 16] Device or resource busy

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &quot;/usr/lib/python3.7/runpy.py&quot;, line 193, in _run_module_as_main
    &quot;__main__&quot;, mod_spec)
  File &quot;/usr/lib/python3.7/runpy.py&quot;, line 85, in _run_code
    exec(code, run_globals)
  File &quot;/mnt/home/mendel/lockedin/edgetpuvision/detect.py&quot;, line 50, in &lt;module&gt;

    in1 = GPIO(&quot;/dev/gpiochip2&quot;, 9, &quot;out&quot;) #pin 17
  File &quot;/usr/local/lib/python3.7/dist-packages/periphery/gpio.py&quot;, line 496, in
__init__
    self._open(path, line, direction, edge, bias, drive, inverted, label)
  File &quot;/usr/local/lib/python3.7/dist-packages/periphery/gpio.py&quot;, line 547, in
_open
    self._reopen(direction, edge, bias, drive, inverted)
  File &quot;/usr/local/lib/python3.7/dist-packages/periphery/gpio.py&quot;, line 625, in
_reopen
    raise GPIOError(e.errno, &quot;Opening output line handle: &quot; + e.strerror)
periphery.gpio.GPIOError: [Errno 16] Opening output line handle: Device or resou
rce busy
mendel@elusive-mole:/mnt/home/mendel/lockedin$
</code></pre>
<p>Detect.py file where trying to implement webserver</p>
<pre><code># Copyright 2019 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

&quot;&quot;&quot;A demo which runs object detection on camera frames.

export TEST_DATA=/usr/lib/python3/dist-packages/edgetpu/test_data

Run face detection model:
python3 -m edgetpuvision.detect \
  --model ${TEST_DATA}/mobilenet_ssd_v2_face_quant_postprocess_edgetpu.tflite

Run coco model:
python3 -m edgetpuvision.detect \
  --model ${TEST_DATA}/mobilenet_ssd_v2_coco_quant_postprocess_edgetpu.tflite \
  --labels ${TEST_DATA}/coco_labels.txt
&quot;&quot;&quot;

import argparse
import colorsys
import itertools
import time
import sys

from flask import Flask, render_template, request
app = Flask(__name__)

from pycoral.adapters import detect
from pycoral.utils import edgetpu

from periphery import GPIO
from periphery import PWM

from . import svg
from . import utils
from .apps import run_app



#google &quot;Coral GPIO&quot;
in1 = GPIO(&quot;/dev/gpiochip2&quot;, 9, &quot;out&quot;) #pin 17
in2 = GPIO(&quot;/dev/gpiochip4&quot;, 10, &quot;out&quot;) #pin 18
pwm1 = PWM(0, 0) #pin32

in3 = GPIO(&quot;/dev/gpiochip0&quot;, 7, &quot;out&quot;) #pin 29
in4 = GPIO(&quot;/dev/gpiochip0&quot;, 8, &quot;out&quot;) #pin 31
pwm2 = PWM(1, 0) #pin33



CSS_STYLES = str(svg.CssStyle({'.back': svg.Style(fill='black',
                                                  stroke='black',
                                                  stroke_width='0.5em'),
                               '.bbox': svg.Style(fill_opacity=0.0,
                                                  stroke_width='0.1em')}))

def size_em(length):
    return '%sem' % str(0.6 * (length + 1))

def color(i, total):
    return tuple(int(255.0 * c) for c in colorsys.hsv_to_rgb(i / total, 1.0, 1.0))

def make_palette(keys):
    return {key : svg.rgb(color(i, len(keys))) for i, key in enumerate(keys)}

def make_get_color(color, labels):
    if color:
        return lambda obj_id: color

    if labels:
        palette = make_palette(labels.keys())
        return lambda obj_id: palette[obj_id]

    return lambda obj_id: 'white'

def overlay(title, objs, get_color, labels, inference_time, inference_rate, layout):
    x0, y0, width, height = layout.window
    font_size = 0.03 * height

    defs = svg.Defs()
    defs += CSS_STYLES

    doc = svg.Svg(width=width, height=height,
                  viewBox='%s %s %s %s' % layout.window,
                  font_size=font_size, font_family='monospace', font_weight=500)
    doc += defs

    # if len(objs) == 0:
    #     in1.write(False)
    #     in2.write(False)
    #     pwm1.frequency = 1e3
    #     pwm1.duty_cycle = .75
    #     pwm1.enable()

    #     in3.write(False)
    #     in4.write(False)
    #     pwm2.frequency = 1e3
    #     pwm2.duty_cycle = .75
    #     pwm2.enable()

    for obj in objs:         

        color = get_color(obj.id)
        inference_width, inference_height = layout.inference_size
        bbox = obj.bbox.scale(1.0 / inference_width, 1.0 / inference_height).scale(*layout.size)
        x, y, w, h = bbox.xmin, bbox.ymin, bbox.width, bbox.height

        percent = int(100 * obj.score)
        if labels:
            caption = '%d%% %d %d %s' % (percent, bbox.xmin, bbox.ymin, labels[obj.id])
        else:
            caption = '%d %d' % (x + w/2, y + h/2)


        motor_IO(x, y, w, h)

        

        doc += svg.Rect(x=x, y=y, width=w, height=h,
                        style='stroke:%s' % color, _class='bbox')
        doc += svg.Rect(x=x, y=y+h ,
                        width=size_em(len(caption)), height='1.2em', fill=color)
        t = svg.Text(x=x, y=y+h, fill='black')
        t += svg.TSpan(caption, dy='1em')
        doc += t
    

    ox = x0 + 20
    oy1, oy2 = y0 + 20 + font_size, y0 + height - 20

    # Title
    if title:
        doc += svg.Rect(x=0, y=0, width=size_em(len(title)), height='1em',
                        transform='translate(%s, %s) scale(1,-1)' % (ox, oy1), _class='back')
        doc += svg.Text(title, x=ox, y=oy1, fill='white')

    # Info
    lines = [
        'Objects: %d' % len(objs),
        'Inference time: %.2f ms (%.2f fps)' % (inference_time * 1000, 1.0 / inference_time)
    ]

    for i, line in enumerate(reversed(lines)):
        y = oy2 - i * 1.7 * font_size
        doc += svg.Rect(x=0, y=0, width=size_em(len(line)), height='1em',
                       transform='translate(%s, %s) scale(1,-1)' % (ox, y), _class='back')
        doc += svg.Text(line, x=ox, y=y, fill='white')

    return str(doc)

def motor_IO(x, y, w, h):
    if x + w/2 &gt; 400 :
        in1.write(True)
        in2.write(False)
        pwm1.frequency = 1e3
        pwm1.duty_cycle = .75
        pwm1.enable()
    else :
        in1.write(False)
        in2.write(True)
        pwm1.frequency = 1e3
        pwm1.duty_cycle = .75
        pwm1.enable()

    if y + h/2 &gt; 400 :
        in3.write(True)
        in4.write(False)
        pwm2.frequency = 1e3
        pwm2.duty_cycle = .75
        pwm2.enable()
    else :
        in3.write(False)
        in4.write(True)
        pwm2.frequency = 1e3
        pwm2.duty_cycle = .75
        pwm2.enable()    


def print_results(inference_rate, objs):
    print('\nInference (rate=%.2f fps):' % inference_rate)
    for i, obj in enumerate(objs):
        print('    %d: %s, area=%.2f' % (i, obj, obj.bbox.area))

def render_gen(args):
    
    fps_counter  = utils.avg_fps_counter(30)

    interpreters, titles = utils.make_interpreters(args.model)
    assert utils.same_input_image_sizes(interpreters)
    interpreters = itertools.cycle(interpreters)
    interpreter = next(interpreters)

    labels = utils.load_labels(args.labels) if args.labels else None
    filtered_labels = set(l.strip() for l in args.filter.split(',')) if args.filter else None
    get_color = make_get_color(args.color, labels)

    draw_overlay = True

    width, height = utils.input_image_size(interpreter)
    yield width, height

    output = None
    while True:
        tensor, layout, command = (yield output)

        inference_rate = next(fps_counter)
        if draw_overlay:
            start = time.monotonic()
            edgetpu.run_inference(interpreter, tensor)
            inference_time = time.monotonic() - start

            objs = detect.get_objects(interpreter, args.threshold)[:args.top_k]
            if labels and filtered_labels:
                objs = [obj for obj in objs if labels[obj.id] in filtered_labels]

            objs = [obj for obj in objs \
                    if args.min_area &lt;= obj.bbox.scale(1.0 / width, 1.0 / height).area &lt;= args.max_area]

            if args.print:
                print_results(inference_rate, objs)

            title = titles[interpreter]
            output = overlay(title, objs, get_color, labels, inference_time, inference_rate, layout)
        else:
            output = None

        if command == 'o':
            draw_overlay = not draw_overlay
        elif command == 'n':
            interpreter = next(interpreters)

def add_render_gen_args(parser):
    parser.add_argument('--model',
                        help='.tflite model path', required=True)
    parser.add_argument('--labels',
                        help='labels file path')
    parser.add_argument('--top_k', type=int, default=50,
                        help='Max number of objects to detect')
    parser.add_argument('--threshold', type=float, default=0.1,
                        help='Detection threshold')
    parser.add_argument('--min_area', type=float, default=0.0,
                        help='Min bounding box area')
    parser.add_argument('--max_area', type=float, default=1.0,
                        help='Max bounding box area')
    parser.add_argument('--filter', default=None,
                        help='Comma-separated list of allowed labels')
    parser.add_argument('--color', default=None,
                        help='Bounding box display color'),
    parser.add_argument('--print', default=False, action='store_true',
                        help='Print inference results')

#@app.route(&quot;/&quot;)
def main():
    app.run(host='0.0.0.0', port=3000, debug=True)
    run_app(add_render_gen_args, render_gen)
    
    #templateData = {
    #}
   # Pass the template data into the template main.html and return it to the user
    #return render_template('main.html', **templateData)

#@app.route(&quot;/&lt;changePin&gt;/&lt;action&gt;&quot;)
#def action(changePin, action):
#    print(&quot;yo&quot;)

if __name__ == '__main__':        
    main()
    
    
</code></pre>
",74,0,0,3,python;flask;google-coral,2022-04-20 22:35:00,2022-04-20 22:35:00,2022-04-20 22:35:00,the programming is displaying web cam footage to a monitor  i am trying to add a webserver to the program via flask  when i try to run the flask app it throws a gpio device busy error  i had the webserver running separate from this code   terminal connected to coral dev board detect py file where trying to implement webserver,periphery and flask device or resource busy error
321,13913250,71918410,Could not find module ‘Criterion.Main’ when trying to benchmark haskell,"<p>I cannot get Criterion to work. I followed the tutorial <a href=""http://www.serpentine.com/criterion/tutorial.html"" rel=""nofollow noreferrer"">here</a>, installing Criterion by doing the following.</p>
<pre><code>cabal update
cabal install -j --disable-tests criterion
</code></pre>
<p>when I try <code>ghc -O Fibber.hs</code> or <code>ghc -O --make Fibber</code> I receive the error</p>
<pre><code>[1 of 1] Compiling Main             ( Fibber.hs, Fibber.o )

Fibber.hs:1:1: error:
    Could not find module ‘Criterion.Main’
    Use -v (or `:set -v` in ghci) to see a list of the files searched for.
  |
1 | import Criterion.Main
  |
</code></pre>
<p>I expect tests and diagnostics to be run and outputted to the console and an HTML file.
trying with stack results in the same error. I have solved this problem before with my own modules by including them in my <code>.cabal</code> file like so</p>
<pre><code>library
  Exposed-Modules:
    Geometry.Sphere
    Geometry.Cuboid
    Geometry.Cube
</code></pre>
<p>But doing this same in this case does not resolve the issue. I have also tried <a href=""https://stackoverflow.com/questions/50637221/could-not-find-module-criterion-main"">this SO solution</a>, but to no avail. I receive basically the same error:</p>
<pre><code>
/Users/me/Documents/projects/haskell/performance/criterion-1.5.13.0/Criterion/Fibber.hs:3:1: error:
    Could not find module ‘CriterionMain’
    Use -v (or `:set -v` in ghci) to see a list of the files searched for.
  |
3 | import CriterionMain
  | ^^^^^^^^^^^^^^^^^^^^
Received ExitFailure 1 when running
Raw command: /Users/me/.stack/programs/aarch64-osx/ghc-9.2.2/bin/ghc-9.2.2 -i -i/Users/me/Documents/projects/haskell/performance/criterion-1.5.13.0/Criterion/ -hide-all-packages -fdiagnostics-color=always -packagebase -O2 /Users/me/Documents/projects/haskell/performance/criterion-1.5.13.0/Criterion/Fibber.hs
Run from: /Users/me/Documents/projects/haskell/performance/criterion-1.5.13.0/Criterion/
Standard output:

[1 of 1] Compiling Main             ( /Users/me/Documents/projects/haskell/performance/criterion-1.5.13.0/Criterion/Fibber.hs, /Users/me/Documents/projects/haskell/performance/criterion-1.5.13.0/Criterion/Fibber.o )
</code></pre>
<p>this is my <code>.cabal</code> file.</p>
<pre><code>name:           criterion
version:        1.5.13.0
synopsis:       Robust, reliable performance measurement and analysis
license:        BSD3
license-file:   LICENSE
author:         Bryan O'Sullivan &lt;bos@serpentine.com&gt;
maintainer:     Ryan Scott &lt;ryan.gl.scott@gmail.com&gt;
copyright:      2009-2016 Bryan O'Sullivan and others
category:       Development, Performance, Testing, Benchmarking
homepage:       http://www.serpentine.com/criterion
bug-reports:    https://github.com/haskell/criterion/issues
build-type:     Simple
cabal-version:  &gt;= 1.10
extra-source-files:
  README.markdown
  changelog.md
  examples/LICENSE
  examples/*.cabal
  examples/*.hs
tested-with:
  GHC==7.4.2,
  GHC==7.6.3,
  GHC==7.8.4,
  GHC==7.10.3,
  GHC==8.0.2,
  GHC==8.2.2,
  GHC==8.4.4,
  GHC==8.6.5,
  GHC==8.8.4,
  GHC==8.10.7,
  GHC==9.0.2,
  GHC==9.2.1

data-files:
  templates/*.css
  templates/*.tpl
  templates/*.js

description:
  This library provides a powerful but simple way to measure software
  performance.  It provides both a framework for executing and
  analysing benchmarks and a set of driver functions that makes it
  easy to build and run benchmarks, and to analyse their results.
  .
  The fastest way to get started is to read the
  &lt;http://www.serpentine.com/criterion/tutorial.html online tutorial&gt;,
  followed by the documentation and examples in the &quot;Criterion.Main&quot;
  module.
  .
  For examples of the kinds of reports that criterion generates, see
  &lt;http://www.serpentine.com/criterion the home page&gt;.

flag fast
  description: compile without optimizations
  default: False
  manual: True

flag embed-data-files
  description: Embed the data files in the binary for a relocatable executable.
               (Warning: This will increase the executable size significantly.)
  default: False
  manual: True

library
  exposed-modules:
    Criterion
    Criterion.Analysis
    Criterion.IO
    Criterion.IO.Printf
    Criterion.Internal
    Criterion.Main
    Criterion.Main.Options
    Criterion.Monad
    Criterion.Report
    Criterion.Types

  other-modules:
    Criterion.Main.Options.Internal
    Criterion.Monad.Internal

  other-modules:
    Paths_criterion

  build-depends:
    -- TODO: Eventually, we should bump the lower version bounds to &gt;=2 so that
    -- we can remove some CPP in Criterion.Report. See #247.
    aeson &gt;= 1 &amp;&amp; &lt; 2.1,
    ansi-wl-pprint &gt;= 0.6.7.2,
    base &gt;= 4.5 &amp;&amp; &lt; 5,
    base-compat-batteries &gt;= 0.10 &amp;&amp; &lt; 0.13,
    binary &gt;= 0.5.1.0,
    binary-orphans &gt;= 1.0.1 &amp;&amp; &lt; 1.1,
    bytestring &gt;= 0.9 &amp;&amp; &lt; 1.0,
    cassava &gt;= 0.3.0.0,
    code-page,
    containers,
    criterion-measurement &gt;= 0.1.1.0 &amp;&amp; &lt; 0.2,
    deepseq &gt;= 1.1.0.0,
    directory,
    exceptions &gt;= 0.8.2 &amp;&amp; &lt; 0.11,
    filepath,
    Glob &gt;= 0.7.2,
    microstache &gt;= 1.0.1 &amp;&amp; &lt; 1.1,
    js-chart &gt;= 2.9.4 &amp;&amp; &lt; 3,
    mtl &gt;= 2,
    mwc-random &gt;= 0.8.0.3,
    -- TODO: Depend on optparse-applicative-0.17 as the minimum (see #258)
    optparse-applicative &gt;= 0.13 &amp;&amp; &lt; 0.18,
    parsec &gt;= 3.1.0,
    statistics &gt;= 0.14 &amp;&amp; &lt; 0.16,
    text &gt;= 0.11,
    time,
    transformers,
    transformers-compat &gt;= 0.6.4,
    vector &gt;= 0.7.1,
    vector-algorithms &gt;= 0.4
  if impl(ghc &lt; 7.6)
    build-depends:
      ghc-prim
  if !impl(ghc &gt;= 8.0)
    build-depends:
      fail == 4.9.*,
      semigroups

  default-language: Haskell2010
  ghc-options: -Wall -funbox-strict-fields
  if impl(ghc &gt;= 6.8)
    ghc-options: -fwarn-tabs
  if flag(fast)
    ghc-options: -O0
  else
    ghc-options: -O2

  if flag(embed-data-files)
    other-modules: Criterion.EmbeddedData
    build-depends: file-embed &lt; 0.1,
                   template-haskell
    cpp-options: &quot;-DEMBED&quot;

Executable criterion-report
  Default-Language:     Haskell2010
  GHC-Options:          -Wall -rtsopts
  Main-Is:              Report.hs
  Other-Modules:        Options
                        Paths_criterion
  Hs-Source-Dirs:       app

  Build-Depends:
    base,
    base-compat-batteries,
    criterion,
    optparse-applicative &gt;= 0.13

  if impl(ghc &lt; 7.6)
    build-depends:
      ghc-prim

  if !impl(ghc &gt;= 8.0)
    build-depends:
      semigroups

test-suite sanity
  type:                 exitcode-stdio-1.0
  hs-source-dirs:       tests
  main-is:              Sanity.hs
  default-language:     Haskell2010
  ghc-options:          -Wall -rtsopts
  if flag(fast)
    ghc-options:        -O0
  else
    ghc-options:        -O2

  build-depends:
    HUnit,
    base,
    bytestring,
    criterion,
    deepseq,
    tasty,
    tasty-hunit

test-suite tests
  type:                 exitcode-stdio-1.0
  hs-source-dirs:       tests
  main-is:              Tests.hs
  default-language:     Haskell2010
  other-modules:        Properties

  ghc-options:
    -Wall -threaded     -O0 -rtsopts

  build-depends:
    QuickCheck &gt;= 2.4,
    base,
    base-compat-batteries,
    criterion,
    statistics,
    HUnit,
    tasty,
    tasty-hunit,
    tasty-quickcheck,
    vector,
    aeson

test-suite cleanup
  type:                 exitcode-stdio-1.0
  hs-source-dirs:       tests
  default-language:     Haskell2010
  main-is:              Cleanup.hs

  ghc-options:
    -Wall -threaded     -O0 -rtsopts

  build-depends:
    HUnit,
    base,
    base-compat,
    bytestring,
    criterion,
    deepseq,
    directory,
    tasty,
    tasty-hunit

source-repository head
  type:     git
  location: https://github.com/haskell/criterion.git

</code></pre>
",114,2,0,4,haskell;ghc;cabal;haskell-criterion,2022-04-19 03:33:33,2022-04-19 03:33:33,2022-04-20 12:20:12,i cannot get criterion to work  i followed the tutorial   installing criterion by doing the following  when i try ghc  o fibber hs or ghc  o   make fibber i receive the error but doing this same in this case does not resolve the issue  i have also tried   but to no avail  i receive basically the same error  this is my  cabal file ,could not find module  criterion main  when trying to benchmark haskell
322,5853383,58117404,"Using C#, .NET Core 3 and GTK# for cross-platform Programming (and alternatives)","<p>I am about to start development of a software project that should run on Linux and Windows if possible. As I already have some experience with C# I am eager to use it for this project. I assumed that with .NET Core 3 and GTK# 3.22 this shouldn't be a problem since .NET Core App should be cross-platform out of the box. GTK# - from my understanding - should work everywhere GTK+ in the same version is also available. </p>

<p>Why c#? Well I just like the language and there is an ECS Framework for c# I'd like to use.</p>

<p>So far I have setup a test Console App project in Visual Studio targeting .NET Core 3 and added an <a href=""https://github.com/GtkSharp/GtkSharp"" rel=""noreferrer"">GTK# specific NuGet package</a>.</p>

<p>I wrote a simple Hello World program for testing of the environment.</p>

<pre><code>using System;
using Gtk;

namespace GTKTest
{
    class Program
    {
        static void Main(string[] args)
        {
            Application.Init();
            Window win = new Window(""Hello GTK"");
            Label lbl = new Label(""This is a test GTK App written with C# for GNU/Linux and Windows"");
            win.DeleteEvent += Win_DeleteEvent;
            win.Add(lbl);
            win.ShowAll();
            Application.Run();
            win.Dispose();
            Console.Write(""Press any key..."");
            Console.ReadKey();
        }

        private static void Win_DeleteEvent(object o, DeleteEventArgs args)
        {
            Application.Quit();
            args.RetVal = true;
        }

    }
}
</code></pre>

<p>When I run this code from Visual Studio 2019 I get </p>

<pre><code>System.TypeInitializationException
  HResult=0x80131534
  Message=The type initializer for 'Gtk.Application' threw an exception.
  Source=GtkSharp
  StackTrace:
   at Gtk.Application.Init()
   at GTKTest.Program.Main(String[] args) in D:\Workspace\VSRepos\C#\GTKTest\Program.cs:line 10

Inner Exception 1:
DllNotFoundException: Gtk
</code></pre>

<p>While searching for a solution I installed mono and <a href=""https://www.mono-project.com/download/stable/#download-win"" rel=""noreferrer"">GTK# for Windows from this page</a>. The mono part shouldn't be necessary if I stick to .NET Core I think.</p>

<p>What am I missing? What am I doing wrong? Is what I'm trying to achieve even possible like I am imaging it? I'm also interested in some alternatives how to program cross-platform GUI-Software with C#. I stumbled upon electron.js but I heard it has some big Memory overhead and I'm not really into javascript. AvaloniaUI sounded interesting but I thought that the above approach would be better.</p>

<p>Edit: After adding msys path like suggested <a href=""https://github.com/GtkSharp/GtkSharp/wiki/Installing-Gtk-on-Windows"" rel=""noreferrer"">here in step 3</a> I get following error preceding the exception from above. The error states that the procedure entry point couldn't be found in the dll.</p>

<p><a href=""https://i.stack.imgur.com/PTtnC.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/PTtnC.png"" alt=""enter image description here""></a></p>
",7018,1,6,5,c#;.net-core;mono;cross-platform;gtk#,2019-09-26 16:02:23,2019-09-26 16:02:23,2022-04-20 02:28:31,i am about to start development of a software project that should run on linux and windows if possible  as i already have some experience with c  i am eager to use it for this project  i assumed that with  net core  and gtk    this shouldn t be a problem since  net core app should be cross platform out of the box  gtk    from my understanding   should work everywhere gtk  in the same version is also available   why c   well i just like the language and there is an ecs framework for c  i d like to use  so far i have setup a test console app project in visual studio targeting  net core  and added an   i wrote a simple hello world program for testing of the environment  when i run this code from visual studio  i get  while searching for a solution i installed mono and   the mono part shouldn t be necessary if i stick to  net core i think  what am i missing  what am i doing wrong  is what i m trying to achieve even possible like i am imaging it  i m also interested in some alternatives how to program cross platform gui software with c   i stumbled upon electron js but i heard it has some big memory overhead and i m not really into javascript  avaloniaui sounded interesting but i thought that the above approach would be better  edit  after adding msys path like suggested  i get following error preceding the exception from above  the error states that the procedure entry point couldn t be found in the dll  ,using c    net core  and gtk  for cross platform programming  and alternatives 
323,2172243,71928396,How to Serialise and Deserialise Flink Avro in Java,"<p>I want to serialise and deserialise avro messages within apache flink Java. I'm also happy to do implement in in Scala.</p>
<p>I have attached my source code below. I hope the comments within the source code makes it clear enough.</p>
<pre><code>package com.example;

// import io.confluent.kafka.serializers.KafkaAvroSerializer;
// import org.apache.flink.api.common.serialization.SimpleStringSchema;

import io.confluent.kafka.serializers.KafkaAvroDeserializer;
import io.confluent.kafka.serializers.KafkaAvroSerializer;
import org.apache.flink.api.common.serialization.SimpleStringSchema;
import org.apache.flink.streaming.api.CheckpointingMode;
import org.apache.flink.streaming.api.datastream.DataStreamSource;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;
import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase;
import org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.serialization.StringSerializer;
import org.json.simple.JSONObject;
import org.json.simple.parser.JSONParser;

import java.io.FileReader;
import java.util.Properties;

public class StreamingJob {

    public static void main(String[] args) throws Exception {

        // Reading from a json file
        JSONParser parser = new JSONParser();
        try {
            // This is the path to the Jason file
            Object obj = parser.parse(new FileReader(&quot;/opt/flink/conf/config.json&quot;));

            // creating our json object
            JSONObject jsonObject = (JSONObject) obj;

            String bootstrapServer = jsonObject.get(&quot;bootstrapServers&quot;).toString(); // localhost:32310
            String groupId = jsonObject.get(&quot;groupId&quot;).toString();
            String kafkaInputTopic = jsonObject.get(&quot;kafkaInputTopic&quot;).toString();
            String kafkaOutputTopic = jsonObject.get(&quot;kafkaOutputTopic&quot;).toString();
            String windowTimerInSecondsString = jsonObject.get(&quot;windowTimerInSeconds&quot;).toString();
            String schemaRegistry = jsonObject.get(&quot;schemaReg&quot;).toString();
            int windowTimerInSeconds = Integer.parseInt(windowTimerInSecondsString);
            String jobName = jsonObject.get(&quot;jobName&quot;).toString();

            // Creating our data stream
            final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
            env.setParallelism(1); // setting the number of Parallelism processes to 1
            env.enableCheckpointing(5000); // setting the checkpoint
            env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);

            // Our Properties for our data consumption
            Properties consumerProperties = new Properties();
            consumerProperties.setProperty(&quot;bootstrap.servers&quot;, bootstrapServer);
            consumerProperties.setProperty(&quot;group.id&quot;, groupId);
            consumerProperties.setProperty(&quot;schema.registry.url&quot;, schemaRegistry);
            consumerProperties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, KafkaAvroDeserializer.class.getName());
            consumerProperties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, KafkaAvroDeserializer.class.getName());

            // This is our Flink kafka consumer
            FlinkKafkaConsumer&lt;String&gt; kafkaConsumer = new FlinkKafkaConsumer&lt;&gt;(kafkaInputTopic,
                    new SimpleStringSchema(), consumerProperties);

            DataStreamSource&lt;String&gt; consumedKafkaData = env.addSource(kafkaConsumer);
            consumedKafkaData.print();


            Properties producer = new Properties();

            producer.setProperty(&quot;bootstrap.servers&quot;, bootstrapServer);
            producer.setProperty(&quot;acks&quot;, &quot;1&quot;);
            producer.setProperty(&quot;retries&quot;, &quot;10&quot;);
            producer.setProperty(&quot;schema.registry.url&quot;, schemaRegistry);

            producer.setProperty(&quot;key.serializer&quot;, StringSerializer.class.getName());
            producer.setProperty(&quot;value.serializer&quot;, KafkaAvroSerializer.class.getName()); // KafkaAvroSerializer
            // Producer
            FlinkKafkaProducer kafkaProducer = new FlinkKafkaProducer(
                    bootstrapServer,
                    kafkaOutputTopic,
                    new SimpleStringSchema());

            kafkaProducer.setWriteTimestampToKafka(true);
            consumedKafkaData.addSink(kafkaProducer);


            env.execute(jobName);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }


}

</code></pre>
<p>Here is the pom file</p>
<pre><code>&lt;!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
&quot;License&quot;); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
&quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
--&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;FlinkDeDup&lt;/groupId&gt;
    &lt;artifactId&gt;FlinkDeDup&lt;/artifactId&gt;
    &lt;version&gt;0.1&lt;/version&gt;
    &lt;packaging&gt;jar&lt;/packaging&gt;

    &lt;name&gt;Flink Quickstart Job&lt;/name&gt;
    &lt;url&gt;http://www.myorganization.org&lt;/url&gt;

    &lt;properties&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
        &lt;scala.binary.version&gt;2.11&lt;/scala.binary.version&gt;
        &lt;maven.compiler.source&gt;${java.version}&lt;/maven.compiler.source&gt;
        &lt;maven.compiler.target&gt;${java.version}&lt;/maven.compiler.target&gt;

        &lt;avro.version&gt;1.8.2&lt;/avro.version&gt;
        &lt;confluent.version&gt;3.3.1&lt;/confluent.version&gt;
    &lt;/properties&gt;

    &lt;repositories&gt;
        &lt;repository&gt;
            &lt;id&gt;apache.snapshots&lt;/id&gt;
            &lt;name&gt;Apache Development Snapshot Repository&lt;/name&gt;
            &lt;url&gt;https://repository.apache.org/content/repositories/snapshots/&lt;/url&gt;
            &lt;releases&gt;
                &lt;enabled&gt;false&lt;/enabled&gt;
            &lt;/releases&gt;
            &lt;snapshots&gt;
                &lt;enabled&gt;true&lt;/enabled&gt;
            &lt;/snapshots&gt;
        &lt;/repository&gt;

        &lt;repository&gt;
            &lt;id&gt;confluent&lt;/id&gt;
            &lt;url&gt;https://packages.confluent.io/maven/&lt;/url&gt;
        &lt;/repository&gt;
    &lt;/repositories&gt;

    &lt;dependencies&gt;
        &lt;!-- Apache Flink dependencies --&gt;
        &lt;!-- These dependencies are provided, because they should not be packaged into the JAR file. --&gt;
&lt;!--        &lt;dependency&gt;--&gt;
&lt;!--            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;--&gt;
&lt;!--            &lt;artifactId&gt;flink-core&lt;/artifactId&gt;--&gt;
&lt;!--            &lt;version&gt;1.13.2&lt;/version&gt;--&gt;
&lt;!--            &lt;scope&gt;provided&lt;/scope&gt;--&gt;
&lt;!--        &lt;/dependency&gt;--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-streaming-java_${scala.binary.version}&lt;/artifactId&gt;
            &lt;version&gt;1.13.2&lt;/version&gt;
            &lt;scope&gt;provided&lt;/scope&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;com.googlecode.json-simple&lt;/groupId&gt;
            &lt;artifactId&gt;json-simple&lt;/artifactId&gt;
            &lt;version&gt;1.1.1&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-connector-kafka_2.11&lt;/artifactId&gt;
            &lt;version&gt;1.13.2&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-clients_2.12&lt;/artifactId&gt;
            &lt;version&gt;1.13.2&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- Add connector dependencies here. They must be in the default scope (compile). --&gt;

        &lt;!-- Example:

        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-connector-kafka-0.10_${scala.binary.version}&lt;/artifactId&gt;
            &lt;version&gt;1.13.2&lt;/version&gt;
        &lt;/dependency&gt;
        --&gt;

        &lt;!-- Add logging framework, to produce console output when running in the IDE. --&gt;
        &lt;!-- These dependencies are excluded from the application JAR by default. --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
            &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;
            &lt;version&gt;1.7.7&lt;/version&gt;
            &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.avro&lt;/groupId&gt;
            &lt;artifactId&gt;avro&lt;/artifactId&gt;
            &lt;version&gt;${avro.version}&lt;/version&gt;
            &lt;!--            &lt;version&gt;1.8.2&lt;/version&gt;--&gt;
        &lt;/dependency&gt;

        &lt;!-- https://mvnrepository.com/artifact/io.confluent/kafka-avro-serializer --&gt;
&lt;!--        &lt;dependency&gt;--&gt;
&lt;!--        &lt;groupId&gt;io.confluent&lt;/groupId&gt;--&gt;
&lt;!--        &lt;artifactId&gt;kafka-avro-serializer&lt;/artifactId&gt;--&gt;
&lt;!--        &lt;version&gt;${confluent.version}&lt;/version&gt;--&gt;
&lt;!--        &amp;lt;!&amp;ndash;            &lt;version&gt;7.0.1&lt;/version&gt;&amp;ndash;&amp;gt;--&gt;
&lt;!--        &lt;/dependency&gt;--&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;log4j&lt;/groupId&gt;
            &lt;artifactId&gt;log4j&lt;/artifactId&gt;
            &lt;version&gt;1.2.17&lt;/version&gt;
            &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;
            &lt;artifactId&gt;gson&lt;/artifactId&gt;
            &lt;version&gt;2.8.5&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot&lt;/artifactId&gt;
            &lt;version&gt;2.5.3&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;

            &lt;!-- Java Compiler --&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.7.0&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;source&gt;${java.version}&lt;/source&gt;
                    &lt;target&gt;${java.version}&lt;/target&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;

            &lt;!-- We use the maven-shade plugin to create a fat jar that contains all necessary dependencies. --&gt;
            &lt;!-- Change the value of &lt;mainClass&gt;...&lt;/mainClass&gt; if your program entry point changes. --&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.0.0&lt;/version&gt;
                &lt;executions&gt;
                    &lt;!-- Run shade goal on package phase --&gt;
                    &lt;execution&gt;
                        &lt;phase&gt;package&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;shade&lt;/goal&gt;
                        &lt;/goals&gt;
                        &lt;configuration&gt;
                            &lt;artifactSet&gt;
                                &lt;excludes&gt;
                                    &lt;exclude&gt;org.apache.flink:force-shading&lt;/exclude&gt;
                                    &lt;exclude&gt;com.google.code.findbugs:jsr305&lt;/exclude&gt;
                                    &lt;exclude&gt;org.slf4j:*&lt;/exclude&gt;
                                    &lt;exclude&gt;log4j:*&lt;/exclude&gt;
                                &lt;/excludes&gt;
                            &lt;/artifactSet&gt;
                            &lt;filters&gt;
                                &lt;filter&gt;
                                    &lt;!-- Do not copy the signatures in the META-INF folder.
                                    Otherwise, this might cause SecurityExceptions when using the JAR. --&gt;
                                    &lt;artifact&gt;*:*&lt;/artifact&gt;
                                    &lt;excludes&gt;
                                        &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt;
                                        &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt;
                                        &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt;
                                    &lt;/excludes&gt;
                                &lt;/filter&gt;
                            &lt;/filters&gt;
                            &lt;transformers&gt;
                                &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt;
                                    &lt;mainClass&gt;com.example.StreamingJob&lt;/mainClass&gt;
                                &lt;/transformer&gt;
                            &lt;/transformers&gt;
                        &lt;/configuration&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;

            &lt;!--for specific record--&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.avro&lt;/groupId&gt;
                &lt;artifactId&gt;avro-maven-plugin&lt;/artifactId&gt;
                &lt;version&gt;${avro.version}&lt;/version&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;phase&gt;generate-sources&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;schema&lt;/goal&gt;
                            &lt;goal&gt;protocol&lt;/goal&gt;
                            &lt;goal&gt;idl-protocol&lt;/goal&gt;
                        &lt;/goals&gt;
                        &lt;configuration&gt;
                            &lt;sourceDirectory&gt;${project.basedir}/src/main/resources/avro&lt;/sourceDirectory&gt;
                            &lt;stringType&gt;String&lt;/stringType&gt;
                            &lt;createSetters&gt;false&lt;/createSetters&gt;
                            &lt;enableDecimalLogicalType&gt;true&lt;/enableDecimalLogicalType&gt;
                            &lt;fieldVisibility&gt;private&lt;/fieldVisibility&gt;
                        &lt;/configuration&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;

        &lt;/plugins&gt;

        &lt;pluginManagement&gt;
            &lt;plugins&gt;

                &lt;!-- This improves the out-of-the-box experience in Eclipse by resolving some warnings. --&gt;
                &lt;plugin&gt;
                    &lt;groupId&gt;org.eclipse.m2e&lt;/groupId&gt;
                    &lt;artifactId&gt;lifecycle-mapping&lt;/artifactId&gt;
                    &lt;version&gt;1.0.0&lt;/version&gt;
                    &lt;configuration&gt;
                        &lt;lifecycleMappingMetadata&gt;
                            &lt;pluginExecutions&gt;
                                &lt;pluginExecution&gt;
                                    &lt;pluginExecutionFilter&gt;
                                        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                                        &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;
                                        &lt;versionRange&gt;[3.0.0,)&lt;/versionRange&gt;
                                        &lt;goals&gt;
                                            &lt;goal&gt;shade&lt;/goal&gt;
                                        &lt;/goals&gt;
                                    &lt;/pluginExecutionFilter&gt;
                                    &lt;action&gt;
                                        &lt;ignore/&gt;
                                    &lt;/action&gt;
                                &lt;/pluginExecution&gt;
                                &lt;pluginExecution&gt;
                                    &lt;pluginExecutionFilter&gt;
                                        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                                        &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                                        &lt;versionRange&gt;[3.1,)&lt;/versionRange&gt;
                                        &lt;goals&gt;
                                            &lt;goal&gt;testCompile&lt;/goal&gt;
                                            &lt;goal&gt;compile&lt;/goal&gt;
                                        &lt;/goals&gt;
                                    &lt;/pluginExecutionFilter&gt;
                                    &lt;action&gt;
                                        &lt;ignore/&gt;
                                    &lt;/action&gt;
                                &lt;/pluginExecution&gt;
                            &lt;/pluginExecutions&gt;
                        &lt;/lifecycleMappingMetadata&gt;
                    &lt;/configuration&gt;
                &lt;/plugin&gt;

                &lt;!--for specific record--&gt;
                &lt;plugin&gt;
                    &lt;groupId&gt;org.apache.avro&lt;/groupId&gt;
                    &lt;artifactId&gt;avro-maven-plugin&lt;/artifactId&gt;
                    &lt;version&gt;${avro.version}&lt;/version&gt;
                    &lt;executions&gt;
                        &lt;execution&gt;
                            &lt;phase&gt;generate-sources&lt;/phase&gt;
                            &lt;goals&gt;
                                &lt;goal&gt;schema&lt;/goal&gt;
                                &lt;goal&gt;protocol&lt;/goal&gt;
                                &lt;goal&gt;idl-protocol&lt;/goal&gt;
                            &lt;/goals&gt;
                            &lt;configuration&gt;
                                &lt;sourceDirectory&gt;${project.basedir}/src/main/resources/avro&lt;/sourceDirectory&gt;
                                &lt;stringType&gt;String&lt;/stringType&gt;
                                &lt;createSetters&gt;false&lt;/createSetters&gt;
                                &lt;enableDecimalLogicalType&gt;true&lt;/enableDecimalLogicalType&gt;
                                &lt;fieldVisibility&gt;private&lt;/fieldVisibility&gt;
                            &lt;/configuration&gt;
                        &lt;/execution&gt;
                    &lt;/executions&gt;
                &lt;/plugin&gt;


            &lt;/plugins&gt;
        &lt;/pluginManagement&gt;
    &lt;/build&gt;

    &lt;!-- This profile helps to make things run out of the box in IntelliJ --&gt;
    &lt;!-- Its adds Flink's core classes to the runtime class path. --&gt;
    &lt;!-- Otherwise they are missing in IntelliJ, because the dependency is 'provided' --&gt;
    &lt;profiles&gt;
        &lt;profile&gt;
            &lt;id&gt;add-dependencies-for-IDEA&lt;/id&gt;

            &lt;activation&gt;
                &lt;property&gt;
                    &lt;name&gt;idea.version&lt;/name&gt;
                &lt;/property&gt;
            &lt;/activation&gt;

            &lt;dependencies&gt;
                &lt;dependency&gt;
                    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
                    &lt;artifactId&gt;flink-java&lt;/artifactId&gt;
                    &lt;version&gt;1.13.2&lt;/version&gt;
                    &lt;scope&gt;compile&lt;/scope&gt;
                &lt;/dependency&gt;
                &lt;dependency&gt;
                    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
                    &lt;artifactId&gt;flink-streaming-java_${scala.binary.version}&lt;/artifactId&gt;
                    &lt;version&gt;1.13.2&lt;/version&gt;
                    &lt;scope&gt;compile&lt;/scope&gt;
                &lt;/dependency&gt;
            &lt;/dependencies&gt;
        &lt;/profile&gt;
    &lt;/profiles&gt;

&lt;/project&gt;

</code></pre>
<p>Here is the configuration</p>
<p>{
&quot;bootstrapServers&quot;: &quot;192.168.1.100:31957&quot;,
&quot;groupId&quot;: &quot;myjob&quot;,
&quot;kafkaInputTopic&quot;: &quot;in&quot;,
&quot;kafkaOutputTopic&quot;: &quot;out&quot;,
&quot;windowTimerInSeconds&quot;: &quot;10&quot;,
&quot;jobName&quot;: &quot;iMonitor-Deduplication-Job-v1&quot;,
&quot;schemaReg&quot; : &quot;http://192.168.1.100:32081&quot;
}</p>
",232,1,0,2,apache-flink;flink-streaming,2022-04-19 19:38:05,2022-04-19 19:38:05,2022-04-19 21:25:23,i want to serialise and deserialise avro messages within apache flink java  i m also happy to do implement in in scala  i have attached my source code below  i hope the comments within the source code makes it clear enough  here is the pom file here is the configuration,how to serialise and deserialise flink avro in java
324,18375608,71355191,Correct way to create a software install script which can manage dependencies,"<p>I'm currently working on an university research related software which uses statistical models in it in order to process some calculations around Item Response Theory. The entire source code was written in Go, whereas it communicates with a Rscript server to run scripts written in R and return the generated results. As expected, the software itself has some dependencies needed to work properly (one of them, as seen before, is to have R/Rscript installed and some of its packages).</p>
<p>Due to the fact I'm new to software development, I can't find a proper way to manage all these dependencies on Windows or Linux (but I'm prioritizing Windows right now). What I was thinking is to have a kind of script which checks if [for example] R is properly installed and, if so, if each used package is also installed. If everything went well, then the software could be installed without further problems.</p>
<p>My question is what's the best way to do anything like that and if it's possible to do the same for other possible dependencies, such as Python, Go and some of its libraries. I'm also open to hear suggestions if installing programming languages locally on the machine isn't the proper way to manage software dependencies, or if there's a most convenient way to do it aside from creating a script.</p>
<p>Sorry if any needed information is missing, I would also like to know.</p>
<p>Thanks in advance</p>
",102,0,0,4,r;windows;installation;dependencies,2022-03-04 19:35:08,2022-03-04 19:35:08,2022-04-19 20:50:29,i m currently working on an university research related software which uses statistical models in it in order to process some calculations around item response theory  the entire source code was written in go  whereas it communicates with a rscript server to run scripts written in r and return the generated results  as expected  the software itself has some dependencies needed to work properly  one of them  as seen before  is to have r rscript installed and some of its packages   due to the fact i m new to software development  i can t find a proper way to manage all these dependencies on windows or linux  but i m prioritizing windows right now   what i was thinking is to have a kind of script which checks if  for example  r is properly installed and  if so  if each used package is also installed  if everything went well  then the software could be installed without further problems  my question is what s the best way to do anything like that and if it s possible to do the same for other possible dependencies  such as python  go and some of its libraries  i m also open to hear suggestions if installing programming languages locally on the machine isn t the proper way to manage software dependencies  or if there s a most convenient way to do it aside from creating a script  sorry if any needed information is missing  i would also like to know  thanks in advance,correct way to create a software install script which can manage dependencies
325,341750,8481396,Should one leave asserts in production iOS apps?,"<p>Common practice might be to put asserts in code to check input parameters, data integrity, and such, during app development.</p>
<p>I test my apps, BUT, given that I'm not Knuth (and <strong>he</strong> writes $1 checks), and I can't afford to employ a large team of full-time QA people as do some medical and space systems software companies, I assume that all my apps will always have plenty of bugs that have never yet been seen during testing or QA.  Assuming otherwise seems quite intellectually dishonest.  So after testing an app (and obviously removing all bugs causing any previously seen ASSERT failures) and getting the app ready to ship to Apple, what should be done with all the ASSERT checks in the Release/Distribution build?  Leave or no-op?</p>
<p>Here's one rationale for leaving them in:  If an app acts wonky for some users, the app might get rated by those users as 1-Star without anyone ever telling the developer why in sufficient detail.  But if the app crashes from an ASSERT failure, the app might still get rated 1-Star, but the developer could potentially get some crash dumps, indirectly via iTunes and iTunes Connect if enough users opts in, to figure out what is going wrong.  And if the app gets rejected by Apple due to a brand new ASSERT crash, that will prevent a bad version of the app from ever getting onto one's customer's devices.</p>
",10343,4,10,3,ios;iphone;assert,2011-12-12 23:52:11,2011-12-12 23:52:11,2022-04-19 20:48:56,common practice might be to put asserts in code to check input parameters  data integrity  and such  during app development  i test my apps  but  given that i m not knuth  and he writes   checks   and i can t afford to employ a large team of full time qa people as do some medical and space systems software companies  i assume that all my apps will always have plenty of bugs that have never yet been seen during testing or qa   assuming otherwise seems quite intellectually dishonest   so after testing an app  and obviously removing all bugs causing any previously seen assert failures  and getting the app ready to ship to apple  what should be done with all the assert checks in the release distribution build   leave or no op  here s one rationale for leaving them in   if an app acts wonky for some users  the app might get rated by those users as  star without anyone ever telling the developer why in sufficient detail   but if the app crashes from an assert failure  the app might still get rated  star  but the developer could potentially get some crash dumps  indirectly via itunes and itunes connect if enough users opts in  to figure out what is going wrong   and if the app gets rejected by apple due to a brand new assert crash  that will prevent a bad version of the app from ever getting onto one s customer s devices ,should one leave asserts in production ios apps 
326,755666,68911835,NestJS Testing ConfigService works,"<p>I am writing an application to handle requests and return predefined responses to allow testing of external REST endpoints by software that cannot have internal tests written into it currently.  Therefore, my code uses the Nest JS framework to handle the routes, and then extracts values and returns data.  The data returned is stored in external files.</p>
<p>To handle constant changes and different team usage, the program uses a .env file to give the base (root) directory where the files to respond are located.  I am trying to write a test case to ensure that the NestJS ConfigService is working properly, but also to use as a base for all my other tests.</p>
<p>With different routes, different data files need to be returned.  My code will need to mock all these files.  As this data relies on the base ConfigService having read the .env to find the base paths, my routes are based on this starting point.</p>
<p>During development, I have a local .env file with these values set.  However, I want to test without this .env file being used, so my tests do not rely on the presence of the .env file, since the CI/CD server, build server, etc., will not have a .env file.</p>
<p>I am simply trying a test file then to work with the configuration, to get set data from my mock.</p>
<p>nestjs-config.service.spec.ts</p>
<pre><code>import { Test, TestingModule } from '@nestjs/testing';
import { ConfigModule, ConfigService } from '@nestjs/config';

describe('NestJS Configuration .env', () =&gt; {
    let service: ConfigService;

    beforeEach(async () =&gt; {
        const module: TestingModule = await Test.createTestingModule({
            imports: [
                ConfigModule.forRoot({
                    expandVariables: true,
                }),
            ],
            providers: [
                {
                    provide: ConfigService,
                    useValue: {
                        get: jest.fn((key: string) =&gt; {
                            if (key === 'FILES') {
                                return './fakedata/';
                            } else if (key === 'PORT') {
                                return '9999';
                            }
                            return null;
                        }),
                    },
                },
            ],
        }).compile();

        service = module.get&lt;ConfigService&gt;(ConfigService);
    });

    it('should be defined', () =&gt; {
        expect(service).toBeDefined();
    });

    it.each([
        ['FILES=', 'FILES', './', './fakedata/'],
        ['PORT=', 'PORT', '2000', '9999'],
        ['default value when key is not found', 'NOTFOUND', './', './'],
    ])('should get from the .env file, %s', (Text: string, Key: string, Default: string, Expected: string) =&gt; {
        const Result: string = service.get&lt;string&gt;(Key, Default);
        expect(Key).toBeDefined();
        expect(Result).toBe(Expected);
    });
});
</code></pre>
<p>The problem in this test is the default values are always returned, meaning the .env file was not read, but the provider had the code to handle this.</p>
<p>Ideally, I would like to create a fake class for testing so I could use it in all my test files. However, when trying to create the fake class, I get an error about other methods missing, that are unrelated to this class.</p>
<pre><code>export class ConfigServiceFake {
    get(key: string) {
        switch (key) {
            case 'FILES':
                return './fakedata/';
            case 'PORT':
                return '9999';
        }
    }
}
</code></pre>
<p>This does not seem to execute, and it appears to still go through the original service.</p>
",1000,1,0,3,testing;mocking;nestjs,2021-08-24 20:41:44,2021-08-24 20:41:44,2022-04-19 19:35:03,i am writing an application to handle requests and return predefined responses to allow testing of external rest endpoints by software that cannot have internal tests written into it currently   therefore  my code uses the nest js framework to handle the routes  and then extracts values and returns data   the data returned is stored in external files  to handle constant changes and different team usage  the program uses a  env file to give the base  root  directory where the files to respond are located   i am trying to write a test case to ensure that the nestjs configservice is working properly  but also to use as a base for all my other tests  with different routes  different data files need to be returned   my code will need to mock all these files   as this data relies on the base configservice having read the  env to find the base paths  my routes are based on this starting point  during development  i have a local  env file with these values set   however  i want to test without this  env file being used  so my tests do not rely on the presence of the  env file  since the ci cd server  build server  etc   will not have a  env file  i am simply trying a test file then to work with the configuration  to get set data from my mock  nestjs config service spec ts the problem in this test is the default values are always returned  meaning the  env file was not read  but the provider had the code to handle this  ideally  i would like to create a fake class for testing so i could use it in all my test files  however  when trying to create the fake class  i get an error about other methods missing  that are unrelated to this class  this does not seem to execute  and it appears to still go through the original service ,nestjs testing configservice works
327,244413,54903381,kafka failed authentication due to: SSL handshake failed,"<p>I have to add encryption and authentication with SSL in kafka.</p>

<p>This is what I have done:</p>

<ol>
<li><p>Generate certificate for each broker kafka:</p>

<p><code>keytool -keystore server.keystore.jks -alias localhost -validity 365 -genkey</code></p></li>
<li><p>Create CA. The generated CA is a public-private key pair and certificate <strong>used to sign other certificates</strong>. A CA is responsible for signing certificates. </p>

<p><code>openssl req -new -x509 -keyout ca-key -out ca-cert -days 365</code></p></li>
<li><p>Sign all brokers certificates with the generated CA
Export the certificate from the keystore: </p>

<p><code>keytool -keystore server.keystore.jks -alias localhost -certreq -file cert-file</code></p>

<p>Sign it with the CA: </p>

<p><code>openssl x509 -req -CA ca-cert -CAkey ca-key -in cert-file -out cert-signed -days {validity} -CAcreateserial -passin pass:{ca-password}</code></p></li>
<li><p>Import both the certificate of the CA and the signed certificate into the keystore:</p>

<p><code>keytool -keystore server.keystore.jks -alias CARoot -import -file ca-cert</code></p>

<p><code>keytool -keystore server.keystore.jks -alias localhost -import -file cert-signed</code></p></li>
<li><p>Import CA to client truststore and broker/server truststore:</p>

<p><code>keytool -keystore server.truststore.jks -alias CARoot -import -file ca-cert</code>
<code>keytool -keystore client.truststore.jks -alias CARoot -import -file ca-cert</code></p></li>
<li><p>Add these line in the configuration server.properties:
<code>listeners=PLAINTEXT://localhost:9092, SSL://localhost:9192
ssl.client.auth=required
ssl.keystore.location=/home/xrobot/kafka_2.12-2.1.0/certificate/server.keystore.jks
ssl.keystore.password=blablabla
ssl.key.password=blablabla
ssl.truststore.location=/home/xrobot/kafka_2.12-2.1.0/certificate/server.truststore.jks
ssl.truststore.password=blablabla
security.inter.broker.protocol=SSL</code></p></li>
</ol>

<p>The problem is that when I start kafka, then I get this error:</p>

<pre><code>[2019-02-26 19:03:59,783] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-02-26 19:04:00,011] ERROR [Controller id=0, targetBrokerId=0] Connection to node 0 (localhost/127.0.0.1:9192) failed authentication due to: SSL handshake failed (org.apache.kafka.clients.NetworkClient)
[2019-02-26 19:04:00,178] ERROR [Controller id=0, targetBrokerId=0] Connection to node 0 (localhost/127.0.0.1:9192) failed authentication due to: SSL handshake failed (org.apache.kafka.clients.NetworkClient)
[2019-02-26 19:04:00,319] ERROR [Controller id=0, targetBrokerId=0] Connection to node 0 (localhost/127.0.0.1:9192) failed authentication due to: SSL handshake failed (org.apache.kafka.clients.NetworkClient)
</code></pre>

<p>Why?</p>

<p>EDIT:
<strong>server.properties:</strong></p>

<pre><code># Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# see kafka.server.KafkaConfig for additional details and defaults

############################# Server Basics #############################

# The id of the broker. This must be set to a unique integer for each broker.
broker.id=0

############################# Socket Server Settings #############################

# The address the socket server listens on. It will get the value returned from 
# java.net.InetAddress.getCanonicalHostName() if not configured.
#   FORMAT:
#     listeners = listener_name://host_name:port
#   EXAMPLE:
#     listeners = PLAINTEXT://your.host.name:9092

listeners=PLAINTEXT://localhost:9092, SSL://localhost:9192

ssl.client.auth=required
ssl.keystore.location=/home/xrobot/kafka_2.12-2.1.0/certificate/server.keystore.jks
ssl.keystore.password=onailime
ssl.key.password=onailime
ssl.truststore.location=/home/xrobot/kafka_2.12-2.1.0/certificate/server.truststore.jks
ssl.truststore.password=onailime

security.inter.broker.protocol=SSL

# Hostname and port the broker will advertise to producers and consumers. If not set, 
# it uses the value for ""listeners"" if configured.  Otherwise, it will use the value
# returned from java.net.InetAddress.getCanonicalHostName().
#advertised.listeners=PLAINTEXT://your.host.name:9092

# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details
#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL

# The number of threads that the server uses for receiving requests from the network and sending responses to the network
num.network.threads=3

# The number of threads that the server uses for processing requests, which may include disk I/O
num.io.threads=8

# The send buffer (SO_SNDBUF) used by the socket server
socket.send.buffer.bytes=102400

# The receive buffer (SO_RCVBUF) used by the socket server
socket.receive.buffer.bytes=102400

# The maximum size of a request that the socket server will accept (protection against OOM)
socket.request.max.bytes=104857600


############################# Log Basics #############################

# A comma separated list of directories under which to store log files
log.dirs=/home/xrobot/kafka_2.12-2.1.0/data/kafka

# The default number of log partitions per topic. More partitions allow greater
# parallelism for consumption, but this will also result in more files across
# the brokers.
num.partitions=1

# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.
# This value is recommended to be increased for installations with data dirs located in RAID array.
num.recovery.threads.per.data.dir=1

############################# Internal Topic Settings  #############################
# The replication factor for the group metadata internal topics ""__consumer_offsets"" and ""__transaction_state""
# For anything other than development testing, a value greater than 1 is recommended for to ensure availability such as 3.
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1

############################# Log Flush Policy #############################

# Messages are immediately written to the filesystem but by default we only fsync() to sync
# the OS cache lazily. The following configurations control the flush of data to disk.
# There are a few important trade-offs here:
#    1. Durability: Unflushed data may be lost if you are not using replication.
#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.
#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.
# The settings below allow one to configure the flush policy to flush data after a period of time or
# every N messages (or both). This can be done globally and overridden on a per-topic basis.

# The number of messages to accept before forcing a flush of data to disk
#log.flush.interval.messages=10000

# The maximum amount of time a message can sit in a log before we force a flush
#log.flush.interval.ms=1000

############################# Log Retention Policy #############################

# The following configurations control the disposal of log segments. The policy can
# be set to delete segments after a period of time, or after a given size has accumulated.
# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens
# from the end of the log.

# The minimum age of a log file to be eligible for deletion due to age
log.retention.hours=168

# A size-based retention policy for logs. Segments are pruned from the log unless the remaining
# segments drop below log.retention.bytes. Functions independently of log.retention.hours.
#log.retention.bytes=1073741824

# The maximum size of a log segment file. When this size is reached a new log segment will be created.
log.segment.bytes=1073741824

# The interval at which log segments are checked to see if they can be deleted according
# to the retention policies
log.retention.check.interval.ms=300000

############################# Zookeeper #############################

# Zookeeper connection string (see zookeeper docs for details).
# This is a comma separated host:port pairs, each corresponding to a zk
# server. e.g. ""127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002"".
# You can also append an optional chroot string to the urls to specify the
# root directory for all kafka znodes.
zookeeper.connect=localhost:2181

# Timeout in ms for connecting to zookeeper
zookeeper.connection.timeout.ms=6000


############################# Group Coordinator Settings #############################

# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.
# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.
# The default value for this is 3 seconds.
# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.
# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.
group.initial.rebalance.delay.ms=0
</code></pre>

<p><strong>zookeeper.properties:</strong></p>

<pre><code># Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
# 
#    http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# the directory where the snapshot is stored.
dataDir=/home/xrobot/kafka_2.12-2.1.0/data/zookeeper
# the port at which the clients will connect
clientPort=2181
# disable the per-ip limit on the number of connections since this is a non-production config
maxClientCnxns=0
</code></pre>
",47483,3,21,3,apache-kafka;kafka-consumer-api;kafka-producer-api,2019-02-27 12:32:10,2019-02-27 12:32:10,2022-04-19 18:05:20,i have to add encryption and authentication with ssl in kafka  this is what i have done  generate certificate for each broker kafka  keytool  keystore server keystore jks  alias localhost  validity   genkey create ca  the generated ca is a public private key pair and certificate used to sign other certificates  a ca is responsible for signing certificates   openssl req  new  x  keyout ca key  out ca cert  days  keytool  keystore server keystore jks  alias localhost  certreq  file cert file sign it with the ca   openssl x  req  ca ca cert  cakey ca key  in cert file  out cert signed  days  validity   cacreateserial  passin pass  ca password  import both the certificate of the ca and the signed certificate into the keystore  keytool  keystore server keystore jks  alias caroot  import  file ca cert keytool  keystore server keystore jks  alias localhost  import  file cert signed import ca to client truststore and broker server truststore  the problem is that when i start kafka  then i get this error  why  zookeeper properties ,kafka failed authentication due to  ssl handshake failed
328,9628342,56696940,how to install face_recognition module for python,"<p>i have installed the cmake but still dlib is not installing which is required for the installation of face_recognition module</p>

<p>the below mentioned error i am getting whenever i try to install the dlib by using the pip install dlib</p>

<pre><code>ERROR: Complete output from command 'c:\users\sunil\appdata\local\programs\python\python37\python.exe' -u -c 'import setuptools, tokenize;__file__='""'""'C:\\Users\\sunil\\AppData\\Local\\Temp\\pip-install-oufh_gcl\\dlib\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\sunil\AppData\Local\Temp\pip-wheel-2fd_0qt9' --python-tag cp37:
  ERROR: running bdist_wheel
  running build
  running build_py
  package init file 'dlib\__init__.py' not found (or not a regular file)
  running build_ext
  Building extension for Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)]
  Invoking CMake setup: 'cmake C:\Users\sunil\AppData\Local\Temp\pip-install-oufh_gcl\dlib\tools\python -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=C:\Users\sunil\AppData\Local\Temp\pip-install-oufh_gcl\dlib\build\lib.win-amd64-3.7 -DPYTHON_EXECUTABLE=c:\users\sunil\appdata\local\programs\python\python37\python.exe -DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELEASE=C:\Users\sunil\AppData\Local\Temp\pip-install-oufh_gcl\dlib\build\lib.win-amd64-3.7 -A x64'
  -- Building for: NMake Makefiles
  CMake Error in CMakeLists.txt:
    Generator

      NMake Makefiles

    does not support platform specification, but platform

      x64

    was specified.


  CMake Error: CMAKE_C_COMPILER not set, after EnableLanguage
  CMake Error: CMAKE_CXX_COMPILER not set, after EnableLanguage
  -- Configuring incomplete, errors occurred!
  See also ""C:/Users/sunil/AppData/Local/Temp/pip-install-oufh_gcl/dlib/build/temp.win-amd64-3.7/Release/CMakeFiles/CMakeOutput.log"".
  Traceback (most recent call last):
    File ""&lt;string&gt;"", line 1, in &lt;module&gt;
    File ""C:\Users\sunil\AppData\Local\Temp\pip-install-oufh_gcl\dlib\setup.py"", line 261, in &lt;module&gt;
      'Topic :: Software Development',
    File ""c:\users\sunil\appdata\local\programs\python\python37\lib\site-packages\setuptools\__init__.py"", line 129, in setup
      return distutils.core.setup(**attrs)
    File ""c:\users\sunil\appdata\local\programs\python\python37\lib\distutils\core.py"", line 148, in setup
      dist.run_commands()
    File ""c:\users\sunil\appdata\local\programs\python\python37\lib\distutils\dist.py"", line 966, in run_commands
      self.run_command(cmd)
    File ""c:\users\sunil\appdata\local\programs\python\python37\lib\distutils\dist.py"", line 985, in run_command
      cmd_obj.run()
    File ""c:\users\sunil\appdata\local\programs\python\python37\lib\site-packages\wheel\bdist_wheel.py"", line 192, in run
      self.run_command('build')
    File ""c:\users\sunil\appdata\local\programs\python\python37\lib\distutils\cmd.py"", line 313, in run_command
      self.distribution.run_command(command)
    File ""c:\users\sunil\appdata\local\programs\python\python37\lib\distutils\dist.py"", line 985, in run_command
      cmd_obj.run()
    File ""c:\users\sunil\appdata\local\programs\python\python37\lib\distutils\command\build.py"", line 135, in run
      self.run_command(cmd_name)
    File ""c:\users\sunil\appdata\local\programs\python\python37\lib\distutils\cmd.py"", line 313, in run_command
      self.distribution.run_command(command)
    File ""c:\users\sunil\appdata\local\programs\python\python37\lib\distutils\dist.py"", line 985, in run_command
      cmd_obj.run()
    File ""C:\Users\sunil\AppData\Local\Temp\pip-install-oufh_gcl\dlib\setup.py"", line 135, in run
      self.build_extension(ext)
    File ""C:\Users\sunil\AppData\Local\Temp\pip-install-oufh_gcl\dlib\setup.py"", line 172, in build_extension
      subprocess.check_call(cmake_setup, cwd=build_folder)
    File ""c:\users\sunil\appdata\local\programs\python\python37\lib\subprocess.py"", line 328, in check_call
      raise CalledProcessError(retcode, cmd)
  subprocess.CalledProcessError: Command '['cmake', 'C:\\Users\\sunil\\AppData\\Local\\Temp\\pip-install-oufh_gcl\\dlib\\tools\\python', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY=C:\\Users\\sunil\\AppData\\Local\\Temp\\pip-install-oufh_gcl\\dlib\\build\\lib.win-amd64-3.7', '-DPYTHON_EXECUTABLE=c:\\users\\sunil\\appdata\\local\\programs\\python\\python37\\python.exe', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELEASE=C:\\Users\\sunil\\AppData\\Local\\Temp\\pip-install-oufh_gcl\\dlib\\build\\lib.win-amd64-3.7', '-A', 'x64']' returned non-zero exit status 1.
  ----------------------------------------
  ERROR: Failed building wheel for dlib
  Running setup.py clean for dlib
Failed to build dlib
Installing collected packages: dlib
  Running setup.py install for dlib ... error
    ERROR: Complete output from command 'c:\users\sunil\appdata\local\programs\python\python37\python.exe' -u -c 'import setuptools, tokenize;__file__='""'""'C:\\Users\\sunil\\AppData\\Local\\Temp\\pip-install-oufh_gcl\\dlib\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\sunil\AppData\Local\Temp\pip-record-89jcoq15\install-record.txt' --single-version-externally-managed --compile:
    ERROR: running install
    running build
    running build_py
    package init file 'dlib\__init__.py' not found (or not a regular file)
    running build_ext
    Building extension for Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)]
    Invoking CMake setup: 'cmake C:\Users\sunil\AppData\Local\Temp\pip-install-oufh_gcl\dlib\tools\python -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=C:\Users\sunil\AppData\Local\Temp\pip-install-oufh_gcl\dlib\build\lib.win-amd64-3.7 -DPYTHON_EXECUTABLE=c:\users\sunil\appdata\local\programs\python\python37\python.exe -DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELEASE=C:\Users\sunil\AppData\Local\Temp\pip-install-oufh_gcl\dlib\build\lib.win-amd64-3.7 -A x64'
    -- Building for: NMake Makefiles
    CMake Error in CMakeLists.txt:
      Generator

        NMake Makefiles

      does not support platform specification, but platform

        x64

      was specified.


    CMake Error: CMAKE_C_COMPILER not set, after EnableLanguage
    CMake Error: CMAKE_CXX_COMPILER not set, after EnableLanguage
    -- Configuring incomplete, errors occurred!
    See also ""C:/Users/sunil/AppData/Local/Temp/pip-install-oufh_gcl/dlib/build/temp.win-amd64-3.7/Release/CMakeFiles/CMakeOutput.log"".
    Traceback (most recent call last):
      File ""&lt;string&gt;"", line 1, in &lt;module&gt;
      File ""C:\Users\sunil\AppData\Local\Temp\pip-install-oufh_gcl\dlib\setup.py"", line 261, in &lt;module&gt;
        'Topic :: Software Development',
      File ""c:\users\sunil\appdata\local\programs\python\python37\lib\site-packages\setuptools\__init__.py"", line 129, in setup
        return distutils.core.setup(**attrs)
      File ""c:\users\sunil\appdata\local\programs\python\python37\lib\distutils\core.py"", line 148, in setup
        dist.run_commands()
      File ""c:\users\sunil\appdata\local\programs\python\python37\lib\distutils\dist.py"", line 966, in run_commands
        self.run_command(cmd)
      File ""c:\users\sunil\appdata\local\programs\python\python37\lib\distutils\dist.py"", line 985, in run_command
        cmd_obj.run()
      File ""c:\users\sunil\appdata\local\programs\python\python37\lib\site-packages\setuptools\command\install.py"", line 61, in run
        return orig.install.run(self)
      File ""c:\users\sunil\appdata\local\programs\python\python37\lib\distutils\command\install.py"", line 545, in run
        self.run_command('build')
      File ""c:\users\sunil\appdata\local\programs\python\python37\lib\distutils\cmd.py"", line 313, in run_command
        self.distribution.run_command(command)
      File ""c:\users\sunil\appdata\local\programs\python\python37\lib\distutils\dist.py"", line 985, in run_command
        cmd_obj.run()
      File ""c:\users\sunil\appdata\local\programs\python\python37\lib\distutils\command\build.py"", line 135, in run
        self.run_command(cmd_name)
      File ""c:\users\sunil\appdata\local\programs\python\python37\lib\distutils\cmd.py"", line 313, in run_command
        self.distribution.run_command(command)
      File ""c:\users\sunil\appdata\local\programs\python\python37\lib\distutils\dist.py"", line 985, in run_command
        cmd_obj.run()
      File ""C:\Users\sunil\AppData\Local\Temp\pip-install-oufh_gcl\dlib\setup.py"", line 135, in run
        self.build_extension(ext)
      File ""C:\Users\sunil\AppData\Local\Temp\pip-install-oufh_gcl\dlib\setup.py"", line 172, in build_extension
        subprocess.check_call(cmake_setup, cwd=build_folder)
      File ""c:\users\sunil\appdata\local\programs\python\python37\lib\subprocess.py"", line 328, in check_call
        raise CalledProcessError(retcode, cmd)
    subprocess.CalledProcessError: Command '['cmake', 'C:\\Users\\sunil\\AppData\\Local\\Temp\\pip-install-oufh_gcl\\dlib\\tools\\python', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY=C:\\Users\\sunil\\AppData\\Local\\Temp\\pip-install-oufh_gcl\\dlib\\build\\lib.win-amd64-3.7', '-DPYTHON_EXECUTABLE=c:\\users\\sunil\\appdata\\local\\programs\\python\\python37\\python.exe', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELEASE=C:\\Users\\sunil\\AppData\\Local\\Temp\\pip-install-oufh_gcl\\dlib\\build\\lib.win-amd64-3.7', '-A', 'x64']' returned non-zero exit status 1.
    ----------------------------------------
ERROR: Command ""'c:\users\sunil\appdata\local\programs\python\python37\python.exe' -u -c 'import setuptools, tokenize;__file__='""'""'C:\\Users\\sunil\\AppData\\Local\\Temp\\pip-install-oufh_gcl\\dlib\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\sunil\AppData\Local\Temp\pip-record-89jcoq15\install-record.txt' --single-version-externally-managed --compile"" failed with error code 1 in C:\Users\sunil\AppData\Local\Temp\pip-install-oufh_gcl\dlib\
</code></pre>

<p>can anyone tell me the easiest way to install the face_recognition module for my windows 10</p>
",18677,8,2,5,python;cmake;pip;face-recognition;dlib,2019-06-21 07:41:01,2019-06-21 07:41:01,2022-04-19 10:47:30,i have installed the cmake but still dlib is not installing which is required for the installation of face_recognition module the below mentioned error i am getting whenever i try to install the dlib by using the pip install dlib can anyone tell me the easiest way to install the face_recognition module for my windows ,how to install face_recognition module for python
329,1267275,43936483,Eclipse export/print contents of debug variable,"<p>I use Eclipse for embedded project development (C language). I debug my project and in Expressions window I have an array (1024 x 2 integer elements). I want to export contents of this array to clipboard/file so I can process the data from the array in another software. Is that possible?</p>
",1335,2,1,1,eclipse,2017-05-12 14:15:26,2017-05-12 14:15:26,2022-04-18 23:31:20,i use eclipse for embedded project development  c language   i debug my project and in expressions window i have an array   x  integer elements   i want to export contents of this array to clipboard file so i can process the data from the array in another software  is that possible ,eclipse export print contents of debug variable
330,18469611,71913868,Page not reading CSS files for some ungodly reason,"<p>Ok, so I recently had an SEO audit done on my site and per the recommendations I added the Geo.txt, robots.txt, Schema.txt and sitemap.xml files to my root directory (not sure exactly if this is where these files go...) And now for some reason my page displays like there is no CSS file at all.  Could adding one of these files affect that?  Do I need to add the path to my CSS to one of the files?  I will add my header section below.</p>
<pre><code>   &lt;head&gt;
    &lt;!-- Global site tag (gtag.js) - Google Analytics --&gt;
    &lt;script async src=&quot;https://www.googletagmanager.com/gtag/js?id=G-L6BBJ36NQR&quot;&gt;&lt;/script&gt;
    &lt;script&gt;
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-L6BBJ36NQR');
    &lt;/script&gt;

    &lt;asp:ContentPlaceHolder ID=&quot;contentHead&quot; runat=&quot;server&quot;&gt;

    &lt;/asp:ContentPlaceHolder&gt;

    &lt;meta charset=&quot;utf-8&quot;&gt;
    &lt;meta http-equiv=&quot;x-ua-compatible&quot; content=&quot;ie=edge&quot;&gt;
    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot; /&gt;
    &lt;meta name=&quot;keywords&quot; content=&quot;Web Development Erie PA Application Custom Software Northwest PA&quot; /&gt;
    &lt;link rel=&quot;manifest&quot; href=&quot;site.webmanifest&quot; /&gt;
    &lt;link rel=&quot;shortcut icon&quot; type=&quot;image/x-icon&quot; href=&quot;assets/img/favicon.ico&quot; /&gt;

    &lt;!-- CSS here --&gt;
    &lt;link href=&quot;&quot; rel=&quot;stylesheet&quot; /&gt;
    &lt;link rel=&quot;stylesheet&quot; href=&quot;assets/css/bootstrap.min.css&quot; /&gt;
    &lt;link rel=&quot;stylesheet&quot; href=&quot;assets/css/owl.carousel.min.css&quot; /&gt;
    &lt;link rel=&quot;stylesheet&quot; href=&quot;assets/css/slicknav.css&quot; /&gt;
    &lt;link rel=&quot;stylesheet&quot; href=&quot;assets/css/flaticon.css&quot; /&gt;
    &lt;link rel=&quot;stylesheet&quot; href=&quot;assets/css/progressbar_barfiller.css&quot; /&gt;
    &lt;link rel=&quot;stylesheet&quot; href=&quot;assets/css/gijgo.css&quot; /&gt;
    &lt;link rel=&quot;stylesheet&quot; href=&quot;assets/css/animate.min.css&quot; /&gt;
    &lt;link rel=&quot;stylesheet&quot; href=&quot;assets/css/animated-headline.css&quot; /&gt;
    &lt;link rel=&quot;stylesheet&quot; href=&quot;assets/css/magnific-popup.css&quot; /&gt;
    &lt;link rel=&quot;stylesheet&quot; href=&quot;assets/css/themify-icons.css&quot; /&gt;
    &lt;link rel=&quot;stylesheet&quot; href=&quot;assets/css/slick.css&quot; /&gt;
    &lt;link rel=&quot;stylesheet&quot; href=&quot;assets/css/nice-select.css&quot; /&gt;
    &lt;link rel=&quot;stylesheet&quot; href=&quot;assets/css/style.css&quot; /&gt;
    

&lt;/head&gt;
</code></pre>
<p>The page is supposed to look like this:</p>
<p><a href=""https://i.stack.imgur.com/6Bunq.png"" rel=""nofollow noreferrer"">Proper site look</a></p>
<p>But instead it looks like this:</p>
<p><a href=""https://i.stack.imgur.com/jC3YS.png"" rel=""nofollow noreferrer"">Wrong site look</a></p>
",34,0,0,3,c#;html;.net,2022-04-18 18:34:57,2022-04-18 18:34:57,2022-04-18 18:34:57,ok  so i recently had an seo audit done on my site and per the recommendations i added the geo txt  robots txt  schema txt and sitemap xml files to my root directory  not sure exactly if this is where these files go     and now for some reason my page displays like there is no css file at all   could adding one of these files affect that   do i need to add the path to my css to one of the files   i will add my header section below  the page is supposed to look like this   but instead it looks like this  ,page not reading css files for some ungodly reason
331,1431660,23296655,How to do live self monitoring inside the application,"<p>We are applying unittests, integration tests and we are practicing test driven and behaviour driven development.</p>
<p>We are also monitoring our applications and servers from outside (with dedicated software in our network)</p>
<p>What is missing is some standard for a live monitoring inside the apllication.</p>
<p>I give an example:</p>
<p>There should be a cron-like process inside the application, that regularily checks some structural health inside our data structures</p>
<p>We need to monitor that users have done some regular stuff that does not endanger the health of the applications (there are some actions and input that we can not prevent them  to do)</p>
<p>My question is, what is the correct name for this so I can further research in the literature. I did a lot of searching but I almosdt always find the xunit and bdd / integration test stuff that I already have.</p>
<p>So how is this called, what is the standard in professional application development, I  would like to know if there is some standard structure like <code>xunit</code>, or could xunit libraries even bee used for it? I could not even find appropriate tagging for this question, so please if you read this and know some better tags, why not add them to this answer and remove the ones that don't fit.</p>
<p>I need this for applications written in python, erlang or javascript and those are mostly server side applications, web applications or daemons.</p>
<p>What we are already doing is that we created http gateway from inside the applications that report some stuff and this is monitored by the nagios infrastructure.</p>
<p>I have no problem rolling some cron-like controlled self health scheme inside the applications, but I am interested about knowing some professional standardized way of doing it.</p>
<p>I found this article, it already comes close: <a href=""https://ieeexplore.ieee.org/document/6300158"" rel=""nofollow noreferrer"">Link</a></p>
",115,1,0,2,automated-tests;unit-testing,2014-04-19 19:00:53,2014-04-19 19:00:53,2022-04-18 14:05:52,we are applying unittests  integration tests and we are practicing test driven and behaviour driven development  we are also monitoring our applications and servers from outside  with dedicated software in our network  what is missing is some standard for a live monitoring inside the apllication  i give an example  there should be a cron like process inside the application  that regularily checks some structural health inside our data structures we need to monitor that users have done some regular stuff that does not endanger the health of the applications  there are some actions and input that we can not prevent them  to do  my question is  what is the correct name for this so i can further research in the literature  i did a lot of searching but i almosdt always find the xunit and bdd   integration test stuff that i already have  so how is this called  what is the standard in professional application development  i  would like to know if there is some standard structure like xunit  or could xunit libraries even bee used for it  i could not even find appropriate tagging for this question  so please if you read this and know some better tags  why not add them to this answer and remove the ones that don t fit  i need this for applications written in python  erlang or javascript and those are mostly server side applications  web applications or daemons  what we are already doing is that we created http gateway from inside the applications that report some stuff and this is monitored by the nagios infrastructure  i have no problem rolling some cron like controlled self health scheme inside the applications  but i am interested about knowing some professional standardized way of doing it  i found this article  it already comes close  ,how to do live self monitoring inside the application
332,17739860,71908074,UML - Where do I start? Do I even need to learn it?,"<p>I'm currently learning to be a developer. When it comes to problem solving, I find myself struggle a lot to understand the problem, it's requirements, how things connect with each other, etc...</p>
<p>Then I stumbled across Mosh Hamedani's design pattern course and found out about UML - The Unified Modelling language, and <em>think</em> to myself <strong>&quot;I need this! This will help me become a better problem solver / developer.&quot;</strong></p>
<p>I really hate the feeling of not knowing what the hell I'm doing. Even a simple example like making a <em>counter</em> app in React. Just keep watching tutorials over and over feels pointless when I lack the fundamental understanding for software development.</p>
<p>So with this post, I want to ask: Will UML help me:</p>
<ol>
<li>Identify / Organize the requirements when building software?</li>
<li>Better Visualization / Understanding Algorithms &amp; Data Structures?</li>
</ol>
<p>With UML, can I:</p>
<ol>
<li>Make diagrams to explain &amp; understand how Algorithms work? (Recursive functions for example).</li>
<li>Make me knowing the entire structure of what I'm going to build, from simple to big complex systems?</li>
</ol>
<p>If UML can do all of those, <em>aside from Video Tutorials from Youtube</em>, where can I find <em><strong>free resources</strong></em> to <strong>learn &amp; master UML</strong>?</p>
<p>Thank you!</p>
",81,1,-2,2,architecture;uml,2022-04-18 08:57:16,2022-04-18 08:57:16,2022-04-18 09:13:50,i m currently learning to be a developer  when it comes to problem solving  i find myself struggle a lot to understand the problem  it s requirements  how things connect with each other  etc    then i stumbled across mosh hamedani s design pattern course and found out about uml   the unified modelling language  and think to myself  i need this  this will help me become a better problem solver   developer   i really hate the feeling of not knowing what the hell i m doing  even a simple example like making a counter app in react  just keep watching tutorials over and over feels pointless when i lack the fundamental understanding for software development  so with this post  i want to ask  will uml help me  with uml  can i  if uml can do all of those  aside from video tutorials from youtube  where can i find free resources to learn  amp  master uml  thank you ,uml   where do i start  do i even need to learn it 
333,17132555,71907713,How to populate a property value with javascript object to a javascript object?,"<p>say I have two arrays:</p>
<pre><code>authors = [
  {
    name: 'Robert Martin',
    id: &quot;afa51ab0-344d-11e9-a414-719c6709cf3e&quot;,
    born: 1952,
  },
  {
    name: 'Martin Fowler',
    id: &quot;afa5b6f0-344d-11e9-a414-719c6709cf3e&quot;,
    born: 1963
  }
]
</code></pre>
<pre><code>let books = [
  {
    title: 'Clean Code',
    published: 2008,
    author: 'Robert Martin',
    id: &quot;afa5b6f4-344d-11e9-a414-719c6709cf3e&quot;,
    genres: ['refactoring']
  },
  {
    title: 'Agile software development',
    published: 2002,
    author: 'Robert Martin',
    id: &quot;afa5b6f5-344d-11e9-a414-719c6709cf3e&quot;,
    genres: ['agile', 'patterns', 'design']
  },
  {
    title: 'Refactoring, edition 2',
    published: 2018,
    author: 'Martin Fowler',
    id: &quot;afa5de00-344d-11e9-a414-719c6709cf3e&quot;,
    genres: ['refactoring']
  }
]
</code></pre>
<p>const Book = require('./controllers/book')</p>
<p>const Author = require('./controllers/author')</p>
<p>using mongoose object schema, book object's author property wants to be populated with complete author object if book.author === author.name.</p>
<p>like this:</p>
<pre><code>{
    title: 'Clean Code',
    published: 2008,
    author: {
               name: 'Robert Martin',
               id: &quot;afa51ab0-344d-11e9-a414-719c6709cf3e&quot;,
               born: 1952,
               },
    id: &quot;afa5b6f4-344d-11e9-a414-719c6709cf3e&quot;,
    genres: ['refactoring']
  },

</code></pre>
<p>I have tried this:</p>
<pre><code>books.forEach(book =&gt; {
const bookAuthor = authors.find(author =&gt; book.author === author.name).name
Book.findOne({author: bookAuthor}).populate('author') }
</code></pre>
<p>no success, somehow js is hard to manipulate data structure on the fly than Python I feel. Could you help?</p>
",42,0,0,4,javascript;mongoose;properties;populate,2022-04-18 07:55:36,2022-04-18 07:55:36,2022-04-18 07:55:36,say i have two arrays  const book   require    controllers book   const author   require    controllers author   using mongoose object schema  book object s author property wants to be populated with complete author object if book author     author name  like this  i have tried this  no success  somehow js is hard to manipulate data structure on the fly than python i feel  could you help ,how to populate a property value with javascript object to a javascript object 
334,5665997,56809106,How to add TLD to search exception in Safari,"<p>How can I add <code>.locahost</code> to the list of TLDs that Safari will <strong>load</strong> — instead of searching — without supplying a protocol? Alternatively (or perhaps additionally), how do I get Safari to stop removing the <code>http://</code> protocol from the URL?</p>

<hr>

<p>I've been using <code>project.localhost</code> to handle local development for a while, now that <code>.dev</code> is no longer a viable development TLD. But I'm getting frustrated with Safari's default behavior. What I'd like to do is prevent Safari from submitting the domain name to the search engine.</p>

<p>Desired:</p>

<ol>
<li>enter <code>project.localhost</code> into address bar</li>
<li>browser loads <code>http://project.localhost</code></li>
</ol>

<p>I would be satisfied with Safari not removing the <code>http://</code> in the address bar, but I can't find a way to do that, either.</p>

<p>What actually happens:</p>

<ol>
<li>enter <code>project.localhost</code> into address bar</li>
<li>browser sends <code>project.localhost</code> to Duck Duck Go</li>
<li>user is tempted to test the ballistic properties of keyboard</li>
</ol>

<p>Or, after I've loaded <code>http://project.localhost</code> and then try to add something after the current URL:</p>

<ol>
<li>click in address bar, URL has been shortened to <code>project.localhost</code></li>
<li>add <code>/test.html</code> to end</li>
<li>browser sends <code>project.localhost/test.html</code> to Duck Duck Go</li>
<li>user considers software violence</li>
</ol>
",565,3,5,3,macos;safari;tld,2019-06-28 17:56:40,2019-06-28 17:56:40,2022-04-18 06:12:21,how can i add  locahost to the list of tlds that safari will load   instead of searching   without supplying a protocol  alternatively  or perhaps additionally   how do i get safari to stop removing the http    protocol from the url  i ve been using project localhost to handle local development for a while  now that  dev is no longer a viable development tld  but i m getting frustrated with safari s default behavior  what i d like to do is prevent safari from submitting the domain name to the search engine  desired  i would be satisfied with safari not removing the http    in the address bar  but i can t find a way to do that  either  what actually happens  or  after i ve loaded http   project localhost and then try to add something after the current url ,how to add tld to search exception in safari
336,18832642,71899148,How to set up my build environment in VSCode,"<p>I currently have my VSCode C++ environment setup using mingw. I'm attempting to start playing with the winsock library, but I'm caught up at creating the build environment, since I've used an IDE for the most part in the past.</p>
<p><strong>Step 2 from Microsofts documentation states:</strong> &quot;Ensure that the build environment refers to the Include, Lib, and Src directories of the Microsoft Windows Software Development Kit (SDK) or the earlier Platform Software Development Kit (SDK).&quot;</p>
<p>Does this just mean to throw these in a folder in the project and #include them somehow?
Then</p>
<p><strong>Step 3 from Microsofts documentation states:</strong> &quot;Ensure that the build environment links to the Winsock Library file Ws2_32.lib. &quot;</p>
<p>Again, I'm not quite sure how to link to the Winsock library file, or if that just means have a folder with it. I'm new to creating projects.</p>
",48,0,0,2,c++;visual-studio-code,2022-04-17 06:50:40,2022-04-17 06:50:40,2022-04-17 12:31:34,i currently have my vscode c   environment setup using mingw  i m attempting to start playing with the winsock library  but i m caught up at creating the build environment  since i ve used an ide for the most part in the past  step  from microsofts documentation states   ensure that the build environment refers to the include  lib  and src directories of the microsoft windows software development kit  sdk  or the earlier platform software development kit  sdk    step  from microsofts documentation states   ensure that the build environment links to the winsock library file ws_ lib    again  i m not quite sure how to link to the winsock library file  or if that just means have a folder with it  i m new to creating projects ,how to set up my build environment in vscode
337,2395630,52256489,Django: ImportError: No module named doc,"<p>here is the traceback </p>

<pre><code>System check identified 1 issue (0 silenced).
September 10, 2018 - 13:01:31
Django version 1.8, using settings 'settings'
Starting development server at http://127.0.0.1:8000/
Quit the server with CONTROL-C.
Traceback (most recent call last):
  File ""/usr/lib/python2.7/wsgiref/handlers.py"", line 85, in run
    self.result = application(self.environ, self.start_response)
  File ""/home/basha/UpgradeMloss/venv1.8/local/lib/python2.7/site-packages/django/core/handlers/wsgi.py"", line 170, in __call__
    self.load_middleware()
  File ""/home/basha/UpgradeMloss/venv1.8/local/lib/python2.7/site-packages/django/core/handlers/base.py"", line 50, in load_middleware
    mw_class = import_string(middleware_path)
  File ""/home/basha/UpgradeMloss/venv1.8/local/lib/python2.7/site-packages/django/utils/module_loading.py"", line 26, in import_string
    module = import_module(module_path)
  File ""/usr/lib/python2.7/importlib/__init__.py"", line 37, in import_module
    __import__(name)
ImportError: No module named doc
</code></pre>

<p>and here is the installed libraries pip freeze:</p>

<pre><code>certifi==2018.8.24
chardet==3.0.4
Django==1.8
django-contrib-comments==1.5
django-markup-deprecated==0.0.3
django-recaptcha2==1.3.0
idna==2.7
Markdown==2.6.11
Pillow==5.2.0
pytz==2018.5
recaptcha-client==1.0.6
requests==2.19.1
urllib3==1.23
</code></pre>

<p>and here is also the INSTALLED_APPS: </p>

<pre><code>INSTALLED_APPS = (
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.sites',
    'django.contrib.admin',
    'django_comments',
    'django.contrib.syndication',
    'django.contrib.flatpages',
    'django.contrib.humanize',
    'software',
    'revision',
    'registration',
    'community',
    'forshow',
    'user',
    'subscriptions2',
    'aggregator',
    'blog',
    'captcha',
    'snowpenguin.django.recaptcha2',
    'markup_deprecated',
)
</code></pre>

<p>I don't know exactly where is the problem or how can I resolve it.
I've been searching about this ImportError but there is nothing talking about such an error.!</p>
",1109,1,1,2,python;django,2018-09-10 14:07:39,2018-09-10 14:07:39,2022-04-16 22:38:33,here is the traceback  and here is the installed libraries pip freeze  and here is also the installed_apps  ,django  importerror  no module named doc
338,18782366,71893588,how to sum total in individual column searchable data table and how to add date range,"<p>this datatable allows individual column search to filter data. now i want to sum subtotal of filtered salary data, Like when the table data will do filter then a auto calculation will be done with filtered data. and also i want to add date-range datepicker, so that i can search from date to date. the subtotal calculation will also work for date picker.</p>
<p>here is my table</p>
<pre><code>&lt;table id=&quot;example&quot; class=&quot;display&quot; style=&quot;width:100%&quot;&gt;
        &lt;thead&gt;
            &lt;tr&gt;
                &lt;th&gt;Name&lt;/th&gt;
                &lt;th&gt;Position&lt;/th&gt;
                &lt;th&gt;Office&lt;/th&gt;
                &lt;th&gt;Age&lt;/th&gt;
                &lt;th&gt;Start date&lt;/th&gt;
                &lt;th&gt;Salary&lt;/th&gt;
            &lt;/tr&gt;
        &lt;/thead&gt;
        &lt;tbody&gt;
            &lt;tr&gt;
                &lt;td&gt;Tiger Nixon&lt;/td&gt;
                &lt;td&gt;System Architect&lt;/td&gt;
                &lt;td&gt;Edinburgh&lt;/td&gt;
                &lt;td&gt;61&lt;/td&gt;
                &lt;td&gt;2011/04/25&lt;/td&gt;
                &lt;td&gt;$320,800&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Garrett Winters&lt;/td&gt;
                &lt;td&gt;Accountant&lt;/td&gt;
                &lt;td&gt;Tokyo&lt;/td&gt;
                &lt;td&gt;63&lt;/td&gt;
                &lt;td&gt;2011/07/25&lt;/td&gt;
                &lt;td&gt;$170,750&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Ashton Cox&lt;/td&gt;
                &lt;td&gt;Junior Technical Author&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;66&lt;/td&gt;
                &lt;td&gt;2009/01/12&lt;/td&gt;
                &lt;td&gt;$86,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Cedric Kelly&lt;/td&gt;
                &lt;td&gt;Senior Javascript Developer&lt;/td&gt;
                &lt;td&gt;Edinburgh&lt;/td&gt;
                &lt;td&gt;22&lt;/td&gt;
                &lt;td&gt;2012/03/29&lt;/td&gt;
                &lt;td&gt;$433,060&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Airi Satou&lt;/td&gt;
                &lt;td&gt;Accountant&lt;/td&gt;
                &lt;td&gt;Tokyo&lt;/td&gt;
                &lt;td&gt;33&lt;/td&gt;
                &lt;td&gt;2008/11/28&lt;/td&gt;
                &lt;td&gt;$162,700&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Brielle Williamson&lt;/td&gt;
                &lt;td&gt;Integration Specialist&lt;/td&gt;
                &lt;td&gt;New York&lt;/td&gt;
                &lt;td&gt;61&lt;/td&gt;
                &lt;td&gt;2012/12/02&lt;/td&gt;
                &lt;td&gt;$372,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Herrod Chandler&lt;/td&gt;
                &lt;td&gt;Sales Assistant&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;59&lt;/td&gt;
                &lt;td&gt;2012/08/06&lt;/td&gt;
                &lt;td&gt;$137,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Rhona Davidson&lt;/td&gt;
                &lt;td&gt;Integration Specialist&lt;/td&gt;
                &lt;td&gt;Tokyo&lt;/td&gt;
                &lt;td&gt;55&lt;/td&gt;
                &lt;td&gt;2010/10/14&lt;/td&gt;
                &lt;td&gt;$327,900&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Colleen Hurst&lt;/td&gt;
                &lt;td&gt;Javascript Developer&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;39&lt;/td&gt;
                &lt;td&gt;2009/09/15&lt;/td&gt;
                &lt;td&gt;$205,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Sonya Frost&lt;/td&gt;
                &lt;td&gt;Software Engineer&lt;/td&gt;
                &lt;td&gt;Edinburgh&lt;/td&gt;
                &lt;td&gt;23&lt;/td&gt;
                &lt;td&gt;2008/12/13&lt;/td&gt;
                &lt;td&gt;$103,600&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Jena Gaines&lt;/td&gt;
                &lt;td&gt;Office Manager&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;30&lt;/td&gt;
                &lt;td&gt;2008/12/19&lt;/td&gt;
                &lt;td&gt;$90,560&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Quinn Flynn&lt;/td&gt;
                &lt;td&gt;Support Lead&lt;/td&gt;
                &lt;td&gt;Edinburgh&lt;/td&gt;
                &lt;td&gt;22&lt;/td&gt;
                &lt;td&gt;2013/03/03&lt;/td&gt;
                &lt;td&gt;$342,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Charde Marshall&lt;/td&gt;
                &lt;td&gt;Regional Director&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;36&lt;/td&gt;
                &lt;td&gt;2008/10/16&lt;/td&gt;
                &lt;td&gt;$470,600&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Haley Kennedy&lt;/td&gt;
                &lt;td&gt;Senior Marketing Designer&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;43&lt;/td&gt;
                &lt;td&gt;2012/12/18&lt;/td&gt;
                &lt;td&gt;$313,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Tatyana Fitzpatrick&lt;/td&gt;
                &lt;td&gt;Regional Director&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;19&lt;/td&gt;
                &lt;td&gt;2010/03/17&lt;/td&gt;
                &lt;td&gt;$385,750&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Michael Silva&lt;/td&gt;
                &lt;td&gt;Marketing Designer&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;66&lt;/td&gt;
                &lt;td&gt;2012/11/27&lt;/td&gt;
                &lt;td&gt;$198,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Paul Byrd&lt;/td&gt;
                &lt;td&gt;Chief Financial Officer (CFO)&lt;/td&gt;
                &lt;td&gt;New York&lt;/td&gt;
                &lt;td&gt;64&lt;/td&gt;
                &lt;td&gt;2010/06/09&lt;/td&gt;
                &lt;td&gt;$725,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Gloria Little&lt;/td&gt;
                &lt;td&gt;Systems Administrator&lt;/td&gt;
                &lt;td&gt;New York&lt;/td&gt;
                &lt;td&gt;59&lt;/td&gt;
                &lt;td&gt;2009/04/10&lt;/td&gt;
                &lt;td&gt;$237,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Bradley Greer&lt;/td&gt;
                &lt;td&gt;Software Engineer&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;41&lt;/td&gt;
                &lt;td&gt;2012/10/13&lt;/td&gt;
                &lt;td&gt;$132,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Dai Rios&lt;/td&gt;
                &lt;td&gt;Personnel Lead&lt;/td&gt;
                &lt;td&gt;Edinburgh&lt;/td&gt;
                &lt;td&gt;35&lt;/td&gt;
                &lt;td&gt;2012/09/26&lt;/td&gt;
                &lt;td&gt;$217,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Jenette Caldwell&lt;/td&gt;
                &lt;td&gt;Development Lead&lt;/td&gt;
                &lt;td&gt;New York&lt;/td&gt;
                &lt;td&gt;30&lt;/td&gt;
                &lt;td&gt;2011/09/03&lt;/td&gt;
                &lt;td&gt;$345,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Yuri Berry&lt;/td&gt;
                &lt;td&gt;Chief Marketing Officer (CMO)&lt;/td&gt;
                &lt;td&gt;New York&lt;/td&gt;
                &lt;td&gt;40&lt;/td&gt;
                &lt;td&gt;2009/06/25&lt;/td&gt;
                &lt;td&gt;$675,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Caesar Vance&lt;/td&gt;
                &lt;td&gt;Pre-Sales Support&lt;/td&gt;
                &lt;td&gt;New York&lt;/td&gt;
                &lt;td&gt;21&lt;/td&gt;
                &lt;td&gt;2011/12/12&lt;/td&gt;
                &lt;td&gt;$106,450&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Doris Wilder&lt;/td&gt;
                &lt;td&gt;Sales Assistant&lt;/td&gt;
                &lt;td&gt;Sydney&lt;/td&gt;
                &lt;td&gt;23&lt;/td&gt;
                &lt;td&gt;2010/09/20&lt;/td&gt;
                &lt;td&gt;$85,600&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Angelica Ramos&lt;/td&gt;
                &lt;td&gt;Chief Executive Officer (CEO)&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;47&lt;/td&gt;
                &lt;td&gt;2009/10/09&lt;/td&gt;
                &lt;td&gt;$1,200,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Gavin Joyce&lt;/td&gt;
                &lt;td&gt;Developer&lt;/td&gt;
                &lt;td&gt;Edinburgh&lt;/td&gt;
                &lt;td&gt;42&lt;/td&gt;
                &lt;td&gt;2010/12/22&lt;/td&gt;
                &lt;td&gt;$92,575&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Jennifer Chang&lt;/td&gt;
                &lt;td&gt;Regional Director&lt;/td&gt;
                &lt;td&gt;Singapore&lt;/td&gt;
                &lt;td&gt;28&lt;/td&gt;
                &lt;td&gt;2010/11/14&lt;/td&gt;
                &lt;td&gt;$357,650&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Brenden Wagner&lt;/td&gt;
                &lt;td&gt;Software Engineer&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;28&lt;/td&gt;
                &lt;td&gt;2011/06/07&lt;/td&gt;
                &lt;td&gt;$206,850&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Fiona Green&lt;/td&gt;
                &lt;td&gt;Chief Operating Officer (COO)&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;48&lt;/td&gt;
                &lt;td&gt;2010/03/11&lt;/td&gt;
                &lt;td&gt;$850,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Shou Itou&lt;/td&gt;
                &lt;td&gt;Regional Marketing&lt;/td&gt;
                &lt;td&gt;Tokyo&lt;/td&gt;
                &lt;td&gt;20&lt;/td&gt;
                &lt;td&gt;2011/08/14&lt;/td&gt;
                &lt;td&gt;$163,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Michelle House&lt;/td&gt;
                &lt;td&gt;Integration Specialist&lt;/td&gt;
                &lt;td&gt;Sydney&lt;/td&gt;
                &lt;td&gt;37&lt;/td&gt;
                &lt;td&gt;2011/06/02&lt;/td&gt;
                &lt;td&gt;$95,400&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Suki Burks&lt;/td&gt;
                &lt;td&gt;Developer&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;53&lt;/td&gt;
                &lt;td&gt;2009/10/22&lt;/td&gt;
                &lt;td&gt;$114,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Prescott Bartlett&lt;/td&gt;
                &lt;td&gt;Technical Author&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;27&lt;/td&gt;
                &lt;td&gt;2011/05/07&lt;/td&gt;
                &lt;td&gt;$145,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Gavin Cortez&lt;/td&gt;
                &lt;td&gt;Team Leader&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;22&lt;/td&gt;
                &lt;td&gt;2008/10/26&lt;/td&gt;
                &lt;td&gt;$235,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Martena Mccray&lt;/td&gt;
                &lt;td&gt;Post-Sales support&lt;/td&gt;
                &lt;td&gt;Edinburgh&lt;/td&gt;
                &lt;td&gt;46&lt;/td&gt;
                &lt;td&gt;2011/03/09&lt;/td&gt;
                &lt;td&gt;$324,050&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Unity Butler&lt;/td&gt;
                &lt;td&gt;Marketing Designer&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;47&lt;/td&gt;
                &lt;td&gt;2009/12/09&lt;/td&gt;
                &lt;td&gt;$85,675&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Howard Hatfield&lt;/td&gt;
                &lt;td&gt;Office Manager&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;51&lt;/td&gt;
                &lt;td&gt;2008/12/16&lt;/td&gt;
                &lt;td&gt;$164,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Hope Fuentes&lt;/td&gt;
                &lt;td&gt;Secretary&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;41&lt;/td&gt;
                &lt;td&gt;2010/02/12&lt;/td&gt;
                &lt;td&gt;$109,850&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Vivian Harrell&lt;/td&gt;
                &lt;td&gt;Financial Controller&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;62&lt;/td&gt;
                &lt;td&gt;2009/02/14&lt;/td&gt;
                &lt;td&gt;$452,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Timothy Mooney&lt;/td&gt;
                &lt;td&gt;Office Manager&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;37&lt;/td&gt;
                &lt;td&gt;2008/12/11&lt;/td&gt;
                &lt;td&gt;$136,200&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Jackson Bradshaw&lt;/td&gt;
                &lt;td&gt;Director&lt;/td&gt;
                &lt;td&gt;New York&lt;/td&gt;
                &lt;td&gt;65&lt;/td&gt;
                &lt;td&gt;2008/09/26&lt;/td&gt;
                &lt;td&gt;$645,750&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Olivia Liang&lt;/td&gt;
                &lt;td&gt;Support Engineer&lt;/td&gt;
                &lt;td&gt;Singapore&lt;/td&gt;
                &lt;td&gt;64&lt;/td&gt;
                &lt;td&gt;2011/02/03&lt;/td&gt;
                &lt;td&gt;$234,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Bruno Nash&lt;/td&gt;
                &lt;td&gt;Software Engineer&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;38&lt;/td&gt;
                &lt;td&gt;2011/05/03&lt;/td&gt;
                &lt;td&gt;$163,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Sakura Yamamoto&lt;/td&gt;
                &lt;td&gt;Support Engineer&lt;/td&gt;
                &lt;td&gt;Tokyo&lt;/td&gt;
                &lt;td&gt;37&lt;/td&gt;
                &lt;td&gt;2009/08/19&lt;/td&gt;
                &lt;td&gt;$139,575&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Thor Walton&lt;/td&gt;
                &lt;td&gt;Developer&lt;/td&gt;
                &lt;td&gt;New York&lt;/td&gt;
                &lt;td&gt;61&lt;/td&gt;
                &lt;td&gt;2013/08/11&lt;/td&gt;
                &lt;td&gt;$98,540&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Finn Camacho&lt;/td&gt;
                &lt;td&gt;Support Engineer&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;47&lt;/td&gt;
                &lt;td&gt;2009/07/07&lt;/td&gt;
                &lt;td&gt;$87,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Serge Baldwin&lt;/td&gt;
                &lt;td&gt;Data Coordinator&lt;/td&gt;
                &lt;td&gt;Singapore&lt;/td&gt;
                &lt;td&gt;64&lt;/td&gt;
                &lt;td&gt;2012/04/09&lt;/td&gt;
                &lt;td&gt;$138,575&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Zenaida Frank&lt;/td&gt;
                &lt;td&gt;Software Engineer&lt;/td&gt;
                &lt;td&gt;New York&lt;/td&gt;
                &lt;td&gt;63&lt;/td&gt;
                &lt;td&gt;2010/01/04&lt;/td&gt;
                &lt;td&gt;$125,250&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Zorita Serrano&lt;/td&gt;
                &lt;td&gt;Software Engineer&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;56&lt;/td&gt;
                &lt;td&gt;2012/06/01&lt;/td&gt;
                &lt;td&gt;$115,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Jennifer Acosta&lt;/td&gt;
                &lt;td&gt;Junior Javascript Developer&lt;/td&gt;
                &lt;td&gt;Edinburgh&lt;/td&gt;
                &lt;td&gt;43&lt;/td&gt;
                &lt;td&gt;2013/02/01&lt;/td&gt;
                &lt;td&gt;$75,650&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Cara Stevens&lt;/td&gt;
                &lt;td&gt;Sales Assistant&lt;/td&gt;
                &lt;td&gt;New York&lt;/td&gt;
                &lt;td&gt;46&lt;/td&gt;
                &lt;td&gt;2011/12/06&lt;/td&gt;
                &lt;td&gt;$145,600&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Hermione Butler&lt;/td&gt;
                &lt;td&gt;Regional Director&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;47&lt;/td&gt;
                &lt;td&gt;2011/03/21&lt;/td&gt;
                &lt;td&gt;$356,250&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Lael Greer&lt;/td&gt;
                &lt;td&gt;Systems Administrator&lt;/td&gt;
                &lt;td&gt;London&lt;/td&gt;
                &lt;td&gt;21&lt;/td&gt;
                &lt;td&gt;2009/02/27&lt;/td&gt;
                &lt;td&gt;$103,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Jonas Alexander&lt;/td&gt;
                &lt;td&gt;Developer&lt;/td&gt;
                &lt;td&gt;San Francisco&lt;/td&gt;
                &lt;td&gt;30&lt;/td&gt;
                &lt;td&gt;2010/07/14&lt;/td&gt;
                &lt;td&gt;$86,500&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Shad Decker&lt;/td&gt;
                &lt;td&gt;Regional Director&lt;/td&gt;
                &lt;td&gt;Edinburgh&lt;/td&gt;
                &lt;td&gt;51&lt;/td&gt;
                &lt;td&gt;2008/11/13&lt;/td&gt;
                &lt;td&gt;$183,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Michael Bruce&lt;/td&gt;
                &lt;td&gt;Javascript Developer&lt;/td&gt;
                &lt;td&gt;Singapore&lt;/td&gt;
                &lt;td&gt;29&lt;/td&gt;
                &lt;td&gt;2011/06/27&lt;/td&gt;
                &lt;td&gt;$183,000&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;Donna Snider&lt;/td&gt;
                &lt;td&gt;Customer Support&lt;/td&gt;
                &lt;td&gt;New York&lt;/td&gt;
                &lt;td&gt;27&lt;/td&gt;
                &lt;td&gt;2011/01/25&lt;/td&gt;
                &lt;td&gt;$112,000&lt;/td&gt;
            &lt;/tr&gt;
        &lt;/tbody&gt;
        &lt;tfoot&gt;
            &lt;tr&gt;
                &lt;th&gt;Name&lt;/th&gt;
                &lt;th&gt;Position&lt;/th&gt;
                &lt;th&gt;Office&lt;/th&gt;
                &lt;th&gt;Age&lt;/th&gt;
                &lt;th&gt;Start date&lt;/th&gt;
                &lt;th&gt;Salary&lt;/th&gt;
            &lt;/tr&gt;
        &lt;/tfoot&gt;
    &lt;/table&gt;

</code></pre>
<p>here is my javascript</p>
<pre><code>$(document).ready(function() {
    // Setup - add a text input to each footer cell
    $('#example tfoot th').each( function () {
        var title = $(this).text();
        $(this).html( '&lt;input type=&quot;text&quot; placeholder=&quot;Search '+title+'&quot; /&gt;' );
    } );
 
    // DataTable
    var table = $('#example').DataTable({
        initComplete: function () {
            // Apply the search
            this.api().columns().every( function () {
                var that = this;
 
                $( 'input', this.footer() ).on( 'keyup change clear', function () {
                    if ( that.search() !== this.value ) {
                        that
                            .search( this.value )
                            .draw();
                    }
                } );
            } );
        }
    });
 
} );

</code></pre>
<p>here is my css</p>
<pre><code>tfoot input {
        width: 100%;
        padding: 3px;
        box-sizing: border-box;
    }

</code></pre>
<p>my CDN</p>
<pre><code>https://cdn.datatables.net/1.11.5/css/jquery.dataTables.min.css
https://code.jquery.com/jquery-3.5.1.js
https://cdn.datatables.net/1.11.5/js/jquery.dataTables.min.js

</code></pre>
<p>please give me some solution.</p>
",37,0,0,3,javascript;php;datatable,2022-04-16 14:44:01,2022-04-16 14:44:01,2022-04-16 14:44:01,this datatable allows individual column search to filter data  now i want to sum subtotal of filtered salary data  like when the table data will do filter then a auto calculation will be done with filtered data  and also i want to add date range datepicker  so that i can search from date to date  the subtotal calculation will also work for date picker  here is my table here is my javascript here is my css my cdn please give me some solution ,how to sum total in individual column searchable data table and how to add date range
340,5219761,71828221,Using JavaScript Fetch() and formData() To Update A Database,"<p>I have some javascript <code>fetch()</code> on a project and, although it works, the issue I have is, (although I understand the basics of <code>fetch</code> and <code>formData</code>), the piece of code seems overly complicated for what it is doing, and I don't understand how it is working?</p>
<p>I have some PHP that when a download button is clicked it updates a 'downloads' count in a MySQL database. I've included the PHP at the end, but it isn't really relevant to the issue.</p>
<p>What I don't understand is, if the form button is assigned to a <code>downloadButton</code> variable, why the code is written how it is, particularly on the <code>click</code> event listener?</p>
<p>It would be amazing if someone could explain this to me and possibly show a better way of doing it using the <code>downloadButton</code> variable?</p>
<p>I've added code comments on the parts I don't understand.</p>
<p>Also please feel free to explain this as if you are talking to an idiot - I am new to JavaScript/software development.</p>
<p><strong>Note:</strong> Using JSON / URL endpoints is not an option.</p>
<p><strong>JavaScript</strong></p>
<pre><code>let forms = document.querySelectorAll('.download-form-js'),
    downloadButton = document.querySelectorAll('.dl-button')

// URL details
let myURL = new URL(window.location.href), // get URL
pagePath = myURL.pathname // add pathname to get full URL

if (forms) {
        forms.forEach(item =&gt; {
            
            // Why is it done like this when a variable is assigned to the download button above?
            item.querySelectorAll('[type=&quot;submit&quot;], button').forEach( button =&gt; {
                button.addEventListener(&quot;click&quot;, e =&gt; item._button = button); //store this button in the form element?
            })

            // The 'btn' parameter in this function isn't used ?
            item.addEventListener(&quot;submit&quot;, function(evt, btn) {

                evt.preventDefault();

                const formData = new FormData(this);

                // Can the parameters inside the '.set()' function not be done with the 'downloadButton' variable?
                if (this._button) // submitted by a button?
                {
                    formData.set(this._button.name, this._button.value);
                    delete this._button; // have no idea why this is even used?
                }

            fetch (pagePath, {
                method: 'post',
                body: formData
            }).then(function(response){
                return response.text();
            // }).then(function(data){
            //     console.log(data);
            }).catch(function (error){
                console.error(error);
            })

        })

    })

} // end of if (forms)
</code></pre>
<p><strong>HTML</strong>
This form appears at least twice on any page.</p>
<pre><code>&lt;section&gt;
    &lt;div class=&quot;image-wrapper&quot;&gt;
        &lt;img src=&quot;image.jpg&quot; alt=&quot;image&quot;&gt;
    &lt;/div&gt;
    &lt;form class=&quot;download-form-js&quot; enctype=&quot;multipart/form-data&quot; method=&quot;post&quot;&gt;
        &lt;div class=&quot;dl-button-wrapper&quot;&gt;
                &lt;label for=&quot;download-button&quot;&gt;Download&lt;/label&gt;
                &lt;button id=&quot;download-button&quot; type=&quot;submit&quot; name=&quot;download&quot; title=&quot;Download&quot; value=&quot;12&quot; class=&quot;dl-button&quot;&gt;&lt;/button&gt;
            &lt;input type=&quot;hidden&quot; name=&quot;image-id&quot; value=&quot;12&quot;&gt;
        &lt;/div&gt;
    &lt;/form&gt;
&lt;/section&gt;
</code></pre>
<p><strong>PHP (not really relevant, but thought I'd include it)</strong></p>
<p>Below is the PHP function that is used to update the downloads count but isn't really relevant to the above problem.</p>
<pre><code>function downloadCounter($connection, $imageID) {
    if (isset($_POST['download'])) {
         // value from hidden form element
         $imageID = $_POST['image-id'];

         try {
              $sql = &quot;UPDATE lj_imageposts SET downloads = downloads +1 WHERE image_id = :image_id&quot;;
              $stmt = $connection-&gt;prepare($sql);

              $stmt-&gt;execute([
                   ':image_id' =&gt; $imageID
              ]);

         } catch (PDOException $e) {
              echo &quot;Error: &quot; . $e-&gt;getMessage();
         }
    }
}
</code></pre>
",504,2,2,5,javascript;html;ajax;fetch;form-data,2022-04-11 15:54:48,2022-04-11 15:54:48,2022-04-14 20:17:01,i have some javascript fetch   on a project and  although it works  the issue i have is   although i understand the basics of fetch and formdata   the piece of code seems overly complicated for what it is doing  and i don t understand how it is working  i have some php that when a download button is clicked it updates a  downloads  count in a mysql database  i ve included the php at the end  but it isn t really relevant to the issue  what i don t understand is  if the form button is assigned to a downloadbutton variable  why the code is written how it is  particularly on the click event listener  it would be amazing if someone could explain this to me and possibly show a better way of doing it using the downloadbutton variable  i ve added code comments on the parts i don t understand  also please feel free to explain this as if you are talking to an idiot   i am new to javascript software development  note  using json   url endpoints is not an option  javascript php  not really relevant  but thought i d include it  below is the php function that is used to update the downloads count but isn t really relevant to the above problem ,using javascript fetch   and formdata   to update a database
341,18799159,71865953,Cancel/Clear Unity Upload to Firestore?,"<p>I am working on a Unity project and have been using a Firestore Database.</p>
<p>I realised there was a formatting error with the current data in my collection so I saved it to a list, changed it and attempted to reupload to a new collection.</p>
<p>In play mode, I attempted to upload this.  It was a pretty large list.  I stopped play mode and the data did not upload to the Firestore DB.</p>
<p>I basically looped a list and passed the samples to this method.</p>
<pre><code> public void AddSample(Sample sample)
    {
       
        firestore.Collection(_collectionPath).Document().SetAsync(sample);
    }
</code></pre>
<p>I was receiving an error, when I would reentered play mode</p>
<pre><code> Future with handle 1 still exists though its backing API &lt;&lt;code number here&gt;&gt; is being deleted.
</code></pre>
<p>This error is no longer appearing. Nothing I upload through the Unity app in Play Mode is appearing in the database.  Uploads from my app build on my phone are working, they are set to a different collection on the same database.  I have not rebuilt the app since attempting the large upload.</p>
<p>I am somewhat new to unity and firebase, and still learning a lot about software development.
I figure large upload is preventing any smaller uploads.  I am hoping there must be some way of clearing the upload / stopping the upload i.e. maybe its working off some cache when reconnected to the internet.</p>
<p>Any advice, information, links etc., would be greatly appreciated.</p>
<p>I tried :</p>
<pre><code> firestore.TerminateAsync();
            firestore.ClearPersistenceAsync();
</code></pre>
<p>hoping that might clear the upload, no success.</p>
",34,1,0,4,android;firebase;unity3d;google-cloud-firestore,2022-04-14 05:48:35,2022-04-14 05:48:35,2022-04-14 17:05:11,i am working on a unity project and have been using a firestore database  i realised there was a formatting error with the current data in my collection so i saved it to a list  changed it and attempted to reupload to a new collection  in play mode  i attempted to upload this   it was a pretty large list   i stopped play mode and the data did not upload to the firestore db  i basically looped a list and passed the samples to this method  i was receiving an error  when i would reentered play mode this error is no longer appearing  nothing i upload through the unity app in play mode is appearing in the database   uploads from my app build on my phone are working  they are set to a different collection on the same database   i have not rebuilt the app since attempting the large upload  any advice  information  links etc   would be greatly appreciated  i tried   hoping that might clear the upload  no success ,cancel clear unity upload to firestore 
342,571723,63851344,NodeJS - TypeError [ERR_INVALID_ARG_TYPE]: The &quot;path&quot; argument must be of type string. Received undefined,"<p>I have a Node/React project in my Webstorm that won't run because of this error.  I had to reinstall Windows and start fresh with my development.  I got the code back into the IDE, but when I start up the Node server, I am getting the following error: <code>TypeError [ERR_INVALID_ARG_TYPE]: The &quot;path&quot; argument must be of type string. Received undefined</code></p>
<p>More context for that error:</p>
<pre><code>[nodemon] starting `babel-node src/node-server/index.js`
internal/validators.js:122
    throw new ERR_INVALID_ARG_TYPE(name, 'string', value);
    ^

TypeError [ERR_INVALID_ARG_TYPE]: The &quot;path&quot; argument must be of type string. Received undefined
    at validateString (internal/validators.js:122:11)
    at Object.join (path.js:375:7)
    at Object.&lt;anonymous&gt; (C:\Projects\Production-Orchestrator\src\node-server\/index.js:17:15)
</code></pre>
<p>I went to index.js and here is lines 1-17:</p>
<pre><code>// npm run server
import dotenv from 'dotenv';
import express from 'express';
import path from 'path';
import sql from 'mssql';
import cors from 'cors';
import http from 'http';
import { setupWebSocket } from './ws/setupWebSocket.js';

const useWebSockets = true;

dotenv.config();

const dbConfig = {
    user: process.env.DB_USER,
    password: process.env.DB_PASS,
    server: path.join(process.env.DB_SERVER, process.env.DB_HOST),
</code></pre>
<p>I am running <code>npm run server</code> to start up my node server.</p>
<p>And here is my package.json if it helps:</p>
<pre><code>{
  &quot;name&quot;: &quot;my-app&quot;,
  &quot;version&quot;: &quot;0.1.0&quot;,
  &quot;private&quot;: true,
  &quot;description&quot;: &quot;my app&quot;,
  &quot;homepage&quot;: &quot;.&quot;,
  &quot;repository&quot;: {
    &quot;type&quot;: &quot;git&quot;,
    &quot;url&quot;: &quot;git+https://github.com/xxxxxxx&quot;
  },
  &quot;license&quot;: &quot;UNLICENSED&quot;,
  &quot;scripts&quot;: {
    &quot;buildp&quot;: &quot;env-cmd -f .env.production react-scripts build&quot;,
    &quot;buildt&quot;: &quot;env-cmd -f .env.test react-scripts build&quot;,
    &quot;buildw&quot;: &quot;webpack --config ./webpack.config.js --mode production&quot;,
    &quot;eject&quot;: &quot;react-scripts eject&quot;,
    &quot;eslint-check&quot;: &quot;eslint --print-config src/components/search/Search.js | eslint-config-prettier-check&quot;,
    &quot;server&quot;: &quot;nodemon --exec babel-node src/node-server/index.js&quot;,
    &quot;start&quot;: &quot;SET REACT_APP_WS_PORT=3001 &amp; react-scripts start&quot;,
    &quot;startw&quot;: &quot;webpack-dev-server --config ./webpack.config.js --mode development --open&quot;,
    &quot;stylelint&quot;: &quot;stylelint **/*.scss&quot;,
    &quot;test&quot;: &quot;react-scripts test&quot;,
    &quot;ws&quot;: &quot;node --experimental-modules src/node-server/websocket.js&quot;,
    &quot;ws2&quot;: &quot;nodemon --exec babel-node src/node-server/websocket.js&quot;
  },
  &quot;browserslist&quot;: {
    &quot;production&quot;: [
      &quot;&gt;0.2%&quot;,
      &quot;not dead&quot;,
      &quot;not op_mini all&quot;
    ],
    &quot;development&quot;: [
      &quot;last 1 chrome version&quot;,
      &quot;last 1 firefox version&quot;,
      &quot;last 1 safari version&quot;
    ]
  },
  &quot;dependencies&quot;: {
    &quot;@babel/preset-react&quot;: &quot;^7.8.0&quot;,
    &quot;@emotion/core&quot;: &quot;latest&quot;,
    &quot;@fortawesome/fontawesome&quot;: &quot;^1.1.8&quot;,
    &quot;@fortawesome/fontawesome-svg-core&quot;: &quot;^1.2.27&quot;,
    &quot;@fortawesome/free-regular-svg-icons&quot;: &quot;^5.12.1&quot;,
    &quot;@fortawesome/free-solid-svg-icons&quot;: &quot;^5.12.1&quot;,
    &quot;@fortawesome/react-fontawesome&quot;: &quot;^0.1.8&quot;,
    &quot;@popperjs/core&quot;: &quot;^2.0.6&quot;,
    &quot;@react-pdf/renderer&quot;: &quot;^1.6.8&quot;,
    &quot;@types/react&quot;: &quot;^16.9.19&quot;,
    &quot;animate.css&quot;: &quot;^3.7.2&quot;,
    &quot;axios&quot;: &quot;^0.19.2&quot;,
    &quot;babel-loader&quot;: &quot;^8.0.6&quot;,
    &quot;bootstrap&quot;: &quot;^4.4.1&quot;,
    &quot;bufferutil&quot;: &quot;^4.0.1&quot;,
    &quot;cors&quot;: &quot;^2.8.5&quot;,
    &quot;dayjs&quot;: &quot;^1.8.20&quot;,
    &quot;device-detector-js&quot;: &quot;^2.2.1&quot;,
    &quot;dotenv&quot;: &quot;^8.2.0&quot;,
    &quot;express&quot;: &quot;^4.17.1&quot;,
    &quot;express-ws&quot;: &quot;^4.0.0&quot;,
    &quot;file-saver&quot;: &quot;^2.0.2&quot;,
    &quot;javascript-time-ago&quot;: &quot;latest&quot;,
    &quot;jquery&quot;: &quot;^3.4.1&quot;,
    &quot;jsbarcode&quot;: &quot;^3.11.0&quot;,
    &quot;mssql&quot;: &quot;^6.1.0&quot;,
    &quot;popper.js&quot;: &quot;^1.16.1&quot;,
    &quot;print-js&quot;: &quot;^1.0.63&quot;,
    &quot;prop-types&quot;: &quot;^15.7.2&quot;,
    &quot;react&quot;: &quot;^16.12.0&quot;,
    &quot;react-animations&quot;: &quot;^1.0.0&quot;,
    &quot;react-beautiful-dnd&quot;: &quot;^12.2.0&quot;,
    &quot;react-beforeunload&quot;: &quot;^2.2.1&quot;,
    &quot;react-collapse&quot;: &quot;^5.0.1&quot;,
    &quot;react-confirm-alert&quot;: &quot;^2.6.1&quot;,
    &quot;react-custom-scrollbars&quot;: &quot;^4.2.1&quot;,
    &quot;react-detect-offline&quot;: &quot;^2.4.0&quot;,
    &quot;react-dnd&quot;: &quot;^10.0.2&quot;,
    &quot;react-dnd-html5-backend&quot;: &quot;^10.0.2&quot;,
    &quot;react-dom&quot;: &quot;^16.12.0&quot;,
    &quot;react-modal&quot;: &quot;^3.11.1&quot;,
    &quot;react-notifications-component&quot;: &quot;^2.3.0&quot;,
    &quot;react-popup&quot;: &quot;^0.10.0&quot;,
    &quot;react-radio-group&quot;: &quot;^3.0.3&quot;,
    &quot;react-router-dom&quot;: &quot;^5.1.2&quot;,
    &quot;react-scripts&quot;: &quot;^3.4.3&quot;,
    &quot;react-select&quot;: &quot;^3.0.8&quot;,
    &quot;react-spinners&quot;: &quot;^0.8.0&quot;,
    &quot;react-spring&quot;: &quot;^8.0.27&quot;,
    &quot;react-time-ago&quot;: &quot;^5.0.7&quot;,
    &quot;react-transition-group&quot;: &quot;^4.3.0&quot;,
    &quot;sort-package-json&quot;: &quot;^1.40.0&quot;,
    &quot;styled-components&quot;: &quot;^4.4.1&quot;,
    &quot;typescript&quot;: &quot;^3.7.5&quot;,
    &quot;utf-8-validate&quot;: &quot;^5.0.2&quot;,
    &quot;ws&quot;: &quot;^7.2.5&quot;
  },
  &quot;devDependencies&quot;: {
    &quot;@babel/cli&quot;: &quot;^7.8.4&quot;,
    &quot;@babel/core&quot;: &quot;^7.8.4&quot;,
    &quot;@babel/node&quot;: &quot;^7.10.5&quot;,
    &quot;@babel/preset-env&quot;: &quot;^7.8.4&quot;,
    &quot;@welldone-software/why-did-you-render&quot;: &quot;^4.2.5&quot;,
    &quot;css-loader&quot;: &quot;^3.4.2&quot;,
    &quot;dotenv-cli&quot;: &quot;^3.2.0&quot;,
    &quot;env-cmd&quot;: &quot;^10.1.0&quot;,
    &quot;eslint&quot;: &quot;^6.8.0&quot;,
    &quot;eslint-config-prettier&quot;: &quot;^6.10.0&quot;,
    &quot;eslint-loader&quot;: &quot;^3.0.3&quot;,
    &quot;eslint-plugin-babel&quot;: &quot;^5.3.0&quot;,
    &quot;eslint-plugin-prettier&quot;: &quot;^3.1.2&quot;,
    &quot;file-loader&quot;: &quot;^5.0.2&quot;,
    &quot;html-loader&quot;: &quot;^0.5.5&quot;,
    &quot;html-webpack-plugin&quot;: &quot;^3.2.0&quot;,
    &quot;node-sass&quot;: &quot;^4.13.1&quot;,
    &quot;nodemon&quot;: &quot;^2.0.4&quot;,
    &quot;prettier&quot;: &quot;^1.19.1&quot;,
    &quot;react-hot-loader&quot;: &quot;^4.12.19&quot;,
    &quot;sass-loader&quot;: &quot;^8.0.2&quot;,
    &quot;stylelint&quot;: &quot;^13.2.0&quot;,
    &quot;stylelint-config-rational-order&quot;: &quot;^0.1.2&quot;,
    &quot;stylelint-config-standard&quot;: &quot;^19.0.0&quot;,
    &quot;stylelint-order&quot;: &quot;^4.0.0&quot;,
    &quot;stylelint-scss&quot;: &quot;^3.14.2&quot;,
    &quot;url-loader&quot;: &quot;^3.0.0&quot;,
    &quot;webpack&quot;: &quot;^4.44.1&quot;,
    &quot;webpack-cli&quot;: &quot;^3.3.11&quot;
  },
  &quot;proxy&quot;: &quot;http://localhost:3000&quot;
}
</code></pre>
",36072,6,7,3,node.js;babeljs;package.json,2020-09-11 19:59:05,2020-09-11 19:59:05,2022-04-13 07:42:12,i have a node react project in my webstorm that won t run because of this error   i had to reinstall windows and start fresh with my development   i got the code back into the ide  but when i start up the node server  i am getting the following error  typeerror  err_invalid_arg_type   the  path  argument must be of type string  received undefined more context for that error  i went to index js and here is lines    i am running npm run server to start up my node server  and here is my package json if it helps ,nodejs   typeerror  err_invalid_arg_type   the  path  argument must be of type string  received undefined
343,1559401,71838599,Is it possible to add a new wiki entry in a GitLab project using a standard merge request?,"<p><strong>Using free, self-managed GitLab</strong></p>
<p>Due to group-level custom project templates available only to paid tiers (even there there are restrictions) I am looking into an alternative solution using a simple project, where</p>
<ul>
<li>in the code repository each branch provides a template</li>
<li>in the wiki each code repository branch has an entry documenting what the template does</li>
</ul>
<p>I know that the wiki and the code are actually two separate repositories.</p>
<p>In its nature a template is a construct that offers a pre-made setup for working on a reoccurring task. A group template adds the additional restriction that the reoccurring task applies to more then one individual.</p>
<p>In order to limit tomfoolery and people pushing whatever they want thinking it's worth becoming a group-level template (even though they made something real quick to tackle a problem that has been long forgotten and even they themselves will not work on it ever again) I would like to impose access restrictions to all members. Beside the maintainer/owner all other members are assigned a <strong>developer</strong> role. All branches are protected so a change of an existing branch or the creation of a new one can only be done through a merge request leading to an assessment whether the committed changes to the repository are actually worthy of becoming a template for the whole group.</p>
<p>Many members of my group have the bad habit of choosing poor names for functionality they have developed (e.g. a script called <code>jennifers_help_script_23.py</code>) and not documenting what was actually implemented. And yes, we are not a software development company but a research institute. :D So in order to improve the documentation and the ability to actually reuse some of the quite useful things that people have developed I would like to make it mandatory for people to provide documentation if they want their stuff to be added to the project.</p>
<p>So the question here is can a user submit a code merge request that also acts as a merge request for a change in the wiki (e.g. user has created a new template, which requires also a new wiki page documenting that template) or the two have to be handled separately given the nature of a GitLab project (wiki separate from code)?</p>
<p>I was thinking maybe each branch (representing a template) will contain a <strong>markdown</strong> file that will be inserted as a wiki automatically after the merge request has been approved. However I don't know how to automate this. I am currently looking into <a href=""https://stackoverflow.com/questions/51405934/how-to-upload-a-file-into-the-wiki-of-gitlab-using-python?msclkid=addd56c4ba3011eca2a01982a624f1d8"">uploading a file to the wiki using the GitLab API</a>, hoping a can somehow add a trigger in GitLab to execute the &quot;command&quot; upon a successful merge. Needless to say I am quite new to all of this.</p>
",48,0,0,5,automation;gitlab;repository;wiki;merge-request,2022-04-12 10:20:03,2022-04-12 10:20:03,2022-04-12 10:20:03,using free  self managed gitlab due to group level custom project templates available only to paid tiers  even there there are restrictions  i am looking into an alternative solution using a simple project  where i know that the wiki and the code are actually two separate repositories  in its nature a template is a construct that offers a pre made setup for working on a reoccurring task  a group template adds the additional restriction that the reoccurring task applies to more then one individual  in order to limit tomfoolery and people pushing whatever they want thinking it s worth becoming a group level template  even though they made something real quick to tackle a problem that has been long forgotten and even they themselves will not work on it ever again  i would like to impose access restrictions to all members  beside the maintainer owner all other members are assigned a developer role  all branches are protected so a change of an existing branch or the creation of a new one can only be done through a merge request leading to an assessment whether the committed changes to the repository are actually worthy of becoming a template for the whole group  many members of my group have the bad habit of choosing poor names for functionality they have developed  e g  a script called jennifers_help_script_ py  and not documenting what was actually implemented  and yes  we are not a software development company but a research institute   d so in order to improve the documentation and the ability to actually reuse some of the quite useful things that people have developed i would like to make it mandatory for people to provide documentation if they want their stuff to be added to the project  so the question here is can a user submit a code merge request that also acts as a merge request for a change in the wiki  e g  user has created a new template  which requires also a new wiki page documenting that template  or the two have to be handled separately given the nature of a gitlab project  wiki separate from code   i was thinking maybe each branch  representing a template  will contain a markdown file that will be inserted as a wiki automatically after the merge request has been approved  however i don t know how to automate this  i am currently looking into   hoping a can somehow add a trigger in gitlab to execute the  command  upon a successful merge  needless to say i am quite new to all of this ,is it possible to add a new wiki entry in a gitlab project using a standard merge request 
344,8355054,71836006,Expo EAS Build iOS Failed: Attempted to initialize an object with an unknown UUID,"<p>I know that a similar question has been asked by a few people on StackOverflow, but they were not using expo to build their project, so the solution of using XCode does not apply to me.</p>
<p>I am trying to build my expo project using the command <code>eas build --profile development --platform ios</code>, and it keeps failing with the error <code>[stderr] [!] &lt;PBXResourcesBuildPhase UUID=13B07F8E1A680F5B00A75B9A&gt;attempted to initialize an object with an unknown UUID.5360B39C71704D31869D9F73for attribute:files. This can be the result of a merge and the unknown UUID is being discarded.</code></p>
<p>The relevant solutions proposed by other people such as downgrading to SDK Version 43 do not work for me. I was hoping someone could look at my error trace stack and see what could be the issue. I have attached my package.json, Podfile, environment info, as well as an image of my error.</p>
<p>If someone could please figure this out for me that would be excellent because this has significantly held the development of my app for about a week. I have also added this issue on GitHub, but I didn't get a response and I really need quick help to continue development. Here are the links:</p>
<p><a href=""https://github.com/expo/expo/issues/16996"" rel=""nofollow noreferrer"">GitHub Link - SDK Version 44</a></p>
<p><a href=""https://github.com/expo/expo/issues/16995"" rel=""nofollow noreferrer"">GitHub Link - SDK Version 43</a></p>
<p>Environment:</p>
<pre><code>System:
OS: macOS 12.2.1
Shell: 5.8 - /bin/zsh
Binaries:
Node: 16.3.0 - /opt/homebrew/bin/node
Yarn: 1.22.10 - /opt/homebrew/bin/yarn
npm: 8.3.0 - /opt/homebrew/bin/npm
Watchman: 2022.01.31.00 - /opt/homebrew/bin/watchman
Managers:
CocoaPods: 1.11.3 - /usr/local/bin/pod
SDKs:
iOS SDK:
Platforms: DriverKit 21.4, iOS 15.4, macOS 12.3, tvOS 15.4, watchOS 8.5
IDEs:
Xcode: 13.3/13E113 - /usr/bin/xcodebuild
npmPackages:
expo: ^44.0.0 =&gt; 44.0.6
react: 17.0.1 =&gt; 17.0.1
react-dom: 17.0.1 =&gt; 17.0.1
react-native: 0.64.3 =&gt; 0.64.3
react-native-web: 0.17.1 =&gt; 0.17.1
npmGlobalPackages:
eas-cli: 0.47.0
expo-cli: 5.3.0
Expo Workflow: bare
</code></pre>
<p>package.json</p>
<pre><code>{
  &quot;name&quot;: &quot;yourhud&quot;,
  &quot;version&quot;: &quot;1.0.0&quot;,
  &quot;scripts&quot;: {
    &quot;start&quot;: &quot;expo start --dev-client&quot;,
    &quot;android&quot;: &quot;expo run:android&quot;,
    &quot;ios&quot;: &quot;expo run:ios&quot;,
    &quot;web&quot;: &quot;expo start --web&quot;,
    &quot;eject&quot;: &quot;expo eject&quot;
  },
  &quot;dependencies&quot;: {
    &quot;@config-plugins/react-native-ble-plx&quot;: &quot;^0.0.2&quot;,
    &quot;@expo-google-fonts/be-vietnam&quot;: &quot;^0.2.0&quot;,
    &quot;@expo-google-fonts/dev&quot;: &quot;^0.2.0&quot;,
    &quot;@expo-google-fonts/heebo&quot;: &quot;^0.2.2&quot;,
    &quot;@expo-google-fonts/hind-siliguri&quot;: &quot;^0.2.2&quot;,
    &quot;@expo-google-fonts/inter&quot;: &quot;^0.2.2&quot;,
    &quot;@expo-google-fonts/josefin-sans&quot;: &quot;^0.2.2&quot;,
    &quot;@expo-google-fonts/lato&quot;: &quot;^0.2.2&quot;,
    &quot;@expo-google-fonts/michroma&quot;: &quot;^0.2.0&quot;,
    &quot;@expo-google-fonts/montserrat&quot;: &quot;^0.2.0&quot;,
    &quot;@expo-google-fonts/nunito&quot;: &quot;^0.2.0&quot;,
    &quot;@expo-google-fonts/open-sans&quot;: &quot;^0.2.2&quot;,
    &quot;@expo-google-fonts/orbitron&quot;: &quot;^0.2.2&quot;,
    &quot;@expo-google-fonts/oswald&quot;: &quot;^0.2.2&quot;,
    &quot;@expo-google-fonts/overpass&quot;: &quot;^0.2.2&quot;,
    &quot;@expo-google-fonts/poppins&quot;: &quot;^0.2.2&quot;,
    &quot;@expo-google-fonts/prompt&quot;: &quot;^0.2.2&quot;,
    &quot;@expo-google-fonts/quicksand&quot;: &quot;^0.2.0&quot;,
    &quot;@expo-google-fonts/raleway&quot;: &quot;^0.2.0&quot;,
    &quot;@expo-google-fonts/rubik&quot;: &quot;^0.2.0&quot;,
    &quot;@expo-google-fonts/varela-round&quot;: &quot;^0.2.2&quot;,
    &quot;@expo-google-fonts/work-sans&quot;: &quot;^0.2.2&quot;,
    &quot;@mapbox/polyline&quot;: &quot;^1.1.1&quot;,
    &quot;@miblanchard/react-native-slider&quot;: &quot;^2.1.0&quot;,
    &quot;@react-native-async-storage/async-storage&quot;: &quot;~1.15.0&quot;,
    &quot;@react-native-community/geolocation&quot;: &quot;^2.0.2&quot;,
    &quot;@react-native-picker/picker&quot;: &quot;2.2.1&quot;,
    &quot;@react-navigation/drawer&quot;: &quot;^6.1.8&quot;,
    &quot;@react-navigation/material-top-tabs&quot;: &quot;^6.0.6&quot;,
    &quot;@react-navigation/native&quot;: &quot;^6.0.6&quot;,
    &quot;@react-navigation/native-stack&quot;: &quot;^6.2.5&quot;,
    &quot;@types/haversine&quot;: &quot;^1.1.5&quot;,
    &quot;@types/mapbox__polyline&quot;: &quot;^1.0.2&quot;,
    &quot;@types/react-native-base64&quot;: &quot;^0.2.0&quot;,
    &quot;@types/react-native-linear-gradient&quot;: &quot;^2.4.0&quot;,
    &quot;@types/react-native-snap-carousel&quot;: &quot;^3.8.5&quot;,
    &quot;@types/react-native-version-check&quot;: &quot;^3.4.4&quot;,
    &quot;axios&quot;: &quot;^0.24.0&quot;,
    &quot;dotenv&quot;: &quot;^10.0.0&quot;,
    &quot;eas-cli&quot;: &quot;0.49.0&quot;,
    &quot;expo&quot;: &quot;^44.0.0&quot;,
    &quot;expo-app-loading&quot;: &quot;~1.3.0&quot;,
    &quot;expo-av&quot;: &quot;~10.2.0&quot;,
    &quot;expo-brightness&quot;: &quot;~10.1.0&quot;,
    &quot;expo-dev-client&quot;: &quot;~0.8.4&quot;,
    &quot;expo-device&quot;: &quot;~4.1.0&quot;,
    &quot;expo-font&quot;: &quot;~10.0.4&quot;,
    &quot;expo-in-app-purchases&quot;: &quot;~12.1.0&quot;,
    &quot;expo-linear-gradient&quot;: &quot;~11.0.3&quot;,
    &quot;expo-linking&quot;: &quot;~3.0.0&quot;,
    &quot;expo-location&quot;: &quot;~14.0.1&quot;,
    &quot;expo-notifications&quot;: &quot;~0.14.0&quot;,
    &quot;expo-permissions&quot;: &quot;~13.1.0&quot;,
    &quot;expo-sensors&quot;: &quot;~11.1.0&quot;,
    &quot;expo-speech&quot;: &quot;~10.1.0&quot;,
    &quot;expo-splash-screen&quot;: &quot;~0.14.1&quot;,
    &quot;expo-status-bar&quot;: &quot;~1.2.0&quot;,
    &quot;expo-task-manager&quot;: &quot;~10.1.0&quot;,
    &quot;haversine&quot;: &quot;^1.1.1&quot;,
    &quot;luxon&quot;: &quot;^2.2.0&quot;,
    &quot;react&quot;: &quot;17.0.1&quot;,
    &quot;react-dom&quot;: &quot;17.0.1&quot;,
    &quot;react-native&quot;: &quot;0.64.3&quot;,
    &quot;react-native-anchor-point&quot;: &quot;^1.0.6&quot;,
    &quot;react-native-base64&quot;: &quot;^0.2.1&quot;,
    &quot;react-native-ble-plx&quot;: &quot;^2.0.3&quot;,
    &quot;react-native-bouncy-checkbox&quot;: &quot;^2.1.9&quot;,
    &quot;react-native-color-matrix-image-filters&quot;: &quot;^5.2.14&quot;,
    &quot;react-native-dotenv&quot;: &quot;^3.3.1&quot;,
    &quot;react-native-dropdown-picker&quot;: &quot;^5.3.0&quot;,
    &quot;react-native-email&quot;: &quot;^1.1.0&quot;,
    &quot;react-native-gesture-handler&quot;: &quot;~2.1.0&quot;,
    &quot;react-native-google-places-autocomplete&quot;: &quot;^2.4.1&quot;,
    &quot;react-native-html-parser&quot;: &quot;^0.1.0&quot;,
    &quot;react-native-numeric-input&quot;: &quot;^1.9.0&quot;,
    &quot;react-native-obd2&quot;: &quot;^0.0.2&quot;,
    &quot;react-native-pager-view&quot;: &quot;5.4.9&quot;,
    &quot;react-native-picker-select&quot;: &quot;^8.0.4&quot;,
    &quot;react-native-progress&quot;: &quot;^5.0.0&quot;,
    &quot;react-native-reanimated&quot;: &quot;~2.3.1&quot;,
    &quot;react-native-render-html&quot;: &quot;^6.3.4&quot;,
    &quot;react-native-safe-area-context&quot;: &quot;3.3.2&quot;,
    &quot;react-native-screens&quot;: &quot;~3.10.1&quot;,
    &quot;react-native-shake&quot;: &quot;^5.1.1&quot;,
    &quot;react-native-snap-carousel&quot;: &quot;^3.9.1&quot;,
    &quot;react-native-speedometer&quot;: &quot;^1.0.5&quot;,
    &quot;react-native-svg&quot;: &quot;12.1.1&quot;,
    &quot;react-native-swiper&quot;: &quot;^1.6.0&quot;,
    &quot;react-native-tab-view&quot;: &quot;^3.1.1&quot;,
    &quot;react-native-track-player&quot;: &quot;^2.1.3&quot;,
    &quot;react-native-triangle&quot;: &quot;^0.0.9&quot;,
    &quot;react-native-tts&quot;: &quot;^4.1.0&quot;,
    &quot;react-native-version-check&quot;: &quot;^3.4.2&quot;,
    &quot;react-native-web&quot;: &quot;0.17.1&quot;,
    &quot;shortid&quot;: &quot;^2.2.16&quot;,
    &quot;use-places-autocomplete&quot;: &quot;^1.11.0&quot;
  },
  &quot;devDependencies&quot;: {
    &quot;@babel/core&quot;: &quot;^7.12.9&quot;,
    &quot;@types/jest&quot;: &quot;^27.4.0&quot;,
    &quot;@types/luxon&quot;: &quot;^2.0.9&quot;,
    &quot;@types/react&quot;: &quot;~17.0.21&quot;,
    &quot;@types/react-native&quot;: &quot;~0.64.12&quot;,
    &quot;@types/react-test-renderer&quot;: &quot;^17.0.1&quot;,
    &quot;@types/shortid&quot;: &quot;^0.0.29&quot;,
    &quot;typescript&quot;: &quot;~4.3.5&quot;
  },
  &quot;private&quot;: true
}
</code></pre>
<p>Podfile</p>
<pre><code>require File.join(File.dirname(`node --print &quot;require.resolve('expo/package.json')&quot;`), &quot;scripts/autolinking&quot;)
require File.join(File.dirname(`node --print &quot;require.resolve('react-native/package.json')&quot;`), &quot;scripts/react_native_pods&quot;)
require File.join(File.dirname(`node --print &quot;require.resolve('@react-native-community/cli-platform-ios/package.json')&quot;`), &quot;native_modules&quot;)

platform :ios, '12.0'

require 'json'
podfile_properties = JSON.parse(File.read('./Podfile.properties.json')) rescue {}

target 'YourHUD' do
  use_expo_modules!
  config = use_native_modules!

  pod 'expo-dev-launcher', path: '../node_modules/expo-dev-launcher', :configurations =&gt; :debug
  pod 'expo-dev-menu', path: '../node_modules/expo-dev-menu', :configurations =&gt; :debug
# @generated begin pre_installer - expo prebuild (DO NOT MODIFY) sync-c8812095000d6054b846ce74840f0ffb540c2757
  pre_install do |installer|
# @generated begin @react-native-mapbox-gl/maps-pre_installer - expo prebuild (DO NOT MODIFY) sync-5a7ed0a20d5aff2d61639bc5bb4fd5551233d57c
    $RNMBGL.pre_install(installer)
# @generated end @react-native-mapbox-gl/maps-pre_installer
  end
# @generated end pre_installer
  use_react_native!(
    :path =&gt; config[:reactNativePath],
    :hermes_enabled =&gt; podfile_properties['expo.jsEngine'] == 'hermes'
  )

  # Uncomment to opt-in to using Flipper
  #
  # if !ENV['CI']
  #   use_flipper!('Flipper' =&gt; '0.75.1', 'Flipper-Folly' =&gt; '2.5.3', 'Flipper-RSocket' =&gt; '1.3.1')
  # end

  post_install do |installer|
    react_native_post_install(installer)

    # Workaround `Cycle inside FBReactNativeSpec` error for react-native 0.64
    # Reference: https://github.com/software-mansion/react-native-screens/issues/842#issuecomment-812543933
    installer.pods_project.targets.each do |target|
      if (target.name&amp;.eql?('FBReactNativeSpec'))
        target.build_phases.each do |build_phase|
          if (build_phase.respond_to?(:name) &amp;&amp; build_phase.name.eql?('[CP-User] Generate Specs'))
            target.build_phases.move(build_phase, 0)
          end
        end
      end
    end
  end

  post_integrate do |installer|
    begin
      expo_patch_react_imports!(installer)
    rescue =&gt; e
      Pod::UI.warn e
    end
  end

end
</code></pre>
<p>Build Log:
<img src=""https://user-images.githubusercontent.com/37488506/162637287-d150c19d-6cb2-4a18-bd17-1961bf9bff29.png"" /></p>
",757,1,0,3,react-native;build;expo,2022-04-12 04:30:41,2022-04-12 04:30:41,2022-04-12 10:10:42,i know that a similar question has been asked by a few people on stackoverflow  but they were not using expo to build their project  so the solution of using xcode does not apply to me  i am trying to build my expo project using the command eas build   profile development   platform ios  and it keeps failing with the error  stderr       lt pbxresourcesbuildphase uuid bfeafbaba gt attempted to initialize an object with an unknown uuid bcddffor attribute files  this can be the result of a merge and the unknown uuid is being discarded  the relevant solutions proposed by other people such as downgrading to sdk version  do not work for me  i was hoping someone could look at my error trace stack and see what could be the issue  i have attached my package json  podfile  environment info  as well as an image of my error  if someone could please figure this out for me that would be excellent because this has significantly held the development of my app for about a week  i have also added this issue on github  but i didn t get a response and i really need quick help to continue development  here are the links    environment  package json podfile,expo eas build ios failed  attempted to initialize an object with an unknown uuid
345,5673922,45002739,g++ - Python.h: No such file or directory,"<p>I'm trying to make a C++ script that will run some simple Python code:</p>
<pre><code>// t.cpp
#include &lt;Python.h&gt;

int main(int argc, char* argv[])
{
    Py_Initialize();
    PyRun_SimpleString(&quot;print('TEST PASSED')&quot;);
    Py_Finalize();

    return 0;
}
</code></pre>
<p>Upon running <code>g++ t.cpp</code>, I get the error:</p>
<blockquote>
<p>t.cpp:1:20: fatal error: Python.h: No such file or directory</p>
<p>compilation terminated</p>
</blockquote>
<p>I've found many similar questions, all specific to an IDE or other development software, or were solved by installing <code>python3-dev</code>. The <code>python3-dev</code> package <em>is already installed</em>, and I even tried manually including the header when attempting to compile:</p>
<pre><code>g++ t.cpp -I ~/.virtualenvs/MainEnv/include/python3.5m/Python.h
g++ t.cpp -I /usr/include/python3.5m/Python.h
</code></pre>
<p>Neither changes anything.</p>
<p>How can I fix this error?</p>
<p>UPDATE: I found that using <code>g++ t.cpp -I /usr/include/python3.5/</code> seems to include the header, but then it runs into more errors:</p>
<blockquote>
<p>t.cpp:(.text+0x10): undefined reference to `Py_Initialize'</p>
<p>t.cpp:(.text+0x1f): undefined reference to `PyRun_SimpleStringFlags'</p>
<p>t.cpp:(.text+0x24): undefined reference to `Py_Finalize'</p>
<p>collect2: error: ld returned 1 exit status</p>
</blockquote>
",9502,3,1,4,c++;python-3.x;ubuntu;g++,2017-07-10 04:47:05,2017-07-10 04:47:05,2022-04-12 02:30:39,i m trying to make a c   script that will run some simple python code  upon running g   t cpp  i get the error  t cpp    fatal error  python h  no such file or directory compilation terminated i ve found many similar questions  all specific to an ide or other development software  or were solved by installing python dev  the python dev package is already installed  and i even tried manually including the header when attempting to compile  neither changes anything  how can i fix this error  update  i found that using g   t cpp  i  usr include python   seems to include the header  but then it runs into more errors  t cpp   text x   undefined reference to  py_initialize  t cpp   text xf   undefined reference to  pyrun_simplestringflags  t cpp   text x   undefined reference to  py_finalize  collect  error  ld returned  exit status,g     python h  no such file or directory
346,0,67682031,Comparing double values using stream filter,"<p>I need your help in determining what is wrong with the code that I am working on right now.</p>
<p>The specifications for this task is to filter the list of objects obtained from a csv file and only get the top 10 employees with the highest salary. I am trying these lines:</p>
<pre><code>List&lt;Employee&gt; listOfTop10HighestPaidMaleEmployee = new ArrayList&lt;&gt;(employeeList);
    List&lt;Employee&gt; filterSalary;

            filterSalary = listOfTop10HighestPaidMaleEmployee
                    .stream()
                    .sorted(
                            Comparator.comparingDouble(Employee::getSalary)
                    )
                    .limit(10)
                    .collect(Collectors.toList());
</code></pre>
<p>When I test it using a for-each loop, it prints out 10 values, but doesn't properly filter out the salary part. I get this output:</p>
<pre><code>Employee{id='261461', name='Lucila Isai Gray Silvestre', department='Software Development Team', 
gender=M, age=34, employment status=Permanent, salary=20079.75, years of service=9}
Employee{id='368487', name='Joey Quinn Uson Solivio', department='Marketing', gender=M, age=34, 
employment status=Not Permanent, salary=20200.25, years of service=3}
Employee{id='353810', name='Carter Jamie Pagsisihan Lingao', department='Marketing', gender=M, 
age=24, employment status=Permanent, salary=20444.25, years of service=4}
Employee{id='330680', name='Erick Colby Magan Formalouza', department='IT Services', gender=M, 
age=52, employment status=Permanent, salary=20887.0, years of service=14}
Employee{id='220888', name='Jack Cornelius Parker Guinto', department='IT Services', gender=M, 
age=32, employment status=Permanent, salary=20950.0, years of service=10}
Employee{id='215350', name='Eugenio Jermaine Quiblat Bonachita', department='Marketing', gender=M, 
age=45, employment status=Not Permanent, salary=21263.5, years of service=2}
Employee{id='257430', name='Malaya Kaitlyn Hakamada Gonz�lez', department='IT Services', gender=F, 
age=35, employment status=Not Permanent, salary=21362.0, years of service=2}
Employee{id='212292', name='Kendra Mercedes Lomondot Fernando', department='Marketing', gender=F, a 
age=41, employment status=Not Permanent, salary=21371.75, years of service=3}
Employee{id='348771', name='Kristofer Israel Dura Portugal', department='Human Resource', gender=M, 
age=49, employment status=Permanent, salary=21402.5, years of service=6}
Employee{id='353227', name='Maegan Jaden Mahiya Isidro', department='Human Resource', gender=F, 
age=59, employment status=Not Permanent, salary=21442.25, years of service=3}
</code></pre>
<p>Upon cross-checking the results and the list, it prints out the list with salary of range 20000-21,000. In the original list, the salary goes up to 30,000. Any tips on how can I filter the list so that it shows the list of 10 employees with the highest salary? Any help would be deeply appreciated. Thank you in advance!</p>
",365,1,0,3,java;filter;java-stream,2021-05-25 08:01:15,2021-05-25 08:01:15,2022-04-11 22:24:45,i need your help in determining what is wrong with the code that i am working on right now  the specifications for this task is to filter the list of objects obtained from a csv file and only get the top  employees with the highest salary  i am trying these lines  when i test it using a for each loop  it prints out  values  but doesn t properly filter out the salary part  i get this output  upon cross checking the results and the list  it prints out the list with salary of range     in the original list  the salary goes up to    any tips on how can i filter the list so that it shows the list of  employees with the highest salary  any help would be deeply appreciated  thank you in advance ,comparing double values using stream filter
347,16578749,68623797,How do i Stop the v.s code source code from displaying all my desktop files?,"<p>i just started using v.s code and im still getting around it but im not comfortable seeing &quot;1k plus changes&quot; on the SCM icon.it seems to be tracking all of my files on my desktop and it really makes me uncomfortable.<a href=""https://i.stack.imgur.com/3Olzo.png"" rel=""nofollow noreferrer"">picture showing SCM tracking changes that do not concern software development </a></p>
",405,2,0,3,visual-studio-code;vscode-settings;helper,2021-08-02 17:58:04,2021-08-02 17:58:04,2022-04-11 19:01:44,i just started using v s code and im still getting around it but im not comfortable seeing  k plus changes  on the scm icon it seems to be tracking all of my files on my desktop and it really makes me uncomfortable ,how do i stop the v s code source code from displaying all my desktop files 
348,7570259,71766820,Using Spring Security to convert a SAMl2.0 token into a JWT/OIDC,"<p>I am working on a team that needs to add OIDC (JWT/id token) support to an existing Java Spring application using SAML2.0. Do you all have any suggestions or resources to help tackle this problem?</p>
<p>From the little research I have done, it sounds like there may be a way for us to convert a SAML2.0 token into a JSON Web Token/OIDC/ID Token. Is that a thing?</p>
<p>Sorry for any poor wording, I am a data scientist by nature so my software development skills are not strong.</p>
<p>Thank you all for any help you can provide.</p>
",184,1,1,5,java;spring-security;openid-connect;saml-2.0;spring-saml,2022-04-06 15:32:58,2022-04-06 15:32:58,2022-04-11 15:45:57,i am working on a team that needs to add oidc  jwt id token  support to an existing java spring application using saml   do you all have any suggestions or resources to help tackle this problem  from the little research i have done  it sounds like there may be a way for us to convert a saml  token into a json web token oidc id token  is that a thing  sorry for any poor wording  i am a data scientist by nature so my software development skills are not strong  thank you all for any help you can provide ,using spring security to convert a saml  token into a jwt oidc
349,1830916,63402320,Can&#39;t processes Resx with msbuild commandline because its restricted,"<p>I am writing an ant script (yes I know we are in 2020) to build a c# solution. This solution has many projects associate with it and for the most part i can get each project in the solution to build with the following ant task (names obfuscated due to sensitivity of the program):</p>
<pre><code>&lt;target name=&quot;MyProject1&quot; description=&quot;Build MyProject1&quot;&gt;
  &lt;exec executable=&quot;${msbuild}&quot;&gt;
    &lt;arg value=&quot;MySolution.sln /t:MyProject1:Rebuild /p:Configuration=Release&quot; /&gt;
  &lt;/exec&gt; 
&lt;/target&gt;
</code></pre>
<p>As i mentioned this works for most of all my projects but I have one project that has a <code>resx</code> file and I get the error <code>Couldn't process file resx due to its being in the Internet or Restricted zone or having the mark of the web on the file</code></p>
<p>I did come across this solution</p>
<p><a href=""https://stackoverflow.com/questions/51348919/couldnt-process-file-resx-due-to-its-being-in-the-internet-or-restricted-zone-o"">Couldn&#39;t process file resx due to its being in the Internet or Restricted zone or having the mark of the web on the file</a></p>
<p>Which talked about running the file through powershell so I added this to my target:</p>
<pre><code>  &lt;exec executable=&quot;powershell&quot;&gt;
    &lt;arg value=&quot;get-childitem MyResource.resx | unblock-file&quot; /&gt;
  &lt;/exec&gt;
</code></pre>
<p>But that did not seem to work and get the same error.</p>
<p>So my question would be is there another command I can run either in a batch file, as a switch to msbuild or a task in ant that will unlock the file. All the other suggestions were manual editing of the file and this has to be automated.</p>
<p>This file is being pulled in from a cm location that I cannot touch thus removing the lock and putting it back I cannot do. I could ask someone who does have access to change the file but that takes an act of congress (literally).</p>
<p>The idea behind the ant script is for any developer to be able to run it on any of our windows development machines and build the software without having to go through visual studio.</p>
",99,1,0,3,c#;ant;msbuild,2020-08-13 22:51:48,2020-08-13 22:51:48,2022-04-11 15:39:03,i am writing an ant script  yes i know we are in   to build a c  solution  this solution has many projects associate with it and for the most part i can get each project in the solution to build with the following ant task  names obfuscated due to sensitivity of the program   as i mentioned this works for most of all my projects but i have one project that has a resx file and i get the error couldn t process file resx due to its being in the internet or restricted zone or having the mark of the web on the file i did come across this solution  which talked about running the file through powershell so i added this to my target  but that did not seem to work and get the same error  so my question would be is there another command i can run either in a batch file  as a switch to msbuild or a task in ant that will unlock the file  all the other suggestions were manual editing of the file and this has to be automated  this file is being pulled in from a cm location that i cannot touch thus removing the lock and putting it back i cannot do  i could ask someone who does have access to change the file but that takes an act of congress  literally   the idea behind the ant script is for any developer to be able to run it on any of our windows development machines and build the software without having to go through visual studio ,can   t processes resx with msbuild commandline because its restricted
350,1262204,71699887,MySQL Workbench 8.0.28 export issue on MacOS 12.3,"<p>Up until recently I was using MySQL Workbench 8.0.20 without any issues till I upgraded my MacOS to 12.3 after which the Workbench software itself stopped working. I then upgraded my Workbench version to 8.0.28 (latest version at the time of writing).</p>
<p>But after updating to the new version, I initially had issues connecting to my remote databases. I was getting the following error -</p>
<p><code>Got error: 2026: SSL connection error: error:1425F102:SSL routines:ssl_choose_client_version:unsupported protocol when trying to connect</code></p>
<p>But I was able to solve that one by setting the 'Use SSL' option under the SSL tab for the connection to 'No'.</p>
<p>The next issue though is now I am not able to perform exports on the server using mysqldump. The Workbench software is trying to run the following command -</p>
<p><code>Running: /Applications/MySQLWorkbench.app/Contents/MacOS/mysqldump --defaults-file=&quot;/var/folders/fd/jt76prtj4z35dqd6y1y1_jcw0000gn/T/tmppuwxrtig/extraparams.cnf&quot;  --host=host.db.com --port=3306 --default-character-set=utf8 --user=logicspice --protocol=tcp --single-transaction=TRUE --column-statistics=0 --skip-triggers &quot;database&quot;</code></p>
<p>after which I'm getting a similar issue -</p>
<p><code>mysqldump: Got error: 2026: SSL connection error: error:1425F102:SSL routines:ssl_choose_client_version:unsupported protocol when trying to connect</code></p>
<p>Is there an update I can do to a certain configuration file for either mysqldump or MySQL Workbench that will disable the use of SSL when trying to use mysqldump?</p>
<p>Your assistance would be much appreciated as this issue is causing delays in my development work. Thanks!</p>
<pre><code>Summary of system - 
Operating system - MacOS Monterey 12.3
Processor - 2.4 GHz 8-Core Intel Core i9
MySQL Workbench version - mysql-workbench-community-8.0.28-macos-x86_64.dmg
MySQL version - 5.6.10 (MySQL Community Server (GPL)) on AWS RDS
</code></pre>
",788,1,1,2,mysql;mysql-workbench,2022-04-01 01:41:34,2022-04-01 01:41:34,2022-04-10 13:55:31,up until recently i was using mysql workbench    without any issues till i upgraded my macos to   after which the workbench software itself stopped working  i then upgraded my workbench version to     latest version at the time of writing   but after updating to the new version  i initially had issues connecting to my remote databases  i was getting the following error   got error    ssl connection error  error f ssl routines ssl_choose_client_version unsupported protocol when trying to connect but i was able to solve that one by setting the  use ssl  option under the ssl tab for the connection to  no   the next issue though is now i am not able to perform exports on the server using mysqldump  the workbench software is trying to run the following command   running   applications mysqlworkbench app contents macos mysqldump   defaults file   var folders fd jtprtjzdqdyy_jcwgn t tmppuwxrtig extraparams cnf     host host db com   port    default character set utf   user logicspice   protocol tcp   single transaction true   column statistics    skip triggers  database  after which i m getting a similar issue   mysqldump  got error    ssl connection error  error f ssl routines ssl_choose_client_version unsupported protocol when trying to connect is there an update i can do to a certain configuration file for either mysqldump or mysql workbench that will disable the use of ssl when trying to use mysqldump  your assistance would be much appreciated as this issue is causing delays in my development work  thanks ,mysql workbench    export issue on macos  
351,7952980,71499421,How can I use the latest version of Hibernate Tools with Gradle to reverse engineer persistence objects from the database?,"<p>Following along with the answer to <a href=""https://stackoverflow.com/questions/66135295/hibernate-tools-reverse-engineering-with-gradle"">this question</a>, I was able to use Gradle to reverse engineer Java entities from a MySQL 8 database.</p>
<p>However, the highest version of <strong>hibernate-tools</strong> and <strong>hibernate-core</strong> that worked without error is <strong>4.3.5.Final</strong>.</p>
<p>When updating my build.gradle to use a newer version of <strong>hibernte-tools</strong> and <strong>hibernate-core</strong> (e.g. <strong>5.6.2.Final</strong> or newer), I get this error:</p>
<pre><code> Task :reverseMap FAILED
HHH000181: No appropriate connection provider encountered, assuming application will be supplying connections
HHH000342: Could not obtain connection to query metadata
java.lang.UnsupportedOperationException: The application must supply JDBC connections
        at org.hibernate.engine.jdbc.connections.internal.UserSuppliedConnectionProviderImpl.getConnection(UserSuppliedConnectionProviderImpl.java:44)
        at org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator$ConnectionProviderJdbcConnectionAccess.obtainConnection(JdbcEnvironmentInitiator.java:181)
        at org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator.initiateService(JdbcEnvironmentInitiator.java:68)
        at org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator.initiateService(JdbcEnvironmentInitiator.java:35)
        at org.hibernate.boot.registry.internal.StandardServiceRegistryImpl.initiateService(StandardServiceRegistryImpl.java:101)
        at org.hibernate.service.internal.AbstractServiceRegistryImpl.createService(AbstractServiceRegistryImpl.java:263)
        at org.hibernate.service.internal.AbstractServiceRegistryImpl.initializeService(AbstractServiceRegistryImpl.java:237)
        at org.hibernate.service.internal.AbstractServiceRegistryImpl.getService(AbstractServiceRegistryImpl.java:214)
        at org.hibernate.id.factory.internal.DefaultIdentifierGeneratorFactory.injectServices(DefaultIdentifierGeneratorFactory.java:175)
        at org.hibernate.service.internal.AbstractServiceRegistryImpl.injectDependencies(AbstractServiceRegistryImpl.java:286)
        at org.hibernate.service.internal.AbstractServiceRegistryImpl.initializeService(AbstractServiceRegistryImpl.java:243)
        at org.hibernate.service.internal.AbstractServiceRegistryImpl.getService(AbstractServiceRegistryImpl.java:214)
        at org.hibernate.boot.internal.InFlightMetadataCollectorImpl.&lt;init&gt;(InFlightMetadataCollectorImpl.java:173)
        at org.hibernate.tool.internal.metadata.JdbcMetadataDescriptor.getMetadataCollector(JdbcMetadataDescriptor.java:92)
        at org.hibernate.tool.internal.metadata.JdbcMetadataDescriptor.createMetadata(JdbcMetadataDescriptor.java:65)
        at org.hibernate.tool.hbm2x.AbstractExporter.buildMetadata(AbstractExporter.java:206)
        at org.hibernate.tool.hbm2x.AbstractExporter.getMetadata(AbstractExporter.java:56)
        at org.hibernate.tool.hbm2x.AbstractExporter.setupContext(AbstractExporter.java:177)
        at org.hibernate.tool.hbm2x.POJOExporter.setupContext(POJOExporter.java:35)
        at org.hibernate.tool.hbm2x.AbstractExporter.start(AbstractExporter.java:104)
        at org.hibernate.tool.ant.ExporterTask.execute(ExporterTask.java:39)
        at org.hibernate.tool.ant.HibernateToolTask.execute(HibernateToolTask.java:174)
        at org.apache.tools.ant.UnknownElement.execute(UnknownElement.java:299)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.base/java.lang.reflect.Method.invoke(Method.java:568)
        at org.apache.tools.ant.dispatch.DispatchUtils.execute(DispatchUtils.java:99)
        at groovy.util.AntBuilder.performTask(AntBuilder.java:335)
        at groovy.util.AntBuilder.nodeCompleted(AntBuilder.java:280)
        at org.gradle.api.internal.project.ant.BasicAntBuilder.nodeCompleted(BasicAntBuilder.java:90)
        at groovy.util.BuilderSupport.doInvokeMethod(BuilderSupport.java:160)
        at groovy.util.AntBuilder.doInvokeMethod(AntBuilder.java:215)
        at org.gradle.api.internal.project.ant.BasicAntBuilder.doInvokeMethod(BasicAntBuilder.java:117)
        at groovy.util.BuilderSupport.invokeMethod(BuilderSupport.java:74)
        at org.gradle.internal.metaobject.BeanDynamicObject$GroovyObjectAdapter.invokeOpaqueMethod(BeanDynamicObject.java:584)
        at org.gradle.internal.metaobject.BeanDynamicObject$MetaClassAdapter.invokeMethod(BeanDynamicObject.java:511)
        at org.gradle.internal.metaobject.BeanDynamicObject.tryInvokeMethod(BeanDynamicObject.java:196)
        at org.gradle.internal.metaobject.ConfigureDelegate.invokeMethod(ConfigureDelegate.java:56)
        at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeOnDelegationObjects(ClosureMetaClass.java:408)
        at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:348)
        at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:61)
        at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:51)
        at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:171)
        at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:194)
        at build_5jkow12rms5eudzcotor2w7gj$_run_closure6$_closure8$_closure9.doCall(/Users/samuel04/Dev/projects/Consultant-Dashboard/build.gradle:70)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.base/java.lang.reflect.Method.invoke(Method.java:568)
        at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:107)
        at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:323)
        at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:274)
        at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1035)
        at groovy.lang.Closure.call(Closure.java:412)
        at groovy.lang.Closure.call(Closure.java:428)
        at org.gradle.util.internal.ClosureBackedAction.execute(ClosureBackedAction.java:72)
        at org.gradle.util.internal.ConfigureUtil.configureTarget(ConfigureUtil.java:155)
        at org.gradle.util.internal.ConfigureUtil.configure(ConfigureUtil.java:106)
        at org.gradle.api.internal.project.DefaultProject.ant(DefaultProject.java:1189)
        at jdk.internal.reflect.GeneratedMethodAccessor688.invoke(Unknown Source)
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.base/java.lang.reflect.Method.invoke(Method.java:568)
        at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:107)
        at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:323)
        at org.gradle.internal.metaobject.BeanDynamicObject$MetaClassAdapter.invokeMethod(BeanDynamicObject.java:484)
        at org.gradle.internal.metaobject.BeanDynamicObject.tryInvokeMethod(BeanDynamicObject.java:196)
        at org.gradle.internal.metaobject.CompositeDynamicObject.tryInvokeMethod(CompositeDynamicObject.java:98)
        at org.gradle.internal.extensibility.MixInClosurePropertiesAsMethodsDynamicObject.tryInvokeMethod(MixInClosurePropertiesAsMethodsDynamicObject.java:34)
        at org.gradle.groovy.scripts.BasicScript$ScriptDynamicObject.tryInvokeMethod(BasicScript.java:135)
        at org.gradle.internal.metaobject.ConfigureDelegate.invokeMethod(ConfigureDelegate.java:77)
        at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeOnDelegationObjects(ClosureMetaClass.java:408)
        at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:348)
        at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1035)
        at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:819)
        at groovy.lang.GroovyObject.invokeMethod(GroovyObject.java:39)
        at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeOnDelegationObjects(ClosureMetaClass.java:424)
        at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:350)
        at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:61)
        at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:51)
        at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:171)
        at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:185)
        at build_5jkow12rms5eudzcotor2w7gj$_run_closure6$_closure8.doCall(/Users/samuel04/Dev/projects/Consultant-Dashboard/build.gradle:64)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.base/java.lang.reflect.Method.invoke(Method.java:568)
        at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:107)
        at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:323)
        at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:274)
        at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1035)
        at groovy.lang.Closure.call(Closure.java:412)
        at groovy.lang.Closure.call(Closure.java:428)
        at org.gradle.api.internal.AbstractTask$ClosureTaskAction.doExecute(AbstractTask.java:751)
        at org.gradle.api.internal.AbstractTask$ClosureTaskAction.lambda$execute$0(AbstractTask.java:738)
        at org.gradle.configuration.internal.DefaultUserCodeApplicationContext$CurrentApplication.reapply(DefaultUserCodeApplicationContext.java:98)
        at org.gradle.api.internal.AbstractTask$ClosureTaskAction.execute(AbstractTask.java:738)
        at org.gradle.api.internal.AbstractTask$ClosureTaskAction.execute(AbstractTask.java:713)
        at org.gradle.api.internal.tasks.execution.TaskExecution$3.run(TaskExecution.java:242)
        at org.gradle.internal.operations.DefaultBuildOperationRunner$1.execute(DefaultBuildOperationRunner.java:29)
        at org.gradle.internal.operations.DefaultBuildOperationRunner$1.execute(DefaultBuildOperationRunner.java:26)
        at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:66)
        at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:59)
        at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:157)
        at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:59)
        at org.gradle.internal.operations.DefaultBuildOperationRunner.run(DefaultBuildOperationRunner.java:47)
        at org.gradle.internal.operations.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:68)
        at org.gradle.api.internal.tasks.execution.TaskExecution.executeAction(TaskExecution.java:227)
        at org.gradle.api.internal.tasks.execution.TaskExecution.executeActions(TaskExecution.java:210)
        at org.gradle.api.internal.tasks.execution.TaskExecution.executeWithPreviousOutputFiles(TaskExecution.java:193)
        at org.gradle.api.internal.tasks.execution.TaskExecution.execute(TaskExecution.java:171)
        at org.gradle.internal.execution.steps.ExecuteStep.executeInternal(ExecuteStep.java:89)
        at org.gradle.internal.execution.steps.ExecuteStep.access$000(ExecuteStep.java:40)
        at org.gradle.internal.execution.steps.ExecuteStep$1.call(ExecuteStep.java:53)
        at org.gradle.internal.execution.steps.ExecuteStep$1.call(ExecuteStep.java:50)
        at org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:204)
        at org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:199)
        at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:66)
        at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:59)
        at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:157)
        at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:59)
        at org.gradle.internal.operations.DefaultBuildOperationRunner.call(DefaultBuildOperationRunner.java:53)
        at org.gradle.internal.operations.DefaultBuildOperationExecutor.call(DefaultBuildOperationExecutor.java:73)
        at org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:50)
        at org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:40)
        at org.gradle.internal.execution.steps.RemovePreviousOutputsStep.execute(RemovePreviousOutputsStep.java:68)
        at org.gradle.internal.execution.steps.RemovePreviousOutputsStep.execute(RemovePreviousOutputsStep.java:38)
        at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:48)
        at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:36)
        at org.gradle.internal.execution.steps.CancelExecutionStep.execute(CancelExecutionStep.java:41)
        at org.gradle.internal.execution.steps.TimeoutStep.executeWithoutTimeout(TimeoutStep.java:74)
        at org.gradle.internal.execution.steps.TimeoutStep.execute(TimeoutStep.java:55)
        at org.gradle.internal.execution.steps.CreateOutputsStep.execute(CreateOutputsStep.java:51)
        at org.gradle.internal.execution.steps.CreateOutputsStep.execute(CreateOutputsStep.java:29)
        at org.gradle.internal.execution.steps.CaptureStateAfterExecutionStep.execute(CaptureStateAfterExecutionStep.java:61)
        at org.gradle.internal.execution.steps.CaptureStateAfterExecutionStep.execute(CaptureStateAfterExecutionStep.java:42)
        at org.gradle.internal.execution.steps.BroadcastChangingOutputsStep.execute(BroadcastChangingOutputsStep.java:60)
        at org.gradle.internal.execution.steps.BroadcastChangingOutputsStep.execute(BroadcastChangingOutputsStep.java:27)
        at org.gradle.internal.execution.steps.BuildCacheStep.executeWithoutCache(BuildCacheStep.java:180)
        at org.gradle.internal.execution.steps.BuildCacheStep.lambda$execute$1(BuildCacheStep.java:75)
        at org.gradle.internal.Either$Right.fold(Either.java:175)
        at org.gradle.internal.execution.caching.CachingState.fold(CachingState.java:59)
        at org.gradle.internal.execution.steps.BuildCacheStep.execute(BuildCacheStep.java:73)
        at org.gradle.internal.execution.steps.BuildCacheStep.execute(BuildCacheStep.java:48)
        at org.gradle.internal.execution.steps.StoreExecutionStateStep.execute(StoreExecutionStateStep.java:36)
        at org.gradle.internal.execution.steps.StoreExecutionStateStep.execute(StoreExecutionStateStep.java:25)
        at org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:36)
        at org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:22)
        at org.gradle.internal.execution.steps.SkipUpToDateStep.executeBecause(SkipUpToDateStep.java:110)
        at org.gradle.internal.execution.steps.SkipUpToDateStep.lambda$execute$2(SkipUpToDateStep.java:56)
        at java.base/java.util.Optional.orElseGet(Optional.java:364)
        at org.gradle.internal.execution.steps.SkipUpToDateStep.execute(SkipUpToDateStep.java:56)
        at org.gradle.internal.execution.steps.SkipUpToDateStep.execute(SkipUpToDateStep.java:38)
        at org.gradle.internal.execution.steps.ResolveChangesStep.execute(ResolveChangesStep.java:73)
        at org.gradle.internal.execution.steps.ResolveChangesStep.execute(ResolveChangesStep.java:44)
        at org.gradle.internal.execution.steps.legacy.MarkSnapshottingInputsFinishedStep.execute(MarkSnapshottingInputsFinishedStep.java:37)
        at org.gradle.internal.execution.steps.legacy.MarkSnapshottingInputsFinishedStep.execute(MarkSnapshottingInputsFinishedStep.java:27)
        at org.gradle.internal.execution.steps.ResolveCachingStateStep.execute(ResolveCachingStateStep.java:89)
        at org.gradle.internal.execution.steps.ResolveCachingStateStep.execute(ResolveCachingStateStep.java:50)
        at org.gradle.internal.execution.steps.ValidateStep.execute(ValidateStep.java:114)
        at org.gradle.internal.execution.steps.ValidateStep.execute(ValidateStep.java:57)
        at org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:76)
        at org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:50)
        at org.gradle.internal.execution.steps.SkipEmptyWorkStep.executeWithNoEmptySources(SkipEmptyWorkStep.java:249)
        at org.gradle.internal.execution.steps.SkipEmptyWorkStep.execute(SkipEmptyWorkStep.java:86)
        at org.gradle.internal.execution.steps.SkipEmptyWorkStep.execute(SkipEmptyWorkStep.java:54)
        at org.gradle.internal.execution.steps.RemoveUntrackedExecutionStateStep.execute(RemoveUntrackedExecutionStateStep.java:32)
        at org.gradle.internal.execution.steps.RemoveUntrackedExecutionStateStep.execute(RemoveUntrackedExecutionStateStep.java:21)
        at org.gradle.internal.execution.steps.legacy.MarkSnapshottingInputsStartedStep.execute(MarkSnapshottingInputsStartedStep.java:38)
        at org.gradle.internal.execution.steps.LoadPreviousExecutionStateStep.execute(LoadPreviousExecutionStateStep.java:43)
        at org.gradle.internal.execution.steps.LoadPreviousExecutionStateStep.execute(LoadPreviousExecutionStateStep.java:31)
        at org.gradle.internal.execution.steps.AssignWorkspaceStep.lambda$execute$0(AssignWorkspaceStep.java:40)
        at org.gradle.api.internal.tasks.execution.TaskExecution$4.withWorkspace(TaskExecution.java:287)
        at org.gradle.internal.execution.steps.AssignWorkspaceStep.execute(AssignWorkspaceStep.java:40)
        at org.gradle.internal.execution.steps.AssignWorkspaceStep.execute(AssignWorkspaceStep.java:30)
        at org.gradle.internal.execution.steps.IdentityCacheStep.execute(IdentityCacheStep.java:37)
        at org.gradle.internal.execution.steps.IdentityCacheStep.execute(IdentityCacheStep.java:27)
        at org.gradle.internal.execution.steps.IdentifyStep.execute(IdentifyStep.java:44)
        at org.gradle.internal.execution.steps.IdentifyStep.execute(IdentifyStep.java:33)
        at org.gradle.internal.execution.impl.DefaultExecutionEngine$1.execute(DefaultExecutionEngine.java:76)
        at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeIfValid(ExecuteActionsTaskExecuter.java:144)
        at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:133)
        at org.gradle.api.internal.tasks.execution.CleanupStaleOutputsExecuter.execute(CleanupStaleOutputsExecuter.java:77)
        at org.gradle.api.internal.tasks.execution.FinalizePropertiesTaskExecuter.execute(FinalizePropertiesTaskExecuter.java:46)
        at org.gradle.api.internal.tasks.execution.ResolveTaskExecutionModeExecuter.execute(ResolveTaskExecutionModeExecuter.java:51)
        at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:57)
        at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:56)
        at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:36)
        at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.executeTask(EventFiringTaskExecuter.java:77)
        at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.call(EventFiringTaskExecuter.java:55)
        at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.call(EventFiringTaskExecuter.java:52)
        at org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:204)
        at org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:199)
        at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:66)
        at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:59)
        at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:157)
        at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:59)
        at org.gradle.internal.operations.DefaultBuildOperationRunner.call(DefaultBuildOperationRunner.java:53)
        at org.gradle.internal.operations.DefaultBuildOperationExecutor.call(DefaultBuildOperationExecutor.java:73)
        at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter.execute(EventFiringTaskExecuter.java:52)
        at org.gradle.execution.plan.LocalTaskNodeExecutor.execute(LocalTaskNodeExecutor.java:74)
        at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$InvokeNodeExecutorsAction.execute(DefaultTaskExecutionGraph.java:333)
        at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$InvokeNodeExecutorsAction.execute(DefaultTaskExecutionGraph.java:320)
        at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:313)
        at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:299)
        at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.lambda$run$0(DefaultPlanExecutor.java:143)
        at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.execute(DefaultPlanExecutor.java:227)
        at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.executeNextNode(DefaultPlanExecutor.java:218)
        at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.run(DefaultPlanExecutor.java:140)
        at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64)
        at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48)
        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base/java.lang.Thread.run(Thread.java:833)
[ant:hibernatetool] An exception occurred while running exporter #2:hbm2java (Generates a set of .java files)
[ant:hibernatetool] To get the full stack trace run ant with -verbose
[ant:hibernatetool] org.hibernate.service.spi.ServiceException: Unable to create requested service [org.hibernate.engine.jdbc.env.spi.JdbcEnvironment]
[ant:hibernatetool] org.hibernate.HibernateException: Access to DialectResolutionInfo cannot be null when 'hibernate.dialect' not set

FAILURE: Build failed with an exception.
</code></pre>
<p>This is my <strong>build.gradle</strong> file:</p>
<pre><code>plugins {
  id 'java'                                     // Java for Java application tasks
  id 'org.springframework.boot' version '2.6.3' // Spring Boot for quickly making applications with the Java Spring Framework
}

// The 'repositories' method specifies sources for Gradle to look at for application dependencies
repositories {
  mavenCentral() // Consult the Apache Maven software registry/build depot for dependencies
}

group = 'com.test.app' // Uniquely identifies the project (should follow the Java package name rules)
version = '1.0.0-SNAPSHOT'                           // The version of the project Gradle is building
sourceCompatibility = '17'                           // Java source language level
targetCompatibility = '17'                           // Java ByteCode language level

configurations {
  reverseMap
}

// The 'dependencies' method specifies the actual application dependencies and their types
dependencies {
  implementation(project(':src:main:ui'))                                        // This project uses the &quot;ui&quot; project
  annotationProcessor 'org.projectlombok:lombok:1.18.22'                         // Project Lombok is a lodash-like utility package for Java Spring applications
  compileOnly 'org.projectlombok:lombok:1.18.22'                                 // Project Lombok is a lodash-like utility package for Java Spring applications
  runtimeOnly 'mysql:mysql-connector-java:8.0.28'                                // JDBC Type 4 driver for MySQL database connections to Java applications
  testRuntimeOnly 'org.junit.jupiter:junit-jupiter-engine:5.8.2'                 // JUnit Jupiter Engine for Java unit testing
  implementation 'org.springframework.boot:spring-boot-starter-data-jpa:2.6.4'   // Spring Boot Starter Data JPA for using Spring Data JPA with Hibernate
  implementation 'org.springframework.boot:spring-boot-starter-validation:2.6.4' // Spring Boot Starter Validation for using Java Bean validation with Hibernate Validator
  implementation 'org.springframework.boot:spring-boot-starter-web:2.6.4'        // Spring Boot Starter Web for building web applications (using Spring MVC)
  testImplementation 'org.springframework.boot:spring-boot-starter-test:2.6.4'   // Spring Boot Starter Test for testing Spring Boot applications with JUnit Jupiter
  testImplementation 'io.github.bonigarcia:webdrivermanager:5.1.0'               // WebDriverManager
  testImplementation 'org.junit.jupiter:junit-jupiter-api:5.8.2'                 // JUnit Jupiter API for development
  testImplementation 'org.assertj:assertj-core:3.22.0'                           // AssertJ Fluent Assertions for Java unit testing
  reverseMap 'org.hibernate:hibernate-core:5.6.2.Final'
  reverseMap 'org.hibernate:hibernate-tools:5.6.2.Final'
  reverseMap 'org.slf4j:slf4j-simple:1.7.36'
  reverseMap 'mysql:mysql-connector-java:8.0.28'
}

tasks.test {
  useJUnitPlatform()
}

project.ext {
  hibernateDestDir = file(&quot;$projectDir/src/main/java&quot;)
}

task reverseMap {
  outputs.dir hibernateDestDir
  doLast {
    hibernateDestDir.exists() || hibernateDestDir.mkdirs()
    ant {
      taskdef(
              name: 'hibernatetool',
              classname: 'org.hibernate.tool.ant.HibernateToolTask',
              classpath: configurations.reverseMap.asPath
      )
      hibernatetool(destdir: hibernateDestDir) {
        jdbcconfiguration(
                configurationfile: &quot;$projectDir/provision/reverse-engineering/hibernate.cfg.xml&quot;,
                packagename: &quot;com.test.app.persistence&quot;
        )
        hbm2java(
                jdk5: true,
                ejb3: true
        )
      }
    }
  }
}
</code></pre>
<p>This is my <strong>hibernate.cfg.xml</strong> file:</p>
<pre><code>&lt;?xml version = &quot;1.0&quot; encoding = &quot;utf-8&quot;?&gt;
&lt;!DOCTYPE hibernate-configuration SYSTEM
        &quot;http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd&quot;&gt;
&lt;hibernate-configuration&gt;
    &lt;session-factory&gt;
        &lt;property name=&quot;hibernate.dialect&quot;&gt;
            org.hibernate.dialect.MySQLDialect
        &lt;/property&gt;
        &lt;property name=&quot;hibernate.connection.driver_class&quot;&gt;
            com.mysql.cj.jdbc.Driver
        &lt;/property&gt;
        &lt;property name=&quot;hibernate.connection.url&quot;&gt;
            jdbc:mysql://127.0.0.1:3306/db
        &lt;/property&gt;
        &lt;property name=&quot;hibernate.connection.username&quot;&gt;
            dbuser
        &lt;/property&gt;
        &lt;property name=&quot;hibernate.connection.password&quot;&gt;
            dbpass
        &lt;/property&gt;
    &lt;/session-factory&gt;
&lt;/hibernate-configuration&gt;
</code></pre>
<p>Something has changed between version 4.x.x and 5.x.x of Hibernate Tools and Hibernate Core. Has anyone else encountered this in a Gradle build? If so, how did you resolve it?</p>
",227,1,1,4,java;spring;gradle;hibernate-tools,2022-03-16 17:03:46,2022-03-16 17:03:46,2022-04-10 12:27:20,following along with the answer to   i was able to use gradle to reverse engineer java entities from a mysql  database  however  the highest version of hibernate tools and hibernate core that worked without error is    final  when updating my build gradle to use a newer version of hibernte tools and hibernate core  e g     final or newer   i get this error  this is my build gradle file  this is my hibernate cfg xml file  something has changed between version  x x and  x x of hibernate tools and hibernate core  has anyone else encountered this in a gradle build  if so  how did you resolve it ,how can i use the latest version of hibernate tools with gradle to reverse engineer persistence objects from the database 
352,18074892,71812355,how to make a second down menu under the first using only html and css,"<p>I was trying my best to do a down menu for my project and I was searching on youtube for about a week and it was useless.</p>
<p>The code hints:</p>
<p>The commented code are unfinished code that still I have to edit
Most of code are not styled yet because I am still testing the code of the development menu</p>
<p><strong>HTML:</strong></p>
<pre><code>    &lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot;&gt;
  &lt;head&gt;
    &lt;meta charset=&quot;UTF-8&quot; /&gt;
    &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot; /&gt;
    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; /&gt;
    &lt;title&gt;ABF&lt;/title&gt;
    &lt;link rel=&quot;stylesheet&quot; href=&quot;style.css&quot; /&gt;
    &lt;link
      rel=&quot;stylesheet&quot;
      href=&quot;https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css&quot;
    /&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;header&gt;
      &lt;ul class=&quot;right-side&quot;&gt;
        &lt;li&gt;
          &lt;a class=&quot;header-title&quot;&gt;abf&lt;/a&gt;
        &lt;/li&gt;
        &lt;li class=&quot;menu&quot;&gt;
          &lt;a class=&quot;header-courses&quot;&gt;courses&lt;i class=&quot;fas fa-caret-down&quot;&gt;&lt;/i&gt;&lt;/a&gt;
          &lt;div class=&quot;sub-menu-div&quot;&gt;
            &lt;ul class=&quot;sub-menu&quot;&gt;

              &lt;li class=&quot;development-menu&quot;&gt;
                &lt;a href=&quot;#&quot; class=&quot;development-menu-title&quot;&gt;Development&lt;/a&gt;
                &lt;i class=&quot;fa-solid fa-caret-right development-right-arrow&quot;&gt;&lt;/i&gt;

                &lt;div class=&quot;development-down-menu&quot;&gt;
                  &lt;ul&gt;
                    &lt;li&gt;&lt;a href=&quot;#&quot;&gt;Front end&lt;/a&gt;&lt;/li&gt;
                    &lt;li&gt;&lt;a href=&quot;#&quot;&gt;Back end&lt;/a&gt;&lt;/li&gt;
                  &lt;/ul&gt;
                &lt;/div&gt;
              &lt;/li&gt;

              &lt;li class=&quot;business-menu&quot;&gt;
                &lt;a href=&quot;#&quot; class=&quot;business-down-menu-title&quot;&gt;Business&lt;/a&gt;
                &lt;i class=&quot;fa-solid fa-caret-right business-right-arrow&quot;&gt;&lt;/i&gt;
                &lt;!-- &lt;div class=&quot;business-down-menu&quot;&gt;
                  &lt;ul&gt;
                    &lt;li&gt;&lt;a href=&quot;#&quot; class=&quot;business-down-menu-Management&quot;&gt;Management &lt;/a&gt;&lt;/li&gt;
                    &lt;li&gt;&lt;a href=&quot;#&quot; class=&quot;business-down-menu-sales&quot;&gt;Sales&lt;/a&gt;&lt;/li&gt;
                  &lt;/ul&gt;
                &lt;/div&gt; --&gt;
              &lt;/li&gt;

              &lt;li class=&quot;IT--Software-menu&quot;&gt;
                &lt;a href=&quot;#&quot; class=&quot;IT--Software-down-menu-title&quot;&gt;IT &amp; Software&lt;/a&gt;
                &lt;i class=&quot;fa-solid fa-caret-right IT--Software-right-arrow&quot;&gt;&lt;/i&gt;
                &lt;!-- &lt;div class=&quot;IT--Software-down-menu&quot;&gt;
                  &lt;ul&gt;
                    &lt;li&gt;&lt;a href=&quot;#&quot; class=&quot;IT--Software-down-menu-Hardware&quot;&gt;Hardware &lt;/a&gt;&lt;/li&gt;
                    &lt;li&gt;&lt;a href=&quot;#&quot; class=&quot;IT--Software-down-menu-Network--Security&quot;&gt;Network &amp; Security&lt;/a&gt;&lt;/li&gt;
                  &lt;/ul&gt;
                &lt;/div&gt; --&gt;
              &lt;/li&gt;

               &lt;li class=&quot;Finance--Accounting-menu&quot;&gt;
                &lt;a href=&quot;#&quot;&gt;Finance &amp; Accounting&lt;/a&gt;
                &lt;i class=&quot;fa-solid fa-caret-right Finance--Accounting-right-arrow&quot;&gt;&lt;/i&gt;
                &lt;!-- &lt;div class=&quot;Finance--Accounting-down-menu&quot;&gt;
                  &lt;ul&gt;
                    &lt;li&gt;&lt;a href=&quot;#&quot;&gt;Finance &lt;/a&gt;&lt;/li&gt;
                    &lt;li&gt;&lt;a href=&quot;#&quot;&gt;Economics&lt;/a&gt;&lt;/li&gt;
                  &lt;/ul&gt;
                &lt;/div&gt; --&gt;
              &lt;/li&gt; 

               &lt;li class=&quot;Design-menu&quot;&gt;
                &lt;a href=&quot;#&quot;&gt;Design&lt;/a&gt;
                &lt;i class=&quot;fa-solid fa-caret-right Design-right-arrow&quot;&gt;&lt;/i&gt;
                &lt;!-- &lt;div class=&quot;Design-down-menu&quot;&gt;
                  &lt;ul&gt;
                    &lt;li&gt;&lt;a href=&quot;#&quot;&gt;Web Design &lt;/a&gt;&lt;/li&gt;
                    &lt;li&gt;&lt;a href=&quot;#&quot;&gt;Game Design&lt;/a&gt;&lt;/li&gt;
                  &lt;/ul&gt;
                &lt;/div&gt; --&gt;
              &lt;/li&gt;

               &lt;li class=&quot;markting-menu&quot;&gt;
                &lt;a href=&quot;#&quot;&gt;markting&lt;/a&gt;
                &lt;i class=&quot;fa-solid fa-caret-right markting-right-arrow&quot;&gt;&lt;/i&gt;
                &lt;!-- &lt;div class=&quot;marketing-down-menu&quot;&gt;
                  &lt;ul&gt;
                    &lt;li&gt;&lt;a href=&quot;#&quot;&gt;Digital Marketing &lt;/a&gt;&lt;/li&gt;
                    &lt;li&gt;&lt;a href=&quot;#&quot;&gt;Branding&lt;/a&gt;&lt;/li&gt;
                  &lt;/ul&gt;
                &lt;/div&gt; --&gt;
              &lt;/li&gt;  

               &lt;li class=&quot;Music-menu&quot;&gt;   
                 &lt;a href=&quot;#&quot;&gt;Music&lt;/a&gt;
                &lt;i class=&quot;fa-solid fa-caret-right Music-right-arrow&quot;&gt;&lt;/i&gt;
                &lt;!-- &lt;div class=&quot;Music-down-menu&quot;&gt;
                  &lt;ul&gt;
                    &lt;li&gt;&lt;a href=&quot;#&quot;&gt;Instruments&lt;/a&gt;&lt;/li&gt;
                    &lt;li&gt;&lt;a href=&quot;#&quot;&gt;Music Production&lt;/a&gt;&lt;/li&gt;
                  &lt;/ul&gt;
                &lt;/div&gt; --&gt;

              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/div&gt;
        &lt;/li&gt;
      &lt;/ul&gt;

      &lt;form class=&quot;search-bar&quot;&gt;
        &lt;input class=&quot;search-input&quot; type=&quot;text&quot; placeholder=&quot;search&quot; /&gt;
        &lt;i class=&quot;fa-solid fa-magnifying-glass&quot;&gt;&lt;/i&gt;
      &lt;/form&gt;

      &lt;nav&gt;
        &lt;a href=&quot;&quot; class=&quot;login&quot;&gt;Login&lt;/a&gt;
        &lt;a href=&quot;&quot; class=&quot;sign-up&quot;&gt;Sign up&lt;/a&gt;
      &lt;/nav&gt;
    &lt;/header&gt;
    &lt;section class=&quot;main-section&quot;&gt;
      &lt;div class=&quot;main-wisdom&quot;&gt;
        &lt;p class=&quot;wisdom&quot;&gt;
          Unlimited Content &lt;br /&gt;
          of online courses
        &lt;/p&gt;
      &lt;/div&gt;
      &lt;div class=&quot;main-shape&quot;&gt;
        &lt;div class=&quot;main-shape1&quot;&gt;&lt;/div&gt;
        &lt;div class=&quot;main-shape2&quot;&gt;&lt;/div&gt;
        &lt;img class=&quot;man&quot; src=&quot;images/man.png&quot; alt=&quot;&quot; /&gt;
      &lt;/div&gt;
    &lt;/section&gt;
    &lt;!-- &lt;section class=&quot;some-courses&quot;&gt;
      &lt;h2&gt;Some Courses&lt;/h2&gt;
      &lt;div class=&quot;courses&quot;&gt;
        &lt;div class=&quot;Some-Courses-course&quot;&gt;

        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/section&gt; --&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>
<p><strong>CSS:</strong></p>
<pre><code>@import url('https://fonts.googleapis.com/css2?family=Playfair+Display:ital,wght@0,400;0,500;0,600;0,700;0,800;0,900;1,400;1,500;1,600;1,700;1,800;1,900&amp;family=Poppins:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,400;1,500;1,600;1,700;1,800;1,900&amp;display=swap');

*{
    padding: 0px;
    margin: 0px;
    box-sizing: border-box;
    scroll-behavior: smooth;
}
header{
    width: 100%;
    background-color: white;
    display: flex;
    z-index: 999;
    position: fixed;
    align-items: center;
    padding: 10px ;
    box-shadow: 0px 3px 3px rgba(1, 1, 1, 15%);
    position: absolute;
}

.right-side{
    height: 100%;
}
.header-title{
    text-decoration: none;
    font-size: 2em;
    font-weight: 800;
    text-transform: uppercase;
    padding-left: 30px;
}
.header-courses{
    font-size: 1.5em;
    padding-left: 30px;
    padding-right: 30px;
    position: relative;
    top: 6px;
    
}
.header-courses:hover{
    color: #5b0fb3;
}

.fa-caret-down{
    font-size: 16px;
    margin-left: 5px;
}
.courses-down-menu{
    display: none;
}
.right-side{
    position: relative;
    display: block;
    float: left;
}
.right-side &gt; li{
    float: left;
}
.sub-menu {
    list-style-type: none;
    display: none;
    position: absolute;
    padding: 20px;
    width: 200px;
    height: 310px;
    top: 30px;
    background-color: white;
    box-shadow: 0px 3px 3px rgba(1, 1, 1, 15%);
}
.sub-menu li{
    padding-bottom: 15px;
}
.sub-menu li a{
    cursor: pointer;
    text-decoration: none;
    color: black;
}
.sub-menu li a:hover{
    color: #5b0fb3;
}
.right-side .menu:hover .sub-menu{
    display: block;
}

/* Development */
.development-menu a{
    font-size: 1.2em;
    list-style-type: none;
}
.development-right-arrow{
    position: relative;
    left: 45px;
}
.development-down-menu{
    display: none;
    position: absolute;
    padding: 20px;
    width: 150px;
    height: 310px;
    top: 0px;
    left: 200px;
    background-color: white;
    box-shadow: 0px 3px 3px rgba(1, 1, 1, 15%);
}
.courses-down-menu ul {
    list-style-type: none;
    position: relative;
    left: 20px;
    padding-bottom: 15px;
}
.sub-menu-div ul li:hover .development-down-menu{
    display: block;
}
/* Business */
.business-menu a{
    font-size: 1.2em;
    list-style-type: none;
}
.business-right-arrow{
    position: relative;
    left: 78px;
}

/* IT&amp;Software */
.IT--Software-menu a{
    font-size: 1.2em;
    list-style-type: none;
}

.IT--Software-right-arrow{
    position: relative;
    left: 35px;
}

/* Finnace&amp;Accounting */
.Finance--Accounting-menu a{
    font-size: 1.2em;
    list-style-type: none;
}
.Finance--Accounting-right-arrow{
    position: relative;
    left: 55px;
}

/* Design */
.Design-menu a{
    font-size: 1.2em;
    list-style-type: none;
}
.Design-right-arrow{
    position: relative;
    left: 88px;
}

/* marketing */
.markting-menu a{
    font-size: 1.2em;
    list-style-type: none;
}
.markting-right-arrow{
    position: relative;
    left: 73px;
}

/* Music */
.Music-menu a{
    font-size: 1.2em;
    list-style-type: none;
}
.Music-right-arrow{
    position: relative;
    left: 93px;
}

.search-bar{
    background-color: #F2F0F0;
    width: 800px;
    height: 35px;
    margin-right: 30px;
    border-radius: 20px;
}
.search-input{
    width: 770px;
    height: 35px;
    outline: none;
    border: none;
    background-color: #F2F0F0;
    border-radius: 20px;
    text-align: left;
    padding-left: 20px;
}
nav{
    display: block;
    height: 100%;
    margin-left: 30px;
}
.login{
    display: inline-block;
    text-decoration: none;
    border: 2px solid black;
    width: 100px;
    height: 35px;
    color: black;
    text-align: center;
    display: flex;
    justify-content: center;
    align-items: center;
    float: left;
    margin-right: 10px;
}
.sign-up{
    display: inline-block;
    text-decoration: none;
    background-color: black;
    width: 100px;
    height: 35px;
    color: white;
    text-align: center;
    display: flex;
    justify-content: center;
    align-items: center;
    float: right;
}
.main-section{
    background-color: #F4F4F4;
    width: 100%;
    height: 600px;
    position: absolute;
}
.main-wisdom{
    width: 500px;
    height: 200px;
    position: relative;
    left: 100px;
    top: 180px;
    display: flex;
    align-items: center;
    justify-content: center;
    background-color: white;
    box-shadow: 0px 3px 3px rgba(1, 1, 1, 15%);
}
.wisdom{
    font-family: 'Playfair Display', serif;
    font-size: 3em;

}
.main-shape1{
    width: 400px;
    height: 250px;
    position: relative;
    left: 700px;
    top: 150px;
    background-color: #6607D6;

}
.main-shape2{
    width: 340px;
    height: 350px;
    position: relative;
    left: 950px;
    bottom: 200px;
    background-color: #6607D6;
}
.man{
    position: relative;
    bottom: 598px;
    left: 805px;
    size: 10px;
}
</code></pre>
",38,0,0,5,html;css;web;drop-down-menu;menu,2022-04-10 01:23:41,2022-04-10 01:23:41,2022-04-10 01:23:41,i was trying my best to do a down menu for my project and i was searching on youtube for about a week and it was useless  the code hints  html  css ,how to make a second down menu under the first using only html and css
353,611724,71795637,&#39;bundle exec passenger start&#39; failing on Rake command,"<p>I'm using passenger 5.3.2 in a Ruby on Rails app. My dev environment is MacOS 12.1, I'm using Ruby 2.6.6</p>
<p>Bundle install succeeded.</p>
<p>When I try and run
<code>bundle exec passenger start</code>
I get the following message:</p>
<pre><code> --&gt; Downloading a Phusion Passenger agent binary for your platform
     Could not download https://oss-binaries.phusionpassenger.com/binaries/passenger/by_release/5.3.2/agent-x86_64-macosx-12.1.tar.gz: The requested URL returned error: 404
     Trying next mirror...
     Could not download https://s3.amazonaws.com/phusion-passenger/binaries/passenger/by_release/5.3.2/agent-x86_64-macosx-12.1.tar.gz: The requested URL returned error: 403
     ------------------------------------------
     Sorry, no precompiled agent binary is available for your platform.

---------------------------------------

The Phusion Passenger agent binary could not be downloaded. Compiling it from source instead.
</code></pre>
<p>It then proceeds</p>
<pre><code>Checking for required software...

 * Checking for C compiler...
      Found: yes
      Location: /usr/bin/cc
 * Checking for C++ compiler...
      Found: yes
      Location: /usr/bin/c++
 * Checking for Rake (associated with /Users/stefan/.rvm/gems/ruby-2.6.6/wrappers/ruby)...
      Found: yes
      Location: /Users/stefan/.rvm/gems/ruby-2.6.6/wrappers/rake
 * Checking for Curl development headers with SSL support...
      Found: yes
      curl-config location: /usr/bin/curl-config
      Header location: /Library/Developer/CommandLineTools/SDKs/MacOSX12.1.sdk/usr/include/curl/curl.h
      Version: libcurl 7.77.0
      Usable: yes
      Supports SSL: yes
 * Checking for OpenSSL development headers...
      Found: yes
      Location: /usr/local/opt/openssl/include/openssl/ssl.h
 * Checking for Zlib development headers...
      Found: yes
      Location: /Library/Developer/CommandLineTools/SDKs/MacOSX12.1.sdk/usr/include/zlib.h


--------------------------------------------

Compile the agent with optimizations?

Compiling the agent with optimizations will make Phusion Passenger faster, but
it will take longer to compile and it requires at least 2 GB of memory.

Compile with optimizations? [y/n]: n  
</code></pre>
<p>After that it fails with error</p>
<pre><code>*** ERROR: a Rake command failed. You can find the full log in /var/folders/9s/0sjkwffd4kv3xp_1y_xfcg8h0000gn/T/passenger-install-log-9wh8h1. Below, you can find the last few lines of the command's output.
------------- Begin command output snippet -------------
rake aborted!
Command failed with status (1): [c++ -o /var/folders/9s/0sjkwffd4kv3xp_1y_xfcg8h0000gn/T/passenger-install.2eduk2/support-binaries/WatchdogMain.o  -Isrc/agent -Isrc/cxx_supportlib -Isrc/cxx_supportlib/vendor-copy -Isrc/cxx_supportlib/vendor-modified -Isrc/cxx_supportlib/vendor-modified/libev -Wno-ambiguous-member-template -Isrc/cxx_supportlib/vendor-copy/libuv/include -Isrc/cxx_supportlib/vendor-copy/websocketpp -I/usr/local/opt/openssl/include -D_REENTRANT -I/usr/local/include -Wall -Wextra -Wno-unused-parameter -Wno-parentheses -Wpointer-arith -Wwrite-strings -Wno-long-long -Wno-missing-field-initializers -Wno-ambiguous-member-template -fvisibility=hidden -DVISIBILITY_ATTRIBUTE_SUPPORTED -DHAS_ALLOCA_H -DHAS_SFENCE -DHAS_LFENCE -DPASSENGER_DEBUG -DBOOST_DISABLE_ASSERTS -g -fno-limit-debug-info -std=gnu++11 -Wno-unused-local-typedefs -DHAS_UNORDERED_MAP -c src/agent/Watchdog/WatchdogMain.cpp]
/Users/stefan/.rvm/gems/ruby-2.6.6/gems/passenger-5.3.2/build/support/cplusplus.rb:53:in `run_compiler'
/Users/stefan/.rvm/gems/ruby-2.6.6/gems/passenger-5.3.2/build/support/cplusplus.rb:104:in `compile_cxx'
/Users/stefan/.rvm/gems/ruby-2.6.6/gems/passenger-5.3.2/build/support/cplusplus.rb:162:in `block in define_cxx_object_compilation_task'
/Users/stefan/.rvm/gems/ruby-2.6.6/gems/rake-13.0.3/lib/rake/task.rb:281:in `block in execute'
</code></pre>
<p>Any advice on how to resolve this?
I'm out of my depth here. Running with optimizations gives same result.</p>
<p>Thank you.</p>
",99,1,0,4,ruby-on-rails;ruby;rubygems;passenger,2022-04-08 13:44:29,2022-04-08 13:44:29,2022-04-08 21:04:13,i m using passenger    in a ruby on rails app  my dev environment is macos    i m using ruby    bundle install succeeded  it then proceeds after that it fails with error thank you ,   bundle exec passenger start    failing on rake command
354,6774425,71790948,iterate over columns to count words in a sentence and put it in a new column,"<p>I have some columns titles essay 0-9, I want to iterate over them count the words and then make a new column with the number of words. so essay0 will get a column essay0_num with 5 if that is how many words it has in it.</p>
<p>so far i got <code>cupid &lt;- cupid %&gt;% mutate(essay9_num = sapply(strsplit(essay9, &quot; &quot;), length))</code>
to count the words and add a column but i don't want to do it one by one for all 10.</p>
<p>i tried a for loop:</p>
<pre><code>for (i in 0:31) {
   cupid &lt;- cupid %&gt;% mutate(xxx_num = sapply(strsplit(xxx, &quot; &quot;), length))
}
</code></pre>
<p>but i am not sure how iterate the columns in a for loop in R. I thought maybe i can pull out the columns i need and put them into a new df and use sapply somehow that way? but i still run into the problem of iterating over the columns.</p>
<p>dput:</p>
<pre><code>dput(head(cupid))
structure(list(age = c(22L, 35L, 38L, 23L, 29L, 29L), status = c(&quot;single&quot;, 
&quot;single&quot;, &quot;available&quot;, &quot;single&quot;, &quot;single&quot;, &quot;single&quot;), sex = c(&quot;m&quot;,
&quot;m&quot;, &quot;m&quot;, &quot;m&quot;, &quot;m&quot;, &quot;m&quot;), orientation = c(&quot;straight&quot;, &quot;straight&quot;,
&quot;straight&quot;, &quot;straight&quot;, &quot;straight&quot;, &quot;straight&quot;), body_type = c(&quot;a little extra&quot;,
&quot;average&quot;, &quot;thin&quot;, &quot;thin&quot;, &quot;athletic&quot;, &quot;average&quot;), diet = c(&quot;strictly anything&quot;,
&quot;mostly other&quot;, &quot;anything&quot;, &quot;vegetarian&quot;, &quot;&quot;, &quot;mostly anything&quot;
), drinks = c(&quot;socially&quot;, &quot;often&quot;, &quot;socially&quot;, &quot;socially&quot;, &quot;socially&quot;, 
&quot;socially&quot;), drugs = c(&quot;never&quot;, &quot;sometimes&quot;, &quot;&quot;, &quot;&quot;, &quot;never&quot;,
&quot;&quot;), education = c(&quot;working on college/university&quot;, &quot;working on space camp&quot;,
&quot;graduated from masters program&quot;, &quot;working on college/university&quot;,
&quot;graduated from college/university&quot;, &quot;graduated from college/university&quot;
), ethnicity = c(&quot;asian, white&quot;, &quot;white&quot;, &quot;&quot;, &quot;white&quot;, &quot;asian, black, other&quot;,
&quot;white&quot;), height = c(75, 70, 68, 71, 66, 67), income = c(-1L, 
80000L, -1L, 20000L, -1L, -1L), job = c(&quot;transportation&quot;, &quot;hospitality / travel&quot;,
&quot;&quot;, &quot;student&quot;, &quot;artistic / musical / writer&quot;, &quot;computer / hardware / software&quot;
), last_online = c(&quot;2012-06-28-20-30&quot;, &quot;2012-06-29-21-41&quot;, &quot;2012-06-27-09-10&quot;,
&quot;2012-06-28-14-22&quot;, &quot;2012-06-27-21-26&quot;, &quot;2012-06-29-19-18&quot;),
    location = c(&quot;south san francisco, california&quot;, &quot;oakland, california&quot;,
    &quot;san francisco, california&quot;, &quot;berkeley, california&quot;, &quot;san francisco, california&quot;, 
    &quot;san francisco, california&quot;), offspring = c(&quot;doesn't have kids, but might want them&quot;,
    &quot;doesn't have kids, but might want them&quot;, &quot;&quot;, &quot;doesn't want kids&quot;,
    &quot;&quot;, &quot;doesn't have kids, but might want them&quot;), pets = c(&quot;likes dogs and likes cats&quot;,
    &quot;likes dogs and likes cats&quot;, &quot;has cats&quot;, &quot;likes cats&quot;, &quot;likes dogs and likes cats&quot;,
    &quot;likes cats&quot;), religion = c(&quot;agnosticism and very serious about it&quot;,
    &quot;agnosticism but not too serious about it&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;atheism&quot;
    ), sign = c(&quot;gemini&quot;, &quot;cancer&quot;, &quot;pisces but it doesn&amp;rsquo;t matter&quot;,
    &quot;pisces&quot;, &quot;aquarius&quot;, &quot;taurus&quot;), smokes = c(&quot;sometimes&quot;,
    &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;), speaks = c(&quot;english&quot;, &quot;english (fluently), spanish (poorly), french (poorly)&quot;,
    &quot;english, french, c++&quot;, &quot;english, german (poorly)&quot;, &quot;english&quot;,
    &quot;english (fluently), chinese (okay)&quot;), essay0 = c(&quot;about me:  i would love to think that i was some some kind of intellectual: either the dumbest smart guy, or the smartest dumb guy. can't say i can tell the difference. i love to talk about ideas and concepts. i forge odd metaphors instead of reciting cliches. like the simularities between a friend of mine's house and an underwater salt mine. my favorite word is salt by the way (weird choice i know). to me most things in life are better as metaphors. i seek to 
make myself a little better everyday, in some productively lazy way. got tired of tying my shoes. considered hiring a five year old, but would probably have to tie both of our shoes... decided to only wear leather shoes dress shoes.  about you:  you love to have really serious, really deep conversations about really silly stuff. you have to be willing to snap me out of a light hearted rant with a kiss. you don't have to be funny, but you have to be able to make me laugh. you should be able to bend spoons with your 
mind, and telepathically make me smile while i am still at work. you should love life, and be cool with just letting the wind blow. extra points for reading all this and guessing my favorite video game (no hints given yet). and lastly you have a good attention span.&quot;,
    &quot;i am a chef: this is what that means. 1. i am a workaholic. 2. i love to cook regardless of whether i am at work. 3. i love to drink and eat foods that are probably really bad for me. 4. i love being around people that resemble line 1-3. i love the outdoors and i am an avid skier. if its snowing i will be in tahoe at the very least. i am a very confident and friendly. i'm not interested in acting or being a typical guy. i have no time or patience for rediculous acts of territorial pissing. overall i am a very 
likable easygoing individual. i am very adventurous and always looking forward to doing new things and hopefully sharing it with the right person.&quot;,
    &quot;i'm not ashamed of much, but writing public text on an online dating site makes me pleasantly uncomfortable. i'll try to be as earnest as possible in the noble endeavor of standing naked before the world.  i've lived in san francisco for 15 years, and both love it and find myself frustrated with its deficits. lots of great friends and acquaintances (which increases my apprehension to put anything on this site), but i'm feeling like meeting some new people that aren't just friends of friends. it's okay if you are a friend of a friend too. chances are, if you make it through the complex filtering process of multiple choice questions, lifestyle statistics, photo scanning, and these indulgent blurbs of text without moving quickly on to another search result, you are probably already a cultural peer and at most 2 people removed. at first, i thought i should say as little as possible here to avoid 
you, but that seems silly.  as far as culture goes, i'm definitely more on the weird side of the spectrum, but i don't exactly wear it on my sleeve. once you get me talking, it will probably become increasingly apparent that while i'd like to think of myself as just like everybody else (and by some definition i certainly am), most people don't see me that way. that's fine with me. most of the people i find myself gravitating towards are pretty weird themselves. you probably are too.&quot;,
    &quot;i work in a library and go to school. . .&quot;, &quot;hey how's it going? currently vague on the profile i know, more to come soon. looking to meet new folks outside of my circle of friends. i'm pretty responsive on the reply tip, feel free to drop a line. cheers.&quot;,
    &quot;i'm an australian living in san francisco, but don't hold that against me. i spend most of my days trying to build cool stuff for my company. i speak mandarin and have been known to bust out chinese songs at karaoke. i'm pretty cheeky. someone asked me if that meant something about my arse, which i find really funny.  i'm a little oddball. i have a wild imagination; i like to think 
of the most improbable reasons people are doing things just for fun. i love to laugh and look for reasons to do so. occasionally this gets me in trouble because people think i'm laughing at them. sometimes i am, but more often i'm only laughing at myself.  i'm an entrepreneur (like everyone else in sf, it seems) and i love what i do. i enjoy parties and downtime in equal measure. intelligence really turns me on and i love people who can teach me new things.&quot;
    ), essay1 = c(&quot;currently working as an international agent for a freight forwarding company. import, export, domestic you know the works. online classes and trying to better myself in my free time. perhaps a hours worth of a good book or a video game on a 
lazy sunday.&quot;,
    &quot;dedicating everyday to being an unbelievable badass.&quot;, &quot;i make nerdy software for musicians, artists, and experimenters to indulge in their own weirdness, but i like to spend time away from the computer when working on my artwork (which is typically more 
concerned with group dynamics and communication, than with visual form, objects, or technology). i also record and deejay dance, noise, pop, and experimental music (most of which electronic or at least studio based). besides these relatively ego driven activities, i've been enjoying things like meditation and tai chi to try and gently flirt with ego death.&quot;,
    &quot;reading things written by old dead people&quot;, &quot;work work work work + play&quot;,
    &quot;building awesome stuff. figuring out what's important. having adventures. looking for treasure.&quot;
    ), essay2 = c(&quot;making people laugh. ranting about a good salting. finding simplicity in complexity, and complexity in simplicity.&quot;,
    &quot;being silly. having ridiculous amonts of fun wherever. being a smart ass. ohh and i can cook. ;)&quot;,
    &quot;improvising in different contexts. alternating between being present and decidedly outside of a moment, or trying to hold both at once. rambling intellectual conversations that hold said conversations in contempt while seeking to find something that transcends them. being critical while remaining generous. listening to and using body language--often performed in caricature or large 
gestures, if not outright interpretive dance. dry, dark, and raunchy humor.&quot;, 
    &quot;playing synthesizers and organizing books according to the library of congress classification system&quot;,
    &quot;creating imagery to look at: http://bagsbrown.blogspot.com/ http://stayruly.blogspot.com/&quot;,
    &quot;imagining random shit. laughing at aforementioned random shit. being goofy. articulating what i think and feel. convincing people i'm right. admitting when i'm wrong.  i'm also pretty good at helping people think through problems; my friends say i give good advice. and when i don't have a clue how to help, i will say: i give pretty good hug.&quot;
    ), essay3 = c(&quot;the way i look. i am a six foot half asian, half caucasian mutt. it makes it tough not to notice me, and for me to blend in.&quot;,
    &quot;&quot;, &quot;my large jaw and large glasses are the physical things people comment on the most. when sufficiently stimulated, i have an unmistakable cackle of a laugh. after that, it goes in more directions than i care to describe right now. maybe i'll come back to this.&quot;,
    &quot;socially awkward but i do my best&quot;, &quot;i smile a lot and my inquisitive nature&quot;, 
    &quot;i have a big smile. i also get asked if i'm wearing blue-coloured contacts (no).&quot;
    ), essay4 = c(&quot;books: absurdistan, the republic, of mice and men (only book that made me want to cry), catcher in the rye, the prince.  movies: gladiator, operation valkyrie, the producers, down periscope.  shows: the borgia, arrested development, game of 
thrones, monty python  music: aesop rock, hail mary mallon, george thorogood and the delaware destroyers, felt  food: i'm down for anything.&quot;,
    &quot;i am die hard christopher moore fan. i don't really watch a lot of tv unless there is humor involved. i am kind of stuck on 90's alternative music. i am pretty much a fan of everything though... i do need to draw a line at most types of electronica.&quot;,    
    &quot;okay this is where the cultural matrix gets so specific, it's like being in the crosshairs.  for what it's worth, i find myself reading more non-fiction than fiction. it's usually some kind of philosophy, art, or science text by silly authors such as ranciere, de certeau, bataille, baudrillard, butler, stein, arendt, nietzche, zizek, etc. i'll often throw in some weird new age or pop-psychology book in the mix as well. as for fiction, i enjoy what little i've read of eco, perec, wallace, bolao, dick, vonnegut, atwood, delilo, etc. when i was young, i was a rabid asimov reader.  directors i find myself drawn to are makavejev, kuchar, jodorowsky, herzog, hara, klein, waters, verhoeven, ackerman, hitchcock, lang, gorin, goddard, miike, ohbayashi, tarkovsky, sokurov, warhol, etc. but i also like a good amount of \&quot;trashy\&quot; stuff. too much to name.  i definitely enjoy the character development that happens in long form episodic television over the course of 10-100 episodes, which a 1-2hr movie usually can't compete with. some of my recent tv favorites are: breaking bad, the wire, dexter, true blood, the prisoner, lost, fringe.  a smattered sampling of 
the vast field of music i like and deejay: art ensemble, sun ra, evan parker, lil wayne, dj funk, mr. fingers, maurizio, rob hood, dan bell, james blake, nonesuch recordings, omar souleyman, ethiopiques, fela kuti, john cage, meredith monk, robert ashley, terry riley, yoko ono, merzbow, tom tom club, jit, juke, bounce, hyphy, snap, crunk, b'more, kuduro, pop, noise, jazz, techno, house, 
acid, new/no wave, (post)punk, etc.  a few of the famous art/dance/theater folk that might locate my sensibility: andy warhol, bruce nauman, yayoi kusama, louise bourgeois, tino sehgal, george kuchar, michel duchamp, marina abramovic, gelatin, carolee schneeman, gustav metzger, mike kelly, mike smith, andrea fraser, gordon matta-clark, jerzy grotowski, samuel beckett, antonin artaud, tadeusz kantor, anna halperin, merce cunningham, etc. i'm clearly leaving out a younger generation of contemporary artists, many of whom are friends.  local food regulars: sushi zone, chow, ppq, pagolac, lers ros, burma superstar, minako, shalimar, delfina pizza, rosamunde, arinells, suppenkuche, cha-ya, blue plate, golden era, etc.&quot;,
    &quot;bataille, celine, beckett. . . lynch, jarmusch, r.w. fassbender. . . twin peaks &amp; fishing w/ john joy division, throbbing gristle, cabaret voltaire. . . vegetarian pho and coffee&quot;,
    &quot;music: bands, rappers, musicians at the moment: thee oh sees. forever: wu-tang books: artbooks for days audiobooks: my collection, thick (thanks audible) shows: live ones food: with stellar friends whenever movies &gt; tv podcast: radiolab, this american life, the moth, joe rogan, the champs&quot;,
    &quot;books: to kill a mockingbird, lord of the rings, 1984, the farseer trilogy.  music: the beatles, frank sinatra, john mayer, jason mraz, deadmau5, andrew bayer, everything on anjunadeep records, bach, satie.  tv shows: how i met your mother, scrubs, the west wing, breaking bad.  movies: star wars, the godfather pt ii, 500 days of summer, napoleon dynamite, american beauty, lotr  food: thai, vietnamese, shanghai dumplings, pizza!&quot;
    ), essay5 = c(&quot;food. water. cell phone. shelter.&quot;, &quot;delicious porkness in all of its glories. my big ass doughboy's sinking into 15 new inches. my overly resilient liver. a good sharp knife. my ps3... it plays blurays too. ;) my over the top energy and my 
outlook on life... just give me a bag of lemons and see what happens. ;)&quot;,
    &quot;movement conversation creation contemplation touch humor&quot;,
    &quot;&quot;, &quot;&quot;, &quot;like everyone else, i love my friends and family, and need hugs, human contact, water and sunshine. let's take that as given.  1. something to build 2. something to sing 3. something to play on (my guitar would be first choice) 4. something to write/draw on 5. a big goal worth dreaming about 6. something to laugh at&quot;
    ), essay6 = c(&quot;duality and humorous things&quot;, &quot;&quot;, &quot;&quot;, &quot;cats and german philosophy&quot;,
    &quot;&quot;, &quot;what my contribution to the world is going to be and/or should be. and what's for breakfast. i love breakfast.&quot;
    ), essay7 = c(&quot;trying to find someone to hang out with. i am down for anything except a club.&quot;, 
    &quot;&quot;, &quot;viewing. listening. dancing. talking. drinking. performing.&quot;,
    &quot;&quot;, &quot;&quot;, &quot;out with my friends!&quot;), essay8 = c(&quot;i am new to california and looking for someone to wisper my secrets to.&quot;,        
    &quot;i am very open and will share just about anything.&quot;, &quot;when i was five years old, i was known as \&quot;the boogerman\&quot;.&quot;,
    &quot;&quot;, &quot;&quot;, &quot;i cried on my first day at school because a bird shat on my head. true story.&quot;
    ), essay9 = c(&quot;you want to be swept off your feet! you are tired of the norm. you want to catch a coffee or a bite. or if you 
want to talk philosophy.&quot;,
    &quot;&quot;, &quot;you are bright, open, intense, silly, ironic, critical, caring, generous, looking for an exploration, rather than finding \&quot;a match\&quot; of some predetermined qualities.  i'm currently in a fabulous and open relationship, so you should be comfortable with that.&quot;,
    &quot;you feel so inclined.&quot;, &quot;&quot;, &quot;you're awesome.&quot;)), row.names = c(NA,
6L), class = &quot;data.frame&quot;)
</code></pre>
",42,1,0,2,r;tidyverse,2022-04-08 05:15:47,2022-04-08 05:15:47,2022-04-08 07:54:15,i have some columns titles essay    i want to iterate over them count the words and then make a new column with the number of words  so essay will get a column essay_num with  if that is how many words it has in it  i tried a for loop  but i am not sure how iterate the columns in a for loop in r  i thought maybe i can pull out the columns i need and put them into a new df and use sapply somehow that way  but i still run into the problem of iterating over the columns  dput ,iterate over columns to count words in a sentence and put it in a new column
355,5533102,33564788,URLDownloadToCacheFile Problems,"<p>--My first question here, please give me a hint If I do something wrong!</p>
<p>I'm using the <a href=""https://docs.microsoft.com/en-us/previous-versions/windows/internet-explorer/ie-developer/platform-apis/ms775122(v=vs.85)"" rel=""nofollow noreferrer""><strong>URLDownloadToCacheFile</strong></a> function in different places of a software project I work for.</p>
<ol>
<li>In the main UI is use this function to update a INI file from the Internet. Here I download the ini file directly with a URL. Works well.</li>
<li>In a DLL I use the same function to download a little binary file. This file has exact 308 bytes. It is an encrypted textfile with the ending &quot;.db&quot;.</li>
</ol>
<p>It's this second call that fails.</p>
<p>But this function do not fail on all computers, it just fail on a handfull of computers.</p>
<ul>
<li>On my development computer it does not fail.</li>
<li>On some customer computers it does fail.</li>
</ul>
<p>But just the one in the DLL. The call in the main GUI does not fail. Any idea? Or more information needed?</p>
<pre><code>HRESULT hr = URLDownloadToCacheFile(
    NULL,                            //ActiveX component calling this function
    dbUrl,                           //Url to download
    strFileName.GetBuffer(MAX_PATH), //pointer to a string containing the name of the downloade file
    URLOSTRM_GETNEWESTVERSION,       //size of filename buffer above
    0,                               //reserved; must be zero
    NULL);                           //optional IBindStatusCallback
        
if(SUCCEEDED(hr))
{
}
</code></pre>
",615,1,1,3,c++;windows;winapi,2015-11-06 12:33:39,2015-11-06 12:33:39,2022-04-07 18:39:05,  my first question here  please give me a hint if i do something wrong  i m using the  function in different places of a software project i work for  it s this second call that fails  but this function do not fail on all computers  it just fail on a handfull of computers  but just the one in the dll  the call in the main gui does not fail  any idea  or more information needed ,urldownloadtocachefile problems
356,892029,11701732,How to automate PDF form-filling in Java,"<p>I am doing some ""pro bono"" development for a food pantry near where I live. They are inundated with forms and paperwork, and I would like to develop a system that simply reads data from their MySQL server (which I set up for them on a previous project) and feeds data into PDF versions of all the forms they are required to fill out. This will help them out enormously and save them a lot of time, as well as get rid of a lot of human errors that are made when filling out these forms.</p>

<p>Not knowing <em>anything</em> about the internals of PDF files, I can foresee two avenues here:</p>

<ul>
<li><strong>Harder Way</strong>: It is possible to scan a paper document, turn it into a PDF, and then have software that ""fills out"" the PDF simply by saying ""add text except <em>blah</em> to the following (x,y) coordinates...""; or</li>
<li><strong>Easier Way</strong>: PDF specification already allows for the construct of ""fields"" that can be filled out; this way I just write code that says ""add text excerpt <em>blah</em> to the field called *address_value*..."", etc.</li>
</ul>

<p>So my first question is: which of the two avenues am I facing? Does PDF have a concept of ""fields"" or do I need to ""fill out"" these documents by telling the PDF library the pixel coordinates of where to place data?</p>

<p>Second, I obviously need an open source (and Java) library to do this. iText seems to be a good start but I've heard it can be difficult to work with. Can anyone lend some ideas or general recommendations here? Thanks in advance!</p>
",60274,3,27,4,java;forms;pdf;itext,2012-07-28 17:11:17,2012-07-28 17:11:17,2022-04-07 00:03:34,i am doing some pro bono development for a food pantry near where i live  they are inundated with forms and paperwork  and i would like to develop a system that simply reads data from their mysql server  which i set up for them on a previous project  and feeds data into pdf versions of all the forms they are required to fill out  this will help them out enormously and save them a lot of time  as well as get rid of a lot of human errors that are made when filling out these forms  not knowing anything about the internals of pdf files  i can foresee two avenues here  so my first question is  which of the two avenues am i facing  does pdf have a concept of fields or do i need to fill out these documents by telling the pdf library the pixel coordinates of where to place data  second  i obviously need an open source  and java  library to do this  itext seems to be a good start but i ve heard it can be difficult to work with  can anyone lend some ideas or general recommendations here  thanks in advance ,how to automate pdf form filling in java
357,18727228,71770388,MYSQL Schema Synchronization from One to Many DBs,"<p>How do companies typically handle needing to synchronize the DB schemas from one development database to many production databases? There are plenty of tools for one to one syncing, such as DBForge, but this manual process is not scalable as the number of customers and production databases grow.</p>
<p>Is there software or pipelines created for this sort of deployment?</p>
",21,0,0,4,mysql;database;synchronization;schema,2022-04-06 19:25:51,2022-04-06 19:25:51,2022-04-06 19:25:51,how do companies typically handle needing to synchronize the db schemas from one development database to many production databases  there are plenty of tools for one to one syncing  such as dbforge  but this manual process is not scalable as the number of customers and production databases grow  is there software or pipelines created for this sort of deployment ,mysql schema synchronization from one to many dbs
358,2056201,50590700,How do I install Windows 10 SDK for use with Visual Studio 2017,"<p>I can't figure out how to install Windows 10 SDK for Visual Studio 2017.</p>

<p>I downloaded and ran the Windows 10 SDK installer, and it displays <code>Please find winsdksetup.exe in ....\Windows kits\10\WindowsSDK to install Windows Software Development Kit - Windows 10.0.17134.12.</code></p>

<p>When I run <code>winsdksetup.exe</code>, it takes me through the same loop, where it downloads a bunch of executable installers into this directory and show the same exact message.</p>

<p>When I try to build a DirectX project in VS2017, I get the error:</p>

<pre><code>MSB8036 The Windows SDK version 10.0.16299.0 was not found. Install the required version of Windows SDK or change the SDK version in the project property pages or by right-clicking the solution and selecting ""Retarget solution"".    
</code></pre>

<p>Do I need to install one of those installers? Which one do I need to run to build and debug DirectX projects for Visual Studio? Specifically to use VS2017 shader debugging functionality.</p>

<p>Thanks,</p>

<p>EDIT: 
Under VS2017 - Tools -> Get Tools and Features
I have checked</p>

<p>Game Development with C++</p>

<p>and under Optional I have </p>

<p>C++ Profiling tools
Windows 10 SDK (10.0.17134.0)</p>

<p>I'm downloading 16299.0, this fixed the first error of not having the right SDK.</p>

<p>But now I get the runtime error <code>Failed Creating the Direct3D device</code> when running in Debug. I can still run samples in Release</p>
",103765,2,55,4,c++;visual-studio-2017;windows-10;directx,2018-05-29 21:26:09,2018-05-29 21:26:09,2022-04-06 16:06:51,i can t figure out how to install windows  sdk for visual studio   i downloaded and ran the windows  sdk installer  and it displays please find winsdksetup exe in      windows kits  windowssdk to install windows software development kit   windows      when i run winsdksetup exe  it takes me through the same loop  where it downloads a bunch of executable installers into this directory and show the same exact message  when i try to build a directx project in vs  i get the error  do i need to install one of those installers  which one do i need to run to build and debug directx projects for visual studio  specifically to use vs shader debugging functionality  thanks  game development with c   and under optional i have  i m downloading    this fixed the first error of not having the right sdk  but now i get the runtime error failed creating the directd device when running in debug  i can still run samples in release,how do i install windows  sdk for use with visual studio 
359,10204328,71761633,How to get error message in JSON SCHEMA VALIDATION using EVERIT in java?,"<p>I am trying to validate a json schema against the json input.
I am using</p>
<blockquote>
<p>org.everit.json.schema-1.0.0.jar</p>
</blockquote>
<p>My json input</p>
<blockquote>
<p>{
&quot;id&quot;: 200,
&quot;name&quot;: &quot;Green Learner&quot;,
&quot;cost&quot;: 0
}</p>
</blockquote>
<p>My JSON SCHEMA .</p>
<pre><code>    {
    &quot;$schema&quot;: &quot;http://json-schema.org/draft-07/schema#&quot;,
    &quot;title&quot;: &quot;Youtube Channel&quot;,
    &quot;description&quot;: &quot;Youtube Channel for software development training&quot;,
    &quot;type&quot;: &quot;object&quot;,
     
    &quot;properties&quot;: {
     
       &quot;id&quot;: {
          &quot;description&quot;: &quot;The unique identifier for a product&quot;,
          &quot;type&quot;: &quot;integer&quot;
       },
         
       &quot;name&quot;: {
          &quot;description&quot;: &quot;Name of the the channle&quot;,
          &quot;type&quot;: &quot;string&quot;
       },
         
       &quot;cost&quot;: {
          &quot;type&quot;: &quot;number&quot;,
          &quot;minimum&quot;: 100,
          &quot;maximum&quot;:10000
       }
    },
     
    &quot;required&quot;: [&quot;id&quot;, &quot;name&quot;, &quot;cost&quot;]
 }
</code></pre>
<p>JAVA Code for validation.</p>
<pre><code>import org.everit.json.schema.loader.SchemaLoader;
import org.json.JSONObject;
import org.json.JSONTokener;
import org.everit.json.schema.Schema;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;

/**
 *
 * @author amitkumar
 */
public class JsonValidate {
    public static void main(String[] args) throws FileNotFoundException {
        File schemaFile = new File(&quot;schema.json&quot;);

        JSONTokener schemaData = new JSONTokener(new FileInputStream(schemaFile));
        JSONObject jsonSchema = new JSONObject(schemaData);

        //json data
        File jsonData = new File(&quot;product_invalid.json&quot;);
        JSONTokener jsonDataFile = new JSONTokener(new FileInputStream(jsonData));
        JSONObject jsonObject = new JSONObject(jsonDataFile);

       
        Schema schemaValidator = SchemaLoader.load(jsonSchema);
        schemaValidator.validate(jsonObject);

        System.out.println(jsonObject.getInt(&quot;cost&quot;));

    }
}
</code></pre>
<p>When i run the code with org.everit.json.schema-1.0.0.jar, i get following error message .</p>
<blockquote>
<p>Exception in thread &quot;main&quot;
org.everit.json.schema.ValidationException:v0.0 is not higher or equal
to 100</p>
</blockquote>
<p>This is the warning message i get when i use</p>
<blockquote>
<p>json-schema-validator-1.0.42.jar comes with com.networknt it clearly mention me object name which got error.</p>
</blockquote>
<pre><code>$.Cost: 0.0 is not higher or equal to 100
</code></pre>
<p>i want to do the same with org.everit.json.schema-1.0.0.jar, which object in my json input got the error .It does not show me the object name .</p>
",494,1,0,5,java;json;jsonschema;json-schema-validator;everit,2022-04-06 08:52:11,2022-04-06 08:52:11,2022-04-06 09:32:01,org everit json schema    jar my json input my json schema   java code for validation  when i run the code with org everit json schema    jar  i get following error message   this is the warning message i get when i use json schema validator    jar comes with com networknt it clearly mention me object name which got error  i want to do the same with org everit json schema    jar  which object in my json input got the error  it does not show me the object name  ,how to get error message in json schema validation using everit in java 
