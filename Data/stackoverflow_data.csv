,Unnamed: 0,AuthorId,Q_id,Title,Abstract,Views,Answers,Cites,Tags_n,Tags,Date,CR_Date,LA_Date,Abstract_clean,Title_clean
0,0,19545402,72973703,How to set null class while teaching a machine?,"<p>I am really new to machine learning and image processing. I am building a machine working with hand gestures. I created 3 classes in teachable machine, made a successfully teaching and its working now. The problem is I don't know how to create a &quot;null&quot; class. The null class will be the fourth class and work only if the hand gesture is not like first 3 classes. Basically I want an other class that including the every possibility outside of first 3 classes.
How can I create this &quot;null&quot; class?</p>
",35,0,-3,3,python;tensorflow;teachable-machine,2022-07-14 05:04:05,2022-07-14 05:04:05,2022-07-14 11:37:10,,how to set null class while teaching a machine 
1,1,8389618,60319321,Enhancing the resolution of an image,"<p>I have images that are having very low quality and these images I have to use for person identification but with this quality it's difficult to detect. I want to enhance the quality of the images using deep learning/machine learning techniques. I have studied about SRCNN, perceptual Loss, SRResNet, SRGAN but most of the super image resolution techniques require original images for improving the quality of the images. So my question is there any deep learning techniques that can be used for the improving the quality of the images without using the original images.</p>

<p><a href=""https://i.stack.imgur.com/Lwv4T.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Lwv4T.jpg"" alt=""image with low quality""></a></p>
",144,2,2,5,image;machine-learning;image-processing;deep-learning;computer-vision,2020-02-20 17:22:30,2020-02-20 17:22:30,2022-07-14 11:16:37,i have images that are having very low quality and these images i have to use for person identification but with this quality it s difficult to detect  i want to enhance the quality of the images using deep learning machine learning techniques  i have studied about srcnn  perceptual loss  srresnet  srgan but most of the super image resolution techniques require original images for improving the quality of the images  so my question is there any deep learning techniques that can be used for the improving the quality of the images without using the original images  ,enhancing the resolution of an image
2,2,19543504,72969730,Getting error while checking hosts IP via Ansible Server machine,"<p>I'm getting an error prompt while checking the node's IP in hosts/inventory from my server machines, all nodes are connected.</p>
<p>Error Prompt:</p>
<pre><code>[WARNING]: Unable to parse /etc/ansible/hosts #poll_interval  = 15 as an inventory source
[WARNING]: No inventory was parsed, only implicit localhost is available
[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all'
[WARNING]: Could not match supplied host pattern, ignoring: demo 
</code></pre>
<p>SSH connections are already established with my nodes and can access from the server machine as well</p>
<p>Also, in the <em>hosts</em> file inside the ansible server a group is created with the node's private IPs:</p>
<pre class=""lang-ini prettyprint-override""><code># Ex 1: Ungrouped hosts, specify before any group headers.

[demo]
172.31.31.15
172.31.31.128
</code></pre>
<p>Also, inside the ansible server config file:</p>
<pre><code>inventory = /etc/ansible/hosts
sudo_user = root
</code></pre>
<p>Both these are uncommented as well. I'm learning ansible and new with this configuration tool.</p>
<p>Please help as I'm unable to fetch details of nodes with the above-said command not by group which I created as <code>demo</code>.</p>
",21,0,0,1,ansible,2022-07-13 22:06:53,2022-07-13 22:06:53,2022-07-14 10:48:05,i m getting an error prompt while checking the node s ip in hosts inventory from my server machines  all nodes are connected  error prompt  ssh connections are already established with my nodes and can access from the server machine as well also  in the hosts file inside the ansible server a group is created with the node s private ips  also  inside the ansible server config file  both these are uncommented as well  i m learning ansible and new with this configuration tool  please help as i m unable to fetch details of nodes with the above said command not by group which i created as demo ,getting error while checking hosts ip via ansible server machine
3,3,4903479,72873249,Deployment of Machine Learning models in Azure machine learning through mlflow,"<p>I am new to MLOps. It would be helpful if someone can share the procedure to use mlflow in deployment of Machine Learning models in azure machine learning.
I don't want to use databricks.
A sample run step by step with example will be helpful.. thanks in anticipation</p>
",28,0,0,3,azure;machine-learning;mlflow,2022-07-05 22:43:47,2022-07-05 22:43:47,2022-07-14 09:08:05,,deployment of machine learning models in azure machine learning through mlflow
4,4,0,72107817,I Cannot Install SQL Server 2019 Express. It gets stuck on Offline Installation of Microsoft Machine Learning Server Components,"<p>I'm trying to install SQL Server 2019 Express on my laptop. I initially click on custom to start and everything seems to go smooth up to the point where it's at the Offline Installation of Microsoft Machine Learning Server Components section.</p>
<p>When I get there I get a screenshot that looks like this:<br>
<p><img src=""https://bobgatto.com/images/sql_install.jpg""></p>
<p>From this point on I cannot figure out what to do next. I tried creating a directory, downloading all of the files listed to that directory, and enter that directory in the Install Path line. But when I do that the Next button still is disabled.</p>
<p>So what is the next step?</p>
<p>Thanks for any help</p> 
",3350,4,2,1,sql-server,2022-05-04 09:37:37,2022-05-04 09:37:37,2022-07-14 08:23:19,i m trying to install sql server  express on my laptop  i initially click on custom to start and everything seems to go smooth up to the point where it s at the offline installation of microsoft machine learning server components section   from this point on i cannot figure out what to do next  i tried creating a directory  downloading all of the files listed to that directory  and enter that directory in the install path line  but when i do that the next button still is disabled  so what is the next step  thanks for any help,i cannot install sql server  express  it gets stuck on offline installation of microsoft machine learning server components
5,5,6237651,55079999,Adding an image to a toolbar in a Vue + Vuetify Single File Compnonent,"<p>I'm essentially just remixing the code available here for a side project: <a href=""https://github.com/aws-samples/aws-ai-qna-bot.git"" rel=""nofollow noreferrer"">https://github.com/aws-samples/aws-ai-qna-bot.git</a></p>
<p><strong>Problem</strong>: I'm trying to insert a centered logo in the toolbar between the app drawer and the logout button.  Typically I could accomplish this pretty easily with vanilla HTML and CSS, but this project is leveraging Vue.js and Vuetify, which I'm doing my best to get myself up to speed with.</p>
<p>I've referenced the following documents, including the <code>README.md</code> in the git repo:</p>
<p><a href=""https://vuetifyjs.com/en/components/images"" rel=""nofollow noreferrer"">https://vuetifyjs.com/en/components/images</a></p>
<p><a href=""https://v2.vuejs.org/v2/guide/single-file-components.html"" rel=""nofollow noreferrer"">https://v2.vuejs.org/v2/guide/single-file-components.html</a></p>
<p><strong>File path</strong>: <code>qna-bot-template/website/js/admin.vue</code></p>
<pre><code>&lt;template lang=&quot;pug&quot;&gt;
  v-app
    v-navigation-drawer(temporary v-model=&quot;drawer&quot; app)
      v-toolbar(flat)
        v-list
          v-list-tile
            v-list-tile-title.title Tools
      v-divider
      v-list(dense three-line subheader)
        v-list-tile(v-for=&quot;(page,key) in pages&quot; :key=&quot;key&quot;
          @click=&quot;drawer=false&quot; 
          :href=&quot;page.href&quot;
          :id=&quot;'page-link-'+page.id&quot;
          :target=&quot;page.target || '_self'&quot;) 
          v-list-tile-avatar
            v-icon(color=&quot;primary&quot;) {{page.icon}}
          v-list-tile-content
            v-list-tile-title {{page.title}}
            v-list-tile-sub-title {{page.subTitle}}
        v-list-group( prepend-icon=&quot;info&quot; value=&quot;true&quot; color=&quot;primary&quot;)
          v-list-tile(slot=&quot;activator&quot;) 
            v-list-tile-title QnABot Help
          v-list-tile
            v-list-tile-content 
              v-list-tile-title Version: {{Version}}
              v-list-tile-title BuildDate: {{BuildDate}}
          v-list-tile
            v-list-tile-content
              v-list-tile-title 
                a(href=&quot;https://amazon.com/qnabot&quot; target=&quot;_blank&quot;) General Instructions / QnABot Blog Post
              v-list-tile-title
                a(href=&quot;https://aws.amazon.com/blogs/machine-learning/creating-virtual-guided-navigation-using-a-question-and-answer-bot-with-amazon-lex-and-amazon-alexa/&quot; target=&quot;_blank&quot;) Guided Navigation using QnABot
              v-list-tile-title
                a(href=&quot;https://aws.amazon.com/blogs/machine-learning/create-a-questionnaire-bot-with-amazon-lex-and-amazon-alexa/&quot; target=&quot;_blank&quot;) Create a questionnaire using QnABot
    v-toolbar(app fixed)
      v-toolbar-side-icon.primary--text(
        id=&quot;nav-open&quot;
        @click.stop=&quot;drawer = !drawer&quot;
      )
      v-toolbar-title 
        v-breadcrumbs
          v-breadcrumbs-item(href='#/edit') {{$store.state.info.StackName}}:{{$store.state.user.name}}
          v-breadcrumbs-item {{page}}
      v-spacer
      v-toolbar-items
        v-btn.primary--text(flat
          id=&quot;logout-button&quot;
          @click=&quot;logout&quot;
          v-if=&quot;login&quot;) LogOut
    v-container(fluid id=&quot;workspace&quot;)
      v-layout(column)
        v-flex
          router-view
    v-footer
&lt;/template&gt;
</code></pre>
<p>So far I've tried following the following syntax, which I added right after the <code>v-spacer</code> toward the bottom of the wrapping template tags.</p>
<pre><code>v-container
  v-img(:src=&quot;/abc/xyz&quot;)
</code></pre>
<p>and this doesn't seem to be working.</p>
<p>Lastly I'll add that since this environment is deployed to an EC2 instance (don't think you can deploy it locally to prototype via <code>vue serve</code> or at least I haven't been able to), I'm having to do this very roundabout way of prototyping by deploying this S3 bucket where the webpages are built to, then I <code>make</code> this webpack listener which will see whenever I modify a file.  Then I can refresh the index.html that is built in the S3 bucket to see my changes.  Extremely clunky workflow, I know, but I've never worked in an environment like this so I'm not sure if there's a better way, plus the readme provided in the github repo is very light on details for how to modify the default layout.</p>
<p>Any help/pointers would be greatly appreciated.</p>
",5757,1,0,3,amazon-web-services;vue.js;vuetify.js,2019-03-09 22:52:23,2019-03-09 22:52:23,2022-07-14 07:14:12,i m essentially just remixing the code available here for a side project   problem  i m trying to insert a centered logo in the toolbar between the app drawer and the logout button   typically i could accomplish this pretty easily with vanilla html and css  but this project is leveraging vue js and vuetify  which i m doing my best to get myself up to speed with  i ve referenced the following documents  including the readme md in the git repo    file path  qna bot template website js admin vue so far i ve tried following the following syntax  which i added right after the v spacer toward the bottom of the wrapping template tags  and this doesn t seem to be working  lastly i ll add that since this environment is deployed to an ec instance  don t think you can deploy it locally to prototype via vue serve or at least i haven t been able to   i m having to do this very roundabout way of prototyping by deploying this s bucket where the webpages are built to  then i make this webpack listener which will see whenever i modify a file   then i can refresh the index html that is built in the s bucket to see my changes   extremely clunky workflow  i know  but i ve never worked in an environment like this so i m not sure if there s a better way  plus the readme provided in the github repo is very light on details for how to modify the default layout  any help pointers would be greatly appreciated ,adding an image to a toolbar in a vue   vuetify single file compnonent
6,6,19520507,72973487,Which Random Forest for stock market analysis?,"<p>Wanting to use machine learning for stock market analysis as a summer project (new to compter sci). Want to use random forest but am unsure if i need randomfroestclassifier or randomforestregression and am also unsure about the difference between the two. I want to also find out advantaged of this over LSTM models. THANKS</p>
",11,0,2,1,lstm,2022-07-14 04:24:13,2022-07-14 04:24:13,2022-07-14 04:24:13,wanting to use machine learning for stock market analysis as a summer project  new to compter sci   want to use random forest but am unsure if i need randomfroestclassifier or randomforestregression and am also unsure about the difference between the two  i want to also find out advantaged of this over lstm models  thanks,which random forest for stock market analysis 
7,7,14748027,72971178,How to specify columns in data for Machine Learning?,"<p>I am learning some Machine Learning stuff? and need some help on data preparation.
The data gives details about properties in an area.</p>
<p><a href=""https://i.stack.imgur.com/M4Csr.png"" rel=""nofollow noreferrer"">Property Data</a><br />
<a href=""https://i.stack.imgur.com/WVfWM.png"" rel=""nofollow noreferrer"">Data info</a></p>
<p>So, during loading time I discovered that one column named &quot;BHK&quot; (which specifies for no. of bedrooms, hall, kitchen in the property) is categorical but values are numeric separated by ','.</p>
<p><a href=""https://i.stack.imgur.com/wthVp.png"" rel=""nofollow noreferrer"">BHK column categories</a><br />
For example: for the 1st row, the BHK column specifies (5,1,2) meaning 5 bedrooms, 1 hall, 2 kitchens</p>
<p>So, how should I format it so, that it becomes easy for further modelling and prediction stages?
should I use separated values from BHK column?</p>
",11,0,0,4,pandas;csv;machine-learning;data-modeling,2022-07-14 00:14:32,2022-07-14 00:14:32,2022-07-14 00:14:32,so  during loading time i discovered that one column named  bhk   which specifies for no  of bedrooms  hall  kitchen in the property  is categorical but values are numeric separated by     ,how to specify columns in data for machine learning 
8,8,308827,72970228,Ensemble of machine learning models in scikit-learn,"<pre><code>group        feature_1        feature_2       year            dependent_variable
group_a         12               19           2010               0.4
group_a         11               13           2011               0.9
group_a         10               5            2012               1.2
group_a         16               9            2013               3.2
group_b         8               29            2010               0.6
group_b         9               33            2011               0.1 
group_b         111             15            2012               2.1 
group_b         16              19            2013               12.2  
</code></pre>
<p>In the dataframe above, I want to use <code>feature_1</code>, <code>feature_2</code> to predict <code>dependent_variable</code>. To do this, I want to construct two models: In the first model, I want to construct a separate model for each group. In the second model, I want to use all the available data. In both cases, data from the years 2010 to 2012 will be used for training and 2013 will be used for testing.</p>
<p>How can I construct an ensemble model using the two models outlined above? The data is a toy dataset but in the real dataset, there will be a lot more groups, years and features. In particular, I am interested in an approach that will work with scikit-learn compatible models.</p>
",11,0,0,3,python;scikit-learn;ensemble-learning,2022-07-13 22:47:38,2022-07-13 22:47:38,2022-07-13 22:47:38,in the dataframe above  i want to use feature_  feature_ to predict dependent_variable  to do this  i want to construct two models  in the first model  i want to construct a separate model for each group  in the second model  i want to use all the available data  in both cases  data from the years  to  will be used for training and  will be used for testing  how can i construct an ensemble model using the two models outlined above  the data is a toy dataset but in the real dataset  there will be a lot more groups  years and features  in particular  i am interested in an approach that will work with scikit learn compatible models ,ensemble of machine learning models in scikit learn
9,9,19295532,72969484,Non-Linear Machine Learning Algorithms,"<p>I am working on a dataset using python I have 17 variables that need to be used to predict one thing (Thing being a %) is there any non-linear machine learning algorithms anyone knows that could achieve this. I have. already implemented a multiple linear regression to it but the data is not very linear so I would want a better fit. All the other algorithms I've tried such as polynomial regression need the same values X=Y but in this case that is not possible as I have 17 variables all needed to predict one thing.</p>
",23,1,-1,3,python;regression;non-linear,2022-07-13 21:46:37,2022-07-13 21:46:37,2022-07-13 22:05:30,i am working on a dataset using python i have  variables that need to be used to predict one thing  thing being a    is there any non linear machine learning algorithms anyone knows that could achieve this  i have  already implemented a multiple linear regression to it but the data is not very linear so i would want a better fit  all the other algorithms i ve tried such as polynomial regression need the same values x y but in this case that is not possible as i have  variables all needed to predict one thing ,non linear machine learning algorithms
10,10,8993562,47445310,Python : (Titanic) debugging error in imputing fare,"<p>I will thank very much for your help.I have a problem with the classic Kaggle Titanic Tutorial for machine learning. My problem is when using a pivotal table to imput means in a dataframe (or tupple):</p>

<pre><code>fare_means = df.pivot_table(""Fare"", index= ""Pclass"", aggfunc=""mean"")

​fare_means.info()    
fare_class 'pandas.core.frame.DataFrame'&gt;    
Int64   
Index: 3 entries, 1 to 3    
Data columns (total 1 columns):  Fare    3 non-null float64  
dtypes: float64(1)   
memory usage: 48.0 bytes

fare_means   
Out[46]:   
Fare ---Pclass     
1     ------- 84.154687  
2      -------20.662183   
3      -------13.675550

df_test['Fare'] = df_test[['Fare', 'Pclass']].apply(lambda x:

fare_means[x['Pclass']] if pd.isnull(x['Fare'])

else x['Fare'], axis=1)
</code></pre>

<h1>KeyError: (3, u'occurred at index 152')</h1>

<pre><code>df_test.iloc[150:155, 0: ]   
  Index-- Pclass    ----    Fare       
  150 ------ 1      --------83.1583   
  151 ------ 3      --------7.8958    
  152 ------ 3      --------NaN    
  153 ------ 3      --------12.1833  
  154 ------ 3      --------31.3875 
</code></pre>
",146,1,0,3,python;python-2.7;debugging,2017-11-23 04:48:24,2017-11-23 04:48:24,2022-07-13 21:10:50,i will thank very much for your help i have a problem with the classic kaggle titanic tutorial for machine learning  my problem is when using a pivotal table to imput means in a dataframe  or tupple  ,python    titanic  debugging error in imputing fare
11,11,9554792,72968500,How to monitor all API calls made in windows?,"<p>I'm trying to monitor and log all windows API calls made (by every application) and then run it through a machine learning model to find any malicious applications. Some tools monitor API calls; however, they only work for a single process. Is there a way I can get every API call done by all currently running processes?
Thank you</p>
",13,0,0,3,windows;machine-learning;logging,2022-07-13 20:34:35,2022-07-13 20:34:35,2022-07-13 20:34:35,,how to monitor all api calls made in windows 
12,12,16469159,72963263,Python read from csv with condition for TimeSeriesGenerator,"<p>I have a .csv file with many entries that looks like this:</p>
<pre><code>observation1, observation2, tag
observation1, observation2, tag
...
b r e a k
observation1, observation2, tag
...
b r e a k
</code></pre>
<p>whereas the observations are some numbers and the tag the ground truth true/false.</p>
<p>the <code>break</code> part comes with the data and symbolizes the end of a file and the end of an observation chain. Datapoints within two <code>break</code> entries belong together. (All those datapoints are merged from multiple files into one huge csv).</p>
<p>With this data I am supposed to do some machine learning using the tensorflow TimeSeriesGenerator.</p>
<p>I found out however, that TSG uses a fixed time series chain length, which means I have to do some cutting/filtering of my data given.</p>
<p>Condition one, is that if a <code>true</code> appears in the chain, it has to be the last value. Condition two, that all chains consist of the same amount of entries.</p>
<p>This means, if say my chain length would be 3, then the following chains are allowed:</p>
<pre><code>b r e a k
observation1, observation2, false
observation1, observation2, false
observation1, observation2, true
b r e a k
</code></pre>
<pre><code>b r e a k
observation1, observation2, false
observation1, observation2, false
observation1, observation2, false
b r e a k
</code></pre>
<p>but not</p>
<pre><code>b r e a k
observation1, observation2, false
observation1, observation2, true
observation1, observation2, false
b r e a k
</code></pre>
<p>A chain like this would also be allowed</p>
<pre><code>observation1, observation2, false
observation1, observation2, false
observation1, observation2, false
observation1, observation2, true
</code></pre>
<p>as I could simply throw the first line away to get a length of 3.</p>
<p>But not a chain like this:</p>
<pre><code>observation1, observation2, false
b r e a k
observation1, observation2, false
observation1, observation2, true
b r e a k
</code></pre>
<p>This means I need some way (my guess would be pandas) to filter the .csv file and find all occurences, where between to <code>b r e a k</code> lines there are at least x amount of <code>false</code> datapoints followed by a <code>true</code> or another <code>false</code>.</p>
<p>What would be a good way of achieving this filtering?</p>
",20,0,1,4,python;csv;tensorflow;filter,2022-07-13 14:10:11,2022-07-13 14:10:11,2022-07-13 14:10:11,i have a  csv file with many entries that looks like this  whereas the observations are some numbers and the tag the ground truth true false  the break part comes with the data and symbolizes the end of a file and the end of an observation chain  datapoints within two break entries belong together   all those datapoints are merged from multiple files into one huge csv   with this data i am supposed to do some machine learning using the tensorflow timeseriesgenerator  i found out however  that tsg uses a fixed time series chain length  which means i have to do some cutting filtering of my data given  condition one  is that if a true appears in the chain  it has to be the last value  condition two  that all chains consist of the same amount of entries  this means  if say my chain length would be   then the following chains are allowed  but not a chain like this would also be allowed as i could simply throw the first line away to get a length of   but not a chain like this  this means i need some way  my guess would be pandas  to filter the  csv file and find all occurences  where between to b r e a k lines there are at least x amount of false datapoints followed by a true or another false  what would be a good way of achieving this filtering ,python read from csv with condition for timeseriesgenerator
13,13,18355714,72955247,GPU question about multithreading and machine learning,"<p>I have a machine learning model that uses nearly 3GB of my GPU. I would like to multithread this. In my head, this is how it should happen:</p>
<p>For each thread, I create I would need to generate a duplicate neural network to put into the GPU. As having all threads using the same model could be dangerous? and I don't want to wrap the model in a critical lock section.</p>
<p>Therefore to have 2 threads running I would need 6GB of GPU space?</p>
",22,0,-1,4,multithreading;machine-learning;computer-vision;gpu,2022-07-12 21:34:15,2022-07-12 21:34:15,2022-07-13 14:07:34,i have a machine learning model that uses nearly gb of my gpu  i would like to multithread this  in my head  this is how it should happen  for each thread  i create i would need to generate a duplicate neural network to put into the gpu  as having all threads using the same model could be dangerous  and i don t want to wrap the model in a critical lock section  therefore to have  threads running i would need gb of gpu space ,gpu question about multithreading and machine learning
14,14,19539272,72961417,I came across assertion error while doing machine learning project,"<p><a href=""https://i.stack.imgur.com/6N0Az.jpg"" rel=""nofollow noreferrer"">this is the error I got while running my code</a></p>
",15,0,-2,1,machine-learning,2022-07-13 11:11:22,2022-07-13 11:11:22,2022-07-13 11:11:22,,i came across assertion error while doing machine learning project
15,15,19539060,72961125,Best way to build an &quot;engine&quot; or &quot;solver&quot; for a card game,"<p>I am interested in building a card game(cabo) and a solver or engine to try and learn the most optimal way to play it as a project for my resume. I'd say that I am pretty fluent in C++ and am open to learning python/JS if it will make things easier(a little background if it helps: I just finished intro to CS 2 at my college and will be taking DSA in the fall). From what I have read, a machine learning/neural network model is what most chess engines and poker solvers use, which is what gave me inspiration for this project. I just wanted to get some input on what would be the best way to approach this. Thanks.</p>
",14,0,-4,3,machine-learning;neural-network;solver,2022-07-13 10:25:52,2022-07-13 10:25:52,2022-07-13 10:25:52,i am interested in building a card game cabo  and a solver or engine to try and learn the most optimal way to play it as a project for my resume  i d say that i am pretty fluent in c   and am open to learning python js if it will make things easier a little background if it helps  i just finished intro to cs  at my college and will be taking dsa in the fall   from what i have read  a machine learning neural network model is what most chess engines and poker solvers use  which is what gave me inspiration for this project  i just wanted to get some input on what would be the best way to approach this  thanks ,best way to build an  engine  or  solver  for a card game
16,16,19538261,72960178,how to insert or update a new data into existing table using mysql in python flask (data from machine learning),"<p><strong>My problem when i using query insert or update the result of value from naive bayes algorithm into my existing table and column</strong></p>
<p>example of problem 1 that occurs when I use the query insert into my table data_uji3 at column prob which is the column that is used as the result value from the naive bayes algorithm, the data stored in the data_uji3 table in the &quot;prob&quot; column does not start from the top or the first row, but it start from the bottom row and makes as many rows as the amount of data available.
i have tried to insert it to another table for the result of algorithm and it works, but i need this value from algorithm must be place at table data_uji3 at column prob, the code for insert describe at below</p>
<pre><code>akurasi=pd.read_sql_query('SELECT*FROM data_uji3',cur )
        x1 = akurasi.iloc[:,[4,5,6,7,8]].values
        y_pred1=NBmodel.predict(x1)
        print(y_pred1)
        pt= y_pred1.reshape(250,1)
        if request.method == &quot;POST&quot;:
            
            cur1 =mysql.connection.cursor()
            for i in pt:
             cur1.execute(&quot;INSERT INTO data_uji3 (prob) VALUES (%s)&quot;,i)
             print(i)       
             mysql.connection.commit()
</code></pre>
<p>and the result at my table at this image
<a href=""https://i.stack.imgur.com/pFJjn.png"" rel=""nofollow noreferrer"">https://i.stack.imgur.com/pFJjn.png</a></p>
<p>example of next problem is when i used the update query for that case, the data updated from result of algorithm just write by one, the code for update describe at below</p>
<pre><code>akurasi=pd.read_sql_query('SELECT*FROM data_uji3',cur )
        x1 = akurasi.iloc[:,[4,5,6,7,8]].values
        y_pred1=NBmodel.predict(x1)
        print(y_pred1)
        pt= y_pred1.reshape(250,1)
        if request.method == &quot;POST&quot;:
            
            cur1 =mysql.connection.cursor()
            for i in pt:
             cur1.execute(&quot;UPDATE data_uji3 SET prob=%s&quot;,i)
             print(i)       
             mysql.connection.commit()
</code></pre>
<p>and the result at my table at this image
<a href=""https://i.stack.imgur.com/tqa2I.png"" rel=""nofollow noreferrer"">https://i.stack.imgur.com/tqa2I.png</a></p>
<p>on those my case, is there any unused code in my program or is there any solution for my case, please some one to help me</p>
",20,0,-1,3,python;mysql;pandas,2022-07-13 07:43:33,2022-07-13 07:43:33,2022-07-13 08:42:59,my problem when i using query insert or update the result of value from naive bayes algorithm into my existing table and column example of next problem is when i used the update query for that case  the data updated from result of algorithm just write by one  the code for update describe at below on those my case  is there any unused code in my program or is there any solution for my case  please some one to help me,how to insert or update a new data into existing table using mysql in python flask  data from machine learning 
17,17,17752727,72960044,How are decision trees in random forest algorithms made?,"<p>I am new to machine learning! While doing an assignment I was suddenly presented with the profound question of how does a computer generate a decision tree.</p>
<p>For example, consider the problem of predicting a specific flower species using the random forest algorithm. There are two specific attributes of a flower (petal width, petal length) that distinguish the species.</p>
<p>In terms of the flower problem, when using sclearn's Python decisiontreemaker(), how does the computer figure out what petal width and petal length to create the tree? Also, does a random forest algorithm create these decision trees by brute forcing and testing every single variation of a tree by weighing entrophy? Thanks!</p>
",20,0,0,3,python;artificial-intelligence;sklearn-pandas,2022-07-13 07:15:45,2022-07-13 07:15:45,2022-07-13 07:15:45,i am new to machine learning  while doing an assignment i was suddenly presented with the profound question of how does a computer generate a decision tree  for example  consider the problem of predicting a specific flower species using the random forest algorithm  there are two specific attributes of a flower  petal width  petal length  that distinguish the species  in terms of the flower problem  when using sclearn s python decisiontreemaker    how does the computer figure out what petal width and petal length to create the tree  also  does a random forest algorithm create these decision trees by brute forcing and testing every single variation of a tree by weighing entrophy  thanks ,how are decision trees in random forest algorithms made 
18,18,13555760,72958457,custom neural network model that shares the same fixed weights across a variable number of inputs,"<p>I have a special machine learning problem and I've come up with a weird solution that I'm not entirely sure how to implement in tensorflow for python (and it has to be tensorflow for python). The problem is essentially just picking the best of 5 options, where each option is represented by a vector of length 10. The training data is organized into input vectors of length 50 (5 options * 10 option length) and labeled with one-hot vectors of length 5.</p>
<p>Here's the wacky part: it might not be 5. The model needs to be able to choose from any number of options. So, just having a dense model with 50 inputs and 5 outputs isn't going to work.</p>
<p>The best solution I can think of is to just evaluate individual options rather than a full set. Make a model with 10 inputs and 1 output, where the output is just the model's &quot;confidence&quot; in how good the input vector is. Pass all 5 (or however many) inputs through the model, put each confidence value into an array, and pass that array through a softmax function to get an output.</p>
<p>Now, I can't just train a model with 10 inputs and 1 output and do the combination and softmax stuff afterwards in numpy, because my training data isn't 10 values mapped to a confidence value. It's 30, 40, 50, or 10*n values mapped to a one-hot vector of size 3, 4, 5, or n. It needs to train in sets, so the model itself needs to be able to handle sets. I have no clue how to do this in tensorflow. As far as I can tell, Keras forces you to build models with a fixed input and output size. Even though it has a nice functional API, it won't let me do variable input/output sizes.</p>
<p>If this were libtorch for C++, I would just create a forward() function when defining my model and it would let me do whatever input and output sizes I want, but I can't find how to make the equivalent of this in tensorflow for python. Is this even possible?</p>
<p>Any tips are appreciated, thanks.</p>
",24,0,0,3,python;tensorflow;keras,2022-07-13 02:44:11,2022-07-13 02:44:11,2022-07-13 04:26:19,i have a special machine learning problem and i ve come up with a weird solution that i m not entirely sure how to implement in tensorflow for python  and it has to be tensorflow for python   the problem is essentially just picking the best of  options  where each option is represented by a vector of length   the training data is organized into input vectors of length    options    option length  and labeled with one hot vectors of length   here s the wacky part  it might not be   the model needs to be able to choose from any number of options  so  just having a dense model with  inputs and  outputs isn t going to work  the best solution i can think of is to just evaluate individual options rather than a full set  make a model with  inputs and  output  where the output is just the model s  confidence  in how good the input vector is  pass all   or however many  inputs through the model  put each confidence value into an array  and pass that array through a softmax function to get an output  now  i can t just train a model with  inputs and  output and do the combination and softmax stuff afterwards in numpy  because my training data isn t  values mapped to a confidence value  it s       or  n values mapped to a one hot vector of size       or n  it needs to train in sets  so the model itself needs to be able to handle sets  i have no clue how to do this in tensorflow  as far as i can tell  keras forces you to build models with a fixed input and output size  even though it has a nice functional api  it won t let me do variable input output sizes  if this were libtorch for c    i would just create a forward   function when defining my model and it would let me do whatever input and output sizes i want  but i can t find how to make the equivalent of this in tensorflow for python  is this even possible  any tips are appreciated  thanks ,custom neural network model that shares the same fixed weights across a variable number of inputs
19,19,19480081,72880854,How to balance a dataset using SCUT and the scutr-package in R,"<p>I was given a machine learning project in R by a colleague who can no longer work on it. I am currently trying to balance the used dataset with the SCUT function in the scutr package and I keep running into the following Problem:</p>
<p>The project I am working with contains the base dataset, formatted as a standard dataframe that contains different information on different YouTube channels (URL, name, description, etc.) and also a classification of 4 classes (hkgeschlecht). The classification is numerical, some of the other information as well, but the channel description for example is a text:</p>
<pre><code>'data.frame':   199 obs. of  6 variables:
 $ ctitle       : chr  &quot;Gaming Kati&quot; &quot;EinfallsReich&quot; &quot;Frank / Generation - E&quot; &quot;Gladiator Glubschi&quot; ...
 $ cdescr       : chr  &quot;Dieser Kanal ist einfach ein Kanal von einem Mädel, welches einfach im Animal Crossing hype ist &lt;U+0001F61D&gt;&lt;U+&quot;| __truncated__ &quot;Kurze und EinfallsReiche Fakten Videos mit folgenden Themen:\n\n                                               &quot;| __truncated__ &quot;Ich bin Frank aus Hamburg...\n\n...glücklicher Ehemann und Vater von zwei fantastischen Jungs. \n\nZu meinen gr&quot;| __truncated__ &quot;Gladiator Glubschi\n- Ein Glubschi\n- Zwei krasse Kanäle\n- Drei Unterhaltung!\n\nUnd damit erstmal danke fürs &quot;| __truncated__ ...
 $ cthumbnailurl: chr  &quot;https://yt3.ggpht.com/a/AATXAJwsWCPoVZ6g-uk_9UbMU3NqOU-QuoQyunPoYg=s240-c-k-c0xffffffff-no-rj-mo&quot; &quot;https://yt3.ggpht.com/a/AATXAJxunaT5qD2CbS7AQodCYq-HDOVee87NYBnRnw=s240-c-k-c0xffffffff-no-rj-mo&quot; &quot;https://yt3.ggpht.com/a/AATXAJzaeY6aZJuWpCsa8ul1CXHmQ1bC6reTWk9mTw=s240-c-k-c0xffffffff-no-rj-mo&quot; &quot;https://yt3.ggpht.com/a/AATXAJx0pmglui0v3YZblGuT1yOdNTm33qVP7mLXxQ=s240-c-k-c0xffffffff-no-rj-mo&quot; ...
 $ cviews       : int  1348087 2764 229744 15556 1884 1077314 158044 113570 25495 2364116 ...
 $ csubscriber  : int  13000 0 1140 320 0 7940 623 823 406 34700 ...
 $ hkgeschlecht : num  2 99 1 1 1 2 1 1 1 2 ...
</code></pre>
<p>The project uses a Naive Bayes Classifier and thus the channel description (sdescr) in the dataframe is transformed into a document feature matrix dfm which then is split into a training dataset and test dataset. This all works out fine and the model gives me decent predictions.</p>
<p>However the main dataset is unbalanced as one class is much more dominant than the others. I now want to balance this dataset using the SCUT-method so that the prediction of the minority classes improves. I had planned on using the <a href=""https://mran.microsoft.com/web/packages/scutr/scutr.pdf"" rel=""nofollow noreferrer"">scutr package</a> and the SCUT function in it since it is seems fairly straight forward.</p>
<p>Now my problem is, if I apply the function to main dataset like this:</p>
<pre><code>ret &lt;- SCUT(mldata, &quot;hkgeschlecht&quot;, oversample = oversample_smote, undersample = undersample_hclust,)
</code></pre>
<p>I get this error:</p>
<blockquote>
<p>Error in get.knnx(data, query, k, algorithm) : Data non-numeric</p>
</blockquote>
<p>I assume that is due to the differently formated variables in the dataframe.</p>
<p>But if I try to apply it only to the training dataset like this:</p>
<pre><code>ret &lt;- SCUT(testdfm1, testdfm1@docvars$docvars, oversample = oversample_smote, undersample = undersample_hclust,)
</code></pre>
<p>I get this error:</p>
<blockquote>
<p>Error in validate_dataset(data, cls_col) :
Column not found in data: 22211299112111312111122333311133211111111</p>
</blockquote>
<p>Which I assume is due to the SCUT function needing a dataframe format and not a document feature matrix.</p>
<p>My question thus is: How I can apply the SCUT method in this case? Is there a way to make the function work with a document feature matrix, say to get it to recognize the column with the classification? Would that even make sense? Or do I have to go about it in a completely different way?</p>
",22,0,0,4,r;dataframe;machine-learning;matrix,2022-07-06 14:46:41,2022-07-06 14:46:41,2022-07-13 01:36:23,i was given a machine learning project in r by a colleague who can no longer work on it  i am currently trying to balance the used dataset with the scut function in the scutr package and i keep running into the following problem  the project i am working with contains the base dataset  formatted as a standard dataframe that contains different information on different youtube channels  url  name  description  etc   and also a classification of  classes  hkgeschlecht   the classification is numerical  some of the other information as well  but the channel description for example is a text  the project uses a naive bayes classifier and thus the channel description  sdescr  in the dataframe is transformed into a document feature matrix dfm which then is split into a training dataset and test dataset  this all works out fine and the model gives me decent predictions  however the main dataset is unbalanced as one class is much more dominant than the others  i now want to balance this dataset using the scut method so that the prediction of the minority classes improves  i had planned on using the  and the scut function in it since it is seems fairly straight forward  now my problem is  if i apply the function to main dataset like this  i get this error  error in get knnx data  query  k  algorithm    data non numeric i assume that is due to the differently formated variables in the dataframe  but if i try to apply it only to the training dataset like this  i get this error  which i assume is due to the scut function needing a dataframe format and not a document feature matrix  my question thus is  how i can apply the scut method in this case  is there a way to make the function work with a document feature matrix  say to get it to recognize the column with the classification  would that even make sense  or do i have to go about it in a completely different way ,how to balance a dataset using scut and the scutr package in r
20,20,17878377,72955280,how to combine parquet files in S3 into one parquet file using spark,"<p>I have 12 parquet files, each file represent monthly New York Taxi pick up and drop information and consist of +500K rows. I want to combine all these 12 files by row into 1 parquet file and save it in S3 to do machine learning model. How I can do that using pyspark
I will upload these 12 files into AWS S3
<a href=""https://i.stack.imgur.com/zTPst.png"" rel=""nofollow noreferrer"">files names</a></p>
",22,1,0,4,apache-spark;amazon-s3;bigdata;parquet,2022-07-12 21:37:07,2022-07-12 21:37:07,2022-07-13 00:55:17,,how to combine parquet files in s into one parquet file using spark
21,21,18089331,72914328,Compare similarity of two names and identify duplicates with neural network,"<p>I have a dataset which contains pairs of names, it looks like this:</p>
<pre><code>ID; name1; name2
1; Mike Miller; Mike Miler
2; John Doe; Pete McGillen
3; Sara Johnson; Edita Johnson
4; John Lemond-Lee Peter; John LL. Peter
5; Marta Sunz; Martha Sund
6; John Peter; Johanna Petera
7; Joanna Nemzik; Joanna Niemczik
</code></pre>
<p>I have some cases, which are labelled. So I check them manually and decide if these are duplicates or not. The manual judgement in these cases would be:</p>
<pre><code>1: Is a duplicate
2: Is not a duplicate
3: Is not a duplicate
4: Is a duplicate
5: Is not a duplicate
6: Is not a duplicate
7: Is a duplicate
</code></pre>
<p>(The 7th case is a specific case, because here phonetics come into the game too. However, this is not the main problem, I am ok with ignoring phonetics.)</p>
<p>A first approach would be to calculate the Levenshtein-distance for each pair and mark those as a duplicate, where the Levenshtein-distance is for example less or equal than 2. This would lead to the following output:</p>
<pre><code>1: Levenshtein distance: 2 =&gt; duplicate
2: Levenshtein distance: 11 =&gt; not a duplicate
3: Levenshtein distance: 4 =&gt; not a duplicate
4: Levenshtein distance: 8 =&gt; not a duplicate
5: Levenshtein distance: 2 =&gt; duplicate
6: Levenshtein distance: 4 =&gt; not a duplicate
7: Levenshtein distance: 2 =&gt; duplicate
</code></pre>
<p>This would be an approach which uses a &quot;fixed&quot; algorithm based on the Levinshtein distance.</p>
<p>Now, I would like to do this task with using a neural network / machine learning:</p>
<p>I do not need the neural network to detect semantic similarity, like &quot;hospital&quot; and &quot;clininc&quot;. However, I would like to avoid the Levenshtein-distance, as I would like the ML algorithm to be able to detect &quot;John Lemond-Lee Peter&quot; and &quot;John LL. Peter&quot; as a potential duplicate, also not with a 100% certainty. The Levenshtein distance would lead to a relative high number in this case (8), as there are quite some characters to be added. In a case like &quot;John Peter&quot; and &quot;Johanna Petera&quot; the Levenshtein-distance would lead to a smaller number (4), however this is in fact no duplicate and for this case I would hope that the ML algorithm would be able to detect that this is likely not a duplicate. So I need the ML algorithm to &quot;learn the way I need the duplicates to be checked&quot;. With my labelling I would give as an input I would give the ML algorithm the direction, of what I want.</p>
<p>I actually thought that this should be an easy task for a ML algorithm / neural network, but I am not sure.</p>
<p><strong>How can I implement a neural network to compare the pairs of names and identify duplicates without using an explicit distance metric like the Levenshtein distance?</strong></p>
<p>I thought that it would be possible to convert the strings to numbers and a neural network can work with this and learn to detect duplicates according to my labelling style. So without having to specify a distance metric. <strong>I thought about an human: I would give this task to a person and this person would judge and make a decision. This person has no clue about a Levenshtein-distance or any other mathematical concept. So I just want to train the neural network to learn to do what the human is doing.</strong> Of course, every human is different and it also depends on my labelling.</p>
",42,1,2,5,python;tensorflow;machine-learning;neural-network;levenshtein-distance,2022-07-08 21:55:04,2022-07-08 21:55:04,2022-07-13 00:46:00,i have a dataset which contains pairs of names  it looks like this  i have some cases  which are labelled  so i check them manually and decide if these are duplicates or not  the manual judgement in these cases would be   the th case is a specific case  because here phonetics come into the game too  however  this is not the main problem  i am ok with ignoring phonetics   a first approach would be to calculate the levenshtein distance for each pair and mark those as a duplicate  where the levenshtein distance is for example less or equal than   this would lead to the following output  this would be an approach which uses a  fixed  algorithm based on the levinshtein distance  now  i would like to do this task with using a neural network   machine learning  i do not need the neural network to detect semantic similarity  like  hospital  and  clininc   however  i would like to avoid the levenshtein distance  as i would like the ml algorithm to be able to detect  john lemond lee peter  and  john ll  peter  as a potential duplicate  also not with a   certainty  the levenshtein distance would lead to a relative high number in this case     as there are quite some characters to be added  in a case like  john peter  and  johanna petera  the levenshtein distance would lead to a smaller number     however this is in fact no duplicate and for this case i would hope that the ml algorithm would be able to detect that this is likely not a duplicate  so i need the ml algorithm to  learn the way i need the duplicates to be checked   with my labelling i would give as an input i would give the ml algorithm the direction  of what i want  i actually thought that this should be an easy task for a ml algorithm   neural network  but i am not sure  how can i implement a neural network to compare the pairs of names and identify duplicates without using an explicit distance metric like the levenshtein distance  i thought that it would be possible to convert the strings to numbers and a neural network can work with this and learn to detect duplicates according to my labelling style  so without having to specify a distance metric  i thought about an human  i would give this task to a person and this person would judge and make a decision  this person has no clue about a levenshtein distance or any other mathematical concept  so i just want to train the neural network to learn to do what the human is doing  of course  every human is different and it also depends on my labelling ,compare similarity of two names and identify duplicates with neural network
22,22,13329315,72956556,"column 3&#39;s mode is needed, but i cannot name columns to get data","<p>url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'
data = np.genfromtxt(url, delimiter=',', dtype='object')</p>
<p>columns = ['A', 'B', 'C', 'D', 'E']
import io
import requests</p>
<p>df = pd.read_csv(io.StringIO(data.decode('utf-8')), header = None, names=columns)</p>
<p>#data.columns = (65+np.arange(data.shape[1])).view('U2')</p>
",13,0,0,1,pandas,2022-07-12 23:28:01,2022-07-12 23:28:01,2022-07-12 23:28:01,df   pd read_csv io stringio data decode  utf      header   none  names columns   data columns     np arange data shape     view  u  ,column    s mode is needed  but i cannot name columns to get data
23,23,18543927,72937452,ImportError: dlopen(...): Library not loaded: @rpath/_pywrap_tensorflow_internal.so,"<p>I am a beginner at machine learning. I try to use LSTM algorism but when I write</p>
<p><code>from keras.models import Sequential</code></p>
<p>it shows error as below:</p>
<pre><code>ImportError: dlopen(/Users/wangzifan/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/_pywrap_tfe.so, 2): Library not loaded: @rpath/_pywrap_tensorflow_internal.so
  Referenced from: /Users/wangzifan/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/_pywrap_tfe.so
  Reason: image not found
</code></pre>
<p>How can I fix this? Thank you so much!</p>
<p>full error message:</p>
<pre><code>Traceback (most recent call last):
  File &quot;/Users/wangzifan/Desktop/machine/LSTM.py&quot;, line 39, in &lt;module&gt;
    from keras.models import Sequential
  File &quot;/Users/wangzifan/opt/anaconda3/lib/python3.9/site-packages/keras/__init__.py&quot;, line 21, in &lt;module&gt;
    from tensorflow.python import tf2
  File &quot;/Users/wangzifan/opt/anaconda3/lib/python3.9/site-packages/tensorflow/__init__.py&quot;, line 37, in &lt;module&gt;
    from tensorflow.python.tools import module_util as _module_util
  File &quot;/Users/wangzifan/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/__init__.py&quot;, line 37, in &lt;module&gt;
    from tensorflow.python.eager import context
  File &quot;/Users/wangzifan/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/context.py&quot;, line 33, in &lt;module&gt;
    from tensorflow.python import pywrap_tfe
  File &quot;/Users/wangzifan/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/pywrap_tfe.py&quot;, line 25, in &lt;module&gt;
    from tensorflow.python._pywrap_tfe import *
ImportError: dlopen(/Users/wangzifan/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/_pywrap_tfe.so, 2): Library not loaded: @rpath/_pywrap_tensorflow_internal.so
  Referenced from: /Users/wangzifan/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/_pywrap_tfe.so
  Reason: image not found

</code></pre>
",22,1,0,5,python;tensorflow;keras;pip;lstm,2022-07-11 16:26:50,2022-07-11 16:26:50,2022-07-12 22:07:14,i am a beginner at machine learning  i try to use lstm algorism but when i write from keras models import sequential it shows error as below  how can i fix this  thank you so much  full error message ,importerror  dlopen       library not loaded   rpath _pywrap_tensorflow_internal so
24,24,10018602,72850230,"Creating and Merging Multiple Datasets Does Not Fit Into Memory, Use Dask?","<p>I'm not quite sure how to ask this question, but I need some clarification on how to make use of Dask's ability to &quot;handle datasets that don't fit into memory&quot;, because I'm a little confused on how it works from the CREATION of these datasets.</p>
<p>I have made a reproducible code below that closely emulates my problem. Although this example DOES fit into my 16Gb memory, we can assume that it doesn't because it does take up ALMOST all of my RAM.</p>
<p>I'm working with 1min, 5min, 15min and Daily stock market datasets, all of which have their own technical indicators, so each of these separate dataframes are 234 columns in width, with the 1min dataset having the most rows (521,811), and going down from there. Each of these datasets can be created and fit into memory on their own, but here's where it gets tricky.</p>
<p>I'm trying to merge them column-wise into 1 dataframe, each column prepended with their respective timeframes so I can tell them apart, but this creates the memory problem. This is what I'm looking to accomplish visually:</p>
<p><a href=""https://i.stack.imgur.com/DEtpN.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/DEtpN.png"" alt=""DesiredOutcome"" /></a></p>
<p>I'm not really sure if Dask is what I need here, but I assume so. I'm NOT looking to use any kind of &quot;parallel calculations&quot; here (yet), I just need a way to create this dataframe before feeding it into a machine learning pipeline (yes, I know it's a stock market problem, just overlook that for now). I know Dask has a machine learning pipeline I can use, so maybe I'll make use of that in the future, however I need a way to save this big dataframe to disk, or create it upon importing it on the fly.</p>
<p>What I need help with is how to do this. Seeing as each of these datasets on their own fit into memory nicely, an idea I had (and this may not be correct at all so please let me know), would be to save each of the dataframes to separate parquet files to disk, then create a Dask dataframe object to import each of them into, when I go to start the machine learning pipeline. Something like this:</p>
<p><a href=""https://i.stack.imgur.com/rR8Co.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/rR8Co.png"" alt=""Idea1"" /></a></p>
<p>Is this conceptually correct with what I need to do, or am I way off? haha. I've read through the documentation on Dask, and also checked out <a href=""https://docs.dask.org/en/latest/10-minutes-to-dask.html"" rel=""nofollow noreferrer"">this guide</a> specifically, which is good, however as a newbie I need some guidance with how to do this for the first time.</p>
<p>How can I create and save this big merged dataframe to disk, if I can't create it in memory in the first place?</p>
<p>Here is my reproducible dataframe/memory problem code. Be careful when you go to run this as it'll eat up your RAM pretty quickly, I have 16Gb of RAM and it does run on my fairly light machine, but not without some red-lining RAM, just wanted to give the Dask gods out there something specific to work with. Thanks!</p>
<pre><code>from pandas import DataFrame, date_range, merge
from numpy import random

# ------------------------------------------------------------------------------------------------ #
#                                         1 MINUTE DATASET                                         #
# ------------------------------------------------------------------------------------------------ #
ONE_MIN_NUM_OF_ROWS = 521811
ONE_MIN_NUM_OF_COLS = 234
main_df = DataFrame(random.randint(0,100, size=(ONE_MIN_NUM_OF_ROWS, ONE_MIN_NUM_OF_COLS)), 
                    columns=list(&quot;col_&quot; + str(x) for x in range(ONE_MIN_NUM_OF_COLS)),
                    index=date_range(start=&quot;2019-12-09 04:00:00&quot;, freq=&quot;min&quot;, periods=ONE_MIN_NUM_OF_ROWS))


# ------------------------------------------------------------------------------------------------ #
#                                         5 MINUTE DATASET                                         #
# ------------------------------------------------------------------------------------------------ #
FIVE_MIN_NUM_OF_ROWS = 117732
FIVE_MIN_NUM_OF_COLS = 234
five_min_df = DataFrame(random.randint(0,100, size=(FIVE_MIN_NUM_OF_ROWS, FIVE_MIN_NUM_OF_COLS)), 
                    columns=list(&quot;5_min_col_&quot; + str(x) for x in range(FIVE_MIN_NUM_OF_COLS)),
                    index=date_range(start=&quot;2019-12-09 04:00:00&quot;, freq=&quot;5min&quot;, periods=FIVE_MIN_NUM_OF_ROWS))
# Merge the 5 minute to the 1 minute df
main_df = merge(main_df, five_min_df, how=&quot;outer&quot;, left_index=True, right_index=True, sort=True)


# ------------------------------------------------------------------------------------------------ #
#                                         15 MINUTE DATASET                                        #
# ------------------------------------------------------------------------------------------------ #
FIFTEEN_MIN_NUM_OF_ROWS = 117732
FIFTEEN_MIN_NUM_OF_COLS = 234
fifteen_min_df = DataFrame(random.randint(0,100, size=(FIFTEEN_MIN_NUM_OF_ROWS, FIFTEEN_MIN_NUM_OF_COLS)), 
                    columns=list(&quot;15_min_col_&quot; + str(x) for x in range(FIFTEEN_MIN_NUM_OF_COLS)),
                    index=date_range(start=&quot;2019-12-09 04:00:00&quot;, freq=&quot;15min&quot;, periods=FIFTEEN_MIN_NUM_OF_ROWS))
# Merge the 15 minute to the main df
main_df = merge(main_df, fifteen_min_df, how=&quot;outer&quot;, left_index=True, right_index=True, sort=True)


# ------------------------------------------------------------------------------------------------ #
#                                           DAILY DATASET                                          #
# ------------------------------------------------------------------------------------------------ #
DAILY_NUM_OF_ROWS = 933
DAILY_NUM_OF_COLS = 234
fifteen_min_df = DataFrame(random.randint(0,100, size=(DAILY_NUM_OF_ROWS, DAILY_NUM_OF_COLS)), 
                    columns=list(&quot;daily_col_&quot; + str(x) for x in range(DAILY_NUM_OF_COLS)),
                    index=date_range(start=&quot;2019-12-09 04:00:00&quot;, freq=&quot;D&quot;, periods=DAILY_NUM_OF_ROWS))
# Merge the daily to the main df (don't worry about &quot;forward peaking&quot; dates)
main_df = merge(main_df, fifteen_min_df, how=&quot;outer&quot;, left_index=True, right_index=True, sort=True)


# ------------------------------------------------------------------------------------------------ #
#                                            FFILL NAN's                                           #
# ------------------------------------------------------------------------------------------------ #
main_df = main_df.fillna(method=&quot;ffill&quot;)

# ------------------------------------------------------------------------------------------------ #
#                                              INSPECT                                             #
# ------------------------------------------------------------------------------------------------ #
print(main_df)
</code></pre>
<p><strong>UPDATE</strong></p>
<p>I took a stab at an attempt for a solution, but I'm still lost.</p>
<p>I see in the tutorials that it's best to merge a pandas DF with a Dask DF. Knowing that one of these dataframes fits into memory on its own, I figured what I could try was:</p>
<ol>
<li>Make the 1 minute dataframe (the biggest one) a Dask dataframe</li>
<li>Generate the 5, 15 and Daily dataframes one at a time in pandas</li>
<li>Merge the pandas dataframes with the Dask dataframe, starting with the 5 min</li>
<li>Save the final, merged Dask dataframe to disk as a parquet (or parquet's as I see it being saved as now)</li>
</ol>
<p>HOWEVER, I still don't understand how the &quot;chunk&quot;/partition sizes fits into what I'm trying to do here because, aren't partitions just chunks of ROWS that it processes? I'm working with COLUMNS here.</p>
<p>My code attempt (thanks to the first answer I received) looks something like this (but again, I'm a newbie here):</p>
<pre><code>from pandas import DataFrame, date_range, merge
from numpy import random
import dask.dataframe as dd, dask.delayed

# ------------------------------------------------------------------------------------------------ #
#                                             Variables                                            #
# ------------------------------------------------------------------------------------------------ #
ONE_MIN_NUM_OF_ROWS = 521811
FIVE_MIN_NUM_OF_ROWS = 117732
FIFTEEN_MIN_NUM_OF_ROWS = 5000
DAILY_NUM_OF_ROWS = 933
ONE_MIN_INDEX = date_range(
    start=&quot;2019-12-09 04:00:00&quot;,
    freq=&quot;1min&quot;,
    periods=ONE_MIN_NUM_OF_ROWS,
)

# ------------------------------------------------------------------------------------------------ #
#                                Function to load data by chuck size                               #
# ------------------------------------------------------------------------------------------------ #
@dask.delayed
def load_data_subset(start_date, freq, periods):
    # presumably, you'd query some API or something here
    dummy_ind = date_range(start_date, freq=freq, periods=periods)
    dummy_response = DataFrame(
        random.randint(0, 100, size=(len(dummy_ind), 234)),
        columns=list(freq + str(x) for x in range(234)),
        index=dummy_ind
    )
    return dummy_response

# ------------------------------------------------------------------------------------------------ #
#                       Create the Dask dataframe from the 1 minute dataframe                      #
# ------------------------------------------------------------------------------------------------ #
ddf = dd.from_delayed([
    load_data_subset(ONE_MIN_INDEX[i], freq=&quot;1min&quot;, periods=10000) for i in range(0, ONE_MIN_NUM_OF_ROWS, 10000)
])

# ------------------------------------------------------------------------------------------------ #
#              Merge the 5, 15, and Daily datasets to the Dask dataframe, COLUMN WISE              #
# ------------------------------------------------------------------------------------------------ #
for current_num_of_rows, current_timeframe in zip([FIVE_MIN_NUM_OF_ROWS, FIFTEEN_MIN_NUM_OF_ROWS, DAILY_NUM_OF_ROWS],
                                                  [&quot;5min&quot;, &quot;15min&quot;, &quot;1D&quot;]):
    five_min_df = DataFrame(random.randint(0,100, size=(FIVE_MIN_NUM_OF_ROWS, 234)), 
                    columns=list(&quot;5_min_col_&quot; + str(x) for x in range(234)),
                    index=date_range(start=&quot;2019-12-09 04:00:00&quot;, freq=&quot;5min&quot;, periods=FIVE_MIN_NUM_OF_ROWS))
    ddf = ddf.merge(five_min_df, how=&quot;outer&quot;, left_index=True, right_index=True)
    
    fifteen_min_df = DataFrame(random.randint(0,100, size=(FIFTEEN_MIN_NUM_OF_ROWS, 234)), 
                    columns=list(&quot;15_min_col_&quot; + str(x) for x in range(234)),
                    index=date_range(start=&quot;2019-12-09 04:00:00&quot;, freq=&quot;15min&quot;, periods=FIFTEEN_MIN_NUM_OF_ROWS))
    ddf = ddf.merge(fifteen_min_df, how=&quot;outer&quot;, left_index=True, right_index=True)

    daily_df = DataFrame(random.randint(0,100, size=(DAILY_NUM_OF_ROWS, 234)), 
                    columns=list(&quot;daily_col_&quot; + str(x) for x in range(234)),
                    index=date_range(start=&quot;2019-12-09 04:00:00&quot;, freq=&quot;1D&quot;, periods=DAILY_NUM_OF_ROWS))
    ddf = ddf.merge(daily_df, how=&quot;outer&quot;, left_index=True, right_index=True)

# ------------------------------------------------------------------------------------------------ #
#                                              Export                                              #
# ------------------------------------------------------------------------------------------------ #
ddf.to_parquet(&quot;test&quot;, overwrite=True)
</code></pre>
<p>When I do this, my resources look like this for a while:</p>
<p><a href=""https://i.stack.imgur.com/RZkgR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/RZkgR.png"" alt=""Resources"" /></a></p>
<p>...then as it starts writing the parquet files to disk, it's this:</p>
<p><a href=""https://i.stack.imgur.com/P4Ker.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/P4Ker.png"" alt=""Resources2"" /></a>
<a href=""https://i.stack.imgur.com/olPS5.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/olPS5.png"" alt=""Resources3"" /></a></p>
<p>I'm hoping this provides some direction in what I'm looking to accomplish here, I just have no idea how to make this work.</p>
<p>KEEP IN MIND, that technical indicators are being used in the application I'm trying to emulate, so I can't calculate the technical indicators on &quot;chunks&quot; of rows, because, in the instance of a moving average for example, the first X rows would all be nan's while it's making the moving average. The entire dataframe needs to be made first in order to keep the technical indicators in tact before merging the dataframes together.</p>
<p>Thanks!</p>
",96,1,1,5,python;pandas;dataframe;dask;dask-dataframe,2022-07-04 03:40:09,2022-07-04 03:40:09,2022-07-12 21:23:49,i m not quite sure how to ask this question  but i need some clarification on how to make use of dask s ability to  handle datasets that don t fit into memory   because i m a little confused on how it works from the creation of these datasets  i have made a reproducible code below that closely emulates my problem  although this example does fit into my gb memory  we can assume that it doesn t because it does take up almost all of my ram  i m working with min  min  min and daily stock market datasets  all of which have their own technical indicators  so each of these separate dataframes are  columns in width  with the min dataset having the most rows      and going down from there  each of these datasets can be created and fit into memory on their own  but here s where it gets tricky  i m trying to merge them column wise into  dataframe  each column prepended with their respective timeframes so i can tell them apart  but this creates the memory problem  this is what i m looking to accomplish visually   i m not really sure if dask is what i need here  but i assume so  i m not looking to use any kind of  parallel calculations  here  yet   i just need a way to create this dataframe before feeding it into a machine learning pipeline  yes  i know it s a stock market problem  just overlook that for now   i know dask has a machine learning pipeline i can use  so maybe i ll make use of that in the future  however i need a way to save this big dataframe to disk  or create it upon importing it on the fly  what i need help with is how to do this  seeing as each of these datasets on their own fit into memory nicely  an idea i had  and this may not be correct at all so please let me know   would be to save each of the dataframes to separate parquet files to disk  then create a dask dataframe object to import each of them into  when i go to start the machine learning pipeline  something like this   is this conceptually correct with what i need to do  or am i way off  haha  i ve read through the documentation on dask  and also checked out  specifically  which is good  however as a newbie i need some guidance with how to do this for the first time  how can i create and save this big merged dataframe to disk  if i can t create it in memory in the first place  here is my reproducible dataframe memory problem code  be careful when you go to run this as it ll eat up your ram pretty quickly  i have gb of ram and it does run on my fairly light machine  but not without some red lining ram  just wanted to give the dask gods out there something specific to work with  thanks  update i took a stab at an attempt for a solution  but i m still lost  i see in the tutorials that it s best to merge a pandas df with a dask df  knowing that one of these dataframes fits into memory on its own  i figured what i could try was  however  i still don t understand how the  chunk  partition sizes fits into what i m trying to do here because  aren t partitions just chunks of rows that it processes  i m working with columns here  my code attempt  thanks to the first answer i received  looks something like this  but again  i m a newbie here   when i do this  my resources look like this for a while      then as it starts writing the parquet files to disk  it s this  i m hoping this provides some direction in what i m looking to accomplish here  i just have no idea how to make this work  keep in mind  that technical indicators are being used in the application i m trying to emulate  so i can t calculate the technical indicators on  chunks  of rows  because  in the instance of a moving average for example  the first x rows would all be nan s while it s making the moving average  the entire dataframe needs to be made first in order to keep the technical indicators in tact before merging the dataframes together  thanks ,creating and merging multiple datasets does not fit into memory  use dask 
25,25,17126954,72936240,identifying miss classified values in confusion matrix in R,"<p>I am using the caret package along with the confusionMatrix function and I would like to know if it is possible to know which are the exact values that were not clasified properly.</p>
<p>Here is a subset of my train data</p>
<pre><code>train_sub &lt;- structure(
  list(
    corr = c(
      0.629922866893549,
      0.632354159559817,
      0.656112138936032,
      0.4469719807955,
      0.598136079870775,
      0.314461239093862,
      0.379065842199838,
      0.347331370037428,
      0.310270891798492,
      0.361064451331448,
      0.335628455451358
    ),
    rdist = c(
      0.775733824285612,
      0.834148208687529,
      0.884167982488944,
      0.633989717138057,
      0.850225777237626,
      0.626197919283803,
      0.649597055761598,
      0.680382136363523,
      0.627828985862852,
      0.713674404108905,
      0.646094473468118
    ),
    CCF2 = c(
      0.634465565134314,
      0.722096802135009,
      0.792385621105087,
      0.46497582143802,
      0.739612023831014,
      0.470724554509749,
      0.505961260826622,
      0.527876803999064,
      0.461724328071479,
      0.564117580569802,
      0.490084457081904
    ),
    Wcorr = c(
      0.629,
      0.613,
      0.812,
      0.424,
      0.593,
      0.36,
      0.346,
      0.286,
      0.333,
      0.381,
      0.333
    ),
    Wcorr2 = c(
      0.735,
      0.743,
      0.802,
      0.588,
      0.691,
      0.632,
      0.61,
      0.599,
      0.599,
      0.632,
      0.613
    ),
    Wcorr3 = c(
      0.21,
      0.301,
      0.421,
      -0.052,
      0.169,
      -0.032,
      -0.042,-0.048,
      -0.035,
      0.006,
      -0.004
    ),
    Var = c(&quot;W&quot;, &quot;W&quot;, &quot;W&quot;, &quot;W&quot;,
            &quot;W&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;)
  ),
  row.names = c(1L, 2L,
                3L, 5L, 7L, 214L, 215L, 216L, 217L, 218L, 221L),
  class = &quot;data.frame&quot;
)
</code></pre>
<p>and here is a subset of my test data</p>
<pre><code>test_sub &lt;- structure(
  list(
    corr = c(
      0.636658204667785,
      0.5637857758104,
      0.540558984461647,
      0.392647603023863,
      0.561801911406989,
      0.297187412065481,
      0.278864501603015,
      0.505277007007347,
      0.403811785308709,
      0.510158398354856,
      0.459607853624603
    ),
    rdist = c(
      0.887270722679019,
      0.843656768956754,
      0.815806338767273,
      0.732093571145576,
      0.832944903081762,
      0.485497073465096,
      0.454461718498521,
      0.69094669881886,
      0.627667080657035,
      0.705558894672344,
      0.620838398507191
    ),
    CCF2 = c(
      0.802017782695131,
      0.731763898271157,
      0.689402284804853,
      0.577932997250877,
      0.715111899030751,
      0.324826043263382,
      0.298456267077388,
      0.544808216945995,
      0.458148923874818,
      0.551160266327893,
      0.461228649848996
    ),
    Wcorr = c(
      0.655,
      0.536,
      0.677,
      0.556,
      0.571,
      0.29,
      0.25,
      0.484,
      0.25,
      0.515,
      0.314
    ),
    Wcorr2 = c(
      0.779,
      0.682,
      0.734,
      0.675,
      0.736,
      0.5,
      0.529,
      0.611,
      0.555,
      0.639,
      0.572
    ),
    Wcorr3 = c(
      0.368,
      0.154,
      0.266,
      0.103,
      0.224,
      -0.204,
      -0.16,
      -0.026,
      -0.149,
      0.032,
      -0.097
    ),
    Var = c(&quot;W&quot;, &quot;W&quot;, &quot;W&quot;, &quot;W&quot;, &quot;W&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;,
            &quot;B&quot;)
  ),
  row.names = c(4L, 6L, 8L, 13L, 15L, 321L, 322L, 329L,
                334L, 341L, 344L),
  class = &quot;data.frame&quot;
)
</code></pre>
<p>When I use this line,</p>
<pre><code>confusionMatrix(reference=as.factor(test$Var),data=fittedTL,mode = &quot;everything&quot;)
</code></pre>
<p>With this I compute some machine learning using glmnet method (it gives the best accuracy ini my case)</p>
<pre><code>classCtrl &lt;- trainControl(method = &quot;repeatedcv&quot;, number=10,repeats=5,classProbs =  TRUE,savePredictions = &quot;final&quot;)
set.seed(355)
glmnetTL &lt;- train(Var~., train_sub, method= &quot;glmnet&quot;,   trControl=classCtrl)
glmnetTL
</code></pre>
<p>And finally I compute the confusion matrix on my test set:</p>
<pre><code>predict_glmnet &lt;- predict(glmnetTL,test_sub)
predict_glmnet

CM_glmnet &lt;- confusionMatrix(reference=as.factor(test_sub$Var),data=predict_glmnet,mode = &quot;everything&quot;)
CM_glmnet
</code></pre>
<p>The output of the confusion matrix is a table like so</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th style=""text-align: left;""></th>
<th style=""text-align: center;"">B</th>
<th style=""text-align: right;"">W</th>
</tr>
</thead>
<tbody>
<tr>
<td style=""text-align: left;"">B</td>
<td style=""text-align: center;"">4</td>
<td style=""text-align: right;"">0</td>
</tr>
<tr>
<td style=""text-align: left;"">W</td>
<td style=""text-align: center;"">2</td>
<td style=""text-align: right;"">5</td>
</tr>
</tbody>
</table>
</div>
<p>So here I have two predictions/classifications that are not good.</p>
<p>Is there any way I can traceback to which row of my test set it corresponds ?</p>
",22,0,0,3,r;r-caret;confusion-matrix,2022-07-11 14:50:10,2022-07-11 14:50:10,2022-07-12 19:54:26,i am using the caret package along with the confusionmatrix function and i would like to know if it is possible to know which are the exact values that were not clasified properly  here is a subset of my train data and here is a subset of my test data when i use this line  with this i compute some machine learning using glmnet method  it gives the best accuracy ini my case  and finally i compute the confusion matrix on my test set  the output of the confusion matrix is a table like so so here i have two predictions classifications that are not good  is there any way i can traceback to which row of my test set it corresponds  ,identifying miss classified values in confusion matrix in r
26,26,19534112,72952963,Neural network doesn&#39;t classify sleep EEG recordings,"<p>We have a problem with the code that I'm running in an academic course and I'd appreciate getting some help from someone on the forum.
We're trying to train a CNN model to classify EEG sleep recordings as male or female. It's something that was done in some papers but we use a different dataset in our course. The problem is that the network doesn't learn no matter what we do - we tried changing the number of the layers, the size of each layer, the learning rate, the number of epochs, the batch sizem the optimizer and also adding data.
We also tried using an RNN with a GRU (Gated Recurrent Unit) instead of a CNN but it didn't help.
Here are some examples of the network not learning:</p>
<p><a href=""https://i.stack.imgur.com/kr8yD.png"" rel=""nofollow noreferrer"">Example 1</a>
<a href=""https://i.stack.imgur.com/WYUuG.png"" rel=""nofollow noreferrer"">Example 2</a></p>
<p>Note that the &quot;test&quot; dataset is actually validation.</p>
<p>We can't find any problem with the machine learning part of our code. We think that maybe the problem is with the data processing part but we're not sure so we wanted someone to check if he/she can find a problem with the machine learning part.
Before I should say that we have 200 8-hour recordings of sleep EEG obtained from 200 patients. These are 100 Hz recording. The shape of each sample is 4X2X1000 (4 batches X 2 EEG channels for each recording X 1000 voltage values representing 10 seconds of recording).</p>
<p>Here's the machine learning part (I post a lot of code in case someone says that more code is needed...):</p>
<pre><code>import _pickle
import contextlib
import io
import torch
import os
import numpy as np
from aux_eegproj_funcs_simplified import *
from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler
import torch
import torch.nn as nn
from sklearn.metrics import accuracy_score, f1_score, ConfusionMatrixDisplay
import pandas as pd
import matplotlib.pyplot as plt
from tqdm import tqdm
import torchviz
import mne
</code></pre>
<pre><code># DATASET
table_name = 'sleep_1_10sec.csv' # name of the table from which we take the beginning and end time of each sample (subrecording)
eeg_ds = EEGDataset(EEGTransform, exp_table=build_experiment_tbl(table_name), filtered=0)  # EEGDataSet and EEGTransform are a class
batch_sz = 4 # batch size

# splitting the data to train, validation and test
dl_train, dl_val, dl_test = tt_split_by_pid_mf(dataset=eeg_ds, batch_size=batch_sz, train_rt=.8,  num_workers=0, verbose=1)
nF = sum(eeg_ds.table['sex (F=1)'][dl_train.sampler.indices] == 1)  # number of females
nM = sum(eeg_ds.table['sex (F=1)'][dl_train.sampler.indices] == 2)  # number of males
wF = nM / (nF + nM)  # females percentage
wM = nF / (nF + nM)  # males percentage
</code></pre>
<p>The model:</p>
<pre><code>class eegSexNet(nn.Module):  # Define a network to classify Sex
    def __init__(self, input_shape):
        &quot;&quot;&quot;
        :param input_shape: input tensor shape - every batch size will be ok as it is used to compute the FCs input size.
        &quot;&quot;&quot;
        super().__init__()
        # Define the CNN layers in a nn.Sequential.
        # Remember to use the number of input channels as the first layer input shape.
        self.CNN = nn.Sequential(
            nn.Conv1d(in_channels=input_shape[1], out_channels=8, kernel_size=5, stride=1, padding=0, dilation=2),
            # TODO try changing the kernel sizes they were 3
            nn.ReLU(),
            nn.Conv1d(in_channels=8, out_channels=16, kernel_size=5, stride=1, padding=0, dilation=2),
            nn.ReLU(),
            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0, dilation=2),
            nn.ReLU(),
            Residual(in_channels=32)
        )

        # Compute the CNN output size here to use as the input size for the fully-connected part.
        CNN_forward = self.CNN(torch.zeros(input_shape))

        self.FCs = nn.Sequential(
            nn.Linear(CNN_forward.shape[1] * CNN_forward.shape[2], 10),
            nn.ReLU(),
            nn.Linear(10, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        # ------Your code------#
        # Forward through the CNN by passing x, flatten and then forward through the linears.
        features = self.CNN(x)
        features = features.view(features.size(0), -1)  # reshape/flatten
        scores = self.FCs(features)
        # ------^^^^^^^^^------#
        return torch.squeeze(scores)
</code></pre>
<p>Residual block used in the class of the model:</p>
<pre><code>class Residual(nn.Module):
    def __init__(self, in_channels):
        super().__init__()
        # Define self.direct_path by adding the layers into a nn.Sequential. Use nn.Conv1d and nn.Relu.
        # You can use padding to avoid reducing L size, to allow the skip-connection adding.
        self.direct_path = nn.Sequential(
            nn.Conv1d(in_channels=in_channels, out_channels=16, kernel_size=7, padding=3),
            nn.ReLU(),
            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=7, padding=3)
        )
        # You should use convolution layer with a kernel size of 1 to consider the case where the input and output shapes mismatch.
        skip_layers = []
        if in_channels != 32:  # HOW DOES THIS PART WORK? When are you adding the layers
            skip_layers.append(
                nn.Conv1d(in_channels=in_channels, out_channels=32, kernel_size=1, stride=1, padding=0, dilation=1,
                          bias=False)
            )
        else:
            self.skip_path = nn.Sequential(*skip_layers)

    def forward(self, x):
        # Compute the two paths and add the results to each other, then use ReLU (torch.relu) to activate the output.
        direct_output = self.direct_path(x)
        skip_output = self.skip_path(x)
        activated_output = torch.relu(direct_output + skip_output)
        return activated_output
</code></pre>
<p>Training loop:</p>
<pre><code>def Train_Sex_Net(epochs=n_epochs, fn='None', optimizer=opt_sex, loss_function=bce):  # Training SEXNET
    global sex_net
    gpu_0 = torch.device(1)
    label = 0  # select the sex label
    train_loss_vec = []
    test_loss_vec = []
    train_acc_vec = []
    test_acc_vec = []
    for i_epoch in range(epochs):
        train_loss = 0
        test_loss = 0
        # Train set
        train_loss, y_true_train, y_pred_train = forward_epoch(sex_net, dl_train, loss_function, optimizer,
                                                                wM, train_loss,
                                                               to_train=True, desc='Train', device=gpu_0, label=label)
        # Test set
        test_loss, y_true_test, y_pred_test = forward_epoch(sex_net, dl_test, loss_function, optimizer, wM, test_loss,
                                                            to_train=False, desc='Test', device=gpu_0, label=label)

        # Metrics:
        train_loss = train_loss / len(dl_train)  # we want to get the mean over batches.
        test_loss = test_loss / len(dl_test)
        train_loss_vec.append(train_loss)
        test_loss_vec.append(test_loss)

        train_accuracy = accuracy_score(y_true_train.cpu(),
                                        (y_pred_train.cpu().detach() &gt; 0.5) * 1)
        test_accuracy = accuracy_score(y_true_test.cpu(),
                                       (y_pred_test.cpu().detach() &gt; 0.5) * 1)

        train_acc_vec.append(train_accuracy)
        test_acc_vec.append(test_accuracy)

        print('\n')
        print(f'train_loss={round(train_loss, 3)}; train_accuracy={round(train_accuracy, 3)} \
              test_loss={round(test_loss, 3)}; test_accuracy={round(test_accuracy, 3)}')

    return (train_loss_vec, train_acc_vec), (test_loss_vec, test_acc_vec) # (val_loss_vec, val_acc_vec)

</code></pre>
<p>Called by the training loop:</p>
<pre><code>def forward_epoch(model, dl, loss_function, optimizer, weight, total_loss=0,
                  to_train=False, desc=None, device=torch.device('cpu'), label=0): # Training loop
    # label =0 is for sex
    # label = 1 is for Age
    # total loss is over the entire epoch
    # y_trues is by patient for the entire epoch; can get last batch with [-batch_size]
    # y_preds is by patient for the entire epoch
    #
    with tqdm(total=len(dl), desc=desc, ncols=100) as pbar:
        model = model.double().to(device)  # solving runtime memory issue

        y_trues = torch.empty(0).type(torch.int).to(device)
        y_preds = torch.empty(0).type(torch.int).to(device)
        for i_batch, (X, y) in enumerate(dl):
            X = X.to(device)
            X = X.type(torch.double)
            y = y[label].to(device)  # added index because of get label returning sex, age
            y_pred = model(X)  # Forward
            y_true = y.type(torch.double)  # Loss:
            y_true_copy = torch.clone(y_true)
            loss = loss_function(y_pred, y_true)  # loss of one batch
            total_loss += loss.item()

            y_trues = torch.cat((y_trues, y_true))
            y_preds = torch.cat((y_preds, y_pred))
            if to_train:
                optimizer.zero_grad()  #  Backward:zero the gradients to not accumulate their changes.
                loss.backward()  # get gradients
                optimizer.step()  # Optimization step: use gradients
            pbar.update(1)  # Progress bar

    return total_loss, y_trues, y_preds
</code></pre>
<p>Calling all the functions:</p>
<pre><code>sex_net = eegSexNet(torch.Size([4, 2, 1000]))  # Instantiate the network

learning_rate = 0.0001
opt_sex = torch.optim.Adam(params=sex_net.parameters(), lr=learning_rate)  # Optimizer for eegnet
bce = nn.BCELoss()
n_epochs = 6
f0 = 'sex_k7'  # file format '.pickle' added automatically
train_res, test_res = Train_Sex_Net(epochs=n_epochs, fn=f0)
</code></pre>
<p>Does anyone see anything that might be wrong in the code? Or maybe the problem is in the data processing and choosing part that I didn't show?</p>
",44,1,0,4,python;machine-learning;neural-network;pytorch,2022-07-12 18:47:11,2022-07-12 18:47:11,2022-07-12 19:30:34,note that the  test  dataset is actually validation  here s the machine learning part  i post a lot of code in case someone says that more code is needed      the model  residual block used in the class of the model  training loop  called by the training loop  calling all the functions  does anyone see anything that might be wrong in the code  or maybe the problem is in the data processing and choosing part that i didn t show ,neural network doesn   t classify sleep eeg recordings
27,27,19520661,72933415,ROOT&#39;s TMVA user guide,"<p>I am using ROOT's TMVA (developed by CERN), the version of the ROOT is 6.24.
the user manual i have is for TMVA version 4.3.0 (for ROOT &gt;= 6.12/00 on May 26, 2020)
but the manual seems to be a little bit different from my current version (for example, the options available for a particular machine learning model).</p>
<p>is there any updated user manual, or portals that provide guides on the options available for a particular machine learning model.</p>
",17,1,0,1,root-framework,2022-07-11 09:00:43,2022-07-11 09:00:43,2022-07-12 19:21:37,is there any updated user manual  or portals that provide guides on the options available for a particular machine learning model ,root   s tmva user guide
28,28,5654564,38380795,"pandas read_json: &quot;If using all scalar values, you must pass an index&quot;","<p>I have some difficulty in importing a JSON file with pandas.</p>

<pre><code>import pandas as pd
map_index_to_word = pd.read_json('people_wiki_map_index_to_word.json')
</code></pre>

<p>This is the  error that I get: </p>

<pre><code>ValueError: If using all scalar values, you must pass an index
</code></pre>

<p>The file structure is simplified like this:</p>

<pre><code>{""biennials"": 522004, ""lb915"": 116290, ""shatzky"": 127647, ""woode"": 174106, ""damfunk"": 133206, ""nualart"": 153444, ""hatefillot"": 164111, ""missionborn"": 261765, ""yeardescribed"": 161075, ""theoryhe"": 521685}
</code></pre>

<p>It is from the machine learning course of University of Washington on Coursera. You can find the file <a href=""https://www.coursera.org/learn/ml-clustering-and-retrieval/supplement/gJSfc/choosing-features-and-metrics-for-nearest-neighbor-search"" rel=""noreferrer"">here</a>.</p>
",81429,7,56,3,python;json;pandas,2016-07-14 23:11:10,2016-07-14 23:11:10,2022-07-12 14:40:53,i have some difficulty in importing a json file with pandas  this is the  error that i get   the file structure is simplified like this  it is from the machine learning course of university of washington on coursera  you can find the file  ,pandas read_json   if using all scalar values  you must pass an index 
29,29,19457689,72948809,terraform conditionals to use different resources in azure,"<p>I want to create resources like azure kubernetes cluster and azure compute cluster to attach it with the Azure machine learning workspace. I need to create a conditional to use either one of Kuberenetes cluster or compute cluster. Is there a way to do that.</p>
",25,0,-1,3,azure;terraform;conditional-statements,2022-07-12 13:23:45,2022-07-12 13:23:45,2022-07-12 13:23:45,i want to create resources like azure kubernetes cluster and azure compute cluster to attach it with the azure machine learning workspace  i need to create a conditional to use either one of kuberenetes cluster or compute cluster  is there a way to do that ,terraform conditionals to use different resources in azure
30,30,11053795,72945697,how to get pycharm to do GraphViz,"<p>The data for this comes from the UCI machine learning repository
Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.</p>
<p>This code runs without any technical error but whether I run it with None for out_file or give it a png file name it doesnt make the decision tree visual, instead it just prints it like this:</p>
<pre><code>digraph Tree {
node [shape=box, style=&quot;filled&quot;, color=&quot;black&quot;, fontname=&quot;helvetica&quot;] ;
edge [fontname=&quot;helvetica&quot;] ;
0 [label=&quot;income_ &gt;50K &lt;= 0.5\ngini = 0.366\nsamples = 32561\nvalue = [24720, 
7841]\nclass = i&quot;, fillcolor=&quot;#eda978&quot;] ;
1 [label=&quot;gini = 0.0\nsamples = 24720\nvalue = [24720, 0]\nclass = i&quot;, 
fillcolor=&quot;#e58139&quot;] ;
0 -&gt; 1 [labeldistance=2.5, labelangle=45, headlabel=&quot;True&quot;] ;
2 [label=&quot;gini = 0.0\nsamples = 7841\nvalue = [0, 7841]\nclass = n&quot;, 
fillcolor=&quot;#399de5&quot;] ;
0 -&gt; 2 [labeldistance=2.5, labelangle=-45, headlabel=&quot;False&quot;] ;
}
</code></pre>
<p><strong>here is my code</strong></p>
<pre><code>csv_file = age, workclass, fnlwgt, education, educationnum, maritalstatus, occupation, 
relationship, race, sex, capitalgain, capitalloss, hoursperweek, nativecountry, income
39, State-gov, 77516, Bachelors, 13, Never-married, Adm-clerical, Not-in-family, White, 
Male, 2174, 0, 40, United-States, &lt;=50K
50, Self-emp-not-inc, 83311, Bachelors, 13, Married-civ-spouse, Exec-managerial, 
Husband, White, Male, 0, 0, 13, United-States, &lt;=50K
38, Private, 215646, HS-grad, 9, Divorced, Handlers-cleaners, Not-in-family, White, 
Male, 0, 0, 40, United-States, &lt;=50K
53, Private, 234721, 11th, 7, Married-civ-spouse, Handlers-cleaners, Husband, Black, 
Male, 0, 0, 40, United-States, &lt;=50K


########## alternative 2 ##########
import pandas as pd
import numpy as np
from sklearn.preprocessing import OneHotEncoder
import graphviz

# basic dataframe
dataframe = pd.read_csv(csv_file)

# cleaned up dataframe
dataframe.columns = dataframe.columns.str.strip()

# one hot encoded dataframe
ohe = pd.get_dummies(dataframe, columns=dataframe.columns)

# decision tree classifier
clf = tree.DecisionTreeClassifier(max_leaf_nodes=3)
clf = clf.fit(ohe, ohe['income_ &gt;50K'])

# display for user
dot_data = tree.export_graphviz(clf, out_file=None,
                            feature_names=ohe.columns, class_names='income_ &gt;50K', 
filled=True)

graph = graphviz.Source(dot_data, format='png')

print(graph)
</code></pre>
<p>I am unsure how to proceed...</p>
",25,0,1,4,python-3.x;scikit-learn;pycharm;graphviz,2022-07-12 05:19:55,2022-07-12 05:19:55,2022-07-12 06:37:07,this code runs without any technical error but whether i run it with none for out_file or give it a png file name it doesnt make the decision tree visual  instead it just prints it like this  here is my code i am unsure how to proceed   ,how to get pycharm to do graphviz
31,31,78259,648246,At what point does a config file become a programming language?,"<p>I have been mulling over config files and their relationship to code for a while now and depending on the day and direction of the wind my opinions seem to change.  More and more though I keep coming back to the realization I first had while learning Lisp: there is little difference between data and code.  This seems doubly true for config files.  When looked at in the right light a Perl script is little more than a config file for perl.  This tends to have fairly heavy consequences for tasks such as QA and divisions of labor like who should be responsible for changing config files.</p>

<p>The creep from config file to full fledged language is generally slow and seems to be driven by the desire to have a generic system.  Most projects seem to start out small with a few config items like where to write logs, where to look for data, user names and passwords, etc.  But then they start to grow: features start to be able to be turned on or off, the timings and order of operations start to be controlled, and, inevitably, someone wants to start adding logic to it (e.g. use 10 if the machine is X and 15 if the machine is Y).  At a certain point the config file becomes a domain specific language, and a poorly written one at that.</p>

<p>Now that I have rambled on to set the stage, here are my questions:</p>

<ol>
<li>What is the true purpose of a config
file?</li>
<li>Should an attempt be made to keep
config files simple?</li>
<li>Who should be responsible for making
changes to them (developers, users,
admins, etc.)?</li>
<li>Should they be source controlled
(see question 3)?</li>
</ol>

<p>As I said earlier my answers to these questions shift constantly, but right now I am thinking:</p>

<ol>
<li>to allow a non-programmers to change
large chunks of behaviour quickly</li>
<li>yes, anything that is not coarsely
grained should be in code</li>
<li>users should be responsible for
config files and programmers should
be responsible for a configuration
layer between config files and code
that gives more fine grained control
of the application</li>
<li>no, but the finer grained middle layer should be</li>
</ol>
",17117,19,101,4,configuration;programming-languages;configuration-files;config,2009-03-15 23:37:14,2009-03-15 23:37:14,2022-07-12 05:30:09,i have been mulling over config files and their relationship to code for a while now and depending on the day and direction of the wind my opinions seem to change   more and more though i keep coming back to the realization i first had while learning lisp  there is little difference between data and code   this seems doubly true for config files   when looked at in the right light a perl script is little more than a config file for perl   this tends to have fairly heavy consequences for tasks such as qa and divisions of labor like who should be responsible for changing config files  the creep from config file to full fledged language is generally slow and seems to be driven by the desire to have a generic system   most projects seem to start out small with a few config items like where to write logs  where to look for data  user names and passwords  etc   but then they start to grow  features start to be able to be turned on or off  the timings and order of operations start to be controlled  and  inevitably  someone wants to start adding logic to it  e g  use  if the machine is x and  if the machine is y    at a certain point the config file becomes a domain specific language  and a poorly written one at that  now that i have rambled on to set the stage  here are my questions  as i said earlier my answers to these questions shift constantly  but right now i am thinking ,at what point does a config file become a programming language 
32,32,2451456,72409120,"Unity&#39;s ml-agents assets throw warnings and errors [PushBlockWithInput, Actuator, Barracuda]","<h2>The Problem</h2>
<p>I'm trying to work with <a href=""https://unity.com/products/machine-learning-agents"" rel=""nofollow noreferrer"">Unity Machine Learning Agents</a> and encountered problems during the setup. When I try to import the assets from <a href=""https://github.com/Unity-Technologies/ml-agents"" rel=""nofollow noreferrer"">Unity's ml-agents git</a> into Unity, I get many warnings and errors inside Unity. For the purpose of context, I'm at the very beginning of learning Unity, so I don't know if the errors are due to the ml-agents package or user error from my side in how to set everything up.</p>
<h2>The errors and warnings</h2>
<p>Instructions to create a first test scene with assets from Unity's ml-agents git suggest making a new 3D project in Unity and drag and drop the folder <code>projects/assets/ml-agents</code> into the project's assets. At this point, Unity is showing many errors and warnings in the Terminal. It still has the examples in the assets but every element in the scene is full of warnings.</p>
<p>according to these tutorials from 2020 by dragging and dropping the assets into Unity <a href=""https://www.youtube.com/watch?v=GhS6-vvhOy8&amp;t=469s"" rel=""nofollow noreferrer"">[1]</a> <a href=""https://www.youtube.com/watch?v=_9aPZH6pyA8&amp;t=86s"" rel=""nofollow noreferrer"">[2]</a>, I subsequently
<a href=""https://i.stack.imgur.com/FIVsQ.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/FIVsQ.jpg"" alt=""enter image description here"" /></a></p>
<p>In my case the majority of the warnings seem to come from <code>PushBlockWithInput</code>, <code>PushblockActions</code> and <code>PushBlockWithInputPlayerController</code> missing <code>UnityEngine.InputSystem</code> and <code>Unity.MLAgents.Extensions.Input</code> with the note &quot;(are you missing a using directive or an assembly reference?)&quot;. This; however, did not happen in the aforementioned tutorials.</p>
<p>Although they make the majority of errors, they are not exclusively about assembly references. Other errors, which may or may not be about assembly references, are</p>
<ul>
<li>error CS0115: 'Match3Board.GetCurrentBoardSize()': no suitable method found to override</li>
<li>error CS0535: 'SensorBase' does not implement interface member 'ISensor.GetCompressionType()'</li>
</ul>
<p><a href=""https://i.stack.imgur.com/dH4Gj.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/dH4Gj.jpg"" alt=""enter image description here"" /></a></p>
<h2>The things I've tried</h2>
<h3>Python</h3>
<p>I've followed the <a href=""https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Installation.md"" rel=""nofollow noreferrer"">instructions</a> from Unity's ml-agents git and was successful in installing a Python 3.7 environment with Anaconda, PyTorch with Cuda, and the Unity's ml-agents python package via pip. When trying to verify the ml-agents python package works with <code>mlagents-learn --help</code>, I first got an exception but could resolve that by updating <code>protobuf==3.20.1</code> as per <a href=""https://discuss.streamlit.io/t/typeerror-descriptors-cannot-not-be-created-directly/25639/3"" rel=""nofollow noreferrer"">suggestion from a forum</a> (just mentioning this in case it is relevant).</p>
<h3>Unity</h3>
<p>I downloaded the C# package from Unity's package manager and tried it for several versions (<code>1.0.8 (Verified), 1.9.1 (Preview), 2.0.1, and 2.1.0 (Preview) -- lastest</code>). After which I'm able to select ML-Agents from the 'Add Component' menu in the Inspector.</p>
<p>I've also tried to create a new Unity project with the <code>ml-agent package 1.9.1 (Preview)</code> with the right Barracuda version, and the release 19 branch of Unity's ml-agents git, without success (now it's 53 warnings and 70 errors). Now also the Actuators are not found, which seems to be a more common problem on its own.</p>
<h3>VS Code</h3>
<p>I'm using VS Code as opposed to VS as was recommended <a href=""https://stackoverflow.com/a/63301180/2451456"">here</a>. I downloaded .Net version 6.0.301 and checked it was installed with 'dotnet --info'. In the VS Code's extension manager, I installed the extensions <a href=""https://marketplace.visualstudio.com/items?itemName=ms-dotnettools.csharp"" rel=""nofollow noreferrer"">C#</a>, <a href=""https://marketplace.visualstudio.com/items?itemName=formulahendry.code-runner"" rel=""nofollow noreferrer"">Code Runner</a>, <a href=""https://marketplace.visualstudio.com/items?itemName=Tobiah.unity-tools"" rel=""nofollow noreferrer"">Unity Tools
</a>, <a href=""https://marketplace.visualstudio.com/items?itemName=Unity.unity-debug"" rel=""nofollow noreferrer"">Debugger for Unity</a>.</p>
<h3>Git-Repository</h3>
<p>I have also switched from Unity's ml-agents git's main branch to the <a href=""https://github.com/Unity-Technologies/ml-agents/tree/release_19_branch"" rel=""nofollow noreferrer"">release 19 branch</a> and also tried other versions of the Barracuda package, e.g. <code>Version 3.0.0</code>, which seems to remove the warnings, but not the errors and instead gives these notifications:</p>
<p><a href=""https://i.stack.imgur.com/gQZqW.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/gQZqW.jpg"" alt=""enter image description here"" /></a></p>
<p>However, warnings still show up in the assets' settings:</p>
<p><a href=""https://i.stack.imgur.com/rQWDb.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/rQWDb.jpg"" alt=""enter image description here"" /></a></p>
<h2>Course: ML-Agents: Hummingbirds</h2>
<p>I successfully completed the <a href=""https://learn.unity.com/course/ml-agents-hummingbirds?uv=2019.3"" rel=""nofollow noreferrer"">ML-Agents: Hummingbirds</a>. This course doesn't use any of the assets from the ML-agents Git repository. Although, assets for this course are downloaded and added the same way, without issues. This lets me assume that the general setup for ML-agents is working but I specifically can't import the assets.</p>
<h2>My setup</h2>
<ul>
<li>I'm working on a machine with Windows 11</li>
<li><code>Unity Version is 2020.3.32f1 Personal &lt;DX11&gt;</code></li>
<li>The Unity <code>ml-agent package</code> was tried with <code>1.0.8 (Verified), 1.9.1 (Preview), 2.0.1, and 2.0.2 (Preview)</code></li>
<li>The Unity <code>ML Agents Extensions</code> package 0.6.1 (preview)</li>
<li>Python Version is, as per <a href=""https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Installation.md"" rel=""nofollow noreferrer"">instructions</a>, <code>3.7 with an Anaconda virtual environment</code></li>
<li>Unity's ml-agents git is <code>main</code>, as well as <code>release_19_branch</code></li>
<li>C# editor would be <code>Visual Studio Code 1.67.2</code></li>
<li>DotNet Version: 6.0.301</li>
</ul>
<h2>Things I found out so far</h2>
<p>This problem seems to be somewhat common, I've found several variations of similar problems over a couple of years, some more specific to the <a href=""https://stackoverflow.com/questions/64085348/unity-ml-agents-package-manager-is-not-importing-actuator-script"">Actuators</a> missing, some more <a href=""https://github.com/Unity-Technologies/ml-agents/issues/3027"" rel=""nofollow noreferrer"">general</a>. Some are posting about <a href=""https://forum.unity.com/threads/cannot-find-unityengine-inputsystem.807645/"" rel=""nofollow noreferrer"">problems with the InputSystem</a> as well, but seemingly different solutions and mixed reactions to the solutions.</p>
<p>There are various suggestions, about version changes for Unity, the ml-agents package, and Visual Studio Code. Other solutions involve downloading additional packages in Visual Studio or Unity. Some suggest editing scripts within the cloned git repository. Although most of these threads are from the past 2 years. I've spent two days trying to set this up and fix this and am just about to give up on the ml-agents package. A shame the installation process for a seemingly great resource seems so infeasible. I'd appreciate further suggestions or directions on additional resources on how to set up this package.</p>
",144,1,2,4,python;c#;unity3d;ml-agent,2022-05-27 23:02:29,2022-05-27 23:02:29,2022-07-11 22:28:00,i m trying to work with  and encountered problems during the setup  when i try to import the assets from  into unity  i get many warnings and errors inside unity  for the purpose of context  i m at the very beginning of learning unity  so i don t know if the errors are due to the ml agents package or user error from my side in how to set everything up  instructions to create a first test scene with assets from unity s ml agents git suggest making a new d project in unity and drag and drop the folder projects assets ml agents into the project s assets  at this point  unity is showing many errors and warnings in the terminal  it still has the examples in the assets but every element in the scene is full of warnings  in my case the majority of the warnings seem to come from pushblockwithinput  pushblockactions and pushblockwithinputplayercontroller missing unityengine inputsystem and unity mlagents extensions input with the note   are you missing a using directive or an assembly reference     this  however  did not happen in the aforementioned tutorials  although they make the majority of errors  they are not exclusively about assembly references  other errors  which may or may not be about assembly references  are  i ve followed the  from unity s ml agents git and was successful in installing a python   environment with anaconda  pytorch with cuda  and the unity s ml agents python package via pip  when trying to verify the ml agents python package works with mlagents learn   help  i first got an exception but could resolve that by updating protobuf     as per   just mentioning this in case it is relevant   i downloaded the c  package from unity s package manager and tried it for several versions      verified       preview       and     preview     lastest   after which i m able to select ml agents from the  add component  menu in the inspector  i ve also tried to create a new unity project with the ml agent package     preview  with the right barracuda version  and the release  branch of unity s ml agents git  without success  now it s  warnings and  errors   now also the actuators are not found  which seems to be a more common problem on its own  i have also switched from unity s ml agents git s main branch to the  and also tried other versions of the barracuda package  e g  version     which seems to remove the warnings  but not the errors and instead gives these notifications   however  warnings still show up in the assets  settings   i successfully completed the   this course doesn t use any of the assets from the ml agents git repository  although  assets for this course are downloaded and added the same way  without issues  this lets me assume that the general setup for ml agents is working but i specifically can t import the assets  this problem seems to be somewhat common  i ve found several variations of similar problems over a couple of years  some more specific to the  missing  some more   some are posting about  as well  but seemingly different solutions and mixed reactions to the solutions  there are various suggestions  about version changes for unity  the ml agents package  and visual studio code  other solutions involve downloading additional packages in visual studio or unity  some suggest editing scripts within the cloned git repository  although most of these threads are from the past  years  i ve spent two days trying to set this up and fix this and am just about to give up on the ml agents package  a shame the installation process for a seemingly great resource seems so infeasible  i d appreciate further suggestions or directions on additional resources on how to set up this package ,unity   s ml agents assets throw warnings and errors  pushblockwithinput  actuator  barracuda 
33,33,345660,7044808,"Using R to download gzipped data file, extract, and import data","<p>A follow up to <a href=""https://stackoverflow.com/questions/3053833/using-r-to-download-zipped-data-file-extract-and-import-data"">this question</a>: How can I download and uncompress a gzipped file using R?  For example (from <a href=""http://archive.ics.uci.edu/ml/datasets"" rel=""noreferrer"">the UCI Machine Learning Repository</a>), I have a <a href=""http://archive.ics.uci.edu/ml/datasets/Insurance+Company+Benchmark+%28COIL+2000%29"" rel=""noreferrer"">file of insurance data</a>.  How can I download it using R?</p>

<p>Here is the data url: <code>http://archive.ics.uci.edu/ml/databases/tic/tic.tar.gz</code>.</p>
",8730,4,11,3,r;zip;connection,2011-08-13 00:10:45,2011-08-13 00:10:45,2022-07-11 21:36:21,a follow up to   how can i download and uncompress a gzipped file using r   for example  from    i have a    how can i download it using r  here is the data url  http   archive ics uci edu ml databases tic tic tar gz ,using r to download gzipped data file  extract  and import data
34,34,14415252,72938511,Detect a logo and compare it with original logo with percentage of matching,"<p>I need to make a machine learning model which will detect if a particular image contains the logo, and if it contains the logo then up to what percentage it matches with the original logo.</p>
<ol>
<li>Which libraries should I use?</li>
<li>Which algorithms do I need to learn?</li>
<li>Which algorithms and libraries will be quicker to learn for this
purpose?</li>
</ol>
",38,1,-4,5,python;tensorflow;machine-learning;image-processing;deep-learning,2022-07-11 17:51:37,2022-07-11 17:51:37,2022-07-11 20:21:51,i need to make a machine learning model which will detect if a particular image contains the logo  and if it contains the logo then up to what percentage it matches with the original logo ,detect a logo and compare it with original logo with percentage of matching
35,35,17957100,72938442,How do I return all pages from a rest API request without manually specifying the page number?,"<p>I'm retrieving data from a paginated API and converting it to .JSON format and I'd like to retrieve all pages in the response, without having to specify the page number in the URL. The API accepts page number and results per page (max. 250) as inputs.</p>
<p>I understand that the typical solution is to loop through pages using a key that specifies the address of the next page. However, it appears as though this API doesn't include a next page parameter in the output (see example response below). I can only think that the last page (i.e. total pages) parameter could be useful here? How can I scrape all of the pages without specifying the page number?</p>
<p><strong>My script:</strong></p>
<pre><code>  import requests
  import json

  url = &quot;https://api-v2.pitchbook.com/deals/search?keywords=machine learning accelerator&amp;perPage=250&quot;

  payload={}
  headers = {
      'Authorization': 'PB-Token 1234567'
   }

  response = requests.request(&quot;GET&quot;, url, headers=headers, data=payload)

  data = response.json()

  print(data)                                                                                                                                                                                 
</code></pre>
<p><strong>Example response</strong></p>
<p>{'stats': {'total': 2, 'perPage': 250, 'page': 1, 'lastPage': 1}, 'items': [{'dealId': '98982-
28T', 'companyId': '162120-79', 'companyName': 'companyA'}, {'dealId': '112532-05T',
'companyId': '233527-87', 'companyName': 'companyB'}]}</p>
",27,1,0,5,python;json;loops;rest;pagination,2022-07-11 17:46:07,2022-07-11 17:46:07,2022-07-11 19:05:55,i m retrieving data from a paginated api and converting it to  json format and i d like to retrieve all pages in the response  without having to specify the page number in the url  the api accepts page number and results per page  max    as inputs  i understand that the typical solution is to loop through pages using a key that specifies the address of the next page  however  it appears as though this api doesn t include a next page parameter in the output  see example response below   i can only think that the last page  i e  total pages  parameter could be useful here  how can i scrape all of the pages without specifying the page number  my script  example response,how do i return all pages from a rest api request without manually specifying the page number 
36,36,19436129,72939406,SQL Server Vector Index,"<p>I would like to create a vector index for a database table in SQL Server. In my case, I have 256-dimensional vectors (numerical representations of the text contents of each row, derived from some NLP methods). However, SQL Server unfortunately does not seem to include array functionality (numerical vector data type).</p>
<p>Some potential solutions are offered here: <a href=""https://www.sqlshack.com/implement-array-like-functionality-sql-server/"" rel=""nofollow noreferrer"">https://www.sqlshack.com/implement-array-like-functionality-sql-server/</a>. For instance, I could create a table with one column for each entry of the vector. Is there a more elegant (performant) way?</p>
<hr />
<p>Background: I am implementing a semantic search feature for my database using MS Machine Learning Services (Python), that is, I want to be able to compare vector representations of query texts to the index (using cosine similarity). I know that there is also a full-text search feature for SQL server. Currently, I do not use it because it provides too little control over the pre-processing of the rather messy text fields in my database.</p>
",27,0,0,4,sql-server;python-3.x;indexing;full-text-search,2022-07-11 19:01:21,2022-07-11 19:01:21,2022-07-11 19:01:21,i would like to create a vector index for a database table in sql server  in my case  i have  dimensional vectors  numerical representations of the text contents of each row  derived from some nlp methods   however  sql server unfortunately does not seem to include array functionality  numerical vector data type   some potential solutions are offered here    for instance  i could create a table with one column for each entry of the vector  is there a more elegant  performant  way  background  i am implementing a semantic search feature for my database using ms machine learning services  python   that is  i want to be able to compare vector representations of query texts to the index  using cosine similarity   i know that there is also a full text search feature for sql server  currently  i do not use it because it provides too little control over the pre processing of the rather messy text fields in my database ,sql server vector index
37,37,17668281,72938908,MS Azure Machine Learning - Notebook extremely slow in comparison to GC,"<p>I work with a jupyter notebook on different platforms.</p>
<p>The notebook includes a detectron2 algorithm.</p>
<p>The runtime for the training process on different platforms differs significantl (Same Code, Same parameters, same data)</p>
<p><strong>Google Colab</strong></p>
<ul>
<li>K80 GPU (Successfully used while training)</li>
<li>Data stored on Google Drive</li>
<li>Torch: 1.9.0+cu111</li>
<li><strong>Runtime: 4,5h</strong></li>
</ul>
<hr />
<p><strong>Microsoft Azure - Machine Learning</strong></p>
<ul>
<li>K80 GPU (Successfully used while training)</li>
<li>STANDARD_NC6</li>
<li>Data stored an Azure Files</li>
<li>Torch: 1.9.0+cu111</li>
<li><strong>Runtime: 15h</strong></li>
</ul>
<p>Why is the expensive Azure ML three times slower than free Google Colab and is there a possibility to improve that?</p>
",15,0,0,5,azure;deep-learning;jupyter-notebook;google-colaboratory;object-detection,2022-07-11 18:21:35,2022-07-11 18:21:35,2022-07-11 18:21:35,i work with a jupyter notebook on different platforms  the notebook includes a detectron algorithm  the runtime for the training process on different platforms differs significantl  same code  same parameters  same data  google colab microsoft azure   machine learning why is the expensive azure ml three times slower than free google colab and is there a possibility to improve that ,ms azure machine learning   notebook extremely slow in comparison to gc
38,38,6151951,72911756,GCP Pipeline for ML Images in Cloud Storage,"<p>I am setting up a Machine Learning training instance on the GKE. My images live in Cloud Storage. How can I access those images without first downloading them onto the GKE? They are considered private (medical data), and so I do not want to risk them being exposed by transferring them to a GKE instance first.</p>
<p>Is there a recommended way to do this?</p>
",34,0,-1,3,machine-learning;google-cloud-storage;google-kubernetes-engine,2022-07-08 18:25:28,2022-07-08 18:25:28,2022-07-11 17:30:20,i am setting up a machine learning training instance on the gke  my images live in cloud storage  how can i access those images without first downloading them onto the gke  they are considered private  medical data   and so i do not want to risk them being exposed by transferring them to a gke instance first  is there a recommended way to do this ,gcp pipeline for ml images in cloud storage
39,39,11143347,72935277,upload a pre-trained model locally into databricks,"<p>Is it possible to upload a pre-trained machine learning model that was trained on a different environment on databricks, and serve it? Or is it impossible on Databricks ?</p>
",38,1,0,3,machine-learning;databricks;mlflow,2022-07-11 13:20:31,2022-07-11 13:20:31,2022-07-11 17:28:05,is it possible to upload a pre trained machine learning model that was trained on a different environment on databricks  and serve it  or is it impossible on databricks  ,upload a pre trained model locally into databricks
40,40,8614508,72937870,"The method is not allowed for the requested URL - flask, model deployment","<p>I was trying to build a web application for my machine learning model deployment.</p>
<p>First I was testing the connection using the below code:</p>
<pre><code>import pickle  ## read .bin file
from distutils.log import debug
from pyexpat import model
from urllib import response
from flask import Flask, request, jsonify
from model_file.ml_model import predict_mpg

app = Flask(&quot;mpg_prediction&quot;)

@app.route('/', methods=['GET'])  ## test if the app is working
def ping():
    return &quot;Pinging Model Application!!&quot;
</code></pre>
<p>The above worked fine when I went to the server and the web app reads <code>Pinging Model Application!!</code></p>
<p>The problem was when I tried to &quot;fit&quot; my machine learning model to the app. I've pickled my trained model into the model.bin file and I used the below codes:</p>
<pre><code>@app.route('/', methods=['POST'])
def predict():
    vehicle_config = request.get_json()

    with open('./model_file/model.bin', 'rb') as f_in:
        model = pickle.load(f_in)
        f_in.close()

        predictions = predict_mpg(vehicle_config, model)

        response = {
            'mpg_predictions': list(predictions)
        }
        return jsonify()
</code></pre>
<p>After I ran the above codes, and tested the web app, I came across the error message:
<code>The method is not allowed for the requested URL</code></p>
<p>This is my first time using Flask, so I've no idea what went wrong.</p>
<p>I'd appreciate any help on this. Thanks in advance.</p>
",23,0,-1,4,python;flask;deployment;pickle,2022-07-11 17:00:42,2022-07-11 17:00:42,2022-07-11 17:00:42,i was trying to build a web application for my machine learning model deployment  first i was testing the connection using the below code  the above worked fine when i went to the server and the web app reads pinging model application   the problem was when i tried to  fit  my machine learning model to the app  i ve pickled my trained model into the model bin file and i used the below codes  this is my first time using flask  so i ve no idea what went wrong  i d appreciate any help on this  thanks in advance ,the method is not allowed for the requested url   flask  model deployment
41,41,11619848,72936419,Getting error 404 in azure machine learning service,"<p>I am new to the cloud and i've been trying to follow a tutorial. I am trying to create a simple pipeline and understand how the <strong>Execute python script</strong> component works. So far this is what i'm trying to execute.</p>
<p><a href=""https://i.stack.imgur.com/Kkn9z.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Kkn9z.png"" alt=""Pipeline structure"" /></a></p>
<p>This is the code i have within the execute block:</p>
<pre><code>import pandas as pd

def azureml_main(dataframe1 = None, dataframe2 = None):
    dataframe1['Dollar/HP'] = dataframe1.price / dataframe1.horsepower
    return dataframe1
</code></pre>
<p>No matter what i try i get the same error and i can't find anything about it on the internet.</p>
<p><strong>Job preparation failed: HTTP Error 404: Unable to find snapshot with id: ...</strong></p>
",14,0,0,1,azure-pipelines,2022-07-11 15:04:48,2022-07-11 15:04:48,2022-07-11 15:04:48,i am new to the cloud and i ve been trying to follow a tutorial  i am trying to create a simple pipeline and understand how the execute python script component works  so far this is what i m trying to execute   this is the code i have within the execute block  no matter what i try i get the same error and i can t find anything about it on the internet  job preparation failed  http error   unable to find snapshot with id     ,getting error  in azure machine learning service
42,42,1361737,72927724,Why do I get &#39;c50 code called exit with value 1&#39; in R?,"<p>I am using RStudio 2021.09.0 &quot;Ghost Orchid&quot; Release for macOS.</p>
<p>I am learning to use to C5.0 algorithm in R. For this I am following <em>'Machine Learning in R'</em> by Brett Lantz. The dataset I am using is a modified version of one relating to loans obtained from a credit agency in Germany.</p>
<p>The data has no missing values, and no empty factor levels (this has caused the same error in other posts I have viewed). I have split the data into training and test tibbles using the <code>initial_split()</code> function in <code>rsample</code> package. The structure of the data is:</p>
<pre><code>str(credit_train)

tibble [900 × 21] (S3: tbl_df/tbl/data.frame)
 $ checking_balance    : Factor w/ 4 levels &quot;&lt; 0 DM&quot;,&quot;&gt; 200 DM&quot;,..: 4 1 4 3 3 4 3 4 1 1 ...
 $ months_loan_duration: Factor w/ 33 levels &quot;4&quot;,&quot;5&quot;,&quot;6&quot;,&quot;7&quot;,..: 18 22 18 16 30 18 9 9 14 9 ...
 $ credit_history      : Factor w/ 5 levels &quot;critical&quot;,&quot;delayed&quot;,..: 1 1 1 5 4 2 5 5 5 5 ...
 $ purpose             : Factor w/ 10 levels &quot;business&quot;,&quot;car (new)&quot;,..: 8 3 3 1 1 1 8 1 2 2 ...
 $ amount              : num [1:900] 2611 6187 2197 2767 6416 ...
 $ savings_balance     : Factor w/ 5 levels &quot;&lt; 100 DM&quot;,&quot;&gt; 1000 DM&quot;,..: 1 3 5 3 1 1 1 1 3 1 ...
 $ employment_length   : Factor w/ 5 levels &quot;&gt; 7 yrs&quot;,&quot;0 - 1 yrs&quot;,..: 1 4 4 1 1 3 1 4 4 3 ...
 $ installment_rate    : Factor w/ 4 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;: 4 1 4 4 4 1 3 2 4 4 ...
 $ personal_status     : Factor w/ 4 levels &quot;divorced male&quot;,..: 3 3 4 1 2 4 3 4 4 2 ...
 $ other_debtors       : Factor w/ 3 levels &quot;co-applicant&quot;,..: 1 3 3 3 3 3 2 3 3 2 ...
 $ residence_history   : Factor w/ 4 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;: 3 4 4 2 3 2 3 4 3 4 ...
 $ property            : Factor w/ 4 levels &quot;building society savings&quot;,..: 3 2 2 2 4 4 3 2 2 1 ...
 $ age                 : num [1:900] 46 24 43 61 59 32 40 36 30 29 ...
 $ installment_plan    : Factor w/ 3 levels &quot;bank&quot;,&quot;none&quot;,..: 2 2 2 1 2 2 1 2 2 2 ...
 $ housing             : Factor w/ 3 levels &quot;for free&quot;,&quot;own&quot;,..: 2 3 2 3 3 1 2 2 2 2 ...
 $ existing_credits    : Factor w/ 4 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;: 2 2 2 2 1 1 2 1 1 1 ...
 $ default             : Factor w/ 2 levels &quot;paid&quot;,&quot;default&quot;: 1 1 1 2 2 1 1 1 1 1 ...
 $ dependents          : Factor w/ 2 levels &quot;1&quot;,&quot;2&quot;: 1 1 2 1 1 1 1 1 2 1 ...
 $ telephone           : Factor w/ 2 levels &quot;none&quot;,&quot;yes&quot;: 1 1 2 1 1 1 1 2 2 2 ...
 $ foreign_worker      : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 2 2 2 2 2 2 2 2 2 2 ...
 $ job                 : Factor w/ 4 levels &quot;management self-employed&quot;,..: 2 2 2 4 2 2 4 2 1 2 ...

</code></pre>
<p>My issue is specifically when I try to fit a model using a cost matrix. Without this cost matrix, the model does <strong>not</strong> throw this error. This is how I have created the cost matrix:</p>
<pre><code>error_cost &lt;- matrix(nrow = 2, 
                     ncol = 2,
                     dimnames = list(c('predict_paid','predict_default'), #rows
                                     c('actual_paid','actual_default')), #columns
                     data = c(0, 1, 4, 0))  
</code></pre>
<p>I must also point out that I have tried several ways to create this matrix, including literally copying the exact method given in the Lantz book, and they all result in this same error.</p>
<p>Here is the code I am using to try and fit the model.</p>
<pre><code>c5_boostTree &lt;- C5.0(default ~.,
                     credit_train,
                     trials = 3,
                     costs = error_cost)
</code></pre>
<p>However, this also happens if I use the <code>x = credit_train %&gt;% select(-default), y = credit_train$default</code> rather than the formula approach, and any similar approaches I can find or think of. I am at a complete loss as to why I am getting this error.</p>
<pre><code>c50 code called exit with value 1
</code></pre>
<p>Anyone have any ideas???</p>
<p>====================================</p>
<p>In response to a request for <code>dput(credit_train</code>, here is the output for dput(head(credit_train)), it seems too large otherwise:</p>
<pre><code>structure(list(checking_balance = structure(c(4L, 1L, 4L, 3L, 
3L, 4L), .Label = c(&quot;&lt; 0 DM&quot;, &quot;&gt; 200 DM&quot;, &quot;1 - 200 DM&quot;, &quot;unknown&quot;
), class = &quot;factor&quot;), months_loan_duration = structure(c(18L, 
22L, 18L, 16L, 30L, 18L), .Label = c(&quot;4&quot;, &quot;5&quot;, &quot;6&quot;, &quot;7&quot;, &quot;8&quot;, 
&quot;9&quot;, &quot;10&quot;, &quot;11&quot;, &quot;12&quot;, &quot;13&quot;, &quot;14&quot;, &quot;15&quot;, &quot;16&quot;, &quot;18&quot;, &quot;20&quot;, &quot;21&quot;, 
&quot;22&quot;, &quot;24&quot;, &quot;26&quot;, &quot;27&quot;, &quot;28&quot;, &quot;30&quot;, &quot;33&quot;, &quot;36&quot;, &quot;39&quot;, &quot;40&quot;, &quot;42&quot;, 
&quot;45&quot;, &quot;47&quot;, &quot;48&quot;, &quot;54&quot;, &quot;60&quot;, &quot;72&quot;), class = &quot;factor&quot;), credit_history = structure(c(1L, 
1L, 1L, 5L, 4L, 2L), .Label = c(&quot;critical&quot;, &quot;delayed&quot;, &quot;fully repaid&quot;, 
&quot;fully repaid this bank&quot;, &quot;repaid&quot;), class = &quot;factor&quot;), purpose = structure(c(8L, 
3L, 3L, 1L, 1L, 1L), .Label = c(&quot;business&quot;, &quot;car (new)&quot;, &quot;car (used)&quot;, 
&quot;domestic appliances&quot;, &quot;education&quot;, &quot;furniture&quot;, &quot;others&quot;, &quot;radio/tv&quot;, 
&quot;repairs&quot;, &quot;retraining&quot;), class = &quot;factor&quot;), amount = c(2611, 
6187, 2197, 2767, 6416, 3863), savings_balance = structure(c(1L, 
3L, 5L, 3L, 1L, 1L), .Label = c(&quot;&lt; 100 DM&quot;, &quot;&gt; 1000 DM&quot;, &quot;101 - 500 DM&quot;, 
&quot;501 - 1000 DM&quot;, &quot;unknown&quot;), class = &quot;factor&quot;), employment_length = structure(c(1L, 
4L, 4L, 1L, 1L, 3L), .Label = c(&quot;&gt; 7 yrs&quot;, &quot;0 - 1 yrs&quot;, &quot;1 - 4 yrs&quot;, 
&quot;4 - 7 yrs&quot;, &quot;unemployed&quot;), class = &quot;factor&quot;), installment_rate = structure(c(4L, 
1L, 4L, 4L, 4L, 1L), .Label = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;), class = &quot;factor&quot;), 
    personal_status = structure(c(3L, 3L, 4L, 1L, 2L, 4L), .Label = c(&quot;divorced male&quot;, 
    &quot;female&quot;, &quot;married male&quot;, &quot;single male&quot;), class = &quot;factor&quot;), 
    other_debtors = structure(c(1L, 3L, 3L, 3L, 3L, 3L), .Label = c(&quot;co-applicant&quot;, 
    &quot;guarantor&quot;, &quot;none&quot;), class = &quot;factor&quot;), residence_history = structure(c(3L, 
    4L, 4L, 2L, 3L, 2L), .Label = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;), class = &quot;factor&quot;), 
    property = structure(c(3L, 2L, 2L, 2L, 4L, 4L), .Label = c(&quot;building society savings&quot;, 
    &quot;other&quot;, &quot;real estate&quot;, &quot;unknown/none&quot;), class = &quot;factor&quot;), 
    age = c(46, 24, 43, 61, 59, 32), installment_plan = structure(c(2L, 
    2L, 2L, 1L, 2L, 2L), .Label = c(&quot;bank&quot;, &quot;none&quot;, &quot;stores&quot;), class = &quot;factor&quot;), 
    housing = structure(c(2L, 3L, 2L, 3L, 3L, 1L), .Label = c(&quot;for free&quot;, 
    &quot;own&quot;, &quot;rent&quot;), class = &quot;factor&quot;), existing_credits = structure(c(2L, 
    2L, 2L, 2L, 1L, 1L), .Label = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;), class = &quot;factor&quot;), 
    default = structure(c(1L, 1L, 1L, 2L, 2L, 1L), .Label = c(&quot;paid&quot;, 
    &quot;default&quot;), class = &quot;factor&quot;), dependents = structure(c(1L, 
    1L, 2L, 1L, 1L, 1L), .Label = c(&quot;1&quot;, &quot;2&quot;), class = &quot;factor&quot;), 
    telephone = structure(c(1L, 1L, 2L, 1L, 1L, 1L), .Label = c(&quot;none&quot;, 
    &quot;yes&quot;), class = &quot;factor&quot;), foreign_worker = structure(c(2L, 
    2L, 2L, 2L, 2L, 2L), .Label = c(&quot;no&quot;, &quot;yes&quot;), class = &quot;factor&quot;), 
    job = structure(c(2L, 2L, 2L, 4L, 2L, 2L), .Label = c(&quot;management self-employed&quot;, 
    &quot;skilled employee&quot;, &quot;unemployed non-resident&quot;, &quot;unskilled resident&quot;
    ), class = &quot;factor&quot;)), row.names = c(NA, -6L), class = c(&quot;tbl_df&quot;, 
&quot;tbl&quot;, &quot;data.frame&quot;))
</code></pre>
",41,1,0,4,r;machine-learning;classification;c5.0,2022-07-10 15:47:02,2022-07-10 15:47:02,2022-07-11 14:34:35,i am using rstudio     ghost orchid  release for macos  i am learning to use to c  algorithm in r  for this i am following  machine learning in r  by brett lantz  the dataset i am using is a modified version of one relating to loans obtained from a credit agency in germany  the data has no missing values  and no empty factor levels  this has caused the same error in other posts i have viewed   i have split the data into training and test tibbles using the initial_split   function in rsample package  the structure of the data is  my issue is specifically when i try to fit a model using a cost matrix  without this cost matrix  the model does not throw this error  this is how i have created the cost matrix  i must also point out that i have tried several ways to create this matrix  including literally copying the exact method given in the lantz book  and they all result in this same error  here is the code i am using to try and fit the model  however  this also happens if i use the x   credit_train   gt   select  default   y   credit_train default rather than the formula approach  and any similar approaches i can find or think of  i am at a complete loss as to why i am getting this error  anyone have any ideas                                         in response to a request for dput credit_train  here is the output for dput head credit_train    it seems too large otherwise ,why do i get    c code called exit with value     in r 
43,43,614157,31610971,Spark - repartition() vs coalesce(),"<p>According to Learning Spark</p>

<blockquote>
  <p>Keep in mind that repartitioning your data is a fairly expensive operation.
  Spark also has an optimized version of <code>repartition()</code> called <code>coalesce()</code> that allows avoiding data movement, but only if you are decreasing the number of RDD partitions.</p>
</blockquote>

<p>One difference I get is that with <code>repartition()</code> the number of partitions can be increased/decreased, but with <code>coalesce()</code> the number of partitions can only be decreased.</p>

<p>If the partitions are spread across multiple machines and <code>coalesce()</code> is run, how can it avoid data movement?</p>
",324094,20,373,3,apache-spark;distributed-computing;rdd,2015-07-24 18:19:19,2015-07-24 18:19:19,2022-07-11 11:53:03,according to learning spark one difference i get is that with repartition   the number of partitions can be increased decreased  but with coalesce   the number of partitions can only be decreased  if the partitions are spread across multiple machines and coalesce   is run  how can it avoid data movement ,spark   repartition   vs coalesce  
44,44,19523154,72932792,what is difference between computer vision and NLP? in detail,"<p>what is difference between computer vision and NLP? in detail</p>
<p>Deep learning neural networks have recently have shown very powerful improvements in tasks in computer vision and NLP compared to some other machine learning methods that have been popular for longer.</p>
<p>Deep learning neural networks have recently have shown very powerful improvements in tasks in computer vision and NLP compared to some other machine learning methods that have been popular for longer.</p>
",21,0,-3,4,python;nlp;computer-vision;artificial-intelligence,2022-07-11 06:11:46,2022-07-11 06:11:46,2022-07-11 11:21:45,what is difference between computer vision and nlp  in detail deep learning neural networks have recently have shown very powerful improvements in tasks in computer vision and nlp compared to some other machine learning methods that have been popular for longer  deep learning neural networks have recently have shown very powerful improvements in tasks in computer vision and nlp compared to some other machine learning methods that have been popular for longer ,what is difference between computer vision and nlp  in detail
45,45,19475312,72933382,Need help understanding this constructor exercise,"<p>I am learning constructors, Im trying to work through this exercise. I am trying to follow these instructions. But I cant get the entire program to work.
I am using instanceof to verify the coin object. I am wondering if there is another way to do this. I hope the instructions are clear enough.</p>
<p>COIN OBJECT:
Should have 1 property and 2 methods.
Properties:
State - this should be 1 or a 0  heads(1) or tails (0)
Methods:
flip() - This should randomly assign a 0 or a 1 to the state property
toString()Based upon the state, this should return the string &quot;heads&quot; or &quot;tails&quot;</p>
<p>CHICKEN COOP OBJECT:
secod constructor function, create an chicken coop object
the chicken coop should have one parameter ti the Coop functionm numChickens
Coop needs one property and one method
Properties:
numChickens - the total number of chickens.
Methods:
gatherEggs() - return a random number 1-3 x numChickens
Add the chicken coop properties and methods here</p>
<p>CHICKEN FEED VENDING MACHINE:
Two properties and one method
Properties:
food - The amount of food in the vending machine. This should start at 12.
numCoins - number of coins put into the machine. This should start at 0.
Methods:
dispence(coin) - dispense 5 feed for every coin passed to the method. The coin parameter, should be a coin object from the Coin constuctor above. If coin is valid AND there is 5 food AND
add +1 numCoins. Return the number 5 or the remaining food in the machine. If food is 0 return 0</p>
<pre><code>/** 1. Coin Constructor

 * Fill in the properties and methods inside of the coin function */

    const Coin = function()  {
        state: 0,
        flip: function () {
            this.state = Math.floor(Math.random() * 2) == 0 ? &quot;tails&quot; : &quot;heads&quot;;
        },
        toString: function () {
            if (this.state === 0) {
                sides = &quot;heads&quot;;
            } else if (this.state === 1) {
                sides = &quot;tails&quot;;
            }
            return sides;
        },
    };



/** 2. Chicken Coop Constructor,
 * fill in the properties and methods inside of the Coop function */
    
    const Coop = function (numChickens) {
        this.numChickens = numChickens;
        this.gatherEggs = function () {
            return Math.floor(Math.random() * 3 + 1) * numChickens;
        };
    };


    
    /** 3. Feed Vending Machine Constructor,
     * fill in the properties and methods inside of the FeedMachine function */
    
    const FeedMachine = function () {
    //Add the feed vending machine properties and methods here
        this.food = 12;
        this.numCoins = 0;
        this.dispense = function (coin) {
            if (coin instanceof Coin &amp;&amp; this.food &gt; 5) {
                this.food -= 5;
                this.numCoins += 1;
                return 5;
            } else if (!Coin) {
                return 0;
            }
            if (this.food === 0) {
                return 0;
            } else if (this.food &lt; 5) {
                this.numCoins++;
                const restOfFood = this.food;
                this.food -= this.food;
                return restOfFood;
            }
        };
    };



    export { Coin, Coop, FeedMachine };
</code></pre>
",42,0,0,3,javascript;constructor;state,2022-07-11 08:52:43,2022-07-11 08:52:43,2022-07-11 09:22:13,,need help understanding this constructor exercise
46,46,14837550,65324610,Python Machine Learning - Rule based match,"<p>I am new to machine learning and need help on the best approach.</p>
<p>I have a master dataset with millions of rows with columns:</p>
<pre><code>Customer first name, 
last name, 
SSN , 
address,
Unique cust id 
</code></pre>
<p>Input is a new customer details with same columns.I want to create a machine learning model with following rules</p>
<pre><code>If new customer matches any customer on SSN then return cust ids of
    matching customers  
else if customer matches any customer on First +
    Last name + zip then return cust ids of matching customers  
else
    create new cust id
</code></pre>
<p>The other issue is that name and address could have spelling errors, so exact match is not an option</p>
<p>what is the best approach and what model will work</p>
",137,1,0,2,python;match,2020-12-16 19:21:58,2020-12-16 19:21:58,2022-07-11 09:05:43,i am new to machine learning and need help on the best approach  i have a master dataset with millions of rows with columns  input is a new customer details with same columns i want to create a machine learning model with following rules the other issue is that name and address could have spelling errors  so exact match is not an option what is the best approach and what model will work,python machine learning   rule based match
47,47,9744542,72932518,How to deal with a skewed Time series data,"<p>I have hourly data of no. of minutes spent online by people for 2 years. Hence the values are distributed between 0 and 60 and also most data is either 0 or 60. My goal is to predict the number of minutes the person will spend online in the future (next day/hour/month etc.). What kind of approach or machine learning model can I use to predict this data? Can this be modelled into a regression/forecasting problem in spite of the skewness?<a href=""https://i.stack.imgur.com/Vk93I.png"" rel=""nofollow noreferrer"">hourly data</a></p>
",21,1,-2,2,machine-learning;time-series,2022-07-11 04:59:36,2022-07-11 04:59:36,2022-07-11 06:52:05,i have hourly data of no  of minutes spent online by people for  years  hence the values are distributed between  and  and also most data is either  or   my goal is to predict the number of minutes the person will spend online in the future  next day hour month etc    what kind of approach or machine learning model can i use to predict this data  can this be modelled into a regression forecasting problem in spite of the skewness ,how to deal with a skewed time series data
48,48,14515155,72931509,Symbol not found error while importing tensorflow in M1 Macbook Pro,"<p>I have installed tensorflow in my M1 Macbook Pro using these commands in a conda environment:</p>
<pre><code>conda install -c apple tensorflow-deps
python -m pip install tensorflow-macos
python -m pip install tensorflow-metal
python -m pip install tensorflow-datasets
conda install jupyter pandas numpy matplotlib scikit-learn
</code></pre>
<p>I did it following this instruction - <a href=""https://github.com/mrdbourke/m1-machine-learning-test"" rel=""nofollow noreferrer"">https://github.com/mrdbourke/m1-machine-learning-test</a></p>
<p>But when I import the packages I installed it gives me an error message.</p>
<p>Here:</p>
<pre><code>import numpy as np
import pandas as pd
import sklearn
import tensorflow as tf
import matplotlib.pyplot as plt

# Check for TensorFlow GPU access
print(f&quot;TensorFlow has access to the following devices:\n{tf.config.list_physical_devices()}&quot;)

# See TensorFlow version
print(f&quot;TensorFlow version: {tf.__version__}&quot;)
</code></pre>
<p>Error:</p>
<pre><code>---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
Input In [1], in &lt;cell line: 4&gt;()
      2 import pandas as pd
      3 import sklearn
----&gt; 4 import tensorflow as tf
      5 import matplotlib.pyplot as plt
      7 # Check for TensorFlow GPU access

File ~/miniforge3/lib/python3.9/site-packages/tensorflow/__init__.py:443, in &lt;module&gt;
    441 _plugin_dir = _os.path.join(_s, 'tensorflow-plugins')
    442 if _os.path.exists(_plugin_dir):
--&gt; 443   _ll.load_library(_plugin_dir)
    444   # Load Pluggable Device Library
    445   _ll.load_pluggable_device_library(_plugin_dir)

File ~/miniforge3/lib/python3.9/site-packages/tensorflow/python/framework/load_library.py:151, in load_library(library_location)
    148     kernel_libraries = [library_location]
    150   for lib in kernel_libraries:
--&gt; 151     py_tf.TF_LoadLibrary(lib)
    153 else:
    154   raise OSError(
    155       errno.ENOENT,
    156       'The file or folder to load kernel libraries from does not exist.',
    157       library_location)

NotFoundError: dlopen(/Users/arannya/miniforge3/lib/python3.9/site-packages/tensorflow-plugins/libmetal_plugin.dylib, 6): Symbol not found: __ZNKSt3__115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEE3strEv
  Referenced from: /Users/arannya/miniforge3/lib/python3.9/site-packages/tensorflow-plugins/libmetal_plugin.dylib (which was built for Mac OS X 12.3)
  Expected in: /usr/lib/libc++.1.dylib
</code></pre>
<p>Please help me solve this issue. Thank you.</p>
",21,0,0,3,python;tensorflow;apple-m1,2022-07-11 01:29:45,2022-07-11 01:29:45,2022-07-11 01:29:45,i have installed tensorflow in my m macbook pro using these commands in a conda environment  i did it following this instruction    but when i import the packages i installed it gives me an error message  here  error  please help me solve this issue  thank you ,symbol not found error while importing tensorflow in m macbook pro
49,49,17573228,72930868,errors in the tutorial (Interpreting Machine Learning Models with the iml Package),"<p>I am getting the following error when trying to execute the following code in section entitled &quot;Replication requirements&quot; (<a href=""https://uc-r.github.io/iml-pkg"" rel=""nofollow noreferrer"">https://uc-r.github.io/iml-pkg</a>):</p>
<pre><code>#classification data
df &lt;- rsample::attrition %&gt;%
mutate_if(is.ordered, factor, ordered = FALSE) %&gt;%
mutate(Attrition = recode(Attrition, &quot;Yes&quot; = &quot;1&quot;, &quot;No&quot; = &quot;0&quot;) %&gt;% factor(levels = c(&quot;1&quot;, &quot;0&quot;)))

&gt; Error: 'attrition' is not an exported object from 'namespace:rsample'
</code></pre>
<p>The problem was solved using the following code:</p>
<pre><code>#data
library(modeldata)
data(&quot;attrition&quot;, package = &quot;modeldata&quot;)
#classification data
df &lt;- attrition %&gt;%
mutate_if(is.ordered, factor, ordered = FALSE) %&gt;%
mutate(Attrition = recode(Attrition, &quot;Yes&quot; = &quot;1&quot;, &quot;No&quot; = &quot;0&quot;) %&gt;% factor(levels = c(&quot;1&quot;, &quot;0&quot;)))
</code></pre>
<p>Unfortunately, I got another error after trying to execute the following code (section entitled &quot;Global interpretation/Feature importance&quot; (<a href=""https://uc-r.github.io/iml-pkg"" rel=""nofollow noreferrer"">https://uc-r.github.io/iml-pkg</a>):</p>
<pre><code>#compute feature importance with specified loss metric
imp.glm &lt;- FeatureImp$new(predictor.glm, loss = &quot;mse&quot;)
imp.rf &lt;- FeatureImp$new(predictor.rf, loss = &quot;mse&quot;)
imp.gbm &lt;- FeatureImp$new(predictor.gbm, loss = &quot;mse&quot;)

&gt; Error in [.data.frame(prediction, , self$class, drop = FALSE) : undefined columns selected

&gt; Error in [.data.frame(prediction, , self$class, drop = FALSE) : undefined columns selected

&gt; Error in [.data.frame(prediction, , self$class, drop = FALSE) : undefined columns selected
</code></pre>
<p>I use R 4.2.0/ Win10</p>
",19,0,0,2,r;iml,2022-07-10 23:51:37,2022-07-10 23:51:37,2022-07-10 23:51:37,i am getting the following error when trying to execute the following code in section entitled  replication requirements      the problem was solved using the following code  unfortunately  i got another error after trying to execute the following code  section entitled  global interpretation feature importance      i use r     win,errors in the tutorial  interpreting machine learning models with the iml package 
50,50,13605647,72929325,nginx: [emerg] invalid number of arguments in &quot;include&quot; directive,"<p>I am learning how to deploy AWS for the first time. I am following this guide here: <a href=""https://www.youtube.com/watch?v=HtWgb_vbyvY"" rel=""nofollow noreferrer"">https://www.youtube.com/watch?v=HtWgb_vbyvY</a>.</p>
<p>I am using windows machine while the person in the video uses mac.</p>
<p>I am getting the following error when running ngnix commands on the windows terminal: &quot;nginx: [emerg] CreateFile() &quot;C:/nginx-1.23.0/nginx-1.23.0/mime.types&quot; failed (3: The system cannot find the path specified) in C:\Users\Shi Jie\Downloads\nginx-1.23.0\nginx-1.23.0/conf/nginx.conf:12&quot;</p>
<p>i think it is how i write the path on my ngnix.conf which i write as such</p>
<pre><code>worker_processes  1;

error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;

events {
    worker_connections  1024;
}

http {
    include \Users\Shi Jie\Downloads\nginx-1.23.0\nginx-1.23.0\mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] &quot;$request&quot; '
                      '$status $body_bytes_sent &quot;$http_referer&quot; '
                      '&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;';

    access_log  /var/log/nginx/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    client_body_buffer_size 100k;
    client_header_buffer_size 1k;
    client_max_body_size 100k;
    large_client_header_buffers 2 1k;
    client_body_timeout 10;
    client_header_timeout 10;
    keepalive_timeout 5 5;
    send_timeout 10;
    server_tokens off;
    #gzip  on; on;

    include /etc/nginx/conf.d/*.conf;
}


</code></pre>
<p>Can anyone point the way to teach me how to write the path properly? Thank you.</p>
",18,1,0,2,amazon-web-services;amazon-ec2,2022-07-10 20:12:01,2022-07-10 20:12:01,2022-07-10 23:08:04,i am learning how to deploy aws for the first time  i am following this guide here    i am using windows machine while the person in the video uses mac  i am getting the following error when running ngnix commands on the windows terminal   nginx   emerg  createfile    c  nginx    nginx    mime types  failed    the system cannot find the path specified  in c  users shi jie downloads nginx    nginx    conf nginx conf   i think it is how i write the path on my ngnix conf which i write as such can anyone point the way to teach me how to write the path properly  thank you ,nginx   emerg  invalid number of arguments in  include  directive
51,51,16421594,72919440,I need guidance for first published Article/paper,"<p>I have a novel idea to use machine learning and object detection to distinguish between two similar skin diseases. I need guidance where to publish this article/paper.</p>
",40,0,-3,3,machine-learning;computer-vision;medical-imaging,2022-07-09 12:02:38,2022-07-09 12:02:38,2022-07-10 18:14:00,i have a novel idea to use machine learning and object detection to distinguish between two similar skin diseases  i need guidance where to publish this article paper ,i need guidance for first published article paper
52,52,19519627,72926799,How to use the rear camera instead of the front camera on a teachable machine,"
<br>




    // More API functions here:
    // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image
<pre><code>// the link to your model provided by Teachable Machine export panel
const URL = &quot;./my_model/&quot;;

let model, webcam, labelContainer, maxPredictions;

// Load the image model and setup the webcam
async function init() {
    const modelURL = URL + &quot;model.json&quot;;
    const metadataURL = URL + &quot;metadata.json&quot;;
   

    // load the model and metadata
    // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
    // or files from your local hard drive
    // Note: the pose library adds &quot;tmImage&quot; object to your window (window.tmImage)
    model = await tmImage.load(modelURL, metadataURL);
    maxPredictions = model.getTotalClasses();
    
    // Convenience function to setup a webcam

    const size = 350;
    const flip = true; // whether to flip the webcam
    webcam = new tmImage.Webcam(size, size, flip); // width, height, flip
    await webcam.setup(); // request access to the webcam
    await webcam.play();
    window.requestAnimationFrame(loop);

    // append elements to the DOM
    document.getElementById(&quot;webcam-container&quot;).appendChild(webcam.canvas);
    labelContainer = document.getElementById(&quot;label-container&quot;);
    for (let i = 0; i &lt; maxPredictions; i++) { // and class labels
        labelContainer.appendChild(document.createElement(&quot;div&quot;));
    }
}

async function loop() {
    webcam.update(); // update the webcam frame
    await predict();
    window.requestAnimationFrame(loop);
}
</code></pre>
<p>Currently, it is producing a program that can produce food-related information by filming food with a mobile phone rear camera using a learning machine.</p>
<p>I want to use the back camera in this part, but only the front camera keeps coming out. I'd appreciate it if you could help me :)</p>
",13,0,0,4,javascript;camera;webcam;teachable-machine,2022-07-10 12:51:46,2022-07-10 12:51:46,2022-07-10 12:51:46,currently  it is producing a program that can produce food related information by filming food with a mobile phone rear camera using a learning machine  i want to use the back camera in this part  but only the front camera keeps coming out  i d appreciate it if you could help me   ,how to use the rear camera instead of the front camera on a teachable machine
53,53,7723320,72926266,Best solution for visualising custom neural network data,"<p>I have essentially built my own machine learning framework from the ground up in c and c#. There are a number of reasons why I have chosen to do this. Mainly because I couldn't find any solutions for unsupervised learning that were suitable for my project needs. Please note I am fully aware of the pros and cons and challenges of creating my own machine learning framework. Furthermore, my framework is already functional at this point.</p>
<p>I am now looking to find ways to visualise the weights, biases, fitness etc. and other metrics while training my networks. Something similar to <a href=""https://www.tensorflow.org/tensorboard"" rel=""nofollow noreferrer"">Tensorboard</a> or <a href=""https://wandb.ai/site"" rel=""nofollow noreferrer"">Weights and Biases.</a> I figured my best option would be to somehow convert my neural network data into an existing ml format such as Keras models. I of course understand the exact file format of my neural network files however, it seems like it would be quite challenging to fully understand or find documentation on the format of a keras file and to convert my data like this.</p>
<p>To give you an idea of how I am currently capturing the weights and biases throughout training in my framework - At each epoch an 'NN' file (my custom file format) is created which holds all of the weight and bias values encoded as a series doubles. Each layers weight and bias values are stored consecutively in a single NN file. Each NN file also has a header containing extra info about the network.</p>
<p>I've also just started exploring other data visualisation tools such as this <a href=""https://observablehq.com"" rel=""nofollow noreferrer"">https://observablehq.com</a> . Which has got me quite excited as this seems like it may be the easiest to implement. However, I could potentially be missing out on all of the machine learning specific data analysis already built into solutions such as Tensorboard.</p>
<p>Any guidance or advice on what would be the best way to proceed with this would be much appreciated.</p>
",24,0,-2,5,tensorflow;machine-learning;keras;neural-network;data-analysis,2022-07-10 10:36:37,2022-07-10 10:36:37,2022-07-10 10:36:37,i have essentially built my own machine learning framework from the ground up in c and c   there are a number of reasons why i have chosen to do this  mainly because i couldn t find any solutions for unsupervised learning that were suitable for my project needs  please note i am fully aware of the pros and cons and challenges of creating my own machine learning framework  furthermore  my framework is already functional at this point  i am now looking to find ways to visualise the weights  biases  fitness etc  and other metrics while training my networks  something similar to  or  i figured my best option would be to somehow convert my neural network data into an existing ml format such as keras models  i of course understand the exact file format of my neural network files however  it seems like it would be quite challenging to fully understand or find documentation on the format of a keras file and to convert my data like this  to give you an idea of how i am currently capturing the weights and biases throughout training in my framework   at each epoch an  nn  file  my custom file format  is created which holds all of the weight and bias values encoded as a series doubles  each layers weight and bias values are stored consecutively in a single nn file  each nn file also has a header containing extra info about the network  i ve also just started exploring other data visualisation tools such as this    which has got me quite excited as this seems like it may be the easiest to implement  however  i could potentially be missing out on all of the machine learning specific data analysis already built into solutions such as tensorboard  any guidance or advice on what would be the best way to proceed with this would be much appreciated ,best solution for visualising custom neural network data
54,54,9721314,72924904,Stratified Sampling in Python without scikit-learn,"<p>I have a vector which contains 10 values of sample 1 and 25 values of sample 2.</p>
<pre><code>Fact = np.array((2,2,2,2,1,2,1,1,2,2,2,1,2,2,2,1,2,2,2,1,2,2,1,1,2,1,2,2,2,2,2,2,1,2,2))
</code></pre>
<p>I want to create a stratified output vector where :</p>
<p>sample 1 is divided in 80% : 8 values of 1 and 20% : 2 values of 0.</p>
<p>sample 2 is divided in 80% : 20 values of 1 and 20% : 5 values of 0.</p>
<p>The expected output will be :</p>
<pre><code>Output = np.array((0,1,1,1,0,1,1,1,1,0,1,1,1,0,1,1,1,0,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1))
</code></pre>
<p>How can I automate this ? I can’t use the sampling function from scikit-learn because it is not for a machine learning experience.</p>
",45,1,0,2,python;numpy,2022-07-10 03:35:59,2022-07-10 03:35:59,2022-07-10 07:17:43,i have a vector which contains  values of sample  and  values of sample   i want to create a stratified output vector where   sample  is divided in      values of  and      values of   sample  is divided in      values of  and      values of   the expected output will be   how can i automate this   i can t use the sampling function from scikit learn because it is not for a machine learning experience ,stratified sampling in python without scikit learn
55,55,19303916,72555192,How to generate passwords using PassGAN,"<p>Sorry if this question is very basic and simple, I'm a beginner at programming and especially machine learning.</p>
<p>I'm trying to evaluate the performance of the PassGAN AI by having it generate passwords, and then I compare them to a testing list that contains around a million passwords and see how many matches I get.</p>
<p>I have managed to train the algorithm, but I'm not sure how to get it to generate a password file with generated passwords.</p>
<p>Link to the GitHub source of PassGAN: <a href=""https://github.com/d4ichi/PassGAN"" rel=""nofollow noreferrer"">https://github.com/d4ichi/PassGAN</a>
<br/>
Training &amp; Testing file: <a href=""https://github.com/d4ichi/PassGAN/releases/download/data/rockyou-test.txt"" rel=""nofollow noreferrer"">https://github.com/d4ichi/PassGAN/releases/download/data/rockyou-test.txt</a></p>
<p>*Note: I did have to modify some of the code, and downgrade the TensorFlow version to get it to work.
<br/>
I simply replaced all:
<br/>
<code>import tensorflow as tf</code>
<br/>
with
<br/>
<code>import tensorflow.compat.v1 as tf</code>
<br/>
<code>tf.disable_v2_behavior()</code>
<br/>
in every .py file.</p>
<p>I'd really appreciate any help on this.</p>
",41,1,0,5,python;tensorflow;machine-learning;artificial-intelligence;generative-adversarial-network,2022-06-09 11:09:21,2022-06-09 11:09:21,2022-07-10 01:56:19,sorry if this question is very basic and simple  i m a beginner at programming and especially machine learning  i m trying to evaluate the performance of the passgan ai by having it generate passwords  and then i compare them to a testing list that contains around a million passwords and see how many matches i get  i have managed to train the algorithm  but i m not sure how to get it to generate a password file with generated passwords  i d really appreciate any help on this ,how to generate passwords using passgan
56,56,17169994,72924263,"IndexError: positional indexers are out-of-bounds, Machine Learning Classification","<p>I'm trying to do machine learning classification with a leave-one-out Cross-Validation. This is the first part of the code.</p>
<pre><code>listOfRows = []
dfModelPerf = pd.DataFrame(columns = ['threshold', 'c', 'class_weights', 'RFCacc', 'RFCsens', 'RFCspec', 'RFCprec', 'RFCFscore', 'RFCAUC-ROC'
                                    'SVMacc', 'SVMsens', 'SVMspec', 'SVMprec', 'SVMFscore', 'SVMAUC-ROC'])
thresholds = [0.75]
cs = [1]
class_weights = [{'Control':1, 'SCD':1}, #'MCI':1}, 
                {'Control':1.75, 'SCD':1.5}, #'MCI':1}, 
                {'Control':2, 'SCD':1.75} #'MCI':1}
                ]

#this is the loop used to iterate through param combintions
for threshold in thresholds:
    for c in cs:
        for class_weight in class_weights:
            row = {}
            svmAcc = []
            rfAcc = []
            X=dfClass
            y=df_classification.loc[df_classification['Diagnosis'].isin(['Control', 'SCD'])]
            loo = LeaveOneOut()
            loo.get_n_splits(dfClass)
            # let's count the selected features in a Counter
            featCount = Counter()
            # the LOOCV happens here with the selected parameter combination
            for train_index, test_index in loo.split(dfClass):
                X_train, X_test = X.iloc[train_index], X.iloc[test_index]
                y_train, y_test = y.iloc[train_index], y.iloc[test_index]
                pvalue = []
                x_control = X_train.loc[y_train=='Control', :].astype('float64', copy=False)
                x_scd = X_train.loc[y_train=='SCD', :].astype('float64', copy=False)
</code></pre>
<p>When I do this, I come across this error.</p>
<pre><code>IndexError                                Traceback (most recent call last)
~\anaconda3\lib\site-packages\pandas\core\indexing.py in _get_list_axis(self, key, axis)
   1529         try:
-&gt; 1530             return self.obj._take_with_is_copy(key, axis=axis)
   1531         except IndexError as err:

~\anaconda3\lib\site-packages\pandas\core\generic.py in _take_with_is_copy(self, indices, axis)
   3627         &quot;&quot;&quot;
-&gt; 3628         result = self.take(indices=indices, axis=axis)
   3629         # Maybe set copy if we didn't actually change the index.

~\anaconda3\lib\site-packages\pandas\core\generic.py in take(self, indices, axis, is_copy, **kwargs)
   3615         new_data = self._mgr.take(
-&gt; 3616             indices, axis=self._get_block_manager_axis(axis), verify=True
   3617         )

~\anaconda3\lib\site-packages\pandas\core\internals\managers.py in take(self, indexer, axis, verify)
    861         n = self.shape[axis]
--&gt; 862         indexer = maybe_convert_indices(indexer, n, verify=verify)
    863 

~\anaconda3\lib\site-packages\pandas\core\indexers.py in maybe_convert_indices(indices, n, verify)
    291         if mask.any():
--&gt; 292             raise IndexError(&quot;indices are out-of-bounds&quot;)
    293     return indices

IndexError: indices are out-of-bounds

The above exception was the direct cause of the following exception:

IndexError                                Traceback (most recent call last)
&lt;ipython-input-14-7df8494e8241&gt; in &lt;module&gt;
     27             for train_index, test_index in loo.split(dfClass):
     28                 X_train, X_test = X.iloc[train_index], X.iloc[test_index]
---&gt; 29                 y_train, y_test = y.iloc[train_index], y.iloc[test_index]
     30                 pvalue = []
     31                 x_control = X_train.loc[y_train=='Control', :].astype('float64', copy=False)

~\anaconda3\lib\site-packages\pandas\core\indexing.py in __getitem__(self, key)
    929 
    930             maybe_callable = com.apply_if_callable(key, self.obj)
--&gt; 931             return self._getitem_axis(maybe_callable, axis=axis)
    932 
    933     def _is_scalar_access(self, key: tuple):

~\anaconda3\lib\site-packages\pandas\core\indexing.py in _getitem_axis(self, key, axis)
   1555         # a list of integers
   1556         elif is_list_like_indexer(key):
-&gt; 1557             return self._get_list_axis(key, axis=axis)
   1558 
   1559         # a single integer

~\anaconda3\lib\site-packages\pandas\core\indexing.py in _get_list_axis(self, key, axis)
   1531         except IndexError as err:
   1532             # re-raise with different error message
-&gt; 1533             raise IndexError(&quot;positional indexers are out-of-bounds&quot;) from err
   1534 
   1535     def _getitem_axis(self, key, axis: int):

IndexError: positional indexers are out-of-bounds
</code></pre>
<p>This error may be because I'm using .loc and then .iloc, but is there a way around it? I want only certain parts of my dataframe as &quot;y&quot; for the classification. What else am I doing wrong here?</p>
",47,0,0,3,python;pandas;classification,2022-07-10 01:32:32,2022-07-10 01:32:32,2022-07-10 01:32:32,i m trying to do machine learning classification with a leave one out cross validation  this is the first part of the code  when i do this  i come across this error  this error may be because i m using  loc and then  iloc  but is there a way around it  i want only certain parts of my dataframe as  y  for the classification  what else am i doing wrong here ,indexerror  positional indexers are out of bounds  machine learning classification
57,57,19502829,72898584,Why is XmlWriter failing to replace characters not supported by the current encoding with equivalent character entities?,"<p>I am attempting to write an <code>XmlDocument</code> to a file using an encoding other than UTF8 (<code>Encoding.ASCII</code> in this case) and have <code>XmlWriter</code> automatically replace characters not supported by the encoding with equivalent character entities.  To do this, I am using the sample code from <em><a href=""https://stackoverflow.com/q/72348095/3744182"">Conversion of the special characters while adding it to the XML innertext in C#</a></em>.  However, for my XML, rather than replacing characters with character entities, it is throwing an exception like the below:</p>
<blockquote>
<p>Unable to translate Unicode character \u2018 at index 5852 to specified code page.Encode_Save</p>
</blockquote>
<p>What is the cause of this exception?  Why aren't the unsupported characters getting escaped as expected?</p>
<p><strong>Code used:</strong></p>
<p>My serialization code:</p>
<pre><code>using (var stream = new FileStream(clsGlobal.outputXMLPath, FileMode.OpenOrCreate))
{
    clsGlobal.XMLDoc.Save(stream, indent: false, encoding: Encoding.ASCII, omitXmlDeclaration: false);
}
</code></pre>
<p>The code for <code>Save()</code> from the linked question:</p>
<pre><code>public static class XmlSerializationHelper
{
    public static string GetOuterXml(this XmlNode node, bool indent = false, Encoding encoding = null, bool omitXmlDeclaration = false)
    {
        if (node == null)
            return null;
        
            var stream = new MemoryStream();

            node.Save(stream, indent: indent, encoding: encoding, omitXmlDeclaration: omitXmlDeclaration, closeOutput: false);
            stream.Position = 0;
            
            var reader = new StreamReader(stream);
            return reader.ReadToEnd();
      
    }

    public static void Save(this XmlNode node, Stream stream, bool indent = false, Encoding encoding = null, bool omitXmlDeclaration = false, bool closeOutput = true) =&gt;
        node.Save(stream, new XmlWriterSettings
        {
            Indent = indent,
            Encoding = encoding,               
            OmitXmlDeclaration = omitXmlDeclaration,
            CloseOutput = closeOutput,    
        });

    public static void Save(this XmlNode node, Stream stream, XmlWriterSettings settings)
    {
        try
        {
            using (var xmlWriter = XmlWriter.Create(stream, settings))
            {
                node.WriteTo(xmlWriter);
            }
        }
        catch (Exception ex)
        {
            clsGlobal.globalErrCount++;
            clsGlobal.WriteLog(ex.Message + &quot;Encode_Save&quot;);
        }
    }
}
</code></pre>
<p><strong>Input XML Data</strong>, stored in <code>clsGlobal.XMLDoc</code>:</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;article dtd=&quot;RSCART3.8&quot;&gt;
   &lt;art-admin&gt;
      &lt;ms-id&gt;BK9781839161964-00123&lt;/ms-id&gt;
      &lt;doi&gt;10.1039/9781839165580-00123&lt;/doi&gt;
   &lt;/art-admin&gt;
   &lt;published type=&quot;book&quot;&gt;
      &lt;journalref&gt;
         &lt;title&gt;DNA Photodamage: From Light Absorption to Cellular Responses and Skin Cancer&lt;/title&gt;
         &lt;sercode&gt;BK&lt;/sercode&gt;
         &lt;publisher&gt;
            &lt;orgname&gt;
               &lt;nameelt&gt;Royal Society of Chemistry&lt;/nameelt&gt;
            &lt;/orgname&gt;
         &lt;/publisher&gt;
         &lt;issn type=&quot;isbn&quot; /&gt;
         &lt;cpyrt&gt;© European Society for Photobiology 2022&lt;/cpyrt&gt;
      &lt;/journalref&gt;
      &lt;volumeref&gt;
         &lt;link /&gt;
      &lt;/volumeref&gt;
      &lt;pubfront&gt;
         &lt;fpage&gt;0&lt;/fpage&gt;
         &lt;lpage&gt;0&lt;/lpage&gt;
         &lt;no-of-pages&gt;0&lt;/no-of-pages&gt;
         &lt;date&gt;
            &lt;year&gt;2022&lt;/year&gt;
         &lt;/date&gt;
      &lt;/pubfront&gt;
   &lt;/published&gt;
   &lt;art-front&gt;
      &lt;titlegrp&gt;
         &lt;title&gt;Chapter 2&lt;/title&gt;
         &lt;title&gt;In Silico Tools to Assess Chemical Hazard&lt;/title&gt;
      &lt;/titlegrp&gt;
      &lt;abstract&gt;
         &lt;p&gt;
            Fundamentally, chemical hazard is a function of structure, and the quickest and cheapest way to predict toxicity is to do so from structure alone. Currently, there are many tools available to predict absorption, distribution, metabolism, and excretion (ADME), as well as some key endpoints, such as LD
            &lt;inf&gt;50&lt;/inf&gt;
            (the minimal dose necessary to kill half the animals exposed), mutagenicity, skin sensitization, and ecotoxicity. While quantitative structure–activity relationships (QSARS) and read-across are well established, the field is rapidly changing with the advent of larger data sets and more sophisticated machine learning approaches. As computational power increases, 3D models may become widely available. However, virtually all models have blind spots, and some endpoints (such as developmental toxicity and endocrine disruption) have proven difficult to predict from structure alone – in these cases, it is necessary to use toxicity tests that capture the complexity of a biological system.
         &lt;/p&gt;
      &lt;/abstract&gt;
   &lt;/art-front&gt;
   &lt;art-body&gt;
      &lt;section&gt;
         &lt;no&gt;0.0&lt;/no&gt;
         &lt;title&gt;2.1 Introduction&lt;/title&gt;
         &lt;p&gt;
            “It is obvious that there must exist a relation between the chemical constitution and the physiological action of a substance, but as yet scarcely any attempts have been made to discover what this relation is. . . .”
            &lt;citref idrefs=&quot;cit1&quot;&gt;1&lt;/citref&gt;
            This was written in 1865 by Alexander Crum Brown, a chemist who worked in tandem with a medical student, and represents the very first conjecture of the basic principle that is the foundation of
            &lt;it&gt;in silico&lt;/it&gt;
            toxicology: that, fundamentally, chemical hazard is a function of chemical structure. In theory, then, the quickest and cheapest way to predict toxicity is to do so from structure alone. In practice, as we shall see, this is often challenging – but understanding what we can and cannot predict from structure alone is a good way to understand how chemicals affect biological systems.
         &lt;/p&gt;
         &lt;p&gt;
            At its most basic, a chemical can be said to be hazardous when it has the potential to interact with a biological system in a way that causes harm – or to use the regulatory term, “an adverse outcome.” Sometimes the negative effect is because a chemical is a mutagen –
            &lt;it&gt;e.g&lt;/it&gt;
            . an electrophilic chemical might cause alkylation of DNA, which is nucleophilic, resulting in an error in the genetic code and, potentially, cancer. Or, a chemical might have a structure that so closely mimics a biological molecule that it can interact with a receptor for the endogenous molecule – as happens when chemicals that are large and coplanar, such as diethylstilbestrol, bind to the estrogen receptor and therefore prevent normal endocrine signaling. Similar mechanisms are thought to underlie many of the chemicals that are considered potential endocrine disruptors. A chemical can displace something essential –
            &lt;it&gt;e.g&lt;/it&gt;
            . carbon monoxide (CO) binds more strongly to hemoglobin than oxygen, and in sufficient quantities, it will deprive tissues of oxygen, resulting in cellular death and eventually asphyxiation.
         &lt;/p&gt;
         &lt;p&gt;
            Sometimes hazard is a straightforward result of the chemical properties of a molecule – most strong acids or bases will cause skin and eye irritation. Other times there are several steps –
            &lt;it&gt;e.g&lt;/it&gt;
            . 2,4-dinitrochlorobenzene can easily be absorbed through the skin barrier, and then bind with many proteins in the dermal layer. These altered proteins (“haptens”) are then recognized by the immune system as “foreign material” – and because your immune system is always on the lookout for foreign proteins, it activates immune cells that respond to the hapten, creating an allergic reaction that will persist. In some cases, the chemical itself is not a problem, but once inside the body, it can be metabolized into something problematic, as in the case of acetaminophen.
         &lt;/p&gt;
         &lt;p&gt;
            There are two main components to predicting toxicity. Toxicokinetics refers to how the xenobiotic is absorbed, distributed, metabolized, and excreted. Fundamentally, the balance of these factors determines the biologically effective dose – the amount of a xenobiotic that can cause harm. Toxicodynamics refers to how the chemical reacts in a negative way with biological molecules – proteins, DNA, or the cell membrane. Ultimately, the dose and the manner in which a compound causes harm determines whether there are effects at the cellular level. Severe enough effects at the cellular level eventually cause organ damage – the harmful outcome referred to as an “adverse effect.” (
            &lt;figref idrefs=&quot;fig1&quot;&gt;Figure 2.1&lt;/figref&gt;
            ).
         &lt;/p&gt;
      &lt;/section&gt;      
      &lt;section&gt;
         &lt;no&gt;0.0&lt;/no&gt;
         &lt;title&gt;2.5 Conclusion&lt;/title&gt;
         &lt;p&gt;
            Skin sensitization is the one endpoint that also has multiple
            &lt;it&gt;in silico&lt;/it&gt;
            tools models available, ranging from SAR approaches such as ToxTree to more sophisticated QSARs:
            &lt;it&gt;e.g.&lt;/it&gt;
            PredSkin,
            &lt;citref idrefs=&quot;cit47&quot;&gt;47&lt;/citref&gt;
            which is based on human data and available
            &lt;it&gt;via&lt;/it&gt;
            the web, and the OECD QSAR Toolbox,
            &lt;citref idrefs=&quot;cit48&quot;&gt;48&lt;/citref&gt;
            which has an automated workflow for skin sensitization. In general, most of these models perform well (with the OECD QSAR Toolbox having 80% balanced accuracy) although the models differ in their sensitivity and specificity
            &lt;!--AQ27--&gt;
            . The value of 80% might seem disappointing, but the reality is that the animal test these models are built off of – the LLNA test – is only ≈80% reproducible,
            &lt;citref idrefs=&quot;cit46&quot;&gt;46&lt;/citref&gt;
            and although figures vary, it only predicts human sensitization with a similar level of accuracy.
            &lt;citref idrefs=&quot;cit49&quot;&gt;49&lt;/citref&gt;
            As yet, these models typically predict binary sensitization status, instead of potency, which is a significant drawback – many chemicals that are very weak sensitizers are often predicted as sensitizers although their actual hazard under most exposure conditions might be small. However, the
            &lt;it&gt;in silico&lt;/it&gt;
            models are, at this point, performing about as well as can be expected given the limitations of the data. Because skin sensitization represents an instance where the toxicodynamics are well understood – something we will discuss in Chapter 3 – it also offers an instance where
            &lt;it&gt;in vitro&lt;/it&gt;
            data can be used as an effective supplement in
            &lt;it&gt;in silico&lt;/it&gt;
            models. Further improvement will likely require new ways to think about combining
            &lt;it&gt;in silico&lt;/it&gt;
            ,
            &lt;it&gt;in chemico&lt;/it&gt;
            , and
            &lt;it&gt;in vitro&lt;/it&gt;
            data.
         &lt;/p&gt;
         &lt;p&gt;
            Currently, there are many tools available to predict ADME, as well as some key endpoints, such as LD
            &lt;inf&gt;50&lt;/inf&gt;
            , mutagenicity, skin sensitization, and ecotoxicity. We can predict some important endpoints based on others –
            &lt;it&gt;e.g.&lt;/it&gt;
            it does not take a great leap of imagination to understand that most skin irritants will also be eye irritants, even though the reverse is not always true. Skin sensitization should raise a concern for respiratory sensitization, although not conclusively as there are differences in bioavailability and mechanism that means this is not a universal rule.
            &lt;citref idrefs=&quot;cit50&quot;&gt;50&lt;/citref&gt;
            A chemical that interferes in DNA replication is likely to cause developmental effects should it go through the fetal–placental barrier, but there are many mechanisms by which a chemical can cause developmental effects, and there are no validated models that are considered robust enough for regulatory acceptance. In theory, read-across and QSARs can be used in a well-defined chemical class if the mechanism is known. In practice, given the well-known difficulty of connecting structure to developmental toxicity, this remains an endpoint that requires an
            &lt;it&gt;in vivo&lt;/it&gt;
            study for clarity.
         &lt;/p&gt;
         &lt;p&gt;
            Of course, no model is perfect and there are several caveats that apply to all models broadly. A model is only as good as the data that goes into it, and in many instances the data will have a great deal of noise as well as missing data. Most data sets assembled for predictive models will not cover a diverse area of the chemical space, and are often biased towards positives, for the simple reason that people tend not to gather data on chemicals that are largely biologically inert. However, this can be problematic:
            &lt;it&gt;e.g.&lt;/it&gt;
            if a data set consists of 100 chemicals, and 80% of them are considered skin sensitizers, a model that simply declares every chemical a sensitizer will have 80% accuracy. Therefore, when judging model performance, always look to the sensitivity, specificity, and balanced accuracy. Many models, like structural alerts and read-across, are better at identifying toxic compounds than establishing the absence of toxicity. While this is useful for screening-level approaches that are oriented towards being precautionary, it is problematic when trying to decide between chemical candidates in the R&amp;amp;D phase.
         &lt;/p&gt;
         &lt;p&gt;Passive diffusion is relatively easy to predict, because it depends solely on chemical properties, and because of this we have models that will predict diffusion across skin, intestine, and lung tissue. We can also predict whether a chemical will likely passively diffuse across the blood–brain barrier, but have few models that can identify transporter-mediated absorption. With the exception of the relatively well-studied PGP transporter, this has proven very difficult to model because of the diversity of transporters. The probability of a chemical being metabolized by a Phase I enzyme can also be predicted, even if the prediction of the metabolite is more difficult. Finally, based on physical chemical properties, we can estimate overall distribution, excretion, and half-life.&lt;/p&gt;
         &lt;p&gt;
            In terms of toxicodynamics – predicting biological targets of chemicals and the downstream effects –the search space is more complicated both because of the diversity of targets and the biological variability of the subsequent events. Endpoints with a straightforward connection to chemical structure –
            &lt;it&gt;e.g.&lt;/it&gt;
            mutagenicity and skin sensitization, which are both related to electrophilicity – can be proactively identified with structural alerts, and modeled with QSARs. More complicated endpoints can be predicted with limited success, and most such models should be treated with caution. If you do not truly understand the relationship between chemical structure and toxicity, read-across or QSARs will necessarily be limited – you can never know whether two similar molecules are in fact an activity cliff. Moreover, virtually all models will have some blindspots that will reflect the era in which they were developed as well as the data available, and if not updated will tend to become increasingly outdated.
         &lt;/p&gt;
         &lt;p&gt;
            Finally,
            &lt;it&gt;in silico&lt;/it&gt;
            approaches can only be used on discrete, organic structures
            &lt;!--AQ28--&gt;
            . By a rough estimate, however, that means that 50% of the chemicals within commerce cannot be evaluated with
            &lt;it&gt;in silico&lt;/it&gt;
            tools, as they are mixtures (called UVCBs), metal compounds, or salts, in addition to containing impurities – and even small amounts of impurities can give rise to adverse events (
            &lt;it&gt;e.g.&lt;/it&gt;
            sensitization or mutagenicity
            &lt;!--AQ29--&gt;
            ). Such chemicals are likely to increase as many bio-based chemicals are UVCBs, polymers, and engineered nanomaterials, which cannot be handled easily by existing
            &lt;it&gt;in silico&lt;/it&gt;
            tools.
         &lt;/p&gt;
         &lt;p&gt;Glossary&lt;/p&gt;
         &lt;figure id=&quot;fig1&quot; xsrc=&quot;BK9781839161964-00123-f1.tif&quot; pos=&quot;float&quot;&gt;
            &lt;title&gt;
               Toxicokinetics and toxicodynamics together determine whether a xenobiotic will cause a disease. Adapted from ref.
               &lt;citref idrefs=&quot;cit51&quot;&gt;51&lt;/citref&gt;
               , https://doi.org/10.14573/altex.1610101, under the terms of the CC BY 4.0 license,
               &lt;url url=&quot;https://creativecommons.org/licenses/by/4.0/&quot;&gt;https://creativecommons.org/licenses/by/4.0/&lt;/url&gt;
               .
            &lt;/title&gt;
         &lt;/figure&gt;
         &lt;figure id=&quot;fig2&quot; xsrc=&quot;BK9781839161964-00123-f2.tif&quot; pos=&quot;float&quot;&gt;
            &lt;title&gt;Phase I metabolism involves either oxidation or hydrolysis, typically resulting in a more reactive intermediate. Phase II conjugates the compounds either with glutathione, in the case of electrophiles, or sulfation, acetylation, or glucuronidation to make a compound more water soluble.&lt;/title&gt;
         &lt;/figure&gt;
         &lt;figure id=&quot;fig3&quot; xsrc=&quot;BK9781839161964-00123-f3.tif&quot; pos=&quot;float&quot;&gt;
            &lt;title&gt;
               ADME is determined by absorption (ingestion, inhalation, or dermal), distribution primarily
               &lt;it&gt;via&lt;/it&gt;
               The blood and lymph, and excretion
               &lt;!--AQ87--&gt;
               .
            &lt;/title&gt;
         &lt;/figure&gt;
         &lt;figure id=&quot;fig4&quot; xsrc=&quot;BK9781839161964-00123-f4.tif&quot; pos=&quot;float&quot;&gt;
            &lt;title&gt;
               Paracetamol metabolism. Paracetamol can be immediately glucuronidated or sulfated without being metabolized by a Phase I enzyme. However, some will be oxidized
               &lt;it&gt;via&lt;/it&gt;
               CYP2E1 into a reactive intermediate.
            &lt;/title&gt;
         &lt;/figure&gt;
         &lt;figure id=&quot;fig5&quot; xsrc=&quot;BK9781839161964-00123-f5.tif&quot; pos=&quot;float&quot;&gt;
            &lt;title&gt;Phorbol ester structure, from PubChem.&lt;/title&gt;
         &lt;/figure&gt;
         &lt;figure id=&quot;fig6&quot; xsrc=&quot;BK9781839161964-00123-f6.tif&quot; pos=&quot;float&quot;&gt;
            &lt;title&gt;The ultimate rat carcinogen. Reproduced from Ref. 52, DOI:10.2788/6234, under the terms of the CC BY 4.0 license https://creativecommons.org/licenses/by/4.0/.&lt;/title&gt;
         &lt;/figure&gt;
         &lt;figure id=&quot;fig7&quot; xsrc=&quot;BK9781839161964-00123-f7.tif&quot; pos=&quot;float&quot;&gt;
            &lt;title&gt;Structural analogs for Bisphenol A as selected by GenRA. One the left is ToxPrints, on the right Morgan fingerprints.&lt;/title&gt;
         &lt;/figure&gt;         
         &lt;table-entry id=&quot;tab4&quot;&gt;
            &lt;title&gt;Table 2.4 Non-commercial read-across and QSAR&lt;/title&gt;
            &lt;table frame=&quot;topbot&quot;&gt;
               &lt;tgroup cols=&quot;3&quot; align=&quot;left&quot; colsep=&quot;1&quot; rowsep=&quot;1&quot; /&gt;
               &lt;colspec colnum=&quot;1&quot; colname=&quot;c1&quot; /&gt;
               &lt;colspec colnum=&quot;2&quot; colname=&quot;c2&quot; /&gt;
               &lt;colspec colnum=&quot;3&quot; colname=&quot;c3&quot; /&gt;
               &lt;thead /&gt;
               &lt;tbody&gt;
                  &lt;row&gt;
                     &lt;entry&gt;
                        &lt;bo&gt;
                           &lt;it&gt;Software&lt;/it&gt;
                        &lt;/bo&gt;
                     &lt;/entry&gt;
                     &lt;entry&gt;
                        &lt;bo&gt;
                           &lt;it&gt;Models available&lt;/it&gt;
                        &lt;/bo&gt;
                     &lt;/entry&gt;
                     &lt;entry&gt;
                        &lt;bo&gt;
                           &lt;it&gt;Platform&lt;/it&gt;
                        &lt;/bo&gt;
                     &lt;/entry&gt;
                  &lt;/row&gt;
                  &lt;row&gt;
                     &lt;entry&gt;OECD QSAR Toolbox&lt;/entry&gt;
                     &lt;entry&gt;Read-across, QSARs, QSPR for multiple endpoints&lt;/entry&gt;
                     &lt;entry&gt;Requires Windows&lt;/entry&gt;
                  &lt;/row&gt;
                  &lt;row&gt;
                     &lt;entry&gt;GenRA&lt;/entry&gt;
                     &lt;entry&gt;Read-across&lt;/entry&gt;
                     &lt;entry&gt;
                        Available
                        &lt;it&gt;via&lt;/it&gt;
                        Web at the EPA Comptox Dashboard
                     &lt;/entry&gt;
                  &lt;/row&gt;
                  &lt;row&gt;
                     &lt;entry align=&quot;char&quot; char=&quot;.&quot;&gt;T.E.S.T.&lt;/entry&gt;
                     &lt;entry&gt;Global QSAR for acute toxicity, estrogen receptor binding, developmental toxicity, ecotoxicology endpoints&lt;/entry&gt;
                     &lt;entry&gt;
                        Available
                        &lt;it&gt;via&lt;/it&gt;
                        web at the EPA Comptox Dashboard and as stand-alone software
                     &lt;/entry&gt;
                  &lt;/row&gt;
                  &lt;row&gt;
                     &lt;entry&gt;ECOSAR&lt;/entry&gt;
                     &lt;entry&gt;Ecotoxicology endpoints&lt;/entry&gt;
                     &lt;entry&gt;Available as stand-alone software&lt;/entry&gt;
                  &lt;/row&gt;
                  &lt;row&gt;
                     &lt;entry&gt;VEGA&lt;/entry&gt;
                     &lt;entry&gt;ADME, Read-across, and QSAR for multiple endpoints&lt;/entry&gt;
                     &lt;entry&gt;Java application for Mac\Linux\&lt;/entry&gt;
                  &lt;/row&gt;
                  &lt;row&gt;
                     &lt;entry&gt;Danish QSAR Database&lt;/entry&gt;
                     &lt;entry&gt;Global QSARs based on existing models for multiple endpoints; applicability domain indicated&lt;/entry&gt;
                     &lt;entry&gt;
                        Available
                        &lt;it&gt;via&lt;/it&gt;
                        the web
                     &lt;/entry&gt;
                  &lt;/row&gt;
               &lt;/tbody&gt;
            &lt;/table&gt;
         &lt;/table-entry&gt;
      &lt;/section&gt;
   &lt;/art-body&gt;
   &lt;art-back&gt;
      &lt;biblist title=&quot;References&quot;&gt;
         &lt;citgroup id=&quot;cit1&quot;&gt;
            &lt;journalcit&gt;
               &lt;citauth&gt;
                  &lt;fname&gt;A. C.&lt;/fname&gt;
                  &lt;surname&gt;Brown&lt;/surname&gt;
               &lt;/citauth&gt;
               &lt;citauth&gt;
                  &lt;fname&gt;T. R.&lt;/fname&gt;
                  &lt;surname&gt;Fraser&lt;/surname&gt;
               &lt;/citauth&gt;
               &lt;arttitle&gt;On the Connection between Chemical Constitution and Physiological Action; with special reference to the Physiological Action of the Salts of the Ammonium Bases derived from Strychnia, Brucia, Thebaia, Codeia, Morphia, and Nicotia&lt;/arttitle&gt;
               &lt;title&gt;J. Anat. Physiol.&lt;/title&gt;
               &lt;year&gt;1868&lt;/year&gt;
               &lt;volumeno&gt;2&lt;/volumeno&gt;
               &lt;pages&gt;
                  &lt;fpage&gt;224&lt;/fpage&gt;
                  &lt;lpage&gt;242&lt;/lpage&gt;
               &lt;/pages&gt;
            &lt;/journalcit&gt;
         &lt;/citgroup&gt;
         &lt;citgroup id=&quot;cit2&quot;&gt;
            &lt;journalcit&gt;
               &lt;citauth&gt;
                  &lt;fname&gt;C.&lt;/fname&gt;
                  &lt;surname&gt;Lynch&lt;/surname&gt;
               &lt;/citauth&gt;
               &lt;title&gt;Anesth. Analg.&lt;/title&gt;
               &lt;year&gt;2008&lt;/year&gt;
               &lt;volumeno&gt;107&lt;/volumeno&gt;
               &lt;pages&gt;
                  &lt;fpage&gt;864&lt;/fpage&gt;
                  &lt;lpage&gt;867&lt;/lpage&gt;
               &lt;/pages&gt;
            &lt;/journalcit&gt;
         &lt;/citgroup&gt;
         &lt;citgroup id=&quot;cit3&quot;&gt;
            &lt;journalcit&gt;
               &lt;citauth&gt;
                  &lt;fname&gt;C. A.&lt;/fname&gt;
                  &lt;surname&gt;Lipinski&lt;/surname&gt;
               &lt;/citauth&gt;
               &lt;arttitle&gt;Lead- and drug-like compounds: the rule-of-five revolution&lt;/arttitle&gt;
               &lt;title&gt;Drug Discov. Today Technol.&lt;/title&gt;
               &lt;year&gt;2004&lt;/year&gt;
               &lt;volumeno&gt;1&lt;/volumeno&gt;
               &lt;pages&gt;
                  &lt;fpage&gt;337&lt;/fpage&gt;
                  &lt;lpage&gt;341&lt;/lpage&gt;
               &lt;/pages&gt;
            &lt;/journalcit&gt;
         &lt;/citgroup&gt;
         &lt;citgroup id=&quot;cit4&quot;&gt;
            &lt;journalcit&gt;
               &lt;citauth&gt;
                  &lt;fname&gt;D.&lt;/fname&gt;
                  &lt;surname&gt;Epel&lt;/surname&gt;
               &lt;/citauth&gt;
               &lt;citauth&gt;
                  &lt;fname&gt;T.&lt;/fname&gt;
                  &lt;surname&gt;Luckenbach&lt;/surname&gt;
               &lt;/citauth&gt;
               &lt;citauth&gt;
                  &lt;fname&gt;C. N.&lt;/fname&gt;
                  &lt;surname&gt;Stevenson&lt;/surname&gt;
               &lt;/citauth&gt;
               &lt;citauth&gt;
                  &lt;fname&gt;L. A.&lt;/fname&gt;
                  &lt;surname&gt;Macmanus-Spencer&lt;/surname&gt;
               &lt;/citauth&gt;
               &lt;citauth&gt;
                  &lt;fname&gt;A.&lt;/fname&gt;
                  &lt;surname&gt;Hamdoun&lt;/surname&gt;
               &lt;/citauth&gt;
               &lt;citauth&gt;
                  &lt;fname&gt;T.&lt;/fname&gt;
                  &lt;surname&gt;Smital&lt;/surname&gt;
               &lt;/citauth&gt;
               &lt;arttitle&gt;Efflux transporters: newly appreciated roles in protection against pollutants&lt;/arttitle&gt;
               &lt;title&gt;Environ. Sci. Technol.&lt;/title&gt;
               &lt;year&gt;2008&lt;/year&gt;
               &lt;volumeno&gt;42&lt;/volumeno&gt;
               &lt;pages&gt;
                  &lt;fpage&gt;3914&lt;/fpage&gt;
                  &lt;lpage&gt;3920&lt;/lpage&gt;
               &lt;/pages&gt;
            &lt;/journalcit&gt;
         &lt;/citgroup&gt;
         &lt;citgroup id=&quot;cit5&quot;&gt;
            &lt;journalcit&gt;
               &lt;citauth&gt;
                  &lt;fname&gt;L.-A.&lt;/fname&gt;
                  &lt;surname&gt;Clerbaux&lt;/surname&gt;
               &lt;/citauth&gt;
               &lt;citauth&gt;
                  &lt;fname&gt;A.&lt;/fname&gt;
                  &lt;surname&gt;Paini&lt;/surname&gt;
               &lt;/citauth&gt;
               &lt;citauth&gt;
                  &lt;fname&gt;A.&lt;/fname&gt;
                  &lt;surname&gt;Lumen&lt;/surname&gt;
               &lt;/citauth&gt;
               &lt;citauth&gt;
                  &lt;fname&gt;H.&lt;/fname&gt;
                  &lt;surname&gt;Osman-Ponchet&lt;/surname&gt;
               &lt;/citauth&gt;
               &lt;citauth&gt;
                  &lt;fname&gt;A. P.&lt;/fname&gt;
                  &lt;surname&gt;Worth&lt;/surname&gt;
               &lt;/citauth&gt;
               &lt;citauth&gt;
                  &lt;fname&gt;O.&lt;/fname&gt;
                  &lt;surname&gt;Fardel&lt;/surname&gt;
               &lt;/citauth&gt;
               &lt;arttitle&gt;Membrane transporter data to support kinetically-informed chemical risk assessment using non-animal methods: Scientific and regulatory perspectives&lt;/arttitle&gt;
               &lt;title&gt;Environ. Int.&lt;/title&gt;
               &lt;year&gt;2019&lt;/year&gt;
               &lt;volumeno&gt;126&lt;/volumeno&gt;
               &lt;pages&gt;
                  &lt;fpage&gt;659&lt;/fpage&gt;
                  &lt;lpage&gt;671&lt;/lpage&gt;
               &lt;/pages&gt;
            &lt;/journalcit&gt;
         &lt;/citgroup&gt;         
         &lt;citgroup id=&quot;cit54&quot;&gt;
            &lt;journalcit&gt;
               &lt;citauth&gt;
                  &lt;surname&gt;Oecd&lt;/surname&gt;
               &lt;/citauth&gt;
               &lt;arttitle&gt;Data from: EChemPortal: Global portal to information on chemical substances&lt;/arttitle&gt;
               &lt;title&gt;OECD Obs.&lt;/title&gt;
            &lt;/journalcit&gt;
         &lt;/citgroup&gt;
      &lt;/biblist&gt;
      &lt;compoundgrp /&gt;
      &lt;annotationgrp /&gt;
      &lt;datagrp /&gt;
      &lt;resourcegrp /&gt;
   &lt;/art-back&gt;
   &lt;!--MAQ1: AQ: Please insert the expansion for the acronym ‘PGP’ if appropriate for the reader.--&gt;
   &lt;!--MAQ2: CE: The sentence beginning ‘The PGP transporter is expressed.’ has been altered for clarity, please check that the meaning is correct.--&gt;
   &lt;!--MAQ3: &lt;AQ&gt;The sentence beginning ‘The fraction unbound in plasma.’ has been altered for clarity, please check that the meaning is correct.&lt;/AQ&gt;--&gt;
   &lt;!--MAQ5: &lt;AQ&gt;In the sentence beginning ‘In pharmacology studies.’ a word or phrase appears to be missing after ‘is known and the remaining’. Please check this carefully and indicate any changes required here.&lt;/AQ&gt;--&gt;   
&lt;/article&gt;
</code></pre>
",58,2,-1,4,c#;xml;encoding;xmlwriter,2022-07-07 18:49:49,2022-07-07 18:49:49,2022-07-10 00:33:15,i am attempting to write an xmldocument to a file using an encoding other than utf  encoding ascii in this case  and have xmlwriter automatically replace characters not supported by the encoding with equivalent character entities   to do this  i am using the sample code from    however  for my xml  rather than replacing characters with character entities  it is throwing an exception like the below  unable to translate unicode character  u at index  to specified code page encode_save what is the cause of this exception   why aren t the unsupported characters getting escaped as expected  code used  my serialization code  the code for save   from the linked question  input xml data  stored in clsglobal xmldoc ,why is xmlwriter failing to replace characters not supported by the current encoding with equivalent character entities 
58,58,19517141,72923148,The Impact of TV Advertising on Website Traffic,"<p>I need to build a model that measures the impact of TV advertising on website traffic.</p>
<p>I have two datasets: one contains the number of visits to the page and a timestamp, the other contains a timestamp and TV ad data such as a channel, information about whether the ads are shown in the middle, after or before a TV show, and so on.</p>
<p>My problem is that I don't know how to merge these datasets as the timestamps in the datasets have different granularity and then which machine learning method should be appropriate to measure this impact.</p>
<p>If you have any ideas or experiences please let me know.</p>
",18,0,-4,4,python;machine-learning;modeling;web-traffic,2022-07-09 22:16:14,2022-07-09 22:16:14,2022-07-09 23:02:03,i need to build a model that measures the impact of tv advertising on website traffic  i have two datasets  one contains the number of visits to the page and a timestamp  the other contains a timestamp and tv ad data such as a channel  information about whether the ads are shown in the middle  after or before a tv show  and so on  my problem is that i don t know how to merge these datasets as the timestamps in the datasets have different granularity and then which machine learning method should be appropriate to measure this impact  if you have any ideas or experiences please let me know ,the impact of tv advertising on website traffic
59,59,14328643,72844991,Code Challange Joining repeated numbers on an array,"<p>my output from a machine learning algorithm is a list of segments, segments are represented by a pair of ids, each segment is part of a track(ideally, there are repeated ids and missing ids), and the following code produces a similar array:</p>
<pre><code>    import numpy as np
    np.random.seed(42)
    #ids pairs are less the further you go on the track
    ids_ammount= np.arange(26,8,-2)
    # the array is a 2 column array  with conected segments
    ids_array = np.zeros((np.sum(ids_ammount),2))
    idx_0 = 0
    idx_1 = 0
    for i, ids in enumerate(ids_ammount):
      idx_1+=ids
      #first column is in order from smaller to largest id
      ids_array[:,0][idx_0:idx_1] = np.sort(np.random.randint(i * 10,10*(i+1),size=ids))
      ids_array[:,1][idx_0:idx_1] = np.random.randint((i + 1) * 10,10*(i+2),size=ids)
      idx_0+= ids
</code></pre>
<p>my goal is to reconstruct the tracks using <strong>ids_array</strong>, I have an implementation but is really inefficient with 3 <strong>if</strong> statements and I need to check manually the max number of repeated ids every time in order to make it work, so I prefer not to include it as I would like to get some fresh ideas on how to solve this as efficient as possible.
My desired output would be 9 arrays, one with ids that have just one connection, the other with 2 connections, and so on until 9 connections, example:</p>
<p>single_conection = [[0,18],[67,73]...],
double_conection = [[1,14,26], [53,68,79],....]
.
.
.
nine_conections = [[3,15,28,36,41,59,66,79,82,99]....]</p>
<p>Some of the problems that I encounter are, that ids are repeated, some ids don't exist, and the maximum number of repeated ids is variable.
If someone has an idea on how to reconstruct these tracks would be amazing, and if anyone knows how to do it efficiently would be even better.
Thanks</p>
",58,1,0,5,python;arrays;algorithm;performance;sorting,2022-07-03 14:01:54,2022-07-03 14:01:54,2022-07-09 19:04:54,my output from a machine learning algorithm is a list of segments  segments are represented by a pair of ids  each segment is part of a track ideally  there are repeated ids and missing ids   and the following code produces a similar array ,code challange joining repeated numbers on an array
60,60,14429324,66687941,Openpyxl load_workbook gives me KeyError,"<p>I'm using Jupyter Notebook and I'm trying to convert a file <code>.xlsx</code> into pandas DataFrame but <code>openpyxl</code> keeps giving me error.</p>
<p>My file's name is <code>Dry_Bean_Dataset.xlsx</code>, so what I'm doing is setting the path to that file and then creating the workbook with <code>openpyxl</code>. However, when I try the 'ws' function, it gives me KeyError.</p>
<pre><code>import pandas as pd
from openpyxl import load_workbook
path2= 'C:/Users/nbravo/OneDrive - Schenck Process Group Holding/Documents/13. Master of Information Technology/2. Semestre 1 - 2021/Machine Learning/Lab02/DryBeanDataset/Dry_Bean_Dataset.xlsx'
wb = load_workbook(path2)
ws = wb['Dry_Bean_Dataset']
</code></pre>
<p>And this is the error that I get:</p>
<hr />
<p>KeyError                                  Traceback (most recent call last)
 in 
----&gt; 1 ws = wb['Dry_Bean_Dataset']</p>
<p>~\Anaconda3\lib\site-packages\openpyxl\workbook\workbook.py in __ getitem__(self, key)
271             if sheet.title == key:
272                 return sheet
--&gt; 273         raise KeyError(&quot;Worksheet {0} does not exist.&quot;.format(key))
274
275     def __ delitem__(self, key):</p>
<p>KeyError: 'Worksheet Dry_Bean_Dataset does not exist.'</p>
",145,0,2,4,python;pandas;jupyter-notebook;openpyxl,2021-03-18 14:40:34,2021-03-18 14:40:34,2022-07-09 18:20:35,i m using jupyter notebook and i m trying to convert a file  xlsx into pandas dataframe but openpyxl keeps giving me error  my file s name is dry_bean_dataset xlsx  so what i m doing is setting the path to that file and then creating the workbook with openpyxl  however  when i try the  ws  function  it gives me keyerror  and this is the error that i get  keyerror   worksheet dry_bean_dataset does not exist  ,openpyxl load_workbook gives me keyerror
61,61,19349751,72920959,How to increase the score in Kaggle competition?,"<p>I am new to Kaggle and recently I submitted the notebook for the <strong>Titanic - Machine Learning from Disaster</strong> competition. My Logistic Regression model is giving me <strong>80% accuracy</strong> but when I submitted the same CSV file, my Kaggle score is <strong>0</strong>.</p>
<p>So I wanted to know what is going wrong and how to fix this issue.</p>
",24,0,-3,4,python;machine-learning;regression;kaggle,2022-07-09 16:54:51,2022-07-09 16:54:51,2022-07-09 16:54:51,i am new to kaggle and recently i submitted the notebook for the titanic   machine learning from disaster competition  my logistic regression model is giving me   accuracy but when i submitted the same csv file  my kaggle score is   so i wanted to know what is going wrong and how to fix this issue ,how to increase the score in kaggle competition 
62,62,19387078,72918614,"Overfitting Gradient Boosting, should I increase or decrease learning rate?","<p>I was reading how to regularize gradient boosting by adjusting the learning rate and cant seem to understand why a smaller learning rate can regularize better. In the book Hands-On Machine Learning with Scikit-Learn, keras and Tensorflow, the author suggests decreasing learning rate. However, at the same time the author compares a large learning rate 1, with a small learning rate 0.1, the graph for rate 1 seems far more regularize than 0.1.</p>
<p>Here's my take on this:</p>
<ol>
<li>It will regularize better if you decrease the number of iterations and a smaller learning rate (can't just lower learning rate)</li>
<li>Or just increase the learning rate</li>
</ol>
<p>Is this idea anywhere near correct? Or am I completely wrong. Thanks!</p>
",26,0,-2,3,machine-learning;ensemble-learning;boosting,2022-07-09 08:26:50,2022-07-09 08:26:50,2022-07-09 08:26:50,i was reading how to regularize gradient boosting by adjusting the learning rate and cant seem to understand why a smaller learning rate can regularize better  in the book hands on machine learning with scikit learn  keras and tensorflow  the author suggests decreasing learning rate  however  at the same time the author compares a large learning rate   with a small learning rate    the graph for rate  seems far more regularize than    here s my take on this  is this idea anywhere near correct  or am i completely wrong  thanks ,overfitting gradient boosting  should i increase or decrease learning rate 
63,63,18726236,72778858,"neural network not optimizing weights of first layer, returning all 1&#39;s for z1","<p>So im building a neural network in python right now losely following Andrew Ng's machine learning course. It has 3 layers (all sigmoid) and works on predicting the MNIST dataset. But it fails to actually predict the dataset, and while the cost is decreasing with every iteration accuracy remains at around 0.1, indicating something isnt working properly.
After playing around and letting the program display the different steps i noticed that z1 (calculated from the train_X@theta1 in the activation layer) is pretty much uniformly 1's, which seems to be hindering the network to function. This is due to the train_X@theta1 being high values, making e^(-z) basically 0 and the sigmoid function returning basically 1. But that also leads to the derivative for theta1 (due to being multiplied by (1-z1) to just be 0's, hindering the network from doing anything.
Things i have tried are:</p>
<p>Regularizing the dataset</p>
<p>Playing around with alpha values (which doesnt do anything, as expected)</p>
<p>Making theta1 values start out really small (all calculated through a uniform distribution, which i then multiplied by like 0.000001): this, while fixing the problem for the first iteration just makes the network optimize theta1 to where it leads to uniformly 1's at z1 again, so i suspect backwards/forward propagation to not be working properly? Even though I basically copied that from one of my working solutions to an exercise in the course in octave, which produced resonable results and ended up with a high accuracy.</p>
<p>Here is my algorithm:</p>
<pre><code>def nn_forwardPropagation(train_X, train_Y, theta1, theta2, theta3):
    accuracy = 0
    J = 0
    #forward propagation, always adding 1's for the bias unit
    train_X = np.c_[ np.ones((np.shape(train_X)[0],1)), train_X]
    z1 = sigmoid(train_X@np.transpose(theta1))
    a1 = np.c_[ np.ones((np.shape(z1)[0],1)), z1]
    z2 = sigmoid(a1@np.transpose(theta2))
    a2 = np.c_[ np.ones((np.shape(z2)[0],1)), z2]
    #last step
    predValues = np.zeros((10,len(train_Y)))
    y1 = predValues.copy()
    predValues2 = y1.copy()
    for j in range(len(train_Y)):
        for i in range(np.shape(theta3)[0]):
            predValues[i,j] = sigmoid(a2[j,:]@np.transpose(theta3[i,:]))
        #making y1 our &quot;target matrix&quot; where we would like to see a 1 at the place of the right number and 0's everywhere else 
        y1[train_Y[j],j] = 1
        J += np.sum((np.transpose(-y1[:,j])@np.log(predValues[:,j]))  -  (1-np.transpose(y1[:,j]))@np.log(1 - predValues[:,j]))/len(train_Y)
        #in order to calculate accuracy, we just assume that the highest value in our predicted values dictates which value is &quot;right&quot; and looks if that's right
        predValues2[np.where(predValues[:,j] == max(predValues[:,j])),j] = 1 
        if np.array_equiv(predValues2[:,j], y1[:,j]):
            accuracy += 1/len(train_Y)
    #calculating the derivatives
    delta3 = predValues - y1  
    delta2 = np.transpose(delta3) @ theta3[:,1:] * z2 * (1-z2)
    delta1 = delta2 @ theta2[:,1:] * z1 * (1-z1)
    D3 = delta3 @ a2 
    D2 = np.transpose(delta2) @ a1
    D1 = np.transpose(delta1) @ train_X
    theta3_grad = D3 / len(train_Y)
    theta2_grad = D2 / len(train_Y)
    theta1_grad = D1 / len(train_Y)
    return J, theta3_grad, theta2_grad, theta1_grad, accuracy
    
def nn_runner(train_X, train_Y, iterations, alpha1, alpha2, alpha3):
    theta1 = np.random.rand(4,785)
    theta2 = np.random.rand(7,5)
    theta3 = np.random.rand(10,8)
    for i in range(1,iterations+1):
        J, theta3_grad, theta2_grad, theta1_grad, accuracy = nn_forwardPropagation(train_X, train_Y, theta1, theta2, theta3)
        theta3 -= alpha3*theta3_grad
        theta2 -= alpha2*theta2_grad
        theta1 -= alpha1*theta1_grad
        if i % 1 == 0:
            print(&quot;At iteration&quot;,i,&quot;:&quot;, J)
    print(&quot;This amounts to a total accuracy on training data of&quot;, accuracy)
    return theta3, theta2, theta1
</code></pre>
<p>Does anybody here know what i did wrong/could look into to make this working?
Thanks</p>
",47,1,0,4,python;machine-learning;neural-network;mnist,2022-06-28 03:52:00,2022-06-28 03:52:00,2022-07-09 04:46:44,regularizing the dataset playing around with alpha values  which doesnt do anything  as expected  making theta values start out really small  all calculated through a uniform distribution  which i then multiplied by like     this  while fixing the problem for the first iteration just makes the network optimize theta to where it leads to uniformly  s at z again  so i suspect backwards forward propagation to not be working properly  even though i basically copied that from one of my working solutions to an exercise in the course in octave  which produced resonable results and ended up with a high accuracy  here is my algorithm ,neural network not optimizing weights of first layer  returning all    s for z
64,64,5930146,48013034,Full &amp; complete uninstall QT Creator,"<p>Question:</p>

<p><strong>How to uninstall QT Creator from Linux machine?</strong></p>

<p>I have a corrupted install on a Debian Jessie machine. I have tried reinstalling, fixing, etc. and with no luck. I was advised to uninstall completely, grab the newest version and reinstall.</p>

<p>The problem is that I'm not sure how to do this and every time I try, QT keeps coming back with the same exact issues, I'm assuming because of some config files that are not getting deleted in the removal process.</p>

<p>Running <code>qmake --version</code> gives me this output:</p>

<pre><code>QMake version 3.0
Using Qt version 5.6.2 in /home/greg/anaconda2/lib
</code></pre>

<p>Running <code>pkg-config --modversion QtCore</code> gives me this output:</p>

<pre><code>Package QtCore was not found in the pkg-config search path.
Perhaps you should add the directory containing `QtCore.pc'
to the PKG_CONFIG_PATH environment variable
No package 'QtCore' found
</code></pre>

<p>The problem is that I've got several versions installed, in different folders and I want to completely start over with a fresh install of QT Creator. Version 5.10 was installed yesterday via the QT maintenence tool, but for some reason won't run. I just need to remove it and start over. QT 5.9.3 and 5.10 are installed at <code>/home/greg</code> and you can see 5.6.2 is installed in my anaconda2 folder. Not sure how this happened. I'm still a newb so still learning.</p>

<p><strong>How can I do a complete/full uninstall and removal of ALL QT creator files without deleting other QT files, such as KDE dependencies, etc., so that I can do a fresh install with new config settings????</strong></p>
",12055,1,4,3,qt;qt-creator;debian-jessie,2017-12-29 00:39:41,2017-12-29 00:39:41,2022-07-09 03:38:05,question  how to uninstall qt creator from linux machine  i have a corrupted install on a debian jessie machine  i have tried reinstalling  fixing  etc  and with no luck  i was advised to uninstall completely  grab the newest version and reinstall  the problem is that i m not sure how to do this and every time i try  qt keeps coming back with the same exact issues  i m assuming because of some config files that are not getting deleted in the removal process  running qmake   version gives me this output  running pkg config   modversion qtcore gives me this output  the problem is that i ve got several versions installed  in different folders and i want to completely start over with a fresh install of qt creator  version   was installed yesterday via the qt maintenence tool  but for some reason won t run  i just need to remove it and start over  qt    and   are installed at  home greg and you can see    is installed in my anaconda folder  not sure how this happened  i m still a newb so still learning  how can i do a complete full uninstall and removal of all qt creator files without deleting other qt files  such as kde dependencies  etc   so that i can do a fresh install with new config settings    ,full  amp  complete uninstall qt creator
65,65,19512158,72915205,Flask Error: werkzeug.routing.BuildError: Could not build url for endpoint &#39;prediction&#39;. Did you mean &#39;flower_prediction&#39; instead?,"<p>I'm deploying a machine learning model with python through flask, however I'm getting an error when I input the information for the model to process.</p>
<p><a href=""https://i.stack.imgur.com/t5OIf.png"" rel=""nofollow noreferrer"">Picture of inputting values on website</a></p>
<p>However, after I input the values and press the button to analyze it, it shows me an error. In VS Code where I made the flask back-end programming, it says this:</p>
<pre><code>File &quot;C:\Users\danis\anaconda3\Lib\site-packages\werkzeug\routing.py&quot;, line 2314, in build
raise BuildError(endpoint, values, method, self)
werkzeug.routing.BuildError: Could not build url for endpoint 'prediction'. Did you mean 'flower_prediction' instead?
</code></pre>
<p>I also turned on an option for a debugger named werkzeug.routing.BuildError to pop up in my browser and it said:</p>
<pre><code>werkzeug.routing.BuildError: Could not build url for endpoint 'prediction'. Did you mean 'flower_prediction' instead?
File &quot;C:\Users\danis\Documents\Udemy AI Course Files\TF_2_Notebooks_and_Data\09-Deployment\test.py&quot;, line 44, in index
return redirect(url_for(&quot;prediction&quot;))
</code></pre>
<p>flower_prediction is my function that calls the machine learning model to process the data, so I'm unsure what to do next.</p>
<p>I'm a beginner to flask, so here is the code for the back-end program:</p>
<pre><code>from flask import Flask, render_template,session,url_for,redirect, session
import numpy as np 
from flask_wtf import FlaskForm
from wtforms import TextField,SubmitField
from wtforms.validators import NumberRange
from tensorflow.keras.models import load_model
import joblib 

def return_prediction(model,scaler,sample_json):

    s_len = sample_json[&quot;sepal_length&quot;]
    s_wid = sample_json[&quot;sepal_width&quot;]
    p_len = sample_json[&quot;petal_length&quot;]
    p_wid = sample_json[&quot;petal_width&quot;]

    flower = [[s_len,s_wid,p_len,p_wid]]
    flower = scaler.transform(flower)
    classes = np.array(['setosa','versicolor','virginica'])
    class_ind = np.argmax(model.predict(flower))
    return classes[class_ind][0]

app = Flask(__name__)
app.config['SECRET_KEY'] = 'mysecretkey'

flower_model = load_model(&quot;final_iris_model.h5&quot;)
flower_scaler = joblib.load(&quot;iris_scaler.pkl&quot;)

class FlowerForm(FlaskForm):
    sep_len = TextField(&quot;Sepal Length&quot;)
    sep_wid = TextField(&quot;Sepal Width&quot;)
    pet_len = TextField(&quot;Petal Length&quot;)
    pet_wid = TextField(&quot;Petal Width&quot;)
    submit = SubmitField(&quot;Analyze&quot;)

@app.route(&quot;/&quot;,methods=['GET','POST'])
def index():
    form = FlowerForm()
    if form.validate_on_submit():
        session['sep_len'] = form.sep_len.data
        session['sep_wid'] = form.sep_wid.data
        session['pet_len'] = form.pet_len.data
        session['pet_wid'] = form.pet_wid.data
        
        return redirect(url_for(&quot;prediction&quot;))
    return render_template('home.html',form=form)


@app.route('/prediction',methods=['POST'])
def flower_prediction():
    content = {}
    content['sepal_length'] = float(session['sep_len'])
    content['sepal_width'] = float(session['sep_wid'])
    content['petal_length'] = float(session['pet_len'])
    content['petal_width'] = float(session['pet_wid'])
    
    results = return_prediction(model=flower_model,scaler=flower_scaler,sample_json=content)
    return render_template('prediction.html',results=results)


if __name__ == '__main__':
    app.run(debug=True)
</code></pre>
<p>Why is it not building the URL endpoint for 'prediction'?</p>
",38,0,-1,2,python;flask,2022-07-08 23:22:03,2022-07-08 23:22:03,2022-07-09 02:03:29,i m deploying a machine learning model with python through flask  however i m getting an error when i input the information for the model to process   however  after i input the values and press the button to analyze it  it shows me an error  in vs code where i made the flask back end programming  it says this  i also turned on an option for a debugger named werkzeug routing builderror to pop up in my browser and it said  flower_prediction is my function that calls the machine learning model to process the data  so i m unsure what to do next  i m a beginner to flask  so here is the code for the back end program  why is it not building the url endpoint for  prediction  ,flask error  werkzeug routing builderror  could not build url for endpoint    prediction     did you mean    flower_prediction    instead 
66,66,19510948,72912509,Machine Learning model to be deployed in Server less Azure cloud,"<p>Computer Vision Model I want to deploy into Azure Server less cloud. <code>__init__.py</code> is not responding to my main program.how to write serverless function</p>
",21,0,-1,5,python;azure;deployment;computer-vision;serverless,2022-07-08 19:26:52,2022-07-08 19:26:52,2022-07-08 21:41:47,computer vision model i want to deploy into azure server less cloud  __init__ py is not responding to my main program how to write serverless function,machine learning model to be deployed in server less azure cloud
67,67,18067785,72192511,ModuleNotFoundError: No module named &#39;pyarrow.lib&#39;,"<p>This is the full error message.</p>
<pre><code>Traceback (most recent call last):
  File &quot;C:\Users\adi\OneDrive\Desktop\Python310\machine learning project.py&quot;, line 3, in &lt;module&gt;
    import streamlit as st
  File &quot;C:\Users\adi\OneDrive\Desktop\Python310\lib\site-packages\streamlit\__init__.py&quot;, line 70, in &lt;module&gt;
    from streamlit.delta_generator import DeltaGenerator as _DeltaGenerator
  File &quot;C:\Users\adi\OneDrive\Desktop\Python310\lib\site-packages\streamlit\delta_generator.py&quot;, line 19, in &lt;module&gt;
    from streamlit import cursor, caching
  File &quot;C:\Users\adi\OneDrive\Desktop\Python310\lib\site-packages\streamlit\cursor.py&quot;, line 18, in &lt;module&gt;
    from streamlit.scriptrunner import get_script_run_ctx
  File &quot;C:\Users\adi\OneDrive\Desktop\Python310\lib\site-packages\streamlit\scriptrunner\__init__.py&quot;, line 16, in &lt;module&gt;
    from .script_runner import (
  File &quot;C:\Users\adi\OneDrive\Desktop\Python310\lib\site-packages\streamlit\scriptrunner\script_runner.py&quot;, line 35, in &lt;module&gt;
    from streamlit.state import (
  File &quot;C:\Users\adi\OneDrive\Desktop\Python310\lib\site-packages\streamlit\state\__init__.py&quot;, line 27, in &lt;module&gt;
    from .session_state_proxy import (
  File &quot;C:\Users\adi\OneDrive\Desktop\Python310\lib\site-packages\streamlit\state\session_state_proxy.py&quot;, line 24, in &lt;module&gt;
    from streamlit.type_util import Key
  File &quot;C:\Users\adi\OneDrive\Desktop\Python310\lib\site-packages\streamlit\type_util.py&quot;, line 22, in &lt;module&gt;
    import pyarrow as pa
  File &quot;C:\Users\adi\OneDrive\Desktop\Python310\lib\site-packages\pyarrow\__init__.py&quot;, line 65, in &lt;module&gt;
    import pyarrow.lib as _lib
</code></pre>
<p>I am working with streamlit for a project but can't work out this problem.
I have tried uninstalling and reinstalling streamlit but that did'nt help.</p>
<p>i using python 3.8</p>
",238,2,1,4,python;pyarrow;streamlit;facebook-prophet,2022-05-11 01:50:03,2022-05-11 01:50:03,2022-07-08 21:29:31,this is the full error message  i using python  ,modulenotfounderror  no module named    pyarrow lib   
68,68,17259565,72913971,Does my histogram display number of pixels?,"<p>I am doing some machine learning training on images and wanted to display the MSE losses between the train and test images in a histogram. Each image size is (512, 768, 3).</p>
<p>In the code below, pred and test_set are both arrays of the image pixel values and of length 512 each (i.e. 512 images)</p>
<pre><code>rain_loss = tf.keras.losses.mean_squared_error(pred[1], test_set[1])
plt.hist(train_loss, bins=50, alpha=0.5)
plt.xlabel(&quot;Train loss&quot;)
plt.ylabel(&quot;No of pixels&quot;)

plt.show()
</code></pre>
<p>This is the graph formed for image 1:</p>
<p><a href=""https://i.stack.imgur.com/K7NZZ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/K7NZZ.png"" alt=""1"" /></a></p>
<p>Now, I do not understand what this graph is actually representing. I initially thought it would be the number of pixels but the numbers don't add up, unless I am missing something?</p>
",26,0,-1,4,machine-learning;image-processing;deep-learning;neural-network,2022-07-08 21:21:52,2022-07-08 21:21:52,2022-07-08 21:26:38,i am doing some machine learning training on images and wanted to display the mse losses between the train and test images in a histogram  each image size is         in the code below  pred and test_set are both arrays of the image pixel values and of length  each  i e   images  this is the graph formed for image    now  i do not understand what this graph is actually representing  i initially thought it would be the number of pixels but the numbers don t add up  unless i am missing something ,does my histogram display number of pixels 
69,69,18298324,72831330,Incorrect Number of Dimensions on Train and Test Dataset,"<p>I am running a machine learning algorithms in a loop. Everything is working perfectly but at where I have to split and train the data, I get error saying incorrect number of dimensions.</p>
<ol>
<li>I have a data from UCI; heart disease</li>
<li>Now I am applying MCAR mechanism and imputations methods</li>
<li>Machine learning algorithms</li>
</ol>
<p>The data can be downloaded using this link (<a href=""https://www.kaggle.com//code//mchtklb//kalebasi-heart-disease-ml-modeling//data?select=heart.csv"" rel=""nofollow noreferrer"">https://www.kaggle.com//code//mchtklb//kalebasi-heart-disease-ml-modeling//data?select=heart.csv</a>)</p>
<p>This is the code from where the loop starts
p  &lt;- c(0.01,0.02) #generating prob of missing data
ip = 2 #number of imputations</p>
<pre><code>#MICE BINS
hd_mcar  &lt;- vector(mode = &quot;list&quot;, length = length(p))
mice_mcar &lt;- vector(mode = &quot;list&quot;, length = length(p))
app1 &lt;- vector(mode = &quot;list&quot;, length = length(p))
min1 &lt;- vector(mode = &quot;list&quot;, length = length(p))
sm1 &lt;- vector(mode = &quot;list&quot;, length = length(p))
final_clean_hd_mcar &lt;- vector(mode = &quot;list&quot;, length = length(p))
mice.mcar &lt;- vector(mode = &quot;list&quot;, length = length(p))


for(i in 1:length(p)){
  hd_mcar[[i]] &lt;- delete_MCAR(heart.ds, p[i])

                    
              #Applying Imputation
    
    
  ###1. Method(MICE)
  mice_mcar[[i]] &lt;- mice(hd_mcar[[i]], m=ip, method = c(&quot;pmm&quot;,&quot;logreg&quot;,&quot;polyreg&quot;,&quot;pmm&quot;,&quot;pmm&quot;,&quot;logreg&quot;,
                                            &quot;polyreg&quot;,&quot;pmm&quot;,&quot;logreg&quot;,&quot;pmm&quot;,&quot;polyreg&quot;,&quot;pmm&quot;,
                                            &quot;polyreg&quot;,&quot;logreg&quot;), maxit = 20)

  #Diagnostic check
  summary(heart.ds$age)
  mice_mcar[[i]]$imp$age


  #Finding the means of the impuatations
  app1[[i]] &lt;- apply(mice_mcar[[i]]$imp$age, MARGIN = 2, FUN = mean)
  min1[[i]] &lt;- abs(app1[[i]]-mean(heart.ds$age))
  
  #Selecting the minimum index
  sm1[[i]] &lt;- which(min1[[i]]==min(min1[[i]]))
  
  #Selecting final imputation
  final_clean_hd_mcar[[i]] =mice::complete(mice_mcar[[i]],sm1[[i]])
  mice.mcar[[i]] &lt;- final_clean_hd_mcar[[i]]


#MLA BINS
control &lt;- vector(mode = &quot;list&quot;, length = length(p))
results &lt;- vector(mode = &quot;list&quot;, length = length(p))
vimp &lt;- vector(mode = &quot;list&quot;, length = length(p))

#Feature Selection Using Recursive Feature Elimination
control[[i]] &lt;- rfeControl(functions=rfFuncs, method=&quot;cv&quot;, number=10)
# run the RFE algorithm
results[[i]] &lt;- rfe(mice.mcar[[i]][,1:13], mice.mcar[[i]][,14], sizes=c(1:13), rfeControl=control[[i]], metric = &quot;Accuracy&quot;)

# list the chosen features
predictors(results[[i]])


#BINS
n.heart.ds &lt;- vector(mode = &quot;list&quot;, length = length(p))
tr.dat &lt;- vector(mode = &quot;list&quot;, length = length(p))
TrainSet &lt;- vector(mode = &quot;list&quot;, length = length(p))
ValidSet &lt;- vector(mode = &quot;list&quot;, length = length(p))
fitControl &lt;- vector(mode = &quot;list&quot;, length = length(p))

#Re-selection from the Feature Selection
n.heart.ds[[i]] &lt;- mice.mcar[[i]][,-c(2,6,7,8,9,11)]

#Data Splitting
set.seed(1237)
tr.dat[[i]] &lt;- sample(nrow(n.heart.ds[[i]]), .7*nrow(n.heart.ds[[i]]), replace = FALSE)

TrainSet[[i]] &lt;- n.heart.ds[tr.dat[[i]],]
ValidSet[[i]] &lt;- n.heart.ds[-tr.dat[[i]],]
}
</code></pre>
<p>Now at the TrainSet, I get an error:</p>
<pre><code>Error in n.heart.ds[tr.dat[[i]], ] : incorrect number of dimensions
In addition: There were 50 or more warnings (use warnings() to see the first 50)
</code></pre>
<p>Please how do i solve the error on the Training and Validation dataset? I mean the dimension errors is printing</p>
",47,0,0,2,r;machine-learning,2022-07-01 20:44:18,2022-07-01 20:44:18,2022-07-08 16:22:37,i am running a machine learning algorithms in a loop  everything is working perfectly but at where i have to split and train the data  i get error saying incorrect number of dimensions  the data can be downloaded using this link    now at the trainset  i get an error  please how do i solve the error on the training and validation dataset  i mean the dimension errors is printing,incorrect number of dimensions on train and test dataset
70,70,18432393,72909820,Should I use object detection or segmentation? Detection by position rather than looks?,"<p>I am working on a project that needs to decide which olive tree branches should be cut. The goal is to detect the specific type of branch (watersprouts).</p>
<p>The problem I'm facing is that I'm unsure if I should use object detection (image classification + localization) or image segmentation. The difference between branches is mostly in their position with watersprouts growing mostly vertical to the main branch(there is a very small difference in looks between watersprouts and other branches) while other branches can grow in all ways (mostly parallel to the main branch).</p>
<p>My plan was to use object detection so I can classify watersprouts and localize them in the picture. I think that segmentation is a bit overkill for this problem because I don't see the need for localizing every pixel. The plan was to take pictures of watersprouts as class 1 and other branches as class 2, train them so I can detect them and localize. When I localize them I can now see which of these branches is a watersprout branch and which is a regular branch and then I know that watersprout should be cut.</p>
<p>The other problem I have is with understanding if it is possible for my machine learning project to recognize watersprouts not by their looks but by their position in regards to the main branch and correctly differentiate them from other branches because this is the main difference between watersprouts branch and regular branch. My understending is that the network learns how the object looks like and that position doesn't matter.</p>
<p>Am I on a right track or am I missing something?</p>
",23,0,-1,4,machine-learning;computer-vision;classification;image-segmentation,2022-07-08 15:37:12,2022-07-08 15:37:12,2022-07-08 16:03:25,i am working on a project that needs to decide which olive tree branches should be cut  the goal is to detect the specific type of branch  watersprouts   the problem i m facing is that i m unsure if i should use object detection  image classification   localization  or image segmentation  the difference between branches is mostly in their position with watersprouts growing mostly vertical to the main branch there is a very small difference in looks between watersprouts and other branches  while other branches can grow in all ways  mostly parallel to the main branch   my plan was to use object detection so i can classify watersprouts and localize them in the picture  i think that segmentation is a bit overkill for this problem because i don t see the need for localizing every pixel  the plan was to take pictures of watersprouts as class  and other branches as class   train them so i can detect them and localize  when i localize them i can now see which of these branches is a watersprout branch and which is a regular branch and then i know that watersprout should be cut  the other problem i have is with understanding if it is possible for my machine learning project to recognize watersprouts not by their looks but by their position in regards to the main branch and correctly differentiate them from other branches because this is the main difference between watersprouts branch and regular branch  my understending is that the network learns how the object looks like and that position doesn t matter  am i on a right track or am i missing something ,should i use object detection or segmentation  detection by position rather than looks 
71,71,14022684,72906803,how can I run python file in remote server using Paramiko?,"<p>I'm trying to execute a python script(machine learning) via remote server which has good resources.
And I'm trying to call remote python code in local environment with Paramiko library. (I send command to remote server, and that remote server will execute that command)</p>
<p>code in local environment is below:</p>
<pre><code>cli = paramiko.SSHClient()
cli.set_missing_host_key_policy(paramiko.AutoAddPolicy)
server = config['ip']
user = 'ubuntu'
pwd = config['pw']
cli.connect(server, username=user, password=pwd)
command=&quot;python my_code.py&quot;
stdin, stdout, stderr = cli.exec_command(command)
</code></pre>
<p>I send a command to remote server via above code. But, that doesn't work.
When the command is basic linux command (ex, ls -al, cd, pwd ...) those work.
But the remote server's cell does not recognize other commands like, python ~.py, conda activate, pip install...</p>
<p>My wonder is that, those commands are available when I directly connect to remote server's shell. see below:</p>
<p><a href=""https://i.stack.imgur.com/V2HSL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/V2HSL.png"" alt=""python command works"" /></a></p>
<p><a href=""https://i.stack.imgur.com/aaY1F.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/aaY1F.png"" alt=""pip command works"" /></a></p>
<p>I guess the bash that is opened when I directly connect is different from the bash that Paramiko handles. How can I handles this problem?
thanks sincerely</p>
",38,1,0,3,python;remote-access;paramiko,2022-07-08 10:26:11,2022-07-08 10:26:11,2022-07-08 12:49:14,code in local environment is below  my wonder is that  those commands are available when i directly connect to remote server s shell  see below   ,how can i run python file in remote server using paramiko 
72,72,11143347,72899762,upload a pre-trained model on databricks mlflow experiment,"<p>Is it possible to upload  a pre-trained machine learning model (from my local computer, for which I generated a model.pkl) on databricks, and serve it?
Or is it impossible on Databricks ?</p>
",27,0,0,4,machine-learning;databricks;mlflow;pre-trained-model,2022-07-07 20:08:21,2022-07-07 20:08:21,2022-07-08 12:25:10,,upload a pre trained model on databricks mlflow experiment
73,73,3317122,64418032,How do I reshape this Pandas dataframe?,"<p>I have the first dataframe in Pandas, which I'm trying to reshape to the second dataframe for supervised machine learning purposes. <code>[foo,bar]</code> represents a datapoint; each <code>id</code> has a definite label <code>[dog,cat]</code> and multiple datapoints. The final dataframe includes up to 3 datapoints in the order that they're initially given, using either truncation or zero-padding to achieve this goal.</p>
<pre class=""lang-py prettyprint-override""><code>   foo  bar  dog  cat   id
0  1.1  1.6    0    1   12
1  2.3  2.4    0    1   12
2  4.5  4.2    0    1   12
3  2.3  1.2    0    1   12
4  4.2  3.8    1    0  535
5  1.6  4.1    1    0  535
...
</code></pre>
<pre class=""lang-py prettyprint-override""><code> id  foo1  bar1  foo2  bar2  foo3  bar3  dog  cat
 12   1.1   1.6   2.3   2.4   4.5   4.2    0    1
535   4.2   3.8   1.6   4.1     0     0    1    0
...
</code></pre>
<p>I've tried calling <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot.html"" rel=""nofollow noreferrer""><code>pd.pivot()</code></a>, <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.stack.html"" rel=""nofollow noreferrer""><code>pd.stack()</code></a>, and <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.unstack.html"" rel=""nofollow noreferrer""><code>pd.unstack()</code></a>, but I haven't gotten anywhere. I also haven't been able to find what I'm trying to do on the <a href=""https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html"" rel=""nofollow noreferrer"">Pandas reshaping docs</a>.</p>
",53,1,-2,3,python;pandas;reshape,2020-10-19 02:00:49,2020-10-19 02:00:49,2022-07-08 10:37:07,i have the first dataframe in pandas  which i m trying to reshape to the second dataframe for supervised machine learning purposes   foo bar  represents a datapoint  each id has a definite label  dog cat  and multiple datapoints  the final dataframe includes up to  datapoints in the order that they re initially given  using either truncation or zero padding to achieve this goal  i ve tried calling     and   but i haven t gotten anywhere  i also haven t been able to find what i m trying to do on the  ,how do i reshape this pandas dataframe 
74,74,19507573,72906861,grid of mtry values while training random forests with ranger,"<p>I am working with a subset of the 'Ames Housing' dataset and have originally 17 features. Using the 'recipes' package, I have engineered the original set of features and created dummy variables for nominal predictors with the following code. That has resulted in 35 features in the 'baked_train' dataset below.</p>
<pre><code>blueprint &lt;- recipe(Sale_Price ~ ., data = _train) %&gt;%
      step_nzv(Street, Utilities, Pool_Area, Screen_Porch, Misc_Val) %&gt;%
      step_impute_knn(Gr_Liv_Area) %&gt;%
      step_integer(Overall_Qual) %&gt;%
      step_normalize(all_numeric_predictors()) %&gt;%
      step_other(Neighborhood, threshold = 0.01, other = &quot;other&quot;) %&gt;%
      step_dummy(all_nominal_predictors(), one_hot = FALSE)

prepare &lt;- prep(blueprint, data = ames_train)

baked_train &lt;- bake(prepare, new_data = ames_train)

baked_test &lt;- bake(prepare, new_data = ames_test)
</code></pre>
<p>Now, I am trying to train random forests with the 'ranger' package using the following code.</p>
<pre><code>cv_specs &lt;- trainControl(method = &quot;repeatedcv&quot;, number = 5, repeats = 5)

param_grid_rf &lt;- expand.grid(mtry = seq(1, 35, 1),
                             splitrule = &quot;variance&quot;,
                             min.node.size = 2)

rf_cv &lt;- train(blueprint,
           data = ames_train,
           method = &quot;ranger&quot;,
           trControl = cv_specs,
           tuneGrid = param_grid_rf,
           metric = &quot;RMSE&quot;)
</code></pre>
<p>I have set the grid of 'mtry' values based on the number of features in the 'baked_train' data. It is my understanding that 'caret' will apply the blueprint within each resample of 'ames_train' creating a baked version at each CV step.</p>
<p>The text Hands-On Machine Learning with R by Boehmke &amp; Greenwell says on section 3.8.3,</p>
<p><strong>Consequently, the goal is to develop our blueprint, then within each resample iteration we want to apply prep() and bake() to our resample training and validation data. Luckily, the caret package simplifies this process. We only need to specify the blueprint and caret will automatically prepare and bake within each resample.</strong></p>
<p>However, when I run the code above I get an error,</p>
<p><em>mtry can not be larger than number of variables in data. Ranger will EXIT now.</em></p>
<p>I get the same error when I specify 'tuneLength = 20' instead of the 'tuneGrid'. Although the code works fine when the grid of 'mtry' values is specified to be from 1 to 17 (the number of features in the original training data 'ames_train').</p>
<p>When I specify a grid of 'mtry' values from 1 to 17, info about the final model after CV is shown below. Notice that it mentions <strong>Number of independent variables: 35</strong> which corresponds to the 'baked_train' data, although specifying a grid from 1 to 35 throws an error.</p>
<pre><code>Type:                             Regression 
Number of trees:                  500 
Sample size:                      618 
Number of independent variables:  35 
Mtry:                             15 
Target node size:                 2 
Variable importance mode:         impurity 
Splitrule:                        variance 
OOB prediction error (MSE):       995351989 
R squared (OOB):                  0.8412147 
</code></pre>
<p>What am I missing here? Specifically, why do I have to specify the number of features in 'ames_train' instead of 'baked_train' when essentially 'caret' is supposed to create a baked version before fitting and evaluating the model for each resample?</p>
<p>Thanks.</p>
",15,0,0,4,random-forest;r-caret;r-recipes;r-ranger,2022-07-08 10:34:12,2022-07-08 10:34:12,2022-07-08 10:34:12,i am working with a subset of the  ames housing  dataset and have originally  features  using the  recipes  package  i have engineered the original set of features and created dummy variables for nominal predictors with the following code  that has resulted in  features in the  baked_train  dataset below  now  i am trying to train random forests with the  ranger  package using the following code  i have set the grid of  mtry  values based on the number of features in the  baked_train  data  it is my understanding that  caret  will apply the blueprint within each resample of  ames_train  creating a baked version at each cv step  the text hands on machine learning with r by boehmke  amp  greenwell says on section     consequently  the goal is to develop our blueprint  then within each resample iteration we want to apply prep   and bake   to our resample training and validation data  luckily  the caret package simplifies this process  we only need to specify the blueprint and caret will automatically prepare and bake within each resample  however  when i run the code above i get an error  mtry can not be larger than number of variables in data  ranger will exit now  i get the same error when i specify  tunelength     instead of the  tunegrid   although the code works fine when the grid of  mtry  values is specified to be from  to   the number of features in the original training data  ames_train    when i specify a grid of  mtry  values from  to   info about the final model after cv is shown below  notice that it mentions number of independent variables   which corresponds to the  baked_train  data  although specifying a grid from  to  throws an error  what am i missing here  specifically  why do i have to specify the number of features in  ames_train  instead of  baked_train  when essentially  caret  is supposed to create a baked version before fitting and evaluating the model for each resample  thanks ,grid of mtry values while training random forests with ranger
75,75,17271390,70802006,Clean Up Azure Machine Learning Blob Storage,"<p>I manage a frequently used Azure Machine Learning workspace. With several Experiments and active pipelines. Everything is working good so far. My problem is to get rid of old data from runs, experiments and pipelines. Over the last year the blob storage grew to enourmus size, because every pipeline data is stored.</p>
<p>I have deleted older runs from experimnents by using the gui, but the actual pipeline data on the blob store is not deleted. Is there a smart way to clean up data on the blob store from runs which have been deleted ?</p>
<p>On one of the countless Microsoft support pages, I found the following not very helpfull post:</p>
<p>*Azure does not automatically delete intermediate data written with OutputFileDatasetConfig. To avoid storage charges for large amounts of unneeded data, you should either:</p>
<ol>
<li>Programmatically delete intermediate data at the end of a pipeline
run, when it is no longer needed</li>
<li>Use blob storage with a short-term storage policy for intermediate data (see Optimize costs by automating Azure Blob Storage access tiers)</li>
<li>Regularly review and delete no-longer-needed data*</li>
</ol>
<p><a href=""https://docs.microsoft.com/en-us/azure/machine-learning/how-to-move-data-in-out-of-pipelines#delete-outputfiledatasetconfig-contents-when-no-longer-needed"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/machine-learning/how-to-move-data-in-out-of-pipelines#delete-outputfiledatasetconfig-contents-when-no-longer-needed</a></p>
<p>Any idea is welcome.</p>
",251,1,4,2,azure-blob-storage;azure-machine-learning-service,2022-01-21 18:53:46,2022-01-21 18:53:46,2022-07-08 09:37:43,i manage a frequently used azure machine learning workspace  with several experiments and active pipelines  everything is working good so far  my problem is to get rid of old data from runs  experiments and pipelines  over the last year the blob storage grew to enourmus size  because every pipeline data is stored  i have deleted older runs from experimnents by using the gui  but the actual pipeline data on the blob store is not deleted  is there a smart way to clean up data on the blob store from runs which have been deleted   on one of the countless microsoft support pages  i found the following not very helpfull post   azure does not automatically delete intermediate data written with outputfiledatasetconfig  to avoid storage charges for large amounts of unneeded data  you should either   any idea is welcome ,clean up azure machine learning blob storage
76,76,14038854,72905185,How to classify an unknown class from the test dataset if the training dataset never had that particular class in supervised machine learning,"<p>I have a training dataset whose features describe 2 classes (say dog and cat). But, my test dataset has more than 2 classes which are unknown. If I train and run SVM and Random forest on the training data, then it will not be able to find anything other species other than cat or dog on the test data.</p>
<p>Is there any algorithm to predict cat, dog or other species out of the test data? But still should be accurate enough to determine the cat and dog?</p>
<p>Sorry, if similar questions were asked. I checked quite some posts, but they were around 3 years old. So looking for any updated and efficient solutions.</p>
",15,0,-3,4,python;machine-learning;classification;supervised-learning,2022-07-08 04:52:11,2022-07-08 04:52:11,2022-07-08 04:52:11,i have a training dataset whose features describe  classes  say dog and cat   but  my test dataset has more than  classes which are unknown  if i train and run svm and random forest on the training data  then it will not be able to find anything other species other than cat or dog on the test data  is there any algorithm to predict cat  dog or other species out of the test data  but still should be accurate enough to determine the cat and dog  sorry  if similar questions were asked  i checked quite some posts  but they were around  years old  so looking for any updated and efficient solutions ,how to classify an unknown class from the test dataset if the training dataset never had that particular class in supervised machine learning
77,77,19457312,72826975,"I am working with Dask, what are the advantages of using Datashader for the dataviz instead of the classic Seaborn in Python?","<p>It is the first time I am working on a Machine Learning model with Dask, but before splitting the data I have to produce some visualisations of basic descriptive statistics. I have read that Datashader is &quot;smoother&quot; than Seaborn when working with Dask. What I don't understand is what makes that library optimal when parallelising with Dask. Is there any substantive advantage in terms of performance? By the way, I'm using the describe() method to calculate the descriptive statistics.</p>
<p>Thanks in advance.</p>
",25,1,-1,2,python;dask,2022-07-01 14:41:58,2022-07-01 14:41:58,2022-07-08 04:33:49,it is the first time i am working on a machine learning model with dask  but before splitting the data i have to produce some visualisations of basic descriptive statistics  i have read that datashader is  smoother  than seaborn when working with dask  what i don t understand is what makes that library optimal when parallelising with dask  is there any substantive advantage in terms of performance  by the way  i m using the describe   method to calculate the descriptive statistics  thanks in advance ,i am working with dask  what are the advantages of using datashader for the dataviz instead of the classic seaborn in python 
78,78,18311567,72904193,Why is time taken by O(NlogN) algorithm same as that of O(N^2)?,"<p>I wrote two functions <code>maxSubSum2</code> and <code>maxSubSum3</code>, both of which try to find the maximum continuous sum of a sub-sequence in a given sequence.</p>
<h2><code>maxSubSum2()</code></h2>
<ul>
<li>Loops through the entire vector and sets a beginning marker <code>i</code> on each iteration.</li>
<li>For each beginning marker <code>i</code> it sets a corresponding ending marker <code>j</code>.</li>
<li>The elements bound between these two markers form a valid sub-sequence; therefore, it calculates its sum.</li>
<li>And checks if it is greater than the previous highest sum.</li>
</ul>
<pre class=""lang-cpp prettyprint-override""><code>int maxSubSum2(const std::vector&lt;int&gt; &amp;v)
{
    int maxSum = 0;
    for(std::size_t begin = 0; begin &lt; v.size(); ++begin)
    {
        int thisSum = 0;
        for(std::size_t end = begin; end &lt; v.size(); ++end)
        {
            thisSum += v[end];
            if(thisSum &gt; maxSum)
                maxSum = thisSum;
        }
    }
    return maxSum;
}
</code></pre>
<h2><code>maxSubSum3()</code></h2>
<ul>
<li>Is itself a driver function to the recursive function <code>maxSumRec()</code>.</li>
<li><code>maxSumRec</code> uses divide-and-conquer to calculate the maximum sub-sequence sum.</li>
<li>The maximum sub-sequence sum can be either in the entirety of the left part, or right part, or it can between the two (in which case, it is the sum of maximum sum in left part which <strong>includes</strong> its border: <code>center</code>, and the maximum sum in right part which also <strong>includes</strong> its border: <code>center + 1</code>.</li>
</ul>
<pre class=""lang-cpp prettyprint-override""><code>int maxSubSum3(const std::vector&lt;int&gt; &amp;v)
{
    return maxSumRec(v, 0, v.size() - 1);
}

int maxSumRec(const std::vector&lt;int&gt; &amp;v, std::vector&lt;int&gt;::size_type left, std::vector&lt;int&gt;::size_type right)
{
    if(left == right)
        if(v[left] &gt; 0)
            return v[left];
        else
            return 0;
    std::vector&lt;int&gt;::size_type center = (left + right) / 2;
    int maxLeftSum = maxSumRec(v, left, center);
    int maxRightSum = maxSumRec(v, center + 1, right);
    int maxLeftBorderSum = 0;
    int leftBorderSum = 0;
    for(std::vector&lt;int&gt;::size_type idx = center; idx &lt; v.size(); --idx)
    {
        leftBorderSum += v[idx];
        if(leftBorderSum &gt; maxLeftBorderSum)
            maxLeftBorderSum = leftBorderSum;
    }
    int maxRightBorderSum = 0;
    int rightBorderSum = 0;
    for(std::vector&lt;int&gt;::size_type idx = center + 1; idx &lt;= right; ++idx)
    {
        rightBorderSum += v[idx];
        if(rightBorderSum &gt; maxRightBorderSum)
            maxRightBorderSum = rightBorderSum;
    }
    return max3(maxLeftSum, maxRightSum, maxLeftBorderSum + maxRightBorderSum);
}

int max3(int n1, int n2, int n3)
{
    if(n1 &gt;= n2 &amp;&amp; n1 &gt;= n3) return n1;
    if(n2 &gt;= n1 &amp;&amp; n2 &gt;= n3) return n2;
    if(n3 &gt;= n1 &amp;&amp; n3 &gt;= n2) return n3;
    return 0; // &lt;--- Should never happen
}
</code></pre>
<p>Because <code>maxSubSum2()</code> has a double nested <code>for</code> loops, its time complexity needs to be <strong>O(N)</strong>, and because <code>maxSubSum3()</code> uses divide and conquer, its time complexity needs to be <strong>O(NlogN)</strong>.</p>
<p>However, I created a simple running time calculation function <code>stopwatch()</code> to measure the actual running time <code>runtime</code> for each function. It looks like the following:</p>
<pre class=""lang-cpp prettyprint-override""><code>void stopwatch(int (*maxSubSumN)(const std::vector&lt;int&gt;&amp;), const std::vector&lt;int&gt; &amp;v)
{
    std::chrono::time_point start = std::chrono::steady_clock::now();
    maxSubSumN(v);
    std::chrono::time_point end = std::chrono::steady_clock::now();
    std::chrono::duration&lt;double&gt; runtime = end - start;
    std::cout &lt;&lt; std::fixed &lt;&lt; std::setprecision(9) &lt;&lt; std::left &lt;&lt; std::setw(9) &lt;&lt; runtime.count();
}
</code></pre>
<p>Before the program begins, I populate two vectors <code>small</code> and <code>big</code> with 1000 and 10000 randomly generated <code>int</code> respectively; like this:</p>
<pre class=""lang-cpp prettyprint-override""><code>int randInt()
{
    return std::rand() % 101 - 50;
}

void populate(std::vector&lt;int&gt; &amp;v)
{
    for(int &amp;i : v)
        i = randInt();
}

int main()
{
    std::srand(std::time(NULL));
    std::vector&lt;int&gt; small(1000);
    std::vector&lt;int&gt; big(10000);
    populate(small);
    populate(big);
    std::cout &lt;&lt; &quot;[OPTIMIZED BRUTE FORCE] \t: &quot;;
    stopwatch(maxSubSum2, small);
    std::cout &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;[OPTIMIZED BRUTE FORCE] \t: &quot;;
    stopwatch(maxSubSum2, big);
    std::cout &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;[DIVIDE AND CONQUER] \t\t: &quot;;
    stopwatch(maxSubSum3, small);
    std::cout &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;[DIVIDE AND CONQUER] \t\t: &quot;;
    stopwatch(maxSubSum3, big);
    std::cout &lt;&lt; std::endl;
    return 0;
}
</code></pre>
<p>However, after running the program several times, the execution time for both <code>maxSubSum2</code> and <code>maxSubSum3</code> is almost identical. Below are the results on my machine.</p>
<h2><code>small.size() == 10 &amp;&amp; big.size() == 100</code></h2>
<pre><code>[OPTIMIZED BRUTE FORCE]         : 0.000001015
[OPTIMIZED BRUTE FORCE]         : 0.000041509
[DIVIDE AND CONQUER]            : 0.000001789
[DIVIDE AND CONQUER]            : 0.000058110
</code></pre>
<h2><code>small.size() == 100 &amp;&amp; big.size() == 1000</code></h2>
<pre><code>[OPTIMIZED BRUTE FORCE]         : 0.000042093
[OPTIMIZED BRUTE FORCE]         : 0.003870208
[DIVIDE AND CONQUER]            : 0.000053203
[DIVIDE AND CONQUER]            : 0.003899243
</code></pre>
<h2><code>small.size() == 1000 &amp;&amp; big.size() == 10000</code></h2>
<pre><code>[OPTIMIZED BRUTE FORCE]         : 0.002765456
[OPTIMIZED BRUTE FORCE]         : 0.271172096
[DIVIDE AND CONQUER]            : 0.002931273
[DIVIDE AND CONQUER]            : 0.274476880
</code></pre>
<h2><code>small.size() == 1000 &amp;&amp; big.size() == 1000000</code></h2>
<pre><code>[OPTIMIZED BRUTE FORCE]         : 0.002730444
[OPTIMIZED BRUTE FORCE]         : 26.383375030
[DIVIDE AND CONQUER]            : 0.002903615
[DIVIDE AND CONQUER]            : 26.508168165
</code></pre>
<ul>
<li>Is there something that I did wrong in calculation of time complexities?</li>
<li>Did I make some mistake in the implementation of <code>maxSumRec</code> <em>it gives the right results though</em>?</li>
<li>Is there some other bottleneck in the implementation that I did not consider?</li>
<li>Or, is there something that I am missing or did not understand?</li>
</ul>
<p>Any help would be highly appreciated. For reference, I am learning from the book: <a href=""https://www.pearson.com/us/higher-education/program/Weiss-Data-Structures-and-Algorithm-Analysis-in-C-4th-Edition/PGM148299.html"" rel=""nofollow noreferrer"">Data Structures and Algorithms in C++ (4th Edition)</a>.</p>
<h2>Problem solved. Problematic part: use of overflowing integer</h2>
<p>See <a href=""https://stackoverflow.com/a/72904384/18311567"">interjay's answer below</a></p>
<pre class=""lang-cpp prettyprint-override""><code>for(std::vector&lt;int&gt;::size_type idx = center; idx &lt; v.size(); --idx)
</code></pre>
<blockquote>
<p>It makes a difference because the loop is only supposed to go down to left but you made it go down to 0. This changes the recursive call's runtime to O(n) instead of O(right - left), and the total runtime to O(n^2) because there are a total of O(n) recursive calls</p>
</blockquote>
<p><strong>Credits:</strong> <a href=""https://stackoverflow.com/users/189205/interjay"">interjay</a></p>
",98,1,2,4,c++;algorithm;c++11;time-complexity,2022-07-08 02:34:59,2022-07-08 02:34:59,2022-07-08 03:14:40,i wrote two functions maxsubsum and maxsubsum  both of which try to find the maximum continuous sum of a sub sequence in a given sequence  because maxsubsum   has a double nested for loops  its time complexity needs to be o n   and because maxsubsum   uses divide and conquer  its time complexity needs to be o nlogn   however  i created a simple running time calculation function stopwatch   to measure the actual running time runtime for each function  it looks like the following  before the program begins  i populate two vectors small and big with  and  randomly generated int respectively  like this  however  after running the program several times  the execution time for both maxsubsum and maxsubsum is almost identical  below are the results on my machine  any help would be highly appreciated  for reference  i am learning from the book    see  it makes a difference because the loop is only supposed to go down to left but you made it go down to   this changes the recursive call s runtime to o n  instead of o right   left   and the total runtime to o n   because there are a total of o n  recursive calls credits  ,why is time taken by o nlogn  algorithm same as that of o n   
79,79,17264096,72818690,How to identify curved lines in an image and take their lengths based on a scale,"<p>I am trying to automate the measurement of several curved lines based on a scale (see the example image). I have several images like the example one that I have to extract the measurement of each line. I have managed to binarize the image and have been searching for a solution with opencv in python. The procedure that I thought the algorithm should follow is something like:</p>
<ol>
<li>binarize the image</li>
<li>find the scale and set it for measurements</li>
<li>identify lines to be measured</li>
<li>measure lines based on scale</li>
<li>store measurements in a dataframe</li>
</ol>
<p>I am newbie with programming and been thinking in doing it with python. Should I apply a machine learning algorithm to segment each region containing each line and get their measurement? Or is there a simpler and more intuitive way of doing it without having to train a ML algorithm?</p>
<p><a href=""https://i.stack.imgur.com/JniYS.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/JniYS.png"" alt=""lines image"" /></a></p>
",74,2,1,5,python;image;opencv;image-processing;computer-vision,2022-06-30 21:20:58,2022-06-30 21:20:58,2022-07-08 00:16:39,i am trying to automate the measurement of several curved lines based on a scale  see the example image   i have several images like the example one that i have to extract the measurement of each line  i have managed to binarize the image and have been searching for a solution with opencv in python  the procedure that i thought the algorithm should follow is something like  i am newbie with programming and been thinking in doing it with python  should i apply a machine learning algorithm to segment each region containing each line and get their measurement  or is there a simpler and more intuitive way of doing it without having to train a ml algorithm  ,how to identify curved lines in an image and take their lengths based on a scale
80,80,19316680,72902042,How to determine the community affiliation of a set of nodes from a set of known communities containing the rest of nodes in a network?,"<p>I have a dictionary that contains the nodes and edges in an activity network diagram. I also have a dictionary that specifies the community corresponding to each node. Specifically, there is a community called &quot;Unknown&quot; that contains a good fraction of the nodes. This community is named as such since some of the nodes are not known to belong to any one of the other known communities. Do I need a machine learning algorithm to assign a community label (from the available ones) for those nodes that are missing community affiliation?</p>
<p>I would appreciate if you can put me on a right track for this problem.</p>
",23,0,0,5,machine-learning;graph;deep-learning;neural-network;network-analysis,2022-07-07 22:58:07,2022-07-07 22:58:07,2022-07-08 00:12:53,i have a dictionary that contains the nodes and edges in an activity network diagram  i also have a dictionary that specifies the community corresponding to each node  specifically  there is a community called  unknown  that contains a good fraction of the nodes  this community is named as such since some of the nodes are not known to belong to any one of the other known communities  do i need a machine learning algorithm to assign a community label  from the available ones  for those nodes that are missing community affiliation  i would appreciate if you can put me on a right track for this problem ,how to determine the community affiliation of a set of nodes from a set of known communities containing the rest of nodes in a network 
81,81,19503683,72899698,How can I check the gameobject that the script is attached to in order to use the same script on multiple gameobjects?,"<p>I've just started learning to use Unity and so far I've managed to solve the problems I've encountered. I tried not to post, but I couldn't find what I was looking for. </p>
<p>In my game, I have a machine that changes the players' sprites. I wanted to use the same script for multiple machines. The idea was to detect the game object (machine) and change the sprite accordingly. For example, the script detects that it is a green machine and changes the sprites to green or detects that it is a red machine and changes the sprites to red.</p>
<p>I hope I made myself clear. I tend to overcomplicate things...</p>
",37,1,0,2,c#;unity3d,2022-07-07 20:04:59,2022-07-07 20:04:59,2022-07-07 23:22:36,i ve just started learning to use unity and so far i ve managed to solve the problems i ve encountered  i tried not to post  but i couldn t find what i was looking for   in my game  i have a machine that changes the players  sprites  i wanted to use the same script for multiple machines  the idea was to detect the game object  machine  and change the sprite accordingly  for example  the script detects that it is a green machine and changes the sprites to green or detects that it is a red machine and changes the sprites to red  i hope i made myself clear  i tend to overcomplicate things   ,how can i check the gameobject that the script is attached to in order to use the same script on multiple gameobjects 
82,82,17394856,72897473,Can I separately train a classifier (e.g. SVM) with two different types of features and combine the results later?,"<p>I am a student and working on my first simple machine learning project. The project is about classifying articles into fake and true. I want to use SVM as classification algorithm and two different types of features:</p>
<ol>
<li>TF-IDF</li>
<li>Lexical Features like the count of exclamation marks and numbers</li>
</ol>
<p>I have figured out how to use the lexical features and TF-IDF as a features separately. However, I have not managed to figure out, how to combine them.</p>
<p><strong>Is it possible, to train and test two separate learning algorithms (one with TF-IDF and the other one with lexical features) and later combine the results?</strong></p>
<p>For example, can I calculate Accuracy, Precision and Recall for both separately and then take the average?</p>
",24,1,0,1,classification,2022-07-07 17:29:36,2022-07-07 17:29:36,2022-07-07 23:03:16,i am a student and working on my first simple machine learning project  the project is about classifying articles into fake and true  i want to use svm as classification algorithm and two different types of features  i have figured out how to use the lexical features and tf idf as a features separately  however  i have not managed to figure out  how to combine them  is it possible  to train and test two separate learning algorithms  one with tf idf and the other one with lexical features  and later combine the results  for example  can i calculate accuracy  precision and recall for both separately and then take the average ,can i separately train a classifier  e g  svm  with two different types of features and combine the results later 
83,83,19238612,72900440,How RandomOverSampler from imblearn is oversampling the data?,"<p>I am working on a machine learning problem in which I should determine if a particular asteroid correspond to a certain class, among 6 classes, or to another.
The dataset I am using is very unbalanced with respect to one class and if I use the RandomOverSampler class from the Imblearn model on python it works really well.
The point is that I would like to dig more how this class (RandomOverSampler) works, I have also read the paper that they link in the documentation (<a href=""https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html#imblearn.over_sampling.RandomOverSampler"" rel=""nofollow noreferrer"">https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html#imblearn.over_sampling.RandomOverSampler</a>) in the reference 1, but I didn't get if on default it is working oversampling the data just by duplicating or more or if there is a not naive way to do that.
When I say default it means just using the class with no parameters inside, I know it is not using for sure the SMOTE and the ADASYN techniques because there are separete classes for that, but I'd like to know if it is using the ROSE technique explained in the paper they link (<a href=""https://link.springer.com/article/10.1007/s10618-012-0295-5"" rel=""nofollow noreferrer"">https://link.springer.com/article/10.1007/s10618-012-0295-5</a>).</p>
<p>Thank you so much for your answer!</p>
",15,0,-1,5,python;dataset;random-forest;imbalanced-data;oversampling,2022-07-07 20:51:40,2022-07-07 20:51:40,2022-07-07 20:51:40,thank you so much for your answer ,how randomoversampler from imblearn is oversampling the data 
84,84,17499387,72897875,"Deep Reinforcement Learning, how to make an agent that control many machines","<p>Good morning, Im facing a &quot;RL&quot; problem, which have many constraints, the main idea is that my agent will control many different machines with for example ordering them to go out for doing their missions (we don't give importance for the mission), or ordering them to enter to the depot and choosing for them the right place where they should sit (depending from constraints).
The problem is: the agent will take decision at periods of time that are defined, for each periode we know which of actions (go out, go in) are allowed. He will for example at 8oclock decide to order for 4 machines to go out, and at 14oclock decide to bring back 2 machines(with choosing for them the right place).</p>
<p>In literature i show many ideas which refers to BDQ, but is it recquired for my problem ? Im thinking about having actions like [chooseMachine1, chooseMachine2,chooseMachine3...chooseMachineN, goOut, goInPlace1, goInPlace2, goInPlace3, goInPlace4]. And in the code specifying the logic that depending of the period we are, i expose for the begening a number M&lt;=N of the machines to choose (with giving 0 probability to those actions that aren't possible for the moment' if it is 14oclock you know that only the machines that are out are concerned with the agent decision'), if the agent choose Machine1, so he will access to only the possible actions from choosing it.</p>
<p>So, my question is, do you think that my ideas are right ? (am beginner), my idea is to make a DQN with giving the logic for the possible/impossible actions,
Do you think that a BDQ is more accurate with my problem ? like having N branchs for N machines which have the same possible actions (brach1(Machine1) : go out, goPlace1, goPlace2 ...)
If it is the case is there any implementation examples ?</p>
<p>If you have ressources to advise me, i will be glad of checking them.</p>
<p>Thank You</p>
",47,1,0,5,deep-learning;artificial-intelligence;reinforcement-learning;dqn;multi-agent-reinforcement-learning,2022-07-07 18:01:59,2022-07-07 18:01:59,2022-07-07 20:38:44,in literature i show many ideas which refers to bdq  but is it recquired for my problem   im thinking about having actions like  choosemachine  choosemachine choosemachine   choosemachinen  goout  goinplace  goinplace  goinplace  goinplace   and in the code specifying the logic that depending of the period we are  i expose for the begening a number m lt  n of the machines to choose  with giving  probability to those actions that aren t possible for the moment  if it is oclock you know that only the machines that are out are concerned with the agent decision    if the agent choose machine  so he will access to only the possible actions from choosing it  if you have ressources to advise me  i will be glad of checking them  thank you,deep reinforcement learning  how to make an agent that control many machines
85,85,7196912,72899661,Zorin Permanently change bluetooth headset name,"<p>So I have Zorin OS 16.1 and I am trying to permanently change the name of my bluetooth headset. I want to change it as we have several users that use the same model headset and it would help if we could change the name of the headset on their specific machine.</p>
<p>I tried to follow the answer from <a href=""https://askubuntu.com/questions/80960/how-to-change-bluetooth-broadcast-device-name"">https://askubuntu.com/questions/80960/how-to-change-bluetooth-broadcast-device-name</a></p>
<p>I get it to change the name, but as soon as I disconnect it then reconnect the headset it reverts back to the original name. Is what I am looking to do possible in Zorin?</p>
<p>I have tried changing the name withing /etc/bluetooth and /var/lib/bluetooth. Even tried creating a file called machine-info. Could use some guidance. I am still learning Linux as a whole.</p>
",13,0,0,1,bluetooth,2022-07-07 20:02:06,2022-07-07 20:02:06,2022-07-07 20:02:06,so i have zorin os   and i am trying to permanently change the name of my bluetooth headset  i want to change it as we have several users that use the same model headset and it would help if we could change the name of the headset on their specific machine  i tried to follow the answer from  i get it to change the name  but as soon as i disconnect it then reconnect the headset it reverts back to the original name  is what i am looking to do possible in zorin  i have tried changing the name withing  etc bluetooth and  var lib bluetooth  even tried creating a file called machine info  could use some guidance  i am still learning linux as a whole ,zorin permanently change bluetooth headset name
86,86,14350322,72896686,Cloud GPU for CNN projects,"<p>A project I worked on involved recognizing the arrow on a manometer and calculating the steam machine's pressure using OpenCV. Everything was live, so I used a web cam. Since accuracy was solely dependent upon external factors such as sharpness of the picture, light, darkness, etc., I was not satisfied with the results.</p>
<p>Now I plan to implement a deep learning solution for that case, i.e. train a neural network (probably CNN type) and use it the same way . However, the question is whether cloud GPU solutions are viable, especially when working with external devices, such as cameras, in real time. Due to security concerns, I've heard it's difficult to use web cam in Google Colab. Are there any other options? Thanks in advance.</p>
",13,0,-1,3,deep-learning;conv-neural-network;cloud,2022-07-07 16:33:22,2022-07-07 16:33:22,2022-07-07 17:36:52,a project i worked on involved recognizing the arrow on a manometer and calculating the steam machine s pressure using opencv  everything was live  so i used a web cam  since accuracy was solely dependent upon external factors such as sharpness of the picture  light  darkness  etc   i was not satisfied with the results  now i plan to implement a deep learning solution for that case  i e  train a neural network  probably cnn type  and use it the same way   however  the question is whether cloud gpu solutions are viable  especially when working with external devices  such as cameras  in real time  due to security concerns  i ve heard it s difficult to use web cam in google colab  are there any other options  thanks in advance ,cloud gpu for cnn projects
87,87,14027466,72896426,How to stabilize NN-model for timeseries prediction,"<p>I'm new to Machine Learning and Neural Nets and am experimenting with a configuration I found in a <a href=""https://iq.opengenus.org/time-series-prediction-techniques/"" rel=""nofollow noreferrer"">blog post</a>. I try to build a model to predict the value 4 time steps ahead of the last value fed to the model as a feature (window-size is flexibel). E.g. I give the model weeks 1-5 and want to get a prediction for week 9.</p>
<p>Currently I run into the challenge that the model is quite unstable. With this I mean that the predictions differ quite a lot if repeating the steps of data preparation, building a dataset, building and training the model and finally doing the forecasting.</p>
<p>Sometimes the forecast seems to fit quite nice, sometimes it seems to be inverted via a negativ sign and sometimes just the amplitude doesn't match while the directions are right (see the following screenshots).</p>
<p><a href=""https://i.stack.imgur.com/12Lxk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/12Lxk.png"" alt=""enter image description here"" /></a>
<a href=""https://i.stack.imgur.com/Wauis.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Wauis.png"" alt=""enter image description here"" /></a>
<a href=""https://i.stack.imgur.com/P64gg.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/P64gg.png"" alt=""enter image description here"" /></a>
<a href=""https://i.stack.imgur.com/jkF8M.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jkF8M.png"" alt=""enter image description here"" /></a></p>
<p>I thought that might has to something with the shuffling and size of shuffle_buffer, but this also happens for different sizes of shuffle_buffer, e.g. 20.</p>
<p><a href=""https://i.stack.imgur.com/EfQak.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/EfQak.png"" alt=""enter image description here"" /></a>
<a href=""https://i.stack.imgur.com/iqDWO.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/iqDWO.png"" alt=""enter image description here"" /></a></p>
<p>What is the reason for this behaviour and how to prevent this?</p>
<p>The code:</p>
<pre><code>#%% Initializing
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow import keras

#%% Defining the series
series = np.array([ 218,  555,  550,  563, 2492, 2848, 4041, 1302, 1040, 1073, 1392, 2093,
 1870, 2328, 2102, 2844, 1730, 2431, 1974, 2450, 1975, 1415, 2568, 2831,
 3011, 2576, 2825, 3327, 3539, 3392, 2949, 3283, 3854, 3918, 2639, 3826,
 3980, 3134, 3997, 2708, 3257, 3435, 3337, 2571, 3370, 4277, 3482, 2804,
 3253, 2979, 2458, 2306, 2482, 3209, 3915, 1292,  931, 2748, 2874, 2089,
 2660, 3205, 3093, 1389,  834, 1914, 2568, 2831, 2129, 3138, 2841, 2318,
 2653, 1598, 1779, 1529, 2190, 2180, 1737, 1845, 2511, 1922, 3679, 3277,
 2633, 2064, 2802, 2853, 2220, 1987, 2491, 1867, 3593, 1998, 2425, 3226,
 2143, 3466, 3327, 3283, 3011, 2552, 2844, 2501, 1575, 1829, 3086, 3345,
 1905, 1192, 2772, 3667, 4223, 4117, 2113, 2312, 2615, 3126, 2581, 3265,
 3682, 3355, 1820, 2989, 2806, 3333, 2395, 2777, 2189, 2628, 2379, 1867])


time = range(1, len(series)+1)

#%% Prepare Data for NN 
def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
  dataset = tf.data.Dataset.from_tensor_slices(series)
  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)
  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))
  dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-4], window[-1])) # :-4 because we want to predict the value in 4 weeks, not for the next week
  dataset = dataset.batch(batch_size).prefetch(1)
  return dataset

split_time = len(time)-16
time_train = time[:split_time]
x_train = series[:split_time]

# For normalization based on training data, so that model does not &quot;see&quot; the validation data before validation
train_mean = x_train.mean()
train_std = x_train.std()

x_train_norm = (x_train - train_mean) / train_std
series_norm = (series - train_mean) / train_std


time_valid = time[split_time:]
x_valid = series[split_time:]


def plot_series(time, series, format=&quot;-&quot;, start=0, end=None):
    plt.plot(time[start:end], series[start:end], format)
    plt.xlabel(&quot;Time&quot;)
    plt.ylabel(&quot;Value&quot;)
    plt.grid(True)

plt.figure(figsize=(10, 6))
plot_series(time_train, x_train)
plt.show()

plt.figure(figsize=(10, 6))
plot_series(time_valid, x_valid)
plt.show()

#%% Build the dataset
w_size = 4
b_size = 4
sb_size = 1
w_size_adjusted = w_size - 3

dataset = windowed_dataset(series_norm, window_size = w_size, batch_size = b_size, shuffle_buffer = sb_size)

#%% Build and train the model


l0 = tf.keras.layers.Dense(1, input_shape=[w_size_adjusted])
model = tf.keras.models.Sequential([l0])

model.compile(loss=&quot;mse&quot;, optimizer=tf.keras.optimizers.SGD(learning_rate=1e-6, momentum=0.9)) # original: learning_rat = 1e-6, also trid [... ].optimizers.Adam(learning_rate=1e-6)
model.fit(dataset,epochs=100,verbose=0)

#%% Forecast data
forecast = []

for time_step in range(len(series) - w_size_adjusted +1):
  forecast.append(model.predict(series_norm[time_step:time_step + w_size_adjusted][np.newaxis]))

forecast_subset = forecast[split_time - w_size_adjusted + 1:]
results_norm = np.array(forecast_subset)[:, 0, 0]

#%% Unnormalize

results = (results_norm * train_std)+train_mean


#%% Plot

plt.figure(figsize=(10, 6))

plot_series(time_valid, x_valid)
plot_series(time_valid, results)
plt.title('window_size: {0}, batch_size: {1}, shuffle_buffer: {2}'.format(w_size, b_size, sb_size))
</code></pre>
",37,1,1,3,python;tensorflow;machine-learning,2022-07-07 16:15:37,2022-07-07 16:15:37,2022-07-07 17:01:50,i m new to machine learning and neural nets and am experimenting with a configuration i found in a   i try to build a model to predict the value  time steps ahead of the last value fed to the model as a feature  window size is flexibel   e g  i give the model weeks   and want to get a prediction for week   currently i run into the challenge that the model is quite unstable  with this i mean that the predictions differ quite a lot if repeating the steps of data preparation  building a dataset  building and training the model and finally doing the forecasting  sometimes the forecast seems to fit quite nice  sometimes it seems to be inverted via a negativ sign and sometimes just the amplitude doesn t match while the directions are right  see the following screenshots   i thought that might has to something with the shuffling and size of shuffle_buffer  but this also happens for different sizes of shuffle_buffer  e g    what is the reason for this behaviour and how to prevent this  the code ,how to stabilize nn model for timeseries prediction
88,88,15393588,72896025,How do researchers calculate the differentiation of the energy function in the conference/journal papers?,"<p>I am a computer vision/graphics guy. Although nowadays machine learning solutions dominate the mainstream methods, sometimes we need to deal with classical solutions. For example, SLAM (simultaneous localization and mapping) and accurate 3D reconstructions.</p>
<p>When implementing conference papers such as CVPR (Computer Vision and Pattern Recognition) and SIGGRAPH, the biggest trouble for me is to calculate the derivatives of the energy function while the number of variables may be thousands.</p>
<p>I know analytical differentiation is a standard method to calculate the derivatives, but the energy functions can be very complex for programmers without strong math background to adopt analytical differentiation.</p>
<p>I was using numerical differentiation to calculate the derivatives of the energy functions. Numerical differentiation is not accurate but easy to implement.<br />
Sometimes you have to build a custom system while the existing software doesn't meet the requirement. I wonder how the other programmers and the paper authors implement the derivatives of energy functions. If they manually do the analytical differentiation, that's amazing.</p>
",9,0,0,3,computer-vision;derivative;differentiation,2022-07-07 15:42:07,2022-07-07 15:42:07,2022-07-07 15:42:07,i am a computer vision graphics guy  although nowadays machine learning solutions dominate the mainstream methods  sometimes we need to deal with classical solutions  for example  slam  simultaneous localization and mapping  and accurate d reconstructions  when implementing conference papers such as cvpr  computer vision and pattern recognition  and siggraph  the biggest trouble for me is to calculate the derivatives of the energy function while the number of variables may be thousands  i know analytical differentiation is a standard method to calculate the derivatives  but the energy functions can be very complex for programmers without strong math background to adopt analytical differentiation ,how do researchers calculate the differentiation of the energy function in the conference journal papers 
89,89,17765060,72893883,Is regularization in machine learning and deep learning same,"<p>As there are L1 , L2 , etc out and other technique are those all same for machine learning and deep learning while using Ml algorithm and DL algorithm</p>
",23,0,-1,2,machine-learning;deep-learning,2022-07-07 13:01:22,2022-07-07 13:01:22,2022-07-07 13:20:39,as there are l   l   etc out and other technique are those all same for machine learning and deep learning while using ml algorithm and dl algorithm,is regularization in machine learning and deep learning same
90,90,19338925,72889705,supervised machine learning prediction datatype,"<p>/* how can one set the datatype of the label column while using classifier to make prediction. I have a dataset whose label's column datatype is of int64 but I want my model to predict values in object datatype. I have tried to change the label columns datatype from int64 to object datatype by using astype() but when I make predictions my model returns me values in int64 and not in object datatype.  */</p>
<pre><code>convert_dict = {'Outcome': object
                
             }
  
df1 = df1.astype(convert_dict)
print(df1.dtypes)
</code></pre>
<p>/* following is the result*/</p>
<pre><code>Pregnancies                   int64
Glucose                       int64
BloodPressure                 int64
SkinThickness               float64
Insulin                       int64
BMI                         float64
DiabetesPedigreeFunction    float64
Age                           int64
Outcome                      object
dtype: object
       
</code></pre>
<p>/* but when I check the datatype of my predicted value after executing astype() I still get int64 datatype. */</p>
<pre><code>prediction=LogReg.predict([[0,13,40,35,168,43.1,2.288,33]])
print(prediction)
prediction.dtype
</code></pre>
<p>/* following is the result*/</p>
<pre><code>[0]
dtype('int64')
</code></pre>
<p>/* I want this predicted value to be object datatype every time I made a prediction. am I doing something wrong here. please guide*/</p>
",18,0,0,1,types,2022-07-07 02:20:38,2022-07-07 02:20:38,2022-07-07 12:27:54,   how can one set the datatype of the label column while using classifier to make prediction  i have a dataset whose label s column datatype is of int but i want my model to predict values in object datatype  i have tried to change the label columns datatype from int to object datatype by using astype   but when i make predictions my model returns me values in int and not in object datatype         following is the result      but when i check the datatype of my predicted value after executing astype   i still get int datatype        following is the result      i want this predicted value to be object datatype every time i made a prediction  am i doing something wrong here  please guide  ,supervised machine learning prediction datatype
91,91,17668281,72814539,Detectron2 - Same Code&amp;Data // Different platforms // highly divergent results,"<p>I use different hardware to benchmark multiple possibilites. The Code runs in a jupyter Notebook.</p>
<p>When i evaluate the different losses i get highly divergent results.</p>
<p>I also checked the full .cfg with <code>cfg.dump()</code> - it is completely consistent.</p>
<p><strong>Detectron2 Parameters:</strong></p>
<pre><code>cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file(&quot;COCO-Detection/retinanet_R_101_FPN_3x.yaml&quot;))
cfg.DATASETS.TRAIN = (&quot;dataset_train&quot;,)
cfg.DATASETS.TEST = (&quot;dataset_test&quot;,)
cfg.DATALOADER.NUM_WORKERS = 2
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(&quot;COCO-Detection/retinanet_R_101_FPN_3x.yaml&quot;)  # Let training initialize from model zoo
cfg.SOLVER.IMS_PER_BATCH = 2
cfg.SOLVER.BASE_LR = 0.00025  # 0.00125 pick a good LR
cfg.SOLVER.MAX_ITER = 1200    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset
cfg.SOLVER.STEPS = []        # do not decay learning rate
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # faster, and good enough for this toy dataset (default: 512)
#cfg.MODEL.ROI_HEADS.NUM_CLASSES = 25  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)
cfg.MODEL.RETINANET.NUM_CLASSES = 3
# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.
cfg.OUTPUT_DIR = &quot;/content/drive/MyDrive/Colab_Notebooks/testrun/output&quot;
cfg.TEST.EVAL_PERIOD = 25
cfg.SEED=5
</code></pre>
<hr />
<p><strong>1. Environment: Azure</strong></p>
<pre><code>Microsoft Azure - Machine Learning
STANDARD_NC6
Torch: 1.9.0+cu111
</code></pre>
<p><em><strong>Results</strong></em>:</p>
<p><a href=""https://i.stack.imgur.com/oKXID.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/oKXID.png"" alt=""Results Azure"" /></a></p>
<p><em><strong>Training Log:</strong></em> <a href=""https://pastebin.com/rBv2PQqY"" rel=""nofollow noreferrer"">Log Azure</a></p>
<hr />
<p><strong>2. Environment: Colab</strong></p>
<pre><code>GoogleColab free

Torch: 1.9.0+cu111 
</code></pre>
<p><em><strong>Results</strong></em>:</p>
<p><a href=""https://i.stack.imgur.com/uYQ6y.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/uYQ6y.png"" alt=""Results GoogleColab"" /></a></p>
<p><em><strong>Training Log:</strong></em> <a href=""https://pastebin.com/egVVUupP"" rel=""nofollow noreferrer"">Log Colab</a></p>
<hr />
<p><strong>EDIT:</strong></p>
<p><strong>3. Environment: Ubuntu</strong></p>
<pre><code>Ubuntu 22.04
RTX 3080
Torch: 1.9.0+cu111
</code></pre>
<p><em><strong>Results:</strong></em></p>
<p><a href=""https://i.stack.imgur.com/SzrG6.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/SzrG6.jpg"" alt=""enter image description here"" /></a></p>
<p><em><strong>Training Log:</strong></em> <a href=""https://pastebin.com/PwXMz4hY"" rel=""nofollow noreferrer"">https://pastebin.com/PwXMz4hY</a></p>
<hr />
<p><strong>New dataset</strong></p>
<p>Issue is not reproducible with a larger dataset:</p>
<p><a href=""https://i.stack.imgur.com/2IFaR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/2IFaR.png"" alt=""enter image description here"" /></a></p>
",70,0,3,5,machine-learning;computer-vision;conv-neural-network;object-detection;detectron,2022-06-30 16:22:53,2022-06-30 16:22:53,2022-07-07 12:19:54,i use different hardware to benchmark multiple possibilites  the code runs in a jupyter notebook  when i evaluate the different losses i get highly divergent results  i also checked the full  cfg with cfg dump     it is completely consistent  detectron parameters    environment  azure results   training log     environment  colab results   training log   edit    environment  ubuntu results   training log   new dataset issue is not reproducible with a larger dataset  ,detectron   same code amp data    different platforms    highly divergent results
92,92,19332126,72890588,extract rectangular area from noisy image,"<p>extract rectangular area from noisy image</p>
<p>I want to get the clean figure (right) from the noisy figure (left):</p>
<p><a href=""https://i.stack.imgur.com/cTDWN.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/cTDWN.png"" alt="""" /></a></p>
<p>To do this, I have a dataset with the noisy figure and its corresponding clean figures. When I put the algorithm into a noisy figure, I want it to estimate the clean figure. Which machine learning algorithm should I use to achieve this?</p>
<p>I know I will use Python, but I am unsure how to input this dataset and to which algorithm? I would appreciate any help provided.</p>
",20,1,-1,2,python;machine-learning,2022-07-07 04:14:34,2022-07-07 04:14:34,2022-07-07 04:21:27,extract rectangular area from noisy image i want to get the clean figure  right  from the noisy figure  left    to do this  i have a dataset with the noisy figure and its corresponding clean figures  when i put the algorithm into a noisy figure  i want it to estimate the clean figure  which machine learning algorithm should i use to achieve this  i know i will use python  but i am unsure how to input this dataset and to which algorithm  i would appreciate any help provided ,extract rectangular area from noisy image
93,93,13200965,72876754,It it possible to have data leakage from the training set to the test set in a Machine Learning data preprocessing?,"<p>I'm building this flowchart for a machine learning pipeline and during the data preprocessing I found myself wondering if is it possible to have data leakage (besides from test to train) also from train to test. I'd appreciate if someone could analyze my flowchart and say what you think.</p>
<p><a href=""https://i.stack.imgur.com/60jFu.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/60jFu.png"" alt=""enter image description here"" /></a></p>
",18,0,0,2,machine-learning;preprocessor,2022-07-06 05:50:23,2022-07-06 05:50:23,2022-07-07 04:03:27,i m building this flowchart for a machine learning pipeline and during the data preprocessing i found myself wondering if is it possible to have data leakage  besides from test to train  also from train to test  i d appreciate if someone could analyze my flowchart and say what you think  ,it it possible to have data leakage from the training set to the test set in a machine learning data preprocessing 
94,94,10755032,72884667,ML - How to avoid estimating prices that are more than 25 dollars off of the actual price in Machine Learning model?,"<p>I am currently working on a case study where I have to estimate how much a person makes by giving their property for rent. They provided me with a constraint which is as follows:</p>
<blockquote>
<p>&quot;avoid estimating prices that are more than 25 dollars off of the
actual price&quot;</p>
</blockquote>
<p>At first, I tried modeling without considering the constraint but failed miserably since the score I was getting is around 0.25. I did the training by using RandomForestRegressor along with RandomizedSearchCV. I used <code>.score</code> at last which gave me 0.25</p>
<p>So, I guess that constraint should be implemented for sure. As I am somewhat of a novice, I did not come across such a case before, therefore having no idea how to approach it.</p>
<p>The dataset I am using is: <a href=""https://www.kaggle.com/datasets/karthikbhandary2/property-rentals"" rel=""nofollow noreferrer"">https://www.kaggle.com/datasets/karthikbhandary2/property-rentals</a></p>
<p>For the sake of context I am sharing with you the full details of the case study:</p>
<blockquote>
<p>You have been hired by Inn the Neighborhood, an online platform that
allows people to rent out their properties for short stays. Currently,
the webpage for renters has a conversion rate of 2%. This means that
most people leave the platform without signing up.</p>
<p>The product manager would like to increase this conversion rate. They
are interested in developing an application to help people estimate
the money they could earn renting out their living space. They hope
that this would make people more likely to sign up.</p>
<p>The company has provided you with a dataset that includes details
about each property rented, as well as the price charged per night.
<strong>They want to avoid estimating prices that are more than 25 dollars off
of the actual price</strong>, as this may discourage people.</p>
</blockquote>
",42,0,-3,3,python;machine-learning;prediction,2022-07-06 19:14:09,2022-07-06 19:14:09,2022-07-06 22:00:38,i am currently working on a case study where i have to estimate how much a person makes by giving their property for rent  they provided me with a constraint which is as follows  at first  i tried modeling without considering the constraint but failed miserably since the score i was getting is around    i did the training by using randomforestregressor along with randomizedsearchcv  i used  score at last which gave me   so  i guess that constraint should be implemented for sure  as i am somewhat of a novice  i did not come across such a case before  therefore having no idea how to approach it  the dataset i am using is   for the sake of context i am sharing with you the full details of the case study ,ml   how to avoid estimating prices that are more than  dollars off of the actual price in machine learning model 
95,95,18021400,71930838,Protect python source code that runs as API,"<p>The company has built a python API with Machine Learning modules and we want to install this API on our customers' local server.</p>
<p>Of course, we don't want them to read the code, but when I try to use pyinstaller or pyarmor the fastAPI server can't understand the code anymore.</p>
<p>Is there a way to obfuscate or compile the python code and make it work with a server like fastapi with the uvicorn command?</p>
",88,0,0,5,python;api;compilation;obfuscation;fastapi,2022-04-20 01:46:42,2022-04-20 01:46:42,2022-07-06 21:53:42,the company has built a python api with machine learning modules and we want to install this api on our customers  local server  of course  we don t want them to read the code  but when i try to use pyinstaller or pyarmor the fastapi server can t understand the code anymore  is there a way to obfuscate or compile the python code and make it work with a server like fastapi with the uvicorn command ,protect python source code that runs as api
96,96,18216019,72886394,Making a AI that guess the number that the user is thinking python,"<p>The goal is that the user enters a number between 1-10 and AI tries to figure out what number the player picked.
For example I take the number: 6 and AI then tries to find out which number with 3 attempts.</p>
<p>AI learns which numbers are frequently chosen and tries them.</p>
<p>The problem is. I'm new to machine learning and thought this would be a good project to learn about machine learning. I can't find such a project anywhere and I don't know where to start. I've already asked this question on other platforms but it looks like nobody can help me.</p>
<p>I thought I use python, keras and tensorflow for that</p>
<p><strong>Has anyone done this before or know where it is?</strong></p>
<p>Thanks :)</p>
",41,1,-1,2,python;artificial-intelligence,2022-07-06 21:09:09,2022-07-06 21:09:09,2022-07-06 21:34:10,ai learns which numbers are frequently chosen and tries them  the problem is  i m new to machine learning and thought this would be a good project to learn about machine learning  i can t find such a project anywhere and i don t know where to start  i ve already asked this question on other platforms but it looks like nobody can help me  i thought i use python  keras and tensorflow for that has anyone done this before or know where it is  thanks   ,making a ai that guess the number that the user is thinking python
97,97,12587364,72882549,Comparing the predicted class for each instance of test data from different models,"<p>My test set data contains about 50,000 instances. I trained different machine learning models. Now I want to do some comparison to see for example if for every instance <code>x_i</code> that model A predicted as 0, models B and C also predicted that instance as 0.</p>
<p>For example, below are the first 5 predictions by the models.</p>
<pre><code>import pandas as pd

data = {'true_class': [3.0, 3.0, 3.0, 3.0, 3.0],
 'rf_pred': [3.0, 0.0, 0.0, 0.0, 0.0],
 'mlp_pred': [3.0, 0.0, 0.0, 0.0, 0.0],
 'knn_pred': [3.0, 0.0, 0.0, 0.0, 0.0],
 'lg_pred': [3.0, 0.0, 0.0, 0.0, 0.0],
 'ada_pred': [2.0, 2.0, 2.0, 2.0, 2.0]}

df = pd.DataFrame(data)
df
 true_class rf_pred mlp_pred knn_pred lg_pred ada_pred
0   3.0     3.0     3.0      3.0      3.0      2.0
1   3.0     0.0     0.0      0.0      0.0      2.0
2   3.0     0.0     0.0      0.0      0.0      2.0
3   3.0     0.0     0.0      0.0      0.0      2.0
4   3.0     0.0     0.0      0.0      0.0      2.0
</code></pre>
<p>Clearly predictions of <code>rf_pred, mlp_pred, knn_pred</code> &amp; <code>lg_pred</code> are the same for these five instances.</p>
<p>Is there any way to perform such analysis, per haps visually?</p>
",37,2,-1,5,python;python-3.x;machine-learning;classification;supervised-learning,2022-07-06 16:40:28,2022-07-06 16:40:28,2022-07-06 20:27:09,my test set data contains about   instances  i trained different machine learning models  now i want to do some comparison to see for example if for every instance x_i that model a predicted as   models b and c also predicted that instance as   for example  below are the first  predictions by the models  clearly predictions of rf_pred  mlp_pred  knn_pred  amp  lg_pred are the same for these five instances  is there any way to perform such analysis  per haps visually ,comparing the predicted class for each instance of test data from different models
98,98,6545834,38179829,How to load a .json file with python nltk,"<p>I'm trying to load a .json file from an output of an application so I can feed it into different machine learning algorithms so I can classify the text, problem is I can't seem to figure out why NLTK is not loading my .json file, even if I try it with their own .json file, it doesn't seem to work. From what I gather based on the book, I should only need to import 'nltk' and I can use the function 'load' from 'nltk.data'. Can somebody help me realise what I am doing wrong?</p>

<p>Below is the code I used to try loading my the file from nltk.</p>

<pre><code>import nltk
nltk.data.load('corpora/twitter_samples/negative_tweets.json')
</code></pre>

<p>After trying that out I got an error from it.</p>

<pre><code>C:\Python34\python.exe ""C:/Users/JarvinLi/PycharmProjects/ThesisTrial1/Trial Loading.py""
Traceback (most recent call last):
   File ""C:/Users/JarvinLi/PycharmProjects/ThesisTrial1/Trial Loading.py"", line 7, in &lt;module&gt;
     nltk.data.load('corpora/twitter_samples/negative_tweets.json')
  File ""C:\Python34\lib\site-packages\nltk\data.py"", line 810, in load
    resource_val = json.load(opened_resource)
  File ""C:\Python34\lib\json\__init__.py"", line 268, in load
    parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)
  File ""C:\Python34\lib\json\__init__.py"", line 312, in loads
    s.__class__.__name__))
TypeError: the JSON object must be str, not 'bytes'

Process finished with exit code 1
</code></pre>

<p>EDIT #1 : I'm using Python 3.4.1 and NLTK 3.</p>

<p>EDIT #2 : Below is another try I did but now using json.load()</p>

<pre><code>  import json
  json.load('corpora/twitter_samples/negative_tweets.json')
</code></pre>

<p>But I encountered a similar error</p>

<pre><code>C:\Python34\python.exe ""C:/Users/JarvinLi/PycharmProjects/ThesisTrial1/Trial Loading.py""
Traceback (most recent call last):
  File ""C:/Users/JarvinLi/PycharmProjects/ThesisTrial1/Trial Loading.py"", line 5, in &lt;module&gt;
    json.load('corpora/twitter_samples/quotefileNeg.json')
  File ""C:\Python34\lib\json\__init__.py"", line 265, in load
    return loads(fp.read(),
AttributeError: 'str' object has no attribute 'read'

Process finished with exit code 1
</code></pre>
",2406,1,0,3,python;json;nltk,2016-07-04 13:46:30,2016-07-04 13:46:30,2022-07-06 20:21:24,i m trying to load a  json file from an output of an application so i can feed it into different machine learning algorithms so i can classify the text  problem is i can t seem to figure out why nltk is not loading my  json file  even if i try it with their own  json file  it doesn t seem to work  from what i gather based on the book  i should only need to import  nltk  and i can use the function  load  from  nltk data   can somebody help me realise what i am doing wrong  below is the code i used to try loading my the file from nltk  after trying that out i got an error from it  edit     i m using python    and nltk   edit     below is another try i did but now using json load   but i encountered a similar error,how to load a  json file with python nltk
99,99,10868740,72884585,How to synchronize production and developement database,"<p>We want to implement a database for development purposes. We are currently developing on the production database (MSSQL 2019).
The application that accesses the database is a data intensive machine Learning process that runs every morning for ~5h. We have the following requirements:</p>
<p>Our desired architecture looks like this:</p>
<p><a href=""https://i.stack.imgur.com/tP6IX.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/tP6IX.jpg"" alt=""enter image description here"" /></a></p>
<p>We want:</p>
<ul>
<li>To have the customers data on both servers</li>
<li>Maintainers input quick fixes in production, these quick fixes are also applied to the development database</li>
<li>The developers add new tables and add further data to the database. On-Demand they deploy their changes to the production database.</li>
<li>Within both databases we have ETL tasks. We want to test our ETL tasks as well.</li>
</ul>
<p>We tried implementing this with SQL server replication. We transfered the production database with transactional replication to the development database.
However, this lead to key violations because the transactional replication from production and other tasks during developement led to the same primary key.
Is there a way to avoid these violations? Do you have other ideas to implement this?</p>
",33,0,-1,2,sql-server;database,2022-07-06 19:09:29,2022-07-06 19:09:29,2022-07-06 19:09:29,our desired architecture looks like this   we want ,how to synchronize production and developement database
100,100,14022554,72883416,Elegant way or common practice for passing a large number of parameters and file paths to python scripts?,"<p>At the moment I either use simple command line arguments, when there is only around 3-4 parameters, or I use separate input json files, when the parameter list becomes too bloated. The former seems user friendly when I have to pass the script to people that are unfamiliar with its functions, while the latter is good for reproducibility, as I can just copy the input json into the output folder along with the results. However, non of them feels very professional to me, nor efficient. The command line arguments simply turn chaotic when there are 5 different file locations and 10 different parameters needed (e.g.: for machine learning models), while for the json files, I'm not sure that I can expect non-IT users to edit those for the preferred parameters.</p>
<p>Is there a better way? Something more common practice?</p>
",21,0,0,3,python;json;shell,2022-07-06 17:46:26,2022-07-06 17:46:26,2022-07-06 17:46:26,at the moment i either use simple command line arguments  when there is only around   parameters  or i use separate input json files  when the parameter list becomes too bloated  the former seems user friendly when i have to pass the script to people that are unfamiliar with its functions  while the latter is good for reproducibility  as i can just copy the input json into the output folder along with the results  however  non of them feels very professional to me  nor efficient  the command line arguments simply turn chaotic when there are  different file locations and  different parameters needed  e g   for machine learning models   while for the json files  i m not sure that i can expect non it users to edit those for the preferred parameters  is there a better way  something more common practice ,elegant way or common practice for passing a large number of parameters and file paths to python scripts 
101,101,19494519,72883384,Adding 95% condifence ellipses to PCA in python,"<p>I have peformed a PCA of my experimental data, however i would like to add 95% confidence ellipses to the plot, one for each set of points. Could you help me?
This is the code I developed for the PCA. The iris dataset is used here as an example.</p>
<pre><code>import numpy as np
file = &quot;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&quot;
df = pd.read_csv(file, names=[sepal length','sepal width','petal length','petal width','target'])
from sklearn.preprocessing import StandardScaler
features = ['sepal length','sepal width','petal length','petal width']
x = df.loc[:, features].values
y = df.loc[:, ['target']].values
x = StandardScaler() .fit_transform(x)
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
principalComponents = pca.fit_transform(x)
principalDf = pd.DataFrame(data = principalComponents
             , columns = ['principal component 1', 'principal component 2'])
finalDF = pd.concat([principalDf, df[['target']]], axis = 1)
print(&quot;PCA Components&quot;, pca.components_) #array [ncomponents, nfeatures]
print(&quot;Explained Variance&quot;, pca.explained_variance_)  #var explained by each component
print(&quot;% Variance Explained&quot;, pca.explained_variance_ratio_) #percentage explained by each component

import matplotlib.pyplot as plt
fig = plt.figure(figsize = (8,8))
ax = fig.add_subplot(1,1,1)
ax.set_xlabel ('Principal Component 1', fontsize = 15)
ax.set_ylabel ('Principal Component 2', fontsize = 15)
ax.set_title ('PCA', fontsize = 20)
targets = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']


colors = ['r', 'g', 'b']


for target, color in zip(targets, colors):
    indicesToKeep = finalDF['target'] == target
    ax.scatter(finalDF.loc[indicesToKeep, 'principal component 1'], finalDF.loc[indicesToKeep, 'principal component 2'], c = color, s = 50)
    ax.legend(targets)
    ax.grid()
plt.savefig('PCA_test1.png')
plt.show()
plt.close()
</code></pre>
",13,0,0,4,python;pandas;pca;ellipse,2022-07-06 17:44:33,2022-07-06 17:44:33,2022-07-06 17:44:33,,adding   condifence ellipses to pca in python
102,102,13165659,72882083,What are drawbacks of serializing custom objects along with their definition?,"<p>My question is what future repercussions are conceivable when I &quot;force&quot; Python class/function definitions to be serialized along with the objects, by &quot;re-declaring&quot; them in <code>__main__</code> just before serialization.</p>
<p><strong>Details</strong></p>
<p>It is a common gotcha that Python libraries such as pickle and dill do not serialize class or function definitions along with the objects, if the definitions are not located in <code>__main__</code>.</p>
<p>As a result, when deserializing an object, its dependencies must be found in the same location as during serialization. This adds some overhead/inflexibility to deployment, as the definitions must be maintained in a separate package which must be versioned and present in the (production) environment.</p>
<p>I sometimes use the workaround of &quot;mainifying&quot; objects before serializing them, as described for instance by Oege Dijk <a href=""https://oegedijk.github.io/blog/pickle/dill/python/2020/11/10/serializing-dill-references.html"" rel=""nofollow noreferrer"">here</a>. It essentially redeclares the object's definition in <code>__main__</code> so that it will be serialized. The code I use is listed below.</p>
<p>So far this approach has worked well for all my (machine learning) workflows, for quite a while. Yet, it seems quite hacky, and I wonder whether it might cause problems down the line, and which. Of course, the ability to easily modify the serialized definitions is removed (e.g. bugfix). But that is something I can live with. Are there other dangers I am unaware of?</p>
<pre><code>import inspect
import types

def mainify(obj):
   
    if obj.__module__ != '__main__':                                                
        
        import __main__       
        is_func = True if isinstance(obj, types.FunctionType) else False                                                            
                                
        # Get source code and compile
        source = inspect.getsource(obj if is_func else obj.__class__)
        compiled = compile(source, '&lt;string&gt;', 'exec')                    

        # &quot;Declare&quot; in __main__ and keep track which key
        # of __main__ dict is new 
        pre = list(__main__.__dict__.keys()) 
        exec(compiled, __main__.__dict__)
        post = list(__main__.__dict__.keys())                        
        new_in_main = list(set(post) - set(pre))[0]
        
        # for function return mainified version, else assign new
        # class to obj and return object
        if is_func:
            obj = __main__.__dict__[new_in_main]            
        else:            
            obj.__class__ = __main__.__dict__[new_in_main]
                
    return obj
</code></pre>
",14,0,0,4,python;serialization;pickle;dill,2022-07-06 16:10:08,2022-07-06 16:10:08,2022-07-06 16:14:11,my question is what future repercussions are conceivable when i  force  python class function definitions to be serialized along with the objects  by  re declaring  them in __main__ just before serialization  details it is a common gotcha that python libraries such as pickle and dill do not serialize class or function definitions along with the objects  if the definitions are not located in __main__  as a result  when deserializing an object  its dependencies must be found in the same location as during serialization  this adds some overhead inflexibility to deployment  as the definitions must be maintained in a separate package which must be versioned and present in the  production  environment  i sometimes use the workaround of  mainifying  objects before serializing them  as described for instance by oege dijk   it essentially redeclares the object s definition in __main__ so that it will be serialized  the code i use is listed below  so far this approach has worked well for all my  machine learning  workflows  for quite a while  yet  it seems quite hacky  and i wonder whether it might cause problems down the line  and which  of course  the ability to easily modify the serialized definitions is removed  e g  bugfix   but that is something i can live with  are there other dangers i am unaware of ,what are drawbacks of serializing custom objects along with their definition 
103,103,19489199,72880499,Machine learning algorithm for correlation between indicators,"<p>I have a dataset with several indicators related to some geographical entities ,I want to study factors that influence an indicator A (among the other indicator) .I need to determine which indicators affect it the most (correlation)
which ML algo should I use
I want to have a kind of scoring function for my indicator A to allow its prediction</p>
<p><a href=""https://i.stack.imgur.com/xO9zv.png"" rel=""nofollow noreferrer"">enter image description here</a></p>
",30,2,0,5,algorithm;machine-learning;dataset;data-science;correlation,2022-07-06 14:21:13,2022-07-06 14:21:13,2022-07-06 16:10:14,,machine learning algorithm for correlation between indicators
104,104,9490832,57888291,How to properly pickle sklearn pipeline when using custom transformer,"<p>I am trying to pickle a sklearn machine-learning model, and load it in another project. The model is wrapped in pipeline that does feature encoding, scaling etc. The problem starts when i want to use self-written transformers in the pipeline for more advanced tasks. </p>

<p>Let's say I have 2 projects: </p>

<ul>
<li>train_project: it has the custom transformers in src.feature_extraction.transformers.py</li>
<li>use_project: it has other things in src, or has no src catalog at all</li>
</ul>

<p>If in ""train_project"" I save the pipeline with joblib.dump(), and then in ""use_project"" i load it with joblib.load() it will not find something such as ""src.feature_extraction.transformers"" and throw exception:</p>

<blockquote>
  <p>ModuleNotFoundError: No module named 'src.feature_extraction'</p>
</blockquote>

<p>I should also add that my intention from the beginning was to simplify usage of the model, so programist can load the model as any other model, pass very simple, human readable features, and all ""magic"" preprocessing of features for actual model (e.g. gradient boosting) is happening inside.</p>

<p>I thought of creating /dependencies/xxx_model/ catalog in root of both projects, and store all needed classes and functions in there (copy code from ""train_project"" to ""use_project""), so structure of projects is equal and transformers can be loaded. I find this solution extremely inelegant, because it would force the structure of any project where the model would be used.</p>

<p>I thought of just recreating the pipeline and all transformers inside ""use_project"" and somehow loading fitted values of transformers from ""train_project"".</p>

<p>The best possible solution would be if dumped file contained all needed info and needed no dependencies, and I am honestly shocked that sklearn.Pipelines seem to not have that possibility - what's the point of fitting a pipeline if i can not load fitted object later? Yes it would work if i used only sklearn classes, and not create custom ones, but non-custom ones do not have all needed functionality.</p>

<p>Example code:</p>

<p>train_project</p>

<p>src.feature_extraction.transformers.py</p>

<pre class=""lang-py prettyprint-override""><code>from sklearn.pipeline import TransformerMixin
class FilterOutBigValuesTransformer(TransformerMixin):
    def __init__(self):
        pass

    def fit(self, X, y=None):
        self.biggest_value = X.c1.max()
        return self

    def transform(self, X):
        return X.loc[X.c1 &lt;= self.biggest_value]
</code></pre>

<p>train_project</p>

<p>main.py</p>

<pre class=""lang-py prettyprint-override""><code>from sklearn.externals import joblib
from sklearn.preprocessing import MinMaxScaler
from src.feature_extraction.transformers import FilterOutBigValuesTransformer

pipeline = Pipeline([
    ('filter', FilterOutBigValuesTransformer()),
    ('encode', MinMaxScaler()),
])
X=load_some_pandas_dataframe()
pipeline.fit(X)
joblib.dump(pipeline, 'path.x')
</code></pre>

<p>test_project</p>

<p>main.py</p>

<pre class=""lang-py prettyprint-override""><code>from sklearn.externals import joblib

pipeline = joblib.load('path.x')
</code></pre>

<p>The expected result is pipeline loaded correctly with transform method possible to use.</p>

<p>Actual result is exception when loading the file.</p>
",13220,7,24,5,python;scikit-learn;persistence;pipeline;joblib,2019-09-11 17:06:03,2019-09-11 17:06:03,2022-07-06 15:41:48,i am trying to pickle a sklearn machine learning model  and load it in another project  the model is wrapped in pipeline that does feature encoding  scaling etc  the problem starts when i want to use self written transformers in the pipeline for more advanced tasks   let s say i have  projects   if in train_project i save the pipeline with joblib dump    and then in use_project i load it with joblib load   it will not find something such as src feature_extraction transformers and throw exception  modulenotfounderror  no module named  src feature_extraction  i should also add that my intention from the beginning was to simplify usage of the model  so programist can load the model as any other model  pass very simple  human readable features  and all magic preprocessing of features for actual model  e g  gradient boosting  is happening inside  i thought of creating  dependencies xxx_model  catalog in root of both projects  and store all needed classes and functions in there  copy code from train_project to use_project   so structure of projects is equal and transformers can be loaded  i find this solution extremely inelegant  because it would force the structure of any project where the model would be used  i thought of just recreating the pipeline and all transformers inside use_project and somehow loading fitted values of transformers from train_project  the best possible solution would be if dumped file contained all needed info and needed no dependencies  and i am honestly shocked that sklearn pipelines seem to not have that possibility   what s the point of fitting a pipeline if i can not load fitted object later  yes it would work if i used only sklearn classes  and not create custom ones  but non custom ones do not have all needed functionality  example code  train_project src feature_extraction transformers py train_project main py test_project main py the expected result is pipeline loaded correctly with transform method possible to use  actual result is exception when loading the file ,how to properly pickle sklearn pipeline when using custom transformer
105,105,4678218,72879855,how to classified and digitalized huge amount of paper using python,"<p>I have an archive papers in a company representing different business operation form different sections.
I want to scan all these documents and after that I want a way to classify all these scanned document into different category and sub-category based on custom preference such as (name, age, section, ..etc).</p>
<p>I want the end result to be digital files categorized according to the preferences that I set.</p>
<p>How can I do this using <strong>Python NLP</strong> or any other <strong>machine learning approach</strong></p>
",27,1,-2,3,python;nlp;document-classification,2022-07-06 13:32:50,2022-07-06 13:32:50,2022-07-06 15:12:59,i want the end result to be digital files categorized according to the preferences that i set  how can i do this using python nlp or any other machine learning approach,how to classified and digitalized huge amount of paper using python
106,106,12969291,72880184,SciPy optimization to a machine learning model,"<p>Recently I have been facing a problem which I think that SciPy might be a good candidate to solve. However, I have not been able to properly apply it. Not sure if I am missing something or if what I am looking for is actually not possible at all.</p>
<p>This is a fictitious example which I made to makes things more clear and easier to visualize. My case is way more complicated. However, what I want to find out is how many dogs and cats would there be given a specific number of rats?</p>
<pre><code>from sklearn.svm import SVR
from scipy.optimize import minimize
from sklearn.ensemble import RandomForestRegressor
import numpy as np
import pandas as pd

n_dogs = [10, 5, 5, 2, 19, 12, 1,2]
n_cats = [5, 100, 5, 3, 1000, 0, 1,2]
n_rats = [100, 0, 50, 30, 0, 1000, 10, 5]


X = np.array([n_dogs, n_cats]).T
y = np.array([n_rats]).T 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)    
model = RandomForestRegressor()
model.fit(X,y)

#Boundaries of condition
bnds = [(100,500), (100,150)]
#Initial guesses
x0 = [300,125]
#Predict from condition
residual_plant = minimize(lambda x: model.predict([[12,8]]), x0, method='SLSQP',bounds=bnds,options = {'eps': np.radians(5.0)})
print(residual_plant)```

</code></pre>
",30,0,0,4,python;numpy;scikit-learn;scipy,2022-07-06 13:57:37,2022-07-06 13:57:37,2022-07-06 13:57:37,recently i have been facing a problem which i think that scipy might be a good candidate to solve  however  i have not been able to properly apply it  not sure if i am missing something or if what i am looking for is actually not possible at all  this is a fictitious example which i made to makes things more clear and easier to visualize  my case is way more complicated  however  what i want to find out is how many dogs and cats would there be given a specific number of rats ,scipy optimization to a machine learning model
107,107,19345011,72879170,Deployment of Machine Learning models on KAFKA,"<p>Anyone having experience with deploying ML models on KAFKA.
if yes kindly refer to some useful links/sources or share your work for reference.</p>
",9,0,-1,4,machine-learning;apache-kafka;deployment;confluent-platform,2022-07-06 12:32:31,2022-07-06 12:32:31,2022-07-06 12:32:31,,deployment of machine learning models on kafka
108,108,19491907,72878566,AttributeError: module &#39;keras.api._v2.keras.experimental&#39; has no attribute &#39;export_saved_model&#39;,"<p>can anyone here help me fix this? i cant find the solution to this in the internet. also i am not good in python/machine learning</p>
<pre><code>tf.keras.experimental.export_saved_model(model, SHOE_SAVED_MODEL)
shoe_model = tf.keras.experimental.load_from_saved_model(SHOE_SAVED_MODEL,
custom_objects={'KerasLayer':hub.KerasLayer})



AttributeError                            Traceback (most recent call last)
&lt;ipython-input-20-82a8de315a24&gt; in &lt;module&gt;()
      2 
      3 SHOE_SAVED_MODEL = &quot;saved_models/shoe&quot;
----&gt; 4 tf.keras.experimental.export_saved_model(model, SHOE_SAVED_MODEL)
      5 shoe_model = tf.keras.experimental.load_from_saved_model(SHOE_SAVED_MODEL,
      6 custom_objects={'KerasLayer':hub.KerasLayer})

AttributeError: module 'keras.api._v2.keras.experimental' has no attribute 'export_saved_model'```
</code></pre>
",15,1,0,4,python;tensorflow;machine-learning;keras,2022-07-06 11:30:09,2022-07-06 11:30:09,2022-07-06 11:39:10,can anyone here help me fix this  i cant find the solution to this in the internet  also i am not good in python machine learning,attributeerror  module    keras api _v keras experimental    has no attribute    export_saved_model   
109,109,17350567,72876127,Machine Learning: multiple steps per turn,"<p>I have a question of understanding. I have an environment that passes possible actions and the state of the board to the agent. The agent chooses an action and stores it, together with the state, in a collection.</p>
<p>Now I have the problem that I have a board game where a chosen move might lead to possible other moves in the same turn. To make it clearer, let's say that I take an action and place my piece on square A. From the rules of the game it then follows that the piece from square A may go to square B or C in the same turn. So suddenly I have two new possibilities - in the same turn.</p>
<p>I have solved it as follows. The actions that are passed to the agent are only the next field. As soon as the agent has selected an action, it is stored in the collection together with the board. Afterwards, the environment is looked at to see if the piece can continue from the new position in the same round. If so, the agent decides which action he then selects, then saves this too and this continues until the figure can no longer move - then the next round begins.</p>
<p>Is it stupid to have implemented it this way? Doesn't the agent learn properly then?</p>
",24,1,1,2,machine-learning;reinforcement-learning,2022-07-06 03:50:16,2022-07-06 03:50:16,2022-07-06 03:59:15,i have a question of understanding  i have an environment that passes possible actions and the state of the board to the agent  the agent chooses an action and stores it  together with the state  in a collection  now i have the problem that i have a board game where a chosen move might lead to possible other moves in the same turn  to make it clearer  let s say that i take an action and place my piece on square a  from the rules of the game it then follows that the piece from square a may go to square b or c in the same turn  so suddenly i have two new possibilities   in the same turn  i have solved it as follows  the actions that are passed to the agent are only the next field  as soon as the agent has selected an action  it is stored in the collection together with the board  afterwards  the environment is looked at to see if the piece can continue from the new position in the same round  if so  the agent decides which action he then selects  then saves this too and this continues until the figure can no longer move   then the next round begins  is it stupid to have implemented it this way  doesn t the agent learn properly then ,machine learning  multiple steps per turn
110,110,19489959,72875600,Machine Learning question (Solving ValueError: could not convert string to float:),"<p><strong>I am running the example code Below:</strong></p>
<pre><code>import pandas as pd

from sklearn.tree import DecisionTreeClassifier

from sklearn.preprocessing import OneHotEncoder
</code></pre>
<p><a href=""https://i.stack.imgur.com/Hw0eT.png"" rel=""nofollow noreferrer"">How the CSV looks</a></p>
<pre><code>url_data = pd.read_csv('phishing_site_urls.csv')

url_data.drop_duplicates(inplace = True)
print(url_data.shape)


#X = input Data (Urls) // Y = output (Wether its Bad or Good)

X = url_data.drop(columns=['Label'])
y = url_data['Label']

model = DecisionTreeClassifier()

model.fit(X, y)
predictions = model.predict([[&quot;Paste suspected Phishy Link here&quot;]])

print(predictions)
</code></pre>
<p>**-Using a csv with the name phishing_site_urls.csv, that has two columns one named &quot;URL&quot; and the other &quot;Label&quot;. Where the URL column holds links that are either phishy or valid and the label column has a corresponding &quot;bad&quot; or &quot;good&quot; for determining which link in the URL column is phishy or valid.</p>
<p>-My question is I keep getting the error: &quot;ValueError: could not convert string to float:&quot; I assume there has to be some way of encoding the links from strings to floats so the model can run? If so I would appreciate some insight on how I can do this.**</p>
",40,1,1,2,python;machine-learning,2022-07-06 02:43:28,2022-07-06 02:43:28,2022-07-06 03:30:43,i am running the example code below      using a csv with the name phishing_site_urls csv  that has two columns one named  url  and the other  label   where the url column holds links that are either phishy or valid and the label column has a corresponding  bad  or  good  for determining which link in the url column is phishy or valid   my question is i keep getting the error   valueerror  could not convert string to float   i assume there has to be some way of encoding the links from strings to floats so the model can run  if so i would appreciate some insight on how i can do this   ,machine learning question  solving valueerror  could not convert string to float  
111,111,19489602,72875251,How to deal this task with machine learning?,"<h1>Question</h1>
<p>I'm trying to deal following task with machine learning, but the performance is not so good. Actually I'm not familiar with around machine learning and data science, so I don't have much acknowledgement. Don't you know there was some similar tasks in the past at like Kaggle?</p>
<h1>Task</h1>
<ul>
<li>The dataset is several queries and list of contents respect to each queries.</li>
<li>Contents in each queries have 0 or 1 as a label.</li>
<li>Almost all contents in each queries has 0 as a label.</li>
<li>There is only 1 or 0 content which has 1 as a label in each queries.</li>
<li>I wanna give the highest output from the model to the content which has 1 as a label in each queries.</li>
<li>I don't care about the order, difference of output from the model among contents with label 0, I just wanna bring content with label 1 at No.1 in each queries.</li>
<li>When the model gives exactly the same output to the all of contents, the content with label 1 will be No.1 of the ranking in the query, duh. But this doesn't have no meaning.</li>
</ul>
<h1>What I did</h1>
<p>At first, I didn't look the dataset by each queries, and I treated as a classification task to classify into 0 or 1. Let's say the model could classify a content with label 1 as 1, but sometimes there was content with label 0 classified as 1 with higher score than the content whose label is 1 in the same query. Actually the order (content whose label is 1 comes No.1 in each queries) is the most important thing, so I'm using &quot;Learn to Rank&quot; now.</p>
<h1>Problems I'm facing</h1>
<p>I'm visiting many website which describes on Learn to Rank, but I can't find the case like this, I don't know how can I call, like binary ranking.
Actually I'm using &quot;LambdaRank&quot; method, which scale the differential of loss function(cross entropy) because I'm expecting this method will contribute to bring the content with label 1 to the top of the list in each queries. And I'm using LightGBM or PyTorchBut now I'm facing several problems like this.</p>
<ul>
<li>Because almost all contents has 0 as their label, so the model can make loss small with predicting all of them are 0. Then, the slope of loss function is almost 0, so the training will not progress. Then, all of the contents is No.1 in the ranking.</li>
<li>(In PyTorch,) training is depends on the beginning of the training. In many cases, the model will predict all of the content is 0 at the 1st epoch of training. Then, the training will not progress as I said before. But, I'm not sure the reason, but sometimes, there is the content with label 1 at the top of ranking with about 10% of queries. In this case, the training will progress.</li>
<li>(Confirming with PyTorch is not yet) After training, about 80% of contents with label 1 is No.1 in their queries. But there is several queries who has no content with label 1, only has contents with label 0. Actually I wanna cut such queries, so I did score-cut but it was not effective. So, I guess there is no consistency of prediction among queries. Let's say there is 2 queries and predictions on each contents is like, query1[A:0.9, B:0.6, C:0.1] query2[D:0.7, E:0.2], then A is more relevant than D respect to each query?</li>
</ul>
<h1>Ideas but I've not tried yet</h1>
<p>Training will not progress due to a lot of contents with label 0.</p>
<ul>
<li>Use any other loss function like focal loss.</li>
<li>Use the differential of loss function at the prediction on content with label 1 for updating model parameters.
To reduce contents with label 0 at the No.1 in the ranking even if there is also the content with label 1 at the No.1,</li>
<li>Create custom metric which reduces them.</li>
<li>Create custom metric which compares the prediction of the content with label 1 and the content with the highest score in the list except for the content with label 1.</li>
<li>But I guess these metrics are not differentiable, but I think I can use for scaling differential of loss function instead of NDCG in LambdaRank method.</li>
</ul>
",23,0,0,3,machine-learning;deep-learning;kaggle,2022-07-06 02:05:37,2022-07-06 02:05:37,2022-07-06 02:05:37,i m trying to deal following task with machine learning  but the performance is not so good  actually i m not familiar with around machine learning and data science  so i don t have much acknowledgement  don t you know there was some similar tasks in the past at like kaggle  at first  i didn t look the dataset by each queries  and i treated as a classification task to classify into  or   let s say the model could classify a content with label  as   but sometimes there was content with label  classified as  with higher score than the content whose label is  in the same query  actually the order  content whose label is  comes no  in each queries  is the most important thing  so i m using  learn to rank  now  training will not progress due to a lot of contents with label  ,how to deal this task with machine learning 
112,112,17758340,72874722,How to configure SQL Server Machine Learning Services on Mac?,"<p>I'm trying to run Python within SQL Server using Machine Learning Services, however, I am having a really hard time getting started. I have SQL Server 2019 running/set up on Mac using Docker according to this <a href=""https://www.youtube.com/watch?v=glxE7w4D8v8&amp;t=301s"" rel=""nofollow noreferrer"">video</a>.</p>
<p>What I've tried to get Machine Learning Services working:</p>
<ul>
<li><p>Installing the Machine Learning extension for Azure Data Studio, including following listed prerequisites:</p>
<p>-Specifying the local path to a preexisting Python installation under Settings</p>
<p>-Microsoft ODBC driver 17 for SQL Server for macOS</p>
</li>
<li><p>Running the script (which runs successfully):</p>
</li>
</ul>
<pre><code>EXEC sp_configure 'external scripts enabled', 1 
RECONFIGURE WITH OVERRIDE
</code></pre>
<ul>
<li>After running the above script: disconnecting from the server, quitting Azure Data Studio, and either stopping or restarting the container</li>
</ul>
<p>However, whenever I attempt to run a piece of code like this:</p>
<pre><code>EXEC sp_execute_external_script
  @language = N'Python',
  @script=N'print(&quot;Hello World!&quot;)'
GO
</code></pre>
<p>I keep receiving the error:</p>
<blockquote>
<p>Msg 39111, Level 16, State 1, Procedure sp_execute_external_script, Line 1
The SQL Server Machine Learning Services End-User License Agreement (EULA) has not been accepted.</p>
</blockquote>
<p>I've followed other solutions, though all seem to be Windows oriented, such as restarting SQL Server services or Launchpad via Configuration Manager. Any help is much appreciated, thank you.</p>
",28,0,0,2,sql-server;sql-server-2019,2022-07-06 01:12:16,2022-07-06 01:12:16,2022-07-06 01:13:55,i m trying to run python within sql server using machine learning services  however  i am having a really hard time getting started  i have sql server  running set up on mac using docker according to this   what i ve tried to get machine learning services working  installing the machine learning extension for azure data studio  including following listed prerequisites   specifying the local path to a preexisting python installation under settings  microsoft odbc driver  for sql server for macos running the script  which runs successfully   however  whenever i attempt to run a piece of code like this  i keep receiving the error  i ve followed other solutions  though all seem to be windows oriented  such as restarting sql server services or launchpad via configuration manager  any help is much appreciated  thank you ,how to configure sql server machine learning services on mac 
113,113,19489442,72874254,"ValueError: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required","<p>So I'm new at programming and machine learning, and I'm using this code I found from a journal for spam detection. When I try to use it, the result turns out to be error, even though I already prepared the data correctly. The error message is 'ValueError: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required.'
Can anyone please help me out with this issue?
[The link for the complete code is here] (<a href=""https://github.com/ijdutse/spd"" rel=""nofollow noreferrer"">https://github.com/ijdutse/spd</a>)</p>
<pre><code>#!/usr/bin/env python3
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from collections import defaultdict, Counter
from datetime import datetime
import preprocessor as p
import random, os, utils, smart_open, json, codecs, pickle, time
import gensim
from gensim.models.doc2vec import Doc2Vec, TaggedDocument
from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from scipy.fftpack import fft

data_sources = ['I:\Data Penelitian\Iphone/iphone.json']

def main():
    spd = Spd(data_sources) #class instantiation
    start = time.process_time()
    relevant_tweets = spd.detector(data_sources)
    stop = time.process_time()
    return relevant_tweets




class Spd:
    &quot;&quot;&quot; some functions to accept raw files, extract relevant fields and filter our irrelevent content&quot;&quot;&quot;
    def __init__(self, data_sources):
        self.data_sources = data_sources
    pass
        
    # first function in the class:
    def extractor(self, data_sources): # accept list of files consisting of raw tweets in form of json object
        data_extracts = {'TweetID':[],'ScreenName':[],'RawTweets':[],'CreatedAt':[],'RetweetCount':[],\
                         'FollowersCount':[],'FriendsCount':[], 'StatusesCount':[],'FavouritesCount':[],\
                         'UserName':[],'Location':[],'AccountCreated':[],'Language':[],'Description':[],\
                         'UserURL':[],'VerifiedAccount':[],'CleanTweets':[],'UserID':[], 'TimeZone':[],'TweetFavouriteCount':[]}
        non_english_tweets = 0 # keep track of the non-English tweets
        with codecs.open('I:\Data Penelitian\Iphone/iphone.json', 'r') as f: # data_source is read from extractor() function
            for line in f.readlines():
                non_English = 0
                try:
                    line = json.loads(line)
                    if line['lang'] in ['en','en-gb','en-GB','en-AU','en-IN','en_US']:
                        data_extracts['Language'].append(line['Language'])
                        data_extracts['TweetID'].append(line['TweetID'])
                        data_extracts['RawTweets'].append(line['RawTweets'])
                        data_extracts['CleanTweets'].append(p.clean(line['RawTweets']))
                        data_extracts['CreatedAt'].append(line['CreatedAt'])
                        data_extracts['AccountCreated'].append(line['AccountCreated'])                       
                        data_extracts['ScreenName'].append(line['ScreenName'])                          
                        data_extracts['RetweetCount'].append(line['RetweetCount'])
                        data_extracts['FollowersCount'].append(line['FollowersCount'])
                        data_extracts['FriendsCount'].append(line['FriendsCount'])
                        data_extracts['StatusesCount'].append(line['StatusesCount'])
                        data_extracts['FavouritesCount'].append(line['FavouritesCount'])
                        data_extracts['UserName'].append(line['UserName'])
                        data_extracts['Location'].append(line['Location'])
                        data_extracts['Description'].append(line['Description'])
                        data_extracts['UserURL'].append(line['UserURL'])
                        data_extracts['VerifiedAccount'].append(line['VerifiedAccount'])
                        data_extracts['UserID'].append(line['UserID'])
                        data_extracts['TimeZone'].append(line['TimeZone'])
                        data_extracts['TweetFavouriteCount'].append(line['TweetFavouriteCount'])
                    else:
                        non_english_tweets +=1
                except:
                    continue
            df0 = pd.DataFrame(data_extracts) #convert data extracts to pandas DataFrame
            df0['CreatedAt']=pd.to_datetime(data_extracts['CreatedAt'],errors='coerce') # convert to datetime
            df0['AccountCreated']=pd.to_datetime(data_extracts['AccountCreated'],errors='coerce')
            df0 = df0.dropna(subset=['AccountCreated','CreatedAt']) # drop na in datetime
            AccountAge = [] # compute the account age of accounts
            date_format = &quot;%Y-%m-%d  %H:%M:%S&quot;
            for dr,dc in zip(df0.CreatedAt, df0.AccountCreated):
                #try:
                dr = str(dr)
                dc = str(dc)
                d1 = datetime.strptime(dr,date_format)
                d2 = datetime.strptime(dc,date_format)
                dif = d1 - d2
                AccountAge.append(dif.days)
                #except:
                    #continue
            df0['AccountAge']=AccountAge
            # add/define additional features ...
            df0['Retweets'] = df0.RawTweets.apply(lambda x: str(x).split()[0]=='RT' )
            df0['RawTweetsLen'] = df0.RawTweets.apply(lambda x: len(str(x))) # modified
            df0['DescriptionLen'] = df0.Description.apply(lambda x: len(str(x)))
            df0['UserNameLen'] = df0.UserName.apply(lambda x: len(str(x)))
            df0['ScreenNameLen'] = df0.ScreenName.apply(lambda x: len(str(x)))
            df0['LocationLen'] = df0.Location.apply(lambda x: len(str(x)))
            df0['Activeness'] = df0.StatusesCount.truediv(df0.AccountAge)
            df0['Friendship'] = df0.FriendsCount.truediv(df0.FollowersCount)
            df0['Followership'] = df0.FollowersCount.truediv(df0.FriendsCount)
            df0['Interestingness'] = df0.FavouritesCount.truediv(df0.StatusesCount)
            df0['BidirFriendship'] = (df0.FriendsCount + df0.FollowersCount).truediv(df0.FriendsCount)
            df0['BidirFollowership'] = (df0.FriendsCount + df0.FollowersCount).truediv(df0.FollowersCount)
            df0['NamesRatio'] = df0.ScreenNameLen.truediv(df0.UserNameLen)
            df0['CleanTweetsLen'] = df0.CleanTweets.apply(lambda x: len(str(x)))
            df0['LexRichness'] = df0.CleanTweetsLen.truediv(df0.RawTweetsLen)       
            # Remove all RTs, set UserID as index and save relevant files:
            df0 = df0[df0.Retweets.values==False] # remove retweets
            df0 = df0.set_index('UserID')
            df0 = df0[~df0.index.duplicated()] # remove duplicates in the tweet
            #df0.to_csv(data_source[:15]+'all_extracts.csv') #save all extracts as csv
            df0.to_csv(data_sources[:5]+'all_extracts.csv') #save all extracts as csv 
            with open(data_sources[:5]+'non_English.txt','w') as d: # save count of non-English tweets
                d.write('{}'.format(non_english_tweets))
                d.close()
        return df0

    
    def detector(self, data_sources): # accept list of raw tweets as json objects
        self.data_sources = data_sources
        for data_sources in data_sources:
            self.data_sources = data_sources
            df0 = self.extractor(data_sources)
            #drop fields not required for predicition
            X = df0.drop(['Language','TweetID','RawTweets','CleanTweets','CreatedAt','AccountCreated','ScreenName',\
                 'Retweets','UserName','Location','Description','UserURL','VerifiedAccount','RetweetCount','TimeZone','TweetFavouriteCount'], axis=1)
            X = X.replace([np.inf,-np.inf],np.nan) # replace infinity values to avoid 0 division ...
            X = X.dropna()
            # reload the trained model for use:
            spd_filter=pickle.load(open('trained_rf.pkl','rb'))
            PredictedClass = spd_filter.predict(X) # Predict spam or automated accounts/tweets:
            X['PredictedClass'] = PredictedClass # include the predicted class in the dataframe
            nonspam = df0.loc[X.PredictedClass.values==1] # sort out the nonspam accounts
            spam = df0.loc[X.PredictedClass.values==0] # sort out spam/automated accounts
            #relevant_tweets = nonspam[['CreatedAt', 'CleanTweets']]
            relevant_tweets = nonspam[['CreatedAt','AccountCreated','ScreenName','Location','TimeZone','Description','VerifiedAccount','RawTweets', 'CleanTweets','TweetFavouriteCount','Retweets']]
            relevant_tweets = relevant_tweets.reset_index() # reset index and remove it from the dataframe
            #relevant_tweets = relevant_tweets.drop('UserID', axis=1) 
            # save files:
            X.to_csv(data_source[:5]+'_all_predicted_classes.csv') #save all extracts as csv, used to be 15
            nonspam.to_csv(data_source[:5]+'_nonspam_accounts.csv')
            spam.to_csv(data_source[:5]+'_spam_accounts.csv')
            relevant_tweets.to_csv(data_source[:5]+'_relevant_tweets.csv') # relevant tweets for subsequent analysis
        return relevant_tweets # or return relevant_tweets, nonspam, spam

if __name__ =='__main__':
    main()
</code></pre>
<p>The traceback error is as follow</p>
<pre><code>ValueError                                Traceback (most recent call last)
&lt;ipython-input-2-5dc56f49d005&gt; in &lt;module&gt;
    142 
    143 if __name__ =='__main__':
--&gt; 144     main()

&lt;ipython-input-2-5dc56f49d005&gt; in main()
     18     spd = Spd(data_sources) #class instantiation
     19     start = time.process_time()
---&gt; 20     relevant_tweets = spd.detector(data_sources)
     21     stop = time.process_time()
     22     return relevant_tweets

&lt;ipython-input-2-5dc56f49d005&gt; in detector(self, data_sources)
    126             # reload the trained model for use:
    127             spd_filter=pickle.load(open('trained_rf.pkl','rb'))
--&gt; 128             PredictedClass = spd_filter.predict(X) # Predict spam or automated accounts/tweets:
    129             X['PredictedClass'] = PredictedClass # include the predicted class in the dataframe
    130             nonspam = df0.loc[X.PredictedClass.values==1] # sort out the nonspam accounts

~\Anaconda3\lib\site-packages\sklearn\ensemble\forest.py in predict(self, X)
    543             The predicted classes.
    544         &quot;&quot;&quot;
--&gt; 545         proba = self.predict_proba(X)
    546 
    547         if self.n_outputs_ == 1:

~\Anaconda3\lib\site-packages\sklearn\ensemble\forest.py in predict_proba(self, X)
    586         check_is_fitted(self, 'estimators_')
    587         # Check data
--&gt; 588         X = self._validate_X_predict(X)
    589 
    590         # Assign chunk of trees to jobs

~\Anaconda3\lib\site-packages\sklearn\ensemble\forest.py in _validate_X_predict(self, X)
    357                                  &quot;call `fit` before exploiting the model.&quot;)
    358 
--&gt; 359         return self.estimators_[0]._validate_X_predict(X, check_input=True)
    360 
    361     @property

~\Anaconda3\lib\site-packages\sklearn\tree\tree.py in _validate_X_predict(self, X, check_input)
    389         &quot;&quot;&quot;Validate X whenever one tries to predict, apply, predict_proba&quot;&quot;&quot;
    390         if check_input:
--&gt; 391             X = check_array(X, dtype=DTYPE, accept_sparse=&quot;csr&quot;)
    392             if issparse(X) and (X.indices.dtype != np.intc or
    393                                 X.indptr.dtype != np.intc):

~\Anaconda3\lib\site-packages\sklearn\utils\validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)
    548                              &quot; minimum of %d is required%s.&quot;
    549                              % (n_samples, array.shape, ensure_min_samples,
--&gt; 550                                 context))
    551 
    552     if ensure_min_features &gt; 0 and array.ndim == 2:

ValueError: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required.
</code></pre>
",50,0,0,2,python;scikit-learn,2022-07-06 00:22:11,2022-07-06 00:22:11,2022-07-06 01:09:02,the traceback error is as follow,valueerror  found array with  sample s   shape       while a minimum of  is required
114,114,19489272,72874070,How do I predict on Keras LSTM model?,"<p>I'm trying to implement time-series forecasting using an LSTM model. My input data are timestamps, where x is the start time of a cycle and y is the end time of a cycle. (Example: timestamps for <code>2021-12-31 19:16:14.337738</code> as start time and <code>2021-12-31 19:16:23.768758</code> for end time).</p>
<p>I've split my training set to be 80% of total data and am passing it in as parameters in model.fit(), where my model is defined as:</p>
<pre><code>model = Sequential()
model.add(LSTM(64, activation='relu', return_sequences=True, input_shape=(2, 2)))
model.add(BatchNormalization())
model.add(Dense(10))
model.compile(optimizer='adam', loss='mse', metrics=[&quot;accuracy&quot;])
</code></pre>
<p>Afterwards, I use <code>model.predict()</code> on my x-values (cycle start times) of my testing set which is 20% of my data. I am trying to obtain y-values (cycle end times) for the given x-values but all I'm getting are nans:</p>
<pre><code>yhat = model.predict(np.array(x_input))
print(yhat)
</code></pre>
<p>Output:</p>
<pre><code>[[[nan nan nan ... nan nan nan]
  [nan nan nan ... nan nan nan]]

 [[nan nan nan ... nan nan nan]
  [nan nan nan ... nan nan nan]]

 [[nan nan nan ... nan nan nan]
  [nan nan nan ... nan nan nan]]

 ...

 [[nan nan nan ... nan nan nan]
  [nan nan nan ... nan nan nan]]

 [[nan nan nan ... nan nan nan]
  [nan nan nan ... nan nan nan]]

 [[nan nan nan ... nan nan nan]
  [nan nan nan ... nan nan nan]]]
</code></pre>
<p>How do I get the model to predict the y-values I need and not nans? I'm very new to machine learning and have never worked with it before so I'm not really sure what I'm doing or where I'm going wrong.</p>
<p>Thank you for any help!</p>
",19,0,0,3,python;dataframe;nan,2022-07-06 00:03:11,2022-07-06 00:03:11,2022-07-06 00:06:31,i m trying to implement time series forecasting using an lstm model  my input data are timestamps  where x is the start time of a cycle and y is the end time of a cycle   example  timestamps for        as start time and        for end time   i ve split my training set to be   of total data and am passing it in as parameters in model fit    where my model is defined as  afterwards  i use model predict   on my x values  cycle start times  of my testing set which is   of my data  i am trying to obtain y values  cycle end times  for the given x values but all i m getting are nans  output  how do i get the model to predict the y values i need and not nans  i m very new to machine learning and have never worked with it before so i m not really sure what i m doing or where i m going wrong  thank you for any help ,how do i predict on keras lstm model 
115,115,9749124,72872978,Split text into sentences without NLTK,"<p>I want to split large text into sentences.
I know how to do that with NLTK but I do not know how to do that without it.</p>
<p>This is my text, it has 8 sentences:</p>
<pre><code>import re
import nltk

text = &quot;&quot;&quot;Machine learning (ML) is the study of computer algorithms that can improve automatically through experience and by the use of data. 
        It is seen as a part of artificial intelligence. 
        Machine learning algorithms build a model based on sample data, known as training data, in order to make predictions or decisions without being explicitly programmed to do so. 
        Machine learning algorithms are used in a wide variety of applications, such as in medicine, email filtering, speech recognition, and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks. 
        A subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers, but not all machine learning is statistical learning. 
        The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning. 
        Some implementations of machine learning use data and neural networks in a way that mimics the working of a biological brain. As of 2020, many sources continue to assert that ML remains a subfield of AI. 
        Others have the view that not all ML is part of AI, but only an 'intelligent subset' of ML should be considered AI.&quot;&quot;&quot;


sent_num = len(re.split(&quot;(?&lt;=[^A-Z].[.?])(\s|\n)+(?=[A-Z])&quot;, text))
print(&quot;Number of sentences with regex:&quot;, sent_num)  #15

sent_num = len(nltk.sent_tokenize(text))
print(&quot;Number of sentences with NLTK:&quot;, sent_num)  #8
</code></pre>
<p>I have wrote a regex that can split text based on condition:
If word ends with punctuation (.!?) and if there is empty space or new line after punctuation and if word after empty space has first capital letter, then split it.</p>
<p>But Im getting bad results, NLTK gives 8 (correct), and my regex gives 15 instead of 8.</p>
",35,2,1,1,python,2022-07-05 22:18:23,2022-07-05 22:18:23,2022-07-05 23:13:14,this is my text  it has  sentences  but im getting bad results  nltk gives   correct   and my regex gives  instead of  ,split text into sentences without nltk
116,116,19488951,72873412,How to solve error of regexflag object not subscriptable,"<p>It's a machine learning python error where imputer.fit is giving error. I tried importing re and all but still showing error.<a href=""https://i.stack.imgur.com/z4XXP.jpg"" rel=""nofollow noreferrer"">this is what error and not able to resolve since so long</a></p>
",12,0,0,4,machine-learning;data-science;sklearn-pandas;imputation,2022-07-05 22:58:39,2022-07-05 22:58:39,2022-07-05 22:58:39,it s a machine learning python error where imputer fit is giving error  i tried importing re and all but still showing error ,how to solve error of regexflag object not subscriptable
117,117,12283890,72873088,ModuleNotFoundError: No module named &#39;tensorflow&#39; Command skipped related to Databrics notebook (Azure databrics labs),"<blockquote>
<p>This issue is mainly related to &quot;Databrics notebook&quot; provided for Azure machine learning lab notebooks</p>
</blockquote>
",7,1,-1,2,tensorflow;jupyter-notebook,2022-07-05 22:29:37,2022-07-05 22:29:37,2022-07-05 22:29:37,this issue is mainly related to  databrics notebook  provided for azure machine learning lab notebooks,modulenotfounderror  no module named    tensorflow    command skipped related to databrics notebook  azure databrics labs 
118,118,15673855,72332126,Variable input and output size for Keras,"<p>Before I start, I am quite new to Keras and machine learning. I know the theory quite well but the syntax less so.</p>
<p>I am trying to create a reinforcement learning neural network using Keras. The problem to be solved is essentially the travelling salesman problem. The problem is, is that the network is fed in its location and the environment, which is a randomly created network of points such as [[0,5],[30,17],[19,83]..., and as the agent travels through this network, it changes as a point cannot be visited again. So if the agent goes from [0,0] to [0,5] then [30,17], the input would look like [0,5],[30,17],[19,83] to [30,17],[19,83] to [19,83]. There is a similar issue with the output, which is just the index of the possible locations to move to. This means that there could be any number of outputs.</p>
<p>The size of the input is initially 100, and the output could also be anywhere between 0 and 100. Methods like padding the inputs with a number would not work as the network would be fed a location impossible to get to, and there is a similar problem with padding the output with a number - the network can just stay in the same position whilst 'moving' ([0,0] to [0,0] etc). The agent also has limited time, so even with filling with random numbers it could just travel to locations which don't actually exist which doesn't solve the problem at hand.</p>
<p>How would I dynamically change the input and output sizes? Is it even possible, and if not, how should it be done?</p>
<p>edit: code because someone wanted it. Quite unintelligible but in essence a class containing the actions able to be done, the input in the form of self.state, and the enviroment in self.point_space. Reward is calculated as the distance travelled at each step and when complete, the distance compared to a random loop. The more important thing is if i can change the input and output sizes.</p>
<pre><code>class GraphEnv(Env):
  def __init__(self):
      self.point_space = createpoints()
      self.action_space = Discrete(len(self.point_space))
      self.observation_space = self.point_space.copy()
      self.state = [[0,0]]
     
      for i in self.observation_space:
        self.state.append(i)
      self.length = len(self.point_space)
      self.totallen = 0
      self.unchangedpoint_space = self.point_space.copy()
  def step(self, action):
    oldstate = self.state[0]
    self.state = []
    self.state.append(list(self.point_space[action-1]))
    try:
      del self.point_space[action-1]
    except:
      pass
    self.observation_space = self.point_space.copy()
    for i in self.observation_space:
        self.state.append(i)
    self.action_space = Discrete(len(self.point_space))
    #print(&quot;self.state = &quot;, self.state)

    reward = int(-math.sqrt((oldstate[0] - self.state[0][0])**2 + (oldstate[1] - self.state[0][1])**2))
    self.totallen += reward

    self.length -= 1
    if self.length &lt;= 0:
      #print(&quot;unchanged =&quot;, self.unchangedpoint_space)
      randomscore = scoreforrandom(self.unchangedpoint_space)
      reward = self.totallen - randomscore
      #print(&quot;totallen =&quot;,self.totallen)
      #print(&quot;randomscore =&quot;, randomscore)
      #print(&quot;reward&quot;, reward)
      done = True
    else:
      done = False


    info = {}

    return(self.state,reward,done,info)
  def render(self):
    
    pass
  def reset(self):
    self.state = [[0,0]]
    self.length = 100
    self.point_space = createpoints()
    self.observation_space = self.point_space.copy()
    self.state.append(self.observation_space)
    self.unchangedpoint_space = self.point_space.copy()
    #print(&quot;unchanged on init&quot;, self.unchangedpoint_space)
    self.action_space = Discrete(len(self.point_space))
    self.totallen = 0
    pass
</code></pre>
<p>The video i used as help: <a href=""https://www.youtube.com/watch?v=bD6V3rcr_54&amp;t=77s&amp;ab_channel=NicholasRenotte"" rel=""nofollow noreferrer"">https://www.youtube.com/watch?v=bD6V3rcr_54&amp;t=77s&amp;ab_channel=NicholasRenotte</a></p>
",50,1,0,5,machine-learning;keras;deep-learning;neural-network;reinforcement-learning,2022-05-21 23:41:40,2022-05-21 23:41:40,2022-07-05 22:04:32,before i start  i am quite new to keras and machine learning  i know the theory quite well but the syntax less so  i am trying to create a reinforcement learning neural network using keras  the problem to be solved is essentially the travelling salesman problem  the problem is  is that the network is fed in its location and the environment  which is a randomly created network of points such as                  and as the agent travels through this network  it changes as a point cannot be visited again  so if the agent goes from     to     then      the input would look like             to         to      there is a similar issue with the output  which is just the index of the possible locations to move to  this means that there could be any number of outputs  the size of the input is initially   and the output could also be anywhere between  and   methods like padding the inputs with a number would not work as the network would be fed a location impossible to get to  and there is a similar problem with padding the output with a number   the network can just stay in the same position whilst  moving       to     etc   the agent also has limited time  so even with filling with random numbers it could just travel to locations which don t actually exist which doesn t solve the problem at hand  how would i dynamically change the input and output sizes  is it even possible  and if not  how should it be done  edit  code because someone wanted it  quite unintelligible but in essence a class containing the actions able to be done  the input in the form of self state  and the enviroment in self point_space  reward is calculated as the distance travelled at each step and when complete  the distance compared to a random loop  the more important thing is if i can change the input and output sizes  the video i used as help  ,variable input and output size for keras
119,119,15319497,72871434,how can i edit a local html file via the browser such as how jupyter notebooks work,"<p>So i have a bunch of data and i need to loop through it all and label it. the data is Natural language that needs labels for Machine learning. so i wanted to build a template with all the possible labels as javascript buttons so that as i loop through the data i can click the label and have the html save permanently to the html file. ive looked at chrome work station but you still have to edit the file in a side panel. downloading the file seems like a way but i would still like to know if i can do it my way. The only good example i have found is such as jupyter notebooks. on there you load the browser from terminal and then in the browser you can edit the file, add files, directories, save the file and even run python so i know its possible i just dont know how.</p>
<pre><code>&lt;!DOCTYPE HTML&gt;

&lt;html&gt;
&lt;head&gt;
&lt;meta content=&quot;text/html;charset=utf-8&quot; http-equiv=&quot;content-type&quot;/&gt;
&lt;title&gt;Title here&lt;/title&gt;
&lt;style&gt;
    p.customer{color: red;}
    p.assitant{color: black;  }
    p.tech{color: blue; }
    p.fixed { font-size: 20px;}
&lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;

&lt;p id=&quot;demo&quot;&gt;&lt;/p&gt;
&lt;p class=&quot;customer&quot;&gt;customer says they have a problem&lt;/p&gt;
&lt;p class=&quot;assitant&quot;&gt;what have you tried so far&lt;/p&gt;
&lt;p class=&quot;tech&quot;&gt;thats going to cost 100 dollars to fix&lt;/p&gt;
&lt;p class=&quot;customer&quot;&gt;Customer Text Here&lt;/p&gt;
&lt;p class=&quot;customer&quot;&gt;Customer Text Here&lt;/p&gt;
&lt;p class=&quot;customer&quot;&gt;Customer make us rich&lt;/p&gt;
&lt;p class=&quot;customer fixed&quot;&gt;Customer make us&lt;/p&gt;
&lt;p class=&quot;customer fixed&quot;&gt;Customer make us rich&lt;/p&gt;
&lt;button onclick=&quot;document.getElementById('demo').innerHTML = Date()&quot; type=&quot;button&quot;&gt;
click this button to label this issue as resolved&lt;/button&gt;
&lt;button onclick=&quot;document.getElementById('demo').innerHTML = Date()&quot; type=&quot;button&quot;&gt;
click this button to label this issue as not resolved&lt;/button&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<p>i want to be able to open this document in a browser(or something that can handle javascript) which would be stored on my machine. on clicking the javascript buttons the script would edit the html in some way and subsequently save the file to is original location.</p>
",17,0,0,3,python;html;jupyter-notebook,2022-07-05 20:20:30,2022-07-05 20:20:30,2022-07-05 22:03:55,so i have a bunch of data and i need to loop through it all and label it  the data is natural language that needs labels for machine learning  so i wanted to build a template with all the possible labels as javascript buttons so that as i loop through the data i can click the label and have the html save permanently to the html file  ive looked at chrome work station but you still have to edit the file in a side panel  downloading the file seems like a way but i would still like to know if i can do it my way  the only good example i have found is such as jupyter notebooks  on there you load the browser from terminal and then in the browser you can edit the file  add files  directories  save the file and even run python so i know its possible i just dont know how  i want to be able to open this document in a browser or something that can handle javascript  which would be stored on my machine  on clicking the javascript buttons the script would edit the html in some way and subsequently save the file to is original location ,how can i edit a local html file via the browser such as how jupyter notebooks work
120,120,12273900,72867573,RuntimeError: CUDA out of memory. Getting this error while custom training JoJoGAN any workarounds?,"<p>Started a custom project i.e. an application that converts a human face to a toon image,
so i came across this <a href=""https://www.youtube.com/watch?v=FNtnmarvrOg&amp;t=266s"" rel=""nofollow noreferrer"">youtube video</a> explaining JoJoGAN and i thought this could be a workaround for my project. So, I started working on the project using JoJoGAN, custom training a model but i keep getting an error</p>
<blockquote>
<p>RuntimeError: CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 3.82 GiB total capacity; 2.53 GiB already allocated; 74.69 MiB free; 2.64 GiB reserved in total by PyTorch) If reserved memory is &gt;&gt; allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF</p>
</blockquote>
<p>I searched over the internet and came around a conclusion that reducing the batch size would do the trick but the problem is I<code>ve recently started Machine Learning journey and am clear with basics of Neural Net. and stuff not the advanced stuff so how can i deal with this issue and also i don</code>t know how to chhage the batch size as well  so if anybody knows please help.</p>
<p>Thanks.</p>
",30,0,-6,4,machine-learning;memory;neural-network;pytorch,2022-07-05 15:36:42,2022-07-05 15:36:42,2022-07-05 21:27:00,runtimeerror  cuda out of memory  tried to allocate   mib  gpu     gib total capacity    gib already allocated    mib free    gib reserved in total by pytorch  if reserved memory is  gt  gt  allocated memory try setting max_split_size_mb to avoid fragmentation   see documentation for memory management and pytorch_cuda_alloc_conf i searched over the internet and came around a conclusion that reducing the batch size would do the trick but the problem is ive recently started machine learning journey and am clear with basics of neural net  and stuff not the advanced stuff so how can i deal with this issue and also i dont know how to chhage the batch size as well  so if anybody knows please help  thanks ,runtimeerror  cuda out of memory  getting this error while custom training jojogan any workarounds 
121,121,14894805,72871669,"If you proceed with the bash command, the ec2 connection is disconnected, but if you go directly to the terminal and proceed, there is no problem","<p>I wrote the code to start ec2 locally using bash and run.
Below is a part of the code.</p>
<pre><code>ssh -i $AWS_KEY -t ubuntu@$INSTANCE_DNS 'cd /home/ubuntu/Hardware-Data-Collect/&amp;&amp; sudo bash ./settings.sh &amp;&amp; sudo bash ./Run_gpu.sh'
</code></pre>
<p>It proceeds normally until settings.sh is installed.</p>
<p>However, as soon as I run Run_gpu.sh to run machine learning, the ec2 connection is disconnected.</p>
<blockquote>
<p>Connection to ec2-18-236-69-227.us-west-2.compute.amazonaws.com closed.</p>
</blockquote>
<p>If i connect directly to ec2 with ssh and then execute the run_gpu.sh, there is no error.</p>
<p>I want to know why ec2 connection is disconnected in terminal (The instance is not terminated)</p>
",21,0,-2,5,bash;amazon-web-services;amazon-ec2;ssh;nohup,2022-07-05 20:35:41,2022-07-05 20:35:41,2022-07-05 20:35:41,it proceeds normally until settings sh is installed  however  as soon as i run run_gpu sh to run machine learning  the ec connection is disconnected  connection to ec     us west  compute amazonaws com closed  if i connect directly to ec with ssh and then execute the run_gpu sh  there is no error  i want to know why ec connection is disconnected in terminal  the instance is not terminated ,if you proceed with the bash command  the ec connection is disconnected  but if you go directly to the terminal and proceed  there is no problem
122,122,17260574,72871653,Create release pipeline/artifact for ML training (Azureml),"<p>I have the following pipeline which runs the machine learning training however I want to create a release pipeline. The pipeline should build an artifact which then the release pipeline should be able to deploy.</p>
<pre><code>trigger: 
  none
  
pool:
  vmImage: &quot;ubuntu-latest&quot;


variables:
  - group: variable group
    

steps:

  # Set the version of Python that the build agent should use
- task: UsePythonVersion@0
  displayName: Use Python 3.8
  inputs:
    versionSpec: '3.8'
    addToPath: true 

  # Run Pip installer for any prerequisite libraries
- bash: pip3 install -r requirements.txt
  displayName: Install pip package requirements
  workingDirectory: workingDirectory/Scripts


- task: AzureCLI@2
  inputs:
    azureSubscription: 'azureSubscription:'
    scriptType: 'bash'
    scriptLocation: 'inlineScript'
    inlineScript: 'python run-training.py'
    workingDirectory: 'workingDirectory/Scripts'
</code></pre>
<p>Use the following as research but still not sure how to do this:
<a href=""https://docs.microsoft.com/en-us/azure/devops/pipelines/artifacts/build-artifacts?view=azure-devops&amp;tabs=yaml"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/devops/pipelines/artifacts/build-artifacts?view=azure-devops&amp;tabs=yaml</a>
<a href=""https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/utility/publish-build-artifacts?view=azure-devops"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/utility/publish-build-artifacts?view=azure-devops</a></p>
",15,0,-1,4,azure-pipelines;azure-pipelines-release-pipeline;mlops;azureml-python-sdk,2022-07-05 20:34:31,2022-07-05 20:34:31,2022-07-05 20:34:31,i have the following pipeline which runs the machine learning training however i want to create a release pipeline  the pipeline should build an artifact which then the release pipeline should be able to deploy ,create release pipeline artifact for ml training  azureml 
123,123,16770626,72865453,How do you display data when you have multiple machine learning models,"<p>I have developed a program that finds the probabilities of around 500 classes based on some training data that involves a few thousand features.</p>
<p>It works by training about 500 logistic regression models that take these few thousand features and find the probability of a single class. Each model finds the probability for a different class, so I am able to find to find the probability for each of the classes.</p>
<p>Since these are all different models, I have been able to find the accuracy for each model and have the mean accuracy by averaging all of these values.</p>
<p>My problem is that right now I have these 500 or so data points and the average and I don't really know how to represent them graphically. I can't really plot them with a line graph since there isn't much relation between the classes and the ROC curves don't work since this isn't a binary classification.</p>
<p>Does anyone have any suggestions on ways I can graph this data? Thank you!</p>
",33,1,-2,4,python;machine-learning;graph;artificial-intelligence,2022-07-05 12:52:36,2022-07-05 12:52:36,2022-07-05 19:03:58,i have developed a program that finds the probabilities of around  classes based on some training data that involves a few thousand features  it works by training about  logistic regression models that take these few thousand features and find the probability of a single class  each model finds the probability for a different class  so i am able to find to find the probability for each of the classes  since these are all different models  i have been able to find the accuracy for each model and have the mean accuracy by averaging all of these values  my problem is that right now i have these  or so data points and the average and i don t really know how to represent them graphically  i can t really plot them with a line graph since there isn t much relation between the classes and the roc curves don t work since this isn t a binary classification  does anyone have any suggestions on ways i can graph this data  thank you ,how do you display data when you have multiple machine learning models
124,124,13990977,72831076,How can I use a sequence of numbers to predict a single number in Tensorflow?,"<p>I am trying to build a machine learning model which predicts a single number from a series of numbers. I am using a Sequential model from the keras API of Tensorflow.</p>
<p>You can imagine my dataset to look something like this:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>Index</th>
<th>x data</th>
<th>y data</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td><code>np.ndarray(shape (1209278,) )</code></td>
<td><code>numpy.float32</code></td>
</tr>
<tr>
<td>1</td>
<td><code>np.ndarray(shape (1211140,) )</code></td>
<td><code>numpy.float32</code></td>
</tr>
<tr>
<td>2</td>
<td><code>np.ndarray(shape (1418411,) )</code></td>
<td><code>numpy.float32</code></td>
</tr>
<tr>
<td>3</td>
<td><code>np.ndarray(shape (1077132,) )</code></td>
<td><code>numpy.float32</code></td>
</tr>
<tr>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
</tbody>
</table>
</div>
<p><strong>This was my first attempt:</strong></p>
<p>I tried using a numpy ndarray which contains numpy ndarrays which finally contain floats as my xdata, so something like this:</p>
<pre class=""lang-py prettyprint-override""><code>array([
    array([3.59280851, 3.60459062, 3.60459062, ..., 4.02911493])
    array([3.54752101, 3.56740332, 3.56740332, ..., 4.02837855])
    array([3.61048168, 3.62152741, 3.62152741, ..., 4.02764217])
])
</code></pre>
<p>My y data is a numpy ndarray containing floats, which looks something like this</p>
<pre class=""lang-py prettyprint-override""><code>array([2.9864411, 3.0562437, ... , 2.7750807, 2.8712902], dtype=float32)
</code></pre>
<p>But when I tried to train the model using <code>model.fit()</code> it yields this error:</p>
<pre><code>ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).
</code></pre>
<p>I was able to solve this error by asking a question related to this:
<a href=""https://stackoverflow.com/questions/72815591/how-can-i-have-a-series-of-numpy-ndarrays-as-the-input-data-to-train-a-tensorflo"">How can I have a series of numpy ndarrays as the input data to train a tensorflow machine learning model?</a></p>
<p><strong>My latest attempt:</strong>
Because Tensorflow does not seem to be able to convert a ndarray of ndarrays to a tensor, I tried to convert my x data to a list of ndarrays like this:</p>
<pre class=""lang-py prettyprint-override""><code>[
    array([3.59280851, 3.60459062, 3.60459062, ..., 4.02911493])
    array([3.54752101, 3.56740332, 3.56740332, ..., 4.02837855])
    array([3.61048168, 3.62152741, 3.62152741, ..., 4.02764217])
]
</code></pre>
<p>I left my y data untouched, so as a ndarray of floats.
Sadly my attempt of using a list of ndarrays instead of a ndarray of ndarrays yielded this error:</p>
<pre class=""lang-py prettyprint-override""><code>ValueError: Data cardinality is ambiguous:
  x sizes: 1304593, 1209278, 1407624, ...
  y sizes: 46
Make sure all arrays contain the same number of samples.
</code></pre>
<p>As you can see, my x data consists of arrays which all have a different shape.
But I don't think that this should be a problem.</p>
<p><strong>Question:</strong></p>
<p>My guess is that Tensorflow tries to use my list of arrays as <em>multiple</em> inputs.
<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"" rel=""nofollow noreferrer"">Tensorflow fit() documentation</a></p>
<p>But I don't want to use my x data as multiple inputs.
Easily said I just want my model to predict a number from a sequence of numbers.
For example like this:</p>
<ul>
<li>array([3.59280851, 3.60459062, 3.60459062, ...]) =&gt; 2.8989773</li>
<li>array([3.54752101, 3.56740332, 3.56740332, ...]) =&gt; 3.0893357</li>
<li>...</li>
</ul>
<p><strong>How can I use a sequence of numbers to predict a single number in Tensorflow?</strong></p>
<p><strong>EDIT</strong>
Maybe I should have added that I want to use a RNN, especially a LSTM.
I have had a look at the Keras documentation, and in their simplest example they are using a <code>Embedding</code> layer. But I don't really know what to do.</p>
<p>All in all I think that my question ist pretty general and should be easy to answer if you know how to tackle this problem, unlike me.
Thanks in advance!</p>
",111,1,5,5,python;arrays;numpy;tensorflow;keras,2022-07-01 20:23:16,2022-07-01 20:23:16,2022-07-05 18:51:44,i am trying to build a machine learning model which predicts a single number from a series of numbers  i am using a sequential model from the keras api of tensorflow  you can imagine my dataset to look something like this  this was my first attempt  i tried using a numpy ndarray which contains numpy ndarrays which finally contain floats as my xdata  so something like this  my y data is a numpy ndarray containing floats  which looks something like this but when i tried to train the model using model fit   it yields this error  question  how can i use a sequence of numbers to predict a single number in tensorflow ,how can i use a sequence of numbers to predict a single number in tensorflow 
125,125,4903479,72806592,Model deployment failing in azure machine learning,"<p>I am following the procedure as described <a href=""https://www.analyticsvidhya.com/blog/2022/02/deploy-your-ml-model-as-a-web-service-in-microsoft-azure-cloud/"" rel=""nofollow noreferrer"">here</a>.<br />
I am trying to register models and deploy them in Azure machine learning. I have the following script:</p>
<pre class=""lang-py prettyprint-override""><code>    import pandas as pd
    import sklearn
    from sklearn.svm import SVC
    import pickle
    import joblib
    from sklearn.model_selection import train_test_split
    dataset = pd.read_csv(&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&quot;, header = None, names= colnames )
    dataset = dataset.replace({&quot;class&quot;:  {&quot;Iris-setosa&quot;:1,&quot;Iris-versicolor&quot;:2, &quot;Iris-virginica&quot;:3}})
    X = dataset.drop(['class'], axis=1)[:,0]
    y = dataset['class']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)
    classifier = SVC(kernel = 'linear', random_state = 0)
    #Fit the model on training data
    classifier.fit(X_train, y_train)
    #Make the prediction
    y_pred = classifier.predict(X_test)
    ## Save as a pickle file
    filename= 'final_mod_v1.pkl'
    joblib.dump(classifier,open(filename, 'wb'))
</code></pre>
<p>In the models tab I registered the model. Then I tried to deploy the model as web service. The following is the scoring script file.</p>
<pre class=""lang-py prettyprint-override""><code>    import json
    import numpy as np
    import os
    import pickle
    import joblib
    from sklearn.svm import SVC
    from azureml.core import Model
    
    def init():
        global model
        model_name = 'classifier'
        path = Model.get_model_path(model_name)
        model = joblib.load(path)
    
    def run(data):
        try:
            data = json.loads(data)
            result = model.predict(data['data'])
            return {'data' : result.tolist() , 'message' : &quot;Successfully classified Iris&quot;}
    
        except Exception as e:
            error = str(e)
            return {'data' : error , 'message' : 'Failed to classify iris'}
</code></pre>
<p>The following is the <strong>conda_dependencies.yml</strong>:</p>
<pre><code>channels:
- anaconda
- conda-forge
dependencies:
- python=3.6.2
- pip:
  - pandas==1.1.5
  - azureml-defaults
  - joblib==0.17.0
- scikit-learn==0.23.2
name: azureml_2d0fd20031db3baaed8684d5f08fe619
</code></pre>
<p>I am confused about the last line in the above script <code>azureml_2d0fd20031db3baaed8684d5f08fe619</code></p>
<pre><code> name: azureml_2d0fd20031db3baaed8684d5f08fe619
</code></pre>
<p>The deployment is failing. Deployment log shows:</p>
<pre><code> container &quot;classifier&quot; in pod &quot;wk-caas-9a4c565844b043cfa9d8ba246af11ff5-517e6d8f74175a01ffc43147e5dd8133-pod&quot; is waiting to start: PodInitializing
</code></pre>
<p>It would be helpful if I can get a guidance on this.</p>
",70,0,0,4,azure;machine-learning;azure-devops;azure-web-app-service,2022-06-30 00:34:34,2022-06-30 00:34:34,2022-07-05 18:09:59,in the models tab i registered the model  then i tried to deploy the model as web service  the following is the scoring script file  the following is the conda_dependencies yml  i am confused about the last line in the above script azureml_dfddbbaaeddffe the deployment is failing  deployment log shows  it would be helpful if i can get a guidance on this ,model deployment failing in azure machine learning
126,126,15005884,72863309,"Machine learning model, where every new value depends on previously predicted values","<p>My intension is to simulate daily activities of persons, based on their home area and socio-economic category (those are always constants). They should perform activities (type of activity, time of start, duration, geographic area, bee-line distance to it from previous location), but it's necessary to get there somehow (mean of transport). And every next activity more or less depends on previous activity.</p>
<p>==== Background ===</p>
<p>It is clear (from everyone's experience and from data we collected), that a person who works full-time will not spend several hours shopping or doing sports after job, whereas a person, who goes from home to those activities directly can stay there for longer time. Time spent at every activity depends on their order, choice of location also depends on how far from the city center person lives (people from in sattelite towns choose activities more close to each other, because they have to deal with bigger distances), etc...</p>
<p>I admit, this is a bit complex task (especially for beginner like me). Currently I compute daily schedules by hardcoding some parts (pre-defined activity chains and their durations, assigned to persons of certain categories who live in particular areas), and by using some simple statistics or rules (Weibull distribution for distances depending on upcoming activities, mean of transport chosen based on how far public transit stop is from start and from end of trip, and what is predicted distance). And it works, but not always as expected.</p>
<p>The main problem is - not everything takes previous choices into account, they are not thoroughly connected. And also hardcoding is bad for models that should predict some future states, so the way of how times are defined should be more sophisticated. And I tried that too, but simple statistics didn't reflect time of activities as sequence, so it only guessed time of upcoming activity, not looking at how many activities have already been performed and how much time it took, or also how many is left. Same problem with distances. This is not a big deal to define them one after another with some limitations (always return to same home or work place no matter how far it is), but as was mentioned before, people from different areas behave differently, even if they are in the same place in certain phase of the day.</p>
<p>=== End of background ===</p>
<p>How do I do this process now:</p>
<ol>
<li>Preprocessing of all persons - Assigning all persons social categories and initial modes of
transport (from stats by areas)</li>
<li>Preprocessing of all persons - Assigning activities-durations chains
based on category and area of origin</li>
<li>Generating distances to every activity from Weibull distribution
with parameters I got from stats (they vary for activities and home
areas of persons [not actual zone they are currently in])</li>
<li>Picking certain facilities for activities (mostly by generated
distance, but also by attractivity) and finalizing distances (from
generated to actual)</li>
<li>Calculating distances to public transit stops and defining final
means of transport</li>
<li>Calculating start and end times of activities based on modes of transport and distances</li>
</ol>
<p>Steps 3-6 iterate over list of activities (or distances, or times) of every person.</p>
<p>How I think about doing it in future:</p>
<ol>
<li>Assigning all persons social categories and initial modes of
transport (from stats by areas)</li>
<li>Assigning activities chains (only sequence, no durations) based on category and area of
origin</li>
<li>(ML) Predict first activity, its area, distance to it, duration, start time, (optionally) mean of transport</li>
<li>Find place for first activity based on predicted area and distance</li>
<li>(ML) Predict the same for second activity knowing previous prediction</li>
<li>Continue until there are no activities left</li>
</ol>
<p>Data that I got from survey have detailed description of every trip that every person performed, as a row, with columns:</p>
<p>person category (str), person home area (str), activity number (int), activity type (str), departure time (float), area of departure (str), mean of transport (str), arrival time (str), area of arrival (str)</p>
<p>For convenience and versatility I also add columns with previous or next areas, activities, durations where applicable.</p>
<p>Could anyone please suggest a suitable tool for making such operations (within tensorflow package preferably)? Should I make models for every possible length of activities chains? I couldn't figure out how, because inputs would be very complex because of many categorical and numeric columns. How do I even arrange data? Or should I do it completely differently?</p>
",29,0,-3,4,python;tensorflow;machine-learning;data-analysis,2022-07-05 07:28:04,2022-07-05 07:28:04,2022-07-05 16:48:19,my intension is to simulate daily activities of persons  based on their home area and socio economic category  those are always constants   they should perform activities  type of activity  time of start  duration  geographic area  bee line distance to it from previous location   but it s necessary to get there somehow  mean of transport   and every next activity more or less depends on previous activity       background     it is clear  from everyone s experience and from data we collected   that a person who works full time will not spend several hours shopping or doing sports after job  whereas a person  who goes from home to those activities directly can stay there for longer time  time spent at every activity depends on their order  choice of location also depends on how far from the city center person lives  people from in sattelite towns choose activities more close to each other  because they have to deal with bigger distances   etc    i admit  this is a bit complex task  especially for beginner like me   currently i compute daily schedules by hardcoding some parts  pre defined activity chains and their durations  assigned to persons of certain categories who live in particular areas   and by using some simple statistics or rules  weibull distribution for distances depending on upcoming activities  mean of transport chosen based on how far public transit stop is from start and from end of trip  and what is predicted distance   and it works  but not always as expected  the main problem is   not everything takes previous choices into account  they are not thoroughly connected  and also hardcoding is bad for models that should predict some future states  so the way of how times are defined should be more sophisticated  and i tried that too  but simple statistics didn t reflect time of activities as sequence  so it only guessed time of upcoming activity  not looking at how many activities have already been performed and how much time it took  or also how many is left  same problem with distances  this is not a big deal to define them one after another with some limitations  always return to same home or work place no matter how far it is   but as was mentioned before  people from different areas behave differently  even if they are in the same place in certain phase of the day      end of background     how do i do this process now  steps   iterate over list of activities  or distances  or times  of every person  how i think about doing it in future  data that i got from survey have detailed description of every trip that every person performed  as a row  with columns  person category  str   person home area  str   activity number  int   activity type  str   departure time  float   area of departure  str   mean of transport  str   arrival time  str   area of arrival  str  for convenience and versatility i also add columns with previous or next areas  activities  durations where applicable  could anyone please suggest a suitable tool for making such operations  within tensorflow package preferably   should i make models for every possible length of activities chains  i couldn t figure out how  because inputs would be very complex because of many categorical and numeric columns  how do i even arrange data  or should i do it completely differently ,machine learning model  where every new value depends on previously predicted values
127,127,4871597,67160576,YoloV5 killed at first epoch,"<p>I'm using a virtual machine on Windows 10 with this config:</p>
<pre><code>Memory 7.8 GiB
Processor Intel® Core™ i5-6600K CPU @ 3.50GHz × 3
Graphics llvmpipe (LLVM 11.0.0, 256 bits)
Disk Capcity 80.5 GB
OS Ubuntu 20.10 64 Bit
Virtualization Oracle
</code></pre>
<p>I installed docker for Ubuntu as described in <a href=""https://docs.docker.com/engine/install/ubuntu/"" rel=""nofollow noreferrer"">the official documentation</a>.<br>
I pulled the docker image as described on the <a href=""https://github.com/ultralytics/yolov5/wiki/Docker-Quickstart"" rel=""nofollow noreferrer"">yolo github section for docker</a>.<br>
Since I have no NVIDIA GPU I could not install a driver or CUDA.
I pulled the aquarium from <a href=""https://public.roboflow.com/object-detection/aquarium"" rel=""nofollow noreferrer"">roboflow</a> and installed it on a folde aquarium.
I ran this command to start the image and have my aquarium folder mounted</p>
<pre><code>sudo docker run --ipc=host -it -v &quot;$(pwd)&quot;/Desktop/yolo/aquarium:/usr/src/app/aquarium ultralytics/yolov5:latest
</code></pre>
<p>And was greeted with this banner</p>
<blockquote>
<h1>=============
== PyTorch ==</h1>
<p>NVIDIA Release 21.03 (build 21060478) PyTorch Version 1.9.0a0+df837d0</p>
<p>Container image Copyright (c) 2021, NVIDIA CORPORATION.  All rights
reserved.</p>
<p>Copyright (c) 2014-2021 Facebook Inc. Copyright (c) 2011-2014 Idiap
Research Institute (Ronan Collobert) Copyright (c) 2012-2014 Deepmind
Technologies    (Koray Kavukcuoglu) Copyright (c) 2011-2012 NEC
Laboratories America (Koray Kavukcuoglu) Copyright (c) 2011-2013 NYU<br />
(Clement Farabet) Copyright (c) 2006-2010 NEC Laboratories America
(Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston) Copyright
(c) 2006      Idiap Research Institute (Samy Bengio) Copyright (c)
2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio,
Johnny Mariethoz) Copyright (c) 2015      Google Inc. Copyright (c)
2015      Yangqing Jia Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.</p>
<p>NVIDIA Deep Learning Profiler (dlprof) Copyright (c) 2021, NVIDIA
CORPORATION.  All rights reserved.</p>
<p>Various files include modifications (c) NVIDIA CORPORATION.  All
rights reserved.</p>
<p>This container image and its contents are governed by the NVIDIA Deep
Learning Container License. By pulling and using the container, you
accept the terms and conditions of this license:
<a href=""https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license"" rel=""nofollow noreferrer"">https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license</a></p>
<p>WARNING: The NVIDIA Driver was not detected.  GPU functionality will
not be available.    Use 'nvidia-docker run' to start this container;
see    <a href=""https://github.com/NVIDIA/nvidia-docker/wiki/nvidia-docker"" rel=""nofollow noreferrer"">https://github.com/NVIDIA/nvidia-docker/wiki/nvidia-docker</a> .</p>
<p>NOTE: MOFED driver for multi-node communication was not detected.
Multi-node communication performance may be reduced.</p>
</blockquote>
<p>So no error there.<br>
I installed pip and with pip wandb I added wandb. I used <code>wandb login</code> and set my API key.<br><br>
I ran following command:</p>
<pre><code># python train.py --img 640 --batch 16 --epochs 10 --data ./aquarium/data.yaml --weights yolov5s.pt --project ip5 --name aquarium5 --nosave --cache
</code></pre>
<p>And received this output:</p>
<pre><code>github: skipping check (Docker image)
YOLOv5 🚀 v5.0-14-g238583b torch 1.9.0a0+df837d0 CPU

Namespace(adam=False, artifact_alias='latest', batch_size=16, bbox_interval=-1, bucket='', cache_images=True, cfg='', data='./aquarium/data.yaml', device='', entity=None, epochs=10, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='aquarium5', noautoanchor=False, nosave=True, notest=False, project='ip5', quad=False, rect=False, resume=False, save_dir='ip5/aquarium5', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=16, upload_dataset=False, weights='yolov5s.pt', workers=8, world_size=1)
tensorboard: Start with 'tensorboard --logdir ip5', view at http://localhost:6006/
hyperparameters: lr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0
wandb: Currently logged in as: pebs (use `wandb login --relogin` to force relogin)
wandb: Tracking run with wandb version 0.10.26
wandb: Syncing run aquarium5
wandb: ⭐️ View project at https://wandb.ai/pebs/ip5
wandb: 🚀 View run at https://wandb.ai/pebs/ip5/runs/1c2j80ii
wandb: Run data is saved locally in /usr/src/app/wandb/run-20210419_102642-1c2j80ii
wandb: Run `wandb offline` to turn off syncing.

Overriding model.yaml nc=80 with nc=7

                 from  n    params  module                                  arguments                     
  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    
  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                
  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   
  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               
  4                -1  1    156928  models.common.C3                        [128, 128, 3]                 
  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              
  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 
  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              
  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        
  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          
 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 12           [-1, 6]  1         0  models.common.Concat                    [1]                           
 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          
 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              
 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 16           [-1, 4]  1         0  models.common.Concat                    [1]                           
 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          
 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              
 19          [-1, 14]  1         0  models.common.Concat                    [1]                           
 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          
 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              
 22          [-1, 10]  1         0  models.common.Concat                    [1]                           
 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          
 24      [17, 20, 23]  1     32364  models.yolo.Detect                      [7, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]
[W NNPACK.cpp:80] Could not initialize NNPACK! Reason: Unsupported hardware.
Model Summary: 283 layers, 7079724 parameters, 7079724 gradients, 16.4 GFLOPS

Transferred 356/362 items from yolov5s.pt
Scaled weight_decay = 0.0005
Optimizer groups: 62 .bias, 62 conv.weight, 59 other
train: Scanning '/usr/src/app/aquarium/train/labels.cache' images and labels... 448 found, 0 missing, 1 empty, 0 corrupted: 100%|█| 448/448 [00:00&lt;?, ?
train: Caching images (0.4GB): 100%|████████████████████████████████████████████████████████████████████████████████| 448/448 [00:01&lt;00:00, 313.77it/s]
val: Scanning '/usr/src/app/aquarium/valid/labels.cache' images and labels... 127 found, 0 missing, 0 empty, 0 corrupted: 100%|█| 127/127 [00:00&lt;?, ?it
val: Caching images (0.1GB): 100%|██████████████████████████████████████████████████████████████████████████████████| 127/127 [00:00&lt;00:00, 141.31it/s]
Plotting labels... 

autoanchor: Analyzing anchors... anchors/target = 5.17, Best Possible Recall (BPR) = 0.9997
Image sizes 640 train, 640 test
Using 3 dataloader workers
Logging results to ip5/aquarium5
Starting training for 10 epochs...

     Epoch   gpu_mem       box       obj       cls     total    labels  img_size
  0%|                                                                                                                           | 0/28 [00:00&lt;?, ?it/s]Killed
root@cf40a6498016:~# /opt/conda/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 6 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
</code></pre>
<p>From this output I would think that there were 0 epochs completed.<br>
My data.yaml contains this code:</p>
<pre><code>train: /usr/src/app/aquarium/train/images
val: /usr/src/app/aquarium/valid/images

nc: 7
names: ['fish', 'jellyfish', 'penguin', 'puffin', 'shark', 'starfish', 'stingray']
</code></pre>
<p><a href=""https://wandb.ai/"" rel=""nofollow noreferrer"">wandb.ai</a> does not display any metrics, but I have the files config.yaml, requirements.txt, wandb-metadata.json and wandb-summary.json.</p>
<p>Why am I not getting any output?<br>
Has there in fact be no training at all?<br>
If there was a training, how can I use my model?</p>
",1614,2,2,5,python;docker;pytorch;yolov5;wandb,2021-04-19 16:19:10,2021-04-19 16:19:10,2022-07-05 16:44:56,i m using a virtual machine on windows  with this config  and was greeted with this banner nvidia release    build   pytorch version   a dfd and received this output   does not display any metrics  but i have the files config yaml  requirements txt  wandb metadata json and wandb summary json ,yolov killed at first epoch
128,128,45843,72867109,What is PyTorch Dataset supposed to return?,"<p>I'm trying to get PyTorch to work with DataLoader, this being said to be the easiest way to handle mini batches, which are in some cases necessary for best performance.</p>
<p>DataLoader wants a Dataset as input.</p>
<p>Most of the documentation on Dataset assumes you are working with an off-the-shelf standard data set e.g. MNIST, or at least with images, and can use existing machinery as a black box. I'm working with non-image data I'm generating myself. My best current attempt to distill the documentation about how to do that, down to a minimal test case, is:</p>
<pre><code>import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader


class Dataset1(Dataset):
    def __init__(self):
        pass

    def __len__(self):
        return 80

    def __getitem__(self, i):
        # actual data is blank, just to test the mechanics of Dataset
        return [0.0, 0.0, 0.0], 1.0


train_dataloader = DataLoader(Dataset1(), batch_size=8)

for X, y in train_dataloader:
    print(f&quot;X: {X}&quot;)
    print(f&quot;y: {y.shape} {y.dtype} {y}&quot;)
    break


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.layers = nn.Sequential(
            nn.Linear(3, 10),
            nn.ReLU(),
            nn.Linear(10, 1),
            nn.Sigmoid(),
        )

    def forward(self, x):
        return self.layers(x)


device = torch.device(&quot;cpu&quot;)
model = Net().to(device)
criterion = nn.BCELoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.1)

for epoch in range(10):
    for X, y in train_dataloader:
        X, y = X.to(device), y.to(device)

        pred = model(X)
        loss = criterion(pred, y)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
</code></pre>
<p>The output of the above program is:</p>
<pre><code>X: [tensor([0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64), tensor([0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)]
y: torch.Size([8]) torch.float64 tensor([1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)
Traceback (most recent call last):
  File &quot;C:\ml\test_dataloader.py&quot;, line 47, in &lt;module&gt;
    X, y = X.to(device), y.to(device)
AttributeError: 'list' object has no attribute 'to'
</code></pre>
<p>In all the example code I can find, <code>X, y = X.to(device), y.to(device)</code> succeeds, because <code>X</code> is indeed a tensor (whereas it is not in my version). Now I'm trying to find out what exactly converts <code>X</code> to a tensor, because either the example code e.g. <a href=""https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html"" rel=""nofollow noreferrer"">https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html</a> does not do so, or I am failing to understand how and where it does.</p>
<p>Does Dataset itself convert things to tensors? The answer seems to be 'sort of'.</p>
<p>It has converted <code>y</code> to a tensor, a column of the <code>y</code> value for every example in the batch. That much, makes sense, though it has used type float64, whereas in machine learning, we usually prefer float32. I am used to the idea that Python always represents scalars in double precision, so the conversion from double to single precision happens at the time of forming a tensor, and that this can be insured by specifying the <code>dtype</code> parameter. But in this case Dataset seems to have formed the tensor implicitly. Is there a place or way to specify the <code>dtype</code> parameter?</p>
<p><code>X</code> is not a tensor, but a list thereof. It would make intuitive sense if it were a list of the examples in the batch, but instead of a list of 8 elements each containing 3 elements, it's the other way around. So Dataset has transposed the input data, which would make sense if it is forming a tensor to match the shape of <code>y</code>, but instead of making a single 2d tensor, it has made a list of 1d tensors. (And, again, in double precision.) Why? Is there a way to change this behavior?</p>
<p>The answer posted so far to <a href=""https://stackoverflow.com/questions/67416496/does-pytorch-dataset-getitem-have-to-return-a-dict"">Does pytorch Dataset.__getitem__ have to return a dict?</a> says <code>__getitem__</code> can return anything. Okay, but then how does the anything get converted to the form the training procedure requires?</p>
",30,2,1,2,pytorch;pytorch-dataloader,2022-07-05 15:02:55,2022-07-05 15:02:55,2022-07-05 15:56:24,i m trying to get pytorch to work with dataloader  this being said to be the easiest way to handle mini batches  which are in some cases necessary for best performance  dataloader wants a dataset as input  most of the documentation on dataset assumes you are working with an off the shelf standard data set e g  mnist  or at least with images  and can use existing machinery as a black box  i m working with non image data i m generating myself  my best current attempt to distill the documentation about how to do that  down to a minimal test case  is  the output of the above program is  in all the example code i can find  x  y   x to device   y to device  succeeds  because x is indeed a tensor  whereas it is not in my version   now i m trying to find out what exactly converts x to a tensor  because either the example code e g   does not do so  or i am failing to understand how and where it does  does dataset itself convert things to tensors  the answer seems to be  sort of   it has converted y to a tensor  a column of the y value for every example in the batch  that much  makes sense  though it has used type float  whereas in machine learning  we usually prefer float  i am used to the idea that python always represents scalars in double precision  so the conversion from double to single precision happens at the time of forming a tensor  and that this can be insured by specifying the dtype parameter  but in this case dataset seems to have formed the tensor implicitly  is there a place or way to specify the dtype parameter  x is not a tensor  but a list thereof  it would make intuitive sense if it were a list of the examples in the batch  but instead of a list of  elements each containing  elements  it s the other way around  so dataset has transposed the input data  which would make sense if it is forming a tensor to match the shape of y  but instead of making a single d tensor  it has made a list of d tensors   and  again  in double precision   why  is there a way to change this behavior  the answer posted so far to  says __getitem__ can return anything  okay  but then how does the anything get converted to the form the training procedure requires ,what is pytorch dataset supposed to return 
129,129,12733110,72866639,Detect in which vehicle i am on an Android device,"<p>I want to detect a specific pattern of motion on an Android mobile phone with a various sensor like GPS, accelerometer, gyroscope, step detector etc
I need it because I would like to detect in which vehicle I am, e.g subway, bicycle, in a car or walking.
I think Machine Learning can help me solve this issue, by learning from a lot of sensor values coming from different devices, with different sampling rates, in the different vehicle.
I’m fluent with Java, I never used Python and I never work with machine learning.
I'm looking for help from the community to help me use something in machine learning to train my app to recognize the vehicle and other motion sensors patterns.</p>
",41,0,-1,4,java;android;machine-learning;android-sensors,2022-07-05 14:27:49,2022-07-05 14:27:49,2022-07-05 14:37:15,,detect in which vehicle i am on an android device
130,130,19417433,72861688,Using PCA on Part of Dataframe,"<p>I want to use a clustering algorithm to a dataframe that contains a lot of features (32 columns).</p>
<p>A part of the features are encoded using one hot encoder.</p>
<p>I want to use PCA ( Principal Component analysis ) to reduce the dimension and  make the machine learning process easier.</p>
<p>Is it possible to use the PCA just for some columns of the data frame and keep the other columns as they are then use machine learning model.</p>
<p>Or it is obligatory to use PCA for all the dataframe before clustering.</p>
",26,1,-1,4,dataframe;machine-learning;artificial-intelligence;pca,2022-07-05 01:50:57,2022-07-05 01:50:57,2022-07-05 13:43:41,i want to use a clustering algorithm to a dataframe that contains a lot of features   columns   a part of the features are encoded using one hot encoder  i want to use pca   principal component analysis   to reduce the dimension and  make the machine learning process easier  is it possible to use the pca just for some columns of the data frame and keep the other columns as they are then use machine learning model  or it is obligatory to use pca for all the dataframe before clustering ,using pca on part of dataframe
131,131,11377545,72862092,"WebRTC: ICE failed in Firefox, but working in MS Edge","<p>I want to develop a WebRTC based streaming application and I am learning about the protocol starting from the basics. In particular, I followed this extremely simple <a href=""https://github.com/hnasr/javascript_playground/tree/master/webrtc"" rel=""nofollow noreferrer"">example on GitHub</a> (also shown in this <a href=""https://www.youtube.com/watch?v=FExZvpVvYxA&amp;t=48m00s"" rel=""nofollow noreferrer"">YouTube video</a>) that just opens a WebRTC channel  between two browser tabs, and was able to run it on Microsoft Edge in my local machine. However, if I use the same JavaScript code in Firefox (version 102.0 on Windows 11), I receive an error <code>WebRTC: ICE failed, add a STUN server and see about:webrtc for more details</code> on both sender and receiver tabs.</p>
<p>I have therefore tried to include the STUN, TURN and TURNS servers provided by <a href=""https://www.metered.ca/tools/openrelay/"" rel=""nofollow noreferrer"">Open Relay</a> in the configuration, but the same error message always appears.</p>
<p>I would like my application to work on the most used internet browsers, so I am wondering how this can be fixed before digging deeper. Similar questions seemed a bit outdated or related to different errors.</p>
<p>Thank you all in advance for your help and suggestion.</p>
<hr />
<p>Considering the simplest case with no STUN nor TURN server (which should work in a local network or at least on the same localhost), WebRTC's connection registry contains this:</p>
<pre><code>+++++++ BEGIN (process id 21692) ++++++++
(generic/CRIT) PR_Connect failed: -5980
(ice/WARNING) /builds/worker/checkouts/gecko/dom/media/webrtc/transport/third_party/nICEr/src/net/nr_socket_multi_tcp.c:639 function nr_socket_multi_tcp_listen failed with error 3
(ice/WARNING) ICE-STREAM(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home) transport-id=transport_0 - a9c7cadd:7ce62f845d4f5b83df2a70e1bac037bf): failed to create passive TCP host candidate: 3
(ice/INFO) ICE(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home)): All candidates initialized
(generic/CRIT) PR_Connect failed: -5980
(ice/WARNING) /builds/worker/checkouts/gecko/dom/media/webrtc/transport/third_party/nICEr/src/net/nr_socket_multi_tcp.c:639 function nr_socket_multi_tcp_listen failed with error 3
(ice/WARNING) ICE-STREAM(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home) transport-id=transport_0 - c71730bb:54ae3990a18fe7c5e8e67bddb6f56bbb): failed to create passive TCP host candidate: 3
(ice/INFO) ICE(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home)): peer (PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home):default) starting grace period timer for 5000 ms
(ice/NOTICE) ICE(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home)): peer (PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home):default) no streams with non-empty check lists
(ice/NOTICE) ICE(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home)): peer (PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home):default) no streams with pre-answer requests
(ice/INFO) ICE(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home)): peer (PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home):default) no checks to start, but gathering is not done yet, cancelling grace period timer
(ice/ERR) ICE(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home)): peer (PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home):default) pairing local trickle ICE candidate host(IP4:192.168.1.28:56443/UDP)
(ice/INFO) ICE(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home)): peer (PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home):default) starting grace period timer for 5000 ms
(ice/ERR) ICE(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home)): peer (PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home):default) pairing local trickle ICE candidate host(IP4:192.168.1.28:63946/TCP) active
(ice/INFO) ICE(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home)): All candidates initialized
(ice/INFO) ICE(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home)): peer (PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home):default) Trickle grace period is over; marking every component with only failed pairs as failed.
(ice/INFO) ICE-PEER(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home):default)/STREAM(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home) transport-id=transport_0 - c71730bb:54ae3990a18fe7c5e8e67bddb6f56bbb)/COMP(1): All pairs are failed, and grace period has elapsed. Marking component as failed.
(ice/ERR) ICE(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home))/STREAM(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home) transport-id=transport_0 - c71730bb:54ae3990a18fe7c5e8e67bddb6f56bbb): state dump
(ice/ERR) ICE(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home))/ICE-STREAM(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home) transport-id=transport_0 - c71730bb:54ae3990a18fe7c5e8e67bddb6f56bbb): Local component 1 - dumping candidates
(ice/ERR) ICE(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home))/ICE-STREAM(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home) transport-id=transport_0 - c71730bb:54ae3990a18fe7c5e8e67bddb6f56bbb)/CAND(5fk0): host(IP4:192.168.1.28:56443/UDP)
(ice/ERR) ICE(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home))/ICE-STREAM(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home) transport-id=transport_0 - c71730bb:54ae3990a18fe7c5e8e67bddb6f56bbb)/CAND(vE/5): host(IP4:192.168.1.28:63946/TCP) active
(ice/ERR) ICE-PEER(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home):default)/STREAM(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home) transport-id=transport_0 - c71730bb:54ae3990a18fe7c5e8e67bddb6f56bbb): state dump
(ice/ERR) ICE(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home))/ICE-STREAM(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home) transport-id=transport_0 - c71730bb:54ae3990a18fe7c5e8e67bddb6f56bbb): Remote component 1 in state 3 - dumping candidates
(ice/INFO) ICE-PEER(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home):default): all checks completed success=0 fail=1
(ice/INFO) ICE(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home)): peer (PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home):default) starting grace period timer for 5000 ms
(ice/NOTICE) ICE(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home)): peer (PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home):default) no streams with non-empty check lists
(ice/NOTICE) ICE(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home)): peer (PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home):default) no streams with pre-answer requests
(ice/INFO) ICE-PEER(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home):default)/CAND-PAIR(S2jI): setting pair to state FROZEN: S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)
(ice/INFO) ICE(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home))/CAND-PAIR(S2jI): Pairing candidate IP4:192.168.1.28:56005/UDP (7e7f00ff):IP4:192.168.1.28:56443/UDP (7e7f00ff) priority=9115005270282338815 (7e7f00fffcfe01ff)
(ice/INFO) ICE-PEER(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home):default)/ICE-STREAM(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home) transport-id=transport_0 - a9c7cadd:7ce62f845d4f5b83df2a70e1bac037bf): Starting check timer for stream.
(ice/INFO) ICE-PEER(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home):default)/CAND-PAIR(S2jI): setting pair to state WAITING: S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)
(ice/INFO) ICE-PEER(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home):default)/CAND-PAIR(S2jI): setting pair to state IN_PROGRESS: S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)
(ice/NOTICE) ICE(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home)): peer (PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home):default) is now checking
(stun/INFO) Responding with error 400: ICE Failure
(ice/NOTICE) ICE(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home)): Message does not correspond to any registered stun ctx
(stun/INFO) STUN-CLIENT(S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)): Received response; processing
(stun/WARNING) STUN-CLIENT(S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)): nr_stun_process_error_response failed
(stun/WARNING) STUN-CLIENT(S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)): Error processing response: Retry may be possible, stun error code 400.
(ice/INFO) ICE-PEER(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home):default): no FROZEN/WAITING pairs for PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home) transport-id=transport_0 - a9c7cadd:7ce62f845d4f5b83df2a70e1bac037bf
(stun/INFO) Responding with error 400: ICE Failure
(ice/NOTICE) ICE(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home)): Message does not correspond to any registered stun ctx
(stun/INFO) STUN-CLIENT(S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)): Received response; processing
(stun/WARNING) STUN-CLIENT(S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)): nr_stun_process_error_response failed
(stun/WARNING) STUN-CLIENT(S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)): Error processing response: Retry may be possible, stun error code 400.
(stun/INFO) Responding with error 400: ICE Failure
(ice/NOTICE) ICE(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home)): Message does not correspond to any registered stun ctx
(stun/INFO) STUN-CLIENT(S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)): Received response; processing
(stun/WARNING) STUN-CLIENT(S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)): nr_stun_process_error_response failed
(stun/WARNING) STUN-CLIENT(S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)): Error processing response: Retry may be possible, stun error code 400.
(stun/INFO) Responding with error 400: ICE Failure
(ice/NOTICE) ICE(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home)): Message does not correspond to any registered stun ctx
(stun/INFO) STUN-CLIENT(S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)): Received response; processing
(stun/WARNING) STUN-CLIENT(S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)): nr_stun_process_error_response failed
(stun/WARNING) STUN-CLIENT(S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)): Error processing response: Retry may be possible, stun error code 400.
(stun/INFO) Responding with error 400: ICE Failure
(ice/NOTICE) ICE(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home)): Message does not correspond to any registered stun ctx
(stun/INFO) STUN-CLIENT(S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)): Received response; processing
(stun/WARNING) STUN-CLIENT(S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)): nr_stun_process_error_response failed
(stun/WARNING) STUN-CLIENT(S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)): Error processing response: Retry may be possible, stun error code 400.
(stun/INFO) Responding with error 400: ICE Failure
(ice/NOTICE) ICE(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home)): Message does not correspond to any registered stun ctx
(stun/INFO) STUN-CLIENT(S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)): Received response; processing
(stun/WARNING) STUN-CLIENT(S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)): nr_stun_process_error_response failed
(stun/WARNING) STUN-CLIENT(S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)): Error processing response: Retry may be possible, stun error code 400.
(ice/INFO) ICE(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home)): peer (PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home):default) Trickle grace period is over; marking every component with only failed pairs as failed.
(stun/INFO) Responding with error 400: ICE Failure
(ice/NOTICE) ICE(PC:{f1eb3850-ea2c-4c5d-8699-1bd8bcdbe09b} 1656968377394000 (id=2147483690 url=about:home)): Message does not correspond to any registered stun ctx
(stun/INFO) STUN-CLIENT(S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)): Received response; processing
(stun/WARNING) STUN-CLIENT(S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)): nr_stun_process_error_response failed
(stun/WARNING) STUN-CLIENT(S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)): Error processing response: Retry may be possible, stun error code 400.
(stun/INFO) STUN-CLIENT(S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)): Timed out
(ice/INFO) ICE-PEER(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home):default)/CAND-PAIR(S2jI): setting pair to state FAILED: S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host)
(ice/INFO) ICE-PEER(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home):default)/STREAM(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home) transport-id=transport_0 - a9c7cadd:7ce62f845d4f5b83df2a70e1bac037bf)/COMP(1): All pairs are failed, and grace period has elapsed. Marking component as failed.
(ice/ERR) ICE(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home))/STREAM(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home) transport-id=transport_0 - a9c7cadd:7ce62f845d4f5b83df2a70e1bac037bf): state dump
(ice/ERR) ICE(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home))/ICE-STREAM(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home) transport-id=transport_0 - a9c7cadd:7ce62f845d4f5b83df2a70e1bac037bf): Local component 1 - dumping candidates
(ice/ERR) ICE(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home))/ICE-STREAM(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home) transport-id=transport_0 - a9c7cadd:7ce62f845d4f5b83df2a70e1bac037bf)/CAND(R6E4): host(IP4:192.168.1.28:56005/UDP)
(ice/ERR) ICE(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home))/ICE-STREAM(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home) transport-id=transport_0 - a9c7cadd:7ce62f845d4f5b83df2a70e1bac037bf)/CAND(xSO3): host(IP4:192.168.1.28:60680/TCP) active
(ice/ERR) ICE-PEER(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home):default)/STREAM(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home) transport-id=transport_0 - a9c7cadd:7ce62f845d4f5b83df2a70e1bac037bf): state dump
(ice/ERR) CAND-PAIR(S2jI): pair S2jI|IP4:192.168.1.28:56005/UDP|IP4:192.168.1.28:56443/UDP(host(IP4:192.168.1.28:56005/UDP)|candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host): state=FAILED, priority=0x7e7f00fffcfe01ff
(ice/ERR) ICE(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home))/ICE-STREAM(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home) transport-id=transport_0 - a9c7cadd:7ce62f845d4f5b83df2a70e1bac037bf): Remote component 1 in state 3 - dumping candidates
(ice/ERR) ICE(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home))/ICE-STREAM(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home) transport-id=transport_0 - a9c7cadd:7ce62f845d4f5b83df2a70e1bac037bf)/CAND(giJB): candidate:0 1 UDP 2122252543 192.168.1.28 56443 typ host
(ice/ERR) ICE(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home))/ICE-STREAM(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home) transport-id=transport_0 - a9c7cadd:7ce62f845d4f5b83df2a70e1bac037bf)/CAND(eRB0): candidate:1 1 TCP 2105524479 192.168.1.28 9 typ host tcptype active
(ice/INFO) ICE-PEER(PC:{a3e94488-2d82-4739-9c98-ce3de577714b} 1656968349764000 (id=2147483688 url=about:home):default): all checks completed success=0 fail=1
+++++++ END (process id 21692) ++++++++
</code></pre>
<p>while local and remote SDPs respectively look like this:</p>
<pre><code>v=0
o=mozilla...THIS_IS_SDPARTA-99.0 1501128418895448605 0 IN IP4 0.0.0.0
s=-
t=0 0
a=fingerprint:sha-256 26:27:49:F1:75:8E:96:56:D6:A9:3F:E9:28:A9:D8:3A:E3:99:CA:52:4B:22:3C:6C:9D:02:FD:C7:AE:21:17:3F
a=group:BUNDLE 0
a=ice-options:trickle
a=msid-semantic:WMS *
m=application 9 UDP/DTLS/SCTP webrtc-datachannel
c=IN IP4 0.0.0.0
a=sendrecv
a=ice-pwd:7ce62f845d4f5b83df2a70e1bac037bf
a=ice-ufrag:a9c7cadd
a=mid:0
a=setup:actpass
a=sctp-port:5000
a=max-message-size:1073741823
</code></pre>
<pre><code>v=0
o=mozilla...THIS_IS_SDPARTA-99.0 5475832728403267594 0 IN IP4 0.0.0.0
s=-
t=0 0
a=sendrecv
a=fingerprint:sha-256 DC:E2:A0:CE:08:9B:25:D6:63:E0:6A:D8:94:05:82:1A:9B:27:47:4B:83:30:95:72:B4:BD:0B:62:2F:44:7C:9D
a=group:BUNDLE 0
a=ice-options:trickle
a=msid-semantic:WMS *
m=application 9 UDP/DTLS/SCTP webrtc-datachannel
c=IN IP4 0.0.0.0
a=candidate:0 1 UDP 2122252543 eb5fb3b1-f3d1-4add-afff-e9cde1bf07a2.local 56443 typ host
a=candidate:1 1 TCP 2105524479 eb5fb3b1-f3d1-4add-afff-e9cde1bf07a2.local 9 typ host tcptype active
a=sendrecv
a=end-of-candidates
a=ice-pwd:54ae3990a18fe7c5e8e67bddb6f56bbb
a=ice-ufrag:c71730bb
a=mid:0
a=setup:active
a=sctp-port:5000
a=max-message-size:1073741823
</code></pre>
<hr />
<p>Strangely, connection can be established between tabs of different browsers (sender in Edge and receiver in Firefox, or vice versa). Remote SDPs of the Firefox client (therefore describing Edge session) look like this:</p>
<pre><code>v=0
o=- 6799550255512083034 2 IN IP4 127.0.0.1
s=-
t=0 0
a=group:BUNDLE 0
a=extmap-allow-mixed
a=msid-semantic: WMS
m=application 9 UDP/DTLS/SCTP webrtc-datachannel
c=IN IP4 0.0.0.0
a=candidate:2606571665 1 udp 2113937151 5b5fd4e1-64b5-421c-b103-ca4a29c106dc.local 62776 typ host generation 0 network-cost 999
a=ice-ufrag:Gc38
a=ice-pwd:zxGRR6Dlm+usOA+Xx4BmuN2x
a=ice-options:trickle
a=fingerprint:sha-256 6C:23:49:63:D3:60:78:D2:AF:1E:68:4F:7C:EC:19:1C:29:5C:64:A0:5B:29:7B:D3:5B:5F:CC:81:7E:EA:56:97
a=setup:actpass
a=mid:0
a=sctp-port:5000
a=max-message-size:262144
</code></pre>
",42,1,0,5,javascript;firefox;networking;webrtc;sdp,2022-07-05 02:45:17,2022-07-05 02:45:17,2022-07-05 12:56:34,i want to develop a webrtc based streaming application and i am learning about the protocol starting from the basics  in particular  i followed this extremely simple   also shown in this   that just opens a webrtc channel  between two browser tabs  and was able to run it on microsoft edge in my local machine  however  if i use the same javascript code in firefox  version   on windows    i receive an error webrtc  ice failed  add a stun server and see about webrtc for more details on both sender and receiver tabs  i have therefore tried to include the stun  turn and turns servers provided by  in the configuration  but the same error message always appears  i would like my application to work on the most used internet browsers  so i am wondering how this can be fixed before digging deeper  similar questions seemed a bit outdated or related to different errors  thank you all in advance for your help and suggestion  considering the simplest case with no stun nor turn server  which should work in a local network or at least on the same localhost   webrtc s connection registry contains this  while local and remote sdps respectively look like this  strangely  connection can be established between tabs of different browsers  sender in edge and receiver in firefox  or vice versa   remote sdps of the firefox client  therefore describing edge session  look like this ,webrtc  ice failed in firefox  but working in ms edge
132,132,806160,72865447,Compute similarity in pyspark,"<p>I have a <code>csv</code> file contains some data, I want select the similar data with an input.
my data is like:</p>
<pre><code>H1      | H2      | H3
--------+---------+----------
A       | 1       | 7
B       | 5       | 3
C       | 7       | 2
</code></pre>
<p>And the data point that I want find data similar to that in my <code>csv</code> is like : <code>[6, 8]</code>.</p>
<p>Actually I want find rows that <code>H2</code> and <code>H3</code> of data set is similar to input, and It return <code>H1</code>.</p>
<p>I want use pyspark and some similarity measure like Euclidean Distance, Manhattan Distance, Cosine Similarity or machine learning algorithm.</p>
",39,0,0,3,pyspark;similarity;sentence-similarity,2022-07-05 12:52:19,2022-07-05 12:52:19,2022-07-05 12:52:19,and the data point that i want find data similar to that in my csv is like         actually i want find rows that h and h of data set is similar to input  and it return h  i want use pyspark and some similarity measure like euclidean distance  manhattan distance  cosine similarity or machine learning algorithm ,compute similarity in pyspark
133,133,9098088,72862237,MATLAB string to integer conversion,"<p>I am a newbie at matlab. I have deployed a machine learning model(developed using python) using flask. From matlab, I have called the API and received a string response. The response is like: '[0.8]'. but matlab is showing the size of the string is 1. I need only the value 0.8. My code:</p>
<pre><code>import matlab.net.http.*
import matlab.net.http.field.*

request = RequestMessage( 'POST', ...
    [ContentTypeField( 'application/vnd.api+json' ), AcceptField('application/vnd.api+json')], ...
    '{&quot;meta&quot;: {&quot;Speed_RPM_PU&quot;: 0.2}}' );
response = request.send( 'http://127.0.0.1:5000/predict' );
ans=response.Body.Data
length(ans) % equals to 1
% for i = 1:length(ans)
%  
%    fprintf('%c ',ans(i))
%  
%    %disp(String(i))
%  
% end
</code></pre>
<p>Here, ans='[0.8]'</p>
",32,1,1,2,string;matlab,2022-07-05 03:08:43,2022-07-05 03:08:43,2022-07-05 12:45:53,i am a newbie at matlab  i have deployed a machine learning model developed using python  using flask  from matlab  i have called the api and received a string response  the response is like         but matlab is showing the size of the string is   i need only the value    my code  here  ans      ,matlab string to integer conversion
134,134,14097339,72864679,Apache Spark machine learning using mllib,"<p>I have imported the dataset in spark scala which has many numeric, string, and JSON type fields. How can I transform this data for classification and clustering tasks? I am new to spark, any help would be appreciated.</p>
",24,0,-1,3,scala;apache-spark;apache-spark-mllib,2022-07-05 11:39:06,2022-07-05 11:39:06,2022-07-05 11:39:06,i have imported the dataset in spark scala which has many numeric  string  and json type fields  how can i transform this data for classification and clustering tasks  i am new to spark  any help would be appreciated ,apache spark machine learning using mllib
135,135,12698225,72863635,Getting error message when pinging target machine through ssh with ansible inventory file,"<p>I'm learning Ansible. I created an inventory file to ping my target hosts through it.</p>
<p>Every time i am doing it I am getting the error message:</p>
<pre><code>ansible [core 2.12.7]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/home/ubuntu/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python3/dist-packages/ansible
  ansible collection location = /home/ubuntu/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/bin/ansible
  python version = 3.10.4 (main, Apr  2 2022, 09:04:19) [GCC 11.2.0]
  jinja version = 3.0.3
  libyaml = True
Using /etc/ansible/ansible.cfg as config file
host_list declined parsing /home/ubuntu/vprofile/exercise1/inventory as it did not pass its verify_file() method
script declined parsing /home/ubuntu/vprofile/exercise1/inventory as it did not pass its verify_file() method
auto declined parsing /home/ubuntu/vprofile/exercise1/inventory as it did not pass its verify_file() method
Parsed /home/ubuntu/vprofile/exercise1/inventory inventory source with ini plugin
Skipping callback 'default', as we already have a stdout callback.
Skipping callback 'minimal', as we already have a stdout callback.
Skipping callback 'oneline', as we already have a stdout callback.
META: ran handlers
&lt;172.31.84.210&gt; ESTABLISH SSH CONNECTION FOR USER: amazon
&lt;172.31.84.210&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile=&quot;vprofile-key.pem&quot;' -o KbdInteractivi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;amazon&quot;' -o ConnectTimeout=10 -o 'ControlPath=&quot;/home/ubuntu/.ansible/cp/715n &amp;&amp; sleep 0'&quot;'&quot;''
&lt;172.31.84.210&gt; (255, b'', b'amazon@172.31.84.210: Permission denied (publickey,gssapi-keyex,gssapi-with-mic).\r\n')
web01 | UNREACHABLE! =&gt; {
    &quot;changed&quot;: false,
    &quot;msg&quot;: &quot;Failed to connect to the host via ssh: amazon@172.31.84.210: Permission denied (publickey,gssapi-keyex,gssapi-with-mic).&quot;,
    &quot;unreachable&quot;: true





I tried SSH with my host machine to target machine its working fine.
</code></pre>
<p>PS: Im using Ubuntu server as my host and target machine and I have put ansible_user=amazon</p>
<p>Please help me out.</p>
",21,0,0,4,amazon-web-services;amazon-ec2;ansible;ansible-inventory,2022-07-05 08:41:25,2022-07-05 08:41:25,2022-07-05 09:26:21,i m learning ansible  i created an inventory file to ping my target hosts through it  every time i am doing it i am getting the error message  ps  im using ubuntu server as my host and target machine and i have put ansible_user amazon please help me out ,getting error message when pinging target machine through ssh with ansible inventory file
136,136,16523991,72863524,Is My Extra Tree Classifier Model Over/Underfit?,"<p>I was playing around with some models and training them on a heart disease dataset and found my Extra Tree Classifier reported a 100% accuracy. I was shocked at first since I had never gotten a perfect score report from a model, but I realized that the model is most likely over/underfit. After doing some research, I found that you can determine if a model is over/underfit by comparing the Training Score and Cross Validation Score reports, but after looking at the report, I could not tell if my model was over/underfit or if it really is perfect. (I am new to machine learning and I have high doubts that it is actually perfect.)
Here is the model report:</p>
<p><a href=""https://i.stack.imgur.com/bTJMU.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bTJMU.png"" alt=""Extra Tree Classifier Model Report"" /></a></p>
<p>Can someone help me figure out if this model is over/underfit? (If I need to give any more data/info to figure this out, please let me know!)</p>
",22,0,-2,3,python;machine-learning;classification,2022-07-05 08:17:53,2022-07-05 08:17:53,2022-07-05 08:17:53, can someone help me figure out if this model is over underfit   if i need to give any more data info to figure this out  please let me know  ,is my extra tree classifier model over underfit 
137,137,224059,7673509,Automatically built regex expressions that fit set of strings,"<p>We have written the system to analyse log messages from the large network. The system takes log messages from lots of different network elements, and analyses it by regex expressions. For example user may have written two rules:</p>

<pre><code>^cron/script\.sh.*
.*script\.sh [0-9]+$
</code></pre>

<p>In this case only logs that match given patterns will be selected. The reason of the filtering is that there may be really lots of log messages, up to 1 GB per day.</p>

<p>Now the main part of my question. Since there is lots of network elements, and several types of them, and every one of them has different parameters in path... Is there any way to automatically generate set of regexes that will somehow group the logs? The system can learn on historical data, e.g. from the last week. Generated regex must not be very accurate, it is supposed to be the hint for user to add such new rule into system.</p>

<p>I was thinking about unsupervised machine learning to divide input into groups and then in each group find proper regex. Is there any other way, maybe faster or better? And, last but not least, <em>how to</em> find regex that matches all strings in obtained group?  (Non-trivial, so <code>.*</code> is not the answer.)</p>

<hr>

<p><strong>Edit</strong> After some thinking I'll try to simplify the problem. Suppose I have already grouped logs. I'd like to find (at most) three largest substrings (at least one) common to all the strings in set. For example:</p>

<pre><code>Set of strings:
cron/script1.sh -abc 1243 all
cron/script2.sh 1
bin/script1.sh -asdf 15

Obtained groups:
/script
.sh 
</code></pre>

<p>Now I can build some simple regex by concatenating these groups with <code>.*?</code>. In this example it would be <code>.*?(/script).*?(\.sh ).*?</code>. It seems to be simpler solution.</p>
",4155,4,8,4,regex;string;algorithm;grammar-induction,2011-10-06 16:48:39,2011-10-06 16:48:39,2022-07-05 02:16:17,we have written the system to analyse log messages from the large network  the system takes log messages from lots of different network elements  and analyses it by regex expressions  for example user may have written two rules  in this case only logs that match given patterns will be selected  the reason of the filtering is that there may be really lots of log messages  up to  gb per day  now the main part of my question  since there is lots of network elements  and several types of them  and every one of them has different parameters in path    is there any way to automatically generate set of regexes that will somehow group the logs  the system can learn on historical data  e g  from the last week  generated regex must not be very accurate  it is supposed to be the hint for user to add such new rule into system  i was thinking about unsupervised machine learning to divide input into groups and then in each group find proper regex  is there any other way  maybe faster or better  and  last but not least  how to find regex that matches all strings in obtained group    non trivial  so    is not the answer   edit after some thinking i ll try to simplify the problem  suppose i have already grouped logs  i d like to find  at most  three largest substrings  at least one  common to all the strings in set  for example  now i can build some simple regex by concatenating these groups with      in this example it would be      script       sh       it seems to be simpler solution ,automatically built regex expressions that fit set of strings
138,138,19481384,72860224,I want to get data from another site and display it on my site with my old CSS,"<p>I made this site using HTML CSS
And I want to get data from this site <strong><a href=""http://103.152.199.179/YCCE/Suported%20file/Supprted%20file/SERIES%20WISE%20BOOKS/CIVIL%20ENGINEERING/"" rel=""nofollow noreferrer"">I want to get data from this site</a></strong>
and update now in my site there are 6 files so I wrote CSS according to them
But in the future, it will be more. So how can I get the files from that site, and it should auto-update on my site. Whatever new files will come, the CSS that I have written for the old 6 files should also apply to it.
So can anyone help me?
<div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-css lang-css prettyprint-override""><code>* {
    padding: 0;
    margin: 0;

}

body {
    /* font-family: 'Open Sans', sans-serif; */
    overflow-x: hidden;
    /* overflow: hidden;
    Hide scrollbars  */
}


.nav {
    background-color: rgb(90, 183, 241);
    padding: 7px;
    margin-top: -1px;
    width: 100%;
    overflow: hidden;
}



/* ADMINISTRATION Start */
.nav ul {
    display: inline-flex;
    list-style: none;
    color: white;
    font-size: 13px;
    margin: -4px 0px -5px 0px;
    letter-spacing: 0.5px;
    font-weight: bolder;
}

.nav ul li {
    margin: 1px 1px 1px 1px;

}


.nav ul li a {
    text-decoration: none;
    color: white;
    padding-inline: 5px;
    line-height: 1.42857143;
}

/* LOGO */
.logo img {
    vertical-align: middle;
    height: 25px;
    border: 0px;
    margin: 0px 10px 5px 0px;
}


.nav .fa {
    margin-left: 1px;
}

.sub-menu-1 .fa-caret-right {
    margin-left: 10px;
}

.active,
.nav ul li:hover {
    background-color: #bca3f2;
    border-radius: 3px;
    color: black;
    padding: 4px 2px 4px;
}

/* SUB-MENU-1 */
.sub-menu-1 ul li a {
    font-weight: bolder;
    font-size: 12px;
    letter-spacing: 0.5px;

}

.sub-menu-1 ul li:hover {
    background-color: #bca3f2;
    padding: 0px 0px 0px 0px;

}

.sub-menu-1 ul li a:hover {
    color: black;
}

.sub-menu-1 {
    display: none;
    position: absolute;
    box-shadow: 0px 8px 16px 0px rgba(0, 0, 0, 0.2);
    z-index: 1;
    top: 30px;
    margin-left: -3;
}

.sub-menu-1 a {
    padding: 5% 0px 1px 0px;
    text-decoration: none;
    display: block;
}

.nav ul li:hover .sub-menu-1 {
    display: block;
    position: absolute;
    background: rgb(72, 162, 197);
}

.nav ul li:hover .sub-menu-1 ul {
    display: block;
    margin: 10px;
}


/* inside sub menu User Management */
.fa-caret-right {
    float: right;
    right: 2px;
}

/*sub-in-menu1 start  */

.sub-in-menu1 {
    display: none;
    position: absolute;
    box-shadow: 0px 8px 16px 0px rgb(0 0 0 / 20%);
    margin-top: -29px;
    margin-left: 250px;
    z-index: 1;
    justify-content: space-between;
    -webkit-justify-content: space-between;
    border-bottom: 1px solid #e6e6e6;
}

.hover-me .sub-in-menu1 a {
    text-decoration: none;
    display: block;
    width: 100%;
    margin: 0px 100px 5px 1px;
}

.hover-me .sub-in-menu1 ul li {
    padding: 0px 10px 0px 0px;
    border-bottom: 1px solid #e6e6e6;
}


.hover-me:hover .sub-in-menu1 {
    display: block;
    position: absolute;
    background: rgb(72, 162, 197);
}

/* sub-in-menu1 End */
/* ADMINISTRATION End */

/* ACADEMIC Start */
/* sub-in-menu2 Start */
.sub-in-menu2 {
    display: none;
    position: absolute;
    box-shadow: 0px 8px 16px 0px rgb(0 0 0 / 20%);
    margin-top: -29px;
    margin-left: 220px;
    z-index: 1;
    justify-content: space-between;
    -webkit-justify-content: space-between;
    border-bottom: 1px solid #e6e6e6;
}

.hover-me .sub-in-menu2 a {
    margin: 0px 60px 5px 1px;
    text-decoration: none;
    display: block;
    width: 100%;
}

.hover-me .sub-in-menu2 ul li {
    padding: 0px 10px 0px 0px;
    border-bottom: 1px solid #e6e6e6;
}


.hover-me:hover .sub-in-menu2 {
    display: block;
    position: absolute;
    background: rgb(72, 162, 197);
}

/* sub-in-menu2 End */
/* ACADEMIC End */

/* Responsive */
@media screen and (max-width:700px) {
    .nav ul {
        float: none;
        display: block;
        width: 100%;
        text-align: left;
        /* If you want the text to be left-aligned on small screens */
    }
}


/* FOOTER */
/* FOOTER */

strong {
    letter-spacing: 0.5px;
    font-size: 14px;
    font-weight: bolder;
    font-family: 'Open Sans', sans-serif;
}

.main-footer {
    background: #fff;
    padding: 0px;
    color: #444;
    border-top: 1px solid #d2d6de;
}

.navbar-fixed-bottom {
    bottom: 0;
    margin-bottom: 0;
    border-width: 1px 0 0;
}


.navbar-fixed-bottom,
.navbar-fixed-top {
    position: fixed;
    right: 0;
    left: 0;
    z-index: 1030;
    text-align: center;
}

.content-wrapper {
    min-height: 565px;
}</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;!DOCTYPE html&gt;
&lt;html lang=""en""&gt;

&lt;head&gt;
    &lt;meta charset=""UTF-8""&gt;
    &lt;meta http-equiv=""X-UA-Compatible"" content=""IE=edge""&gt;
    &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1.0""&gt;
    &lt;title&gt;YC_LIBRARY&lt;/title&gt;
    &lt;link href=""https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,600;0,700;1,800&amp;display=swap""
        rel=""stylesheet""&gt;
    &lt;link rel=""stylesheet"" href=""lib.css""&gt;
    &lt;link rel=""stylesheet"" href=""https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/fontawesome.min.css""&gt;
    &lt;script src=""https://kit.fontawesome.com/892d11d632.js"" crossorigin=""anonymous""&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body&gt;
    &lt;div class=""content-wrapper""&gt;
        &lt;div class=""nav""&gt;
            &lt;ul&gt;
                &lt;div class=""logo""&gt;
                    &lt;img src=""YCC Logo.png"" alt=""YCC Logo""&gt;
                &lt;/div&gt;
                &lt;li class=""active""&gt;&lt;a href=""#""&gt;BOOKS&lt;i class=""fa
                                fa-caret-down""&gt;&lt;/i&gt;&lt;/a&gt;
                    &lt;div class=""sub-menu-1""&gt;
                        &lt;ul&gt;
                            &lt;li class=""hover-me""&gt;&lt;a href=""#""&gt;UG COURSES&lt;i class=""fa fa-caret-right""&gt;&lt;/i&gt;&lt;/a&gt;
                                &lt;div class=""sub-in-menu1""&gt;
                                    &lt;ul&gt;

                                        &lt;li&gt;&lt;a href=""http://103.152.199.179/YCCE/Suported%20file/Supprted%20file/SERIES%20WISE%20BOOKS/CIVIL%20ENGINEERING/""
                                                target=""_blank""&gt;Civil
                                                Engineering&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Mechanical
                                                Engineering&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Electrical
                                                Engineering&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Electronics &amp;
                                                Telecommunication&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Engineering&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Electronics
                                                Engineering&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Computer Technology&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Information
                                                Technology&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Computer Science &amp;
                                                Engineering&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Computer Science &amp;
                                                Engineering(Artificial
                                                Intelligence
                                                &amp; Machine
                                                Learning)&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Computer Science &amp;
                                                Design&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Industrial IOT&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Artificial
                                                Intelligence
                                                &amp; Data Science&lt;/a&gt;&lt;/li&gt;
                                    &lt;/ul&gt;
                                &lt;/div&gt;
                            &lt;/li&gt;
                            &lt;li class=""hover-me""&gt;&lt;a href=""#""&gt;PG COURSES&lt;i class=""fa fa-caret-right""&gt;&lt;/i&gt;&lt;/a&gt;
                                &lt;div class=""sub-in-menu1""&gt;
                                    &lt;ul&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Structural
                                                Engineering&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;CAD/CAM&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Integrated Power
                                                System&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Computer Science &amp;
                                                Engineering&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Communication
                                                Engineering&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Environmental
                                                Engineering&lt;/a&gt;&lt;/li&gt;
                                    &lt;/ul&gt;
                                &lt;/div&gt;

                            &lt;/li&gt;
                            &lt;li class=""hover-me""&gt;&lt;a href=""#""&gt;OTHER BOOKS&lt;i class=""fa fa-caret-right""&gt;&lt;/i&gt;&lt;/a&gt;
                                &lt;div class=""sub-in-menu1""&gt;
                                    &lt;ul&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Engineering &amp;
                                                Technology&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;General books&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;PD books&lt;/a&gt;&lt;/li&gt;
                                    &lt;/ul&gt;
                                &lt;/div&gt;
                            &lt;/li&gt;
                            &lt;li class=""hover-me""&gt;&lt;a href=""#""&gt;APPLIED
                                    SCIENCES
                                    &amp;HUMANITIES&lt;i class=""fa fa-caret-right""&gt;&lt;/i&gt;&lt;/a&gt;
                                &lt;div class=""sub-in-menu1""&gt;
                                    &lt;ul&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Physics&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Chemistry&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Mathematics&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Communication Skill&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Social Science&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Sciences&lt;/a&gt;&lt;/li&gt;
                                    &lt;/ul&gt;
                                &lt;/div&gt;
                            &lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/li&gt;
                &lt;li&gt;&lt;a href=""#""&gt;JOURNALS &lt;i class=""fa fa-caret-down""&gt;&lt;/i&gt;&lt;/a&gt;
                    &lt;div class=""sub-menu-1""&gt;
                        &lt;ul&gt;
                            &lt;li class=""hover-me""&gt;&lt;a href=""#""&gt;IEEE ASPP
                                    ONLINE
                                    JOURNALS&lt;i class=""fa
                                            fa-caret-right""&gt;&lt;/i&gt;
                                &lt;/a&gt;
                                &lt;div class=""sub-in-menu2""&gt;
                                    &lt;ul&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Download List&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Login&lt;/a&gt;&lt;/li&gt;
                                    &lt;/ul&gt;
                                &lt;/div&gt;
                            &lt;/li&gt;
                            &lt;li class=""hover-me""&gt;&lt;a href=""#""&gt;CONFERENCE
                                    PROCEEDINGS&lt;i class=""fa fa-caret-right""&gt;&lt;/i&gt;&lt;/a&gt;
                                &lt;div class=""sub-in-menu2""&gt;
                                    &lt;ul&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;Download List&lt;/a&gt;&lt;/li&gt;
                                    &lt;/ul&gt;
                                &lt;/div&gt;

                            &lt;/li&gt;
                            &lt;li class=""hover-me""&gt;&lt;a href=""#""&gt;PRINT JOURNALS&lt;i class=""fa
                                            fa-caret-right""&gt;&lt;/i&gt;&lt;/a&gt;
                                &lt;div class=""sub-in-menu2""&gt;
                                    &lt;ul&gt;
                                        &lt;li&gt;
                                            &lt;a href=""#""&gt;Download List&lt;/a&gt;
                                        &lt;/li&gt;
                                    &lt;/ul&gt;
                                &lt;/div&gt;
                            &lt;/li&gt;
                            &lt;li class=""hover-me""&gt;&lt;a href=""#""&gt;MAT JOURNALS&lt;i class=""fa fa-caret-right""&gt;&lt;/i&gt;&lt;/a&gt;
                                &lt;div class=""sub-in-menu2""&gt;
                                    &lt;ul&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;DOWNLOAD ONLINE
                                                JOURNALS
                                                NATIONAL LIST&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;ONLINE USERNAME
                                                PASSWORD&lt;/a&gt;&lt;/li&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;ONLINE PORTAL&lt;/a&gt;&lt;/li&gt;
                                    &lt;/ul&gt;
                                &lt;/div&gt;
                            &lt;/li&gt;
                            &lt;li class=""hover-me""&gt;&lt;a href=""#""&gt;OPAC&lt;i class=""fa fa-caret-right""&gt;&lt;/i&gt;&lt;/a&gt;
                                &lt;div class=""sub-in-menu2""&gt;
                                    &lt;ul&gt;
                                        &lt;li&gt;&lt;a href=""#""&gt;OPAC PORTAL&lt;/a&gt;&lt;/li&gt;
                                    &lt;/ul&gt;
                                &lt;/div&gt;
                            &lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/li&gt;
                &lt;li&gt;&lt;a href=""#""&gt;E-RESOURCES &lt;i class=""fa
                                fa-caret-down""&gt;&lt;/i&gt;&lt;/a&gt;
                    &lt;div class=""sub-in-menu1""&gt;
                        &lt;ul&gt;
                            &lt;li&gt;

                            &lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/div&gt;
                &lt;/li&gt;
                &lt;footer class=""main-footer navbar-fixed-bottom text-center""&gt;
                    &lt;strong&gt;
                        Designed and Developed By: MIS/ERP
                    &lt;/strong&gt;
                &lt;/footer&gt;
        &lt;/div&gt;
&lt;/body&gt;

&lt;/html&gt;</code></pre>
</div>
</div>
</p>
",48,0,0,3,javascript;html;css,2022-07-04 22:56:19,2022-07-04 22:56:19,2022-07-05 00:19:23,,i want to get data from another site and display it on my site with my old css
139,139,6527049,70663003,MongoServerSelectionError: connection &lt;monitor&gt; to &lt;MyIP&gt; closed,"<p>I have started learning MongoDB, I am just trying to connect to the database using MongoDB Shell.
I am using the below command.</p>
<pre><code>mongosh &quot;mongodb+srv://cluster0.12345.mongodb.net/myFirstDatabase&quot; --username viveknuna
</code></pre>
<p>I have added my current IP Address to IP Access List. But getting this error.</p>
<blockquote>
<p>MongoServerSelectionError: connection  to  closed</p>
</blockquote>
<p>I have referred to <a href=""https://stackoverflow.com/q/60431996/6527049"">this</a> question and added 0.0.0.0/0 (Allow access from AnyWhere) in the IP Access List. and it works as expected. But this is a security risk, Is there any way without allowing all IPs.</p>
<p><strong>FYI</strong>: I am inside Virtual Machine and running this command also from VM.</p>
",871,1,1,3,mongodb;mongodb-atlas;mongo-shell,2022-01-11 12:55:15,2022-01-11 12:55:15,2022-07-04 23:22:05,i have added my current ip address to ip access list  but getting this error  mongoserverselectionerror  connection  to  closed i have referred to  question and added       allow access from anywhere  in the ip access list  and it works as expected  but this is a security risk  is there any way without allowing all ips  fyi  i am inside virtual machine and running this command also from vm ,mongoserverselectionerror  connection  lt monitor gt  to  lt myip gt  closed
140,140,9895048,59408524,How to unzip image folder in colab,"<p><strong>I want to train a deep learning model on a Devanagari dataset containing around 9000 images. Since the dataset is huge, I want to use Google colab since it's GPU supported.I uploaded folder from my local machine to Colab in Zip format . But an error is occurred while unzipping file.</strong></p>

<pre><code>    from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file ""{name}"" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))
</code></pre>

<p><strong>When I tried following to unzip file</strong></p>

<pre><code>unzip devanagari-character-dataset.zip  
</code></pre>

<p><strong>I have following error.</strong></p>

<pre><code>      File ""&lt;ipython-input-8-92b289004693&gt;"", line 1
        unzip devanagari-character-dataset.zip
                       ^

SyntaxError: invalid syntax
</code></pre>

<p><strong>How to solve above issue.</strong></p>
",826,2,3,2,python;deep-learning,2019-12-19 16:41:33,2019-12-19 16:41:33,2022-07-04 22:05:20,i want to train a deep learning model on a devanagari dataset containing around  images  since the dataset is huge  i want to use google colab since it s gpu supported i uploaded folder from my local machine to colab in zip format   but an error is occurred while unzipping file  when i tried following to unzip file i have following error  how to solve above issue ,how to unzip image folder in colab
141,141,14680256,72853315,Font Awesome icon not changing color based on React state,"<p>Font awesome icon is not changing color based on react state, I have an app which shows random quotes and display random color in background, new quote button and twitter icon. On first reload twitter icon color is changing as intended, however, when new quote button is clicked it stays the same. Here is my code</p>
<pre><code>import React from 'react';
import './style.scss';
import randomColor from 'randomcolor';
import '@fortawesome/fontawesome-free/css/all.css';
import '@fortawesome/fontawesome-free/js/all.js';

const quotes = [
    'I do not fear computers. I fear lack of them.',
    'A computer once beat me at chess, but it was no match for me at kick boxing.',
    'Computer Science is no more about computers than astronomy is about telescopes.',
    'The computer was born to solve problems that did not exist before.',
    'Software is like entropy: It is difficult to grasp, weighs nothing, and obeys the Second Law of Thermodynamics; i.e., it always increases.',
    'Software is a gas; it expands to fill its container.',
    &quot;All parts should go together without forcing.  You must remember that the parts you are reassembling were disassembled by you.  Therefore, if you can't get them together again, there must be a reason.  By all means, do not use a hammer.&quot;,
    &quot;Standards are always out of date.  That's what makes them standards.&quot;,
    &quot;Physics is the universe's operating system.&quot;,
    &quot;It's hardware that makes a machine fast.  It's software that makes a fast machine slow.&quot;,
    'Imagination is more important than knowledge.  For knowledge is limited, whereas imagination embraces the entire world.',
    'The greatest enemy of knowledge is not ignorance, it is the illusion of knowledge.',
    'The more you know, the more you realize you know nothing.',
    'Tell me and I forget.  Teach me and I remember.  Involve me and I learn.',
    &quot;Real knowledge is to know the extent of one's ignorance.&quot;,
    'If people never did silly things, nothing intelligent would ever get done.',
    'Getting information off the Internet is like taking a drink from a fire hydrant.',
    'If you think your users are idiots, only idiots will use it.',
    &quot;From a programmer's point of view, the user is a peripheral that types when you issue a read request.&quot;,
    &quot;Where is the 'any' key?&quot;,
    'Computers are good at following instructions, but not at reading your mind.',
    &quot;There is only one problem with common sense; it's not very common.&quot;,
    'Your most unhappy customers are your greatest source of learning.',
    'Let us change our traditional attitude to the construction of programs: Instead of imagining that our main task is to instruct a computer what to do, let us concentrate rather on explaining to human beings what we want a computer to do.',
];
const authors = [
    '- Isaac Asimov',
    '- Emo Philips',
    '- Edsger W. Dijkstra',
    '- Bill Gates',
    '- Norman Augustine',
    '- Nathan Myhrvold',
    '- IBM Manual, 1925',
    '- Alan Bennett',
    '- Steven R Garman',
    '- Craig Bruce',
    '- Albert Einstein',
    '- Stephen Hawking',
    '- Socrates',
    '- Benjamin Franklin',
    '- Confucius',
    '- Ludwig Wittgenstein',
    '- Mitchell Kapor',
    '- Linus Torvalds',
    '- P. Williams',
    '- Homer Simpson, in response to the message, “Press any key”',
    '- Donald Knuth',
    '- Milt Bryce',
    '- Bill Gates',
    '- Donald E. Knuth',
];

const random = Math.floor(Math.random() * quotes.length);
class App extends React.Component {
    constructor(props) {
        super(props);
        this.state = {
            quote: quotes[random],
            author: authors[random],
            color: randomColor(),
        };
        this.handleClick = this.handleClick.bind(this);
    }

    handleClick() {
        const clickRandom = Math.floor(Math.random() * quotes.length);
        this.setState({
            quote: quotes[clickRandom],
            author: authors[clickRandom],
            color: randomColor(),
        });
    }

    render() {
        return (
            &lt;div
                id=&quot;bg&quot;
                style={{
                    backgroundColor: this.state.color,
                }}
            &gt;
                &lt;div id=&quot;quote-box&quot;&gt;
                    &lt;p id=&quot;text&quot;&gt;{this.state.quote}&lt;/p&gt;
                    &lt;p id=&quot;author&quot;&gt;{this.state.author}&lt;/p&gt;
                    &lt;a id=&quot;tweet-quote&quot; href=&quot;https://twitter.com/intent/tweet&quot;&gt;
                        &lt;i
                            className=&quot;fa-brands fa-twitter-square fa-2xl&quot;
                            style={{
                                color: this.state.color,
                            }}
                        &gt;&lt;/i&gt;
                    &lt;/a&gt;
                    &lt;div style={{
                        width: 20,
                        height: 20,
                        backgroundColor: this.state.color
                    }}&gt;&lt;/div&gt;
                    &lt;button
                        id=&quot;new-quote&quot;
                        onClick={this.handleClick}
                        style={{
                            backgroundColor: this.state.color,
                            border: 'solid 1px ' + this.state.color,
                        }}
                    &gt;
                        New Quote
                    &lt;/button&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        );
    }
}

export default App;
</code></pre>
<p>To diagnose the problem I have specifically made a div box of 20 x 20px, every element is changing color upon click on new quote button except font awesome twitter icon.</p>
",57,1,0,4,javascript;html;css;reactjs,2022-07-04 13:15:46,2022-07-04 13:15:46,2022-07-04 19:00:12,font awesome icon is not changing color based on react state  i have an app which shows random quotes and display random color in background  new quote button and twitter icon  on first reload twitter icon color is changing as intended  however  when new quote button is clicked it stays the same  here is my code to diagnose the problem i have specifically made a div box of  x px  every element is changing color upon click on new quote button except font awesome twitter icon ,font awesome icon not changing color based on react state
142,142,13788653,72856267,How to split chessboard into tensors so that they can be analyzed as a batch,"<p>I am currently trying to process a chessboard with a machine learning model by splitting the image into 64 squares, and then getting the model prediction from each square. However, I was wondering if there is any way I can somehow split the original image into groups so that they can be analyzed simultaneously as a batch so the code can run much faster.</p>
<p>Here is my current code:</p>
<pre><code>squares = image_processing('/Users/Me/Downloads/Screen Shot 2022-07-04 at 11.09.04 AM.png')
image_transforms = transforms.Compose([  
                    transforms.ToTensor()])

board = []
for square in squares:
    square = Image.fromarray(square)
    square = image_transforms(square).float()
    square = square.unsqueeze(0)

    output = model(square)
    _, predicted = torch.max(output.data, 1)
    board.append(classes[predicted.item()])
</code></pre>
",25,1,0,3,performance;machine-learning;pytorch,2022-07-04 17:22:46,2022-07-04 17:22:46,2022-07-04 17:57:26,i am currently trying to process a chessboard with a machine learning model by splitting the image into  squares  and then getting the model prediction from each square  however  i was wondering if there is any way i can somehow split the original image into groups so that they can be analyzed simultaneously as a batch so the code can run much faster  here is my current code ,how to split chessboard into tensors so that they can be analyzed as a batch
143,143,19338925,72854063,making pipeline for machine learning models,"<pre><code>from sklearn import svm
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier

model_params = {           /* creating dictionary of all classifiers with paramters */
     'svm': {
        'model': svm.SVC(gamma='auto'),
         'params' : {
             'svc__C': [1,10,100,1000],
             'svc__kernel': ['rbf','linear']
         }  
     },
    
        'logistic_regression' : {
         'model': LogisticRegression(solver='liblinear',multi_class='auto'),
         'params': {
             'logisticregression__C': [1,5,10]
         }
     },
    
    'random_forest1': {
         'model': RandomForestClassifier(),
         'params' : {
             'randomforestclassifier__n_estimators': [1,5,10]
         }
     },
    
       

      'decision_tree': {
         'model': DecisionTreeClassifier(),
         'params': {
             'decisionTreeClassifier__criterion': [&quot;gini&quot;,&quot;entropy&quot;,&quot;log_loss&quot;]
            
         }
    
       }
}
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline

scores = []
best_estimators = {}
import pandas as pd
for algo, mp in model_params.items():
    pipe = make_pipeline(StandardScaler(), mp['model']) /* creating pipeline to scale data and fetching classifiers from dictionary */
    
    clf =  GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)  /* using grid search cv on my classifiers */
   
    clf.fit(features,target)
    scores.append({
        'model': algo,
        'best_score': clf.best_score_,
        'best_params': clf.best_params_
    })
    best_estimators[algo] = clf.best_estimator_
    
df = pd.DataFrame(scores,columns=['model','best_score','best_params'])
</code></pre>
<p>Error:</p>
<pre><code>Invalid parameter '' for estimator Pipeline(steps=[('standardscaler', StandardScaler()),
                ('decision_tree', DecisionTreeClassifier() ]). Valid parameters are: ['memory', 'steps', 'verbose'].  
</code></pre>
<p>the code works  fine for svm logistic regression and random forest classifiers but throw parameter error for the decision tree classifier. cant figure out whether it is a syntax issue or something else</p>
",38,1,0,5,python;machine-learning;scikit-learn;classification;pipeline,2022-07-04 14:21:41,2022-07-04 14:21:41,2022-07-04 17:10:40,error  the code works  fine for svm logistic regression and random forest classifiers but throw parameter error for the decision tree classifier  cant figure out whether it is a syntax issue or something else,making pipeline for machine learning models
144,144,17260574,72853790,Azure machine learning compute bicep template naming error,"<p>I have a file called machine-learning.bicep file which contains both resources machine learning workspace and compute(I want to keep both resources together). Getting the following naming error for the compute resource 'incorrect segment lengths. A nested resource type must have identical number of segments as its resource name. A root resource type must have segment length one greater than its resource name'. I also removed cluster in compute name to match segment length but still getting error</p>
<pre><code>resource machineLearning 'Microsoft.MachineLearningServices/workspaces@2022-01-01-preview' = {
  name: 'mlw-${project}-${env}'
  location: loc
  tags: tags
  identity: {
    type: 'SystemAssigned'
  }
  properties: {
    // dependent resources
    applicationInsights: appInsights.id
    containerRegistry: containerRegistry.id
    keyVault: keyVaultId
    storageAccount: storage.id
  }
}

resource amlci 'Microsoft.MachineLearningServices/workspaces/computes@2020-09-01-preview' = {
  name: 'mlw-${project}-${env}-cluster'
  location: loc
  properties: {
    computeType: 'AmlCompute'
    properties: {
      vmSize: 'Standard_DS3_v2'
      subnet: json('null')
      osType: 'Linux'
      scaleSettings: {
        maxNodeCount: 5
        minNodeCount: 0
      }
    }
  }
}
</code></pre>
",28,1,0,4,azure;machine-learning;azure-resource-manager;azure-bicep,2022-07-04 13:59:49,2022-07-04 13:59:49,2022-07-04 15:00:45,i have a file called machine learning bicep file which contains both resources machine learning workspace and compute i want to keep both resources together   getting the following naming error for the compute resource  incorrect segment lengths  a nested resource type must have identical number of segments as its resource name  a root resource type must have segment length one greater than its resource name   i also removed cluster in compute name to match segment length but still getting error,azure machine learning compute bicep template naming error
145,145,1279459,54635355,What does log_prob do?,"<p>In some (e.g. machine learning) libraries, we can find <code>log_prob</code> function. What does it do and how is it different from taking just regular <code>log</code>?</p>

<p>For example, what is the purpose of this code:</p>

<pre><code>dist = Normal(mean, std)
sample = dist.sample()
logprob = dist.log_prob(sample)
</code></pre>

<p>And subsequently, why would we first take a log and then exponentiate the resulting value instead of just evaluating it directly:</p>

<pre><code>prob = torch.exp(dist.log_prob(sample))
</code></pre>
",17835,4,22,2,pytorch;probability-distribution,2019-02-11 22:21:07,2019-02-11 22:21:07,2022-07-04 14:07:51,in some  e g  machine learning  libraries  we can find log_prob function  what does it do and how is it different from taking just regular log  for example  what is the purpose of this code  and subsequently  why would we first take a log and then exponentiate the resulting value instead of just evaluating it directly ,what does log_prob do 
146,146,6891262,48082414,init docker swarm with docker machine: context deadline exceeded,"<p>I'm learing Docker machine while encount some problems.<br>
My computer is mac and use Docker for mac.  I create 2 vm,vm1&amp; vm2 by docker-machine,and try to init a swarm who has nodes-vm1,vm2 and my mac.My steps are below:<br>
1. create an image called ""sprinla/cms:latest"" and a docker-compose.yml</p>

<pre><code>version: ""3""
services:
  web:
    image: sprinla/cms:latest
    deploy:
      replicas: 1
    ports:
      - ""80:80""
    networks:
      - webnet
    command: /data/start.sh
networks:
  webnet:
</code></pre>

<p>2.create 2 vms.Here is vm info:  </p>

<pre><code>yuxrdeMBP:~ yuxr$ docker-machine ls  
NAME   ACTIVE   DRIVER       STATE     URL                         SWARM   DOCKER        ERRORS  
vm1    -        virtualbox   Running   tcp://192.168.99.100:2376           v17.12.0-ce  
vm2    -        virtualbox   Running   tcp://192.168.99.101:2376           v17.12.0-ce  
</code></pre>

<ol start=""3"">
<li>init swarm on my mac host:  </li>
</ol>

<blockquote>
<pre><code>yuxrdeMBP:~ yuxr$ docker swarm init
Swarm initialized: current node (uf6rg1v91exlwntlskyj8iim7) is now a manager.
To add a worker to this swarm, run the following command:
docker swarm join --token SWMTKN-1-3qb32l84n0s8vl74rj9d6psm7bzdany3piw55ohtrq0q7ly814-c5km5zg3kj9d6vn6vrtt6xxtg 192.168.65.2:2377
To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.
</code></pre>
</blockquote>

<p>4 join vm1 to swarm,then comes the problem</p>

<pre><code>yuxrdeMBP:~ yuxr$ docker-machine ssh vm1 ""docker swarm join --token SWMTKN-1-3qb32l84n0s8vl74rj9d6psm7bzdany3piw55ohtrq0q7ly814-c5km5zg3kj9d6vn6vrtt6xxtg 192.168.65.2:2377""
Error response from daemon: Timeout was reached before node joined. The attempt to join the swarm will continue in the background. Use the ""docker info"" command to see the current swarm status of your node.
exit status 1
</code></pre>

<p>5.cat the docker log :</p>

<pre><code>time=""2018-01-03T17:13:50.387854642Z"" level=debug msg=""Calling GET /_ping""
time=""2018-01-03T17:13:50.388228524Z"" level=debug msg=""Calling GET /_ping""
time=""2018-01-03T17:13:50.388521374Z"" level=debug msg=""Calling POST /v1.35/swarm/join""
time=""2018-01-03T17:13:50.388583426Z"" level=debug msg=""form data: {\""AdvertiseAddr\"":\""\"",\""Availability\"":\""\"",\""DataPathAddr\"":\""\"",\""JoinToken\"":\""*****\"",\""ListenAddr\"":\""0.0.0.0:2377\"",\""RemoteAddrs\"":[\""192.168.65.2:2377\""]}""
time=""2018-01-03T17:13:55.392578452Z"" level=error msg=""failed to retrieve remote root CA certificate"" error=""rpc error: code = DeadlineExceeded desc = context deadline exceeded"" module=node
time=""2018-01-03T17:14:02.394608777Z"" level=error msg=""failed to retrieve remote root CA certificate"" error=""rpc error: code = DeadlineExceeded desc = context deadline exceeded"" module=node
time=""2018-01-03T17:14:09.395720474Z"" level=error msg=""failed to retrieve remote root CA certificate"" error=""rpc error: code = DeadlineExceeded desc = context deadline exceeded"" module=node
time=""2018-01-03T17:14:10.393743738Z"" level=error msg=""Handler for POST /v1.35/swarm/join returned error: Timeout was reached before node joined. The attempt to join the swarm will continue in the background. Use the \""docker info\"" command to see the current swarm status of your node.""
time=""2018-01-03T17:14:16.398095265Z"" level=error msg=""failed to retrieve remote root CA certificate"" error=""rpc error: code = DeadlineExceeded desc = context deadline exceeded"" module=node
time=""2018-01-03T17:14:23.399587783Z"" level=error msg=""failed to retrieve remote root CA certificate"" error=""rpc error: code = DeadlineExceeded desc = context deadline exceeded"" module=node
time=""2018-01-03T17:14:25.399943337Z"" level=error msg=""cluster exited with error: rpc error: code = DeadlineExceeded desc = context deadline exceeded""
</code></pre>

<ol start=""6"">
<li><p>below is my mac ifconfig info:  </p>

<blockquote>
<pre><code>yuxrdeMBP:~ yuxr$ ifconfig
lo0: flags=8049&lt;UP,LOOPBACK,RUNNING,MULTICAST&gt; mtu 16384
  options=1203&lt;RXCSUM,TXCSUM,TXSTATUS,SW_TIMESTAMP&gt;
  inet 127.0.0.1 netmask 0xff000000
  inet6 ::1 prefixlen 128
  inet6 fe80::1%lo0 prefixlen 64 scopeid 0x1
  nd6 options=201&lt;PERFORMNUD,DAD&gt;
gif0: flags=8010&lt;POINTOPOINT,MULTICAST&gt; mtu 1280
stf0: flags=0&lt;&gt; mtu 1280
XHC20: flags=0&lt;&gt; mtu 0
en0: flags=8863&lt;UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST&gt; mtu 1500
  ether ac:bc:32:81:97:37
  inet6 fe80::4d8:6b2:718a:5d3b%en0 prefixlen 64 secured scopeid 0x5
  inet 192.168.199.169 netmask 0xffffff00 broadcast 192.168.199.255
  nd6 options=201&lt;PERFORMNUD,DAD&gt;
  media: autoselect
  status: active
p2p0: flags=8843&lt;UP,BROADCAST,RUNNING,SIMPLEX,MULTICAST&gt; mtu 2304
  ether 0e:bc:32:81:97:37
  media: autoselect
  status: inactive
awdl0: flags=8943&lt;UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST&gt; mtu 1484
  ether 36:9f:65:fd:34:c3
  inet6 fe80::349f:65ff:fefd:34c3%awdl0 prefixlen 64 scopeid 0x7
  nd6 options=201&lt;PERFORMNUD,DAD&gt;
  media: autoselect
  status: active
en1: flags=8963&lt;UP,BROADCAST,SMART,RUNNING,PROMISC,SIMPLEX,MULTICAST&gt; mtu 1500
  options=60&lt;TSO4,TSO6&gt;
  ether 6a:00:00:e3:4c:30
  media: autoselect &lt;full-duplex&gt;
  status: inactive
en2: flags=8963&lt;UP,BROADCAST,SMART,RUNNING,PROMISC,SIMPLEX,MULTICAST&gt; mtu 1500
  options=60&lt;TSO4,TSO6&gt;
  ether 6a:00:00:e3:4c:31
  media: autoselect &lt;full-duplex&gt;
  status: inactive
bridge0: flags=8822&lt;BROADCAST,SMART,SIMPLEX,MULTICAST&gt; mtu 1500
  options=63&lt;RXCSUM,TXCSUM,TSO4,TSO6&gt;
  ether 6a:00:00:e3:4c:30
  Configuration:
      id 0:0:0:0:0:0 priority 0 hellotime 0 fwddelay 0
      maxage 0 holdcnt 0 proto stp maxaddr 100 timeout 1200
      root id 0:0:0:0:0:0 priority 0 ifcost 0 port 0
      ipfilter disabled flags 0x2
  member: en1 flags=3&lt;LEARNING,DISCOVER&gt;
          ifmaxaddr 0 port 8 priority 0 path cost 0
  member: en2 flags=3&lt;LEARNING,DISCOVER&gt;
          ifmaxaddr 0 port 9 priority 0 path cost 0
  media: &lt;unknown type&gt;
  status: inactive
utun0: flags=8051&lt;UP,POINTOPOINT,RUNNING,MULTICAST&gt; mtu 2000
  options=6403&lt;RXCSUM,TXCSUM,CHANNEL_IO,PARTIAL_CSUM,ZEROINVERT_CSUM&gt;
  inet6 fe80::441e:c0e3:5429:2abb%utun0 prefixlen 64 scopeid 0xb
  nd6 options=201&lt;PERFORMNUD,DAD&gt;
utun1: flags=8051&lt;UP,POINTOPOINT,RUNNING,MULTICAST&gt; mtu 1380
  options=6403&lt;RXCSUM,TXCSUM,CHANNEL_IO,PARTIAL_CSUM,ZEROINVERT_CSUM&gt;
  inet6 fe80::7820:5bac:4735:7f82%utun1 prefixlen 64 scopeid 0xc
  inet6 fd44:5cb3:4ab4:5d08:7820:5bac:4735:7f82 prefixlen 64
  nd6 options=201&lt;PERFORMNUD,DAD&gt;
utun2: flags=8051&lt;UP,POINTOPOINT,RUNNING,MULTICAST&gt; mtu 1380
  options=6403&lt;RXCSUM,TXCSUM,CHANNEL_IO,PARTIAL_CSUM,ZEROINVERT_CSUM&gt;
  inet6 fe80::26f2:e964:8dfb:e884%utun2 prefixlen 64 scopeid 0xd
  nd6 options=201&lt;PERFORMNUD,DAD&gt;
gpd0: flags=8862&lt;BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST&gt; mtu 1400
  ether 02:50:41:00:01:01
vboxnet0: flags=8943&lt;UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST&gt; mtu 1500
  ether 0a:00:27:00:00:00
  inet 192.168.99.1 netmask 0xffffff00 broadcast 192.168.99.255
</code></pre>
</blockquote></li>
</ol>

<p>Why????<br>
mac host has ip, 192.168.99.1 ,vm1 has ip 192.168.99.100,vm2 has ip 192.168.99.101,they are in the same network,why can't vm1 nor vm2
join the mac host's swarm?</p>

<p>ANOTHER QUESTION:if i use vm1 as swarm manager,run ""docker swarm join"" commad on the mac host,when join as worker,it can join but can't use;when join as manager will has error:</p>

<pre><code>yuxrdeMBP:~ yuxr$ docker swarm join --token SWMTKN-1-49w1hd28hs1mtj3sgmd0o3q7n59zgppvd18vs0iwhcnjemzmwb-7mk35zdnaslt1p41gninvwlud 192.168.99.100:2377
Error response from daemon: manager stopped: can't initialize raft node: rpc error: code = Unknown desc = could not connect to prospective new cluster member using its advertised address: rpc error: code = Unavailable desc = grpc: the connection is unavailable
</code></pre>

<p>THANK YOU FOR HELP ME !!!</p>
",4860,3,1,3,docker;docker-swarm;docker-machine,2018-01-03 23:09:16,2018-01-03 23:09:16,2022-07-04 12:21:03, create  vms here is vm info     join vm to swarm then comes the problem  cat the docker log   below is my mac ifconfig info    another question if i use vm as swarm manager run docker swarm join commad on the mac host when join as worker it can join but can t use when join as manager will has error  thank you for help me    ,init docker swarm with docker machine  context deadline exceeded
147,147,19214553,72846197,Tensorflow virtual environment on Mac in vs code doesn&#39;t work help please,"<p>I followed this guide: <a href=""https://github.com/mrdbourke/m1-machine-learning-test"" rel=""nofollow noreferrer"">https://github.com/mrdbourke/m1-machine-learning-test</a> to create a virtual environment to run TensorFlow on my Mac but I could not get it to run in VS Code. Somehow the kernel is not right I don't know much about this stuff.</p>
<p><a href=""https://i.stack.imgur.com/hYN7m.jpg"" rel=""nofollow noreferrer""><strong>Vs code code doesn't work</strong></a></p>
<p><a href=""https://i.stack.imgur.com/hYN7m.jpg"" rel=""nofollow noreferrer"">2</a>: <a href=""https://i.stack.imgur.com/HVNoD.jpg"" rel=""nofollow noreferrer"">https://i.stack.imgur.com/HVNoD.jpg</a> Jupyter code works in browser</p>
<p>here's the terminal log:</p>
<pre><code>Error 14:27:30.924: Error in execution (get message for cell) c [Error]: Kernel base (Python 3.9.13) is not usable. Check the Jupyter output tab for more information.
    at b.createNewKernelSession (/Users/lukasgassner/.vscode/extensions/ms-toolsai.jupyter-2022.4.1021342353/out/extension.node.js:2:408801)
    at runNextTicks (node:internal/process/task_queues:61:5)
    at processTimers (node:internal/timers:497:9)
    at b.connect (/Users/lukasgassner/.vscode/extensions/ms-toolsai.jupyter-2022.4.1021342353/out/extension.node.js:2:407398)
    at d.startNew (/Users/lukasgassner/.vscode/extensions/ms-toolsai.jupyter-2022.4.1021342353/out/extension.node.js:2:415056)
    at a (/Users/lukasgassner/.vscode/extensions/ms-toolsai.jupyter-2022.4.1021342353/out/extension.node.js:2:365465)
    at S.createNotebookInstance (/Users/lukasgassner/.vscode/extensions/ms-toolsai.jupyter-2022.4.1021342353/out/extension.node.js:2:365663)
    at S.createNotebook (/Users/lukasgassner/.vscode/extensions/ms-toolsai.jupyter-2022.4.1021342353/out/extension.node.js:2:366262) {
  category: 'invalidkernel',
  kernelConnectionMetadata: {
    kind: 'startUsingPythonInterpreter',
    kernelSpec: {
      specFile: '/Users/lukasgassner/.vscode/extensions/ms-toolsai.jupyter-2022.4.1021342353/temp/jupyter/kernels/python3913jvsc74a57bd071973c23121dc5e6b00777b455410e06e065f8f26f2253b01b08bb5762db1de7/kernel.json',
      interpreterPath: '/Users/lukasgassner/miniforge3/bin/python',
      isRegisteredByVSC: 'registeredByNewVersionOfExt',
      name: 'python3913jvsc74a57bd071973c23121dc5e6b00777b455410e06e065f8f26f2253b01b08bb5762db1de7',
      argv: [Array],
      language: 'python',
      executable: 'python',
      display_name: &quot;Python 3.9.13 ('base')&quot;,
      metadata: [Object],
      env: {}
    },
    interpreter: {
      id: '/Users/lukasgassner/miniforge3/bin/python',
      sysPrefix: '/Users/lukasgassner/miniforge3',
      envType: 'Conda',
      envName: 'base',
      envPath: [m],
      architecture: 3,
      sysVersion: '3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) \n' +
        '[Clang 13.0.1 ]',
      version: [Object],
      companyDisplayName: 'Anaconda, Inc.',
      displayName: &quot;Python 3.9.13 ('base')&quot;,
      detailedDisplayName: &quot;Python 3.9.13 ('base': conda)&quot;,
      uri: [m]
    },
    id: '.jvsc74a57bd071973c23121dc5e6b00777b455410e06e065f8f26f2253b01b08bb5762db1de7./Users/lukasgassner/miniforge3/python./Users/lukasgassner/miniforge3/python.-m#ipykernel_launcher'
  }
}
</code></pre>
",26,0,0,4,macos;tensorflow;visual-studio-code;virtualenv,2022-07-03 17:13:00,2022-07-03 17:13:00,2022-07-04 12:07:28,i followed this guide   to create a virtual environment to run tensorflow on my mac but i could not get it to run in vs code  somehow the kernel is not right i don t know much about this stuff      jupyter code works in browser here s the terminal log ,tensorflow virtual environment on mac in vs code doesn   t work help please
148,148,17424122,72852489,Firebase - Machine Learning and interest tracking to create an algorithm for sorting posts,"<p>One of my applications includes user-generated posts and functions in a similar way to Instagram. When a user opens the app they see a feed of posts sorted by date. This works when there just one small demographic using the app, but as the user base becomes more diverse, not everyone is interested in the same posts. This is why apps like TikTok and Instagram have algorithms to decide which posts to show to a user. Where do I even start with this? I understand that there need to be tags on each post for what they are about (this is where I think I can use machine learning) and then each users information needs to include their interests (I’m not sure what can be used to change this as they like or dislike posts). Is there a simple pre-built way of doing this or any examples? It seems fo be a pretty big secret that mostly big tech companies understand and use.</p>
",12,0,0,2,firebase;firebase-machine-learning,2022-07-04 11:53:01,2022-07-04 11:53:01,2022-07-04 11:53:01,one of my applications includes user generated posts and functions in a similar way to instagram  when a user opens the app they see a feed of posts sorted by date  this works when there just one small demographic using the app  but as the user base becomes more diverse  not everyone is interested in the same posts  this is why apps like tiktok and instagram have algorithms to decide which posts to show to a user  where do i even start with this  i understand that there need to be tags on each post for what they are about  this is where i think i can use machine learning  and then each users information needs to include their interests  i m not sure what can be used to change this as they like or dislike posts   is there a simple pre built way of doing this or any examples  it seems fo be a pretty big secret that mostly big tech companies understand and use ,firebase   machine learning and interest tracking to create an algorithm for sorting posts
149,149,18744280,72852267,When to use what classifier,"<p>I am relatively new to machine learning.  I know there are different classifiers. There is no clear answer on when to use what.  But I am sure there are characteristics of different datasets that pre dispose them to one classifier Vs another.  For example, I was told naive Bayes is usually used for text classification.</p>
<p>Is there such a table or paper that can serve as a useful reference guide on what to use?</p>
<p>I have googled and asked different people but have not gotten a satisfactory answer other than &quot;it depends?&quot;</p>
",11,0,-1,1,classification,2022-07-04 11:21:43,2022-07-04 11:21:43,2022-07-04 11:21:43,i am relatively new to machine learning   i know there are different classifiers  there is no clear answer on when to use what   but i am sure there are characteristics of different datasets that pre dispose them to one classifier vs another   for example  i was told naive bayes is usually used for text classification  is there such a table or paper that can serve as a useful reference guide on what to use  i have googled and asked different people but have not gotten a satisfactory answer other than  it depends  ,when to use what classifier
150,150,1361737,72844445,How do I extract the classification tree from this parsnip model in R?,"<p>I am working through 'Machine Learning &amp; R Expert techniques for predictive modeling' by Brett Lantz. I am using the <code>tidymodels</code> suite as I try the example modeling exercises in R.</p>
<p>I am working through chapter 5 in which you build a decision tree with the C5.0 algorithm. I hav e created the model using the code shown below</p>
<pre><code> c5_v1 &lt;- C5_rules() %&gt;% 
 set_mode('classification') %&gt;% 
 set_engine('C5.0')
  

c5_res_1 &lt;- fit(object = c5_v1, formula = default ~., data = credit_train)
</code></pre>
<p>This has worked successfully:</p>
<pre><code>parsnip model object


Call:
C5.0.default(x = x, y = y, trials = trials, rules = TRUE, control
 = C50::C5.0Control(minCases = minCases, seed = sample.int(10^5, 1), earlyStopping
 = FALSE))

Rule-Based Model
Number of samples: 900 
Number of predictors: 20 

Number of Rules: 22 

Non-standard options: attempt to group attributes
</code></pre>
<p>Try as I might, Google as I do, read <code>parsnips</code> documentation, etc., I <em>cannot</em> find out how to view the decision tree. Can anyone tell me how to view the actual tree it has created?</p>
",46,1,2,5,r;decision-tree;tidymodels;r-parsnip;c5.0,2022-07-03 12:16:56,2022-07-03 12:16:56,2022-07-04 07:10:41,i am working through  machine learning  amp  r expert techniques for predictive modeling  by brett lantz  i am using the tidymodels suite as i try the example modeling exercises in r  i am working through chapter  in which you build a decision tree with the c  algorithm  i hav e created the model using the code shown below this has worked successfully  try as i might  google as i do  read parsnips documentation  etc   i cannot find out how to view the decision tree  can anyone tell me how to view the actual tree it has created ,how do i extract the classification tree from this parsnip model in r 
151,151,19474127,72848936,Generate costum data using machine learning,"<p>Hello I have a dataset containing a word and a distorted version of it, is there a way to train a model to predict from the distorted word the normal version of it? Example: if I have &quot;/--pPython&quot; can the program output python using the dataset <a href=""https://i.stack.imgur.com/v5N7u.png"" rel=""nofollow noreferrer"">dataset.csv</a></p>
",25,0,-3,5,python-3.x;csv;machine-learning;dataset;tensorflow-datasets,2022-07-03 23:53:45,2022-07-03 23:53:45,2022-07-03 23:56:55,hello i have a dataset containing a word and a distorted version of it  is there a way to train a model to predict from the distorted word the normal version of it  example  if i have     ppython  can the program output python using the dataset ,generate costum data using machine learning
152,152,14384656,72848458,How do I fix ValueError: Classification metrics can&#39;t handle a mix of multiclass and continuous-multioutput targets?,"<p>I am currently learning how sentiment analysis and machine learning works. I am following this <a href=""https://medium.com/mlearning-ai/twitter-sentiment-analysis-with-deep-learning-using-bert-and-hugging-face-830005bcdbbf"" rel=""nofollow noreferrer"">tutorial</a> and this is the <a href=""https://github.com/baotramduong/Twitter-Sentiment-Analysis-with-Deep-Learning-using-BERT/blob/main/Notebook.ipynb"" rel=""nofollow noreferrer"">Github</a> source code. When it comes to training the model, I am facing this error:</p>
<pre><code>ValueError: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets
</code></pre>
<p>Upon researching solutions on the internet, I found that it could be due to the presence of continuous values. I have tried to change this line but to no avail:<br />
<code>val_f1 = f1_score_func(predictions, true_vals)</code><br />
to<br />
<code>val_f1 = f1_score_func(predictions, np.round(true_vals))</code></p>
<p>Here is the relevant part of the codes:</p>
<pre><code>def evaluate(dataloader_val):

    #evaluation mode disables the dropout layer 
    model.eval()
    
    #tracking variables
    loss_val_total = 0
    predictions, true_vals = [], []
    
    for batch in tqdm(dataloader_val):
        
        #load into GPU
        batch = tuple(b.to(device) for b in batch)
        
        #define inputs
        inputs = {'input_ids':      batch[0],
                  'attention_mask': batch[1],
                  'labels':         batch[2]}

        #compute logits
        with torch.no_grad():        
            outputs = model(**inputs)
        
        #compute loss
        loss = outputs[0]
        logits = outputs[1]
        loss_val_total += loss.item()

        #compute accuracy
        logits = logits.detach().cpu().numpy()
        label_ids = inputs['labels'].cpu().numpy()
        predictions.append(logits)
        true_vals.append(label_ids)
    
    #compute average loss
    loss_val_avg = loss_val_total/len(dataloader_val) 
    
    predictions = np.concatenate(predictions, axis=0)
    true_vals = np.concatenate(true_vals, axis=0)
            
    return loss_val_avg, predictions, true_vals


for epoch in tqdm(range(1, epochs+1)):

    #set model in train mode
    model.train()

    #tracking variable
    loss_train_total = 0
    
    #set up progress bar
    progress_bar = tqdm(dataloader_train, 
                        desc='Epoch {:1d}'.format(epoch), 
                        leave=False, 
                        disable=False)
    
    for batch in progress_bar:
        #set gradient to 0
        model.zero_grad()

        #load into GPU
        batch = tuple(b.to(device) for b in batch)

        #define inputs
        inputs = {'input_ids': batch[0],
                  'attention_mask': batch[1],
                  'labels': batch[2]}
        
        outputs = model(**inputs)
        loss = outputs[0] #output.loss
        loss_train_total +=loss.item()

        #backward pass to get gradients
        loss.backward()
        
        #clip the norm of the gradients to 1.0 to prevent exploding gradients
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        
        #update optimizer
        optimizer.step()

        #update scheduler
        scheduler.step()
        
        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     
    
    tqdm.write('\nEpoch {epoch}')
    
    #print training result
    loss_train_avg = loss_train_total/len(dataloader_train)
    tqdm.write(f'Training loss: {loss_train_avg}')
    
    #evaluate
    val_loss, predictions, true_vals = evaluate(dataloader_val)
    
    #f1 score
    #val_f1 = f1_score_func(predictions, true_vals) #old
    val_f1 = f1_score_func(predictions, np.round(true_vals)) #new
    tqdm.write(f'Validation loss: {val_loss}')
    tqdm.write(f'F1 Score (weighted): {val_f1}')
</code></pre>
<p>I am new to this and I really wanna know the actual reasoning and working solution behind the error I am facing. Thank you for your help.</p>
",54,0,0,5,python;nlp;sentiment-analysis;bert-language-model;transformer,2022-07-03 22:40:14,2022-07-03 22:40:14,2022-07-03 23:54:34,i am currently learning how sentiment analysis and machine learning works  i am following this  and this is the  source code  when it comes to training the model  i am facing this error  here is the relevant part of the codes  i am new to this and i really wanna know the actual reasoning and working solution behind the error i am facing  thank you for your help ,how do i fix valueerror  classification metrics can   t handle a mix of multiclass and continuous multioutput targets 
153,153,19090141,72194943,How to find location of the Microsoft Machine Learning Server installation files in SQL 2019,"<p><a href=""https://i.stack.imgur.com/NRWUA.png"" rel=""nofollow noreferrer"">enter image description here</a></p>
<p>I am stuck here and can't find location of the Microsoft Machine Learning Server installation files. If any one know please answer on this issue.</p>
",95,1,0,2,sql-server;machine-learning,2022-05-11 08:36:51,2022-05-11 08:36:51,2022-07-03 22:56:21, i am stuck here and can t find location of the microsoft machine learning server installation files  if any one know please answer on this issue ,how to find location of the microsoft machine learning server installation files in sql 
154,154,10783052,67212939,How to pause and resume a python script,"<p>First of all I am not a python specialist.
I am currently working on a machine learning issue where I must run scripts that could take days to end. So to make it easier for me, I am looking for a method that could pause the execution, save the execution state in a file or something.</p>
<p>The goal is to be able to interrupt the script, save the execution state, do something else even maybe power down the computer. Then come back load the execution state and run the program without starting over from the beginning.
I don't know if it is something possible, but it would make things a lot easier for me.
Thank you for your help</p>
",1408,1,0,4,python;execution;resume;pause,2021-04-22 17:32:50,2021-04-22 17:32:50,2022-07-03 19:48:23,,how to pause and resume a python script
155,155,15633016,67088805,"C++ not printing to console during while loop, only after loop is finished","<p><strong>Background</strong><br />
I'm currently writing some code for a naughts and crosses machine learning program based on M.E.N.A.C.E, and I have finished the code for the actual machine learning and for playing against the computer, as well as another computer to play games against it to train it. The user can enter that they'd like to let the computer train itself, and then enter the number of games to play.</p>
<p><strong>Problem</strong><br />
I'm trying to make a % completion display that overwrites itself each time it updates. The issue I have is that for some reason the code won't print anything that should be printed during the while loop, instead waiting until the end to print all of it in one go. I am using '\r' (carriage return) to overwrite the last printed text. If I remove the carriage return, the while loop prints the text on each iteration like it should do. I don't have any idea what's causing this problem as I'm quite new to C++.</p>
<p>I am programming in Repl.it since I'm not able to install an IDE on the computer I'm using.</p>
<p>Here is the subroutine for calculating and displaying the % completion (using namespace std).</p>
<pre><code>void calcCompletion(int a, int b)
{
  int completion = (static_cast&lt;float&gt;(a)/b) * 100;
  cout &lt;&lt; '\r';
  cout &lt;&lt; completion &lt;&lt; &quot;%&quot;;
}
</code></pre>
<p>And here is the start of the while loop where the procedure is called (mode is always 2 when I am testing this).</p>
<pre><code>while(gamesPlayed &lt; gameEnd)
  {
  //permutations();
  if(mode != &quot;1&quot;)
  {
    calcCompletion(gamesPlayed, gameEnd);
  }
</code></pre>
<p>It's a very long while loop so I won't show the whole thing (hence why the curly brackets do not match up).</p>
<p>And here is the output:</p>
<pre><code> clang++-7 -pthread -std=c++17 -o main ai.cpp base3.cpp main.cpp otherai.cpp permutations.cpp winCheck.cpp
 ./main
Enter mode. 
1 - Play the AI 
2 - Train the AI
2
How many games would you like the AI to play?
5

Simulating...
80%
Games complete.
Games played: 5
Games won: 1
Games lost: 0
Games drawn: 4
Win Percentage: 20%
Loss Percentage: 0%
--------------
</code></pre>
<p>It just waits until it is done with the while loop and then prints the last number, instead of printing as it goes.</p>
<p>I have tested trying to overwrite something I've written with no time delay in another code, it works fine so clearly being overwritten too quickly isn't the problem.</p>
",285,1,0,5,c++;while-loop;iostream;cout;carriage-return,2021-04-14 14:40:34,2021-04-14 14:40:34,2022-07-03 19:33:24,i am programming in repl it since i m not able to install an ide on the computer i m using  here is the subroutine for calculating and displaying the   completion  using namespace std   and here is the start of the while loop where the procedure is called  mode is always  when i am testing this   it s a very long while loop so i won t show the whole thing  hence why the curly brackets do not match up   and here is the output  it just waits until it is done with the while loop and then prints the last number  instead of printing as it goes  i have tested trying to overwrite something i ve written with no time delay in another code  it works fine so clearly being overwritten too quickly isn t the problem ,c   not printing to console during while loop  only after loop is finished
156,156,15535535,72846936,Python package is missed for machine learning and neural networks on windows 10_64bit Enterprise LTSC,"<p>I’m running a neural network code downloaded from github (<a href=""https://github.com/okada39/pinn_wave"" rel=""nofollow noreferrer"">https://github.com/okada39/pinn_wave</a>) that solves the 1D wave equation via PINNs algorithm.
After running my executed neural network code.py by cmd I got:</p>
<p>Traceback (most recent call last):
File &quot;file path&quot;, line 1, in 
import lib.tf_silent
ModuleNotFoundError: No module
named 'lib.tf_silent'</p>
<p>The Python code is as follows:</p>
<pre><code>import lib.tf_silent
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from matplotlib.colors import Normalize
from matplotlib.gridspec import GridSpec
from lib.pinn import PINN
from lib.network import Network
from lib.optimizer import L_BFGS_B

def u0(tx, c=1, k=2, sd=0.5):
&quot;&quot;&quot;
Initial wave form.
Args:
    tx: variables (t, x) as tf.Tensor.
    c: wave velocity.
    k: wave number.
    sd: standard deviation.
Returns:
    u(t, x) as tf.Tensor.
&quot;&quot;&quot;

t = tx[..., 0, None]
x = tx[..., 1, None]
z = k*x - (c*k)*t
return tf.sin(z) * tf.exp(-(0.5*z/sd)**2)

def du0_dt(tx):
&quot;&quot;&quot;
First derivative of t for the initial wave form.
Args:
    tx: variables (t, x) as tf.Tensor.
Returns:
    du(t, x)/dt as tf.Tensor.
&quot;&quot;&quot;

with tf.GradientTape() as g:
    g.watch(tx)
    u = u0(tx)
du_dt = g.batch_jacobian(u, tx)[..., 0]
return du_dt

if __name__ == '__main__':
&quot;&quot;&quot;
Test the physics informed neural network (PINN) model for the wave equation.
&quot;&quot;&quot;

# number of training samples
num_train_samples = 10000
# number of test samples
num_test_samples = 1000

# build a core network model
network = Network.build()
network.summary()
# build a PINN model
pinn = PINN(network).build()

# create training input
tx_eqn = np.random.rand(num_train_samples, 2)
tx_eqn[..., 0] = 4*tx_eqn[..., 0]                # t =  0 ~ +4
tx_eqn[..., 1] = 2*tx_eqn[..., 1] - 1            # x = -1 ~ +1
tx_ini = np.random.rand(num_train_samples, 2)
tx_ini[..., 0] = 0                               # t = 0
tx_ini[..., 1] = 2*tx_ini[..., 1] - 1            # x = -1 ~ +1
tx_bnd = np.random.rand(num_train_samples, 2)
tx_bnd[..., 0] = 4*tx_bnd[..., 0]                # t =  0 ~ +4
tx_bnd[..., 1] = 2*np.round(tx_bnd[..., 1]) - 1  # x = -1 or +1
# create training output
u_zero = np.zeros((num_train_samples, 1))
u_ini = u0(tf.constant(tx_ini)).numpy()
du_dt_ini = du0_dt(tf.constant(tx_ini)).numpy()

# train the model using L-BFGS-B algorithm
x_train = [tx_eqn, tx_ini, tx_bnd]
y_train = [u_zero, u_ini, du_dt_ini, u_zero]
lbfgs = L_BFGS_B(model=pinn, x_train=x_train, y_train=y_train)
lbfgs.fit()

# predict u(t,x) distribution
t_flat = np.linspace(0, 4, num_test_samples)
x_flat = np.linspace(-1, 1, num_test_samples)
t, x = np.meshgrid(t_flat, x_flat)
tx = np.stack([t.flatten(), x.flatten()], axis=-1)
u = network.predict(tx, batch_size=num_test_samples)
u = u.reshape(t.shape)

# plot u(t,x) distribution as a color-map
fig = plt.figure(figsize=(7,4))
gs = GridSpec(2, 3)
plt.subplot(gs[0, :])
vmin, vmax = -0.5, +0.5
plt.pcolormesh(t, x, u, cmap='rainbow', norm=Normalize(vmin=vmin, vmax=vmax))
plt.xlabel('t')
plt.ylabel('x')
cbar = plt.colorbar(pad=0.05, aspect=10)
cbar.set_label('u(t,x)')
cbar.mappable.set_clim(vmin, vmax)
# plot u(t=const, x) cross-sections
t_cross_sections = [1, 2, 3]
for i, t_cs in enumerate(t_cross_sections):
    plt.subplot(gs[1, i])
    tx = np.stack([np.full(t_flat.shape, t_cs), x_flat], axis=-1)
    u = network.predict(tx, batch_size=num_test_samples)
    plt.plot(x_flat, u)
    plt.title('t={}'.format(t_cs))
    plt.xlabel('x')
    plt.ylabel('u(t,x)')
plt.tight_layout()
plt.savefig('result_img_neumann.png', transparent=True)
plt.show()
</code></pre>
<p>How to fix this? please help?</p>
",33,0,0,3,python;tensorflow;importerror,2022-07-03 19:05:27,2022-07-03 19:05:27,2022-07-03 19:05:27,the python code is as follows  how to fix this  please help ,python package is missed for machine learning and neural networks on windows _bit enterprise ltsc
157,157,19375021,72846088,sklearn is not visible in VSC,"<p>I installed sklearn by <strong>python3 -m pip install scikit-learn</strong></p>
<p>I can see its version, so it's ok:
<strong>python -m pip show scikit-learn</strong>
<em>Name: scikit-learn
Version: 1.1.1
Summary: A set of python modules for machine learning and data mining
Home-page: <a href=""http://scikit-learn.org"" rel=""nofollow noreferrer"">http://scikit-learn.org</a>
Author:
Author-email:
License: new BSD
Location: /Users/imac/opt/anaconda3/lib/python3.9/site-packages
Requires: threadpoolctl, scipy, numpy, joblib
Required-by: sklearn, scikit-learn-intelex</em></p>
<p>but VSC tell me the package it not there. Nothing of the kind with numpy or pandas or other libs.</p>
<p>IDLE tells the same btw((</p>
<p>tried to google but no success. Can anyone help please, I'm just learning Python.</p>
",17,0,0,2,python;scikit-learn,2022-07-03 16:57:03,2022-07-03 16:57:03,2022-07-03 16:58:02,i installed sklearn by python  m pip install scikit learn but vsc tell me the package it not there  nothing of the kind with numpy or pandas or other libs  idle tells the same btw   tried to google but no success  can anyone help please  i m just learning python ,sklearn is not visible in vsc
158,158,18155045,72844013,Visualization and Analysis of Clusters for huge data and features,"<p>I am newbie to Machine learning. I am trying to use Clustering Algorithms like K-means on my data (<code>.csv</code>) but it has just too many columns (features) and rows. The objective of using Clustering is to find out new information about the data with it's existing information as base. I am dealing with YAML (<code>.yaml</code>/<code>.yml</code>) files consisting hierarchical syntax and therefore, I am converting each file into a vector. Each vector (1D) generated is passed on to a <code>.csv</code> file.  Let me elaborate my problem here:</p>
<p>I have a <code>.csv</code> generated which contains around 7k+ columns and presumably more than 7k+ rows as well. I took around 3.3K rows (as an experiment) and tried clustering them which of course, took me a while but eventually got clustered. I did also try clustering after using some feature selection techniques such as Information gain etc., which have shown to-some-extent better results (through K-means). However, my problems starts when <strong>I am unable to visualize this huge data</strong>   and therefore, I am to take the manual approach of looking into samples of each cluster. Here are my questions:</p>
<ol>
<li><p>How do I visualize such a huge data? (after clustering)</p>
</li>
<li><p>How do I analyze each cluster?</p>
</li>
</ol>
<p>Thanks in Advance! If you require any extra details, do comment!</p>
<p>P.S. I did try other algorithms such as Agglomerative, BIRCH and GMMs. If you feel some other algorithm may work in my case, do drop by in the comments!</p>
",31,0,0,5,machine-learning;yaml;bigdata;cluster-analysis;visualization,2022-07-03 10:33:47,2022-07-03 10:33:47,2022-07-03 14:11:28,i am newbie to machine learning  i am trying to use clustering algorithms like k means on my data   csv  but it has just too many columns  features  and rows  the objective of using clustering is to find out new information about the data with it s existing information as base  i am dealing with yaml   yaml  yml  files consisting hierarchical syntax and therefore  i am converting each file into a vector  each vector  d  generated is passed on to a  csv file   let me elaborate my problem here  i have a  csv generated which contains around k  columns and presumably more than k  rows as well  i took around  k rows  as an experiment  and tried clustering them which of course  took me a while but eventually got clustered  i did also try clustering after using some feature selection techniques such as information gain etc   which have shown to some extent better results  through k means   however  my problems starts when i am unable to visualize this huge data   and therefore  i am to take the manual approach of looking into samples of each cluster  here are my questions  how do i visualize such a huge data   after clustering  how do i analyze each cluster  thanks in advance  if you require any extra details  do comment  p s  i did try other algorithms such as agglomerative  birch and gmms  if you feel some other algorithm may work in my case  do drop by in the comments ,visualization and analysis of clusters for huge data and features
159,159,11434567,72844729,is this ok to use AssemblyScript in React project?,"<p>I have a question about using AssemblyScript  in React project
I already read some stuff about using AssemblyScript to increase performance but the question is when my project is not that big sth like a game or machine learning etc when I have a less computational project, is that ok to use AssemblyScript to increase performance for better user experience? if yes could you please tell me where and when it's better to use it?</p>
",26,0,0,4,javascript;reactjs;performance;assemblyscript,2022-07-03 13:13:08,2022-07-03 13:13:08,2022-07-03 13:23:43,,is this ok to use assemblyscript in react project 
160,160,19469286,72842705,Machine Learning: failed to upload .h5 file to Python Notebook,"<p>After installed Colab in my labtop with Windows system I connected it with Google drive(<a href=""https://drive.google.com/drive/my-drive"" rel=""nofollow noreferrer"">https://drive.google.com/drive/my-drive</a>). Then I opened a Python Notebook from Colab. There I read in file from Notebook with path: /content/mydrive/SVHN_single_grey1.h5</p>
<p>But, I got OSError message:
OSError: Unable to open file (unable to open file: name = '/content/my=drive/SVHN_single_grey1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)</p>
<p>I explored the problem for some time, it seems that the path is correct.</p>
<p>Anyone can suggestion possible solution for it?</p>
<p>Thanks</p>
",28,0,0,1,python,2022-07-03 03:31:45,2022-07-03 03:31:45,2022-07-03 06:11:53,after installed colab in my labtop with windows system i connected it with google drive    then i opened a python notebook from colab  there i read in file from notebook with path   content mydrive svhn_single_grey h i explored the problem for some time  it seems that the path is correct  anyone can suggestion possible solution for it  thanks,machine learning  failed to upload  h file to python notebook
161,161,5212614,72843042,How can we deploy a Machine Learning Model using Flask?,"<p>I am trying, for the first time ever, to deploy a ML model, using Flask. I'm following the instructions from the link below.</p>
<p><a href=""https://towardsdatascience.com/deploy-a-machine-learning-model-using-flask-da580f84e60c"" rel=""nofollow noreferrer"">https://towardsdatascience.com/deploy-a-machine-learning-model-using-flask-da580f84e60c</a></p>
<p>I created three separate and distinct .py files named 'model.py', 'server.py', and 'request.py'. I open my Anaconda Prompt end entered this: 'C:\Users\ryans&gt;C:\Users\ryans\model.py'</p>
<p>Now, I get this.</p>
<p><a href=""https://i.stack.imgur.com/iuRf4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/iuRf4.png"" alt=""enter image description here"" /></a></p>
<p>I definitely have Numpy installed! Something must be wrong with my setup, or maybe the way I am starting the process is wrong, but I'm not sure what the issue is. Has anyone encountered this problem before.</p>
",26,1,0,4,python;numpy;anaconda;conda,2022-07-03 04:55:06,2022-07-03 04:55:06,2022-07-03 05:30:18,i am trying  for the first time ever  to deploy a ml model  using flask  i m following the instructions from the link below   i created three separate and distinct  py files named  model py    server py   and  request py   i open my anaconda prompt end entered this   c  users ryans gt c  users ryans model py  now  i get this   i definitely have numpy installed  something must be wrong with my setup  or maybe the way i am starting the process is wrong  but i m not sure what the issue is  has anyone encountered this problem before ,how can we deploy a machine learning model using flask 
162,162,19240921,72838009,What does the &#39;CI&#39; terminology mean for ML based modelling?,"<p>I was going through some papers about Machine learning applied to cancer datasets.</p>
<p>I found a specific term with which I was not familiar.</p>
<blockquote>
<p>the AI system achieved an AUROC of 0.976 (95% <strong>CI: 0.972</strong>, 0.980) in identifying ... malignant lesions.</p>
</blockquote>
<p>I dug a bit about this 'CI'... came across another article about <em>Continuous Integration to Machine Learning Projects</em></p>
<p>Link to that: <a href=""https://towardsdatascience.com/how-i-apply-continuous-integration-to-machine-learning-projects-8273274a565a"" rel=""nofollow noreferrer"">https://towardsdatascience.com/how-i-apply-continuous-integration-to-machine-learning-projects-8273274a565a</a></p>
<p>Are these the same? If yes can someone please elaborate a bit on this topic? I am confused..</p>
",21,0,-1,1,machine-learning,2022-07-02 15:04:20,2022-07-02 15:04:20,2022-07-03 03:13:51,i was going through some papers about machine learning applied to cancer datasets  i found a specific term with which i was not familiar  the ai system achieved an auroc of      ci        in identifying     malignant lesions  i dug a bit about this  ci     came across another article about continuous integration to machine learning projects link to that   are these the same  if yes can someone please elaborate a bit on this topic  i am confused  ,what does the    ci    terminology mean for ml based modelling 
163,163,19462451,72832840,Trying to process json file returned from an API call in NodeJS - error: undefined - why?,"<p>I am receiving a JSON file from an APIcall (see below). Now, I would like to access the different keys of the JSON file to present the various values separately. However, I get an 'undefined' message in the console. Any ideas?</p>
<p>This is the code to call the API and process JSON file:</p>
<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>   const input = req.body.var_1;
    console.log('Request Query:' + JSON.stringify({ ""user_input"": input}));
    const articles = [];
    const sent = 'test';
    const api_url = '...';
    const options = {
        method: 'POST',
        body: JSON.stringify({""user_input"": input}),
        headers: {'Content-Type': 'application/json'}
    }

    const response = await fetch(api_url, options);
    const results = await Promise.all([response.json()]);
    console.log(results);
    data = JSON.parse(JSON.stringify(results))
    console.log(data);
    console.log(data.Topic);</code></pre>
</div>
</div>
</p>
<p>This is the console output I get:</p>
<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>Request Query:{""user_input"":""xgboost""}
[
  {
    Topic: {
      '0': 'random forest , Machine Learning and Wine Quality: Finding a good wine using multiple classifications',
      '1': 'decision tree learning , Gradient Boost for Classification',
      '2': 'feature selection , Understanding Multilabel Text Classification and the related process',
      '3': 'decision tree learning , Gradient Boost for Regression',
      '4': '&lt;strong class=""markup--strong markup--h3-strong""&gt;Understanding AdaBoost&lt;/strong&gt; , Anyone starting to learn Boosting technique should start first with AdaBoost or…'
    },
    'URL/PDF': {
      '0': 'https://dev.to//leading-edje/machine-learning-and-wine-quality-finding-a-good-wine-using-multiple-classifications-4kho',
      '1': 'https://dev.to//xsabzal/gradient-boost-for-classification-2f15',
      '2': 'https://dev.to//botreetechnologies/understanding-multilabel-text-classification-and-the-related-process-n66',
      '3': 'https://dev.to//xsabzal/gradient-boost-for-regression-1e42',
      '4': 'https://towardsdatascience.com/understanding-adaboost-2f94f22d5bfe'
    },
    Doc_Type: {
      '0': 'article',
      '1': 'article',
      '2': 'article',
      '3': 'article',
      '4': 'article'
    }
  }
]
[
  {
    Topic: {
      '0': 'random forest , Machine Learning and Wine Quality: Finding a good wine using multiple classifications',
      '1': 'decision tree learning , Gradient Boost for Classification',
      '2': 'feature selection , Understanding Multilabel Text Classification and the related process',
      '3': 'decision tree learning , Gradient Boost for Regression',
      '4': '&lt;strong class=""markup--strong markup--h3-strong""&gt;Understanding AdaBoost&lt;/strong&gt; , Anyone starting to learn Boosting technique should start first with AdaBoost or…'
    },
    'URL/PDF': {
      '0': 'https://dev.to//leading-edje/machine-learning-and-wine-quality-finding-a-good-wine-using-multiple-classifications-4kho',
      '1': 'https://dev.to//xsabzal/gradient-boost-for-classification-2f15',
      '2': 'https://dev.to//botreetechnologies/understanding-multilabel-text-classification-and-the-related-process-n66',
      '3': 'https://dev.to//xsabzal/gradient-boost-for-regression-1e42',
      '4': 'https://towardsdatascience.com/understanding-adaboost-2f94f22d5bfe'
    },
    Doc_Type: {
      '0': 'article',
      '1': 'article',
      '2': 'article',
      '3': 'article',
      '4': 'article'
    }
  }
]
undefined</code></pre>
</div>
</div>
</p>
<p>Happy for any help, thx</p>
",30,2,1,3,javascript;node.js;api,2022-07-01 23:03:01,2022-07-01 23:03:01,2022-07-03 00:38:14,i am receiving a json file from an apicall  see below   now  i would like to access the different keys of the json file to present the various values separately  however  i get an  undefined  message in the console  any ideas  this is the code to call the api and process json file  this is the console output i get  happy for any help  thx,trying to process json file returned from an api call in nodejs   error  undefined   why 
164,164,3837660,56836530,Auto-activate conda env when changing directory,"<p>I have few conda environments that I use in different projects, say:</p>

<ul>
<li>ml37 (for machine learning)</li>
<li>etl37 (for data pipelines)</li>
</ul>

<p>I have local projects organized in their own directories:</p>

<ul>
<li>apps/some_app</li>
<li>apps/other_app</li>
<li>...</li>
</ul>

<p>Each time I <code>cd</code> to a specific project, I already know which env I would like to use. So I end up doing <code>conda activate [some env]</code> each time I change directories. I feel like there must be a better way. </p>

<p>What would be a clean way to automatize this?</p>

<p>Or is my use of conda environments wrong?</p>
",1044,1,2,1,conda,2019-07-01 18:55:12,2019-07-01 18:55:12,2022-07-02 17:45:53,i have few conda environments that i use in different projects  say  i have local projects organized in their own directories  each time i cd to a specific project  i already know which env i would like to use  so i end up doing conda activate  some env  each time i change directories  i feel like there must be a better way   what would be a clean way to automatize this  or is my use of conda environments wrong ,auto activate conda env when changing directory
165,165,851249,72837248,what is the difference between database search technique and machine learning search technique?,"<p>We have <code>database</code> table which contains columns like <code>complaint name,complaint category and complaint sub category</code>.If i search for complaint name then i will get required details specific to passed complaint name in database. In <code>machine learning</code> technique, if we make the dataset similar to database table and create a model. If you pass same complaint name to model, it will give the same result. So then why we have to go for machine learning instead of database technique?</p>
",23,0,-1,4,machine-learning;artificial-intelligence;svm;data-mining,2022-07-02 12:53:30,2022-07-02 12:53:30,2022-07-02 13:55:11,we have database table which contains columns like complaint name complaint category and complaint sub category if i search for complaint name then i will get required details specific to passed complaint name in database  in machine learning technique  if we make the dataset similar to database table and create a model  if you pass same complaint name to model  it will give the same result  so then why we have to go for machine learning instead of database technique ,what is the difference between database search technique and machine learning search technique 
166,166,17385780,72834060,Classification in high-dimensional data by extreme learning machine in R,"<p>When I simulate 50 high-dimensional data set from multivariate normal distribution and classify by ELM, I find the AUC scores I get very different from each other in each loop. In some loops it goes below 50%. Where am I doing wrong? I want the deviation in the scores I get to be low for each loop. How can I achieve stable and high scores for each loop? How should I make changes in data generation? I look forward to your valuable contributions.</p>
<pre><code>install.packages(&quot;MASS&quot;)
install.packages(&quot;stats&quot;)
install.packages(&quot;pROC&quot;)
install.packages(&quot;elmNNRcpp&quot;)

library(MASS)
library(stats)
library(pROC)
library(elmNNRcpp)

######################################################
# DATA SIMULATE FUNCTION
######################################################
#  rm(list = ls())
generateData&lt;- function(n,p) {
pr &lt;- seq(0.80, 0.40, length.out = p)
pr[1] &lt;- 1
covmat &lt;- toeplitz(pr)
mu= rep(0,p)
X_ &lt;- data.frame(mvrnorm(n, mu = mu, Sigma = covmat))
X &lt;- unname(as.matrix(sample(X_)))
vCoef = rnorm(ncol(X))
vProb =exp(X%*%vCoef)/(1+exp(X%*%vCoef))
Y &lt;- rbinom(nrow(X), 1, vProb)
mydata= data.frame(cbind(X,Y))
return(mydata)
}

######################################################
# SIMULATED DATA
######################################################
n &lt;- 100
p &lt;- 120
nsim &lt;- 50

set.seed(123)
mydata &lt;- list()
for (k in 1 : nsim ) {
data &lt;- generateData(n , p)
# table(data[ncol(data)])
X &lt;- data[-ncol(data)]
Y &lt;- data[ncol(data)]
mydata[[k]] &lt;- data
}

######################################################
# ELM CLASSIFICATION
######################################################
######################################################
# ELM CLASSIFICATION FUNCTION
######################################################
fELMCLASS &lt;- function(x, col_names){ 
trainIndex &lt;- sample(1:nrow(x), size=0.7*nrow(x))
trainSet &lt;- x[trainIndex,]
testSet &lt;- x[-trainIndex,]

xtrain &lt;- as.matrix(trainSet[, 1:(length(trainSet)-1)])
ytrain &lt;- as.matrix(trainSet[, length(trainSet)])
xtest &lt;- as.matrix(testSet[, 1:(length(testSet)-1)])
ytest &lt;- as.matrix(testSet[, length(testSet)])

model=elm_train(xtrain, ytrain, nhid=25 , actfun='relu')
pred.class=elm_predict(model,xtest,normalize=TRUE)
roc.model=roc(as.factor(ytest) ~ as.numeric(pred.class), direction=c(&quot;auto&quot;))

performance_metrics &lt;-t(data.frame(&quot;AUC&quot; = roc.model$auc))
return(performance_metrics)
}
######################################################
######################################################
# SAVE RESULTS
######################################################
datalist = data.frame()
for (j in 1:nsim) {
data_ELM &lt;- as.data.frame(mydata[[j]])
datalist &lt;- rbind(datalist,fELMCLASS(data_ELM, &quot;data&quot;))
}

datalist
</code></pre>
",20,0,0,5,r;performance;classification;simulation;auc,2022-07-02 01:21:35,2022-07-02 01:21:35,2022-07-02 01:21:35,when i simulate  high dimensional data set from multivariate normal distribution and classify by elm  i find the auc scores i get very different from each other in each loop  in some loops it goes below    where am i doing wrong  i want the deviation in the scores i get to be low for each loop  how can i achieve stable and high scores for each loop  how should i make changes in data generation  i look forward to your valuable contributions ,classification in high dimensional data by extreme learning machine in r
167,167,17419684,72832970,MLFlow Experiment in Databricks Regressors,"<p>I'm new to Databricks and following a tutorial on mlflow in Databricks:</p>
<p><a href=""https://www.youtube.com/watch?v=_PxEdtAQXME&amp;t=1471s"" rel=""nofollow noreferrer"">https://www.youtube.com/watch?v=_PxEdtAQXME&amp;t=1471s</a></p>
<p>for a simple dataset on bike rentals:</p>
<p><a href=""https://www.kaggle.com/datasets/archit9406/bike-sharing"" rel=""nofollow noreferrer"">https://www.kaggle.com/datasets/archit9406/bike-sharing</a></p>
<p>Objective is to predict bike rentals or in this case &quot;cnt&quot;</p>
<p>I've created an ml cluster in Databricks and followed the code to as far as cmd 6 where it seems to be referencing other &quot;treeDepth&quot; data.</p>
<p>When I run this I get an AttributeError: 'GBTRegressor' object has no attribute ' setMaxDept'
I've tried to re-enter the variables in my dataframe to be more in line with the code but I cant seem to get it to work.</p>
<p>My overall objective is to get the script running and predicting &quot;cnt&quot;</p>
<p>Can anyone help with this?</p>
<pre><code>    Cmd1
    #install
    %pip install mlflow
</code></pre>
<pre><code>    Cmd 2
    #model name
    modelName = &quot;BikesModelMVP2&quot;
</code></pre>
<pre><code>    Cmd 3
    #importing a variety of different packages
    import mlflow
    from pyspark.ml.evaluation import RegressionEvaluator
    from pyspark.ml import PipelineModel
    from pyspark.ml import Pipeline
    from pyspark.ml.regression import DecisionTreeRegressor, RandomForestRegressor, GBTRegressor
    from pyspark.ml.feature import VectorAssembler, VectorIndexer, MinMaxScaler
    import mlflow.spark
    #import mlflow.xgboost
    import pyspark.sql.functions as F
    from mlflow.tracking.client import MlflowClient
    from mlflow.entities.model_registry.model_version_status import ModelVersionStatus
</code></pre>
<pre><code>    Cmd 4
    print(mlflow.__version__)
</code></pre>
<pre><code>    Cmd 5
    #reading in some data from dataset that's just abailable inside Databricks
    dataLocation = &quot;/databricks-datasets/bikeSharing/data-001/hour.csv&quot;
    
    df = (spark
         .read
         .option(&quot;header&quot;,&quot;true&quot;)
         .option(&quot;inferSchema&quot;,&quot;true&quot;)
         .csv(dataLocation)
         )
    
    df = df.drop(&quot;instant&quot;,&quot;dteday&quot;,&quot;casual&quot;,&quot;holiday&quot;,&quot;weekday&quot;,&quot;registered&quot;)
    
    df = df.withColumn(&quot;AMPM&quot;, F.when(F.col(&quot;hr&quot;)&lt;12,1).otherwise(0))
</code></pre>
<pre><code>    Cmd 6
    #Function that's going to create a machine learning model for me
    def runModel(_depth,_iter,_ntrees,_modelname):
    #def runModel(season,yr,mnth,hr,workingday,weathersit,temp,atemp,hum,windspeed):
        #with mlflow.start_run(experiment_id=&quot;2526553914207328&quot;):
        with mlflow.start_run():
            seed = 42
            trainDF, testDF = df.randomSplit([0.7,0.3], seed=42)
            
            #clf = RandomForestRegressor()
            clf = GBTRegressor()
            
            clf.setLabelCol(&quot;cnt&quot;)
            
            treeDepth = _depth
            numTrees = _ntrees
            iterations = _iter
            clf.setMaxDept(treeDepth)
            clf.setMaxIter(iterations)
            
            #clf.setNumTrees(numTrees)
            mlflow.log_param(&quot;treeDepth&quot;, treeDepth)
            mlflow.log_param(&quot;numTrees&quot;, numTrees)
            mlflow.log_param(&quot;numIterations&quot;, iterations)
            
            featureCols = df.drop(&quot;cnt&quot;).columns # Removes &quot;cnt&quot;
            vectorAssembler = VectorAssembler(inputCols=featureCols, outputCol=&quot;rawFeatures&quot;)
            vectorIndexer = VectorIndexer(inputCol=&quot;rawFeatures&quot;, outputCol=&quot;features&quot;, maxCategories=4)
            
            pipeline = Pipeline().setStages([vectorAssembler, vectorIndexer, clf])
            pipelineModel = pipeline.fit(trainDF)
            
            predictionsDF = pipelineModel.transform(testDF)
            
            evaluator = RegressionEvaluator().setMetricName(&quot;rmse&quot;).setPredictionCol(&quot;prediction&quot;).setLabelCol(&quot;cnt&quot;)
            evaluatorR2 = RegressionEvaluator().setMetricName(&quot;r2&quot;).setPredictionCol(&quot;prediction&quot;).setLabelCol(&quot;cnt&quot;)
            
            mlflow.log_metric(&quot;rmse&quot;, evaluator.evaluate(predictionsDF))
            mlflow.log_metric(&quot;r2&quot;, evaluatorR2.evaluate(predictionsDF))
            
            mlflow.log_artifact(&quot;/dbfs&quot;+ dataLocation)
            
            mlflow.spark.log_model(spark_model=pipelineModel, artifact_path=&quot;model&quot; , registered_model_name=_modelname)
            
            run_id = mlflow.active_run().info.run_id
            
            return run_id
    
</code></pre>
",20,0,0,3,regression;databricks;mlflow,2022-07-01 23:17:29,2022-07-01 23:17:29,2022-07-01 23:17:29,i m new to databricks and following a tutorial on mlflow in databricks   for a simple dataset on bike rentals   objective is to predict bike rentals or in this case  cnt  i ve created an ml cluster in databricks and followed the code to as far as cmd  where it seems to be referencing other  treedepth  data  my overall objective is to get the script running and predicting  cnt  can anyone help with this ,mlflow experiment in databricks regressors
168,168,19461687,72832049,Is it possible to use geodata (latitude &amp; longitude) as a predictor variable?,"<p>I'm a newbie in programming and using machine learning. This is my first post here as I've just recently stumbled upon the first unresolved -of probably many- question.</p>
<p>So I have an extensive database with data on the real-state market of my country and I want to predict the price of the houses -a pretty standard theme ikr- using the latitude and longitude as one variable.</p>
<p>So far I have found Waddell &amp; Besharati-Zadeh's study: <a href=""https://arxiv.org/pdf/2011.14924.pdf"" rel=""nofollow noreferrer"">https://arxiv.org/pdf/2011.14924.pdf</a> in which they reconstruct the geodata by combining it with other libraries and obtaining string variables as to if certain activities are within a walking distance of 500 meters. So this is a cool alternative but I'm worried there's no accurate data of the walking distance and establishments to do certain activities in my country, not even on google maps. Is there any way in which the combination of the latitude and longitude alone can be used as a predictor variable?</p>
",16,0,0,4,scope;geospatial;latitude-longitude;geo,2022-07-01 21:43:14,2022-07-01 21:43:14,2022-07-01 21:43:14,i m a newbie in programming and using machine learning  this is my first post here as i ve just recently stumbled upon the first unresolved  of probably many  question  so i have an extensive database with data on the real state market of my country and i want to predict the price of the houses  a pretty standard theme ikr  using the latitude and longitude as one variable  so far i have found waddell  amp  besharati zadeh s study   in which they reconstruct the geodata by combining it with other libraries and obtaining string variables as to if certain activities are within a walking distance of  meters  so this is a cool alternative but i m worried there s no accurate data of the walking distance and establishments to do certain activities in my country  not even on google maps  is there any way in which the combination of the latitude and longitude alone can be used as a predictor variable ,is it possible to use geodata  latitude  amp  longitude  as a predictor variable 
169,169,18739801,72831813,Uncertainty in target feature in machine learning,"<p>Okay, let's suppose i have a data set with some features, let's say X, and a target one Y with an error('cause this is an experimental measure, and it have an uncertainty), how should I handle this when training some Machine Learning regression algorithm? Both X and Y are continuous.</p>
<p>Does the RMSE say something about the error in the predicted value from the model i trained without the error information? Or should i use another metric to calculate the error? I don't remember the statistics behind these things, so, you guys can recommend me anything to read.</p>
<p>The first thing i was doing was to ignore the error of Y and try to fit the &quot;crude&quot; X and Y, get the model and given some metric(Like RMSE that i was thinking that could work), acquire the error of my predictions, but i don't think it's right.</p>
<p>So, how should i treat my data set with error to create an more accurate model? And how can i take the error information of my predictions?</p>
",32,0,-2,5,python;machine-learning;statistics;data-science;uncertainty,2022-07-01 21:23:42,2022-07-01 21:23:42,2022-07-01 21:25:11,okay  let s suppose i have a data set with some features  let s say x  and a target one y with an error  cause this is an experimental measure  and it have an uncertainty   how should i handle this when training some machine learning regression algorithm  both x and y are continuous  does the rmse say something about the error in the predicted value from the model i trained without the error information  or should i use another metric to calculate the error  i don t remember the statistics behind these things  so  you guys can recommend me anything to read  the first thing i was doing was to ignore the error of y and try to fit the  crude  x and y  get the model and given some metric like rmse that i was thinking that could work   acquire the error of my predictions  but i don t think it s right  so  how should i treat my data set with error to create an more accurate model  and how can i take the error information of my predictions ,uncertainty in target feature in machine learning
170,170,15195156,72830619,Machine Learning for RNA Sequence Recognition,"<p>I am looking for a machine learning training model for Natural Language Processing to go through scientific papers and look for Protein Sequences, amino acids and genes. I already have a script that is able to send a 'get' request for the papers and then pre-process the text removing stop words, stemming, and lemmatization. The next step for me would be introducing the NLP and machine learning. If anyone has any good sources or ideas on where to start it would be appreciated.</p>
",21,0,-1,2,machine-learning;nlp,2022-07-01 19:45:34,2022-07-01 19:45:34,2022-07-01 19:45:34,i am looking for a machine learning training model for natural language processing to go through scientific papers and look for protein sequences  amino acids and genes  i already have a script that is able to send a  get  request for the papers and then pre process the text removing stop words  stemming  and lemmatization  the next step for me would be introducing the nlp and machine learning  if anyone has any good sources or ideas on where to start it would be appreciated ,machine learning for rna sequence recognition
171,171,19442237,72828671,is python PIP important for machine learning or python programming,"<p>I need to know that does python3 has already installed PIP or it needs to be installed and is it important for machine learning ?</p>
",18,1,-1,1,python-3.x,2022-07-01 17:06:54,2022-07-01 17:06:54,2022-07-01 17:19:12,i need to know that does python has already installed pip or it needs to be installed and is it important for machine learning  ,is python pip important for machine learning or python programming
172,172,19338205,72826443,Assessing molecules geometry similarity with machine learning,"<p>I participate in a project where I am required to compare a set of molecules to a reference molecule, to assess which molecule is the most similar, from geometrical perspective only (neglecting chemical features).</p>
<p>The nature of the problem is unsupervised, because there is no label for each molecule.</p>
<p>My data consist of 1800~ molecules and a reference molecule, each has a table of XYZ coordinates.</p>
<p>I began with feature extraction - computing distances and angels between each point, and calculating the mean, median, variance and skewness as features for each molecule.</p>
<p>Another thought that came to my mind was to use 2d PCA, and use the variance of each PC as feature (Assuming similar mol will result in similar PCA).</p>
<p>I'm trying to think which algo could fit. The first that came to my mind were clustering algos, but I wonder if there are others that could fit?</p>
<p>Thanks you!</p>
",27,0,-2,5,machine-learning;geometry;unsupervised-learning;chemistry;molecule,2022-07-01 13:56:52,2022-07-01 13:56:52,2022-07-01 13:56:52,i participate in a project where i am required to compare a set of molecules to a reference molecule  to assess which molecule is the most similar  from geometrical perspective only  neglecting chemical features   the nature of the problem is unsupervised  because there is no label for each molecule  my data consist of   molecules and a reference molecule  each has a table of xyz coordinates  i began with feature extraction   computing distances and angels between each point  and calculating the mean  median  variance and skewness as features for each molecule  another thought that came to my mind was to use d pca  and use the variance of each pc as feature  assuming similar mol will result in similar pca   i m trying to think which algo could fit  the first that came to my mind were clustering algos  but i wonder if there are others that could fit  thanks you ,assessing molecules geometry similarity with machine learning
173,173,3025242,72826319,A way to perform voting and select a candidate based on nearest neighbours,"<p>I'm working on a project where I use <a href=""https://github.com/facebookresearch/faiss"" rel=""nofollow noreferrer"">FAISS</a> to retrieve <em>n</em> neighbouring vectors based on a query vector. The data in question is textual and is being embedded by using a machine learning model to create a vector before it goes into FAISS.</p>
<p>These neighbors each have a category assigned to them, and also have a similarity score to the query, like the following:</p>
<pre><code>Query: Berlin is the capital of Germany
=====
Neighbours output:

5 Neighbour ids: [57, 163, 177, 124, 91]

Text | Category | Similarity

Berlin is a great city to live in | Capital cities | 0.897843
Capital letters are often used to indicate nouns in German | Grammar | 0.803834
Over 3 million people live in Berlin | Capital cities | 0.79434
Germany is a country in Central Europe | Countries | 0.763232
Germany has many big cities | Countries | 0.7304545
</code></pre>
<p>Now, the thing I want to achieve is getting a single category for the query based on the categories of the neighbours, a kind of vector based recommender/suggestion system. What I tried already is just doing simple and weighted (based on similarity) majority voting.</p>
<p>Using simple majority voting, in the above example I would just get &quot;Capital cities&quot; or &quot;Country&quot; category as they both occur 2 out of 5 times. Using weighted voting I would arrive at &quot;Capital cities&quot; as they have higher similarity overall.</p>
<p>Both the approaches seem to work, however I am looking for a slightly more sophisticated approach to combine different signals. I read about the concept of <a href=""https://www.hindawi.com/journals/tswj/2013/704504/"" rel=""nofollow noreferrer"">data fusion</a> in machine learning, but I don't quite know yet how to best apply it here to arrive at one category based on the neighbours.</p>
<p>Any ideas are appreciated!</p>
",12,0,0,5,classification;similarity;recommendation-engine;information-retrieval;nearest-neighbor,2022-07-01 13:46:17,2022-07-01 13:46:17,2022-07-01 13:46:17,i m working on a project where i use  to retrieve n neighbouring vectors based on a query vector  the data in question is textual and is being embedded by using a machine learning model to create a vector before it goes into faiss  these neighbors each have a category assigned to them  and also have a similarity score to the query  like the following  now  the thing i want to achieve is getting a single category for the query based on the categories of the neighbours  a kind of vector based recommender suggestion system  what i tried already is just doing simple and weighted  based on similarity  majority voting  using simple majority voting  in the above example i would just get  capital cities  or  country  category as they both occur  out of  times  using weighted voting i would arrive at  capital cities  as they have higher similarity overall  both the approaches seem to work  however i am looking for a slightly more sophisticated approach to combine different signals  i read about the concept of  in machine learning  but i don t quite know yet how to best apply it here to arrive at one category based on the neighbours  any ideas are appreciated ,a way to perform voting and select a candidate based on nearest neighbours
174,174,13788653,72824476,How to efficiently run machine learning model over single images?,"<p>I am currently trying to find a way to determine a chess position based on an overhead picture of a chessboard. My model is a retrained resnet50. Here is my code:</p>
<pre><code>classes = ['b','k','n','p','q','r',None,'B','K','N','P','Q','R']

squares = image_processing('/Users/Me/Downloads/s-zoom.file.jpeg')
image_transforms = transforms.Compose([  
                    transforms.Resize((227,227)),
                    transforms.ToTensor()

])

board = []
for square in squares:
    square = Image.fromarray(square)
    square = image_transforms(square).float()
    square = square.unsqueeze(0)

    output = model(square)
    _, predicted = torch.max(output.data, 1)
    board.append(classes[predicted.item()])
</code></pre>
<p>The problem is that this takes a long time to process - over 20 seconds, when ideally it should take under 5. What is a more efficient way of doing this?</p>
",24,0,1,4,performance;machine-learning;computer-vision;conv-neural-network,2022-07-01 10:17:55,2022-07-01 10:17:55,2022-07-01 12:58:27,i am currently trying to find a way to determine a chess position based on an overhead picture of a chessboard  my model is a retrained resnet  here is my code  the problem is that this takes a long time to process   over  seconds  when ideally it should take under   what is a more efficient way of doing this ,how to efficiently run machine learning model over single images 
175,175,13002570,72824489,tf.distribute.MirroredStrategy - suggestion for improving test mean_iou for segmentation network using distributed training,"<p>I am using tensorflow 2.5.0 and implemented semantic segmatation network. used DeepLab_v3_plus network with ResNet101 backbone, adam optimizer and Categorical cross entropy loss to train network. I have first build code for single gpu and achieved test accuracy (mean_iou) of 54% trained for 96 epochs. Then added tf MirroredStrategy (one machine) in code to support for multi gpu training. Surprisingly with 2 gpus, training for 48 epochs, test mean_iou is just 27% and training with 4 gpus, for 24 epochs, test mean_iou can around 12% for same dataset.</p>
<ul>
<li>Code I have modified to support multi-gpu training from single-gpu training.</li>
</ul>
<ol>
<li>By following tensorflow blog for distributed training, created mirrored strategy and created model, model compilation and dataset_generator inside strategy scope. As per my understanding, by doing so, model.fit() method will take care of synchronization of gradients and distributing data on each gpus for training. Though code was running without any error, and also training time reduced compared to single gpu for same number of image training, test mean_iou keep getting worst with more number of gpus.</li>
<li>Replaced BatchNormalization with SyncBatchNormalization, but no improvement.</li>
<li>used warmup learning rate with linear scaling of learning rate with number of gpus, but no improvement.</li>
<li>in cross entropy loss, used both losses_utils.ReductionV2.AUTO and losses_utils.ReductionV2.NONE.</li>
</ol>
<pre><code>loss = ce(y_true, y_pred)
# reshape loss for each sample (BxHxWxC -&gt; BxN)
# Normalize loss by number of non zero elements and sum for each sample and mean across all samples.

</code></pre>
<p>using .AUTO/.NONE options, I am not scaling loss by global_batch_size understanding tf will take care of it and I am already normalizing for each gpus. but with both options, didn't get any luck.</p>
<ol start=""5"">
<li>changed data_generator to tf.data.Dataset obj. Though it has helped in training time, but test mean_iou become even worst.</li>
</ol>
<p>I would appreciate if any lead or suggestion for improving test_iou in distributed training.
let me know if you need any additional details.</p>
<p>Thank you</p>
",23,0,0,5,tensorflow;computer-vision;tf.keras;semantic-segmentation;distributed-training,2022-07-01 10:19:28,2022-07-01 10:19:28,2022-07-01 10:59:43,i am using tensorflow    and implemented semantic segmatation network  used deeplab_v_plus network with resnet backbone  adam optimizer and categorical cross entropy loss to train network  i have first build code for single gpu and achieved test accuracy  mean_iou  of   trained for  epochs  then added tf mirroredstrategy  one machine  in code to support for multi gpu training  surprisingly with  gpus  training for  epochs  test mean_iou is just   and training with  gpus  for  epochs  test mean_iou can around   for same dataset  using  auto  none options  i am not scaling loss by global_batch_size understanding tf will take care of it and i am already normalizing for each gpus  but with both options  didn t get any luck  thank you,tf distribute mirroredstrategy   suggestion for improving test mean_iou for segmentation network using distributed training
176,176,12882606,72619764,Compress Large Data in R into csv without NULLS or LIST,"<p>FIRST TIME POSTING:</p>
<p>I'm preparing data for <code>arules() read.transactions</code> and need to compress unique Invoice data (500k+ cases) so that each unique Invoice and its associated info fits on a single line like this:</p>
<blockquote>
<p>Invoice001,CustomerID,Country,StockCodeXYZ,StockCode123</p>
<p>Invoice002...etc</p>
</blockquote>
<p>However, the data reads in repeating the Invoice for each <code>StockCode</code> like this:</p>
<blockquote>
<p>Invoice001,CustomerID,Country,StockCodeXYZ</p>
<p>Invoice001,CustomerID,Country,StockCode123</p>
<p>Invoice002....etc</p>
</blockquote>
<p>I've been trying <code>pivot_wider()</code> and then <code>unite()</code>, but it generates 285M+ MOSTLY NULL cells into a LIST which I'm having a hard time resolving and unable to write to csv or read into <code>arules</code>.  I've also tried <code>keep(~!is.null(.)), discard(is.null), compact()</code> without success and am open to any method to achieve the desired outcome above.</p>
<p>However, I feel like I should be able to solve it using the built-in <code>arules() read.transactions() fx</code>, but am getting various errors as I try different things there too.</p>
<p>The data is opensource from University of California, Irvin and found here: <a href=""https://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx"" rel=""nofollow noreferrer"">https://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx</a></p>
<p>Any help would be greatly appreciated.</p>
<pre><code>library(readxl)
url &lt;- &quot;https://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx&quot;
destfile &lt;- &quot;Online_20Retail.xlsx&quot;
curl::curl_download(url, destfile)
Online_20Retail &lt;- read_excel(destfile)

trans &lt;- read.transactions(????????????)
</code></pre>
",56,1,0,5,dataframe;dplyr;tidyr;arules;readxl,2022-06-14 21:06:58,2022-06-14 21:06:58,2022-07-01 08:46:06,first time posting  i m preparing data for arules   read transactions and need to compress unique invoice data  k  cases  so that each unique invoice and its associated info fits on a single line like this  invoice customerid country stockcodexyz stockcode invoice   etc however  the data reads in repeating the invoice for each stockcode like this  invoice customerid country stockcodexyz invoice customerid country stockcode invoice    etc i ve been trying pivot_wider   and then unite    but it generates m  mostly null cells into a list which i m having a hard time resolving and unable to write to csv or read into arules   i ve also tried keep   is null      discard is null   compact   without success and am open to any method to achieve the desired outcome above  however  i feel like i should be able to solve it using the built in arules   read transactions   fx  but am getting various errors as i try different things there too  the data is opensource from university of california  irvin and found here   any help would be greatly appreciated ,compress large data in r into csv without nulls or list
177,177,19456970,72823991,Not able to preview input file in Query (Azure Stream Analytics),"<p>I am trying to set up a basic query in my Azure Stream Analytics. I have set up a Stream Analytics Job as well as a storage account under a Resource Group.</p>
<p>In my storage account, I created an input and output container. I tried to upload a json file as well as a csv file into my input container. The json file was created from a python dataframe of an public dataset (ai4i2020.csv), and the csv file was the exact ai4i2020.csv.</p>
<p>&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/00601/ai4i2020.csv&quot;</p>
<p>I tagged the input container to my Stream Analytics Job Input, but when I went to Query section, Azure was unable to provide me with an input preview. The error message reads</p>
<p>&quot;Unable to connect to input source at the moment. Please check if the input source is available and if it has not hit connection limits.&quot; May I know what might be to cause of this issue?</p>
",16,0,0,1,azure,2022-07-01 08:36:34,2022-07-01 08:36:34,2022-07-01 08:36:34,i am trying to set up a basic query in my azure stream analytics  i have set up a stream analytics job as well as a storage account under a resource group  in my storage account  i created an input and output container  i tried to upload a json file as well as a csv file into my input container  the json file was created from a python dataframe of an public dataset  aii csv   and the csv file was the exact aii csv   https   archive ics uci edu ml machine learning databases  aii csv  i tagged the input container to my stream analytics job input  but when i went to query section  azure was unable to provide me with an input preview  the error message reads  unable to connect to input source at the moment  please check if the input source is available and if it has not hit connection limits   may i know what might be to cause of this issue ,not able to preview input file in query  azure stream analytics 
178,178,6334082,72823016,Machine Learning training with high resolution to increase low resolution data,"<p>If I had some high resolution data. For example weather IR satellite imagery over the CONUS.</p>
<p>And I had some low resolution satellite imagery for the entire globe.</p>
<p>Could I train a machine learning model over one region and apply it globally? If so what ML models should I use and what resources can you recommend.</p>
<p>high_res_conus + low_res_conus -&gt; model</p>
<p>model(low_res_gobal)-&gt;high_res_global</p>
",12,0,-1,1,machine-learning,2022-07-01 05:02:24,2022-07-01 05:02:24,2022-07-01 05:02:24,if i had some high resolution data  for example weather ir satellite imagery over the conus  and i had some low resolution satellite imagery for the entire globe  could i train a machine learning model over one region and apply it globally  if so what ml models should i use and what resources can you recommend  high_res_conus   low_res_conus   gt  model model low_res_gobal   gt high_res_global,machine learning training with high resolution to increase low resolution data
179,179,8272206,50953685,Agriculture commodity price predictions using machine learning,"<p>I want to create a web application which uses machine learning to predict the price of agriculture commodities before 2-3 months.</p>

<p>Is it really feasible or not?</p>

<p>If yes, then please provide some rough idea about which tools and technologies I can use to implement it.</p>
",311,2,1,3,node.js;machine-learning;prediction,2018-06-20 22:43:06,2018-06-20 22:43:06,2022-07-01 03:46:46,i want to create a web application which uses machine learning to predict the price of agriculture commodities before   months  is it really feasible or not  if yes  then please provide some rough idea about which tools and technologies i can use to implement it ,agriculture commodity price predictions using machine learning
180,180,19454404,72820290,Trouble following Scatter Plot Implementation,"<p>I'm having trouble following along with an example provided by my professor. We're meant to follow along provided examples to understand the code and how the implementation goes and then do a different assignment based on topics covered in examples.</p>
<p>I'm having problems implementing a Scatter plot on the example. The code uses the Adult dataset from the UCI machine learning repository and has the following code.</p>
<pre><code>#install.packages(&quot;ggplot2&quot;)
library(ggplot2)

#import data
adult = read.csv(&quot;adult.DATA&quot;, header = FALSE, stringsAsFactors = TRUE)
summary(adult)
colnames(adult)

#remove similar columns and rename
adult_trim = adult[,-c(3,4,11,12)]
names(adult_trim) &lt;- c(&quot;Age&quot;, &quot;WorkClass&quot;, &quot;Education&quot;, &quot;Marital.Status&quot;, &quot;Occupation&quot;, &quot;Relationship&quot;, &quot;Race&quot;,
                   &quot;Sex&quot;, &quot;Hours.per.Week&quot;, &quot;Native.Country&quot;, &quot;Income&quot;)

#remove empty values &amp; Race/NativeCountry
adult_trim &lt;- adult_trim[rowSums(adult_trim == &quot;?&quot;) ==0, -c(7,10), drop = FALSE]
</code></pre>
<p>The problem is in the following scatterplot. The data doesnt have any header values for column names so it imports as v1,v2,... etc.</p>
<pre><code>adult$V4 = as.factor(as.character(adult$V4))
levels(adult$V4)
plot(
  jitter(as.numeric(adult$V4),0.5) ~ jitter(as.numeric(adult$V4), 0.5),
  data = adult_trim,
  xlab = &quot;Income&quot;,
  ylab = &quot;Education&quot;,
  pch = 19, 
  cex = 1, 
  bty = &quot;n&quot;,
  xlim = c(1:2),
  col = rgb(180,0,180,30, maxColorValue = 255)
 )
</code></pre>
<p>When trying to implement this plot on my machine it just gives me an error.</p>
<pre><code>Warning message:
In plot.formula(jitter(as.numeric(adult$V4), 0.5) ~ jitter(as.numeric(adult$V4),  :
  c(&quot;the formula 'jitter(as.numeric(adult$V4), 0.5) ~ jitter(as.numeric(adult$V4), ' 
 is treated as 'jitter(as.numeric(adult$V4), 0.5) ~ 1'&quot;, &quot;the formula '    0.5)' 
 is treated as 'jitter(as.numeric(adult$V4), 0.5) ~ 1'&quot;)
</code></pre>
<p>its supposed to look like this graph but with education <a href=""https://i.stack.imgur.com/EPfhX.png"" rel=""nofollow noreferrer"">https://i.stack.imgur.com/EPfhX.png</a> but I'm just getting the error. Also is there any reason this decides to use the original &quot;adult&quot; instead of &quot;adult_trim&quot; ?</p>
<p>Any help or explanation would be appreciated.</p>
",23,1,0,2,r;ggplot2,2022-06-30 23:41:28,2022-06-30 23:41:28,2022-07-01 00:26:28,i m having trouble following along with an example provided by my professor  we re meant to follow along provided examples to understand the code and how the implementation goes and then do a different assignment based on topics covered in examples  i m having problems implementing a scatter plot on the example  the code uses the adult dataset from the uci machine learning repository and has the following code  the problem is in the following scatterplot  the data doesnt have any header values for column names so it imports as v v     etc  when trying to implement this plot on my machine it just gives me an error  its supposed to look like this graph but with education  but i m just getting the error  also is there any reason this decides to use the original  adult  instead of  adult_trim    any help or explanation would be appreciated ,trouble following scatter plot implementation
181,181,19452872,72817554,Multivariate Times Series Classification using Machine Learning Algorithms,"<p>I am fairly new to machine learning and am currently working on a way to classify time series data. In order to do so, I would like to get a better understanding of how time series data can be fed into machine learning algorithms.</p>
<p>Further information:</p>
<ul>
<li><p>Each sample is a time series consisting of 2000 time points. For each time point, there are several variables, like temperature, speed, acceleration, etc. The data can be represented like this:
<a href=""https://i.stack.imgur.com/mxCPO.png"" rel=""nofollow noreferrer"">data structure for one time series sample</a></p>
</li>
<li><p>The whole dataset consists of 3000 samples. 3000 samples x 2000 data points per sample = 6000000 data points for each variable.</p>
</li>
<li><p>the goal is to classify the samples into classes from 0 to 4.</p>
</li>
</ul>
<p>My first attempt was just feeding the data as an array into the machine learning algorithms.
Let's say, we just focus on temperature. We can now structure the data like this:
<a href=""https://i.stack.imgur.com/lT40S.png"" rel=""nofollow noreferrer"">input training data for a ml-algorithm</a>
. Let X be the training input and y be the training output, the data looks like:</p>
<p>[21,21,22,...]=0</p>
<p>[35,35,35,...]=2</p>
<p>[11,12,12,...]=1</p>
<p>[18,17,18,...]=0</p>
<p>Can I just feed the machine learning algorithm (like SVCs) with array-type time series data like this? How does the algorithm know that the elements in the array are chronological data and not single features?</p>
<p>Here is an example code of what I did so far:</p>
<pre><code>dataframe.head()

     'sample_nr' 'timestamp' 'temperature' 'speed' 'acceleration'
 0   1           0.01        21             -0.43   0.34205 
 1   1           0.02        21             -0.43   0.34205 
 2   1           0.03        22             -0.43   0.34205 
</code></pre>
<p>Create a data_list, which contains all the sample_nr's in a list. Also, the dataframe gets grouped by the sample_nr</p>
<pre><code>data_list = []
for sample_nr, sample_df in dataframe.groupby('sample_nr'):    
    dataframe.groupby('sample_nr'):
    data_list.append(dataframe)
</code></pre>
<p>For a first step, we will only focus on one feature, let's say the temperature:</p>
<pre><code>X_list = []
y_list = []

for sample in data_list:
    temp_X = np.array(sample['temperature'])
    temp_y = sample['label'].unique()[0]

    X_list.append(temp_X)
    y_list.append(temp_y)
</code></pre>
<p>Transform the lists to pandas.Dataframes:</p>
<pre><code>X_df = pd.DataFrame(X_list)
y_df = pd.DataFrame(y_list)
</code></pre>
<p>Now, the X_df is a 3000x2000 list: Each row describes a sample, and the values in the columns are the temperature values for each of the 2000 time steps:</p>
<pre><code>print(X_df)
</code></pre>
<p>....<strong>0</strong>....<strong>1</strong>....<strong>2</strong>....<strong>3</strong></p>
<p><strong>0</strong> 21 21 22 22</p>
<p><strong>1</strong> 35 35 35 36</p>
<p><strong>2</strong> 11 12 12 12</p>
<p>Also, for the output value:</p>
<pre><code>print(y_df)
</code></pre>
<p>....<strong>0</strong></p>
<p><strong>0</strong> 0</p>
<p><strong>1</strong> 2</p>
<p><strong>2</strong> 1</p>
<p>Now split up the dataframe to train and test data:</p>
<pre><code>X_train_array, X_test_array, y_train_array, y_test_array = train_test_split(X_df, y_df, test_size=0.2, shuffle=True, random_state=42)
X_train_df = pd.DataFrame(X_train_array)
X_test_df = pd.DataFrame(X_test_array)
y_train_df = pd.DataFrame(y_train_array)
y_test_df = pd.DataFrame(y_test_array)

from sklearn import svm
clf = svm.SVC()
clf.fit(X_train_df, y_train_df)
</code></pre>
",25,0,0,5,python;machine-learning;time-series;classification;multivariate-time-series,2022-06-30 19:57:10,2022-06-30 19:57:10,2022-06-30 22:19:40,i am fairly new to machine learning and am currently working on a way to classify time series data  in order to do so  i would like to get a better understanding of how time series data can be fed into machine learning algorithms  further information  the whole dataset consists of  samples   samples x  data points per sample    data points for each variable  the goal is to classify the samples into classes from  to                                           can i just feed the machine learning algorithm  like svcs  with array type time series data like this  how does the algorithm know that the elements in the array are chronological data and not single features  here is an example code of what i did so far  create a data_list  which contains all the sample_nr s in a list  also  the dataframe gets grouped by the sample_nr for a first step  we will only focus on one feature  let s say the temperature  transform the lists to pandas dataframes  now  the x_df is a x list  each row describes a sample  and the values in the columns are the temperature values for each of the  time steps                                  also  for the output value             now split up the dataframe to train and test data ,multivariate times series classification using machine learning algorithms
182,182,7373787,62409303,How to handle missing values (NaN) in categorical data when using scikit-learn OneHotEncoder?,"<p>I have recently started learning python to develop a predictive model for a research project using machine learning methods. I have a large dataset comprised of both numerical and categorical data. The dataset has lots of missing values. I am currently trying to encode the categorical features using OneHotEncoder. When I read about OneHotEncoder, my understanding was that for a missing value (NaN), OneHotEncoder would assign 0s to all the feature's categories, as such:</p>

<pre><code>0     Male 
1     Female
2     NaN
</code></pre>

<p>After applying OneHotEncoder:</p>

<pre><code>0     10 
1     01
2     00
</code></pre>

<p>However, when running the following code:</p>

<pre class=""lang-py prettyprint-override""><code>    # Encoding categorical data
    from sklearn.compose import ColumnTransformer
    from sklearn.preprocessing import OneHotEncoder


    ct = ColumnTransformer([('encoder', OneHotEncoder(handle_unknown='ignore'), [1])],
                           remainder='passthrough')
    obj_df = np.array(ct.fit_transform(obj_df))
    print(obj_df)

</code></pre>

<p>I am getting the error <strong>ValueError: Input contains NaN</strong></p>

<p>So I am guessing my previous understanding of how OneHotEncoder handles missing values is wrong. 
Is there a way for me to get the functionality described above? I know imputing the missing values before encoding will resolve this issue, but I am reluctant to do this as I am dealing with medical data and fear that imputation may decrease the predictive accuracy of my model. </p>

<p>I found this <a href=""https://stackoverflow.com/questions/58222008/nan-giving-valueerror-in-onehotencoder-in-scikit-learn"">question</a> that is similar but the answer doesn't offer a detailed enough solution on how to deal with the NaN values.</p>

<p>Let me know what your thoughts are, thanks.</p>
",11832,5,15,3,python;machine-learning;scikit-learn,2020-06-16 18:39:16,2020-06-16 18:39:16,2022-06-30 21:06:48,i have recently started learning python to develop a predictive model for a research project using machine learning methods  i have a large dataset comprised of both numerical and categorical data  the dataset has lots of missing values  i am currently trying to encode the categorical features using onehotencoder  when i read about onehotencoder  my understanding was that for a missing value  nan   onehotencoder would assign s to all the feature s categories  as such  after applying onehotencoder  however  when running the following code  i am getting the error valueerror  input contains nan i found this  that is similar but the answer doesn t offer a detailed enough solution on how to deal with the nan values  let me know what your thoughts are  thanks ,how to handle missing values  nan  in categorical data when using scikit learn onehotencoder 
183,183,11967549,72815510,"Matplotlib - When I format ticks, they are not replaced and instead added to the plot","<p>Hello I am using Matplotlib to plot some curves for machine learning. I have the problem that when I format my x_ticks , instead of replacing the old ones they are added to the plot. See the first plot on the image below on the left where percent and numbers are plotted:</p>
<p><a href=""https://i.stack.imgur.com/yJd6d.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yJd6d.png"" alt=""enter image description here"" /></a></p>
<p>This is the code from scikit learn. I use <code>axes[0].xaxis.set_major_formatter(PercentFormatter(xmax=5))</code> to format the first plot which seems to work, but like I said the labels are just added on top. I had the same problem with other matplotlib implementations in geopandas for example so I thought maybe someone knows what to do.</p>
<pre><code>from matplotlib.ticker import PercentFormatter
fig, axes = plt.subplots(3, 2, figsize=(10, 15))

plot_learning_curve(...)


def plot_learning_curve(
    estimator,
    title,
    X,
    y,
    axes=None,
    ylim=None,
    cv=None,
    n_jobs=None,
    train_sizes=np.linspace(0.1, 1.0, 5),
):
    &quot;&quot;&quot;
    Generate 3 plots: the test and training learning curve, the training
    samples vs fit times curve, the fit times vs score curve.

    Parameters
    ----------
    estimator : estimator instance
        An estimator instance implementing `fit` and `predict` methods which
        will be cloned for each validation.

    title : str
        Title for the chart.

    X : array-like of shape (n_samples, n_features)
        Training vector, where ``n_samples`` is the number of samples and
        ``n_features`` is the number of features.

    y : array-like of shape (n_samples) or (n_samples, n_features)
        Target relative to ``X`` for classification or regression;
        None for unsupervised learning.

    axes : array-like of shape (3,), default=None
        Axes to use for plotting the curves.

    ylim : tuple of shape (2,), default=None
        Defines minimum and maximum y-values plotted, e.g. (ymin, ymax).

    cv : int, cross-validation generator or an iterable, default=None
        Determines the cross-validation splitting strategy.
        Possible inputs for cv are:

          - None, to use the default 5-fold cross-validation,
          - integer, to specify the number of folds.
          - :term:`CV splitter`,
          - An iterable yielding (train, test) splits as arrays of indices.

        For integer/None inputs, if ``y`` is binary or multiclass,
        :class:`StratifiedKFold` used. If the estimator is not a classifier
        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.

        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various
        cross-validators that can be used here.

    n_jobs : int or None, default=None
        Number of jobs to run in parallel.
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`
        for more details.

    train_sizes : array-like of shape (n_ticks,)
        Relative or absolute numbers of training examples that will be used to
        generate the learning curve. If the ``dtype`` is float, it is regarded
        as a fraction of the maximum size of the training set (that is
        determined by the selected validation method), i.e. it has to be within
        (0, 1]. Otherwise it is interpreted as absolute sizes of the training
        sets. Note that for classification the number of samples usually have
        to be big enough to contain at least one sample from each class.
        (default: np.linspace(0.1, 1.0, 5))
    &quot;&quot;&quot;
    if axes is None:
        _, axes = plt.subplots(1, 3, figsize=(20, 5))

    axes[0].set_title(title)
    if ylim is not None:
        axes[0].set_ylim(*ylim)
    axes[0].set_xlabel(&quot;Training examples&quot;)
    axes[0].set_ylabel(&quot;Score&quot;)

    train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(
        estimator,
        X,
        y,
        cv=cv,
        n_jobs=n_jobs,
        train_sizes=train_sizes,
        return_times=True,
    )
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    fit_times_mean = np.mean(fit_times, axis=1)
    fit_times_std = np.std(fit_times, axis=1)

    # Plot learning curve
    axes[0].grid()
    axes[0].fill_between(
        train_sizes,
        train_scores_mean - train_scores_std,
        train_scores_mean + train_scores_std,
        alpha=0.1,
        color=&quot;r&quot;,
    )
    axes[0].fill_between(
        train_sizes,
        test_scores_mean - test_scores_std,
        test_scores_mean + test_scores_std,
        alpha=0.1,
        color=&quot;g&quot;,
    )
    axes[0].plot(
        train_sizes, train_scores_mean, &quot;o-&quot;, color=&quot;r&quot;, label=&quot;Training score&quot;
    )
    axes[0].plot(
        train_sizes, test_scores_mean, &quot;o-&quot;, color=&quot;g&quot;, label=&quot;Cross-validation score&quot;
    )
    axes[0].legend(loc=&quot;best&quot;)
    axes[0].xaxis.set_major_formatter(PercentFormatter(xmax=5))
    
    # Plot n_samples vs fit_times
    axes[1].grid()
    axes[1].plot(train_sizes, fit_times_mean, &quot;o-&quot;)
    axes[1].fill_between(
        train_sizes,
        fit_times_mean - fit_times_std,
        fit_times_mean + fit_times_std,
        alpha=0.1,
    )
    axes[1].set_xlabel(&quot;Training examples&quot;)
    axes[1].set_ylabel(&quot;fit_times&quot;)
    axes[1].set_title(&quot;Scalability of the model&quot;)

    # Plot fit_time vs score
    fit_time_argsort = fit_times_mean.argsort()
    fit_time_sorted = fit_times_mean[fit_time_argsort]
    test_scores_mean_sorted = test_scores_mean[fit_time_argsort]
    test_scores_std_sorted = test_scores_std[fit_time_argsort]
    axes[2].grid()
    axes[2].plot(fit_time_sorted, test_scores_mean_sorted, &quot;o-&quot;)
    axes[2].fill_between(
        fit_time_sorted,
        test_scores_mean_sorted - test_scores_std_sorted,
        test_scores_mean_sorted + test_scores_std_sorted,
        alpha=0.1,
    )
    axes[2].set_xlabel(&quot;fit_times&quot;)
    axes[2].set_ylabel(&quot;Score&quot;)
    axes[2].set_title(&quot;Performance of the model&quot;)

    return plt
</code></pre>
",30,1,-1,4,python;matplotlib;plot;scikit-learn,2022-06-30 17:35:12,2022-06-30 17:35:12,2022-06-30 18:52:00,hello i am using matplotlib to plot some curves for machine learning  i have the problem that when i format my x_ticks   instead of replacing the old ones they are added to the plot  see the first plot on the image below on the left where percent and numbers are plotted   this is the code from scikit learn  i use axes   xaxis set_major_formatter percentformatter xmax    to format the first plot which seems to work  but like i said the labels are just added on top  i had the same problem with other matplotlib implementations in geopandas for example so i thought maybe someone knows what to do ,matplotlib   when i format ticks  they are not replaced and instead added to the plot
184,184,17031310,72816363,"Python List [:,3]","<p>i'm new to machine learning and I have found this code from github and currently i'm trying to replicate it.</p>
<p>However the code has some runtime errors particularly the way it is accessing the list.</p>
<pre><code>trainx, trainy = train[:, 1], train[:, 3]
</code></pre>
<p>Take this block of code for example, python throws an error
TypeError: list indices must be integers or slices, not tuple</p>
<p>I understand that this is not the code i've written however, I don't understand the reference [:,1]</p>
<p>The code is littered with [:,1] . [:,2]
Is he trying to access the first and second column of the csv?
I believe he is trying to achieve that.</p>
<p>Can anyone explain what he is trying to access from the list.</p>
<p>The github code is located here</p>
<pre><code>https://github.com/anthonymorast/lstm-lstm/blob/master/model/lstm.py
</code></pre>
",31,0,-1,2,python;list,2022-06-30 18:35:51,2022-06-30 18:35:51,2022-06-30 18:35:51,i m new to machine learning and i have found this code from github and currently i m trying to replicate it  however the code has some runtime errors particularly the way it is accessing the list  i understand that this is not the code i ve written however  i don t understand the reference      can anyone explain what he is trying to access from the list  the github code is located here,python list     
185,185,19146827,72816169,Shiny app (leafviz) in docker container not loading in browser,"<p>I am building a docker container to use the Leafcutter and Leafviz analysis tools. The final visualization commanded from an R file uses shiny app, it works fine on my machine but when ran in the container I can't connect to it.</p>
<p>I run the container with the following line of code:</p>
<pre><code>docker run -dit --name leaf --rm -p 1234:1234 leafcutter
</code></pre>
<p>All is in order when I check with docker ps:</p>
<pre><code>CONTAINER ID   IMAGE        COMMAND   CREATED         STATUS         PORTS                                       NAMES
783f550df965   leafcutter   &quot;bash&quot;    2 minutes ago   Up 2 minutes   0.0.0.0:1234-&gt;1234/tcp, :::1234-&gt;1234/tcp   leaf
</code></pre>
<p>Executing the pipeline in the container calls several snakefiles, and the last rule of the last one calls the R file:</p>
<pre><code>Rscript /path/to/run_leafviz.R -i {input}
</code></pre>
<p>That script calls several functions before calling leafviz() which basically just runs the shiny app, I've modified the options like so:</p>
<pre><code>shiny::runApp(launch.browser=FALSE, appDir = system.file(&quot;application&quot;, package = &quot;leafviz&quot;), host = &quot;0.0.0.0&quot;, port = 1234)
</code></pre>
<p>All the shiny files and packages are installed with the R leafviz package. When I execute my container all goes fine, the output shows &quot;Listening on <a href=""http://0.0.0.0:1234%22"" rel=""nofollow noreferrer"">http://0.0.0.0:1234&quot;</a>, but when I try to connect I get the &quot;connexion failed&quot; page.</p>
<p>My Dockerfile is fairly large but here are the most relevant parts:</p>
<pre><code>FROM ubuntu:22.04
ENV DEBIAN_FRONTEND noninteractive

#Install Ubuntu packages
RUN apt-get update &amp;&amp; apt-get install \
    -y cmake -y curl \
    -y default-jre \
    -y gdebi-core \
    -y less -y libarchive13 -y libbz2-dev -y libcairo2-dev -y libcurl4-openssl-dev -y libgsl-dev \
    -y liblzma-dev -y libncurses5-dev -y libncursesw5-dev -y libssl-dev -y libxml2-dev -y libxt-dev \
    -y pandoc -y pandoc-citeproc -y python-pip \
    -y tabix \
    -y unzip \
    -y wget \
    -y zlib1g-dev \
    &amp;&amp; rm -rf /var/lib/apt/lists/*

#Install conda, snakemake, samtools, regtools...
#[...]

#Install R
LABEL org.label-schema.license=&quot;GPL-2.0&quot; \
      org.label-schema.vcs-url=&quot;https://github.com/rocker-org/r-apt&quot; \
      org.label-schema.vendor=&quot;Rocker Project&quot; \
      maintainer=&quot;Dirk Eddelbuettel &lt;edd@debian.org&gt;&quot;
RUN useradd docker \
    &amp;&amp; mkdir /home/docker \
    &amp;&amp; chown docker:docker /home/docker \
    &amp;&amp; addgroup docker staff
RUN apt-get update \
    &amp;&amp; apt-get install -y --no-install-recommends \
    littler r-base r-base-dev r-recommended r-cran-docopt
RUN ln -s /usr/lib/R/site-library/littler/examples/install.r /usr/local/bin/install.r \
    &amp;&amp; ln -s /usr/lib/R/site-library/littler/examples/install2.r /usr/local/bin/install2.r \
    &amp;&amp; ln -s /usr/lib/R/site-library/littler/examples/installGithub.r /usr/local/bin/installGithub.r \
    &amp;&amp; ln -s /usr/lib/R/site-library/littler/examples/testInstalled.r /usr/local/bin/testInstalled.r \
    &amp;&amp; rm -rf /tmp/downloaded_packages/ /tmp/*.rds \
    &amp;&amp; rm -rf /var/lib/apt/lists/*

#Install shiny server (I have tried with and without this RUN command)
RUN wget --no-verbose https://s3.amazonaws.com/rstudio-shiny-server-os-build/ubuntu-12.04/x86_64/VERSION -O &quot;version.txt&quot; &amp;&amp; \
    VERSION=$(cat version.txt)  &amp;&amp; \
    wget --no-verbose &quot;https://s3.amazonaws.com/rstudio-shiny-server-os-build/ubuntu-12.04/x86_64/shiny-server-$VERSION-amd64.deb&quot; -O ss-latest.deb &amp;&amp; \
    gdebi -n ss-latest.deb &amp;&amp; \
    rm -f version.txt ss-latest.deb

EXPOSE 1234

#Install R packages
COPY install_packages.R /tmp/install_packages.R 
RUN Rscript /tmp/install_packages.R 

CMD [&quot;bash&quot;]
</code></pre>
<p>I've been learning docker quite chaotically so I don't know if some elements are clashing, but I have exposed the container port and published it to the host and no error message seems to indicate there is a problem coming from somewhere else. I would really appreciate some help.</p>
",21,0,0,3,docker;shiny;dockerfile,2022-06-30 18:21:11,2022-06-30 18:21:11,2022-06-30 18:21:11,i am building a docker container to use the leafcutter and leafviz analysis tools  the final visualization commanded from an r file uses shiny app  it works fine on my machine but when ran in the container i can t connect to it  i run the container with the following line of code  all is in order when i check with docker ps  executing the pipeline in the container calls several snakefiles  and the last rule of the last one calls the r file  that script calls several functions before calling leafviz   which basically just runs the shiny app  i ve modified the options like so  all the shiny files and packages are installed with the r leafviz package  when i execute my container all goes fine  the output shows  listening on   but when i try to connect i get the  connexion failed  page  my dockerfile is fairly large but here are the most relevant parts  i ve been learning docker quite chaotically so i don t know if some elements are clashing  but i have exposed the container port and published it to the host and no error message seems to indicate there is a problem coming from somewhere else  i would really appreciate some help ,shiny app  leafviz  in docker container not loading in browser
186,186,13990977,72815591,How can I have a series of numpy ndarrays as the input data to train a tensorflow machine learning model?,"<p>I am trying to build a machine learning model which predicts a single number from a series of numbers. I am using a Sequential model from the keras API of Tensorflow.</p>
<p>Basically my x data is a Pandas series which contains numpy ndarrays, which contain floats.
My y data is a series of numpy ndarrays of shape (1,1), so basically just a single float value.</p>
<p>You can imagine my dataset to look something like this:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>Index</th>
<th>x data (pandas series)</th>
<th>y data (pandas series)</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td><code>np.ndarray(shape (1209278,) )</code></td>
<td><code>np.ndarray(shape = () )</code></td>
</tr>
<tr>
<td>1</td>
<td><code>np.ndarray(shape (1211140,) )</code></td>
<td><code>np.ndarray(shape = () )</code></td>
</tr>
<tr>
<td>2</td>
<td><code>np.ndarray(shape (1418411,) )</code></td>
<td><code>np.ndarray(shape = () )</code></td>
</tr>
<tr>
<td>3</td>
<td><code>np.ndarray(shape (1077132,) )</code></td>
<td><code>np.ndarray(shape = () )</code></td>
</tr>
<tr>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
</tbody>
</table>
</div>
<p>The type of my x data and y data is, as stated above, a pandas series.
When I try to train my model using the fit function it yields this error:</p>
<p><em>ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)</em></p>
<p>I also tried converting the pandas series to a numpy array, but this did not help.
As it seems, the fact that I have a series of differently shaped ndarrays as my input data is the problem itself.</p>
<p>I don't really know what I can do, to fix this error.
Which leads me to my question:</p>
<p><strong>How can I have a series of numpy ndarrays as the input data to train a tensorflow machine learning model?</strong></p>
",39,1,1,5,python;pandas;numpy;tensorflow;keras,2022-06-30 17:40:33,2022-06-30 17:40:33,2022-06-30 17:57:00,i am trying to build a machine learning model which predicts a single number from a series of numbers  i am using a sequential model from the keras api of tensorflow  you can imagine my dataset to look something like this  valueerror  failed to convert a numpy array to a tensor  unsupported object type numpy ndarray  how can i have a series of numpy ndarrays as the input data to train a tensorflow machine learning model ,how can i have a series of numpy ndarrays as the input data to train a tensorflow machine learning model 
187,187,18276526,72815361,Using Bootstrap tab view in Django,"<p>I am trying to implement tabs using Django and Bootstrap.
The following code does not switch tabs properly. Tab switching is not working even thought URL is changing
Please let me know how I can switch tabs without any problems.</p>
<p>Code</p>
<pre><code>        &lt;div class = &quot;company-info-tab&quot;&gt;
            &lt;div class=&quot;container&quot;&gt;
              &lt;!-- Nav tabs --&gt;
              &lt;ul class=&quot;nav nav-tabs&quot;&gt;
                &lt;li class=&quot;nav-item&quot;&gt;
                  &lt;a class=&quot;nav-link active&quot; data-toggle=&quot;tab&quot; href=&quot;#home&quot;&gt;Home&lt;/a&gt;
                &lt;/li&gt;
                &lt;li class=&quot;nav-item&quot;&gt;
                  &lt;a class=&quot;nav-link&quot; data-toggle=&quot;tab&quot; href=&quot;#menu1&quot;&gt;Baby computer Man&lt;/a&gt;
                &lt;/li&gt;
                &lt;li class=&quot;nav-item&quot;&gt;
                  &lt;a class=&quot;nav-link&quot; data-toggle=&quot;tab&quot; href=&quot;#menu2&quot;&gt;Menu 2&lt;/a&gt;
                &lt;/li&gt;
              &lt;/ul&gt;
              &lt;!-- Tab panes --&gt;
              &lt;div class=&quot;tab-content&quot;&gt;
                &lt;div class=&quot;tab-pane container active&quot; id=&quot;home&quot;&gt;A &quot;Hello, World!&quot; program generally is a computer program that outputs or displays the message &quot;Hello, World!&quot;. Such a program is very simple in most programming languages, and is often used to illustrate the basic syntax of a programming language. It is often the first program written by people learning to code.&lt;/div&gt;
                &lt;div class=&quot;tab-pane container fade&quot; id=&quot;menu1&quot;&gt;The Manchester Baby, also known as the Small-Scale Experimental Machine, was the world's first electronic stored-program computer. It was built at the University of Manchester, UK, by Frederic C. Williams, Tom Kilburn, and Geoff Tootill, and ran its first program on 21 June 1948, seventy-one years ago&lt;/div&gt;
                &lt;div class=&quot;tab-pane container fade&quot; id=&quot;menu2&quot;&gt;...&lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
      &lt;/div&gt; 
</code></pre>
<p>Screen</p>
<p><a href=""https://i.stack.imgur.com/Mc7pH.png"" rel=""nofollow noreferrer"">Screen</a></p>
",27,1,0,3,html;django;bootstrap-4,2022-06-30 17:25:20,2022-06-30 17:25:20,2022-06-30 17:49:51,code screen ,using bootstrap tab view in django
188,188,1332991,72814901,How do machine learning algorithms speak to each other?,"<p>My understanding is that if a company creates a machine learning application, they use an API to ensure that applications talk to one another, which is what I found in my initial research (<a href=""https://www.ibm.com/cloud/learn/api"" rel=""nofollow noreferrer"">https://www.ibm.com/cloud/learn/api</a>). However, is this correct - is there an inner working within the machine learning application that enable two algorithms to connect? And how does this work in practice?</p>
",15,0,-1,2,api;machine-learning,2022-06-30 16:51:49,2022-06-30 16:51:49,2022-06-30 16:51:49,my understanding is that if a company creates a machine learning application  they use an api to ensure that applications talk to one another  which is what i found in my initial research     however  is this correct   is there an inner working within the machine learning application that enable two algorithms to connect  and how does this work in practice ,how do machine learning algorithms speak to each other 
189,189,15682594,72805521,Getting an index error while training machine learning model for spam detection,"<p>I am creating a spam detection ML model using Naive Bayes from scratch and for that i need the likelihood of all classes(or P(feature|not spam)). For that, I've created a function:</p>
<pre><code>import numpy as np
def get_likelihood(term_document_matrix, label_index, smoothing=0):
    likelihood = {}
    for label, index in label_index.items():
        likelihood[label]=term_document_matrix[index, :].sum(axis=0) + smoothing
        likelihood[label]= np.asarray(likelihood[label])[0]
        total_count = likelihood[label].sum()
        likelihood[label] = likelihood[label]/float(total_count)
    return likelihood
</code></pre>
<p>And then I've implemented this function using the following call:</p>
<pre><code>smoothing = 1
likelihood = get_likelihood(term_docs,label_index,smoothing)
</code></pre>
<p>But I seem to be getting this error:</p>
<pre><code>IndexError                                Traceback (most recent call last)
c:\Users\SUKHMAN\Desktop\Spam detection project\spamdetection.ipynb Cell 9' in &lt;cell line: 2&gt;()
  1 smoothing=1
----&gt; 2 likelihood = get_likelihood(term_docs,label_index,smoothing)

c:\Users\SUKHMAN\Desktop\Spam detection project\spamdetection.ipynb Cell 8' in get_likelihood(term_document_matrix, label_index, smoothing)
  3 likelihood = {}
  4 for label, index in label_index.items():
----&gt; 5     likelihood[label]=term_document_matrix[index, :].sum(axis=0) + smoothing
  6     likelihood[label]= np.asarray(likelihood[label])[0]
  7     total_count = likelihood[label].sum()

File ~\AppData\Roaming\Python\Python310\site-packages\scipy\sparse\_index.py:47, in IndexMixin.__getitem__(self, key)
 46 def __getitem__(self, key):
---&gt; 47     row, col = self._validate_indices(key)
 49     # Dispatch to specialized methods.
 50     if isinstance(row, INT_TYPES):

File ~\AppData\Roaming\Python\Python310\site-packages\scipy\sparse\_index.py:159, in IndexMixin._validate_indices(self, key)
157         row += M
158 elif not isinstance(row, slice):
--&gt; 159     row = self._asindices(row, M)
161 if isintlike(col):
162     col = int(col)
...
--&gt; 191     raise IndexError('index (%d) out of range' % max_indx)
193 min_indx = x.min()
194 if min_indx &lt; 0:

IndexError: index (1499) out of range
</code></pre>
",27,1,0,5,python;machine-learning;deep-learning;jupyter-notebook;naivebayes,2022-06-29 22:53:21,2022-06-29 22:53:21,2022-06-30 16:46:55,i am creating a spam detection ml model using naive bayes from scratch and for that i need the likelihood of all classes or p feature not spam    for that  i ve created a function  and then i ve implemented this function using the following call  but i seem to be getting this error ,getting an index error while training machine learning model for spam detection
190,190,3976008,72559416,Swift - Remove image background with CoreML,"<p>I am using CoreML with the DeepLabV3 model to remove the background from an image: <a href=""https://developer.apple.com/machine-learning/models/"" rel=""nofollow noreferrer"">https://developer.apple.com/machine-learning/models/</a></p>
<p>This is working well for removing the background from photos where the subject it a person/dog/car, but for other cases, such as skylines and some objects on a table (please see example images), it is unable to detect the object from the background.</p>
<p>Should I be using a different method for this?</p>
<p>Thank you</p>
<pre><code>var imageSegmentationModel = DeepLabV3()
var request :  VNCoreMLRequest?

func setUpModel() {
        if let visionModel = try? VNCoreMLModel(for: imageSegmentationModel.model) {
                request = VNCoreMLRequest(model: visionModel, completionHandler: visionRequestDidComplete)
                request?.imageCropAndScaleOption = .scaleFill
        }
        else {
                fatalError()
        }
}

func predict() {
        DispatchQueue.global(qos: .userInitiated).async {
            guard let request = self.request else { fatalError() }
            let handler = VNImageRequestHandler(cgImage: (self.originalImage?.cgImage)!, options: [:])
            do {
                try handler.perform([request])
            }catch {
                print(error)
            }
        }
   }

func visionRequestDidComplete(request: VNRequest, error: Error?) {
        DispatchQueue.main.async {
            if let observations = request.results as? [VNCoreMLFeatureValueObservation],
                let segmentationmap = observations.first?.featureValue.multiArrayValue {
                
                self.maskImage = segmentationmap.image(min: 0, max: 255)
                print(self.maskImage!.size)
                
                self.maskImage = self.maskImage?.resizedImage(for: self.originalImage!.size)
                if let image:UIImage = self.maskOriginalImage(){
                    print(&quot;Success&quot;)
                    self.outputImageView.image = image
                }
            }
        }
            
    }

func maskOriginalImage() -&gt; UIImage? {
        if(self.maskImage != nil &amp;&amp; self.originalImage != nil){
            let maskReference = self.maskImage?.cgImage!
            let imageMask = CGImage(maskWidth: maskReference!.width,
                                    height: maskReference!.height,
                                    bitsPerComponent: maskReference!.bitsPerComponent,
                                    bitsPerPixel: maskReference!.bitsPerPixel,
                                    bytesPerRow: maskReference!.bytesPerRow,
                                    provider: maskReference!.dataProvider!, decode: nil, shouldInterpolate: true)
            
            let maskedReference = self.originalImage?.cgImage!.masking(imageMask!)
            return UIImage(cgImage: maskedReference!)
            
        }
        return nil
    }
</code></pre>
<p><a href=""https://i.stack.imgur.com/lSOLm.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lSOLm.jpg"" alt=""Good Image Example"" /></a></p>
<p><a href=""https://i.stack.imgur.com/e8VQ0.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/e8VQ0.jpg"" alt=""Bad Image Example"" /></a></p>
",95,1,1,5,ios;swift;coreml;apple-vision;deeplab,2022-06-09 16:51:15,2022-06-09 16:51:15,2022-06-30 15:39:32,i am using coreml with the deeplabv model to remove the background from an image   this is working well for removing the background from photos where the subject it a person dog car  but for other cases  such as skylines and some objects on a table  please see example images   it is unable to detect the object from the background  should i be using a different method for this  thank you  ,swift   remove image background with coreml
191,191,12051503,72471691,How to deploy multiple models to an endpoint using Azure Machine Learning CLI v2?,"<p>At the GA of <a href=""https://docs.microsoft.com/en-us/azure/machine-learning/azure-machine-learning-release-notes-cli-v2#2022-05-24"" rel=""nofollow noreferrer"">az ml cli v2</a>, we've been working on some POC using <a href=""https://docs.microsoft.com/en-us/azure/machine-learning/reference-yaml-deployment-managed-online"" rel=""nofollow noreferrer"">yml online deployment</a> on top of managed endpoint and it all went well for single model, until when there's certain scenario where there is requirement to deploy multiple trained and registered models to one managed endpoint, it seems there is no documentations on how to achieve that.</p>
<p>Previously using Python SDK, it was able to deploy list of models to AKS cluster.</p>
<p>Checking if there's any limitation or could be some docs I might have missed?</p>
",77,1,0,2,azure-cli;azure-machine-learning-service,2022-06-02 12:04:23,2022-06-02 12:04:23,2022-06-30 14:52:33,at the ga of   we ve been working on some poc using  on top of managed endpoint and it all went well for single model  until when there s certain scenario where there is requirement to deploy multiple trained and registered models to one managed endpoint  it seems there is no documentations on how to achieve that  previously using python sdk  it was able to deploy list of models to aks cluster  checking if there s any limitation or could be some docs i might have missed ,how to deploy multiple models to an endpoint using azure machine learning cli v 
192,192,10883094,72804704,Reduce fastText memory usage for big models,"<p>I trained a machine learning sentence classification model that uses, among other features, also the vectors obtained from a pretrained fastText model (like <a href=""https://fasttext.cc/docs/en/crawl-vectors.html"" rel=""nofollow noreferrer"">these</a>) which is 7Gb.  I use the pretrained fastText Italian model: I am using this word embedding only to get some semantic features to feed into the effective ML model.</p>
<p>I built a simple API based on fastText that, at prediction time, computes the vectors needed by the effective ML model. Under the hood, this API receives a string as input and calls <code>get_sentence_vector</code>. When the API starts, it loads the fastText model into memory.</p>
<p><strong>How can I reduce the memory footprint of fastText, which is loaded into RAM?</strong></p>
<p>Constraints:</p>
<ul>
<li>My model works fine, training was time-consuming and expensive, so I wouldn't want to retrain it using smaller vectors</li>
<li>I need the fastText ability to handle out-of-vocabulary words, so I can't use just vectors but I need the full model</li>
<li>I should reduce the RAM usage, even at the expense of a reduction in speed.</li>
</ul>
<p>At the moment, I'm starting to experiment with <a href=""https://github.com/avidale/compress-fasttext"" rel=""nofollow noreferrer"">compress-fasttext</a>...</p>
<p><strong>Please share your suggestions and thoughts even if they do not represent full-fledged solutions.</strong></p>
",26,0,0,5,python;machine-learning;optimization;nlp;fasttext,2022-06-29 21:44:26,2022-06-29 21:44:26,2022-06-30 14:12:26,i trained a machine learning sentence classification model that uses  among other features  also the vectors obtained from a pretrained fasttext model  like   which is gb   i use the pretrained fasttext italian model  i am using this word embedding only to get some semantic features to feed into the effective ml model  i built a simple api based on fasttext that  at prediction time  computes the vectors needed by the effective ml model  under the hood  this api receives a string as input and calls get_sentence_vector  when the api starts  it loads the fasttext model into memory  how can i reduce the memory footprint of fasttext  which is loaded into ram  constraints  at the moment  i m starting to experiment with     please share your suggestions and thoughts even if they do not represent full fledged solutions ,reduce fasttext memory usage for big models
193,193,19436733,72809575,How to include the weighting factors of a survey when doing machine learning?,"<p>I am applying a Lasso regression for an analysis in machine learning. But I have to consider the weighting factors of the survey that I am using.</p>
<p>How to include the weighting factors of a survey when doing machine learning? where in the code is this entered? I would appreciate if you have any python code examples on this.
Thank you very much for the advice,</p>
",24,0,-1,2,python;machine-learning,2022-06-30 07:33:51,2022-06-30 07:33:51,2022-06-30 07:33:51,i am applying a lasso regression for an analysis in machine learning  but i have to consider the weighting factors of the survey that i am using ,how to include the weighting factors of a survey when doing machine learning 
194,194,8833267,72809158,"AttributeError: transform not found in Countvectorizer , using sklearn","<p>Trying to load my spam text detection Machine Learning model in API using Django framework.</p>
<p>My error when sending request with text:&quot;Ahmed,,, Awwad.. Test&quot;</p>
<pre><code>File &quot;path/to/API.py&quot;, line 39, in predict_text
    vector = selector.transform(clean_text)
  File &quot;/usr/lib/python3/dist-packages/scipy/sparse/base.py&quot;, line 687, in __getattr__
    raise AttributeError(attr + &quot; not found&quot;)
AttributeError: transform not found
[30/Jun/2022 00:11:23] &quot;POST /api/spamurai HTTP/1.1&quot; 500 103644
</code></pre>
<p>This my model:</p>
<pre><code>#convert a collection of text to amatrix of tokens (Bag of words)
from sklearn.feature_extraction.text import CountVectorizer
from joblib import dump
import pickle
#process_text previously defined function to preprocess text in model
msg_vector= CountVectorizer(analyzer=process_text)
message_bow = msg_vector.fit_transform(df['text'])
pickle.dump(message_bow, open(&quot;vector_text.pkl&quot;, &quot;wb&quot;))
dump(MultinomialNB,'spam_model_text.joblib')
</code></pre>
<blockquote>
<p>I was using joblib in both dumping but i got many errors with countervectorizer and joblib so i am trying pickle and joblib</p>
</blockquote>
<p>In my API.py file I load my text vector and MultinomialNB file as follows:</p>
<pre><code>from joblib import load
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import CountVectorizer

MultinomialNB_file = os.path.join(BASE_DIR, 'tutorials/data', 'spam_model_text.joblib')
CountVectorize_file = os.path.join(BASE_DIR, 'tutorials/data','vector_text.pkl')

txt_model = load(MultinomialNB_file)
selector = pickle.load(open(CountVectorize_file, &quot;rb&quot;))

# # pre processing email text to be used in ML Model without affecting accuracy of model
def process_text(text):
     #processing_code
      return clean_text

# # function uses trainig utilities used in TEXT ML Model
def predict_text(text):
# call pre processing email text in here
    # text is my input 
    # text:  Ahmed,,, Awwad.. Test
    clean_text = process_text(text)
    # clean_TXT: ['Ahmed', 'Awwad', 'Test'] 
    #clean_txt is my input after preprocessing
    vector = selector.transform(clean_text)
    result = txt_model.predict(vector)
</code></pre>
<p>My thoughts may help : 'vector_text.pkl' is not probably readable as countvectorizer dumped file</p>
",35,0,0,5,python;python-3.x;django;machine-learning;scikit-learn,2022-06-30 05:56:41,2022-06-30 05:56:41,2022-06-30 05:56:41,trying to load my spam text detection machine learning model in api using django framework  my error when sending request with text  ahmed    awwad   test  this my model  i was using joblib in both dumping but i got many errors with countervectorizer and joblib so i am trying pickle and joblib in my api py file i load my text vector and multinomialnb file as follows  my thoughts may help    vector_text pkl  is not probably readable as countvectorizer dumped file,attributeerror  transform not found in countvectorizer   using sklearn
195,195,18906734,72807512,Machine Learning - How to compare two models?,"<p>I am working on loan eligibility supervised project. I used logistic regression and a support vector machine as two models. For the logistic regression, accuracy is 0.84 and the loss function is 0.45. For SVM accuracy is 0.80 and loss function is 0.33. Which of these algorithms performs better? How do we compare two models (by the accuracy or by loss function)?</p>
",25,1,0,3,machine-learning;svm;logistic-regression,2022-06-30 02:01:49,2022-06-30 02:01:49,2022-06-30 03:34:43,i am working on loan eligibility supervised project  i used logistic regression and a support vector machine as two models  for the logistic regression  accuracy is   and the loss function is    for svm accuracy is   and loss function is    which of these algorithms performs better  how do we compare two models  by the accuracy or by loss function  ,machine learning   how to compare two models 
196,196,1999833,72797783,Machine Learning to predict time-series multi-class signal changes,"<p>I would like to predict the switching behavior of time-dependent signals. Currently the signal has 3 states (1, 2, 3), but it could be that this will change in the future. For the moment, however, it is absolutely okay to assume three states.</p>
<p>I can make the following assumptions about these states (see picture):</p>
<ol>
<li>the signals repeat periodically, possibly with variations concerning the time of day.</li>
<li>the duration of state 2 is always constant and relatively short for all signals.</li>
<li>the duration of states 1 and 3 are also constant, but vary for the different signals.</li>
<li>the switching sequence is always the same: 1 --&gt; 2 --&gt; 3 --&gt; 2 --&gt; 1 --&gt; [...]</li>
<li>there is a constant but unknown time reference between the different signals.</li>
<li>There is no constant time reference between my observations for the different signals. They are simply measured one after the other, but always at different times.</li>
<li>I am able to rebuild my model periodically after i obtained more samples.</li>
</ol>
<p><a href=""https://i.stack.imgur.com/0EMVo.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0EMVo.png"" alt=""Sketch of signal model and observations"" /></a></p>
<p>I have the following problems:</p>
<ol>
<li>I can only observe one signal at a time.</li>
<li>I can only observe the signals at different times.</li>
<li>I cannot trigger my measurement with the state transition. That means, when I measure, I am always &quot;in the middle&quot; of a state. Therefore I don't know when this state has started and also not exactly when this state will end.</li>
<li>I cannot observe a certain signal for a long duration. So, i am not able to observe a complete period.</li>
<li>My samples (observations) are widespread in time.</li>
<li>I would like to get a prediction either for the state change or the current state for the current time. It is likely to happen that i will never have measured my signals for that requested time.</li>
</ol>
<p>So far I have tested the TimeSeriesPredictor from the ML.NET Toolbox, as it seemed suitable to me. However, in my opinion, this algorithm requires that you always pass only the data of one signal. This means that assumption 5 is not included in the prediction, which is probably suboptimal. Also, in this case I had problems with the prediction not changing, which should actually happen time-dependently when I query multiple predictions. This behavior led me to believe that only the order of the values entered the model, but not the associated timestamp. If I have understood everything correctly, then exactly this timestamp is my most important &quot;feature&quot;...
So far, i did not do any tests on Regression-based approaches, e.g. FastTree, since my data is not linear, but keeps changing states. Maybe this assumption is not valid and regression-based methods could also be suitable?</p>
<p>I also don't know if a multiclassifier is required, because I had understood that the TimeSeriesPredictor would also be suitable for this, since it works with the single data type. Whether the prediction is 1.3 or exactly 1.0 would be fine for me.</p>
<p><strong>To sum it up:</strong>
I am looking for a algorithm which is able to recognize the switching patterns based on lose and widespread samples. It would be okay to define boundaries, e.g. state duration 3 of signal 1 will never last longer than 30s or state duration 1 of signal 3 will never last longer 60s.
Then, after the algorithm has obtained an approximate model of the switching behaviour, i would like to request a prediction of a certain signal state for a certain time.</p>
<p>Which methods can I use to get the best prediction, preferably using the ML.NET toolbox or based on matlab?</p>
",49,1,-1,5,matlab;machine-learning;time-series;prediction;ml.net,2022-06-29 13:29:52,2022-06-29 13:29:52,2022-06-30 01:32:48,i would like to predict the switching behavior of time dependent signals  currently the signal has  states         but it could be that this will change in the future  for the moment  however  it is absolutely okay to assume three states  i can make the following assumptions about these states  see picture    i have the following problems  i also don t know if a multiclassifier is required  because i had understood that the timeseriespredictor would also be suitable for this  since it works with the single data type  whether the prediction is   or exactly   would be fine for me  which methods can i use to get the best prediction  preferably using the ml net toolbox or based on matlab ,machine learning to predict time series multi class signal changes
197,197,2068931,62359175,Pytorch says that CUDA is not available,"<p>I'm trying to run Pytorch on a laptop that I have. It's an older model but it does have an Nvidia graphics card. I realize it is probably not going to be sufficient for real machine learning but I am trying to do it so I can learn the process of getting CUDA installed.</p>

<p>I have followed the steps on the <a href=""https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html"" rel=""noreferrer"">installation guide</a> for Ubuntu 18.04 (my specific distribution is Xubuntu).</p>

<p>My graphics card is a GeForce 845M, verified by <code>lspci | grep nvidia</code>:</p>

<pre><code>01:00.0 3D controller: NVIDIA Corporation GM107M [GeForce 845M] (rev a2)
01:00.1 Audio device: NVIDIA Corporation Device 0fbc (rev a1)
</code></pre>

<p>I also have gcc 7.5 installed, verified by <code>gcc --version</code></p>

<pre><code>gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
Copyright (C) 2017 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
</code></pre>

<p>And I have the correct headers installed, verified by trying to install them with <code>sudo apt-get install linux-headers-$(uname -r)</code>:</p>

<pre><code>Reading package lists... Done
Building dependency tree       
Reading state information... Done
linux-headers-4.15.0-106-generic is already the newest version (4.15.0-106.107).
</code></pre>

<p>I then followed the installation instructions using a local .deb for version 10.1.</p>

<p>Npw, when I run <code>nvidia-smi</code>, I get:</p>

<pre><code>+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce 845M        On   | 00000000:01:00.0 Off |                  N/A |
| N/A   40C    P0    N/A /  N/A |     88MiB /  2004MiB |      1%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0       982      G   /usr/lib/xorg/Xorg                            87MiB |
+-----------------------------------------------------------------------------+
</code></pre>

<p>and I run <code>nvcc -V</code> I get:</p>

<pre><code>nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
</code></pre>

<p>I then performed the post-installation instructions from <a href=""https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#mandatory-post"" rel=""noreferrer"">section 6.1</a>, and so as a result, <code>echo $PATH</code> looks like this:</p>

<pre><code>/home/isaek/anaconda3/envs/stylegan2_pytorch/bin:/home/isaek/anaconda3/bin:/home/isaek/anaconda3/condabin:/usr/local/cuda-10.1/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
</code></pre>

<p><code>echo $LD_LIBRARY_PATH</code> looks like this:</p>

<pre><code>/usr/local/cuda-10.1/lib64
</code></pre>

<p>and my <code>/etc/udev/rules.d/40-vm-hotadd.rules</code> file looks like this:</p>

<pre><code># On Hyper-V and Xen Virtual Machines we want to add memory and cpus as soon as they appear
ATTR{[dmi/id]sys_vendor}==""Microsoft Corporation"", ATTR{[dmi/id]product_name}==""Virtual Machine"", GOTO=""vm_hotadd_apply""
ATTR{[dmi/id]sys_vendor}==""Xen"", GOTO=""vm_hotadd_apply""
GOTO=""vm_hotadd_end""

LABEL=""vm_hotadd_apply""

# Memory hotadd request

# CPU hotadd request
SUBSYSTEM==""cpu"", ACTION==""add"", DEVPATH==""/devices/system/cpu/cpu[0-9]*"", TEST==""online"", ATTR{online}=""1""

LABEL=""vm_hotadd_end""
</code></pre>

<p>After all of this, I even compiled and ran the samples. <code>./deviceQuery</code> returns:</p>

<pre><code>./deviceQuery Starting...

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 1 CUDA Capable device(s)

Device 0: ""GeForce 845M""
  CUDA Driver Version / Runtime Version          10.1 / 10.1
  CUDA Capability Major/Minor version number:    5.0
  Total amount of global memory:                 2004 MBytes (2101870592 bytes)
  ( 4) Multiprocessors, (128) CUDA Cores/MP:     512 CUDA Cores
  GPU Max Clock rate:                            863 MHz (0.86 GHz)
  Memory Clock rate:                             1001 Mhz
  Memory Bus Width:                              64-bit
  L2 Cache Size:                                 1048576 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)
  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)
  Run time limit on kernels:                     Yes
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Disabled
  Device supports Unified Addressing (UVA):      Yes
  Device supports Compute Preemption:            No
  Supports Cooperative Kernel Launch:            No
  Supports MultiDevice Co-op Kernel Launch:      No
  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0
  Compute Mode:
     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.1, CUDA Runtime Version = 10.1, NumDevs = 1
Result = PASS
</code></pre>

<p>and <code>./bandwidthTest</code> returns:</p>

<pre><code>[CUDA Bandwidth Test] - Starting...
Running on...

 Device 0: GeForce 845M
 Quick Mode

 Host to Device Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)    Bandwidth(GB/s)
   32000000         11.7

 Device to Host Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)    Bandwidth(GB/s)
   32000000         11.8

 Device to Device Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)    Bandwidth(GB/s)
   32000000         14.5

Result = PASS

NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.
</code></pre>

<p>But after all of this, this Python snippet (in a conda environment with all dependencies installed):</p>

<pre><code>import torch
torch.cuda.is_available()
</code></pre>

<p>returns <code>False</code></p>

<p>Does anybody have any idea about how to resolve this? I've tried to add <code>/usr/local/cuda-10.1/bin</code> to <code>etc/environment</code> like this:</p>

<pre><code>PATH=""/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games""
PATH=$PATH:/usr/local/cuda-10.1/bin
</code></pre>

<p>And restarting the terminal, but that didn't fix it. I really don't know what else to try.</p>

<h1>EDIT - Results of collect_env for @kHarshit</h1>

<pre><code>Collecting environment information...
PyTorch version: 1.5.0
Is debug build: No
CUDA used to build PyTorch: 10.2

OS: Ubuntu 18.04.4 LTS
GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CMake version: Could not collect

Python version: 3.6
Is CUDA available: No
CUDA runtime version: 10.1.243
GPU models and configuration: GPU 0: GeForce 845M
Nvidia driver version: 418.87.00
cuDNN version: Could not collect

Versions of relevant libraries:
[pip] numpy==1.18.5
[pip] pytorch-ranger==0.1.1
[pip] stylegan2-pytorch==0.12.0
[pip] torch==1.5.0
[pip] torch-optimizer==0.0.1a12
[pip] torchvision==0.6.0
[pip] vector-quantize-pytorch==0.0.2
[conda] numpy                     1.18.5                   pypi_0    pypi
[conda] pytorch-ranger            0.1.1                    pypi_0    pypi
[conda] stylegan2-pytorch         0.12.0                   pypi_0    pypi
[conda] torch                     1.5.0                    pypi_0    pypi
[conda] torch-optimizer           0.0.1a12                 pypi_0    pypi
[conda] torchvision               0.6.0                    pypi_0    pypi
[conda] vector-quantize-pytorch   0.0.2                    pypi_0    pypi
</code></pre>
",113955,4,45,3,linux;pytorch;ubuntu-18.04,2020-06-13 17:06:19,2020-06-13 17:06:19,2022-06-30 01:25:16,i m trying to run pytorch on a laptop that i have  it s an older model but it does have an nvidia graphics card  i realize it is probably not going to be sufficient for real machine learning but i am trying to do it so i can learn the process of getting cuda installed  i have followed the steps on the  for ubuntu    my specific distribution is xubuntu   my graphics card is a geforce m  verified by lspci   grep nvidia  i also have gcc   installed  verified by gcc   version and i have the correct headers installed  verified by trying to install them with sudo apt get install linux headers   uname  r   i then followed the installation instructions using a local  deb for version    npw  when i run nvidia smi  i get  and i run nvcc  v i get  i then performed the post installation instructions from   and so as a result  echo  path looks like this  echo  ld_library_path looks like this  and my  etc udev rules d  vm hotadd rules file looks like this  after all of this  i even compiled and ran the samples    devicequery returns  and   bandwidthtest returns  but after all of this  this python snippet  in a conda environment with all dependencies installed   returns false does anybody have any idea about how to resolve this  i ve tried to add  usr local cuda   bin to etc environment like this  and restarting the terminal  but that didn t fix it  i really don t know what else to try ,pytorch says that cuda is not available
198,198,15445155,72806504,Multi-input Model,"<p>I'm trying to implement a machine learning model (variational autoencoder) where the architecture of the model is</p>
<pre><code>        start_filter_num = 32
        kernel_size = 3
        latent_dim = 16

        x = tf.keras.Input(shape=(width,1))

        conv_seq1 = conv_block_seq_res(x, start_filter_num, kernel_size, 1, &quot;conv_seq1&quot;)
        pool1 = tf.keras.layers.MaxPooling1D(name=&quot;pool1&quot;)(conv_seq1)

        conv_seq2 = conv_block_seq_res(pool1, int(start_filter_num*1.5), kernel_size, 1, &quot;conv_seq2&quot;)
        pool2 = tf.keras.layers.MaxPooling1D(name=&quot;pool2&quot;)(conv_seq2)

        conv_seq3 = conv_block_seq_res(pool2, start_filter_num*3, kernel_size, 1, &quot;conv_seq3&quot;)
        pool3 = tf.keras.layers.MaxPooling1D(name=&quot;pool3&quot;)(conv_seq3)

        conv_seq4 = conv_block_seq_res(pool3, int(start_filter_num*4.5), kernel_size, 1, &quot;conv_seq4&quot;)
        pool4 = tf.keras.layers.MaxPooling1D(name=&quot;pool4&quot;)(conv_seq4)

        conv_seq5 = conv_block_seq_res(pool4, start_filter_num*6, kernel_size, 1, &quot;conv_seq5&quot;)
        pool5 = tf.keras.layers.MaxPooling1D(name=&quot;pool5&quot;)(conv_seq5)

        conv_seq6 = conv_block_seq_res(pool5, int(start_filter_num*7.5), kernel_size, 1, &quot;conv_seq6&quot;, In=False)
        pool6 = tf.keras.layers.MaxPooling1D(name=&quot;pool6&quot;)(conv_seq6)

        conv_seq7 = conv_block_seq_res(pool6, start_filter_num*9, kernel_size, 1, &quot;conv_seq7&quot;, In=False)

        flatten1 = tf.keras.layers.Flatten()(conv_seq7)

        z_mu = tf.keras.layers.Dense(latent_dim, name=&quot;z_mu&quot;)(flatten1)
        z_log_var = tf.keras.layers.Dense(latent_dim, name=&quot;z_log_var&quot;)(flatten1)

        ###############################################################################
        # normalize log variance to std dev
        z_sigma = tf.keras.layers.Lambda(lambda t: K.exp(.5*t), name=&quot;z_sigma&quot;)(z_log_var)
        eps = tf.keras.Input(tensor=K.random_normal(shape=(K.shape(x)[0], latent_dim)), name=&quot;eps&quot;)

        z_eps = tf.keras.layers.Multiply(name=&quot;z_eps&quot;)([z_sigma, eps])
        z = tf.keras.layers.Add(name=&quot;z&quot;)([z_mu, z_eps])

        #latent_conv = tf.keras.layers.Dense(width//64, name=&quot;latent_conv&quot;)(z)
        reshape1 = tf.keras.layers.Reshape([width//64,1], name=&quot;reshape1&quot;)(z)

        ###############################################################################
        #New for conditional VAE
        dconv_seq4 = conv_block_seq_res(reshape1, start_filter_num*9, kernel_size, 1, &quot;dconv_seq4&quot;, In=False)
        dconc5 = tf.keras.layers.concatenate([dconv_seq4, conv_seq7], name=&quot;dconc5&quot;)
        deconv1 = Conv1DTranspose(dconc5, start_filter_num*2, kernel_size=3, strides=2, padding='same')

        dconv_seq5 = conv_block_seq_res(deconv1, int(start_filter_num*7.5), kernel_size, 1, &quot;dconv_seq5&quot;, In=False)
        dconc7 = tf.keras.layers.concatenate([dconv_seq5, conv_seq6], name=&quot;dconc7&quot;)
        deconv2 = Conv1DTranspose(dconc7, start_filter_num, kernel_size=3, strides=2, padding='same')

        dconv_seq6 = conv_block_seq_res(deconv2, start_filter_num*6, kernel_size, 1, &quot;dconv_seq6&quot;, In=False)
        dconc9 = tf.keras.layers.concatenate([dconv_seq6, conv_seq5], name=&quot;dconc9&quot;)
        deconv3 = Conv1DTranspose(dconc9, start_filter_num, kernel_size=3, strides=2, padding='same')

        dconv_seq7 = conv_block_seq_res(deconv3, int(start_filter_num*4.5), kernel_size, 1, &quot;dconv_seq7&quot;, In=False)
        dconc11 = tf.keras.layers.concatenate([dconv_seq7, conv_seq4], name=&quot;dconc11&quot;)
        deconv4 = Conv1DTranspose(dconc11, start_filter_num, kernel_size=3, strides=2, padding='same')

        dconv_seq8 = conv_block_seq_res(deconv4, start_filter_num*3, kernel_size, 1, &quot;dconv_seq8&quot;, In=False)
        dconc13 = tf.keras.layers.concatenate([dconv_seq8, conv_seq3], name=&quot;dconc13&quot;)
        deconv5 = Conv1DTranspose(dconc13, start_filter_num, kernel_size=3, strides=2, padding='same')

        dconv_seq9 = conv_block_seq_res(deconv5, int(start_filter_num*1.5), kernel_size, 1, &quot;dconv_seq9&quot;, In=False)
        dconc15 = tf.keras.layers.concatenate([dconv_seq9, conv_seq2], name=&quot;dconc15&quot;)
        deconv6 = Conv1DTranspose(dconc15, start_filter_num, kernel_size=3, strides=2, padding='same')

        dconv_seq10 = conv_block_seq_res(deconv6, start_filter_num, kernel_size, 1, &quot;dconv_seq10&quot;, In=False)
        dconc17 = tf.keras.layers.concatenate([dconv_seq10, conv_seq1], name=&quot;dconc17&quot;)

        x_pred = tf.keras.layers.Conv1D(1, 3, padding=&quot;same&quot;, activation=&quot;relu&quot;, name=&quot;x_pred&quot;)(dconc17)

        model = tf.keras.Model(inputs=[x, eps], outputs=x_pred)
        model.summary()
</code></pre>
<p>when I try to fit the model use this</p>
<pre><code>history = model.fit((x_train-main_mean)/main_std, (y_train-app_mean)/app_std, shuffle=True, validation_split=nilm[&quot;training&quot;][&quot;validation_split&quot;],
                            epochs=epochs, batch_size=batch_size, callbacks=list_callbacks, verbose=1, initial_epoch=0)
</code></pre>
<p>which of course gave me this error</p>
<p><strong>ValueError: Layer &quot;model&quot; expects 2 input(s), but it received 1 input tensors. Inputs received: [&lt;tf.Tensor 'IteratorGetNext:0' shape=(None, 1024, 1) dtype=float32&gt;]</strong></p>
<p>I tried this</p>
<pre><code>        latent_dim = 16
        eps = tf.keras.Input(tensor = K.random_normal(shape=(K.shape(x_train)[0], latent_dim)))
        history = model.fit([(x_train-main_mean)/main_std, eps], (y_train-app_mean)/app_std, shuffle=True,# validation_split=nilm[&quot;training&quot;][&quot;validation_split&quot;],
                            epochs=epochs, batch_size=batch_size, callbacks=list_callbacks, verbose=1, initial_epoch=0)
</code></pre>
<p>but it gives me an error</p>
<p><strong>TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='Placeholder:0', description=&quot;created by layer 'tf.cast_4'&quot;), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as <code>tf.cond</code>, <code>tf.function</code>, gradient tapes, or <code>tf.map_fn</code>. Keras Functional model construction only supports TF API calls that <em>do</em> support dispatching, such as <code>tf.math.add</code> or <code>tf.reshape</code>. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer <code>call</code> and calling that layer on this symbolic input/output.</strong></p>
<p>I don't know how to solve it. I appreciate the help
thanks in advance</p>
",30,0,0,4,tensorflow;keras;autoencoder;multiple-input,2022-06-30 00:27:47,2022-06-30 00:27:47,2022-06-30 00:27:47,i m trying to implement a machine learning model  variational autoencoder  where the architecture of the model is when i try to fit the model use this which of course gave me this error valueerror  layer  model  expects  input s   but it received  input tensors  inputs received    lt tf tensor  iteratorgetnext   shape  none      dtype float gt   i tried this but it gives me an error typeerror  you are passing kerastensor type_spec tensorspec shape     dtype tf float  name none   name  placeholder    description  created by layer  tf cast_     an intermediate keras symbolic input output  to a tf api that does not allow registering custom dispatchers  such as tf cond  tf function  gradient tapes  or tf map_fn  keras functional model construction only supports tf api calls that do support dispatching  such as tf math add or tf reshape  other apis cannot be called directly on symbolic kerasinputs outputs  you can work around this limitation by putting the operation in a custom keras layer call and calling that layer on this symbolic input output ,multi input model
199,199,17156297,72598952,Azure Machine Learning REST API request limits,"<p>My application sends requests to Azure Machine Learning REST API in order to invoke a batch endpoint and start scoring jobs as described <a href=""https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-batch-with-rest#invoke-the-batch-endpoint-to-start-a-batch-scoring-job"" rel=""nofollow noreferrer"">here</a>. It works well for small number of requests, but if the app sends many concurrent requests the REST API sometimes responds with status code 429 &quot;TooManyRequests&quot; and message &quot;Received too many requests in a short amount of time. Retry again after 1 seconds.&quot;. For example, it happened after sending 77 requests at once.</p>
<p>The message is pretty clear and the best solution I can think about is to throttle outgoing requests. That is making sure the app doesn't exceed limits when it sends concurrent requests. But the problem is I don't know what are the request limits for Azure Machine Learning REST API. Looking through the Microsoft documentation I could only find <a href=""https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-quotas#azure-machine-learning-managed-online-endpoints"" rel=""nofollow noreferrer"">this article</a> which provides limits for Managed online endpoints whereas I'm looking for Batch endpoints.</p>
<p>I would really appreciate if someone helped me to find the Azure ML REST API request limits or suggested a better solution. Thanks.</p>
<p><strong>UPDATE 20 Jun 2022</strong>:
I couldn't find out how many concurrent requests are allowed by Azure Machine Learning batch endpoints. So I ended with a limit of 10 outgoing requests which solved the &quot;TooManyRequests&quot; problem. In order to throttle requests I used SemaphoreSlim as described <a href=""https://codeburst.io/throttling-concurrent-outgoing-http-requests-in-net-core-404b5acd987b"" rel=""nofollow noreferrer"">here</a>.</p>
",80,2,0,4,azure;limit;azure-machine-learning-service;azure-rest-api,2022-06-13 12:44:37,2022-06-13 12:44:37,2022-06-29 22:32:27,my application sends requests to azure machine learning rest api in order to invoke a batch endpoint and start scoring jobs as described   it works well for small number of requests  but if the app sends many concurrent requests the rest api sometimes responds with status code   toomanyrequests  and message  received too many requests in a short amount of time  retry again after  seconds    for example  it happened after sending  requests at once  the message is pretty clear and the best solution i can think about is to throttle outgoing requests  that is making sure the app doesn t exceed limits when it sends concurrent requests  but the problem is i don t know what are the request limits for azure machine learning rest api  looking through the microsoft documentation i could only find  which provides limits for managed online endpoints whereas i m looking for batch endpoints  i would really appreciate if someone helped me to find the azure ml rest api request limits or suggested a better solution  thanks ,azure machine learning rest api request limits
200,200,1901071,72698110,Python translate matplotlib to a plotnine chart,"<p>I am currently working through the book <a href=""https://rads.stackoverflow.com/amzn/click/com/1492032646"" rel=""nofollow noreferrer"" rel=""nofollow noreferrer"">Hands On Machine Learning</a> and am trying to replicate a visualization where we plot the lat and lon co-ordinates on a scatter plot of San Diego. I have taken the plot code from the book which uses the code below (matplotlib method). I would like to replicate the same visualization using <a href=""https://plotnine.readthedocs.io/en/stable/index.html"" rel=""nofollow noreferrer"">plotnine</a>. Could someone help me with the translation.</p>
<h3>matplotlib method</h3>
<pre><code># DATA INGEST -------------------------------------------------------------    
# Import the file from github
url = &quot;https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.csv&quot; # Make sure the url is the raw version of the file on GitHub
download = requests.get(url).content

# Reading the downloaded content and turning it into a pandas dataframe
housing = pd.read_csv(io.StringIO(download.decode('utf-8')))

# Then plot
import matplotlib.pyplot as plt

# The size is now related to population divided by 100
# the colour is related to the median house value
housing.plot(kind=&quot;scatter&quot;, x=&quot;longitude&quot;, y=&quot;latitude&quot;, alpha=0.4, 
              s=housing[&quot;population&quot;]/100, label=&quot;population&quot;, figsize=(10,7),
              c=&quot;median_house_value&quot;, cmap=plt.get_cmap(&quot;jet&quot;), colorbar=True)
plt.legend()
plt.show()

</code></pre>
<h3>plotnine method</h3>
<pre><code>from plotnine import ggplot, geom_point, aes, stat_smooth, scale_color_cmap

# Lets try the same thing in ggplot
(ggplot(housing, aes('longitude', 'latitude', size = &quot;population&quot;, color = &quot;median_house_value&quot;))
 + geom_point(alpha = 0.1)
 + scale_color_cmap(name=&quot;jet&quot;))
 
</code></pre>
",38,1,1,4,python;matplotlib;ggplot2;plotnine,2022-06-21 14:40:43,2022-06-21 14:40:43,2022-06-29 22:17:33,i am currently working through the book  and am trying to replicate a visualization where we plot the lat and lon co ordinates on a scatter plot of san diego  i have taken the plot code from the book which uses the code below  matplotlib method   i would like to replicate the same visualization using   could someone help me with the translation ,python translate matplotlib to a plotnine chart
201,201,15181029,72804986,SnapML model issue on Lens Studio,"<p>I built a custom model for classifying images of cars using Tensorflow and Keras, to use it for building a Snap lens powered by machine learning. Lens Studio only accepts quantized models; the model had to go through the quantization process using the TFLite module.</p>
<p>However, the problem is that the model passed into Lens Studio is unable to function properly. It only displays classification results for the first time after its initiation;  then the results (and even the probability numbers behind classification) remain static despite image/video changes.</p>
<p>Any tips on how to solve this issue would be appreciated. The configurations for input image setups remain identical as the provided template by Snap.</p>
",12,0,0,5,tensorflow;keras;quantization;snapchat;tflite,2022-06-29 22:07:02,2022-06-29 22:07:02,2022-06-29 22:07:02,i built a custom model for classifying images of cars using tensorflow and keras  to use it for building a snap lens powered by machine learning  lens studio only accepts quantized models  the model had to go through the quantization process using the tflite module  however  the problem is that the model passed into lens studio is unable to function properly  it only displays classification results for the first time after its initiation   then the results  and even the probability numbers behind classification  remain static despite image video changes  any tips on how to solve this issue would be appreciated  the configurations for input image setups remain identical as the provided template by snap ,snapml model issue on lens studio
202,202,15493107,72767023,Fullscreen mode not working in D3D12 raytracing samples,"<p>Presently I'm learning the basics of real-time raytracing with the DXR API in DirectX 12 Ultimate. I'm studying the D3D12 raytracing samples on the official GitHub and am using an i9/Intel Iris Xe/RTX3070 laptop and building the programs in VS2022.</p>
<p>Since the samples were written for Windows 10 and I'm using a hybrid graphics PC, a Debug build will run in Windows 11 after adding <code>D3D12_MESSAGE_ID_RESOURCE_BARRIER_MISMATCHING_COMMAND_LIST_TYPE</code> to <strong>D3D12_INFO_QUEUE_FILTER</strong> during device creation (see <a href=""https://stackoverflow.com/questions/69805245/directx-12-application-is-crashing-in-windows-11"">DirectX 12 application is crashing in Windows 11</a>). The only trouble is that none of the sample programs change to fullscreen (i.e. borderless windowed) mode when pressing the Alt+Enter key combination. The programs always stay in windowed mode.</p>
<p>This hasn't worried me so far, because I've been copying the raytracing code over to a template (based on DirectX Tool Kit for Windows desktop) where fullscreen toggling works properly. In this way, I was able to run the <em>HelloWorld</em> and <em>SimpleLighting</em> samples successfully in both windowed mode and fullscreen (2560x1440 monitor resolution).</p>
<p>However, this hasn't been so successful for the <em>ProceduralGeometry</em> sample, which introduces intersection shaders. Once again, the original sample program renders the scene properly, but only in a bordered window. But when the code is reproduced in the template where I can toggle to fullscreen, the raytraced scene does not render properly.</p>
<p>In the scene, the triangle geometry used for the ground plane of the scene renders ok, but a translucent bounding box around the fractal pyramid is visible, and all other procedural geometry also appears translucent. Every couple of seconds, the bounding box for the metaballs also appears briefly, then vanishes.</p>
<p>I was able to determine that by freezing the scene, the reason for the translucency was that the following frames were being presented in sequence:</p>
<ul>
<li>triangle ground plane quad only</li>
<li>floor geometry plus opaque fractal pyramid bounding box</li>
<li>all of the above plus opaque metaball bounding box</li>
<li>completed scene with opaque geometry and no bounding boxes</li>
</ul>
<p>At the native framerate (165Hz on my machine), this results in both the procedural geometry and bounding boxes always being visible, but 'see-through' due to all the partially complete frames being presented to the display. This happens in both windowed and fullscreen modes, but it's worse in fullscreen, because the scene gets affected by random image corruption not seen in windowed mode.</p>
<p>I've been grappling with this issue for a few days and can't work out the problem. The only changes I've made to the sample program are the Windows 11 fix, and using a template for proper fullscreen rendering, which the original sample ignores or doesn't implement properly.</p>
<p>Hopefully someone can shed light on this perplexing issue!</p>
",46,1,1,5,visual-studio-2022;raytracing;windows-11;directx-12;direct3d12,2022-06-27 10:03:11,2022-06-27 10:03:11,2022-06-29 21:47:04,presently i m learning the basics of real time raytracing with the dxr api in directx  ultimate  i m studying the dd raytracing samples on the official github and am using an i intel iris xe rtx laptop and building the programs in vs  since the samples were written for windows  and i m using a hybrid graphics pc  a debug build will run in windows  after adding dd_message_id_resource_barrier_mismatching_command_list_type to dd_info_queue_filter during device creation  see    the only trouble is that none of the sample programs change to fullscreen  i e  borderless windowed  mode when pressing the alt enter key combination  the programs always stay in windowed mode  this hasn t worried me so far  because i ve been copying the raytracing code over to a template  based on directx tool kit for windows desktop  where fullscreen toggling works properly  in this way  i was able to run the helloworld and simplelighting samples successfully in both windowed mode and fullscreen  x monitor resolution   however  this hasn t been so successful for the proceduralgeometry sample  which introduces intersection shaders  once again  the original sample program renders the scene properly  but only in a bordered window  but when the code is reproduced in the template where i can toggle to fullscreen  the raytraced scene does not render properly  in the scene  the triangle geometry used for the ground plane of the scene renders ok  but a translucent bounding box around the fractal pyramid is visible  and all other procedural geometry also appears translucent  every couple of seconds  the bounding box for the metaballs also appears briefly  then vanishes  i was able to determine that by freezing the scene  the reason for the translucency was that the following frames were being presented in sequence  at the native framerate  hz on my machine   this results in both the procedural geometry and bounding boxes always being visible  but  see through  due to all the partially complete frames being presented to the display  this happens in both windowed and fullscreen modes  but it s worse in fullscreen  because the scene gets affected by random image corruption not seen in windowed mode  i ve been grappling with this issue for a few days and can t work out the problem  the only changes i ve made to the sample program are the windows  fix  and using a template for proper fullscreen rendering  which the original sample ignores or doesn t implement properly  hopefully someone can shed light on this perplexing issue ,fullscreen mode not working in dd raytracing samples
203,203,19281672,72804036,Compositional data preprocessing for machine learning,"<p>I have this compositional data from a metagenomics project, in which each row is a sample (60 rows) and each column is a taxonomical Genus (473 columns):
<a href=""https://i.stack.imgur.com/Py6wo.png"" rel=""nofollow noreferrer"">Compositional data (extract)</a></p>
<p>In addition, I transformed these data in R with the &quot;clr&quot; transformation:</p>
<pre><code>phy_gen_clr &lt;- microbiome::transform(phy_gen_comp, 'clr')
</code></pre>
<p>After which I obtained the following data points, which are relative abundances:
<a href=""https://i.stack.imgur.com/84FLk.png"" rel=""nofollow noreferrer"">clr transformed compositional data (extract)</a></p>
<p>Given this data, I want to create a Random Forest model, which should be able to predict, given these transformed abundances, which group each sample belongs to. I am firstly doing this without partitioning the data in training/test sets. This is the code I have developed in Python, using a pipeline:</p>
<pre><code>import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV,KFold
from sklearn.metrics import make_scorer
from sklearn.pipeline import make_pipeline
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, balanced_accuracy_score
from sklearn.feature_selection import SelectFromModel
from sklearn.linear_model import LogisticRegression
import warnings

data = pd.read_csv('clr_abundances.csv', decimal=&quot;.&quot;,delimiter=&quot;;&quot;)
X = data.values[ :, 1:-2].astype(np.float64)
y = (data.values[ :, -1 ])

print(X.shape)

warnings.filterwarnings(&quot;ignore&quot;, category=Warning)
pipeline_rf = Pipeline([(&quot;sel&quot;,SelectFromModel(LogisticRegression(penalty='l1',solver='liblinear'))),(&quot;RF&quot;,RandomForestClassifier())])
param_grid_rf = {&quot;sel__estimator__C&quot;:np.arange(0.001,1.1,0.1).astype(np.float),
         &quot;RF__n_estimators&quot;:np.arange(1,102,10).astype(np.int),
         &quot;RF__criterion&quot;:[&quot;gini&quot;,&quot;entropy&quot;,&quot;log_loss&quot;],
         &quot;RF__max_depth&quot;:[2,3,4],
         &quot;RF__max_features&quot;:[1,20]}
skfold_rf=KFold(n_splits=X.shape[0])
gridcv_rf=GridSearchCV(pipeline_rf,param_grid_rf,cv=skfold_rf)
result_rf=gridcv_rf.fit(X, y)
print(&quot;Best parameters:&quot;,gridcv_rf.best_params_)
print(&quot;Score:&quot;,gridcv_rf.score(X, y))
</code></pre>
<p>As you can see, I first import the data, then define X, which are all the data points, and y, which a list with the group each sample belongs to:</p>
<pre><code>['Group 2' 'Group 1' 'Group 2' 'Group 2' 'Group 2' 'Group 2' 'Group 1'
'Group 2' 'Group 1' 'Group 1' 'Group 1' 'Group 2' 'Group 1' 'Group 1'
'Group 2' 'Group 1' 'Group 2' 'Group 1' 'Group 2' 'Group 2' 'Group 1'
'Group 2' 'Group 1' 'Group 2' 'Group 2' 'Group 1' 'Group 1' 'Group 2'
'Group 2' 'Group 2' 'Group 2' 'Group 2' 'Group 2' 'Group 2' 'Group 1'
'Group 2' 'Group 2' 'Group 1' 'Group 1' 'Group 2' 'Group 1' 'Group 2'
'Group 1' 'Group 2' 'Group 1' 'Group 2' 'Group 1' 'Group 1' 'Group 1'
'Group 1' 'Group 1' 'Group 2' 'Group 1' 'Group 2' 'Group 2' 'Group 2'
'Group 1' 'Group 2' 'Group 1' 'Group 2']
</code></pre>
<p>After this, in a pipeline, I am performing first a LASSO feature selection, whose parameter &quot;C&quot; I am tuning in the &quot;param_grid_rf&quot; variable, after which I define the Random Forest Classifier, whose parameters I am also tuning in that variable. Following this, I want to perform a Leave One Out Cross Validation (LOOCV), which I am doing with &quot;KFold(<em>number of samples</em>)&quot;. Then, I search for the best hyperparameter values with &quot;GridSearchCV&quot;, and I fit this model with my clr-transformed abundances (X) and groups (y).</p>
<p>This code should return the best hyperparameter values and the score obtained from this model given these values.</p>
<p>The problem from this code is that it does not throw any errors, but <strong>it never stops executing</strong>. Is there something I should have done to avoid this?</p>
<p>Before the feature selection process (SelectFromModel), should I <strong>standardize</strong>/<strong>normalize</strong> the already clr-transformed data?</p>
<p>Thank you in advance.</p>
",16,0,0,5,python;machine-learning;scikit-learn;gridsearchcv;leave-one-out,2022-06-29 20:56:09,2022-06-29 20:56:09,2022-06-29 20:56:09,in addition  i transformed these data in r with the  clr  transformation  given this data  i want to create a random forest model  which should be able to predict  given these transformed abundances  which group each sample belongs to  i am firstly doing this without partitioning the data in training test sets  this is the code i have developed in python  using a pipeline  as you can see  i first import the data  then define x  which are all the data points  and y  which a list with the group each sample belongs to  after this  in a pipeline  i am performing first a lasso feature selection  whose parameter  c  i am tuning in the  param_grid_rf  variable  after which i define the random forest classifier  whose parameters i am also tuning in that variable  following this  i want to perform a leave one out cross validation  loocv   which i am doing with  kfold number of samples    then  i search for the best hyperparameter values with  gridsearchcv   and i fit this model with my clr transformed abundances  x  and groups  y   this code should return the best hyperparameter values and the score obtained from this model given these values  the problem from this code is that it does not throw any errors  but it never stops executing  is there something i should have done to avoid this  before the feature selection process  selectfrommodel   should i standardize normalize the already clr transformed data  thank you in advance ,compositional data preprocessing for machine learning
204,204,19436129,72798225,Remote Connection fails in setup of Python data-science client for SQL Server Machine Learning Services,"<p>I am trying to test the remote connection of a Python data-science client with SQL Server Machine Learning Services following this guide: <a href=""https://docs.microsoft.com/en-us/sql/machine-learning/python/setup-python-client-tools-sql"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/sql/machine-learning/python/setup-python-client-tools-sql</a> (section 6).
Running the following script</p>

<pre class=""lang-py prettyprint-override""><code>def send_this_func_to_sql():
    from revoscalepy import RxSqlServerData, rx_import
    from pandas.tools.plotting import scatter_matrix
    import matplotlib.pyplot as plt
    import io
    
    # remember the scope of the variables in this func are within our SQL Server Python Runtime
    connection_string = &quot;Driver=SQL Server;Server=localhost\instance02;Database=testmlsiris;Trusted_Connection=Yes;&quot;
    
    # specify a query and load into pandas dataframe df
    sql_query = RxSqlServerData(connection_string=connection_string, sql_query = &quot;select * from iris_data&quot;)
    df = rx_import(sql_query)
    
    scatter_matrix(df)
    
    # return bytestream of image created by scatter_matrix
    buf = io.BytesIO()
    plt.savefig(buf, format=&quot;png&quot;)
    buf.seek(0)
    
    return buf.getvalue()

new_db_name = &quot;testmlsiris&quot;
connection_string = &quot;driver={sql server};server=sqlrzs\instance02;database=%s;trusted_connection=yes;&quot; 

from revoscalepy import RxInSqlServer, rx_exec

# create a remote compute context with connection to SQL Server
sql_compute_context = RxInSqlServer(connection_string=connection_string%new_db_name)

# use rx_exec to send the function execution to SQL Server
image = rx_exec(send_this_func_to_sql, compute_context=sql_compute_context)[0]
</code></pre>
<p>yields the following error message returned by rx_exec (stored in the <em>image</em> variable)</p>
<pre class=""lang-py prettyprint-override""><code>connection_string: &quot;driver={sql server};server=sqlrzs\instance02;database=testmlsiris;trusted_connection=yes;&quot;
num_tasks: 1
execution_timeout_seconds: 0
wait: True
console_output: False
auto_cleanup: True
packages_to_load: []
description: &quot;sqlserver&quot;
version: &quot;1.0&quot;
XXX lineno: 2, opcode: 0
Traceback (most recent call last):
  File &quot;&lt;string&gt;&quot;, line 3, in &lt;module&gt;
  File &quot;E:\SQL\MSSQL15.INSTANCE02\PYTHON_SERVICES\lib\site-packages\revoscalepy\computecontext\RxInSqlServer.py&quot;, line 664, in rx_sql_satellite_pool_call
    exec(inputfile.read())
  File &quot;&lt;string&gt;&quot;, line 34, in &lt;module&gt;
  File &quot;E:\SQL\MSSQL15.INSTANCE02\PYTHON_SERVICES\lib\site-packages\revoscalepy\computecontext\RxInSqlServer.py&quot;, line 886, in rx_remote_call
    results = rx_resumeexecution(state_file = inputfile, patched_server_name=args[&quot;hostname&quot;])
  File &quot;E:\SQL\MSSQL15.INSTANCE02\PYTHON_SERVICES\lib\site-packages\revoscalepy\computecontext\RxInSqlServer.py&quot;, line 135, in rx_resumeexecution
    return _state[&quot;function&quot;](**_state[&quot;args&quot;])
  File &quot;C:\Users\username\sendtosql.py&quot;, line 2, in send_this_func_to_sql
SystemError: unknown opcode
====== sqlrzs ( process 0 ) has started run at 2022-06-29 13:47:04 W. Europe Daylight Time ======
{'local_state': {}, 'args': {}, 'function': &lt;function send_this_func_to_sql at 0x0000020F5810F1E0&gt;}
</code></pre>
<p>What is going wrong here? Line 2 in the script is just an import (which works when testing Python scripts on SQL Server directly). Any help is appreciated - thanks.</p>
",39,1,0,4,python;sql-server;azure-machine-learning-studio;microsoft-machine-learning-server,2022-06-29 14:02:20,2022-06-29 14:02:20,2022-06-29 20:07:17,yields the following error message returned by rx_exec  stored in the image variable  what is going wrong here  line  in the script is just an import  which works when testing python scripts on sql server directly   any help is appreciated   thanks ,remote connection fails in setup of python data science client for sql server machine learning services
205,205,17230057,72789246,Combine numerical and categorical data within the same feature for machine learning,"<p>I want to predict concept labels given to specific records, but have trouble handling the variation these records have, in particularly the presence (or absence) of values for specific features because of mixed data.</p>
<p>I have a dataset in which we want to cluster data and label these clusters for easier retrieval and eventually further detailed processing. We therefore group by the parameter label provided which is a short description of the concept, but with a large variation. We therefore want to include summary statistics such as mean values and most frequent values to improve these as concept-specific words are often repeated in meta-records which are not important.</p>
<p>Unfortunately, the underlying data is sometimes numeric, sometimes categorical, resulting in mixed data for the aggregated features of most frequent values, and missing values for features such as the mean value. Imputing these missing values seems impossible as they should not have a mean to begin with. The most frequent value has mixed data with frequently large gaps between numerical values (e.g. parameters close to 0 - 10, but sometimes closer to 100 - 500, or even &gt; 20k) so binning seems impractical as well.</p>
<p>Example data:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>text_description</th>
<th>timestamp</th>
<th>value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Text example one describing data</td>
<td>0</td>
<td>80</td>
</tr>
<tr>
<td>Text example one describing data</td>
<td>1</td>
<td>80</td>
</tr>
<tr>
<td>Text example one describing data</td>
<td>2</td>
<td>70</td>
</tr>
<tr>
<td>Text example one describing data</td>
<td>3</td>
<td>2000</td>
</tr>
<tr>
<td>Text example two describing data</td>
<td>0</td>
<td>Home</td>
</tr>
<tr>
<td>Text example two describing data</td>
<td>1</td>
<td>Transit</td>
</tr>
<tr>
<td>Text example two describing data</td>
<td>2</td>
<td>Parents</td>
</tr>
<tr>
<td>Text example two describing data</td>
<td>3</td>
<td>Transit</td>
</tr>
<tr>
<td>Text example three describing data</td>
<td>0</td>
<td>1.0</td>
</tr>
<tr>
<td>Text example three describing data</td>
<td>1</td>
<td>0.0</td>
</tr>
<tr>
<td>Text example three describing data</td>
<td>2</td>
<td>1.0</td>
</tr>
<tr>
<td>Text example three describing data</td>
<td>3</td>
<td>1.0</td>
</tr>
</tbody>
</table>
</div>
<p>Example aggregated dataframe:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>text_description</th>
<th>summary_mean</th>
<th>summary_most_frequent</th>
<th>target_concept_label</th>
</tr>
</thead>
<tbody>
<tr>
<td>Text example one describing data</td>
<td>1000</td>
<td>80</td>
<td>Label_One</td>
</tr>
<tr>
<td>Text example two describing data</td>
<td>NaN</td>
<td>Transit</td>
<td>Label_Two</td>
</tr>
<tr>
<td>Text example three describing data</td>
<td>0.8</td>
<td>1.0</td>
<td>Label_Three</td>
</tr>
</tbody>
</table>
</div>
<p>This lower table will be used as input to try to infer the target_concept_label. I've also thought of other approaches like separating the dataset and training three different models for each datatype, but that would mean losing a lot of training data for the text description parts. How would you approach this problem?</p>
",15,0,-2,2,machine-learning;data-processing,2022-06-28 20:56:14,2022-06-28 20:56:14,2022-06-29 19:35:40,i want to predict concept labels given to specific records  but have trouble handling the variation these records have  in particularly the presence  or absence  of values for specific features because of mixed data  i have a dataset in which we want to cluster data and label these clusters for easier retrieval and eventually further detailed processing  we therefore group by the parameter label provided which is a short description of the concept  but with a large variation  we therefore want to include summary statistics such as mean values and most frequent values to improve these as concept specific words are often repeated in meta records which are not important  unfortunately  the underlying data is sometimes numeric  sometimes categorical  resulting in mixed data for the aggregated features of most frequent values  and missing values for features such as the mean value  imputing these missing values seems impossible as they should not have a mean to begin with  the most frequent value has mixed data with frequently large gaps between numerical values  e g  parameters close to      but sometimes closer to      or even  gt  k  so binning seems impractical as well  example data  example aggregated dataframe  this lower table will be used as input to try to infer the target_concept_label  i ve also thought of other approaches like separating the dataset and training three different models for each datatype  but that would mean losing a lot of training data for the text description parts  how would you approach this problem ,combine numerical and categorical data within the same feature for machine learning
206,206,19437952,72792101,Are there any models to extract specific data from pdf files?,"<p>For the purpose of my project, I am given large pdfs and need to manually extract one specific value (commission). I am looking for ay machine learning or AI model that would be able to automate this process. The structure of the pdfs vary, so ideally the model would be able to scan the pdf and return the commission percent for any type of pdf. For example the value can be provided in such ways:</p>
<ol>
<li><p>Commission Rate = 20%</p>
</li>
<li><p>The commission rate for this transaction is 20%.</p>
</li>
<li><p>Premium             Commission           Net</p>
<p>50000               20%                  40000</p>
</li>
</ol>
",25,1,-2,3,machine-learning;artificial-intelligence;textdecoder,2022-06-29 00:53:03,2022-06-29 00:53:03,2022-06-29 19:34:24,for the purpose of my project  i am given large pdfs and need to manually extract one specific value  commission   i am looking for ay machine learning or ai model that would be able to automate this process  the structure of the pdfs vary  so ideally the model would be able to scan the pdf and return the commission percent for any type of pdf  for example the value can be provided in such ways  commission rate     the commission rate for this transaction is    premium             commission           net                                   ,are there any models to extract specific data from pdf files 
207,207,19425906,72794079,Python (sklearn) train_test_split: choosing which data to train and which data to test,"<p>I want to use sklearn's train_test_split to manually split data into train and test categories. Specifically, in my .csv file, I want to use all the rows of data until the last row to train, and the last row to test. </p> The reason I'm doing this is because I need to launch a machine learning model but am incredibly short on time. I thought the best way would be to use predictions rather than deploying it using IBM Watson. I don't need it to be live. </p> My code so far looks like this:</p>
<pre><code>df=pd.read_csv('Book5.csv', names=['Amiability', 'Email'])

from sklearn.model_selection import train_test_split

df_x = df['Amiability']
df_y = df['Email']

x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=4) 
</code></pre>
<p>Then,</p>
<pre><code>len(df)
</code></pre>
<p>Produces</p>
<pre><code>331
</code></pre>
<p>I want to train with rows 0-330, and test with row 331. How can I do this?</p>
",39,1,-1,3,python;pandas;scikit-learn,2022-06-29 04:36:45,2022-06-29 04:36:45,2022-06-29 19:31:32,i want to use sklearn s train_test_split to manually split data into train and test categories  specifically  in my  csv file  i want to use all the rows of data until the last row to train  and the last row to test   then  produces i want to train with rows    and test with row   how can i do this ,python  sklearn  train_test_split  choosing which data to train and which data to test
208,208,19096400,72802557,Machine Learning outcome with more than 2 categories-caret,"<p>I know that there are many algorithms for ML problems where the outcome has 2 categories.
I am wondering kwon if there are algorithms that accept outcomes with more than 2 categories, especially in the caret package.</p>
",15,0,-2,4,r;machine-learning;classification;r-caret,2022-06-29 19:19:41,2022-06-29 19:19:41,2022-06-29 19:25:09,,machine learning outcome with more than  categories caret
209,209,15797456,72794761,Displaying an Image with Matplotlib in deeplearning,"<p>Running this piece of code:</p>
<pre><code>#loading test images
val_ds = tf.keras.preprocessing.image_dataset_from_directory(
test_path,image_size=(img_height,img_width), label_mode='int', 
batch_size=batch_size)
                                                       
import matplotlib.pyplot as plt

plt.figure(figsize=(12,12))
for img ,label in val_ds.take(1):
    for i in range(12):
        ax = plt.subplot(4,3,i + 1)
        plt.imshow(img[i].numpy().astype('uint8'))
        plt.title(class_name[label[i]])
        plt.axis('off')
</code></pre>
<p>I got this error :</p>
<blockquote>
<p>NotFoundError: NewRandomAccessFile failed to Create/Open: D:\Machine
Learning\DPL\Deep Learning for Computer Vision with TensorFlow
2[TutsNode.com] - Deep Learning for Computer Vision with TensorFlow
2\3. Convolutional Neural Networks\15.1
covid19\covid19\test\Covid\auntminnie-a-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg
: The system cannot find the path specified. ; No such process<br />
[[{{node ReadFile}}]] [Op:IteratorGetNext]</p>
</blockquote>
<p>Any help ??</p>
",24,0,0,4,python;tensorflow;keras;deep-learning,2022-06-29 06:52:37,2022-06-29 06:52:37,2022-06-29 18:48:36,running this piece of code  i got this error   any help   ,displaying an image with matplotlib in deeplearning
210,210,19436129,72789256,Jupyter-notebook fails to start | PyForMLS,"<p>I am currently setting up a Python data-science client for SQL Server Machine Learning Services following this guide: <a href=""https://docs.microsoft.com/en-us/sql/machine-learning/python/setup-python-client-tools-sql?view=sql-server-ver15"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/sql/machine-learning/python/setup-python-client-tools-sql?view=sql-server-ver15</a></p>
<p>Unfortunately, running Jupyter notebooks for this distribution does not seem to work for me: Typing <code>.\Scripts\jupyter-notebook</code> in the distribution folder, or directly running jupyter-notebook.exe from the Scripts sub-folder does not start Jupyter. In the terminal, the command exits with no ouput.
Afterwards, https://localhost:8889/tree is not reachable as should be the case according to the tutorial above.</p>
<p>Any suggestions? (I already checked <a href=""https://jupyter-notebook.readthedocs.io/en/stable/troubleshooting.html"" rel=""nofollow noreferrer"">https://jupyter-notebook.readthedocs.io/en/stable/troubleshooting.html</a> for solutions). Thank you!</p>
<hr />
<p>Update: At least <code>.\Scripts\jupyter-console</code> is running, though it is not the same experience.</p>
",48,1,0,2,jupyter-notebook;azure-machine-learning-service,2022-06-28 20:56:50,2022-06-28 20:56:50,2022-06-29 18:03:35,i am currently setting up a python data science client for sql server machine learning services following this guide   any suggestions   i already checked  for solutions   thank you  update  at least   scripts jupyter console is running  though it is not the same experience ,jupyter notebook fails to start   pyformls
211,211,16982484,72801120,why does scaling improve the accuracy of my model when all my features are in the same range,"<p>so i am new to machine learning and i learnt that scaling is used when two features have different scales and hence one comes of as more weighted than others, but in MNIST dataset, all the features have values from 0 to 255, then why does standard scaling improve accuracy?</p>
",32,1,0,3,machine-learning;data-science;data-preprocessing,2022-06-29 17:33:15,2022-06-29 17:33:15,2022-06-29 17:39:38,so i am new to machine learning and i learnt that scaling is used when two features have different scales and hence one comes of as more weighted than others  but in mnist dataset  all the features have values from  to   then why does standard scaling improve accuracy ,why does scaling improve the accuracy of my model when all my features are in the same range
212,212,283538,72799969,install tensorflow-decision-forests in windows,"<p>I have to install tensorflow-decision-forests in windows. I tried:</p>
<pre><code>pip install tensorflow-decision-forests
pip3 install tensorflow-decision-forests
pip3 install tensorflow_decision_forests --upgrade
</code></pre>
<p>I get:</p>
<pre><code>ERROR: Could not find a version that satisfies the requirement tensorflow-decision-forests (from versions: none)
ERROR: No matching distribution found for tensorflow-decision-forests
</code></pre>
<p>I have (pip show tensorflow):</p>
<pre><code>Name: tensorflow
Version: 2.9.1
Summary: TensorFlow is an open source machine learning framework for everyone.
Home-page: https://www.tensorflow.org/
Author: Google Inc.
Author-email: packages@tensorflow.org
License: Apache 2.0
</code></pre>
<p>AFIK this is the latest version amy ideas?</p>
",39,1,1,4,python;tensorflow;pip;tensorflow-decision-forests,2022-06-29 16:07:17,2022-06-29 16:07:17,2022-06-29 16:35:17,i have to install tensorflow decision forests in windows  i tried  i get  i have  pip show tensorflow   afik this is the latest version amy ideas ,install tensorflow decision forests in windows
213,213,11572260,70576271,Relationship between Automata theory and Dynamic programming,"<p>I am learning automata theory. I think that there must be some relationship between state machine theory and dynamic programming. for the reason that the essence of dynamic programming is state transition equations. And automata theory is also deal with the problems about the transition between different states. Furthermore, since we can analysis string matching algorithms through the method using the state machine, I vaguely think that state machine can also help us understand DP more clearly.</p>
<p>However, I find there are few materials talking about this. I think that if we can apply automata theory to the process of learning dynamic programming techniques, it can help us understand so many DP problems which are usually too difficult and complex for us to understand.</p>
<p>Can anyone recommend some materials which are talking about the applications of automata theory in dynamic programming algorithms' designing or the analysis of DP problems using state machine theory?</p>
<p>ps. the terminology 'dynamic programming' here just refers to our normal understanding of that algorithm designing tricks, not that mathematics field which is created by Bellman.</p>
",73,0,2,3,dynamic-programming;state-machine;automata-theory,2022-01-04 14:27:16,2022-01-04 14:27:16,2022-06-29 15:30:08,i am learning automata theory  i think that there must be some relationship between state machine theory and dynamic programming  for the reason that the essence of dynamic programming is state transition equations  and automata theory is also deal with the problems about the transition between different states  furthermore  since we can analysis string matching algorithms through the method using the state machine  i vaguely think that state machine can also help us understand dp more clearly  however  i find there are few materials talking about this  i think that if we can apply automata theory to the process of learning dynamic programming techniques  it can help us understand so many dp problems which are usually too difficult and complex for us to understand  can anyone recommend some materials which are talking about the applications of automata theory in dynamic programming algorithms  designing or the analysis of dp problems using state machine theory  ps  the terminology  dynamic programming  here just refers to our normal understanding of that algorithm designing tricks  not that mathematics field which is created by bellman ,relationship between automata theory and dynamic programming
214,214,19016900,72798613,Unmet Dependencies while trying to install the Microsoft mssql-mlservices-packages-py Machine Learning package on Ubuntu 21.10,"<p>I followed the instructions from <a href=""https://t.ly/KUFs"" rel=""nofollow noreferrer"">Install MS ML</a> to install the Microsoft Machine Learning Services on Ubuntu 21.10. I started with a fresh installed version of Ubuntu 21.10, installing the updates and required files. I also installed SQL Server 2019 on another Server and have full access to connect to it via ISQL. Nevertheless, when I reached the point to install the actual ML Installation files, I am met with a File Dependency error:</p>
<pre><code>johnny@JSML:~$ sudo apt-get install mssql-mlservices-mlm-py
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
Some packages could not be installed. This may mean that you have
requested an impossible situation or if you are using the unstable
distribution that some required packages have not yet been created
or been moved out of Incoming.
The following information may help to resolve the situation:

The following packages have unmet dependencies:
mssql-mlservices-packages-py : Depends: microsoft-openmpi (&gt;= 3.0.0) but it is not installable
Depends: mssql-server-extensibility (&gt;= 15.0.2000) but it is not installable
E: Unable to correct problems, you have held broken packages.
</code></pre>
<p>Tried to manually install the Depends file to no avail. I am not sure how to repair this issue.  Any guidance would be appreciated.</p>
",24,0,-1,2,sql-server;machine-learning,2022-06-29 14:30:57,2022-06-29 14:30:57,2022-06-29 14:30:57,i followed the instructions from  to install the microsoft machine learning services on ubuntu    i started with a fresh installed version of ubuntu    installing the updates and required files  i also installed sql server  on another server and have full access to connect to it via isql  nevertheless  when i reached the point to install the actual ml installation files  i am met with a file dependency error  tried to manually install the depends file to no avail  i am not sure how to repair this issue   any guidance would be appreciated ,unmet dependencies while trying to install the microsoft mssql mlservices packages py machine learning package on ubuntu  
215,215,15797456,72794225,Tensorboard Callback,"<pre><code>from tensorflow.keras.callbacks 
import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint

early_stopping =EarlyStopping(patience=5, monitor='val_loss', mode='min')
learning_rate_reduction = ReduceLROnPlateau(patience=4,monitor='val_loss', factor=0.1)

#path for saving the best weights
checkpoint_best_path =r'C:\Users\Administrator\Desktop\Desktop\Work\Data Science\Practice\Machine Learning\Deep Learning\Custom Deep Learning\Deep Learning with Computer vision\Basics\Covid 19 Project\Model\Model best checkpoint'

check_bestpoint = ModelCheckpoint(filepath=checkpoint_best_path, save_weights_only=True, save_freq='epoch',
                                 monitor='val_loss',save_best_only=True, verbose=1)


#tensorboard path
log_dir_path =r'C:\Users\Administrator\Desktop\Desktop\Work\Data Science\Practice\Machine Learning\Deep Learning\Custom Deep Learning\Deep Learning with Computer vision\Basics\Covid 19 Project\Data\logs/' 
log_dir = os.path.join(log_dir_path, datetime.datetime.now().strftime(&quot;%Y%m%d-%H%M%S&quot;))

tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1)

callbacks= [early_stopping, learning_rate_reduction,check_bestpoint,tensorboard_callback]
</code></pre>
<p>but I got an error stating :</p>
<blockquote>
<p>NotFoundError: Failed to create a NewWriteableFile:
C:\Users\Administrator\Desktop\Desktop\Work\Data
Science\Practice\Machine Learning\Deep Learning\Custom Deep
Learning\Deep Learning with Computer vision\Basics\Covid 19
Project\Data\logs/20220628-231734\train/events.out.tfevents.1656501454.DESKTOP-1ULGF16.14344.2.v2
: The system cannot find the path specified. ; No such process
Creating writable file
C:\Users\Administrator\Desktop\Desktop\Work\Data
Science\Practice\Machine Learning\Deep Learning\Custom Deep
Learning\Deep Learning with Computer vision\Basics\Covid 19
Project\Data\logs/20220628-231734\train/events.out.tfevents.1656501454.DESKTOP-1ULGF16.14344.2.v2
Could not initialize events writer. [Op:CreateSummaryFileWriter]</p>
</blockquote>
",27,1,0,5,python;tensorflow;machine-learning;keras;deep-learning,2022-06-29 05:02:40,2022-06-29 05:02:40,2022-06-29 14:21:31,but i got an error stating  ,tensorboard callback
216,216,19441122,72797110,Issue while installing a lower python version in conda prompt,"<p>I have python version 3.8.8 in conda. I want version 3.5.0 for a Machine learning project but when I ran the command <code>conda install python=3.5.0</code>, following output came:</p>
<p>**Collecting package metadata (current_repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Collecting package metadata (repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.</p>
<p>PackagesNotFoundError: The following packages are not available from current channels:</p>
<ul>
<li>python=3.5.0</li>
</ul>
<p>Current channels:</p>
<ul>
<li><a href=""https://repo.anaconda.com/pkgs/main/win-64"" rel=""nofollow noreferrer"">https://repo.anaconda.com/pkgs/main/win-64</a></li>
<li><a href=""https://repo.anaconda.com/pkgs/main/noarch"" rel=""nofollow noreferrer"">https://repo.anaconda.com/pkgs/main/noarch</a></li>
<li><a href=""https://repo.anaconda.com/pkgs/r/win-64"" rel=""nofollow noreferrer"">https://repo.anaconda.com/pkgs/r/win-64</a></li>
<li><a href=""https://repo.anaconda.com/pkgs/r/noarch"" rel=""nofollow noreferrer"">https://repo.anaconda.com/pkgs/r/noarch</a></li>
<li><a href=""https://repo.anaconda.com/pkgs/msys2/win-64"" rel=""nofollow noreferrer"">https://repo.anaconda.com/pkgs/msys2/win-64</a></li>
<li><a href=""https://repo.anaconda.com/pkgs/msys2/noarch"" rel=""nofollow noreferrer"">https://repo.anaconda.com/pkgs/msys2/noarch</a></li>
</ul>
<p>To search for alternate channels that may provide the conda package you're
looking for, navigate to</p>
<pre><code>https://anaconda.org
</code></pre>
<p>and use the search bar at the top of the page.**</p>
<p>I am not able to comprehend this. How can I install the required python version?</p>
",12,1,0,2,python-3.x;anaconda,2022-06-29 12:34:46,2022-06-29 12:34:46,2022-06-29 12:54:22,i have python version    in conda  i want version    for a machine learning project but when i ran the command conda install python     following output came  packagesnotfounderror  the following packages are not available from current channels  current channels  and use the search bar at the top of the page    i am not able to comprehend this  how can i install the required python version ,issue while installing a lower python version in conda prompt
217,217,15958905,72794914,Survey bot or Survey Chatbot with Flask and HTML,"<p>So now I'm working on a survey chatbot that requires users to answer my questions. After the said user answered the question, I will append their answers to a pandas dataframe and my machine learning model will predict the disease based on the symptoms. My machine learning model has been saved to json and now I'm really confused on how to make it work with Flask and HTML. I've watched so many chatbot tutorials but they usually just predict the user's input and response right away. I want my chatbot to ask questions and append user's inputs in a loop before predict it all. Here's my code snippet so far.</p>
<pre><code>from flask import Flask, render_template, request
from xgboost import XGBClassifier

app = Flask(__name__)

@app.route('/welcome')

def home():
    return render_template('home.html')

@app.route('/chatbot')
def get_user():
    name=request.args.get('name')
    gender=request.form['gender']
    age=request.form['age']
    hypertension=request.form['hypertension']
    heart_disease=request.form['heart_disease']
    ever_married=request.form['ever_married']
    work_type=request.form['work_type']
    residence_type=request.form['residence_type']
    weight=request.form['weight']
    height=request.form['height']
    smoking=request.form['smoking']
    return render_template('fortunecookie.html',name=name)

def predict():
    data=pd.DataFrame({'gender':[gender],
                             'age':[age],
                             'hypertension':[hypertension],
                             'heart_disease':[heart_disease],
                             'ever_married':[ever_married],
                             'work_type':[work_type],
                             'residence_type':[residence_type],
                             'bmi':[weight/(height/100)**2],
                             'smoking':[smoking]})
    model=XGBClassifier.load_model(&quot;xgbimbalance.json&quot;)
    predresult=model.predict(data.values)

if __name__==&quot;__main__&quot;:
    app.run()
</code></pre>
<p>Thank you in advance, I'm sorry if it's a bit confusing but the point is to design a survey bot with machine learning to predict the user's input after all the questions are answered.</p>
",25,0,-1,2,python;flask,2022-06-29 07:18:53,2022-06-29 07:18:53,2022-06-29 09:29:31,so now i m working on a survey chatbot that requires users to answer my questions  after the said user answered the question  i will append their answers to a pandas dataframe and my machine learning model will predict the disease based on the symptoms  my machine learning model has been saved to json and now i m really confused on how to make it work with flask and html  i ve watched so many chatbot tutorials but they usually just predict the user s input and response right away  i want my chatbot to ask questions and append user s inputs in a loop before predict it all  here s my code snippet so far  thank you in advance  i m sorry if it s a bit confusing but the point is to design a survey bot with machine learning to predict the user s input after all the questions are answered ,survey bot or survey chatbot with flask and html
218,218,19437661,72791482,"Not able to upload project on heroku,getting the below error","<pre><code>(carprediction) E:\Machine learning project( car price predictor)&gt;python app.py
C:\Users\sourav sharma\anaconda3\envs\carprediction\lib\site-packages\sklearn\base.py:338: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.1.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations
  UserWarning,
C:\Users\sourav sharma\anaconda3\envs\carprediction\lib\site-packages\sklearn\base.py:338: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 1.1.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations
</code></pre>
",32,0,-5,1,scikit-learn,2022-06-28 23:56:50,2022-06-28 23:56:50,2022-06-29 07:00:28,,not able to upload project on heroku getting the below error
219,219,13251544,72794304,Trying to run a virtual machine on a desktop environment,"<p>I was using vagrant to use a virtual machine on a windows desktop environment. Since a few days ago, I am having trouble starting the virtual machine. I keep on getting the same error message when I tried to start it by typing - &quot;vagrant up&quot;. I uninstalled it, deleted all related files and reinstalled it but all in vain. As I am still learning on how to use vagrant, virtual machines, and generally computing, I really appreciate any help on this issue. Below is a snapshot of the error message.
<a href=""https://i.stack.imgur.com/x4BAg.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/x4BAg.png"" alt=""enter image description here"" /></a></p>
",11,0,0,1,vagrant-windows,2022-06-29 05:17:28,2022-06-29 05:17:28,2022-06-29 05:17:28,,trying to run a virtual machine on a desktop environment
220,220,18204980,72767066,Stratified sampling getting odd proportion of factor levels,"<p>I'm experimenting with the Dry Bean dataset from UCI machine learning repo. I want to iterate through the dataset, repeatedly removing samples and running classifiers to see how accuracy changes as sample size decreases, but first I make the loop and check it works.</p>
<p>The dataset:</p>
<pre><code>&gt; summary(DryBean)
      Area          Perimeter      MajorAxisLength MinorAxisLength  AspectRation    Eccentricity      ConvexArea     EquivDiameter       Extent          Solidity     
 Min.   : 20420   Min.   : 524.7   Min.   :183.6   Min.   :122.5   Min.   :1.025   Min.   :0.2190   Min.   : 20684   Min.   :161.2   Min.   :0.5553   Min.   :0.9192  
 1st Qu.: 36328   1st Qu.: 703.5   1st Qu.:253.3   1st Qu.:175.8   1st Qu.:1.432   1st Qu.:0.7159   1st Qu.: 36715   1st Qu.:215.1   1st Qu.:0.7186   1st Qu.:0.9857  
 Median : 44652   Median : 794.9   Median :296.9   Median :192.4   Median :1.551   Median :0.7644   Median : 45178   Median :238.4   Median :0.7599   Median :0.9883  
 Mean   : 53048   Mean   : 855.3   Mean   :320.1   Mean   :202.3   Mean   :1.583   Mean   :0.7509   Mean   : 53768   Mean   :253.1   Mean   :0.7497   Mean   :0.9871  
 3rd Qu.: 61332   3rd Qu.: 977.2   3rd Qu.:376.5   3rd Qu.:217.0   3rd Qu.:1.707   3rd Qu.:0.8105   3rd Qu.: 62294   3rd Qu.:279.4   3rd Qu.:0.7869   3rd Qu.:0.9900  
 Max.   :254616   Max.   :1985.4   Max.   :738.9   Max.   :460.2   Max.   :2.430   Max.   :0.9114   Max.   :263261   Max.   :569.4   Max.   :0.8662   Max.   :0.9947  
                                                                                                                                                                      
   roundness       Compactness      ShapeFactor1       ShapeFactor2        ShapeFactor3     ShapeFactor4         Class     
 Min.   :0.4896   Min.   :0.6406   Min.   :0.002778   Min.   :0.0005642   Min.   :0.4103   Min.   :0.9477   BARBUNYA:1322  
 1st Qu.:0.8321   1st Qu.:0.7625   1st Qu.:0.005900   1st Qu.:0.0011535   1st Qu.:0.5814   1st Qu.:0.9937   BOMBAY  : 522  
 Median :0.8832   Median :0.8013   Median :0.006645   Median :0.0016935   Median :0.6420   Median :0.9964   CALI    :1630  
 Mean   :0.8733   Mean   :0.7999   Mean   :0.006564   Mean   :0.0017159   Mean   :0.6436   Mean   :0.9951   DERMASON:3546  
 3rd Qu.:0.9169   3rd Qu.:0.8343   3rd Qu.:0.007271   3rd Qu.:0.0021703   3rd Qu.:0.6960   3rd Qu.:0.9979   HOROZ   :1928  
 Max.   :0.9907   Max.   :0.9873   Max.   :0.010451   Max.   :0.0036650   Max.   :0.9748   Max.   :0.9997   SEKER   :2027  
                                                                                                            SIRA    :2636  
</code></pre>
<p>I set the Class variable to a factor, then found the proportion of levels:</p>
<pre><code>&gt; prop.table(table(DryBean$Class))

  BARBUNYA     BOMBAY       CALI   DERMASON      HOROZ      SEKER       SIRA 
0.09712732 0.03835133 0.11975608 0.26052458 0.14165014 0.14892366 0.19366689
</code></pre>
<p>I created a copy of the data then used a loop to remove samples in those proportions:</p>
<pre><code>while(nrow(beanclone) &gt; 100) {
  mysample &lt;- stratified(beanclone, &quot;Class&quot;, size = c(&quot;BARBUNYA&quot; = 0.09712732 , &quot;BOMBAY&quot; = 0.03835133 , &quot;CALI&quot; = 0.11975608 , &quot;DERMASON&quot; = 0.26052458 , &quot;HOROZ&quot; = 0.14165014 , &quot;SEKER&quot; = 0.14892366 , &quot;SIRA&quot; = 0.19366689 ), keep.rownames = TRUE)
  beanclone &lt;- beanclone[!seq_len(nrow(beanclone)) %in% mysample$rn,]
  print(table(beanclone$Class))
  print(nrow(beanclone))
}
</code></pre>
<p>However, the first few iterations of the loop had this output:</p>
<pre><code>BARBUNYA   BOMBAY     CALI DERMASON    HOROZ    SEKER     SIRA 
    1271      459     1205     2859     1655     1830     2243 
[1] 11522

BARBUNYA   BOMBAY     CALI DERMASON    HOROZ    SEKER     SIRA 
    1222      404      891     2305     1421     1652     1909 
[1] 9804

BARBUNYA   BOMBAY     CALI DERMASON    HOROZ    SEKER     SIRA 
    1175      356      659     1859     1220     1492     1625 
[1] 8386
</code></pre>
<p>The Barbunya level is losing samples much more slowly than the rest, ultimately ending at this distribution:</p>
<pre><code>BARBUNYA   BOMBAY     CALI DERMASON    HOROZ    SEKER     SIRA 
      80        4        1        2        3        5        3 
[1] 98
</code></pre>
<p>Testing with the size being set to different integers for each level showed that the loop was associating the correct size label with the level, i.e. setting &quot;Barbunya&quot; = 3 would result in barbunya losing 3 samples at each iteration, so why is it changing so slowly when going by proportion?</p>
<p>Edit:</p>
<p>Changing some of the proportion decimals has shown some unexpected results.
Barbunya 0.09712732 -&gt; 0.5 ended the loop at:</p>
<pre><code>BARBUNYA   BOMBAY     CALI DERMASON    HOROZ    SEKER     SIRA 
     89        4        1        2        3        1        3 
[1] 103

BARBUNYA   BOMBAY     CALI DERMASON    HOROZ    SEKER     SIRA 
     86        4        1        2        3        1        3 
[1] 100
</code></pre>
<p>Which is a negligible increase in the amount of Barbunya being removed at each iteration.</p>
",53,0,3,3,r;while-loop;sampling,2022-06-27 10:09:27,2022-06-27 10:09:27,2022-06-29 04:12:48,i m experimenting with the dry bean dataset from uci machine learning repo  i want to iterate through the dataset  repeatedly removing samples and running classifiers to see how accuracy changes as sample size decreases  but first i make the loop and check it works  the dataset  i set the class variable to a factor  then found the proportion of levels  i created a copy of the data then used a loop to remove samples in those proportions  however  the first few iterations of the loop had this output  the barbunya level is losing samples much more slowly than the rest  ultimately ending at this distribution  testing with the size being set to different integers for each level showed that the loop was associating the correct size label with the level  i e  setting  barbunya     would result in barbunya losing  samples at each iteration  so why is it changing so slowly when going by proportion  edit  which is a negligible increase in the amount of barbunya being removed at each iteration ,stratified sampling getting odd proportion of factor levels
221,221,18201044,72788138,Machine Learning - Train a model using imbalanced data,"<p>I have two classes in my data.</p>
<p>This is how class distribution looks like.</p>
<pre><code>0.0    169072
1.0     84944
</code></pre>
<p>In other words, I have 2:1 class distribution.</p>
<p>I believe I have two choices. Downsample the class <code>0.0</code> or upsample class <code>1.0</code>. If I go with option 1, I'm losing data. If i go with option 2, then I'm using non-real data.</p>
<p>Is there a way, I can train the model without upsample or downsample?</p>
<p>This is how my classification_report looks like.</p>
<pre><code>               precision    recall  f1-score   support

         0.0       0.68      1.00      0.81     51683
         1.0       1.00      0.00      0.00     24522

    accuracy                           0.68     76205
   macro avg       0.84      0.50      0.40     76205
weighted avg       0.78      0.68      0.55     76205  
</code></pre>
",27,2,0,4,scikit-learn;logistic-regression;xgboost;lightgbm,2022-06-28 19:48:30,2022-06-28 19:48:30,2022-06-28 20:09:49,i have two classes in my data  this is how class distribution looks like  in other words  i have   class distribution  i believe i have two choices  downsample the class   or upsample class    if i go with option   i m losing data  if i go with option   then i m using non real data  is there a way  i can train the model without upsample or downsample  this is how my classification_report looks like ,machine learning   train a model using imbalanced data
222,222,10029745,72788374,What is a ML model suitable for a nutricionist AI?,"<p>Say a Machine Learning engineer wants to make an AI that predicts the best diet for a person. It takes into account the goal of the diet, profile of the person, calorie intake and possible meals from a database of diets.</p>
<p>Is there an existing model that serves this purpose? Would you recomend using AI to solve this problem as opposed to another algorithm? If no, then why?</p>
<p>The context is I am new to AI and am trying to understand its use cases.</p>
",15,0,-2,3,machine-learning;artificial-intelligence;diet,2022-06-28 20:01:59,2022-06-28 20:01:59,2022-06-28 20:01:59,say a machine learning engineer wants to make an ai that predicts the best diet for a person  it takes into account the goal of the diet  profile of the person  calorie intake and possible meals from a database of diets  is there an existing model that serves this purpose  would you recomend using ai to solve this problem as opposed to another algorithm  if no  then why  the context is i am new to ai and am trying to understand its use cases ,what is a ml model suitable for a nutricionist ai 
223,223,10456623,72777047,How to use data without leakage,"<p>I am developing a deep learning model, but the data is sensitive and can only be stored on a remote server. However, coding and debugging on that server is inconvenient.  So, is it possible to use the data in my local machine without data leakage? (make sure I can't download the real data from my side otherwise the person who manages the data won't allow me to do it.)</p>
",16,0,-1,3,deep-learning;privacy;data-security,2022-06-28 00:20:10,2022-06-28 00:20:10,2022-06-28 19:56:09,i am developing a deep learning model  but the data is sensitive and can only be stored on a remote server  however  coding and debugging on that server is inconvenient   so  is it possible to use the data in my local machine without data leakage   make sure i can t download the real data from my side otherwise the person who manages the data won t allow me to do it  ,how to use data without leakage
224,224,9222360,72786131,Scrape large scale data from Wikipedia,"<p>I am training a large machine learning model and need to scrape a lot of data for the same. I want to train my model on domain specific tasks and hence, given a domain, I will need to scrape Wikipedia pages and pages from the web.</p>
<p>For example, if the domain name is &quot;finance&quot;, I will need to crawl Wikipedia pages that are related to finance and then store the text present in them. Wikipedia Rest API has a limit of 200 requests per second. I will probably need more data than that.</p>
<p>There are wikipedia data dumps but the size of the dumps are too large.</p>
<p>Is there any other way of doing this or working with the API?</p>
<p>On a similar note, if I want to search for pages on the web related to some query, how will I do it?</p>
",20,0,-1,3,web-scraping;web-crawler;mediawiki,2022-06-28 17:36:52,2022-06-28 17:36:52,2022-06-28 18:30:17,i am training a large machine learning model and need to scrape a lot of data for the same  i want to train my model on domain specific tasks and hence  given a domain  i will need to scrape wikipedia pages and pages from the web  for example  if the domain name is  finance   i will need to crawl wikipedia pages that are related to finance and then store the text present in them  wikipedia rest api has a limit of  requests per second  i will probably need more data than that  there are wikipedia data dumps but the size of the dumps are too large  is there any other way of doing this or working with the api  on a similar note  if i want to search for pages on the web related to some query  how will i do it ,scrape large scale data from wikipedia
225,225,19160479,72700574,Compute the loss of a moving dataset,"<p>I’m new to the world of machine learning, so it could be that my question is trivial or incorrectly posed.</p>
<p>I am using a moving dataset that I have forwarded to an STN network (Spatial Tranformation Network). To the STN I forward each image individually, then restack the whole images together in a tuple.
My problem lies in the loss calculation. My target has a torch.tensor with this size [2,1,64,64]
and my prediction that I want to implement has a torch.tensor [2,1,10,64,64], which means that the prediction and the target are not the same.
Could someone explain an idea to me. The only idea I have is to return the last STN output meaning something like this [2,1,1,64,64] to my prediction and then squeezed to be [2,1,64,64] and then calculate the loss.</p>
<p>Thank you in advance</p>
",39,0,0,5,python;machine-learning;pytorch;mnist;spatial-transformer-network,2022-06-21 17:42:31,2022-06-21 17:42:31,2022-06-28 18:19:39,i m new to the world of machine learning  so it could be that my question is trivial or incorrectly posed  thank you in advance,compute the loss of a moving dataset
226,226,11719827,72786082,Mixing video and data streams on raspberry pi for machine learning,"<p>What is best way to mix data and video for machine learning on single board computer like raspberry pi?</p>
<p>It should be very common problem. I found there is GPMF and KLV extensions for video formats. But I fail to find someone to implment that for raspberry pi, opencv, etc.</p>
<p>It seems I can solve the problem by mixing 2 data streams in single file and then read that file with my own code but I wonder what is canonical solution for that kind of problem.</p>
",30,0,2,3,machine-learning;raspberry-pi;klvdata,2022-06-28 17:33:13,2022-06-28 17:33:13,2022-06-28 17:33:13,what is best way to mix data and video for machine learning on single board computer like raspberry pi  it should be very common problem  i found there is gpmf and klv extensions for video formats  but i fail to find someone to implment that for raspberry pi  opencv  etc  it seems i can solve the problem by mixing  data streams in single file and then read that file with my own code but i wonder what is canonical solution for that kind of problem ,mixing video and data streams on raspberry pi for machine learning
227,227,18390926,72782753,"How can I resize a image to shape=(None, 321, 321, 3) with name name=None and dtype=tf.float32","<p><strong>Problem</strong>: I am trying to reshape a image to size (None,321,321,3) and also set the name of image to None. I want to match the image dimension requirements to train a machine learning model of specs,</p>
<pre><code>TensorSpec(shape=(None, 321, 321, 3), dtype=tf.float32, name=None)
</code></pre>
<p><strong>What I have done:</strong> I am using <code>PIL</code> to reshape the image. I can convert the image to the required size and RGB band, but have no idea how to make the first argument in the size as <code>None</code> and also how to set the name of image to <code>None</code>. Please help me find a solution to this problem.</p>
",39,1,2,5,python;tensorflow;image-processing;python-imaging-library;image-resizing,2022-06-28 13:31:46,2022-06-28 13:31:46,2022-06-28 14:50:59,problem  i am trying to reshape a image to size  none     and also set the name of image to none  i want to match the image dimension requirements to train a machine learning model of specs  what i have done  i am using pil to reshape the image  i can convert the image to the required size and rgb band  but have no idea how to make the first argument in the size as none and also how to set the name of image to none  please help me find a solution to this problem ,how can i resize a image to shape  none        with name name none and dtype tf float
228,228,9690492,62669501,Accessing Saved Pickle Model in github,"<p>So I saved my trained machine learning model as pickle in github, but I can't find a way  to access it yet? Anyone have a suggestion?</p>
",293,1,0,5,python;machine-learning;github;pickle;github-pages,2020-07-01 09:33:14,2020-07-01 09:33:14,2022-06-28 13:42:32,so i saved my trained machine learning model as pickle in github  but i can t find a way  to access it yet  anyone have a suggestion ,accessing saved pickle model in github
229,229,11088453,72781392,Unable to get functionality of python application build in flask on locla host,"<p>I am trying to build a machine learning model and implement it in flask.</p>
<p>However, I am getting an error:</p>
<p><strong>Internal Server Error The Server Encountered an internal error aand was unable to complete your request.</strong></p>
<p><a href=""https://i.stack.imgur.com/Gb5uF.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Gb5uF.png"" alt=""The error message"" /></a></p>
<p>Can someone tell me what exactly is the issue.</p>
<p>Everything was running fine.</p>
<p>When I changed the data then the application opened but when I run it, it crashed like this.</p>
<p>Regards</p>
",19,0,-2,5,python;flask;machine-learning;web;server,2022-06-28 11:29:14,2022-06-28 11:29:14,2022-06-28 11:29:14,i am trying to build a machine learning model and implement it in flask  however  i am getting an error  internal server error the server encountered an internal error aand was unable to complete your request   can someone tell me what exactly is the issue  everything was running fine  when i changed the data then the application opened but when i run it  it crashed like this  regards,unable to get functionality of python application build in flask on locla host
230,230,10765849,72780436,Deploying the Machine Learning Model in React Native,"<p>I am working on Heart Disease Classification using Scikit Learn. I have generated the model in .h5 extension. Next, I want to deploy the model in react native framework. I am not sure how to go about it.</p>
",27,0,-1,3,react-native;machine-learning;scikit-learn,2022-06-28 08:58:14,2022-06-28 08:58:14,2022-06-28 08:58:14,i am working on heart disease classification using scikit learn  i have generated the model in  h extension  next  i want to deploy the model in react native framework  i am not sure how to go about it ,deploying the machine learning model in react native
231,231,3274103,21966033,Error While trying to connect to DB2 SAMPLE database for the First TIme,"<p>I want to install DB2 UDW in my machine for learning purpose but I am having a hard time configuring the local instance. Any help would be highly appreciated. </p>

<p>I installed DB2 express edition -c . I have selected all the default choices. I am trying to connect using IBM data Studio 4.1,  In the ""DB2 first Steps""  GUI I have chosen to create SAMPLE Database. I am getting the below error</p>

<p><strong>Creating database ""SAMPLE"" on path ""C:""...
  Existing ""SAMPLE"" database found...
    The ""-force"" option was not specified...
  Attempt to create the database ""SAMPLE"" failed
  'db2sampl' processing complete.</strong></p>

<p>I tried connecting from Data Studio using the following options </p>

<p>Database- SAMPLE
Port- 50000
host - localhost</p>

<p>Error I am getting </p>

<p><strong>Explanation</strong>:
An attempt was made to access a database that was not found, has not been started, or does not support transactions.
<strong>User response:</strong>
Ensure that the specified database name exists in the system database directory. If the database name does not exist in the system database directory, either the database does not exist or the database name has not been cataloged. If needed, issue a db2start command and then resubmit the current command.
SQL4499N A fatal error occurred that resulted in a disconnect from the data source.
SQLSTATE: 08004</p>

<p>Problem is I am having zero knowledge in DB2.   If I need to run db2start command from where I should run this?  Please help</p>
",9450,1,0,2,database;db2,2014-02-23 14:10:36,2014-02-23 14:10:36,2022-06-28 05:33:40,i want to install db udw in my machine for learning purpose but i am having a hard time configuring the local instance  any help would be highly appreciated   i installed db express edition  c   i have selected all the default choices  i am trying to connect using ibm data studio     in the db first steps  gui i have chosen to create sample database  i am getting the below error i tried connecting from data studio using the following options  error i am getting  problem is i am having zero knowledge in db    if i need to run dbstart command from where i should run this   please help,error while trying to connect to db sample database for the first time
232,232,19428875,72776427,"How to automate Python script run by using GCP apps (secluder, scheduled query in Big Query, or any other ideas)","<p>I am trying to create a batch ETL using a local python script and GCP.</p>
<p>I have built a python script that generates a random json file containing some fake data fields as a &quot;fake data generator&quot;...I am working on a project that will eventually use a more complex algorithm to generate a json, but for designing the framework of my ETL... I am just using a placeholder in the meantime.</p>
<p>The goal is to set up a system in GCP that would allow the scheduled running of this script (on my local repo in visual studio), and then the retrieving of the json file it generates. Then I need to append this file to a data table in BQ.</p>
<p>What would be the best way to do this operation? It is important to note that the request to run the python script on a schedule needs to come from GCP, or else I would just use a cronjobs system on my local machine.</p>
<p>I have tried learning how to create a scheduled query in Google Big Query, although I'm not very familiar with how this could work, and am still learning how to use Big Query and GCP.</p>
<p>All advice is welcome, thanks!!!</p>
",39,0,1,5,python;google-cloud-platform;google-bigquery;etl;data-pipeline,2022-06-27 23:22:43,2022-06-27 23:22:43,2022-06-27 23:22:43,i am trying to create a batch etl using a local python script and gcp  i have built a python script that generates a random json file containing some fake data fields as a  fake data generator    i am working on a project that will eventually use a more complex algorithm to generate a json  but for designing the framework of my etl    i am just using a placeholder in the meantime  the goal is to set up a system in gcp that would allow the scheduled running of this script  on my local repo in visual studio   and then the retrieving of the json file it generates  then i need to append this file to a data table in bq  what would be the best way to do this operation  it is important to note that the request to run the python script on a schedule needs to come from gcp  or else i would just use a cronjobs system on my local machine  i have tried learning how to create a scheduled query in google big query  although i m not very familiar with how this could work  and am still learning how to use big query and gcp  all advice is welcome  thanks   ,how to automate python script run by using gcp apps  secluder  scheduled query in big query  or any other ideas 
233,233,18190949,72774090,Applying PCA to 2 dimentional feature arrays,"<p>I am working with a database where for each element (individual sample) of the database I have a 150x160 matrix of features. The columns of the matrix represent spatial dimantion and the rows represent frequency. So for each element, I have data of the intensity at different points of the sample and for different frequencies. I want to apply a PCA to reduce the dimentionality of the dataset and, additionally, maximize the variability of the dataset before applying machine learning algorithms. But I don't know how to apply PCA in this case, as I normally use it for 1 dimentional data arrays. All help is welcome, thanks!</p>
",17,1,0,3,python;r;pca,2022-06-27 20:19:27,2022-06-27 20:19:27,2022-06-27 20:29:23,i am working with a database where for each element  individual sample  of the database i have a x matrix of features  the columns of the matrix represent spatial dimantion and the rows represent frequency  so for each element  i have data of the intensity at different points of the sample and for different frequencies  i want to apply a pca to reduce the dimentionality of the dataset and  additionally  maximize the variability of the dataset before applying machine learning algorithms  but i don t know how to apply pca in this case  as i normally use it for  dimentional data arrays  all help is welcome  thanks ,applying pca to  dimentional feature arrays
234,234,19427321,72773807,How to handle dataset which is a csv file that contains image names in one column and image path in other column?,"<p>I am new to python and machine learning. I am just practicing with model training and dataset thingy. I came across this dataset that have test and train folder. In that folder there are several containing different images (It's a music instrument dataset so each music instrument is categorized by names in different folders). And the csv file has this name of the instrument and their path in the folder like this: <a href=""https://i.stack.imgur.com/Wykkf.png"" rel=""nofollow noreferrer"">Instrument.csv</a></p>
<p>Now my question is how do I handle this dataset? Should I iterate through train and test folders or use this csv file?
And if I want to choose the folder option then how can go through each sub-folder and access the images?
Here is the link for the dataset : <a href=""https://www.kaggle.com/datasets/gpiosenka/musical-instruments-image-classification"" rel=""nofollow noreferrer"">https://www.kaggle.com/datasets/gpiosenka/musical-instruments-image-classification</a></p>
<p>sorry if the question doesn't make any sense or too easy to do it. I agree I am noob</p>
",19,1,0,4,python;csv;machine-learning;dataset,2022-06-27 20:00:58,2022-06-27 20:00:58,2022-06-27 20:08:14,i am new to python and machine learning  i am just practicing with model training and dataset thingy  i came across this dataset that have test and train folder  in that folder there are several containing different images  it s a music instrument dataset so each music instrument is categorized by names in different folders   and the csv file has this name of the instrument and their path in the folder like this   sorry if the question doesn t make any sense or too easy to do it  i agree i am noob,how to handle dataset which is a csv file that contains image names in one column and image path in other column 
235,235,6333517,72773806,Where to store scripts in a Python project?,"<p>I'm working on a machine learning python project. As a part of this project I have two components: (1) the library itself, with the model definitions, data processing functions, etc., and (2) a set of scripts that execute and train models, generate data, etc. These scripts are using the functionalities implemented in the library. The library component is where functionalities are defined and the scripts component is where functionalities are executed.</p>
<p>My question is how to store this kind of script in my repository. I have two options:</p>
<ol>
<li><strong>Use python entry points</strong>: The first option is to have all these scripts as part of the library and install them using python entry points.</li>
</ol>
<pre><code>project
│
└───library
│   │   __init__.py
│   │
│   └───subfolder1
│   │   │   __init__.py
│   │   │   file1.py
│   │   │   file2.py
│   │   │   ...
│   └───scripts
│       │   __init__.py
│       │   script1.py
│       │   script2.py
│       │   ...
│
│ setup.py
│ setup.cfg
</code></pre>
<p>where <code>setup.cfg</code> installs the scripts like</p>
<pre><code>[options.entry_points]
console_scripts =
    execute-script1 = library.scripts.script1:main
    execute-script2 = library.scripts.script2:main
</code></pre>
<p>And the scripts, after installing the package, are executed from the command line like <code>execute-script1 --arg1 ...</code>.</p>
<ol start=""2"">
<li><strong>Script folder</strong>: the second option is to have a folder of scripts outside the library with all the scripts defined there. This is, something like</li>
</ol>
<pre><code>project
│
└───library
│   │   __init__.py
│   │
│   └───subfolder1
│       │   file1.py
│       │   file2.py
│       │   ...
│   
│ setup.py
│
└───scripts
    │   script1.py
    │   script2.
</code></pre>
<p>where <code>setup.py</code> installs only the modules in <code>library</code>. And the scripts look like</p>
<pre class=""lang-py prettyprint-override""><code>def parse_args():
    ...

def main():
    args = parse_args()
    ...

if __name__ == &quot;__main__&quot;:
    main()
</code></pre>
<p>And the scripts are executed from the command line like <code>python scripts/scrip1.py --arg1 ...</code></p>
<p>Which is the recommended way to store these scripts? I've been looking at several python projects but I couldn't find a standard way.</p>
",19,0,0,4,python;package;repository;structure,2022-06-27 20:00:58,2022-06-27 20:00:58,2022-06-27 20:00:58,i m working on a machine learning python project  as a part of this project i have two components     the library itself  with the model definitions  data processing functions  etc   and    a set of scripts that execute and train models  generate data  etc  these scripts are using the functionalities implemented in the library  the library component is where functionalities are defined and the scripts component is where functionalities are executed  my question is how to store this kind of script in my repository  i have two options  where setup cfg installs the scripts like and the scripts  after installing the package  are executed from the command line like execute script   arg      where setup py installs only the modules in library  and the scripts look like and the scripts are executed from the command line like python scripts scrip py   arg     which is the recommended way to store these scripts  i ve been looking at several python projects but i couldn t find a standard way ,where to store scripts in a python project 
236,236,14686347,72773295,Encountered error while trying to install package. kaggle,"<p>I am new to machine learning and am currently trying to build a python function that can download a specified datasets from Kaggle given the URL. However, I keep on encountering the below problem when ever I run the <code>pip install kaggle</code> or <code>pip install opendatasets</code> commands in my windows command line.</p>
<blockquote>
<p>× Encountered error while trying to install package.
╰─&gt; kaggle</p>
</blockquote>
<p><a href=""https://i.stack.imgur.com/rXNvt.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/rXNvt.png"" alt=""Error encountered"" /></a></p>
<p>I am using Jupyter Notebook for machine learning practice running on windows 10, python version 3.10.1.</p>
<p>Any help will be truly appreciated</p>
",33,0,0,3,python;jupyter-notebook;kaggle,2022-06-27 19:24:48,2022-06-27 19:24:48,2022-06-27 19:24:48,i am new to machine learning and am currently trying to build a python function that can download a specified datasets from kaggle given the url  however  i keep on encountering the below problem when ever i run the pip install kaggle or pip install opendatasets commands in my windows command line   i am using jupyter notebook for machine learning practice running on windows   python version     any help will be truly appreciated,encountered error while trying to install package  kaggle
237,237,5961731,42484746,Two-Class-Logistic VS Binary Logistic Regression,"<p>During a test project on Azure Machine Learning Studio I have some questions based on my understandings.
In my project (in R) I have used Binary Logistic Regression, but in AML I found two Logistic regression Two-Class and MultiClass. So in that case I have used two-class Logistic regression. Am I Right in this case?</p>
<p>In another case during running glm() in R tool it perform Logistic regression and after summary(loreg Eqn) it provides the each variable's co-efficient &amp; estimates.</p>
<p>From R I have the following output:</p>
<p><a href=""https://i.stack.imgur.com/vjcU2.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/vjcU2.png"" alt=""enter image description here"" /></a></p>
<p>From AML after right-clicking Train Model and visualize:</p>
<p><a href=""https://i.stack.imgur.com/YRgEA.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/YRgEA.png"" alt=""enter image description here"" /></a></p>
<p>The weight in the above Picture is the estimates, am I right (Dataset is diff)?</p>
",645,1,0,3,azure;machine-learning;azure-machine-learning-studio,2017-02-27 17:03:23,2017-02-27 17:03:23,2022-06-27 18:58:22,in another case during running glm   in r tool it perform logistic regression and after summary loreg eqn  it provides the each variable s co efficient  amp  estimates  from r i have the following output   from aml after right clicking train model and visualize   the weight in the above picture is the estimates  am i right  dataset is diff  ,two class logistic vs binary logistic regression
238,238,18490724,72493838,TensorFlow Error: dictionary update sequence element #0 has length 6; 2 is required,"<p>I am new to Python and machine learning.  I am getting an error whenever I run the following code:</p>
<pre><code>def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):
  def input_function():  
    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  
    if shuffle:
      ds = ds.shuffle(1000)  
    ds = ds.batch(batch_size).repeat(num_epochs) 
    return ds  
  return input_function  


train_input_fn = make_input_fn(X_train, y_train)  
eval_input_fn = make_input_fn(X_test, y_test, num_epochs=1, shuffle=False)

linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)

linear_est.train(train_input_fn) 
result = linear_est.evaluate(eval_input_fn) 

clear_output() 
print(result['accuracy']) 
</code></pre>
<p>Error:</p>
<pre><code>ValueError                                Traceback (most recent call last)
&lt;ipython-input-38-47fb35491976&gt; in &lt;module&gt;()
----&gt; 1 linear_est.train(train_input_fn)
      2 result = linear_est.evaluate(eval_input_fn)
      3 
      4 clear_output()
      5 print(result['accuracy'])

5 frames
&lt;ipython-input-36-16cfc32eb7b2&gt; in input_function()
      1 def make_input_fn(X_train, y_train, num_epochs=10, shuffle=True, batch_size=32):
      2   def input_function():
----&gt; 3     ds = tf.data.Dataset.from_tensor_slices((dict(X_train), y_train))
      4     if shuffle:
      5       ds = ds.shuffle(1000)

ValueError: dictionary update sequence element #0 has length 6; 2 is required
</code></pre>
<p>I am not sure if the issue would be related to my data or data types. My data has no blanks.</p>
",38,1,0,3,python;tensorflow;machine-learning,2022-06-04 00:05:33,2022-06-04 00:05:33,2022-06-27 18:25:48,i am new to python and machine learning   i am getting an error whenever i run the following code  error  i am not sure if the issue would be related to my data or data types  my data has no blanks ,tensorflow error  dictionary update sequence element   has length    is required
239,239,19426239,72771746,How to calculate the accumulated weights of my variables in machine learning,"<p>I am working on a dataset that uses decision tree model, random forest and Gradient boosting. So I am trying to get the importance of their variables through their accumulated weight. How can I deal with this?</p>
",11,0,-2,2,machine-learning;data-science,2022-06-27 17:31:19,2022-06-27 17:31:19,2022-06-27 17:31:19,i am working on a dataset that uses decision tree model  random forest and gradient boosting  so i am trying to get the importance of their variables through their accumulated weight  how can i deal with this ,how to calculate the accumulated weights of my variables in machine learning
