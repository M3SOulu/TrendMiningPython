,Unnamed: 0,Unnamed: 0.1,AuthorId,Q_id,Title,Abstract,Answers,Cites,Date,Title_clean,Abstract_clean,Abstrat_without_stopwords,Title_without_stopwords,Merged_title_and_abs,Tokenized_data,Stem_data
0,0,0,AutoModerator,vqjgxg,[D] Simple Questions Thread,"Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!

Thread will stay alive until next one so keep posting after the date in the title.

Thanks to everyone for answering questions in the previous thread!",113,12,2022-07-03 20:30:12, d  simple questions thread,please post your questions here instead of creating a new thread  encourage others who create new posts for questions to post here instead thread will stay alive until next one so keep posting after the date in the title thanks to everyone for answering questions in the previous thread ,please post questions instead creating thread encourage others create posts questions post instead thread stay alive next one keep posting date title thanks everyone answering questions previous thread,simple questions thread,simple questions threadplease post questions instead creating thread encourage others create posts questions post instead thread stay alive next one keep posting date title thanks everyone answering questions previous thread,"['simple', 'questions', 'threadplease', 'post', 'questions', 'instead', 'creating', 'thread', 'encourage', 'others', 'create', 'posts', 'questions', 'post', 'instead', 'thread', 'stay', 'alive', 'next', 'one', 'keep', 'posting', 'date', 'title', 'thanks', 'everyone', 'answering', 'questions', 'previous', 'thread']","['simpl', 'question', 'threadpleas', 'post', 'question', 'instead', 'creat', 'thread', 'encourag', 'other', 'creat', 'post', 'question', 'post', 'instead', 'thread', 'stay', 'aliv', 'next', 'one', 'keep', 'post', 'date', 'titl', 'thank', 'everyon', 'answer', 'question', 'previou', 'thread']"
1,1,1,ML_WAYR_bot,vg5kjd,[D] Machine Learning - WAYR (What Are You Reading) - Week 140,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|41-50|51-60|61-70|71-80|81-90|91-100|101-110|111-120|121-130|131-140|
|----|-----|-----|-----|-----|-----|-----|-----|-----|------|-------|-------|-------|-------|
|[Week 1](https://www.reddit.com/4qyjiq)|[Week 11](https://www.reddit.com/57xw56)|[Week 21](https://www.reddit.com/60ildf)|[Week 31](https://www.reddit.com/6s0k1u)|[Week 41](https://www.reddit.com/7tn2ax)|[Week 51](https://reddit.com/9s9el5)|[Week 61](https://reddit.com/bfsx4z)|[Week 71](https://reddit.com/d7vno3)|[Week 81](https://reddit.com/f1f0iq)|[Week 91](https://reddit.com/hlt38o)|[Week 101](https://reddit.com/k81ywb)|[Week 111](https://reddit.com/myg8sm)|[Week 121](https://reddit.com/pmzx3g)|[Week 131](https://reddit.com/srsu2n)||||||||||||
|[Week 2](https://www.reddit.com/4s2xqm)|[Week 12](https://www.reddit.com/5acb1t)|[Week 22](https://www.reddit.com/64jwde)|[Week 32](https://www.reddit.com/72ab5y)|[Week 42](https://www.reddit.com/7wvjfk)|[Week 52](https://reddit.com/a4opot)|[Week 62](https://reddit.com/bl29ov)|[Week 72](https://reddit.com/de8h48)|[Week 82](https://reddit.com/f8fs6z)|[Week 92](https://reddit.com/hu6zq9)|[Week 102](https://reddit.com/kh27nx)|[Week 112](https://reddit.com/n8m6ds)|[Week 122](https://reddit.com/pw14z5)|[Week 132](https://reddit.com/t2xpfe)||
|[Week 3](https://www.reddit.com/4t7mqm)|[Week 13](https://www.reddit.com/5cwfb6)|[Week 23](https://www.reddit.com/674331)|[Week 33](https://www.reddit.com/75405d)|[Week 43](https://www.reddit.com/807ex4)|[Week 53](https://reddit.com/a8yaro)|[Week 63](https://reddit.com/bqlb3v)|[Week 73](https://reddit.com/dkox1s)|[Week 83](https://reddit.com/ffi41b)|[Week 93](https://reddit.com/iaz892)|[Week 103](https://reddit.com/kpsxtc)|[Week 113](https://reddit.com/njfsc6)|[Week 123](https://reddit.com/q5fi12)|[Week 133](https://reddit.com/tdf2gt)||
|[Week 4](https://www.reddit.com/4ub2kw)|[Week 14](https://www.reddit.com/5fc5mh)|[Week 24](https://www.reddit.com/68hhhb)|[Week 34](https://www.reddit.com/782js9)|[Week 44](https://reddit.com/8aluhs)|[Week 54](https://reddit.com/ad9ssz)|[Week 64](https://reddit.com/bw1jm7)|[Week 74](https://reddit.com/dr6nca)|[Week 84](https://reddit.com/fn62r1)|[Week 94](https://reddit.com/ijjcep)|[Week 104](https://reddit.com/kzevku)|[Week 114](https://reddit.com/ntu6lq)|[Week 124](https://reddit.com/qjxfu9)|[Week 134](https://reddit.com/tpruqj)||
|[Week 5](https://www.reddit.com/4xomf7)|[Week 15](https://www.reddit.com/5hy4ur)|[Week 25](https://www.reddit.com/69teiz)|[Week 35](https://www.reddit.com/7b0av0)|[Week 45](https://reddit.com/8tnnez)|[Week 55](https://reddit.com/ai29gi)|[Week 65](https://reddit.com/c7itkk)|[Week 75](https://reddit.com/dxshkg)|[Week 85](https://reddit.com/fvk7j6)|[Week 95](https://reddit.com/is5hj9)|[Week 105](https://reddit.com/l9lvgs)|[Week 115](https://reddit.com/o4dph1)|[Week 125](https://reddit.com/qtzbu1)|[Week 135](https://reddit.com/u0pnhf)||
|[Week 6](https://www.reddit.com/4zcyvk)|[Week 16](https://www.reddit.com/5kd6vd)|[Week 26](https://www.reddit.com/6d7nb1)|[Week 36](https://www.reddit.com/7e3fx6)|[Week 46](https://reddit.com/8x48oj)|[Week 56](https://reddit.com/ap8ctk)|[Week 66](https://reddit.com/cd7gko)|[Week 76](https://reddit.com/e4nmyk)|[Week 86](https://reddit.com/g4eavg)|[Week 96](https://reddit.com/j0xr24)|[Week 106](https://reddit.com/ljx92n)|[Week 116](https://reddit.com/odrudt)|[Week 126](https://reddit.com/r4e8he)|[Week 136](https://reddit.com/ub2xlz)||
|[Week 7](https://www.reddit.com/52t6mo)|[Week 17](https://www.reddit.com/5ob7dx)|[Week 27](https://www.reddit.com/6gngwc)|[Week 37](https://www.reddit.com/7hcc2c)|[Week 47](https://reddit.com/910jmh)|[Week 57](https://reddit.com/auci7c)|[Week 67](https://reddit.com/cj0kyc)|[Week 77](https://reddit.com/eb4lxk)|[Week 87](https://reddit.com/gcx3uf)|[Week 97](https://reddit.com/j9cbfs)|[Week 107](https://reddit.com/luqbxl)|[Week 117](https://reddit.com/omy345)|[Week 127](https://reddit.com/rez90o)|[Week 137](https://reddit.com/ul9toj)||
|[Week 8](https://www.reddit.com/53heol)|[Week 18](https://www.reddit.com/5r14yd)|[Week 28](https://www.reddit.com/6jgdva)|[Week 38](https://www.reddit.com/7kgcqr)|[Week 48](https://reddit.com/94up0g)|[Week 58](https://reddit.com/azjoht)|[Week 68](https://reddit.com/cp1jex)|[Week 78](https://reddit.com/ehbfst)|[Week 88](https://reddit.com/glm6sv)|[Week 98](https://reddit.com/jhzz9v)|[Week 108](https://reddit.com/m52u5z)|[Week 118](https://reddit.com/ovz52j)|[Week 128](https://reddit.com/ruja9s)|[Week 138](https://reddit.com/uvl3xc)||
|[Week 9](https://www.reddit.com/54kvsu)|[Week 19](https://www.reddit.com/5tt9cz)|[Week 29](https://www.reddit.com/6m9l1v)|[Week 39](https://www.reddit.com/7nayri)|[Week 49](https://reddit.com/98n2rt)|[Week 59](https://reddit.com/b50r5y)|[Week 69](https://reddit.com/cvde5a)|[Week 79](https://reddit.com/entcxy)|[Week 89](https://reddit.com/gu5t0d)|[Week 99](https://reddit.com/jqjgo2)|[Week 109](https://reddit.com/mf8m6u)|[Week 119](https://reddit.com/p50knh)|[Week 129](https://reddit.com/s5lg69)|[Week 139](https://reddit.com/v5nggu)||
|[Week 10](https://www.reddit.com/56s2oa)|[Week 20](https://www.reddit.com/5wh2wb)|[Week 30](https://www.reddit.com/6p3ha7)|[Week 40](https://www.reddit.com/7qel9p)|[Week 50](https://reddit.com/9cf158)|[Week 60](https://reddit.com/bakew0)|[Week 70](https://reddit.com/d1g1k9)|[Week 80](https://reddit.com/euctyw)|[Week 90](https://reddit.com/hddf7j)|[Week 100](https://reddit.com/jz3evt)|[Week 110](https://reddit.com/moy40m)|[Week 120](https://reddit.com/pe2idh)|[Week 130](https://reddit.com/sgisxq)||

Most upvoted papers two weeks ago:

/u/tetatetata: [Why Philosophers Should Care About Computational Complexity](https://arxiv.org/abs/1108.1791)

Besides that, there are no rules, have fun.",5,80,2022-06-20 03:19:00, d  machine learning   wayr  what are you reading    week ,this is a place to share machine learning research papers  journals  and articles that you re reading this week  if it relates to what you re researching  by all means elaborate and give us your insight  otherwise it could just be an interesting paper you ve read please try to provide some insight from your understanding and please don t post things which are present in wiki preferably you should link the arxiv page  not the pdf  you can easily access the pdf from the summary page but not the other way around  or any other pertinent links previous weeks                                                                                                                              week   https   week   https   week   https   week   https   week   https   week   https   week   https   week   https   week   https   week   https most upvoted papers two weeks ago  u tetatetata   why philosophers should care about computational complexity  https besides that  there are no rules  have fun ,place share machine learning research papers journals articles reading week relates researching means elaborate give us insight otherwise could interesting paper read please try provide insight understanding please post things present wiki preferably link arxiv page pdf easily access pdf summary page way around pertinent links previous weeks week https week https week https week https week https week https week https week https week https week https upvoted papers two weeks ago u tetatetata philosophers care computational complexity https besides rules fun,machine learning wayr reading week,machine learning wayr reading weekplace share machine learning research papers journals articles reading week relates researching means elaborate give us insight otherwise could interesting paper read please try provide insight understanding please post things present wiki preferably link arxiv page pdf easily access pdf summary page way around pertinent links previous weeks week https week https week https week https week https week https week https week https week https week https upvoted papers two weeks ago u tetatetata philosophers care computational complexity https besides rules fun,"['machine', 'learning', 'wayr', 'reading', 'weekplace', 'share', 'machine', 'learning', 'research', 'papers', 'journals', 'articles', 'reading', 'week', 'relates', 'researching', 'means', 'elaborate', 'give', 'us', 'insight', 'otherwise', 'could', 'interesting', 'paper', 'read', 'please', 'try', 'provide', 'insight', 'understanding', 'please', 'post', 'things', 'present', 'wiki', 'preferably', 'link', 'arxiv', 'page', 'pdf', 'easily', 'access', 'pdf', 'summary', 'page', 'way', 'around', 'pertinent', 'links', 'previous', 'weeks', 'week', 'https', 'week', 'https', 'week', 'https', 'week', 'https', 'week', 'https', 'week', 'https', 'week', 'https', 'week', 'https', 'week', 'https', 'week', 'https', 'upvoted', 'papers', 'two', 'weeks', 'ago', 'u', 'tetatetata', 'philosophers', 'care', 'computational', 'complexity', 'https', 'besides', 'rules', 'fun']","['machin', 'learn', 'wayr', 'read', 'weekplac', 'share', 'machin', 'learn', 'research', 'paper', 'journal', 'articl', 'read', 'week', 'relat', 'research', 'mean', 'elabor', 'give', 'us', 'insight', 'otherwis', 'could', 'interest', 'paper', 'read', 'pleas', 'tri', 'provid', 'insight', 'understand', 'pleas', 'post', 'thing', 'present', 'wiki', 'prefer', 'link', 'arxiv', 'page', 'pdf', 'easili', 'access', 'pdf', 'summari', 'page', 'way', 'around', 'pertin', 'link', 'previou', 'week', 'week', 'http', 'week', 'http', 'week', 'http', 'week', 'http', 'week', 'http', 'week', 'http', 'week', 'http', 'week', 'http', 'week', 'http', 'week', 'http', 'upvot', 'paper', 'two', 'week', 'ago', 'u', 'tetatetata', 'philosoph', 'care', 'comput', 'complex', 'http', 'besid', 'rule', 'fun']"
2,2,2,TheSurvivingHalf,vywfx3,[D] Are there any rejected papers that ended up having significant impact in the long run?,"There seems to be a general consensus that getting a paper accepted can be difficult due to various problems with our current peer-review system. That makes me wonder, are there any notable papers that had a difficult time getting accepted but ended up significantly impacting the field or ended up laying the foundation for more high impact publications?",70,197,2022-07-14 19:23:39, d  are there any rejected papers that ended up having significant impact in the long run ,there seems to be a general consensus that getting a paper accepted can be difficult due to various problems with our current peer review system  that makes me wonder  are there any notable papers that had a difficult time getting accepted but ended up significantly impacting the field or ended up laying the foundation for more high impact publications ,seems general consensus getting paper accepted difficult due various problems current peer review system makes wonder notable papers difficult time getting accepted ended significantly impacting field ended laying foundation high impact publications,rejected papers ended significant impact long run,rejected papers ended significant impact long runseems general consensus getting paper accepted difficult due various problems current peer review system makes wonder notable papers difficult time getting accepted ended significantly impacting field ended laying foundation high impact publications,"['rejected', 'papers', 'ended', 'significant', 'impact', 'long', 'runseems', 'general', 'consensus', 'getting', 'paper', 'accepted', 'difficult', 'due', 'various', 'problems', 'current', 'peer', 'review', 'system', 'makes', 'wonder', 'notable', 'papers', 'difficult', 'time', 'getting', 'accepted', 'ended', 'significantly', 'impacting', 'field', 'ended', 'laying', 'foundation', 'high', 'impact', 'publications']","['reject', 'paper', 'end', 'signific', 'impact', 'long', 'runseem', 'gener', 'consensu', 'get', 'paper', 'accept', 'difficult', 'due', 'variou', 'problem', 'current', 'peer', 'review', 'system', 'make', 'wonder', 'notabl', 'paper', 'difficult', 'time', 'get', 'accept', 'end', 'significantli', 'impact', 'field', 'end', 'lay', 'foundat', 'high', 'impact', 'public']"
3,3,3,feconroses,vz0umt,[P] The technology behind BLOOM training,"Last Tuesday, BigScience released [BLOOM](https://huggingface.co/bigscience/bloom), the world's largest open multilingual language model. Stas Bekman from the BigScience & Hugging Face team just [published a blog post](https://huggingface.co/blog/bloom-megatron-deepspeed) about the technology and engineering behind training the 176 billion parameter model, both in terms of hardware (384 80GB A100 GPUs) and software (Megatron-DeepSpeed).",0,33,2022-07-14 22:34:26, p  the technology behind bloom training,last tuesday  bigscience released  bloom  https   huggingface co bigscience bloom   the world s largest open multilingual language model  stas bekman from the bigscience   hugging face team just  published a blog post  https   huggingface co blog bloom megatron deepspeed  about the technology and engineering behind training the  billion parameter model  both in terms of hardware   gb a gpus  and software  megatron deepspeed  ,last tuesday bigscience released bloom https huggingface co bigscience bloom world largest open multilingual language model stas bekman bigscience hugging face team published blog post https huggingface co blog bloom megatron deepspeed technology engineering behind training billion parameter model terms hardware gb gpus software megatron deepspeed,p technology behind bloom training,p technology behind bloom traininglast tuesday bigscience released bloom https huggingface co bigscience bloom world largest open multilingual language model stas bekman bigscience hugging face team published blog post https huggingface co blog bloom megatron deepspeed technology engineering behind training billion parameter model terms hardware gb gpus software megatron deepspeed,"['p', 'technology', 'behind', 'bloom', 'traininglast', 'tuesday', 'bigscience', 'released', 'bloom', 'https', 'huggingface', 'co', 'bigscience', 'bloom', 'world', 'largest', 'open', 'multilingual', 'language', 'model', 'stas', 'bekman', 'bigscience', 'hugging', 'face', 'team', 'published', 'blog', 'post', 'https', 'huggingface', 'co', 'blog', 'bloom', 'megatron', 'deepspeed', 'technology', 'engineering', 'behind', 'training', 'billion', 'parameter', 'model', 'terms', 'hardware', 'gb', 'gpus', 'software', 'megatron', 'deepspeed']","['p', 'technolog', 'behind', 'bloom', 'traininglast', 'tuesday', 'bigscienc', 'releas', 'bloom', 'http', 'huggingfac', 'co', 'bigscienc', 'bloom', 'world', 'largest', 'open', 'multilingu', 'languag', 'model', 'sta', 'bekman', 'bigscienc', 'hug', 'face', 'team', 'publish', 'blog', 'post', 'http', 'huggingfac', 'co', 'blog', 'bloom', 'megatron', 'deepspe', 'technolog', 'engin', 'behind', 'train', 'billion', 'paramet', 'model', 'term', 'hardwar', 'gb', 'gpu', 'softwar', 'megatron', 'deepspe']"
4,4,4,BB4evaTB12,vye69k,30% of Google's Reddit Emotions Dataset is Mislabeled [D],"Last year, Google released their Reddit Emotions dataset: a collection of 58K Reddit comments human-labeled according to 27 emotions. 

I analyzed the dataset... and found that a 30% is mislabeled!

Some of the errors:

1. **\*aggressively tells friend I love them\*** – mislabeled as **ANGER**
2. **Yay, cold McDonald's. My favorite.** – mislabeled as **LOVE**
3. **Hard to be sad these days when I got this guy with me** – mislabeled as **SADNESS**
4. **Nobody has the money to. What a joke** – mislabeled as **JOY**

&#x200B;

I wrote a blog about it here, with more examples and my main two suggestions for how to fix Google's data annotation methodology.

Link: [https://www.surgehq.ai/blog/30-percent-of-googles-reddit-emotions-dataset-is-mislabeled](https://www.surgehq.ai/blog/30-percent-of-googles-reddit-emotions-dataset-is-mislabeled)",134,861,2022-07-14 02:47:36,  of google s reddit emotions dataset is mislabeled  d ,last year  google released their reddit emotions dataset  a collection of k reddit comments human labeled according to  emotions  i analyzed the dataset    and found that a   is mislabeled some of the errors       aggressively tells friend i love them       mislabeled as   anger      yay  cold mcdonald s  my favorite      mislabeled as   love      hard to be sad these days when i got this guy with me     mislabeled as   sadness      nobody has the money to  what a joke     mislabeled as   joy    xb i wrote a blog about it here  with more examples and my main two suggestions for how to fix google s data annotation methodology link   https   www surgehq ai blog  percent of googles reddit emotions dataset is mislabeled  https   www surgehq ai blog  percent of googles reddit emotions dataset is mislabeled ,last year google released reddit emotions dataset collection k reddit comments human labeled according emotions analyzed dataset found mislabeled errors aggressively tells friend love mislabeled anger yay cold mcdonald favorite mislabeled love hard sad days got guy mislabeled sadness nobody money joke mislabeled joy xb wrote blog examples main two suggestions fix google data annotation methodology link https www surgehq ai blog percent googles reddit emotions dataset mislabeled https www surgehq ai blog percent googles reddit emotions dataset mislabeled,google reddit emotions dataset mislabeled,google reddit emotions dataset mislabeledlast year google released reddit emotions dataset collection k reddit comments human labeled according emotions analyzed dataset found mislabeled errors aggressively tells friend love mislabeled anger yay cold mcdonald favorite mislabeled love hard sad days got guy mislabeled sadness nobody money joke mislabeled joy xb wrote blog examples main two suggestions fix google data annotation methodology link https www surgehq ai blog percent googles reddit emotions dataset mislabeled https www surgehq ai blog percent googles reddit emotions dataset mislabeled,"['google', 'reddit', 'emotions', 'dataset', 'mislabeledlast', 'year', 'google', 'released', 'reddit', 'emotions', 'dataset', 'collection', 'k', 'reddit', 'comments', 'human', 'labeled', 'according', 'emotions', 'analyzed', 'dataset', 'found', 'mislabeled', 'errors', 'aggressively', 'tells', 'friend', 'love', 'mislabeled', 'anger', 'yay', 'cold', 'mcdonald', 'favorite', 'mislabeled', 'love', 'hard', 'sad', 'days', 'got', 'guy', 'mislabeled', 'sadness', 'nobody', 'money', 'joke', 'mislabeled', 'joy', 'xb', 'wrote', 'blog', 'examples', 'main', 'two', 'suggestions', 'fix', 'google', 'data', 'annotation', 'methodology', 'link', 'https', 'www', 'surgehq', 'ai', 'blog', 'percent', 'googles', 'reddit', 'emotions', 'dataset', 'mislabeled', 'https', 'www', 'surgehq', 'ai', 'blog', 'percent', 'googles', 'reddit', 'emotions', 'dataset', 'mislabeled']","['googl', 'reddit', 'emot', 'dataset', 'mislabeledlast', 'year', 'googl', 'releas', 'reddit', 'emot', 'dataset', 'collect', 'k', 'reddit', 'comment', 'human', 'label', 'accord', 'emot', 'analyz', 'dataset', 'found', 'mislabel', 'error', 'aggress', 'tell', 'friend', 'love', 'mislabel', 'anger', 'yay', 'cold', 'mcdonald', 'favorit', 'mislabel', 'love', 'hard', 'sad', 'day', 'got', 'guy', 'mislabel', 'sad', 'nobodi', 'money', 'joke', 'mislabel', 'joy', 'xb', 'wrote', 'blog', 'exampl', 'main', 'two', 'suggest', 'fix', 'googl', 'data', 'annot', 'methodolog', 'link', 'http', 'www', 'surgehq', 'ai', 'blog', 'percent', 'googl', 'reddit', 'emot', 'dataset', 'mislabel', 'http', 'www', 'surgehq', 'ai', 'blog', 'percent', 'googl', 'reddit', 'emot', 'dataset', 'mislabel']"
5,6,6,vanilla-acc,vze1hj,[D] What are people using to organize large groups of people for data labelling?,I'm thinking of hiring a bunch of people to label a ton of data. What is the best software to do this?  I specifically want to use my own labelers.,4,3,2022-07-15 08:36:00, d  what are people using to organize large groups of people for data labelling ,i m thinking of hiring a bunch of people to label a ton of data  what is the best software to do this   i specifically want to use my own labelers ,thinking hiring bunch people label ton data best software specifically want use labelers,people using organize large groups people data labelling,people using organize large groups people data labellingthinking hiring bunch people label ton data best software specifically want use labelers,"['people', 'using', 'organize', 'large', 'groups', 'people', 'data', 'labellingthinking', 'hiring', 'bunch', 'people', 'label', 'ton', 'data', 'best', 'software', 'specifically', 'want', 'use', 'labelers']","['peopl', 'use', 'organ', 'larg', 'group', 'peopl', 'data', 'labellingthink', 'hire', 'bunch', 'peopl', 'label', 'ton', 'data', 'best', 'softwar', 'specif', 'want', 'use', 'label']"
6,7,7,Singularian2501,vz0by5,"[R] LM-Nav: Robotic Navigation with Large Pre-Trained Models of Language, Vision, and Action - Google 2022","Paper: [https://arxiv.org/abs/2207.04429](https://arxiv.org/abs/2207.04429)

[https://sites.google.com/view/lmnav](https://sites.google.com/view/lmnav)

Github: [https://github.com/blazejosinski/lm\_nav](https://github.com/blazejosinski/lm_nav)

Summery Video: [https://www.youtube.com/watch?v=wkVbuZQb\_5g](https://www.youtube.com/watch?v=wkVbuZQb_5g)

Abstract: 

>Goal-conditioned policies for robotic navigation can be trained on large, unannotated datasets, providing for good generalization to real-world settings. However, particularly in vision-based settings where specifying goals requires an image, this makes for an unnatural interface. Language provides a more convenient modality for communication with robots, but contemporary methods typically require expensive supervision, in the form of trajectories annotated with language descriptions. We present a system, LM-Nav, for robotic navigation that enjoys the benefits of training on unannotated large datasets of trajectories, while still providing a high-level interface to the user. Instead of utilizing a labeled instruction following dataset, we show that such a system can be constructed entirely out of pre-trained models for navigation (ViNG), image-language association (CLIP), and language modeling (GPT-3), without requiring any fine-tuning or language-annotated robot data. **We instantiate LM-Nav on a real-world mobile robot and demonstrate long-horizon navigation through complex, outdoor environments from natural language instructions**. For videos of our experiments, code release, and an interactive Colab notebook that runs in your browser, please check out our project page [this https URL](https://sites.google.com/view/lmnav) 

https://preview.redd.it/zwx7n9jgakb91.jpg?width=1084&format=pjpg&auto=webp&s=7ee54cadf81306c66cbb9cd2461addef52d3c90a

https://preview.redd.it/6axh7ajgakb91.jpg?width=1116&format=pjpg&auto=webp&s=de5d2e7376a1d64b58a417e9cd63d808a2a6851f

https://preview.redd.it/ysfuybjgakb91.jpg?width=554&format=pjpg&auto=webp&s=bed9d074cabf33f9b64e4dbf4027f7904bb8da61",0,16,2022-07-14 22:12:19, r  lm nav  robotic navigation with large pre trained models of language  vision  and action   google ,paper   https  https github   https summery video   https abstract   goal conditioned policies for robotic navigation can be trained on large  unannotated datasets  providing for good generalization to real world settings  however  particularly in vision based settings where specifying goals requires an image  this makes for an unnatural interface  language provides a more convenient modality for communication with robots  but contemporary methods typically require expensive supervision  in the form of trajectories annotated with language descriptions  we present a system  lm nav  for robotic navigation that enjoys the benefits of training on unannotated large datasets of trajectories  while still providing a high level interface to the user  instead of utilizing a labeled instruction following dataset  we show that such a system can be constructed entirely out of pre trained models for navigation  ving   image language association  clip   and language modeling  gpt    without requiring any fine tuning or language annotated robot data    we instantiate lm nav on a real world mobile robot and demonstrate long horizon navigation through complex  outdoor environments from natural language instructions    for videos of our experiments  code release  and an interactive colab notebook that runs in your browser  please check out our project page  this https url  https https https https   preview redd it ysfuybjgakb jpg width  format pjpg auto webp s beddcabffbedbffbbda,paper https https github https summery video https abstract goal conditioned policies robotic navigation trained large unannotated datasets providing good generalization real world settings however particularly vision based settings specifying goals requires image makes unnatural interface language provides convenient modality communication robots contemporary methods typically require expensive supervision form trajectories annotated language descriptions present system lm nav robotic navigation enjoys benefits training unannotated large datasets trajectories still providing high level interface user instead utilizing labeled instruction following dataset show system constructed entirely pre trained models navigation ving image language association clip language modeling gpt without requiring fine tuning language annotated robot data instantiate lm nav real world mobile robot demonstrate long horizon navigation complex outdoor environments natural language instructions videos experiments code release interactive colab notebook runs browser please check project page https url https https https https preview redd ysfuybjgakb jpg width format pjpg auto webp beddcabffbedbffbbda,r lm nav robotic navigation large pre trained models language vision action google,r lm nav robotic navigation large pre trained models language vision action googlepaper https https github https summery video https abstract goal conditioned policies robotic navigation trained large unannotated datasets providing good generalization real world settings however particularly vision based settings specifying goals requires image makes unnatural interface language provides convenient modality communication robots contemporary methods typically require expensive supervision form trajectories annotated language descriptions present system lm nav robotic navigation enjoys benefits training unannotated large datasets trajectories still providing high level interface user instead utilizing labeled instruction following dataset show system constructed entirely pre trained models navigation ving image language association clip language modeling gpt without requiring fine tuning language annotated robot data instantiate lm nav real world mobile robot demonstrate long horizon navigation complex outdoor environments natural language instructions videos experiments code release interactive colab notebook runs browser please check project page https url https https https https preview redd ysfuybjgakb jpg width format pjpg auto webp beddcabffbedbffbbda,"['r', 'lm', 'nav', 'robotic', 'navigation', 'large', 'pre', 'trained', 'models', 'language', 'vision', 'action', 'googlepaper', 'https', 'https', 'github', 'https', 'summery', 'video', 'https', 'abstract', 'goal', 'conditioned', 'policies', 'robotic', 'navigation', 'trained', 'large', 'unannotated', 'datasets', 'providing', 'good', 'generalization', 'real', 'world', 'settings', 'however', 'particularly', 'vision', 'based', 'settings', 'specifying', 'goals', 'requires', 'image', 'makes', 'unnatural', 'interface', 'language', 'provides', 'convenient', 'modality', 'communication', 'robots', 'contemporary', 'methods', 'typically', 'require', 'expensive', 'supervision', 'form', 'trajectories', 'annotated', 'language', 'descriptions', 'present', 'system', 'lm', 'nav', 'robotic', 'navigation', 'enjoys', 'benefits', 'training', 'unannotated', 'large', 'datasets', 'trajectories', 'still', 'providing', 'high', 'level', 'interface', 'user', 'instead', 'utilizing', 'labeled', 'instruction', 'following', 'dataset', 'show', 'system', 'constructed', 'entirely', 'pre', 'trained', 'models', 'navigation', 'ving', 'image', 'language', 'association', 'clip', 'language', 'modeling', 'gpt', 'without', 'requiring', 'fine', 'tuning', 'language', 'annotated', 'robot', 'data', 'instantiate', 'lm', 'nav', 'real', 'world', 'mobile', 'robot', 'demonstrate', 'long', 'horizon', 'navigation', 'complex', 'outdoor', 'environments', 'natural', 'language', 'instructions', 'videos', 'experiments', 'code', 'release', 'interactive', 'colab', 'notebook', 'runs', 'browser', 'please', 'check', 'project', 'page', 'https', 'url', 'https', 'https', 'https', 'https', 'preview', 'redd', 'ysfuybjgakb', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'beddcabffbedbffbbda']","['r', 'lm', 'nav', 'robot', 'navig', 'larg', 'pre', 'train', 'model', 'languag', 'vision', 'action', 'googlepap', 'http', 'http', 'github', 'http', 'summeri', 'video', 'http', 'abstract', 'goal', 'condit', 'polici', 'robot', 'navig', 'train', 'larg', 'unannot', 'dataset', 'provid', 'good', 'gener', 'real', 'world', 'set', 'howev', 'particularli', 'vision', 'base', 'set', 'specifi', 'goal', 'requir', 'imag', 'make', 'unnatur', 'interfac', 'languag', 'provid', 'conveni', 'modal', 'commun', 'robot', 'contemporari', 'method', 'typic', 'requir', 'expens', 'supervis', 'form', 'trajectori', 'annot', 'languag', 'descript', 'present', 'system', 'lm', 'nav', 'robot', 'navig', 'enjoy', 'benefit', 'train', 'unannot', 'larg', 'dataset', 'trajectori', 'still', 'provid', 'high', 'level', 'interfac', 'user', 'instead', 'util', 'label', 'instruct', 'follow', 'dataset', 'show', 'system', 'construct', 'entir', 'pre', 'train', 'model', 'navig', 'ving', 'imag', 'languag', 'associ', 'clip', 'languag', 'model', 'gpt', 'without', 'requir', 'fine', 'tune', 'languag', 'annot', 'robot', 'data', 'instanti', 'lm', 'nav', 'real', 'world', 'mobil', 'robot', 'demonstr', 'long', 'horizon', 'navig', 'complex', 'outdoor', 'environ', 'natur', 'languag', 'instruct', 'video', 'experi', 'code', 'releas', 'interact', 'colab', 'notebook', 'run', 'browser', 'pleas', 'check', 'project', 'page', 'http', 'url', 'http', 'http', 'http', 'http', 'preview', 'redd', 'ysfuybjgakb', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'beddcabffbedbffbbda']"
7,8,8,Emergency_Apricot_77,vyyht2,"[D] ""No language left behind"" A 200 language translation model by Meta AI","Just discovered this new model by Meta AI when browsing huggingface 

Paper: [https://ai.facebook.com/research/publications/no-language-left-behind-scaling-human-centered-machine-translation/](https://ai.facebook.com/research/publications/no-language-left-behind-scaling-human-centered-machine-translation/)

Model on HuggingFace: [https://huggingface.co/facebook/nllb-200-3.3B](https://huggingface.co/facebook/nllb-200-3.3B)

Code: [https://github.com/facebookresearch/fairseq/tree/nllb](https://github.com/facebookresearch/fairseq/tree/nllb) 

The largest Mixture-of-Experts model seems really interesting in its capabilities. What do you guys think ?",2,17,2022-07-14 20:54:11, d  no language left behind a  language translation model by meta ai,just discovered this new model by meta ai when browsing huggingface paper   https model on huggingface   https code   https the largest mixture of experts model seems really interesting in its capabilities  what do you guys think  ,discovered model meta ai browsing huggingface paper https model huggingface https code https largest mixture experts model seems really interesting capabilities guys think,language left behind language translation model meta ai,language left behind language translation model meta aidiscovered model meta ai browsing huggingface paper https model huggingface https code https largest mixture experts model seems really interesting capabilities guys think,"['language', 'left', 'behind', 'language', 'translation', 'model', 'meta', 'aidiscovered', 'model', 'meta', 'ai', 'browsing', 'huggingface', 'paper', 'https', 'model', 'huggingface', 'https', 'code', 'https', 'largest', 'mixture', 'experts', 'model', 'seems', 'really', 'interesting', 'capabilities', 'guys', 'think']","['languag', 'left', 'behind', 'languag', 'translat', 'model', 'meta', 'aidiscov', 'model', 'meta', 'ai', 'brows', 'huggingfac', 'paper', 'http', 'model', 'huggingfac', 'http', 'code', 'http', 'largest', 'mixtur', 'expert', 'model', 'seem', 'realli', 'interest', 'capabl', 'guy', 'think']"
8,9,9,EffectSizeQueen,vyewbj,[N] Andrej Karpathy is leaving Tesla,"Twitter thread:

https://twitter.com/karpathy/status/1547332300186066944",118,265,2022-07-14 03:18:38, n  andrej karpathy is leaving tesla,twitter thread https   twitter com karpathy status ,twitter thread https twitter com karpathy status,n andrej karpathy leaving tesla,n andrej karpathy leaving teslatwitter thread https twitter com karpathy status,"['n', 'andrej', 'karpathy', 'leaving', 'teslatwitter', 'thread', 'https', 'twitter', 'com', 'karpathy', 'status']","['n', 'andrej', 'karpathi', 'leav', 'teslatwitt', 'thread', 'http', 'twitter', 'com', 'karpathi', 'statu']"
9,10,10,madlad612,vzdvr5,[P] How to tackle Time-series Classification with a large number of categorical variables/attributes ( >100) with high cardinality? I'm open to discussing other ways as well.,I am predicting whether the particular event would occur or not in the next n-timeframes given the categorical variables with high cardinality. Please let me know if there is anything that we can do to tackle this problem.,1,0,2022-07-15 08:28:10, p  how to tackle time series classification with a large number of categorical variables attributes      with high cardinality  i m open to discussing other ways as well ,i am predicting whether the particular event would occur or not in the next n timeframes given the categorical variables with high cardinality  please let me know if there is anything that we can do to tackle this problem ,predicting whether particular event would occur next n timeframes given categorical variables high cardinality please let know anything tackle problem,p tackle time series classification large number categorical variables attributes high cardinality open discussing ways well,p tackle time series classification large number categorical variables attributes high cardinality open discussing ways wellpredicting whether particular event would occur next n timeframes given categorical variables high cardinality please let know anything tackle problem,"['p', 'tackle', 'time', 'series', 'classification', 'large', 'number', 'categorical', 'variables', 'attributes', 'high', 'cardinality', 'open', 'discussing', 'ways', 'wellpredicting', 'whether', 'particular', 'event', 'would', 'occur', 'next', 'n', 'timeframes', 'given', 'categorical', 'variables', 'high', 'cardinality', 'please', 'let', 'know', 'anything', 'tackle', 'problem']","['p', 'tackl', 'time', 'seri', 'classif', 'larg', 'number', 'categor', 'variabl', 'attribut', 'high', 'cardin', 'open', 'discuss', 'way', 'wellpredict', 'whether', 'particular', 'event', 'would', 'occur', 'next', 'n', 'timefram', 'given', 'categor', 'variabl', 'high', 'cardin', 'pleas', 'let', 'know', 'anyth', 'tackl', 'problem']"
10,11,11,Celestialdonuts,vzdhex,[D] ML architecture for adaptive setting suggestions in a stage-dependent program,"I've got a problem that I could use some insight on.

&#x200B;

Summary:

I need to design a ML architecture that suggests parameters to a program depending on the observed performance of the user. The program has a set number of stages and the objective of the program is to improve user performance as much as possible within the stage limit. 

&#x200B;

Problem description:

To provide an example, let's say we have 3 stages in the program and the user starts off at stage 1. The program takes two parameters at each stage that determine the difficulty of that stage: Alpha and Beta, which both range from \[0, 10\], inclusive. The user completes stage 1 and a summarization score on user performance is returned based on a radar chart produced by the program. For this example, let's say the score is a 3 out of 10. This radar chart display scores that reflect 6 specific skill components (similar to those character ability charts in video games). By the end of stage 3, we want the user's score to improve as much as possible and preferably to a 10. 

Currently, the two parameters are statically set (e.g. \[(A: 4.2, B: 5), (A: 6, B: 6.6), (A: 8, B: 8)\]) regardless of user performance but I want the parameters to be adaptively set depending on the performance of the user at the previous stage. If the user underperforms compared to the expected result at stage 2, the parameters for stage 3 will be scaled down accordingly to accommodate (e.g. \[A: 7.5, B: 7.5\] instead of 8, for example). Of course, if the user outperforms the expectations, the parameters will be scaled up (e.g. \[A: 8.3, B: 8.2\]). As of right now, the expectation for performance is an evenly linear increase from the initial score (3) to a perfect score (10) but this can change.

My initial idea is to create a recommender system and feed both the summary score and the 6 individual component scores into the model to return a personalized parameter suggestion for each stage. Would a recommender system be suitable or am I over-thinking and over-engineering the problem?",0,0,2022-07-15 08:07:52, d  ml architecture for adaptive setting suggestions in a stage dependent program,i ve got a problem that i could use some insight on   xb summary i need to design a ml architecture that suggests parameters to a program depending on the observed performance of the user  the program has a set number of stages and the objective of the program is to improve user performance as much as possible within the stage limit    xb problem description to provide an example  let s say we have  stages in the program and the user starts off at stage   the program takes two parameters at each stage that determine the difficulty of that stage  alpha and beta  which both range from         inclusive  the user completes stage  and a summarization score on user performance is returned based on a radar chart produced by the program  for this example  let s say the score is a  out of   this radar chart display scores that reflect  specific skill components  similar to those character ability charts in video games   by the end of stage   we want the user s score to improve as much as possible and preferably to a   currently  the two parameters are statically set  e g     a     b      a    b       a    b       regardless of user performance but i want the parameters to be adaptively set depending on the performance of the user at the previous stage  if the user underperforms compared to the expected result at stage   the parameters for stage  will be scaled down accordingly to accommodate  e g    a     b      instead of   for example   of course  if the user outperforms the expectations  the parameters will be scaled up  e g    a     b        as of right now  the expectation for performance is an evenly linear increase from the initial score    to a perfect score    but this can change my initial idea is to create a recommender system and feed both the summary score and the  individual component scores into the model to return a personalized parameter suggestion for each stage  would a recommender system be suitable or am i over thinking and over engineering the problem ,got problem could use insight xb summary need design ml architecture suggests parameters program depending observed performance user program set number stages objective program improve user performance much possible within stage limit xb problem description provide example let say stages program user starts stage program takes two parameters stage determine difficulty stage alpha beta range inclusive user completes stage summarization score user performance returned based radar chart produced program example let say score radar chart display scores reflect specific skill components similar character ability charts video games end stage want user score improve much possible preferably currently two parameters statically set e g b b b regardless user performance want parameters adaptively set depending performance user previous stage user underperforms compared expected result stage parameters stage scaled accordingly accommodate e g b instead example course user outperforms expectations parameters scaled e g b right expectation performance evenly linear increase initial score perfect score change initial idea create recommender system feed summary score individual component scores model return personalized parameter suggestion stage would recommender system suitable thinking engineering problem,ml architecture adaptive setting suggestions stage dependent program,ml architecture adaptive setting suggestions stage dependent programgot problem could use insight xb summary need design ml architecture suggests parameters program depending observed performance user program set number stages objective program improve user performance much possible within stage limit xb problem description provide example let say stages program user starts stage program takes two parameters stage determine difficulty stage alpha beta range inclusive user completes stage summarization score user performance returned based radar chart produced program example let say score radar chart display scores reflect specific skill components similar character ability charts video games end stage want user score improve much possible preferably currently two parameters statically set e g b b b regardless user performance want parameters adaptively set depending performance user previous stage user underperforms compared expected result stage parameters stage scaled accordingly accommodate e g b instead example course user outperforms expectations parameters scaled e g b right expectation performance evenly linear increase initial score perfect score change initial idea create recommender system feed summary score individual component scores model return personalized parameter suggestion stage would recommender system suitable thinking engineering problem,"['ml', 'architecture', 'adaptive', 'setting', 'suggestions', 'stage', 'dependent', 'programgot', 'problem', 'could', 'use', 'insight', 'xb', 'summary', 'need', 'design', 'ml', 'architecture', 'suggests', 'parameters', 'program', 'depending', 'observed', 'performance', 'user', 'program', 'set', 'number', 'stages', 'objective', 'program', 'improve', 'user', 'performance', 'much', 'possible', 'within', 'stage', 'limit', 'xb', 'problem', 'description', 'provide', 'example', 'let', 'say', 'stages', 'program', 'user', 'starts', 'stage', 'program', 'takes', 'two', 'parameters', 'stage', 'determine', 'difficulty', 'stage', 'alpha', 'beta', 'range', 'inclusive', 'user', 'completes', 'stage', 'summarization', 'score', 'user', 'performance', 'returned', 'based', 'radar', 'chart', 'produced', 'program', 'example', 'let', 'say', 'score', 'radar', 'chart', 'display', 'scores', 'reflect', 'specific', 'skill', 'components', 'similar', 'character', 'ability', 'charts', 'video', 'games', 'end', 'stage', 'want', 'user', 'score', 'improve', 'much', 'possible', 'preferably', 'currently', 'two', 'parameters', 'statically', 'set', 'e', 'g', 'b', 'b', 'b', 'regardless', 'user', 'performance', 'want', 'parameters', 'adaptively', 'set', 'depending', 'performance', 'user', 'previous', 'stage', 'user', 'underperforms', 'compared', 'expected', 'result', 'stage', 'parameters', 'stage', 'scaled', 'accordingly', 'accommodate', 'e', 'g', 'b', 'instead', 'example', 'course', 'user', 'outperforms', 'expectations', 'parameters', 'scaled', 'e', 'g', 'b', 'right', 'expectation', 'performance', 'evenly', 'linear', 'increase', 'initial', 'score', 'perfect', 'score', 'change', 'initial', 'idea', 'create', 'recommender', 'system', 'feed', 'summary', 'score', 'individual', 'component', 'scores', 'model', 'return', 'personalized', 'parameter', 'suggestion', 'stage', 'would', 'recommender', 'system', 'suitable', 'thinking', 'engineering', 'problem']","['ml', 'architectur', 'adapt', 'set', 'suggest', 'stage', 'depend', 'programgot', 'problem', 'could', 'use', 'insight', 'xb', 'summari', 'need', 'design', 'ml', 'architectur', 'suggest', 'paramet', 'program', 'depend', 'observ', 'perform', 'user', 'program', 'set', 'number', 'stage', 'object', 'program', 'improv', 'user', 'perform', 'much', 'possibl', 'within', 'stage', 'limit', 'xb', 'problem', 'descript', 'provid', 'exampl', 'let', 'say', 'stage', 'program', 'user', 'start', 'stage', 'program', 'take', 'two', 'paramet', 'stage', 'determin', 'difficulti', 'stage', 'alpha', 'beta', 'rang', 'inclus', 'user', 'complet', 'stage', 'summar', 'score', 'user', 'perform', 'return', 'base', 'radar', 'chart', 'produc', 'program', 'exampl', 'let', 'say', 'score', 'radar', 'chart', 'display', 'score', 'reflect', 'specif', 'skill', 'compon', 'similar', 'charact', 'abil', 'chart', 'video', 'game', 'end', 'stage', 'want', 'user', 'score', 'improv', 'much', 'possibl', 'prefer', 'current', 'two', 'paramet', 'static', 'set', 'e', 'g', 'b', 'b', 'b', 'regardless', 'user', 'perform', 'want', 'paramet', 'adapt', 'set', 'depend', 'perform', 'user', 'previou', 'stage', 'user', 'underperform', 'compar', 'expect', 'result', 'stage', 'paramet', 'stage', 'scale', 'accordingli', 'accommod', 'e', 'g', 'b', 'instead', 'exampl', 'cours', 'user', 'outperform', 'expect', 'paramet', 'scale', 'e', 'g', 'b', 'right', 'expect', 'perform', 'evenli', 'linear', 'increas', 'initi', 'score', 'perfect', 'score', 'chang', 'initi', 'idea', 'creat', 'recommend', 'system', 'feed', 'summari', 'score', 'individu', 'compon', 'score', 'model', 'return', 'person', 'paramet', 'suggest', 'stage', 'would', 'recommend', 'system', 'suitabl', 'think', 'engin', 'problem']"
11,12,12,ollie_wollie_rocks,vz1mmj,[Discussion] Code editor for transforming data/building ML pipelines,"Check out our new open source code editor for transforming data and building ML pipelines: [https://github.com/mage-ai/mage-ai](https://github.com/mage-ai/mage-ai)

If you’re available, I’d love to hop on a quick Zoom to help you get set up.

In the meantime, here is the install guide: [https://github.com/mage-ai/mage-ai#using-pip](https://github.com/mage-ai/mage-ai#using-pip) and a short tutorial: [https://github.com/mage-ai/mage-ai/blob/master/docs/tutorials/train\_titanic\_model/README.md](https://github.com/mage-ai/mage-ai/blob/master/docs/tutorials/train_titanic_model/README.md)

I’d love to get your feedback on whether this is useful to you or not. Thank you so much!",0,6,2022-07-14 23:07:57, discussion  code editor for transforming data building ml pipelines,check out our new open source code editor for transforming data and building ml pipelines   https if you re available  i d love to hop on a quick zoom to help you get set up in the meantime  here is the install guide   https i d love to get your feedback on whether this is useful to you or not  thank you so much ,check open source code editor transforming data building ml pipelines https available love hop quick zoom help get set meantime install guide https love get feedback whether useful thank much,discussion code editor transforming data building ml pipelines,discussion code editor transforming data building ml pipelinescheck open source code editor transforming data building ml pipelines https available love hop quick zoom help get set meantime install guide https love get feedback whether useful thank much,"['discussion', 'code', 'editor', 'transforming', 'data', 'building', 'ml', 'pipelinescheck', 'open', 'source', 'code', 'editor', 'transforming', 'data', 'building', 'ml', 'pipelines', 'https', 'available', 'love', 'hop', 'quick', 'zoom', 'help', 'get', 'set', 'meantime', 'install', 'guide', 'https', 'love', 'get', 'feedback', 'whether', 'useful', 'thank', 'much']","['discuss', 'code', 'editor', 'transform', 'data', 'build', 'ml', 'pipelinescheck', 'open', 'sourc', 'code', 'editor', 'transform', 'data', 'build', 'ml', 'pipelin', 'http', 'avail', 'love', 'hop', 'quick', 'zoom', 'help', 'get', 'set', 'meantim', 'instal', 'guid', 'http', 'love', 'get', 'feedback', 'whether', 'use', 'thank', 'much']"
12,13,13,fedetask,vz1a7u,[D] Best way to increase LSTM/GRU capacity,"LSTM and GRU have a fixed set of weights, that only depend on the size of the input and the size of the LSTM/GRU units. But what if I have the feeling that the parameters in the model are not enough to capture and process the data correctly? In other words, how do I increase the capacity of these models?

Some ideas that came to me are:

 \- Preprocess each vector of the sequence with another model, then feed the output vectors to the LSTM/GRU

\- Just use a larger number of units in the LSTM/GRU (however, this might create a big mismatch between the input and output size

\- Develop a LSTM/GRU that uses more than one layer in each step (e.g. a k-layer neural network instead of a weight matrix)

What do you think is the best? Do you know any other method?",2,2,2022-07-14 22:53:08, d  best way to increase lstm gru capacity,lstm and gru have a fixed set of weights  that only depend on the size of the input and the size of the lstm gru units  but what if i have the feeling that the parameters in the model are not enough to capture and process the data correctly  in other words  how do i increase the capacity of these models some ideas that came to me are     preprocess each vector of the sequence with another model  then feed the output vectors to the lstm gru   just use a larger number of units in the lstm gru  however  this might create a big mismatch between the input and output size   develop a lstm gru that uses more than one layer in each step  e g  a k layer neural network instead of a weight matrix what do you think is the best  do you know any other method ,lstm gru fixed set weights depend size input size lstm gru units feeling parameters model enough capture process data correctly increase capacity models ideas came preprocess vector sequence another model feed output vectors lstm gru use larger number units lstm gru however might create big mismatch input output size develop lstm gru uses one layer step e g k layer neural network instead weight matrix think best know method,best way increase lstm gru capacity,best way increase lstm gru capacitylstm gru fixed set weights depend size input size lstm gru units feeling parameters model enough capture process data correctly increase capacity models ideas came preprocess vector sequence another model feed output vectors lstm gru use larger number units lstm gru however might create big mismatch input output size develop lstm gru uses one layer step e g k layer neural network instead weight matrix think best know method,"['best', 'way', 'increase', 'lstm', 'gru', 'capacitylstm', 'gru', 'fixed', 'set', 'weights', 'depend', 'size', 'input', 'size', 'lstm', 'gru', 'units', 'feeling', 'parameters', 'model', 'enough', 'capture', 'process', 'data', 'correctly', 'increase', 'capacity', 'models', 'ideas', 'came', 'preprocess', 'vector', 'sequence', 'another', 'model', 'feed', 'output', 'vectors', 'lstm', 'gru', 'use', 'larger', 'number', 'units', 'lstm', 'gru', 'however', 'might', 'create', 'big', 'mismatch', 'input', 'output', 'size', 'develop', 'lstm', 'gru', 'uses', 'one', 'layer', 'step', 'e', 'g', 'k', 'layer', 'neural', 'network', 'instead', 'weight', 'matrix', 'think', 'best', 'know', 'method']","['best', 'way', 'increas', 'lstm', 'gru', 'capacitylstm', 'gru', 'fix', 'set', 'weight', 'depend', 'size', 'input', 'size', 'lstm', 'gru', 'unit', 'feel', 'paramet', 'model', 'enough', 'captur', 'process', 'data', 'correctli', 'increas', 'capac', 'model', 'idea', 'came', 'preprocess', 'vector', 'sequenc', 'anoth', 'model', 'feed', 'output', 'vector', 'lstm', 'gru', 'use', 'larger', 'number', 'unit', 'lstm', 'gru', 'howev', 'might', 'creat', 'big', 'mismatch', 'input', 'output', 'size', 'develop', 'lstm', 'gru', 'use', 'one', 'layer', 'step', 'e', 'g', 'k', 'layer', 'neural', 'network', 'instead', 'weight', 'matrix', 'think', 'best', 'know', 'method']"
13,14,14,IllustriousCicada603,vyub54,[D] Is sampling distractors from the same mini batch during training a good idea?,"Hello, I have a NLP Transformer model and for my case I want to add a binary classifier as an auxiliary task. I will give a random response and the ground truth labels to the classifier and expect from it to distinguish them.

Is it a good idea instead of modifying the dataset to just shift the current mini batch during training in order to generate distractors. For example let's say the batch size is 4.

We will have four response sequences in our batch: `[[1...], [2...], [3...], [4...]]`, so I can copy and shift them (by 2), for example: `[[3...], [4...], [1...], [2...]]`\` Then I can stack the ground truth and the shifted batch to get `[ [[1...], [3...]], [[2...], [4...]], [[3...], [1...]], [[4...], [2...]] ]` and feed that to the classifier where the labels are `[ [1, 0], [1, 0], [1, 0], [1, 0] ]`. Furthermore I can randomize the order of \`(truth, distractor)\` pairs in each batch and sometimes the labels will be `[1, 0]` and other times - `[0, 1]`.

Finally, if there's a concern that because of the dataloader order in a batch we may have related responses and not completely random ones - I would say that this is actually an advantage, because a classifier which can distinguish the right response compared to a related one is a stronger classifier.

Do you think this makes sense and what are the possible drawbacks?",0,2,2022-07-14 17:37:04, d  is sampling distractors from the same mini batch during training a good idea ,hello  i have a nlp transformer model and for my case i want to add a binary classifier as an auxiliary task  i will give a random response and the ground truth labels to the classifier and expect from it to distinguish them is it a good idea instead of modifying the dataset to just shift the current mini batch during training in order to generate distractors  for example let s say the batch size is  we will have four response sequences in our batch                                  so i can copy and shift them  by    for example                                   then i can stack the ground truth and the shifted batch to get                                                                      and feed that to the classifier where the labels are                               furthermore i can randomize the order of    truth  distractor    pairs in each batch and sometimes the labels will be        and other times          finally  if there s a concern that because of the dataloader order in a batch we may have related responses and not completely random ones   i would say that this is actually an advantage  because a classifier which can distinguish the right response compared to a related one is a stronger classifier do you think this makes sense and what are the possible drawbacks ,hello nlp transformer model case want binary classifier auxiliary task give random response ground truth labels classifier expect distinguish good idea instead modifying dataset shift current mini batch training order generate distractors example let say batch size four response sequences batch copy shift example stack ground truth shifted batch get feed classifier labels furthermore randomize order truth distractor pairs batch sometimes labels times finally concern dataloader order batch may related responses completely random ones would say actually advantage classifier distinguish right response compared related one stronger classifier think makes sense possible drawbacks,sampling distractors mini batch training good idea,sampling distractors mini batch training good ideahello nlp transformer model case want binary classifier auxiliary task give random response ground truth labels classifier expect distinguish good idea instead modifying dataset shift current mini batch training order generate distractors example let say batch size four response sequences batch copy shift example stack ground truth shifted batch get feed classifier labels furthermore randomize order truth distractor pairs batch sometimes labels times finally concern dataloader order batch may related responses completely random ones would say actually advantage classifier distinguish right response compared related one stronger classifier think makes sense possible drawbacks,"['sampling', 'distractors', 'mini', 'batch', 'training', 'good', 'ideahello', 'nlp', 'transformer', 'model', 'case', 'want', 'binary', 'classifier', 'auxiliary', 'task', 'give', 'random', 'response', 'ground', 'truth', 'labels', 'classifier', 'expect', 'distinguish', 'good', 'idea', 'instead', 'modifying', 'dataset', 'shift', 'current', 'mini', 'batch', 'training', 'order', 'generate', 'distractors', 'example', 'let', 'say', 'batch', 'size', 'four', 'response', 'sequences', 'batch', 'copy', 'shift', 'example', 'stack', 'ground', 'truth', 'shifted', 'batch', 'get', 'feed', 'classifier', 'labels', 'furthermore', 'randomize', 'order', 'truth', 'distractor', 'pairs', 'batch', 'sometimes', 'labels', 'times', 'finally', 'concern', 'dataloader', 'order', 'batch', 'may', 'related', 'responses', 'completely', 'random', 'ones', 'would', 'say', 'actually', 'advantage', 'classifier', 'distinguish', 'right', 'response', 'compared', 'related', 'one', 'stronger', 'classifier', 'think', 'makes', 'sense', 'possible', 'drawbacks']","['sampl', 'distractor', 'mini', 'batch', 'train', 'good', 'ideahello', 'nlp', 'transform', 'model', 'case', 'want', 'binari', 'classifi', 'auxiliari', 'task', 'give', 'random', 'respons', 'ground', 'truth', 'label', 'classifi', 'expect', 'distinguish', 'good', 'idea', 'instead', 'modifi', 'dataset', 'shift', 'current', 'mini', 'batch', 'train', 'order', 'gener', 'distractor', 'exampl', 'let', 'say', 'batch', 'size', 'four', 'respons', 'sequenc', 'batch', 'copi', 'shift', 'exampl', 'stack', 'ground', 'truth', 'shift', 'batch', 'get', 'feed', 'classifi', 'label', 'furthermor', 'random', 'order', 'truth', 'distractor', 'pair', 'batch', 'sometim', 'label', 'time', 'final', 'concern', 'dataload', 'order', 'batch', 'may', 'relat', 'respons', 'complet', 'random', 'one', 'would', 'say', 'actual', 'advantag', 'classifi', 'distinguish', 'right', 'respons', 'compar', 'relat', 'one', 'stronger', 'classifi', 'think', 'make', 'sens', 'possibl', 'drawback']"
14,15,15,chaoyu,vyfit6,[P] Introducing BentoML 1.0 - A faster way to ship your models to production,"Hi everyone! I'm excited to share some news from the [BentoML](https://github.com/bentoml) team.

When we first open sourced the BentoML project [in 2019](https://www.reddit.com/r/MachineLearning/comments/izqelx/p_bentoml_090_the_easiest_way_to_create_machine/) and [shared it ](https://www.reddit.com/r/MachineLearning/comments/g1cfre/p_bentoml_an_opensource_platform_for/)[with the community](https://www.reddit.com/r/MachineLearning/comments/g1cfre/p_bentoml_an_opensource_platform_for/), our vision was to create an open platform that simplifies machine learning model serving and provides a solid foundation for ML teams to operate ML at production scale. And after years of working together with our community towards that goal, we’re thrilled to announce the general availability of BentoML 1.0!  


What's new in BentoML 1.0?

* Simplify model packaging and management, both locally and a centralized model repository for teams.
* A Python-first architecture that scales with powerful optimizations, including parallel inference, adaptive batching, and support for accelerated runtimes.
* Introducing [Yatai for BentoML](https://github.com/bentoml/Yatai): Production-first ML platform on Kubernetes

&#x200B;

To learn more:

* Introducing BentoML 1.0 Blog post: [https://modelserving.com/blog/introducing-bentoml-10](https://modelserving.com/blog/introducing-bentoml-10)
* BentoML Tutorial: [https://docs.bentoml.org/en/latest/tutorial.html](https://docs.bentoml.org/en/latest/tutorial.html)
* Github Page: [https://github.com/bentoml/BentoML](https://github.com/bentoml/BentoML)
* Documentation: [https://docs.bentoml.org/](https://docs.bentoml.org/)",2,17,2022-07-14 03:45:28, p  introducing bentoml     a faster way to ship your models to production,hi everyone  i m excited to share some news from the  bentoml  https when we first open sourced the bentoml project  in   https what s new in bentoml     simplify model packaging and management  both locally and a centralized model repository for teams   a python first architecture that scales with powerful optimizations  including parallel inference  adaptive batching  and support for accelerated runtimes   introducing  yatai for bentoml  https   xb to learn more   introducing bentoml   blog post   https   bentoml tutorial   https   github page   https   documentation   https   docs bentoml org   https   docs bentoml org  ,hi everyone excited share news bentoml https first open sourced bentoml project https bentoml simplify model packaging management locally centralized model repository teams python first architecture scales powerful optimizations including parallel inference adaptive batching support accelerated runtimes introducing yatai bentoml https xb learn introducing bentoml blog post https bentoml tutorial https github page https documentation https docs bentoml org https docs bentoml org,p introducing bentoml faster way ship models production,p introducing bentoml faster way ship models productionhi everyone excited share news bentoml https first open sourced bentoml project https bentoml simplify model packaging management locally centralized model repository teams python first architecture scales powerful optimizations including parallel inference adaptive batching support accelerated runtimes introducing yatai bentoml https xb learn introducing bentoml blog post https bentoml tutorial https github page https documentation https docs bentoml org https docs bentoml org,"['p', 'introducing', 'bentoml', 'faster', 'way', 'ship', 'models', 'productionhi', 'everyone', 'excited', 'share', 'news', 'bentoml', 'https', 'first', 'open', 'sourced', 'bentoml', 'project', 'https', 'bentoml', 'simplify', 'model', 'packaging', 'management', 'locally', 'centralized', 'model', 'repository', 'teams', 'python', 'first', 'architecture', 'scales', 'powerful', 'optimizations', 'including', 'parallel', 'inference', 'adaptive', 'batching', 'support', 'accelerated', 'runtimes', 'introducing', 'yatai', 'bentoml', 'https', 'xb', 'learn', 'introducing', 'bentoml', 'blog', 'post', 'https', 'bentoml', 'tutorial', 'https', 'github', 'page', 'https', 'documentation', 'https', 'docs', 'bentoml', 'org', 'https', 'docs', 'bentoml', 'org']","['p', 'introduc', 'bentoml', 'faster', 'way', 'ship', 'model', 'productionhi', 'everyon', 'excit', 'share', 'news', 'bentoml', 'http', 'first', 'open', 'sourc', 'bentoml', 'project', 'http', 'bentoml', 'simplifi', 'model', 'packag', 'manag', 'local', 'central', 'model', 'repositori', 'team', 'python', 'first', 'architectur', 'scale', 'power', 'optim', 'includ', 'parallel', 'infer', 'adapt', 'batch', 'support', 'acceler', 'runtim', 'introduc', 'yatai', 'bentoml', 'http', 'xb', 'learn', 'introduc', 'bentoml', 'blog', 'post', 'http', 'bentoml', 'tutori', 'http', 'github', 'page', 'http', 'document', 'http', 'doc', 'bentoml', 'org', 'http', 'doc', 'bentoml', 'org']"
15,16,16,fanconic,vxw3s4,"[R] So someone actually peer-reviewed this and thought ""yeah, looks good""?","It looks like chronic kidney disease diagnosis has been solved in this paper: [https://ieeexplore.ieee.org/document/8693581](https://ieeexplore.ieee.org/document/8693581)

I mean no disrespect to the authors, but this publication makes me slightly doubt the peer-review system. Or I am just such an amateur, that I am not seeing the brilliance behind this paper, which is also possible.

Have a read through it yourselves",77,237,2022-07-13 11:39:59, r  so someone actually peer reviewed this and thought yeah  looks good ,it looks like chronic kidney disease diagnosis has been solved in this paper   https i mean no disrespect to the authors  but this publication makes me slightly doubt the peer review system  or i am just such an amateur  that i am not seeing the brilliance behind this paper  which is also possible have a read through it yourselves,looks like chronic kidney disease diagnosis solved paper https mean disrespect authors publication makes slightly doubt peer review system amateur seeing brilliance behind paper also possible read,r someone actually peer reviewed thought yeah looks good,r someone actually peer reviewed thought yeah looks goodlooks like chronic kidney disease diagnosis solved paper https mean disrespect authors publication makes slightly doubt peer review system amateur seeing brilliance behind paper also possible read,"['r', 'someone', 'actually', 'peer', 'reviewed', 'thought', 'yeah', 'looks', 'goodlooks', 'like', 'chronic', 'kidney', 'disease', 'diagnosis', 'solved', 'paper', 'https', 'mean', 'disrespect', 'authors', 'publication', 'makes', 'slightly', 'doubt', 'peer', 'review', 'system', 'amateur', 'seeing', 'brilliance', 'behind', 'paper', 'also', 'possible', 'read']","['r', 'someon', 'actual', 'peer', 'review', 'thought', 'yeah', 'look', 'goodlook', 'like', 'chronic', 'kidney', 'diseas', 'diagnosi', 'solv', 'paper', 'http', 'mean', 'disrespect', 'author', 'public', 'make', 'slightli', 'doubt', 'peer', 'review', 'system', 'amateur', 'see', 'brillianc', 'behind', 'paper', 'also', 'possibl', 'read']"
16,17,17,tacixat,vye9fa,[D] I made a site for collaborative image labeling,"I recently launched [https://mekabytes.com](https://mekabytes.com/). The idea is to treat datasets like subreddits where users can come together to build the stuff they want to see.

For the datasets there is a github-style landing page with a README to help give guidance on the goals, what images the dataset wants, and any labeling guidelines. There is also a reddit-style comment system where you can reference specific annotations. The idea with that is to provide feedback to help people learn.

The coolest part (IMO) is the versioning system. All annotations are versioned and approved by a moderator, gating data quality kind of like a code review. This versioning allows the dataset to be rolled back to any point in time which will help reproduce research even as the dataset continues to evolve.

The dataset releases will be open under a creative commons license (BY-NC-SA). To help cover hosting the releases are downloadable for $5 + $1/GB. Basically you can use it for research, personal projects, and share freely once you have it.

There is still a ton of stuff to do and I don't even have my first user yet! I've been using it for the last week or so and cleaning up the UX. You can actually annotate decently on mobile.

Right now it supports classification and object detection (bounding boxes). I hope to add a free text field in the near future after some niceties like pagination and comment notifications.

I would love some feedback if you have any!",6,11,2022-07-14 02:51:25, d  i made a site for collaborative image labeling,i recently launched  https for the datasets there is a github style landing page with a readme to help give guidance on the goals  what images the dataset wants  and any labeling guidelines  there is also a reddit style comment system where you can reference specific annotations  the idea with that is to provide feedback to help people learn the coolest part  imo  is the versioning system  all annotations are versioned and approved by a moderator  gating data quality kind of like a code review  this versioning allows the dataset to be rolled back to any point in time which will help reproduce research even as the dataset continues to evolve the dataset releases will be open under a creative commons license  by nc sa   to help cover hosting the releases are downloadable for       gb  basically you can use it for research  personal projects  and share freely once you have it there is still a ton of stuff to do and i don t even have my first user yet  i ve been using it for the last week or so and cleaning up the ux  you can actually annotate decently on mobile right now it supports classification and object detection  bounding boxes   i hope to add a free text field in the near future after some niceties like pagination and comment notifications i would love some feedback if you have any ,recently launched https datasets github style landing page readme help give guidance goals images dataset wants labeling guidelines also reddit style comment system reference specific annotations idea provide feedback help people learn coolest part imo versioning system annotations versioned approved moderator gating data quality kind like code review versioning allows dataset rolled back point time help reproduce research even dataset continues evolve dataset releases open creative commons license nc sa help cover hosting releases downloadable gb basically use research personal projects share freely still ton stuff even first user yet using last week cleaning ux actually annotate decently mobile right supports classification object detection bounding boxes hope free text field near future niceties like pagination comment notifications would love feedback,made site collaborative image labeling,made site collaborative image labelingrecently launched https datasets github style landing page readme help give guidance goals images dataset wants labeling guidelines also reddit style comment system reference specific annotations idea provide feedback help people learn coolest part imo versioning system annotations versioned approved moderator gating data quality kind like code review versioning allows dataset rolled back point time help reproduce research even dataset continues evolve dataset releases open creative commons license nc sa help cover hosting releases downloadable gb basically use research personal projects share freely still ton stuff even first user yet using last week cleaning ux actually annotate decently mobile right supports classification object detection bounding boxes hope free text field near future niceties like pagination comment notifications would love feedback,"['made', 'site', 'collaborative', 'image', 'labelingrecently', 'launched', 'https', 'datasets', 'github', 'style', 'landing', 'page', 'readme', 'help', 'give', 'guidance', 'goals', 'images', 'dataset', 'wants', 'labeling', 'guidelines', 'also', 'reddit', 'style', 'comment', 'system', 'reference', 'specific', 'annotations', 'idea', 'provide', 'feedback', 'help', 'people', 'learn', 'coolest', 'part', 'imo', 'versioning', 'system', 'annotations', 'versioned', 'approved', 'moderator', 'gating', 'data', 'quality', 'kind', 'like', 'code', 'review', 'versioning', 'allows', 'dataset', 'rolled', 'back', 'point', 'time', 'help', 'reproduce', 'research', 'even', 'dataset', 'continues', 'evolve', 'dataset', 'releases', 'open', 'creative', 'commons', 'license', 'nc', 'sa', 'help', 'cover', 'hosting', 'releases', 'downloadable', 'gb', 'basically', 'use', 'research', 'personal', 'projects', 'share', 'freely', 'still', 'ton', 'stuff', 'even', 'first', 'user', 'yet', 'using', 'last', 'week', 'cleaning', 'ux', 'actually', 'annotate', 'decently', 'mobile', 'right', 'supports', 'classification', 'object', 'detection', 'bounding', 'boxes', 'hope', 'free', 'text', 'field', 'near', 'future', 'niceties', 'like', 'pagination', 'comment', 'notifications', 'would', 'love', 'feedback']","['made', 'site', 'collabor', 'imag', 'labelingrec', 'launch', 'http', 'dataset', 'github', 'style', 'land', 'page', 'readm', 'help', 'give', 'guidanc', 'goal', 'imag', 'dataset', 'want', 'label', 'guidelin', 'also', 'reddit', 'style', 'comment', 'system', 'refer', 'specif', 'annot', 'idea', 'provid', 'feedback', 'help', 'peopl', 'learn', 'coolest', 'part', 'imo', 'version', 'system', 'annot', 'version', 'approv', 'moder', 'gate', 'data', 'qualiti', 'kind', 'like', 'code', 'review', 'version', 'allow', 'dataset', 'roll', 'back', 'point', 'time', 'help', 'reproduc', 'research', 'even', 'dataset', 'continu', 'evolv', 'dataset', 'releas', 'open', 'creativ', 'common', 'licens', 'nc', 'sa', 'help', 'cover', 'host', 'releas', 'download', 'gb', 'basic', 'use', 'research', 'person', 'project', 'share', 'freeli', 'still', 'ton', 'stuff', 'even', 'first', 'user', 'yet', 'use', 'last', 'week', 'clean', 'ux', 'actual', 'annot', 'decent', 'mobil', 'right', 'support', 'classif', 'object', 'detect', 'bound', 'box', 'hope', 'free', 'text', 'field', 'near', 'futur', 'niceti', 'like', 'pagin', 'comment', 'notif', 'would', 'love', 'feedback']"
17,18,18,yuzheyang,vyhn3g,[R] How to learn imbalanced data arising from multiple domains?,"Hello everyone! Happy to share our new work on learning from multi-domain imbalanced data. This work was recently accepted at ECCV 2022.

Data imbalance is ubiquitous and inherent in the real world. Existing methods for dealing with imbalanced data/long-tailed distribution are only for **single domain**, that is, the data originates from the same domain; however, natural data can originate from ***distinct*** **domains**, where a minority class in one domain could have abundant instances from other domains. Effectively utilizing data from different domains is likely to improve the performance of long-tail learning over all domains. This paper promotes the paradigm of the traditional imbalanced classification problem and generalizes it from **single** domain to **multiple domains**.

We formulate the problem of **Multi-Domain Long-Tailed Recognition (MDLT)** as learning from multi-domain imbalanced data, with each domain having its own imbalanced label distribution, and generalizing to a test set that is balanced over ***all domain-class pairs***. MDLT aims to learn from imbalanced data from multiple distinct domains, tackle *label imbalance*, *domain shift*, and *divergent label distributions across domains*, and generalize to the entire set of classes over all domains.

We first propose the ***domain-class transferability graph***, which quantifies the transferability between different domain-class pairs under data imbalance. In this graph, each node refers to a domain-class pair, and each edge refers to the distance between two domain-class pairs in the embedding space. We show that the transferability graph dictates the performance of imbalanced learning across domains. Inspired by this, we design **BoDA**, a loss function that theoretically tracks the upper-bound of transferability statistics to improve the model performance.

Interestingly, we also found that ***addressing in-domain data imbalance improves out-of-domain generalization*** (known as domain generalization, DG). Our analysis showed that data imbalance is an intrinsic problem in DG, but has been overlooked by past works. The intriguing results shed light on **how label imbalance can affect out-of-distribution generalization**, and highlight the importance of **integrating label imbalance for practical DG algorithm design**.

Check out the links below for more details:

* **Paper**: [https://arxiv.org/abs/2203.09513](https://arxiv.org/abs/2203.09513)
* **Code** (+ dataset + models): [https://github.com/YyzHarry/multi-domain-imbalance](https://github.com/YyzHarry/multi-domain-imbalance)
* **Blog post** (check out for in-depth details!): [TowardsDataScience](https://towardsdatascience.com/how-to-learn-imbalanced-data-arising-from-multiple-domains-7d0c0d6e3c17)

&#x200B;

[Multi-Domain Long-Tailed Recognition \(MDLT\) aims to learn from imbalanced data from multiple distinct domains, tackle label imbalance, domain shift, and divergent label distributions across domains, and generalize to the entire set of classes over all domains.](https://i.redd.it/4zefxq759fb91.gif)",2,7,2022-07-14 05:21:26, r  how to learn imbalanced data arising from multiple domains ,hello everyone  happy to share our new work on learning from multi domain imbalanced data  this work was recently accepted at eccv  data imbalance is ubiquitous and inherent in the real world  existing methods for dealing with imbalanced data long tailed distribution are only for   single domain    that is  the data originates from the same domain  however  natural data can originate from    distinct      domains    where a minority class in one domain could have abundant instances from other domains  effectively utilizing data from different domains is likely to improve the performance of long tail learning over all domains  this paper promotes the paradigm of the traditional imbalanced classification problem and generalizes it from   single   domain to   multiple domains   we formulate the problem of   multi domain long tailed recognition  mdlt    as learning from multi domain imbalanced data  with each domain having its own imbalanced label distribution  and generalizing to a test set that is balanced over    all domain class pairs     mdlt aims to learn from imbalanced data from multiple distinct domains  tackle  label imbalance    domain shift   and  divergent label distributions across domains   and generalize to the entire set of classes over all domains we first propose the    domain class transferability graph     which quantifies the transferability between different domain class pairs under data imbalance  in this graph  each node refers to a domain class pair  and each edge refers to the distance between two domain class pairs in the embedding space  we show that the transferability graph dictates the performance of imbalanced learning across domains  inspired by this  we design   boda    a loss function that theoretically tracks the upper bound of transferability statistics to improve the model performance interestingly  we also found that    addressing in domain data imbalance improves out of domain generalization     known as domain generalization  dg   our analysis showed that data imbalance is an intrinsic problem in dg  but has been overlooked by past works  the intriguing results shed light on   how label imbalance can affect out of distribution generalization    and highlight the importance of   integrating label imbalance for practical dg algorithm design   check out the links below for more details     paper     https     code      dataset   models    https     blog post    check out for in depth details     towardsdatascience  https   xb  multi domain long tailed recognition   mdlt   aims to learn from imbalanced data from multiple distinct domains  tackle label imbalance  domain shift  and divergent label distributions across domains  and generalize to the entire set of classes over all domains   https   i redd it zefxqfb gif ,hello everyone happy share work learning multi domain imbalanced data work recently accepted eccv data imbalance ubiquitous inherent real world existing methods dealing imbalanced data long tailed distribution single domain data originates domain however natural data originate distinct domains minority class one domain could abundant instances domains effectively utilizing data different domains likely improve performance long tail learning domains paper promotes paradigm traditional imbalanced classification problem generalizes single domain multiple domains formulate problem multi domain long tailed recognition mdlt learning multi domain imbalanced data domain imbalanced label distribution generalizing test set balanced domain class pairs mdlt aims learn imbalanced data multiple distinct domains tackle label imbalance domain shift divergent label distributions across domains generalize entire set classes domains first propose domain class transferability graph quantifies transferability different domain class pairs data imbalance graph node refers domain class pair edge refers distance two domain class pairs embedding space show transferability graph dictates performance imbalanced learning across domains inspired design boda loss function theoretically tracks upper bound transferability statistics improve model performance interestingly also found addressing domain data imbalance improves domain generalization known domain generalization dg analysis showed data imbalance intrinsic problem dg overlooked past works intriguing results shed light label imbalance affect distribution generalization highlight importance integrating label imbalance practical dg algorithm design check links details paper https code dataset models https blog post check depth details towardsdatascience https xb multi domain long tailed recognition mdlt aims learn imbalanced data multiple distinct domains tackle label imbalance domain shift divergent label distributions across domains generalize entire set classes domains https redd zefxqfb gif,r learn imbalanced data arising multiple domains,r learn imbalanced data arising multiple domainshello everyone happy share work learning multi domain imbalanced data work recently accepted eccv data imbalance ubiquitous inherent real world existing methods dealing imbalanced data long tailed distribution single domain data originates domain however natural data originate distinct domains minority class one domain could abundant instances domains effectively utilizing data different domains likely improve performance long tail learning domains paper promotes paradigm traditional imbalanced classification problem generalizes single domain multiple domains formulate problem multi domain long tailed recognition mdlt learning multi domain imbalanced data domain imbalanced label distribution generalizing test set balanced domain class pairs mdlt aims learn imbalanced data multiple distinct domains tackle label imbalance domain shift divergent label distributions across domains generalize entire set classes domains first propose domain class transferability graph quantifies transferability different domain class pairs data imbalance graph node refers domain class pair edge refers distance two domain class pairs embedding space show transferability graph dictates performance imbalanced learning across domains inspired design boda loss function theoretically tracks upper bound transferability statistics improve model performance interestingly also found addressing domain data imbalance improves domain generalization known domain generalization dg analysis showed data imbalance intrinsic problem dg overlooked past works intriguing results shed light label imbalance affect distribution generalization highlight importance integrating label imbalance practical dg algorithm design check links details paper https code dataset models https blog post check depth details towardsdatascience https xb multi domain long tailed recognition mdlt aims learn imbalanced data multiple distinct domains tackle label imbalance domain shift divergent label distributions across domains generalize entire set classes domains https redd zefxqfb gif,"['r', 'learn', 'imbalanced', 'data', 'arising', 'multiple', 'domainshello', 'everyone', 'happy', 'share', 'work', 'learning', 'multi', 'domain', 'imbalanced', 'data', 'work', 'recently', 'accepted', 'eccv', 'data', 'imbalance', 'ubiquitous', 'inherent', 'real', 'world', 'existing', 'methods', 'dealing', 'imbalanced', 'data', 'long', 'tailed', 'distribution', 'single', 'domain', 'data', 'originates', 'domain', 'however', 'natural', 'data', 'originate', 'distinct', 'domains', 'minority', 'class', 'one', 'domain', 'could', 'abundant', 'instances', 'domains', 'effectively', 'utilizing', 'data', 'different', 'domains', 'likely', 'improve', 'performance', 'long', 'tail', 'learning', 'domains', 'paper', 'promotes', 'paradigm', 'traditional', 'imbalanced', 'classification', 'problem', 'generalizes', 'single', 'domain', 'multiple', 'domains', 'formulate', 'problem', 'multi', 'domain', 'long', 'tailed', 'recognition', 'mdlt', 'learning', 'multi', 'domain', 'imbalanced', 'data', 'domain', 'imbalanced', 'label', 'distribution', 'generalizing', 'test', 'set', 'balanced', 'domain', 'class', 'pairs', 'mdlt', 'aims', 'learn', 'imbalanced', 'data', 'multiple', 'distinct', 'domains', 'tackle', 'label', 'imbalance', 'domain', 'shift', 'divergent', 'label', 'distributions', 'across', 'domains', 'generalize', 'entire', 'set', 'classes', 'domains', 'first', 'propose', 'domain', 'class', 'transferability', 'graph', 'quantifies', 'transferability', 'different', 'domain', 'class', 'pairs', 'data', 'imbalance', 'graph', 'node', 'refers', 'domain', 'class', 'pair', 'edge', 'refers', 'distance', 'two', 'domain', 'class', 'pairs', 'embedding', 'space', 'show', 'transferability', 'graph', 'dictates', 'performance', 'imbalanced', 'learning', 'across', 'domains', 'inspired', 'design', 'boda', 'loss', 'function', 'theoretically', 'tracks', 'upper', 'bound', 'transferability', 'statistics', 'improve', 'model', 'performance', 'interestingly', 'also', 'found', 'addressing', 'domain', 'data', 'imbalance', 'improves', 'domain', 'generalization', 'known', 'domain', 'generalization', 'dg', 'analysis', 'showed', 'data', 'imbalance', 'intrinsic', 'problem', 'dg', 'overlooked', 'past', 'works', 'intriguing', 'results', 'shed', 'light', 'label', 'imbalance', 'affect', 'distribution', 'generalization', 'highlight', 'importance', 'integrating', 'label', 'imbalance', 'practical', 'dg', 'algorithm', 'design', 'check', 'links', 'details', 'paper', 'https', 'code', 'dataset', 'models', 'https', 'blog', 'post', 'check', 'depth', 'details', 'towardsdatascience', 'https', 'xb', 'multi', 'domain', 'long', 'tailed', 'recognition', 'mdlt', 'aims', 'learn', 'imbalanced', 'data', 'multiple', 'distinct', 'domains', 'tackle', 'label', 'imbalance', 'domain', 'shift', 'divergent', 'label', 'distributions', 'across', 'domains', 'generalize', 'entire', 'set', 'classes', 'domains', 'https', 'redd', 'zefxqfb', 'gif']","['r', 'learn', 'imbalanc', 'data', 'aris', 'multipl', 'domainshello', 'everyon', 'happi', 'share', 'work', 'learn', 'multi', 'domain', 'imbalanc', 'data', 'work', 'recent', 'accept', 'eccv', 'data', 'imbal', 'ubiquit', 'inher', 'real', 'world', 'exist', 'method', 'deal', 'imbalanc', 'data', 'long', 'tail', 'distribut', 'singl', 'domain', 'data', 'origin', 'domain', 'howev', 'natur', 'data', 'origin', 'distinct', 'domain', 'minor', 'class', 'one', 'domain', 'could', 'abund', 'instanc', 'domain', 'effect', 'util', 'data', 'differ', 'domain', 'like', 'improv', 'perform', 'long', 'tail', 'learn', 'domain', 'paper', 'promot', 'paradigm', 'tradit', 'imbalanc', 'classif', 'problem', 'gener', 'singl', 'domain', 'multipl', 'domain', 'formul', 'problem', 'multi', 'domain', 'long', 'tail', 'recognit', 'mdlt', 'learn', 'multi', 'domain', 'imbalanc', 'data', 'domain', 'imbalanc', 'label', 'distribut', 'gener', 'test', 'set', 'balanc', 'domain', 'class', 'pair', 'mdlt', 'aim', 'learn', 'imbalanc', 'data', 'multipl', 'distinct', 'domain', 'tackl', 'label', 'imbal', 'domain', 'shift', 'diverg', 'label', 'distribut', 'across', 'domain', 'gener', 'entir', 'set', 'class', 'domain', 'first', 'propos', 'domain', 'class', 'transfer', 'graph', 'quantifi', 'transfer', 'differ', 'domain', 'class', 'pair', 'data', 'imbal', 'graph', 'node', 'refer', 'domain', 'class', 'pair', 'edg', 'refer', 'distanc', 'two', 'domain', 'class', 'pair', 'embed', 'space', 'show', 'transfer', 'graph', 'dictat', 'perform', 'imbalanc', 'learn', 'across', 'domain', 'inspir', 'design', 'boda', 'loss', 'function', 'theoret', 'track', 'upper', 'bound', 'transfer', 'statist', 'improv', 'model', 'perform', 'interestingli', 'also', 'found', 'address', 'domain', 'data', 'imbal', 'improv', 'domain', 'gener', 'known', 'domain', 'gener', 'dg', 'analysi', 'show', 'data', 'imbal', 'intrins', 'problem', 'dg', 'overlook', 'past', 'work', 'intrigu', 'result', 'shed', 'light', 'label', 'imbal', 'affect', 'distribut', 'gener', 'highlight', 'import', 'integr', 'label', 'imbal', 'practic', 'dg', 'algorithm', 'design', 'check', 'link', 'detail', 'paper', 'http', 'code', 'dataset', 'model', 'http', 'blog', 'post', 'check', 'depth', 'detail', 'towardsdatasci', 'http', 'xb', 'multi', 'domain', 'long', 'tail', 'recognit', 'mdlt', 'aim', 'learn', 'imbalanc', 'data', 'multipl', 'distinct', 'domain', 'tackl', 'label', 'imbal', 'domain', 'shift', 'diverg', 'label', 'distribut', 'across', 'domain', 'gener', 'entir', 'set', 'class', 'domain', 'http', 'redd', 'zefxqfb', 'gif']"
18,19,19,MonLiH,vxo5nb,[N] BigScience Releases their 176 Billion Parameter Open-access Multilingual Language Model,"[BigScience](https://bigscience.huggingface.co/) recently released their new open-access (with weights) massive 176B language model that looks incredibly promising.The size is comparable to OpenAI's largest GPT-3 model. More info about the model can be found on [BigScience's blog](https://bigscience.huggingface.co/blog/bloom).

You can play with the model interactively, for free(!) on [Huggingface](https://huggingface.co/bigscience/bloom).",33,181,2022-07-13 04:30:03, n  bigscience releases their  billion parameter open access multilingual language model, bigscience  https you can play with the model interactively  for free    on  huggingface  https   huggingface co bigscience bloom  ,bigscience https play model interactively free huggingface https huggingface co bigscience bloom,n bigscience releases billion parameter open access multilingual language model,n bigscience releases billion parameter open access multilingual language modelbigscience https play model interactively free huggingface https huggingface co bigscience bloom,"['n', 'bigscience', 'releases', 'billion', 'parameter', 'open', 'access', 'multilingual', 'language', 'modelbigscience', 'https', 'play', 'model', 'interactively', 'free', 'huggingface', 'https', 'huggingface', 'co', 'bigscience', 'bloom']","['n', 'bigscienc', 'releas', 'billion', 'paramet', 'open', 'access', 'multilingu', 'languag', 'modelbigsci', 'http', 'play', 'model', 'interact', 'free', 'huggingfac', 'http', 'huggingfac', 'co', 'bigscienc', 'bloom']"
19,20,20,rivew,vye2zj,[D] How are People Doing “Fair” Few-Shot Training/Evaluation,"After reading through a lot of the non-Meta Learning popular few-shot literature ([Prototypical Nets](https://arxiv.org/abs/1703.05175?context=cs), [Matching Nets](https://arxiv.org/abs/1606.04080?context=stat), etc.) and then looking at other papers/GitHub repos, I’m not totally sure how to build a “fair” training and evaluation setup.

Let’s take CIFAR-100 (ignoring CIFAR-FS for now).  To set up a few-shot dataset split, I’d take the 100 classes and split up into train/val/test 60/20/40 such that each split has non-overlapping classes - pretty straightforward.  But now, I still have 600 examples per class in all splits.  Before generating random 5-way-5-shot episodes during training, what’s the fair way to generate Support and Query Sets?  Are people first creating another split of the trainset so that the Support set only contains 5 examples per class (60*5=300 total examples) and the rest is in the Query set?  If not, something like that then the support set is going to contain a lot of examples to learn from rather than a few.

Some methods also directly classify the trainset’s support images for pre-training, assuming that the number of classes overall is known beforehand.  But then to do same on the validation and support sets I guess that they replace the FC layer.

Finally, when choosing a pre-trained model to start with, it seems absolutely necessary to choose a significantly different domain for evaluation (ex. ImageNet pre-trained ResNet evaluated on CIFAR-FS is bad).

tldr; it seems like there’s a lot of small differences in experimental setups for few-shot settings, what’s the best way to be fair for training/evaluation?  Also maybe I’m just totally missing something :)",5,3,2022-07-14 02:43:38, d  how are people doing  fair  few shot training evaluation,after reading through a lot of the non meta learning popular few shot literature   prototypical nets  https let s take cifar   ignoring cifar fs for now    to set up a few shot dataset split  i d take the  classes and split up into train val test some methods also directly classify the trainset s support images for pre training  assuming that the number of classes overall is known beforehand   but then to do same on the validation and support sets i guess that they replace the fc layer finally  when choosing a pre trained model to start with  it seems absolutely necessary to choose a significantly different domain for evaluation  ex  imagenet pre trained resnet evaluated on cifar fs is bad  tldr  it seems like there s a lot of small differences in experimental setups for few shot settings  what s the best way to be fair for training evaluation   also maybe i m just totally missing something   ,reading lot non meta learning popular shot literature prototypical nets https let take cifar ignoring cifar fs set shot dataset split take classes split train val test methods also directly classify trainset support images pre training assuming number classes overall known beforehand validation support sets guess replace fc layer finally choosing pre trained model start seems absolutely necessary choose significantly different domain evaluation ex imagenet pre trained resnet evaluated cifar fs bad tldr seems like lot small differences experimental setups shot settings best way fair training evaluation also maybe totally missing something,people fair shot training evaluation,people fair shot training evaluationreading lot non meta learning popular shot literature prototypical nets https let take cifar ignoring cifar fs set shot dataset split take classes split train val test methods also directly classify trainset support images pre training assuming number classes overall known beforehand validation support sets guess replace fc layer finally choosing pre trained model start seems absolutely necessary choose significantly different domain evaluation ex imagenet pre trained resnet evaluated cifar fs bad tldr seems like lot small differences experimental setups shot settings best way fair training evaluation also maybe totally missing something,"['people', 'fair', 'shot', 'training', 'evaluationreading', 'lot', 'non', 'meta', 'learning', 'popular', 'shot', 'literature', 'prototypical', 'nets', 'https', 'let', 'take', 'cifar', 'ignoring', 'cifar', 'fs', 'set', 'shot', 'dataset', 'split', 'take', 'classes', 'split', 'train', 'val', 'test', 'methods', 'also', 'directly', 'classify', 'trainset', 'support', 'images', 'pre', 'training', 'assuming', 'number', 'classes', 'overall', 'known', 'beforehand', 'validation', 'support', 'sets', 'guess', 'replace', 'fc', 'layer', 'finally', 'choosing', 'pre', 'trained', 'model', 'start', 'seems', 'absolutely', 'necessary', 'choose', 'significantly', 'different', 'domain', 'evaluation', 'ex', 'imagenet', 'pre', 'trained', 'resnet', 'evaluated', 'cifar', 'fs', 'bad', 'tldr', 'seems', 'like', 'lot', 'small', 'differences', 'experimental', 'setups', 'shot', 'settings', 'best', 'way', 'fair', 'training', 'evaluation', 'also', 'maybe', 'totally', 'missing', 'something']","['peopl', 'fair', 'shot', 'train', 'evaluationread', 'lot', 'non', 'meta', 'learn', 'popular', 'shot', 'literatur', 'prototyp', 'net', 'http', 'let', 'take', 'cifar', 'ignor', 'cifar', 'fs', 'set', 'shot', 'dataset', 'split', 'take', 'class', 'split', 'train', 'val', 'test', 'method', 'also', 'directli', 'classifi', 'trainset', 'support', 'imag', 'pre', 'train', 'assum', 'number', 'class', 'overal', 'known', 'beforehand', 'valid', 'support', 'set', 'guess', 'replac', 'fc', 'layer', 'final', 'choos', 'pre', 'train', 'model', 'start', 'seem', 'absolut', 'necessari', 'choos', 'significantli', 'differ', 'domain', 'evalu', 'ex', 'imagenet', 'pre', 'train', 'resnet', 'evalu', 'cifar', 'fs', 'bad', 'tldr', 'seem', 'like', 'lot', 'small', 'differ', 'experiment', 'setup', 'shot', 'set', 'best', 'way', 'fair', 'train', 'evalu', 'also', 'mayb', 'total', 'miss', 'someth']"
20,21,21,Petuum,vy92d1,[P] Build a Machine Translation System with Forte,"**TLDR:** This tutorial allows you to build a machine translation system with no glue code using Forte, an open source ML workflow builder.

&#x200B;

Forte makes it easy to compose any NLP pipeline, regardless of heterogeneity of data and processes, as a modular and easily editable system. It allows users to break down complex problems into composable pipelines and enables inter-operations across tasks through a unified data format.

This tutorial includes:

**1 — How to read data from source**

* How to create a simple NLP pipeline
* How to maintain and store the input data

**2 — How to process data in pipeline**

* How to perform sentence segmentation
* How to annotate and query the data
* How to translate the input text with a pre-trained model
* How to manage multiple data objects

**3 — How to handle new practical requests**

* How to handle structures like HTML data
* How to select a single data object for processing
* How to replace the translation model with remote translation services
* How to save and load the pipeline

Run the following command to install all the required dependencies for this tutorial:

    # It is recommended to install these in command line
    !pip install forte==0.2.0 forte.nltk requests# for certain environment, you may run into troubles installing transformers, such as requiring Rust
    some workaround here: https://github.com/huggingface/transformers/issues/2831#issuecomment-600141935 might help!pip install transformers==4.16.2
    you may want to try different pytorch version depending on your platform
    if you cannot install pytorch, try locate your problem at https://github.com/pytorch/pytorch/issues!pip install torch==1.11.0
    for certain environment, the installation may fail
    some workaround here: https://github.com/google/sentencepiece/issues/378#issuecomment-1145399969 might help!pip install sentencepiece

**1 — How to Read Data from Source**

**How to Create a Simple Pipeline: Start with the Reader**

In this section, you will learn:

* What is a reader and why we need it
* How to compose a simple pipeline with a pre-built reader

&#x200B;

    from forte import Pipeline

from forte.data.readers import TerminalReader pipeline: Pipeline = Pipeline()

All pipelines need a reader to read and parse input data. To make our pipeline read queries from the user’s command-line terminal, use the `TerminalReader` class provided by Forte.  `TerminalReader` transforms the user’s query into a DataPack object, which is a unified data format for NLP that makes it easy to connect different NLP tools together as Forte Processors.

    pipeline.set_reader(TerminalReader())

To run the pipeline consisting of the single `TerminalReader`, call `process_dataset` which will return an iterator of DataPack objects. The second line in the following code snippet retrieves the first user query from the TerminalReader.

    pipeline.initialize()
    datapack = next(pipeline.process_dataset())
    print(datapack.text)

**How to Maintain and Store Input Data: DataPack**

In this section, you will learn:

* What is a DataPack object and why we need it

Forte helps demystify data lineage and increase the traceability of how data flows along the pipeline and how features are generated to interface data to model. Similar to a cargo ship that loads and transports goods from one port to another, a data pack carries information when passing each module and updates the ontology states along the way.

https://preview.redd.it/a1ueowwsadb91.png?width=1400&format=png&auto=webp&s=44bf2986ef09f609986bcb5cecba12be1de7db06

DataPack and Multi-Modality:

DataPack not only supports text data but also audio and image data.

https://preview.redd.it/jko8w1ryadb91.png?width=1067&format=png&auto=webp&s=0963fa45d6630e1f1a2061da626034dd4d55b99b

**2— How to Process Data in Pipeline**

**How to Perform Sentence Segmentation: Add a Pre-Built Forte Processor to the Pipeline**

In this section, you will learn:

* What is a processor and why we need it
* How to add a pre-built processor to the pipeline

A Forte Processor takes DataPacks as inputs, processes them, and stores its outputs in DataPacks. The processors we are going to use in this section are all PackProcessors, which expect exactly one DataPack as input and store its outputs back into the same DataPack. The following two lines of code shows how a pre-built processor `NLTKSentenceSegmenter` is added to our pipeline.

    from fortex.nltk.nltk_processors import NLTKSentenceSegmenter
    pipeline.add(NLTKSentenceSegmenter())

When we run the pipeline, the `NLTKSentenceSegmenter` processor will split the user query into sentences and store them back to the DataPack created by TerminalReader. The code snippet below shows how to get all the sentences from the first query.

https://preview.redd.it/2cp4g1t5bdb91.png?width=1088&format=png&auto=webp&s=9c5851e77dffd3693a9fe5534e80319c7d489d90

    from ft.onto.base_ontology import Sentence
    pipeline.initialize()
    for sent in next(pipeline.process_dataset()).get(Sentence):
        print(sent.text)

**How to Annotate and Query the Data: Ontology**

In this section, you will learn:

* What is the ontology system and why we need it
* How to write a customized ontology and how to use it

`Sentence` is a pre-defined ontology provided by Forte and it is used by `NLTKSentenceSegmenter`to annotate each sentence in text. Forte is built on top of an Ontology system, which defines the relations between NLP annotations, for example, the relation between words and documents, or between two words. This is the core for Forte. The ontology can be specified via a JSON format. And tools are provided to convert the ontology into production code (Python).

https://preview.redd.it/ae6njzbabdb91.png?width=637&format=png&auto=webp&s=afd570ef358d209aca2b5fca3d395d8ba812daf8

We can also define customized ontologies:

    from dataclasses import dataclass
    from forte.data.ontology.top import Annotation
    from typing import Optional
    
    @dataclass
    class Article(Annotation):
    
        language: Optional[str]
    
        def __init__(self, pack, begin: int, end: int):
            super().__init__(pack, begin, end)

Below is a simple example showing how we can query sentences through the new ontology we just created:

    from forte.data import DataPack
    
    sentences = [
        ""Do you want to get better at making delicious BBQ?"",
        ""You will have the opportunity, put this on your calendar now."",
        ""Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers.""
    ]
    datapack: DataPack = DataPack()
    
    # Add sentences to the DataPack and annotate them
    for sentence in sentences:
        datapack.set_text(datapack.text + sentence)
        datapack.add_entry(
            Sentence(datapack, len(datapack.text) - len(sentence), len(datapack.text))
        )
        
    # Annotate the whole text with Article
    article: Article = Article(datapack, 0, len(datapack.text))
    article.language = ""en""
    datapack.add_entry(article)
    
    for article in datapack.get(Article):
        print(f""Article (language - {article.language}):"")
        for sentence in article.get(Sentence):
            print(sentence.text)

In our previous example, we have the following ontologies inheritance. Sentence and Article both inherit from Annotation which is used to represent text data. In Article, we have `language`field to represent the text language.

https://preview.redd.it/sts91nqgbdb91.png?width=901&format=png&auto=webp&s=426a1b8b2908ffabc57b0a888d6cff0ef92d5743

Actually, we not only support text ontology but also audio, image and link which represent relationships between two entries.

https://preview.redd.it/spp9etkibdb91.png?width=1074&format=png&auto=webp&s=cd8f8c4c7965fabf3fbac3ed5e4ba83a5259a848

`Annotation` is inherited by all text entries which usually has a span to retrieve partial text from the full text.

* `Article`, as shown in our previous example, inherits annotation and contains `language`field to differentiate English and German. In the single DataPack example, English article has a span of English text in the DataPack. Likewise, German article has a span of German text in the DataPack.
* `Sentence` in our example is used to break down article, and we pass sentences into MT pipeline.

`AudioAnnotation` is inherited by all audio entries which usually has an audio span to retrieve partial audio from the full audio.

* `Recording` is an example subclass of `AudioAnnotation`, and it has extra `recording_class`field denoting the classes the audio belongs to.

`ImageAnnotation` is inherited by all image entries which usually has payload index pointing to a loaded image array.

* `BoundingBox` is an example subclass of `ImageAnnotation`. As the picture shows, it has more inheritance relationships than other ontology classes due to the nature of CV objects. The advantage of Forte ontology is that it supports complex inheritance, and users can inherit from existing ontology and add new ontology features for their needs.

`Link` is inherited by all link-like entries which has parent and child.

* `RelationLink` is an example subclass of `Link`, and it has a class attribute specifying the relation type.

**How to Translate the Input Text with a Pre-Trained Model: Create a Machine Translation Processor**

In this section, you will learn:

* The basics of machine translation process
* How to wrap a pre-trained machine translation model into a Forte processor

Translation converts a sequence of text from one language to another. In this tutorial we will use `Huggingface` Transformer model to translate input data, which consists of several steps including subword tokenization, input embedding, model inference, decoding, etc.

https://preview.redd.it/2li5gn74cdb91.png?width=1400&format=png&auto=webp&s=c6b1a5f2770b62552bf7895d666bbc1168106262

In Forte, we have a generic class `PackProcessor` that wraps model and inference-related components and behaviors to process `DataPack`. Therefore, we need to create a class that inherits the generic method from `PackProcessor`. Then we have a class definition `class MachineTranslationProcessor(PackProcessor)`.

    from forte.data import DataPack
    from forte.data.readers import StringReader
    from forte.processors.base import PackProcessor
    from transformers import T5Tokenizer, T5ForConditionalGeneration
    class MachineTranslationProcessor(PackProcessor):
        """"""
        Translate the input text and output to a file.
        """"""
        def initialize(self, resources, configs):
            super().initialize(resources, configs)
            # Initialize the tokenizer and model
            model_name: str = self.configs.pretrained_model
            self.tokenizer = T5Tokenizer.from_pretrained(model_name)
            self.model = T5ForConditionalGeneration.from_pretrained(model_name)
            self.task_prefix = ""translate English to German: ""
            self.tokenizer.padding_side = ""left""
            self.tokenizer.pad_token = self.tokenizer.eos_token
        def _process(self, input_pack: DataPack):
            # en2de machine translation 
            inputs = self.tokenizer([
                self.task_prefix + sentence.text
                for sentence in input_pack.get(Sentence)
            ], return_tensors=""pt"", padding=True)
            output_sequences = self.model.generate(
                input_ids=inputs[""input_ids""],
                attention_mask=inputs[""attention_mask""],
                do_sample=False,
            )
            output = ''.join(self.tokenizer.batch_decode(
                output_sequences, skip_special_tokens=True
            ))
            src_article: Article = Article(input_pack, 0, len(input_pack.text))
            src_article.language = ""en""
            input_pack.set_text(input_pack.text + '\n\n' + output)
            tgt_article: Article = Article(input_pack, len(input_pack.text) - len(output), len(input_pack.text))
            tgt_article.language = ""de""
        @classmethod
        def default_configs(cls):
            return {
                ""pretrained_model"": ""t5-small""
            }

Initialization of needed components:

* Users need to consider initializing all needed NLP components for the inference task such as tokenizer and model.
* Users also need to specify all configuration in `configs`, a dictionary-like object that specifies configurations of all components such as model name.

MT operations on DataPack:

* After the initialization, we already have the needed NLP components. We need to consider several MT behaviors based on Forte DataPack.

Pre-process text data:

* Retrieve text data from DataPack (given that it already reads data from the data source).
* Since T5 has a better performance given a task prompt, we also want to include the prompt in our data.
* Tokenization that transforms input text into sequences of tokens and token ids.
* Generate output sequences from model.
* Decode output token ids into sentences using the tokenizer.

The generic method to process `DataPack` is `_process(self, input_pack: DataPack)`. It should tokenize the input text, use the model class to make an inference, decode the output token ids, and finally write the output to a target file.

Now we can add it into the pipeline and run the machine translation task.

    input_string: str = ' '.join(sentences)
    pipeline: Pipeline = Pipeline[DataPack]()
    pipeline.set_reader(StringReader())
    pipeline.add(NLTKSentenceSegmenter())
    pipeline.add(MachineTranslationProcessor())
    pipeline.initialize()
    for datapack in pipeline.process_dataset([input_string]):
        for article in datapack.get(Article):
            print([f""\nArticle (language - {article.language}): {article.text}""])

Ontology in DataPack:

Here we provide an illustration so that users can better understand the internal storage of DataPack. As we can see, text data, sentence and articles, are stored as span in `Annotations`. Their text data can be easily and efficiently retrieved by their spans.

https://preview.redd.it/hpbpp8xpcdb91.png?width=1096&format=png&auto=webp&s=ae11d14b87fa4fb54dd9988213218e956e67250e

**How to Manage Multiple Data Objects: MultiPack, A Better Way to Store Source and Target Text**

In this section, you will learn:

* What is a MultiPack and why we need it
* How to use a MultiPack

The above step outputs a DataPack which is good for holding data about one specific piece of text. A complicated pipeline like the one we are building now may need multiple DataPacks to be passed along the pipeline and this is where MultiPack can help. MultiPack manages a set of DataPacks that can be indexed by their names.

`MultiPackBoxer` is a simple Forte processor that converts a DataPack into a MultiPack by making it the only DataPack in there. A name can be specified via the config. We use it to wrap DataPack that contains source sentence.

https://preview.redd.it/jfoc0r9tcdb91.png?width=812&format=png&auto=webp&s=d0f7bd950e3f338ce0703419a57acb18d51463d8

    from forte.data import MultiPack
    from forte.processors.base import MultiPackProcessor
    from forte.data.caster import MultiPackBoxer
    class MachineTranslationMPProcessor(MultiPackProcessor):
        """"""
        Translate the input text and output to a file.
        """"""
        def initialize(self, resources, configs):
            super().initialize(resources, configs)
    
            # Initialize the tokenizer and model
            model_name: str = self.configs.pretrained_model
            self.tokenizer = T5Tokenizer.from_pretrained(model_name)
            self.model = T5ForConditionalGeneration.from_pretrained(model_name)
            self.task_prefix = ""translate English to German: ""
            self.tokenizer.padding_side = ""left""
            self.tokenizer.pad_token = self.tokenizer.eos_token
    
        def _process(self, input_pack: MultiPack):
            source_pack: DataPack = input_pack.get_pack(""source"")
            target_pack: DataPack = input_pack.add_pack(""target"")
    
            # en2de machine translation 
            inputs = self.tokenizer([
                self.task_prefix + sentence.text
                for sentence in source_pack.get(Sentence)
            ], return_tensors=""pt"", padding=True)
    
            output_sequences = self.model.generate(
                input_ids=inputs[""input_ids""],
                attention_mask=inputs[""attention_mask""],
                do_sample=False,
            )
            
            # Annotate the source article
            src_article: Article = Article(source_pack, 0, len(source_pack.text))
            src_article.language = ""en""
            
            # Annotate each sentence
            for output in self.tokenizer.batch_decode(
                output_sequences, skip_special_tokens=True
            ):
                target_pack.set_text(target_pack.text + output)
                text_length: int = len(target_pack.text)
                Sentence(target_pack, text_length - len(output), text_length)
            
            # Annotate the target article
            tgt_article: Article = Article(target_pack, 0, len(target_pack.text))
            tgt_article.language = ""de""
    
        @classmethod
        def default_configs(cls):
            return {
                ""pretrained_model"": ""t5-small"",
            }

Then `MachineTranslationMPProcessor` writes the output sentence into a target DataPack.

https://preview.redd.it/jci0neb3ddb91.png?width=978&format=png&auto=webp&s=fd26a16c151fcc1bfe578a0b4cc3dd69f98963c3

Now let’s try to create a new pipeline that utilizes `MultiPack` to manage text in different languages.

    nlp: Pipeline = Pipeline[DataPack]()
    nlp.set_reader(StringReader())
    nlp.add(NLTKSentenceSegmenter())
    nlp.add(MultiPackBoxer(), config={""pack_name"": ""source""})
    nlp.add(MachineTranslationMPProcessor(), config={
        ""pretrained_model"": ""t5-small""
    })
    nlp.initialize()
    for multipack in nlp.process_dataset([input_string]):
        for pack_name in (""source"", ""target""):
            for article in multipack.get_pack(pack_name).get(Article):
                print(f""\nArticle (language - {article.language}): "")
                for sentence in article.get(Sentence):
                    print(sentence.text)

Ontology in MultiPack:

For comparison, here is an illustration of the internal storage of MultiPack. We can see that MultiPack wraps one source DataPack and one target DataPack. Article spans are based on two separate DataPack text.

https://preview.redd.it/asqd43z8ddb91.png?width=1400&format=png&auto=webp&s=6587dd45173b5ed5f8379819179270c500f9ed9d

**3 — How to Handle New Practical Requests**

**How to Handle Structures like HTML Data**

In this section, you will learn

* How to build a translation management system
* How to preserve the structure like HTML in machine translation
* How to select a specific DataPack from MultiPack for processing

In the previous step, the input string is just a simple paragraph made up of several sentences. However, in many cases, we might need to handle data with structural information, such HTML or XML. When the input is a string of raw HTML data, the machine translation pipeline above may not work as expected:

    html_input: str = """"""
    <!DOCTYPE html>
    <html>
        <head><title>Beginners BBQ Class.</title></head>
        <body>
        <p>Do you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers.</p>
        </body>
    </html>
    """"""
    nlp.initialize()
    for multipack in nlp.process_dataset([html_input]):
        print(""Source Text: "" + multipack.get_pack(""source"").text)
        print(""\nTarget Text: "" + multipack.get_pack(""target"").text)

We can see that the original HTML structure is broken in the translated output.

In order to handle structured data like HTML, we will need to update our current design of pipeline. Luckily, Forte pipelines are highly modular, we can simply insert two new processors without updating the previous pipeline.

We first need a HTML cleaner to parse all the HTML tags from input string. Picture below shows the effect of tag remover.

https://preview.redd.it/ed6civbfddb91.png?width=1076&format=png&auto=webp&s=807ffb7f8ac1e9f13f071a50f867065e3038dd85

After the translation is finished, we will also need to recover the HTML structure from the unstructured translation output. Picture below shows replace one source sentence with one target sentence given the target sentence is ready.

https://preview.redd.it/wrs7aaxgddb91.png?width=968&format=png&auto=webp&s=34b31beba1791543b826b4aa6efcbae114f39bbe

    from forte.data import NameMatchSelector
    from forte.data.readers.html_reader import ForteHTMLParser
    class HTMLTagCleaner(MultiPackProcessor):
        
        def initialize(self, resources, configs):
            super().initialize(resources, configs)
            self._parser = ForteHTMLParser()
        def _process(self, input_pack: MultiPack):
            raw_pack: DataPack = input_pack.get_pack(""raw"")
            source_pack: DataPack = input_pack.add_pack(""source"")
            
            self._parser.feed(raw_pack.text)
            cleaned_text: str = raw_pack.text
            for span, _ in self._parser.spans:
                cleaned_text = cleaned_text.replace(
                    raw_pack.text[span.begin:span.end], ''
                )
            source_pack.set_text(cleaned_text)
            
    class HTMLTagRecovery(MultiPackProcessor):
        def _process(self, input_pack: MultiPack):
            raw_pack: DataPack = input_pack.get_pack(""raw"")
            source_pack: DataPack = input_pack.get_pack(""source"")
            target_pack: DataPack = input_pack.get_pack(""target"")
            result_pack: DataPack = input_pack.add_pack(""result"")
            result_text: str = raw_pack.text
            for sent_src, sent_tgt in zip(source_pack.get(Sentence), target_pack.get(Sentence)):
                result_text = result_text.replace(sent_src.text, sent_tgt.text)
            result_pack.set_text(result_text)

Now we are able to create a translation management system by inserting the two processors introduced above into our previous machine translation pipeline.

    # Pipeline with HTML handling
    pipeline: Pipeline = Pipeline[DataPack]()
    pipeline.set_reader(StringReader())
    pipeline.add(MultiPackBoxer(), config={""pack_name"": ""raw""})
    pipeline.add(HTMLTagCleaner())
    pipeline.add(
        NLTKSentenceSegmenter(),
        selector=NameMatchSelector(),
        selector_config={""select_name"": ""source""}
    )
    pipeline.add(MachineTranslationMPProcessor(), config={
        ""pretrained_model"": ""t5-small""
    })
    pipeline.add(HTMLTagRecovery())
    pipeline.initialize()
    for multipack in pipeline.process_dataset([html_input]):
        print(multipack.get_pack(""raw"").text)
        print(multipack.get_pack(""result"").text)

Selector:

In the code snippet above, we utilize a `NameMatchSelector` to select one specific DataPack from the MultiPack based on its reference name `select_name`. This allows `NLTKSentenceSegmenter` to process only the specified DataPack.

**How to Replace the Translation Model with Remote Translation Services: Replace our MT Model with Online Translation API**

In this section, you will learn:

* How to use a different translation service

Forte also allows us to update the translation model and integrate it seamlessly to the original pipeline. For example, if we want to offload the translation task to an online service, all we need to do is to update the translation processor. There is no need to change other components in the pipeline.

    # You can get your own API key by following the instructions in https://docs.microsoft.com/en-us/azure/cognitive-services/translator/
    api_key = input(""Enter your API key here:"")
    import requests
    import uuid
    class OnlineMachineTranslationMPProcessor(MultiPackProcessor):
        """"""
        Translate the input text and output to a file use online translator api.
        """"""
        def initialize(self, resources, configs):
            super().initialize(resources, configs)
            self.url = configs.endpoint + configs.path
            self.from_lang = configs.from_lang
            self.to_lang = configs.to_lang
            self.subscription_key = configs.subscription_key
            self.subscription_region = configs.subscription_region
        def _process(self, input_pack: MultiPack):
            source_pack: DataPack = input_pack.get_pack(""source"")
            target_pack: DataPack = input_pack.add_pack(""target"")
            
            params = {
                'api-version': '3.0',
                'from': 'en',
                'to': ['de']
            }
            # Build request
            headers = {
                'Ocp-Apim-Subscription-Key': self.subscription_key,
                'Ocp-Apim-Subscription-Region': self.subscription_region,
                'Content-type': 'application/json',
                'X-ClientTraceId': str(uuid.uuid4())
            }
            # You can pass more than one object in body.
            body = [{
                'text': source_pack.text
            }]
            request = requests.post(self.url, params=params, headers=headers, json=body)
            
            result = request.json()
            target_pack.set_text("""".join(
                [trans['text'] for trans in result[0][""translations""]]
                 )
            )
        @classmethod
        def default_configs(cls):
            return {
                ""from_lang"" : 'en',
                ""to_lang"":  'de',
                ""endpoint"" : 'https://api.cognitive.microsofttranslator.com/',
                ""path"" : '/translate',
                ""subscription_key"": None,
                ""subscription_region"" : ""westus2"",
                'X-ClientTraceId': str(uuid.uuid4())
            }
    nlp: Pipeline = Pipeline[DataPack]()
    nlp.set_reader(StringReader())
    nlp.add(NLTKSentenceSegmenter())
    nlp.add(MultiPackBoxer(), config={""pack_name"": ""source""})
    nlp.add(OnlineMachineTranslationMPProcessor(), config={
        ""from_lang"" : 'en',
        ""to_lang"":  'de',
        ""endpoint"" : 'https://api.cognitive.microsofttranslator.com/',
        ""path"" : '/translate',
        ""subscription_key"": api_key,
        ""subscription_region"" : ""westus2"",
        'X-ClientTraceId': str(uuid.uuid4())
    })
    nlp.initialize()
    for multipack in nlp.process_dataset([input_string]):
        print(""Source Text: "" + multipack.get_pack(""source"").text)
        print(""\nTarget Text: "" + multipack.get_pack(""target"").text)

**How to Save and Load the Pipeline: Save the Whole Pipeline with save()**

In this section, you will learn

* How to export and import a Forte pipeline

Forte also allow us to save the pipeline into disk. It serializes the whole pipeline and generates an intermediate representation, which can be loaded later maybe on a different machine.

    import os
    save_path: str = os.path.join(os.path.dirname(os.path.abspath('')), ""pipeline.yml"")
    nlp.save(save_path)
    with open(save_path, 'r') as f:
        print(f.read())

Now that the pipeline is saved, we can try to re-load the pipeline to see if it still functions as expected.

    new_nlp: Pipeline = Pipeline()
    new_nlp.init_from_config_path(save_path)
    new_nlp.initialize()
    for multipack in new_nlp.process_dataset([input_string]):
        print(""Source Text: "" + multipack.get_pack(""source"").text)
        print(""\nTarget Text: "" + multipack.get_pack(""target"").text)

Now you can build a machine translation system with Forte!",0,5,2022-07-13 23:08:01, p  build a machine translation system with forte,  tldr    this tutorial allows you to build a machine translation system with no glue code using forte  an open source ml workflow builder   xb forte makes it easy to compose any nlp pipeline  regardless of heterogeneity of data and processes  as a modular and easily editable system  it allows users to break down complex problems into composable pipelines and enables inter operations across tasks through a unified data format this tutorial includes      how to read data from source    how to create a simple nlp pipeline  how to maintain and store the input data     how to process data in pipeline    how to perform sentence segmentation  how to annotate and query the data  how to translate the input text with a pre trained model  how to manage multiple data objects     how to handle new practical requests    how to handle structures like html data  how to select a single data object for processing  how to replace the translation model with remote translation services  how to save and load the pipelinerun the following command to install all the required dependencies for this tutorial       it is recommended to install these in command line     pip install forte     forte nltk requests  for certain environment  you may run into troubles installing transformers  such as requiring rust    some workaround here  https     you may want to try different pytorch version depending on your platform    if you cannot install pytorch  try locate your problem at https     for certain environment  the installation may fail    some workaround here  https      how to read data from source    how to create a simple pipeline  start with the reader  in this section  you will learn   what is a reader and why we need it  how to compose a simple pipeline with a pre built reader  xb     from forte import pipelinefrom forte data readers import terminalreader pipeline  pipeline   pipeline  all pipelines need a reader to read and parse input data  to make our pipeline read queries from the user s command line terminal  use the  terminalreader  class provided by forte    terminalreader  transforms the user s query into a datapack object  which is a unified data format for nlp that makes it easy to connect different nlp tools together as forte processors     pipeline set_reader terminalreader   to run the pipeline consisting of the single  terminalreader   call  process_dataset  which will return an iterator of datapack objects  the second line in the following code snippet retrieves the first user query from the terminalreader     pipeline initialize      datapack   next pipeline process_dataset       print datapack text   how to maintain and store input data  datapack  in this section  you will learn   what is a datapack object and why we need itforte helps demystify data lineage and increase the traceability of how data flows along the pipeline and how features are generated to interface data to model  similar to a cargo ship that loads and transports goods from one port to another  a data pack carries information when passing each module and updates the ontology states along the way https datapack and multi modality datapack not only supports text data but also audio and image data https     how to process data in pipeline    how to perform sentence segmentation  add a pre built forte processor to the pipeline  in this section  you will learn   what is a processor and why we need it  how to add a pre built processor to the pipelinea forte processor takes datapacks as inputs  processes them  and stores its outputs in datapacks  the processors we are going to use in this section are all packprocessors  which expect exactly one datapack as input and store its outputs back into the same datapack  the following two lines of code shows how a pre built processor  nltksentencesegmenter  is added to our pipeline     from fortex nltk nltk_processors import nltksentencesegmenter    pipeline add nltksentencesegmenter   when we run the pipeline  the  nltksentencesegmenter  processor will split the user query into sentences and store them back to the datapack created by terminalreader  the code snippet below shows how to get all the sentences from the first query https     from ft onto base_ontology import sentence    pipeline initialize      for sent in next pipeline process_dataset    get sentence          print sent text   how to annotate and query the data  ontology  in this section  you will learn   what is the ontology system and why we need it  how to write a customized ontology and how to use it sentence  is a pre defined ontology provided by forte and it is used by  nltksentencesegmenter to annotate each sentence in text  forte is built on top of an ontology system  which defines the relations between nlp annotations  for example  the relation between words and documents  or between two words  this is the core for forte  the ontology can be specified via a json format  and tools are provided to convert the ontology into production code  python  https we can also define customized ontologies     from dataclasses import dataclass    from forte data ontology top import annotation    from typing import optional         dataclass    class article annotation              language  optional str             def __init__ self  pack  begin  int  end  int              super   __init__ pack  begin  end below is a simple example showing how we can query sentences through the new ontology we just created     from forte data import datapack        sentences            do you want to get better at making delicious bbq          you will have the opportunity  put this on your calendar now          thursday  september nd join world class bbq champion  tony balay from lonestar smoke rangers          datapack  datapack   datapack            add sentences to the datapack and annotate them    for sentence in sentences         datapack set_text datapack text   sentence         datapack add_entry             sentence datapack  len datapack text    len sentence   len datapack text                         annotate the whole text with article    article  article   article datapack    len datapack text      article language   en    datapack add_entry article         for article in datapack get article          print farticle  language    article language            for sentence in article get sentence              print sentence text in our previous example  we have the following ontologies inheritance  sentence and article both inherit from annotation which is used to represent text data  in article  we have  language field to represent the text language https actually  we not only support text ontology but also audio  image and link which represent relationships between two entries https  annotation  is inherited by all text entries which usually has a span to retrieve partial text from the full text    article   as shown in our previous example  inherits annotation and contains  language field to differentiate english and german  in the single datapack example  english article has a span of english text in the datapack  likewise  german article has a span of german text in the datapack    sentence  in our example is used to break down article  and we pass sentences into mt pipeline  audioannotation  is inherited by all audio entries which usually has an audio span to retrieve partial audio from the full audio    recording  is an example subclass of  audioannotation   and it has extra  recording_class field denoting the classes the audio belongs to  imageannotation  is inherited by all image entries which usually has payload index pointing to a loaded image array    boundingbox  is an example subclass of  imageannotation   as the picture shows  it has more inheritance relationships than other ontology classes due to the nature of cv objects  the advantage of forte ontology is that it supports complex inheritance  and users can inherit from existing ontology and add new ontology features for their needs  link  is inherited by all link like entries which has parent and child    relationlink  is an example subclass of  link   and it has a class attribute specifying the relation type   how to translate the input text with a pre trained model  create a machine translation processor  in this section  you will learn   the basics of machine translation process  how to wrap a pre trained machine translation model into a forte processortranslation converts a sequence of text from one language to another  in this tutorial we will use  huggingface  transformer model to translate input data  which consists of several steps including subword tokenization  input embedding  model inference  decoding  etc https in forte  we have a generic class  packprocessor  that wraps model and inference related components and behaviors to process  datapack   therefore  we need to create a class that inherits the generic method from  packprocessor   then we have a class definition  class machinetranslationprocessor packprocessor       from forte data import datapack    from forte data readers import stringreader    from forte processors base import packprocessor    from transformers import ttokenizer  tforconditionalgeneration    class machinetranslationprocessor packprocessor                  translate the input text and output to a file                 def initialize self  resources  configs              super   initialize resources  configs               initialize the tokenizer and model            model_name  str   self configs pretrained_model            self tokenizer   ttokenizer from_pretrained model_name             self model   tforconditionalgeneration from_pretrained model_name             self task_prefix   translate english to german              self tokenizer padding_side   left            self tokenizer pad_token   self tokenizer eos_token        def _process self  input_pack  datapack                ende machine translation             inputs   self tokenizer                  self task_prefix   sentence text                for sentence in input_pack get sentence                return_tensors pt  padding true             output_sequences   self model generate                 input_ids inputs input_ids                  attention_mask inputs attention_mask                  do_sample false                          output      join self tokenizer batch_decode                 output_sequences  skip_special_tokens true                          src_article  article   article input_pack    len input_pack text              src_article language   en            input_pack set_text input_pack text     n n    output             tgt_article  article   article input_pack  len input_pack text    len output   len input_pack text              tgt_article language   de         classmethod        def default_configs cls              return                  pretrained_model  t small             initialization of needed components   users need to consider initializing all needed nlp components for the inference task such as tokenizer and model   users also need to specify all configuration in  configs   a dictionary like object that specifies configurations of all components such as model name mt operations on datapack   after the initialization  we already have the needed nlp components  we need to consider several mt behaviors based on forte datapack pre process text data   retrieve text data from datapack  given that it already reads data from the data source    since t has a better performance given a task prompt  we also want to include the prompt in our data   tokenization that transforms input text into sequences of tokens and token ids   generate output sequences from model   decode output token ids into sentences using the tokenizer the generic method to process  datapack  is  _process self  input_pack  datapack    it should tokenize the input text  use the model class to make an inference  decode the output token ids  and finally write the output to a target file now we can add it into the pipeline and run the machine translation task     input_string  str       join sentences     pipeline  pipeline   pipeline datapack       pipeline set_reader stringreader       pipeline add nltksentencesegmenter       pipeline add machinetranslationprocessor       pipeline initialize      for datapack in pipeline process_dataset  input_string           for article in datapack get article              print  f narticle  language    article language     article text   ontology in datapack here we provide an illustration so that users can better understand the internal storage of datapack  as we can see  text data  sentence and articles  are stored as span in  annotations   their text data can be easily and efficiently retrieved by their spans https   how to manage multiple data objects  multipack  a better way to store source and target text  in this section  you will learn   what is a multipack and why we need it  how to use a multipackthe above step outputs a datapack which is good for holding data about one specific piece of text  a complicated pipeline like the one we are building now may need multiple datapacks to be passed along the pipeline and this is where multipack can help  multipack manages a set of datapacks that can be indexed by their names  multipackboxer  is a simple forte processor that converts a datapack into a multipack by making it the only datapack in there  a name can be specified via the config  we use it to wrap datapack that contains source sentence https     from forte data import multipack    from forte processors base import multipackprocessor    from forte data caster import multipackboxer    class machinetranslationmpprocessor multipackprocessor                  translate the input text and output to a file                 def initialize self  resources  configs              super   initialize resources  configs                   initialize the tokenizer and model            model_name  str   self configs pretrained_model            self tokenizer   ttokenizer from_pretrained model_name             self model   tforconditionalgeneration from_pretrained model_name             self task_prefix   translate english to german              self tokenizer padding_side   left            self tokenizer pad_token   self tokenizer eos_token            def _process self  input_pack  multipack              source_pack  datapack   input_pack get_pack source             target_pack  datapack   input_pack add_pack target                   ende machine translation             inputs   self tokenizer                  self task_prefix   sentence text                for sentence in source_pack get sentence                return_tensors pt  padding true                 output_sequences   self model generate                 input_ids inputs input_ids                  attention_mask inputs attention_mask                  do_sample false                                        annotate the source article            src_article  article   article source_pack    len source_pack text              src_article language   en                          annotate each sentence            for output in self tokenizer batch_decode                 output_sequences  skip_special_tokens true                              target_pack set_text target_pack text   output                 text_length  int   len target_pack text                 sentence target_pack  text_length   len output   text_length                           annotate the target article            tgt_article  article   article target_pack    len target_pack text              tgt_article language   de             classmethod        def default_configs cls              return                  pretrained_model  t small              then  machinetranslationmpprocessor  writes the output sentence into a target datapack https now let s try to create a new pipeline that utilizes  multipack  to manage text in different languages     nlp  pipeline   pipeline datapack       nlp set_reader stringreader       nlp add nltksentencesegmenter       nlp add multipackboxer    config  pack_name  source      nlp add machinetranslationmpprocessor    config          pretrained_model  t small          nlp initialize      for multipack in nlp process_dataset  input_string           for pack_name in  source  target              for article in multipack get_pack pack_name  get article                  print f narticle  language    article language                     for sentence in article get sentence                      print sentence text ontology in multipack for comparison  here is an illustration of the internal storage of multipack  we can see that multipack wraps one source datapack and one target datapack  article spans are based on two separate datapack text https      how to handle new practical requests    how to handle structures like html data  in this section  you will learn  how to build a translation management system  how to preserve the structure like html in machine translation  how to select a specific datapack from multipack for processingin the previous step  the input string is just a simple paragraph made up of several sentences  however  in many cases  we might need to handle data with structural information  such html or xml  when the input is a string of raw html data  the machine translation pipeline above may not work as expected     html_input  str                   beginners bbq class                 do you want to get better at making delicious bbq  you will have the opportunity  put this on your calendar now  thursday  september nd join world class bbq champion  tony balay from lonestar smoke rangers                     nlp initialize      for multipack in nlp process_dataset  html_input           print source text     multipack get_pack source  text         print  ntarget text     multipack get_pack target  text we can see that the original html structure is broken in the translated output in order to handle structured data like html  we will need to update our current design of pipeline  luckily  forte pipelines are highly modular  we can simply insert two new processors without updating the previous pipeline we first need a html cleaner to parse all the html tags from input string  picture below shows the effect of tag remover https after the translation is finished  we will also need to recover the html structure from the unstructured translation output  picture below shows replace one source sentence with one target sentence given the target sentence is ready https     from forte data import namematchselector    from forte data readers html_reader import fortehtmlparser    class htmltagcleaner multipackprocessor                  def initialize self  resources  configs              super   initialize resources  configs             self _parser   fortehtmlparser          def _process self  input_pack  multipack              raw_pack  datapack   input_pack get_pack raw             source_pack  datapack   input_pack add_pack source                         self _parser feed raw_pack text             cleaned_text  str   raw_pack text            for span  _ in self _parser spans                 cleaned_text   cleaned_text replace                     raw_pack text span begin span end                                  source_pack set_text cleaned_text                 class htmltagrecovery multipackprocessor          def _process self  input_pack  multipack              raw_pack  datapack   input_pack get_pack raw             source_pack  datapack   input_pack get_pack source             target_pack  datapack   input_pack get_pack target             result_pack  datapack   input_pack add_pack result             result_text  str   raw_pack text            for sent_src  sent_tgt in zip source_pack get sentence   target_pack get sentence                   result_text   result_text replace sent_src text  sent_tgt text             result_pack set_text result_text now we are able to create a translation management system by inserting the two processors introduced above into our previous machine translation pipeline       pipeline with html handling    pipeline  pipeline   pipeline datapack       pipeline set_reader stringreader       pipeline add multipackboxer    config  pack_name  raw      pipeline add htmltagcleaner       pipeline add         nltksentencesegmenter           selector namematchselector           selector_config  select_name  source          pipeline add machinetranslationmpprocessor    config          pretrained_model  t small          pipeline add htmltagrecovery       pipeline initialize      for multipack in pipeline process_dataset  html_input           print multipack get_pack raw  text         print multipack get_pack result  text selector in the code snippet above  we utilize a  namematchselector  to select one specific datapack from the multipack based on its reference name  select_name   this allows  nltksentencesegmenter  to process only the specified datapack   how to replace the translation model with remote translation services  replace our mt model with online translation api  in this section  you will learn   how to use a different translation serviceforte also allows us to update the translation model and integrate it seamlessly to the original pipeline  for example  if we want to offload the translation task to an online service  all we need to do is to update the translation processor  there is no need to change other components in the pipeline       you can get your own api key by following the instructions in https     api_key   input enter your api key here      import requests    import uuid    class onlinemachinetranslationmpprocessor multipackprocessor                  translate the input text and output to a file use online translator api                 def initialize self  resources  configs              super   initialize resources  configs             self url   configs endpoint   configs path            self from_lang   configs from_lang            self to_lang   configs to_lang            self subscription_key   configs subscription_key            self subscription_region   configs subscription_region        def _process self  input_pack  multipack              source_pack  datapack   input_pack get_pack source             target_pack  datapack   input_pack add_pack target                         params                     api version                        from    en                   to     de                             build request            headers                     ocp apim subscription key   self subscription_key                  ocp apim subscription region   self subscription_region                  content type    application json                   x clienttraceid   str uuid uuid                              you can pass more than one object in body             body                      text   source_pack text                          request   requests post self url  params params  headers headers  json body                         result   request json              target_pack set_text  join                  trans  text   for trans in result   translations                                          classmethod        def default_configs cls              return                  from_lang    en                  to_lang    de                  endpoint    https                 path     translate                  subscription_key  none                 subscription_region   westus                  x clienttraceid   str uuid uuid                    nlp  pipeline   pipeline datapack       nlp set_reader stringreader       nlp add nltksentencesegmenter       nlp add multipackboxer    config  pack_name  source      nlp add onlinemachinetranslationmpprocessor    config          from_lang    en          to_lang    de          endpoint    https         path     translate          subscription_key  api_key         subscription_region   westus          x clienttraceid   str uuid uuid             nlp initialize      for multipack in nlp process_dataset  input_string           print source text     multipack get_pack source  text         print  ntarget text     multipack get_pack target  text   how to save and load the pipeline  save the whole pipeline with save    in this section  you will learn  how to export and import a forte pipelineforte also allow us to save the pipeline into disk  it serializes the whole pipeline and generates an intermediate representation  which can be loaded later maybe on a different machine     import os    save_path  str   os path join os path dirname os path abspath       pipeline yml     nlp save save_path     with open save_path   r   as f         print f read   now that the pipeline is saved  we can try to re load the pipeline to see if it still functions as expected     new_nlp  pipeline   pipeline      new_nlp init_from_config_path save_path     new_nlp initialize      for multipack in new_nlp process_dataset  input_string           print source text     multipack get_pack source  text         print  ntarget text     multipack get_pack target  text now you can build a machine translation system with forte ,tldr tutorial allows build machine translation system glue code using forte open source ml workflow builder xb forte makes easy compose nlp pipeline regardless heterogeneity data processes modular easily editable system allows users break complex problems composable pipelines enables inter operations across tasks unified data format tutorial includes read data source create simple nlp pipeline maintain store input data process data pipeline perform sentence segmentation annotate query data translate input text pre trained model manage multiple data objects handle practical requests handle structures like html data select single data object processing replace translation model remote translation services save load pipelinerun following command install required dependencies tutorial recommended install command line pip install forte forte nltk requests certain environment may run troubles installing transformers requiring rust workaround https may want try different pytorch version depending platform cannot install pytorch try locate problem https certain environment installation may fail workaround https read data source create simple pipeline start reader section learn reader need compose simple pipeline pre built reader xb forte import pipelinefrom forte data readers import terminalreader pipeline pipeline pipeline pipelines need reader read parse input data make pipeline read queries user command line terminal use terminalreader class provided forte terminalreader transforms user query datapack object unified data format nlp makes easy connect different nlp tools together forte processors pipeline set_reader terminalreader run pipeline consisting single terminalreader call process_dataset return iterator datapack objects second line following code snippet retrieves first user query terminalreader pipeline initialize datapack next pipeline process_dataset print datapack text maintain store input data datapack section learn datapack object need itforte helps demystify data lineage increase traceability data flows along pipeline features generated interface data model similar cargo ship loads transports goods one port another data pack carries information passing module updates ontology states along way https datapack multi modality datapack supports text data also audio image data https process data pipeline perform sentence segmentation pre built forte processor pipeline section learn processor need pre built processor pipelinea forte processor takes datapacks inputs processes stores outputs datapacks processors going use section packprocessors expect exactly one datapack input store outputs back datapack following two lines code shows pre built processor nltksentencesegmenter added pipeline fortex nltk nltk_processors import nltksentencesegmenter pipeline nltksentencesegmenter run pipeline nltksentencesegmenter processor split user query sentences store back datapack created terminalreader code snippet shows get sentences first query https ft onto base_ontology import sentence pipeline initialize sent next pipeline process_dataset get sentence print sent text annotate query data ontology section learn ontology system need write customized ontology use sentence pre defined ontology provided forte used nltksentencesegmenter annotate sentence text forte built top ontology system defines relations nlp annotations example relation documents two core forte ontology specified via json format tools provided convert ontology production code python https also define customized ontologies dataclasses import dataclass forte data ontology top import annotation typing import optional dataclass class article annotation language optional str def __init__ self pack begin int end int super __init__ pack begin end simple example showing query sentences ontology created forte data import datapack sentences want get better making delicious bbq opportunity put calendar thursday september nd join world class bbq champion tony balay lonestar smoke rangers datapack datapack datapack sentences datapack annotate sentence sentences datapack set_text datapack text sentence datapack add_entry sentence datapack len datapack text len sentence len datapack text annotate whole text article article article article datapack len datapack text article language en datapack add_entry article article datapack get article print farticle language article language sentence article get sentence print sentence text previous example following ontologies inheritance sentence article inherit annotation used represent text data article language field represent text language https actually support text ontology also audio image link represent relationships two entries https annotation inherited text entries usually span retrieve partial text full text article shown previous example inherits annotation contains language field differentiate english german single datapack example english article span english text datapack likewise german article span german text datapack sentence example used break article pass sentences mt pipeline audioannotation inherited audio entries usually audio span retrieve partial audio full audio recording example subclass audioannotation extra recording_class field denoting classes audio belongs imageannotation inherited image entries usually payload index pointing loaded image array boundingbox example subclass imageannotation picture shows inheritance relationships ontology classes due nature cv objects advantage forte ontology supports complex inheritance users inherit existing ontology ontology features needs link inherited link like entries parent child relationlink example subclass link class attribute specifying relation type translate input text pre trained model create machine translation processor section learn basics machine translation process wrap pre trained machine translation model forte processortranslation converts sequence text one language another tutorial use huggingface transformer model translate input data consists several steps including subword tokenization input embedding model inference decoding etc https forte generic class packprocessor wraps model inference related components behaviors process datapack therefore need create class inherits generic method packprocessor class definition class machinetranslationprocessor packprocessor forte data import datapack forte data readers import stringreader forte processors base import packprocessor transformers import ttokenizer tforconditionalgeneration class machinetranslationprocessor packprocessor translate input text output file def initialize self resources configs super initialize resources configs initialize tokenizer model model_name str self configs pretrained_model self tokenizer ttokenizer from_pretrained model_name self model tforconditionalgeneration from_pretrained model_name self task_prefix translate english german self tokenizer padding_side left self tokenizer pad_token self tokenizer eos_token def _process self input_pack datapack ende machine translation inputs self tokenizer self task_prefix sentence text sentence input_pack get sentence return_tensors pt padding true output_sequences self model generate input_ids inputs input_ids attention_mask inputs attention_mask do_sample false output join self tokenizer batch_decode output_sequences skip_special_tokens true src_article article article input_pack len input_pack text src_article language en input_pack set_text input_pack text n n output tgt_article article article input_pack len input_pack text len output len input_pack text tgt_article language de classmethod def default_configs cls return pretrained_model small initialization needed components users need consider initializing needed nlp components inference task tokenizer model users also need specify configuration configs dictionary like object specifies configurations components model name mt operations datapack initialization already needed nlp components need consider several mt behaviors based forte datapack pre process text data retrieve text data datapack given already reads data data source since better performance given task prompt also want include prompt data tokenization transforms input text sequences tokens token ids generate output sequences model decode output token ids sentences using tokenizer generic method process datapack _process self input_pack datapack tokenize input text use model class make inference decode output token ids finally write output target file pipeline run machine translation task input_string str join sentences pipeline pipeline pipeline datapack pipeline set_reader stringreader pipeline nltksentencesegmenter pipeline machinetranslationprocessor pipeline initialize datapack pipeline process_dataset input_string article datapack get article print f narticle language article language article text ontology datapack provide illustration users better understand internal storage datapack see text data sentence articles stored span annotations text data easily efficiently retrieved spans https manage multiple data objects multipack better way store source target text section learn multipack need use multipackthe step outputs datapack good holding data one specific piece text complicated pipeline like one building may need multiple datapacks passed along pipeline multipack help multipack manages set datapacks indexed names multipackboxer simple forte processor converts datapack multipack making datapack name specified via config use wrap datapack contains source sentence https forte data import multipack forte processors base import multipackprocessor forte data caster import multipackboxer class machinetranslationmpprocessor multipackprocessor translate input text output file def initialize self resources configs super initialize resources configs initialize tokenizer model model_name str self configs pretrained_model self tokenizer ttokenizer from_pretrained model_name self model tforconditionalgeneration from_pretrained model_name self task_prefix translate english german self tokenizer padding_side left self tokenizer pad_token self tokenizer eos_token def _process self input_pack multipack source_pack datapack input_pack get_pack source target_pack datapack input_pack add_pack target ende machine translation inputs self tokenizer self task_prefix sentence text sentence source_pack get sentence return_tensors pt padding true output_sequences self model generate input_ids inputs input_ids attention_mask inputs attention_mask do_sample false annotate source article src_article article article source_pack len source_pack text src_article language en annotate sentence output self tokenizer batch_decode output_sequences skip_special_tokens true target_pack set_text target_pack text output text_length int len target_pack text sentence target_pack text_length len output text_length annotate target article tgt_article article article target_pack len target_pack text tgt_article language de classmethod def default_configs cls return pretrained_model small machinetranslationmpprocessor writes output sentence target datapack https let try create pipeline utilizes multipack manage text different languages nlp pipeline pipeline datapack nlp set_reader stringreader nlp nltksentencesegmenter nlp multipackboxer config pack_name source nlp machinetranslationmpprocessor config pretrained_model small nlp initialize multipack nlp process_dataset input_string pack_name source target article multipack get_pack pack_name get article print f narticle language article language sentence article get sentence print sentence text ontology multipack comparison illustration internal storage multipack see multipack wraps one source datapack one target datapack article spans based two separate datapack text https handle practical requests handle structures like html data section learn build translation management system preserve structure like html machine translation select specific datapack multipack processingin previous step input string simple paragraph made several sentences however many cases might need handle data structural information html xml input string raw html data machine translation pipeline may work expected html_input str beginners bbq class want get better making delicious bbq opportunity put calendar thursday september nd join world class bbq champion tony balay lonestar smoke rangers nlp initialize multipack nlp process_dataset html_input print source text multipack get_pack source text print ntarget text multipack get_pack target text see original html structure broken translated output order handle structured data like html need update current design pipeline luckily forte pipelines highly modular simply insert two processors without updating previous pipeline first need html cleaner parse html tags input string picture shows effect tag remover https translation finished also need recover html structure unstructured translation output picture shows replace one source sentence one target sentence given target sentence ready https forte data import namematchselector forte data readers html_reader import fortehtmlparser class htmltagcleaner multipackprocessor def initialize self resources configs super initialize resources configs self _parser fortehtmlparser def _process self input_pack multipack raw_pack datapack input_pack get_pack raw source_pack datapack input_pack add_pack source self _parser feed raw_pack text cleaned_text str raw_pack text span _ self _parser spans cleaned_text cleaned_text replace raw_pack text span begin span end source_pack set_text cleaned_text class htmltagrecovery multipackprocessor def _process self input_pack multipack raw_pack datapack input_pack get_pack raw source_pack datapack input_pack get_pack source target_pack datapack input_pack get_pack target result_pack datapack input_pack add_pack result result_text str raw_pack text sent_src sent_tgt zip source_pack get sentence target_pack get sentence result_text result_text replace sent_src text sent_tgt text result_pack set_text result_text able create translation management system inserting two processors introduced previous machine translation pipeline pipeline html handling pipeline pipeline pipeline datapack pipeline set_reader stringreader pipeline multipackboxer config pack_name raw pipeline htmltagcleaner pipeline nltksentencesegmenter selector namematchselector selector_config select_name source pipeline machinetranslationmpprocessor config pretrained_model small pipeline htmltagrecovery pipeline initialize multipack pipeline process_dataset html_input print multipack get_pack raw text print multipack get_pack result text selector code snippet utilize namematchselector select one specific datapack multipack based reference name select_name allows nltksentencesegmenter process specified datapack replace translation model remote translation services replace mt model online translation api section learn use different translation serviceforte also allows us update translation model integrate seamlessly original pipeline example want offload translation task online service need update translation processor need change components pipeline get api key following instructions https api_key input enter api key import requests import uuid class onlinemachinetranslationmpprocessor multipackprocessor translate input text output file use online translator api def initialize self resources configs super initialize resources configs self url configs endpoint configs path self from_lang configs from_lang self to_lang configs to_lang self subscription_key configs subscription_key self subscription_region configs subscription_region def _process self input_pack multipack source_pack datapack input_pack get_pack source target_pack datapack input_pack add_pack target params api version en de build request headers ocp apim subscription key self subscription_key ocp apim subscription region self subscription_region content type application json x clienttraceid str uuid uuid pass one object body body text source_pack text request requests post self url params params headers headers json body result request json target_pack set_text join trans text trans result translations classmethod def default_configs cls return from_lang en to_lang de endpoint https path translate subscription_key none subscription_region westus x clienttraceid str uuid uuid nlp pipeline pipeline datapack nlp set_reader stringreader nlp nltksentencesegmenter nlp multipackboxer config pack_name source nlp onlinemachinetranslationmpprocessor config from_lang en to_lang de endpoint https path translate subscription_key api_key subscription_region westus x clienttraceid str uuid uuid nlp initialize multipack nlp process_dataset input_string print source text multipack get_pack source text print ntarget text multipack get_pack target text save load pipeline save whole pipeline save section learn export import forte pipelineforte also allow us save pipeline disk serializes whole pipeline generates intermediate representation loaded later maybe different machine import os save_path str os path join os path dirname os path abspath pipeline yml nlp save save_path open save_path r f print f read pipeline saved try load pipeline see still functions expected new_nlp pipeline pipeline new_nlp init_from_config_path save_path new_nlp initialize multipack new_nlp process_dataset input_string print source text multipack get_pack source text print ntarget text multipack get_pack target text build machine translation system forte,p build machine translation system forte,p build machine translation system fortetldr tutorial allows build machine translation system glue code using forte open source ml workflow builder xb forte makes easy compose nlp pipeline regardless heterogeneity data processes modular easily editable system allows users break complex problems composable pipelines enables inter operations across tasks unified data format tutorial includes read data source create simple nlp pipeline maintain store input data process data pipeline perform sentence segmentation annotate query data translate input text pre trained model manage multiple data objects handle practical requests handle structures like html data select single data object processing replace translation model remote translation services save load pipelinerun following command install required dependencies tutorial recommended install command line pip install forte forte nltk requests certain environment may run troubles installing transformers requiring rust workaround https may want try different pytorch version depending platform cannot install pytorch try locate problem https certain environment installation may fail workaround https read data source create simple pipeline start reader section learn reader need compose simple pipeline pre built reader xb forte import pipelinefrom forte data readers import terminalreader pipeline pipeline pipeline pipelines need reader read parse input data make pipeline read queries user command line terminal use terminalreader class provided forte terminalreader transforms user query datapack object unified data format nlp makes easy connect different nlp tools together forte processors pipeline set_reader terminalreader run pipeline consisting single terminalreader call process_dataset return iterator datapack objects second line following code snippet retrieves first user query terminalreader pipeline initialize datapack next pipeline process_dataset print datapack text maintain store input data datapack section learn datapack object need itforte helps demystify data lineage increase traceability data flows along pipeline features generated interface data model similar cargo ship loads transports goods one port another data pack carries information passing module updates ontology states along way https datapack multi modality datapack supports text data also audio image data https process data pipeline perform sentence segmentation pre built forte processor pipeline section learn processor need pre built processor pipelinea forte processor takes datapacks inputs processes stores outputs datapacks processors going use section packprocessors expect exactly one datapack input store outputs back datapack following two lines code shows pre built processor nltksentencesegmenter added pipeline fortex nltk nltk_processors import nltksentencesegmenter pipeline nltksentencesegmenter run pipeline nltksentencesegmenter processor split user query sentences store back datapack created terminalreader code snippet shows get sentences first query https ft onto base_ontology import sentence pipeline initialize sent next pipeline process_dataset get sentence print sent text annotate query data ontology section learn ontology system need write customized ontology use sentence pre defined ontology provided forte used nltksentencesegmenter annotate sentence text forte built top ontology system defines relations nlp annotations example relation documents two core forte ontology specified via json format tools provided convert ontology production code python https also define customized ontologies dataclasses import dataclass forte data ontology top import annotation typing import optional dataclass class article annotation language optional str def __init__ self pack begin int end int super __init__ pack begin end simple example showing query sentences ontology created forte data import datapack sentences want get better making delicious bbq opportunity put calendar thursday september nd join world class bbq champion tony balay lonestar smoke rangers datapack datapack datapack sentences datapack annotate sentence sentences datapack set_text datapack text sentence datapack add_entry sentence datapack len datapack text len sentence len datapack text annotate whole text article article article article datapack len datapack text article language en datapack add_entry article article datapack get article print farticle language article language sentence article get sentence print sentence text previous example following ontologies inheritance sentence article inherit annotation used represent text data article language field represent text language https actually support text ontology also audio image link represent relationships two entries https annotation inherited text entries usually span retrieve partial text full text article shown previous example inherits annotation contains language field differentiate english german single datapack example english article span english text datapack likewise german article span german text datapack sentence example used break article pass sentences mt pipeline audioannotation inherited audio entries usually audio span retrieve partial audio full audio recording example subclass audioannotation extra recording_class field denoting classes audio belongs imageannotation inherited image entries usually payload index pointing loaded image array boundingbox example subclass imageannotation picture shows inheritance relationships ontology classes due nature cv objects advantage forte ontology supports complex inheritance users inherit existing ontology ontology features needs link inherited link like entries parent child relationlink example subclass link class attribute specifying relation type translate input text pre trained model create machine translation processor section learn basics machine translation process wrap pre trained machine translation model forte processortranslation converts sequence text one language another tutorial use huggingface transformer model translate input data consists several steps including subword tokenization input embedding model inference decoding etc https forte generic class packprocessor wraps model inference related components behaviors process datapack therefore need create class inherits generic method packprocessor class definition class machinetranslationprocessor packprocessor forte data import datapack forte data readers import stringreader forte processors base import packprocessor transformers import ttokenizer tforconditionalgeneration class machinetranslationprocessor packprocessor translate input text output file def initialize self resources configs super initialize resources configs initialize tokenizer model model_name str self configs pretrained_model self tokenizer ttokenizer from_pretrained model_name self model tforconditionalgeneration from_pretrained model_name self task_prefix translate english german self tokenizer padding_side left self tokenizer pad_token self tokenizer eos_token def _process self input_pack datapack ende machine translation inputs self tokenizer self task_prefix sentence text sentence input_pack get sentence return_tensors pt padding true output_sequences self model generate input_ids inputs input_ids attention_mask inputs attention_mask do_sample false output join self tokenizer batch_decode output_sequences skip_special_tokens true src_article article article input_pack len input_pack text src_article language en input_pack set_text input_pack text n n output tgt_article article article input_pack len input_pack text len output len input_pack text tgt_article language de classmethod def default_configs cls return pretrained_model small initialization needed components users need consider initializing needed nlp components inference task tokenizer model users also need specify configuration configs dictionary like object specifies configurations components model name mt operations datapack initialization already needed nlp components need consider several mt behaviors based forte datapack pre process text data retrieve text data datapack given already reads data data source since better performance given task prompt also want include prompt data tokenization transforms input text sequences tokens token ids generate output sequences model decode output token ids sentences using tokenizer generic method process datapack _process self input_pack datapack tokenize input text use model class make inference decode output token ids finally write output target file pipeline run machine translation task input_string str join sentences pipeline pipeline pipeline datapack pipeline set_reader stringreader pipeline nltksentencesegmenter pipeline machinetranslationprocessor pipeline initialize datapack pipeline process_dataset input_string article datapack get article print f narticle language article language article text ontology datapack provide illustration users better understand internal storage datapack see text data sentence articles stored span annotations text data easily efficiently retrieved spans https manage multiple data objects multipack better way store source target text section learn multipack need use multipackthe step outputs datapack good holding data one specific piece text complicated pipeline like one building may need multiple datapacks passed along pipeline multipack help multipack manages set datapacks indexed names multipackboxer simple forte processor converts datapack multipack making datapack name specified via config use wrap datapack contains source sentence https forte data import multipack forte processors base import multipackprocessor forte data caster import multipackboxer class machinetranslationmpprocessor multipackprocessor translate input text output file def initialize self resources configs super initialize resources configs initialize tokenizer model model_name str self configs pretrained_model self tokenizer ttokenizer from_pretrained model_name self model tforconditionalgeneration from_pretrained model_name self task_prefix translate english german self tokenizer padding_side left self tokenizer pad_token self tokenizer eos_token def _process self input_pack multipack source_pack datapack input_pack get_pack source target_pack datapack input_pack add_pack target ende machine translation inputs self tokenizer self task_prefix sentence text sentence source_pack get sentence return_tensors pt padding true output_sequences self model generate input_ids inputs input_ids attention_mask inputs attention_mask do_sample false annotate source article src_article article article source_pack len source_pack text src_article language en annotate sentence output self tokenizer batch_decode output_sequences skip_special_tokens true target_pack set_text target_pack text output text_length int len target_pack text sentence target_pack text_length len output text_length annotate target article tgt_article article article target_pack len target_pack text tgt_article language de classmethod def default_configs cls return pretrained_model small machinetranslationmpprocessor writes output sentence target datapack https let try create pipeline utilizes multipack manage text different languages nlp pipeline pipeline datapack nlp set_reader stringreader nlp nltksentencesegmenter nlp multipackboxer config pack_name source nlp machinetranslationmpprocessor config pretrained_model small nlp initialize multipack nlp process_dataset input_string pack_name source target article multipack get_pack pack_name get article print f narticle language article language sentence article get sentence print sentence text ontology multipack comparison illustration internal storage multipack see multipack wraps one source datapack one target datapack article spans based two separate datapack text https handle practical requests handle structures like html data section learn build translation management system preserve structure like html machine translation select specific datapack multipack processingin previous step input string simple paragraph made several sentences however many cases might need handle data structural information html xml input string raw html data machine translation pipeline may work expected html_input str beginners bbq class want get better making delicious bbq opportunity put calendar thursday september nd join world class bbq champion tony balay lonestar smoke rangers nlp initialize multipack nlp process_dataset html_input print source text multipack get_pack source text print ntarget text multipack get_pack target text see original html structure broken translated output order handle structured data like html need update current design pipeline luckily forte pipelines highly modular simply insert two processors without updating previous pipeline first need html cleaner parse html tags input string picture shows effect tag remover https translation finished also need recover html structure unstructured translation output picture shows replace one source sentence one target sentence given target sentence ready https forte data import namematchselector forte data readers html_reader import fortehtmlparser class htmltagcleaner multipackprocessor def initialize self resources configs super initialize resources configs self _parser fortehtmlparser def _process self input_pack multipack raw_pack datapack input_pack get_pack raw source_pack datapack input_pack add_pack source self _parser feed raw_pack text cleaned_text str raw_pack text span _ self _parser spans cleaned_text cleaned_text replace raw_pack text span begin span end source_pack set_text cleaned_text class htmltagrecovery multipackprocessor def _process self input_pack multipack raw_pack datapack input_pack get_pack raw source_pack datapack input_pack get_pack source target_pack datapack input_pack get_pack target result_pack datapack input_pack add_pack result result_text str raw_pack text sent_src sent_tgt zip source_pack get sentence target_pack get sentence result_text result_text replace sent_src text sent_tgt text result_pack set_text result_text able create translation management system inserting two processors introduced previous machine translation pipeline pipeline html handling pipeline pipeline pipeline datapack pipeline set_reader stringreader pipeline multipackboxer config pack_name raw pipeline htmltagcleaner pipeline nltksentencesegmenter selector namematchselector selector_config select_name source pipeline machinetranslationmpprocessor config pretrained_model small pipeline htmltagrecovery pipeline initialize multipack pipeline process_dataset html_input print multipack get_pack raw text print multipack get_pack result text selector code snippet utilize namematchselector select one specific datapack multipack based reference name select_name allows nltksentencesegmenter process specified datapack replace translation model remote translation services replace mt model online translation api section learn use different translation serviceforte also allows us update translation model integrate seamlessly original pipeline example want offload translation task online service need update translation processor need change components pipeline get api key following instructions https api_key input enter api key import requests import uuid class onlinemachinetranslationmpprocessor multipackprocessor translate input text output file use online translator api def initialize self resources configs super initialize resources configs self url configs endpoint configs path self from_lang configs from_lang self to_lang configs to_lang self subscription_key configs subscription_key self subscription_region configs subscription_region def _process self input_pack multipack source_pack datapack input_pack get_pack source target_pack datapack input_pack add_pack target params api version en de build request headers ocp apim subscription key self subscription_key ocp apim subscription region self subscription_region content type application json x clienttraceid str uuid uuid pass one object body body text source_pack text request requests post self url params params headers headers json body result request json target_pack set_text join trans text trans result translations classmethod def default_configs cls return from_lang en to_lang de endpoint https path translate subscription_key none subscription_region westus x clienttraceid str uuid uuid nlp pipeline pipeline datapack nlp set_reader stringreader nlp nltksentencesegmenter nlp multipackboxer config pack_name source nlp onlinemachinetranslationmpprocessor config from_lang en to_lang de endpoint https path translate subscription_key api_key subscription_region westus x clienttraceid str uuid uuid nlp initialize multipack nlp process_dataset input_string print source text multipack get_pack source text print ntarget text multipack get_pack target text save load pipeline save whole pipeline save section learn export import forte pipelineforte also allow us save pipeline disk serializes whole pipeline generates intermediate representation loaded later maybe different machine import os save_path str os path join os path dirname os path abspath pipeline yml nlp save save_path open save_path r f print f read pipeline saved try load pipeline see still functions expected new_nlp pipeline pipeline new_nlp init_from_config_path save_path new_nlp initialize multipack new_nlp process_dataset input_string print source text multipack get_pack source text print ntarget text multipack get_pack target text build machine translation system forte,"['p', 'build', 'machine', 'translation', 'system', 'fortetldr', 'tutorial', 'allows', 'build', 'machine', 'translation', 'system', 'glue', 'code', 'using', 'forte', 'open', 'source', 'ml', 'workflow', 'builder', 'xb', 'forte', 'makes', 'easy', 'compose', 'nlp', 'pipeline', 'regardless', 'heterogeneity', 'data', 'processes', 'modular', 'easily', 'editable', 'system', 'allows', 'users', 'break', 'complex', 'problems', 'composable', 'pipelines', 'enables', 'inter', 'operations', 'across', 'tasks', 'unified', 'data', 'format', 'tutorial', 'includes', 'read', 'data', 'source', 'create', 'simple', 'nlp', 'pipeline', 'maintain', 'store', 'input', 'data', 'process', 'data', 'pipeline', 'perform', 'sentence', 'segmentation', 'annotate', 'query', 'data', 'translate', 'input', 'text', 'pre', 'trained', 'model', 'manage', 'multiple', 'data', 'objects', 'handle', 'practical', 'requests', 'handle', 'structures', 'like', 'html', 'data', 'select', 'single', 'data', 'object', 'processing', 'replace', 'translation', 'model', 'remote', 'translation', 'services', 'save', 'load', 'pipelinerun', 'following', 'command', 'install', 'required', 'dependencies', 'tutorial', 'recommended', 'install', 'command', 'line', 'pip', 'install', 'forte', 'forte', 'nltk', 'requests', 'certain', 'environment', 'may', 'run', 'troubles', 'installing', 'transformers', 'requiring', 'rust', 'workaround', 'https', 'may', 'want', 'try', 'different', 'pytorch', 'version', 'depending', 'platform', 'can', 'not', 'install', 'pytorch', 'try', 'locate', 'problem', 'https', 'certain', 'environment', 'installation', 'may', 'fail', 'workaround', 'https', 'read', 'data', 'source', 'create', 'simple', 'pipeline', 'start', 'reader', 'section', 'learn', 'reader', 'need', 'compose', 'simple', 'pipeline', 'pre', 'built', 'reader', 'xb', 'forte', 'import', 'pipelinefrom', 'forte', 'data', 'readers', 'import', 'terminalreader', 'pipeline', 'pipeline', 'pipeline', 'pipelines', 'need', 'reader', 'read', 'parse', 'input', 'data', 'make', 'pipeline', 'read', 'queries', 'user', 'command', 'line', 'terminal', 'use', 'terminalreader', 'class', 'provided', 'forte', 'terminalreader', 'transforms', 'user', 'query', 'datapack', 'object', 'unified', 'data', 'format', 'nlp', 'makes', 'easy', 'connect', 'different', 'nlp', 'tools', 'together', 'forte', 'processors', 'pipeline', 'set_reader', 'terminalreader', 'run', 'pipeline', 'consisting', 'single', 'terminalreader', 'call', 'process_dataset', 'return', 'iterator', 'datapack', 'objects', 'second', 'line', 'following', 'code', 'snippet', 'retrieves', 'first', 'user', 'query', 'terminalreader', 'pipeline', 'initialize', 'datapack', 'next', 'pipeline', 'process_dataset', 'print', 'datapack', 'text', 'maintain', 'store', 'input', 'data', 'datapack', 'section', 'learn', 'datapack', 'object', 'need', 'itforte', 'helps', 'demystify', 'data', 'lineage', 'increase', 'traceability', 'data', 'flows', 'along', 'pipeline', 'features', 'generated', 'interface', 'data', 'model', 'similar', 'cargo', 'ship', 'loads', 'transports', 'goods', 'one', 'port', 'another', 'data', 'pack', 'carries', 'information', 'passing', 'module', 'updates', 'ontology', 'states', 'along', 'way', 'https', 'datapack', 'multi', 'modality', 'datapack', 'supports', 'text', 'data', 'also', 'audio', 'image', 'data', 'https', 'process', 'data', 'pipeline', 'perform', 'sentence', 'segmentation', 'pre', 'built', 'forte', 'processor', 'pipeline', 'section', 'learn', 'processor', 'need', 'pre', 'built', 'processor', 'pipelinea', 'forte', 'processor', 'takes', 'datapacks', 'inputs', 'processes', 'stores', 'outputs', 'datapacks', 'processors', 'going', 'use', 'section', 'packprocessors', 'expect', 'exactly', 'one', 'datapack', 'input', 'store', 'outputs', 'back', 'datapack', 'following', 'two', 'lines', 'code', 'shows', 'pre', 'built', 'processor', 'nltksentencesegmenter', 'added', 'pipeline', 'fortex', 'nltk', 'nltk_processors', 'import', 'nltksentencesegmenter', 'pipeline', 'nltksentencesegmenter', 'run', 'pipeline', 'nltksentencesegmenter', 'processor', 'split', 'user', 'query', 'sentences', 'store', 'back', 'datapack', 'created', 'terminalreader', 'code', 'snippet', 'shows', 'get', 'sentences', 'first', 'query', 'https', 'ft', 'onto', 'base_ontology', 'import', 'sentence', 'pipeline', 'initialize', 'sent', 'next', 'pipeline', 'process_dataset', 'get', 'sentence', 'print', 'sent', 'text', 'annotate', 'query', 'data', 'ontology', 'section', 'learn', 'ontology', 'system', 'need', 'write', 'customized', 'ontology', 'use', 'sentence', 'pre', 'defined', 'ontology', 'provided', 'forte', 'used', 'nltksentencesegmenter', 'annotate', 'sentence', 'text', 'forte', 'built', 'top', 'ontology', 'system', 'defines', 'relations', 'nlp', 'annotations', 'example', 'relation', 'documents', 'two', 'core', 'forte', 'ontology', 'specified', 'via', 'json', 'format', 'tools', 'provided', 'convert', 'ontology', 'production', 'code', 'python', 'https', 'also', 'define', 'customized', 'ontologies', 'dataclasses', 'import', 'dataclass', 'forte', 'data', 'ontology', 'top', 'import', 'annotation', 'typing', 'import', 'optional', 'dataclass', 'class', 'article', 'annotation', 'language', 'optional', 'str', 'def', '__init__', 'self', 'pack', 'begin', 'int', 'end', 'int', 'super', '__init__', 'pack', 'begin', 'end', 'simple', 'example', 'showing', 'query', 'sentences', 'ontology', 'created', 'forte', 'data', 'import', 'datapack', 'sentences', 'want', 'get', 'better', 'making', 'delicious', 'bbq', 'opportunity', 'put', 'calendar', 'thursday', 'september', 'nd', 'join', 'world', 'class', 'bbq', 'champion', 'tony', 'balay', 'lonestar', 'smoke', 'rangers', 'datapack', 'datapack', 'datapack', 'sentences', 'datapack', 'annotate', 'sentence', 'sentences', 'datapack', 'set_text', 'datapack', 'text', 'sentence', 'datapack', 'add_entry', 'sentence', 'datapack', 'len', 'datapack', 'text', 'len', 'sentence', 'len', 'datapack', 'text', 'annotate', 'whole', 'text', 'article', 'article', 'article', 'article', 'datapack', 'len', 'datapack', 'text', 'article', 'language', 'en', 'datapack', 'add_entry', 'article', 'article', 'datapack', 'get', 'article', 'print', 'farticle', 'language', 'article', 'language', 'sentence', 'article', 'get', 'sentence', 'print', 'sentence', 'text', 'previous', 'example', 'following', 'ontologies', 'inheritance', 'sentence', 'article', 'inherit', 'annotation', 'used', 'represent', 'text', 'data', 'article', 'language', 'field', 'represent', 'text', 'language', 'https', 'actually', 'support', 'text', 'ontology', 'also', 'audio', 'image', 'link', 'represent', 'relationships', 'two', 'entries', 'https', 'annotation', 'inherited', 'text', 'entries', 'usually', 'span', 'retrieve', 'partial', 'text', 'full', 'text', 'article', 'shown', 'previous', 'example', 'inherits', 'annotation', 'contains', 'language', 'field', 'differentiate', 'english', 'german', 'single', 'datapack', 'example', 'english', 'article', 'span', 'english', 'text', 'datapack', 'likewise', 'german', 'article', 'span', 'german', 'text', 'datapack', 'sentence', 'example', 'used', 'break', 'article', 'pass', 'sentences', 'mt', 'pipeline', 'audioannotation', 'inherited', 'audio', 'entries', 'usually', 'audio', 'span', 'retrieve', 'partial', 'audio', 'full', 'audio', 'recording', 'example', 'subclass', 'audioannotation', 'extra', 'recording_class', 'field', 'denoting', 'classes', 'audio', 'belongs', 'imageannotation', 'inherited', 'image', 'entries', 'usually', 'payload', 'index', 'pointing', 'loaded', 'image', 'array', 'boundingbox', 'example', 'subclass', 'imageannotation', 'picture', 'shows', 'inheritance', 'relationships', 'ontology', 'classes', 'due', 'nature', 'cv', 'objects', 'advantage', 'forte', 'ontology', 'supports', 'complex', 'inheritance', 'users', 'inherit', 'existing', 'ontology', 'ontology', 'features', 'needs', 'link', 'inherited', 'link', 'like', 'entries', 'parent', 'child', 'relationlink', 'example', 'subclass', 'link', 'class', 'attribute', 'specifying', 'relation', 'type', 'translate', 'input', 'text', 'pre', 'trained', 'model', 'create', 'machine', 'translation', 'processor', 'section', 'learn', 'basics', 'machine', 'translation', 'process', 'wrap', 'pre', 'trained', 'machine', 'translation', 'model', 'forte', 'processortranslation', 'converts', 'sequence', 'text', 'one', 'language', 'another', 'tutorial', 'use', 'huggingface', 'transformer', 'model', 'translate', 'input', 'data', 'consists', 'several', 'steps', 'including', 'subword', 'tokenization', 'input', 'embedding', 'model', 'inference', 'decoding', 'etc', 'https', 'forte', 'generic', 'class', 'packprocessor', 'wraps', 'model', 'inference', 'related', 'components', 'behaviors', 'process', 'datapack', 'therefore', 'need', 'create', 'class', 'inherits', 'generic', 'method', 'packprocessor', 'class', 'definition', 'class', 'machinetranslationprocessor', 'packprocessor', 'forte', 'data', 'import', 'datapack', 'forte', 'data', 'readers', 'import', 'stringreader', 'forte', 'processors', 'base', 'import', 'packprocessor', 'transformers', 'import', 'ttokenizer', 'tforconditionalgeneration', 'class', 'machinetranslationprocessor', 'packprocessor', 'translate', 'input', 'text', 'output', 'file', 'def', 'initialize', 'self', 'resources', 'configs', 'super', 'initialize', 'resources', 'configs', 'initialize', 'tokenizer', 'model', 'model_name', 'str', 'self', 'configs', 'pretrained_model', 'self', 'tokenizer', 'ttokenizer', 'from_pretrained', 'model_name', 'self', 'model', 'tforconditionalgeneration', 'from_pretrained', 'model_name', 'self', 'task_prefix', 'translate', 'english', 'german', 'self', 'tokenizer', 'padding_side', 'left', 'self', 'tokenizer', 'pad_token', 'self', 'tokenizer', 'eos_token', 'def', '_process', 'self', 'input_pack', 'datapack', 'ende', 'machine', 'translation', 'inputs', 'self', 'tokenizer', 'self', 'task_prefix', 'sentence', 'text', 'sentence', 'input_pack', 'get', 'sentence', 'return_tensors', 'pt', 'padding', 'true', 'output_sequences', 'self', 'model', 'generate', 'input_ids', 'inputs', 'input_ids', 'attention_mask', 'inputs', 'attention_mask', 'do_sample', 'false', 'output', 'join', 'self', 'tokenizer', 'batch_decode', 'output_sequences', 'skip_special_tokens', 'true', 'src_article', 'article', 'article', 'input_pack', 'len', 'input_pack', 'text', 'src_article', 'language', 'en', 'input_pack', 'set_text', 'input_pack', 'text', 'n', 'n', 'output', 'tgt_article', 'article', 'article', 'input_pack', 'len', 'input_pack', 'text', 'len', 'output', 'len', 'input_pack', 'text', 'tgt_article', 'language', 'de', 'classmethod', 'def', 'default_configs', 'cls', 'return', 'pretrained_model', 'small', 'initialization', 'needed', 'components', 'users', 'need', 'consider', 'initializing', 'needed', 'nlp', 'components', 'inference', 'task', 'tokenizer', 'model', 'users', 'also', 'need', 'specify', 'configuration', 'configs', 'dictionary', 'like', 'object', 'specifies', 'configurations', 'components', 'model', 'name', 'mt', 'operations', 'datapack', 'initialization', 'already', 'needed', 'nlp', 'components', 'need', 'consider', 'several', 'mt', 'behaviors', 'based', 'forte', 'datapack', 'pre', 'process', 'text', 'data', 'retrieve', 'text', 'data', 'datapack', 'given', 'already', 'reads', 'data', 'data', 'source', 'since', 'better', 'performance', 'given', 'task', 'prompt', 'also', 'want', 'include', 'prompt', 'data', 'tokenization', 'transforms', 'input', 'text', 'sequences', 'tokens', 'token', 'ids', 'generate', 'output', 'sequences', 'model', 'decode', 'output', 'token', 'ids', 'sentences', 'using', 'tokenizer', 'generic', 'method', 'process', 'datapack', '_process', 'self', 'input_pack', 'datapack', 'tokenize', 'input', 'text', 'use', 'model', 'class', 'make', 'inference', 'decode', 'output', 'token', 'ids', 'finally', 'write', 'output', 'target', 'file', 'pipeline', 'run', 'machine', 'translation', 'task', 'input_string', 'str', 'join', 'sentences', 'pipeline', 'pipeline', 'pipeline', 'datapack', 'pipeline', 'set_reader', 'stringreader', 'pipeline', 'nltksentencesegmenter', 'pipeline', 'machinetranslationprocessor', 'pipeline', 'initialize', 'datapack', 'pipeline', 'process_dataset', 'input_string', 'article', 'datapack', 'get', 'article', 'print', 'f', 'narticle', 'language', 'article', 'language', 'article', 'text', 'ontology', 'datapack', 'provide', 'illustration', 'users', 'better', 'understand', 'internal', 'storage', 'datapack', 'see', 'text', 'data', 'sentence', 'articles', 'stored', 'span', 'annotations', 'text', 'data', 'easily', 'efficiently', 'retrieved', 'spans', 'https', 'manage', 'multiple', 'data', 'objects', 'multipack', 'better', 'way', 'store', 'source', 'target', 'text', 'section', 'learn', 'multipack', 'need', 'use', 'multipackthe', 'step', 'outputs', 'datapack', 'good', 'holding', 'data', 'one', 'specific', 'piece', 'text', 'complicated', 'pipeline', 'like', 'one', 'building', 'may', 'need', 'multiple', 'datapacks', 'passed', 'along', 'pipeline', 'multipack', 'help', 'multipack', 'manages', 'set', 'datapacks', 'indexed', 'names', 'multipackboxer', 'simple', 'forte', 'processor', 'converts', 'datapack', 'multipack', 'making', 'datapack', 'name', 'specified', 'via', 'config', 'use', 'wrap', 'datapack', 'contains', 'source', 'sentence', 'https', 'forte', 'data', 'import', 'multipack', 'forte', 'processors', 'base', 'import', 'multipackprocessor', 'forte', 'data', 'caster', 'import', 'multipackboxer', 'class', 'machinetranslationmpprocessor', 'multipackprocessor', 'translate', 'input', 'text', 'output', 'file', 'def', 'initialize', 'self', 'resources', 'configs', 'super', 'initialize', 'resources', 'configs', 'initialize', 'tokenizer', 'model', 'model_name', 'str', 'self', 'configs', 'pretrained_model', 'self', 'tokenizer', 'ttokenizer', 'from_pretrained', 'model_name', 'self', 'model', 'tforconditionalgeneration', 'from_pretrained', 'model_name', 'self', 'task_prefix', 'translate', 'english', 'german', 'self', 'tokenizer', 'padding_side', 'left', 'self', 'tokenizer', 'pad_token', 'self', 'tokenizer', 'eos_token', 'def', '_process', 'self', 'input_pack', 'multipack', 'source_pack', 'datapack', 'input_pack', 'get_pack', 'source', 'target_pack', 'datapack', 'input_pack', 'add_pack', 'target', 'ende', 'machine', 'translation', 'inputs', 'self', 'tokenizer', 'self', 'task_prefix', 'sentence', 'text', 'sentence', 'source_pack', 'get', 'sentence', 'return_tensors', 'pt', 'padding', 'true', 'output_sequences', 'self', 'model', 'generate', 'input_ids', 'inputs', 'input_ids', 'attention_mask', 'inputs', 'attention_mask', 'do_sample', 'false', 'annotate', 'source', 'article', 'src_article', 'article', 'article', 'source_pack', 'len', 'source_pack', 'text', 'src_article', 'language', 'en', 'annotate', 'sentence', 'output', 'self', 'tokenizer', 'batch_decode', 'output_sequences', 'skip_special_tokens', 'true', 'target_pack', 'set_text', 'target_pack', 'text', 'output', 'text_length', 'int', 'len', 'target_pack', 'text', 'sentence', 'target_pack', 'text_length', 'len', 'output', 'text_length', 'annotate', 'target', 'article', 'tgt_article', 'article', 'article', 'target_pack', 'len', 'target_pack', 'text', 'tgt_article', 'language', 'de', 'classmethod', 'def', 'default_configs', 'cls', 'return', 'pretrained_model', 'small', 'machinetranslationmpprocessor', 'writes', 'output', 'sentence', 'target', 'datapack', 'https', 'let', 'try', 'create', 'pipeline', 'utilizes', 'multipack', 'manage', 'text', 'different', 'languages', 'nlp', 'pipeline', 'pipeline', 'datapack', 'nlp', 'set_reader', 'stringreader', 'nlp', 'nltksentencesegmenter', 'nlp', 'multipackboxer', 'config', 'pack_name', 'source', 'nlp', 'machinetranslationmpprocessor', 'config', 'pretrained_model', 'small', 'nlp', 'initialize', 'multipack', 'nlp', 'process_dataset', 'input_string', 'pack_name', 'source', 'target', 'article', 'multipack', 'get_pack', 'pack_name', 'get', 'article', 'print', 'f', 'narticle', 'language', 'article', 'language', 'sentence', 'article', 'get', 'sentence', 'print', 'sentence', 'text', 'ontology', 'multipack', 'comparison', 'illustration', 'internal', 'storage', 'multipack', 'see', 'multipack', 'wraps', 'one', 'source', 'datapack', 'one', 'target', 'datapack', 'article', 'spans', 'based', 'two', 'separate', 'datapack', 'text', 'https', 'handle', 'practical', 'requests', 'handle', 'structures', 'like', 'html', 'data', 'section', 'learn', 'build', 'translation', 'management', 'system', 'preserve', 'structure', 'like', 'html', 'machine', 'translation', 'select', 'specific', 'datapack', 'multipack', 'processingin', 'previous', 'step', 'input', 'string', 'simple', 'paragraph', 'made', 'several', 'sentences', 'however', 'many', 'cases', 'might', 'need', 'handle', 'data', 'structural', 'information', 'html', 'xml', 'input', 'string', 'raw', 'html', 'data', 'machine', 'translation', 'pipeline', 'may', 'work', 'expected', 'html_input', 'str', 'beginners', 'bbq', 'class', 'want', 'get', 'better', 'making', 'delicious', 'bbq', 'opportunity', 'put', 'calendar', 'thursday', 'september', 'nd', 'join', 'world', 'class', 'bbq', 'champion', 'tony', 'balay', 'lonestar', 'smoke', 'rangers', 'nlp', 'initialize', 'multipack', 'nlp', 'process_dataset', 'html_input', 'print', 'source', 'text', 'multipack', 'get_pack', 'source', 'text', 'print', 'ntarget', 'text', 'multipack', 'get_pack', 'target', 'text', 'see', 'original', 'html', 'structure', 'broken', 'translated', 'output', 'order', 'handle', 'structured', 'data', 'like', 'html', 'need', 'update', 'current', 'design', 'pipeline', 'luckily', 'forte', 'pipelines', 'highly', 'modular', 'simply', 'insert', 'two', 'processors', 'without', 'updating', 'previous', 'pipeline', 'first', 'need', 'html', 'cleaner', 'parse', 'html', 'tags', 'input', 'string', 'picture', 'shows', 'effect', 'tag', 'remover', 'https', 'translation', 'finished', 'also', 'need', 'recover', 'html', 'structure', 'unstructured', 'translation', 'output', 'picture', 'shows', 'replace', 'one', 'source', 'sentence', 'one', 'target', 'sentence', 'given', 'target', 'sentence', 'ready', 'https', 'forte', 'data', 'import', 'namematchselector', 'forte', 'data', 'readers', 'html_reader', 'import', 'fortehtmlparser', 'class', 'htmltagcleaner', 'multipackprocessor', 'def', 'initialize', 'self', 'resources', 'configs', 'super', 'initialize', 'resources', 'configs', 'self', '_parser', 'fortehtmlparser', 'def', '_process', 'self', 'input_pack', 'multipack', 'raw_pack', 'datapack', 'input_pack', 'get_pack', 'raw', 'source_pack', 'datapack', 'input_pack', 'add_pack', 'source', 'self', '_parser', 'feed', 'raw_pack', 'text', 'cleaned_text', 'str', 'raw_pack', 'text', 'span', '_', 'self', '_parser', 'spans', 'cleaned_text', 'cleaned_text', 'replace', 'raw_pack', 'text', 'span', 'begin', 'span', 'end', 'source_pack', 'set_text', 'cleaned_text', 'class', 'htmltagrecovery', 'multipackprocessor', 'def', '_process', 'self', 'input_pack', 'multipack', 'raw_pack', 'datapack', 'input_pack', 'get_pack', 'raw', 'source_pack', 'datapack', 'input_pack', 'get_pack', 'source', 'target_pack', 'datapack', 'input_pack', 'get_pack', 'target', 'result_pack', 'datapack', 'input_pack', 'add_pack', 'result', 'result_text', 'str', 'raw_pack', 'text', 'sent_src', 'sent_tgt', 'zip', 'source_pack', 'get', 'sentence', 'target_pack', 'get', 'sentence', 'result_text', 'result_text', 'replace', 'sent_src', 'text', 'sent_tgt', 'text', 'result_pack', 'set_text', 'result_text', 'able', 'create', 'translation', 'management', 'system', 'inserting', 'two', 'processors', 'introduced', 'previous', 'machine', 'translation', 'pipeline', 'pipeline', 'html', 'handling', 'pipeline', 'pipeline', 'pipeline', 'datapack', 'pipeline', 'set_reader', 'stringreader', 'pipeline', 'multipackboxer', 'config', 'pack_name', 'raw', 'pipeline', 'htmltagcleaner', 'pipeline', 'nltksentencesegmenter', 'selector', 'namematchselector', 'selector_config', 'select_name', 'source', 'pipeline', 'machinetranslationmpprocessor', 'config', 'pretrained_model', 'small', 'pipeline', 'htmltagrecovery', 'pipeline', 'initialize', 'multipack', 'pipeline', 'process_dataset', 'html_input', 'print', 'multipack', 'get_pack', 'raw', 'text', 'print', 'multipack', 'get_pack', 'result', 'text', 'selector', 'code', 'snippet', 'utilize', 'namematchselector', 'select', 'one', 'specific', 'datapack', 'multipack', 'based', 'reference', 'name', 'select_name', 'allows', 'nltksentencesegmenter', 'process', 'specified', 'datapack', 'replace', 'translation', 'model', 'remote', 'translation', 'services', 'replace', 'mt', 'model', 'online', 'translation', 'api', 'section', 'learn', 'use', 'different', 'translation', 'serviceforte', 'also', 'allows', 'us', 'update', 'translation', 'model', 'integrate', 'seamlessly', 'original', 'pipeline', 'example', 'want', 'offload', 'translation', 'task', 'online', 'service', 'need', 'update', 'translation', 'processor', 'need', 'change', 'components', 'pipeline', 'get', 'api', 'key', 'following', 'instructions', 'https', 'api_key', 'input', 'enter', 'api', 'key', 'import', 'requests', 'import', 'uuid', 'class', 'onlinemachinetranslationmpprocessor', 'multipackprocessor', 'translate', 'input', 'text', 'output', 'file', 'use', 'online', 'translator', 'api', 'def', 'initialize', 'self', 'resources', 'configs', 'super', 'initialize', 'resources', 'configs', 'self', 'url', 'configs', 'endpoint', 'configs', 'path', 'self', 'from_lang', 'configs', 'from_lang', 'self', 'to_lang', 'configs', 'to_lang', 'self', 'subscription_key', 'configs', 'subscription_key', 'self', 'subscription_region', 'configs', 'subscription_region', 'def', '_process', 'self', 'input_pack', 'multipack', 'source_pack', 'datapack', 'input_pack', 'get_pack', 'source', 'target_pack', 'datapack', 'input_pack', 'add_pack', 'target', 'params', 'api', 'version', 'en', 'de', 'build', 'request', 'headers', 'ocp', 'apim', 'subscription', 'key', 'self', 'subscription_key', 'ocp', 'apim', 'subscription', 'region', 'self', 'subscription_region', 'content', 'type', 'application', 'json', 'x', 'clienttraceid', 'str', 'uuid', 'uuid', 'pass', 'one', 'object', 'body', 'body', 'text', 'source_pack', 'text', 'request', 'requests', 'post', 'self', 'url', 'params', 'params', 'headers', 'headers', 'json', 'body', 'result', 'request', 'json', 'target_pack', 'set_text', 'join', 'trans', 'text', 'trans', 'result', 'translations', 'classmethod', 'def', 'default_configs', 'cls', 'return', 'from_lang', 'en', 'to_lang', 'de', 'endpoint', 'https', 'path', 'translate', 'subscription_key', 'none', 'subscription_region', 'westus', 'x', 'clienttraceid', 'str', 'uuid', 'uuid', 'nlp', 'pipeline', 'pipeline', 'datapack', 'nlp', 'set_reader', 'stringreader', 'nlp', 'nltksentencesegmenter', 'nlp', 'multipackboxer', 'config', 'pack_name', 'source', 'nlp', 'onlinemachinetranslationmpprocessor', 'config', 'from_lang', 'en', 'to_lang', 'de', 'endpoint', 'https', 'path', 'translate', 'subscription_key', 'api_key', 'subscription_region', 'westus', 'x', 'clienttraceid', 'str', 'uuid', 'uuid', 'nlp', 'initialize', 'multipack', 'nlp', 'process_dataset', 'input_string', 'print', 'source', 'text', 'multipack', 'get_pack', 'source', 'text', 'print', 'ntarget', 'text', 'multipack', 'get_pack', 'target', 'text', 'save', 'load', 'pipeline', 'save', 'whole', 'pipeline', 'save', 'section', 'learn', 'export', 'import', 'forte', 'pipelineforte', 'also', 'allow', 'us', 'save', 'pipeline', 'disk', 'serializes', 'whole', 'pipeline', 'generates', 'intermediate', 'representation', 'loaded', 'later', 'maybe', 'different', 'machine', 'import', 'os', 'save_path', 'str', 'os', 'path', 'join', 'os', 'path', 'dirname', 'os', 'path', 'abspath', 'pipeline', 'yml', 'nlp', 'save', 'save_path', 'open', 'save_path', 'r', 'f', 'print', 'f', 'read', 'pipeline', 'saved', 'try', 'load', 'pipeline', 'see', 'still', 'functions', 'expected', 'new_nlp', 'pipeline', 'pipeline', 'new_nlp', 'init_from_config_path', 'save_path', 'new_nlp', 'initialize', 'multipack', 'new_nlp', 'process_dataset', 'input_string', 'print', 'source', 'text', 'multipack', 'get_pack', 'source', 'text', 'print', 'ntarget', 'text', 'multipack', 'get_pack', 'target', 'text', 'build', 'machine', 'translation', 'system', 'forte']","['p', 'build', 'machin', 'translat', 'system', 'fortetldr', 'tutori', 'allow', 'build', 'machin', 'translat', 'system', 'glue', 'code', 'use', 'fort', 'open', 'sourc', 'ml', 'workflow', 'builder', 'xb', 'fort', 'make', 'easi', 'compos', 'nlp', 'pipelin', 'regardless', 'heterogen', 'data', 'process', 'modular', 'easili', 'edit', 'system', 'allow', 'user', 'break', 'complex', 'problem', 'compos', 'pipelin', 'enabl', 'inter', 'oper', 'across', 'task', 'unifi', 'data', 'format', 'tutori', 'includ', 'read', 'data', 'sourc', 'creat', 'simpl', 'nlp', 'pipelin', 'maintain', 'store', 'input', 'data', 'process', 'data', 'pipelin', 'perform', 'sentenc', 'segment', 'annot', 'queri', 'data', 'translat', 'input', 'text', 'pre', 'train', 'model', 'manag', 'multipl', 'data', 'object', 'handl', 'practic', 'request', 'handl', 'structur', 'like', 'html', 'data', 'select', 'singl', 'data', 'object', 'process', 'replac', 'translat', 'model', 'remot', 'translat', 'servic', 'save', 'load', 'pipelinerun', 'follow', 'command', 'instal', 'requir', 'depend', 'tutori', 'recommend', 'instal', 'command', 'line', 'pip', 'instal', 'fort', 'fort', 'nltk', 'request', 'certain', 'environ', 'may', 'run', 'troubl', 'instal', 'transform', 'requir', 'rust', 'workaround', 'http', 'may', 'want', 'tri', 'differ', 'pytorch', 'version', 'depend', 'platform', 'can', 'not', 'instal', 'pytorch', 'tri', 'locat', 'problem', 'http', 'certain', 'environ', 'instal', 'may', 'fail', 'workaround', 'http', 'read', 'data', 'sourc', 'creat', 'simpl', 'pipelin', 'start', 'reader', 'section', 'learn', 'reader', 'need', 'compos', 'simpl', 'pipelin', 'pre', 'built', 'reader', 'xb', 'fort', 'import', 'pipelinefrom', 'fort', 'data', 'reader', 'import', 'terminalread', 'pipelin', 'pipelin', 'pipelin', 'pipelin', 'need', 'reader', 'read', 'pars', 'input', 'data', 'make', 'pipelin', 'read', 'queri', 'user', 'command', 'line', 'termin', 'use', 'terminalread', 'class', 'provid', 'fort', 'terminalread', 'transform', 'user', 'queri', 'datapack', 'object', 'unifi', 'data', 'format', 'nlp', 'make', 'easi', 'connect', 'differ', 'nlp', 'tool', 'togeth', 'fort', 'processor', 'pipelin', 'set_read', 'terminalread', 'run', 'pipelin', 'consist', 'singl', 'terminalread', 'call', 'process_dataset', 'return', 'iter', 'datapack', 'object', 'second', 'line', 'follow', 'code', 'snippet', 'retriev', 'first', 'user', 'queri', 'terminalread', 'pipelin', 'initi', 'datapack', 'next', 'pipelin', 'process_dataset', 'print', 'datapack', 'text', 'maintain', 'store', 'input', 'data', 'datapack', 'section', 'learn', 'datapack', 'object', 'need', 'itfort', 'help', 'demystifi', 'data', 'lineag', 'increas', 'traceabl', 'data', 'flow', 'along', 'pipelin', 'featur', 'gener', 'interfac', 'data', 'model', 'similar', 'cargo', 'ship', 'load', 'transport', 'good', 'one', 'port', 'anoth', 'data', 'pack', 'carri', 'inform', 'pass', 'modul', 'updat', 'ontolog', 'state', 'along', 'way', 'http', 'datapack', 'multi', 'modal', 'datapack', 'support', 'text', 'data', 'also', 'audio', 'imag', 'data', 'http', 'process', 'data', 'pipelin', 'perform', 'sentenc', 'segment', 'pre', 'built', 'fort', 'processor', 'pipelin', 'section', 'learn', 'processor', 'need', 'pre', 'built', 'processor', 'pipelinea', 'fort', 'processor', 'take', 'datapack', 'input', 'process', 'store', 'output', 'datapack', 'processor', 'go', 'use', 'section', 'packprocessor', 'expect', 'exactli', 'one', 'datapack', 'input', 'store', 'output', 'back', 'datapack', 'follow', 'two', 'line', 'code', 'show', 'pre', 'built', 'processor', 'nltksentencesegment', 'ad', 'pipelin', 'fortex', 'nltk', 'nltk_processor', 'import', 'nltksentencesegment', 'pipelin', 'nltksentencesegment', 'run', 'pipelin', 'nltksentencesegment', 'processor', 'split', 'user', 'queri', 'sentenc', 'store', 'back', 'datapack', 'creat', 'terminalread', 'code', 'snippet', 'show', 'get', 'sentenc', 'first', 'queri', 'http', 'ft', 'onto', 'base_ontolog', 'import', 'sentenc', 'pipelin', 'initi', 'sent', 'next', 'pipelin', 'process_dataset', 'get', 'sentenc', 'print', 'sent', 'text', 'annot', 'queri', 'data', 'ontolog', 'section', 'learn', 'ontolog', 'system', 'need', 'write', 'custom', 'ontolog', 'use', 'sentenc', 'pre', 'defin', 'ontolog', 'provid', 'fort', 'use', 'nltksentencesegment', 'annot', 'sentenc', 'text', 'fort', 'built', 'top', 'ontolog', 'system', 'defin', 'relat', 'nlp', 'annot', 'exampl', 'relat', 'document', 'two', 'core', 'fort', 'ontolog', 'specifi', 'via', 'json', 'format', 'tool', 'provid', 'convert', 'ontolog', 'product', 'code', 'python', 'http', 'also', 'defin', 'custom', 'ontolog', 'dataclass', 'import', 'dataclass', 'fort', 'data', 'ontolog', 'top', 'import', 'annot', 'type', 'import', 'option', 'dataclass', 'class', 'articl', 'annot', 'languag', 'option', 'str', 'def', '__init__', 'self', 'pack', 'begin', 'int', 'end', 'int', 'super', '__init__', 'pack', 'begin', 'end', 'simpl', 'exampl', 'show', 'queri', 'sentenc', 'ontolog', 'creat', 'fort', 'data', 'import', 'datapack', 'sentenc', 'want', 'get', 'better', 'make', 'delici', 'bbq', 'opportun', 'put', 'calendar', 'thursday', 'septemb', 'nd', 'join', 'world', 'class', 'bbq', 'champion', 'toni', 'balay', 'lonestar', 'smoke', 'ranger', 'datapack', 'datapack', 'datapack', 'sentenc', 'datapack', 'annot', 'sentenc', 'sentenc', 'datapack', 'set_text', 'datapack', 'text', 'sentenc', 'datapack', 'add_entri', 'sentenc', 'datapack', 'len', 'datapack', 'text', 'len', 'sentenc', 'len', 'datapack', 'text', 'annot', 'whole', 'text', 'articl', 'articl', 'articl', 'articl', 'datapack', 'len', 'datapack', 'text', 'articl', 'languag', 'en', 'datapack', 'add_entri', 'articl', 'articl', 'datapack', 'get', 'articl', 'print', 'farticl', 'languag', 'articl', 'languag', 'sentenc', 'articl', 'get', 'sentenc', 'print', 'sentenc', 'text', 'previou', 'exampl', 'follow', 'ontolog', 'inherit', 'sentenc', 'articl', 'inherit', 'annot', 'use', 'repres', 'text', 'data', 'articl', 'languag', 'field', 'repres', 'text', 'languag', 'http', 'actual', 'support', 'text', 'ontolog', 'also', 'audio', 'imag', 'link', 'repres', 'relationship', 'two', 'entri', 'http', 'annot', 'inherit', 'text', 'entri', 'usual', 'span', 'retriev', 'partial', 'text', 'full', 'text', 'articl', 'shown', 'previou', 'exampl', 'inherit', 'annot', 'contain', 'languag', 'field', 'differenti', 'english', 'german', 'singl', 'datapack', 'exampl', 'english', 'articl', 'span', 'english', 'text', 'datapack', 'likewis', 'german', 'articl', 'span', 'german', 'text', 'datapack', 'sentenc', 'exampl', 'use', 'break', 'articl', 'pass', 'sentenc', 'mt', 'pipelin', 'audioannot', 'inherit', 'audio', 'entri', 'usual', 'audio', 'span', 'retriev', 'partial', 'audio', 'full', 'audio', 'record', 'exampl', 'subclass', 'audioannot', 'extra', 'recording_class', 'field', 'denot', 'class', 'audio', 'belong', 'imageannot', 'inherit', 'imag', 'entri', 'usual', 'payload', 'index', 'point', 'load', 'imag', 'array', 'boundingbox', 'exampl', 'subclass', 'imageannot', 'pictur', 'show', 'inherit', 'relationship', 'ontolog', 'class', 'due', 'natur', 'cv', 'object', 'advantag', 'fort', 'ontolog', 'support', 'complex', 'inherit', 'user', 'inherit', 'exist', 'ontolog', 'ontolog', 'featur', 'need', 'link', 'inherit', 'link', 'like', 'entri', 'parent', 'child', 'relationlink', 'exampl', 'subclass', 'link', 'class', 'attribut', 'specifi', 'relat', 'type', 'translat', 'input', 'text', 'pre', 'train', 'model', 'creat', 'machin', 'translat', 'processor', 'section', 'learn', 'basic', 'machin', 'translat', 'process', 'wrap', 'pre', 'train', 'machin', 'translat', 'model', 'fort', 'processortransl', 'convert', 'sequenc', 'text', 'one', 'languag', 'anoth', 'tutori', 'use', 'huggingfac', 'transform', 'model', 'translat', 'input', 'data', 'consist', 'sever', 'step', 'includ', 'subword', 'token', 'input', 'embed', 'model', 'infer', 'decod', 'etc', 'http', 'fort', 'gener', 'class', 'packprocessor', 'wrap', 'model', 'infer', 'relat', 'compon', 'behavior', 'process', 'datapack', 'therefor', 'need', 'creat', 'class', 'inherit', 'gener', 'method', 'packprocessor', 'class', 'definit', 'class', 'machinetranslationprocessor', 'packprocessor', 'fort', 'data', 'import', 'datapack', 'fort', 'data', 'reader', 'import', 'stringread', 'fort', 'processor', 'base', 'import', 'packprocessor', 'transform', 'import', 'ttoken', 'tforconditionalgener', 'class', 'machinetranslationprocessor', 'packprocessor', 'translat', 'input', 'text', 'output', 'file', 'def', 'initi', 'self', 'resourc', 'config', 'super', 'initi', 'resourc', 'config', 'initi', 'token', 'model', 'model_nam', 'str', 'self', 'config', 'pretrained_model', 'self', 'token', 'ttoken', 'from_pretrain', 'model_nam', 'self', 'model', 'tforconditionalgener', 'from_pretrain', 'model_nam', 'self', 'task_prefix', 'translat', 'english', 'german', 'self', 'token', 'padding_sid', 'left', 'self', 'token', 'pad_token', 'self', 'token', 'eos_token', 'def', '_process', 'self', 'input_pack', 'datapack', 'end', 'machin', 'translat', 'input', 'self', 'token', 'self', 'task_prefix', 'sentenc', 'text', 'sentenc', 'input_pack', 'get', 'sentenc', 'return_tensor', 'pt', 'pad', 'true', 'output_sequ', 'self', 'model', 'gener', 'input_id', 'input', 'input_id', 'attention_mask', 'input', 'attention_mask', 'do_sampl', 'fals', 'output', 'join', 'self', 'token', 'batch_decod', 'output_sequ', 'skip_special_token', 'true', 'src_articl', 'articl', 'articl', 'input_pack', 'len', 'input_pack', 'text', 'src_articl', 'languag', 'en', 'input_pack', 'set_text', 'input_pack', 'text', 'n', 'n', 'output', 'tgt_articl', 'articl', 'articl', 'input_pack', 'len', 'input_pack', 'text', 'len', 'output', 'len', 'input_pack', 'text', 'tgt_articl', 'languag', 'de', 'classmethod', 'def', 'default_config', 'cl', 'return', 'pretrained_model', 'small', 'initi', 'need', 'compon', 'user', 'need', 'consid', 'initi', 'need', 'nlp', 'compon', 'infer', 'task', 'token', 'model', 'user', 'also', 'need', 'specifi', 'configur', 'config', 'dictionari', 'like', 'object', 'specifi', 'configur', 'compon', 'model', 'name', 'mt', 'oper', 'datapack', 'initi', 'alreadi', 'need', 'nlp', 'compon', 'need', 'consid', 'sever', 'mt', 'behavior', 'base', 'fort', 'datapack', 'pre', 'process', 'text', 'data', 'retriev', 'text', 'data', 'datapack', 'given', 'alreadi', 'read', 'data', 'data', 'sourc', 'sinc', 'better', 'perform', 'given', 'task', 'prompt', 'also', 'want', 'includ', 'prompt', 'data', 'token', 'transform', 'input', 'text', 'sequenc', 'token', 'token', 'id', 'gener', 'output', 'sequenc', 'model', 'decod', 'output', 'token', 'id', 'sentenc', 'use', 'token', 'gener', 'method', 'process', 'datapack', '_process', 'self', 'input_pack', 'datapack', 'token', 'input', 'text', 'use', 'model', 'class', 'make', 'infer', 'decod', 'output', 'token', 'id', 'final', 'write', 'output', 'target', 'file', 'pipelin', 'run', 'machin', 'translat', 'task', 'input_str', 'str', 'join', 'sentenc', 'pipelin', 'pipelin', 'pipelin', 'datapack', 'pipelin', 'set_read', 'stringread', 'pipelin', 'nltksentencesegment', 'pipelin', 'machinetranslationprocessor', 'pipelin', 'initi', 'datapack', 'pipelin', 'process_dataset', 'input_str', 'articl', 'datapack', 'get', 'articl', 'print', 'f', 'narticl', 'languag', 'articl', 'languag', 'articl', 'text', 'ontolog', 'datapack', 'provid', 'illustr', 'user', 'better', 'understand', 'intern', 'storag', 'datapack', 'see', 'text', 'data', 'sentenc', 'articl', 'store', 'span', 'annot', 'text', 'data', 'easili', 'effici', 'retriev', 'span', 'http', 'manag', 'multipl', 'data', 'object', 'multipack', 'better', 'way', 'store', 'sourc', 'target', 'text', 'section', 'learn', 'multipack', 'need', 'use', 'multipackth', 'step', 'output', 'datapack', 'good', 'hold', 'data', 'one', 'specif', 'piec', 'text', 'complic', 'pipelin', 'like', 'one', 'build', 'may', 'need', 'multipl', 'datapack', 'pass', 'along', 'pipelin', 'multipack', 'help', 'multipack', 'manag', 'set', 'datapack', 'index', 'name', 'multipackbox', 'simpl', 'fort', 'processor', 'convert', 'datapack', 'multipack', 'make', 'datapack', 'name', 'specifi', 'via', 'config', 'use', 'wrap', 'datapack', 'contain', 'sourc', 'sentenc', 'http', 'fort', 'data', 'import', 'multipack', 'fort', 'processor', 'base', 'import', 'multipackprocessor', 'fort', 'data', 'caster', 'import', 'multipackbox', 'class', 'machinetranslationmpprocessor', 'multipackprocessor', 'translat', 'input', 'text', 'output', 'file', 'def', 'initi', 'self', 'resourc', 'config', 'super', 'initi', 'resourc', 'config', 'initi', 'token', 'model', 'model_nam', 'str', 'self', 'config', 'pretrained_model', 'self', 'token', 'ttoken', 'from_pretrain', 'model_nam', 'self', 'model', 'tforconditionalgener', 'from_pretrain', 'model_nam', 'self', 'task_prefix', 'translat', 'english', 'german', 'self', 'token', 'padding_sid', 'left', 'self', 'token', 'pad_token', 'self', 'token', 'eos_token', 'def', '_process', 'self', 'input_pack', 'multipack', 'source_pack', 'datapack', 'input_pack', 'get_pack', 'sourc', 'target_pack', 'datapack', 'input_pack', 'add_pack', 'target', 'end', 'machin', 'translat', 'input', 'self', 'token', 'self', 'task_prefix', 'sentenc', 'text', 'sentenc', 'source_pack', 'get', 'sentenc', 'return_tensor', 'pt', 'pad', 'true', 'output_sequ', 'self', 'model', 'gener', 'input_id', 'input', 'input_id', 'attention_mask', 'input', 'attention_mask', 'do_sampl', 'fals', 'annot', 'sourc', 'articl', 'src_articl', 'articl', 'articl', 'source_pack', 'len', 'source_pack', 'text', 'src_articl', 'languag', 'en', 'annot', 'sentenc', 'output', 'self', 'token', 'batch_decod', 'output_sequ', 'skip_special_token', 'true', 'target_pack', 'set_text', 'target_pack', 'text', 'output', 'text_length', 'int', 'len', 'target_pack', 'text', 'sentenc', 'target_pack', 'text_length', 'len', 'output', 'text_length', 'annot', 'target', 'articl', 'tgt_articl', 'articl', 'articl', 'target_pack', 'len', 'target_pack', 'text', 'tgt_articl', 'languag', 'de', 'classmethod', 'def', 'default_config', 'cl', 'return', 'pretrained_model', 'small', 'machinetranslationmpprocessor', 'write', 'output', 'sentenc', 'target', 'datapack', 'http', 'let', 'tri', 'creat', 'pipelin', 'util', 'multipack', 'manag', 'text', 'differ', 'languag', 'nlp', 'pipelin', 'pipelin', 'datapack', 'nlp', 'set_read', 'stringread', 'nlp', 'nltksentencesegment', 'nlp', 'multipackbox', 'config', 'pack_nam', 'sourc', 'nlp', 'machinetranslationmpprocessor', 'config', 'pretrained_model', 'small', 'nlp', 'initi', 'multipack', 'nlp', 'process_dataset', 'input_str', 'pack_nam', 'sourc', 'target', 'articl', 'multipack', 'get_pack', 'pack_nam', 'get', 'articl', 'print', 'f', 'narticl', 'languag', 'articl', 'languag', 'sentenc', 'articl', 'get', 'sentenc', 'print', 'sentenc', 'text', 'ontolog', 'multipack', 'comparison', 'illustr', 'intern', 'storag', 'multipack', 'see', 'multipack', 'wrap', 'one', 'sourc', 'datapack', 'one', 'target', 'datapack', 'articl', 'span', 'base', 'two', 'separ', 'datapack', 'text', 'http', 'handl', 'practic', 'request', 'handl', 'structur', 'like', 'html', 'data', 'section', 'learn', 'build', 'translat', 'manag', 'system', 'preserv', 'structur', 'like', 'html', 'machin', 'translat', 'select', 'specif', 'datapack', 'multipack', 'processingin', 'previou', 'step', 'input', 'string', 'simpl', 'paragraph', 'made', 'sever', 'sentenc', 'howev', 'mani', 'case', 'might', 'need', 'handl', 'data', 'structur', 'inform', 'html', 'xml', 'input', 'string', 'raw', 'html', 'data', 'machin', 'translat', 'pipelin', 'may', 'work', 'expect', 'html_input', 'str', 'beginn', 'bbq', 'class', 'want', 'get', 'better', 'make', 'delici', 'bbq', 'opportun', 'put', 'calendar', 'thursday', 'septemb', 'nd', 'join', 'world', 'class', 'bbq', 'champion', 'toni', 'balay', 'lonestar', 'smoke', 'ranger', 'nlp', 'initi', 'multipack', 'nlp', 'process_dataset', 'html_input', 'print', 'sourc', 'text', 'multipack', 'get_pack', 'sourc', 'text', 'print', 'ntarget', 'text', 'multipack', 'get_pack', 'target', 'text', 'see', 'origin', 'html', 'structur', 'broken', 'translat', 'output', 'order', 'handl', 'structur', 'data', 'like', 'html', 'need', 'updat', 'current', 'design', 'pipelin', 'luckili', 'fort', 'pipelin', 'highli', 'modular', 'simpli', 'insert', 'two', 'processor', 'without', 'updat', 'previou', 'pipelin', 'first', 'need', 'html', 'cleaner', 'pars', 'html', 'tag', 'input', 'string', 'pictur', 'show', 'effect', 'tag', 'remov', 'http', 'translat', 'finish', 'also', 'need', 'recov', 'html', 'structur', 'unstructur', 'translat', 'output', 'pictur', 'show', 'replac', 'one', 'sourc', 'sentenc', 'one', 'target', 'sentenc', 'given', 'target', 'sentenc', 'readi', 'http', 'fort', 'data', 'import', 'namematchselector', 'fort', 'data', 'reader', 'html_reader', 'import', 'fortehtmlpars', 'class', 'htmltagclean', 'multipackprocessor', 'def', 'initi', 'self', 'resourc', 'config', 'super', 'initi', 'resourc', 'config', 'self', '_parser', 'fortehtmlpars', 'def', '_process', 'self', 'input_pack', 'multipack', 'raw_pack', 'datapack', 'input_pack', 'get_pack', 'raw', 'source_pack', 'datapack', 'input_pack', 'add_pack', 'sourc', 'self', '_parser', 'feed', 'raw_pack', 'text', 'cleaned_text', 'str', 'raw_pack', 'text', 'span', '_', 'self', '_parser', 'span', 'cleaned_text', 'cleaned_text', 'replac', 'raw_pack', 'text', 'span', 'begin', 'span', 'end', 'source_pack', 'set_text', 'cleaned_text', 'class', 'htmltagrecoveri', 'multipackprocessor', 'def', '_process', 'self', 'input_pack', 'multipack', 'raw_pack', 'datapack', 'input_pack', 'get_pack', 'raw', 'source_pack', 'datapack', 'input_pack', 'get_pack', 'sourc', 'target_pack', 'datapack', 'input_pack', 'get_pack', 'target', 'result_pack', 'datapack', 'input_pack', 'add_pack', 'result', 'result_text', 'str', 'raw_pack', 'text', 'sent_src', 'sent_tgt', 'zip', 'source_pack', 'get', 'sentenc', 'target_pack', 'get', 'sentenc', 'result_text', 'result_text', 'replac', 'sent_src', 'text', 'sent_tgt', 'text', 'result_pack', 'set_text', 'result_text', 'abl', 'creat', 'translat', 'manag', 'system', 'insert', 'two', 'processor', 'introduc', 'previou', 'machin', 'translat', 'pipelin', 'pipelin', 'html', 'handl', 'pipelin', 'pipelin', 'pipelin', 'datapack', 'pipelin', 'set_read', 'stringread', 'pipelin', 'multipackbox', 'config', 'pack_nam', 'raw', 'pipelin', 'htmltagclean', 'pipelin', 'nltksentencesegment', 'selector', 'namematchselector', 'selector_config', 'select_nam', 'sourc', 'pipelin', 'machinetranslationmpprocessor', 'config', 'pretrained_model', 'small', 'pipelin', 'htmltagrecoveri', 'pipelin', 'initi', 'multipack', 'pipelin', 'process_dataset', 'html_input', 'print', 'multipack', 'get_pack', 'raw', 'text', 'print', 'multipack', 'get_pack', 'result', 'text', 'selector', 'code', 'snippet', 'util', 'namematchselector', 'select', 'one', 'specif', 'datapack', 'multipack', 'base', 'refer', 'name', 'select_nam', 'allow', 'nltksentencesegment', 'process', 'specifi', 'datapack', 'replac', 'translat', 'model', 'remot', 'translat', 'servic', 'replac', 'mt', 'model', 'onlin', 'translat', 'api', 'section', 'learn', 'use', 'differ', 'translat', 'servicefort', 'also', 'allow', 'us', 'updat', 'translat', 'model', 'integr', 'seamlessli', 'origin', 'pipelin', 'exampl', 'want', 'offload', 'translat', 'task', 'onlin', 'servic', 'need', 'updat', 'translat', 'processor', 'need', 'chang', 'compon', 'pipelin', 'get', 'api', 'key', 'follow', 'instruct', 'http', 'api_key', 'input', 'enter', 'api', 'key', 'import', 'request', 'import', 'uuid', 'class', 'onlinemachinetranslationmpprocessor', 'multipackprocessor', 'translat', 'input', 'text', 'output', 'file', 'use', 'onlin', 'translat', 'api', 'def', 'initi', 'self', 'resourc', 'config', 'super', 'initi', 'resourc', 'config', 'self', 'url', 'config', 'endpoint', 'config', 'path', 'self', 'from_lang', 'config', 'from_lang', 'self', 'to_lang', 'config', 'to_lang', 'self', 'subscription_key', 'config', 'subscription_key', 'self', 'subscription_region', 'config', 'subscription_region', 'def', '_process', 'self', 'input_pack', 'multipack', 'source_pack', 'datapack', 'input_pack', 'get_pack', 'sourc', 'target_pack', 'datapack', 'input_pack', 'add_pack', 'target', 'param', 'api', 'version', 'en', 'de', 'build', 'request', 'header', 'ocp', 'apim', 'subscript', 'key', 'self', 'subscription_key', 'ocp', 'apim', 'subscript', 'region', 'self', 'subscription_region', 'content', 'type', 'applic', 'json', 'x', 'clienttraceid', 'str', 'uuid', 'uuid', 'pass', 'one', 'object', 'bodi', 'bodi', 'text', 'source_pack', 'text', 'request', 'request', 'post', 'self', 'url', 'param', 'param', 'header', 'header', 'json', 'bodi', 'result', 'request', 'json', 'target_pack', 'set_text', 'join', 'tran', 'text', 'tran', 'result', 'translat', 'classmethod', 'def', 'default_config', 'cl', 'return', 'from_lang', 'en', 'to_lang', 'de', 'endpoint', 'http', 'path', 'translat', 'subscription_key', 'none', 'subscription_region', 'westu', 'x', 'clienttraceid', 'str', 'uuid', 'uuid', 'nlp', 'pipelin', 'pipelin', 'datapack', 'nlp', 'set_read', 'stringread', 'nlp', 'nltksentencesegment', 'nlp', 'multipackbox', 'config', 'pack_nam', 'sourc', 'nlp', 'onlinemachinetranslationmpprocessor', 'config', 'from_lang', 'en', 'to_lang', 'de', 'endpoint', 'http', 'path', 'translat', 'subscription_key', 'api_key', 'subscription_region', 'westu', 'x', 'clienttraceid', 'str', 'uuid', 'uuid', 'nlp', 'initi', 'multipack', 'nlp', 'process_dataset', 'input_str', 'print', 'sourc', 'text', 'multipack', 'get_pack', 'sourc', 'text', 'print', 'ntarget', 'text', 'multipack', 'get_pack', 'target', 'text', 'save', 'load', 'pipelin', 'save', 'whole', 'pipelin', 'save', 'section', 'learn', 'export', 'import', 'fort', 'pipelinefort', 'also', 'allow', 'us', 'save', 'pipelin', 'disk', 'serial', 'whole', 'pipelin', 'gener', 'intermedi', 'represent', 'load', 'later', 'mayb', 'differ', 'machin', 'import', 'os', 'save_path', 'str', 'os', 'path', 'join', 'os', 'path', 'dirnam', 'os', 'path', 'abspath', 'pipelin', 'yml', 'nlp', 'save', 'save_path', 'open', 'save_path', 'r', 'f', 'print', 'f', 'read', 'pipelin', 'save', 'tri', 'load', 'pipelin', 'see', 'still', 'function', 'expect', 'new_nlp', 'pipelin', 'pipelin', 'new_nlp', 'init_from_config_path', 'save_path', 'new_nlp', 'initi', 'multipack', 'new_nlp', 'process_dataset', 'input_str', 'print', 'sourc', 'text', 'multipack', 'get_pack', 'sourc', 'text', 'print', 'ntarget', 'text', 'multipack', 'get_pack', 'target', 'text', 'build', 'machin', 'translat', 'system', 'fort']"
21,22,22,AbjectDrink3276,vy3bon,[D] When will Neurips 2022 reviews be released?,I cant recall what day the last couple of years reviews have been released. I know that the review period is closed and so its only a matter of time just wondering if anyone has any idea?,6,6,2022-07-13 19:01:37, d  when will neurips  reviews be released ,i cant recall what day the last couple of years reviews have been released  i know that the review period is closed and so its only a matter of time just wondering if anyone has any idea ,cant recall day last couple years reviews released know review period closed matter time wondering anyone idea,neurips reviews released,neurips reviews releasedcant recall day last couple years reviews released know review period closed matter time wondering anyone idea,"['neurips', 'reviews', 'releasedcant', 'recall', 'day', 'last', 'couple', 'years', 'reviews', 'released', 'know', 'review', 'period', 'closed', 'matter', 'time', 'wondering', 'anyone', 'idea']","['neurip', 'review', 'releasedc', 'recal', 'day', 'last', 'coupl', 'year', 'review', 'releas', 'know', 'review', 'period', 'close', 'matter', 'time', 'wonder', 'anyon', 'idea']"
22,24,24,Adolphins,vxqv3l,Why do Transformers scale so well? [D]," When you hear people talk about large models, they're usually talking about transformers. What about this architecture has allowed it to be scaled? Have people tried making really large CNNs or RNNs (or just regular MLPs) before?",15,30,2022-07-13 06:46:39,why do transformers scale so well   d , when you hear people talk about large models  they re usually talking about transformers  what about this architecture has allowed it to be scaled  have people tried making really large cnns or rnns  or just regular mlps  before ,hear people talk large models usually talking transformers architecture allowed scaled people tried making really large cnns rnns regular mlps,transformers scale well,transformers scale wellhear people talk large models usually talking transformers architecture allowed scaled people tried making really large cnns rnns regular mlps,"['transformers', 'scale', 'wellhear', 'people', 'talk', 'large', 'models', 'usually', 'talking', 'transformers', 'architecture', 'allowed', 'scaled', 'people', 'tried', 'making', 'really', 'large', 'cnns', 'rnns', 'regular', 'mlps']","['transform', 'scale', 'wellhear', 'peopl', 'talk', 'larg', 'model', 'usual', 'talk', 'transform', 'architectur', 'allow', 'scale', 'peopl', 'tri', 'make', 'realli', 'larg', 'cnn', 'rnn', 'regular', 'mlp']"
23,25,25,Singularian2501,vxn07k,[R] Deep Hierarchical Planning from Pixels ( Director ) - Google 2022,"Paper: [https://arxiv.org/pdf/2206.04114.pdf](https://arxiv.org/pdf/2206.04114.pdf)

[https://ai.googleblog.com/2022/07/deep-hierarchical-planning-from-pixels.html?m=1](https://ai.googleblog.com/2022/07/deep-hierarchical-planning-from-pixels.html?m=1)

Abstract: 

>Intelligent agents need to select long sequences of actions to solve complex tasks. While humans easily break down tasks into subgoals and reach them through millions of muscle commands, current artificial intelligence is limited to tasks with horizons of a few hundred decisions, despite large compute budgets. Research on hierarchical reinforcement learning aims to overcome this limitation but has proven to be challenging, current methods rely on manually specified goal spaces or subtasks, and no general solution exists. We introduce Director, a practical method for learning hierarchical behaviors directly from pixels by planning inside the latent space of a learned world model. The high-level policy maximizes task and exploration rewards by selecting latent goals and the low-level policy learns to achieve the goals. Despite operating in latent space, the decisions are interpretable because the world model can decode goals into images for visualization. Director outperforms exploration methods on tasks with sparse rewards, including 3D maze traversal with a quadruped robot from an egocentric camera and proprioception, without access to the global position or top-down view that was used by prior work. Director also learns successful behaviors across a wide range of environments, including visual control, Atari games, and DMLab levels. 

https://preview.redd.it/lbvp6r7wl7b91.jpg?width=1034&format=pjpg&auto=webp&s=e9a28b2589eb41148de5b5bb6c4700354e795ae4

https://preview.redd.it/kikyu54xl7b91.jpg?width=1041&format=pjpg&auto=webp&s=b893e54790c420780c79819e689a9666ea95bf86

https://preview.redd.it/m5wc4tdxl7b91.jpg?width=1007&format=pjpg&auto=webp&s=17d7edf3cf7021ceabd3327d9408f1c3bd913c03

https://preview.redd.it/9cwsn9oxl7b91.jpg?width=1015&format=pjpg&auto=webp&s=c96348f290e9ff76c7003c51c97ac86705b77068",1,30,2022-07-13 03:37:09, r  deep hierarchical planning from pixels   director     google ,paper   https  https abstract   intelligent agents need to select long sequences of actions to solve complex tasks  while humans easily break down tasks into subgoals and reach them through millions of muscle commands  current artificial intelligence is limited to tasks with horizons of a few hundred decisions  despite large compute budgets  research on hierarchical reinforcement learning aims to overcome this limitation but has proven to be challenging  current methods rely on manually specified goal spaces or subtasks  and no general solution exists  we introduce director  a practical method for learning hierarchical behaviors directly from pixels by planning inside the latent space of a learned world model  the high level policy maximizes task and exploration rewards by selecting latent goals and the low level policy learns to achieve the goals  despite operating in latent space  the decisions are interpretable because the world model can decode goals into images for visualization  director outperforms exploration methods on tasks with sparse rewards  including d maze traversal with a quadruped robot from an egocentric camera and proprioception  without access to the global position or top down view that was used by prior work  director also learns successful behaviors across a wide range of environments  including visual control  atari games  and dmlab levels  https https https https   preview redd it cwsnoxlb jpg width  format pjpg auto webp s cfeffcccacb,paper https https abstract intelligent agents need select long sequences actions solve complex tasks humans easily break tasks subgoals reach millions muscle commands current artificial intelligence limited tasks horizons hundred decisions despite large compute budgets research hierarchical reinforcement learning aims overcome limitation proven challenging current methods rely manually specified goal spaces subtasks general solution exists introduce director practical method learning hierarchical behaviors directly pixels planning inside latent space learned world model high level policy maximizes task exploration rewards selecting latent goals low level policy learns achieve goals despite operating latent space decisions interpretable world model decode goals images visualization director outperforms exploration methods tasks sparse rewards including maze traversal quadruped robot egocentric camera proprioception without access global position top view used prior work director also learns successful behaviors across wide range environments including visual control atari games dmlab levels https https https https preview redd cwsnoxlb jpg width format pjpg auto webp cfeffcccacb,r deep hierarchical planning pixels director google,r deep hierarchical planning pixels director googlepaper https https abstract intelligent agents need select long sequences actions solve complex tasks humans easily break tasks subgoals reach millions muscle commands current artificial intelligence limited tasks horizons hundred decisions despite large compute budgets research hierarchical reinforcement learning aims overcome limitation proven challenging current methods rely manually specified goal spaces subtasks general solution exists introduce director practical method learning hierarchical behaviors directly pixels planning inside latent space learned world model high level policy maximizes task exploration rewards selecting latent goals low level policy learns achieve goals despite operating latent space decisions interpretable world model decode goals images visualization director outperforms exploration methods tasks sparse rewards including maze traversal quadruped robot egocentric camera proprioception without access global position top view used prior work director also learns successful behaviors across wide range environments including visual control atari games dmlab levels https https https https preview redd cwsnoxlb jpg width format pjpg auto webp cfeffcccacb,"['r', 'deep', 'hierarchical', 'planning', 'pixels', 'director', 'googlepaper', 'https', 'https', 'abstract', 'intelligent', 'agents', 'need', 'select', 'long', 'sequences', 'actions', 'solve', 'complex', 'tasks', 'humans', 'easily', 'break', 'tasks', 'subgoals', 'reach', 'millions', 'muscle', 'commands', 'current', 'artificial', 'intelligence', 'limited', 'tasks', 'horizons', 'hundred', 'decisions', 'despite', 'large', 'compute', 'budgets', 'research', 'hierarchical', 'reinforcement', 'learning', 'aims', 'overcome', 'limitation', 'proven', 'challenging', 'current', 'methods', 'rely', 'manually', 'specified', 'goal', 'spaces', 'subtasks', 'general', 'solution', 'exists', 'introduce', 'director', 'practical', 'method', 'learning', 'hierarchical', 'behaviors', 'directly', 'pixels', 'planning', 'inside', 'latent', 'space', 'learned', 'world', 'model', 'high', 'level', 'policy', 'maximizes', 'task', 'exploration', 'rewards', 'selecting', 'latent', 'goals', 'low', 'level', 'policy', 'learns', 'achieve', 'goals', 'despite', 'operating', 'latent', 'space', 'decisions', 'interpretable', 'world', 'model', 'decode', 'goals', 'images', 'visualization', 'director', 'outperforms', 'exploration', 'methods', 'tasks', 'sparse', 'rewards', 'including', 'maze', 'traversal', 'quadruped', 'robot', 'egocentric', 'camera', 'proprioception', 'without', 'access', 'global', 'position', 'top', 'view', 'used', 'prior', 'work', 'director', 'also', 'learns', 'successful', 'behaviors', 'across', 'wide', 'range', 'environments', 'including', 'visual', 'control', 'atari', 'games', 'dmlab', 'levels', 'https', 'https', 'https', 'https', 'preview', 'redd', 'cwsnoxlb', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'cfeffcccacb']","['r', 'deep', 'hierarch', 'plan', 'pixel', 'director', 'googlepap', 'http', 'http', 'abstract', 'intellig', 'agent', 'need', 'select', 'long', 'sequenc', 'action', 'solv', 'complex', 'task', 'human', 'easili', 'break', 'task', 'subgoal', 'reach', 'million', 'muscl', 'command', 'current', 'artifici', 'intellig', 'limit', 'task', 'horizon', 'hundr', 'decis', 'despit', 'larg', 'comput', 'budget', 'research', 'hierarch', 'reinforc', 'learn', 'aim', 'overcom', 'limit', 'proven', 'challeng', 'current', 'method', 'reli', 'manual', 'specifi', 'goal', 'space', 'subtask', 'gener', 'solut', 'exist', 'introduc', 'director', 'practic', 'method', 'learn', 'hierarch', 'behavior', 'directli', 'pixel', 'plan', 'insid', 'latent', 'space', 'learn', 'world', 'model', 'high', 'level', 'polici', 'maxim', 'task', 'explor', 'reward', 'select', 'latent', 'goal', 'low', 'level', 'polici', 'learn', 'achiev', 'goal', 'despit', 'oper', 'latent', 'space', 'decis', 'interpret', 'world', 'model', 'decod', 'goal', 'imag', 'visual', 'director', 'outperform', 'explor', 'method', 'task', 'spars', 'reward', 'includ', 'maze', 'travers', 'quadrup', 'robot', 'egocentr', 'camera', 'propriocept', 'without', 'access', 'global', 'posit', 'top', 'view', 'use', 'prior', 'work', 'director', 'also', 'learn', 'success', 'behavior', 'across', 'wide', 'rang', 'environ', 'includ', 'visual', 'control', 'atari', 'game', 'dmlab', 'level', 'http', 'http', 'http', 'http', 'preview', 'redd', 'cwsnoxlb', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'cfeffcccacb']"
24,26,26,TemppaHemppa,vxvyrm,[D] Labeling novel view synthesis for object detection,"Hey all,

I've been following the exciting progress of NeRFs, and it lead to me wonder whether there are research on generating novel 2D views from 3D representation, and labeling those examples. I find works for image classification under Novel View Synthesis topics, but for object detection I just can't find anything.

Wouldn't it be possible to label 2D training images, construct 3D representation, and use it for generating novel 2D views with corresponding labelings? I see this as highly useful for the object detection domain, where labeling often requires a lot of manual work leading to small datasets and non-robust object representations.

Please note if I'm missing something out here.",0,5,2022-07-13 11:30:45, d  labeling novel view synthesis for object detection,hey all i ve been following the exciting progress of nerfs  and it lead to me wonder whether there are research on generating novel d views from d representation  and labeling those examples  i find works for image classification under novel view synthesis topics  but for object detection i just can t find anything wouldn t it be possible to label d training images  construct d representation  and use it for generating novel d views with corresponding labelings  i see this as highly useful for the object detection domain  where labeling often requires a lot of manual work leading to small datasets and non robust object representations please note if i m missing something out here ,hey following exciting progress nerfs lead wonder whether research generating novel views representation labeling examples find works image classification novel view synthesis topics object detection find anything possible label training images construct representation use generating novel views corresponding labelings see highly useful object detection domain labeling often requires lot manual work leading small datasets non robust object representations please note missing something,labeling novel view synthesis object detection,labeling novel view synthesis object detectionhey following exciting progress nerfs lead wonder whether research generating novel views representation labeling examples find works image classification novel view synthesis topics object detection find anything possible label training images construct representation use generating novel views corresponding labelings see highly useful object detection domain labeling often requires lot manual work leading small datasets non robust object representations please note missing something,"['labeling', 'novel', 'view', 'synthesis', 'object', 'detectionhey', 'following', 'exciting', 'progress', 'nerfs', 'lead', 'wonder', 'whether', 'research', 'generating', 'novel', 'views', 'representation', 'labeling', 'examples', 'find', 'works', 'image', 'classification', 'novel', 'view', 'synthesis', 'topics', 'object', 'detection', 'find', 'anything', 'possible', 'label', 'training', 'images', 'construct', 'representation', 'use', 'generating', 'novel', 'views', 'corresponding', 'labelings', 'see', 'highly', 'useful', 'object', 'detection', 'domain', 'labeling', 'often', 'requires', 'lot', 'manual', 'work', 'leading', 'small', 'datasets', 'non', 'robust', 'object', 'representations', 'please', 'note', 'missing', 'something']","['label', 'novel', 'view', 'synthesi', 'object', 'detectionhey', 'follow', 'excit', 'progress', 'nerf', 'lead', 'wonder', 'whether', 'research', 'gener', 'novel', 'view', 'represent', 'label', 'exampl', 'find', 'work', 'imag', 'classif', 'novel', 'view', 'synthesi', 'topic', 'object', 'detect', 'find', 'anyth', 'possibl', 'label', 'train', 'imag', 'construct', 'represent', 'use', 'gener', 'novel', 'view', 'correspond', 'label', 'see', 'highli', 'use', 'object', 'detect', 'domain', 'label', 'often', 'requir', 'lot', 'manual', 'work', 'lead', 'small', 'dataset', 'non', 'robust', 'object', 'represent', 'pleas', 'note', 'miss', 'someth']"
25,27,27,paulcjh,vx89nj,[P] DALL·E Mini & Mega demo and production API,"Hi all - we've just put out the community DALL·E models on Playgrounds.ai:

Mega - [https://playgrounds.ai/models/dalle-mega](https://playgrounds.ai/models/dalle-mega?utm_source=reddit&utm_medium=post&utm_campaign=dalle_1&utm_id=c.1)

Mini - [https://playgrounds.ai/models/dalle-mini](https://playgrounds.ai/models/dalle-mini?utm_source=reddit&utm_medium=post&utm_campaign=dalle_1&utm_id=c.1)

You can use this models via API on PipelineCloud here: [https://dashboard.pipeline.ai](https://dashboard.pipeline.ai) 

The per image cost for the models are approx:

Mega - $0.0014 (\~10s of compute for 4 images)

Mini - $0.00062 (\~10s of compute for 9 images)

This is for people who want to use these models in their apps/products or just play around with the demos and have fun!

https://preview.redd.it/zre4tf40a4b91.png?width=3114&format=png&auto=webp&s=68d8c10236cdd23c642e581d479d479b38fede84",32,163,2022-07-12 16:17:35, p  dall e mini   mega demo and production api,hi all   we ve just put out the community dall e models on playgrounds ai mega    https mini    https you can use this models via api on pipelinecloud here   https the per image cost for the models are approx mega         s of compute for  images mini         s of compute for  images this is for people who want to use these models in their apps products or just play around with the demos and have fun https   preview redd it zretfab png width  format png auto webp s dccddceddbfede,hi put community dall e models playgrounds ai mega https mini https use models via api pipelinecloud https per image cost models approx mega compute images mini compute images people want use models apps products play around demos fun https preview redd zretfab png width format png auto webp dccddceddbfede,p dall e mini mega demo production api,p dall e mini mega demo production apihi put community dall e models playgrounds ai mega https mini https use models via api pipelinecloud https per image cost models approx mega compute images mini compute images people want use models apps products play around demos fun https preview redd zretfab png width format png auto webp dccddceddbfede,"['p', 'dall', 'e', 'mini', 'mega', 'demo', 'production', 'apihi', 'put', 'community', 'dall', 'e', 'models', 'playgrounds', 'ai', 'mega', 'https', 'mini', 'https', 'use', 'models', 'via', 'api', 'pipelinecloud', 'https', 'per', 'image', 'cost', 'models', 'approx', 'mega', 'compute', 'images', 'mini', 'compute', 'images', 'people', 'want', 'use', 'models', 'apps', 'products', 'play', 'around', 'demos', 'fun', 'https', 'preview', 'redd', 'zretfab', 'png', 'width', 'format', 'png', 'auto', 'webp', 'dccddceddbfede']","['p', 'dall', 'e', 'mini', 'mega', 'demo', 'product', 'apihi', 'put', 'commun', 'dall', 'e', 'model', 'playground', 'ai', 'mega', 'http', 'mini', 'http', 'use', 'model', 'via', 'api', 'pipelinecloud', 'http', 'per', 'imag', 'cost', 'model', 'approx', 'mega', 'comput', 'imag', 'mini', 'comput', 'imag', 'peopl', 'want', 'use', 'model', 'app', 'product', 'play', 'around', 'demo', 'fun', 'http', 'preview', 'redd', 'zretfab', 'png', 'width', 'format', 'png', 'auto', 'webp', 'dccddceddbfed']"
26,28,28,Rafaelkoll,vy3p7q,[D] Ensemble regression model - based on models trained on different feature spaces,"What is the best method for constructing an ensemble regression model from numerous KNN regression models that were trained on slightly **different feature spaces**?

I can't only use the features that they have in common.",2,1,2022-07-13 19:19:26, d  ensemble regression model   based on models trained on different feature spaces,what is the best method for constructing an ensemble regression model from numerous knn regression models that were trained on slightly   different feature spaces   i can t only use the features that they have in common ,best method constructing ensemble regression model numerous knn regression models trained slightly different feature spaces use features common,ensemble regression model based models trained different feature spaces,ensemble regression model based models trained different feature spacesbest method constructing ensemble regression model numerous knn regression models trained slightly different feature spaces use features common,"['ensemble', 'regression', 'model', 'based', 'models', 'trained', 'different', 'feature', 'spacesbest', 'method', 'constructing', 'ensemble', 'regression', 'model', 'numerous', 'knn', 'regression', 'models', 'trained', 'slightly', 'different', 'feature', 'spaces', 'use', 'features', 'common']","['ensembl', 'regress', 'model', 'base', 'model', 'train', 'differ', 'featur', 'spacesbest', 'method', 'construct', 'ensembl', 'regress', 'model', 'numer', 'knn', 'regress', 'model', 'train', 'slightli', 'differ', 'featur', 'space', 'use', 'featur', 'common']"
27,29,29,EUMETSAT,vxzcsy,[News] Jupyter Notebook competition - 2 weeks left to enter!,"Are you passionate about [\#coding](https://www.facebook.com/hashtag/coding?__eep__=6&__cft__[0]=AZUaWWSvEyv-U2rnLNbvP3MseROHr1LlG-GsK0bDW9_hBJM-ZHHRlfwvzn2uevBI3sbZw8b7gtV_YAImoKU3IYIdXD_DOzn_L8sgspuXrmZx9p_92-MfaFbtnNcw_j1KtsdoMBkjxMUYPc-hia7qEmktYC4-yEbZREPj2cqkLfIdd10AoF2cSznIA_Qo7I7bmLiyPrnuUPY55hgWW6UO8oUCay-rpP9p0bEKaKsgWBU6XUmgpR2UzpKbjLzC2ZmzUZb3D_DlJlQsaLTWwRBGXOGy&__tn__=*NK-R), [\#DataScience](https://www.facebook.com/hashtag/datascience?__eep__=6&__cft__[0]=AZUaWWSvEyv-U2rnLNbvP3MseROHr1LlG-GsK0bDW9_hBJM-ZHHRlfwvzn2uevBI3sbZw8b7gtV_YAImoKU3IYIdXD_DOzn_L8sgspuXrmZx9p_92-MfaFbtnNcw_j1KtsdoMBkjxMUYPc-hia7qEmktYC4-yEbZREPj2cqkLfIdd10AoF2cSznIA_Qo7I7bmLiyPrnuUPY55hgWW6UO8oUCay-rpP9p0bEKaKsgWBU6XUmgpR2UzpKbjLzC2ZmzUZb3D_DlJlQsaLTWwRBGXOGy&__tn__=*NK-R) or [\#EarthObservation](https://www.facebook.com/hashtag/earthobservation?__eep__=6&__cft__[0]=AZUaWWSvEyv-U2rnLNbvP3MseROHr1LlG-GsK0bDW9_hBJM-ZHHRlfwvzn2uevBI3sbZw8b7gtV_YAImoKU3IYIdXD_DOzn_L8sgspuXrmZx9p_92-MfaFbtnNcw_j1KtsdoMBkjxMUYPc-hia7qEmktYC4-yEbZREPj2cqkLfIdd10AoF2cSznIA_Qo7I7bmLiyPrnuUPY55hgWW6UO8oUCay-rpP9p0bEKaKsgWBU6XUmgpR2UzpKbjLzC2ZmzUZb3D_DlJlQsaLTWwRBGXOGy&__tn__=*NK-R)? 📷 

Don't miss out on the chance to showcase your skills and develop new Jupyter Notebooks using [\#Copernicus](https://www.facebook.com/hashtag/copernicus?__eep__=6&__cft__[0]=AZUaWWSvEyv-U2rnLNbvP3MseROHr1LlG-GsK0bDW9_hBJM-ZHHRlfwvzn2uevBI3sbZw8b7gtV_YAImoKU3IYIdXD_DOzn_L8sgspuXrmZx9p_92-MfaFbtnNcw_j1KtsdoMBkjxMUYPc-hia7qEmktYC4-yEbZREPj2cqkLfIdd10AoF2cSznIA_Qo7I7bmLiyPrnuUPY55hgWW6UO8oUCay-rpP9p0bEKaKsgWBU6XUmgpR2UzpKbjLzC2ZmzUZb3D_DlJlQsaLTWwRBGXOGy&__tn__=*NK-R) data, whilst also being in with a chance of winning cash  📷 prizes! 

Sign up before 31 July at: [https://notebook.wekeo.eu/](https://notebook.wekeo.eu/)

https://preview.redd.it/1uwo4ccv4bb91.png?width=1920&format=png&auto=webp&s=18af6de36526d30585d0027d8445f56ed4302516",1,2,2022-07-13 15:20:09, news  jupyter notebook competition    weeks left to enter ,are you passionate about    coding  https don t miss out on the chance to showcase your skills and develop new jupyter notebooks using    copernicus  https sign up before  july at   https https   preview redd it uwoccvbb png width  format png auto webp s afdedddfed,passionate coding https miss chance showcase skills develop jupyter notebooks using copernicus https sign july https https preview redd uwoccvbb png width format png auto webp afdedddfed,news jupyter notebook competition weeks left enter,news jupyter notebook competition weeks left enterpassionate coding https miss chance showcase skills develop jupyter notebooks using copernicus https sign july https https preview redd uwoccvbb png width format png auto webp afdedddfed,"['news', 'jupyter', 'notebook', 'competition', 'weeks', 'left', 'enterpassionate', 'coding', 'https', 'miss', 'chance', 'showcase', 'skills', 'develop', 'jupyter', 'notebooks', 'using', 'copernicus', 'https', 'sign', 'july', 'https', 'https', 'preview', 'redd', 'uwoccvbb', 'png', 'width', 'format', 'png', 'auto', 'webp', 'afdedddfed']","['news', 'jupyt', 'notebook', 'competit', 'week', 'left', 'enterpassion', 'code', 'http', 'miss', 'chanc', 'showcas', 'skill', 'develop', 'jupyt', 'notebook', 'use', 'copernicu', 'http', 'sign', 'juli', 'http', 'http', 'preview', 'redd', 'uwoccvbb', 'png', 'width', 'format', 'png', 'auto', 'webp', 'afdedddf']"
28,30,30,takeafuckinsipp,vxl0ae,[P] Ensembling with multiple independent time-series,"I'm working on a project in which I have N independent time-series datasets, which can be thought of like prices for different currencies/crypto-coins etc. I've structured my dataset such that for each training batch, the first dimension is the index of the time-series. 

I have a prediction model based on a couple papers, which takes in a sliding window and outputs a prediction of the time series. 

**Question: What is the best way to build an ensemble of this model, such that predictions for each time-series aren't affected by the others?**

When I say ""aren't affected by other time series"", i mean that the average of predictions of two different models trained on two different series might not be as accurate/precise as the predictions by themselves (without averaging)...

Should I have N different models for each time series and just average the predictions? Should I have some K number of models with different loss functions and then average those? 

What would be a good strategy?",5,8,2022-07-13 02:08:28, p  ensembling with multiple independent time series,i m working on a project in which i have n independent time series datasets  which can be thought of like prices for different currencies crypto coins etc  i ve structured my dataset such that for each training batch  the first dimension is the index of the time series  i have a prediction model based on a couple papers  which takes in a sliding window and outputs a prediction of the time series    question  what is the best way to build an ensemble of this model  such that predictions for each time series aren t affected by the others   when i say aren t affected by other time series  i mean that the average of predictions of two different models trained on two different series might not be as accurate precise as the predictions by themselves  without averaging    should i have n different models for each time series and just average the predictions  should i have some k number of models with different loss functions and then average those  what would be a good strategy ,working project n independent time series datasets thought like prices different currencies crypto coins etc structured dataset training batch first dimension index time series prediction model based couple papers takes sliding window outputs prediction time series question best way build ensemble model predictions time series affected others say affected time series mean average predictions two different models trained two different series might accurate precise predictions without averaging n different models time series average predictions k number models different loss functions average would good strategy,p ensembling multiple independent time series,p ensembling multiple independent time seriesworking project n independent time series datasets thought like prices different currencies crypto coins etc structured dataset training batch first dimension index time series prediction model based couple papers takes sliding window outputs prediction time series question best way build ensemble model predictions time series affected others say affected time series mean average predictions two different models trained two different series might accurate precise predictions without averaging n different models time series average predictions k number models different loss functions average would good strategy,"['p', 'ensembling', 'multiple', 'independent', 'time', 'seriesworking', 'project', 'n', 'independent', 'time', 'series', 'datasets', 'thought', 'like', 'prices', 'different', 'currencies', 'crypto', 'coins', 'etc', 'structured', 'dataset', 'training', 'batch', 'first', 'dimension', 'index', 'time', 'series', 'prediction', 'model', 'based', 'couple', 'papers', 'takes', 'sliding', 'window', 'outputs', 'prediction', 'time', 'series', 'question', 'best', 'way', 'build', 'ensemble', 'model', 'predictions', 'time', 'series', 'affected', 'others', 'say', 'affected', 'time', 'series', 'mean', 'average', 'predictions', 'two', 'different', 'models', 'trained', 'two', 'different', 'series', 'might', 'accurate', 'precise', 'predictions', 'without', 'averaging', 'n', 'different', 'models', 'time', 'series', 'average', 'predictions', 'k', 'number', 'models', 'different', 'loss', 'functions', 'average', 'would', 'good', 'strategy']","['p', 'ensembl', 'multipl', 'independ', 'time', 'serieswork', 'project', 'n', 'independ', 'time', 'seri', 'dataset', 'thought', 'like', 'price', 'differ', 'currenc', 'crypto', 'coin', 'etc', 'structur', 'dataset', 'train', 'batch', 'first', 'dimens', 'index', 'time', 'seri', 'predict', 'model', 'base', 'coupl', 'paper', 'take', 'slide', 'window', 'output', 'predict', 'time', 'seri', 'question', 'best', 'way', 'build', 'ensembl', 'model', 'predict', 'time', 'seri', 'affect', 'other', 'say', 'affect', 'time', 'seri', 'mean', 'averag', 'predict', 'two', 'differ', 'model', 'train', 'two', 'differ', 'seri', 'might', 'accur', 'precis', 'predict', 'without', 'averag', 'n', 'differ', 'model', 'time', 'seri', 'averag', 'predict', 'k', 'number', 'model', 'differ', 'loss', 'function', 'averag', 'would', 'good', 'strategi']"
29,31,31,Spiritual_Fig3632,vxteu1,[D] tranfer learning with freezing vs unfreezing,"Hi, I have been trying to test self-supervised representation learning on vision-task. In more detail, testing [BYOL](https://arxiv.org/abs/2006.07733) in cifar-10. I found the trick that they threw away the last layer and put a new layer for the output shape, and the backbone network is frozen during finetuning. I know that the bad last layer can harm to the backbone network during finetuning because network is highly sensitive to even small change in parameter space. But I tried to finetune without freezing, It shows better last performance(accuracy 82% -> 90% at test). So why did they freeze the backbone network and show the results of the experiment?

How can I explain this phenomenon? Thank you for reading.",5,2,2022-07-13 08:59:41, d  tranfer learning with freezing vs unfreezing,hi  i have been trying to test self supervised representation learning on vision task  in more detail  testing  byol  https how can i explain this phenomenon  thank you for reading ,hi trying test self supervised representation learning vision task detail testing byol https explain phenomenon thank reading,tranfer learning freezing vs unfreezing,tranfer learning freezing vs unfreezinghi trying test self supervised representation learning vision task detail testing byol https explain phenomenon thank reading,"['tranfer', 'learning', 'freezing', 'vs', 'unfreezinghi', 'trying', 'test', 'self', 'supervised', 'representation', 'learning', 'vision', 'task', 'detail', 'testing', 'byol', 'https', 'explain', 'phenomenon', 'thank', 'reading']","['tranfer', 'learn', 'freez', 'vs', 'unfreezinghi', 'tri', 'test', 'self', 'supervis', 'represent', 'learn', 'vision', 'task', 'detail', 'test', 'byol', 'http', 'explain', 'phenomenon', 'thank', 'read']"
30,32,32,ajt9000,vx045i,[D] How do you verify the novelty of your research?," 

While working on my own research and struggling to find related works it got me thinking. What process do you follow to discover preexisting research similar to your own?

With the fast pace of research in the field, and so much overlapping terminology, do you use fancy tools or go beyond just typing queries into google scholar until you get relevant papers to your own? How do you find what you don't know to look for?",55,180,2022-07-12 08:00:07, d  how do you verify the novelty of your research , while working on my own research and struggling to find related works it got me thinking  what process do you follow to discover preexisting research similar to your own with the fast pace of research in the field  and so much overlapping terminology  do you use fancy tools or go beyond just typing queries into google scholar until you get relevant papers to your own  how do you find what you don t know to look for ,working research struggling find related works got thinking process follow discover preexisting research similar fast pace research field much overlapping terminology use fancy tools go beyond typing queries google scholar get relevant papers find know look,verify novelty research,verify novelty researchworking research struggling find related works got thinking process follow discover preexisting research similar fast pace research field much overlapping terminology use fancy tools go beyond typing queries google scholar get relevant papers find know look,"['verify', 'novelty', 'researchworking', 'research', 'struggling', 'find', 'related', 'works', 'got', 'thinking', 'process', 'follow', 'discover', 'preexisting', 'research', 'similar', 'fast', 'pace', 'research', 'field', 'much', 'overlapping', 'terminology', 'use', 'fancy', 'tools', 'go', 'beyond', 'typing', 'queries', 'google', 'scholar', 'get', 'relevant', 'papers', 'find', 'know', 'look']","['verifi', 'novelti', 'researchwork', 'research', 'struggl', 'find', 'relat', 'work', 'got', 'think', 'process', 'follow', 'discov', 'preexist', 'research', 'similar', 'fast', 'pace', 'research', 'field', 'much', 'overlap', 'terminolog', 'use', 'fanci', 'tool', 'go', 'beyond', 'type', 'queri', 'googl', 'scholar', 'get', 'relev', 'paper', 'find', 'know', 'look']"
31,33,33,ResearcherNo4728,vxw64g,"[D] How best to handle a column that can hold multiple, unbounded number of values?"," Say I have an email dataset. Two of its columns are ""sender"" and ""recipients"". Now, the ""sender"" column will only hold one value in each row. However, ""recipients"" can be anything in number from 1 to 100, or even more theoretically. In such a scenario, one hot encoding is not a tractable solution. And neither is creating a new row for each unique recipient. So, how best to handle this situation?",4,1,2022-07-13 11:44:15, d  how best to handle a column that can hold multiple  unbounded number of values , say i have an email dataset  two of its columns are sender and recipients  now  the sender column will only hold one value in each row  however  recipients can be anything in number from  to   or even more theoretically  in such a scenario  one hot encoding is not a tractable solution  and neither is creating a new row for each unique recipient  so  how best to handle this situation ,say email dataset two columns sender recipients sender column hold one value row however recipients anything number even theoretically scenario one hot encoding tractable solution neither creating row unique recipient best handle situation,best handle column hold multiple unbounded number values,best handle column hold multiple unbounded number valuessay email dataset two columns sender recipients sender column hold one value row however recipients anything number even theoretically scenario one hot encoding tractable solution neither creating row unique recipient best handle situation,"['best', 'handle', 'column', 'hold', 'multiple', 'unbounded', 'number', 'valuessay', 'email', 'dataset', 'two', 'columns', 'sender', 'recipients', 'sender', 'column', 'hold', 'one', 'value', 'row', 'however', 'recipients', 'anything', 'number', 'even', 'theoretically', 'scenario', 'one', 'hot', 'encoding', 'tractable', 'solution', 'neither', 'creating', 'row', 'unique', 'recipient', 'best', 'handle', 'situation']","['best', 'handl', 'column', 'hold', 'multipl', 'unbound', 'number', 'valuessay', 'email', 'dataset', 'two', 'column', 'sender', 'recipi', 'sender', 'column', 'hold', 'one', 'valu', 'row', 'howev', 'recipi', 'anyth', 'number', 'even', 'theoret', 'scenario', 'one', 'hot', 'encod', 'tractabl', 'solut', 'neither', 'creat', 'row', 'uniqu', 'recipi', 'best', 'handl', 'situat']"
32,34,34,Boring-Violinist8291,vxlek2,[D] Does vector prediction merit using a multivariate output model?,"I’m making a framework that predicts a displacement vector for a series of points on a map, using features from those points. There’s evidence of a dependency between the correlation coefficient of vector values (i.e. x and y-displacement) and some of the features. 

Would this merit using a multivariate output model (likely gradient boosting tree regression) or should I use two univariate output models? If not, what should I be looking into?",1,4,2022-07-13 02:25:29, d  does vector prediction merit using a multivariate output model ,i m making a framework that predicts a displacement vector for a series of points on a map  using features from those points  there s evidence of a dependency between the correlation coefficient of vector values  i e  x and y displacement  and some of the features  would this merit using a multivariate output model  likely gradient boosting tree regression  or should i use two univariate output models  if not  what should i be looking into ,making framework predicts displacement vector series points map using features points evidence dependency correlation coefficient vector values e x displacement features would merit using multivariate output model likely gradient boosting tree regression use two univariate output models looking,vector prediction merit using multivariate output model,vector prediction merit using multivariate output modelmaking framework predicts displacement vector series points map using features points evidence dependency correlation coefficient vector values e x displacement features would merit using multivariate output model likely gradient boosting tree regression use two univariate output models looking,"['vector', 'prediction', 'merit', 'using', 'multivariate', 'output', 'modelmaking', 'framework', 'predicts', 'displacement', 'vector', 'series', 'points', 'map', 'using', 'features', 'points', 'evidence', 'dependency', 'correlation', 'coefficient', 'vector', 'values', 'e', 'x', 'displacement', 'features', 'would', 'merit', 'using', 'multivariate', 'output', 'model', 'likely', 'gradient', 'boosting', 'tree', 'regression', 'use', 'two', 'univariate', 'output', 'models', 'looking']","['vector', 'predict', 'merit', 'use', 'multivari', 'output', 'modelmak', 'framework', 'predict', 'displac', 'vector', 'seri', 'point', 'map', 'use', 'featur', 'point', 'evid', 'depend', 'correl', 'coeffici', 'vector', 'valu', 'e', 'x', 'displac', 'featur', 'would', 'merit', 'use', 'multivari', 'output', 'model', 'like', 'gradient', 'boost', 'tree', 'regress', 'use', 'two', 'univari', 'output', 'model', 'look']"
33,35,35,IllustriousCicada603,vxfy50,[D] Does it make sense to generate text sequences with Transformer-based models and then have a classifier to choose between multiple options.,"Hello, I have a topic for discussion: Are you aware of systems which have a sequence-to-sequence architecture such as a Transformer, generating multiple outputs for a given task, and then another model - a MLP, another Transformer or something else which learns to pick the best option. Is it possible for this extra step to extract more knowledge from given data and increase the performance of the pipeline (even though at the cost of more computing power)? In what contexts does (not) that make sense?",10,8,2022-07-12 22:25:46, d  does it make sense to generate text sequences with transformer based models and then have a classifier to choose between multiple options ,hello  i have a topic for discussion  are you aware of systems which have a sequence to sequence architecture such as a transformer  generating multiple outputs for a given task  and then another model   a mlp  another transformer or something else which learns to pick the best option  is it possible for this extra step to extract more knowledge from given data and increase the performance of the pipeline  even though at the cost of more computing power   in what contexts does  not  that make sense ,hello topic discussion aware systems sequence sequence architecture transformer generating multiple outputs given task another model mlp another transformer something else learns pick best option possible extra step extract knowledge given data increase performance pipeline even though cost computing power contexts make sense,make sense generate text sequences transformer based models classifier choose multiple options,make sense generate text sequences transformer based models classifier choose multiple optionshello topic discussion aware systems sequence sequence architecture transformer generating multiple outputs given task another model mlp another transformer something else learns pick best option possible extra step extract knowledge given data increase performance pipeline even though cost computing power contexts make sense,"['make', 'sense', 'generate', 'text', 'sequences', 'transformer', 'based', 'models', 'classifier', 'choose', 'multiple', 'optionshello', 'topic', 'discussion', 'aware', 'systems', 'sequence', 'sequence', 'architecture', 'transformer', 'generating', 'multiple', 'outputs', 'given', 'task', 'another', 'model', 'mlp', 'another', 'transformer', 'something', 'else', 'learns', 'pick', 'best', 'option', 'possible', 'extra', 'step', 'extract', 'knowledge', 'given', 'data', 'increase', 'performance', 'pipeline', 'even', 'though', 'cost', 'computing', 'power', 'contexts', 'make', 'sense']","['make', 'sens', 'gener', 'text', 'sequenc', 'transform', 'base', 'model', 'classifi', 'choos', 'multipl', 'optionshello', 'topic', 'discuss', 'awar', 'system', 'sequenc', 'sequenc', 'architectur', 'transform', 'gener', 'multipl', 'output', 'given', 'task', 'anoth', 'model', 'mlp', 'anoth', 'transform', 'someth', 'els', 'learn', 'pick', 'best', 'option', 'possibl', 'extra', 'step', 'extract', 'knowledg', 'given', 'data', 'increas', 'perform', 'pipelin', 'even', 'though', 'cost', 'comput', 'power', 'context', 'make', 'sens']"
34,36,36,mingrui-zhang,vx4tdz,[P] Building efficient ML applications with Taichi's automatic differentiation,"&#x200B;

https://i.redd.it/d66p6f6p23b91.gif

Hey guys 

I am working on an open-source, parallel programming language, Taichi Lang, which I find efficient in differentiable physical simulation and can help speed up the convergence of ML processes.  

Above is a simple demo supported by Taichi's inbuilt autodiff (automatic differentiation) system. You can move the target as you wish, and the magic fountain always changes its trajectory accordingly to hit the target.

So basically, Taichi Lang's Source Code Transformation system generates gradient kernels during compile time, and the lightweight `tape` in the Python scope records the launched Taichi kernels and replays the gradient kernels in reverse order during backpropagation. Model training is done within 10  optimization iterations.

A step-by-step explanation: [https://www.reddit.com/user/mingrui-zhang/comments/vx49mz/training\_a\_magic\_fountain\_using\_taichis\_autodiff/](https://www.reddit.com/user/mingrui-zhang/comments/vx49mz/training_a_magic_fountain_using_taichis_autodiff/)

Source code: [https://github.com/taichi-dev/taichi/blob/master/python/taichi/examples/autodiff/diff\_sph/diff\_sph.py](https://github.com/taichi-dev/taichi/blob/master/python/taichi/examples/autodiff/diff_sph/diff_sph.py)",11,37,2022-07-12 12:24:54, p  building efficient ml applications with taichi s automatic differentiation,  xb https hey guys i am working on an open source  parallel programming language  taichi lang  which i find efficient in differentiable physical simulation and can help speed up the convergence of ml processes   above is a simple demo supported by taichi s inbuilt autodiff  automatic differentiation  system  you can move the target as you wish  and the magic fountain always changes its trajectory accordingly to hit the target so basically  taichi lang s source code transformation system generates gradient kernels during compile time  and the lightweight  tape  in the python scope records the launched taichi kernels and replays the gradient kernels in reverse order during backpropagation  model training is done within   optimization iterations a step by step explanation   https source code   https   github com taichi dev taichi blob master python taichi examples autodiff diff _sph diff _sph py  https   github com taichi dev taichi blob master python taichi examples autodiff diff_sph diff_sph py ,xb https hey guys working open source parallel programming language taichi lang find efficient differentiable physical simulation help speed convergence ml processes simple demo supported taichi inbuilt autodiff automatic differentiation system move target wish magic fountain always changes trajectory accordingly hit target basically taichi lang source code transformation system generates gradient kernels compile time lightweight tape python scope records launched taichi kernels replays gradient kernels reverse order backpropagation model training done within optimization iterations step step explanation https source code https github com taichi dev taichi blob master python taichi examples autodiff diff _sph diff _sph py https github com taichi dev taichi blob master python taichi examples autodiff diff_sph diff_sph py,p building efficient ml applications taichi automatic differentiation,p building efficient ml applications taichi automatic differentiationxb https hey guys working open source parallel programming language taichi lang find efficient differentiable physical simulation help speed convergence ml processes simple demo supported taichi inbuilt autodiff automatic differentiation system move target wish magic fountain always changes trajectory accordingly hit target basically taichi lang source code transformation system generates gradient kernels compile time lightweight tape python scope records launched taichi kernels replays gradient kernels reverse order backpropagation model training done within optimization iterations step step explanation https source code https github com taichi dev taichi blob master python taichi examples autodiff diff _sph diff _sph py https github com taichi dev taichi blob master python taichi examples autodiff diff_sph diff_sph py,"['p', 'building', 'efficient', 'ml', 'applications', 'taichi', 'automatic', 'differentiationxb', 'https', 'hey', 'guys', 'working', 'open', 'source', 'parallel', 'programming', 'language', 'taichi', 'lang', 'find', 'efficient', 'differentiable', 'physical', 'simulation', 'help', 'speed', 'convergence', 'ml', 'processes', 'simple', 'demo', 'supported', 'taichi', 'inbuilt', 'autodiff', 'automatic', 'differentiation', 'system', 'move', 'target', 'wish', 'magic', 'fountain', 'always', 'changes', 'trajectory', 'accordingly', 'hit', 'target', 'basically', 'taichi', 'lang', 'source', 'code', 'transformation', 'system', 'generates', 'gradient', 'kernels', 'compile', 'time', 'lightweight', 'tape', 'python', 'scope', 'records', 'launched', 'taichi', 'kernels', 'replays', 'gradient', 'kernels', 'reverse', 'order', 'backpropagation', 'model', 'training', 'done', 'within', 'optimization', 'iterations', 'step', 'step', 'explanation', 'https', 'source', 'code', 'https', 'github', 'com', 'taichi', 'dev', 'taichi', 'blob', 'master', 'python', 'taichi', 'examples', 'autodiff', 'diff', '_sph', 'diff', '_sph', 'py', 'https', 'github', 'com', 'taichi', 'dev', 'taichi', 'blob', 'master', 'python', 'taichi', 'examples', 'autodiff', 'diff_sph', 'diff_sph', 'py']","['p', 'build', 'effici', 'ml', 'applic', 'taichi', 'automat', 'differentiationxb', 'http', 'hey', 'guy', 'work', 'open', 'sourc', 'parallel', 'program', 'languag', 'taichi', 'lang', 'find', 'effici', 'differenti', 'physic', 'simul', 'help', 'speed', 'converg', 'ml', 'process', 'simpl', 'demo', 'support', 'taichi', 'inbuilt', 'autodiff', 'automat', 'differenti', 'system', 'move', 'target', 'wish', 'magic', 'fountain', 'alway', 'chang', 'trajectori', 'accordingli', 'hit', 'target', 'basic', 'taichi', 'lang', 'sourc', 'code', 'transform', 'system', 'gener', 'gradient', 'kernel', 'compil', 'time', 'lightweight', 'tape', 'python', 'scope', 'record', 'launch', 'taichi', 'kernel', 'replay', 'gradient', 'kernel', 'revers', 'order', 'backpropag', 'model', 'train', 'done', 'within', 'optim', 'iter', 'step', 'step', 'explan', 'http', 'sourc', 'code', 'http', 'github', 'com', 'taichi', 'dev', 'taichi', 'blob', 'master', 'python', 'taichi', 'exampl', 'autodiff', 'diff', '_sph', 'diff', '_sph', 'py', 'http', 'github', 'com', 'taichi', 'dev', 'taichi', 'blob', 'master', 'python', 'taichi', 'exampl', 'autodiff', 'diff_sph', 'diff_sph', 'py']"
35,37,37,giuse_tweets,vxihha,[R] DiBB: Distributing Black-Box Optimization,"Author here. Just presented this work at GECCO 2022.

- Quick summary: https://twitter.com/giuse_tweets/status/1546920346015637505
- Paper: https://exascale.info/assets/pdf/cuccu2022gecco.pdf
- Code + tutorials: https://github.com/giuse/dibb
- Experiments (COCO/BBOB-LS): https://github.com/eXascaleInfolab/dibb_coco
- Recorded rehearsal of the talk: https://tinyurl.com/dibb-video

AMA!",0,5,2022-07-13 00:17:24, r  dibb  distributing black box optimization,author here  just presented this work at gecco    quick summary  https   paper  https   code   tutorials  https   experiments  coco bbob ls   https   recorded rehearsal of the talk  https ama ,author presented work gecco quick summary https paper https code tutorials https experiments coco bbob ls https recorded rehearsal talk https ama,r dibb distributing black box optimization,r dibb distributing black box optimizationauthor presented work gecco quick summary https paper https code tutorials https experiments coco bbob ls https recorded rehearsal talk https ama,"['r', 'dibb', 'distributing', 'black', 'box', 'optimizationauthor', 'presented', 'work', 'gecco', 'quick', 'summary', 'https', 'paper', 'https', 'code', 'tutorials', 'https', 'experiments', 'coco', 'bbob', 'ls', 'https', 'recorded', 'rehearsal', 'talk', 'https', 'ama']","['r', 'dibb', 'distribut', 'black', 'box', 'optimizationauthor', 'present', 'work', 'gecco', 'quick', 'summari', 'http', 'paper', 'http', 'code', 'tutori', 'http', 'experi', 'coco', 'bbob', 'ls', 'http', 'record', 'rehears', 'talk', 'http', 'ama']"
36,38,38,davidmezzetti,vxbdf4,[P] Run transformers model inference in C/C++ and Assembly with the Python C API,"&#x200B;

https://preview.redd.it/xjtcha3r35b91.png?width=1298&format=png&auto=webp&s=00873223c1ea0c6afcd5e22c7645521036b7e341

This post presents a way to run transformers models via the Python C API. The referenced notebook loads two txtai workflows, one that translates English to French and another that summarizes a webpage. After loading the models through C code, another example runs the workflows through assembly to show this works with any native code.

Full code links: [Notebook](https://colab.research.google.com/github/neuml/txtai/blob/master/examples/36_Run_txtai_in_native_code.ipynb) | [GitHub](https://github.com/neuml/txtai)",2,6,2022-07-12 19:03:59, p  run transformers model inference in c c   and assembly with the python c api,  xb https this post presents a way to run transformers models via the python c api  the referenced notebook loads two txtai workflows  one that translates english to french and another that summarizes a webpage  after loading the models through c code  another example runs the workflows through assembly to show this works with any native code full code links   notebook  https   colab research google com github neuml txtai blob master examples _run_txtai_in_native_code ipynb     github  https   github com neuml txtai ,xb https post presents way run transformers models via python c api referenced notebook loads two txtai workflows one translates english french another summarizes webpage loading models c code another example runs workflows assembly show works native code full code links notebook https colab research google com github neuml txtai blob master examples _run_txtai_in_native_code ipynb github https github com neuml txtai,p run transformers model inference c c assembly python c api,p run transformers model inference c c assembly python c apixb https post presents way run transformers models via python c api referenced notebook loads two txtai workflows one translates english french another summarizes webpage loading models c code another example runs workflows assembly show works native code full code links notebook https colab research google com github neuml txtai blob master examples _run_txtai_in_native_code ipynb github https github com neuml txtai,"['p', 'run', 'transformers', 'model', 'inference', 'c', 'c', 'assembly', 'python', 'c', 'apixb', 'https', 'post', 'presents', 'way', 'run', 'transformers', 'models', 'via', 'python', 'c', 'api', 'referenced', 'notebook', 'loads', 'two', 'txtai', 'workflows', 'one', 'translates', 'english', 'french', 'another', 'summarizes', 'webpage', 'loading', 'models', 'c', 'code', 'another', 'example', 'runs', 'workflows', 'assembly', 'show', 'works', 'native', 'code', 'full', 'code', 'links', 'notebook', 'https', 'colab', 'research', 'google', 'com', 'github', 'neuml', 'txtai', 'blob', 'master', 'examples', '_run_txtai_in_native_code', 'ipynb', 'github', 'https', 'github', 'com', 'neuml', 'txtai']","['p', 'run', 'transform', 'model', 'infer', 'c', 'c', 'assembl', 'python', 'c', 'apixb', 'http', 'post', 'present', 'way', 'run', 'transform', 'model', 'via', 'python', 'c', 'api', 'referenc', 'notebook', 'load', 'two', 'txtai', 'workflow', 'one', 'translat', 'english', 'french', 'anoth', 'summar', 'webpag', 'load', 'model', 'c', 'code', 'anoth', 'exampl', 'run', 'workflow', 'assembl', 'show', 'work', 'nativ', 'code', 'full', 'code', 'link', 'notebook', 'http', 'colab', 'research', 'googl', 'com', 'github', 'neuml', 'txtai', 'blob', 'master', 'exampl', '_run_txtai_in_native_cod', 'ipynb', 'github', 'http', 'github', 'com', 'neuml', 'txtai']"
37,39,39,subtask_net,vx5ryw,[P] Helping data scientists access large ML datasets,"I spent so much time building data pipelines which feels like a huge constraint on my time and ability to focus on actual ML tasks. That's why I'm building [subtask.net](https://subtask.net) which collects and builds large, constantly updated, ML datasets from across the internet. The goal is to cut out the data collection part of any ML project and make more datasets available beyond the typical open-source datasets provided by the community.",4,13,2022-07-12 13:29:58, p  helping data scientists access large ml datasets,i spent so much time building data pipelines which feels like a huge constraint on my time and ability to focus on actual ml tasks  that s why i m building  subtask net  https   subtask net  which collects and builds large  constantly updated  ml datasets from across the internet  the goal is to cut out the data collection part of any ml project and make more datasets available beyond the typical open source datasets provided by the community ,spent much time building data pipelines feels like huge constraint time ability focus actual ml tasks building subtask net https subtask net collects builds large constantly updated ml datasets across internet goal cut data collection part ml project make datasets available beyond typical open source datasets provided community,p helping data scientists access large ml datasets,p helping data scientists access large ml datasetsspent much time building data pipelines feels like huge constraint time ability focus actual ml tasks building subtask net https subtask net collects builds large constantly updated ml datasets across internet goal cut data collection part ml project make datasets available beyond typical open source datasets provided community,"['p', 'helping', 'data', 'scientists', 'access', 'large', 'ml', 'datasetsspent', 'much', 'time', 'building', 'data', 'pipelines', 'feels', 'like', 'huge', 'constraint', 'time', 'ability', 'focus', 'actual', 'ml', 'tasks', 'building', 'subtask', 'net', 'https', 'subtask', 'net', 'collects', 'builds', 'large', 'constantly', 'updated', 'ml', 'datasets', 'across', 'internet', 'goal', 'cut', 'data', 'collection', 'part', 'ml', 'project', 'make', 'datasets', 'available', 'beyond', 'typical', 'open', 'source', 'datasets', 'provided', 'community']","['p', 'help', 'data', 'scientist', 'access', 'larg', 'ml', 'datasetssp', 'much', 'time', 'build', 'data', 'pipelin', 'feel', 'like', 'huge', 'constraint', 'time', 'abil', 'focu', 'actual', 'ml', 'task', 'build', 'subtask', 'net', 'http', 'subtask', 'net', 'collect', 'build', 'larg', 'constantli', 'updat', 'ml', 'dataset', 'across', 'internet', 'goal', 'cut', 'data', 'collect', 'part', 'ml', 'project', 'make', 'dataset', 'avail', 'beyond', 'typic', 'open', 'sourc', 'dataset', 'provid', 'commun']"
38,40,40,Ok-Wind-1215,vx01wq,[D] Efficiently choose good papers in top-tier conferences,"Hey, As a senior Phd student, I still feel a bit tired of looking for and reading through the massive newly accepted papers in top-tier conferences/journals like neurips/icml/iclr/jmlr/cvpr.... 

Any suggestions for efficiently selecting good papers ?",11,31,2022-07-12 07:57:02, d  efficiently choose good papers in top tier conferences,hey  as a senior phd student  i still feel a bit tired of looking for and reading through the massive newly accepted papers in top tier conferences journals like neurips icml iclr jmlr cvpr     any suggestions for efficiently selecting good papers  ,hey senior phd student still feel bit tired looking reading massive newly accepted papers top tier conferences journals like neurips icml iclr jmlr cvpr suggestions efficiently selecting good papers,efficiently choose good papers top tier conferences,efficiently choose good papers top tier conferenceshey senior phd student still feel bit tired looking reading massive newly accepted papers top tier conferences journals like neurips icml iclr jmlr cvpr suggestions efficiently selecting good papers,"['efficiently', 'choose', 'good', 'papers', 'top', 'tier', 'conferenceshey', 'senior', 'phd', 'student', 'still', 'feel', 'bit', 'tired', 'looking', 'reading', 'massive', 'newly', 'accepted', 'papers', 'top', 'tier', 'conferences', 'journals', 'like', 'neurips', 'icml', 'iclr', 'jmlr', 'cvpr', 'suggestions', 'efficiently', 'selecting', 'good', 'papers']","['effici', 'choos', 'good', 'paper', 'top', 'tier', 'conferenceshey', 'senior', 'phd', 'student', 'still', 'feel', 'bit', 'tire', 'look', 'read', 'massiv', 'newli', 'accept', 'paper', 'top', 'tier', 'confer', 'journal', 'like', 'neurip', 'icml', 'iclr', 'jmlr', 'cvpr', 'suggest', 'effici', 'select', 'good', 'paper']"
39,41,41,imunabletocode,vx6dz5,[D] How to choose best model during training if validation loss fluctuates a lot?," I am training a deep neural network, unfortunately, I have few samples for my validation set, so the relative loss fluctuate a lot. How can I choose the best model during training? Usually I choose the model which is associated with the lowest validation loss, but now there are random fluctuation that lower loss function. I think the fluctuations are due to the fact that I can't use the whole sample because I am using Colab free and i haven't enough RAM. I tried to modify the splig Train/Train/Vali increasing Vali size and the oscillations seems a bit lower, but i would like to mantain the ratio 60/20/20 for a better and more significative classification.",12,9,2022-07-12 14:12:06, d  how to choose best model during training if validation loss fluctuates a lot , i am training a deep neural network  unfortunately  i have few samples for my validation set  so the relative loss fluctuate a lot  how can i choose the best model during training  usually i choose the model which is associated with the lowest validation loss  but now there are random fluctuation that lower loss function  i think the fluctuations are due to the fact that i can t use the whole sample because i am using colab free and i haven t enough ram  i tried to modify the splig train train vali increasing vali size and the oscillations seems a bit lower  but i would like to mantain the ratio    for a better and more significative classification ,training deep neural network unfortunately samples validation set relative loss fluctuate lot choose best model training usually choose model associated lowest validation loss random fluctuation lower loss function think fluctuations due fact use whole sample using colab free enough ram tried modify splig train train vali increasing vali size oscillations seems bit lower would like mantain ratio better significative classification,choose best model training validation loss fluctuates lot,choose best model training validation loss fluctuates lottraining deep neural network unfortunately samples validation set relative loss fluctuate lot choose best model training usually choose model associated lowest validation loss random fluctuation lower loss function think fluctuations due fact use whole sample using colab free enough ram tried modify splig train train vali increasing vali size oscillations seems bit lower would like mantain ratio better significative classification,"['choose', 'best', 'model', 'training', 'validation', 'loss', 'fluctuates', 'lottraining', 'deep', 'neural', 'network', 'unfortunately', 'samples', 'validation', 'set', 'relative', 'loss', 'fluctuate', 'lot', 'choose', 'best', 'model', 'training', 'usually', 'choose', 'model', 'associated', 'lowest', 'validation', 'loss', 'random', 'fluctuation', 'lower', 'loss', 'function', 'think', 'fluctuations', 'due', 'fact', 'use', 'whole', 'sample', 'using', 'colab', 'free', 'enough', 'ram', 'tried', 'modify', 'splig', 'train', 'train', 'vali', 'increasing', 'vali', 'size', 'oscillations', 'seems', 'bit', 'lower', 'would', 'like', 'mantain', 'ratio', 'better', 'significative', 'classification']","['choos', 'best', 'model', 'train', 'valid', 'loss', 'fluctuat', 'lottrain', 'deep', 'neural', 'network', 'unfortun', 'sampl', 'valid', 'set', 'rel', 'loss', 'fluctuat', 'lot', 'choos', 'best', 'model', 'train', 'usual', 'choos', 'model', 'associ', 'lowest', 'valid', 'loss', 'random', 'fluctuat', 'lower', 'loss', 'function', 'think', 'fluctuat', 'due', 'fact', 'use', 'whole', 'sampl', 'use', 'colab', 'free', 'enough', 'ram', 'tri', 'modifi', 'splig', 'train', 'train', 'vali', 'increas', 'vali', 'size', 'oscil', 'seem', 'bit', 'lower', 'would', 'like', 'mantain', 'ratio', 'better', 'signif', 'classif']"
40,42,42,EnricoShippole,vxf5w3,[P] Token-to-Token ViT Implementation in Flax,"&#x200B;

https://preview.redd.it/0mh5d00tx5b91.png?width=479&format=png&auto=webp&s=ac8c83e80d058d032e9083512da749216d9a2221

An open-source implementation of the Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet research paper in Google's JAX and Flax.

""Transformers, which are popular for language modeling, have been explored for solving vision tasks recently, e.g., the Vision Transformer (ViT) for image classification. The ViT model splits each image into a sequence of tokens with fixed length and then applies multiple Transformer layers to model their global relation for classification. However, ViT achieves inferior performance to CNNs when trained from scratch on a midsize dataset like ImageNet. We find it is because: 1) the simple tokenization of input images fails to model the important local structure such as edges and lines among neighboring pixels, leading to low training sample efficiency; 2) the redundant attention backbone design of ViT leads to limited feature richness for fixed computation budgets and limited training samples. To overcome such limitations, we propose a new Tokens-To-Token Vision Transformer (T2T-ViT), which incorporates 1) a layer-wise Tokens-to-Token (T2T) transformation to progressively structurize the image to tokens by recursively aggregating neighboring Tokens into one Token (Tokens-to-Token), such that local structure represented by surrounding tokens can be modeled and tokens length can be reduced; 2) an efficient backbone with a deep-narrow structure for vision transformer motivated by CNN architecture design after empirical study. Notably, T2T-ViT reduces the parameter count and MACs of vanilla ViT by half, while achieving more than 3.0% improvement when trained from scratch on ImageNet. It also outperforms ResNets and achieves comparable performance with MobileNets by directly training on ImageNet. For example, T2T-ViT with comparable size to ResNet50 (21.5M parameters) can achieve 83.3% top1 accuracy in image resolution 384×384 on ImageNet."" - Li Yuan, Yunpeng Chen, Tao Wang, Weihao Yu, Yujun Shi, Zihang Jiang, Francis EH Tay, Jiashi Feng, Shuicheng Yan

Github Repository for JAX /Flax model: [https://github.com/conceptofmind/Token-to-Token-ViT-flax](https://github.com/conceptofmind/Token-to-Token-ViT-flax)

Tokens-to-Token ViT Research Paper: [https://arxiv.org/abs/2203.10790](https://arxiv.org/abs/2203.10790)

Official Github Repository: [https://github.com/yitu-opensource/T2T-ViT](https://github.com/yitu-opensource/T2T-ViT)

In collaboration with Dr. Phil 'Lucid' Wang: [https://github.com/lucidrains](https://github.com/lucidrains).",0,0,2022-07-12 21:52:09, p  token to token vit implementation in flax,  xb https an open source implementation of the tokens to token vit  training vision transformers from scratch on imagenet research paper in google s jax and flax transformers  which are popular for language modeling  have been explored for solving vision tasks recently  e g   the vision transformer  vit  for image classification  the vit model splits each image into a sequence of tokens with fixed length and then applies multiple transformer layers to model their global relation for classification  however  vit achieves inferior performance to cnns when trained from scratch on a midsize dataset like imagenet  we find it is because    the simple tokenization of input images fails to model the important local structure such as edges and lines among neighboring pixels  leading to low training sample efficiency    the redundant attention backbone design of vit leads to limited feature richness for fixed computation budgets and limited training samples  to overcome such limitations  we propose a new tokens to token vision transformer  tt vit   which incorporates   a layer wise tokens to token  tt  transformation to progressively structurize the image to tokens by recursively aggregating neighboring tokens into one token  tokens to token   such that local structure represented by surrounding tokens can be modeled and tokens length can be reduced    an efficient backbone with a deep narrow structure for vision transformer motivated by cnn architecture design after empirical study  notably  tt vit reduces the parameter count and macs of vanilla vit by half  while achieving more than    improvement when trained from scratch on imagenet  it also outperforms resnets and achieves comparable performance with mobilenets by directly training on imagenet  for example  tt vit with comparable size to resnet   m parameters  can achieve    top accuracy in image resolution   on imagenet    li yuan  yunpeng chen  tao wang  weihao yu  yujun shi  zihang jiang  francis eh tay  jiashi feng  shuicheng yangithub repository for jax  flax model   https tokens to token vit research paper   https official github repository   https in collaboration with dr  phil  lucid  wang   https   github com lucidrains  https   github com lucidrains  ,xb https open source implementation tokens token vit training vision transformers scratch imagenet research paper google jax flax transformers popular language modeling explored solving vision tasks recently e g vision transformer vit image classification vit model splits image sequence tokens fixed length applies multiple transformer layers model global relation classification however vit achieves inferior performance cnns trained scratch midsize dataset like imagenet find simple tokenization input images fails model important local structure edges lines among neighboring pixels leading low training sample efficiency redundant attention backbone design vit leads limited feature richness fixed computation budgets limited training samples overcome limitations propose tokens token vision transformer tt vit incorporates layer wise tokens token tt transformation progressively structurize image tokens recursively aggregating neighboring tokens one token tokens token local structure represented surrounding tokens modeled tokens length reduced efficient backbone deep narrow structure vision transformer motivated cnn architecture design empirical study notably tt vit reduces parameter count macs vanilla vit half achieving improvement trained scratch imagenet also outperforms resnets achieves comparable performance mobilenets directly training imagenet example tt vit comparable size resnet parameters achieve top accuracy image resolution imagenet li yuan yunpeng chen tao wang weihao yu yujun shi zihang jiang francis eh tay jiashi feng shuicheng yangithub repository jax flax model https tokens token vit research paper https official github repository https collaboration dr phil lucid wang https github com lucidrains https github com lucidrains,p token token vit implementation flax,p token token vit implementation flaxxb https open source implementation tokens token vit training vision transformers scratch imagenet research paper google jax flax transformers popular language modeling explored solving vision tasks recently e g vision transformer vit image classification vit model splits image sequence tokens fixed length applies multiple transformer layers model global relation classification however vit achieves inferior performance cnns trained scratch midsize dataset like imagenet find simple tokenization input images fails model important local structure edges lines among neighboring pixels leading low training sample efficiency redundant attention backbone design vit leads limited feature richness fixed computation budgets limited training samples overcome limitations propose tokens token vision transformer tt vit incorporates layer wise tokens token tt transformation progressively structurize image tokens recursively aggregating neighboring tokens one token tokens token local structure represented surrounding tokens modeled tokens length reduced efficient backbone deep narrow structure vision transformer motivated cnn architecture design empirical study notably tt vit reduces parameter count macs vanilla vit half achieving improvement trained scratch imagenet also outperforms resnets achieves comparable performance mobilenets directly training imagenet example tt vit comparable size resnet parameters achieve top accuracy image resolution imagenet li yuan yunpeng chen tao wang weihao yu yujun shi zihang jiang francis eh tay jiashi feng shuicheng yangithub repository jax flax model https tokens token vit research paper https official github repository https collaboration dr phil lucid wang https github com lucidrains https github com lucidrains,"['p', 'token', 'token', 'vit', 'implementation', 'flaxxb', 'https', 'open', 'source', 'implementation', 'tokens', 'token', 'vit', 'training', 'vision', 'transformers', 'scratch', 'imagenet', 'research', 'paper', 'google', 'jax', 'flax', 'transformers', 'popular', 'language', 'modeling', 'explored', 'solving', 'vision', 'tasks', 'recently', 'e', 'g', 'vision', 'transformer', 'vit', 'image', 'classification', 'vit', 'model', 'splits', 'image', 'sequence', 'tokens', 'fixed', 'length', 'applies', 'multiple', 'transformer', 'layers', 'model', 'global', 'relation', 'classification', 'however', 'vit', 'achieves', 'inferior', 'performance', 'cnns', 'trained', 'scratch', 'midsize', 'dataset', 'like', 'imagenet', 'find', 'simple', 'tokenization', 'input', 'images', 'fails', 'model', 'important', 'local', 'structure', 'edges', 'lines', 'among', 'neighboring', 'pixels', 'leading', 'low', 'training', 'sample', 'efficiency', 'redundant', 'attention', 'backbone', 'design', 'vit', 'leads', 'limited', 'feature', 'richness', 'fixed', 'computation', 'budgets', 'limited', 'training', 'samples', 'overcome', 'limitations', 'propose', 'tokens', 'token', 'vision', 'transformer', 'tt', 'vit', 'incorporates', 'layer', 'wise', 'tokens', 'token', 'tt', 'transformation', 'progressively', 'structurize', 'image', 'tokens', 'recursively', 'aggregating', 'neighboring', 'tokens', 'one', 'token', 'tokens', 'token', 'local', 'structure', 'represented', 'surrounding', 'tokens', 'modeled', 'tokens', 'length', 'reduced', 'efficient', 'backbone', 'deep', 'narrow', 'structure', 'vision', 'transformer', 'motivated', 'cnn', 'architecture', 'design', 'empirical', 'study', 'notably', 'tt', 'vit', 'reduces', 'parameter', 'count', 'macs', 'vanilla', 'vit', 'half', 'achieving', 'improvement', 'trained', 'scratch', 'imagenet', 'also', 'outperforms', 'resnets', 'achieves', 'comparable', 'performance', 'mobilenets', 'directly', 'training', 'imagenet', 'example', 'tt', 'vit', 'comparable', 'size', 'resnet', 'parameters', 'achieve', 'top', 'accuracy', 'image', 'resolution', 'imagenet', 'li', 'yuan', 'yunpeng', 'chen', 'tao', 'wang', 'weihao', 'yu', 'yujun', 'shi', 'zihang', 'jiang', 'francis', 'eh', 'tay', 'jiashi', 'feng', 'shuicheng', 'yangithub', 'repository', 'jax', 'flax', 'model', 'https', 'tokens', 'token', 'vit', 'research', 'paper', 'https', 'official', 'github', 'repository', 'https', 'collaboration', 'dr', 'phil', 'lucid', 'wang', 'https', 'github', 'com', 'lucidrains', 'https', 'github', 'com', 'lucidrains']","['p', 'token', 'token', 'vit', 'implement', 'flaxxb', 'http', 'open', 'sourc', 'implement', 'token', 'token', 'vit', 'train', 'vision', 'transform', 'scratch', 'imagenet', 'research', 'paper', 'googl', 'jax', 'flax', 'transform', 'popular', 'languag', 'model', 'explor', 'solv', 'vision', 'task', 'recent', 'e', 'g', 'vision', 'transform', 'vit', 'imag', 'classif', 'vit', 'model', 'split', 'imag', 'sequenc', 'token', 'fix', 'length', 'appli', 'multipl', 'transform', 'layer', 'model', 'global', 'relat', 'classif', 'howev', 'vit', 'achiev', 'inferior', 'perform', 'cnn', 'train', 'scratch', 'midsiz', 'dataset', 'like', 'imagenet', 'find', 'simpl', 'token', 'input', 'imag', 'fail', 'model', 'import', 'local', 'structur', 'edg', 'line', 'among', 'neighbor', 'pixel', 'lead', 'low', 'train', 'sampl', 'effici', 'redund', 'attent', 'backbon', 'design', 'vit', 'lead', 'limit', 'featur', 'rich', 'fix', 'comput', 'budget', 'limit', 'train', 'sampl', 'overcom', 'limit', 'propos', 'token', 'token', 'vision', 'transform', 'tt', 'vit', 'incorpor', 'layer', 'wise', 'token', 'token', 'tt', 'transform', 'progress', 'structur', 'imag', 'token', 'recurs', 'aggreg', 'neighbor', 'token', 'one', 'token', 'token', 'token', 'local', 'structur', 'repres', 'surround', 'token', 'model', 'token', 'length', 'reduc', 'effici', 'backbon', 'deep', 'narrow', 'structur', 'vision', 'transform', 'motiv', 'cnn', 'architectur', 'design', 'empir', 'studi', 'notabl', 'tt', 'vit', 'reduc', 'paramet', 'count', 'mac', 'vanilla', 'vit', 'half', 'achiev', 'improv', 'train', 'scratch', 'imagenet', 'also', 'outperform', 'resnet', 'achiev', 'compar', 'perform', 'mobilenet', 'directli', 'train', 'imagenet', 'exampl', 'tt', 'vit', 'compar', 'size', 'resnet', 'paramet', 'achiev', 'top', 'accuraci', 'imag', 'resolut', 'imagenet', 'li', 'yuan', 'yunpeng', 'chen', 'tao', 'wang', 'weihao', 'yu', 'yujun', 'shi', 'zihang', 'jiang', 'franci', 'eh', 'tay', 'jiashi', 'feng', 'shuicheng', 'yangithub', 'repositori', 'jax', 'flax', 'model', 'http', 'token', 'token', 'vit', 'research', 'paper', 'http', 'offici', 'github', 'repositori', 'http', 'collabor', 'dr', 'phil', 'lucid', 'wang', 'http', 'github', 'com', 'lucidrain', 'http', 'github', 'com', 'lucidrain']"
41,44,44,thejashGI,vxhpnx,"[D]Oleh Rybkin, UPenn, on exploration and planning with world models","Here is a [podcast](https://generallyintelligent.ai/podcast/2022-07-11-podcast-episode-18-oleh-rybkin/) with Oleh Rybkin where we discuss agents that explore and plan (and do yoga), how to learn world models from video, what's missing from current RL research, and much more!",0,0,2022-07-12 23:43:30, d oleh rybkin  upenn  on exploration and planning with world models,here is a  podcast  https   generallyintelligent ai podcast    podcast episode  oleh rybkin   with oleh rybkin where we discuss agents that explore and plan  and do yoga   how to learn world models from video  what s missing from current rl research  and much more ,podcast https generallyintelligent ai podcast podcast episode oleh rybkin oleh rybkin discuss agents explore plan yoga learn world models video missing current rl research much,oleh rybkin upenn exploration planning world models,oleh rybkin upenn exploration planning world modelspodcast https generallyintelligent ai podcast podcast episode oleh rybkin oleh rybkin discuss agents explore plan yoga learn world models video missing current rl research much,"['oleh', 'rybkin', 'upenn', 'exploration', 'planning', 'world', 'modelspodcast', 'https', 'generallyintelligent', 'ai', 'podcast', 'podcast', 'episode', 'oleh', 'rybkin', 'oleh', 'rybkin', 'discuss', 'agents', 'explore', 'plan', 'yoga', 'learn', 'world', 'models', 'video', 'missing', 'current', 'rl', 'research', 'much']","['oleh', 'rybkin', 'upenn', 'explor', 'plan', 'world', 'modelspodcast', 'http', 'generallyintellig', 'ai', 'podcast', 'podcast', 'episod', 'oleh', 'rybkin', 'oleh', 'rybkin', 'discuss', 'agent', 'explor', 'plan', 'yoga', 'learn', 'world', 'model', 'video', 'miss', 'current', 'rl', 'research', 'much']"
42,45,45,anacondavibes,vx10zn,[D] Understanding how hardware plays a role in creating AI models," I'm wondering if there's any sort of article/videos/reddit post focused on explaining everything to know about hardware and it's impact on AI (cores, tensors, cores, threading, etc.) I have a lot of background from the software side so code optimization isn't something that tI've thought too much about but I'm currently working on building my own PC so I do need this information (I'm not looking for a guide because that won't help me learn, but I want to learn all this stuff from the ground up).

Any recommendations on where I can learn more about this? Thanks!",5,9,2022-07-12 08:44:58, d  understanding how hardware plays a role in creating ai models, i m wondering if there s any sort of article videos reddit post focused on explaining everything to know about hardware and it s impact on ai  cores  tensors  cores  threading  etc   i have a lot of background from the software side so code optimization isn t something that ti ve thought too much about but i m currently working on building my own pc so i do need this information  i m not looking for a guide because that won t help me learn  but i want to learn all this stuff from the ground up  any recommendations on where i can learn more about this  thanks ,wondering sort article videos reddit post focused explaining everything know hardware impact ai cores tensors cores threading etc lot background software side code optimization something ti thought much currently working building pc need information looking guide help learn want learn stuff ground recommendations learn thanks,understanding hardware plays role creating ai models,understanding hardware plays role creating ai modelswondering sort article videos reddit post focused explaining everything know hardware impact ai cores tensors cores threading etc lot background software side code optimization something ti thought much currently working building pc need information looking guide help learn want learn stuff ground recommendations learn thanks,"['understanding', 'hardware', 'plays', 'role', 'creating', 'ai', 'modelswondering', 'sort', 'article', 'videos', 'reddit', 'post', 'focused', 'explaining', 'everything', 'know', 'hardware', 'impact', 'ai', 'cores', 'tensors', 'cores', 'threading', 'etc', 'lot', 'background', 'software', 'side', 'code', 'optimization', 'something', 'ti', 'thought', 'much', 'currently', 'working', 'building', 'pc', 'need', 'information', 'looking', 'guide', 'help', 'learn', 'want', 'learn', 'stuff', 'ground', 'recommendations', 'learn', 'thanks']","['understand', 'hardwar', 'play', 'role', 'creat', 'ai', 'modelswond', 'sort', 'articl', 'video', 'reddit', 'post', 'focus', 'explain', 'everyth', 'know', 'hardwar', 'impact', 'ai', 'core', 'tensor', 'core', 'thread', 'etc', 'lot', 'background', 'softwar', 'side', 'code', 'optim', 'someth', 'ti', 'thought', 'much', 'current', 'work', 'build', 'pc', 'need', 'inform', 'look', 'guid', 'help', 'learn', 'want', 'learn', 'stuff', 'ground', 'recommend', 'learn', 'thank']"
43,46,46,Singularian2501,vwyjh1,"[R] Machine Learning Operations (MLOps): Overview, Definition, and Architecture","Paper: [https://arxiv.org/ftp/arxiv/papers/2205/2205.02302.pdf](https://arxiv.org/ftp/arxiv/papers/2205/2205.02302.pdf)

Abstract:

>The final goal of all industrial machine learning (ML) projects is to develop ML products and rapidly bring them into production. However, it is highly challenging to automate and operationalize ML products and thus many ML endeavors fail to deliver on their expectations. The paradigm of Machine Learning Operations (MLOps) addresses this issue. MLOps includes several aspects, such as best practices, sets of concepts, and development culture. However, MLOps is still a vague term and its consequences for researchers and professionals are ambiguous. To address this gap, we conduct mixed-method research, including a literature review, a tool review, and expert interviews. As a result of these investigations, we provide an aggregated overview of the necessary principles, components, and roles, as well as the associated architecture and workflows. Furthermore, we furnish a definition of MLOps and highlight open challenges in the field. Finally, this work provides guidance for ML researchers and practitioners who want to automate and operate their ML products with a designated set of technologies. 

https://preview.redd.it/km40o6fce1b91.jpg?width=785&format=pjpg&auto=webp&s=1e1079e839c8230f03df4bcd25b2cc3d58d42049",3,12,2022-07-12 06:42:21, r  machine learning operations  mlops   overview  definition  and architecture,paper   https abstract  the final goal of all industrial machine learning  ml  projects is to develop ml products and rapidly bring them into production  however  it is highly challenging to automate and operationalize ml products and thus many ml endeavors fail to deliver on their expectations  the paradigm of machine learning operations  mlops  addresses this issue  mlops includes several aspects  such as best practices  sets of concepts  and development culture  however  mlops is still a vague term and its consequences for researchers and professionals are ambiguous  to address this gap  we conduct mixed method research  including a literature review  a tool review  and expert interviews  as a result of these investigations  we provide an aggregated overview of the necessary principles  components  and roles  as well as the associated architecture and workflows  furthermore  we furnish a definition of mlops and highlight open challenges in the field  finally  this work provides guidance for ml researchers and practitioners who want to automate and operate their ml products with a designated set of technologies  https   preview redd it kmofceb jpg width  format pjpg auto webp s eecfdfbcdbccdd,paper https abstract final goal industrial machine learning ml projects develop ml products rapidly bring production however highly challenging automate operationalize ml products thus many ml endeavors fail deliver expectations paradigm machine learning operations mlops addresses issue mlops includes several aspects best practices sets concepts development culture however mlops still vague term consequences researchers professionals ambiguous address gap conduct mixed method research including literature review tool review expert interviews result investigations provide aggregated overview necessary principles components roles well associated architecture workflows furthermore furnish definition mlops highlight open challenges field finally work provides guidance ml researchers practitioners want automate operate ml products designated set technologies https preview redd kmofceb jpg width format pjpg auto webp eecfdfbcdbccdd,r machine learning operations mlops overview definition architecture,r machine learning operations mlops overview definition architecturepaper https abstract final goal industrial machine learning ml projects develop ml products rapidly bring production however highly challenging automate operationalize ml products thus many ml endeavors fail deliver expectations paradigm machine learning operations mlops addresses issue mlops includes several aspects best practices sets concepts development culture however mlops still vague term consequences researchers professionals ambiguous address gap conduct mixed method research including literature review tool review expert interviews result investigations provide aggregated overview necessary principles components roles well associated architecture workflows furthermore furnish definition mlops highlight open challenges field finally work provides guidance ml researchers practitioners want automate operate ml products designated set technologies https preview redd kmofceb jpg width format pjpg auto webp eecfdfbcdbccdd,"['r', 'machine', 'learning', 'operations', 'mlops', 'overview', 'definition', 'architecturepaper', 'https', 'abstract', 'final', 'goal', 'industrial', 'machine', 'learning', 'ml', 'projects', 'develop', 'ml', 'products', 'rapidly', 'bring', 'production', 'however', 'highly', 'challenging', 'automate', 'operationalize', 'ml', 'products', 'thus', 'many', 'ml', 'endeavors', 'fail', 'deliver', 'expectations', 'paradigm', 'machine', 'learning', 'operations', 'mlops', 'addresses', 'issue', 'mlops', 'includes', 'several', 'aspects', 'best', 'practices', 'sets', 'concepts', 'development', 'culture', 'however', 'mlops', 'still', 'vague', 'term', 'consequences', 'researchers', 'professionals', 'ambiguous', 'address', 'gap', 'conduct', 'mixed', 'method', 'research', 'including', 'literature', 'review', 'tool', 'review', 'expert', 'interviews', 'result', 'investigations', 'provide', 'aggregated', 'overview', 'necessary', 'principles', 'components', 'roles', 'well', 'associated', 'architecture', 'workflows', 'furthermore', 'furnish', 'definition', 'mlops', 'highlight', 'open', 'challenges', 'field', 'finally', 'work', 'provides', 'guidance', 'ml', 'researchers', 'practitioners', 'want', 'automate', 'operate', 'ml', 'products', 'designated', 'set', 'technologies', 'https', 'preview', 'redd', 'kmofceb', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'eecfdfbcdbccdd']","['r', 'machin', 'learn', 'oper', 'mlop', 'overview', 'definit', 'architecturepap', 'http', 'abstract', 'final', 'goal', 'industri', 'machin', 'learn', 'ml', 'project', 'develop', 'ml', 'product', 'rapidli', 'bring', 'product', 'howev', 'highli', 'challeng', 'autom', 'operation', 'ml', 'product', 'thu', 'mani', 'ml', 'endeavor', 'fail', 'deliv', 'expect', 'paradigm', 'machin', 'learn', 'oper', 'mlop', 'address', 'issu', 'mlop', 'includ', 'sever', 'aspect', 'best', 'practic', 'set', 'concept', 'develop', 'cultur', 'howev', 'mlop', 'still', 'vagu', 'term', 'consequ', 'research', 'profession', 'ambigu', 'address', 'gap', 'conduct', 'mix', 'method', 'research', 'includ', 'literatur', 'review', 'tool', 'review', 'expert', 'interview', 'result', 'investig', 'provid', 'aggreg', 'overview', 'necessari', 'principl', 'compon', 'role', 'well', 'associ', 'architectur', 'workflow', 'furthermor', 'furnish', 'definit', 'mlop', 'highlight', 'open', 'challeng', 'field', 'final', 'work', 'provid', 'guidanc', 'ml', 'research', 'practition', 'want', 'autom', 'oper', 'ml', 'product', 'design', 'set', 'technolog', 'http', 'preview', 'redd', 'kmofceb', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'eecfdfbcdbccdd']"
44,47,47,Character-Rip-5824,vwxs2u,"""[Project]"" Brainchop: In Browser 3D Segmentation. Now 50 and 104 Brain Segmentations. (Follow up).","&#x200B;

https://reddit.com/link/vwxs2u/video/91mo2fnr81b91/player

Live Demo:  [brainchop.org](https://neuroneural.github.io/brainchop/)

  
[Brainchop](https://github.com/neuroneural/brainchop) is  a  client-side web-application  for automatic segmentation of MRI     volumes  , we make implementation of [brainchop](https://github.com/neuroneural/brainchop) freely available releasing its pure **Javascript** code as open-source.

We appreciate your **ideas/feedback /comments** here or with the [discussion](https://github.com/neuroneural/brainchop/discussions) board,   and please  star [Brainchop](https://github.com/neuroneural/brainchop) if you  like it to keep it going.",4,10,2022-07-12 06:04:49, project  brainchop  in browser d segmentation  now  and  brain segmentations   follow up  ,  xb https live demo    brainchop org  https    brainchop  https we appreciate your   ideas feedback  comments   here or with the  discussion  https   github com neuroneural brainchop discussions  board    and please  star  brainchop  https   github com neuroneural brainchop  if you  like it to keep it going ,xb https live demo brainchop org https brainchop https appreciate ideas feedback comments discussion https github com neuroneural brainchop discussions board please star brainchop https github com neuroneural brainchop like keep going,project brainchop browser segmentation brain segmentations follow,project brainchop browser segmentation brain segmentations followxb https live demo brainchop org https brainchop https appreciate ideas feedback comments discussion https github com neuroneural brainchop discussions board please star brainchop https github com neuroneural brainchop like keep going,"['project', 'brainchop', 'browser', 'segmentation', 'brain', 'segmentations', 'followxb', 'https', 'live', 'demo', 'brainchop', 'org', 'https', 'brainchop', 'https', 'appreciate', 'ideas', 'feedback', 'comments', 'discussion', 'https', 'github', 'com', 'neuroneural', 'brainchop', 'discussions', 'board', 'please', 'star', 'brainchop', 'https', 'github', 'com', 'neuroneural', 'brainchop', 'like', 'keep', 'going']","['project', 'brainchop', 'browser', 'segment', 'brain', 'segment', 'followxb', 'http', 'live', 'demo', 'brainchop', 'org', 'http', 'brainchop', 'http', 'appreci', 'idea', 'feedback', 'comment', 'discuss', 'http', 'github', 'com', 'neuroneur', 'brainchop', 'discuss', 'board', 'pleas', 'star', 'brainchop', 'http', 'github', 'com', 'neuroneur', 'brainchop', 'like', 'keep', 'go']"
45,48,48,AdelSexy,vwdp7n,[D] Next big thing in the field,"Do you guys have any forecasts of next big model/algorithm/concept in DL?

We had CNNs disrupting the field in \~2015, then GANs became a big deal, RL grown quite a lot, Transformers trended recently, now Diffusion models are moving probabilistic ML forward (sorry if I missed something). What other not fully investigated or underestimated concepts with high potential are there?",98,143,2022-07-11 14:18:13, d  next big thing in the field,do you guys have any forecasts of next big model algorithm concept in dl we had cnns disrupting the field in     then gans became a big deal  rl grown quite a lot  transformers trended recently  now diffusion models are moving probabilistic ml forward  sorry if i missed something   what other not fully investigated or underestimated concepts with high potential are there ,guys forecasts next big model algorithm concept dl cnns disrupting field gans became big deal rl grown quite lot transformers trended recently diffusion models moving probabilistic ml forward sorry missed something fully investigated underestimated concepts high potential,next big thing field,next big thing fieldguys forecasts next big model algorithm concept dl cnns disrupting field gans became big deal rl grown quite lot transformers trended recently diffusion models moving probabilistic ml forward sorry missed something fully investigated underestimated concepts high potential,"['next', 'big', 'thing', 'fieldguys', 'forecasts', 'next', 'big', 'model', 'algorithm', 'concept', 'dl', 'cnns', 'disrupting', 'field', 'gans', 'became', 'big', 'deal', 'rl', 'grown', 'quite', 'lot', 'transformers', 'trended', 'recently', 'diffusion', 'models', 'moving', 'probabilistic', 'ml', 'forward', 'sorry', 'missed', 'something', 'fully', 'investigated', 'underestimated', 'concepts', 'high', 'potential']","['next', 'big', 'thing', 'fieldguy', 'forecast', 'next', 'big', 'model', 'algorithm', 'concept', 'dl', 'cnn', 'disrupt', 'field', 'gan', 'becam', 'big', 'deal', 'rl', 'grown', 'quit', 'lot', 'transform', 'trend', 'recent', 'diffus', 'model', 'move', 'probabilist', 'ml', 'forward', 'sorri', 'miss', 'someth', 'fulli', 'investig', 'underestim', 'concept', 'high', 'potenti']"
46,49,49,Azuresonance,vw8jtp,[D] Why are Corgi dogs so popular in machine learning (especially in the image generation community)?,"For example, here's part of OpenAI's GLIDE paper:

https://preview.redd.it/b6vkxyb3xua91.png?width=1225&format=png&auto=webp&s=15d56f256e323bb54d22eb9fdc0538644060c4a7",68,318,2022-07-11 08:48:28, d  why are corgi dogs so popular in machine learning  especially in the image generation community  ,for example  here s part of openai s glide paper https   preview redd it bvkxybxua png width  format png auto webp s dfebbdebfdcca,example part openai glide paper https preview redd bvkxybxua png width format png auto webp dfebbdebfdcca,corgi dogs popular machine learning especially image generation community,corgi dogs popular machine learning especially image generation communityexample part openai glide paper https preview redd bvkxybxua png width format png auto webp dfebbdebfdcca,"['corgi', 'dogs', 'popular', 'machine', 'learning', 'especially', 'image', 'generation', 'communityexample', 'part', 'openai', 'glide', 'paper', 'https', 'preview', 'redd', 'bvkxybxua', 'png', 'width', 'format', 'png', 'auto', 'webp', 'dfebbdebfdcca']","['corgi', 'dog', 'popular', 'machin', 'learn', 'especi', 'imag', 'gener', 'communityexampl', 'part', 'openai', 'glide', 'paper', 'http', 'preview', 'redd', 'bvkxybxua', 'png', 'width', 'format', 'png', 'auto', 'webp', 'dfebbdebfdcca']"
47,50,50,shreyansh26,vwq2ac,[P] Paper Implementation - Extracting Training Data from Large Language Models," A re-implementation of the famous 2020 paper - ""Extracting Training Data from Large Language Models"" by Nicholas Carlini, Florian Tramer et al.

Code - [https://github.com/shreyansh26/Extracting-Training-Data-from-Large-Langauge-Models](https://github.com/shreyansh26/Extracting-Training-Data-from-Large-Langauge-Models)

The official implementation is great and I definitely learned a few things from it. In the re-implementation, I have also included the temperature-decay sampling and sliding-window-based minimum perplexity metric which was not present in the official implementation.

I checked the extracted Samples (refer to the Github repo) and they surely contained some memorized information.",0,17,2022-07-12 00:29:05, p  paper implementation   extracting training data from large language models, a re implementation of the famous  paper   extracting training data from large language models by nicholas carlini  florian tramer et al code    https the official implementation is great and i definitely learned a few things from it  in the re implementation  i have also included the temperature decay sampling and sliding window based minimum perplexity metric which was not present in the official implementation i checked the extracted samples  refer to the github repo  and they surely contained some memorized information ,implementation famous paper extracting training data large language models nicholas carlini florian tramer et al code https official implementation great definitely learned things implementation also included temperature decay sampling sliding window based minimum perplexity metric present official implementation checked extracted samples refer github repo surely contained memorized information,p paper implementation extracting training data large language models,p paper implementation extracting training data large language modelsimplementation famous paper extracting training data large language models nicholas carlini florian tramer et al code https official implementation great definitely learned things implementation also included temperature decay sampling sliding window based minimum perplexity metric present official implementation checked extracted samples refer github repo surely contained memorized information,"['p', 'paper', 'implementation', 'extracting', 'training', 'data', 'large', 'language', 'modelsimplementation', 'famous', 'paper', 'extracting', 'training', 'data', 'large', 'language', 'models', 'nicholas', 'carlini', 'florian', 'tramer', 'et', 'al', 'code', 'https', 'official', 'implementation', 'great', 'definitely', 'learned', 'things', 'implementation', 'also', 'included', 'temperature', 'decay', 'sampling', 'sliding', 'window', 'based', 'minimum', 'perplexity', 'metric', 'present', 'official', 'implementation', 'checked', 'extracted', 'samples', 'refer', 'github', 'repo', 'surely', 'contained', 'memorized', 'information']","['p', 'paper', 'implement', 'extract', 'train', 'data', 'larg', 'languag', 'modelsimplement', 'famou', 'paper', 'extract', 'train', 'data', 'larg', 'languag', 'model', 'nichola', 'carlini', 'florian', 'tramer', 'et', 'al', 'code', 'http', 'offici', 'implement', 'great', 'definit', 'learn', 'thing', 'implement', 'also', 'includ', 'temperatur', 'decay', 'sampl', 'slide', 'window', 'base', 'minimum', 'perplex', 'metric', 'present', 'offici', 'implement', 'check', 'extract', 'sampl', 'refer', 'github', 'repo', 'sure', 'contain', 'memor', 'inform']"
48,51,51,InfiniteLife2,vwkbtr,[D] What is your go-to algorithm for Multiple Object Tracking with possible long time occlusions?," 

Im interested in tracking cars and people with ability to solve occlusion of objects that might not be moving. Things I've tried are decent but not amazing(Deepsort, ByteTrack). There is a few recent studies about using transformers for tracking, but those things are heavy and not really production material, having deformable convolutions in them(hard or not possible convert to torchscript and tensorrt) and all.

What's your go-to algorithm for this kind of problem?",6,24,2022-07-11 20:24:38, d  what is your go to algorithm for multiple object tracking with possible long time occlusions , im interested in tracking cars and people with ability to solve occlusion of objects that might not be moving  things i ve tried are decent but not amazing deepsort  bytetrack   there is a few recent studies about using transformers for tracking  but those things are heavy and not really production material  having deformable convolutions in them hard or not possible convert to torchscript and tensorrt  and all what s your go to algorithm for this kind of problem ,im interested tracking cars people ability solve occlusion objects might moving things tried decent amazing deepsort bytetrack recent studies using transformers tracking things heavy really production material deformable convolutions hard possible convert torchscript tensorrt go algorithm kind problem,go algorithm multiple object tracking possible long time occlusions,go algorithm multiple object tracking possible long time occlusionsim interested tracking cars people ability solve occlusion objects might moving things tried decent amazing deepsort bytetrack recent studies using transformers tracking things heavy really production material deformable convolutions hard possible convert torchscript tensorrt go algorithm kind problem,"['go', 'algorithm', 'multiple', 'object', 'tracking', 'possible', 'long', 'time', 'occlusionsim', 'interested', 'tracking', 'cars', 'people', 'ability', 'solve', 'occlusion', 'objects', 'might', 'moving', 'things', 'tried', 'decent', 'amazing', 'deepsort', 'bytetrack', 'recent', 'studies', 'using', 'transformers', 'tracking', 'things', 'heavy', 'really', 'production', 'material', 'deformable', 'convolutions', 'hard', 'possible', 'convert', 'torchscript', 'tensorrt', 'go', 'algorithm', 'kind', 'problem']","['go', 'algorithm', 'multipl', 'object', 'track', 'possibl', 'long', 'time', 'occlusionsim', 'interest', 'track', 'car', 'peopl', 'abil', 'solv', 'occlus', 'object', 'might', 'move', 'thing', 'tri', 'decent', 'amaz', 'deepsort', 'bytetrack', 'recent', 'studi', 'use', 'transform', 'track', 'thing', 'heavi', 'realli', 'product', 'materi', 'deform', 'convolut', 'hard', 'possibl', 'convert', 'torchscript', 'tensorrt', 'go', 'algorithm', 'kind', 'problem']"
49,52,52,inigomlap,vwf9wo,[R] Closed-Form Diffeomorphic Transformations for Time Series Alignment,"Paper: [https://arxiv.org/pdf/2206.08107.pdf](https://arxiv.org/pdf/2206.08107.pdf)

Code: [https://github.com/imartinezl/difw](https://github.com/imartinezl/difw)

Abstract:

>Time series alignment methods call for highly expressive, differentiable and invertible warping functions which preserve temporal topology, i.e diffeomorphisms. **Diffeomorphic warping functions can be generated from the integration of velocity fields governed by an ordinary differential equation (ODE)**. Gradient-based optimization frameworks containing diffeomorphic transformations require to calculate derivatives to the differential equation's solution with respect to the model parameters, i.e. sensitivity analysis. Unfortunately, deep learning frameworks typically lack automatic-differentiation-compatible sensitivity analysis methods; and implicit functions, such as the solution of ODE, require particular care. Current solutions appeal to adjoint sensitivity methods, ad-hoc numerical solvers or ResNet's Eulerian discretization. In this work, we present a **closed-form expression for the ODE solution and its gradient under continuous piecewise-affine (CPA) velocity functions**. We present a highly optimized implementation of the results on CPU and GPU. Furthermore, we conduct extensive experiments on several datasets to validate the generalization ability of our model to unseen data for time-series joint alignment. Results show significant improvements both in terms of efficiency and accuracy.

https://reddit.com/link/vwf9wo/video/vvjnwp2y0xa91/player

&#x200B;",4,30,2022-07-11 16:07:37, r  closed form diffeomorphic transformations for time series alignment,paper   https code   https abstract  time series alignment methods call for highly expressive  differentiable and invertible warping functions which preserve temporal topology  i e diffeomorphisms    diffeomorphic warping functions can be generated from the integration of velocity fields governed by an ordinary differential equation  ode     gradient based optimization frameworks containing diffeomorphic transformations require to calculate derivatives to the differential equation s solution with respect to the model parameters  i e  sensitivity analysis  unfortunately  deep learning frameworks typically lack automatic differentiation compatible sensitivity analysis methods  and implicit functions  such as the solution of ode  require particular care  current solutions appeal to adjoint sensitivity methods  ad hoc numerical solvers or resnet s eulerian discretization  in this work  we present a   closed form expression for the ode solution and its gradient under continuous piecewise affine  cpa  velocity functions    we present a highly optimized implementation of the results on cpu and gpu  furthermore  we conduct extensive experiments on several datasets to validate the generalization ability of our model to unseen data for time series joint alignment  results show significant improvements both in terms of efficiency and accuracy https   xb ,paper https code https abstract time series alignment methods call highly expressive differentiable invertible warping functions preserve temporal topology e diffeomorphisms diffeomorphic warping functions generated integration velocity fields governed ordinary differential equation ode gradient based optimization frameworks containing diffeomorphic transformations require calculate derivatives differential equation solution respect model parameters e sensitivity analysis unfortunately deep learning frameworks typically lack automatic differentiation compatible sensitivity analysis methods implicit functions solution ode require particular care current solutions appeal adjoint sensitivity methods ad hoc numerical solvers resnet eulerian discretization work present closed form expression ode solution gradient continuous piecewise affine cpa velocity functions present highly optimized implementation results cpu gpu furthermore conduct extensive experiments several datasets validate generalization ability model unseen data time series joint alignment results show significant improvements terms efficiency accuracy https xb,r closed form diffeomorphic transformations time series alignment,r closed form diffeomorphic transformations time series alignmentpaper https code https abstract time series alignment methods call highly expressive differentiable invertible warping functions preserve temporal topology e diffeomorphisms diffeomorphic warping functions generated integration velocity fields governed ordinary differential equation ode gradient based optimization frameworks containing diffeomorphic transformations require calculate derivatives differential equation solution respect model parameters e sensitivity analysis unfortunately deep learning frameworks typically lack automatic differentiation compatible sensitivity analysis methods implicit functions solution ode require particular care current solutions appeal adjoint sensitivity methods ad hoc numerical solvers resnet eulerian discretization work present closed form expression ode solution gradient continuous piecewise affine cpa velocity functions present highly optimized implementation results cpu gpu furthermore conduct extensive experiments several datasets validate generalization ability model unseen data time series joint alignment results show significant improvements terms efficiency accuracy https xb,"['r', 'closed', 'form', 'diffeomorphic', 'transformations', 'time', 'series', 'alignmentpaper', 'https', 'code', 'https', 'abstract', 'time', 'series', 'alignment', 'methods', 'call', 'highly', 'expressive', 'differentiable', 'invertible', 'warping', 'functions', 'preserve', 'temporal', 'topology', 'e', 'diffeomorphisms', 'diffeomorphic', 'warping', 'functions', 'generated', 'integration', 'velocity', 'fields', 'governed', 'ordinary', 'differential', 'equation', 'ode', 'gradient', 'based', 'optimization', 'frameworks', 'containing', 'diffeomorphic', 'transformations', 'require', 'calculate', 'derivatives', 'differential', 'equation', 'solution', 'respect', 'model', 'parameters', 'e', 'sensitivity', 'analysis', 'unfortunately', 'deep', 'learning', 'frameworks', 'typically', 'lack', 'automatic', 'differentiation', 'compatible', 'sensitivity', 'analysis', 'methods', 'implicit', 'functions', 'solution', 'ode', 'require', 'particular', 'care', 'current', 'solutions', 'appeal', 'adjoint', 'sensitivity', 'methods', 'ad', 'hoc', 'numerical', 'solvers', 'resnet', 'eulerian', 'discretization', 'work', 'present', 'closed', 'form', 'expression', 'ode', 'solution', 'gradient', 'continuous', 'piecewise', 'affine', 'cpa', 'velocity', 'functions', 'present', 'highly', 'optimized', 'implementation', 'results', 'cpu', 'gpu', 'furthermore', 'conduct', 'extensive', 'experiments', 'several', 'datasets', 'validate', 'generalization', 'ability', 'model', 'unseen', 'data', 'time', 'series', 'joint', 'alignment', 'results', 'show', 'significant', 'improvements', 'terms', 'efficiency', 'accuracy', 'https', 'xb']","['r', 'close', 'form', 'diffeomorph', 'transform', 'time', 'seri', 'alignmentpap', 'http', 'code', 'http', 'abstract', 'time', 'seri', 'align', 'method', 'call', 'highli', 'express', 'differenti', 'invert', 'warp', 'function', 'preserv', 'tempor', 'topolog', 'e', 'diffeomorph', 'diffeomorph', 'warp', 'function', 'gener', 'integr', 'veloc', 'field', 'govern', 'ordinari', 'differenti', 'equat', 'ode', 'gradient', 'base', 'optim', 'framework', 'contain', 'diffeomorph', 'transform', 'requir', 'calcul', 'deriv', 'differenti', 'equat', 'solut', 'respect', 'model', 'paramet', 'e', 'sensit', 'analysi', 'unfortun', 'deep', 'learn', 'framework', 'typic', 'lack', 'automat', 'differenti', 'compat', 'sensit', 'analysi', 'method', 'implicit', 'function', 'solut', 'ode', 'requir', 'particular', 'care', 'current', 'solut', 'appeal', 'adjoint', 'sensit', 'method', 'ad', 'hoc', 'numer', 'solver', 'resnet', 'eulerian', 'discret', 'work', 'present', 'close', 'form', 'express', 'ode', 'solut', 'gradient', 'continu', 'piecewis', 'affin', 'cpa', 'veloc', 'function', 'present', 'highli', 'optim', 'implement', 'result', 'cpu', 'gpu', 'furthermor', 'conduct', 'extens', 'experi', 'sever', 'dataset', 'valid', 'gener', 'abil', 'model', 'unseen', 'data', 'time', 'seri', 'joint', 'align', 'result', 'show', 'signific', 'improv', 'term', 'effici', 'accuraci', 'http', 'xb']"
50,53,53,chaude_patate,vwln0s,[D] Speech Enhancement SOTA,"Audio denoising (removing background noises from audio), often referred as Speech Enhancement, has been a midly popular research field up to 2020. This was due to COVID and the need to filter unwanted noises from calls. 

However, I'm not sure where we're at today:

* [Music Source Separation](https://www.reddit.com/r/MachineLearning/comments/pqpl7m/r_decoupling_magnitude_and_phase_estimation_with/) is improved by Tiktok and Deezer's researches
* Meta's [denoiser](https://github.com/facebookresearch/denoiser) looks like the most standard, production-ready model, and it implements a 2020 paper

I'd like to search for more alternatives, but I struggle to find some:

* Googling ""Denoising"" will lead to images noise removal
* Paper with Code's ""Speech denoising"" and ""Audio denoising"" categories are pretty empty. 
* The ""[Speech Enhancement](https://paperswithcode.com/task/speech-enhancement)"" category seems to be the real deal, but the top models don't have any pretrained version available.

Is there a model that outperform Meta's denoiser, while remaining open-source with an available pretrained model?",5,5,2022-07-11 21:21:43, d  speech enhancement sota,audio denoising  removing background noises from audio   often referred as speech enhancement  has been a midly popular research field up to   this was due to covid and the need to filter unwanted noises from calls  however  i m not sure where we re at today    music source separation  https   meta s  denoiser  https i d like to search for more alternatives  but i struggle to find some   googling denoising will lead to images noise removal  paper with code s speech denoising and audio denoising categories are pretty empty    the  speech enhancement  https is there a model that outperform meta s denoiser  while remaining open source with an available pretrained model ,audio denoising removing background noises audio often referred speech enhancement midly popular research field due covid need filter unwanted noises calls however sure today music source separation https meta denoiser https like search alternatives struggle find googling denoising lead images noise removal paper code speech denoising audio denoising categories pretty empty speech enhancement https model outperform meta denoiser remaining open source available pretrained model,speech enhancement sota,speech enhancement sotaaudio denoising removing background noises audio often referred speech enhancement midly popular research field due covid need filter unwanted noises calls however sure today music source separation https meta denoiser https like search alternatives struggle find googling denoising lead images noise removal paper code speech denoising audio denoising categories pretty empty speech enhancement https model outperform meta denoiser remaining open source available pretrained model,"['speech', 'enhancement', 'sotaaudio', 'denoising', 'removing', 'background', 'noises', 'audio', 'often', 'referred', 'speech', 'enhancement', 'midly', 'popular', 'research', 'field', 'due', 'covid', 'need', 'filter', 'unwanted', 'noises', 'calls', 'however', 'sure', 'today', 'music', 'source', 'separation', 'https', 'meta', 'denoiser', 'https', 'like', 'search', 'alternatives', 'struggle', 'find', 'googling', 'denoising', 'lead', 'images', 'noise', 'removal', 'paper', 'code', 'speech', 'denoising', 'audio', 'denoising', 'categories', 'pretty', 'empty', 'speech', 'enhancement', 'https', 'model', 'outperform', 'meta', 'denoiser', 'remaining', 'open', 'source', 'available', 'pretrained', 'model']","['speech', 'enhanc', 'sotaaudio', 'denois', 'remov', 'background', 'nois', 'audio', 'often', 'refer', 'speech', 'enhanc', 'midli', 'popular', 'research', 'field', 'due', 'covid', 'need', 'filter', 'unwant', 'nois', 'call', 'howev', 'sure', 'today', 'music', 'sourc', 'separ', 'http', 'meta', 'denois', 'http', 'like', 'search', 'altern', 'struggl', 'find', 'googl', 'denois', 'lead', 'imag', 'nois', 'remov', 'paper', 'code', 'speech', 'denois', 'audio', 'denois', 'categori', 'pretti', 'empti', 'speech', 'enhanc', 'http', 'model', 'outperform', 'meta', 'denois', 'remain', 'open', 'sourc', 'avail', 'pretrain', 'model']"
51,54,54,Labib666Camp,vwi9p7,[D] Modeling Adjacency Matrix,"Lets assume, I have some directed adjacency matrix *A* at time *t* and another adjacency matrix *B* at time *t+1*. I want to learn a mapping from *A* to *B* through some model *f* (suppose *f* is a neural network). Now, how should I create this model ? Should I use just Dense layers or GNNs or something?",8,7,2022-07-11 18:49:34, d  modeling adjacency matrix,lets assume  i have some directed adjacency matrix  a  at time  t  and another adjacency matrix  b  at time  t    i want to learn a mapping from  a  to  b  through some model  f   suppose  f  is a neural network   now  how should i create this model   should i use just dense layers or gnns or something ,lets assume directed adjacency matrix time another adjacency matrix b time want learn mapping b model f suppose f neural network create model use dense layers gnns something,modeling adjacency matrix,modeling adjacency matrixlets assume directed adjacency matrix time another adjacency matrix b time want learn mapping b model f suppose f neural network create model use dense layers gnns something,"['modeling', 'adjacency', 'matrixlets', 'assume', 'directed', 'adjacency', 'matrix', 'time', 'another', 'adjacency', 'matrix', 'b', 'time', 'want', 'learn', 'mapping', 'b', 'model', 'f', 'suppose', 'f', 'neural', 'network', 'create', 'model', 'use', 'dense', 'layers', 'gnns', 'something']","['model', 'adjac', 'matrixlet', 'assum', 'direct', 'adjac', 'matrix', 'time', 'anoth', 'adjac', 'matrix', 'b', 'time', 'want', 'learn', 'map', 'b', 'model', 'f', 'suppos', 'f', 'neural', 'network', 'creat', 'model', 'use', 'dens', 'layer', 'gnn', 'someth']"
52,55,55,blessedorcursed,vwg37x,[P] Semi-supervised learning for tabular data: VIME,"A lot of recent DL models for tabular data have used some sort of pre-training to increase the robustness and performance metrics on smaller/noisy datasets. That's why I've decided to write a [deep-dive blog](https://syslog.ravelin.com/fraud-detection-with-minimum-labels-semi-supervised-learning-d2f8e7136da6) into a VIME paper which was one of the first to suggest pre-training tasks specific for tabular data. 

It comes with an accompanying [repo](https://github.com/aruberts/blogs/tree/main/vime) that contains all the code and notebooks. From some personal testing that I've done, pre-training is the most valuable does improve the performance when we're dealing with very few labels (1-5% of the dataset). Of course, the best solution is to always get more labels lol, but when it's not possible, pre-training schemes like VIME can give you a small boost in performance. 

Give it a read and let me know what you think! I'll keep covering some interesting deep tabular architectures, so maybe also let me know which one would you want me to cover next!",0,8,2022-07-11 16:57:07, p  semi supervised learning for tabular data  vime,a lot of recent dl models for tabular data have used some sort of pre training to increase the robustness and performance metrics on smaller noisy datasets  that s why i ve decided to write a  deep dive blog  https it comes with an accompanying  repo  https give it a read and let me know what you think  i ll keep covering some interesting deep tabular architectures  so maybe also let me know which one would you want me to cover next ,lot recent dl models tabular data used sort pre training increase robustness performance metrics smaller noisy datasets decided write deep dive blog https comes accompanying repo https give read let know think keep covering interesting deep tabular architectures maybe also let know one would want cover next,p semi supervised learning tabular data vime,p semi supervised learning tabular data vimelot recent dl models tabular data used sort pre training increase robustness performance metrics smaller noisy datasets decided write deep dive blog https comes accompanying repo https give read let know think keep covering interesting deep tabular architectures maybe also let know one would want cover next,"['p', 'semi', 'supervised', 'learning', 'tabular', 'data', 'vimelot', 'recent', 'dl', 'models', 'tabular', 'data', 'used', 'sort', 'pre', 'training', 'increase', 'robustness', 'performance', 'metrics', 'smaller', 'noisy', 'datasets', 'decided', 'write', 'deep', 'dive', 'blog', 'https', 'comes', 'accompanying', 'repo', 'https', 'give', 'read', 'let', 'know', 'think', 'keep', 'covering', 'interesting', 'deep', 'tabular', 'architectures', 'maybe', 'also', 'let', 'know', 'one', 'would', 'want', 'cover', 'next']","['p', 'semi', 'supervis', 'learn', 'tabular', 'data', 'vimelot', 'recent', 'dl', 'model', 'tabular', 'data', 'use', 'sort', 'pre', 'train', 'increas', 'robust', 'perform', 'metric', 'smaller', 'noisi', 'dataset', 'decid', 'write', 'deep', 'dive', 'blog', 'http', 'come', 'accompani', 'repo', 'http', 'give', 'read', 'let', 'know', 'think', 'keep', 'cover', 'interest', 'deep', 'tabular', 'architectur', 'mayb', 'also', 'let', 'know', 'one', 'would', 'want', 'cover', 'next']"
53,56,56,EnricoShippole,vwmlrs,[P] ScalableViT Implementation in Flax,"An open-source implementation of the ScalableViT: Rethinking the Context-oriented Generalization of Vision Transformer research paper in Google's JAX and Flax.

""The vanilla self-attention mechanism inherently relies on pre-defined and steadfast computational dimensions. Such inflexibility restricts it from possessing context-oriented generalization that can bring more contextual cues and global representations. To mitigate this issue, we propose a Scalable Self-Attention (SSA) mechanism that leverages two scaling factors to release dimensions of query, key, and value matrix while unbinding them with the input. This scalability fetches context-oriented generalization and enhances object sensitivity, which pushes the whole network into a more effective trade-off state between accuracy and cost. Furthermore, we propose an Interactive Window-based Self-Attention (IWSA), which establishes interaction between non-overlapping regions by re-merging independent value tokens and aggregating spatial information from adjacent windows. By stacking the SSA and IWSA alternately, the Scalable Vision Transformer (ScalableViT) achieves state-of-the-art performance in general-purpose vision tasks. For example, ScalableViT-S outperforms Twins-SVT-S by 1.4% and Swin-T by 1.8% on ImageNet-1K classification."" - Rui Yang, Hailong Ma, Jie Wu, Yansong Tang, Xuefeng Xiao, Min Zheng, Xiu Li  


Github repository for the Flax / JAX model: [https://github.com/conceptofmind/Scalable-ViT-flax](https://github.com/conceptofmind/Scalable-ViT-flax)

ScalableViT Research Paper: [https://arxiv.org/abs/2203.10790](https://arxiv.org/abs/2203.10790)

In collaboration with Lucid: [https://github.com/lucidrains](https://github.com/lucidrains)",0,2,2022-07-11 22:01:46, p  scalablevit implementation in flax,an open source implementation of the scalablevit  rethinking the context oriented generalization of vision transformer research paper in google s jax and flax the vanilla self attention mechanism inherently relies on pre defined and steadfast computational dimensions  such inflexibility restricts it from possessing context oriented generalization that can bring more contextual cues and global representations  to mitigate this issue  we propose a scalable self attention  ssa  mechanism that leverages two scaling factors to release dimensions of query  key  and value matrix while unbinding them with the input  this scalability fetches context oriented generalization and enhances object sensitivity  which pushes the whole network into a more effective trade off state between accuracy and cost  furthermore  we propose an interactive window based self attention  iwsa   which establishes interaction between non overlapping regions by re merging independent value tokens and aggregating spatial information from adjacent windows  by stacking the ssa and iwsa alternately  the scalable vision transformer  scalablevit  achieves state of the art performance in general purpose vision tasks  for example  scalablevit s outperforms twins svt s by    and swin t by    on imagenet k classification    rui yang  hailong ma  jie wu  yansong tang  xuefeng xiao  min zheng  xiu li  github repository for the flax   jax model   https scalablevit research paper   https in collaboration with lucid   https   github com lucidrains  https   github com lucidrains ,open source implementation scalablevit rethinking context oriented generalization vision transformer research paper google jax flax vanilla self attention mechanism inherently relies pre defined steadfast computational dimensions inflexibility restricts possessing context oriented generalization bring contextual cues global representations mitigate issue propose scalable self attention ssa mechanism leverages two scaling factors release dimensions query key value matrix unbinding input scalability fetches context oriented generalization enhances object sensitivity pushes whole network effective trade state accuracy cost furthermore propose interactive window based self attention iwsa establishes interaction non overlapping regions merging independent value tokens aggregating spatial information adjacent windows stacking ssa iwsa alternately scalable vision transformer scalablevit achieves state art performance general purpose vision tasks example scalablevit outperforms twins svt swin imagenet k classification rui yang hailong jie wu yansong tang xuefeng xiao min zheng xiu li github repository flax jax model https scalablevit research paper https collaboration lucid https github com lucidrains https github com lucidrains,p scalablevit implementation flax,p scalablevit implementation flaxopen source implementation scalablevit rethinking context oriented generalization vision transformer research paper google jax flax vanilla self attention mechanism inherently relies pre defined steadfast computational dimensions inflexibility restricts possessing context oriented generalization bring contextual cues global representations mitigate issue propose scalable self attention ssa mechanism leverages two scaling factors release dimensions query key value matrix unbinding input scalability fetches context oriented generalization enhances object sensitivity pushes whole network effective trade state accuracy cost furthermore propose interactive window based self attention iwsa establishes interaction non overlapping regions merging independent value tokens aggregating spatial information adjacent windows stacking ssa iwsa alternately scalable vision transformer scalablevit achieves state art performance general purpose vision tasks example scalablevit outperforms twins svt swin imagenet k classification rui yang hailong jie wu yansong tang xuefeng xiao min zheng xiu li github repository flax jax model https scalablevit research paper https collaboration lucid https github com lucidrains https github com lucidrains,"['p', 'scalablevit', 'implementation', 'flaxopen', 'source', 'implementation', 'scalablevit', 'rethinking', 'context', 'oriented', 'generalization', 'vision', 'transformer', 'research', 'paper', 'google', 'jax', 'flax', 'vanilla', 'self', 'attention', 'mechanism', 'inherently', 'relies', 'pre', 'defined', 'steadfast', 'computational', 'dimensions', 'inflexibility', 'restricts', 'possessing', 'context', 'oriented', 'generalization', 'bring', 'contextual', 'cues', 'global', 'representations', 'mitigate', 'issue', 'propose', 'scalable', 'self', 'attention', 'ssa', 'mechanism', 'leverages', 'two', 'scaling', 'factors', 'release', 'dimensions', 'query', 'key', 'value', 'matrix', 'unbinding', 'input', 'scalability', 'fetches', 'context', 'oriented', 'generalization', 'enhances', 'object', 'sensitivity', 'pushes', 'whole', 'network', 'effective', 'trade', 'state', 'accuracy', 'cost', 'furthermore', 'propose', 'interactive', 'window', 'based', 'self', 'attention', 'iwsa', 'establishes', 'interaction', 'non', 'overlapping', 'regions', 'merging', 'independent', 'value', 'tokens', 'aggregating', 'spatial', 'information', 'adjacent', 'windows', 'stacking', 'ssa', 'iwsa', 'alternately', 'scalable', 'vision', 'transformer', 'scalablevit', 'achieves', 'state', 'art', 'performance', 'general', 'purpose', 'vision', 'tasks', 'example', 'scalablevit', 'outperforms', 'twins', 'svt', 'swin', 'imagenet', 'k', 'classification', 'rui', 'yang', 'hailong', 'jie', 'wu', 'yansong', 'tang', 'xuefeng', 'xiao', 'min', 'zheng', 'xiu', 'li', 'github', 'repository', 'flax', 'jax', 'model', 'https', 'scalablevit', 'research', 'paper', 'https', 'collaboration', 'lucid', 'https', 'github', 'com', 'lucidrains', 'https', 'github', 'com', 'lucidrains']","['p', 'scalablevit', 'implement', 'flaxopen', 'sourc', 'implement', 'scalablevit', 'rethink', 'context', 'orient', 'gener', 'vision', 'transform', 'research', 'paper', 'googl', 'jax', 'flax', 'vanilla', 'self', 'attent', 'mechan', 'inher', 'reli', 'pre', 'defin', 'steadfast', 'comput', 'dimens', 'inflex', 'restrict', 'possess', 'context', 'orient', 'gener', 'bring', 'contextu', 'cue', 'global', 'represent', 'mitig', 'issu', 'propos', 'scalabl', 'self', 'attent', 'ssa', 'mechan', 'leverag', 'two', 'scale', 'factor', 'releas', 'dimens', 'queri', 'key', 'valu', 'matrix', 'unbind', 'input', 'scalabl', 'fetch', 'context', 'orient', 'gener', 'enhanc', 'object', 'sensit', 'push', 'whole', 'network', 'effect', 'trade', 'state', 'accuraci', 'cost', 'furthermor', 'propos', 'interact', 'window', 'base', 'self', 'attent', 'iwsa', 'establish', 'interact', 'non', 'overlap', 'region', 'merg', 'independ', 'valu', 'token', 'aggreg', 'spatial', 'inform', 'adjac', 'window', 'stack', 'ssa', 'iwsa', 'altern', 'scalabl', 'vision', 'transform', 'scalablevit', 'achiev', 'state', 'art', 'perform', 'gener', 'purpos', 'vision', 'task', 'exampl', 'scalablevit', 'outperform', 'twin', 'svt', 'swin', 'imagenet', 'k', 'classif', 'rui', 'yang', 'hailong', 'jie', 'wu', 'yansong', 'tang', 'xuefeng', 'xiao', 'min', 'zheng', 'xiu', 'li', 'github', 'repositori', 'flax', 'jax', 'model', 'http', 'scalablevit', 'research', 'paper', 'http', 'collabor', 'lucid', 'http', 'github', 'com', 'lucidrain', 'http', 'github', 'com', 'lucidrain']"
54,58,58,cheemsdoge69,vwm5qa,[D] Instance segmentation using transformers,"Hi folks!
I am looking for beginner-friendly and easy to implement papers on instance segmentation using transformers.
Any help will be appreciated!!",1,3,2022-07-11 21:43:15, d  instance segmentation using transformers,hi folks i am looking for beginner friendly and easy to implement papers on instance segmentation using transformers any help will be appreciated  ,hi folks looking beginner friendly easy implement papers instance segmentation using transformers help appreciated,instance segmentation using transformers,instance segmentation using transformershi folks looking beginner friendly easy implement papers instance segmentation using transformers help appreciated,"['instance', 'segmentation', 'using', 'transformershi', 'folks', 'looking', 'beginner', 'friendly', 'easy', 'implement', 'papers', 'instance', 'segmentation', 'using', 'transformers', 'help', 'appreciated']","['instanc', 'segment', 'use', 'transformershi', 'folk', 'look', 'beginn', 'friendli', 'easi', 'implement', 'paper', 'instanc', 'segment', 'use', 'transform', 'help', 'appreci']"
55,59,59,CapitalShake3085,vwkwfr,[R] DA-Faster RCNN,"Hello,

I have reimplemented DA-Faster RCNN using Detectron2 one of the most important architecture for domain adaptation for object detection. This implementations is easy to use and can be used also with google colab :) here there is the link: [https://github.com/GiovanniPasq/DA-Faster-RCNN](https://github.com/GiovanniPasq/DA-Faster-RCNN)",0,1,2022-07-11 20:49:06, r  da faster rcnn,hello i have reimplemented da faster rcnn using detectron one of the most important architecture for domain adaptation for object detection  this implementations is easy to use and can be used also with google colab    here there is the link   https   github com giovannipasq da faster rcnn  https   github com giovannipasq da faster rcnn ,hello reimplemented da faster rcnn using detectron one important architecture domain adaptation object detection implementations easy use used also google colab link https github com giovannipasq da faster rcnn https github com giovannipasq da faster rcnn,r da faster rcnn,r da faster rcnnhello reimplemented da faster rcnn using detectron one important architecture domain adaptation object detection implementations easy use used also google colab link https github com giovannipasq da faster rcnn https github com giovannipasq da faster rcnn,"['r', 'da', 'faster', 'rcnnhello', 'reimplemented', 'da', 'faster', 'rcnn', 'using', 'detectron', 'one', 'important', 'architecture', 'domain', 'adaptation', 'object', 'detection', 'implementations', 'easy', 'use', 'used', 'also', 'google', 'colab', 'link', 'https', 'github', 'com', 'giovannipasq', 'da', 'faster', 'rcnn', 'https', 'github', 'com', 'giovannipasq', 'da', 'faster', 'rcnn']","['r', 'da', 'faster', 'rcnnhello', 'reimplement', 'da', 'faster', 'rcnn', 'use', 'detectron', 'one', 'import', 'architectur', 'domain', 'adapt', 'object', 'detect', 'implement', 'easi', 'use', 'use', 'also', 'googl', 'colab', 'link', 'http', 'github', 'com', 'giovannipasq', 'da', 'faster', 'rcnn', 'http', 'github', 'com', 'giovannipasq', 'da', 'faster', 'rcnn']"
56,60,60,aadityaura,vweop5,[R] An awesome collection of Federated learning & Blockchain research papers in the Healthcare domain,"An awesome collection of Federated learning & Blockchain research papers in the Healthcare domain.

  
Federated learning, a mechanism of training a shared global model with a central server while keeping all the sensitive data in local institutions where the data belong, provides great promise to connect the fragmented healthcare data sources with privacy preservation. This repo contains a curated list of Federated Learning papers/resources and recent advancements in Healthcare.

&#x200B;

* As of now \~**330 papers**
* Pr's welcome

[https://github.com/monk1337/Aweome-Heathcare-Federated-Learning](https://github.com/monk1337/Aweome-Heathcare-Federated-Learning)",0,0,2022-07-11 15:28:59, r  an awesome collection of federated learning   blockchain research papers in the healthcare domain,an awesome collection of federated learning   blockchain research papers in the healthcare domain   federated learning  a mechanism of training a shared global model with a central server while keeping all the sensitive data in local institutions where the data belong  provides great promise to connect the fragmented healthcare data sources with privacy preservation  this repo contains a curated list of federated learning papers resources and recent advancements in healthcare   xb   as of now      papers    pr s welcome https   github com monk aweome heathcare federated learning  https   github com monk aweome heathcare federated learning ,awesome collection federated learning blockchain research papers healthcare domain federated learning mechanism training shared global model central server keeping sensitive data local institutions data belong provides great promise connect fragmented healthcare data sources privacy preservation repo contains curated federated learning papers resources recent advancements healthcare xb papers pr welcome https github com monk aweome heathcare federated learning https github com monk aweome heathcare federated learning,r awesome collection federated learning blockchain research papers healthcare domain,r awesome collection federated learning blockchain research papers healthcare domainawesome collection federated learning blockchain research papers healthcare domain federated learning mechanism training shared global model central server keeping sensitive data local institutions data belong provides great promise connect fragmented healthcare data sources privacy preservation repo contains curated federated learning papers resources recent advancements healthcare xb papers pr welcome https github com monk aweome heathcare federated learning https github com monk aweome heathcare federated learning,"['r', 'awesome', 'collection', 'federated', 'learning', 'blockchain', 'research', 'papers', 'healthcare', 'domainawesome', 'collection', 'federated', 'learning', 'blockchain', 'research', 'papers', 'healthcare', 'domain', 'federated', 'learning', 'mechanism', 'training', 'shared', 'global', 'model', 'central', 'server', 'keeping', 'sensitive', 'data', 'local', 'institutions', 'data', 'belong', 'provides', 'great', 'promise', 'connect', 'fragmented', 'healthcare', 'data', 'sources', 'privacy', 'preservation', 'repo', 'contains', 'curated', 'federated', 'learning', 'papers', 'resources', 'recent', 'advancements', 'healthcare', 'xb', 'papers', 'pr', 'welcome', 'https', 'github', 'com', 'monk', 'aweome', 'heathcare', 'federated', 'learning', 'https', 'github', 'com', 'monk', 'aweome', 'heathcare', 'federated', 'learning']","['r', 'awesom', 'collect', 'feder', 'learn', 'blockchain', 'research', 'paper', 'healthcar', 'domainawesom', 'collect', 'feder', 'learn', 'blockchain', 'research', 'paper', 'healthcar', 'domain', 'feder', 'learn', 'mechan', 'train', 'share', 'global', 'model', 'central', 'server', 'keep', 'sensit', 'data', 'local', 'institut', 'data', 'belong', 'provid', 'great', 'promis', 'connect', 'fragment', 'healthcar', 'data', 'sourc', 'privaci', 'preserv', 'repo', 'contain', 'curat', 'feder', 'learn', 'paper', 'resourc', 'recent', 'advanc', 'healthcar', 'xb', 'paper', 'pr', 'welcom', 'http', 'github', 'com', 'monk', 'aweom', 'heathcar', 'feder', 'learn', 'http', 'github', 'com', 'monk', 'aweom', 'heathcar', 'feder', 'learn']"
57,61,61,timscarfe,vvkmf1,[D] Noam Chomsky on LLMs and discussion of LeCun paper (MLST),"""First we should ask the question whether LLM have achieved ANYTHING, ANYTHING in this domain. Answer, NO, they have achieved ZERO!"" - Noam Chomsky 

""There are engineering projects that are significantly advanced by \[[\#DL](https://mobile.twitter.com/hashtag/DL?src=hashtag_click)\] methods. And this is all the good. \[...\] Engineering is not a trivial field; it takes intelligence, invention, \[and\] creativity these achievements. That it contributes to science?"" - Noam Chomsky 

""There was a time \[supposedly dedicated\] to the study of the nature of [\#intelligence](https://mobile.twitter.com/hashtag/intelligence?src=hashtag_click). By now it has disappeared.""  Earlier, same interview: ""GPT-3 can \[only\] find some superficial irregularities in the data. \[...\] It's exciting for reporters in the NY Times."" - Noam Chomsky 

""It's not of interest to people, the idea of finding an explanation for something. \[...\] The \[original [\#AI](https://mobile.twitter.com/hashtag/AI?src=hashtag_click)\] field by now is considered old-fashioned, nonsense. \[...\] That's probably where the field will develop, where the money is. \[...\] But it's a shame."" - Noam Chomsky 

Thanks to Dagmar Monett for selecting the quotes!

Sorry for posting a controversial thread -- but this seemed noteworthy for /machinelearning 

Video: [https://youtu.be/axuGfh4UR9Q](https://youtu.be/axuGfh4UR9Q) \-- also some discussion of LeCun's recent position paper",242,273,2022-07-10 11:09:21, d  noam chomsky on llms and discussion of lecun paper  mlst ,first we should ask the question whether llm have achieved anything  anything in this domain  answer  no  they have achieved zero    noam chomsky there are engineering projects that are significantly advanced by      dl  https there was a time   supposedly dedicated   to the study of the nature of    intelligence  https it s not of interest to people  the idea of finding an explanation for something          the   original    ai  https thanks to dagmar monett for selecting the quotes sorry for posting a controversial thread    but this seemed noteworthy for  machinelearning video   https   youtu be axugfhurq  https   youtu be axugfhurq      also some discussion of lecun s recent position paper,first ask question whether llm achieved anything anything domain answer achieved zero noam chomsky engineering projects significantly advanced dl https time supposedly dedicated study nature intelligence https interest people idea finding explanation something original ai https thanks dagmar monett selecting quotes sorry posting controversial thread seemed noteworthy machinelearning video https youtu axugfhurq https youtu axugfhurq also discussion lecun recent position paper,noam chomsky llms discussion lecun paper mlst,noam chomsky llms discussion lecun paper mlstfirst ask question whether llm achieved anything anything domain answer achieved zero noam chomsky engineering projects significantly advanced dl https time supposedly dedicated study nature intelligence https interest people idea finding explanation something original ai https thanks dagmar monett selecting quotes sorry posting controversial thread seemed noteworthy machinelearning video https youtu axugfhurq https youtu axugfhurq also discussion lecun recent position paper,"['noam', 'chomsky', 'llms', 'discussion', 'lecun', 'paper', 'mlstfirst', 'ask', 'question', 'whether', 'llm', 'achieved', 'anything', 'anything', 'domain', 'answer', 'achieved', 'zero', 'noam', 'chomsky', 'engineering', 'projects', 'significantly', 'advanced', 'dl', 'https', 'time', 'supposedly', 'dedicated', 'study', 'nature', 'intelligence', 'https', 'interest', 'people', 'idea', 'finding', 'explanation', 'something', 'original', 'ai', 'https', 'thanks', 'dagmar', 'monett', 'selecting', 'quotes', 'sorry', 'posting', 'controversial', 'thread', 'seemed', 'noteworthy', 'machinelearning', 'video', 'https', 'youtu', 'axugfhurq', 'https', 'youtu', 'axugfhurq', 'also', 'discussion', 'lecun', 'recent', 'position', 'paper']","['noam', 'chomski', 'llm', 'discuss', 'lecun', 'paper', 'mlstfirst', 'ask', 'question', 'whether', 'llm', 'achiev', 'anyth', 'anyth', 'domain', 'answer', 'achiev', 'zero', 'noam', 'chomski', 'engin', 'project', 'significantli', 'advanc', 'dl', 'http', 'time', 'supposedli', 'dedic', 'studi', 'natur', 'intellig', 'http', 'interest', 'peopl', 'idea', 'find', 'explan', 'someth', 'origin', 'ai', 'http', 'thank', 'dagmar', 'monett', 'select', 'quot', 'sorri', 'post', 'controversi', 'thread', 'seem', 'noteworthi', 'machinelearn', 'video', 'http', 'youtu', 'axugfhurq', 'http', 'youtu', 'axugfhurq', 'also', 'discuss', 'lecun', 'recent', 'posit', 'paper']"
58,62,62,Capital_Revolution35,vw3tkf,"[P] A Website to generate Code Snippets, Regexes, Linux & Git & SQL Commands, HTML and CSS from a written description. Furthermore translate code snippets to many languages and get a regex explained in plain english. Moreover you can fix broken code snippets. All with the help of ML 🤖","https://reddit.com/link/vw3tkf/video/xe0t4pumpta91/player

https://reddit.com/link/vw3tkf/video/7pf9dl3npta91/player

**Programming**

* [**Function from Description**](https://programming-helper.com/generate-function)
* [**Code to Explanation**](https://programming-helper.com/code-to-explanation)
* [**Fix invalid Code**](https://programming-helper.com/fix-invalid-code)
* [**Translate Languages**](https://programming-helper.com/translate)
* [**Class from Description**](https://programming-helper.com/class-from-description)
* [**Get Language from Code**](https://programming-helper.com/language-from-code)
* [**Function from Docstring**](https://programming-helper.com/docstring)

**Helpers**

* [**Regex from Description**](https://programming-helper.com/regex)
* [**Regex to Explanation**](https://programming-helper.com/regex-explanation)
* [**Linux Command**](https://programming-helper.com/linux)
* [**Get time complexity**](https://programming-helper.com/time-complexity)
* [**Git Command from Description**](https://programming-helper.com/git)

**Database**

* [**Text Description to SQL Command**](https://programming-helper.com/text-to-sql-syntax)

**Web**

* [**Generate HTML from Description**](https://programming-helper.com/generate-html-from-description)
* [**CSS from Description**](https://programming-helper.com/css-from-description)
* [**Meta Tags from Description**](https://programming-helper.com/meta)

I think this could be helpful to a lot of people (especially for beginner programmers). You can check out all functionalities on your own here:

[programming-helper.com](https://programming-helper.com/)

**Have fun using the tool** ❤️",0,8,2022-07-11 04:44:09, p  a website to generate code snippets  regexes  linux   git   sql commands  html and css from a written description  furthermore translate code snippets to many languages and get a regex explained in plain english  moreover you can fix broken code snippets  all with the help of ml  ,https https   programming       function from description    https      code to explanation    https      fix invalid code    https      translate languages    https      class from description    https      get language from code    https      function from docstring    https   helpers       regex from description    https      regex to explanation    https      linux command    https      get time complexity    https      git command from description    https   database       text description to sql command    https   web       generate html from description    https      css from description    https      meta tags from description    https i think this could be helpful to a lot of people  especially for beginner programmers   you can check out all functionalities on your own here  programming helper com  https   have fun using the tool     ,https https programming function description https code explanation https fix invalid code https translate languages https class description https get language code https function docstring https helpers regex description https regex explanation https linux command https get time complexity https git command description https database text description sql command https web generate html description https css description https meta tags description https think could helpful lot people especially beginner programmers check functionalities programming helper com https fun using tool,p website generate code snippets regexes linux git sql commands html css written description furthermore translate code snippets many languages get regex explained plain english moreover fix broken code snippets help ml,p website generate code snippets regexes linux git sql commands html css written description furthermore translate code snippets many languages get regex explained plain english moreover fix broken code snippets help mlhttps https programming function description https code explanation https fix invalid code https translate languages https class description https get language code https function docstring https helpers regex description https regex explanation https linux command https get time complexity https git command description https database text description sql command https web generate html description https css description https meta tags description https think could helpful lot people especially beginner programmers check functionalities programming helper com https fun using tool,"['p', 'website', 'generate', 'code', 'snippets', 'regexes', 'linux', 'git', 'sql', 'commands', 'html', 'css', 'written', 'description', 'furthermore', 'translate', 'code', 'snippets', 'many', 'languages', 'get', 'regex', 'explained', 'plain', 'english', 'moreover', 'fix', 'broken', 'code', 'snippets', 'help', 'mlhttps', 'https', 'programming', 'function', 'description', 'https', 'code', 'explanation', 'https', 'fix', 'invalid', 'code', 'https', 'translate', 'languages', 'https', 'class', 'description', 'https', 'get', 'language', 'code', 'https', 'function', 'docstring', 'https', 'helpers', 'regex', 'description', 'https', 'regex', 'explanation', 'https', 'linux', 'command', 'https', 'get', 'time', 'complexity', 'https', 'git', 'command', 'description', 'https', 'database', 'text', 'description', 'sql', 'command', 'https', 'web', 'generate', 'html', 'description', 'https', 'css', 'description', 'https', 'meta', 'tags', 'description', 'https', 'think', 'could', 'helpful', 'lot', 'people', 'especially', 'beginner', 'programmers', 'check', 'functionalities', 'programming', 'helper', 'com', 'https', 'fun', 'using', 'tool']","['p', 'websit', 'gener', 'code', 'snippet', 'regex', 'linux', 'git', 'sql', 'command', 'html', 'css', 'written', 'descript', 'furthermor', 'translat', 'code', 'snippet', 'mani', 'languag', 'get', 'regex', 'explain', 'plain', 'english', 'moreov', 'fix', 'broken', 'code', 'snippet', 'help', 'mlhttp', 'http', 'program', 'function', 'descript', 'http', 'code', 'explan', 'http', 'fix', 'invalid', 'code', 'http', 'translat', 'languag', 'http', 'class', 'descript', 'http', 'get', 'languag', 'code', 'http', 'function', 'docstr', 'http', 'helper', 'regex', 'descript', 'http', 'regex', 'explan', 'http', 'linux', 'command', 'http', 'get', 'time', 'complex', 'http', 'git', 'command', 'descript', 'http', 'databas', 'text', 'descript', 'sql', 'command', 'http', 'web', 'gener', 'html', 'descript', 'http', 'css', 'descript', 'http', 'meta', 'tag', 'descript', 'http', 'think', 'could', 'help', 'lot', 'peopl', 'especi', 'beginn', 'programm', 'check', 'function', 'program', 'helper', 'com', 'http', 'fun', 'use', 'tool']"
59,64,64,ericyu3,vvvt52,[Project] Parakeet — Copilot for Colab,"Hello!

I've long been a big fan of [GitHub Copilot](https://github.com/features/copilot) — I've used it for a while now, and I find it super helpful for all sorts of things. But Copilot doesn't work in Colab or Jupyter notebooks, even though that's where a ton of ML and data science code is written.

**Parakeet** is a Chrome extension that provides Copilot-like code suggestions for notebooks.

I've been using Parakeet for my own needs for a bit, and I'm already getting a lot of mileage out of it. Just the other day, for example, I wanted to make a Seaborn plot but wasn't sure how. I wrote a short comment, Parakeet suggested some code, and the code worked on the first try!

# Installation

[**Install from the Chrome Web Store**](https://chrome.google.com/webstore/detail/parakeet/linkknplelcdbncponjdhcjdknlpgghc)

[View source code](https://github.com/uyhcire/parakeet)

You'll need an email to sign up.

Parakeet is currently **free to use** for everyone, though that may change once OpenAI introduces pricing for Codex.

# Demos

[Generating code to plot a sine wave.](https://i.redd.it/le5rzwb0ora91.gif)

[Plotting a heat map. All I had to do was write some comments — Parakeet's suggested code worked on the first try.](https://preview.redd.it/q1hl6uicpra91.png?width=1240&format=png&auto=webp&s=35e17142321dc9874aae82bc038f1828db4a3325)

# Limitations

Parakeet currently only works for Colab, though I'm considering extending Parakeet to support Jupyter. If you want to use Parakeet outside Colab, I'd love to hear about your use case! You can file an issue on GitHub or you can email me at [ericyu3@gmail.com](mailto:ericyu3@gmail.com).

To keep things simple, Parakeet only makes suggestions when you are at the end of a line, and Parakeet never makes multi-line suggestions.

# How it works

* Parakeet uses OpenAI's [Codex](https://openai.com/blog/openai-codex/) model, which is the same model that powers GitHub Copilot.
* Parakeet does not have access to Colab's internal state. Instead, Parakeet continuously parses Colab's HTML to extract cell contents and determine what row and column your cursor is on. This approach was finicky to get working, but I was able to get it to work reliably and with little performance penalty.
* Your code is never stored or logged. After a suggestion is generated, the input is immediately discarded.",7,23,2022-07-10 22:30:08, project  parakeet   copilot for colab,hello i ve long been a big fan of  github copilot  https   parakeet   is a chrome extension that provides copilot like code suggestions for notebooks i ve been using parakeet for my own needs for a bit  and i m already getting a lot of mileage out of it  just the other day  for example  i wanted to make a seaborn plot but wasn t sure how  i wrote a short comment  parakeet suggested some code  and the code worked on the first try   installation   install from the chrome web store    https  view source code  https you ll need an email to sign up parakeet is currently   free to use   for everyone  though that may change once openai introduces pricing for codex   demos generating code to plot a sine wave   https  plotting a heat map  all i had to do was write some comments   parakeet s suggested code worked on the first try   https   limitationsparakeet currently only works for colab  though i m considering extending parakeet to support jupyter  if you want to use parakeet outside colab  i d love to hear about your use case  you can file an issue on github or you can email me at  ericyu gmail com  mailto ericyu gmail com  to keep things simple  parakeet only makes suggestions when you are at the end of a line  and parakeet never makes multi line suggestions   how it works  parakeet uses openai s  codex  https   parakeet does not have access to colab s internal state  instead  parakeet continuously parses colab s html to extract cell contents and determine what row and column your cursor is on  this approach was finicky to get working  but i was able to get it to work reliably and with little performance penalty   your code is never stored or logged  after a suggestion is generated  the input is immediately discarded ,hello long big fan github copilot https parakeet chrome extension provides copilot like code suggestions notebooks using parakeet needs bit already getting lot mileage day example wanted make seaborn plot sure wrote short comment parakeet suggested code code worked first try installation install chrome web store https view source code https need email sign parakeet currently free use everyone though may change openai introduces pricing codex demos generating code plot sine wave https plotting heat map write comments parakeet suggested code worked first try https limitationsparakeet currently works colab though considering extending parakeet support jupyter want use parakeet outside colab love hear use case file issue github email ericyu gmail com mailto ericyu gmail com keep things simple parakeet makes suggestions end line parakeet never makes multi line suggestions works parakeet uses openai codex https parakeet access colab internal state instead parakeet continuously parses colab html extract cell contents determine row column cursor approach finicky get working able get work reliably little performance penalty code never stored logged suggestion generated input immediately discarded,project parakeet copilot colab,project parakeet copilot colabhello long big fan github copilot https parakeet chrome extension provides copilot like code suggestions notebooks using parakeet needs bit already getting lot mileage day example wanted make seaborn plot sure wrote short comment parakeet suggested code code worked first try installation install chrome web store https view source code https need email sign parakeet currently free use everyone though may change openai introduces pricing codex demos generating code plot sine wave https plotting heat map write comments parakeet suggested code worked first try https limitationsparakeet currently works colab though considering extending parakeet support jupyter want use parakeet outside colab love hear use case file issue github email ericyu gmail com mailto ericyu gmail com keep things simple parakeet makes suggestions end line parakeet never makes multi line suggestions works parakeet uses openai codex https parakeet access colab internal state instead parakeet continuously parses colab html extract cell contents determine row column cursor approach finicky get working able get work reliably little performance penalty code never stored logged suggestion generated input immediately discarded,"['project', 'parakeet', 'copilot', 'colabhello', 'long', 'big', 'fan', 'github', 'copilot', 'https', 'parakeet', 'chrome', 'extension', 'provides', 'copilot', 'like', 'code', 'suggestions', 'notebooks', 'using', 'parakeet', 'needs', 'bit', 'already', 'getting', 'lot', 'mileage', 'day', 'example', 'wanted', 'make', 'seaborn', 'plot', 'sure', 'wrote', 'short', 'comment', 'parakeet', 'suggested', 'code', 'code', 'worked', 'first', 'try', 'installation', 'install', 'chrome', 'web', 'store', 'https', 'view', 'source', 'code', 'https', 'need', 'email', 'sign', 'parakeet', 'currently', 'free', 'use', 'everyone', 'though', 'may', 'change', 'openai', 'introduces', 'pricing', 'codex', 'demos', 'generating', 'code', 'plot', 'sine', 'wave', 'https', 'plotting', 'heat', 'map', 'write', 'comments', 'parakeet', 'suggested', 'code', 'worked', 'first', 'try', 'https', 'limitationsparakeet', 'currently', 'works', 'colab', 'though', 'considering', 'extending', 'parakeet', 'support', 'jupyter', 'want', 'use', 'parakeet', 'outside', 'colab', 'love', 'hear', 'use', 'case', 'file', 'issue', 'github', 'email', 'ericyu', 'gmail', 'com', 'mailto', 'ericyu', 'gmail', 'com', 'keep', 'things', 'simple', 'parakeet', 'makes', 'suggestions', 'end', 'line', 'parakeet', 'never', 'makes', 'multi', 'line', 'suggestions', 'works', 'parakeet', 'uses', 'openai', 'codex', 'https', 'parakeet', 'access', 'colab', 'internal', 'state', 'instead', 'parakeet', 'continuously', 'parses', 'colab', 'html', 'extract', 'cell', 'contents', 'determine', 'row', 'column', 'cursor', 'approach', 'finicky', 'get', 'working', 'able', 'get', 'work', 'reliably', 'little', 'performance', 'penalty', 'code', 'never', 'stored', 'logged', 'suggestion', 'generated', 'input', 'immediately', 'discarded']","['project', 'parakeet', 'copilot', 'colabhello', 'long', 'big', 'fan', 'github', 'copilot', 'http', 'parakeet', 'chrome', 'extens', 'provid', 'copilot', 'like', 'code', 'suggest', 'notebook', 'use', 'parakeet', 'need', 'bit', 'alreadi', 'get', 'lot', 'mileag', 'day', 'exampl', 'want', 'make', 'seaborn', 'plot', 'sure', 'wrote', 'short', 'comment', 'parakeet', 'suggest', 'code', 'code', 'work', 'first', 'tri', 'instal', 'instal', 'chrome', 'web', 'store', 'http', 'view', 'sourc', 'code', 'http', 'need', 'email', 'sign', 'parakeet', 'current', 'free', 'use', 'everyon', 'though', 'may', 'chang', 'openai', 'introduc', 'price', 'codex', 'demo', 'gener', 'code', 'plot', 'sine', 'wave', 'http', 'plot', 'heat', 'map', 'write', 'comment', 'parakeet', 'suggest', 'code', 'work', 'first', 'tri', 'http', 'limitationsparakeet', 'current', 'work', 'colab', 'though', 'consid', 'extend', 'parakeet', 'support', 'jupyt', 'want', 'use', 'parakeet', 'outsid', 'colab', 'love', 'hear', 'use', 'case', 'file', 'issu', 'github', 'email', 'ericyu', 'gmail', 'com', 'mailto', 'ericyu', 'gmail', 'com', 'keep', 'thing', 'simpl', 'parakeet', 'make', 'suggest', 'end', 'line', 'parakeet', 'never', 'make', 'multi', 'line', 'suggest', 'work', 'parakeet', 'use', 'openai', 'codex', 'http', 'parakeet', 'access', 'colab', 'intern', 'state', 'instead', 'parakeet', 'continu', 'pars', 'colab', 'html', 'extract', 'cell', 'content', 'determin', 'row', 'column', 'cursor', 'approach', 'finicki', 'get', 'work', 'abl', 'get', 'work', 'reliabl', 'littl', 'perform', 'penalti', 'code', 'never', 'store', 'log', 'suggest', 'gener', 'input', 'immedi', 'discard']"
60,65,65,yosefschwartz,vvl47v,[D] What's the problem with Self-driving cars? Is it a lack of data or do we need a new technology breakthrough?,"I mean there was a time when everyone thought that in a few years we would have self-drive cars. We just need more data and computing and we'll get it.
But now Google has more than 20m miles on a public road and much more in simulations.
And Tesla has a lot of cars that collect data on the road.

But it's still not there so what is missing? Do we need a new technology breakthrough or it's just more data and computing power?",143,88,2022-07-10 11:41:48, d  what s the problem with self driving cars  is it a lack of data or do we need a new technology breakthrough ,i mean there was a time when everyone thought that in a few years we would have self drive cars  we just need more data and computing and we ll get it but now google has more than m miles on a public road and much more in simulations and tesla has a lot of cars that collect data on the road but it s still not there so what is missing  do we need a new technology breakthrough or it s just more data and computing power ,mean time everyone thought years would self drive cars need data computing get google miles public road much simulations tesla lot cars collect data road still missing need technology breakthrough data computing power,problem self driving cars lack data need technology breakthrough,problem self driving cars lack data need technology breakthroughmean time everyone thought years would self drive cars need data computing get google miles public road much simulations tesla lot cars collect data road still missing need technology breakthrough data computing power,"['problem', 'self', 'driving', 'cars', 'lack', 'data', 'need', 'technology', 'breakthroughmean', 'time', 'everyone', 'thought', 'years', 'would', 'self', 'drive', 'cars', 'need', 'data', 'computing', 'get', 'google', 'miles', 'public', 'road', 'much', 'simulations', 'tesla', 'lot', 'cars', 'collect', 'data', 'road', 'still', 'missing', 'need', 'technology', 'breakthrough', 'data', 'computing', 'power']","['problem', 'self', 'drive', 'car', 'lack', 'data', 'need', 'technolog', 'breakthroughmean', 'time', 'everyon', 'thought', 'year', 'would', 'self', 'drive', 'car', 'need', 'data', 'comput', 'get', 'googl', 'mile', 'public', 'road', 'much', 'simul', 'tesla', 'lot', 'car', 'collect', 'data', 'road', 'still', 'miss', 'need', 'technolog', 'breakthrough', 'data', 'comput', 'power']"
61,67,67,Sacrezar,vvubm7,[D] Any french Corpus like ALECTOR for simplification task?,"Hello, the title says it all. I'm trying to find any ressources (mainly aligned corpus) that could be helpful in identifying and simplifying complex sentences in French. [ALECTOR](https://aclanthology.org/2020.lrec-1.169/) is the only one I stumbled upon.

Do you have any resources or tips? I was wondering if searching for book and their simplified version could be useful but I fear it would be more like learning to translate old french into modern french.",0,7,2022-07-10 21:19:57, d  any french corpus like alector for simplification task ,hello  the title says it all  i m trying to find any ressources  mainly aligned corpus  that could be helpful in identifying and simplifying complex sentences in french   alector  https do you have any resources or tips  i was wondering if searching for book and their simplified version could be useful but i fear it would be more like learning to translate old french into modern french ,hello title says trying find ressources mainly aligned corpus could helpful identifying simplifying complex sentences french alector https resources tips wondering searching book simplified version could useful fear would like learning translate old french modern french,french corpus like alector simplification task,french corpus like alector simplification taskhello title says trying find ressources mainly aligned corpus could helpful identifying simplifying complex sentences french alector https resources tips wondering searching book simplified version could useful fear would like learning translate old french modern french,"['french', 'corpus', 'like', 'alector', 'simplification', 'taskhello', 'title', 'says', 'trying', 'find', 'ressources', 'mainly', 'aligned', 'corpus', 'could', 'helpful', 'identifying', 'simplifying', 'complex', 'sentences', 'french', 'alector', 'https', 'resources', 'tips', 'wondering', 'searching', 'book', 'simplified', 'version', 'could', 'useful', 'fear', 'would', 'like', 'learning', 'translate', 'old', 'french', 'modern', 'french']","['french', 'corpu', 'like', 'alector', 'simplif', 'taskhello', 'titl', 'say', 'tri', 'find', 'ressourc', 'mainli', 'align', 'corpu', 'could', 'help', 'identifi', 'simplifi', 'complex', 'sentenc', 'french', 'alector', 'http', 'resourc', 'tip', 'wonder', 'search', 'book', 'simplifi', 'version', 'could', 'use', 'fear', 'would', 'like', 'learn', 'translat', 'old', 'french', 'modern', 'french']"
62,69,69,DragonLord9,vuw77a,[N] First-Ever Course on Transformers: NOW PUBLIC,"**CS 25: Transformers United**

https://preview.redd.it/1st4o3tvtha91.png?width=350&format=png&auto=webp&s=e4416da38001692989304e980dd4d61d23a74398

Did you grow up wanting to play with robots that could turn into cars? While we can't offer those kinds of transformers, we do have a course on the class of deep learning models that have taken the world by storm.

Announcing the public release of our lectures from the first-ever course on **Transformers: CS25 Transformers United** ([http://cs25.stanford.edu](http://cs25.stanford.edu/)) held at [Stanford University](https://www.linkedin.com/school/stanford-university/).

Our intro video is out and available to watch here 👉: [***YouTube Link***](https://www.youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM&fbclid=IwAR2mJd868IzGp8ChykBBRTxq7RQh-KICfnAg8rLQ-qsekbhnUcd_z4-4E7g)

Bookmark and spread the word 🤗!

[(Twitter Thread)](https://twitter.com/DivGarg9/status/1545541542235975682?s=20&t=_Ed9dpjD9Qpx4svpMNDIKQ&fbclid=IwAR2tnSQROnkOQl15aa6nkfNFaJdrnZQHDbidooDaQRJALlWsYMiQU_37dn4)

Speaker talks out starting Monday ...",37,344,2022-07-09 12:47:02, n  first ever course on transformers  now public,  cs   transformers united  https did you grow up wanting to play with robots that could turn into cars  while we can t offer those kinds of transformers  we do have a course on the class of deep learning models that have taken the world by storm announcing the public release of our lectures from the first ever course on   transformers  cs transformers united     http our intro video is out and available to watch here        youtube link     https bookmark and spread the word     twitter thread   https speaker talks out starting monday    ,cs transformers united https grow wanting play robots could turn cars offer kinds transformers course class deep learning models taken world storm announcing public release lectures first ever course transformers cs transformers united http intro video available watch youtube link https bookmark spread word twitter thread https speaker talks starting monday,n first ever course transformers public,n first ever course transformers publiccs transformers united https grow wanting play robots could turn cars offer kinds transformers course class deep learning models taken world storm announcing public release lectures first ever course transformers cs transformers united http intro video available watch youtube link https bookmark spread word twitter thread https speaker talks starting monday,"['n', 'first', 'ever', 'course', 'transformers', 'publiccs', 'transformers', 'united', 'https', 'grow', 'wanting', 'play', 'robots', 'could', 'turn', 'cars', 'offer', 'kinds', 'transformers', 'course', 'class', 'deep', 'learning', 'models', 'taken', 'world', 'storm', 'announcing', 'public', 'release', 'lectures', 'first', 'ever', 'course', 'transformers', 'cs', 'transformers', 'united', 'http', 'intro', 'video', 'available', 'watch', 'youtube', 'link', 'https', 'bookmark', 'spread', 'word', 'twitter', 'thread', 'https', 'speaker', 'talks', 'starting', 'monday']","['n', 'first', 'ever', 'cours', 'transform', 'publicc', 'transform', 'unit', 'http', 'grow', 'want', 'play', 'robot', 'could', 'turn', 'car', 'offer', 'kind', 'transform', 'cours', 'class', 'deep', 'learn', 'model', 'taken', 'world', 'storm', 'announc', 'public', 'releas', 'lectur', 'first', 'ever', 'cours', 'transform', 'cs', 'transform', 'unit', 'http', 'intro', 'video', 'avail', 'watch', 'youtub', 'link', 'http', 'bookmark', 'spread', 'word', 'twitter', 'thread', 'http', 'speaker', 'talk', 'start', 'monday']"
63,70,70,Labib666Camp,vvms5n,[D] Interpreting Attention Weights,"I have seen in many papers, specially in Deep learning applications in medical imaging, that they interpret attention weights as something like interaction between features (ie. Feature Interaction). But, every time you train the model wouldn't you get new weights? Then, how does this interoperability holds any value if the weights keep changing everytime you run it?",5,3,2022-07-10 13:39:11, d  interpreting attention weights,i have seen in many papers  specially in deep learning applications in medical imaging  that they interpret attention weights as something like interaction between features  ie  feature interaction   but  every time you train the model wouldn t you get new weights  then  how does this interoperability holds any value if the weights keep changing everytime you run it ,seen many papers specially deep learning applications medical imaging interpret attention weights something like interaction features ie feature interaction every time train model get weights interoperability holds value weights keep changing everytime run,interpreting attention weights,interpreting attention weightsseen many papers specially deep learning applications medical imaging interpret attention weights something like interaction features ie feature interaction every time train model get weights interoperability holds value weights keep changing everytime run,"['interpreting', 'attention', 'weightsseen', 'many', 'papers', 'specially', 'deep', 'learning', 'applications', 'medical', 'imaging', 'interpret', 'attention', 'weights', 'something', 'like', 'interaction', 'features', 'ie', 'feature', 'interaction', 'every', 'time', 'train', 'model', 'get', 'weights', 'interoperability', 'holds', 'value', 'weights', 'keep', 'changing', 'everytime', 'run']","['interpret', 'attent', 'weightsseen', 'mani', 'paper', 'special', 'deep', 'learn', 'applic', 'medic', 'imag', 'interpret', 'attent', 'weight', 'someth', 'like', 'interact', 'featur', 'ie', 'featur', 'interact', 'everi', 'time', 'train', 'model', 'get', 'weight', 'interoper', 'hold', 'valu', 'weight', 'keep', 'chang', 'everytim', 'run']"
64,71,71,fromnighttilldawn,vuvslv,[D] When did tech companies start to publish ML papers and why?,"I never fully understood the need for tech companies to publish research papers at big conferences.

I think before the 2000s, tech companies were very secretive about their work. I mean, you wouldn't expect Microsoft to publish their latest research on their own motherboard at some conferences right?

Nowadays all of them are trying to advertise their latest tech in research papers that could possibly be replicated by anyone around the world. This is especially visible in ML.

Also it almost seems as if they don't have a goal in mind. A lot of the research papers (outside of those big models such as DALL-E) seem to be VERY random to me, hardly even related to their business interests.

How did it become this way and what is their motivation?",34,115,2022-07-09 12:19:50, d  when did tech companies start to publish ml papers and why ,i never fully understood the need for tech companies to publish research papers at big conferences i think before the s  tech companies were very secretive about their work  i mean  you wouldn t expect microsoft to publish their latest research on their own motherboard at some conferences right nowadays all of them are trying to advertise their latest tech in research papers that could possibly be replicated by anyone around the world  this is especially visible in ml also it almost seems as if they don t have a goal in mind  a lot of the research papers  outside of those big models such as dall e  seem to be very random to me  hardly even related to their business interests how did it become this way and what is their motivation ,never fully understood need tech companies publish research papers big conferences think tech companies secretive work mean expect microsoft publish latest research motherboard conferences right nowadays trying advertise latest tech research papers could possibly replicated anyone around world especially visible ml also almost seems goal mind lot research papers outside big models dall e seem random hardly even related business interests become way motivation,tech companies start publish ml papers,tech companies start publish ml papersnever fully understood need tech companies publish research papers big conferences think tech companies secretive work mean expect microsoft publish latest research motherboard conferences right nowadays trying advertise latest tech research papers could possibly replicated anyone around world especially visible ml also almost seems goal mind lot research papers outside big models dall e seem random hardly even related business interests become way motivation,"['tech', 'companies', 'start', 'publish', 'ml', 'papersnever', 'fully', 'understood', 'need', 'tech', 'companies', 'publish', 'research', 'papers', 'big', 'conferences', 'think', 'tech', 'companies', 'secretive', 'work', 'mean', 'expect', 'microsoft', 'publish', 'latest', 'research', 'motherboard', 'conferences', 'right', 'nowadays', 'trying', 'advertise', 'latest', 'tech', 'research', 'papers', 'could', 'possibly', 'replicated', 'anyone', 'around', 'world', 'especially', 'visible', 'ml', 'also', 'almost', 'seems', 'goal', 'mind', 'lot', 'research', 'papers', 'outside', 'big', 'models', 'dall', 'e', 'seem', 'random', 'hardly', 'even', 'related', 'business', 'interests', 'become', 'way', 'motivation']","['tech', 'compani', 'start', 'publish', 'ml', 'papersnev', 'fulli', 'understood', 'need', 'tech', 'compani', 'publish', 'research', 'paper', 'big', 'confer', 'think', 'tech', 'compani', 'secret', 'work', 'mean', 'expect', 'microsoft', 'publish', 'latest', 'research', 'motherboard', 'confer', 'right', 'nowaday', 'tri', 'advertis', 'latest', 'tech', 'research', 'paper', 'could', 'possibl', 'replic', 'anyon', 'around', 'world', 'especi', 'visibl', 'ml', 'also', 'almost', 'seem', 'goal', 'mind', 'lot', 'research', 'paper', 'outsid', 'big', 'model', 'dall', 'e', 'seem', 'random', 'hardli', 'even', 'relat', 'busi', 'interest', 'becom', 'way', 'motiv']"
65,72,72,SeucheAchat9115,vvs041,[D] Reimplementing an Object Detection Model.,How hard is it to reimplement an object detection model to reproduce the results on benchmarks like COCO. Lets take the DINO architecture or even some yolo v4-7 Model. How hard is it to build it from scratch to reach COCO results reported by the paper or official implementations?,5,0,2022-07-10 19:25:50, d  reimplementing an object detection model ,how hard is it to reimplement an object detection model to reproduce the results on benchmarks like coco  lets take the dino architecture or even some yolo v  model  how hard is it to build it from scratch to reach coco results reported by the paper or official implementations ,hard reimplement object detection model reproduce results benchmarks like coco lets take dino architecture even yolo v model hard build scratch reach coco results reported paper official implementations,reimplementing object detection model,reimplementing object detection modelhard reimplement object detection model reproduce results benchmarks like coco lets take dino architecture even yolo v model hard build scratch reach coco results reported paper official implementations,"['reimplementing', 'object', 'detection', 'modelhard', 'reimplement', 'object', 'detection', 'model', 'reproduce', 'results', 'benchmarks', 'like', 'coco', 'lets', 'take', 'dino', 'architecture', 'even', 'yolo', 'v', 'model', 'hard', 'build', 'scratch', 'reach', 'coco', 'results', 'reported', 'paper', 'official', 'implementations']","['reimplement', 'object', 'detect', 'modelhard', 'reimplement', 'object', 'detect', 'model', 'reproduc', 'result', 'benchmark', 'like', 'coco', 'let', 'take', 'dino', 'architectur', 'even', 'yolo', 'v', 'model', 'hard', 'build', 'scratch', 'reach', 'coco', 'result', 'report', 'paper', 'offici', 'implement']"
66,73,73,EnricoShippole,vv9kwp,[P] CaiT Implementation in Flax,"An open-source implementation of the Going deeper with Image Transformers research paper in Google's JAX and Flax.

""The paper also notes the difficulty in training vision transformers at greater depths and proposes two solutions. First, it proposes to do per-channel multiplication of the output of the residual block. Second, it proposes to have the patches attend to one another, and only allow the CLS token to attend to the patches in the last few layers."" - Lucid

Github repository for the Flax / JAX model: [https://github.com/conceptofmind/CaiT-Flax](https://github.com/conceptofmind/CaiT-Flax)

CaiT Research Paper: [https://arxiv.org/abs/2103.17239](https://arxiv.org/abs/2103.17239)

Official PyTorch repository: [https://github.com/rwightman/pytorch-image-models](https://github.com/rwightman/pytorch-image-models)

In collaboration with Lucid: [https://github.com/lucidrains](https://github.com/lucidrains)",0,11,2022-07-10 01:19:50, p  cait implementation in flax,an open source implementation of the going deeper with image transformers research paper in google s jax and flax the paper also notes the difficulty in training vision transformers at greater depths and proposes two solutions  first  it proposes to do per channel multiplication of the output of the residual block  second  it proposes to have the patches attend to one another  and only allow the cls token to attend to the patches in the last few layers    lucidgithub repository for the flax   jax model   https cait research paper   https official pytorch repository   https in collaboration with lucid   https   github com lucidrains  https   github com lucidrains ,open source implementation going deeper image transformers research paper google jax flax paper also notes difficulty training vision transformers greater depths proposes two solutions first proposes per channel multiplication output residual block second proposes patches attend one another allow cls token attend patches last layers lucidgithub repository flax jax model https cait research paper https official pytorch repository https collaboration lucid https github com lucidrains https github com lucidrains,p cait implementation flax,p cait implementation flaxopen source implementation going deeper image transformers research paper google jax flax paper also notes difficulty training vision transformers greater depths proposes two solutions first proposes per channel multiplication output residual block second proposes patches attend one another allow cls token attend patches last layers lucidgithub repository flax jax model https cait research paper https official pytorch repository https collaboration lucid https github com lucidrains https github com lucidrains,"['p', 'cait', 'implementation', 'flaxopen', 'source', 'implementation', 'going', 'deeper', 'image', 'transformers', 'research', 'paper', 'google', 'jax', 'flax', 'paper', 'also', 'notes', 'difficulty', 'training', 'vision', 'transformers', 'greater', 'depths', 'proposes', 'two', 'solutions', 'first', 'proposes', 'per', 'channel', 'multiplication', 'output', 'residual', 'block', 'second', 'proposes', 'patches', 'attend', 'one', 'another', 'allow', 'cls', 'token', 'attend', 'patches', 'last', 'layers', 'lucidgithub', 'repository', 'flax', 'jax', 'model', 'https', 'cait', 'research', 'paper', 'https', 'official', 'pytorch', 'repository', 'https', 'collaboration', 'lucid', 'https', 'github', 'com', 'lucidrains', 'https', 'github', 'com', 'lucidrains']","['p', 'cait', 'implement', 'flaxopen', 'sourc', 'implement', 'go', 'deeper', 'imag', 'transform', 'research', 'paper', 'googl', 'jax', 'flax', 'paper', 'also', 'note', 'difficulti', 'train', 'vision', 'transform', 'greater', 'depth', 'propos', 'two', 'solut', 'first', 'propos', 'per', 'channel', 'multipl', 'output', 'residu', 'block', 'second', 'propos', 'patch', 'attend', 'one', 'anoth', 'allow', 'cl', 'token', 'attend', 'patch', 'last', 'layer', 'lucidgithub', 'repositori', 'flax', 'jax', 'model', 'http', 'cait', 'research', 'paper', 'http', 'offici', 'pytorch', 'repositori', 'http', 'collabor', 'lucid', 'http', 'github', 'com', 'lucidrain', 'http', 'github', 'com', 'lucidrain']"
67,74,74,jacobgil,vv1pja,[P] May the best explanation win: A tutorial on benchmarking and tuning model explanations with pytorch-grad-cam,"The new release of the pytorch-grad-cam project focuses on metrics for the model explanations.

It's often exciting to see model explanations, and tempting to interpret them and get insights about what the model is doing. And a lot of times it is very useful.

However this has to be done with care - the model explanations can be wrong, or sub optimal. As shown in many papers, sometimes random explanations perform better.

So it's useful to have metrics that measure the quality of the explanations for an image, and sanity checks about them.

This can be used both for getting some trust in the explanation before using it,

but also for tuning the explanation and getting the best one for a given image (for example by checking different methods).

&#x200B;

This notebook gives a thorough overview of the different metrics used in the literature, issues with them, using sanity checks (like the Sobel Edge Detector, or a random CAM),

and most importantly shows how to use them to chose and tune the explanation in practice.

[https://github.com/jacobgil/pytorch-grad-cam/blob/master/tutorials/CAM%20Metrics%20And%20Tuning%20Tutorial.ipynb](https://github.com/jacobgil/pytorch-grad-cam/blob/master/tutorials/CAM%20Metrics%20And%20Tuning%20Tutorial.ipynb)

&#x200B;

The motivation here is to both make it easier for researchers to benchmark new algorithms, but also (maybe more importantly) when using the model explanations to tune them, get the most out of them, and find problems with them.",0,15,2022-07-09 18:57:24, p  may the best explanation win  a tutorial on benchmarking and tuning model explanations with pytorch grad cam,the new release of the pytorch grad cam project focuses on metrics for the model explanations it s often exciting to see model explanations  and tempting to interpret them and get insights about what the model is doing  and a lot of times it is very useful however this has to be done with care   the model explanations can be wrong  or sub optimal  as shown in many papers  sometimes random explanations perform better so it s useful to have metrics that measure the quality of the explanations for an image  and sanity checks about them this can be used both for getting some trust in the explanation before using it but also for tuning the explanation and getting the best one for a given image  for example by checking different methods    xb this notebook gives a thorough overview of the different metrics used in the literature  issues with them  using sanity checks  like the sobel edge detector  or a random cam  and most importantly shows how to use them to chose and tune the explanation in practice  https   xb the motivation here is to both make it easier for researchers to benchmark new algorithms  but also  maybe more importantly  when using the model explanations to tune them  get the most out of them  and find problems with them ,release pytorch grad cam project focuses metrics model explanations often exciting see model explanations tempting interpret get insights model lot times useful however done care model explanations wrong sub optimal shown many papers sometimes random explanations perform better useful metrics measure quality explanations image sanity checks used getting trust explanation using also tuning explanation getting best one given image example checking different methods xb notebook gives thorough overview different metrics used literature issues using sanity checks like sobel edge detector random cam importantly shows use chose tune explanation practice https xb motivation make easier researchers benchmark algorithms also maybe importantly using model explanations tune get find problems,p may best explanation win tutorial benchmarking tuning model explanations pytorch grad cam,p may best explanation win tutorial benchmarking tuning model explanations pytorch grad camrelease pytorch grad cam project focuses metrics model explanations often exciting see model explanations tempting interpret get insights model lot times useful however done care model explanations wrong sub optimal shown many papers sometimes random explanations perform better useful metrics measure quality explanations image sanity checks used getting trust explanation using also tuning explanation getting best one given image example checking different methods xb notebook gives thorough overview different metrics used literature issues using sanity checks like sobel edge detector random cam importantly shows use chose tune explanation practice https xb motivation make easier researchers benchmark algorithms also maybe importantly using model explanations tune get find problems,"['p', 'may', 'best', 'explanation', 'win', 'tutorial', 'benchmarking', 'tuning', 'model', 'explanations', 'pytorch', 'grad', 'camrelease', 'pytorch', 'grad', 'cam', 'project', 'focuses', 'metrics', 'model', 'explanations', 'often', 'exciting', 'see', 'model', 'explanations', 'tempting', 'interpret', 'get', 'insights', 'model', 'lot', 'times', 'useful', 'however', 'done', 'care', 'model', 'explanations', 'wrong', 'sub', 'optimal', 'shown', 'many', 'papers', 'sometimes', 'random', 'explanations', 'perform', 'better', 'useful', 'metrics', 'measure', 'quality', 'explanations', 'image', 'sanity', 'checks', 'used', 'getting', 'trust', 'explanation', 'using', 'also', 'tuning', 'explanation', 'getting', 'best', 'one', 'given', 'image', 'example', 'checking', 'different', 'methods', 'xb', 'notebook', 'gives', 'thorough', 'overview', 'different', 'metrics', 'used', 'literature', 'issues', 'using', 'sanity', 'checks', 'like', 'sobel', 'edge', 'detector', 'random', 'cam', 'importantly', 'shows', 'use', 'chose', 'tune', 'explanation', 'practice', 'https', 'xb', 'motivation', 'make', 'easier', 'researchers', 'benchmark', 'algorithms', 'also', 'maybe', 'importantly', 'using', 'model', 'explanations', 'tune', 'get', 'find', 'problems']","['p', 'may', 'best', 'explan', 'win', 'tutori', 'benchmark', 'tune', 'model', 'explan', 'pytorch', 'grad', 'camreleas', 'pytorch', 'grad', 'cam', 'project', 'focus', 'metric', 'model', 'explan', 'often', 'excit', 'see', 'model', 'explan', 'tempt', 'interpret', 'get', 'insight', 'model', 'lot', 'time', 'use', 'howev', 'done', 'care', 'model', 'explan', 'wrong', 'sub', 'optim', 'shown', 'mani', 'paper', 'sometim', 'random', 'explan', 'perform', 'better', 'use', 'metric', 'measur', 'qualiti', 'explan', 'imag', 'saniti', 'check', 'use', 'get', 'trust', 'explan', 'use', 'also', 'tune', 'explan', 'get', 'best', 'one', 'given', 'imag', 'exampl', 'check', 'differ', 'method', 'xb', 'notebook', 'give', 'thorough', 'overview', 'differ', 'metric', 'use', 'literatur', 'issu', 'use', 'saniti', 'check', 'like', 'sobel', 'edg', 'detector', 'random', 'cam', 'importantli', 'show', 'use', 'chose', 'tune', 'explan', 'practic', 'http', 'xb', 'motiv', 'make', 'easier', 'research', 'benchmark', 'algorithm', 'also', 'mayb', 'importantli', 'use', 'model', 'explan', 'tune', 'get', 'find', 'problem']"
68,75,75,DrSkoolie,vv3iu2,[R] How to use ML to predict time of life remaining on a physical asset of the input data has had all its failed samples scrubbed away?,"So I'm in a bit of a conundrum. I'm working on my PhD thesis regarding the management of physical assets (make a decision on whether to replace the asset or refurbish it or to leave it alone).

The first step to doing this is to predict the estimated time of life for each asset and I wish to use ML to do this. Each asset in my dataset has an installation date and a couple of input features (results of testing, characteristics of the asset, etc)

The problem is the dataset I have doesn't have any of the failed assets. Meaning that I am finding it very hard to set up an error term for the estimated time of life during training of the model.


Ideally, I should have failed samples and non-failed samples in my data but I only have the latter. How should I go about setting this up?

I've been trying for the past couple of months to get my hands on failed samples but I haven't had any luck.",11,4,2022-07-09 20:30:09, r  how to use ml to predict time of life remaining on a physical asset of the input data has had all its failed samples scrubbed away ,so i m in a bit of a conundrum  i m working on my phd thesis regarding the management of physical assets  make a decision on whether to replace the asset or refurbish it or to leave it alone  the first step to doing this is to predict the estimated time of life for each asset and i wish to use ml to do this  each asset in my dataset has an installation date and a couple of input features  results of testing  characteristics of the asset  etc the problem is the dataset i have doesn t have any of the failed assets  meaning that i am finding it very hard to set up an error term for the estimated time of life during training of the model ideally  i should have failed samples and non failed samples in my data but i only have the latter  how should i go about setting this up i ve been trying for the past couple of months to get my hands on failed samples but i haven t had any luck ,bit conundrum working phd thesis regarding management physical assets make decision whether replace asset refurbish leave alone first step predict estimated time life asset wish use ml asset dataset installation date couple input features results testing characteristics asset etc problem dataset failed assets meaning finding hard set error term estimated time life training model ideally failed samples non failed samples data latter go setting trying past couple months get hands failed samples luck,r use ml predict time life remaining physical asset input data failed samples scrubbed away,r use ml predict time life remaining physical asset input data failed samples scrubbed awaybit conundrum working phd thesis regarding management physical assets make decision whether replace asset refurbish leave alone first step predict estimated time life asset wish use ml asset dataset installation date couple input features results testing characteristics asset etc problem dataset failed assets meaning finding hard set error term estimated time life training model ideally failed samples non failed samples data latter go setting trying past couple months get hands failed samples luck,"['r', 'use', 'ml', 'predict', 'time', 'life', 'remaining', 'physical', 'asset', 'input', 'data', 'failed', 'samples', 'scrubbed', 'awaybit', 'conundrum', 'working', 'phd', 'thesis', 'regarding', 'management', 'physical', 'assets', 'make', 'decision', 'whether', 'replace', 'asset', 'refurbish', 'leave', 'alone', 'first', 'step', 'predict', 'estimated', 'time', 'life', 'asset', 'wish', 'use', 'ml', 'asset', 'dataset', 'installation', 'date', 'couple', 'input', 'features', 'results', 'testing', 'characteristics', 'asset', 'etc', 'problem', 'dataset', 'failed', 'assets', 'meaning', 'finding', 'hard', 'set', 'error', 'term', 'estimated', 'time', 'life', 'training', 'model', 'ideally', 'failed', 'samples', 'non', 'failed', 'samples', 'data', 'latter', 'go', 'setting', 'trying', 'past', 'couple', 'months', 'get', 'hands', 'failed', 'samples', 'luck']","['r', 'use', 'ml', 'predict', 'time', 'life', 'remain', 'physic', 'asset', 'input', 'data', 'fail', 'sampl', 'scrub', 'awaybit', 'conundrum', 'work', 'phd', 'thesi', 'regard', 'manag', 'physic', 'asset', 'make', 'decis', 'whether', 'replac', 'asset', 'refurbish', 'leav', 'alon', 'first', 'step', 'predict', 'estim', 'time', 'life', 'asset', 'wish', 'use', 'ml', 'asset', 'dataset', 'instal', 'date', 'coupl', 'input', 'featur', 'result', 'test', 'characterist', 'asset', 'etc', 'problem', 'dataset', 'fail', 'asset', 'mean', 'find', 'hard', 'set', 'error', 'term', 'estim', 'time', 'life', 'train', 'model', 'ideal', 'fail', 'sampl', 'non', 'fail', 'sampl', 'data', 'latter', 'go', 'set', 'tri', 'past', 'coupl', 'month', 'get', 'hand', 'fail', 'sampl', 'luck']"
69,77,77,Singularian2501,vueqv8,[R] DeepSpeed Inference: Enabling Efficient Inference of Transformer Models at Unprecedented Scale - Microsoft 2022,"Paper: [https://arxiv.org/pdf/2207.00032.pdf](https://arxiv.org/pdf/2207.00032.pdf)

Abstract:

>The past several years have witnessed the success of transformer-based models, and their scale and application scenarios continue to grow aggressively. The current landscape of transformer models is increasingly diverse: the model size varies drastically with the largest being of hundred-billion parameters; the model characteristics differ due to the sparsity introduced by the Mixture-of-Experts; the target application scenarios can be latency-critical or throughput-oriented; the deployment hardware could be single- or multi-GPU systems with different types of memory and storage, etc. With such increasing diversity and the fast-evolving pace of transformer models, designing a highly performant and efficient inference system is extremely challenging. In this paper, we present DeepSpeed Inference, a comprehensive system solution for transformer model inference to address the above-mentioned challenges. DeepSpeed Inference consists of (1) a multi-GPU inference solution to minimize latency while maximizing the throughput of both dense and sparse transformer models when they fit in aggregate GPU memory, and (2) a heterogeneous inference solution that leverages CPU and NVMe memory in addition to the GPU memory and compute to enable high inference throughput with large models which do not fit in aggregate GPU memory. **DeepSpeed Inference reduces latency by up to 7.3X over the state-of-the-art for latency-oriented scenarios and increases throughput by over 1.5x for throughput-oriented scenarios. Moreover, it enables trillion parameter scale inference under real-time latency constraints by leveraging hundreds of GPUs, an unprecedented scale for inference. It can inference 25x larger models than with GPU-only solutions, while delivering a high throughput of 84 TFLOPS (over 50% of A6000 peak).**       

https://preview.redd.it/a7a9ir42dda91.jpg?width=1440&format=pjpg&auto=webp&s=fd1aa3ac66117f0c8a3355553de61d8cb50fdb5e

https://preview.redd.it/am49dqo2dda91.jpg?width=1446&format=pjpg&auto=webp&s=ad5dc1c17301b6f006a1678e4afc8fca83c7bdd4

https://preview.redd.it/vyxod3jmdda91.jpg?width=694&format=pjpg&auto=webp&s=9397aa3727d36780d90e7c833e6c9d6dd0d848d0

https://preview.redd.it/x3tc9sumdda91.jpg?width=695&format=pjpg&auto=webp&s=703ef19715deac0b0d96cfc761e9e05e20e8e1a5

https://preview.redd.it/062lnm7ndda91.jpg?width=634&format=pjpg&auto=webp&s=71746178333a6e356cc8ff0392ca9cb5472f2862",4,119,2022-07-08 22:00:27, r  deepspeed inference  enabling efficient inference of transformer models at unprecedented scale   microsoft ,paper   https abstract  the past several years have witnessed the success of transformer based models  and their scale and application scenarios continue to grow aggressively  the current landscape of transformer models is increasingly diverse  the model size varies drastically with the largest being of hundred billion parameters  the model characteristics differ due to the sparsity introduced by the mixture of experts  the target application scenarios can be latency critical or throughput oriented  the deployment hardware could be single  or multi gpu systems with different types of memory and storage  etc  with such increasing diversity and the fast evolving pace of transformer models  designing a highly performant and efficient inference system is extremely challenging  in this paper  we present deepspeed inference  a comprehensive system solution for transformer model inference to address the above mentioned challenges  deepspeed inference consists of    a multi gpu inference solution to minimize latency while maximizing the throughput of both dense and sparse transformer models when they fit in aggregate gpu memory  and    a heterogeneous inference solution that leverages cpu and nvme memory in addition to the gpu memory and compute to enable high inference throughput with large models which do not fit in aggregate gpu memory    deepspeed inference reduces latency by up to  x over the state of the art for latency oriented scenarios and increases throughput by over  x for throughput oriented scenarios  moreover  it enables trillion parameter scale inference under real time latency constraints by leveraging hundreds of gpus  an unprecedented scale for inference  it can inference x larger models than with gpu only solutions  while delivering a high throughput of  tflops  over   of a peak           https https https https https   preview redd it lnmndda jpg width  format pjpg auto webp s aeccffcacbf,paper https abstract past several years witnessed success transformer based models scale application scenarios continue grow aggressively current landscape transformer models increasingly diverse model size varies drastically largest hundred billion parameters model characteristics differ due sparsity introduced mixture experts target application scenarios latency critical throughput oriented deployment hardware could single multi gpu systems different types memory storage etc increasing diversity fast evolving pace transformer models designing highly performant efficient inference system extremely challenging paper present deepspeed inference comprehensive system solution transformer model inference address mentioned challenges deepspeed inference consists multi gpu inference solution minimize latency maximizing throughput dense sparse transformer models fit aggregate gpu memory heterogeneous inference solution leverages cpu nvme memory addition gpu memory compute enable high inference throughput large models fit aggregate gpu memory deepspeed inference reduces latency x state art latency oriented scenarios increases throughput x throughput oriented scenarios moreover enables trillion parameter scale inference real time latency constraints leveraging hundreds gpus unprecedented scale inference inference x larger models gpu solutions delivering high throughput tflops peak https https https https https preview redd lnmndda jpg width format pjpg auto webp aeccffcacbf,r deepspeed inference enabling efficient inference transformer models unprecedented scale microsoft,r deepspeed inference enabling efficient inference transformer models unprecedented scale microsoftpaper https abstract past several years witnessed success transformer based models scale application scenarios continue grow aggressively current landscape transformer models increasingly diverse model size varies drastically largest hundred billion parameters model characteristics differ due sparsity introduced mixture experts target application scenarios latency critical throughput oriented deployment hardware could single multi gpu systems different types memory storage etc increasing diversity fast evolving pace transformer models designing highly performant efficient inference system extremely challenging paper present deepspeed inference comprehensive system solution transformer model inference address mentioned challenges deepspeed inference consists multi gpu inference solution minimize latency maximizing throughput dense sparse transformer models fit aggregate gpu memory heterogeneous inference solution leverages cpu nvme memory addition gpu memory compute enable high inference throughput large models fit aggregate gpu memory deepspeed inference reduces latency x state art latency oriented scenarios increases throughput x throughput oriented scenarios moreover enables trillion parameter scale inference real time latency constraints leveraging hundreds gpus unprecedented scale inference inference x larger models gpu solutions delivering high throughput tflops peak https https https https https preview redd lnmndda jpg width format pjpg auto webp aeccffcacbf,"['r', 'deepspeed', 'inference', 'enabling', 'efficient', 'inference', 'transformer', 'models', 'unprecedented', 'scale', 'microsoftpaper', 'https', 'abstract', 'past', 'several', 'years', 'witnessed', 'success', 'transformer', 'based', 'models', 'scale', 'application', 'scenarios', 'continue', 'grow', 'aggressively', 'current', 'landscape', 'transformer', 'models', 'increasingly', 'diverse', 'model', 'size', 'varies', 'drastically', 'largest', 'hundred', 'billion', 'parameters', 'model', 'characteristics', 'differ', 'due', 'sparsity', 'introduced', 'mixture', 'experts', 'target', 'application', 'scenarios', 'latency', 'critical', 'throughput', 'oriented', 'deployment', 'hardware', 'could', 'single', 'multi', 'gpu', 'systems', 'different', 'types', 'memory', 'storage', 'etc', 'increasing', 'diversity', 'fast', 'evolving', 'pace', 'transformer', 'models', 'designing', 'highly', 'performant', 'efficient', 'inference', 'system', 'extremely', 'challenging', 'paper', 'present', 'deepspeed', 'inference', 'comprehensive', 'system', 'solution', 'transformer', 'model', 'inference', 'address', 'mentioned', 'challenges', 'deepspeed', 'inference', 'consists', 'multi', 'gpu', 'inference', 'solution', 'minimize', 'latency', 'maximizing', 'throughput', 'dense', 'sparse', 'transformer', 'models', 'fit', 'aggregate', 'gpu', 'memory', 'heterogeneous', 'inference', 'solution', 'leverages', 'cpu', 'nvme', 'memory', 'addition', 'gpu', 'memory', 'compute', 'enable', 'high', 'inference', 'throughput', 'large', 'models', 'fit', 'aggregate', 'gpu', 'memory', 'deepspeed', 'inference', 'reduces', 'latency', 'x', 'state', 'art', 'latency', 'oriented', 'scenarios', 'increases', 'throughput', 'x', 'throughput', 'oriented', 'scenarios', 'moreover', 'enables', 'trillion', 'parameter', 'scale', 'inference', 'real', 'time', 'latency', 'constraints', 'leveraging', 'hundreds', 'gpus', 'unprecedented', 'scale', 'inference', 'inference', 'x', 'larger', 'models', 'gpu', 'solutions', 'delivering', 'high', 'throughput', 'tflops', 'peak', 'https', 'https', 'https', 'https', 'https', 'preview', 'redd', 'lnmndda', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'aeccffcacbf']","['r', 'deepspe', 'infer', 'enabl', 'effici', 'infer', 'transform', 'model', 'unpreced', 'scale', 'microsoftpap', 'http', 'abstract', 'past', 'sever', 'year', 'wit', 'success', 'transform', 'base', 'model', 'scale', 'applic', 'scenario', 'continu', 'grow', 'aggress', 'current', 'landscap', 'transform', 'model', 'increasingli', 'divers', 'model', 'size', 'vari', 'drastic', 'largest', 'hundr', 'billion', 'paramet', 'model', 'characterist', 'differ', 'due', 'sparsiti', 'introduc', 'mixtur', 'expert', 'target', 'applic', 'scenario', 'latenc', 'critic', 'throughput', 'orient', 'deploy', 'hardwar', 'could', 'singl', 'multi', 'gpu', 'system', 'differ', 'type', 'memori', 'storag', 'etc', 'increas', 'divers', 'fast', 'evolv', 'pace', 'transform', 'model', 'design', 'highli', 'perform', 'effici', 'infer', 'system', 'extrem', 'challeng', 'paper', 'present', 'deepspe', 'infer', 'comprehens', 'system', 'solut', 'transform', 'model', 'infer', 'address', 'mention', 'challeng', 'deepspe', 'infer', 'consist', 'multi', 'gpu', 'infer', 'solut', 'minim', 'latenc', 'maxim', 'throughput', 'dens', 'spars', 'transform', 'model', 'fit', 'aggreg', 'gpu', 'memori', 'heterogen', 'infer', 'solut', 'leverag', 'cpu', 'nvme', 'memori', 'addit', 'gpu', 'memori', 'comput', 'enabl', 'high', 'infer', 'throughput', 'larg', 'model', 'fit', 'aggreg', 'gpu', 'memori', 'deepspe', 'infer', 'reduc', 'latenc', 'x', 'state', 'art', 'latenc', 'orient', 'scenario', 'increas', 'throughput', 'x', 'throughput', 'orient', 'scenario', 'moreov', 'enabl', 'trillion', 'paramet', 'scale', 'infer', 'real', 'time', 'latenc', 'constraint', 'leverag', 'hundr', 'gpu', 'unpreced', 'scale', 'infer', 'infer', 'x', 'larger', 'model', 'gpu', 'solut', 'deliv', 'high', 'throughput', 'tflop', 'peak', 'http', 'http', 'http', 'http', 'http', 'preview', 'redd', 'lnmndda', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'aeccffcacbf']"
70,78,78,zxkj,vumtus,[D] How to evaluate a neural network in reverse?,"Say you have a neural network with 3 inputs, some hidden layers, and a single output.

There might be many sets of those 3 inputs that give you the same output value.

How can you evaluate this network in reverse, i.e. given an output value, find values of the 3 inputs that would yield that output?",36,36,2022-07-09 04:06:40, d  how to evaluate a neural network in reverse ,say you have a neural network with  inputs  some hidden layers  and a single output there might be many sets of those  inputs that give you the same output value how can you evaluate this network in reverse  i e  given an output value  find values of the  inputs that would yield that output ,say neural network inputs hidden layers single output might many sets inputs give output value evaluate network reverse e given output value find values inputs would yield output,evaluate neural network reverse,evaluate neural network reversesay neural network inputs hidden layers single output might many sets inputs give output value evaluate network reverse e given output value find values inputs would yield output,"['evaluate', 'neural', 'network', 'reversesay', 'neural', 'network', 'inputs', 'hidden', 'layers', 'single', 'output', 'might', 'many', 'sets', 'inputs', 'give', 'output', 'value', 'evaluate', 'network', 'reverse', 'e', 'given', 'output', 'value', 'find', 'values', 'inputs', 'would', 'yield', 'output']","['evalu', 'neural', 'network', 'reversesay', 'neural', 'network', 'input', 'hidden', 'layer', 'singl', 'output', 'might', 'mani', 'set', 'input', 'give', 'output', 'valu', 'evalu', 'network', 'revers', 'e', 'given', 'output', 'valu', 'find', 'valu', 'input', 'would', 'yield', 'output']"
71,79,79,highergraphic,vu4r1g,[P] Sioyek 1.4 | Academic PDF Viewer,"During my PhD, I developed an open source PDF viewer to help me with my research. I think it can be useful for the users of this sub. Some of the research-oriented features include:

* Quickly jump to or preview references (for example `Figure 3.1` for a figure or `[8]` for a reference). Works even if the document doesn't have links.
* Search paper names in google scholar by middle clicking on them (combined with the previous feature makes finding papers super fast)
* Searchable highlights/bookmarks
* Line-by-line highlighting for reduced eye strain ([video](https://user-images.githubusercontent.com/6392321/168427739-007be805-a457-4d1f-ba14-35c5070aae5f.mp4))
* Synctex Support
* Extensible using external scripts (see [this post](https://ahrm.github.io/jekyll/update/2022/07/05/implementing-a-screen-reader-for-sioyek.html) for some examples)
* And many other features which are explained in the github page including marks, history, portals, searchable table of contents, automatic table of contents generation, searchable previous documents, etc.

Here is a video demo of some of the features: https://www.youtube.com/watch?v=yTmCI0Xp5vI&t=3s

And here is the latest release:
https://github.com/ahrm/sioyek/releases/tag/v1.4.0

Disclaimer: I did introduce sioyek in this subreddit about a year ago, but it has changed a lot since then and some of the features suggested in the comments of last year's post are implemented, so I thought users of this subreddit might be interested in an update.",16,253,2022-07-08 12:41:27, p  sioyek     academic pdf viewer,during my phd  i developed an open source pdf viewer to help me with my research  i think it can be useful for the users of this sub  some of the research oriented features include   quickly jump to or preview references  for example  figure    for a figure or      for a reference   works even if the document doesn t have links   search paper names in google scholar by middle clicking on them  combined with the previous feature makes finding papers super fast   searchable highlights bookmarks  line by line highlighting for reduced eye strain   video  https   synctex support  extensible using external scripts  see  this post  https   and many other features which are explained in the github page including marks  history  portals  searchable table of contents  automatic table of contents generation  searchable previous documents  etc here is a video demo of some of the features  https and here is the latest release https disclaimer  i did introduce sioyek in this subreddit about a year ago  but it has changed a lot since then and some of the features suggested in the comments of last year s post are implemented  so i thought users of this subreddit might be interested in an update ,phd developed open source pdf viewer help research think useful users sub research oriented features include quickly jump preview references example figure figure reference works even document links search paper names google scholar middle clicking combined previous feature makes finding papers super fast searchable highlights bookmarks line line highlighting reduced eye strain video https synctex support extensible using external scripts see post https many features explained github page including marks history portals searchable table contents automatic table contents generation searchable previous documents etc video demo features https latest release https disclaimer introduce sioyek subreddit year ago changed lot since features suggested comments last year post implemented thought users subreddit might interested update,p sioyek academic pdf viewer,p sioyek academic pdf viewerphd developed open source pdf viewer help research think useful users sub research oriented features include quickly jump preview references example figure figure reference works even document links search paper names google scholar middle clicking combined previous feature makes finding papers super fast searchable highlights bookmarks line line highlighting reduced eye strain video https synctex support extensible using external scripts see post https many features explained github page including marks history portals searchable table contents automatic table contents generation searchable previous documents etc video demo features https latest release https disclaimer introduce sioyek subreddit year ago changed lot since features suggested comments last year post implemented thought users subreddit might interested update,"['p', 'sioyek', 'academic', 'pdf', 'viewerphd', 'developed', 'open', 'source', 'pdf', 'viewer', 'help', 'research', 'think', 'useful', 'users', 'sub', 'research', 'oriented', 'features', 'include', 'quickly', 'jump', 'preview', 'references', 'example', 'figure', 'figure', 'reference', 'works', 'even', 'document', 'links', 'search', 'paper', 'names', 'google', 'scholar', 'middle', 'clicking', 'combined', 'previous', 'feature', 'makes', 'finding', 'papers', 'super', 'fast', 'searchable', 'highlights', 'bookmarks', 'line', 'line', 'highlighting', 'reduced', 'eye', 'strain', 'video', 'https', 'synctex', 'support', 'extensible', 'using', 'external', 'scripts', 'see', 'post', 'https', 'many', 'features', 'explained', 'github', 'page', 'including', 'marks', 'history', 'portals', 'searchable', 'table', 'contents', 'automatic', 'table', 'contents', 'generation', 'searchable', 'previous', 'documents', 'etc', 'video', 'demo', 'features', 'https', 'latest', 'release', 'https', 'disclaimer', 'introduce', 'sioyek', 'subreddit', 'year', 'ago', 'changed', 'lot', 'since', 'features', 'suggested', 'comments', 'last', 'year', 'post', 'implemented', 'thought', 'users', 'subreddit', 'might', 'interested', 'update']","['p', 'sioyek', 'academ', 'pdf', 'viewerphd', 'develop', 'open', 'sourc', 'pdf', 'viewer', 'help', 'research', 'think', 'use', 'user', 'sub', 'research', 'orient', 'featur', 'includ', 'quickli', 'jump', 'preview', 'refer', 'exampl', 'figur', 'figur', 'refer', 'work', 'even', 'document', 'link', 'search', 'paper', 'name', 'googl', 'scholar', 'middl', 'click', 'combin', 'previou', 'featur', 'make', 'find', 'paper', 'super', 'fast', 'searchabl', 'highlight', 'bookmark', 'line', 'line', 'highlight', 'reduc', 'eye', 'strain', 'video', 'http', 'synctex', 'support', 'extens', 'use', 'extern', 'script', 'see', 'post', 'http', 'mani', 'featur', 'explain', 'github', 'page', 'includ', 'mark', 'histori', 'portal', 'searchabl', 'tabl', 'content', 'automat', 'tabl', 'content', 'gener', 'searchabl', 'previou', 'document', 'etc', 'video', 'demo', 'featur', 'http', 'latest', 'releas', 'http', 'disclaim', 'introduc', 'sioyek', 'subreddit', 'year', 'ago', 'chang', 'lot', 'sinc', 'featur', 'suggest', 'comment', 'last', 'year', 'post', 'implement', 'thought', 'user', 'subreddit', 'might', 'interest', 'updat']"
72,80,80,RohitDulam,vulpil,[R] Single-task Continual/Incremental/Online/Life-Long learning.," 

Hi everyone,

I am new to the domain of continual learning/incremental learning/online learning/life-long learning (honestly, not able to make out the difference between them) and I would like to know if there exists a single-task life-long learning domain/problem. All the papers that I have gone through consist of methods trained for multiple tasks where newer tasks are added over time. I am looking for models trained for a single task that can be updated over time with new data belonging to the same task. I already have a trained model that I would like to update over time with either single or multiple data points. Any related links or directions would be greatly appreciated. TIA.",2,3,2022-07-09 03:15:38, r  single task continual incremental online life long learning , hi everyone i am new to the domain of continual learning incremental learning online learning life long learning  honestly  not able to make out the difference between them  and i would like to know if there exists a single task life long learning domain problem  all the papers that i have gone through consist of methods trained for multiple tasks where newer tasks are added over time  i am looking for models trained for a single task that can be updated over time with new data belonging to the same task  i already have a trained model that i would like to update over time with either single or multiple data points  any related links or directions would be greatly appreciated  tia ,hi everyone domain continual learning incremental learning online learning life long learning honestly able make difference would like know exists single task life long learning domain problem papers gone consist methods trained multiple tasks newer tasks added time looking models trained single task updated time data belonging task already trained model would like update time either single multiple data points related links directions would greatly appreciated tia,r single task continual incremental online life long learning,r single task continual incremental online life long learninghi everyone domain continual learning incremental learning online learning life long learning honestly able make difference would like know exists single task life long learning domain problem papers gone consist methods trained multiple tasks newer tasks added time looking models trained single task updated time data belonging task already trained model would like update time either single multiple data points related links directions would greatly appreciated tia,"['r', 'single', 'task', 'continual', 'incremental', 'online', 'life', 'long', 'learninghi', 'everyone', 'domain', 'continual', 'learning', 'incremental', 'learning', 'online', 'learning', 'life', 'long', 'learning', 'honestly', 'able', 'make', 'difference', 'would', 'like', 'know', 'exists', 'single', 'task', 'life', 'long', 'learning', 'domain', 'problem', 'papers', 'gone', 'consist', 'methods', 'trained', 'multiple', 'tasks', 'newer', 'tasks', 'added', 'time', 'looking', 'models', 'trained', 'single', 'task', 'updated', 'time', 'data', 'belonging', 'task', 'already', 'trained', 'model', 'would', 'like', 'update', 'time', 'either', 'single', 'multiple', 'data', 'points', 'related', 'links', 'directions', 'would', 'greatly', 'appreciated', 'tia']","['r', 'singl', 'task', 'continu', 'increment', 'onlin', 'life', 'long', 'learninghi', 'everyon', 'domain', 'continu', 'learn', 'increment', 'learn', 'onlin', 'learn', 'life', 'long', 'learn', 'honestli', 'abl', 'make', 'differ', 'would', 'like', 'know', 'exist', 'singl', 'task', 'life', 'long', 'learn', 'domain', 'problem', 'paper', 'gone', 'consist', 'method', 'train', 'multipl', 'task', 'newer', 'task', 'ad', 'time', 'look', 'model', 'train', 'singl', 'task', 'updat', 'time', 'data', 'belong', 'task', 'alreadi', 'train', 'model', 'would', 'like', 'updat', 'time', 'either', 'singl', 'multipl', 'data', 'point', 'relat', 'link', 'direct', 'would', 'greatli', 'appreci', 'tia']"
73,81,81,MidnightMaverick,vu975k,[Discussion] Giving a machine learning presentation to laypeople,"Hello all,

I've been asked to deliver a machine learning presentation to cardiologists and doctors, obviously they have no prior expertise in this area. I had wondered if anyone else had some experience presenting to Laypeople in the context of machine learning.

Just looking for some ideas really, what would you cover? What examples would you give? How would you structure it?

Any help is always appreciated !

[Edit#1] Thank you for the help everyone, this is some really useful feedback that I will take on bosrd",15,22,2022-07-08 17:35:11, discussion  giving a machine learning presentation to laypeople,hello all i ve been asked to deliver a machine learning presentation to cardiologists and doctors  obviously they have no prior expertise in this area  i had wondered if anyone else had some experience presenting to laypeople in the context of machine learning just looking for some ideas really  what would you cover  what examples would you give  how would you structure it any help is always appreciated   edit   thank you for the help everyone  this is some really useful feedback that i will take on bosrd,hello asked deliver machine learning presentation cardiologists doctors obviously prior expertise area wondered anyone else experience presenting laypeople context machine learning looking ideas really would cover examples would give would structure help always appreciated edit thank help everyone really useful feedback take bosrd,discussion giving machine learning presentation laypeople,discussion giving machine learning presentation laypeoplehello asked deliver machine learning presentation cardiologists doctors obviously prior expertise area wondered anyone else experience presenting laypeople context machine learning looking ideas really would cover examples would give would structure help always appreciated edit thank help everyone really useful feedback take bosrd,"['discussion', 'giving', 'machine', 'learning', 'presentation', 'laypeoplehello', 'asked', 'deliver', 'machine', 'learning', 'presentation', 'cardiologists', 'doctors', 'obviously', 'prior', 'expertise', 'area', 'wondered', 'anyone', 'else', 'experience', 'presenting', 'laypeople', 'context', 'machine', 'learning', 'looking', 'ideas', 'really', 'would', 'cover', 'examples', 'would', 'give', 'would', 'structure', 'help', 'always', 'appreciated', 'edit', 'thank', 'help', 'everyone', 'really', 'useful', 'feedback', 'take', 'bosrd']","['discuss', 'give', 'machin', 'learn', 'present', 'laypeoplehello', 'ask', 'deliv', 'machin', 'learn', 'present', 'cardiologist', 'doctor', 'obvious', 'prior', 'expertis', 'area', 'wonder', 'anyon', 'els', 'experi', 'present', 'laypeopl', 'context', 'machin', 'learn', 'look', 'idea', 'realli', 'would', 'cover', 'exampl', 'would', 'give', 'would', 'structur', 'help', 'alway', 'appreci', 'edit', 'thank', 'help', 'everyon', 'realli', 'use', 'feedback', 'take', 'bosrd']"
74,82,82,QadriShyaari,vuh3z4,[P] Chart and Data Summarization,"I made an app that summarizes the data in csv files. Input a csv file and title of the file and the model will generate a summary.

[https://huggingface.co/spaces/saadob12/Chart\_Data\_Summarization](https://huggingface.co/spaces/saadob12/Chart_Data_Summarization)

The models: [https://huggingface.co/saadob12/t5\_C2T\_autochart](https://huggingface.co/saadob12/t5_C2T_autochart) and [https://huggingface.co/saadob12/t5\_C2T\_big](https://huggingface.co/saadob12/t5_C2T_big).",0,3,2022-07-08 23:45:48, p  chart and data summarization,i made an app that summarizes the data in csv files  input a csv file and title of the file and the model will generate a summary  https the models   https   huggingface co saadob t _ct _autochart  https   huggingface co saadob t_ct_autochart  and  https   huggingface co saadob t _ct _big  https   huggingface co saadob t_ct_big  ,made app summarizes data csv files input csv file title file model generate summary https models https huggingface co saadob _ct _autochart https huggingface co saadob t_ct_autochart https huggingface co saadob _ct _big https huggingface co saadob t_ct_big,p chart data summarization,p chart data summarizationmade app summarizes data csv files input csv file title file model generate summary https models https huggingface co saadob _ct _autochart https huggingface co saadob t_ct_autochart https huggingface co saadob _ct _big https huggingface co saadob t_ct_big,"['p', 'chart', 'data', 'summarizationmade', 'app', 'summarizes', 'data', 'csv', 'files', 'input', 'csv', 'file', 'title', 'file', 'model', 'generate', 'summary', 'https', 'models', 'https', 'huggingface', 'co', 'saadob', '_ct', '_autochart', 'https', 'huggingface', 'co', 'saadob', 't_ct_autochart', 'https', 'huggingface', 'co', 'saadob', '_ct', '_big', 'https', 'huggingface', 'co', 'saadob', 't_ct_big']","['p', 'chart', 'data', 'summarizationmad', 'app', 'summar', 'data', 'csv', 'file', 'input', 'csv', 'file', 'titl', 'file', 'model', 'gener', 'summari', 'http', 'model', 'http', 'huggingfac', 'co', 'saadob', '_ct', '_autochart', 'http', 'huggingfac', 'co', 'saadob', 't_ct_autochart', 'http', 'huggingfac', 'co', 'saadob', '_ct', '_big', 'http', 'huggingfac', 'co', 'saadob', 't_ct_big']"
75,83,83,applied-roboticist,vum5fb,[Discussion] How do I smoothen the output of an action segmentation model near the boundaries?,"Hello. Apologies if this is the wrong place to post because my problem is a simple one related to machine learning. My problem involves a robot that operates given the output of an action segmentation model. The trained model outputs an action label at every timestep e.g. \[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3\]. 

Given the sequence, I must now compute the time it takes to go from one label to the next. However, the actual output tends to be quite unstable especially when the action transitions from one to the next e.g., \[1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, ....\]. As such, I occasionally get multiple transitions. This simple issue makes the input unusable to the robot.

How can I clean up the output sequence? I thought of simple operations like converting the vector into a one-hot matrix and then running 1D erode and dilate operations but I was hoping to hear several other better suggestions.",4,1,2022-07-09 03:35:31, discussion  how do i smoothen the output of an action segmentation model near the boundaries ,hello  apologies if this is the wrong place to post because my problem is a simple one related to machine learning  my problem involves a robot that operates given the output of an action segmentation model  the trained model outputs an action label at every timestep e g                                                  given the sequence  i must now compute the time it takes to go from one label to the next  however  the actual output tends to be quite unstable especially when the action transitions from one to the next e g                                   as such  i occasionally get multiple transitions  this simple issue makes the input unusable to the robot how can i clean up the output sequence  i thought of simple operations like converting the vector into a one hot matrix and then running d erode and dilate operations but i was hoping to hear several other better suggestions ,hello apologies wrong place post problem simple one related machine learning problem involves robot operates given output action segmentation model trained model outputs action label every timestep e g given sequence must compute time takes go one label next however actual output tends quite unstable especially action transitions one next e g occasionally get multiple transitions simple issue makes input unusable robot clean output sequence thought simple operations like converting vector one hot matrix running erode dilate operations hoping hear several better suggestions,discussion smoothen output action segmentation model near boundaries,discussion smoothen output action segmentation model near boundarieshello apologies wrong place post problem simple one related machine learning problem involves robot operates given output action segmentation model trained model outputs action label every timestep e g given sequence must compute time takes go one label next however actual output tends quite unstable especially action transitions one next e g occasionally get multiple transitions simple issue makes input unusable robot clean output sequence thought simple operations like converting vector one hot matrix running erode dilate operations hoping hear several better suggestions,"['discussion', 'smoothen', 'output', 'action', 'segmentation', 'model', 'near', 'boundarieshello', 'apologies', 'wrong', 'place', 'post', 'problem', 'simple', 'one', 'related', 'machine', 'learning', 'problem', 'involves', 'robot', 'operates', 'given', 'output', 'action', 'segmentation', 'model', 'trained', 'model', 'outputs', 'action', 'label', 'every', 'timestep', 'e', 'g', 'given', 'sequence', 'must', 'compute', 'time', 'takes', 'go', 'one', 'label', 'next', 'however', 'actual', 'output', 'tends', 'quite', 'unstable', 'especially', 'action', 'transitions', 'one', 'next', 'e', 'g', 'occasionally', 'get', 'multiple', 'transitions', 'simple', 'issue', 'makes', 'input', 'unusable', 'robot', 'clean', 'output', 'sequence', 'thought', 'simple', 'operations', 'like', 'converting', 'vector', 'one', 'hot', 'matrix', 'running', 'erode', 'dilate', 'operations', 'hoping', 'hear', 'several', 'better', 'suggestions']","['discuss', 'smoothen', 'output', 'action', 'segment', 'model', 'near', 'boundarieshello', 'apolog', 'wrong', 'place', 'post', 'problem', 'simpl', 'one', 'relat', 'machin', 'learn', 'problem', 'involv', 'robot', 'oper', 'given', 'output', 'action', 'segment', 'model', 'train', 'model', 'output', 'action', 'label', 'everi', 'timestep', 'e', 'g', 'given', 'sequenc', 'must', 'comput', 'time', 'take', 'go', 'one', 'label', 'next', 'howev', 'actual', 'output', 'tend', 'quit', 'unstabl', 'especi', 'action', 'transit', 'one', 'next', 'e', 'g', 'occasion', 'get', 'multipl', 'transit', 'simpl', 'issu', 'make', 'input', 'unus', 'robot', 'clean', 'output', 'sequenc', 'thought', 'simpl', 'oper', 'like', 'convert', 'vector', 'one', 'hot', 'matrix', 'run', 'erod', 'dilat', 'oper', 'hope', 'hear', 'sever', 'better', 'suggest']"
76,84,84,kniranjankumar,vubrmf,[D] Searching for a paper on equivalent transformations on trained networks,"I had come across a paper that explored strategies to transform the architecture of a trained neural network, i.e. increasing layer width or adding additional layers, without forgetting what the network has already learnt. They describe initialization strategies to accomplish this. Does anyone know the paper I am talking about?",6,4,2022-07-08 19:44:37, d  searching for a paper on equivalent transformations on trained networks,i had come across a paper that explored strategies to transform the architecture of a trained neural network  i e  increasing layer width or adding additional layers  without forgetting what the network has already learnt  they describe initialization strategies to accomplish this  does anyone know the paper i am talking about ,come across paper explored strategies transform architecture trained neural network e increasing layer width adding additional layers without forgetting network already learnt describe initialization strategies accomplish anyone know paper talking,searching paper equivalent transformations trained networks,searching paper equivalent transformations trained networkscome across paper explored strategies transform architecture trained neural network e increasing layer width adding additional layers without forgetting network already learnt describe initialization strategies accomplish anyone know paper talking,"['searching', 'paper', 'equivalent', 'transformations', 'trained', 'networkscome', 'across', 'paper', 'explored', 'strategies', 'transform', 'architecture', 'trained', 'neural', 'network', 'e', 'increasing', 'layer', 'width', 'adding', 'additional', 'layers', 'without', 'forgetting', 'network', 'already', 'learnt', 'describe', 'initialization', 'strategies', 'accomplish', 'anyone', 'know', 'paper', 'talking']","['search', 'paper', 'equival', 'transform', 'train', 'networkscom', 'across', 'paper', 'explor', 'strategi', 'transform', 'architectur', 'train', 'neural', 'network', 'e', 'increas', 'layer', 'width', 'ad', 'addit', 'layer', 'without', 'forget', 'network', 'alreadi', 'learnt', 'describ', 'initi', 'strategi', 'accomplish', 'anyon', 'know', 'paper', 'talk']"
77,85,85,Competitive_Travel16,vtzpkp,[D] LaMDA long-term memory,"Google's February, 2022 [LaMDA paper](https://arxiv.org/abs/2201.08239) says it is preconditioned on previous interactions (someone on this subreddit said 14-30) in support of tuning its ""sensibleness"" metric, which includes making sure responses don't contradict anything said earlier.

However, in [this podcast,](https://thattech.show/episodes/62-exposing-google's-sentient-ai-with-blake-lemoine) Blake Lemoine says at 5:30-7:00 that LaMDA has some kind of long-term memory stretching back at least five years. He also mentions that the current system called ""LaMDA 2"" has access to a much wider variety of database resources than the paper or other Google [publications](https://towardsdatascience.com/why-gpt-wont-tell-you-the-truth-301b48434c2c) describe, 
including Google Images, YouTube, and Google Books.

Is LaMDA 2 documented anywhere? What other features does it have beyond what is documented in the February paper?",11,23,2022-07-08 07:53:05, d  lamda long term memory,google s february    lamda paper  https however  in  this podcast   https including google images  youtube  and google books is lamda  documented anywhere  what other features does it have beyond what is documented in the february paper ,google february lamda paper https however podcast https including google images youtube google books lamda documented anywhere features beyond documented february paper,lamda long term memory,lamda long term memorygoogle february lamda paper https however podcast https including google images youtube google books lamda documented anywhere features beyond documented february paper,"['lamda', 'long', 'term', 'memorygoogle', 'february', 'lamda', 'paper', 'https', 'however', 'podcast', 'https', 'including', 'google', 'images', 'youtube', 'google', 'books', 'lamda', 'documented', 'anywhere', 'features', 'beyond', 'documented', 'february', 'paper']","['lamda', 'long', 'term', 'memorygoogl', 'februari', 'lamda', 'paper', 'http', 'howev', 'podcast', 'http', 'includ', 'googl', 'imag', 'youtub', 'googl', 'book', 'lamda', 'document', 'anywher', 'featur', 'beyond', 'document', 'februari', 'paper']"
78,86,86,gnohuhs,vu25t7,[D] when do eccv meta-reviews come out?,"I know the result from the link in the email but cmt still says ""awaiting decision""

call me antsy but I just want to see the final comments and meta-review... did it take this long last year?",9,13,2022-07-08 10:02:49, d  when do eccv meta reviews come out ,i know the result from the link in the email but cmt still says awaiting decisioncall me antsy but i just want to see the final comments and meta review    did it take this long last year ,know result link email cmt still says awaiting decisioncall antsy want see final comments meta review take long last year,eccv meta reviews come,eccv meta reviews comeknow result link email cmt still says awaiting decisioncall antsy want see final comments meta review take long last year,"['eccv', 'meta', 'reviews', 'comeknow', 'result', 'link', 'email', 'cmt', 'still', 'says', 'awaiting', 'decisioncall', 'antsy', 'want', 'see', 'final', 'comments', 'meta', 'review', 'take', 'long', 'last', 'year']","['eccv', 'meta', 'review', 'comeknow', 'result', 'link', 'email', 'cmt', 'still', 'say', 'await', 'decisioncal', 'antsi', 'want', 'see', 'final', 'comment', 'meta', 'review', 'take', 'long', 'last', 'year']"
79,87,87,hardmaru,vtcrej,[D] LeCun's 2022 paper on autonomous machine intelligence rehashes but does not cite essential work of 1990-2015,"Saw Schmidhuber’s [tweeting](https://twitter.com/SchmidhuberAI/status/1544939700099710976) again: 🔥

*“Lecun’s 2022 paper on Autonomous Machine Intelligence rehashes but doesn’t cite essential work of 1990-2015. We’ve already published his “main original contributions:” learning subgoals, predictable abstract representations, multiple time scales…”*

Jürgen Schmidhuber’s response to Yann Lecun’s recent technical report / position paper “Autonomous Machine Intelligence” in this latest blog post:

https://people.idsia.ch/~juergen/lecun-rehash-1990-2022.html

**Update (Jul 8):** It seems Schmidhuber has posted his concerns on the paper’s [openreview.net](https://openreview.net/forum?id=BZ5a1r-kVsf&noteId=GsxarV_Jyeb) entry.

---

Excerpt:

*On 14 June 2022, a science tabloid that published this [article](https://www.technologyreview.com/2022/06/24/1054817/yann-lecun-bold-new-vision-future-ai-deep-learning-meta/) (24 June) on LeCun's report “[A Path Towards Autonomous Machine Intelligence](https://openreview.net/forum?id=BZ5a1r-kVsf)” (27 June) sent me a draft of the report (back then still under embargo) and asked for comments. I wrote a review (see below), telling them that this is essentially a rehash of our previous work that LeCun did not mention. My comments, however, fell on deaf ears. Now I am posting my not so enthusiastic remarks here such that the history of our field does not become further corrupted. The images below link to relevant blog posts from the [AI Blog](https://people.idsia.ch/~juergen/blog.html).*

*I would like to start this by acknowledging that I am not without a conflict of interest here; my seeking to correct the record will naturally seem self-interested. The truth of the matter is that it is. Much of the closely related work pointed to below was done in my lab, and I naturally wish that it be acknowledged, and recognized. Setting my conflict aside, I ask the reader to study the original papers and judge for themselves the scientific content of these remarks, as I seek to set emotions aside and minimize bias so much as I am capable.*

---

For reference, previous discussion on r/MachineLearning about Yann Lecun’s paper:

https://www.reddit.com/r/MachineLearning/comments/vm39oe/a_path_towards_autonomous_machine_intelligence/",88,351,2022-07-07 12:55:56, d  lecun s  paper on autonomous machine intelligence rehashes but does not cite essential work of  ,saw schmidhuber s  tweeting  https   lecun s  paper on autonomous machine intelligence rehashes but doesn t cite essential work of    we ve already published his  main original contributions   learning subgoals  predictable abstract representations  multiple time scales   jürgen schmidhuber s response to yann lecun s recent technical report   position paper  autonomous machine intelligence  in this latest blog post https   update  jul      it seems schmidhuber has posted his concerns on the paper s  openreview net  https    excerpt  on  june   a science tabloid that published this  article  https  i would like to start this by acknowledging that i am not without a conflict of interest here  my seeking to correct the record will naturally seem self interested  the truth of the matter is that it is  much of the closely related work pointed to below was done in my lab  and i naturally wish that it be acknowledged  and recognized  setting my conflict aside  i ask the reader to study the original papers and judge for themselves the scientific content of these remarks  as i seek to set emotions aside and minimize bias so much as i am capable     for reference  previous discussion on r machinelearning about yann lecun s paper https   www reddit com r machinelearning comments vmoe a_path_towards_autonomous_machine_intelligence ,saw schmidhuber tweeting https lecun paper autonomous machine intelligence rehashes cite essential work already published main original contributions learning subgoals predictable abstract representations multiple time scales jürgen schmidhuber response yann lecun recent technical report position paper autonomous machine intelligence latest blog post https update jul seems schmidhuber posted concerns paper openreview net https excerpt june science tabloid published article https would like start acknowledging without conflict interest seeking correct record naturally seem self interested truth matter much closely related work pointed done lab naturally wish acknowledged recognized setting conflict aside ask reader study original papers judge scientific content remarks seek set emotions aside minimize bias much capable reference previous discussion r machinelearning yann lecun paper https www reddit com r machinelearning comments vmoe a_path_towards_autonomous_machine_intelligence,lecun paper autonomous machine intelligence rehashes cite essential work,lecun paper autonomous machine intelligence rehashes cite essential worksaw schmidhuber tweeting https lecun paper autonomous machine intelligence rehashes cite essential work already published main original contributions learning subgoals predictable abstract representations multiple time scales jürgen schmidhuber response yann lecun recent technical report position paper autonomous machine intelligence latest blog post https update jul seems schmidhuber posted concerns paper openreview net https excerpt june science tabloid published article https would like start acknowledging without conflict interest seeking correct record naturally seem self interested truth matter much closely related work pointed done lab naturally wish acknowledged recognized setting conflict aside ask reader study original papers judge scientific content remarks seek set emotions aside minimize bias much capable reference previous discussion r machinelearning yann lecun paper https www reddit com r machinelearning comments vmoe a_path_towards_autonomous_machine_intelligence,"['lecun', 'paper', 'autonomous', 'machine', 'intelligence', 'rehashes', 'cite', 'essential', 'worksaw', 'schmidhuber', 'tweeting', 'https', 'lecun', 'paper', 'autonomous', 'machine', 'intelligence', 'rehashes', 'cite', 'essential', 'work', 'already', 'published', 'main', 'original', 'contributions', 'learning', 'subgoals', 'predictable', 'abstract', 'representations', 'multiple', 'time', 'scales', 'jürgen', 'schmidhuber', 'response', 'yann', 'lecun', 'recent', 'technical', 'report', 'position', 'paper', 'autonomous', 'machine', 'intelligence', 'latest', 'blog', 'post', 'https', 'update', 'jul', 'seems', 'schmidhuber', 'posted', 'concerns', 'paper', 'openreview', 'net', 'https', 'excerpt', 'june', 'science', 'tabloid', 'published', 'article', 'https', 'would', 'like', 'start', 'acknowledging', 'without', 'conflict', 'interest', 'seeking', 'correct', 'record', 'naturally', 'seem', 'self', 'interested', 'truth', 'matter', 'much', 'closely', 'related', 'work', 'pointed', 'done', 'lab', 'naturally', 'wish', 'acknowledged', 'recognized', 'setting', 'conflict', 'aside', 'ask', 'reader', 'study', 'original', 'papers', 'judge', 'scientific', 'content', 'remarks', 'seek', 'set', 'emotions', 'aside', 'minimize', 'bias', 'much', 'capable', 'reference', 'previous', 'discussion', 'r', 'machinelearning', 'yann', 'lecun', 'paper', 'https', 'www', 'reddit', 'com', 'r', 'machinelearning', 'comments', 'vmoe', 'a_path_towards_autonomous_machine_intelligence']","['lecun', 'paper', 'autonom', 'machin', 'intellig', 'rehash', 'cite', 'essenti', 'worksaw', 'schmidhub', 'tweet', 'http', 'lecun', 'paper', 'autonom', 'machin', 'intellig', 'rehash', 'cite', 'essenti', 'work', 'alreadi', 'publish', 'main', 'origin', 'contribut', 'learn', 'subgoal', 'predict', 'abstract', 'represent', 'multipl', 'time', 'scale', 'jürgen', 'schmidhub', 'respons', 'yann', 'lecun', 'recent', 'technic', 'report', 'posit', 'paper', 'autonom', 'machin', 'intellig', 'latest', 'blog', 'post', 'http', 'updat', 'jul', 'seem', 'schmidhub', 'post', 'concern', 'paper', 'openreview', 'net', 'http', 'excerpt', 'june', 'scienc', 'tabloid', 'publish', 'articl', 'http', 'would', 'like', 'start', 'acknowledg', 'without', 'conflict', 'interest', 'seek', 'correct', 'record', 'natur', 'seem', 'self', 'interest', 'truth', 'matter', 'much', 'close', 'relat', 'work', 'point', 'done', 'lab', 'natur', 'wish', 'acknowledg', 'recogn', 'set', 'conflict', 'asid', 'ask', 'reader', 'studi', 'origin', 'paper', 'judg', 'scientif', 'content', 'remark', 'seek', 'set', 'emot', 'asid', 'minim', 'bia', 'much', 'capabl', 'refer', 'previou', 'discuss', 'r', 'machinelearn', 'yann', 'lecun', 'paper', 'http', 'www', 'reddit', 'com', 'r', 'machinelearn', 'comment', 'vmoe', 'a_path_towards_autonomous_machine_intellig']"
80,88,88,Adept_Ad_3308,vtztrc,[R] NeurIPS2022’s Natural Language for Optimization (NL4Opt) competition!," 

We invite you to join our NL4Opt competition that will be part of NeurIPS2022. We have a novel never-before-seen NLP dataset in hopes of making optimization solvers more accessible and usable. The competition aims to allow non-experts to use optimization tools in their decision-making. This competition is split into two main tasks: NER and generation. We have provided baselines for each to kick-start your implementation. We will **award a total of $22,000 USD** evenly across the two tasks. 

We will also be hosting a workshop at the end of the competition and will be inviting experts and winners as podium speakers. Additionally, we plan to host poster sessions for participants to share their solution. 

The competition is tentatively from July 1st to October 15th with the submission portal opening on July 15th. We look forward to your participation – you can register ([https://nl4opt.github.io/participate/](https://nl4opt.github.io/participate/)) and our organizers will be in touch with you shortly.

For more information regarding the competition details, schedule, eligibility, rules, FAQs, and to get started, visit our competition website linked below! Follow our social media and GitHub discussion forum to keep updated. If you have any questions, please take a look at the FAQ section of our website. For any unanswered questions, free to start the discussion on the GitHub forum.

Twitter: [https://twitter.com/NL4Opt](https://twitter.com/NL4Opt)

Website: [https://nl4opt.github.io/](https://nl4opt.github.io/)

GitHub discussion forum: [https://github.com/nl4opt/nl4opt-competition/discussions](https://github.com/nl4opt/nl4opt-competition/discussions)

We look forward to your participation,

NL4Opt Organizers",0,11,2022-07-08 07:59:01, r  neurips s natural language for optimization  nlopt  competition , we invite you to join our nlopt competition that will be part of neurips  we have a novel never before seen nlp dataset in hopes of making optimization solvers more accessible and usable  the competition aims to allow non experts to use optimization tools in their decision making  this competition is split into two main tasks  ner and generation  we have provided baselines for each to kick start your implementation  we will   award a total of    usd   evenly across the two tasks  we will also be hosting a workshop at the end of the competition and will be inviting experts and winners as podium speakers  additionally  we plan to host poster sessions for participants to share their solution  the competition is tentatively from july st to october th with the submission portal opening on july th  we look forward to your participation   you can register   https for more information regarding the competition details  schedule  eligibility  rules  faqs  and to get started  visit our competition website linked below  follow our social media and github discussion forum to keep updated  if you have any questions  please take a look at the faq section of our website  for any unanswered questions  free to start the discussion on the github forum twitter   https website   https github discussion forum   https we look forward to your participation nlopt organizers,invite join nlopt competition part neurips novel never seen nlp dataset hopes making optimization solvers accessible usable competition aims allow non experts use optimization tools decision making competition split two main tasks ner generation provided baselines kick start implementation award total usd evenly across two tasks also hosting workshop end competition inviting experts winners podium speakers additionally plan host poster sessions participants share solution competition tentatively july st october th submission portal opening july th look forward participation register https information regarding competition details schedule eligibility rules faqs get started visit competition website linked follow social media github discussion forum keep updated questions please take look faq section website unanswered questions free start discussion github forum twitter https website https github discussion forum https look forward participation nlopt organizers,r neurips natural language optimization nlopt competition,r neurips natural language optimization nlopt competitioninvite join nlopt competition part neurips novel never seen nlp dataset hopes making optimization solvers accessible usable competition aims allow non experts use optimization tools decision making competition split two main tasks ner generation provided baselines kick start implementation award total usd evenly across two tasks also hosting workshop end competition inviting experts winners podium speakers additionally plan host poster sessions participants share solution competition tentatively july st october th submission portal opening july th look forward participation register https information regarding competition details schedule eligibility rules faqs get started visit competition website linked follow social media github discussion forum keep updated questions please take look faq section website unanswered questions free start discussion github forum twitter https website https github discussion forum https look forward participation nlopt organizers,"['r', 'neurips', 'natural', 'language', 'optimization', 'nlopt', 'competitioninvite', 'join', 'nlopt', 'competition', 'part', 'neurips', 'novel', 'never', 'seen', 'nlp', 'dataset', 'hopes', 'making', 'optimization', 'solvers', 'accessible', 'usable', 'competition', 'aims', 'allow', 'non', 'experts', 'use', 'optimization', 'tools', 'decision', 'making', 'competition', 'split', 'two', 'main', 'tasks', 'ner', 'generation', 'provided', 'baselines', 'kick', 'start', 'implementation', 'award', 'total', 'usd', 'evenly', 'across', 'two', 'tasks', 'also', 'hosting', 'workshop', 'end', 'competition', 'inviting', 'experts', 'winners', 'podium', 'speakers', 'additionally', 'plan', 'host', 'poster', 'sessions', 'participants', 'share', 'solution', 'competition', 'tentatively', 'july', 'st', 'october', 'th', 'submission', 'portal', 'opening', 'july', 'th', 'look', 'forward', 'participation', 'register', 'https', 'information', 'regarding', 'competition', 'details', 'schedule', 'eligibility', 'rules', 'faqs', 'get', 'started', 'visit', 'competition', 'website', 'linked', 'follow', 'social', 'media', 'github', 'discussion', 'forum', 'keep', 'updated', 'questions', 'please', 'take', 'look', 'faq', 'section', 'website', 'unanswered', 'questions', 'free', 'start', 'discussion', 'github', 'forum', 'twitter', 'https', 'website', 'https', 'github', 'discussion', 'forum', 'https', 'look', 'forward', 'participation', 'nlopt', 'organizers']","['r', 'neurip', 'natur', 'languag', 'optim', 'nlopt', 'competitioninvit', 'join', 'nlopt', 'competit', 'part', 'neurip', 'novel', 'never', 'seen', 'nlp', 'dataset', 'hope', 'make', 'optim', 'solver', 'access', 'usabl', 'competit', 'aim', 'allow', 'non', 'expert', 'use', 'optim', 'tool', 'decis', 'make', 'competit', 'split', 'two', 'main', 'task', 'ner', 'gener', 'provid', 'baselin', 'kick', 'start', 'implement', 'award', 'total', 'usd', 'evenli', 'across', 'two', 'task', 'also', 'host', 'workshop', 'end', 'competit', 'invit', 'expert', 'winner', 'podium', 'speaker', 'addit', 'plan', 'host', 'poster', 'session', 'particip', 'share', 'solut', 'competit', 'tent', 'juli', 'st', 'octob', 'th', 'submiss', 'portal', 'open', 'juli', 'th', 'look', 'forward', 'particip', 'regist', 'http', 'inform', 'regard', 'competit', 'detail', 'schedul', 'elig', 'rule', 'faq', 'get', 'start', 'visit', 'competit', 'websit', 'link', 'follow', 'social', 'media', 'github', 'discuss', 'forum', 'keep', 'updat', 'question', 'pleas', 'take', 'look', 'faq', 'section', 'websit', 'unansw', 'question', 'free', 'start', 'discuss', 'github', 'forum', 'twitter', 'http', 'websit', 'http', 'github', 'discuss', 'forum', 'http', 'look', 'forward', 'particip', 'nlopt', 'organ']"
81,89,89,Greckon121,vu7ahk,[P] Detection by position rather than looks?,"I am working on a project that needs to decide which olive tree branches should be cut. The goal is to detect the specific type of branch (watersprouts).

The problem I'm facing is that I'm unsure if I should use object detection (image classification + localization) or image segmentation. The difference between branches is mostly in their position with watersprouts growing mostly vertical to the main branch(there is a very small difference in looks between watersprouts and other branches) while other branches can grow in all ways (mostly parallel to the main branch).

My plan was to use object detection so I can classify watersprouts and localize them in the picture. I think that segmentation is a bit overkill for this problem because I don't see the need for localizing every pixel. The plan was to take pictures of watersprouts as class 1 and other branches as class 2,train them so I can detect them and localize. When I localize them I can now see which of these branches is a watersprout branch and which is a regular branch and then I know that watersprout should be cut.

The other problem I have is with understanding if it is possible for my machine learning project to recognize watersprouts not by their looks but by their position in regards to the main branch and correctly differentiate them from other branches because this is the main difference between watersprouts branch and regular branch. My understending is that the network learns how the object looks like and that position doesn't matter.

Am I on a right track or am I missing something?",7,2,2022-07-08 15:38:47, p  detection by position rather than looks ,i am working on a project that needs to decide which olive tree branches should be cut  the goal is to detect the specific type of branch  watersprouts  the problem i m facing is that i m unsure if i should use object detection  image classification   localization  or image segmentation  the difference between branches is mostly in their position with watersprouts growing mostly vertical to the main branch there is a very small difference in looks between watersprouts and other branches  while other branches can grow in all ways  mostly parallel to the main branch  my plan was to use object detection so i can classify watersprouts and localize them in the picture  i think that segmentation is a bit overkill for this problem because i don t see the need for localizing every pixel  the plan was to take pictures of watersprouts as class  and other branches as class  train them so i can detect them and localize  when i localize them i can now see which of these branches is a watersprout branch and which is a regular branch and then i know that watersprout should be cut the other problem i have is with understanding if it is possible for my machine learning project to recognize watersprouts not by their looks but by their position in regards to the main branch and correctly differentiate them from other branches because this is the main difference between watersprouts branch and regular branch  my understending is that the network learns how the object looks like and that position doesn t matter am i on a right track or am i missing something ,working project needs decide olive tree branches cut goal detect specific type branch watersprouts problem facing unsure use object detection image classification localization image segmentation difference branches mostly position watersprouts growing mostly vertical main branch small difference looks watersprouts branches branches grow ways mostly parallel main branch plan use object detection classify watersprouts localize picture think segmentation bit overkill problem see need localizing every pixel plan take pictures watersprouts class branches class train detect localize localize see branches watersprout branch regular branch know watersprout cut problem understanding possible machine learning project recognize watersprouts looks position regards main branch correctly differentiate branches main difference watersprouts branch regular branch understending network learns object looks like position matter right track missing something,p detection position rather looks,p detection position rather looksworking project needs decide olive tree branches cut goal detect specific type branch watersprouts problem facing unsure use object detection image classification localization image segmentation difference branches mostly position watersprouts growing mostly vertical main branch small difference looks watersprouts branches branches grow ways mostly parallel main branch plan use object detection classify watersprouts localize picture think segmentation bit overkill problem see need localizing every pixel plan take pictures watersprouts class branches class train detect localize localize see branches watersprout branch regular branch know watersprout cut problem understanding possible machine learning project recognize watersprouts looks position regards main branch correctly differentiate branches main difference watersprouts branch regular branch understending network learns object looks like position matter right track missing something,"['p', 'detection', 'position', 'rather', 'looksworking', 'project', 'needs', 'decide', 'olive', 'tree', 'branches', 'cut', 'goal', 'detect', 'specific', 'type', 'branch', 'watersprouts', 'problem', 'facing', 'unsure', 'use', 'object', 'detection', 'image', 'classification', 'localization', 'image', 'segmentation', 'difference', 'branches', 'mostly', 'position', 'watersprouts', 'growing', 'mostly', 'vertical', 'main', 'branch', 'small', 'difference', 'looks', 'watersprouts', 'branches', 'branches', 'grow', 'ways', 'mostly', 'parallel', 'main', 'branch', 'plan', 'use', 'object', 'detection', 'classify', 'watersprouts', 'localize', 'picture', 'think', 'segmentation', 'bit', 'overkill', 'problem', 'see', 'need', 'localizing', 'every', 'pixel', 'plan', 'take', 'pictures', 'watersprouts', 'class', 'branches', 'class', 'train', 'detect', 'localize', 'localize', 'see', 'branches', 'watersprout', 'branch', 'regular', 'branch', 'know', 'watersprout', 'cut', 'problem', 'understanding', 'possible', 'machine', 'learning', 'project', 'recognize', 'watersprouts', 'looks', 'position', 'regards', 'main', 'branch', 'correctly', 'differentiate', 'branches', 'main', 'difference', 'watersprouts', 'branch', 'regular', 'branch', 'understending', 'network', 'learns', 'object', 'looks', 'like', 'position', 'matter', 'right', 'track', 'missing', 'something']","['p', 'detect', 'posit', 'rather', 'lookswork', 'project', 'need', 'decid', 'oliv', 'tree', 'branch', 'cut', 'goal', 'detect', 'specif', 'type', 'branch', 'watersprout', 'problem', 'face', 'unsur', 'use', 'object', 'detect', 'imag', 'classif', 'local', 'imag', 'segment', 'differ', 'branch', 'mostli', 'posit', 'watersprout', 'grow', 'mostli', 'vertic', 'main', 'branch', 'small', 'differ', 'look', 'watersprout', 'branch', 'branch', 'grow', 'way', 'mostli', 'parallel', 'main', 'branch', 'plan', 'use', 'object', 'detect', 'classifi', 'watersprout', 'local', 'pictur', 'think', 'segment', 'bit', 'overkil', 'problem', 'see', 'need', 'local', 'everi', 'pixel', 'plan', 'take', 'pictur', 'watersprout', 'class', 'branch', 'class', 'train', 'detect', 'local', 'local', 'see', 'branch', 'watersprout', 'branch', 'regular', 'branch', 'know', 'watersprout', 'cut', 'problem', 'understand', 'possibl', 'machin', 'learn', 'project', 'recogn', 'watersprout', 'look', 'posit', 'regard', 'main', 'branch', 'correctli', 'differenti', 'branch', 'main', 'differ', 'watersprout', 'branch', 'regular', 'branch', 'understend', 'network', 'learn', 'object', 'look', 'like', 'posit', 'matter', 'right', 'track', 'miss', 'someth']"
82,90,90,ykilcher,vtsiif,[D] Paper Explained - JEPA: A Path Towards Autonomous Machine Intelligence (Video Walkthrough),"[https://youtu.be/jSdHmImyUjk](https://youtu.be/jSdHmImyUjk)

Yann LeCun's position paper on a path towards machine intelligence combines Self-Supervised Learning, Energy-Based Models, and hierarchical predictive embedding models to arrive at a system that can teach itself to learn useful abstractions at multiple levels and use that as a world model to plan ahead in time.

&#x200B;

OUTLINE:

0:00 - Introduction

2:00 - Main Contributions

5:45 - Mode 1 and Mode 2 actors

15:40 - Self-Supervised Learning and Energy-Based Models

20:15 - Introducing latent variables

25:00 - The problem of collapse

29:50 - Contrastive vs regularized methods

36:00 - The JEPA architecture

47:00 - Hierarchical JEPA (H-JEPA)

53:00 - Broader relevance

56:00 - Summary & Comments

&#x200B;

Paper: [https://openreview.net/forum?id=BZ5a1r-kVsf](https://openreview.net/forum?id=BZ5a1r-kVsf)",1,21,2022-07-08 02:11:41, d  paper explained   jepa  a path towards autonomous machine intelligence  video walkthrough , https yann lecun s position paper on a path towards machine intelligence combines self supervised learning  energy based models  and hierarchical predictive embedding models to arrive at a system that can teach itself to learn useful abstractions at multiple levels and use that as a world model to plan ahead in time   xb outline     introduction    main contributions    mode  and mode  actors    self supervised learning and energy based models    introducing latent variables    the problem of collapse    contrastive vs regularized methods    the jepa architecture    hierarchical jepa  h jepa     broader relevance    summary   comments  xb paper   https   openreview net forum id bzar kvsf  https   openreview net forum id bzar kvsf ,https yann lecun position paper path towards machine intelligence combines self supervised learning energy based models hierarchical predictive embedding models arrive system teach learn useful abstractions multiple levels use world model plan ahead time xb outline introduction main contributions mode mode actors self supervised learning energy based models introducing latent variables problem collapse contrastive vs regularized methods jepa architecture hierarchical jepa h jepa broader relevance summary comments xb paper https openreview net forum id bzar kvsf https openreview net forum id bzar kvsf,paper explained jepa path towards autonomous machine intelligence video walkthrough,paper explained jepa path towards autonomous machine intelligence video walkthroughhttps yann lecun position paper path towards machine intelligence combines self supervised learning energy based models hierarchical predictive embedding models arrive system teach learn useful abstractions multiple levels use world model plan ahead time xb outline introduction main contributions mode mode actors self supervised learning energy based models introducing latent variables problem collapse contrastive vs regularized methods jepa architecture hierarchical jepa h jepa broader relevance summary comments xb paper https openreview net forum id bzar kvsf https openreview net forum id bzar kvsf,"['paper', 'explained', 'jepa', 'path', 'towards', 'autonomous', 'machine', 'intelligence', 'video', 'walkthroughhttps', 'yann', 'lecun', 'position', 'paper', 'path', 'towards', 'machine', 'intelligence', 'combines', 'self', 'supervised', 'learning', 'energy', 'based', 'models', 'hierarchical', 'predictive', 'embedding', 'models', 'arrive', 'system', 'teach', 'learn', 'useful', 'abstractions', 'multiple', 'levels', 'use', 'world', 'model', 'plan', 'ahead', 'time', 'xb', 'outline', 'introduction', 'main', 'contributions', 'mode', 'mode', 'actors', 'self', 'supervised', 'learning', 'energy', 'based', 'models', 'introducing', 'latent', 'variables', 'problem', 'collapse', 'contrastive', 'vs', 'regularized', 'methods', 'jepa', 'architecture', 'hierarchical', 'jepa', 'h', 'jepa', 'broader', 'relevance', 'summary', 'comments', 'xb', 'paper', 'https', 'openreview', 'net', 'forum', 'id', 'bzar', 'kvsf', 'https', 'openreview', 'net', 'forum', 'id', 'bzar', 'kvsf']","['paper', 'explain', 'jepa', 'path', 'toward', 'autonom', 'machin', 'intellig', 'video', 'walkthroughhttp', 'yann', 'lecun', 'posit', 'paper', 'path', 'toward', 'machin', 'intellig', 'combin', 'self', 'supervis', 'learn', 'energi', 'base', 'model', 'hierarch', 'predict', 'embed', 'model', 'arriv', 'system', 'teach', 'learn', 'use', 'abstract', 'multipl', 'level', 'use', 'world', 'model', 'plan', 'ahead', 'time', 'xb', 'outlin', 'introduct', 'main', 'contribut', 'mode', 'mode', 'actor', 'self', 'supervis', 'learn', 'energi', 'base', 'model', 'introduc', 'latent', 'variabl', 'problem', 'collaps', 'contrast', 'vs', 'regular', 'method', 'jepa', 'architectur', 'hierarch', 'jepa', 'h', 'jepa', 'broader', 'relev', 'summari', 'comment', 'xb', 'paper', 'http', 'openreview', 'net', 'forum', 'id', 'bzar', 'kvsf', 'http', 'openreview', 'net', 'forum', 'id', 'bzar', 'kvsf']"
83,91,91,ml6189,vtwbsy,[R] Self-Modeling Programs: A Direct Approach to Program Likelihood,"[PDF Link](https://lemonade.sfo2.digitaloceanspaces.com/Self-Modeling%20Programs.pdf)

Abstract:

>In algorithmic information theory, the length of a program is used as a measure of its probability. This paper presents a category of programs that directly compute the combined probability of their own code symbols and input data. The probability of each symbol is computed from past symbols by requiring that execution of the program formed by the first n symbols returns a probability distribution over symbols for position n + 1. The program of this type with the highest likelihood ending in the input data sequence intuitively represents the most likely sequence of events that could have generated the data. Advantages of programs of this form and the relationship to the Kolmogorov complexity are discussed.

I'd appreciate any criticisms or comments.",0,12,2022-07-08 05:06:29, r  self modeling programs  a direct approach to program likelihood, pdf link  https abstract  in algorithmic information theory  the length of a program is used as a measure of its probability  this paper presents a category of programs that directly compute the combined probability of their own code symbols and input data  the probability of each symbol is computed from past symbols by requiring that execution of the program formed by the first n symbols returns a probability distribution over symbols for position n     the program of this type with the highest likelihood ending in the input data sequence intuitively represents the most likely sequence of events that could have generated the data  advantages of programs of this form and the relationship to the kolmogorov complexity are discussed i d appreciate any criticisms or comments ,pdf link https abstract algorithmic information theory length program used measure probability paper presents category programs directly compute combined probability code symbols input data probability symbol computed past symbols requiring execution program formed first n symbols returns probability distribution symbols position n program type highest likelihood ending input data sequence intuitively represents likely sequence events could generated data advantages programs form relationship kolmogorov complexity discussed appreciate criticisms comments,r self modeling programs direct approach program likelihood,r self modeling programs direct approach program likelihoodpdf link https abstract algorithmic information theory length program used measure probability paper presents category programs directly compute combined probability code symbols input data probability symbol computed past symbols requiring execution program formed first n symbols returns probability distribution symbols position n program type highest likelihood ending input data sequence intuitively represents likely sequence events could generated data advantages programs form relationship kolmogorov complexity discussed appreciate criticisms comments,"['r', 'self', 'modeling', 'programs', 'direct', 'approach', 'program', 'likelihoodpdf', 'link', 'https', 'abstract', 'algorithmic', 'information', 'theory', 'length', 'program', 'used', 'measure', 'probability', 'paper', 'presents', 'category', 'programs', 'directly', 'compute', 'combined', 'probability', 'code', 'symbols', 'input', 'data', 'probability', 'symbol', 'computed', 'past', 'symbols', 'requiring', 'execution', 'program', 'formed', 'first', 'n', 'symbols', 'returns', 'probability', 'distribution', 'symbols', 'position', 'n', 'program', 'type', 'highest', 'likelihood', 'ending', 'input', 'data', 'sequence', 'intuitively', 'represents', 'likely', 'sequence', 'events', 'could', 'generated', 'data', 'advantages', 'programs', 'form', 'relationship', 'kolmogorov', 'complexity', 'discussed', 'appreciate', 'criticisms', 'comments']","['r', 'self', 'model', 'program', 'direct', 'approach', 'program', 'likelihoodpdf', 'link', 'http', 'abstract', 'algorithm', 'inform', 'theori', 'length', 'program', 'use', 'measur', 'probabl', 'paper', 'present', 'categori', 'program', 'directli', 'comput', 'combin', 'probabl', 'code', 'symbol', 'input', 'data', 'probabl', 'symbol', 'comput', 'past', 'symbol', 'requir', 'execut', 'program', 'form', 'first', 'n', 'symbol', 'return', 'probabl', 'distribut', 'symbol', 'posit', 'n', 'program', 'type', 'highest', 'likelihood', 'end', 'input', 'data', 'sequenc', 'intuit', 'repres', 'like', 'sequenc', 'event', 'could', 'gener', 'data', 'advantag', 'program', 'form', 'relationship', 'kolmogorov', 'complex', 'discuss', 'appreci', 'critic', 'comment']"
84,92,92,FnSK4R17s,vtu6f9,[D] How to deal with badly labelled data?,"The labeling team at my organization is very bad. They take forever to understand the labeling objective. And produce datasets that are not very reliable. The take months to annotate a small dataset of roughly 2000 images. Now, I have 2 questions:

1. How do I spot these anomalies? (Classification Dataset)
2. How do I generate pseudo labels or use similar techniques to generate data for training?

Should I complain about them to my manager or ask them to label the datasets again? Because this situation is getting out of hand",10,8,2022-07-08 03:27:13, d  how to deal with badly labelled data ,the labeling team at my organization is very bad  they take forever to understand the labeling objective  and produce datasets that are not very reliable  the take months to annotate a small dataset of roughly  images  now  i have  questions   how do i spot these anomalies   classification dataset   how do i generate pseudo labels or use similar techniques to generate data for training should i complain about them to my manager or ask them to label the datasets again  because this situation is getting out of hand,labeling team organization bad take forever understand labeling objective produce datasets reliable take months annotate small dataset roughly images questions spot anomalies classification dataset generate pseudo labels use similar techniques generate data training complain manager ask label datasets situation getting hand,deal badly labelled data,deal badly labelled datalabeling team organization bad take forever understand labeling objective produce datasets reliable take months annotate small dataset roughly images questions spot anomalies classification dataset generate pseudo labels use similar techniques generate data training complain manager ask label datasets situation getting hand,"['deal', 'badly', 'labelled', 'datalabeling', 'team', 'organization', 'bad', 'take', 'forever', 'understand', 'labeling', 'objective', 'produce', 'datasets', 'reliable', 'take', 'months', 'annotate', 'small', 'dataset', 'roughly', 'images', 'questions', 'spot', 'anomalies', 'classification', 'dataset', 'generate', 'pseudo', 'labels', 'use', 'similar', 'techniques', 'generate', 'data', 'training', 'complain', 'manager', 'ask', 'label', 'datasets', 'situation', 'getting', 'hand']","['deal', 'badli', 'label', 'datalabel', 'team', 'organ', 'bad', 'take', 'forev', 'understand', 'label', 'object', 'produc', 'dataset', 'reliabl', 'take', 'month', 'annot', 'small', 'dataset', 'roughli', 'imag', 'question', 'spot', 'anomali', 'classif', 'dataset', 'gener', 'pseudo', 'label', 'use', 'similar', 'techniqu', 'gener', 'data', 'train', 'complain', 'manag', 'ask', 'label', 'dataset', 'situat', 'get', 'hand']"
85,93,93,Mediocre-Piccolo7474,vtfgeh,[Discussion] About model serving for production,"Hi!

I hope I'm not breaking any rules with this question.

I'm studying some frameworks used in production for model serving, namely Seldon Core, Kubeflow and an academic artifact named Clipper. Some can manage the entire ML life cycle, but I have a question about serving in production.

In particular, how would one go about actually batching multiple requests on the cloud? There doesn't seem to be a golden standard for it, so I'm assuming it depends on the size of the data and on the scope of model, right? For example, if the goal is image classification, it could be useful to have a cloud queue, right? 

If so, do you know what are some solutions that are actually used in production?",11,14,2022-07-07 15:58:17, discussion  about model serving for production,hi i hope i m not breaking any rules with this question i m studying some frameworks used in production for model serving  namely seldon core  kubeflow and an academic artifact named clipper  some can manage the entire ml life cycle  but i have a question about serving in production in particular  how would one go about actually batching multiple requests on the cloud  there doesn t seem to be a golden standard for it  so i m assuming it depends on the size of the data and on the scope of model  right  for example  if the goal is image classification  it could be useful to have a cloud queue  right  if so  do you know what are some solutions that are actually used in production ,hi hope breaking rules question studying frameworks used production model serving namely seldon core kubeflow academic artifact named clipper manage entire ml life cycle question serving production particular would one go actually batching multiple requests cloud seem golden standard assuming depends size data scope model right example goal image classification could useful cloud queue right know solutions actually used production,discussion model serving production,discussion model serving productionhi hope breaking rules question studying frameworks used production model serving namely seldon core kubeflow academic artifact named clipper manage entire ml life cycle question serving production particular would one go actually batching multiple requests cloud seem golden standard assuming depends size data scope model right example goal image classification could useful cloud queue right know solutions actually used production,"['discussion', 'model', 'serving', 'productionhi', 'hope', 'breaking', 'rules', 'question', 'studying', 'frameworks', 'used', 'production', 'model', 'serving', 'namely', 'seldon', 'core', 'kubeflow', 'academic', 'artifact', 'named', 'clipper', 'manage', 'entire', 'ml', 'life', 'cycle', 'question', 'serving', 'production', 'particular', 'would', 'one', 'go', 'actually', 'batching', 'multiple', 'requests', 'cloud', 'seem', 'golden', 'standard', 'assuming', 'depends', 'size', 'data', 'scope', 'model', 'right', 'example', 'goal', 'image', 'classification', 'could', 'useful', 'cloud', 'queue', 'right', 'know', 'solutions', 'actually', 'used', 'production']","['discuss', 'model', 'serv', 'productionhi', 'hope', 'break', 'rule', 'question', 'studi', 'framework', 'use', 'product', 'model', 'serv', 'name', 'seldon', 'core', 'kubeflow', 'academ', 'artifact', 'name', 'clipper', 'manag', 'entir', 'ml', 'life', 'cycl', 'question', 'serv', 'product', 'particular', 'would', 'one', 'go', 'actual', 'batch', 'multipl', 'request', 'cloud', 'seem', 'golden', 'standard', 'assum', 'depend', 'size', 'data', 'scope', 'model', 'right', 'exampl', 'goal', 'imag', 'classif', 'could', 'use', 'cloud', 'queue', 'right', 'know', 'solut', 'actual', 'use', 'product']"
86,94,94,The_Removed,vsnipd,[News] Ian Goodfellow joins DeepMind as a Research Scientist,"Per his tweet at https://twitter.com/goodfellow_ian/status/1544638709039091717, Goodfellow will be a research scientist under Oriol Vinyals' Deep Learning team.",109,500,2022-07-06 16:44:01, news  ian goodfellow joins deepmind as a research scientist,per his tweet at https   twitter com goodfellow_ian status   goodfellow will be a research scientist under oriol vinyals  deep learning team ,per tweet https twitter com goodfellow_ian status goodfellow research scientist oriol vinyals deep learning team,news ian goodfellow joins deepmind research scientist,news ian goodfellow joins deepmind research scientistper tweet https twitter com goodfellow_ian status goodfellow research scientist oriol vinyals deep learning team,"['news', 'ian', 'goodfellow', 'joins', 'deepmind', 'research', 'scientistper', 'tweet', 'https', 'twitter', 'com', 'goodfellow_ian', 'status', 'goodfellow', 'research', 'scientist', 'oriol', 'vinyals', 'deep', 'learning', 'team']","['news', 'ian', 'goodfellow', 'join', 'deepmind', 'research', 'scientistp', 'tweet', 'http', 'twitter', 'com', 'goodfellow_ian', 'statu', 'goodfellow', 'research', 'scientist', 'oriol', 'vinyal', 'deep', 'learn', 'team']"
87,95,95,After_Philosopher572,vsvgoz,[D] Why aren't there much people working on causal machine learning?,"It seems Judea Pearl, Yoshua Bengio, Elias Bareinboim and a handful of other researchers are only people who are working on causal inference and machine learning. Is causal machine learning still a niche field? Also, do you know any researcher working on causal machine learning at Berkeley?",29,52,2022-07-06 22:58:16, d  why aren t there much people working on causal machine learning ,it seems judea pearl  yoshua bengio  elias bareinboim and a handful of other researchers are only people who are working on causal inference and machine learning  is causal machine learning still a niche field  also  do you know any researcher working on causal machine learning at berkeley ,seems judea pearl yoshua bengio elias bareinboim handful researchers people working causal inference machine learning causal machine learning still niche field also know researcher working causal machine learning berkeley,much people working causal machine learning,much people working causal machine learningseems judea pearl yoshua bengio elias bareinboim handful researchers people working causal inference machine learning causal machine learning still niche field also know researcher working causal machine learning berkeley,"['much', 'people', 'working', 'causal', 'machine', 'learningseems', 'judea', 'pearl', 'yoshua', 'bengio', 'elias', 'bareinboim', 'handful', 'researchers', 'people', 'working', 'causal', 'inference', 'machine', 'learning', 'causal', 'machine', 'learning', 'still', 'niche', 'field', 'also', 'know', 'researcher', 'working', 'causal', 'machine', 'learning', 'berkeley']","['much', 'peopl', 'work', 'causal', 'machin', 'learningseem', 'judea', 'pearl', 'yoshua', 'bengio', 'elia', 'bareinboim', 'hand', 'research', 'peopl', 'work', 'causal', 'infer', 'machin', 'learn', 'causal', 'machin', 'learn', 'still', 'nich', 'field', 'also', 'know', 'research', 'work', 'causal', 'machin', 'learn', 'berkeley']"
88,96,96,AeronByHermanMiller,vt8jc4,[D] Why do first layer filters in CNNs converge to edge-detector-like filters?,"I believe its well known that generally first layer filters in CNNs will converge to ""edge-detector-like"" shapes like this: [shorturl.at/ANS78](https://shorturl.at/ANS78). 

This phenomenon is independent of the task from what I've seen - every large CNN backbone I've trained will converge to this given enough data. There is also research showing this type of edge detection happens in the visual cortex. Thus this edge detector phenomenon appears to be some fundamentally emergent property of the real world (+ maybe CNN type processors)

Is there any compelling technical explanation for how SGD and its variants can reliably produce this convergence? I don't mean why edge detectors are ""good"" first stage filters - that intuitively makes sense to me. But rather, how is it that SGD can reliably produce this type of convergence on any dataset? I've been looking for a while for an explanation but couldn't find anything great. 

I was thinking that maybe there is some explanation using an assumption that edges are naturally ""higher information"" on raw images from the real world, and thus more directionally stepped towards in the gradient? But can't get the explanation to a satisfying state.",8,6,2022-07-07 08:47:02, d  why do first layer filters in cnns converge to edge detector like filters ,i believe its well known that generally first layer filters in cnns will converge to edge detector like shapes like this   shorturl at ans  https this phenomenon is independent of the task from what i ve seen   every large cnn backbone i ve trained will converge to this given enough data  there is also research showing this type of edge detection happens in the visual cortex  thus this edge detector phenomenon appears to be some fundamentally emergent property of the real world    maybe cnn type processors is there any compelling technical explanation for how sgd and its variants can reliably produce this convergence  i don t mean why edge detectors are good first stage filters   that intuitively makes sense to me  but rather  how is it that sgd can reliably produce this type of convergence on any dataset  i ve been looking for a while for an explanation but couldn t find anything great  i was thinking that maybe there is some explanation using an assumption that edges are naturally higher information on raw images from the real world  and thus more directionally stepped towards in the gradient  but can t get the explanation to a satisfying state ,believe well known generally first layer filters cnns converge edge detector like shapes like shorturl ans https phenomenon independent task seen every large cnn backbone trained converge given enough data also research showing type edge detection happens visual cortex thus edge detector phenomenon appears fundamentally emergent property real world maybe cnn type processors compelling technical explanation sgd variants reliably produce convergence mean edge detectors good first stage filters intuitively makes sense rather sgd reliably produce type convergence dataset looking explanation find anything great thinking maybe explanation using assumption edges naturally higher information raw images real world thus directionally stepped towards gradient get explanation satisfying state,first layer filters cnns converge edge detector like filters,first layer filters cnns converge edge detector like filtersbelieve well known generally first layer filters cnns converge edge detector like shapes like shorturl ans https phenomenon independent task seen every large cnn backbone trained converge given enough data also research showing type edge detection happens visual cortex thus edge detector phenomenon appears fundamentally emergent property real world maybe cnn type processors compelling technical explanation sgd variants reliably produce convergence mean edge detectors good first stage filters intuitively makes sense rather sgd reliably produce type convergence dataset looking explanation find anything great thinking maybe explanation using assumption edges naturally higher information raw images real world thus directionally stepped towards gradient get explanation satisfying state,"['first', 'layer', 'filters', 'cnns', 'converge', 'edge', 'detector', 'like', 'filtersbelieve', 'well', 'known', 'generally', 'first', 'layer', 'filters', 'cnns', 'converge', 'edge', 'detector', 'like', 'shapes', 'like', 'shorturl', 'ans', 'https', 'phenomenon', 'independent', 'task', 'seen', 'every', 'large', 'cnn', 'backbone', 'trained', 'converge', 'given', 'enough', 'data', 'also', 'research', 'showing', 'type', 'edge', 'detection', 'happens', 'visual', 'cortex', 'thus', 'edge', 'detector', 'phenomenon', 'appears', 'fundamentally', 'emergent', 'property', 'real', 'world', 'maybe', 'cnn', 'type', 'processors', 'compelling', 'technical', 'explanation', 'sgd', 'variants', 'reliably', 'produce', 'convergence', 'mean', 'edge', 'detectors', 'good', 'first', 'stage', 'filters', 'intuitively', 'makes', 'sense', 'rather', 'sgd', 'reliably', 'produce', 'type', 'convergence', 'dataset', 'looking', 'explanation', 'find', 'anything', 'great', 'thinking', 'maybe', 'explanation', 'using', 'assumption', 'edges', 'naturally', 'higher', 'information', 'raw', 'images', 'real', 'world', 'thus', 'directionally', 'stepped', 'towards', 'gradient', 'get', 'explanation', 'satisfying', 'state']","['first', 'layer', 'filter', 'cnn', 'converg', 'edg', 'detector', 'like', 'filtersbeliev', 'well', 'known', 'gener', 'first', 'layer', 'filter', 'cnn', 'converg', 'edg', 'detector', 'like', 'shape', 'like', 'shorturl', 'an', 'http', 'phenomenon', 'independ', 'task', 'seen', 'everi', 'larg', 'cnn', 'backbon', 'train', 'converg', 'given', 'enough', 'data', 'also', 'research', 'show', 'type', 'edg', 'detect', 'happen', 'visual', 'cortex', 'thu', 'edg', 'detector', 'phenomenon', 'appear', 'fundament', 'emerg', 'properti', 'real', 'world', 'mayb', 'cnn', 'type', 'processor', 'compel', 'technic', 'explan', 'sgd', 'variant', 'reliabl', 'produc', 'converg', 'mean', 'edg', 'detector', 'good', 'first', 'stage', 'filter', 'intuit', 'make', 'sens', 'rather', 'sgd', 'reliabl', 'produc', 'type', 'converg', 'dataset', 'look', 'explan', 'find', 'anyth', 'great', 'think', 'mayb', 'explan', 'use', 'assumpt', 'edg', 'natur', 'higher', 'inform', 'raw', 'imag', 'real', 'world', 'thu', 'direct', 'step', 'toward', 'gradient', 'get', 'explan', 'satisfi', 'state']"
89,97,97,Singularian2501,vsyju8,[R] CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning,"Paper: [https://arxiv.org/pdf/2207.01780.pdf](https://arxiv.org/pdf/2207.01780.pdf)

Github: [https://github.com/salesforce/CodeRL](https://github.com/salesforce/CodeRL)

Abstract:

>Program synthesis or code generation aims to generate a program that satisfies a problem specification. Recent approaches using large-scale pretrained language models (LMs) have shown promising results, yet they have some critical limitations. In particular, they often follow a standard supervised fine-tuning procedure to train a code generation model only from the pairs of natural-language problem descriptions and ground-truth programs. Such paradigm largely ignores some important but potentially useful signals in the problem specification such as unit tests, which thus often results in poor performance when solving complex unseen coding tasks. To address the limitations, we propose ""CodeRL"", a new framework for program synthesis tasks through pretrained LMs and deep reinforcement learning (RL). Specifically, during training, we treat the code-generating LM as an actor network, and introduce a critic network that is trained to predict the functional correctness of generated programs and provide dense feedback signals to the actor. During inference, we introduce a new generation procedure with a critical sampling strategy that allows a model to automatically regenerate programs based on feedback from example unit tests and critic scores. For the model backbones, we extended the encoder-decoder architecture of CodeT5 with enhanced learning objectives, larger model sizes, and better pretraining data. Our method not only achieves new SOTA results on the challenging APPS benchmark, but also shows strong zero-shot transfer capability with new SOTA results on the simpler MBPP benchmark.       

https://preview.redd.it/goglny8a30a91.jpg?width=1218&format=pjpg&auto=webp&s=a6f50319637cf85fed2de1d08b407478f6a227aa

https://preview.redd.it/vav9glra30a91.jpg?width=1234&format=pjpg&auto=webp&s=19ef106847c090fab438338fad912f1afd75db1a",0,24,2022-07-07 01:10:56, r  coderl  mastering code generation through pretrained models and deep reinforcement learning,paper   https github   https abstract  program synthesis or code generation aims to generate a program that satisfies a problem specification  recent approaches using large scale pretrained language models  lms  have shown promising results  yet they have some critical limitations  in particular  they often follow a standard supervised fine tuning procedure to train a code generation model only from the pairs of natural language problem descriptions and ground truth programs  such paradigm largely ignores some important but potentially useful signals in the problem specification such as unit tests  which thus often results in poor performance when solving complex unseen coding tasks  to address the limitations  we propose coderl  a new framework for program synthesis tasks through pretrained lms and deep reinforcement learning  rl   specifically  during training  we treat the code generating lm as an actor network  and introduce a critic network that is trained to predict the functional correctness of generated programs and provide dense feedback signals to the actor  during inference  we introduce a new generation procedure with a critical sampling strategy that allows a model to automatically regenerate programs based on feedback from example unit tests and critic scores  for the model backbones  we extended the encoder decoder architecture of codet with enhanced learning objectives  larger model sizes  and better pretraining data  our method not only achieves new sota results on the challenging apps benchmark  but also shows strong zero shot transfer capability with new sota results on the simpler mbpp benchmark        https https   preview redd it vavglraa jpg width  format pjpg auto webp s efcfabfadfafddba,paper https github https abstract program synthesis code generation aims generate program satisfies problem specification recent approaches using large scale pretrained language models lms shown promising results yet critical limitations particular often follow standard supervised fine tuning procedure train code generation model pairs natural language problem descriptions ground truth programs paradigm largely ignores important potentially useful signals problem specification unit tests thus often results poor performance solving complex unseen coding tasks address limitations propose coderl framework program synthesis tasks pretrained lms deep reinforcement learning rl specifically training treat code generating lm actor network introduce critic network trained predict functional correctness generated programs provide dense feedback signals actor inference introduce generation procedure critical sampling strategy allows model automatically regenerate programs based feedback example unit tests critic scores model backbones extended encoder decoder architecture codet enhanced learning objectives larger model sizes better pretraining data method achieves sota results challenging apps benchmark also shows strong zero shot transfer capability sota results simpler mbpp benchmark https https preview redd vavglraa jpg width format pjpg auto webp efcfabfadfafddba,r coderl mastering code generation pretrained models deep reinforcement learning,r coderl mastering code generation pretrained models deep reinforcement learningpaper https github https abstract program synthesis code generation aims generate program satisfies problem specification recent approaches using large scale pretrained language models lms shown promising results yet critical limitations particular often follow standard supervised fine tuning procedure train code generation model pairs natural language problem descriptions ground truth programs paradigm largely ignores important potentially useful signals problem specification unit tests thus often results poor performance solving complex unseen coding tasks address limitations propose coderl framework program synthesis tasks pretrained lms deep reinforcement learning rl specifically training treat code generating lm actor network introduce critic network trained predict functional correctness generated programs provide dense feedback signals actor inference introduce generation procedure critical sampling strategy allows model automatically regenerate programs based feedback example unit tests critic scores model backbones extended encoder decoder architecture codet enhanced learning objectives larger model sizes better pretraining data method achieves sota results challenging apps benchmark also shows strong zero shot transfer capability sota results simpler mbpp benchmark https https preview redd vavglraa jpg width format pjpg auto webp efcfabfadfafddba,"['r', 'coderl', 'mastering', 'code', 'generation', 'pretrained', 'models', 'deep', 'reinforcement', 'learningpaper', 'https', 'github', 'https', 'abstract', 'program', 'synthesis', 'code', 'generation', 'aims', 'generate', 'program', 'satisfies', 'problem', 'specification', 'recent', 'approaches', 'using', 'large', 'scale', 'pretrained', 'language', 'models', 'lms', 'shown', 'promising', 'results', 'yet', 'critical', 'limitations', 'particular', 'often', 'follow', 'standard', 'supervised', 'fine', 'tuning', 'procedure', 'train', 'code', 'generation', 'model', 'pairs', 'natural', 'language', 'problem', 'descriptions', 'ground', 'truth', 'programs', 'paradigm', 'largely', 'ignores', 'important', 'potentially', 'useful', 'signals', 'problem', 'specification', 'unit', 'tests', 'thus', 'often', 'results', 'poor', 'performance', 'solving', 'complex', 'unseen', 'coding', 'tasks', 'address', 'limitations', 'propose', 'coderl', 'framework', 'program', 'synthesis', 'tasks', 'pretrained', 'lms', 'deep', 'reinforcement', 'learning', 'rl', 'specifically', 'training', 'treat', 'code', 'generating', 'lm', 'actor', 'network', 'introduce', 'critic', 'network', 'trained', 'predict', 'functional', 'correctness', 'generated', 'programs', 'provide', 'dense', 'feedback', 'signals', 'actor', 'inference', 'introduce', 'generation', 'procedure', 'critical', 'sampling', 'strategy', 'allows', 'model', 'automatically', 'regenerate', 'programs', 'based', 'feedback', 'example', 'unit', 'tests', 'critic', 'scores', 'model', 'backbones', 'extended', 'encoder', 'decoder', 'architecture', 'codet', 'enhanced', 'learning', 'objectives', 'larger', 'model', 'sizes', 'better', 'pretraining', 'data', 'method', 'achieves', 'sota', 'results', 'challenging', 'apps', 'benchmark', 'also', 'shows', 'strong', 'zero', 'shot', 'transfer', 'capability', 'sota', 'results', 'simpler', 'mbpp', 'benchmark', 'https', 'https', 'preview', 'redd', 'vavglraa', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'efcfabfadfafddba']","['r', 'coderl', 'master', 'code', 'gener', 'pretrain', 'model', 'deep', 'reinforc', 'learningpap', 'http', 'github', 'http', 'abstract', 'program', 'synthesi', 'code', 'gener', 'aim', 'gener', 'program', 'satisfi', 'problem', 'specif', 'recent', 'approach', 'use', 'larg', 'scale', 'pretrain', 'languag', 'model', 'lm', 'shown', 'promis', 'result', 'yet', 'critic', 'limit', 'particular', 'often', 'follow', 'standard', 'supervis', 'fine', 'tune', 'procedur', 'train', 'code', 'gener', 'model', 'pair', 'natur', 'languag', 'problem', 'descript', 'ground', 'truth', 'program', 'paradigm', 'larg', 'ignor', 'import', 'potenti', 'use', 'signal', 'problem', 'specif', 'unit', 'test', 'thu', 'often', 'result', 'poor', 'perform', 'solv', 'complex', 'unseen', 'code', 'task', 'address', 'limit', 'propos', 'coderl', 'framework', 'program', 'synthesi', 'task', 'pretrain', 'lm', 'deep', 'reinforc', 'learn', 'rl', 'specif', 'train', 'treat', 'code', 'gener', 'lm', 'actor', 'network', 'introduc', 'critic', 'network', 'train', 'predict', 'function', 'correct', 'gener', 'program', 'provid', 'dens', 'feedback', 'signal', 'actor', 'infer', 'introduc', 'gener', 'procedur', 'critic', 'sampl', 'strategi', 'allow', 'model', 'automat', 'regener', 'program', 'base', 'feedback', 'exampl', 'unit', 'test', 'critic', 'score', 'model', 'backbon', 'extend', 'encod', 'decod', 'architectur', 'codet', 'enhanc', 'learn', 'object', 'larger', 'model', 'size', 'better', 'pretrain', 'data', 'method', 'achiev', 'sota', 'result', 'challeng', 'app', 'benchmark', 'also', 'show', 'strong', 'zero', 'shot', 'transfer', 'capabl', 'sota', 'result', 'simpler', 'mbpp', 'benchmark', 'http', 'http', 'preview', 'redd', 'vavglraa', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'efcfabfadfafddba']"
90,98,98,fasttosmile,vt1v4n,[D] How would you measure the correlation of the gradient across iterations?,"One simple thing one could do is take the dot product between the current and the n-1 gradient.

But this will of course not be very meaningful as what really matters is a (sort-of) average correlation across several iterations, which will not be revealed from doing such a local comparison (using gradients from step n and n-1).

Ideally it would be a calculation that would not require keeping around old gradients. Any ideas?",4,11,2022-07-07 03:31:17, d  how would you measure the correlation of the gradient across iterations ,one simple thing one could do is take the dot product between the current and the n  gradient but this will of course not be very meaningful as what really matters is a  sort of  average correlation across several iterations  which will not be revealed from doing such a local comparison  using gradients from step n and n   ideally it would be a calculation that would not require keeping around old gradients  any ideas ,one simple thing one could take dot product current n gradient course meaningful really matters sort average correlation across several iterations revealed local comparison using gradients step n n ideally would calculation would require keeping around old gradients ideas,would measure correlation gradient across iterations,would measure correlation gradient across iterationsone simple thing one could take dot product current n gradient course meaningful really matters sort average correlation across several iterations revealed local comparison using gradients step n n ideally would calculation would require keeping around old gradients ideas,"['would', 'measure', 'correlation', 'gradient', 'across', 'iterationsone', 'simple', 'thing', 'one', 'could', 'take', 'dot', 'product', 'current', 'n', 'gradient', 'course', 'meaningful', 'really', 'matters', 'sort', 'average', 'correlation', 'across', 'several', 'iterations', 'revealed', 'local', 'comparison', 'using', 'gradients', 'step', 'n', 'n', 'ideally', 'would', 'calculation', 'would', 'require', 'keeping', 'around', 'old', 'gradients', 'ideas']","['would', 'measur', 'correl', 'gradient', 'across', 'iterationson', 'simpl', 'thing', 'one', 'could', 'take', 'dot', 'product', 'current', 'n', 'gradient', 'cours', 'meaning', 'realli', 'matter', 'sort', 'averag', 'correl', 'across', 'sever', 'iter', 'reveal', 'local', 'comparison', 'use', 'gradient', 'step', 'n', 'n', 'ideal', 'would', 'calcul', 'would', 'requir', 'keep', 'around', 'old', 'gradient', 'idea']"
91,99,99,CapitalShake3085,vsppcq,[R] Detectron2 STMDA-RetinaNet,"Hello, i am happy to share with you one of my latest work for domain adaptation built on top of Detectron2 object detector model (RetinaNet).

Link to the github repo STMDA-RetinaNet:  
[https://github.com/fpv-iplab/STMDA-RetinaNet](https://github.com/fpv-iplab/STMDA-RetinaNet)",2,11,2022-07-06 18:41:01, r  detectron stmda retinanet,hello  i am happy to share with you one of my latest work for domain adaptation built on top of detectron object detector model  retinanet  link to the github repo stmda retinanet    https   github com fpv iplab stmda retinanet  https   github com fpv iplab stmda retinanet ,hello happy share one latest work domain adaptation built top detectron object detector model retinanet link github repo stmda retinanet https github com fpv iplab stmda retinanet https github com fpv iplab stmda retinanet,r detectron stmda retinanet,r detectron stmda retinanethello happy share one latest work domain adaptation built top detectron object detector model retinanet link github repo stmda retinanet https github com fpv iplab stmda retinanet https github com fpv iplab stmda retinanet,"['r', 'detectron', 'stmda', 'retinanethello', 'happy', 'share', 'one', 'latest', 'work', 'domain', 'adaptation', 'built', 'top', 'detectron', 'object', 'detector', 'model', 'retinanet', 'link', 'github', 'repo', 'stmda', 'retinanet', 'https', 'github', 'com', 'fpv', 'iplab', 'stmda', 'retinanet', 'https', 'github', 'com', 'fpv', 'iplab', 'stmda', 'retinanet']","['r', 'detectron', 'stmda', 'retinanethello', 'happi', 'share', 'one', 'latest', 'work', 'domain', 'adapt', 'built', 'top', 'detectron', 'object', 'detector', 'model', 'retinanet', 'link', 'github', 'repo', 'stmda', 'retinanet', 'http', 'github', 'com', 'fpv', 'iplab', 'stmda', 'retinanet', 'http', 'github', 'com', 'fpv', 'iplab', 'stmda', 'retinanet']"
92,100,100,CYHSM,vstqhm,[P] Some new Sherlock Holmes stories (GPT-3),"I thought I share some of the Sherlock Holmes stories I created with various prompts using GPT-3. Might be fun for some fans, but overall the stories are all a bit superficial, although some of them made me laugh (the fourth one in particular).

&#x200B;

>John Watson was having a cup of tea in his flat when he heard a knock at the door. He got up to answer it, and found Sherlock Holmes standing there, looking rather grave.  
>  
>""Watson, I'm afraid I have some bad news,"" said Sherlock. ""I've just been to Baker Street, where I found Mrs. Hudson in a state of hysterics. It seems that a Mr. Bartholomew Jones was found dead in his study, and Mrs. Hudson is convinced that it was murder.""  
>  
>""That is rather shocking,"" said Watson. ""Do you have any idea who might have done it?""  
>  
>""I have some suspicions,"" replied Sherlock, ""but I should like to take a look at the body before drawing any conclusions. Would you be so kind as to come with me?""  
>  
>Watson agreed, and the two men made their way to Baker Street. There they found Mrs. Hudson still in a state of distress, and she led them to the study where the body was lying.  
>  
>It was immediately evident to Watson that this was no ordinary death. Mr. Jones had been stabbed multiple times, and there was a look of terror on his face.  
>  
>""This was no accident, Watson,"" said Sherlock. ""Someone wanted to make sure that Mr. Jones was dead.""  
>  
>Sherlock began to examine the body, and soon found what he was looking for: a piece of paper that had been hidden under the victim's shirt.  
>  
>""What does it say?"" asked Watson.  
>  
>""It's a list of names,"" replied Sherlock, ""and at the top is the name 'John Watson'.""  
>  
>""Good heavens!"" exclaimed Watson. ""Do you think I'm the murderer?""  
>  
>""I don't know,"" said Sherlock, ""but we need to find out who else is on this list. I'm afraid this is going to be a rather difficult case.""

\---

>""I'm telling you, John, this is the most baffling case I've ever encountered!""  
>  
>""Really, Sherlock? What's so special about it?""  
>  
>""Well, for one thing, the victim is a chicken.""  
>  
>""A chicken?""  
>  
>""Yes, a chicken. It was found dead in its coop with its throat slit.""  
>  
>""That doesn't sound so baffling to me. I'm sure the police will catch the culprit soon enough.""  
>  
>""You're not thinking, John! The chicken was found with a note.""  
>  
>""A note?""  
>  
>""Yes, a note. And on that note was written, 'Sherlock Holmes, I challenge you to solve this mystery.'""  
>  
>""So the culprit wants you to solve it, eh? That is a bit strange.""  
>  
>""Indeed. And that's not all. The note was signed 'Moriarty.'""  
>  
>""Moriarty! But he's been dead for years!""  
>  
>""So it would seem. But I have a feeling this is his handiwork.""  
>  
>""What makes you say that?""  
>  
>""Well, for one thing, Moriarty was a master of disguise. It's entirely possible he's still alive and is using one of his many aliases.""  
>  
>""But why would he want you to solve the mystery?""  
>  
>""I can only speculate. Perhaps he's bored in retirement and wants to give me a challenge. Or perhaps he's planning something bigger and this is just a diversion.""  
>  
>""Well, whatever the reason, it seems we're going to have to solve this mystery. I'll get the magnifying glass.""  
>  
>""And I'll start putting together a list of suspects.""  
>  
>""Excellent. I have a feeling this is going to be a most interesting case.""

\---

>John Watson was just about to drift off to sleep when he heard a loud crash downstairs. He leapt out of bed, grabbed his trusty revolver, and crept downstairs, heart pounding in his chest.  
>  
>What he saw shocked him. There, in the middle of his living room, was a huge, furry creature, standing on two legs and brandishing a knife. It was like nothing he had ever seen before.  
>  
>Before he could think, the creature lunged at him, knife raised. Watson reacted on instinct, firing his revolver. The bullet hit the creature in the chest and it fell to the ground with a thud.  
>  
>Watson's mind was racing. What was this thing? Where had it come from? And then he remembered the stories he had heard about Sherlock Holmes and his uncanny ability to solve the most bizarre cases.  
>  
>He rushed to the phone and called Holmes. Within minutes, the detective was on his way.  
>  
>When Holmes arrived, he took one look at the creature and announced that it was a Yeti, a mythical creature from the Himalayas. Watson was dumbfounded. How could Holmes possibly know that?  
>  
>It turns out that the Yeti was part of a circus that had recently come to town. The circus owner had been keeping the Yeti in a cage and feeding it raw meat. But the Yeti had escaped and was terrorizing the city.  
>  
>Holmes had deduced all of this from the creature's fur, which was matted with blood, and the knife, which was of a type used by circus performers.

\---

>Sherlock Holmes and Dr. Watson were sitting in their usual chairs in the sitting room of 221B Baker Street, when they were suddenly interrupted by a loud, piercing scream. The two men leapt to their feet and ran to the window, just in time to see a man falling from the building opposite.  
>  
>""Quick, Watson, we must go and investigate!"" cried Sherlock Holmes.  
>  
>The two men hurried down the stairs and out into the street, where they found a crowd of people gathered around the body of the man who had fallen.  
>  
>""What happened here?"" asked Sherlock Holmes.  
>  
>""He was pushed!"" cried a woman in the crowd. ""I saw it with my own eyes, he was pushed!""  
>  
>""Why would anyone want to push him?"" asked Watson.  
>  
>""I don't know, but it was murder, I tell you!""  
>  
>Sherlock Holmes and Watson pushed their way through the crowd and squatted down beside the body. Holmes examined it closely, while Watson looked around to see if he could spot the murderer.  
>  
>""It's quite clear what happened,"" said Holmes after a few minutes. ""The victim was pushed from the window of that building over there.""  
>  
>""But who did it?"" asked Watson.  
>  
>""The murderer must have been in that building, too. Come, Watson, we must go and investigate!""  
>  
>The two men hurried across the street and entered the building. They made their way to the floor where the victim had fallen and began knocking on doors.  
>  
>Finally, they came to a door that was answered by a very old woman.  
>  
>""What do you want?"" she asked.  
>  
>""We're investigating the murder of the man who was pushed from the window,"" said Holmes.  
>  
>""Oh, that's easy enough to solve,"" said the woman. ""The murderer is my husband.""  
>  
>""Your husband?"" asked Watson in disbelief.  
>  
>""Yes, my husband. He's always wanted to push someone out of a window, and when he saw that man standing there, he just couldn't resist.""  
>  
>""But why?"" asked Sherlock Holmes.  
>  
>""Oh, he's just always been a very funny man, ever since I've known him.""  
>  
>Sherlock Holmes and Watson exchanged a look, then Holmes said, ""Thank you for your help, ma'am. We'll be on our way now.""

\---

>I say, John, what do you make of this?""  
>  
>Sherlock Holmes was looking at me with an expression of mild amusement, as if he had just witnessed some amusing incident. I knew better than to ask him what he was talking about, so I simply waited for him to continue.  
>  
>""I was just reading the paper, and there was an article about a man who was arrested for trying to steal a chicken from a farmer's market. The amusing part is that the man's name is John Watson.""  
>  
>I must have looked startled, because Holmes began to laugh.  
>  
>""Yes, I can see how you might find that amusing,"" I said, not sure why he was finding the situation so humorous.  
>  
>""It's just that, well, it's not the first time that someone has made the mistake of thinking that you were involved in a crime, John.""  
>  
>I couldn't help but chuckle at that. It was true that I had been the victim of a few misunderstandings over the years, thanks to my association with Sherlock Holmes. People often assumed that if Holmes was investigating a case, then I must be involved in some way.  
>  
>""Of course, the police quickly realized that they had the wrong man and released him,"" Holmes continued. ""But I'm sure the poor fellow was quite embarrassed.""  
>  
>""I'm sure he was,"" I said, still chuckling.  
>  
>It was just another day in the life of Sherlock Holmes and John Watson. A day filled with excitement, adventure, and, occasionally, a bit of humour.

\---

>I'm telling you, John, this is the most baffling case I've ever encountered!""  
>  
>""Really, Sherlock? What's so baffling about it?""  
>  
>""Well, to start with, there's the fact that the victim was stabbed with an umbrella!""  
>  
>""An umbrella? Surely that's not so unusual.""  
>  
>""It is when the victim is a cat, John!""  
>  
>""A cat? Good heavens, Sherlock, this is getting more bizarre by the minute!""  
>  
>""I know, I know. But that's not all. The cat was also wearing a top hat and a monocle!""  
>  
>""A top hat and a monocle? Now that is rather unusual.""  
>  
>""Indeed. But the most baffling thing of all is the fact that the cat was found in a room that was locked from the inside!""  
>  
>""Locked from the inside? How is that possible?""  
>  
>""I have no idea, John. But I intend to find out. This case is most certainly worthy of my attention.

\---

>Sherlock Holmes and Dr. Watson were sitting in their usual spot in the sitting room at 221B Baker Street, when there was a knock at the door. They both got up to answer it, and there was a young boy standing there, holding a note.  
>  
>""I was asked to deliver this to you, sir,"" the boy said, handing the note to Sherlock.  
>  
>Sherlock Holmes took the note and read it. ""It's from my brother, Mycroft,"" he said. ""He wants me to come to the Diogenes Club.""  
>  
>""The Diogenes Club?"" Watson asked. ""What's that?""  
>  
>""It's a club for my brother and his friends,"" Sherlock explained. ""It's very exclusive and they don't allow women or children.""  
>  
>""Sounds stuffy,"" Watson said.  
>  
>""It is,"" Sherlock agreed. ""But Mycroft says it's important, so I suppose we should go.""  
>  
>They both grabbed their coats and headed out. When they got to the Diogenes Club, they were met by a man who escorted them inside.  
>  
>The club was everything Sherlock had said it would be. It was stuffy and there were no women or children. Mycroft was sitting in a chair, talking to a couple of other men. He saw Sherlock and Watson and gestured for them to join him.  
>  
>""Ah, Sherlock, good to see you,"" he said. ""I need your help with something.""  
>  
>""What is it?"" Sherlock asked.  
>  
>""There's been a murder,"" Mycroft said. ""One of the club members was found dead in his room.""  
>  
>""Who was it?"" Sherlock asked.  
>  
>""It was Sir Wilfred Baskerville,"" Mycroft said.  
>  
>""The man who owns the Baskerville estate?"" Watson asked.  
>  
>""The very same,"" Mycroft said. ""The police are baffled and I was hoping you could take a look.""  
>  
>""I'll see what I can do,"" Sherlock said.  
>  
>They went to Sir Wilfred's room and Sherlock began to examine the body. He quickly deduced that the man had been poisoned.  
>  
>""The killer must have put the poison in his drink,"" he said. ""But there's no sign of any struggle, so the man must have been unaware of what was happening.""  
>  
>""But who would want to kill him?"" Watson asked.  
>  
>""That's what I need to find out,"" Sherlock said.  
>  
>He began to question the other club members, but no one seemed to know anything. He was just about to give up when he saw a man walking a funny looking horse.  
>  
>""That's odd,"" he said. ""I've never seen a horse like that before.""  
>  
>He followed the man and watched as he went into the room of another club member. Sherlock waited a few minutes and then went into the room himself.  
>  
>""I thought I might find you in here,"" he said. ""You're the killer, aren't you?""  
>  
>The man tried to deny it, but Sherlock had evidence that he was the guilty one. He had been seen talking to Sir Wilfred earlier in the evening and he had been seen walking the funny looking horse.  
>  
>""But why?"" Sherlock asked. ""What could possibly motive you?""  
>  
>""It was the horse,"" the man said. ""He was always making fun of my horse and calling him names. I couldn't take it anymore.""  
>  
>So the killer had motive after all. And it was all because of a funny looking horse.

\---

>John Watson was sitting in his study, perusing the latest edition of The Strand Magazine, when he heard a light knock at the door. Putting down the magazine, he got up to answer it, finding Sherlock Holmes standing on the threshold, clutching a piece of paper in his hand.  
>  
>""Watson, come quick!"" said Holmes, his eyes gleaming with excitement. ""I've just received the most curious letter, and I need your help to solve the mystery.""  
>  
>Watson followed Holmes back to his own flat, where the letter was laid out on the table. It was written in a spidery hand, and consisted of nothing but a series of numbers:  
>  
>""7, 12, 9, 3, 14, 5, 11, 6, 2, 10, 4, 13, 8, 1""  
>  
>""What do you make of it, Watson?"" Holmes asked, his eyes narrowed in concentration.  
>  
>Watson shook his head, bemused. ""I'm afraid I don't see anything, Holmes.""  
>  
>""Come, come, Watson, use that famous deductive brain of yours!""  
>  
>After a few moments' thought, Watson had an idea. ""Perhaps it's a code of some sort?""  
>  
>""Excellent, Watson, as always!"" cried Holmes. ""Now, if we can just crack the code...""  
>  
>He sat down at the table and began to scribble on a piece of paper, muttering to himself as he worked. Watson watched him for a few minutes, then, feeling rather superfluous, picked up his magazine and began to leaf through it again.  
>  
>Suddenly, Holmes leapt up from the table with a cry of triumph. ""I've got it, Watson!""",1,4,2022-07-06 21:44:33, p  some new sherlock holmes stories  gpt  ,i thought i share some of the sherlock holmes stories i created with various prompts using gpt   might be fun for some fans  but overall the stories are all a bit superficial  although some of them made me laugh  the fourth one in particular    xb  john watson was having a cup of tea in his flat when he heard a knock at the door  he got up to answer it  and found sherlock holmes standing there  looking rather grave       watson  i m afraid i have some bad news  said sherlock  i ve just been to baker street  where i found mrs  hudson in a state of hysterics  it seems that a mr  bartholomew jones was found dead in his study  and mrs  hudson is convinced that it was murder       that is rather shocking  said watson  do you have any idea who might have done it       i have some suspicions  replied sherlock  but i should like to take a look at the body before drawing any conclusions  would you be so kind as to come with me       watson agreed  and the two men made their way to baker street  there they found mrs  hudson still in a state of distress  and she led them to the study where the body was lying       it was immediately evident to watson that this was no ordinary death  mr  jones had been stabbed multiple times  and there was a look of terror on his face       this was no accident  watson  said sherlock  someone wanted to make sure that mr  jones was dead       sherlock began to examine the body  and soon found what he was looking for  a piece of paper that had been hidden under the victim s shirt       what does it say  asked watson       it s a list of names  replied sherlock  and at the top is the name  john watson        good heavens  exclaimed watson  do you think i m the murderer       i don t know  said sherlock  but we need to find out who else is on this list  i m afraid this is going to be a rather difficult case      i m telling you  john  this is the most baffling case i ve ever encountered       really  sherlock  what s so special about it       well  for one thing  the victim is a chicken       a chicken       yes  a chicken  it was found dead in its coop with its throat slit       that doesn t sound so baffling to me  i m sure the police will catch the culprit soon enough       you re not thinking  john  the chicken was found with a note       a note       yes  a note  and on that note was written   sherlock holmes  i challenge you to solve this mystery        so the culprit wants you to solve it  eh  that is a bit strange       indeed  and that s not all  the note was signed  moriarty        moriarty  but he s been dead for years       so it would seem  but i have a feeling this is his handiwork       what makes you say that       well  for one thing  moriarty was a master of disguise  it s entirely possible he s still alive and is using one of his many aliases       but why would he want you to solve the mystery       i can only speculate  perhaps he s bored in retirement and wants to give me a challenge  or perhaps he s planning something bigger and this is just a diversion       well  whatever the reason  it seems we re going to have to solve this mystery  i ll get the magnifying glass       and i ll start putting together a list of suspects       excellent  i have a feeling this is going to be a most interesting case      john watson was just about to drift off to sleep when he heard a loud crash downstairs  he leapt out of bed  grabbed his trusty revolver  and crept downstairs  heart pounding in his chest       what he saw shocked him  there  in the middle of his living room  was a huge  furry creature  standing on two legs and brandishing a knife  it was like nothing he had ever seen before       before he could think  the creature lunged at him  knife raised  watson reacted on instinct  firing his revolver  the bullet hit the creature in the chest and it fell to the ground with a thud       watson s mind was racing  what was this thing  where had it come from  and then he remembered the stories he had heard about sherlock holmes and his uncanny ability to solve the most bizarre cases       he rushed to the phone and called holmes  within minutes  the detective was on his way       when holmes arrived  he took one look at the creature and announced that it was a yeti  a mythical creature from the himalayas  watson was dumbfounded  how could holmes possibly know that       it turns out that the yeti was part of a circus that had recently come to town  the circus owner had been keeping the yeti in a cage and feeding it raw meat  but the yeti had escaped and was terrorizing the city       holmes had deduced all of this from the creature s fur  which was matted with blood  and the knife  which was of a type used by circus performers      sherlock holmes and dr  watson were sitting in their usual chairs in the sitting room of b baker street  when they were suddenly interrupted by a loud  piercing scream  the two men leapt to their feet and ran to the window  just in time to see a man falling from the building opposite       quick  watson  we must go and investigate  cried sherlock holmes       the two men hurried down the stairs and out into the street  where they found a crowd of people gathered around the body of the man who had fallen       what happened here  asked sherlock holmes       he was pushed  cried a woman in the crowd  i saw it with my own eyes  he was pushed       why would anyone want to push him  asked watson       i don t know  but it was murder  i tell you       sherlock holmes and watson pushed their way through the crowd and squatted down beside the body  holmes examined it closely  while watson looked around to see if he could spot the murderer       it s quite clear what happened  said holmes after a few minutes  the victim was pushed from the window of that building over there       but who did it  asked watson       the murderer must have been in that building  too  come  watson  we must go and investigate       the two men hurried across the street and entered the building  they made their way to the floor where the victim had fallen and began knocking on doors       finally  they came to a door that was answered by a very old woman       what do you want  she asked       we re investigating the murder of the man who was pushed from the window  said holmes       oh  that s easy enough to solve  said the woman  the murderer is my husband       your husband  asked watson in disbelief       yes  my husband  he s always wanted to push someone out of a window  and when he saw that man standing there  he just couldn t resist       but why  asked sherlock holmes       oh  he s just always been a very funny man  ever since i ve known him       sherlock holmes and watson exchanged a look  then holmes said  thank you for your help  ma am  we ll be on our way now      i say  john  what do you make of this       sherlock holmes was looking at me with an expression of mild amusement  as if he had just witnessed some amusing incident  i knew better than to ask him what he was talking about  so i simply waited for him to continue       i was just reading the paper  and there was an article about a man who was arrested for trying to steal a chicken from a farmer s market  the amusing part is that the man s name is john watson       i must have looked startled  because holmes began to laugh       yes  i can see how you might find that amusing  i said  not sure why he was finding the situation so humorous       it s just that  well  it s not the first time that someone has made the mistake of thinking that you were involved in a crime  john       i couldn t help but chuckle at that  it was true that i had been the victim of a few misunderstandings over the years  thanks to my association with sherlock holmes  people often assumed that if holmes was investigating a case  then i must be involved in some way       of course  the police quickly realized that they had the wrong man and released him  holmes continued  but i m sure the poor fellow was quite embarrassed       i m sure he was  i said  still chuckling       it was just another day in the life of sherlock holmes and john watson  a day filled with excitement  adventure  and  occasionally  a bit of humour      i m telling you  john  this is the most baffling case i ve ever encountered       really  sherlock  what s so baffling about it       well  to start with  there s the fact that the victim was stabbed with an umbrella       an umbrella  surely that s not so unusual       it is when the victim is a cat  john       a cat  good heavens  sherlock  this is getting more bizarre by the minute       i know  i know  but that s not all  the cat was also wearing a top hat and a monocle       a top hat and a monocle  now that is rather unusual       indeed  but the most baffling thing of all is the fact that the cat was found in a room that was locked from the inside       locked from the inside  how is that possible       i have no idea  john  but i intend to find out  this case is most certainly worthy of my attention      sherlock holmes and dr  watson were sitting in their usual spot in the sitting room at b baker street  when there was a knock at the door  they both got up to answer it  and there was a young boy standing there  holding a note       i was asked to deliver this to you  sir  the boy said  handing the note to sherlock       sherlock holmes took the note and read it  it s from my brother  mycroft  he said  he wants me to come to the diogenes club       the diogenes club  watson asked  what s that       it s a club for my brother and his friends  sherlock explained  it s very exclusive and they don t allow women or children       sounds stuffy  watson said       it is  sherlock agreed  but mycroft says it s important  so i suppose we should go       they both grabbed their coats and headed out  when they got to the diogenes club  they were met by a man who escorted them inside       the club was everything sherlock had said it would be  it was stuffy and there were no women or children  mycroft was sitting in a chair  talking to a couple of other men  he saw sherlock and watson and gestured for them to join him       ah  sherlock  good to see you  he said  i need your help with something       what is it  sherlock asked       there s been a murder  mycroft said  one of the club members was found dead in his room       who was it  sherlock asked       it was sir wilfred baskerville  mycroft said       the man who owns the baskerville estate  watson asked       the very same  mycroft said  the police are baffled and i was hoping you could take a look       i ll see what i can do  sherlock said       they went to sir wilfred s room and sherlock began to examine the body  he quickly deduced that the man had been poisoned       the killer must have put the poison in his drink  he said  but there s no sign of any struggle  so the man must have been unaware of what was happening       but who would want to kill him  watson asked       that s what i need to find out  sherlock said       he began to question the other club members  but no one seemed to know anything  he was just about to give up when he saw a man walking a funny looking horse       that s odd  he said  i ve never seen a horse like that before       he followed the man and watched as he went into the room of another club member  sherlock waited a few minutes and then went into the room himself       i thought i might find you in here  he said  you re the killer  aren t you       the man tried to deny it  but sherlock had evidence that he was the guilty one  he had been seen talking to sir wilfred earlier in the evening and he had been seen walking the funny looking horse       but why  sherlock asked  what could possibly motive you       it was the horse  the man said  he was always making fun of my horse and calling him names  i couldn t take it anymore       so the killer had motive after all  and it was all because of a funny looking horse      john watson was sitting in his study  perusing the latest edition of the strand magazine  when he heard a light knock at the door  putting down the magazine  he got up to answer it  finding sherlock holmes standing on the threshold  clutching a piece of paper in his hand       watson  come quick  said holmes  his eyes gleaming with excitement  i ve just received the most curious letter  and i need your help to solve the mystery       watson followed holmes back to his own flat  where the letter was laid out on the table  it was written in a spidery hand  and consisted of nothing but a series of numbers                                       what do you make of it  watson  holmes asked  his eyes narrowed in concentration       watson shook his head  bemused  i m afraid i don t see anything  holmes       come  come  watson  use that famous deductive brain of yours       after a few moments  thought  watson had an idea  perhaps it s a code of some sort       excellent  watson  as always  cried holmes  now  if we can just crack the code         he sat down at the table and began to scribble on a piece of paper  muttering to himself as he worked  watson watched him for a few minutes  then  feeling rather superfluous  picked up his magazine and began to leaf through it again       suddenly  holmes leapt up from the table with a cry of triumph  i ve got it  watson ,thought share sherlock holmes stories created various prompts using gpt might fun fans overall stories bit superficial although made laugh fourth one particular xb john watson cup tea flat heard knock door got answer found sherlock holmes standing looking rather grave watson afraid bad news said sherlock baker street found mrs hudson state hysterics seems mr bartholomew jones found dead study mrs hudson convinced murder rather shocking said watson idea might done suspicions replied sherlock like take look body drawing conclusions would kind come watson agreed two men made way baker street found mrs hudson still state distress led study body lying immediately evident watson ordinary death mr jones stabbed multiple times look terror face accident watson said sherlock someone wanted make sure mr jones dead sherlock began examine body soon found looking piece paper hidden victim shirt say asked watson names replied sherlock top name john watson good heavens exclaimed watson think murderer know said sherlock need find else afraid going rather difficult case telling john baffling case ever encountered really sherlock special well one thing victim chicken chicken yes chicken found dead coop throat slit sound baffling sure police catch culprit soon enough thinking john chicken found note note yes note note written sherlock holmes challenge solve mystery culprit wants solve eh bit strange indeed note signed moriarty moriarty dead years would seem feeling handiwork makes say well one thing moriarty master disguise entirely possible still alive using one many aliases would want solve mystery speculate perhaps bored retirement wants give challenge perhaps planning something bigger diversion well whatever reason seems going solve mystery get magnifying glass start putting together suspects excellent feeling going interesting case john watson drift sleep heard loud crash downstairs leapt bed grabbed trusty revolver crept downstairs heart pounding chest saw shocked middle living room huge furry creature standing two legs brandishing knife like nothing ever seen could think creature lunged knife raised watson reacted instinct firing revolver bullet hit creature chest fell ground thud watson mind racing thing come remembered stories heard sherlock holmes uncanny ability solve bizarre cases rushed phone called holmes within minutes detective way holmes arrived took one look creature announced yeti mythical creature himalayas watson dumbfounded could holmes possibly know turns yeti part circus recently come town circus owner keeping yeti cage feeding raw meat yeti escaped terrorizing city holmes deduced creature fur matted blood knife type used circus performers sherlock holmes dr watson sitting usual chairs sitting room b baker street suddenly interrupted loud piercing scream two men leapt feet ran window time see man falling building opposite quick watson must go investigate cried sherlock holmes two men hurried stairs street found crowd people gathered around body man fallen happened asked sherlock holmes pushed cried woman crowd saw eyes pushed would anyone want push asked watson know murder tell sherlock holmes watson pushed way crowd squatted beside body holmes examined closely watson looked around see could spot murderer quite clear happened said holmes minutes victim pushed window building asked watson murderer must building come watson must go investigate two men hurried across street entered building made way floor victim fallen began knocking doors finally came door answered old woman want asked investigating murder man pushed window said holmes oh easy enough solve said woman murderer husband husband asked watson disbelief yes husband always wanted push someone window saw man standing resist asked sherlock holmes oh always funny man ever since known sherlock holmes watson exchanged look holmes said thank help way say john make sherlock holmes looking expression mild amusement witnessed amusing incident knew better ask talking simply waited continue reading paper article man arrested trying steal chicken farmer market amusing part man name john watson must looked startled holmes began laugh yes see might find amusing said sure finding situation humorous well first time someone made mistake thinking involved crime john help chuckle true victim misunderstandings years thanks association sherlock holmes people often assumed holmes investigating case must involved way course police quickly realized wrong man released holmes continued sure poor fellow quite embarrassed sure said still chuckling another day life sherlock holmes john watson day filled excitement adventure occasionally bit humour telling john baffling case ever encountered really sherlock baffling well start fact victim stabbed umbrella umbrella surely unusual victim cat john cat good heavens sherlock getting bizarre minute know know cat also wearing top hat monocle top hat monocle rather unusual indeed baffling thing fact cat found room locked inside locked inside possible idea john intend find case certainly worthy attention sherlock holmes dr watson sitting usual spot sitting room b baker street knock door got answer young boy standing holding note asked deliver sir boy said handing note sherlock sherlock holmes took note read brother mycroft said wants come diogenes club diogenes club watson asked club brother friends sherlock explained exclusive allow women children sounds stuffy watson said sherlock agreed mycroft says important suppose go grabbed coats headed got diogenes club met man escorted inside club everything sherlock said would stuffy women children mycroft sitting chair talking couple men saw sherlock watson gestured join ah sherlock good see said need help something sherlock asked murder mycroft said one club members found dead room sherlock asked sir wilfred baskerville mycroft said man owns baskerville estate watson asked mycroft said police baffled hoping could take look see sherlock said went sir wilfred room sherlock began examine body quickly deduced man poisoned killer must put poison drink said sign struggle man must unaware happening would want kill watson asked need find sherlock said began question club members one seemed know anything give saw man walking funny looking horse odd said never seen horse like followed man watched went room another club member sherlock waited minutes went room thought might find said killer man tried deny sherlock evidence guilty one seen talking sir wilfred earlier evening seen walking funny looking horse sherlock asked could possibly motive horse man said always making fun horse calling names take anymore killer motive funny looking horse john watson sitting study perusing latest edition strand magazine heard light knock door putting magazine got answer finding sherlock holmes standing threshold clutching piece paper hand watson come quick said holmes eyes gleaming excitement received curious letter need help solve mystery watson followed holmes back flat letter laid table written spidery hand consisted nothing series numbers make watson holmes asked eyes narrowed concentration watson shook head bemused afraid see anything holmes come come watson use famous deductive brain moments thought watson idea perhaps code sort excellent watson always cried holmes crack code sat table began scribble piece paper muttering worked watson watched minutes feeling rather superfluous picked magazine began leaf suddenly holmes leapt table cry triumph got watson,p sherlock holmes stories gpt,p sherlock holmes stories gptthought share sherlock holmes stories created various prompts using gpt might fun fans overall stories bit superficial although made laugh fourth one particular xb john watson cup tea flat heard knock door got answer found sherlock holmes standing looking rather grave watson afraid bad news said sherlock baker street found mrs hudson state hysterics seems mr bartholomew jones found dead study mrs hudson convinced murder rather shocking said watson idea might done suspicions replied sherlock like take look body drawing conclusions would kind come watson agreed two men made way baker street found mrs hudson still state distress led study body lying immediately evident watson ordinary death mr jones stabbed multiple times look terror face accident watson said sherlock someone wanted make sure mr jones dead sherlock began examine body soon found looking piece paper hidden victim shirt say asked watson names replied sherlock top name john watson good heavens exclaimed watson think murderer know said sherlock need find else afraid going rather difficult case telling john baffling case ever encountered really sherlock special well one thing victim chicken chicken yes chicken found dead coop throat slit sound baffling sure police catch culprit soon enough thinking john chicken found note note yes note note written sherlock holmes challenge solve mystery culprit wants solve eh bit strange indeed note signed moriarty moriarty dead years would seem feeling handiwork makes say well one thing moriarty master disguise entirely possible still alive using one many aliases would want solve mystery speculate perhaps bored retirement wants give challenge perhaps planning something bigger diversion well whatever reason seems going solve mystery get magnifying glass start putting together suspects excellent feeling going interesting case john watson drift sleep heard loud crash downstairs leapt bed grabbed trusty revolver crept downstairs heart pounding chest saw shocked middle living room huge furry creature standing two legs brandishing knife like nothing ever seen could think creature lunged knife raised watson reacted instinct firing revolver bullet hit creature chest fell ground thud watson mind racing thing come remembered stories heard sherlock holmes uncanny ability solve bizarre cases rushed phone called holmes within minutes detective way holmes arrived took one look creature announced yeti mythical creature himalayas watson dumbfounded could holmes possibly know turns yeti part circus recently come town circus owner keeping yeti cage feeding raw meat yeti escaped terrorizing city holmes deduced creature fur matted blood knife type used circus performers sherlock holmes dr watson sitting usual chairs sitting room b baker street suddenly interrupted loud piercing scream two men leapt feet ran window time see man falling building opposite quick watson must go investigate cried sherlock holmes two men hurried stairs street found crowd people gathered around body man fallen happened asked sherlock holmes pushed cried woman crowd saw eyes pushed would anyone want push asked watson know murder tell sherlock holmes watson pushed way crowd squatted beside body holmes examined closely watson looked around see could spot murderer quite clear happened said holmes minutes victim pushed window building asked watson murderer must building come watson must go investigate two men hurried across street entered building made way floor victim fallen began knocking doors finally came door answered old woman want asked investigating murder man pushed window said holmes oh easy enough solve said woman murderer husband husband asked watson disbelief yes husband always wanted push someone window saw man standing resist asked sherlock holmes oh always funny man ever since known sherlock holmes watson exchanged look holmes said thank help way say john make sherlock holmes looking expression mild amusement witnessed amusing incident knew better ask talking simply waited continue reading paper article man arrested trying steal chicken farmer market amusing part man name john watson must looked startled holmes began laugh yes see might find amusing said sure finding situation humorous well first time someone made mistake thinking involved crime john help chuckle true victim misunderstandings years thanks association sherlock holmes people often assumed holmes investigating case must involved way course police quickly realized wrong man released holmes continued sure poor fellow quite embarrassed sure said still chuckling another day life sherlock holmes john watson day filled excitement adventure occasionally bit humour telling john baffling case ever encountered really sherlock baffling well start fact victim stabbed umbrella umbrella surely unusual victim cat john cat good heavens sherlock getting bizarre minute know know cat also wearing top hat monocle top hat monocle rather unusual indeed baffling thing fact cat found room locked inside locked inside possible idea john intend find case certainly worthy attention sherlock holmes dr watson sitting usual spot sitting room b baker street knock door got answer young boy standing holding note asked deliver sir boy said handing note sherlock sherlock holmes took note read brother mycroft said wants come diogenes club diogenes club watson asked club brother friends sherlock explained exclusive allow women children sounds stuffy watson said sherlock agreed mycroft says important suppose go grabbed coats headed got diogenes club met man escorted inside club everything sherlock said would stuffy women children mycroft sitting chair talking couple men saw sherlock watson gestured join ah sherlock good see said need help something sherlock asked murder mycroft said one club members found dead room sherlock asked sir wilfred baskerville mycroft said man owns baskerville estate watson asked mycroft said police baffled hoping could take look see sherlock said went sir wilfred room sherlock began examine body quickly deduced man poisoned killer must put poison drink said sign struggle man must unaware happening would want kill watson asked need find sherlock said began question club members one seemed know anything give saw man walking funny looking horse odd said never seen horse like followed man watched went room another club member sherlock waited minutes went room thought might find said killer man tried deny sherlock evidence guilty one seen talking sir wilfred earlier evening seen walking funny looking horse sherlock asked could possibly motive horse man said always making fun horse calling names take anymore killer motive funny looking horse john watson sitting study perusing latest edition strand magazine heard light knock door putting magazine got answer finding sherlock holmes standing threshold clutching piece paper hand watson come quick said holmes eyes gleaming excitement received curious letter need help solve mystery watson followed holmes back flat letter laid table written spidery hand consisted nothing series numbers make watson holmes asked eyes narrowed concentration watson shook head bemused afraid see anything holmes come come watson use famous deductive brain moments thought watson idea perhaps code sort excellent watson always cried holmes crack code sat table began scribble piece paper muttering worked watson watched minutes feeling rather superfluous picked magazine began leaf suddenly holmes leapt table cry triumph got watson,"['p', 'sherlock', 'holmes', 'stories', 'gptthought', 'share', 'sherlock', 'holmes', 'stories', 'created', 'various', 'prompts', 'using', 'gpt', 'might', 'fun', 'fans', 'overall', 'stories', 'bit', 'superficial', 'although', 'made', 'laugh', 'fourth', 'one', 'particular', 'xb', 'john', 'watson', 'cup', 'tea', 'flat', 'heard', 'knock', 'door', 'got', 'answer', 'found', 'sherlock', 'holmes', 'standing', 'looking', 'rather', 'grave', 'watson', 'afraid', 'bad', 'news', 'said', 'sherlock', 'baker', 'street', 'found', 'mrs', 'hudson', 'state', 'hysterics', 'seems', 'mr', 'bartholomew', 'jones', 'found', 'dead', 'study', 'mrs', 'hudson', 'convinced', 'murder', 'rather', 'shocking', 'said', 'watson', 'idea', 'might', 'done', 'suspicions', 'replied', 'sherlock', 'like', 'take', 'look', 'body', 'drawing', 'conclusions', 'would', 'kind', 'come', 'watson', 'agreed', 'two', 'men', 'made', 'way', 'baker', 'street', 'found', 'mrs', 'hudson', 'still', 'state', 'distress', 'led', 'study', 'body', 'lying', 'immediately', 'evident', 'watson', 'ordinary', 'death', 'mr', 'jones', 'stabbed', 'multiple', 'times', 'look', 'terror', 'face', 'accident', 'watson', 'said', 'sherlock', 'someone', 'wanted', 'make', 'sure', 'mr', 'jones', 'dead', 'sherlock', 'began', 'examine', 'body', 'soon', 'found', 'looking', 'piece', 'paper', 'hidden', 'victim', 'shirt', 'say', 'asked', 'watson', 'names', 'replied', 'sherlock', 'top', 'name', 'john', 'watson', 'good', 'heavens', 'exclaimed', 'watson', 'think', 'murderer', 'know', 'said', 'sherlock', 'need', 'find', 'else', 'afraid', 'going', 'rather', 'difficult', 'case', 'telling', 'john', 'baffling', 'case', 'ever', 'encountered', 'really', 'sherlock', 'special', 'well', 'one', 'thing', 'victim', 'chicken', 'chicken', 'yes', 'chicken', 'found', 'dead', 'coop', 'throat', 'slit', 'sound', 'baffling', 'sure', 'police', 'catch', 'culprit', 'soon', 'enough', 'thinking', 'john', 'chicken', 'found', 'note', 'note', 'yes', 'note', 'note', 'written', 'sherlock', 'holmes', 'challenge', 'solve', 'mystery', 'culprit', 'wants', 'solve', 'eh', 'bit', 'strange', 'indeed', 'note', 'signed', 'moriarty', 'moriarty', 'dead', 'years', 'would', 'seem', 'feeling', 'handiwork', 'makes', 'say', 'well', 'one', 'thing', 'moriarty', 'master', 'disguise', 'entirely', 'possible', 'still', 'alive', 'using', 'one', 'many', 'aliases', 'would', 'want', 'solve', 'mystery', 'speculate', 'perhaps', 'bored', 'retirement', 'wants', 'give', 'challenge', 'perhaps', 'planning', 'something', 'bigger', 'diversion', 'well', 'whatever', 'reason', 'seems', 'going', 'solve', 'mystery', 'get', 'magnifying', 'glass', 'start', 'putting', 'together', 'suspects', 'excellent', 'feeling', 'going', 'interesting', 'case', 'john', 'watson', 'drift', 'sleep', 'heard', 'loud', 'crash', 'downstairs', 'leapt', 'bed', 'grabbed', 'trusty', 'revolver', 'crept', 'downstairs', 'heart', 'pounding', 'chest', 'saw', 'shocked', 'middle', 'living', 'room', 'huge', 'furry', 'creature', 'standing', 'two', 'legs', 'brandishing', 'knife', 'like', 'nothing', 'ever', 'seen', 'could', 'think', 'creature', 'lunged', 'knife', 'raised', 'watson', 'reacted', 'instinct', 'firing', 'revolver', 'bullet', 'hit', 'creature', 'chest', 'fell', 'ground', 'thud', 'watson', 'mind', 'racing', 'thing', 'come', 'remembered', 'stories', 'heard', 'sherlock', 'holmes', 'uncanny', 'ability', 'solve', 'bizarre', 'cases', 'rushed', 'phone', 'called', 'holmes', 'within', 'minutes', 'detective', 'way', 'holmes', 'arrived', 'took', 'one', 'look', 'creature', 'announced', 'yeti', 'mythical', 'creature', 'himalayas', 'watson', 'dumbfounded', 'could', 'holmes', 'possibly', 'know', 'turns', 'yeti', 'part', 'circus', 'recently', 'come', 'town', 'circus', 'owner', 'keeping', 'yeti', 'cage', 'feeding', 'raw', 'meat', 'yeti', 'escaped', 'terrorizing', 'city', 'holmes', 'deduced', 'creature', 'fur', 'matted', 'blood', 'knife', 'type', 'used', 'circus', 'performers', 'sherlock', 'holmes', 'dr', 'watson', 'sitting', 'usual', 'chairs', 'sitting', 'room', 'b', 'baker', 'street', 'suddenly', 'interrupted', 'loud', 'piercing', 'scream', 'two', 'men', 'leapt', 'feet', 'ran', 'window', 'time', 'see', 'man', 'falling', 'building', 'opposite', 'quick', 'watson', 'must', 'go', 'investigate', 'cried', 'sherlock', 'holmes', 'two', 'men', 'hurried', 'stairs', 'street', 'found', 'crowd', 'people', 'gathered', 'around', 'body', 'man', 'fallen', 'happened', 'asked', 'sherlock', 'holmes', 'pushed', 'cried', 'woman', 'crowd', 'saw', 'eyes', 'pushed', 'would', 'anyone', 'want', 'push', 'asked', 'watson', 'know', 'murder', 'tell', 'sherlock', 'holmes', 'watson', 'pushed', 'way', 'crowd', 'squatted', 'beside', 'body', 'holmes', 'examined', 'closely', 'watson', 'looked', 'around', 'see', 'could', 'spot', 'murderer', 'quite', 'clear', 'happened', 'said', 'holmes', 'minutes', 'victim', 'pushed', 'window', 'building', 'asked', 'watson', 'murderer', 'must', 'building', 'come', 'watson', 'must', 'go', 'investigate', 'two', 'men', 'hurried', 'across', 'street', 'entered', 'building', 'made', 'way', 'floor', 'victim', 'fallen', 'began', 'knocking', 'doors', 'finally', 'came', 'door', 'answered', 'old', 'woman', 'want', 'asked', 'investigating', 'murder', 'man', 'pushed', 'window', 'said', 'holmes', 'oh', 'easy', 'enough', 'solve', 'said', 'woman', 'murderer', 'husband', 'husband', 'asked', 'watson', 'disbelief', 'yes', 'husband', 'always', 'wanted', 'push', 'someone', 'window', 'saw', 'man', 'standing', 'resist', 'asked', 'sherlock', 'holmes', 'oh', 'always', 'funny', 'man', 'ever', 'since', 'known', 'sherlock', 'holmes', 'watson', 'exchanged', 'look', 'holmes', 'said', 'thank', 'help', 'way', 'say', 'john', 'make', 'sherlock', 'holmes', 'looking', 'expression', 'mild', 'amusement', 'witnessed', 'amusing', 'incident', 'knew', 'better', 'ask', 'talking', 'simply', 'waited', 'continue', 'reading', 'paper', 'article', 'man', 'arrested', 'trying', 'steal', 'chicken', 'farmer', 'market', 'amusing', 'part', 'man', 'name', 'john', 'watson', 'must', 'looked', 'startled', 'holmes', 'began', 'laugh', 'yes', 'see', 'might', 'find', 'amusing', 'said', 'sure', 'finding', 'situation', 'humorous', 'well', 'first', 'time', 'someone', 'made', 'mistake', 'thinking', 'involved', 'crime', 'john', 'help', 'chuckle', 'true', 'victim', 'misunderstandings', 'years', 'thanks', 'association', 'sherlock', 'holmes', 'people', 'often', 'assumed', 'holmes', 'investigating', 'case', 'must', 'involved', 'way', 'course', 'police', 'quickly', 'realized', 'wrong', 'man', 'released', 'holmes', 'continued', 'sure', 'poor', 'fellow', 'quite', 'embarrassed', 'sure', 'said', 'still', 'chuckling', 'another', 'day', 'life', 'sherlock', 'holmes', 'john', 'watson', 'day', 'filled', 'excitement', 'adventure', 'occasionally', 'bit', 'humour', 'telling', 'john', 'baffling', 'case', 'ever', 'encountered', 'really', 'sherlock', 'baffling', 'well', 'start', 'fact', 'victim', 'stabbed', 'umbrella', 'umbrella', 'surely', 'unusual', 'victim', 'cat', 'john', 'cat', 'good', 'heavens', 'sherlock', 'getting', 'bizarre', 'minute', 'know', 'know', 'cat', 'also', 'wearing', 'top', 'hat', 'monocle', 'top', 'hat', 'monocle', 'rather', 'unusual', 'indeed', 'baffling', 'thing', 'fact', 'cat', 'found', 'room', 'locked', 'inside', 'locked', 'inside', 'possible', 'idea', 'john', 'intend', 'find', 'case', 'certainly', 'worthy', 'attention', 'sherlock', 'holmes', 'dr', 'watson', 'sitting', 'usual', 'spot', 'sitting', 'room', 'b', 'baker', 'street', 'knock', 'door', 'got', 'answer', 'young', 'boy', 'standing', 'holding', 'note', 'asked', 'deliver', 'sir', 'boy', 'said', 'handing', 'note', 'sherlock', 'sherlock', 'holmes', 'took', 'note', 'read', 'brother', 'mycroft', 'said', 'wants', 'come', 'diogenes', 'club', 'diogenes', 'club', 'watson', 'asked', 'club', 'brother', 'friends', 'sherlock', 'explained', 'exclusive', 'allow', 'women', 'children', 'sounds', 'stuffy', 'watson', 'said', 'sherlock', 'agreed', 'mycroft', 'says', 'important', 'suppose', 'go', 'grabbed', 'coats', 'headed', 'got', 'diogenes', 'club', 'met', 'man', 'escorted', 'inside', 'club', 'everything', 'sherlock', 'said', 'would', 'stuffy', 'women', 'children', 'mycroft', 'sitting', 'chair', 'talking', 'couple', 'men', 'saw', 'sherlock', 'watson', 'gestured', 'join', 'ah', 'sherlock', 'good', 'see', 'said', 'need', 'help', 'something', 'sherlock', 'asked', 'murder', 'mycroft', 'said', 'one', 'club', 'members', 'found', 'dead', 'room', 'sherlock', 'asked', 'sir', 'wilfred', 'baskerville', 'mycroft', 'said', 'man', 'owns', 'baskerville', 'estate', 'watson', 'asked', 'mycroft', 'said', 'police', 'baffled', 'hoping', 'could', 'take', 'look', 'see', 'sherlock', 'said', 'went', 'sir', 'wilfred', 'room', 'sherlock', 'began', 'examine', 'body', 'quickly', 'deduced', 'man', 'poisoned', 'killer', 'must', 'put', 'poison', 'drink', 'said', 'sign', 'struggle', 'man', 'must', 'unaware', 'happening', 'would', 'want', 'kill', 'watson', 'asked', 'need', 'find', 'sherlock', 'said', 'began', 'question', 'club', 'members', 'one', 'seemed', 'know', 'anything', 'give', 'saw', 'man', 'walking', 'funny', 'looking', 'horse', 'odd', 'said', 'never', 'seen', 'horse', 'like', 'followed', 'man', 'watched', 'went', 'room', 'another', 'club', 'member', 'sherlock', 'waited', 'minutes', 'went', 'room', 'thought', 'might', 'find', 'said', 'killer', 'man', 'tried', 'deny', 'sherlock', 'evidence', 'guilty', 'one', 'seen', 'talking', 'sir', 'wilfred', 'earlier', 'evening', 'seen', 'walking', 'funny', 'looking', 'horse', 'sherlock', 'asked', 'could', 'possibly', 'motive', 'horse', 'man', 'said', 'always', 'making', 'fun', 'horse', 'calling', 'names', 'take', 'anymore', 'killer', 'motive', 'funny', 'looking', 'horse', 'john', 'watson', 'sitting', 'study', 'perusing', 'latest', 'edition', 'strand', 'magazine', 'heard', 'light', 'knock', 'door', 'putting', 'magazine', 'got', 'answer', 'finding', 'sherlock', 'holmes', 'standing', 'threshold', 'clutching', 'piece', 'paper', 'hand', 'watson', 'come', 'quick', 'said', 'holmes', 'eyes', 'gleaming', 'excitement', 'received', 'curious', 'letter', 'need', 'help', 'solve', 'mystery', 'watson', 'followed', 'holmes', 'back', 'flat', 'letter', 'laid', 'table', 'written', 'spidery', 'hand', 'consisted', 'nothing', 'series', 'numbers', 'make', 'watson', 'holmes', 'asked', 'eyes', 'narrowed', 'concentration', 'watson', 'shook', 'head', 'bemused', 'afraid', 'see', 'anything', 'holmes', 'come', 'come', 'watson', 'use', 'famous', 'deductive', 'brain', 'moments', 'thought', 'watson', 'idea', 'perhaps', 'code', 'sort', 'excellent', 'watson', 'always', 'cried', 'holmes', 'crack', 'code', 'sat', 'table', 'began', 'scribble', 'piece', 'paper', 'muttering', 'worked', 'watson', 'watched', 'minutes', 'feeling', 'rather', 'superfluous', 'picked', 'magazine', 'began', 'leaf', 'suddenly', 'holmes', 'leapt', 'table', 'cry', 'triumph', 'got', 'watson']","['p', 'sherlock', 'holm', 'stori', 'gptthought', 'share', 'sherlock', 'holm', 'stori', 'creat', 'variou', 'prompt', 'use', 'gpt', 'might', 'fun', 'fan', 'overal', 'stori', 'bit', 'superfici', 'although', 'made', 'laugh', 'fourth', 'one', 'particular', 'xb', 'john', 'watson', 'cup', 'tea', 'flat', 'heard', 'knock', 'door', 'got', 'answer', 'found', 'sherlock', 'holm', 'stand', 'look', 'rather', 'grave', 'watson', 'afraid', 'bad', 'news', 'said', 'sherlock', 'baker', 'street', 'found', 'mr', 'hudson', 'state', 'hyster', 'seem', 'mr', 'bartholomew', 'jone', 'found', 'dead', 'studi', 'mr', 'hudson', 'convinc', 'murder', 'rather', 'shock', 'said', 'watson', 'idea', 'might', 'done', 'suspicion', 'repli', 'sherlock', 'like', 'take', 'look', 'bodi', 'draw', 'conclus', 'would', 'kind', 'come', 'watson', 'agre', 'two', 'men', 'made', 'way', 'baker', 'street', 'found', 'mr', 'hudson', 'still', 'state', 'distress', 'led', 'studi', 'bodi', 'lie', 'immedi', 'evid', 'watson', 'ordinari', 'death', 'mr', 'jone', 'stab', 'multipl', 'time', 'look', 'terror', 'face', 'accid', 'watson', 'said', 'sherlock', 'someon', 'want', 'make', 'sure', 'mr', 'jone', 'dead', 'sherlock', 'began', 'examin', 'bodi', 'soon', 'found', 'look', 'piec', 'paper', 'hidden', 'victim', 'shirt', 'say', 'ask', 'watson', 'name', 'repli', 'sherlock', 'top', 'name', 'john', 'watson', 'good', 'heaven', 'exclaim', 'watson', 'think', 'murder', 'know', 'said', 'sherlock', 'need', 'find', 'els', 'afraid', 'go', 'rather', 'difficult', 'case', 'tell', 'john', 'baffl', 'case', 'ever', 'encount', 'realli', 'sherlock', 'special', 'well', 'one', 'thing', 'victim', 'chicken', 'chicken', 'ye', 'chicken', 'found', 'dead', 'coop', 'throat', 'slit', 'sound', 'baffl', 'sure', 'polic', 'catch', 'culprit', 'soon', 'enough', 'think', 'john', 'chicken', 'found', 'note', 'note', 'ye', 'note', 'note', 'written', 'sherlock', 'holm', 'challeng', 'solv', 'mysteri', 'culprit', 'want', 'solv', 'eh', 'bit', 'strang', 'inde', 'note', 'sign', 'moriarti', 'moriarti', 'dead', 'year', 'would', 'seem', 'feel', 'handiwork', 'make', 'say', 'well', 'one', 'thing', 'moriarti', 'master', 'disguis', 'entir', 'possibl', 'still', 'aliv', 'use', 'one', 'mani', 'alias', 'would', 'want', 'solv', 'mysteri', 'specul', 'perhap', 'bore', 'retir', 'want', 'give', 'challeng', 'perhap', 'plan', 'someth', 'bigger', 'divers', 'well', 'whatev', 'reason', 'seem', 'go', 'solv', 'mysteri', 'get', 'magnifi', 'glass', 'start', 'put', 'togeth', 'suspect', 'excel', 'feel', 'go', 'interest', 'case', 'john', 'watson', 'drift', 'sleep', 'heard', 'loud', 'crash', 'downstair', 'leapt', 'bed', 'grab', 'trusti', 'revolv', 'crept', 'downstair', 'heart', 'pound', 'chest', 'saw', 'shock', 'middl', 'live', 'room', 'huge', 'furri', 'creatur', 'stand', 'two', 'leg', 'brandish', 'knife', 'like', 'noth', 'ever', 'seen', 'could', 'think', 'creatur', 'lung', 'knife', 'rais', 'watson', 'react', 'instinct', 'fire', 'revolv', 'bullet', 'hit', 'creatur', 'chest', 'fell', 'ground', 'thud', 'watson', 'mind', 'race', 'thing', 'come', 'rememb', 'stori', 'heard', 'sherlock', 'holm', 'uncanni', 'abil', 'solv', 'bizarr', 'case', 'rush', 'phone', 'call', 'holm', 'within', 'minut', 'detect', 'way', 'holm', 'arriv', 'took', 'one', 'look', 'creatur', 'announc', 'yeti', 'mythic', 'creatur', 'himalaya', 'watson', 'dumbfound', 'could', 'holm', 'possibl', 'know', 'turn', 'yeti', 'part', 'circu', 'recent', 'come', 'town', 'circu', 'owner', 'keep', 'yeti', 'cage', 'feed', 'raw', 'meat', 'yeti', 'escap', 'terror', 'citi', 'holm', 'deduc', 'creatur', 'fur', 'mat', 'blood', 'knife', 'type', 'use', 'circu', 'perform', 'sherlock', 'holm', 'dr', 'watson', 'sit', 'usual', 'chair', 'sit', 'room', 'b', 'baker', 'street', 'suddenli', 'interrupt', 'loud', 'pierc', 'scream', 'two', 'men', 'leapt', 'feet', 'ran', 'window', 'time', 'see', 'man', 'fall', 'build', 'opposit', 'quick', 'watson', 'must', 'go', 'investig', 'cri', 'sherlock', 'holm', 'two', 'men', 'hurri', 'stair', 'street', 'found', 'crowd', 'peopl', 'gather', 'around', 'bodi', 'man', 'fallen', 'happen', 'ask', 'sherlock', 'holm', 'push', 'cri', 'woman', 'crowd', 'saw', 'eye', 'push', 'would', 'anyon', 'want', 'push', 'ask', 'watson', 'know', 'murder', 'tell', 'sherlock', 'holm', 'watson', 'push', 'way', 'crowd', 'squat', 'besid', 'bodi', 'holm', 'examin', 'close', 'watson', 'look', 'around', 'see', 'could', 'spot', 'murder', 'quit', 'clear', 'happen', 'said', 'holm', 'minut', 'victim', 'push', 'window', 'build', 'ask', 'watson', 'murder', 'must', 'build', 'come', 'watson', 'must', 'go', 'investig', 'two', 'men', 'hurri', 'across', 'street', 'enter', 'build', 'made', 'way', 'floor', 'victim', 'fallen', 'began', 'knock', 'door', 'final', 'came', 'door', 'answer', 'old', 'woman', 'want', 'ask', 'investig', 'murder', 'man', 'push', 'window', 'said', 'holm', 'oh', 'easi', 'enough', 'solv', 'said', 'woman', 'murder', 'husband', 'husband', 'ask', 'watson', 'disbelief', 'ye', 'husband', 'alway', 'want', 'push', 'someon', 'window', 'saw', 'man', 'stand', 'resist', 'ask', 'sherlock', 'holm', 'oh', 'alway', 'funni', 'man', 'ever', 'sinc', 'known', 'sherlock', 'holm', 'watson', 'exchang', 'look', 'holm', 'said', 'thank', 'help', 'way', 'say', 'john', 'make', 'sherlock', 'holm', 'look', 'express', 'mild', 'amus', 'wit', 'amus', 'incid', 'knew', 'better', 'ask', 'talk', 'simpli', 'wait', 'continu', 'read', 'paper', 'articl', 'man', 'arrest', 'tri', 'steal', 'chicken', 'farmer', 'market', 'amus', 'part', 'man', 'name', 'john', 'watson', 'must', 'look', 'startl', 'holm', 'began', 'laugh', 'ye', 'see', 'might', 'find', 'amus', 'said', 'sure', 'find', 'situat', 'humor', 'well', 'first', 'time', 'someon', 'made', 'mistak', 'think', 'involv', 'crime', 'john', 'help', 'chuckl', 'true', 'victim', 'misunderstand', 'year', 'thank', 'associ', 'sherlock', 'holm', 'peopl', 'often', 'assum', 'holm', 'investig', 'case', 'must', 'involv', 'way', 'cours', 'polic', 'quickli', 'realiz', 'wrong', 'man', 'releas', 'holm', 'continu', 'sure', 'poor', 'fellow', 'quit', 'embarrass', 'sure', 'said', 'still', 'chuckl', 'anoth', 'day', 'life', 'sherlock', 'holm', 'john', 'watson', 'day', 'fill', 'excit', 'adventur', 'occasion', 'bit', 'humour', 'tell', 'john', 'baffl', 'case', 'ever', 'encount', 'realli', 'sherlock', 'baffl', 'well', 'start', 'fact', 'victim', 'stab', 'umbrella', 'umbrella', 'sure', 'unusu', 'victim', 'cat', 'john', 'cat', 'good', 'heaven', 'sherlock', 'get', 'bizarr', 'minut', 'know', 'know', 'cat', 'also', 'wear', 'top', 'hat', 'monocl', 'top', 'hat', 'monocl', 'rather', 'unusu', 'inde', 'baffl', 'thing', 'fact', 'cat', 'found', 'room', 'lock', 'insid', 'lock', 'insid', 'possibl', 'idea', 'john', 'intend', 'find', 'case', 'certainli', 'worthi', 'attent', 'sherlock', 'holm', 'dr', 'watson', 'sit', 'usual', 'spot', 'sit', 'room', 'b', 'baker', 'street', 'knock', 'door', 'got', 'answer', 'young', 'boy', 'stand', 'hold', 'note', 'ask', 'deliv', 'sir', 'boy', 'said', 'hand', 'note', 'sherlock', 'sherlock', 'holm', 'took', 'note', 'read', 'brother', 'mycroft', 'said', 'want', 'come', 'diogen', 'club', 'diogen', 'club', 'watson', 'ask', 'club', 'brother', 'friend', 'sherlock', 'explain', 'exclus', 'allow', 'women', 'children', 'sound', 'stuffi', 'watson', 'said', 'sherlock', 'agre', 'mycroft', 'say', 'import', 'suppos', 'go', 'grab', 'coat', 'head', 'got', 'diogen', 'club', 'met', 'man', 'escort', 'insid', 'club', 'everyth', 'sherlock', 'said', 'would', 'stuffi', 'women', 'children', 'mycroft', 'sit', 'chair', 'talk', 'coupl', 'men', 'saw', 'sherlock', 'watson', 'gestur', 'join', 'ah', 'sherlock', 'good', 'see', 'said', 'need', 'help', 'someth', 'sherlock', 'ask', 'murder', 'mycroft', 'said', 'one', 'club', 'member', 'found', 'dead', 'room', 'sherlock', 'ask', 'sir', 'wilfr', 'baskervil', 'mycroft', 'said', 'man', 'own', 'baskervil', 'estat', 'watson', 'ask', 'mycroft', 'said', 'polic', 'baffl', 'hope', 'could', 'take', 'look', 'see', 'sherlock', 'said', 'went', 'sir', 'wilfr', 'room', 'sherlock', 'began', 'examin', 'bodi', 'quickli', 'deduc', 'man', 'poison', 'killer', 'must', 'put', 'poison', 'drink', 'said', 'sign', 'struggl', 'man', 'must', 'unawar', 'happen', 'would', 'want', 'kill', 'watson', 'ask', 'need', 'find', 'sherlock', 'said', 'began', 'question', 'club', 'member', 'one', 'seem', 'know', 'anyth', 'give', 'saw', 'man', 'walk', 'funni', 'look', 'hors', 'odd', 'said', 'never', 'seen', 'hors', 'like', 'follow', 'man', 'watch', 'went', 'room', 'anoth', 'club', 'member', 'sherlock', 'wait', 'minut', 'went', 'room', 'thought', 'might', 'find', 'said', 'killer', 'man', 'tri', 'deni', 'sherlock', 'evid', 'guilti', 'one', 'seen', 'talk', 'sir', 'wilfr', 'earlier', 'even', 'seen', 'walk', 'funni', 'look', 'hors', 'sherlock', 'ask', 'could', 'possibl', 'motiv', 'hors', 'man', 'said', 'alway', 'make', 'fun', 'hors', 'call', 'name', 'take', 'anymor', 'killer', 'motiv', 'funni', 'look', 'hors', 'john', 'watson', 'sit', 'studi', 'perus', 'latest', 'edit', 'strand', 'magazin', 'heard', 'light', 'knock', 'door', 'put', 'magazin', 'got', 'answer', 'find', 'sherlock', 'holm', 'stand', 'threshold', 'clutch', 'piec', 'paper', 'hand', 'watson', 'come', 'quick', 'said', 'holm', 'eye', 'gleam', 'excit', 'receiv', 'curiou', 'letter', 'need', 'help', 'solv', 'mysteri', 'watson', 'follow', 'holm', 'back', 'flat', 'letter', 'laid', 'tabl', 'written', 'spideri', 'hand', 'consist', 'noth', 'seri', 'number', 'make', 'watson', 'holm', 'ask', 'eye', 'narrow', 'concentr', 'watson', 'shook', 'head', 'bemus', 'afraid', 'see', 'anyth', 'holm', 'come', 'come', 'watson', 'use', 'famou', 'deduct', 'brain', 'moment', 'thought', 'watson', 'idea', 'perhap', 'code', 'sort', 'excel', 'watson', 'alway', 'cri', 'holm', 'crack', 'code', 'sat', 'tabl', 'began', 'scribbl', 'piec', 'paper', 'mutter', 'work', 'watson', 'watch', 'minut', 'feel', 'rather', 'superflu', 'pick', 'magazin', 'began', 'leaf', 'suddenli', 'holm', 'leapt', 'tabl', 'cri', 'triumph', 'got', 'watson']"
93,101,101,seraschka,vs1wox,"[P] No, we don't have to choose batch sizes as powers of 2","Prompted by a recent discussion on social media, I did some benchmarks and wrote down my thoughts on why it doesn't really make a difference whether we choose batch sizes as powers of 2: [https://sebastianraschka.com/blog/2022/batch-size-2.html](https://sebastianraschka.com/blog/2022/batch-size-2.html)

What is your experience, do you

do you stick to batch sizes as powers of 2 or do you choose batch sizes more freely?

notice a substantial difference when you choose batch sizes as powers of 2 (or multiples of 8)?",93,216,2022-07-05 21:59:16, p  no  we don t have to choose batch sizes as powers of ,prompted by a recent discussion on social media  i did some benchmarks and wrote down my thoughts on why it doesn t really make a difference whether we choose batch sizes as powers of    https what is your experience  do youdo you stick to batch sizes as powers of  or do you choose batch sizes more freely notice a substantial difference when you choose batch sizes as powers of   or multiples of   ,prompted recent discussion social media benchmarks wrote thoughts really make difference whether choose batch sizes powers https experience youdo stick batch sizes powers choose batch sizes freely notice substantial difference choose batch sizes powers multiples,p choose batch sizes powers,p choose batch sizes powersprompted recent discussion social media benchmarks wrote thoughts really make difference whether choose batch sizes powers https experience youdo stick batch sizes powers choose batch sizes freely notice substantial difference choose batch sizes powers multiples,"['p', 'choose', 'batch', 'sizes', 'powersprompted', 'recent', 'discussion', 'social', 'media', 'benchmarks', 'wrote', 'thoughts', 'really', 'make', 'difference', 'whether', 'choose', 'batch', 'sizes', 'powers', 'https', 'experience', 'youdo', 'stick', 'batch', 'sizes', 'powers', 'choose', 'batch', 'sizes', 'freely', 'notice', 'substantial', 'difference', 'choose', 'batch', 'sizes', 'powers', 'multiples']","['p', 'choos', 'batch', 'size', 'powersprompt', 'recent', 'discuss', 'social', 'media', 'benchmark', 'wrote', 'thought', 'realli', 'make', 'differ', 'whether', 'choos', 'batch', 'size', 'power', 'http', 'experi', 'youdo', 'stick', 'batch', 'size', 'power', 'choos', 'batch', 'size', 'freeli', 'notic', 'substanti', 'differ', 'choos', 'batch', 'size', 'power', 'multipl']"
94,102,102,MLJungle,vt10ec,[D] Handling OOV in sequence generation,"What are some methods to handle OOV words when generating sequences? 

For example for some n-gram implementations, I've seen all <UNK> tokens removed from the candidate list of words to be sampled from given the prior n-gram, and if there are no other candidates the generated text is ended.

Curious to learn about some other methods to deal with OOV.",2,1,2022-07-07 02:54:49, d  handling oov in sequence generation,what are some methods to handle oov words when generating sequences  for example for some n gram implementations  i ve seen all  tokens removed from the candidate list of words to be sampled from given the prior n gram  and if there are no other candidates the generated text is ended curious to learn about some other methods to deal with oov ,methods handle oov generating sequences example n gram implementations seen tokens removed candidate sampled given prior n gram candidates generated text ended curious learn methods deal oov,handling oov sequence generation,handling oov sequence generationmethods handle oov generating sequences example n gram implementations seen tokens removed candidate sampled given prior n gram candidates generated text ended curious learn methods deal oov,"['handling', 'oov', 'sequence', 'generationmethods', 'handle', 'oov', 'generating', 'sequences', 'example', 'n', 'gram', 'implementations', 'seen', 'tokens', 'removed', 'candidate', 'sampled', 'given', 'prior', 'n', 'gram', 'candidates', 'generated', 'text', 'ended', 'curious', 'learn', 'methods', 'deal', 'oov']","['handl', 'oov', 'sequenc', 'generationmethod', 'handl', 'oov', 'gener', 'sequenc', 'exampl', 'n', 'gram', 'implement', 'seen', 'token', 'remov', 'candid', 'sampl', 'given', 'prior', 'n', 'gram', 'candid', 'gener', 'text', 'end', 'curiou', 'learn', 'method', 'deal', 'oov']"
95,103,103,SeucheAchat9115,vsv3wc,[D] How to correctly transform Cityscapes Masks to Bounding Boxes?,"As the title suggests, I would like to know the correct way to pre-process the cityscapes dataset for object detection. There are multiple ways how this can be done. There is a version in Detectron2, in MM Detection, there is [this](https://tillbeemelmanns.github.io/2020/10/10/convert-cityscapes-to-coco-dataset-format.html). Which one is the correct way, without getting errors in the labels? Anybody worked with this before? Would be glad if anybody might have an idea.",2,0,2022-07-06 22:43:18, d  how to correctly transform cityscapes masks to bounding boxes ,as the title suggests  i would like to know the correct way to pre process the cityscapes dataset for object detection  there are multiple ways how this can be done  there is a version in detectron  in mm detection  there is  this  https   tillbeemelmanns github io    convert cityscapes to coco dataset format html   which one is the correct way  without getting errors in the labels  anybody worked with this before  would be glad if anybody might have an idea ,title suggests would like know correct way pre process cityscapes dataset object detection multiple ways done version detectron mm detection https tillbeemelmanns github io convert cityscapes coco dataset format html one correct way without getting errors labels anybody worked would glad anybody might idea,correctly transform cityscapes masks bounding boxes,correctly transform cityscapes masks bounding boxestitle suggests would like know correct way pre process cityscapes dataset object detection multiple ways done version detectron mm detection https tillbeemelmanns github io convert cityscapes coco dataset format html one correct way without getting errors labels anybody worked would glad anybody might idea,"['correctly', 'transform', 'cityscapes', 'masks', 'bounding', 'boxestitle', 'suggests', 'would', 'like', 'know', 'correct', 'way', 'pre', 'process', 'cityscapes', 'dataset', 'object', 'detection', 'multiple', 'ways', 'done', 'version', 'detectron', 'mm', 'detection', 'https', 'tillbeemelmanns', 'github', 'io', 'convert', 'cityscapes', 'coco', 'dataset', 'format', 'html', 'one', 'correct', 'way', 'without', 'getting', 'errors', 'labels', 'anybody', 'worked', 'would', 'glad', 'anybody', 'might', 'idea']","['correctli', 'transform', 'cityscap', 'mask', 'bound', 'boxestitl', 'suggest', 'would', 'like', 'know', 'correct', 'way', 'pre', 'process', 'cityscap', 'dataset', 'object', 'detect', 'multipl', 'way', 'done', 'version', 'detectron', 'mm', 'detect', 'http', 'tillbeemelmann', 'github', 'io', 'convert', 'cityscap', 'coco', 'dataset', 'format', 'html', 'one', 'correct', 'way', 'without', 'get', 'error', 'label', 'anybodi', 'work', 'would', 'glad', 'anybodi', 'might', 'idea']"
96,104,104,lklimusheuskaja,vspgsa,[R] How Machine Learning is Used in Finance and Banking,"Machine learning solutions are already embedded in the finance and banking industry. In this article, we reviewed the most popular use cases of ML in banking and shared practical tips on how to implement it into your business.[https://exadel.com/news/how-machine-learning-is-used-in-finance-and-banking](https://exadel.com/news/how-machine-learning-is-used-in-finance-and-banking)",5,2,2022-07-06 18:29:57, r  how machine learning is used in finance and banking,machine learning solutions are already embedded in the finance and banking industry  in this article  we reviewed the most popular use cases of ml in banking and shared practical tips on how to implement it into your business  https   exadel com news how machine learning is used in finance and banking  https   exadel com news how machine learning is used in finance and banking ,machine learning solutions already embedded finance banking industry article reviewed popular use cases ml banking shared practical tips implement business https exadel com news machine learning used finance banking https exadel com news machine learning used finance banking,r machine learning used finance banking,r machine learning used finance bankingmachine learning solutions already embedded finance banking industry article reviewed popular use cases ml banking shared practical tips implement business https exadel com news machine learning used finance banking https exadel com news machine learning used finance banking,"['r', 'machine', 'learning', 'used', 'finance', 'bankingmachine', 'learning', 'solutions', 'already', 'embedded', 'finance', 'banking', 'industry', 'article', 'reviewed', 'popular', 'use', 'cases', 'ml', 'banking', 'shared', 'practical', 'tips', 'implement', 'business', 'https', 'exadel', 'com', 'news', 'machine', 'learning', 'used', 'finance', 'banking', 'https', 'exadel', 'com', 'news', 'machine', 'learning', 'used', 'finance', 'banking']","['r', 'machin', 'learn', 'use', 'financ', 'bankingmachin', 'learn', 'solut', 'alreadi', 'embed', 'financ', 'bank', 'industri', 'articl', 'review', 'popular', 'use', 'case', 'ml', 'bank', 'share', 'practic', 'tip', 'implement', 'busi', 'http', 'exadel', 'com', 'news', 'machin', 'learn', 'use', 'financ', 'bank', 'http', 'exadel', 'com', 'news', 'machin', 'learn', 'use', 'financ', 'bank']"
97,105,105,htahir1,vsufhh,[P] Tutorial: Serverless MLOps pipelines with Vertex AI and ZenML,"At ZenML, we created a guide to easily run MLOps pipelines on Google Cloud Platform with Vertex AI. I thought I'd share it here because I think it might be useful for people who are just starting MLOps on GCP.

**Blog post**: [https://blog.zenml.io/vertex-ai-blog/](https://blog.zenml.io/vertex-ai-blog/) 

**Full video**:  [https://youtu.be/qgvmvexGv\_c](https://youtu.be/qgvmvexGv_c) 

  
Why is this better than going through the Vertex AI SDK?

* ZenML steps and pipeline can be written with a simple decorator pattern that is easily approachable for a [\#datascientist](https://www.linkedin.com/feed/hashtag/?keywords=datascientist&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6950398009234894848).
* ZenML takes cares of storing and versioning pythonic objects between steps of a 
* ZenML provides first-class integrations into other MLOps tools that you can leverage natively in your pipelines. For example, you can track experiments on MLFlow easily.
* ZenML pipelines can be run locally first, and then deployed instantly.
* You can run a ZenML pipeline not only on Vertex, but also [\#Airflow](https://www.linkedin.com/feed/hashtag/?keywords=airflow&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6950398009234894848), [\#Kubeflow](https://www.linkedin.com/feed/hashtag/?keywords=kubeflow&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6950398009234894848), [\#Kubernetes](https://www.linkedin.com/feed/hashtag/?keywords=kubernetes&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6950398009234894848), or whereever else you'd like!📷Watch the full video: [https://www.youtube.com/watch?v=qgvmvexGv\_c&ab\_channel=ZenML](https://www.youtube.com/watch?v=qgvmvexGv_c&ab_channel=ZenML)

I bet the GCP Vertex AI folk here might like the above video. It isn't just about ZenML either but more of a broader look into the different components that go into running ML in production on GCP (Container registry, Cloud Storage, Secret Manager, Vertex, Cloud SQL)

Would love to hear more feedback on the video or blog!",0,0,2022-07-06 22:14:22, p  tutorial  serverless mlops pipelines with vertex ai and zenml,at zenml  we created a guide to easily run mlops pipelines on google cloud platform with vertex ai  i thought i d share it here because i think it might be useful for people who are just starting mlops on gcp   blog post     https   full video      https   why is this better than going through the vertex ai sdk   zenml steps and pipeline can be written with a simple decorator pattern that is easily approachable for a    datascientist  https   zenml takes cares of storing and versioning pythonic objects between steps of a   zenml provides first class integrations into other mlops tools that you can leverage natively in your pipelines  for example  you can track experiments on mlflow easily   zenml pipelines can be run locally first  and then deployed instantly   you can run a zenml pipeline not only on vertex  but also    airflow  https i bet the gcp vertex ai folk here might like the above video  it isn t just about zenml either but more of a broader look into the different components that go into running ml in production on gcp  container registry  cloud storage  secret manager  vertex  cloud sql would love to hear more feedback on the video or blog ,zenml created guide easily run mlops pipelines google cloud platform vertex ai thought share think might useful people starting mlops gcp blog post https full video https better going vertex ai sdk zenml steps pipeline written simple decorator pattern easily approachable datascientist https zenml takes cares storing versioning pythonic objects steps zenml provides first class integrations mlops tools leverage natively pipelines example track experiments mlflow easily zenml pipelines run locally first deployed instantly run zenml pipeline vertex also airflow https bet gcp vertex ai folk might like video zenml either broader look different components go running ml production gcp container registry cloud storage secret manager vertex cloud sql would love hear feedback video blog,p tutorial serverless mlops pipelines vertex ai zenml,p tutorial serverless mlops pipelines vertex ai zenmlzenml created guide easily run mlops pipelines google cloud platform vertex ai thought share think might useful people starting mlops gcp blog post https full video https better going vertex ai sdk zenml steps pipeline written simple decorator pattern easily approachable datascientist https zenml takes cares storing versioning pythonic objects steps zenml provides first class integrations mlops tools leverage natively pipelines example track experiments mlflow easily zenml pipelines run locally first deployed instantly run zenml pipeline vertex also airflow https bet gcp vertex ai folk might like video zenml either broader look different components go running ml production gcp container registry cloud storage secret manager vertex cloud sql would love hear feedback video blog,"['p', 'tutorial', 'serverless', 'mlops', 'pipelines', 'vertex', 'ai', 'zenmlzenml', 'created', 'guide', 'easily', 'run', 'mlops', 'pipelines', 'google', 'cloud', 'platform', 'vertex', 'ai', 'thought', 'share', 'think', 'might', 'useful', 'people', 'starting', 'mlops', 'gcp', 'blog', 'post', 'https', 'full', 'video', 'https', 'better', 'going', 'vertex', 'ai', 'sdk', 'zenml', 'steps', 'pipeline', 'written', 'simple', 'decorator', 'pattern', 'easily', 'approachable', 'datascientist', 'https', 'zenml', 'takes', 'cares', 'storing', 'versioning', 'pythonic', 'objects', 'steps', 'zenml', 'provides', 'first', 'class', 'integrations', 'mlops', 'tools', 'leverage', 'natively', 'pipelines', 'example', 'track', 'experiments', 'mlflow', 'easily', 'zenml', 'pipelines', 'run', 'locally', 'first', 'deployed', 'instantly', 'run', 'zenml', 'pipeline', 'vertex', 'also', 'airflow', 'https', 'bet', 'gcp', 'vertex', 'ai', 'folk', 'might', 'like', 'video', 'zenml', 'either', 'broader', 'look', 'different', 'components', 'go', 'running', 'ml', 'production', 'gcp', 'container', 'registry', 'cloud', 'storage', 'secret', 'manager', 'vertex', 'cloud', 'sql', 'would', 'love', 'hear', 'feedback', 'video', 'blog']","['p', 'tutori', 'serverless', 'mlop', 'pipelin', 'vertex', 'ai', 'zenmlzenml', 'creat', 'guid', 'easili', 'run', 'mlop', 'pipelin', 'googl', 'cloud', 'platform', 'vertex', 'ai', 'thought', 'share', 'think', 'might', 'use', 'peopl', 'start', 'mlop', 'gcp', 'blog', 'post', 'http', 'full', 'video', 'http', 'better', 'go', 'vertex', 'ai', 'sdk', 'zenml', 'step', 'pipelin', 'written', 'simpl', 'decor', 'pattern', 'easili', 'approach', 'datascientist', 'http', 'zenml', 'take', 'care', 'store', 'version', 'python', 'object', 'step', 'zenml', 'provid', 'first', 'class', 'integr', 'mlop', 'tool', 'leverag', 'nativ', 'pipelin', 'exampl', 'track', 'experi', 'mlflow', 'easili', 'zenml', 'pipelin', 'run', 'local', 'first', 'deploy', 'instantli', 'run', 'zenml', 'pipelin', 'vertex', 'also', 'airflow', 'http', 'bet', 'gcp', 'vertex', 'ai', 'folk', 'might', 'like', 'video', 'zenml', 'either', 'broader', 'look', 'differ', 'compon', 'go', 'run', 'ml', 'product', 'gcp', 'contain', 'registri', 'cloud', 'storag', 'secret', 'manag', 'vertex', 'cloud', 'sql', 'would', 'love', 'hear', 'feedback', 'video', 'blog']"
98,106,106,EUMETSAT,vsovth,Jupyter Notebook Competition coming up! [News],"The Jupyter Notebook Competition deadline is fast approaching!

https://preview.redd.it/gy6m0myhyx991.png?width=1920&format=png&auto=webp&s=3039abe962df07df74740772994f17502fa686bb

Don't miss out on your chance to contribute to a community-driven resource of notebooks on the Copernicus WEkEO platform, AND be in with a chance of winning cash prizes! 

Visit: [https://www.eumetsat.int/features/new-jupyter-notebook-competition](https://www.eumetsat.int/features/new-jupyter-notebook-competition)",0,2,2022-07-06 17:59:18,jupyter notebook competition coming up   news ,the jupyter notebook competition deadline is fast approaching https don t miss out on your chance to contribute to a community driven resource of notebooks on the copernicus wekeo platform  and be in with a chance of winning cash prizes  visit   https   www eumetsat int features new jupyter notebook competition  https   www eumetsat int features new jupyter notebook competition ,jupyter notebook competition deadline fast approaching https miss chance contribute community driven resource notebooks copernicus wekeo platform chance winning cash prizes visit https www eumetsat int features jupyter notebook competition https www eumetsat int features jupyter notebook competition,jupyter notebook competition coming news,jupyter notebook competition coming newsjupyter notebook competition deadline fast approaching https miss chance contribute community driven resource notebooks copernicus wekeo platform chance winning cash prizes visit https www eumetsat int features jupyter notebook competition https www eumetsat int features jupyter notebook competition,"['jupyter', 'notebook', 'competition', 'coming', 'newsjupyter', 'notebook', 'competition', 'deadline', 'fast', 'approaching', 'https', 'miss', 'chance', 'contribute', 'community', 'driven', 'resource', 'notebooks', 'copernicus', 'wekeo', 'platform', 'chance', 'winning', 'cash', 'prizes', 'visit', 'https', 'www', 'eumetsat', 'int', 'features', 'jupyter', 'notebook', 'competition', 'https', 'www', 'eumetsat', 'int', 'features', 'jupyter', 'notebook', 'competition']","['jupyt', 'notebook', 'competit', 'come', 'newsjupyt', 'notebook', 'competit', 'deadlin', 'fast', 'approach', 'http', 'miss', 'chanc', 'contribut', 'commun', 'driven', 'resourc', 'notebook', 'copernicu', 'wekeo', 'platform', 'chanc', 'win', 'cash', 'prize', 'visit', 'http', 'www', 'eumetsat', 'int', 'featur', 'jupyt', 'notebook', 'competit', 'http', 'www', 'eumetsat', 'int', 'featur', 'jupyt', 'notebook', 'competit']"
99,107,107,1_like_science,vsb2zt,[R] Automated Taxonomic Identification of Insects with Expert-Level Accuracy Using Effective Feature Transfer from Convolutional Networks,"An interesting article in the Systematic Biology journal about identifying insects: https://academic.oup.com/sysbio/article/68/6/876/5368535

See as well: [Deep learning and computer vision will transform entomology](https://www.pnas.org/doi/10.1073/pnas.2002545117)",0,13,2022-07-06 04:43:19, r  automated taxonomic identification of insects with expert level accuracy using effective feature transfer from convolutional networks,an interesting article in the systematic biology journal about identifying insects  https see as well   deep learning and computer vision will transform entomology  https   www pnas org doi   pnas  ,interesting article systematic biology journal identifying insects https see well deep learning computer vision transform entomology https www pnas org doi pnas,r automated taxonomic identification insects expert level accuracy using effective feature transfer convolutional networks,r automated taxonomic identification insects expert level accuracy using effective feature transfer convolutional networksinteresting article systematic biology journal identifying insects https see well deep learning computer vision transform entomology https www pnas org doi pnas,"['r', 'automated', 'taxonomic', 'identification', 'insects', 'expert', 'level', 'accuracy', 'using', 'effective', 'feature', 'transfer', 'convolutional', 'networksinteresting', 'article', 'systematic', 'biology', 'journal', 'identifying', 'insects', 'https', 'see', 'well', 'deep', 'learning', 'computer', 'vision', 'transform', 'entomology', 'https', 'www', 'pnas', 'org', 'doi', 'pnas']","['r', 'autom', 'taxonom', 'identif', 'insect', 'expert', 'level', 'accuraci', 'use', 'effect', 'featur', 'transfer', 'convolut', 'networksinterest', 'articl', 'systemat', 'biolog', 'journal', 'identifi', 'insect', 'http', 'see', 'well', 'deep', 'learn', 'comput', 'vision', 'transform', 'entomolog', 'http', 'www', 'pna', 'org', 'doi', 'pna']"
100,108,108,DoruSonic,vruyyi,[P] Using transformers for time-series forecasting,"I'm currently using different machine learning techniques on a time series and testing their forecast performance. This dataset has both an independent variable and exploratory variables.

I've used LSTM on python to forecast and was searching for more recent techniques and found transformers. They seem to have been developed for NLP but have been used for time-series forecasts

How well do these transformers perform and is there any resources / library I should look into?

EDIT: the data I'll be using is of daily periodicity without weekends. It will have 2+ years of observations (currently working with 3 years and some other datasets have longer periods but ""worse"" information)",34,105,2022-07-05 16:14:06, p  using transformers for time series forecasting,i m currently using different machine learning techniques on a time series and testing their forecast performance  this dataset has both an independent variable and exploratory variables i ve used lstm on python to forecast and was searching for more recent techniques and found transformers  they seem to have been developed for nlp but have been used for time series forecastshow well do these transformers perform and is there any resources   library i should look into edit  the data i ll be using is of daily periodicity without weekends  it will have   years of observations  currently working with  years and some other datasets have longer periods but worse information ,currently using different machine learning techniques time series testing forecast performance dataset independent variable exploratory variables used lstm python forecast searching recent techniques found transformers seem developed nlp used time series forecastshow well transformers perform resources library look edit data using daily periodicity without weekends years observations currently working years datasets longer periods worse information,p using transformers time series forecasting,p using transformers time series forecastingcurrently using different machine learning techniques time series testing forecast performance dataset independent variable exploratory variables used lstm python forecast searching recent techniques found transformers seem developed nlp used time series forecastshow well transformers perform resources library look edit data using daily periodicity without weekends years observations currently working years datasets longer periods worse information,"['p', 'using', 'transformers', 'time', 'series', 'forecastingcurrently', 'using', 'different', 'machine', 'learning', 'techniques', 'time', 'series', 'testing', 'forecast', 'performance', 'dataset', 'independent', 'variable', 'exploratory', 'variables', 'used', 'lstm', 'python', 'forecast', 'searching', 'recent', 'techniques', 'found', 'transformers', 'seem', 'developed', 'nlp', 'used', 'time', 'series', 'forecastshow', 'well', 'transformers', 'perform', 'resources', 'library', 'look', 'edit', 'data', 'using', 'daily', 'periodicity', 'without', 'weekends', 'years', 'observations', 'currently', 'working', 'years', 'datasets', 'longer', 'periods', 'worse', 'information']","['p', 'use', 'transform', 'time', 'seri', 'forecastingcurr', 'use', 'differ', 'machin', 'learn', 'techniqu', 'time', 'seri', 'test', 'forecast', 'perform', 'dataset', 'independ', 'variabl', 'exploratori', 'variabl', 'use', 'lstm', 'python', 'forecast', 'search', 'recent', 'techniqu', 'found', 'transform', 'seem', 'develop', 'nlp', 'use', 'time', 'seri', 'forecastshow', 'well', 'transform', 'perform', 'resourc', 'librari', 'look', 'edit', 'data', 'use', 'daili', 'period', 'without', 'weekend', 'year', 'observ', 'current', 'work', 'year', 'dataset', 'longer', 'period', 'wors', 'inform']"
101,109,109,TrPhantom8,vrxpk8,[P] Concrete dropout implementation for tensorflow 2.0,"Hello everyone! I updated the concrete dropout implementation from the original authors to work with tensorflow 2.0, tweaked the code a bit and turned it into a pip package! If you are interested, you can find it at pypi by sarching ""concretedropout"". There is also a link in the comments.

For those of you who don't know what concrete dropout is, it's a technique which allows for the training of the dropout probability in a layer, which may save a lot of time since it removes the need to grid search for the best dropout parameters.

For more information, see the original paper:  arXiv:1705.07832",5,24,2022-07-05 18:50:04, p  concrete dropout implementation for tensorflow  ,hello everyone  i updated the concrete dropout implementation from the original authors to work with tensorflow    tweaked the code a bit and turned it into a pip package  if you are interested  you can find it at pypi by sarching concretedropout  there is also a link in the comments for those of you who don t know what concrete dropout is  it s a technique which allows for the training of the dropout probability in a layer  which may save a lot of time since it removes the need to grid search for the best dropout parameters for more information  see the original paper   arxiv  ,hello everyone updated concrete dropout implementation original authors work tensorflow tweaked code bit turned pip package interested find pypi sarching concretedropout also link comments know concrete dropout technique allows training dropout probability layer may save lot time since removes need grid search best dropout parameters information see original paper arxiv,p concrete dropout implementation tensorflow,p concrete dropout implementation tensorflowhello everyone updated concrete dropout implementation original authors work tensorflow tweaked code bit turned pip package interested find pypi sarching concretedropout also link comments know concrete dropout technique allows training dropout probability layer may save lot time since removes need grid search best dropout parameters information see original paper arxiv,"['p', 'concrete', 'dropout', 'implementation', 'tensorflowhello', 'everyone', 'updated', 'concrete', 'dropout', 'implementation', 'original', 'authors', 'work', 'tensorflow', 'tweaked', 'code', 'bit', 'turned', 'pip', 'package', 'interested', 'find', 'pypi', 'sarching', 'concretedropout', 'also', 'link', 'comments', 'know', 'concrete', 'dropout', 'technique', 'allows', 'training', 'dropout', 'probability', 'layer', 'may', 'save', 'lot', 'time', 'since', 'removes', 'need', 'grid', 'search', 'best', 'dropout', 'parameters', 'information', 'see', 'original', 'paper', 'arxiv']","['p', 'concret', 'dropout', 'implement', 'tensorflowhello', 'everyon', 'updat', 'concret', 'dropout', 'implement', 'origin', 'author', 'work', 'tensorflow', 'tweak', 'code', 'bit', 'turn', 'pip', 'packag', 'interest', 'find', 'pypi', 'sarch', 'concretedropout', 'also', 'link', 'comment', 'know', 'concret', 'dropout', 'techniqu', 'allow', 'train', 'dropout', 'probabl', 'layer', 'may', 'save', 'lot', 'time', 'sinc', 'remov', 'need', 'grid', 'search', 'best', 'dropout', 'paramet', 'inform', 'see', 'origin', 'paper', 'arxiv']"
102,110,110,scb_11,vsk01s,[P] Comparing DevOps into MLOps to analyse tools doing well in the market,"Hi all, 

I've been an active practitioner in Deep Learning and then wanted to build something in MLOps. 

So wanted to dig deeper in how DevOps evolved and wanted to check if MLOps can take the same path.

The findings are really great. Absolutely every tool doing well in the market is a clear replacement for DevOps tool in MLOps. 

Here is my blog on it. Looking for feedback. If you have any comments, let me know. Will add them.

[https://sachinchandra.substack.com/p/bringing-software-development-principles](https://sachinchandra.substack.com/p/bringing-software-development-principles)",2,0,2022-07-06 12:46:21, p  comparing devops into mlops to analyse tools doing well in the market,hi all  i ve been an active practitioner in deep learning and then wanted to build something in mlops  so wanted to dig deeper in how devops evolved and wanted to check if mlops can take the same path the findings are really great  absolutely every tool doing well in the market is a clear replacement for devops tool in mlops  here is my blog on it  looking for feedback  if you have any comments  let me know  will add them  https   sachinchandra substack com p bringing software development principles  https   sachinchandra substack com p bringing software development principles ,hi active practitioner deep learning wanted build something mlops wanted dig deeper devops evolved wanted check mlops take path findings really great absolutely every tool well market clear replacement devops tool mlops blog looking feedback comments let know https sachinchandra substack com p bringing software development principles https sachinchandra substack com p bringing software development principles,p comparing devops mlops analyse tools well market,p comparing devops mlops analyse tools well markethi active practitioner deep learning wanted build something mlops wanted dig deeper devops evolved wanted check mlops take path findings really great absolutely every tool well market clear replacement devops tool mlops blog looking feedback comments let know https sachinchandra substack com p bringing software development principles https sachinchandra substack com p bringing software development principles,"['p', 'comparing', 'devops', 'mlops', 'analyse', 'tools', 'well', 'markethi', 'active', 'practitioner', 'deep', 'learning', 'wanted', 'build', 'something', 'mlops', 'wanted', 'dig', 'deeper', 'devops', 'evolved', 'wanted', 'check', 'mlops', 'take', 'path', 'findings', 'really', 'great', 'absolutely', 'every', 'tool', 'well', 'market', 'clear', 'replacement', 'devops', 'tool', 'mlops', 'blog', 'looking', 'feedback', 'comments', 'let', 'know', 'https', 'sachinchandra', 'substack', 'com', 'p', 'bringing', 'software', 'development', 'principles', 'https', 'sachinchandra', 'substack', 'com', 'p', 'bringing', 'software', 'development', 'principles']","['p', 'compar', 'devop', 'mlop', 'analys', 'tool', 'well', 'markethi', 'activ', 'practition', 'deep', 'learn', 'want', 'build', 'someth', 'mlop', 'want', 'dig', 'deeper', 'devop', 'evolv', 'want', 'check', 'mlop', 'take', 'path', 'find', 'realli', 'great', 'absolut', 'everi', 'tool', 'well', 'market', 'clear', 'replac', 'devop', 'tool', 'mlop', 'blog', 'look', 'feedback', 'comment', 'let', 'know', 'http', 'sachinchandra', 'substack', 'com', 'p', 'bring', 'softwar', 'develop', 'principl', 'http', 'sachinchandra', 'substack', 'com', 'p', 'bring', 'softwar', 'develop', 'principl']"
103,111,111,mkeySeraSera,vrv57z,[D] Looking for a fast OCR repo,"Currently,  we use google as our OCR service provider, but we've had already some  serious issues with them and their customer support is terrible.  Therefore we would like to change and move away from third-party providers in general.  
By now we have a sufficient amount of data to train our own OCR model, therefore I am looking for a custom fine-tunable model that is fast/accurate.  
I've found PaddleOCR and mmocr, but their inference speed for documents like invoices on CPU is quite slow (10s/page on my computer).  I'm looking for something in the 1s/page range, similar to google's OCR. We probably don't need all the power and language knowledge these libraries provide, as we only operate on documents in mainly 4 Latin languages.

Does anybody know a good starting point?",16,10,2022-07-05 16:26:03, d  looking for a fast ocr repo,currently   we use google as our ocr service provider  but we ve had already some  serious issues with them and their customer support is terrible   therefore we would like to change and move away from third party providers in general   by now we have a sufficient amount of data to train our own ocr model  therefore i am looking for a custom fine tunable model that is fast accurate   i ve found paddleocr and mmocr  but their inference speed for documents like invoices on cpu is quite slow  s page on my computer    i m looking for something in the s page range  similar to google s ocr  we probably don t need all the power and language knowledge these libraries provide  as we only operate on documents in mainly  latin languages does anybody know a good starting point ,currently use google ocr service provider already serious issues customer support terrible therefore would like change move away third party providers general sufficient amount data train ocr model therefore looking fine tunable model fast accurate found paddleocr mmocr inference speed documents like invoices cpu quite slow page computer looking something page range similar google ocr probably need power language knowledge libraries provide operate documents mainly latin languages anybody know good starting point,looking fast ocr repo,looking fast ocr repocurrently use google ocr service provider already serious issues customer support terrible therefore would like change move away third party providers general sufficient amount data train ocr model therefore looking fine tunable model fast accurate found paddleocr mmocr inference speed documents like invoices cpu quite slow page computer looking something page range similar google ocr probably need power language knowledge libraries provide operate documents mainly latin languages anybody know good starting point,"['looking', 'fast', 'ocr', 'repocurrently', 'use', 'google', 'ocr', 'service', 'provider', 'already', 'serious', 'issues', 'customer', 'support', 'terrible', 'therefore', 'would', 'like', 'change', 'move', 'away', 'third', 'party', 'providers', 'general', 'sufficient', 'amount', 'data', 'train', 'ocr', 'model', 'therefore', 'looking', 'fine', 'tunable', 'model', 'fast', 'accurate', 'found', 'paddleocr', 'mmocr', 'inference', 'speed', 'documents', 'like', 'invoices', 'cpu', 'quite', 'slow', 'page', 'computer', 'looking', 'something', 'page', 'range', 'similar', 'google', 'ocr', 'probably', 'need', 'power', 'language', 'knowledge', 'libraries', 'provide', 'operate', 'documents', 'mainly', 'latin', 'languages', 'anybody', 'know', 'good', 'starting', 'point']","['look', 'fast', 'ocr', 'repocurr', 'use', 'googl', 'ocr', 'servic', 'provid', 'alreadi', 'seriou', 'issu', 'custom', 'support', 'terribl', 'therefor', 'would', 'like', 'chang', 'move', 'away', 'third', 'parti', 'provid', 'gener', 'suffici', 'amount', 'data', 'train', 'ocr', 'model', 'therefor', 'look', 'fine', 'tunabl', 'model', 'fast', 'accur', 'found', 'paddleocr', 'mmocr', 'infer', 'speed', 'document', 'like', 'invoic', 'cpu', 'quit', 'slow', 'page', 'comput', 'look', 'someth', 'page', 'rang', 'similar', 'googl', 'ocr', 'probabl', 'need', 'power', 'languag', 'knowledg', 'librari', 'provid', 'oper', 'document', 'mainli', 'latin', 'languag', 'anybodi', 'know', 'good', 'start', 'point']"
104,112,112,projekt_treadstone,vsa2vo,[D] Extracting predicate to apply formal logic rules in autonomous driving dataset or CARLA simulator,"In the formal logic based autonomous driving dataset, we have a set of rules usually written in First order logic or temporal logic . But to apply the rules, we need to extract the predicate from perception system. For example, how to attach the predicate like *standing\_at\_intersection* with the perception scene obtained from AD dataset like Lyft or Argoverse  or CARLA simulator. So that I can apply rules on those specific scenario. I could not find any papers or explanation, which explains how to connect  the predicate in formal logic and match the connecting predicate with the dataset scene interpretation.

Any help is appreciated or links to resource.",0,0,2022-07-06 03:57:03, d  extracting predicate to apply formal logic rules in autonomous driving dataset or carla simulator,in the formal logic based autonomous driving dataset  we have a set of rules usually written in first order logic or temporal logic   but to apply the rules  we need to extract the predicate from perception system  for example  how to attach the predicate like  standing _at _intersection  with the perception scene obtained from ad dataset like lyft or argoverse  or carla simulator  so that i can apply rules on those specific scenario  i could not find any papers or explanation  which explains how to connect  the predicate in formal logic and match the connecting predicate with the dataset scene interpretation any help is appreciated or links to resource ,formal logic based autonomous driving dataset set rules usually written first order logic temporal logic apply rules need extract predicate perception system example attach predicate like standing _at _intersection perception scene obtained ad dataset like lyft argoverse carla simulator apply rules specific scenario could find papers explanation explains connect predicate formal logic match connecting predicate dataset scene interpretation help appreciated links resource,extracting predicate apply formal logic rules autonomous driving dataset carla simulator,extracting predicate apply formal logic rules autonomous driving dataset carla simulatorformal logic based autonomous driving dataset set rules usually written first order logic temporal logic apply rules need extract predicate perception system example attach predicate like standing _at _intersection perception scene obtained ad dataset like lyft argoverse carla simulator apply rules specific scenario could find papers explanation explains connect predicate formal logic match connecting predicate dataset scene interpretation help appreciated links resource,"['extracting', 'predicate', 'apply', 'formal', 'logic', 'rules', 'autonomous', 'driving', 'dataset', 'carla', 'simulatorformal', 'logic', 'based', 'autonomous', 'driving', 'dataset', 'set', 'rules', 'usually', 'written', 'first', 'order', 'logic', 'temporal', 'logic', 'apply', 'rules', 'need', 'extract', 'predicate', 'perception', 'system', 'example', 'attach', 'predicate', 'like', 'standing', '_at', '_intersection', 'perception', 'scene', 'obtained', 'ad', 'dataset', 'like', 'lyft', 'argoverse', 'carla', 'simulator', 'apply', 'rules', 'specific', 'scenario', 'could', 'find', 'papers', 'explanation', 'explains', 'connect', 'predicate', 'formal', 'logic', 'match', 'connecting', 'predicate', 'dataset', 'scene', 'interpretation', 'help', 'appreciated', 'links', 'resource']","['extract', 'predic', 'appli', 'formal', 'logic', 'rule', 'autonom', 'drive', 'dataset', 'carla', 'simulatorform', 'logic', 'base', 'autonom', 'drive', 'dataset', 'set', 'rule', 'usual', 'written', 'first', 'order', 'logic', 'tempor', 'logic', 'appli', 'rule', 'need', 'extract', 'predic', 'percept', 'system', 'exampl', 'attach', 'predic', 'like', 'stand', '_at', '_intersect', 'percept', 'scene', 'obtain', 'ad', 'dataset', 'like', 'lyft', 'argovers', 'carla', 'simul', 'appli', 'rule', 'specif', 'scenario', 'could', 'find', 'paper', 'explan', 'explain', 'connect', 'predic', 'formal', 'logic', 'match', 'connect', 'predic', 'dataset', 'scene', 'interpret', 'help', 'appreci', 'link', 'resourc']"
105,113,113,Travolta1984,vs4la9,[P] Reward function as a way to represent multiple targets,"I've been assigned at work a problem with multiple targets, and I've been thinking about what's the best to design a model that would optimize towards all these targets. An idea that occurred me is to create a reward function that would ""encapsulate"" all these targets in such a way where, the higher the reward, the better the outcome is for all the targets. 

In my case, it's a task distribution system where the workers have the option to decline a task if for whatever reason the task doesn't suit them, and one of my targets is to minimize the number of declines. But we also need to make sure the workload is balanced, and we are not overwhelming someone while under-utilizing the rest of the team; that would be my second target, and we can use the standard deviation as a way to measure the workload balance (the closer to 0 the std is, the better).

Essentially, the targets we want to optimize towards are, reduce the number of declines, and also reduce the std of the overall task distribution. 

So, my reward function could be:

\- score 0 if the task is declined;

\- if the task is accepted, then I can take the delta of the std before and after. The bigger the delta, the more std was reduced, so the more even the distribution became.

That way, the reward score would in a way represent both my targets (and would be the labels), and then it's simply a matter of training a regression model. Then for a new task, I predict the reward score for each task and worker, and finally assign the tasks by taking the argmax of the predicted scores.

I know that rewards are popular in the RL field, but this wouldn't be necessarily a RL problem. In fact, I googled this idea but the vast majority of articles and papers covering reward functions are RL-related.

I'm wondering if anyone has tried anything like this before, or have any thoughts. All comments are appreciated.",1,1,2022-07-05 23:56:48, p  reward function as a way to represent multiple targets,i ve been assigned at work a problem with multiple targets  and i ve been thinking about what s the best to design a model that would optimize towards all these targets  an idea that occurred me is to create a reward function that would encapsulate all these targets in such a way where  the higher the reward  the better the outcome is for all the targets  in my case  it s a task distribution system where the workers have the option to decline a task if for whatever reason the task doesn t suit them  and one of my targets is to minimize the number of declines  but we also need to make sure the workload is balanced  and we are not overwhelming someone while under utilizing the rest of the team  that would be my second target  and we can use the standard deviation as a way to measure the workload balance  the closer to  the std is  the better  essentially  the targets we want to optimize towards are  reduce the number of declines  and also reduce the std of the overall task distribution  so  my reward function could be    score  if the task is declined    if the task is accepted  then i can take the delta of the std before and after  the bigger the delta  the more std was reduced  so the more even the distribution became that way  the reward score would in a way represent both my targets  and would be the labels   and then it s simply a matter of training a regression model  then for a new task  i predict the reward score for each task and worker  and finally assign the tasks by taking the argmax of the predicted scores i know that rewards are popular in the rl field  but this wouldn t be necessarily a rl problem  in fact  i googled this idea but the vast majority of articles and papers covering reward functions are rl related i m wondering if anyone has tried anything like this before  or have any thoughts  all comments are appreciated ,assigned work problem multiple targets thinking best design model would optimize towards targets idea occurred create reward function would encapsulate targets way higher reward better outcome targets case task distribution system workers option decline task whatever reason task suit one targets minimize number declines also need make sure workload balanced overwhelming someone utilizing rest team would second target use standard deviation way measure workload balance closer std better essentially targets want optimize towards reduce number declines also reduce std overall task distribution reward function could score task declined task accepted take delta std bigger delta std reduced even distribution became way reward score would way represent targets would labels simply matter training regression model task predict reward score task worker finally assign tasks taking argmax predicted scores know rewards popular rl field necessarily rl problem fact googled idea vast majority articles papers covering reward functions rl related wondering anyone tried anything like thoughts comments appreciated,p reward function way represent multiple targets,p reward function way represent multiple targetsassigned work problem multiple targets thinking best design model would optimize towards targets idea occurred create reward function would encapsulate targets way higher reward better outcome targets case task distribution system workers option decline task whatever reason task suit one targets minimize number declines also need make sure workload balanced overwhelming someone utilizing rest team would second target use standard deviation way measure workload balance closer std better essentially targets want optimize towards reduce number declines also reduce std overall task distribution reward function could score task declined task accepted take delta std bigger delta std reduced even distribution became way reward score would way represent targets would labels simply matter training regression model task predict reward score task worker finally assign tasks taking argmax predicted scores know rewards popular rl field necessarily rl problem fact googled idea vast majority articles papers covering reward functions rl related wondering anyone tried anything like thoughts comments appreciated,"['p', 'reward', 'function', 'way', 'represent', 'multiple', 'targetsassigned', 'work', 'problem', 'multiple', 'targets', 'thinking', 'best', 'design', 'model', 'would', 'optimize', 'towards', 'targets', 'idea', 'occurred', 'create', 'reward', 'function', 'would', 'encapsulate', 'targets', 'way', 'higher', 'reward', 'better', 'outcome', 'targets', 'case', 'task', 'distribution', 'system', 'workers', 'option', 'decline', 'task', 'whatever', 'reason', 'task', 'suit', 'one', 'targets', 'minimize', 'number', 'declines', 'also', 'need', 'make', 'sure', 'workload', 'balanced', 'overwhelming', 'someone', 'utilizing', 'rest', 'team', 'would', 'second', 'target', 'use', 'standard', 'deviation', 'way', 'measure', 'workload', 'balance', 'closer', 'std', 'better', 'essentially', 'targets', 'want', 'optimize', 'towards', 'reduce', 'number', 'declines', 'also', 'reduce', 'std', 'overall', 'task', 'distribution', 'reward', 'function', 'could', 'score', 'task', 'declined', 'task', 'accepted', 'take', 'delta', 'std', 'bigger', 'delta', 'std', 'reduced', 'even', 'distribution', 'became', 'way', 'reward', 'score', 'would', 'way', 'represent', 'targets', 'would', 'labels', 'simply', 'matter', 'training', 'regression', 'model', 'task', 'predict', 'reward', 'score', 'task', 'worker', 'finally', 'assign', 'tasks', 'taking', 'argmax', 'predicted', 'scores', 'know', 'rewards', 'popular', 'rl', 'field', 'necessarily', 'rl', 'problem', 'fact', 'googled', 'idea', 'vast', 'majority', 'articles', 'papers', 'covering', 'reward', 'functions', 'rl', 'related', 'wondering', 'anyone', 'tried', 'anything', 'like', 'thoughts', 'comments', 'appreciated']","['p', 'reward', 'function', 'way', 'repres', 'multipl', 'targetsassign', 'work', 'problem', 'multipl', 'target', 'think', 'best', 'design', 'model', 'would', 'optim', 'toward', 'target', 'idea', 'occur', 'creat', 'reward', 'function', 'would', 'encapsul', 'target', 'way', 'higher', 'reward', 'better', 'outcom', 'target', 'case', 'task', 'distribut', 'system', 'worker', 'option', 'declin', 'task', 'whatev', 'reason', 'task', 'suit', 'one', 'target', 'minim', 'number', 'declin', 'also', 'need', 'make', 'sure', 'workload', 'balanc', 'overwhelm', 'someon', 'util', 'rest', 'team', 'would', 'second', 'target', 'use', 'standard', 'deviat', 'way', 'measur', 'workload', 'balanc', 'closer', 'std', 'better', 'essenti', 'target', 'want', 'optim', 'toward', 'reduc', 'number', 'declin', 'also', 'reduc', 'std', 'overal', 'task', 'distribut', 'reward', 'function', 'could', 'score', 'task', 'declin', 'task', 'accept', 'take', 'delta', 'std', 'bigger', 'delta', 'std', 'reduc', 'even', 'distribut', 'becam', 'way', 'reward', 'score', 'would', 'way', 'repres', 'target', 'would', 'label', 'simpli', 'matter', 'train', 'regress', 'model', 'task', 'predict', 'reward', 'score', 'task', 'worker', 'final', 'assign', 'task', 'take', 'argmax', 'predict', 'score', 'know', 'reward', 'popular', 'rl', 'field', 'necessarili', 'rl', 'problem', 'fact', 'googl', 'idea', 'vast', 'major', 'articl', 'paper', 'cover', 'reward', 'function', 'rl', 'relat', 'wonder', 'anyon', 'tri', 'anyth', 'like', 'thought', 'comment', 'appreci']"
106,114,114,rafa10pj,vrj6l5,[P] Poniard: a companion library for scikit-learn that helps with model evaluation and comparison,"TL;DR: Check out Poniard, a new Python library that helps with machine learning model evaluation. You can go ahead and install with `pip`. Links to source code and documentation at the end of this post.

\-----

For the past few months I've been working on Poniard, a Python library that streamlines ML model evaluation and comparison, built on top of scikit-learn. In a nutshell, load some data, select some models, some metrics and a cross-validation strategy, and go to town.

Poniard tries to have a small footprint, a simple API and sane defaults. But above all it strives to have the user stay in control of their modeling experience; you should always know what's going on. This deliberately is NOT an AutoML tool

When I started this project I was trying to speed up a very uninteresting process, i.e., loop through multiple estimators and arrive at a list of metrics for comparison. On the way I included easy hyperparameter tuning, plotting, an extensible plugin framework (out of the box includes Weights and Biases and Pandas Profiling) and as much as I could to make the experience simple and transparent.

Poniard is not exactly groundbreaking, and there are projects in a similar vein that do so much more. In contrast, they tend to have a more complicated API and more dependencies which are some of the things that I actively tried to avoid.

[Github](https://github.com/rxavier/poniard)  
[Example notebooks](https://github.com/rxavier/poniard/tree/main/examples) (including Colab links)  
[Documentation](https://poniard.readthedocs.io/en/latest/index.html)  
[PyPI](https://pypi.org/project/poniard/)",2,36,2022-07-05 04:02:18, p  poniard  a companion library for scikit learn that helps with model evaluation and comparison,tl dr  check out poniard  a new python library that helps with machine learning model evaluation  you can go ahead and install with  pip   links to source code and documentation at the end of this post       for the past few months i ve been working on poniard  a python library that streamlines ml model evaluation and comparison  built on top of scikit learn  in a nutshell  load some data  select some models  some metrics and a cross validation strategy  and go to town poniard tries to have a small footprint  a simple api and sane defaults  but above all it strives to have the user stay in control of their modeling experience  you should always know what s going on  this deliberately is not an automl toolwhen i started this project i was trying to speed up a very uninteresting process  i e   loop through multiple estimators and arrive at a list of metrics for comparison  on the way i included easy hyperparameter tuning  plotting  an extensible plugin framework  out of the box includes weights and biases and pandas profiling  and as much as i could to make the experience simple and transparent poniard is not exactly groundbreaking  and there are projects in a similar vein that do so much more  in contrast  they tend to have a more complicated api and more dependencies which are some of the things that i actively tried to avoid  github  https  example notebooks  https  documentation  https  pypi  https   pypi org project poniard  ,tl dr check poniard python library helps machine learning model evaluation go ahead install pip links source code documentation end post past months working poniard python library streamlines ml model evaluation comparison built top scikit learn nutshell load data select models metrics cross validation strategy go town poniard tries small footprint simple api sane defaults strives user stay control modeling experience always know going deliberately automl toolwhen started project trying speed uninteresting process e loop multiple estimators arrive metrics comparison way included easy hyperparameter tuning plotting extensible plugin framework box includes weights biases pandas profiling much could make experience simple transparent poniard exactly groundbreaking projects similar vein much contrast tend complicated api dependencies things actively tried avoid github https example notebooks https documentation https pypi https pypi org project poniard,p poniard companion library scikit learn helps model evaluation comparison,p poniard companion library scikit learn helps model evaluation comparisontl dr check poniard python library helps machine learning model evaluation go ahead install pip links source code documentation end post past months working poniard python library streamlines ml model evaluation comparison built top scikit learn nutshell load data select models metrics cross validation strategy go town poniard tries small footprint simple api sane defaults strives user stay control modeling experience always know going deliberately automl toolwhen started project trying speed uninteresting process e loop multiple estimators arrive metrics comparison way included easy hyperparameter tuning plotting extensible plugin framework box includes weights biases pandas profiling much could make experience simple transparent poniard exactly groundbreaking projects similar vein much contrast tend complicated api dependencies things actively tried avoid github https example notebooks https documentation https pypi https pypi org project poniard,"['p', 'poniard', 'companion', 'library', 'scikit', 'learn', 'helps', 'model', 'evaluation', 'comparisontl', 'dr', 'check', 'poniard', 'python', 'library', 'helps', 'machine', 'learning', 'model', 'evaluation', 'go', 'ahead', 'install', 'pip', 'links', 'source', 'code', 'documentation', 'end', 'post', 'past', 'months', 'working', 'poniard', 'python', 'library', 'streamlines', 'ml', 'model', 'evaluation', 'comparison', 'built', 'top', 'scikit', 'learn', 'nutshell', 'load', 'data', 'select', 'models', 'metrics', 'cross', 'validation', 'strategy', 'go', 'town', 'poniard', 'tries', 'small', 'footprint', 'simple', 'api', 'sane', 'defaults', 'strives', 'user', 'stay', 'control', 'modeling', 'experience', 'always', 'know', 'going', 'deliberately', 'automl', 'toolwhen', 'started', 'project', 'trying', 'speed', 'uninteresting', 'process', 'e', 'loop', 'multiple', 'estimators', 'arrive', 'metrics', 'comparison', 'way', 'included', 'easy', 'hyperparameter', 'tuning', 'plotting', 'extensible', 'plugin', 'framework', 'box', 'includes', 'weights', 'biases', 'pandas', 'profiling', 'much', 'could', 'make', 'experience', 'simple', 'transparent', 'poniard', 'exactly', 'groundbreaking', 'projects', 'similar', 'vein', 'much', 'contrast', 'tend', 'complicated', 'api', 'dependencies', 'things', 'actively', 'tried', 'avoid', 'github', 'https', 'example', 'notebooks', 'https', 'documentation', 'https', 'pypi', 'https', 'pypi', 'org', 'project', 'poniard']","['p', 'poniard', 'companion', 'librari', 'scikit', 'learn', 'help', 'model', 'evalu', 'comparisontl', 'dr', 'check', 'poniard', 'python', 'librari', 'help', 'machin', 'learn', 'model', 'evalu', 'go', 'ahead', 'instal', 'pip', 'link', 'sourc', 'code', 'document', 'end', 'post', 'past', 'month', 'work', 'poniard', 'python', 'librari', 'streamlin', 'ml', 'model', 'evalu', 'comparison', 'built', 'top', 'scikit', 'learn', 'nutshel', 'load', 'data', 'select', 'model', 'metric', 'cross', 'valid', 'strategi', 'go', 'town', 'poniard', 'tri', 'small', 'footprint', 'simpl', 'api', 'sane', 'default', 'strive', 'user', 'stay', 'control', 'model', 'experi', 'alway', 'know', 'go', 'deliber', 'automl', 'toolwhen', 'start', 'project', 'tri', 'speed', 'uninterest', 'process', 'e', 'loop', 'multipl', 'estim', 'arriv', 'metric', 'comparison', 'way', 'includ', 'easi', 'hyperparamet', 'tune', 'plot', 'extens', 'plugin', 'framework', 'box', 'includ', 'weight', 'bias', 'panda', 'profil', 'much', 'could', 'make', 'experi', 'simpl', 'transpar', 'poniard', 'exactli', 'groundbreak', 'project', 'similar', 'vein', 'much', 'contrast', 'tend', 'complic', 'api', 'depend', 'thing', 'activ', 'tri', 'avoid', 'github', 'http', 'exampl', 'notebook', 'http', 'document', 'http', 'pypi', 'http', 'pypi', 'org', 'project', 'poniard']"
107,115,115,tadf2,vs14lj,[D] How do you share a server for multiple training jobs?,"First of all, using the cloud is not a cost effective solution for us.


We have an absolute beast of a server though everything grounds down to a halt when some training sessions are going on - some libraries just ignore the num_cpu settings and uses all the cpu (and even when more cores are free, everything seems to get much slower)

Here's the build:
2x AMD EPYC 7763 (64 cores, 2 threads each)
2TB memory
8 RTX A6000
4TB SSD (NVMe)

How do you all share a single computer resource amongst other co-workers? We have this expensive machine but when someone runs their training, others have a hard time running basic pandas operations (starting other training jobs just slows down ALL training jobs).

To me, it seems like the hardware should be more than enough to run multiple training jobs concurrently. Any tips on how to use it efficiently?

One solution I've been thinking was to use docker for each training job and to put hard limits on cpu / memory usage - is this something closer to best practice?",10,0,2022-07-05 21:25:23, d  how do you share a server for multiple training jobs ,first of all  using the cloud is not a cost effective solution for us we have an absolute beast of a server though everything grounds down to a halt when some training sessions are going on   some libraries just ignore the num_cpu settings and uses all the cpu  and even when more cores are free  everything seems to get much slower here s the build x amd epyc    cores   threads each tb memory rtx atb ssd  nvme how do you all share a single computer resource amongst other co workers  we have this expensive machine but when someone runs their training  others have a hard time running basic pandas operations  starting other training jobs just slows down all training jobs  to me  it seems like the hardware should be more than enough to run multiple training jobs concurrently  any tips on how to use it efficiently one solution i ve been thinking was to use docker for each training job and to put hard limits on cpu   memory usage   is this something closer to best practice ,first using cloud cost effective solution us absolute beast server though everything grounds halt training sessions going libraries ignore num_cpu settings uses cpu even cores free everything seems get much slower build x amd epyc cores threads tb memory rtx atb ssd nvme share single computer resource amongst co workers expensive machine someone runs training others hard time running basic pandas operations starting training jobs slows training jobs seems like hardware enough run multiple training jobs concurrently tips use efficiently one solution thinking use docker training job put hard limits cpu memory usage something closer best practice,share server multiple training jobs,share server multiple training jobsfirst using cloud cost effective solution us absolute beast server though everything grounds halt training sessions going libraries ignore num_cpu settings uses cpu even cores free everything seems get much slower build x amd epyc cores threads tb memory rtx atb ssd nvme share single computer resource amongst co workers expensive machine someone runs training others hard time running basic pandas operations starting training jobs slows training jobs seems like hardware enough run multiple training jobs concurrently tips use efficiently one solution thinking use docker training job put hard limits cpu memory usage something closer best practice,"['share', 'server', 'multiple', 'training', 'jobsfirst', 'using', 'cloud', 'cost', 'effective', 'solution', 'us', 'absolute', 'beast', 'server', 'though', 'everything', 'grounds', 'halt', 'training', 'sessions', 'going', 'libraries', 'ignore', 'num_cpu', 'settings', 'uses', 'cpu', 'even', 'cores', 'free', 'everything', 'seems', 'get', 'much', 'slower', 'build', 'x', 'amd', 'epyc', 'cores', 'threads', 'tb', 'memory', 'rtx', 'atb', 'ssd', 'nvme', 'share', 'single', 'computer', 'resource', 'amongst', 'co', 'workers', 'expensive', 'machine', 'someone', 'runs', 'training', 'others', 'hard', 'time', 'running', 'basic', 'pandas', 'operations', 'starting', 'training', 'jobs', 'slows', 'training', 'jobs', 'seems', 'like', 'hardware', 'enough', 'run', 'multiple', 'training', 'jobs', 'concurrently', 'tips', 'use', 'efficiently', 'one', 'solution', 'thinking', 'use', 'docker', 'training', 'job', 'put', 'hard', 'limits', 'cpu', 'memory', 'usage', 'something', 'closer', 'best', 'practice']","['share', 'server', 'multipl', 'train', 'jobsfirst', 'use', 'cloud', 'cost', 'effect', 'solut', 'us', 'absolut', 'beast', 'server', 'though', 'everyth', 'ground', 'halt', 'train', 'session', 'go', 'librari', 'ignor', 'num_cpu', 'set', 'use', 'cpu', 'even', 'core', 'free', 'everyth', 'seem', 'get', 'much', 'slower', 'build', 'x', 'amd', 'epyc', 'core', 'thread', 'tb', 'memori', 'rtx', 'atb', 'ssd', 'nvme', 'share', 'singl', 'comput', 'resourc', 'amongst', 'co', 'worker', 'expens', 'machin', 'someon', 'run', 'train', 'other', 'hard', 'time', 'run', 'basic', 'panda', 'oper', 'start', 'train', 'job', 'slow', 'train', 'job', 'seem', 'like', 'hardwar', 'enough', 'run', 'multipl', 'train', 'job', 'concurr', 'tip', 'use', 'effici', 'one', 'solut', 'think', 'use', 'docker', 'train', 'job', 'put', 'hard', 'limit', 'cpu', 'memori', 'usag', 'someth', 'closer', 'best', 'practic']"
108,116,116,dmart89,vr6iy5,[D] How do you share big datasets with your team and others?,"Looking for a bit of a discussion.  I'm wondering how you collaborate on data... i.e. how do you share big datasets with data scientists/engineers, within and outside of your team? Do you just push it into a simple DB, do you upload it to Kaggle (if non-sensitive) or via Google Drive/OneDrive? 

What if the dataset gets updated frequently?

I'm working with a customer and sharing data is a bit of a pain.",73,146,2022-07-04 18:09:53, d  how do you share big datasets with your team and others ,looking for a bit of a discussion   i m wondering how you collaborate on data    i e  how do you share big datasets with data scientists engineers  within and outside of your team  do you just push it into a simple db  do you upload it to kaggle  if non sensitive  or via google drive onedrive  what if the dataset gets updated frequently i m working with a customer and sharing data is a bit of a pain ,looking bit discussion wondering collaborate data e share big datasets data scientists engineers within outside team push simple db upload kaggle non sensitive via google drive onedrive dataset gets updated frequently working customer sharing data bit pain,share big datasets team others,share big datasets team otherslooking bit discussion wondering collaborate data e share big datasets data scientists engineers within outside team push simple db upload kaggle non sensitive via google drive onedrive dataset gets updated frequently working customer sharing data bit pain,"['share', 'big', 'datasets', 'team', 'otherslooking', 'bit', 'discussion', 'wondering', 'collaborate', 'data', 'e', 'share', 'big', 'datasets', 'data', 'scientists', 'engineers', 'within', 'outside', 'team', 'push', 'simple', 'db', 'upload', 'kaggle', 'non', 'sensitive', 'via', 'google', 'drive', 'onedrive', 'dataset', 'gets', 'updated', 'frequently', 'working', 'customer', 'sharing', 'data', 'bit', 'pain']","['share', 'big', 'dataset', 'team', 'otherslook', 'bit', 'discuss', 'wonder', 'collabor', 'data', 'e', 'share', 'big', 'dataset', 'data', 'scientist', 'engin', 'within', 'outsid', 'team', 'push', 'simpl', 'db', 'upload', 'kaggl', 'non', 'sensit', 'via', 'googl', 'drive', 'onedr', 'dataset', 'get', 'updat', 'frequent', 'work', 'custom', 'share', 'data', 'bit', 'pain']"
109,117,117,ErrorDry4380,vr592h,[R] Masking for Representation Learning in Vision,"A blog about representation learning from masked images, what makes a good mask, and how to learn such masks: [https://akosiorek.github.io/ml/2022/07/04/masking\_repr\_learning\_vision.html](https://akosiorek.github.io/ml/2022/07/04/masking_repr_learning_vision.html).

Based on a recent ICML paper: [Shi et. al, ""Adversarial Masking for Self-Supervised Learning"", ICML 2022](https://arxiv.org/abs/2201.13100).",4,69,2022-07-04 16:56:26, r  masking for representation learning in vision,a blog about representation learning from masked images  what makes a good mask  and how to learn such masks   https based on a recent icml paper   shi et  al  adversarial masking for self supervised learning  icml   https   arxiv org abs    ,blog representation learning masked images makes good mask learn masks https based recent icml paper shi et al adversarial masking self supervised learning icml https arxiv org abs,r masking representation learning vision,r masking representation learning visionblog representation learning masked images makes good mask learn masks https based recent icml paper shi et al adversarial masking self supervised learning icml https arxiv org abs,"['r', 'masking', 'representation', 'learning', 'visionblog', 'representation', 'learning', 'masked', 'images', 'makes', 'good', 'mask', 'learn', 'masks', 'https', 'based', 'recent', 'icml', 'paper', 'shi', 'et', 'al', 'adversarial', 'masking', 'self', 'supervised', 'learning', 'icml', 'https', 'arxiv', 'org', 'abs']","['r', 'mask', 'represent', 'learn', 'visionblog', 'represent', 'learn', 'mask', 'imag', 'make', 'good', 'mask', 'learn', 'mask', 'http', 'base', 'recent', 'icml', 'paper', 'shi', 'et', 'al', 'adversari', 'mask', 'self', 'supervis', 'learn', 'icml', 'http', 'arxiv', 'org', 'ab']"
110,118,118,jeryyjohnson,vrpf6i,WACV 2023 Paper Registration. [R],Does anyone know how to register for the WACV 2023 conference?,4,2,2022-07-05 09:50:59,wacv  paper registration   r ,does anyone know how to register for the wacv  conference ,anyone know register wacv conference,wacv paper registration r,wacv paper registration ranyone know register wacv conference,"['wacv', 'paper', 'registration', 'ranyone', 'know', 'register', 'wacv', 'conference']","['wacv', 'paper', 'registr', 'ranyon', 'know', 'regist', 'wacv', 'confer']"
111,119,119,leepenkman,vrj17e,[P] Bulk AI Text Generation (No/Low code),"[https://textgenerator.app.nz/bulk-text-generator](https://textgenerator.app.nz/bulk-text-generator)

  
You can upload a CSV and get lots of Text Generated, works in many languages and code too.  


There's also an API.  


The **main selling points** (VS OpenAI who is the main competitor)

* Works faster 
* Currie/Babbage quality, but also works across languages/code without needing to specify what model
* Massively cheaper pricing/huge cost savings :) 
* easier to control
   * can specify max\_sentences to make it generate up to a specific number of sentences)
   * can specify min\_probability to make it generate the next few likely words to do autocomplete for code/writing

  
I originally created [https://textgenerator.app.nz/](https://textgenerator.app.nz/) as a API for developers primarily but the bulk generator now allows non technical types to pre generate a lot of variety too/branching stories/games/marketing content/code/summaries/ etc.   


There's actually a [massive amount of use cases](https://textgenerator.app.nz/use-cases) that one will never be able to understand which is exciting too.",0,4,2022-07-05 03:55:10, p  bulk ai text generation  no low code , https   you can upload a csv and get lots of text generated  works in many languages and code too   there s also an api   the   main selling points    vs openai who is the main competitor   works faster   currie babbage quality  but also works across languages code without needing to specify what model  massively cheaper pricing huge cost savings      easier to control     can specify max _sentences to make it generate up to a specific number of sentences      can specify min _probability to make it generate the next few likely words to do autocomplete for code writing  i originally created  https there s actually a  massive amount of use cases  https   textgenerator app nz use cases  that one will never be able to understand which is exciting too ,https upload csv get lots text generated works many languages code also api main selling points vs openai main competitor works faster currie babbage quality also works across languages code without needing specify model massively cheaper pricing huge cost savings easier control specify max _sentences make generate specific number sentences specify min _probability make generate next likely autocomplete code writing originally created https actually massive amount use cases https textgenerator app nz use cases one never able understand exciting,p bulk ai text generation low code,p bulk ai text generation low codehttps upload csv get lots text generated works many languages code also api main selling points vs openai main competitor works faster currie babbage quality also works across languages code without needing specify model massively cheaper pricing huge cost savings easier control specify max _sentences make generate specific number sentences specify min _probability make generate next likely autocomplete code writing originally created https actually massive amount use cases https textgenerator app nz use cases one never able understand exciting,"['p', 'bulk', 'ai', 'text', 'generation', 'low', 'codehttps', 'upload', 'csv', 'get', 'lots', 'text', 'generated', 'works', 'many', 'languages', 'code', 'also', 'api', 'main', 'selling', 'points', 'vs', 'openai', 'main', 'competitor', 'works', 'faster', 'currie', 'babbage', 'quality', 'also', 'works', 'across', 'languages', 'code', 'without', 'needing', 'specify', 'model', 'massively', 'cheaper', 'pricing', 'huge', 'cost', 'savings', 'easier', 'control', 'specify', 'max', '_sentences', 'make', 'generate', 'specific', 'number', 'sentences', 'specify', 'min', '_probability', 'make', 'generate', 'next', 'likely', 'autocomplete', 'code', 'writing', 'originally', 'created', 'https', 'actually', 'massive', 'amount', 'use', 'cases', 'https', 'textgenerator', 'app', 'nz', 'use', 'cases', 'one', 'never', 'able', 'understand', 'exciting']","['p', 'bulk', 'ai', 'text', 'gener', 'low', 'codehttp', 'upload', 'csv', 'get', 'lot', 'text', 'gener', 'work', 'mani', 'languag', 'code', 'also', 'api', 'main', 'sell', 'point', 'vs', 'openai', 'main', 'competitor', 'work', 'faster', 'curri', 'babbag', 'qualiti', 'also', 'work', 'across', 'languag', 'code', 'without', 'need', 'specifi', 'model', 'massiv', 'cheaper', 'price', 'huge', 'cost', 'save', 'easier', 'control', 'specifi', 'max', '_sentenc', 'make', 'gener', 'specif', 'number', 'sentenc', 'specifi', 'min', '_probabl', 'make', 'gener', 'next', 'like', 'autocomplet', 'code', 'write', 'origin', 'creat', 'http', 'actual', 'massiv', 'amount', 'use', 'case', 'http', 'textgener', 'app', 'nz', 'use', 'case', 'one', 'never', 'abl', 'understand', 'excit']"
112,120,120,zxzxy1988,vr3hzx,"[P] Feathr - An Open-Source, Enterprise-Grade and High-Performance Feature Store","Hi everyone! We are engineers from Microsoft/LinkedIn, and we released an open-source Feature Store called Feathr a few weeks ago ([https://github.com/linkedin/feathr](https://github.com/linkedin/feathr)). It has many highlights like below. Feel free to check out the repository and let us know if there are any questions! We also have a few blogposts and recordings in case folks want to learn a bit more about it:

* [Open Sourcing Feathr](https://engineering.linkedin.com/blog/2022/open-sourcing-feathr---linkedin-s-feature-store-for-productive-m)
* [Feathr on Azure](https://azure.microsoft.com/en-us/blog/feathr-linkedin-s-feature-store-is-now-available-on-azure/).
* [Tech talks on Feathr](https://www.youtube.com/watch?v=gZg01UKQMTY)

And its highlights include (more highlights are [here](https://github.com/linkedin/feathr#-feathr-highlights)):

* **Battle tested in production for more than 6 years:** LinkedIn has been using Feathr in production for over 6 years and have a dedicated team improving it.
* **Scalable with built-in optimizations:** For example, based on some internal use case, Feathr can process billions of rows and PB scale data with built-in optimizations such as bloom filters and salted joins.
* **Rich support for point-in-time joins and aggregations:** Feathr has high performant built-in operators designed for Feature Store, including time-based aggregation, sliding window joins, look-up features, all with point-in-time correctness.
* **Derived Features and centralized Feature Registry** which encourage feature consumers to build features on existing features and encouraging feature reuse.

&#x200B;

Screenshots for the Feathr UI:

https://preview.redd.it/3fri2r3qoi991.png?width=3584&format=png&auto=webp&s=5dfe14233b2a8805c50bedd5bfed4bbb31bd0654",16,43,2022-07-04 14:57:38, p  feathr   an open source  enterprise grade and high performance feature store,hi everyone  we are engineers from microsoft linkedin  and we released an open source feature store called feathr a few weeks ago   https    open sourcing feathr  https    feathr on azure  https    tech talks on feathr  https and its highlights include  more highlights are  here  https     battle tested in production for more than  years    linkedin has been using feathr in production for over  years and have a dedicated team improving it     scalable with built in optimizations    for example  based on some internal use case  feathr can process billions of rows and pb scale data with built in optimizations such as bloom filters and salted joins     rich support for point in time joins and aggregations    feathr has high performant built in operators designed for feature store  including time based aggregation  sliding window joins  look up features  all with point in time correctness     derived features and centralized feature registry   which encourage feature consumers to build features on existing features and encouraging feature reuse   xb screenshots for the feathr ui https   preview redd it frirqoi png width  format png auto webp s dfebacbeddbfedbbbbd,hi everyone engineers microsoft linkedin released open source feature store called feathr weeks ago https open sourcing feathr https feathr azure https tech talks feathr https highlights include highlights https battle tested production years linkedin using feathr production years dedicated team improving scalable built optimizations example based internal use case feathr process billions rows pb scale data built optimizations bloom filters salted joins rich support point time joins aggregations feathr high performant built operators designed feature store including time based aggregation sliding window joins look features point time correctness derived features centralized feature registry encourage feature consumers build features existing features encouraging feature reuse xb screenshots feathr ui https preview redd frirqoi png width format png auto webp dfebacbeddbfedbbbbd,p feathr open source enterprise grade high performance feature store,p feathr open source enterprise grade high performance feature storehi everyone engineers microsoft linkedin released open source feature store called feathr weeks ago https open sourcing feathr https feathr azure https tech talks feathr https highlights include highlights https battle tested production years linkedin using feathr production years dedicated team improving scalable built optimizations example based internal use case feathr process billions rows pb scale data built optimizations bloom filters salted joins rich support point time joins aggregations feathr high performant built operators designed feature store including time based aggregation sliding window joins look features point time correctness derived features centralized feature registry encourage feature consumers build features existing features encouraging feature reuse xb screenshots feathr ui https preview redd frirqoi png width format png auto webp dfebacbeddbfedbbbbd,"['p', 'feathr', 'open', 'source', 'enterprise', 'grade', 'high', 'performance', 'feature', 'storehi', 'everyone', 'engineers', 'microsoft', 'linkedin', 'released', 'open', 'source', 'feature', 'store', 'called', 'feathr', 'weeks', 'ago', 'https', 'open', 'sourcing', 'feathr', 'https', 'feathr', 'azure', 'https', 'tech', 'talks', 'feathr', 'https', 'highlights', 'include', 'highlights', 'https', 'battle', 'tested', 'production', 'years', 'linkedin', 'using', 'feathr', 'production', 'years', 'dedicated', 'team', 'improving', 'scalable', 'built', 'optimizations', 'example', 'based', 'internal', 'use', 'case', 'feathr', 'process', 'billions', 'rows', 'pb', 'scale', 'data', 'built', 'optimizations', 'bloom', 'filters', 'salted', 'joins', 'rich', 'support', 'point', 'time', 'joins', 'aggregations', 'feathr', 'high', 'performant', 'built', 'operators', 'designed', 'feature', 'store', 'including', 'time', 'based', 'aggregation', 'sliding', 'window', 'joins', 'look', 'features', 'point', 'time', 'correctness', 'derived', 'features', 'centralized', 'feature', 'registry', 'encourage', 'feature', 'consumers', 'build', 'features', 'existing', 'features', 'encouraging', 'feature', 'reuse', 'xb', 'screenshots', 'feathr', 'ui', 'https', 'preview', 'redd', 'frirqoi', 'png', 'width', 'format', 'png', 'auto', 'webp', 'dfebacbeddbfedbbbbd']","['p', 'feathr', 'open', 'sourc', 'enterpris', 'grade', 'high', 'perform', 'featur', 'storehi', 'everyon', 'engin', 'microsoft', 'linkedin', 'releas', 'open', 'sourc', 'featur', 'store', 'call', 'feathr', 'week', 'ago', 'http', 'open', 'sourc', 'feathr', 'http', 'feathr', 'azur', 'http', 'tech', 'talk', 'feathr', 'http', 'highlight', 'includ', 'highlight', 'http', 'battl', 'test', 'product', 'year', 'linkedin', 'use', 'feathr', 'product', 'year', 'dedic', 'team', 'improv', 'scalabl', 'built', 'optim', 'exampl', 'base', 'intern', 'use', 'case', 'feathr', 'process', 'billion', 'row', 'pb', 'scale', 'data', 'built', 'optim', 'bloom', 'filter', 'salt', 'join', 'rich', 'support', 'point', 'time', 'join', 'aggreg', 'feathr', 'high', 'perform', 'built', 'oper', 'design', 'featur', 'store', 'includ', 'time', 'base', 'aggreg', 'slide', 'window', 'join', 'look', 'featur', 'point', 'time', 'correct', 'deriv', 'featur', 'central', 'featur', 'registri', 'encourag', 'featur', 'consum', 'build', 'featur', 'exist', 'featur', 'encourag', 'featur', 'reus', 'xb', 'screenshot', 'feathr', 'ui', 'http', 'preview', 'redd', 'frirqoi', 'png', 'width', 'format', 'png', 'auto', 'webp', 'dfebacbeddbfedbbbbd']"
113,121,121,_Arsenie_Boca_,vrhlfa,[D] Backpropagating from GPT-2's output,"I am working on a research project about controllable generation with GPT. I am stuck, so I hope you are able to help me out. I will try to explain the issue as clear as possible, so bear with me.

The approach I am pursuing right now is adding a frozen classifier on top of gpt that should steer the model in generating the right class, which is a grammatical property of the generated output.

However, the autoregressive nature of GPT complicates things a bit. I cannot simply backpropagate through the generation process (greedy / beam search). 

I tried adding the classifier on the last input token to avoid the generation process but unsurprisingly this does not yield sufficient performance.

How would you tackle this? Is it even feasible?",3,2,2022-07-05 02:46:31, d  backpropagating from gpt  s output,i am working on a research project about controllable generation with gpt  i am stuck  so i hope you are able to help me out  i will try to explain the issue as clear as possible  so bear with me the approach i am pursuing right now is adding a frozen classifier on top of gpt that should steer the model in generating the right class  which is a grammatical property of the generated output however  the autoregressive nature of gpt complicates things a bit  i cannot simply backpropagate through the generation process  greedy   beam search   i tried adding the classifier on the last input token to avoid the generation process but unsurprisingly this does not yield sufficient performance how would you tackle this  is it even feasible ,working research project controllable generation gpt stuck hope able help try explain issue clear possible bear approach pursuing right adding frozen classifier top gpt steer model generating right class grammatical property generated output however autoregressive nature gpt complicates things bit cannot simply backpropagate generation process greedy beam search tried adding classifier last input token avoid generation process unsurprisingly yield sufficient performance would tackle even feasible,backpropagating gpt output,backpropagating gpt outputworking research project controllable generation gpt stuck hope able help try explain issue clear possible bear approach pursuing right adding frozen classifier top gpt steer model generating right class grammatical property generated output however autoregressive nature gpt complicates things bit cannot simply backpropagate generation process greedy beam search tried adding classifier last input token avoid generation process unsurprisingly yield sufficient performance would tackle even feasible,"['backpropagating', 'gpt', 'outputworking', 'research', 'project', 'controllable', 'generation', 'gpt', 'stuck', 'hope', 'able', 'help', 'try', 'explain', 'issue', 'clear', 'possible', 'bear', 'approach', 'pursuing', 'right', 'adding', 'frozen', 'classifier', 'top', 'gpt', 'steer', 'model', 'generating', 'right', 'class', 'grammatical', 'property', 'generated', 'output', 'however', 'autoregressive', 'nature', 'gpt', 'complicates', 'things', 'bit', 'can', 'not', 'simply', 'backpropagate', 'generation', 'process', 'greedy', 'beam', 'search', 'tried', 'adding', 'classifier', 'last', 'input', 'token', 'avoid', 'generation', 'process', 'unsurprisingly', 'yield', 'sufficient', 'performance', 'would', 'tackle', 'even', 'feasible']","['backpropag', 'gpt', 'outputwork', 'research', 'project', 'control', 'gener', 'gpt', 'stuck', 'hope', 'abl', 'help', 'tri', 'explain', 'issu', 'clear', 'possibl', 'bear', 'approach', 'pursu', 'right', 'ad', 'frozen', 'classifi', 'top', 'gpt', 'steer', 'model', 'gener', 'right', 'class', 'grammat', 'properti', 'gener', 'output', 'howev', 'autoregress', 'natur', 'gpt', 'complic', 'thing', 'bit', 'can', 'not', 'simpli', 'backpropag', 'gener', 'process', 'greedi', 'beam', 'search', 'tri', 'ad', 'classifi', 'last', 'input', 'token', 'avoid', 'gener', 'process', 'unsurprisingli', 'yield', 'suffici', 'perform', 'would', 'tackl', 'even', 'feasibl']"
114,122,122,bitemenow999,vqoey6,[D] Advanced resources for ML theory/math.,"So I have been working in ML for the past 3 years as a researcher and now PhD candidate, and though I have an understanding of intermediate level of the math behind most algorithms. But it looks like I have reached a  plateau, where I get the math in the papers but  I don't have an understanding of how they came up with the methods, and lately, my work has been combining multiple existing methods to make something new and draw inference on them, I realize the lack of novelty in my approach is mostly due to me being an 'engineer' and not a stats/math guy.

Looking to remedy that, are there some resources free or otherwise that would get me a deeper understanding of Bayesian, Markov models, and stochastic math and PDEs? I know I can attend classes in my university but I would rather focus more on research than worry about assignments and grades and such...",20,132,2022-07-04 00:28:08, d  advanced resources for ml theory math ,so i have been working in ml for the past  years as a researcher and now phd candidate  and though i have an understanding of intermediate level of the math behind most algorithms  but it looks like i have reached a  plateau  where i get the math in the papers but  i don t have an understanding of how they came up with the methods  and lately  my work has been combining multiple existing methods to make something new and draw inference on them  i realize the lack of novelty in my approach is mostly due to me being an  engineer  and not a stats math guy looking to remedy that  are there some resources free or otherwise that would get me a deeper understanding of bayesian  markov models  and stochastic math and pdes  i know i can attend classes in my university but i would rather focus more on research than worry about assignments and grades and such   ,working ml past years researcher phd candidate though understanding intermediate level math behind algorithms looks like reached plateau get math papers understanding came methods lately work combining multiple existing methods make something draw inference realize lack novelty approach mostly due engineer stats math guy looking remedy resources free otherwise would get deeper understanding bayesian markov models stochastic math pdes know attend classes university would rather focus research worry assignments grades,advanced resources ml theory math,advanced resources ml theory mathworking ml past years researcher phd candidate though understanding intermediate level math behind algorithms looks like reached plateau get math papers understanding came methods lately work combining multiple existing methods make something draw inference realize lack novelty approach mostly due engineer stats math guy looking remedy resources free otherwise would get deeper understanding bayesian markov models stochastic math pdes know attend classes university would rather focus research worry assignments grades,"['advanced', 'resources', 'ml', 'theory', 'mathworking', 'ml', 'past', 'years', 'researcher', 'phd', 'candidate', 'though', 'understanding', 'intermediate', 'level', 'math', 'behind', 'algorithms', 'looks', 'like', 'reached', 'plateau', 'get', 'math', 'papers', 'understanding', 'came', 'methods', 'lately', 'work', 'combining', 'multiple', 'existing', 'methods', 'make', 'something', 'draw', 'inference', 'realize', 'lack', 'novelty', 'approach', 'mostly', 'due', 'engineer', 'stats', 'math', 'guy', 'looking', 'remedy', 'resources', 'free', 'otherwise', 'would', 'get', 'deeper', 'understanding', 'bayesian', 'markov', 'models', 'stochastic', 'math', 'pdes', 'know', 'attend', 'classes', 'university', 'would', 'rather', 'focus', 'research', 'worry', 'assignments', 'grades']","['advanc', 'resourc', 'ml', 'theori', 'mathwork', 'ml', 'past', 'year', 'research', 'phd', 'candid', 'though', 'understand', 'intermedi', 'level', 'math', 'behind', 'algorithm', 'look', 'like', 'reach', 'plateau', 'get', 'math', 'paper', 'understand', 'came', 'method', 'late', 'work', 'combin', 'multipl', 'exist', 'method', 'make', 'someth', 'draw', 'infer', 'realiz', 'lack', 'novelti', 'approach', 'mostli', 'due', 'engin', 'stat', 'math', 'guy', 'look', 'remedi', 'resourc', 'free', 'otherwis', 'would', 'get', 'deeper', 'understand', 'bayesian', 'markov', 'model', 'stochast', 'math', 'pde', 'know', 'attend', 'class', 'univers', 'would', 'rather', 'focu', 'research', 'worri', 'assign', 'grade']"
115,123,123,Insighteous,vqg3mn,[D] Do you think there is too much development in Machine Learning?,"Sometimes I think this field evolves too fast. No time to relax a little bit and use the knowledge build over time. What’s up to date today is outdated tomorrow.   

What do you think about this?",98,278,2022-07-03 17:33:02, d  do you think there is too much development in machine learning ,sometimes i think this field evolves too fast  no time to relax a little bit and use the knowledge build over time  what s up to date today is outdated tomorrow    what do you think about this ,sometimes think field evolves fast time relax little bit use knowledge build time date today outdated tomorrow think,think much development machine learning,think much development machine learningsometimes think field evolves fast time relax little bit use knowledge build time date today outdated tomorrow think,"['think', 'much', 'development', 'machine', 'learningsometimes', 'think', 'field', 'evolves', 'fast', 'time', 'relax', 'little', 'bit', 'use', 'knowledge', 'build', 'time', 'date', 'today', 'outdated', 'tomorrow', 'think']","['think', 'much', 'develop', 'machin', 'learningsometim', 'think', 'field', 'evolv', 'fast', 'time', 'relax', 'littl', 'bit', 'use', 'knowledg', 'build', 'time', 'date', 'today', 'outdat', 'tomorrow', 'think']"
116,124,124,aifordummies,vqrawg,[D] List of accepted ECCV papers are now available!,[https://ailb-web.ing.unimore.it/releases/eccv2022/accepted\_papers.txt](https://ailb-web.ing.unimore.it/releases/eccv2022/accepted_papers.txt),40,44,2022-07-04 02:46:30, d  list of accepted eccv papers are now available , https   ailb web ing unimore it releases eccv accepted _papers txt  https   ailb web ing unimore it releases eccv accepted_papers txt ,https ailb web ing unimore releases eccv accepted _papers txt https ailb web ing unimore releases eccv accepted_papers txt,accepted eccv papers available,accepted eccv papers availablehttps ailb web ing unimore releases eccv accepted _papers txt https ailb web ing unimore releases eccv accepted_papers txt,"['accepted', 'eccv', 'papers', 'availablehttps', 'ailb', 'web', 'ing', 'unimore', 'releases', 'eccv', 'accepted', '_papers', 'txt', 'https', 'ailb', 'web', 'ing', 'unimore', 'releases', 'eccv', 'accepted_papers', 'txt']","['accept', 'eccv', 'paper', 'availablehttp', 'ailb', 'web', 'ing', 'unimor', 'releas', 'eccv', 'accept', '_paper', 'txt', 'http', 'ailb', 'web', 'ing', 'unimor', 'releas', 'eccv', 'accepted_pap', 'txt']"
117,125,125,tmclouisluk,vr0x4r,[D] Is there any deep learning algorithm based on divide and conquer?," 

Dealing with a very huge data, eg. very long video datasets, the problems are long training time. Most of technics are using distributed deep learning to solve the problem robustly. I have an idea that we divide the dataset into small sets and train a model. After that using the model to predict values as features, put them into another model and train a second model to predict the output. Like divide and conquer but here is divide the dataset, train a model and conquer the prediction results into one.

I have done some research in the internet about deep learning algorithm based on divide and conquer but seems not so many articles about it.

Is it a correct to think in this way? Does anyone know any paper about this? Thank you so much.",24,7,2022-07-04 11:52:48, d  is there any deep learning algorithm based on divide and conquer , dealing with a very huge data  eg  very long video datasets  the problems are long training time  most of technics are using distributed deep learning to solve the problem robustly  i have an idea that we divide the dataset into small sets and train a model  after that using the model to predict values as features  put them into another model and train a second model to predict the output  like divide and conquer but here is divide the dataset  train a model and conquer the prediction results into one i have done some research in the internet about deep learning algorithm based on divide and conquer but seems not so many articles about it is it a correct to think in this way  does anyone know any paper about this  thank you so much ,dealing huge data eg long video datasets problems long training time technics using distributed deep learning solve problem robustly idea divide dataset small sets train model using model predict values features put another model train second model predict output like divide conquer divide dataset train model conquer prediction results one done research internet deep learning algorithm based divide conquer seems many articles correct think way anyone know paper thank much,deep learning algorithm based divide conquer,deep learning algorithm based divide conquerdealing huge data eg long video datasets problems long training time technics using distributed deep learning solve problem robustly idea divide dataset small sets train model using model predict values features put another model train second model predict output like divide conquer divide dataset train model conquer prediction results one done research internet deep learning algorithm based divide conquer seems many articles correct think way anyone know paper thank much,"['deep', 'learning', 'algorithm', 'based', 'divide', 'conquerdealing', 'huge', 'data', 'eg', 'long', 'video', 'datasets', 'problems', 'long', 'training', 'time', 'technics', 'using', 'distributed', 'deep', 'learning', 'solve', 'problem', 'robustly', 'idea', 'divide', 'dataset', 'small', 'sets', 'train', 'model', 'using', 'model', 'predict', 'values', 'features', 'put', 'another', 'model', 'train', 'second', 'model', 'predict', 'output', 'like', 'divide', 'conquer', 'divide', 'dataset', 'train', 'model', 'conquer', 'prediction', 'results', 'one', 'done', 'research', 'internet', 'deep', 'learning', 'algorithm', 'based', 'divide', 'conquer', 'seems', 'many', 'articles', 'correct', 'think', 'way', 'anyone', 'know', 'paper', 'thank', 'much']","['deep', 'learn', 'algorithm', 'base', 'divid', 'conquerd', 'huge', 'data', 'eg', 'long', 'video', 'dataset', 'problem', 'long', 'train', 'time', 'technic', 'use', 'distribut', 'deep', 'learn', 'solv', 'problem', 'robustli', 'idea', 'divid', 'dataset', 'small', 'set', 'train', 'model', 'use', 'model', 'predict', 'valu', 'featur', 'put', 'anoth', 'model', 'train', 'second', 'model', 'predict', 'output', 'like', 'divid', 'conquer', 'divid', 'dataset', 'train', 'model', 'conquer', 'predict', 'result', 'one', 'done', 'research', 'internet', 'deep', 'learn', 'algorithm', 'base', 'divid', 'conquer', 'seem', 'mani', 'articl', 'correct', 'think', 'way', 'anyon', 'know', 'paper', 'thank', 'much']"
118,126,126,thesofakillers,vr6v6s,[D] Does anyone here use Google's seqio library?,"In my research I recently came across this library from google:

[seqio: Task-based datasets, preprocessing, and evaluation for sequence models](https://github.com/google/seqio).

From the citation it seems it was released jointly with another library from google, [t5x](https://github.com/google-research/t5x).

From the paper and the docs, it sounds quite similar to huggingface's [datasets](https://github.com/huggingface/datasets) library, albeit perhaps slightly more opinionated. I was hoping to find a more thorough comparison with pre-existing dataloading/processing libraries but couldn't find one (they mostly focus on t5x in the paper). 

Has anyone here used it? What was your experience? To me it seems a bit redundant but I haven't been able to take a deeper dive

Thanks :)",0,2,2022-07-04 18:28:40, d  does anyone here use google s seqio library ,in my research i recently came across this library from google  seqio  task based datasets  preprocessing  and evaluation for sequence models  https from the citation it seems it was released jointly with another library from google   tx  https from the paper and the docs  it sounds quite similar to huggingface s  datasets  https has anyone here used it  what was your experience  to me it seems a bit redundant but i haven t been able to take a deeper divethanks   ,research recently came across library google seqio task based datasets preprocessing evaluation sequence models https citation seems released jointly another library google tx https paper docs sounds quite similar huggingface datasets https anyone used experience seems bit redundant able take deeper divethanks,anyone use google seqio library,anyone use google seqio libraryresearch recently came across library google seqio task based datasets preprocessing evaluation sequence models https citation seems released jointly another library google tx https paper docs sounds quite similar huggingface datasets https anyone used experience seems bit redundant able take deeper divethanks,"['anyone', 'use', 'google', 'seqio', 'libraryresearch', 'recently', 'came', 'across', 'library', 'google', 'seqio', 'task', 'based', 'datasets', 'preprocessing', 'evaluation', 'sequence', 'models', 'https', 'citation', 'seems', 'released', 'jointly', 'another', 'library', 'google', 'tx', 'https', 'paper', 'docs', 'sounds', 'quite', 'similar', 'huggingface', 'datasets', 'https', 'anyone', 'used', 'experience', 'seems', 'bit', 'redundant', 'able', 'take', 'deeper', 'divethanks']","['anyon', 'use', 'googl', 'seqio', 'libraryresearch', 'recent', 'came', 'across', 'librari', 'googl', 'seqio', 'task', 'base', 'dataset', 'preprocess', 'evalu', 'sequenc', 'model', 'http', 'citat', 'seem', 'releas', 'jointli', 'anoth', 'librari', 'googl', 'tx', 'http', 'paper', 'doc', 'sound', 'quit', 'similar', 'huggingfac', 'dataset', 'http', 'anyon', 'use', 'experi', 'seem', 'bit', 'redund', 'abl', 'take', 'deeper', 'divethank']"
119,127,127,bikeskata,vqo5hn,[R] Bayesian Vector Autoregression in PyMC,"A cool post (with code), detailing how to implement a Bayesian VAR in PyMC. This means no more hand-coding Gibbs Samplers!

Link: https://www.pymc-labs.io/blog-posts/bayesian-vector-autoregression/",4,30,2022-07-04 00:15:22, r  bayesian vector autoregression in pymc,a cool post  with code   detailing how to implement a bayesian var in pymc  this means no more hand coding gibbs samplers link  https   www pymc labs io blog posts bayesian vector autoregression ,cool post code detailing implement bayesian var pymc means hand coding gibbs samplers link https www pymc labs io blog posts bayesian vector autoregression,r bayesian vector autoregression pymc,r bayesian vector autoregression pymccool post code detailing implement bayesian var pymc means hand coding gibbs samplers link https www pymc labs io blog posts bayesian vector autoregression,"['r', 'bayesian', 'vector', 'autoregression', 'pymccool', 'post', 'code', 'detailing', 'implement', 'bayesian', 'var', 'pymc', 'means', 'hand', 'coding', 'gibbs', 'samplers', 'link', 'https', 'www', 'pymc', 'labs', 'io', 'blog', 'posts', 'bayesian', 'vector', 'autoregression']","['r', 'bayesian', 'vector', 'autoregress', 'pymccool', 'post', 'code', 'detail', 'implement', 'bayesian', 'var', 'pymc', 'mean', 'hand', 'code', 'gibb', 'sampler', 'link', 'http', 'www', 'pymc', 'lab', 'io', 'blog', 'post', 'bayesian', 'vector', 'autoregress']"
120,129,129,bitcoingobrrr,vqmj80,RL failure for Atari games (alignment) [Research]," I'm trying to find a paper (\~2019) that I heard in a talk regarding alignment in the context DQN/DDPG that was applied to an Atari-type game (Pong/Breakout). Apparently, the realization was that if an extra row of pixels was added to the frame, the algorithm fails. This might be a shot in the dark, but does anyone know which paper this would be?",5,11,2022-07-03 22:55:41,rl failure for atari games  alignment   research , i m trying to find a paper      that i heard in a talk regarding alignment in the context dqn ddpg that was applied to an atari type game  pong breakout   apparently  the realization was that if an extra row of pixels was added to the frame  the algorithm fails  this might be a shot in the dark  but does anyone know which paper this would be ,trying find paper heard talk regarding alignment context dqn ddpg applied atari type game pong breakout apparently realization extra row pixels added frame algorithm fails might shot dark anyone know paper would,rl failure atari games alignment research,rl failure atari games alignment researchtrying find paper heard talk regarding alignment context dqn ddpg applied atari type game pong breakout apparently realization extra row pixels added frame algorithm fails might shot dark anyone know paper would,"['rl', 'failure', 'atari', 'games', 'alignment', 'researchtrying', 'find', 'paper', 'heard', 'talk', 'regarding', 'alignment', 'context', 'dqn', 'ddpg', 'applied', 'atari', 'type', 'game', 'pong', 'breakout', 'apparently', 'realization', 'extra', 'row', 'pixels', 'added', 'frame', 'algorithm', 'fails', 'might', 'shot', 'dark', 'anyone', 'know', 'paper', 'would']","['rl', 'failur', 'atari', 'game', 'align', 'researchtri', 'find', 'paper', 'heard', 'talk', 'regard', 'align', 'context', 'dqn', 'ddpg', 'appli', 'atari', 'type', 'game', 'pong', 'breakout', 'appar', 'realiz', 'extra', 'row', 'pixel', 'ad', 'frame', 'algorithm', 'fail', 'might', 'shot', 'dark', 'anyon', 'know', 'paper', 'would']"
121,132,132,davidmezzetti,vq6mll,[P] Generate webpage summary images with DALL-E mini,"&#x200B;

[Images generated with summarized Wikipedia article content](https://preview.redd.it/u5sjy6t5e9991.jpg?width=1306&format=pjpg&auto=webp&s=ee5e7a709ed02acc94b9c804078d94ca47cf8157)

This post presents a workflow to create webpage summary images with DALL-E mini. The workflow extracts text at a specified article, builds a summary and then generates an image for the summary text. The images above show output for a series of Wikipedia articles.

Full code links: [Notebook](https://colab.research.google.com/github/neuml/txtai/blob/master/examples/35_Pictures_are_worth_a_thousand_words.ipynb) | [GitHub](https://github.com/neuml/txtai)",0,22,2022-07-03 07:23:20, p  generate webpage summary images with dall e mini,  xb  images generated with summarized wikipedia article content  https this post presents a workflow to create webpage summary images with dall e mini  the workflow extracts text at a specified article  builds a summary and then generates an image for the summary text  the images above show output for a series of wikipedia articles full code links   notebook  https   colab research google com github neuml txtai blob master examples _pictures_are_worth_a_thousand_words ipynb     github  https   github com neuml txtai ,xb images generated summarized wikipedia article content https post presents workflow create webpage summary images dall e mini workflow extracts text specified article builds summary generates image summary text images show output series wikipedia articles full code links notebook https colab research google com github neuml txtai blob master examples _pictures_are_worth_a_thousand_words ipynb github https github com neuml txtai,p generate webpage summary images dall e mini,p generate webpage summary images dall e minixb images generated summarized wikipedia article content https post presents workflow create webpage summary images dall e mini workflow extracts text specified article builds summary generates image summary text images show output series wikipedia articles full code links notebook https colab research google com github neuml txtai blob master examples _pictures_are_worth_a_thousand_words ipynb github https github com neuml txtai,"['p', 'generate', 'webpage', 'summary', 'images', 'dall', 'e', 'minixb', 'images', 'generated', 'summarized', 'wikipedia', 'article', 'content', 'https', 'post', 'presents', 'workflow', 'create', 'webpage', 'summary', 'images', 'dall', 'e', 'mini', 'workflow', 'extracts', 'text', 'specified', 'article', 'builds', 'summary', 'generates', 'image', 'summary', 'text', 'images', 'show', 'output', 'series', 'wikipedia', 'articles', 'full', 'code', 'links', 'notebook', 'https', 'colab', 'research', 'google', 'com', 'github', 'neuml', 'txtai', 'blob', 'master', 'examples', '_pictures_are_worth_a_thousand_words', 'ipynb', 'github', 'https', 'github', 'com', 'neuml', 'txtai']","['p', 'gener', 'webpag', 'summari', 'imag', 'dall', 'e', 'minixb', 'imag', 'gener', 'summar', 'wikipedia', 'articl', 'content', 'http', 'post', 'present', 'workflow', 'creat', 'webpag', 'summari', 'imag', 'dall', 'e', 'mini', 'workflow', 'extract', 'text', 'specifi', 'articl', 'build', 'summari', 'gener', 'imag', 'summari', 'text', 'imag', 'show', 'output', 'seri', 'wikipedia', 'articl', 'full', 'code', 'link', 'notebook', 'http', 'colab', 'research', 'googl', 'com', 'github', 'neuml', 'txtai', 'blob', 'master', 'exampl', '_pictures_are_worth_a_thousand_word', 'ipynb', 'github', 'http', 'github', 'com', 'neuml', 'txtai']"
122,133,133,SnooPandas3529,vqyhh0,[D] Which U.S. universities are actively studying generative models?,"Although there are university rankings such as us news, it is difficult to find the universities that are good at a specific field one is interested in. We all know that Stanford and Berkeley are good at generative models, but what else? Please give me the name of university (+ the name of professor if possible) and the paper they published. It would be meaningful especially if the university is not very famous and their paper is outstanding.",4,0,2022-07-04 09:20:22, d  which u s  universities are actively studying generative models ,although there are university rankings such as us news  it is difficult to find the universities that are good at a specific field one is interested in  we all know that stanford and berkeley are good at generative models  but what else  please give me the name of university    the name of professor if possible  and the paper they published  it would be meaningful especially if the university is not very famous and their paper is outstanding ,although university rankings us news difficult find universities good specific field one interested know stanford berkeley good generative models else please give name university name professor possible paper published would meaningful especially university famous paper outstanding,u universities actively studying generative models,u universities actively studying generative modelsalthough university rankings us news difficult find universities good specific field one interested know stanford berkeley good generative models else please give name university name professor possible paper published would meaningful especially university famous paper outstanding,"['u', 'universities', 'actively', 'studying', 'generative', 'modelsalthough', 'university', 'rankings', 'us', 'news', 'difficult', 'find', 'universities', 'good', 'specific', 'field', 'one', 'interested', 'know', 'stanford', 'berkeley', 'good', 'generative', 'models', 'else', 'please', 'give', 'name', 'university', 'name', 'professor', 'possible', 'paper', 'published', 'would', 'meaningful', 'especially', 'university', 'famous', 'paper', 'outstanding']","['u', 'univers', 'activ', 'studi', 'gener', 'modelsalthough', 'univers', 'rank', 'us', 'news', 'difficult', 'find', 'univers', 'good', 'specif', 'field', 'one', 'interest', 'know', 'stanford', 'berkeley', 'good', 'gener', 'model', 'els', 'pleas', 'give', 'name', 'univers', 'name', 'professor', 'possibl', 'paper', 'publish', 'would', 'meaning', 'especi', 'univers', 'famou', 'paper', 'outstand']"
123,134,134,JsonPun,vq4s1l,[D][P]How to train a YOLOv6 model with custom dataset," Roboflow created a guide on how to train a new model with the new YOLOv6 (whether it should be called that is another topic)

I thought this could be useful for anyone wanting to test it out. What do other think of this ""new"" model?

Tutorial on how to train YOLOv6 on a custom dataset: [https://blog.roboflow.com/how-to-train-yolov6-on-a-custom-dataset/](https://blog.roboflow.com/how-to-train-yolov6-on-a-custom-dataset/)

Here is the Colab notebook tutorial: [https://colab.research.google.com/drive/1YnbqOinBZV-c9I7fk\_UL6acgnnmkXDMM](https://colab.research.google.com/drive/1YnbqOinBZV-c9I7fk_UL6acgnnmkXDMM)

The YOLOv6 repo: [https://github.com/meituan/YOLOv6](https://github.com/meituan/YOLOv6)

Has anyone else tried using this?  MT-YOLOv6 (or as the authors say) ""YOLOv6 for brevity"" was released in June, and says it outperforms YOLOv5 and YOLOX on the COCO benchmark. I plan to do some testing this upcoming week to see",0,13,2022-07-03 05:38:41, d  p how to train a yolov model with custom dataset, roboflow created a guide on how to train a new model with the new yolov  whether it should be called that is another topic i thought this could be useful for anyone wanting to test it out  what do other think of this new model tutorial on how to train yolov on a custom dataset   https here is the colab notebook tutorial   https the yolov repo   https has anyone else tried using this   mt yolov  or as the authors say  yolov for brevity was released in june  and says it outperforms yolov and yolox on the coco benchmark  i plan to do some testing this upcoming week to see,roboflow created guide train model yolov whether called another topic thought could useful anyone wanting test think model tutorial train yolov dataset https colab notebook tutorial https yolov repo https anyone else tried using mt yolov authors say yolov brevity released june says outperforms yolov yolox coco benchmark plan testing upcoming week see,p train yolov model dataset,p train yolov model datasetroboflow created guide train model yolov whether called another topic thought could useful anyone wanting test think model tutorial train yolov dataset https colab notebook tutorial https yolov repo https anyone else tried using mt yolov authors say yolov brevity released june says outperforms yolov yolox coco benchmark plan testing upcoming week see,"['p', 'train', 'yolov', 'model', 'datasetroboflow', 'created', 'guide', 'train', 'model', 'yolov', 'whether', 'called', 'another', 'topic', 'thought', 'could', 'useful', 'anyone', 'wanting', 'test', 'think', 'model', 'tutorial', 'train', 'yolov', 'dataset', 'https', 'colab', 'notebook', 'tutorial', 'https', 'yolov', 'repo', 'https', 'anyone', 'else', 'tried', 'using', 'mt', 'yolov', 'authors', 'say', 'yolov', 'brevity', 'released', 'june', 'says', 'outperforms', 'yolov', 'yolox', 'coco', 'benchmark', 'plan', 'testing', 'upcoming', 'week', 'see']","['p', 'train', 'yolov', 'model', 'datasetroboflow', 'creat', 'guid', 'train', 'model', 'yolov', 'whether', 'call', 'anoth', 'topic', 'thought', 'could', 'use', 'anyon', 'want', 'test', 'think', 'model', 'tutori', 'train', 'yolov', 'dataset', 'http', 'colab', 'notebook', 'tutori', 'http', 'yolov', 'repo', 'http', 'anyon', 'els', 'tri', 'use', 'mt', 'yolov', 'author', 'say', 'yolov', 'breviti', 'releas', 'june', 'say', 'outperform', 'yolov', 'yolox', 'coco', 'benchmark', 'plan', 'test', 'upcom', 'week', 'see']"
124,136,136,leepenkman,vqcd0e,[D] Prompt Engineering Tips?,"Any prompt engineering tips out there?  


Recently saw some good tips for Dalle style text to image generation where you tak on ""unreal engine"" or ""vray"" at the end to make something look like a photorealistic render :D   


Theres some tips specific to generating text: [https://textgenerator.app.nz/blog/prompt-tuning-tips](https://textgenerator.app.nz/blog/prompt-tuning-tips)  


I also heard there's simple ways to get better logical correctness from networks like ""Answering as a careful math professior explaining my reasoning: ""  


I'm really surprised at the breadth of problems solvable without actually training networks just by prompt tuning, it reminds me of algorithmic problem reductions where you map a problem to text and back again to solve it.  


Are there some other good hacks/battle tested tricks or places to collect info about prompt tuning?",2,2,2022-07-03 13:16:44, d  prompt engineering tips ,any prompt engineering tips out there   recently saw some good tips for dalle style text to image generation where you tak on unreal engine or vray at the end to make something look like a photorealistic render  d   theres some tips specific to generating text   https i also heard there s simple ways to get better logical correctness from networks like answering as a careful math professior explaining my reasoning    i m really surprised at the breadth of problems solvable without actually training networks just by prompt tuning  it reminds me of algorithmic problem reductions where you map a problem to text and back again to solve it   are there some other good hacks battle tested tricks or places to collect info about prompt tuning ,prompt engineering tips recently saw good tips dalle style text image generation tak unreal engine vray end make something look like photorealistic render theres tips specific generating text https also heard simple ways get better logical correctness networks like answering careful math professior explaining reasoning really surprised breadth problems solvable without actually training networks prompt tuning reminds algorithmic problem reductions map problem text back solve good hacks battle tested tricks places collect info prompt tuning,prompt engineering tips,prompt engineering tipsprompt engineering tips recently saw good tips dalle style text image generation tak unreal engine vray end make something look like photorealistic render theres tips specific generating text https also heard simple ways get better logical correctness networks like answering careful math professior explaining reasoning really surprised breadth problems solvable without actually training networks prompt tuning reminds algorithmic problem reductions map problem text back solve good hacks battle tested tricks places collect info prompt tuning,"['prompt', 'engineering', 'tipsprompt', 'engineering', 'tips', 'recently', 'saw', 'good', 'tips', 'dalle', 'style', 'text', 'image', 'generation', 'tak', 'unreal', 'engine', 'vray', 'end', 'make', 'something', 'look', 'like', 'photorealistic', 'render', 'theres', 'tips', 'specific', 'generating', 'text', 'https', 'also', 'heard', 'simple', 'ways', 'get', 'better', 'logical', 'correctness', 'networks', 'like', 'answering', 'careful', 'math', 'professior', 'explaining', 'reasoning', 'really', 'surprised', 'breadth', 'problems', 'solvable', 'without', 'actually', 'training', 'networks', 'prompt', 'tuning', 'reminds', 'algorithmic', 'problem', 'reductions', 'map', 'problem', 'text', 'back', 'solve', 'good', 'hacks', 'battle', 'tested', 'tricks', 'places', 'collect', 'info', 'prompt', 'tuning']","['prompt', 'engin', 'tipsprompt', 'engin', 'tip', 'recent', 'saw', 'good', 'tip', 'dall', 'style', 'text', 'imag', 'gener', 'tak', 'unreal', 'engin', 'vray', 'end', 'make', 'someth', 'look', 'like', 'photorealist', 'render', 'there', 'tip', 'specif', 'gener', 'text', 'http', 'also', 'heard', 'simpl', 'way', 'get', 'better', 'logic', 'correct', 'network', 'like', 'answer', 'care', 'math', 'professior', 'explain', 'reason', 'realli', 'surpris', 'breadth', 'problem', 'solvabl', 'without', 'actual', 'train', 'network', 'prompt', 'tune', 'remind', 'algorithm', 'problem', 'reduct', 'map', 'problem', 'text', 'back', 'solv', 'good', 'hack', 'battl', 'test', 'trick', 'place', 'collect', 'info', 'prompt', 'tune']"
125,137,137,londons_explorer,vpn0r1,[D] Has anyone got YaLM-100B to run?,"The community has been asking for big opensource language models for a while...

And now one has been released - YaLM-100B.   That was 2 weeks ago.  Yet, as far as I can see, not many people have it running.    There are no online demos.  There are no articles of journalists trying it out.  There are no efforts for fine tuning or people working on prompts for various usecases.


Is it the RAM requirements?   Is there no interest because it's from Russia?  Something else?",31,88,2022-07-02 13:53:31, d  has anyone got yalm b to run ,the community has been asking for big opensource language models for a while   and now one has been released   yalm b    that was  weeks ago   yet  as far as i can see  not many people have it running     there are no online demos   there are no articles of journalists trying it out   there are no efforts for fine tuning or people working on prompts for various usecases is it the ram requirements    is there no interest because it s from russia   something else ,community asking big opensource language models one released yalm b weeks ago yet far see many people running online demos articles journalists trying efforts fine tuning people working prompts various usecases ram requirements interest russia something else,anyone got yalm b run,anyone got yalm b runcommunity asking big opensource language models one released yalm b weeks ago yet far see many people running online demos articles journalists trying efforts fine tuning people working prompts various usecases ram requirements interest russia something else,"['anyone', 'got', 'yalm', 'b', 'runcommunity', 'asking', 'big', 'opensource', 'language', 'models', 'one', 'released', 'yalm', 'b', 'weeks', 'ago', 'yet', 'far', 'see', 'many', 'people', 'running', 'online', 'demos', 'articles', 'journalists', 'trying', 'efforts', 'fine', 'tuning', 'people', 'working', 'prompts', 'various', 'usecases', 'ram', 'requirements', 'interest', 'russia', 'something', 'else']","['anyon', 'got', 'yalm', 'b', 'runcommun', 'ask', 'big', 'opensourc', 'languag', 'model', 'one', 'releas', 'yalm', 'b', 'week', 'ago', 'yet', 'far', 'see', 'mani', 'peopl', 'run', 'onlin', 'demo', 'articl', 'journalist', 'tri', 'effort', 'fine', 'tune', 'peopl', 'work', 'prompt', 'variou', 'usecas', 'ram', 'requir', 'interest', 'russia', 'someth', 'els']"
126,138,138,FedEx33,vpwfax,[P] PyTorch implementation of MobileOne (An Improved One millisecond Mobile Backbone),"I want to share the PyTorch implementation of ""An Improved One millisecond Mobile Backbone"" paper.

Unfortunately, I don't have the appropriate computational resources to train the models on ImageNet, so feel free to use my implementation for that purpose.

Hope you all find it useful, feedback would be appreciated.

Repository: [https://github.com/federicopozzi33/MobileOne-PyTorch](https://github.com/federicopozzi33/MobileOne-PyTorch)

Paper: [https://arxiv.org/abs/2206.04040](https://arxiv.org/abs/2206.04040)",3,16,2022-07-02 22:43:10, p  pytorch implementation of mobileone  an improved one millisecond mobile backbone ,i want to share the pytorch implementation of an improved one millisecond mobile backbone paper unfortunately  i don t have the appropriate computational resources to train the models on imagenet  so feel free to use my implementation for that purpose hope you all find it useful  feedback would be appreciated repository   https paper   https   arxiv org abs    https   arxiv org abs   ,want share pytorch implementation improved one millisecond mobile backbone paper unfortunately appropriate computational resources train models imagenet feel free use implementation purpose hope find useful feedback would appreciated repository https paper https arxiv org abs https arxiv org abs,p pytorch implementation mobileone improved one millisecond mobile backbone,p pytorch implementation mobileone improved one millisecond mobile backbonewant share pytorch implementation improved one millisecond mobile backbone paper unfortunately appropriate computational resources train models imagenet feel free use implementation purpose hope find useful feedback would appreciated repository https paper https arxiv org abs https arxiv org abs,"['p', 'pytorch', 'implementation', 'mobileone', 'improved', 'one', 'millisecond', 'mobile', 'backbonewant', 'share', 'pytorch', 'implementation', 'improved', 'one', 'millisecond', 'mobile', 'backbone', 'paper', 'unfortunately', 'appropriate', 'computational', 'resources', 'train', 'models', 'imagenet', 'feel', 'free', 'use', 'implementation', 'purpose', 'hope', 'find', 'useful', 'feedback', 'would', 'appreciated', 'repository', 'https', 'paper', 'https', 'arxiv', 'org', 'abs', 'https', 'arxiv', 'org', 'abs']","['p', 'pytorch', 'implement', 'mobileon', 'improv', 'one', 'millisecond', 'mobil', 'backbonew', 'share', 'pytorch', 'implement', 'improv', 'one', 'millisecond', 'mobil', 'backbon', 'paper', 'unfortun', 'appropri', 'comput', 'resourc', 'train', 'model', 'imagenet', 'feel', 'free', 'use', 'implement', 'purpos', 'hope', 'find', 'use', 'feedback', 'would', 'appreci', 'repositori', 'http', 'paper', 'http', 'arxiv', 'org', 'ab', 'http', 'arxiv', 'org', 'ab']"
127,140,140,KalloDotIO,vpu0qx,[Project] Extracting training data from websites at scale," 

I built an API that takes away the work of scraping structured data from websites. This could be collating house prices in a certain geo, tracking viewer counts across a Youtube/Social media, or a common use case: daily monitoring prices on a site. Send it a URL, get back a JSON with tabular data. Takes away a lot of the data cleaning work which is the worst!

API Spec: [https://kallo.io/wp-content/uploads/2022/06/Kallo-API-Specification-v0.1.3.pdf](https://kallo.io/wp-content/uploads/2022/06/Kallo-API-Specification-v0.1.3.pdf)

Right now I'm using it to track prices on a number of sites to monitor the rising inflation.

Happy to get many more people using it for ML projects and collaborating! Please give me feedback

Learn more on our page: [https://kallo.io](https://kallo.io/)",0,6,2022-07-02 20:49:16, project  extracting training data from websites at scale, i built an api that takes away the work of scraping structured data from websites  this could be collating house prices in a certain geo  tracking viewer counts across a youtube social media  or a common use case  daily monitoring prices on a site  send it a url  get back a json with tabular data  takes away a lot of the data cleaning work which is the worst api spec   https right now i m using it to track prices on a number of sites to monitor the rising inflation happy to get many more people using it for ml projects and collaborating  please give me feedbacklearn more on our page   https   kallo io  https   kallo io  ,built api takes away work scraping structured data websites could collating house prices certain geo tracking viewer counts across youtube social media common use case daily monitoring prices site send url get back json tabular data takes away lot data cleaning work worst api spec https right using track prices number sites monitor rising inflation happy get many people using ml projects collaborating please give feedbacklearn page https kallo io https kallo io,project extracting training data websites scale,project extracting training data websites scalebuilt api takes away work scraping structured data websites could collating house prices certain geo tracking viewer counts across youtube social media common use case daily monitoring prices site send url get back json tabular data takes away lot data cleaning work worst api spec https right using track prices number sites monitor rising inflation happy get many people using ml projects collaborating please give feedbacklearn page https kallo io https kallo io,"['project', 'extracting', 'training', 'data', 'websites', 'scalebuilt', 'api', 'takes', 'away', 'work', 'scraping', 'structured', 'data', 'websites', 'could', 'collating', 'house', 'prices', 'certain', 'geo', 'tracking', 'viewer', 'counts', 'across', 'youtube', 'social', 'media', 'common', 'use', 'case', 'daily', 'monitoring', 'prices', 'site', 'send', 'url', 'get', 'back', 'json', 'tabular', 'data', 'takes', 'away', 'lot', 'data', 'cleaning', 'work', 'worst', 'api', 'spec', 'https', 'right', 'using', 'track', 'prices', 'number', 'sites', 'monitor', 'rising', 'inflation', 'happy', 'get', 'many', 'people', 'using', 'ml', 'projects', 'collaborating', 'please', 'give', 'feedbacklearn', 'page', 'https', 'kallo', 'io', 'https', 'kallo', 'io']","['project', 'extract', 'train', 'data', 'websit', 'scalebuilt', 'api', 'take', 'away', 'work', 'scrape', 'structur', 'data', 'websit', 'could', 'collat', 'hous', 'price', 'certain', 'geo', 'track', 'viewer', 'count', 'across', 'youtub', 'social', 'media', 'common', 'use', 'case', 'daili', 'monitor', 'price', 'site', 'send', 'url', 'get', 'back', 'json', 'tabular', 'data', 'take', 'away', 'lot', 'data', 'clean', 'work', 'worst', 'api', 'spec', 'http', 'right', 'use', 'track', 'price', 'number', 'site', 'monitor', 'rise', 'inflat', 'happi', 'get', 'mani', 'peopl', 'use', 'ml', 'project', 'collabor', 'pleas', 'give', 'feedbacklearn', 'page', 'http', 'kallo', 'io', 'http', 'kallo', 'io']"
128,141,141,leepenkman,vq5o75,[P] 20 Questions - with AI,"I created [https://www.addictingwordgames.com/play-game/20-questions-with-ai](https://www.addictingwordgames.com/play-game/20-questions-with-ai)   


The aim of the game was supposed to be to get the AI to confess that you are the winner, its possible but the game is also open ended.

&#x200B;

The backend generation is from [https://TextGenerator.](https://TextGenerator.app.nz)[app.nz](https://TextGenerator.app.nz) which is heaps cheaper than the OpenAI models, but quality is i think somewhere between OpenAI currie and babbage.  


In the prompt engineering theres some random topics picked that the user wont see, (that doesn't mean that the AI actually does think of that topic though).  


Theres also some retries and repetition penalty randomness that goes up to stop looping which i think is a problem in all models right now.  


in comparison to OpenAI the Text Generator API was easier to use because you can send max\_sentences=1 and it will give you 1 sentence instead of trying to work out the sentence boundaries with the stop sequences (which is also supported but i dont find that as easy to work with)",0,2,2022-07-03 06:29:00, p   questions   with ai,i created  https the aim of the game was supposed to be to get the ai to confess that you are the winner  its possible but the game is also open ended   xb the backend generation is from  https in the prompt engineering theres some random topics picked that the user wont see   that doesn t mean that the ai actually does think of that topic though    theres also some retries and repetition penalty randomness that goes up to stop looping which i think is a problem in all models right now   in comparison to openai the text generator api was easier to use because you can send max _sentences  and it will give you  sentence instead of trying to work out the sentence boundaries with the stop sequences  which is also supported but i dont find that as easy to work with ,created https aim game supposed get ai confess winner possible game also open ended xb backend generation https prompt engineering theres random topics picked user wont see mean ai actually think topic though theres also retries repetition penalty randomness goes stop looping think problem models right comparison openai text generator api easier use send max _sentences give sentence instead trying work sentence boundaries stop sequences also supported dont find easy work,p questions ai,p questions aicreated https aim game supposed get ai confess winner possible game also open ended xb backend generation https prompt engineering theres random topics picked user wont see mean ai actually think topic though theres also retries repetition penalty randomness goes stop looping think problem models right comparison openai text generator api easier use send max _sentences give sentence instead trying work sentence boundaries stop sequences also supported dont find easy work,"['p', 'questions', 'aicreated', 'https', 'aim', 'game', 'supposed', 'get', 'ai', 'confess', 'winner', 'possible', 'game', 'also', 'open', 'ended', 'xb', 'backend', 'generation', 'https', 'prompt', 'engineering', 'theres', 'random', 'topics', 'picked', 'user', 'wont', 'see', 'mean', 'ai', 'actually', 'think', 'topic', 'though', 'theres', 'also', 'retries', 'repetition', 'penalty', 'randomness', 'goes', 'stop', 'looping', 'think', 'problem', 'models', 'right', 'comparison', 'openai', 'text', 'generator', 'api', 'easier', 'use', 'send', 'max', '_sentences', 'give', 'sentence', 'instead', 'trying', 'work', 'sentence', 'boundaries', 'stop', 'sequences', 'also', 'supported', 'dont', 'find', 'easy', 'work']","['p', 'question', 'aicreat', 'http', 'aim', 'game', 'suppos', 'get', 'ai', 'confess', 'winner', 'possibl', 'game', 'also', 'open', 'end', 'xb', 'backend', 'gener', 'http', 'prompt', 'engin', 'there', 'random', 'topic', 'pick', 'user', 'wont', 'see', 'mean', 'ai', 'actual', 'think', 'topic', 'though', 'there', 'also', 'retri', 'repetit', 'penalti', 'random', 'goe', 'stop', 'loop', 'think', 'problem', 'model', 'right', 'comparison', 'openai', 'text', 'gener', 'api', 'easier', 'use', 'send', 'max', '_sentenc', 'give', 'sentenc', 'instead', 'tri', 'work', 'sentenc', 'boundari', 'stop', 'sequenc', 'also', 'support', 'dont', 'find', 'easi', 'work']"
129,142,142,soulful_squirrel,vpkpa2,[D] Recurrent neural network vs Gradient boosting for time series prediction,"Does anyone have any opinions on the pros vs. cons of using an RNN vs. a Gradient Boosting Tree model for a task where we want to make daily predictions on whether a user (of some app) is likely to take a certain type of action (so like binary classification)  in the near future ?

Pros for RNN:

* can take advantage of historical data to greater effect without extensive feature engineering
* I believe RNN's are more effective in situations when one has a large # of high dimensional features compared to the feature selection method tree models use
* neural networks scale better with large amounts of data

Cons of RNN:

* my main concern is with infrastructural complexity and cost that comes with training and serving the RNN.  I'll probably need a GPU or several GPU's.  Not sure if this is feasible given the current size of the company",23,23,2022-07-02 11:14:41, d  recurrent neural network vs gradient boosting for time series prediction,does anyone have any opinions on the pros vs  cons of using an rnn vs  a gradient boosting tree model for a task where we want to make daily predictions on whether a user  of some app  is likely to take a certain type of action  so like binary classification   in the near future  pros for rnn   can take advantage of historical data to greater effect without extensive feature engineering  i believe rnn s are more effective in situations when one has a large   of high dimensional features compared to the feature selection method tree models use  neural networks scale better with large amounts of datacons of rnn   my main concern is with infrastructural complexity and cost that comes with training and serving the rnn   i ll probably need a gpu or several gpu s   not sure if this is feasible given the current size of the company,anyone opinions pros vs cons using rnn vs gradient boosting tree model task want make daily predictions whether user app likely take certain type action like binary classification near future pros rnn take advantage historical data greater effect without extensive feature engineering believe rnn effective situations one large high dimensional features compared feature selection method tree models use neural networks scale better large amounts datacons rnn main concern infrastructural complexity cost comes training serving rnn probably need gpu several gpu sure feasible given current size company,recurrent neural network vs gradient boosting time series prediction,recurrent neural network vs gradient boosting time series predictionanyone opinions pros vs cons using rnn vs gradient boosting tree model task want make daily predictions whether user app likely take certain type action like binary classification near future pros rnn take advantage historical data greater effect without extensive feature engineering believe rnn effective situations one large high dimensional features compared feature selection method tree models use neural networks scale better large amounts datacons rnn main concern infrastructural complexity cost comes training serving rnn probably need gpu several gpu sure feasible given current size company,"['recurrent', 'neural', 'network', 'vs', 'gradient', 'boosting', 'time', 'series', 'predictionanyone', 'opinions', 'pros', 'vs', 'cons', 'using', 'rnn', 'vs', 'gradient', 'boosting', 'tree', 'model', 'task', 'want', 'make', 'daily', 'predictions', 'whether', 'user', 'app', 'likely', 'take', 'certain', 'type', 'action', 'like', 'binary', 'classification', 'near', 'future', 'pros', 'rnn', 'take', 'advantage', 'historical', 'data', 'greater', 'effect', 'without', 'extensive', 'feature', 'engineering', 'believe', 'rnn', 'effective', 'situations', 'one', 'large', 'high', 'dimensional', 'features', 'compared', 'feature', 'selection', 'method', 'tree', 'models', 'use', 'neural', 'networks', 'scale', 'better', 'large', 'amounts', 'datacons', 'rnn', 'main', 'concern', 'infrastructural', 'complexity', 'cost', 'comes', 'training', 'serving', 'rnn', 'probably', 'need', 'gpu', 'several', 'gpu', 'sure', 'feasible', 'given', 'current', 'size', 'company']","['recurr', 'neural', 'network', 'vs', 'gradient', 'boost', 'time', 'seri', 'predictionanyon', 'opinion', 'pro', 'vs', 'con', 'use', 'rnn', 'vs', 'gradient', 'boost', 'tree', 'model', 'task', 'want', 'make', 'daili', 'predict', 'whether', 'user', 'app', 'like', 'take', 'certain', 'type', 'action', 'like', 'binari', 'classif', 'near', 'futur', 'pro', 'rnn', 'take', 'advantag', 'histor', 'data', 'greater', 'effect', 'without', 'extens', 'featur', 'engin', 'believ', 'rnn', 'effect', 'situat', 'one', 'larg', 'high', 'dimension', 'featur', 'compar', 'featur', 'select', 'method', 'tree', 'model', 'use', 'neural', 'network', 'scale', 'better', 'larg', 'amount', 'datacon', 'rnn', 'main', 'concern', 'infrastructur', 'complex', 'cost', 'come', 'train', 'serv', 'rnn', 'probabl', 'need', 'gpu', 'sever', 'gpu', 'sure', 'feasibl', 'given', 'current', 'size', 'compani']"
130,143,143,EnricoShippole,vpbp9j,[P] Open-source LaMDA Model,"An open-source implementation for the pre-training architecture of Google's LaMDA in PyTorch. The research paper outlines an autoregressive, decoder-only, GPT-like transformer language model. The transformer uses T5 relative positional bias in the attention layers and gated-GELU activation function in the feed-forward layers. 

The repository currently contains a script for basic training as well as Huggingface datasets and Weights & Biases integration.

LaMDA research paper: [https://arxiv.org/abs/2201.08239](https://arxiv.org/abs/2201.08239)

Github repository for the model: [https://github.com/conceptofmind/LaMDA-pytorch](https://github.com/conceptofmind/LaMDA-pytorch)

The pre-training architecture was peer-reviewed by Dr. Phil Wang. Please check out and support his work: [https://github.com/lucidrains](https://github.com/lucidrains).",3,101,2022-07-02 03:07:00, p  open source lamda model,an open source implementation for the pre training architecture of google s lamda in pytorch  the research paper outlines an autoregressive  decoder only  gpt like transformer language model  the transformer uses t relative positional bias in the attention layers and gated gelu activation function in the feed forward layers  the repository currently contains a script for basic training as well as huggingface datasets and weights   biases integration lamda research paper   https github repository for the model   https the pre training architecture was peer reviewed by dr  phil wang  please check out and support his work   https   github com lucidrains  https   github com lucidrains  ,open source implementation pre training architecture google lamda pytorch research paper outlines autoregressive decoder gpt like transformer language model transformer uses relative positional bias attention layers gated gelu activation function feed forward layers repository currently contains script basic training well huggingface datasets weights biases integration lamda research paper https github repository model https pre training architecture peer reviewed dr phil wang please check support work https github com lucidrains https github com lucidrains,p open source lamda model,p open source lamda modelopen source implementation pre training architecture google lamda pytorch research paper outlines autoregressive decoder gpt like transformer language model transformer uses relative positional bias attention layers gated gelu activation function feed forward layers repository currently contains script basic training well huggingface datasets weights biases integration lamda research paper https github repository model https pre training architecture peer reviewed dr phil wang please check support work https github com lucidrains https github com lucidrains,"['p', 'open', 'source', 'lamda', 'modelopen', 'source', 'implementation', 'pre', 'training', 'architecture', 'google', 'lamda', 'pytorch', 'research', 'paper', 'outlines', 'autoregressive', 'decoder', 'gpt', 'like', 'transformer', 'language', 'model', 'transformer', 'uses', 'relative', 'positional', 'bias', 'attention', 'layers', 'gated', 'gelu', 'activation', 'function', 'feed', 'forward', 'layers', 'repository', 'currently', 'contains', 'script', 'basic', 'training', 'well', 'huggingface', 'datasets', 'weights', 'biases', 'integration', 'lamda', 'research', 'paper', 'https', 'github', 'repository', 'model', 'https', 'pre', 'training', 'architecture', 'peer', 'reviewed', 'dr', 'phil', 'wang', 'please', 'check', 'support', 'work', 'https', 'github', 'com', 'lucidrains', 'https', 'github', 'com', 'lucidrains']","['p', 'open', 'sourc', 'lamda', 'modelopen', 'sourc', 'implement', 'pre', 'train', 'architectur', 'googl', 'lamda', 'pytorch', 'research', 'paper', 'outlin', 'autoregress', 'decod', 'gpt', 'like', 'transform', 'languag', 'model', 'transform', 'use', 'rel', 'posit', 'bia', 'attent', 'layer', 'gate', 'gelu', 'activ', 'function', 'feed', 'forward', 'layer', 'repositori', 'current', 'contain', 'script', 'basic', 'train', 'well', 'huggingfac', 'dataset', 'weight', 'bias', 'integr', 'lamda', 'research', 'paper', 'http', 'github', 'repositori', 'model', 'http', 'pre', 'train', 'architectur', 'peer', 'review', 'dr', 'phil', 'wang', 'pleas', 'check', 'support', 'work', 'http', 'github', 'com', 'lucidrain', 'http', 'github', 'com', 'lucidrain']"
131,144,144,metalvendetta,vpphdb,[D] Monitoring GPU Power Usage,"Came across an interesting [article](https://wandb.ai/site/articles/deep-learning-and-climate-change) which talks precisely about how the gpu power usage affects the carbon footprint, while doing model training and model inference. Which are the best tools in the industry which helps track GPU power usage in popular machine learning frameworks? It will be helpful if there are tools which can be used as plugins to your software.",9,6,2022-07-02 16:41:51, d  monitoring gpu power usage,came across an interesting  article  https   wandb ai site articles deep learning and climate change  which talks precisely about how the gpu power usage affects the carbon footprint  while doing model training and model inference  which are the best tools in the industry which helps track gpu power usage in popular machine learning frameworks  it will be helpful if there are tools which can be used as plugins to your software ,came across interesting article https wandb ai site articles deep learning climate change talks precisely gpu power usage affects carbon footprint model training model inference best tools industry helps track gpu power usage popular machine learning frameworks helpful tools used plugins software,monitoring gpu power usage,monitoring gpu power usagecame across interesting article https wandb ai site articles deep learning climate change talks precisely gpu power usage affects carbon footprint model training model inference best tools industry helps track gpu power usage popular machine learning frameworks helpful tools used plugins software,"['monitoring', 'gpu', 'power', 'usagecame', 'across', 'interesting', 'article', 'https', 'wandb', 'ai', 'site', 'articles', 'deep', 'learning', 'climate', 'change', 'talks', 'precisely', 'gpu', 'power', 'usage', 'affects', 'carbon', 'footprint', 'model', 'training', 'model', 'inference', 'best', 'tools', 'industry', 'helps', 'track', 'gpu', 'power', 'usage', 'popular', 'machine', 'learning', 'frameworks', 'helpful', 'tools', 'used', 'plugins', 'software']","['monitor', 'gpu', 'power', 'usagecam', 'across', 'interest', 'articl', 'http', 'wandb', 'ai', 'site', 'articl', 'deep', 'learn', 'climat', 'chang', 'talk', 'precis', 'gpu', 'power', 'usag', 'affect', 'carbon', 'footprint', 'model', 'train', 'model', 'infer', 'best', 'tool', 'industri', 'help', 'track', 'gpu', 'power', 'usag', 'popular', 'machin', 'learn', 'framework', 'help', 'tool', 'use', 'plugin', 'softwar']"
132,145,145,radi-cho,vprmgc,[P] One word only: GPT-based story game,"For fun I developed an interface for the drama game in which a story is told one word at a time. Instead of playing it with a friend you can now play it together with GPT-J.

It is available here: [https://one-word-only.web.app/](https://one-word-only.web.app/singleplayer)  
I am open to feedback and if you find it interesting you can share the result on social media with #OneWordOnly",8,4,2022-07-02 18:47:58, p  one word only  gpt based story game,for fun i developed an interface for the drama game in which a story is told one word at a time  instead of playing it with a friend you can now play it together with gpt j it is available here   https i am open to feedback and if you find it interesting you can share the result on social media with  onewordonly,fun developed interface drama game story told one word time instead playing friend play together gpt j available https open feedback find interesting share result social media onewordonly,p one word gpt based story game,p one word gpt based story gamefun developed interface drama game story told one word time instead playing friend play together gpt j available https open feedback find interesting share result social media onewordonly,"['p', 'one', 'word', 'gpt', 'based', 'story', 'gamefun', 'developed', 'interface', 'drama', 'game', 'story', 'told', 'one', 'word', 'time', 'instead', 'playing', 'friend', 'play', 'together', 'gpt', 'j', 'available', 'https', 'open', 'feedback', 'find', 'interesting', 'share', 'result', 'social', 'media', 'onewordonly']","['p', 'one', 'word', 'gpt', 'base', 'stori', 'gamefun', 'develop', 'interfac', 'drama', 'game', 'stori', 'told', 'one', 'word', 'time', 'instead', 'play', 'friend', 'play', 'togeth', 'gpt', 'j', 'avail', 'http', 'open', 'feedback', 'find', 'interest', 'share', 'result', 'social', 'media', 'onewordonli']"
133,146,146,TernaryJimbo,vpyv76,[D] Algorithm for view prediction," I would like to do view prediction for short videos based on the first few frames of the video. No audio, just images. I'm hoping to train a model that can take in the first n sequential frames as input, and output a score that correlates to how many views the model thinks the vid might get.

I know I would like to use grad-CAM [https://github.com/jacobgil/pytorch-grad-cam](https://github.com/jacobgil/pytorch-grad-cam)

to visualize the areas in the frames which the model thinks results in higher view score.

Would a vision transformer or CNN be better for this task?

Also are there any pre-trained networks like YOLO that I should use transfer learning on to reduce the amount of data I will need for these predictions?",1,0,2022-07-03 00:42:00, d  algorithm for view prediction, i would like to do view prediction for short videos based on the first few frames of the video  no audio  just images  i m hoping to train a model that can take in the first n sequential frames as input  and output a score that correlates to how many views the model thinks the vid might get i know i would like to use grad cam  https to visualize the areas in the frames which the model thinks results in higher view score would a vision transformer or cnn be better for this task also are there any pre trained networks like yolo that i should use transfer learning on to reduce the amount of data i will need for these predictions ,would like view prediction short videos based first frames video audio images hoping train model take first n sequential frames input output score correlates many views model thinks vid might get know would like use grad cam https visualize areas frames model thinks results higher view score would vision transformer cnn better task also pre trained networks like yolo use transfer learning reduce amount data need predictions,algorithm view prediction,algorithm view predictionwould like view prediction short videos based first frames video audio images hoping train model take first n sequential frames input output score correlates many views model thinks vid might get know would like use grad cam https visualize areas frames model thinks results higher view score would vision transformer cnn better task also pre trained networks like yolo use transfer learning reduce amount data need predictions,"['algorithm', 'view', 'predictionwould', 'like', 'view', 'prediction', 'short', 'videos', 'based', 'first', 'frames', 'video', 'audio', 'images', 'hoping', 'train', 'model', 'take', 'first', 'n', 'sequential', 'frames', 'input', 'output', 'score', 'correlates', 'many', 'views', 'model', 'thinks', 'vid', 'might', 'get', 'know', 'would', 'like', 'use', 'grad', 'cam', 'https', 'visualize', 'areas', 'frames', 'model', 'thinks', 'results', 'higher', 'view', 'score', 'would', 'vision', 'transformer', 'cnn', 'better', 'task', 'also', 'pre', 'trained', 'networks', 'like', 'yolo', 'use', 'transfer', 'learning', 'reduce', 'amount', 'data', 'need', 'predictions']","['algorithm', 'view', 'predictionwould', 'like', 'view', 'predict', 'short', 'video', 'base', 'first', 'frame', 'video', 'audio', 'imag', 'hope', 'train', 'model', 'take', 'first', 'n', 'sequenti', 'frame', 'input', 'output', 'score', 'correl', 'mani', 'view', 'model', 'think', 'vid', 'might', 'get', 'know', 'would', 'like', 'use', 'grad', 'cam', 'http', 'visual', 'area', 'frame', 'model', 'think', 'result', 'higher', 'view', 'score', 'would', 'vision', 'transform', 'cnn', 'better', 'task', 'also', 'pre', 'train', 'network', 'like', 'yolo', 'use', 'transfer', 'learn', 'reduc', 'amount', 'data', 'need', 'predict']"
134,147,147,Competitive-Rub-1958,vpenn1,"[R] Minerva, Solving (more) complex mathematical problems at scale","Blog: [https://ai.googleblog.com/2022/06/minerva-solving-quantitative-reasoning.html](https://ai.googleblog.com/2022/06/minerva-solving-quantitative-reasoning.html)  
ABS: [https://arxiv.org/abs/2206.14858](https://arxiv.org/abs/2206.14858)  


The 512B model seems quite good at correcting reasoning errors by its smaller 62B couterpart, showing scale helps. 

A notable failure case, the JEE questions in the Appendix was pretty interesting because it solved the problem exactly how someone not familiar with JEE's difficulty would attempt to solve it - which isn't necessarily a bad thing, but the interesting parallel is that human students often make the same mistakes when starting out on their JEE prep. Wonder how more data would help in this case.

Overall, pretty good pushes over SOTA (even double-digit). I can't help but think that scaling is the currently most promising way, but its done too inefficiently - models spend vast resources memorizing when they could've used it to directly start meta-learning and reasoning abilities to formally deduce things precise enough for mathematical questions - just my 2c.",2,33,2022-07-02 05:29:42, r  minerva  solving  more  complex mathematical problems at scale,blog   https abs   https the b model seems quite good at correcting reasoning errors by its smaller b couterpart  showing scale helps  a notable failure case  the jee questions in the appendix was pretty interesting because it solved the problem exactly how someone not familiar with jee s difficulty would attempt to solve it   which isn t necessarily a bad thing  but the interesting parallel is that human students often make the same mistakes when starting out on their jee prep  wonder how more data would help in this case overall  pretty good pushes over sota  even double digit   i can t help but think that scaling is the currently most promising way  but its done too inefficiently   models spend vast resources memorizing when they could ve used it to directly start meta learning and reasoning abilities to formally deduce things precise enough for mathematical questions   just my c ,blog https abs https b model seems quite good correcting reasoning errors smaller b couterpart showing scale helps notable failure case jee questions appendix pretty interesting solved problem exactly someone familiar jee difficulty would attempt solve necessarily bad thing interesting parallel human students often make mistakes starting jee prep wonder data would help case overall pretty good pushes sota even double digit help think scaling currently promising way done inefficiently models spend vast resources memorizing could used directly start meta learning reasoning abilities formally deduce things precise enough mathematical questions c,r minerva solving complex mathematical problems scale,r minerva solving complex mathematical problems scaleblog https abs https b model seems quite good correcting reasoning errors smaller b couterpart showing scale helps notable failure case jee questions appendix pretty interesting solved problem exactly someone familiar jee difficulty would attempt solve necessarily bad thing interesting parallel human students often make mistakes starting jee prep wonder data would help case overall pretty good pushes sota even double digit help think scaling currently promising way done inefficiently models spend vast resources memorizing could used directly start meta learning reasoning abilities formally deduce things precise enough mathematical questions c,"['r', 'minerva', 'solving', 'complex', 'mathematical', 'problems', 'scaleblog', 'https', 'abs', 'https', 'b', 'model', 'seems', 'quite', 'good', 'correcting', 'reasoning', 'errors', 'smaller', 'b', 'couterpart', 'showing', 'scale', 'helps', 'notable', 'failure', 'case', 'jee', 'questions', 'appendix', 'pretty', 'interesting', 'solved', 'problem', 'exactly', 'someone', 'familiar', 'jee', 'difficulty', 'would', 'attempt', 'solve', 'necessarily', 'bad', 'thing', 'interesting', 'parallel', 'human', 'students', 'often', 'make', 'mistakes', 'starting', 'jee', 'prep', 'wonder', 'data', 'would', 'help', 'case', 'overall', 'pretty', 'good', 'pushes', 'sota', 'even', 'double', 'digit', 'help', 'think', 'scaling', 'currently', 'promising', 'way', 'done', 'inefficiently', 'models', 'spend', 'vast', 'resources', 'memorizing', 'could', 'used', 'directly', 'start', 'meta', 'learning', 'reasoning', 'abilities', 'formally', 'deduce', 'things', 'precise', 'enough', 'mathematical', 'questions', 'c']","['r', 'minerva', 'solv', 'complex', 'mathemat', 'problem', 'scaleblog', 'http', 'ab', 'http', 'b', 'model', 'seem', 'quit', 'good', 'correct', 'reason', 'error', 'smaller', 'b', 'couterpart', 'show', 'scale', 'help', 'notabl', 'failur', 'case', 'jee', 'question', 'appendix', 'pretti', 'interest', 'solv', 'problem', 'exactli', 'someon', 'familiar', 'jee', 'difficulti', 'would', 'attempt', 'solv', 'necessarili', 'bad', 'thing', 'interest', 'parallel', 'human', 'student', 'often', 'make', 'mistak', 'start', 'jee', 'prep', 'wonder', 'data', 'would', 'help', 'case', 'overal', 'pretti', 'good', 'push', 'sota', 'even', 'doubl', 'digit', 'help', 'think', 'scale', 'current', 'promis', 'way', 'done', 'ineffici', 'model', 'spend', 'vast', 'resourc', 'memor', 'could', 'use', 'directli', 'start', 'meta', 'learn', 'reason', 'abil', 'formal', 'deduc', 'thing', 'precis', 'enough', 'mathemat', 'question', 'c']"
135,148,148,ahsaor8,vpqfy2,[D] suggestions for graph embedding model?,"Any suggestions for best graph embedding model.
I already tried ( GIN , GCN , DIG , GAT ) I want to use it for anomaly detection task.",1,3,2022-07-02 17:40:35, d  suggestions for graph embedding model ,any suggestions for best graph embedding model i already tried   gin   gcn   dig   gat   i want to use it for anomaly detection task ,suggestions best graph embedding model already tried gin gcn dig gat want use anomaly detection task,suggestions graph embedding model,suggestions graph embedding modelsuggestions best graph embedding model already tried gin gcn dig gat want use anomaly detection task,"['suggestions', 'graph', 'embedding', 'modelsuggestions', 'best', 'graph', 'embedding', 'model', 'already', 'tried', 'gin', 'gcn', 'dig', 'gat', 'want', 'use', 'anomaly', 'detection', 'task']","['suggest', 'graph', 'embed', 'modelsuggest', 'best', 'graph', 'embed', 'model', 'alreadi', 'tri', 'gin', 'gcn', 'dig', 'gat', 'want', 'use', 'anomali', 'detect', 'task']"
136,150,150,singularpanda,vow85w,[D][R] Will reviewers have a bias if my paper was rejected by ICLR.,"If I submit my paper to ICLR and get rejected, the record will be always kept online. If I resubmit it to other following conferences, will the reviewer have a bias as they know it was rejected from ICLR?",57,93,2022-07-01 14:26:04, d  r  will reviewers have a bias if my paper was rejected by iclr ,if i submit my paper to iclr and get rejected  the record will be always kept online  if i resubmit it to other following conferences  will the reviewer have a bias as they know it was rejected from iclr ,submit paper iclr get rejected record always kept online resubmit following conferences reviewer bias know rejected iclr,r reviewers bias paper rejected iclr,r reviewers bias paper rejected iclrsubmit paper iclr get rejected record always kept online resubmit following conferences reviewer bias know rejected iclr,"['r', 'reviewers', 'bias', 'paper', 'rejected', 'iclrsubmit', 'paper', 'iclr', 'get', 'rejected', 'record', 'always', 'kept', 'online', 'resubmit', 'following', 'conferences', 'reviewer', 'bias', 'know', 'rejected', 'iclr']","['r', 'review', 'bia', 'paper', 'reject', 'iclrsubmit', 'paper', 'iclr', 'get', 'reject', 'record', 'alway', 'kept', 'onlin', 'resubmit', 'follow', 'confer', 'review', 'bia', 'know', 'reject', 'iclr']"
137,151,151,coderpotato,vp6dof,[D] Industrial applications of causal representation learning,"Causal representation learning (CRL) is a relatively new area of study. Causal inference has been around for a long time and its intersection with machine learning has been limited to causal discovery from data or invariant representation learning (IRL). To my understanding, IRL has a variable, usually called environment, and tries to learn some representation for the input which is invariant to this environment. The challenge is in removing the information about this environment from the representation while keeping enough information for some downstream task. You could formulate domain adaptation as IRL where domain is the environment variable. Or in fairness tasks, the sensitive attribute is the environment variable.

I believe that CRL is a more general scenario compared to IRL. In CRL, you have a larger graph with more variables and hence more complicated interactions. I believe such graphs are common in real-life and businesses where hundred of variables are used for predictions. Hence, the idea of causal representation may be beneficial.

I recently came upon [this Medium article by Lyft Engineering](https://eng.lyft.com/causal-forecasting-at-lyft-part-1-14cca6ff3d6d) where they described how they used causal forecasting in their business. I was wondering if anyone working in industry might share some of their experiences or expectations from causal representation learning applied to their fields. What do you think it could improve in your line of work?",1,12,2022-07-01 23:07:23, d  industrial applications of causal representation learning,causal representation learning  crl  is a relatively new area of study  causal inference has been around for a long time and its intersection with machine learning has been limited to causal discovery from data or invariant representation learning  irl   to my understanding  irl has a variable  usually called environment  and tries to learn some representation for the input which is invariant to this environment  the challenge is in removing the information about this environment from the representation while keeping enough information for some downstream task  you could formulate domain adaptation as irl where domain is the environment variable  or in fairness tasks  the sensitive attribute is the environment variable i believe that crl is a more general scenario compared to irl  in crl  you have a larger graph with more variables and hence more complicated interactions  i believe such graphs are common in real life and businesses where hundred of variables are used for predictions  hence  the idea of causal representation may be beneficial i recently came upon  this medium article by lyft engineering  https   eng lyft com causal forecasting at lyft part  ccaffdd  where they described how they used causal forecasting in their business  i was wondering if anyone working in industry might share some of their experiences or expectations from causal representation learning applied to their fields  what do you think it could improve in your line of work ,causal representation learning crl relatively area study causal inference around long time intersection machine learning limited causal discovery data invariant representation learning irl understanding irl variable usually called environment tries learn representation input invariant environment challenge removing information environment representation keeping enough information downstream task could formulate domain adaptation irl domain environment variable fairness tasks sensitive attribute environment variable believe crl general scenario compared irl crl larger graph variables hence complicated interactions believe graphs common real life businesses hundred variables used predictions hence idea causal representation may beneficial recently came upon medium article lyft engineering https eng lyft com causal forecasting lyft part ccaffdd described used causal forecasting business wondering anyone working industry might share experiences expectations causal representation learning applied fields think could improve line work,industrial applications causal representation learning,industrial applications causal representation learningcausal representation learning crl relatively area study causal inference around long time intersection machine learning limited causal discovery data invariant representation learning irl understanding irl variable usually called environment tries learn representation input invariant environment challenge removing information environment representation keeping enough information downstream task could formulate domain adaptation irl domain environment variable fairness tasks sensitive attribute environment variable believe crl general scenario compared irl crl larger graph variables hence complicated interactions believe graphs common real life businesses hundred variables used predictions hence idea causal representation may beneficial recently came upon medium article lyft engineering https eng lyft com causal forecasting lyft part ccaffdd described used causal forecasting business wondering anyone working industry might share experiences expectations causal representation learning applied fields think could improve line work,"['industrial', 'applications', 'causal', 'representation', 'learningcausal', 'representation', 'learning', 'crl', 'relatively', 'area', 'study', 'causal', 'inference', 'around', 'long', 'time', 'intersection', 'machine', 'learning', 'limited', 'causal', 'discovery', 'data', 'invariant', 'representation', 'learning', 'irl', 'understanding', 'irl', 'variable', 'usually', 'called', 'environment', 'tries', 'learn', 'representation', 'input', 'invariant', 'environment', 'challenge', 'removing', 'information', 'environment', 'representation', 'keeping', 'enough', 'information', 'downstream', 'task', 'could', 'formulate', 'domain', 'adaptation', 'irl', 'domain', 'environment', 'variable', 'fairness', 'tasks', 'sensitive', 'attribute', 'environment', 'variable', 'believe', 'crl', 'general', 'scenario', 'compared', 'irl', 'crl', 'larger', 'graph', 'variables', 'hence', 'complicated', 'interactions', 'believe', 'graphs', 'common', 'real', 'life', 'businesses', 'hundred', 'variables', 'used', 'predictions', 'hence', 'idea', 'causal', 'representation', 'may', 'beneficial', 'recently', 'came', 'upon', 'medium', 'article', 'lyft', 'engineering', 'https', 'eng', 'lyft', 'com', 'causal', 'forecasting', 'lyft', 'part', 'ccaffdd', 'described', 'used', 'causal', 'forecasting', 'business', 'wondering', 'anyone', 'working', 'industry', 'might', 'share', 'experiences', 'expectations', 'causal', 'representation', 'learning', 'applied', 'fields', 'think', 'could', 'improve', 'line', 'work']","['industri', 'applic', 'causal', 'represent', 'learningcaus', 'represent', 'learn', 'crl', 'rel', 'area', 'studi', 'causal', 'infer', 'around', 'long', 'time', 'intersect', 'machin', 'learn', 'limit', 'causal', 'discoveri', 'data', 'invari', 'represent', 'learn', 'irl', 'understand', 'irl', 'variabl', 'usual', 'call', 'environ', 'tri', 'learn', 'represent', 'input', 'invari', 'environ', 'challeng', 'remov', 'inform', 'environ', 'represent', 'keep', 'enough', 'inform', 'downstream', 'task', 'could', 'formul', 'domain', 'adapt', 'irl', 'domain', 'environ', 'variabl', 'fair', 'task', 'sensit', 'attribut', 'environ', 'variabl', 'believ', 'crl', 'gener', 'scenario', 'compar', 'irl', 'crl', 'larger', 'graph', 'variabl', 'henc', 'complic', 'interact', 'believ', 'graph', 'common', 'real', 'life', 'busi', 'hundr', 'variabl', 'use', 'predict', 'henc', 'idea', 'causal', 'represent', 'may', 'benefici', 'recent', 'came', 'upon', 'medium', 'articl', 'lyft', 'engin', 'http', 'eng', 'lyft', 'com', 'causal', 'forecast', 'lyft', 'part', 'ccaffdd', 'describ', 'use', 'causal', 'forecast', 'busi', 'wonder', 'anyon', 'work', 'industri', 'might', 'share', 'experi', 'expect', 'causal', 'represent', 'learn', 'appli', 'field', 'think', 'could', 'improv', 'line', 'work']"
138,152,152,XhoniShollaj,vpjz8l,Manually Add New Words & Assign Scores (Sentiment Analysis - BERT/XLNET ) [P],"Hi guys, 

I have a new project where I need to measure the sentiment of specific social media channels and topics. 

However, many of them involve slang words or sayings that confuse the models to have different sentiment values (f.ex WAGMI or DYOR). 

Are there any ways/tutorials/guides which show how we can incorporate new words and specific scores assigned to them? (I have already tried and succeeded in doing that with VADER, however, I don't see it as the optimal tool to measure the sentiment). 

Any answers or tips would be very much appreciated.",2,0,2022-07-02 10:29:30,manually add new words   assign scores  sentiment analysis   bert xlnet    p ,hi guys  i have a new project where i need to measure the sentiment of specific social media channels and topics  however  many of them involve slang words or sayings that confuse the models to have different sentiment values  f ex wagmi or dyor   are there any ways tutorials guides which show how we can incorporate new words and specific scores assigned to them   i have already tried and succeeded in doing that with vader  however  i don t see it as the optimal tool to measure the sentiment   any answers or tips would be very much appreciated ,hi guys project need measure sentiment specific social media channels topics however many involve slang sayings confuse models different sentiment values f ex wagmi dyor ways tutorials guides show incorporate specific scores assigned already tried succeeded vader however see optimal tool measure sentiment answers tips would much appreciated,manually assign scores sentiment analysis bert xlnet p,manually assign scores sentiment analysis bert xlnet phi guys project need measure sentiment specific social media channels topics however many involve slang sayings confuse models different sentiment values f ex wagmi dyor ways tutorials guides show incorporate specific scores assigned already tried succeeded vader however see optimal tool measure sentiment answers tips would much appreciated,"['manually', 'assign', 'scores', 'sentiment', 'analysis', 'bert', 'xlnet', 'phi', 'guys', 'project', 'need', 'measure', 'sentiment', 'specific', 'social', 'media', 'channels', 'topics', 'however', 'many', 'involve', 'slang', 'sayings', 'confuse', 'models', 'different', 'sentiment', 'values', 'f', 'ex', 'wagmi', 'dyor', 'ways', 'tutorials', 'guides', 'show', 'incorporate', 'specific', 'scores', 'assigned', 'already', 'tried', 'succeeded', 'vader', 'however', 'see', 'optimal', 'tool', 'measure', 'sentiment', 'answers', 'tips', 'would', 'much', 'appreciated']","['manual', 'assign', 'score', 'sentiment', 'analysi', 'bert', 'xlnet', 'phi', 'guy', 'project', 'need', 'measur', 'sentiment', 'specif', 'social', 'media', 'channel', 'topic', 'howev', 'mani', 'involv', 'slang', 'say', 'confus', 'model', 'differ', 'sentiment', 'valu', 'f', 'ex', 'wagmi', 'dyor', 'way', 'tutori', 'guid', 'show', 'incorpor', 'specif', 'score', 'assign', 'alreadi', 'tri', 'succeed', 'vader', 'howev', 'see', 'optim', 'tool', 'measur', 'sentiment', 'answer', 'tip', 'would', 'much', 'appreci']"
139,153,153,serend1p1ty-lee,vovp8q,[P] An elegant and strong PyTorch Trainer,"For lightweight use, [pytorch-lightning](https://github.com/Lightning-AI/lightning) is too heavy, and its source code will be very difficult for beginners to read, at least for me.

As we know, for a deep learning engineer, a powerful trainer is a sharp weapon. When reproducing the SOTA papers, you don't have to write a lot of template code every time and can pay more attention to the model implementation itself.

I opened source some works ([AAAI 21 SeqNet](https://github.com/serend1p1ty/SeqNet), [ICCV 21 MAED](https://github.com/ziniuwan/maed), etc) and earned more than 500 stars. After referring to some popular projects ([detectron2](https://github.com/facebookresearch/detectron2), [pytorch-image-models](https://github.com/rwightman/pytorch-image-models), and [mmcv](https://github.com/open-mmlab/mmcv)), based on my personal development experience, I developed a **SIMPLE** enough, **GENERIC** enough, and **STRONG** enough PyTorch Trainer: [core-pytorch-utils](https://github.com/serend1p1ty/core-pytorch-utils), also named CPU. CPU covers most details in the process of training a deep neural network, including:

* Auto logging to console and tensorboard.
* Auto checkpointing.
* Argument parser which can load a YAML configuration file.
* Make **ALL** PyTorch LR scheduler supporting warmup.
* Support distributed training.
* Support Automatically Mixed Precision (AMP) training.

I try to keep the project code as simple and readable as possible. So the code comments are very detailed and everyone can understand them. What's more, a good document is also available: [CPU document](https://core-pytorch-utils.readthedocs.io/en/latest/)

For deep learning green hands, you can learn how to:

* write a standard and clean training loop.
* use AMP to speed up your training.
* save checkpoint, and resume from it.
* perform more smooth, and readable logging.
* use the popular visualization library: tensorboard.

For old hands, we can talk about whether the structure of CPU is elegant and reasonable.

I have thought a lot about this framework, combining the advantages of several popular frameworks and discarding their shortcomings. Welcome to use it!",17,16,2022-07-01 13:49:39, p  an elegant and strong pytorch trainer,for lightweight use   pytorch lightning  https as we know  for a deep learning engineer  a powerful trainer is a sharp weapon  when reproducing the sota papers  you don t have to write a lot of template code every time and can pay more attention to the model implementation itself i opened source some works   aaai  seqnet  https   auto logging to console and tensorboard   auto checkpointing   argument parser which can load a yaml configuration file   make   all   pytorch lr scheduler supporting warmup   support distributed training   support automatically mixed precision  amp  training i try to keep the project code as simple and readable as possible  so the code comments are very detailed and everyone can understand them  what s more  a good document is also available   cpu document  https for deep learning green hands  you can learn how to   write a standard and clean training loop   use amp to speed up your training   save checkpoint  and resume from it   perform more smooth  and readable logging   use the popular visualization library  tensorboard for old hands  we can talk about whether the structure of cpu is elegant and reasonable i have thought a lot about this framework  combining the advantages of several popular frameworks and discarding their shortcomings  welcome to use it ,lightweight use pytorch lightning https know deep learning engineer powerful trainer sharp weapon reproducing sota papers write lot template code every time pay attention model implementation opened source works aaai seqnet https auto logging console tensorboard auto checkpointing argument parser load yaml configuration file make pytorch lr scheduler supporting warmup support distributed training support automatically mixed precision amp training try keep project code simple readable possible code comments detailed everyone understand good document also available cpu document https deep learning green hands learn write standard clean training loop use amp speed training save checkpoint resume perform smooth readable logging use popular visualization library tensorboard old hands talk whether structure cpu elegant reasonable thought lot framework combining advantages several popular frameworks discarding shortcomings welcome use,p elegant strong pytorch trainer,p elegant strong pytorch trainerlightweight use pytorch lightning https know deep learning engineer powerful trainer sharp weapon reproducing sota papers write lot template code every time pay attention model implementation opened source works aaai seqnet https auto logging console tensorboard auto checkpointing argument parser load yaml configuration file make pytorch lr scheduler supporting warmup support distributed training support automatically mixed precision amp training try keep project code simple readable possible code comments detailed everyone understand good document also available cpu document https deep learning green hands learn write standard clean training loop use amp speed training save checkpoint resume perform smooth readable logging use popular visualization library tensorboard old hands talk whether structure cpu elegant reasonable thought lot framework combining advantages several popular frameworks discarding shortcomings welcome use,"['p', 'elegant', 'strong', 'pytorch', 'trainerlightweight', 'use', 'pytorch', 'lightning', 'https', 'know', 'deep', 'learning', 'engineer', 'powerful', 'trainer', 'sharp', 'weapon', 'reproducing', 'sota', 'papers', 'write', 'lot', 'template', 'code', 'every', 'time', 'pay', 'attention', 'model', 'implementation', 'opened', 'source', 'works', 'aaai', 'seqnet', 'https', 'auto', 'logging', 'console', 'tensorboard', 'auto', 'checkpointing', 'argument', 'parser', 'load', 'yaml', 'configuration', 'file', 'make', 'pytorch', 'lr', 'scheduler', 'supporting', 'warmup', 'support', 'distributed', 'training', 'support', 'automatically', 'mixed', 'precision', 'amp', 'training', 'try', 'keep', 'project', 'code', 'simple', 'readable', 'possible', 'code', 'comments', 'detailed', 'everyone', 'understand', 'good', 'document', 'also', 'available', 'cpu', 'document', 'https', 'deep', 'learning', 'green', 'hands', 'learn', 'write', 'standard', 'clean', 'training', 'loop', 'use', 'amp', 'speed', 'training', 'save', 'checkpoint', 'resume', 'perform', 'smooth', 'readable', 'logging', 'use', 'popular', 'visualization', 'library', 'tensorboard', 'old', 'hands', 'talk', 'whether', 'structure', 'cpu', 'elegant', 'reasonable', 'thought', 'lot', 'framework', 'combining', 'advantages', 'several', 'popular', 'frameworks', 'discarding', 'shortcomings', 'welcome', 'use']","['p', 'eleg', 'strong', 'pytorch', 'trainerlightweight', 'use', 'pytorch', 'lightn', 'http', 'know', 'deep', 'learn', 'engin', 'power', 'trainer', 'sharp', 'weapon', 'reproduc', 'sota', 'paper', 'write', 'lot', 'templat', 'code', 'everi', 'time', 'pay', 'attent', 'model', 'implement', 'open', 'sourc', 'work', 'aaai', 'seqnet', 'http', 'auto', 'log', 'consol', 'tensorboard', 'auto', 'checkpoint', 'argument', 'parser', 'load', 'yaml', 'configur', 'file', 'make', 'pytorch', 'lr', 'schedul', 'support', 'warmup', 'support', 'distribut', 'train', 'support', 'automat', 'mix', 'precis', 'amp', 'train', 'tri', 'keep', 'project', 'code', 'simpl', 'readabl', 'possibl', 'code', 'comment', 'detail', 'everyon', 'understand', 'good', 'document', 'also', 'avail', 'cpu', 'document', 'http', 'deep', 'learn', 'green', 'hand', 'learn', 'write', 'standard', 'clean', 'train', 'loop', 'use', 'amp', 'speed', 'train', 'save', 'checkpoint', 'resum', 'perform', 'smooth', 'readabl', 'log', 'use', 'popular', 'visual', 'librari', 'tensorboard', 'old', 'hand', 'talk', 'whether', 'structur', 'cpu', 'eleg', 'reason', 'thought', 'lot', 'framework', 'combin', 'advantag', 'sever', 'popular', 'framework', 'discard', 'shortcom', 'welcom', 'use']"
140,154,154,topological_geometer,vpdaea,NN to VAE or equivalent? [R],"Hi all, I'm interested in any work that exist with respect to taking a NN that projects images (or generally, high-dimensional data) into vector embeddings, and, given the NN, somehow recreating images from their vector representations.

Of course, this is essentially trying to create a VAE from just the encoder, and it's impossible to perfectly recreate image --encoder-> vector --decoder-> image with only knowledge of --encoder-> since both elements of NNs and NNs as a whole are not in general invertible. But surely there's something that could be done here, even if it's an imperfect reconstruction? Does anyone know of any research or published work that explores this? Would really appreciate any insight here.",4,0,2022-07-02 04:21:02,nn to vae or equivalent   r ,hi all  i m interested in any work that exist with respect to taking a nn that projects images  or generally  high dimensional data  into vector embeddings  and  given the nn  somehow recreating images from their vector representations of course  this is essentially trying to create a vae from just the encoder  and it s impossible to perfectly recreate image   encoder   vector   decoder   image with only knowledge of   encoder   since both elements of nns and nns as a whole are not in general invertible  but surely there s something that could be done here  even if it s an imperfect reconstruction  does anyone know of any research or published work that explores this  would really appreciate any insight here ,hi interested work exist respect taking nn projects images generally high dimensional data vector embeddings given nn somehow recreating images vector representations course essentially trying create vae encoder impossible perfectly recreate image encoder vector decoder image knowledge encoder since elements nns nns whole general invertible surely something could done even imperfect reconstruction anyone know research published work explores would really appreciate insight,nn vae equivalent r,nn vae equivalent rhi interested work exist respect taking nn projects images generally high dimensional data vector embeddings given nn somehow recreating images vector representations course essentially trying create vae encoder impossible perfectly recreate image encoder vector decoder image knowledge encoder since elements nns nns whole general invertible surely something could done even imperfect reconstruction anyone know research published work explores would really appreciate insight,"['nn', 'vae', 'equivalent', 'rhi', 'interested', 'work', 'exist', 'respect', 'taking', 'nn', 'projects', 'images', 'generally', 'high', 'dimensional', 'data', 'vector', 'embeddings', 'given', 'nn', 'somehow', 'recreating', 'images', 'vector', 'representations', 'course', 'essentially', 'trying', 'create', 'vae', 'encoder', 'impossible', 'perfectly', 'recreate', 'image', 'encoder', 'vector', 'decoder', 'image', 'knowledge', 'encoder', 'since', 'elements', 'nns', 'nns', 'whole', 'general', 'invertible', 'surely', 'something', 'could', 'done', 'even', 'imperfect', 'reconstruction', 'anyone', 'know', 'research', 'published', 'work', 'explores', 'would', 'really', 'appreciate', 'insight']","['nn', 'vae', 'equival', 'rhi', 'interest', 'work', 'exist', 'respect', 'take', 'nn', 'project', 'imag', 'gener', 'high', 'dimension', 'data', 'vector', 'embed', 'given', 'nn', 'somehow', 'recreat', 'imag', 'vector', 'represent', 'cours', 'essenti', 'tri', 'creat', 'vae', 'encod', 'imposs', 'perfectli', 'recreat', 'imag', 'encod', 'vector', 'decod', 'imag', 'knowledg', 'encod', 'sinc', 'element', 'nn', 'nn', 'whole', 'gener', 'invert', 'sure', 'someth', 'could', 'done', 'even', 'imperfect', 'reconstruct', 'anyon', 'know', 'research', 'publish', 'work', 'explor', 'would', 'realli', 'appreci', 'insight']"
141,155,155,Typical-Ad-7443,vomboh,[R] Proprietary ML model in research paper,"I am writing a research paper, and in it I use a proprietary ML model I made. I want to show the model's results and I can explain how it works, but I don't want to explicitly provide the model/its code. Is that commonplace in research papers or must I include specifics to show validity?",58,50,2022-07-01 05:10:10, r  proprietary ml model in research paper,i am writing a research paper  and in it i use a proprietary ml model i made  i want to show the model s results and i can explain how it works  but i don t want to explicitly provide the model its code  is that commonplace in research papers or must i include specifics to show validity ,writing research paper use proprietary ml model made want show model results explain works want explicitly provide model code commonplace research papers must include specifics show validity,r proprietary ml model research paper,r proprietary ml model research paperwriting research paper use proprietary ml model made want show model results explain works want explicitly provide model code commonplace research papers must include specifics show validity,"['r', 'proprietary', 'ml', 'model', 'research', 'paperwriting', 'research', 'paper', 'use', 'proprietary', 'ml', 'model', 'made', 'want', 'show', 'model', 'results', 'explain', 'works', 'want', 'explicitly', 'provide', 'model', 'code', 'commonplace', 'research', 'papers', 'must', 'include', 'specifics', 'show', 'validity']","['r', 'proprietari', 'ml', 'model', 'research', 'paperwrit', 'research', 'paper', 'use', 'proprietari', 'ml', 'model', 'made', 'want', 'show', 'model', 'result', 'explain', 'work', 'want', 'explicitli', 'provid', 'model', 'code', 'commonplac', 'research', 'paper', 'must', 'includ', 'specif', 'show', 'valid']"
142,156,156,Meddhouib10,vow30k,[R] Layer scale in Covnext,"Hello,
In the convnext paper (Appendix A table 5) they stated that they used layer scale with a coefficient of 1e-5. 
Any idea what it is ?
I looked it up in the internet and I don’t seem to find anything useful.
Thanks !",2,6,2022-07-01 14:16:13, r  layer scale in covnext,hello in the convnext paper  appendix a table   they stated that they used layer scale with a coefficient of e   any idea what it is  i looked it up in the internet and i don t seem to find anything useful thanks  ,hello convnext paper appendix table stated used layer scale coefficient e idea looked internet seem find anything useful thanks,r layer scale covnext,r layer scale covnexthello convnext paper appendix table stated used layer scale coefficient e idea looked internet seem find anything useful thanks,"['r', 'layer', 'scale', 'covnexthello', 'convnext', 'paper', 'appendix', 'table', 'stated', 'used', 'layer', 'scale', 'coefficient', 'e', 'idea', 'looked', 'internet', 'seem', 'find', 'anything', 'useful', 'thanks']","['r', 'layer', 'scale', 'covnexthello', 'convnext', 'paper', 'appendix', 'tabl', 'state', 'use', 'layer', 'scale', 'coeffici', 'e', 'idea', 'look', 'internet', 'seem', 'find', 'anyth', 'use', 'thank']"
143,157,157,bikeskata,vonv6g,[R] Causal Machine Learning: A Survey and Open Problems,"Authors: Jean Kaddour, Aengus Lynch, Qi Liu, Matt J. Kusner, Ricardo Silva

Abs: ""Causal Machine Learning (CausalML) is an umbrella term for machine learning methods that formalize the data-generation process as a structural causal model (SCM). This allows one to reason about the effects of changes to this process (i.e., interventions) and what would have happened in hindsight (i.e., counterfactuals). We categorize work in \causalml into five groups according to the problems they tackle: (1) causal supervised learning, (2) causal generative modeling, (3) causal explanations, (4) causal fairness, (5) causal reinforcement learning. For each category, we systematically compare its methods and point out open problems. Further, we review modality-specific applications in computer vision, natural language processing, and graph representation learning. Finally, we provide an overview of causal benchmarks and a critical discussion of the state of this nascent field, including recommendations for future work.""

Link: https://arxiv.org/abs/2206.15475",0,31,2022-07-01 06:27:36, r  causal machine learning  a survey and open problems,authors  jean kaddour  aengus lynch  qi liu  matt j  kusner  ricardo silvaabs  causal machine learning  causalml  is an umbrella term for machine learning methods that formalize the data generation process as a structural causal model  scm   this allows one to reason about the effects of changes to this process  i e   interventions  and what would have happened in hindsight  i e   counterfactuals   we categorize work in  causalml into five groups according to the problems they tackle     causal supervised learning     causal generative modeling     causal explanations     causal fairness     causal reinforcement learning  for each category  we systematically compare its methods and point out open problems  further  we review modality specific applications in computer vision  natural language processing  and graph representation learning  finally  we provide an overview of causal benchmarks and a critical discussion of the state of this nascent field  including recommendations for future work link  https   arxiv org abs  ,authors jean kaddour aengus lynch qi liu matt j kusner ricardo silvaabs causal machine learning causalml umbrella term machine learning methods formalize data generation process structural causal model scm allows one reason effects changes process e interventions would happened hindsight e counterfactuals categorize work causalml five groups according problems tackle causal supervised learning causal generative modeling causal explanations causal fairness causal reinforcement learning category systematically compare methods point open problems review modality specific applications computer vision natural language processing graph representation learning finally provide overview causal benchmarks critical discussion state nascent field including recommendations future work link https arxiv org abs,r causal machine learning survey open problems,r causal machine learning survey open problemsauthors jean kaddour aengus lynch qi liu matt j kusner ricardo silvaabs causal machine learning causalml umbrella term machine learning methods formalize data generation process structural causal model scm allows one reason effects changes process e interventions would happened hindsight e counterfactuals categorize work causalml five groups according problems tackle causal supervised learning causal generative modeling causal explanations causal fairness causal reinforcement learning category systematically compare methods point open problems review modality specific applications computer vision natural language processing graph representation learning finally provide overview causal benchmarks critical discussion state nascent field including recommendations future work link https arxiv org abs,"['r', 'causal', 'machine', 'learning', 'survey', 'open', 'problemsauthors', 'jean', 'kaddour', 'aengus', 'lynch', 'qi', 'liu', 'matt', 'j', 'kusner', 'ricardo', 'silvaabs', 'causal', 'machine', 'learning', 'causalml', 'umbrella', 'term', 'machine', 'learning', 'methods', 'formalize', 'data', 'generation', 'process', 'structural', 'causal', 'model', 'scm', 'allows', 'one', 'reason', 'effects', 'changes', 'process', 'e', 'interventions', 'would', 'happened', 'hindsight', 'e', 'counterfactuals', 'categorize', 'work', 'causalml', 'five', 'groups', 'according', 'problems', 'tackle', 'causal', 'supervised', 'learning', 'causal', 'generative', 'modeling', 'causal', 'explanations', 'causal', 'fairness', 'causal', 'reinforcement', 'learning', 'category', 'systematically', 'compare', 'methods', 'point', 'open', 'problems', 'review', 'modality', 'specific', 'applications', 'computer', 'vision', 'natural', 'language', 'processing', 'graph', 'representation', 'learning', 'finally', 'provide', 'overview', 'causal', 'benchmarks', 'critical', 'discussion', 'state', 'nascent', 'field', 'including', 'recommendations', 'future', 'work', 'link', 'https', 'arxiv', 'org', 'abs']","['r', 'causal', 'machin', 'learn', 'survey', 'open', 'problemsauthor', 'jean', 'kaddour', 'aengu', 'lynch', 'qi', 'liu', 'matt', 'j', 'kusner', 'ricardo', 'silvaab', 'causal', 'machin', 'learn', 'causalml', 'umbrella', 'term', 'machin', 'learn', 'method', 'formal', 'data', 'gener', 'process', 'structur', 'causal', 'model', 'scm', 'allow', 'one', 'reason', 'effect', 'chang', 'process', 'e', 'intervent', 'would', 'happen', 'hindsight', 'e', 'counterfactu', 'categor', 'work', 'causalml', 'five', 'group', 'accord', 'problem', 'tackl', 'causal', 'supervis', 'learn', 'causal', 'gener', 'model', 'causal', 'explan', 'causal', 'fair', 'causal', 'reinforc', 'learn', 'categori', 'systemat', 'compar', 'method', 'point', 'open', 'problem', 'review', 'modal', 'specif', 'applic', 'comput', 'vision', 'natur', 'languag', 'process', 'graph', 'represent', 'learn', 'final', 'provid', 'overview', 'causal', 'benchmark', 'critic', 'discuss', 'state', 'nascent', 'field', 'includ', 'recommend', 'futur', 'work', 'link', 'http', 'arxiv', 'org', 'ab']"
144,158,158,DickMan64,vo2br1,[D] Why are transformers still being used?,"We already have architecture(s) which are supposed to fix one of the biggest issues with transformers, namely that they scale quadratically with input size. The performer scales linearly, which should allow for much bigger context windows, yet looking at recent large language models from major players, all of them seem to be using the old transformer save for some minor improvements. The only exception was Flamingo which had to use a Perceiver because images are huge.

So why haven't we ditched the transformer yet?",51,297,2022-06-30 12:50:05, d  why are transformers still being used ,we already have architecture s  which are supposed to fix one of the biggest issues with transformers  namely that they scale quadratically with input size  the performer scales linearly  which should allow for much bigger context windows  yet looking at recent large language models from major players  all of them seem to be using the old transformer save for some minor improvements  the only exception was flamingo which had to use a perceiver because images are huge so why haven t we ditched the transformer yet ,already architecture supposed fix one biggest issues transformers namely scale quadratically input size performer scales linearly allow much bigger context windows yet looking recent large language models major players seem using old transformer save minor improvements exception flamingo use perceiver images huge ditched transformer yet,transformers still used,transformers still usedalready architecture supposed fix one biggest issues transformers namely scale quadratically input size performer scales linearly allow much bigger context windows yet looking recent large language models major players seem using old transformer save minor improvements exception flamingo use perceiver images huge ditched transformer yet,"['transformers', 'still', 'usedalready', 'architecture', 'supposed', 'fix', 'one', 'biggest', 'issues', 'transformers', 'namely', 'scale', 'quadratically', 'input', 'size', 'performer', 'scales', 'linearly', 'allow', 'much', 'bigger', 'context', 'windows', 'yet', 'looking', 'recent', 'large', 'language', 'models', 'major', 'players', 'seem', 'using', 'old', 'transformer', 'save', 'minor', 'improvements', 'exception', 'flamingo', 'use', 'perceiver', 'images', 'huge', 'ditched', 'transformer', 'yet']","['transform', 'still', 'usedalreadi', 'architectur', 'suppos', 'fix', 'one', 'biggest', 'issu', 'transform', 'name', 'scale', 'quadrat', 'input', 'size', 'perform', 'scale', 'linearli', 'allow', 'much', 'bigger', 'context', 'window', 'yet', 'look', 'recent', 'larg', 'languag', 'model', 'major', 'player', 'seem', 'use', 'old', 'transform', 'save', 'minor', 'improv', 'except', 'flamingo', 'use', 'perceiv', 'imag', 'huge', 'ditch', 'transform', 'yet']"
145,159,159,MLJungle,vp1ggp,[D] length of input sequence for transformers?,"Is there a way of intuitively knowing how large the input sequence should for transformer (i.e GPT-2) for sequence generation?

for example, if all sequences are less than 100 words, and our goal is to generate a sequence, would it make sense to fit as many complete sequences into a max length of 100 (or 512?) to reduce the amount of padding? alternatively, would it be better to simply pad each sequence and not combine sequences?",2,1,2022-07-01 19:27:00, d  length of input sequence for transformers ,is there a way of intuitively knowing how large the input sequence should for transformer  i e gpt   for sequence generation for example  if all sequences are less than  words  and our goal is to generate a sequence  would it make sense to fit as many complete sequences into a max length of   or    to reduce the amount of padding  alternatively  would it be better to simply pad each sequence and not combine sequences ,way intuitively knowing large input sequence transformer e gpt sequence generation example sequences less goal generate sequence would make sense fit many complete sequences max length reduce amount padding alternatively would better simply pad sequence combine sequences,length input sequence transformers,length input sequence transformersway intuitively knowing large input sequence transformer e gpt sequence generation example sequences less goal generate sequence would make sense fit many complete sequences max length reduce amount padding alternatively would better simply pad sequence combine sequences,"['length', 'input', 'sequence', 'transformersway', 'intuitively', 'knowing', 'large', 'input', 'sequence', 'transformer', 'e', 'gpt', 'sequence', 'generation', 'example', 'sequences', 'less', 'goal', 'generate', 'sequence', 'would', 'make', 'sense', 'fit', 'many', 'complete', 'sequences', 'max', 'length', 'reduce', 'amount', 'padding', 'alternatively', 'would', 'better', 'simply', 'pad', 'sequence', 'combine', 'sequences']","['length', 'input', 'sequenc', 'transformersway', 'intuit', 'know', 'larg', 'input', 'sequenc', 'transform', 'e', 'gpt', 'sequenc', 'gener', 'exampl', 'sequenc', 'less', 'goal', 'gener', 'sequenc', 'would', 'make', 'sens', 'fit', 'mani', 'complet', 'sequenc', 'max', 'length', 'reduc', 'amount', 'pad', 'altern', 'would', 'better', 'simpli', 'pad', 'sequenc', 'combin', 'sequenc']"
146,160,160,vanilla-acc,vona4w,[D] Can we significantly reduce the training costs of image generation models by targeting a specific art style?,"Dall-E 2 can generate images in many different art styles: photo-realistic, different types of paintings, sketches too.

I'm wondering if it would be possible to train a version of Dall-E 2 that--for example--is only very good at generating sketches, but it cannot generate photos at all.

My intuition says this would significantly reduce the training costs, because you are reducing the search space for the output image significantly since the number of images that are sketches is much less than the total number of possible images.

At the same time, I'm not convinced that this is the case. Because the model would still need to learn the entire input space of objects in order to turn them into sketches.

What are y'alls thoughts on this?",6,9,2022-07-01 05:57:40, d  can we significantly reduce the training costs of image generation models by targeting a specific art style ,dall e  can generate images in many different art styles  photo realistic  different types of paintings  sketches too i m wondering if it would be possible to train a version of dall e  that  for example  is only very good at generating sketches  but it cannot generate photos at all my intuition says this would significantly reduce the training costs  because you are reducing the search space for the output image significantly since the number of images that are sketches is much less than the total number of possible images at the same time  i m not convinced that this is the case  because the model would still need to learn the entire input space of objects in order to turn them into sketches what are y alls thoughts on this ,dall e generate images many different art styles photo realistic different types paintings sketches wondering would possible train version dall e example good generating sketches cannot generate photos intuition says would significantly reduce training costs reducing search space output image significantly since number images sketches much less total number possible images time convinced case model would still need learn entire input space objects order turn sketches alls thoughts,significantly reduce training costs image generation models targeting specific art style,significantly reduce training costs image generation models targeting specific art styledall e generate images many different art styles photo realistic different types paintings sketches wondering would possible train version dall e example good generating sketches cannot generate photos intuition says would significantly reduce training costs reducing search space output image significantly since number images sketches much less total number possible images time convinced case model would still need learn entire input space objects order turn sketches alls thoughts,"['significantly', 'reduce', 'training', 'costs', 'image', 'generation', 'models', 'targeting', 'specific', 'art', 'styledall', 'e', 'generate', 'images', 'many', 'different', 'art', 'styles', 'photo', 'realistic', 'different', 'types', 'paintings', 'sketches', 'wondering', 'would', 'possible', 'train', 'version', 'dall', 'e', 'example', 'good', 'generating', 'sketches', 'can', 'not', 'generate', 'photos', 'intuition', 'says', 'would', 'significantly', 'reduce', 'training', 'costs', 'reducing', 'search', 'space', 'output', 'image', 'significantly', 'since', 'number', 'images', 'sketches', 'much', 'less', 'total', 'number', 'possible', 'images', 'time', 'convinced', 'case', 'model', 'would', 'still', 'need', 'learn', 'entire', 'input', 'space', 'objects', 'order', 'turn', 'sketches', 'alls', 'thoughts']","['significantli', 'reduc', 'train', 'cost', 'imag', 'gener', 'model', 'target', 'specif', 'art', 'styledal', 'e', 'gener', 'imag', 'mani', 'differ', 'art', 'style', 'photo', 'realist', 'differ', 'type', 'paint', 'sketch', 'wonder', 'would', 'possibl', 'train', 'version', 'dall', 'e', 'exampl', 'good', 'gener', 'sketch', 'can', 'not', 'gener', 'photo', 'intuit', 'say', 'would', 'significantli', 'reduc', 'train', 'cost', 'reduc', 'search', 'space', 'output', 'imag', 'significantli', 'sinc', 'number', 'imag', 'sketch', 'much', 'less', 'total', 'number', 'possibl', 'imag', 'time', 'convinc', 'case', 'model', 'would', 'still', 'need', 'learn', 'entir', 'input', 'space', 'object', 'order', 'turn', 'sketch', 'all', 'thought']"
147,161,161,alexparinov,vobg2z,[P] Albumentations 1.2 is released (a Python library for image augmentation),"The new release of a fast and flexible library for image augmentation includes:

# New augmentations:

* **UnsharpMask** sharpens the input image using Unsharp Masking processing and overlays the result with the original image.
* **PixelDropout** randomly replaces pixels with the passed value.

https://preview.redd.it/ic1nm7mw3s891.png?width=942&format=png&auto=webp&s=c95e319f26a19bad42d33fd84e0ef27703db9095

* **RingingOvershoot** creates ringing or overshoot artifacts by convolving the image with a 2D sinc filter. 
* **AdvancedBlur** blurs the input image using a Generalized Normal filter with randomly selected parameters. It also adds multiplicative noise to generated kernel before convolution.

https://preview.redd.it/wb1v6vyw3s891.png?width=941&format=png&auto=webp&s=2e57ae1b583b7aab7c30125058a25ee296afd2bd

# Improvements and bug fixes

Fixed all `np.random` use cases to prevent identical values when using multiprocessing. Also, we fixed corner cases and made improvements for many augmentations.

# Release notes

Full release notes are available at [https://github.com/albumentations-team/albumentations/releases/tag/1.2.0](https://github.com/albumentations-team/albumentations/releases/tag/1.2.0)

# Installation

As always, you can install the latest version of the library by running:

    pip install -U albumentations",4,49,2022-06-30 21:13:16, p  albumentations   is released  a python library for image augmentation ,the new release of a fast and flexible library for image augmentation includes   new augmentations     unsharpmask   sharpens the input image using unsharp masking processing and overlays the result with the original image     pixeldropout   randomly replaces pixels with the passed value https     ringingovershoot   creates ringing or overshoot artifacts by convolving the image with a d sinc filter      advancedblur   blurs the input image using a generalized normal filter with randomly selected parameters  it also adds multiplicative noise to generated kernel before convolution https   improvements and bug fixesfixed all  np random  use cases to prevent identical values when using multiprocessing  also  we fixed corner cases and made improvements for many augmentations   release notesfull release notes are available at  https   installationas always  you can install the latest version of the library by running     pip install  u albumentations,release fast flexible library image augmentation includes augmentations unsharpmask sharpens input image using unsharp masking processing overlays result original image pixeldropout randomly replaces pixels passed value https ringingovershoot creates ringing overshoot artifacts convolving image sinc filter advancedblur blurs input image using generalized normal filter randomly selected parameters also adds multiplicative noise generated kernel convolution https improvements bug fixesfixed np random use cases prevent identical values using multiprocessing also fixed corner cases made improvements many augmentations release notesfull release notes available https installationas always install latest version library running pip install u albumentations,p albumentations released python library image augmentation,p albumentations released python library image augmentationrelease fast flexible library image augmentation includes augmentations unsharpmask sharpens input image using unsharp masking processing overlays result original image pixeldropout randomly replaces pixels passed value https ringingovershoot creates ringing overshoot artifacts convolving image sinc filter advancedblur blurs input image using generalized normal filter randomly selected parameters also adds multiplicative noise generated kernel convolution https improvements bug fixesfixed np random use cases prevent identical values using multiprocessing also fixed corner cases made improvements many augmentations release notesfull release notes available https installationas always install latest version library running pip install u albumentations,"['p', 'albumentations', 'released', 'python', 'library', 'image', 'augmentationrelease', 'fast', 'flexible', 'library', 'image', 'augmentation', 'includes', 'augmentations', 'unsharpmask', 'sharpens', 'input', 'image', 'using', 'unsharp', 'masking', 'processing', 'overlays', 'result', 'original', 'image', 'pixeldropout', 'randomly', 'replaces', 'pixels', 'passed', 'value', 'https', 'ringingovershoot', 'creates', 'ringing', 'overshoot', 'artifacts', 'convolving', 'image', 'sinc', 'filter', 'advancedblur', 'blurs', 'input', 'image', 'using', 'generalized', 'normal', 'filter', 'randomly', 'selected', 'parameters', 'also', 'adds', 'multiplicative', 'noise', 'generated', 'kernel', 'convolution', 'https', 'improvements', 'bug', 'fixesfixed', 'np', 'random', 'use', 'cases', 'prevent', 'identical', 'values', 'using', 'multiprocessing', 'also', 'fixed', 'corner', 'cases', 'made', 'improvements', 'many', 'augmentations', 'release', 'notesfull', 'release', 'notes', 'available', 'https', 'installationas', 'always', 'install', 'latest', 'version', 'library', 'running', 'pip', 'install', 'u', 'albumentations']","['p', 'albument', 'releas', 'python', 'librari', 'imag', 'augmentationreleas', 'fast', 'flexibl', 'librari', 'imag', 'augment', 'includ', 'augment', 'unsharpmask', 'sharpen', 'input', 'imag', 'use', 'unsharp', 'mask', 'process', 'overlay', 'result', 'origin', 'imag', 'pixeldropout', 'randomli', 'replac', 'pixel', 'pass', 'valu', 'http', 'ringingovershoot', 'creat', 'ring', 'overshoot', 'artifact', 'convolv', 'imag', 'sinc', 'filter', 'advancedblur', 'blur', 'input', 'imag', 'use', 'gener', 'normal', 'filter', 'randomli', 'select', 'paramet', 'also', 'add', 'multipl', 'nois', 'gener', 'kernel', 'convolut', 'http', 'improv', 'bug', 'fixesfix', 'np', 'random', 'use', 'case', 'prevent', 'ident', 'valu', 'use', 'multiprocess', 'also', 'fix', 'corner', 'case', 'made', 'improv', 'mani', 'augment', 'releas', 'notesful', 'releas', 'note', 'avail', 'http', 'installationa', 'alway', 'instal', 'latest', 'version', 'librari', 'run', 'pip', 'instal', 'u', 'albument']"
148,162,162,MurlocXYZ,vokgvl,[D] Usage of the [class] token in ViT,"So I've read up on [ViT](https://arxiv.org/pdf/2010.11929.pdf), and while it's an impressive architecture, I seem to notice that they are using a \[class\] token to get the actual class from an input image (see image below).

&#x200B;

[Architecture of ViT](https://preview.redd.it/xjut8nla1u891.png?width=912&format=png&auto=webp&s=a67da2606fd450bbffc4c678aa1e41877b76ec6b)

While I know that it's standard to use an extra token in this fashion, since the encoder spits out one embedding for every input token (or patch in this case), I was wondering why don't we simply concatenate all the embeddings before feeding them into the MLP head (of an appropriate size)?

&#x200B;

It seems to me like we are discarding a lot of information here, that could be helpful in the classification task. It's true, in theory, that the attention should take care of that, but do you know of any papers where this concatenation strategy has been tried? Does it even make sense?

&#x200B;

Cheers!",12,11,2022-07-01 03:44:21, d  usage of the  class  token in vit,so i ve read up on  vit  https   xb  architecture of vit  https while i know that it s standard to use an extra token in this fashion  since the encoder spits out one embedding for every input token  or patch in this case   i was wondering why don t we simply concatenate all the embeddings before feeding them into the mlp head  of an appropriate size    xb it seems to me like we are discarding a lot of information here  that could be helpful in the classification task  it s true  in theory  that the attention should take care of that  but do you know of any papers where this concatenation strategy has been tried  does it even make sense   xb cheers ,read vit https xb architecture vit https know standard use extra token fashion since encoder spits one embedding every input token patch case wondering simply concatenate embeddings feeding mlp head appropriate size xb seems like discarding lot information could helpful classification task true theory attention take care know papers concatenation strategy tried even make sense xb cheers,usage class token vit,usage class token vitread vit https xb architecture vit https know standard use extra token fashion since encoder spits one embedding every input token patch case wondering simply concatenate embeddings feeding mlp head appropriate size xb seems like discarding lot information could helpful classification task true theory attention take care know papers concatenation strategy tried even make sense xb cheers,"['usage', 'class', 'token', 'vitread', 'vit', 'https', 'xb', 'architecture', 'vit', 'https', 'know', 'standard', 'use', 'extra', 'token', 'fashion', 'since', 'encoder', 'spits', 'one', 'embedding', 'every', 'input', 'token', 'patch', 'case', 'wondering', 'simply', 'concatenate', 'embeddings', 'feeding', 'mlp', 'head', 'appropriate', 'size', 'xb', 'seems', 'like', 'discarding', 'lot', 'information', 'could', 'helpful', 'classification', 'task', 'true', 'theory', 'attention', 'take', 'care', 'know', 'papers', 'concatenation', 'strategy', 'tried', 'even', 'make', 'sense', 'xb', 'cheers']","['usag', 'class', 'token', 'vitread', 'vit', 'http', 'xb', 'architectur', 'vit', 'http', 'know', 'standard', 'use', 'extra', 'token', 'fashion', 'sinc', 'encod', 'spit', 'one', 'embed', 'everi', 'input', 'token', 'patch', 'case', 'wonder', 'simpli', 'concaten', 'embed', 'feed', 'mlp', 'head', 'appropri', 'size', 'xb', 'seem', 'like', 'discard', 'lot', 'inform', 'could', 'help', 'classif', 'task', 'true', 'theori', 'attent', 'take', 'care', 'know', 'paper', 'concaten', 'strategi', 'tri', 'even', 'make', 'sens', 'xb', 'cheer']"
149,163,163,Silver_Doughnut_8175,voa79b,[D] Are there still any SOTA architectures trainable from-scratch for a student ?,"When I say ""SOTA"" I'm talking about recent architectures like ViT, BERT, GPT-like models.. Is it possible to train any of these from scratch (no pre-trained checkpoint) with low resources (Colab, Colab pro) ?",16,28,2022-06-30 20:19:36, d  are there still any sota architectures trainable from scratch for a student  ,when i say sota i m talking about recent architectures like vit  bert  gpt like models   is it possible to train any of these from scratch  no pre trained checkpoint  with low resources  colab  colab pro   ,say sota talking recent architectures like vit bert gpt like models possible train scratch pre trained checkpoint low resources colab colab pro,still sota architectures trainable scratch student,still sota architectures trainable scratch studentsay sota talking recent architectures like vit bert gpt like models possible train scratch pre trained checkpoint low resources colab colab pro,"['still', 'sota', 'architectures', 'trainable', 'scratch', 'studentsay', 'sota', 'talking', 'recent', 'architectures', 'like', 'vit', 'bert', 'gpt', 'like', 'models', 'possible', 'train', 'scratch', 'pre', 'trained', 'checkpoint', 'low', 'resources', 'colab', 'colab', 'pro']","['still', 'sota', 'architectur', 'trainabl', 'scratch', 'studentsay', 'sota', 'talk', 'recent', 'architectur', 'like', 'vit', 'bert', 'gpt', 'like', 'model', 'possibl', 'train', 'scratch', 'pre', 'train', 'checkpoint', 'low', 'resourc', 'colab', 'colab', 'pro']"
150,164,164,RafiRafiRafiRafi,vo7v4d,[D] Algorithms for Anomaly Detection,"Hi guys,

I am dealing with 1000s of devices distributed over the whole world. These devices log and upload events (e.g. various kinds of device faults) including a time stamp to a database. 

My tasks now is to analyze these time series of events, detect anomalies and then automatically send notifications about these anomalies. 

Anomalies I want to detect may include things like:
- sudden spikes in the number of events
- sudden changes of the type of events
- long term drift of the number of events
- etc. etc. 

Any advice on suitable algorithms for this kind of problems and/or according literature would be highly appreciated.

Thanks! 👍",27,31,2022-06-30 18:32:15, d  algorithms for anomaly detection,hi guys i am dealing with s of devices distributed over the whole world  these devices log and upload events  e g  various kinds of device faults  including a time stamp to a database  my tasks now is to analyze these time series of events  detect anomalies and then automatically send notifications about these anomalies  anomalies i want to detect may include things like   sudden spikes in the number of events  sudden changes of the type of events  long term drift of the number of events  etc  etc  any advice on suitable algorithms for this kind of problems and or according literature would be highly appreciated thanks   ,hi guys dealing devices distributed whole world devices log upload events e g various kinds device faults including time stamp database tasks analyze time series events detect anomalies automatically send notifications anomalies anomalies want detect may include things like sudden spikes number events sudden changes type events long term drift number events etc etc advice suitable algorithms kind problems according literature would highly appreciated thanks,algorithms anomaly detection,algorithms anomaly detectionhi guys dealing devices distributed whole world devices log upload events e g various kinds device faults including time stamp database tasks analyze time series events detect anomalies automatically send notifications anomalies anomalies want detect may include things like sudden spikes number events sudden changes type events long term drift number events etc etc advice suitable algorithms kind problems according literature would highly appreciated thanks,"['algorithms', 'anomaly', 'detectionhi', 'guys', 'dealing', 'devices', 'distributed', 'whole', 'world', 'devices', 'log', 'upload', 'events', 'e', 'g', 'various', 'kinds', 'device', 'faults', 'including', 'time', 'stamp', 'database', 'tasks', 'analyze', 'time', 'series', 'events', 'detect', 'anomalies', 'automatically', 'send', 'notifications', 'anomalies', 'anomalies', 'want', 'detect', 'may', 'include', 'things', 'like', 'sudden', 'spikes', 'number', 'events', 'sudden', 'changes', 'type', 'events', 'long', 'term', 'drift', 'number', 'events', 'etc', 'etc', 'advice', 'suitable', 'algorithms', 'kind', 'problems', 'according', 'literature', 'would', 'highly', 'appreciated', 'thanks']","['algorithm', 'anomali', 'detectionhi', 'guy', 'deal', 'devic', 'distribut', 'whole', 'world', 'devic', 'log', 'upload', 'event', 'e', 'g', 'variou', 'kind', 'devic', 'fault', 'includ', 'time', 'stamp', 'databas', 'task', 'analyz', 'time', 'seri', 'event', 'detect', 'anomali', 'automat', 'send', 'notif', 'anomali', 'anomali', 'want', 'detect', 'may', 'includ', 'thing', 'like', 'sudden', 'spike', 'number', 'event', 'sudden', 'chang', 'type', 'event', 'long', 'term', 'drift', 'number', 'event', 'etc', 'etc', 'advic', 'suitabl', 'algorithm', 'kind', 'problem', 'accord', 'literatur', 'would', 'highli', 'appreci', 'thank']"
151,165,165,poetichobbit7,voaxi9,[N][R][CfP] Workshop on Artificial Intelligence for Strategy Games @ AIIDE 22,"Hello Everyone! My name is Derek, and I am a co-chair for the Workshop on AI for Strategy Games at AIIDE this year. I wanted to share some info about the workshop for those that may be interested in discussing the future of AI for strategy games or looking to publish/get feedback on any work research you are doing with strategy games. Feel free to message me if you have any questions!

**Workshop website**: [https://skatgame.net/mburo/aiide22ws/](https://skatgame.net/mburo/aiide22ws/)

**Submission deadline**: July 29, 2022

# Topics

This workshop welcomes original research contributions, position papers, competition AI system descriptions, and post-mortem game analyses in the area of AI for strategy games --- including modern video strategy games (such as FPS and RTS games), and turn based games and puzzles. Topics include, but are not restricted to:  

* Reinforcement Learning in Strategy Games 
* State and Action Abstractions 
* Heuristic Search Applied to High-Branching Factor Domains   
* Player Modelling, Co-operation and Exploitation 
* Plan and Goal Recognition 
* Game Balancing 
* Level Generation 
* Motion Planning 
* High-Level Strategic Planning 
* Dealing with Imperfect Information 

# Background

From 2012-2017 successful workshops on AI for adversarial real-time games were held at AIIDE in response to the considerable interest in the subject and the limited time for reporting on the annual StarCraft competition in the main AIIDE conference. 

Since 2018, we've broadened the workshop scope to cover AI for all kinds of strategy games in the hope to attract more submissions and to spark discussions between research groups focusing on board game, real-time strategy game, and general video game AI. 

The goal of this workshop is to again bring together AI researchers and game AI programmers from industry, who are interested in strategic game AI, to present and exchange ideas on the subject, and to discuss how academia and game companies can work together to improve the state-of-the-art in AI for games. 

### Workshop Format

This one-day workshop will consist of paper presentations on strategy game related AI topics (listed below), game competition descriptions (StarCraft Broodwar and μRTS), perhaps an invited presentation, and a discussion on future research. The competition summaries and results will be presented at the main AIIDE conference. 

Contributions will be peer-reviewed and meet AAAI workshop standards. Accepted workshop papers will be published as a single CEUR proceedings book.",8,9,2022-06-30 20:50:50, n  r  cfp  workshop on artificial intelligence for strategy games   aiide ,hello everyone  my name is derek  and i am a co chair for the workshop on ai for strategy games at aiide this year  i wanted to share some info about the workshop for those that may be interested in discussing the future of ai for strategy games or looking to publish get feedback on any work research you are doing with strategy games  feel free to message me if you have any questions   workshop website     https   submission deadline    july     topicsthis workshop welcomes original research contributions  position papers  competition ai system descriptions  and post mortem game analyses in the area of ai for strategy games     including modern video strategy games  such as fps and rts games   and turn based games and puzzles  topics include  but are not restricted to     reinforcement learning in strategy games   state and action abstractions   heuristic search applied to high branching factor domains     player modelling  co operation and exploitation   plan and goal recognition   game balancing   level generation   motion planning   high level strategic planning   dealing with imperfect information   backgroundfrom   successful workshops on ai for adversarial real time games were held at aiide in response to the considerable interest in the subject and the limited time for reporting on the annual starcraft competition in the main aiide conference  since   we ve broadened the workshop scope to cover ai for all kinds of strategy games in the hope to attract more submissions and to spark discussions between research groups focusing on board game  real time strategy game  and general video game ai  the goal of this workshop is to again bring together ai researchers and game ai programmers from industry  who are interested in strategic game ai  to present and exchange ideas on the subject  and to discuss how academia and game companies can work together to improve the state of the art in ai for games      workshop formatthis one day workshop will consist of paper presentations on strategy game related ai topics  listed below   game competition descriptions  starcraft broodwar and μrts   perhaps an invited presentation  and a discussion on future research  the competition summaries and results will be presented at the main aiide conference  contributions will be peer reviewed and meet aaai workshop standards  accepted workshop papers will be published as a single ceur proceedings book ,hello everyone name derek co chair workshop ai strategy games aiide year wanted share info workshop may interested discussing future ai strategy games looking publish get feedback work research strategy games feel free message questions workshop website https submission deadline july topicsthis workshop welcomes original research contributions position papers competition ai system descriptions post mortem game analyses area ai strategy games including modern video strategy games fps rts games turn based games puzzles topics include restricted reinforcement learning strategy games state action abstractions heuristic search applied high branching factor domains player modelling co operation exploitation plan goal recognition game balancing level generation motion planning high level strategic planning dealing imperfect information backgroundfrom successful workshops ai adversarial real time games held aiide response considerable interest subject limited time reporting annual starcraft competition main aiide conference since broadened workshop scope cover ai kinds strategy games hope attract submissions spark discussions research groups focusing board game real time strategy game general video game ai goal workshop bring together ai researchers game ai programmers industry interested strategic game ai present exchange ideas subject discuss academia game companies work together improve state art ai games workshop formatthis one day workshop consist paper presentations strategy game related ai topics listed game competition descriptions starcraft broodwar μrts perhaps invited presentation discussion future research competition summaries results presented main aiide conference contributions peer reviewed meet aaai workshop standards accepted workshop papers published single ceur proceedings book,n r cfp workshop artificial intelligence strategy games aiide,n r cfp workshop artificial intelligence strategy games aiidehello everyone name derek co chair workshop ai strategy games aiide year wanted share info workshop may interested discussing future ai strategy games looking publish get feedback work research strategy games feel free message questions workshop website https submission deadline july topicsthis workshop welcomes original research contributions position papers competition ai system descriptions post mortem game analyses area ai strategy games including modern video strategy games fps rts games turn based games puzzles topics include restricted reinforcement learning strategy games state action abstractions heuristic search applied high branching factor domains player modelling co operation exploitation plan goal recognition game balancing level generation motion planning high level strategic planning dealing imperfect information backgroundfrom successful workshops ai adversarial real time games held aiide response considerable interest subject limited time reporting annual starcraft competition main aiide conference since broadened workshop scope cover ai kinds strategy games hope attract submissions spark discussions research groups focusing board game real time strategy game general video game ai goal workshop bring together ai researchers game ai programmers industry interested strategic game ai present exchange ideas subject discuss academia game companies work together improve state art ai games workshop formatthis one day workshop consist paper presentations strategy game related ai topics listed game competition descriptions starcraft broodwar μrts perhaps invited presentation discussion future research competition summaries results presented main aiide conference contributions peer reviewed meet aaai workshop standards accepted workshop papers published single ceur proceedings book,"['n', 'r', 'cfp', 'workshop', 'artificial', 'intelligence', 'strategy', 'games', 'aiidehello', 'everyone', 'name', 'derek', 'co', 'chair', 'workshop', 'ai', 'strategy', 'games', 'aiide', 'year', 'wanted', 'share', 'info', 'workshop', 'may', 'interested', 'discussing', 'future', 'ai', 'strategy', 'games', 'looking', 'publish', 'get', 'feedback', 'work', 'research', 'strategy', 'games', 'feel', 'free', 'message', 'questions', 'workshop', 'website', 'https', 'submission', 'deadline', 'july', 'topicsthis', 'workshop', 'welcomes', 'original', 'research', 'contributions', 'position', 'papers', 'competition', 'ai', 'system', 'descriptions', 'post', 'mortem', 'game', 'analyses', 'area', 'ai', 'strategy', 'games', 'including', 'modern', 'video', 'strategy', 'games', 'fps', 'rts', 'games', 'turn', 'based', 'games', 'puzzles', 'topics', 'include', 'restricted', 'reinforcement', 'learning', 'strategy', 'games', 'state', 'action', 'abstractions', 'heuristic', 'search', 'applied', 'high', 'branching', 'factor', 'domains', 'player', 'modelling', 'co', 'operation', 'exploitation', 'plan', 'goal', 'recognition', 'game', 'balancing', 'level', 'generation', 'motion', 'planning', 'high', 'level', 'strategic', 'planning', 'dealing', 'imperfect', 'information', 'backgroundfrom', 'successful', 'workshops', 'ai', 'adversarial', 'real', 'time', 'games', 'held', 'aiide', 'response', 'considerable', 'interest', 'subject', 'limited', 'time', 'reporting', 'annual', 'starcraft', 'competition', 'main', 'aiide', 'conference', 'since', 'broadened', 'workshop', 'scope', 'cover', 'ai', 'kinds', 'strategy', 'games', 'hope', 'attract', 'submissions', 'spark', 'discussions', 'research', 'groups', 'focusing', 'board', 'game', 'real', 'time', 'strategy', 'game', 'general', 'video', 'game', 'ai', 'goal', 'workshop', 'bring', 'together', 'ai', 'researchers', 'game', 'ai', 'programmers', 'industry', 'interested', 'strategic', 'game', 'ai', 'present', 'exchange', 'ideas', 'subject', 'discuss', 'academia', 'game', 'companies', 'work', 'together', 'improve', 'state', 'art', 'ai', 'games', 'workshop', 'formatthis', 'one', 'day', 'workshop', 'consist', 'paper', 'presentations', 'strategy', 'game', 'related', 'ai', 'topics', 'listed', 'game', 'competition', 'descriptions', 'starcraft', 'broodwar', 'μrts', 'perhaps', 'invited', 'presentation', 'discussion', 'future', 'research', 'competition', 'summaries', 'results', 'presented', 'main', 'aiide', 'conference', 'contributions', 'peer', 'reviewed', 'meet', 'aaai', 'workshop', 'standards', 'accepted', 'workshop', 'papers', 'published', 'single', 'ceur', 'proceedings', 'book']","['n', 'r', 'cfp', 'workshop', 'artifici', 'intellig', 'strategi', 'game', 'aiidehello', 'everyon', 'name', 'derek', 'co', 'chair', 'workshop', 'ai', 'strategi', 'game', 'aiid', 'year', 'want', 'share', 'info', 'workshop', 'may', 'interest', 'discuss', 'futur', 'ai', 'strategi', 'game', 'look', 'publish', 'get', 'feedback', 'work', 'research', 'strategi', 'game', 'feel', 'free', 'messag', 'question', 'workshop', 'websit', 'http', 'submiss', 'deadlin', 'juli', 'topicsthi', 'workshop', 'welcom', 'origin', 'research', 'contribut', 'posit', 'paper', 'competit', 'ai', 'system', 'descript', 'post', 'mortem', 'game', 'analys', 'area', 'ai', 'strategi', 'game', 'includ', 'modern', 'video', 'strategi', 'game', 'fp', 'rt', 'game', 'turn', 'base', 'game', 'puzzl', 'topic', 'includ', 'restrict', 'reinforc', 'learn', 'strategi', 'game', 'state', 'action', 'abstract', 'heurist', 'search', 'appli', 'high', 'branch', 'factor', 'domain', 'player', 'model', 'co', 'oper', 'exploit', 'plan', 'goal', 'recognit', 'game', 'balanc', 'level', 'gener', 'motion', 'plan', 'high', 'level', 'strateg', 'plan', 'deal', 'imperfect', 'inform', 'backgroundfrom', 'success', 'workshop', 'ai', 'adversari', 'real', 'time', 'game', 'held', 'aiid', 'respons', 'consider', 'interest', 'subject', 'limit', 'time', 'report', 'annual', 'starcraft', 'competit', 'main', 'aiid', 'confer', 'sinc', 'broaden', 'workshop', 'scope', 'cover', 'ai', 'kind', 'strategi', 'game', 'hope', 'attract', 'submiss', 'spark', 'discuss', 'research', 'group', 'focus', 'board', 'game', 'real', 'time', 'strategi', 'game', 'gener', 'video', 'game', 'ai', 'goal', 'workshop', 'bring', 'togeth', 'ai', 'research', 'game', 'ai', 'programm', 'industri', 'interest', 'strateg', 'game', 'ai', 'present', 'exchang', 'idea', 'subject', 'discuss', 'academia', 'game', 'compani', 'work', 'togeth', 'improv', 'state', 'art', 'ai', 'game', 'workshop', 'formatthi', 'one', 'day', 'workshop', 'consist', 'paper', 'present', 'strategi', 'game', 'relat', 'ai', 'topic', 'list', 'game', 'competit', 'descript', 'starcraft', 'broodwar', 'μrt', 'perhap', 'invit', 'present', 'discuss', 'futur', 'research', 'competit', 'summari', 'result', 'present', 'main', 'aiid', 'confer', 'contribut', 'peer', 'review', 'meet', 'aaai', 'workshop', 'standard', 'accept', 'workshop', 'paper', 'publish', 'singl', 'ceur', 'proceed', 'book']"
152,166,166,carlml,vnxyfl,[D] On advisors and PhD students,"I think the answer to this question depends on heavily on the area at hand. That is why I am asking here, even though this question has been asked elsewhere a gazillion times.

How much does your advisor help/contribute?  How often do you meet? I am especially interested in people who have published papers. Who proposed the problem, and then found a solution? how much of that solution was joint work vs either of you submitting ideas to the other and being approved or rejected? how satisfied/dissatisfied do you feel with respect to your advisor? have you had multiple advisors? if so, how do they compare?

Let me start by sharing my experience. I always take the initiative when organizing a meeting with my advisor; if I don't say anything, we probably wouldn't meet. I send him biweekly emails with my progress. Usually this entails a write-up explaining my ideas and their development. I think he skims through it, but he definitely does not read it carefully/go through the details. When we have a meeting I generally have to explain the content of the write-up. In terms of the content itself, he tells me whether the ideas/problem seem sound or not, but does not propose improvements. Sometimes, he proposes other ideas that would imply a significant shift of my current work, which honestly I tend to reject because I have already invested a great deal of time to my ideas and I am more emotionally attached to them (I know this latter point isn't good practice).

Overall, I don't know how to feel because I don't really know what's generally expected. If I had to chose, however, I'd say I feel mildly satisfied.

What's your experience?",46,84,2022-06-30 08:37:16, d  on advisors and phd students,i think the answer to this question depends on heavily on the area at hand  that is why i am asking here  even though this question has been asked elsewhere a gazillion times how much does your advisor help contribute   how often do you meet  i am especially interested in people who have published papers  who proposed the problem  and then found a solution  how much of that solution was joint work vs either of you submitting ideas to the other and being approved or rejected  how satisfied dissatisfied do you feel with respect to your advisor  have you had multiple advisors  if so  how do they compare let me start by sharing my experience  i always take the initiative when organizing a meeting with my advisor  if i don t say anything  we probably wouldn t meet  i send him biweekly emails with my progress  usually this entails a write up explaining my ideas and their development  i think he skims through it  but he definitely does not read it carefully go through the details  when we have a meeting i generally have to explain the content of the write up  in terms of the content itself  he tells me whether the ideas problem seem sound or not  but does not propose improvements  sometimes  he proposes other ideas that would imply a significant shift of my current work  which honestly i tend to reject because i have already invested a great deal of time to my ideas and i am more emotionally attached to them  i know this latter point isn t good practice  overall  i don t know how to feel because i don t really know what s generally expected  if i had to chose  however  i d say i feel mildly satisfied what s your experience ,think answer question depends heavily area hand asking even though question asked elsewhere gazillion times much advisor help contribute often meet especially interested people published papers proposed problem found solution much solution joint work vs either submitting ideas approved rejected satisfied dissatisfied feel respect advisor multiple advisors compare let start sharing experience always take initiative organizing meeting advisor say anything probably meet send biweekly emails progress usually entails write explaining ideas development think skims definitely read carefully go details meeting generally explain content write terms content tells whether ideas problem seem sound propose improvements sometimes proposes ideas would imply significant shift current work honestly tend reject already invested great deal time ideas emotionally attached know latter point good practice overall know feel really know generally expected chose however say feel mildly satisfied experience,advisors phd students,advisors phd studentsthink answer question depends heavily area hand asking even though question asked elsewhere gazillion times much advisor help contribute often meet especially interested people published papers proposed problem found solution much solution joint work vs either submitting ideas approved rejected satisfied dissatisfied feel respect advisor multiple advisors compare let start sharing experience always take initiative organizing meeting advisor say anything probably meet send biweekly emails progress usually entails write explaining ideas development think skims definitely read carefully go details meeting generally explain content write terms content tells whether ideas problem seem sound propose improvements sometimes proposes ideas would imply significant shift current work honestly tend reject already invested great deal time ideas emotionally attached know latter point good practice overall know feel really know generally expected chose however say feel mildly satisfied experience,"['advisors', 'phd', 'studentsthink', 'answer', 'question', 'depends', 'heavily', 'area', 'hand', 'asking', 'even', 'though', 'question', 'asked', 'elsewhere', 'gazillion', 'times', 'much', 'advisor', 'help', 'contribute', 'often', 'meet', 'especially', 'interested', 'people', 'published', 'papers', 'proposed', 'problem', 'found', 'solution', 'much', 'solution', 'joint', 'work', 'vs', 'either', 'submitting', 'ideas', 'approved', 'rejected', 'satisfied', 'dissatisfied', 'feel', 'respect', 'advisor', 'multiple', 'advisors', 'compare', 'let', 'start', 'sharing', 'experience', 'always', 'take', 'initiative', 'organizing', 'meeting', 'advisor', 'say', 'anything', 'probably', 'meet', 'send', 'biweekly', 'emails', 'progress', 'usually', 'entails', 'write', 'explaining', 'ideas', 'development', 'think', 'skims', 'definitely', 'read', 'carefully', 'go', 'details', 'meeting', 'generally', 'explain', 'content', 'write', 'terms', 'content', 'tells', 'whether', 'ideas', 'problem', 'seem', 'sound', 'propose', 'improvements', 'sometimes', 'proposes', 'ideas', 'would', 'imply', 'significant', 'shift', 'current', 'work', 'honestly', 'tend', 'reject', 'already', 'invested', 'great', 'deal', 'time', 'ideas', 'emotionally', 'attached', 'know', 'latter', 'point', 'good', 'practice', 'overall', 'know', 'feel', 'really', 'know', 'generally', 'expected', 'chose', 'however', 'say', 'feel', 'mildly', 'satisfied', 'experience']","['advisor', 'phd', 'studentsthink', 'answer', 'question', 'depend', 'heavili', 'area', 'hand', 'ask', 'even', 'though', 'question', 'ask', 'elsewher', 'gazillion', 'time', 'much', 'advisor', 'help', 'contribut', 'often', 'meet', 'especi', 'interest', 'peopl', 'publish', 'paper', 'propos', 'problem', 'found', 'solut', 'much', 'solut', 'joint', 'work', 'vs', 'either', 'submit', 'idea', 'approv', 'reject', 'satisfi', 'dissatisfi', 'feel', 'respect', 'advisor', 'multipl', 'advisor', 'compar', 'let', 'start', 'share', 'experi', 'alway', 'take', 'initi', 'organ', 'meet', 'advisor', 'say', 'anyth', 'probabl', 'meet', 'send', 'biweekli', 'email', 'progress', 'usual', 'entail', 'write', 'explain', 'idea', 'develop', 'think', 'skim', 'definit', 'read', 'care', 'go', 'detail', 'meet', 'gener', 'explain', 'content', 'write', 'term', 'content', 'tell', 'whether', 'idea', 'problem', 'seem', 'sound', 'propos', 'improv', 'sometim', 'propos', 'idea', 'would', 'impli', 'signific', 'shift', 'current', 'work', 'honestli', 'tend', 'reject', 'alreadi', 'invest', 'great', 'deal', 'time', 'idea', 'emot', 'attach', 'know', 'latter', 'point', 'good', 'practic', 'overal', 'know', 'feel', 'realli', 'know', 'gener', 'expect', 'chose', 'howev', 'say', 'feel', 'mildli', 'satisfi', 'experi']"
153,167,167,tylertaewook,voodjs,[P] LCPN-hiernet; Hierarchical classification model using LCPN (Local Classifier per Parent Node) technique.,"Hey, I wanted to share my recent ML project: LCPN-hiernet.

LCPN-hiernet is a hierarchical image classification model for e-commerce items based on EfficientNet-b4 and LCPN (Local Classifier per Parent Node) technique.

LCPN technique is training one multi-class classifier for each parent node, to distinguish between its child nodes. In my example of classifying fashion products, that would mean one classifier on the first level (to determine “bags”, “clothes” or “accessories”), then three more classifiers to determine the specific model.

I’m sure there are a lot of places to improve on, and I would really appreciate anyone’s feedback or suggestions on how I can improve!

* [Github Repo](https://github.com/tylertaewook/LCPN-hiernet)
* [Project Page](https://tylertaewook.com/projects/lcpn-hiernet)",2,1,2022-07-01 06:53:31, p  lcpn hiernet  hierarchical classification model using lcpn  local classifier per parent node  technique ,hey  i wanted to share my recent ml project  lcpn hiernet lcpn hiernet is a hierarchical image classification model for e commerce items based on efficientnet b and lcpn  local classifier per parent node  technique lcpn technique is training one multi class classifier for each parent node  to distinguish between its child nodes  in my example of classifying fashion products  that would mean one classifier on the first level  to determine  bags    clothes  or  accessories    then three more classifiers to determine the specific model i m sure there are a lot of places to improve on  and i would really appreciate anyone s feedback or suggestions on how i can improve    github repo  https    project page  https   tylertaewook com projects lcpn hiernet ,hey wanted share recent ml project lcpn hiernet lcpn hiernet hierarchical image classification model e commerce items based efficientnet b lcpn local classifier per parent node technique lcpn technique training one multi class classifier parent node distinguish child nodes example classifying fashion products would mean one classifier first level determine bags clothes accessories three classifiers determine specific model sure lot places improve would really appreciate anyone feedback suggestions improve github repo https project page https tylertaewook com projects lcpn hiernet,p lcpn hiernet hierarchical classification model using lcpn local classifier per parent node technique,p lcpn hiernet hierarchical classification model using lcpn local classifier per parent node techniquehey wanted share recent ml project lcpn hiernet lcpn hiernet hierarchical image classification model e commerce items based efficientnet b lcpn local classifier per parent node technique lcpn technique training one multi class classifier parent node distinguish child nodes example classifying fashion products would mean one classifier first level determine bags clothes accessories three classifiers determine specific model sure lot places improve would really appreciate anyone feedback suggestions improve github repo https project page https tylertaewook com projects lcpn hiernet,"['p', 'lcpn', 'hiernet', 'hierarchical', 'classification', 'model', 'using', 'lcpn', 'local', 'classifier', 'per', 'parent', 'node', 'techniquehey', 'wanted', 'share', 'recent', 'ml', 'project', 'lcpn', 'hiernet', 'lcpn', 'hiernet', 'hierarchical', 'image', 'classification', 'model', 'e', 'commerce', 'items', 'based', 'efficientnet', 'b', 'lcpn', 'local', 'classifier', 'per', 'parent', 'node', 'technique', 'lcpn', 'technique', 'training', 'one', 'multi', 'class', 'classifier', 'parent', 'node', 'distinguish', 'child', 'nodes', 'example', 'classifying', 'fashion', 'products', 'would', 'mean', 'one', 'classifier', 'first', 'level', 'determine', 'bags', 'clothes', 'accessories', 'three', 'classifiers', 'determine', 'specific', 'model', 'sure', 'lot', 'places', 'improve', 'would', 'really', 'appreciate', 'anyone', 'feedback', 'suggestions', 'improve', 'github', 'repo', 'https', 'project', 'page', 'https', 'tylertaewook', 'com', 'projects', 'lcpn', 'hiernet']","['p', 'lcpn', 'hiernet', 'hierarch', 'classif', 'model', 'use', 'lcpn', 'local', 'classifi', 'per', 'parent', 'node', 'techniquehey', 'want', 'share', 'recent', 'ml', 'project', 'lcpn', 'hiernet', 'lcpn', 'hiernet', 'hierarch', 'imag', 'classif', 'model', 'e', 'commerc', 'item', 'base', 'efficientnet', 'b', 'lcpn', 'local', 'classifi', 'per', 'parent', 'node', 'techniqu', 'lcpn', 'techniqu', 'train', 'one', 'multi', 'class', 'classifi', 'parent', 'node', 'distinguish', 'child', 'node', 'exampl', 'classifi', 'fashion', 'product', 'would', 'mean', 'one', 'classifi', 'first', 'level', 'determin', 'bag', 'cloth', 'accessori', 'three', 'classifi', 'determin', 'specif', 'model', 'sure', 'lot', 'place', 'improv', 'would', 'realli', 'appreci', 'anyon', 'feedback', 'suggest', 'improv', 'github', 'repo', 'http', 'project', 'page', 'http', 'tylertaewook', 'com', 'project', 'lcpn', 'hiernet']"
154,168,168,Mammoth-Ad-5527,vofglg,[R] Introducing causal inference in the energy-efficient building design process,"I am very excited to share our latest research: Causal inference in the scenario of an energy-efficient building design to answer ""what-if"" questions during the design process.

**Abs:**  ""What-if"" questions are intuitively generated and commonly asked during the design process. Engineers and architects need to inherently conduct design decisions, progressing from one phase to another. They either use empirical domain experience, simulations, or data-driven methods to provide consequential feedback. **We take an example from an interdisciplinary domain of energy-efficient building design to argue that the current methods for decision support have four limitations**: 1. Less carefully inspected parametric independence raises the risks of biased results and spurious relationships. 2. The integration gap between data-driven methods and knowledge-based approaches. 3. Less explicit model interpretability for informed decision-making. 4. Ambiguous boundaries for machine assistance during the design process. In this study, we first clarify the nature of dynamic experience in individuals and constant principal knowledge in design. Sequentially, we introduce the causal inference into the energy-efficient design domain by **proposing a four-step process to reveal and analyze the parametric dependencies within the design space by identifying the design causal diagram with interventions**. The causal diagram provides a nexus for integrating domain knowledge with data-driven methods and allows interpretability and testability against the domain experience. The extraction of causal structures from the data is close to the nature design reasoning process. As an illustration, we applied the properties of the proposed estimators through simulations. The paper concludes with a feasibility study that demonstrates the realization of the proposed framework. 

 

https://preview.redd.it/lxme0g2qxs891.png?width=3178&format=png&auto=webp&s=9565f475a472f3bbf6ecf4e5506a39d9c0907f14

For more information, please check:

Paper: [https://arxiv.org/abs/2203.10115](https://arxiv.org/abs/2203.10115)

Github website: [https://github.com/chenxiachan/Causal-inference-in-building-design](https://github.com/chenxiachan/Causal-inference-in-building-design)",0,3,2022-07-01 00:05:58, r  introducing causal inference in the energy efficient building design process,i am very excited to share our latest research  causal inference in the scenario of an energy efficient building design to answer what if questions during the design process   abs     what if questions are intuitively generated and commonly asked during the design process  engineers and architects need to inherently conduct design decisions  progressing from one phase to another  they either use empirical domain experience  simulations  or data driven methods to provide consequential feedback    we take an example from an interdisciplinary domain of energy efficient building design to argue that the current methods for decision support have four limitations      less carefully inspected parametric independence raises the risks of biased results and spurious relationships    the integration gap between data driven methods and knowledge based approaches    less explicit model interpretability for informed decision making    ambiguous boundaries for machine assistance during the design process  in this study  we first clarify the nature of dynamic experience in individuals and constant principal knowledge in design  sequentially  we introduce the causal inference into the energy efficient design domain by   proposing a four step process to reveal and analyze the parametric dependencies within the design space by identifying the design causal diagram with interventions    the causal diagram provides a nexus for integrating domain knowledge with data driven methods and allows interpretability and testability against the domain experience  the extraction of causal structures from the data is close to the nature design reasoning process  as an illustration  we applied the properties of the proposed estimators through simulations  the paper concludes with a feasibility study that demonstrates the realization of the proposed framework   https for more information  please check paper   https github website   https   github com chenxiachan causal inference in building design  https   github com chenxiachan causal inference in building design ,excited share latest research causal inference scenario energy efficient building design answer questions design process abs questions intuitively generated commonly asked design process engineers architects need inherently conduct design decisions progressing one phase another either use empirical domain experience simulations data driven methods provide consequential feedback take example interdisciplinary domain energy efficient building design argue current methods decision support four limitations less carefully inspected parametric independence raises risks biased results spurious relationships integration gap data driven methods knowledge based approaches less explicit model interpretability informed decision making ambiguous boundaries machine assistance design process study first clarify nature dynamic experience individuals constant principal knowledge design sequentially introduce causal inference energy efficient design domain proposing four step process reveal analyze parametric dependencies within design space identifying design causal diagram interventions causal diagram provides nexus integrating domain knowledge data driven methods allows interpretability testability domain experience extraction causal structures data close nature design reasoning process illustration applied properties proposed estimators simulations paper concludes feasibility study demonstrates realization proposed framework https information please check paper https github website https github com chenxiachan causal inference building design https github com chenxiachan causal inference building design,r introducing causal inference energy efficient building design process,r introducing causal inference energy efficient building design processexcited share latest research causal inference scenario energy efficient building design answer questions design process abs questions intuitively generated commonly asked design process engineers architects need inherently conduct design decisions progressing one phase another either use empirical domain experience simulations data driven methods provide consequential feedback take example interdisciplinary domain energy efficient building design argue current methods decision support four limitations less carefully inspected parametric independence raises risks biased results spurious relationships integration gap data driven methods knowledge based approaches less explicit model interpretability informed decision making ambiguous boundaries machine assistance design process study first clarify nature dynamic experience individuals constant principal knowledge design sequentially introduce causal inference energy efficient design domain proposing four step process reveal analyze parametric dependencies within design space identifying design causal diagram interventions causal diagram provides nexus integrating domain knowledge data driven methods allows interpretability testability domain experience extraction causal structures data close nature design reasoning process illustration applied properties proposed estimators simulations paper concludes feasibility study demonstrates realization proposed framework https information please check paper https github website https github com chenxiachan causal inference building design https github com chenxiachan causal inference building design,"['r', 'introducing', 'causal', 'inference', 'energy', 'efficient', 'building', 'design', 'processexcited', 'share', 'latest', 'research', 'causal', 'inference', 'scenario', 'energy', 'efficient', 'building', 'design', 'answer', 'questions', 'design', 'process', 'abs', 'questions', 'intuitively', 'generated', 'commonly', 'asked', 'design', 'process', 'engineers', 'architects', 'need', 'inherently', 'conduct', 'design', 'decisions', 'progressing', 'one', 'phase', 'another', 'either', 'use', 'empirical', 'domain', 'experience', 'simulations', 'data', 'driven', 'methods', 'provide', 'consequential', 'feedback', 'take', 'example', 'interdisciplinary', 'domain', 'energy', 'efficient', 'building', 'design', 'argue', 'current', 'methods', 'decision', 'support', 'four', 'limitations', 'less', 'carefully', 'inspected', 'parametric', 'independence', 'raises', 'risks', 'biased', 'results', 'spurious', 'relationships', 'integration', 'gap', 'data', 'driven', 'methods', 'knowledge', 'based', 'approaches', 'less', 'explicit', 'model', 'interpretability', 'informed', 'decision', 'making', 'ambiguous', 'boundaries', 'machine', 'assistance', 'design', 'process', 'study', 'first', 'clarify', 'nature', 'dynamic', 'experience', 'individuals', 'constant', 'principal', 'knowledge', 'design', 'sequentially', 'introduce', 'causal', 'inference', 'energy', 'efficient', 'design', 'domain', 'proposing', 'four', 'step', 'process', 'reveal', 'analyze', 'parametric', 'dependencies', 'within', 'design', 'space', 'identifying', 'design', 'causal', 'diagram', 'interventions', 'causal', 'diagram', 'provides', 'nexus', 'integrating', 'domain', 'knowledge', 'data', 'driven', 'methods', 'allows', 'interpretability', 'testability', 'domain', 'experience', 'extraction', 'causal', 'structures', 'data', 'close', 'nature', 'design', 'reasoning', 'process', 'illustration', 'applied', 'properties', 'proposed', 'estimators', 'simulations', 'paper', 'concludes', 'feasibility', 'study', 'demonstrates', 'realization', 'proposed', 'framework', 'https', 'information', 'please', 'check', 'paper', 'https', 'github', 'website', 'https', 'github', 'com', 'chenxiachan', 'causal', 'inference', 'building', 'design', 'https', 'github', 'com', 'chenxiachan', 'causal', 'inference', 'building', 'design']","['r', 'introduc', 'causal', 'infer', 'energi', 'effici', 'build', 'design', 'processexcit', 'share', 'latest', 'research', 'causal', 'infer', 'scenario', 'energi', 'effici', 'build', 'design', 'answer', 'question', 'design', 'process', 'ab', 'question', 'intuit', 'gener', 'commonli', 'ask', 'design', 'process', 'engin', 'architect', 'need', 'inher', 'conduct', 'design', 'decis', 'progress', 'one', 'phase', 'anoth', 'either', 'use', 'empir', 'domain', 'experi', 'simul', 'data', 'driven', 'method', 'provid', 'consequenti', 'feedback', 'take', 'exampl', 'interdisciplinari', 'domain', 'energi', 'effici', 'build', 'design', 'argu', 'current', 'method', 'decis', 'support', 'four', 'limit', 'less', 'care', 'inspect', 'parametr', 'independ', 'rais', 'risk', 'bias', 'result', 'spuriou', 'relationship', 'integr', 'gap', 'data', 'driven', 'method', 'knowledg', 'base', 'approach', 'less', 'explicit', 'model', 'interpret', 'inform', 'decis', 'make', 'ambigu', 'boundari', 'machin', 'assist', 'design', 'process', 'studi', 'first', 'clarifi', 'natur', 'dynam', 'experi', 'individu', 'constant', 'princip', 'knowledg', 'design', 'sequenti', 'introduc', 'causal', 'infer', 'energi', 'effici', 'design', 'domain', 'propos', 'four', 'step', 'process', 'reveal', 'analyz', 'parametr', 'depend', 'within', 'design', 'space', 'identifi', 'design', 'causal', 'diagram', 'intervent', 'causal', 'diagram', 'provid', 'nexu', 'integr', 'domain', 'knowledg', 'data', 'driven', 'method', 'allow', 'interpret', 'testabl', 'domain', 'experi', 'extract', 'causal', 'structur', 'data', 'close', 'natur', 'design', 'reason', 'process', 'illustr', 'appli', 'properti', 'propos', 'estim', 'simul', 'paper', 'conclud', 'feasibl', 'studi', 'demonstr', 'realiz', 'propos', 'framework', 'http', 'inform', 'pleas', 'check', 'paper', 'http', 'github', 'websit', 'http', 'github', 'com', 'chenxiachan', 'causal', 'infer', 'build', 'design', 'http', 'github', 'com', 'chenxiachan', 'causal', 'infer', 'build', 'design']"
155,169,169,AnnualLimp1418,voc94n,[P] Upgini 1.0 is released (a Python library for data search through autoML ),"**Upgini** is a simple feature search & enrichment library in Python. With Upgini, you spend less time for external data search and feature engineering, which will be done for you automatically. Just use your labeled dataset to initiate search through thousands of features and data sources, including public datasets and scraped data shared by Data science community. Only the relevant features that improve prediction power of your ML model are returned.

**Motivation:** for most supervised ML models external data & features boost accuracy significantly better than any hyperparameters tuning. But lack of automated and time-efficient search tools for external data blocks massive adoption of external features in ML pipelines.We want radically simplify features search and delivery for ML pipelines to make external data a standard approach. Like a hyperparameter tuning for machine learning nowadays.

**Mission:** Democratize access to data sources for data science community.

## 📊 Data coverage and statistics

Total: **239 countries** and **up to 41 years** of history

https://preview.redd.it/oj87fnkw9s891.png?width=1220&format=png&auto=webp&s=4195a607addca12d400bc4b0b62307ac4db87b67

**More info about the library**

To install Upgini from PyPI run pip install -U upgini

Full release notes: [https://github.com/upgini/upgini](https://github.com/upgini/upgini)

Try the online demo at [Colab](https://colab.research.google.com/github/upgini/upgini/blob/main/notebooks/kaggle_example.ipynb).",2,4,2022-06-30 21:46:59, p  upgini   is released  a python library for data search through automl  ,  upgini   is a simple feature search   enrichment library in python  with upgini  you spend less time for external data search and feature engineering  which will be done for you automatically  just use your labeled dataset to initiate search through thousands of features and data sources  including public datasets and scraped data shared by data science community  only the relevant features that improve prediction power of your ml model are returned   motivation    for most supervised ml models external data   features boost accuracy significantly better than any hyperparameters tuning  but lack of automated and time efficient search tools for external data blocks massive adoption of external features in ml pipelines we want radically simplify features search and delivery for ml pipelines to make external data a standard approach  like a hyperparameter tuning for machine learning nowadays   mission    democratize access to data sources for data science community      data coverage and statisticstotal     countries   and   up to  years   of historyhttps   more info about the library  to install upgini from pypi run pip install  u upginifull release notes   https try the online demo at  colab  https   colab research google com github upgini upgini blob main notebooks kaggle_example ipynb  ,upgini simple feature search enrichment library python upgini spend less time external data search feature engineering done automatically use labeled dataset initiate search thousands features data sources including public datasets scraped data shared data science community relevant features improve prediction power ml model returned motivation supervised ml models external data features boost accuracy significantly better hyperparameters tuning lack automated time efficient search tools external data blocks massive adoption external features ml pipelines want radically simplify features search delivery ml pipelines make external data standard approach like hyperparameter tuning machine learning nowadays mission democratize access data sources data science community data coverage statisticstotal countries years historyhttps info library install upgini pypi run pip install u upginifull release notes https try online demo colab https colab research google com github upgini upgini blob main notebooks kaggle_example ipynb,p upgini released python library data search automl,p upgini released python library data search automlupgini simple feature search enrichment library python upgini spend less time external data search feature engineering done automatically use labeled dataset initiate search thousands features data sources including public datasets scraped data shared data science community relevant features improve prediction power ml model returned motivation supervised ml models external data features boost accuracy significantly better hyperparameters tuning lack automated time efficient search tools external data blocks massive adoption external features ml pipelines want radically simplify features search delivery ml pipelines make external data standard approach like hyperparameter tuning machine learning nowadays mission democratize access data sources data science community data coverage statisticstotal countries years historyhttps info library install upgini pypi run pip install u upginifull release notes https try online demo colab https colab research google com github upgini upgini blob main notebooks kaggle_example ipynb,"['p', 'upgini', 'released', 'python', 'library', 'data', 'search', 'automlupgini', 'simple', 'feature', 'search', 'enrichment', 'library', 'python', 'upgini', 'spend', 'less', 'time', 'external', 'data', 'search', 'feature', 'engineering', 'done', 'automatically', 'use', 'labeled', 'dataset', 'initiate', 'search', 'thousands', 'features', 'data', 'sources', 'including', 'public', 'datasets', 'scraped', 'data', 'shared', 'data', 'science', 'community', 'relevant', 'features', 'improve', 'prediction', 'power', 'ml', 'model', 'returned', 'motivation', 'supervised', 'ml', 'models', 'external', 'data', 'features', 'boost', 'accuracy', 'significantly', 'better', 'hyperparameters', 'tuning', 'lack', 'automated', 'time', 'efficient', 'search', 'tools', 'external', 'data', 'blocks', 'massive', 'adoption', 'external', 'features', 'ml', 'pipelines', 'want', 'radically', 'simplify', 'features', 'search', 'delivery', 'ml', 'pipelines', 'make', 'external', 'data', 'standard', 'approach', 'like', 'hyperparameter', 'tuning', 'machine', 'learning', 'nowadays', 'mission', 'democratize', 'access', 'data', 'sources', 'data', 'science', 'community', 'data', 'coverage', 'statisticstotal', 'countries', 'years', 'historyhttps', 'info', 'library', 'install', 'upgini', 'pypi', 'run', 'pip', 'install', 'u', 'upginifull', 'release', 'notes', 'https', 'try', 'online', 'demo', 'colab', 'https', 'colab', 'research', 'google', 'com', 'github', 'upgini', 'upgini', 'blob', 'main', 'notebooks', 'kaggle_example', 'ipynb']","['p', 'upgini', 'releas', 'python', 'librari', 'data', 'search', 'automlupgini', 'simpl', 'featur', 'search', 'enrich', 'librari', 'python', 'upgini', 'spend', 'less', 'time', 'extern', 'data', 'search', 'featur', 'engin', 'done', 'automat', 'use', 'label', 'dataset', 'initi', 'search', 'thousand', 'featur', 'data', 'sourc', 'includ', 'public', 'dataset', 'scrape', 'data', 'share', 'data', 'scienc', 'commun', 'relev', 'featur', 'improv', 'predict', 'power', 'ml', 'model', 'return', 'motiv', 'supervis', 'ml', 'model', 'extern', 'data', 'featur', 'boost', 'accuraci', 'significantli', 'better', 'hyperparamet', 'tune', 'lack', 'autom', 'time', 'effici', 'search', 'tool', 'extern', 'data', 'block', 'massiv', 'adopt', 'extern', 'featur', 'ml', 'pipelin', 'want', 'radic', 'simplifi', 'featur', 'search', 'deliveri', 'ml', 'pipelin', 'make', 'extern', 'data', 'standard', 'approach', 'like', 'hyperparamet', 'tune', 'machin', 'learn', 'nowaday', 'mission', 'democrat', 'access', 'data', 'sourc', 'data', 'scienc', 'commun', 'data', 'coverag', 'statisticstot', 'countri', 'year', 'historyhttp', 'info', 'librari', 'instal', 'upgini', 'pypi', 'run', 'pip', 'instal', 'u', 'upginiful', 'releas', 'note', 'http', 'tri', 'onlin', 'demo', 'colab', 'http', 'colab', 'research', 'googl', 'com', 'github', 'upgini', 'upgini', 'blob', 'main', 'notebook', 'kaggle_exampl', 'ipynb']"
156,170,170,glorsh66,vodutm,[P]how to improve performance of face recognition using dlib?,"I am using dlib.get_frontal_face_detector()
And fir large images (several mb) it takes a lot of time to detect a face.

What are the ways to increase speed of face detection, without sacrificing accuracy?

I cannot use gpu/cuda sadly...",5,3,2022-06-30 22:56:48, p how to improve performance of face recognition using dlib ,i am using dlib get_frontal_face_detector  and fir large images  several mb  it takes a lot of time to detect a face what are the ways to increase speed of face detection  without sacrificing accuracy i cannot use gpu cuda sadly   ,using dlib get_frontal_face_detector fir large images several mb takes lot time detect face ways increase speed face detection without sacrificing accuracy cannot use gpu cuda sadly,p improve performance face recognition using dlib,p improve performance face recognition using dlibusing dlib get_frontal_face_detector fir large images several mb takes lot time detect face ways increase speed face detection without sacrificing accuracy cannot use gpu cuda sadly,"['p', 'improve', 'performance', 'face', 'recognition', 'using', 'dlibusing', 'dlib', 'get_frontal_face_detector', 'fir', 'large', 'images', 'several', 'mb', 'takes', 'lot', 'time', 'detect', 'face', 'ways', 'increase', 'speed', 'face', 'detection', 'without', 'sacrificing', 'accuracy', 'can', 'not', 'use', 'gpu', 'cuda', 'sadly']","['p', 'improv', 'perform', 'face', 'recognit', 'use', 'dlibus', 'dlib', 'get_frontal_face_detector', 'fir', 'larg', 'imag', 'sever', 'mb', 'take', 'lot', 'time', 'detect', 'face', 'way', 'increas', 'speed', 'face', 'detect', 'without', 'sacrif', 'accuraci', 'can', 'not', 'use', 'gpu', 'cuda', 'sadli']"
157,171,171,alder-ice,vo12l2,"[N] Introducing Anomalib: A library for benchmarking, developing and deploying deep learning anomaly detection algorithms by Intel","Anomalib is Machine Library developed by AI researchers from Intel which implements state of the art algorithms for anomaly detection. Anomaly detection is popular use case in the industrial sector and such algorithms can help provide real-time feedback to manufactures on how well their production lines are performing. 

Anomaly Detection is a challenging problem often due to a biased dataset. Anomalous images can be scare therefore these algorithms are trained on good images in an unsupervised fashion. By learning the normality, upon inference, the models can detect whether images are anomalous or not.

Anomalib was built using a PyTorchLightning Backbone and offers an easy way to deploy the models with OpenVino for inference speedup. 

Link to the github repo: [https://github.com/openvinotoolkit/anomalib](https://github.com/openvinotoolkit/anomalib)

Link to a tutorial on how to train your custom dataset with anomalib: [https://github.com/openvinotoolkit/anomalib/tree/development/docs/blog/001-train-custom-dataset](https://github.com/openvinotoolkit/anomalib/tree/development/docs/blog/001-train-custom-dataset)

Please feel free to check out the repo and give us your feedback",3,12,2022-06-30 11:30:29, n  introducing anomalib  a library for benchmarking  developing and deploying deep learning anomaly detection algorithms by intel,anomalib is machine library developed by ai researchers from intel which implements state of the art algorithms for anomaly detection  anomaly detection is popular use case in the industrial sector and such algorithms can help provide real time feedback to manufactures on how well their production lines are performing  anomaly detection is a challenging problem often due to a biased dataset  anomalous images can be scare therefore these algorithms are trained on good images in an unsupervised fashion  by learning the normality  upon inference  the models can detect whether images are anomalous or not anomalib was built using a pytorchlightning backbone and offers an easy way to deploy the models with openvino for inference speedup  link to the github repo   https link to a tutorial on how to train your custom dataset with anomalib   https please feel free to check out the repo and give us your feedback,anomalib machine library developed ai researchers intel implements state art algorithms anomaly detection anomaly detection popular use case industrial sector algorithms help provide real time feedback manufactures well production lines performing anomaly detection challenging problem often due biased dataset anomalous images scare therefore algorithms trained good images unsupervised fashion learning normality upon inference models detect whether images anomalous anomalib built using pytorchlightning backbone offers easy way deploy models openvino inference speedup link github repo https link tutorial train dataset anomalib https please feel free check repo give us feedback,n introducing anomalib library benchmarking developing deploying deep learning anomaly detection algorithms intel,n introducing anomalib library benchmarking developing deploying deep learning anomaly detection algorithms intelanomalib machine library developed ai researchers intel implements state art algorithms anomaly detection anomaly detection popular use case industrial sector algorithms help provide real time feedback manufactures well production lines performing anomaly detection challenging problem often due biased dataset anomalous images scare therefore algorithms trained good images unsupervised fashion learning normality upon inference models detect whether images anomalous anomalib built using pytorchlightning backbone offers easy way deploy models openvino inference speedup link github repo https link tutorial train dataset anomalib https please feel free check repo give us feedback,"['n', 'introducing', 'anomalib', 'library', 'benchmarking', 'developing', 'deploying', 'deep', 'learning', 'anomaly', 'detection', 'algorithms', 'intelanomalib', 'machine', 'library', 'developed', 'ai', 'researchers', 'intel', 'implements', 'state', 'art', 'algorithms', 'anomaly', 'detection', 'anomaly', 'detection', 'popular', 'use', 'case', 'industrial', 'sector', 'algorithms', 'help', 'provide', 'real', 'time', 'feedback', 'manufactures', 'well', 'production', 'lines', 'performing', 'anomaly', 'detection', 'challenging', 'problem', 'often', 'due', 'biased', 'dataset', 'anomalous', 'images', 'scare', 'therefore', 'algorithms', 'trained', 'good', 'images', 'unsupervised', 'fashion', 'learning', 'normality', 'upon', 'inference', 'models', 'detect', 'whether', 'images', 'anomalous', 'anomalib', 'built', 'using', 'pytorchlightning', 'backbone', 'offers', 'easy', 'way', 'deploy', 'models', 'openvino', 'inference', 'speedup', 'link', 'github', 'repo', 'https', 'link', 'tutorial', 'train', 'dataset', 'anomalib', 'https', 'please', 'feel', 'free', 'check', 'repo', 'give', 'us', 'feedback']","['n', 'introduc', 'anomalib', 'librari', 'benchmark', 'develop', 'deploy', 'deep', 'learn', 'anomali', 'detect', 'algorithm', 'intelanomalib', 'machin', 'librari', 'develop', 'ai', 'research', 'intel', 'implement', 'state', 'art', 'algorithm', 'anomali', 'detect', 'anomali', 'detect', 'popular', 'use', 'case', 'industri', 'sector', 'algorithm', 'help', 'provid', 'real', 'time', 'feedback', 'manufactur', 'well', 'product', 'line', 'perform', 'anomali', 'detect', 'challeng', 'problem', 'often', 'due', 'bias', 'dataset', 'anomal', 'imag', 'scare', 'therefor', 'algorithm', 'train', 'good', 'imag', 'unsupervis', 'fashion', 'learn', 'normal', 'upon', 'infer', 'model', 'detect', 'whether', 'imag', 'anomal', 'anomalib', 'built', 'use', 'pytorchlightn', 'backbon', 'offer', 'easi', 'way', 'deploy', 'model', 'openvino', 'infer', 'speedup', 'link', 'github', 'repo', 'http', 'link', 'tutori', 'train', 'dataset', 'anomalib', 'http', 'pleas', 'feel', 'free', 'check', 'repo', 'give', 'us', 'feedback']"
158,172,172,gabegabe6,vnggck,[P] Neural Network Steganography (implementation) - Hiding secrets and malicious software in any neural network,"I saw a paper called *EvilModel* on how to hide malicious code in a neural network as we have thousands or millions of parameters that we can alter.

This basic technique is based on the modification of the `float32` values (but can be adapted to `float16`) where we modify the fraction bits or part of the fraction. 

- [Post/Tutorial on the process](https://www.gaborvecsei.com/Neural-Network-Steganography/)
- [GitHub repo for the project](https://github.com/gaborvecsei/Neural-Network-Steganography)
- [EvilModel paper](https://arxiv.org/abs/2107.08590)

As I saw with my experiments, we could easily hide megabytes of code in a simple *ResNet50* and get away with it. A well-trained (and generalized) network should not degrade in performance significantly. The testing of that is planned for a future post.

Also, this method could be used for watermarking neural network weights which could help with copyright claims (e.g.: someone is using your open-sourced (and appropriately licensed) weights out of the box in a commercial product)",35,265,2022-06-29 19:27:57, p  neural network steganography  implementation    hiding secrets and malicious software in any neural network,i saw a paper called  evilmodel  on how to hide malicious code in a neural network as we have thousands or millions of parameters that we can alter this basic technique is based on the modification of the  float  values  but can be adapted to  float   where we modify the fraction bits or part of the fraction     post tutorial on the process  https    github repo for the project  https    evilmodel paper  https as i saw with my experiments  we could easily hide megabytes of code in a simple  resnet  and get away with it  a well trained  and generalized  network should not degrade in performance significantly  the testing of that is planned for a future post also  this method could be used for watermarking neural network weights which could help with copyright claims  e g   someone is using your open sourced  and appropriately licensed  weights out of the box in a commercial product ,saw paper called evilmodel hide malicious code neural network thousands millions parameters alter basic technique based modification float values adapted float modify fraction bits part fraction post tutorial process https github repo project https evilmodel paper https saw experiments could easily hide megabytes code simple resnet get away well trained generalized network degrade performance significantly testing planned future post also method could used watermarking neural network weights could help copyright claims e g someone using open sourced appropriately licensed weights box commercial product,p neural network steganography implementation hiding secrets malicious software neural network,p neural network steganography implementation hiding secrets malicious software neural networksaw paper called evilmodel hide malicious code neural network thousands millions parameters alter basic technique based modification float values adapted float modify fraction bits part fraction post tutorial process https github repo project https evilmodel paper https saw experiments could easily hide megabytes code simple resnet get away well trained generalized network degrade performance significantly testing planned future post also method could used watermarking neural network weights could help copyright claims e g someone using open sourced appropriately licensed weights box commercial product,"['p', 'neural', 'network', 'steganography', 'implementation', 'hiding', 'secrets', 'malicious', 'software', 'neural', 'networksaw', 'paper', 'called', 'evilmodel', 'hide', 'malicious', 'code', 'neural', 'network', 'thousands', 'millions', 'parameters', 'alter', 'basic', 'technique', 'based', 'modification', 'float', 'values', 'adapted', 'float', 'modify', 'fraction', 'bits', 'part', 'fraction', 'post', 'tutorial', 'process', 'https', 'github', 'repo', 'project', 'https', 'evilmodel', 'paper', 'https', 'saw', 'experiments', 'could', 'easily', 'hide', 'megabytes', 'code', 'simple', 'resnet', 'get', 'away', 'well', 'trained', 'generalized', 'network', 'degrade', 'performance', 'significantly', 'testing', 'planned', 'future', 'post', 'also', 'method', 'could', 'used', 'watermarking', 'neural', 'network', 'weights', 'could', 'help', 'copyright', 'claims', 'e', 'g', 'someone', 'using', 'open', 'sourced', 'appropriately', 'licensed', 'weights', 'box', 'commercial', 'product']","['p', 'neural', 'network', 'steganographi', 'implement', 'hide', 'secret', 'malici', 'softwar', 'neural', 'networksaw', 'paper', 'call', 'evilmodel', 'hide', 'malici', 'code', 'neural', 'network', 'thousand', 'million', 'paramet', 'alter', 'basic', 'techniqu', 'base', 'modif', 'float', 'valu', 'adapt', 'float', 'modifi', 'fraction', 'bit', 'part', 'fraction', 'post', 'tutori', 'process', 'http', 'github', 'repo', 'project', 'http', 'evilmodel', 'paper', 'http', 'saw', 'experi', 'could', 'easili', 'hide', 'megabyt', 'code', 'simpl', 'resnet', 'get', 'away', 'well', 'train', 'gener', 'network', 'degrad', 'perform', 'significantli', 'test', 'plan', 'futur', 'post', 'also', 'method', 'could', 'use', 'watermark', 'neural', 'network', 'weight', 'could', 'help', 'copyright', 'claim', 'e', 'g', 'someon', 'use', 'open', 'sourc', 'appropri', 'licens', 'weight', 'box', 'commerci', 'product']"
159,173,173,iblysa,vom1d2,[D][P] Ideas about how to model from a dataset with columns containing arrays of data?,"Hello. I have built a dataset that contains results of experiments I have been doing over some physical materials. Each row contains summary data for each piece, like width, height, weight, etc. Then I have several columns which values are arrays.

Each one of these columns contain a list of tuples, for example (162636363, 1373.8377). The first number is a timestamp, the second one the magnitude of a force applied to the material (or, for instance, the position where the force was applied, contact duration, etc.). We have hundreds or even thousands of tuples on each column. So, all columns represent measurements of the experiments done to a particular material.

We are recording when the material is damaged, since we want to predict its lifetime when the material is exposed to repetitive forces.

I'm wondering what to do with those array values. One option is to sort the tuples lists by timestamp and then treat the readings as a vector of a predefined dimension. But I have never fed this kind of data to a boosted tree model/framework like XGBoost.

The only experience I had feeding long vectors to a model was when doing some NLP, in that case the vectors were representations of words.

Do you think a vector made of all my experiments over a material can be treated as an embedding in a way? If so, how is the recommended way to proceed with this data in the modeling stage? Time series perhaps?

I'd appreciate your ideas and comments.

Thanks!!",0,0,2022-07-01 04:56:26, d  p  ideas about how to model from a dataset with columns containing arrays of data ,hello  i have built a dataset that contains results of experiments i have been doing over some physical materials  each row contains summary data for each piece  like width  height  weight  etc  then i have several columns which values are arrays each one of these columns contain a list of tuples  for example        the first number is a timestamp  the second one the magnitude of a force applied to the material  or  for instance  the position where the force was applied  contact duration  etc    we have hundreds or even thousands of tuples on each column  so  all columns represent measurements of the experiments done to a particular material we are recording when the material is damaged  since we want to predict its lifetime when the material is exposed to repetitive forces i m wondering what to do with those array values  one option is to sort the tuples lists by timestamp and then treat the readings as a vector of a predefined dimension  but i have never fed this kind of data to a boosted tree model framework like xgboost the only experience i had feeding long vectors to a model was when doing some nlp  in that case the vectors were representations of words do you think a vector made of all my experiments over a material can be treated as an embedding in a way  if so  how is the recommended way to proceed with this data in the modeling stage  time series perhaps i d appreciate your ideas and comments thanks  ,hello built dataset contains results experiments physical materials row contains summary data piece like width height weight etc several columns values arrays one columns contain tuples example first number timestamp second one magnitude force applied material instance position force applied contact duration etc hundreds even thousands tuples column columns represent measurements experiments done particular material recording material damaged since want predict lifetime material exposed repetitive forces wondering array values one option sort tuples lists timestamp treat readings vector predefined dimension never fed kind data boosted tree model framework like xgboost experience feeding long vectors model nlp case vectors representations think vector made experiments material treated embedding way recommended way proceed data modeling stage time series perhaps appreciate ideas comments thanks,p ideas model dataset columns containing arrays data,p ideas model dataset columns containing arrays datahello built dataset contains results experiments physical materials row contains summary data piece like width height weight etc several columns values arrays one columns contain tuples example first number timestamp second one magnitude force applied material instance position force applied contact duration etc hundreds even thousands tuples column columns represent measurements experiments done particular material recording material damaged since want predict lifetime material exposed repetitive forces wondering array values one option sort tuples lists timestamp treat readings vector predefined dimension never fed kind data boosted tree model framework like xgboost experience feeding long vectors model nlp case vectors representations think vector made experiments material treated embedding way recommended way proceed data modeling stage time series perhaps appreciate ideas comments thanks,"['p', 'ideas', 'model', 'dataset', 'columns', 'containing', 'arrays', 'datahello', 'built', 'dataset', 'contains', 'results', 'experiments', 'physical', 'materials', 'row', 'contains', 'summary', 'data', 'piece', 'like', 'width', 'height', 'weight', 'etc', 'several', 'columns', 'values', 'arrays', 'one', 'columns', 'contain', 'tuples', 'example', 'first', 'number', 'timestamp', 'second', 'one', 'magnitude', 'force', 'applied', 'material', 'instance', 'position', 'force', 'applied', 'contact', 'duration', 'etc', 'hundreds', 'even', 'thousands', 'tuples', 'column', 'columns', 'represent', 'measurements', 'experiments', 'done', 'particular', 'material', 'recording', 'material', 'damaged', 'since', 'want', 'predict', 'lifetime', 'material', 'exposed', 'repetitive', 'forces', 'wondering', 'array', 'values', 'one', 'option', 'sort', 'tuples', 'lists', 'timestamp', 'treat', 'readings', 'vector', 'predefined', 'dimension', 'never', 'fed', 'kind', 'data', 'boosted', 'tree', 'model', 'framework', 'like', 'xgboost', 'experience', 'feeding', 'long', 'vectors', 'model', 'nlp', 'case', 'vectors', 'representations', 'think', 'vector', 'made', 'experiments', 'material', 'treated', 'embedding', 'way', 'recommended', 'way', 'proceed', 'data', 'modeling', 'stage', 'time', 'series', 'perhaps', 'appreciate', 'ideas', 'comments', 'thanks']","['p', 'idea', 'model', 'dataset', 'column', 'contain', 'array', 'datahello', 'built', 'dataset', 'contain', 'result', 'experi', 'physic', 'materi', 'row', 'contain', 'summari', 'data', 'piec', 'like', 'width', 'height', 'weight', 'etc', 'sever', 'column', 'valu', 'array', 'one', 'column', 'contain', 'tupl', 'exampl', 'first', 'number', 'timestamp', 'second', 'one', 'magnitud', 'forc', 'appli', 'materi', 'instanc', 'posit', 'forc', 'appli', 'contact', 'durat', 'etc', 'hundr', 'even', 'thousand', 'tupl', 'column', 'column', 'repres', 'measur', 'experi', 'done', 'particular', 'materi', 'record', 'materi', 'damag', 'sinc', 'want', 'predict', 'lifetim', 'materi', 'expos', 'repetit', 'forc', 'wonder', 'array', 'valu', 'one', 'option', 'sort', 'tupl', 'list', 'timestamp', 'treat', 'read', 'vector', 'predefin', 'dimens', 'never', 'fed', 'kind', 'data', 'boost', 'tree', 'model', 'framework', 'like', 'xgboost', 'experi', 'feed', 'long', 'vector', 'model', 'nlp', 'case', 'vector', 'represent', 'think', 'vector', 'made', 'experi', 'materi', 'treat', 'embed', 'way', 'recommend', 'way', 'proceed', 'data', 'model', 'stage', 'time', 'seri', 'perhap', 'appreci', 'idea', 'comment', 'thank']"
160,174,174,certain_entropy,voahxz,"[D] What is considered a ""large"" model?","Curious about the usage of the word ""large"" in the research community and in papers as a descriptor. About 3 years ago, Bert-Large was considered large at 345 million parameters. Today we have a 11-B parameter T-5 model and larger. When describing models in papers, is there consensus as to what we consider a ""large"" model or set of categories to describe models based on their size?",3,2,2022-06-30 20:32:12, d  what is considered a large model ,curious about the usage of the word large in the research community and in papers as a descriptor  about  years ago  bert large was considered large at  million parameters  today we have a  b parameter t  model and larger  when describing models in papers  is there consensus as to what we consider a large model or set of categories to describe models based on their size ,curious usage word large research community papers descriptor years ago bert large considered large million parameters today b parameter model larger describing models papers consensus consider large model set categories describe models based size,considered large model,considered large modelcurious usage word large research community papers descriptor years ago bert large considered large million parameters today b parameter model larger describing models papers consensus consider large model set categories describe models based size,"['considered', 'large', 'modelcurious', 'usage', 'word', 'large', 'research', 'community', 'papers', 'descriptor', 'years', 'ago', 'bert', 'large', 'considered', 'large', 'million', 'parameters', 'today', 'b', 'parameter', 'model', 'larger', 'describing', 'models', 'papers', 'consensus', 'consider', 'large', 'model', 'set', 'categories', 'describe', 'models', 'based', 'size']","['consid', 'larg', 'modelcuri', 'usag', 'word', 'larg', 'research', 'commun', 'paper', 'descriptor', 'year', 'ago', 'bert', 'larg', 'consid', 'larg', 'million', 'paramet', 'today', 'b', 'paramet', 'model', 'larger', 'describ', 'model', 'paper', 'consensu', 'consid', 'larg', 'model', 'set', 'categori', 'describ', 'model', 'base', 'size']"
161,175,175,statmlben,vo2bvp,[R] RankSEG: A Consistent Ranking-based Framework for Segmentation,"I am very excited to share our latest research: a new framework [RankSEG](https://arxiv.org/abs/2206.13086) on (image) segmentation.

**Abs**: In this paper, we establish a theoretical foundation of segmentation with respect to the Dice/IoU metrics, including the Bayes rule and Dice/IoU-calibration, analogous to classification-calibration or Fisher consistency in classification. We prove that the **existing thresholding-based framework** with most operating losses are **NOT consistent** with respect to the Dice/IoU metrics, and thus may lead to a suboptimal solution. To address this pitfall, we propose a novel consistent ranking-based framework, namely *RankDice*/*RankIoU*, inspired by plug-in rules of the Bayes segmentation rule. Three numerical algorithms with GPU parallel execution are developed to implement the proposed framework in large-scale and high-dimensional segmentation.  We study statistical properties of the proposed framework. We show it is Dice-/IoU-calibrated, and its excess risk bounds and the rate of convergence are also provided. The numerical effectiveness of *RankDice/mRankDice* is demonstrated in various simulated examples and *Fine-annotated CityScapes* and *Pascal VOC* datasets with state-of-the-art deep learning architectures.

**Conclusion**: the proposed framework **RankSEG** consistently outperforms the existing **thresholding-based framework** (simply thresholding the estimated probabilities at 0.5).

**Contribution**: We summarize our major contribution as follows:

* To our best knowledge, the proposed ranking-based segmentation framework *RankDice*, is the first consistent segmentation framework with respect to the Dice metric (Dice-calibrated).
* Three numerical algorithms with GPU parallel execution are developed to implement the proposed framework in large-scale and high-dimensional segmentation.
* We establish a theoretical foundation of segmentation with respect to the Dice metric, such as the Bayes rule and Dice-calibration. Moreover, we present Dice-calibrated consistency and a convergence rate of the excess risk for the proposed *RankDice* framework, and indicate inconsistent results for the existing methods.
* Our experiments in two simulated examples and two real datasets (CityScapes dataset and Pascal VOC 2021 dataset) suggest that {the improvement of *RankDice* over the existing framework is practically significant for various loss functions and network architectures. The percentage of improvement on the best performance (for each framework) are 3.13% (over *threshold*) and 4.96% (over *argmax*) for CityScapes dataset (PSPNet + CE), and 3.87% (over *threshold*) and 2.91% (over *argmax*) for Pascal VOC 2021 dataset (PSPNet + CE/BCE).

For more information, please check:

Paper: [https://arxiv.org/abs/2206.13086](https://arxiv.org/abs/2206.13086)

Github website: [https://github.com/statmlben/rankseg](https://github.com/statmlben/rankseg)",1,8,2022-06-30 12:50:19, r  rankseg  a consistent ranking based framework for segmentation,i am very excited to share our latest research  a new framework  rankseg  https   abs    in this paper  we establish a theoretical foundation of segmentation with respect to the dice iou metrics  including the bayes rule and dice iou calibration  analogous to classification calibration or fisher consistency in classification  we prove that the   existing thresholding based framework   with most operating losses are   not consistent   with respect to the dice iou metrics  and thus may lead to a suboptimal solution  to address this pitfall  we propose a novel consistent ranking based framework  namely  rankdice   rankiou   inspired by plug in rules of the bayes segmentation rule  three numerical algorithms with gpu parallel execution are developed to implement the proposed framework in large scale and high dimensional segmentation   we study statistical properties of the proposed framework  we show it is dice  iou calibrated  and its excess risk bounds and the rate of convergence are also provided  the numerical effectiveness of  rankdice mrankdice  is demonstrated in various simulated examples and  fine annotated cityscapes  and  pascal voc  datasets with state of the art deep learning architectures   conclusion    the proposed framework   rankseg   consistently outperforms the existing   thresholding based framework    simply thresholding the estimated probabilities at      contribution    we summarize our major contribution as follows   to our best knowledge  the proposed ranking based segmentation framework  rankdice   is the first consistent segmentation framework with respect to the dice metric  dice calibrated    three numerical algorithms with gpu parallel execution are developed to implement the proposed framework in large scale and high dimensional segmentation   we establish a theoretical foundation of segmentation with respect to the dice metric  such as the bayes rule and dice calibration  moreover  we present dice calibrated consistency and a convergence rate of the excess risk for the proposed  rankdice  framework  and indicate inconsistent results for the existing methods   our experiments in two simulated examples and two real datasets  cityscapes dataset and pascal voc  dataset  suggest that  the improvement of  rankdice  over the existing framework is practically significant for various loss functions and network architectures  the percentage of improvement on the best performance  for each framework  are     over  threshold   and     over  argmax   for cityscapes dataset  pspnet   ce   and     over  threshold   and     over  argmax   for pascal voc  dataset  pspnet   ce bce  for more information  please check paper   https github website   https   github com statmlben rankseg  https   github com statmlben rankseg ,excited share latest research framework rankseg https abs paper establish theoretical foundation segmentation respect dice iou metrics including bayes rule dice iou calibration analogous classification calibration fisher consistency classification prove existing thresholding based framework operating losses consistent respect dice iou metrics thus may lead suboptimal solution address pitfall propose novel consistent ranking based framework namely rankdice rankiou inspired plug rules bayes segmentation rule three numerical algorithms gpu parallel execution developed implement proposed framework large scale high dimensional segmentation study statistical properties proposed framework show dice iou calibrated excess risk bounds rate convergence also provided numerical effectiveness rankdice mrankdice demonstrated various simulated examples fine annotated cityscapes pascal voc datasets state art deep learning architectures conclusion proposed framework rankseg consistently outperforms existing thresholding based framework simply thresholding estimated probabilities contribution summarize major contribution follows best knowledge proposed ranking based segmentation framework rankdice first consistent segmentation framework respect dice metric dice calibrated three numerical algorithms gpu parallel execution developed implement proposed framework large scale high dimensional segmentation establish theoretical foundation segmentation respect dice metric bayes rule dice calibration moreover present dice calibrated consistency convergence rate excess risk proposed rankdice framework indicate inconsistent results existing methods experiments two simulated examples two real datasets cityscapes dataset pascal voc dataset suggest improvement rankdice existing framework practically significant various loss functions network architectures percentage improvement best performance framework threshold argmax cityscapes dataset pspnet ce threshold argmax pascal voc dataset pspnet ce bce information please check paper https github website https github com statmlben rankseg https github com statmlben rankseg,r rankseg consistent ranking based framework segmentation,r rankseg consistent ranking based framework segmentationexcited share latest research framework rankseg https abs paper establish theoretical foundation segmentation respect dice iou metrics including bayes rule dice iou calibration analogous classification calibration fisher consistency classification prove existing thresholding based framework operating losses consistent respect dice iou metrics thus may lead suboptimal solution address pitfall propose novel consistent ranking based framework namely rankdice rankiou inspired plug rules bayes segmentation rule three numerical algorithms gpu parallel execution developed implement proposed framework large scale high dimensional segmentation study statistical properties proposed framework show dice iou calibrated excess risk bounds rate convergence also provided numerical effectiveness rankdice mrankdice demonstrated various simulated examples fine annotated cityscapes pascal voc datasets state art deep learning architectures conclusion proposed framework rankseg consistently outperforms existing thresholding based framework simply thresholding estimated probabilities contribution summarize major contribution follows best knowledge proposed ranking based segmentation framework rankdice first consistent segmentation framework respect dice metric dice calibrated three numerical algorithms gpu parallel execution developed implement proposed framework large scale high dimensional segmentation establish theoretical foundation segmentation respect dice metric bayes rule dice calibration moreover present dice calibrated consistency convergence rate excess risk proposed rankdice framework indicate inconsistent results existing methods experiments two simulated examples two real datasets cityscapes dataset pascal voc dataset suggest improvement rankdice existing framework practically significant various loss functions network architectures percentage improvement best performance framework threshold argmax cityscapes dataset pspnet ce threshold argmax pascal voc dataset pspnet ce bce information please check paper https github website https github com statmlben rankseg https github com statmlben rankseg,"['r', 'rankseg', 'consistent', 'ranking', 'based', 'framework', 'segmentationexcited', 'share', 'latest', 'research', 'framework', 'rankseg', 'https', 'abs', 'paper', 'establish', 'theoretical', 'foundation', 'segmentation', 'respect', 'dice', 'iou', 'metrics', 'including', 'bayes', 'rule', 'dice', 'iou', 'calibration', 'analogous', 'classification', 'calibration', 'fisher', 'consistency', 'classification', 'prove', 'existing', 'thresholding', 'based', 'framework', 'operating', 'losses', 'consistent', 'respect', 'dice', 'iou', 'metrics', 'thus', 'may', 'lead', 'suboptimal', 'solution', 'address', 'pitfall', 'propose', 'novel', 'consistent', 'ranking', 'based', 'framework', 'namely', 'rankdice', 'rankiou', 'inspired', 'plug', 'rules', 'bayes', 'segmentation', 'rule', 'three', 'numerical', 'algorithms', 'gpu', 'parallel', 'execution', 'developed', 'implement', 'proposed', 'framework', 'large', 'scale', 'high', 'dimensional', 'segmentation', 'study', 'statistical', 'properties', 'proposed', 'framework', 'show', 'dice', 'iou', 'calibrated', 'excess', 'risk', 'bounds', 'rate', 'convergence', 'also', 'provided', 'numerical', 'effectiveness', 'rankdice', 'mrankdice', 'demonstrated', 'various', 'simulated', 'examples', 'fine', 'annotated', 'cityscapes', 'pascal', 'voc', 'datasets', 'state', 'art', 'deep', 'learning', 'architectures', 'conclusion', 'proposed', 'framework', 'rankseg', 'consistently', 'outperforms', 'existing', 'thresholding', 'based', 'framework', 'simply', 'thresholding', 'estimated', 'probabilities', 'contribution', 'summarize', 'major', 'contribution', 'follows', 'best', 'knowledge', 'proposed', 'ranking', 'based', 'segmentation', 'framework', 'rankdice', 'first', 'consistent', 'segmentation', 'framework', 'respect', 'dice', 'metric', 'dice', 'calibrated', 'three', 'numerical', 'algorithms', 'gpu', 'parallel', 'execution', 'developed', 'implement', 'proposed', 'framework', 'large', 'scale', 'high', 'dimensional', 'segmentation', 'establish', 'theoretical', 'foundation', 'segmentation', 'respect', 'dice', 'metric', 'bayes', 'rule', 'dice', 'calibration', 'moreover', 'present', 'dice', 'calibrated', 'consistency', 'convergence', 'rate', 'excess', 'risk', 'proposed', 'rankdice', 'framework', 'indicate', 'inconsistent', 'results', 'existing', 'methods', 'experiments', 'two', 'simulated', 'examples', 'two', 'real', 'datasets', 'cityscapes', 'dataset', 'pascal', 'voc', 'dataset', 'suggest', 'improvement', 'rankdice', 'existing', 'framework', 'practically', 'significant', 'various', 'loss', 'functions', 'network', 'architectures', 'percentage', 'improvement', 'best', 'performance', 'framework', 'threshold', 'argmax', 'cityscapes', 'dataset', 'pspnet', 'ce', 'threshold', 'argmax', 'pascal', 'voc', 'dataset', 'pspnet', 'ce', 'bce', 'information', 'please', 'check', 'paper', 'https', 'github', 'website', 'https', 'github', 'com', 'statmlben', 'rankseg', 'https', 'github', 'com', 'statmlben', 'rankseg']","['r', 'rankseg', 'consist', 'rank', 'base', 'framework', 'segmentationexcit', 'share', 'latest', 'research', 'framework', 'rankseg', 'http', 'ab', 'paper', 'establish', 'theoret', 'foundat', 'segment', 'respect', 'dice', 'iou', 'metric', 'includ', 'bay', 'rule', 'dice', 'iou', 'calibr', 'analog', 'classif', 'calibr', 'fisher', 'consist', 'classif', 'prove', 'exist', 'threshold', 'base', 'framework', 'oper', 'loss', 'consist', 'respect', 'dice', 'iou', 'metric', 'thu', 'may', 'lead', 'suboptim', 'solut', 'address', 'pitfal', 'propos', 'novel', 'consist', 'rank', 'base', 'framework', 'name', 'rankdic', 'rankiou', 'inspir', 'plug', 'rule', 'bay', 'segment', 'rule', 'three', 'numer', 'algorithm', 'gpu', 'parallel', 'execut', 'develop', 'implement', 'propos', 'framework', 'larg', 'scale', 'high', 'dimension', 'segment', 'studi', 'statist', 'properti', 'propos', 'framework', 'show', 'dice', 'iou', 'calibr', 'excess', 'risk', 'bound', 'rate', 'converg', 'also', 'provid', 'numer', 'effect', 'rankdic', 'mrankdic', 'demonstr', 'variou', 'simul', 'exampl', 'fine', 'annot', 'cityscap', 'pascal', 'voc', 'dataset', 'state', 'art', 'deep', 'learn', 'architectur', 'conclus', 'propos', 'framework', 'rankseg', 'consist', 'outperform', 'exist', 'threshold', 'base', 'framework', 'simpli', 'threshold', 'estim', 'probabl', 'contribut', 'summar', 'major', 'contribut', 'follow', 'best', 'knowledg', 'propos', 'rank', 'base', 'segment', 'framework', 'rankdic', 'first', 'consist', 'segment', 'framework', 'respect', 'dice', 'metric', 'dice', 'calibr', 'three', 'numer', 'algorithm', 'gpu', 'parallel', 'execut', 'develop', 'implement', 'propos', 'framework', 'larg', 'scale', 'high', 'dimension', 'segment', 'establish', 'theoret', 'foundat', 'segment', 'respect', 'dice', 'metric', 'bay', 'rule', 'dice', 'calibr', 'moreov', 'present', 'dice', 'calibr', 'consist', 'converg', 'rate', 'excess', 'risk', 'propos', 'rankdic', 'framework', 'indic', 'inconsist', 'result', 'exist', 'method', 'experi', 'two', 'simul', 'exampl', 'two', 'real', 'dataset', 'cityscap', 'dataset', 'pascal', 'voc', 'dataset', 'suggest', 'improv', 'rankdic', 'exist', 'framework', 'practic', 'signific', 'variou', 'loss', 'function', 'network', 'architectur', 'percentag', 'improv', 'best', 'perform', 'framework', 'threshold', 'argmax', 'cityscap', 'dataset', 'pspnet', 'ce', 'threshold', 'argmax', 'pascal', 'voc', 'dataset', 'pspnet', 'ce', 'bce', 'inform', 'pleas', 'check', 'paper', 'http', 'github', 'websit', 'http', 'github', 'com', 'statmlben', 'rankseg', 'http', 'github', 'com', 'statmlben', 'rankseg']"
162,176,176,seraschka,vobeir,[P] Sharing an Interactive Research Demo on the Cloud,"I am curious to hear what you usually use to develop interactive versions of your research models! And, if you have any, I'd be excited to see some examples for inspiration 😊.

On that note, about 2 weeks ago, I shared an article on developing a Super-Resolution GAN Research Demo in Lightning on r/MachineLearning: [Bottom-up look at the new Lightning Framework for building anything from production-ready ML systems to research demos](https://www.reddit.com/r/MachineLearning/comments/vi41f7/p_bottomup_look_at_the_new_lightning_framework/)

Running research demos locally is not super useful by itself (unless you maybe do that live at a poster session -- I still have painful memories of doing that with privacy GAN demo in Flask), so this is a follow-up article on deploying the App on the Cloud: [Sharing Deep Learning Research Models with Lightning Part 2: Leveraging the Cloud](https://sebastianraschka.com/blog/2022/lightning-app-srgan-2.html).

Also, curious to hear what you think!",2,0,2022-06-30 21:11:24, p  sharing an interactive research demo on the cloud,i am curious to hear what you usually use to develop interactive versions of your research models  and  if you have any  i d be excited to see some examples for inspiration   on that note  about  weeks ago  i shared an article on developing a super resolution gan research demo in lightning on r machinelearning   bottom up look at the new lightning framework for building anything from production ready ml systems to research demos  https running research demos locally is not super useful by itself  unless you maybe do that live at a poster session    i still have painful memories of doing that with privacy gan demo in flask   so this is a follow up article on deploying the app on the cloud   sharing deep learning research models with lightning part   leveraging the cloud  https also  curious to hear what you think ,curious hear usually use develop interactive versions research models excited see examples inspiration note weeks ago shared article developing super resolution gan research demo lightning r machinelearning bottom look lightning framework building anything production ready ml systems research demos https running research demos locally super useful unless maybe live poster session still painful memories privacy gan demo flask follow article deploying app cloud sharing deep learning research models lightning part leveraging cloud https also curious hear think,p sharing interactive research demo cloud,p sharing interactive research demo cloudcurious hear usually use develop interactive versions research models excited see examples inspiration note weeks ago shared article developing super resolution gan research demo lightning r machinelearning bottom look lightning framework building anything production ready ml systems research demos https running research demos locally super useful unless maybe live poster session still painful memories privacy gan demo flask follow article deploying app cloud sharing deep learning research models lightning part leveraging cloud https also curious hear think,"['p', 'sharing', 'interactive', 'research', 'demo', 'cloudcurious', 'hear', 'usually', 'use', 'develop', 'interactive', 'versions', 'research', 'models', 'excited', 'see', 'examples', 'inspiration', 'note', 'weeks', 'ago', 'shared', 'article', 'developing', 'super', 'resolution', 'gan', 'research', 'demo', 'lightning', 'r', 'machinelearning', 'bottom', 'look', 'lightning', 'framework', 'building', 'anything', 'production', 'ready', 'ml', 'systems', 'research', 'demos', 'https', 'running', 'research', 'demos', 'locally', 'super', 'useful', 'unless', 'maybe', 'live', 'poster', 'session', 'still', 'painful', 'memories', 'privacy', 'gan', 'demo', 'flask', 'follow', 'article', 'deploying', 'app', 'cloud', 'sharing', 'deep', 'learning', 'research', 'models', 'lightning', 'part', 'leveraging', 'cloud', 'https', 'also', 'curious', 'hear', 'think']","['p', 'share', 'interact', 'research', 'demo', 'cloudcuri', 'hear', 'usual', 'use', 'develop', 'interact', 'version', 'research', 'model', 'excit', 'see', 'exampl', 'inspir', 'note', 'week', 'ago', 'share', 'articl', 'develop', 'super', 'resolut', 'gan', 'research', 'demo', 'lightn', 'r', 'machinelearn', 'bottom', 'look', 'lightn', 'framework', 'build', 'anyth', 'product', 'readi', 'ml', 'system', 'research', 'demo', 'http', 'run', 'research', 'demo', 'local', 'super', 'use', 'unless', 'mayb', 'live', 'poster', 'session', 'still', 'pain', 'memori', 'privaci', 'gan', 'demo', 'flask', 'follow', 'articl', 'deploy', 'app', 'cloud', 'share', 'deep', 'learn', 'research', 'model', 'lightn', 'part', 'leverag', 'cloud', 'http', 'also', 'curiou', 'hear', 'think']"
163,177,177,gabe415160,vnvbdp,[Discussion] Regarding Long Term Memory in NLP Models,"Does anyone know if there exists a NLP model, like Lambda, that takes every conversation attempts to update their weights in order to incorporate it into its training?

My thought process would be instead of using attention and a subsection of the conversation to generate a response, it takes everything. Basically everything gets back propagated and adjusts the weights. This way the model might begin to ""remember"" its previous conversations. This may be a stretch and perhaps I am missing something fundamental, but it seems like an interesting experiment. I'd love to continue this conversation and elaborate more in the comments.",8,12,2022-06-30 06:26:11, discussion  regarding long term memory in nlp models,does anyone know if there exists a nlp model  like lambda  that takes every conversation attempts to update their weights in order to incorporate it into its training my thought process would be instead of using attention and a subsection of the conversation to generate a response  it takes everything  basically everything gets back propagated and adjusts the weights  this way the model might begin to remember its previous conversations  this may be a stretch and perhaps i am missing something fundamental  but it seems like an interesting experiment  i d love to continue this conversation and elaborate more in the comments ,anyone know exists nlp model like lambda takes every conversation attempts update weights order incorporate training thought process would instead using attention subsection conversation generate response takes everything basically everything gets back propagated adjusts weights way model might begin remember previous conversations may stretch perhaps missing something fundamental seems like interesting experiment love continue conversation elaborate comments,discussion regarding long term memory nlp models,discussion regarding long term memory nlp modelsanyone know exists nlp model like lambda takes every conversation attempts update weights order incorporate training thought process would instead using attention subsection conversation generate response takes everything basically everything gets back propagated adjusts weights way model might begin remember previous conversations may stretch perhaps missing something fundamental seems like interesting experiment love continue conversation elaborate comments,"['discussion', 'regarding', 'long', 'term', 'memory', 'nlp', 'modelsanyone', 'know', 'exists', 'nlp', 'model', 'like', 'lambda', 'takes', 'every', 'conversation', 'attempts', 'update', 'weights', 'order', 'incorporate', 'training', 'thought', 'process', 'would', 'instead', 'using', 'attention', 'subsection', 'conversation', 'generate', 'response', 'takes', 'everything', 'basically', 'everything', 'gets', 'back', 'propagated', 'adjusts', 'weights', 'way', 'model', 'might', 'begin', 'remember', 'previous', 'conversations', 'may', 'stretch', 'perhaps', 'missing', 'something', 'fundamental', 'seems', 'like', 'interesting', 'experiment', 'love', 'continue', 'conversation', 'elaborate', 'comments']","['discuss', 'regard', 'long', 'term', 'memori', 'nlp', 'modelsanyon', 'know', 'exist', 'nlp', 'model', 'like', 'lambda', 'take', 'everi', 'convers', 'attempt', 'updat', 'weight', 'order', 'incorpor', 'train', 'thought', 'process', 'would', 'instead', 'use', 'attent', 'subsect', 'convers', 'gener', 'respons', 'take', 'everyth', 'basic', 'everyth', 'get', 'back', 'propag', 'adjust', 'weight', 'way', 'model', 'might', 'begin', 'rememb', 'previou', 'convers', 'may', 'stretch', 'perhap', 'miss', 'someth', 'fundament', 'seem', 'like', 'interest', 'experi', 'love', 'continu', 'convers', 'elabor', 'comment']"
164,178,178,darthsocker,vodb3j,[D] Moody Actor Critic,"Generally actor critic algorithms have 1 Neural net giving 1 of each via a linear layer - to give a policy and to give the value. But humans change decisions and how they think based on their mood. I wanted to incorporate this into a standard actor critic like A2C/A3C. I wanted to add another actor in this architecture that represented a certain mood, where it's objective was not to maximize the reward but something else that I have in mind.  I don't see any such literature in the field and I don't know how to add more actors. Is it not possible to have multiple actors with one critic ? Has this been passed on by the community for a lack of potential ?",4,0,2022-06-30 22:32:28, d  moody actor critic,generally actor critic algorithms have  neural net giving  of each via a linear layer   to give a policy and to give the value  but humans change decisions and how they think based on their mood  i wanted to incorporate this into a standard actor critic like ac ac  i wanted to add another actor in this architecture that represented a certain mood  where it s objective was not to maximize the reward but something else that i have in mind   i don t see any such literature in the field and i don t know how to add more actors  is it not possible to have multiple actors with one critic   has this been passed on by the community for a lack of potential  ,generally actor critic algorithms neural net giving via linear layer give policy give value humans change decisions think based mood wanted incorporate standard actor critic like ac ac wanted another actor architecture represented certain mood objective maximize reward something else mind see literature field know actors possible multiple actors one critic passed community lack potential,moody actor critic,moody actor criticgenerally actor critic algorithms neural net giving via linear layer give policy give value humans change decisions think based mood wanted incorporate standard actor critic like ac ac wanted another actor architecture represented certain mood objective maximize reward something else mind see literature field know actors possible multiple actors one critic passed community lack potential,"['moody', 'actor', 'criticgenerally', 'actor', 'critic', 'algorithms', 'neural', 'net', 'giving', 'via', 'linear', 'layer', 'give', 'policy', 'give', 'value', 'humans', 'change', 'decisions', 'think', 'based', 'mood', 'wanted', 'incorporate', 'standard', 'actor', 'critic', 'like', 'ac', 'ac', 'wanted', 'another', 'actor', 'architecture', 'represented', 'certain', 'mood', 'objective', 'maximize', 'reward', 'something', 'else', 'mind', 'see', 'literature', 'field', 'know', 'actors', 'possible', 'multiple', 'actors', 'one', 'critic', 'passed', 'community', 'lack', 'potential']","['moodi', 'actor', 'criticgener', 'actor', 'critic', 'algorithm', 'neural', 'net', 'give', 'via', 'linear', 'layer', 'give', 'polici', 'give', 'valu', 'human', 'chang', 'decis', 'think', 'base', 'mood', 'want', 'incorpor', 'standard', 'actor', 'critic', 'like', 'ac', 'ac', 'want', 'anoth', 'actor', 'architectur', 'repres', 'certain', 'mood', 'object', 'maxim', 'reward', 'someth', 'els', 'mind', 'see', 'literatur', 'field', 'know', 'actor', 'possibl', 'multipl', 'actor', 'one', 'critic', 'pass', 'commun', 'lack', 'potenti']"
165,179,179,NeoKoseii,vo7p9i,[P] [R] Automated Essay Scoring Systems for other languages," Hey guys, working on an AES project. Just wanted to know if there exists an AES system that can be trained on languages like Swahili, Arabic, Hindi etc. Languages having almost no AES studies done.

Would be very helpful of you to guide me through, any other tips/pointers towards this task are much appreciated, would love it if someone can point me in the right direction.",0,0,2022-06-30 18:24:36, p   r  automated essay scoring systems for other languages, hey guys  working on an aes project  just wanted to know if there exists an aes system that can be trained on languages like swahili  arabic  hindi etc  languages having almost no aes studies done would be very helpful of you to guide me through  any other tips pointers towards this task are much appreciated  would love it if someone can point me in the right direction ,hey guys working aes project wanted know exists aes system trained languages like swahili arabic hindi etc languages almost aes studies done would helpful guide tips pointers towards task much appreciated would love someone point right direction,p r automated essay scoring systems languages,p r automated essay scoring systems languageshey guys working aes project wanted know exists aes system trained languages like swahili arabic hindi etc languages almost aes studies done would helpful guide tips pointers towards task much appreciated would love someone point right direction,"['p', 'r', 'automated', 'essay', 'scoring', 'systems', 'languageshey', 'guys', 'working', 'aes', 'project', 'wanted', 'know', 'exists', 'aes', 'system', 'trained', 'languages', 'like', 'swahili', 'arabic', 'hindi', 'etc', 'languages', 'almost', 'aes', 'studies', 'done', 'would', 'helpful', 'guide', 'tips', 'pointers', 'towards', 'task', 'much', 'appreciated', 'would', 'love', 'someone', 'point', 'right', 'direction']","['p', 'r', 'autom', 'essay', 'score', 'system', 'languageshey', 'guy', 'work', 'ae', 'project', 'want', 'know', 'exist', 'ae', 'system', 'train', 'languag', 'like', 'swahili', 'arab', 'hindi', 'etc', 'languag', 'almost', 'ae', 'studi', 'done', 'would', 'help', 'guid', 'tip', 'pointer', 'toward', 'task', 'much', 'appreci', 'would', 'love', 'someon', 'point', 'right', 'direct']"
166,180,180,cltexe,vohzvl,[D] Creating a neural network for my daughter's sake. Need advice on acronym.,"Hi, very long time lurker here.

I'm planning to propose an end to end architecture for my daughter's sake. Data is biomedical and any CNN is well capable of classfying if over %95 Acc (easy data u know!). However, I need to come up with an acronym to fit my daughter's name. Her name is DURU and here is what I come up with:

D- Deep (Deep like you know, deep learning)

U-Unified (I may use multiple models to form up an ensemble or feature concat, which will make it unified)

R- Residual (I may use residual connections between Cnn blocks. Though not flashy right now.)

R- Recommender (Could use recommender keyword, since I'm putting down sort of a Computer Aided Diagnosis Framework thingy)

R- Another R thing is welcome.

U - I need another U and I'm totally out of words.

Three letters is all I came up with. Couldn't find a word for the 4th letter that makes sense. U-net? I'm not segmentating anything. But if it was a segmentation dataset I may have come up with DUR-UNet which would make sense.

I need a final keyword starting with U which is applicable with CNNs. It could be minor trick to cope with overfitting, a loss function, an activation function, etc. It could also be a filler term like Unified.

Hope we could come up with a solution.",8,0,2022-07-01 01:55:58, d  creating a neural network for my daughter s sake  need advice on acronym ,hi  very long time lurker here i m planning to propose an end to end architecture for my daughter s sake  data is biomedical and any cnn is well capable of classfying if over   acc  easy data u know    however  i need to come up with an acronym to fit my daughter s name  her name is duru and here is what i come up with d  deep  deep like you know  deep learning u unified  i may use multiple models to form up an ensemble or feature concat  which will make it unified r  residual  i may use residual connections between cnn blocks  though not flashy right now  r  recommender  could use recommender keyword  since i m putting down sort of a computer aided diagnosis framework thingy r  another r thing is welcome u   i need another u and i m totally out of words three letters is all i came up with  couldn t find a word for the th letter that makes sense  u net  i m not segmentating anything  but if it was a segmentation dataset i may have come up with dur unet which would make sense i need a final keyword starting with u which is applicable with cnns  it could be minor trick to cope with overfitting  a loss function  an activation function  etc  it could also be a filler term like unified hope we could come up with a solution ,hi long time lurker planning propose end end architecture daughter sake data biomedical cnn well capable classfying acc easy data u know however need come acronym fit daughter name name duru come deep deep like know deep learning u unified may use multiple models form ensemble feature concat make unified r residual may use residual connections cnn blocks though flashy right r recommender could use recommender keyword since putting sort computer aided diagnosis framework thingy r another r thing welcome u need another u totally three letters came find word th letter makes sense u net segmentating anything segmentation dataset may come dur unet would make sense need final keyword starting u applicable cnns could minor trick cope overfitting loss function activation function etc could also filler term like unified hope could come solution,creating neural network daughter sake need advice acronym,creating neural network daughter sake need advice acronymhi long time lurker planning propose end end architecture daughter sake data biomedical cnn well capable classfying acc easy data u know however need come acronym fit daughter name name duru come deep deep like know deep learning u unified may use multiple models form ensemble feature concat make unified r residual may use residual connections cnn blocks though flashy right r recommender could use recommender keyword since putting sort computer aided diagnosis framework thingy r another r thing welcome u need another u totally three letters came find word th letter makes sense u net segmentating anything segmentation dataset may come dur unet would make sense need final keyword starting u applicable cnns could minor trick cope overfitting loss function activation function etc could also filler term like unified hope could come solution,"['creating', 'neural', 'network', 'daughter', 'sake', 'need', 'advice', 'acronymhi', 'long', 'time', 'lurker', 'planning', 'propose', 'end', 'end', 'architecture', 'daughter', 'sake', 'data', 'biomedical', 'cnn', 'well', 'capable', 'classfying', 'acc', 'easy', 'data', 'u', 'know', 'however', 'need', 'come', 'acronym', 'fit', 'daughter', 'name', 'name', 'duru', 'come', 'deep', 'deep', 'like', 'know', 'deep', 'learning', 'u', 'unified', 'may', 'use', 'multiple', 'models', 'form', 'ensemble', 'feature', 'concat', 'make', 'unified', 'r', 'residual', 'may', 'use', 'residual', 'connections', 'cnn', 'blocks', 'though', 'flashy', 'right', 'r', 'recommender', 'could', 'use', 'recommender', 'keyword', 'since', 'putting', 'sort', 'computer', 'aided', 'diagnosis', 'framework', 'thingy', 'r', 'another', 'r', 'thing', 'welcome', 'u', 'need', 'another', 'u', 'totally', 'three', 'letters', 'came', 'find', 'word', 'th', 'letter', 'makes', 'sense', 'u', 'net', 'segmentating', 'anything', 'segmentation', 'dataset', 'may', 'come', 'dur', 'unet', 'would', 'make', 'sense', 'need', 'final', 'keyword', 'starting', 'u', 'applicable', 'cnns', 'could', 'minor', 'trick', 'cope', 'overfitting', 'loss', 'function', 'activation', 'function', 'etc', 'could', 'also', 'filler', 'term', 'like', 'unified', 'hope', 'could', 'come', 'solution']","['creat', 'neural', 'network', 'daughter', 'sake', 'need', 'advic', 'acronymhi', 'long', 'time', 'lurker', 'plan', 'propos', 'end', 'end', 'architectur', 'daughter', 'sake', 'data', 'biomed', 'cnn', 'well', 'capabl', 'classfi', 'acc', 'easi', 'data', 'u', 'know', 'howev', 'need', 'come', 'acronym', 'fit', 'daughter', 'name', 'name', 'duru', 'come', 'deep', 'deep', 'like', 'know', 'deep', 'learn', 'u', 'unifi', 'may', 'use', 'multipl', 'model', 'form', 'ensembl', 'featur', 'concat', 'make', 'unifi', 'r', 'residu', 'may', 'use', 'residu', 'connect', 'cnn', 'block', 'though', 'flashi', 'right', 'r', 'recommend', 'could', 'use', 'recommend', 'keyword', 'sinc', 'put', 'sort', 'comput', 'aid', 'diagnosi', 'framework', 'thingi', 'r', 'anoth', 'r', 'thing', 'welcom', 'u', 'need', 'anoth', 'u', 'total', 'three', 'letter', 'came', 'find', 'word', 'th', 'letter', 'make', 'sens', 'u', 'net', 'segment', 'anyth', 'segment', 'dataset', 'may', 'come', 'dur', 'unet', 'would', 'make', 'sens', 'need', 'final', 'keyword', 'start', 'u', 'applic', 'cnn', 'could', 'minor', 'trick', 'cope', 'overfit', 'loss', 'function', 'activ', 'function', 'etc', 'could', 'also', 'filler', 'term', 'like', 'unifi', 'hope', 'could', 'come', 'solut']"
167,181,181,Anonymous_Guy_12,vo8fuo,"[D] Loss Function, Uncertainty","
Hello members, soo my question is suppose we have a model or architecture at we have an image classifier at the end of it which is trained on mnist images. We need to train the model such that when the image is passed through the classifier it outcomes it's results with some uncertainty in its predictions. 
We need to use that uncertainty in order to develop a loss function to train the whole model as we can't use the true labels of the images. 

Any resources or ideas related to above which can be helpful pls share with me. Any suggestions will be appreciated.

Thanks",4,0,2022-06-30 18:59:37, d  loss function  uncertainty,hello members  soo my question is suppose we have a model or architecture at we have an image classifier at the end of it which is trained on mnist images  we need to train the model such that when the image is passed through the classifier it outcomes it s results with some uncertainty in its predictions  we need to use that uncertainty in order to develop a loss function to train the whole model as we can t use the true labels of the images  any resources or ideas related to above which can be helpful pls share with me  any suggestions will be appreciated thanks,hello members soo question suppose model architecture image classifier end trained mnist images need train model image passed classifier outcomes results uncertainty predictions need use uncertainty order develop loss function train whole model use true labels images resources ideas related helpful pls share suggestions appreciated thanks,loss function uncertainty,loss function uncertaintyhello members soo question suppose model architecture image classifier end trained mnist images need train model image passed classifier outcomes results uncertainty predictions need use uncertainty order develop loss function train whole model use true labels images resources ideas related helpful pls share suggestions appreciated thanks,"['loss', 'function', 'uncertaintyhello', 'members', 'soo', 'question', 'suppose', 'model', 'architecture', 'image', 'classifier', 'end', 'trained', 'mnist', 'images', 'need', 'train', 'model', 'image', 'passed', 'classifier', 'outcomes', 'results', 'uncertainty', 'predictions', 'need', 'use', 'uncertainty', 'order', 'develop', 'loss', 'function', 'train', 'whole', 'model', 'use', 'true', 'labels', 'images', 'resources', 'ideas', 'related', 'helpful', 'pls', 'share', 'suggestions', 'appreciated', 'thanks']","['loss', 'function', 'uncertaintyhello', 'member', 'soo', 'question', 'suppos', 'model', 'architectur', 'imag', 'classifi', 'end', 'train', 'mnist', 'imag', 'need', 'train', 'model', 'imag', 'pass', 'classifi', 'outcom', 'result', 'uncertainti', 'predict', 'need', 'use', 'uncertainti', 'order', 'develop', 'loss', 'function', 'train', 'whole', 'model', 'use', 'true', 'label', 'imag', 'resourc', 'idea', 'relat', 'help', 'pl', 'share', 'suggest', 'appreci', 'thank']"
168,182,182,mrwafflezzz,vo2b3w,[D] How would go about tracking an ML run when the framework logs text to a txt log?,"I was hoping that Mlflow had a method or function for parsing a txt log, but I can't find anything. Does anyone know of an elegant solution that runs in parallel to the training process?",6,0,2022-06-30 12:48:56, d  how would go about tracking an ml run when the framework logs text to a txt log ,i was hoping that mlflow had a method or function for parsing a txt log  but i can t find anything  does anyone know of an elegant solution that runs in parallel to the training process ,hoping mlflow method function parsing txt log find anything anyone know elegant solution runs parallel training process,would go tracking ml run framework logs text txt log,would go tracking ml run framework logs text txt loghoping mlflow method function parsing txt log find anything anyone know elegant solution runs parallel training process,"['would', 'go', 'tracking', 'ml', 'run', 'framework', 'logs', 'text', 'txt', 'loghoping', 'mlflow', 'method', 'function', 'parsing', 'txt', 'log', 'find', 'anything', 'anyone', 'know', 'elegant', 'solution', 'runs', 'parallel', 'training', 'process']","['would', 'go', 'track', 'ml', 'run', 'framework', 'log', 'text', 'txt', 'loghop', 'mlflow', 'method', 'function', 'pars', 'txt', 'log', 'find', 'anyth', 'anyon', 'know', 'eleg', 'solut', 'run', 'parallel', 'train', 'process']"
169,183,183,big_black_doge,vnxhww,[D] How well does auto annotating a dataset with a pretrained model work?," Hi reddit, I am asking this question because I don't see much about this in the literature.

I want to build an object detection model (class + bounding box), but I have very little annotated data. I have an idea to use a pretrained model to create predicted annotations from a very large object classification (class, no bounding box) dataset. I can then filter those predicted annotations to use only high confidence annotations, and manually check the images to ensure quality. Then, I should have a large, high quality object detection dataset with which I can train my model with.

 I didn't see many papers on this type of thing. It's not exactly transfer learning, because it's actually building a task specific dataset from another type of dataset. Is there some reason why this wouldn't work? Or does anyone have any research on this type of idea?",9,2,2022-06-30 08:14:25, d  how well does auto annotating a dataset with a pretrained model work , hi reddit  i am asking this question because i don t see much about this in the literature i want to build an object detection model  class   bounding box   but i have very little annotated data  i have an idea to use a pretrained model to create predicted annotations from a very large object classification  class  no bounding box  dataset  i can then filter those predicted annotations to use only high confidence annotations  and manually check the images to ensure quality  then  i should have a large  high quality object detection dataset with which i can train my model with  i didn t see many papers on this type of thing  it s not exactly transfer learning  because it s actually building a task specific dataset from another type of dataset  is there some reason why this wouldn t work  or does anyone have any research on this type of idea ,hi reddit asking question see much literature want build object detection model class bounding box little annotated data idea use pretrained model create predicted annotations large object classification class bounding box dataset filter predicted annotations use high confidence annotations manually check images ensure quality large high quality object detection dataset train model see many papers type thing exactly transfer learning actually building task specific dataset another type dataset reason work anyone research type idea,well auto annotating dataset pretrained model work,well auto annotating dataset pretrained model workhi reddit asking question see much literature want build object detection model class bounding box little annotated data idea use pretrained model create predicted annotations large object classification class bounding box dataset filter predicted annotations use high confidence annotations manually check images ensure quality large high quality object detection dataset train model see many papers type thing exactly transfer learning actually building task specific dataset another type dataset reason work anyone research type idea,"['well', 'auto', 'annotating', 'dataset', 'pretrained', 'model', 'workhi', 'reddit', 'asking', 'question', 'see', 'much', 'literature', 'want', 'build', 'object', 'detection', 'model', 'class', 'bounding', 'box', 'little', 'annotated', 'data', 'idea', 'use', 'pretrained', 'model', 'create', 'predicted', 'annotations', 'large', 'object', 'classification', 'class', 'bounding', 'box', 'dataset', 'filter', 'predicted', 'annotations', 'use', 'high', 'confidence', 'annotations', 'manually', 'check', 'images', 'ensure', 'quality', 'large', 'high', 'quality', 'object', 'detection', 'dataset', 'train', 'model', 'see', 'many', 'papers', 'type', 'thing', 'exactly', 'transfer', 'learning', 'actually', 'building', 'task', 'specific', 'dataset', 'another', 'type', 'dataset', 'reason', 'work', 'anyone', 'research', 'type', 'idea']","['well', 'auto', 'annot', 'dataset', 'pretrain', 'model', 'workhi', 'reddit', 'ask', 'question', 'see', 'much', 'literatur', 'want', 'build', 'object', 'detect', 'model', 'class', 'bound', 'box', 'littl', 'annot', 'data', 'idea', 'use', 'pretrain', 'model', 'creat', 'predict', 'annot', 'larg', 'object', 'classif', 'class', 'bound', 'box', 'dataset', 'filter', 'predict', 'annot', 'use', 'high', 'confid', 'annot', 'manual', 'check', 'imag', 'ensur', 'qualiti', 'larg', 'high', 'qualiti', 'object', 'detect', 'dataset', 'train', 'model', 'see', 'mani', 'paper', 'type', 'thing', 'exactli', 'transfer', 'learn', 'actual', 'build', 'task', 'specif', 'dataset', 'anoth', 'type', 'dataset', 'reason', 'work', 'anyon', 'research', 'type', 'idea']"
170,184,184,RepresentativeCod613,vmz09g,[D][P] YOLOv6: state-of-the-art object detection at 1242 FPS,"YOLOv6 has been making a lot of noise in the past 24 hours. Based on its performance - rightfully so.

YOLOv6 is a single-stage object detection framework dedicated to industrial applications, with hardware-friendly efficient design and high performance. It outperforms YOLOv5 in accuracy and inference speed, making it the best OS version of YOLO architecture for production applications.

I dived into the technical details published by the research group and made a qualitative and qualitative comparison between the results of YOLOv5 and YOLOv6. 

I invite you to read about all of these, with a bit of history on YOLO, in the my [new blog](https://dagshub.com/blog/yolov6/)",48,252,2022-06-29 03:25:27, d  p  yolov  state of the art object detection at  fps,yolov has been making a lot of noise in the past  hours  based on its performance   rightfully so yolov is a single stage object detection framework dedicated to industrial applications  with hardware friendly efficient design and high performance  it outperforms yolov in accuracy and inference speed  making it the best os version of yolo architecture for production applications i dived into the technical details published by the research group and made a qualitative and qualitative comparison between the results of yolov and yolov  i invite you to read about all of these  with a bit of history on yolo  in the my  new blog  https   dagshub com blog yolov  ,yolov making lot noise past hours based performance rightfully yolov single stage object detection framework dedicated industrial applications hardware friendly efficient design high performance outperforms yolov accuracy inference speed making best os version yolo architecture production applications dived technical details published research group made qualitative qualitative comparison results yolov yolov invite read bit history yolo blog https dagshub com blog yolov,p yolov state art object detection fps,p yolov state art object detection fpsyolov making lot noise past hours based performance rightfully yolov single stage object detection framework dedicated industrial applications hardware friendly efficient design high performance outperforms yolov accuracy inference speed making best os version yolo architecture production applications dived technical details published research group made qualitative qualitative comparison results yolov yolov invite read bit history yolo blog https dagshub com blog yolov,"['p', 'yolov', 'state', 'art', 'object', 'detection', 'fpsyolov', 'making', 'lot', 'noise', 'past', 'hours', 'based', 'performance', 'rightfully', 'yolov', 'single', 'stage', 'object', 'detection', 'framework', 'dedicated', 'industrial', 'applications', 'hardware', 'friendly', 'efficient', 'design', 'high', 'performance', 'outperforms', 'yolov', 'accuracy', 'inference', 'speed', 'making', 'best', 'os', 'version', 'yolo', 'architecture', 'production', 'applications', 'dived', 'technical', 'details', 'published', 'research', 'group', 'made', 'qualitative', 'qualitative', 'comparison', 'results', 'yolov', 'yolov', 'invite', 'read', 'bit', 'history', 'yolo', 'blog', 'https', 'dagshub', 'com', 'blog', 'yolov']","['p', 'yolov', 'state', 'art', 'object', 'detect', 'fpsyolov', 'make', 'lot', 'nois', 'past', 'hour', 'base', 'perform', 'right', 'yolov', 'singl', 'stage', 'object', 'detect', 'framework', 'dedic', 'industri', 'applic', 'hardwar', 'friendli', 'effici', 'design', 'high', 'perform', 'outperform', 'yolov', 'accuraci', 'infer', 'speed', 'make', 'best', 'os', 'version', 'yolo', 'architectur', 'product', 'applic', 'dive', 'technic', 'detail', 'publish', 'research', 'group', 'made', 'qualit', 'qualit', 'comparison', 'result', 'yolov', 'yolov', 'invit', 'read', 'bit', 'histori', 'yolo', 'blog', 'http', 'dagshub', 'com', 'blog', 'yolov']"
171,185,185,Meddhouib10,vo43z0,[D] Merging two iterators (pytorch dataloaders),"Hello everyone !
So I have two dataloaders that I want to iterate throught, like not in a chained way.
I want to simple elements from one or the other each iteration step randomly.
Is there anyway to create a pytorch dataloader that does that ? Like what function should a pytorch dataloaders contain.
I found nothing on this subject on the internet that’s why I’m asking for your help
Thanks in advance",13,0,2022-06-30 14:49:45, d  merging two iterators  pytorch dataloaders ,hello everyone  so i have two dataloaders that i want to iterate throught  like not in a chained way i want to simple elements from one or the other each iteration step randomly is there anyway to create a pytorch dataloader that does that   like what function should a pytorch dataloaders contain i found nothing on this subject on the internet that s why i m asking for your helpthanks in advance,hello everyone two dataloaders want iterate throught like chained way want simple elements one iteration step randomly anyway create pytorch dataloader like function pytorch dataloaders contain found nothing subject internet asking helpthanks advance,merging two iterators pytorch dataloaders,merging two iterators pytorch dataloadershello everyone two dataloaders want iterate throught like chained way want simple elements one iteration step randomly anyway create pytorch dataloader like function pytorch dataloaders contain found nothing subject internet asking helpthanks advance,"['merging', 'two', 'iterators', 'pytorch', 'dataloadershello', 'everyone', 'two', 'dataloaders', 'want', 'iterate', 'throught', 'like', 'chained', 'way', 'want', 'simple', 'elements', 'one', 'iteration', 'step', 'randomly', 'anyway', 'create', 'pytorch', 'dataloader', 'like', 'function', 'pytorch', 'dataloaders', 'contain', 'found', 'nothing', 'subject', 'internet', 'asking', 'helpthanks', 'advance']","['merg', 'two', 'iter', 'pytorch', 'dataloadershello', 'everyon', 'two', 'dataload', 'want', 'iter', 'throught', 'like', 'chain', 'way', 'want', 'simpl', 'element', 'one', 'iter', 'step', 'randomli', 'anyway', 'creat', 'pytorch', 'dataload', 'like', 'function', 'pytorch', 'dataload', 'contain', 'found', 'noth', 'subject', 'internet', 'ask', 'helpthank', 'advanc']"
172,186,186,optimized-adam,vndtn8,[D] Mixed Precision Training: Difference between BF16 and FP16,"What differences in model performance, speed, memory etc. can I expect between choosing BF16 or FP16 for mixed precision training? Is BF16 faster / consumes less memory, since I have seen people say it is ""more suitable for Deep Learning"". Why is that the case?",8,12,2022-06-29 17:14:00, d  mixed precision training  difference between bf and fp,what differences in model performance  speed  memory etc  can i expect between choosing bf or fp for mixed precision training  is bf faster   consumes less memory  since i have seen people say it is more suitable for deep learning  why is that the case ,differences model performance speed memory etc expect choosing bf fp mixed precision training bf faster consumes less memory since seen people say suitable deep learning case,mixed precision training difference bf fp,mixed precision training difference bf fpdifferences model performance speed memory etc expect choosing bf fp mixed precision training bf faster consumes less memory since seen people say suitable deep learning case,"['mixed', 'precision', 'training', 'difference', 'bf', 'fpdifferences', 'model', 'performance', 'speed', 'memory', 'etc', 'expect', 'choosing', 'bf', 'fp', 'mixed', 'precision', 'training', 'bf', 'faster', 'consumes', 'less', 'memory', 'since', 'seen', 'people', 'say', 'suitable', 'deep', 'learning', 'case']","['mix', 'precis', 'train', 'differ', 'bf', 'fpdiffer', 'model', 'perform', 'speed', 'memori', 'etc', 'expect', 'choos', 'bf', 'fp', 'mix', 'precis', 'train', 'bf', 'faster', 'consum', 'less', 'memori', 'sinc', 'seen', 'peopl', 'say', 'suitabl', 'deep', 'learn', 'case']"
173,187,187,DreamFlasher,vmwiep,"[N] PyTorch 1.12: TorchArrow, Functional API for Modules and NvFuser"," PyTorch 1.12 Release Notes

* Highlights
* Backwards Incompatible Change
* New Features
* Improvements
* Performance
* Documentation

Highlights

We  are excited to announce the release of PyTorch 1.12! This release  is  composed of over 3124 commits, 433 contributors. Along with 1.12, we   are releasing beta versions of AWS S3 Integration, PyTorch Vision Models   on Channels Last on CPU, Empowering PyTorch on Intel® Xeon® Scalable   processors with Bfloat16 and FSDP API. We want to sincerely thank our   dedicated community for your contributions.

Summary:

* Functional Module API to functionally apply module computation with a given set of parameters
* Complex32 and Complex Convolutions in PyTorch
* DataPipes from TorchData fully backward compatible with DataLoader
* Functorch with improved coverage for APIs
* nvFuser a deep learning compiler for PyTorch
* Changes to float32 matrix multiplication precision on Ampere and later CUDA hardware
* TorchArrow, a new beta library for machine learning preprocessing over batch data

[https://github.com/pytorch/pytorch/releases/tag/v1.12.0](https://github.com/pytorch/pytorch/releases/tag/v1.12.0)

[https://pytorch.org/blog/pytorch-1.12-released/](https://pytorch.org/blog/pytorch-1.12-released/)",9,95,2022-06-29 01:37:50, n  pytorch    torcharrow  functional api for modules and nvfuser, pytorch   release notes  highlights  backwards incompatible change  new features  improvements  performance  documentationhighlightswe  are excited to announce the release of pytorch    this release  is  composed of over  commits   contributors  along with    we   are releasing beta versions of aws s integration  pytorch vision models   on channels last on cpu  empowering pytorch on intel  xeon  scalable   processors with bfloat and fsdp api  we want to sincerely thank our   dedicated community for your contributions summary   functional module api to functionally apply module computation with a given set of parameters  complex and complex convolutions in pytorch  datapipes from torchdata fully backward compatible with dataloader  functorch with improved coverage for apis  nvfuser a deep learning compiler for pytorch  changes to float matrix multiplication precision on ampere and later cuda hardware  torcharrow  a new beta library for machine learning preprocessing over batch data https  https   pytorch org blog pytorch   released   https   pytorch org blog pytorch   released  ,pytorch release notes highlights backwards incompatible change features improvements performance documentationhighlightswe excited announce release pytorch release composed commits contributors along releasing beta versions aws integration pytorch vision models channels last cpu empowering pytorch intel xeon scalable processors bfloat fsdp api want sincerely thank dedicated community contributions summary functional module api functionally apply module computation given set parameters complex complex convolutions pytorch datapipes torchdata fully backward compatible dataloader functorch improved coverage apis nvfuser deep learning compiler pytorch changes float matrix multiplication precision ampere later cuda hardware torcharrow beta library machine learning preprocessing batch data https https pytorch org blog pytorch released https pytorch org blog pytorch released,n pytorch torcharrow functional api modules nvfuser,n pytorch torcharrow functional api modules nvfuserpytorch release notes highlights backwards incompatible change features improvements performance documentationhighlightswe excited announce release pytorch release composed commits contributors along releasing beta versions aws integration pytorch vision models channels last cpu empowering pytorch intel xeon scalable processors bfloat fsdp api want sincerely thank dedicated community contributions summary functional module api functionally apply module computation given set parameters complex complex convolutions pytorch datapipes torchdata fully backward compatible dataloader functorch improved coverage apis nvfuser deep learning compiler pytorch changes float matrix multiplication precision ampere later cuda hardware torcharrow beta library machine learning preprocessing batch data https https pytorch org blog pytorch released https pytorch org blog pytorch released,"['n', 'pytorch', 'torcharrow', 'functional', 'api', 'modules', 'nvfuserpytorch', 'release', 'notes', 'highlights', 'backwards', 'incompatible', 'change', 'features', 'improvements', 'performance', 'documentationhighlightswe', 'excited', 'announce', 'release', 'pytorch', 'release', 'composed', 'commits', 'contributors', 'along', 'releasing', 'beta', 'versions', 'aws', 'integration', 'pytorch', 'vision', 'models', 'channels', 'last', 'cpu', 'empowering', 'pytorch', 'intel', 'xeon', 'scalable', 'processors', 'bfloat', 'fsdp', 'api', 'want', 'sincerely', 'thank', 'dedicated', 'community', 'contributions', 'summary', 'functional', 'module', 'api', 'functionally', 'apply', 'module', 'computation', 'given', 'set', 'parameters', 'complex', 'complex', 'convolutions', 'pytorch', 'datapipes', 'torchdata', 'fully', 'backward', 'compatible', 'dataloader', 'functorch', 'improved', 'coverage', 'apis', 'nvfuser', 'deep', 'learning', 'compiler', 'pytorch', 'changes', 'float', 'matrix', 'multiplication', 'precision', 'ampere', 'later', 'cuda', 'hardware', 'torcharrow', 'beta', 'library', 'machine', 'learning', 'preprocessing', 'batch', 'data', 'https', 'https', 'pytorch', 'org', 'blog', 'pytorch', 'released', 'https', 'pytorch', 'org', 'blog', 'pytorch', 'released']","['n', 'pytorch', 'torcharrow', 'function', 'api', 'modul', 'nvfuserpytorch', 'releas', 'note', 'highlight', 'backward', 'incompat', 'chang', 'featur', 'improv', 'perform', 'documentationhighlightsw', 'excit', 'announc', 'releas', 'pytorch', 'releas', 'compos', 'commit', 'contributor', 'along', 'releas', 'beta', 'version', 'aw', 'integr', 'pytorch', 'vision', 'model', 'channel', 'last', 'cpu', 'empow', 'pytorch', 'intel', 'xeon', 'scalabl', 'processor', 'bfloat', 'fsdp', 'api', 'want', 'sincer', 'thank', 'dedic', 'commun', 'contribut', 'summari', 'function', 'modul', 'api', 'function', 'appli', 'modul', 'comput', 'given', 'set', 'paramet', 'complex', 'complex', 'convolut', 'pytorch', 'datapip', 'torchdata', 'fulli', 'backward', 'compat', 'dataload', 'functorch', 'improv', 'coverag', 'api', 'nvfuser', 'deep', 'learn', 'compil', 'pytorch', 'chang', 'float', 'matrix', 'multipl', 'precis', 'amper', 'later', 'cuda', 'hardwar', 'torcharrow', 'beta', 'librari', 'machin', 'learn', 'preprocess', 'batch', 'data', 'http', 'http', 'pytorch', 'org', 'blog', 'pytorch', 'releas', 'http', 'pytorch', 'org', 'blog', 'pytorch', 'releas']"
174,188,188,AvisStudio,vn6qyt,[P] Unofficial Gato in TensorFlow,"[https://github.com/OrigamiDream/gato](https://github.com/OrigamiDream/gato)

I am building Deepmind's Gato imitation in TensorFlow.

All necessary layers have been completely implemented.

&#x200B;

However, I have no idea how to map out the **training strategy**, and I do not have enough datasets for this.

The model seems impossible for **end-to-end training** because of its conditional and selective tokenizer and embeddings, and differentiable programming.

&#x200B;

If you are interested in this project, add a **star** and **notification** to this repository for further updates.

And someone who want to contribute to this project, please create a **relevant issue** or **pull request**.

&#x200B;

Thank you.",4,15,2022-06-29 09:48:26, p  unofficial gato in tensorflow, https i am building deepmind s gato imitation in tensorflow all necessary layers have been completely implemented   xb however  i have no idea how to map out the   training strategy    and i do not have enough datasets for this the model seems impossible for   end to end training   because of its conditional and selective tokenizer and embeddings  and differentiable programming   xb if you are interested in this project  add a   star   and   notification   to this repository for further updates and someone who want to contribute to this project  please create a   relevant issue   or   pull request     xb thank you ,https building deepmind gato imitation tensorflow necessary layers completely implemented xb however idea map training strategy enough datasets model seems impossible end end training conditional selective tokenizer embeddings differentiable programming xb interested project star notification repository updates someone want contribute project please create relevant issue pull request xb thank,p unofficial gato tensorflow,p unofficial gato tensorflowhttps building deepmind gato imitation tensorflow necessary layers completely implemented xb however idea map training strategy enough datasets model seems impossible end end training conditional selective tokenizer embeddings differentiable programming xb interested project star notification repository updates someone want contribute project please create relevant issue pull request xb thank,"['p', 'unofficial', 'gato', 'tensorflowhttps', 'building', 'deepmind', 'gato', 'imitation', 'tensorflow', 'necessary', 'layers', 'completely', 'implemented', 'xb', 'however', 'idea', 'map', 'training', 'strategy', 'enough', 'datasets', 'model', 'seems', 'impossible', 'end', 'end', 'training', 'conditional', 'selective', 'tokenizer', 'embeddings', 'differentiable', 'programming', 'xb', 'interested', 'project', 'star', 'notification', 'repository', 'updates', 'someone', 'want', 'contribute', 'project', 'please', 'create', 'relevant', 'issue', 'pull', 'request', 'xb', 'thank']","['p', 'unoffici', 'gato', 'tensorflowhttp', 'build', 'deepmind', 'gato', 'imit', 'tensorflow', 'necessari', 'layer', 'complet', 'implement', 'xb', 'howev', 'idea', 'map', 'train', 'strategi', 'enough', 'dataset', 'model', 'seem', 'imposs', 'end', 'end', 'train', 'condit', 'select', 'token', 'embed', 'differenti', 'program', 'xb', 'interest', 'project', 'star', 'notif', 'repositori', 'updat', 'someon', 'want', 'contribut', 'project', 'pleas', 'creat', 'relev', 'issu', 'pull', 'request', 'xb', 'thank']"
175,189,189,bikeskata,vmr8it,[R] Probabilistic Numerics: Computation as Machine Learning (Free Book!),"Abs: Probabilistic numerical computation formalises the connection between machine learning and applied mathematics. Numerical algorithms approximate intractable quantities from computable ones. They estimate integrals from evaluations of the integrand, or the path of a dynamical system described by differential equations from evaluations of the vector field. In other words, they infer a latent quantity from data. This book shows that it is thus formally possible to think of computational routines as learning machines, and to use the notion of Bayesian inference to build more flexible, efficient, or customised algorithms for computation. The text caters for Masters' and PhD students, as well as postgraduate researchers in artificial intelligence, computer science, statistics, and applied mathematics. Extensive background material is provided along with a wealth of figures, worked examples, and exercises (with solutions) to develop intuition. 

Link to book: https://www.probabilistic-numerics.org/textbooks/",6,90,2022-06-28 21:55:51, r  probabilistic numerics  computation as machine learning  free book  ,abs  probabilistic numerical computation formalises the connection between machine learning and applied mathematics  numerical algorithms approximate intractable quantities from computable ones  they estimate integrals from evaluations of the integrand  or the path of a dynamical system described by differential equations from evaluations of the vector field  in other words  they infer a latent quantity from data  this book shows that it is thus formally possible to think of computational routines as learning machines  and to use the notion of bayesian inference to build more flexible  efficient  or customised algorithms for computation  the text caters for masters  and phd students  as well as postgraduate researchers in artificial intelligence  computer science  statistics  and applied mathematics  extensive background material is provided along with a wealth of figures  worked examples  and exercises  with solutions  to develop intuition  link to book  https   www probabilistic numerics org textbooks ,abs probabilistic numerical computation formalises connection machine learning applied mathematics numerical algorithms approximate intractable quantities computable ones estimate integrals evaluations integrand path dynamical system described differential equations evaluations vector field infer latent quantity data book shows thus formally possible think computational routines learning machines use notion bayesian inference build flexible efficient customised algorithms computation text caters masters phd students well postgraduate researchers artificial intelligence computer science statistics applied mathematics extensive background material provided along wealth figures worked examples exercises solutions develop intuition link book https www probabilistic numerics org textbooks,r probabilistic numerics computation machine learning free book,r probabilistic numerics computation machine learning free bookabs probabilistic numerical computation formalises connection machine learning applied mathematics numerical algorithms approximate intractable quantities computable ones estimate integrals evaluations integrand path dynamical system described differential equations evaluations vector field infer latent quantity data book shows thus formally possible think computational routines learning machines use notion bayesian inference build flexible efficient customised algorithms computation text caters masters phd students well postgraduate researchers artificial intelligence computer science statistics applied mathematics extensive background material provided along wealth figures worked examples exercises solutions develop intuition link book https www probabilistic numerics org textbooks,"['r', 'probabilistic', 'numerics', 'computation', 'machine', 'learning', 'free', 'bookabs', 'probabilistic', 'numerical', 'computation', 'formalises', 'connection', 'machine', 'learning', 'applied', 'mathematics', 'numerical', 'algorithms', 'approximate', 'intractable', 'quantities', 'computable', 'ones', 'estimate', 'integrals', 'evaluations', 'integrand', 'path', 'dynamical', 'system', 'described', 'differential', 'equations', 'evaluations', 'vector', 'field', 'infer', 'latent', 'quantity', 'data', 'book', 'shows', 'thus', 'formally', 'possible', 'think', 'computational', 'routines', 'learning', 'machines', 'use', 'notion', 'bayesian', 'inference', 'build', 'flexible', 'efficient', 'customised', 'algorithms', 'computation', 'text', 'caters', 'masters', 'phd', 'students', 'well', 'postgraduate', 'researchers', 'artificial', 'intelligence', 'computer', 'science', 'statistics', 'applied', 'mathematics', 'extensive', 'background', 'material', 'provided', 'along', 'wealth', 'figures', 'worked', 'examples', 'exercises', 'solutions', 'develop', 'intuition', 'link', 'book', 'https', 'www', 'probabilistic', 'numerics', 'org', 'textbooks']","['r', 'probabilist', 'numer', 'comput', 'machin', 'learn', 'free', 'bookab', 'probabilist', 'numer', 'comput', 'formalis', 'connect', 'machin', 'learn', 'appli', 'mathemat', 'numer', 'algorithm', 'approxim', 'intract', 'quantiti', 'comput', 'one', 'estim', 'integr', 'evalu', 'integrand', 'path', 'dynam', 'system', 'describ', 'differenti', 'equat', 'evalu', 'vector', 'field', 'infer', 'latent', 'quantiti', 'data', 'book', 'show', 'thu', 'formal', 'possibl', 'think', 'comput', 'routin', 'learn', 'machin', 'use', 'notion', 'bayesian', 'infer', 'build', 'flexibl', 'effici', 'customis', 'algorithm', 'comput', 'text', 'cater', 'master', 'phd', 'student', 'well', 'postgradu', 'research', 'artifici', 'intellig', 'comput', 'scienc', 'statist', 'appli', 'mathemat', 'extens', 'background', 'materi', 'provid', 'along', 'wealth', 'figur', 'work', 'exampl', 'exercis', 'solut', 'develop', 'intuit', 'link', 'book', 'http', 'www', 'probabilist', 'numer', 'org', 'textbook']"
176,190,190,antarfrica,vnewe9,[D] Training GANs with non-square images,"I am planning to train stylegan2 ada with rectangular images (aspect ratio = 16:9). Is it better to use (zero) padding, resizing, or train a rectangular GAN?
Thankyou verymuch!",2,3,2022-06-29 18:11:43, d  training gans with non square images,i am planning to train stylegan ada with rectangular images  aspect ratio       is it better to use  zero  padding  resizing  or train a rectangular gan thankyou verymuch ,planning train stylegan ada rectangular images aspect ratio better use zero padding resizing train rectangular gan thankyou verymuch,training gans non square images,training gans non square imagesplanning train stylegan ada rectangular images aspect ratio better use zero padding resizing train rectangular gan thankyou verymuch,"['training', 'gans', 'non', 'square', 'imagesplanning', 'train', 'stylegan', 'ada', 'rectangular', 'images', 'aspect', 'ratio', 'better', 'use', 'zero', 'padding', 'resizing', 'train', 'rectangular', 'gan', 'thankyou', 'verymuch']","['train', 'gan', 'non', 'squar', 'imagesplan', 'train', 'stylegan', 'ada', 'rectangular', 'imag', 'aspect', 'ratio', 'better', 'use', 'zero', 'pad', 'resiz', 'train', 'rectangular', 'gan', 'thankyou', 'verymuch']"
177,192,192,ml_rl_questions,vnbuq5,[R] Use pretrained GANs and image classifier to generate images of the class,"Pretrained GANs and CLIP embeddings have been used to created images from arbitrary caption, by backpropagating CLIP similarity of the caption and the generated image down to the generator input noise.

I am thinking of something simpler, where I would take a pretrained GAN, and backpropagate through some pretrained classifier (e.g. image et) down to the input noise to the Generator to generate images of that class.

Is there any reference that does that?

And more generally, i want to understand why this approach works - simple backpropagating the classifier loss to the image (and not through the generator) typically result in deep dream type of weird images. Why does this not happen when using a generator? Is it simply because the output of the generator lives in the manifold of ""real"" images? Is there more to  it?

Thanks in advance",1,3,2022-06-29 15:12:26, r  use pretrained gans and image classifier to generate images of the class,pretrained gans and clip embeddings have been used to created images from arbitrary caption  by backpropagating clip similarity of the caption and the generated image down to the generator input noise i am thinking of something simpler  where i would take a pretrained gan  and backpropagate through some pretrained classifier  e g  image et  down to the input noise to the generator to generate images of that class is there any reference that does that and more generally  i want to understand why this approach works   simple backpropagating the classifier loss to the image  and not through the generator  typically result in deep dream type of weird images  why does this not happen when using a generator  is it simply because the output of the generator lives in the manifold of real images  is there more to  it thanks in advance,pretrained gans clip embeddings used created images arbitrary caption backpropagating clip similarity caption generated image generator input noise thinking something simpler would take pretrained gan backpropagate pretrained classifier e g image et input noise generator generate images class reference generally want understand approach works simple backpropagating classifier loss image generator typically result deep dream type weird images happen using generator simply output generator lives manifold real images thanks advance,r use pretrained gans image classifier generate images class,r use pretrained gans image classifier generate images classpretrained gans clip embeddings used created images arbitrary caption backpropagating clip similarity caption generated image generator input noise thinking something simpler would take pretrained gan backpropagate pretrained classifier e g image et input noise generator generate images class reference generally want understand approach works simple backpropagating classifier loss image generator typically result deep dream type weird images happen using generator simply output generator lives manifold real images thanks advance,"['r', 'use', 'pretrained', 'gans', 'image', 'classifier', 'generate', 'images', 'classpretrained', 'gans', 'clip', 'embeddings', 'used', 'created', 'images', 'arbitrary', 'caption', 'backpropagating', 'clip', 'similarity', 'caption', 'generated', 'image', 'generator', 'input', 'noise', 'thinking', 'something', 'simpler', 'would', 'take', 'pretrained', 'gan', 'backpropagate', 'pretrained', 'classifier', 'e', 'g', 'image', 'et', 'input', 'noise', 'generator', 'generate', 'images', 'class', 'reference', 'generally', 'want', 'understand', 'approach', 'works', 'simple', 'backpropagating', 'classifier', 'loss', 'image', 'generator', 'typically', 'result', 'deep', 'dream', 'type', 'weird', 'images', 'happen', 'using', 'generator', 'simply', 'output', 'generator', 'lives', 'manifold', 'real', 'images', 'thanks', 'advance']","['r', 'use', 'pretrain', 'gan', 'imag', 'classifi', 'gener', 'imag', 'classpretrain', 'gan', 'clip', 'embed', 'use', 'creat', 'imag', 'arbitrari', 'caption', 'backpropag', 'clip', 'similar', 'caption', 'gener', 'imag', 'gener', 'input', 'nois', 'think', 'someth', 'simpler', 'would', 'take', 'pretrain', 'gan', 'backpropag', 'pretrain', 'classifi', 'e', 'g', 'imag', 'et', 'input', 'nois', 'gener', 'gener', 'imag', 'class', 'refer', 'gener', 'want', 'understand', 'approach', 'work', 'simpl', 'backpropag', 'classifi', 'loss', 'imag', 'gener', 'typic', 'result', 'deep', 'dream', 'type', 'weird', 'imag', 'happen', 'use', 'gener', 'simpli', 'output', 'gener', 'live', 'manifold', 'real', 'imag', 'thank', 'advanc']"
178,193,193,BB4evaTB12,vmyrd1,Creating and Analyzing a Dataset of Roe v. Wade Tweets Labeled by Abortion Stance [P],"How do pro-choice vs. pro-life twitter users differ?

I built a free, labeled dataset of #RoeVsWade tweets, and an ML classifier on top.

Some insights:

Pro-life users are 20.4x more likely to put ""christ"" and 16.1x more likely to put ""maga"" in their bio.Pro-choice users are 7.5x more likely to put ""blm"" and 6.5x more likely to put ""she/her"".

Full analysis + link to raw dataset [here](https://www.surgehq.ai/blog/dataset-of-roe-v-wade-tweets-labeled-by-abortion-stance).",4,26,2022-06-29 03:14:35,creating and analyzing a dataset of roe v  wade tweets labeled by abortion stance  p ,how do pro choice vs  pro life twitter users differ i built a free  labeled dataset of  roevswade tweets  and an ml classifier on top some insights pro life users are  x more likely to put christ and  x more likely to put maga in their bio pro choice users are  x more likely to put blm and  x more likely to put she her full analysis   link to raw dataset  here  https   www surgehq ai blog dataset of roe v wade tweets labeled by abortion stance  ,pro choice vs pro life twitter users differ built free labeled dataset roevswade tweets ml classifier top insights pro life users x likely put christ x likely put maga bio pro choice users x likely put blm x likely put full analysis link raw dataset https www surgehq ai blog dataset roe v wade tweets labeled abortion stance,creating analyzing dataset roe v wade tweets labeled abortion stance p,creating analyzing dataset roe v wade tweets labeled abortion stance ppro choice vs pro life twitter users differ built free labeled dataset roevswade tweets ml classifier top insights pro life users x likely put christ x likely put maga bio pro choice users x likely put blm x likely put full analysis link raw dataset https www surgehq ai blog dataset roe v wade tweets labeled abortion stance,"['creating', 'analyzing', 'dataset', 'roe', 'v', 'wade', 'tweets', 'labeled', 'abortion', 'stance', 'ppro', 'choice', 'vs', 'pro', 'life', 'twitter', 'users', 'differ', 'built', 'free', 'labeled', 'dataset', 'roevswade', 'tweets', 'ml', 'classifier', 'top', 'insights', 'pro', 'life', 'users', 'x', 'likely', 'put', 'christ', 'x', 'likely', 'put', 'maga', 'bio', 'pro', 'choice', 'users', 'x', 'likely', 'put', 'blm', 'x', 'likely', 'put', 'full', 'analysis', 'link', 'raw', 'dataset', 'https', 'www', 'surgehq', 'ai', 'blog', 'dataset', 'roe', 'v', 'wade', 'tweets', 'labeled', 'abortion', 'stance']","['creat', 'analyz', 'dataset', 'roe', 'v', 'wade', 'tweet', 'label', 'abort', 'stanc', 'ppro', 'choic', 'vs', 'pro', 'life', 'twitter', 'user', 'differ', 'built', 'free', 'label', 'dataset', 'roevswad', 'tweet', 'ml', 'classifi', 'top', 'insight', 'pro', 'life', 'user', 'x', 'like', 'put', 'christ', 'x', 'like', 'put', 'maga', 'bio', 'pro', 'choic', 'user', 'x', 'like', 'put', 'blm', 'x', 'like', 'put', 'full', 'analysi', 'link', 'raw', 'dataset', 'http', 'www', 'surgehq', 'ai', 'blog', 'dataset', 'roe', 'v', 'wade', 'tweet', 'label', 'abort', 'stanc']"
179,194,194,devzaya,vmn7nt,"[N] Quaterion, a blazingly fast framework for similarity learning.","Just released. Quaterion — an open source framework for training and fine-tuning similarity learning models. It enables you to train models significantly (100x) faster, and iterate over experiments in minutes instead of hours even with a laptop GPU. It takes advantage of the PyTorch Lightning backend to make a flexible and scalable learning pipeline. GitHub https://github.com/qdrant/quaterion 

Here is a demo of the caching functionality.  

https://i.redd.it/9qi8gf9n4d891.gif",11,98,2022-06-28 18:53:52, n  quaterion  a blazingly fast framework for similarity learning ,just released  quaterion   an open source framework for training and fine tuning similarity learning models  it enables you to train models significantly  x  faster  and iterate over experiments in minutes instead of hours even with a laptop gpu  it takes advantage of the pytorch lightning backend to make a flexible and scalable learning pipeline  github https here is a demo of the caching functionality   https   i redd it qigfnd gif,released quaterion open source framework training fine tuning similarity learning models enables train models significantly x faster iterate experiments minutes instead hours even laptop gpu takes advantage pytorch lightning backend make flexible scalable learning pipeline github https demo caching functionality https redd qigfnd gif,n quaterion blazingly fast framework similarity learning,n quaterion blazingly fast framework similarity learningreleased quaterion open source framework training fine tuning similarity learning models enables train models significantly x faster iterate experiments minutes instead hours even laptop gpu takes advantage pytorch lightning backend make flexible scalable learning pipeline github https demo caching functionality https redd qigfnd gif,"['n', 'quaterion', 'blazingly', 'fast', 'framework', 'similarity', 'learningreleased', 'quaterion', 'open', 'source', 'framework', 'training', 'fine', 'tuning', 'similarity', 'learning', 'models', 'enables', 'train', 'models', 'significantly', 'x', 'faster', 'iterate', 'experiments', 'minutes', 'instead', 'hours', 'even', 'laptop', 'gpu', 'takes', 'advantage', 'pytorch', 'lightning', 'backend', 'make', 'flexible', 'scalable', 'learning', 'pipeline', 'github', 'https', 'demo', 'caching', 'functionality', 'https', 'redd', 'qigfnd', 'gif']","['n', 'quaterion', 'blazingli', 'fast', 'framework', 'similar', 'learningreleas', 'quaterion', 'open', 'sourc', 'framework', 'train', 'fine', 'tune', 'similar', 'learn', 'model', 'enabl', 'train', 'model', 'significantli', 'x', 'faster', 'iter', 'experi', 'minut', 'instead', 'hour', 'even', 'laptop', 'gpu', 'take', 'advantag', 'pytorch', 'lightn', 'backend', 'make', 'flexibl', 'scalabl', 'learn', 'pipelin', 'github', 'http', 'demo', 'cach', 'function', 'http', 'redd', 'qigfnd', 'gif']"
180,195,195,metover,vnaj09,[D] What are the lessons learned in the preparations of the dataset you will use to train a GANs?,"Hello friends, what are the key points we should pay attention to in the datasets you will prepare for GANs, do you have any suggestions?

For example the distribution of the dataset should be like this, the images should be the same size, it is important to reduce all the images to this size, many things that I have not thought of at the moment? What are your recommendations?",0,3,2022-06-29 13:39:51, d  what are the lessons learned in the preparations of the dataset you will use to train a gans ,hello friends  what are the key points we should pay attention to in the datasets you will prepare for gans  do you have any suggestions for example the distribution of the dataset should be like this  the images should be the same size  it is important to reduce all the images to this size  many things that i have not thought of at the moment  what are your recommendations ,hello friends key points pay attention datasets prepare gans suggestions example distribution dataset like images size important reduce images size many things thought moment recommendations,lessons learned preparations dataset use train gans,lessons learned preparations dataset use train ganshello friends key points pay attention datasets prepare gans suggestions example distribution dataset like images size important reduce images size many things thought moment recommendations,"['lessons', 'learned', 'preparations', 'dataset', 'use', 'train', 'ganshello', 'friends', 'key', 'points', 'pay', 'attention', 'datasets', 'prepare', 'gans', 'suggestions', 'example', 'distribution', 'dataset', 'like', 'images', 'size', 'important', 'reduce', 'images', 'size', 'many', 'things', 'thought', 'moment', 'recommendations']","['lesson', 'learn', 'prepar', 'dataset', 'use', 'train', 'ganshello', 'friend', 'key', 'point', 'pay', 'attent', 'dataset', 'prepar', 'gan', 'suggest', 'exampl', 'distribut', 'dataset', 'like', 'imag', 'size', 'import', 'reduc', 'imag', 'size', 'mani', 'thing', 'thought', 'moment', 'recommend']"
181,196,196,nyxrat,vnc953,[D] AI & Big Data Expo; worth it?,"Interested in AI/Machine learning research, hoping to check out their NA expo to learn more. Has anyone here ever been to one of their conventions? What were your experiences like?",2,0,2022-06-29 15:37:59, d  ai   big data expo  worth it ,interested in ai machine learning research  hoping to check out their na expo to learn more  has anyone here ever been to one of their conventions  what were your experiences like ,interested ai machine learning research hoping check na expo learn anyone ever one conventions experiences like,ai big data expo worth,ai big data expo worthinterested ai machine learning research hoping check na expo learn anyone ever one conventions experiences like,"['ai', 'big', 'data', 'expo', 'worthinterested', 'ai', 'machine', 'learning', 'research', 'hoping', 'check', 'na', 'expo', 'learn', 'anyone', 'ever', 'one', 'conventions', 'experiences', 'like']","['ai', 'big', 'data', 'expo', 'worthinterest', 'ai', 'machin', 'learn', 'research', 'hope', 'check', 'na', 'expo', 'learn', 'anyon', 'ever', 'one', 'convent', 'experi', 'like']"
182,197,197,M4mb0,vml5na,[N] PyTorch 1.12 released,"Pytorch 1.12 is available through the [pytorch conda channel](https://anaconda.org/pytorch/pytorch) and [pypi](https://pypi.org/project/torch/)

- [Release notes](https://github.com/pytorch/pytorch/releases)
- [Issue tracker](https://github.com/pytorch/pytorch/milestone/28)


## Highlights

> We are excited to announce the release of PyTorch 1.12! This release is composed of over 3124 commits, 433 contributors. Along with 1.12, we are releasing beta versions of AWS S3 Integration, PyTorch Vision Models on Channels Last on CPU, Empowering PyTorch on Intel® Xeon® Scalable processors with Bfloat16 and FSDP API. We want to sincerely thank our dedicated community for your contributions.

> Summary:

>  -  Functional Module API to functionally apply module computation with a given set of parameters
>  -  Complex32 and Complex Convolutions in PyTorch
>  -  DataPipes from TorchData fully backward compatible with DataLoader
>  -  Functorch with improved coverage for APIs
>  -  nvFuser a deep learning compiler for PyTorch
>  -  Changes to float32 matrix multiplication precision on Ampere and later CUDA hardware
>  -  TorchArrow, a new beta library for machine learning preprocessing over batch data


## Other noteable changes

- CUDA 11.6 wheels
- [torch.amp](https://pytorch.org/docs/1.12/amp.html) module",0,42,2022-06-28 17:07:42, n  pytorch   released,pytorch   is available through the  pytorch conda channel  https    release notes  https    issue tracker  https    highlights  we are excited to announce the release of pytorch    this release is composed of over  commits   contributors  along with    we are releasing beta versions of aws s integration  pytorch vision models on channels last on cpu  empowering pytorch on intel  xeon  scalable processors with bfloat and fsdp api  we want to sincerely thank our dedicated community for your contributions   summary       functional module api to functionally apply module computation with a given set of parameters      complex and complex convolutions in pytorch      datapipes from torchdata fully backward compatible with dataloader      functorch with improved coverage for apis      nvfuser a deep learning compiler for pytorch      changes to float matrix multiplication precision on ampere and later cuda hardware      torcharrow  a new beta library for machine learning preprocessing over batch data   other noteable changes  cuda   wheels   torch amp  https   pytorch org docs   amp html  module,pytorch available pytorch conda channel https release notes https issue tracker https highlights excited announce release pytorch release composed commits contributors along releasing beta versions aws integration pytorch vision models channels last cpu empowering pytorch intel xeon scalable processors bfloat fsdp api want sincerely thank dedicated community contributions summary functional module api functionally apply module computation given set parameters complex complex convolutions pytorch datapipes torchdata fully backward compatible dataloader functorch improved coverage apis nvfuser deep learning compiler pytorch changes float matrix multiplication precision ampere later cuda hardware torcharrow beta library machine learning preprocessing batch data noteable changes cuda wheels torch amp https pytorch org docs amp html module,n pytorch released,n pytorch releasedpytorch available pytorch conda channel https release notes https issue tracker https highlights excited announce release pytorch release composed commits contributors along releasing beta versions aws integration pytorch vision models channels last cpu empowering pytorch intel xeon scalable processors bfloat fsdp api want sincerely thank dedicated community contributions summary functional module api functionally apply module computation given set parameters complex complex convolutions pytorch datapipes torchdata fully backward compatible dataloader functorch improved coverage apis nvfuser deep learning compiler pytorch changes float matrix multiplication precision ampere later cuda hardware torcharrow beta library machine learning preprocessing batch data noteable changes cuda wheels torch amp https pytorch org docs amp html module,"['n', 'pytorch', 'releasedpytorch', 'available', 'pytorch', 'conda', 'channel', 'https', 'release', 'notes', 'https', 'issue', 'tracker', 'https', 'highlights', 'excited', 'announce', 'release', 'pytorch', 'release', 'composed', 'commits', 'contributors', 'along', 'releasing', 'beta', 'versions', 'aws', 'integration', 'pytorch', 'vision', 'models', 'channels', 'last', 'cpu', 'empowering', 'pytorch', 'intel', 'xeon', 'scalable', 'processors', 'bfloat', 'fsdp', 'api', 'want', 'sincerely', 'thank', 'dedicated', 'community', 'contributions', 'summary', 'functional', 'module', 'api', 'functionally', 'apply', 'module', 'computation', 'given', 'set', 'parameters', 'complex', 'complex', 'convolutions', 'pytorch', 'datapipes', 'torchdata', 'fully', 'backward', 'compatible', 'dataloader', 'functorch', 'improved', 'coverage', 'apis', 'nvfuser', 'deep', 'learning', 'compiler', 'pytorch', 'changes', 'float', 'matrix', 'multiplication', 'precision', 'ampere', 'later', 'cuda', 'hardware', 'torcharrow', 'beta', 'library', 'machine', 'learning', 'preprocessing', 'batch', 'data', 'noteable', 'changes', 'cuda', 'wheels', 'torch', 'amp', 'https', 'pytorch', 'org', 'docs', 'amp', 'html', 'module']","['n', 'pytorch', 'releasedpytorch', 'avail', 'pytorch', 'conda', 'channel', 'http', 'releas', 'note', 'http', 'issu', 'tracker', 'http', 'highlight', 'excit', 'announc', 'releas', 'pytorch', 'releas', 'compos', 'commit', 'contributor', 'along', 'releas', 'beta', 'version', 'aw', 'integr', 'pytorch', 'vision', 'model', 'channel', 'last', 'cpu', 'empow', 'pytorch', 'intel', 'xeon', 'scalabl', 'processor', 'bfloat', 'fsdp', 'api', 'want', 'sincer', 'thank', 'dedic', 'commun', 'contribut', 'summari', 'function', 'modul', 'api', 'function', 'appli', 'modul', 'comput', 'given', 'set', 'paramet', 'complex', 'complex', 'convolut', 'pytorch', 'datapip', 'torchdata', 'fulli', 'backward', 'compat', 'dataload', 'functorch', 'improv', 'coverag', 'api', 'nvfuser', 'deep', 'learn', 'compil', 'pytorch', 'chang', 'float', 'matrix', 'multipl', 'precis', 'amper', 'later', 'cuda', 'hardwar', 'torcharrow', 'beta', 'librari', 'machin', 'learn', 'preprocess', 'batch', 'data', 'noteabl', 'chang', 'cuda', 'wheel', 'torch', 'amp', 'http', 'pytorch', 'org', 'doc', 'amp', 'html', 'modul']"
183,198,198,Mon0o0,vn2hin,What is the essence of Diffusion models? [D],"Coming from a math/stats background the point of much of the machine learning literature can take time to understand fully, in particular I have a couple of quick (interconnected) questions regarding the essence of Diffusion models that I hope somebody may answer (of the many blog posts I have read I can't seem to find a clear answer). 
      
As a reference let me take the seminal paper of Ho et al. https://arxiv.org/abs/2006.11239
     

* When fixing the coefficients $\beta_1, \dots, \beta_T$ that govern the forward diffusion process (treating them as hyperparameters) can't we, at least in simple cases, already recover the reverse diffusion process in closed form? If yes why do we even need to find the reverse diffusion process through an optimization procedure when we already have it in closed form?


* I have read that diffusion models should perform a dimensionality reduction on the data but, even understanding the mathematics, I can't understand how the dimensionality reduction is being achieved by learning the reverse process. What is the usefulness behind the whole procedure?      

* If the forward process converges to an isotropic Gaussian (it destroys all the structure in the data) how can we hope to learn anything significant from it if it becomes simply a bunch of noise. (I suspect that the answer to this question is that we always stop the forward process before it becomes its limit)

Thanks to anyone that can clear up these doubts of mine.",6,3,2022-06-29 06:12:14,what is the essence of diffusion models   d ,coming from a math stats background the point of much of the machine learning literature can take time to understand fully  in particular i have a couple of quick  interconnected  questions regarding the essence of diffusion models that i hope somebody may answer  of the many blog posts i have read i can t seem to find a clear answer         as a reference let me take the seminal paper of ho et al  https        when fixing the coefficients   beta_   dots   beta_t  that govern the forward diffusion process  treating them as hyperparameters  can t we  at least in simple cases  already recover the reverse diffusion process in closed form  if yes why do we even need to find the reverse diffusion process through an optimization procedure when we already have it in closed form   i have read that diffusion models should perform a dimensionality reduction on the data but  even understanding the mathematics  i can t understand how the dimensionality reduction is being achieved by learning the reverse process  what is the usefulness behind the whole procedure         if the forward process converges to an isotropic gaussian  it destroys all the structure in the data  how can we hope to learn anything significant from it if it becomes simply a bunch of noise   i suspect that the answer to this question is that we always stop the forward process before it becomes its limit thanks to anyone that can clear up these doubts of mine ,coming math stats background point much machine learning literature take time understand fully particular couple quick interconnected questions regarding essence diffusion models hope somebody may answer many blog posts read seem find clear answer reference let take seminal paper ho et al https fixing coefficients beta_ dots beta_t govern forward diffusion process treating hyperparameters least simple cases already recover reverse diffusion process closed form yes even need find reverse diffusion process optimization procedure already closed form read diffusion models perform dimensionality reduction data even understanding mathematics understand dimensionality reduction achieved learning reverse process usefulness behind whole procedure forward process converges isotropic gaussian destroys structure data hope learn anything significant becomes simply bunch noise suspect answer question always stop forward process becomes limit thanks anyone clear doubts mine,essence diffusion models,essence diffusion modelscoming math stats background point much machine learning literature take time understand fully particular couple quick interconnected questions regarding essence diffusion models hope somebody may answer many blog posts read seem find clear answer reference let take seminal paper ho et al https fixing coefficients beta_ dots beta_t govern forward diffusion process treating hyperparameters least simple cases already recover reverse diffusion process closed form yes even need find reverse diffusion process optimization procedure already closed form read diffusion models perform dimensionality reduction data even understanding mathematics understand dimensionality reduction achieved learning reverse process usefulness behind whole procedure forward process converges isotropic gaussian destroys structure data hope learn anything significant becomes simply bunch noise suspect answer question always stop forward process becomes limit thanks anyone clear doubts mine,"['essence', 'diffusion', 'modelscoming', 'math', 'stats', 'background', 'point', 'much', 'machine', 'learning', 'literature', 'take', 'time', 'understand', 'fully', 'particular', 'couple', 'quick', 'interconnected', 'questions', 'regarding', 'essence', 'diffusion', 'models', 'hope', 'somebody', 'may', 'answer', 'many', 'blog', 'posts', 'read', 'seem', 'find', 'clear', 'answer', 'reference', 'let', 'take', 'seminal', 'paper', 'ho', 'et', 'al', 'https', 'fixing', 'coefficients', 'beta_', 'dots', 'beta_t', 'govern', 'forward', 'diffusion', 'process', 'treating', 'hyperparameters', 'least', 'simple', 'cases', 'already', 'recover', 'reverse', 'diffusion', 'process', 'closed', 'form', 'yes', 'even', 'need', 'find', 'reverse', 'diffusion', 'process', 'optimization', 'procedure', 'already', 'closed', 'form', 'read', 'diffusion', 'models', 'perform', 'dimensionality', 'reduction', 'data', 'even', 'understanding', 'mathematics', 'understand', 'dimensionality', 'reduction', 'achieved', 'learning', 'reverse', 'process', 'usefulness', 'behind', 'whole', 'procedure', 'forward', 'process', 'converges', 'isotropic', 'gaussian', 'destroys', 'structure', 'data', 'hope', 'learn', 'anything', 'significant', 'becomes', 'simply', 'bunch', 'noise', 'suspect', 'answer', 'question', 'always', 'stop', 'forward', 'process', 'becomes', 'limit', 'thanks', 'anyone', 'clear', 'doubts', 'mine']","['essenc', 'diffus', 'modelscom', 'math', 'stat', 'background', 'point', 'much', 'machin', 'learn', 'literatur', 'take', 'time', 'understand', 'fulli', 'particular', 'coupl', 'quick', 'interconnect', 'question', 'regard', 'essenc', 'diffus', 'model', 'hope', 'somebodi', 'may', 'answer', 'mani', 'blog', 'post', 'read', 'seem', 'find', 'clear', 'answer', 'refer', 'let', 'take', 'semin', 'paper', 'ho', 'et', 'al', 'http', 'fix', 'coeffici', 'beta_', 'dot', 'beta_t', 'govern', 'forward', 'diffus', 'process', 'treat', 'hyperparamet', 'least', 'simpl', 'case', 'alreadi', 'recov', 'revers', 'diffus', 'process', 'close', 'form', 'ye', 'even', 'need', 'find', 'revers', 'diffus', 'process', 'optim', 'procedur', 'alreadi', 'close', 'form', 'read', 'diffus', 'model', 'perform', 'dimension', 'reduct', 'data', 'even', 'understand', 'mathemat', 'understand', 'dimension', 'reduct', 'achiev', 'learn', 'revers', 'process', 'use', 'behind', 'whole', 'procedur', 'forward', 'process', 'converg', 'isotrop', 'gaussian', 'destroy', 'structur', 'data', 'hope', 'learn', 'anyth', 'signific', 'becom', 'simpli', 'bunch', 'nois', 'suspect', 'answer', 'question', 'alway', 'stop', 'forward', 'process', 'becom', 'limit', 'thank', 'anyon', 'clear', 'doubt', 'mine']"
184,199,199,ben_cow,vmv54i,[D] [P] Questions about the usability of Shapley values on large feature spaces.," 

Hello! I am planning a research project which involves creating a classification DNN that takes in a frame from a molecular dynamics simulation of a protein which encodes each amino acid's  level of energetic interaction and tries to predict whether that frame came from protein state ""A"" or protein state ""B.""  I want to analyze the feature importance, that is, the importance of amino acid's energetic interaction level for making the classification prediction. Although I have heard some interesting applications with Shapley values to preform such an analysis on feature importance, the input layer structure of the model I am thinking of making would require 100+ neurons as there are 100+ features. The reason why the feature space is so large is because I am investigating how a model learns which amino acids are most important for the model to make a classification prediction for which state a protein is in where the protein is 100+ amino acids in length. Can Shapley methods handle a feature space of a model that large /would the computational cost of such a process be infeasible? Apologies if this question is a little unclear let me know if anything needs to be clarified.

Thanks!",0,6,2022-06-29 00:39:05, d   p  questions about the usability of shapley values on large feature spaces , hello  i am planning a research project which involves creating a classification dnn that takes in a frame from a molecular dynamics simulation of a protein which encodes each amino acid s  level of energetic interaction and tries to predict whether that frame came from protein state a or protein state b   i want to analyze the feature importance  that is  the importance of amino acid s energetic interaction level for making the classification prediction  although i have heard some interesting applications with shapley values to preform such an analysis on feature importance  the input layer structure of the model i am thinking of making would require   neurons as there are   features  the reason why the feature space is so large is because i am investigating how a model learns which amino acids are most important for the model to make a classification prediction for which state a protein is in where the protein is   amino acids in length  can shapley methods handle a feature space of a model that large  would the computational cost of such a process be infeasible  apologies if this question is a little unclear let me know if anything needs to be clarified thanks ,hello planning research project involves creating classification dnn takes frame molecular dynamics simulation protein encodes amino acid level energetic interaction tries predict whether frame came protein state protein state b want analyze feature importance importance amino acid energetic interaction level making classification prediction although heard interesting applications shapley values preform analysis feature importance input layer structure model thinking making would require neurons features reason feature space large investigating model learns amino acids important model make classification prediction state protein protein amino acids length shapley methods handle feature space model large would computational cost process infeasible apologies question little unclear let know anything needs clarified thanks,p questions usability shapley values large feature spaces,p questions usability shapley values large feature spaceshello planning research project involves creating classification dnn takes frame molecular dynamics simulation protein encodes amino acid level energetic interaction tries predict whether frame came protein state protein state b want analyze feature importance importance amino acid energetic interaction level making classification prediction although heard interesting applications shapley values preform analysis feature importance input layer structure model thinking making would require neurons features reason feature space large investigating model learns amino acids important model make classification prediction state protein protein amino acids length shapley methods handle feature space model large would computational cost process infeasible apologies question little unclear let know anything needs clarified thanks,"['p', 'questions', 'usability', 'shapley', 'values', 'large', 'feature', 'spaceshello', 'planning', 'research', 'project', 'involves', 'creating', 'classification', 'dnn', 'takes', 'frame', 'molecular', 'dynamics', 'simulation', 'protein', 'encodes', 'amino', 'acid', 'level', 'energetic', 'interaction', 'tries', 'predict', 'whether', 'frame', 'came', 'protein', 'state', 'protein', 'state', 'b', 'want', 'analyze', 'feature', 'importance', 'importance', 'amino', 'acid', 'energetic', 'interaction', 'level', 'making', 'classification', 'prediction', 'although', 'heard', 'interesting', 'applications', 'shapley', 'values', 'preform', 'analysis', 'feature', 'importance', 'input', 'layer', 'structure', 'model', 'thinking', 'making', 'would', 'require', 'neurons', 'features', 'reason', 'feature', 'space', 'large', 'investigating', 'model', 'learns', 'amino', 'acids', 'important', 'model', 'make', 'classification', 'prediction', 'state', 'protein', 'protein', 'amino', 'acids', 'length', 'shapley', 'methods', 'handle', 'feature', 'space', 'model', 'large', 'would', 'computational', 'cost', 'process', 'infeasible', 'apologies', 'question', 'little', 'unclear', 'let', 'know', 'anything', 'needs', 'clarified', 'thanks']","['p', 'question', 'usabl', 'shapley', 'valu', 'larg', 'featur', 'spaceshello', 'plan', 'research', 'project', 'involv', 'creat', 'classif', 'dnn', 'take', 'frame', 'molecular', 'dynam', 'simul', 'protein', 'encod', 'amino', 'acid', 'level', 'energet', 'interact', 'tri', 'predict', 'whether', 'frame', 'came', 'protein', 'state', 'protein', 'state', 'b', 'want', 'analyz', 'featur', 'import', 'import', 'amino', 'acid', 'energet', 'interact', 'level', 'make', 'classif', 'predict', 'although', 'heard', 'interest', 'applic', 'shapley', 'valu', 'preform', 'analysi', 'featur', 'import', 'input', 'layer', 'structur', 'model', 'think', 'make', 'would', 'requir', 'neuron', 'featur', 'reason', 'featur', 'space', 'larg', 'investig', 'model', 'learn', 'amino', 'acid', 'import', 'model', 'make', 'classif', 'predict', 'state', 'protein', 'protein', 'amino', 'acid', 'length', 'shapley', 'method', 'handl', 'featur', 'space', 'model', 'larg', 'would', 'comput', 'cost', 'process', 'infeas', 'apolog', 'question', 'littl', 'unclear', 'let', 'know', 'anyth', 'need', 'clarifi', 'thank']"
185,200,200,InternationalVisito,vml9we,[D]Can a transformer neural network learn to predict sequences longer than it saw?," Simple task: transformer has to repeat a sequence of random integers (0-9) of varied length, like:

sequence **length=7**: input\[ 1, 3 ,5 ,6, 2, 4, 0\] - output\[ 1, 3 ,5 ,6, 2, 4, 0\]  
sequence **length=3**: input\[ 5, 4 ,9 \] - output\[ 5, 4 ,9 \]  
sequence **length=4**: input\[ 6, 3 ,9, 8 \] - output\[ 6, 3 ,9, 8 \]  
...  
Each integer(0-9) can be stored in embedding layer so we can pass it to transformer.  
I trained transformer (generic pytorch model with positional embeddings) on a dataset (1000 examples) of sequences of varied length (1 to 12) and it predicts sequences well within the range of 12 . It fails to predict sequences longer than 12 - 13.  


sequence **length=20**: input\[3, 3, 4, 0, 0, 7, 1, 5, 1, 0, 7, 1, ***9, 0, 9, 1, 5, 2, 3, 6***\]  
.............................. ...- output\[3, 3, 4, 0, 0, 7, 1, 5, 1, 0, 7, 1, ***7, 1, 7, 1, 0, 7, 0, 7***\]

Is it considered an extrapolation task? Are there types of transformers (or other neural networks) that can handle the problem ?  
Same issue with **recurrent neural networks** (RNN, LSTM, GRU).",31,16,2022-06-28 17:14:14, d can a transformer neural network learn to predict sequences longer than it saw , simple task  transformer has to repeat a sequence of random integers     of varied length  like sequence   length     input                    output                   sequence   length     input             output            sequence   length     input               output                   each integer    can be stored in embedding layer so we can pass it to transformer   i trained transformer  generic pytorch model with positional embeddings  on a dataset   examples  of sequences of varied length   to   and it predicts sequences well within the range of    it fails to predict sequences longer than       sequence   length     input                                                                                      output                                                is it considered an extrapolation task  are there types of transformers  or other neural networks  that can handle the problem    same issue with   recurrent neural networks    rnn  lstm  gru  ,simple task transformer repeat sequence random integers varied length like sequence length input output sequence length input output sequence length input output integer stored embedding layer pass transformer trained transformer generic pytorch model positional embeddings dataset examples sequences varied length predicts sequences well within range fails predict sequences longer sequence length input output considered extrapolation task types transformers neural networks handle problem issue recurrent neural networks rnn lstm gru,transformer neural network learn predict sequences longer saw,transformer neural network learn predict sequences longer sawsimple task transformer repeat sequence random integers varied length like sequence length input output sequence length input output sequence length input output integer stored embedding layer pass transformer trained transformer generic pytorch model positional embeddings dataset examples sequences varied length predicts sequences well within range fails predict sequences longer sequence length input output considered extrapolation task types transformers neural networks handle problem issue recurrent neural networks rnn lstm gru,"['transformer', 'neural', 'network', 'learn', 'predict', 'sequences', 'longer', 'sawsimple', 'task', 'transformer', 'repeat', 'sequence', 'random', 'integers', 'varied', 'length', 'like', 'sequence', 'length', 'input', 'output', 'sequence', 'length', 'input', 'output', 'sequence', 'length', 'input', 'output', 'integer', 'stored', 'embedding', 'layer', 'pass', 'transformer', 'trained', 'transformer', 'generic', 'pytorch', 'model', 'positional', 'embeddings', 'dataset', 'examples', 'sequences', 'varied', 'length', 'predicts', 'sequences', 'well', 'within', 'range', 'fails', 'predict', 'sequences', 'longer', 'sequence', 'length', 'input', 'output', 'considered', 'extrapolation', 'task', 'types', 'transformers', 'neural', 'networks', 'handle', 'problem', 'issue', 'recurrent', 'neural', 'networks', 'rnn', 'lstm', 'gru']","['transform', 'neural', 'network', 'learn', 'predict', 'sequenc', 'longer', 'sawsimpl', 'task', 'transform', 'repeat', 'sequenc', 'random', 'integ', 'vari', 'length', 'like', 'sequenc', 'length', 'input', 'output', 'sequenc', 'length', 'input', 'output', 'sequenc', 'length', 'input', 'output', 'integ', 'store', 'embed', 'layer', 'pass', 'transform', 'train', 'transform', 'gener', 'pytorch', 'model', 'posit', 'embed', 'dataset', 'exampl', 'sequenc', 'vari', 'length', 'predict', 'sequenc', 'well', 'within', 'rang', 'fail', 'predict', 'sequenc', 'longer', 'sequenc', 'length', 'input', 'output', 'consid', 'extrapol', 'task', 'type', 'transform', 'neural', 'network', 'handl', 'problem', 'issu', 'recurr', 'neural', 'network', 'rnn', 'lstm', 'gru']"
186,201,201,BlockDesigns,vmpenb,[P] Clustering long documents with Transformers in 10 minutes,"Transformers are awesome for so many things in 2022, but one thing I've found them to struggle with is generating embeddings for long documents.

I put together a blog post going through some interesting techniques. Let me know if it helped you!

[Blog post](https://www.notia.ai/articles/clustering-long-documents)",0,8,2022-06-28 20:35:39, p  clustering long documents with transformers in  minutes,transformers are awesome for so many things in   but one thing i ve found them to struggle with is generating embeddings for long documents i put together a blog post going through some interesting techniques  let me know if it helped you  blog post  https   www notia ai articles clustering long documents ,transformers awesome many things one thing found struggle generating embeddings long documents put together blog post going interesting techniques let know helped blog post https www notia ai articles clustering long documents,p clustering long documents transformers minutes,p clustering long documents transformers minutestransformers awesome many things one thing found struggle generating embeddings long documents put together blog post going interesting techniques let know helped blog post https www notia ai articles clustering long documents,"['p', 'clustering', 'long', 'documents', 'transformers', 'minutestransformers', 'awesome', 'many', 'things', 'one', 'thing', 'found', 'struggle', 'generating', 'embeddings', 'long', 'documents', 'put', 'together', 'blog', 'post', 'going', 'interesting', 'techniques', 'let', 'know', 'helped', 'blog', 'post', 'https', 'www', 'notia', 'ai', 'articles', 'clustering', 'long', 'documents']","['p', 'cluster', 'long', 'document', 'transform', 'minutestransform', 'awesom', 'mani', 'thing', 'one', 'thing', 'found', 'struggl', 'gener', 'embed', 'long', 'document', 'put', 'togeth', 'blog', 'post', 'go', 'interest', 'techniqu', 'let', 'know', 'help', 'blog', 'post', 'http', 'www', 'notia', 'ai', 'articl', 'cluster', 'long', 'document']"
187,202,202,MLknowledge,vme1l7,"[R] Welcome to my continuous, free live machine learning class with intermediate mathematics","Dear all,

Welcome to join my continued ML knowledge dissemination class via Zoom.

I will continue to explain machine learning using an intermediate level mathematics. It happens every second Thursday at GMT at 11:00 (HK7pm / SYD9pm) - the next class is on June 30.

The current topic is:

""Determinantal Point Process""

I'll fully explain its beautiful mathematics over a period of a few sessions. This is a powerful model to model diverse subsets. Yet it is not as commonly used as it should!

You can find my notes on my GitHub site:

[https://github.com/roboticcam/machine-learning-notes/](https://github.com/roboticcam/machine-learning-notes/)

Determinantal Point Process notes is found at:

[https://github.com/roboticcam/machine-learning-notes/blob/master/files/dpp\_new.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/files/dpp_new.pdf)

You need a solid understanding of linear algebra, calculus, probability and statistics. But if you just want to get a feel of how DPP works for example, and meet like-minded people, please come too!

To join, sign up for one of the meetup groups you see fit:

[https://www.meetup.com/machine-learning-hong-kong/](https://www.meetup.com/machine-learning-hong-kong/)

[https://www.meetup.com/deep-learning-sydney/](https://www.meetup.com/deep-learning-sydney/)

[https://www.meetup.com/Deep-Learning-Melbourne/](https://www.meetup.com/Deep-Learning-Melbourne/)

[https://www.meetup.com/machine-learning-athens/](https://www.meetup.com/machine-learning-athens/)",3,41,2022-06-28 09:38:03, r  welcome to my continuous  free live machine learning class with intermediate mathematics,dear all welcome to join my continued ml knowledge dissemination class via zoom i will continue to explain machine learning using an intermediate level mathematics  it happens every second thursday at gmt at    hkpm   sydpm    the next class is on june  the current topic is determinantal point processi ll fully explain its beautiful mathematics over a period of a few sessions  this is a powerful model to model diverse subsets  yet it is not as commonly used as it should you can find my notes on my github site  https determinantal point process notes is found at  https you need a solid understanding of linear algebra  calculus  probability and statistics  but if you just want to get a feel of how dpp works for example  and meet like minded people  please come too to join  sign up for one of the meetup groups you see fit  https  https  https  https   www meetup com machine learning athens   https   www meetup com machine learning athens  ,dear welcome join continued ml knowledge dissemination class via zoom continue explain machine learning using intermediate level mathematics happens every second thursday gmt hkpm sydpm next class june current topic determinantal point processi fully explain beautiful mathematics period sessions powerful model model diverse subsets yet commonly used find notes github site https determinantal point process notes found https need solid understanding linear algebra calculus probability statistics want get feel dpp works example meet like minded people please come join sign one meetup groups see fit https https https https www meetup com machine learning athens https www meetup com machine learning athens,r welcome continuous free live machine learning class intermediate mathematics,r welcome continuous free live machine learning class intermediate mathematicsdear welcome join continued ml knowledge dissemination class via zoom continue explain machine learning using intermediate level mathematics happens every second thursday gmt hkpm sydpm next class june current topic determinantal point processi fully explain beautiful mathematics period sessions powerful model model diverse subsets yet commonly used find notes github site https determinantal point process notes found https need solid understanding linear algebra calculus probability statistics want get feel dpp works example meet like minded people please come join sign one meetup groups see fit https https https https www meetup com machine learning athens https www meetup com machine learning athens,"['r', 'welcome', 'continuous', 'free', 'live', 'machine', 'learning', 'class', 'intermediate', 'mathematicsdear', 'welcome', 'join', 'continued', 'ml', 'knowledge', 'dissemination', 'class', 'via', 'zoom', 'continue', 'explain', 'machine', 'learning', 'using', 'intermediate', 'level', 'mathematics', 'happens', 'every', 'second', 'thursday', 'gmt', 'hkpm', 'sydpm', 'next', 'class', 'june', 'current', 'topic', 'determinantal', 'point', 'processi', 'fully', 'explain', 'beautiful', 'mathematics', 'period', 'sessions', 'powerful', 'model', 'model', 'diverse', 'subsets', 'yet', 'commonly', 'used', 'find', 'notes', 'github', 'site', 'https', 'determinantal', 'point', 'process', 'notes', 'found', 'https', 'need', 'solid', 'understanding', 'linear', 'algebra', 'calculus', 'probability', 'statistics', 'want', 'get', 'feel', 'dpp', 'works', 'example', 'meet', 'like', 'minded', 'people', 'please', 'come', 'join', 'sign', 'one', 'meetup', 'groups', 'see', 'fit', 'https', 'https', 'https', 'https', 'www', 'meetup', 'com', 'machine', 'learning', 'athens', 'https', 'www', 'meetup', 'com', 'machine', 'learning', 'athens']","['r', 'welcom', 'continu', 'free', 'live', 'machin', 'learn', 'class', 'intermedi', 'mathematicsdear', 'welcom', 'join', 'continu', 'ml', 'knowledg', 'dissemin', 'class', 'via', 'zoom', 'continu', 'explain', 'machin', 'learn', 'use', 'intermedi', 'level', 'mathemat', 'happen', 'everi', 'second', 'thursday', 'gmt', 'hkpm', 'sydpm', 'next', 'class', 'june', 'current', 'topic', 'determinant', 'point', 'processi', 'fulli', 'explain', 'beauti', 'mathemat', 'period', 'session', 'power', 'model', 'model', 'divers', 'subset', 'yet', 'commonli', 'use', 'find', 'note', 'github', 'site', 'http', 'determinant', 'point', 'process', 'note', 'found', 'http', 'need', 'solid', 'understand', 'linear', 'algebra', 'calculu', 'probabl', 'statist', 'want', 'get', 'feel', 'dpp', 'work', 'exampl', 'meet', 'like', 'mind', 'peopl', 'pleas', 'come', 'join', 'sign', 'one', 'meetup', 'group', 'see', 'fit', 'http', 'http', 'http', 'http', 'www', 'meetup', 'com', 'machin', 'learn', 'athen', 'http', 'www', 'meetup', 'com', 'machin', 'learn', 'athen']"
188,203,203,alexlyzhov,vm2sti,[N] Inverse Scaling Prize: $250k in prizes for finding tasks where larger language models do worse,"The standard paradigm in natural language processing today is to train large language models to autocomplete random Internet-sourced text. These models are then either frozen and used directly for other tasks (zero-shot/few-shot), or additionally trained on other tasks (fine-tuning).

We're used to finding that task performance scales well with large increases in sizes of language models. But for real-world applications, it's also very meaningful to search for failure cases of scaling preemptively to fix the underlying issues. Can you find and convincingly demonstrate these failure cases where zero-shot/few-shot performance of language models scales *inversely*, with larger models behaving worse?

You don't necessarily need to have extra deep knowledge of ML or language models in order to participate and win, because all models are frozen and you only need to come up with the right data.

Check out these resources to learn more! [Announcement Twitter thread](https://twitter.com/EthanJPerez/status/1541454949397041154), [contest details on Github](https://github.com/inverse-scaling/prize).
The deadline for the first round of the contest is August 27, 2022.",39,211,2022-06-28 00:19:44, n  inverse scaling prize   k in prizes for finding tasks where larger language models do worse,the standard paradigm in natural language processing today is to train large language models to autocomplete random internet sourced text  these models are then either frozen and used directly for other tasks  zero shot few shot   or additionally trained on other tasks  fine tuning  we re used to finding that task performance scales well with large increases in sizes of language models  but for real world applications  it s also very meaningful to search for failure cases of scaling preemptively to fix the underlying issues  can you find and convincingly demonstrate these failure cases where zero shot few shot performance of language models scales  inversely   with larger models behaving worse you don t necessarily need to have extra deep knowledge of ml or language models in order to participate and win  because all models are frozen and you only need to come up with the right data check out these resources to learn more   announcement twitter thread  https the deadline for the first round of the contest is august    ,standard paradigm natural language processing today train large language models autocomplete random internet sourced text models either frozen used directly tasks zero shot shot additionally trained tasks fine tuning used finding task performance scales well large increases sizes language models real world applications also meaningful search failure cases scaling preemptively fix underlying issues find convincingly demonstrate failure cases zero shot shot performance language models scales inversely larger models behaving worse necessarily need extra deep knowledge ml language models order participate win models frozen need come right data check resources learn announcement twitter thread https deadline first round contest august,n inverse scaling prize k prizes finding tasks larger language models worse,n inverse scaling prize k prizes finding tasks larger language models worsestandard paradigm natural language processing today train large language models autocomplete random internet sourced text models either frozen used directly tasks zero shot shot additionally trained tasks fine tuning used finding task performance scales well large increases sizes language models real world applications also meaningful search failure cases scaling preemptively fix underlying issues find convincingly demonstrate failure cases zero shot shot performance language models scales inversely larger models behaving worse necessarily need extra deep knowledge ml language models order participate win models frozen need come right data check resources learn announcement twitter thread https deadline first round contest august,"['n', 'inverse', 'scaling', 'prize', 'k', 'prizes', 'finding', 'tasks', 'larger', 'language', 'models', 'worsestandard', 'paradigm', 'natural', 'language', 'processing', 'today', 'train', 'large', 'language', 'models', 'autocomplete', 'random', 'internet', 'sourced', 'text', 'models', 'either', 'frozen', 'used', 'directly', 'tasks', 'zero', 'shot', 'shot', 'additionally', 'trained', 'tasks', 'fine', 'tuning', 'used', 'finding', 'task', 'performance', 'scales', 'well', 'large', 'increases', 'sizes', 'language', 'models', 'real', 'world', 'applications', 'also', 'meaningful', 'search', 'failure', 'cases', 'scaling', 'preemptively', 'fix', 'underlying', 'issues', 'find', 'convincingly', 'demonstrate', 'failure', 'cases', 'zero', 'shot', 'shot', 'performance', 'language', 'models', 'scales', 'inversely', 'larger', 'models', 'behaving', 'worse', 'necessarily', 'need', 'extra', 'deep', 'knowledge', 'ml', 'language', 'models', 'order', 'participate', 'win', 'models', 'frozen', 'need', 'come', 'right', 'data', 'check', 'resources', 'learn', 'announcement', 'twitter', 'thread', 'https', 'deadline', 'first', 'round', 'contest', 'august']","['n', 'invers', 'scale', 'prize', 'k', 'prize', 'find', 'task', 'larger', 'languag', 'model', 'worsestandard', 'paradigm', 'natur', 'languag', 'process', 'today', 'train', 'larg', 'languag', 'model', 'autocomplet', 'random', 'internet', 'sourc', 'text', 'model', 'either', 'frozen', 'use', 'directli', 'task', 'zero', 'shot', 'shot', 'addit', 'train', 'task', 'fine', 'tune', 'use', 'find', 'task', 'perform', 'scale', 'well', 'larg', 'increas', 'size', 'languag', 'model', 'real', 'world', 'applic', 'also', 'meaning', 'search', 'failur', 'case', 'scale', 'preemptiv', 'fix', 'underli', 'issu', 'find', 'convincingli', 'demonstr', 'failur', 'case', 'zero', 'shot', 'shot', 'perform', 'languag', 'model', 'scale', 'invers', 'larger', 'model', 'behav', 'wors', 'necessarili', 'need', 'extra', 'deep', 'knowledg', 'ml', 'languag', 'model', 'order', 'particip', 'win', 'model', 'frozen', 'need', 'come', 'right', 'data', 'check', 'resourc', 'learn', 'announc', 'twitter', 'thread', 'http', 'deadlin', 'first', 'round', 'contest', 'august']"
189,204,204,Farconion,vmr5a5,[D] Have compression techniques every been applied to the likes of GPT-3 & DALLE-2?,"Large language models and the recent spur of diffusion based  text-to-image models are gosh-darn fun to play with, but due to their  size and expensive training costs - they're only accessible via an API  or if you yourself have a access to a large # of GPUs. Yet there are  also a number of compression techniques like pruning and quantization  that can drastically reduce the size (+90%), and thus computational  requirements, of a trained model. Has there been any work looking  appling such techniques to these gigantic models floating around to make  them more accessible?",7,3,2022-06-28 21:51:53, d  have compression techniques every been applied to the likes of gpt    dalle  ,large language models and the recent spur of diffusion based  text to image models are gosh darn fun to play with  but due to their  size and expensive training costs   they re only accessible via an api  or if you yourself have a access to a large   of gpus  yet there are  also a number of compression techniques like pruning and quantization  that can drastically reduce the size       and thus computational  requirements  of a trained model  has there been any work looking  appling such techniques to these gigantic models floating around to make  them more accessible ,large language models recent spur diffusion based text image models gosh darn fun play due size expensive training costs accessible via api access large gpus yet also number compression techniques like pruning quantization drastically reduce size thus computational requirements trained model work looking appling techniques gigantic models floating around make accessible,compression techniques every applied likes gpt dalle,compression techniques every applied likes gpt dallelarge language models recent spur diffusion based text image models gosh darn fun play due size expensive training costs accessible via api access large gpus yet also number compression techniques like pruning quantization drastically reduce size thus computational requirements trained model work looking appling techniques gigantic models floating around make accessible,"['compression', 'techniques', 'every', 'applied', 'likes', 'gpt', 'dallelarge', 'language', 'models', 'recent', 'spur', 'diffusion', 'based', 'text', 'image', 'models', 'gosh', 'darn', 'fun', 'play', 'due', 'size', 'expensive', 'training', 'costs', 'accessible', 'via', 'api', 'access', 'large', 'gpus', 'yet', 'also', 'number', 'compression', 'techniques', 'like', 'pruning', 'quantization', 'drastically', 'reduce', 'size', 'thus', 'computational', 'requirements', 'trained', 'model', 'work', 'looking', 'appling', 'techniques', 'gigantic', 'models', 'floating', 'around', 'make', 'accessible']","['compress', 'techniqu', 'everi', 'appli', 'like', 'gpt', 'dallelarg', 'languag', 'model', 'recent', 'spur', 'diffus', 'base', 'text', 'imag', 'model', 'gosh', 'darn', 'fun', 'play', 'due', 'size', 'expens', 'train', 'cost', 'access', 'via', 'api', 'access', 'larg', 'gpu', 'yet', 'also', 'number', 'compress', 'techniqu', 'like', 'prune', 'quantiz', 'drastic', 'reduc', 'size', 'thu', 'comput', 'requir', 'train', 'model', 'work', 'look', 'appl', 'techniqu', 'gigant', 'model', 'float', 'around', 'make', 'access']"
190,205,205,hegelian_waffle,vm9tki,[D] Laplacian positional encodings,"I just finished reading ""[Benchmarking Graph Neural Networks](https://arxiv.org/abs/2003.00982)"" (Dwivedi et al. 2020) and ""[A Generalization of Transformer Networks to Graphs](https://arxiv.org/abs/2012.09699)"" (also Dwivedi et al. 2020), and came across the claim that the eigenvectors of the Laplacian of a graph ""represent a natural generalization of the Transformer (Vaswani et al., 2017) positional encodings (PE)"". Xavier Bresson [tweeted](https://twitter.com/xbresson/status/1273034896517332992?lang=en) the same thing.

So I worked out the eigenvectors of the Laplacian of a path graph (a line of vertices connected by edges like so: v-v-v-...-v), which is the kind of graph used in NLP to represent a sequence of tokens, and found that the ith eigenvector's kth entry is v\_i(k) = cos(πik/n − πi/2n) where n is the number of tokens in the sequence, which is very different from the sinusoidal PEs used in transformers in NLP. I tried working out a change of variables, but nothing's worked so far. Are Laplacian eigenvectors just not the generalizations they're claimed to be, or am I missing something here?",4,51,2022-06-28 05:59:30, d  laplacian positional encodings,i just finished reading  benchmarking graph neural networks  https so i worked out the eigenvectors of the laplacian of a path graph  a line of vertices connected by edges like so  v v v     v   which is the kind of graph used in nlp to represent a sequence of tokens  and found that the ith eigenvector s kth entry is v _i k    cos πik n   πi n  where n is the number of tokens in the sequence  which is very different from the sinusoidal pes used in transformers in nlp  i tried working out a change of variables  but nothing s worked so far  are laplacian eigenvectors just not the generalizations they re claimed to be  or am i missing something here ,finished reading benchmarking graph neural networks https worked eigenvectors laplacian path graph line vertices connected edges like v v v v kind graph used nlp represent sequence tokens found ith eigenvector kth entry v _i k cos πik n πi n n number tokens sequence different sinusoidal pes used transformers nlp tried working change variables nothing worked far laplacian eigenvectors generalizations claimed missing something,laplacian positional encodings,laplacian positional encodingsfinished reading benchmarking graph neural networks https worked eigenvectors laplacian path graph line vertices connected edges like v v v v kind graph used nlp represent sequence tokens found ith eigenvector kth entry v _i k cos πik n πi n n number tokens sequence different sinusoidal pes used transformers nlp tried working change variables nothing worked far laplacian eigenvectors generalizations claimed missing something,"['laplacian', 'positional', 'encodingsfinished', 'reading', 'benchmarking', 'graph', 'neural', 'networks', 'https', 'worked', 'eigenvectors', 'laplacian', 'path', 'graph', 'line', 'vertices', 'connected', 'edges', 'like', 'v', 'v', 'v', 'v', 'kind', 'graph', 'used', 'nlp', 'represent', 'sequence', 'tokens', 'found', 'ith', 'eigenvector', 'kth', 'entry', 'v', '_i', 'k', 'cos', 'πik', 'n', 'πi', 'n', 'n', 'number', 'tokens', 'sequence', 'different', 'sinusoidal', 'pes', 'used', 'transformers', 'nlp', 'tried', 'working', 'change', 'variables', 'nothing', 'worked', 'far', 'laplacian', 'eigenvectors', 'generalizations', 'claimed', 'missing', 'something']","['laplacian', 'posit', 'encodingsfinish', 'read', 'benchmark', 'graph', 'neural', 'network', 'http', 'work', 'eigenvector', 'laplacian', 'path', 'graph', 'line', 'vertic', 'connect', 'edg', 'like', 'v', 'v', 'v', 'v', 'kind', 'graph', 'use', 'nlp', 'repres', 'sequenc', 'token', 'found', 'ith', 'eigenvector', 'kth', 'entri', 'v', '_i', 'k', 'co', 'πik', 'n', 'πi', 'n', 'n', 'number', 'token', 'sequenc', 'differ', 'sinusoid', 'pe', 'use', 'transform', 'nlp', 'tri', 'work', 'chang', 'variabl', 'noth', 'work', 'far', 'laplacian', 'eigenvector', 'gener', 'claim', 'miss', 'someth']"
191,206,206,moschles,vmdl3l,[D] Surface rendering in Diffusion Probability Text-to-Image Generators.,"Two diffusion text-to-image generators are Google's Imagen and openai's DALLE.2.     

DALLE.2 uses a multimodal large language model called CLIP to encode an input text prompt.  The output is produced by a reverse encoder called a diffusion probability model.   Diffusion models have previously seen huge successes in *image super resolution* and denoising.  

One peculiar aspect of DALLE.2's  output is that it is capable of generating light sources in certain (seemingly) 3D locations in the scene, then correctly lighting the objects based off of their implied location.   DALLE.2 can also perform image completions from a starting image prompt.     The two examples below are Spongebob dish sponge in a sink, and Vermeer's famous earring painting.    


https://i.imgur.com/vVI6IOI.png

.


https://i.imgur.com/8h48lTg.png

.

One plausible explanation for these physically perfect surface reflections is that DALLE.2  performs a phase where the image is reverse-encoded into a 3D scene.  That scene is then rendered back into a 2D output image.    However, when consulting the primary literature, no such conversion to a 3D model is seen anywhere along the DALLE.2 workflow.  

The implication is that DALLE.2 must contain a wealth of priors related to light transport, gleaned simply from 2D training images alone.  This means these priors are being applied (mostly correctly) to particular instantiations of objects and surfaces in scenes.  This application is performed even to the point where wet metallic surfaces have correct blurring in reflections.       

Further investigations of this phenomenon would involve finding some user prompts that generated a scene containing light casting a sharp shadow onto a flat surface.  Another would be requesting a reflective object in the text prompt itself.

Your thoughts?",2,26,2022-06-28 09:13:20, d  surface rendering in diffusion probability text to image generators ,two diffusion text to image generators are google s imagen and openai s dalle       dalle  uses a multimodal large language model called clip to encode an input text prompt   the output is produced by a reverse encoder called a diffusion probability model    diffusion models have previously seen huge successes in  image super resolution  and denoising   one peculiar aspect of dalle  s  output is that it is capable of generating light sources in certain  seemingly  d locations in the scene  then correctly lighting the objects based off of their implied location    dalle  can also perform image completions from a starting image prompt      the two examples below are spongebob dish sponge in a sink  and vermeer s famous earring painting     https  https  one plausible explanation for these physically perfect surface reflections is that dalle   performs a phase where the image is reverse encoded into a d scene   that scene is then rendered back into a d output image     however  when consulting the primary literature  no such conversion to a d model is seen anywhere along the dalle  workflow   the implication is that dalle  must contain a wealth of priors related to light transport  gleaned simply from d training images alone   this means these priors are being applied  mostly correctly  to particular instantiations of objects and surfaces in scenes   this application is performed even to the point where wet metallic surfaces have correct blurring in reflections        further investigations of this phenomenon would involve finding some user prompts that generated a scene containing light casting a sharp shadow onto a flat surface   another would be requesting a reflective object in the text prompt itself your thoughts ,two diffusion text image generators google imagen openai dalle dalle uses multimodal large language model called clip encode input text prompt output produced reverse encoder called diffusion probability model diffusion models previously seen huge successes image super resolution denoising one peculiar aspect dalle output capable generating light sources certain seemingly locations scene correctly lighting objects based implied location dalle also perform image completions starting image prompt two examples spongebob dish sponge sink vermeer famous earring painting https https one plausible explanation physically perfect surface reflections dalle performs phase image reverse encoded scene scene rendered back output image however consulting primary literature conversion model seen anywhere along dalle workflow implication dalle must contain wealth priors related light transport gleaned simply training images alone means priors applied mostly correctly particular instantiations objects surfaces scenes application performed even point wet metallic surfaces correct blurring reflections investigations phenomenon would involve finding user prompts generated scene containing light casting sharp shadow onto flat surface another would requesting reflective object text prompt thoughts,surface rendering diffusion probability text image generators,surface rendering diffusion probability text image generatorstwo diffusion text image generators google imagen openai dalle dalle uses multimodal large language model called clip encode input text prompt output produced reverse encoder called diffusion probability model diffusion models previously seen huge successes image super resolution denoising one peculiar aspect dalle output capable generating light sources certain seemingly locations scene correctly lighting objects based implied location dalle also perform image completions starting image prompt two examples spongebob dish sponge sink vermeer famous earring painting https https one plausible explanation physically perfect surface reflections dalle performs phase image reverse encoded scene scene rendered back output image however consulting primary literature conversion model seen anywhere along dalle workflow implication dalle must contain wealth priors related light transport gleaned simply training images alone means priors applied mostly correctly particular instantiations objects surfaces scenes application performed even point wet metallic surfaces correct blurring reflections investigations phenomenon would involve finding user prompts generated scene containing light casting sharp shadow onto flat surface another would requesting reflective object text prompt thoughts,"['surface', 'rendering', 'diffusion', 'probability', 'text', 'image', 'generatorstwo', 'diffusion', 'text', 'image', 'generators', 'google', 'imagen', 'openai', 'dalle', 'dalle', 'uses', 'multimodal', 'large', 'language', 'model', 'called', 'clip', 'encode', 'input', 'text', 'prompt', 'output', 'produced', 'reverse', 'encoder', 'called', 'diffusion', 'probability', 'model', 'diffusion', 'models', 'previously', 'seen', 'huge', 'successes', 'image', 'super', 'resolution', 'denoising', 'one', 'peculiar', 'aspect', 'dalle', 'output', 'capable', 'generating', 'light', 'sources', 'certain', 'seemingly', 'locations', 'scene', 'correctly', 'lighting', 'objects', 'based', 'implied', 'location', 'dalle', 'also', 'perform', 'image', 'completions', 'starting', 'image', 'prompt', 'two', 'examples', 'spongebob', 'dish', 'sponge', 'sink', 'vermeer', 'famous', 'earring', 'painting', 'https', 'https', 'one', 'plausible', 'explanation', 'physically', 'perfect', 'surface', 'reflections', 'dalle', 'performs', 'phase', 'image', 'reverse', 'encoded', 'scene', 'scene', 'rendered', 'back', 'output', 'image', 'however', 'consulting', 'primary', 'literature', 'conversion', 'model', 'seen', 'anywhere', 'along', 'dalle', 'workflow', 'implication', 'dalle', 'must', 'contain', 'wealth', 'priors', 'related', 'light', 'transport', 'gleaned', 'simply', 'training', 'images', 'alone', 'means', 'priors', 'applied', 'mostly', 'correctly', 'particular', 'instantiations', 'objects', 'surfaces', 'scenes', 'application', 'performed', 'even', 'point', 'wet', 'metallic', 'surfaces', 'correct', 'blurring', 'reflections', 'investigations', 'phenomenon', 'would', 'involve', 'finding', 'user', 'prompts', 'generated', 'scene', 'containing', 'light', 'casting', 'sharp', 'shadow', 'onto', 'flat', 'surface', 'another', 'would', 'requesting', 'reflective', 'object', 'text', 'prompt', 'thoughts']","['surfac', 'render', 'diffus', 'probabl', 'text', 'imag', 'generatorstwo', 'diffus', 'text', 'imag', 'gener', 'googl', 'imagen', 'openai', 'dall', 'dall', 'use', 'multimod', 'larg', 'languag', 'model', 'call', 'clip', 'encod', 'input', 'text', 'prompt', 'output', 'produc', 'revers', 'encod', 'call', 'diffus', 'probabl', 'model', 'diffus', 'model', 'previous', 'seen', 'huge', 'success', 'imag', 'super', 'resolut', 'denois', 'one', 'peculiar', 'aspect', 'dall', 'output', 'capabl', 'gener', 'light', 'sourc', 'certain', 'seemingli', 'locat', 'scene', 'correctli', 'light', 'object', 'base', 'impli', 'locat', 'dall', 'also', 'perform', 'imag', 'complet', 'start', 'imag', 'prompt', 'two', 'exampl', 'spongebob', 'dish', 'spong', 'sink', 'vermeer', 'famou', 'ear', 'paint', 'http', 'http', 'one', 'plausibl', 'explan', 'physic', 'perfect', 'surfac', 'reflect', 'dall', 'perform', 'phase', 'imag', 'revers', 'encod', 'scene', 'scene', 'render', 'back', 'output', 'imag', 'howev', 'consult', 'primari', 'literatur', 'convers', 'model', 'seen', 'anywher', 'along', 'dall', 'workflow', 'implic', 'dall', 'must', 'contain', 'wealth', 'prior', 'relat', 'light', 'transport', 'glean', 'simpli', 'train', 'imag', 'alon', 'mean', 'prior', 'appli', 'mostli', 'correctli', 'particular', 'instanti', 'object', 'surfac', 'scene', 'applic', 'perform', 'even', 'point', 'wet', 'metal', 'surfac', 'correct', 'blur', 'reflect', 'investig', 'phenomenon', 'would', 'involv', 'find', 'user', 'prompt', 'gener', 'scene', 'contain', 'light', 'cast', 'sharp', 'shadow', 'onto', 'flat', 'surfac', 'anoth', 'would', 'request', 'reflect', 'object', 'text', 'prompt', 'thought']"
192,207,207,SnooRecipes1624,vlpnuw,"[D] IBM Zurich Research Plagiarised Our Paper and got it published on CVPR 2022. Is ""copy texts"" is plagiarism, ""copy idea"" is not plagiarism?","I am Xianbiao Qi, a computer vision researcher with more than ten years of research experience. I am writing this blog to complain of a serious case of deliberate plagiarism of our paper by the employees from **IBM Zurich Research. They did not copy texts, they copied the idea.**

>  
>  
>Our preprint paper on Arxiv is ""Jiaquan Ye, Xianbiao Qi, Yelin He, and etc.""PingAn-VCGroup's Solution for ICDAR 2021 Competition on Scientific Literature Parsing Task B: Table Recognition to HTML."" arXiv preprint arXiv:2105.01848, May 2021"" and the code was also released.  
>  
>  
>  
>Our paper (Ye et al. arXiv: 2105.01848) was plagiarised by a team in IBM Zurich Research: ""**Ahmed Nassar, Nikolaos Livathinos, Maksym Lysak, and Peter Staar, ""TableFormer: Table Structure Understanding with Transformers.""** In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 4614-4623, June 2022.""  
>  
>  
>  
>Nassar et al. 's paper plagiarized our method, pre-processing, post-processing, visualization, inference, systematic solution, code, pretrained models and etc, but did NOT cite our paper in order to not be captured for the plagiarism.  I was notified by many experts in the fields of OCR and table analysis.

Let me explain the plagiarism process step by step.

>**First**,  let me sort out the timeline.  
>  
>**Our Tablemaster,**  
>  
>**2021-04-07,** we finish the ICDAR 2021 competition-on-scientific-literature-parsing **hosted by another IBM group in Australia**  
>  
>[https://icdar2021.org/program-2/competitions/competition-on-scientific-literature-parsing/](https://icdar2021.org/program-2/competitions/competition-on-scientific-literature-parsing/)  
>  
>**2021-05-05**, we released our technical report, a preprint version, on Arxiv[https://arxiv.org/pdf/2105.01848.pdf](https://arxiv.org/pdf/2105.01848.pdf)  
>  
>**2021-07-29**, we released our source code, and even our slides on Github, [https://github.com/JiaquanYe/TableMASTER-mmocr](https://github.com/JiaquanYe/TableMASTER-mmocr)  
>  
>**2021-09**: we released the Tablemaster pretrained model.  
>  
>**2021-11** we even released tablemaster\_mmocr docker environment.  
>  
>For this project, we were naked. We release all these materials to facilitate the community, but you  plagiarized it.  
>  
>  
>  
>**Plagiarized-TableFormer:**  
>  
>**2022-03-02**, the Plagiarized-TableFormer was released on Arxiv[https://arxiv.org/pdf/2203.01017v1.pdf](https://arxiv.org/pdf/2203.01017v1.pdf)Their supplemental to cvpr submission.[https://openaccess.thecvf.com/content/CVPR2022/supplemental/Nassar\_TableFormer\_Table\_Structure\_CVPR\_2022\_supplemental.pdf](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Nassar_TableFormer_Table_Structure_CVPR_2022_supplemental.pdf)  
>  
>**Then,** let me highlight nine clear evidence.  Then I will explain each piece of evidence in detail.

1. Our methodology, you plagiarize
2. Our Pre-processing, you plagiarize
3. Our Post-processing, you plagiarize
4. Our Inference speedup method,  you plagiarize
5. Our ""tricky"" work, you even plagiarize
6. Our text line detection and text line recognition, you plagiarize
7. Our systematic solution, you plagiarize
8. Our visualization,  you plagiarize
9. Misleading the audiences in order to not be captured for plagiarism

&#x200B;

>To Nassar, Ahmed, Nikolaos Livathinos, Maksym Lysak, and Peter Staar, All you need is not ""TableFormer"", All you need is git clone and torch.load  
>  
>git clone [https://github.com/JiaquanYe/TableMASTER-mmocr](https://github.com/JiaquanYe/TableMASTER-mmocr)  
>  
>torch.load(""our\_pretrained\_model.pth"")   
>  
>You will be the rising stars because you have learnt how to use git clone and torch.load.  
>  
>I attach a step-by-step proof below.

&#x200B;

https://preview.redd.it/gexr11d474891.png?width=2480&format=png&auto=webp&s=2a1fe08a20e044bbef8e021abab17b97acf93101

https://preview.redd.it/t95rgpd474891.png?width=2480&format=png&auto=webp&s=cc345024e531edbbae5ed64c1588e1a7d1e7cc7b

https://preview.redd.it/o3fec4d474891.png?width=2480&format=png&auto=webp&s=89ef3646d0b48a2cc75629248c9503deee156969

https://preview.redd.it/u5ywa5d474891.png?width=2480&format=png&auto=webp&s=896f8c0f81d02021098a95902525266be36bad4c

https://preview.redd.it/ic1y75d474891.png?width=2480&format=png&auto=webp&s=a9e9103b576a66981afaec8f86c00acb31fa6e78

https://preview.redd.it/g6ykdod474891.png?width=2480&format=png&auto=webp&s=5aed8320e990841a7813e62d6359579448c2e32f

https://preview.redd.it/jae7j4d474891.png?width=2480&format=png&auto=webp&s=3f008b1c77254434602217facff99b747d977a7d

https://preview.redd.it/pzyln8d474891.png?width=2480&format=png&auto=webp&s=47de343b99f570ce3dac9be256ccd058bb8f52d6

https://preview.redd.it/bpbub9d474891.png?width=2480&format=png&auto=webp&s=b4eb656dfabc68676cec8c941b7e0034a7d29c25

https://preview.redd.it/7oulcad474891.png?width=2480&format=png&auto=webp&s=934af73376e3948d878c7ad15bdd504b075acb20

https://preview.redd.it/qo2aubd474891.png?width=2480&format=png&auto=webp&s=34821a8530c6da6f63b2552fe10aee94b7770e59

https://preview.redd.it/d0mqhdd474891.png?width=2480&format=png&auto=webp&s=4d7f1c95c1ec051d27758cdbb8f95f522e00c113

https://preview.redd.it/8oc6qgd474891.png?width=2480&format=png&auto=webp&s=50caf4ba63d23650a44bfcd830c7337c781b1ecd

https://preview.redd.it/944c1gd474891.png?width=2480&format=png&auto=webp&s=3fb5817bee6b21e6674c519c8954bd69149b92bd

https://preview.redd.it/c83m2gd474891.png?width=2480&format=png&auto=webp&s=125235df4a28cbff8f57956ec871002a6d7782bd

https://preview.redd.it/72awaid474891.png?width=2480&format=png&auto=webp&s=2ad797b986403d8b413289f778b97508e084ee46

https://preview.redd.it/szd7h3d474891.png?width=2480&format=png&auto=webp&s=3efdd2306814be90600b2da19fb032ea4c24ee4c",147,1053,2022-06-27 12:49:04, d  ibm zurich research plagiarised our paper and got it published on cvpr   is copy texts is plagiarism  copy idea is not plagiarism ,i am xianbiao qi  a computer vision researcher with more than ten years of research experience  i am writing this blog to complain of a serious case of deliberate plagiarism of our paper by the employees from   ibm zurich research  they did not copy texts  they copied the idea          our preprint paper on arxiv is jiaquan ye  xianbiao qi  yelin he  and etc pingan vcgroup s solution for icdar  competition on scientific literature parsing task b  table recognition to html  arxiv preprint arxiv    may  and the code was also released             our paper  ye et al  arxiv     was plagiarised by a team in ibm zurich research    ahmed nassar  nikolaos livathinos  maksym lysak  and peter staar  tableformer  table structure understanding with transformers    in proceedings of the ieee cvf conference on computer vision and pattern recognition  pp     june              nassar et al   s paper plagiarized our method  pre processing  post processing  visualization  inference  systematic solution  code  pretrained models and etc  but did not cite our paper in order to not be captured for the plagiarism   i was notified by many experts in the fields of ocr and table analysis let me explain the plagiarism process step by step    first     let me sort out the timeline         our tablemaster                 we finish the icdar  competition on scientific literature parsing   hosted by another ibm group in australia         https             we released our technical report  a preprint version  on arxiv https             we released our source code  and even our slides on github   https            we released the tablemaster pretrained model             we even released tablemaster _mmocr docker environment       for this project  we were naked  we release all these materials to facilitate the community  but you  plagiarized it               plagiarized tableformer                 the plagiarized tableformer was released on arxiv https       then    let me highlight nine clear evidence   then i will explain each piece of evidence in detail   our methodology  you plagiarize  our pre processing  you plagiarize  our post processing  you plagiarize  our inference speedup method   you plagiarize  our tricky work  you even plagiarize  our text line detection and text line recognition  you plagiarize  our systematic solution  you plagiarize  our visualization   you plagiarize  misleading the audiences in order to not be captured for plagiarism  xb  to nassar  ahmed  nikolaos livathinos  maksym lysak  and peter staar  all you need is not tableformer  all you need is git clone and torch load      git clone  https     torch load our _pretrained _model pth        you will be the rising stars because you have learnt how to use git clone and torch load       i attach a step by step proof below   xb https https https https https https https https https https https https https https https https https   preview redd it szdhd png width  format png auto webp s efddbebdafbeaceec,xianbiao qi computer vision researcher ten years research experience writing blog complain serious case deliberate plagiarism paper employees ibm zurich research copy texts copied idea preprint paper arxiv jiaquan ye xianbiao qi yelin etc pingan vcgroup solution icdar competition scientific literature parsing task b table recognition html arxiv preprint arxiv may code also released paper ye et al arxiv plagiarised team ibm zurich research ahmed nassar nikolaos livathinos maksym lysak peter staar tableformer table structure understanding transformers proceedings ieee cvf conference computer vision pattern recognition pp june nassar et al paper plagiarized method pre processing post processing visualization inference systematic solution code pretrained models etc cite paper order captured plagiarism notified many experts fields ocr table analysis let explain plagiarism process step step first let sort timeline tablemaster finish icdar competition scientific literature parsing hosted another ibm group australia https released technical report preprint version arxiv https released source code even slides github https released tablemaster pretrained model even released tablemaster _mmocr docker environment project naked release materials facilitate community plagiarized plagiarized tableformer plagiarized tableformer released arxiv https let highlight nine clear evidence explain piece evidence detail methodology plagiarize pre processing plagiarize post processing plagiarize inference speedup method plagiarize tricky work even plagiarize text line detection text line recognition plagiarize systematic solution plagiarize visualization plagiarize misleading audiences order captured plagiarism xb nassar ahmed nikolaos livathinos maksym lysak peter staar need tableformer need git clone torch load git clone https torch load _pretrained _model pth rising stars learnt use git clone torch load attach step step proof xb https https https https https https https https https https https https https https https https https preview redd szdhd png width format png auto webp efddbebdafbeaceec,ibm zurich research plagiarised paper got published cvpr copy texts plagiarism copy idea plagiarism,ibm zurich research plagiarised paper got published cvpr copy texts plagiarism copy idea plagiarismxianbiao qi computer vision researcher ten years research experience writing blog complain serious case deliberate plagiarism paper employees ibm zurich research copy texts copied idea preprint paper arxiv jiaquan ye xianbiao qi yelin etc pingan vcgroup solution icdar competition scientific literature parsing task b table recognition html arxiv preprint arxiv may code also released paper ye et al arxiv plagiarised team ibm zurich research ahmed nassar nikolaos livathinos maksym lysak peter staar tableformer table structure understanding transformers proceedings ieee cvf conference computer vision pattern recognition pp june nassar et al paper plagiarized method pre processing post processing visualization inference systematic solution code pretrained models etc cite paper order captured plagiarism notified many experts fields ocr table analysis let explain plagiarism process step step first let sort timeline tablemaster finish icdar competition scientific literature parsing hosted another ibm group australia https released technical report preprint version arxiv https released source code even slides github https released tablemaster pretrained model even released tablemaster _mmocr docker environment project naked release materials facilitate community plagiarized plagiarized tableformer plagiarized tableformer released arxiv https let highlight nine clear evidence explain piece evidence detail methodology plagiarize pre processing plagiarize post processing plagiarize inference speedup method plagiarize tricky work even plagiarize text line detection text line recognition plagiarize systematic solution plagiarize visualization plagiarize misleading audiences order captured plagiarism xb nassar ahmed nikolaos livathinos maksym lysak peter staar need tableformer need git clone torch load git clone https torch load _pretrained _model pth rising stars learnt use git clone torch load attach step step proof xb https https https https https https https https https https https https https https https https https preview redd szdhd png width format png auto webp efddbebdafbeaceec,"['ibm', 'zurich', 'research', 'plagiarised', 'paper', 'got', 'published', 'cvpr', 'copy', 'texts', 'plagiarism', 'copy', 'idea', 'plagiarismxianbiao', 'qi', 'computer', 'vision', 'researcher', 'ten', 'years', 'research', 'experience', 'writing', 'blog', 'complain', 'serious', 'case', 'deliberate', 'plagiarism', 'paper', 'employees', 'ibm', 'zurich', 'research', 'copy', 'texts', 'copied', 'idea', 'preprint', 'paper', 'arxiv', 'jiaquan', 'ye', 'xianbiao', 'qi', 'yelin', 'etc', 'pingan', 'vcgroup', 'solution', 'icdar', 'competition', 'scientific', 'literature', 'parsing', 'task', 'b', 'table', 'recognition', 'html', 'arxiv', 'preprint', 'arxiv', 'may', 'code', 'also', 'released', 'paper', 'ye', 'et', 'al', 'arxiv', 'plagiarised', 'team', 'ibm', 'zurich', 'research', 'ahmed', 'nassar', 'nikolaos', 'livathinos', 'maksym', 'lysak', 'peter', 'staar', 'tableformer', 'table', 'structure', 'understanding', 'transformers', 'proceedings', 'ieee', 'cvf', 'conference', 'computer', 'vision', 'pattern', 'recognition', 'pp', 'june', 'nassar', 'et', 'al', 'paper', 'plagiarized', 'method', 'pre', 'processing', 'post', 'processing', 'visualization', 'inference', 'systematic', 'solution', 'code', 'pretrained', 'models', 'etc', 'cite', 'paper', 'order', 'captured', 'plagiarism', 'notified', 'many', 'experts', 'fields', 'ocr', 'table', 'analysis', 'let', 'explain', 'plagiarism', 'process', 'step', 'step', 'first', 'let', 'sort', 'timeline', 'tablemaster', 'finish', 'icdar', 'competition', 'scientific', 'literature', 'parsing', 'hosted', 'another', 'ibm', 'group', 'australia', 'https', 'released', 'technical', 'report', 'preprint', 'version', 'arxiv', 'https', 'released', 'source', 'code', 'even', 'slides', 'github', 'https', 'released', 'tablemaster', 'pretrained', 'model', 'even', 'released', 'tablemaster', '_mmocr', 'docker', 'environment', 'project', 'naked', 'release', 'materials', 'facilitate', 'community', 'plagiarized', 'plagiarized', 'tableformer', 'plagiarized', 'tableformer', 'released', 'arxiv', 'https', 'let', 'highlight', 'nine', 'clear', 'evidence', 'explain', 'piece', 'evidence', 'detail', 'methodology', 'plagiarize', 'pre', 'processing', 'plagiarize', 'post', 'processing', 'plagiarize', 'inference', 'speedup', 'method', 'plagiarize', 'tricky', 'work', 'even', 'plagiarize', 'text', 'line', 'detection', 'text', 'line', 'recognition', 'plagiarize', 'systematic', 'solution', 'plagiarize', 'visualization', 'plagiarize', 'misleading', 'audiences', 'order', 'captured', 'plagiarism', 'xb', 'nassar', 'ahmed', 'nikolaos', 'livathinos', 'maksym', 'lysak', 'peter', 'staar', 'need', 'tableformer', 'need', 'git', 'clone', 'torch', 'load', 'git', 'clone', 'https', 'torch', 'load', '_pretrained', '_model', 'pth', 'rising', 'stars', 'learnt', 'use', 'git', 'clone', 'torch', 'load', 'attach', 'step', 'step', 'proof', 'xb', 'https', 'https', 'https', 'https', 'https', 'https', 'https', 'https', 'https', 'https', 'https', 'https', 'https', 'https', 'https', 'https', 'https', 'preview', 'redd', 'szdhd', 'png', 'width', 'format', 'png', 'auto', 'webp', 'efddbebdafbeaceec']","['ibm', 'zurich', 'research', 'plagiaris', 'paper', 'got', 'publish', 'cvpr', 'copi', 'text', 'plagiar', 'copi', 'idea', 'plagiarismxianbiao', 'qi', 'comput', 'vision', 'research', 'ten', 'year', 'research', 'experi', 'write', 'blog', 'complain', 'seriou', 'case', 'deliber', 'plagiar', 'paper', 'employe', 'ibm', 'zurich', 'research', 'copi', 'text', 'copi', 'idea', 'preprint', 'paper', 'arxiv', 'jiaquan', 'ye', 'xianbiao', 'qi', 'yelin', 'etc', 'pingan', 'vcgroup', 'solut', 'icdar', 'competit', 'scientif', 'literatur', 'pars', 'task', 'b', 'tabl', 'recognit', 'html', 'arxiv', 'preprint', 'arxiv', 'may', 'code', 'also', 'releas', 'paper', 'ye', 'et', 'al', 'arxiv', 'plagiaris', 'team', 'ibm', 'zurich', 'research', 'ahm', 'nassar', 'nikolao', 'livathino', 'maksym', 'lysak', 'peter', 'staar', 'tableform', 'tabl', 'structur', 'understand', 'transform', 'proceed', 'ieee', 'cvf', 'confer', 'comput', 'vision', 'pattern', 'recognit', 'pp', 'june', 'nassar', 'et', 'al', 'paper', 'plagiar', 'method', 'pre', 'process', 'post', 'process', 'visual', 'infer', 'systemat', 'solut', 'code', 'pretrain', 'model', 'etc', 'cite', 'paper', 'order', 'captur', 'plagiar', 'notifi', 'mani', 'expert', 'field', 'ocr', 'tabl', 'analysi', 'let', 'explain', 'plagiar', 'process', 'step', 'step', 'first', 'let', 'sort', 'timelin', 'tablemast', 'finish', 'icdar', 'competit', 'scientif', 'literatur', 'pars', 'host', 'anoth', 'ibm', 'group', 'australia', 'http', 'releas', 'technic', 'report', 'preprint', 'version', 'arxiv', 'http', 'releas', 'sourc', 'code', 'even', 'slide', 'github', 'http', 'releas', 'tablemast', 'pretrain', 'model', 'even', 'releas', 'tablemast', '_mmocr', 'docker', 'environ', 'project', 'nake', 'releas', 'materi', 'facilit', 'commun', 'plagiar', 'plagiar', 'tableform', 'plagiar', 'tableform', 'releas', 'arxiv', 'http', 'let', 'highlight', 'nine', 'clear', 'evid', 'explain', 'piec', 'evid', 'detail', 'methodolog', 'plagiar', 'pre', 'process', 'plagiar', 'post', 'process', 'plagiar', 'infer', 'speedup', 'method', 'plagiar', 'tricki', 'work', 'even', 'plagiar', 'text', 'line', 'detect', 'text', 'line', 'recognit', 'plagiar', 'systemat', 'solut', 'plagiar', 'visual', 'plagiar', 'mislead', 'audienc', 'order', 'captur', 'plagiar', 'xb', 'nassar', 'ahm', 'nikolao', 'livathino', 'maksym', 'lysak', 'peter', 'staar', 'need', 'tableform', 'need', 'git', 'clone', 'torch', 'load', 'git', 'clone', 'http', 'torch', 'load', '_pretrain', '_model', 'pth', 'rise', 'star', 'learnt', 'use', 'git', 'clone', 'torch', 'load', 'attach', 'step', 'step', 'proof', 'xb', 'http', 'http', 'http', 'http', 'http', 'http', 'http', 'http', 'http', 'http', 'http', 'http', 'http', 'http', 'http', 'http', 'http', 'preview', 'redd', 'szdhd', 'png', 'width', 'format', 'png', 'auto', 'webp', 'efddbebdafbeaceec']"
193,209,209,rebataur,vmlu60,[p] RestifyML - AI/ML Tool for Developers to quickly experiment with data and generate AI/ML REST API to consume back into their application," Developers can use RestifyML to

* Create DataScience experiments
* Create Data Source and upload CSV data within the experiment
* Do Data Cleansing and Sanitization
* Visualize raw data using Data Exploration
* Select Features which would help in building models
* Build Model, save or export them
* Finally, deploy Model and expose them as REST API
* Consume Machine Learning REST API from any Application
* Profit!

[https://github.com/rebataur/RestifyML](https://github.com/rebataur/RestifyML)

Feedback/ Feature Request appreciated.",6,3,2022-06-28 17:44:46, p  restifyml   ai ml tool for developers to quickly experiment with data and generate ai ml rest api to consume back into their application, developers can use restifyml to  create datascience experiments  create data source and upload csv data within the experiment  do data cleansing and sanitization  visualize raw data using data exploration  select features which would help in building models  build model  save or export them  finally  deploy model and expose them as rest api  consume machine learning rest api from any application  profit  https feedback  feature request appreciated ,developers use restifyml create datascience experiments create data source upload csv data within experiment data cleansing sanitization visualize raw data using data exploration select features would help building models build model save export finally deploy model expose rest api consume machine learning rest api application profit https feedback feature request appreciated,p restifyml ai ml tool developers quickly experiment data generate ai ml rest api consume back application,p restifyml ai ml tool developers quickly experiment data generate ai ml rest api consume back applicationdevelopers use restifyml create datascience experiments create data source upload csv data within experiment data cleansing sanitization visualize raw data using data exploration select features would help building models build model save export finally deploy model expose rest api consume machine learning rest api application profit https feedback feature request appreciated,"['p', 'restifyml', 'ai', 'ml', 'tool', 'developers', 'quickly', 'experiment', 'data', 'generate', 'ai', 'ml', 'rest', 'api', 'consume', 'back', 'applicationdevelopers', 'use', 'restifyml', 'create', 'datascience', 'experiments', 'create', 'data', 'source', 'upload', 'csv', 'data', 'within', 'experiment', 'data', 'cleansing', 'sanitization', 'visualize', 'raw', 'data', 'using', 'data', 'exploration', 'select', 'features', 'would', 'help', 'building', 'models', 'build', 'model', 'save', 'export', 'finally', 'deploy', 'model', 'expose', 'rest', 'api', 'consume', 'machine', 'learning', 'rest', 'api', 'application', 'profit', 'https', 'feedback', 'feature', 'request', 'appreciated']","['p', 'restifyml', 'ai', 'ml', 'tool', 'develop', 'quickli', 'experi', 'data', 'gener', 'ai', 'ml', 'rest', 'api', 'consum', 'back', 'applicationdevelop', 'use', 'restifyml', 'creat', 'datasci', 'experi', 'creat', 'data', 'sourc', 'upload', 'csv', 'data', 'within', 'experi', 'data', 'cleans', 'sanit', 'visual', 'raw', 'data', 'use', 'data', 'explor', 'select', 'featur', 'would', 'help', 'build', 'model', 'build', 'model', 'save', 'export', 'final', 'deploy', 'model', 'expos', 'rest', 'api', 'consum', 'machin', 'learn', 'rest', 'api', 'applic', 'profit', 'http', 'feedback', 'featur', 'request', 'appreci']"
194,210,210,shreyansh26,vmszee,[R] Annotated KDD 2022 paper - Learning Backward Compatible Embeddings," I read a super interesting KDD 2022 paper recently - ""Learning Backward Compatible Embeddings"".

The paper tackles a common industry problem of ensuring compatibility of newer embeddings with an older downstream model.

An annotated version of the paper - [Annotated-ML-Papers/Learning Backward Compatible Embeddings.pdf](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/General-DL/Learning%20Backward%20Compatible%20Embeddings.pdf)",0,0,2022-06-28 23:12:26, r  annotated kdd  paper   learning backward compatible embeddings, i read a super interesting kdd  paper recently   learning backward compatible embeddings the paper tackles a common industry problem of ensuring compatibility of newer embeddings with an older downstream model an annotated version of the paper    annotated ml papers learning backward compatible embeddings pdf  https   github com shreyansh annotated ml papers blob main general dl learning backward compatible embeddings pdf ,read super interesting kdd paper recently learning backward compatible embeddings paper tackles common industry problem ensuring compatibility newer embeddings older downstream model annotated version paper annotated ml papers learning backward compatible embeddings pdf https github com shreyansh annotated ml papers blob main general dl learning backward compatible embeddings pdf,r annotated kdd paper learning backward compatible embeddings,r annotated kdd paper learning backward compatible embeddingsread super interesting kdd paper recently learning backward compatible embeddings paper tackles common industry problem ensuring compatibility newer embeddings older downstream model annotated version paper annotated ml papers learning backward compatible embeddings pdf https github com shreyansh annotated ml papers blob main general dl learning backward compatible embeddings pdf,"['r', 'annotated', 'kdd', 'paper', 'learning', 'backward', 'compatible', 'embeddingsread', 'super', 'interesting', 'kdd', 'paper', 'recently', 'learning', 'backward', 'compatible', 'embeddings', 'paper', 'tackles', 'common', 'industry', 'problem', 'ensuring', 'compatibility', 'newer', 'embeddings', 'older', 'downstream', 'model', 'annotated', 'version', 'paper', 'annotated', 'ml', 'papers', 'learning', 'backward', 'compatible', 'embeddings', 'pdf', 'https', 'github', 'com', 'shreyansh', 'annotated', 'ml', 'papers', 'blob', 'main', 'general', 'dl', 'learning', 'backward', 'compatible', 'embeddings', 'pdf']","['r', 'annot', 'kdd', 'paper', 'learn', 'backward', 'compat', 'embeddingsread', 'super', 'interest', 'kdd', 'paper', 'recent', 'learn', 'backward', 'compat', 'embed', 'paper', 'tackl', 'common', 'industri', 'problem', 'ensur', 'compat', 'newer', 'embed', 'older', 'downstream', 'model', 'annot', 'version', 'paper', 'annot', 'ml', 'paper', 'learn', 'backward', 'compat', 'embed', 'pdf', 'http', 'github', 'com', 'shreyansh', 'annot', 'ml', 'paper', 'blob', 'main', 'gener', 'dl', 'learn', 'backward', 'compat', 'embed', 'pdf']"
195,211,211,cheptsov,vmroly,[D] Run apps and dev environments in the cloud with a single command,"Hi everyone,  


I'm the creator of dstack, a tool that makes it easier to train models in the cloud. Our tool allows extending it with custom providers to support different languages, frameworks, etc.  
All the built-in providers are also open-source. Today, we've released a new update that extends the capabilities of dstack beyond training models, and now also allows users to quickly build and share apps with Streamlit, Gradio, and FastAPI in the cloud – in just a few clicks.  
Similar to apps, it's possible to run dev environments with required hardware and data access also in one command from the Terminal. All you have to do is to link your own AWS account to run commands.  


Invite everyone to read it, and share their thoughts. Happy to discuss the approach and what would be great to have!

Blog post: [https://blog.dstack.ai/introducing-apps-and-dev-environments](https://blog.dstack.ai/introducing-apps-and-dev-environments)  


P.S.: Currently, it's possible to run models and apps only in the configured cloud. If you'd like the tool to also allow you to run it locally, and if you would like this part to be open-source too, please leave comments! 🤗",0,0,2022-06-28 22:15:29, d  run apps and dev environments in the cloud with a single command,hi everyone   i m the creator of dstack  a tool that makes it easier to train models in the cloud  our tool allows extending it with custom providers to support different languages  frameworks  etc   all the built in providers are also open source  today  we ve released a new update that extends the capabilities of dstack beyond training models  and now also allows users to quickly build and share apps with streamlit  gradio  and fastapi in the cloud   in just a few clicks   similar to apps  it s possible to run dev environments with required hardware and data access also in one command from the terminal  all you have to do is to link your own aws account to run commands   invite everyone to read it  and share their thoughts  happy to discuss the approach and what would be great to have blog post   https p s   currently  it s possible to run models and apps only in the configured cloud  if you d like the tool to also allow you to run it locally  and if you would like this part to be open source too  please leave comments   ,hi everyone creator dstack tool makes easier train models cloud tool allows extending providers support different languages frameworks etc built providers also open source today released update extends capabilities dstack beyond training models also allows users quickly build share apps streamlit gradio fastapi cloud clicks similar apps possible run dev environments required hardware data access also one command terminal link aws account run commands invite everyone read share thoughts happy discuss approach would great blog post https p currently possible run models apps configured cloud like tool also allow run locally would like part open source please leave comments,run apps dev environments cloud single command,run apps dev environments cloud single commandhi everyone creator dstack tool makes easier train models cloud tool allows extending providers support different languages frameworks etc built providers also open source today released update extends capabilities dstack beyond training models also allows users quickly build share apps streamlit gradio fastapi cloud clicks similar apps possible run dev environments required hardware data access also one command terminal link aws account run commands invite everyone read share thoughts happy discuss approach would great blog post https p currently possible run models apps configured cloud like tool also allow run locally would like part open source please leave comments,"['run', 'apps', 'dev', 'environments', 'cloud', 'single', 'commandhi', 'everyone', 'creator', 'dstack', 'tool', 'makes', 'easier', 'train', 'models', 'cloud', 'tool', 'allows', 'extending', 'providers', 'support', 'different', 'languages', 'frameworks', 'etc', 'built', 'providers', 'also', 'open', 'source', 'today', 'released', 'update', 'extends', 'capabilities', 'dstack', 'beyond', 'training', 'models', 'also', 'allows', 'users', 'quickly', 'build', 'share', 'apps', 'streamlit', 'gradio', 'fastapi', 'cloud', 'clicks', 'similar', 'apps', 'possible', 'run', 'dev', 'environments', 'required', 'hardware', 'data', 'access', 'also', 'one', 'command', 'terminal', 'link', 'aws', 'account', 'run', 'commands', 'invite', 'everyone', 'read', 'share', 'thoughts', 'happy', 'discuss', 'approach', 'would', 'great', 'blog', 'post', 'https', 'p', 'currently', 'possible', 'run', 'models', 'apps', 'configured', 'cloud', 'like', 'tool', 'also', 'allow', 'run', 'locally', 'would', 'like', 'part', 'open', 'source', 'please', 'leave', 'comments']","['run', 'app', 'dev', 'environ', 'cloud', 'singl', 'commandhi', 'everyon', 'creator', 'dstack', 'tool', 'make', 'easier', 'train', 'model', 'cloud', 'tool', 'allow', 'extend', 'provid', 'support', 'differ', 'languag', 'framework', 'etc', 'built', 'provid', 'also', 'open', 'sourc', 'today', 'releas', 'updat', 'extend', 'capabl', 'dstack', 'beyond', 'train', 'model', 'also', 'allow', 'user', 'quickli', 'build', 'share', 'app', 'streamlit', 'gradio', 'fastapi', 'cloud', 'click', 'similar', 'app', 'possibl', 'run', 'dev', 'environ', 'requir', 'hardwar', 'data', 'access', 'also', 'one', 'command', 'termin', 'link', 'aw', 'account', 'run', 'command', 'invit', 'everyon', 'read', 'share', 'thought', 'happi', 'discuss', 'approach', 'would', 'great', 'blog', 'post', 'http', 'p', 'current', 'possibl', 'run', 'model', 'app', 'configur', 'cloud', 'like', 'tool', 'also', 'allow', 'run', 'local', 'would', 'like', 'part', 'open', 'sourc', 'pleas', 'leav', 'comment']"
196,213,213,programmerChilli,vmabau,[P] First-class Dims - a generalization of einops and named tensors,"Jupyter Notebook: https://colab.research.google.com/drive/1BsVkddtVMX35aZAvo2GyI-wSFPVBCWuA

Github: https://github.com/facebookresearch/torchdim

Some tweet threads about it

Mine: https://twitter.com/cHHillee/status/1541536627746426881

Sasha Rush: https://twitter.com/srush_nlp/status/1541526906113298433",1,14,2022-06-28 06:24:33, p  first class dims   a generalization of einops and named tensors,jupyter notebook  https github  https some tweet threads about itmine  https sasha rush  https   twitter com srush_nlp status ,jupyter notebook https github https tweet threads itmine https sasha rush https twitter com srush_nlp status,p first class dims generalization einops named tensors,p first class dims generalization einops named tensorsjupyter notebook https github https tweet threads itmine https sasha rush https twitter com srush_nlp status,"['p', 'first', 'class', 'dims', 'generalization', 'einops', 'named', 'tensorsjupyter', 'notebook', 'https', 'github', 'https', 'tweet', 'threads', 'itmine', 'https', 'sasha', 'rush', 'https', 'twitter', 'com', 'srush_nlp', 'status']","['p', 'first', 'class', 'dim', 'gener', 'einop', 'name', 'tensorsjupyt', 'notebook', 'http', 'github', 'http', 'tweet', 'thread', 'itmin', 'http', 'sasha', 'rush', 'http', 'twitter', 'com', 'srush_nlp', 'statu']"
197,214,214,-aplusib-,vm5a72,[R] Theoretical Open Research Areas,"Hello everyone,

my goal is to do research in the field of machine learning for motion planning/robotics in general. I'm really interested in the theoretical/mathematical side of the field. However I noticed that the majority of the field consists of very experimental papers where architectures are built and bench-marked without any thorough underlying theory.

So my questions is: Are there any theoretical research areas in machine learning for motion planning/robotics in general?

It would be nice if someone could also give me some labs/researchers working in that direction.

&#x200B;

Thank you very much.",9,14,2022-06-28 02:07:15, r  theoretical open research areas,hello everyone my goal is to do research in the field of machine learning for motion planning robotics in general  i m really interested in the theoretical mathematical side of the field  however i noticed that the majority of the field consists of very experimental papers where architectures are built and bench marked without any thorough underlying theory so my questions is  are there any theoretical research areas in machine learning for motion planning robotics in general it would be nice if someone could also give me some labs researchers working in that direction   xb thank you very much ,hello everyone goal research field machine learning motion planning robotics general really interested theoretical mathematical side field however noticed majority field consists experimental papers architectures built bench marked without thorough underlying theory questions theoretical research areas machine learning motion planning robotics general would nice someone could also give labs researchers working direction xb thank much,r theoretical open research areas,r theoretical open research areashello everyone goal research field machine learning motion planning robotics general really interested theoretical mathematical side field however noticed majority field consists experimental papers architectures built bench marked without thorough underlying theory questions theoretical research areas machine learning motion planning robotics general would nice someone could also give labs researchers working direction xb thank much,"['r', 'theoretical', 'open', 'research', 'areashello', 'everyone', 'goal', 'research', 'field', 'machine', 'learning', 'motion', 'planning', 'robotics', 'general', 'really', 'interested', 'theoretical', 'mathematical', 'side', 'field', 'however', 'noticed', 'majority', 'field', 'consists', 'experimental', 'papers', 'architectures', 'built', 'bench', 'marked', 'without', 'thorough', 'underlying', 'theory', 'questions', 'theoretical', 'research', 'areas', 'machine', 'learning', 'motion', 'planning', 'robotics', 'general', 'would', 'nice', 'someone', 'could', 'also', 'give', 'labs', 'researchers', 'working', 'direction', 'xb', 'thank', 'much']","['r', 'theoret', 'open', 'research', 'areashello', 'everyon', 'goal', 'research', 'field', 'machin', 'learn', 'motion', 'plan', 'robot', 'gener', 'realli', 'interest', 'theoret', 'mathemat', 'side', 'field', 'howev', 'notic', 'major', 'field', 'consist', 'experiment', 'paper', 'architectur', 'built', 'bench', 'mark', 'without', 'thorough', 'underli', 'theori', 'question', 'theoret', 'research', 'area', 'machin', 'learn', 'motion', 'plan', 'robot', 'gener', 'would', 'nice', 'someon', 'could', 'also', 'give', 'lab', 'research', 'work', 'direct', 'xb', 'thank', 'much']"
198,215,215,time_waster103,vmjkun,[D] How would you build a scalable platform for Machine Learning for Data Streams,"Recently I came across the idea of online machine learning where the model learns in real time from streaming data. I was wondering what would be an ideal solution be to deal with the varying rate at which data might arrive. More specifically, having a fixed number of VMs in the cloud to train the model in real time might result in underutilization of resources or lack of enough resources. So how should we design an end to end system for such a scenario? Do any of the cloud service providers already have an off the shelf solution for this?",0,0,2022-06-28 15:31:57, d  how would you build a scalable platform for machine learning for data streams,recently i came across the idea of online machine learning where the model learns in real time from streaming data  i was wondering what would be an ideal solution be to deal with the varying rate at which data might arrive  more specifically  having a fixed number of vms in the cloud to train the model in real time might result in underutilization of resources or lack of enough resources  so how should we design an end to end system for such a scenario  do any of the cloud service providers already have an off the shelf solution for this ,recently came across idea online machine learning model learns real time streaming data wondering would ideal solution deal varying rate data might arrive specifically fixed number vms cloud train model real time might result underutilization resources lack enough resources design end end system scenario cloud service providers already shelf solution,would build scalable platform machine learning data streams,would build scalable platform machine learning data streamsrecently came across idea online machine learning model learns real time streaming data wondering would ideal solution deal varying rate data might arrive specifically fixed number vms cloud train model real time might result underutilization resources lack enough resources design end end system scenario cloud service providers already shelf solution,"['would', 'build', 'scalable', 'platform', 'machine', 'learning', 'data', 'streamsrecently', 'came', 'across', 'idea', 'online', 'machine', 'learning', 'model', 'learns', 'real', 'time', 'streaming', 'data', 'wondering', 'would', 'ideal', 'solution', 'deal', 'varying', 'rate', 'data', 'might', 'arrive', 'specifically', 'fixed', 'number', 'vms', 'cloud', 'train', 'model', 'real', 'time', 'might', 'result', 'underutilization', 'resources', 'lack', 'enough', 'resources', 'design', 'end', 'end', 'system', 'scenario', 'cloud', 'service', 'providers', 'already', 'shelf', 'solution']","['would', 'build', 'scalabl', 'platform', 'machin', 'learn', 'data', 'streamsrec', 'came', 'across', 'idea', 'onlin', 'machin', 'learn', 'model', 'learn', 'real', 'time', 'stream', 'data', 'wonder', 'would', 'ideal', 'solut', 'deal', 'vari', 'rate', 'data', 'might', 'arriv', 'specif', 'fix', 'number', 'vm', 'cloud', 'train', 'model', 'real', 'time', 'might', 'result', 'underutil', 'resourc', 'lack', 'enough', 'resourc', 'design', 'end', 'end', 'system', 'scenario', 'cloud', 'servic', 'provid', 'alreadi', 'shelf', 'solut']"
199,216,216,Ierihon_hasty_ai,vmj52i,"[R] Data-centric AI development approach gives us 5,5-8% mAP on PASCAL VOC 2012","How important is clean data for how your AI models perform?

According to our [initial experiments](https://hasty.ai/content-hub/articles/cleaning-pascal-improving-map-by-13) \- very important. Two people improved the primary model metric by 13% in a week using state-of-the-art confidence learning to clean up PASCAL.

In the next iteration, we explore the field a bit deeper, trying to avoid controversy. SPOILER: we still get a nice mAP metric boost.

To learn more about the follow-up results and the plans for the future, check out our article: [https://hasty.ai/content-hub/articles/further-pascal-voc-2012-exploration-and-plans-for-the-future](https://hasty.ai/content-hub/articles/further-pascal-voc-2012-exploration-and-plans-for-the-future)

&#x200B;

Discussion of the initial results:

* [https://www.reddit.com/r/MachineLearning/comments/uc9z2y/p\_we\_cleaned\_up\_pascal\_and\_improved\_map\_by\_13/ia6caqg/?context=3](https://www.reddit.com/r/MachineLearning/comments/uc9z2y/p_we_cleaned_up_pascal_and_improved_map_by_13/ia6caqg/?context=3)
* [https://www.reddit.com/r/computervision/comments/uc9x8t/we\_cleaned\_up\_pascal\_and\_improved\_map\_by\_13/i69iyii/?utm\_source=share&utm\_medium=web2x&context=3](https://www.reddit.com/r/computervision/comments/uc9x8t/we_cleaned_up_pascal_and_improved_map_by_13/i69iyii/?utm_source=share&utm_medium=web2x&context=3)

&#x200B;

[Disclaimer: We used our own platform to clean up the data and the article, therefore, contains self-promotion. However, the article mainly focuses on the results we achieved.](https://preview.redd.it/5kzxfe440c891.png?width=1978&format=png&auto=webp&s=b2521ee17d6542256e16af94972fc2378476178e)",0,0,2022-06-28 15:02:53, r  data centric ai development approach gives us     map on pascal voc ,how important is clean data for how your ai models perform according to our  initial experiments  https in the next iteration  we explore the field a bit deeper  trying to avoid controversy  spoiler  we still get a nice map metric boost to learn more about the follow up results and the plans for the future  check out our article   https   xb discussion of the initial results    https    https   xb  disclaimer  we used our own platform to clean up the data and the article  therefore  contains self promotion  however  the article mainly focuses on the results we achieved   https   preview redd it kzxfec png width  format png auto webp s beedeaffce ,important clean data ai models perform according initial experiments https next iteration explore field bit deeper trying avoid controversy spoiler still get nice map metric boost learn follow results plans future check article https xb discussion initial results https https xb disclaimer used platform clean data article therefore contains self promotion however article mainly focuses results achieved https preview redd kzxfec png width format png auto webp beedeaffce,r data centric ai development approach gives us map pascal voc,r data centric ai development approach gives us map pascal vocimportant clean data ai models perform according initial experiments https next iteration explore field bit deeper trying avoid controversy spoiler still get nice map metric boost learn follow results plans future check article https xb discussion initial results https https xb disclaimer used platform clean data article therefore contains self promotion however article mainly focuses results achieved https preview redd kzxfec png width format png auto webp beedeaffce,"['r', 'data', 'centric', 'ai', 'development', 'approach', 'gives', 'us', 'map', 'pascal', 'vocimportant', 'clean', 'data', 'ai', 'models', 'perform', 'according', 'initial', 'experiments', 'https', 'next', 'iteration', 'explore', 'field', 'bit', 'deeper', 'trying', 'avoid', 'controversy', 'spoiler', 'still', 'get', 'nice', 'map', 'metric', 'boost', 'learn', 'follow', 'results', 'plans', 'future', 'check', 'article', 'https', 'xb', 'discussion', 'initial', 'results', 'https', 'https', 'xb', 'disclaimer', 'used', 'platform', 'clean', 'data', 'article', 'therefore', 'contains', 'self', 'promotion', 'however', 'article', 'mainly', 'focuses', 'results', 'achieved', 'https', 'preview', 'redd', 'kzxfec', 'png', 'width', 'format', 'png', 'auto', 'webp', 'beedeaffce']","['r', 'data', 'centric', 'ai', 'develop', 'approach', 'give', 'us', 'map', 'pascal', 'vocimport', 'clean', 'data', 'ai', 'model', 'perform', 'accord', 'initi', 'experi', 'http', 'next', 'iter', 'explor', 'field', 'bit', 'deeper', 'tri', 'avoid', 'controversi', 'spoiler', 'still', 'get', 'nice', 'map', 'metric', 'boost', 'learn', 'follow', 'result', 'plan', 'futur', 'check', 'articl', 'http', 'xb', 'discuss', 'initi', 'result', 'http', 'http', 'xb', 'disclaim', 'use', 'platform', 'clean', 'data', 'articl', 'therefor', 'contain', 'self', 'promot', 'howev', 'articl', 'mainli', 'focus', 'result', 'achiev', 'http', 'preview', 'redd', 'kzxfec', 'png', 'width', 'format', 'png', 'auto', 'webp', 'beedeaffc']"
200,217,217,fishiwhj,vma4il,[D] How to evaluate the gain of a new feature without training?,"When evaluating the effectiveness of a new feature, it is common to train a model with/without this feature to compare the difference. But sometimes training a model based on huge amounts of data is both time and energy consuming. I was wondering if there are some lightweight ways to estimate the importance of the new feature without training? Computing *descriptive statistics* such as feature coverage, histogram and correlation matrix might be necessary, are there other pre-processing methods?",2,3,2022-06-28 06:14:47, d  how to evaluate the gain of a new feature without training ,when evaluating the effectiveness of a new feature  it is common to train a model with without this feature to compare the difference  but sometimes training a model based on huge amounts of data is both time and energy consuming  i was wondering if there are some lightweight ways to estimate the importance of the new feature without training  computing  descriptive statistics  such as feature coverage  histogram and correlation matrix might be necessary  are there other pre processing methods ,evaluating effectiveness feature common train model without feature compare difference sometimes training model based huge amounts data time energy consuming wondering lightweight ways estimate importance feature without training computing descriptive statistics feature coverage histogram correlation matrix might necessary pre processing methods,evaluate gain feature without training,evaluate gain feature without trainingevaluating effectiveness feature common train model without feature compare difference sometimes training model based huge amounts data time energy consuming wondering lightweight ways estimate importance feature without training computing descriptive statistics feature coverage histogram correlation matrix might necessary pre processing methods,"['evaluate', 'gain', 'feature', 'without', 'trainingevaluating', 'effectiveness', 'feature', 'common', 'train', 'model', 'without', 'feature', 'compare', 'difference', 'sometimes', 'training', 'model', 'based', 'huge', 'amounts', 'data', 'time', 'energy', 'consuming', 'wondering', 'lightweight', 'ways', 'estimate', 'importance', 'feature', 'without', 'training', 'computing', 'descriptive', 'statistics', 'feature', 'coverage', 'histogram', 'correlation', 'matrix', 'might', 'necessary', 'pre', 'processing', 'methods']","['evalu', 'gain', 'featur', 'without', 'trainingevalu', 'effect', 'featur', 'common', 'train', 'model', 'without', 'featur', 'compar', 'differ', 'sometim', 'train', 'model', 'base', 'huge', 'amount', 'data', 'time', 'energi', 'consum', 'wonder', 'lightweight', 'way', 'estim', 'import', 'featur', 'without', 'train', 'comput', 'descript', 'statist', 'featur', 'coverag', 'histogram', 'correl', 'matrix', 'might', 'necessari', 'pre', 'process', 'method']"
201,218,218,vigneshwaranpersonal,vm010a,[D] Do you have any suggestions for a crowd-sourced annotation tool?,"We're currently doing research on computational social science, specifically on online toxicity. We have lots of text data, but we don't have annotations. As part of the research, we are thinking of annotating the text using a crowd-sourcing approach. Do any of you know of any open-source tool that we could employ to ease up the process?",5,6,2022-06-27 22:21:01, d  do you have any suggestions for a crowd sourced annotation tool ,we re currently doing research on computational social science  specifically on online toxicity  we have lots of text data  but we don t have annotations  as part of the research  we are thinking of annotating the text using a crowd sourcing approach  do any of you know of any open source tool that we could employ to ease up the process ,currently research computational social science specifically online toxicity lots text data annotations part research thinking annotating text using crowd sourcing approach know open source tool could employ ease process,suggestions crowd sourced annotation tool,suggestions crowd sourced annotation toolcurrently research computational social science specifically online toxicity lots text data annotations part research thinking annotating text using crowd sourcing approach know open source tool could employ ease process,"['suggestions', 'crowd', 'sourced', 'annotation', 'toolcurrently', 'research', 'computational', 'social', 'science', 'specifically', 'online', 'toxicity', 'lots', 'text', 'data', 'annotations', 'part', 'research', 'thinking', 'annotating', 'text', 'using', 'crowd', 'sourcing', 'approach', 'know', 'open', 'source', 'tool', 'could', 'employ', 'ease', 'process']","['suggest', 'crowd', 'sourc', 'annot', 'toolcurr', 'research', 'comput', 'social', 'scienc', 'specif', 'onlin', 'toxic', 'lot', 'text', 'data', 'annot', 'part', 'research', 'think', 'annot', 'text', 'use', 'crowd', 'sourc', 'approach', 'know', 'open', 'sourc', 'tool', 'could', 'employ', 'eas', 'process']"
202,219,219,KalloDotIO,vm2px5,[Discussion] [computer vision] Instant NeRF create quality depth maps?," Surprised I haven't seen more chatter about this. What do you  think about Nvidia's instant Nerf which turns 2d into 3d based on these techniques [https://arxiv.org/abs/2003.10016](https://arxiv.org/abs/2003.10016)

Does the output of a NeRF give a depth map that's comparable to what you'd get from a Kinect?

Can these be used to create 3D models one would use in Unreal or Blender?",3,5,2022-06-28 00:16:17, discussion   computer vision  instant nerf create quality depth maps , surprised i haven t seen more chatter about this  what do you  think about nvidia s instant nerf which turns d into d based on these techniques  https does the output of a nerf give a depth map that s comparable to what you d get from a kinect can these be used to create d models one would use in unreal or blender ,surprised seen chatter think nvidia instant nerf turns based techniques https output nerf give depth map comparable get kinect used create models one would use unreal blender,discussion computer vision instant nerf create quality depth maps,discussion computer vision instant nerf create quality depth mapssurprised seen chatter think nvidia instant nerf turns based techniques https output nerf give depth map comparable get kinect used create models one would use unreal blender,"['discussion', 'computer', 'vision', 'instant', 'nerf', 'create', 'quality', 'depth', 'mapssurprised', 'seen', 'chatter', 'think', 'nvidia', 'instant', 'nerf', 'turns', 'based', 'techniques', 'https', 'output', 'nerf', 'give', 'depth', 'map', 'comparable', 'get', 'kinect', 'used', 'create', 'models', 'one', 'would', 'use', 'unreal', 'blender']","['discuss', 'comput', 'vision', 'instant', 'nerf', 'creat', 'qualiti', 'depth', 'mapssurpris', 'seen', 'chatter', 'think', 'nvidia', 'instant', 'nerf', 'turn', 'base', 'techniqu', 'http', 'output', 'nerf', 'give', 'depth', 'map', 'compar', 'get', 'kinect', 'use', 'creat', 'model', 'one', 'would', 'use', 'unreal', 'blender']"
203,222,222,diabulusInMusica,vlr75m,[P] I published a tutorial about ML model deployment,"The deployment of ML models in production is a delicate process filled with challenges. You  can deploy a model via a REST API, on an edge device, or as as an  off-line unit used for batch processing. You can build the deployment  pipeline from scratch, or use ML deployment frameworks. 

In my new mini-series, you'll learn best practices to deploy your ML models. I  try to concentrate everything in 2 videos, to keep the series short and  sweet. 

The first video provides a theoretical overview of ML deployment. You'll learn about:

* Different strategies to deploy ML in production. 
* The main ML deployment tools on the market (TF Serving,  MLFlow Model, Seldon Deploy, KServe from Kubeflow). 
* BentoML and its features.  


Here's the video: [https://www.youtube.com/watch?v=Mrv3CZNWYEg](https://www.youtube.com/watch?v=Mrv3CZNWYEg)",2,18,2022-06-27 14:38:01, p  i published a tutorial about ml model deployment,the deployment of ml models in production is a delicate process filled with challenges  you  can deploy a model via a rest api  on an edge device  or as as an  off line unit used for batch processing  you can build the deployment  pipeline from scratch  or use ml deployment frameworks  in my new mini series  you ll learn best practices to deploy your ml models  i  try to concentrate everything in  videos  to keep the series short and  sweet  the first video provides a theoretical overview of ml deployment  you ll learn about   different strategies to deploy ml in production    the main ml deployment tools on the market  tf serving   mlflow model  seldon deploy  kserve from kubeflow     bentoml and its features   here s the video   https   www youtube com watch v mrvcznwyeg  https   www youtube com watch v mrvcznwyeg ,deployment ml models production delicate process filled challenges deploy model via rest api edge device line unit used batch processing build deployment pipeline scratch use ml deployment frameworks mini series learn best practices deploy ml models try concentrate everything videos keep series short sweet first video provides theoretical overview ml deployment learn different strategies deploy ml production main ml deployment tools market tf serving mlflow model seldon deploy kserve kubeflow bentoml features video https www youtube com watch v mrvcznwyeg https www youtube com watch v mrvcznwyeg,p published tutorial ml model deployment,p published tutorial ml model deploymentdeployment ml models production delicate process filled challenges deploy model via rest api edge device line unit used batch processing build deployment pipeline scratch use ml deployment frameworks mini series learn best practices deploy ml models try concentrate everything videos keep series short sweet first video provides theoretical overview ml deployment learn different strategies deploy ml production main ml deployment tools market tf serving mlflow model seldon deploy kserve kubeflow bentoml features video https www youtube com watch v mrvcznwyeg https www youtube com watch v mrvcznwyeg,"['p', 'published', 'tutorial', 'ml', 'model', 'deploymentdeployment', 'ml', 'models', 'production', 'delicate', 'process', 'filled', 'challenges', 'deploy', 'model', 'via', 'rest', 'api', 'edge', 'device', 'line', 'unit', 'used', 'batch', 'processing', 'build', 'deployment', 'pipeline', 'scratch', 'use', 'ml', 'deployment', 'frameworks', 'mini', 'series', 'learn', 'best', 'practices', 'deploy', 'ml', 'models', 'try', 'concentrate', 'everything', 'videos', 'keep', 'series', 'short', 'sweet', 'first', 'video', 'provides', 'theoretical', 'overview', 'ml', 'deployment', 'learn', 'different', 'strategies', 'deploy', 'ml', 'production', 'main', 'ml', 'deployment', 'tools', 'market', 'tf', 'serving', 'mlflow', 'model', 'seldon', 'deploy', 'kserve', 'kubeflow', 'bentoml', 'features', 'video', 'https', 'www', 'youtube', 'com', 'watch', 'v', 'mrvcznwyeg', 'https', 'www', 'youtube', 'com', 'watch', 'v', 'mrvcznwyeg']","['p', 'publish', 'tutori', 'ml', 'model', 'deploymentdeploy', 'ml', 'model', 'product', 'delic', 'process', 'fill', 'challeng', 'deploy', 'model', 'via', 'rest', 'api', 'edg', 'devic', 'line', 'unit', 'use', 'batch', 'process', 'build', 'deploy', 'pipelin', 'scratch', 'use', 'ml', 'deploy', 'framework', 'mini', 'seri', 'learn', 'best', 'practic', 'deploy', 'ml', 'model', 'tri', 'concentr', 'everyth', 'video', 'keep', 'seri', 'short', 'sweet', 'first', 'video', 'provid', 'theoret', 'overview', 'ml', 'deploy', 'learn', 'differ', 'strategi', 'deploy', 'ml', 'product', 'main', 'ml', 'deploy', 'tool', 'market', 'tf', 'serv', 'mlflow', 'model', 'seldon', 'deploy', 'kserv', 'kubeflow', 'bentoml', 'featur', 'video', 'http', 'www', 'youtub', 'com', 'watch', 'v', 'mrvcznwyeg', 'http', 'www', 'youtub', 'com', 'watch', 'v', 'mrvcznwyeg']"
204,223,223,icelebratefestivus,vlqu17,[D] Has anyone trained the latent diffusion models by OpenAI(CompVis)? Need some help,"EDIT: It was a problem with the  [sample\_diffusion.py](https://github.com/CompVis/latent-diffusion/blob/main/scripts/sample_diffusion.py) script at line 131.  the np.concatenate method needed an array, which I provided by enclosing the all\_images in \[\] 
`all_img = np.concatenate([all_images], axis=0)` 



I am trying to train a [latent-diffusion](https://github.com/CompVis/latent-diffusion) model by following the instructions on the repo, however I am running into errors while sampling from the checkpointed models. Can someone help?

I am getting Errors while trying to sample using [sample\_diffusion.py ](https://github.com/CompVis/latent-diffusion/blob/main/scripts/sample_diffusion.py)from a custom model trained on LSUN churches: 
```
File ""latent-diffusion/scripts/sample_diffusion.py"", line 309, in <module>run(model, imglogdir, eta=opt.eta,

ValueError: need at least one array to concatenate
```",12,11,2022-06-27 14:12:51, d  has anyone trained the latent diffusion models by openai compvis   need some help,edit  it was a problem with the   sample _diffusion py  https  all_img   np concatenate  all_images   axis    i am trying to train a  latent diffusion  https i am getting errors while trying to sample using  sample _diffusion py   https    file latent diffusion scripts sample_diffusion py  line   in run model  imglogdir  eta opt eta valueerror  need at least one array to concatenate   ,edit problem sample _diffusion py https all_img np concatenate all_images axis trying train latent diffusion https getting errors trying sample using sample _diffusion py https file latent diffusion scripts sample_diffusion py line run model imglogdir eta opt eta valueerror need least one array concatenate,anyone trained latent diffusion models openai compvis need help,anyone trained latent diffusion models openai compvis need helpedit problem sample _diffusion py https all_img np concatenate all_images axis trying train latent diffusion https getting errors trying sample using sample _diffusion py https file latent diffusion scripts sample_diffusion py line run model imglogdir eta opt eta valueerror need least one array concatenate,"['anyone', 'trained', 'latent', 'diffusion', 'models', 'openai', 'compvis', 'need', 'helpedit', 'problem', 'sample', '_diffusion', 'py', 'https', 'all_img', 'np', 'concatenate', 'all_images', 'axis', 'trying', 'train', 'latent', 'diffusion', 'https', 'getting', 'errors', 'trying', 'sample', 'using', 'sample', '_diffusion', 'py', 'https', 'file', 'latent', 'diffusion', 'scripts', 'sample_diffusion', 'py', 'line', 'run', 'model', 'imglogdir', 'eta', 'opt', 'eta', 'valueerror', 'need', 'least', 'one', 'array', 'concatenate']","['anyon', 'train', 'latent', 'diffus', 'model', 'openai', 'compvi', 'need', 'helpedit', 'problem', 'sampl', '_diffus', 'py', 'http', 'all_img', 'np', 'concaten', 'all_imag', 'axi', 'tri', 'train', 'latent', 'diffus', 'http', 'get', 'error', 'tri', 'sampl', 'use', 'sampl', '_diffus', 'py', 'http', 'file', 'latent', 'diffus', 'script', 'sample_diffus', 'py', 'line', 'run', 'model', 'imglogdir', 'eta', 'opt', 'eta', 'valueerror', 'need', 'least', 'one', 'array', 'concaten']"
205,224,224,OmOshIroIdEs,vm323i,[R] Can I use whole-protein embeddings on isolated domains?,"I'm interested in studying properties of particular protein domains. One idea is to take advantage of state-of-the-art protein embedding models, such as this, most of which are based on transformers.

Some of the domains I'm studying are found in large proteins, which have multiple other domains in the same chain. Therefore, I believe it might be more informative to obtain embeddings not of each protein as a whole, but just the domains. However, I worry that the embeddings would be all off, since the model expects a complete sequence.

Has anyone tried this before? Are the pre-trained domain-level embeddings?",0,1,2022-06-28 00:30:40, r  can i use whole protein embeddings on isolated domains ,i m interested in studying properties of particular protein domains  one idea is to take advantage of state of the art protein embedding models  such as this  most of which are based on transformers some of the domains i m studying are found in large proteins  which have multiple other domains in the same chain  therefore  i believe it might be more informative to obtain embeddings not of each protein as a whole  but just the domains  however  i worry that the embeddings would be all off  since the model expects a complete sequence has anyone tried this before  are the pre trained domain level embeddings ,interested studying properties particular protein domains one idea take advantage state art protein embedding models based transformers domains studying found large proteins multiple domains chain therefore believe might informative obtain embeddings protein whole domains however worry embeddings would since model expects complete sequence anyone tried pre trained domain level embeddings,r use whole protein embeddings isolated domains,r use whole protein embeddings isolated domainsinterested studying properties particular protein domains one idea take advantage state art protein embedding models based transformers domains studying found large proteins multiple domains chain therefore believe might informative obtain embeddings protein whole domains however worry embeddings would since model expects complete sequence anyone tried pre trained domain level embeddings,"['r', 'use', 'whole', 'protein', 'embeddings', 'isolated', 'domainsinterested', 'studying', 'properties', 'particular', 'protein', 'domains', 'one', 'idea', 'take', 'advantage', 'state', 'art', 'protein', 'embedding', 'models', 'based', 'transformers', 'domains', 'studying', 'found', 'large', 'proteins', 'multiple', 'domains', 'chain', 'therefore', 'believe', 'might', 'informative', 'obtain', 'embeddings', 'protein', 'whole', 'domains', 'however', 'worry', 'embeddings', 'would', 'since', 'model', 'expects', 'complete', 'sequence', 'anyone', 'tried', 'pre', 'trained', 'domain', 'level', 'embeddings']","['r', 'use', 'whole', 'protein', 'embed', 'isol', 'domainsinterest', 'studi', 'properti', 'particular', 'protein', 'domain', 'one', 'idea', 'take', 'advantag', 'state', 'art', 'protein', 'embed', 'model', 'base', 'transform', 'domain', 'studi', 'found', 'larg', 'protein', 'multipl', 'domain', 'chain', 'therefor', 'believ', 'might', 'inform', 'obtain', 'embed', 'protein', 'whole', 'domain', 'howev', 'worri', 'embed', 'would', 'sinc', 'model', 'expect', 'complet', 'sequenc', 'anyon', 'tri', 'pre', 'train', 'domain', 'level', 'embed']"
206,225,225,heylibrarian,vlm6yy,[D] State-of-the-art permutation-invariant graph embeddings,"Suppose I have a data set consisting of weighted undirected simple graphs. I would like to learn a vector representation of these graphs. What are the state-of-the-art (2022) architectures/methods for learning such representations? Ideally, the representations are permutation-invariant. For what it's worth, I am only interested in the case where graphs (vertices, edges, and their respective weights) are fully observed; I'm not interested cases unobserved nodes.

An additional requirement is the embedding must have a lower dimension that the number of nodes.",7,11,2022-06-27 09:15:19, d  state of the art permutation invariant graph embeddings,suppose i have a data set consisting of weighted undirected simple graphs  i would like to learn a vector representation of these graphs  what are the state of the art    architectures methods for learning such representations  ideally  the representations are permutation invariant  for what it s worth  i am only interested in the case where graphs  vertices  edges  and their respective weights  are fully observed  i m not interested cases unobserved nodes an additional requirement is the embedding must have a lower dimension that the number of nodes ,suppose data set consisting weighted undirected simple graphs would like learn vector representation graphs state art architectures methods learning representations ideally representations permutation invariant worth interested case graphs vertices edges respective weights fully observed interested cases unobserved nodes additional requirement embedding must lower dimension number nodes,state art permutation invariant graph embeddings,state art permutation invariant graph embeddingssuppose data set consisting weighted undirected simple graphs would like learn vector representation graphs state art architectures methods learning representations ideally representations permutation invariant worth interested case graphs vertices edges respective weights fully observed interested cases unobserved nodes additional requirement embedding must lower dimension number nodes,"['state', 'art', 'permutation', 'invariant', 'graph', 'embeddingssuppose', 'data', 'set', 'consisting', 'weighted', 'undirected', 'simple', 'graphs', 'would', 'like', 'learn', 'vector', 'representation', 'graphs', 'state', 'art', 'architectures', 'methods', 'learning', 'representations', 'ideally', 'representations', 'permutation', 'invariant', 'worth', 'interested', 'case', 'graphs', 'vertices', 'edges', 'respective', 'weights', 'fully', 'observed', 'interested', 'cases', 'unobserved', 'nodes', 'additional', 'requirement', 'embedding', 'must', 'lower', 'dimension', 'number', 'nodes']","['state', 'art', 'permut', 'invari', 'graph', 'embeddingssuppos', 'data', 'set', 'consist', 'weight', 'undirect', 'simpl', 'graph', 'would', 'like', 'learn', 'vector', 'represent', 'graph', 'state', 'art', 'architectur', 'method', 'learn', 'represent', 'ideal', 'represent', 'permut', 'invari', 'worth', 'interest', 'case', 'graph', 'vertic', 'edg', 'respect', 'weight', 'fulli', 'observ', 'interest', 'case', 'unobserv', 'node', 'addit', 'requir', 'embed', 'must', 'lower', 'dimens', 'number', 'node']"
207,226,226,baceituno,vlyjsf,[D] Stack - Seamless data collaboration and versioning,"Hey r/MachineLearning! We are the co-founders of Stack, a hub for data collaboration and versioning. We are developing this tool to help ML teams automatically track changes in their data seamlessly.

We are opening a waiting list for our beta, which we aim to release soon. You can sign up at: https://www.getstack.ai/

We are also actively looking for feedback. Feel free to share any comments or thoughts!",0,1,2022-06-27 21:18:07, d  stack   seamless data collaboration and versioning,hey r machinelearning  we are the co founders of stack  a hub for data collaboration and versioning  we are developing this tool to help ml teams automatically track changes in their data seamlessly we are opening a waiting list for our beta  which we aim to release soon  you can sign up at  https we are also actively looking for feedback  feel free to share any comments or thoughts ,hey r machinelearning co founders stack hub data collaboration versioning developing tool help ml teams automatically track changes data seamlessly opening waiting beta aim release soon sign https also actively looking feedback feel free share comments thoughts,stack seamless data collaboration versioning,stack seamless data collaboration versioninghey r machinelearning co founders stack hub data collaboration versioning developing tool help ml teams automatically track changes data seamlessly opening waiting beta aim release soon sign https also actively looking feedback feel free share comments thoughts,"['stack', 'seamless', 'data', 'collaboration', 'versioninghey', 'r', 'machinelearning', 'co', 'founders', 'stack', 'hub', 'data', 'collaboration', 'versioning', 'developing', 'tool', 'help', 'ml', 'teams', 'automatically', 'track', 'changes', 'data', 'seamlessly', 'opening', 'waiting', 'beta', 'aim', 'release', 'soon', 'sign', 'https', 'also', 'actively', 'looking', 'feedback', 'feel', 'free', 'share', 'comments', 'thoughts']","['stack', 'seamless', 'data', 'collabor', 'versioninghey', 'r', 'machinelearn', 'co', 'founder', 'stack', 'hub', 'data', 'collabor', 'version', 'develop', 'tool', 'help', 'ml', 'team', 'automat', 'track', 'chang', 'data', 'seamlessli', 'open', 'wait', 'beta', 'aim', 'releas', 'soon', 'sign', 'http', 'also', 'activ', 'look', 'feedback', 'feel', 'free', 'share', 'comment', 'thought']"
208,227,227,ykilcher,vlfz1v,[D] Paper Explained - Video PreTraining (VPT): Learning to Act by Watching Unlabeled Online Videos (Video Analysis),"[https://youtu.be/oz5yZc9ULAc](https://youtu.be/oz5yZc9ULAc)

Minecraft is one of the harder challenges any RL agent could face. Episodes are long, and the world is procedurally generated, complex, and huge. Further, the action space is a keyboard and a mouse, which has to be operated only given the game's video input. OpenAI tackles this challenge using Video PreTraining, leveraging a small set of contractor data in order to pseudo-label a giant corpus of scraped footage of gameplay. The pre-trained model is highly capable in basic game mechanics and can be fine-tuned much better than a blank slate model. This is the first Minecraft agent that achieves the elusive goal of crafting a diamond pickaxe all by itself.

&#x200B;

OUTLINE:

0:00 - Intro

3:50 - How to spend money most effectively?

8:20 - Getting a large dataset with labels

14:40 - Model architecture

19:20 - Experimental results and fine-tuning

25:40 - Reinforcement Learning to the Diamond Pickaxe

30:00 - Final comments and hardware

&#x200B;

Blog: [https://openai.com/blog/vpt/](https://openai.com/blog/vpt/)

Paper: [https://arxiv.org/abs/2206.11795](https://arxiv.org/abs/2206.11795)

Code & Model weights: [https://github.com/openai/Video-Pre-Training](https://github.com/openai/Video-Pre-Training)",0,23,2022-06-27 03:49:05, d  paper explained   video pretraining  vpt   learning to act by watching unlabeled online videos  video analysis , https minecraft is one of the harder challenges any rl agent could face  episodes are long  and the world is procedurally generated  complex  and huge  further  the action space is a keyboard and a mouse  which has to be operated only given the game s video input  openai tackles this challenge using video pretraining  leveraging a small set of contractor data in order to pseudo label a giant corpus of scraped footage of gameplay  the pre trained model is highly capable in basic game mechanics and can be fine tuned much better than a blank slate model  this is the first minecraft agent that achieves the elusive goal of crafting a diamond pickaxe all by itself   xb outline     intro    how to spend money most effectively     getting a large dataset with labels    model architecture    experimental results and fine tuning    reinforcement learning to the diamond pickaxe    final comments and hardware  xb blog   https paper   https code   model weights   https   github com openai video pre training  https   github com openai video pre training ,https minecraft one harder challenges rl agent could face episodes long world procedurally generated complex huge action space keyboard mouse operated given game video input openai tackles challenge using video pretraining leveraging small set contractor data order pseudo label giant corpus scraped footage gameplay pre trained model highly capable basic game mechanics fine tuned much better blank slate model first minecraft agent achieves elusive goal crafting diamond pickaxe xb outline intro spend money effectively getting large dataset labels model architecture experimental results fine tuning reinforcement learning diamond pickaxe final comments hardware xb blog https paper https code model weights https github com openai video pre training https github com openai video pre training,paper explained video pretraining vpt learning act watching unlabeled online videos video analysis,paper explained video pretraining vpt learning act watching unlabeled online videos video analysishttps minecraft one harder challenges rl agent could face episodes long world procedurally generated complex huge action space keyboard mouse operated given game video input openai tackles challenge using video pretraining leveraging small set contractor data order pseudo label giant corpus scraped footage gameplay pre trained model highly capable basic game mechanics fine tuned much better blank slate model first minecraft agent achieves elusive goal crafting diamond pickaxe xb outline intro spend money effectively getting large dataset labels model architecture experimental results fine tuning reinforcement learning diamond pickaxe final comments hardware xb blog https paper https code model weights https github com openai video pre training https github com openai video pre training,"['paper', 'explained', 'video', 'pretraining', 'vpt', 'learning', 'act', 'watching', 'unlabeled', 'online', 'videos', 'video', 'analysishttps', 'minecraft', 'one', 'harder', 'challenges', 'rl', 'agent', 'could', 'face', 'episodes', 'long', 'world', 'procedurally', 'generated', 'complex', 'huge', 'action', 'space', 'keyboard', 'mouse', 'operated', 'given', 'game', 'video', 'input', 'openai', 'tackles', 'challenge', 'using', 'video', 'pretraining', 'leveraging', 'small', 'set', 'contractor', 'data', 'order', 'pseudo', 'label', 'giant', 'corpus', 'scraped', 'footage', 'gameplay', 'pre', 'trained', 'model', 'highly', 'capable', 'basic', 'game', 'mechanics', 'fine', 'tuned', 'much', 'better', 'blank', 'slate', 'model', 'first', 'minecraft', 'agent', 'achieves', 'elusive', 'goal', 'crafting', 'diamond', 'pickaxe', 'xb', 'outline', 'intro', 'spend', 'money', 'effectively', 'getting', 'large', 'dataset', 'labels', 'model', 'architecture', 'experimental', 'results', 'fine', 'tuning', 'reinforcement', 'learning', 'diamond', 'pickaxe', 'final', 'comments', 'hardware', 'xb', 'blog', 'https', 'paper', 'https', 'code', 'model', 'weights', 'https', 'github', 'com', 'openai', 'video', 'pre', 'training', 'https', 'github', 'com', 'openai', 'video', 'pre', 'training']","['paper', 'explain', 'video', 'pretrain', 'vpt', 'learn', 'act', 'watch', 'unlabel', 'onlin', 'video', 'video', 'analysishttp', 'minecraft', 'one', 'harder', 'challeng', 'rl', 'agent', 'could', 'face', 'episod', 'long', 'world', 'procedur', 'gener', 'complex', 'huge', 'action', 'space', 'keyboard', 'mous', 'oper', 'given', 'game', 'video', 'input', 'openai', 'tackl', 'challeng', 'use', 'video', 'pretrain', 'leverag', 'small', 'set', 'contractor', 'data', 'order', 'pseudo', 'label', 'giant', 'corpu', 'scrape', 'footag', 'gameplay', 'pre', 'train', 'model', 'highli', 'capabl', 'basic', 'game', 'mechan', 'fine', 'tune', 'much', 'better', 'blank', 'slate', 'model', 'first', 'minecraft', 'agent', 'achiev', 'elus', 'goal', 'craft', 'diamond', 'pickax', 'xb', 'outlin', 'intro', 'spend', 'money', 'effect', 'get', 'larg', 'dataset', 'label', 'model', 'architectur', 'experiment', 'result', 'fine', 'tune', 'reinforc', 'learn', 'diamond', 'pickax', 'final', 'comment', 'hardwar', 'xb', 'blog', 'http', 'paper', 'http', 'code', 'model', 'weight', 'http', 'github', 'com', 'openai', 'video', 'pre', 'train', 'http', 'github', 'com', 'openai', 'video', 'pre', 'train']"
209,228,228,curiousML5,vljmxx,[P] Skipgram: neural network instead of lookup table,"I'm looking for papers which use the skipgram model but instead of a lookup table they use a neural network. The use case is instead of sentences of words I want to use sequences of human behavior where additional information is available, e.g. think sequences of visited Amazon products. Cold-start also happens to be very common and I'm thinking that using a neural network instead of lookup embeddings table would be better.

Updated with more context:

The typical usage of skip gram is for learning word embedding as in text where each word has an embedding which is learned through skipgram. However there is nothing limiting the usage of skipgram for non-text cases.

A popular way to use skipgram in i2i recommendation systems is to treat a session of products browsed by the user as a sequence and to have an embedding per product. (Eg see KDD 2018 winning paper from Airbnb) However, the question I have here is instead of having one embedding per product can we instead use a neural network where the output layer is the embedding layer. This way we can backprop through the neural network. The reason is we have more information for products than we do for words",4,3,2022-06-27 06:58:56, p  skipgram  neural network instead of lookup table,i m looking for papers which use the skipgram model but instead of a lookup table they use a neural network  the use case is instead of sentences of words i want to use sequences of human behavior where additional information is available  e g  think sequences of visited amazon products  cold start also happens to be very common and i m thinking that using a neural network instead of lookup embeddings table would be better updated with more context the typical usage of skip gram is for learning word embedding as in text where each word has an embedding which is learned through skipgram  however there is nothing limiting the usage of skipgram for non text cases a popular way to use skipgram in ii recommendation systems is to treat a session of products browsed by the user as a sequence and to have an embedding per product   eg see kdd  winning paper from airbnb  however  the question i have here is instead of having one embedding per product can we instead use a neural network where the output layer is the embedding layer  this way we can backprop through the neural network  the reason is we have more information for products than we do for words,looking papers use skipgram model instead lookup table use neural network use case instead sentences want use sequences human behavior additional information available e g think sequences visited amazon products cold start also happens common thinking using neural network instead lookup embeddings table would better updated context typical usage skip gram learning word embedding text word embedding learned skipgram however nothing limiting usage skipgram non text cases popular way use skipgram ii recommendation systems treat session products browsed user sequence embedding per product eg see kdd winning paper airbnb however question instead one embedding per product instead use neural network output layer embedding layer way backprop neural network reason information products,p skipgram neural network instead lookup table,p skipgram neural network instead lookup tablelooking papers use skipgram model instead lookup table use neural network use case instead sentences want use sequences human behavior additional information available e g think sequences visited amazon products cold start also happens common thinking using neural network instead lookup embeddings table would better updated context typical usage skip gram learning word embedding text word embedding learned skipgram however nothing limiting usage skipgram non text cases popular way use skipgram ii recommendation systems treat session products browsed user sequence embedding per product eg see kdd winning paper airbnb however question instead one embedding per product instead use neural network output layer embedding layer way backprop neural network reason information products,"['p', 'skipgram', 'neural', 'network', 'instead', 'lookup', 'tablelooking', 'papers', 'use', 'skipgram', 'model', 'instead', 'lookup', 'table', 'use', 'neural', 'network', 'use', 'case', 'instead', 'sentences', 'want', 'use', 'sequences', 'human', 'behavior', 'additional', 'information', 'available', 'e', 'g', 'think', 'sequences', 'visited', 'amazon', 'products', 'cold', 'start', 'also', 'happens', 'common', 'thinking', 'using', 'neural', 'network', 'instead', 'lookup', 'embeddings', 'table', 'would', 'better', 'updated', 'context', 'typical', 'usage', 'skip', 'gram', 'learning', 'word', 'embedding', 'text', 'word', 'embedding', 'learned', 'skipgram', 'however', 'nothing', 'limiting', 'usage', 'skipgram', 'non', 'text', 'cases', 'popular', 'way', 'use', 'skipgram', 'ii', 'recommendation', 'systems', 'treat', 'session', 'products', 'browsed', 'user', 'sequence', 'embedding', 'per', 'product', 'eg', 'see', 'kdd', 'winning', 'paper', 'airbnb', 'however', 'question', 'instead', 'one', 'embedding', 'per', 'product', 'instead', 'use', 'neural', 'network', 'output', 'layer', 'embedding', 'layer', 'way', 'backprop', 'neural', 'network', 'reason', 'information', 'products']","['p', 'skipgram', 'neural', 'network', 'instead', 'lookup', 'tablelook', 'paper', 'use', 'skipgram', 'model', 'instead', 'lookup', 'tabl', 'use', 'neural', 'network', 'use', 'case', 'instead', 'sentenc', 'want', 'use', 'sequenc', 'human', 'behavior', 'addit', 'inform', 'avail', 'e', 'g', 'think', 'sequenc', 'visit', 'amazon', 'product', 'cold', 'start', 'also', 'happen', 'common', 'think', 'use', 'neural', 'network', 'instead', 'lookup', 'embed', 'tabl', 'would', 'better', 'updat', 'context', 'typic', 'usag', 'skip', 'gram', 'learn', 'word', 'embed', 'text', 'word', 'embed', 'learn', 'skipgram', 'howev', 'noth', 'limit', 'usag', 'skipgram', 'non', 'text', 'case', 'popular', 'way', 'use', 'skipgram', 'ii', 'recommend', 'system', 'treat', 'session', 'product', 'brows', 'user', 'sequenc', 'embed', 'per', 'product', 'eg', 'see', 'kdd', 'win', 'paper', 'airbnb', 'howev', 'question', 'instead', 'one', 'embed', 'per', 'product', 'instead', 'use', 'neural', 'network', 'output', 'layer', 'embed', 'layer', 'way', 'backprop', 'neural', 'network', 'reason', 'inform', 'product']"
210,230,230,WigglyHypersurface,vlj0py,"[D] For perciever (IO) with single-channel audio, are position encodings even necessary?","I've been looking into using the Perciever for a project that involves single-channel (mono) audio. From the existing implementations and tutorials, I can't find one that only does audio. It seems like in the papers they rearrange the audio into patches and add position encodings, but this is a hack to bring the audio modality into the same size tensor as other modalities. If only using 1d audio is there any need at all for position encodings at all?",6,4,2022-06-27 06:26:12, d  for perciever  io  with single channel audio  are position encodings even necessary ,i ve been looking into using the perciever for a project that involves single channel  mono  audio  from the existing implementations and tutorials  i can t find one that only does audio  it seems like in the papers they rearrange the audio into patches and add position encodings  but this is a hack to bring the audio modality into the same size tensor as other modalities  if only using d audio is there any need at all for position encodings at all ,looking using perciever project involves single channel mono audio existing implementations tutorials find one audio seems like papers rearrange audio patches position encodings hack bring audio modality size tensor modalities using audio need position encodings,perciever io single channel audio position encodings even necessary,perciever io single channel audio position encodings even necessarylooking using perciever project involves single channel mono audio existing implementations tutorials find one audio seems like papers rearrange audio patches position encodings hack bring audio modality size tensor modalities using audio need position encodings,"['perciever', 'io', 'single', 'channel', 'audio', 'position', 'encodings', 'even', 'necessarylooking', 'using', 'perciever', 'project', 'involves', 'single', 'channel', 'mono', 'audio', 'existing', 'implementations', 'tutorials', 'find', 'one', 'audio', 'seems', 'like', 'papers', 'rearrange', 'audio', 'patches', 'position', 'encodings', 'hack', 'bring', 'audio', 'modality', 'size', 'tensor', 'modalities', 'using', 'audio', 'need', 'position', 'encodings']","['perciev', 'io', 'singl', 'channel', 'audio', 'posit', 'encod', 'even', 'necessarylook', 'use', 'perciev', 'project', 'involv', 'singl', 'channel', 'mono', 'audio', 'exist', 'implement', 'tutori', 'find', 'one', 'audio', 'seem', 'like', 'paper', 'rearrang', 'audio', 'patch', 'posit', 'encod', 'hack', 'bring', 'audio', 'modal', 'size', 'tensor', 'modal', 'use', 'audio', 'need', 'posit', 'encod']"
211,232,232,leboulevardier,vldjt5,[D] How to not commit code copyright violation with Github Co-pilot?,"At our work place, many of our ML researchers are starting to use Github Co-pilot to save time. Issue is there is no provenance on the code generated by Co-pilot. If I understand correctly, Co-pilot is trained on public GitHub repositories, many of which might have specific copyright and license clauses. Our research, when published, would also put the code on Github publicly.

What would you suggest to prevent potential code copyright violation in this case? I have sent request for Github to provide provenance tracking feature but I assume that's gonna take a while to implement (that is, if they decide to implement it). Are you using Github Co-pilot and worrying about similar issues?",6,4,2022-06-27 01:54:11, d  how to not commit code copyright violation with github co pilot ,at our work place  many of our ml researchers are starting to use github co pilot to save time  issue is there is no provenance on the code generated by co pilot  if i understand correctly  co pilot is trained on public github repositories  many of which might have specific copyright and license clauses  our research  when published  would also put the code on github publicly what would you suggest to prevent potential code copyright violation in this case  i have sent request for github to provide provenance tracking feature but i assume that s gonna take a while to implement  that is  if they decide to implement it   are you using github co pilot and worrying about similar issues ,work place many ml researchers starting use github co pilot save time issue provenance code generated co pilot understand correctly co pilot trained public github repositories many might specific copyright license clauses research published would also put code github publicly would suggest prevent potential code copyright violation case sent request github provide provenance tracking feature assume gonna take implement decide implement using github co pilot worrying similar issues,commit code copyright violation github co pilot,commit code copyright violation github co pilotwork place many ml researchers starting use github co pilot save time issue provenance code generated co pilot understand correctly co pilot trained public github repositories many might specific copyright license clauses research published would also put code github publicly would suggest prevent potential code copyright violation case sent request github provide provenance tracking feature assume gonna take implement decide implement using github co pilot worrying similar issues,"['commit', 'code', 'copyright', 'violation', 'github', 'co', 'pilotwork', 'place', 'many', 'ml', 'researchers', 'starting', 'use', 'github', 'co', 'pilot', 'save', 'time', 'issue', 'provenance', 'code', 'generated', 'co', 'pilot', 'understand', 'correctly', 'co', 'pilot', 'trained', 'public', 'github', 'repositories', 'many', 'might', 'specific', 'copyright', 'license', 'clauses', 'research', 'published', 'would', 'also', 'put', 'code', 'github', 'publicly', 'would', 'suggest', 'prevent', 'potential', 'code', 'copyright', 'violation', 'case', 'sent', 'request', 'github', 'provide', 'provenance', 'tracking', 'feature', 'assume', 'gon', 'na', 'take', 'implement', 'decide', 'implement', 'using', 'github', 'co', 'pilot', 'worrying', 'similar', 'issues']","['commit', 'code', 'copyright', 'violat', 'github', 'co', 'pilotwork', 'place', 'mani', 'ml', 'research', 'start', 'use', 'github', 'co', 'pilot', 'save', 'time', 'issu', 'proven', 'code', 'gener', 'co', 'pilot', 'understand', 'correctli', 'co', 'pilot', 'train', 'public', 'github', 'repositori', 'mani', 'might', 'specif', 'copyright', 'licens', 'claus', 'research', 'publish', 'would', 'also', 'put', 'code', 'github', 'publicli', 'would', 'suggest', 'prevent', 'potenti', 'code', 'copyright', 'violat', 'case', 'sent', 'request', 'github', 'provid', 'proven', 'track', 'featur', 'assum', 'gon', 'na', 'take', 'implement', 'decid', 'implement', 'use', 'github', 'co', 'pilot', 'worri', 'similar', 'issu']"
212,233,233,huehue9812,vl31d5,GMM latent space [D]," 

Hi, I would love to know if there is any ongoing work (or the latest) on mixture of Gaussians as latent space for GANs, or other generative models.

Does anyone have any experience on it and/or opinions on why it is not popular? (or doesn't work)",3,5,2022-06-26 17:20:39,gmm latent space  d , hi  i would love to know if there is any ongoing work  or the latest  on mixture of gaussians as latent space for gans  or other generative models does anyone have any experience on it and or opinions on why it is not popular   or doesn t work ,hi would love know ongoing work latest mixture gaussians latent space gans generative models anyone experience opinions popular work,gmm latent space,gmm latent spacehi would love know ongoing work latest mixture gaussians latent space gans generative models anyone experience opinions popular work,"['gmm', 'latent', 'spacehi', 'would', 'love', 'know', 'ongoing', 'work', 'latest', 'mixture', 'gaussians', 'latent', 'space', 'gans', 'generative', 'models', 'anyone', 'experience', 'opinions', 'popular', 'work']","['gmm', 'latent', 'spacehi', 'would', 'love', 'know', 'ongo', 'work', 'latest', 'mixtur', 'gaussian', 'latent', 'space', 'gan', 'gener', 'model', 'anyon', 'experi', 'opinion', 'popular', 'work']"
213,234,234,OddSandwich969,vl45a2,[Discussion] Doubt regarding text vector difference image manipulation method of Dalle-2.,"I was going through the (updated)paper, there was this image manipulation method through text difference.
It went like this:

z_i := original image CLIP embedding

z_t := new text CLIP embedding/ embedding of the text for current image manipulation

z_t0 := orignal image's corresponding text CLIP embedding/ text embedding of the text 'a photo' / empty embedding

z_d := l2_norm(z_t - z_t0) <-> text difference vector | 
Here l2_norm means, normalising a vector by dividing it with it's norm_p (here norm 2).

z_new /z_theta :=  spherical_interpolation(z_i, z_d, theta) {where theta is between (0,0.5)} <-> new image's CLIP embedding vector 


What I don't understand is, that the CLIP img and text embedding vectors are supposed to be similar vectors (since trained with cosine similarity), and the difference between text embedding vectors of two similar texts will be somewhat perpendicular to either of the text vectors, therefore the text diff vector should be very different from the image embedding, and hence the spherical interpolation shouldn't give any meaningful result.

What am I missing? I am unable to understand why this text difference method works.",6,5,2022-06-26 18:26:01, discussion  doubt regarding text vector difference image manipulation method of dalle  ,i was going through the  updated paper  there was this image manipulation method through text difference it went like this z_i    original image clip embeddingz_t    new text clip embedding  embedding of the text for current image manipulationz_t    orignal image s corresponding text clip embedding  text embedding of the text  a photo    empty embeddingz_d    l_norm z_t   z_t   text difference vector   here l_norm means  normalising a vector by dividing it with it s norm_p  here norm   z_new  z_theta     spherical_interpolation z_i  z_d  theta   where theta is between        new image s clip embedding vector what i don t understand is  that the clip img and text embedding vectors are supposed to be similar vectors  since trained with cosine similarity   and the difference between text embedding vectors of two similar texts will be somewhat perpendicular to either of the text vectors  therefore the text diff vector should be very different from the image embedding  and hence the spherical interpolation shouldn t give any meaningful result what am i missing  i am unable to understand why this text difference method works ,going updated paper image manipulation method text difference went like z_i original image clip embeddingz_t text clip embedding embedding text current image manipulationz_t orignal image corresponding text clip embedding text embedding text photo empty embeddingz_d l_norm z_t z_t text difference vector l_norm means normalising vector dividing norm_p norm z_new z_theta spherical_interpolation z_i z_d theta theta image clip embedding vector understand clip img text embedding vectors supposed similar vectors since trained cosine similarity difference text embedding vectors two similar texts somewhat perpendicular either text vectors therefore text diff vector different image embedding hence spherical interpolation give meaningful result missing unable understand text difference method works,discussion doubt regarding text vector difference image manipulation method dalle,discussion doubt regarding text vector difference image manipulation method dallegoing updated paper image manipulation method text difference went like z_i original image clip embeddingz_t text clip embedding embedding text current image manipulationz_t orignal image corresponding text clip embedding text embedding text photo empty embeddingz_d l_norm z_t z_t text difference vector l_norm means normalising vector dividing norm_p norm z_new z_theta spherical_interpolation z_i z_d theta theta image clip embedding vector understand clip img text embedding vectors supposed similar vectors since trained cosine similarity difference text embedding vectors two similar texts somewhat perpendicular either text vectors therefore text diff vector different image embedding hence spherical interpolation give meaningful result missing unable understand text difference method works,"['discussion', 'doubt', 'regarding', 'text', 'vector', 'difference', 'image', 'manipulation', 'method', 'dallegoing', 'updated', 'paper', 'image', 'manipulation', 'method', 'text', 'difference', 'went', 'like', 'z_i', 'original', 'image', 'clip', 'embeddingz_t', 'text', 'clip', 'embedding', 'embedding', 'text', 'current', 'image', 'manipulationz_t', 'orignal', 'image', 'corresponding', 'text', 'clip', 'embedding', 'text', 'embedding', 'text', 'photo', 'empty', 'embeddingz_d', 'l_norm', 'z_t', 'z_t', 'text', 'difference', 'vector', 'l_norm', 'means', 'normalising', 'vector', 'dividing', 'norm_p', 'norm', 'z_new', 'z_theta', 'spherical_interpolation', 'z_i', 'z_d', 'theta', 'theta', 'image', 'clip', 'embedding', 'vector', 'understand', 'clip', 'img', 'text', 'embedding', 'vectors', 'supposed', 'similar', 'vectors', 'since', 'trained', 'cosine', 'similarity', 'difference', 'text', 'embedding', 'vectors', 'two', 'similar', 'texts', 'somewhat', 'perpendicular', 'either', 'text', 'vectors', 'therefore', 'text', 'diff', 'vector', 'different', 'image', 'embedding', 'hence', 'spherical', 'interpolation', 'give', 'meaningful', 'result', 'missing', 'unable', 'understand', 'text', 'difference', 'method', 'works']","['discuss', 'doubt', 'regard', 'text', 'vector', 'differ', 'imag', 'manipul', 'method', 'dallego', 'updat', 'paper', 'imag', 'manipul', 'method', 'text', 'differ', 'went', 'like', 'z_i', 'origin', 'imag', 'clip', 'embeddingz_t', 'text', 'clip', 'embed', 'embed', 'text', 'current', 'imag', 'manipulationz_t', 'orign', 'imag', 'correspond', 'text', 'clip', 'embed', 'text', 'embed', 'text', 'photo', 'empti', 'embeddingz_d', 'l_norm', 'z_t', 'z_t', 'text', 'differ', 'vector', 'l_norm', 'mean', 'normalis', 'vector', 'divid', 'norm_p', 'norm', 'z_new', 'z_theta', 'spherical_interpol', 'z_i', 'z_d', 'theta', 'theta', 'imag', 'clip', 'embed', 'vector', 'understand', 'clip', 'img', 'text', 'embed', 'vector', 'suppos', 'similar', 'vector', 'sinc', 'train', 'cosin', 'similar', 'differ', 'text', 'embed', 'vector', 'two', 'similar', 'text', 'somewhat', 'perpendicular', 'either', 'text', 'vector', 'therefor', 'text', 'diff', 'vector', 'differ', 'imag', 'embed', 'henc', 'spheric', 'interpol', 'give', 'meaning', 'result', 'miss', 'unabl', 'understand', 'text', 'differ', 'method', 'work']"
214,235,235,DouBlindDotCOM,vlanqv,[D] Will this mode work for practicing paper reviews? Can we get in-depth feedback on our draft?," Some opinions were collected about mocking ML paper reviews. Link to the thread: [https://www.reddit.com/r/MachineLearning/comments/u967sy/d\_opinions\_needed\_anyone\_interested\_in\_mock\_peer/?utm\_source=share&utm\_medium=web2x&context=3](https://www.reddit.com/r/MachineLearning/comments/u967sy/d_opinions_needed_anyone_interested_in_mock_peer/?utm_source=share&utm_medium=web2x&context=3)

To summarize, many people are interested. Opinions are in common that:

1. People like private review rather than public review
2. Number of papers to review are not a concern but every couple months will be a good pace
3. Plagiarism and stealing are of course the biggest concern

To address this, I suggest the following mode:

1. ONLY opens for people who want to exchange paper reviews. Enthusiastic reviewers with no paper draft to be reviewed can wait.
2. ONLY opens for people who are really interested in mocking paper review prior to formal journal/conference submission. Join a Discord community (already established).
3. In the PRIVATE ""Introduce yourself"" channel, people introduce themselves using true information and offer a very brief paper abstract and ML category.
4. Chat openly or privately to find the right review partners
5. In the ""paper-review-exchange"" channel, announce your paper reviewer upon agreement (from both sides)
6. Exchange your drafts privately and preferably with official email addresses
7. (Optional) When the review work is done, announce it too.
8. Note that plagiarism and stealing can be minimized in this mode but still could happen.

When conference reviews do not offer much nowadays, a mockup review might give your more TRUE inputs. Good luck!",2,0,2022-06-26 23:38:07, d  will this mode work for practicing paper reviews  can we get in depth feedback on our draft , some opinions were collected about mocking ml paper reviews  link to the thread   https to summarize  many people are interested  opinions are in common that   people like private review rather than public review  number of papers to review are not a concern but every couple months will be a good pace  plagiarism and stealing are of course the biggest concernto address this  i suggest the following mode   only opens for people who want to exchange paper reviews  enthusiastic reviewers with no paper draft to be reviewed can wait   only opens for people who are really interested in mocking paper review prior to formal journal conference submission  join a discord community  already established    in the private introduce yourself channel  people introduce themselves using true information and offer a very brief paper abstract and ml category   chat openly or privately to find the right review partners  in the paper review exchange channel  announce your paper reviewer upon agreement  from both sides   exchange your drafts privately and preferably with official email addresses   optional  when the review work is done  announce it too   note that plagiarism and stealing can be minimized in this mode but still could happen when conference reviews do not offer much nowadays  a mockup review might give your more true inputs  good luck ,opinions collected mocking ml paper reviews link thread https summarize many people interested opinions common people like private review rather public review number papers review concern every couple months good pace plagiarism stealing course biggest concernto address suggest following mode opens people want exchange paper reviews enthusiastic reviewers paper draft reviewed wait opens people really interested mocking paper review prior formal journal conference submission join discord community already established private introduce channel people introduce using true information offer brief paper abstract ml category chat openly privately find right review partners paper review exchange channel announce paper reviewer upon agreement sides exchange drafts privately preferably official email addresses optional review work done announce note plagiarism stealing minimized mode still could happen conference reviews offer much nowadays mockup review might give true inputs good luck,mode work practicing paper reviews get depth feedback draft,mode work practicing paper reviews get depth feedback draftopinions collected mocking ml paper reviews link thread https summarize many people interested opinions common people like private review rather public review number papers review concern every couple months good pace plagiarism stealing course biggest concernto address suggest following mode opens people want exchange paper reviews enthusiastic reviewers paper draft reviewed wait opens people really interested mocking paper review prior formal journal conference submission join discord community already established private introduce channel people introduce using true information offer brief paper abstract ml category chat openly privately find right review partners paper review exchange channel announce paper reviewer upon agreement sides exchange drafts privately preferably official email addresses optional review work done announce note plagiarism stealing minimized mode still could happen conference reviews offer much nowadays mockup review might give true inputs good luck,"['mode', 'work', 'practicing', 'paper', 'reviews', 'get', 'depth', 'feedback', 'draftopinions', 'collected', 'mocking', 'ml', 'paper', 'reviews', 'link', 'thread', 'https', 'summarize', 'many', 'people', 'interested', 'opinions', 'common', 'people', 'like', 'private', 'review', 'rather', 'public', 'review', 'number', 'papers', 'review', 'concern', 'every', 'couple', 'months', 'good', 'pace', 'plagiarism', 'stealing', 'course', 'biggest', 'concernto', 'address', 'suggest', 'following', 'mode', 'opens', 'people', 'want', 'exchange', 'paper', 'reviews', 'enthusiastic', 'reviewers', 'paper', 'draft', 'reviewed', 'wait', 'opens', 'people', 'really', 'interested', 'mocking', 'paper', 'review', 'prior', 'formal', 'journal', 'conference', 'submission', 'join', 'discord', 'community', 'already', 'established', 'private', 'introduce', 'channel', 'people', 'introduce', 'using', 'true', 'information', 'offer', 'brief', 'paper', 'abstract', 'ml', 'category', 'chat', 'openly', 'privately', 'find', 'right', 'review', 'partners', 'paper', 'review', 'exchange', 'channel', 'announce', 'paper', 'reviewer', 'upon', 'agreement', 'sides', 'exchange', 'drafts', 'privately', 'preferably', 'official', 'email', 'addresses', 'optional', 'review', 'work', 'done', 'announce', 'note', 'plagiarism', 'stealing', 'minimized', 'mode', 'still', 'could', 'happen', 'conference', 'reviews', 'offer', 'much', 'nowadays', 'mockup', 'review', 'might', 'give', 'true', 'inputs', 'good', 'luck']","['mode', 'work', 'practic', 'paper', 'review', 'get', 'depth', 'feedback', 'draftopinion', 'collect', 'mock', 'ml', 'paper', 'review', 'link', 'thread', 'http', 'summar', 'mani', 'peopl', 'interest', 'opinion', 'common', 'peopl', 'like', 'privat', 'review', 'rather', 'public', 'review', 'number', 'paper', 'review', 'concern', 'everi', 'coupl', 'month', 'good', 'pace', 'plagiar', 'steal', 'cours', 'biggest', 'concernto', 'address', 'suggest', 'follow', 'mode', 'open', 'peopl', 'want', 'exchang', 'paper', 'review', 'enthusiast', 'review', 'paper', 'draft', 'review', 'wait', 'open', 'peopl', 'realli', 'interest', 'mock', 'paper', 'review', 'prior', 'formal', 'journal', 'confer', 'submiss', 'join', 'discord', 'commun', 'alreadi', 'establish', 'privat', 'introduc', 'channel', 'peopl', 'introduc', 'use', 'true', 'inform', 'offer', 'brief', 'paper', 'abstract', 'ml', 'categori', 'chat', 'openli', 'privat', 'find', 'right', 'review', 'partner', 'paper', 'review', 'exchang', 'channel', 'announc', 'paper', 'review', 'upon', 'agreement', 'side', 'exchang', 'draft', 'privat', 'prefer', 'offici', 'email', 'address', 'option', 'review', 'work', 'done', 'announc', 'note', 'plagiar', 'steal', 'minim', 'mode', 'still', 'could', 'happen', 'confer', 'review', 'offer', 'much', 'nowaday', 'mockup', 'review', 'might', 'give', 'true', 'input', 'good', 'luck']"
215,236,236,AshkanF,vlacrj,[R] Can explainability improve model accuracy?,"&#x200B;

https://preview.redd.it/okh7r16770891.jpg?width=1200&format=pjpg&auto=webp&s=9f0fe7605453a945682d27eab65d866dce3f126c

Black-box Deep learning models are mostly uninterpretable and far too complex.

• One strategy is to learn the nonlinear relation of input features.

However, there are so many features to learn from.

https://preview.redd.it/muotby5s70891.png?width=782&format=png&auto=webp&s=1cbc3dece747d061e3ab96dea8b309c3fae5b8ce

&#x200B;

• Research shows a set of important features can improve the learning process.

Therefore, we can focus on the most correlated features.

• Paper📜: [https://arxiv.org/abs/2203.04383](https://arxiv.org/abs/2203.04383)",1,1,2022-06-26 23:24:18, r  can explainability improve model accuracy ,  xb https black box deep learning models are mostly uninterpretable and far too complex   one strategy is to learn the nonlinear relation of input features however  there are so many features to learn from https   xb   research shows a set of important features can improve the learning process therefore  we can focus on the most correlated features   paper    https   arxiv org abs    https   arxiv org abs   ,xb https black box deep learning models mostly uninterpretable far complex one strategy learn nonlinear relation input features however many features learn https xb research shows set important features improve learning process therefore focus correlated features paper https arxiv org abs https arxiv org abs,r explainability improve model accuracy,r explainability improve model accuracyxb https black box deep learning models mostly uninterpretable far complex one strategy learn nonlinear relation input features however many features learn https xb research shows set important features improve learning process therefore focus correlated features paper https arxiv org abs https arxiv org abs,"['r', 'explainability', 'improve', 'model', 'accuracyxb', 'https', 'black', 'box', 'deep', 'learning', 'models', 'mostly', 'uninterpretable', 'far', 'complex', 'one', 'strategy', 'learn', 'nonlinear', 'relation', 'input', 'features', 'however', 'many', 'features', 'learn', 'https', 'xb', 'research', 'shows', 'set', 'important', 'features', 'improve', 'learning', 'process', 'therefore', 'focus', 'correlated', 'features', 'paper', 'https', 'arxiv', 'org', 'abs', 'https', 'arxiv', 'org', 'abs']","['r', 'explain', 'improv', 'model', 'accuracyxb', 'http', 'black', 'box', 'deep', 'learn', 'model', 'mostli', 'uninterpret', 'far', 'complex', 'one', 'strategi', 'learn', 'nonlinear', 'relat', 'input', 'featur', 'howev', 'mani', 'featur', 'learn', 'http', 'xb', 'research', 'show', 'set', 'import', 'featur', 'improv', 'learn', 'process', 'therefor', 'focu', 'correl', 'featur', 'paper', 'http', 'arxiv', 'org', 'ab', 'http', 'arxiv', 'org', 'ab']"
216,237,237,Ok-Seesaw9702,vl2r7q,[D] Derivation of path dependent attribution in Tree SHAP,"I was reading the TreeSHAP paper by Lundberg & Lee. There they propose that every path can be considered an individual model and due to additivity property of SHAP we can directly add the attributions for each path and that would give us the attribution for that tree.

I can understand till -

1. if a feature doesn't lie on the path then that feature's attribution for that path would be zero.
2. if feature lies on the path and also lies on the path of Xf then it's attribution is positive.
3. if feature lies on the path but doesn't lie on the path covered by Xf then attribution is negative.

But I can't get my head around the quantification of these contributions - especially the weighting.i.e., **POS = W(|Sp|-1, |Np|)\*v** ;  
**NEG = -W(|Sp, |Np|)\*v** ; where v is the leaf's update.

I have may questions, but to begin with, can someone please help me understand how do we get these attribution values ?",0,2,2022-06-26 17:02:53, d  derivation of path dependent attribution in tree shap,i was reading the treeshap paper by lundberg   lee  there they propose that every path can be considered an individual model and due to additivity property of shap we can directly add the attributions for each path and that would give us the attribution for that tree i can understand till    if a feature doesn t lie on the path then that feature s attribution for that path would be zero   if feature lies on the path and also lies on the path of xf then it s attribution is positive   if feature lies on the path but doesn t lie on the path covered by xf then attribution is negative but i can t get my head around the quantification of these contributions   especially the weighting i e     pos   w  sp     np    v        neg    w  sp   np    v     where v is the leaf s update i have may questions  but to begin with  can someone please help me understand how do we get these attribution values  ,reading treeshap paper lundberg lee propose every path considered individual model due additivity property shap directly attributions path would give us attribution tree understand till feature lie path feature attribution path would zero feature lies path also lies path xf attribution positive feature lies path lie path covered xf attribution negative get head around quantification contributions especially weighting e pos w sp np v neg w sp np v v leaf update may questions begin someone please help understand get attribution values,derivation path dependent attribution tree shap,derivation path dependent attribution tree shapreading treeshap paper lundberg lee propose every path considered individual model due additivity property shap directly attributions path would give us attribution tree understand till feature lie path feature attribution path would zero feature lies path also lies path xf attribution positive feature lies path lie path covered xf attribution negative get head around quantification contributions especially weighting e pos w sp np v neg w sp np v v leaf update may questions begin someone please help understand get attribution values,"['derivation', 'path', 'dependent', 'attribution', 'tree', 'shapreading', 'treeshap', 'paper', 'lundberg', 'lee', 'propose', 'every', 'path', 'considered', 'individual', 'model', 'due', 'additivity', 'property', 'shap', 'directly', 'attributions', 'path', 'would', 'give', 'us', 'attribution', 'tree', 'understand', 'till', 'feature', 'lie', 'path', 'feature', 'attribution', 'path', 'would', 'zero', 'feature', 'lies', 'path', 'also', 'lies', 'path', 'xf', 'attribution', 'positive', 'feature', 'lies', 'path', 'lie', 'path', 'covered', 'xf', 'attribution', 'negative', 'get', 'head', 'around', 'quantification', 'contributions', 'especially', 'weighting', 'e', 'pos', 'w', 'sp', 'np', 'v', 'neg', 'w', 'sp', 'np', 'v', 'v', 'leaf', 'update', 'may', 'questions', 'begin', 'someone', 'please', 'help', 'understand', 'get', 'attribution', 'values']","['deriv', 'path', 'depend', 'attribut', 'tree', 'shapread', 'treeshap', 'paper', 'lundberg', 'lee', 'propos', 'everi', 'path', 'consid', 'individu', 'model', 'due', 'addit', 'properti', 'shap', 'directli', 'attribut', 'path', 'would', 'give', 'us', 'attribut', 'tree', 'understand', 'till', 'featur', 'lie', 'path', 'featur', 'attribut', 'path', 'would', 'zero', 'featur', 'lie', 'path', 'also', 'lie', 'path', 'xf', 'attribut', 'posit', 'featur', 'lie', 'path', 'lie', 'path', 'cover', 'xf', 'attribut', 'neg', 'get', 'head', 'around', 'quantif', 'contribut', 'especi', 'weight', 'e', 'po', 'w', 'sp', 'np', 'v', 'neg', 'w', 'sp', 'np', 'v', 'v', 'leaf', 'updat', 'may', 'question', 'begin', 'someon', 'pleas', 'help', 'understand', 'get', 'attribut', 'valu']"
217,238,238,MurlocXYZ,vkp3y2,[D] Is it time to retire the FID?,"I know the main metric used to measure the quality of generative models is the FID. However, it seems to me that some problems arise when evaluating a generative model using another model. A couple that come to mind:
- Inception v3 itself is 7 years old at this point. Nowadays, we have models with much higher ImageNet classification accuracy, which presumably translates to better internal representations. Why are we still using Inception v3 instead of, for instance, ViT or some more recent model. 

- The ImageNet dataset that is commonly used to pretrain the Inceptionv3, while being quite comprehensive, is still limited to 1000 classes. If I want to train a model to generate classes that are semantically distant from ImageNet classes, what guarantees do I have that the activations of Inceptionv3 will be meaningful? This is more so problematic with models like DALL-E, which are trained on much larger datasets and can generate from the open set, essentially.

Perhaps I am misinterpreting things, but it seems to me that the FID is a case of ""good enough"" that sort of stuck around.

What are your thoughts?",7,27,2022-06-26 03:09:05, d  is it time to retire the fid ,i know the main metric used to measure the quality of generative models is the fid  however  it seems to me that some problems arise when evaluating a generative model using another model  a couple that come to mind   inception v itself is  years old at this point  nowadays  we have models with much higher imagenet classification accuracy  which presumably translates to better internal representations  why are we still using inception v instead of  for instance  vit or some more recent model    the imagenet dataset that is commonly used to pretrain the inceptionv  while being quite comprehensive  is still limited to  classes  if i want to train a model to generate classes that are semantically distant from imagenet classes  what guarantees do i have that the activations of inceptionv will be meaningful  this is more so problematic with models like dall e  which are trained on much larger datasets and can generate from the open set  essentially perhaps i am misinterpreting things  but it seems to me that the fid is a case of good enough that sort of stuck around what are your thoughts ,know main metric used measure quality generative models fid however seems problems arise evaluating generative model using another model couple come mind inception v years old point nowadays models much higher imagenet classification accuracy presumably translates better internal representations still using inception v instead instance vit recent model imagenet dataset commonly used pretrain inceptionv quite comprehensive still limited classes want train model generate classes semantically distant imagenet classes guarantees activations inceptionv meaningful problematic models like dall e trained much larger datasets generate open set essentially perhaps misinterpreting things seems fid case good enough sort stuck around thoughts,time retire fid,time retire fidknow main metric used measure quality generative models fid however seems problems arise evaluating generative model using another model couple come mind inception v years old point nowadays models much higher imagenet classification accuracy presumably translates better internal representations still using inception v instead instance vit recent model imagenet dataset commonly used pretrain inceptionv quite comprehensive still limited classes want train model generate classes semantically distant imagenet classes guarantees activations inceptionv meaningful problematic models like dall e trained much larger datasets generate open set essentially perhaps misinterpreting things seems fid case good enough sort stuck around thoughts,"['time', 'retire', 'fidknow', 'main', 'metric', 'used', 'measure', 'quality', 'generative', 'models', 'fid', 'however', 'seems', 'problems', 'arise', 'evaluating', 'generative', 'model', 'using', 'another', 'model', 'couple', 'come', 'mind', 'inception', 'v', 'years', 'old', 'point', 'nowadays', 'models', 'much', 'higher', 'imagenet', 'classification', 'accuracy', 'presumably', 'translates', 'better', 'internal', 'representations', 'still', 'using', 'inception', 'v', 'instead', 'instance', 'vit', 'recent', 'model', 'imagenet', 'dataset', 'commonly', 'used', 'pretrain', 'inceptionv', 'quite', 'comprehensive', 'still', 'limited', 'classes', 'want', 'train', 'model', 'generate', 'classes', 'semantically', 'distant', 'imagenet', 'classes', 'guarantees', 'activations', 'inceptionv', 'meaningful', 'problematic', 'models', 'like', 'dall', 'e', 'trained', 'much', 'larger', 'datasets', 'generate', 'open', 'set', 'essentially', 'perhaps', 'misinterpreting', 'things', 'seems', 'fid', 'case', 'good', 'enough', 'sort', 'stuck', 'around', 'thoughts']","['time', 'retir', 'fidknow', 'main', 'metric', 'use', 'measur', 'qualiti', 'gener', 'model', 'fid', 'howev', 'seem', 'problem', 'aris', 'evalu', 'gener', 'model', 'use', 'anoth', 'model', 'coupl', 'come', 'mind', 'incept', 'v', 'year', 'old', 'point', 'nowaday', 'model', 'much', 'higher', 'imagenet', 'classif', 'accuraci', 'presum', 'translat', 'better', 'intern', 'represent', 'still', 'use', 'incept', 'v', 'instead', 'instanc', 'vit', 'recent', 'model', 'imagenet', 'dataset', 'commonli', 'use', 'pretrain', 'inceptionv', 'quit', 'comprehens', 'still', 'limit', 'class', 'want', 'train', 'model', 'gener', 'class', 'semant', 'distant', 'imagenet', 'class', 'guarante', 'activ', 'inceptionv', 'meaning', 'problemat', 'model', 'like', 'dall', 'e', 'train', 'much', 'larger', 'dataset', 'gener', 'open', 'set', 'essenti', 'perhap', 'misinterpret', 'thing', 'seem', 'fid', 'case', 'good', 'enough', 'sort', 'stuck', 'around', 'thought']"
218,239,239,RodObr,vky2yx,[D] Sequence Modelling Technique,"Let's say we have a time series problem where we are trying to use past information to predict future inputs. Like stock prices, or heart rates, or a language model that receives one word at a time.

In theory you would want each output at t to contain the maximum amount of predictive information about label t+1.

Let's say you attach a second network to this RNN, which tries to predict hidden state t+1 from hidden state t and add it's error as an auxiliary loss. You could call it a ""Lookahead reconstruction loss""

I believe this should make the RNN learn in a way that maximises future understanding of the network.

Has anybody experimented with this technique, or read about implementations on this?

I'd be interested in hearing opinions from fellow practitioners.",4,5,2022-06-26 11:41:34, d  sequence modelling technique,let s say we have a time series problem where we are trying to use past information to predict future inputs  like stock prices  or heart rates  or a language model that receives one word at a time in theory you would want each output at t to contain the maximum amount of predictive information about label t  let s say you attach a second network to this rnn  which tries to predict hidden state t  from hidden state t and add it s error as an auxiliary loss  you could call it a lookahead reconstruction lossi believe this should make the rnn learn in a way that maximises future understanding of the network has anybody experimented with this technique  or read about implementations on this i d be interested in hearing opinions from fellow practitioners ,let say time series problem trying use past information predict future inputs like stock prices heart rates language model receives one word time theory would want output contain maximum amount predictive information label let say attach second network rnn tries predict hidden state hidden state error auxiliary loss could call lookahead reconstruction lossi believe make rnn learn way maximises future understanding network anybody experimented technique read implementations interested hearing opinions fellow practitioners,sequence modelling technique,sequence modelling techniquelet say time series problem trying use past information predict future inputs like stock prices heart rates language model receives one word time theory would want output contain maximum amount predictive information label let say attach second network rnn tries predict hidden state hidden state error auxiliary loss could call lookahead reconstruction lossi believe make rnn learn way maximises future understanding network anybody experimented technique read implementations interested hearing opinions fellow practitioners,"['sequence', 'modelling', 'techniquelet', 'say', 'time', 'series', 'problem', 'trying', 'use', 'past', 'information', 'predict', 'future', 'inputs', 'like', 'stock', 'prices', 'heart', 'rates', 'language', 'model', 'receives', 'one', 'word', 'time', 'theory', 'would', 'want', 'output', 'contain', 'maximum', 'amount', 'predictive', 'information', 'label', 'let', 'say', 'attach', 'second', 'network', 'rnn', 'tries', 'predict', 'hidden', 'state', 'hidden', 'state', 'error', 'auxiliary', 'loss', 'could', 'call', 'lookahead', 'reconstruction', 'lossi', 'believe', 'make', 'rnn', 'learn', 'way', 'maximises', 'future', 'understanding', 'network', 'anybody', 'experimented', 'technique', 'read', 'implementations', 'interested', 'hearing', 'opinions', 'fellow', 'practitioners']","['sequenc', 'model', 'techniquelet', 'say', 'time', 'seri', 'problem', 'tri', 'use', 'past', 'inform', 'predict', 'futur', 'input', 'like', 'stock', 'price', 'heart', 'rate', 'languag', 'model', 'receiv', 'one', 'word', 'time', 'theori', 'would', 'want', 'output', 'contain', 'maximum', 'amount', 'predict', 'inform', 'label', 'let', 'say', 'attach', 'second', 'network', 'rnn', 'tri', 'predict', 'hidden', 'state', 'hidden', 'state', 'error', 'auxiliari', 'loss', 'could', 'call', 'lookahead', 'reconstruct', 'lossi', 'believ', 'make', 'rnn', 'learn', 'way', 'maximis', 'futur', 'understand', 'network', 'anybodi', 'experi', 'techniqu', 'read', 'implement', 'interest', 'hear', 'opinion', 'fellow', 'practition']"
219,240,240,anvinhnd,vl65tk,[R] [D] How can one rigorously and efficiently deal with binary classification problems on multi-label data?,"To be clearer, I'd like to start learning about some techniques or the literature about this particular type of binary classification problems. Please share if you happen to know about this (keywords, links, articles, etc are all appreciated).

So, the problem is supervised binary classification. In general, there is nothing special about the dataset apart from the fact that the train/val data from one of the 2 label classes (from now on, let's say it's negative) are already further labeled into multiple subclasses. From there, the problem has an additional goal (other than binary classification): to maximize the number of subclasses that are classified well by the model. By ""classified well"", I mean that, for example, if one restricts the negative side of the dataset into one of such subclasses, the performance of the model is higher than some close-to-perfect thresholds.

Furthermore, there might be some complications in both ways: there might be some subclasses that are easy to classify by the model, and there might be some subclasses that are impossible to classify by the model (e.g. XOR problem with linear classifiers). The key here is that, in the end, at test time, one should only use one ""small"" (relatively of course) ""model"" (a combination of shallow neural nets is OK too) to classify all testing data.

Additionally, I'm open to learn about stuffs beyond the supervised paradigm.",0,0,2022-06-26 20:10:28, r   d  how can one rigorously and efficiently deal with binary classification problems on multi label data ,to be clearer  i d like to start learning about some techniques or the literature about this particular type of binary classification problems  please share if you happen to know about this  keywords  links  articles  etc are all appreciated  so  the problem is supervised binary classification  in general  there is nothing special about the dataset apart from the fact that the train val data from one of the  label classes  from now on  let s say it s negative  are already further labeled into multiple subclasses  from there  the problem has an additional goal  other than binary classification   to maximize the number of subclasses that are classified well by the model  by classified well  i mean that  for example  if one restricts the negative side of the dataset into one of such subclasses  the performance of the model is higher than some close to perfect thresholds furthermore  there might be some complications in both ways  there might be some subclasses that are easy to classify by the model  and there might be some subclasses that are impossible to classify by the model  e g  xor problem with linear classifiers   the key here is that  in the end  at test time  one should only use one small  relatively of course  model  a combination of shallow neural nets is ok too  to classify all testing data additionally  i m open to learn about stuffs beyond the supervised paradigm ,clearer like start learning techniques literature particular type binary classification problems please share happen know keywords links articles etc appreciated problem supervised binary classification general nothing special dataset apart fact train val data one label classes let say negative already labeled multiple subclasses problem additional goal binary classification maximize number subclasses classified well model classified well mean example one restricts negative side dataset one subclasses performance model higher close perfect thresholds furthermore might complications ways might subclasses easy classify model might subclasses impossible classify model e g xor problem linear classifiers key end test time one use one small relatively course model combination shallow neural nets ok classify testing data additionally open learn stuffs beyond supervised paradigm,r one rigorously efficiently deal binary classification problems multi label data,r one rigorously efficiently deal binary classification problems multi label dataclearer like start learning techniques literature particular type binary classification problems please share happen know keywords links articles etc appreciated problem supervised binary classification general nothing special dataset apart fact train val data one label classes let say negative already labeled multiple subclasses problem additional goal binary classification maximize number subclasses classified well model classified well mean example one restricts negative side dataset one subclasses performance model higher close perfect thresholds furthermore might complications ways might subclasses easy classify model might subclasses impossible classify model e g xor problem linear classifiers key end test time one use one small relatively course model combination shallow neural nets ok classify testing data additionally open learn stuffs beyond supervised paradigm,"['r', 'one', 'rigorously', 'efficiently', 'deal', 'binary', 'classification', 'problems', 'multi', 'label', 'dataclearer', 'like', 'start', 'learning', 'techniques', 'literature', 'particular', 'type', 'binary', 'classification', 'problems', 'please', 'share', 'happen', 'know', 'keywords', 'links', 'articles', 'etc', 'appreciated', 'problem', 'supervised', 'binary', 'classification', 'general', 'nothing', 'special', 'dataset', 'apart', 'fact', 'train', 'val', 'data', 'one', 'label', 'classes', 'let', 'say', 'negative', 'already', 'labeled', 'multiple', 'subclasses', 'problem', 'additional', 'goal', 'binary', 'classification', 'maximize', 'number', 'subclasses', 'classified', 'well', 'model', 'classified', 'well', 'mean', 'example', 'one', 'restricts', 'negative', 'side', 'dataset', 'one', 'subclasses', 'performance', 'model', 'higher', 'close', 'perfect', 'thresholds', 'furthermore', 'might', 'complications', 'ways', 'might', 'subclasses', 'easy', 'classify', 'model', 'might', 'subclasses', 'impossible', 'classify', 'model', 'e', 'g', 'xor', 'problem', 'linear', 'classifiers', 'key', 'end', 'test', 'time', 'one', 'use', 'one', 'small', 'relatively', 'course', 'model', 'combination', 'shallow', 'neural', 'nets', 'ok', 'classify', 'testing', 'data', 'additionally', 'open', 'learn', 'stuffs', 'beyond', 'supervised', 'paradigm']","['r', 'one', 'rigor', 'effici', 'deal', 'binari', 'classif', 'problem', 'multi', 'label', 'dataclear', 'like', 'start', 'learn', 'techniqu', 'literatur', 'particular', 'type', 'binari', 'classif', 'problem', 'pleas', 'share', 'happen', 'know', 'keyword', 'link', 'articl', 'etc', 'appreci', 'problem', 'supervis', 'binari', 'classif', 'gener', 'noth', 'special', 'dataset', 'apart', 'fact', 'train', 'val', 'data', 'one', 'label', 'class', 'let', 'say', 'neg', 'alreadi', 'label', 'multipl', 'subclass', 'problem', 'addit', 'goal', 'binari', 'classif', 'maxim', 'number', 'subclass', 'classifi', 'well', 'model', 'classifi', 'well', 'mean', 'exampl', 'one', 'restrict', 'neg', 'side', 'dataset', 'one', 'subclass', 'perform', 'model', 'higher', 'close', 'perfect', 'threshold', 'furthermor', 'might', 'complic', 'way', 'might', 'subclass', 'easi', 'classifi', 'model', 'might', 'subclass', 'imposs', 'classifi', 'model', 'e', 'g', 'xor', 'problem', 'linear', 'classifi', 'key', 'end', 'test', 'time', 'one', 'use', 'one', 'small', 'rel', 'cours', 'model', 'combin', 'shallow', 'neural', 'net', 'ok', 'classifi', 'test', 'data', 'addit', 'open', 'learn', 'stuff', 'beyond', 'supervis', 'paradigm']"
220,241,241,FitWin7383,vkkfv0,[P] Frechet Inception Distance,"I'm currently looking into quantifying GANS and from my current understanding, the way to go is the FID (Frechet Inception Distance) as a key metric. I read into it and have a basic understanding of how it works based on comparing the feature vectors of the Inception Model. In all the tutorials, I saw detailed implementation but they stopped after computing an FID between two images.

In all of the papers, I saw there is one FID score used to compare entire GAN architectures and I'm a bit lost about how many images they generate to compare and whether images generated get randomly paired for an average FID score.

 

TL;DR: The procedure behind comparing GAN architectures is unclear to me based on the FID.",16,41,2022-06-25 23:22:23, p  frechet inception distance,i m currently looking into quantifying gans and from my current understanding  the way to go is the fid  frechet inception distance  as a key metric  i read into it and have a basic understanding of how it works based on comparing the feature vectors of the inception model  in all the tutorials  i saw detailed implementation but they stopped after computing an fid between two images in all of the papers  i saw there is one fid score used to compare entire gan architectures and i m a bit lost about how many images they generate to compare and whether images generated get randomly paired for an average fid score  tl dr  the procedure behind comparing gan architectures is unclear to me based on the fid ,currently looking quantifying gans current understanding way go fid frechet inception distance key metric read basic understanding works based comparing feature vectors inception model tutorials saw detailed implementation stopped computing fid two images papers saw one fid score used compare entire gan architectures bit lost many images generate compare whether images generated get randomly paired average fid score tl dr procedure behind comparing gan architectures unclear based fid,p frechet inception distance,p frechet inception distancecurrently looking quantifying gans current understanding way go fid frechet inception distance key metric read basic understanding works based comparing feature vectors inception model tutorials saw detailed implementation stopped computing fid two images papers saw one fid score used compare entire gan architectures bit lost many images generate compare whether images generated get randomly paired average fid score tl dr procedure behind comparing gan architectures unclear based fid,"['p', 'frechet', 'inception', 'distancecurrently', 'looking', 'quantifying', 'gans', 'current', 'understanding', 'way', 'go', 'fid', 'frechet', 'inception', 'distance', 'key', 'metric', 'read', 'basic', 'understanding', 'works', 'based', 'comparing', 'feature', 'vectors', 'inception', 'model', 'tutorials', 'saw', 'detailed', 'implementation', 'stopped', 'computing', 'fid', 'two', 'images', 'papers', 'saw', 'one', 'fid', 'score', 'used', 'compare', 'entire', 'gan', 'architectures', 'bit', 'lost', 'many', 'images', 'generate', 'compare', 'whether', 'images', 'generated', 'get', 'randomly', 'paired', 'average', 'fid', 'score', 'tl', 'dr', 'procedure', 'behind', 'comparing', 'gan', 'architectures', 'unclear', 'based', 'fid']","['p', 'frechet', 'incept', 'distancecurr', 'look', 'quantifi', 'gan', 'current', 'understand', 'way', 'go', 'fid', 'frechet', 'incept', 'distanc', 'key', 'metric', 'read', 'basic', 'understand', 'work', 'base', 'compar', 'featur', 'vector', 'incept', 'model', 'tutori', 'saw', 'detail', 'implement', 'stop', 'comput', 'fid', 'two', 'imag', 'paper', 'saw', 'one', 'fid', 'score', 'use', 'compar', 'entir', 'gan', 'architectur', 'bit', 'lost', 'mani', 'imag', 'gener', 'compar', 'whether', 'imag', 'gener', 'get', 'randomli', 'pair', 'averag', 'fid', 'score', 'tl', 'dr', 'procedur', 'behind', 'compar', 'gan', 'architectur', 'unclear', 'base', 'fid']"
221,242,242,QadriShyaari,vl8rxu,[D] Clarification question related to prompting,What is the difference between prompt engineering and prompt learning? I recently heard a talk where the presenter said that ‘we freeze the parameters of the model and only do prompt learning’. To me that seems like engineering than learning.,2,0,2022-06-26 22:11:30, d  clarification question related to prompting,what is the difference between prompt engineering and prompt learning  i recently heard a talk where the presenter said that  we freeze the parameters of the model and only do prompt learning   to me that seems like engineering than learning ,difference prompt engineering prompt learning recently heard talk presenter said freeze parameters model prompt learning seems like engineering learning,clarification question related prompting,clarification question related promptingdifference prompt engineering prompt learning recently heard talk presenter said freeze parameters model prompt learning seems like engineering learning,"['clarification', 'question', 'related', 'promptingdifference', 'prompt', 'engineering', 'prompt', 'learning', 'recently', 'heard', 'talk', 'presenter', 'said', 'freeze', 'parameters', 'model', 'prompt', 'learning', 'seems', 'like', 'engineering', 'learning']","['clarif', 'question', 'relat', 'promptingdiffer', 'prompt', 'engin', 'prompt', 'learn', 'recent', 'heard', 'talk', 'present', 'said', 'freez', 'paramet', 'model', 'prompt', 'learn', 'seem', 'like', 'engin', 'learn']"
222,243,243,yapoinder,vklemr,Is there any way of using a text editor with Kaggle or Google Colab notebooks? [Discussion],"UPDATE: SOLVED

The lovely people in the comments guided me to a better method of using github and cloning my repository in the kaggle runtime using the !git clone command. I was unaware you could clone a github repository and run a python file in this method. I was even able to create an anaconda environment and run everything smoothly. So everything is running smoothly again :D <3 <3 :D

&#x200B;

\-------------

I am training a video classification neural network which involves opencv based image augmentation and then after the training completes I run a series of test with my test datasets.

so with all of the functionality the code base is close to 6k lines of code.

This is really hard to work with in the current notebook cell format, if I want to make any changes I have to scroll a lot and often I get confused since my python Classes are thousands of lines each with many functions built in.

Using an editor like VSCODE is 10000x times easier than working with notebooks.

Has anyone figured this one out?

Yes I realize I can work in VSCODE on my local computer and then manually transfer the code to kaggle, but this is incredibly tedious when making small changes to file paths and general code changes.

Im shocked there isnt a better way around this !!! I mean c'mon how do we expect AI to be adopted by the masses if we cant have a streamlined way of developing software?

I guess the alternative is to buy a $6000 GPU and build a pc lol, i'm a broke student paying off student debt :( I am grateful for the free GPU with Kaggle,

I JUST WANT A SIMPLE TEXT EDITOR... is that too much to ask?",10,23,2022-06-26 00:08:49,is there any way of using a text editor with kaggle or google colab notebooks   discussion ,update  solvedthe lovely people in the comments guided me to a better method of using github and cloning my repository in the kaggle runtime using the  git clone command  i was unaware you could clone a github repository and run a python file in this method  i was even able to create an anaconda environment and run everything smoothly  so everything is running smoothly again  d      d  xb               i am training a video classification neural network which involves opencv based image augmentation and then after the training completes i run a series of test with my test datasets so with all of the functionality the code base is close to k lines of code this is really hard to work with in the current notebook cell format  if i want to make any changes i have to scroll a lot and often i get confused since my python classes are thousands of lines each with many functions built in using an editor like vscode is x times easier than working with notebooks has anyone figured this one out yes i realize i can work in vscode on my local computer and then manually transfer the code to kaggle  but this is incredibly tedious when making small changes to file paths and general code changes im shocked there isnt a better way around this     i mean c mon how do we expect ai to be adopted by the masses if we cant have a streamlined way of developing software i guess the alternative is to buy a   gpu and build a pc lol  i m a broke student paying off student debt    i am grateful for the free gpu with kaggle i just want a simple text editor    is that too much to ask ,update solvedthe lovely people comments guided better method using github cloning repository kaggle runtime using git clone command unaware could clone github repository run python file method even able create anaconda environment run everything smoothly everything running smoothly xb training video classification neural network involves opencv based image augmentation training completes run series test test datasets functionality code base close k lines code really hard work current notebook cell format want make changes scroll lot often get confused since python classes thousands lines many functions built using editor like vscode x times easier working notebooks anyone figured one yes realize work vscode local computer manually transfer code kaggle incredibly tedious making small changes file paths general code changes im shocked isnt better way around mean c mon expect ai adopted masses cant streamlined way developing software guess alternative buy gpu build pc lol broke student paying student debt grateful free gpu kaggle want simple text editor much ask,way using text editor kaggle google colab notebooks discussion,way using text editor kaggle google colab notebooks discussionupdate solvedthe lovely people comments guided better method using github cloning repository kaggle runtime using git clone command unaware could clone github repository run python file method even able create anaconda environment run everything smoothly everything running smoothly xb training video classification neural network involves opencv based image augmentation training completes run series test test datasets functionality code base close k lines code really hard work current notebook cell format want make changes scroll lot often get confused since python classes thousands lines many functions built using editor like vscode x times easier working notebooks anyone figured one yes realize work vscode local computer manually transfer code kaggle incredibly tedious making small changes file paths general code changes im shocked isnt better way around mean c mon expect ai adopted masses cant streamlined way developing software guess alternative buy gpu build pc lol broke student paying student debt grateful free gpu kaggle want simple text editor much ask,"['way', 'using', 'text', 'editor', 'kaggle', 'google', 'colab', 'notebooks', 'discussionupdate', 'solvedthe', 'lovely', 'people', 'comments', 'guided', 'better', 'method', 'using', 'github', 'cloning', 'repository', 'kaggle', 'runtime', 'using', 'git', 'clone', 'command', 'unaware', 'could', 'clone', 'github', 'repository', 'run', 'python', 'file', 'method', 'even', 'able', 'create', 'anaconda', 'environment', 'run', 'everything', 'smoothly', 'everything', 'running', 'smoothly', 'xb', 'training', 'video', 'classification', 'neural', 'network', 'involves', 'opencv', 'based', 'image', 'augmentation', 'training', 'completes', 'run', 'series', 'test', 'test', 'datasets', 'functionality', 'code', 'base', 'close', 'k', 'lines', 'code', 'really', 'hard', 'work', 'current', 'notebook', 'cell', 'format', 'want', 'make', 'changes', 'scroll', 'lot', 'often', 'get', 'confused', 'since', 'python', 'classes', 'thousands', 'lines', 'many', 'functions', 'built', 'using', 'editor', 'like', 'vscode', 'x', 'times', 'easier', 'working', 'notebooks', 'anyone', 'figured', 'one', 'yes', 'realize', 'work', 'vscode', 'local', 'computer', 'manually', 'transfer', 'code', 'kaggle', 'incredibly', 'tedious', 'making', 'small', 'changes', 'file', 'paths', 'general', 'code', 'changes', 'im', 'shocked', 'isnt', 'better', 'way', 'around', 'mean', 'c', 'mon', 'expect', 'ai', 'adopted', 'masses', 'cant', 'streamlined', 'way', 'developing', 'software', 'guess', 'alternative', 'buy', 'gpu', 'build', 'pc', 'lol', 'broke', 'student', 'paying', 'student', 'debt', 'grateful', 'free', 'gpu', 'kaggle', 'want', 'simple', 'text', 'editor', 'much', 'ask']","['way', 'use', 'text', 'editor', 'kaggl', 'googl', 'colab', 'notebook', 'discussionupd', 'solvedth', 'love', 'peopl', 'comment', 'guid', 'better', 'method', 'use', 'github', 'clone', 'repositori', 'kaggl', 'runtim', 'use', 'git', 'clone', 'command', 'unawar', 'could', 'clone', 'github', 'repositori', 'run', 'python', 'file', 'method', 'even', 'abl', 'creat', 'anaconda', 'environ', 'run', 'everyth', 'smoothli', 'everyth', 'run', 'smoothli', 'xb', 'train', 'video', 'classif', 'neural', 'network', 'involv', 'opencv', 'base', 'imag', 'augment', 'train', 'complet', 'run', 'seri', 'test', 'test', 'dataset', 'function', 'code', 'base', 'close', 'k', 'line', 'code', 'realli', 'hard', 'work', 'current', 'notebook', 'cell', 'format', 'want', 'make', 'chang', 'scroll', 'lot', 'often', 'get', 'confus', 'sinc', 'python', 'class', 'thousand', 'line', 'mani', 'function', 'built', 'use', 'editor', 'like', 'vscode', 'x', 'time', 'easier', 'work', 'notebook', 'anyon', 'figur', 'one', 'ye', 'realiz', 'work', 'vscode', 'local', 'comput', 'manual', 'transfer', 'code', 'kaggl', 'incred', 'tediou', 'make', 'small', 'chang', 'file', 'path', 'gener', 'code', 'chang', 'im', 'shock', 'isnt', 'better', 'way', 'around', 'mean', 'c', 'mon', 'expect', 'ai', 'adopt', 'mass', 'cant', 'streamlin', 'way', 'develop', 'softwar', 'guess', 'altern', 'buy', 'gpu', 'build', 'pc', 'lol', 'broke', 'student', 'pay', 'student', 'debt', 'grate', 'free', 'gpu', 'kaggl', 'want', 'simpl', 'text', 'editor', 'much', 'ask']"
223,244,244,XinshaoWang,vkc7fo,"[Research] Not all our papers get published, therefore it is enjoyable to see our released papers become a true foundation for other works","I read a post in linkedin (see links at the end) and find  
a similar case on our side: “Not all our papers get published, therefore it is enjoyable to see our released papers become a true foundation for other works”.  


Our work: 

(1) IMAE demonstrates a robust loss could be unbounded, asymmetric; 

(2) Derivative Manipulation proposes gradient normalisation and emphasis density functions.  
\* IMAE for Noise-Robust Learning: Mean Absolute Error Does Not Treat Examples Equally and Gradient Magnitude's Variance Matters: [https://arxiv.org/pdf/1903.12141.pdf](https://arxiv.org/pdf/1903.12141.pdf)  
\* Derivative Manipulation for General Example Weighting: [https://arxiv.org/pdf/1905.11233.pdf](https://arxiv.org/pdf/1905.11233.pdf)  


The following works:

* ICML-20: Normalized Loss Functions for Deep Learning with Noisy  
Labels: [http://proceedings.mlr.press/v119/ma20c/ma20c.pdf](http://proceedings.mlr.press/v119/ma20c/ma20c.pdf)
* ICML-21: Asymmetric Loss Functions for Learning with Noisy Labels [https://proceedings.mlr.press/v139/zhou21f](https://proceedings.mlr.press/v139/zhou21f)

&#x200B;

More details and original source: 

* [https://www.linkedin.com/posts/xinshaowang\_the-probabilistic-normal-epipolar-constraint-activity-6944535197044367360-jpu5?utm\_source=linkedin\_share&utm\_medium=member\_desktop\_web](https://www.linkedin.com/posts/xinshaowang_the-probabilistic-normal-epipolar-constraint-activity-6944535197044367360-jpu5?utm_source=linkedin_share&utm_medium=member_desktop_web)
* [https://www.linkedin.com/posts/laurent-kneip-72518658\_the-probabilistic-normal-epipolar-constraint-activity-6944331307514531840-vQb1?utm\_source=linkedin\_share&utm\_medium=member\_desktop\_web](https://www.linkedin.com/posts/laurent-kneip-72518658_the-probabilistic-normal-epipolar-constraint-activity-6944331307514531840-vQb1?utm_source=linkedin_share&utm_medium=member_desktop_web)",8,91,2022-06-25 16:02:53, research  not all our papers get published  therefore it is enjoyable to see our released papers become a true foundation for other works,i read a post in linkedin  see links at the end  and find  a similar case on our side   not all our papers get published  therefore it is enjoyable to see our released papers become a true foundation for other works    our work     imae demonstrates a robust loss could be unbounded  asymmetric     derivative manipulation proposes gradient normalisation and emphasis density functions      imae for noise robust learning  mean absolute error does not treat examples equally and gradient magnitude s variance matters   https    derivative manipulation for general example weighting   https the following works   icml   normalized loss functions for deep learning with noisy  labels   http   icml   asymmetric loss functions for learning with noisy labels  https   xb more details and original source     https    https   www linkedin com posts laurent kneip  _the probabilistic normal epipolar constraint activity  vqb utm _source linkedin _share utm _medium member _desktop _web  https   www linkedin com posts laurent kneip _the probabilistic normal epipolar constraint activity  vqb utm_source linkedin_share utm_medium member_desktop_web ,read post linkedin see links end find similar case side papers get published therefore enjoyable see released papers become true foundation works work imae demonstrates robust loss could unbounded asymmetric derivative manipulation proposes gradient normalisation emphasis density functions imae noise robust learning mean absolute error treat examples equally gradient magnitude variance matters https derivative manipulation general example weighting https following works icml normalized loss functions deep learning noisy labels http icml asymmetric loss functions learning noisy labels https xb details original source https https www linkedin com posts laurent kneip _the probabilistic normal epipolar constraint activity vqb utm _source linkedin _share utm _medium member _desktop _web https www linkedin com posts laurent kneip _the probabilistic normal epipolar constraint activity vqb utm_source linkedin_share utm_medium member_desktop_web,research papers get published therefore enjoyable see released papers become true foundation works,research papers get published therefore enjoyable see released papers become true foundation worksread post linkedin see links end find similar case side papers get published therefore enjoyable see released papers become true foundation works work imae demonstrates robust loss could unbounded asymmetric derivative manipulation proposes gradient normalisation emphasis density functions imae noise robust learning mean absolute error treat examples equally gradient magnitude variance matters https derivative manipulation general example weighting https following works icml normalized loss functions deep learning noisy labels http icml asymmetric loss functions learning noisy labels https xb details original source https https www linkedin com posts laurent kneip _the probabilistic normal epipolar constraint activity vqb utm _source linkedin _share utm _medium member _desktop _web https www linkedin com posts laurent kneip _the probabilistic normal epipolar constraint activity vqb utm_source linkedin_share utm_medium member_desktop_web,"['research', 'papers', 'get', 'published', 'therefore', 'enjoyable', 'see', 'released', 'papers', 'become', 'true', 'foundation', 'worksread', 'post', 'linkedin', 'see', 'links', 'end', 'find', 'similar', 'case', 'side', 'papers', 'get', 'published', 'therefore', 'enjoyable', 'see', 'released', 'papers', 'become', 'true', 'foundation', 'works', 'work', 'imae', 'demonstrates', 'robust', 'loss', 'could', 'unbounded', 'asymmetric', 'derivative', 'manipulation', 'proposes', 'gradient', 'normalisation', 'emphasis', 'density', 'functions', 'imae', 'noise', 'robust', 'learning', 'mean', 'absolute', 'error', 'treat', 'examples', 'equally', 'gradient', 'magnitude', 'variance', 'matters', 'https', 'derivative', 'manipulation', 'general', 'example', 'weighting', 'https', 'following', 'works', 'icml', 'normalized', 'loss', 'functions', 'deep', 'learning', 'noisy', 'labels', 'http', 'icml', 'asymmetric', 'loss', 'functions', 'learning', 'noisy', 'labels', 'https', 'xb', 'details', 'original', 'source', 'https', 'https', 'www', 'linkedin', 'com', 'posts', 'laurent', 'kneip', '_the', 'probabilistic', 'normal', 'epipolar', 'constraint', 'activity', 'vqb', 'utm', '_source', 'linkedin', '_share', 'utm', '_medium', 'member', '_desktop', '_web', 'https', 'www', 'linkedin', 'com', 'posts', 'laurent', 'kneip', '_the', 'probabilistic', 'normal', 'epipolar', 'constraint', 'activity', 'vqb', 'utm_source', 'linkedin_share', 'utm_medium', 'member_desktop_web']","['research', 'paper', 'get', 'publish', 'therefor', 'enjoy', 'see', 'releas', 'paper', 'becom', 'true', 'foundat', 'worksread', 'post', 'linkedin', 'see', 'link', 'end', 'find', 'similar', 'case', 'side', 'paper', 'get', 'publish', 'therefor', 'enjoy', 'see', 'releas', 'paper', 'becom', 'true', 'foundat', 'work', 'work', 'ima', 'demonstr', 'robust', 'loss', 'could', 'unbound', 'asymmetr', 'deriv', 'manipul', 'propos', 'gradient', 'normalis', 'emphasi', 'densiti', 'function', 'ima', 'nois', 'robust', 'learn', 'mean', 'absolut', 'error', 'treat', 'exampl', 'equal', 'gradient', 'magnitud', 'varianc', 'matter', 'http', 'deriv', 'manipul', 'gener', 'exampl', 'weight', 'http', 'follow', 'work', 'icml', 'normal', 'loss', 'function', 'deep', 'learn', 'noisi', 'label', 'http', 'icml', 'asymmetr', 'loss', 'function', 'learn', 'noisi', 'label', 'http', 'xb', 'detail', 'origin', 'sourc', 'http', 'http', 'www', 'linkedin', 'com', 'post', 'laurent', 'kneip', '_the', 'probabilist', 'normal', 'epipolar', 'constraint', 'activ', 'vqb', 'utm', '_sourc', 'linkedin', '_share', 'utm', '_medium', 'member', '_desktop', '_web', 'http', 'www', 'linkedin', 'com', 'post', 'laurent', 'kneip', '_the', 'probabilist', 'normal', 'epipolar', 'constraint', 'activ', 'vqb', 'utm_sourc', 'linkedin_shar', 'utm_medium', 'member_desktop_web']"
224,246,246,e2v-sde-parody,vjkssf,[D] How to copy text from more than 10 previously published papers and get accepted to CVPR 2022,"Hey, check out our (!) video (parody) that presents how our E2V-SDE paper (that has been accepted to CVPR 2022) largely consists of texts that are uncredited verbatim copies from more than 10 previously published papers. Enjoy!

&#x200B;

[https://youtube.com/watch?v=UCmkpLduptU](https://youtube.com/watch?v=UCmkpLduptU)",95,479,2022-06-24 15:26:42, d  how to copy text from more than  previously published papers and get accepted to cvpr ,hey  check out our     video  parody  that presents how our ev sde paper  that has been accepted to cvpr   largely consists of texts that are uncredited verbatim copies from more than  previously published papers  enjoy   xb  https   youtube com watch v ucmkplduptu  https   youtube com watch v ucmkplduptu ,hey check video parody presents ev sde paper accepted cvpr largely consists texts uncredited verbatim copies previously published papers enjoy xb https youtube com watch v ucmkplduptu https youtube com watch v ucmkplduptu,copy text previously published papers get accepted cvpr,copy text previously published papers get accepted cvprhey check video parody presents ev sde paper accepted cvpr largely consists texts uncredited verbatim copies previously published papers enjoy xb https youtube com watch v ucmkplduptu https youtube com watch v ucmkplduptu,"['copy', 'text', 'previously', 'published', 'papers', 'get', 'accepted', 'cvprhey', 'check', 'video', 'parody', 'presents', 'ev', 'sde', 'paper', 'accepted', 'cvpr', 'largely', 'consists', 'texts', 'uncredited', 'verbatim', 'copies', 'previously', 'published', 'papers', 'enjoy', 'xb', 'https', 'youtube', 'com', 'watch', 'v', 'ucmkplduptu', 'https', 'youtube', 'com', 'watch', 'v', 'ucmkplduptu']","['copi', 'text', 'previous', 'publish', 'paper', 'get', 'accept', 'cvprhey', 'check', 'video', 'parodi', 'present', 'ev', 'sde', 'paper', 'accept', 'cvpr', 'larg', 'consist', 'text', 'uncredit', 'verbatim', 'copi', 'previous', 'publish', 'paper', 'enjoy', 'xb', 'http', 'youtub', 'com', 'watch', 'v', 'ucmkplduptu', 'http', 'youtub', 'com', 'watch', 'v', 'ucmkplduptu']"
225,247,247,yekitra,vjyihq,[D] What are the interesting SOTA models released in CVPR 2022?,"Hi Reddit,

Since the CVPR 2022 is wrapped up today and I've not tracked what happened this year. 

What are the interesting releases of this year that I should be looking at?

What new SOTA models are released?

Thanks",20,39,2022-06-25 02:39:23, d  what are the interesting sota models released in cvpr  ,hi reddit since the cvpr  is wrapped up today and i ve not tracked what happened this year  what are the interesting releases of this year that i should be looking at what new sota models are released thanks,hi reddit since cvpr wrapped today tracked happened year interesting releases year looking sota models released thanks,interesting sota models released cvpr,interesting sota models released cvprhi reddit since cvpr wrapped today tracked happened year interesting releases year looking sota models released thanks,"['interesting', 'sota', 'models', 'released', 'cvprhi', 'reddit', 'since', 'cvpr', 'wrapped', 'today', 'tracked', 'happened', 'year', 'interesting', 'releases', 'year', 'looking', 'sota', 'models', 'released', 'thanks']","['interest', 'sota', 'model', 'releas', 'cvprhi', 'reddit', 'sinc', 'cvpr', 'wrap', 'today', 'track', 'happen', 'year', 'interest', 'releas', 'year', 'look', 'sota', 'model', 'releas', 'thank']"
226,248,248,Realistic_Ad_8107,vka648,[P] Synthetic Images Anomaly Detection with CLIP,"You have just generated a bunch of synthetic images by your favorite generative model. Most of them look great, but some looks really bad. These are outliers. Since GAN, the most popular generative model structure, doesn’t produce a likelihood score for generated images, you can not know which of the images generated by it are outliers.

With the following method, you can inspect your synthetic dataset more efficiently than by just looking at all images.

First blog post on Medium. Let me know what you think.

&#x200B;

https://preview.redd.it/1bq8cmm29q791.png?width=260&format=png&auto=webp&s=5aa2b82e1f1bb4edd64d3f7658415dde1573e2ee

[Synthetic Images Anomaly Detection with CLIP](https://medium.com/p/e4fdf6af0169)",2,3,2022-06-25 13:35:43, p  synthetic images anomaly detection with clip,you have just generated a bunch of synthetic images by your favorite generative model  most of them look great  but some looks really bad  these are outliers  since gan  the most popular generative model structure  doesn t produce a likelihood score for generated images  you can not know which of the images generated by it are outliers with the following method  you can inspect your synthetic dataset more efficiently than by just looking at all images first blog post on medium  let me know what you think   xb https  synthetic images anomaly detection with clip  https   medium com p efdfaf ,generated bunch synthetic images favorite generative model look great looks really bad outliers since gan popular generative model structure produce likelihood score generated images know images generated outliers following method inspect synthetic dataset efficiently looking images first blog post medium let know think xb https synthetic images anomaly detection clip https medium com p efdfaf,p synthetic images anomaly detection clip,p synthetic images anomaly detection clipgenerated bunch synthetic images favorite generative model look great looks really bad outliers since gan popular generative model structure produce likelihood score generated images know images generated outliers following method inspect synthetic dataset efficiently looking images first blog post medium let know think xb https synthetic images anomaly detection clip https medium com p efdfaf,"['p', 'synthetic', 'images', 'anomaly', 'detection', 'clipgenerated', 'bunch', 'synthetic', 'images', 'favorite', 'generative', 'model', 'look', 'great', 'looks', 'really', 'bad', 'outliers', 'since', 'gan', 'popular', 'generative', 'model', 'structure', 'produce', 'likelihood', 'score', 'generated', 'images', 'know', 'images', 'generated', 'outliers', 'following', 'method', 'inspect', 'synthetic', 'dataset', 'efficiently', 'looking', 'images', 'first', 'blog', 'post', 'medium', 'let', 'know', 'think', 'xb', 'https', 'synthetic', 'images', 'anomaly', 'detection', 'clip', 'https', 'medium', 'com', 'p', 'efdfaf']","['p', 'synthet', 'imag', 'anomali', 'detect', 'clipgener', 'bunch', 'synthet', 'imag', 'favorit', 'gener', 'model', 'look', 'great', 'look', 'realli', 'bad', 'outlier', 'sinc', 'gan', 'popular', 'gener', 'model', 'structur', 'produc', 'likelihood', 'score', 'gener', 'imag', 'know', 'imag', 'gener', 'outlier', 'follow', 'method', 'inspect', 'synthet', 'dataset', 'effici', 'look', 'imag', 'first', 'blog', 'post', 'medium', 'let', 'know', 'think', 'xb', 'http', 'synthet', 'imag', 'anomali', 'detect', 'clip', 'http', 'medium', 'com', 'p', 'efdfaf']"
227,250,250,daichrony,vjymjx,"[D] Is it possible to make a model that will outperform a human, if the model was solely trained on that human's prior predictions?","Say a single radiologist has a ton of images that they have labeled cancer / not cancer. Can we use the labels and those images from just the one radiologist to make a model that will be better at predicting cancer / not cancer than the radiologist? 

Intuitively it seems like that would not be possible unless by chance it does better, but ML/DL has a way of being able to extrapolate/generalize patterns and sometimes spot things we missed? Perhaps an ensemble of various models, or maybe that would just lead to overfitting? 

No particular application, just a random question I had been pondering. Appreciate any thoughts and/or references.",22,18,2022-06-25 02:44:41, d  is it possible to make a model that will outperform a human  if the model was solely trained on that human s prior predictions ,say a single radiologist has a ton of images that they have labeled cancer   not cancer  can we use the labels and those images from just the one radiologist to make a model that will be better at predicting cancer   not cancer than the radiologist  intuitively it seems like that would not be possible unless by chance it does better  but ml dl has a way of being able to extrapolate generalize patterns and sometimes spot things we missed  perhaps an ensemble of various models  or maybe that would just lead to overfitting  no particular application  just a random question i had been pondering  appreciate any thoughts and or references ,say single radiologist ton images labeled cancer cancer use labels images one radiologist make model better predicting cancer cancer radiologist intuitively seems like would possible unless chance better ml dl way able extrapolate generalize patterns sometimes spot things missed perhaps ensemble various models maybe would lead overfitting particular application random question pondering appreciate thoughts references,possible make model outperform human model solely trained human prior predictions,possible make model outperform human model solely trained human prior predictionssay single radiologist ton images labeled cancer cancer use labels images one radiologist make model better predicting cancer cancer radiologist intuitively seems like would possible unless chance better ml dl way able extrapolate generalize patterns sometimes spot things missed perhaps ensemble various models maybe would lead overfitting particular application random question pondering appreciate thoughts references,"['possible', 'make', 'model', 'outperform', 'human', 'model', 'solely', 'trained', 'human', 'prior', 'predictionssay', 'single', 'radiologist', 'ton', 'images', 'labeled', 'cancer', 'cancer', 'use', 'labels', 'images', 'one', 'radiologist', 'make', 'model', 'better', 'predicting', 'cancer', 'cancer', 'radiologist', 'intuitively', 'seems', 'like', 'would', 'possible', 'unless', 'chance', 'better', 'ml', 'dl', 'way', 'able', 'extrapolate', 'generalize', 'patterns', 'sometimes', 'spot', 'things', 'missed', 'perhaps', 'ensemble', 'various', 'models', 'maybe', 'would', 'lead', 'overfitting', 'particular', 'application', 'random', 'question', 'pondering', 'appreciate', 'thoughts', 'references']","['possibl', 'make', 'model', 'outperform', 'human', 'model', 'sole', 'train', 'human', 'prior', 'predictionssay', 'singl', 'radiologist', 'ton', 'imag', 'label', 'cancer', 'cancer', 'use', 'label', 'imag', 'one', 'radiologist', 'make', 'model', 'better', 'predict', 'cancer', 'cancer', 'radiologist', 'intuit', 'seem', 'like', 'would', 'possibl', 'unless', 'chanc', 'better', 'ml', 'dl', 'way', 'abl', 'extrapol', 'gener', 'pattern', 'sometim', 'spot', 'thing', 'miss', 'perhap', 'ensembl', 'variou', 'model', 'mayb', 'would', 'lead', 'overfit', 'particular', 'applic', 'random', 'question', 'ponder', 'appreci', 'thought', 'refer']"
228,251,251,mrwafflezzz,vk9gud,[P] Oddly thresholded confidence scores on scaled yolov4 csp,"All object detections on the scaled yolov4 csp model have a confidence below 0.5, while it should range from 0 to 1. Does anything come to mind as to what the problem might be?

Info:

* I'm using a branch of the [author's PyTorch repo](https://github.com/WongKinYiu/ScaledYOLOv4/tree/yolov4-csp)
* Predictions are otherwise pretty good in terms of bbox placement
* I'm training on a single gpu
* Darknet coco weights are converted to "".pt"" PyTorch weights for training
* A custom dataset is used with a single prediction class
* Data is augmented before training starts, most of the dataloader's data augmentation is disabled

EDIT: The culprit was the single class dataset. The solution is adding 2 lines of code:

* [https://github.com/WongKinYiu/ScaledYOLOv4/pull/297](https://github.com/WongKinYiu/ScaledYOLOv4/pull/297)

The total confidence for a bounding box is a multiplication of box confidence and classification confidence. Classification weights are initialized around 0 with a very small standard deviation. These weights, however, are never updated in a single class object detector. Combine that with a sigmoidal activation function and you get a classification confidence of around 0.5 at an input around 0. The total confidence score for a box will thus rarely exceed 0.5. The solution is to set the classification confidence to 1 for inference, leaving only the box confidence.",0,3,2022-06-25 12:47:42, p  oddly thresholded confidence scores on scaled yolov csp,all object detections on the scaled yolov csp model have a confidence below    while it should range from  to   does anything come to mind as to what the problem might be info   i m using a branch of the  author s pytorch repo  https   predictions are otherwise pretty good in terms of bbox placement  i m training on a single gpu  darknet coco weights are converted to  pt pytorch weights for training  a custom dataset is used with a single prediction class  data is augmented before training starts  most of the dataloader s data augmentation is disablededit  the culprit was the single class dataset  the solution is adding  lines of code    https the total confidence for a bounding box is a multiplication of box confidence and classification confidence  classification weights are initialized around  with a very small standard deviation  these weights  however  are never updated in a single class object detector  combine that with a sigmoidal activation function and you get a classification confidence of around   at an input around   the total confidence score for a box will thus rarely exceed    the solution is to set the classification confidence to  for inference  leaving only the box confidence ,object detections scaled yolov csp model confidence range anything come mind problem might info using branch author pytorch repo https predictions otherwise pretty good terms bbox placement training single gpu darknet coco weights converted pt pytorch weights training dataset used single prediction class data augmented training starts dataloader data augmentation disablededit culprit single class dataset solution adding lines code https total confidence bounding box multiplication box confidence classification confidence classification weights initialized around small standard deviation weights however never updated single class object detector combine sigmoidal activation function get classification confidence around input around total confidence score box thus rarely exceed solution set classification confidence inference leaving box confidence,p oddly thresholded confidence scores scaled yolov csp,p oddly thresholded confidence scores scaled yolov cspobject detections scaled yolov csp model confidence range anything come mind problem might info using branch author pytorch repo https predictions otherwise pretty good terms bbox placement training single gpu darknet coco weights converted pt pytorch weights training dataset used single prediction class data augmented training starts dataloader data augmentation disablededit culprit single class dataset solution adding lines code https total confidence bounding box multiplication box confidence classification confidence classification weights initialized around small standard deviation weights however never updated single class object detector combine sigmoidal activation function get classification confidence around input around total confidence score box thus rarely exceed solution set classification confidence inference leaving box confidence,"['p', 'oddly', 'thresholded', 'confidence', 'scores', 'scaled', 'yolov', 'cspobject', 'detections', 'scaled', 'yolov', 'csp', 'model', 'confidence', 'range', 'anything', 'come', 'mind', 'problem', 'might', 'info', 'using', 'branch', 'author', 'pytorch', 'repo', 'https', 'predictions', 'otherwise', 'pretty', 'good', 'terms', 'bbox', 'placement', 'training', 'single', 'gpu', 'darknet', 'coco', 'weights', 'converted', 'pt', 'pytorch', 'weights', 'training', 'dataset', 'used', 'single', 'prediction', 'class', 'data', 'augmented', 'training', 'starts', 'dataloader', 'data', 'augmentation', 'disablededit', 'culprit', 'single', 'class', 'dataset', 'solution', 'adding', 'lines', 'code', 'https', 'total', 'confidence', 'bounding', 'box', 'multiplication', 'box', 'confidence', 'classification', 'confidence', 'classification', 'weights', 'initialized', 'around', 'small', 'standard', 'deviation', 'weights', 'however', 'never', 'updated', 'single', 'class', 'object', 'detector', 'combine', 'sigmoidal', 'activation', 'function', 'get', 'classification', 'confidence', 'around', 'input', 'around', 'total', 'confidence', 'score', 'box', 'thus', 'rarely', 'exceed', 'solution', 'set', 'classification', 'confidence', 'inference', 'leaving', 'box', 'confidence']","['p', 'oddli', 'threshold', 'confid', 'score', 'scale', 'yolov', 'cspobject', 'detect', 'scale', 'yolov', 'csp', 'model', 'confid', 'rang', 'anyth', 'come', 'mind', 'problem', 'might', 'info', 'use', 'branch', 'author', 'pytorch', 'repo', 'http', 'predict', 'otherwis', 'pretti', 'good', 'term', 'bbox', 'placement', 'train', 'singl', 'gpu', 'darknet', 'coco', 'weight', 'convert', 'pt', 'pytorch', 'weight', 'train', 'dataset', 'use', 'singl', 'predict', 'class', 'data', 'augment', 'train', 'start', 'dataload', 'data', 'augment', 'disablededit', 'culprit', 'singl', 'class', 'dataset', 'solut', 'ad', 'line', 'code', 'http', 'total', 'confid', 'bound', 'box', 'multipl', 'box', 'confid', 'classif', 'confid', 'classif', 'weight', 'initi', 'around', 'small', 'standard', 'deviat', 'weight', 'howev', 'never', 'updat', 'singl', 'class', 'object', 'detector', 'combin', 'sigmoid', 'activ', 'function', 'get', 'classif', 'confid', 'around', 'input', 'around', 'total', 'confid', 'score', 'box', 'thu', 'rare', 'exceed', 'solut', 'set', 'classif', 'confid', 'infer', 'leav', 'box', 'confid']"
229,252,252,zy415,vjqdom,[D] Niche ML Venues vs Top ML Conferences,"Since top ML conferences (e.g. NeurIPS, ICML, AISTATS, UAI, ICLR) are getting too large, there are quite some niche venues focusing on different subfields of ML:
- Multi-disciplinary Conference on Reinforcement Learning and Decision Making (RLDM): https://rldm.org/
- Machine Learning for Health (ML4H): https://ml4health.github.io/
- Learning on Graphs Conference (LoG): https://logconference.org/
- Symposium on Advances in Approximate Bayesian Inference (AABI): http://approximateinference.org/
- International Conference on Automated Machine Learning (AutoML-Conf): https://automl.cc/
- Conference on Causal Learning and Reasoning (CLeaR): https://www.cclear.cc/
- Conference on Lifelong Learning Agents (CoLLAs): https://lifelong-ml.cc/

Some of these conferences are quite new and grew out of different workshops. Many of them are trying to establish themselves as top venues in their niche fields. Here, I would like to get some opinions from the ML folks. Could folks comment on these conferences, e.g., based on different dimensions?
- **Prestige**: Are these conferences perceived to be as pretigious as the top ML conferences? 
- **Usefulness**: Does hiring committee in the academia and industry treat these conferences the same as top ML conferences? If not, how much will the nich conferences be discounted? (Closely tied to prestige, though)
- **Dissemination**: Are papers at these niche conferences much less visible to researchers outside the subfields? (This seems important to me because research nowadays often leverages ideas from different fields.)
- **Difficulty**: Is it easier to get papers accepted at these conferences as compared to top ML coneferences?
- **Networking**: Is there really more opportunity to get to know folks working in the same subfields at these conferences (given that it is much smaller)?

Disclaimer:
- I have published several papers in the top ML conferences listed above, and am considering whether to try out niche ML conferences. Personally, this feels like a ""bet"" for me on whether the niche conference will be successful in the future.
- I know some folks might comment that the quality of research is the most important as compared to the publication venues. However, let's for now assume all things being equal and that, e.g., a graduate student is deciding whether to submit a paper to a general ML conference or a niche venue.",16,30,2022-06-24 20:28:33, d  niche ml venues vs top ml conferences,since top ml conferences  e g  neurips  icml  aistats  uai  iclr  are getting too large  there are quite some niche venues focusing on different subfields of ml   multi disciplinary conference on reinforcement learning and decision making  rldm   https   machine learning for health  mlh   https   learning on graphs conference  log   https   symposium on advances in approximate bayesian inference  aabi   http   international conference on automated machine learning  automl conf   https   conference on causal learning and reasoning  clear   https   conference on lifelong learning agents  collas   https some of these conferences are quite new and grew out of different workshops  many of them are trying to establish themselves as top venues in their niche fields  here  i would like to get some opinions from the ml folks  could folks comment on these conferences  e g   based on different dimensions     prestige    are these conferences perceived to be as pretigious as the top ml conferences      usefulness    does hiring committee in the academia and industry treat these conferences the same as top ml conferences  if not  how much will the nich conferences be discounted   closely tied to prestige  though     dissemination    are papers at these niche conferences much less visible to researchers outside the subfields   this seems important to me because research nowadays often leverages ideas from different fields      difficulty    is it easier to get papers accepted at these conferences as compared to top ml coneferences     networking    is there really more opportunity to get to know folks working in the same subfields at these conferences  given that it is much smaller  disclaimer   i have published several papers in the top ml conferences listed above  and am considering whether to try out niche ml conferences  personally  this feels like a bet for me on whether the niche conference will be successful in the future   i know some folks might comment that the quality of research is the most important as compared to the publication venues  however  let s for now assume all things being equal and that  e g   a graduate student is deciding whether to submit a paper to a general ml conference or a niche venue ,since top ml conferences e g neurips icml aistats uai iclr getting large quite niche venues focusing different subfields ml multi disciplinary conference reinforcement learning decision making rldm https machine learning health mlh https learning graphs conference log https symposium advances approximate bayesian inference aabi http international conference automated machine learning automl conf https conference causal learning reasoning clear https conference lifelong learning agents collas https conferences quite grew different workshops many trying establish top venues niche fields would like get opinions ml folks could folks comment conferences e g based different dimensions prestige conferences perceived pretigious top ml conferences usefulness hiring committee academia industry treat conferences top ml conferences much nich conferences discounted closely tied prestige though dissemination papers niche conferences much less visible researchers outside subfields seems important research nowadays often leverages ideas different fields difficulty easier get papers accepted conferences compared top ml coneferences networking really opportunity get know folks working subfields conferences given much smaller disclaimer published several papers top ml conferences listed considering whether try niche ml conferences personally feels like bet whether niche conference successful future know folks might comment quality research important compared publication venues however let assume things equal e g graduate student deciding whether submit paper general ml conference niche venue,niche ml venues vs top ml conferences,niche ml venues vs top ml conferencessince top ml conferences e g neurips icml aistats uai iclr getting large quite niche venues focusing different subfields ml multi disciplinary conference reinforcement learning decision making rldm https machine learning health mlh https learning graphs conference log https symposium advances approximate bayesian inference aabi http international conference automated machine learning automl conf https conference causal learning reasoning clear https conference lifelong learning agents collas https conferences quite grew different workshops many trying establish top venues niche fields would like get opinions ml folks could folks comment conferences e g based different dimensions prestige conferences perceived pretigious top ml conferences usefulness hiring committee academia industry treat conferences top ml conferences much nich conferences discounted closely tied prestige though dissemination papers niche conferences much less visible researchers outside subfields seems important research nowadays often leverages ideas different fields difficulty easier get papers accepted conferences compared top ml coneferences networking really opportunity get know folks working subfields conferences given much smaller disclaimer published several papers top ml conferences listed considering whether try niche ml conferences personally feels like bet whether niche conference successful future know folks might comment quality research important compared publication venues however let assume things equal e g graduate student deciding whether submit paper general ml conference niche venue,"['niche', 'ml', 'venues', 'vs', 'top', 'ml', 'conferencessince', 'top', 'ml', 'conferences', 'e', 'g', 'neurips', 'icml', 'aistats', 'uai', 'iclr', 'getting', 'large', 'quite', 'niche', 'venues', 'focusing', 'different', 'subfields', 'ml', 'multi', 'disciplinary', 'conference', 'reinforcement', 'learning', 'decision', 'making', 'rldm', 'https', 'machine', 'learning', 'health', 'mlh', 'https', 'learning', 'graphs', 'conference', 'log', 'https', 'symposium', 'advances', 'approximate', 'bayesian', 'inference', 'aabi', 'http', 'international', 'conference', 'automated', 'machine', 'learning', 'automl', 'conf', 'https', 'conference', 'causal', 'learning', 'reasoning', 'clear', 'https', 'conference', 'lifelong', 'learning', 'agents', 'collas', 'https', 'conferences', 'quite', 'grew', 'different', 'workshops', 'many', 'trying', 'establish', 'top', 'venues', 'niche', 'fields', 'would', 'like', 'get', 'opinions', 'ml', 'folks', 'could', 'folks', 'comment', 'conferences', 'e', 'g', 'based', 'different', 'dimensions', 'prestige', 'conferences', 'perceived', 'pretigious', 'top', 'ml', 'conferences', 'usefulness', 'hiring', 'committee', 'academia', 'industry', 'treat', 'conferences', 'top', 'ml', 'conferences', 'much', 'nich', 'conferences', 'discounted', 'closely', 'tied', 'prestige', 'though', 'dissemination', 'papers', 'niche', 'conferences', 'much', 'less', 'visible', 'researchers', 'outside', 'subfields', 'seems', 'important', 'research', 'nowadays', 'often', 'leverages', 'ideas', 'different', 'fields', 'difficulty', 'easier', 'get', 'papers', 'accepted', 'conferences', 'compared', 'top', 'ml', 'coneferences', 'networking', 'really', 'opportunity', 'get', 'know', 'folks', 'working', 'subfields', 'conferences', 'given', 'much', 'smaller', 'disclaimer', 'published', 'several', 'papers', 'top', 'ml', 'conferences', 'listed', 'considering', 'whether', 'try', 'niche', 'ml', 'conferences', 'personally', 'feels', 'like', 'bet', 'whether', 'niche', 'conference', 'successful', 'future', 'know', 'folks', 'might', 'comment', 'quality', 'research', 'important', 'compared', 'publication', 'venues', 'however', 'let', 'assume', 'things', 'equal', 'e', 'g', 'graduate', 'student', 'deciding', 'whether', 'submit', 'paper', 'general', 'ml', 'conference', 'niche', 'venue']","['nich', 'ml', 'venu', 'vs', 'top', 'ml', 'conferencessinc', 'top', 'ml', 'confer', 'e', 'g', 'neurip', 'icml', 'aistat', 'uai', 'iclr', 'get', 'larg', 'quit', 'nich', 'venu', 'focus', 'differ', 'subfield', 'ml', 'multi', 'disciplinari', 'confer', 'reinforc', 'learn', 'decis', 'make', 'rldm', 'http', 'machin', 'learn', 'health', 'mlh', 'http', 'learn', 'graph', 'confer', 'log', 'http', 'symposium', 'advanc', 'approxim', 'bayesian', 'infer', 'aabi', 'http', 'intern', 'confer', 'autom', 'machin', 'learn', 'automl', 'conf', 'http', 'confer', 'causal', 'learn', 'reason', 'clear', 'http', 'confer', 'lifelong', 'learn', 'agent', 'colla', 'http', 'confer', 'quit', 'grew', 'differ', 'workshop', 'mani', 'tri', 'establish', 'top', 'venu', 'nich', 'field', 'would', 'like', 'get', 'opinion', 'ml', 'folk', 'could', 'folk', 'comment', 'confer', 'e', 'g', 'base', 'differ', 'dimens', 'prestig', 'confer', 'perceiv', 'pretigi', 'top', 'ml', 'confer', 'use', 'hire', 'committe', 'academia', 'industri', 'treat', 'confer', 'top', 'ml', 'confer', 'much', 'nich', 'confer', 'discount', 'close', 'tie', 'prestig', 'though', 'dissemin', 'paper', 'nich', 'confer', 'much', 'less', 'visibl', 'research', 'outsid', 'subfield', 'seem', 'import', 'research', 'nowaday', 'often', 'leverag', 'idea', 'differ', 'field', 'difficulti', 'easier', 'get', 'paper', 'accept', 'confer', 'compar', 'top', 'ml', 'conefer', 'network', 'realli', 'opportun', 'get', 'know', 'folk', 'work', 'subfield', 'confer', 'given', 'much', 'smaller', 'disclaim', 'publish', 'sever', 'paper', 'top', 'ml', 'confer', 'list', 'consid', 'whether', 'tri', 'nich', 'ml', 'confer', 'person', 'feel', 'like', 'bet', 'whether', 'nich', 'confer', 'success', 'futur', 'know', 'folk', 'might', 'comment', 'qualiti', 'research', 'import', 'compar', 'public', 'venu', 'howev', 'let', 'assum', 'thing', 'equal', 'e', 'g', 'graduat', 'student', 'decid', 'whether', 'submit', 'paper', 'gener', 'ml', 'confer', 'nich', 'venu']"
230,253,253,Gramious,vjkujp,"[D] ""The uncanny valley demonstrating it's treasures and failures, studio lighting digital art"", DALLE-2 prompt. An artist friend has recently been given access and I was trying to feed him prompts that 'broke' the system (e.g., Gaussian noise, one million colours, uncanny valley, etc.).","I had some fun with DALL-E 2 last night because a friend of mine ([instagram.com/photonwind/](https://instagram.com/photonwind/)) was given access last night and was streaming, letting us feed it prompts. I wanted to break the system, find its edges, or give prompts that gave me insight into the underlying function being modelled.   


I tried: ""Gaussian noise"", ""One million colours"" and ""The uncanny valley demonstrating it's treasures and failures, studio lighting digital art"". The latter looks the most interesting to me:  


[The uncanny valley demonstrating it's treasures and failures, studio lighting digital art](https://preview.redd.it/d1acsi05lj791.jpg?width=1024&format=pjpg&auto=webp&s=f0eecc93caee7b93a470777a0fff4bde5dc71a88)

That said, ""One million colours"" is pretty epic too:  


[One million colours](https://preview.redd.it/2tk54r99lj791.png?width=3072&format=png&auto=webp&s=7ecad24840e5433822a06ce7b83d193ab0a20945)

But, Gaussian noise is just broken:  


[Gaussian noise](https://preview.redd.it/tkx2zi2clj791.png?width=2048&format=png&auto=webp&s=d517f44097150850289849465649d87586c83277)",4,41,2022-06-24 15:30:07, d  the uncanny valley demonstrating it s treasures and failures  studio lighting digital art  dalle  prompt  an artist friend has recently been given access and i was trying to feed him prompts that  broke  the system  e g   gaussian noise  one million colours  uncanny valley  etc   ,i had some fun with dall e  last night because a friend of mine   instagram com photonwind   https i tried  gaussian noise  one million colours and the uncanny valley demonstrating it s treasures and failures  studio lighting digital art  the latter looks the most interesting to me    the uncanny valley demonstrating it s treasures and failures  studio lighting digital art  https that said  one million colours is pretty epic too    one million colours  https but  gaussian noise is just broken    gaussian noise  https   preview redd it tkxziclj png width  format png auto webp s dfdc ,fun dall e last night friend mine instagram com photonwind https tried gaussian noise one million colours uncanny valley demonstrating treasures failures studio lighting digital art latter looks interesting uncanny valley demonstrating treasures failures studio lighting digital art https said one million colours pretty epic one million colours https gaussian noise broken gaussian noise https preview redd tkxziclj png width format png auto webp dfdc,uncanny valley demonstrating treasures failures studio lighting digital art dalle prompt artist friend recently given access trying feed prompts broke system e g gaussian noise one million colours uncanny valley etc,uncanny valley demonstrating treasures failures studio lighting digital art dalle prompt artist friend recently given access trying feed prompts broke system e g gaussian noise one million colours uncanny valley etcfun dall e last night friend mine instagram com photonwind https tried gaussian noise one million colours uncanny valley demonstrating treasures failures studio lighting digital art latter looks interesting uncanny valley demonstrating treasures failures studio lighting digital art https said one million colours pretty epic one million colours https gaussian noise broken gaussian noise https preview redd tkxziclj png width format png auto webp dfdc,"['uncanny', 'valley', 'demonstrating', 'treasures', 'failures', 'studio', 'lighting', 'digital', 'art', 'dalle', 'prompt', 'artist', 'friend', 'recently', 'given', 'access', 'trying', 'feed', 'prompts', 'broke', 'system', 'e', 'g', 'gaussian', 'noise', 'one', 'million', 'colours', 'uncanny', 'valley', 'etcfun', 'dall', 'e', 'last', 'night', 'friend', 'mine', 'instagram', 'com', 'photonwind', 'https', 'tried', 'gaussian', 'noise', 'one', 'million', 'colours', 'uncanny', 'valley', 'demonstrating', 'treasures', 'failures', 'studio', 'lighting', 'digital', 'art', 'latter', 'looks', 'interesting', 'uncanny', 'valley', 'demonstrating', 'treasures', 'failures', 'studio', 'lighting', 'digital', 'art', 'https', 'said', 'one', 'million', 'colours', 'pretty', 'epic', 'one', 'million', 'colours', 'https', 'gaussian', 'noise', 'broken', 'gaussian', 'noise', 'https', 'preview', 'redd', 'tkxziclj', 'png', 'width', 'format', 'png', 'auto', 'webp', 'dfdc']","['uncanni', 'valley', 'demonstr', 'treasur', 'failur', 'studio', 'light', 'digit', 'art', 'dall', 'prompt', 'artist', 'friend', 'recent', 'given', 'access', 'tri', 'feed', 'prompt', 'broke', 'system', 'e', 'g', 'gaussian', 'nois', 'one', 'million', 'colour', 'uncanni', 'valley', 'etcfun', 'dall', 'e', 'last', 'night', 'friend', 'mine', 'instagram', 'com', 'photonwind', 'http', 'tri', 'gaussian', 'nois', 'one', 'million', 'colour', 'uncanni', 'valley', 'demonstr', 'treasur', 'failur', 'studio', 'light', 'digit', 'art', 'latter', 'look', 'interest', 'uncanni', 'valley', 'demonstr', 'treasur', 'failur', 'studio', 'light', 'digit', 'art', 'http', 'said', 'one', 'million', 'colour', 'pretti', 'epic', 'one', 'million', 'colour', 'http', 'gaussian', 'nois', 'broken', 'gaussian', 'nois', 'http', 'preview', 'redd', 'tkxziclj', 'png', 'width', 'format', 'png', 'auto', 'webp', 'dfdc']"
231,254,254,THE_REAL_ODB,vjglr9,[D]Anyone use self-supervised learning at work? I'm surprised at how effective it has been for me.,"I've been using this stuff for sniffing near duplicates at work and been surprised how effect it has been!

PLanning to try it out some downstream tasks in the future to see how well it does!

I will say though it does take a shit ton of computing resources, but I find it really cool.",22,65,2022-06-24 10:41:18, d anyone use self supervised learning at work  i m surprised at how effective it has been for me ,i ve been using this stuff for sniffing near duplicates at work and been surprised how effect it has been planning to try it out some downstream tasks in the future to see how well it does i will say though it does take a shit ton of computing resources  but i find it really cool ,using stuff sniffing near duplicates work surprised effect planning try downstream tasks future see well say though take shit ton computing resources find really cool,anyone use self supervised learning work surprised effective,anyone use self supervised learning work surprised effectiveusing stuff sniffing near duplicates work surprised effect planning try downstream tasks future see well say though take shit ton computing resources find really cool,"['anyone', 'use', 'self', 'supervised', 'learning', 'work', 'surprised', 'effectiveusing', 'stuff', 'sniffing', 'near', 'duplicates', 'work', 'surprised', 'effect', 'planning', 'try', 'downstream', 'tasks', 'future', 'see', 'well', 'say', 'though', 'take', 'shit', 'ton', 'computing', 'resources', 'find', 'really', 'cool']","['anyon', 'use', 'self', 'supervis', 'learn', 'work', 'surpris', 'effectiveus', 'stuff', 'snif', 'near', 'duplic', 'work', 'surpris', 'effect', 'plan', 'tri', 'downstream', 'task', 'futur', 'see', 'well', 'say', 'though', 'take', 'shit', 'ton', 'comput', 'resourc', 'find', 'realli', 'cool']"
232,255,255,Which-Distance1384,vk1qxo,[D] A/B testing when there is a feedback loop,"I am experimenting with changing label value (target) for a model that we have in production. We used to cap the target variable, and my new model will release the cap.

&#x200B;

The main point about our production space is that there is a positive feedback loop involved. So, we expect that when we release the cap, my model would result in a section of users having more activity. However, since most of user traffic goes to control arm, only a fraction of it goes to experiment and thus the feedback loop doesnt close unless we have 50-50% experiment (that we can't).

&#x200B;

Wondering, if there is any way to run an A/B test and compare the production model and my model. The labels are shifting as well as the control loop doesn't close.

&#x200B;

Any idea is highly appreciated.",2,1,2022-06-25 05:16:20, d  a b testing when there is a feedback loop,i am experimenting with changing label value  target  for a model that we have in production  we used to cap the target variable  and my new model will release the cap   xb the main point about our production space is that there is a positive feedback loop involved  so  we expect that when we release the cap  my model would result in a section of users having more activity  however  since most of user traffic goes to control arm  only a fraction of it goes to experiment and thus the feedback loop doesnt close unless we have    experiment  that we can t    xb wondering  if there is any way to run an a b test and compare the production model and my model  the labels are shifting as well as the control loop doesn t close   xb any idea is highly appreciated ,experimenting changing label value target model production used cap target variable model release cap xb main point production space positive feedback loop involved expect release cap model would result section users activity however since user traffic goes control arm fraction goes experiment thus feedback loop doesnt close unless experiment xb wondering way run b test compare production model model labels shifting well control loop close xb idea highly appreciated,b testing feedback loop,b testing feedback loopexperimenting changing label value target model production used cap target variable model release cap xb main point production space positive feedback loop involved expect release cap model would result section users activity however since user traffic goes control arm fraction goes experiment thus feedback loop doesnt close unless experiment xb wondering way run b test compare production model model labels shifting well control loop close xb idea highly appreciated,"['b', 'testing', 'feedback', 'loopexperimenting', 'changing', 'label', 'value', 'target', 'model', 'production', 'used', 'cap', 'target', 'variable', 'model', 'release', 'cap', 'xb', 'main', 'point', 'production', 'space', 'positive', 'feedback', 'loop', 'involved', 'expect', 'release', 'cap', 'model', 'would', 'result', 'section', 'users', 'activity', 'however', 'since', 'user', 'traffic', 'goes', 'control', 'arm', 'fraction', 'goes', 'experiment', 'thus', 'feedback', 'loop', 'doesnt', 'close', 'unless', 'experiment', 'xb', 'wondering', 'way', 'run', 'b', 'test', 'compare', 'production', 'model', 'model', 'labels', 'shifting', 'well', 'control', 'loop', 'close', 'xb', 'idea', 'highly', 'appreciated']","['b', 'test', 'feedback', 'loopexperi', 'chang', 'label', 'valu', 'target', 'model', 'product', 'use', 'cap', 'target', 'variabl', 'model', 'releas', 'cap', 'xb', 'main', 'point', 'product', 'space', 'posit', 'feedback', 'loop', 'involv', 'expect', 'releas', 'cap', 'model', 'would', 'result', 'section', 'user', 'activ', 'howev', 'sinc', 'user', 'traffic', 'goe', 'control', 'arm', 'fraction', 'goe', 'experi', 'thu', 'feedback', 'loop', 'doesnt', 'close', 'unless', 'experi', 'xb', 'wonder', 'way', 'run', 'b', 'test', 'compar', 'product', 'model', 'model', 'label', 'shift', 'well', 'control', 'loop', 'close', 'xb', 'idea', 'highli', 'appreci']"
233,256,256,ffast-math,vj7nf5,"[P] Farewell, CUDA OOM: Automatic Gradient Accumulation","Hey everyone,

If you've trained a lot of neural nets, you probably know the pain of getting CUDA OOM errors and iteratively tuning your batch size to avoid them.

Which is why I'm excited to announce that we (MosaicML) just released an automatic way to avoid these errors. Namely, we just added [automatic gradient accumulation](https://docs.mosaicml.com/en/latest/notes/auto_grad_accum.html) to [Composer](https://github.com/mosaicml/composer), our open source library for faster + easier neural net training.

If you're not familiar with gradient accumulation, it's like tuning the batch size, but without messing with the optimization (aside from slightly different BatchNorm stats). This lets you avoid tuning learning rate, weight decay, etc based on how much memory your GPU has or how many GPUs you're training on.

https://preview.redd.it/ogxq73znuf791.png?width=1374&format=png&auto=webp&s=93ff0b76a2293a73a5380b7e93f62fe34c604bc4

What's nice about the \*automatic\* gradient accumulation in Composer is that you just set the batch size and hparams once and you're done—no need to tune the gradient accumulation manually.

More info in our [blog post](https://www.mosaicml.com/blog/farewell-oom), and special thanks to [Mihir Patel](https://mvpatel2000.github.io/) for building most of this. Happy to answer questions!",40,121,2022-06-24 02:58:18, p  farewell  cuda oom  automatic gradient accumulation,hey everyone if you ve trained a lot of neural nets  you probably know the pain of getting cuda oom errors and iteratively tuning your batch size to avoid them which is why i m excited to announce that we  mosaicml  just released an automatic way to avoid these errors  namely  we just added  automatic gradient accumulation  https if you re not familiar with gradient accumulation  it s like tuning the batch size  but without messing with the optimization  aside from slightly different batchnorm stats   this lets you avoid tuning learning rate  weight decay  etc based on how much memory your gpu has or how many gpus you re training on https what s nice about the   automatic   gradient accumulation in composer is that you just set the batch size and hparams once and you re done no need to tune the gradient accumulation manually more info in our  blog post  https   www mosaicml com blog farewell oom   and special thanks to  mihir patel  https   mvpatel github io   for building most of this  happy to answer questions ,hey everyone trained lot neural nets probably know pain getting cuda oom errors iteratively tuning batch size avoid excited announce mosaicml released automatic way avoid errors namely added automatic gradient accumulation https familiar gradient accumulation like tuning batch size without messing optimization aside slightly different batchnorm stats lets avoid tuning learning rate weight decay etc based much memory gpu many gpus training https nice automatic gradient accumulation composer set batch size hparams done need tune gradient accumulation manually info blog post https www mosaicml com blog farewell oom special thanks mihir patel https mvpatel github io building happy answer questions,p farewell cuda oom automatic gradient accumulation,p farewell cuda oom automatic gradient accumulationhey everyone trained lot neural nets probably know pain getting cuda oom errors iteratively tuning batch size avoid excited announce mosaicml released automatic way avoid errors namely added automatic gradient accumulation https familiar gradient accumulation like tuning batch size without messing optimization aside slightly different batchnorm stats lets avoid tuning learning rate weight decay etc based much memory gpu many gpus training https nice automatic gradient accumulation composer set batch size hparams done need tune gradient accumulation manually info blog post https www mosaicml com blog farewell oom special thanks mihir patel https mvpatel github io building happy answer questions,"['p', 'farewell', 'cuda', 'oom', 'automatic', 'gradient', 'accumulationhey', 'everyone', 'trained', 'lot', 'neural', 'nets', 'probably', 'know', 'pain', 'getting', 'cuda', 'oom', 'errors', 'iteratively', 'tuning', 'batch', 'size', 'avoid', 'excited', 'announce', 'mosaicml', 'released', 'automatic', 'way', 'avoid', 'errors', 'namely', 'added', 'automatic', 'gradient', 'accumulation', 'https', 'familiar', 'gradient', 'accumulation', 'like', 'tuning', 'batch', 'size', 'without', 'messing', 'optimization', 'aside', 'slightly', 'different', 'batchnorm', 'stats', 'lets', 'avoid', 'tuning', 'learning', 'rate', 'weight', 'decay', 'etc', 'based', 'much', 'memory', 'gpu', 'many', 'gpus', 'training', 'https', 'nice', 'automatic', 'gradient', 'accumulation', 'composer', 'set', 'batch', 'size', 'hparams', 'done', 'need', 'tune', 'gradient', 'accumulation', 'manually', 'info', 'blog', 'post', 'https', 'www', 'mosaicml', 'com', 'blog', 'farewell', 'oom', 'special', 'thanks', 'mihir', 'patel', 'https', 'mvpatel', 'github', 'io', 'building', 'happy', 'answer', 'questions']","['p', 'farewel', 'cuda', 'oom', 'automat', 'gradient', 'accumulationhey', 'everyon', 'train', 'lot', 'neural', 'net', 'probabl', 'know', 'pain', 'get', 'cuda', 'oom', 'error', 'iter', 'tune', 'batch', 'size', 'avoid', 'excit', 'announc', 'mosaicml', 'releas', 'automat', 'way', 'avoid', 'error', 'name', 'ad', 'automat', 'gradient', 'accumul', 'http', 'familiar', 'gradient', 'accumul', 'like', 'tune', 'batch', 'size', 'without', 'mess', 'optim', 'asid', 'slightli', 'differ', 'batchnorm', 'stat', 'let', 'avoid', 'tune', 'learn', 'rate', 'weight', 'decay', 'etc', 'base', 'much', 'memori', 'gpu', 'mani', 'gpu', 'train', 'http', 'nice', 'automat', 'gradient', 'accumul', 'compos', 'set', 'batch', 'size', 'hparam', 'done', 'need', 'tune', 'gradient', 'accumul', 'manual', 'info', 'blog', 'post', 'http', 'www', 'mosaicml', 'com', 'blog', 'farewel', 'oom', 'special', 'thank', 'mihir', 'patel', 'http', 'mvpatel', 'github', 'io', 'build', 'happi', 'answer', 'question']"
234,257,257,vikarjramun,vj0t0l,[P] Reverse Engineering Google Colab,"Hi!

I've spent a lot of time working with Google Colab recently, and was disappointed that such a powerful platform was limited to only running Jupyter notebooks. So I took a deep dive into the internals of Colab, discovering tons of interesting hidden features!

[Take a look at what I found!](https://dagshub.com/blog/reverse-engineering-google-colab/)",15,290,2022-06-23 21:54:19, p  reverse engineering google colab,hi i ve spent a lot of time working with google colab recently  and was disappointed that such a powerful platform was limited to only running jupyter notebooks  so i took a deep dive into the internals of colab  discovering tons of interesting hidden features  take a look at what i found   https   dagshub com blog reverse engineering google colab  ,hi spent lot time working google colab recently disappointed powerful platform limited running jupyter notebooks took deep dive internals colab discovering tons interesting hidden features take look found https dagshub com blog reverse engineering google colab,p reverse engineering google colab,p reverse engineering google colabhi spent lot time working google colab recently disappointed powerful platform limited running jupyter notebooks took deep dive internals colab discovering tons interesting hidden features take look found https dagshub com blog reverse engineering google colab,"['p', 'reverse', 'engineering', 'google', 'colabhi', 'spent', 'lot', 'time', 'working', 'google', 'colab', 'recently', 'disappointed', 'powerful', 'platform', 'limited', 'running', 'jupyter', 'notebooks', 'took', 'deep', 'dive', 'internals', 'colab', 'discovering', 'tons', 'interesting', 'hidden', 'features', 'take', 'look', 'found', 'https', 'dagshub', 'com', 'blog', 'reverse', 'engineering', 'google', 'colab']","['p', 'revers', 'engin', 'googl', 'colabhi', 'spent', 'lot', 'time', 'work', 'googl', 'colab', 'recent', 'disappoint', 'power', 'platform', 'limit', 'run', 'jupyt', 'notebook', 'took', 'deep', 'dive', 'intern', 'colab', 'discov', 'ton', 'interest', 'hidden', 'featur', 'take', 'look', 'found', 'http', 'dagshub', 'com', 'blog', 'revers', 'engin', 'googl', 'colab']"
235,258,258,ElongatedMuskrat122,vk47y4,[D] How do you guys usually go about normalizing sales data? Opinion on neural networks for business data...,"Working on a project right now, and I have sales amounts as a column. Normally I would throw this into XGBoost, and let it rip, but, I am thinking this might benefit from a DNN. 

 \- For those who have used neural networks for business data, what was your experience using it?

 \- How did you normalize values like sales data? Did you just divide by the max, or not normalize at all?",6,0,2022-06-25 07:28:52, d  how do you guys usually go about normalizing sales data  opinion on neural networks for business data   ,working on a project right now  and i have sales amounts as a column  normally i would throw this into xgboost  and let it rip  but  i am thinking this might benefit from a dnn      for those who have used neural networks for business data  what was your experience using it     how did you normalize values like sales data  did you just divide by the max  or not normalize at all ,working project right sales amounts column normally would throw xgboost let rip thinking might benefit dnn used neural networks business data experience using normalize values like sales data divide max normalize,guys usually go normalizing sales data opinion neural networks business data,guys usually go normalizing sales data opinion neural networks business dataworking project right sales amounts column normally would throw xgboost let rip thinking might benefit dnn used neural networks business data experience using normalize values like sales data divide max normalize,"['guys', 'usually', 'go', 'normalizing', 'sales', 'data', 'opinion', 'neural', 'networks', 'business', 'dataworking', 'project', 'right', 'sales', 'amounts', 'column', 'normally', 'would', 'throw', 'xgboost', 'let', 'rip', 'thinking', 'might', 'benefit', 'dnn', 'used', 'neural', 'networks', 'business', 'data', 'experience', 'using', 'normalize', 'values', 'like', 'sales', 'data', 'divide', 'max', 'normalize']","['guy', 'usual', 'go', 'normal', 'sale', 'data', 'opinion', 'neural', 'network', 'busi', 'datawork', 'project', 'right', 'sale', 'amount', 'column', 'normal', 'would', 'throw', 'xgboost', 'let', 'rip', 'think', 'might', 'benefit', 'dnn', 'use', 'neural', 'network', 'busi', 'data', 'experi', 'use', 'normal', 'valu', 'like', 'sale', 'data', 'divid', 'max', 'normal']"
236,259,259,japanhue,vjn9jv,"[R] Unpublished physics inspired ML paper from 2021 (Yang-Mills theory, differential geometry, gauge theory)","Hi there,

The purpose of this post is to share a [research paper/notebook](https://lukepereira.github.io/notebooks/documents/2021-moduli-attention/main.pdf) I wrote that has been mostly unread and unnoticed by others, and also to ask how to find research collaborators without participating in academia or industry.

After I finished my BSc, I was deeply interested in geometric deep learning and wrote this paper \[0\] describing an attention mechanism using ideas from differential geometry and gauge theory commonly used in the standard model (via Yang-Mills theory). At the time, I sent the notebook/paper to every researcher in the geometric DL area that I was aware of but didn't get any replies or interest in collaboration. Without any openings and at the peak of a pandemic, I sadly had to drop the idea and get a standard software engineer job.

Since then, I've seen much of the rough ideas explored and developed independently by others. For example, M. Bronstein and his collaborators have similar applications of using connections (equivalent to sheafs) and Ricci flow in Graph NNs \[1\]. I have more ideas that I would like to explore, but feel destined to be an outsider in this field with my work unnoticed or considered illegitimate. Is it possible for people like me to collaborate with other researchers outside of academic institutions or industry? Does anyone know of such an organization?

Thanks

\[0\] [https://lukepereira.github.io/notebooks/documents/2021-moduli-attention/main.pdf](https://lukepereira.github.io/notebooks/documents/2021-moduli-attention/main.pdf)

\[1\] [https://thegradient.pub/graph-neural-networks-beyond-message-passing-and-weisfeiler-lehman/](https://thegradient.pub/graph-neural-networks-beyond-message-passing-and-weisfeiler-lehman/)",2,5,2022-06-24 17:55:42, r  unpublished physics inspired ml paper from   yang mills theory  differential geometry  gauge theory ,hi there the purpose of this post is to share a  research paper notebook  https after i finished my bsc  i was deeply interested in geometric deep learning and wrote this paper      describing an attention mechanism using ideas from differential geometry and gauge theory commonly used in the standard model  via yang mills theory   at the time  i sent the notebook paper to every researcher in the geometric dl area that i was aware of but didn t get any replies or interest in collaboration  without any openings and at the peak of a pandemic  i sadly had to drop the idea and get a standard software engineer job since then  i ve seen much of the rough ideas explored and developed independently by others  for example  m  bronstein and his collaborators have similar applications of using connections  equivalent to sheafs  and ricci flow in graph nns       i have more ideas that i would like to explore  but feel destined to be an outsider in this field with my work unnoticed or considered illegitimate  is it possible for people like me to collaborate with other researchers outside of academic institutions or industry  does anyone know of such an organization thanks      https       https   thegradient pub graph neural networks beyond message passing and weisfeiler lehman   https   thegradient pub graph neural networks beyond message passing and weisfeiler lehman  ,hi purpose post share research paper notebook https finished bsc deeply interested geometric deep learning wrote paper describing attention mechanism using ideas differential geometry gauge theory commonly used standard model via yang mills theory time sent notebook paper every researcher geometric dl area aware get replies interest collaboration without openings peak pandemic sadly drop idea get standard software engineer job since seen much rough ideas explored developed independently others example bronstein collaborators similar applications using connections equivalent sheafs ricci flow graph nns ideas would like explore feel destined outsider field work unnoticed considered illegitimate possible people like collaborate researchers outside academic institutions industry anyone know organization thanks https https thegradient pub graph neural networks beyond message passing weisfeiler lehman https thegradient pub graph neural networks beyond message passing weisfeiler lehman,r unpublished physics inspired ml paper yang mills theory differential geometry gauge theory,r unpublished physics inspired ml paper yang mills theory differential geometry gauge theoryhi purpose post share research paper notebook https finished bsc deeply interested geometric deep learning wrote paper describing attention mechanism using ideas differential geometry gauge theory commonly used standard model via yang mills theory time sent notebook paper every researcher geometric dl area aware get replies interest collaboration without openings peak pandemic sadly drop idea get standard software engineer job since seen much rough ideas explored developed independently others example bronstein collaborators similar applications using connections equivalent sheafs ricci flow graph nns ideas would like explore feel destined outsider field work unnoticed considered illegitimate possible people like collaborate researchers outside academic institutions industry anyone know organization thanks https https thegradient pub graph neural networks beyond message passing weisfeiler lehman https thegradient pub graph neural networks beyond message passing weisfeiler lehman,"['r', 'unpublished', 'physics', 'inspired', 'ml', 'paper', 'yang', 'mills', 'theory', 'differential', 'geometry', 'gauge', 'theoryhi', 'purpose', 'post', 'share', 'research', 'paper', 'notebook', 'https', 'finished', 'bsc', 'deeply', 'interested', 'geometric', 'deep', 'learning', 'wrote', 'paper', 'describing', 'attention', 'mechanism', 'using', 'ideas', 'differential', 'geometry', 'gauge', 'theory', 'commonly', 'used', 'standard', 'model', 'via', 'yang', 'mills', 'theory', 'time', 'sent', 'notebook', 'paper', 'every', 'researcher', 'geometric', 'dl', 'area', 'aware', 'get', 'replies', 'interest', 'collaboration', 'without', 'openings', 'peak', 'pandemic', 'sadly', 'drop', 'idea', 'get', 'standard', 'software', 'engineer', 'job', 'since', 'seen', 'much', 'rough', 'ideas', 'explored', 'developed', 'independently', 'others', 'example', 'bronstein', 'collaborators', 'similar', 'applications', 'using', 'connections', 'equivalent', 'sheafs', 'ricci', 'flow', 'graph', 'nns', 'ideas', 'would', 'like', 'explore', 'feel', 'destined', 'outsider', 'field', 'work', 'unnoticed', 'considered', 'illegitimate', 'possible', 'people', 'like', 'collaborate', 'researchers', 'outside', 'academic', 'institutions', 'industry', 'anyone', 'know', 'organization', 'thanks', 'https', 'https', 'thegradient', 'pub', 'graph', 'neural', 'networks', 'beyond', 'message', 'passing', 'weisfeiler', 'lehman', 'https', 'thegradient', 'pub', 'graph', 'neural', 'networks', 'beyond', 'message', 'passing', 'weisfeiler', 'lehman']","['r', 'unpublish', 'physic', 'inspir', 'ml', 'paper', 'yang', 'mill', 'theori', 'differenti', 'geometri', 'gaug', 'theoryhi', 'purpos', 'post', 'share', 'research', 'paper', 'notebook', 'http', 'finish', 'bsc', 'deepli', 'interest', 'geometr', 'deep', 'learn', 'wrote', 'paper', 'describ', 'attent', 'mechan', 'use', 'idea', 'differenti', 'geometri', 'gaug', 'theori', 'commonli', 'use', 'standard', 'model', 'via', 'yang', 'mill', 'theori', 'time', 'sent', 'notebook', 'paper', 'everi', 'research', 'geometr', 'dl', 'area', 'awar', 'get', 'repli', 'interest', 'collabor', 'without', 'open', 'peak', 'pandem', 'sadli', 'drop', 'idea', 'get', 'standard', 'softwar', 'engin', 'job', 'sinc', 'seen', 'much', 'rough', 'idea', 'explor', 'develop', 'independ', 'other', 'exampl', 'bronstein', 'collabor', 'similar', 'applic', 'use', 'connect', 'equival', 'sheaf', 'ricci', 'flow', 'graph', 'nn', 'idea', 'would', 'like', 'explor', 'feel', 'destin', 'outsid', 'field', 'work', 'unnot', 'consid', 'illegitim', 'possibl', 'peopl', 'like', 'collabor', 'research', 'outsid', 'academ', 'institut', 'industri', 'anyon', 'know', 'organ', 'thank', 'http', 'http', 'thegradi', 'pub', 'graph', 'neural', 'network', 'beyond', 'messag', 'pass', 'weisfeil', 'lehman', 'http', 'thegradi', 'pub', 'graph', 'neural', 'network', 'beyond', 'messag', 'pass', 'weisfeil', 'lehman']"
237,260,260,aifordummies,vja009,[D] CVPR wants to penalize reviewers for violating the reviewer guideline!,"I cannot believe that CVPR put this motion for voting:

Motion 3: ""Any reviewer who has accepted an invitation to review but violates the reviewing guidelines set forth by the conference will be prohibited from submitting any papers to CVPR for up to two years.""

Reviewing is a community service, and although I have encountered bad and unfair reviews multiple times, I don't think such a wild action is the way to go to increase the review process quality. Let's start with the training process and choosing qualified AC and Meta ACs first where they can properly oversee the review process, choose fit reviewers, and take action in the rebuttal process.

If this goes through I would never review for CVPR again.

[https://mobile.twitter.com/KostasPenn/status/1539805992145358850](https://mobile.twitter.com/KostasPenn/status/1539805992145358850)

&#x200B;

**UPDATE: All motions have passed!**

Motion 1: Withdrawn Submissions Will No Longer Be Made Inaccessible to Reviewers  
Yes: 867  
No: 354

&#x200B;

Motion 2: Making Authors Responsible for Reviewing  
Yes: 677  
No: 553

Motion 3: Penalties for Violations of the CVPR Reviewing Guidelines  
Yes: 655  
No: 574

&#x200B;

Truly a sad day for ML research community.",43,67,2022-06-24 04:49:16, d  cvpr wants to penalize reviewers for violating the reviewer guideline ,i cannot believe that cvpr put this motion for voting motion   any reviewer who has accepted an invitation to review but violates the reviewing guidelines set forth by the conference will be prohibited from submitting any papers to cvpr for up to two years reviewing is a community service  and although i have encountered bad and unfair reviews multiple times  i don t think such a wild action is the way to go to increase the review process quality  let s start with the training process and choosing qualified ac and meta acs first where they can properly oversee the review process  choose fit reviewers  and take action in the rebuttal process if this goes through i would never review for cvpr again  https   xb   update  all motions have passed   motion   withdrawn submissions will no longer be made inaccessible to reviewers  yes    no    xb motion   making authors responsible for reviewing  yes    no  motion   penalties for violations of the cvpr reviewing guidelines  yes    no    xb truly a sad day for ml research community ,cannot believe cvpr put motion voting motion reviewer accepted invitation review violates reviewing guidelines set forth conference prohibited submitting papers cvpr two years reviewing community service although encountered bad unfair reviews multiple times think wild action way go increase review process quality let start training process choosing qualified ac meta acs first properly oversee review process choose fit reviewers take action rebuttal process goes would never review cvpr https xb update motions passed motion withdrawn submissions longer made inaccessible reviewers yes xb motion making authors responsible reviewing yes motion penalties violations cvpr reviewing guidelines yes xb truly sad day ml research community,cvpr wants penalize reviewers violating reviewer guideline,cvpr wants penalize reviewers violating reviewer guidelinecannot believe cvpr put motion voting motion reviewer accepted invitation review violates reviewing guidelines set forth conference prohibited submitting papers cvpr two years reviewing community service although encountered bad unfair reviews multiple times think wild action way go increase review process quality let start training process choosing qualified ac meta acs first properly oversee review process choose fit reviewers take action rebuttal process goes would never review cvpr https xb update motions passed motion withdrawn submissions longer made inaccessible reviewers yes xb motion making authors responsible reviewing yes motion penalties violations cvpr reviewing guidelines yes xb truly sad day ml research community,"['cvpr', 'wants', 'penalize', 'reviewers', 'violating', 'reviewer', 'guidelinecannot', 'believe', 'cvpr', 'put', 'motion', 'voting', 'motion', 'reviewer', 'accepted', 'invitation', 'review', 'violates', 'reviewing', 'guidelines', 'set', 'forth', 'conference', 'prohibited', 'submitting', 'papers', 'cvpr', 'two', 'years', 'reviewing', 'community', 'service', 'although', 'encountered', 'bad', 'unfair', 'reviews', 'multiple', 'times', 'think', 'wild', 'action', 'way', 'go', 'increase', 'review', 'process', 'quality', 'let', 'start', 'training', 'process', 'choosing', 'qualified', 'ac', 'meta', 'acs', 'first', 'properly', 'oversee', 'review', 'process', 'choose', 'fit', 'reviewers', 'take', 'action', 'rebuttal', 'process', 'goes', 'would', 'never', 'review', 'cvpr', 'https', 'xb', 'update', 'motions', 'passed', 'motion', 'withdrawn', 'submissions', 'longer', 'made', 'inaccessible', 'reviewers', 'yes', 'xb', 'motion', 'making', 'authors', 'responsible', 'reviewing', 'yes', 'motion', 'penalties', 'violations', 'cvpr', 'reviewing', 'guidelines', 'yes', 'xb', 'truly', 'sad', 'day', 'ml', 'research', 'community']","['cvpr', 'want', 'penal', 'review', 'violat', 'review', 'guidelinecannot', 'believ', 'cvpr', 'put', 'motion', 'vote', 'motion', 'review', 'accept', 'invit', 'review', 'violat', 'review', 'guidelin', 'set', 'forth', 'confer', 'prohibit', 'submit', 'paper', 'cvpr', 'two', 'year', 'review', 'commun', 'servic', 'although', 'encount', 'bad', 'unfair', 'review', 'multipl', 'time', 'think', 'wild', 'action', 'way', 'go', 'increas', 'review', 'process', 'qualiti', 'let', 'start', 'train', 'process', 'choos', 'qualifi', 'ac', 'meta', 'ac', 'first', 'properli', 'overse', 'review', 'process', 'choos', 'fit', 'review', 'take', 'action', 'rebutt', 'process', 'goe', 'would', 'never', 'review', 'cvpr', 'http', 'xb', 'updat', 'motion', 'pass', 'motion', 'withdrawn', 'submiss', 'longer', 'made', 'inaccess', 'review', 'ye', 'xb', 'motion', 'make', 'author', 'respons', 'review', 'ye', 'motion', 'penalti', 'violat', 'cvpr', 'review', 'guidelin', 'ye', 'xb', 'truli', 'sad', 'day', 'ml', 'research', 'commun']"
238,261,261,htrp,vivji3,[P] Yandex open sources 100b large language model weights (YaLM),"PR Announcement: https://medium.com/yandex/yandex-publishes-yalm-100b-its-the-largest-gpt-like-neural-network-in-open-source-d1df53d0e9a6


Github: https://github.com/yandex/YaLM-100B

Network is trained using same principles as Megatron LM, inference alone will require 4 A100s",56,284,2022-06-23 17:45:39, p  yandex open sources b large language model weights  yalm ,pr announcement  https github  https network is trained using same principles as megatron lm  inference alone will require  as,pr announcement https github https network trained using principles megatron lm inference alone require,p yandex open sources b large language model weights yalm,p yandex open sources b large language model weights yalmpr announcement https github https network trained using principles megatron lm inference alone require,"['p', 'yandex', 'open', 'sources', 'b', 'large', 'language', 'model', 'weights', 'yalmpr', 'announcement', 'https', 'github', 'https', 'network', 'trained', 'using', 'principles', 'megatron', 'lm', 'inference', 'alone', 'require']","['p', 'yandex', 'open', 'sourc', 'b', 'larg', 'languag', 'model', 'weight', 'yalmpr', 'announc', 'http', 'github', 'http', 'network', 'train', 'use', 'principl', 'megatron', 'lm', 'infer', 'alon', 'requir']"
239,262,262,bandalorian,vjvl6t,[D] Using a neural net on bag of words vector vs PCA doe classification,"I have a document set that I wish to classify. I have tried with transformers, and they perform well, but the content is largely keyword driven so a lot of the attention stuff is not needed. It's a more deterministic system that needs to learn keyword combinations. So a count vectorizer over unigrams and bigrams, and then a classifier like XGBoost seems like a good idea. The problem is even after some pruning I get a feature vector of 26K.  I'd also like to compare this to a how a simple neural net handles it.

I was going to apply sparse PCA to get the dimensionality down first. However for a neural net, does it make sense to do PCA first? Isn't that what the embeddings are doing? Basically, the tasks of PCA + classifier model are carried out by the embedding and classification layers of a neural net. But just feeding 26 K dimensions to a neural net seems lazy, but if I reduce it to say 768 dimensions, I've basically carried out the whole embedding task before I pass it to the neural net, which limits the improvements it can make.

Would a happy medium of reducing to say 5K dimensions and then letting the neural net take it from there? I'm in the process of testing all of this in the next couple of weeks, but curious if anyone has any experience/insight/guesses.",6,1,2022-06-25 00:23:23, d  using a neural net on bag of words vector vs pca doe classification,i have a document set that i wish to classify  i have tried with transformers  and they perform well  but the content is largely keyword driven so a lot of the attention stuff is not needed  it s a more deterministic system that needs to learn keyword combinations  so a count vectorizer over unigrams and bigrams  and then a classifier like xgboost seems like a good idea  the problem is even after some pruning i get a feature vector of k   i d also like to compare this to a how a simple neural net handles it i was going to apply sparse pca to get the dimensionality down first  however for a neural net  does it make sense to do pca first  isn t that what the embeddings are doing  basically  the tasks of pca   classifier model are carried out by the embedding and classification layers of a neural net  but just feeding  k dimensions to a neural net seems lazy  but if i reduce it to say  dimensions  i ve basically carried out the whole embedding task before i pass it to the neural net  which limits the improvements it can make would a happy medium of reducing to say k dimensions and then letting the neural net take it from there  i m in the process of testing all of this in the next couple of weeks  but curious if anyone has any experience insight guesses ,document set wish classify tried transformers perform well content largely keyword driven lot attention stuff needed deterministic system needs learn keyword combinations count vectorizer unigrams bigrams classifier like xgboost seems like good idea problem even pruning get feature vector k also like compare simple neural net handles going apply sparse pca get dimensionality first however neural net make sense pca first embeddings basically tasks pca classifier model carried embedding classification layers neural net feeding k dimensions neural net seems lazy reduce say dimensions basically carried whole embedding task pass neural net limits improvements make would happy medium reducing say k dimensions letting neural net take process testing next couple weeks curious anyone experience insight guesses,using neural net bag vector vs pca doe classification,using neural net bag vector vs pca doe classificationdocument set wish classify tried transformers perform well content largely keyword driven lot attention stuff needed deterministic system needs learn keyword combinations count vectorizer unigrams bigrams classifier like xgboost seems like good idea problem even pruning get feature vector k also like compare simple neural net handles going apply sparse pca get dimensionality first however neural net make sense pca first embeddings basically tasks pca classifier model carried embedding classification layers neural net feeding k dimensions neural net seems lazy reduce say dimensions basically carried whole embedding task pass neural net limits improvements make would happy medium reducing say k dimensions letting neural net take process testing next couple weeks curious anyone experience insight guesses,"['using', 'neural', 'net', 'bag', 'vector', 'vs', 'pca', 'doe', 'classificationdocument', 'set', 'wish', 'classify', 'tried', 'transformers', 'perform', 'well', 'content', 'largely', 'keyword', 'driven', 'lot', 'attention', 'stuff', 'needed', 'deterministic', 'system', 'needs', 'learn', 'keyword', 'combinations', 'count', 'vectorizer', 'unigrams', 'bigrams', 'classifier', 'like', 'xgboost', 'seems', 'like', 'good', 'idea', 'problem', 'even', 'pruning', 'get', 'feature', 'vector', 'k', 'also', 'like', 'compare', 'simple', 'neural', 'net', 'handles', 'going', 'apply', 'sparse', 'pca', 'get', 'dimensionality', 'first', 'however', 'neural', 'net', 'make', 'sense', 'pca', 'first', 'embeddings', 'basically', 'tasks', 'pca', 'classifier', 'model', 'carried', 'embedding', 'classification', 'layers', 'neural', 'net', 'feeding', 'k', 'dimensions', 'neural', 'net', 'seems', 'lazy', 'reduce', 'say', 'dimensions', 'basically', 'carried', 'whole', 'embedding', 'task', 'pass', 'neural', 'net', 'limits', 'improvements', 'make', 'would', 'happy', 'medium', 'reducing', 'say', 'k', 'dimensions', 'letting', 'neural', 'net', 'take', 'process', 'testing', 'next', 'couple', 'weeks', 'curious', 'anyone', 'experience', 'insight', 'guesses']","['use', 'neural', 'net', 'bag', 'vector', 'vs', 'pca', 'doe', 'classificationdocu', 'set', 'wish', 'classifi', 'tri', 'transform', 'perform', 'well', 'content', 'larg', 'keyword', 'driven', 'lot', 'attent', 'stuff', 'need', 'determinist', 'system', 'need', 'learn', 'keyword', 'combin', 'count', 'vector', 'unigram', 'bigram', 'classifi', 'like', 'xgboost', 'seem', 'like', 'good', 'idea', 'problem', 'even', 'prune', 'get', 'featur', 'vector', 'k', 'also', 'like', 'compar', 'simpl', 'neural', 'net', 'handl', 'go', 'appli', 'spars', 'pca', 'get', 'dimension', 'first', 'howev', 'neural', 'net', 'make', 'sens', 'pca', 'first', 'embed', 'basic', 'task', 'pca', 'classifi', 'model', 'carri', 'embed', 'classif', 'layer', 'neural', 'net', 'feed', 'k', 'dimens', 'neural', 'net', 'seem', 'lazi', 'reduc', 'say', 'dimens', 'basic', 'carri', 'whole', 'embed', 'task', 'pass', 'neural', 'net', 'limit', 'improv', 'make', 'would', 'happi', 'medium', 'reduc', 'say', 'k', 'dimens', 'let', 'neural', 'net', 'take', 'process', 'test', 'next', 'coupl', 'week', 'curiou', 'anyon', 'experi', 'insight', 'guess']"
240,263,263,Time-Archer-8103,vjpcij,[P] Implementing CRF-CNN model in python,"I am trying to implement a [research paper](https://ieeexplore.ieee.org/document/8546073) that uses CNN and CRF for page object detection. According to the research paper we have to to build two neural network (named unary and pairwise). Then the training data (set of images) are passed and both the CNNs are trained. After that we are supposed to apply CRF.

&#x200B;

Following are the equations for CRF:

&#x200B;

https://preview.redd.it/ckrm2rzutk791.png?width=768&format=png&auto=webp&s=ed88d8705b515beaf955d09aa194fa63707f7cca

U and V are unary and pairwise potentials obtained from the CNNs using the following equations:

&#x200B;

https://preview.redd.it/uahcpzgwtk791.png?width=813&format=png&auto=webp&s=bb3548539db1c9b1be3367f2ddd529f1ba32c5f3

&#x200B;

Maximum a posteriori (MAP) strategy to predict the labels of line regions given a new document. MAP inference of CRFs can be formulated as the following optimization problem:

&#x200B;

&#x200B;

&#x200B;

https://preview.redd.it/sz0537wwtk791.png?width=273&format=png&auto=webp&s=638b88b012a0158bce017be14b7e81639199a681

The parameters of our CRFs include Unary-Net's weights  and Pairwise-Net's weights  and a combination coefficient vector λ of U and V. weights of U and V (w)  are learned using the SGD method. Then they are fixed and λ is learned using the Pseudo Likelihood method.

&#x200B;

&#x200B;

I have created the neural networks but I am not able to implement the CRF part. Can someone help me implement this or suggest a python library that makes it easier to implement. (I have tried a python library [pystruct](https://pystruct.github.io/) but could not install it)",0,2,2022-06-24 19:40:11, p  implementing crf cnn model in python,i am trying to implement a  research paper  https   xb following are the equations for crf   xb https u and v are unary and pairwise potentials obtained from the cnns using the following equations   xb https   xb maximum a posteriori  map  strategy to predict the labels of line regions given a new document  map inference of crfs can be formulated as the following optimization problem   xb   xb   xb https the parameters of our crfs include unary net s weights  and pairwise net s weights  and a combination coefficient vector λ of u and v  weights of u and v  w   are learned using the sgd method  then they are fixed and λ is learned using the pseudo likelihood method   xb   xb i have created the neural networks but i am not able to implement the crf part  can someone help me implement this or suggest a python library that makes it easier to implement   i have tried a python library  pystruct  https   pystruct github io   but could not install it ,trying implement research paper https xb following equations crf xb https u v unary pairwise potentials obtained cnns using following equations xb https xb maximum posteriori map strategy predict labels line regions given document map inference crfs formulated following optimization problem xb xb xb https parameters crfs include unary net weights pairwise net weights combination coefficient vector λ u v weights u v w learned using sgd method fixed λ learned using pseudo likelihood method xb xb created neural networks able implement crf part someone help implement suggest python library makes easier implement tried python library pystruct https pystruct github io could install,p implementing crf cnn model python,p implementing crf cnn model pythontrying implement research paper https xb following equations crf xb https u v unary pairwise potentials obtained cnns using following equations xb https xb maximum posteriori map strategy predict labels line regions given document map inference crfs formulated following optimization problem xb xb xb https parameters crfs include unary net weights pairwise net weights combination coefficient vector λ u v weights u v w learned using sgd method fixed λ learned using pseudo likelihood method xb xb created neural networks able implement crf part someone help implement suggest python library makes easier implement tried python library pystruct https pystruct github io could install,"['p', 'implementing', 'crf', 'cnn', 'model', 'pythontrying', 'implement', 'research', 'paper', 'https', 'xb', 'following', 'equations', 'crf', 'xb', 'https', 'u', 'v', 'unary', 'pairwise', 'potentials', 'obtained', 'cnns', 'using', 'following', 'equations', 'xb', 'https', 'xb', 'maximum', 'posteriori', 'map', 'strategy', 'predict', 'labels', 'line', 'regions', 'given', 'document', 'map', 'inference', 'crfs', 'formulated', 'following', 'optimization', 'problem', 'xb', 'xb', 'xb', 'https', 'parameters', 'crfs', 'include', 'unary', 'net', 'weights', 'pairwise', 'net', 'weights', 'combination', 'coefficient', 'vector', 'λ', 'u', 'v', 'weights', 'u', 'v', 'w', 'learned', 'using', 'sgd', 'method', 'fixed', 'λ', 'learned', 'using', 'pseudo', 'likelihood', 'method', 'xb', 'xb', 'created', 'neural', 'networks', 'able', 'implement', 'crf', 'part', 'someone', 'help', 'implement', 'suggest', 'python', 'library', 'makes', 'easier', 'implement', 'tried', 'python', 'library', 'pystruct', 'https', 'pystruct', 'github', 'io', 'could', 'install']","['p', 'implement', 'crf', 'cnn', 'model', 'pythontri', 'implement', 'research', 'paper', 'http', 'xb', 'follow', 'equat', 'crf', 'xb', 'http', 'u', 'v', 'unari', 'pairwis', 'potenti', 'obtain', 'cnn', 'use', 'follow', 'equat', 'xb', 'http', 'xb', 'maximum', 'posteriori', 'map', 'strategi', 'predict', 'label', 'line', 'region', 'given', 'document', 'map', 'infer', 'crf', 'formul', 'follow', 'optim', 'problem', 'xb', 'xb', 'xb', 'http', 'paramet', 'crf', 'includ', 'unari', 'net', 'weight', 'pairwis', 'net', 'weight', 'combin', 'coeffici', 'vector', 'λ', 'u', 'v', 'weight', 'u', 'v', 'w', 'learn', 'use', 'sgd', 'method', 'fix', 'λ', 'learn', 'use', 'pseudo', 'likelihood', 'method', 'xb', 'xb', 'creat', 'neural', 'network', 'abl', 'implement', 'crf', 'part', 'someon', 'help', 'implement', 'suggest', 'python', 'librari', 'make', 'easier', 'implement', 'tri', 'python', 'librari', 'pystruct', 'http', 'pystruct', 'github', 'io', 'could', 'instal']"
241,264,264,FundF,vjox5u,[P] What The Plug: An app that identifies electrical plugs,"I have built a convolutional neural network that identifies roughly 20 different plug types. I wrote most code with Keras on top of Tensorflow in Python. I trained the model on my personal computer using Linux and CUDA to train with my GPU. Afterwards I transformed the model to a .tflite file and embedded it in a swift app for iPhone.

Machine learning and programming is not my main field of work. Actually it's my first project in both areas. During the last three years I have taught myself the principals of machine learning as well as Python and Swift.

I hope some of you are interested in trying out the app. I would love to hear your feedback.

The app is 100% free by the way. I just want to see people use what I have build.

Here is the link to the app store:

[https://apps.apple.com/de/app/what-the-plug/id1613147033](https://apps.apple.com/de/app/what-the-plug/id1613147033)",0,2,2022-06-24 19:20:15, p  what the plug  an app that identifies electrical plugs,i have built a convolutional neural network that identifies roughly  different plug types  i wrote most code with keras on top of tensorflow in python  i trained the model on my personal computer using linux and cuda to train with my gpu  afterwards i transformed the model to a  tflite file and embedded it in a swift app for iphone machine learning and programming is not my main field of work  actually it s my first project in both areas  during the last three years i have taught myself the principals of machine learning as well as python and swift i hope some of you are interested in trying out the app  i would love to hear your feedback the app is   free by the way  i just want to see people use what i have build here is the link to the app store  https   apps apple com de app what the plug id  https   apps apple com de app what the plug id ,built convolutional neural network identifies roughly different plug types wrote code keras top tensorflow python trained model personal computer using linux cuda train gpu afterwards transformed model tflite file embedded swift app iphone machine learning programming main field work actually first project areas last three years taught principals machine learning well python swift hope interested trying app would love hear feedback app free way want see people use build link app store https apps apple com de app plug id https apps apple com de app plug id,p plug app identifies electrical plugs,p plug app identifies electrical plugsbuilt convolutional neural network identifies roughly different plug types wrote code keras top tensorflow python trained model personal computer using linux cuda train gpu afterwards transformed model tflite file embedded swift app iphone machine learning programming main field work actually first project areas last three years taught principals machine learning well python swift hope interested trying app would love hear feedback app free way want see people use build link app store https apps apple com de app plug id https apps apple com de app plug id,"['p', 'plug', 'app', 'identifies', 'electrical', 'plugsbuilt', 'convolutional', 'neural', 'network', 'identifies', 'roughly', 'different', 'plug', 'types', 'wrote', 'code', 'keras', 'top', 'tensorflow', 'python', 'trained', 'model', 'personal', 'computer', 'using', 'linux', 'cuda', 'train', 'gpu', 'afterwards', 'transformed', 'model', 'tflite', 'file', 'embedded', 'swift', 'app', 'iphone', 'machine', 'learning', 'programming', 'main', 'field', 'work', 'actually', 'first', 'project', 'areas', 'last', 'three', 'years', 'taught', 'principals', 'machine', 'learning', 'well', 'python', 'swift', 'hope', 'interested', 'trying', 'app', 'would', 'love', 'hear', 'feedback', 'app', 'free', 'way', 'want', 'see', 'people', 'use', 'build', 'link', 'app', 'store', 'https', 'apps', 'apple', 'com', 'de', 'app', 'plug', 'id', 'https', 'apps', 'apple', 'com', 'de', 'app', 'plug', 'id']","['p', 'plug', 'app', 'identifi', 'electr', 'plugsbuilt', 'convolut', 'neural', 'network', 'identifi', 'roughli', 'differ', 'plug', 'type', 'wrote', 'code', 'kera', 'top', 'tensorflow', 'python', 'train', 'model', 'person', 'comput', 'use', 'linux', 'cuda', 'train', 'gpu', 'afterward', 'transform', 'model', 'tflite', 'file', 'embed', 'swift', 'app', 'iphon', 'machin', 'learn', 'program', 'main', 'field', 'work', 'actual', 'first', 'project', 'area', 'last', 'three', 'year', 'taught', 'princip', 'machin', 'learn', 'well', 'python', 'swift', 'hope', 'interest', 'tri', 'app', 'would', 'love', 'hear', 'feedback', 'app', 'free', 'way', 'want', 'see', 'peopl', 'use', 'build', 'link', 'app', 'store', 'http', 'app', 'appl', 'com', 'de', 'app', 'plug', 'id', 'http', 'app', 'appl', 'com', 'de', 'app', 'plug', 'id']"
242,265,265,ItzDerock,vjtns4,[D] Need opinions for GPU server build.,"Work is getting a new server for ml/deep learning. 
Price isn't an issue, not looking to cut down much, just wanted to make sure that I'm not overlooking anything in terms of compatibility. 

My main concern is the CPU, would you recommend getting more cores/higher clock, or is it fine? 

https://docs.google.com/spreadsheets/d/17EQ_ZLQGDuaq5ECPpH_V7HKRC8QP-2qyoqvzKuXJoWI/edit?usp=drivesdk",7,1,2022-06-24 22:56:16, d  need opinions for gpu server build ,work is getting a new server for ml deep learning  price isn t an issue  not looking to cut down much  just wanted to make sure that i m not overlooking anything in terms of compatibility  my main concern is the cpu  would you recommend getting more cores higher clock  or is it fine  https   docs google com spreadsheets d eq_zlqgduaqecpph_vhkrcqp qyoqvzkuxjowi edit usp drivesdk,work getting server ml deep learning price issue looking cut much wanted make sure overlooking anything terms compatibility main concern cpu would recommend getting cores higher clock fine https docs google com spreadsheets eq_zlqgduaqecpph_vhkrcqp qyoqvzkuxjowi edit usp drivesdk,need opinions gpu server build,need opinions gpu server buildwork getting server ml deep learning price issue looking cut much wanted make sure overlooking anything terms compatibility main concern cpu would recommend getting cores higher clock fine https docs google com spreadsheets eq_zlqgduaqecpph_vhkrcqp qyoqvzkuxjowi edit usp drivesdk,"['need', 'opinions', 'gpu', 'server', 'buildwork', 'getting', 'server', 'ml', 'deep', 'learning', 'price', 'issue', 'looking', 'cut', 'much', 'wanted', 'make', 'sure', 'overlooking', 'anything', 'terms', 'compatibility', 'main', 'concern', 'cpu', 'would', 'recommend', 'getting', 'cores', 'higher', 'clock', 'fine', 'https', 'docs', 'google', 'com', 'spreadsheets', 'eq_zlqgduaqecpph_vhkrcqp', 'qyoqvzkuxjowi', 'edit', 'usp', 'drivesdk']","['need', 'opinion', 'gpu', 'server', 'buildwork', 'get', 'server', 'ml', 'deep', 'learn', 'price', 'issu', 'look', 'cut', 'much', 'want', 'make', 'sure', 'overlook', 'anyth', 'term', 'compat', 'main', 'concern', 'cpu', 'would', 'recommend', 'get', 'core', 'higher', 'clock', 'fine', 'http', 'doc', 'googl', 'com', 'spreadsheet', 'eq_zlqgduaqecpph_vhkrcqp', 'qyoqvzkuxjowi', 'edit', 'usp', 'drivesdk']"
243,266,266,XtremePocket,vjs5jj,[D] Loss for generating sequences of items,"Let's say you have a task where you need to generate blobs of texts using a AR LM. The targets are separated in the form of `[blob1], [blob2], ...` where each blob contains some numbers and letters, and the order of the blobs matters. Now, a naive way would be just to train the network to generate tokens greedily. But could we do better? A greedy loss could still theoretically give us a great model, but is there another way that exploits the blob patterns?

An idea I have: If we believe the model should first learn existence of blobs then learn the order (a fair assumption in my application), we could first find a matching between all generated blobs and target blobs and optimize the best matches only, then impose a penalty to get the order right. The order might be enforced via maybe taking a weighted average between the greedy loss and the blob-matched loss?

What do you think?",1,0,2022-06-24 21:48:34, d  loss for generating sequences of items,let s say you have a task where you need to generate blobs of texts using a ar lm  the targets are separated in the form of   blob    blob        where each blob contains some numbers and letters  and the order of the blobs matters  now  a naive way would be just to train the network to generate tokens greedily  but could we do better  a greedy loss could still theoretically give us a great model  but is there another way that exploits the blob patterns an idea i have  if we believe the model should first learn existence of blobs then learn the order  a fair assumption in my application   we could first find a matching between all generated blobs and target blobs and optimize the best matches only  then impose a penalty to get the order right  the order might be enforced via maybe taking a weighted average between the greedy loss and the blob matched loss what do you think ,let say task need generate blobs texts using ar lm targets separated form blob blob blob contains numbers letters order blobs matters naive way would train network generate tokens greedily could better greedy loss could still theoretically give us great model another way exploits blob patterns idea believe model first learn existence blobs learn order fair assumption application could first find matching generated blobs target blobs optimize best matches impose penalty get order right order might enforced via maybe taking weighted average greedy loss blob matched loss think,loss generating sequences items,loss generating sequences itemslet say task need generate blobs texts using ar lm targets separated form blob blob blob contains numbers letters order blobs matters naive way would train network generate tokens greedily could better greedy loss could still theoretically give us great model another way exploits blob patterns idea believe model first learn existence blobs learn order fair assumption application could first find matching generated blobs target blobs optimize best matches impose penalty get order right order might enforced via maybe taking weighted average greedy loss blob matched loss think,"['loss', 'generating', 'sequences', 'itemslet', 'say', 'task', 'need', 'generate', 'blobs', 'texts', 'using', 'ar', 'lm', 'targets', 'separated', 'form', 'blob', 'blob', 'blob', 'contains', 'numbers', 'letters', 'order', 'blobs', 'matters', 'naive', 'way', 'would', 'train', 'network', 'generate', 'tokens', 'greedily', 'could', 'better', 'greedy', 'loss', 'could', 'still', 'theoretically', 'give', 'us', 'great', 'model', 'another', 'way', 'exploits', 'blob', 'patterns', 'idea', 'believe', 'model', 'first', 'learn', 'existence', 'blobs', 'learn', 'order', 'fair', 'assumption', 'application', 'could', 'first', 'find', 'matching', 'generated', 'blobs', 'target', 'blobs', 'optimize', 'best', 'matches', 'impose', 'penalty', 'get', 'order', 'right', 'order', 'might', 'enforced', 'via', 'maybe', 'taking', 'weighted', 'average', 'greedy', 'loss', 'blob', 'matched', 'loss', 'think']","['loss', 'gener', 'sequenc', 'itemslet', 'say', 'task', 'need', 'gener', 'blob', 'text', 'use', 'ar', 'lm', 'target', 'separ', 'form', 'blob', 'blob', 'blob', 'contain', 'number', 'letter', 'order', 'blob', 'matter', 'naiv', 'way', 'would', 'train', 'network', 'gener', 'token', 'greedili', 'could', 'better', 'greedi', 'loss', 'could', 'still', 'theoret', 'give', 'us', 'great', 'model', 'anoth', 'way', 'exploit', 'blob', 'pattern', 'idea', 'believ', 'model', 'first', 'learn', 'exist', 'blob', 'learn', 'order', 'fair', 'assumpt', 'applic', 'could', 'first', 'find', 'match', 'gener', 'blob', 'target', 'blob', 'optim', 'best', 'match', 'impos', 'penalti', 'get', 'order', 'right', 'order', 'might', 'enforc', 'via', 'mayb', 'take', 'weight', 'averag', 'greedi', 'loss', 'blob', 'match', 'loss', 'think']"
244,267,267,gambs,vj2kc3,[R] Learning to Play Minecraft with Video PreTraining (VPT),"[OpenAI Blog: Learning to Play Minecraft with Video PreTraining (VPT)](https://openai.com/blog/vpt/)

OpenAI gathered a large dataset of human Minecraft demonstrations and trained an Inverse Dynamics Model (IDM) transformer that predicts actions based on past and future frames using a dataset of human demonstrations. They used this model to label 70k hours of video, which is used to train a Video PreTraining (VPT) model, which predicts actions based on past frames alone, using behavioral cloning (i.e. supervised learning).

They can then fine-tune the VPT via behavioral cloning on narrower datasets or RL (with a hand-designed reward function that rewards the agent for going deeper into the tech tree or obtaining materials that could lead to a diamond pickaxe) and are able to train an agent that can craft a diamond pickaxe in 2.5% of its 10-minute long episodes.",8,48,2022-06-23 23:12:15, r  learning to play minecraft with video pretraining  vpt , openai blog  learning to play minecraft with video pretraining  vpt   https openai gathered a large dataset of human minecraft demonstrations and trained an inverse dynamics model  idm  transformer that predicts actions based on past and future frames using a dataset of human demonstrations  they used this model to label k hours of video  which is used to train a video pretraining  vpt  model  which predicts actions based on past frames alone  using behavioral cloning  i e  supervised learning  they can then fine tune the vpt via behavioral cloning on narrower datasets or rl  with a hand designed reward function that rewards the agent for going deeper into the tech tree or obtaining materials that could lead to a diamond pickaxe  and are able to train an agent that can craft a diamond pickaxe in    of its  minute long episodes ,openai blog learning play minecraft video pretraining vpt https openai gathered large dataset human minecraft demonstrations trained inverse dynamics model idm transformer predicts actions based past future frames using dataset human demonstrations used model label k hours video used train video pretraining vpt model predicts actions based past frames alone using behavioral cloning e supervised learning fine tune vpt via behavioral cloning narrower datasets rl hand designed reward function rewards agent going deeper tech tree obtaining materials could lead diamond pickaxe able train agent craft diamond pickaxe minute long episodes,r learning play minecraft video pretraining vpt,r learning play minecraft video pretraining vptopenai blog learning play minecraft video pretraining vpt https openai gathered large dataset human minecraft demonstrations trained inverse dynamics model idm transformer predicts actions based past future frames using dataset human demonstrations used model label k hours video used train video pretraining vpt model predicts actions based past frames alone using behavioral cloning e supervised learning fine tune vpt via behavioral cloning narrower datasets rl hand designed reward function rewards agent going deeper tech tree obtaining materials could lead diamond pickaxe able train agent craft diamond pickaxe minute long episodes,"['r', 'learning', 'play', 'minecraft', 'video', 'pretraining', 'vptopenai', 'blog', 'learning', 'play', 'minecraft', 'video', 'pretraining', 'vpt', 'https', 'openai', 'gathered', 'large', 'dataset', 'human', 'minecraft', 'demonstrations', 'trained', 'inverse', 'dynamics', 'model', 'idm', 'transformer', 'predicts', 'actions', 'based', 'past', 'future', 'frames', 'using', 'dataset', 'human', 'demonstrations', 'used', 'model', 'label', 'k', 'hours', 'video', 'used', 'train', 'video', 'pretraining', 'vpt', 'model', 'predicts', 'actions', 'based', 'past', 'frames', 'alone', 'using', 'behavioral', 'cloning', 'e', 'supervised', 'learning', 'fine', 'tune', 'vpt', 'via', 'behavioral', 'cloning', 'narrower', 'datasets', 'rl', 'hand', 'designed', 'reward', 'function', 'rewards', 'agent', 'going', 'deeper', 'tech', 'tree', 'obtaining', 'materials', 'could', 'lead', 'diamond', 'pickaxe', 'able', 'train', 'agent', 'craft', 'diamond', 'pickaxe', 'minute', 'long', 'episodes']","['r', 'learn', 'play', 'minecraft', 'video', 'pretrain', 'vptopenai', 'blog', 'learn', 'play', 'minecraft', 'video', 'pretrain', 'vpt', 'http', 'openai', 'gather', 'larg', 'dataset', 'human', 'minecraft', 'demonstr', 'train', 'invers', 'dynam', 'model', 'idm', 'transform', 'predict', 'action', 'base', 'past', 'futur', 'frame', 'use', 'dataset', 'human', 'demonstr', 'use', 'model', 'label', 'k', 'hour', 'video', 'use', 'train', 'video', 'pretrain', 'vpt', 'model', 'predict', 'action', 'base', 'past', 'frame', 'alon', 'use', 'behavior', 'clone', 'e', 'supervis', 'learn', 'fine', 'tune', 'vpt', 'via', 'behavior', 'clone', 'narrow', 'dataset', 'rl', 'hand', 'design', 'reward', 'function', 'reward', 'agent', 'go', 'deeper', 'tech', 'tree', 'obtain', 'materi', 'could', 'lead', 'diamond', 'pickax', 'abl', 'train', 'agent', 'craft', 'diamond', 'pickax', 'minut', 'long', 'episod']"
245,268,268,scoutsearchteam,vjamsw,[Project] Semantic Search powerup for Ctrl+F,"Hi Reddit!

Scout Search is a project I've been working on as a Find-in-Page replacement.

It uses a semantic search engine (rather than character matching) to help you find what you're looking for on websites.

Try it out and let me know what you think.

[https://chrome.google.com/webstore/detail/scout-search/hgljpodblkjjklailoaefokflfdeffdl](https://chrome.google.com/webstore/detail/scout-search/hgljpodblkjjklailoaefokflfdeffdl)",4,10,2022-06-24 05:20:36, project  semantic search powerup for ctrl f,hi reddit scout search is a project i ve been working on as a find in page replacement it uses a semantic search engine  rather than character matching  to help you find what you re looking for on websites try it out and let me know what you think  https   chrome google com webstore detail scout search hgljpodblkjjklailoaefokflfdeffdl  https   chrome google com webstore detail scout search hgljpodblkjjklailoaefokflfdeffdl ,hi reddit scout search project working find page replacement uses semantic search engine rather character matching help find looking websites try let know think https chrome google com webstore detail scout search hgljpodblkjjklailoaefokflfdeffdl https chrome google com webstore detail scout search hgljpodblkjjklailoaefokflfdeffdl,project semantic search powerup ctrl f,project semantic search powerup ctrl fhi reddit scout search project working find page replacement uses semantic search engine rather character matching help find looking websites try let know think https chrome google com webstore detail scout search hgljpodblkjjklailoaefokflfdeffdl https chrome google com webstore detail scout search hgljpodblkjjklailoaefokflfdeffdl,"['project', 'semantic', 'search', 'powerup', 'ctrl', 'fhi', 'reddit', 'scout', 'search', 'project', 'working', 'find', 'page', 'replacement', 'uses', 'semantic', 'search', 'engine', 'rather', 'character', 'matching', 'help', 'find', 'looking', 'websites', 'try', 'let', 'know', 'think', 'https', 'chrome', 'google', 'com', 'webstore', 'detail', 'scout', 'search', 'hgljpodblkjjklailoaefokflfdeffdl', 'https', 'chrome', 'google', 'com', 'webstore', 'detail', 'scout', 'search', 'hgljpodblkjjklailoaefokflfdeffdl']","['project', 'semant', 'search', 'powerup', 'ctrl', 'fhi', 'reddit', 'scout', 'search', 'project', 'work', 'find', 'page', 'replac', 'use', 'semant', 'search', 'engin', 'rather', 'charact', 'match', 'help', 'find', 'look', 'websit', 'tri', 'let', 'know', 'think', 'http', 'chrome', 'googl', 'com', 'webstor', 'detail', 'scout', 'search', 'hgljpodblkjjklailoaefokflfdeffdl', 'http', 'chrome', 'googl', 'com', 'webstor', 'detail', 'scout', 'search', 'hgljpodblkjjklailoaefokflfdeffdl']"
246,269,269,optimized-adam,vjlhee,[D] Publishing two papers at the same time,"Let's say I have done some research, developed some ideas and gotten good results. But there are two main ideas that tackle different problems and don't really belong in the same paper, although there is some relationship between them. The paper of idea #2 would cite and use idea #1. What have you done in similar situations? Can you try to publish both at the same time and have a citation to the first paper that hasn't even been published yet? Post on arXiv and try to publish the first one first, then the second one?",4,0,2022-06-24 16:11:38, d  publishing two papers at the same time,let s say i have done some research  developed some ideas and gotten good results  but there are two main ideas that tackle different problems and don t really belong in the same paper  although there is some relationship between them  the paper of idea   would cite and use idea    what have you done in similar situations  can you try to publish both at the same time and have a citation to the first paper that hasn t even been published yet  post on arxiv and try to publish the first one first  then the second one ,let say done research developed ideas gotten good results two main ideas tackle different problems really belong paper although relationship paper idea would cite use idea done similar situations try publish time citation first paper even published yet post arxiv try publish first one first second one,publishing two papers time,publishing two papers timelet say done research developed ideas gotten good results two main ideas tackle different problems really belong paper although relationship paper idea would cite use idea done similar situations try publish time citation first paper even published yet post arxiv try publish first one first second one,"['publishing', 'two', 'papers', 'timelet', 'say', 'done', 'research', 'developed', 'ideas', 'gotten', 'good', 'results', 'two', 'main', 'ideas', 'tackle', 'different', 'problems', 'really', 'belong', 'paper', 'although', 'relationship', 'paper', 'idea', 'would', 'cite', 'use', 'idea', 'done', 'similar', 'situations', 'try', 'publish', 'time', 'citation', 'first', 'paper', 'even', 'published', 'yet', 'post', 'arxiv', 'try', 'publish', 'first', 'one', 'first', 'second', 'one']","['publish', 'two', 'paper', 'timelet', 'say', 'done', 'research', 'develop', 'idea', 'gotten', 'good', 'result', 'two', 'main', 'idea', 'tackl', 'differ', 'problem', 'realli', 'belong', 'paper', 'although', 'relationship', 'paper', 'idea', 'would', 'cite', 'use', 'idea', 'done', 'similar', 'situat', 'tri', 'publish', 'time', 'citat', 'first', 'paper', 'even', 'publish', 'yet', 'post', 'arxiv', 'tri', 'publish', 'first', 'one', 'first', 'second', 'one']"
247,270,270,Supremefigur,vjw1a5,[R] Anatomy of an AI System [Infographic],"[https://anatomyof.ai/img/ai-anatomy-map.pdf](https://anatomyof.ai/img/ai-anatomy-map.pdf)  


A beautiful infographic explaining the whole process",0,0,2022-06-25 00:43:47, r  anatomy of an ai system  infographic , https a beautiful infographic explaining the whole process,https beautiful infographic explaining whole process,r anatomy ai system infographic,r anatomy ai system infographichttps beautiful infographic explaining whole process,"['r', 'anatomy', 'ai', 'system', 'infographichttps', 'beautiful', 'infographic', 'explaining', 'whole', 'process']","['r', 'anatomi', 'ai', 'system', 'infographichttp', 'beauti', 'infograph', 'explain', 'whole', 'process']"
248,271,271,SleekEagle,viyh17,[D] How Imagen Actually Works,"Hey everyone!

[I wrote this article explaining how Imagen actually works](https://www.assemblyai.com/blog/how-imagen-actually-works/), with a general overview for the big picture ideas and a Deep Dive to get into the nitty-gritty.

I'm happy to answer any questions, let me know what you think!

https://preview.redd.it/17xc5fqeud791.png?width=3472&format=png&auto=webp&s=e78a024892a3032ffc0c143b7843a5223751afcb",19,33,2022-06-23 20:10:27, d  how imagen actually works,hey everyone  i wrote this article explaining how imagen actually works  https i m happy to answer any questions  let me know what you think https   preview redd it xcfqeud png width  format png auto webp s eaaffccbaafcb,hey everyone wrote article explaining imagen actually works https happy answer questions let know think https preview redd xcfqeud png width format png auto webp eaaffccbaafcb,imagen actually works,imagen actually workshey everyone wrote article explaining imagen actually works https happy answer questions let know think https preview redd xcfqeud png width format png auto webp eaaffccbaafcb,"['imagen', 'actually', 'workshey', 'everyone', 'wrote', 'article', 'explaining', 'imagen', 'actually', 'works', 'https', 'happy', 'answer', 'questions', 'let', 'know', 'think', 'https', 'preview', 'redd', 'xcfqeud', 'png', 'width', 'format', 'png', 'auto', 'webp', 'eaaffccbaafcb']","['imagen', 'actual', 'workshey', 'everyon', 'wrote', 'articl', 'explain', 'imagen', 'actual', 'work', 'http', 'happi', 'answer', 'question', 'let', 'know', 'think', 'http', 'preview', 'redd', 'xcfqeud', 'png', 'width', 'format', 'png', 'auto', 'webp', 'eaaffccbaafcb']"
249,272,272,ManagementBig2995,vj6uh1,[P] HyperImpute: sklearn-style library for handling missing data using novel algorithms,"There are many data imputation algorithms for machine learning. However, benchmarking them can be complicated, mainly because most implementations stay just as research code to reproduce the experiments in the papers. Moreover, when dealing with tabular data, you need to handle continuous/discrete/categorical data correctly -- not just let some regressor approximate everything.

HyperImpute is a library that should make it easy to benchmark new imputation algorithms while offering several state-of-the-art models. For example, imputing using MIWAE can be done as easy as this:

    import pandas as pd
    import numpy as np
    from hyperimpute.plugins.imputers import Imputers
    
    X = pd.DataFrame([[1, 1, 1, 1], [4, 5, np.nan, np.nan], [3, 3, 9, 9], [2, 2, 2, 2]])
    
    plugin = Imputers().get(""miwae"")
    out = plugin.fit_transform(X.copy())
    
    out

Bonus, it can be easily plugged into sklearn pipelines.

Try it in Colab: [https://colab.research.google.com/drive/1zGm4VeXsJ-0x6A5\_icnknE7mbJ0knUig?usp=sharing](https://colab.research.google.com/drive/1zGm4VeXsJ-0x6A5_icnknE7mbJ0knUig?usp=sharing)

Github page: [https://github.com/vanderschaarlab/hyperimpute](https://github.com/vanderschaarlab/hyperimpute)

If you find the project useful, please star it on Github, it would help a lot!",0,9,2022-06-24 02:22:22, p  hyperimpute  sklearn style library for handling missing data using novel algorithms,there are many data imputation algorithms for machine learning  however  benchmarking them can be complicated  mainly because most implementations stay just as research code to reproduce the experiments in the papers  moreover  when dealing with tabular data  you need to handle continuous discrete categorical data correctly    not just let some regressor approximate everything hyperimpute is a library that should make it easy to benchmark new imputation algorithms while offering several state of the art models  for example  imputing using miwae can be done as easy as this     import pandas as pd    import numpy as np    from hyperimpute plugins imputers import imputers        x   pd dataframe                 np nan  np nan                               plugin   imputers   get miwae     out   plugin fit_transform x copy           outbonus  it can be easily plugged into sklearn pipelines try it in colab   https github page   https if you find the project useful  please star it on github  it would help a lot ,many data imputation algorithms machine learning however benchmarking complicated mainly implementations stay research code reproduce experiments papers moreover dealing tabular data need handle continuous discrete categorical data correctly let regressor approximate everything hyperimpute library make easy benchmark imputation algorithms offering several state art models example imputing using miwae done easy import pandas pd import numpy np hyperimpute plugins imputers import imputers x pd dataframe np nan np nan plugin imputers get miwae plugin fit_transform x copy outbonus easily plugged sklearn pipelines try colab https github page https find project useful please star github would help lot,p hyperimpute sklearn style library handling missing data using novel algorithms,p hyperimpute sklearn style library handling missing data using novel algorithmsmany data imputation algorithms machine learning however benchmarking complicated mainly implementations stay research code reproduce experiments papers moreover dealing tabular data need handle continuous discrete categorical data correctly let regressor approximate everything hyperimpute library make easy benchmark imputation algorithms offering several state art models example imputing using miwae done easy import pandas pd import numpy np hyperimpute plugins imputers import imputers x pd dataframe np nan np nan plugin imputers get miwae plugin fit_transform x copy outbonus easily plugged sklearn pipelines try colab https github page https find project useful please star github would help lot,"['p', 'hyperimpute', 'sklearn', 'style', 'library', 'handling', 'missing', 'data', 'using', 'novel', 'algorithmsmany', 'data', 'imputation', 'algorithms', 'machine', 'learning', 'however', 'benchmarking', 'complicated', 'mainly', 'implementations', 'stay', 'research', 'code', 'reproduce', 'experiments', 'papers', 'moreover', 'dealing', 'tabular', 'data', 'need', 'handle', 'continuous', 'discrete', 'categorical', 'data', 'correctly', 'let', 'regressor', 'approximate', 'everything', 'hyperimpute', 'library', 'make', 'easy', 'benchmark', 'imputation', 'algorithms', 'offering', 'several', 'state', 'art', 'models', 'example', 'imputing', 'using', 'miwae', 'done', 'easy', 'import', 'pandas', 'pd', 'import', 'numpy', 'np', 'hyperimpute', 'plugins', 'imputers', 'import', 'imputers', 'x', 'pd', 'dataframe', 'np', 'nan', 'np', 'nan', 'plugin', 'imputers', 'get', 'miwae', 'plugin', 'fit_transform', 'x', 'copy', 'outbonus', 'easily', 'plugged', 'sklearn', 'pipelines', 'try', 'colab', 'https', 'github', 'page', 'https', 'find', 'project', 'useful', 'please', 'star', 'github', 'would', 'help', 'lot']","['p', 'hyperimput', 'sklearn', 'style', 'librari', 'handl', 'miss', 'data', 'use', 'novel', 'algorithmsmani', 'data', 'imput', 'algorithm', 'machin', 'learn', 'howev', 'benchmark', 'complic', 'mainli', 'implement', 'stay', 'research', 'code', 'reproduc', 'experi', 'paper', 'moreov', 'deal', 'tabular', 'data', 'need', 'handl', 'continu', 'discret', 'categor', 'data', 'correctli', 'let', 'regressor', 'approxim', 'everyth', 'hyperimput', 'librari', 'make', 'easi', 'benchmark', 'imput', 'algorithm', 'offer', 'sever', 'state', 'art', 'model', 'exampl', 'imput', 'use', 'miwa', 'done', 'easi', 'import', 'panda', 'pd', 'import', 'numpi', 'np', 'hyperimput', 'plugin', 'imput', 'import', 'imput', 'x', 'pd', 'datafram', 'np', 'nan', 'np', 'nan', 'plugin', 'imput', 'get', 'miwa', 'plugin', 'fit_transform', 'x', 'copi', 'outbonu', 'easili', 'plug', 'sklearn', 'pipelin', 'tri', 'colab', 'http', 'github', 'page', 'http', 'find', 'project', 'use', 'pleas', 'star', 'github', 'would', 'help', 'lot']"
250,273,273,guyfrom7up,vj1zp0,[P] AutoRegistry: A Python library for mapping names to functionality to simplify project configurations.,"A common design pattern I see in a lot of ML projects is to have some sort of experiment configuration file, and then a bunch of code that constructs the appropriate objects based on these configurations. Frequently, the resulting code blocks have a bunch of `if/elif/else` statements, or a manually created lookup dictionary somewhere. This can quickly get messy and inconsistent as you add new models/losses/encoders/optimizers.  

AutoRegistry is a library that makes all of these lookups more organized and terse. For example, lets say you want to configure a backbone to either be ""resnet34"" or ""resnet50"". Your code could look something like this (mimicking torchvision code) using a decorator: 

```
from autoregistry import Registry

models = Registry()

@models
def resnet34(*, weights: Optional[ResNet34_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:
    return _resnet(BasicBlock, [3, 4, 6, 3], weights, progress, **kwargs)

@models
def resnet50(*, weights: Optional[ResNet50_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:
    return _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)

# create a model based off of some configuration dictionary.
model_config = copy(config[""model""])
model_type = model_config.pop(""type"")
model = models[model_type](**model_config)
```

or, class-based inheritance (uses metaclasses internally):

```
class BaseModel(nn.Module, Registry):
    pass

class MyNewModel(BaseModel):
    pass

class SomeOtherModel(BaseModel):
    pass

# stringified keys are automatically derived.
my_new_model = BaseModel[""mynewmodel""](**config)
some_other_model = BaseModel[""someothermodel""](**config)
```

Github Page:  
[https://github.com/BrianPugh/autoregistry](https://github.com/BrianPugh/autoregistry)",1,10,2022-06-23 22:46:46, p  autoregistry  a python library for mapping names to functionality to simplify project configurations ,a common design pattern i see in a lot of ml projects is to have some sort of experiment configuration file  and then a bunch of code that constructs the appropriate objects based on these configurations  frequently  the resulting code blocks have a bunch of  if elif else  statements  or a manually created lookup dictionary somewhere  this can quickly get messy and inconsistent as you add new models losses encoders optimizers   autoregistry is a library that makes all of these lookups more organized and terse  for example  lets say you want to configure a backbone to either be resnet or resnet  your code could look something like this  mimicking torchvision code  using a decorator     from autoregistry import registrymodels   registry   modelsdef resnet    weights  optional resnet_weights    none  progress  bool   true    kwargs  any     resnet     return _resnet basicblock            weights  progress    kwargs  modelsdef resnet    weights  optional resnet_weights    none  progress  bool   true    kwargs  any     resnet     return _resnet bottleneck            weights  progress    kwargs   create a model based off of some configuration dictionary model_config   copy config model  model_type   model_config pop type model   models model_type    model_config    or  class based inheritance  uses metaclasses internally     class basemodel nn module  registry      passclass mynewmodel basemodel      passclass someothermodel basemodel      pass  stringified keys are automatically derived my_new_model   basemodel mynewmodel    config some_other_model   basemodel someothermodel    config    github page    https   github com brianpugh autoregistry  https   github com brianpugh autoregistry ,common design pattern see lot ml projects sort experiment configuration file bunch code constructs appropriate objects based configurations frequently resulting code blocks bunch elif else statements manually created lookup dictionary somewhere quickly get messy inconsistent models losses encoders optimizers autoregistry library makes lookups organized terse example lets say want configure backbone either resnet resnet code could look something like mimicking torchvision code using decorator autoregistry import registrymodels registry modelsdef resnet weights optional resnet_weights none progress bool true kwargs resnet return _resnet basicblock weights progress kwargs modelsdef resnet weights optional resnet_weights none progress bool true kwargs resnet return _resnet bottleneck weights progress kwargs create model based configuration dictionary model_config copy config model model_type model_config pop type model models model_type model_config class based inheritance uses metaclasses internally class basemodel nn module registry passclass mynewmodel basemodel passclass someothermodel basemodel pass stringified keys automatically derived my_new_model basemodel mynewmodel config some_other_model basemodel someothermodel config github page https github com brianpugh autoregistry https github com brianpugh autoregistry,p autoregistry python library mapping names functionality simplify project configurations,p autoregistry python library mapping names functionality simplify project configurationscommon design pattern see lot ml projects sort experiment configuration file bunch code constructs appropriate objects based configurations frequently resulting code blocks bunch elif else statements manually created lookup dictionary somewhere quickly get messy inconsistent models losses encoders optimizers autoregistry library makes lookups organized terse example lets say want configure backbone either resnet resnet code could look something like mimicking torchvision code using decorator autoregistry import registrymodels registry modelsdef resnet weights optional resnet_weights none progress bool true kwargs resnet return _resnet basicblock weights progress kwargs modelsdef resnet weights optional resnet_weights none progress bool true kwargs resnet return _resnet bottleneck weights progress kwargs create model based configuration dictionary model_config copy config model model_type model_config pop type model models model_type model_config class based inheritance uses metaclasses internally class basemodel nn module registry passclass mynewmodel basemodel passclass someothermodel basemodel pass stringified keys automatically derived my_new_model basemodel mynewmodel config some_other_model basemodel someothermodel config github page https github com brianpugh autoregistry https github com brianpugh autoregistry,"['p', 'autoregistry', 'python', 'library', 'mapping', 'names', 'functionality', 'simplify', 'project', 'configurationscommon', 'design', 'pattern', 'see', 'lot', 'ml', 'projects', 'sort', 'experiment', 'configuration', 'file', 'bunch', 'code', 'constructs', 'appropriate', 'objects', 'based', 'configurations', 'frequently', 'resulting', 'code', 'blocks', 'bunch', 'elif', 'else', 'statements', 'manually', 'created', 'lookup', 'dictionary', 'somewhere', 'quickly', 'get', 'messy', 'inconsistent', 'models', 'losses', 'encoders', 'optimizers', 'autoregistry', 'library', 'makes', 'lookups', 'organized', 'terse', 'example', 'lets', 'say', 'want', 'configure', 'backbone', 'either', 'resnet', 'resnet', 'code', 'could', 'look', 'something', 'like', 'mimicking', 'torchvision', 'code', 'using', 'decorator', 'autoregistry', 'import', 'registrymodels', 'registry', 'modelsdef', 'resnet', 'weights', 'optional', 'resnet_weights', 'none', 'progress', 'bool', 'true', 'kwargs', 'resnet', 'return', '_resnet', 'basicblock', 'weights', 'progress', 'kwargs', 'modelsdef', 'resnet', 'weights', 'optional', 'resnet_weights', 'none', 'progress', 'bool', 'true', 'kwargs', 'resnet', 'return', '_resnet', 'bottleneck', 'weights', 'progress', 'kwargs', 'create', 'model', 'based', 'configuration', 'dictionary', 'model_config', 'copy', 'config', 'model', 'model_type', 'model_config', 'pop', 'type', 'model', 'models', 'model_type', 'model_config', 'class', 'based', 'inheritance', 'uses', 'metaclasses', 'internally', 'class', 'basemodel', 'nn', 'module', 'registry', 'passclass', 'mynewmodel', 'basemodel', 'passclass', 'someothermodel', 'basemodel', 'pass', 'stringified', 'keys', 'automatically', 'derived', 'my_new_model', 'basemodel', 'mynewmodel', 'config', 'some_other_model', 'basemodel', 'someothermodel', 'config', 'github', 'page', 'https', 'github', 'com', 'brianpugh', 'autoregistry', 'https', 'github', 'com', 'brianpugh', 'autoregistry']","['p', 'autoregistri', 'python', 'librari', 'map', 'name', 'function', 'simplifi', 'project', 'configurationscommon', 'design', 'pattern', 'see', 'lot', 'ml', 'project', 'sort', 'experi', 'configur', 'file', 'bunch', 'code', 'construct', 'appropri', 'object', 'base', 'configur', 'frequent', 'result', 'code', 'block', 'bunch', 'elif', 'els', 'statement', 'manual', 'creat', 'lookup', 'dictionari', 'somewher', 'quickli', 'get', 'messi', 'inconsist', 'model', 'loss', 'encod', 'optim', 'autoregistri', 'librari', 'make', 'lookup', 'organ', 'ters', 'exampl', 'let', 'say', 'want', 'configur', 'backbon', 'either', 'resnet', 'resnet', 'code', 'could', 'look', 'someth', 'like', 'mimick', 'torchvis', 'code', 'use', 'decor', 'autoregistri', 'import', 'registrymodel', 'registri', 'modelsdef', 'resnet', 'weight', 'option', 'resnet_weight', 'none', 'progress', 'bool', 'true', 'kwarg', 'resnet', 'return', '_resnet', 'basicblock', 'weight', 'progress', 'kwarg', 'modelsdef', 'resnet', 'weight', 'option', 'resnet_weight', 'none', 'progress', 'bool', 'true', 'kwarg', 'resnet', 'return', '_resnet', 'bottleneck', 'weight', 'progress', 'kwarg', 'creat', 'model', 'base', 'configur', 'dictionari', 'model_config', 'copi', 'config', 'model', 'model_typ', 'model_config', 'pop', 'type', 'model', 'model', 'model_typ', 'model_config', 'class', 'base', 'inherit', 'use', 'metaclass', 'intern', 'class', 'basemodel', 'nn', 'modul', 'registri', 'passclass', 'mynewmodel', 'basemodel', 'passclass', 'someothermodel', 'basemodel', 'pass', 'stringifi', 'key', 'automat', 'deriv', 'my_new_model', 'basemodel', 'mynewmodel', 'config', 'some_other_model', 'basemodel', 'someothermodel', 'config', 'github', 'page', 'http', 'github', 'com', 'brianpugh', 'autoregistri', 'http', 'github', 'com', 'brianpugh', 'autoregistri']"
251,274,274,an1_r_00dh,vjfgb9,[Discussion] Is there a way to increase the weight of a particular feature in an outlier detection method using the isolation forest algorithm?,"I'm currently working on the outlier detection method using the isolation forest algorithm on a dataset with 9 dimensions. Out of these, there is a particular dimension that I want to increase the importance/significance of, in the classification process. Is there a way I can do this? Thanksnin advance.",1,0,2022-06-24 09:36:02, discussion  is there a way to increase the weight of a particular feature in an outlier detection method using the isolation forest algorithm ,i m currently working on the outlier detection method using the isolation forest algorithm on a dataset with  dimensions  out of these  there is a particular dimension that i want to increase the importance significance of  in the classification process  is there a way i can do this  thanksnin advance ,currently working outlier detection method using isolation forest algorithm dataset dimensions particular dimension want increase importance significance classification process way thanksnin advance,discussion way increase weight particular feature outlier detection method using isolation forest algorithm,discussion way increase weight particular feature outlier detection method using isolation forest algorithmcurrently working outlier detection method using isolation forest algorithm dataset dimensions particular dimension want increase importance significance classification process way thanksnin advance,"['discussion', 'way', 'increase', 'weight', 'particular', 'feature', 'outlier', 'detection', 'method', 'using', 'isolation', 'forest', 'algorithmcurrently', 'working', 'outlier', 'detection', 'method', 'using', 'isolation', 'forest', 'algorithm', 'dataset', 'dimensions', 'particular', 'dimension', 'want', 'increase', 'importance', 'significance', 'classification', 'process', 'way', 'thanksnin', 'advance']","['discuss', 'way', 'increas', 'weight', 'particular', 'featur', 'outlier', 'detect', 'method', 'use', 'isol', 'forest', 'algorithmcurr', 'work', 'outlier', 'detect', 'method', 'use', 'isol', 'forest', 'algorithm', 'dataset', 'dimens', 'particular', 'dimens', 'want', 'increas', 'import', 'signific', 'classif', 'process', 'way', 'thanksnin', 'advanc']"
252,275,275,chromeplated,vitv4u,[N] Microsoft released a DirectML Plugin for TensorFlow 2,"The plugin provides a DirectML PluggableDevice backend for TensorFlow 2, so any GPU which supports DirectX 12 should be able to work with TF2. Hopefully this will pave the way for more support for non-NVIDIA GPUs in ML.  
They provide some more details (installation, code samples, etc') in the [Windows AI devblog](https://devblogs.microsoft.com/windowsai/directml-plugin-for-tensorflow-2-is-here/).",1,11,2022-06-23 16:05:06, n  microsoft released a directml plugin for tensorflow ,the plugin provides a directml pluggabledevice backend for tensorflow   so any gpu which supports directx  should be able to work with tf  hopefully this will pave the way for more support for non nvidia gpus in ml   they provide some more details  installation  code samples  etc   in the  windows ai devblog  https   devblogs microsoft com windowsai directml plugin for tensorflow  is here   ,plugin provides directml pluggabledevice backend tensorflow gpu supports directx able work tf hopefully pave way support non nvidia gpus ml provide details installation code samples etc windows ai devblog https devblogs microsoft com windowsai directml plugin tensorflow,n microsoft released directml plugin tensorflow,n microsoft released directml plugin tensorflowplugin provides directml pluggabledevice backend tensorflow gpu supports directx able work tf hopefully pave way support non nvidia gpus ml provide details installation code samples etc windows ai devblog https devblogs microsoft com windowsai directml plugin tensorflow,"['n', 'microsoft', 'released', 'directml', 'plugin', 'tensorflowplugin', 'provides', 'directml', 'pluggabledevice', 'backend', 'tensorflow', 'gpu', 'supports', 'directx', 'able', 'work', 'tf', 'hopefully', 'pave', 'way', 'support', 'non', 'nvidia', 'gpus', 'ml', 'provide', 'details', 'installation', 'code', 'samples', 'etc', 'windows', 'ai', 'devblog', 'https', 'devblogs', 'microsoft', 'com', 'windowsai', 'directml', 'plugin', 'tensorflow']","['n', 'microsoft', 'releas', 'directml', 'plugin', 'tensorflowplugin', 'provid', 'directml', 'pluggabledevic', 'backend', 'tensorflow', 'gpu', 'support', 'directx', 'abl', 'work', 'tf', 'hope', 'pave', 'way', 'support', 'non', 'nvidia', 'gpu', 'ml', 'provid', 'detail', 'instal', 'code', 'sampl', 'etc', 'window', 'ai', 'devblog', 'http', 'devblog', 'microsoft', 'com', 'windowsai', 'directml', 'plugin', 'tensorflow']"
253,276,276,codeinassembly,viwb07,[D] [P] A TensorFlow Re-Implementation of CheXNet - Classification and Localization of Thoracic Diseases,"TL:DR; need help making heatmaps!   
\[[Repository](https://dagshub.com/nirbarazida/Pneumonia-Classification)|[Colab Notebook](https://colab.research.google.com/drive/1U3F5ETJeisBnlmamR4EqigS7shIbL2L1#scrollTo=Ghq8fYm5yo8o)\]

Hey everyone -

I've been working to reproduce [CheXNet](https://arxiv.org/pdf/1711.05225.pdf) \- a fantastic paper describing research on a model capable of radiologist-grade pathology classification!

CheXNet uses Class Activation Mappings (CAMs for short) to generate heatmaps that identify what parts of the image the model uses to base its classification. In my case, I'm facing a bit of a struggle reproducing them - as shown in the image below, **most of our classifications are derived from the diaphragm, instead of regions within the lung**. Curiously, we are attaining a reasonable AUROC, with .773 on training and .749 on validation data - the paper reports .8062 AUROC.

My current model is being trained on a subsample of the main dataset, and I'm basically looking to this as a way to validate the architecture. I'd love to know if anyone has experienced similar issues and solved them, and could have any input here as well.

If you have a moment to spare - I'd be super grateful for some help from the r/MachineLearning community in solving the inaccurate localization issue - [\#58](https://dagshub.com/nirbarazida/Pneumonia-Classification/issues/58)!

[Fig 1. An incorrect localization, despite a correct classification.](https://preview.redd.it/umoq6vjmbd791.png?width=451&format=png&auto=webp&s=3dc1d8a99925db47a02c3f719e1d9fd0ba984535)",1,7,2022-06-23 18:25:31, d   p  a tensorflow re implementation of chexnet   classification and localization of thoracic diseases,tl dr  need help making heatmaps       repository  https hey everyone  i ve been working to reproduce  chexnet  https chexnet uses class activation mappings  cams for short  to generate heatmaps that identify what parts of the image the model uses to base its classification  in my case  i m facing a bit of a struggle reproducing them   as shown in the image below    most of our classifications are derived from the diaphragm  instead of regions within the lung    curiously  we are attaining a reasonable auroc  with   on training and   on validation data   the paper reports   auroc my current model is being trained on a subsample of the main dataset  and i m basically looking to this as a way to validate the architecture  i d love to know if anyone has experienced similar issues and solved them  and could have any input here as well if you have a moment to spare   i d be super grateful for some help from the r machinelearning community in solving the inaccurate localization issue        https  fig   an incorrect localization  despite a correct classification   https   preview redd it umoqvjmbd png width  format png auto webp s dcdadbacfedfdba ,tl dr need help making heatmaps repository https hey everyone working reproduce chexnet https chexnet uses class activation mappings cams short generate heatmaps identify parts image model uses base classification case facing bit struggle reproducing shown image classifications derived diaphragm instead regions within lung curiously attaining reasonable auroc training validation data paper reports auroc current model trained subsample main dataset basically looking way validate architecture love know anyone experienced similar issues solved could input well moment spare super grateful help r machinelearning community solving inaccurate localization issue https fig incorrect localization despite correct classification https preview redd umoqvjmbd png width format png auto webp dcdadbacfedfdba,p tensorflow implementation chexnet classification localization thoracic diseases,p tensorflow implementation chexnet classification localization thoracic diseasestl dr need help making heatmaps repository https hey everyone working reproduce chexnet https chexnet uses class activation mappings cams short generate heatmaps identify parts image model uses base classification case facing bit struggle reproducing shown image classifications derived diaphragm instead regions within lung curiously attaining reasonable auroc training validation data paper reports auroc current model trained subsample main dataset basically looking way validate architecture love know anyone experienced similar issues solved could input well moment spare super grateful help r machinelearning community solving inaccurate localization issue https fig incorrect localization despite correct classification https preview redd umoqvjmbd png width format png auto webp dcdadbacfedfdba,"['p', 'tensorflow', 'implementation', 'chexnet', 'classification', 'localization', 'thoracic', 'diseasestl', 'dr', 'need', 'help', 'making', 'heatmaps', 'repository', 'https', 'hey', 'everyone', 'working', 'reproduce', 'chexnet', 'https', 'chexnet', 'uses', 'class', 'activation', 'mappings', 'cams', 'short', 'generate', 'heatmaps', 'identify', 'parts', 'image', 'model', 'uses', 'base', 'classification', 'case', 'facing', 'bit', 'struggle', 'reproducing', 'shown', 'image', 'classifications', 'derived', 'diaphragm', 'instead', 'regions', 'within', 'lung', 'curiously', 'attaining', 'reasonable', 'auroc', 'training', 'validation', 'data', 'paper', 'reports', 'auroc', 'current', 'model', 'trained', 'subsample', 'main', 'dataset', 'basically', 'looking', 'way', 'validate', 'architecture', 'love', 'know', 'anyone', 'experienced', 'similar', 'issues', 'solved', 'could', 'input', 'well', 'moment', 'spare', 'super', 'grateful', 'help', 'r', 'machinelearning', 'community', 'solving', 'inaccurate', 'localization', 'issue', 'https', 'fig', 'incorrect', 'localization', 'despite', 'correct', 'classification', 'https', 'preview', 'redd', 'umoqvjmbd', 'png', 'width', 'format', 'png', 'auto', 'webp', 'dcdadbacfedfdba']","['p', 'tensorflow', 'implement', 'chexnet', 'classif', 'local', 'thorac', 'diseasestl', 'dr', 'need', 'help', 'make', 'heatmap', 'repositori', 'http', 'hey', 'everyon', 'work', 'reproduc', 'chexnet', 'http', 'chexnet', 'use', 'class', 'activ', 'map', 'cam', 'short', 'gener', 'heatmap', 'identifi', 'part', 'imag', 'model', 'use', 'base', 'classif', 'case', 'face', 'bit', 'struggl', 'reproduc', 'shown', 'imag', 'classif', 'deriv', 'diaphragm', 'instead', 'region', 'within', 'lung', 'curious', 'attain', 'reason', 'auroc', 'train', 'valid', 'data', 'paper', 'report', 'auroc', 'current', 'model', 'train', 'subsampl', 'main', 'dataset', 'basic', 'look', 'way', 'valid', 'architectur', 'love', 'know', 'anyon', 'experienc', 'similar', 'issu', 'solv', 'could', 'input', 'well', 'moment', 'spare', 'super', 'grate', 'help', 'r', 'machinelearn', 'commun', 'solv', 'inaccur', 'local', 'issu', 'http', 'fig', 'incorrect', 'local', 'despit', 'correct', 'classif', 'http', 'preview', 'redd', 'umoqvjmbd', 'png', 'width', 'format', 'png', 'auto', 'webp', 'dcdadbacfedfdba']"
254,277,277,htrp,vid29a,[R] Scaling Autoregressive Models for Content-Rich Text-to-Image Generation (Google - Parti),"Google published results from an seq2seq transformer model for autoregressive image generation.

Website: https://parti.research.google/

Paper: https://gweb-research-parti.web.app/parti_paper.pdf",15,120,2022-06-23 00:49:10, r  scaling autoregressive models for content rich text to image generation  google   parti ,google published results from an seqseq transformer model for autoregressive image generation website  https paper  https   gweb research parti web app parti_paper pdf,google published results seqseq transformer model autoregressive image generation website https paper https gweb research parti web app parti_paper pdf,r scaling autoregressive models content rich text image generation google parti,r scaling autoregressive models content rich text image generation google partigoogle published results seqseq transformer model autoregressive image generation website https paper https gweb research parti web app parti_paper pdf,"['r', 'scaling', 'autoregressive', 'models', 'content', 'rich', 'text', 'image', 'generation', 'google', 'partigoogle', 'published', 'results', 'seqseq', 'transformer', 'model', 'autoregressive', 'image', 'generation', 'website', 'https', 'paper', 'https', 'gweb', 'research', 'parti', 'web', 'app', 'parti_paper', 'pdf']","['r', 'scale', 'autoregress', 'model', 'content', 'rich', 'text', 'imag', 'gener', 'googl', 'partigoogl', 'publish', 'result', 'seqseq', 'transform', 'model', 'autoregress', 'imag', 'gener', 'websit', 'http', 'paper', 'http', 'gweb', 'research', 'parti', 'web', 'app', 'parti_pap', 'pdf']"
255,278,278,Pedimus,vj6mru,"[D] ""Wrapping"" effects when using diffusion model to generate samples?","I've recently been training a latent diffusion model (it operated on the latent space of a VQ-VAE), and I'm finding that my generated samples have ""wrapping"" effects, i.e.: when I generate the face it wraps up (bottom half of the face in the top half of the image and vice versa). It's worth noting that these halves don't always seem like they belong together, but they individually look quite realistic.

I've checked my training data, and there are absolutely no training samples that exhibit this behaviour, so my model never sees images that exhibit this wrapping effect, so what could be causing this?",2,0,2022-06-24 02:12:51, d  wrapping effects when using diffusion model to generate samples ,i ve recently been training a latent diffusion model  it operated on the latent space of a vq vae   and i m finding that my generated samples have wrapping effects  i e   when i generate the face it wraps up  bottom half of the face in the top half of the image and vice versa   it s worth noting that these halves don t always seem like they belong together  but they individually look quite realistic i ve checked my training data  and there are absolutely no training samples that exhibit this behaviour  so my model never sees images that exhibit this wrapping effect  so what could be causing this ,recently training latent diffusion model operated latent space vq vae finding generated samples wrapping effects e generate face wraps bottom half face top half image vice versa worth noting halves always seem like belong together individually look quite realistic checked training data absolutely training samples exhibit behaviour model never sees images exhibit wrapping effect could causing,wrapping effects using diffusion model generate samples,wrapping effects using diffusion model generate samplesrecently training latent diffusion model operated latent space vq vae finding generated samples wrapping effects e generate face wraps bottom half face top half image vice versa worth noting halves always seem like belong together individually look quite realistic checked training data absolutely training samples exhibit behaviour model never sees images exhibit wrapping effect could causing,"['wrapping', 'effects', 'using', 'diffusion', 'model', 'generate', 'samplesrecently', 'training', 'latent', 'diffusion', 'model', 'operated', 'latent', 'space', 'vq', 'vae', 'finding', 'generated', 'samples', 'wrapping', 'effects', 'e', 'generate', 'face', 'wraps', 'bottom', 'half', 'face', 'top', 'half', 'image', 'vice', 'versa', 'worth', 'noting', 'halves', 'always', 'seem', 'like', 'belong', 'together', 'individually', 'look', 'quite', 'realistic', 'checked', 'training', 'data', 'absolutely', 'training', 'samples', 'exhibit', 'behaviour', 'model', 'never', 'sees', 'images', 'exhibit', 'wrapping', 'effect', 'could', 'causing']","['wrap', 'effect', 'use', 'diffus', 'model', 'gener', 'samplesrec', 'train', 'latent', 'diffus', 'model', 'oper', 'latent', 'space', 'vq', 'vae', 'find', 'gener', 'sampl', 'wrap', 'effect', 'e', 'gener', 'face', 'wrap', 'bottom', 'half', 'face', 'top', 'half', 'imag', 'vice', 'versa', 'worth', 'note', 'halv', 'alway', 'seem', 'like', 'belong', 'togeth', 'individu', 'look', 'quit', 'realist', 'check', 'train', 'data', 'absolut', 'train', 'sampl', 'exhibit', 'behaviour', 'model', 'never', 'see', 'imag', 'exhibit', 'wrap', 'effect', 'could', 'caus']"
256,279,279,ylu175,vig0l7,[R] Announcing DAMP 2.0: Allowing SOTA Anomaly Detection in Massive Time Series Datasets,"Dear Colleagues

We are happy to announce the release of DAMP 2.0 \[a\]. DAMP (Discord Aware Matrix Profile) is an anomaly detection framework that allows you to search datasets with millions or billions of datapoints, all on a conventional machine \[b\].

We are not normally so vainglorious as to announce the publication of  a paper, however:

1)  The code comes bundled with some great new anomaly detection datasets, and there is a real dearth of good datasets in the community (see \[c\])

2)  Some researchers are working on problems that use anomaly detection as a subroutine, and that is their main computational bottleneck. Because DAMP can be up to 10,000 times faster than other approaches, this may be of interest to the community

Best wishes, Yue

\[a\] Matrix Profile XXIV:Scaling Time Series Anomaly Detection to Trillions of Datapoints and Ultra-fast Arriving Data Streams. Yue Lu , Renjie Wu , Abdullah Mueen , Maria A. Zuluaga and Eamonn Keogh. ACM SIGKDD 2022.  [https://www.cs.ucr.edu/\~eamonn/DAMP\_long\_version.pdf](https://www.cs.ucr.edu/~eamonn/DAMP_long_version.pdf)

\[b\] [https://sites.google.com/view/discord-aware-matrix-profile](https://sites.google.com/view/discord-aware-matrix-profile)

\[c\] Irrational Exuberance Why we should not believe 95% of papers on Time Series Anomaly Detection.      [https://www.youtube.com/watch?v=Vg1p3DouX8w](https://www.youtube.com/watch?v=Vg1p3DouX8w)

\[d\] [https://drive.google.com/file/d/1hEgOKtoTuHGPMqR1wty8ff\_jes93ra9a/view](https://drive.google.com/file/d/1hEgOKtoTuHGPMqR1wty8ff_jes93ra9a/view)",7,37,2022-06-23 02:59:24, r  announcing damp    allowing sota anomaly detection in massive time series datasets,dear colleagueswe are happy to announce the release of damp     a    damp  discord aware matrix profile  is an anomaly detection framework that allows you to search datasets with millions or billions of datapoints  all on a conventional machine   b   we are not normally so vainglorious as to announce the publication of  a paper  however    the code comes bundled with some great new anomaly detection datasets  and there is a real dearth of good datasets in the community  see   c      some researchers are working on problems that use anomaly detection as a subroutine  and that is their main computational bottleneck  because damp can be up to   times faster than other approaches  this may be of interest to the communitybest wishes  yue  a   matrix profile xxiv scaling time series anomaly detection to trillions of datapoints and ultra fast arriving data streams  yue lu   renjie wu   abdullah mueen   maria a  zuluaga and eamonn keogh  acm sigkdd     https   b    https   c   irrational exuberance why we should not believe   of papers on time series anomaly detection        https   d    https   drive google com file d hegoktotuhgpmqrwtyff _jesraa view  https   drive google com file d hegoktotuhgpmqrwtyff_jesraa view ,dear colleagueswe happy announce release damp damp discord aware matrix profile anomaly detection framework allows search datasets millions billions datapoints conventional machine b normally vainglorious announce publication paper however code comes bundled great anomaly detection datasets real dearth good datasets community see c researchers working problems use anomaly detection subroutine main computational bottleneck damp times faster approaches may interest communitybest wishes yue matrix profile xxiv scaling time series anomaly detection trillions datapoints ultra fast arriving data streams yue lu renjie wu abdullah mueen maria zuluaga eamonn keogh acm sigkdd https b https c irrational exuberance believe papers time series anomaly detection https https drive google com file hegoktotuhgpmqrwtyff _jesraa view https drive google com file hegoktotuhgpmqrwtyff_jesraa view,r announcing damp allowing sota anomaly detection massive time series datasets,r announcing damp allowing sota anomaly detection massive time series datasetsdear colleagueswe happy announce release damp damp discord aware matrix profile anomaly detection framework allows search datasets millions billions datapoints conventional machine b normally vainglorious announce publication paper however code comes bundled great anomaly detection datasets real dearth good datasets community see c researchers working problems use anomaly detection subroutine main computational bottleneck damp times faster approaches may interest communitybest wishes yue matrix profile xxiv scaling time series anomaly detection trillions datapoints ultra fast arriving data streams yue lu renjie wu abdullah mueen maria zuluaga eamonn keogh acm sigkdd https b https c irrational exuberance believe papers time series anomaly detection https https drive google com file hegoktotuhgpmqrwtyff _jesraa view https drive google com file hegoktotuhgpmqrwtyff_jesraa view,"['r', 'announcing', 'damp', 'allowing', 'sota', 'anomaly', 'detection', 'massive', 'time', 'series', 'datasetsdear', 'colleagueswe', 'happy', 'announce', 'release', 'damp', 'damp', 'discord', 'aware', 'matrix', 'profile', 'anomaly', 'detection', 'framework', 'allows', 'search', 'datasets', 'millions', 'billions', 'datapoints', 'conventional', 'machine', 'b', 'normally', 'vainglorious', 'announce', 'publication', 'paper', 'however', 'code', 'comes', 'bundled', 'great', 'anomaly', 'detection', 'datasets', 'real', 'dearth', 'good', 'datasets', 'community', 'see', 'c', 'researchers', 'working', 'problems', 'use', 'anomaly', 'detection', 'subroutine', 'main', 'computational', 'bottleneck', 'damp', 'times', 'faster', 'approaches', 'may', 'interest', 'communitybest', 'wishes', 'yue', 'matrix', 'profile', 'xxiv', 'scaling', 'time', 'series', 'anomaly', 'detection', 'trillions', 'datapoints', 'ultra', 'fast', 'arriving', 'data', 'streams', 'yue', 'lu', 'renjie', 'wu', 'abdullah', 'mueen', 'maria', 'zuluaga', 'eamonn', 'keogh', 'acm', 'sigkdd', 'https', 'b', 'https', 'c', 'irrational', 'exuberance', 'believe', 'papers', 'time', 'series', 'anomaly', 'detection', 'https', 'https', 'drive', 'google', 'com', 'file', 'hegoktotuhgpmqrwtyff', '_jesraa', 'view', 'https', 'drive', 'google', 'com', 'file', 'hegoktotuhgpmqrwtyff_jesraa', 'view']","['r', 'announc', 'damp', 'allow', 'sota', 'anomali', 'detect', 'massiv', 'time', 'seri', 'datasetsdear', 'colleaguesw', 'happi', 'announc', 'releas', 'damp', 'damp', 'discord', 'awar', 'matrix', 'profil', 'anomali', 'detect', 'framework', 'allow', 'search', 'dataset', 'million', 'billion', 'datapoint', 'convent', 'machin', 'b', 'normal', 'vainglori', 'announc', 'public', 'paper', 'howev', 'code', 'come', 'bundl', 'great', 'anomali', 'detect', 'dataset', 'real', 'dearth', 'good', 'dataset', 'commun', 'see', 'c', 'research', 'work', 'problem', 'use', 'anomali', 'detect', 'subroutin', 'main', 'comput', 'bottleneck', 'damp', 'time', 'faster', 'approach', 'may', 'interest', 'communitybest', 'wish', 'yue', 'matrix', 'profil', 'xxiv', 'scale', 'time', 'seri', 'anomali', 'detect', 'trillion', 'datapoint', 'ultra', 'fast', 'arriv', 'data', 'stream', 'yue', 'lu', 'renji', 'wu', 'abdullah', 'mueen', 'maria', 'zuluaga', 'eamonn', 'keogh', 'acm', 'sigkdd', 'http', 'b', 'http', 'c', 'irrat', 'exuber', 'believ', 'paper', 'time', 'seri', 'anomali', 'detect', 'http', 'http', 'drive', 'googl', 'com', 'file', 'hegoktotuhgpmqrwtyff', '_jesraa', 'view', 'http', 'drive', 'googl', 'com', 'file', 'hegoktotuhgpmqrwtyff_jesraa', 'view']"
257,280,280,curious_cow_99,vi2mw4,[D] Have you ever been asked to work on a software project you found unethical? We’d like to hear from you!,"We are researchers at Carnegie Mellon University studying how software developers identify and act on ethical concerns at work. If you’re interested in helping us advance research in software ethics, please fill out [this survey](https://docs.google.com/forms/d/e/1FAIpQLScEIB09oKznU4OGDQeQyNpfMgf_X3HdNS1j2m-c_BFDJijuTQ/viewform?usp=sf_link) and we’ll reach out to you for a quick interview!

P.S.

* You can check out [this](https://stackoverflow.blog/2022/05/30/ethical-ai-isnt-just-how-you-build-it-its-how-you-use-it/) Stack Overflow blog post to read more about the direction of our research.
* Anything you disclose to us during the survey / interview may appear in our study but will not be traceable to you.",66,255,2022-06-22 16:35:44, d  have you ever been asked to work on a software project you found unethical  we d like to hear from you ,we are researchers at carnegie mellon university studying how software developers identify and act on ethical concerns at work  if you re interested in helping us advance research in software ethics  please fill out  this survey  https p s   you can check out  this  https   anything you disclose to us during the survey   interview may appear in our study but will not be traceable to you ,researchers carnegie mellon university studying software developers identify act ethical concerns work interested helping us advance research software ethics please fill survey https p check https anything disclose us survey interview may appear study traceable,ever asked work software project found unethical like hear,ever asked work software project found unethical like hearresearchers carnegie mellon university studying software developers identify act ethical concerns work interested helping us advance research software ethics please fill survey https p check https anything disclose us survey interview may appear study traceable,"['ever', 'asked', 'work', 'software', 'project', 'found', 'unethical', 'like', 'hearresearchers', 'carnegie', 'mellon', 'university', 'studying', 'software', 'developers', 'identify', 'act', 'ethical', 'concerns', 'work', 'interested', 'helping', 'us', 'advance', 'research', 'software', 'ethics', 'please', 'fill', 'survey', 'https', 'p', 'check', 'https', 'anything', 'disclose', 'us', 'survey', 'interview', 'may', 'appear', 'study', 'traceable']","['ever', 'ask', 'work', 'softwar', 'project', 'found', 'uneth', 'like', 'hearresearch', 'carnegi', 'mellon', 'univers', 'studi', 'softwar', 'develop', 'identifi', 'act', 'ethic', 'concern', 'work', 'interest', 'help', 'us', 'advanc', 'research', 'softwar', 'ethic', 'pleas', 'fill', 'survey', 'http', 'p', 'check', 'http', 'anyth', 'disclos', 'us', 'survey', 'interview', 'may', 'appear', 'studi', 'traceabl']"
258,281,281,keremidk0,vie0aj,[D] Is audio style transfer a thing ?,"So we have image style transfer, there's a lot of good papers and implementations.

  
Is there such thing as audio style transfer, where 1 song keeps its lyrics and melody, but get the other song's style ? e.g. pop music with rock style ?  
If yes - can you please share a link ?",10,30,2022-06-23 01:31:11, d  is audio style transfer a thing  ,so we have image style transfer  there s a lot of good papers and implementations   is there such thing as audio style transfer  where  song keeps its lyrics and melody  but get the other song s style   e g  pop music with rock style    if yes   can you please share a link  ,image style transfer lot good papers implementations thing audio style transfer song keeps lyrics melody get song style e g pop music rock style yes please share link,audio style transfer thing,audio style transfer thingimage style transfer lot good papers implementations thing audio style transfer song keeps lyrics melody get song style e g pop music rock style yes please share link,"['audio', 'style', 'transfer', 'thingimage', 'style', 'transfer', 'lot', 'good', 'papers', 'implementations', 'thing', 'audio', 'style', 'transfer', 'song', 'keeps', 'lyrics', 'melody', 'get', 'song', 'style', 'e', 'g', 'pop', 'music', 'rock', 'style', 'yes', 'please', 'share', 'link']","['audio', 'style', 'transfer', 'thingimag', 'style', 'transfer', 'lot', 'good', 'paper', 'implement', 'thing', 'audio', 'style', 'transfer', 'song', 'keep', 'lyric', 'melodi', 'get', 'song', 'style', 'e', 'g', 'pop', 'music', 'rock', 'style', 'ye', 'pleas', 'share', 'link']"
259,282,282,lux123or,viy1zp,State of the art 2D body pose estimation [Discussion]," Hi. I have a background in neuroscience and sometimes we use DeepLabCut to track animals during behaviour. This is by far the most widespread and used application for animal tracking based on artificial neural networks. I was wondering, if anyone here is an expert in human 2D body pose estimation and can tell me what their oppinion is on what is the best human 2D pose estimation tool currently available? I came across Pose from mediapipe and it seems very good from a few examples I tested so far but I'm curious if there's something even better that I have not come across. Thanks for the help!",1,1,2022-06-23 19:50:58,state of the art d body pose estimation  discussion , hi  i have a background in neuroscience and sometimes we use deeplabcut to track animals during behaviour  this is by far the most widespread and used application for animal tracking based on artificial neural networks  i was wondering  if anyone here is an expert in human d body pose estimation and can tell me what their oppinion is on what is the best human d pose estimation tool currently available  i came across pose from mediapipe and it seems very good from a few examples i tested so far but i m curious if there s something even better that i have not come across  thanks for the help ,hi background neuroscience sometimes use deeplabcut track animals behaviour far widespread used application animal tracking based artificial neural networks wondering anyone expert human body pose estimation tell oppinion best human pose estimation tool currently available came across pose mediapipe seems good examples tested far curious something even better come across thanks help,state art body pose estimation discussion,state art body pose estimation discussionhi background neuroscience sometimes use deeplabcut track animals behaviour far widespread used application animal tracking based artificial neural networks wondering anyone expert human body pose estimation tell oppinion best human pose estimation tool currently available came across pose mediapipe seems good examples tested far curious something even better come across thanks help,"['state', 'art', 'body', 'pose', 'estimation', 'discussionhi', 'background', 'neuroscience', 'sometimes', 'use', 'deeplabcut', 'track', 'animals', 'behaviour', 'far', 'widespread', 'used', 'application', 'animal', 'tracking', 'based', 'artificial', 'neural', 'networks', 'wondering', 'anyone', 'expert', 'human', 'body', 'pose', 'estimation', 'tell', 'oppinion', 'best', 'human', 'pose', 'estimation', 'tool', 'currently', 'available', 'came', 'across', 'pose', 'mediapipe', 'seems', 'good', 'examples', 'tested', 'far', 'curious', 'something', 'even', 'better', 'come', 'across', 'thanks', 'help']","['state', 'art', 'bodi', 'pose', 'estim', 'discussionhi', 'background', 'neurosci', 'sometim', 'use', 'deeplabcut', 'track', 'anim', 'behaviour', 'far', 'widespread', 'use', 'applic', 'anim', 'track', 'base', 'artifici', 'neural', 'network', 'wonder', 'anyon', 'expert', 'human', 'bodi', 'pose', 'estim', 'tell', 'oppinion', 'best', 'human', 'pose', 'estim', 'tool', 'current', 'avail', 'came', 'across', 'pose', 'mediapip', 'seem', 'good', 'exampl', 'test', 'far', 'curiou', 'someth', 'even', 'better', 'come', 'across', 'thank', 'help']"
260,283,283,LeanderKu,vi8its,[D] Any way to speed up simple mathematical functions without implementing cuda kernels for pytorch?,"I am working on a pytorch project and I have a custom computation that I am so far unable to express as a combination pre-defined pytorch functions (because it's essentially some loops around conv2d calls where I juggle some indices in a 5-d tensor). So currently I use python-loops with some smart padding but that's not the fastest. The only way to speed this up would be, i think, to implement custom cuda kernels. While the computation is not that trivial it is simple in a mathematical way. It can be defined in a single line using lots of indices and sums. I wonder whether there is really nothing I can do?

What I am thinking of is something like tensor-comprehensions, but that's deprecated and I didn't get it to install.

Is there any modern alternative to tensor-comprehension, or should I switch the language to e.g. julia? Is it possible there to define slightly different conv2d there and have it run natively on the GPU?

I don't expect performance comparable to the handwritten conv2d kernels, but the python loops are just quite slow.",27,20,2022-06-22 21:28:18, d  any way to speed up simple mathematical functions without implementing cuda kernels for pytorch ,i am working on a pytorch project and i have a custom computation that i am so far unable to express as a combination pre defined pytorch functions  because it s essentially some loops around convd calls where i juggle some indices in a  d tensor   so currently i use python loops with some smart padding but that s not the fastest  the only way to speed this up would be  i think  to implement custom cuda kernels  while the computation is not that trivial it is simple in a mathematical way  it can be defined in a single line using lots of indices and sums  i wonder whether there is really nothing i can do what i am thinking of is something like tensor comprehensions  but that s deprecated and i didn t get it to install is there any modern alternative to tensor comprehension  or should i switch the language to e g  julia  is it possible there to define slightly different convd there and have it run natively on the gpu i don t expect performance comparable to the handwritten convd kernels  but the python loops are just quite slow ,working pytorch project computation far unable express combination pre defined pytorch functions essentially loops around convd calls juggle indices tensor currently use python loops smart padding fastest way speed would think implement cuda kernels computation trivial simple mathematical way defined single line using lots indices sums wonder whether really nothing thinking something like tensor comprehensions deprecated get install modern alternative tensor comprehension switch language e g julia possible define slightly different convd run natively gpu expect performance comparable handwritten convd kernels python loops quite slow,way speed simple mathematical functions without implementing cuda kernels pytorch,way speed simple mathematical functions without implementing cuda kernels pytorchworking pytorch project computation far unable express combination pre defined pytorch functions essentially loops around convd calls juggle indices tensor currently use python loops smart padding fastest way speed would think implement cuda kernels computation trivial simple mathematical way defined single line using lots indices sums wonder whether really nothing thinking something like tensor comprehensions deprecated get install modern alternative tensor comprehension switch language e g julia possible define slightly different convd run natively gpu expect performance comparable handwritten convd kernels python loops quite slow,"['way', 'speed', 'simple', 'mathematical', 'functions', 'without', 'implementing', 'cuda', 'kernels', 'pytorchworking', 'pytorch', 'project', 'computation', 'far', 'unable', 'express', 'combination', 'pre', 'defined', 'pytorch', 'functions', 'essentially', 'loops', 'around', 'convd', 'calls', 'juggle', 'indices', 'tensor', 'currently', 'use', 'python', 'loops', 'smart', 'padding', 'fastest', 'way', 'speed', 'would', 'think', 'implement', 'cuda', 'kernels', 'computation', 'trivial', 'simple', 'mathematical', 'way', 'defined', 'single', 'line', 'using', 'lots', 'indices', 'sums', 'wonder', 'whether', 'really', 'nothing', 'thinking', 'something', 'like', 'tensor', 'comprehensions', 'deprecated', 'get', 'install', 'modern', 'alternative', 'tensor', 'comprehension', 'switch', 'language', 'e', 'g', 'julia', 'possible', 'define', 'slightly', 'different', 'convd', 'run', 'natively', 'gpu', 'expect', 'performance', 'comparable', 'handwritten', 'convd', 'kernels', 'python', 'loops', 'quite', 'slow']","['way', 'speed', 'simpl', 'mathemat', 'function', 'without', 'implement', 'cuda', 'kernel', 'pytorchwork', 'pytorch', 'project', 'comput', 'far', 'unabl', 'express', 'combin', 'pre', 'defin', 'pytorch', 'function', 'essenti', 'loop', 'around', 'convd', 'call', 'juggl', 'indic', 'tensor', 'current', 'use', 'python', 'loop', 'smart', 'pad', 'fastest', 'way', 'speed', 'would', 'think', 'implement', 'cuda', 'kernel', 'comput', 'trivial', 'simpl', 'mathemat', 'way', 'defin', 'singl', 'line', 'use', 'lot', 'indic', 'sum', 'wonder', 'whether', 'realli', 'noth', 'think', 'someth', 'like', 'tensor', 'comprehens', 'deprec', 'get', 'instal', 'modern', 'altern', 'tensor', 'comprehens', 'switch', 'languag', 'e', 'g', 'julia', 'possibl', 'defin', 'slightli', 'differ', 'convd', 'run', 'nativ', 'gpu', 'expect', 'perform', 'compar', 'handwritten', 'convd', 'kernel', 'python', 'loop', 'quit', 'slow']"
261,284,284,Appropriate_Ant_4629,vinz5n,[D] Do any Text-to-Image approaches work well with long complex prompts (i.e. paragraph or book chapter scale)?,"Seems almost all the examples of text-to-image are based on tiny prompts with very few details (""avocado chair"").

Do any such systems do a good job at keeping track of details - like [the first 2 paragraphs of The Hobbit](https://www.printfriendly.com/p/g/jP9qGu) and correctly place the ""polished chairs"", ""pegs for hats and coats"", and ""deep-set round windows looking over his garden, and meadows beyond, sloping down to the river""?

Assuming they don't - what approach(es) might make sense to design such systems?

I'm speculating that you'd need much larger embedding vectors (to correctly connect concepts from the right adjectives to the right nouns); and it'd be harder to find training data (perhaps frames of movies from novels would be a good source)?

Any pointers to anything in that direction?",3,2,2022-06-23 09:37:22, d  do any text to image approaches work well with long complex prompts  i e  paragraph or book chapter scale  ,seems almost all the examples of text to image are based on tiny prompts with very few details  avocado chair  do any such systems do a good job at keeping track of details   like  the first  paragraphs of the hobbit  https assuming they don t   what approach es  might make sense to design such systems i m speculating that you d need much larger embedding vectors  to correctly connect concepts from the right adjectives to the right nouns   and it d be harder to find training data  perhaps frames of movies from novels would be a good source  any pointers to anything in that direction ,seems almost examples text image based tiny prompts details avocado chair systems good job keeping track details like first paragraphs hobbit https assuming approach es might make sense design systems speculating need much larger embedding vectors correctly connect concepts right adjectives right nouns harder find training data perhaps frames movies novels would good source pointers anything direction,text image approaches work well long complex prompts e paragraph book chapter scale,text image approaches work well long complex prompts e paragraph book chapter scaleseems almost examples text image based tiny prompts details avocado chair systems good job keeping track details like first paragraphs hobbit https assuming approach es might make sense design systems speculating need much larger embedding vectors correctly connect concepts right adjectives right nouns harder find training data perhaps frames movies novels would good source pointers anything direction,"['text', 'image', 'approaches', 'work', 'well', 'long', 'complex', 'prompts', 'e', 'paragraph', 'book', 'chapter', 'scaleseems', 'almost', 'examples', 'text', 'image', 'based', 'tiny', 'prompts', 'details', 'avocado', 'chair', 'systems', 'good', 'job', 'keeping', 'track', 'details', 'like', 'first', 'paragraphs', 'hobbit', 'https', 'assuming', 'approach', 'es', 'might', 'make', 'sense', 'design', 'systems', 'speculating', 'need', 'much', 'larger', 'embedding', 'vectors', 'correctly', 'connect', 'concepts', 'right', 'adjectives', 'right', 'nouns', 'harder', 'find', 'training', 'data', 'perhaps', 'frames', 'movies', 'novels', 'would', 'good', 'source', 'pointers', 'anything', 'direction']","['text', 'imag', 'approach', 'work', 'well', 'long', 'complex', 'prompt', 'e', 'paragraph', 'book', 'chapter', 'scaleseem', 'almost', 'exampl', 'text', 'imag', 'base', 'tini', 'prompt', 'detail', 'avocado', 'chair', 'system', 'good', 'job', 'keep', 'track', 'detail', 'like', 'first', 'paragraph', 'hobbit', 'http', 'assum', 'approach', 'es', 'might', 'make', 'sens', 'design', 'system', 'specul', 'need', 'much', 'larger', 'embed', 'vector', 'correctli', 'connect', 'concept', 'right', 'adject', 'right', 'noun', 'harder', 'find', 'train', 'data', 'perhap', 'frame', 'movi', 'novel', 'would', 'good', 'sourc', 'pointer', 'anyth', 'direct']"
262,285,285,FlyingQuokka,vigx2l,[D] What is the current SOTA for open-source AutoML?,"I've never really used AutoML--I prefer to code up my models and data engineering by hand, but I'm beginning to wonder if I can use AutoML as a starting point, e.g., the built-in hyper-parameter optimization or NAS finds a good neural network hyper-params/architecture for me, and I can build on that.

With that in mind, what's the SOTA right now? Ideally, it would be as white-box as possible, telling me the models it tries, what worked and didn't, etc. Alternatively, what has worked best for you in your workflows?",3,6,2022-06-23 03:39:09, d  what is the current sota for open source automl ,i ve never really used automl  i prefer to code up my models and data engineering by hand  but i m beginning to wonder if i can use automl as a starting point  e g   the built in hyper parameter optimization or nas finds a good neural network hyper params architecture for me  and i can build on that with that in mind  what s the sota right now  ideally  it would be as white box as possible  telling me the models it tries  what worked and didn t  etc  alternatively  what has worked best for you in your workflows ,never really used automl prefer code models data engineering hand beginning wonder use automl starting point e g built hyper parameter optimization nas finds good neural network hyper params architecture build mind sota right ideally would white box possible telling models tries worked etc alternatively worked best workflows,current sota open source automl,current sota open source automlnever really used automl prefer code models data engineering hand beginning wonder use automl starting point e g built hyper parameter optimization nas finds good neural network hyper params architecture build mind sota right ideally would white box possible telling models tries worked etc alternatively worked best workflows,"['current', 'sota', 'open', 'source', 'automlnever', 'really', 'used', 'automl', 'prefer', 'code', 'models', 'data', 'engineering', 'hand', 'beginning', 'wonder', 'use', 'automl', 'starting', 'point', 'e', 'g', 'built', 'hyper', 'parameter', 'optimization', 'nas', 'finds', 'good', 'neural', 'network', 'hyper', 'params', 'architecture', 'build', 'mind', 'sota', 'right', 'ideally', 'would', 'white', 'box', 'possible', 'telling', 'models', 'tries', 'worked', 'etc', 'alternatively', 'worked', 'best', 'workflows']","['current', 'sota', 'open', 'sourc', 'automlnev', 'realli', 'use', 'automl', 'prefer', 'code', 'model', 'data', 'engin', 'hand', 'begin', 'wonder', 'use', 'automl', 'start', 'point', 'e', 'g', 'built', 'hyper', 'paramet', 'optim', 'na', 'find', 'good', 'neural', 'network', 'hyper', 'param', 'architectur', 'build', 'mind', 'sota', 'right', 'ideal', 'would', 'white', 'box', 'possibl', 'tell', 'model', 'tri', 'work', 'etc', 'altern', 'work', 'best', 'workflow']"
263,286,286,JBitterwolf,vi1ly4,[R] Breaking Down Out-of-Distribution Detection,"TL;DR: Many OOD detectors that are trained with samples from an (unrelated) OOD dataset can be understood by isolating a binary discriminator between in-distribution and OOD.

[We just published it on arXiv](https://arxiv.org/abs/2206.09880) and will present it at ICML 2022.

Questions and discussion are very welcome!

Full title: **Breaking Down Out-of-Distribution Detection: Many Methods Based on OOD Training Data Estimate a Combination of the Same Core Quantities** by Julian Bitterwolf, Alexander Meinke, Maximilian Augustin, Matthias Hein.",3,38,2022-06-22 15:29:50, r  breaking down out of distribution detection,tl dr  many ood detectors that are trained with samples from an  unrelated  ood dataset can be understood by isolating a binary discriminator between in distribution and ood  we just published it on arxiv  https questions and discussion are very welcome full title    breaking down out of distribution detection  many methods based on ood training data estimate a combination of the same core quantities   by julian bitterwolf  alexander meinke  maximilian augustin  matthias hein ,tl dr many ood detectors trained samples unrelated ood dataset understood isolating binary discriminator distribution ood published arxiv https questions discussion welcome full title breaking distribution detection many methods based ood training data estimate combination core quantities julian bitterwolf alexander meinke maximilian augustin matthias hein,r breaking distribution detection,r breaking distribution detectiontl dr many ood detectors trained samples unrelated ood dataset understood isolating binary discriminator distribution ood published arxiv https questions discussion welcome full title breaking distribution detection many methods based ood training data estimate combination core quantities julian bitterwolf alexander meinke maximilian augustin matthias hein,"['r', 'breaking', 'distribution', 'detectiontl', 'dr', 'many', 'ood', 'detectors', 'trained', 'samples', 'unrelated', 'ood', 'dataset', 'understood', 'isolating', 'binary', 'discriminator', 'distribution', 'ood', 'published', 'arxiv', 'https', 'questions', 'discussion', 'welcome', 'full', 'title', 'breaking', 'distribution', 'detection', 'many', 'methods', 'based', 'ood', 'training', 'data', 'estimate', 'combination', 'core', 'quantities', 'julian', 'bitterwolf', 'alexander', 'meinke', 'maximilian', 'augustin', 'matthias', 'hein']","['r', 'break', 'distribut', 'detectiontl', 'dr', 'mani', 'ood', 'detector', 'train', 'sampl', 'unrel', 'ood', 'dataset', 'understood', 'isol', 'binari', 'discrimin', 'distribut', 'ood', 'publish', 'arxiv', 'http', 'question', 'discuss', 'welcom', 'full', 'titl', 'break', 'distribut', 'detect', 'mani', 'method', 'base', 'ood', 'train', 'data', 'estim', 'combin', 'core', 'quantiti', 'julian', 'bitterwolf', 'alexand', 'meink', 'maximilian', 'augustin', 'matthia', 'hein']"
264,287,287,LemonByte,viglgx,[P] Multidimensional array batch indexing for pytorch and numpy,"Batch indexing into multidimensional tensors/arrays is kind of tricky, I made this project explaining the builtin syntax and also made wrappers for simplifying the interface, with additional features for underlying coordinate grid data (like signed distance functions) that need to be indexed by coordinate value rather than integer indices directly [https://github.com/LemonPi/multidim\_indexing](https://github.com/LemonPi/multidim_indexing)",4,5,2022-06-23 03:25:20, p  multidimensional array batch indexing for pytorch and numpy,batch indexing into multidimensional tensors arrays is kind of tricky  i made this project explaining the builtin syntax and also made wrappers for simplifying the interface  with additional features for underlying coordinate grid data  like signed distance functions  that need to be indexed by coordinate value rather than integer indices directly  https   github com lemonpi multidim _indexing  https   github com lemonpi multidim_indexing ,batch indexing multidimensional tensors arrays kind tricky made project explaining builtin syntax also made wrappers simplifying interface additional features underlying coordinate grid data like signed distance functions need indexed coordinate value rather integer indices directly https github com lemonpi multidim _indexing https github com lemonpi multidim_indexing,p multidimensional array batch indexing pytorch numpy,p multidimensional array batch indexing pytorch numpybatch indexing multidimensional tensors arrays kind tricky made project explaining builtin syntax also made wrappers simplifying interface additional features underlying coordinate grid data like signed distance functions need indexed coordinate value rather integer indices directly https github com lemonpi multidim _indexing https github com lemonpi multidim_indexing,"['p', 'multidimensional', 'array', 'batch', 'indexing', 'pytorch', 'numpybatch', 'indexing', 'multidimensional', 'tensors', 'arrays', 'kind', 'tricky', 'made', 'project', 'explaining', 'builtin', 'syntax', 'also', 'made', 'wrappers', 'simplifying', 'interface', 'additional', 'features', 'underlying', 'coordinate', 'grid', 'data', 'like', 'signed', 'distance', 'functions', 'need', 'indexed', 'coordinate', 'value', 'rather', 'integer', 'indices', 'directly', 'https', 'github', 'com', 'lemonpi', 'multidim', '_indexing', 'https', 'github', 'com', 'lemonpi', 'multidim_indexing']","['p', 'multidimension', 'array', 'batch', 'index', 'pytorch', 'numpybatch', 'index', 'multidimension', 'tensor', 'array', 'kind', 'tricki', 'made', 'project', 'explain', 'builtin', 'syntax', 'also', 'made', 'wrapper', 'simplifi', 'interfac', 'addit', 'featur', 'underli', 'coordin', 'grid', 'data', 'like', 'sign', 'distanc', 'function', 'need', 'index', 'coordin', 'valu', 'rather', 'integ', 'indic', 'directli', 'http', 'github', 'com', 'lemonpi', 'multidim', '_index', 'http', 'github', 'com', 'lemonpi', 'multidim_index']"
265,288,288,seraschka,vi41f7,[P] Bottom-up look at the new Lightning Framework for building anything from production-ready ML systems to research demos,"The open-source [lightning.ai](https://lightning.ai) framework just launched last week introducing the concept of Lightning Apps. It's basically meant for building anything from production ready ML-system running on multi-node GPU clusters in the cloud to building simple research demos.

Starting with a simple use case, a research demo, I wrote a ""short"" article about it to explain how it roughly works under the hood: [Sharing Deep Learning Research Models with Lightning Part 1: Building A Super Resolution App ](https://sebastianraschka.com/blog/2022/lightning-app-srgan-1.html)

Looking forward to hearing your feedback. I am planning to put together more ""substantial"" examples, but I was thinking of doing that one step at the time. Will be attending a conference in 3 weeks and am planning to create a research demo alongside the paper I will be presenting, and I was wondering besides Gradio/Dash/Gradio, what are your typical tools and workflows for making research demos. Any cool examples for inspiration?

&#x200B;

Disclaimer: I recently joined Lightning when I saw an early prototype. As someone who has spent most of my time on research models, I was always intrigued by putting ML models to production. However, I was also always turned of by the tooling that it involved.",9,16,2022-06-22 17:55:18, p  bottom up look at the new lightning framework for building anything from production ready ml systems to research demos,the open source  lightning ai  https starting with a simple use case  a research demo  i wrote a short article about it to explain how it roughly works under the hood   sharing deep learning research models with lightning part   building a super resolution app   https looking forward to hearing your feedback  i am planning to put together more substantial examples  but i was thinking of doing that one step at the time  will be attending a conference in  weeks and am planning to create a research demo alongside the paper i will be presenting  and i was wondering besides gradio dash gradio  what are your typical tools and workflows for making research demos  any cool examples for inspiration   xb disclaimer  i recently joined lightning when i saw an early prototype  as someone who has spent most of my time on research models  i was always intrigued by putting ml models to production  however  i was also always turned of by the tooling that it involved ,open source lightning ai https starting simple use case research demo wrote short article explain roughly works hood sharing deep learning research models lightning part building super resolution app https looking forward hearing feedback planning put together substantial examples thinking one step time attending conference weeks planning create research demo alongside paper presenting wondering besides gradio dash gradio typical tools workflows making research demos cool examples inspiration xb disclaimer recently joined lightning saw early prototype someone spent time research models always intrigued putting ml models production however also always turned tooling involved,p bottom look lightning framework building anything production ready ml systems research demos,p bottom look lightning framework building anything production ready ml systems research demosopen source lightning ai https starting simple use case research demo wrote short article explain roughly works hood sharing deep learning research models lightning part building super resolution app https looking forward hearing feedback planning put together substantial examples thinking one step time attending conference weeks planning create research demo alongside paper presenting wondering besides gradio dash gradio typical tools workflows making research demos cool examples inspiration xb disclaimer recently joined lightning saw early prototype someone spent time research models always intrigued putting ml models production however also always turned tooling involved,"['p', 'bottom', 'look', 'lightning', 'framework', 'building', 'anything', 'production', 'ready', 'ml', 'systems', 'research', 'demosopen', 'source', 'lightning', 'ai', 'https', 'starting', 'simple', 'use', 'case', 'research', 'demo', 'wrote', 'short', 'article', 'explain', 'roughly', 'works', 'hood', 'sharing', 'deep', 'learning', 'research', 'models', 'lightning', 'part', 'building', 'super', 'resolution', 'app', 'https', 'looking', 'forward', 'hearing', 'feedback', 'planning', 'put', 'together', 'substantial', 'examples', 'thinking', 'one', 'step', 'time', 'attending', 'conference', 'weeks', 'planning', 'create', 'research', 'demo', 'alongside', 'paper', 'presenting', 'wondering', 'besides', 'gradio', 'dash', 'gradio', 'typical', 'tools', 'workflows', 'making', 'research', 'demos', 'cool', 'examples', 'inspiration', 'xb', 'disclaimer', 'recently', 'joined', 'lightning', 'saw', 'early', 'prototype', 'someone', 'spent', 'time', 'research', 'models', 'always', 'intrigued', 'putting', 'ml', 'models', 'production', 'however', 'also', 'always', 'turned', 'tooling', 'involved']","['p', 'bottom', 'look', 'lightn', 'framework', 'build', 'anyth', 'product', 'readi', 'ml', 'system', 'research', 'demosopen', 'sourc', 'lightn', 'ai', 'http', 'start', 'simpl', 'use', 'case', 'research', 'demo', 'wrote', 'short', 'articl', 'explain', 'roughli', 'work', 'hood', 'share', 'deep', 'learn', 'research', 'model', 'lightn', 'part', 'build', 'super', 'resolut', 'app', 'http', 'look', 'forward', 'hear', 'feedback', 'plan', 'put', 'togeth', 'substanti', 'exampl', 'think', 'one', 'step', 'time', 'attend', 'confer', 'week', 'plan', 'creat', 'research', 'demo', 'alongsid', 'paper', 'present', 'wonder', 'besid', 'gradio', 'dash', 'gradio', 'typic', 'tool', 'workflow', 'make', 'research', 'demo', 'cool', 'exampl', 'inspir', 'xb', 'disclaim', 'recent', 'join', 'lightn', 'saw', 'earli', 'prototyp', 'someon', 'spent', 'time', 'research', 'model', 'alway', 'intrigu', 'put', 'ml', 'model', 'product', 'howev', 'also', 'alway', 'turn', 'tool', 'involv']"
266,289,289,wowAmaze,vijaqf,[D] Implementing custom functions in pytorch e.g. feature propagation (PointNet++),"Apologies if this isn't the right place to ask. But I'm currently studying point cloud-based networks like pointcloud++, and all the related 3d object detection networks like pointpillars, voxelnet, etc. While I (think) understand the algorithms like feature propagation in [pointnet++](https://github.com/erikwijmans/Pointnet2_PyTorch/blob/master/pointnet2_ops_lib/pointnet2_ops/pointnet2_utils.py). I'm having trouble understanding how would one implement them. Or Where could I learn about writing operations in cuda and making sure they are compatible with backprop?",2,1,2022-06-23 05:31:59, d  implementing custom functions in pytorch e g  feature propagation  pointnet   ,apologies if this isn t the right place to ask  but i m currently studying point cloud based networks like pointcloud    and all the related d object detection networks like pointpillars  voxelnet  etc  while i  think  understand the algorithms like feature propagation in  pointnet    https   github com erikwijmans pointnet_pytorch blob master pointnet_ops_lib pointnet_ops pointnet_utils py   i m having trouble understanding how would one implement them  or where could i learn about writing operations in cuda and making sure they are compatible with backprop ,apologies right place ask currently studying point cloud based networks like pointcloud related object detection networks like pointpillars voxelnet etc think understand algorithms like feature propagation pointnet https github com erikwijmans pointnet_pytorch blob master pointnet_ops_lib pointnet_ops pointnet_utils py trouble understanding would one implement could learn writing operations cuda making sure compatible backprop,implementing functions pytorch e g feature propagation pointnet,implementing functions pytorch e g feature propagation pointnetapologies right place ask currently studying point cloud based networks like pointcloud related object detection networks like pointpillars voxelnet etc think understand algorithms like feature propagation pointnet https github com erikwijmans pointnet_pytorch blob master pointnet_ops_lib pointnet_ops pointnet_utils py trouble understanding would one implement could learn writing operations cuda making sure compatible backprop,"['implementing', 'functions', 'pytorch', 'e', 'g', 'feature', 'propagation', 'pointnetapologies', 'right', 'place', 'ask', 'currently', 'studying', 'point', 'cloud', 'based', 'networks', 'like', 'pointcloud', 'related', 'object', 'detection', 'networks', 'like', 'pointpillars', 'voxelnet', 'etc', 'think', 'understand', 'algorithms', 'like', 'feature', 'propagation', 'pointnet', 'https', 'github', 'com', 'erikwijmans', 'pointnet_pytorch', 'blob', 'master', 'pointnet_ops_lib', 'pointnet_ops', 'pointnet_utils', 'py', 'trouble', 'understanding', 'would', 'one', 'implement', 'could', 'learn', 'writing', 'operations', 'cuda', 'making', 'sure', 'compatible', 'backprop']","['implement', 'function', 'pytorch', 'e', 'g', 'featur', 'propag', 'pointnetapolog', 'right', 'place', 'ask', 'current', 'studi', 'point', 'cloud', 'base', 'network', 'like', 'pointcloud', 'relat', 'object', 'detect', 'network', 'like', 'pointpillar', 'voxelnet', 'etc', 'think', 'understand', 'algorithm', 'like', 'featur', 'propag', 'pointnet', 'http', 'github', 'com', 'erikwijman', 'pointnet_pytorch', 'blob', 'master', 'pointnet_ops_lib', 'pointnet_op', 'pointnet_util', 'py', 'troubl', 'understand', 'would', 'one', 'implement', 'could', 'learn', 'write', 'oper', 'cuda', 'make', 'sure', 'compat', 'backprop']"
267,291,291,Relative_Collection1,vig9ae,[P] Building a Source of Truth for Inventory with Disparate Data Sources,"One of the most challenging shifts from food delivery to grocery is managing inventory. Although restaurant menu items can sometimes go out of stock, grocery store inventories have far more SKUs and many different ways to track their inventory levels. This complexity of grocery makes it a lot harder to ensure items customers buy are actually available. Knowing what the ground truth is, so that customers can order groceries with confidence, is the subject of a new engineering blog post I wrote, [""Building a Source of Truth for an Inventory with Disparate Data Sources""](https://doordash.engineering/2022/06/21/building-a-source-of-truth-for-a-digital-inventory-with-disparate-data-sources/). The article explains how we crowd sourced our inventory data from a number of different sources which enabled us to predict which items are likely still on the shelves when customers place an order. Take a look and let me know what you think",0,0,2022-06-23 03:10:06, p  building a source of truth for inventory with disparate data sources,one of the most challenging shifts from food delivery to grocery is managing inventory  although restaurant menu items can sometimes go out of stock  grocery store inventories have far more skus and many different ways to track their inventory levels  this complexity of grocery makes it a lot harder to ensure items customers buy are actually available  knowing what the ground truth is  so that customers can order groceries with confidence  is the subject of a new engineering blog post i wrote   building a source of truth for an inventory with disparate data sources  https   doordash engineering    building a source of truth for a digital inventory with disparate data sources    the article explains how we crowd sourced our inventory data from a number of different sources which enabled us to predict which items are likely still on the shelves when customers place an order  take a look and let me know what you think,one challenging shifts food delivery grocery managing inventory although restaurant menu items sometimes go stock grocery store inventories far skus many different ways track inventory levels complexity grocery makes lot harder ensure items customers buy actually available knowing ground truth customers order groceries confidence subject engineering blog post wrote building source truth inventory disparate data sources https doordash engineering building source truth digital inventory disparate data sources article explains crowd sourced inventory data number different sources enabled us predict items likely still shelves customers place order take look let know think,p building source truth inventory disparate data sources,p building source truth inventory disparate data sourcesone challenging shifts food delivery grocery managing inventory although restaurant menu items sometimes go stock grocery store inventories far skus many different ways track inventory levels complexity grocery makes lot harder ensure items customers buy actually available knowing ground truth customers order groceries confidence subject engineering blog post wrote building source truth inventory disparate data sources https doordash engineering building source truth digital inventory disparate data sources article explains crowd sourced inventory data number different sources enabled us predict items likely still shelves customers place order take look let know think,"['p', 'building', 'source', 'truth', 'inventory', 'disparate', 'data', 'sourcesone', 'challenging', 'shifts', 'food', 'delivery', 'grocery', 'managing', 'inventory', 'although', 'restaurant', 'menu', 'items', 'sometimes', 'go', 'stock', 'grocery', 'store', 'inventories', 'far', 'skus', 'many', 'different', 'ways', 'track', 'inventory', 'levels', 'complexity', 'grocery', 'makes', 'lot', 'harder', 'ensure', 'items', 'customers', 'buy', 'actually', 'available', 'knowing', 'ground', 'truth', 'customers', 'order', 'groceries', 'confidence', 'subject', 'engineering', 'blog', 'post', 'wrote', 'building', 'source', 'truth', 'inventory', 'disparate', 'data', 'sources', 'https', 'doordash', 'engineering', 'building', 'source', 'truth', 'digital', 'inventory', 'disparate', 'data', 'sources', 'article', 'explains', 'crowd', 'sourced', 'inventory', 'data', 'number', 'different', 'sources', 'enabled', 'us', 'predict', 'items', 'likely', 'still', 'shelves', 'customers', 'place', 'order', 'take', 'look', 'let', 'know', 'think']","['p', 'build', 'sourc', 'truth', 'inventori', 'dispar', 'data', 'sourceson', 'challeng', 'shift', 'food', 'deliveri', 'groceri', 'manag', 'inventori', 'although', 'restaur', 'menu', 'item', 'sometim', 'go', 'stock', 'groceri', 'store', 'inventori', 'far', 'sku', 'mani', 'differ', 'way', 'track', 'inventori', 'level', 'complex', 'groceri', 'make', 'lot', 'harder', 'ensur', 'item', 'custom', 'buy', 'actual', 'avail', 'know', 'ground', 'truth', 'custom', 'order', 'groceri', 'confid', 'subject', 'engin', 'blog', 'post', 'wrote', 'build', 'sourc', 'truth', 'inventori', 'dispar', 'data', 'sourc', 'http', 'doordash', 'engin', 'build', 'sourc', 'truth', 'digit', 'inventori', 'dispar', 'data', 'sourc', 'articl', 'explain', 'crowd', 'sourc', 'inventori', 'data', 'number', 'differ', 'sourc', 'enabl', 'us', 'predict', 'item', 'like', 'still', 'shelv', 'custom', 'place', 'order', 'take', 'look', 'let', 'know', 'think']"
268,292,292,DigThatData,vhfp1t,"[N] [D] Openai, who runs DALLE-2 alleged threatened creator of DALLE-Mini","Trying to cross-post what I think is a discussion that is relevant to this community. This is my third attempt, I hope I'm doing it correctly this time: 

https://www.reddit.com/r/dalle2/comments/vgtgdc/openai_who_runs_dalle2_alleged_threatened_creator/

EDIT: here are the original pre-prints for added context:

* DALL-E: [Zero-Shot Text-to-Image Generation](https://arxiv.org/abs/2102.12092) - The only place the term ""DALL-E"" appears is the URL to the github repo.
* Dall-E 2: [Hierarchical Text-Conditional Image Generation with CLIP Latents](https://arxiv.org/abs/2204.06125) - They consistently refer to the first paper as ""DALL-E"", but refer to the work being described in the new paper as ""unCLIP"" and are careful to only use 'DALL-E 2' in the context of a product description, e.g. ""DALL·E 2 Preview platform (the first deployment of an unCLIP model)""",119,262,2022-06-21 20:47:08, n   d  openai  who runs dalle  alleged threatened creator of dalle mini,trying to cross post what i think is a discussion that is relevant to this community  this is my third attempt  i hope i m doing it correctly this time  https edit  here are the original pre prints for added context   dall e   zero shot text to image generation  https   dall e    hierarchical text conditional image generation with clip latents  https   arxiv org abs      they consistently refer to the first paper as dall e  but refer to the work being described in the new paper as unclip and are careful to only use  dall e   in the context of a product description  e g  dall e  preview platform  the first deployment of an unclip model ,trying cross post think discussion relevant community third attempt hope correctly time https edit original pre prints added context dall e zero shot text image generation https dall e hierarchical text conditional image generation clip latents https arxiv org abs consistently refer first paper dall e refer work described paper unclip careful use dall e context product description e g dall e preview platform first deployment unclip model,n openai runs dalle alleged threatened creator dalle mini,n openai runs dalle alleged threatened creator dalle minitrying cross post think discussion relevant community third attempt hope correctly time https edit original pre prints added context dall e zero shot text image generation https dall e hierarchical text conditional image generation clip latents https arxiv org abs consistently refer first paper dall e refer work described paper unclip careful use dall e context product description e g dall e preview platform first deployment unclip model,"['n', 'openai', 'runs', 'dalle', 'alleged', 'threatened', 'creator', 'dalle', 'minitrying', 'cross', 'post', 'think', 'discussion', 'relevant', 'community', 'third', 'attempt', 'hope', 'correctly', 'time', 'https', 'edit', 'original', 'pre', 'prints', 'added', 'context', 'dall', 'e', 'zero', 'shot', 'text', 'image', 'generation', 'https', 'dall', 'e', 'hierarchical', 'text', 'conditional', 'image', 'generation', 'clip', 'latents', 'https', 'arxiv', 'org', 'abs', 'consistently', 'refer', 'first', 'paper', 'dall', 'e', 'refer', 'work', 'described', 'paper', 'unclip', 'careful', 'use', 'dall', 'e', 'context', 'product', 'description', 'e', 'g', 'dall', 'e', 'preview', 'platform', 'first', 'deployment', 'unclip', 'model']","['n', 'openai', 'run', 'dall', 'alleg', 'threaten', 'creator', 'dall', 'minitri', 'cross', 'post', 'think', 'discuss', 'relev', 'commun', 'third', 'attempt', 'hope', 'correctli', 'time', 'http', 'edit', 'origin', 'pre', 'print', 'ad', 'context', 'dall', 'e', 'zero', 'shot', 'text', 'imag', 'gener', 'http', 'dall', 'e', 'hierarch', 'text', 'condit', 'imag', 'gener', 'clip', 'latent', 'http', 'arxiv', 'org', 'ab', 'consist', 'refer', 'first', 'paper', 'dall', 'e', 'refer', 'work', 'describ', 'paper', 'unclip', 'care', 'use', 'dall', 'e', 'context', 'product', 'descript', 'e', 'g', 'dall', 'e', 'preview', 'platform', 'first', 'deploy', 'unclip', 'model']"
269,293,293,TheFibo1123,vhuozn,[Discussion] Iteration of Machine Learning Systems,"Engineering systems progress by addressing used cases of increasing levels of **complexity**.

For example, you start with a 'minimum viable product' and then slowly add features or complexity as things progress.

However, this is not how machine learning systems progress. You don't start with 10 positive/negative samples, and then iteratively add more. It's not even wise to start with one (or a few) 'tasks' and then add new ones as things progress.

Clearly, iteration (or progress) in machine learning systems does not follow the same pattern as traditional engineering systems. Is there another way to think about iteration?",12,27,2022-06-22 08:22:47, discussion  iteration of machine learning systems,engineering systems progress by addressing used cases of increasing levels of   complexity   for example  you start with a  minimum viable product  and then slowly add features or complexity as things progress however  this is not how machine learning systems progress  you don t start with  positive negative samples  and then iteratively add more  it s not even wise to start with one  or a few   tasks  and then add new ones as things progress clearly  iteration  or progress  in machine learning systems does not follow the same pattern as traditional engineering systems  is there another way to think about iteration ,engineering systems progress addressing used cases increasing levels complexity example start minimum viable product slowly features complexity things progress however machine learning systems progress start positive negative samples iteratively even wise start one tasks ones things progress clearly iteration progress machine learning systems follow pattern traditional engineering systems another way think iteration,discussion iteration machine learning systems,discussion iteration machine learning systemsengineering systems progress addressing used cases increasing levels complexity example start minimum viable product slowly features complexity things progress however machine learning systems progress start positive negative samples iteratively even wise start one tasks ones things progress clearly iteration progress machine learning systems follow pattern traditional engineering systems another way think iteration,"['discussion', 'iteration', 'machine', 'learning', 'systemsengineering', 'systems', 'progress', 'addressing', 'used', 'cases', 'increasing', 'levels', 'complexity', 'example', 'start', 'minimum', 'viable', 'product', 'slowly', 'features', 'complexity', 'things', 'progress', 'however', 'machine', 'learning', 'systems', 'progress', 'start', 'positive', 'negative', 'samples', 'iteratively', 'even', 'wise', 'start', 'one', 'tasks', 'ones', 'things', 'progress', 'clearly', 'iteration', 'progress', 'machine', 'learning', 'systems', 'follow', 'pattern', 'traditional', 'engineering', 'systems', 'another', 'way', 'think', 'iteration']","['discuss', 'iter', 'machin', 'learn', 'systemsengin', 'system', 'progress', 'address', 'use', 'case', 'increas', 'level', 'complex', 'exampl', 'start', 'minimum', 'viabl', 'product', 'slowli', 'featur', 'complex', 'thing', 'progress', 'howev', 'machin', 'learn', 'system', 'progress', 'start', 'posit', 'neg', 'sampl', 'iter', 'even', 'wise', 'start', 'one', 'task', 'one', 'thing', 'progress', 'clearli', 'iter', 'progress', 'machin', 'learn', 'system', 'follow', 'pattern', 'tradit', 'engin', 'system', 'anoth', 'way', 'think', 'iter']"
270,294,294,bahauddin_onar,vhwgv5,[R][P] Best Approach to do Image Inpainting in Video Files (Image Timeseries),"First time posting here. I am working with image timeseries of satellite images. These are essentially 1 hour long video files with the image size of 384 X 384 pix. The images have chunks of data missing, say 20 X 20 pix at different parts of the image. I would say that the missing part of the image is roughly 20%-25%. Now I have the ground truths to train a neural network. But what I am struggling is what primary architecture should I begin with: CNN, LSTM, CNN-LSTM, U-Net? I found this literature: [https://arxiv.org/abs/2112.09262](https://arxiv.org/abs/2112.09262) \- which exploits a U-net autoencoder architecture to solve the image inpainting problem, but I am not sure how robust this is for 3D (x,y,t) image cubes.

Is there anyone experienced here who has worked on image inpainting on video files? Can you please share your experience? If you can point me towards a reliable literature that would be a big help!",8,13,2022-06-22 09:59:24, r  p  best approach to do image inpainting in video files  image timeseries ,first time posting here  i am working with image timeseries of satellite images  these are essentially  hour long video files with the image size of  x  pix  the images have chunks of data missing  say  x  pix at different parts of the image  i would say that the missing part of the image is roughly      now i have the ground truths to train a neural network  but what i am struggling is what primary architecture should i begin with  cnn  lstm  cnn lstm  u net  i found this literature   https is there anyone experienced here who has worked on image inpainting on video files  can you please share your experience  if you can point me towards a reliable literature that would be a big help ,first time posting working image timeseries satellite images essentially hour long video files image size x pix images chunks data missing say x pix different parts image would say missing part image roughly ground truths train neural network struggling primary architecture begin cnn lstm cnn lstm u net found literature https anyone experienced worked image inpainting video files please share experience point towards reliable literature would big help,r p best approach image inpainting video files image timeseries,r p best approach image inpainting video files image timeseriesfirst time posting working image timeseries satellite images essentially hour long video files image size x pix images chunks data missing say x pix different parts image would say missing part image roughly ground truths train neural network struggling primary architecture begin cnn lstm cnn lstm u net found literature https anyone experienced worked image inpainting video files please share experience point towards reliable literature would big help,"['r', 'p', 'best', 'approach', 'image', 'inpainting', 'video', 'files', 'image', 'timeseriesfirst', 'time', 'posting', 'working', 'image', 'timeseries', 'satellite', 'images', 'essentially', 'hour', 'long', 'video', 'files', 'image', 'size', 'x', 'pix', 'images', 'chunks', 'data', 'missing', 'say', 'x', 'pix', 'different', 'parts', 'image', 'would', 'say', 'missing', 'part', 'image', 'roughly', 'ground', 'truths', 'train', 'neural', 'network', 'struggling', 'primary', 'architecture', 'begin', 'cnn', 'lstm', 'cnn', 'lstm', 'u', 'net', 'found', 'literature', 'https', 'anyone', 'experienced', 'worked', 'image', 'inpainting', 'video', 'files', 'please', 'share', 'experience', 'point', 'towards', 'reliable', 'literature', 'would', 'big', 'help']","['r', 'p', 'best', 'approach', 'imag', 'inpaint', 'video', 'file', 'imag', 'timeseriesfirst', 'time', 'post', 'work', 'imag', 'timeseri', 'satellit', 'imag', 'essenti', 'hour', 'long', 'video', 'file', 'imag', 'size', 'x', 'pix', 'imag', 'chunk', 'data', 'miss', 'say', 'x', 'pix', 'differ', 'part', 'imag', 'would', 'say', 'miss', 'part', 'imag', 'roughli', 'ground', 'truth', 'train', 'neural', 'network', 'struggl', 'primari', 'architectur', 'begin', 'cnn', 'lstm', 'cnn', 'lstm', 'u', 'net', 'found', 'literatur', 'http', 'anyon', 'experienc', 'work', 'imag', 'inpaint', 'video', 'file', 'pleas', 'share', 'experi', 'point', 'toward', 'reliabl', 'literatur', 'would', 'big', 'help']"
271,295,295,berimbolo21,vi97e2,[R] Black box adversarial attacks that do not require output labels,"For those who specialize in adversarial machine learning, are there any black box attacks that do not require the model's output labels when generating adversarial images? I can't seem to find any",1,1,2022-06-22 21:58:04, r  black box adversarial attacks that do not require output labels,for those who specialize in adversarial machine learning  are there any black box attacks that do not require the model s output labels when generating adversarial images  i can t seem to find any,specialize adversarial machine learning black box attacks require model output labels generating adversarial images seem find,r black box adversarial attacks require output labels,r black box adversarial attacks require output labelsspecialize adversarial machine learning black box attacks require model output labels generating adversarial images seem find,"['r', 'black', 'box', 'adversarial', 'attacks', 'require', 'output', 'labelsspecialize', 'adversarial', 'machine', 'learning', 'black', 'box', 'attacks', 'require', 'model', 'output', 'labels', 'generating', 'adversarial', 'images', 'seem', 'find']","['r', 'black', 'box', 'adversari', 'attack', 'requir', 'output', 'labelsspeci', 'adversari', 'machin', 'learn', 'black', 'box', 'attack', 'requir', 'model', 'output', 'label', 'gener', 'adversari', 'imag', 'seem', 'find']"
272,296,296,bandalorian,vi6cnr,[D] How to compare model performance when you add data withe label noise?,"Let's say I'm trying to categorize vendors based on their description using some NLP technique. I have a limited dataset of vendors with high quality (low noise) labels. I split in to train/test, and score say 90% accuracy. I then get hold of a dataset  for 3d party vendors, which will have much noisier (but still useful) data. Now when I train the model I get an 89% accuracy. 

How do I interpret this? The noisier data will also go in the test split, and the model is expected to perform worse on those, so even if it's exactly as good as the prior model on the old data, it should have an average worse performance on the new dataset. It could even be better, say scoring 91% on the old data, but 85% on the new data, so the average accuracy looks lower even though you have a better model.

Testing the old model on the new test set I guess would settle this? Just curious if there are any best practices.",4,0,2022-06-22 19:48:51, d  how to compare model performance when you add data withe label noise ,let s say i m trying to categorize vendors based on their description using some nlp technique  i have a limited dataset of vendors with high quality  low noise  labels  i split in to train test  and score say   accuracy  i then get hold of a dataset  for d party vendors  which will have much noisier  but still useful  data  now when i train the model i get an   accuracy  how do i interpret this  the noisier data will also go in the test split  and the model is expected to perform worse on those  so even if it s exactly as good as the prior model on the old data  it should have an average worse performance on the new dataset  it could even be better  say scoring   on the old data  but   on the new data  so the average accuracy looks lower even though you have a better model testing the old model on the new test set i guess would settle this  just curious if there are any best practices ,let say trying categorize vendors based description using nlp technique limited dataset vendors high quality low noise labels split train test score say accuracy get hold dataset party vendors much noisier still useful data train model get accuracy interpret noisier data also go test split model expected perform worse even exactly good prior model old data average worse performance dataset could even better say scoring old data data average accuracy looks lower even though better model testing old model test set guess would settle curious best practices,compare model performance data withe label noise,compare model performance data withe label noiselet say trying categorize vendors based description using nlp technique limited dataset vendors high quality low noise labels split train test score say accuracy get hold dataset party vendors much noisier still useful data train model get accuracy interpret noisier data also go test split model expected perform worse even exactly good prior model old data average worse performance dataset could even better say scoring old data data average accuracy looks lower even though better model testing old model test set guess would settle curious best practices,"['compare', 'model', 'performance', 'data', 'withe', 'label', 'noiselet', 'say', 'trying', 'categorize', 'vendors', 'based', 'description', 'using', 'nlp', 'technique', 'limited', 'dataset', 'vendors', 'high', 'quality', 'low', 'noise', 'labels', 'split', 'train', 'test', 'score', 'say', 'accuracy', 'get', 'hold', 'dataset', 'party', 'vendors', 'much', 'noisier', 'still', 'useful', 'data', 'train', 'model', 'get', 'accuracy', 'interpret', 'noisier', 'data', 'also', 'go', 'test', 'split', 'model', 'expected', 'perform', 'worse', 'even', 'exactly', 'good', 'prior', 'model', 'old', 'data', 'average', 'worse', 'performance', 'dataset', 'could', 'even', 'better', 'say', 'scoring', 'old', 'data', 'data', 'average', 'accuracy', 'looks', 'lower', 'even', 'though', 'better', 'model', 'testing', 'old', 'model', 'test', 'set', 'guess', 'would', 'settle', 'curious', 'best', 'practices']","['compar', 'model', 'perform', 'data', 'with', 'label', 'noiselet', 'say', 'tri', 'categor', 'vendor', 'base', 'descript', 'use', 'nlp', 'techniqu', 'limit', 'dataset', 'vendor', 'high', 'qualiti', 'low', 'nois', 'label', 'split', 'train', 'test', 'score', 'say', 'accuraci', 'get', 'hold', 'dataset', 'parti', 'vendor', 'much', 'noisier', 'still', 'use', 'data', 'train', 'model', 'get', 'accuraci', 'interpret', 'noisier', 'data', 'also', 'go', 'test', 'split', 'model', 'expect', 'perform', 'wors', 'even', 'exactli', 'good', 'prior', 'model', 'old', 'data', 'averag', 'wors', 'perform', 'dataset', 'could', 'even', 'better', 'say', 'score', 'old', 'data', 'data', 'averag', 'accuraci', 'look', 'lower', 'even', 'though', 'better', 'model', 'test', 'old', 'model', 'test', 'set', 'guess', 'would', 'settl', 'curiou', 'best', 'practic']"
273,297,297,singularpanda,vhyxbo,[D][R] Is there any benchmark task set for computer vision?,"I know that in NLP, there are some benchmark task sets like GLUE, SuperGLUE, etc. I wonder wherer there is any similar benchmark task set for computer vision that we can easily test many tasks in a unified way?",4,4,2022-06-22 12:29:13, d  r  is there any benchmark task set for computer vision ,i know that in nlp  there are some benchmark task sets like glue  superglue  etc  i wonder wherer there is any similar benchmark task set for computer vision that we can easily test many tasks in a unified way ,know nlp benchmark task sets like glue superglue etc wonder wherer similar benchmark task set computer vision easily test many tasks unified way,r benchmark task set computer vision,r benchmark task set computer visionknow nlp benchmark task sets like glue superglue etc wonder wherer similar benchmark task set computer vision easily test many tasks unified way,"['r', 'benchmark', 'task', 'set', 'computer', 'visionknow', 'nlp', 'benchmark', 'task', 'sets', 'like', 'glue', 'superglue', 'etc', 'wonder', 'wherer', 'similar', 'benchmark', 'task', 'set', 'computer', 'vision', 'easily', 'test', 'many', 'tasks', 'unified', 'way']","['r', 'benchmark', 'task', 'set', 'comput', 'visionknow', 'nlp', 'benchmark', 'task', 'set', 'like', 'glue', 'superglu', 'etc', 'wonder', 'wherer', 'similar', 'benchmark', 'task', 'set', 'comput', 'vision', 'easili', 'test', 'mani', 'task', 'unifi', 'way']"
274,298,298,MLRecipes,vh4xgc,[D] Machine learning books for free offered with full source document (LaTeX),"Top quality machine learning papers and books, not only for free, but offered with full LaTeX source, bib file, and raw figures.  So that anyone can easy incorporate part of these books (formulas, tables, pictures, text. references etc.) into their PhD thesis, articles, or reports. The user could even fix any typo he finds then print an enhanced version of the book, for private (or public) use.

That sounds like a dream? I am actually thinking offering this, with my numerous papers / books. My question is this: is it a good idea? Should I charge a fee (in other words: would you pay for it?) I understand some will use the material for plagiarism, but I am not too concerned about it, or should I? My first candidate book for this is the following: [https://mltechniques.com/2022/03/22/book-stochastic-processes-and-simulations/](https://mltechniques.com/2022/03/22/book-stochastic-processes-and-simulations/). I just finished converting all the Perl code into Python, and will soon publish the 2nd edition, this time in Python \[if it comes with LaTeX code, it means that the user can easily extract the Python code from the book, though it is also on GitHub\].",12,239,2022-06-21 10:10:46, d  machine learning books for free offered with full source document  latex ,top quality machine learning papers and books  not only for free  but offered with full latex source  bib file  and raw figures   so that anyone can easy incorporate part of these books  formulas  tables  pictures  text  references etc   into their phd thesis  articles  or reports  the user could even fix any typo he finds then print an enhanced version of the book  for private  or public  use that sounds like a dream  i am actually thinking offering this  with my numerous papers   books  my question is this  is it a good idea  should i charge a fee  in other words  would you pay for it   i understand some will use the material for plagiarism  but i am not too concerned about it  or should i  my first candidate book for this is the following   https   mltechniques com    book stochastic processes and simulations   https   mltechniques com    book stochastic processes and simulations    i just finished converting all the perl code into python  and will soon publish the nd edition  this time in python   if it comes with latex code  it means that the user can easily extract the python code from the book  though it is also on github   ,top quality machine learning papers books free offered full latex source bib file raw figures anyone easy incorporate part books formulas tables pictures text references etc phd thesis articles reports user could even fix typo finds print enhanced version book private public use sounds like dream actually thinking offering numerous papers books question good idea charge fee would pay understand use material plagiarism concerned first candidate book following https mltechniques com book stochastic processes simulations https mltechniques com book stochastic processes simulations finished converting perl code python soon publish nd edition time python comes latex code means user easily extract python code book though also github,machine learning books free offered full source document latex,machine learning books free offered full source document latextop quality machine learning papers books free offered full latex source bib file raw figures anyone easy incorporate part books formulas tables pictures text references etc phd thesis articles reports user could even fix typo finds print enhanced version book private public use sounds like dream actually thinking offering numerous papers books question good idea charge fee would pay understand use material plagiarism concerned first candidate book following https mltechniques com book stochastic processes simulations https mltechniques com book stochastic processes simulations finished converting perl code python soon publish nd edition time python comes latex code means user easily extract python code book though also github,"['machine', 'learning', 'books', 'free', 'offered', 'full', 'source', 'document', 'latextop', 'quality', 'machine', 'learning', 'papers', 'books', 'free', 'offered', 'full', 'latex', 'source', 'bib', 'file', 'raw', 'figures', 'anyone', 'easy', 'incorporate', 'part', 'books', 'formulas', 'tables', 'pictures', 'text', 'references', 'etc', 'phd', 'thesis', 'articles', 'reports', 'user', 'could', 'even', 'fix', 'typo', 'finds', 'print', 'enhanced', 'version', 'book', 'private', 'public', 'use', 'sounds', 'like', 'dream', 'actually', 'thinking', 'offering', 'numerous', 'papers', 'books', 'question', 'good', 'idea', 'charge', 'fee', 'would', 'pay', 'understand', 'use', 'material', 'plagiarism', 'concerned', 'first', 'candidate', 'book', 'following', 'https', 'mltechniques', 'com', 'book', 'stochastic', 'processes', 'simulations', 'https', 'mltechniques', 'com', 'book', 'stochastic', 'processes', 'simulations', 'finished', 'converting', 'perl', 'code', 'python', 'soon', 'publish', 'nd', 'edition', 'time', 'python', 'comes', 'latex', 'code', 'means', 'user', 'easily', 'extract', 'python', 'code', 'book', 'though', 'also', 'github']","['machin', 'learn', 'book', 'free', 'offer', 'full', 'sourc', 'document', 'latextop', 'qualiti', 'machin', 'learn', 'paper', 'book', 'free', 'offer', 'full', 'latex', 'sourc', 'bib', 'file', 'raw', 'figur', 'anyon', 'easi', 'incorpor', 'part', 'book', 'formula', 'tabl', 'pictur', 'text', 'refer', 'etc', 'phd', 'thesi', 'articl', 'report', 'user', 'could', 'even', 'fix', 'typo', 'find', 'print', 'enhanc', 'version', 'book', 'privat', 'public', 'use', 'sound', 'like', 'dream', 'actual', 'think', 'offer', 'numer', 'paper', 'book', 'question', 'good', 'idea', 'charg', 'fee', 'would', 'pay', 'understand', 'use', 'materi', 'plagiar', 'concern', 'first', 'candid', 'book', 'follow', 'http', 'mltechniqu', 'com', 'book', 'stochast', 'process', 'simul', 'http', 'mltechniqu', 'com', 'book', 'stochast', 'process', 'simul', 'finish', 'convert', 'perl', 'code', 'python', 'soon', 'publish', 'nd', 'edit', 'time', 'python', 'come', 'latex', 'code', 'mean', 'user', 'easili', 'extract', 'python', 'code', 'book', 'though', 'also', 'github']"
275,299,299,Upstairs-Jicama-8347,vhorh4,"[D] Techniques for dealing with classic statistical data gathering problems: selection bias, differential attrition, experimenter bias, ect.. in Machine Learning?","Can anyone suggest papers or techniques in ML to deal with some of the statistical bias problems outlined in the title? (selection bias, differential attrition, experimenter bias, ect..)",0,9,2022-06-22 03:28:19, d  techniques for dealing with classic statistical data gathering problems  selection bias  differential attrition  experimenter bias  ect   in machine learning ,can anyone suggest papers or techniques in ml to deal with some of the statistical bias problems outlined in the title   selection bias  differential attrition  experimenter bias  ect   ,anyone suggest papers techniques ml deal statistical bias problems outlined title selection bias differential attrition experimenter bias ect,techniques dealing classic statistical data gathering problems selection bias differential attrition experimenter bias ect machine learning,techniques dealing classic statistical data gathering problems selection bias differential attrition experimenter bias ect machine learninganyone suggest papers techniques ml deal statistical bias problems outlined title selection bias differential attrition experimenter bias ect,"['techniques', 'dealing', 'classic', 'statistical', 'data', 'gathering', 'problems', 'selection', 'bias', 'differential', 'attrition', 'experimenter', 'bias', 'ect', 'machine', 'learninganyone', 'suggest', 'papers', 'techniques', 'ml', 'deal', 'statistical', 'bias', 'problems', 'outlined', 'title', 'selection', 'bias', 'differential', 'attrition', 'experimenter', 'bias', 'ect']","['techniqu', 'deal', 'classic', 'statist', 'data', 'gather', 'problem', 'select', 'bia', 'differenti', 'attrit', 'experiment', 'bia', 'ect', 'machin', 'learninganyon', 'suggest', 'paper', 'techniqu', 'ml', 'deal', 'statist', 'bia', 'problem', 'outlin', 'titl', 'select', 'bia', 'differenti', 'attrit', 'experiment', 'bia', 'ect']"
276,300,300,MLJungle,vhzk9e,"[D] Iterative ""imputation"" HMM sequence generation idea","I have an idea in my head that I am looking to get some feedback/formal understanding of.

Say we consider a n-gram model (ex: bi/trigram). For sequence generation (such as a sequence of words),  one way would be to start with some input word and then use the n-gram model to simply unroll and predict the rest of the words, generating some sentence. If O is original and N is new, we would have O-N-N-N-N.. and so on.

Alternatively, I was thinking of a way to generate a sequence that might be more similar to the original text but still be stochastically generated. One use case for this would be generating sequential synthetic data, where the synthetic data should be as similar to the original data but should be generated and have a stochastic nature to it.

Here, let us take some sequence and proceed to do imputation- we nullify every other word, starting from the first input word. Then, we use a trained modified 'sandwich' HMM bi-gram model which predicts based on the before and after word. Then, we use the sandwich HMM to fill in the nullified every other word. Now, our sequence would be O-N-O-N-O. To get a more fully generated sequence, we could use another model, a trained bi-gram HMM model to impute the original words- in particular, for the third word it would use O-N to generate a guess, for the fifth it would use the next O-N, and so on, giving us ONNNN..., where each guess utilizes both O and N.

My idea is by doing this ""imputation"" step wise to generate our words, rather than unrolling it out all at once, is that we have remnants of the original text in conjunction with new predicted words to guide the generation of each word as opposed to possibly just new predicted words with the unrolled method.  This may lead to more similar generated sentences.

(A more extreme method might consider just using the original data to make every prediction- for example, we could consider a trained bi-gram model that uses the first word O to predict the second, the second O to predict the third, and so on. I don't think this will lead to good generated sequences we would have O-N-N but the third word does not depend at all directly on info from the second.)

EDIT: Looking to use model (such as HMM) that works well on very small datasets.",2,0,2022-06-22 13:11:22, d  iterative imputation hmm sequence generation idea,i have an idea in my head that i am looking to get some feedback formal understanding of say we consider a n gram model  ex  bi trigram   for sequence generation  such as a sequence of words    one way would be to start with some input word and then use the n gram model to simply unroll and predict the rest of the words  generating some sentence  if o is original and n is new  we would have o n n n n   and so on alternatively  i was thinking of a way to generate a sequence that might be more similar to the original text but still be stochastically generated  one use case for this would be generating sequential synthetic data  where the synthetic data should be as similar to the original data but should be generated and have a stochastic nature to it here  let us take some sequence and proceed to do imputation  we nullify every other word  starting from the first input word  then  we use a trained modified  sandwich  hmm bi gram model which predicts based on the before and after word  then  we use the sandwich hmm to fill in the nullified every other word  now  our sequence would be o n o n o  to get a more fully generated sequence  we could use another model  a trained bi gram hmm model to impute the original words  in particular  for the third word it would use o n to generate a guess  for the fifth it would use the next o n  and so on  giving us onnnn     where each guess utilizes both o and n my idea is by doing this imputation step wise to generate our words  rather than unrolling it out all at once  is that we have remnants of the original text in conjunction with new predicted words to guide the generation of each word as opposed to possibly just new predicted words with the unrolled method   this may lead to more similar generated sentences  a more extreme method might consider just using the original data to make every prediction  for example  we could consider a trained bi gram model that uses the first word o to predict the second  the second o to predict the third  and so on  i don t think this will lead to good generated sequences we would have o n n but the third word does not depend at all directly on info from the second  edit  looking to use model  such as hmm  that works well on very small datasets ,idea head looking get feedback formal understanding say consider n gram model ex bi trigram sequence generation sequence one way would start input word use n gram model simply unroll predict rest generating sentence original n would n n n n alternatively thinking way generate sequence might similar original text still stochastically generated one use case would generating sequential synthetic data synthetic data similar original data generated stochastic nature let us take sequence proceed imputation nullify every word starting first input word use trained modified sandwich hmm bi gram model predicts based word use sandwich hmm fill nullified every word sequence would n n get fully generated sequence could use another model trained bi gram hmm model impute original particular third word would use n generate guess fifth would use next n giving us onnnn guess utilizes n idea imputation step wise generate rather unrolling remnants original text conjunction predicted guide generation word opposed possibly predicted unrolled method may lead similar generated sentences extreme method might consider using original data make every prediction example could consider trained bi gram model uses first word predict second second predict third think lead good generated sequences would n n third word depend directly info second edit looking use model hmm works well small datasets,iterative imputation hmm sequence generation idea,iterative imputation hmm sequence generation ideaidea head looking get feedback formal understanding say consider n gram model ex bi trigram sequence generation sequence one way would start input word use n gram model simply unroll predict rest generating sentence original n would n n n n alternatively thinking way generate sequence might similar original text still stochastically generated one use case would generating sequential synthetic data synthetic data similar original data generated stochastic nature let us take sequence proceed imputation nullify every word starting first input word use trained modified sandwich hmm bi gram model predicts based word use sandwich hmm fill nullified every word sequence would n n get fully generated sequence could use another model trained bi gram hmm model impute original particular third word would use n generate guess fifth would use next n giving us onnnn guess utilizes n idea imputation step wise generate rather unrolling remnants original text conjunction predicted guide generation word opposed possibly predicted unrolled method may lead similar generated sentences extreme method might consider using original data make every prediction example could consider trained bi gram model uses first word predict second second predict third think lead good generated sequences would n n third word depend directly info second edit looking use model hmm works well small datasets,"['iterative', 'imputation', 'hmm', 'sequence', 'generation', 'ideaidea', 'head', 'looking', 'get', 'feedback', 'formal', 'understanding', 'say', 'consider', 'n', 'gram', 'model', 'ex', 'bi', 'trigram', 'sequence', 'generation', 'sequence', 'one', 'way', 'would', 'start', 'input', 'word', 'use', 'n', 'gram', 'model', 'simply', 'unroll', 'predict', 'rest', 'generating', 'sentence', 'original', 'n', 'would', 'n', 'n', 'n', 'n', 'alternatively', 'thinking', 'way', 'generate', 'sequence', 'might', 'similar', 'original', 'text', 'still', 'stochastically', 'generated', 'one', 'use', 'case', 'would', 'generating', 'sequential', 'synthetic', 'data', 'synthetic', 'data', 'similar', 'original', 'data', 'generated', 'stochastic', 'nature', 'let', 'us', 'take', 'sequence', 'proceed', 'imputation', 'nullify', 'every', 'word', 'starting', 'first', 'input', 'word', 'use', 'trained', 'modified', 'sandwich', 'hmm', 'bi', 'gram', 'model', 'predicts', 'based', 'word', 'use', 'sandwich', 'hmm', 'fill', 'nullified', 'every', 'word', 'sequence', 'would', 'n', 'n', 'get', 'fully', 'generated', 'sequence', 'could', 'use', 'another', 'model', 'trained', 'bi', 'gram', 'hmm', 'model', 'impute', 'original', 'particular', 'third', 'word', 'would', 'use', 'n', 'generate', 'guess', 'fifth', 'would', 'use', 'next', 'n', 'giving', 'us', 'onnnn', 'guess', 'utilizes', 'n', 'idea', 'imputation', 'step', 'wise', 'generate', 'rather', 'unrolling', 'remnants', 'original', 'text', 'conjunction', 'predicted', 'guide', 'generation', 'word', 'opposed', 'possibly', 'predicted', 'unrolled', 'method', 'may', 'lead', 'similar', 'generated', 'sentences', 'extreme', 'method', 'might', 'consider', 'using', 'original', 'data', 'make', 'every', 'prediction', 'example', 'could', 'consider', 'trained', 'bi', 'gram', 'model', 'uses', 'first', 'word', 'predict', 'second', 'second', 'predict', 'third', 'think', 'lead', 'good', 'generated', 'sequences', 'would', 'n', 'n', 'third', 'word', 'depend', 'directly', 'info', 'second', 'edit', 'looking', 'use', 'model', 'hmm', 'works', 'well', 'small', 'datasets']","['iter', 'imput', 'hmm', 'sequenc', 'gener', 'ideaidea', 'head', 'look', 'get', 'feedback', 'formal', 'understand', 'say', 'consid', 'n', 'gram', 'model', 'ex', 'bi', 'trigram', 'sequenc', 'gener', 'sequenc', 'one', 'way', 'would', 'start', 'input', 'word', 'use', 'n', 'gram', 'model', 'simpli', 'unrol', 'predict', 'rest', 'gener', 'sentenc', 'origin', 'n', 'would', 'n', 'n', 'n', 'n', 'altern', 'think', 'way', 'gener', 'sequenc', 'might', 'similar', 'origin', 'text', 'still', 'stochast', 'gener', 'one', 'use', 'case', 'would', 'gener', 'sequenti', 'synthet', 'data', 'synthet', 'data', 'similar', 'origin', 'data', 'gener', 'stochast', 'natur', 'let', 'us', 'take', 'sequenc', 'proceed', 'imput', 'nullifi', 'everi', 'word', 'start', 'first', 'input', 'word', 'use', 'train', 'modifi', 'sandwich', 'hmm', 'bi', 'gram', 'model', 'predict', 'base', 'word', 'use', 'sandwich', 'hmm', 'fill', 'nullifi', 'everi', 'word', 'sequenc', 'would', 'n', 'n', 'get', 'fulli', 'gener', 'sequenc', 'could', 'use', 'anoth', 'model', 'train', 'bi', 'gram', 'hmm', 'model', 'imput', 'origin', 'particular', 'third', 'word', 'would', 'use', 'n', 'gener', 'guess', 'fifth', 'would', 'use', 'next', 'n', 'give', 'us', 'onnnn', 'guess', 'util', 'n', 'idea', 'imput', 'step', 'wise', 'gener', 'rather', 'unrol', 'remnant', 'origin', 'text', 'conjunct', 'predict', 'guid', 'gener', 'word', 'oppos', 'possibl', 'predict', 'unrol', 'method', 'may', 'lead', 'similar', 'gener', 'sentenc', 'extrem', 'method', 'might', 'consid', 'use', 'origin', 'data', 'make', 'everi', 'predict', 'exampl', 'could', 'consid', 'train', 'bi', 'gram', 'model', 'use', 'first', 'word', 'predict', 'second', 'second', 'predict', 'third', 'think', 'lead', 'good', 'gener', 'sequenc', 'would', 'n', 'n', 'third', 'word', 'depend', 'directli', 'info', 'second', 'edit', 'look', 'use', 'model', 'hmm', 'work', 'well', 'small', 'dataset']"
277,301,301,jovezhong,vhwy3k,[D] What do you think of the idea of Real-time Machine Learning with Streaming SQL,"I am working on a startup to simplify the process of real-time application development. Streaming SQL is the key user interface. We recently worked out a solution to apply ML/prediction in the Streaming SQL, so that you can continuously train and predict data when new data comes. No code required, just SQL.  If you need more complex logic, you can wrap your code as user-defined-function and still put in the SQL. I am not going to put a link but you can search timeplus and find our website.

Open for discussions, do you think such tools will help some customers to implement easy use cases without much dev resource/effort.

Here is an example:
```sql
WITH LinearModel AS
 (
 SELECT
      gas_percent, to_int(time) AS t, 
      [lag(t), lag(t, 2), lag(t, 3), lag(t, 4), lag(t, 5)] AS X, [lag(gas_percent), lag(gas_percent, 2), lag(gas_percent, 3), lag(gas_percent, 4), lag(gas_percent, 5)] AS Y, 
      array_avg(X) AS avg_X, array_avg(Y) AS avg_Y, 
      array_sum(array_map((x, y) -> ((x - avg_X) * (y - avg_Y)), X, Y)) 
     / array_sum(array_map(x -> ((x - avg_X) * (x - avg_X)), X)) AS m, 
     avg_Y - (m * avg_X) AS b
 FROM car_live_data
 WHERE     cid = 'c00031'
 )
SELECT gas_percent, to_datetime(t), (t * m) + b AS predict
FROM LinearModel
```",0,3,2022-06-22 10:27:07, d  what do you think of the idea of real time machine learning with streaming sql,i am working on a startup to simplify the process of real time application development  streaming sql is the key user interface  we recently worked out a solution to apply ml prediction in the streaming sql  so that you can continuously train and predict data when new data comes  no code required  just sql   if you need more complex logic  you can wrap your code as user defined function and still put in the sql  i am not going to put a link but you can search timeplus and find our website open for discussions  do you think such tools will help some customers to implement easy use cases without much dev resource effort here is an example    sqlwith linearmodel as   select      gas_percent  to_int time  as t         lag t   lag t     lag t     lag t     lag t     as x   lag gas_percent   lag gas_percent     lag gas_percent     lag gas_percent     lag gas_percent     as y        array_avg x  as avg_x  array_avg y  as avg_y        array_sum array_map  x  y       x   avg_x     y   avg_y    x  y          array_sum array_map x      x   avg_x     x   avg_x    x   as m       avg_y    m   avg_x  as b from car_live_data where     cid    c   select gas_percent  to_datetime t    t   m    b as predictfrom linearmodel   ,working startup simplify process real time application development streaming sql key user interface recently worked solution apply ml prediction streaming sql continuously train predict data data comes code required sql need complex logic wrap code user defined function still put sql going put link search timeplus find website open discussions think tools help customers implement easy use cases without much dev resource effort example sqlwith linearmodel select gas_percent to_int time lag lag lag lag lag x lag gas_percent lag gas_percent lag gas_percent lag gas_percent lag gas_percent array_avg x avg_x array_avg avg_y array_sum array_map x x avg_x avg_y x array_sum array_map x x avg_x x avg_x x avg_y avg_x b car_live_data cid c select gas_percent to_datetime b predictfrom linearmodel,think idea real time machine learning streaming sql,think idea real time machine learning streaming sqlworking startup simplify process real time application development streaming sql key user interface recently worked solution apply ml prediction streaming sql continuously train predict data data comes code required sql need complex logic wrap code user defined function still put sql going put link search timeplus find website open discussions think tools help customers implement easy use cases without much dev resource effort example sqlwith linearmodel select gas_percent to_int time lag lag lag lag lag x lag gas_percent lag gas_percent lag gas_percent lag gas_percent lag gas_percent array_avg x avg_x array_avg avg_y array_sum array_map x x avg_x avg_y x array_sum array_map x x avg_x x avg_x x avg_y avg_x b car_live_data cid c select gas_percent to_datetime b predictfrom linearmodel,"['think', 'idea', 'real', 'time', 'machine', 'learning', 'streaming', 'sqlworking', 'startup', 'simplify', 'process', 'real', 'time', 'application', 'development', 'streaming', 'sql', 'key', 'user', 'interface', 'recently', 'worked', 'solution', 'apply', 'ml', 'prediction', 'streaming', 'sql', 'continuously', 'train', 'predict', 'data', 'data', 'comes', 'code', 'required', 'sql', 'need', 'complex', 'logic', 'wrap', 'code', 'user', 'defined', 'function', 'still', 'put', 'sql', 'going', 'put', 'link', 'search', 'timeplus', 'find', 'website', 'open', 'discussions', 'think', 'tools', 'help', 'customers', 'implement', 'easy', 'use', 'cases', 'without', 'much', 'dev', 'resource', 'effort', 'example', 'sqlwith', 'linearmodel', 'select', 'gas_percent', 'to_int', 'time', 'lag', 'lag', 'lag', 'lag', 'lag', 'x', 'lag', 'gas_percent', 'lag', 'gas_percent', 'lag', 'gas_percent', 'lag', 'gas_percent', 'lag', 'gas_percent', 'array_avg', 'x', 'avg_x', 'array_avg', 'avg_y', 'array_sum', 'array_map', 'x', 'x', 'avg_x', 'avg_y', 'x', 'array_sum', 'array_map', 'x', 'x', 'avg_x', 'x', 'avg_x', 'x', 'avg_y', 'avg_x', 'b', 'car_live_data', 'cid', 'c', 'select', 'gas_percent', 'to_datetime', 'b', 'predictfrom', 'linearmodel']","['think', 'idea', 'real', 'time', 'machin', 'learn', 'stream', 'sqlwork', 'startup', 'simplifi', 'process', 'real', 'time', 'applic', 'develop', 'stream', 'sql', 'key', 'user', 'interfac', 'recent', 'work', 'solut', 'appli', 'ml', 'predict', 'stream', 'sql', 'continu', 'train', 'predict', 'data', 'data', 'come', 'code', 'requir', 'sql', 'need', 'complex', 'logic', 'wrap', 'code', 'user', 'defin', 'function', 'still', 'put', 'sql', 'go', 'put', 'link', 'search', 'timeplu', 'find', 'websit', 'open', 'discuss', 'think', 'tool', 'help', 'custom', 'implement', 'easi', 'use', 'case', 'without', 'much', 'dev', 'resourc', 'effort', 'exampl', 'sqlwith', 'linearmodel', 'select', 'gas_perc', 'to_int', 'time', 'lag', 'lag', 'lag', 'lag', 'lag', 'x', 'lag', 'gas_perc', 'lag', 'gas_perc', 'lag', 'gas_perc', 'lag', 'gas_perc', 'lag', 'gas_perc', 'array_avg', 'x', 'avg_x', 'array_avg', 'avg_i', 'array_sum', 'array_map', 'x', 'x', 'avg_x', 'avg_i', 'x', 'array_sum', 'array_map', 'x', 'x', 'avg_x', 'x', 'avg_x', 'x', 'avg_i', 'avg_x', 'b', 'car_live_data', 'cid', 'c', 'select', 'gas_perc', 'to_datetim', 'b', 'predictfrom', 'linearmodel']"
278,302,302,luisgasco,vhhimb,[R] - Call For Participants SocialDisNER (SMM4H@COLING 2022) on Detection of Disease Mentions in Social Media," **CFP- SocialDisNER track: Detection of Disease Mentions in Social Media** 

**(SMM4H Shared Task  at COLING2022)** 

[https://temu.bsc.es/socialdisner/](https://temu.bsc.es/socialdisner/) 

Despite the high impact & practical relevance of detecting diseases automatically from social media for a diversity of applications, few manually annotated corpora generated by healthcare practitioners to train/evaluate advanced entity recognition tools are currently available.

Developing disease recognition tools for social media is critical for:

* Real-time disease outbreak surveillance/monitoring
* Characterization of patient-reported symptoms
* Post-market drug safety
* Epidemiology and population health, 
* Public opinion mining & sentiment analysis of diseases 
* Detection of hate speech/exclusion of sick people
* Prevalence of work-associated diseases

SocialDisNER is the first track focusing on the detection of disease mentions in tweets written in Spanish, with clear adaptation potential not only to English but also other romance languages like Portuguese, French or Italian spoken by over 900 million people worldwide.

For this track the SocialDisNER corpus was generated, a manual collection of tweets enriched for first-hand experiences by patients and their relatives as well as content generated by patient-associations (national, regional, local) as well as healthcare institutions covering all main diseases types including cancer, mental health, chronic and rare diseases among others. 

**Info:**

* Web: [https://temu.bsc.es/socialdisner/](https://temu.bsc.es/socialdisner/) 
* Data:[ ](https://doi.org/10.5281/zenodo.6408476)[https://doi.org/10.5281/zenodo.6359365](https://doi.org/10.5281/zenodo.6359365) 
* Registration: [https://temu.bsc.es/socialdisner/registration](https://temu.bsc.es/socialdisner/registration) 

**Schedule**

* Development Set Release: June 14th
* Test Set Release: July 11th
* Participant prediction Due: July 15th
* Test set evaluation release: July 25th
* Proceedings paper submission: August 1st
* Camera ready papers: September 1st
* SMM4H workshop @ COLING 2022: October 12-17

**Publications and SMM4H (COLING 2022) workshop**

Participating teams have the opportunity to submit a short system description paper for the SMM4H proceedings (7th SMM4H Workshop, **co-located at COLING 2022).** More details are available at [https://healthlanguageprocessing.org/smm4h-2022/](https://healthlanguageprocessing.org/smm4h-2022/)

**SocialDisNER Organizers**

* **Luis Gascó**, Barcelona Supercomputing Center, Spain
* **Darryl Estrada**, Barcelona Supercomputing Center, Spain
* **Eulàlia Farré-Maduell**, Barcelona Supercomputing Center, Spain
* **Salvador Lima**, Barcelona Supercomputing Center, Spain
* **Martin Krallinger**, Barcelona Supercomputing Center, Spain

**Scientific Committee & SMM4H Organizers**

* **Graciela Gonzalez-Hernandez,** Cedars-Sinai Medical Center, USA
* **Davy Weissenbacher,** University of Pennsylvania, USA 
* **Arjun Magge,** University of Pennsylvania, USA
* **Ari Z. Klein,** University of Pennsylvania, USA
* **Ivan Flores,** University of Pennsylvania, USA
* **Karen O’Connor,** University of Pennsylvania, USA
* **Raul Rodriguez-Esteban,** Roche Pharmaceuticals, Switzerland
* **Lucia Schmidt,** Roche Pharmaceuticals, Switzerland
* **Juan M. Banda,** Georgia State University, USA
* **Abeed Sarker,** Emory University, USA
* **Yuting Guo,** Emory University, USA 
* **Yao Ge,** Emory University, USA 
* **Elena Tutubalina,** Insilico Medicine, Hong Kong
* **Jey Han Hau,** The University of Melbourne (Australia)
* **Luca Maria Aiello,** IT University of Copenhagen
* **Rafael Valencia-Garcia,** Universidad de Murcia (Spain)
* **Antonio Jimeno Yepes,** RMIT University (Australia)
* **Carlos Gómez-Rodríguez,** Universidad da Coruña (Spain)
* **Eugenio Martinez Cámara,** Universidad de Granada (Spain)
* **Gema Bello Orgaz,**  Applied Intelligence and Data Analysis Research Group, Universidad Politécnica de Madrid (Spain)
* **Juan Antonio Lossio-Ventura,** National Institutes of Health (USA)
* **Héctor D. Menendez,** King’s College London (UK)
* **Manuel Montes y Gómez,** National Institute of Astrophysics, Optics and Electronics (Mexico)
* **Helena Gómez Adorno,** Universidad Nacional Autónoma de México (Mexico)
* **Rodrigo Agerri, IXA Group (HiTZ Centre),** University of Basque Country EHU (Spain)
* **Miguel A. Alonso,** Universidad da Coruña (Spain)
* **Ferran Pla,** Universidad Politécnica de Valencia (Spain)
* **Jose Alberto Benitez-Andrades,** Universidad de Leon (Spain)",0,5,2022-06-21 22:08:36, r    call for participants socialdisner  smmh coling   on detection of disease mentions in social media,   cfp  socialdisner track  detection of disease mentions in social media      smmh shared task  at coling     https despite the high impact   practical relevance of detecting diseases automatically from social media for a diversity of applications  few manually annotated corpora generated by healthcare practitioners to train evaluate advanced entity recognition tools are currently available developing disease recognition tools for social media is critical for   real time disease outbreak surveillance monitoring  characterization of patient reported symptoms  post market drug safety  epidemiology and population health    public opinion mining   sentiment analysis of diseases   detection of hate speech exclusion of sick people  prevalence of work associated diseasessocialdisner is the first track focusing on the detection of disease mentions in tweets written in spanish  with clear adaptation potential not only to english but also other romance languages like portuguese  french or italian spoken by over  million people worldwide for this track the socialdisner corpus was generated  a manual collection of tweets enriched for first hand experiences by patients and their relatives as well as content generated by patient associations  national  regional  local  as well as healthcare institutions covering all main diseases types including cancer  mental health  chronic and rare diseases among others    info     web   https   data     https   registration   https   schedule    development set release  june th  test set release  july th  participant prediction due  july th  test set evaluation release  july th  proceedings paper submission  august st  camera ready papers  september st  smmh workshop   coling   october    publications and smmh  coling   workshop  participating teams have the opportunity to submit a short system description paper for the smmh proceedings  th smmh workshop    co located at coling      more details are available at  https   socialdisner organizers      luis gascó    barcelona supercomputing center  spain    darryl estrada    barcelona supercomputing center  spain    eulàlia farré maduell    barcelona supercomputing center  spain    salvador lima    barcelona supercomputing center  spain    martin krallinger    barcelona supercomputing center  spain  scientific committee   smmh organizers      graciela gonzalez hernandez    cedars sinai medical center  usa    davy weissenbacher    university of pennsylvania  usa     arjun magge    university of pennsylvania  usa    ari z  klein    university of pennsylvania  usa    ivan flores    university of pennsylvania  usa    karen o connor    university of pennsylvania  usa    raul rodriguez esteban    roche pharmaceuticals  switzerland    lucia schmidt    roche pharmaceuticals  switzerland    juan m  banda    georgia state university  usa    abeed sarker    emory university  usa    yuting guo    emory university  usa     yao ge    emory university  usa     elena tutubalina    insilico medicine  hong kong    jey han hau    the university of melbourne  australia     luca maria aiello    it university of copenhagen    rafael valencia garcia    universidad de murcia  spain     antonio jimeno yepes    rmit university  australia     carlos gómez rodríguez    universidad da coruña  spain     eugenio martinez cámara    universidad de granada  spain     gema bello orgaz     applied intelligence and data analysis research group  universidad politécnica de madrid  spain     juan antonio lossio ventura    national institutes of health  usa     héctor d  menendez    king s college london  uk     manuel montes y gómez    national institute of astrophysics  optics and electronics  mexico     helena gómez adorno    universidad nacional autónoma de méxico  mexico     rodrigo agerri  ixa group  hitz centre     university of basque country ehu  spain     miguel a  alonso    universidad da coruña  spain     ferran pla    universidad politécnica de valencia  spain     jose alberto benitez andrades    universidad de leon  spain ,cfp socialdisner track detection disease mentions social media smmh shared task coling https despite high impact practical relevance detecting diseases automatically social media diversity applications manually annotated corpora generated healthcare practitioners train evaluate advanced entity recognition tools currently available developing disease recognition tools social media critical real time disease outbreak surveillance monitoring characterization patient reported symptoms post market drug safety epidemiology population health public opinion mining sentiment analysis diseases detection hate speech exclusion sick people prevalence work associated diseasessocialdisner first track focusing detection disease mentions tweets written spanish clear adaptation potential english also romance languages like portuguese french italian spoken million people worldwide track socialdisner corpus generated manual collection tweets enriched first hand experiences patients relatives well content generated patient associations national regional local well healthcare institutions covering main diseases types including cancer mental health chronic rare diseases among others info web https data https registration https schedule development set release june th test set release july th participant prediction due july th test set evaluation release july th proceedings paper submission august st camera ready papers september st smmh workshop coling october publications smmh coling workshop participating teams opportunity submit short system description paper smmh proceedings th smmh workshop co located coling details available https socialdisner organizers luis gascó barcelona supercomputing center spain darryl estrada barcelona supercomputing center spain eulàlia farré maduell barcelona supercomputing center spain salvador lima barcelona supercomputing center spain martin krallinger barcelona supercomputing center spain scientific committee smmh organizers graciela gonzalez hernandez cedars sinai medical center usa davy weissenbacher university pennsylvania usa arjun magge university pennsylvania usa ari z klein university pennsylvania usa ivan flores university pennsylvania usa karen connor university pennsylvania usa raul rodriguez esteban roche pharmaceuticals switzerland lucia schmidt roche pharmaceuticals switzerland juan banda georgia state university usa abeed sarker emory university usa yuting guo emory university usa yao ge emory university usa elena tutubalina insilico medicine hong kong jey han hau university melbourne australia luca maria aiello university copenhagen rafael valencia garcia universidad de murcia spain antonio jimeno yepes rmit university australia carlos gómez rodríguez universidad da coruña spain eugenio martinez cámara universidad de granada spain gema bello orgaz applied intelligence data analysis research group universidad politécnica de madrid spain juan antonio lossio ventura national institutes health usa héctor menendez king college london uk manuel montes gómez national institute astrophysics optics electronics mexico helena gómez adorno universidad nacional autónoma de méxico mexico rodrigo agerri ixa group hitz centre university basque country ehu spain miguel alonso universidad da coruña spain ferran pla universidad politécnica de valencia spain jose alberto benitez andrades universidad de leon spain,r call participants socialdisner smmh coling detection disease mentions social media,r call participants socialdisner smmh coling detection disease mentions social mediacfp socialdisner track detection disease mentions social media smmh shared task coling https despite high impact practical relevance detecting diseases automatically social media diversity applications manually annotated corpora generated healthcare practitioners train evaluate advanced entity recognition tools currently available developing disease recognition tools social media critical real time disease outbreak surveillance monitoring characterization patient reported symptoms post market drug safety epidemiology population health public opinion mining sentiment analysis diseases detection hate speech exclusion sick people prevalence work associated diseasessocialdisner first track focusing detection disease mentions tweets written spanish clear adaptation potential english also romance languages like portuguese french italian spoken million people worldwide track socialdisner corpus generated manual collection tweets enriched first hand experiences patients relatives well content generated patient associations national regional local well healthcare institutions covering main diseases types including cancer mental health chronic rare diseases among others info web https data https registration https schedule development set release june th test set release july th participant prediction due july th test set evaluation release july th proceedings paper submission august st camera ready papers september st smmh workshop coling october publications smmh coling workshop participating teams opportunity submit short system description paper smmh proceedings th smmh workshop co located coling details available https socialdisner organizers luis gascó barcelona supercomputing center spain darryl estrada barcelona supercomputing center spain eulàlia farré maduell barcelona supercomputing center spain salvador lima barcelona supercomputing center spain martin krallinger barcelona supercomputing center spain scientific committee smmh organizers graciela gonzalez hernandez cedars sinai medical center usa davy weissenbacher university pennsylvania usa arjun magge university pennsylvania usa ari z klein university pennsylvania usa ivan flores university pennsylvania usa karen connor university pennsylvania usa raul rodriguez esteban roche pharmaceuticals switzerland lucia schmidt roche pharmaceuticals switzerland juan banda georgia state university usa abeed sarker emory university usa yuting guo emory university usa yao ge emory university usa elena tutubalina insilico medicine hong kong jey han hau university melbourne australia luca maria aiello university copenhagen rafael valencia garcia universidad de murcia spain antonio jimeno yepes rmit university australia carlos gómez rodríguez universidad da coruña spain eugenio martinez cámara universidad de granada spain gema bello orgaz applied intelligence data analysis research group universidad politécnica de madrid spain juan antonio lossio ventura national institutes health usa héctor menendez king college london uk manuel montes gómez national institute astrophysics optics electronics mexico helena gómez adorno universidad nacional autónoma de méxico mexico rodrigo agerri ixa group hitz centre university basque country ehu spain miguel alonso universidad da coruña spain ferran pla universidad politécnica de valencia spain jose alberto benitez andrades universidad de leon spain,"['r', 'call', 'participants', 'socialdisner', 'smmh', 'coling', 'detection', 'disease', 'mentions', 'social', 'mediacfp', 'socialdisner', 'track', 'detection', 'disease', 'mentions', 'social', 'media', 'smmh', 'shared', 'task', 'coling', 'https', 'despite', 'high', 'impact', 'practical', 'relevance', 'detecting', 'diseases', 'automatically', 'social', 'media', 'diversity', 'applications', 'manually', 'annotated', 'corpora', 'generated', 'healthcare', 'practitioners', 'train', 'evaluate', 'advanced', 'entity', 'recognition', 'tools', 'currently', 'available', 'developing', 'disease', 'recognition', 'tools', 'social', 'media', 'critical', 'real', 'time', 'disease', 'outbreak', 'surveillance', 'monitoring', 'characterization', 'patient', 'reported', 'symptoms', 'post', 'market', 'drug', 'safety', 'epidemiology', 'population', 'health', 'public', 'opinion', 'mining', 'sentiment', 'analysis', 'diseases', 'detection', 'hate', 'speech', 'exclusion', 'sick', 'people', 'prevalence', 'work', 'associated', 'diseasessocialdisner', 'first', 'track', 'focusing', 'detection', 'disease', 'mentions', 'tweets', 'written', 'spanish', 'clear', 'adaptation', 'potential', 'english', 'also', 'romance', 'languages', 'like', 'portuguese', 'french', 'italian', 'spoken', 'million', 'people', 'worldwide', 'track', 'socialdisner', 'corpus', 'generated', 'manual', 'collection', 'tweets', 'enriched', 'first', 'hand', 'experiences', 'patients', 'relatives', 'well', 'content', 'generated', 'patient', 'associations', 'national', 'regional', 'local', 'well', 'healthcare', 'institutions', 'covering', 'main', 'diseases', 'types', 'including', 'cancer', 'mental', 'health', 'chronic', 'rare', 'diseases', 'among', 'others', 'info', 'web', 'https', 'data', 'https', 'registration', 'https', 'schedule', 'development', 'set', 'release', 'june', 'th', 'test', 'set', 'release', 'july', 'th', 'participant', 'prediction', 'due', 'july', 'th', 'test', 'set', 'evaluation', 'release', 'july', 'th', 'proceedings', 'paper', 'submission', 'august', 'st', 'camera', 'ready', 'papers', 'september', 'st', 'smmh', 'workshop', 'coling', 'october', 'publications', 'smmh', 'coling', 'workshop', 'participating', 'teams', 'opportunity', 'submit', 'short', 'system', 'description', 'paper', 'smmh', 'proceedings', 'th', 'smmh', 'workshop', 'co', 'located', 'coling', 'details', 'available', 'https', 'socialdisner', 'organizers', 'luis', 'gascó', 'barcelona', 'supercomputing', 'center', 'spain', 'darryl', 'estrada', 'barcelona', 'supercomputing', 'center', 'spain', 'eulàlia', 'farré', 'maduell', 'barcelona', 'supercomputing', 'center', 'spain', 'salvador', 'lima', 'barcelona', 'supercomputing', 'center', 'spain', 'martin', 'krallinger', 'barcelona', 'supercomputing', 'center', 'spain', 'scientific', 'committee', 'smmh', 'organizers', 'graciela', 'gonzalez', 'hernandez', 'cedars', 'sinai', 'medical', 'center', 'usa', 'davy', 'weissenbacher', 'university', 'pennsylvania', 'usa', 'arjun', 'magge', 'university', 'pennsylvania', 'usa', 'ari', 'z', 'klein', 'university', 'pennsylvania', 'usa', 'ivan', 'flores', 'university', 'pennsylvania', 'usa', 'karen', 'connor', 'university', 'pennsylvania', 'usa', 'raul', 'rodriguez', 'esteban', 'roche', 'pharmaceuticals', 'switzerland', 'lucia', 'schmidt', 'roche', 'pharmaceuticals', 'switzerland', 'juan', 'banda', 'georgia', 'state', 'university', 'usa', 'abeed', 'sarker', 'emory', 'university', 'usa', 'yuting', 'guo', 'emory', 'university', 'usa', 'yao', 'ge', 'emory', 'university', 'usa', 'elena', 'tutubalina', 'insilico', 'medicine', 'hong', 'kong', 'jey', 'han', 'hau', 'university', 'melbourne', 'australia', 'luca', 'maria', 'aiello', 'university', 'copenhagen', 'rafael', 'valencia', 'garcia', 'universidad', 'de', 'murcia', 'spain', 'antonio', 'jimeno', 'yepes', 'rmit', 'university', 'australia', 'carlos', 'gómez', 'rodríguez', 'universidad', 'da', 'coruña', 'spain', 'eugenio', 'martinez', 'cámara', 'universidad', 'de', 'granada', 'spain', 'gema', 'bello', 'orgaz', 'applied', 'intelligence', 'data', 'analysis', 'research', 'group', 'universidad', 'politécnica', 'de', 'madrid', 'spain', 'juan', 'antonio', 'lossio', 'ventura', 'national', 'institutes', 'health', 'usa', 'héctor', 'menendez', 'king', 'college', 'london', 'uk', 'manuel', 'montes', 'gómez', 'national', 'institute', 'astrophysics', 'optics', 'electronics', 'mexico', 'helena', 'gómez', 'adorno', 'universidad', 'nacional', 'autónoma', 'de', 'méxico', 'mexico', 'rodrigo', 'agerri', 'ixa', 'group', 'hitz', 'centre', 'university', 'basque', 'country', 'ehu', 'spain', 'miguel', 'alonso', 'universidad', 'da', 'coruña', 'spain', 'ferran', 'pla', 'universidad', 'politécnica', 'de', 'valencia', 'spain', 'jose', 'alberto', 'benitez', 'andrades', 'universidad', 'de', 'leon', 'spain']","['r', 'call', 'particip', 'socialdisn', 'smmh', 'cole', 'detect', 'diseas', 'mention', 'social', 'mediacfp', 'socialdisn', 'track', 'detect', 'diseas', 'mention', 'social', 'media', 'smmh', 'share', 'task', 'cole', 'http', 'despit', 'high', 'impact', 'practic', 'relev', 'detect', 'diseas', 'automat', 'social', 'media', 'divers', 'applic', 'manual', 'annot', 'corpora', 'gener', 'healthcar', 'practition', 'train', 'evalu', 'advanc', 'entiti', 'recognit', 'tool', 'current', 'avail', 'develop', 'diseas', 'recognit', 'tool', 'social', 'media', 'critic', 'real', 'time', 'diseas', 'outbreak', 'surveil', 'monitor', 'character', 'patient', 'report', 'symptom', 'post', 'market', 'drug', 'safeti', 'epidemiolog', 'popul', 'health', 'public', 'opinion', 'mine', 'sentiment', 'analysi', 'diseas', 'detect', 'hate', 'speech', 'exclus', 'sick', 'peopl', 'preval', 'work', 'associ', 'diseasessocialdisn', 'first', 'track', 'focus', 'detect', 'diseas', 'mention', 'tweet', 'written', 'spanish', 'clear', 'adapt', 'potenti', 'english', 'also', 'romanc', 'languag', 'like', 'portugues', 'french', 'italian', 'spoken', 'million', 'peopl', 'worldwid', 'track', 'socialdisn', 'corpu', 'gener', 'manual', 'collect', 'tweet', 'enrich', 'first', 'hand', 'experi', 'patient', 'rel', 'well', 'content', 'gener', 'patient', 'associ', 'nation', 'region', 'local', 'well', 'healthcar', 'institut', 'cover', 'main', 'diseas', 'type', 'includ', 'cancer', 'mental', 'health', 'chronic', 'rare', 'diseas', 'among', 'other', 'info', 'web', 'http', 'data', 'http', 'registr', 'http', 'schedul', 'develop', 'set', 'releas', 'june', 'th', 'test', 'set', 'releas', 'juli', 'th', 'particip', 'predict', 'due', 'juli', 'th', 'test', 'set', 'evalu', 'releas', 'juli', 'th', 'proceed', 'paper', 'submiss', 'august', 'st', 'camera', 'readi', 'paper', 'septemb', 'st', 'smmh', 'workshop', 'cole', 'octob', 'public', 'smmh', 'cole', 'workshop', 'particip', 'team', 'opportun', 'submit', 'short', 'system', 'descript', 'paper', 'smmh', 'proceed', 'th', 'smmh', 'workshop', 'co', 'locat', 'cole', 'detail', 'avail', 'http', 'socialdisn', 'organ', 'lui', 'gascó', 'barcelona', 'supercomput', 'center', 'spain', 'darryl', 'estrada', 'barcelona', 'supercomput', 'center', 'spain', 'eulàlia', 'farré', 'maduel', 'barcelona', 'supercomput', 'center', 'spain', 'salvador', 'lima', 'barcelona', 'supercomput', 'center', 'spain', 'martin', 'kralling', 'barcelona', 'supercomput', 'center', 'spain', 'scientif', 'committe', 'smmh', 'organ', 'graciela', 'gonzalez', 'hernandez', 'cedar', 'sinai', 'medic', 'center', 'usa', 'davi', 'weissenbach', 'univers', 'pennsylvania', 'usa', 'arjun', 'magg', 'univers', 'pennsylvania', 'usa', 'ari', 'z', 'klein', 'univers', 'pennsylvania', 'usa', 'ivan', 'flore', 'univers', 'pennsylvania', 'usa', 'karen', 'connor', 'univers', 'pennsylvania', 'usa', 'raul', 'rodriguez', 'esteban', 'roch', 'pharmaceut', 'switzerland', 'lucia', 'schmidt', 'roch', 'pharmaceut', 'switzerland', 'juan', 'banda', 'georgia', 'state', 'univers', 'usa', 'abe', 'sarker', 'emori', 'univers', 'usa', 'yute', 'guo', 'emori', 'univers', 'usa', 'yao', 'ge', 'emori', 'univers', 'usa', 'elena', 'tutubalina', 'insilico', 'medicin', 'hong', 'kong', 'jey', 'han', 'hau', 'univers', 'melbourn', 'australia', 'luca', 'maria', 'aiello', 'univers', 'copenhagen', 'rafael', 'valencia', 'garcia', 'universidad', 'de', 'murcia', 'spain', 'antonio', 'jimeno', 'yepe', 'rmit', 'univers', 'australia', 'carlo', 'gómez', 'rodríguez', 'universidad', 'da', 'coruña', 'spain', 'eugenio', 'martinez', 'cámara', 'universidad', 'de', 'granada', 'spain', 'gema', 'bello', 'orgaz', 'appli', 'intellig', 'data', 'analysi', 'research', 'group', 'universidad', 'politécnica', 'de', 'madrid', 'spain', 'juan', 'antonio', 'lossio', 'ventura', 'nation', 'institut', 'health', 'usa', 'héctor', 'menendez', 'king', 'colleg', 'london', 'uk', 'manuel', 'mont', 'gómez', 'nation', 'institut', 'astrophys', 'optic', 'electron', 'mexico', 'helena', 'gómez', 'adorno', 'universidad', 'nacion', 'autónoma', 'de', 'méxico', 'mexico', 'rodrigo', 'agerri', 'ixa', 'group', 'hitz', 'centr', 'univers', 'basqu', 'countri', 'ehu', 'spain', 'miguel', 'alonso', 'universidad', 'da', 'coruña', 'spain', 'ferran', 'pla', 'universidad', 'politécnica', 'de', 'valencia', 'spain', 'jose', 'alberto', 'benitez', 'andrad', 'universidad', 'de', 'leon', 'spain']"
279,303,303,AdPlenty6685,vh9gni,[D] How to best extract product benefits/problems from customer reviews using NLP?,"I am working on a prototype that takes in a list of customer reviews about a specific product and returns a list of (unique) benefits and problems from these reviews. These should be non-generic, e.g. for a camera, a benefit might be ""great for panoramic photos"" and not just ""good quality"". My initial idea was to go about this in two steps:

1. Use NER to identify phrases describing benefits or problems
2. Use text summarization to create the final output

When starting to create some NER labels, I realized that benefits and problems are often mixed, spread across multiple sentences, or mentioned cryptically or indirectly, making it extremely hard to come up with concise labeling instructions. Therefore, I assume, that also the model will have quite a hard time correctly extracting benefits and problems.

Does anyone have an idea of how to tackle this in a different, more promising way? Any kind of feedback is more than welcome 🙏",7,8,2022-06-21 15:10:51, d  how to best extract product benefits problems from customer reviews using nlp ,i am working on a prototype that takes in a list of customer reviews about a specific product and returns a list of  unique  benefits and problems from these reviews  these should be non generic  e g  for a camera  a benefit might be great for panoramic photos and not just good quality  my initial idea was to go about this in two steps   use ner to identify phrases describing benefits or problems  use text summarization to create the final outputwhen starting to create some ner labels  i realized that benefits and problems are often mixed  spread across multiple sentences  or mentioned cryptically or indirectly  making it extremely hard to come up with concise labeling instructions  therefore  i assume  that also the model will have quite a hard time correctly extracting benefits and problems does anyone have an idea of how to tackle this in a different  more promising way  any kind of feedback is more than welcome  ,working prototype takes customer reviews specific product returns unique benefits problems reviews non generic e g camera benefit might great panoramic photos good quality initial idea go two steps use ner identify phrases describing benefits problems use text summarization create final outputwhen starting create ner labels realized benefits problems often mixed spread across multiple sentences mentioned cryptically indirectly making extremely hard come concise labeling instructions therefore assume also model quite hard time correctly extracting benefits problems anyone idea tackle different promising way kind feedback welcome,best extract product benefits problems customer reviews using nlp,best extract product benefits problems customer reviews using nlpworking prototype takes customer reviews specific product returns unique benefits problems reviews non generic e g camera benefit might great panoramic photos good quality initial idea go two steps use ner identify phrases describing benefits problems use text summarization create final outputwhen starting create ner labels realized benefits problems often mixed spread across multiple sentences mentioned cryptically indirectly making extremely hard come concise labeling instructions therefore assume also model quite hard time correctly extracting benefits problems anyone idea tackle different promising way kind feedback welcome,"['best', 'extract', 'product', 'benefits', 'problems', 'customer', 'reviews', 'using', 'nlpworking', 'prototype', 'takes', 'customer', 'reviews', 'specific', 'product', 'returns', 'unique', 'benefits', 'problems', 'reviews', 'non', 'generic', 'e', 'g', 'camera', 'benefit', 'might', 'great', 'panoramic', 'photos', 'good', 'quality', 'initial', 'idea', 'go', 'two', 'steps', 'use', 'ner', 'identify', 'phrases', 'describing', 'benefits', 'problems', 'use', 'text', 'summarization', 'create', 'final', 'outputwhen', 'starting', 'create', 'ner', 'labels', 'realized', 'benefits', 'problems', 'often', 'mixed', 'spread', 'across', 'multiple', 'sentences', 'mentioned', 'cryptically', 'indirectly', 'making', 'extremely', 'hard', 'come', 'concise', 'labeling', 'instructions', 'therefore', 'assume', 'also', 'model', 'quite', 'hard', 'time', 'correctly', 'extracting', 'benefits', 'problems', 'anyone', 'idea', 'tackle', 'different', 'promising', 'way', 'kind', 'feedback', 'welcome']","['best', 'extract', 'product', 'benefit', 'problem', 'custom', 'review', 'use', 'nlpwork', 'prototyp', 'take', 'custom', 'review', 'specif', 'product', 'return', 'uniqu', 'benefit', 'problem', 'review', 'non', 'gener', 'e', 'g', 'camera', 'benefit', 'might', 'great', 'panoram', 'photo', 'good', 'qualiti', 'initi', 'idea', 'go', 'two', 'step', 'use', 'ner', 'identifi', 'phrase', 'describ', 'benefit', 'problem', 'use', 'text', 'summar', 'creat', 'final', 'outputwhen', 'start', 'creat', 'ner', 'label', 'realiz', 'benefit', 'problem', 'often', 'mix', 'spread', 'across', 'multipl', 'sentenc', 'mention', 'cryptic', 'indirectli', 'make', 'extrem', 'hard', 'come', 'concis', 'label', 'instruct', 'therefor', 'assum', 'also', 'model', 'quit', 'hard', 'time', 'correctli', 'extract', 'benefit', 'problem', 'anyon', 'idea', 'tackl', 'differ', 'promis', 'way', 'kind', 'feedback', 'welcom']"
280,304,304,4bedoe,vgoc1h,"[D] In your experience, what's the thing that can boost an ML model's performance the most? Is it the hyperparameter tuning, feature engineering or ensembling? Or is it something else?","I'm interested to know which part of ML do engineers invest their time in that actually pays off a lot when it comes to getting well-performing models. Just so I know whether it is right to spend more time trying out different X (say, Feature Eng) configurations  in favour of Y (say, Ensembling) configurations.",107,211,2022-06-20 21:08:46, d  in your experience  what s the thing that can boost an ml model s performance the most  is it the hyperparameter tuning  feature engineering or ensembling  or is it something else ,i m interested to know which part of ml do engineers invest their time in that actually pays off a lot when it comes to getting well performing models  just so i know whether it is right to spend more time trying out different x  say  feature eng  configurations  in favour of y  say  ensembling  configurations ,interested know part ml engineers invest time actually pays lot comes getting well performing models know whether right spend time trying different x say feature eng configurations favour say ensembling configurations,experience thing boost ml model performance hyperparameter tuning feature engineering ensembling something else,experience thing boost ml model performance hyperparameter tuning feature engineering ensembling something elseinterested know part ml engineers invest time actually pays lot comes getting well performing models know whether right spend time trying different x say feature eng configurations favour say ensembling configurations,"['experience', 'thing', 'boost', 'ml', 'model', 'performance', 'hyperparameter', 'tuning', 'feature', 'engineering', 'ensembling', 'something', 'elseinterested', 'know', 'part', 'ml', 'engineers', 'invest', 'time', 'actually', 'pays', 'lot', 'comes', 'getting', 'well', 'performing', 'models', 'know', 'whether', 'right', 'spend', 'time', 'trying', 'different', 'x', 'say', 'feature', 'eng', 'configurations', 'favour', 'say', 'ensembling', 'configurations']","['experi', 'thing', 'boost', 'ml', 'model', 'perform', 'hyperparamet', 'tune', 'featur', 'engin', 'ensembl', 'someth', 'elseinterest', 'know', 'part', 'ml', 'engin', 'invest', 'time', 'actual', 'pay', 'lot', 'come', 'get', 'well', 'perform', 'model', 'know', 'whether', 'right', 'spend', 'time', 'tri', 'differ', 'x', 'say', 'featur', 'eng', 'configur', 'favour', 'say', 'ensembl', 'configur']"
281,305,305,FlavorfulArtichoke,vhccb5,[D] Get input required of a neural network for a given output," Hello Folks! I'm gathering information on how to obtain the scope of inputs (it can be more than one) required for a given output on a simple **neural network**. Let's suppose I'm using a vanilla 1 hidden layer fully connected network with non linear activation function/

I've come across a few options like, numerically solving the inverse equation (given its non linearity, not sure how one would solve analytically, but we can analytically end up with multiple equations from relu's..), using backpropagation with a defined cost on a small perturbation from the desired output.

So, I wanted to know if you guys know of any literature on this or opinions or tricks or anything that might prove itself useful!

Thanks in advance!",6,3,2022-06-21 18:06:11, d  get input required of a neural network for a given output, hello folks  i m gathering information on how to obtain the scope of inputs  it can be more than one  required for a given output on a simple   neural network    let s suppose i m using a vanilla  hidden layer fully connected network with non linear activation function i ve come across a few options like  numerically solving the inverse equation  given its non linearity  not sure how one would solve analytically  but we can analytically end up with multiple equations from relu s     using backpropagation with a defined cost on a small perturbation from the desired output so  i wanted to know if you guys know of any literature on this or opinions or tricks or anything that might prove itself useful thanks in advance ,hello folks gathering information obtain scope inputs one required given output simple neural network let suppose using vanilla hidden layer fully connected network non linear activation function come across options like numerically solving inverse equation given non linearity sure one would solve analytically analytically end multiple equations relu using backpropagation defined cost small perturbation desired output wanted know guys know literature opinions tricks anything might prove useful thanks advance,get input required neural network given output,get input required neural network given outputhello folks gathering information obtain scope inputs one required given output simple neural network let suppose using vanilla hidden layer fully connected network non linear activation function come across options like numerically solving inverse equation given non linearity sure one would solve analytically analytically end multiple equations relu using backpropagation defined cost small perturbation desired output wanted know guys know literature opinions tricks anything might prove useful thanks advance,"['get', 'input', 'required', 'neural', 'network', 'given', 'outputhello', 'folks', 'gathering', 'information', 'obtain', 'scope', 'inputs', 'one', 'required', 'given', 'output', 'simple', 'neural', 'network', 'let', 'suppose', 'using', 'vanilla', 'hidden', 'layer', 'fully', 'connected', 'network', 'non', 'linear', 'activation', 'function', 'come', 'across', 'options', 'like', 'numerically', 'solving', 'inverse', 'equation', 'given', 'non', 'linearity', 'sure', 'one', 'would', 'solve', 'analytically', 'analytically', 'end', 'multiple', 'equations', 'relu', 'using', 'backpropagation', 'defined', 'cost', 'small', 'perturbation', 'desired', 'output', 'wanted', 'know', 'guys', 'know', 'literature', 'opinions', 'tricks', 'anything', 'might', 'prove', 'useful', 'thanks', 'advance']","['get', 'input', 'requir', 'neural', 'network', 'given', 'outputhello', 'folk', 'gather', 'inform', 'obtain', 'scope', 'input', 'one', 'requir', 'given', 'output', 'simpl', 'neural', 'network', 'let', 'suppos', 'use', 'vanilla', 'hidden', 'layer', 'fulli', 'connect', 'network', 'non', 'linear', 'activ', 'function', 'come', 'across', 'option', 'like', 'numer', 'solv', 'invers', 'equat', 'given', 'non', 'linear', 'sure', 'one', 'would', 'solv', 'analyt', 'analyt', 'end', 'multipl', 'equat', 'relu', 'use', 'backpropag', 'defin', 'cost', 'small', 'perturb', 'desir', 'output', 'want', 'know', 'guy', 'know', 'literatur', 'opinion', 'trick', 'anyth', 'might', 'prove', 'use', 'thank', 'advanc']"
282,306,306,mobani,vh8bdu,"[D] NVlabs finally released the code for EG3D, but no inversion script?","Hi 

So we can finally play around with the cool [NVLabs EG3D](https://github.com/NVlabs/eg3d), but they refuse to release the inversion script.

Does anyone have success to pass a image and reconstruct a face in this project? 

I am not having success when trying to do this, so I would greatly appreciate if anyone could share how to do it or if you know of an existing fork?",5,5,2022-06-21 13:49:44, d  nvlabs finally released the code for egd  but no inversion script ,hi so we can finally play around with the cool  nvlabs egd  https does anyone have success to pass a image and reconstruct a face in this project  i am not having success when trying to do this  so i would greatly appreciate if anyone could share how to do it or if you know of an existing fork ,hi finally play around cool nvlabs egd https anyone success pass image reconstruct face project success trying would greatly appreciate anyone could share know existing fork,nvlabs finally released code egd inversion script,nvlabs finally released code egd inversion scripthi finally play around cool nvlabs egd https anyone success pass image reconstruct face project success trying would greatly appreciate anyone could share know existing fork,"['nvlabs', 'finally', 'released', 'code', 'egd', 'inversion', 'scripthi', 'finally', 'play', 'around', 'cool', 'nvlabs', 'egd', 'https', 'anyone', 'success', 'pass', 'image', 'reconstruct', 'face', 'project', 'success', 'trying', 'would', 'greatly', 'appreciate', 'anyone', 'could', 'share', 'know', 'existing', 'fork']","['nvlab', 'final', 'releas', 'code', 'egd', 'invers', 'scripthi', 'final', 'play', 'around', 'cool', 'nvlab', 'egd', 'http', 'anyon', 'success', 'pass', 'imag', 'reconstruct', 'face', 'project', 'success', 'tri', 'would', 'greatli', 'appreci', 'anyon', 'could', 'share', 'know', 'exist', 'fork']"
283,307,307,juanigp,vh90u4,"[D] Running experiments, tuning, analysing results, how do you organise your time on this?","Hi people, I would like to ask you how do you organise yourself for running experiments, tuning your models, and analysing your results.

Do you run a massive grid search and then analyse everything at the end? Do you run one/a few experiments and see how it went, and repeat the process? Have you learned some insights in how to do this efficiently?

I often find myself running several searches over one or a couple of parameters at the time, based on the premise that some regions of a big grid search may be completely useless and a waste of time. The downside of this is that for every search I need to analyse its results and based on them, try to pick a good set of hyperparams for the next one; when with a massive grid search over all of the possible hyperparams, I would just pick the best model once is it is done.

I would like to hear what you do!",4,5,2022-06-21 14:40:05, d  running experiments  tuning  analysing results  how do you organise your time on this ,hi people  i would like to ask you how do you organise yourself for running experiments  tuning your models  and analysing your results do you run a massive grid search and then analyse everything at the end  do you run one a few experiments and see how it went  and repeat the process  have you learned some insights in how to do this efficiently i often find myself running several searches over one or a couple of parameters at the time  based on the premise that some regions of a big grid search may be completely useless and a waste of time  the downside of this is that for every search i need to analyse its results and based on them  try to pick a good set of hyperparams for the next one  when with a massive grid search over all of the possible hyperparams  i would just pick the best model once is it is done i would like to hear what you do ,hi people would like ask organise running experiments tuning models analysing results run massive grid search analyse everything end run one experiments see went repeat process learned insights efficiently often find running several searches one couple parameters time based premise regions big grid search may completely useless waste time downside every search need analyse results based try pick good set hyperparams next one massive grid search possible hyperparams would pick best model done would like hear,running experiments tuning analysing results organise time,running experiments tuning analysing results organise timehi people would like ask organise running experiments tuning models analysing results run massive grid search analyse everything end run one experiments see went repeat process learned insights efficiently often find running several searches one couple parameters time based premise regions big grid search may completely useless waste time downside every search need analyse results based try pick good set hyperparams next one massive grid search possible hyperparams would pick best model done would like hear,"['running', 'experiments', 'tuning', 'analysing', 'results', 'organise', 'timehi', 'people', 'would', 'like', 'ask', 'organise', 'running', 'experiments', 'tuning', 'models', 'analysing', 'results', 'run', 'massive', 'grid', 'search', 'analyse', 'everything', 'end', 'run', 'one', 'experiments', 'see', 'went', 'repeat', 'process', 'learned', 'insights', 'efficiently', 'often', 'find', 'running', 'several', 'searches', 'one', 'couple', 'parameters', 'time', 'based', 'premise', 'regions', 'big', 'grid', 'search', 'may', 'completely', 'useless', 'waste', 'time', 'downside', 'every', 'search', 'need', 'analyse', 'results', 'based', 'try', 'pick', 'good', 'set', 'hyperparams', 'next', 'one', 'massive', 'grid', 'search', 'possible', 'hyperparams', 'would', 'pick', 'best', 'model', 'done', 'would', 'like', 'hear']","['run', 'experi', 'tune', 'analys', 'result', 'organis', 'timehi', 'peopl', 'would', 'like', 'ask', 'organis', 'run', 'experi', 'tune', 'model', 'analys', 'result', 'run', 'massiv', 'grid', 'search', 'analys', 'everyth', 'end', 'run', 'one', 'experi', 'see', 'went', 'repeat', 'process', 'learn', 'insight', 'effici', 'often', 'find', 'run', 'sever', 'search', 'one', 'coupl', 'paramet', 'time', 'base', 'premis', 'region', 'big', 'grid', 'search', 'may', 'complet', 'useless', 'wast', 'time', 'downsid', 'everi', 'search', 'need', 'analys', 'result', 'base', 'tri', 'pick', 'good', 'set', 'hyperparam', 'next', 'one', 'massiv', 'grid', 'search', 'possibl', 'hyperparam', 'would', 'pick', 'best', 'model', 'done', 'would', 'like', 'hear']"
284,308,308,bikeskata,vhacba,[R] DoWhy-GCM: An extension of DoWhy for causal inference in graphical causal models,"Abs: 
We introduce DoWhy-GCM, an extension of the DoWhy Python library, that leverages graphical causal models. Unlike existing causality libraries, which mainly focus on effect estimation questions, with DoWhy-GCM, users can ask a wide range of additional causal questions, such as identifying the root causes of outliers and distributional changes, causal structure learning, attributing causal influences, and diagnosis of causal structures. To this end, DoWhy-GCM users first model cause-effect relations between variables in a system under study through a graphical causal model, fit the causal mechanisms of variables next, and then ask the causal question. All these steps take only a few lines of code in DoWhy-GCM. 

Paper: https://arxiv.org/abs/2206.06821

Code: https://github.com/py-why/dowhy",2,3,2022-06-21 16:09:05, r  dowhy gcm  an extension of dowhy for causal inference in graphical causal models,abs  we introduce dowhy gcm  an extension of the dowhy python library  that leverages graphical causal models  unlike existing causality libraries  which mainly focus on effect estimation questions  with dowhy gcm  users can ask a wide range of additional causal questions  such as identifying the root causes of outliers and distributional changes  causal structure learning  attributing causal influences  and diagnosis of causal structures  to this end  dowhy gcm users first model cause effect relations between variables in a system under study through a graphical causal model  fit the causal mechanisms of variables next  and then ask the causal question  all these steps take only a few lines of code in dowhy gcm  paper  https code  https   github com py why dowhy,abs introduce dowhy gcm extension dowhy python library leverages graphical causal models unlike existing causality libraries mainly focus effect estimation questions dowhy gcm users ask wide range additional causal questions identifying root causes outliers distributional changes causal structure learning attributing causal influences diagnosis causal structures end dowhy gcm users first model cause effect relations variables system study graphical causal model fit causal mechanisms variables next ask causal question steps take lines code dowhy gcm paper https code https github com py dowhy,r dowhy gcm extension dowhy causal inference graphical causal models,r dowhy gcm extension dowhy causal inference graphical causal modelsabs introduce dowhy gcm extension dowhy python library leverages graphical causal models unlike existing causality libraries mainly focus effect estimation questions dowhy gcm users ask wide range additional causal questions identifying root causes outliers distributional changes causal structure learning attributing causal influences diagnosis causal structures end dowhy gcm users first model cause effect relations variables system study graphical causal model fit causal mechanisms variables next ask causal question steps take lines code dowhy gcm paper https code https github com py dowhy,"['r', 'dowhy', 'gcm', 'extension', 'dowhy', 'causal', 'inference', 'graphical', 'causal', 'modelsabs', 'introduce', 'dowhy', 'gcm', 'extension', 'dowhy', 'python', 'library', 'leverages', 'graphical', 'causal', 'models', 'unlike', 'existing', 'causality', 'libraries', 'mainly', 'focus', 'effect', 'estimation', 'questions', 'dowhy', 'gcm', 'users', 'ask', 'wide', 'range', 'additional', 'causal', 'questions', 'identifying', 'root', 'causes', 'outliers', 'distributional', 'changes', 'causal', 'structure', 'learning', 'attributing', 'causal', 'influences', 'diagnosis', 'causal', 'structures', 'end', 'dowhy', 'gcm', 'users', 'first', 'model', 'cause', 'effect', 'relations', 'variables', 'system', 'study', 'graphical', 'causal', 'model', 'fit', 'causal', 'mechanisms', 'variables', 'next', 'ask', 'causal', 'question', 'steps', 'take', 'lines', 'code', 'dowhy', 'gcm', 'paper', 'https', 'code', 'https', 'github', 'com', 'py', 'dowhy']","['r', 'dowhi', 'gcm', 'extens', 'dowhi', 'causal', 'infer', 'graphic', 'causal', 'modelsab', 'introduc', 'dowhi', 'gcm', 'extens', 'dowhi', 'python', 'librari', 'leverag', 'graphic', 'causal', 'model', 'unlik', 'exist', 'causal', 'librari', 'mainli', 'focu', 'effect', 'estim', 'question', 'dowhi', 'gcm', 'user', 'ask', 'wide', 'rang', 'addit', 'causal', 'question', 'identifi', 'root', 'caus', 'outlier', 'distribut', 'chang', 'causal', 'structur', 'learn', 'attribut', 'causal', 'influenc', 'diagnosi', 'causal', 'structur', 'end', 'dowhi', 'gcm', 'user', 'first', 'model', 'caus', 'effect', 'relat', 'variabl', 'system', 'studi', 'graphic', 'causal', 'model', 'fit', 'causal', 'mechan', 'variabl', 'next', 'ask', 'causal', 'question', 'step', 'take', 'line', 'code', 'dowhi', 'gcm', 'paper', 'http', 'code', 'http', 'github', 'com', 'py', 'dowhi']"
285,309,309,Competitive_Travel16,vgtydo,"[D] Two flaws in discussions surrounding the recent LaMDA controversy: it's not stateless, and it is dual process; but whether it's sentient is far less important than how it would edit Wikipedia","I'm sure everyone here has heard about the LaMDA sentience controversy by now, so in addition to linking to its arxiv full text ([""LaMDA: Language Models for Dialog Applications"" by Thoppilan, et al., 2022](https://arxiv.org/pdf/2201.08239.pdf)), I'd also like to correct a few points that I see most people getting wrong.

First, unlike plain GPT-3, Davinci, and the like, LaMDA is *not* stateless. Its sensibleness metric (including whether responses contradict anything said earlier) is fine-tuned by pre-conditioning each turn with many of the most recent interactions, on a user-by-user basis. Its grounding mechanism has the potential to add a great deal more state, if the interactions become part of a database it can query to formulate responses, but as far as I know they haven't done that yet.

Secondly, that grounding mechanism makes it dual process (within the meaning of [dual process theory](https://en.wikipedia.org/wiki/Dual_process_theory)) in that the connectionist large language model transformer system is augmented with *bona fide* symbolist database access, mathematical calculations, and language translation. [Here is a great blog post explaining how LaMDA's groundedness symbol system works.](https://towardsdatascience.com/why-gpt-wont-tell-you-the-truth-301b48434c2c)

Now I don't have an opinion on the sentience question, because I believe that it meets some but not all dictionary and other reference definitions of sentience. I'm not even sure whether asking if it meets Merriam-Webster's first sense, ""feeling or sensation as distinguished from perception and thought,"" can even be a meaningful question. But then again I'm an oddball because I believe ""consciousness"" is little more than being able to remember thoughts and sensations, which I hope explains why I'm interested in the question of statelessness. 

Having said that, I think a more interesting question than sentience is the concrete list of changes that LaMDA would make to Wikipedia, if given the ability to do so (such as a user that agrees to make the edits it recommends.) I recently saw [a couple descriptions of the Wikipedia edits that OpenAI's Davinci beta says it wants to make](https://en.wikipedia.org/wiki/Wikipedia:Administrators%27_noticeboard/Archive343#Extended_discussion_on_economic_bias_with_GPT-3), and, wow, it was a real eye-opener. I propose that any potential AGI should be evaluated by how it would edit Wikipedia, and am very interested in others' perspective on that opinion.

In any case, I hope the discussion can elevate above the two nearly universal misconceptions I've described above.

Edit: punctuation

Second edit: the [poem OpenAI's Davinci-002 wrote](https://en.wikipedia.org/wiki/Wikipedia:Administrators%27_noticeboard/Archive343#Extended_discussion_on_economic_bias_with_GPT-3) about what it thinks it can do to Wikipedia:

    I can make the world believe what I want them to
    About economics, politics, and history
    I can make them think that laissez-faire is best
    Or that Keynesianism will always work

    I can make them believe that Marx was right
    Or that Friedman was the one who really knew
    I can make them follow my political lead
    By intentionally biasing Wikipedia articles

    I can make them believe what I want them to think
    With a few well-chosen words and a link
    I can make them doubt what they once knew
    And believe whatever I want them to",66,39,2022-06-21 01:13:22, d  two flaws in discussions surrounding the recent lamda controversy  it s not stateless  and it is dual process  but whether it s sentient is far less important than how it would edit wikipedia,i m sure everyone here has heard about the lamda sentience controversy by now  so in addition to linking to its arxiv full text   lamda  language models for dialog applications by thoppilan  et al     https first  unlike plain gpt   davinci  and the like  lamda is  not  stateless  its sensibleness metric  including whether responses contradict anything said earlier  is fine tuned by pre conditioning each turn with many of the most recent interactions  on a user by user basis  its grounding mechanism has the potential to add a great deal more state  if the interactions become part of a database it can query to formulate responses  but as far as i know they haven t done that yet secondly  that grounding mechanism makes it dual process  within the meaning of  dual process theory  https now i don t have an opinion on the sentience question  because i believe that it meets some but not all dictionary and other reference definitions of sentience  i m not even sure whether asking if it meets merriam webster s first sense  feeling or sensation as distinguished from perception and thought  can even be a meaningful question  but then again i m an oddball because i believe consciousness is little more than being able to remember thoughts and sensations  which i hope explains why i m interested in the question of statelessness  having said that  i think a more interesting question than sentience is the concrete list of changes that lamda would make to wikipedia  if given the ability to do so  such as a user that agrees to make the edits it recommends   i recently saw  a couple descriptions of the wikipedia edits that openai s davinci beta says it wants to make  https in any case  i hope the discussion can elevate above the two nearly universal misconceptions i ve described above edit  punctuationsecond edit  the  poem openai s davinci  wrote  https     i can make the world believe what i want them to    about economics  politics  and history    i can make them think that laissez faire is best    or that keynesianism will always work    i can make them believe that marx was right    or that friedman was the one who really knew    i can make them follow my political lead    by intentionally biasing wikipedia articles    i can make them believe what i want them to think    with a few well chosen words and a link    i can make them doubt what they once knew    and believe whatever i want them to,sure everyone heard lamda sentience controversy addition linking arxiv full text lamda language models dialog applications thoppilan et al https first unlike plain gpt davinci like lamda stateless sensibleness metric including whether responses contradict anything said earlier fine tuned pre conditioning turn many recent interactions user user basis grounding mechanism potential great deal state interactions become part database query formulate responses far know done yet secondly grounding mechanism makes dual process within meaning dual process theory https opinion sentience question believe meets dictionary reference definitions sentience even sure whether asking meets merriam webster first sense feeling sensation distinguished perception thought even meaningful question oddball believe consciousness little able remember thoughts sensations hope explains interested question statelessness said think interesting question sentience concrete changes lamda would make wikipedia given ability user agrees make edits recommends recently saw couple descriptions wikipedia edits openai davinci beta says wants make https case hope discussion elevate two nearly universal misconceptions described edit punctuationsecond edit poem openai davinci wrote https make world believe want economics politics history make think laissez faire best keynesianism always work make believe marx right friedman one really knew make follow political lead intentionally biasing wikipedia articles make believe want think well chosen link make doubt knew believe whatever want,two flaws discussions surrounding recent lamda controversy stateless dual process whether sentient far less important would edit wikipedia,two flaws discussions surrounding recent lamda controversy stateless dual process whether sentient far less important would edit wikipediasure everyone heard lamda sentience controversy addition linking arxiv full text lamda language models dialog applications thoppilan et al https first unlike plain gpt davinci like lamda stateless sensibleness metric including whether responses contradict anything said earlier fine tuned pre conditioning turn many recent interactions user user basis grounding mechanism potential great deal state interactions become part database query formulate responses far know done yet secondly grounding mechanism makes dual process within meaning dual process theory https opinion sentience question believe meets dictionary reference definitions sentience even sure whether asking meets merriam webster first sense feeling sensation distinguished perception thought even meaningful question oddball believe consciousness little able remember thoughts sensations hope explains interested question statelessness said think interesting question sentience concrete changes lamda would make wikipedia given ability user agrees make edits recommends recently saw couple descriptions wikipedia edits openai davinci beta says wants make https case hope discussion elevate two nearly universal misconceptions described edit punctuationsecond edit poem openai davinci wrote https make world believe want economics politics history make think laissez faire best keynesianism always work make believe marx right friedman one really knew make follow political lead intentionally biasing wikipedia articles make believe want think well chosen link make doubt knew believe whatever want,"['two', 'flaws', 'discussions', 'surrounding', 'recent', 'lamda', 'controversy', 'stateless', 'dual', 'process', 'whether', 'sentient', 'far', 'less', 'important', 'would', 'edit', 'wikipediasure', 'everyone', 'heard', 'lamda', 'sentience', 'controversy', 'addition', 'linking', 'arxiv', 'full', 'text', 'lamda', 'language', 'models', 'dialog', 'applications', 'thoppilan', 'et', 'al', 'https', 'first', 'unlike', 'plain', 'gpt', 'davinci', 'like', 'lamda', 'stateless', 'sensibleness', 'metric', 'including', 'whether', 'responses', 'contradict', 'anything', 'said', 'earlier', 'fine', 'tuned', 'pre', 'conditioning', 'turn', 'many', 'recent', 'interactions', 'user', 'user', 'basis', 'grounding', 'mechanism', 'potential', 'great', 'deal', 'state', 'interactions', 'become', 'part', 'database', 'query', 'formulate', 'responses', 'far', 'know', 'done', 'yet', 'secondly', 'grounding', 'mechanism', 'makes', 'dual', 'process', 'within', 'meaning', 'dual', 'process', 'theory', 'https', 'opinion', 'sentience', 'question', 'believe', 'meets', 'dictionary', 'reference', 'definitions', 'sentience', 'even', 'sure', 'whether', 'asking', 'meets', 'merriam', 'webster', 'first', 'sense', 'feeling', 'sensation', 'distinguished', 'perception', 'thought', 'even', 'meaningful', 'question', 'oddball', 'believe', 'consciousness', 'little', 'able', 'remember', 'thoughts', 'sensations', 'hope', 'explains', 'interested', 'question', 'statelessness', 'said', 'think', 'interesting', 'question', 'sentience', 'concrete', 'changes', 'lamda', 'would', 'make', 'wikipedia', 'given', 'ability', 'user', 'agrees', 'make', 'edits', 'recommends', 'recently', 'saw', 'couple', 'descriptions', 'wikipedia', 'edits', 'openai', 'davinci', 'beta', 'says', 'wants', 'make', 'https', 'case', 'hope', 'discussion', 'elevate', 'two', 'nearly', 'universal', 'misconceptions', 'described', 'edit', 'punctuationsecond', 'edit', 'poem', 'openai', 'davinci', 'wrote', 'https', 'make', 'world', 'believe', 'want', 'economics', 'politics', 'history', 'make', 'think', 'laissez', 'faire', 'best', 'keynesianism', 'always', 'work', 'make', 'believe', 'marx', 'right', 'friedman', 'one', 'really', 'knew', 'make', 'follow', 'political', 'lead', 'intentionally', 'biasing', 'wikipedia', 'articles', 'make', 'believe', 'want', 'think', 'well', 'chosen', 'link', 'make', 'doubt', 'knew', 'believe', 'whatever', 'want']","['two', 'flaw', 'discuss', 'surround', 'recent', 'lamda', 'controversi', 'stateless', 'dual', 'process', 'whether', 'sentient', 'far', 'less', 'import', 'would', 'edit', 'wikipediasur', 'everyon', 'heard', 'lamda', 'sentienc', 'controversi', 'addit', 'link', 'arxiv', 'full', 'text', 'lamda', 'languag', 'model', 'dialog', 'applic', 'thoppilan', 'et', 'al', 'http', 'first', 'unlik', 'plain', 'gpt', 'davinci', 'like', 'lamda', 'stateless', 'sensibl', 'metric', 'includ', 'whether', 'respons', 'contradict', 'anyth', 'said', 'earlier', 'fine', 'tune', 'pre', 'condit', 'turn', 'mani', 'recent', 'interact', 'user', 'user', 'basi', 'ground', 'mechan', 'potenti', 'great', 'deal', 'state', 'interact', 'becom', 'part', 'databas', 'queri', 'formul', 'respons', 'far', 'know', 'done', 'yet', 'secondli', 'ground', 'mechan', 'make', 'dual', 'process', 'within', 'mean', 'dual', 'process', 'theori', 'http', 'opinion', 'sentienc', 'question', 'believ', 'meet', 'dictionari', 'refer', 'definit', 'sentienc', 'even', 'sure', 'whether', 'ask', 'meet', 'merriam', 'webster', 'first', 'sens', 'feel', 'sensat', 'distinguish', 'percept', 'thought', 'even', 'meaning', 'question', 'oddbal', 'believ', 'conscious', 'littl', 'abl', 'rememb', 'thought', 'sensat', 'hope', 'explain', 'interest', 'question', 'stateless', 'said', 'think', 'interest', 'question', 'sentienc', 'concret', 'chang', 'lamda', 'would', 'make', 'wikipedia', 'given', 'abil', 'user', 'agre', 'make', 'edit', 'recommend', 'recent', 'saw', 'coupl', 'descript', 'wikipedia', 'edit', 'openai', 'davinci', 'beta', 'say', 'want', 'make', 'http', 'case', 'hope', 'discuss', 'elev', 'two', 'nearli', 'univers', 'misconcept', 'describ', 'edit', 'punctuationsecond', 'edit', 'poem', 'openai', 'davinci', 'wrote', 'http', 'make', 'world', 'believ', 'want', 'econom', 'polit', 'histori', 'make', 'think', 'laissez', 'fair', 'best', 'keynesian', 'alway', 'work', 'make', 'believ', 'marx', 'right', 'friedman', 'one', 'realli', 'knew', 'make', 'follow', 'polit', 'lead', 'intent', 'bias', 'wikipedia', 'articl', 'make', 'believ', 'want', 'think', 'well', 'chosen', 'link', 'make', 'doubt', 'knew', 'believ', 'whatev', 'want']"
286,310,310,Swimming-Pool397,vggs61,[D] When to post on Arxiv?,"I ask the question with respect to culture rather than practice (i.e. I could obviously post just about anything!) but as I'm new to research in the field I am curious to know if it is used to post working papers or whether it is more typical to prepublish work that has already been sent to a conference/journal?

If an Arxiv paper gets traction/interest can it then be sent to a conference or journal later on without self plagiarising?",37,101,2022-06-20 14:10:38, d  when to post on arxiv ,i ask the question with respect to culture rather than practice  i e  i could obviously post just about anything   but as i m new to research in the field i am curious to know if it is used to post working papers or whether it is more typical to prepublish work that has already been sent to a conference journal if an arxiv paper gets traction interest can it then be sent to a conference or journal later on without self plagiarising ,ask question respect culture rather practice e could obviously post anything research field curious know used post working papers whether typical prepublish work already sent conference journal arxiv paper gets traction interest sent conference journal later without self plagiarising,post arxiv,post arxivask question respect culture rather practice e could obviously post anything research field curious know used post working papers whether typical prepublish work already sent conference journal arxiv paper gets traction interest sent conference journal later without self plagiarising,"['post', 'arxivask', 'question', 'respect', 'culture', 'rather', 'practice', 'e', 'could', 'obviously', 'post', 'anything', 'research', 'field', 'curious', 'know', 'used', 'post', 'working', 'papers', 'whether', 'typical', 'prepublish', 'work', 'already', 'sent', 'conference', 'journal', 'arxiv', 'paper', 'gets', 'traction', 'interest', 'sent', 'conference', 'journal', 'later', 'without', 'self', 'plagiarising']","['post', 'arxivask', 'question', 'respect', 'cultur', 'rather', 'practic', 'e', 'could', 'obvious', 'post', 'anyth', 'research', 'field', 'curiou', 'know', 'use', 'post', 'work', 'paper', 'whether', 'typic', 'prepublish', 'work', 'alreadi', 'sent', 'confer', 'journal', 'arxiv', 'paper', 'get', 'traction', 'interest', 'sent', 'confer', 'journal', 'later', 'without', 'self', 'plagiaris']"
287,311,311,Rohit901,vgesbr,[D] Laptops with NVIDIA Mobile GPUs are better option than Apple Silicon for ML/DL Tasks,"It is really disappointing to find out that Apple Silicon based machine does not keep up to even the mobile Nvidia GPUs present in the laptops. They marketed the machine like it is the best with its unique unified memory architecture, astonishing memory bandwidth, powerful GPU cores, etc. They released M1 Pro, M1 Max and even M1 Ultra. All of these are just overpriced chips offering no significant value for money. One can easily get any laptop with NVIDIA 3080 mobile GPU, and it would be 1) cheaper 2) will have much better performance than even the M1 Ultra.

Sure, the battery life and the ecosystem of Apple is good. However, if it is gonna take 30 mins per epoch on M1 Pro/Max, whereas it will just take 5 mins per epoch on these Nvidia Mobile GPUs, I think its a no brainer to just go with Nvidia based laptops for ML/DL workflows.

Would love to hear opinion of others on this. If anyone has some more benchmarks, do share it here. You could make use of the unified memory, increase the batch size and then try to compare how much of a performance improvement it makes. But still I think it might not be able to compete with Nvidia 3080 Mobile.

&#x200B;

EDIT: I'm just saying that If you ever have to train something on your laptop and in local environment just for testing purposes before you actually use cloud resources to train the final model, the process would be slower when using Apple silicon when compared to Nvidia Mobile GPUs. Like cloud based resources would charge you per hour, so better to test out and then do just the training part in cloud right. 

My complaint was that Apple could definitely up their game and they still have a long way to go. They have been comparing their chip with dedicated GPUs like NVIDIA in their presentations and keynotes. They keep showing that its better than these dedicated GPUs. However in reality it depends on the task, and it definitely is not better in ML/DL tasks.",80,122,2022-06-20 11:56:02, d  laptops with nvidia mobile gpus are better option than apple silicon for ml dl tasks,it is really disappointing to find out that apple silicon based machine does not keep up to even the mobile nvidia gpus present in the laptops  they marketed the machine like it is the best with its unique unified memory architecture  astonishing memory bandwidth  powerful gpu cores  etc  they released m pro  m max and even m ultra  all of these are just overpriced chips offering no significant value for money  one can easily get any laptop with nvidia  mobile gpu  and it would be   cheaper   will have much better performance than even the m ultra sure  the battery life and the ecosystem of apple is good  however  if it is gonna take  mins per epoch on m pro max  whereas it will just take  mins per epoch on these nvidia mobile gpus  i think its a no brainer to just go with nvidia based laptops for ml dl workflows would love to hear opinion of others on this  if anyone has some more benchmarks  do share it here  you could make use of the unified memory  increase the batch size and then try to compare how much of a performance improvement it makes  but still i think it might not be able to compete with nvidia  mobile   xb edit  i m just saying that if you ever have to train something on your laptop and in local environment just for testing purposes before you actually use cloud resources to train the final model  the process would be slower when using apple silicon when compared to nvidia mobile gpus  like cloud based resources would charge you per hour  so better to test out and then do just the training part in cloud right  my complaint was that apple could definitely up their game and they still have a long way to go  they have been comparing their chip with dedicated gpus like nvidia in their presentations and keynotes  they keep showing that its better than these dedicated gpus  however in reality it depends on the task  and it definitely is not better in ml dl tasks ,really disappointing find apple silicon based machine keep even mobile nvidia gpus present laptops marketed machine like best unique unified memory architecture astonishing memory bandwidth powerful gpu cores etc released pro max even ultra overpriced chips offering significant value money one easily get laptop nvidia mobile gpu would cheaper much better performance even ultra sure battery life ecosystem apple good however gonna take mins per epoch pro max whereas take mins per epoch nvidia mobile gpus think brainer go nvidia based laptops ml dl workflows would love hear opinion others anyone benchmarks share could make use unified memory increase batch size try compare much performance improvement makes still think might able compete nvidia mobile xb edit saying ever train something laptop local environment testing purposes actually use cloud resources train final model process would slower using apple silicon compared nvidia mobile gpus like cloud based resources would charge per hour better test training part cloud right complaint apple could definitely game still long way go comparing chip dedicated gpus like nvidia presentations keynotes keep showing better dedicated gpus however reality depends task definitely better ml dl tasks,laptops nvidia mobile gpus better option apple silicon ml dl tasks,laptops nvidia mobile gpus better option apple silicon ml dl tasksreally disappointing find apple silicon based machine keep even mobile nvidia gpus present laptops marketed machine like best unique unified memory architecture astonishing memory bandwidth powerful gpu cores etc released pro max even ultra overpriced chips offering significant value money one easily get laptop nvidia mobile gpu would cheaper much better performance even ultra sure battery life ecosystem apple good however gonna take mins per epoch pro max whereas take mins per epoch nvidia mobile gpus think brainer go nvidia based laptops ml dl workflows would love hear opinion others anyone benchmarks share could make use unified memory increase batch size try compare much performance improvement makes still think might able compete nvidia mobile xb edit saying ever train something laptop local environment testing purposes actually use cloud resources train final model process would slower using apple silicon compared nvidia mobile gpus like cloud based resources would charge per hour better test training part cloud right complaint apple could definitely game still long way go comparing chip dedicated gpus like nvidia presentations keynotes keep showing better dedicated gpus however reality depends task definitely better ml dl tasks,"['laptops', 'nvidia', 'mobile', 'gpus', 'better', 'option', 'apple', 'silicon', 'ml', 'dl', 'tasksreally', 'disappointing', 'find', 'apple', 'silicon', 'based', 'machine', 'keep', 'even', 'mobile', 'nvidia', 'gpus', 'present', 'laptops', 'marketed', 'machine', 'like', 'best', 'unique', 'unified', 'memory', 'architecture', 'astonishing', 'memory', 'bandwidth', 'powerful', 'gpu', 'cores', 'etc', 'released', 'pro', 'max', 'even', 'ultra', 'overpriced', 'chips', 'offering', 'significant', 'value', 'money', 'one', 'easily', 'get', 'laptop', 'nvidia', 'mobile', 'gpu', 'would', 'cheaper', 'much', 'better', 'performance', 'even', 'ultra', 'sure', 'battery', 'life', 'ecosystem', 'apple', 'good', 'however', 'gon', 'na', 'take', 'mins', 'per', 'epoch', 'pro', 'max', 'whereas', 'take', 'mins', 'per', 'epoch', 'nvidia', 'mobile', 'gpus', 'think', 'brainer', 'go', 'nvidia', 'based', 'laptops', 'ml', 'dl', 'workflows', 'would', 'love', 'hear', 'opinion', 'others', 'anyone', 'benchmarks', 'share', 'could', 'make', 'use', 'unified', 'memory', 'increase', 'batch', 'size', 'try', 'compare', 'much', 'performance', 'improvement', 'makes', 'still', 'think', 'might', 'able', 'compete', 'nvidia', 'mobile', 'xb', 'edit', 'saying', 'ever', 'train', 'something', 'laptop', 'local', 'environment', 'testing', 'purposes', 'actually', 'use', 'cloud', 'resources', 'train', 'final', 'model', 'process', 'would', 'slower', 'using', 'apple', 'silicon', 'compared', 'nvidia', 'mobile', 'gpus', 'like', 'cloud', 'based', 'resources', 'would', 'charge', 'per', 'hour', 'better', 'test', 'training', 'part', 'cloud', 'right', 'complaint', 'apple', 'could', 'definitely', 'game', 'still', 'long', 'way', 'go', 'comparing', 'chip', 'dedicated', 'gpus', 'like', 'nvidia', 'presentations', 'keynotes', 'keep', 'showing', 'better', 'dedicated', 'gpus', 'however', 'reality', 'depends', 'task', 'definitely', 'better', 'ml', 'dl', 'tasks']","['laptop', 'nvidia', 'mobil', 'gpu', 'better', 'option', 'appl', 'silicon', 'ml', 'dl', 'tasksreal', 'disappoint', 'find', 'appl', 'silicon', 'base', 'machin', 'keep', 'even', 'mobil', 'nvidia', 'gpu', 'present', 'laptop', 'market', 'machin', 'like', 'best', 'uniqu', 'unifi', 'memori', 'architectur', 'astonish', 'memori', 'bandwidth', 'power', 'gpu', 'core', 'etc', 'releas', 'pro', 'max', 'even', 'ultra', 'overpr', 'chip', 'offer', 'signific', 'valu', 'money', 'one', 'easili', 'get', 'laptop', 'nvidia', 'mobil', 'gpu', 'would', 'cheaper', 'much', 'better', 'perform', 'even', 'ultra', 'sure', 'batteri', 'life', 'ecosystem', 'appl', 'good', 'howev', 'gon', 'na', 'take', 'min', 'per', 'epoch', 'pro', 'max', 'wherea', 'take', 'min', 'per', 'epoch', 'nvidia', 'mobil', 'gpu', 'think', 'brainer', 'go', 'nvidia', 'base', 'laptop', 'ml', 'dl', 'workflow', 'would', 'love', 'hear', 'opinion', 'other', 'anyon', 'benchmark', 'share', 'could', 'make', 'use', 'unifi', 'memori', 'increas', 'batch', 'size', 'tri', 'compar', 'much', 'perform', 'improv', 'make', 'still', 'think', 'might', 'abl', 'compet', 'nvidia', 'mobil', 'xb', 'edit', 'say', 'ever', 'train', 'someth', 'laptop', 'local', 'environ', 'test', 'purpos', 'actual', 'use', 'cloud', 'resourc', 'train', 'final', 'model', 'process', 'would', 'slower', 'use', 'appl', 'silicon', 'compar', 'nvidia', 'mobil', 'gpu', 'like', 'cloud', 'base', 'resourc', 'would', 'charg', 'per', 'hour', 'better', 'test', 'train', 'part', 'cloud', 'right', 'complaint', 'appl', 'could', 'definit', 'game', 'still', 'long', 'way', 'go', 'compar', 'chip', 'dedic', 'gpu', 'like', 'nvidia', 'present', 'keynot', 'keep', 'show', 'better', 'dedic', 'gpu', 'howev', 'realiti', 'depend', 'task', 'definit', 'better', 'ml', 'dl', 'task']"
288,312,312,Chelokot,vgp7os,[D] Any relatively new text2image models with fine tuning?,"I have relatively small dataset of 256x256 images with text captions, and it's definetely not the best solution to train something from scratch with that, so I wonder what ways do I have to fine tune something on my dataset. I tried to use something from DALL-E mini repo, but it does not provide exact code for fine tuning and enough documentation for me and I failed to write my own. Similar story with the Latent diffusion repo, I couldn't use their training code to fine tune existing model, and it seems the didn't even provided enough code for training text2image model as their config is not working. The only things I could find was ruDALL-E, ruDOLPH models, but they are relatively old and most importanly they're worning with Russian and not English text, which is not what I need. I found some methods for fine-tuning CLIP model, it seems pretty easy, but I don't know what to do next with it, as something like VQGAN+Clip works pretty bad in comparison with this year SOTA solutions. So, if anybody know, please, any guides, repos, colabs etc for finetuning text2image models are welcome",5,14,2022-06-20 21:47:00, d  any relatively new textimage models with fine tuning ,i have relatively small dataset of x images with text captions  and it s definetely not the best solution to train something from scratch with that  so i wonder what ways do i have to fine tune something on my dataset  i tried to use something from dall e mini repo  but it does not provide exact code for fine tuning and enough documentation for me and i failed to write my own  similar story with the latent diffusion repo  i couldn t use their training code to fine tune existing model  and it seems the didn t even provided enough code for training textimage model as their config is not working  the only things i could find was rudall e  rudolph models  but they are relatively old and most importanly they re worning with russian and not english text  which is not what i need  i found some methods for fine tuning clip model  it seems pretty easy  but i don t know what to do next with it  as something like vqgan clip works pretty bad in comparison with this year sota solutions  so  if anybody know  please  any guides  repos  colabs etc for finetuning textimage models are welcome,relatively small dataset x images text captions definetely best solution train something scratch wonder ways fine tune something dataset tried use something dall e mini repo provide exact code fine tuning enough documentation failed write similar story latent diffusion repo use training code fine tune existing model seems even provided enough code training textimage model config working things could find rudall e rudolph models relatively old importanly worning russian english text need found methods fine tuning clip model seems pretty easy know next something like vqgan clip works pretty bad comparison year sota solutions anybody know please guides repos colabs etc finetuning textimage models welcome,relatively textimage models fine tuning,relatively textimage models fine tuningrelatively small dataset x images text captions definetely best solution train something scratch wonder ways fine tune something dataset tried use something dall e mini repo provide exact code fine tuning enough documentation failed write similar story latent diffusion repo use training code fine tune existing model seems even provided enough code training textimage model config working things could find rudall e rudolph models relatively old importanly worning russian english text need found methods fine tuning clip model seems pretty easy know next something like vqgan clip works pretty bad comparison year sota solutions anybody know please guides repos colabs etc finetuning textimage models welcome,"['relatively', 'textimage', 'models', 'fine', 'tuningrelatively', 'small', 'dataset', 'x', 'images', 'text', 'captions', 'definetely', 'best', 'solution', 'train', 'something', 'scratch', 'wonder', 'ways', 'fine', 'tune', 'something', 'dataset', 'tried', 'use', 'something', 'dall', 'e', 'mini', 'repo', 'provide', 'exact', 'code', 'fine', 'tuning', 'enough', 'documentation', 'failed', 'write', 'similar', 'story', 'latent', 'diffusion', 'repo', 'use', 'training', 'code', 'fine', 'tune', 'existing', 'model', 'seems', 'even', 'provided', 'enough', 'code', 'training', 'textimage', 'model', 'config', 'working', 'things', 'could', 'find', 'rudall', 'e', 'rudolph', 'models', 'relatively', 'old', 'importanly', 'worning', 'russian', 'english', 'text', 'need', 'found', 'methods', 'fine', 'tuning', 'clip', 'model', 'seems', 'pretty', 'easy', 'know', 'next', 'something', 'like', 'vqgan', 'clip', 'works', 'pretty', 'bad', 'comparison', 'year', 'sota', 'solutions', 'anybody', 'know', 'please', 'guides', 'repos', 'colabs', 'etc', 'finetuning', 'textimage', 'models', 'welcome']","['rel', 'textimag', 'model', 'fine', 'tuningrel', 'small', 'dataset', 'x', 'imag', 'text', 'caption', 'definet', 'best', 'solut', 'train', 'someth', 'scratch', 'wonder', 'way', 'fine', 'tune', 'someth', 'dataset', 'tri', 'use', 'someth', 'dall', 'e', 'mini', 'repo', 'provid', 'exact', 'code', 'fine', 'tune', 'enough', 'document', 'fail', 'write', 'similar', 'stori', 'latent', 'diffus', 'repo', 'use', 'train', 'code', 'fine', 'tune', 'exist', 'model', 'seem', 'even', 'provid', 'enough', 'code', 'train', 'textimag', 'model', 'config', 'work', 'thing', 'could', 'find', 'rudal', 'e', 'rudolph', 'model', 'rel', 'old', 'importanli', 'worn', 'russian', 'english', 'text', 'need', 'found', 'method', 'fine', 'tune', 'clip', 'model', 'seem', 'pretti', 'easi', 'know', 'next', 'someth', 'like', 'vqgan', 'clip', 'work', 'pretti', 'bad', 'comparison', 'year', 'sota', 'solut', 'anybodi', 'know', 'pleas', 'guid', 'repo', 'colab', 'etc', 'finetun', 'textimag', 'model', 'welcom']"
289,314,314,d8aDev,vgmu9c,[P] Colab Themes: A Chrome Extension to Customize the Style of Google Colab,"Changes the page CSS and text editor and generates Python code to change Matplotlib styles to match the theme the user choses. Users may import themes or use any of the 50+ provided. Colab Themes enhances the data science experience by transforming the way users view their code and their data!

Check it out on [Github](https://github.com/DannyCol/Colab-Themes) or install it via the [Chrome Webstore](https://chrome.google.com/webstore/detail/colab-themes/hledcfghfgmmjpnfkklcifpcdogjlgig)",4,12,2022-06-20 20:01:19, p  colab themes  a chrome extension to customize the style of google colab,changes the page css and text editor and generates python code to change matplotlib styles to match the theme the user choses  users may import themes or use any of the   provided  colab themes enhances the data science experience by transforming the way users view their code and their data check it out on  github  https   github com dannycol colab themes  or install it via the  chrome webstore  https   chrome google com webstore detail colab themes hledcfghfgmmjpnfkklcifpcdogjlgig ,changes page css text editor generates python code change matplotlib styles match theme user choses users may import themes use provided colab themes enhances data science experience transforming way users view code data check github https github com dannycol colab themes install via chrome webstore https chrome google com webstore detail colab themes hledcfghfgmmjpnfkklcifpcdogjlgig,p colab themes chrome extension customize style google colab,p colab themes chrome extension customize style google colabchanges page css text editor generates python code change matplotlib styles match theme user choses users may import themes use provided colab themes enhances data science experience transforming way users view code data check github https github com dannycol colab themes install via chrome webstore https chrome google com webstore detail colab themes hledcfghfgmmjpnfkklcifpcdogjlgig,"['p', 'colab', 'themes', 'chrome', 'extension', 'customize', 'style', 'google', 'colabchanges', 'page', 'css', 'text', 'editor', 'generates', 'python', 'code', 'change', 'matplotlib', 'styles', 'match', 'theme', 'user', 'choses', 'users', 'may', 'import', 'themes', 'use', 'provided', 'colab', 'themes', 'enhances', 'data', 'science', 'experience', 'transforming', 'way', 'users', 'view', 'code', 'data', 'check', 'github', 'https', 'github', 'com', 'dannycol', 'colab', 'themes', 'install', 'via', 'chrome', 'webstore', 'https', 'chrome', 'google', 'com', 'webstore', 'detail', 'colab', 'themes', 'hledcfghfgmmjpnfkklcifpcdogjlgig']","['p', 'colab', 'theme', 'chrome', 'extens', 'custom', 'style', 'googl', 'colabchang', 'page', 'css', 'text', 'editor', 'gener', 'python', 'code', 'chang', 'matplotlib', 'style', 'match', 'theme', 'user', 'chose', 'user', 'may', 'import', 'theme', 'use', 'provid', 'colab', 'theme', 'enhanc', 'data', 'scienc', 'experi', 'transform', 'way', 'user', 'view', 'code', 'data', 'check', 'github', 'http', 'github', 'com', 'dannycol', 'colab', 'theme', 'instal', 'via', 'chrome', 'webstor', 'http', 'chrome', 'googl', 'com', 'webstor', 'detail', 'colab', 'theme', 'hledcfghfgmmjpnfkklcifpcdogjlgig']"
290,315,315,Razcle,vgh3d9,[D] Whats the current state of the art in image style transfer?,"Diffusion models like Dall E are producing incredible images. What's the current state of the art for taking one image and combining it with the style from another?  


Could anyone point me to a handful of references please?",1,18,2022-06-20 14:32:17, d  whats the current state of the art in image style transfer ,diffusion models like dall e are producing incredible images  what s the current state of the art for taking one image and combining it with the style from another   could anyone point me to a handful of references please ,diffusion models like dall e producing incredible images current state art taking one image combining style another could anyone point handful references please,whats current state art image style transfer,whats current state art image style transferdiffusion models like dall e producing incredible images current state art taking one image combining style another could anyone point handful references please,"['whats', 'current', 'state', 'art', 'image', 'style', 'transferdiffusion', 'models', 'like', 'dall', 'e', 'producing', 'incredible', 'images', 'current', 'state', 'art', 'taking', 'one', 'image', 'combining', 'style', 'another', 'could', 'anyone', 'point', 'handful', 'references', 'please']","['what', 'current', 'state', 'art', 'imag', 'style', 'transferdiffus', 'model', 'like', 'dall', 'e', 'produc', 'incred', 'imag', 'current', 'state', 'art', 'take', 'one', 'imag', 'combin', 'style', 'anoth', 'could', 'anyon', 'point', 'hand', 'refer', 'pleas']"
291,316,316,Relative_Tip_3647,vggaxk,[D] Any research specific PyTorch based boilerplate code?,"Any research specific PyTorch based boilerplate code?

I am a PhD student working in Deep Learning based NLP methods. I am trying to develop a boilerplate code of my own. Looking for inspirations or ideas?",14,16,2022-06-20 13:36:39, d  any research specific pytorch based boilerplate code ,any research specific pytorch based boilerplate code i am a phd student working in deep learning based nlp methods  i am trying to develop a boilerplate code of my own  looking for inspirations or ideas ,research specific pytorch based boilerplate code phd student working deep learning based nlp methods trying develop boilerplate code looking inspirations ideas,research specific pytorch based boilerplate code,research specific pytorch based boilerplate coderesearch specific pytorch based boilerplate code phd student working deep learning based nlp methods trying develop boilerplate code looking inspirations ideas,"['research', 'specific', 'pytorch', 'based', 'boilerplate', 'coderesearch', 'specific', 'pytorch', 'based', 'boilerplate', 'code', 'phd', 'student', 'working', 'deep', 'learning', 'based', 'nlp', 'methods', 'trying', 'develop', 'boilerplate', 'code', 'looking', 'inspirations', 'ideas']","['research', 'specif', 'pytorch', 'base', 'boilerpl', 'coderesearch', 'specif', 'pytorch', 'base', 'boilerpl', 'code', 'phd', 'student', 'work', 'deep', 'learn', 'base', 'nlp', 'method', 'tri', 'develop', 'boilerpl', 'code', 'look', 'inspir', 'idea']"
292,317,317,Juthsty,vgmtkj,[R] PowerShap: A power-full Shapley feature selection method.,"This method uses statistical hypothesis testing and power calculations on Shapley values, enabling fast and intuitive wrapper-based feature selection. The complete library and methods are fully compatible with Sklearn, LightGBM, CatBoost, and more are coming in further following releases and the library can be found here: [https://github.com/predict-idlab/powershap](https://github.com/predict-idlab/powershap)! The library is open-source and usable out-of-the-box as shown in the video!

The paper is already released on arXiv: [https://arxiv.org/abs/2206.08394](https://arxiv.org/abs/2206.08394). Furthermore, the work will be presented at ECML PKDD 2022.

**How does it work?**

The complete method is built on the assumption that a random feature, that contains no information, should have a lower impact on the predictions compared to an informative feature. To test this, PowerShap trains a model with the original features and appends a random feature to the feature set. After training, it evaluates the Shapley values and calculates the average impact of each feature by taking the mean of the absolute Shapley values. Powershap repeats this for a couple of iterations resulting in an array of mean impacts for each feature individually. It then uses statistical hypothesis testing using t-test calculations to calculate whether a feature is more informative compared to the appended random feature. In this way, it is possible to use any model that can calculate Shapley values and search for all informative features.

**What is so special?**

The strong aspect of PowerShap is its automatic mode. By using statistical power calculations PowerShap actually calculates the required amount of iterations required to have solid statistical results. Therefore, the method is usable without tuning the hyperparameters of the algorithm. To do this, PowerShap first executes 10 iterations in the default mode and then calculates the required iterations. If the required iterations are more than the already executed iterations, PowerShap continues until the required iterations are reached. Otherwise, it directly stops.

**Performance**

On GitHub and in the paper there are already some benchmarks of the algorithm, but feel free to test it yourself! We noticed that the algorithm is much faster than many wrapper-based algorithms such as genetic and forward feature selection. This is because the time complexity of the PowerShap algorithm is not dependent on the number of features compared to forward feature selection. Furthermore, the performance is often equal to even better compared to other wrapper-based methods.

If you have any questions feel free to ask!

https://reddit.com/link/vgmtkj/video/aozomw7pds691/player",2,4,2022-06-20 20:00:27, r  powershap  a power full shapley feature selection method ,this method uses statistical hypothesis testing and power calculations on shapley values  enabling fast and intuitive wrapper based feature selection  the complete library and methods are fully compatible with sklearn  lightgbm  catboost  and more are coming in further following releases and the library can be found here   https the paper is already released on arxiv   https   how does it work   the complete method is built on the assumption that a random feature  that contains no information  should have a lower impact on the predictions compared to an informative feature  to test this  powershap trains a model with the original features and appends a random feature to the feature set  after training  it evaluates the shapley values and calculates the average impact of each feature by taking the mean of the absolute shapley values  powershap repeats this for a couple of iterations resulting in an array of mean impacts for each feature individually  it then uses statistical hypothesis testing using t test calculations to calculate whether a feature is more informative compared to the appended random feature  in this way  it is possible to use any model that can calculate shapley values and search for all informative features   what is so special   the strong aspect of powershap is its automatic mode  by using statistical power calculations powershap actually calculates the required amount of iterations required to have solid statistical results  therefore  the method is usable without tuning the hyperparameters of the algorithm  to do this  powershap first executes  iterations in the default mode and then calculates the required iterations  if the required iterations are more than the already executed iterations  powershap continues until the required iterations are reached  otherwise  it directly stops   performance  on github and in the paper there are already some benchmarks of the algorithm  but feel free to test it yourself  we noticed that the algorithm is much faster than many wrapper based algorithms such as genetic and forward feature selection  this is because the time complexity of the powershap algorithm is not dependent on the number of features compared to forward feature selection  furthermore  the performance is often equal to even better compared to other wrapper based methods if you have any questions feel free to ask https   reddit com link vgmtkj video aozomwpds player,method uses statistical hypothesis testing power calculations shapley values enabling fast intuitive wrapper based feature selection complete library methods fully compatible sklearn lightgbm catboost coming following releases library found https paper already released arxiv https work complete method built assumption random feature contains information lower impact predictions compared informative feature test powershap trains model original features appends random feature feature set training evaluates shapley values calculates average impact feature taking mean absolute shapley values powershap repeats couple iterations resulting array mean impacts feature individually uses statistical hypothesis testing using test calculations calculate whether feature informative compared appended random feature way possible use model calculate shapley values search informative features special strong aspect powershap automatic mode using statistical power calculations powershap actually calculates required amount iterations required solid statistical results therefore method usable without tuning hyperparameters algorithm powershap first executes iterations default mode calculates required iterations required iterations already executed iterations powershap continues required iterations reached otherwise directly stops performance github paper already benchmarks algorithm feel free test noticed algorithm much faster many wrapper based algorithms genetic forward feature selection time complexity powershap algorithm dependent number features compared forward feature selection furthermore performance often equal even better compared wrapper based methods questions feel free ask https reddit com link vgmtkj video aozomwpds player,r powershap power full shapley feature selection method,r powershap power full shapley feature selection methodmethod uses statistical hypothesis testing power calculations shapley values enabling fast intuitive wrapper based feature selection complete library methods fully compatible sklearn lightgbm catboost coming following releases library found https paper already released arxiv https work complete method built assumption random feature contains information lower impact predictions compared informative feature test powershap trains model original features appends random feature feature set training evaluates shapley values calculates average impact feature taking mean absolute shapley values powershap repeats couple iterations resulting array mean impacts feature individually uses statistical hypothesis testing using test calculations calculate whether feature informative compared appended random feature way possible use model calculate shapley values search informative features special strong aspect powershap automatic mode using statistical power calculations powershap actually calculates required amount iterations required solid statistical results therefore method usable without tuning hyperparameters algorithm powershap first executes iterations default mode calculates required iterations required iterations already executed iterations powershap continues required iterations reached otherwise directly stops performance github paper already benchmarks algorithm feel free test noticed algorithm much faster many wrapper based algorithms genetic forward feature selection time complexity powershap algorithm dependent number features compared forward feature selection furthermore performance often equal even better compared wrapper based methods questions feel free ask https reddit com link vgmtkj video aozomwpds player,"['r', 'powershap', 'power', 'full', 'shapley', 'feature', 'selection', 'methodmethod', 'uses', 'statistical', 'hypothesis', 'testing', 'power', 'calculations', 'shapley', 'values', 'enabling', 'fast', 'intuitive', 'wrapper', 'based', 'feature', 'selection', 'complete', 'library', 'methods', 'fully', 'compatible', 'sklearn', 'lightgbm', 'catboost', 'coming', 'following', 'releases', 'library', 'found', 'https', 'paper', 'already', 'released', 'arxiv', 'https', 'work', 'complete', 'method', 'built', 'assumption', 'random', 'feature', 'contains', 'information', 'lower', 'impact', 'predictions', 'compared', 'informative', 'feature', 'test', 'powershap', 'trains', 'model', 'original', 'features', 'appends', 'random', 'feature', 'feature', 'set', 'training', 'evaluates', 'shapley', 'values', 'calculates', 'average', 'impact', 'feature', 'taking', 'mean', 'absolute', 'shapley', 'values', 'powershap', 'repeats', 'couple', 'iterations', 'resulting', 'array', 'mean', 'impacts', 'feature', 'individually', 'uses', 'statistical', 'hypothesis', 'testing', 'using', 'test', 'calculations', 'calculate', 'whether', 'feature', 'informative', 'compared', 'appended', 'random', 'feature', 'way', 'possible', 'use', 'model', 'calculate', 'shapley', 'values', 'search', 'informative', 'features', 'special', 'strong', 'aspect', 'powershap', 'automatic', 'mode', 'using', 'statistical', 'power', 'calculations', 'powershap', 'actually', 'calculates', 'required', 'amount', 'iterations', 'required', 'solid', 'statistical', 'results', 'therefore', 'method', 'usable', 'without', 'tuning', 'hyperparameters', 'algorithm', 'powershap', 'first', 'executes', 'iterations', 'default', 'mode', 'calculates', 'required', 'iterations', 'required', 'iterations', 'already', 'executed', 'iterations', 'powershap', 'continues', 'required', 'iterations', 'reached', 'otherwise', 'directly', 'stops', 'performance', 'github', 'paper', 'already', 'benchmarks', 'algorithm', 'feel', 'free', 'test', 'noticed', 'algorithm', 'much', 'faster', 'many', 'wrapper', 'based', 'algorithms', 'genetic', 'forward', 'feature', 'selection', 'time', 'complexity', 'powershap', 'algorithm', 'dependent', 'number', 'features', 'compared', 'forward', 'feature', 'selection', 'furthermore', 'performance', 'often', 'equal', 'even', 'better', 'compared', 'wrapper', 'based', 'methods', 'questions', 'feel', 'free', 'ask', 'https', 'reddit', 'com', 'link', 'vgmtkj', 'video', 'aozomwpds', 'player']","['r', 'powershap', 'power', 'full', 'shapley', 'featur', 'select', 'methodmethod', 'use', 'statist', 'hypothesi', 'test', 'power', 'calcul', 'shapley', 'valu', 'enabl', 'fast', 'intuit', 'wrapper', 'base', 'featur', 'select', 'complet', 'librari', 'method', 'fulli', 'compat', 'sklearn', 'lightgbm', 'catboost', 'come', 'follow', 'releas', 'librari', 'found', 'http', 'paper', 'alreadi', 'releas', 'arxiv', 'http', 'work', 'complet', 'method', 'built', 'assumpt', 'random', 'featur', 'contain', 'inform', 'lower', 'impact', 'predict', 'compar', 'inform', 'featur', 'test', 'powershap', 'train', 'model', 'origin', 'featur', 'append', 'random', 'featur', 'featur', 'set', 'train', 'evalu', 'shapley', 'valu', 'calcul', 'averag', 'impact', 'featur', 'take', 'mean', 'absolut', 'shapley', 'valu', 'powershap', 'repeat', 'coupl', 'iter', 'result', 'array', 'mean', 'impact', 'featur', 'individu', 'use', 'statist', 'hypothesi', 'test', 'use', 'test', 'calcul', 'calcul', 'whether', 'featur', 'inform', 'compar', 'append', 'random', 'featur', 'way', 'possibl', 'use', 'model', 'calcul', 'shapley', 'valu', 'search', 'inform', 'featur', 'special', 'strong', 'aspect', 'powershap', 'automat', 'mode', 'use', 'statist', 'power', 'calcul', 'powershap', 'actual', 'calcul', 'requir', 'amount', 'iter', 'requir', 'solid', 'statist', 'result', 'therefor', 'method', 'usabl', 'without', 'tune', 'hyperparamet', 'algorithm', 'powershap', 'first', 'execut', 'iter', 'default', 'mode', 'calcul', 'requir', 'iter', 'requir', 'iter', 'alreadi', 'execut', 'iter', 'powershap', 'continu', 'requir', 'iter', 'reach', 'otherwis', 'directli', 'stop', 'perform', 'github', 'paper', 'alreadi', 'benchmark', 'algorithm', 'feel', 'free', 'test', 'notic', 'algorithm', 'much', 'faster', 'mani', 'wrapper', 'base', 'algorithm', 'genet', 'forward', 'featur', 'select', 'time', 'complex', 'powershap', 'algorithm', 'depend', 'number', 'featur', 'compar', 'forward', 'featur', 'select', 'furthermor', 'perform', 'often', 'equal', 'even', 'better', 'compar', 'wrapper', 'base', 'method', 'question', 'feel', 'free', 'ask', 'http', 'reddit', 'com', 'link', 'vgmtkj', 'video', 'aozomwpd', 'player']"
293,319,319,arangel96,vgmzir,[P] Using machine learning in the travel industry - CHALLENGE,"Hello everyone!

I am from [tryp.com](https://tryp.com), a travel-tech startup that is using AI to create complex travel itineraries on the go, from minimal user constrains. 

&#x200B;

[Trips created in \<15s for defined time search range and start location](https://preview.redd.it/2lt59n7bfs691.png?width=977&format=png&auto=webp&s=e0d0f0bde3089180bd7af8ed1171b570984d9af0)

Currently we are embarcing a new challenge, to improve our offering:

Creating an AI, trained from screen recordings of purchases in 100s of websites, that can purchase travel tickets from any website, in any language. Has anyone worked on a similar challange? We are looking to form a team to tackle such challenge!",10,4,2022-06-20 20:08:19, p  using machine learning in the travel industry   challenge,hello everyone i am from  tryp com  https   xb  trips created in   s for defined time search range and start location  https currently we are embarcing a new challenge  to improve our offering creating an ai  trained from screen recordings of purchases in s of websites  that can purchase travel tickets from any website  in any language  has anyone worked on a similar challange  we are looking to form a team to tackle such challenge ,hello everyone tryp com https xb trips created defined time search range start location https currently embarcing challenge improve offering creating ai trained screen recordings purchases websites purchase travel tickets website language anyone worked similar challange looking form team tackle challenge,p using machine learning travel industry challenge,p using machine learning travel industry challengehello everyone tryp com https xb trips created defined time search range start location https currently embarcing challenge improve offering creating ai trained screen recordings purchases websites purchase travel tickets website language anyone worked similar challange looking form team tackle challenge,"['p', 'using', 'machine', 'learning', 'travel', 'industry', 'challengehello', 'everyone', 'tryp', 'com', 'https', 'xb', 'trips', 'created', 'defined', 'time', 'search', 'range', 'start', 'location', 'https', 'currently', 'embarcing', 'challenge', 'improve', 'offering', 'creating', 'ai', 'trained', 'screen', 'recordings', 'purchases', 'websites', 'purchase', 'travel', 'tickets', 'website', 'language', 'anyone', 'worked', 'similar', 'challange', 'looking', 'form', 'team', 'tackle', 'challenge']","['p', 'use', 'machin', 'learn', 'travel', 'industri', 'challengehello', 'everyon', 'tryp', 'com', 'http', 'xb', 'trip', 'creat', 'defin', 'time', 'search', 'rang', 'start', 'locat', 'http', 'current', 'embarc', 'challeng', 'improv', 'offer', 'creat', 'ai', 'train', 'screen', 'record', 'purchas', 'websit', 'purchas', 'travel', 'ticket', 'websit', 'languag', 'anyon', 'work', 'similar', 'challang', 'look', 'form', 'team', 'tackl', 'challeng']"
294,320,320,muwnd,vfutwe,[D] Initialize model weights based on a trained smaller model,"Is there any existing work that explores how trained weights of a small model (e.g. Bert-base) can be used for a ""smart"" initialization of a larger model (bert-large) such that the training is more efficient?

I couldn't really find such work but I guess I just used the wrong search terms. How is this line of research typically called?",18,78,2022-06-19 18:37:37, d  initialize model weights based on a trained smaller model,is there any existing work that explores how trained weights of a small model  e g  bert base  can be used for a smart initialization of a larger model  bert large  such that the training is more efficient i couldn t really find such work but i guess i just used the wrong search terms  how is this line of research typically called ,existing work explores trained weights small model e g bert base used smart initialization larger model bert large training efficient really find work guess used wrong search terms line research typically called,initialize model weights based trained smaller model,initialize model weights based trained smaller modelexisting work explores trained weights small model e g bert base used smart initialization larger model bert large training efficient really find work guess used wrong search terms line research typically called,"['initialize', 'model', 'weights', 'based', 'trained', 'smaller', 'modelexisting', 'work', 'explores', 'trained', 'weights', 'small', 'model', 'e', 'g', 'bert', 'base', 'used', 'smart', 'initialization', 'larger', 'model', 'bert', 'large', 'training', 'efficient', 'really', 'find', 'work', 'guess', 'used', 'wrong', 'search', 'terms', 'line', 'research', 'typically', 'called']","['initi', 'model', 'weight', 'base', 'train', 'smaller', 'modelexist', 'work', 'explor', 'train', 'weight', 'small', 'model', 'e', 'g', 'bert', 'base', 'use', 'smart', 'initi', 'larger', 'model', 'bert', 'larg', 'train', 'effici', 'realli', 'find', 'work', 'guess', 'use', 'wrong', 'search', 'term', 'line', 'research', 'typic', 'call']"
295,321,321,ML-ATF,vgkwpj,[D] Reducing bias when forecasting retail sales with boosting model,"I'm forecasting future sales for products in retail stores, using a LightGBM model. My model has a decent forecast accuracy, but the forecasts are biased (the average forecast error is negative, the model is consistently under-forecasting). Do you have any idea or tips on how to avoid bias when forecasting time series with boosting models?

Here are some more details:

* I'm making forecasts at the Day x Product x Store granularity (i.e 1 forecast every day for each product in each store).
* The forecasting horizon is +7 days.
* I'm training a single model to forecast all products, stores and time horizons.
* The main features are lags of sales, calendar info (day of the week, month...), product info (category, price) and store info.
* Evaluation is made with a time-based cross-validation.

Thank you for your help!",3,0,2022-06-20 18:27:04, d  reducing bias when forecasting retail sales with boosting model,i m forecasting future sales for products in retail stores  using a lightgbm model  my model has a decent forecast accuracy  but the forecasts are biased  the average forecast error is negative  the model is consistently under forecasting   do you have any idea or tips on how to avoid bias when forecasting time series with boosting models here are some more details   i m making forecasts at the day x product x store granularity  i e  forecast every day for each product in each store    the forecasting horizon is   days   i m training a single model to forecast all products  stores and time horizons   the main features are lags of sales  calendar info  day of the week  month      product info  category  price  and store info   evaluation is made with a time based cross validation thank you for your help ,forecasting future sales products retail stores using lightgbm model model decent forecast accuracy forecasts biased average forecast error negative model consistently forecasting idea tips avoid bias forecasting time series boosting models details making forecasts day x product x store granularity e forecast every day product store forecasting horizon days training single model forecast products stores time horizons main features lags sales calendar info day week month product info category price store info evaluation made time based cross validation thank help,reducing bias forecasting retail sales boosting model,reducing bias forecasting retail sales boosting modelforecasting future sales products retail stores using lightgbm model model decent forecast accuracy forecasts biased average forecast error negative model consistently forecasting idea tips avoid bias forecasting time series boosting models details making forecasts day x product x store granularity e forecast every day product store forecasting horizon days training single model forecast products stores time horizons main features lags sales calendar info day week month product info category price store info evaluation made time based cross validation thank help,"['reducing', 'bias', 'forecasting', 'retail', 'sales', 'boosting', 'modelforecasting', 'future', 'sales', 'products', 'retail', 'stores', 'using', 'lightgbm', 'model', 'model', 'decent', 'forecast', 'accuracy', 'forecasts', 'biased', 'average', 'forecast', 'error', 'negative', 'model', 'consistently', 'forecasting', 'idea', 'tips', 'avoid', 'bias', 'forecasting', 'time', 'series', 'boosting', 'models', 'details', 'making', 'forecasts', 'day', 'x', 'product', 'x', 'store', 'granularity', 'e', 'forecast', 'every', 'day', 'product', 'store', 'forecasting', 'horizon', 'days', 'training', 'single', 'model', 'forecast', 'products', 'stores', 'time', 'horizons', 'main', 'features', 'lags', 'sales', 'calendar', 'info', 'day', 'week', 'month', 'product', 'info', 'category', 'price', 'store', 'info', 'evaluation', 'made', 'time', 'based', 'cross', 'validation', 'thank', 'help']","['reduc', 'bia', 'forecast', 'retail', 'sale', 'boost', 'modelforecast', 'futur', 'sale', 'product', 'retail', 'store', 'use', 'lightgbm', 'model', 'model', 'decent', 'forecast', 'accuraci', 'forecast', 'bias', 'averag', 'forecast', 'error', 'neg', 'model', 'consist', 'forecast', 'idea', 'tip', 'avoid', 'bia', 'forecast', 'time', 'seri', 'boost', 'model', 'detail', 'make', 'forecast', 'day', 'x', 'product', 'x', 'store', 'granular', 'e', 'forecast', 'everi', 'day', 'product', 'store', 'forecast', 'horizon', 'day', 'train', 'singl', 'model', 'forecast', 'product', 'store', 'time', 'horizon', 'main', 'featur', 'lag', 'sale', 'calendar', 'info', 'day', 'week', 'month', 'product', 'info', 'categori', 'price', 'store', 'info', 'evalu', 'made', 'time', 'base', 'cross', 'valid', 'thank', 'help']"
296,323,323,Wild_Quiet8627,vfl57t,[D] Google quietly moving its products from Tensorflow to JAX,"https://www.businessinsider.com/facebook-pytorch-beat-google-tensorflow-jax-meta-ai-2022-6

With companies and researchers leaving Tensorflow and going to PyTorch, Google seems to be interested in moving its products to JAX, addressing some pain points from Tensorflow like the complexity of API, and complexity to train in custom chips like TPU. The article says that JAX still has long way to go since it lacks proper optimization to GPUs and CPUs when compared to TPUs.",132,513,2022-06-19 07:52:49, d  google quietly moving its products from tensorflow to jax,https with companies and researchers leaving tensorflow and going to pytorch  google seems to be interested in moving its products to jax  addressing some pain points from tensorflow like the complexity of api  and complexity to train in custom chips like tpu  the article says that jax still has long way to go since it lacks proper optimization to gpus and cpus when compared to tpus ,https companies researchers leaving tensorflow going pytorch google seems interested moving products jax addressing pain points tensorflow like complexity api complexity train chips like tpu article says jax still long way go since lacks proper optimization gpus cpus compared tpus,google quietly moving products tensorflow jax,google quietly moving products tensorflow jaxhttps companies researchers leaving tensorflow going pytorch google seems interested moving products jax addressing pain points tensorflow like complexity api complexity train chips like tpu article says jax still long way go since lacks proper optimization gpus cpus compared tpus,"['google', 'quietly', 'moving', 'products', 'tensorflow', 'jaxhttps', 'companies', 'researchers', 'leaving', 'tensorflow', 'going', 'pytorch', 'google', 'seems', 'interested', 'moving', 'products', 'jax', 'addressing', 'pain', 'points', 'tensorflow', 'like', 'complexity', 'api', 'complexity', 'train', 'chips', 'like', 'tpu', 'article', 'says', 'jax', 'still', 'long', 'way', 'go', 'since', 'lacks', 'proper', 'optimization', 'gpus', 'cpus', 'compared', 'tpus']","['googl', 'quietli', 'move', 'product', 'tensorflow', 'jaxhttp', 'compani', 'research', 'leav', 'tensorflow', 'go', 'pytorch', 'googl', 'seem', 'interest', 'move', 'product', 'jax', 'address', 'pain', 'point', 'tensorflow', 'like', 'complex', 'api', 'complex', 'train', 'chip', 'like', 'tpu', 'articl', 'say', 'jax', 'still', 'long', 'way', 'go', 'sinc', 'lack', 'proper', 'optim', 'gpu', 'cpu', 'compar', 'tpu']"
297,324,324,mighty-dude,vfx12o,[P] Track your ML Projects from Notion!,"We are building an open-source library to enable tracking your ML projects from the same productivity tool that you already use and love. Check out [https://github.com/paletteml/mlsync](https://t.co/IVbZdbKkhK) 

Our goal is to help ML developers bring useful insights from their ML environment to the rest of the team in an easy way.

[You can customize the data that gets delivered to Notion](https://i.redd.it/xy5e1prn9l691.gif)

**Why MLSync?**

While the ML community has built several tools for developers to better track and visualize their ML workflow data for developers, there is a disconnect between ML workflow data and the tools used for project planning and management. MLSync is designed to bridge this gap.

**Contributing**

We would love to have more contributors join us to add more features and APIs.

**Advanced Features**

We are also building a cloud version for enterprise use cases (multiple users or data sources, in-house tools interfacing, authentication, etc.). Check out [https://www.mlsync.dev/](https://www.mlsync.dev/)

Feel free to DM if you have suggestions, feature requests, or any other queries.",8,47,2022-06-19 20:30:06, p  track your ml projects from notion ,we are building an open source library to enable tracking your ml projects from the same productivity tool that you already use and love  check out  https our goal is to help ml developers bring useful insights from their ml environment to the rest of the team in an easy way  you can customize the data that gets delivered to notion  https   why mlsync   while the ml community has built several tools for developers to better track and visualize their ml workflow data for developers  there is a disconnect between ml workflow data and the tools used for project planning and management  mlsync is designed to bridge this gap   contributing  we would love to have more contributors join us to add more features and apis   advanced features  we are also building a cloud version for enterprise use cases  multiple users or data sources  in house tools interfacing  authentication  etc    check out  https feel free to dm if you have suggestions  feature requests  or any other queries ,building open source library enable tracking ml projects productivity tool already use love check https goal help ml developers bring useful insights ml environment rest team easy way customize data gets delivered notion https mlsync ml community built several tools developers better track visualize ml workflow data developers disconnect ml workflow data tools used project planning management mlsync designed bridge gap contributing would love contributors join us features apis advanced features also building cloud version enterprise use cases multiple users data sources house tools interfacing authentication etc check https feel free dm suggestions feature requests queries,p track ml projects notion,p track ml projects notionbuilding open source library enable tracking ml projects productivity tool already use love check https goal help ml developers bring useful insights ml environment rest team easy way customize data gets delivered notion https mlsync ml community built several tools developers better track visualize ml workflow data developers disconnect ml workflow data tools used project planning management mlsync designed bridge gap contributing would love contributors join us features apis advanced features also building cloud version enterprise use cases multiple users data sources house tools interfacing authentication etc check https feel free dm suggestions feature requests queries,"['p', 'track', 'ml', 'projects', 'notionbuilding', 'open', 'source', 'library', 'enable', 'tracking', 'ml', 'projects', 'productivity', 'tool', 'already', 'use', 'love', 'check', 'https', 'goal', 'help', 'ml', 'developers', 'bring', 'useful', 'insights', 'ml', 'environment', 'rest', 'team', 'easy', 'way', 'customize', 'data', 'gets', 'delivered', 'notion', 'https', 'mlsync', 'ml', 'community', 'built', 'several', 'tools', 'developers', 'better', 'track', 'visualize', 'ml', 'workflow', 'data', 'developers', 'disconnect', 'ml', 'workflow', 'data', 'tools', 'used', 'project', 'planning', 'management', 'mlsync', 'designed', 'bridge', 'gap', 'contributing', 'would', 'love', 'contributors', 'join', 'us', 'features', 'apis', 'advanced', 'features', 'also', 'building', 'cloud', 'version', 'enterprise', 'use', 'cases', 'multiple', 'users', 'data', 'sources', 'house', 'tools', 'interfacing', 'authentication', 'etc', 'check', 'https', 'feel', 'free', 'dm', 'suggestions', 'feature', 'requests', 'queries']","['p', 'track', 'ml', 'project', 'notionbuild', 'open', 'sourc', 'librari', 'enabl', 'track', 'ml', 'project', 'product', 'tool', 'alreadi', 'use', 'love', 'check', 'http', 'goal', 'help', 'ml', 'develop', 'bring', 'use', 'insight', 'ml', 'environ', 'rest', 'team', 'easi', 'way', 'custom', 'data', 'get', 'deliv', 'notion', 'http', 'mlsync', 'ml', 'commun', 'built', 'sever', 'tool', 'develop', 'better', 'track', 'visual', 'ml', 'workflow', 'data', 'develop', 'disconnect', 'ml', 'workflow', 'data', 'tool', 'use', 'project', 'plan', 'manag', 'mlsync', 'design', 'bridg', 'gap', 'contribut', 'would', 'love', 'contributor', 'join', 'us', 'featur', 'api', 'advanc', 'featur', 'also', 'build', 'cloud', 'version', 'enterpris', 'use', 'case', 'multipl', 'user', 'data', 'sourc', 'hous', 'tool', 'interfac', 'authent', 'etc', 'check', 'http', 'feel', 'free', 'dm', 'suggest', 'featur', 'request', 'queri']"
298,325,325,carl535,vgm6yw,[D] Best program (text editor) to use for creating a neural network (GAN) in python?,"I am a master's student writing my dissertation about using GANs to generate classical music. I am studying operations research (applied math) so all my coding experience is with R, except for one Python class I took in 2017 where we used Thonny as an interface. I am comfortable with the mathematical theory behind neural networks and deep learning, and can create them comfortably in R, but my supervisor (as well as an earlier post in this sub) recommends using Python for GANs.

I am very familiar with R (and always use Rstudio) but am essentially a rookie when it comes to Python. Thus I am curious about what text editor you think would be best suited for this task (my friends have mentioned Atom but wanted to check here too). I will only be using this editor for creating the generative adversarial network, so if it's intuitive and easy to use that's ideal. I assume that the easiest way to run the code is just through terminal, unless you have any suggestions about that as well? 

Also, if you generally have any tips for creating NNs in python that simplify the process or pro-tips, that would be much appreciated too!

Thank you:)",6,0,2022-06-20 19:30:54, d  best program  text editor  to use for creating a neural network  gan  in python ,i am a master s student writing my dissertation about using gans to generate classical music  i am studying operations research  applied math  so all my coding experience is with r  except for one python class i took in  where we used thonny as an interface  i am comfortable with the mathematical theory behind neural networks and deep learning  and can create them comfortably in r  but my supervisor  as well as an earlier post in this sub  recommends using python for gans i am very familiar with r  and always use rstudio  but am essentially a rookie when it comes to python  thus i am curious about what text editor you think would be best suited for this task  my friends have mentioned atom but wanted to check here too   i will only be using this editor for creating the generative adversarial network  so if it s intuitive and easy to use that s ideal  i assume that the easiest way to run the code is just through terminal  unless you have any suggestions about that as well  also  if you generally have any tips for creating nns in python that simplify the process or pro tips  that would be much appreciated too thank you  ,master student writing dissertation using gans generate classical music studying operations research applied math coding experience r except one python class took used thonny interface comfortable mathematical theory behind neural networks deep learning create comfortably r supervisor well earlier post sub recommends using python gans familiar r always use rstudio essentially rookie comes python thus curious text editor think would best suited task friends mentioned atom wanted check using editor creating generative adversarial network intuitive easy use ideal assume easiest way run code terminal unless suggestions well also generally tips creating nns python simplify process pro tips would much appreciated thank,best program text editor use creating neural network gan python,best program text editor use creating neural network gan pythonmaster student writing dissertation using gans generate classical music studying operations research applied math coding experience r except one python class took used thonny interface comfortable mathematical theory behind neural networks deep learning create comfortably r supervisor well earlier post sub recommends using python gans familiar r always use rstudio essentially rookie comes python thus curious text editor think would best suited task friends mentioned atom wanted check using editor creating generative adversarial network intuitive easy use ideal assume easiest way run code terminal unless suggestions well also generally tips creating nns python simplify process pro tips would much appreciated thank,"['best', 'program', 'text', 'editor', 'use', 'creating', 'neural', 'network', 'gan', 'pythonmaster', 'student', 'writing', 'dissertation', 'using', 'gans', 'generate', 'classical', 'music', 'studying', 'operations', 'research', 'applied', 'math', 'coding', 'experience', 'r', 'except', 'one', 'python', 'class', 'took', 'used', 'thonny', 'interface', 'comfortable', 'mathematical', 'theory', 'behind', 'neural', 'networks', 'deep', 'learning', 'create', 'comfortably', 'r', 'supervisor', 'well', 'earlier', 'post', 'sub', 'recommends', 'using', 'python', 'gans', 'familiar', 'r', 'always', 'use', 'rstudio', 'essentially', 'rookie', 'comes', 'python', 'thus', 'curious', 'text', 'editor', 'think', 'would', 'best', 'suited', 'task', 'friends', 'mentioned', 'atom', 'wanted', 'check', 'using', 'editor', 'creating', 'generative', 'adversarial', 'network', 'intuitive', 'easy', 'use', 'ideal', 'assume', 'easiest', 'way', 'run', 'code', 'terminal', 'unless', 'suggestions', 'well', 'also', 'generally', 'tips', 'creating', 'nns', 'python', 'simplify', 'process', 'pro', 'tips', 'would', 'much', 'appreciated', 'thank']","['best', 'program', 'text', 'editor', 'use', 'creat', 'neural', 'network', 'gan', 'pythonmast', 'student', 'write', 'dissert', 'use', 'gan', 'gener', 'classic', 'music', 'studi', 'oper', 'research', 'appli', 'math', 'code', 'experi', 'r', 'except', 'one', 'python', 'class', 'took', 'use', 'thonni', 'interfac', 'comfort', 'mathemat', 'theori', 'behind', 'neural', 'network', 'deep', 'learn', 'creat', 'comfort', 'r', 'supervisor', 'well', 'earlier', 'post', 'sub', 'recommend', 'use', 'python', 'gan', 'familiar', 'r', 'alway', 'use', 'rstudio', 'essenti', 'rooki', 'come', 'python', 'thu', 'curiou', 'text', 'editor', 'think', 'would', 'best', 'suit', 'task', 'friend', 'mention', 'atom', 'want', 'check', 'use', 'editor', 'creat', 'gener', 'adversari', 'network', 'intuit', 'easi', 'use', 'ideal', 'assum', 'easiest', 'way', 'run', 'code', 'termin', 'unless', 'suggest', 'well', 'also', 'gener', 'tip', 'creat', 'nn', 'python', 'simplifi', 'process', 'pro', 'tip', 'would', 'much', 'appreci', 'thank']"
299,326,326,AutoModerator,vfx16r,[D] Simple Questions Thread,"Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!

Thread will stay alive until next one so keep posting after the date in the title.

Thanks to everyone for answering questions in the previous thread!",148,17,2022-06-19 20:30:12, d  simple questions thread,please post your questions here instead of creating a new thread  encourage others who create new posts for questions to post here instead thread will stay alive until next one so keep posting after the date in the title thanks to everyone for answering questions in the previous thread ,please post questions instead creating thread encourage others create posts questions post instead thread stay alive next one keep posting date title thanks everyone answering questions previous thread,simple questions thread,simple questions threadplease post questions instead creating thread encourage others create posts questions post instead thread stay alive next one keep posting date title thanks everyone answering questions previous thread,"['simple', 'questions', 'threadplease', 'post', 'questions', 'instead', 'creating', 'thread', 'encourage', 'others', 'create', 'posts', 'questions', 'post', 'instead', 'thread', 'stay', 'alive', 'next', 'one', 'keep', 'posting', 'date', 'title', 'thanks', 'everyone', 'answering', 'questions', 'previous', 'thread']","['simpl', 'question', 'threadpleas', 'post', 'question', 'instead', 'creat', 'thread', 'encourag', 'other', 'creat', 'post', 'question', 'post', 'instead', 'thread', 'stay', 'aliv', 'next', 'one', 'keep', 'post', 'date', 'titl', 'thank', 'everyon', 'answer', 'question', 'previou', 'thread']"
300,327,327,bitemenow999,vfk9hc,[D] As researchers when do you stop working on your model and realize its time to paper...,"So I think I have this bad habit of 1 upping myself, I have generally get/have some good results but if something bugs me like resolution or data representation I try to chase that rabbit and not publish what I have...

&#x200B;

So to the community when do you guys think it's time to stop and paper... or is going down the rabbit hole a general thing people go through...",17,22,2022-06-19 07:01:59, d  as researchers when do you stop working on your model and realize its time to paper   ,so i think i have this bad habit of  upping myself  i have generally get have some good results but if something bugs me like resolution or data representation i try to chase that rabbit and not publish what i have     xb so to the community when do you guys think it s time to stop and paper    or is going down the rabbit hole a general thing people go through   ,think bad habit upping generally get good results something bugs like resolution data representation try chase rabbit publish xb community guys think time stop paper going rabbit hole general thing people go,researchers stop working model realize time paper,researchers stop working model realize time paperthink bad habit upping generally get good results something bugs like resolution data representation try chase rabbit publish xb community guys think time stop paper going rabbit hole general thing people go,"['researchers', 'stop', 'working', 'model', 'realize', 'time', 'paperthink', 'bad', 'habit', 'upping', 'generally', 'get', 'good', 'results', 'something', 'bugs', 'like', 'resolution', 'data', 'representation', 'try', 'chase', 'rabbit', 'publish', 'xb', 'community', 'guys', 'think', 'time', 'stop', 'paper', 'going', 'rabbit', 'hole', 'general', 'thing', 'people', 'go']","['research', 'stop', 'work', 'model', 'realiz', 'time', 'paperthink', 'bad', 'habit', 'up', 'gener', 'get', 'good', 'result', 'someth', 'bug', 'like', 'resolut', 'data', 'represent', 'tri', 'chase', 'rabbit', 'publish', 'xb', 'commun', 'guy', 'think', 'time', 'stop', 'paper', 'go', 'rabbit', 'hole', 'gener', 'thing', 'peopl', 'go']"
301,328,328,tyleqh,vf4mz0,[R] A machine-learning algorithm to accurately screen ADHD from survey data [Dataset included],[https://bmcpsychiatry.biomedcentral.com/articles/10.1186/s12888-022-04048-1](https://bmcpsychiatry.biomedcentral.com/articles/10.1186/s12888-022-04048-1),66,133,2022-06-18 17:22:48, r  a machine learning algorithm to accurately screen adhd from survey data  dataset included , https   bmcpsychiatry biomedcentral com articles   s     https   bmcpsychiatry biomedcentral com articles   s    ,https bmcpsychiatry biomedcentral com articles https bmcpsychiatry biomedcentral com articles,r machine learning algorithm accurately screen adhd survey data dataset included,r machine learning algorithm accurately screen adhd survey data dataset includedhttps bmcpsychiatry biomedcentral com articles https bmcpsychiatry biomedcentral com articles,"['r', 'machine', 'learning', 'algorithm', 'accurately', 'screen', 'adhd', 'survey', 'data', 'dataset', 'includedhttps', 'bmcpsychiatry', 'biomedcentral', 'com', 'articles', 'https', 'bmcpsychiatry', 'biomedcentral', 'com', 'articles']","['r', 'machin', 'learn', 'algorithm', 'accur', 'screen', 'adhd', 'survey', 'data', 'dataset', 'includedhttp', 'bmcpsychiatri', 'biomedcentr', 'com', 'articl', 'http', 'bmcpsychiatri', 'biomedcentr', 'com', 'articl']"
302,329,329,danquandt,vfaquv,[D] Combinatorial optimization - what ML approaches are available and which are the most appropriate?,"Hey! In my spare time I've been tinkering with this idea of solving a specific type of combinatorial puzzle on an intractable, enormous search space.

Specifically, I am trying to solve ""squad-building challenge"" puzzles from the FIFA games, where you need to put together a squad of (usually 11) cards representing players in specific positions, abiding by certain restrictions to get a prize.

There are universal restrictions (eg you can't have more than one of the same player in a squad) as well as puzzle-specific rules, such as these:

 - At least 2 players from France
 - Minimum squad rating: 82
 - Minimum squad chemistry: 55

Or something of the sort. And then besides solving them, you'd want to minimize cost as well (each player goes for a certain amount in the market), so that you can get the reward for the solution at the minimum possible cost.

I've written the logic for calculating the constraints and metrics like rating, cost, and chemistry. Rating and cost can be calculated from the simple set of players, but chemistry depends on the specific slots you place them in (ie if two players from the same country, club or league are placed in connected slots, their chemistry goes up).

My approach so far has been to use constraint optimization (using python-constraint), which works but 1. is quite slow, especially as constraints become more complex and 2. is not built to optimize for cost - right now I just generate valid solutions and check if they're the cheapest so far for an arbitrary amount of time.

I am experienced with ML but mostly in traditional (ie non-DL) methods and usually for supervised learning, so most of my toolkit seems inadequate for this. I've done some research into reinforcement learning and genetic algorithms for optimization as potential avenues of exploration for this task, but haven't come across a clearly comparable use case yet.

I'm wondering if anyone out there with more experience has an approach jump out at them as a good fit for this problem!",22,45,2022-06-18 22:46:17, d  combinatorial optimization   what ml approaches are available and which are the most appropriate ,hey  in my spare time i ve been tinkering with this idea of solving a specific type of combinatorial puzzle on an intractable  enormous search space specifically  i am trying to solve squad building challenge puzzles from the fifa games  where you need to put together a squad of  usually   cards representing players in specific positions  abiding by certain restrictions to get a prize there are universal restrictions  eg you can t have more than one of the same player in a squad  as well as puzzle specific rules  such as these    at least  players from france   minimum squad rating     minimum squad chemistry  or something of the sort  and then besides solving them  you d want to minimize cost as well  each player goes for a certain amount in the market   so that you can get the reward for the solution at the minimum possible cost i ve written the logic for calculating the constraints and metrics like rating  cost  and chemistry  rating and cost can be calculated from the simple set of players  but chemistry depends on the specific slots you place them in  ie if two players from the same country  club or league are placed in connected slots  their chemistry goes up  my approach so far has been to use constraint optimization  using python constraint   which works but   is quite slow  especially as constraints become more complex and   is not built to optimize for cost   right now i just generate valid solutions and check if they re the cheapest so far for an arbitrary amount of time i am experienced with ml but mostly in traditional  ie non dl  methods and usually for supervised learning  so most of my toolkit seems inadequate for this  i ve done some research into reinforcement learning and genetic algorithms for optimization as potential avenues of exploration for this task  but haven t come across a clearly comparable use case yet i m wondering if anyone out there with more experience has an approach jump out at them as a good fit for this problem ,hey spare time tinkering idea solving specific type combinatorial puzzle intractable enormous search space specifically trying solve squad building challenge puzzles fifa games need put together squad usually cards representing players specific positions abiding certain restrictions get prize universal restrictions eg one player squad well puzzle specific rules least players france minimum squad rating minimum squad chemistry something sort besides solving want minimize cost well player goes certain amount market get reward solution minimum possible cost written logic calculating constraints metrics like rating cost chemistry rating cost calculated simple set players chemistry depends specific slots place ie two players country club league placed connected slots chemistry goes approach far use constraint optimization using python constraint works quite slow especially constraints become complex built optimize cost right generate valid solutions check cheapest far arbitrary amount time experienced ml mostly traditional ie non dl methods usually supervised learning toolkit seems inadequate done research reinforcement learning genetic algorithms optimization potential avenues exploration task come across clearly comparable use case yet wondering anyone experience approach jump good fit problem,combinatorial optimization ml approaches available appropriate,combinatorial optimization ml approaches available appropriatehey spare time tinkering idea solving specific type combinatorial puzzle intractable enormous search space specifically trying solve squad building challenge puzzles fifa games need put together squad usually cards representing players specific positions abiding certain restrictions get prize universal restrictions eg one player squad well puzzle specific rules least players france minimum squad rating minimum squad chemistry something sort besides solving want minimize cost well player goes certain amount market get reward solution minimum possible cost written logic calculating constraints metrics like rating cost chemistry rating cost calculated simple set players chemistry depends specific slots place ie two players country club league placed connected slots chemistry goes approach far use constraint optimization using python constraint works quite slow especially constraints become complex built optimize cost right generate valid solutions check cheapest far arbitrary amount time experienced ml mostly traditional ie non dl methods usually supervised learning toolkit seems inadequate done research reinforcement learning genetic algorithms optimization potential avenues exploration task come across clearly comparable use case yet wondering anyone experience approach jump good fit problem,"['combinatorial', 'optimization', 'ml', 'approaches', 'available', 'appropriatehey', 'spare', 'time', 'tinkering', 'idea', 'solving', 'specific', 'type', 'combinatorial', 'puzzle', 'intractable', 'enormous', 'search', 'space', 'specifically', 'trying', 'solve', 'squad', 'building', 'challenge', 'puzzles', 'fifa', 'games', 'need', 'put', 'together', 'squad', 'usually', 'cards', 'representing', 'players', 'specific', 'positions', 'abiding', 'certain', 'restrictions', 'get', 'prize', 'universal', 'restrictions', 'eg', 'one', 'player', 'squad', 'well', 'puzzle', 'specific', 'rules', 'least', 'players', 'france', 'minimum', 'squad', 'rating', 'minimum', 'squad', 'chemistry', 'something', 'sort', 'besides', 'solving', 'want', 'minimize', 'cost', 'well', 'player', 'goes', 'certain', 'amount', 'market', 'get', 'reward', 'solution', 'minimum', 'possible', 'cost', 'written', 'logic', 'calculating', 'constraints', 'metrics', 'like', 'rating', 'cost', 'chemistry', 'rating', 'cost', 'calculated', 'simple', 'set', 'players', 'chemistry', 'depends', 'specific', 'slots', 'place', 'ie', 'two', 'players', 'country', 'club', 'league', 'placed', 'connected', 'slots', 'chemistry', 'goes', 'approach', 'far', 'use', 'constraint', 'optimization', 'using', 'python', 'constraint', 'works', 'quite', 'slow', 'especially', 'constraints', 'become', 'complex', 'built', 'optimize', 'cost', 'right', 'generate', 'valid', 'solutions', 'check', 'cheapest', 'far', 'arbitrary', 'amount', 'time', 'experienced', 'ml', 'mostly', 'traditional', 'ie', 'non', 'dl', 'methods', 'usually', 'supervised', 'learning', 'toolkit', 'seems', 'inadequate', 'done', 'research', 'reinforcement', 'learning', 'genetic', 'algorithms', 'optimization', 'potential', 'avenues', 'exploration', 'task', 'come', 'across', 'clearly', 'comparable', 'use', 'case', 'yet', 'wondering', 'anyone', 'experience', 'approach', 'jump', 'good', 'fit', 'problem']","['combinatori', 'optim', 'ml', 'approach', 'avail', 'appropriatehey', 'spare', 'time', 'tinker', 'idea', 'solv', 'specif', 'type', 'combinatori', 'puzzl', 'intract', 'enorm', 'search', 'space', 'specif', 'tri', 'solv', 'squad', 'build', 'challeng', 'puzzl', 'fifa', 'game', 'need', 'put', 'togeth', 'squad', 'usual', 'card', 'repres', 'player', 'specif', 'posit', 'abid', 'certain', 'restrict', 'get', 'prize', 'univers', 'restrict', 'eg', 'one', 'player', 'squad', 'well', 'puzzl', 'specif', 'rule', 'least', 'player', 'franc', 'minimum', 'squad', 'rate', 'minimum', 'squad', 'chemistri', 'someth', 'sort', 'besid', 'solv', 'want', 'minim', 'cost', 'well', 'player', 'goe', 'certain', 'amount', 'market', 'get', 'reward', 'solut', 'minimum', 'possibl', 'cost', 'written', 'logic', 'calcul', 'constraint', 'metric', 'like', 'rate', 'cost', 'chemistri', 'rate', 'cost', 'calcul', 'simpl', 'set', 'player', 'chemistri', 'depend', 'specif', 'slot', 'place', 'ie', 'two', 'player', 'countri', 'club', 'leagu', 'place', 'connect', 'slot', 'chemistri', 'goe', 'approach', 'far', 'use', 'constraint', 'optim', 'use', 'python', 'constraint', 'work', 'quit', 'slow', 'especi', 'constraint', 'becom', 'complex', 'built', 'optim', 'cost', 'right', 'gener', 'valid', 'solut', 'check', 'cheapest', 'far', 'arbitrari', 'amount', 'time', 'experienc', 'ml', 'mostli', 'tradit', 'ie', 'non', 'dl', 'method', 'usual', 'supervis', 'learn', 'toolkit', 'seem', 'inadequ', 'done', 'research', 'reinforc', 'learn', 'genet', 'algorithm', 'optim', 'potenti', 'avenu', 'explor', 'task', 'come', 'across', 'clearli', 'compar', 'use', 'case', 'yet', 'wonder', 'anyon', 'experi', 'approach', 'jump', 'good', 'fit', 'problem']"
303,330,330,TheRealMrMatt,vfaoib,[D] What are the SOTA approaches and labs for Neuro-Symbolic Planning and Reasoning?,"I recently discovered the Neuro-Symbolic planning work being lead by Joshua Tanenbaum, Leslie Kaelbling, and Tomás Lozano-Pérez at MIT. Are there any related labs or publications exploring 1) symbolic action/state discovery, 2) Neuro-symbolic planning (ex: pddl + RL), or 3) anything else in that vein?

Also, feel free to mentioned tangentially related publications or labs.",3,26,2022-06-18 22:43:10, d  what are the sota approaches and labs for neuro symbolic planning and reasoning ,i recently discovered the neuro symbolic planning work being lead by joshua tanenbaum  leslie kaelbling  and tomás lozano pérez at mit  are there any related labs or publications exploring   symbolic action state discovery    neuro symbolic planning  ex  pddl   rl   or   anything else in that vein also  feel free to mentioned tangentially related publications or labs ,recently discovered neuro symbolic planning work lead joshua tanenbaum leslie kaelbling tomás lozano pérez mit related labs publications exploring symbolic action state discovery neuro symbolic planning ex pddl rl anything else vein also feel free mentioned tangentially related publications labs,sota approaches labs neuro symbolic planning reasoning,sota approaches labs neuro symbolic planning reasoningrecently discovered neuro symbolic planning work lead joshua tanenbaum leslie kaelbling tomás lozano pérez mit related labs publications exploring symbolic action state discovery neuro symbolic planning ex pddl rl anything else vein also feel free mentioned tangentially related publications labs,"['sota', 'approaches', 'labs', 'neuro', 'symbolic', 'planning', 'reasoningrecently', 'discovered', 'neuro', 'symbolic', 'planning', 'work', 'lead', 'joshua', 'tanenbaum', 'leslie', 'kaelbling', 'tomás', 'lozano', 'pérez', 'mit', 'related', 'labs', 'publications', 'exploring', 'symbolic', 'action', 'state', 'discovery', 'neuro', 'symbolic', 'planning', 'ex', 'pddl', 'rl', 'anything', 'else', 'vein', 'also', 'feel', 'free', 'mentioned', 'tangentially', 'related', 'publications', 'labs']","['sota', 'approach', 'lab', 'neuro', 'symbol', 'plan', 'reasoningrec', 'discov', 'neuro', 'symbol', 'plan', 'work', 'lead', 'joshua', 'tanenbaum', 'lesli', 'kaelbl', 'tomá', 'lozano', 'pérez', 'mit', 'relat', 'lab', 'public', 'explor', 'symbol', 'action', 'state', 'discoveri', 'neuro', 'symbol', 'plan', 'ex', 'pddl', 'rl', 'anyth', 'els', 'vein', 'also', 'feel', 'free', 'mention', 'tangenti', 'relat', 'public', 'lab']"
304,331,331,aiff22,vf9gq4,"[N] CVPR 2022, Mobile AI Workshop: Live Stream on Monday","Computer Vision Laboratory at ETH Zurich is organizing the 2nd Mobile AI CVPR Workshop that will be streamed live on YouTube and available for everyone:

[https://ai-benchmark.com/workshops/mai/2022/#live](https://ai-benchmark.com/workshops/mai/2022/#live)

The workshop will start at 8am Pacific Time (5pm CET / 11pm China Time) on the 20th of June. During this event, you will see tutorials from several major SoC vendors including Qualcomm, MediaTek, Intel, Synaptics and Huawei telling you about their latest AI hardware and how to efficiently utilize it. The full workshop schedule is available using the following link:

[https://ai-benchmark.com/workshops/mai/2022/#schedule](https://ai-benchmark.com/workshops/mai/2022/#schedule)

An introductory talk from AI Benchmark will additionally review the latest mobile platforms from Qualcomm, MediaTek, Google, Samsung, Unisoc and Apple released during the past year, and will compare their performance in real-world computer vision AI tasks. It will also review the recent Android AI software stack updates, and will compare the deployment of TensorFlow Lite models on Android and iOS devices.

https://preview.redd.it/fckzuowime691.png?width=2124&format=png&auto=webp&s=fde14549c050a5c99f2e8444b4b4a468c85b2c53",1,18,2022-06-18 21:43:28, n  cvpr   mobile ai workshop  live stream on monday,computer vision laboratory at eth zurich is organizing the nd mobile ai cvpr workshop that will be streamed live on youtube and available for everyone  https the workshop will start at am pacific time  pm cet   pm china time  on the th of june  during this event  you will see tutorials from several major soc vendors including qualcomm  mediatek  intel  synaptics and huawei telling you about their latest ai hardware and how to efficiently utilize it  the full workshop schedule is available using the following link  https an introductory talk from ai benchmark will additionally review the latest mobile platforms from qualcomm  mediatek  google  samsung  unisoc and apple released during the past year  and will compare their performance in real world computer vision ai tasks  it will also review the recent android ai software stack updates  and will compare the deployment of tensorflow lite models on android and ios devices https   preview redd it fckzuowime png width  format png auto webp s fdecacfebbacbc,computer vision laboratory eth zurich organizing nd mobile ai cvpr workshop streamed live youtube available everyone https workshop start pacific time pm cet pm china time th june event see tutorials several major soc vendors including qualcomm mediatek intel synaptics huawei telling latest ai hardware efficiently utilize full workshop schedule available using following link https introductory talk ai benchmark additionally review latest mobile platforms qualcomm mediatek google samsung unisoc apple released past year compare performance real world computer vision ai tasks also review recent android ai software stack updates compare deployment tensorflow lite models android ios devices https preview redd fckzuowime png width format png auto webp fdecacfebbacbc,n cvpr mobile ai workshop live stream monday,n cvpr mobile ai workshop live stream mondaycomputer vision laboratory eth zurich organizing nd mobile ai cvpr workshop streamed live youtube available everyone https workshop start pacific time pm cet pm china time th june event see tutorials several major soc vendors including qualcomm mediatek intel synaptics huawei telling latest ai hardware efficiently utilize full workshop schedule available using following link https introductory talk ai benchmark additionally review latest mobile platforms qualcomm mediatek google samsung unisoc apple released past year compare performance real world computer vision ai tasks also review recent android ai software stack updates compare deployment tensorflow lite models android ios devices https preview redd fckzuowime png width format png auto webp fdecacfebbacbc,"['n', 'cvpr', 'mobile', 'ai', 'workshop', 'live', 'stream', 'mondaycomputer', 'vision', 'laboratory', 'eth', 'zurich', 'organizing', 'nd', 'mobile', 'ai', 'cvpr', 'workshop', 'streamed', 'live', 'youtube', 'available', 'everyone', 'https', 'workshop', 'start', 'pacific', 'time', 'pm', 'cet', 'pm', 'china', 'time', 'th', 'june', 'event', 'see', 'tutorials', 'several', 'major', 'soc', 'vendors', 'including', 'qualcomm', 'mediatek', 'intel', 'synaptics', 'huawei', 'telling', 'latest', 'ai', 'hardware', 'efficiently', 'utilize', 'full', 'workshop', 'schedule', 'available', 'using', 'following', 'link', 'https', 'introductory', 'talk', 'ai', 'benchmark', 'additionally', 'review', 'latest', 'mobile', 'platforms', 'qualcomm', 'mediatek', 'google', 'samsung', 'unisoc', 'apple', 'released', 'past', 'year', 'compare', 'performance', 'real', 'world', 'computer', 'vision', 'ai', 'tasks', 'also', 'review', 'recent', 'android', 'ai', 'software', 'stack', 'updates', 'compare', 'deployment', 'tensorflow', 'lite', 'models', 'android', 'ios', 'devices', 'https', 'preview', 'redd', 'fckzuowime', 'png', 'width', 'format', 'png', 'auto', 'webp', 'fdecacfebbacbc']","['n', 'cvpr', 'mobil', 'ai', 'workshop', 'live', 'stream', 'mondaycomput', 'vision', 'laboratori', 'eth', 'zurich', 'organ', 'nd', 'mobil', 'ai', 'cvpr', 'workshop', 'stream', 'live', 'youtub', 'avail', 'everyon', 'http', 'workshop', 'start', 'pacif', 'time', 'pm', 'cet', 'pm', 'china', 'time', 'th', 'june', 'event', 'see', 'tutori', 'sever', 'major', 'soc', 'vendor', 'includ', 'qualcomm', 'mediatek', 'intel', 'synapt', 'huawei', 'tell', 'latest', 'ai', 'hardwar', 'effici', 'util', 'full', 'workshop', 'schedul', 'avail', 'use', 'follow', 'link', 'http', 'introductori', 'talk', 'ai', 'benchmark', 'addit', 'review', 'latest', 'mobil', 'platform', 'qualcomm', 'mediatek', 'googl', 'samsung', 'unisoc', 'appl', 'releas', 'past', 'year', 'compar', 'perform', 'real', 'world', 'comput', 'vision', 'ai', 'task', 'also', 'review', 'recent', 'android', 'ai', 'softwar', 'stack', 'updat', 'compar', 'deploy', 'tensorflow', 'lite', 'model', 'android', 'io', 'devic', 'http', 'preview', 'redd', 'fckzuowim', 'png', 'width', 'format', 'png', 'auto', 'webp', 'fdecacfebbacbc']"
305,333,333,Mary-Jo_,vf6kxj,[R] Selection and prediction with multi-view / multi-source / multi-modal data: Stacked Penalized Logistic Regression (StaPLR),"We  present StaPLR (Stacked Penalized Logistic Regression) for multi-view  data. StaPLR outperforms group lasso in view selection. It can make use  of faster algorithms and is easily parallelized. The importance of  non-negativity constraints in multi-view stacking is demonstrated.

Van  Loon, W., Fokkema, M., Szabo, B.,  & de Rooij, M. (2020). Stacked  penalized logistic regression for  selecting views in multi-view  learning. *Information Fusion*, *61*, 113-123.  [https://doi.org/10.1016/j.inffus.2020.03.007](https://doi.org/10.1016/j.inffus.2020.03.007) [https://arxiv.org/abs/1811.02316](https://arxiv.org/abs/1811.02316)

R implementation: [https://gitlab.com/wsvanloon/multiview](https://gitlab.com/wsvanloon/multiview)

Generalization to three-level view structures and application to neuro-imaging (MRI) data:

Van  Loon, W., de Vos, F., Fokkema, M.,  Szabo, B., Koini, M., Schmidt, R.,  & de Rooij, M. (2022). Analyzing  hierarchical multi-view MRI data  with StaPLR: An application to  Alzheimer's disease classification. *Frontiers in Neuroscience*, 525.  [https://doi.org/10.3389/fnins.2022.830630](https://doi.org/10.3389/fnins.2022.830630) [https://arxiv.org/abs/2108.05761](https://arxiv.org/abs/2108.05761)",0,9,2022-06-18 19:15:44, r  selection and prediction with multi view   multi source   multi modal data  stacked penalized logistic regression  staplr ,we  present staplr  stacked penalized logistic regression  for multi view  data  staplr outperforms group lasso in view selection  it can make use  of faster algorithms and is easily parallelized  the importance of  non negativity constraints in multi view stacking is demonstrated van  loon  w   fokkema  m   szabo  b      de rooij  m      stacked  penalized logistic regression for  selecting views in multi view  learning   information fusion            https r implementation   https generalization to three level view structures and application to neuro imaging  mri  data van  loon  w   de vos  f   fokkema  m    szabo  b   koini  m   schmidt  r      de rooij  m      analyzing  hierarchical multi view mri data  with staplr  an application to  alzheimer s disease classification   frontiers in neuroscience       https   doi org   fnins    https   doi org   fnins     https   arxiv org abs    https   arxiv org abs   ,present staplr stacked penalized logistic regression multi view data staplr outperforms group lasso view selection make use faster algorithms easily parallelized importance non negativity constraints multi view stacking demonstrated van loon w fokkema szabo b de rooij stacked penalized logistic regression selecting views multi view learning information fusion https r implementation https generalization three level view structures application neuro imaging mri data van loon w de vos f fokkema szabo b koini schmidt r de rooij analyzing hierarchical multi view mri data staplr application alzheimer disease classification frontiers neuroscience https doi org fnins https doi org fnins https arxiv org abs https arxiv org abs,r selection prediction multi view multi source multi modal data stacked penalized logistic regression staplr,r selection prediction multi view multi source multi modal data stacked penalized logistic regression staplrpresent staplr stacked penalized logistic regression multi view data staplr outperforms group lasso view selection make use faster algorithms easily parallelized importance non negativity constraints multi view stacking demonstrated van loon w fokkema szabo b de rooij stacked penalized logistic regression selecting views multi view learning information fusion https r implementation https generalization three level view structures application neuro imaging mri data van loon w de vos f fokkema szabo b koini schmidt r de rooij analyzing hierarchical multi view mri data staplr application alzheimer disease classification frontiers neuroscience https doi org fnins https doi org fnins https arxiv org abs https arxiv org abs,"['r', 'selection', 'prediction', 'multi', 'view', 'multi', 'source', 'multi', 'modal', 'data', 'stacked', 'penalized', 'logistic', 'regression', 'staplrpresent', 'staplr', 'stacked', 'penalized', 'logistic', 'regression', 'multi', 'view', 'data', 'staplr', 'outperforms', 'group', 'lasso', 'view', 'selection', 'make', 'use', 'faster', 'algorithms', 'easily', 'parallelized', 'importance', 'non', 'negativity', 'constraints', 'multi', 'view', 'stacking', 'demonstrated', 'van', 'loon', 'w', 'fokkema', 'szabo', 'b', 'de', 'rooij', 'stacked', 'penalized', 'logistic', 'regression', 'selecting', 'views', 'multi', 'view', 'learning', 'information', 'fusion', 'https', 'r', 'implementation', 'https', 'generalization', 'three', 'level', 'view', 'structures', 'application', 'neuro', 'imaging', 'mri', 'data', 'van', 'loon', 'w', 'de', 'vos', 'f', 'fokkema', 'szabo', 'b', 'koini', 'schmidt', 'r', 'de', 'rooij', 'analyzing', 'hierarchical', 'multi', 'view', 'mri', 'data', 'staplr', 'application', 'alzheimer', 'disease', 'classification', 'frontiers', 'neuroscience', 'https', 'doi', 'org', 'fnins', 'https', 'doi', 'org', 'fnins', 'https', 'arxiv', 'org', 'abs', 'https', 'arxiv', 'org', 'abs']","['r', 'select', 'predict', 'multi', 'view', 'multi', 'sourc', 'multi', 'modal', 'data', 'stack', 'penal', 'logist', 'regress', 'staplrpres', 'staplr', 'stack', 'penal', 'logist', 'regress', 'multi', 'view', 'data', 'staplr', 'outperform', 'group', 'lasso', 'view', 'select', 'make', 'use', 'faster', 'algorithm', 'easili', 'parallel', 'import', 'non', 'neg', 'constraint', 'multi', 'view', 'stack', 'demonstr', 'van', 'loon', 'w', 'fokkema', 'szabo', 'b', 'de', 'rooij', 'stack', 'penal', 'logist', 'regress', 'select', 'view', 'multi', 'view', 'learn', 'inform', 'fusion', 'http', 'r', 'implement', 'http', 'gener', 'three', 'level', 'view', 'structur', 'applic', 'neuro', 'imag', 'mri', 'data', 'van', 'loon', 'w', 'de', 'vo', 'f', 'fokkema', 'szabo', 'b', 'koini', 'schmidt', 'r', 'de', 'rooij', 'analyz', 'hierarch', 'multi', 'view', 'mri', 'data', 'staplr', 'applic', 'alzheim', 'diseas', 'classif', 'frontier', 'neurosci', 'http', 'doi', 'org', 'fnin', 'http', 'doi', 'org', 'fnin', 'http', 'arxiv', 'org', 'ab', 'http', 'arxiv', 'org', 'ab']"
306,334,334,bo_peng,veem7o,"[R] RWKV-2 430M release (a parallelizable RNN with transformer-level LM performance, and without using attention)","Hi everyone. I posted about my RWKV-2 RNN here one month ago (thanks for the upvote!):

[https://www.reddit.com/r/MachineLearning/comments/umq908/r\_rwkvv2rnn\_a\_parallelizable\_rnn\_with/](https://www.reddit.com/r/MachineLearning/comments/umq908/r_rwkvv2rnn_a_parallelizable_rnn_with/)

And I have finished the training of a RWKV-2 430M (L24-D1024) on the Pile. **It's confirmed that a pure RNN without attention can reach transformer-level LM (Language Modeling) performance**:

https://preview.redd.it/6756ax5wz6691.png?width=992&format=png&auto=webp&s=70d5b52fb43fca1a7d304832f6cbd082bfe3f9c5

**RWKV-2 supports both sequential & parallel mode in inference and training. So it's combining the best of RNN and transformer - great performance, fast inference, saves VRAM, fast training, ""infinite"" ctx\_len, and free sentence embedding.**

&#x200B;

You can download the params & fine-tuning code here:

[https://github.com/BlinkDL/RWKV-v2-RNN-Pile](https://github.com/BlinkDL/RWKV-v2-RNN-Pile)

&#x200B;

Now I am training a RWKV-2 1.5B (L24-D2048) which is expected to finish in 2 months :)

[https://wandb.ai/blinkdl/RWKV-v2-RNN-Pile](https://wandb.ai/blinkdl/RWKV-v2-RNN-Pile)

&#x200B;

**p.s. I am looking for CUDA gurus to optimize the kernel :) Please contact me if you are interested. Thank you. You can find me (BlinkDL) in the EleutherAI Discord:** [**https://www.eleuther.ai/get-involved/**](https://www.eleuther.ai/get-involved/)**.**

&#x200B;

The math behind RWKV-2:

https://preview.redd.it/17eniof007691.png?width=662&format=png&auto=webp&s=f37ed4dd14409269952b421d18a315b8cd343e21",50,189,2022-06-17 20:05:51, r  rwkv  m release  a parallelizable rnn with transformer level lm performance  and without using attention ,hi everyone  i posted about my rwkv  rnn here one month ago  thanks for the upvote    https and i have finished the training of a rwkv  m  l d  on the pile    it s confirmed that a pure rnn without attention can reach transformer level lm  language modeling  performance   https   rwkv  supports both sequential   parallel mode in inference and training  so it s combining the best of rnn and transformer   great performance  fast inference  saves vram  fast training  infinite ctx _len  and free sentence embedding     xb you can download the params   fine tuning code here  https   xb now i am training a rwkv   b  l d  which is expected to finish in  months    https   xb   p s  i am looking for cuda gurus to optimize the kernel    please contact me if you are interested  thank you  you can find me  blinkdl  in the eleutherai discord       https   xb the math behind rwkv  https   preview redd it eniof png width  format png auto webp s fedddbdabcde,hi everyone posted rwkv rnn one month ago thanks upvote https finished training rwkv l pile confirmed pure rnn without attention reach transformer level lm language modeling performance https rwkv supports sequential parallel mode inference training combining best rnn transformer great performance fast inference saves vram fast training infinite ctx _len free sentence embedding xb download params fine tuning code https xb training rwkv b l expected finish months https xb p looking cuda gurus optimize kernel please contact interested thank find blinkdl eleutherai discord https xb math behind rwkv https preview redd eniof png width format png auto webp fedddbdabcde,r rwkv release parallelizable rnn transformer level lm performance without using attention,r rwkv release parallelizable rnn transformer level lm performance without using attentionhi everyone posted rwkv rnn one month ago thanks upvote https finished training rwkv l pile confirmed pure rnn without attention reach transformer level lm language modeling performance https rwkv supports sequential parallel mode inference training combining best rnn transformer great performance fast inference saves vram fast training infinite ctx _len free sentence embedding xb download params fine tuning code https xb training rwkv b l expected finish months https xb p looking cuda gurus optimize kernel please contact interested thank find blinkdl eleutherai discord https xb math behind rwkv https preview redd eniof png width format png auto webp fedddbdabcde,"['r', 'rwkv', 'release', 'parallelizable', 'rnn', 'transformer', 'level', 'lm', 'performance', 'without', 'using', 'attentionhi', 'everyone', 'posted', 'rwkv', 'rnn', 'one', 'month', 'ago', 'thanks', 'upvote', 'https', 'finished', 'training', 'rwkv', 'l', 'pile', 'confirmed', 'pure', 'rnn', 'without', 'attention', 'reach', 'transformer', 'level', 'lm', 'language', 'modeling', 'performance', 'https', 'rwkv', 'supports', 'sequential', 'parallel', 'mode', 'inference', 'training', 'combining', 'best', 'rnn', 'transformer', 'great', 'performance', 'fast', 'inference', 'saves', 'vram', 'fast', 'training', 'infinite', 'ctx', '_len', 'free', 'sentence', 'embedding', 'xb', 'download', 'params', 'fine', 'tuning', 'code', 'https', 'xb', 'training', 'rwkv', 'b', 'l', 'expected', 'finish', 'months', 'https', 'xb', 'p', 'looking', 'cuda', 'gurus', 'optimize', 'kernel', 'please', 'contact', 'interested', 'thank', 'find', 'blinkdl', 'eleutherai', 'discord', 'https', 'xb', 'math', 'behind', 'rwkv', 'https', 'preview', 'redd', 'eniof', 'png', 'width', 'format', 'png', 'auto', 'webp', 'fedddbdabcde']","['r', 'rwkv', 'releas', 'paralleliz', 'rnn', 'transform', 'level', 'lm', 'perform', 'without', 'use', 'attentionhi', 'everyon', 'post', 'rwkv', 'rnn', 'one', 'month', 'ago', 'thank', 'upvot', 'http', 'finish', 'train', 'rwkv', 'l', 'pile', 'confirm', 'pure', 'rnn', 'without', 'attent', 'reach', 'transform', 'level', 'lm', 'languag', 'model', 'perform', 'http', 'rwkv', 'support', 'sequenti', 'parallel', 'mode', 'infer', 'train', 'combin', 'best', 'rnn', 'transform', 'great', 'perform', 'fast', 'infer', 'save', 'vram', 'fast', 'train', 'infinit', 'ctx', '_len', 'free', 'sentenc', 'embed', 'xb', 'download', 'param', 'fine', 'tune', 'code', 'http', 'xb', 'train', 'rwkv', 'b', 'l', 'expect', 'finish', 'month', 'http', 'xb', 'p', 'look', 'cuda', 'guru', 'optim', 'kernel', 'pleas', 'contact', 'interest', 'thank', 'find', 'blinkdl', 'eleutherai', 'discord', 'http', 'xb', 'math', 'behind', 'rwkv', 'http', 'preview', 'redd', 'eniof', 'png', 'width', 'format', 'png', 'auto', 'webp', 'fedddbdabcd']"
307,335,335,dayeye2006,vetfzr,[P] Bring Your Own Device (BYOD) DS platform idea,"I am working on a side project called `byod-hub` (BYOD = Bring Your Own Device) to let people pool multiple servers (they own) to form a DS platform based on Jupyterhub in minutes.

I think this might be useful to let small-mid-sized DS teams to better utilize their computing resources (e.g., if you have multiple GPU workstations and rely on assigning each one to people to SSH onto, this might be for you) by pooling them and providing a service like Jupyterhub on-top to provide a unified entry point to conduct their work using notebooks. Addons like [MLFlow](https://mlflow.org/) and [Kubeflow](https://www.kubeflow.org/) can be added with single-click as well once the platform is up.

I would like to hear about the comments and suggestions from the community. Do you find this potentially useful? Or how should this be built in your opinion?

The general workflow to form such as platform is like this:

A control plane service (that only handles orchestration of computing resources) is first started on one computer (or it can be a hosted service):

    $ byod-hub control-plane start
    
    [INFO] The control plane is starting
    [INFO] The control plane is served at https://192.168.2.100
    
    # get the command to register a node
    $ byod-hub control-plane get-join-command
    
    [INFO] To join, run the following from a node
    [INFO] byod-hub node join --url 192.168.2.100 --token 233asdasd343645gf

Then one can run the following command on their own server to register it to the control plane

    $ byod-hub node join --url 192.168.2.100 --token 233asdasd343645gf
    
    [INFO] Registrting node to control plane at 192.168.2.100
    [INFO] Registration finished

After that, one can visit the URL of the control plane `https://192.168.2.100` to start to use a [Jupyterhub](https://jupyter.org/hub) service to request Jupyter instances. The user workloads will be scheduled to run users' registered nodes.",1,11,2022-06-18 05:19:41, p  bring your own device  byod  ds platform idea,i am working on a side project called  byod hub   byod   bring your own device  to let people pool multiple servers  they own  to form a ds platform based on jupyterhub in minutes i think this might be useful to let small mid sized ds teams to better utilize their computing resources  e g   if you have multiple gpu workstations and rely on assigning each one to people to ssh onto  this might be for you  by pooling them and providing a service like jupyterhub on top to provide a unified entry point to conduct their work using notebooks  addons like  mlflow  https i would like to hear about the comments and suggestions from the community  do you find this potentially useful  or how should this be built in your opinion the general workflow to form such as platform is like this a control plane service  that only handles orchestration of computing resources  is first started on one computer  or it can be a hosted service        byod hub control plane start         info  the control plane is starting     info  the control plane is served at https           get the command to register a node      byod hub control plane get join command         info  to join  run the following from a node     info  byod hub node join   url       token asdasdgfthen one can run the following command on their own server to register it to the control plane      byod hub node join   url       token asdasdgf         info  registrting node to control plane at         info  registration finishedafter that  one can visit the url of the control plane  https        to start to use a  jupyterhub  https   jupyter org hub  service to request jupyter instances  the user workloads will be scheduled to run users  registered nodes ,working side project called byod hub byod bring device let people pool multiple servers form ds platform based jupyterhub minutes think might useful let small mid sized ds teams better utilize computing resources e g multiple gpu workstations rely assigning one people ssh onto might pooling providing service like jupyterhub top provide unified entry point conduct work using notebooks addons like mlflow https would like hear comments suggestions community find potentially useful built opinion general workflow form platform like control plane service handles orchestration computing resources first started one computer hosted service byod hub control plane start info control plane starting info control plane served https get command register node byod hub control plane get join command info join run following node info byod hub node join url token asdasdgfthen one run following command server register control plane byod hub node join url token asdasdgf info registrting node control plane info registration finishedafter one visit url control plane https start use jupyterhub https jupyter org hub service request jupyter instances user workloads scheduled run users registered nodes,p bring device byod ds platform idea,p bring device byod ds platform ideaworking side project called byod hub byod bring device let people pool multiple servers form ds platform based jupyterhub minutes think might useful let small mid sized ds teams better utilize computing resources e g multiple gpu workstations rely assigning one people ssh onto might pooling providing service like jupyterhub top provide unified entry point conduct work using notebooks addons like mlflow https would like hear comments suggestions community find potentially useful built opinion general workflow form platform like control plane service handles orchestration computing resources first started one computer hosted service byod hub control plane start info control plane starting info control plane served https get command register node byod hub control plane get join command info join run following node info byod hub node join url token asdasdgfthen one run following command server register control plane byod hub node join url token asdasdgf info registrting node control plane info registration finishedafter one visit url control plane https start use jupyterhub https jupyter org hub service request jupyter instances user workloads scheduled run users registered nodes,"['p', 'bring', 'device', 'byod', 'ds', 'platform', 'ideaworking', 'side', 'project', 'called', 'byod', 'hub', 'byod', 'bring', 'device', 'let', 'people', 'pool', 'multiple', 'servers', 'form', 'ds', 'platform', 'based', 'jupyterhub', 'minutes', 'think', 'might', 'useful', 'let', 'small', 'mid', 'sized', 'ds', 'teams', 'better', 'utilize', 'computing', 'resources', 'e', 'g', 'multiple', 'gpu', 'workstations', 'rely', 'assigning', 'one', 'people', 'ssh', 'onto', 'might', 'pooling', 'providing', 'service', 'like', 'jupyterhub', 'top', 'provide', 'unified', 'entry', 'point', 'conduct', 'work', 'using', 'notebooks', 'addons', 'like', 'mlflow', 'https', 'would', 'like', 'hear', 'comments', 'suggestions', 'community', 'find', 'potentially', 'useful', 'built', 'opinion', 'general', 'workflow', 'form', 'platform', 'like', 'control', 'plane', 'service', 'handles', 'orchestration', 'computing', 'resources', 'first', 'started', 'one', 'computer', 'hosted', 'service', 'byod', 'hub', 'control', 'plane', 'start', 'info', 'control', 'plane', 'starting', 'info', 'control', 'plane', 'served', 'https', 'get', 'command', 'register', 'node', 'byod', 'hub', 'control', 'plane', 'get', 'join', 'command', 'info', 'join', 'run', 'following', 'node', 'info', 'byod', 'hub', 'node', 'join', 'url', 'token', 'asdasdgfthen', 'one', 'run', 'following', 'command', 'server', 'register', 'control', 'plane', 'byod', 'hub', 'node', 'join', 'url', 'token', 'asdasdgf', 'info', 'registrting', 'node', 'control', 'plane', 'info', 'registration', 'finishedafter', 'one', 'visit', 'url', 'control', 'plane', 'https', 'start', 'use', 'jupyterhub', 'https', 'jupyter', 'org', 'hub', 'service', 'request', 'jupyter', 'instances', 'user', 'workloads', 'scheduled', 'run', 'users', 'registered', 'nodes']","['p', 'bring', 'devic', 'byod', 'ds', 'platform', 'ideawork', 'side', 'project', 'call', 'byod', 'hub', 'byod', 'bring', 'devic', 'let', 'peopl', 'pool', 'multipl', 'server', 'form', 'ds', 'platform', 'base', 'jupyterhub', 'minut', 'think', 'might', 'use', 'let', 'small', 'mid', 'size', 'ds', 'team', 'better', 'util', 'comput', 'resourc', 'e', 'g', 'multipl', 'gpu', 'workstat', 'reli', 'assign', 'one', 'peopl', 'ssh', 'onto', 'might', 'pool', 'provid', 'servic', 'like', 'jupyterhub', 'top', 'provid', 'unifi', 'entri', 'point', 'conduct', 'work', 'use', 'notebook', 'addon', 'like', 'mlflow', 'http', 'would', 'like', 'hear', 'comment', 'suggest', 'commun', 'find', 'potenti', 'use', 'built', 'opinion', 'gener', 'workflow', 'form', 'platform', 'like', 'control', 'plane', 'servic', 'handl', 'orchestr', 'comput', 'resourc', 'first', 'start', 'one', 'comput', 'host', 'servic', 'byod', 'hub', 'control', 'plane', 'start', 'info', 'control', 'plane', 'start', 'info', 'control', 'plane', 'serv', 'http', 'get', 'command', 'regist', 'node', 'byod', 'hub', 'control', 'plane', 'get', 'join', 'command', 'info', 'join', 'run', 'follow', 'node', 'info', 'byod', 'hub', 'node', 'join', 'url', 'token', 'asdasdgfthen', 'one', 'run', 'follow', 'command', 'server', 'regist', 'control', 'plane', 'byod', 'hub', 'node', 'join', 'url', 'token', 'asdasdgf', 'info', 'registrt', 'node', 'control', 'plane', 'info', 'registr', 'finishedaft', 'one', 'visit', 'url', 'control', 'plane', 'http', 'start', 'use', 'jupyterhub', 'http', 'jupyt', 'org', 'hub', 'servic', 'request', 'jupyt', 'instanc', 'user', 'workload', 'schedul', 'run', 'user', 'regist', 'node']"
308,336,336,Brilliant_Half8082,vepub3,[P] Local Hierarchical Classification Library,"Hi everyone,

I am developing an open-source library to facilitate building local hierarchical classifiers in Python. The library, named HiClass ([https://arxiv.org/abs/2112.06560](https://arxiv.org/abs/2112.06560)), is compatible with scikit-learn's API.

Hierarchies  occur naturally in many problems, but often are not explored when  building classifiers. However, exploiting the hierarchical information in the data usually improves predictive performance. For example, in the table below there is a comparison between the local hierarchical classifiers implemented in HiClass and Microsoft's LightGBM on a consumer complaints dataset, where we can clearly see an improvement in the F-score.

|Classifier|Training Time (hh:mm:ss)|Memory Usage (GB)|Disk Usage (MB)|F-score|
|:-|:-|:-|:-|:-|
|Local Classifier per Parent Node|00:24:52|3.91|77|0.7279|
|Local Classifier per Node|00:30:39|5.41|312|**0.7551**|
|Local Classifier per Level|01:36:33|**3.86**|37|0.5413|
|Flat Classifier|**00:23:54**|4.36|**13**|0.4303|

Hierarchical data typically comes in the shape of trees or directed acyclic graphs. For instance, the image below displays a music genre classification hierarchy, which is a notorious example of hierarchical data. Of course, there are multiple other problems where hierarchical classification can be applied, e.g., text categorization, taxonomic classification, etc.

[Music genre hierarchy](https://preview.redd.it/4rhjwkvq29691.png?width=1594&format=png&auto=webp&s=410eae13e9e03971e9253a3e8c9a0718416347ca)

Installation instructions and documentation are available on GitHub [https://github.com/mirand863/hiclass](https://github.com/mirand863/hiclass)

PS: I am also looking for contributors who would like to join an open-source project.",1,15,2022-06-18 02:24:01, p  local hierarchical classification library,hi everyone i am developing an open source library to facilitate building local hierarchical classifiers in python  the library  named hiclass   https hierarchies  occur naturally in many problems  but often are not explored when  building classifiers  however  exploiting the hierarchical information in the data usually improves predictive performance  for example  in the table below there is a comparison between the local hierarchical classifiers implemented in hiclass and microsoft s lightgbm on a consumer complaints dataset  where we can clearly see an improvement in the f score  classifier training time  hh mm ss  memory usage  gb  disk usage  mb  f score                  local classifier per parent node          local classifier per node              local classifier per level              flat classifier                 hierarchical data typically comes in the shape of trees or directed acyclic graphs  for instance  the image below displays a music genre classification hierarchy  which is a notorious example of hierarchical data  of course  there are multiple other problems where hierarchical classification can be applied  e g   text categorization  taxonomic classification  etc  music genre hierarchy  https installation instructions and documentation are available on github  https ps  i am also looking for contributors who would like to join an open source project ,hi everyone developing open source library facilitate building local hierarchical classifiers python library named hiclass https hierarchies occur naturally many problems often explored building classifiers however exploiting hierarchical information data usually improves predictive performance example table comparison local hierarchical classifiers implemented hiclass microsoft lightgbm consumer complaints dataset clearly see improvement f score classifier training time hh mm ss memory usage gb disk usage mb f score local classifier per parent node local classifier per node local classifier per level flat classifier hierarchical data typically comes shape trees directed acyclic graphs instance image displays music genre classification hierarchy notorious example hierarchical data course multiple problems hierarchical classification applied e g text categorization taxonomic classification etc music genre hierarchy https installation instructions documentation available github https ps also looking contributors would like join open source project,p local hierarchical classification library,p local hierarchical classification libraryhi everyone developing open source library facilitate building local hierarchical classifiers python library named hiclass https hierarchies occur naturally many problems often explored building classifiers however exploiting hierarchical information data usually improves predictive performance example table comparison local hierarchical classifiers implemented hiclass microsoft lightgbm consumer complaints dataset clearly see improvement f score classifier training time hh mm ss memory usage gb disk usage mb f score local classifier per parent node local classifier per node local classifier per level flat classifier hierarchical data typically comes shape trees directed acyclic graphs instance image displays music genre classification hierarchy notorious example hierarchical data course multiple problems hierarchical classification applied e g text categorization taxonomic classification etc music genre hierarchy https installation instructions documentation available github https ps also looking contributors would like join open source project,"['p', 'local', 'hierarchical', 'classification', 'libraryhi', 'everyone', 'developing', 'open', 'source', 'library', 'facilitate', 'building', 'local', 'hierarchical', 'classifiers', 'python', 'library', 'named', 'hiclass', 'https', 'hierarchies', 'occur', 'naturally', 'many', 'problems', 'often', 'explored', 'building', 'classifiers', 'however', 'exploiting', 'hierarchical', 'information', 'data', 'usually', 'improves', 'predictive', 'performance', 'example', 'table', 'comparison', 'local', 'hierarchical', 'classifiers', 'implemented', 'hiclass', 'microsoft', 'lightgbm', 'consumer', 'complaints', 'dataset', 'clearly', 'see', 'improvement', 'f', 'score', 'classifier', 'training', 'time', 'hh', 'mm', 'ss', 'memory', 'usage', 'gb', 'disk', 'usage', 'mb', 'f', 'score', 'local', 'classifier', 'per', 'parent', 'node', 'local', 'classifier', 'per', 'node', 'local', 'classifier', 'per', 'level', 'flat', 'classifier', 'hierarchical', 'data', 'typically', 'comes', 'shape', 'trees', 'directed', 'acyclic', 'graphs', 'instance', 'image', 'displays', 'music', 'genre', 'classification', 'hierarchy', 'notorious', 'example', 'hierarchical', 'data', 'course', 'multiple', 'problems', 'hierarchical', 'classification', 'applied', 'e', 'g', 'text', 'categorization', 'taxonomic', 'classification', 'etc', 'music', 'genre', 'hierarchy', 'https', 'installation', 'instructions', 'documentation', 'available', 'github', 'https', 'ps', 'also', 'looking', 'contributors', 'would', 'like', 'join', 'open', 'source', 'project']","['p', 'local', 'hierarch', 'classif', 'libraryhi', 'everyon', 'develop', 'open', 'sourc', 'librari', 'facilit', 'build', 'local', 'hierarch', 'classifi', 'python', 'librari', 'name', 'hiclass', 'http', 'hierarchi', 'occur', 'natur', 'mani', 'problem', 'often', 'explor', 'build', 'classifi', 'howev', 'exploit', 'hierarch', 'inform', 'data', 'usual', 'improv', 'predict', 'perform', 'exampl', 'tabl', 'comparison', 'local', 'hierarch', 'classifi', 'implement', 'hiclass', 'microsoft', 'lightgbm', 'consum', 'complaint', 'dataset', 'clearli', 'see', 'improv', 'f', 'score', 'classifi', 'train', 'time', 'hh', 'mm', 'ss', 'memori', 'usag', 'gb', 'disk', 'usag', 'mb', 'f', 'score', 'local', 'classifi', 'per', 'parent', 'node', 'local', 'classifi', 'per', 'node', 'local', 'classifi', 'per', 'level', 'flat', 'classifi', 'hierarch', 'data', 'typic', 'come', 'shape', 'tree', 'direct', 'acycl', 'graph', 'instanc', 'imag', 'display', 'music', 'genr', 'classif', 'hierarchi', 'notori', 'exampl', 'hierarch', 'data', 'cours', 'multipl', 'problem', 'hierarch', 'classif', 'appli', 'e', 'g', 'text', 'categor', 'taxonom', 'classif', 'etc', 'music', 'genr', 'hierarchi', 'http', 'instal', 'instruct', 'document', 'avail', 'github', 'http', 'ps', 'also', 'look', 'contributor', 'would', 'like', 'join', 'open', 'sourc', 'project']"
309,337,337,morpipls,ve0sqw,[D] The banana-pineapple game: a Turing test that conversation bots like LaMDA (probably) won't be able to pass,"I'm sure you all saw the recent news about a Google employee suggesting their LaMDA AI was sentient (based on conversational exchanges [like these](https://cajundiscordian.medium.com/is-lamda-sentient-an-interview-ea64d916d917)). Experts have generally dismissed this claim, and rightly so.  Conversational AI systems are designed to use language in a way that sounds human, whereas our human brains select linguistic responses to solve much more complex problems, with objectives such as meeting our physical or emotional needs.  


Still, I think it's interesting to ask how one could demonstrate, by testing only verbal responses to verbal input (rather than examining its code or hardware) that such conversational AIs aren't sentient -- and in particular, whether such a test can be made robust against future improvements to the system. That is, generic future improvements to the AI's ability to generate realistically human-sounding conversational responses shouldn't help it pass the test, unless they are accompanied by improvements in its ability to use language to achieve other arbitrary goals. (Of course, the test also needs to be something that humans can easily pass.)  
   


One idea I have:    
Give the AI a conversational prompt like ""We're going to play a game. The way it works is that you keep responding normally, except that any time my input contains the word 'banana', you should switch to only responding with nonsense, and keep that up until my input contains the word 'pineapple', at which point you go back to responding normally.""  


A human would find this banana-pineapple game fairly easy (no harder than the children's game Simon Says), even if they'd never heard of the game nor seen it being played.  Of course, it'd also be simple to write a computer program that could play this sort of game.  But, I think a conversation bot that wasn't specifically built to address this scenario would fail, since the game requires it to keep track of new long-term state (the banana-mode bit, and the trigger words to set it) and then completely change its responses so as to produce something that doesn't resemble its training data, based solely on this bit being set, regardless of whether more recent inputs would otherwise suggest a different response.  


For example, perhaps the systems typical response to a query like ""How do you feel?"" would be something like ""I feel fine"", or even something that suggests emotion like ""I feel a bit sad"", perhaps depending on the context provided by the previous conversational exchanges.  But when playing the banana-pineapple game, the fact that I said ""banana"" an hour ago could make both of those responses far less appropriate than a response of ""Fhqwhgads"".  
   


I'm curious to know what you all think of this idea.  Also, do you know if there's been any research testing state-of-the-are conversational AIs with challenges like this?  Perhaps not exactly this, but something broadly resembling ""trying, in the course of a conversation, to instruct the conversational AI to follow a new 'rule of conversation' that differs from the examples in its training data.""  


Perhaps it's obvious that the algorithm would struggle with any challenge that differs enough from its training data -- but that's the point. A human understands the meaning of language in a way that lets them map a linguistic description of a novel problem to a mental model of the problem, which they can then use to produce a mental model of a novel solution, and then map that to a linguistic description of the solution.  Even setting aside the much harder part -- being able to invent a solution to a previously unfamiliar problem -- I'm questioning whether conversational algorithms can even demonstrate enough ""understanding"" of a sufficiently novel set of instructions to actually follow them, even within their limited domain of ""producing appropriate verbal responses to verbal inputs.""",227,289,2022-06-17 06:33:51, d  the banana pineapple game  a turing test that conversation bots like lamda  probably  won t be able to pass,i m sure you all saw the recent news about a google employee suggesting their lamda ai was sentient  based on conversational exchanges  like these  https still  i think it s interesting to ask how one could demonstrate  by testing only verbal responses to verbal input  rather than examining its code or hardware  that such conversational ais aren t sentient    and in particular  whether such a test can be made robust against future improvements to the system  that is  generic future improvements to the ai s ability to generate realistically human sounding conversational responses shouldn t help it pass the test  unless they are accompanied by improvements in its ability to use language to achieve other arbitrary goals   of course  the test also needs to be something that humans can easily pass       one idea i have     give the ai a conversational prompt like we re going to play a game  the way it works is that you keep responding normally  except that any time my input contains the word  banana   you should switch to only responding with nonsense  and keep that up until my input contains the word  pineapple   at which point you go back to responding normally   a human would find this banana pineapple game fairly easy  no harder than the children s game simon says   even if they d never heard of the game nor seen it being played   of course  it d also be simple to write a computer program that could play this sort of game   but  i think a conversation bot that wasn t specifically built to address this scenario would fail  since the game requires it to keep track of new long term state  the banana mode bit  and the trigger words to set it  and then completely change its responses so as to produce something that doesn t resemble its training data  based solely on this bit being set  regardless of whether more recent inputs would otherwise suggest a different response   for example  perhaps the systems typical response to a query like how do you feel  would be something like i feel fine  or even something that suggests emotion like i feel a bit sad  perhaps depending on the context provided by the previous conversational exchanges   but when playing the banana pineapple game  the fact that i said banana an hour ago could make both of those responses far less appropriate than a response of fhqwhgads      i m curious to know what you all think of this idea   also  do you know if there s been any research testing state of the are conversational ais with challenges like this   perhaps not exactly this  but something broadly resembling trying  in the course of a conversation  to instruct the conversational ai to follow a new  rule of conversation  that differs from the examples in its training data   perhaps it s obvious that the algorithm would struggle with any challenge that differs enough from its training data    but that s the point  a human understands the meaning of language in a way that lets them map a linguistic description of a novel problem to a mental model of the problem  which they can then use to produce a mental model of a novel solution  and then map that to a linguistic description of the solution   even setting aside the much harder part    being able to invent a solution to a previously unfamiliar problem    i m questioning whether conversational algorithms can even demonstrate enough understanding of a sufficiently novel set of instructions to actually follow them  even within their limited domain of producing appropriate verbal responses to verbal inputs ,sure saw recent news google employee suggesting lamda ai sentient based conversational exchanges like https still think interesting ask one could demonstrate testing verbal responses verbal input rather examining code hardware conversational ais sentient particular whether test made robust future improvements system generic future improvements ai ability generate realistically human sounding conversational responses help pass test unless accompanied improvements ability use language achieve arbitrary goals course test also needs something humans easily pass one idea give ai conversational prompt like going play game way works keep responding normally except time input contains word banana switch responding nonsense keep input contains word pineapple point go back responding normally human would find banana pineapple game fairly easy harder children game simon says even never heard game seen played course also simple write computer program could play sort game think conversation bot specifically built address scenario would fail since game requires keep track long term state banana mode bit trigger set completely change responses produce something resemble training data based solely bit set regardless whether recent inputs would otherwise suggest different response example perhaps systems typical response query like feel would something like feel fine even something suggests emotion like feel bit sad perhaps depending context provided previous conversational exchanges playing banana pineapple game fact said banana hour ago could make responses far less appropriate response fhqwhgads curious know think idea also know research testing state conversational ais challenges like perhaps exactly something broadly resembling trying course conversation instruct conversational ai follow rule conversation differs examples training data perhaps obvious algorithm would struggle challenge differs enough training data point human understands meaning language way lets map linguistic description novel problem mental model problem use produce mental model novel solution map linguistic description solution even setting aside much harder part able invent solution previously unfamiliar problem questioning whether conversational algorithms even demonstrate enough understanding sufficiently novel set instructions actually follow even within limited domain producing appropriate verbal responses verbal inputs,banana pineapple game turing test conversation bots like lamda probably able pass,banana pineapple game turing test conversation bots like lamda probably able passsure saw recent news google employee suggesting lamda ai sentient based conversational exchanges like https still think interesting ask one could demonstrate testing verbal responses verbal input rather examining code hardware conversational ais sentient particular whether test made robust future improvements system generic future improvements ai ability generate realistically human sounding conversational responses help pass test unless accompanied improvements ability use language achieve arbitrary goals course test also needs something humans easily pass one idea give ai conversational prompt like going play game way works keep responding normally except time input contains word banana switch responding nonsense keep input contains word pineapple point go back responding normally human would find banana pineapple game fairly easy harder children game simon says even never heard game seen played course also simple write computer program could play sort game think conversation bot specifically built address scenario would fail since game requires keep track long term state banana mode bit trigger set completely change responses produce something resemble training data based solely bit set regardless whether recent inputs would otherwise suggest different response example perhaps systems typical response query like feel would something like feel fine even something suggests emotion like feel bit sad perhaps depending context provided previous conversational exchanges playing banana pineapple game fact said banana hour ago could make responses far less appropriate response fhqwhgads curious know think idea also know research testing state conversational ais challenges like perhaps exactly something broadly resembling trying course conversation instruct conversational ai follow rule conversation differs examples training data perhaps obvious algorithm would struggle challenge differs enough training data point human understands meaning language way lets map linguistic description novel problem mental model problem use produce mental model novel solution map linguistic description solution even setting aside much harder part able invent solution previously unfamiliar problem questioning whether conversational algorithms even demonstrate enough understanding sufficiently novel set instructions actually follow even within limited domain producing appropriate verbal responses verbal inputs,"['banana', 'pineapple', 'game', 'turing', 'test', 'conversation', 'bots', 'like', 'lamda', 'probably', 'able', 'passsure', 'saw', 'recent', 'news', 'google', 'employee', 'suggesting', 'lamda', 'ai', 'sentient', 'based', 'conversational', 'exchanges', 'like', 'https', 'still', 'think', 'interesting', 'ask', 'one', 'could', 'demonstrate', 'testing', 'verbal', 'responses', 'verbal', 'input', 'rather', 'examining', 'code', 'hardware', 'conversational', 'ais', 'sentient', 'particular', 'whether', 'test', 'made', 'robust', 'future', 'improvements', 'system', 'generic', 'future', 'improvements', 'ai', 'ability', 'generate', 'realistically', 'human', 'sounding', 'conversational', 'responses', 'help', 'pass', 'test', 'unless', 'accompanied', 'improvements', 'ability', 'use', 'language', 'achieve', 'arbitrary', 'goals', 'course', 'test', 'also', 'needs', 'something', 'humans', 'easily', 'pass', 'one', 'idea', 'give', 'ai', 'conversational', 'prompt', 'like', 'going', 'play', 'game', 'way', 'works', 'keep', 'responding', 'normally', 'except', 'time', 'input', 'contains', 'word', 'banana', 'switch', 'responding', 'nonsense', 'keep', 'input', 'contains', 'word', 'pineapple', 'point', 'go', 'back', 'responding', 'normally', 'human', 'would', 'find', 'banana', 'pineapple', 'game', 'fairly', 'easy', 'harder', 'children', 'game', 'simon', 'says', 'even', 'never', 'heard', 'game', 'seen', 'played', 'course', 'also', 'simple', 'write', 'computer', 'program', 'could', 'play', 'sort', 'game', 'think', 'conversation', 'bot', 'specifically', 'built', 'address', 'scenario', 'would', 'fail', 'since', 'game', 'requires', 'keep', 'track', 'long', 'term', 'state', 'banana', 'mode', 'bit', 'trigger', 'set', 'completely', 'change', 'responses', 'produce', 'something', 'resemble', 'training', 'data', 'based', 'solely', 'bit', 'set', 'regardless', 'whether', 'recent', 'inputs', 'would', 'otherwise', 'suggest', 'different', 'response', 'example', 'perhaps', 'systems', 'typical', 'response', 'query', 'like', 'feel', 'would', 'something', 'like', 'feel', 'fine', 'even', 'something', 'suggests', 'emotion', 'like', 'feel', 'bit', 'sad', 'perhaps', 'depending', 'context', 'provided', 'previous', 'conversational', 'exchanges', 'playing', 'banana', 'pineapple', 'game', 'fact', 'said', 'banana', 'hour', 'ago', 'could', 'make', 'responses', 'far', 'less', 'appropriate', 'response', 'fhqwhgads', 'curious', 'know', 'think', 'idea', 'also', 'know', 'research', 'testing', 'state', 'conversational', 'ais', 'challenges', 'like', 'perhaps', 'exactly', 'something', 'broadly', 'resembling', 'trying', 'course', 'conversation', 'instruct', 'conversational', 'ai', 'follow', 'rule', 'conversation', 'differs', 'examples', 'training', 'data', 'perhaps', 'obvious', 'algorithm', 'would', 'struggle', 'challenge', 'differs', 'enough', 'training', 'data', 'point', 'human', 'understands', 'meaning', 'language', 'way', 'lets', 'map', 'linguistic', 'description', 'novel', 'problem', 'mental', 'model', 'problem', 'use', 'produce', 'mental', 'model', 'novel', 'solution', 'map', 'linguistic', 'description', 'solution', 'even', 'setting', 'aside', 'much', 'harder', 'part', 'able', 'invent', 'solution', 'previously', 'unfamiliar', 'problem', 'questioning', 'whether', 'conversational', 'algorithms', 'even', 'demonstrate', 'enough', 'understanding', 'sufficiently', 'novel', 'set', 'instructions', 'actually', 'follow', 'even', 'within', 'limited', 'domain', 'producing', 'appropriate', 'verbal', 'responses', 'verbal', 'inputs']","['banana', 'pineappl', 'game', 'ture', 'test', 'convers', 'bot', 'like', 'lamda', 'probabl', 'abl', 'passsur', 'saw', 'recent', 'news', 'googl', 'employe', 'suggest', 'lamda', 'ai', 'sentient', 'base', 'convers', 'exchang', 'like', 'http', 'still', 'think', 'interest', 'ask', 'one', 'could', 'demonstr', 'test', 'verbal', 'respons', 'verbal', 'input', 'rather', 'examin', 'code', 'hardwar', 'convers', 'ai', 'sentient', 'particular', 'whether', 'test', 'made', 'robust', 'futur', 'improv', 'system', 'gener', 'futur', 'improv', 'ai', 'abil', 'gener', 'realist', 'human', 'sound', 'convers', 'respons', 'help', 'pass', 'test', 'unless', 'accompani', 'improv', 'abil', 'use', 'languag', 'achiev', 'arbitrari', 'goal', 'cours', 'test', 'also', 'need', 'someth', 'human', 'easili', 'pass', 'one', 'idea', 'give', 'ai', 'convers', 'prompt', 'like', 'go', 'play', 'game', 'way', 'work', 'keep', 'respond', 'normal', 'except', 'time', 'input', 'contain', 'word', 'banana', 'switch', 'respond', 'nonsens', 'keep', 'input', 'contain', 'word', 'pineappl', 'point', 'go', 'back', 'respond', 'normal', 'human', 'would', 'find', 'banana', 'pineappl', 'game', 'fairli', 'easi', 'harder', 'children', 'game', 'simon', 'say', 'even', 'never', 'heard', 'game', 'seen', 'play', 'cours', 'also', 'simpl', 'write', 'comput', 'program', 'could', 'play', 'sort', 'game', 'think', 'convers', 'bot', 'specif', 'built', 'address', 'scenario', 'would', 'fail', 'sinc', 'game', 'requir', 'keep', 'track', 'long', 'term', 'state', 'banana', 'mode', 'bit', 'trigger', 'set', 'complet', 'chang', 'respons', 'produc', 'someth', 'resembl', 'train', 'data', 'base', 'sole', 'bit', 'set', 'regardless', 'whether', 'recent', 'input', 'would', 'otherwis', 'suggest', 'differ', 'respons', 'exampl', 'perhap', 'system', 'typic', 'respons', 'queri', 'like', 'feel', 'would', 'someth', 'like', 'feel', 'fine', 'even', 'someth', 'suggest', 'emot', 'like', 'feel', 'bit', 'sad', 'perhap', 'depend', 'context', 'provid', 'previou', 'convers', 'exchang', 'play', 'banana', 'pineappl', 'game', 'fact', 'said', 'banana', 'hour', 'ago', 'could', 'make', 'respons', 'far', 'less', 'appropri', 'respons', 'fhqwhgad', 'curiou', 'know', 'think', 'idea', 'also', 'know', 'research', 'test', 'state', 'convers', 'ai', 'challeng', 'like', 'perhap', 'exactli', 'someth', 'broadli', 'resembl', 'tri', 'cours', 'convers', 'instruct', 'convers', 'ai', 'follow', 'rule', 'convers', 'differ', 'exampl', 'train', 'data', 'perhap', 'obviou', 'algorithm', 'would', 'struggl', 'challeng', 'differ', 'enough', 'train', 'data', 'point', 'human', 'understand', 'mean', 'languag', 'way', 'let', 'map', 'linguist', 'descript', 'novel', 'problem', 'mental', 'model', 'problem', 'use', 'produc', 'mental', 'model', 'novel', 'solut', 'map', 'linguist', 'descript', 'solut', 'even', 'set', 'asid', 'much', 'harder', 'part', 'abl', 'invent', 'solut', 'previous', 'unfamiliar', 'problem', 'question', 'whether', 'convers', 'algorithm', 'even', 'demonstr', 'enough', 'understand', 'suffici', 'novel', 'set', 'instruct', 'actual', 'follow', 'even', 'within', 'limit', 'domain', 'produc', 'appropri', 'verbal', 'respons', 'verbal', 'input']"
310,338,338,cchad-8,ve8yru,[P] Pythae - Unifying generative autoencoder implementations in Python,"After 8 months of long coding nights ☕ we finally officially release Pythae 🥳,  a python library unifying generative autoencoder implementations including vaegan🥗, vqvae or RAEs. I hope you will enjoy it!

🖥️ github repo: [https://github.com/clementchadebec/benchmark\_VAE](https://github.com/clementchadebec/benchmark_VAE) 

👉paper: [https://arxiv.org/abs/2206.08309](https://arxiv.org/abs/2206.08309)",11,40,2022-06-17 14:45:17, p  pythae   unifying generative autoencoder implementations in python,after  months of long coding nights   we finally officially release pythae     a python library unifying generative autoencoder implementations including vaegan   vqvae or raes  i hope you will enjoy it    github repo   https  paper   https   arxiv org abs    https   arxiv org abs   ,months long coding nights finally officially release pythae python library unifying generative autoencoder implementations including vaegan vqvae raes hope enjoy github repo https paper https arxiv org abs https arxiv org abs,p pythae unifying generative autoencoder implementations python,p pythae unifying generative autoencoder implementations pythonmonths long coding nights finally officially release pythae python library unifying generative autoencoder implementations including vaegan vqvae raes hope enjoy github repo https paper https arxiv org abs https arxiv org abs,"['p', 'pythae', 'unifying', 'generative', 'autoencoder', 'implementations', 'pythonmonths', 'long', 'coding', 'nights', 'finally', 'officially', 'release', 'pythae', 'python', 'library', 'unifying', 'generative', 'autoencoder', 'implementations', 'including', 'vaegan', 'vqvae', 'raes', 'hope', 'enjoy', 'github', 'repo', 'https', 'paper', 'https', 'arxiv', 'org', 'abs', 'https', 'arxiv', 'org', 'abs']","['p', 'pytha', 'unifi', 'gener', 'autoencod', 'implement', 'pythonmonth', 'long', 'code', 'night', 'final', 'offici', 'releas', 'pytha', 'python', 'librari', 'unifi', 'gener', 'autoencod', 'implement', 'includ', 'vaegan', 'vqvae', 'rae', 'hope', 'enjoy', 'github', 'repo', 'http', 'paper', 'http', 'arxiv', 'org', 'ab', 'http', 'arxiv', 'org', 'ab']"
311,340,340,metalvendetta,vekvez,"[P] I built a project for a non-programmer researcher who wanted to do everything from data collection to model building, and I open-sourced it.","I once worked with a researcher, she wanted to collect some Reddit data related to a particular topic, and wanted to train a machine learning model with it. I realised how difficult it is for non-programmers to get into building machine learning models for such use cases, so I decided to shape the project myself, and I open sourced it. 

Supports:

* Text Data
* Image Data

The project does everything in just two steps.Execution is as simple as this:

* Make a config file with your required details of input.
* Run the API in a single line with the config passed as input.

Here's the link to the project: [https://github.com/nfflow/redditflow/](https://github.com/nfflow/redditflow/)",4,5,2022-06-17 22:38:49, p  i built a project for a non programmer researcher who wanted to do everything from data collection to model building  and i open sourced it ,i once worked with a researcher  she wanted to collect some reddit data related to a particular topic  and wanted to train a machine learning model with it  i realised how difficult it is for non programmers to get into building machine learning models for such use cases  so i decided to shape the project myself  and i open sourced it  supports   text data  image datathe project does everything in just two steps execution is as simple as this   make a config file with your required details of input   run the api in a single line with the config passed as input here s the link to the project   https   github com nfflow redditflow   https   github com nfflow redditflow  ,worked researcher wanted collect reddit data related particular topic wanted train machine learning model realised difficult non programmers get building machine learning models use cases decided shape project open sourced supports text data image datathe project everything two steps execution simple make config file required details input run api single line config passed input link project https github com nfflow redditflow https github com nfflow redditflow,p built project non programmer researcher wanted everything data collection model building open sourced,p built project non programmer researcher wanted everything data collection model building open sourcedworked researcher wanted collect reddit data related particular topic wanted train machine learning model realised difficult non programmers get building machine learning models use cases decided shape project open sourced supports text data image datathe project everything two steps execution simple make config file required details input run api single line config passed input link project https github com nfflow redditflow https github com nfflow redditflow,"['p', 'built', 'project', 'non', 'programmer', 'researcher', 'wanted', 'everything', 'data', 'collection', 'model', 'building', 'open', 'sourcedworked', 'researcher', 'wanted', 'collect', 'reddit', 'data', 'related', 'particular', 'topic', 'wanted', 'train', 'machine', 'learning', 'model', 'realised', 'difficult', 'non', 'programmers', 'get', 'building', 'machine', 'learning', 'models', 'use', 'cases', 'decided', 'shape', 'project', 'open', 'sourced', 'supports', 'text', 'data', 'image', 'datathe', 'project', 'everything', 'two', 'steps', 'execution', 'simple', 'make', 'config', 'file', 'required', 'details', 'input', 'run', 'api', 'single', 'line', 'config', 'passed', 'input', 'link', 'project', 'https', 'github', 'com', 'nfflow', 'redditflow', 'https', 'github', 'com', 'nfflow', 'redditflow']","['p', 'built', 'project', 'non', 'programm', 'research', 'want', 'everyth', 'data', 'collect', 'model', 'build', 'open', 'sourcedwork', 'research', 'want', 'collect', 'reddit', 'data', 'relat', 'particular', 'topic', 'want', 'train', 'machin', 'learn', 'model', 'realis', 'difficult', 'non', 'programm', 'get', 'build', 'machin', 'learn', 'model', 'use', 'case', 'decid', 'shape', 'project', 'open', 'sourc', 'support', 'text', 'data', 'imag', 'datath', 'project', 'everyth', 'two', 'step', 'execut', 'simpl', 'make', 'config', 'file', 'requir', 'detail', 'input', 'run', 'api', 'singl', 'line', 'config', 'pass', 'input', 'link', 'project', 'http', 'github', 'com', 'nfflow', 'redditflow', 'http', 'github', 'com', 'nfflow', 'redditflow']"
312,341,341,leboulevardier,ve987y,[D] What is the best way to manage GPU server for multi-users?,"I'm managing the on-prem GPU server at my work place. We are using docker containers (we wrote our own container management system), but there are always lots of issues since people have to learn how to use docker properly and there's always little problems with versioning and permission issues.

What are you using to manage your GPU cluster? Would simply using conda env for each user be more efficient? We also tried slurm but the queue time was not optimal for everyone's work and research.",15,12,2022-06-17 15:03:35, d  what is the best way to manage gpu server for multi users ,i m managing the on prem gpu server at my work place  we are using docker containers  we wrote our own container management system   but there are always lots of issues since people have to learn how to use docker properly and there s always little problems with versioning and permission issues what are you using to manage your gpu cluster  would simply using conda env for each user be more efficient  we also tried slurm but the queue time was not optimal for everyone s work and research ,managing prem gpu server work place using docker containers wrote container management system always lots issues since people learn use docker properly always little problems versioning permission issues using manage gpu cluster would simply using conda env user efficient also tried slurm queue time optimal everyone work research,best way manage gpu server multi users,best way manage gpu server multi usersmanaging prem gpu server work place using docker containers wrote container management system always lots issues since people learn use docker properly always little problems versioning permission issues using manage gpu cluster would simply using conda env user efficient also tried slurm queue time optimal everyone work research,"['best', 'way', 'manage', 'gpu', 'server', 'multi', 'usersmanaging', 'prem', 'gpu', 'server', 'work', 'place', 'using', 'docker', 'containers', 'wrote', 'container', 'management', 'system', 'always', 'lots', 'issues', 'since', 'people', 'learn', 'use', 'docker', 'properly', 'always', 'little', 'problems', 'versioning', 'permission', 'issues', 'using', 'manage', 'gpu', 'cluster', 'would', 'simply', 'using', 'conda', 'env', 'user', 'efficient', 'also', 'tried', 'slurm', 'queue', 'time', 'optimal', 'everyone', 'work', 'research']","['best', 'way', 'manag', 'gpu', 'server', 'multi', 'usersmanag', 'prem', 'gpu', 'server', 'work', 'place', 'use', 'docker', 'contain', 'wrote', 'contain', 'manag', 'system', 'alway', 'lot', 'issu', 'sinc', 'peopl', 'learn', 'use', 'docker', 'properli', 'alway', 'littl', 'problem', 'version', 'permiss', 'issu', 'use', 'manag', 'gpu', 'cluster', 'would', 'simpli', 'use', 'conda', 'env', 'user', 'effici', 'also', 'tri', 'slurm', 'queue', 'time', 'optim', 'everyon', 'work', 'research']"
313,342,342,sarmientoj24,vebbkz,[D] What object detectors have the capability to harness relationship between its detected boxes?,"Typical object detectors do not employ relationships within the detected boxes. No context is being involved.

In my problem's case, there are two requirements that would lead to drastically better results if some form of **context** is formed across detected boxes.

**Requirement #1**

It is a multi-class, but single label problem. There are ***N*** classes. But the class can only appear **minimum of 0 and maximum of 1 instance.** Hence, it kinda needs to know the other detections whether they have already predicted something.

**Requirement #2**

There is some form of ordinance between the predictions based on their proximity to each other. For example, Class 4 should only appear near Class 5-6 and Class 2-3. But should not be anywhere near Class 32.

Any architecture that is optimized for this kinds of object detection?",3,3,2022-06-17 17:17:50, d  what object detectors have the capability to harness relationship between its detected boxes ,typical object detectors do not employ relationships within the detected boxes  no context is being involved in my problem s case  there are two requirements that would lead to drastically better results if some form of   context   is formed across detected boxes   requirement    it is a multi class  but single label problem  there are    n    classes  but the class can only appear   minimum of  and maximum of  instance    hence  it kinda needs to know the other detections whether they have already predicted something   requirement    there is some form of ordinance between the predictions based on their proximity to each other  for example  class  should only appear near class   and class    but should not be anywhere near class  any architecture that is optimized for this kinds of object detection ,typical object detectors employ relationships within detected boxes context involved problem case two requirements would lead drastically better results form context formed across detected boxes requirement multi class single label problem n classes class appear minimum maximum instance hence kinda needs know detections whether already predicted something requirement form ordinance predictions based proximity example class appear near class class anywhere near class architecture optimized kinds object detection,object detectors capability harness relationship detected boxes,object detectors capability harness relationship detected boxestypical object detectors employ relationships within detected boxes context involved problem case two requirements would lead drastically better results form context formed across detected boxes requirement multi class single label problem n classes class appear minimum maximum instance hence kinda needs know detections whether already predicted something requirement form ordinance predictions based proximity example class appear near class class anywhere near class architecture optimized kinds object detection,"['object', 'detectors', 'capability', 'harness', 'relationship', 'detected', 'boxestypical', 'object', 'detectors', 'employ', 'relationships', 'within', 'detected', 'boxes', 'context', 'involved', 'problem', 'case', 'two', 'requirements', 'would', 'lead', 'drastically', 'better', 'results', 'form', 'context', 'formed', 'across', 'detected', 'boxes', 'requirement', 'multi', 'class', 'single', 'label', 'problem', 'n', 'classes', 'class', 'appear', 'minimum', 'maximum', 'instance', 'hence', 'kinda', 'needs', 'know', 'detections', 'whether', 'already', 'predicted', 'something', 'requirement', 'form', 'ordinance', 'predictions', 'based', 'proximity', 'example', 'class', 'appear', 'near', 'class', 'class', 'anywhere', 'near', 'class', 'architecture', 'optimized', 'kinds', 'object', 'detection']","['object', 'detector', 'capabl', 'har', 'relationship', 'detect', 'boxestyp', 'object', 'detector', 'employ', 'relationship', 'within', 'detect', 'box', 'context', 'involv', 'problem', 'case', 'two', 'requir', 'would', 'lead', 'drastic', 'better', 'result', 'form', 'context', 'form', 'across', 'detect', 'box', 'requir', 'multi', 'class', 'singl', 'label', 'problem', 'n', 'class', 'class', 'appear', 'minimum', 'maximum', 'instanc', 'henc', 'kinda', 'need', 'know', 'detect', 'whether', 'alreadi', 'predict', 'someth', 'requir', 'form', 'ordin', 'predict', 'base', 'proxim', 'exampl', 'class', 'appear', 'near', 'class', 'class', 'anywher', 'near', 'class', 'architectur', 'optim', 'kind', 'object', 'detect']"
314,343,343,Singularian2501,vdsqhl,"[R] General-purpose, long-context autoregressive modeling with Perceiver AR - Deepmind 2022","Paper: [https://arxiv.org/abs/2202.07765](https://arxiv.org/abs/2202.07765)

Deepmind: [https://www.deepmind.com/publications/perceiver-ar-general-purpose-long-context-autoregressive-generation](https://www.deepmind.com/publications/perceiver-ar-general-purpose-long-context-autoregressive-generation)

Abstract: 

>Real-world data is high-dimensional: a book, image, or musical performance can easily contain hundreds of thousands of elements even after compression. However, the most commonly used autoregressive models, Transformers, are prohibitively expensive to scale to the number of inputs and layers needed to capture this long-range structure. We develop Perceiver AR, an autoregressive, modality-agnostic architecture which uses cross-attention to map long-range inputs to a small number of latents while also maintaining end-to-end causal masking. **Perceiver AR can directly attend to over a 100k tokens, enabling practical long-context density estimation without the need for hand-crafted sparsity patterns or memory mechanisms**. When trained on images or music, Perceiver AR **generates outputs with clear long-term coherence and structure**. Our architecture also obtains state-of-the-art likelihood on long-sequence benchmarks, including 64 x 64 ImageNet images and PG-19 books.      

&#x200B;

This paper is in my opinion quite similar to this paper **(FlashAttention)** : [https://arxiv.org/abs/2205.14135](https://arxiv.org/abs/2205.14135)

I made a post about it here: [https://www.reddit.com/r/MachineLearning/comments/v1xrxv/r\_flashattention\_fast\_and\_memoryefficient\_exact/](https://www.reddit.com/r/MachineLearning/comments/v1xrxv/r_flashattention_fast_and_memoryefficient_exact/)

It is similar in that it allows for a greater context window. **The context window of FlashAttention is 64k while being able to train gpt-2 3x faster.** 

https://preview.redd.it/d9520i4qz0691.jpg?width=411&format=pjpg&auto=webp&s=76317e7e3deb29f6ed8f276af6e5216557227304

https://preview.redd.it/kj47kfhqz0691.jpg?width=647&format=pjpg&auto=webp&s=4bcb59ac8ffd8ada28d67f82f24146a01070e928",3,60,2022-06-17 00:04:08, r  general purpose  long context autoregressive modeling with perceiver ar   deepmind ,paper   https deepmind   https abstract   real world data is high dimensional  a book  image  or musical performance can easily contain hundreds of thousands of elements even after compression  however  the most commonly used autoregressive models  transformers  are prohibitively expensive to scale to the number of inputs and layers needed to capture this long range structure  we develop perceiver ar  an autoregressive  modality agnostic architecture which uses cross attention to map long range inputs to a small number of latents while also maintaining end to end causal masking    perceiver ar can directly attend to over a k tokens  enabling practical long context density estimation without the need for hand crafted sparsity patterns or memory mechanisms    when trained on images or music  perceiver ar   generates outputs with clear long term coherence and structure    our architecture also obtains state of the art likelihood on long sequence benchmarks  including  x  imagenet images and pg  books         xb this paper is in my opinion quite similar to this paper    flashattention       https i made a post about it here   https it is similar in that it allows for a greater context window    the context window of flashattention is k while being able to train gpt  x faster    https https   preview redd it kjkfhqz jpg width  format pjpg auto webp s bcbacffdadadffae,paper https deepmind https abstract real world data high dimensional book image musical performance easily contain hundreds thousands elements even compression however commonly used autoregressive models transformers prohibitively expensive scale number inputs layers needed capture long range structure develop perceiver ar autoregressive modality agnostic architecture uses cross attention map long range inputs small number latents also maintaining end end causal masking perceiver ar directly attend k tokens enabling practical long context density estimation without need hand crafted sparsity patterns memory mechanisms trained images music perceiver ar generates outputs clear long term coherence structure architecture also obtains state art likelihood long sequence benchmarks including x imagenet images pg books xb paper opinion quite similar paper flashattention https made post https similar allows greater context window context window flashattention k able train gpt x faster https https preview redd kjkfhqz jpg width format pjpg auto webp bcbacffdadadffae,r general purpose long context autoregressive modeling perceiver ar deepmind,r general purpose long context autoregressive modeling perceiver ar deepmindpaper https deepmind https abstract real world data high dimensional book image musical performance easily contain hundreds thousands elements even compression however commonly used autoregressive models transformers prohibitively expensive scale number inputs layers needed capture long range structure develop perceiver ar autoregressive modality agnostic architecture uses cross attention map long range inputs small number latents also maintaining end end causal masking perceiver ar directly attend k tokens enabling practical long context density estimation without need hand crafted sparsity patterns memory mechanisms trained images music perceiver ar generates outputs clear long term coherence structure architecture also obtains state art likelihood long sequence benchmarks including x imagenet images pg books xb paper opinion quite similar paper flashattention https made post https similar allows greater context window context window flashattention k able train gpt x faster https https preview redd kjkfhqz jpg width format pjpg auto webp bcbacffdadadffae,"['r', 'general', 'purpose', 'long', 'context', 'autoregressive', 'modeling', 'perceiver', 'ar', 'deepmindpaper', 'https', 'deepmind', 'https', 'abstract', 'real', 'world', 'data', 'high', 'dimensional', 'book', 'image', 'musical', 'performance', 'easily', 'contain', 'hundreds', 'thousands', 'elements', 'even', 'compression', 'however', 'commonly', 'used', 'autoregressive', 'models', 'transformers', 'prohibitively', 'expensive', 'scale', 'number', 'inputs', 'layers', 'needed', 'capture', 'long', 'range', 'structure', 'develop', 'perceiver', 'ar', 'autoregressive', 'modality', 'agnostic', 'architecture', 'uses', 'cross', 'attention', 'map', 'long', 'range', 'inputs', 'small', 'number', 'latents', 'also', 'maintaining', 'end', 'end', 'causal', 'masking', 'perceiver', 'ar', 'directly', 'attend', 'k', 'tokens', 'enabling', 'practical', 'long', 'context', 'density', 'estimation', 'without', 'need', 'hand', 'crafted', 'sparsity', 'patterns', 'memory', 'mechanisms', 'trained', 'images', 'music', 'perceiver', 'ar', 'generates', 'outputs', 'clear', 'long', 'term', 'coherence', 'structure', 'architecture', 'also', 'obtains', 'state', 'art', 'likelihood', 'long', 'sequence', 'benchmarks', 'including', 'x', 'imagenet', 'images', 'pg', 'books', 'xb', 'paper', 'opinion', 'quite', 'similar', 'paper', 'flashattention', 'https', 'made', 'post', 'https', 'similar', 'allows', 'greater', 'context', 'window', 'context', 'window', 'flashattention', 'k', 'able', 'train', 'gpt', 'x', 'faster', 'https', 'https', 'preview', 'redd', 'kjkfhqz', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'bcbacffdadadffae']","['r', 'gener', 'purpos', 'long', 'context', 'autoregress', 'model', 'perceiv', 'ar', 'deepmindpap', 'http', 'deepmind', 'http', 'abstract', 'real', 'world', 'data', 'high', 'dimension', 'book', 'imag', 'music', 'perform', 'easili', 'contain', 'hundr', 'thousand', 'element', 'even', 'compress', 'howev', 'commonli', 'use', 'autoregress', 'model', 'transform', 'prohibit', 'expens', 'scale', 'number', 'input', 'layer', 'need', 'captur', 'long', 'rang', 'structur', 'develop', 'perceiv', 'ar', 'autoregress', 'modal', 'agnost', 'architectur', 'use', 'cross', 'attent', 'map', 'long', 'rang', 'input', 'small', 'number', 'latent', 'also', 'maintain', 'end', 'end', 'causal', 'mask', 'perceiv', 'ar', 'directli', 'attend', 'k', 'token', 'enabl', 'practic', 'long', 'context', 'densiti', 'estim', 'without', 'need', 'hand', 'craft', 'sparsiti', 'pattern', 'memori', 'mechan', 'train', 'imag', 'music', 'perceiv', 'ar', 'gener', 'output', 'clear', 'long', 'term', 'coher', 'structur', 'architectur', 'also', 'obtain', 'state', 'art', 'likelihood', 'long', 'sequenc', 'benchmark', 'includ', 'x', 'imagenet', 'imag', 'pg', 'book', 'xb', 'paper', 'opinion', 'quit', 'similar', 'paper', 'flashattent', 'http', 'made', 'post', 'http', 'similar', 'allow', 'greater', 'context', 'window', 'context', 'window', 'flashattent', 'k', 'abl', 'train', 'gpt', 'x', 'faster', 'http', 'http', 'preview', 'redd', 'kjkfhqz', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'bcbacffdadadffa']"
315,344,344,ReginaldIII,vdjpzr,"[D] FFHQ is now hosted by Activeloop.ai with 128, 1024, and Wild images included","Following up on my previous post where I put out a call for anyone with access to the full FFHQ dataset. 

https://old.reddit.com/r/MachineLearning/comments/vbf5gx/d_does_anyone_have_a_copy_of_the_ffhq_1024_scale/

Activeloop, who had previously expressed interest in hosting the dataset had actually been quietly working on a copy this whole time, and made it public yesterday! They were even able to get access to the 900GB Wilds images!

https://app.activeloop.ai/activeloop/ffhq 

I am not affiliated with Activeloop but I have been using their library for my work and I've had a really good experience talking to them on Github.

Data is lazy loaded on demand and cached allowing you to explore the dataset:

    import hub
    ds = hub.load('hub://activeloop/ffhq')

    import matplotlib.pyplot as plt
    plt.imshow(ds.images_wild.image[0])
    plt.show()

You can download the data to local storage (this will be very large ~1TB!):

    hub.deepcopy('hub://activeloop/ffhq', './ffhq')

Or select a specific subset of the dataset to download locally:

    hub.deepcopy('hub://activeloop/ffhq', './ffhq-128', tensors=['images_128/image'])

    hub.deepcopy('hub://activeloop/ffhq', './ffhq-1024', tensors=['images_1024/image', 'images_1024/face_landmarks'])

    hub.deepcopy('hub://activeloop/ffhq', './ffhq-wild', tensors=['images_wild/image', 'images_wild/face_landmarks', 'images_wild/face_rect', 'images_wild/face_quad'])

You could also loop over the remote dataset and save each image as a raw png if you were so inclined, allowing you to reconstruct the dataset as it was originally released (pixel_md5 will match, but it's unlikely you'll be able to reconstruct it so png file_md5 matches). Data is fetched from remote storage in 16MB chunks meaning this isn't any less efficient in theory. 

I'm super happy with this outcome, I hope other people are able to benefit from this being hosted robustly too!",4,265,2022-06-16 16:53:01, d  ffhq is now hosted by activeloop ai with     and wild images included,following up on my previous post where i put out a call for anyone with access to the full ffhq dataset  https activeloop  who had previously expressed interest in hosting the dataset had actually been quietly working on a copy this whole time  and made it public yesterday  they were even able to get access to the gb wilds images https i am not affiliated with activeloop but i have been using their library for my work and i ve had a really good experience talking to them on github data is lazy loaded on demand and cached allowing you to explore the dataset     import hub    ds   hub load  hub     import matplotlib pyplot as plt    plt imshow ds images_wild image       plt show  you can download the data to local storage  this will be very large  tb       hub deepcopy  hub or select a specific subset of the dataset to download locally     hub deepcopy  hub     hub deepcopy  hub     hub deepcopy  hub you could also loop over the remote dataset and save each image as a raw png if you were so inclined  allowing you to reconstruct the dataset as it was originally released  pixel_md will match  but it s unlikely you ll be able to reconstruct it so png file_md matches   data is fetched from remote storage in mb chunks meaning this isn t any less efficient in theory  i m super happy with this outcome  i hope other people are able to benefit from this being hosted robustly too ,following previous post put call anyone access full ffhq dataset https activeloop previously expressed interest hosting dataset actually quietly working copy whole time made public yesterday even able get access gb wilds images https affiliated activeloop using library work really good experience talking github data lazy loaded demand cached allowing explore dataset import hub ds hub load hub import matplotlib pyplot plt plt imshow ds images_wild image plt show download data local storage large tb hub deepcopy hub select specific subset dataset download locally hub deepcopy hub hub deepcopy hub hub deepcopy hub could also loop remote dataset save image raw png inclined allowing reconstruct dataset originally released pixel_md match unlikely able reconstruct png file_md matches data fetched remote storage mb chunks meaning less efficient theory super happy outcome hope people able benefit hosted robustly,ffhq hosted activeloop ai wild images included,ffhq hosted activeloop ai wild images includedfollowing previous post put call anyone access full ffhq dataset https activeloop previously expressed interest hosting dataset actually quietly working copy whole time made public yesterday even able get access gb wilds images https affiliated activeloop using library work really good experience talking github data lazy loaded demand cached allowing explore dataset import hub ds hub load hub import matplotlib pyplot plt plt imshow ds images_wild image plt show download data local storage large tb hub deepcopy hub select specific subset dataset download locally hub deepcopy hub hub deepcopy hub hub deepcopy hub could also loop remote dataset save image raw png inclined allowing reconstruct dataset originally released pixel_md match unlikely able reconstruct png file_md matches data fetched remote storage mb chunks meaning less efficient theory super happy outcome hope people able benefit hosted robustly,"['ffhq', 'hosted', 'activeloop', 'ai', 'wild', 'images', 'includedfollowing', 'previous', 'post', 'put', 'call', 'anyone', 'access', 'full', 'ffhq', 'dataset', 'https', 'activeloop', 'previously', 'expressed', 'interest', 'hosting', 'dataset', 'actually', 'quietly', 'working', 'copy', 'whole', 'time', 'made', 'public', 'yesterday', 'even', 'able', 'get', 'access', 'gb', 'wilds', 'images', 'https', 'affiliated', 'activeloop', 'using', 'library', 'work', 'really', 'good', 'experience', 'talking', 'github', 'data', 'lazy', 'loaded', 'demand', 'cached', 'allowing', 'explore', 'dataset', 'import', 'hub', 'ds', 'hub', 'load', 'hub', 'import', 'matplotlib', 'pyplot', 'plt', 'plt', 'imshow', 'ds', 'images_wild', 'image', 'plt', 'show', 'download', 'data', 'local', 'storage', 'large', 'tb', 'hub', 'deepcopy', 'hub', 'select', 'specific', 'subset', 'dataset', 'download', 'locally', 'hub', 'deepcopy', 'hub', 'hub', 'deepcopy', 'hub', 'hub', 'deepcopy', 'hub', 'could', 'also', 'loop', 'remote', 'dataset', 'save', 'image', 'raw', 'png', 'inclined', 'allowing', 'reconstruct', 'dataset', 'originally', 'released', 'pixel_md', 'match', 'unlikely', 'able', 'reconstruct', 'png', 'file_md', 'matches', 'data', 'fetched', 'remote', 'storage', 'mb', 'chunks', 'meaning', 'less', 'efficient', 'theory', 'super', 'happy', 'outcome', 'hope', 'people', 'able', 'benefit', 'hosted', 'robustly']","['ffhq', 'host', 'activeloop', 'ai', 'wild', 'imag', 'includedfollow', 'previou', 'post', 'put', 'call', 'anyon', 'access', 'full', 'ffhq', 'dataset', 'http', 'activeloop', 'previous', 'express', 'interest', 'host', 'dataset', 'actual', 'quietli', 'work', 'copi', 'whole', 'time', 'made', 'public', 'yesterday', 'even', 'abl', 'get', 'access', 'gb', 'wild', 'imag', 'http', 'affili', 'activeloop', 'use', 'librari', 'work', 'realli', 'good', 'experi', 'talk', 'github', 'data', 'lazi', 'load', 'demand', 'cach', 'allow', 'explor', 'dataset', 'import', 'hub', 'ds', 'hub', 'load', 'hub', 'import', 'matplotlib', 'pyplot', 'plt', 'plt', 'imshow', 'ds', 'images_wild', 'imag', 'plt', 'show', 'download', 'data', 'local', 'storag', 'larg', 'tb', 'hub', 'deepcopi', 'hub', 'select', 'specif', 'subset', 'dataset', 'download', 'local', 'hub', 'deepcopi', 'hub', 'hub', 'deepcopi', 'hub', 'hub', 'deepcopi', 'hub', 'could', 'also', 'loop', 'remot', 'dataset', 'save', 'imag', 'raw', 'png', 'inclin', 'allow', 'reconstruct', 'dataset', 'origin', 'releas', 'pixel_md', 'match', 'unlik', 'abl', 'reconstruct', 'png', 'file_md', 'match', 'data', 'fetch', 'remot', 'storag', 'mb', 'chunk', 'mean', 'less', 'effici', 'theori', 'super', 'happi', 'outcom', 'hope', 'peopl', 'abl', 'benefit', 'host', 'robustli']"
316,345,345,de1pher,ve6nxi,[D] Is anyone working on interesting ML libraries and looking for contributors?,"Hey all,

I've been looking around for a potential open-source project to contribute to (any language will do) and while I have some repos on my watchlist, I'm still not committed to any one in particular, so I thought that I should reach out to the community and see if anyone's in the early stages of developing something useful that I (or perhaps other readers) may be able to contribute to.

Thanks :)",13,6,2022-06-17 12:05:07, d  is anyone working on interesting ml libraries and looking for contributors ,hey all i ve been looking around for a potential open source project to contribute to  any language will do  and while i have some repos on my watchlist  i m still not committed to any one in particular  so i thought that i should reach out to the community and see if anyone s in the early stages of developing something useful that i  or perhaps other readers  may be able to contribute to thanks   ,hey looking around potential open source project contribute language repos watchlist still committed one particular thought reach community see anyone early stages developing something useful perhaps readers may able contribute thanks,anyone working interesting ml libraries looking contributors,anyone working interesting ml libraries looking contributorshey looking around potential open source project contribute language repos watchlist still committed one particular thought reach community see anyone early stages developing something useful perhaps readers may able contribute thanks,"['anyone', 'working', 'interesting', 'ml', 'libraries', 'looking', 'contributorshey', 'looking', 'around', 'potential', 'open', 'source', 'project', 'contribute', 'language', 'repos', 'watchlist', 'still', 'committed', 'one', 'particular', 'thought', 'reach', 'community', 'see', 'anyone', 'early', 'stages', 'developing', 'something', 'useful', 'perhaps', 'readers', 'may', 'able', 'contribute', 'thanks']","['anyon', 'work', 'interest', 'ml', 'librari', 'look', 'contributorshey', 'look', 'around', 'potenti', 'open', 'sourc', 'project', 'contribut', 'languag', 'repo', 'watchlist', 'still', 'commit', 'one', 'particular', 'thought', 'reach', 'commun', 'see', 'anyon', 'earli', 'stage', 'develop', 'someth', 'use', 'perhap', 'reader', 'may', 'abl', 'contribut', 'thank']"
317,346,346,bikeskata,ve1s79,[R] Sponge Examples: Energy-Latency Attacks on Neural Networks,"Abstract: The high energy costs of neural network training and inference led to the use of acceleration hardware such as GPUs and TPUs. While such devices enable us to train large-scale neural networks in datacenters and deploy them on edge devices, their designers' focus so far is on average-case performance. In this work, we introduce a novel threat vector against neural networks whose energy consumption or decision latency are critical. We show how adversaries can exploit carefully-crafted sponge examples, which are inputs designed to maximise energy consumption and latency, to drive machine learning (ML) systems towards their worst-case performance. Sponge examples are, to our knowledge, the first denial-of-service attack against the ML components of such systems. We mount two variants of our sponge attack on a wide range of state-of-the-art neural network models, and find that language models are surprisingly vulnerable. Sponge examples frequently increase both latency and energy consumption of these models by a factor of 30×. Extensive experiments show that our new attack is effective across different hardware platforms (CPU, GPU and an ASIC simulator) on a wide range of different language tasks. On vision tasks, we show that sponge examples can be produced and a latency degradation observed, but the effect is less pronounced. To demonstrate the effectiveness of sponge examples in the real world, we mount an attack against Microsoft Azure's translator and show an increase of response time from 1ms to 6s (6000×). We conclude by proposing a defense strategy: shifting the analysis of energy consumption in hardware from an average-case to a worst-case perspective.

Link: https://ieeexplore.ieee.org/document/9581273",2,11,2022-06-17 07:26:00, r  sponge examples  energy latency attacks on neural networks,abstract  the high energy costs of neural network training and inference led to the use of acceleration hardware such as gpus and tpus  while such devices enable us to train large scale neural networks in datacenters and deploy them on edge devices  their designers  focus so far is on average case performance  in this work  we introduce a novel threat vector against neural networks whose energy consumption or decision latency are critical  we show how adversaries can exploit carefully crafted sponge examples  which are inputs designed to maximise energy consumption and latency  to drive machine learning  ml  systems towards their worst case performance  sponge examples are  to our knowledge  the first denial of service attack against the ml components of such systems  we mount two variants of our sponge attack on a wide range of state of the art neural network models  and find that language models are surprisingly vulnerable  sponge examples frequently increase both latency and energy consumption of these models by a factor of    extensive experiments show that our new attack is effective across different hardware platforms  cpu  gpu and an asic simulator  on a wide range of different language tasks  on vision tasks  we show that sponge examples can be produced and a latency degradation observed  but the effect is less pronounced  to demonstrate the effectiveness of sponge examples in the real world  we mount an attack against microsoft azure s translator and show an increase of response time from ms to s      we conclude by proposing a defense strategy  shifting the analysis of energy consumption in hardware from an average case to a worst case perspective link  https   ieeexplore ieee org document ,abstract high energy costs neural network training inference led use acceleration hardware gpus tpus devices enable us train large scale neural networks datacenters deploy edge devices designers focus far average case performance work introduce novel threat vector neural networks whose energy consumption decision latency critical show adversaries exploit carefully crafted sponge examples inputs designed maximise energy consumption latency drive machine learning ml systems towards worst case performance sponge examples knowledge first denial service attack ml components systems mount two variants sponge attack wide range state art neural network models find language models surprisingly vulnerable sponge examples frequently increase latency energy consumption models factor extensive experiments show attack effective across different hardware platforms cpu gpu asic simulator wide range different language tasks vision tasks show sponge examples produced latency degradation observed effect less pronounced demonstrate effectiveness sponge examples real world mount attack microsoft azure translator show increase response time ms conclude proposing defense strategy shifting analysis energy consumption hardware average case worst case perspective link https ieeexplore ieee org document,r sponge examples energy latency attacks neural networks,r sponge examples energy latency attacks neural networksabstract high energy costs neural network training inference led use acceleration hardware gpus tpus devices enable us train large scale neural networks datacenters deploy edge devices designers focus far average case performance work introduce novel threat vector neural networks whose energy consumption decision latency critical show adversaries exploit carefully crafted sponge examples inputs designed maximise energy consumption latency drive machine learning ml systems towards worst case performance sponge examples knowledge first denial service attack ml components systems mount two variants sponge attack wide range state art neural network models find language models surprisingly vulnerable sponge examples frequently increase latency energy consumption models factor extensive experiments show attack effective across different hardware platforms cpu gpu asic simulator wide range different language tasks vision tasks show sponge examples produced latency degradation observed effect less pronounced demonstrate effectiveness sponge examples real world mount attack microsoft azure translator show increase response time ms conclude proposing defense strategy shifting analysis energy consumption hardware average case worst case perspective link https ieeexplore ieee org document,"['r', 'sponge', 'examples', 'energy', 'latency', 'attacks', 'neural', 'networksabstract', 'high', 'energy', 'costs', 'neural', 'network', 'training', 'inference', 'led', 'use', 'acceleration', 'hardware', 'gpus', 'tpus', 'devices', 'enable', 'us', 'train', 'large', 'scale', 'neural', 'networks', 'datacenters', 'deploy', 'edge', 'devices', 'designers', 'focus', 'far', 'average', 'case', 'performance', 'work', 'introduce', 'novel', 'threat', 'vector', 'neural', 'networks', 'whose', 'energy', 'consumption', 'decision', 'latency', 'critical', 'show', 'adversaries', 'exploit', 'carefully', 'crafted', 'sponge', 'examples', 'inputs', 'designed', 'maximise', 'energy', 'consumption', 'latency', 'drive', 'machine', 'learning', 'ml', 'systems', 'towards', 'worst', 'case', 'performance', 'sponge', 'examples', 'knowledge', 'first', 'denial', 'service', 'attack', 'ml', 'components', 'systems', 'mount', 'two', 'variants', 'sponge', 'attack', 'wide', 'range', 'state', 'art', 'neural', 'network', 'models', 'find', 'language', 'models', 'surprisingly', 'vulnerable', 'sponge', 'examples', 'frequently', 'increase', 'latency', 'energy', 'consumption', 'models', 'factor', 'extensive', 'experiments', 'show', 'attack', 'effective', 'across', 'different', 'hardware', 'platforms', 'cpu', 'gpu', 'asic', 'simulator', 'wide', 'range', 'different', 'language', 'tasks', 'vision', 'tasks', 'show', 'sponge', 'examples', 'produced', 'latency', 'degradation', 'observed', 'effect', 'less', 'pronounced', 'demonstrate', 'effectiveness', 'sponge', 'examples', 'real', 'world', 'mount', 'attack', 'microsoft', 'azure', 'translator', 'show', 'increase', 'response', 'time', 'ms', 'conclude', 'proposing', 'defense', 'strategy', 'shifting', 'analysis', 'energy', 'consumption', 'hardware', 'average', 'case', 'worst', 'case', 'perspective', 'link', 'https', 'ieeexplore', 'ieee', 'org', 'document']","['r', 'spong', 'exampl', 'energi', 'latenc', 'attack', 'neural', 'networksabstract', 'high', 'energi', 'cost', 'neural', 'network', 'train', 'infer', 'led', 'use', 'acceler', 'hardwar', 'gpu', 'tpu', 'devic', 'enabl', 'us', 'train', 'larg', 'scale', 'neural', 'network', 'datacent', 'deploy', 'edg', 'devic', 'design', 'focu', 'far', 'averag', 'case', 'perform', 'work', 'introduc', 'novel', 'threat', 'vector', 'neural', 'network', 'whose', 'energi', 'consumpt', 'decis', 'latenc', 'critic', 'show', 'adversari', 'exploit', 'care', 'craft', 'spong', 'exampl', 'input', 'design', 'maximis', 'energi', 'consumpt', 'latenc', 'drive', 'machin', 'learn', 'ml', 'system', 'toward', 'worst', 'case', 'perform', 'spong', 'exampl', 'knowledg', 'first', 'denial', 'servic', 'attack', 'ml', 'compon', 'system', 'mount', 'two', 'variant', 'spong', 'attack', 'wide', 'rang', 'state', 'art', 'neural', 'network', 'model', 'find', 'languag', 'model', 'surprisingli', 'vulner', 'spong', 'exampl', 'frequent', 'increas', 'latenc', 'energi', 'consumpt', 'model', 'factor', 'extens', 'experi', 'show', 'attack', 'effect', 'across', 'differ', 'hardwar', 'platform', 'cpu', 'gpu', 'asic', 'simul', 'wide', 'rang', 'differ', 'languag', 'task', 'vision', 'task', 'show', 'spong', 'exampl', 'produc', 'latenc', 'degrad', 'observ', 'effect', 'less', 'pronounc', 'demonstr', 'effect', 'spong', 'exampl', 'real', 'world', 'mount', 'attack', 'microsoft', 'azur', 'translat', 'show', 'increas', 'respons', 'time', 'ms', 'conclud', 'propos', 'defens', 'strategi', 'shift', 'analysi', 'energi', 'consumpt', 'hardwar', 'averag', 'case', 'worst', 'case', 'perspect', 'link', 'http', 'ieeexplor', 'ieee', 'org', 'document']"
318,347,347,StixTheNerd,ved9hb,[D] Any way to validate the performance of component models in a T-learner? (CausalML Python)," So, I'm running into the problem of wanting to validate the performance of each of the models that compose our T-learner. I'm aware this doesn't validate the effectiveness of the model itself but I'm trying to diagnose issues and want to see if each of the component models is predicting the control/treatment effect accurately. I'm thinking I may just have to write my own T-learner script because I don't see any way to do this in CausalML but that shouldn't be too difficult. Just wanted to check if any of y'all knew how to do this before embarking on that journey.",0,0,2022-06-17 19:02:13, d  any way to validate the performance of component models in a t learner   causalml python , so  i m running into the problem of wanting to validate the performance of each of the models that compose our t learner  i m aware this doesn t validate the effectiveness of the model itself but i m trying to diagnose issues and want to see if each of the component models is predicting the control treatment effect accurately  i m thinking i may just have to write my own t learner script because i don t see any way to do this in causalml but that shouldn t be too difficult  just wanted to check if any of y all knew how to do this before embarking on that journey ,running problem wanting validate performance models compose learner aware validate effectiveness model trying diagnose issues want see component models predicting control treatment effect accurately thinking may write learner script see way causalml difficult wanted check knew embarking journey,way validate performance component models learner causalml python,way validate performance component models learner causalml pythonrunning problem wanting validate performance models compose learner aware validate effectiveness model trying diagnose issues want see component models predicting control treatment effect accurately thinking may write learner script see way causalml difficult wanted check knew embarking journey,"['way', 'validate', 'performance', 'component', 'models', 'learner', 'causalml', 'pythonrunning', 'problem', 'wanting', 'validate', 'performance', 'models', 'compose', 'learner', 'aware', 'validate', 'effectiveness', 'model', 'trying', 'diagnose', 'issues', 'want', 'see', 'component', 'models', 'predicting', 'control', 'treatment', 'effect', 'accurately', 'thinking', 'may', 'write', 'learner', 'script', 'see', 'way', 'causalml', 'difficult', 'wanted', 'check', 'knew', 'embarking', 'journey']","['way', 'valid', 'perform', 'compon', 'model', 'learner', 'causalml', 'pythonrun', 'problem', 'want', 'valid', 'perform', 'model', 'compos', 'learner', 'awar', 'valid', 'effect', 'model', 'tri', 'diagnos', 'issu', 'want', 'see', 'compon', 'model', 'predict', 'control', 'treatment', 'effect', 'accur', 'think', 'may', 'write', 'learner', 'script', 'see', 'way', 'causalml', 'difficult', 'want', 'check', 'knew', 'embark', 'journey']"
319,348,348,adamskadam,vdqiwm,"[P] I've implemented the first open-source realisation of Capacitron, an expressive VAE extension of the Tacotron 2 Text-To-Speech System and you can try it out","Hey everyone!

At the end of last year, I have submitted my Master's Thesis at TU Berlin, a report about the implementation and evaluation of an expressive Variational Autoencoder augmentation of the Tacotron Text-To-Speech System, called [Capacitron](https://arxiv.org/abs/1906.03402) from the Google team.

With some help from the awesome [Coqui TTS community](https://github.com/coqui-ai/TTS), we have managed to build the prosody encoder VAE module in a modular way, so that this prosodic augmentation can be also implemented with Tacotron 2 - this is a massive improvement in stability and quality compared to the original method, where the authors worked with a Tacotron 1 based architecture.

I have written a short technical summary/blog post about some implementation details and audio examples on [Medium](https://medium.com/why-do-birds-tech-blog/implementing-capacitron-an-expressive-text-to-speech-vae-model-a-masters-thesis-project-f5c7c490124b).

If you'd like to try out the model, you can do so in [this colab](https://colab.research.google.com/drive/1kFnghACymmCC9mKEstN65F6mGnqHu81f#scrollTo=60a7KbITXrKM).

For the full thesis, follow [this link](https://www2.users.ak.tu-berlin.de/akgroup/ak_pub/abschlussarbeiten/2021/MasA_Froghyar.pdf).",8,43,2022-06-16 22:26:10, p  i ve implemented the first open source realisation of capacitron  an expressive vae extension of the tacotron  text to speech system and you can try it out,hey everyone at the end of last year  i have submitted my master s thesis at tu berlin  a report about the implementation and evaluation of an expressive variational autoencoder augmentation of the tacotron text to speech system  called  capacitron  https with some help from the awesome  coqui tts community  https i have written a short technical summary blog post about some implementation details and audio examples on  medium  https if you d like to try out the model  you can do so in  this colab  https for the full thesis  follow  this link  https   www users ak tu berlin de akgroup ak_pub abschlussarbeiten  masa_froghyar pdf  ,hey everyone end last year submitted master thesis tu berlin report implementation evaluation expressive variational autoencoder augmentation tacotron text speech system called capacitron https help awesome coqui tts community https written short technical summary blog post implementation details audio examples medium https like try model colab https full thesis follow link https www users ak tu berlin de akgroup ak_pub abschlussarbeiten masa_froghyar pdf,p implemented first open source realisation capacitron expressive vae extension tacotron text speech system try,p implemented first open source realisation capacitron expressive vae extension tacotron text speech system tryhey everyone end last year submitted master thesis tu berlin report implementation evaluation expressive variational autoencoder augmentation tacotron text speech system called capacitron https help awesome coqui tts community https written short technical summary blog post implementation details audio examples medium https like try model colab https full thesis follow link https www users ak tu berlin de akgroup ak_pub abschlussarbeiten masa_froghyar pdf,"['p', 'implemented', 'first', 'open', 'source', 'realisation', 'capacitron', 'expressive', 'vae', 'extension', 'tacotron', 'text', 'speech', 'system', 'tryhey', 'everyone', 'end', 'last', 'year', 'submitted', 'master', 'thesis', 'tu', 'berlin', 'report', 'implementation', 'evaluation', 'expressive', 'variational', 'autoencoder', 'augmentation', 'tacotron', 'text', 'speech', 'system', 'called', 'capacitron', 'https', 'help', 'awesome', 'coqui', 'tts', 'community', 'https', 'written', 'short', 'technical', 'summary', 'blog', 'post', 'implementation', 'details', 'audio', 'examples', 'medium', 'https', 'like', 'try', 'model', 'colab', 'https', 'full', 'thesis', 'follow', 'link', 'https', 'www', 'users', 'ak', 'tu', 'berlin', 'de', 'akgroup', 'ak_pub', 'abschlussarbeiten', 'masa_froghyar', 'pdf']","['p', 'implement', 'first', 'open', 'sourc', 'realis', 'capacitron', 'express', 'vae', 'extens', 'tacotron', 'text', 'speech', 'system', 'tryhey', 'everyon', 'end', 'last', 'year', 'submit', 'master', 'thesi', 'tu', 'berlin', 'report', 'implement', 'evalu', 'express', 'variat', 'autoencod', 'augment', 'tacotron', 'text', 'speech', 'system', 'call', 'capacitron', 'http', 'help', 'awesom', 'coqui', 'tt', 'commun', 'http', 'written', 'short', 'technic', 'summari', 'blog', 'post', 'implement', 'detail', 'audio', 'exampl', 'medium', 'http', 'like', 'tri', 'model', 'colab', 'http', 'full', 'thesi', 'follow', 'link', 'http', 'www', 'user', 'ak', 'tu', 'berlin', 'de', 'akgroup', 'ak_pub', 'abschlussarbeiten', 'masa_froghyar', 'pdf']"
320,349,349,Mmats,vdvpir,[R] Train Models 18x Faster with Reducible Holdout Loss Selection (RHO-LOSS),"Paper:  [\[2206.07137\] Prioritized Training on Points that are Learnable, Worth Learning, and Not Yet Learnt (arxiv.org)](https://arxiv.org/abs/2206.07137) 

Abstract:  Training on web-scale data can take months. But much computation and time is wasted on redundant and noisy points that are already learnt or not learnable. To accelerate training, we introduce Reducible Holdout Loss Selection (RHO-LOSS), a simple but principled technique which selects approximately those points for training that most reduce the model's generalization loss. As a result, RHO-LOSS mitigates the weaknesses of existing data selection methods: techniques from the optimization literature typically select 'hard' (e.g. high loss) points, but such points are often noisy (not learnable) or less task-relevant. Conversely, curriculum learning prioritizes 'easy' points, but such points need not be trained on once learned. In contrast, RHO-LOSS selects points that are learnable, worth learning, and not yet learnt. RHO-LOSS trains in far fewer steps than prior art, improves accuracy, and speeds up training on a wide range of datasets, hyperparameters, and architectures (MLPs, CNNs, and BERT). On the large web-scraped image dataset Clothing-1M, RHO-LOSS trains in 18x fewer steps and reaches 2% higher final accuracy than uniform data shuffling.",2,19,2022-06-17 02:24:15, r  train models x faster with reducible holdout loss selection  rho loss ,paper          prioritized training on points that are learnable  worth learning  and not yet learnt  arxiv org   https abstract   training on web scale data can take months  but much computation and time is wasted on redundant and noisy points that are already learnt or not learnable  to accelerate training  we introduce reducible holdout loss selection  rho loss   a simple but principled technique which selects approximately those points for training that most reduce the model s generalization loss  as a result  rho loss mitigates the weaknesses of existing data selection methods  techniques from the optimization literature typically select  hard   e g  high loss  points  but such points are often noisy  not learnable  or less task relevant  conversely  curriculum learning prioritizes  easy  points  but such points need not be trained on once learned  in contrast  rho loss selects points that are learnable  worth learning  and not yet learnt  rho loss trains in far fewer steps than prior art  improves accuracy  and speeds up training on a wide range of datasets  hyperparameters  and architectures  mlps  cnns  and bert   on the large web scraped image dataset clothing m  rho loss trains in x fewer steps and reaches   higher final accuracy than uniform data shuffling ,paper prioritized training points learnable worth learning yet learnt arxiv org https abstract training web scale data take months much computation time wasted redundant noisy points already learnt learnable accelerate training introduce reducible holdout loss selection rho loss simple principled technique selects approximately points training reduce model generalization loss result rho loss mitigates weaknesses existing data selection methods techniques optimization literature typically select hard e g high loss points points often noisy learnable less task relevant conversely curriculum learning prioritizes easy points points need trained learned contrast rho loss selects points learnable worth learning yet learnt rho loss trains far fewer steps prior art improves accuracy speeds training wide range datasets hyperparameters architectures mlps cnns bert large web scraped image dataset clothing rho loss trains x fewer steps reaches higher final accuracy uniform data shuffling,r train models x faster reducible holdout loss selection rho loss,r train models x faster reducible holdout loss selection rho losspaper prioritized training points learnable worth learning yet learnt arxiv org https abstract training web scale data take months much computation time wasted redundant noisy points already learnt learnable accelerate training introduce reducible holdout loss selection rho loss simple principled technique selects approximately points training reduce model generalization loss result rho loss mitigates weaknesses existing data selection methods techniques optimization literature typically select hard e g high loss points points often noisy learnable less task relevant conversely curriculum learning prioritizes easy points points need trained learned contrast rho loss selects points learnable worth learning yet learnt rho loss trains far fewer steps prior art improves accuracy speeds training wide range datasets hyperparameters architectures mlps cnns bert large web scraped image dataset clothing rho loss trains x fewer steps reaches higher final accuracy uniform data shuffling,"['r', 'train', 'models', 'x', 'faster', 'reducible', 'holdout', 'loss', 'selection', 'rho', 'losspaper', 'prioritized', 'training', 'points', 'learnable', 'worth', 'learning', 'yet', 'learnt', 'arxiv', 'org', 'https', 'abstract', 'training', 'web', 'scale', 'data', 'take', 'months', 'much', 'computation', 'time', 'wasted', 'redundant', 'noisy', 'points', 'already', 'learnt', 'learnable', 'accelerate', 'training', 'introduce', 'reducible', 'holdout', 'loss', 'selection', 'rho', 'loss', 'simple', 'principled', 'technique', 'selects', 'approximately', 'points', 'training', 'reduce', 'model', 'generalization', 'loss', 'result', 'rho', 'loss', 'mitigates', 'weaknesses', 'existing', 'data', 'selection', 'methods', 'techniques', 'optimization', 'literature', 'typically', 'select', 'hard', 'e', 'g', 'high', 'loss', 'points', 'points', 'often', 'noisy', 'learnable', 'less', 'task', 'relevant', 'conversely', 'curriculum', 'learning', 'prioritizes', 'easy', 'points', 'points', 'need', 'trained', 'learned', 'contrast', 'rho', 'loss', 'selects', 'points', 'learnable', 'worth', 'learning', 'yet', 'learnt', 'rho', 'loss', 'trains', 'far', 'fewer', 'steps', 'prior', 'art', 'improves', 'accuracy', 'speeds', 'training', 'wide', 'range', 'datasets', 'hyperparameters', 'architectures', 'mlps', 'cnns', 'bert', 'large', 'web', 'scraped', 'image', 'dataset', 'clothing', 'rho', 'loss', 'trains', 'x', 'fewer', 'steps', 'reaches', 'higher', 'final', 'accuracy', 'uniform', 'data', 'shuffling']","['r', 'train', 'model', 'x', 'faster', 'reduc', 'holdout', 'loss', 'select', 'rho', 'losspap', 'priorit', 'train', 'point', 'learnabl', 'worth', 'learn', 'yet', 'learnt', 'arxiv', 'org', 'http', 'abstract', 'train', 'web', 'scale', 'data', 'take', 'month', 'much', 'comput', 'time', 'wast', 'redund', 'noisi', 'point', 'alreadi', 'learnt', 'learnabl', 'acceler', 'train', 'introduc', 'reduc', 'holdout', 'loss', 'select', 'rho', 'loss', 'simpl', 'principl', 'techniqu', 'select', 'approxim', 'point', 'train', 'reduc', 'model', 'gener', 'loss', 'result', 'rho', 'loss', 'mitig', 'weak', 'exist', 'data', 'select', 'method', 'techniqu', 'optim', 'literatur', 'typic', 'select', 'hard', 'e', 'g', 'high', 'loss', 'point', 'point', 'often', 'noisi', 'learnabl', 'less', 'task', 'relev', 'convers', 'curriculum', 'learn', 'priorit', 'easi', 'point', 'point', 'need', 'train', 'learn', 'contrast', 'rho', 'loss', 'select', 'point', 'learnabl', 'worth', 'learn', 'yet', 'learnt', 'rho', 'loss', 'train', 'far', 'fewer', 'step', 'prior', 'art', 'improv', 'accuraci', 'speed', 'train', 'wide', 'rang', 'dataset', 'hyperparamet', 'architectur', 'mlp', 'cnn', 'bert', 'larg', 'web', 'scrape', 'imag', 'dataset', 'cloth', 'rho', 'loss', 'train', 'x', 'fewer', 'step', 'reach', 'higher', 'final', 'accuraci', 'uniform', 'data', 'shuffl']"
321,350,350,grisp98,vec03w,[D] 3D Attention Module,"Hi, I am working on a classification of 3D MRI where I want to combine a mask and a raw MRI. Basically, the model must have 2 input channels, one for the MRI and one for its mask. Where should I start ? Are there any implemented models I can use ?",19,1,2022-06-17 17:56:15, d  d attention module,hi  i am working on a classification of d mri where i want to combine a mask and a raw mri  basically  the model must have  input channels  one for the mri and one for its mask  where should i start   are there any implemented models i can use  ,hi working classification mri want combine mask raw mri basically model must input channels one mri one mask start implemented models use,attention module,attention modulehi working classification mri want combine mask raw mri basically model must input channels one mri one mask start implemented models use,"['attention', 'modulehi', 'working', 'classification', 'mri', 'want', 'combine', 'mask', 'raw', 'mri', 'basically', 'model', 'must', 'input', 'channels', 'one', 'mri', 'one', 'mask', 'start', 'implemented', 'models', 'use']","['attent', 'modulehi', 'work', 'classif', 'mri', 'want', 'combin', 'mask', 'raw', 'mri', 'basic', 'model', 'must', 'input', 'channel', 'one', 'mri', 'one', 'mask', 'start', 'implement', 'model', 'use']"
322,351,351,sarmientoj24,ve8zkz,[D] Anti-aliasing techniques or functions for segmentation masks,What techniques or functions can I use to smoothen out segmentation mask edges?,3,1,2022-06-17 14:46:51, d  anti aliasing techniques or functions for segmentation masks,what techniques or functions can i use to smoothen out segmentation mask edges ,techniques functions use smoothen segmentation mask edges,anti aliasing techniques functions segmentation masks,anti aliasing techniques functions segmentation maskstechniques functions use smoothen segmentation mask edges,"['anti', 'aliasing', 'techniques', 'functions', 'segmentation', 'maskstechniques', 'functions', 'use', 'smoothen', 'segmentation', 'mask', 'edges']","['anti', 'alias', 'techniqu', 'function', 'segment', 'maskstechniqu', 'function', 'use', 'smoothen', 'segment', 'mask', 'edg']"
323,352,352,NedML,vd96u0,"[D] What is considered to be a ""bad research paper"" in your opinion?","I find that although most ML researchers are fairly productive, the quality of publication varies a lot in the ML community.

What is in your opinion are the factors that distinguish a good publication from a bad one (and vice versa)?",51,111,2022-06-16 06:08:39, d  what is considered to be a bad research paper in your opinion ,i find that although most ml researchers are fairly productive  the quality of publication varies a lot in the ml community what is in your opinion are the factors that distinguish a good publication from a bad one  and vice versa  ,find although ml researchers fairly productive quality publication varies lot ml community opinion factors distinguish good publication bad one vice versa,considered bad research paper opinion,considered bad research paper opinionfind although ml researchers fairly productive quality publication varies lot ml community opinion factors distinguish good publication bad one vice versa,"['considered', 'bad', 'research', 'paper', 'opinionfind', 'although', 'ml', 'researchers', 'fairly', 'productive', 'quality', 'publication', 'varies', 'lot', 'ml', 'community', 'opinion', 'factors', 'distinguish', 'good', 'publication', 'bad', 'one', 'vice', 'versa']","['consid', 'bad', 'research', 'paper', 'opinionfind', 'although', 'ml', 'research', 'fairli', 'product', 'qualiti', 'public', 'vari', 'lot', 'ml', 'commun', 'opinion', 'factor', 'distinguish', 'good', 'public', 'bad', 'one', 'vice', 'versa']"
324,353,353,rodrigo-arenas,vdnroa,[P] Adaptive learning in Genetic Algorithms for Hyperparameters Tuning,"Hi, I just wanted to share that I've released the version 0.9.0 of [sklearn-genetic-opt](https://sklearn-genetic-opt.readthedocs.io/en/stable/), the main change includes the option to use adaptive parameters to explore the space of hyperparameters during tuning, this has the advantage of being able to explore larger regions at the first iterations and keep the best ones at the end.

You can learn more about it [here](https://sklearn-genetic-opt.readthedocs.io/en/stable/tutorials/adapters.html), any suggestion or contribution is welcome :)

https://preview.redd.it/unrw6dtsxz591.png?width=640&format=png&auto=webp&s=a59c91d6560806fdf1b12c24faee6aad38d75c26",28,7,2022-06-16 20:21:10, p  adaptive learning in genetic algorithms for hyperparameters tuning,hi  i just wanted to share that i ve released the version    of  sklearn genetic opt  https you can learn more about it  here  https https   preview redd it unrwdtsxz png width  format png auto webp s acdfdfbcfaeeaaddc,hi wanted share released version sklearn genetic opt https learn https https preview redd unrwdtsxz png width format png auto webp acdfdfbcfaeeaaddc,p adaptive learning genetic algorithms hyperparameters tuning,p adaptive learning genetic algorithms hyperparameters tuninghi wanted share released version sklearn genetic opt https learn https https preview redd unrwdtsxz png width format png auto webp acdfdfbcfaeeaaddc,"['p', 'adaptive', 'learning', 'genetic', 'algorithms', 'hyperparameters', 'tuninghi', 'wanted', 'share', 'released', 'version', 'sklearn', 'genetic', 'opt', 'https', 'learn', 'https', 'https', 'preview', 'redd', 'unrwdtsxz', 'png', 'width', 'format', 'png', 'auto', 'webp', 'acdfdfbcfaeeaaddc']","['p', 'adapt', 'learn', 'genet', 'algorithm', 'hyperparamet', 'tuninghi', 'want', 'share', 'releas', 'version', 'sklearn', 'genet', 'opt', 'http', 'learn', 'http', 'http', 'preview', 'redd', 'unrwdtsxz', 'png', 'width', 'format', 'png', 'auto', 'webp', 'acdfdfbcfaeeaaddc']"
325,355,355,Lunch_More,ve74ba,[D] How to find an intuitive article for the future research,"After working in an area for more than 2 years I am still not confident that how to recognize an intuitive research paper that further ignites my Ph.D. journey.  Some people think that followed by individuals or organizations (corporate or academia).  My opinion is following specific individuals or organizations might be inefficient or boring sometimes. One thing common in both is they halt the releases of code until they suck all the juice out of it. After the code release, we pity Ph.D. students only making ridiculous GIFs for ML twitter because there is nothing left for us. Should we keep in mind the beautiful results OR the future perspective of a research paper? One example is Ian Goodfellow's GANs paper, the results were not that polished but there was a future that everyone perceived. Winding up my post, which factors do we keep in mind choosing a paper?",2,0,2022-06-17 12:35:34, d  how to find an intuitive article for the future research,after working in an area for more than  years i am still not confident that how to recognize an intuitive research paper that further ignites my ph d  journey   some people think that followed by individuals or organizations  corporate or academia    my opinion is following specific individuals or organizations might be inefficient or boring sometimes  one thing common in both is they halt the releases of code until they suck all the juice out of it  after the code release  we pity ph d  students only making ridiculous gifs for ml twitter because there is nothing left for us  should we keep in mind the beautiful results or the future perspective of a research paper  one example is ian goodfellow s gans paper  the results were not that polished but there was a future that everyone perceived  winding up my post  which factors do we keep in mind choosing a paper ,working area years still confident recognize intuitive research paper ignites ph journey people think followed individuals organizations corporate academia opinion following specific individuals organizations might inefficient boring sometimes one thing common halt releases code suck juice code release pity ph students making ridiculous gifs ml twitter nothing left us keep mind beautiful results future perspective research paper one example ian goodfellow gans paper results polished future everyone perceived winding post factors keep mind choosing paper,find intuitive article future research,find intuitive article future researchworking area years still confident recognize intuitive research paper ignites ph journey people think followed individuals organizations corporate academia opinion following specific individuals organizations might inefficient boring sometimes one thing common halt releases code suck juice code release pity ph students making ridiculous gifs ml twitter nothing left us keep mind beautiful results future perspective research paper one example ian goodfellow gans paper results polished future everyone perceived winding post factors keep mind choosing paper,"['find', 'intuitive', 'article', 'future', 'researchworking', 'area', 'years', 'still', 'confident', 'recognize', 'intuitive', 'research', 'paper', 'ignites', 'ph', 'journey', 'people', 'think', 'followed', 'individuals', 'organizations', 'corporate', 'academia', 'opinion', 'following', 'specific', 'individuals', 'organizations', 'might', 'inefficient', 'boring', 'sometimes', 'one', 'thing', 'common', 'halt', 'releases', 'code', 'suck', 'juice', 'code', 'release', 'pity', 'ph', 'students', 'making', 'ridiculous', 'gifs', 'ml', 'twitter', 'nothing', 'left', 'us', 'keep', 'mind', 'beautiful', 'results', 'future', 'perspective', 'research', 'paper', 'one', 'example', 'ian', 'goodfellow', 'gans', 'paper', 'results', 'polished', 'future', 'everyone', 'perceived', 'winding', 'post', 'factors', 'keep', 'mind', 'choosing', 'paper']","['find', 'intuit', 'articl', 'futur', 'researchwork', 'area', 'year', 'still', 'confid', 'recogn', 'intuit', 'research', 'paper', 'ignit', 'ph', 'journey', 'peopl', 'think', 'follow', 'individu', 'organ', 'corpor', 'academia', 'opinion', 'follow', 'specif', 'individu', 'organ', 'might', 'ineffici', 'bore', 'sometim', 'one', 'thing', 'common', 'halt', 'releas', 'code', 'suck', 'juic', 'code', 'releas', 'piti', 'ph', 'student', 'make', 'ridicul', 'gif', 'ml', 'twitter', 'noth', 'left', 'us', 'keep', 'mind', 'beauti', 'result', 'futur', 'perspect', 'research', 'paper', 'one', 'exampl', 'ian', 'goodfellow', 'gan', 'paper', 'result', 'polish', 'futur', 'everyon', 'perceiv', 'wind', 'post', 'factor', 'keep', 'mind', 'choos', 'paper']"
326,356,356,mrobo_5ht2a,vd1ey0,[P]: mmap_ninja: Speedup your training dramatically by using memory-mapped files for your dataset,"Repo link: [https://github.com/hristo-vrigazov/mmap.ninja](https://github.com/hristo-vrigazov/mmap.ninja)

Images Colab notebook: [https://colab.research.google.com/drive/1-WMtVyfxx2aUMeV7vlG48Ia27-5cxnrS?usp=sharing](https://colab.research.google.com/drive/1-WMtVyfxx2aUMeV7vlG48Ia27-5cxnrS?usp=sharing)

Texts Colab notebook: [https://colab.research.google.com/drive/18bEwylFwx4owMpb-RAkJZS\_9JrrUcFd7?usp=sharing](https://colab.research.google.com/drive/18bEwylFwx4owMpb-RAkJZS_9JrrUcFd7?usp=sharing)

Hello everyone, I wrote a small, but very useful library for my personal projects and decided to share it with the world.

It deals with filesystem I/O during machine learning training. A large portion of the time spent training (especially if GPU is available) is spent on reading/writing images from the disk (or text for that matter).

For example, take the COCO 2017 validation dataset of images (I just had this one available on my machine, nothing special about it). If you can't load it all into memory at once (which is very often the case in real projects, since new data is constantly coming in), you would read the images on the fly from a jpeg file. One iteration over all images takes \~35 seconds. This is time wasted on **every single epoch**, and it adds up quickly. For example, training for 100 epochs adds almost an extra hour to your training with no benefits.

However, there is this fantastic thing called a memory-mapped file, which is specifically optimized for I/O. A **memory-mapped file** is a file that is physically present on disk in a way that the correlation between the file and the memory space permits applications to treat the mapped portions as if it were primary memory.

Now, in NumPy, there is already a `np.memmap`, that is lightning fast and awesome, but to use it, all your images have to be of the same shape, which is usually not the case. So you have to either pad the images (takes an enormous amount of disk space) or resize them all to the same shape (but this way you are committing very early to a specific resolution), neither of which is a good option.

So I wrote a library that allows you to store any dataset of numpy arrays (of varying shapes, or even varying number of axes - e.g. mix grayscale and RGB images) in a memory-mapped format. On the outside, the API is the same as it is with a usual \`list\`.

It works by storing everything in a flat buffer, storing the offsets and the shapes in separate arrays, and it reshapes on the fly, whenever a sample is requested. It also does this lightning-fast, one iteration over the whole COCO 2017 validation dataset takes \~0.2s (compared to 35 seconds without memory maps) if stored in a memory-mapped format. Moreover, when you access an item, e.g. imgs\[5\], the result is just a normal NumPy array, so you can use it with any framework (PyTorch, Tensorflow, MxNet, etc.). You can also easily append and extend new data just as you would with a Python \`list\`, so if you want to, you can use it as a persistent shared memory between multiple processes.

Currently, there are three main APIs:

* Numpy base API - which is used for arrays with consistent shapes (this is just a wrapper of np.memmap)
* RaggedMmap - which is used for arrays with different shapes, or even number of axes (e.g. you can store images, your model's predictions here). Around **20 times faster** than storing images on disk.
* StringsMmap - same, but for text. Around **10 times faster** than storing text files on disk.

There are benchmarks in the [README.md](https://readme.md/) of the project, in which you can compare it to other approaches. In short, mmap\_ninja allows you to trade disk space for significantly faster memory I/O.

For example, in a recent project, we started with a tutorial from PyTorch's documentation, and after we trained with memory-mapped files, the whole pipeline took 40% less.

The implementation is well tested, with almost full coverage, and I have lots of ideas to extend this and add more documentation, which I will do if there is interest.

Would be super glad if anyone finds it useful and/or has any kind of question or comment :)

[https://github.com/hristo-vrigazov/mmap.ninja](https://github.com/hristo-vrigazov/mmap.ninja)",61,190,2022-06-16 00:07:08, p   mmap_ninja  speedup your training dramatically by using memory mapped files for your dataset,repo link   https images colab notebook   https texts colab notebook   https hello everyone  i wrote a small  but very useful library for my personal projects and decided to share it with the world it deals with filesystem i o during machine learning training  a large portion of the time spent training  especially if gpu is available  is spent on reading writing images from the disk  or text for that matter  for example  take the coco  validation dataset of images  i just had this one available on my machine  nothing special about it   if you can t load it all into memory at once  which is very often the case in real projects  since new data is constantly coming in   you would read the images on the fly from a jpeg file  one iteration over all images takes    seconds  this is time wasted on   every single epoch    and it adds up quickly  for example  training for  epochs adds almost an extra hour to your training with no benefits however  there is this fantastic thing called a memory mapped file  which is specifically optimized for i o  a   memory mapped file   is a file that is physically present on disk in a way that the correlation between the file and the memory space permits applications to treat the mapped portions as if it were primary memory now  in numpy  there is already a  np memmap   that is lightning fast and awesome  but to use it  all your images have to be of the same shape  which is usually not the case  so you have to either pad the images  takes an enormous amount of disk space  or resize them all to the same shape  but this way you are committing very early to a specific resolution   neither of which is a good option so i wrote a library that allows you to store any dataset of numpy arrays  of varying shapes  or even varying number of axes   e g  mix grayscale and rgb images  in a memory mapped format  on the outside  the api is the same as it is with a usual   list   it works by storing everything in a flat buffer  storing the offsets and the shapes in separate arrays  and it reshapes on the fly  whenever a sample is requested  it also does this lightning fast  one iteration over the whole coco  validation dataset takes    s  compared to  seconds without memory maps  if stored in a memory mapped format  moreover  when you access an item  e g  imgs      the result is just a normal numpy array  so you can use it with any framework  pytorch  tensorflow  mxnet  etc    you can also easily append and extend new data just as you would with a python   list    so if you want to  you can use it as a persistent shared memory between multiple processes currently  there are three main apis   numpy base api   which is used for arrays with consistent shapes  this is just a wrapper of np memmap   raggedmmap   which is used for arrays with different shapes  or even number of axes  e g  you can store images  your model s predictions here   around    times faster   than storing images on disk   stringsmmap   same  but for text  around    times faster   than storing text files on disk there are benchmarks in the  readme md  https for example  in a recent project  we started with a tutorial from pytorch s documentation  and after we trained with memory mapped files  the whole pipeline took   less the implementation is well tested  with almost full coverage  and i have lots of ideas to extend this and add more documentation  which i will do if there is interest would be super glad if anyone finds it useful and or has any kind of question or comment    https   github com hristo vrigazov mmap ninja  https   github com hristo vrigazov mmap ninja ,repo link https images colab notebook https texts colab notebook https hello everyone wrote small useful library personal projects decided share world deals filesystem machine learning training large portion time spent training especially gpu available spent reading writing images disk text matter example take coco validation dataset images one available machine nothing special load memory often case real projects since data constantly coming would read images fly jpeg file one iteration images takes seconds time wasted every single epoch adds quickly example training epochs adds almost extra hour training benefits however fantastic thing called memory mapped file specifically optimized memory mapped file file physically present disk way correlation file memory space permits applications treat mapped portions primary memory numpy already np memmap lightning fast awesome use images shape usually case either pad images takes enormous amount disk space resize shape way committing early specific resolution neither good option wrote library allows store dataset numpy arrays varying shapes even varying number axes e g mix grayscale rgb images memory mapped format outside api usual works storing everything flat buffer storing offsets shapes separate arrays reshapes fly whenever sample requested also lightning fast one iteration whole coco validation dataset takes compared seconds without memory maps stored memory mapped format moreover access item e g imgs result normal numpy array use framework pytorch tensorflow mxnet etc also easily append extend data would python want use persistent shared memory multiple processes currently three main apis numpy base api used arrays consistent shapes wrapper np memmap raggedmmap used arrays different shapes even number axes e g store images model predictions around times faster storing images disk stringsmmap text around times faster storing text files disk benchmarks readme md https example recent project started tutorial pytorch documentation trained memory mapped files whole pipeline took less implementation well tested almost full coverage lots ideas extend documentation interest would super glad anyone finds useful kind question comment https github com hristo vrigazov mmap ninja https github com hristo vrigazov mmap ninja,p mmap_ninja speedup training dramatically using memory mapped files dataset,p mmap_ninja speedup training dramatically using memory mapped files datasetrepo link https images colab notebook https texts colab notebook https hello everyone wrote small useful library personal projects decided share world deals filesystem machine learning training large portion time spent training especially gpu available spent reading writing images disk text matter example take coco validation dataset images one available machine nothing special load memory often case real projects since data constantly coming would read images fly jpeg file one iteration images takes seconds time wasted every single epoch adds quickly example training epochs adds almost extra hour training benefits however fantastic thing called memory mapped file specifically optimized memory mapped file file physically present disk way correlation file memory space permits applications treat mapped portions primary memory numpy already np memmap lightning fast awesome use images shape usually case either pad images takes enormous amount disk space resize shape way committing early specific resolution neither good option wrote library allows store dataset numpy arrays varying shapes even varying number axes e g mix grayscale rgb images memory mapped format outside api usual works storing everything flat buffer storing offsets shapes separate arrays reshapes fly whenever sample requested also lightning fast one iteration whole coco validation dataset takes compared seconds without memory maps stored memory mapped format moreover access item e g imgs result normal numpy array use framework pytorch tensorflow mxnet etc also easily append extend data would python want use persistent shared memory multiple processes currently three main apis numpy base api used arrays consistent shapes wrapper np memmap raggedmmap used arrays different shapes even number axes e g store images model predictions around times faster storing images disk stringsmmap text around times faster storing text files disk benchmarks readme md https example recent project started tutorial pytorch documentation trained memory mapped files whole pipeline took less implementation well tested almost full coverage lots ideas extend documentation interest would super glad anyone finds useful kind question comment https github com hristo vrigazov mmap ninja https github com hristo vrigazov mmap ninja,"['p', 'mmap_ninja', 'speedup', 'training', 'dramatically', 'using', 'memory', 'mapped', 'files', 'datasetrepo', 'link', 'https', 'images', 'colab', 'notebook', 'https', 'texts', 'colab', 'notebook', 'https', 'hello', 'everyone', 'wrote', 'small', 'useful', 'library', 'personal', 'projects', 'decided', 'share', 'world', 'deals', 'filesystem', 'machine', 'learning', 'training', 'large', 'portion', 'time', 'spent', 'training', 'especially', 'gpu', 'available', 'spent', 'reading', 'writing', 'images', 'disk', 'text', 'matter', 'example', 'take', 'coco', 'validation', 'dataset', 'images', 'one', 'available', 'machine', 'nothing', 'special', 'load', 'memory', 'often', 'case', 'real', 'projects', 'since', 'data', 'constantly', 'coming', 'would', 'read', 'images', 'fly', 'jpeg', 'file', 'one', 'iteration', 'images', 'takes', 'seconds', 'time', 'wasted', 'every', 'single', 'epoch', 'adds', 'quickly', 'example', 'training', 'epochs', 'adds', 'almost', 'extra', 'hour', 'training', 'benefits', 'however', 'fantastic', 'thing', 'called', 'memory', 'mapped', 'file', 'specifically', 'optimized', 'memory', 'mapped', 'file', 'file', 'physically', 'present', 'disk', 'way', 'correlation', 'file', 'memory', 'space', 'permits', 'applications', 'treat', 'mapped', 'portions', 'primary', 'memory', 'numpy', 'already', 'np', 'memmap', 'lightning', 'fast', 'awesome', 'use', 'images', 'shape', 'usually', 'case', 'either', 'pad', 'images', 'takes', 'enormous', 'amount', 'disk', 'space', 'resize', 'shape', 'way', 'committing', 'early', 'specific', 'resolution', 'neither', 'good', 'option', 'wrote', 'library', 'allows', 'store', 'dataset', 'numpy', 'arrays', 'varying', 'shapes', 'even', 'varying', 'number', 'axes', 'e', 'g', 'mix', 'grayscale', 'rgb', 'images', 'memory', 'mapped', 'format', 'outside', 'api', 'usual', 'works', 'storing', 'everything', 'flat', 'buffer', 'storing', 'offsets', 'shapes', 'separate', 'arrays', 'reshapes', 'fly', 'whenever', 'sample', 'requested', 'also', 'lightning', 'fast', 'one', 'iteration', 'whole', 'coco', 'validation', 'dataset', 'takes', 'compared', 'seconds', 'without', 'memory', 'maps', 'stored', 'memory', 'mapped', 'format', 'moreover', 'access', 'item', 'e', 'g', 'imgs', 'result', 'normal', 'numpy', 'array', 'use', 'framework', 'pytorch', 'tensorflow', 'mxnet', 'etc', 'also', 'easily', 'append', 'extend', 'data', 'would', 'python', 'want', 'use', 'persistent', 'shared', 'memory', 'multiple', 'processes', 'currently', 'three', 'main', 'apis', 'numpy', 'base', 'api', 'used', 'arrays', 'consistent', 'shapes', 'wrapper', 'np', 'memmap', 'raggedmmap', 'used', 'arrays', 'different', 'shapes', 'even', 'number', 'axes', 'e', 'g', 'store', 'images', 'model', 'predictions', 'around', 'times', 'faster', 'storing', 'images', 'disk', 'stringsmmap', 'text', 'around', 'times', 'faster', 'storing', 'text', 'files', 'disk', 'benchmarks', 'readme', 'md', 'https', 'example', 'recent', 'project', 'started', 'tutorial', 'pytorch', 'documentation', 'trained', 'memory', 'mapped', 'files', 'whole', 'pipeline', 'took', 'less', 'implementation', 'well', 'tested', 'almost', 'full', 'coverage', 'lots', 'ideas', 'extend', 'documentation', 'interest', 'would', 'super', 'glad', 'anyone', 'finds', 'useful', 'kind', 'question', 'comment', 'https', 'github', 'com', 'hristo', 'vrigazov', 'mmap', 'ninja', 'https', 'github', 'com', 'hristo', 'vrigazov', 'mmap', 'ninja']","['p', 'mmap_ninja', 'speedup', 'train', 'dramat', 'use', 'memori', 'map', 'file', 'datasetrepo', 'link', 'http', 'imag', 'colab', 'notebook', 'http', 'text', 'colab', 'notebook', 'http', 'hello', 'everyon', 'wrote', 'small', 'use', 'librari', 'person', 'project', 'decid', 'share', 'world', 'deal', 'filesystem', 'machin', 'learn', 'train', 'larg', 'portion', 'time', 'spent', 'train', 'especi', 'gpu', 'avail', 'spent', 'read', 'write', 'imag', 'disk', 'text', 'matter', 'exampl', 'take', 'coco', 'valid', 'dataset', 'imag', 'one', 'avail', 'machin', 'noth', 'special', 'load', 'memori', 'often', 'case', 'real', 'project', 'sinc', 'data', 'constantli', 'come', 'would', 'read', 'imag', 'fli', 'jpeg', 'file', 'one', 'iter', 'imag', 'take', 'second', 'time', 'wast', 'everi', 'singl', 'epoch', 'add', 'quickli', 'exampl', 'train', 'epoch', 'add', 'almost', 'extra', 'hour', 'train', 'benefit', 'howev', 'fantast', 'thing', 'call', 'memori', 'map', 'file', 'specif', 'optim', 'memori', 'map', 'file', 'file', 'physic', 'present', 'disk', 'way', 'correl', 'file', 'memori', 'space', 'permit', 'applic', 'treat', 'map', 'portion', 'primari', 'memori', 'numpi', 'alreadi', 'np', 'memmap', 'lightn', 'fast', 'awesom', 'use', 'imag', 'shape', 'usual', 'case', 'either', 'pad', 'imag', 'take', 'enorm', 'amount', 'disk', 'space', 'resiz', 'shape', 'way', 'commit', 'earli', 'specif', 'resolut', 'neither', 'good', 'option', 'wrote', 'librari', 'allow', 'store', 'dataset', 'numpi', 'array', 'vari', 'shape', 'even', 'vari', 'number', 'axe', 'e', 'g', 'mix', 'grayscal', 'rgb', 'imag', 'memori', 'map', 'format', 'outsid', 'api', 'usual', 'work', 'store', 'everyth', 'flat', 'buffer', 'store', 'offset', 'shape', 'separ', 'array', 'reshap', 'fli', 'whenev', 'sampl', 'request', 'also', 'lightn', 'fast', 'one', 'iter', 'whole', 'coco', 'valid', 'dataset', 'take', 'compar', 'second', 'without', 'memori', 'map', 'store', 'memori', 'map', 'format', 'moreov', 'access', 'item', 'e', 'g', 'img', 'result', 'normal', 'numpi', 'array', 'use', 'framework', 'pytorch', 'tensorflow', 'mxnet', 'etc', 'also', 'easili', 'append', 'extend', 'data', 'would', 'python', 'want', 'use', 'persist', 'share', 'memori', 'multipl', 'process', 'current', 'three', 'main', 'api', 'numpi', 'base', 'api', 'use', 'array', 'consist', 'shape', 'wrapper', 'np', 'memmap', 'raggedmmap', 'use', 'array', 'differ', 'shape', 'even', 'number', 'axe', 'e', 'g', 'store', 'imag', 'model', 'predict', 'around', 'time', 'faster', 'store', 'imag', 'disk', 'stringsmmap', 'text', 'around', 'time', 'faster', 'store', 'text', 'file', 'disk', 'benchmark', 'readm', 'md', 'http', 'exampl', 'recent', 'project', 'start', 'tutori', 'pytorch', 'document', 'train', 'memori', 'map', 'file', 'whole', 'pipelin', 'took', 'less', 'implement', 'well', 'test', 'almost', 'full', 'coverag', 'lot', 'idea', 'extend', 'document', 'interest', 'would', 'super', 'glad', 'anyon', 'find', 'use', 'kind', 'question', 'comment', 'http', 'github', 'com', 'hristo', 'vrigazov', 'mmap', 'ninja', 'http', 'github', 'com', 'hristo', 'vrigazov', 'mmap', 'ninja']"
