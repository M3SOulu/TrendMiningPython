,Unnamed: 0,Unnamed: 0.1,AuthorId,Q_id,Title,Abstract,Answers,Cites,Date,Title_clean,Abstract_clean,Abstrat_without_stopwords,Title_without_stopwords,Merged_title_and_abs,Tokenized_data,Stem_data
0,0,0,AutoModerator,w19bf5,[D] Simple Questions Thread,"Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!

Thread will stay alive until next one so keep posting after the date in the title.

Thanks to everyone for answering questions in the previous thread!",149,16,2022-07-17 18:00:10, d  simple questions thread,please post your questions here instead of creating a new thread  encourage others who create new posts for questions to post here instead thread will stay alive until next one so keep posting after the date in the title thanks to everyone for answering questions in the previous thread ,please post questions instead creating thread encourage others create posts questions post instead thread stay alive next one keep posting date title thanks everyone answering questions previous thread,simple questions thread,simple questions threadplease post questions instead creating thread encourage others create posts questions post instead thread stay alive next one keep posting date title thanks everyone answering questions previous thread,"['simple', 'questions', 'threadplease', 'post', 'questions', 'instead', 'creating', 'thread', 'encourage', 'others', 'create', 'posts', 'questions', 'post', 'instead', 'thread', 'stay', 'alive', 'next', 'one', 'keep', 'posting', 'date', 'title', 'thanks', 'everyone', 'answering', 'questions', 'previous', 'thread']","['simpl', 'question', 'threadpleas', 'post', 'question', 'instead', 'creat', 'thread', 'encourag', 'other', 'creat', 'post', 'question', 'post', 'instead', 'thread', 'stay', 'aliv', 'next', 'one', 'keep', 'post', 'date', 'titl', 'thank', 'everyon', 'answer', 'question', 'previou', 'thread']"
1,1,1,ML_WAYR_bot,vg5kjd,[D] Machine Learning - WAYR (What Are You Reading) - Week 140,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|41-50|51-60|61-70|71-80|81-90|91-100|101-110|111-120|121-130|131-140|
|----|-----|-----|-----|-----|-----|-----|-----|-----|------|-------|-------|-------|-------|
|[Week 1](https://www.reddit.com/4qyjiq)|[Week 11](https://www.reddit.com/57xw56)|[Week 21](https://www.reddit.com/60ildf)|[Week 31](https://www.reddit.com/6s0k1u)|[Week 41](https://www.reddit.com/7tn2ax)|[Week 51](https://reddit.com/9s9el5)|[Week 61](https://reddit.com/bfsx4z)|[Week 71](https://reddit.com/d7vno3)|[Week 81](https://reddit.com/f1f0iq)|[Week 91](https://reddit.com/hlt38o)|[Week 101](https://reddit.com/k81ywb)|[Week 111](https://reddit.com/myg8sm)|[Week 121](https://reddit.com/pmzx3g)|[Week 131](https://reddit.com/srsu2n)||||||||||||
|[Week 2](https://www.reddit.com/4s2xqm)|[Week 12](https://www.reddit.com/5acb1t)|[Week 22](https://www.reddit.com/64jwde)|[Week 32](https://www.reddit.com/72ab5y)|[Week 42](https://www.reddit.com/7wvjfk)|[Week 52](https://reddit.com/a4opot)|[Week 62](https://reddit.com/bl29ov)|[Week 72](https://reddit.com/de8h48)|[Week 82](https://reddit.com/f8fs6z)|[Week 92](https://reddit.com/hu6zq9)|[Week 102](https://reddit.com/kh27nx)|[Week 112](https://reddit.com/n8m6ds)|[Week 122](https://reddit.com/pw14z5)|[Week 132](https://reddit.com/t2xpfe)||
|[Week 3](https://www.reddit.com/4t7mqm)|[Week 13](https://www.reddit.com/5cwfb6)|[Week 23](https://www.reddit.com/674331)|[Week 33](https://www.reddit.com/75405d)|[Week 43](https://www.reddit.com/807ex4)|[Week 53](https://reddit.com/a8yaro)|[Week 63](https://reddit.com/bqlb3v)|[Week 73](https://reddit.com/dkox1s)|[Week 83](https://reddit.com/ffi41b)|[Week 93](https://reddit.com/iaz892)|[Week 103](https://reddit.com/kpsxtc)|[Week 113](https://reddit.com/njfsc6)|[Week 123](https://reddit.com/q5fi12)|[Week 133](https://reddit.com/tdf2gt)||
|[Week 4](https://www.reddit.com/4ub2kw)|[Week 14](https://www.reddit.com/5fc5mh)|[Week 24](https://www.reddit.com/68hhhb)|[Week 34](https://www.reddit.com/782js9)|[Week 44](https://reddit.com/8aluhs)|[Week 54](https://reddit.com/ad9ssz)|[Week 64](https://reddit.com/bw1jm7)|[Week 74](https://reddit.com/dr6nca)|[Week 84](https://reddit.com/fn62r1)|[Week 94](https://reddit.com/ijjcep)|[Week 104](https://reddit.com/kzevku)|[Week 114](https://reddit.com/ntu6lq)|[Week 124](https://reddit.com/qjxfu9)|[Week 134](https://reddit.com/tpruqj)||
|[Week 5](https://www.reddit.com/4xomf7)|[Week 15](https://www.reddit.com/5hy4ur)|[Week 25](https://www.reddit.com/69teiz)|[Week 35](https://www.reddit.com/7b0av0)|[Week 45](https://reddit.com/8tnnez)|[Week 55](https://reddit.com/ai29gi)|[Week 65](https://reddit.com/c7itkk)|[Week 75](https://reddit.com/dxshkg)|[Week 85](https://reddit.com/fvk7j6)|[Week 95](https://reddit.com/is5hj9)|[Week 105](https://reddit.com/l9lvgs)|[Week 115](https://reddit.com/o4dph1)|[Week 125](https://reddit.com/qtzbu1)|[Week 135](https://reddit.com/u0pnhf)||
|[Week 6](https://www.reddit.com/4zcyvk)|[Week 16](https://www.reddit.com/5kd6vd)|[Week 26](https://www.reddit.com/6d7nb1)|[Week 36](https://www.reddit.com/7e3fx6)|[Week 46](https://reddit.com/8x48oj)|[Week 56](https://reddit.com/ap8ctk)|[Week 66](https://reddit.com/cd7gko)|[Week 76](https://reddit.com/e4nmyk)|[Week 86](https://reddit.com/g4eavg)|[Week 96](https://reddit.com/j0xr24)|[Week 106](https://reddit.com/ljx92n)|[Week 116](https://reddit.com/odrudt)|[Week 126](https://reddit.com/r4e8he)|[Week 136](https://reddit.com/ub2xlz)||
|[Week 7](https://www.reddit.com/52t6mo)|[Week 17](https://www.reddit.com/5ob7dx)|[Week 27](https://www.reddit.com/6gngwc)|[Week 37](https://www.reddit.com/7hcc2c)|[Week 47](https://reddit.com/910jmh)|[Week 57](https://reddit.com/auci7c)|[Week 67](https://reddit.com/cj0kyc)|[Week 77](https://reddit.com/eb4lxk)|[Week 87](https://reddit.com/gcx3uf)|[Week 97](https://reddit.com/j9cbfs)|[Week 107](https://reddit.com/luqbxl)|[Week 117](https://reddit.com/omy345)|[Week 127](https://reddit.com/rez90o)|[Week 137](https://reddit.com/ul9toj)||
|[Week 8](https://www.reddit.com/53heol)|[Week 18](https://www.reddit.com/5r14yd)|[Week 28](https://www.reddit.com/6jgdva)|[Week 38](https://www.reddit.com/7kgcqr)|[Week 48](https://reddit.com/94up0g)|[Week 58](https://reddit.com/azjoht)|[Week 68](https://reddit.com/cp1jex)|[Week 78](https://reddit.com/ehbfst)|[Week 88](https://reddit.com/glm6sv)|[Week 98](https://reddit.com/jhzz9v)|[Week 108](https://reddit.com/m52u5z)|[Week 118](https://reddit.com/ovz52j)|[Week 128](https://reddit.com/ruja9s)|[Week 138](https://reddit.com/uvl3xc)||
|[Week 9](https://www.reddit.com/54kvsu)|[Week 19](https://www.reddit.com/5tt9cz)|[Week 29](https://www.reddit.com/6m9l1v)|[Week 39](https://www.reddit.com/7nayri)|[Week 49](https://reddit.com/98n2rt)|[Week 59](https://reddit.com/b50r5y)|[Week 69](https://reddit.com/cvde5a)|[Week 79](https://reddit.com/entcxy)|[Week 89](https://reddit.com/gu5t0d)|[Week 99](https://reddit.com/jqjgo2)|[Week 109](https://reddit.com/mf8m6u)|[Week 119](https://reddit.com/p50knh)|[Week 129](https://reddit.com/s5lg69)|[Week 139](https://reddit.com/v5nggu)||
|[Week 10](https://www.reddit.com/56s2oa)|[Week 20](https://www.reddit.com/5wh2wb)|[Week 30](https://www.reddit.com/6p3ha7)|[Week 40](https://www.reddit.com/7qel9p)|[Week 50](https://reddit.com/9cf158)|[Week 60](https://reddit.com/bakew0)|[Week 70](https://reddit.com/d1g1k9)|[Week 80](https://reddit.com/euctyw)|[Week 90](https://reddit.com/hddf7j)|[Week 100](https://reddit.com/jz3evt)|[Week 110](https://reddit.com/moy40m)|[Week 120](https://reddit.com/pe2idh)|[Week 130](https://reddit.com/sgisxq)||

Most upvoted papers two weeks ago:

/u/tetatetata: [Why Philosophers Should Care About Computational Complexity](https://arxiv.org/abs/1108.1791)

Besides that, there are no rules, have fun.",14,93,2022-06-20 00:49:00, d  machine learning   wayr  what are you reading    week ,this is a place to share machine learning research papers  journals  and articles that you re reading this week  if it relates to what you re researching  by all means elaborate and give us your insight  otherwise it could just be an interesting paper you ve read please try to provide some insight from your understanding and please don t post things which are present in wiki preferably you should link the arxiv page  not the pdf  you can easily access the pdf from the summary page but not the other way around  or any other pertinent links previous weeks                                                                                                                              week   https   week   https   week   https   week   https   week   https   week   https   week   https   week   https   week   https   week   https most upvoted papers two weeks ago  u tetatetata   why philosophers should care about computational complexity  https besides that  there are no rules  have fun ,place share machine learning research papers journals articles reading week relates researching means elaborate give us insight otherwise could interesting paper read please try provide insight understanding please post things present wiki preferably link arxiv page pdf easily access pdf summary page way around pertinent links previous weeks week https week https week https week https week https week https week https week https week https week https upvoted papers two weeks ago u tetatetata philosophers care computational complexity https besides rules fun,machine learning wayr reading week,machine learning wayr reading weekplace share machine learning research papers journals articles reading week relates researching means elaborate give us insight otherwise could interesting paper read please try provide insight understanding please post things present wiki preferably link arxiv page pdf easily access pdf summary page way around pertinent links previous weeks week https week https week https week https week https week https week https week https week https week https upvoted papers two weeks ago u tetatetata philosophers care computational complexity https besides rules fun,"['machine', 'learning', 'wayr', 'reading', 'weekplace', 'share', 'machine', 'learning', 'research', 'papers', 'journals', 'articles', 'reading', 'week', 'relates', 'researching', 'means', 'elaborate', 'give', 'us', 'insight', 'otherwise', 'could', 'interesting', 'paper', 'read', 'please', 'try', 'provide', 'insight', 'understanding', 'please', 'post', 'things', 'present', 'wiki', 'preferably', 'link', 'arxiv', 'page', 'pdf', 'easily', 'access', 'pdf', 'summary', 'page', 'way', 'around', 'pertinent', 'links', 'previous', 'weeks', 'week', 'https', 'week', 'https', 'week', 'https', 'week', 'https', 'week', 'https', 'week', 'https', 'week', 'https', 'week', 'https', 'week', 'https', 'week', 'https', 'upvoted', 'papers', 'two', 'weeks', 'ago', 'u', 'tetatetata', 'philosophers', 'care', 'computational', 'complexity', 'https', 'besides', 'rules', 'fun']","['machin', 'learn', 'wayr', 'read', 'weekplac', 'share', 'machin', 'learn', 'research', 'paper', 'journal', 'articl', 'read', 'week', 'relat', 'research', 'mean', 'elabor', 'give', 'us', 'insight', 'otherwis', 'could', 'interest', 'paper', 'read', 'pleas', 'tri', 'provid', 'insight', 'understand', 'pleas', 'post', 'thing', 'present', 'wiki', 'prefer', 'link', 'arxiv', 'page', 'pdf', 'easili', 'access', 'pdf', 'summari', 'page', 'way', 'around', 'pertin', 'link', 'previou', 'week', 'week', 'http', 'week', 'http', 'week', 'http', 'week', 'http', 'week', 'http', 'week', 'http', 'week', 'http', 'week', 'http', 'week', 'http', 'week', 'http', 'upvot', 'paper', 'two', 'week', 'ago', 'u', 'tetatetata', 'philosoph', 'care', 'comput', 'complex', 'http', 'besid', 'rule', 'fun']"
2,4,4,Megixist,wcfj69,[D] Is there an alternative to sinusoidal encoding for temporal embeddings?,"As per the transformer paper, sinusoidal embeddings help inference on longer sequences than the ones it was trained on. This isn't specific to transformers and this property has been extensively used for time series modeling in the past. From what I can see, this is due to the oscillatory property of sinusoidal waves which can be combined in specific manners to embed temporal information. This makes a lot of sense but has there been any method to embed temporal information without sinusoidal encoding?

P.S.: I have done my research but I couldn't find anything significant. If anyone has had any personal experiences with any embedding technique that has worked better or equally well then please let me know.",4,3,2022-07-31 06:55:38, d  is there an alternative to sinusoidal encoding for temporal embeddings ,as per the transformer paper  sinusoidal embeddings help inference on longer sequences than the ones it was trained on  this isn t specific to transformers and this property has been extensively used for time series modeling in the past  from what i can see  this is due to the oscillatory property of sinusoidal waves which can be combined in specific manners to embed temporal information  this makes a lot of sense but has there been any method to embed temporal information without sinusoidal encoding p s   i have done my research but i couldn t find anything significant  if anyone has had any personal experiences with any embedding technique that has worked better or equally well then please let me know ,per transformer paper sinusoidal embeddings help inference longer sequences ones trained specific transformers property extensively used time series modeling past see due oscillatory property sinusoidal waves combined specific manners embed temporal information makes lot sense method embed temporal information without sinusoidal encoding p done research find anything significant anyone personal experiences embedding technique worked better equally well please let know,alternative sinusoidal encoding temporal embeddings,alternative sinusoidal encoding temporal embeddingsper transformer paper sinusoidal embeddings help inference longer sequences ones trained specific transformers property extensively used time series modeling past see due oscillatory property sinusoidal waves combined specific manners embed temporal information makes lot sense method embed temporal information without sinusoidal encoding p done research find anything significant anyone personal experiences embedding technique worked better equally well please let know,"['alternative', 'sinusoidal', 'encoding', 'temporal', 'embeddingsper', 'transformer', 'paper', 'sinusoidal', 'embeddings', 'help', 'inference', 'longer', 'sequences', 'ones', 'trained', 'specific', 'transformers', 'property', 'extensively', 'used', 'time', 'series', 'modeling', 'past', 'see', 'due', 'oscillatory', 'property', 'sinusoidal', 'waves', 'combined', 'specific', 'manners', 'embed', 'temporal', 'information', 'makes', 'lot', 'sense', 'method', 'embed', 'temporal', 'information', 'without', 'sinusoidal', 'encoding', 'p', 'done', 'research', 'find', 'anything', 'significant', 'anyone', 'personal', 'experiences', 'embedding', 'technique', 'worked', 'better', 'equally', 'well', 'please', 'let', 'know']","['altern', 'sinusoid', 'encod', 'tempor', 'embeddingsp', 'transform', 'paper', 'sinusoid', 'embed', 'help', 'infer', 'longer', 'sequenc', 'one', 'train', 'specif', 'transform', 'properti', 'extens', 'use', 'time', 'seri', 'model', 'past', 'see', 'due', 'oscillatori', 'properti', 'sinusoid', 'wave', 'combin', 'specif', 'manner', 'emb', 'tempor', 'inform', 'make', 'lot', 'sens', 'method', 'emb', 'tempor', 'inform', 'without', 'sinusoid', 'encod', 'p', 'done', 'research', 'find', 'anyth', 'signific', 'anyon', 'person', 'experi', 'embed', 'techniqu', 'work', 'better', 'equal', 'well', 'pleas', 'let', 'know']"
3,6,6,ZENDRO_hex,wcgzp5,What shall I do now? [Discussion],"I graduated this year and somehow I've managed to get an MLE role at a (<50 people) startup. I do not have a CS degree. I've learned everything from the internet.  So, I am now confused about what to do next.

What side activity should I do to make myself a valuable asset, both for the current company as well as for other future opportunities?

Shall I focus more on problem-solving (leetcode)? Shall I  start with system design? Should I work on my personal side projects? **What do I do?**",2,1,2022-07-31 08:18:10,what shall i do now   discussion ,i graduated this year and somehow i ve managed to get an mle role at a    people  startup  i do not have a cs degree  i ve learned everything from the internet   so  i am now confused about what to do next what side activity should i do to make myself a valuable asset  both for the current company as well as for other future opportunities shall i focus more on problem solving  leetcode   shall i  start with system design  should i work on my personal side projects    what do i do   ,graduated year somehow managed get mle role people startup cs degree learned everything internet confused next side activity make valuable asset current company well future opportunities shall focus problem solving leetcode shall start system design work personal side projects,shall discussion,shall discussiongraduated year somehow managed get mle role people startup cs degree learned everything internet confused next side activity make valuable asset current company well future opportunities shall focus problem solving leetcode shall start system design work personal side projects,"['shall', 'discussiongraduated', 'year', 'somehow', 'managed', 'get', 'mle', 'role', 'people', 'startup', 'cs', 'degree', 'learned', 'everything', 'internet', 'confused', 'next', 'side', 'activity', 'make', 'valuable', 'asset', 'current', 'company', 'well', 'future', 'opportunities', 'shall', 'focus', 'problem', 'solving', 'leetcode', 'shall', 'start', 'system', 'design', 'work', 'personal', 'side', 'projects']","['shall', 'discussiongradu', 'year', 'somehow', 'manag', 'get', 'mle', 'role', 'peopl', 'startup', 'cs', 'degre', 'learn', 'everyth', 'internet', 'confus', 'next', 'side', 'activ', 'make', 'valuabl', 'asset', 'current', 'compani', 'well', 'futur', 'opportun', 'shall', 'focu', 'problem', 'solv', 'leetcod', 'shall', 'start', 'system', 'design', 'work', 'person', 'side', 'project']"
4,8,8,centipedeshoesale,wcf5yq,[D] Upcoming interview with Amazon. Looking for tips on how to prepare for it.,"\[Mods, please remove. I'm not on the right forum. (also, I can't edit the title...?) Thanks!\]

I was invited for a 60 minute video interview and I'm nervous about this. If anyone has experience with an interview at Amazon, do you mind sharing how it went for you? Thank you!",3,1,2022-07-31 06:35:08, d  upcoming interview with amazon  looking for tips on how to prepare for it ,  mods  please remove  i m not on the right forum   also  i can t edit the title      thanks   i was invited for a  minute video interview and i m nervous about this  if anyone has experience with an interview at amazon  do you mind sharing how it went for you  thank you ,mods please remove right forum also edit title thanks invited minute video interview nervous anyone experience interview amazon mind sharing went thank,upcoming interview amazon looking tips prepare,upcoming interview amazon looking tips preparemods please remove right forum also edit title thanks invited minute video interview nervous anyone experience interview amazon mind sharing went thank,"['upcoming', 'interview', 'amazon', 'looking', 'tips', 'preparemods', 'please', 'remove', 'right', 'forum', 'also', 'edit', 'title', 'thanks', 'invited', 'minute', 'video', 'interview', 'nervous', 'anyone', 'experience', 'interview', 'amazon', 'mind', 'sharing', 'went', 'thank']","['upcom', 'interview', 'amazon', 'look', 'tip', 'preparemod', 'pleas', 'remov', 'right', 'forum', 'also', 'edit', 'titl', 'thank', 'invit', 'minut', 'video', 'interview', 'nervou', 'anyon', 'experi', 'interview', 'amazon', 'mind', 'share', 'went', 'thank']"
5,9,9,Blackforestcheesecak,wbxl0c,[D] Quantum Machine Learning,"What's the goal of quantum ML? It seems to me that current ways of applying QML is to shoehorn quantum systems into well-known classical ML approaches, without any form of benefit.

I recently discovered too that there is a whole subfield dedicated to QNLP, which is quite surprising since NLP requires drawing correlations between continuous sequences, and current quantum systems are currently limited by their lifetimes. How can they retain long-term memory? 

Those familiar with the field, can y'all explain why?",10,11,2022-07-30 16:29:33, d  quantum machine learning,what s the goal of quantum ml  it seems to me that current ways of applying qml is to shoehorn quantum systems into well known classical ml approaches  without any form of benefit i recently discovered too that there is a whole subfield dedicated to qnlp  which is quite surprising since nlp requires drawing correlations between continuous sequences  and current quantum systems are currently limited by their lifetimes  how can they retain long term memory  those familiar with the field  can y all explain why ,goal quantum ml seems current ways applying qml shoehorn quantum systems well known classical ml approaches without form benefit recently discovered whole subfield dedicated qnlp quite surprising since nlp requires drawing correlations continuous sequences current quantum systems currently limited lifetimes retain long term memory familiar field explain,quantum machine learning,quantum machine learninggoal quantum ml seems current ways applying qml shoehorn quantum systems well known classical ml approaches without form benefit recently discovered whole subfield dedicated qnlp quite surprising since nlp requires drawing correlations continuous sequences current quantum systems currently limited lifetimes retain long term memory familiar field explain,"['quantum', 'machine', 'learninggoal', 'quantum', 'ml', 'seems', 'current', 'ways', 'applying', 'qml', 'shoehorn', 'quantum', 'systems', 'well', 'known', 'classical', 'ml', 'approaches', 'without', 'form', 'benefit', 'recently', 'discovered', 'whole', 'subfield', 'dedicated', 'qnlp', 'quite', 'surprising', 'since', 'nlp', 'requires', 'drawing', 'correlations', 'continuous', 'sequences', 'current', 'quantum', 'systems', 'currently', 'limited', 'lifetimes', 'retain', 'long', 'term', 'memory', 'familiar', 'field', 'explain']","['quantum', 'machin', 'learninggo', 'quantum', 'ml', 'seem', 'current', 'way', 'appli', 'qml', 'shoehorn', 'quantum', 'system', 'well', 'known', 'classic', 'ml', 'approach', 'without', 'form', 'benefit', 'recent', 'discov', 'whole', 'subfield', 'dedic', 'qnlp', 'quit', 'surpris', 'sinc', 'nlp', 'requir', 'draw', 'correl', 'continu', 'sequenc', 'current', 'quantum', 'system', 'current', 'limit', 'lifetim', 'retain', 'long', 'term', 'memori', 'familiar', 'field', 'explain']"
6,10,10,Boring-Violinist8291,wcd2pm,[D] Geospatial relationships,"Let’s say I have a set of points on a plane. We know the values of the predictor variables of all points, but we only know the values of the two target variables for some points. 

Is there an existing model that would allow me to incorporate the geospatial relationships between points in predicting target variables for the rest of the points on the plane?",1,1,2022-07-31 04:43:08, d  geospatial relationships,let s say i have a set of points on a plane  we know the values of the predictor variables of all points  but we only know the values of the two target variables for some points  is there an existing model that would allow me to incorporate the geospatial relationships between points in predicting target variables for the rest of the points on the plane ,let say set points plane know values predictor variables points know values two target variables points existing model would allow incorporate geospatial relationships points predicting target variables rest points plane,geospatial relationships,geospatial relationshipslet say set points plane know values predictor variables points know values two target variables points existing model would allow incorporate geospatial relationships points predicting target variables rest points plane,"['geospatial', 'relationshipslet', 'say', 'set', 'points', 'plane', 'know', 'values', 'predictor', 'variables', 'points', 'know', 'values', 'two', 'target', 'variables', 'points', 'existing', 'model', 'would', 'allow', 'incorporate', 'geospatial', 'relationships', 'points', 'predicting', 'target', 'variables', 'rest', 'points', 'plane']","['geospati', 'relationshipslet', 'say', 'set', 'point', 'plane', 'know', 'valu', 'predictor', 'variabl', 'point', 'know', 'valu', 'two', 'target', 'variabl', 'point', 'exist', 'model', 'would', 'allow', 'incorpor', 'geospati', 'relationship', 'point', 'predict', 'target', 'variabl', 'rest', 'point', 'plane']"
7,11,11,edenmannh,wcchyq,Classifying the 'interestingness' of a word? [D],"Does anyone know of any models/software that can classify the interestingness of a word? I'm trying to extract the most frequently spoken interesting words of a transcript.

Any help would be greatly appreciated, thanks.",11,1,2022-07-31 04:12:15,classifying the  interestingness  of a word   d ,does anyone know of any models software that can classify the interestingness of a word  i m trying to extract the most frequently spoken interesting words of a transcript any help would be greatly appreciated  thanks ,anyone know models software classify interestingness word trying extract frequently spoken interesting transcript help would greatly appreciated thanks,classifying interestingness word,classifying interestingness wordanyone know models software classify interestingness word trying extract frequently spoken interesting transcript help would greatly appreciated thanks,"['classifying', 'interestingness', 'wordanyone', 'know', 'models', 'software', 'classify', 'interestingness', 'word', 'trying', 'extract', 'frequently', 'spoken', 'interesting', 'transcript', 'help', 'would', 'greatly', 'appreciated', 'thanks']","['classifi', 'interesting', 'wordanyon', 'know', 'model', 'softwar', 'classifi', 'interesting', 'word', 'tri', 'extract', 'frequent', 'spoken', 'interest', 'transcript', 'help', 'would', 'greatli', 'appreci', 'thank']"
8,12,12,nadavbrandes,wby77s,[R] Blog post series on human genetics for data scientists,"I started writing a blog post series on human genetics for data scientists, with the goal of presenting the major open problems in the field (from an analytical perspective).

I explain in the blog why, on the one hand, genetic data is really convenient for statistical and computational analysis (DNA is literally a digital code) and we can in principle do really cool stuff (like predicting who’s at risk for schizophrenia, heart disease, or any other heritable condition), but it’s somewhat tricky and there are many challenges we still need to make progress on.

It’s a fascinating research area with interesting analytical challenges and a potential to improve the lives of many people.

The first post in the series:
https://incrementally.net/2022/07/14/understanding-the-genetic-basis-of-the-human-condition-16-analytical-challenges/",3,5,2022-07-30 17:00:36, r  blog post series on human genetics for data scientists,i started writing a blog post series on human genetics for data scientists  with the goal of presenting the major open problems in the field  from an analytical perspective  i explain in the blog why  on the one hand  genetic data is really convenient for statistical and computational analysis  dna is literally a digital code  and we can in principle do really cool stuff  like predicting who s at risk for schizophrenia  heart disease  or any other heritable condition   but it s somewhat tricky and there are many challenges we still need to make progress on it s a fascinating research area with interesting analytical challenges and a potential to improve the lives of many people the first post in the series https   incrementally net    understanding the genetic basis of the human condition  analytical challenges ,started writing blog post series human genetics data scientists goal presenting major open problems field analytical perspective explain blog one hand genetic data really convenient statistical computational analysis dna literally digital code principle really cool stuff like predicting risk schizophrenia heart disease heritable condition somewhat tricky many challenges still need make progress fascinating research area interesting analytical challenges potential improve lives many people first post series https incrementally net understanding genetic basis human condition analytical challenges,r blog post series human genetics data scientists,r blog post series human genetics data scientistsstarted writing blog post series human genetics data scientists goal presenting major open problems field analytical perspective explain blog one hand genetic data really convenient statistical computational analysis dna literally digital code principle really cool stuff like predicting risk schizophrenia heart disease heritable condition somewhat tricky many challenges still need make progress fascinating research area interesting analytical challenges potential improve lives many people first post series https incrementally net understanding genetic basis human condition analytical challenges,"['r', 'blog', 'post', 'series', 'human', 'genetics', 'data', 'scientistsstarted', 'writing', 'blog', 'post', 'series', 'human', 'genetics', 'data', 'scientists', 'goal', 'presenting', 'major', 'open', 'problems', 'field', 'analytical', 'perspective', 'explain', 'blog', 'one', 'hand', 'genetic', 'data', 'really', 'convenient', 'statistical', 'computational', 'analysis', 'dna', 'literally', 'digital', 'code', 'principle', 'really', 'cool', 'stuff', 'like', 'predicting', 'risk', 'schizophrenia', 'heart', 'disease', 'heritable', 'condition', 'somewhat', 'tricky', 'many', 'challenges', 'still', 'need', 'make', 'progress', 'fascinating', 'research', 'area', 'interesting', 'analytical', 'challenges', 'potential', 'improve', 'lives', 'many', 'people', 'first', 'post', 'series', 'https', 'incrementally', 'net', 'understanding', 'genetic', 'basis', 'human', 'condition', 'analytical', 'challenges']","['r', 'blog', 'post', 'seri', 'human', 'genet', 'data', 'scientistsstart', 'write', 'blog', 'post', 'seri', 'human', 'genet', 'data', 'scientist', 'goal', 'present', 'major', 'open', 'problem', 'field', 'analyt', 'perspect', 'explain', 'blog', 'one', 'hand', 'genet', 'data', 'realli', 'conveni', 'statist', 'comput', 'analysi', 'dna', 'liter', 'digit', 'code', 'principl', 'realli', 'cool', 'stuff', 'like', 'predict', 'risk', 'schizophrenia', 'heart', 'diseas', 'herit', 'condit', 'somewhat', 'tricki', 'mani', 'challeng', 'still', 'need', 'make', 'progress', 'fascin', 'research', 'area', 'interest', 'analyt', 'challeng', 'potenti', 'improv', 'live', 'mani', 'peopl', 'first', 'post', 'seri', 'http', 'increment', 'net', 'understand', 'genet', 'basi', 'human', 'condit', 'analyt', 'challeng']"
9,13,13,BeautifulVegetable10,wb7daf,[D] AlphaFold just released a database of 200 million protein structures. How would you use this data as an ML engineer?,"The structure of a protein determines its functionality. Researchers have used this data in the past to design new drugs, vaccines, and enzymes. You can access the database for free here - [https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe](https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe)

This new database will allow researchers to gain a deeper understanding of protein families, how they interact and evolve, etc. Deepmind has written some use cases here - [https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe](https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe)

How would you use it? What would you like to explore or predict with it?",88,224,2022-07-29 18:14:13, d  alphafold just released a database of  million protein structures  how would you use this data as an ml engineer ,the structure of a protein determines its functionality  researchers have used this data in the past to design new drugs  vaccines  and enzymes  you can access the database for free here    https this new database will allow researchers to gain a deeper understanding of protein families  how they interact and evolve  etc  deepmind has written some use cases here    https how would you use it  what would you like to explore or predict with it ,structure protein determines functionality researchers used data past design drugs vaccines enzymes access database free https database allow researchers gain deeper understanding protein families interact evolve etc deepmind written use cases https would use would like explore predict,alphafold released database million protein structures would use data ml engineer,alphafold released database million protein structures would use data ml engineerstructure protein determines functionality researchers used data past design drugs vaccines enzymes access database free https database allow researchers gain deeper understanding protein families interact evolve etc deepmind written use cases https would use would like explore predict,"['alphafold', 'released', 'database', 'million', 'protein', 'structures', 'would', 'use', 'data', 'ml', 'engineerstructure', 'protein', 'determines', 'functionality', 'researchers', 'used', 'data', 'past', 'design', 'drugs', 'vaccines', 'enzymes', 'access', 'database', 'free', 'https', 'database', 'allow', 'researchers', 'gain', 'deeper', 'understanding', 'protein', 'families', 'interact', 'evolve', 'etc', 'deepmind', 'written', 'use', 'cases', 'https', 'would', 'use', 'would', 'like', 'explore', 'predict']","['alphafold', 'releas', 'databas', 'million', 'protein', 'structur', 'would', 'use', 'data', 'ml', 'engineerstructur', 'protein', 'determin', 'function', 'research', 'use', 'data', 'past', 'design', 'drug', 'vaccin', 'enzym', 'access', 'databas', 'free', 'http', 'databas', 'allow', 'research', 'gain', 'deeper', 'understand', 'protein', 'famili', 'interact', 'evolv', 'etc', 'deepmind', 'written', 'use', 'case', 'http', 'would', 'use', 'would', 'like', 'explor', 'predict']"
10,14,14,zitrone_dealer,wc2bda,[P] Using time series models to predict product demand,"

Scenario: Suppose a small city has 2000 supermarkets and you have data in real time that shows how much they order certain products from wholesalers and when. 


Task: Reach a level where given a year's worth of the data above where you can get meaningful insights to somewhat predict shortages and plan accordingly.


I would love if you could direct me at any books, articles or videos that go over a similar thing. Also, I wish to know if this has been done before and therefore is somewhat realistic.",8,0,2022-07-30 20:09:58, p  using time series models to predict product demand,scenario  suppose a small city has  supermarkets and you have data in real time that shows how much they order certain products from wholesalers and when  task  reach a level where given a year s worth of the data above where you can get meaningful insights to somewhat predict shortages and plan accordingly i would love if you could direct me at any books  articles or videos that go over a similar thing  also  i wish to know if this has been done before and therefore is somewhat realistic ,scenario suppose small city supermarkets data real time shows much order certain products wholesalers task reach level given year worth data get meaningful insights somewhat predict shortages plan accordingly would love could direct books articles videos go similar thing also wish know done therefore somewhat realistic,p using time series models predict product demand,p using time series models predict product demandscenario suppose small city supermarkets data real time shows much order certain products wholesalers task reach level given year worth data get meaningful insights somewhat predict shortages plan accordingly would love could direct books articles videos go similar thing also wish know done therefore somewhat realistic,"['p', 'using', 'time', 'series', 'models', 'predict', 'product', 'demandscenario', 'suppose', 'small', 'city', 'supermarkets', 'data', 'real', 'time', 'shows', 'much', 'order', 'certain', 'products', 'wholesalers', 'task', 'reach', 'level', 'given', 'year', 'worth', 'data', 'get', 'meaningful', 'insights', 'somewhat', 'predict', 'shortages', 'plan', 'accordingly', 'would', 'love', 'could', 'direct', 'books', 'articles', 'videos', 'go', 'similar', 'thing', 'also', 'wish', 'know', 'done', 'therefore', 'somewhat', 'realistic']","['p', 'use', 'time', 'seri', 'model', 'predict', 'product', 'demandscenario', 'suppos', 'small', 'citi', 'supermarket', 'data', 'real', 'time', 'show', 'much', 'order', 'certain', 'product', 'wholesal', 'task', 'reach', 'level', 'given', 'year', 'worth', 'data', 'get', 'meaning', 'insight', 'somewhat', 'predict', 'shortag', 'plan', 'accordingli', 'would', 'love', 'could', 'direct', 'book', 'articl', 'video', 'go', 'similar', 'thing', 'also', 'wish', 'know', 'done', 'therefor', 'somewhat', 'realist']"
11,15,15,Singularian2501,wbixyj,[R] Reducing Activation Recomputation in Large Transformer Models - Nvidia May 2022,"Paper: [https://arxiv.org/abs/2205.05198#nvidia](https://arxiv.org/abs/2205.05198#nvidia)

Github: [https://github.com/NVIDIA/Megatron-LM](https://github.com/NVIDIA/Megatron-LM)

Abstract:

>Training large transformer models is one of the most important computational challenges of modern AI. In this paper, we show how to significantly accelerate training of large transformer models by reducing activation recomputation. Activation recomputation is commonly used to work around memory capacity constraints. Rather than storing activations for backpropagation, they are traditionally recomputed, which saves memory but adds redundant compute. In this work, we show most of this redundant compute is unnecessary because we can reduce memory consumption sufficiently without it. We present two novel yet very simple techniques: **sequence parallelism and selective activation recomputation**. In conjunction with tensor parallelism, these techniques almost eliminate the need to recompute activations. We evaluate our approach on language models up to one trillion parameters in scale and show that our method reduces **activation memory by 5x, while reducing execution time overhead from activation recomputation by over 90%.** For example, when training a 530B parameter GPT-3 style model on 2240 NVIDIA A100 GPUs, we achieve a **Model Flops Utilization of 54.2%, which is 29% faster than the 42.1% we achieve using recomputation**. Our implementation will be **available in both Megatron-LM and NeMo-Megatron**.       

https://preview.redd.it/fsaumv5zcle91.jpg?width=1505&format=pjpg&auto=webp&s=80f6bad3cf9fed53734c6a6cab0296082fa56d8a

https://preview.redd.it/03q2jy5zcle91.jpg?width=1512&format=pjpg&auto=webp&s=2a97c848e21054d9c3bdb686c5a6137eb1df4c0e

https://preview.redd.it/nxrz9y5zcle91.jpg?width=1312&format=pjpg&auto=webp&s=35f8de183ceee3d8198af8a6d7db5d57298a2dcd

https://preview.redd.it/wa8tfz5zcle91.jpg?width=1260&format=pjpg&auto=webp&s=93638469ad0f8fbb6a17c1a68f713aad4819b936

https://preview.redd.it/0yd0iy5zcle91.jpg?width=1214&format=pjpg&auto=webp&s=7a99326c35c312d738167c247876b8599379d9bf",6,24,2022-07-30 02:32:22, r  reducing activation recomputation in large transformer models   nvidia may ,paper   https github   https abstract  training large transformer models is one of the most important computational challenges of modern ai  in this paper  we show how to significantly accelerate training of large transformer models by reducing activation recomputation  activation recomputation is commonly used to work around memory capacity constraints  rather than storing activations for backpropagation  they are traditionally recomputed  which saves memory but adds redundant compute  in this work  we show most of this redundant compute is unnecessary because we can reduce memory consumption sufficiently without it  we present two novel yet very simple techniques    sequence parallelism and selective activation recomputation    in conjunction with tensor parallelism  these techniques almost eliminate the need to recompute activations  we evaluate our approach on language models up to one trillion parameters in scale and show that our method reduces   activation memory by x  while reducing execution time overhead from activation recomputation by over      for example  when training a b parameter gpt  style model on  nvidia a gpus  we achieve a   model flops utilization of     which is   faster than the    we achieve using recomputation    our implementation will be   available in both megatron lm and nemo megatron          https https https https https   preview redd it ydiyzcle jpg width  format pjpg auto webp s accdcbdbf,paper https github https abstract training large transformer models one important computational challenges modern ai paper show significantly accelerate training large transformer models reducing activation recomputation activation recomputation commonly used work around memory capacity constraints rather storing activations backpropagation traditionally recomputed saves memory adds redundant compute work show redundant compute unnecessary reduce memory consumption sufficiently without present two novel yet simple techniques sequence parallelism selective activation recomputation conjunction tensor parallelism techniques almost eliminate need recompute activations evaluate approach language models one trillion parameters scale show method reduces activation memory x reducing execution time overhead activation recomputation example training b parameter gpt style model nvidia gpus achieve model flops utilization faster achieve using recomputation implementation available megatron lm nemo megatron https https https https https preview redd ydiyzcle jpg width format pjpg auto webp accdcbdbf,r reducing activation recomputation large transformer models nvidia may,r reducing activation recomputation large transformer models nvidia maypaper https github https abstract training large transformer models one important computational challenges modern ai paper show significantly accelerate training large transformer models reducing activation recomputation activation recomputation commonly used work around memory capacity constraints rather storing activations backpropagation traditionally recomputed saves memory adds redundant compute work show redundant compute unnecessary reduce memory consumption sufficiently without present two novel yet simple techniques sequence parallelism selective activation recomputation conjunction tensor parallelism techniques almost eliminate need recompute activations evaluate approach language models one trillion parameters scale show method reduces activation memory x reducing execution time overhead activation recomputation example training b parameter gpt style model nvidia gpus achieve model flops utilization faster achieve using recomputation implementation available megatron lm nemo megatron https https https https https preview redd ydiyzcle jpg width format pjpg auto webp accdcbdbf,"['r', 'reducing', 'activation', 'recomputation', 'large', 'transformer', 'models', 'nvidia', 'maypaper', 'https', 'github', 'https', 'abstract', 'training', 'large', 'transformer', 'models', 'one', 'important', 'computational', 'challenges', 'modern', 'ai', 'paper', 'show', 'significantly', 'accelerate', 'training', 'large', 'transformer', 'models', 'reducing', 'activation', 'recomputation', 'activation', 'recomputation', 'commonly', 'used', 'work', 'around', 'memory', 'capacity', 'constraints', 'rather', 'storing', 'activations', 'backpropagation', 'traditionally', 'recomputed', 'saves', 'memory', 'adds', 'redundant', 'compute', 'work', 'show', 'redundant', 'compute', 'unnecessary', 'reduce', 'memory', 'consumption', 'sufficiently', 'without', 'present', 'two', 'novel', 'yet', 'simple', 'techniques', 'sequence', 'parallelism', 'selective', 'activation', 'recomputation', 'conjunction', 'tensor', 'parallelism', 'techniques', 'almost', 'eliminate', 'need', 'recompute', 'activations', 'evaluate', 'approach', 'language', 'models', 'one', 'trillion', 'parameters', 'scale', 'show', 'method', 'reduces', 'activation', 'memory', 'x', 'reducing', 'execution', 'time', 'overhead', 'activation', 'recomputation', 'example', 'training', 'b', 'parameter', 'gpt', 'style', 'model', 'nvidia', 'gpus', 'achieve', 'model', 'flops', 'utilization', 'faster', 'achieve', 'using', 'recomputation', 'implementation', 'available', 'megatron', 'lm', 'nemo', 'megatron', 'https', 'https', 'https', 'https', 'https', 'preview', 'redd', 'ydiyzcle', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'accdcbdbf']","['r', 'reduc', 'activ', 'recomput', 'larg', 'transform', 'model', 'nvidia', 'maypap', 'http', 'github', 'http', 'abstract', 'train', 'larg', 'transform', 'model', 'one', 'import', 'comput', 'challeng', 'modern', 'ai', 'paper', 'show', 'significantli', 'acceler', 'train', 'larg', 'transform', 'model', 'reduc', 'activ', 'recomput', 'activ', 'recomput', 'commonli', 'use', 'work', 'around', 'memori', 'capac', 'constraint', 'rather', 'store', 'activ', 'backpropag', 'tradit', 'recomput', 'save', 'memori', 'add', 'redund', 'comput', 'work', 'show', 'redund', 'comput', 'unnecessari', 'reduc', 'memori', 'consumpt', 'suffici', 'without', 'present', 'two', 'novel', 'yet', 'simpl', 'techniqu', 'sequenc', 'parallel', 'select', 'activ', 'recomput', 'conjunct', 'tensor', 'parallel', 'techniqu', 'almost', 'elimin', 'need', 'recomput', 'activ', 'evalu', 'approach', 'languag', 'model', 'one', 'trillion', 'paramet', 'scale', 'show', 'method', 'reduc', 'activ', 'memori', 'x', 'reduc', 'execut', 'time', 'overhead', 'activ', 'recomput', 'exampl', 'train', 'b', 'paramet', 'gpt', 'style', 'model', 'nvidia', 'gpu', 'achiev', 'model', 'flop', 'util', 'faster', 'achiev', 'use', 'recomput', 'implement', 'avail', 'megatron', 'lm', 'nemo', 'megatron', 'http', 'http', 'http', 'http', 'http', 'preview', 'redd', 'ydiyzcl', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'accdcbdbf']"
12,16,16,whattoshow,wbt7by,[Discussion]Is there inductive bias in ViT?,"Recently, I've read some paper about CNNs and Transformers, as is well known, there is a natural inductive bias in CNNs, I really wonder if ViT has the inductive bias?",6,3,2022-07-30 12:06:35, discussion is there inductive bias in vit ,recently  i ve read some paper about cnns and transformers  as is well known  there is a natural inductive bias in cnns  i really wonder if vit has the inductive bias ,recently read paper cnns transformers well known natural inductive bias cnns really wonder vit inductive bias,discussion inductive bias vit,discussion inductive bias vitrecently read paper cnns transformers well known natural inductive bias cnns really wonder vit inductive bias,"['discussion', 'inductive', 'bias', 'vitrecently', 'read', 'paper', 'cnns', 'transformers', 'well', 'known', 'natural', 'inductive', 'bias', 'cnns', 'really', 'wonder', 'vit', 'inductive', 'bias']","['discuss', 'induct', 'bia', 'vitrec', 'read', 'paper', 'cnn', 'transform', 'well', 'known', 'natur', 'induct', 'bia', 'cnn', 'realli', 'wonder', 'vit', 'induct', 'bia']"
13,17,17,davidmezzetti,wbx227,[P] Connect models together to build machine-learning workflows,"&#x200B;

https://preview.redd.it/wr8k2xa1epe91.png?width=1091&format=png&auto=webp&s=41e3e0f812067d43faff08aa327b1ea90adc0e2b

txtai executes machine-learning workflows to transform data and build AI-powered semantic search applications.

Workflows can be as simple as a single model. As the picture above illustrates, a workflow can also be a summarization and translation model. Or a model that summarizes and then builds a vector search index.

Workflows are constructed in Python or YAML. Logic is built-in for model serving and packaging workflows as Docker images. Full documentation can be found in the links below.

[GitHub](https://github.com/neuml/txtai) | [Documentation](https://neuml.github.io/txtai)  | [Packaging workflows](https://neuml.github.io/txtai/cloud/) | [Tutorials](https://neuml.hashnode.dev)",0,0,2022-07-30 16:02:27, p  connect models together to build machine learning workflows,  xb https txtai executes machine learning workflows to transform data and build ai powered semantic search applications workflows can be as simple as a single model  as the picture above illustrates  a workflow can also be a summarization and translation model  or a model that summarizes and then builds a vector search index workflows are constructed in python or yaml  logic is built in for model serving and packaging workflows as docker images  full documentation can be found in the links below  github  https   github com neuml txtai     documentation  https   neuml github io txtai      packaging workflows  https   neuml github io txtai cloud      tutorials  https   neuml hashnode dev ,xb https txtai executes machine learning workflows transform data build ai powered semantic search applications workflows simple single model picture illustrates workflow also summarization translation model model summarizes builds vector search index workflows constructed python yaml logic built model serving packaging workflows docker images full documentation found links github https github com neuml txtai documentation https neuml github io txtai packaging workflows https neuml github io txtai cloud tutorials https neuml hashnode dev,p connect models together build machine learning workflows,p connect models together build machine learning workflowsxb https txtai executes machine learning workflows transform data build ai powered semantic search applications workflows simple single model picture illustrates workflow also summarization translation model model summarizes builds vector search index workflows constructed python yaml logic built model serving packaging workflows docker images full documentation found links github https github com neuml txtai documentation https neuml github io txtai packaging workflows https neuml github io txtai cloud tutorials https neuml hashnode dev,"['p', 'connect', 'models', 'together', 'build', 'machine', 'learning', 'workflowsxb', 'https', 'txtai', 'executes', 'machine', 'learning', 'workflows', 'transform', 'data', 'build', 'ai', 'powered', 'semantic', 'search', 'applications', 'workflows', 'simple', 'single', 'model', 'picture', 'illustrates', 'workflow', 'also', 'summarization', 'translation', 'model', 'model', 'summarizes', 'builds', 'vector', 'search', 'index', 'workflows', 'constructed', 'python', 'yaml', 'logic', 'built', 'model', 'serving', 'packaging', 'workflows', 'docker', 'images', 'full', 'documentation', 'found', 'links', 'github', 'https', 'github', 'com', 'neuml', 'txtai', 'documentation', 'https', 'neuml', 'github', 'io', 'txtai', 'packaging', 'workflows', 'https', 'neuml', 'github', 'io', 'txtai', 'cloud', 'tutorials', 'https', 'neuml', 'hashnode', 'dev']","['p', 'connect', 'model', 'togeth', 'build', 'machin', 'learn', 'workflowsxb', 'http', 'txtai', 'execut', 'machin', 'learn', 'workflow', 'transform', 'data', 'build', 'ai', 'power', 'semant', 'search', 'applic', 'workflow', 'simpl', 'singl', 'model', 'pictur', 'illustr', 'workflow', 'also', 'summar', 'translat', 'model', 'model', 'summar', 'build', 'vector', 'search', 'index', 'workflow', 'construct', 'python', 'yaml', 'logic', 'built', 'model', 'serv', 'packag', 'workflow', 'docker', 'imag', 'full', 'document', 'found', 'link', 'github', 'http', 'github', 'com', 'neuml', 'txtai', 'document', 'http', 'neuml', 'github', 'io', 'txtai', 'packag', 'workflow', 'http', 'neuml', 'github', 'io', 'txtai', 'cloud', 'tutori', 'http', 'neuml', 'hashnod', 'dev']"
14,18,18,The_Big_0mg,waxe4u,[D] Professional ML engineers: How much of your day to day job involves math and proofs?,"If you are a professional ML engineer (not data engineer) how much of your day to day work involves doing math and proofs?  I can 'do' linear algebra and statistics but I am not sure if doing math and writing proofs on a daily basis would be my cup of tea.

EDIT: The reason I asked is because the MS program I am considering requires proofs to pass the ML related classes. I can do that for a couple of classes but not every day.",102,216,2022-07-29 09:32:42, d  professional ml engineers  how much of your day to day job involves math and proofs ,if you are a professional ml engineer  not data engineer  how much of your day to day work involves doing math and proofs   i can  do  linear algebra and statistics but i am not sure if doing math and writing proofs on a daily basis would be my cup of tea edit  the reason i asked is because the ms program i am considering requires proofs to pass the ml related classes  i can do that for a couple of classes but not every day ,professional ml engineer data engineer much day day work involves math proofs linear algebra statistics sure math writing proofs daily basis would cup tea edit reason asked ms program considering requires proofs pass ml related classes couple classes every day,professional ml engineers much day day job involves math proofs,professional ml engineers much day day job involves math proofsprofessional ml engineer data engineer much day day work involves math proofs linear algebra statistics sure math writing proofs daily basis would cup tea edit reason asked ms program considering requires proofs pass ml related classes couple classes every day,"['professional', 'ml', 'engineers', 'much', 'day', 'day', 'job', 'involves', 'math', 'proofsprofessional', 'ml', 'engineer', 'data', 'engineer', 'much', 'day', 'day', 'work', 'involves', 'math', 'proofs', 'linear', 'algebra', 'statistics', 'sure', 'math', 'writing', 'proofs', 'daily', 'basis', 'would', 'cup', 'tea', 'edit', 'reason', 'asked', 'ms', 'program', 'considering', 'requires', 'proofs', 'pass', 'ml', 'related', 'classes', 'couple', 'classes', 'every', 'day']","['profession', 'ml', 'engin', 'much', 'day', 'day', 'job', 'involv', 'math', 'proofsprofession', 'ml', 'engin', 'data', 'engin', 'much', 'day', 'day', 'work', 'involv', 'math', 'proof', 'linear', 'algebra', 'statist', 'sure', 'math', 'write', 'proof', 'daili', 'basi', 'would', 'cup', 'tea', 'edit', 'reason', 'ask', 'ms', 'program', 'consid', 'requir', 'proof', 'pass', 'ml', 'relat', 'class', 'coupl', 'class', 'everi', 'day']"
15,19,19,jwngx,wb6z2e,[D] How does multi-head attention actually work?,"I'm trying to understand multi-head attention but don't quite get how queries, keys, and values are projected to different subspaces. More specifically, are the same weight matrices used for each head, or is a different matrix used for each head?

The [Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) shows eight sets of weight matrices being used for eight heads. But other implementations I've seen (The [Annotated Transformer](http://nlp.seas.harvard.edu/annotated-transformer/#full-model) and Gordic Aleksa's [implementation](https://github.com/gordicaleksa/pytorch-original-transformer/blob/main/models/definitions/transformer_model.py), as well as his video on his popular channel The AI Epiphany) seem to use only one linear layer per key, query, and value. I'm confused. Can anybody explain?",16,42,2022-07-29 17:58:14, d  how does multi head attention actually work ,i m trying to understand multi head attention but don t quite get how queries  keys  and values are projected to different subspaces  more specifically  are the same weight matrices used for each head  or is a different matrix used for each head the  illustrated transformer  https   jalammar github io illustrated transformer   shows eight sets of weight matrices being used for eight heads  but other implementations i ve seen  the  annotated transformer  http   nlp seas harvard edu annotated transformer  full model  and gordic aleksa s  implementation  https   github com gordicaleksa pytorch original transformer blob main models definitions transformer_model py   as well as his video on his popular channel the ai epiphany  seem to use only one linear layer per key  query  and value  i m confused  can anybody explain ,trying understand multi head attention quite get queries keys values projected different subspaces specifically weight matrices used head different matrix used head illustrated transformer https jalammar github io illustrated transformer shows eight sets weight matrices used eight heads implementations seen annotated transformer http nlp seas harvard edu annotated transformer full model gordic aleksa implementation https github com gordicaleksa pytorch original transformer blob main models definitions transformer_model py well video popular channel ai epiphany seem use one linear layer per key query value confused anybody explain,multi head attention actually work,multi head attention actually worktrying understand multi head attention quite get queries keys values projected different subspaces specifically weight matrices used head different matrix used head illustrated transformer https jalammar github io illustrated transformer shows eight sets weight matrices used eight heads implementations seen annotated transformer http nlp seas harvard edu annotated transformer full model gordic aleksa implementation https github com gordicaleksa pytorch original transformer blob main models definitions transformer_model py well video popular channel ai epiphany seem use one linear layer per key query value confused anybody explain,"['multi', 'head', 'attention', 'actually', 'worktrying', 'understand', 'multi', 'head', 'attention', 'quite', 'get', 'queries', 'keys', 'values', 'projected', 'different', 'subspaces', 'specifically', 'weight', 'matrices', 'used', 'head', 'different', 'matrix', 'used', 'head', 'illustrated', 'transformer', 'https', 'jalammar', 'github', 'io', 'illustrated', 'transformer', 'shows', 'eight', 'sets', 'weight', 'matrices', 'used', 'eight', 'heads', 'implementations', 'seen', 'annotated', 'transformer', 'http', 'nlp', 'seas', 'harvard', 'edu', 'annotated', 'transformer', 'full', 'model', 'gordic', 'aleksa', 'implementation', 'https', 'github', 'com', 'gordicaleksa', 'pytorch', 'original', 'transformer', 'blob', 'main', 'models', 'definitions', 'transformer_model', 'py', 'well', 'video', 'popular', 'channel', 'ai', 'epiphany', 'seem', 'use', 'one', 'linear', 'layer', 'per', 'key', 'query', 'value', 'confused', 'anybody', 'explain']","['multi', 'head', 'attent', 'actual', 'worktri', 'understand', 'multi', 'head', 'attent', 'quit', 'get', 'queri', 'key', 'valu', 'project', 'differ', 'subspac', 'specif', 'weight', 'matric', 'use', 'head', 'differ', 'matrix', 'use', 'head', 'illustr', 'transform', 'http', 'jalammar', 'github', 'io', 'illustr', 'transform', 'show', 'eight', 'set', 'weight', 'matric', 'use', 'eight', 'head', 'implement', 'seen', 'annot', 'transform', 'http', 'nlp', 'sea', 'harvard', 'edu', 'annot', 'transform', 'full', 'model', 'gordic', 'aleksa', 'implement', 'http', 'github', 'com', 'gordicaleksa', 'pytorch', 'origin', 'transform', 'blob', 'main', 'model', 'definit', 'transformer_model', 'py', 'well', 'video', 'popular', 'channel', 'ai', 'epiphani', 'seem', 'use', 'one', 'linear', 'layer', 'per', 'key', 'queri', 'valu', 'confus', 'anybodi', 'explain']"
16,20,20,philipkiely,wb7al6,"[P] Truss, a new open-source library for model packaging and deployment","Hi r/machinelearning

At work, I just helped launch [Truss](https://github.com/basetenlabs/truss), our company’s first open-source project, and I wanted to tell you a bit about it in case it can help you serve and deploy your models.

Model serving, as part of MLOps, is the DevOps challenge of keeping a complicated, fragile artifact working in multiple dynamic environments. Data scientists working in large, well-resourced organizations can hand off their models to specialized MLOps teams for serving and deployment. The rest of us have to do it ourselves. As a data scientist, serving and deploying a model requires a different set of skills and technologies than building it did.

A data scientist’s working environment is the Jupyter notebook, a flexible and permissive system designed for iterative experimentation. The Jupyter notebook is a great tool for training models, but as an impermanent and development-oriented environment, it isn’t great for model serving. Model serving requires technologies like Docker to bring a stable, predictable environment.

Serving a model in production generally comes down to a few steps:

* Serialize the model
* Put the model behind a web server such as Flask
* Package the web server into a Docker image
* Run the Docker image on a container

Within these steps lurk additional complications. The model needs to accept input and produce output in appropriate formats, transforming from a Python-first interface to a web-first interface. And some models need to access GPU hardware to make predictions, or securely access secret values, or import Python and system packages.

But the bigger issue is that even the basic steps vary for every framework, and sometimes for different models built with the same framework. So even if you know how to serve a TensorFlow model, you’ll have to re-learn how to serve a PyTorch model, and go through the process again when you try a model from Hugging Face.

To give data scientists a better experience with model serving, the team at Baseten built Truss, an open-source Python package for serving models. Truss is a seamless bridge from model development to model delivery. Through a standardized abstraction, it can take a model from almost any framework and run it in any environment (via Docker). For data scientists doing their own MLops, Truss solves difficult problems in model serving, sharing, and deployment.

Truss, first developed at [Baseten](https://baseten.co), is an open source project under the MIT license. We have committed to long-term support and development for Truss — it is deeply integrated in our product strategy — but it lives as an independent project that emphasizes compatibility and interoperability.

Truss is an all-Python project and welcomes contributions, whether code, documentation, or bug reports. The roadmap is public and collaborative; we’ll work with you to build what you need.

We’re already working on features that proved valuable for early testers inside and outside of Baseten, like broadening CUDA support and implementing secret management. Our roadmap includes ideas around:

* Supporting more model frameworks
* Creating a standard for model test cases with assertions
* Interchangeable API backends
* Multi-GPU support and GPU sharing

Machine learning models are only going to get more sophisticated and capable. In turn, serving these models reliably — locally and in production — becomes more essential than ever. Truss offers a unified approach to model serving across model frameworks and deployment targets, and we hope you choose it for your next project. Get started by starring the repo and working through the [end-to-end deployment tutorial](https://truss.baseten.co/e2e) for your favorite framework and platform.",2,35,2022-07-29 18:11:09, p  truss  a new open source library for model packaging and deployment,hi r machinelearningat work  i just helped launch  truss  https model serving  as part of mlops  is the devops challenge of keeping a complicated  fragile artifact working in multiple dynamic environments  data scientists working in large  well resourced organizations can hand off their models to specialized mlops teams for serving and deployment  the rest of us have to do it ourselves  as a data scientist  serving and deploying a model requires a different set of skills and technologies than building it did a data scientist s working environment is the jupyter notebook  a flexible and permissive system designed for iterative experimentation  the jupyter notebook is a great tool for training models  but as an impermanent and development oriented environment  it isn t great for model serving  model serving requires technologies like docker to bring a stable  predictable environment serving a model in production generally comes down to a few steps   serialize the model  put the model behind a web server such as flask  package the web server into a docker image  run the docker image on a containerwithin these steps lurk additional complications  the model needs to accept input and produce output in appropriate formats  transforming from a python first interface to a web first interface  and some models need to access gpu hardware to make predictions  or securely access secret values  or import python and system packages but the bigger issue is that even the basic steps vary for every framework  and sometimes for different models built with the same framework  so even if you know how to serve a tensorflow model  you ll have to re learn how to serve a pytorch model  and go through the process again when you try a model from hugging face to give data scientists a better experience with model serving  the team at baseten built truss  an open source python package for serving models  truss is a seamless bridge from model development to model delivery  through a standardized abstraction  it can take a model from almost any framework and run it in any environment  via docker   for data scientists doing their own mlops  truss solves difficult problems in model serving  sharing  and deployment truss  first developed at  baseten  https truss is an all python project and welcomes contributions  whether code  documentation  or bug reports  the roadmap is public and collaborative  we ll work with you to build what you need we re already working on features that proved valuable for early testers inside and outside of baseten  like broadening cuda support and implementing secret management  our roadmap includes ideas around   supporting more model frameworks  creating a standard for model test cases with assertions  interchangeable api backends  multi gpu support and gpu sharingmachine learning models are only going to get more sophisticated and capable  in turn  serving these models reliably   locally and in production   becomes more essential than ever  truss offers a unified approach to model serving across model frameworks and deployment targets  and we hope you choose it for your next project  get started by starring the repo and working through the  end to end deployment tutorial  https   truss baseten co ee  for your favorite framework and platform ,hi r machinelearningat work helped launch truss https model serving part mlops devops challenge keeping complicated fragile artifact working multiple dynamic environments data scientists working large well resourced organizations hand models specialized mlops teams serving deployment rest us data scientist serving deploying model requires different set skills technologies building data scientist working environment jupyter notebook flexible permissive system designed iterative experimentation jupyter notebook great tool training models impermanent development oriented environment great model serving model serving requires technologies like docker bring stable predictable environment serving model production generally comes steps serialize model put model behind web server flask package web server docker image run docker image containerwithin steps lurk additional complications model needs accept input produce output appropriate formats transforming python first interface web first interface models need access gpu hardware make predictions securely access secret values import python system packages bigger issue even basic steps vary every framework sometimes different models built framework even know serve tensorflow model learn serve pytorch model go process try model hugging face give data scientists better experience model serving team baseten built truss open source python package serving models truss seamless bridge model development model delivery standardized abstraction take model almost framework run environment via docker data scientists mlops truss solves difficult problems model serving sharing deployment truss first developed baseten https truss python project welcomes contributions whether code documentation bug reports roadmap public collaborative work build need already working features proved valuable early testers inside outside baseten like broadening cuda support implementing secret management roadmap includes ideas around supporting model frameworks creating standard model test cases assertions interchangeable api backends multi gpu support gpu sharingmachine learning models going get sophisticated capable turn serving models reliably locally production becomes essential ever truss offers unified approach model serving across model frameworks deployment targets hope choose next project get started starring repo working end end deployment tutorial https truss baseten co ee favorite framework platform,p truss open source library model packaging deployment,p truss open source library model packaging deploymenthi r machinelearningat work helped launch truss https model serving part mlops devops challenge keeping complicated fragile artifact working multiple dynamic environments data scientists working large well resourced organizations hand models specialized mlops teams serving deployment rest us data scientist serving deploying model requires different set skills technologies building data scientist working environment jupyter notebook flexible permissive system designed iterative experimentation jupyter notebook great tool training models impermanent development oriented environment great model serving model serving requires technologies like docker bring stable predictable environment serving model production generally comes steps serialize model put model behind web server flask package web server docker image run docker image containerwithin steps lurk additional complications model needs accept input produce output appropriate formats transforming python first interface web first interface models need access gpu hardware make predictions securely access secret values import python system packages bigger issue even basic steps vary every framework sometimes different models built framework even know serve tensorflow model learn serve pytorch model go process try model hugging face give data scientists better experience model serving team baseten built truss open source python package serving models truss seamless bridge model development model delivery standardized abstraction take model almost framework run environment via docker data scientists mlops truss solves difficult problems model serving sharing deployment truss first developed baseten https truss python project welcomes contributions whether code documentation bug reports roadmap public collaborative work build need already working features proved valuable early testers inside outside baseten like broadening cuda support implementing secret management roadmap includes ideas around supporting model frameworks creating standard model test cases assertions interchangeable api backends multi gpu support gpu sharingmachine learning models going get sophisticated capable turn serving models reliably locally production becomes essential ever truss offers unified approach model serving across model frameworks deployment targets hope choose next project get started starring repo working end end deployment tutorial https truss baseten co ee favorite framework platform,"['p', 'truss', 'open', 'source', 'library', 'model', 'packaging', 'deploymenthi', 'r', 'machinelearningat', 'work', 'helped', 'launch', 'truss', 'https', 'model', 'serving', 'part', 'mlops', 'devops', 'challenge', 'keeping', 'complicated', 'fragile', 'artifact', 'working', 'multiple', 'dynamic', 'environments', 'data', 'scientists', 'working', 'large', 'well', 'resourced', 'organizations', 'hand', 'models', 'specialized', 'mlops', 'teams', 'serving', 'deployment', 'rest', 'us', 'data', 'scientist', 'serving', 'deploying', 'model', 'requires', 'different', 'set', 'skills', 'technologies', 'building', 'data', 'scientist', 'working', 'environment', 'jupyter', 'notebook', 'flexible', 'permissive', 'system', 'designed', 'iterative', 'experimentation', 'jupyter', 'notebook', 'great', 'tool', 'training', 'models', 'impermanent', 'development', 'oriented', 'environment', 'great', 'model', 'serving', 'model', 'serving', 'requires', 'technologies', 'like', 'docker', 'bring', 'stable', 'predictable', 'environment', 'serving', 'model', 'production', 'generally', 'comes', 'steps', 'serialize', 'model', 'put', 'model', 'behind', 'web', 'server', 'flask', 'package', 'web', 'server', 'docker', 'image', 'run', 'docker', 'image', 'containerwithin', 'steps', 'lurk', 'additional', 'complications', 'model', 'needs', 'accept', 'input', 'produce', 'output', 'appropriate', 'formats', 'transforming', 'python', 'first', 'interface', 'web', 'first', 'interface', 'models', 'need', 'access', 'gpu', 'hardware', 'make', 'predictions', 'securely', 'access', 'secret', 'values', 'import', 'python', 'system', 'packages', 'bigger', 'issue', 'even', 'basic', 'steps', 'vary', 'every', 'framework', 'sometimes', 'different', 'models', 'built', 'framework', 'even', 'know', 'serve', 'tensorflow', 'model', 'learn', 'serve', 'pytorch', 'model', 'go', 'process', 'try', 'model', 'hugging', 'face', 'give', 'data', 'scientists', 'better', 'experience', 'model', 'serving', 'team', 'baseten', 'built', 'truss', 'open', 'source', 'python', 'package', 'serving', 'models', 'truss', 'seamless', 'bridge', 'model', 'development', 'model', 'delivery', 'standardized', 'abstraction', 'take', 'model', 'almost', 'framework', 'run', 'environment', 'via', 'docker', 'data', 'scientists', 'mlops', 'truss', 'solves', 'difficult', 'problems', 'model', 'serving', 'sharing', 'deployment', 'truss', 'first', 'developed', 'baseten', 'https', 'truss', 'python', 'project', 'welcomes', 'contributions', 'whether', 'code', 'documentation', 'bug', 'reports', 'roadmap', 'public', 'collaborative', 'work', 'build', 'need', 'already', 'working', 'features', 'proved', 'valuable', 'early', 'testers', 'inside', 'outside', 'baseten', 'like', 'broadening', 'cuda', 'support', 'implementing', 'secret', 'management', 'roadmap', 'includes', 'ideas', 'around', 'supporting', 'model', 'frameworks', 'creating', 'standard', 'model', 'test', 'cases', 'assertions', 'interchangeable', 'api', 'backends', 'multi', 'gpu', 'support', 'gpu', 'sharingmachine', 'learning', 'models', 'going', 'get', 'sophisticated', 'capable', 'turn', 'serving', 'models', 'reliably', 'locally', 'production', 'becomes', 'essential', 'ever', 'truss', 'offers', 'unified', 'approach', 'model', 'serving', 'across', 'model', 'frameworks', 'deployment', 'targets', 'hope', 'choose', 'next', 'project', 'get', 'started', 'starring', 'repo', 'working', 'end', 'end', 'deployment', 'tutorial', 'https', 'truss', 'baseten', 'co', 'ee', 'favorite', 'framework', 'platform']","['p', 'truss', 'open', 'sourc', 'librari', 'model', 'packag', 'deploymenthi', 'r', 'machinelearningat', 'work', 'help', 'launch', 'truss', 'http', 'model', 'serv', 'part', 'mlop', 'devop', 'challeng', 'keep', 'complic', 'fragil', 'artifact', 'work', 'multipl', 'dynam', 'environ', 'data', 'scientist', 'work', 'larg', 'well', 'resourc', 'organ', 'hand', 'model', 'special', 'mlop', 'team', 'serv', 'deploy', 'rest', 'us', 'data', 'scientist', 'serv', 'deploy', 'model', 'requir', 'differ', 'set', 'skill', 'technolog', 'build', 'data', 'scientist', 'work', 'environ', 'jupyt', 'notebook', 'flexibl', 'permiss', 'system', 'design', 'iter', 'experiment', 'jupyt', 'notebook', 'great', 'tool', 'train', 'model', 'imperman', 'develop', 'orient', 'environ', 'great', 'model', 'serv', 'model', 'serv', 'requir', 'technolog', 'like', 'docker', 'bring', 'stabl', 'predict', 'environ', 'serv', 'model', 'product', 'gener', 'come', 'step', 'serial', 'model', 'put', 'model', 'behind', 'web', 'server', 'flask', 'packag', 'web', 'server', 'docker', 'imag', 'run', 'docker', 'imag', 'containerwithin', 'step', 'lurk', 'addit', 'complic', 'model', 'need', 'accept', 'input', 'produc', 'output', 'appropri', 'format', 'transform', 'python', 'first', 'interfac', 'web', 'first', 'interfac', 'model', 'need', 'access', 'gpu', 'hardwar', 'make', 'predict', 'secur', 'access', 'secret', 'valu', 'import', 'python', 'system', 'packag', 'bigger', 'issu', 'even', 'basic', 'step', 'vari', 'everi', 'framework', 'sometim', 'differ', 'model', 'built', 'framework', 'even', 'know', 'serv', 'tensorflow', 'model', 'learn', 'serv', 'pytorch', 'model', 'go', 'process', 'tri', 'model', 'hug', 'face', 'give', 'data', 'scientist', 'better', 'experi', 'model', 'serv', 'team', 'baseten', 'built', 'truss', 'open', 'sourc', 'python', 'packag', 'serv', 'model', 'truss', 'seamless', 'bridg', 'model', 'develop', 'model', 'deliveri', 'standard', 'abstract', 'take', 'model', 'almost', 'framework', 'run', 'environ', 'via', 'docker', 'data', 'scientist', 'mlop', 'truss', 'solv', 'difficult', 'problem', 'model', 'serv', 'share', 'deploy', 'truss', 'first', 'develop', 'baseten', 'http', 'truss', 'python', 'project', 'welcom', 'contribut', 'whether', 'code', 'document', 'bug', 'report', 'roadmap', 'public', 'collabor', 'work', 'build', 'need', 'alreadi', 'work', 'featur', 'prove', 'valuabl', 'earli', 'tester', 'insid', 'outsid', 'baseten', 'like', 'broaden', 'cuda', 'support', 'implement', 'secret', 'manag', 'roadmap', 'includ', 'idea', 'around', 'support', 'model', 'framework', 'creat', 'standard', 'model', 'test', 'case', 'assert', 'interchang', 'api', 'backend', 'multi', 'gpu', 'support', 'gpu', 'sharingmachin', 'learn', 'model', 'go', 'get', 'sophist', 'capabl', 'turn', 'serv', 'model', 'reliabl', 'local', 'product', 'becom', 'essenti', 'ever', 'truss', 'offer', 'unifi', 'approach', 'model', 'serv', 'across', 'model', 'framework', 'deploy', 'target', 'hope', 'choos', 'next', 'project', 'get', 'start', 'star', 'repo', 'work', 'end', 'end', 'deploy', 'tutori', 'http', 'truss', 'baseten', 'co', 'ee', 'favorit', 'framework', 'platform']"
17,21,21,Inferno_1405,wbtdas,[D] Notes for Stanford or UMichigan DL course,Anyone has notes for Stanford's CS231n or UMichigan's EECS 498-007/598-005 deep learning for computer vision course?,2,1,2022-07-30 12:17:34, d  notes for stanford or umichigan dl course,anyone has notes for stanford s csn or umichigan s eecs     deep learning for computer vision course ,anyone notes stanford csn umichigan eecs deep learning computer vision course,notes stanford umichigan dl course,notes stanford umichigan dl courseanyone notes stanford csn umichigan eecs deep learning computer vision course,"['notes', 'stanford', 'umichigan', 'dl', 'courseanyone', 'notes', 'stanford', 'csn', 'umichigan', 'eecs', 'deep', 'learning', 'computer', 'vision', 'course']","['note', 'stanford', 'umichigan', 'dl', 'courseanyon', 'note', 'stanford', 'csn', 'umichigan', 'eec', 'deep', 'learn', 'comput', 'vision', 'cours']"
18,22,22,whipbryd,wbclwp,[D] Are there any tools to quickly label training data manually?,"So, I have heaps of data and I want a way to comfortably label them on my pc or even more preferrably on my phone. I can't really find an app or program to do it. Maybe I am using the wrong search terms, but I really can't find anything. There was [https://borgo.app](https://borgo.app) but development seems to have halted... 

I am just seraching for an application that will show me a piece of text (or image) from a Dataset and I can press a button or similar to quickly label it (as in: sort it into categories). It seems like a trivial app to build and super useful so I cannot believe nobody has done it before.",12,12,2022-07-29 21:49:25, d  are there any tools to quickly label training data manually ,so  i have heaps of data and i want a way to comfortably label them on my pc or even more preferrably on my phone  i can t really find an app or program to do it  maybe i am using the wrong search terms  but i really can t find anything  there was  https i am just seraching for an application that will show me a piece of text  or image  from a dataset and i can press a button or similar to quickly label it  as in  sort it into categories   it seems like a trivial app to build and super useful so i cannot believe nobody has done it before ,heaps data want way comfortably label pc even preferrably phone really find app program maybe using wrong search terms really find anything https seraching application show piece text image dataset press button similar quickly label sort categories seems like trivial app build super useful cannot believe nobody done,tools quickly label training data manually,tools quickly label training data manuallyheaps data want way comfortably label pc even preferrably phone really find app program maybe using wrong search terms really find anything https seraching application show piece text image dataset press button similar quickly label sort categories seems like trivial app build super useful cannot believe nobody done,"['tools', 'quickly', 'label', 'training', 'data', 'manuallyheaps', 'data', 'want', 'way', 'comfortably', 'label', 'pc', 'even', 'preferrably', 'phone', 'really', 'find', 'app', 'program', 'maybe', 'using', 'wrong', 'search', 'terms', 'really', 'find', 'anything', 'https', 'seraching', 'application', 'show', 'piece', 'text', 'image', 'dataset', 'press', 'button', 'similar', 'quickly', 'label', 'sort', 'categories', 'seems', 'like', 'trivial', 'app', 'build', 'super', 'useful', 'can', 'not', 'believe', 'nobody', 'done']","['tool', 'quickli', 'label', 'train', 'data', 'manuallyheap', 'data', 'want', 'way', 'comfort', 'label', 'pc', 'even', 'preferr', 'phone', 'realli', 'find', 'app', 'program', 'mayb', 'use', 'wrong', 'search', 'term', 'realli', 'find', 'anyth', 'http', 'serach', 'applic', 'show', 'piec', 'text', 'imag', 'dataset', 'press', 'button', 'similar', 'quickli', 'label', 'sort', 'categori', 'seem', 'like', 'trivial', 'app', 'build', 'super', 'use', 'can', 'not', 'believ', 'nobodi', 'done']"
19,23,23,BadKarma-18,wbd182,[D] What are some ways to scale and maintain machine learning models?,Other than API endpoints have you ever worked with or encountered process to deploy a machine learning model at scale,1,8,2022-07-29 22:07:49, d  what are some ways to scale and maintain machine learning models ,other than api endpoints have you ever worked with or encountered process to deploy a machine learning model at scale,api endpoints ever worked encountered process deploy machine learning model scale,ways scale maintain machine learning models,ways scale maintain machine learning modelsapi endpoints ever worked encountered process deploy machine learning model scale,"['ways', 'scale', 'maintain', 'machine', 'learning', 'modelsapi', 'endpoints', 'ever', 'worked', 'encountered', 'process', 'deploy', 'machine', 'learning', 'model', 'scale']","['way', 'scale', 'maintain', 'machin', 'learn', 'modelsapi', 'endpoint', 'ever', 'work', 'encount', 'process', 'deploy', 'machin', 'learn', 'model', 'scale']"
20,24,24,Krokodeale,wbdq5c,[D] ROCm vs CUDA,"Hello people,

I tried to look online for comparisons of the recent AMD (ROCm) and GPU (CUDA) cards but I've found very few benchmarks.

Since Pytorch natively supports ROCm, I'm thinking about upgrading my GPU card to AMD instead of Nvidia. But I'm afraid of losing too much performance on training.

If you guys have any information to share I would be glad to hear!

&#x200B;

EDIT : Thanks for the answer, exactly what I needed, I guess we are stuck with Nvidia",7,5,2022-07-29 22:37:58, d  rocm vs cuda,hello people i tried to look online for comparisons of the recent amd  rocm  and gpu  cuda  cards but i ve found very few benchmarks since pytorch natively supports rocm  i m thinking about upgrading my gpu card to amd instead of nvidia  but i m afraid of losing too much performance on training if you guys have any information to share i would be glad to hear   xb edit   thanks for the answer  exactly what i needed  i guess we are stuck with nvidia,hello people tried look online comparisons recent amd rocm gpu cuda cards found benchmarks since pytorch natively supports rocm thinking upgrading gpu card amd instead nvidia afraid losing much performance training guys information share would glad hear xb edit thanks answer exactly needed guess stuck nvidia,rocm vs cuda,rocm vs cudahello people tried look online comparisons recent amd rocm gpu cuda cards found benchmarks since pytorch natively supports rocm thinking upgrading gpu card amd instead nvidia afraid losing much performance training guys information share would glad hear xb edit thanks answer exactly needed guess stuck nvidia,"['rocm', 'vs', 'cudahello', 'people', 'tried', 'look', 'online', 'comparisons', 'recent', 'amd', 'rocm', 'gpu', 'cuda', 'cards', 'found', 'benchmarks', 'since', 'pytorch', 'natively', 'supports', 'rocm', 'thinking', 'upgrading', 'gpu', 'card', 'amd', 'instead', 'nvidia', 'afraid', 'losing', 'much', 'performance', 'training', 'guys', 'information', 'share', 'would', 'glad', 'hear', 'xb', 'edit', 'thanks', 'answer', 'exactly', 'needed', 'guess', 'stuck', 'nvidia']","['rocm', 'vs', 'cudahello', 'peopl', 'tri', 'look', 'onlin', 'comparison', 'recent', 'amd', 'rocm', 'gpu', 'cuda', 'card', 'found', 'benchmark', 'sinc', 'pytorch', 'nativ', 'support', 'rocm', 'think', 'upgrad', 'gpu', 'card', 'amd', 'instead', 'nvidia', 'afraid', 'lose', 'much', 'perform', 'train', 'guy', 'inform', 'share', 'would', 'glad', 'hear', 'xb', 'edit', 'thank', 'answer', 'exactli', 'need', 'guess', 'stuck', 'nvidia']"
21,26,26,Gamwise_Samgee_,wbcery,[D] 2D cuts with decision tree?,"I'm working on a boosted decision tree, and I've got it working fairly well. However it would be better if it was able to make decisions/cuts in more than one dimension (preferably 2D).

Is this something that is even possible? (I'm using sklearn)",5,6,2022-07-29 21:40:25, d  d cuts with decision tree ,i m working on a boosted decision tree  and i ve got it working fairly well  however it would be better if it was able to make decisions cuts in more than one dimension  preferably d  is this something that is even possible   i m using sklearn ,working boosted decision tree got working fairly well however would better able make decisions cuts one dimension preferably something even possible using sklearn,cuts decision tree,cuts decision treeworking boosted decision tree got working fairly well however would better able make decisions cuts one dimension preferably something even possible using sklearn,"['cuts', 'decision', 'treeworking', 'boosted', 'decision', 'tree', 'got', 'working', 'fairly', 'well', 'however', 'would', 'better', 'able', 'make', 'decisions', 'cuts', 'one', 'dimension', 'preferably', 'something', 'even', 'possible', 'using', 'sklearn']","['cut', 'decis', 'treework', 'boost', 'decis', 'tree', 'got', 'work', 'fairli', 'well', 'howev', 'would', 'better', 'abl', 'make', 'decis', 'cut', 'one', 'dimens', 'prefer', 'someth', 'even', 'possibl', 'use', 'sklearn']"
22,27,27,Singularian2501,wbi0gi,[R] PanGu-Coder: Program Synthesis with Function-Level Language Modeling - Huawei 2022,"Paper: [https://arxiv.org/abs/2207.11280](https://arxiv.org/abs/2207.11280)

Abstract:

>We present PanGu-Coder, a pretrained decoder-only language model adopting the PanGu-Alpha architecture for text-to-code generation, i.e. the synthesis of programming language solutions given a natural language problem description. We train PanGu-Coder using a two-stage strategy: the first stage employs Causal Language Modelling (CLM) to pre-train on raw programming language data, while the second stage uses a combination of Causal Language Modelling and Masked Language Modelling (MLM) training objectives that focus on the downstream task of text-to-code generation and train on loosely curated pairs of natural language program definitions and code functions. Finally, we discuss PanGu-Coder-FT, which is fine-tuned on a combination of competitive programming problems and code with continuous integration tests. We evaluate PanGu-Coder with a focus on whether it generates functionally correct programs and demonstrate that it **achieves equivalent or better performance than similarly sized models, such as CodeX, while attending a smaller context window and training on less data.**       

https://preview.redd.it/7hdptg7j5le91.jpg?width=1040&format=pjpg&auto=webp&s=043b82c7752342e4421f7c9bed1475ada4d06609

https://preview.redd.it/6btcig7j5le91.jpg?width=917&format=pjpg&auto=webp&s=712805e02d81aed10ce085b6d83e7b3b72770cff",1,2,2022-07-30 01:48:47, r  pangu coder  program synthesis with function level language modeling   huawei ,paper   https abstract  we present pangu coder  a pretrained decoder only language model adopting the pangu alpha architecture for text to code generation  i e  the synthesis of programming language solutions given a natural language problem description  we train pangu coder using a two stage strategy  the first stage employs causal language modelling  clm  to pre train on raw programming language data  while the second stage uses a combination of causal language modelling and masked language modelling  mlm  training objectives that focus on the downstream task of text to code generation and train on loosely curated pairs of natural language program definitions and code functions  finally  we discuss pangu coder ft  which is fine tuned on a combination of competitive programming problems and code with continuous integration tests  we evaluate pangu coder with a focus on whether it generates functionally correct programs and demonstrate that it   achieves equivalent or better performance than similarly sized models  such as codex  while attending a smaller context window and training on less data          https https   preview redd it btcigjle jpg width  format pjpg auto webp s edaedcebdebbcff,paper https abstract present pangu coder pretrained decoder language model adopting pangu alpha architecture text code generation e synthesis programming language solutions given natural language problem description train pangu coder using two stage strategy first stage employs causal language modelling clm pre train raw programming language data second stage uses combination causal language modelling masked language modelling mlm training objectives focus downstream task text code generation train loosely curated pairs natural language program definitions code functions finally discuss pangu coder ft fine tuned combination competitive programming problems code continuous integration tests evaluate pangu coder focus whether generates functionally correct programs demonstrate achieves equivalent better performance similarly sized models codex attending smaller context window training less data https https preview redd btcigjle jpg width format pjpg auto webp edaedcebdebbcff,r pangu coder program synthesis function level language modeling huawei,r pangu coder program synthesis function level language modeling huaweipaper https abstract present pangu coder pretrained decoder language model adopting pangu alpha architecture text code generation e synthesis programming language solutions given natural language problem description train pangu coder using two stage strategy first stage employs causal language modelling clm pre train raw programming language data second stage uses combination causal language modelling masked language modelling mlm training objectives focus downstream task text code generation train loosely curated pairs natural language program definitions code functions finally discuss pangu coder ft fine tuned combination competitive programming problems code continuous integration tests evaluate pangu coder focus whether generates functionally correct programs demonstrate achieves equivalent better performance similarly sized models codex attending smaller context window training less data https https preview redd btcigjle jpg width format pjpg auto webp edaedcebdebbcff,"['r', 'pangu', 'coder', 'program', 'synthesis', 'function', 'level', 'language', 'modeling', 'huaweipaper', 'https', 'abstract', 'present', 'pangu', 'coder', 'pretrained', 'decoder', 'language', 'model', 'adopting', 'pangu', 'alpha', 'architecture', 'text', 'code', 'generation', 'e', 'synthesis', 'programming', 'language', 'solutions', 'given', 'natural', 'language', 'problem', 'description', 'train', 'pangu', 'coder', 'using', 'two', 'stage', 'strategy', 'first', 'stage', 'employs', 'causal', 'language', 'modelling', 'clm', 'pre', 'train', 'raw', 'programming', 'language', 'data', 'second', 'stage', 'uses', 'combination', 'causal', 'language', 'modelling', 'masked', 'language', 'modelling', 'mlm', 'training', 'objectives', 'focus', 'downstream', 'task', 'text', 'code', 'generation', 'train', 'loosely', 'curated', 'pairs', 'natural', 'language', 'program', 'definitions', 'code', 'functions', 'finally', 'discuss', 'pangu', 'coder', 'ft', 'fine', 'tuned', 'combination', 'competitive', 'programming', 'problems', 'code', 'continuous', 'integration', 'tests', 'evaluate', 'pangu', 'coder', 'focus', 'whether', 'generates', 'functionally', 'correct', 'programs', 'demonstrate', 'achieves', 'equivalent', 'better', 'performance', 'similarly', 'sized', 'models', 'codex', 'attending', 'smaller', 'context', 'window', 'training', 'less', 'data', 'https', 'https', 'preview', 'redd', 'btcigjle', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'edaedcebdebbcff']","['r', 'pangu', 'coder', 'program', 'synthesi', 'function', 'level', 'languag', 'model', 'huaweipap', 'http', 'abstract', 'present', 'pangu', 'coder', 'pretrain', 'decod', 'languag', 'model', 'adopt', 'pangu', 'alpha', 'architectur', 'text', 'code', 'gener', 'e', 'synthesi', 'program', 'languag', 'solut', 'given', 'natur', 'languag', 'problem', 'descript', 'train', 'pangu', 'coder', 'use', 'two', 'stage', 'strategi', 'first', 'stage', 'employ', 'causal', 'languag', 'model', 'clm', 'pre', 'train', 'raw', 'program', 'languag', 'data', 'second', 'stage', 'use', 'combin', 'causal', 'languag', 'model', 'mask', 'languag', 'model', 'mlm', 'train', 'object', 'focu', 'downstream', 'task', 'text', 'code', 'gener', 'train', 'loos', 'curat', 'pair', 'natur', 'languag', 'program', 'definit', 'code', 'function', 'final', 'discuss', 'pangu', 'coder', 'ft', 'fine', 'tune', 'combin', 'competit', 'program', 'problem', 'code', 'continu', 'integr', 'test', 'evalu', 'pangu', 'coder', 'focu', 'whether', 'gener', 'function', 'correct', 'program', 'demonstr', 'achiev', 'equival', 'better', 'perform', 'similarli', 'size', 'model', 'codex', 'attend', 'smaller', 'context', 'window', 'train', 'less', 'data', 'http', 'http', 'preview', 'redd', 'btcigjl', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'edaedcebdebbcff']"
23,28,28,AbjectDrink3276,wb4hwp,[D] Will AAAI Revise their NeurIPS Fast Track score?,"I have reached out to the general inquiries email at AAAI 2023 to see if they will be revising their NeurIPS fasttrack score, since NeurIPS downward revised their scoring system for 4 to be borderline reject this year and in previous years a 5 was a borderline reject and AAAI required a 4.9 to be fast tracked. 

I am curious is anyone has heard anything?",0,10,2022-07-29 16:12:36, d  will aaai revise their neurips fast track score ,i have reached out to the general inquiries email at aaai  to see if they will be revising their neurips fasttrack score  since neurips downward revised their scoring system for  to be borderline reject this year and in previous years a  was a borderline reject and aaai required a   to be fast tracked  i am curious is anyone has heard anything ,reached general inquiries email aaai see revising neurips fasttrack score since neurips downward revised scoring system borderline reject year previous years borderline reject aaai required fast tracked curious anyone heard anything,aaai revise neurips fast track score,aaai revise neurips fast track scorereached general inquiries email aaai see revising neurips fasttrack score since neurips downward revised scoring system borderline reject year previous years borderline reject aaai required fast tracked curious anyone heard anything,"['aaai', 'revise', 'neurips', 'fast', 'track', 'scorereached', 'general', 'inquiries', 'email', 'aaai', 'see', 'revising', 'neurips', 'fasttrack', 'score', 'since', 'neurips', 'downward', 'revised', 'scoring', 'system', 'borderline', 'reject', 'year', 'previous', 'years', 'borderline', 'reject', 'aaai', 'required', 'fast', 'tracked', 'curious', 'anyone', 'heard', 'anything']","['aaai', 'revis', 'neurip', 'fast', 'track', 'scorereach', 'gener', 'inquiri', 'email', 'aaai', 'see', 'revis', 'neurip', 'fasttrack', 'score', 'sinc', 'neurip', 'downward', 'revis', 'score', 'system', 'borderlin', 'reject', 'year', 'previou', 'year', 'borderlin', 'reject', 'aaai', 'requir', 'fast', 'track', 'curiou', 'anyon', 'heard', 'anyth']"
24,29,29,krumb0y,wb2ivp,"[P] Created tutorials on Information Retrieval, specifically Semantic Search","Hi, I've created a repo which tries to cover the current progress in the world of information-retrieval using neural information retrievers / semantic search. Repo: [https://github.com/kuutsav/information-retrieval](https://github.com/kuutsav/information-retrieval) .

Most of the content follows the work of [Nils Reimers](https://www.nils-reimers.de/) (creator of the `sentence_transformers` library) and his research group.

**Topics covered**

* Classic way of information retrieval
* Evaluation metrics
* Bi-Encoders
* Cross-Encoders
* Multilingual retrieval models
* Training techniques using no labeled data
   * Domain adaptation - GPL, TSDAE, SimCSE

**Things to come**

* Vector databases
* Approximate Nearest Neighbor techniques for quick retrieval",0,8,2022-07-29 14:38:39, p  created tutorials on information retrieval  specifically semantic search,hi  i ve created a repo which tries to cover the current progress in the world of information retrieval using neural information retrievers   semantic search  repo   https most of the content follows the work of  nils reimers  https   topics covered    classic way of information retrieval  evaluation metrics  bi encoders  cross encoders  multilingual retrieval models  training techniques using no labeled data     domain adaptation   gpl  tsdae  simcse  things to come    vector databases  approximate nearest neighbor techniques for quick retrieval,hi created repo tries cover current progress world information retrieval using neural information retrievers semantic search repo https content follows work nils reimers https topics covered classic way information retrieval evaluation metrics bi encoders cross encoders multilingual retrieval models training techniques using labeled data domain adaptation gpl tsdae simcse things come vector databases approximate nearest neighbor techniques quick retrieval,p created tutorials information retrieval specifically semantic search,p created tutorials information retrieval specifically semantic searchhi created repo tries cover current progress world information retrieval using neural information retrievers semantic search repo https content follows work nils reimers https topics covered classic way information retrieval evaluation metrics bi encoders cross encoders multilingual retrieval models training techniques using labeled data domain adaptation gpl tsdae simcse things come vector databases approximate nearest neighbor techniques quick retrieval,"['p', 'created', 'tutorials', 'information', 'retrieval', 'specifically', 'semantic', 'searchhi', 'created', 'repo', 'tries', 'cover', 'current', 'progress', 'world', 'information', 'retrieval', 'using', 'neural', 'information', 'retrievers', 'semantic', 'search', 'repo', 'https', 'content', 'follows', 'work', 'nils', 'reimers', 'https', 'topics', 'covered', 'classic', 'way', 'information', 'retrieval', 'evaluation', 'metrics', 'bi', 'encoders', 'cross', 'encoders', 'multilingual', 'retrieval', 'models', 'training', 'techniques', 'using', 'labeled', 'data', 'domain', 'adaptation', 'gpl', 'tsdae', 'simcse', 'things', 'come', 'vector', 'databases', 'approximate', 'nearest', 'neighbor', 'techniques', 'quick', 'retrieval']","['p', 'creat', 'tutori', 'inform', 'retriev', 'specif', 'semant', 'searchhi', 'creat', 'repo', 'tri', 'cover', 'current', 'progress', 'world', 'inform', 'retriev', 'use', 'neural', 'inform', 'retriev', 'semant', 'search', 'repo', 'http', 'content', 'follow', 'work', 'nil', 'reimer', 'http', 'topic', 'cover', 'classic', 'way', 'inform', 'retriev', 'evalu', 'metric', 'bi', 'encod', 'cross', 'encod', 'multilingu', 'retriev', 'model', 'train', 'techniqu', 'use', 'label', 'data', 'domain', 'adapt', 'gpl', 'tsdae', 'simcs', 'thing', 'come', 'vector', 'databas', 'approxim', 'nearest', 'neighbor', 'techniqu', 'quick', 'retriev']"
25,30,30,jonathan-lei,wake5v,[D] TensorDock Core GPU Cloud — GPU servers from $0.29/hr,"Hello r/MachineLearning! 

I’m Jonathan from TensorDock. After 7 months in beta, we’re finally launching Core Cloud, our platform to deploy GPU virtual machines in as little as 45 seconds! I think you guys would find this as a nice alternative to other clouds for you to train your ML models. [https://www.tensordock.com/product-core](https://www.tensordock.com/product-core)

🤔 Why? 

Training machine learning workloads at large clouds can be extremely expensive. This left us wondering, “how did cloud ever become more expensive than on-prem?” I’ve seen too many ML startups buy their own hardware. Cheaper dedicated servers with NVIDIA GPUs are not too hard to find, but they lack the functionality and scalability of the big clouds. 

We thought to ourselves, what if we built a platform that combines the functionality of the large clouds but made it priced somewhere between a dedicated server and the large clouds? That’s exactly what we’ve done. 

👩‍💻 Built to make engineers more productive

1. 3 machine learning images so you can start training ML models in 2 minutes, not 2 hours
2. We provide a REST API, so you can integrate directly your code with ours
3. There’s also a community CLI you can use to manage your servers directly via command line

💪 The feature set only large clouds can match

1. Storage-only billing when the VM is stopped (for only $0.073/GB/month) 
2. Edit virtual machines after they’re created to downsize costs. If you provision a NVIDIA A6000 and find out you’re only using 50% of it, stop the VM, modify it to a NVIDIA A5000, and you’ll be billed the lower hourly rate without needing to recreate your server and migrate data over! 
3. 3x-replicated NVMe-based network storage. Seriously fast
4. 10 Gbps networking
5. 3 locations (New York, Chicago, Las Vegas), and more coming soon! 
6. Custom alerts for billing
7. Billing pro-rated to the minute

🤑 How cheap are we? 

1. CPU-only servers from $0.027/hour
2. NVIDIA Quadro RTX 4000s from $0.29/hour
3. NVIDIA Tesla V100s from $0.52/hour
4. … and 8 other GPU types that let you truly right-size workloads so that you’re never paying for more than you actually need

Example use case: 

1. Spin up a CPU-only server for $0.027/hour to upload all of your data
2. Convert it to a GPU server to train your ML workload for $0.282/hour
3. Convert it back to a CPU-only server to analyze the results for $0.027/hour
4. Stop the server but keep the data for only $0.073/GB/month in storage costs
5. Start the server back up again, and train your next workload! 

🎉 Celebrate our launch with us with $1 in free credit! 

Yes, we sound cheap… but $1 is all you need to get started with us! That’s more than 3 hours of compute time on our cheapest configuration! Use code REDDIT\_1 on the billing page to redeem this free credit. 

Deploy a GPU: [https://console.tensordock.com/deploy](https://console.tensordock.com/deploy)

I'm here to answer your questions, so post them below!",28,115,2022-07-28 23:28:55, d  tensordock core gpu cloud   gpu servers from    hr,hello r machinelearning  i m jonathan from tensordock  after  months in beta  we re finally launching core cloud  our platform to deploy gpu virtual machines in as little as  seconds  i think you guys would find this as a nice alternative to other clouds for you to train your ml models   https   why  training machine learning workloads at large clouds can be extremely expensive  this left us wondering   how did cloud ever become more expensive than on prem   i ve seen too many ml startups buy their own hardware  cheaper dedicated servers with nvidia gpus are not too hard to find  but they lack the functionality and scalability of the big clouds  we thought to ourselves  what if we built a platform that combines the functionality of the large clouds but made it priced somewhere between a dedicated server and the large clouds  that s exactly what we ve done      built to make engineers more productive   machine learning images so you can start training ml models in  minutes  not  hours  we provide a rest api  so you can integrate directly your code with ours  there s also a community cli you can use to manage your servers directly via command line  the feature set only large clouds can match  storage only billing when the vm is stopped  for only    gb month    edit virtual machines after they re created to downsize costs  if you provision a nvidia a and find out you re only using   of it  stop the vm  modify it to a nvidia a  and you ll be billed the lower hourly rate without needing to recreate your server and migrate data over    x replicated nvme based network storage  seriously fast   gbps networking   locations  new york  chicago  las vegas   and more coming soon    custom alerts for billing  billing pro rated to the minute  how cheap are we    cpu only servers from    hour  nvidia quadro rtx s from    hour  nvidia tesla vs from    hour    and  other gpu types that let you truly right size workloads so that you re never paying for more than you actually needexample use case    spin up a cpu only server for    hour to upload all of your data  convert it to a gpu server to train your ml workload for    hour  convert it back to a cpu only server to analyze the results for    hour  stop the server but keep the data for only    gb month in storage costs  start the server back up again  and train your next workload    celebrate our launch with us with   in free credit  yes  we sound cheap  but   is all you need to get started with us  that s more than  hours of compute time on our cheapest configuration  use code reddit _ on the billing page to redeem this free credit  deploy a gpu   https i m here to answer your questions  so post them below ,hello r machinelearning jonathan tensordock months beta finally launching core cloud platform deploy gpu virtual machines little seconds think guys would find nice alternative clouds train ml models https training machine learning workloads large clouds extremely expensive left us wondering cloud ever become expensive prem seen many ml startups buy hardware cheaper dedicated servers nvidia gpus hard find lack functionality scalability big clouds thought built platform combines functionality large clouds made priced somewhere dedicated server large clouds exactly done built make engineers productive machine learning images start training ml models minutes hours provide rest api integrate directly code also community cli use manage servers directly via command line feature set large clouds match storage billing vm stopped gb month edit virtual machines created downsize costs provision nvidia find using stop vm modify nvidia billed lower hourly rate without needing recreate server migrate data x replicated nvme based network storage seriously fast gbps networking locations york chicago las vegas coming soon alerts billing billing pro rated minute cheap cpu servers hour nvidia quadro rtx hour nvidia tesla vs hour gpu types let truly right size workloads never paying actually needexample use case spin cpu server hour upload data convert gpu server train ml workload hour convert back cpu server analyze results hour stop server keep data gb month storage costs start server back train next workload celebrate launch us free credit yes sound cheap need get started us hours compute time cheapest configuration use code reddit _ billing page redeem free credit deploy gpu https answer questions post,tensordock core gpu cloud gpu servers hr,tensordock core gpu cloud gpu servers hrhello r machinelearning jonathan tensordock months beta finally launching core cloud platform deploy gpu virtual machines little seconds think guys would find nice alternative clouds train ml models https training machine learning workloads large clouds extremely expensive left us wondering cloud ever become expensive prem seen many ml startups buy hardware cheaper dedicated servers nvidia gpus hard find lack functionality scalability big clouds thought built platform combines functionality large clouds made priced somewhere dedicated server large clouds exactly done built make engineers productive machine learning images start training ml models minutes hours provide rest api integrate directly code also community cli use manage servers directly via command line feature set large clouds match storage billing vm stopped gb month edit virtual machines created downsize costs provision nvidia find using stop vm modify nvidia billed lower hourly rate without needing recreate server migrate data x replicated nvme based network storage seriously fast gbps networking locations york chicago las vegas coming soon alerts billing billing pro rated minute cheap cpu servers hour nvidia quadro rtx hour nvidia tesla vs hour gpu types let truly right size workloads never paying actually needexample use case spin cpu server hour upload data convert gpu server train ml workload hour convert back cpu server analyze results hour stop server keep data gb month storage costs start server back train next workload celebrate launch us free credit yes sound cheap need get started us hours compute time cheapest configuration use code reddit _ billing page redeem free credit deploy gpu https answer questions post,"['tensordock', 'core', 'gpu', 'cloud', 'gpu', 'servers', 'hrhello', 'r', 'machinelearning', 'jonathan', 'tensordock', 'months', 'beta', 'finally', 'launching', 'core', 'cloud', 'platform', 'deploy', 'gpu', 'virtual', 'machines', 'little', 'seconds', 'think', 'guys', 'would', 'find', 'nice', 'alternative', 'clouds', 'train', 'ml', 'models', 'https', 'training', 'machine', 'learning', 'workloads', 'large', 'clouds', 'extremely', 'expensive', 'left', 'us', 'wondering', 'cloud', 'ever', 'become', 'expensive', 'prem', 'seen', 'many', 'ml', 'startups', 'buy', 'hardware', 'cheaper', 'dedicated', 'servers', 'nvidia', 'gpus', 'hard', 'find', 'lack', 'functionality', 'scalability', 'big', 'clouds', 'thought', 'built', 'platform', 'combines', 'functionality', 'large', 'clouds', 'made', 'priced', 'somewhere', 'dedicated', 'server', 'large', 'clouds', 'exactly', 'done', 'built', 'make', 'engineers', 'productive', 'machine', 'learning', 'images', 'start', 'training', 'ml', 'models', 'minutes', 'hours', 'provide', 'rest', 'api', 'integrate', 'directly', 'code', 'also', 'community', 'cli', 'use', 'manage', 'servers', 'directly', 'via', 'command', 'line', 'feature', 'set', 'large', 'clouds', 'match', 'storage', 'billing', 'vm', 'stopped', 'gb', 'month', 'edit', 'virtual', 'machines', 'created', 'downsize', 'costs', 'provision', 'nvidia', 'find', 'using', 'stop', 'vm', 'modify', 'nvidia', 'billed', 'lower', 'hourly', 'rate', 'without', 'needing', 'recreate', 'server', 'migrate', 'data', 'x', 'replicated', 'nvme', 'based', 'network', 'storage', 'seriously', 'fast', 'gbps', 'networking', 'locations', 'york', 'chicago', 'las', 'vegas', 'coming', 'soon', 'alerts', 'billing', 'billing', 'pro', 'rated', 'minute', 'cheap', 'cpu', 'servers', 'hour', 'nvidia', 'quadro', 'rtx', 'hour', 'nvidia', 'tesla', 'vs', 'hour', 'gpu', 'types', 'let', 'truly', 'right', 'size', 'workloads', 'never', 'paying', 'actually', 'needexample', 'use', 'case', 'spin', 'cpu', 'server', 'hour', 'upload', 'data', 'convert', 'gpu', 'server', 'train', 'ml', 'workload', 'hour', 'convert', 'back', 'cpu', 'server', 'analyze', 'results', 'hour', 'stop', 'server', 'keep', 'data', 'gb', 'month', 'storage', 'costs', 'start', 'server', 'back', 'train', 'next', 'workload', 'celebrate', 'launch', 'us', 'free', 'credit', 'yes', 'sound', 'cheap', 'need', 'get', 'started', 'us', 'hours', 'compute', 'time', 'cheapest', 'configuration', 'use', 'code', 'reddit', '_', 'billing', 'page', 'redeem', 'free', 'credit', 'deploy', 'gpu', 'https', 'answer', 'questions', 'post']","['tensordock', 'core', 'gpu', 'cloud', 'gpu', 'server', 'hrhello', 'r', 'machinelearn', 'jonathan', 'tensordock', 'month', 'beta', 'final', 'launch', 'core', 'cloud', 'platform', 'deploy', 'gpu', 'virtual', 'machin', 'littl', 'second', 'think', 'guy', 'would', 'find', 'nice', 'altern', 'cloud', 'train', 'ml', 'model', 'http', 'train', 'machin', 'learn', 'workload', 'larg', 'cloud', 'extrem', 'expens', 'left', 'us', 'wonder', 'cloud', 'ever', 'becom', 'expens', 'prem', 'seen', 'mani', 'ml', 'startup', 'buy', 'hardwar', 'cheaper', 'dedic', 'server', 'nvidia', 'gpu', 'hard', 'find', 'lack', 'function', 'scalabl', 'big', 'cloud', 'thought', 'built', 'platform', 'combin', 'function', 'larg', 'cloud', 'made', 'price', 'somewher', 'dedic', 'server', 'larg', 'cloud', 'exactli', 'done', 'built', 'make', 'engin', 'product', 'machin', 'learn', 'imag', 'start', 'train', 'ml', 'model', 'minut', 'hour', 'provid', 'rest', 'api', 'integr', 'directli', 'code', 'also', 'commun', 'cli', 'use', 'manag', 'server', 'directli', 'via', 'command', 'line', 'featur', 'set', 'larg', 'cloud', 'match', 'storag', 'bill', 'vm', 'stop', 'gb', 'month', 'edit', 'virtual', 'machin', 'creat', 'downsiz', 'cost', 'provis', 'nvidia', 'find', 'use', 'stop', 'vm', 'modifi', 'nvidia', 'bill', 'lower', 'hourli', 'rate', 'without', 'need', 'recreat', 'server', 'migrat', 'data', 'x', 'replic', 'nvme', 'base', 'network', 'storag', 'serious', 'fast', 'gbp', 'network', 'locat', 'york', 'chicago', 'la', 'vega', 'come', 'soon', 'alert', 'bill', 'bill', 'pro', 'rate', 'minut', 'cheap', 'cpu', 'server', 'hour', 'nvidia', 'quadro', 'rtx', 'hour', 'nvidia', 'tesla', 'vs', 'hour', 'gpu', 'type', 'let', 'truli', 'right', 'size', 'workload', 'never', 'pay', 'actual', 'needexampl', 'use', 'case', 'spin', 'cpu', 'server', 'hour', 'upload', 'data', 'convert', 'gpu', 'server', 'train', 'ml', 'workload', 'hour', 'convert', 'back', 'cpu', 'server', 'analyz', 'result', 'hour', 'stop', 'server', 'keep', 'data', 'gb', 'month', 'storag', 'cost', 'start', 'server', 'back', 'train', 'next', 'workload', 'celebr', 'launch', 'us', 'free', 'credit', 'ye', 'sound', 'cheap', 'need', 'get', 'start', 'us', 'hour', 'comput', 'time', 'cheapest', 'configur', 'use', 'code', 'reddit', '_', 'bill', 'page', 'redeem', 'free', 'credit', 'deploy', 'gpu', 'http', 'answer', 'question', 'post']"
26,31,31,cream_crundle,wav15e,"[D] Seeking Advice - For graph ML, Neo4j or nah?","Believe my concerns are fairly general so would appreciate general opinions as well as expert advice, if such is forthcoming.

I'm working on a project to implement a knowledge graph, and the important requirements are:

1. Every node needs an embedding
2. The graph needs to be persistent, because people are adding things to it fairly regularly.
3. The graph is going to ingest data constantly
4. The graph needs to be updating embeddings, inferring connections and missing properties, pretty much constantly in the background
5. In short, the graph needs to be be able to prune, expand, and self-maintain based on the output of integrated ML systems.

So scability and efficiency (Especially for queries and retrieval and such) is going to be a problem, but I have some ideas about how to deal with it.

The main concern is whether to make my own graph data structure, or to use an existing framework that already incorporates some Graph ML and DB functionality, such as neo4j.

The issue is that this KG is going to be fairly domain and organization specific, and there will be optimizations and changes which I would like to be able to make at a fairly low-level.

A bigger concern is that there is a logical barrier between neo4j's Java backend, and pyTorch/native Python, which might inhibit the potential for customization, optimization, and experimentation with new or speculative GNN algorithms. There is the concern that yes, neo4j does have a graph ML package. On the other hand, how easy will it be to modify the contents of those packages as needed?

This is particularly critical since the KG is eventually intended to perform some fairly novel functions and objectives which I decline to go into.

I understand that neo4j tends to experience criticism for:

* its bulkiness - I will only ever need a small subset of its features, and would prefer a lightweight framework on principle, especially due to the persistence and scalability concerns.
* Somewhat unpredictable efficiency - neo4j struggles performance-wise with more complex queries that traverse longer paths.
* The complexity of CypherQuery, which, by being both expressive and general, tends to lead to a lot of fuckups by people who are not intimately familiar with it. This is a problem because non-specialists are expected to be able to use it conveniently. 

On the other hand, there is lots of documentation, a fairly large community, integrated security and robustness infrastructure, and support. Much of the groundwork has already been done.

Writing my own graph data structure, with its own infrastructure, would sidestep a lot of my concerns, at the cost of labor, effort, and potential duplication of issues that have already been addressed. The basic theory is not too much of a concern, since I am well-acquainted with both GNN and graph theory.

It is more concerns of engineering convenience and scalability in the (very) long-term.

Would appreciate any thoughts on the matter.",12,26,2022-07-29 07:24:23, d  seeking advice   for graph ml  neoj or nah ,believe my concerns are fairly general so would appreciate general opinions as well as expert advice  if such is forthcoming i m working on a project to implement a knowledge graph  and the important requirements are   every node needs an embedding  the graph needs to be persistent  because people are adding things to it fairly regularly   the graph is going to ingest data constantly  the graph needs to be updating embeddings  inferring connections and missing properties  pretty much constantly in the background  in short  the graph needs to be be able to prune  expand  and self maintain based on the output of integrated ml systems so scability and efficiency  especially for queries and retrieval and such  is going to be a problem  but i have some ideas about how to deal with it the main concern is whether to make my own graph data structure  or to use an existing framework that already incorporates some graph ml and db functionality  such as neoj the issue is that this kg is going to be fairly domain and organization specific  and there will be optimizations and changes which i would like to be able to make at a fairly low level a bigger concern is that there is a logical barrier between neoj s java backend  and pytorch native python  which might inhibit the potential for customization  optimization  and experimentation with new or speculative gnn algorithms  there is the concern that yes  neoj does have a graph ml package  on the other hand  how easy will it be to modify the contents of those packages as needed this is particularly critical since the kg is eventually intended to perform some fairly novel functions and objectives which i decline to go into i understand that neoj tends to experience criticism for   its bulkiness   i will only ever need a small subset of its features  and would prefer a lightweight framework on principle  especially due to the persistence and scalability concerns   somewhat unpredictable efficiency   neoj struggles performance wise with more complex queries that traverse longer paths   the complexity of cypherquery  which  by being both expressive and general  tends to lead to a lot of fuckups by people who are not intimately familiar with it  this is a problem because non specialists are expected to be able to use it conveniently  on the other hand  there is lots of documentation  a fairly large community  integrated security and robustness infrastructure  and support  much of the groundwork has already been done writing my own graph data structure  with its own infrastructure  would sidestep a lot of my concerns  at the cost of labor  effort  and potential duplication of issues that have already been addressed  the basic theory is not too much of a concern  since i am well acquainted with both gnn and graph theory it is more concerns of engineering convenience and scalability in the  very  long term would appreciate any thoughts on the matter ,believe concerns fairly general would appreciate general opinions well expert advice forthcoming working project implement knowledge graph important requirements every node needs embedding graph needs persistent people adding things fairly regularly graph going ingest data constantly graph needs updating embeddings inferring connections missing properties pretty much constantly background short graph needs able prune expand self maintain based output integrated ml systems scability efficiency especially queries retrieval going problem ideas deal main concern whether make graph data structure use existing framework already incorporates graph ml db functionality neoj issue kg going fairly domain organization specific optimizations changes would like able make fairly low level bigger concern logical barrier neoj java backend pytorch native python might inhibit potential customization optimization experimentation speculative gnn algorithms concern yes neoj graph ml package hand easy modify contents packages needed particularly critical since kg eventually intended perform fairly novel functions objectives decline go understand neoj tends experience criticism bulkiness ever need small subset features would prefer lightweight framework principle especially due persistence scalability concerns somewhat unpredictable efficiency neoj struggles performance wise complex queries traverse longer paths complexity cypherquery expressive general tends lead lot fuckups people intimately familiar problem non specialists expected able use conveniently hand lots documentation fairly large community integrated security robustness infrastructure support much groundwork already done writing graph data structure infrastructure would sidestep lot concerns cost labor effort potential duplication issues already addressed basic theory much concern since well acquainted gnn graph theory concerns engineering convenience scalability long term would appreciate thoughts matter,seeking advice graph ml neoj nah,seeking advice graph ml neoj nahbelieve concerns fairly general would appreciate general opinions well expert advice forthcoming working project implement knowledge graph important requirements every node needs embedding graph needs persistent people adding things fairly regularly graph going ingest data constantly graph needs updating embeddings inferring connections missing properties pretty much constantly background short graph needs able prune expand self maintain based output integrated ml systems scability efficiency especially queries retrieval going problem ideas deal main concern whether make graph data structure use existing framework already incorporates graph ml db functionality neoj issue kg going fairly domain organization specific optimizations changes would like able make fairly low level bigger concern logical barrier neoj java backend pytorch native python might inhibit potential customization optimization experimentation speculative gnn algorithms concern yes neoj graph ml package hand easy modify contents packages needed particularly critical since kg eventually intended perform fairly novel functions objectives decline go understand neoj tends experience criticism bulkiness ever need small subset features would prefer lightweight framework principle especially due persistence scalability concerns somewhat unpredictable efficiency neoj struggles performance wise complex queries traverse longer paths complexity cypherquery expressive general tends lead lot fuckups people intimately familiar problem non specialists expected able use conveniently hand lots documentation fairly large community integrated security robustness infrastructure support much groundwork already done writing graph data structure infrastructure would sidestep lot concerns cost labor effort potential duplication issues already addressed basic theory much concern since well acquainted gnn graph theory concerns engineering convenience scalability long term would appreciate thoughts matter,"['seeking', 'advice', 'graph', 'ml', 'neoj', 'nahbelieve', 'concerns', 'fairly', 'general', 'would', 'appreciate', 'general', 'opinions', 'well', 'expert', 'advice', 'forthcoming', 'working', 'project', 'implement', 'knowledge', 'graph', 'important', 'requirements', 'every', 'node', 'needs', 'embedding', 'graph', 'needs', 'persistent', 'people', 'adding', 'things', 'fairly', 'regularly', 'graph', 'going', 'ingest', 'data', 'constantly', 'graph', 'needs', 'updating', 'embeddings', 'inferring', 'connections', 'missing', 'properties', 'pretty', 'much', 'constantly', 'background', 'short', 'graph', 'needs', 'able', 'prune', 'expand', 'self', 'maintain', 'based', 'output', 'integrated', 'ml', 'systems', 'scability', 'efficiency', 'especially', 'queries', 'retrieval', 'going', 'problem', 'ideas', 'deal', 'main', 'concern', 'whether', 'make', 'graph', 'data', 'structure', 'use', 'existing', 'framework', 'already', 'incorporates', 'graph', 'ml', 'db', 'functionality', 'neoj', 'issue', 'kg', 'going', 'fairly', 'domain', 'organization', 'specific', 'optimizations', 'changes', 'would', 'like', 'able', 'make', 'fairly', 'low', 'level', 'bigger', 'concern', 'logical', 'barrier', 'neoj', 'java', 'backend', 'pytorch', 'native', 'python', 'might', 'inhibit', 'potential', 'customization', 'optimization', 'experimentation', 'speculative', 'gnn', 'algorithms', 'concern', 'yes', 'neoj', 'graph', 'ml', 'package', 'hand', 'easy', 'modify', 'contents', 'packages', 'needed', 'particularly', 'critical', 'since', 'kg', 'eventually', 'intended', 'perform', 'fairly', 'novel', 'functions', 'objectives', 'decline', 'go', 'understand', 'neoj', 'tends', 'experience', 'criticism', 'bulkiness', 'ever', 'need', 'small', 'subset', 'features', 'would', 'prefer', 'lightweight', 'framework', 'principle', 'especially', 'due', 'persistence', 'scalability', 'concerns', 'somewhat', 'unpredictable', 'efficiency', 'neoj', 'struggles', 'performance', 'wise', 'complex', 'queries', 'traverse', 'longer', 'paths', 'complexity', 'cypherquery', 'expressive', 'general', 'tends', 'lead', 'lot', 'fuckups', 'people', 'intimately', 'familiar', 'problem', 'non', 'specialists', 'expected', 'able', 'use', 'conveniently', 'hand', 'lots', 'documentation', 'fairly', 'large', 'community', 'integrated', 'security', 'robustness', 'infrastructure', 'support', 'much', 'groundwork', 'already', 'done', 'writing', 'graph', 'data', 'structure', 'infrastructure', 'would', 'sidestep', 'lot', 'concerns', 'cost', 'labor', 'effort', 'potential', 'duplication', 'issues', 'already', 'addressed', 'basic', 'theory', 'much', 'concern', 'since', 'well', 'acquainted', 'gnn', 'graph', 'theory', 'concerns', 'engineering', 'convenience', 'scalability', 'long', 'term', 'would', 'appreciate', 'thoughts', 'matter']","['seek', 'advic', 'graph', 'ml', 'neoj', 'nahbeliev', 'concern', 'fairli', 'gener', 'would', 'appreci', 'gener', 'opinion', 'well', 'expert', 'advic', 'forthcom', 'work', 'project', 'implement', 'knowledg', 'graph', 'import', 'requir', 'everi', 'node', 'need', 'embed', 'graph', 'need', 'persist', 'peopl', 'ad', 'thing', 'fairli', 'regularli', 'graph', 'go', 'ingest', 'data', 'constantli', 'graph', 'need', 'updat', 'embed', 'infer', 'connect', 'miss', 'properti', 'pretti', 'much', 'constantli', 'background', 'short', 'graph', 'need', 'abl', 'prune', 'expand', 'self', 'maintain', 'base', 'output', 'integr', 'ml', 'system', 'scabil', 'effici', 'especi', 'queri', 'retriev', 'go', 'problem', 'idea', 'deal', 'main', 'concern', 'whether', 'make', 'graph', 'data', 'structur', 'use', 'exist', 'framework', 'alreadi', 'incorpor', 'graph', 'ml', 'db', 'function', 'neoj', 'issu', 'kg', 'go', 'fairli', 'domain', 'organ', 'specif', 'optim', 'chang', 'would', 'like', 'abl', 'make', 'fairli', 'low', 'level', 'bigger', 'concern', 'logic', 'barrier', 'neoj', 'java', 'backend', 'pytorch', 'nativ', 'python', 'might', 'inhibit', 'potenti', 'custom', 'optim', 'experiment', 'specul', 'gnn', 'algorithm', 'concern', 'ye', 'neoj', 'graph', 'ml', 'packag', 'hand', 'easi', 'modifi', 'content', 'packag', 'need', 'particularli', 'critic', 'sinc', 'kg', 'eventu', 'intend', 'perform', 'fairli', 'novel', 'function', 'object', 'declin', 'go', 'understand', 'neoj', 'tend', 'experi', 'critic', 'bulki', 'ever', 'need', 'small', 'subset', 'featur', 'would', 'prefer', 'lightweight', 'framework', 'principl', 'especi', 'due', 'persist', 'scalabl', 'concern', 'somewhat', 'unpredict', 'effici', 'neoj', 'struggl', 'perform', 'wise', 'complex', 'queri', 'travers', 'longer', 'path', 'complex', 'cypherqueri', 'express', 'gener', 'tend', 'lead', 'lot', 'fuckup', 'peopl', 'intim', 'familiar', 'problem', 'non', 'specialist', 'expect', 'abl', 'use', 'conveni', 'hand', 'lot', 'document', 'fairli', 'larg', 'commun', 'integr', 'secur', 'robust', 'infrastructur', 'support', 'much', 'groundwork', 'alreadi', 'done', 'write', 'graph', 'data', 'structur', 'infrastructur', 'would', 'sidestep', 'lot', 'concern', 'cost', 'labor', 'effort', 'potenti', 'duplic', 'issu', 'alreadi', 'address', 'basic', 'theori', 'much', 'concern', 'sinc', 'well', 'acquaint', 'gnn', 'graph', 'theori', 'concern', 'engin', 'conveni', 'scalabl', 'long', 'term', 'would', 'appreci', 'thought', 'matter']"
27,32,32,rezayazdanfar,wbbrnl,[D] How To Make STGNNsCapable of Forecasting Long-term Multivariate Time Series Data?,"I've just published my recent medium article in Towards AI publication. 

Time Series Forecasting (TSF) data is vital in all industries, from Energy to Healthcare. Researchers have achieved some significant advances through the development of TFS models. By thoroughly considering patterns and their relationships for time series, analysis based on long-dependencies in the dataset is a must. This article is about designing a new model based on another model to perform on long-dependencies and produced segment-level representations. This model stands on STEP, an abbreviation of STGNN (Spatial-Temporal Graph Neural Networks) + Enhanced + Pre-training model. 

Please give it a read and let me know your feedback. If you found it interesting, I would appreciate following me in the medium.


https://pub.towardsai.net/how-to-make-stgnnscapable-of-forecasting-long-term-multivariate-time-series-data-9fe5efd77fa1",2,2,2022-07-29 21:12:52, d  how to make stgnnscapable of forecasting long term multivariate time series data ,i ve just published my recent medium article in towards ai publication  time series forecasting  tsf  data is vital in all industries  from energy to healthcare  researchers have achieved some significant advances through the development of tfs models  by thoroughly considering patterns and their relationships for time series  analysis based on long dependencies in the dataset is a must  this article is about designing a new model based on another model to perform on long dependencies and produced segment level representations  this model stands on step  an abbreviation of stgnn  spatial temporal graph neural networks    enhanced   pre training model  please give it a read and let me know your feedback  if you found it interesting  i would appreciate following me in the medium https   pub towardsai net how to make stgnnscapable of forecasting long term multivariate time series data feefdfa,published recent medium article towards ai publication time series forecasting tsf data vital industries energy healthcare researchers achieved significant advances development tfs models thoroughly considering patterns relationships time series analysis based long dependencies dataset must article designing model based another model perform long dependencies produced segment level representations model stands step abbreviation stgnn spatial temporal graph neural networks enhanced pre training model please give read let know feedback found interesting would appreciate following medium https pub towardsai net make stgnnscapable forecasting long term multivariate time series data feefdfa,make stgnnscapable forecasting long term multivariate time series data,make stgnnscapable forecasting long term multivariate time series datapublished recent medium article towards ai publication time series forecasting tsf data vital industries energy healthcare researchers achieved significant advances development tfs models thoroughly considering patterns relationships time series analysis based long dependencies dataset must article designing model based another model perform long dependencies produced segment level representations model stands step abbreviation stgnn spatial temporal graph neural networks enhanced pre training model please give read let know feedback found interesting would appreciate following medium https pub towardsai net make stgnnscapable forecasting long term multivariate time series data feefdfa,"['make', 'stgnnscapable', 'forecasting', 'long', 'term', 'multivariate', 'time', 'series', 'datapublished', 'recent', 'medium', 'article', 'towards', 'ai', 'publication', 'time', 'series', 'forecasting', 'tsf', 'data', 'vital', 'industries', 'energy', 'healthcare', 'researchers', 'achieved', 'significant', 'advances', 'development', 'tfs', 'models', 'thoroughly', 'considering', 'patterns', 'relationships', 'time', 'series', 'analysis', 'based', 'long', 'dependencies', 'dataset', 'must', 'article', 'designing', 'model', 'based', 'another', 'model', 'perform', 'long', 'dependencies', 'produced', 'segment', 'level', 'representations', 'model', 'stands', 'step', 'abbreviation', 'stgnn', 'spatial', 'temporal', 'graph', 'neural', 'networks', 'enhanced', 'pre', 'training', 'model', 'please', 'give', 'read', 'let', 'know', 'feedback', 'found', 'interesting', 'would', 'appreciate', 'following', 'medium', 'https', 'pub', 'towardsai', 'net', 'make', 'stgnnscapable', 'forecasting', 'long', 'term', 'multivariate', 'time', 'series', 'data', 'feefdfa']","['make', 'stgnnscapabl', 'forecast', 'long', 'term', 'multivari', 'time', 'seri', 'datapublish', 'recent', 'medium', 'articl', 'toward', 'ai', 'public', 'time', 'seri', 'forecast', 'tsf', 'data', 'vital', 'industri', 'energi', 'healthcar', 'research', 'achiev', 'signific', 'advanc', 'develop', 'tf', 'model', 'thoroughli', 'consid', 'pattern', 'relationship', 'time', 'seri', 'analysi', 'base', 'long', 'depend', 'dataset', 'must', 'articl', 'design', 'model', 'base', 'anoth', 'model', 'perform', 'long', 'depend', 'produc', 'segment', 'level', 'represent', 'model', 'stand', 'step', 'abbrevi', 'stgnn', 'spatial', 'tempor', 'graph', 'neural', 'network', 'enhanc', 'pre', 'train', 'model', 'pleas', 'give', 'read', 'let', 'know', 'feedback', 'found', 'interest', 'would', 'appreci', 'follow', 'medium', 'http', 'pub', 'towardsai', 'net', 'make', 'stgnnscapabl', 'forecast', 'long', 'term', 'multivari', 'time', 'seri', 'data', 'feefdfa']"
28,33,33,massagetae,waszxn,[D] Is it possible to get into an ML PhD program without papers these days?,"Sorry, if you've seen a similar question before somewhere. I'm a FAANG ML engineer. I only have a Masters in CS (no thesis) and one third author paper in Robotics (from Bachelors). Didn't end up publishing in Masters due to various reasons. Also, didn't do PhD (kept thinking over whether I'd be accepted or not and didn't apply). I've been trying to get into ML research. I want to work on original ideas and not just implement known stuff. I'm trying to transfer internally to some research role but finding it very difficult. Even research engineer roles seem to ask for first-author papers or something (or maybe it's the recession or maybe I don't have the right connections). Keep thinking about if I should press the PhD application button but get demoralized due to my poor research experience. Just wanted to put my dilemma to rest by asking this group.",22,27,2022-07-29 05:42:53, d  is it possible to get into an ml phd program without papers these days ,sorry  if you ve seen a similar question before somewhere  i m a faang ml engineer  i only have a masters in cs  no thesis  and one third author paper in robotics  from bachelors   didn t end up publishing in masters due to various reasons  also  didn t do phd  kept thinking over whether i d be accepted or not and didn t apply   i ve been trying to get into ml research  i want to work on original ideas and not just implement known stuff  i m trying to transfer internally to some research role but finding it very difficult  even research engineer roles seem to ask for first author papers or something  or maybe it s the recession or maybe i don t have the right connections   keep thinking about if i should press the phd application button but get demoralized due to my poor research experience  just wanted to put my dilemma to rest by asking this group ,sorry seen similar question somewhere faang ml engineer masters cs thesis one third author paper robotics bachelors end publishing masters due various reasons also phd kept thinking whether accepted apply trying get ml research want work original ideas implement known stuff trying transfer internally research role finding difficult even research engineer roles seem ask first author papers something maybe recession maybe right connections keep thinking press phd application button get demoralized due poor research experience wanted put dilemma rest asking group,possible get ml phd program without papers days,possible get ml phd program without papers dayssorry seen similar question somewhere faang ml engineer masters cs thesis one third author paper robotics bachelors end publishing masters due various reasons also phd kept thinking whether accepted apply trying get ml research want work original ideas implement known stuff trying transfer internally research role finding difficult even research engineer roles seem ask first author papers something maybe recession maybe right connections keep thinking press phd application button get demoralized due poor research experience wanted put dilemma rest asking group,"['possible', 'get', 'ml', 'phd', 'program', 'without', 'papers', 'dayssorry', 'seen', 'similar', 'question', 'somewhere', 'faang', 'ml', 'engineer', 'masters', 'cs', 'thesis', 'one', 'third', 'author', 'paper', 'robotics', 'bachelors', 'end', 'publishing', 'masters', 'due', 'various', 'reasons', 'also', 'phd', 'kept', 'thinking', 'whether', 'accepted', 'apply', 'trying', 'get', 'ml', 'research', 'want', 'work', 'original', 'ideas', 'implement', 'known', 'stuff', 'trying', 'transfer', 'internally', 'research', 'role', 'finding', 'difficult', 'even', 'research', 'engineer', 'roles', 'seem', 'ask', 'first', 'author', 'papers', 'something', 'maybe', 'recession', 'maybe', 'right', 'connections', 'keep', 'thinking', 'press', 'phd', 'application', 'button', 'get', 'demoralized', 'due', 'poor', 'research', 'experience', 'wanted', 'put', 'dilemma', 'rest', 'asking', 'group']","['possibl', 'get', 'ml', 'phd', 'program', 'without', 'paper', 'dayssorri', 'seen', 'similar', 'question', 'somewher', 'faang', 'ml', 'engin', 'master', 'cs', 'thesi', 'one', 'third', 'author', 'paper', 'robot', 'bachelor', 'end', 'publish', 'master', 'due', 'variou', 'reason', 'also', 'phd', 'kept', 'think', 'whether', 'accept', 'appli', 'tri', 'get', 'ml', 'research', 'want', 'work', 'origin', 'idea', 'implement', 'known', 'stuff', 'tri', 'transfer', 'intern', 'research', 'role', 'find', 'difficult', 'even', 'research', 'engin', 'role', 'seem', 'ask', 'first', 'author', 'paper', 'someth', 'mayb', 'recess', 'mayb', 'right', 'connect', 'keep', 'think', 'press', 'phd', 'applic', 'button', 'get', 'demor', 'due', 'poor', 'research', 'experi', 'want', 'put', 'dilemma', 'rest', 'ask', 'group']"
29,34,34,Spiritual-Reply5896,wb12ox,[D] Object detection dataset construction and its diversity,"Hey,

I've been trying to look in to explainable deep learning models in object detection and in image recognition in general. Firstly, I feel like the diversity of training data distribution is highly important for the generalization purposes, such that we capture various different views of the wanted object. Later we can augment these views, but this raises problem from image collection point of view. I feel like the explainability of deep learning models could be viewed more clearly, when we can control one variable - the data collection.

However, I can't find any research on collecting such data - like how to collect as little data as possible, while maximizing the diversity of generalization. Kind of like sample efficiency, but instead of finding the optimal classifier we try to find the optimal images to create generalizable representations of the said object from images.

Does anyone have good keywords or know some research that could work as a starting point?",2,3,2022-07-29 13:19:31, d  object detection dataset construction and its diversity,hey i ve been trying to look in to explainable deep learning models in object detection and in image recognition in general  firstly  i feel like the diversity of training data distribution is highly important for the generalization purposes  such that we capture various different views of the wanted object  later we can augment these views  but this raises problem from image collection point of view  i feel like the explainability of deep learning models could be viewed more clearly  when we can control one variable   the data collection however  i can t find any research on collecting such data   like how to collect as little data as possible  while maximizing the diversity of generalization  kind of like sample efficiency  but instead of finding the optimal classifier we try to find the optimal images to create generalizable representations of the said object from images does anyone have good keywords or know some research that could work as a starting point ,hey trying look explainable deep learning models object detection image recognition general firstly feel like diversity training data distribution highly important generalization purposes capture various different views wanted object later augment views raises problem image collection point view feel like explainability deep learning models could viewed clearly control one variable data collection however find research collecting data like collect little data possible maximizing diversity generalization kind like sample efficiency instead finding optimal classifier try find optimal images create generalizable representations said object images anyone good keywords know research could work starting point,object detection dataset construction diversity,object detection dataset construction diversityhey trying look explainable deep learning models object detection image recognition general firstly feel like diversity training data distribution highly important generalization purposes capture various different views wanted object later augment views raises problem image collection point view feel like explainability deep learning models could viewed clearly control one variable data collection however find research collecting data like collect little data possible maximizing diversity generalization kind like sample efficiency instead finding optimal classifier try find optimal images create generalizable representations said object images anyone good keywords know research could work starting point,"['object', 'detection', 'dataset', 'construction', 'diversityhey', 'trying', 'look', 'explainable', 'deep', 'learning', 'models', 'object', 'detection', 'image', 'recognition', 'general', 'firstly', 'feel', 'like', 'diversity', 'training', 'data', 'distribution', 'highly', 'important', 'generalization', 'purposes', 'capture', 'various', 'different', 'views', 'wanted', 'object', 'later', 'augment', 'views', 'raises', 'problem', 'image', 'collection', 'point', 'view', 'feel', 'like', 'explainability', 'deep', 'learning', 'models', 'could', 'viewed', 'clearly', 'control', 'one', 'variable', 'data', 'collection', 'however', 'find', 'research', 'collecting', 'data', 'like', 'collect', 'little', 'data', 'possible', 'maximizing', 'diversity', 'generalization', 'kind', 'like', 'sample', 'efficiency', 'instead', 'finding', 'optimal', 'classifier', 'try', 'find', 'optimal', 'images', 'create', 'generalizable', 'representations', 'said', 'object', 'images', 'anyone', 'good', 'keywords', 'know', 'research', 'could', 'work', 'starting', 'point']","['object', 'detect', 'dataset', 'construct', 'diversityhey', 'tri', 'look', 'explain', 'deep', 'learn', 'model', 'object', 'detect', 'imag', 'recognit', 'gener', 'firstli', 'feel', 'like', 'divers', 'train', 'data', 'distribut', 'highli', 'import', 'gener', 'purpos', 'captur', 'variou', 'differ', 'view', 'want', 'object', 'later', 'augment', 'view', 'rais', 'problem', 'imag', 'collect', 'point', 'view', 'feel', 'like', 'explain', 'deep', 'learn', 'model', 'could', 'view', 'clearli', 'control', 'one', 'variabl', 'data', 'collect', 'howev', 'find', 'research', 'collect', 'data', 'like', 'collect', 'littl', 'data', 'possibl', 'maxim', 'divers', 'gener', 'kind', 'like', 'sampl', 'effici', 'instead', 'find', 'optim', 'classifi', 'tri', 'find', 'optim', 'imag', 'creat', 'generaliz', 'represent', 'said', 'object', 'imag', 'anyon', 'good', 'keyword', 'know', 'research', 'could', 'work', 'start', 'point']"
30,35,35,Jeannetton,wb598m,[Research] Anyone experienced using Transkribus?,"Hi all, I have a couple questions regarding the Handwritten text recognition software Transkribus. Anyone experienced using it?",1,1,2022-07-29 16:46:06, research  anyone experienced using transkribus ,hi all  i have a couple questions regarding the handwritten text recognition software transkribus  anyone experienced using it ,hi couple questions regarding handwritten text recognition software transkribus anyone experienced using,research anyone experienced using transkribus,research anyone experienced using transkribushi couple questions regarding handwritten text recognition software transkribus anyone experienced using,"['research', 'anyone', 'experienced', 'using', 'transkribushi', 'couple', 'questions', 'regarding', 'handwritten', 'text', 'recognition', 'software', 'transkribus', 'anyone', 'experienced', 'using']","['research', 'anyon', 'experienc', 'use', 'transkribushi', 'coupl', 'question', 'regard', 'handwritten', 'text', 'recognit', 'softwar', 'transkribu', 'anyon', 'experienc', 'use']"
31,36,36,Shoddy_Change_6559,wa3sxu,[R] Ten Lessons of Implementing Recommendation Systems in Business,"FunCorp data science team has been long working on improving the user experience with machine learning.  We've picked out key takeaways of that process. Following this article's advice, you will avoid a lot of mistakes when creating a recommendation system for your product.

# 1. Define a Goal that Really Contributes to the Business Tasks

The global task of the recommendation system is to select a shortlist of content from a large catalog that is most suitable for a particular user. The content itself can be different — from products in the online store and articles to banking services. FunCorp product team works with the most interesting kind of content — we recommend memes.

To do this, we rely on the history of the user’s interaction with the service. But “good recommendations” from a user perspective and from a business perspective are not always the same thing. For example, we found that increasing the number of likes that a user clicks thanks to more accurate recommendations does not affect retention, a metric that is important for our business. So we started focusing on models that optimize time spent in the app instead of likes.

That’s why it’s so important to focus on the most important goal for your business. Goals can be different, for example:

* user retention,
* increased revenue,
* cost reduction,
* and so on.

The recommendation system will surely allow you to improve the user experience, and the user will take the targeted action faster and/or more often. What remains to be done is to make sure that you reach your business goals at the same time. Win-win! In our case, we saw a 25% increase in the relative number of smiles (likes) and an almost 40% increase in the viewing depth as a result of implementing a [recommendation system in our feed](https://medium.com/@FunCorp/putting-a-two-layered-recommendation-system-into-production-b8caaf61393d).

Main goal in iFunny is to increase retention and you can see that sometimes we run experiments with a very destructive influence on retention.

&#x200B;

https://preview.redd.it/c3jesrsgl9e91.png?width=700&format=png&auto=webp&s=49b24337974effa5e63b1ee4b9708711a411e690

&#x200B;

# 2. Find the Optimal User Touchpoint in the Product

When you’ve decided on the global goal, you need to figure out what is the best way to display recommendations:

* in the feed — this is relevant for news sites or entertainment apps like our iFunny,
* push notifications,
* email newsletter,
* the section with personalized offers in a personal account,
* or other sections on the site/application.

Many factors influence the choice of touchpoint — for example, the share of DAU in this point (for some users, push notifications may be disabled) or the complexity of integration with ML microservice.

In our case, an ineffective choice might look like this. The iFunny app has an Explore section where we collect a selection of the best memes of the week. One can collect such selections with ML, but only small amount of DAUs go to this section.

&#x200B;

https://preview.redd.it/srpxyzisl9e91.png?width=700&format=png&auto=webp&s=d9a5a4589868aa825c59355e73ab2e7521adc9d1

Using ML at this point is impractical.

The main rule here is to integrate ML where it will make the biggest increase in business metrics. Therefore, in the case of FunCorp we, first of all, decided to implement ML in the feed, because it is seen by the maximum number of users. And secondly, we started to create the recommendation system for the push notifications — because there is a noticeable, but still a smaller volume of the audience interacting with them.

# 3. Collect As Much Diverse Feedback From Users As Possible

In our case, feedback is the actions a user can take to demonstrate how they feel about the content in the app. To build a recommendation system, you need to learn how to collect different types of feedback:

**Explicit** — this can be a rating by any scale or a like/dislike.

And **implicit**:

* the amount of time a user spends on the content,
* the number of visits to the content page,
* the number of times one shares the content on social networks or sends it to friends.

Feedback should correlate with the business goals of the recommendation system. For example, if the goal is to reduce churn, it is reasonable to add a feedback form and show it to users who unsubscribe from the service.

**Here are some important technical points you need to consider:**

* Make it possible to expand user feedback channels. For example, in addition to the time spent on the page, you can start collecting user comments and determining their tone. Positive comments will tell you that you need more of this kind of content. And vice versa.
* Keep a history of user feedback for a long time — at least several months. This is necessary for two purposes. First, the more data you have when training the recommendation system model, the better the model will be — you will be able to identify insights in long-term users’ behavior. Second, a large amount of historical data will allow us to compare models without running AB tests, in an offline format.
* You need a data quality control system. Real case: when we started collecting statistics on the time of viewing content and training the model using this data, we found out in the process that the data was collected from the iOS platform only. On Android, the feature had not been implemented. That is, we expected personalization to improve, but didn’t have data for the whole platform.

Don’t forget about the limitations of channels. For example, only 30–40% of users give feedback using likes. And if you build the recommendation system only on likes, then 60–70% of the audience will receive non-personalized dropout. So the more different channels of user feedback you have, the better.

In iFunny we have only 50% of users with explicit feedback, so we need to develop models with implicit feedback to improve our metrics.

&#x200B;

https://preview.redd.it/dras58n5m9e91.png?width=700&format=png&auto=webp&s=17d8b8ecfbb0e2099b4796f2de7fee612e9c07b5

# 4. Define Business Metrics

Machine learning experts got used to working with the metrics of ML algorithms: precision, recall, NDCG… But in fact, businesses are not interested in these metrics, other indicators play a role:

* session depth,
* conversion to purchase/view,
* retention,
* average check per user.

So you need to choose the metrics that best fit your key business goals. Here’s what you can do:

* Count the various metrics.
* On offline data, find correlations between business metrics and long-term metrics: user retention, revenue growth, etc.

As a result, you get a set of business metrics to grow in AB tests.

# 5. Segment Your Users

From a business perspective, the audience of the site can be very heterogeneous in various ways (such indicators are sometimes called slices):

* socio-demographic characteristics,
* activity on the service (number of feedback, frequency of visits),
* geopositions,
* etc.

Very often your models will have different effects on different audience segments — for example, showing metrics growth on new users and no growth on older users.

The reporting system should provide the ability to calculate metrics in different user sections, to notice the improvement (or deterioration) of metrics in each particular segment.

For example, iFunny has two large segments:

* “high activity” — users visit the app frequently and watch a lot of content,
* “low activity” — users visit the app rarely.

We used to count metrics overall, but when we separated these users in reports, we saw that model changes affect them differently. Sometimes there is growth only in the high activity segment — and when you count metrics without segmentation, you might not notice it.

&#x200B;

https://preview.redd.it/5fg29wr8n9e91.png?width=700&format=png&auto=webp&s=1dc04f1ff78af19cc36ac18b5a2d64262fcd252e

# 6. Determine the Right Offline Metrics

When the feedback data is collected and the business metrics are selected, there is a choice of offline metrics, which will optimize our model, for example:

* precision@k,
* recall@k,
* NDCG,
* MAP.

There are quite a few metrics for recommendation systems. So how do you choose the right one? The answer is simple: choose offline metrics that correlate with business metrics. You can do this by calculating the correlation between offline and online metrics. For example, for a while at FunCorp, we thought that the number of smiles per user correlated with such business metrics as retention, but our experiments showed that this was not the case. And we began to optimize other business metrics, such as time spent.

Analyze, and in this case, you will learn how to avoid mistakes when a model with good offline metrics worsens business metrics.

# 7. Create a Baseline Model

Don’t try to use the most complex models to solve the problem right away — start with simpler approaches. For example, with product recommendations by popularity instead of neural networks. This simple model is called a baseline.

In this case, you will immediately see the growth of product metrics, while avoiding large infrastructure and development costs. In the future, all your more complex models will be compared with the baseline.

For example, at FunCorp, we first used a simple approach based on the K Nearest Neighborhoods algorithm to create a service for recommending content in push notifications, and only in the second iteration, we moved to a more complex boosting model. The boosting model requires more computational resources for training, so we first made sure that ML has a small positive effect — and to enhance it, it makes sense to spend time on developing a more complex model.

# 8. Choose the ML Algorithm and Discard the Worst Models

The next step is to train more complex models. Recommendation systems usually use both neural networks and classical ML algorithms:

* Matrix factorization,
* LogisticRegression,
* KNN (user-based, item-based),
* boosting.

At this stage, we count offline metrics and, thanks to the data already accumulated in the feedback system, we choose the best model to run in the test.

This approach has a noticeable disadvantage. Offline data are the result of the model that was working in production at the time of collecting this data, so offline experiments will be won by the model that most accurately “repeats” the current one.

So with offline data, we only distinguish very bad models from “not quite bad ones” in order to run the “not quite bad model” in the test. Alternatively, we can run the experiment without offline tests — using, for example, the multi-armed bandits mechanism. In case of bad metrics, the bandit automatically stops directing traffic to the “bad” model. But this approach of testing new models greatly complicates the architecture, so we test models on offline data.

# 9. Run Everything Through the AB Testing System

Any changes in the recommendation algorithm, such as switching from a baseline to an advanced model, must go through a system of AB tests.

Without good analytics, you either can’t see the effect of a recommendation system, or you misinterpret the data, which can cause business metrics to deteriorate. For example, if you start recommending more NSFW content, the metric “number of likes per user” will increase in the moment. But in the long run, such content can lead to an increase in unsubscribes from the service.

*This is why AB tests need to measure both short-term and long-term effects.*

When conducting AB tests, you need to ensure that the samples in the test and control groups are representative. At FunCorp, we calculate the sample size depending on what metric growth we expect to see.

We also need to avoid the influence of some tests on others. This is a problem with mature products when a large number of changes are tested in parallel, some of which may affect ML output. For example, if we do tests in parallel for both the recommendation feed and moderation rules (for which the content may be rejected by the moderator), the test and control metrics may diverge not because of differences in the model but because of differences in content sorting.

# 10. Remember the Classic Problems in Production

When rolling out the algorithm “in production” it is necessary to provide a solution to a number of classic problems.

* Users’ cold start: what to recommend to those who haven’t left feedback? We recommend here to make lists of globally popular content and make them as diverse as possible to be more likely to “hook” the user.
* Content’ cold-start: how do you recommend the content that hasn’t had time to gain statistics? To solve this problem, cold-start content is usually swept into recommendations in a small proportion of recommendations.
* A feedback loop is a classic trap for recommendation systems. We show the content to the user, then collect feedback, and run the next learning cycle on that data. In this case, the system learns from the data it generates itself. To avoid this trap, we usually allocate a small percentage of users who receive random output instead of recommendations — with this design, the system will be trained not only on its own data but also on users’ interactions with randomly selected content.

Good luck with building recommendation systems and thanks for your attention!",11,199,2022-07-28 11:03:47, r  ten lessons of implementing recommendation systems in business,funcorp data science team has been long working on improving the user experience with machine learning   we ve picked out key takeaways of that process  following this article s advice  you will avoid a lot of mistakes when creating a recommendation system for your product     define a goal that really contributes to the business tasksthe global task of the recommendation system is to select a shortlist of content from a large catalog that is most suitable for a particular user  the content itself can be different   from products in the online store and articles to banking services  funcorp product team works with the most interesting kind of content   we recommend memes to do this  we rely on the history of the user s interaction with the service  but  good recommendations  from a user perspective and from a business perspective are not always the same thing  for example  we found that increasing the number of likes that a user clicks thanks to more accurate recommendations does not affect retention  a metric that is important for our business  so we started focusing on models that optimize time spent in the app instead of likes that s why it s so important to focus on the most important goal for your business  goals can be different  for example   user retention   increased revenue   cost reduction   and so on the recommendation system will surely allow you to improve the user experience  and the user will take the targeted action faster and or more often  what remains to be done is to make sure that you reach your business goals at the same time  win win  in our case  we saw a   increase in the relative number of smiles  likes  and an almost   increase in the viewing depth as a result of implementing a  recommendation system in our feed  https main goal in ifunny is to increase retention and you can see that sometimes we run experiments with a very destructive influence on retention   xb https   xb     find the optimal user touchpoint in the productwhen you ve decided on the global goal  you need to figure out what is the best way to display recommendations   in the feed   this is relevant for news sites or entertainment apps like our ifunny   push notifications   email newsletter   the section with personalized offers in a personal account   or other sections on the site application many factors influence the choice of touchpoint   for example  the share of dau in this point  for some users  push notifications may be disabled  or the complexity of integration with ml microservice in our case  an ineffective choice might look like this  the ifunny app has an explore section where we collect a selection of the best memes of the week  one can collect such selections with ml  but only small amount of daus go to this section   xb https using ml at this point is impractical the main rule here is to integrate ml where it will make the biggest increase in business metrics  therefore  in the case of funcorp we  first of all  decided to implement ml in the feed  because it is seen by the maximum number of users  and secondly  we started to create the recommendation system for the push notifications   because there is a noticeable  but still a smaller volume of the audience interacting with them     collect as much diverse feedback from users as possiblein our case  feedback is the actions a user can take to demonstrate how they feel about the content in the app  to build a recommendation system  you need to learn how to collect different types of feedback   explicit     this can be a rating by any scale or a like dislike and   implicit     the amount of time a user spends on the content   the number of visits to the content page   the number of times one shares the content on social networks or sends it to friends feedback should correlate with the business goals of the recommendation system  for example  if the goal is to reduce churn  it is reasonable to add a feedback form and show it to users who unsubscribe from the service   here are some important technical points you need to consider     make it possible to expand user feedback channels  for example  in addition to the time spent on the page  you can start collecting user comments and determining their tone  positive comments will tell you that you need more of this kind of content  and vice versa   keep a history of user feedback for a long time   at least several months  this is necessary for two purposes  first  the more data you have when training the recommendation system model  the better the model will be   you will be able to identify insights in long term users  behavior  second  a large amount of historical data will allow us to compare models without running ab tests  in an offline format   you need a data quality control system  real case  when we started collecting statistics on the time of viewing content and training the model using this data  we found out in the process that the data was collected from the ios platform only  on android  the feature had not been implemented  that is  we expected personalization to improve  but didn t have data for the whole platform don t forget about the limitations of channels  for example  only    of users give feedback using likes  and if you build the recommendation system only on likes  then    of the audience will receive non personalized dropout  so the more different channels of user feedback you have  the better in ifunny we have only   of users with explicit feedback  so we need to develop models with implicit feedback to improve our metrics   xb https     define business metricsmachine learning experts got used to working with the metrics of ml algorithms  precision  recall  ndcg  but in fact  businesses are not interested in these metrics  other indicators play a role   session depth   conversion to purchase view   retention   average check per user so you need to choose the metrics that best fit your key business goals  here s what you can do   count the various metrics   on offline data  find correlations between business metrics and long term metrics  user retention  revenue growth  etc as a result  you get a set of business metrics to grow in ab tests     segment your usersfrom a business perspective  the audience of the site can be very heterogeneous in various ways  such indicators are sometimes called slices    socio demographic characteristics   activity on the service  number of feedback  frequency of visits    geopositions   etc very often your models will have different effects on different audience segments   for example  showing metrics growth on new users and no growth on older users the reporting system should provide the ability to calculate metrics in different user sections  to notice the improvement  or deterioration  of metrics in each particular segment for example  ifunny has two large segments    high activity    users visit the app frequently and watch a lot of content    low activity    users visit the app rarely we used to count metrics overall  but when we separated these users in reports  we saw that model changes affect them differently  sometimes there is growth only in the high activity segment   and when you count metrics without segmentation  you might not notice it   xb https     determine the right offline metricswhen the feedback data is collected and the business metrics are selected  there is a choice of offline metrics  which will optimize our model  for example   precision k   recall k   ndcg   map there are quite a few metrics for recommendation systems  so how do you choose the right one  the answer is simple  choose offline metrics that correlate with business metrics  you can do this by calculating the correlation between offline and online metrics  for example  for a while at funcorp  we thought that the number of smiles per user correlated with such business metrics as retention  but our experiments showed that this was not the case  and we began to optimize other business metrics  such as time spent analyze  and in this case  you will learn how to avoid mistakes when a model with good offline metrics worsens business metrics     create a baseline modeldon t try to use the most complex models to solve the problem right away   start with simpler approaches  for example  with product recommendations by popularity instead of neural networks  this simple model is called a baseline in this case  you will immediately see the growth of product metrics  while avoiding large infrastructure and development costs  in the future  all your more complex models will be compared with the baseline for example  at funcorp  we first used a simple approach based on the k nearest neighborhoods algorithm to create a service for recommending content in push notifications  and only in the second iteration  we moved to a more complex boosting model  the boosting model requires more computational resources for training  so we first made sure that ml has a small positive effect   and to enhance it  it makes sense to spend time on developing a more complex model     choose the ml algorithm and discard the worst modelsthe next step is to train more complex models  recommendation systems usually use both neural networks and classical ml algorithms   matrix factorization   logisticregression   knn  user based  item based    boosting at this stage  we count offline metrics and  thanks to the data already accumulated in the feedback system  we choose the best model to run in the test this approach has a noticeable disadvantage  offline data are the result of the model that was working in production at the time of collecting this data  so offline experiments will be won by the model that most accurately  repeats  the current one so with offline data  we only distinguish very bad models from  not quite bad ones  in order to run the  not quite bad model  in the test  alternatively  we can run the experiment without offline tests   using  for example  the multi armed bandits mechanism  in case of bad metrics  the bandit automatically stops directing traffic to the  bad  model  but this approach of testing new models greatly complicates the architecture  so we test models on offline data     run everything through the ab testing systemany changes in the recommendation algorithm  such as switching from a baseline to an advanced model  must go through a system of ab tests without good analytics  you either can t see the effect of a recommendation system  or you misinterpret the data  which can cause business metrics to deteriorate  for example  if you start recommending more nsfw content  the metric  number of likes per user  will increase in the moment  but in the long run  such content can lead to an increase in unsubscribes from the service  this is why ab tests need to measure both short term and long term effects  when conducting ab tests  you need to ensure that the samples in the test and control groups are representative  at funcorp  we calculate the sample size depending on what metric growth we expect to see we also need to avoid the influence of some tests on others  this is a problem with mature products when a large number of changes are tested in parallel  some of which may affect ml output  for example  if we do tests in parallel for both the recommendation feed and moderation rules  for which the content may be rejected by the moderator   the test and control metrics may diverge not because of differences in the model but because of differences in content sorting     remember the classic problems in productionwhen rolling out the algorithm  in production  it is necessary to provide a solution to a number of classic problems   users  cold start  what to recommend to those who haven t left feedback  we recommend here to make lists of globally popular content and make them as diverse as possible to be more likely to  hook  the user   content  cold start  how do you recommend the content that hasn t had time to gain statistics  to solve this problem  cold start content is usually swept into recommendations in a small proportion of recommendations   a feedback loop is a classic trap for recommendation systems  we show the content to the user  then collect feedback  and run the next learning cycle on that data  in this case  the system learns from the data it generates itself  to avoid this trap  we usually allocate a small percentage of users who receive random output instead of recommendations   with this design  the system will be trained not only on its own data but also on users  interactions with randomly selected content good luck with building recommendation systems and thanks for your attention ,funcorp data science team long working improving user experience machine learning picked key takeaways process following article advice avoid lot mistakes creating recommendation system product define goal really contributes business tasksthe global task recommendation system select shortlist content large catalog suitable particular user content different products online store articles banking services funcorp product team works interesting kind content recommend memes rely history user interaction service good recommendations user perspective business perspective always thing example found increasing number likes user clicks thanks accurate recommendations affect retention metric important business started focusing models optimize time spent app instead likes important focus important goal business goals different example user retention increased revenue cost reduction recommendation system surely allow improve user experience user take targeted action faster often remains done make sure reach business goals time win win case saw increase relative number smiles likes almost increase viewing depth result implementing recommendation system feed https main goal ifunny increase retention see sometimes run experiments destructive influence retention xb https xb find optimal user touchpoint productwhen decided global goal need figure best way display recommendations feed relevant news sites entertainment apps like ifunny push notifications email newsletter section personalized offers personal account sections site application many factors influence choice touchpoint example share dau point users push notifications may disabled complexity integration ml microservice case ineffective choice might look like ifunny app explore section collect selection best memes week one collect selections ml small amount daus go section xb https using ml point impractical main rule integrate ml make biggest increase business metrics therefore case funcorp first decided implement ml feed seen maximum number users secondly started create recommendation system push notifications noticeable still smaller volume audience interacting collect much diverse feedback users possiblein case feedback actions user take demonstrate feel content app build recommendation system need learn collect different types feedback explicit rating scale like dislike implicit amount time user spends content number visits content page number times one shares content social networks sends friends feedback correlate business goals recommendation system example goal reduce churn reasonable feedback form show users unsubscribe service important technical points need consider make possible expand user feedback channels example addition time spent page start collecting user comments determining tone positive comments tell need kind content vice versa keep history user feedback long time least several months necessary two purposes first data training recommendation system model better model able identify insights long term users behavior second large amount historical data allow us compare models without running ab tests offline format need data quality control system real case started collecting statistics time viewing content training model using data found process data collected ios platform android feature implemented expected personalization improve data whole platform forget limitations channels example users give feedback using likes build recommendation system likes audience receive non personalized dropout different channels user feedback better ifunny users explicit feedback need develop models implicit feedback improve metrics xb https define business metricsmachine learning experts got used working metrics ml algorithms precision recall ndcg fact businesses interested metrics indicators play role session depth conversion purchase view retention average check per user need choose metrics best fit key business goals count various metrics offline data find correlations business metrics long term metrics user retention revenue growth etc result get set business metrics grow ab tests segment usersfrom business perspective audience site heterogeneous various ways indicators sometimes called slices socio demographic characteristics activity service number feedback frequency visits geopositions etc often models different effects different audience segments example showing metrics growth users growth older users reporting system provide ability calculate metrics different user sections notice improvement deterioration metrics particular segment example ifunny two large segments high activity users visit app frequently watch lot content low activity users visit app rarely used count metrics overall separated users reports saw model changes affect differently sometimes growth high activity segment count metrics without segmentation might notice xb https determine right offline metricswhen feedback data collected business metrics selected choice offline metrics optimize model example precision k recall k ndcg map quite metrics recommendation systems choose right one answer simple choose offline metrics correlate business metrics calculating correlation offline online metrics example funcorp thought number smiles per user correlated business metrics retention experiments showed case began optimize business metrics time spent analyze case learn avoid mistakes model good offline metrics worsens business metrics create baseline modeldon try use complex models solve problem right away start simpler approaches example product recommendations popularity instead neural networks simple model called baseline case immediately see growth product metrics avoiding large infrastructure development costs future complex models compared baseline example funcorp first used simple approach based k nearest neighborhoods algorithm create service recommending content push notifications second iteration moved complex boosting model boosting model requires computational resources training first made sure ml small positive effect enhance makes sense spend time developing complex model choose ml algorithm discard worst modelsthe next step train complex models recommendation systems usually use neural networks classical ml algorithms matrix factorization logisticregression knn user based item based boosting stage count offline metrics thanks data already accumulated feedback system choose best model run test approach noticeable disadvantage offline data result model working production time collecting data offline experiments model accurately repeats current one offline data distinguish bad models quite bad ones order run quite bad model test alternatively run experiment without offline tests using example multi armed bandits mechanism case bad metrics bandit automatically stops directing traffic bad model approach testing models greatly complicates architecture test models offline data run everything ab testing systemany changes recommendation algorithm switching baseline advanced model must go system ab tests without good analytics either see effect recommendation system misinterpret data cause business metrics deteriorate example start recommending nsfw content metric number likes per user increase moment long run content lead increase unsubscribes service ab tests need measure short term long term effects conducting ab tests need ensure samples test control groups representative funcorp calculate sample size depending metric growth expect see also need avoid influence tests others problem mature products large number changes tested parallel may affect ml output example tests parallel recommendation feed moderation rules content may rejected moderator test control metrics may diverge differences model differences content sorting remember classic problems productionwhen rolling algorithm production necessary provide solution number classic problems users cold start recommend left feedback recommend make lists globally popular content make diverse possible likely hook user content cold start recommend content time gain statistics solve problem cold start content usually swept recommendations small proportion recommendations feedback loop classic trap recommendation systems show content user collect feedback run next learning cycle data case system learns data generates avoid trap usually allocate small percentage users receive random output instead recommendations design system trained data also users interactions randomly selected content good luck building recommendation systems thanks attention,r ten lessons implementing recommendation systems business,r ten lessons implementing recommendation systems businessfuncorp data science team long working improving user experience machine learning picked key takeaways process following article advice avoid lot mistakes creating recommendation system product define goal really contributes business tasksthe global task recommendation system select shortlist content large catalog suitable particular user content different products online store articles banking services funcorp product team works interesting kind content recommend memes rely history user interaction service good recommendations user perspective business perspective always thing example found increasing number likes user clicks thanks accurate recommendations affect retention metric important business started focusing models optimize time spent app instead likes important focus important goal business goals different example user retention increased revenue cost reduction recommendation system surely allow improve user experience user take targeted action faster often remains done make sure reach business goals time win win case saw increase relative number smiles likes almost increase viewing depth result implementing recommendation system feed https main goal ifunny increase retention see sometimes run experiments destructive influence retention xb https xb find optimal user touchpoint productwhen decided global goal need figure best way display recommendations feed relevant news sites entertainment apps like ifunny push notifications email newsletter section personalized offers personal account sections site application many factors influence choice touchpoint example share dau point users push notifications may disabled complexity integration ml microservice case ineffective choice might look like ifunny app explore section collect selection best memes week one collect selections ml small amount daus go section xb https using ml point impractical main rule integrate ml make biggest increase business metrics therefore case funcorp first decided implement ml feed seen maximum number users secondly started create recommendation system push notifications noticeable still smaller volume audience interacting collect much diverse feedback users possiblein case feedback actions user take demonstrate feel content app build recommendation system need learn collect different types feedback explicit rating scale like dislike implicit amount time user spends content number visits content page number times one shares content social networks sends friends feedback correlate business goals recommendation system example goal reduce churn reasonable feedback form show users unsubscribe service important technical points need consider make possible expand user feedback channels example addition time spent page start collecting user comments determining tone positive comments tell need kind content vice versa keep history user feedback long time least several months necessary two purposes first data training recommendation system model better model able identify insights long term users behavior second large amount historical data allow us compare models without running ab tests offline format need data quality control system real case started collecting statistics time viewing content training model using data found process data collected ios platform android feature implemented expected personalization improve data whole platform forget limitations channels example users give feedback using likes build recommendation system likes audience receive non personalized dropout different channels user feedback better ifunny users explicit feedback need develop models implicit feedback improve metrics xb https define business metricsmachine learning experts got used working metrics ml algorithms precision recall ndcg fact businesses interested metrics indicators play role session depth conversion purchase view retention average check per user need choose metrics best fit key business goals count various metrics offline data find correlations business metrics long term metrics user retention revenue growth etc result get set business metrics grow ab tests segment usersfrom business perspective audience site heterogeneous various ways indicators sometimes called slices socio demographic characteristics activity service number feedback frequency visits geopositions etc often models different effects different audience segments example showing metrics growth users growth older users reporting system provide ability calculate metrics different user sections notice improvement deterioration metrics particular segment example ifunny two large segments high activity users visit app frequently watch lot content low activity users visit app rarely used count metrics overall separated users reports saw model changes affect differently sometimes growth high activity segment count metrics without segmentation might notice xb https determine right offline metricswhen feedback data collected business metrics selected choice offline metrics optimize model example precision k recall k ndcg map quite metrics recommendation systems choose right one answer simple choose offline metrics correlate business metrics calculating correlation offline online metrics example funcorp thought number smiles per user correlated business metrics retention experiments showed case began optimize business metrics time spent analyze case learn avoid mistakes model good offline metrics worsens business metrics create baseline modeldon try use complex models solve problem right away start simpler approaches example product recommendations popularity instead neural networks simple model called baseline case immediately see growth product metrics avoiding large infrastructure development costs future complex models compared baseline example funcorp first used simple approach based k nearest neighborhoods algorithm create service recommending content push notifications second iteration moved complex boosting model boosting model requires computational resources training first made sure ml small positive effect enhance makes sense spend time developing complex model choose ml algorithm discard worst modelsthe next step train complex models recommendation systems usually use neural networks classical ml algorithms matrix factorization logisticregression knn user based item based boosting stage count offline metrics thanks data already accumulated feedback system choose best model run test approach noticeable disadvantage offline data result model working production time collecting data offline experiments model accurately repeats current one offline data distinguish bad models quite bad ones order run quite bad model test alternatively run experiment without offline tests using example multi armed bandits mechanism case bad metrics bandit automatically stops directing traffic bad model approach testing models greatly complicates architecture test models offline data run everything ab testing systemany changes recommendation algorithm switching baseline advanced model must go system ab tests without good analytics either see effect recommendation system misinterpret data cause business metrics deteriorate example start recommending nsfw content metric number likes per user increase moment long run content lead increase unsubscribes service ab tests need measure short term long term effects conducting ab tests need ensure samples test control groups representative funcorp calculate sample size depending metric growth expect see also need avoid influence tests others problem mature products large number changes tested parallel may affect ml output example tests parallel recommendation feed moderation rules content may rejected moderator test control metrics may diverge differences model differences content sorting remember classic problems productionwhen rolling algorithm production necessary provide solution number classic problems users cold start recommend left feedback recommend make lists globally popular content make diverse possible likely hook user content cold start recommend content time gain statistics solve problem cold start content usually swept recommendations small proportion recommendations feedback loop classic trap recommendation systems show content user collect feedback run next learning cycle data case system learns data generates avoid trap usually allocate small percentage users receive random output instead recommendations design system trained data also users interactions randomly selected content good luck building recommendation systems thanks attention,"['r', 'ten', 'lessons', 'implementing', 'recommendation', 'systems', 'businessfuncorp', 'data', 'science', 'team', 'long', 'working', 'improving', 'user', 'experience', 'machine', 'learning', 'picked', 'key', 'takeaways', 'process', 'following', 'article', 'advice', 'avoid', 'lot', 'mistakes', 'creating', 'recommendation', 'system', 'product', 'define', 'goal', 'really', 'contributes', 'business', 'tasksthe', 'global', 'task', 'recommendation', 'system', 'select', 'shortlist', 'content', 'large', 'catalog', 'suitable', 'particular', 'user', 'content', 'different', 'products', 'online', 'store', 'articles', 'banking', 'services', 'funcorp', 'product', 'team', 'works', 'interesting', 'kind', 'content', 'recommend', 'memes', 'rely', 'history', 'user', 'interaction', 'service', 'good', 'recommendations', 'user', 'perspective', 'business', 'perspective', 'always', 'thing', 'example', 'found', 'increasing', 'number', 'likes', 'user', 'clicks', 'thanks', 'accurate', 'recommendations', 'affect', 'retention', 'metric', 'important', 'business', 'started', 'focusing', 'models', 'optimize', 'time', 'spent', 'app', 'instead', 'likes', 'important', 'focus', 'important', 'goal', 'business', 'goals', 'different', 'example', 'user', 'retention', 'increased', 'revenue', 'cost', 'reduction', 'recommendation', 'system', 'surely', 'allow', 'improve', 'user', 'experience', 'user', 'take', 'targeted', 'action', 'faster', 'often', 'remains', 'done', 'make', 'sure', 'reach', 'business', 'goals', 'time', 'win', 'win', 'case', 'saw', 'increase', 'relative', 'number', 'smiles', 'likes', 'almost', 'increase', 'viewing', 'depth', 'result', 'implementing', 'recommendation', 'system', 'feed', 'https', 'main', 'goal', 'ifunny', 'increase', 'retention', 'see', 'sometimes', 'run', 'experiments', 'destructive', 'influence', 'retention', 'xb', 'https', 'xb', 'find', 'optimal', 'user', 'touchpoint', 'productwhen', 'decided', 'global', 'goal', 'need', 'figure', 'best', 'way', 'display', 'recommendations', 'feed', 'relevant', 'news', 'sites', 'entertainment', 'apps', 'like', 'ifunny', 'push', 'notifications', 'email', 'newsletter', 'section', 'personalized', 'offers', 'personal', 'account', 'sections', 'site', 'application', 'many', 'factors', 'influence', 'choice', 'touchpoint', 'example', 'share', 'dau', 'point', 'users', 'push', 'notifications', 'may', 'disabled', 'complexity', 'integration', 'ml', 'microservice', 'case', 'ineffective', 'choice', 'might', 'look', 'like', 'ifunny', 'app', 'explore', 'section', 'collect', 'selection', 'best', 'memes', 'week', 'one', 'collect', 'selections', 'ml', 'small', 'amount', 'daus', 'go', 'section', 'xb', 'https', 'using', 'ml', 'point', 'impractical', 'main', 'rule', 'integrate', 'ml', 'make', 'biggest', 'increase', 'business', 'metrics', 'therefore', 'case', 'funcorp', 'first', 'decided', 'implement', 'ml', 'feed', 'seen', 'maximum', 'number', 'users', 'secondly', 'started', 'create', 'recommendation', 'system', 'push', 'notifications', 'noticeable', 'still', 'smaller', 'volume', 'audience', 'interacting', 'collect', 'much', 'diverse', 'feedback', 'users', 'possiblein', 'case', 'feedback', 'actions', 'user', 'take', 'demonstrate', 'feel', 'content', 'app', 'build', 'recommendation', 'system', 'need', 'learn', 'collect', 'different', 'types', 'feedback', 'explicit', 'rating', 'scale', 'like', 'dislike', 'implicit', 'amount', 'time', 'user', 'spends', 'content', 'number', 'visits', 'content', 'page', 'number', 'times', 'one', 'shares', 'content', 'social', 'networks', 'sends', 'friends', 'feedback', 'correlate', 'business', 'goals', 'recommendation', 'system', 'example', 'goal', 'reduce', 'churn', 'reasonable', 'feedback', 'form', 'show', 'users', 'unsubscribe', 'service', 'important', 'technical', 'points', 'need', 'consider', 'make', 'possible', 'expand', 'user', 'feedback', 'channels', 'example', 'addition', 'time', 'spent', 'page', 'start', 'collecting', 'user', 'comments', 'determining', 'tone', 'positive', 'comments', 'tell', 'need', 'kind', 'content', 'vice', 'versa', 'keep', 'history', 'user', 'feedback', 'long', 'time', 'least', 'several', 'months', 'necessary', 'two', 'purposes', 'first', 'data', 'training', 'recommendation', 'system', 'model', 'better', 'model', 'able', 'identify', 'insights', 'long', 'term', 'users', 'behavior', 'second', 'large', 'amount', 'historical', 'data', 'allow', 'us', 'compare', 'models', 'without', 'running', 'ab', 'tests', 'offline', 'format', 'need', 'data', 'quality', 'control', 'system', 'real', 'case', 'started', 'collecting', 'statistics', 'time', 'viewing', 'content', 'training', 'model', 'using', 'data', 'found', 'process', 'data', 'collected', 'ios', 'platform', 'android', 'feature', 'implemented', 'expected', 'personalization', 'improve', 'data', 'whole', 'platform', 'forget', 'limitations', 'channels', 'example', 'users', 'give', 'feedback', 'using', 'likes', 'build', 'recommendation', 'system', 'likes', 'audience', 'receive', 'non', 'personalized', 'dropout', 'different', 'channels', 'user', 'feedback', 'better', 'ifunny', 'users', 'explicit', 'feedback', 'need', 'develop', 'models', 'implicit', 'feedback', 'improve', 'metrics', 'xb', 'https', 'define', 'business', 'metricsmachine', 'learning', 'experts', 'got', 'used', 'working', 'metrics', 'ml', 'algorithms', 'precision', 'recall', 'ndcg', 'fact', 'businesses', 'interested', 'metrics', 'indicators', 'play', 'role', 'session', 'depth', 'conversion', 'purchase', 'view', 'retention', 'average', 'check', 'per', 'user', 'need', 'choose', 'metrics', 'best', 'fit', 'key', 'business', 'goals', 'count', 'various', 'metrics', 'offline', 'data', 'find', 'correlations', 'business', 'metrics', 'long', 'term', 'metrics', 'user', 'retention', 'revenue', 'growth', 'etc', 'result', 'get', 'set', 'business', 'metrics', 'grow', 'ab', 'tests', 'segment', 'usersfrom', 'business', 'perspective', 'audience', 'site', 'heterogeneous', 'various', 'ways', 'indicators', 'sometimes', 'called', 'slices', 'socio', 'demographic', 'characteristics', 'activity', 'service', 'number', 'feedback', 'frequency', 'visits', 'geopositions', 'etc', 'often', 'models', 'different', 'effects', 'different', 'audience', 'segments', 'example', 'showing', 'metrics', 'growth', 'users', 'growth', 'older', 'users', 'reporting', 'system', 'provide', 'ability', 'calculate', 'metrics', 'different', 'user', 'sections', 'notice', 'improvement', 'deterioration', 'metrics', 'particular', 'segment', 'example', 'ifunny', 'two', 'large', 'segments', 'high', 'activity', 'users', 'visit', 'app', 'frequently', 'watch', 'lot', 'content', 'low', 'activity', 'users', 'visit', 'app', 'rarely', 'used', 'count', 'metrics', 'overall', 'separated', 'users', 'reports', 'saw', 'model', 'changes', 'affect', 'differently', 'sometimes', 'growth', 'high', 'activity', 'segment', 'count', 'metrics', 'without', 'segmentation', 'might', 'notice', 'xb', 'https', 'determine', 'right', 'offline', 'metricswhen', 'feedback', 'data', 'collected', 'business', 'metrics', 'selected', 'choice', 'offline', 'metrics', 'optimize', 'model', 'example', 'precision', 'k', 'recall', 'k', 'ndcg', 'map', 'quite', 'metrics', 'recommendation', 'systems', 'choose', 'right', 'one', 'answer', 'simple', 'choose', 'offline', 'metrics', 'correlate', 'business', 'metrics', 'calculating', 'correlation', 'offline', 'online', 'metrics', 'example', 'funcorp', 'thought', 'number', 'smiles', 'per', 'user', 'correlated', 'business', 'metrics', 'retention', 'experiments', 'showed', 'case', 'began', 'optimize', 'business', 'metrics', 'time', 'spent', 'analyze', 'case', 'learn', 'avoid', 'mistakes', 'model', 'good', 'offline', 'metrics', 'worsens', 'business', 'metrics', 'create', 'baseline', 'modeldon', 'try', 'use', 'complex', 'models', 'solve', 'problem', 'right', 'away', 'start', 'simpler', 'approaches', 'example', 'product', 'recommendations', 'popularity', 'instead', 'neural', 'networks', 'simple', 'model', 'called', 'baseline', 'case', 'immediately', 'see', 'growth', 'product', 'metrics', 'avoiding', 'large', 'infrastructure', 'development', 'costs', 'future', 'complex', 'models', 'compared', 'baseline', 'example', 'funcorp', 'first', 'used', 'simple', 'approach', 'based', 'k', 'nearest', 'neighborhoods', 'algorithm', 'create', 'service', 'recommending', 'content', 'push', 'notifications', 'second', 'iteration', 'moved', 'complex', 'boosting', 'model', 'boosting', 'model', 'requires', 'computational', 'resources', 'training', 'first', 'made', 'sure', 'ml', 'small', 'positive', 'effect', 'enhance', 'makes', 'sense', 'spend', 'time', 'developing', 'complex', 'model', 'choose', 'ml', 'algorithm', 'discard', 'worst', 'modelsthe', 'next', 'step', 'train', 'complex', 'models', 'recommendation', 'systems', 'usually', 'use', 'neural', 'networks', 'classical', 'ml', 'algorithms', 'matrix', 'factorization', 'logisticregression', 'knn', 'user', 'based', 'item', 'based', 'boosting', 'stage', 'count', 'offline', 'metrics', 'thanks', 'data', 'already', 'accumulated', 'feedback', 'system', 'choose', 'best', 'model', 'run', 'test', 'approach', 'noticeable', 'disadvantage', 'offline', 'data', 'result', 'model', 'working', 'production', 'time', 'collecting', 'data', 'offline', 'experiments', 'model', 'accurately', 'repeats', 'current', 'one', 'offline', 'data', 'distinguish', 'bad', 'models', 'quite', 'bad', 'ones', 'order', 'run', 'quite', 'bad', 'model', 'test', 'alternatively', 'run', 'experiment', 'without', 'offline', 'tests', 'using', 'example', 'multi', 'armed', 'bandits', 'mechanism', 'case', 'bad', 'metrics', 'bandit', 'automatically', 'stops', 'directing', 'traffic', 'bad', 'model', 'approach', 'testing', 'models', 'greatly', 'complicates', 'architecture', 'test', 'models', 'offline', 'data', 'run', 'everything', 'ab', 'testing', 'systemany', 'changes', 'recommendation', 'algorithm', 'switching', 'baseline', 'advanced', 'model', 'must', 'go', 'system', 'ab', 'tests', 'without', 'good', 'analytics', 'either', 'see', 'effect', 'recommendation', 'system', 'misinterpret', 'data', 'cause', 'business', 'metrics', 'deteriorate', 'example', 'start', 'recommending', 'nsfw', 'content', 'metric', 'number', 'likes', 'per', 'user', 'increase', 'moment', 'long', 'run', 'content', 'lead', 'increase', 'unsubscribes', 'service', 'ab', 'tests', 'need', 'measure', 'short', 'term', 'long', 'term', 'effects', 'conducting', 'ab', 'tests', 'need', 'ensure', 'samples', 'test', 'control', 'groups', 'representative', 'funcorp', 'calculate', 'sample', 'size', 'depending', 'metric', 'growth', 'expect', 'see', 'also', 'need', 'avoid', 'influence', 'tests', 'others', 'problem', 'mature', 'products', 'large', 'number', 'changes', 'tested', 'parallel', 'may', 'affect', 'ml', 'output', 'example', 'tests', 'parallel', 'recommendation', 'feed', 'moderation', 'rules', 'content', 'may', 'rejected', 'moderator', 'test', 'control', 'metrics', 'may', 'diverge', 'differences', 'model', 'differences', 'content', 'sorting', 'remember', 'classic', 'problems', 'productionwhen', 'rolling', 'algorithm', 'production', 'necessary', 'provide', 'solution', 'number', 'classic', 'problems', 'users', 'cold', 'start', 'recommend', 'left', 'feedback', 'recommend', 'make', 'lists', 'globally', 'popular', 'content', 'make', 'diverse', 'possible', 'likely', 'hook', 'user', 'content', 'cold', 'start', 'recommend', 'content', 'time', 'gain', 'statistics', 'solve', 'problem', 'cold', 'start', 'content', 'usually', 'swept', 'recommendations', 'small', 'proportion', 'recommendations', 'feedback', 'loop', 'classic', 'trap', 'recommendation', 'systems', 'show', 'content', 'user', 'collect', 'feedback', 'run', 'next', 'learning', 'cycle', 'data', 'case', 'system', 'learns', 'data', 'generates', 'avoid', 'trap', 'usually', 'allocate', 'small', 'percentage', 'users', 'receive', 'random', 'output', 'instead', 'recommendations', 'design', 'system', 'trained', 'data', 'also', 'users', 'interactions', 'randomly', 'selected', 'content', 'good', 'luck', 'building', 'recommendation', 'systems', 'thanks', 'attention']","['r', 'ten', 'lesson', 'implement', 'recommend', 'system', 'businessfuncorp', 'data', 'scienc', 'team', 'long', 'work', 'improv', 'user', 'experi', 'machin', 'learn', 'pick', 'key', 'takeaway', 'process', 'follow', 'articl', 'advic', 'avoid', 'lot', 'mistak', 'creat', 'recommend', 'system', 'product', 'defin', 'goal', 'realli', 'contribut', 'busi', 'tasksth', 'global', 'task', 'recommend', 'system', 'select', 'shortlist', 'content', 'larg', 'catalog', 'suitabl', 'particular', 'user', 'content', 'differ', 'product', 'onlin', 'store', 'articl', 'bank', 'servic', 'funcorp', 'product', 'team', 'work', 'interest', 'kind', 'content', 'recommend', 'meme', 'reli', 'histori', 'user', 'interact', 'servic', 'good', 'recommend', 'user', 'perspect', 'busi', 'perspect', 'alway', 'thing', 'exampl', 'found', 'increas', 'number', 'like', 'user', 'click', 'thank', 'accur', 'recommend', 'affect', 'retent', 'metric', 'import', 'busi', 'start', 'focus', 'model', 'optim', 'time', 'spent', 'app', 'instead', 'like', 'import', 'focu', 'import', 'goal', 'busi', 'goal', 'differ', 'exampl', 'user', 'retent', 'increas', 'revenu', 'cost', 'reduct', 'recommend', 'system', 'sure', 'allow', 'improv', 'user', 'experi', 'user', 'take', 'target', 'action', 'faster', 'often', 'remain', 'done', 'make', 'sure', 'reach', 'busi', 'goal', 'time', 'win', 'win', 'case', 'saw', 'increas', 'rel', 'number', 'smile', 'like', 'almost', 'increas', 'view', 'depth', 'result', 'implement', 'recommend', 'system', 'feed', 'http', 'main', 'goal', 'ifunni', 'increas', 'retent', 'see', 'sometim', 'run', 'experi', 'destruct', 'influenc', 'retent', 'xb', 'http', 'xb', 'find', 'optim', 'user', 'touchpoint', 'productwhen', 'decid', 'global', 'goal', 'need', 'figur', 'best', 'way', 'display', 'recommend', 'feed', 'relev', 'news', 'site', 'entertain', 'app', 'like', 'ifunni', 'push', 'notif', 'email', 'newslett', 'section', 'person', 'offer', 'person', 'account', 'section', 'site', 'applic', 'mani', 'factor', 'influenc', 'choic', 'touchpoint', 'exampl', 'share', 'dau', 'point', 'user', 'push', 'notif', 'may', 'disabl', 'complex', 'integr', 'ml', 'microservic', 'case', 'ineffect', 'choic', 'might', 'look', 'like', 'ifunni', 'app', 'explor', 'section', 'collect', 'select', 'best', 'meme', 'week', 'one', 'collect', 'select', 'ml', 'small', 'amount', 'dau', 'go', 'section', 'xb', 'http', 'use', 'ml', 'point', 'impract', 'main', 'rule', 'integr', 'ml', 'make', 'biggest', 'increas', 'busi', 'metric', 'therefor', 'case', 'funcorp', 'first', 'decid', 'implement', 'ml', 'feed', 'seen', 'maximum', 'number', 'user', 'secondli', 'start', 'creat', 'recommend', 'system', 'push', 'notif', 'notic', 'still', 'smaller', 'volum', 'audienc', 'interact', 'collect', 'much', 'divers', 'feedback', 'user', 'possiblein', 'case', 'feedback', 'action', 'user', 'take', 'demonstr', 'feel', 'content', 'app', 'build', 'recommend', 'system', 'need', 'learn', 'collect', 'differ', 'type', 'feedback', 'explicit', 'rate', 'scale', 'like', 'dislik', 'implicit', 'amount', 'time', 'user', 'spend', 'content', 'number', 'visit', 'content', 'page', 'number', 'time', 'one', 'share', 'content', 'social', 'network', 'send', 'friend', 'feedback', 'correl', 'busi', 'goal', 'recommend', 'system', 'exampl', 'goal', 'reduc', 'churn', 'reason', 'feedback', 'form', 'show', 'user', 'unsubscrib', 'servic', 'import', 'technic', 'point', 'need', 'consid', 'make', 'possibl', 'expand', 'user', 'feedback', 'channel', 'exampl', 'addit', 'time', 'spent', 'page', 'start', 'collect', 'user', 'comment', 'determin', 'tone', 'posit', 'comment', 'tell', 'need', 'kind', 'content', 'vice', 'versa', 'keep', 'histori', 'user', 'feedback', 'long', 'time', 'least', 'sever', 'month', 'necessari', 'two', 'purpos', 'first', 'data', 'train', 'recommend', 'system', 'model', 'better', 'model', 'abl', 'identifi', 'insight', 'long', 'term', 'user', 'behavior', 'second', 'larg', 'amount', 'histor', 'data', 'allow', 'us', 'compar', 'model', 'without', 'run', 'ab', 'test', 'offlin', 'format', 'need', 'data', 'qualiti', 'control', 'system', 'real', 'case', 'start', 'collect', 'statist', 'time', 'view', 'content', 'train', 'model', 'use', 'data', 'found', 'process', 'data', 'collect', 'io', 'platform', 'android', 'featur', 'implement', 'expect', 'person', 'improv', 'data', 'whole', 'platform', 'forget', 'limit', 'channel', 'exampl', 'user', 'give', 'feedback', 'use', 'like', 'build', 'recommend', 'system', 'like', 'audienc', 'receiv', 'non', 'person', 'dropout', 'differ', 'channel', 'user', 'feedback', 'better', 'ifunni', 'user', 'explicit', 'feedback', 'need', 'develop', 'model', 'implicit', 'feedback', 'improv', 'metric', 'xb', 'http', 'defin', 'busi', 'metricsmachin', 'learn', 'expert', 'got', 'use', 'work', 'metric', 'ml', 'algorithm', 'precis', 'recal', 'ndcg', 'fact', 'busi', 'interest', 'metric', 'indic', 'play', 'role', 'session', 'depth', 'convers', 'purchas', 'view', 'retent', 'averag', 'check', 'per', 'user', 'need', 'choos', 'metric', 'best', 'fit', 'key', 'busi', 'goal', 'count', 'variou', 'metric', 'offlin', 'data', 'find', 'correl', 'busi', 'metric', 'long', 'term', 'metric', 'user', 'retent', 'revenu', 'growth', 'etc', 'result', 'get', 'set', 'busi', 'metric', 'grow', 'ab', 'test', 'segment', 'usersfrom', 'busi', 'perspect', 'audienc', 'site', 'heterogen', 'variou', 'way', 'indic', 'sometim', 'call', 'slice', 'socio', 'demograph', 'characterist', 'activ', 'servic', 'number', 'feedback', 'frequenc', 'visit', 'geoposit', 'etc', 'often', 'model', 'differ', 'effect', 'differ', 'audienc', 'segment', 'exampl', 'show', 'metric', 'growth', 'user', 'growth', 'older', 'user', 'report', 'system', 'provid', 'abil', 'calcul', 'metric', 'differ', 'user', 'section', 'notic', 'improv', 'deterior', 'metric', 'particular', 'segment', 'exampl', 'ifunni', 'two', 'larg', 'segment', 'high', 'activ', 'user', 'visit', 'app', 'frequent', 'watch', 'lot', 'content', 'low', 'activ', 'user', 'visit', 'app', 'rare', 'use', 'count', 'metric', 'overal', 'separ', 'user', 'report', 'saw', 'model', 'chang', 'affect', 'differ', 'sometim', 'growth', 'high', 'activ', 'segment', 'count', 'metric', 'without', 'segment', 'might', 'notic', 'xb', 'http', 'determin', 'right', 'offlin', 'metricswhen', 'feedback', 'data', 'collect', 'busi', 'metric', 'select', 'choic', 'offlin', 'metric', 'optim', 'model', 'exampl', 'precis', 'k', 'recal', 'k', 'ndcg', 'map', 'quit', 'metric', 'recommend', 'system', 'choos', 'right', 'one', 'answer', 'simpl', 'choos', 'offlin', 'metric', 'correl', 'busi', 'metric', 'calcul', 'correl', 'offlin', 'onlin', 'metric', 'exampl', 'funcorp', 'thought', 'number', 'smile', 'per', 'user', 'correl', 'busi', 'metric', 'retent', 'experi', 'show', 'case', 'began', 'optim', 'busi', 'metric', 'time', 'spent', 'analyz', 'case', 'learn', 'avoid', 'mistak', 'model', 'good', 'offlin', 'metric', 'worsen', 'busi', 'metric', 'creat', 'baselin', 'modeldon', 'tri', 'use', 'complex', 'model', 'solv', 'problem', 'right', 'away', 'start', 'simpler', 'approach', 'exampl', 'product', 'recommend', 'popular', 'instead', 'neural', 'network', 'simpl', 'model', 'call', 'baselin', 'case', 'immedi', 'see', 'growth', 'product', 'metric', 'avoid', 'larg', 'infrastructur', 'develop', 'cost', 'futur', 'complex', 'model', 'compar', 'baselin', 'exampl', 'funcorp', 'first', 'use', 'simpl', 'approach', 'base', 'k', 'nearest', 'neighborhood', 'algorithm', 'creat', 'servic', 'recommend', 'content', 'push', 'notif', 'second', 'iter', 'move', 'complex', 'boost', 'model', 'boost', 'model', 'requir', 'comput', 'resourc', 'train', 'first', 'made', 'sure', 'ml', 'small', 'posit', 'effect', 'enhanc', 'make', 'sens', 'spend', 'time', 'develop', 'complex', 'model', 'choos', 'ml', 'algorithm', 'discard', 'worst', 'modelsth', 'next', 'step', 'train', 'complex', 'model', 'recommend', 'system', 'usual', 'use', 'neural', 'network', 'classic', 'ml', 'algorithm', 'matrix', 'factor', 'logisticregress', 'knn', 'user', 'base', 'item', 'base', 'boost', 'stage', 'count', 'offlin', 'metric', 'thank', 'data', 'alreadi', 'accumul', 'feedback', 'system', 'choos', 'best', 'model', 'run', 'test', 'approach', 'notic', 'disadvantag', 'offlin', 'data', 'result', 'model', 'work', 'product', 'time', 'collect', 'data', 'offlin', 'experi', 'model', 'accur', 'repeat', 'current', 'one', 'offlin', 'data', 'distinguish', 'bad', 'model', 'quit', 'bad', 'one', 'order', 'run', 'quit', 'bad', 'model', 'test', 'altern', 'run', 'experi', 'without', 'offlin', 'test', 'use', 'exampl', 'multi', 'arm', 'bandit', 'mechan', 'case', 'bad', 'metric', 'bandit', 'automat', 'stop', 'direct', 'traffic', 'bad', 'model', 'approach', 'test', 'model', 'greatli', 'complic', 'architectur', 'test', 'model', 'offlin', 'data', 'run', 'everyth', 'ab', 'test', 'systemani', 'chang', 'recommend', 'algorithm', 'switch', 'baselin', 'advanc', 'model', 'must', 'go', 'system', 'ab', 'test', 'without', 'good', 'analyt', 'either', 'see', 'effect', 'recommend', 'system', 'misinterpret', 'data', 'caus', 'busi', 'metric', 'deterior', 'exampl', 'start', 'recommend', 'nsfw', 'content', 'metric', 'number', 'like', 'per', 'user', 'increas', 'moment', 'long', 'run', 'content', 'lead', 'increas', 'unsubscrib', 'servic', 'ab', 'test', 'need', 'measur', 'short', 'term', 'long', 'term', 'effect', 'conduct', 'ab', 'test', 'need', 'ensur', 'sampl', 'test', 'control', 'group', 'repres', 'funcorp', 'calcul', 'sampl', 'size', 'depend', 'metric', 'growth', 'expect', 'see', 'also', 'need', 'avoid', 'influenc', 'test', 'other', 'problem', 'matur', 'product', 'larg', 'number', 'chang', 'test', 'parallel', 'may', 'affect', 'ml', 'output', 'exampl', 'test', 'parallel', 'recommend', 'feed', 'moder', 'rule', 'content', 'may', 'reject', 'moder', 'test', 'control', 'metric', 'may', 'diverg', 'differ', 'model', 'differ', 'content', 'sort', 'rememb', 'classic', 'problem', 'productionwhen', 'roll', 'algorithm', 'product', 'necessari', 'provid', 'solut', 'number', 'classic', 'problem', 'user', 'cold', 'start', 'recommend', 'left', 'feedback', 'recommend', 'make', 'list', 'global', 'popular', 'content', 'make', 'divers', 'possibl', 'like', 'hook', 'user', 'content', 'cold', 'start', 'recommend', 'content', 'time', 'gain', 'statist', 'solv', 'problem', 'cold', 'start', 'content', 'usual', 'swept', 'recommend', 'small', 'proport', 'recommend', 'feedback', 'loop', 'classic', 'trap', 'recommend', 'system', 'show', 'content', 'user', 'collect', 'feedback', 'run', 'next', 'learn', 'cycl', 'data', 'case', 'system', 'learn', 'data', 'gener', 'avoid', 'trap', 'usual', 'alloc', 'small', 'percentag', 'user', 'receiv', 'random', 'output', 'instead', 'recommend', 'design', 'system', 'train', 'data', 'also', 'user', 'interact', 'randomli', 'select', 'content', 'good', 'luck', 'build', 'recommend', 'system', 'thank', 'attent']"
32,37,37,line777888,wbakc6,finding job [R],Hello friends..i wonder if it is realistic to expect to find a job with the ml education from online courses and a couple if kaggle projects? with no proper university education?,10,0,2022-07-29 20:23:16,finding job  r ,hello friends  i wonder if it is realistic to expect to find a job with the ml education from online courses and a couple if kaggle projects  with no proper university education ,hello friends wonder realistic expect find job ml education online courses couple kaggle projects proper university education,finding job r,finding job rhello friends wonder realistic expect find job ml education online courses couple kaggle projects proper university education,"['finding', 'job', 'rhello', 'friends', 'wonder', 'realistic', 'expect', 'find', 'job', 'ml', 'education', 'online', 'courses', 'couple', 'kaggle', 'projects', 'proper', 'university', 'education']","['find', 'job', 'rhello', 'friend', 'wonder', 'realist', 'expect', 'find', 'job', 'ml', 'educ', 'onlin', 'cours', 'coupl', 'kaggl', 'project', 'proper', 'univers', 'educ']"
33,38,38,LeanderKu,waztqz,[D] Any way to tackle vanishing gradients without changing the architecture/initialization,"I have a problem for which I need a neural network with a relatively small (approximate) lipschitz-constant, which forces the network to reduce the magnitude of the weights throughout the network. I have only managed to train the network by slowly ramping up the penalty, but this always leads to the network to stop improving on the task, which I very much suspect is due to vanishing gradients. Since I need the small lipschitz-constant, I wonder if there is anything I could try that does not result in a increased lipschitz-constant? For example, are there any optimisers that try to improve upon the vanishing gradient problem?",6,1,2022-07-29 12:02:19, d  any way to tackle vanishing gradients without changing the architecture initialization,i have a problem for which i need a neural network with a relatively small  approximate  lipschitz constant  which forces the network to reduce the magnitude of the weights throughout the network  i have only managed to train the network by slowly ramping up the penalty  but this always leads to the network to stop improving on the task  which i very much suspect is due to vanishing gradients  since i need the small lipschitz constant  i wonder if there is anything i could try that does not result in a increased lipschitz constant  for example  are there any optimisers that try to improve upon the vanishing gradient problem ,problem need neural network relatively small approximate lipschitz constant forces network reduce magnitude weights throughout network managed train network slowly ramping penalty always leads network stop improving task much suspect due vanishing gradients since need small lipschitz constant wonder anything could try result increased lipschitz constant example optimisers try improve upon vanishing gradient problem,way tackle vanishing gradients without changing architecture initialization,way tackle vanishing gradients without changing architecture initializationproblem need neural network relatively small approximate lipschitz constant forces network reduce magnitude weights throughout network managed train network slowly ramping penalty always leads network stop improving task much suspect due vanishing gradients since need small lipschitz constant wonder anything could try result increased lipschitz constant example optimisers try improve upon vanishing gradient problem,"['way', 'tackle', 'vanishing', 'gradients', 'without', 'changing', 'architecture', 'initializationproblem', 'need', 'neural', 'network', 'relatively', 'small', 'approximate', 'lipschitz', 'constant', 'forces', 'network', 'reduce', 'magnitude', 'weights', 'throughout', 'network', 'managed', 'train', 'network', 'slowly', 'ramping', 'penalty', 'always', 'leads', 'network', 'stop', 'improving', 'task', 'much', 'suspect', 'due', 'vanishing', 'gradients', 'since', 'need', 'small', 'lipschitz', 'constant', 'wonder', 'anything', 'could', 'try', 'result', 'increased', 'lipschitz', 'constant', 'example', 'optimisers', 'try', 'improve', 'upon', 'vanishing', 'gradient', 'problem']","['way', 'tackl', 'vanish', 'gradient', 'without', 'chang', 'architectur', 'initializationproblem', 'need', 'neural', 'network', 'rel', 'small', 'approxim', 'lipschitz', 'constant', 'forc', 'network', 'reduc', 'magnitud', 'weight', 'throughout', 'network', 'manag', 'train', 'network', 'slowli', 'ramp', 'penalti', 'alway', 'lead', 'network', 'stop', 'improv', 'task', 'much', 'suspect', 'due', 'vanish', 'gradient', 'sinc', 'need', 'small', 'lipschitz', 'constant', 'wonder', 'anyth', 'could', 'tri', 'result', 'increas', 'lipschitz', 'constant', 'exampl', 'optimis', 'tri', 'improv', 'upon', 'vanish', 'gradient', 'problem']"
34,39,39,CheeseBurgersx,wb5k3t,Predicting top SKUs [D],"If I have 100s of part numbers in a warehouse and have to predict what part numbers will be top sellers tomorrow (or next week), what would be the algorithms to start with?",1,0,2022-07-29 16:59:24,predicting top skus  d ,if i have s of part numbers in a warehouse and have to predict what part numbers will be top sellers tomorrow  or next week   what would be the algorithms to start with ,part numbers warehouse predict part numbers top sellers tomorrow next week would algorithms start,predicting top skus,predicting top skuspart numbers warehouse predict part numbers top sellers tomorrow next week would algorithms start,"['predicting', 'top', 'skuspart', 'numbers', 'warehouse', 'predict', 'part', 'numbers', 'top', 'sellers', 'tomorrow', 'next', 'week', 'would', 'algorithms', 'start']","['predict', 'top', 'skuspart', 'number', 'warehous', 'predict', 'part', 'number', 'top', 'seller', 'tomorrow', 'next', 'week', 'would', 'algorithm', 'start']"
35,40,40,barash-616,wapus7,[D] What tools do you use in your development environment?,"I am looking for suggestions of tools for development environment in the context of deep reinforcement learning. I'll list what contexts and tools I'm using, as well as which ones I plan to use in my future development environment. Understand ""tool"" as a library, service, anything used in a development environment.

| Context | Current | Future |
|:-:|:-|:-|
| Machine Learning | [scikit-learn](https://scikit-learn.org/stable/) and [tensorflow](https://www.tensorflow.org/) | I'm migrating everything to use only [JAX](https://github.com/google/jax) |
| Tests | [pytest](https://docs.pytest.org/en/7.1.x/) | pytest, but I would use some to test my model or the algorithm behind it |
| Tracking | [Weight and biases](https://wandb.ai/site) | I accept other suggestions (including self-hosted services) |
| Container | [Docker](https://www.docker.com/) | I think about migrating to [singularity](https://github.com/sylabs/singularity), maybe using both in the appropriate scenarios for each |
| CI/CD | [GitHub Actions](https://github.com/features/actions) | GitHub Actions |
| App | [Streamlit](https://streamlit.io/) | Streamlit |

Can you tell what tools you use and whys? Also, what other contexts am I forgetting and do you think it's important to have?",0,5,2022-07-29 03:17:23, d  what tools do you use in your development environment ,i am looking for suggestions of tools for development environment in the context of deep reinforcement learning  i ll list what contexts and tools i m using  as well as which ones i plan to use in my future development environment  understand tool as a library  service  anything used in a development environment   context   current   future               machine learning    scikit learn  https   tests    pytest  https   tracking    weight and biases  https   container    docker  https   ci cd    github actions  https   app    streamlit  https can you tell what tools you use and whys  also  what other contexts am i forgetting and do you think it s important to have ,looking suggestions tools development environment context deep reinforcement learning contexts tools using well ones plan use future development environment understand tool library service anything used development environment context current future machine learning scikit learn https tests pytest https tracking weight biases https container docker https ci cd github actions https app streamlit https tell tools use whys also contexts forgetting think important,tools use development environment,tools use development environmentlooking suggestions tools development environment context deep reinforcement learning contexts tools using well ones plan use future development environment understand tool library service anything used development environment context current future machine learning scikit learn https tests pytest https tracking weight biases https container docker https ci cd github actions https app streamlit https tell tools use whys also contexts forgetting think important,"['tools', 'use', 'development', 'environmentlooking', 'suggestions', 'tools', 'development', 'environment', 'context', 'deep', 'reinforcement', 'learning', 'contexts', 'tools', 'using', 'well', 'ones', 'plan', 'use', 'future', 'development', 'environment', 'understand', 'tool', 'library', 'service', 'anything', 'used', 'development', 'environment', 'context', 'current', 'future', 'machine', 'learning', 'scikit', 'learn', 'https', 'tests', 'pytest', 'https', 'tracking', 'weight', 'biases', 'https', 'container', 'docker', 'https', 'ci', 'cd', 'github', 'actions', 'https', 'app', 'streamlit', 'https', 'tell', 'tools', 'use', 'whys', 'also', 'contexts', 'forgetting', 'think', 'important']","['tool', 'use', 'develop', 'environmentlook', 'suggest', 'tool', 'develop', 'environ', 'context', 'deep', 'reinforc', 'learn', 'context', 'tool', 'use', 'well', 'one', 'plan', 'use', 'futur', 'develop', 'environ', 'understand', 'tool', 'librari', 'servic', 'anyth', 'use', 'develop', 'environ', 'context', 'current', 'futur', 'machin', 'learn', 'scikit', 'learn', 'http', 'test', 'pytest', 'http', 'track', 'weight', 'bias', 'http', 'contain', 'docker', 'http', 'ci', 'cd', 'github', 'action', 'http', 'app', 'streamlit', 'http', 'tell', 'tool', 'use', 'whi', 'also', 'context', 'forget', 'think', 'import']"
36,41,41,jeanmidev,wa83br,"[P] For Hearthstone and recsys fans, there is a kaggle competition for you :)","Hello Reddit,
I just published on kaggle a competition around recommender system applied in the context of hearthstone. 

https://www.kaggle.com/competitions/what-card-should-i-select-next

I hope that you will enjoy it (I just dived again in hearthstone, and I am hooked to their battlegrounds mode)",2,29,2022-07-28 15:02:55, p  for hearthstone and recsys fans  there is a kaggle competition for you   ,hello reddit i just published on kaggle a competition around recommender system applied in the context of hearthstone  https i hope that you will enjoy it  i just dived again in hearthstone  and i am hooked to their battlegrounds mode ,hello reddit published kaggle competition around recommender system applied context hearthstone https hope enjoy dived hearthstone hooked battlegrounds mode,p hearthstone recsys fans kaggle competition,p hearthstone recsys fans kaggle competitionhello reddit published kaggle competition around recommender system applied context hearthstone https hope enjoy dived hearthstone hooked battlegrounds mode,"['p', 'hearthstone', 'recsys', 'fans', 'kaggle', 'competitionhello', 'reddit', 'published', 'kaggle', 'competition', 'around', 'recommender', 'system', 'applied', 'context', 'hearthstone', 'https', 'hope', 'enjoy', 'dived', 'hearthstone', 'hooked', 'battlegrounds', 'mode']","['p', 'hearthston', 'recsi', 'fan', 'kaggl', 'competitionhello', 'reddit', 'publish', 'kaggl', 'competit', 'around', 'recommend', 'system', 'appli', 'context', 'hearthston', 'http', 'hope', 'enjoy', 'dive', 'hearthston', 'hook', 'battleground', 'mode']"
37,42,42,saltmind123,waqoaw,[D] Measuring human-level performance,"Hi, I would like to get some advice on how to go about measuring human-level performance (HLP) for an object detection task.

What kind of experiments should I design to measure this, because my ground truths also come from human annotators. Does this mean I am comparing one human annotator against the other to measure the HLP?

How about measuring HLP for image classification?",3,2,2022-07-29 03:54:58, d  measuring human level performance,hi  i would like to get some advice on how to go about measuring human level performance  hlp  for an object detection task what kind of experiments should i design to measure this  because my ground truths also come from human annotators  does this mean i am comparing one human annotator against the other to measure the hlp how about measuring hlp for image classification ,hi would like get advice go measuring human level performance hlp object detection task kind experiments design measure ground truths also come human annotators mean comparing one human annotator measure hlp measuring hlp image classification,measuring human level performance,measuring human level performancehi would like get advice go measuring human level performance hlp object detection task kind experiments design measure ground truths also come human annotators mean comparing one human annotator measure hlp measuring hlp image classification,"['measuring', 'human', 'level', 'performancehi', 'would', 'like', 'get', 'advice', 'go', 'measuring', 'human', 'level', 'performance', 'hlp', 'object', 'detection', 'task', 'kind', 'experiments', 'design', 'measure', 'ground', 'truths', 'also', 'come', 'human', 'annotators', 'mean', 'comparing', 'one', 'human', 'annotator', 'measure', 'hlp', 'measuring', 'hlp', 'image', 'classification']","['measur', 'human', 'level', 'performancehi', 'would', 'like', 'get', 'advic', 'go', 'measur', 'human', 'level', 'perform', 'hlp', 'object', 'detect', 'task', 'kind', 'experi', 'design', 'measur', 'ground', 'truth', 'also', 'come', 'human', 'annot', 'mean', 'compar', 'one', 'human', 'annot', 'measur', 'hlp', 'measur', 'hlp', 'imag', 'classif']"
38,43,43,kermitai,wa1rt0,[D] How important is text preprocessing nowadays with transformer models available?,"Hi everyone!

The headline already sums it up pretty much.

Do we still really need stemming, cleaning etc. as we used to or are the transformer models good and big enough to handle raw data nowadays?

Thanks a lot!",24,60,2022-07-28 09:05:58, d  how important is text preprocessing nowadays with transformer models available ,hi everyone the headline already sums it up pretty much do we still really need stemming  cleaning etc  as we used to or are the transformer models good and big enough to handle raw data nowadays thanks a lot ,hi everyone headline already sums pretty much still really need stemming cleaning etc used transformer models good big enough handle raw data nowadays thanks lot,important text preprocessing nowadays transformer models available,important text preprocessing nowadays transformer models availablehi everyone headline already sums pretty much still really need stemming cleaning etc used transformer models good big enough handle raw data nowadays thanks lot,"['important', 'text', 'preprocessing', 'nowadays', 'transformer', 'models', 'availablehi', 'everyone', 'headline', 'already', 'sums', 'pretty', 'much', 'still', 'really', 'need', 'stemming', 'cleaning', 'etc', 'used', 'transformer', 'models', 'good', 'big', 'enough', 'handle', 'raw', 'data', 'nowadays', 'thanks', 'lot']","['import', 'text', 'preprocess', 'nowaday', 'transform', 'model', 'availablehi', 'everyon', 'headlin', 'alreadi', 'sum', 'pretti', 'much', 'still', 'realli', 'need', 'stem', 'clean', 'etc', 'use', 'transform', 'model', 'good', 'big', 'enough', 'handl', 'raw', 'data', 'nowaday', 'thank', 'lot']"
39,44,44,Kindly-Judgment-1889,way8ld,[D] Which clustering algorithm to use to establish ideal limits?,"I have data which shows the time taken for a process to complete on different dates. I need to establish upper and lower limits on that time duration, to define the ideal time range for that process. If I use clustering then what algorithm to use and if not then what method should I use to achieve this.",7,0,2022-07-29 10:21:45, d  which clustering algorithm to use to establish ideal limits ,i have data which shows the time taken for a process to complete on different dates  i need to establish upper and lower limits on that time duration  to define the ideal time range for that process  if i use clustering then what algorithm to use and if not then what method should i use to achieve this ,data shows time taken process complete different dates need establish upper lower limits time duration define ideal time range process use clustering algorithm use method use achieve,clustering algorithm use establish ideal limits,clustering algorithm use establish ideal limitsdata shows time taken process complete different dates need establish upper lower limits time duration define ideal time range process use clustering algorithm use method use achieve,"['clustering', 'algorithm', 'use', 'establish', 'ideal', 'limitsdata', 'shows', 'time', 'taken', 'process', 'complete', 'different', 'dates', 'need', 'establish', 'upper', 'lower', 'limits', 'time', 'duration', 'define', 'ideal', 'time', 'range', 'process', 'use', 'clustering', 'algorithm', 'use', 'method', 'use', 'achieve']","['cluster', 'algorithm', 'use', 'establish', 'ideal', 'limitsdata', 'show', 'time', 'taken', 'process', 'complet', 'differ', 'date', 'need', 'establish', 'upper', 'lower', 'limit', 'time', 'durat', 'defin', 'ideal', 'time', 'rang', 'process', 'use', 'cluster', 'algorithm', 'use', 'method', 'use', 'achiev']"
40,45,45,stoic-AI,wair84,ML in Production Environments - problems and painpoints? [Discussion] [D],"Hi all,

I'm looking to learn/hear about problems and painpoints that individuals/teams are experiencing when deploying ML products to production? Any insight would be great as I'm keen to avoid headaches as much as possible.

&#x200B;

Thanks",6,6,2022-07-28 22:23:34,ml in production environments   problems and painpoints   discussion   d ,hi all i m looking to learn hear about problems and painpoints that individuals teams are experiencing when deploying ml products to production  any insight would be great as i m keen to avoid headaches as much as possible   xb thanks,hi looking learn hear problems painpoints individuals teams experiencing deploying ml products production insight would great keen avoid headaches much possible xb thanks,ml production environments problems painpoints discussion,ml production environments problems painpoints discussionhi looking learn hear problems painpoints individuals teams experiencing deploying ml products production insight would great keen avoid headaches much possible xb thanks,"['ml', 'production', 'environments', 'problems', 'painpoints', 'discussionhi', 'looking', 'learn', 'hear', 'problems', 'painpoints', 'individuals', 'teams', 'experiencing', 'deploying', 'ml', 'products', 'production', 'insight', 'would', 'great', 'keen', 'avoid', 'headaches', 'much', 'possible', 'xb', 'thanks']","['ml', 'product', 'environ', 'problem', 'painpoint', 'discussionhi', 'look', 'learn', 'hear', 'problem', 'painpoint', 'individu', 'team', 'experienc', 'deploy', 'ml', 'product', 'product', 'insight', 'would', 'great', 'keen', 'avoid', 'headach', 'much', 'possibl', 'xb', 'thank']"
41,46,46,CarrotCakeandGin,wa52pf,[D] Honest/Pragmatic thoughts of AutoML frameworks when it comes to (at least some ) daily work?,"Hi all. 

I work with ML and do a lot of data science on a daily basis and it’s a world I love. I’ve worked hard to get to the knowledge base that I have and I’m quite proud of it. I think a lot of us are. 

But making things happen and get results takes WORK - I need to make sure delivery is happening as well. 

Recently I’ve been exploring the AutoML frameworks from AWS and Google. And they are pretty much “dump some data, select a few options  and ML magic happens in a box”. I came at them pretty negatively - cynically at least. And they are not perfect. If I sit down and work I can beat their outputs usually - but often only by a few points. And that will take me a good half day, or a good day, to make happen. 

The thing is - what I’m seeing is that while they are by no means perfect they are …. Entirely OK. For a lot of the work that I’m doing it’s not about fighting for every point of accuracy it’s about exploring or getting a gut feel for data or pulling out some key facets for a different group within a client. 

There are just as many times when accuracy and quality DOES matter - and in those cases I’m going to stay as close as possible to the models and the features. 

So - I find myself torn on my thoughts about them and was wondering what others thought? Are you staying away from them? Diving in fully? Using them in certain times/use-cases?",5,23,2022-07-28 12:19:42, d  honest pragmatic thoughts of automl frameworks when it comes to  at least some   daily work ,hi all  i work with ml and do a lot of data science on a daily basis and it s a world i love  i ve worked hard to get to the knowledge base that i have and i m quite proud of it  i think a lot of us are  but making things happen and get results takes work   i need to make sure delivery is happening as well  recently i ve been exploring the automl frameworks from aws and google  and they are pretty much  dump some data  select a few options  and ml magic happens in a box   i came at them pretty negatively   cynically at least  and they are not perfect  if i sit down and work i can beat their outputs usually   but often only by a few points  and that will take me a good half day  or a good day  to make happen  the thing is   what i m seeing is that while they are by no means perfect they are    entirely ok  for a lot of the work that i m doing it s not about fighting for every point of accuracy it s about exploring or getting a gut feel for data or pulling out some key facets for a different group within a client  there are just as many times when accuracy and quality does matter   and in those cases i m going to stay as close as possible to the models and the features  so   i find myself torn on my thoughts about them and was wondering what others thought  are you staying away from them  diving in fully  using them in certain times use cases ,hi work ml lot data science daily basis world love worked hard get knowledge base quite proud think lot us making things happen get results takes work need make sure delivery happening well recently exploring automl frameworks aws google pretty much dump data select options ml magic happens box came pretty negatively cynically least perfect sit work beat outputs usually often points take good half day good day make happen thing seeing means perfect entirely ok lot work fighting every point accuracy exploring getting gut feel data pulling key facets different group within client many times accuracy quality matter cases going stay close possible models features find torn thoughts wondering others thought staying away diving fully using certain times use cases,honest pragmatic thoughts automl frameworks comes least daily work,honest pragmatic thoughts automl frameworks comes least daily workhi work ml lot data science daily basis world love worked hard get knowledge base quite proud think lot us making things happen get results takes work need make sure delivery happening well recently exploring automl frameworks aws google pretty much dump data select options ml magic happens box came pretty negatively cynically least perfect sit work beat outputs usually often points take good half day good day make happen thing seeing means perfect entirely ok lot work fighting every point accuracy exploring getting gut feel data pulling key facets different group within client many times accuracy quality matter cases going stay close possible models features find torn thoughts wondering others thought staying away diving fully using certain times use cases,"['honest', 'pragmatic', 'thoughts', 'automl', 'frameworks', 'comes', 'least', 'daily', 'workhi', 'work', 'ml', 'lot', 'data', 'science', 'daily', 'basis', 'world', 'love', 'worked', 'hard', 'get', 'knowledge', 'base', 'quite', 'proud', 'think', 'lot', 'us', 'making', 'things', 'happen', 'get', 'results', 'takes', 'work', 'need', 'make', 'sure', 'delivery', 'happening', 'well', 'recently', 'exploring', 'automl', 'frameworks', 'aws', 'google', 'pretty', 'much', 'dump', 'data', 'select', 'options', 'ml', 'magic', 'happens', 'box', 'came', 'pretty', 'negatively', 'cynically', 'least', 'perfect', 'sit', 'work', 'beat', 'outputs', 'usually', 'often', 'points', 'take', 'good', 'half', 'day', 'good', 'day', 'make', 'happen', 'thing', 'seeing', 'means', 'perfect', 'entirely', 'ok', 'lot', 'work', 'fighting', 'every', 'point', 'accuracy', 'exploring', 'getting', 'gut', 'feel', 'data', 'pulling', 'key', 'facets', 'different', 'group', 'within', 'client', 'many', 'times', 'accuracy', 'quality', 'matter', 'cases', 'going', 'stay', 'close', 'possible', 'models', 'features', 'find', 'torn', 'thoughts', 'wondering', 'others', 'thought', 'staying', 'away', 'diving', 'fully', 'using', 'certain', 'times', 'use', 'cases']","['honest', 'pragmat', 'thought', 'automl', 'framework', 'come', 'least', 'daili', 'workhi', 'work', 'ml', 'lot', 'data', 'scienc', 'daili', 'basi', 'world', 'love', 'work', 'hard', 'get', 'knowledg', 'base', 'quit', 'proud', 'think', 'lot', 'us', 'make', 'thing', 'happen', 'get', 'result', 'take', 'work', 'need', 'make', 'sure', 'deliveri', 'happen', 'well', 'recent', 'explor', 'automl', 'framework', 'aw', 'googl', 'pretti', 'much', 'dump', 'data', 'select', 'option', 'ml', 'magic', 'happen', 'box', 'came', 'pretti', 'neg', 'cynic', 'least', 'perfect', 'sit', 'work', 'beat', 'output', 'usual', 'often', 'point', 'take', 'good', 'half', 'day', 'good', 'day', 'make', 'happen', 'thing', 'see', 'mean', 'perfect', 'entir', 'ok', 'lot', 'work', 'fight', 'everi', 'point', 'accuraci', 'explor', 'get', 'gut', 'feel', 'data', 'pull', 'key', 'facet', 'differ', 'group', 'within', 'client', 'mani', 'time', 'accuraci', 'qualiti', 'matter', 'case', 'go', 'stay', 'close', 'possibl', 'model', 'featur', 'find', 'torn', 'thought', 'wonder', 'other', 'thought', 'stay', 'away', 'dive', 'fulli', 'use', 'certain', 'time', 'use', 'case']"
42,47,47,QLaHPD,wasjbl,"[D] Creating a Dataset of people preferences, so it can be used to predict unknown behavior.","I have been thinking about creating a Dataset that contains the preferences of an individual, so that it can be used to predict the personal choices of someone in an unknown situation. Take for example, we know that:

* John likes to read;
* John likes philosophy;

Based on these two, an AI trained on this Dataset could predict that ""John likes astronomy"", or, ""John likes people who like to read"".

Such a Dataset could be useful for social contexts where you have little information about an individual and not many opportunities to ask questions without it negatively affecting your relationship with that person.

What do you guys think about this idea? What would be the challenges to create a Dataset like this?",5,1,2022-07-29 05:20:48, d  creating a dataset of people preferences  so it can be used to predict unknown behavior ,i have been thinking about creating a dataset that contains the preferences of an individual  so that it can be used to predict the personal choices of someone in an unknown situation  take for example  we know that   john likes to read   john likes philosophy based on these two  an ai trained on this dataset could predict that john likes astronomy  or  john likes people who like to read such a dataset could be useful for social contexts where you have little information about an individual and not many opportunities to ask questions without it negatively affecting your relationship with that person what do you guys think about this idea  what would be the challenges to create a dataset like this ,thinking creating dataset contains preferences individual used predict personal choices someone unknown situation take example know john likes read john likes philosophy based two ai trained dataset could predict john likes astronomy john likes people like read dataset could useful social contexts little information individual many opportunities ask questions without negatively affecting relationship person guys think idea would challenges create dataset like,creating dataset people preferences used predict unknown behavior,creating dataset people preferences used predict unknown behaviorthinking creating dataset contains preferences individual used predict personal choices someone unknown situation take example know john likes read john likes philosophy based two ai trained dataset could predict john likes astronomy john likes people like read dataset could useful social contexts little information individual many opportunities ask questions without negatively affecting relationship person guys think idea would challenges create dataset like,"['creating', 'dataset', 'people', 'preferences', 'used', 'predict', 'unknown', 'behaviorthinking', 'creating', 'dataset', 'contains', 'preferences', 'individual', 'used', 'predict', 'personal', 'choices', 'someone', 'unknown', 'situation', 'take', 'example', 'know', 'john', 'likes', 'read', 'john', 'likes', 'philosophy', 'based', 'two', 'ai', 'trained', 'dataset', 'could', 'predict', 'john', 'likes', 'astronomy', 'john', 'likes', 'people', 'like', 'read', 'dataset', 'could', 'useful', 'social', 'contexts', 'little', 'information', 'individual', 'many', 'opportunities', 'ask', 'questions', 'without', 'negatively', 'affecting', 'relationship', 'person', 'guys', 'think', 'idea', 'would', 'challenges', 'create', 'dataset', 'like']","['creat', 'dataset', 'peopl', 'prefer', 'use', 'predict', 'unknown', 'behaviorthink', 'creat', 'dataset', 'contain', 'prefer', 'individu', 'use', 'predict', 'person', 'choic', 'someon', 'unknown', 'situat', 'take', 'exampl', 'know', 'john', 'like', 'read', 'john', 'like', 'philosophi', 'base', 'two', 'ai', 'train', 'dataset', 'could', 'predict', 'john', 'like', 'astronomi', 'john', 'like', 'peopl', 'like', 'read', 'dataset', 'could', 'use', 'social', 'context', 'littl', 'inform', 'individu', 'mani', 'opportun', 'ask', 'question', 'without', 'neg', 'affect', 'relationship', 'person', 'guy', 'think', 'idea', 'would', 'challeng', 'creat', 'dataset', 'like']"
43,48,48,AB3NZ,waf8yw,How to approach Recommendation System Project [P],"Hello , So during my internship I'll be working on building a recommendation system for an e-commerce website and this is the first time I'll be working on such project.  
I need some advices on how to approach such problems and if there any helpful resources I can use it will be much appreciated.

Thank you.",13,5,2022-07-28 20:04:00,how to approach recommendation system project  p ,hello   so during my internship i ll be working on building a recommendation system for an e commerce website and this is the first time i ll be working on such project   i need some advices on how to approach such problems and if there any helpful resources i can use it will be much appreciated thank you ,hello internship working building recommendation system e commerce website first time working project need advices approach problems helpful resources use much appreciated thank,approach recommendation system project p,approach recommendation system project phello internship working building recommendation system e commerce website first time working project need advices approach problems helpful resources use much appreciated thank,"['approach', 'recommendation', 'system', 'project', 'phello', 'internship', 'working', 'building', 'recommendation', 'system', 'e', 'commerce', 'website', 'first', 'time', 'working', 'project', 'need', 'advices', 'approach', 'problems', 'helpful', 'resources', 'use', 'much', 'appreciated', 'thank']","['approach', 'recommend', 'system', 'project', 'phello', 'internship', 'work', 'build', 'recommend', 'system', 'e', 'commerc', 'websit', 'first', 'time', 'work', 'project', 'need', 'advic', 'approach', 'problem', 'help', 'resourc', 'use', 'much', 'appreci', 'thank']"
44,49,49,ilrazziatore,wap355,[D] Question on Bnns and MC-Dropout,"Hi, i am a student and i was reading about bayesian neural networks and mc-dropout. The book i am reading was published in 2018 ( which means written in 2017), and i know that 5 years are a long time in the deep learning field. i have a doubt that i would like to ask you.

In MC-dropout we approximate the variational posterior as a Bernoulli distribution. doesn't this mean that with mc-dropout we partially lose the ability to adapt the variational distribution to the true a posteriori distribution when compared to a fully variational approach with a generalized mean-field approximation ? In general, is there any disadvantage to using mc-dropout as opposed to a fully variational approach? I was using tensorflow probability with DenseLocalReparameterization layers for a regression problem and now I am wondering whether what I was doing makes sense or if I have complicated my life for no reason and no advantage.

sorry if it's a stupid question.

&#x200B;

ah i would also ask if there is a limit in the dimension of the neural network under which mc-dropout is not a good approximation anymore. My nn is fairly small",2,1,2022-07-29 02:43:13, d  question on bnns and mc dropout,hi  i am a student and i was reading about bayesian neural networks and mc dropout  the book i am reading was published in    which means written in    and i know that  years are a long time in the deep learning field  i have a doubt that i would like to ask you in mc dropout we approximate the variational posterior as a bernoulli distribution  doesn t this mean that with mc dropout we partially lose the ability to adapt the variational distribution to the true a posteriori distribution when compared to a fully variational approach with a generalized mean field approximation   in general  is there any disadvantage to using mc dropout as opposed to a fully variational approach  i was using tensorflow probability with denselocalreparameterization layers for a regression problem and now i am wondering whether what i was doing makes sense or if i have complicated my life for no reason and no advantage sorry if it s a stupid question   xb ah i would also ask if there is a limit in the dimension of the neural network under which mc dropout is not a good approximation anymore  my nn is fairly small,hi student reading bayesian neural networks mc dropout book reading published means written know years long time deep learning field doubt would like ask mc dropout approximate variational posterior bernoulli distribution mean mc dropout partially lose ability adapt variational distribution true posteriori distribution compared fully variational approach generalized mean field approximation general disadvantage using mc dropout opposed fully variational approach using tensorflow probability denselocalreparameterization layers regression problem wondering whether makes sense complicated life reason advantage sorry stupid question xb ah would also ask limit dimension neural network mc dropout good approximation anymore nn fairly small,question bnns mc dropout,question bnns mc dropouthi student reading bayesian neural networks mc dropout book reading published means written know years long time deep learning field doubt would like ask mc dropout approximate variational posterior bernoulli distribution mean mc dropout partially lose ability adapt variational distribution true posteriori distribution compared fully variational approach generalized mean field approximation general disadvantage using mc dropout opposed fully variational approach using tensorflow probability denselocalreparameterization layers regression problem wondering whether makes sense complicated life reason advantage sorry stupid question xb ah would also ask limit dimension neural network mc dropout good approximation anymore nn fairly small,"['question', 'bnns', 'mc', 'dropouthi', 'student', 'reading', 'bayesian', 'neural', 'networks', 'mc', 'dropout', 'book', 'reading', 'published', 'means', 'written', 'know', 'years', 'long', 'time', 'deep', 'learning', 'field', 'doubt', 'would', 'like', 'ask', 'mc', 'dropout', 'approximate', 'variational', 'posterior', 'bernoulli', 'distribution', 'mean', 'mc', 'dropout', 'partially', 'lose', 'ability', 'adapt', 'variational', 'distribution', 'true', 'posteriori', 'distribution', 'compared', 'fully', 'variational', 'approach', 'generalized', 'mean', 'field', 'approximation', 'general', 'disadvantage', 'using', 'mc', 'dropout', 'opposed', 'fully', 'variational', 'approach', 'using', 'tensorflow', 'probability', 'denselocalreparameterization', 'layers', 'regression', 'problem', 'wondering', 'whether', 'makes', 'sense', 'complicated', 'life', 'reason', 'advantage', 'sorry', 'stupid', 'question', 'xb', 'ah', 'would', 'also', 'ask', 'limit', 'dimension', 'neural', 'network', 'mc', 'dropout', 'good', 'approximation', 'anymore', 'nn', 'fairly', 'small']","['question', 'bnn', 'mc', 'dropouthi', 'student', 'read', 'bayesian', 'neural', 'network', 'mc', 'dropout', 'book', 'read', 'publish', 'mean', 'written', 'know', 'year', 'long', 'time', 'deep', 'learn', 'field', 'doubt', 'would', 'like', 'ask', 'mc', 'dropout', 'approxim', 'variat', 'posterior', 'bernoulli', 'distribut', 'mean', 'mc', 'dropout', 'partial', 'lose', 'abil', 'adapt', 'variat', 'distribut', 'true', 'posteriori', 'distribut', 'compar', 'fulli', 'variat', 'approach', 'gener', 'mean', 'field', 'approxim', 'gener', 'disadvantag', 'use', 'mc', 'dropout', 'oppos', 'fulli', 'variat', 'approach', 'use', 'tensorflow', 'probabl', 'denselocalreparameter', 'layer', 'regress', 'problem', 'wonder', 'whether', 'make', 'sens', 'complic', 'life', 'reason', 'advantag', 'sorri', 'stupid', 'question', 'xb', 'ah', 'would', 'also', 'ask', 'limit', 'dimens', 'neural', 'network', 'mc', 'dropout', 'good', 'approxim', 'anymor', 'nn', 'fairli', 'small']"
45,50,50,TypicalAngryRedditor,wanvdz,[P] should I always favor using object tracking when annotating videos for segmentation over not using it?,"I'm currently working on CVAT to annotate videos of an object (the object is constant but the camera is moving) and I have the option of using Object Tracking feature, which tracks the object in every frame and annotates it, which in return will give more segmentation masks than annotating every N the frames manually.

However the downside of using that feature is that in some frames the segmentation mask will not be layed out correctly or be very broken.


So my question is, in that case should I still use Object Tracking despite the downside? On one hand I'll be getting more segmentation masks and therefore more data to train on. But on the other hand some of these masks will be faulty and might corrupt the model.",0,1,2022-07-29 01:50:23, p  should i always favor using object tracking when annotating videos for segmentation over not using it ,i m currently working on cvat to annotate videos of an object  the object is constant but the camera is moving  and i have the option of using object tracking feature  which tracks the object in every frame and annotates it  which in return will give more segmentation masks than annotating every n the frames manually however the downside of using that feature is that in some frames the segmentation mask will not be layed out correctly or be very broken so my question is  in that case should i still use object tracking despite the downside  on one hand i ll be getting more segmentation masks and therefore more data to train on  but on the other hand some of these masks will be faulty and might corrupt the model ,currently working cvat annotate videos object object constant camera moving option using object tracking feature tracks object every frame annotates return give segmentation masks annotating every n frames manually however downside using feature frames segmentation mask layed correctly broken question case still use object tracking despite downside one hand getting segmentation masks therefore data train hand masks faulty might corrupt model,p always favor using object tracking annotating videos segmentation using,p always favor using object tracking annotating videos segmentation usingcurrently working cvat annotate videos object object constant camera moving option using object tracking feature tracks object every frame annotates return give segmentation masks annotating every n frames manually however downside using feature frames segmentation mask layed correctly broken question case still use object tracking despite downside one hand getting segmentation masks therefore data train hand masks faulty might corrupt model,"['p', 'always', 'favor', 'using', 'object', 'tracking', 'annotating', 'videos', 'segmentation', 'usingcurrently', 'working', 'cvat', 'annotate', 'videos', 'object', 'object', 'constant', 'camera', 'moving', 'option', 'using', 'object', 'tracking', 'feature', 'tracks', 'object', 'every', 'frame', 'annotates', 'return', 'give', 'segmentation', 'masks', 'annotating', 'every', 'n', 'frames', 'manually', 'however', 'downside', 'using', 'feature', 'frames', 'segmentation', 'mask', 'layed', 'correctly', 'broken', 'question', 'case', 'still', 'use', 'object', 'tracking', 'despite', 'downside', 'one', 'hand', 'getting', 'segmentation', 'masks', 'therefore', 'data', 'train', 'hand', 'masks', 'faulty', 'might', 'corrupt', 'model']","['p', 'alway', 'favor', 'use', 'object', 'track', 'annot', 'video', 'segment', 'usingcurr', 'work', 'cvat', 'annot', 'video', 'object', 'object', 'constant', 'camera', 'move', 'option', 'use', 'object', 'track', 'featur', 'track', 'object', 'everi', 'frame', 'annot', 'return', 'give', 'segment', 'mask', 'annot', 'everi', 'n', 'frame', 'manual', 'howev', 'downsid', 'use', 'featur', 'frame', 'segment', 'mask', 'lay', 'correctli', 'broken', 'question', 'case', 'still', 'use', 'object', 'track', 'despit', 'downsid', 'one', 'hand', 'get', 'segment', 'mask', 'therefor', 'data', 'train', 'hand', 'mask', 'faulti', 'might', 'corrupt', 'model']"
46,51,51,Kelith7,wa2u5g,[D] Building a paraphrasing tool like Quillbot," Quillbot is an amazing tool for paraphrasing. I used it multiple times while writing peer-reviewed articles and my dissertation thesis. Unfortunately, there's no similar tool that I'm aware of for my language (Italian).  
I was wondering what kind of tools/AImodels I could leverage if I wanted to build it in my native language. Any suggestions are much appreciated.

I'm a web developer with some basic knowledge of AI, ML, and statistics, so you can get as geeky as you like in your explanations :)",1,15,2022-07-28 10:07:00, d  building a paraphrasing tool like quillbot, quillbot is an amazing tool for paraphrasing  i used it multiple times while writing peer reviewed articles and my dissertation thesis  unfortunately  there s no similar tool that i m aware of for my language  italian    i was wondering what kind of tools aimodels i could leverage if i wanted to build it in my native language  any suggestions are much appreciated i m a web developer with some basic knowledge of ai  ml  and statistics  so you can get as geeky as you like in your explanations   ,quillbot amazing tool paraphrasing used multiple times writing peer reviewed articles dissertation thesis unfortunately similar tool aware language italian wondering kind tools aimodels could leverage wanted build native language suggestions much appreciated web developer basic knowledge ai ml statistics get geeky like explanations,building paraphrasing tool like quillbot,building paraphrasing tool like quillbotquillbot amazing tool paraphrasing used multiple times writing peer reviewed articles dissertation thesis unfortunately similar tool aware language italian wondering kind tools aimodels could leverage wanted build native language suggestions much appreciated web developer basic knowledge ai ml statistics get geeky like explanations,"['building', 'paraphrasing', 'tool', 'like', 'quillbotquillbot', 'amazing', 'tool', 'paraphrasing', 'used', 'multiple', 'times', 'writing', 'peer', 'reviewed', 'articles', 'dissertation', 'thesis', 'unfortunately', 'similar', 'tool', 'aware', 'language', 'italian', 'wondering', 'kind', 'tools', 'aimodels', 'could', 'leverage', 'wanted', 'build', 'native', 'language', 'suggestions', 'much', 'appreciated', 'web', 'developer', 'basic', 'knowledge', 'ai', 'ml', 'statistics', 'get', 'geeky', 'like', 'explanations']","['build', 'paraphras', 'tool', 'like', 'quillbotquillbot', 'amaz', 'tool', 'paraphras', 'use', 'multipl', 'time', 'write', 'peer', 'review', 'articl', 'dissert', 'thesi', 'unfortun', 'similar', 'tool', 'awar', 'languag', 'italian', 'wonder', 'kind', 'tool', 'aimodel', 'could', 'leverag', 'want', 'build', 'nativ', 'languag', 'suggest', 'much', 'appreci', 'web', 'develop', 'basic', 'knowledg', 'ai', 'ml', 'statist', 'get', 'geeki', 'like', 'explan']"
47,52,52,PetarVelickovic,w9lu7t,[R] Geometric Deep Learning Lecture Course (AMMI'22),"Hi everyone,

I am pleased to share with you all, our new & improved material for diving into geometric deep learning!

For a second year in a row, Michael Bronstein (Oxford / Twitter), Joan Bruna (NYU), Taco Cohen (Qualcomm) and I have delivered our Master's course on Geometric DL for the African Master's in Machine Intelligence, designed to closely follow our [proto-book](https://arxiv.org/abs/2104.13478) released last year. We make all materials publicly available!

[https://geometricdeeplearning.com/lectures/](https://geometricdeeplearning.com/lectures/)

For 2022, we made careful modifications to our content, making it more streamlined and (hopefully) more accessible! This features, among other things:

* A revamped introductory lecture, with a plethora of new historical context on deep learning and geometry;
* Clearer discussion of Transformers, and how they fit into our framework;
* A new lecture going beyond groups, into the realm of category theory!

Beyond this, we offer a set of five exciting guest seminars, exploring various advanced topics and perspectives for future work on geometric DL:

* Francesco Di Giovanni (Twitter): Physics-based GNNs
* Fabrizio Frasca (Twitter / Imperial): Subgraph GNNs
* Geordie Williamson (U. Sydney): Representation Theory in ML
* Cristian Bodnar (Cambridge): Neural Sheaf Diffusion
* Russ Bates (DeepMind): AlphaFold 2

Further, if you would like to sharpen your coding skills in GDL, we also make available several Colab tutorials, from Cristian Bodnar, Iulia Duță, Paul Scherer, Gabriele Cesa, Charlie Harris, Chaitanya Joshi and Ramon Viñas.

This course would not have been made possible without support from the African Institute for Mathematical Sciences. We specially thank Moustapha Cisse, Teta Bahunde, and Kobby Panford-Quainoo (and the entire wider TA team for the course) for their constant support!

Just like last year, we very much hope you will enjoy our materials, which we made freely accessible to everyone, free of charge! And of course, we welcome any and all feedback, especially as we work towards finalising our full book for publication with MIT Press in 2023!",12,157,2022-07-27 21:14:47, r  geometric deep learning lecture course  ammi  ,hi everyone i am pleased to share with you all  our new   improved material for diving into geometric deep learning for a second year in a row  michael bronstein  oxford   twitter   joan bruna  nyu   taco cohen  qualcomm  and i have delivered our master s course on geometric dl for the african master s in machine intelligence  designed to closely follow our  proto book  https  https for   we made careful modifications to our content  making it more streamlined and  hopefully  more accessible  this features  among other things   a revamped introductory lecture  with a plethora of new historical context on deep learning and geometry   clearer discussion of transformers  and how they fit into our framework   a new lecture going beyond groups  into the realm of category theory beyond this  we offer a set of five exciting guest seminars  exploring various advanced topics and perspectives for future work on geometric dl   francesco di giovanni  twitter   physics based gnns  fabrizio frasca  twitter   imperial   subgraph gnns  geordie williamson  u  sydney   representation theory in ml  cristian bodnar  cambridge   neural sheaf diffusion  russ bates  deepmind   alphafold further  if you would like to sharpen your coding skills in gdl  we also make available several colab tutorials  from cristian bodnar  iulia duță  paul scherer  gabriele cesa  charlie harris  chaitanya joshi and ramon viñas this course would not have been made possible without support from the african institute for mathematical sciences  we specially thank moustapha cisse  teta bahunde  and kobby panford quainoo  and the entire wider ta team for the course  for their constant support just like last year  we very much hope you will enjoy our materials  which we made freely accessible to everyone  free of charge  and of course  we welcome any and all feedback  especially as we work towards finalising our full book for publication with mit press in  ,hi everyone pleased share improved material diving geometric deep learning second year row michael bronstein oxford twitter joan bruna nyu taco cohen qualcomm delivered master course geometric dl african master machine intelligence designed closely follow proto book https https made careful modifications content making streamlined hopefully accessible features among things revamped introductory lecture plethora historical context deep learning geometry clearer discussion transformers fit framework lecture going beyond groups realm category theory beyond offer set five exciting guest seminars exploring various advanced topics perspectives future work geometric dl francesco di giovanni twitter physics based gnns fabrizio frasca twitter imperial subgraph gnns geordie williamson u sydney representation theory ml cristian bodnar cambridge neural sheaf diffusion russ bates deepmind alphafold would like sharpen coding skills gdl also make available several colab tutorials cristian bodnar iulia duță paul scherer gabriele cesa charlie harris chaitanya joshi ramon viñas course would made possible without support african institute mathematical sciences specially thank moustapha cisse teta bahunde kobby panford quainoo entire wider ta team course constant support like last year much hope enjoy materials made freely accessible everyone free charge course welcome feedback especially work towards finalising full book publication mit press,r geometric deep learning lecture course ammi,r geometric deep learning lecture course ammihi everyone pleased share improved material diving geometric deep learning second year row michael bronstein oxford twitter joan bruna nyu taco cohen qualcomm delivered master course geometric dl african master machine intelligence designed closely follow proto book https https made careful modifications content making streamlined hopefully accessible features among things revamped introductory lecture plethora historical context deep learning geometry clearer discussion transformers fit framework lecture going beyond groups realm category theory beyond offer set five exciting guest seminars exploring various advanced topics perspectives future work geometric dl francesco di giovanni twitter physics based gnns fabrizio frasca twitter imperial subgraph gnns geordie williamson u sydney representation theory ml cristian bodnar cambridge neural sheaf diffusion russ bates deepmind alphafold would like sharpen coding skills gdl also make available several colab tutorials cristian bodnar iulia duță paul scherer gabriele cesa charlie harris chaitanya joshi ramon viñas course would made possible without support african institute mathematical sciences specially thank moustapha cisse teta bahunde kobby panford quainoo entire wider ta team course constant support like last year much hope enjoy materials made freely accessible everyone free charge course welcome feedback especially work towards finalising full book publication mit press,"['r', 'geometric', 'deep', 'learning', 'lecture', 'course', 'ammihi', 'everyone', 'pleased', 'share', 'improved', 'material', 'diving', 'geometric', 'deep', 'learning', 'second', 'year', 'row', 'michael', 'bronstein', 'oxford', 'twitter', 'joan', 'bruna', 'nyu', 'taco', 'cohen', 'qualcomm', 'delivered', 'master', 'course', 'geometric', 'dl', 'african', 'master', 'machine', 'intelligence', 'designed', 'closely', 'follow', 'proto', 'book', 'https', 'https', 'made', 'careful', 'modifications', 'content', 'making', 'streamlined', 'hopefully', 'accessible', 'features', 'among', 'things', 'revamped', 'introductory', 'lecture', 'plethora', 'historical', 'context', 'deep', 'learning', 'geometry', 'clearer', 'discussion', 'transformers', 'fit', 'framework', 'lecture', 'going', 'beyond', 'groups', 'realm', 'category', 'theory', 'beyond', 'offer', 'set', 'five', 'exciting', 'guest', 'seminars', 'exploring', 'various', 'advanced', 'topics', 'perspectives', 'future', 'work', 'geometric', 'dl', 'francesco', 'di', 'giovanni', 'twitter', 'physics', 'based', 'gnns', 'fabrizio', 'frasca', 'twitter', 'imperial', 'subgraph', 'gnns', 'geordie', 'williamson', 'u', 'sydney', 'representation', 'theory', 'ml', 'cristian', 'bodnar', 'cambridge', 'neural', 'sheaf', 'diffusion', 'russ', 'bates', 'deepmind', 'alphafold', 'would', 'like', 'sharpen', 'coding', 'skills', 'gdl', 'also', 'make', 'available', 'several', 'colab', 'tutorials', 'cristian', 'bodnar', 'iulia', 'duță', 'paul', 'scherer', 'gabriele', 'cesa', 'charlie', 'harris', 'chaitanya', 'joshi', 'ramon', 'viñas', 'course', 'would', 'made', 'possible', 'without', 'support', 'african', 'institute', 'mathematical', 'sciences', 'specially', 'thank', 'moustapha', 'cisse', 'teta', 'bahunde', 'kobby', 'panford', 'quainoo', 'entire', 'wider', 'ta', 'team', 'course', 'constant', 'support', 'like', 'last', 'year', 'much', 'hope', 'enjoy', 'materials', 'made', 'freely', 'accessible', 'everyone', 'free', 'charge', 'course', 'welcome', 'feedback', 'especially', 'work', 'towards', 'finalising', 'full', 'book', 'publication', 'mit', 'press']","['r', 'geometr', 'deep', 'learn', 'lectur', 'cours', 'ammihi', 'everyon', 'pleas', 'share', 'improv', 'materi', 'dive', 'geometr', 'deep', 'learn', 'second', 'year', 'row', 'michael', 'bronstein', 'oxford', 'twitter', 'joan', 'bruna', 'nyu', 'taco', 'cohen', 'qualcomm', 'deliv', 'master', 'cours', 'geometr', 'dl', 'african', 'master', 'machin', 'intellig', 'design', 'close', 'follow', 'proto', 'book', 'http', 'http', 'made', 'care', 'modif', 'content', 'make', 'streamlin', 'hope', 'access', 'featur', 'among', 'thing', 'revamp', 'introductori', 'lectur', 'plethora', 'histor', 'context', 'deep', 'learn', 'geometri', 'clearer', 'discuss', 'transform', 'fit', 'framework', 'lectur', 'go', 'beyond', 'group', 'realm', 'categori', 'theori', 'beyond', 'offer', 'set', 'five', 'excit', 'guest', 'seminar', 'explor', 'variou', 'advanc', 'topic', 'perspect', 'futur', 'work', 'geometr', 'dl', 'francesco', 'di', 'giovanni', 'twitter', 'physic', 'base', 'gnn', 'fabrizio', 'frasca', 'twitter', 'imperi', 'subgraph', 'gnn', 'geordi', 'williamson', 'u', 'sydney', 'represent', 'theori', 'ml', 'cristian', 'bodnar', 'cambridg', 'neural', 'sheaf', 'diffus', 'russ', 'bate', 'deepmind', 'alphafold', 'would', 'like', 'sharpen', 'code', 'skill', 'gdl', 'also', 'make', 'avail', 'sever', 'colab', 'tutori', 'cristian', 'bodnar', 'iulia', 'duță', 'paul', 'scherer', 'gabriel', 'cesa', 'charli', 'harri', 'chaitanya', 'joshi', 'ramon', 'viña', 'cours', 'would', 'made', 'possibl', 'without', 'support', 'african', 'institut', 'mathemat', 'scienc', 'special', 'thank', 'moustapha', 'ciss', 'teta', 'bahund', 'kobbi', 'panford', 'quainoo', 'entir', 'wider', 'ta', 'team', 'cours', 'constant', 'support', 'like', 'last', 'year', 'much', 'hope', 'enjoy', 'materi', 'made', 'freeli', 'access', 'everyon', 'free', 'charg', 'cours', 'welcom', 'feedback', 'especi', 'work', 'toward', 'finalis', 'full', 'book', 'public', 'mit', 'press']"
48,53,53,MC_Dropout,walvaq,[D] Typical compute requirements for the training of a transformer-based recommender systems.,"I recently moved from NLP to recommender systems and I've noticed that most papers seem to not address how many resources it took to train their models.

This has proven slightly frustrating as I'm currently trying to scope out what a manageable first proof of concept would look like. From my background in NLP, I know that the self-supervised training from scratch of such models takes a while but I'm not sure to what extent this is true for time series data.

Has anyone here used something akin to Bert4rec or anything in the Transformer4rec library? What is your experience with your particular dataset/compute capability/model?",2,1,2022-07-29 00:27:28, d  typical compute requirements for the training of a transformer based recommender systems ,i recently moved from nlp to recommender systems and i ve noticed that most papers seem to not address how many resources it took to train their models this has proven slightly frustrating as i m currently trying to scope out what a manageable first proof of concept would look like  from my background in nlp  i know that the self supervised training from scratch of such models takes a while but i m not sure to what extent this is true for time series data has anyone here used something akin to bertrec or anything in the transformerrec library  what is your experience with your particular dataset compute capability model ,recently moved nlp recommender systems noticed papers seem address many resources took train models proven slightly frustrating currently trying scope manageable first proof concept would look like background nlp know self supervised training scratch models takes sure extent true time series data anyone used something akin bertrec anything transformerrec library experience particular dataset compute capability model,typical compute requirements training transformer based recommender systems,typical compute requirements training transformer based recommender systemsrecently moved nlp recommender systems noticed papers seem address many resources took train models proven slightly frustrating currently trying scope manageable first proof concept would look like background nlp know self supervised training scratch models takes sure extent true time series data anyone used something akin bertrec anything transformerrec library experience particular dataset compute capability model,"['typical', 'compute', 'requirements', 'training', 'transformer', 'based', 'recommender', 'systemsrecently', 'moved', 'nlp', 'recommender', 'systems', 'noticed', 'papers', 'seem', 'address', 'many', 'resources', 'took', 'train', 'models', 'proven', 'slightly', 'frustrating', 'currently', 'trying', 'scope', 'manageable', 'first', 'proof', 'concept', 'would', 'look', 'like', 'background', 'nlp', 'know', 'self', 'supervised', 'training', 'scratch', 'models', 'takes', 'sure', 'extent', 'true', 'time', 'series', 'data', 'anyone', 'used', 'something', 'akin', 'bertrec', 'anything', 'transformerrec', 'library', 'experience', 'particular', 'dataset', 'compute', 'capability', 'model']","['typic', 'comput', 'requir', 'train', 'transform', 'base', 'recommend', 'systemsrec', 'move', 'nlp', 'recommend', 'system', 'notic', 'paper', 'seem', 'address', 'mani', 'resourc', 'took', 'train', 'model', 'proven', 'slightli', 'frustrat', 'current', 'tri', 'scope', 'manag', 'first', 'proof', 'concept', 'would', 'look', 'like', 'background', 'nlp', 'know', 'self', 'supervis', 'train', 'scratch', 'model', 'take', 'sure', 'extent', 'true', 'time', 'seri', 'data', 'anyon', 'use', 'someth', 'akin', 'bertrec', 'anyth', 'transformerrec', 'librari', 'experi', 'particular', 'dataset', 'comput', 'capabl', 'model']"
49,54,54,Actual_banana_2002,wairv6,[D] Did anyone get into any AI residency right after the Bachelors/ undergraduate studies ?,I am an undergraduate student from India. I am planning on applying for all the AI residencies. What is expected from an undergraduate applicant with good technical skills and academic record,2,0,2022-07-28 22:24:18, d  did anyone get into any ai residency right after the bachelors  undergraduate studies  ,i am an undergraduate student from india  i am planning on applying for all the ai residencies  what is expected from an undergraduate applicant with good technical skills and academic record,undergraduate student india planning applying ai residencies expected undergraduate applicant good technical skills academic record,anyone get ai residency right bachelors undergraduate studies,anyone get ai residency right bachelors undergraduate studiesundergraduate student india planning applying ai residencies expected undergraduate applicant good technical skills academic record,"['anyone', 'get', 'ai', 'residency', 'right', 'bachelors', 'undergraduate', 'studiesundergraduate', 'student', 'india', 'planning', 'applying', 'ai', 'residencies', 'expected', 'undergraduate', 'applicant', 'good', 'technical', 'skills', 'academic', 'record']","['anyon', 'get', 'ai', 'resid', 'right', 'bachelor', 'undergradu', 'studiesundergradu', 'student', 'india', 'plan', 'appli', 'ai', 'resid', 'expect', 'undergradu', 'applic', 'good', 'technic', 'skill', 'academ', 'record']"
50,55,55,Jan2579,w9ec2e,[P] I Made An Easy-To-Use Python Package That Creates Beautiful Html Reports From Jupyter Notebooks,"**Pretty Jupyter** is an easy-to-use package that creates beautifully styled and dynamic html webpage from Jupyter notebook. Its repo is available here: [https://github.com/JanPalasek/pretty-jupyter](https://github.com/JanPalasek/pretty-jupyter) .

Check out the [**demo**](http://janpalasek.com/pretty-jupyter-example.html) and compare it with the [default jupyter](http://janpalasek.com/classic-jupyter-example.html). You can try also Pretty Jupyter [online](http://janpalasek.com/pretty-jupyter.html) without the need to install it.

**Main Features**

* Visually appealing styles.
* Automatic Table of Contents generation.
* Tabsets: Tabs that hold section content inside them.
* Using Python variables in Markdown: Helps in creating dynamic reports.
* Code Folding: Show/Hide code to filter out unnecessary content.",32,197,2022-07-27 16:07:45, p  i made an easy to use python package that creates beautiful html reports from jupyter notebooks,  pretty jupyter   is an easy to use package that creates beautifully styled and dynamic html webpage from jupyter notebook  its repo is available here   https check out the    demo    http   main features    visually appealing styles   automatic table of contents generation   tabsets  tabs that hold section content inside them   using python variables in markdown  helps in creating dynamic reports   code folding  show hide code to filter out unnecessary content ,pretty jupyter easy use package creates beautifully styled dynamic html webpage jupyter notebook repo available https check demo http main features visually appealing styles automatic table contents generation tabsets tabs hold section content inside using python variables markdown helps creating dynamic reports code folding show hide code filter unnecessary content,p made easy use python package creates beautiful html reports jupyter notebooks,p made easy use python package creates beautiful html reports jupyter notebookspretty jupyter easy use package creates beautifully styled dynamic html webpage jupyter notebook repo available https check demo http main features visually appealing styles automatic table contents generation tabsets tabs hold section content inside using python variables markdown helps creating dynamic reports code folding show hide code filter unnecessary content,"['p', 'made', 'easy', 'use', 'python', 'package', 'creates', 'beautiful', 'html', 'reports', 'jupyter', 'notebookspretty', 'jupyter', 'easy', 'use', 'package', 'creates', 'beautifully', 'styled', 'dynamic', 'html', 'webpage', 'jupyter', 'notebook', 'repo', 'available', 'https', 'check', 'demo', 'http', 'main', 'features', 'visually', 'appealing', 'styles', 'automatic', 'table', 'contents', 'generation', 'tabsets', 'tabs', 'hold', 'section', 'content', 'inside', 'using', 'python', 'variables', 'markdown', 'helps', 'creating', 'dynamic', 'reports', 'code', 'folding', 'show', 'hide', 'code', 'filter', 'unnecessary', 'content']","['p', 'made', 'easi', 'use', 'python', 'packag', 'creat', 'beauti', 'html', 'report', 'jupyt', 'notebookspretti', 'jupyt', 'easi', 'use', 'packag', 'creat', 'beauti', 'style', 'dynam', 'html', 'webpag', 'jupyt', 'notebook', 'repo', 'avail', 'http', 'check', 'demo', 'http', 'main', 'featur', 'visual', 'appeal', 'style', 'automat', 'tabl', 'content', 'gener', 'tabset', 'tab', 'hold', 'section', 'content', 'insid', 'use', 'python', 'variabl', 'markdown', 'help', 'creat', 'dynam', 'report', 'code', 'fold', 'show', 'hide', 'code', 'filter', 'unnecessari', 'content']"
51,57,57,PlayboiCult,wan8gn,[D] Switching from Blockchain development to ML," 

My main skills were solidity and web development. Obviously, I don't think my solidity skills will be useful here, but will my web development skills have some form of value in my journey? Or is it all python?

Also, any recommendations or thoughts of moving from Blockchain to ML and AI are welcomed.

Thanks",1,0,2022-07-29 01:23:01, d  switching from blockchain development to ml, my main skills were solidity and web development  obviously  i don t think my solidity skills will be useful here  but will my web development skills have some form of value in my journey  or is it all python also  any recommendations or thoughts of moving from blockchain to ml and ai are welcomed thanks,main skills solidity web development obviously think solidity skills useful web development skills form value journey python also recommendations thoughts moving blockchain ml ai welcomed thanks,switching blockchain development ml,switching blockchain development mlmain skills solidity web development obviously think solidity skills useful web development skills form value journey python also recommendations thoughts moving blockchain ml ai welcomed thanks,"['switching', 'blockchain', 'development', 'mlmain', 'skills', 'solidity', 'web', 'development', 'obviously', 'think', 'solidity', 'skills', 'useful', 'web', 'development', 'skills', 'form', 'value', 'journey', 'python', 'also', 'recommendations', 'thoughts', 'moving', 'blockchain', 'ml', 'ai', 'welcomed', 'thanks']","['switch', 'blockchain', 'develop', 'mlmain', 'skill', 'solid', 'web', 'develop', 'obvious', 'think', 'solid', 'skill', 'use', 'web', 'develop', 'skill', 'form', 'valu', 'journey', 'python', 'also', 'recommend', 'thought', 'move', 'blockchain', 'ml', 'ai', 'welcom', 'thank']"
52,59,59,THE_REAL_ODB,w9ym12,[D]What are some common sticking points in this field?,"Many people try to improve but either quit or get stuck real quick and not able to advance to the next level in this field.

From your experience and perspective, what are the most common things that need to learned for practitioners to get over the hump?",2,7,2022-07-28 06:22:07, d what are some common sticking points in this field ,many people try to improve but either quit or get stuck real quick and not able to advance to the next level in this field from your experience and perspective  what are the most common things that need to learned for practitioners to get over the hump ,many people try improve either quit get stuck real quick able advance next level field experience perspective common things need learned practitioners get hump,common sticking points field,common sticking points fieldmany people try improve either quit get stuck real quick able advance next level field experience perspective common things need learned practitioners get hump,"['common', 'sticking', 'points', 'fieldmany', 'people', 'try', 'improve', 'either', 'quit', 'get', 'stuck', 'real', 'quick', 'able', 'advance', 'next', 'level', 'field', 'experience', 'perspective', 'common', 'things', 'need', 'learned', 'practitioners', 'get', 'hump']","['common', 'stick', 'point', 'fieldmani', 'peopl', 'tri', 'improv', 'either', 'quit', 'get', 'stuck', 'real', 'quick', 'abl', 'advanc', 'next', 'level', 'field', 'experi', 'perspect', 'common', 'thing', 'need', 'learn', 'practition', 'get', 'hump']"
53,60,60,bruziuz,wa0peu,[R] [P] FL_PyTorch: Optimization Research Simulator for Federated Learning is publicly available on GitHub.,"FL_PyTorch: Optimization Research Simulator for Federated Learning is publicly available on GitHub.

https://burlachenkok.github.io/FL_PyTorch-Available-As-Open-Source/

Repository: https://github.com/burlachenkok/flpytorch

Slack Workspace: https://fl-pytorch.slack.com/

The invitation Link: https://join.slack.com/t/fl-pytorch/shared_invite/zt-1cjkjct9c-1wuFdrbVT4LcrAcjyj_gBw

The arXiv link for the paper: https://arxiv.org/abs/2202.03099

FL_PyTorch is a suite of open-source software written in python that builds on top of one of the most popular research Deep Learning (DL) frameworks PyTorch. We built FL_PyTorch as a research simulator for FL to enable fast development, prototyping, and experimenting with new and existing FL optimization algorithms. Our system supports abstractions that provide researchers with sufficient flexibility to experiment with existing and novel approaches to advance the state-of-the-art. The work is in proceedings of the 2nd International Workshop on Distributed Machine Learning DistributedML 2021.",0,4,2022-07-28 08:07:57, r   p  fl_pytorch  optimization research simulator for federated learning is publicly available on github ,fl_pytorch  optimization research simulator for federated learning is publicly available on github https repository  https slack workspace  https the invitation link  https the arxiv link for the paper  https fl_pytorch is a suite of open source software written in python that builds on top of one of the most popular research deep learning  dl  frameworks pytorch  we built fl_pytorch as a research simulator for fl to enable fast development  prototyping  and experimenting with new and existing fl optimization algorithms  our system supports abstractions that provide researchers with sufficient flexibility to experiment with existing and novel approaches to advance the state of the art  the work is in proceedings of the nd international workshop on distributed machine learning distributedml  ,fl_pytorch optimization research simulator federated learning publicly available github https repository https slack workspace https invitation link https arxiv link paper https fl_pytorch suite open source software written python builds top one popular research deep learning dl frameworks pytorch built fl_pytorch research simulator fl enable fast development prototyping experimenting existing fl optimization algorithms system supports abstractions provide researchers sufficient flexibility experiment existing novel approaches advance state art work proceedings nd international workshop distributed machine learning distributedml,r p fl_pytorch optimization research simulator federated learning publicly available github,r p fl_pytorch optimization research simulator federated learning publicly available githubfl_pytorch optimization research simulator federated learning publicly available github https repository https slack workspace https invitation link https arxiv link paper https fl_pytorch suite open source software written python builds top one popular research deep learning dl frameworks pytorch built fl_pytorch research simulator fl enable fast development prototyping experimenting existing fl optimization algorithms system supports abstractions provide researchers sufficient flexibility experiment existing novel approaches advance state art work proceedings nd international workshop distributed machine learning distributedml,"['r', 'p', 'fl_pytorch', 'optimization', 'research', 'simulator', 'federated', 'learning', 'publicly', 'available', 'githubfl_pytorch', 'optimization', 'research', 'simulator', 'federated', 'learning', 'publicly', 'available', 'github', 'https', 'repository', 'https', 'slack', 'workspace', 'https', 'invitation', 'link', 'https', 'arxiv', 'link', 'paper', 'https', 'fl_pytorch', 'suite', 'open', 'source', 'software', 'written', 'python', 'builds', 'top', 'one', 'popular', 'research', 'deep', 'learning', 'dl', 'frameworks', 'pytorch', 'built', 'fl_pytorch', 'research', 'simulator', 'fl', 'enable', 'fast', 'development', 'prototyping', 'experimenting', 'existing', 'fl', 'optimization', 'algorithms', 'system', 'supports', 'abstractions', 'provide', 'researchers', 'sufficient', 'flexibility', 'experiment', 'existing', 'novel', 'approaches', 'advance', 'state', 'art', 'work', 'proceedings', 'nd', 'international', 'workshop', 'distributed', 'machine', 'learning', 'distributedml']","['r', 'p', 'fl_pytorch', 'optim', 'research', 'simul', 'feder', 'learn', 'publicli', 'avail', 'githubfl_pytorch', 'optim', 'research', 'simul', 'feder', 'learn', 'publicli', 'avail', 'github', 'http', 'repositori', 'http', 'slack', 'workspac', 'http', 'invit', 'link', 'http', 'arxiv', 'link', 'paper', 'http', 'fl_pytorch', 'suit', 'open', 'sourc', 'softwar', 'written', 'python', 'build', 'top', 'one', 'popular', 'research', 'deep', 'learn', 'dl', 'framework', 'pytorch', 'built', 'fl_pytorch', 'research', 'simul', 'fl', 'enabl', 'fast', 'develop', 'prototyp', 'experi', 'exist', 'fl', 'optim', 'algorithm', 'system', 'support', 'abstract', 'provid', 'research', 'suffici', 'flexibl', 'experi', 'exist', 'novel', 'approach', 'advanc', 'state', 'art', 'work', 'proceed', 'nd', 'intern', 'workshop', 'distribut', 'machin', 'learn', 'distributedml']"
54,61,61,TheBloneRanger,w9ecl8,"What is the ""major bottleneck"" for ""self driving cars""? ""[D]""","Question 1) I was wondering if anyone here can ELI5 (or even idiot-er) could explain something about ""the major bottleneck"" that I keep reading about with ""error processing"" or whatever is ""the major issue"" with Tesla. 

For the record, this is not laziness but practicality. There is simply too much to keep up with and I am too busy tryin' to survive.

If anyone is willing to help me, I thank you in advance. 

(I just wanna keep up, but I can't get it done alone. Sad face)

**JUST CHECKING IN WITH AN EDIT AT 10:30 AM OR SO:**

Question 2) So, from what I gather, the issue is, no one really knows why in the hells error checking does not work? Am I understanding that correctly? 

If you answered post edit can you reference if you are answering question 1 or question 2. You do not have to, but it would help my scattered mind!",191,69,2022-07-27 16:08:23,what is the major bottleneck for self driving cars   d ,question   i was wondering if anyone here can eli  or even idiot er  could explain something about the major bottleneck that i keep reading about with error processing or whatever is the major issue with tesla  for the record  this is not laziness but practicality  there is simply too much to keep up with and i am too busy tryin  to survive if anyone is willing to help me  i thank you in advance   i just wanna keep up  but i can t get it done alone  sad face   just checking in with an edit at   am or so   question   so  from what i gather  the issue is  no one really knows why in the hells error checking does not work  am i understanding that correctly  if you answered post edit can you reference if you are answering question  or question   you do not have to  but it would help my scattered mind ,question wondering anyone eli even idiot er could explain something major bottleneck keep reading error processing whatever major issue tesla record laziness practicality simply much keep busy tryin survive anyone willing help thank advance wanna keep get done alone sad face checking edit question gather issue one really knows hells error checking work understanding correctly answered post edit reference answering question question would help scattered mind,major bottleneck self driving cars,major bottleneck self driving carsquestion wondering anyone eli even idiot er could explain something major bottleneck keep reading error processing whatever major issue tesla record laziness practicality simply much keep busy tryin survive anyone willing help thank advance wanna keep get done alone sad face checking edit question gather issue one really knows hells error checking work understanding correctly answered post edit reference answering question question would help scattered mind,"['major', 'bottleneck', 'self', 'driving', 'carsquestion', 'wondering', 'anyone', 'eli', 'even', 'idiot', 'er', 'could', 'explain', 'something', 'major', 'bottleneck', 'keep', 'reading', 'error', 'processing', 'whatever', 'major', 'issue', 'tesla', 'record', 'laziness', 'practicality', 'simply', 'much', 'keep', 'busy', 'tryin', 'survive', 'anyone', 'willing', 'help', 'thank', 'advance', 'wan', 'na', 'keep', 'get', 'done', 'alone', 'sad', 'face', 'checking', 'edit', 'question', 'gather', 'issue', 'one', 'really', 'knows', 'hells', 'error', 'checking', 'work', 'understanding', 'correctly', 'answered', 'post', 'edit', 'reference', 'answering', 'question', 'question', 'would', 'help', 'scattered', 'mind']","['major', 'bottleneck', 'self', 'drive', 'carsquest', 'wonder', 'anyon', 'eli', 'even', 'idiot', 'er', 'could', 'explain', 'someth', 'major', 'bottleneck', 'keep', 'read', 'error', 'process', 'whatev', 'major', 'issu', 'tesla', 'record', 'lazi', 'practic', 'simpli', 'much', 'keep', 'busi', 'tryin', 'surviv', 'anyon', 'will', 'help', 'thank', 'advanc', 'wan', 'na', 'keep', 'get', 'done', 'alon', 'sad', 'face', 'check', 'edit', 'question', 'gather', 'issu', 'one', 'realli', 'know', 'hell', 'error', 'check', 'work', 'understand', 'correctli', 'answer', 'post', 'edit', 'refer', 'answer', 'question', 'question', 'would', 'help', 'scatter', 'mind']"
55,62,62,Sea-Photo5230,wa2uu8,Chest X-ray Network :Simplified Transfer Learning for Chest Radiography Model Development [R],"Researchers have added an additional step of pre training  a generic image deep learning model on 800k chest x-ray images using supervised contrartsive learning using noisy labels from radiology reports. Image embeddings generated from this network can then be used for tasks like abnormality detection on a smaller set of chest x-ray images  They have also released a chest foundation tool for generating image embeddings for chest x-ray.   I liked the idea behind this paper and I believe it can also be extended to other medical imaging modalities like MR,CT. I have made a video on the same . Do checkout :
https://youtu.be/lyhG6hivJqw",0,0,2022-07-28 10:08:03,chest x ray network  simplified transfer learning for chest radiography model development  r ,researchers have added an additional step of pre training  a generic image deep learning model on k chest x ray images using supervised contrartsive learning using noisy labels from radiology reports  image embeddings generated from this network can then be used for tasks like abnormality detection on a smaller set of chest x ray images  they have also released a chest foundation tool for generating image embeddings for chest x ray    i liked the idea behind this paper and i believe it can also be extended to other medical imaging modalities like mr ct  i have made a video on the same   do checkout  https   youtu be lyhghivjqw,researchers added additional step pre training generic image deep learning model k chest x ray images using supervised contrartsive learning using noisy labels radiology reports image embeddings generated network used tasks like abnormality detection smaller set chest x ray images also released chest foundation tool generating image embeddings chest x ray liked idea behind paper believe also extended medical imaging modalities like mr ct made video checkout https youtu lyhghivjqw,chest x ray network simplified transfer learning chest radiography model development r,chest x ray network simplified transfer learning chest radiography model development rresearchers added additional step pre training generic image deep learning model k chest x ray images using supervised contrartsive learning using noisy labels radiology reports image embeddings generated network used tasks like abnormality detection smaller set chest x ray images also released chest foundation tool generating image embeddings chest x ray liked idea behind paper believe also extended medical imaging modalities like mr ct made video checkout https youtu lyhghivjqw,"['chest', 'x', 'ray', 'network', 'simplified', 'transfer', 'learning', 'chest', 'radiography', 'model', 'development', 'rresearchers', 'added', 'additional', 'step', 'pre', 'training', 'generic', 'image', 'deep', 'learning', 'model', 'k', 'chest', 'x', 'ray', 'images', 'using', 'supervised', 'contrartsive', 'learning', 'using', 'noisy', 'labels', 'radiology', 'reports', 'image', 'embeddings', 'generated', 'network', 'used', 'tasks', 'like', 'abnormality', 'detection', 'smaller', 'set', 'chest', 'x', 'ray', 'images', 'also', 'released', 'chest', 'foundation', 'tool', 'generating', 'image', 'embeddings', 'chest', 'x', 'ray', 'liked', 'idea', 'behind', 'paper', 'believe', 'also', 'extended', 'medical', 'imaging', 'modalities', 'like', 'mr', 'ct', 'made', 'video', 'checkout', 'https', 'youtu', 'lyhghivjqw']","['chest', 'x', 'ray', 'network', 'simplifi', 'transfer', 'learn', 'chest', 'radiographi', 'model', 'develop', 'rresearch', 'ad', 'addit', 'step', 'pre', 'train', 'gener', 'imag', 'deep', 'learn', 'model', 'k', 'chest', 'x', 'ray', 'imag', 'use', 'supervis', 'contrarts', 'learn', 'use', 'noisi', 'label', 'radiolog', 'report', 'imag', 'embed', 'gener', 'network', 'use', 'task', 'like', 'abnorm', 'detect', 'smaller', 'set', 'chest', 'x', 'ray', 'imag', 'also', 'releas', 'chest', 'foundat', 'tool', 'gener', 'imag', 'embed', 'chest', 'x', 'ray', 'like', 'idea', 'behind', 'paper', 'believ', 'also', 'extend', 'medic', 'imag', 'modal', 'like', 'mr', 'ct', 'made', 'video', 'checkout', 'http', 'youtu', 'lyhghivjqw']"
56,63,63,dmpetrov,w99xo6,[P] Git-based model registry,"Hey everyone!  
﻿We are excited today to announce the release of our ML model registry for Iterative Studio (from the team behind DVC). This Model Registry is an UI for our [open source tool (MLEM) we introduced in this subreddit earlier this year](https://www.reddit.com/r/MachineLearning/comments/v2jnnd/p_mlem_ml_model_deployment_tool/).

Our philosophy is that ML projects - and MLOps practices - should be built on top of traditional software tools (such as Git), and not as a separate platform. Our goal is to extend DevOps’ wins from software development to ML.

**Git repository as single source of truth for models** \- the core principle behind our registry. This idea is not new if you are familiar with GitOps. We just implemented the model deployment specific workflow using this ideas.

**Technically**, **all is stored in Git repository:**

* assign a version to a model - it creates a corresponded Git tag in your repository
* deploy model to production - a special Git tag is pushed and your CI/CD system triggers for model deployment.
* ML model description and a link to a file in storage (S3, Azure Blob) - is stored in text file in Git.

This functionality can be used from open source tool [mlem.ai](https://mlem.ai) and our released UI that helps to visualize the entire inventory of your models - [https://studio.iterative.ai/](https://studio.iterative.ai/)

[Iterative Model Registry](https://reddit.com/link/w99xo6/video/y7nsmf9bv2e91/player)

﻿We would love your feedback on using GitOps principles in model deployment!",8,39,2022-07-27 12:16:12, p  git based model registry,hey everyone    we are excited today to announce the release of our ml model registry for iterative studio  from the team behind dvc   this model registry is an ui for our  open source tool  mlem  we introduced in this subreddit earlier this year  https our philosophy is that ml projects   and mlops practices   should be built on top of traditional software tools  such as git   and not as a separate platform  our goal is to extend devops  wins from software development to ml   git repository as single source of truth for models      the core principle behind our registry  this idea is not new if you are familiar with gitops  we just implemented the model deployment specific workflow using this ideas   technically      all is stored in git repository     assign a version to a model   it creates a corresponded git tag in your repository  deploy model to production   a special git tag is pushed and your ci cd system triggers for model deployment   ml model description and a link to a file in storage  s  azure blob    is stored in text file in git this functionality can be used from open source tool  mlem ai  https  iterative model registry  https  we would love your feedback on using gitops principles in model deployment ,hey everyone excited today announce release ml model registry iterative studio team behind dvc model registry ui open source tool mlem introduced subreddit earlier year https philosophy ml projects mlops practices built top traditional software tools git separate platform goal extend devops wins software development ml git repository single source truth models core principle behind registry idea familiar gitops implemented model deployment specific workflow using ideas technically stored git repository assign version model creates corresponded git tag repository deploy model production special git tag pushed ci cd system triggers model deployment ml model description link file storage azure blob stored text file git functionality used open source tool mlem ai https iterative model registry https would love feedback using gitops principles model deployment,p git based model registry,p git based model registryhey everyone excited today announce release ml model registry iterative studio team behind dvc model registry ui open source tool mlem introduced subreddit earlier year https philosophy ml projects mlops practices built top traditional software tools git separate platform goal extend devops wins software development ml git repository single source truth models core principle behind registry idea familiar gitops implemented model deployment specific workflow using ideas technically stored git repository assign version model creates corresponded git tag repository deploy model production special git tag pushed ci cd system triggers model deployment ml model description link file storage azure blob stored text file git functionality used open source tool mlem ai https iterative model registry https would love feedback using gitops principles model deployment,"['p', 'git', 'based', 'model', 'registryhey', 'everyone', 'excited', 'today', 'announce', 'release', 'ml', 'model', 'registry', 'iterative', 'studio', 'team', 'behind', 'dvc', 'model', 'registry', 'ui', 'open', 'source', 'tool', 'mlem', 'introduced', 'subreddit', 'earlier', 'year', 'https', 'philosophy', 'ml', 'projects', 'mlops', 'practices', 'built', 'top', 'traditional', 'software', 'tools', 'git', 'separate', 'platform', 'goal', 'extend', 'devops', 'wins', 'software', 'development', 'ml', 'git', 'repository', 'single', 'source', 'truth', 'models', 'core', 'principle', 'behind', 'registry', 'idea', 'familiar', 'gitops', 'implemented', 'model', 'deployment', 'specific', 'workflow', 'using', 'ideas', 'technically', 'stored', 'git', 'repository', 'assign', 'version', 'model', 'creates', 'corresponded', 'git', 'tag', 'repository', 'deploy', 'model', 'production', 'special', 'git', 'tag', 'pushed', 'ci', 'cd', 'system', 'triggers', 'model', 'deployment', 'ml', 'model', 'description', 'link', 'file', 'storage', 'azure', 'blob', 'stored', 'text', 'file', 'git', 'functionality', 'used', 'open', 'source', 'tool', 'mlem', 'ai', 'https', 'iterative', 'model', 'registry', 'https', 'would', 'love', 'feedback', 'using', 'gitops', 'principles', 'model', 'deployment']","['p', 'git', 'base', 'model', 'registryhey', 'everyon', 'excit', 'today', 'announc', 'releas', 'ml', 'model', 'registri', 'iter', 'studio', 'team', 'behind', 'dvc', 'model', 'registri', 'ui', 'open', 'sourc', 'tool', 'mlem', 'introduc', 'subreddit', 'earlier', 'year', 'http', 'philosophi', 'ml', 'project', 'mlop', 'practic', 'built', 'top', 'tradit', 'softwar', 'tool', 'git', 'separ', 'platform', 'goal', 'extend', 'devop', 'win', 'softwar', 'develop', 'ml', 'git', 'repositori', 'singl', 'sourc', 'truth', 'model', 'core', 'principl', 'behind', 'registri', 'idea', 'familiar', 'gitop', 'implement', 'model', 'deploy', 'specif', 'workflow', 'use', 'idea', 'technic', 'store', 'git', 'repositori', 'assign', 'version', 'model', 'creat', 'correspond', 'git', 'tag', 'repositori', 'deploy', 'model', 'product', 'special', 'git', 'tag', 'push', 'ci', 'cd', 'system', 'trigger', 'model', 'deploy', 'ml', 'model', 'descript', 'link', 'file', 'storag', 'azur', 'blob', 'store', 'text', 'file', 'git', 'function', 'use', 'open', 'sourc', 'tool', 'mlem', 'ai', 'http', 'iter', 'model', 'registri', 'http', 'would', 'love', 'feedback', 'use', 'gitop', 'principl', 'model', 'deploy']"
57,64,64,notabot789,w9klti,Do you know any prior work on quantifying Reinforcement Learning environment difficulty / complexity? [Discussion],"Hi, I am interested in learning more about frameworks for characterizing the relative complexity of Reinforcement Learning environments.

This can be used to better understand comparable problems and compare across environments: e.g. How much harder is Mountain Car than Cartpole?

There are many different characteristics that define environments and many different problem formulations - some of which are likely not meaningfully comparable quantitatively (single agent vs multi agent setup) and some that should be (low dimensional action space vs high dimensional action space)

Here are some different dimensions of environment difficulty split by problem setup and relative complexity

Problem formulation dimensions: 
- number of agents: single or multi agent 
- stochasticity: is the environment stochastic or deterministic 
- action space: discrete or continuous

Complexity dimensions: 
- dimensionality: high dimensionality state and action space 
- credit assignment: delayed rewards 
- state representation: noisy signal from raw pixels vs cleanly represented state 
- small number of solutions: some environments require a specific sequential pattern to be discovered (and remembered) E.g. Montezumas revenge vs others have many solutions such as Cartpole 
- how sensitive the environment is to initial conditions

Does anyone know which subfield this falls under? Or can you please link relevant papers / where I can go to learn more?",1,7,2022-07-27 20:24:08,do you know any prior work on quantifying reinforcement learning environment difficulty   complexity   discussion ,hi  i am interested in learning more about frameworks for characterizing the relative complexity of reinforcement learning environments this can be used to better understand comparable problems and compare across environments  e g  how much harder is mountain car than cartpole there are many different characteristics that define environments and many different problem formulations   some of which are likely not meaningfully comparable quantitatively  single agent vs multi agent setup  and some that should be  low dimensional action space vs high dimensional action space here are some different dimensions of environment difficulty split by problem setup and relative complexityproblem formulation dimensions    number of agents  single or multi agent   stochasticity  is the environment stochastic or deterministic   action space  discrete or continuouscomplexity dimensions    dimensionality  high dimensionality state and action space   credit assignment  delayed rewards   state representation  noisy signal from raw pixels vs cleanly represented state   small number of solutions  some environments require a specific sequential pattern to be discovered  and remembered  e g  montezumas revenge vs others have many solutions such as cartpole   how sensitive the environment is to initial conditionsdoes anyone know which subfield this falls under  or can you please link relevant papers   where i can go to learn more ,hi interested learning frameworks characterizing relative complexity reinforcement learning environments used better understand comparable problems compare across environments e g much harder mountain car cartpole many different characteristics define environments many different problem formulations likely meaningfully comparable quantitatively single agent vs multi agent setup low dimensional action space vs high dimensional action space different dimensions environment difficulty split problem setup relative complexityproblem formulation dimensions number agents single multi agent stochasticity environment stochastic deterministic action space discrete continuouscomplexity dimensions dimensionality high dimensionality state action space credit assignment delayed rewards state representation noisy signal raw pixels vs cleanly represented state small number solutions environments require specific sequential pattern discovered remembered e g montezumas revenge vs others many solutions cartpole sensitive environment initial conditionsdoes anyone know subfield falls please link relevant papers go learn,know prior work quantifying reinforcement learning environment difficulty complexity discussion,know prior work quantifying reinforcement learning environment difficulty complexity discussionhi interested learning frameworks characterizing relative complexity reinforcement learning environments used better understand comparable problems compare across environments e g much harder mountain car cartpole many different characteristics define environments many different problem formulations likely meaningfully comparable quantitatively single agent vs multi agent setup low dimensional action space vs high dimensional action space different dimensions environment difficulty split problem setup relative complexityproblem formulation dimensions number agents single multi agent stochasticity environment stochastic deterministic action space discrete continuouscomplexity dimensions dimensionality high dimensionality state action space credit assignment delayed rewards state representation noisy signal raw pixels vs cleanly represented state small number solutions environments require specific sequential pattern discovered remembered e g montezumas revenge vs others many solutions cartpole sensitive environment initial conditionsdoes anyone know subfield falls please link relevant papers go learn,"['know', 'prior', 'work', 'quantifying', 'reinforcement', 'learning', 'environment', 'difficulty', 'complexity', 'discussionhi', 'interested', 'learning', 'frameworks', 'characterizing', 'relative', 'complexity', 'reinforcement', 'learning', 'environments', 'used', 'better', 'understand', 'comparable', 'problems', 'compare', 'across', 'environments', 'e', 'g', 'much', 'harder', 'mountain', 'car', 'cartpole', 'many', 'different', 'characteristics', 'define', 'environments', 'many', 'different', 'problem', 'formulations', 'likely', 'meaningfully', 'comparable', 'quantitatively', 'single', 'agent', 'vs', 'multi', 'agent', 'setup', 'low', 'dimensional', 'action', 'space', 'vs', 'high', 'dimensional', 'action', 'space', 'different', 'dimensions', 'environment', 'difficulty', 'split', 'problem', 'setup', 'relative', 'complexityproblem', 'formulation', 'dimensions', 'number', 'agents', 'single', 'multi', 'agent', 'stochasticity', 'environment', 'stochastic', 'deterministic', 'action', 'space', 'discrete', 'continuouscomplexity', 'dimensions', 'dimensionality', 'high', 'dimensionality', 'state', 'action', 'space', 'credit', 'assignment', 'delayed', 'rewards', 'state', 'representation', 'noisy', 'signal', 'raw', 'pixels', 'vs', 'cleanly', 'represented', 'state', 'small', 'number', 'solutions', 'environments', 'require', 'specific', 'sequential', 'pattern', 'discovered', 'remembered', 'e', 'g', 'montezumas', 'revenge', 'vs', 'others', 'many', 'solutions', 'cartpole', 'sensitive', 'environment', 'initial', 'conditionsdoes', 'anyone', 'know', 'subfield', 'falls', 'please', 'link', 'relevant', 'papers', 'go', 'learn']","['know', 'prior', 'work', 'quantifi', 'reinforc', 'learn', 'environ', 'difficulti', 'complex', 'discussionhi', 'interest', 'learn', 'framework', 'character', 'rel', 'complex', 'reinforc', 'learn', 'environ', 'use', 'better', 'understand', 'compar', 'problem', 'compar', 'across', 'environ', 'e', 'g', 'much', 'harder', 'mountain', 'car', 'cartpol', 'mani', 'differ', 'characterist', 'defin', 'environ', 'mani', 'differ', 'problem', 'formul', 'like', 'meaning', 'compar', 'quantit', 'singl', 'agent', 'vs', 'multi', 'agent', 'setup', 'low', 'dimension', 'action', 'space', 'vs', 'high', 'dimension', 'action', 'space', 'differ', 'dimens', 'environ', 'difficulti', 'split', 'problem', 'setup', 'rel', 'complexityproblem', 'formul', 'dimens', 'number', 'agent', 'singl', 'multi', 'agent', 'stochast', 'environ', 'stochast', 'determinist', 'action', 'space', 'discret', 'continuouscomplex', 'dimens', 'dimension', 'high', 'dimension', 'state', 'action', 'space', 'credit', 'assign', 'delay', 'reward', 'state', 'represent', 'noisi', 'signal', 'raw', 'pixel', 'vs', 'cleanli', 'repres', 'state', 'small', 'number', 'solut', 'environ', 'requir', 'specif', 'sequenti', 'pattern', 'discov', 'rememb', 'e', 'g', 'montezuma', 'reveng', 'vs', 'other', 'mani', 'solut', 'cartpol', 'sensit', 'environ', 'initi', 'conditionsdo', 'anyon', 'know', 'subfield', 'fall', 'pleas', 'link', 'relev', 'paper', 'go', 'learn']"
58,65,65,ThePerson654321,w9epzi,[D] What do you think will be the most exciting thing in ML three years from now?,"I would list the most interesting things happening in machine learning right now to be:

- GPT-3, Gato, Dalle2 (creating incredible models by just pouring in data into them)
- NERF

What do you think we will be most exited about three years from now? GPT-3 was released two years ago.",14,11,2022-07-27 16:24:42, d  what do you think will be the most exciting thing in ml three years from now ,i would list the most interesting things happening in machine learning right now to be   gpt   gato  dalle  creating incredible models by just pouring in data into them   nerfwhat do you think we will be most exited about three years from now  gpt  was released two years ago ,would interesting things happening machine learning right gpt gato dalle creating incredible models pouring data nerfwhat think exited three years gpt released two years ago,think exciting thing ml three years,think exciting thing ml three yearswould interesting things happening machine learning right gpt gato dalle creating incredible models pouring data nerfwhat think exited three years gpt released two years ago,"['think', 'exciting', 'thing', 'ml', 'three', 'yearswould', 'interesting', 'things', 'happening', 'machine', 'learning', 'right', 'gpt', 'gato', 'dalle', 'creating', 'incredible', 'models', 'pouring', 'data', 'nerfwhat', 'think', 'exited', 'three', 'years', 'gpt', 'released', 'two', 'years', 'ago']","['think', 'excit', 'thing', 'ml', 'three', 'yearswould', 'interest', 'thing', 'happen', 'machin', 'learn', 'right', 'gpt', 'gato', 'dall', 'creat', 'incred', 'model', 'pour', 'data', 'nerfwhat', 'think', 'exit', 'three', 'year', 'gpt', 'releas', 'two', 'year', 'ago']"
59,66,66,alobianco,w9vbcn,[D] Naming convention: `train!` or `fit!` for the API of a ML library ?,"I am deeply undecided to name the step where parameters of a model are learned from data in the API of my ML library \`train!(model,X,\[Y\])\` or \`fit!(model,X,\[Y\])\`.

I would intuitively prefer the first, as makes somehow explicit that we are learning something with experience, but \`train/fit\` seems to be more common...

What would you choose ?

PS: the exclamation mark is due to another convention in Julia where functions that change their arguments - the model object in my case - ends with an exclamation mark",12,0,2022-07-28 03:50:00, d  naming convention   train   or  fit   for the api of a ml library  ,i am deeply undecided to name the step where parameters of a model are learned from data in the api of my ml library   train  model x   y      or   fit  model x   y      i would intuitively prefer the first  as makes somehow explicit that we are learning something with experience  but   train fit   seems to be more common   what would you choose  ps  the exclamation mark is due to another convention in julia where functions that change their arguments   the model object in my case   ends with an exclamation mark,deeply undecided name step parameters model learned data api ml library train model x fit model x would intuitively prefer first makes somehow explicit learning something experience train fit seems common would choose ps exclamation mark due another convention julia functions change arguments model object case ends exclamation mark,naming convention train fit api ml library,naming convention train fit api ml librarydeeply undecided name step parameters model learned data api ml library train model x fit model x would intuitively prefer first makes somehow explicit learning something experience train fit seems common would choose ps exclamation mark due another convention julia functions change arguments model object case ends exclamation mark,"['naming', 'convention', 'train', 'fit', 'api', 'ml', 'librarydeeply', 'undecided', 'name', 'step', 'parameters', 'model', 'learned', 'data', 'api', 'ml', 'library', 'train', 'model', 'x', 'fit', 'model', 'x', 'would', 'intuitively', 'prefer', 'first', 'makes', 'somehow', 'explicit', 'learning', 'something', 'experience', 'train', 'fit', 'seems', 'common', 'would', 'choose', 'ps', 'exclamation', 'mark', 'due', 'another', 'convention', 'julia', 'functions', 'change', 'arguments', 'model', 'object', 'case', 'ends', 'exclamation', 'mark']","['name', 'convent', 'train', 'fit', 'api', 'ml', 'librarydeepli', 'undecid', 'name', 'step', 'paramet', 'model', 'learn', 'data', 'api', 'ml', 'librari', 'train', 'model', 'x', 'fit', 'model', 'x', 'would', 'intuit', 'prefer', 'first', 'make', 'somehow', 'explicit', 'learn', 'someth', 'experi', 'train', 'fit', 'seem', 'common', 'would', 'choos', 'ps', 'exclam', 'mark', 'due', 'anoth', 'convent', 'julia', 'function', 'chang', 'argument', 'model', 'object', 'case', 'end', 'exclam', 'mark']"
60,67,67,entropythagorean,w9ph36,[D] Is self driving entirely machine learning?,"It's my understanding that labeling needed for the car to understand its surrounding is done by a neural net or some other machine learning technique. What I'm curious about is whether the decisions of how to operate the car based on it's labeled surroundings is done with more conventional programming like, ""If I'm about to hit this thing labeled as a wall, then brake"" or ""If the bounds of the road angle to the left, then steer left"" or if a black box neural net approach is used where we train it to less deterministically produce certain outputs based on the conditions of the labels?

TLDR: is self driving  
label -> black box neural net -> control output  
OR  
label -> if/then -> control output",15,3,2022-07-27 23:44:53, d  is self driving entirely machine learning ,it s my understanding that labeling needed for the car to understand its surrounding is done by a neural net or some other machine learning technique  what i m curious about is whether the decisions of how to operate the car based on it s labeled surroundings is done with more conventional programming like  if i m about to hit this thing labeled as a wall  then brake or if the bounds of the road angle to the left  then steer left or if a black box neural net approach is used where we train it to less deterministically produce certain outputs based on the conditions of the labels tldr  is self driving  label    black box neural net    control output  or  label    if then    control output,understanding labeling needed car understand surrounding done neural net machine learning technique curious whether decisions operate car based labeled surroundings done conventional programming like hit thing labeled wall brake bounds road angle left steer left black box neural net approach used train less deterministically produce certain outputs based conditions labels tldr self driving label black box neural net control output label control output,self driving entirely machine learning,self driving entirely machine learningunderstanding labeling needed car understand surrounding done neural net machine learning technique curious whether decisions operate car based labeled surroundings done conventional programming like hit thing labeled wall brake bounds road angle left steer left black box neural net approach used train less deterministically produce certain outputs based conditions labels tldr self driving label black box neural net control output label control output,"['self', 'driving', 'entirely', 'machine', 'learningunderstanding', 'labeling', 'needed', 'car', 'understand', 'surrounding', 'done', 'neural', 'net', 'machine', 'learning', 'technique', 'curious', 'whether', 'decisions', 'operate', 'car', 'based', 'labeled', 'surroundings', 'done', 'conventional', 'programming', 'like', 'hit', 'thing', 'labeled', 'wall', 'brake', 'bounds', 'road', 'angle', 'left', 'steer', 'left', 'black', 'box', 'neural', 'net', 'approach', 'used', 'train', 'less', 'deterministically', 'produce', 'certain', 'outputs', 'based', 'conditions', 'labels', 'tldr', 'self', 'driving', 'label', 'black', 'box', 'neural', 'net', 'control', 'output', 'label', 'control', 'output']","['self', 'drive', 'entir', 'machin', 'learningunderstand', 'label', 'need', 'car', 'understand', 'surround', 'done', 'neural', 'net', 'machin', 'learn', 'techniqu', 'curiou', 'whether', 'decis', 'oper', 'car', 'base', 'label', 'surround', 'done', 'convent', 'program', 'like', 'hit', 'thing', 'label', 'wall', 'brake', 'bound', 'road', 'angl', 'left', 'steer', 'left', 'black', 'box', 'neural', 'net', 'approach', 'use', 'train', 'less', 'determinist', 'produc', 'certain', 'output', 'base', 'condit', 'label', 'tldr', 'self', 'drive', 'label', 'black', 'box', 'neural', 'net', 'control', 'output', 'label', 'control', 'output']"
61,68,68,ryxu,w9uqrd,[R] Blog post summarizing undergraduate thesis work,"Hey everyone!

I just published a blog post today that summarizes my undergraduate thesis work. The thesis topic is a multi-network approach to minimize overfitting to noisy data.

Here is a [link to the article](https://medium.com/@ryxu/n-student-learning-fc4e452ad006).

Any feedback or questions would be really appreciated.

Thanks!",3,1,2022-07-28 03:23:56, r  blog post summarizing undergraduate thesis work,hey everyone i just published a blog post today that summarizes my undergraduate thesis work  the thesis topic is a multi network approach to minimize overfitting to noisy data here is a  link to the article  https any feedback or questions would be really appreciated thanks ,hey everyone published blog post today summarizes undergraduate thesis work thesis topic multi network approach minimize overfitting noisy data link article https feedback questions would really appreciated thanks,r blog post summarizing undergraduate thesis work,r blog post summarizing undergraduate thesis workhey everyone published blog post today summarizes undergraduate thesis work thesis topic multi network approach minimize overfitting noisy data link article https feedback questions would really appreciated thanks,"['r', 'blog', 'post', 'summarizing', 'undergraduate', 'thesis', 'workhey', 'everyone', 'published', 'blog', 'post', 'today', 'summarizes', 'undergraduate', 'thesis', 'work', 'thesis', 'topic', 'multi', 'network', 'approach', 'minimize', 'overfitting', 'noisy', 'data', 'link', 'article', 'https', 'feedback', 'questions', 'would', 'really', 'appreciated', 'thanks']","['r', 'blog', 'post', 'summar', 'undergradu', 'thesi', 'workhey', 'everyon', 'publish', 'blog', 'post', 'today', 'summar', 'undergradu', 'thesi', 'work', 'thesi', 'topic', 'multi', 'network', 'approach', 'minim', 'overfit', 'noisi', 'data', 'link', 'articl', 'http', 'feedback', 'question', 'would', 'realli', 'appreci', 'thank']"
62,69,69,ZimaLion,w945a5,[P] How To Train NPCs With Video? VR Badminton Project,Currently with my team we are developing a VR badminton game and we are looking for ways to train the NPCs to play as realistic as possible. We were thinking if there was a way to train the NPCs with video from real badminton players? Any help or idea is highly appreciated! Thanks in advance.,15,41,2022-07-27 06:44:56, p  how to train npcs with video  vr badminton project,currently with my team we are developing a vr badminton game and we are looking for ways to train the npcs to play as realistic as possible  we were thinking if there was a way to train the npcs with video from real badminton players  any help or idea is highly appreciated  thanks in advance ,currently team developing vr badminton game looking ways train npcs play realistic possible thinking way train npcs video real badminton players help idea highly appreciated thanks advance,p train npcs video vr badminton project,p train npcs video vr badminton projectcurrently team developing vr badminton game looking ways train npcs play realistic possible thinking way train npcs video real badminton players help idea highly appreciated thanks advance,"['p', 'train', 'npcs', 'video', 'vr', 'badminton', 'projectcurrently', 'team', 'developing', 'vr', 'badminton', 'game', 'looking', 'ways', 'train', 'npcs', 'play', 'realistic', 'possible', 'thinking', 'way', 'train', 'npcs', 'video', 'real', 'badminton', 'players', 'help', 'idea', 'highly', 'appreciated', 'thanks', 'advance']","['p', 'train', 'npc', 'video', 'vr', 'badminton', 'projectcurr', 'team', 'develop', 'vr', 'badminton', 'game', 'look', 'way', 'train', 'npc', 'play', 'realist', 'possibl', 'think', 'way', 'train', 'npc', 'video', 'real', 'badminton', 'player', 'help', 'idea', 'highli', 'appreci', 'thank', 'advanc']"
63,70,70,JClub,w9g8a8,[D] Reading Group Presentation: Scalable Video-to-Speech Synthesis,"&#x200B;

https://preview.redd.it/uewvxpt7f4e91.png?width=1200&format=png&auto=webp&s=e2a3a89df1337b2df0f81d39cb75b4774e163bd7

[outsystems-ai-reading-group.github.io](https://outsystems-ai-reading-group.github.io/) for more info",0,4,2022-07-27 17:28:36, d  reading group presentation  scalable video to speech synthesis,  xb https  outsystems ai reading group github io  https   outsystems ai reading group github io   for more info,xb https outsystems ai reading group github io https outsystems ai reading group github io info,reading group presentation scalable video speech synthesis,reading group presentation scalable video speech synthesisxb https outsystems ai reading group github io https outsystems ai reading group github io info,"['reading', 'group', 'presentation', 'scalable', 'video', 'speech', 'synthesisxb', 'https', 'outsystems', 'ai', 'reading', 'group', 'github', 'io', 'https', 'outsystems', 'ai', 'reading', 'group', 'github', 'io', 'info']","['read', 'group', 'present', 'scalabl', 'video', 'speech', 'synthesisxb', 'http', 'outsystem', 'ai', 'read', 'group', 'github', 'io', 'http', 'outsystem', 'ai', 'read', 'group', 'github', 'io', 'info']"
64,71,71,Garlic-Naan-7249,w99ybi,[D] Choosing right aws instance for training.,Currently we have training jobs of both image models and large language models. I am having difficult timing choosing between g4 and p3 instances. Please suggest a multi gpu instance that is cost as well as time optimised(we plan to add a savings plan over that). If there is a benchmarks to compare the two from each other please share.,3,8,2022-07-27 12:17:19, d  choosing right aws instance for training ,currently we have training jobs of both image models and large language models  i am having difficult timing choosing between g and p instances  please suggest a multi gpu instance that is cost as well as time optimised we plan to add a savings plan over that   if there is a benchmarks to compare the two from each other please share ,currently training jobs image models large language models difficult timing choosing g p instances please suggest multi gpu instance cost well time optimised plan savings plan benchmarks compare two please share,choosing right aws instance training,choosing right aws instance trainingcurrently training jobs image models large language models difficult timing choosing g p instances please suggest multi gpu instance cost well time optimised plan savings plan benchmarks compare two please share,"['choosing', 'right', 'aws', 'instance', 'trainingcurrently', 'training', 'jobs', 'image', 'models', 'large', 'language', 'models', 'difficult', 'timing', 'choosing', 'g', 'p', 'instances', 'please', 'suggest', 'multi', 'gpu', 'instance', 'cost', 'well', 'time', 'optimised', 'plan', 'savings', 'plan', 'benchmarks', 'compare', 'two', 'please', 'share']","['choos', 'right', 'aw', 'instanc', 'trainingcurr', 'train', 'job', 'imag', 'model', 'larg', 'languag', 'model', 'difficult', 'time', 'choos', 'g', 'p', 'instanc', 'pleas', 'suggest', 'multi', 'gpu', 'instanc', 'cost', 'well', 'time', 'optimis', 'plan', 'save', 'plan', 'benchmark', 'compar', 'two', 'pleas', 'share']"
65,72,72,GullibleEngineer4,w9fbzx,[D] Is anyone training large language models on academic literature?,"I am wondering whether someone is trying to train LLMs on academic literature. I am thinking If openAI codex can spit out functional code from training on all publically available code, surely a model trained on all digital books and research papers can see patterns across different domains and generate surprising insights.

 If it works, it can be ground breaking in terms of pushing forward science since the scientific disciplines have become so specialized that humans cannot become experts within multiple disciplines within a lifetime but a machine may have a chance at it!

Ideas, suggestions are welcome.",6,4,2022-07-27 16:51:27, d  is anyone training large language models on academic literature ,i am wondering whether someone is trying to train llms on academic literature  i am thinking if openai codex can spit out functional code from training on all publically available code  surely a model trained on all digital books and research papers can see patterns across different domains and generate surprising insights  if it works  it can be ground breaking in terms of pushing forward science since the scientific disciplines have become so specialized that humans cannot become experts within multiple disciplines within a lifetime but a machine may have a chance at it ideas  suggestions are welcome ,wondering whether someone trying train llms academic literature thinking openai codex spit functional code training publically available code surely model trained digital books research papers see patterns across different domains generate surprising insights works ground breaking terms pushing forward science since scientific disciplines become specialized humans cannot become experts within multiple disciplines within lifetime machine may chance ideas suggestions welcome,anyone training large language models academic literature,anyone training large language models academic literaturewondering whether someone trying train llms academic literature thinking openai codex spit functional code training publically available code surely model trained digital books research papers see patterns across different domains generate surprising insights works ground breaking terms pushing forward science since scientific disciplines become specialized humans cannot become experts within multiple disciplines within lifetime machine may chance ideas suggestions welcome,"['anyone', 'training', 'large', 'language', 'models', 'academic', 'literaturewondering', 'whether', 'someone', 'trying', 'train', 'llms', 'academic', 'literature', 'thinking', 'openai', 'codex', 'spit', 'functional', 'code', 'training', 'publically', 'available', 'code', 'surely', 'model', 'trained', 'digital', 'books', 'research', 'papers', 'see', 'patterns', 'across', 'different', 'domains', 'generate', 'surprising', 'insights', 'works', 'ground', 'breaking', 'terms', 'pushing', 'forward', 'science', 'since', 'scientific', 'disciplines', 'become', 'specialized', 'humans', 'can', 'not', 'become', 'experts', 'within', 'multiple', 'disciplines', 'within', 'lifetime', 'machine', 'may', 'chance', 'ideas', 'suggestions', 'welcome']","['anyon', 'train', 'larg', 'languag', 'model', 'academ', 'literaturewond', 'whether', 'someon', 'tri', 'train', 'llm', 'academ', 'literatur', 'think', 'openai', 'codex', 'spit', 'function', 'code', 'train', 'public', 'avail', 'code', 'sure', 'model', 'train', 'digit', 'book', 'research', 'paper', 'see', 'pattern', 'across', 'differ', 'domain', 'gener', 'surpris', 'insight', 'work', 'ground', 'break', 'term', 'push', 'forward', 'scienc', 'sinc', 'scientif', 'disciplin', 'becom', 'special', 'human', 'can', 'not', 'becom', 'expert', 'within', 'multipl', 'disciplin', 'within', 'lifetim', 'machin', 'may', 'chanc', 'idea', 'suggest', 'welcom']"
66,73,73,NathanA2C,w9qaow,[D] What methods/tools should I use for a combination of linear and non-linear tabular data?,Title. The non-linear data cannot be transformed into a linear form. What methods or tools should I use for this,16,1,2022-07-28 00:18:07, d  what methods tools should i use for a combination of linear and non linear tabular data ,title  the non linear data cannot be transformed into a linear form  what methods or tools should i use for this,title non linear data cannot transformed linear form methods tools use,methods tools use combination linear non linear tabular data,methods tools use combination linear non linear tabular datatitle non linear data cannot transformed linear form methods tools use,"['methods', 'tools', 'use', 'combination', 'linear', 'non', 'linear', 'tabular', 'datatitle', 'non', 'linear', 'data', 'can', 'not', 'transformed', 'linear', 'form', 'methods', 'tools', 'use']","['method', 'tool', 'use', 'combin', 'linear', 'non', 'linear', 'tabular', 'datatitl', 'non', 'linear', 'data', 'can', 'not', 'transform', 'linear', 'form', 'method', 'tool', 'use']"
67,74,74,swagonflyyyy,w9k130,[D] Is it possible to use machine learning to create 3D images for the purpose of 3D printing?,"I think this is a longshot but I was thinking that I could build a model gathering image data to create a model that creates 3D images that can be added to 3D printing software so it could 3D print the model and sell it on Amazon.

Some items could include 3D printed toys or statues or decorations, small stuff you could add to a desk or somewhere in your room or purchase it as a gift.

Easier said than done, I assume but would such a thing be possible?",7,2,2022-07-27 20:00:46, d  is it possible to use machine learning to create d images for the purpose of d printing ,i think this is a longshot but i was thinking that i could build a model gathering image data to create a model that creates d images that can be added to d printing software so it could d print the model and sell it on amazon some items could include d printed toys or statues or decorations  small stuff you could add to a desk or somewhere in your room or purchase it as a gift easier said than done  i assume but would such a thing be possible ,think longshot thinking could build model gathering image data create model creates images added printing software could print model sell amazon items could include printed toys statues decorations small stuff could desk somewhere room purchase gift easier said done assume would thing possible,possible use machine learning create images purpose printing,possible use machine learning create images purpose printingthink longshot thinking could build model gathering image data create model creates images added printing software could print model sell amazon items could include printed toys statues decorations small stuff could desk somewhere room purchase gift easier said done assume would thing possible,"['possible', 'use', 'machine', 'learning', 'create', 'images', 'purpose', 'printingthink', 'longshot', 'thinking', 'could', 'build', 'model', 'gathering', 'image', 'data', 'create', 'model', 'creates', 'images', 'added', 'printing', 'software', 'could', 'print', 'model', 'sell', 'amazon', 'items', 'could', 'include', 'printed', 'toys', 'statues', 'decorations', 'small', 'stuff', 'could', 'desk', 'somewhere', 'room', 'purchase', 'gift', 'easier', 'said', 'done', 'assume', 'would', 'thing', 'possible']","['possibl', 'use', 'machin', 'learn', 'creat', 'imag', 'purpos', 'printingthink', 'longshot', 'think', 'could', 'build', 'model', 'gather', 'imag', 'data', 'creat', 'model', 'creat', 'imag', 'ad', 'print', 'softwar', 'could', 'print', 'model', 'sell', 'amazon', 'item', 'could', 'includ', 'print', 'toy', 'statu', 'decor', 'small', 'stuff', 'could', 'desk', 'somewher', 'room', 'purchas', 'gift', 'easier', 'said', 'done', 'assum', 'would', 'thing', 'possibl']"
68,75,75,prakhar21,w9jcmr,[D] A Semi-automatic approach for Generating Video Trailers for Learning Pathways (Poster Walkthrough),"In this video, I present a walkthrough of my poster ""A Semi-automatic approach for Generating Video Trailers for Learning Pathways"" that got accepted at the venue AIED 2022. I will be sharing the paper soon.

Let me know your thoughts 💭 Much Appreciated! 🤗 

https://youtu.be/Y93GXvVERmk",0,2,2022-07-27 19:33:45, d  a semi automatic approach for generating video trailers for learning pathways  poster walkthrough ,in this video  i present a walkthrough of my poster a semi automatic approach for generating video trailers for learning pathways that got accepted at the venue aied   i will be sharing the paper soon let me know your thoughts   much appreciated    https   youtu be ygxvvermk,video present walkthrough poster semi automatic approach generating video trailers learning pathways got accepted venue aied sharing paper soon let know thoughts much appreciated https youtu ygxvvermk,semi automatic approach generating video trailers learning pathways poster walkthrough,semi automatic approach generating video trailers learning pathways poster walkthroughvideo present walkthrough poster semi automatic approach generating video trailers learning pathways got accepted venue aied sharing paper soon let know thoughts much appreciated https youtu ygxvvermk,"['semi', 'automatic', 'approach', 'generating', 'video', 'trailers', 'learning', 'pathways', 'poster', 'walkthroughvideo', 'present', 'walkthrough', 'poster', 'semi', 'automatic', 'approach', 'generating', 'video', 'trailers', 'learning', 'pathways', 'got', 'accepted', 'venue', 'aied', 'sharing', 'paper', 'soon', 'let', 'know', 'thoughts', 'much', 'appreciated', 'https', 'youtu', 'ygxvvermk']","['semi', 'automat', 'approach', 'gener', 'video', 'trailer', 'learn', 'pathway', 'poster', 'walkthroughvideo', 'present', 'walkthrough', 'poster', 'semi', 'automat', 'approach', 'gener', 'video', 'trailer', 'learn', 'pathway', 'got', 'accept', 'venu', 'aie', 'share', 'paper', 'soon', 'let', 'know', 'thought', 'much', 'appreci', 'http', 'youtu', 'ygxvvermk']"
69,76,76,giakou4,w9g3eo,[D] Albumentations VS Detectron2,How the augmentations of Detectron2 regarding HSV ([https://github.com/facebookresearch/detectron2/blob/48b598b4f61fbb24182a69b521b2a0ba3252b842/detectron2/data/transforms/augmentation\_impl.py](https://github.com/facebookresearch/detectron2/blob/48b598b4f61fbb24182a69b521b2a0ba3252b842/detectron2/data/transforms/augmentation_impl.py)) correlate with albumentations ones - ColorJitter ([https://albumentations.ai/docs/api\_reference/augmentations/transforms/](https://albumentations.ai/docs/api_reference/augmentations/transforms/))?,0,2,2022-07-27 17:22:54, d  albumentations vs detectron,how the augmentations of detectron regarding hsv   https   github com facebookresearch detectron blob bbffbbabbabab detectron data transforms augmentation _impl py  https   github com facebookresearch detectron blob bbffbbabbabab detectron data transforms augmentation_impl py   correlate with albumentations ones   colorjitter   https   albumentations ai docs api _reference augmentations transforms   https   albumentations ai docs api_reference augmentations transforms    ,augmentations detectron regarding hsv https github com facebookresearch detectron blob bbffbbabbabab detectron data transforms augmentation _impl py https github com facebookresearch detectron blob bbffbbabbabab detectron data transforms augmentation_impl py correlate albumentations ones colorjitter https albumentations ai docs api _reference augmentations transforms https albumentations ai docs api_reference augmentations transforms,albumentations vs detectron,albumentations vs detectronaugmentations detectron regarding hsv https github com facebookresearch detectron blob bbffbbabbabab detectron data transforms augmentation _impl py https github com facebookresearch detectron blob bbffbbabbabab detectron data transforms augmentation_impl py correlate albumentations ones colorjitter https albumentations ai docs api _reference augmentations transforms https albumentations ai docs api_reference augmentations transforms,"['albumentations', 'vs', 'detectronaugmentations', 'detectron', 'regarding', 'hsv', 'https', 'github', 'com', 'facebookresearch', 'detectron', 'blob', 'bbffbbabbabab', 'detectron', 'data', 'transforms', 'augmentation', '_impl', 'py', 'https', 'github', 'com', 'facebookresearch', 'detectron', 'blob', 'bbffbbabbabab', 'detectron', 'data', 'transforms', 'augmentation_impl', 'py', 'correlate', 'albumentations', 'ones', 'colorjitter', 'https', 'albumentations', 'ai', 'docs', 'api', '_reference', 'augmentations', 'transforms', 'https', 'albumentations', 'ai', 'docs', 'api_reference', 'augmentations', 'transforms']","['albument', 'vs', 'detectronaugment', 'detectron', 'regard', 'hsv', 'http', 'github', 'com', 'facebookresearch', 'detectron', 'blob', 'bbffbbabbabab', 'detectron', 'data', 'transform', 'augment', '_impl', 'py', 'http', 'github', 'com', 'facebookresearch', 'detectron', 'blob', 'bbffbbabbabab', 'detectron', 'data', 'transform', 'augmentation_impl', 'py', 'correl', 'albument', 'one', 'colorjitt', 'http', 'albument', 'ai', 'doc', 'api', '_refer', 'augment', 'transform', 'http', 'albument', 'ai', 'doc', 'api_refer', 'augment', 'transform']"
70,77,77,vanilla-acc,w91t6r,[D] How does the loss used in Imagen differ from the loss used in IDDPM?,"The loss term used in the paper [Improved Denoising Diffusion Probabilistic Models](https://arxiv.org/pdf/2102.09672.pdf) is called L\_hybrid. It is a mixture of 2 things:

\- The variational lower bound loss

\- The MSE loss between what the model predicts

I've been staring at the loss term used in Imagen, and I haven't been able to make heads or tails of it. It seems like they use a MSE loss between the model's predicted noise and the actual noise, but do they also do anything else? (For example: utilize the variational lower bound loss).

&#x200B;

&#x200B;

[Imagen Loss](https://preview.redd.it/s8c59rszo0e91.png?width=728&format=png&auto=webp&s=c89e1fc986e99ccb637c02bc6fbbae067f859240)",4,18,2022-07-27 04:55:35, d  how does the loss used in imagen differ from the loss used in iddpm ,the loss term used in the paper  improved denoising diffusion probabilistic models  https    the variational lower bound loss   the mse loss between what the model predictsi ve been staring at the loss term used in imagen  and i haven t been able to make heads or tails of it  it seems like they use a mse loss between the model s predicted noise and the actual noise  but do they also do anything else   for example  utilize the variational lower bound loss    xb   xb  imagen loss  https   preview redd it scrszoe png width  format png auto webp s cefceccbcbcfbbaef ,loss term used paper improved denoising diffusion probabilistic models https variational lower bound loss mse loss model predictsi staring loss term used imagen able make heads tails seems like use mse loss model predicted noise actual noise also anything else example utilize variational lower bound loss xb xb imagen loss https preview redd scrszoe png width format png auto webp cefceccbcbcfbbaef,loss used imagen differ loss used iddpm,loss used imagen differ loss used iddpmloss term used paper improved denoising diffusion probabilistic models https variational lower bound loss mse loss model predictsi staring loss term used imagen able make heads tails seems like use mse loss model predicted noise actual noise also anything else example utilize variational lower bound loss xb xb imagen loss https preview redd scrszoe png width format png auto webp cefceccbcbcfbbaef,"['loss', 'used', 'imagen', 'differ', 'loss', 'used', 'iddpmloss', 'term', 'used', 'paper', 'improved', 'denoising', 'diffusion', 'probabilistic', 'models', 'https', 'variational', 'lower', 'bound', 'loss', 'mse', 'loss', 'model', 'predictsi', 'staring', 'loss', 'term', 'used', 'imagen', 'able', 'make', 'heads', 'tails', 'seems', 'like', 'use', 'mse', 'loss', 'model', 'predicted', 'noise', 'actual', 'noise', 'also', 'anything', 'else', 'example', 'utilize', 'variational', 'lower', 'bound', 'loss', 'xb', 'xb', 'imagen', 'loss', 'https', 'preview', 'redd', 'scrszoe', 'png', 'width', 'format', 'png', 'auto', 'webp', 'cefceccbcbcfbbaef']","['loss', 'use', 'imagen', 'differ', 'loss', 'use', 'iddpmloss', 'term', 'use', 'paper', 'improv', 'denois', 'diffus', 'probabilist', 'model', 'http', 'variat', 'lower', 'bound', 'loss', 'mse', 'loss', 'model', 'predictsi', 'stare', 'loss', 'term', 'use', 'imagen', 'abl', 'make', 'head', 'tail', 'seem', 'like', 'use', 'mse', 'loss', 'model', 'predict', 'nois', 'actual', 'nois', 'also', 'anyth', 'els', 'exampl', 'util', 'variat', 'lower', 'bound', 'loss', 'xb', 'xb', 'imagen', 'loss', 'http', 'preview', 'redd', 'scrszoe', 'png', 'width', 'format', 'png', 'auto', 'webp', 'cefceccbcbcfbbaef']"
71,78,78,zy415,w8k453,[D] NeurIPS 2022 Paper Reviews,"NeurIPS 2022 paper reviews are supposed to be released in a few hours. According to the [website](https://neurips.cc/Conferences/2022/Dates), they should be released at 9am PDT on July 26th. I thought to create a discussion thread for us to discuss any issue/complain/celebration or anything else.

There is so much noise in the reviews every year. Some good work that the authors are proud of might get a low score because of the noisy system, given that NeurIPS is growing so large these years. We should keep in mind that the work is still valuable no matter what the score is.

According to the Program Chair's [tweet](https://twitter.com/kchonyc/status/1551776158831841280), it seems that only \~93% of the reviews are submitted. Hopefully it will not delay the release of the reviews and the start of the rebuttal.",171,141,2022-07-26 16:41:26, d  neurips  paper reviews,neurips  paper reviews are supposed to be released in a few hours  according to the  website  https there is so much noise in the reviews every year  some good work that the authors are proud of might get a low score because of the noisy system  given that neurips is growing so large these years  we should keep in mind that the work is still valuable no matter what the score is according to the program chair s  tweet  https   twitter com kchonyc status    it seems that only     of the reviews are submitted  hopefully it will not delay the release of the reviews and the start of the rebuttal ,neurips paper reviews supposed released hours according website https much noise reviews every year good work authors proud might get low score noisy system given neurips growing large years keep mind work still valuable matter score according program chair tweet https twitter com kchonyc status seems reviews submitted hopefully delay release reviews start rebuttal,neurips paper reviews,neurips paper reviewsneurips paper reviews supposed released hours according website https much noise reviews every year good work authors proud might get low score noisy system given neurips growing large years keep mind work still valuable matter score according program chair tweet https twitter com kchonyc status seems reviews submitted hopefully delay release reviews start rebuttal,"['neurips', 'paper', 'reviewsneurips', 'paper', 'reviews', 'supposed', 'released', 'hours', 'according', 'website', 'https', 'much', 'noise', 'reviews', 'every', 'year', 'good', 'work', 'authors', 'proud', 'might', 'get', 'low', 'score', 'noisy', 'system', 'given', 'neurips', 'growing', 'large', 'years', 'keep', 'mind', 'work', 'still', 'valuable', 'matter', 'score', 'according', 'program', 'chair', 'tweet', 'https', 'twitter', 'com', 'kchonyc', 'status', 'seems', 'reviews', 'submitted', 'hopefully', 'delay', 'release', 'reviews', 'start', 'rebuttal']","['neurip', 'paper', 'reviewsneurip', 'paper', 'review', 'suppos', 'releas', 'hour', 'accord', 'websit', 'http', 'much', 'nois', 'review', 'everi', 'year', 'good', 'work', 'author', 'proud', 'might', 'get', 'low', 'score', 'noisi', 'system', 'given', 'neurip', 'grow', 'larg', 'year', 'keep', 'mind', 'work', 'still', 'valuabl', 'matter', 'score', 'accord', 'program', 'chair', 'tweet', 'http', 'twitter', 'com', 'kchonyc', 'statu', 'seem', 'review', 'submit', 'hope', 'delay', 'releas', 'review', 'start', 'rebutt']"
72,79,79,sayan341,w9itas,[P] Luminaire v0.4.0 Release with Support up to python 3.10,Excited to share that the latest Luminaire v0.4.0 release has several new capabilities with support up to python 3.10 and other package upgrades. Checkout the latest release here: https://github.com/zillow/luminaire,0,1,2022-07-27 19:12:25, p  luminaire v   release with support up to python  ,excited to share that the latest luminaire v   release has several new capabilities with support up to python   and other package upgrades  checkout the latest release here  https   github com zillow luminaire,excited share latest luminaire v release several capabilities support python package upgrades checkout latest release https github com zillow luminaire,p luminaire v release support python,p luminaire v release support pythonexcited share latest luminaire v release several capabilities support python package upgrades checkout latest release https github com zillow luminaire,"['p', 'luminaire', 'v', 'release', 'support', 'pythonexcited', 'share', 'latest', 'luminaire', 'v', 'release', 'several', 'capabilities', 'support', 'python', 'package', 'upgrades', 'checkout', 'latest', 'release', 'https', 'github', 'com', 'zillow', 'luminaire']","['p', 'luminair', 'v', 'releas', 'support', 'pythonexcit', 'share', 'latest', 'luminair', 'v', 'releas', 'sever', 'capabl', 'support', 'python', 'packag', 'upgrad', 'checkout', 'latest', 'releas', 'http', 'github', 'com', 'zillow', 'luminair']"
73,80,80,forthispost96,w8wl0z,Training a Network on a Sine Wave [Discussion] [Research],"I've been attempting to train a simple feed-forward network on sine waves with various frequencies, such that:

y = sin( omega \* x), where my network takes x as input, and outputs y.

&#x200B;

https://preview.redd.it/81xdsas3kzd91.png?width=2230&format=png&auto=webp&s=0856824d215e0aebf8d20c1849b53433245bc91a

y is bounded between -1 and 1, whereas x is bounded between 0 and 2pi. I'm finding that I get interesting convergence behaviour as a function of x, where if I increase omega, values > \~3 seem to reconstruct poorly. The image attached shows this quite well for a sine wave with omega 7Hz. I feel like this shouldn't be happening, but does anyone have idea of why this could occur? If the input values are ""large"" (in this case >3), are the gradients too large and the model breaks? Any thoughts are appreciated!",16,18,2022-07-27 01:05:34,training a network on a sine wave  discussion   research ,i ve been attempting to train a simple feed forward network on sine waves with various frequencies  such that y   sin  omega    x   where my network takes x as input  and outputs y   xb https y is bounded between   and   whereas x is bounded between  and pi  i m finding that i get interesting convergence behaviour as a function of x  where if i increase omega  values      seem to reconstruct poorly  the image attached shows this quite well for a sine wave with omega hz  i feel like this shouldn t be happening  but does anyone have idea of why this could occur  if the input values are large  in this case     are the gradients too large and the model breaks  any thoughts are appreciated ,attempting train simple feed forward network sine waves various frequencies sin omega x network takes x input outputs xb https bounded whereas x bounded pi finding get interesting convergence behaviour function x increase omega values seem reconstruct poorly image attached shows quite well sine wave omega hz feel like happening anyone idea could occur input values large case gradients large model breaks thoughts appreciated,training network sine wave discussion research,training network sine wave discussion researchattempting train simple feed forward network sine waves various frequencies sin omega x network takes x input outputs xb https bounded whereas x bounded pi finding get interesting convergence behaviour function x increase omega values seem reconstruct poorly image attached shows quite well sine wave omega hz feel like happening anyone idea could occur input values large case gradients large model breaks thoughts appreciated,"['training', 'network', 'sine', 'wave', 'discussion', 'researchattempting', 'train', 'simple', 'feed', 'forward', 'network', 'sine', 'waves', 'various', 'frequencies', 'sin', 'omega', 'x', 'network', 'takes', 'x', 'input', 'outputs', 'xb', 'https', 'bounded', 'whereas', 'x', 'bounded', 'pi', 'finding', 'get', 'interesting', 'convergence', 'behaviour', 'function', 'x', 'increase', 'omega', 'values', 'seem', 'reconstruct', 'poorly', 'image', 'attached', 'shows', 'quite', 'well', 'sine', 'wave', 'omega', 'hz', 'feel', 'like', 'happening', 'anyone', 'idea', 'could', 'occur', 'input', 'values', 'large', 'case', 'gradients', 'large', 'model', 'breaks', 'thoughts', 'appreciated']","['train', 'network', 'sine', 'wave', 'discuss', 'researchattempt', 'train', 'simpl', 'feed', 'forward', 'network', 'sine', 'wave', 'variou', 'frequenc', 'sin', 'omega', 'x', 'network', 'take', 'x', 'input', 'output', 'xb', 'http', 'bound', 'wherea', 'x', 'bound', 'pi', 'find', 'get', 'interest', 'converg', 'behaviour', 'function', 'x', 'increas', 'omega', 'valu', 'seem', 'reconstruct', 'poorli', 'imag', 'attach', 'show', 'quit', 'well', 'sine', 'wave', 'omega', 'hz', 'feel', 'like', 'happen', 'anyon', 'idea', 'could', 'occur', 'input', 'valu', 'larg', 'case', 'gradient', 'larg', 'model', 'break', 'thought', 'appreci']"
74,81,81,IllustriousCicada603,w9elnb,[D] Can you turn a one-hot vector to a Embedding in a differentiable way.,"Is there a way to feed a one-hot (`[batch_size, seq_len, vocab_size]`) vector to \`nn.Embedding\` and get the same embeddings you would get from `[batch_size, seq_len]` integer tokens as an input and would that be differentiable?",4,1,2022-07-27 16:19:21, d  can you turn a one hot vector to a embedding in a differentiable way ,is there a way to feed a one hot    batch_size  seq_len  vocab_size    vector to   nn embedding   and get the same embeddings you would get from   batch_size  seq_len   integer tokens as an input and would that be differentiable ,way feed one hot batch_size seq_len vocab_size vector nn embedding get embeddings would get batch_size seq_len integer tokens input would differentiable,turn one hot vector embedding differentiable way,turn one hot vector embedding differentiable wayway feed one hot batch_size seq_len vocab_size vector nn embedding get embeddings would get batch_size seq_len integer tokens input would differentiable,"['turn', 'one', 'hot', 'vector', 'embedding', 'differentiable', 'wayway', 'feed', 'one', 'hot', 'batch_size', 'seq_len', 'vocab_size', 'vector', 'nn', 'embedding', 'get', 'embeddings', 'would', 'get', 'batch_size', 'seq_len', 'integer', 'tokens', 'input', 'would', 'differentiable']","['turn', 'one', 'hot', 'vector', 'embed', 'differenti', 'wayway', 'feed', 'one', 'hot', 'batch_siz', 'seq_len', 'vocab_s', 'vector', 'nn', 'embed', 'get', 'embed', 'would', 'get', 'batch_siz', 'seq_len', 'integ', 'token', 'input', 'would', 'differenti']"
75,82,82,patronus816,w96ev2,"[R] VITT in MOT ""Vision Transformer Tracker""","Was wondering if anyone was able to reproduce the results of this [paper](https://www.researchgate.net/publication/354069244_ViTT_Vision_Transformer_Tracker)?  
Their Github [repository](https://github.com/jiayannan/VITT) is also available for download, but for some reason when I run their training script on their repository, the results are... very different. For example a negative score instead of a ""generally positive"" one.",0,4,2022-07-27 08:42:17, r  vitt in mot vision transformer tracker,was wondering if anyone was able to reproduce the results of this  paper  https their github  repository  https   github com jiayannan vitt  is also available for download  but for some reason when i run their training script on their repository  the results are    very different  for example a negative score instead of a generally positive one ,wondering anyone able reproduce results paper https github repository https github com jiayannan vitt also available download reason run training script repository results different example negative score instead generally positive one,r vitt mot vision transformer tracker,r vitt mot vision transformer trackerwondering anyone able reproduce results paper https github repository https github com jiayannan vitt also available download reason run training script repository results different example negative score instead generally positive one,"['r', 'vitt', 'mot', 'vision', 'transformer', 'trackerwondering', 'anyone', 'able', 'reproduce', 'results', 'paper', 'https', 'github', 'repository', 'https', 'github', 'com', 'jiayannan', 'vitt', 'also', 'available', 'download', 'reason', 'run', 'training', 'script', 'repository', 'results', 'different', 'example', 'negative', 'score', 'instead', 'generally', 'positive', 'one']","['r', 'vitt', 'mot', 'vision', 'transform', 'trackerwond', 'anyon', 'abl', 'reproduc', 'result', 'paper', 'http', 'github', 'repositori', 'http', 'github', 'com', 'jiayannan', 'vitt', 'also', 'avail', 'download', 'reason', 'run', 'train', 'script', 'repositori', 'result', 'differ', 'exampl', 'neg', 'score', 'instead', 'gener', 'posit', 'one']"
76,83,83,Subject-Form,w95d0h,[P] Request: Any datasets of morality stories?,"I'm  looking for a dataset (or just a collection of short stories) that has  lots of characters talk about their values and take actions that try to  achieve their values. I'm specifically not looking for datasets like [ETHICS](https://arxiv.org/abs/2008.02275),  which only have short text fragments and not full stories. Basically,  I'm looking for values embedded in a somewhat natural linguistic  context.

Thanks for your help!",3,4,2022-07-27 07:46:03, p  request  any datasets of morality stories ,i m  looking for a dataset  or just a collection of short stories  that has  lots of characters talk about their values and take actions that try to  achieve their values  i m specifically not looking for datasets like  ethics  https thanks for your help ,looking dataset collection short stories lots characters talk values take actions try achieve values specifically looking datasets like ethics https thanks help,p request datasets morality stories,p request datasets morality storieslooking dataset collection short stories lots characters talk values take actions try achieve values specifically looking datasets like ethics https thanks help,"['p', 'request', 'datasets', 'morality', 'storieslooking', 'dataset', 'collection', 'short', 'stories', 'lots', 'characters', 'talk', 'values', 'take', 'actions', 'try', 'achieve', 'values', 'specifically', 'looking', 'datasets', 'like', 'ethics', 'https', 'thanks', 'help']","['p', 'request', 'dataset', 'moral', 'storieslook', 'dataset', 'collect', 'short', 'stori', 'lot', 'charact', 'talk', 'valu', 'take', 'action', 'tri', 'achiev', 'valu', 'specif', 'look', 'dataset', 'like', 'ethic', 'http', 'thank', 'help']"
77,84,84,fromnighttilldawn,w8dip8,[D] Are there any famous or well-cited ML papers with errors in them?,I'm curious if anyone knows about a famous or well-cited ML paper with errors and whether such error was addressed in follow ups.,70,158,2022-07-26 10:41:34, d  are there any famous or well cited ml papers with errors in them ,i m curious if anyone knows about a famous or well cited ml paper with errors and whether such error was addressed in follow ups ,curious anyone knows famous well cited ml paper errors whether error addressed follow ups,famous well cited ml papers errors,famous well cited ml papers errorscurious anyone knows famous well cited ml paper errors whether error addressed follow ups,"['famous', 'well', 'cited', 'ml', 'papers', 'errorscurious', 'anyone', 'knows', 'famous', 'well', 'cited', 'ml', 'paper', 'errors', 'whether', 'error', 'addressed', 'follow', 'ups']","['famou', 'well', 'cite', 'ml', 'paper', 'errorscuri', 'anyon', 'know', 'famou', 'well', 'cite', 'ml', 'paper', 'error', 'whether', 'error', 'address', 'follow', 'up']"
78,85,85,Zephyrus_2002,w9le1f,[D] Help needed! The code in the OpenAI gym documentation does not work.,"I am an absolute beginner in reinforcement learning. I'm trying to execute the second code snippet given [here](https://www.gymlibrary.ml/content/api/). I'm using python version 3.9.12 as part of the anaconda package. Curiously, no error is thrown when I try to execute this code in a kaggle notebook except for the fact that the notebook can obviously not display the output environment. I checked the version of python in kaggle, and it's 3.7.12Is that the cause behind this issue? Moreover, I was playing around with the code given in the documentation and was able to modify it such that it inadvertently worked natively on my machine. Attaching a screenshot of my code. Can somebody please tell me if I'm doing something wrong? If it is because of the python version, what kind of changes would I have to make in the code given in the OpenAI documentation? Thanks in advance.

Edit: Added the output of my code, the code from the openai documentation, the error that is being thrown by the code from the openai documentation. I've also tried googling the error message I'm seeing, but I didn't find anything relevant.

\*\*\*\*\*\*\*\*\*My code\*\*\*\*\*\*\*\*\*\*\*

import gym

env = gym.make(""LunarLander-v2"")

info = env.reset()

&#x200B;

for \_ in range(1000):

env.render()

action = env.action\_space.sample()

observation, reward, done, info = env.step(action)

&#x200B;

if done:

observation, info = env.reset(return\_info=True)

env.close()

\*\*\*\*\*\*\*\*\*My code\*\*\*\*\*\*\*\*\*\*\*\*\*

&#x200B;

\*\*\*\*\*\*Code from OpenAI documentation\*\*\*\*\*\*\*

import gym

env = gym.make(""LunarLander-v2"", render\_mode=""human"")

env.action\_space.seed(42)

&#x200B;

observation, info = env.reset(seed=42, return\_info=True)

&#x200B;

for \_ in range(1000):

observation, reward, done, info = env.step(env.action\_space.sample())

&#x200B;

if done:

observation, info = env.reset(return\_info=True)

&#x200B;

env.close()

\*\*\*\*\*\*Code from OpenAI documentation\*\*\*\*\*\*\*

&#x200B;

&#x200B;

\*\*\*error thrown by code from OpenAI documentation\*\*\*

env = gym.make(""LunarLander-v2"", render\_mode=""human"")

File ""C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\gym\\envs\\registration.py"", line 592, in make

env = env\_creator(\*\*\_kwargs)

TypeError: \_\_init\_\_() got an unexpected keyword argument 'render\_mode'

\*\*\*error thrown by code from OpenAI documentation\*\*\*",6,0,2022-07-27 20:56:13, d  help needed  the code in the openai gym documentation does not work ,i am an absolute beginner in reinforcement learning  i m trying to execute the second code snippet given  here  https edit  added the output of my code  the code from the openai documentation  the error that is being thrown by the code from the openai documentation  i ve also tried googling the error message i m seeing  but i didn t find anything relevant                   my code                      import gymenv   gym make lunarlander v info   env reset    xb for  _ in range   env render  action   env action _space sample  observation  reward  done  info   env step action   xb if done observation  info   env reset return _info true env close                    my code                            xb             code from openai documentation              import gymenv   gym make lunarlander v  render _mode human env action _space seed    xb observation  info   env reset seed   return _info true   xb for  _ in range   observation  reward  done  info   env step env action _space sample     xb if done observation  info   env reset return _info true   xb env close              code from openai documentation                xb   xb       error thrown by code from openai documentation      env   gym make lunarlander v  render _mode human file c   users  shubh  anaconda  lib  site packages  gym  envs  registration py  line   in makeenv   env _creator      _kwargs typeerror   _ _init _ _   got an unexpected keyword argument  render _mode       error thrown by code from openai documentation      ,absolute beginner reinforcement learning trying execute second code snippet given https edit added output code code openai documentation error thrown code openai documentation also tried googling error message seeing find anything relevant code import gymenv gym make lunarlander v info env reset xb _ range env render action env action _space sample observation reward done info env step action xb done observation info env reset return _info true env close code xb code openai documentation import gymenv gym make lunarlander v render _mode human env action _space seed xb observation info env reset seed return _info true xb _ range observation reward done info env step env action _space sample xb done observation info env reset return _info true xb env close code openai documentation xb xb error thrown code openai documentation env gym make lunarlander v render _mode human file c users shubh anaconda lib site packages gym envs registration py line makeenv env _creator _kwargs typeerror _ _init _ _ got unexpected keyword argument render _mode error thrown code openai documentation,help needed code openai gym documentation work,help needed code openai gym documentation workabsolute beginner reinforcement learning trying execute second code snippet given https edit added output code code openai documentation error thrown code openai documentation also tried googling error message seeing find anything relevant code import gymenv gym make lunarlander v info env reset xb _ range env render action env action _space sample observation reward done info env step action xb done observation info env reset return _info true env close code xb code openai documentation import gymenv gym make lunarlander v render _mode human env action _space seed xb observation info env reset seed return _info true xb _ range observation reward done info env step env action _space sample xb done observation info env reset return _info true xb env close code openai documentation xb xb error thrown code openai documentation env gym make lunarlander v render _mode human file c users shubh anaconda lib site packages gym envs registration py line makeenv env _creator _kwargs typeerror _ _init _ _ got unexpected keyword argument render _mode error thrown code openai documentation,"['help', 'needed', 'code', 'openai', 'gym', 'documentation', 'workabsolute', 'beginner', 'reinforcement', 'learning', 'trying', 'execute', 'second', 'code', 'snippet', 'given', 'https', 'edit', 'added', 'output', 'code', 'code', 'openai', 'documentation', 'error', 'thrown', 'code', 'openai', 'documentation', 'also', 'tried', 'googling', 'error', 'message', 'seeing', 'find', 'anything', 'relevant', 'code', 'import', 'gymenv', 'gym', 'make', 'lunarlander', 'v', 'info', 'env', 'reset', 'xb', '_', 'range', 'env', 'render', 'action', 'env', 'action', '_space', 'sample', 'observation', 'reward', 'done', 'info', 'env', 'step', 'action', 'xb', 'done', 'observation', 'info', 'env', 'reset', 'return', '_info', 'true', 'env', 'close', 'code', 'xb', 'code', 'openai', 'documentation', 'import', 'gymenv', 'gym', 'make', 'lunarlander', 'v', 'render', '_mode', 'human', 'env', 'action', '_space', 'seed', 'xb', 'observation', 'info', 'env', 'reset', 'seed', 'return', '_info', 'true', 'xb', '_', 'range', 'observation', 'reward', 'done', 'info', 'env', 'step', 'env', 'action', '_space', 'sample', 'xb', 'done', 'observation', 'info', 'env', 'reset', 'return', '_info', 'true', 'xb', 'env', 'close', 'code', 'openai', 'documentation', 'xb', 'xb', 'error', 'thrown', 'code', 'openai', 'documentation', 'env', 'gym', 'make', 'lunarlander', 'v', 'render', '_mode', 'human', 'file', 'c', 'users', 'shubh', 'anaconda', 'lib', 'site', 'packages', 'gym', 'envs', 'registration', 'py', 'line', 'makeenv', 'env', '_creator', '_kwargs', 'typeerror', '_', '_init', '_', '_', 'got', 'unexpected', 'keyword', 'argument', 'render', '_mode', 'error', 'thrown', 'code', 'openai', 'documentation']","['help', 'need', 'code', 'openai', 'gym', 'document', 'workabsolut', 'beginn', 'reinforc', 'learn', 'tri', 'execut', 'second', 'code', 'snippet', 'given', 'http', 'edit', 'ad', 'output', 'code', 'code', 'openai', 'document', 'error', 'thrown', 'code', 'openai', 'document', 'also', 'tri', 'googl', 'error', 'messag', 'see', 'find', 'anyth', 'relev', 'code', 'import', 'gymenv', 'gym', 'make', 'lunarland', 'v', 'info', 'env', 'reset', 'xb', '_', 'rang', 'env', 'render', 'action', 'env', 'action', '_space', 'sampl', 'observ', 'reward', 'done', 'info', 'env', 'step', 'action', 'xb', 'done', 'observ', 'info', 'env', 'reset', 'return', '_info', 'true', 'env', 'close', 'code', 'xb', 'code', 'openai', 'document', 'import', 'gymenv', 'gym', 'make', 'lunarland', 'v', 'render', '_mode', 'human', 'env', 'action', '_space', 'seed', 'xb', 'observ', 'info', 'env', 'reset', 'seed', 'return', '_info', 'true', 'xb', '_', 'rang', 'observ', 'reward', 'done', 'info', 'env', 'step', 'env', 'action', '_space', 'sampl', 'xb', 'done', 'observ', 'info', 'env', 'reset', 'return', '_info', 'true', 'xb', 'env', 'close', 'code', 'openai', 'document', 'xb', 'xb', 'error', 'thrown', 'code', 'openai', 'document', 'env', 'gym', 'make', 'lunarland', 'v', 'render', '_mode', 'human', 'file', 'c', 'user', 'shubh', 'anaconda', 'lib', 'site', 'packag', 'gym', 'env', 'registr', 'py', 'line', 'makeenv', 'env', '_creator', '_kwarg', 'typeerror', '_', '_init', '_', '_', 'got', 'unexpect', 'keyword', 'argument', 'render', '_mode', 'error', 'thrown', 'code', 'openai', 'document']"
79,86,86,XinshaoWang,w8tdgc,[R] ProSelfLC: Progressive Self Label Correction Towards A Low-Temperature Entropy State,"Though [this research](https://arxiv.org/abs/2207.00118) studies deep machine learning, its findings are quite consistent with human learning.

* (1) When a trainee is given noisy (e.g., wrong or biased) supervision, it will fit noise (e.g., error or bias).
* (2) When the supervision and guidance contain more noise, the trainee will learn less confidently.

&#x200B;

We present a new insightful finding to complement a previous one “**deep neural networks easily fit random labels** (Understanding deep learning requires rethinking, Zhang et al., ICLR 2017)”: **Deep models fit and generalise significantly less confident when more random labels exist**.

Correspondingly, we propose to decrease the entropy of self knowledge using an Annealed Temperature (AT) and learn towards a revised low-temperature entropy state.

&#x200B;

Read more if your are interested: [https://arxiv.org/abs/2207.00118](https://arxiv.org/abs/2207.00118)",3,6,2022-07-26 22:57:08, r  proselflc  progressive self label correction towards a low temperature entropy state,though  this research  https      when a trainee is given noisy  e g   wrong or biased  supervision  it will fit noise  e g   error or bias       when the supervision and guidance contain more noise  the trainee will learn less confidently   xb we present a new insightful finding to complement a previous one    deep neural networks easily fit random labels    understanding deep learning requires rethinking  zhang et al   iclr       deep models fit and generalise significantly less confident when more random labels exist   correspondingly  we propose to decrease the entropy of self knowledge using an annealed temperature  at  and learn towards a revised low temperature entropy state   xb read more if your are interested   https   arxiv org abs    https   arxiv org abs   ,though research https trainee given noisy e g wrong biased supervision fit noise e g error bias supervision guidance contain noise trainee learn less confidently xb present insightful finding complement previous one deep neural networks easily fit random labels understanding deep learning requires rethinking zhang et al iclr deep models fit generalise significantly less confident random labels exist correspondingly propose decrease entropy self knowledge using annealed temperature learn towards revised low temperature entropy state xb read interested https arxiv org abs https arxiv org abs,r proselflc progressive self label correction towards low temperature entropy state,r proselflc progressive self label correction towards low temperature entropy statethough research https trainee given noisy e g wrong biased supervision fit noise e g error bias supervision guidance contain noise trainee learn less confidently xb present insightful finding complement previous one deep neural networks easily fit random labels understanding deep learning requires rethinking zhang et al iclr deep models fit generalise significantly less confident random labels exist correspondingly propose decrease entropy self knowledge using annealed temperature learn towards revised low temperature entropy state xb read interested https arxiv org abs https arxiv org abs,"['r', 'proselflc', 'progressive', 'self', 'label', 'correction', 'towards', 'low', 'temperature', 'entropy', 'statethough', 'research', 'https', 'trainee', 'given', 'noisy', 'e', 'g', 'wrong', 'biased', 'supervision', 'fit', 'noise', 'e', 'g', 'error', 'bias', 'supervision', 'guidance', 'contain', 'noise', 'trainee', 'learn', 'less', 'confidently', 'xb', 'present', 'insightful', 'finding', 'complement', 'previous', 'one', 'deep', 'neural', 'networks', 'easily', 'fit', 'random', 'labels', 'understanding', 'deep', 'learning', 'requires', 'rethinking', 'zhang', 'et', 'al', 'iclr', 'deep', 'models', 'fit', 'generalise', 'significantly', 'less', 'confident', 'random', 'labels', 'exist', 'correspondingly', 'propose', 'decrease', 'entropy', 'self', 'knowledge', 'using', 'annealed', 'temperature', 'learn', 'towards', 'revised', 'low', 'temperature', 'entropy', 'state', 'xb', 'read', 'interested', 'https', 'arxiv', 'org', 'abs', 'https', 'arxiv', 'org', 'abs']","['r', 'proselflc', 'progress', 'self', 'label', 'correct', 'toward', 'low', 'temperatur', 'entropi', 'statethough', 'research', 'http', 'traine', 'given', 'noisi', 'e', 'g', 'wrong', 'bias', 'supervis', 'fit', 'nois', 'e', 'g', 'error', 'bia', 'supervis', 'guidanc', 'contain', 'nois', 'traine', 'learn', 'less', 'confid', 'xb', 'present', 'insight', 'find', 'complement', 'previou', 'one', 'deep', 'neural', 'network', 'easili', 'fit', 'random', 'label', 'understand', 'deep', 'learn', 'requir', 'rethink', 'zhang', 'et', 'al', 'iclr', 'deep', 'model', 'fit', 'generalis', 'significantli', 'less', 'confid', 'random', 'label', 'exist', 'correspondingli', 'propos', 'decreas', 'entropi', 'self', 'knowledg', 'use', 'anneal', 'temperatur', 'learn', 'toward', 'revis', 'low', 'temperatur', 'entropi', 'state', 'xb', 'read', 'interest', 'http', 'arxiv', 'org', 'ab', 'http', 'arxiv', 'org', 'ab']"
80,87,87,DeepDeeperRIPgradien,w8fmuo,[D] State-of-the-Art for Self-Supervised (Pre-)Training of CNN architectures (e.g. ResNet)?,"Hello, I lost a bit of touch to the current SOTA of self-supervised pretraining of CNNs, in particular ResNet. I found this repository https://github.com/vturrisi/solo-learn that has many methods implemented but I'm not really sure where to start. My goal is to pretrain a ResNet backbone on a decently large amount of image data that comes from a certain domain and after that fine-tune it for different downstream tasks (classification, segmentation, object detection) on a subset of the data I have labels for.

Would be grateful for some tips how/where I should start and what the most promising SSL method would be.",6,23,2022-07-26 12:53:29, d  state of the art for self supervised  pre  training of cnn architectures  e g  resnet  ,hello  i lost a bit of touch to the current sota of self supervised pretraining of cnns  in particular resnet  i found this repository https would be grateful for some tips how where i should start and what the most promising ssl method would be ,hello lost bit touch current sota self supervised pretraining cnns particular resnet found repository https would grateful tips start promising ssl method would,state art self supervised pre training cnn architectures e g resnet,state art self supervised pre training cnn architectures e g resnethello lost bit touch current sota self supervised pretraining cnns particular resnet found repository https would grateful tips start promising ssl method would,"['state', 'art', 'self', 'supervised', 'pre', 'training', 'cnn', 'architectures', 'e', 'g', 'resnethello', 'lost', 'bit', 'touch', 'current', 'sota', 'self', 'supervised', 'pretraining', 'cnns', 'particular', 'resnet', 'found', 'repository', 'https', 'would', 'grateful', 'tips', 'start', 'promising', 'ssl', 'method', 'would']","['state', 'art', 'self', 'supervis', 'pre', 'train', 'cnn', 'architectur', 'e', 'g', 'resnethello', 'lost', 'bit', 'touch', 'current', 'sota', 'self', 'supervis', 'pretrain', 'cnn', 'particular', 'resnet', 'found', 'repositori', 'http', 'would', 'grate', 'tip', 'start', 'promis', 'ssl', 'method', 'would']"
81,88,88,ahmedashrafhamdy,w8oovg,[P] Anees: a multi-turn open-domain Arabic chatbot with a wide set of features,"**Anees** is an Arabic chatbot that can speak to users on different topics or an open-domain multi-turn conversation rather than a specific domain. Anees is your personal AI friend that you can express and witness yourself through a helpful and empathetic conversation. Anees offers a set of features like natural language understanding, emotion classification, intent classification, weather/schedule, recommendation, and natural language generation.

For the code and implementation details: [https://github.com/aashrafh/Anees](https://github.com/aashrafh/Anees)",2,5,2022-07-26 19:49:02, p  anees  a multi turn open domain arabic chatbot with a wide set of features,  anees   is an arabic chatbot that can speak to users on different topics or an open domain multi turn conversation rather than a specific domain  anees is your personal ai friend that you can express and witness yourself through a helpful and empathetic conversation  anees offers a set of features like natural language understanding  emotion classification  intent classification  weather schedule  recommendation  and natural language generation for the code and implementation details   https   github com aashrafh anees  https   github com aashrafh anees ,anees arabic chatbot speak users different topics open domain multi turn conversation rather specific domain anees personal ai friend express witness helpful empathetic conversation anees offers set features like natural language understanding emotion classification intent classification weather schedule recommendation natural language generation code implementation details https github com aashrafh anees https github com aashrafh anees,p anees multi turn open domain arabic chatbot wide set features,p anees multi turn open domain arabic chatbot wide set featuresanees arabic chatbot speak users different topics open domain multi turn conversation rather specific domain anees personal ai friend express witness helpful empathetic conversation anees offers set features like natural language understanding emotion classification intent classification weather schedule recommendation natural language generation code implementation details https github com aashrafh anees https github com aashrafh anees,"['p', 'anees', 'multi', 'turn', 'open', 'domain', 'arabic', 'chatbot', 'wide', 'set', 'featuresanees', 'arabic', 'chatbot', 'speak', 'users', 'different', 'topics', 'open', 'domain', 'multi', 'turn', 'conversation', 'rather', 'specific', 'domain', 'anees', 'personal', 'ai', 'friend', 'express', 'witness', 'helpful', 'empathetic', 'conversation', 'anees', 'offers', 'set', 'features', 'like', 'natural', 'language', 'understanding', 'emotion', 'classification', 'intent', 'classification', 'weather', 'schedule', 'recommendation', 'natural', 'language', 'generation', 'code', 'implementation', 'details', 'https', 'github', 'com', 'aashrafh', 'anees', 'https', 'github', 'com', 'aashrafh', 'anees']","['p', 'ane', 'multi', 'turn', 'open', 'domain', 'arab', 'chatbot', 'wide', 'set', 'featuresane', 'arab', 'chatbot', 'speak', 'user', 'differ', 'topic', 'open', 'domain', 'multi', 'turn', 'convers', 'rather', 'specif', 'domain', 'ane', 'person', 'ai', 'friend', 'express', 'wit', 'help', 'empathet', 'convers', 'ane', 'offer', 'set', 'featur', 'like', 'natur', 'languag', 'understand', 'emot', 'classif', 'intent', 'classif', 'weather', 'schedul', 'recommend', 'natur', 'languag', 'gener', 'code', 'implement', 'detail', 'http', 'github', 'com', 'aashrafh', 'ane', 'http', 'github', 'com', 'aashrafh', 'ane']"
82,89,89,AlanRoofies,w9cimv,"[D] I hate the word ""Latent""","I was reading another paper today with the word ""latent"" and I have had enough. I genuinely still don't understand hat this word mean. Not only that, but I feel like it's used whenever people want to complicate what they are trying to explain. No one can even explain it in a single logical, easy to understand manner. I have asked multiple people in the past couple of months, and everyone has a DIFFERENT explanation.

Can we please stop using big words just to sound smart.",38,0,2022-07-27 14:43:11, d  i hate the word latent,i was reading another paper today with the word latent and i have had enough  i genuinely still don t understand hat this word mean  not only that  but i feel like it s used whenever people want to complicate what they are trying to explain  no one can even explain it in a single logical  easy to understand manner  i have asked multiple people in the past couple of months  and everyone has a different explanation can we please stop using big words just to sound smart ,reading another paper today word latent enough genuinely still understand hat word mean feel like used whenever people want complicate trying explain one even explain single logical easy understand manner asked multiple people past couple months everyone different explanation please stop using big sound smart,hate word latent,hate word latentreading another paper today word latent enough genuinely still understand hat word mean feel like used whenever people want complicate trying explain one even explain single logical easy understand manner asked multiple people past couple months everyone different explanation please stop using big sound smart,"['hate', 'word', 'latentreading', 'another', 'paper', 'today', 'word', 'latent', 'enough', 'genuinely', 'still', 'understand', 'hat', 'word', 'mean', 'feel', 'like', 'used', 'whenever', 'people', 'want', 'complicate', 'trying', 'explain', 'one', 'even', 'explain', 'single', 'logical', 'easy', 'understand', 'manner', 'asked', 'multiple', 'people', 'past', 'couple', 'months', 'everyone', 'different', 'explanation', 'please', 'stop', 'using', 'big', 'sound', 'smart']","['hate', 'word', 'latentread', 'anoth', 'paper', 'today', 'word', 'latent', 'enough', 'genuin', 'still', 'understand', 'hat', 'word', 'mean', 'feel', 'like', 'use', 'whenev', 'peopl', 'want', 'complic', 'tri', 'explain', 'one', 'even', 'explain', 'singl', 'logic', 'easi', 'understand', 'manner', 'ask', 'multipl', 'peopl', 'past', 'coupl', 'month', 'everyon', 'differ', 'explan', 'pleas', 'stop', 'use', 'big', 'sound', 'smart']"
83,90,90,ollie_wollie_rocks,w8ace0,[D] MLOps Community (recorded) session on new open source data prep tool,"Quickly move your notebooks from research to production with no extra work!  
[https://www.youtube.com/watch?v=6Iyt9Wip3C4](https://www.youtube.com/watch?v=6Iyt9Wip3C4)

Mage is an open-source code editor for **transforming data** and building **ML pipelines**. 

Link to tool: [https://github.com/mage-ai/mage-ai](https://github.com/mage-ai/mage-ai)",3,20,2022-07-26 07:40:06, d  mlops community  recorded  session on new open source data prep tool,quickly move your notebooks from research to production with no extra work    https mage is an open source code editor for   transforming data   and building   ml pipelines    link to tool   https   github com mage ai mage ai  https   github com mage ai mage ai ,quickly move notebooks research production extra work https mage open source code editor transforming data building ml pipelines link tool https github com mage ai mage ai https github com mage ai mage ai,mlops community recorded session open source data prep tool,mlops community recorded session open source data prep toolquickly move notebooks research production extra work https mage open source code editor transforming data building ml pipelines link tool https github com mage ai mage ai https github com mage ai mage ai,"['mlops', 'community', 'recorded', 'session', 'open', 'source', 'data', 'prep', 'toolquickly', 'move', 'notebooks', 'research', 'production', 'extra', 'work', 'https', 'mage', 'open', 'source', 'code', 'editor', 'transforming', 'data', 'building', 'ml', 'pipelines', 'link', 'tool', 'https', 'github', 'com', 'mage', 'ai', 'mage', 'ai', 'https', 'github', 'com', 'mage', 'ai', 'mage', 'ai']","['mlop', 'commun', 'record', 'session', 'open', 'sourc', 'data', 'prep', 'toolquickli', 'move', 'notebook', 'research', 'product', 'extra', 'work', 'http', 'mage', 'open', 'sourc', 'code', 'editor', 'transform', 'data', 'build', 'ml', 'pipelin', 'link', 'tool', 'http', 'github', 'com', 'mage', 'ai', 'mage', 'ai', 'http', 'github', 'com', 'mage', 'ai', 'mage', 'ai']"
84,91,91,lifesthateasy,w8mw4j,[D] What else am I missing from the ML data-to-model workflow?,"I am mostly self-taught in ML and have been working with some clients as a lone contractor but never with a full ML team. I've recently been on an interview, where they asked what I know about inference. And frankly, nothing. Apparently they run t-tests and ANOVA and stuff (which I do know from Uni but haven't used in a while) to make sure they can explain exactly what feature correlates with what without risking removing multicollinear-looking columns that aren't actually multicollinear. So I guess I have some big gaps and now I started wondering what else I'm missing.

My process is usually as follows:

1. Get data
2. Check descriptive statistics
3. Impute missing data (may it be simple fillnan up to synthetic data generation)
4. Drop columns that are not usable due to data quality issues
5. Transform data into numeric (basically, encoding, anything from OneHot to TargetEncoding)
6. Look at distributions
7. Check for outliers
8. Check VIF to remove multicollinearity
9. Define a baseline and target variable
10. Apply logic to prevent data leakage (drop columns that are dependent on each other with the target variable)
11. Define metrics
12. Start modeling
13. Check metrics and refine hyperparams/change model if needed
14. Go back to data preprocessing and see if other methods/more data cleaning improves model

I guess ""inference"" would come somewhere between 2 and 12, but I have very little idea about what it means.

Is inference the only step I'm missing here, given a workflow that starts with getting the data and ends with delivering a model (NOT putting it into production, I understand there's multiple steps for that too)?",2,1,2022-07-26 18:37:09, d  what else am i missing from the ml data to model workflow ,i am mostly self taught in ml and have been working with some clients as a lone contractor but never with a full ml team  i ve recently been on an interview  where they asked what i know about inference  and frankly  nothing  apparently they run t tests and anova and stuff  which i do know from uni but haven t used in a while  to make sure they can explain exactly what feature correlates with what without risking removing multicollinear looking columns that aren t actually multicollinear  so i guess i have some big gaps and now i started wondering what else i m missing my process is usually as follows   get data  check descriptive statistics  impute missing data  may it be simple fillnan up to synthetic data generation   drop columns that are not usable due to data quality issues  transform data into numeric  basically  encoding  anything from onehot to targetencoding   look at distributions  check for outliers  check vif to remove multicollinearity  define a baseline and target variable  apply logic to prevent data leakage  drop columns that are dependent on each other with the target variable   define metrics  start modeling  check metrics and refine hyperparams change model if needed  go back to data preprocessing and see if other methods more data cleaning improves modeli guess inference would come somewhere between  and   but i have very little idea about what it means is inference the only step i m missing here  given a workflow that starts with getting the data and ends with delivering a model  not putting it into production  i understand there s multiple steps for that too  ,mostly self taught ml working clients lone contractor never full ml team recently interview asked know inference frankly nothing apparently run tests anova stuff know uni used make sure explain exactly feature correlates without risking removing multicollinear looking columns actually multicollinear guess big gaps started wondering else missing process usually follows get data check descriptive statistics impute missing data may simple fillnan synthetic data generation drop columns usable due data quality issues transform data numeric basically encoding anything onehot targetencoding look distributions check outliers check vif remove multicollinearity define baseline target variable apply logic prevent data leakage drop columns dependent target variable define metrics start modeling check metrics refine hyperparams change model needed go back data preprocessing see methods data cleaning improves modeli guess inference would come somewhere little idea means inference step missing given workflow starts getting data ends delivering model putting production understand multiple steps,else missing ml data model workflow,else missing ml data model workflowmostly self taught ml working clients lone contractor never full ml team recently interview asked know inference frankly nothing apparently run tests anova stuff know uni used make sure explain exactly feature correlates without risking removing multicollinear looking columns actually multicollinear guess big gaps started wondering else missing process usually follows get data check descriptive statistics impute missing data may simple fillnan synthetic data generation drop columns usable due data quality issues transform data numeric basically encoding anything onehot targetencoding look distributions check outliers check vif remove multicollinearity define baseline target variable apply logic prevent data leakage drop columns dependent target variable define metrics start modeling check metrics refine hyperparams change model needed go back data preprocessing see methods data cleaning improves modeli guess inference would come somewhere little idea means inference step missing given workflow starts getting data ends delivering model putting production understand multiple steps,"['else', 'missing', 'ml', 'data', 'model', 'workflowmostly', 'self', 'taught', 'ml', 'working', 'clients', 'lone', 'contractor', 'never', 'full', 'ml', 'team', 'recently', 'interview', 'asked', 'know', 'inference', 'frankly', 'nothing', 'apparently', 'run', 'tests', 'anova', 'stuff', 'know', 'uni', 'used', 'make', 'sure', 'explain', 'exactly', 'feature', 'correlates', 'without', 'risking', 'removing', 'multicollinear', 'looking', 'columns', 'actually', 'multicollinear', 'guess', 'big', 'gaps', 'started', 'wondering', 'else', 'missing', 'process', 'usually', 'follows', 'get', 'data', 'check', 'descriptive', 'statistics', 'impute', 'missing', 'data', 'may', 'simple', 'fillnan', 'synthetic', 'data', 'generation', 'drop', 'columns', 'usable', 'due', 'data', 'quality', 'issues', 'transform', 'data', 'numeric', 'basically', 'encoding', 'anything', 'onehot', 'targetencoding', 'look', 'distributions', 'check', 'outliers', 'check', 'vif', 'remove', 'multicollinearity', 'define', 'baseline', 'target', 'variable', 'apply', 'logic', 'prevent', 'data', 'leakage', 'drop', 'columns', 'dependent', 'target', 'variable', 'define', 'metrics', 'start', 'modeling', 'check', 'metrics', 'refine', 'hyperparams', 'change', 'model', 'needed', 'go', 'back', 'data', 'preprocessing', 'see', 'methods', 'data', 'cleaning', 'improves', 'modeli', 'guess', 'inference', 'would', 'come', 'somewhere', 'little', 'idea', 'means', 'inference', 'step', 'missing', 'given', 'workflow', 'starts', 'getting', 'data', 'ends', 'delivering', 'model', 'putting', 'production', 'understand', 'multiple', 'steps']","['els', 'miss', 'ml', 'data', 'model', 'workflowmostli', 'self', 'taught', 'ml', 'work', 'client', 'lone', 'contractor', 'never', 'full', 'ml', 'team', 'recent', 'interview', 'ask', 'know', 'infer', 'frankli', 'noth', 'appar', 'run', 'test', 'anova', 'stuff', 'know', 'uni', 'use', 'make', 'sure', 'explain', 'exactli', 'featur', 'correl', 'without', 'risk', 'remov', 'multicollinear', 'look', 'column', 'actual', 'multicollinear', 'guess', 'big', 'gap', 'start', 'wonder', 'els', 'miss', 'process', 'usual', 'follow', 'get', 'data', 'check', 'descript', 'statist', 'imput', 'miss', 'data', 'may', 'simpl', 'fillnan', 'synthet', 'data', 'gener', 'drop', 'column', 'usabl', 'due', 'data', 'qualiti', 'issu', 'transform', 'data', 'numer', 'basic', 'encod', 'anyth', 'onehot', 'targetencod', 'look', 'distribut', 'check', 'outlier', 'check', 'vif', 'remov', 'multicollinear', 'defin', 'baselin', 'target', 'variabl', 'appli', 'logic', 'prevent', 'data', 'leakag', 'drop', 'column', 'depend', 'target', 'variabl', 'defin', 'metric', 'start', 'model', 'check', 'metric', 'refin', 'hyperparam', 'chang', 'model', 'need', 'go', 'back', 'data', 'preprocess', 'see', 'method', 'data', 'clean', 'improv', 'mode', 'guess', 'infer', 'would', 'come', 'somewher', 'littl', 'idea', 'mean', 'infer', 'step', 'miss', 'given', 'workflow', 'start', 'get', 'data', 'end', 'deliv', 'model', 'put', 'product', 'understand', 'multipl', 'step']"
85,92,92,_Arsenie_Boca_,w8eoew,[D] Transferability of learned (soft) prompts between tasks,"Im currently reading up on many different forms of prompt learning, especially soft / continuous prompts like p-tuning and prefix tuning.

I was hoping that any of those papers did an ablation on transfering the prompts between datasets of the same task type (e.g. between two QA tasks). But I couldnt find any experiments of that kind.

Are you aware of any work that investigated that topic? Any pointers are much appreciated, no matter if soft or hard prompts.",0,4,2022-07-26 11:54:19, d  transferability of learned  soft  prompts between tasks,im currently reading up on many different forms of prompt learning  especially soft   continuous prompts like p tuning and prefix tuning i was hoping that any of those papers did an ablation on transfering the prompts between datasets of the same task type  e g  between two qa tasks   but i couldnt find any experiments of that kind are you aware of any work that investigated that topic  any pointers are much appreciated  no matter if soft or hard prompts ,im currently reading many different forms prompt learning especially soft continuous prompts like p tuning prefix tuning hoping papers ablation transfering prompts datasets task type e g two qa tasks couldnt find experiments kind aware work investigated topic pointers much appreciated matter soft hard prompts,transferability learned soft prompts tasks,transferability learned soft prompts tasksim currently reading many different forms prompt learning especially soft continuous prompts like p tuning prefix tuning hoping papers ablation transfering prompts datasets task type e g two qa tasks couldnt find experiments kind aware work investigated topic pointers much appreciated matter soft hard prompts,"['transferability', 'learned', 'soft', 'prompts', 'tasksim', 'currently', 'reading', 'many', 'different', 'forms', 'prompt', 'learning', 'especially', 'soft', 'continuous', 'prompts', 'like', 'p', 'tuning', 'prefix', 'tuning', 'hoping', 'papers', 'ablation', 'transfering', 'prompts', 'datasets', 'task', 'type', 'e', 'g', 'two', 'qa', 'tasks', 'couldnt', 'find', 'experiments', 'kind', 'aware', 'work', 'investigated', 'topic', 'pointers', 'much', 'appreciated', 'matter', 'soft', 'hard', 'prompts']","['transfer', 'learn', 'soft', 'prompt', 'tasksim', 'current', 'read', 'mani', 'differ', 'form', 'prompt', 'learn', 'especi', 'soft', 'continu', 'prompt', 'like', 'p', 'tune', 'prefix', 'tune', 'hope', 'paper', 'ablat', 'transfer', 'prompt', 'dataset', 'task', 'type', 'e', 'g', 'two', 'qa', 'task', 'couldnt', 'find', 'experi', 'kind', 'awar', 'work', 'investig', 'topic', 'pointer', 'much', 'appreci', 'matter', 'soft', 'hard', 'prompt']"
86,93,93,Gio_at_QRC,w8cv6f,[D] Pretrained language models for production or train a model,"I am frequently working with text embeddings produced by large pre-trained models. They work quite well, but I do want to hear your thoughts on when it would be better to train your own model. What are your thoughts?",3,4,2022-07-26 10:02:03, d  pretrained language models for production or train a model,i am frequently working with text embeddings produced by large pre trained models  they work quite well  but i do want to hear your thoughts on when it would be better to train your own model  what are your thoughts ,frequently working text embeddings produced large pre trained models work quite well want hear thoughts would better train model thoughts,pretrained language models production train model,pretrained language models production train modelfrequently working text embeddings produced large pre trained models work quite well want hear thoughts would better train model thoughts,"['pretrained', 'language', 'models', 'production', 'train', 'modelfrequently', 'working', 'text', 'embeddings', 'produced', 'large', 'pre', 'trained', 'models', 'work', 'quite', 'well', 'want', 'hear', 'thoughts', 'would', 'better', 'train', 'model', 'thoughts']","['pretrain', 'languag', 'model', 'product', 'train', 'modelfrequ', 'work', 'text', 'embed', 'produc', 'larg', 'pre', 'train', 'model', 'work', 'quit', 'well', 'want', 'hear', 'thought', 'would', 'better', 'train', 'model', 'thought']"
87,94,94,Blu4stone,w8gbja,Pokerbot CFR Game Tree Help [Project],"Hello,

I'm  currently working on a poker-bot that uses Counter Factual Regret  minimization for strategy learning. However, I am having difficulty creating a simplified game tree, since having the bot traverse every possible game state would be practically impossible. Any help would greatly appreciated.

Thank you!",2,2,2022-07-26 13:32:48,pokerbot cfr game tree help  project ,hello i m  currently working on a poker bot that uses counter factual regret  minimization for strategy learning  however  i am having difficulty creating a simplified game tree  since having the bot traverse every possible game state would be practically impossible  any help would greatly appreciated thank you ,hello currently working poker bot uses counter factual regret minimization strategy learning however difficulty creating simplified game tree since bot traverse every possible game state would practically impossible help would greatly appreciated thank,pokerbot cfr game tree help project,pokerbot cfr game tree help projecthello currently working poker bot uses counter factual regret minimization strategy learning however difficulty creating simplified game tree since bot traverse every possible game state would practically impossible help would greatly appreciated thank,"['pokerbot', 'cfr', 'game', 'tree', 'help', 'projecthello', 'currently', 'working', 'poker', 'bot', 'uses', 'counter', 'factual', 'regret', 'minimization', 'strategy', 'learning', 'however', 'difficulty', 'creating', 'simplified', 'game', 'tree', 'since', 'bot', 'traverse', 'every', 'possible', 'game', 'state', 'would', 'practically', 'impossible', 'help', 'would', 'greatly', 'appreciated', 'thank']","['pokerbot', 'cfr', 'game', 'tree', 'help', 'projecthello', 'current', 'work', 'poker', 'bot', 'use', 'counter', 'factual', 'regret', 'minim', 'strategi', 'learn', 'howev', 'difficulti', 'creat', 'simplifi', 'game', 'tree', 'sinc', 'bot', 'travers', 'everi', 'possibl', 'game', 'state', 'would', 'practic', 'imposs', 'help', 'would', 'greatli', 'appreci', 'thank']"
88,95,95,mtahab,w7oael,[Discussion] Causality and the Machine Learning Community,"Last week, I attended the ICML and witnessed the incredible popularity of causality: causal graph discovery, causal inference, causal fairness, causal interpretability, causality for robustness and out-of-domain generalization, causality for offline RL were quite popular. Most people that I talked are either working on causality or planning to work on it. [I work on causality too and there is certainly selection bias in the people that I talk to.] There is an influx of papers on arXiv that try to discover the causal graphs under various, sometimes unrealistic, assumptions. Contrast this with 15-20 years ago when publishing causality papers in ICML and NeurIPS was difficult and some landmark papers on causality have been published in conferences such as UAI.

Few years ago, we had a similar situation for RL: most researchers either were working on RL or liked to work on it. RL was thought as the universal tool to solve all problems. Similarly, these days causality is thought as the right tool to solve many problems. This is not surprising, because of the close connections between “_offline RL <=> observational causality_” and “_online RL <=> experimental causality_.” Similar to RL, I expect those who want to use causality as a tool to solve problems such as interpretability and robustness to get disappointed. Because causality, especially causal discovery, is quite difficult. I am in favor of “_causal thinking_” about problems, but the causality tools are not easy to use for all problems.

Let me know what you think.",33,93,2022-07-25 15:56:28, discussion  causality and the machine learning community,last week  i attended the icml and witnessed the incredible popularity of causality  causal graph discovery  causal inference  causal fairness  causal interpretability  causality for robustness and out of domain generalization  causality for offline rl were quite popular  most people that i talked are either working on causality or planning to work on it   i work on causality too and there is certainly selection bias in the people that i talk to   there is an influx of papers on arxiv that try to discover the causal graphs under various  sometimes unrealistic  assumptions  contrast this with   years ago when publishing causality papers in icml and neurips was difficult and some landmark papers on causality have been published in conferences such as uai few years ago  we had a similar situation for rl  most researchers either were working on rl or liked to work on it  rl was thought as the universal tool to solve all problems  similarly  these days causality is thought as the right tool to solve many problems  this is not surprising  because of the close connections between  _offline rl  observational causality_  and  _online rl  experimental causality_   similar to rl  i expect those who want to use causality as a tool to solve problems such as interpretability and robustness to get disappointed  because causality  especially causal discovery  is quite difficult  i am in favor of  _causal thinking_  about problems  but the causality tools are not easy to use for all problems let me know what you think ,last week attended icml witnessed incredible popularity causality causal graph discovery causal inference causal fairness causal interpretability causality robustness domain generalization causality offline rl quite popular people talked either working causality planning work work causality certainly selection bias people talk influx papers arxiv try discover causal graphs various sometimes unrealistic assumptions contrast years ago publishing causality papers icml neurips difficult landmark papers causality published conferences uai years ago similar situation rl researchers either working rl liked work rl thought universal tool solve problems similarly days causality thought right tool solve many problems surprising close connections _offline rl observational causality_ _online rl experimental causality_ similar rl expect want use causality tool solve problems interpretability robustness get disappointed causality especially causal discovery quite difficult favor _causal thinking_ problems causality tools easy use problems let know think,discussion causality machine learning community,discussion causality machine learning communitylast week attended icml witnessed incredible popularity causality causal graph discovery causal inference causal fairness causal interpretability causality robustness domain generalization causality offline rl quite popular people talked either working causality planning work work causality certainly selection bias people talk influx papers arxiv try discover causal graphs various sometimes unrealistic assumptions contrast years ago publishing causality papers icml neurips difficult landmark papers causality published conferences uai years ago similar situation rl researchers either working rl liked work rl thought universal tool solve problems similarly days causality thought right tool solve many problems surprising close connections _offline rl observational causality_ _online rl experimental causality_ similar rl expect want use causality tool solve problems interpretability robustness get disappointed causality especially causal discovery quite difficult favor _causal thinking_ problems causality tools easy use problems let know think,"['discussion', 'causality', 'machine', 'learning', 'communitylast', 'week', 'attended', 'icml', 'witnessed', 'incredible', 'popularity', 'causality', 'causal', 'graph', 'discovery', 'causal', 'inference', 'causal', 'fairness', 'causal', 'interpretability', 'causality', 'robustness', 'domain', 'generalization', 'causality', 'offline', 'rl', 'quite', 'popular', 'people', 'talked', 'either', 'working', 'causality', 'planning', 'work', 'work', 'causality', 'certainly', 'selection', 'bias', 'people', 'talk', 'influx', 'papers', 'arxiv', 'try', 'discover', 'causal', 'graphs', 'various', 'sometimes', 'unrealistic', 'assumptions', 'contrast', 'years', 'ago', 'publishing', 'causality', 'papers', 'icml', 'neurips', 'difficult', 'landmark', 'papers', 'causality', 'published', 'conferences', 'uai', 'years', 'ago', 'similar', 'situation', 'rl', 'researchers', 'either', 'working', 'rl', 'liked', 'work', 'rl', 'thought', 'universal', 'tool', 'solve', 'problems', 'similarly', 'days', 'causality', 'thought', 'right', 'tool', 'solve', 'many', 'problems', 'surprising', 'close', 'connections', '_offline', 'rl', 'observational', 'causality_', '_online', 'rl', 'experimental', 'causality_', 'similar', 'rl', 'expect', 'want', 'use', 'causality', 'tool', 'solve', 'problems', 'interpretability', 'robustness', 'get', 'disappointed', 'causality', 'especially', 'causal', 'discovery', 'quite', 'difficult', 'favor', '_causal', 'thinking_', 'problems', 'causality', 'tools', 'easy', 'use', 'problems', 'let', 'know', 'think']","['discuss', 'causal', 'machin', 'learn', 'communitylast', 'week', 'attend', 'icml', 'wit', 'incred', 'popular', 'causal', 'causal', 'graph', 'discoveri', 'causal', 'infer', 'causal', 'fair', 'causal', 'interpret', 'causal', 'robust', 'domain', 'gener', 'causal', 'offlin', 'rl', 'quit', 'popular', 'peopl', 'talk', 'either', 'work', 'causal', 'plan', 'work', 'work', 'causal', 'certainli', 'select', 'bia', 'peopl', 'talk', 'influx', 'paper', 'arxiv', 'tri', 'discov', 'causal', 'graph', 'variou', 'sometim', 'unrealist', 'assumpt', 'contrast', 'year', 'ago', 'publish', 'causal', 'paper', 'icml', 'neurip', 'difficult', 'landmark', 'paper', 'causal', 'publish', 'confer', 'uai', 'year', 'ago', 'similar', 'situat', 'rl', 'research', 'either', 'work', 'rl', 'like', 'work', 'rl', 'thought', 'univers', 'tool', 'solv', 'problem', 'similarli', 'day', 'causal', 'thought', 'right', 'tool', 'solv', 'mani', 'problem', 'surpris', 'close', 'connect', '_offlin', 'rl', 'observ', 'causality_', '_onlin', 'rl', 'experiment', 'causality_', 'similar', 'rl', 'expect', 'want', 'use', 'causal', 'tool', 'solv', 'problem', 'interpret', 'robust', 'get', 'disappoint', 'causal', 'especi', 'causal', 'discoveri', 'quit', 'difficult', 'favor', '_causal', 'thinking_', 'problem', 'causal', 'tool', 'easi', 'use', 'problem', 'let', 'know', 'think']"
89,96,96,actc_brth,w8e7g0,[D] Looking for datasets with breathing sounds.,I am doing a project which identifies health condition based on  breathing sounds. So would need a good dataset for the same. Any  suggestions of similar papers are also welcome.,1,0,2022-07-26 11:24:43, d  looking for datasets with breathing sounds ,i am doing a project which identifies health condition based on  breathing sounds  so would need a good dataset for the same  any  suggestions of similar papers are also welcome ,project identifies health condition based breathing sounds would need good dataset suggestions similar papers also welcome,looking datasets breathing sounds,looking datasets breathing soundsproject identifies health condition based breathing sounds would need good dataset suggestions similar papers also welcome,"['looking', 'datasets', 'breathing', 'soundsproject', 'identifies', 'health', 'condition', 'based', 'breathing', 'sounds', 'would', 'need', 'good', 'dataset', 'suggestions', 'similar', 'papers', 'also', 'welcome']","['look', 'dataset', 'breath', 'soundsproject', 'identifi', 'health', 'condit', 'base', 'breath', 'sound', 'would', 'need', 'good', 'dataset', 'suggest', 'similar', 'paper', 'also', 'welcom']"
90,97,97,HeTalksInMaths,w8husv,[P] Popular asymmetric loss functions for bounding or constructing loss functions to guarantee bounding?,"I'm working on a open-ended project for my Masters using the Online Encyclopedia of Integer Sequences and attempting to upper bound future sequence values instead of predicting them. I've managed to get reasonable results using RNNs and Linear-Exponential (LINEX) loss but was wondering what other popular asymmetric loss functions for bounding there are or what general principles I should consider in constructing a loss function if my aim is to ensure all predicted bounds are deterministically (and not probabilistically) sufficient, if possible?",0,0,2022-07-26 14:56:42, p  popular asymmetric loss functions for bounding or constructing loss functions to guarantee bounding ,i m working on a open ended project for my masters using the online encyclopedia of integer sequences and attempting to upper bound future sequence values instead of predicting them  i ve managed to get reasonable results using rnns and linear exponential  linex  loss but was wondering what other popular asymmetric loss functions for bounding there are or what general principles i should consider in constructing a loss function if my aim is to ensure all predicted bounds are deterministically  and not probabilistically  sufficient  if possible ,working open ended project masters using online encyclopedia integer sequences attempting upper bound future sequence values instead predicting managed get reasonable results using rnns linear exponential linex loss wondering popular asymmetric loss functions bounding general principles consider constructing loss function aim ensure predicted bounds deterministically probabilistically sufficient possible,p popular asymmetric loss functions bounding constructing loss functions guarantee bounding,p popular asymmetric loss functions bounding constructing loss functions guarantee boundingworking open ended project masters using online encyclopedia integer sequences attempting upper bound future sequence values instead predicting managed get reasonable results using rnns linear exponential linex loss wondering popular asymmetric loss functions bounding general principles consider constructing loss function aim ensure predicted bounds deterministically probabilistically sufficient possible,"['p', 'popular', 'asymmetric', 'loss', 'functions', 'bounding', 'constructing', 'loss', 'functions', 'guarantee', 'boundingworking', 'open', 'ended', 'project', 'masters', 'using', 'online', 'encyclopedia', 'integer', 'sequences', 'attempting', 'upper', 'bound', 'future', 'sequence', 'values', 'instead', 'predicting', 'managed', 'get', 'reasonable', 'results', 'using', 'rnns', 'linear', 'exponential', 'linex', 'loss', 'wondering', 'popular', 'asymmetric', 'loss', 'functions', 'bounding', 'general', 'principles', 'consider', 'constructing', 'loss', 'function', 'aim', 'ensure', 'predicted', 'bounds', 'deterministically', 'probabilistically', 'sufficient', 'possible']","['p', 'popular', 'asymmetr', 'loss', 'function', 'bound', 'construct', 'loss', 'function', 'guarante', 'boundingwork', 'open', 'end', 'project', 'master', 'use', 'onlin', 'encyclopedia', 'integ', 'sequenc', 'attempt', 'upper', 'bound', 'futur', 'sequenc', 'valu', 'instead', 'predict', 'manag', 'get', 'reason', 'result', 'use', 'rnn', 'linear', 'exponenti', 'linex', 'loss', 'wonder', 'popular', 'asymmetr', 'loss', 'function', 'bound', 'gener', 'principl', 'consid', 'construct', 'loss', 'function', 'aim', 'ensur', 'predict', 'bound', 'determinist', 'probabilist', 'suffici', 'possibl']"
91,98,98,NoisesMaker,w759hp,"[R] Generative Multiplane Images: Making a 2D GAN 3D-Aware (ECCV 2022, Oral presentation). Paper and code available","Paper: https://arxiv.org/abs/2207.10642
Code: https://github.com/apple/ml-gmpi
Webpage: https://xiaoming-zhao.github.io/projects/gmpi/",36,1072,2022-07-24 23:36:39, r  generative multiplane images  making a d gan d aware  eccv   oral presentation   paper and code available,paper  https code  https webpage  https   xiaoming zhao github io projects gmpi ,paper https code https webpage https xiaoming zhao github io projects gmpi,r generative multiplane images making gan aware eccv oral presentation paper code available,r generative multiplane images making gan aware eccv oral presentation paper code availablepaper https code https webpage https xiaoming zhao github io projects gmpi,"['r', 'generative', 'multiplane', 'images', 'making', 'gan', 'aware', 'eccv', 'oral', 'presentation', 'paper', 'code', 'availablepaper', 'https', 'code', 'https', 'webpage', 'https', 'xiaoming', 'zhao', 'github', 'io', 'projects', 'gmpi']","['r', 'gener', 'multiplan', 'imag', 'make', 'gan', 'awar', 'eccv', 'oral', 'present', 'paper', 'code', 'availablepap', 'http', 'code', 'http', 'webpag', 'http', 'xiaom', 'zhao', 'github', 'io', 'project', 'gmpi']"
92,99,99,Boozybrain,w83xzr,[D] SOTA Image Animation from Video?,"I saw a post possibly on here or /r/futurology a few days ago that showed some pretty amazing results for animating images using a driving video, like [this from Snap Research](https://github.com/snap-research/articulated-animation).  I didn't save the post and wanted to read the paper, but was also wondering if this is still an active research area or not.  It felt like lots of work was being done a couple years ago but I haven't seen much lately.",1,8,2022-07-26 02:39:57, d  sota image animation from video ,i saw a post possibly on here or  r futurology a few days ago that showed some pretty amazing results for animating images using a driving video  like  this from snap research  https   github com snap research articulated animation    i didn t save the post and wanted to read the paper  but was also wondering if this is still an active research area or not   it felt like lots of work was being done a couple years ago but i haven t seen much lately ,saw post possibly r futurology days ago showed pretty amazing results animating images using driving video like snap research https github com snap research articulated animation save post wanted read paper also wondering still active research area felt like lots work done couple years ago seen much lately,sota image animation video,sota image animation videosaw post possibly r futurology days ago showed pretty amazing results animating images using driving video like snap research https github com snap research articulated animation save post wanted read paper also wondering still active research area felt like lots work done couple years ago seen much lately,"['sota', 'image', 'animation', 'videosaw', 'post', 'possibly', 'r', 'futurology', 'days', 'ago', 'showed', 'pretty', 'amazing', 'results', 'animating', 'images', 'using', 'driving', 'video', 'like', 'snap', 'research', 'https', 'github', 'com', 'snap', 'research', 'articulated', 'animation', 'save', 'post', 'wanted', 'read', 'paper', 'also', 'wondering', 'still', 'active', 'research', 'area', 'felt', 'like', 'lots', 'work', 'done', 'couple', 'years', 'ago', 'seen', 'much', 'lately']","['sota', 'imag', 'anim', 'videosaw', 'post', 'possibl', 'r', 'futurolog', 'day', 'ago', 'show', 'pretti', 'amaz', 'result', 'anim', 'imag', 'use', 'drive', 'video', 'like', 'snap', 'research', 'http', 'github', 'com', 'snap', 'research', 'articul', 'anim', 'save', 'post', 'want', 'read', 'paper', 'also', 'wonder', 'still', 'activ', 'research', 'area', 'felt', 'like', 'lot', 'work', 'done', 'coupl', 'year', 'ago', 'seen', 'much', 'late']"
93,100,100,IllustriousCicada603,w8eoe7,[D] Can you generate hidden states from ground truth labels?,"In the context of NLP, many models generate some hidden states (e.g. decoder output in Transformers) which then go trough a linear (language modelling) layer to calculate token probabilities. Is it possible somehow to obtain what hidden states the decoder would output for a given ground truth response. In a way use the language modelling layer ""backwards""?",2,0,2022-07-26 11:54:17, d  can you generate hidden states from ground truth labels ,in the context of nlp  many models generate some hidden states  e g  decoder output in transformers  which then go trough a linear  language modelling  layer to calculate token probabilities  is it possible somehow to obtain what hidden states the decoder would output for a given ground truth response  in a way use the language modelling layer backwards ,context nlp many models generate hidden states e g decoder output transformers go trough linear language modelling layer calculate token probabilities possible somehow obtain hidden states decoder would output given ground truth response way use language modelling layer backwards,generate hidden states ground truth labels,generate hidden states ground truth labelscontext nlp many models generate hidden states e g decoder output transformers go trough linear language modelling layer calculate token probabilities possible somehow obtain hidden states decoder would output given ground truth response way use language modelling layer backwards,"['generate', 'hidden', 'states', 'ground', 'truth', 'labelscontext', 'nlp', 'many', 'models', 'generate', 'hidden', 'states', 'e', 'g', 'decoder', 'output', 'transformers', 'go', 'trough', 'linear', 'language', 'modelling', 'layer', 'calculate', 'token', 'probabilities', 'possible', 'somehow', 'obtain', 'hidden', 'states', 'decoder', 'would', 'output', 'given', 'ground', 'truth', 'response', 'way', 'use', 'language', 'modelling', 'layer', 'backwards']","['gener', 'hidden', 'state', 'ground', 'truth', 'labelscontext', 'nlp', 'mani', 'model', 'gener', 'hidden', 'state', 'e', 'g', 'decod', 'output', 'transform', 'go', 'trough', 'linear', 'languag', 'model', 'layer', 'calcul', 'token', 'probabl', 'possibl', 'somehow', 'obtain', 'hidden', 'state', 'decod', 'would', 'output', 'given', 'ground', 'truth', 'respons', 'way', 'use', 'languag', 'model', 'layer', 'backward']"
94,101,101,Aybdee,w7uaf4,[D] opinions on Unify AI,"What do you think about unify AI 

https://lets-unify.ai.
It’s a project to create an abstraction over existing ML libraries 
so they can be used from a single interface 

Do you think it’s feasible 
or useful",17,10,2022-07-25 20:05:56, d  opinions on unify ai,what do you think about unify ai https it s a project to create an abstraction over existing ml libraries so they can be used from a single interface do you think it s feasible or useful,think unify ai https project create abstraction existing ml libraries used single interface think feasible useful,opinions unify ai,opinions unify aithink unify ai https project create abstraction existing ml libraries used single interface think feasible useful,"['opinions', 'unify', 'aithink', 'unify', 'ai', 'https', 'project', 'create', 'abstraction', 'existing', 'ml', 'libraries', 'used', 'single', 'interface', 'think', 'feasible', 'useful']","['opinion', 'unifi', 'aithink', 'unifi', 'ai', 'http', 'project', 'creat', 'abstract', 'exist', 'ml', 'librari', 'use', 'singl', 'interfac', 'think', 'feasibl', 'use']"
95,102,102,IllustriousCicada603,w8eron,[D] GANs for text with a transformer as a generator,"Are there Generative Adversarial Network architecture which use transformer language models (e.g. gpt, t5) as generators and some other architecture (e.g. MLP, another transformer) as discriminators? How do they overcome the discrete sampling problem?",3,0,2022-07-26 12:00:09, d  gans for text with a transformer as a generator,are there generative adversarial network architecture which use transformer language models  e g  gpt  t  as generators and some other architecture  e g  mlp  another transformer  as discriminators  how do they overcome the discrete sampling problem ,generative adversarial network architecture use transformer language models e g gpt generators architecture e g mlp another transformer discriminators overcome discrete sampling problem,gans text transformer generator,gans text transformer generatorgenerative adversarial network architecture use transformer language models e g gpt generators architecture e g mlp another transformer discriminators overcome discrete sampling problem,"['gans', 'text', 'transformer', 'generatorgenerative', 'adversarial', 'network', 'architecture', 'use', 'transformer', 'language', 'models', 'e', 'g', 'gpt', 'generators', 'architecture', 'e', 'g', 'mlp', 'another', 'transformer', 'discriminators', 'overcome', 'discrete', 'sampling', 'problem']","['gan', 'text', 'transform', 'generatorgen', 'adversari', 'network', 'architectur', 'use', 'transform', 'languag', 'model', 'e', 'g', 'gpt', 'gener', 'architectur', 'e', 'g', 'mlp', 'anoth', 'transform', 'discrimin', 'overcom', 'discret', 'sampl', 'problem']"
96,103,103,bandalorian,w7q8ob,[D] Are diffusion models just a data sampling technique?,"I'm just beginning to try to understand diffusion models, so I may be way off here. But from my understanding so far, diffusion models involves adding noise in a series of steps that can be represented as a markov chain. Then you take the gradient of the density function for each transition in that chain and sample them and these become you independent variables. The dependent variables are the next step in the markov chain (i.e. the outcome after adding noise). That's your dataset, and now you give that to a model. And my understanding is that the model itself is not really anything special, it's mainly this noise sampling technique that introduces something new. 

So would ""diffusion data sampling"" be a more descriptive way to talk about the process we refer to as diffusion models? I'm sure several of my assumptions are wrong, but hoping it's at least a starting point for discussion!",2,15,2022-07-25 17:22:16, d  are diffusion models just a data sampling technique ,i m just beginning to try to understand diffusion models  so i may be way off here  but from my understanding so far  diffusion models involves adding noise in a series of steps that can be represented as a markov chain  then you take the gradient of the density function for each transition in that chain and sample them and these become you independent variables  the dependent variables are the next step in the markov chain  i e  the outcome after adding noise   that s your dataset  and now you give that to a model  and my understanding is that the model itself is not really anything special  it s mainly this noise sampling technique that introduces something new  so would diffusion data sampling be a more descriptive way to talk about the process we refer to as diffusion models  i m sure several of my assumptions are wrong  but hoping it s at least a starting point for discussion ,beginning try understand diffusion models may way understanding far diffusion models involves adding noise series steps represented markov chain take gradient density function transition chain sample become independent variables dependent variables next step markov chain e outcome adding noise dataset give model understanding model really anything special mainly noise sampling technique introduces something would diffusion data sampling descriptive way talk process refer diffusion models sure several assumptions wrong hoping least starting point discussion,diffusion models data sampling technique,diffusion models data sampling techniquebeginning try understand diffusion models may way understanding far diffusion models involves adding noise series steps represented markov chain take gradient density function transition chain sample become independent variables dependent variables next step markov chain e outcome adding noise dataset give model understanding model really anything special mainly noise sampling technique introduces something would diffusion data sampling descriptive way talk process refer diffusion models sure several assumptions wrong hoping least starting point discussion,"['diffusion', 'models', 'data', 'sampling', 'techniquebeginning', 'try', 'understand', 'diffusion', 'models', 'may', 'way', 'understanding', 'far', 'diffusion', 'models', 'involves', 'adding', 'noise', 'series', 'steps', 'represented', 'markov', 'chain', 'take', 'gradient', 'density', 'function', 'transition', 'chain', 'sample', 'become', 'independent', 'variables', 'dependent', 'variables', 'next', 'step', 'markov', 'chain', 'e', 'outcome', 'adding', 'noise', 'dataset', 'give', 'model', 'understanding', 'model', 'really', 'anything', 'special', 'mainly', 'noise', 'sampling', 'technique', 'introduces', 'something', 'would', 'diffusion', 'data', 'sampling', 'descriptive', 'way', 'talk', 'process', 'refer', 'diffusion', 'models', 'sure', 'several', 'assumptions', 'wrong', 'hoping', 'least', 'starting', 'point', 'discussion']","['diffus', 'model', 'data', 'sampl', 'techniquebegin', 'tri', 'understand', 'diffus', 'model', 'may', 'way', 'understand', 'far', 'diffus', 'model', 'involv', 'ad', 'nois', 'seri', 'step', 'repres', 'markov', 'chain', 'take', 'gradient', 'densiti', 'function', 'transit', 'chain', 'sampl', 'becom', 'independ', 'variabl', 'depend', 'variabl', 'next', 'step', 'markov', 'chain', 'e', 'outcom', 'ad', 'nois', 'dataset', 'give', 'model', 'understand', 'model', 'realli', 'anyth', 'special', 'mainli', 'nois', 'sampl', 'techniqu', 'introduc', 'someth', 'would', 'diffus', 'data', 'sampl', 'descript', 'way', 'talk', 'process', 'refer', 'diffus', 'model', 'sure', 'sever', 'assumpt', 'wrong', 'hope', 'least', 'start', 'point', 'discuss']"
97,104,104,jayalammar,w7qywh,[D] Running Large Language Models in Production: A look at Cohere's The Inference Framework (TIF),"Hi r/MachineLearning,

The Inference Framework (TIF) is [Cohere](https://cohere.ai/)'s platform for large Transformer language model inference. In this post, we share its high-level structure and some of the methods that help us serve massive language models more efficiently.

[https://txt.cohere.ai/running-large-language-models-in-production-a-look-at-the-inference-framework-tif/](https://txt.cohere.ai/running-large-language-models-in-production-a-look-at-the-inference-framework-tif/)",0,6,2022-07-25 17:53:27, d  running large language models in production  a look at cohere s the inference framework  tif ,hi r machinelearning the inference framework  tif  is  cohere  https  https   txt cohere ai running large language models in production a look at the inference framework tif   https   txt cohere ai running large language models in production a look at the inference framework tif  ,hi r machinelearning inference framework tif cohere https https txt cohere ai running large language models production look inference framework tif https txt cohere ai running large language models production look inference framework tif,running large language models production look cohere inference framework tif,running large language models production look cohere inference framework tifhi r machinelearning inference framework tif cohere https https txt cohere ai running large language models production look inference framework tif https txt cohere ai running large language models production look inference framework tif,"['running', 'large', 'language', 'models', 'production', 'look', 'cohere', 'inference', 'framework', 'tifhi', 'r', 'machinelearning', 'inference', 'framework', 'tif', 'cohere', 'https', 'https', 'txt', 'cohere', 'ai', 'running', 'large', 'language', 'models', 'production', 'look', 'inference', 'framework', 'tif', 'https', 'txt', 'cohere', 'ai', 'running', 'large', 'language', 'models', 'production', 'look', 'inference', 'framework', 'tif']","['run', 'larg', 'languag', 'model', 'product', 'look', 'coher', 'infer', 'framework', 'tifhi', 'r', 'machinelearn', 'infer', 'framework', 'tif', 'coher', 'http', 'http', 'txt', 'coher', 'ai', 'run', 'larg', 'languag', 'model', 'product', 'look', 'infer', 'framework', 'tif', 'http', 'txt', 'coher', 'ai', 'run', 'larg', 'languag', 'model', 'product', 'look', 'infer', 'framework', 'tif']"
98,105,105,sapnupuasop,w7k1mt,[D] Interpretation of latent space extracted from contrastive loss,"Hey, 
for a project, we have a TB of unlabeled sensor data consisting of time series with length of ~10000 steps and a feature size of ~100 describing the state of an object (can’t tell too much about it due to NDA). We need to generate embeddings, which we did successfully by applying contrastive loss. The thing is, I’m looking for ways to interpret the embeddings and map them to the I out space in a way, e.g. find out what contributes or differentiates the different positions in the latent space. A method I found is to apply latent space regularization, do you know of anything else? Any way to map the found embeddings back to the input space in a way?",3,10,2022-07-25 12:08:30, d  interpretation of latent space extracted from contrastive loss,hey  for a project  we have a tb of unlabeled sensor data consisting of time series with length of   steps and a feature size of   describing the state of an object  can t tell too much about it due to nda   we need to generate embeddings  which we did successfully by applying contrastive loss  the thing is  i m looking for ways to interpret the embeddings and map them to the i out space in a way  e g  find out what contributes or differentiates the different positions in the latent space  a method i found is to apply latent space regularization  do you know of anything else  any way to map the found embeddings back to the input space in a way ,hey project tb unlabeled sensor data consisting time series length steps feature size describing state object tell much due nda need generate embeddings successfully applying contrastive loss thing looking ways interpret embeddings map space way e g find contributes differentiates different positions latent space method found apply latent space regularization know anything else way map found embeddings back input space way,interpretation latent space extracted contrastive loss,interpretation latent space extracted contrastive losshey project tb unlabeled sensor data consisting time series length steps feature size describing state object tell much due nda need generate embeddings successfully applying contrastive loss thing looking ways interpret embeddings map space way e g find contributes differentiates different positions latent space method found apply latent space regularization know anything else way map found embeddings back input space way,"['interpretation', 'latent', 'space', 'extracted', 'contrastive', 'losshey', 'project', 'tb', 'unlabeled', 'sensor', 'data', 'consisting', 'time', 'series', 'length', 'steps', 'feature', 'size', 'describing', 'state', 'object', 'tell', 'much', 'due', 'nda', 'need', 'generate', 'embeddings', 'successfully', 'applying', 'contrastive', 'loss', 'thing', 'looking', 'ways', 'interpret', 'embeddings', 'map', 'space', 'way', 'e', 'g', 'find', 'contributes', 'differentiates', 'different', 'positions', 'latent', 'space', 'method', 'found', 'apply', 'latent', 'space', 'regularization', 'know', 'anything', 'else', 'way', 'map', 'found', 'embeddings', 'back', 'input', 'space', 'way']","['interpret', 'latent', 'space', 'extract', 'contrast', 'losshey', 'project', 'tb', 'unlabel', 'sensor', 'data', 'consist', 'time', 'seri', 'length', 'step', 'featur', 'size', 'describ', 'state', 'object', 'tell', 'much', 'due', 'nda', 'need', 'gener', 'embed', 'success', 'appli', 'contrast', 'loss', 'thing', 'look', 'way', 'interpret', 'embed', 'map', 'space', 'way', 'e', 'g', 'find', 'contribut', 'differenti', 'differ', 'posit', 'latent', 'space', 'method', 'found', 'appli', 'latent', 'space', 'regular', 'know', 'anyth', 'els', 'way', 'map', 'found', 'embed', 'back', 'input', 'space', 'way']"
99,106,106,dumboo_,w82qwb,[D] Best ML courses,"**What's the best ML course?**  
I use the Alura one(it's Brazilian) but I don't have any problem to using an English ML course.

Alura's course is very good, but it usually only teaches code, I want something more like ""**What you need to know as a ML engineer**"", ""**Problems you will often have as a ML engineer**"", things like that

Also, I want a **course that teaches the math you need to learn/program in ML**, because I love math, but I don't want to learn useless things I'll not use in my ML engineer career(That's a real problem in Alura's courses, they often don't teach the useful math, or even math).

Basic things the course needs(at least the first two):

* **Be online**(I'm Brazilian and a 13 y/o, so I don't think that will be any schools/universities for me)
* **Teaches the math of the ML ""brain""**(the useful math, how it works, etc.)
* **Tell you which things do you need to know to work as a ML engineer**(What kind of things you need to learn to be a ML engineer, hints of things you'll usually face, what companies are the best for ML engineers, etc.)
* **What kind of problems you'll usually face as a ML engineer**

Optional things the course can have:

* **Be Brazilian Portuguese**(As I said, I have no problem with English, but it'll be more easy if the course is in Brazilian Portuguese. It need to be Brazilian, because European and Brazilian Portuguese has some BIG differences, not only the accent, but things like a curse word in Brazilian but totally normal in European)
* **Be free**(Well... I'm not rich or something, but if I know the course, I can save it and see when I start working((I'll start working with 14y/o)) so, I maybe can pay the course if it's not like 100 dollars per month)

**I don't even need to be just a course, It could be a YouTube channel, a blog, etc.**

Thanks everyone for the help!",3,0,2022-07-26 01:48:27, d  best ml courses,  what s the best ml course     i use the alura one it s brazilian  but i don t have any problem to using an english ml course alura s course is very good  but it usually only teaches code  i want something more like   what you need to know as a ml engineer      problems you will often have as a ml engineer    things like thatalso  i want a   course that teaches the math you need to learn program in ml    because i love math  but i don t want to learn useless things i ll not use in my ml engineer career that s a real problem in alura s courses  they often don t teach the useful math  or even math  basic things the course needs at least the first two      be online   i m brazilian and a  y o  so i don t think that will be any schools universities for me     teaches the math of the ml brain   the useful math  how it works  etc      tell you which things do you need to know to work as a ml engineer   what kind of things you need to learn to be a ml engineer  hints of things you ll usually face  what companies are the best for ml engineers  etc      what kind of problems you ll usually face as a ml engineer  optional things the course can have     be brazilian portuguese   as i said  i have no problem with english  but it ll be more easy if the course is in brazilian portuguese  it need to be brazilian  because european and brazilian portuguese has some big differences  not only the accent  but things like a curse word in brazilian but totally normal in european     be free   well    i m not rich or something  but if i know the course  i can save it and see when i start working  i ll start working with y o   so  i maybe can pay the course if it s not like  dollars per month   i don t even need to be just a course  it could be a youtube channel  a blog  etc   thanks everyone for the help ,best ml course use alura one brazilian problem using english ml course alura course good usually teaches code want something like need know ml engineer problems often ml engineer things like thatalso want course teaches math need learn program ml love math want learn useless things use ml engineer career real problem alura courses often teach useful math even math basic things course needs least first two online brazilian think schools universities teaches math ml brain useful math works etc tell things need know work ml engineer kind things need learn ml engineer hints things usually face companies best ml engineers etc kind problems usually face ml engineer optional things course brazilian portuguese said problem english easy course brazilian portuguese need brazilian european brazilian portuguese big differences accent things like curse word brazilian totally normal european free well rich something know course save see start working start working maybe pay course like dollars per month even need course could youtube channel blog etc thanks everyone help,best ml courses,best ml coursesbest ml course use alura one brazilian problem using english ml course alura course good usually teaches code want something like need know ml engineer problems often ml engineer things like thatalso want course teaches math need learn program ml love math want learn useless things use ml engineer career real problem alura courses often teach useful math even math basic things course needs least first two online brazilian think schools universities teaches math ml brain useful math works etc tell things need know work ml engineer kind things need learn ml engineer hints things usually face companies best ml engineers etc kind problems usually face ml engineer optional things course brazilian portuguese said problem english easy course brazilian portuguese need brazilian european brazilian portuguese big differences accent things like curse word brazilian totally normal european free well rich something know course save see start working start working maybe pay course like dollars per month even need course could youtube channel blog etc thanks everyone help,"['best', 'ml', 'coursesbest', 'ml', 'course', 'use', 'alura', 'one', 'brazilian', 'problem', 'using', 'english', 'ml', 'course', 'alura', 'course', 'good', 'usually', 'teaches', 'code', 'want', 'something', 'like', 'need', 'know', 'ml', 'engineer', 'problems', 'often', 'ml', 'engineer', 'things', 'like', 'thatalso', 'want', 'course', 'teaches', 'math', 'need', 'learn', 'program', 'ml', 'love', 'math', 'want', 'learn', 'useless', 'things', 'use', 'ml', 'engineer', 'career', 'real', 'problem', 'alura', 'courses', 'often', 'teach', 'useful', 'math', 'even', 'math', 'basic', 'things', 'course', 'needs', 'least', 'first', 'two', 'online', 'brazilian', 'think', 'schools', 'universities', 'teaches', 'math', 'ml', 'brain', 'useful', 'math', 'works', 'etc', 'tell', 'things', 'need', 'know', 'work', 'ml', 'engineer', 'kind', 'things', 'need', 'learn', 'ml', 'engineer', 'hints', 'things', 'usually', 'face', 'companies', 'best', 'ml', 'engineers', 'etc', 'kind', 'problems', 'usually', 'face', 'ml', 'engineer', 'optional', 'things', 'course', 'brazilian', 'portuguese', 'said', 'problem', 'english', 'easy', 'course', 'brazilian', 'portuguese', 'need', 'brazilian', 'european', 'brazilian', 'portuguese', 'big', 'differences', 'accent', 'things', 'like', 'curse', 'word', 'brazilian', 'totally', 'normal', 'european', 'free', 'well', 'rich', 'something', 'know', 'course', 'save', 'see', 'start', 'working', 'start', 'working', 'maybe', 'pay', 'course', 'like', 'dollars', 'per', 'month', 'even', 'need', 'course', 'could', 'youtube', 'channel', 'blog', 'etc', 'thanks', 'everyone', 'help']","['best', 'ml', 'coursesbest', 'ml', 'cours', 'use', 'alura', 'one', 'brazilian', 'problem', 'use', 'english', 'ml', 'cours', 'alura', 'cours', 'good', 'usual', 'teach', 'code', 'want', 'someth', 'like', 'need', 'know', 'ml', 'engin', 'problem', 'often', 'ml', 'engin', 'thing', 'like', 'thatalso', 'want', 'cours', 'teach', 'math', 'need', 'learn', 'program', 'ml', 'love', 'math', 'want', 'learn', 'useless', 'thing', 'use', 'ml', 'engin', 'career', 'real', 'problem', 'alura', 'cours', 'often', 'teach', 'use', 'math', 'even', 'math', 'basic', 'thing', 'cours', 'need', 'least', 'first', 'two', 'onlin', 'brazilian', 'think', 'school', 'univers', 'teach', 'math', 'ml', 'brain', 'use', 'math', 'work', 'etc', 'tell', 'thing', 'need', 'know', 'work', 'ml', 'engin', 'kind', 'thing', 'need', 'learn', 'ml', 'engin', 'hint', 'thing', 'usual', 'face', 'compani', 'best', 'ml', 'engin', 'etc', 'kind', 'problem', 'usual', 'face', 'ml', 'engin', 'option', 'thing', 'cours', 'brazilian', 'portugues', 'said', 'problem', 'english', 'easi', 'cours', 'brazilian', 'portugues', 'need', 'brazilian', 'european', 'brazilian', 'portugues', 'big', 'differ', 'accent', 'thing', 'like', 'curs', 'word', 'brazilian', 'total', 'normal', 'european', 'free', 'well', 'rich', 'someth', 'know', 'cours', 'save', 'see', 'start', 'work', 'start', 'work', 'mayb', 'pay', 'cours', 'like', 'dollar', 'per', 'month', 'even', 'need', 'cours', 'could', 'youtub', 'channel', 'blog', 'etc', 'thank', 'everyon', 'help']"
100,108,108,TheMoMatthias,w7uu4d,[D] How can I use my outputs from LSTM (hidden states) as input for a simple FFN that uses other input data?,"Hello All together,

I hope everyone is doing fine! For my master thesis I would like to perform cross-sectional stock predictions. I read a very interesting paper ""deep learning in asset pricing "" that used macro-factors as inputs in a LSTM neural network and then used the transformed output (hidden states) and factor returns as input variables for a feed forward NN. I would like to replicate their approach. So I would first use my macro factors to infer economical cycles and then use this information together with factor returns in a FFN to predict stock returns.

I tried using this code but I am not sure whether this would efficiently use the power of LSTM's

    from tensorflow.keras import layers   
    
    #using a LSTM layer to transform macro factor inputs to a transformed output lstm_layer_1  = layers.LSTM(16, dropout=0.8,return_sequences =True, activation='relu')(x_train_macro)
    
    output_layer_1 = layers.Dense(8, activation='relu')(lstm_layer_1) 
    lstm_layer_2 = layers.LSTM(8, dropout=0.5, return_sequences =True, activation='relu')(output_layer_1) 
    output_layer_2 = layers.Dense(4, activation='relu')(lstm_layer_2) 
    lstm_layer_3 = layers.LSTM(4, dropout=0.2,return_sequences =True, activation='relu')(output_layer_2) 
    output_layer_3 = layers.Dense(1, activation='relu')(lstm_layer_3) 

or this:

    from tensorflow.keras import layers   
    # using a LSTM layer to transform macro factor inputs to a transformed output 
    
    lstm_output, states_h, states_c  = layers.LSTM(4, dropout=0.95,return_sequences=True,return_state=True, activation='relu') (x_train_macro)  

I am relatively new to designing NN's and I know this seems like a tough challenge but any help would be highly appreciated! I wish y'all a nice evening,

cheers,",6,0,2022-07-25 20:27:49, d  how can i use my outputs from lstm  hidden states  as input for a simple ffn that uses other input data ,hello all together i hope everyone is doing fine  for my master thesis i would like to perform cross sectional stock predictions  i read a very interesting paper deep learning in asset pricing  that used macro factors as inputs in a lstm neural network and then used the transformed output  hidden states  and factor returns as input variables for a feed forward nn  i would like to replicate their approach  so i would first use my macro factors to infer economical cycles and then use this information together with factor returns in a ffn to predict stock returns i tried using this code but i am not sure whether this would efficiently use the power of lstm s    from tensorflow keras import layers            using a lstm layer to transform macro factor inputs to a transformed output lstm_layer_    layers lstm   dropout   return_sequences  true  activation  relu   x_train_macro         output_layer_   layers dense   activation  relu   lstm_layer_      lstm_layer_   layers lstm   dropout    return_sequences  true  activation  relu   output_layer_      output_layer_   layers dense   activation  relu   lstm_layer_      lstm_layer_   layers lstm   dropout   return_sequences  true  activation  relu   output_layer_      output_layer_   layers dense   activation  relu   lstm_layer_  or this     from tensorflow keras import layers         using a lstm layer to transform macro factor inputs to a transformed output         lstm_output  states_h  states_c    layers lstm   dropout   return_sequences true return_state true  activation  relu    x_train_macro   i am relatively new to designing nn s and i know this seems like a tough challenge but any help would be highly appreciated  i wish y all a nice evening cheers ,hello together hope everyone fine master thesis would like perform cross sectional stock predictions read interesting paper deep learning asset pricing used macro factors inputs lstm neural network used transformed output hidden states factor returns input variables feed forward nn would like replicate approach would first use macro factors infer economical cycles use information together factor returns ffn predict stock returns tried using code sure whether would efficiently use power lstm tensorflow keras import layers using lstm layer transform macro factor inputs transformed output lstm_layer_ layers lstm dropout return_sequences true activation relu x_train_macro output_layer_ layers dense activation relu lstm_layer_ lstm_layer_ layers lstm dropout return_sequences true activation relu output_layer_ output_layer_ layers dense activation relu lstm_layer_ lstm_layer_ layers lstm dropout return_sequences true activation relu output_layer_ output_layer_ layers dense activation relu lstm_layer_ tensorflow keras import layers using lstm layer transform macro factor inputs transformed output lstm_output states_h states_c layers lstm dropout return_sequences true return_state true activation relu x_train_macro relatively designing nn know seems like tough challenge help would highly appreciated wish nice evening cheers,use outputs lstm hidden states input simple ffn uses input data,use outputs lstm hidden states input simple ffn uses input datahello together hope everyone fine master thesis would like perform cross sectional stock predictions read interesting paper deep learning asset pricing used macro factors inputs lstm neural network used transformed output hidden states factor returns input variables feed forward nn would like replicate approach would first use macro factors infer economical cycles use information together factor returns ffn predict stock returns tried using code sure whether would efficiently use power lstm tensorflow keras import layers using lstm layer transform macro factor inputs transformed output lstm_layer_ layers lstm dropout return_sequences true activation relu x_train_macro output_layer_ layers dense activation relu lstm_layer_ lstm_layer_ layers lstm dropout return_sequences true activation relu output_layer_ output_layer_ layers dense activation relu lstm_layer_ lstm_layer_ layers lstm dropout return_sequences true activation relu output_layer_ output_layer_ layers dense activation relu lstm_layer_ tensorflow keras import layers using lstm layer transform macro factor inputs transformed output lstm_output states_h states_c layers lstm dropout return_sequences true return_state true activation relu x_train_macro relatively designing nn know seems like tough challenge help would highly appreciated wish nice evening cheers,"['use', 'outputs', 'lstm', 'hidden', 'states', 'input', 'simple', 'ffn', 'uses', 'input', 'datahello', 'together', 'hope', 'everyone', 'fine', 'master', 'thesis', 'would', 'like', 'perform', 'cross', 'sectional', 'stock', 'predictions', 'read', 'interesting', 'paper', 'deep', 'learning', 'asset', 'pricing', 'used', 'macro', 'factors', 'inputs', 'lstm', 'neural', 'network', 'used', 'transformed', 'output', 'hidden', 'states', 'factor', 'returns', 'input', 'variables', 'feed', 'forward', 'nn', 'would', 'like', 'replicate', 'approach', 'would', 'first', 'use', 'macro', 'factors', 'infer', 'economical', 'cycles', 'use', 'information', 'together', 'factor', 'returns', 'ffn', 'predict', 'stock', 'returns', 'tried', 'using', 'code', 'sure', 'whether', 'would', 'efficiently', 'use', 'power', 'lstm', 'tensorflow', 'keras', 'import', 'layers', 'using', 'lstm', 'layer', 'transform', 'macro', 'factor', 'inputs', 'transformed', 'output', 'lstm_layer_', 'layers', 'lstm', 'dropout', 'return_sequences', 'true', 'activation', 'relu', 'x_train_macro', 'output_layer_', 'layers', 'dense', 'activation', 'relu', 'lstm_layer_', 'lstm_layer_', 'layers', 'lstm', 'dropout', 'return_sequences', 'true', 'activation', 'relu', 'output_layer_', 'output_layer_', 'layers', 'dense', 'activation', 'relu', 'lstm_layer_', 'lstm_layer_', 'layers', 'lstm', 'dropout', 'return_sequences', 'true', 'activation', 'relu', 'output_layer_', 'output_layer_', 'layers', 'dense', 'activation', 'relu', 'lstm_layer_', 'tensorflow', 'keras', 'import', 'layers', 'using', 'lstm', 'layer', 'transform', 'macro', 'factor', 'inputs', 'transformed', 'output', 'lstm_output', 'states_h', 'states_c', 'layers', 'lstm', 'dropout', 'return_sequences', 'true', 'return_state', 'true', 'activation', 'relu', 'x_train_macro', 'relatively', 'designing', 'nn', 'know', 'seems', 'like', 'tough', 'challenge', 'help', 'would', 'highly', 'appreciated', 'wish', 'nice', 'evening', 'cheers']","['use', 'output', 'lstm', 'hidden', 'state', 'input', 'simpl', 'ffn', 'use', 'input', 'datahello', 'togeth', 'hope', 'everyon', 'fine', 'master', 'thesi', 'would', 'like', 'perform', 'cross', 'section', 'stock', 'predict', 'read', 'interest', 'paper', 'deep', 'learn', 'asset', 'price', 'use', 'macro', 'factor', 'input', 'lstm', 'neural', 'network', 'use', 'transform', 'output', 'hidden', 'state', 'factor', 'return', 'input', 'variabl', 'feed', 'forward', 'nn', 'would', 'like', 'replic', 'approach', 'would', 'first', 'use', 'macro', 'factor', 'infer', 'econom', 'cycl', 'use', 'inform', 'togeth', 'factor', 'return', 'ffn', 'predict', 'stock', 'return', 'tri', 'use', 'code', 'sure', 'whether', 'would', 'effici', 'use', 'power', 'lstm', 'tensorflow', 'kera', 'import', 'layer', 'use', 'lstm', 'layer', 'transform', 'macro', 'factor', 'input', 'transform', 'output', 'lstm_layer_', 'layer', 'lstm', 'dropout', 'return_sequ', 'true', 'activ', 'relu', 'x_train_macro', 'output_layer_', 'layer', 'dens', 'activ', 'relu', 'lstm_layer_', 'lstm_layer_', 'layer', 'lstm', 'dropout', 'return_sequ', 'true', 'activ', 'relu', 'output_layer_', 'output_layer_', 'layer', 'dens', 'activ', 'relu', 'lstm_layer_', 'lstm_layer_', 'layer', 'lstm', 'dropout', 'return_sequ', 'true', 'activ', 'relu', 'output_layer_', 'output_layer_', 'layer', 'dens', 'activ', 'relu', 'lstm_layer_', 'tensorflow', 'kera', 'import', 'layer', 'use', 'lstm', 'layer', 'transform', 'macro', 'factor', 'input', 'transform', 'output', 'lstm_output', 'states_h', 'states_c', 'layer', 'lstm', 'dropout', 'return_sequ', 'true', 'return_st', 'true', 'activ', 'relu', 'x_train_macro', 'rel', 'design', 'nn', 'know', 'seem', 'like', 'tough', 'challeng', 'help', 'would', 'highli', 'appreci', 'wish', 'nice', 'even', 'cheer']"
101,109,109,mrwangyou,w7b0le,"[D] Can a paper about air combat be accepted by conferences such as ICLR, IJCAI, NeurIPS according to its ethics guidelines?","Hello there,

I'm a student of AI in air combat simulation. I'm doing research about dogfights between planes. Recently I just read the ethics guidelines of some conferences. For NeurIPS, it says "" Consider whether the proposed methods and applications can directly facilitate injury to living beings. For example: could it be integrated into weapons or weapons systems?"" For ACM, it says ""Avoid harm ... ""harm"" means negative consequences, especially when those consequences are significant and unjust."" For ICLR, it says ""Avoid harm ... ""harm"" means negative consequences. Well-intended actions, including those that accomplish desired outcomes, may lead to harm. "" So I wonder if a scientific about intelligent maneuver decision methods could be accepted by those conferences? Thank you!

2022.7.25",29,20,2022-07-25 03:56:53, d  can a paper about air combat be accepted by conferences such as iclr  ijcai  neurips according to its ethics guidelines ,hello there i m a student of ai in air combat simulation  i m doing research about dogfights between planes  recently i just read the ethics guidelines of some conferences  for neurips  it says  consider whether the proposed methods and applications can directly facilitate injury to living beings  for example  could it be integrated into weapons or weapons systems  for acm  it says avoid harm     harm means negative consequences  especially when those consequences are significant and unjust  for iclr  it says avoid harm     harm means negative consequences  well intended actions  including those that accomplish desired outcomes  may lead to harm   so i wonder if a scientific about intelligent maneuver decision methods could be accepted by those conferences  thank you   ,hello student ai air combat simulation research dogfights planes recently read ethics guidelines conferences neurips says consider whether proposed methods applications directly facilitate injury living beings example could integrated weapons weapons systems acm says avoid harm harm means negative consequences especially consequences significant unjust iclr says avoid harm harm means negative consequences well intended actions including accomplish desired outcomes may lead harm wonder scientific intelligent maneuver decision methods could accepted conferences thank,paper air combat accepted conferences iclr ijcai neurips according ethics guidelines,paper air combat accepted conferences iclr ijcai neurips according ethics guidelineshello student ai air combat simulation research dogfights planes recently read ethics guidelines conferences neurips says consider whether proposed methods applications directly facilitate injury living beings example could integrated weapons weapons systems acm says avoid harm harm means negative consequences especially consequences significant unjust iclr says avoid harm harm means negative consequences well intended actions including accomplish desired outcomes may lead harm wonder scientific intelligent maneuver decision methods could accepted conferences thank,"['paper', 'air', 'combat', 'accepted', 'conferences', 'iclr', 'ijcai', 'neurips', 'according', 'ethics', 'guidelineshello', 'student', 'ai', 'air', 'combat', 'simulation', 'research', 'dogfights', 'planes', 'recently', 'read', 'ethics', 'guidelines', 'conferences', 'neurips', 'says', 'consider', 'whether', 'proposed', 'methods', 'applications', 'directly', 'facilitate', 'injury', 'living', 'beings', 'example', 'could', 'integrated', 'weapons', 'weapons', 'systems', 'acm', 'says', 'avoid', 'harm', 'harm', 'means', 'negative', 'consequences', 'especially', 'consequences', 'significant', 'unjust', 'iclr', 'says', 'avoid', 'harm', 'harm', 'means', 'negative', 'consequences', 'well', 'intended', 'actions', 'including', 'accomplish', 'desired', 'outcomes', 'may', 'lead', 'harm', 'wonder', 'scientific', 'intelligent', 'maneuver', 'decision', 'methods', 'could', 'accepted', 'conferences', 'thank']","['paper', 'air', 'combat', 'accept', 'confer', 'iclr', 'ijcai', 'neurip', 'accord', 'ethic', 'guidelineshello', 'student', 'ai', 'air', 'combat', 'simul', 'research', 'dogfight', 'plane', 'recent', 'read', 'ethic', 'guidelin', 'confer', 'neurip', 'say', 'consid', 'whether', 'propos', 'method', 'applic', 'directli', 'facilit', 'injuri', 'live', 'be', 'exampl', 'could', 'integr', 'weapon', 'weapon', 'system', 'acm', 'say', 'avoid', 'harm', 'harm', 'mean', 'neg', 'consequ', 'especi', 'consequ', 'signific', 'unjust', 'iclr', 'say', 'avoid', 'harm', 'harm', 'mean', 'neg', 'consequ', 'well', 'intend', 'action', 'includ', 'accomplish', 'desir', 'outcom', 'may', 'lead', 'harm', 'wonder', 'scientif', 'intellig', 'maneuv', 'decis', 'method', 'could', 'accept', 'confer', 'thank']"
102,110,110,l0g1cs,w7jfmd,[N] Accuracy-Aware Inference Optimization Tracking and Profiling,"Optimizing inference for low latency and throughput is a process that requires many iterations of tuning, verification and evaluation. It may even involve model selection since many optimized versions of popular models are available now. Sometimes a retraining is necessary for techniques like weight pruning and quantization. Target hardware is another dimension to consider.

In short, without benchmarking, verification and evaluation, optimizations do not guarantee improved results and may even break things. One example is quantization using instructions that are not supported on target hardware.

To address all these problems, we've built a [tool](https://graphsignal.com/) to track inference optimizations, see how accuracy is affected, verify that the optimizations were applied and locate any bottlenecks for further improvements. All in one place.

https://preview.redd.it/yzlxa21cdod91.png?width=3048&format=png&auto=webp&s=97306440ea508f65582978298f6e3ec291293902

More about inference optimization in [this article](https://graphsignal.com/blog/accuracy-aware-inference-optimization-tracking/), with code. And here is a [live demo](https://app.graphsignal.com/workload-runs/(data_id:e722346fd67d,dimension_id:'9a16c4e11858',workload_id:'7560b8034d72')).",1,5,2022-07-25 11:29:39, n  accuracy aware inference optimization tracking and profiling,optimizing inference for low latency and throughput is a process that requires many iterations of tuning  verification and evaluation  it may even involve model selection since many optimized versions of popular models are available now  sometimes a retraining is necessary for techniques like weight pruning and quantization  target hardware is another dimension to consider in short  without benchmarking  verification and evaluation  optimizations do not guarantee improved results and may even break things  one example is quantization using instructions that are not supported on target hardware to address all these problems  we ve built a  tool  https https more about inference optimization in  this article  https   graphsignal com blog accuracy aware inference optimization tracking    with code  and here is a  live demo  https   app graphsignal com workload runs  data_id efdd dimension_id  ace  workload_id  bd    ,optimizing inference low latency throughput process requires many iterations tuning verification evaluation may even involve model selection since many optimized versions popular models available sometimes retraining necessary techniques like weight pruning quantization target hardware another dimension consider short without benchmarking verification evaluation optimizations guarantee improved results may even break things one example quantization using instructions supported target hardware address problems built tool https https inference optimization article https graphsignal com blog accuracy aware inference optimization tracking code live demo https app graphsignal com workload runs data_id efdd dimension_id ace workload_id bd,n accuracy aware inference optimization tracking profiling,n accuracy aware inference optimization tracking profilingoptimizing inference low latency throughput process requires many iterations tuning verification evaluation may even involve model selection since many optimized versions popular models available sometimes retraining necessary techniques like weight pruning quantization target hardware another dimension consider short without benchmarking verification evaluation optimizations guarantee improved results may even break things one example quantization using instructions supported target hardware address problems built tool https https inference optimization article https graphsignal com blog accuracy aware inference optimization tracking code live demo https app graphsignal com workload runs data_id efdd dimension_id ace workload_id bd,"['n', 'accuracy', 'aware', 'inference', 'optimization', 'tracking', 'profilingoptimizing', 'inference', 'low', 'latency', 'throughput', 'process', 'requires', 'many', 'iterations', 'tuning', 'verification', 'evaluation', 'may', 'even', 'involve', 'model', 'selection', 'since', 'many', 'optimized', 'versions', 'popular', 'models', 'available', 'sometimes', 'retraining', 'necessary', 'techniques', 'like', 'weight', 'pruning', 'quantization', 'target', 'hardware', 'another', 'dimension', 'consider', 'short', 'without', 'benchmarking', 'verification', 'evaluation', 'optimizations', 'guarantee', 'improved', 'results', 'may', 'even', 'break', 'things', 'one', 'example', 'quantization', 'using', 'instructions', 'supported', 'target', 'hardware', 'address', 'problems', 'built', 'tool', 'https', 'https', 'inference', 'optimization', 'article', 'https', 'graphsignal', 'com', 'blog', 'accuracy', 'aware', 'inference', 'optimization', 'tracking', 'code', 'live', 'demo', 'https', 'app', 'graphsignal', 'com', 'workload', 'runs', 'data_id', 'efdd', 'dimension_id', 'ace', 'workload_id', 'bd']","['n', 'accuraci', 'awar', 'infer', 'optim', 'track', 'profilingoptim', 'infer', 'low', 'latenc', 'throughput', 'process', 'requir', 'mani', 'iter', 'tune', 'verif', 'evalu', 'may', 'even', 'involv', 'model', 'select', 'sinc', 'mani', 'optim', 'version', 'popular', 'model', 'avail', 'sometim', 'retrain', 'necessari', 'techniqu', 'like', 'weight', 'prune', 'quantiz', 'target', 'hardwar', 'anoth', 'dimens', 'consid', 'short', 'without', 'benchmark', 'verif', 'evalu', 'optim', 'guarante', 'improv', 'result', 'may', 'even', 'break', 'thing', 'one', 'exampl', 'quantiz', 'use', 'instruct', 'support', 'target', 'hardwar', 'address', 'problem', 'built', 'tool', 'http', 'http', 'infer', 'optim', 'articl', 'http', 'graphsign', 'com', 'blog', 'accuraci', 'awar', 'infer', 'optim', 'track', 'code', 'live', 'demo', 'http', 'app', 'graphsign', 'com', 'workload', 'run', 'data_id', 'efdd', 'dimension_id', 'ace', 'workload_id', 'bd']"
103,111,111,l34df4rm3r,w7kf4v,[D] What's the best resource to learn more about complex networks?,"Hi, I have been working with graph neural networks and graph convolution networks for a while now. However, I wish to learn more about complex networks and other machine learning methods that are already available for tasks like link prediction and node property prediction for such data. 

Is there any good resource, other than research papers, to get started with complex networks?",4,3,2022-07-25 12:30:51, d  what s the best resource to learn more about complex networks ,hi  i have been working with graph neural networks and graph convolution networks for a while now  however  i wish to learn more about complex networks and other machine learning methods that are already available for tasks like link prediction and node property prediction for such data  is there any good resource  other than research papers  to get started with complex networks ,hi working graph neural networks graph convolution networks however wish learn complex networks machine learning methods already available tasks like link prediction node property prediction data good resource research papers get started complex networks,best resource learn complex networks,best resource learn complex networkshi working graph neural networks graph convolution networks however wish learn complex networks machine learning methods already available tasks like link prediction node property prediction data good resource research papers get started complex networks,"['best', 'resource', 'learn', 'complex', 'networkshi', 'working', 'graph', 'neural', 'networks', 'graph', 'convolution', 'networks', 'however', 'wish', 'learn', 'complex', 'networks', 'machine', 'learning', 'methods', 'already', 'available', 'tasks', 'like', 'link', 'prediction', 'node', 'property', 'prediction', 'data', 'good', 'resource', 'research', 'papers', 'get', 'started', 'complex', 'networks']","['best', 'resourc', 'learn', 'complex', 'networkshi', 'work', 'graph', 'neural', 'network', 'graph', 'convolut', 'network', 'howev', 'wish', 'learn', 'complex', 'network', 'machin', 'learn', 'method', 'alreadi', 'avail', 'task', 'like', 'link', 'predict', 'node', 'properti', 'predict', 'data', 'good', 'resourc', 'research', 'paper', 'get', 'start', 'complex', 'network']"
104,112,112,Captain_Clapton,w7qpd0,[P] Pose estimation based on cases generated via Hidden Markov model,"I'm looking to generate a list of pose cases based on sensor data (imu, angle sensors, etc) by feeding gathered data into a hidden Markov model. I'm trying to figure out how to use a hmm to generate pose cases so that my system will be able to predict the movement of a user.

After some brief research online I found [https://hmmlearn.readthedocs.io/en/latest/tutorial.html](https://hmmlearn.readthedocs.io/en/latest/tutorial.html) and [https://www.scitepress.org/Papers/2020/93575/93575.pdf](https://www.scitepress.org/Papers/2020/93575/93575.pdf)

But I'm pretty new to machine learning and after looking through both I'm pretty confused. I understand how hmm's work on a basic level but I'm not sure how to apply them specifically to this case.

I would greatly appreciate any ideas on how to approach this and what aspects of a hmm to use specifically (and with things like types of emissions, etc. ). Also apologies if this is vague, just trying to figure out an approach.

Looking to develop the model in python.

Thanks!",1,1,2022-07-25 17:42:30, p  pose estimation based on cases generated via hidden markov model,i m looking to generate a list of pose cases based on sensor data  imu  angle sensors  etc  by feeding gathered data into a hidden markov model  i m trying to figure out how to use a hmm to generate pose cases so that my system will be able to predict the movement of a user after some brief research online i found  https but i m pretty new to machine learning and after looking through both i m pretty confused  i understand how hmm s work on a basic level but i m not sure how to apply them specifically to this case i would greatly appreciate any ideas on how to approach this and what aspects of a hmm to use specifically  and with things like types of emissions  etc     also apologies if this is vague  just trying to figure out an approach looking to develop the model in python thanks ,looking generate pose cases based sensor data imu angle sensors etc feeding gathered data hidden markov model trying figure use hmm generate pose cases system able predict movement user brief research online found https pretty machine learning looking pretty confused understand hmm work basic level sure apply specifically case would greatly appreciate ideas approach aspects hmm use specifically things like types emissions etc also apologies vague trying figure approach looking develop model python thanks,p pose estimation based cases generated via hidden markov model,p pose estimation based cases generated via hidden markov modellooking generate pose cases based sensor data imu angle sensors etc feeding gathered data hidden markov model trying figure use hmm generate pose cases system able predict movement user brief research online found https pretty machine learning looking pretty confused understand hmm work basic level sure apply specifically case would greatly appreciate ideas approach aspects hmm use specifically things like types emissions etc also apologies vague trying figure approach looking develop model python thanks,"['p', 'pose', 'estimation', 'based', 'cases', 'generated', 'via', 'hidden', 'markov', 'modellooking', 'generate', 'pose', 'cases', 'based', 'sensor', 'data', 'imu', 'angle', 'sensors', 'etc', 'feeding', 'gathered', 'data', 'hidden', 'markov', 'model', 'trying', 'figure', 'use', 'hmm', 'generate', 'pose', 'cases', 'system', 'able', 'predict', 'movement', 'user', 'brief', 'research', 'online', 'found', 'https', 'pretty', 'machine', 'learning', 'looking', 'pretty', 'confused', 'understand', 'hmm', 'work', 'basic', 'level', 'sure', 'apply', 'specifically', 'case', 'would', 'greatly', 'appreciate', 'ideas', 'approach', 'aspects', 'hmm', 'use', 'specifically', 'things', 'like', 'types', 'emissions', 'etc', 'also', 'apologies', 'vague', 'trying', 'figure', 'approach', 'looking', 'develop', 'model', 'python', 'thanks']","['p', 'pose', 'estim', 'base', 'case', 'gener', 'via', 'hidden', 'markov', 'modellook', 'gener', 'pose', 'case', 'base', 'sensor', 'data', 'imu', 'angl', 'sensor', 'etc', 'feed', 'gather', 'data', 'hidden', 'markov', 'model', 'tri', 'figur', 'use', 'hmm', 'gener', 'pose', 'case', 'system', 'abl', 'predict', 'movement', 'user', 'brief', 'research', 'onlin', 'found', 'http', 'pretti', 'machin', 'learn', 'look', 'pretti', 'confus', 'understand', 'hmm', 'work', 'basic', 'level', 'sure', 'appli', 'specif', 'case', 'would', 'greatli', 'appreci', 'idea', 'approach', 'aspect', 'hmm', 'use', 'specif', 'thing', 'like', 'type', 'emiss', 'etc', 'also', 'apolog', 'vagu', 'tri', 'figur', 'approach', 'look', 'develop', 'model', 'python', 'thank']"
105,113,113,Smartch,w6u4mh,[D] What are tools you wish you knew about earlier in your ML career?,"Hi, sorry if it has already been asked but I could not find a similar post. I am starting my Master's thesis next September and I was looking for your insights in tools and software that you wish you knew earlier.

Recently I have learned how to use W&B for logging and it was personally a huge improvement compared to Tensorboard, especially with the built-in hyperparameter sweep. 

I have been using Lightning for a while now but just learned how to use it with Hydra to make configuration tracking easier. It may also sounds ridiculous but I was not using VSCode debugger and it made a huge difference in my workflow.

I am also looking forward to trying out Gradio to perform demos of my model.

Most of these tools I have known about through colleagues or supervisors at work, so /r/MachineLearning  what are the tools you have learned how to use that made a huge difference in your workflow?",59,104,2022-07-24 15:06:13, d  what are tools you wish you knew about earlier in your ml career ,hi  sorry if it has already been asked but i could not find a similar post  i am starting my master s thesis next september and i was looking for your insights in tools and software that you wish you knew earlier recently i have learned how to use w b for logging and it was personally a huge improvement compared to tensorboard  especially with the built in hyperparameter sweep  i have been using lightning for a while now but just learned how to use it with hydra to make configuration tracking easier  it may also sounds ridiculous but i was not using vscode debugger and it made a huge difference in my workflow i am also looking forward to trying out gradio to perform demos of my model most of these tools i have known about through colleagues or supervisors at work  so  r machinelearning  what are the tools you have learned how to use that made a huge difference in your workflow ,hi sorry already asked could find similar post starting master thesis next september looking insights tools software wish knew earlier recently learned use w b logging personally huge improvement compared tensorboard especially built hyperparameter sweep using lightning learned use hydra make configuration tracking easier may also sounds ridiculous using vscode debugger made huge difference workflow also looking forward trying gradio perform demos model tools known colleagues supervisors work r machinelearning tools learned use made huge difference workflow,tools wish knew earlier ml career,tools wish knew earlier ml careerhi sorry already asked could find similar post starting master thesis next september looking insights tools software wish knew earlier recently learned use w b logging personally huge improvement compared tensorboard especially built hyperparameter sweep using lightning learned use hydra make configuration tracking easier may also sounds ridiculous using vscode debugger made huge difference workflow also looking forward trying gradio perform demos model tools known colleagues supervisors work r machinelearning tools learned use made huge difference workflow,"['tools', 'wish', 'knew', 'earlier', 'ml', 'careerhi', 'sorry', 'already', 'asked', 'could', 'find', 'similar', 'post', 'starting', 'master', 'thesis', 'next', 'september', 'looking', 'insights', 'tools', 'software', 'wish', 'knew', 'earlier', 'recently', 'learned', 'use', 'w', 'b', 'logging', 'personally', 'huge', 'improvement', 'compared', 'tensorboard', 'especially', 'built', 'hyperparameter', 'sweep', 'using', 'lightning', 'learned', 'use', 'hydra', 'make', 'configuration', 'tracking', 'easier', 'may', 'also', 'sounds', 'ridiculous', 'using', 'vscode', 'debugger', 'made', 'huge', 'difference', 'workflow', 'also', 'looking', 'forward', 'trying', 'gradio', 'perform', 'demos', 'model', 'tools', 'known', 'colleagues', 'supervisors', 'work', 'r', 'machinelearning', 'tools', 'learned', 'use', 'made', 'huge', 'difference', 'workflow']","['tool', 'wish', 'knew', 'earlier', 'ml', 'careerhi', 'sorri', 'alreadi', 'ask', 'could', 'find', 'similar', 'post', 'start', 'master', 'thesi', 'next', 'septemb', 'look', 'insight', 'tool', 'softwar', 'wish', 'knew', 'earlier', 'recent', 'learn', 'use', 'w', 'b', 'log', 'person', 'huge', 'improv', 'compar', 'tensorboard', 'especi', 'built', 'hyperparamet', 'sweep', 'use', 'lightn', 'learn', 'use', 'hydra', 'make', 'configur', 'track', 'easier', 'may', 'also', 'sound', 'ridicul', 'use', 'vscode', 'debugg', 'made', 'huge', 'differ', 'workflow', 'also', 'look', 'forward', 'tri', 'gradio', 'perform', 'demo', 'model', 'tool', 'known', 'colleagu', 'supervisor', 'work', 'r', 'machinelearn', 'tool', 'learn', 'use', 'made', 'huge', 'differ', 'workflow']"
106,115,115,emissaryo,w82gn6,[D] Did you ever imagine how to create AGI?,"Sometimes I fantasize about AGI and how it can be achieved with ML/RL and etc. I believe that we will see a breakthrough in ML and get much closer to AGI once we achieve quantum supremacy and be able to do ML on quantum computers. I feel like AGI must be something like an ensamble of multiple models each being specific to its own task but still somehow share data with each other. Also even being quantum computer powered, I feel like it'd take years to train an AGI.

And what do you guys think about AGI? Do you have ideas on how it can be achieved? What do you think stops us from having it next year for example?",17,0,2022-07-26 01:36:26, d  did you ever imagine how to create agi ,sometimes i fantasize about agi and how it can be achieved with ml rl and etc  i believe that we will see a breakthrough in ml and get much closer to agi once we achieve quantum supremacy and be able to do ml on quantum computers  i feel like agi must be something like an ensamble of multiple models each being specific to its own task but still somehow share data with each other  also even being quantum computer powered  i feel like it d take years to train an agi and what do you guys think about agi  do you have ideas on how it can be achieved  what do you think stops us from having it next year for example ,sometimes fantasize agi achieved ml rl etc believe see breakthrough ml get much closer agi achieve quantum supremacy able ml quantum computers feel like agi must something like ensamble multiple models specific task still somehow share data also even quantum computer powered feel like take years train agi guys think agi ideas achieved think stops us next year example,ever imagine create agi,ever imagine create agisometimes fantasize agi achieved ml rl etc believe see breakthrough ml get much closer agi achieve quantum supremacy able ml quantum computers feel like agi must something like ensamble multiple models specific task still somehow share data also even quantum computer powered feel like take years train agi guys think agi ideas achieved think stops us next year example,"['ever', 'imagine', 'create', 'agisometimes', 'fantasize', 'agi', 'achieved', 'ml', 'rl', 'etc', 'believe', 'see', 'breakthrough', 'ml', 'get', 'much', 'closer', 'agi', 'achieve', 'quantum', 'supremacy', 'able', 'ml', 'quantum', 'computers', 'feel', 'like', 'agi', 'must', 'something', 'like', 'ensamble', 'multiple', 'models', 'specific', 'task', 'still', 'somehow', 'share', 'data', 'also', 'even', 'quantum', 'computer', 'powered', 'feel', 'like', 'take', 'years', 'train', 'agi', 'guys', 'think', 'agi', 'ideas', 'achieved', 'think', 'stops', 'us', 'next', 'year', 'example']","['ever', 'imagin', 'creat', 'agisometim', 'fantas', 'agi', 'achiev', 'ml', 'rl', 'etc', 'believ', 'see', 'breakthrough', 'ml', 'get', 'much', 'closer', 'agi', 'achiev', 'quantum', 'supremaci', 'abl', 'ml', 'quantum', 'comput', 'feel', 'like', 'agi', 'must', 'someth', 'like', 'ensambl', 'multipl', 'model', 'specif', 'task', 'still', 'somehow', 'share', 'data', 'also', 'even', 'quantum', 'comput', 'power', 'feel', 'like', 'take', 'year', 'train', 'agi', 'guy', 'think', 'agi', 'idea', 'achiev', 'think', 'stop', 'us', 'next', 'year', 'exampl']"
107,116,116,diabulusInMusica,w7kckm,[P] How to deploy ML models in production with BentoML,"Deploying Machine Learning models into production is a big hassle. 

You have to manage models, build a service to run inferences (e.g., with Flask) , and deploy the service somewhere (e.g., Kubernetes).

These steps are often convoluted and disjointed. I talk about these issues in the initial video of my “ML Deployment” mini series.

There are a few MLOps tools that make model deployment easier. 

Out of the many options, I like BentoML the most. 

This framework manages models via a simple CLI. It allows you to create an efficient service to make inferences. It builds units of deployment called bentos that combine both model and service. It makes containerisation easy and deployment on Kubernetes and cloud platforms a piece of cake.

Want to learn more about BentoML?

Check out my latest video in the “ML Deployment” mini-series.

[https://www.youtube.com/watch?v=HHkmfI\_yncc](https://www.youtube.com/watch?v=HHkmfI_yncc)",0,0,2022-07-25 12:26:41, p  how to deploy ml models in production with bentoml,deploying machine learning models into production is a big hassle  you have to manage models  build a service to run inferences  e g   with flask    and deploy the service somewhere  e g   kubernetes  these steps are often convoluted and disjointed  i talk about these issues in the initial video of my  ml deployment  mini series there are a few mlops tools that make model deployment easier  out of the many options  i like bentoml the most  this framework manages models via a simple cli  it allows you to create an efficient service to make inferences  it builds units of deployment called bentos that combine both model and service  it makes containerisation easy and deployment on kubernetes and cloud platforms a piece of cake want to learn more about bentoml check out my latest video in the  ml deployment  mini series  https   www youtube com watch v hhkmfi _yncc  https   www youtube com watch v hhkmfi_yncc ,deploying machine learning models production big hassle manage models build service run inferences e g flask deploy service somewhere e g kubernetes steps often convoluted disjointed talk issues initial video ml deployment mini series mlops tools make model deployment easier many options like bentoml framework manages models via simple cli allows create efficient service make inferences builds units deployment called bentos combine model service makes containerisation easy deployment kubernetes cloud platforms piece cake want learn bentoml check latest video ml deployment mini series https www youtube com watch v hhkmfi _yncc https www youtube com watch v hhkmfi_yncc,p deploy ml models production bentoml,p deploy ml models production bentomldeploying machine learning models production big hassle manage models build service run inferences e g flask deploy service somewhere e g kubernetes steps often convoluted disjointed talk issues initial video ml deployment mini series mlops tools make model deployment easier many options like bentoml framework manages models via simple cli allows create efficient service make inferences builds units deployment called bentos combine model service makes containerisation easy deployment kubernetes cloud platforms piece cake want learn bentoml check latest video ml deployment mini series https www youtube com watch v hhkmfi _yncc https www youtube com watch v hhkmfi_yncc,"['p', 'deploy', 'ml', 'models', 'production', 'bentomldeploying', 'machine', 'learning', 'models', 'production', 'big', 'hassle', 'manage', 'models', 'build', 'service', 'run', 'inferences', 'e', 'g', 'flask', 'deploy', 'service', 'somewhere', 'e', 'g', 'kubernetes', 'steps', 'often', 'convoluted', 'disjointed', 'talk', 'issues', 'initial', 'video', 'ml', 'deployment', 'mini', 'series', 'mlops', 'tools', 'make', 'model', 'deployment', 'easier', 'many', 'options', 'like', 'bentoml', 'framework', 'manages', 'models', 'via', 'simple', 'cli', 'allows', 'create', 'efficient', 'service', 'make', 'inferences', 'builds', 'units', 'deployment', 'called', 'bentos', 'combine', 'model', 'service', 'makes', 'containerisation', 'easy', 'deployment', 'kubernetes', 'cloud', 'platforms', 'piece', 'cake', 'want', 'learn', 'bentoml', 'check', 'latest', 'video', 'ml', 'deployment', 'mini', 'series', 'https', 'www', 'youtube', 'com', 'watch', 'v', 'hhkmfi', '_yncc', 'https', 'www', 'youtube', 'com', 'watch', 'v', 'hhkmfi_yncc']","['p', 'deploy', 'ml', 'model', 'product', 'bentomldeploy', 'machin', 'learn', 'model', 'product', 'big', 'hassl', 'manag', 'model', 'build', 'servic', 'run', 'infer', 'e', 'g', 'flask', 'deploy', 'servic', 'somewher', 'e', 'g', 'kubernet', 'step', 'often', 'convolut', 'disjoint', 'talk', 'issu', 'initi', 'video', 'ml', 'deploy', 'mini', 'seri', 'mlop', 'tool', 'make', 'model', 'deploy', 'easier', 'mani', 'option', 'like', 'bentoml', 'framework', 'manag', 'model', 'via', 'simpl', 'cli', 'allow', 'creat', 'effici', 'servic', 'make', 'infer', 'build', 'unit', 'deploy', 'call', 'bento', 'combin', 'model', 'servic', 'make', 'containeris', 'easi', 'deploy', 'kubernet', 'cloud', 'platform', 'piec', 'cake', 'want', 'learn', 'bentoml', 'check', 'latest', 'video', 'ml', 'deploy', 'mini', 'seri', 'http', 'www', 'youtub', 'com', 'watch', 'v', 'hhkmfi', '_yncc', 'http', 'www', 'youtub', 'com', 'watch', 'v', 'hhkmfi_yncc']"
108,117,117,NikhilArethiya,w7f75f,[D] Panoramic Xrays of teeth - Dataset,"I am looking for dataset that are the panoramic xrays  of the teeth (upper and lowe jaw). That would help to detect the irregular teeth, cysts, tumors and infections by just from ML.
If anyone can help with dataset ????",0,2,2022-07-25 07:21:12, d  panoramic xrays of teeth   dataset,i am looking for dataset that are the panoramic xrays  of the teeth  upper and lowe jaw   that would help to detect the irregular teeth  cysts  tumors and infections by just from ml if anyone can help with dataset     ,looking dataset panoramic xrays teeth upper lowe jaw would help detect irregular teeth cysts tumors infections ml anyone help dataset,panoramic xrays teeth dataset,panoramic xrays teeth datasetlooking dataset panoramic xrays teeth upper lowe jaw would help detect irregular teeth cysts tumors infections ml anyone help dataset,"['panoramic', 'xrays', 'teeth', 'datasetlooking', 'dataset', 'panoramic', 'xrays', 'teeth', 'upper', 'lowe', 'jaw', 'would', 'help', 'detect', 'irregular', 'teeth', 'cysts', 'tumors', 'infections', 'ml', 'anyone', 'help', 'dataset']","['panoram', 'xray', 'teeth', 'datasetlook', 'dataset', 'panoram', 'xray', 'teeth', 'upper', 'low', 'jaw', 'would', 'help', 'detect', 'irregular', 'teeth', 'cyst', 'tumor', 'infect', 'ml', 'anyon', 'help', 'dataset']"
109,118,118,IllustriousCicada603,w7io5w,[D] Can I create a Generative Adversarial Network for text using the logits without argmax,"There are two main problems when creating Generative Adversarial Networks for text:

1. The discrete token values are not differentiable after applying argmax.
2. The language architecture may generate sequences with different lengths so the discriminator should be able to work with them either with padding or with some representation of the whole sequence.

I was wondering if is it possible to adversarially train a model such as [T5](https://huggingface.co/docs/transformers/model_doc/t5). Its decoder produces a sequence with shape `[batch_size, seq_len, model_dim]` and then it is usually passed through a linear layer to get `[batch_size, seq_len, vocab_size]` logits. We can apply a softmax across the `vocab_size` dimension and then these probabilities can go to a discriminator. For the ground truth labels `[batch_size, seq_len]` we can generate one-hot vectors `[batch_size, seq_len, vocab_size]` and then apply the softmax to them as well. This will be sufficient for the discriminator to learn from truths but since we do not apply argmax to the tokens from the generator (T5 decoder), gradients should be able to reach it as well.

For the second problem, I was thinking of computing mean to transform `[batch_size, seq_len, vocab_size]` probabilities to a ""sequence representation"" `[batch_size, vocab_size]`, but I am not sure if this makes sense.

So based on that, is **1** feasible and if not - why? What are some suggestions for solving **2**?",1,0,2022-07-25 10:41:26, d  can i create a generative adversarial network for text using the logits without argmax,there are two main problems when creating generative adversarial networks for text   the discrete token values are not differentiable after applying argmax   the language architecture may generate sequences with different lengths so the discriminator should be able to work with them either with padding or with some representation of the whole sequence i was wondering if is it possible to adversarially train a model such as  t  https for the second problem  i was thinking of computing mean to transform   batch_size  seq_len  vocab_size   probabilities to a sequence representation   batch_size  vocab_size    but i am not sure if this makes sense so based on that  is      feasible and if not   why  what are some suggestions for solving      ,two main problems creating generative adversarial networks text discrete token values differentiable applying argmax language architecture may generate sequences different lengths discriminator able work either padding representation whole sequence wondering possible adversarially train model https second problem thinking computing mean transform batch_size seq_len vocab_size probabilities sequence representation batch_size vocab_size sure makes sense based feasible suggestions solving,create generative adversarial network text using logits without argmax,create generative adversarial network text using logits without argmaxtwo main problems creating generative adversarial networks text discrete token values differentiable applying argmax language architecture may generate sequences different lengths discriminator able work either padding representation whole sequence wondering possible adversarially train model https second problem thinking computing mean transform batch_size seq_len vocab_size probabilities sequence representation batch_size vocab_size sure makes sense based feasible suggestions solving,"['create', 'generative', 'adversarial', 'network', 'text', 'using', 'logits', 'without', 'argmaxtwo', 'main', 'problems', 'creating', 'generative', 'adversarial', 'networks', 'text', 'discrete', 'token', 'values', 'differentiable', 'applying', 'argmax', 'language', 'architecture', 'may', 'generate', 'sequences', 'different', 'lengths', 'discriminator', 'able', 'work', 'either', 'padding', 'representation', 'whole', 'sequence', 'wondering', 'possible', 'adversarially', 'train', 'model', 'https', 'second', 'problem', 'thinking', 'computing', 'mean', 'transform', 'batch_size', 'seq_len', 'vocab_size', 'probabilities', 'sequence', 'representation', 'batch_size', 'vocab_size', 'sure', 'makes', 'sense', 'based', 'feasible', 'suggestions', 'solving']","['creat', 'gener', 'adversari', 'network', 'text', 'use', 'logit', 'without', 'argmaxtwo', 'main', 'problem', 'creat', 'gener', 'adversari', 'network', 'text', 'discret', 'token', 'valu', 'differenti', 'appli', 'argmax', 'languag', 'architectur', 'may', 'gener', 'sequenc', 'differ', 'length', 'discrimin', 'abl', 'work', 'either', 'pad', 'represent', 'whole', 'sequenc', 'wonder', 'possibl', 'adversari', 'train', 'model', 'http', 'second', 'problem', 'think', 'comput', 'mean', 'transform', 'batch_siz', 'seq_len', 'vocab_s', 'probabl', 'sequenc', 'represent', 'batch_siz', 'vocab_s', 'sure', 'make', 'sens', 'base', 'feasibl', 'suggest', 'solv']"
110,119,119,ondrea_luciduma,w6zn12,"[D] With Normalizing Flows, how do they enforce the prior to be a distribution one can sample from?","Hi, sorry if this is a dumb question. I've been reading about normalizing flows recently and just can't wrap my head around this one concept. 



Here's what I do understand:


- We create an invertible neural network that transforms a tensor of shape S to another tensor of the same shape. 



- On the forward pass when we input samples from the distribution we want to model, the goal is for the output to be normal gaussian noise. So that we can then sample random noise and do the backward pass to get images from the complex distribution.



So in my mind the training of a normalizing flow model should look something like this:


X = get_batch_of_samples(  )   # shape:  batch, color_ch, size, size

Y = model(X)  # shape:  batch, color_ch, size, size


loss = something that measures if Y is random gaussian noise??



The loss is the part I don't understand. How can one derivably measure how far away a tensor is from random noise. 



Again, sorry if this is extremely uneducated but I'd really like to understand this. Thanks.",7,10,2022-07-24 19:32:35, d  with normalizing flows  how do they enforce the prior to be a distribution one can sample from ,hi  sorry if this is a dumb question  i ve been reading about normalizing flows recently and just can t wrap my head around this one concept  here s what i do understand   we create an invertible neural network that transforms a tensor of shape s to another tensor of the same shape    on the forward pass when we input samples from the distribution we want to model  the goal is for the output to be normal gaussian noise  so that we can then sample random noise and do the backward pass to get images from the complex distribution so in my mind the training of a normalizing flow model should look something like this x   get_batch_of_samples         shape   batch  color_ch  size  sizey   model x     shape   batch  color_ch  size  sizeloss   something that measures if y is random gaussian noise  the loss is the part i don t understand  how can one derivably measure how far away a tensor is from random noise  again  sorry if this is extremely uneducated but i d really like to understand this  thanks ,hi sorry dumb question reading normalizing flows recently wrap head around one concept understand create invertible neural network transforms tensor shape another tensor shape forward pass input samples distribution want model goal output normal gaussian noise sample random noise backward pass get images complex distribution mind training normalizing flow model look something like x get_batch_of_samples shape batch color_ch size sizey model x shape batch color_ch size sizeloss something measures random gaussian noise loss part understand one derivably measure far away tensor random noise sorry extremely uneducated really like understand thanks,normalizing flows enforce prior distribution one sample,normalizing flows enforce prior distribution one samplehi sorry dumb question reading normalizing flows recently wrap head around one concept understand create invertible neural network transforms tensor shape another tensor shape forward pass input samples distribution want model goal output normal gaussian noise sample random noise backward pass get images complex distribution mind training normalizing flow model look something like x get_batch_of_samples shape batch color_ch size sizey model x shape batch color_ch size sizeloss something measures random gaussian noise loss part understand one derivably measure far away tensor random noise sorry extremely uneducated really like understand thanks,"['normalizing', 'flows', 'enforce', 'prior', 'distribution', 'one', 'samplehi', 'sorry', 'dumb', 'question', 'reading', 'normalizing', 'flows', 'recently', 'wrap', 'head', 'around', 'one', 'concept', 'understand', 'create', 'invertible', 'neural', 'network', 'transforms', 'tensor', 'shape', 'another', 'tensor', 'shape', 'forward', 'pass', 'input', 'samples', 'distribution', 'want', 'model', 'goal', 'output', 'normal', 'gaussian', 'noise', 'sample', 'random', 'noise', 'backward', 'pass', 'get', 'images', 'complex', 'distribution', 'mind', 'training', 'normalizing', 'flow', 'model', 'look', 'something', 'like', 'x', 'get_batch_of_samples', 'shape', 'batch', 'color_ch', 'size', 'sizey', 'model', 'x', 'shape', 'batch', 'color_ch', 'size', 'sizeloss', 'something', 'measures', 'random', 'gaussian', 'noise', 'loss', 'part', 'understand', 'one', 'derivably', 'measure', 'far', 'away', 'tensor', 'random', 'noise', 'sorry', 'extremely', 'uneducated', 'really', 'like', 'understand', 'thanks']","['normal', 'flow', 'enforc', 'prior', 'distribut', 'one', 'samplehi', 'sorri', 'dumb', 'question', 'read', 'normal', 'flow', 'recent', 'wrap', 'head', 'around', 'one', 'concept', 'understand', 'creat', 'invert', 'neural', 'network', 'transform', 'tensor', 'shape', 'anoth', 'tensor', 'shape', 'forward', 'pass', 'input', 'sampl', 'distribut', 'want', 'model', 'goal', 'output', 'normal', 'gaussian', 'nois', 'sampl', 'random', 'nois', 'backward', 'pass', 'get', 'imag', 'complex', 'distribut', 'mind', 'train', 'normal', 'flow', 'model', 'look', 'someth', 'like', 'x', 'get_batch_of_sampl', 'shape', 'batch', 'color_ch', 'size', 'sizey', 'model', 'x', 'shape', 'batch', 'color_ch', 'size', 'sizeloss', 'someth', 'measur', 'random', 'gaussian', 'nois', 'loss', 'part', 'understand', 'one', 'deriv', 'measur', 'far', 'away', 'tensor', 'random', 'nois', 'sorri', 'extrem', 'uneduc', 'realli', 'like', 'understand', 'thank']"
111,120,120,snu95,w7d4k0,[D] CIKM 2022 Phase 1 Notification,Has anyone received the 1st phase notification on June?,2,1,2022-07-25 05:37:44, d  cikm  phase  notification,has anyone received the st phase notification on june ,anyone received st phase notification june,cikm phase notification,cikm phase notificationanyone received st phase notification june,"['cikm', 'phase', 'notificationanyone', 'received', 'st', 'phase', 'notification', 'june']","['cikm', 'phase', 'notificationanyon', 'receiv', 'st', 'phase', 'notif', 'june']"
112,121,121,cucumbersomesalad,w6fgwq,[D] 200+ Flashcards for ML Engineering,"I made 200+ flashcards to review everything from my years of ML research, classes, and independent study. Creating them helped me get ML Engineer offers from several companies in 2022 (including Google, Tesla, Samsung, Motional, UiPath, and TikTok). Questions are loosely based off Chip Huyen's ML Interviews Book.

If this sounds useful, please check them out here! 

[https://github.com/b7leung/MLE-Flashcards](https://github.com/b7leung/MLE-Flashcards)",6,161,2022-07-24 01:05:33, d    flashcards for ml engineering,i made   flashcards to review everything from my years of ml research  classes  and independent study  creating them helped me get ml engineer offers from several companies in   including google  tesla  samsung  motional  uipath  and tiktok   questions are loosely based off chip huyen s ml interviews book if this sounds useful  please check them out here   https   github com bleung mle flashcards  https   github com bleung mle flashcards ,made flashcards review everything years ml research classes independent study creating helped get ml engineer offers several companies including google tesla samsung motional uipath tiktok questions loosely based chip huyen ml interviews book sounds useful please check https github com bleung mle flashcards https github com bleung mle flashcards,flashcards ml engineering,flashcards ml engineeringmade flashcards review everything years ml research classes independent study creating helped get ml engineer offers several companies including google tesla samsung motional uipath tiktok questions loosely based chip huyen ml interviews book sounds useful please check https github com bleung mle flashcards https github com bleung mle flashcards,"['flashcards', 'ml', 'engineeringmade', 'flashcards', 'review', 'everything', 'years', 'ml', 'research', 'classes', 'independent', 'study', 'creating', 'helped', 'get', 'ml', 'engineer', 'offers', 'several', 'companies', 'including', 'google', 'tesla', 'samsung', 'motional', 'uipath', 'tiktok', 'questions', 'loosely', 'based', 'chip', 'huyen', 'ml', 'interviews', 'book', 'sounds', 'useful', 'please', 'check', 'https', 'github', 'com', 'bleung', 'mle', 'flashcards', 'https', 'github', 'com', 'bleung', 'mle', 'flashcards']","['flashcard', 'ml', 'engineeringmad', 'flashcard', 'review', 'everyth', 'year', 'ml', 'research', 'class', 'independ', 'studi', 'creat', 'help', 'get', 'ml', 'engin', 'offer', 'sever', 'compani', 'includ', 'googl', 'tesla', 'samsung', 'motion', 'uipath', 'tiktok', 'question', 'loos', 'base', 'chip', 'huyen', 'ml', 'interview', 'book', 'sound', 'use', 'pleas', 'check', 'http', 'github', 'com', 'bleung', 'mle', 'flashcard', 'http', 'github', 'com', 'bleung', 'mle', 'flashcard']"
113,122,122,happybirthday290,w79r9u,[D] Best way to run YOLO on video data?,"We all know deploying models is hard, and when it's on video it's even harder. How have you built & deployed deep learning models on video?  What were your latency and cost requirements? I'm assuming a cloud-native architecture but I'm open to hearing about edge use-cases as well.",0,1,2022-07-25 02:56:26, d  best way to run yolo on video data ,we all know deploying models is hard  and when it s on video it s even harder  how have you built   deployed deep learning models on video   what were your latency and cost requirements  i m assuming a cloud native architecture but i m open to hearing about edge use cases as well ,know deploying models hard video even harder built deployed deep learning models video latency cost requirements assuming cloud native architecture open hearing edge use cases well,best way run yolo video data,best way run yolo video dataknow deploying models hard video even harder built deployed deep learning models video latency cost requirements assuming cloud native architecture open hearing edge use cases well,"['best', 'way', 'run', 'yolo', 'video', 'dataknow', 'deploying', 'models', 'hard', 'video', 'even', 'harder', 'built', 'deployed', 'deep', 'learning', 'models', 'video', 'latency', 'cost', 'requirements', 'assuming', 'cloud', 'native', 'architecture', 'open', 'hearing', 'edge', 'use', 'cases', 'well']","['best', 'way', 'run', 'yolo', 'video', 'dataknow', 'deploy', 'model', 'hard', 'video', 'even', 'harder', 'built', 'deploy', 'deep', 'learn', 'model', 'video', 'latenc', 'cost', 'requir', 'assum', 'cloud', 'nativ', 'architectur', 'open', 'hear', 'edg', 'use', 'case', 'well']"
114,123,123,trncorn,w7j8xk,[D]Help me set the parameter for GRU in PyTorch,"In this image, I want the shape of the 2nd y result to equal the 1st result. Can you help me with how to do that?

Thanks.

https://preview.redd.it/xezrld9uaod91.png?width=1600&format=png&auto=webp&s=1b37534d77d277506f20925c5a4d405d46843c41",2,0,2022-07-25 11:17:42, d help me set the parameter for gru in pytorch,in this image  i want the shape of the nd y result to equal the st result  can you help me with how to do that thanks https   preview redd it xezrlduaod png width  format png auto webp s bddfcaddc,image want shape nd result equal st result help thanks https preview redd xezrlduaod png width format png auto webp bddfcaddc,help set parameter gru pytorch,help set parameter gru pytorchimage want shape nd result equal st result help thanks https preview redd xezrlduaod png width format png auto webp bddfcaddc,"['help', 'set', 'parameter', 'gru', 'pytorchimage', 'want', 'shape', 'nd', 'result', 'equal', 'st', 'result', 'help', 'thanks', 'https', 'preview', 'redd', 'xezrlduaod', 'png', 'width', 'format', 'png', 'auto', 'webp', 'bddfcaddc']","['help', 'set', 'paramet', 'gru', 'pytorchimag', 'want', 'shape', 'nd', 'result', 'equal', 'st', 'result', 'help', 'thank', 'http', 'preview', 'redd', 'xezrlduaod', 'png', 'width', 'format', 'png', 'auto', 'webp', 'bddfcaddc']"
115,124,124,TrepidEd0601,w6vwlz,[D] Literature on embeddings from metric space to L2 space?,"I'm currently trying to find theory papers on metric embeddings (namely, metric space to L2 space embeddings). I've been able to find literature on the distortion (albeit these results are old) such as [this](http://www-math.mit.edu/~goemans/18409-2006/lec2.pdf), but I haven't been able to find more specific studies that answer questions such as:

* Given a D-embedding into L2 space, how much distortion can we expect on average given certain conditions? (e.g. we know lower bound for distortion for metric -> L2 space is O(log n) by Bourgain's result from 1985, but what can you expect to see on average on a given set of distances assuming the properties of the metric space are known?)
* What sort of geometry of the embeddings will we see in the resulting embeddings?

Are there papers that talk about such questions for other distance-preserving spaces (e.g. L\_infinity instead of L2)?

Thanks!",2,4,2022-07-24 16:41:52, d  literature on embeddings from metric space to l space ,i m currently trying to find theory papers on metric embeddings  namely  metric space to l space embeddings   i ve been able to find literature on the distortion  albeit these results are old  such as  this  http   given a d embedding into l space  how much distortion can we expect on average given certain conditions   e g  we know lower bound for distortion for metric    l space is o log n  by bourgain s result from   but what can you expect to see on average on a given set of distances assuming the properties of the metric space are known    what sort of geometry of the embeddings will we see in the resulting embeddings are there papers that talk about such questions for other distance preserving spaces  e g  l _infinity instead of l  thanks ,currently trying find theory papers metric embeddings namely metric space l space embeddings able find literature distortion albeit results old http given embedding l space much distortion expect average given certain conditions e g know lower bound distortion metric l space log n bourgain result expect see average given set distances assuming properties metric space known sort geometry embeddings see resulting embeddings papers talk questions distance preserving spaces e g l _infinity instead l thanks,literature embeddings metric space l space,literature embeddings metric space l spacecurrently trying find theory papers metric embeddings namely metric space l space embeddings able find literature distortion albeit results old http given embedding l space much distortion expect average given certain conditions e g know lower bound distortion metric l space log n bourgain result expect see average given set distances assuming properties metric space known sort geometry embeddings see resulting embeddings papers talk questions distance preserving spaces e g l _infinity instead l thanks,"['literature', 'embeddings', 'metric', 'space', 'l', 'spacecurrently', 'trying', 'find', 'theory', 'papers', 'metric', 'embeddings', 'namely', 'metric', 'space', 'l', 'space', 'embeddings', 'able', 'find', 'literature', 'distortion', 'albeit', 'results', 'old', 'http', 'given', 'embedding', 'l', 'space', 'much', 'distortion', 'expect', 'average', 'given', 'certain', 'conditions', 'e', 'g', 'know', 'lower', 'bound', 'distortion', 'metric', 'l', 'space', 'log', 'n', 'bourgain', 'result', 'expect', 'see', 'average', 'given', 'set', 'distances', 'assuming', 'properties', 'metric', 'space', 'known', 'sort', 'geometry', 'embeddings', 'see', 'resulting', 'embeddings', 'papers', 'talk', 'questions', 'distance', 'preserving', 'spaces', 'e', 'g', 'l', '_infinity', 'instead', 'l', 'thanks']","['literatur', 'embed', 'metric', 'space', 'l', 'spacecurr', 'tri', 'find', 'theori', 'paper', 'metric', 'embed', 'name', 'metric', 'space', 'l', 'space', 'embed', 'abl', 'find', 'literatur', 'distort', 'albeit', 'result', 'old', 'http', 'given', 'embed', 'l', 'space', 'much', 'distort', 'expect', 'averag', 'given', 'certain', 'condit', 'e', 'g', 'know', 'lower', 'bound', 'distort', 'metric', 'l', 'space', 'log', 'n', 'bourgain', 'result', 'expect', 'see', 'averag', 'given', 'set', 'distanc', 'assum', 'properti', 'metric', 'space', 'known', 'sort', 'geometri', 'embed', 'see', 'result', 'embed', 'paper', 'talk', 'question', 'distanc', 'preserv', 'space', 'e', 'g', 'l', '_infin', 'instead', 'l', 'thank']"
116,125,125,Meddhouib10,w6uuhw,[R] CHOOSING THE ELEMENTS OF AN Epoch,"Hello,
So I have been looking for a way to actively choose the elements of an epoch.  

Let me explain : I noticed that almost all ML learning models learn faster on some elements than other in the dataset they are trained on. It can be caused by the fact that these elements are easy to learn from or that there are many similar elements in the training set which makes their contribution to the total loss greater than isolated elements.  

A naive method to deal with this is to duplicate(many time if needed) the elements according the their loss in the previous epoch. But a drawback is that we may end duplicating badly annotated elements.  

So is there any research done on this area ?
Thanks !",5,4,2022-07-24 15:46:56, r  choosing the elements of an epoch,hello so i have been looking for a way to actively choose the elements of an epoch   let me explain   i noticed that almost all ml learning models learn faster on some elements than other in the dataset they are trained on  it can be caused by the fact that these elements are easy to learn from or that there are many similar elements in the training set which makes their contribution to the total loss greater than isolated elements   a naive method to deal with this is to duplicate many time if needed  the elements according the their loss in the previous epoch  but a drawback is that we may end duplicating badly annotated elements   so is there any research done on this area  thanks  ,hello looking way actively choose elements epoch let explain noticed almost ml learning models learn faster elements dataset trained caused fact elements easy learn many similar elements training set makes contribution total loss greater isolated elements naive method deal duplicate many time needed elements according loss previous epoch drawback may end duplicating badly annotated elements research done area thanks,r choosing elements epoch,r choosing elements epochhello looking way actively choose elements epoch let explain noticed almost ml learning models learn faster elements dataset trained caused fact elements easy learn many similar elements training set makes contribution total loss greater isolated elements naive method deal duplicate many time needed elements according loss previous epoch drawback may end duplicating badly annotated elements research done area thanks,"['r', 'choosing', 'elements', 'epochhello', 'looking', 'way', 'actively', 'choose', 'elements', 'epoch', 'let', 'explain', 'noticed', 'almost', 'ml', 'learning', 'models', 'learn', 'faster', 'elements', 'dataset', 'trained', 'caused', 'fact', 'elements', 'easy', 'learn', 'many', 'similar', 'elements', 'training', 'set', 'makes', 'contribution', 'total', 'loss', 'greater', 'isolated', 'elements', 'naive', 'method', 'deal', 'duplicate', 'many', 'time', 'needed', 'elements', 'according', 'loss', 'previous', 'epoch', 'drawback', 'may', 'end', 'duplicating', 'badly', 'annotated', 'elements', 'research', 'done', 'area', 'thanks']","['r', 'choos', 'element', 'epochhello', 'look', 'way', 'activ', 'choos', 'element', 'epoch', 'let', 'explain', 'notic', 'almost', 'ml', 'learn', 'model', 'learn', 'faster', 'element', 'dataset', 'train', 'caus', 'fact', 'element', 'easi', 'learn', 'mani', 'similar', 'element', 'train', 'set', 'make', 'contribut', 'total', 'loss', 'greater', 'isol', 'element', 'naiv', 'method', 'deal', 'duplic', 'mani', 'time', 'need', 'element', 'accord', 'loss', 'previou', 'epoch', 'drawback', 'may', 'end', 'duplic', 'badli', 'annot', 'element', 'research', 'done', 'area', 'thank']"
117,127,127,IllustriousCicada603,w6xlnv,[D] Modify a transformer to work like a Generative Adversarial Network for text.,"Hello, I am working with a transformer language model. If I add an additional linear head to this architecture in a way in which it takes the output of the decoder and tries to evaluate wether it is the decoded or real response, can we somehow use that as a loss to emulate a generative adversarial model?",5,0,2022-07-24 18:01:40, d  modify a transformer to work like a generative adversarial network for text ,hello  i am working with a transformer language model  if i add an additional linear head to this architecture in a way in which it takes the output of the decoder and tries to evaluate wether it is the decoded or real response  can we somehow use that as a loss to emulate a generative adversarial model ,hello working transformer language model additional linear head architecture way takes output decoder tries evaluate wether decoded real response somehow use loss emulate generative adversarial model,modify transformer work like generative adversarial network text,modify transformer work like generative adversarial network texthello working transformer language model additional linear head architecture way takes output decoder tries evaluate wether decoded real response somehow use loss emulate generative adversarial model,"['modify', 'transformer', 'work', 'like', 'generative', 'adversarial', 'network', 'texthello', 'working', 'transformer', 'language', 'model', 'additional', 'linear', 'head', 'architecture', 'way', 'takes', 'output', 'decoder', 'tries', 'evaluate', 'wether', 'decoded', 'real', 'response', 'somehow', 'use', 'loss', 'emulate', 'generative', 'adversarial', 'model']","['modifi', 'transform', 'work', 'like', 'gener', 'adversari', 'network', 'texthello', 'work', 'transform', 'languag', 'model', 'addit', 'linear', 'head', 'architectur', 'way', 'take', 'output', 'decod', 'tri', 'evalu', 'wether', 'decod', 'real', 'respons', 'somehow', 'use', 'loss', 'emul', 'gener', 'adversari', 'model']"
118,128,128,Singularian2501,w6fmuo,[R] CodeT: Code Generation with Generated Tests ( 20+% improvement over previous state-of-the-art ) - Microsoft 2022,"Paper: [https://arxiv.org/abs/2207.10397#microsoft](https://arxiv.org/abs/2207.10397#microsoft)

Abstract:

>Given a programming problem, pre-trained language models such as Codex have demonstrated the ability to generate multiple different code solutions via sampling. However, selecting a correct or best solution from those samples still remains a challenge. While an easy way to verify the correctness of a code solution is through executing test cases, producing high-quality test cases is prohibitively expensive. In this paper, we explore the use of pre-trained language models to automatically generate test cases, calling our method CodeT: Code generation with generated Tests. CodeT executes the code solutions using the generated test cases, and then chooses the best solution based on a dual execution agreement with both the generated test cases and other generated solutions. We evaluate CodeT on five different pre-trained models with both HumanEval and MBPP benchmarks. **Extensive experimental results demonstrate CodeT can achieve significant, consistent, and surprising improvements over previous methods.** **For example, CodeT improves the pass@1 on HumanEval to 65.8%, an increase of absolute 18.8% on the code-davinci-002 model, and an absolute 20+% improvement over previous state-of-the-art results.**       

https://preview.redd.it/2i43j1mc5ed91.jpg?width=1205&format=pjpg&auto=webp&s=5d2746907d49da95da2d524ace0886c740a8072d

https://preview.redd.it/sl2vtflc5ed91.jpg?width=1228&format=pjpg&auto=webp&s=d9329a1320781477ecf85e5a1a6c3678995786b3

https://preview.redd.it/u5iho5mc5ed91.jpg?width=1189&format=pjpg&auto=webp&s=3f1e2f5d0f9338869bf8283db41e793e027754f3",2,18,2022-07-24 01:12:51, r  codet  code generation with generated tests      improvement over previous state of the art     microsoft ,paper   https abstract  given a programming problem  pre trained language models such as codex have demonstrated the ability to generate multiple different code solutions via sampling  however  selecting a correct or best solution from those samples still remains a challenge  while an easy way to verify the correctness of a code solution is through executing test cases  producing high quality test cases is prohibitively expensive  in this paper  we explore the use of pre trained language models to automatically generate test cases  calling our method codet  code generation with generated tests  codet executes the code solutions using the generated test cases  and then chooses the best solution based on a dual execution agreement with both the generated test cases and other generated solutions  we evaluate codet on five different pre trained models with both humaneval and mbpp benchmarks    extensive experimental results demonstrate codet can achieve significant  consistent  and surprising improvements over previous methods      for example  codet improves the pass  on humaneval to     an increase of absolute    on the code davinci  model  and an absolute    improvement over previous state of the art results          https https https   preview redd it uihomced jpg width  format pjpg auto webp s fefdfbfdbeef,paper https abstract given programming problem pre trained language models codex demonstrated ability generate multiple different code solutions via sampling however selecting correct best solution samples still remains challenge easy way verify correctness code solution executing test cases producing high quality test cases prohibitively expensive paper explore use pre trained language models automatically generate test cases calling method codet code generation generated tests codet executes code solutions using generated test cases chooses best solution based dual execution agreement generated test cases generated solutions evaluate codet five different pre trained models humaneval mbpp benchmarks extensive experimental results demonstrate codet achieve significant consistent surprising improvements previous methods example codet improves pass humaneval increase absolute code davinci model absolute improvement previous state art results https https https preview redd uihomced jpg width format pjpg auto webp fefdfbfdbeef,r codet code generation generated tests improvement previous state art microsoft,r codet code generation generated tests improvement previous state art microsoftpaper https abstract given programming problem pre trained language models codex demonstrated ability generate multiple different code solutions via sampling however selecting correct best solution samples still remains challenge easy way verify correctness code solution executing test cases producing high quality test cases prohibitively expensive paper explore use pre trained language models automatically generate test cases calling method codet code generation generated tests codet executes code solutions using generated test cases chooses best solution based dual execution agreement generated test cases generated solutions evaluate codet five different pre trained models humaneval mbpp benchmarks extensive experimental results demonstrate codet achieve significant consistent surprising improvements previous methods example codet improves pass humaneval increase absolute code davinci model absolute improvement previous state art results https https https preview redd uihomced jpg width format pjpg auto webp fefdfbfdbeef,"['r', 'codet', 'code', 'generation', 'generated', 'tests', 'improvement', 'previous', 'state', 'art', 'microsoftpaper', 'https', 'abstract', 'given', 'programming', 'problem', 'pre', 'trained', 'language', 'models', 'codex', 'demonstrated', 'ability', 'generate', 'multiple', 'different', 'code', 'solutions', 'via', 'sampling', 'however', 'selecting', 'correct', 'best', 'solution', 'samples', 'still', 'remains', 'challenge', 'easy', 'way', 'verify', 'correctness', 'code', 'solution', 'executing', 'test', 'cases', 'producing', 'high', 'quality', 'test', 'cases', 'prohibitively', 'expensive', 'paper', 'explore', 'use', 'pre', 'trained', 'language', 'models', 'automatically', 'generate', 'test', 'cases', 'calling', 'method', 'codet', 'code', 'generation', 'generated', 'tests', 'codet', 'executes', 'code', 'solutions', 'using', 'generated', 'test', 'cases', 'chooses', 'best', 'solution', 'based', 'dual', 'execution', 'agreement', 'generated', 'test', 'cases', 'generated', 'solutions', 'evaluate', 'codet', 'five', 'different', 'pre', 'trained', 'models', 'humaneval', 'mbpp', 'benchmarks', 'extensive', 'experimental', 'results', 'demonstrate', 'codet', 'achieve', 'significant', 'consistent', 'surprising', 'improvements', 'previous', 'methods', 'example', 'codet', 'improves', 'pass', 'humaneval', 'increase', 'absolute', 'code', 'davinci', 'model', 'absolute', 'improvement', 'previous', 'state', 'art', 'results', 'https', 'https', 'https', 'preview', 'redd', 'uihomced', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'fefdfbfdbeef']","['r', 'codet', 'code', 'gener', 'gener', 'test', 'improv', 'previou', 'state', 'art', 'microsoftpap', 'http', 'abstract', 'given', 'program', 'problem', 'pre', 'train', 'languag', 'model', 'codex', 'demonstr', 'abil', 'gener', 'multipl', 'differ', 'code', 'solut', 'via', 'sampl', 'howev', 'select', 'correct', 'best', 'solut', 'sampl', 'still', 'remain', 'challeng', 'easi', 'way', 'verifi', 'correct', 'code', 'solut', 'execut', 'test', 'case', 'produc', 'high', 'qualiti', 'test', 'case', 'prohibit', 'expens', 'paper', 'explor', 'use', 'pre', 'train', 'languag', 'model', 'automat', 'gener', 'test', 'case', 'call', 'method', 'codet', 'code', 'gener', 'gener', 'test', 'codet', 'execut', 'code', 'solut', 'use', 'gener', 'test', 'case', 'choos', 'best', 'solut', 'base', 'dual', 'execut', 'agreement', 'gener', 'test', 'case', 'gener', 'solut', 'evalu', 'codet', 'five', 'differ', 'pre', 'train', 'model', 'humanev', 'mbpp', 'benchmark', 'extens', 'experiment', 'result', 'demonstr', 'codet', 'achiev', 'signific', 'consist', 'surpris', 'improv', 'previou', 'method', 'exampl', 'codet', 'improv', 'pass', 'humanev', 'increas', 'absolut', 'code', 'davinci', 'model', 'absolut', 'improv', 'previou', 'state', 'art', 'result', 'http', 'http', 'http', 'preview', 'redd', 'uihomc', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'fefdfbfdbeef']"
119,129,129,annabelle_croft98,w6v3gz,[D] Multi-objective model training,"I would like to have a model output the best move set based on a changing reward function.

The reward function is a balance between two objectives but the weights between those objectives are undecided.

What I was thinking of doing is training a model like so:

Model inputs = \[actual\_inputs, weight\_1, weight\_2\]

Model outputs = actions

objective\_1 = f1(actions)

objective\_2 = f2(actions)

Reward = min(weight\_1 \* objective\_1, weight\_2 \* objective\_2) + 0.05 \* (weight\_1 \* objective\_1 + weight\_2 \* objective\_2).

This way it will receive a high reward if the balance between the two objectives is as dictated by the weights.

However, I have tried out this method and it doesn't seem to output the optimal actions. Is there a better approach to what I'm trying to do?

Thanks for any help you can give,

Belle",6,1,2022-07-24 16:00:27, d  multi objective model training,i would like to have a model output the best move set based on a changing reward function the reward function is a balance between two objectives but the weights between those objectives are undecided what i was thinking of doing is training a model like so model inputs     actual _inputs  weight _  weight _  model outputs   actionsobjective _   f actions objective _   f actions reward   min weight _    objective _  weight _    objective _          weight _    objective _   weight _    objective _  this way it will receive a high reward if the balance between the two objectives is as dictated by the weights however  i have tried out this method and it doesn t seem to output the optimal actions  is there a better approach to what i m trying to do thanks for any help you can give belle,would like model output best move set based changing reward function reward function balance two objectives weights objectives undecided thinking training model like model inputs actual _inputs weight _ weight _ model outputs actionsobjective _ f actions objective _ f actions reward min weight _ objective _ weight _ objective _ weight _ objective _ weight _ objective _ way receive high reward balance two objectives dictated weights however tried method seem output optimal actions better approach trying thanks help give belle,multi objective model training,multi objective model trainingwould like model output best move set based changing reward function reward function balance two objectives weights objectives undecided thinking training model like model inputs actual _inputs weight _ weight _ model outputs actionsobjective _ f actions objective _ f actions reward min weight _ objective _ weight _ objective _ weight _ objective _ weight _ objective _ way receive high reward balance two objectives dictated weights however tried method seem output optimal actions better approach trying thanks help give belle,"['multi', 'objective', 'model', 'trainingwould', 'like', 'model', 'output', 'best', 'move', 'set', 'based', 'changing', 'reward', 'function', 'reward', 'function', 'balance', 'two', 'objectives', 'weights', 'objectives', 'undecided', 'thinking', 'training', 'model', 'like', 'model', 'inputs', 'actual', '_inputs', 'weight', '_', 'weight', '_', 'model', 'outputs', 'actionsobjective', '_', 'f', 'actions', 'objective', '_', 'f', 'actions', 'reward', 'min', 'weight', '_', 'objective', '_', 'weight', '_', 'objective', '_', 'weight', '_', 'objective', '_', 'weight', '_', 'objective', '_', 'way', 'receive', 'high', 'reward', 'balance', 'two', 'objectives', 'dictated', 'weights', 'however', 'tried', 'method', 'seem', 'output', 'optimal', 'actions', 'better', 'approach', 'trying', 'thanks', 'help', 'give', 'belle']","['multi', 'object', 'model', 'trainingwould', 'like', 'model', 'output', 'best', 'move', 'set', 'base', 'chang', 'reward', 'function', 'reward', 'function', 'balanc', 'two', 'object', 'weight', 'object', 'undecid', 'think', 'train', 'model', 'like', 'model', 'input', 'actual', '_input', 'weight', '_', 'weight', '_', 'model', 'output', 'actionsobject', '_', 'f', 'action', 'object', '_', 'f', 'action', 'reward', 'min', 'weight', '_', 'object', '_', 'weight', '_', 'object', '_', 'weight', '_', 'object', '_', 'weight', '_', 'object', '_', 'way', 'receiv', 'high', 'reward', 'balanc', 'two', 'object', 'dictat', 'weight', 'howev', 'tri', 'method', 'seem', 'output', 'optim', 'action', 'better', 'approach', 'tri', 'thank', 'help', 'give', 'bell']"
120,130,130,carubia,w68dep,[D] Under-the-radar companies doing important work in AI/ML,"Being asked recently by my college student friends which companies to join to work on AI/machine learning.  I do recommend common suspects like Google (Brain, Research), FAIR, and a few others, but interested in broadening this list with some maybe underappreciated or less-known/under-the-radar companies that may become the next Google, Meta of AI. The ones working on some of the most important technologies in AI and with a strong team on the tech side to learn from.

Would appreciate any leads. 

Can be any stage from a small startup to more mature, but please mention why you think they fit “important technology” and “strong team/leader” definition.

Also think having such discussion thread will be helpful to everyone looking for such companies.",29,43,2022-07-23 19:45:00, d  under the radar companies doing important work in ai ml,being asked recently by my college student friends which companies to join to work on ai machine learning   i do recommend common suspects like google  brain  research   fair  and a few others  but interested in broadening this list with some maybe underappreciated or less known under the radar companies that may become the next google  meta of ai  the ones working on some of the most important technologies in ai and with a strong team on the tech side to learn from would appreciate any leads  can be any stage from a small startup to more mature  but please mention why you think they fit  important technology  and  strong team leader  definition also think having such discussion thread will be helpful to everyone looking for such companies ,asked recently college student friends companies join work ai machine learning recommend common suspects like google brain research fair others interested broadening maybe underappreciated less known radar companies may become next google meta ai ones working important technologies ai strong team tech side learn would appreciate leads stage small startup mature please mention think fit important technology strong team leader definition also think discussion thread helpful everyone looking companies,radar companies important work ai ml,radar companies important work ai mlasked recently college student friends companies join work ai machine learning recommend common suspects like google brain research fair others interested broadening maybe underappreciated less known radar companies may become next google meta ai ones working important technologies ai strong team tech side learn would appreciate leads stage small startup mature please mention think fit important technology strong team leader definition also think discussion thread helpful everyone looking companies,"['radar', 'companies', 'important', 'work', 'ai', 'mlasked', 'recently', 'college', 'student', 'friends', 'companies', 'join', 'work', 'ai', 'machine', 'learning', 'recommend', 'common', 'suspects', 'like', 'google', 'brain', 'research', 'fair', 'others', 'interested', 'broadening', 'maybe', 'underappreciated', 'less', 'known', 'radar', 'companies', 'may', 'become', 'next', 'google', 'meta', 'ai', 'ones', 'working', 'important', 'technologies', 'ai', 'strong', 'team', 'tech', 'side', 'learn', 'would', 'appreciate', 'leads', 'stage', 'small', 'startup', 'mature', 'please', 'mention', 'think', 'fit', 'important', 'technology', 'strong', 'team', 'leader', 'definition', 'also', 'think', 'discussion', 'thread', 'helpful', 'everyone', 'looking', 'companies']","['radar', 'compani', 'import', 'work', 'ai', 'mlask', 'recent', 'colleg', 'student', 'friend', 'compani', 'join', 'work', 'ai', 'machin', 'learn', 'recommend', 'common', 'suspect', 'like', 'googl', 'brain', 'research', 'fair', 'other', 'interest', 'broaden', 'mayb', 'underappreci', 'less', 'known', 'radar', 'compani', 'may', 'becom', 'next', 'googl', 'meta', 'ai', 'one', 'work', 'import', 'technolog', 'ai', 'strong', 'team', 'tech', 'side', 'learn', 'would', 'appreci', 'lead', 'stage', 'small', 'startup', 'matur', 'pleas', 'mention', 'think', 'fit', 'import', 'technolog', 'strong', 'team', 'leader', 'definit', 'also', 'think', 'discuss', 'thread', 'help', 'everyon', 'look', 'compani']"
121,132,132,irodeknight,w6nx6h,Optimal Deep Learning model size for embedded system and upcoming question(s) about hardware on embedded system [D],"Hi, I am currently reading up on RetinaNet model. I'm trying to make a palm oil fruit object detection and classification model by using [RetinaNet](https://github.com/fizyr/keras-retinanet). The backbone that I'm using is ResNet50 and my input image dimension is 1280 x 720.

After training and evaluating, I've made my inference model from the training model and and its size is about 140MB.

I also Googled another model, which is YOLOv3 tiny and found out that its size is supposed to be around 35MB.

If I were to integrate deep learning model to an embedded system, what is the optimal size for it? I assume since embedded model has very limited resource, the inference model is supposed to be small, but I'm not sure what is considered small and what is considered to be large (what's the range here?)

Another question for the embedded system:  
I'm training the model with my GTX 1080 8GB. What does the embedded system use for detecting and classifying with the inference model? Does it also require high performance GPU?",5,3,2022-07-24 08:17:56,optimal deep learning model size for embedded system and upcoming question s  about hardware on embedded system  d ,hi  i am currently reading up on retinanet model  i m trying to make a palm oil fruit object detection and classification model by using  retinanet  https after training and evaluating  i ve made my inference model from the training model and and its size is about mb i also googled another model  which is yolov tiny and found out that its size is supposed to be around mb if i were to integrate deep learning model to an embedded system  what is the optimal size for it  i assume since embedded model has very limited resource  the inference model is supposed to be small  but i m not sure what is considered small and what is considered to be large  what s the range here  another question for the embedded system   i m training the model with my gtx  gb  what does the embedded system use for detecting and classifying with the inference model  does it also require high performance gpu ,hi currently reading retinanet model trying make palm oil fruit object detection classification model using retinanet https training evaluating made inference model training model size mb also googled another model yolov tiny found size supposed around mb integrate deep learning model embedded system optimal size assume since embedded model limited resource inference model supposed small sure considered small considered large range another question embedded system training model gtx gb embedded system use detecting classifying inference model also require high performance gpu,optimal deep learning model size embedded system upcoming question hardware embedded system,optimal deep learning model size embedded system upcoming question hardware embedded systemhi currently reading retinanet model trying make palm oil fruit object detection classification model using retinanet https training evaluating made inference model training model size mb also googled another model yolov tiny found size supposed around mb integrate deep learning model embedded system optimal size assume since embedded model limited resource inference model supposed small sure considered small considered large range another question embedded system training model gtx gb embedded system use detecting classifying inference model also require high performance gpu,"['optimal', 'deep', 'learning', 'model', 'size', 'embedded', 'system', 'upcoming', 'question', 'hardware', 'embedded', 'systemhi', 'currently', 'reading', 'retinanet', 'model', 'trying', 'make', 'palm', 'oil', 'fruit', 'object', 'detection', 'classification', 'model', 'using', 'retinanet', 'https', 'training', 'evaluating', 'made', 'inference', 'model', 'training', 'model', 'size', 'mb', 'also', 'googled', 'another', 'model', 'yolov', 'tiny', 'found', 'size', 'supposed', 'around', 'mb', 'integrate', 'deep', 'learning', 'model', 'embedded', 'system', 'optimal', 'size', 'assume', 'since', 'embedded', 'model', 'limited', 'resource', 'inference', 'model', 'supposed', 'small', 'sure', 'considered', 'small', 'considered', 'large', 'range', 'another', 'question', 'embedded', 'system', 'training', 'model', 'gtx', 'gb', 'embedded', 'system', 'use', 'detecting', 'classifying', 'inference', 'model', 'also', 'require', 'high', 'performance', 'gpu']","['optim', 'deep', 'learn', 'model', 'size', 'embed', 'system', 'upcom', 'question', 'hardwar', 'embed', 'systemhi', 'current', 'read', 'retinanet', 'model', 'tri', 'make', 'palm', 'oil', 'fruit', 'object', 'detect', 'classif', 'model', 'use', 'retinanet', 'http', 'train', 'evalu', 'made', 'infer', 'model', 'train', 'model', 'size', 'mb', 'also', 'googl', 'anoth', 'model', 'yolov', 'tini', 'found', 'size', 'suppos', 'around', 'mb', 'integr', 'deep', 'learn', 'model', 'embed', 'system', 'optim', 'size', 'assum', 'sinc', 'embed', 'model', 'limit', 'resourc', 'infer', 'model', 'suppos', 'small', 'sure', 'consid', 'small', 'consid', 'larg', 'rang', 'anoth', 'question', 'embed', 'system', 'train', 'model', 'gtx', 'gb', 'embed', 'system', 'use', 'detect', 'classifi', 'infer', 'model', 'also', 'requir', 'high', 'perform', 'gpu']"
122,133,133,vanilla-acc,w6el4b,[D] What are people here using to visualize gradient flow / distribution of activations in their models?,"What are the good tools for checking things like the following:

\- How fast the gradients for each layer in your model are updating (useful to see which layers are learning fast, which layers might not be learning fast)

\- Visualizing the stdev of activations / the magnitude of the weights

Other such things, which help give a high-level overview of how one's model is doing.",2,8,2022-07-24 00:25:52, d  what are people here using to visualize gradient flow   distribution of activations in their models ,what are the good tools for checking things like the following    how fast the gradients for each layer in your model are updating  useful to see which layers are learning fast  which layers might not be learning fast    visualizing the stdev of activations   the magnitude of the weightsother such things  which help give a high level overview of how one s model is doing ,good tools checking things like following fast gradients layer model updating useful see layers learning fast layers might learning fast visualizing stdev activations magnitude weightsother things help give high level overview one model,people using visualize gradient flow distribution activations models,people using visualize gradient flow distribution activations modelsgood tools checking things like following fast gradients layer model updating useful see layers learning fast layers might learning fast visualizing stdev activations magnitude weightsother things help give high level overview one model,"['people', 'using', 'visualize', 'gradient', 'flow', 'distribution', 'activations', 'modelsgood', 'tools', 'checking', 'things', 'like', 'following', 'fast', 'gradients', 'layer', 'model', 'updating', 'useful', 'see', 'layers', 'learning', 'fast', 'layers', 'might', 'learning', 'fast', 'visualizing', 'stdev', 'activations', 'magnitude', 'weightsother', 'things', 'help', 'give', 'high', 'level', 'overview', 'one', 'model']","['peopl', 'use', 'visual', 'gradient', 'flow', 'distribut', 'activ', 'modelsgood', 'tool', 'check', 'thing', 'like', 'follow', 'fast', 'gradient', 'layer', 'model', 'updat', 'use', 'see', 'layer', 'learn', 'fast', 'layer', 'might', 'learn', 'fast', 'visual', 'stdev', 'activ', 'magnitud', 'weightsoth', 'thing', 'help', 'give', 'high', 'level', 'overview', 'one', 'model']"
123,134,134,Vast-Sector-4008,w6gioa,[D] Looking for a particular machine learning PDF but I can't remember the name of it,This is a real shot in the dark but I'm still going to ask. I remember reading this PDF a few years ago and I think it was written by someone from Facebook and it was just a long numbered list of practical machine learning lessons for deploying a model in production. It was maybe 50 pages long or something like that. I remember it being really good and I wanted to find it again. Sorry this isn't a lot of information but the most vivid detail I remember is the numbered list of lessons and each lesson was about a paragraph long - I remember one of them was on train vs production data drift. Does this ring a bell for anyone? I really want to find it again.,2,5,2022-07-24 01:53:00, d  looking for a particular machine learning pdf but i can t remember the name of it,this is a real shot in the dark but i m still going to ask  i remember reading this pdf a few years ago and i think it was written by someone from facebook and it was just a long numbered list of practical machine learning lessons for deploying a model in production  it was maybe  pages long or something like that  i remember it being really good and i wanted to find it again  sorry this isn t a lot of information but the most vivid detail i remember is the numbered list of lessons and each lesson was about a paragraph long   i remember one of them was on train vs production data drift  does this ring a bell for anyone  i really want to find it again ,real shot dark still going ask remember reading pdf years ago think written someone facebook long numbered practical machine learning lessons deploying model production maybe pages long something like remember really good wanted find sorry lot information vivid detail remember numbered lessons lesson paragraph long remember one train vs production data drift ring bell anyone really want find,looking particular machine learning pdf remember name,looking particular machine learning pdf remember namereal shot dark still going ask remember reading pdf years ago think written someone facebook long numbered practical machine learning lessons deploying model production maybe pages long something like remember really good wanted find sorry lot information vivid detail remember numbered lessons lesson paragraph long remember one train vs production data drift ring bell anyone really want find,"['looking', 'particular', 'machine', 'learning', 'pdf', 'remember', 'namereal', 'shot', 'dark', 'still', 'going', 'ask', 'remember', 'reading', 'pdf', 'years', 'ago', 'think', 'written', 'someone', 'facebook', 'long', 'numbered', 'practical', 'machine', 'learning', 'lessons', 'deploying', 'model', 'production', 'maybe', 'pages', 'long', 'something', 'like', 'remember', 'really', 'good', 'wanted', 'find', 'sorry', 'lot', 'information', 'vivid', 'detail', 'remember', 'numbered', 'lessons', 'lesson', 'paragraph', 'long', 'remember', 'one', 'train', 'vs', 'production', 'data', 'drift', 'ring', 'bell', 'anyone', 'really', 'want', 'find']","['look', 'particular', 'machin', 'learn', 'pdf', 'rememb', 'namer', 'shot', 'dark', 'still', 'go', 'ask', 'rememb', 'read', 'pdf', 'year', 'ago', 'think', 'written', 'someon', 'facebook', 'long', 'number', 'practic', 'machin', 'learn', 'lesson', 'deploy', 'model', 'product', 'mayb', 'page', 'long', 'someth', 'like', 'rememb', 'realli', 'good', 'want', 'find', 'sorri', 'lot', 'inform', 'vivid', 'detail', 'rememb', 'number', 'lesson', 'lesson', 'paragraph', 'long', 'rememb', 'one', 'train', 'vs', 'product', 'data', 'drift', 'ring', 'bell', 'anyon', 'realli', 'want', 'find']"
124,136,136,GoochCommander,w63vti,[P] Built a hungry baby alarm,"[https://youtu.be/Lda1Sq8HRY4](https://youtu.be/Lda1Sq8HRY4)

I used a series of mostly out of the box models to build a hungry baby detection system to alert me when my baby is showing signs of hunger. The goal was to help w/ overnight sleep for me & my wife by me being able to wake up and feed the baby with a bottle before he cries and wakes my wife up.

I used [MediaPipe](https://google.github.io/mediapipe/solutions/face_mesh.html) and built my own classifier to recognize when my baby has a pacifier in his mouth. Let me know what you think on the ML stuff... not sure if there's a better approach I could have taken for pacifier rejection detection lol",6,18,2022-07-23 16:20:22, p  built a hungry baby alarm, https i used a series of mostly out of the box models to build a hungry baby detection system to alert me when my baby is showing signs of hunger  the goal was to help w  overnight sleep for me   my wife by me being able to wake up and feed the baby with a bottle before he cries and wakes my wife up i used  mediapipe  https   google github io mediapipe solutions face_mesh html  and built my own classifier to recognize when my baby has a pacifier in his mouth  let me know what you think on the ml stuff    not sure if there s a better approach i could have taken for pacifier rejection detection lol,https used series mostly box models build hungry baby detection system alert baby showing signs hunger goal help w overnight sleep wife able wake feed baby bottle cries wakes wife used mediapipe https google github io mediapipe solutions face_mesh html built classifier recognize baby pacifier mouth let know think ml stuff sure better approach could taken pacifier rejection detection lol,p built hungry baby alarm,p built hungry baby alarmhttps used series mostly box models build hungry baby detection system alert baby showing signs hunger goal help w overnight sleep wife able wake feed baby bottle cries wakes wife used mediapipe https google github io mediapipe solutions face_mesh html built classifier recognize baby pacifier mouth let know think ml stuff sure better approach could taken pacifier rejection detection lol,"['p', 'built', 'hungry', 'baby', 'alarmhttps', 'used', 'series', 'mostly', 'box', 'models', 'build', 'hungry', 'baby', 'detection', 'system', 'alert', 'baby', 'showing', 'signs', 'hunger', 'goal', 'help', 'w', 'overnight', 'sleep', 'wife', 'able', 'wake', 'feed', 'baby', 'bottle', 'cries', 'wakes', 'wife', 'used', 'mediapipe', 'https', 'google', 'github', 'io', 'mediapipe', 'solutions', 'face_mesh', 'html', 'built', 'classifier', 'recognize', 'baby', 'pacifier', 'mouth', 'let', 'know', 'think', 'ml', 'stuff', 'sure', 'better', 'approach', 'could', 'taken', 'pacifier', 'rejection', 'detection', 'lol']","['p', 'built', 'hungri', 'babi', 'alarmhttp', 'use', 'seri', 'mostli', 'box', 'model', 'build', 'hungri', 'babi', 'detect', 'system', 'alert', 'babi', 'show', 'sign', 'hunger', 'goal', 'help', 'w', 'overnight', 'sleep', 'wife', 'abl', 'wake', 'feed', 'babi', 'bottl', 'cri', 'wake', 'wife', 'use', 'mediapip', 'http', 'googl', 'github', 'io', 'mediapip', 'solut', 'face_mesh', 'html', 'built', 'classifi', 'recogn', 'babi', 'pacifi', 'mouth', 'let', 'know', 'think', 'ml', 'stuff', 'sure', 'better', 'approach', 'could', 'taken', 'pacifi', 'reject', 'detect', 'lol']"
125,137,137,MrAcurite,w649cx,[D] A brief note about GPU power consumption and clock speeds,"I just built myself a new machine with an RTX 3090, and have been training some models.

When I place no limits on the GPU, it consumes ~350 watts, averages ~80% utilization, and completes an epoch for the model and dataset I'm using in 50 seconds.

When I limit the GPU to 1500 MHz, it consumes ~220 watts, averages ~90% utilization, and completes an epoch for the same model and the same dataset in 54 seconds. So I save more than a third of my power consumption, stay much quieter and produce much less heat, and barely even sacrifice any speed. It's also more environmentally friendly, and increases the efficiency of and decreases the strain on my PSU. 

So, consider doing the same thing yourselves.

On my Ubuntu machine, I put the following into /etc/rc.local

    #!/bin/bash
    nvidia-smi -pm 1
    nvidia-smi -i 0 -pl 300
    nvidia-smi -i 0 -lgc 300,1500

To be honest, I have no idea what the second line really accomplishes, but the third line sets the power limit to 300 watts, and the fourth limits the GPU clocks to the range [300, 1500]. Almost certainly I could do a better, more sensible job if I was better with IT and systems, but my university education included Abstract Algebra and not how to not be an idiot with Linux, so there you go.",14,17,2022-07-23 16:38:49, d  a brief note about gpu power consumption and clock speeds,i just built myself a new machine with an rtx   and have been training some models when i place no limits on the gpu  it consumes   watts  averages    utilization  and completes an epoch for the model and dataset i m using in  seconds when i limit the gpu to  mhz  it consumes   watts  averages    utilization  and completes an epoch for the same model and the same dataset in  seconds  so i save more than a third of my power consumption  stay much quieter and produce much less heat  and barely even sacrifice any speed  it s also more environmentally friendly  and increases the efficiency of and decreases the strain on my psu  so  consider doing the same thing yourselves on my ubuntu machine  i put the following into  etc rc local       bin bash    nvidia smi  pm     nvidia smi  i   pl     nvidia smi  i   lgc  to be honest  i have no idea what the second line really accomplishes  but the third line sets the power limit to  watts  and the fourth limits the gpu clocks to the range       almost certainly i could do a better  more sensible job if i was better with it and systems  but my university education included abstract algebra and not how to not be an idiot with linux  so there you go ,built machine rtx training models place limits gpu consumes watts averages utilization completes epoch model dataset using seconds limit gpu mhz consumes watts averages utilization completes epoch model dataset seconds save third power consumption stay much quieter produce much less heat barely even sacrifice speed also environmentally friendly increases efficiency decreases strain psu consider thing ubuntu machine put following etc rc local bin bash nvidia smi pm nvidia smi pl nvidia smi lgc honest idea second line really accomplishes third line sets power limit watts fourth limits gpu clocks range almost certainly could better sensible job better systems university education included abstract algebra idiot linux go,brief note gpu power consumption clock speeds,brief note gpu power consumption clock speedsbuilt machine rtx training models place limits gpu consumes watts averages utilization completes epoch model dataset using seconds limit gpu mhz consumes watts averages utilization completes epoch model dataset seconds save third power consumption stay much quieter produce much less heat barely even sacrifice speed also environmentally friendly increases efficiency decreases strain psu consider thing ubuntu machine put following etc rc local bin bash nvidia smi pm nvidia smi pl nvidia smi lgc honest idea second line really accomplishes third line sets power limit watts fourth limits gpu clocks range almost certainly could better sensible job better systems university education included abstract algebra idiot linux go,"['brief', 'note', 'gpu', 'power', 'consumption', 'clock', 'speedsbuilt', 'machine', 'rtx', 'training', 'models', 'place', 'limits', 'gpu', 'consumes', 'watts', 'averages', 'utilization', 'completes', 'epoch', 'model', 'dataset', 'using', 'seconds', 'limit', 'gpu', 'mhz', 'consumes', 'watts', 'averages', 'utilization', 'completes', 'epoch', 'model', 'dataset', 'seconds', 'save', 'third', 'power', 'consumption', 'stay', 'much', 'quieter', 'produce', 'much', 'less', 'heat', 'barely', 'even', 'sacrifice', 'speed', 'also', 'environmentally', 'friendly', 'increases', 'efficiency', 'decreases', 'strain', 'psu', 'consider', 'thing', 'ubuntu', 'machine', 'put', 'following', 'etc', 'rc', 'local', 'bin', 'bash', 'nvidia', 'smi', 'pm', 'nvidia', 'smi', 'pl', 'nvidia', 'smi', 'lgc', 'honest', 'idea', 'second', 'line', 'really', 'accomplishes', 'third', 'line', 'sets', 'power', 'limit', 'watts', 'fourth', 'limits', 'gpu', 'clocks', 'range', 'almost', 'certainly', 'could', 'better', 'sensible', 'job', 'better', 'systems', 'university', 'education', 'included', 'abstract', 'algebra', 'idiot', 'linux', 'go']","['brief', 'note', 'gpu', 'power', 'consumpt', 'clock', 'speedsbuilt', 'machin', 'rtx', 'train', 'model', 'place', 'limit', 'gpu', 'consum', 'watt', 'averag', 'util', 'complet', 'epoch', 'model', 'dataset', 'use', 'second', 'limit', 'gpu', 'mhz', 'consum', 'watt', 'averag', 'util', 'complet', 'epoch', 'model', 'dataset', 'second', 'save', 'third', 'power', 'consumpt', 'stay', 'much', 'quieter', 'produc', 'much', 'less', 'heat', 'bare', 'even', 'sacrific', 'speed', 'also', 'environment', 'friendli', 'increas', 'effici', 'decreas', 'strain', 'psu', 'consid', 'thing', 'ubuntu', 'machin', 'put', 'follow', 'etc', 'rc', 'local', 'bin', 'bash', 'nvidia', 'smi', 'pm', 'nvidia', 'smi', 'pl', 'nvidia', 'smi', 'lgc', 'honest', 'idea', 'second', 'line', 'realli', 'accomplish', 'third', 'line', 'set', 'power', 'limit', 'watt', 'fourth', 'limit', 'gpu', 'clock', 'rang', 'almost', 'certainli', 'could', 'better', 'sensibl', 'job', 'better', 'system', 'univers', 'educ', 'includ', 'abstract', 'algebra', 'idiot', 'linux', 'go']"
126,138,138,Nspies13,w67b9s,[D] Detecting Dataset Shift: Getting Started,"
ICLR and others have highlighted a number of interesting methods for designing algorithms to be robust to dataset shift. However, I am interested in the simpler question of detecting whether such a shift has occurred. 

Can anyone recommend some materials on the fundamentals and/or SOTA approaches for detecting shifts in uni- and multivariate time series data?",2,8,2022-07-23 18:58:43, d  detecting dataset shift  getting started,iclr and others have highlighted a number of interesting methods for designing algorithms to be robust to dataset shift  however  i am interested in the simpler question of detecting whether such a shift has occurred  can anyone recommend some materials on the fundamentals and or sota approaches for detecting shifts in uni  and multivariate time series data ,iclr others highlighted number interesting methods designing algorithms robust dataset shift however interested simpler question detecting whether shift occurred anyone recommend materials fundamentals sota approaches detecting shifts uni multivariate time series data,detecting dataset shift getting started,detecting dataset shift getting startediclr others highlighted number interesting methods designing algorithms robust dataset shift however interested simpler question detecting whether shift occurred anyone recommend materials fundamentals sota approaches detecting shifts uni multivariate time series data,"['detecting', 'dataset', 'shift', 'getting', 'startediclr', 'others', 'highlighted', 'number', 'interesting', 'methods', 'designing', 'algorithms', 'robust', 'dataset', 'shift', 'however', 'interested', 'simpler', 'question', 'detecting', 'whether', 'shift', 'occurred', 'anyone', 'recommend', 'materials', 'fundamentals', 'sota', 'approaches', 'detecting', 'shifts', 'uni', 'multivariate', 'time', 'series', 'data']","['detect', 'dataset', 'shift', 'get', 'startediclr', 'other', 'highlight', 'number', 'interest', 'method', 'design', 'algorithm', 'robust', 'dataset', 'shift', 'howev', 'interest', 'simpler', 'question', 'detect', 'whether', 'shift', 'occur', 'anyon', 'recommend', 'materi', 'fundament', 'sota', 'approach', 'detect', 'shift', 'uni', 'multivari', 'time', 'seri', 'data']"
127,139,139,diedFindingAUsername,w6bptf,[D] LSTM or CNN or STT for wake word detection?,"I’m making my own voice assistant and rn I’m in the first phase - wake word detection. I am debating between 3 approaches as mentioned in the title. STT (speech to text) is probably the easiest but also will perform the worst (unless I can train a model to only listen to my voice maybe?).

For CNN I was also wondering what if I use transfer learning on a pre-existing model. 

Just curious how would you approach wake word detection",2,4,2022-07-23 22:13:46, d  lstm or cnn or stt for wake word detection ,i m making my own voice assistant and rn i m in the first phase   wake word detection  i am debating between  approaches as mentioned in the title  stt  speech to text  is probably the easiest but also will perform the worst  unless i can train a model to only listen to my voice maybe   for cnn i was also wondering what if i use transfer learning on a pre existing model  just curious how would you approach wake word detection,making voice assistant rn first phase wake word detection debating approaches mentioned title stt speech text probably easiest also perform worst unless train model listen voice maybe cnn also wondering use transfer learning pre existing model curious would approach wake word detection,lstm cnn stt wake word detection,lstm cnn stt wake word detectionmaking voice assistant rn first phase wake word detection debating approaches mentioned title stt speech text probably easiest also perform worst unless train model listen voice maybe cnn also wondering use transfer learning pre existing model curious would approach wake word detection,"['lstm', 'cnn', 'stt', 'wake', 'word', 'detectionmaking', 'voice', 'assistant', 'rn', 'first', 'phase', 'wake', 'word', 'detection', 'debating', 'approaches', 'mentioned', 'title', 'stt', 'speech', 'text', 'probably', 'easiest', 'also', 'perform', 'worst', 'unless', 'train', 'model', 'listen', 'voice', 'maybe', 'cnn', 'also', 'wondering', 'use', 'transfer', 'learning', 'pre', 'existing', 'model', 'curious', 'would', 'approach', 'wake', 'word', 'detection']","['lstm', 'cnn', 'stt', 'wake', 'word', 'detectionmak', 'voic', 'assist', 'rn', 'first', 'phase', 'wake', 'word', 'detect', 'debat', 'approach', 'mention', 'titl', 'stt', 'speech', 'text', 'probabl', 'easiest', 'also', 'perform', 'worst', 'unless', 'train', 'model', 'listen', 'voic', 'mayb', 'cnn', 'also', 'wonder', 'use', 'transfer', 'learn', 'pre', 'exist', 'model', 'curiou', 'would', 'approach', 'wake', 'word', 'detect']"
128,140,140,sunnyville04,w5zhoo,[D] What are the ethics and legality of using using non open-source images to train your model?,"For instance, if I use images from Google images to train an image generation model, and then sell the images that the trained model generates, would this be considered ethical or legal?
  
In this particular scenario, it's not like I'd be displaying the images from Google images anywhere, I'd just be using them to update the weights of my model, so the images themselves aren't stored or displayed anywhere.
  
Thanks.",68,12,2022-07-23 12:02:16, d  what are the ethics and legality of using using non open source images to train your model ,for instance  if i use images from google images to train an image generation model  and then sell the images that the trained model generates  would this be considered ethical or legal   in this particular scenario  it s not like i d be displaying the images from google images anywhere  i d just be using them to update the weights of my model  so the images themselves aren t stored or displayed anywhere   thanks ,instance use images google images train image generation model sell images trained model generates would considered ethical legal particular scenario like displaying images google images anywhere using update weights model images stored displayed anywhere thanks,ethics legality using using non open source images train model,ethics legality using using non open source images train modelinstance use images google images train image generation model sell images trained model generates would considered ethical legal particular scenario like displaying images google images anywhere using update weights model images stored displayed anywhere thanks,"['ethics', 'legality', 'using', 'using', 'non', 'open', 'source', 'images', 'train', 'modelinstance', 'use', 'images', 'google', 'images', 'train', 'image', 'generation', 'model', 'sell', 'images', 'trained', 'model', 'generates', 'would', 'considered', 'ethical', 'legal', 'particular', 'scenario', 'like', 'displaying', 'images', 'google', 'images', 'anywhere', 'using', 'update', 'weights', 'model', 'images', 'stored', 'displayed', 'anywhere', 'thanks']","['ethic', 'legal', 'use', 'use', 'non', 'open', 'sourc', 'imag', 'train', 'modelinst', 'use', 'imag', 'googl', 'imag', 'train', 'imag', 'gener', 'model', 'sell', 'imag', 'train', 'model', 'gener', 'would', 'consid', 'ethic', 'legal', 'particular', 'scenario', 'like', 'display', 'imag', 'googl', 'imag', 'anywher', 'use', 'updat', 'weight', 'model', 'imag', 'store', 'display', 'anywher', 'thank']"
129,141,141,C0R0NA_CHAN,w61umc,[R] What pre processing do I need to do on a video inorder to get my ML model to detect a particular scene/duration in the video?,"So as the title suggests, I want to build a ml model to detect a particular clip/duration of a video which contains any unnecessary info say brand promos or something like that. 
 One thing i thought of is to get the video transcript and train the model to detect where the brand promo exists and detect it. 
Another way i thought of is to extract and analyse audio from and train model to detect the brand promo using that?!

One last way  i could think of is to make a ml model which will predict where sponsored segments in videos occur solely from their frames using an encoder-decoder architecture.

The last one seems promising but will be very time and resource consuming when applying it practically.
Any suggestions to how should I approach this problem would be appreciated.


I'm not well versed at all in ML, i am trying to make a model to detect brand promo  in a video. I'm not able to figure out on which basis should I train my model.",2,4,2022-07-23 14:30:16, r  what pre processing do i need to do on a video inorder to get my ml model to detect a particular scene duration in the video ,so as the title suggests  i want to build a ml model to detect a particular clip duration of a video which contains any unnecessary info say brand promos or something like that   one thing i thought of is to get the video transcript and train the model to detect where the brand promo exists and detect it  another way i thought of is to extract and analyse audio from and train model to detect the brand promo using that  one last way  i could think of is to make a ml model which will predict where sponsored segments in videos occur solely from their frames using an encoder decoder architecture the last one seems promising but will be very time and resource consuming when applying it practically any suggestions to how should i approach this problem would be appreciated i m not well versed at all in ml  i am trying to make a model to detect brand promo  in a video  i m not able to figure out on which basis should i train my model ,title suggests want build ml model detect particular clip duration video contains unnecessary info say brand promos something like one thing thought get video transcript train model detect brand promo exists detect another way thought extract analyse audio train model detect brand promo using one last way could think make ml model predict sponsored segments videos occur solely frames using encoder decoder architecture last one seems promising time resource consuming applying practically suggestions approach problem would appreciated well versed ml trying make model detect brand promo video able figure basis train model,r pre processing need video inorder get ml model detect particular scene duration video,r pre processing need video inorder get ml model detect particular scene duration videotitle suggests want build ml model detect particular clip duration video contains unnecessary info say brand promos something like one thing thought get video transcript train model detect brand promo exists detect another way thought extract analyse audio train model detect brand promo using one last way could think make ml model predict sponsored segments videos occur solely frames using encoder decoder architecture last one seems promising time resource consuming applying practically suggestions approach problem would appreciated well versed ml trying make model detect brand promo video able figure basis train model,"['r', 'pre', 'processing', 'need', 'video', 'inorder', 'get', 'ml', 'model', 'detect', 'particular', 'scene', 'duration', 'videotitle', 'suggests', 'want', 'build', 'ml', 'model', 'detect', 'particular', 'clip', 'duration', 'video', 'contains', 'unnecessary', 'info', 'say', 'brand', 'promos', 'something', 'like', 'one', 'thing', 'thought', 'get', 'video', 'transcript', 'train', 'model', 'detect', 'brand', 'promo', 'exists', 'detect', 'another', 'way', 'thought', 'extract', 'analyse', 'audio', 'train', 'model', 'detect', 'brand', 'promo', 'using', 'one', 'last', 'way', 'could', 'think', 'make', 'ml', 'model', 'predict', 'sponsored', 'segments', 'videos', 'occur', 'solely', 'frames', 'using', 'encoder', 'decoder', 'architecture', 'last', 'one', 'seems', 'promising', 'time', 'resource', 'consuming', 'applying', 'practically', 'suggestions', 'approach', 'problem', 'would', 'appreciated', 'well', 'versed', 'ml', 'trying', 'make', 'model', 'detect', 'brand', 'promo', 'video', 'able', 'figure', 'basis', 'train', 'model']","['r', 'pre', 'process', 'need', 'video', 'inord', 'get', 'ml', 'model', 'detect', 'particular', 'scene', 'durat', 'videotitl', 'suggest', 'want', 'build', 'ml', 'model', 'detect', 'particular', 'clip', 'durat', 'video', 'contain', 'unnecessari', 'info', 'say', 'brand', 'promo', 'someth', 'like', 'one', 'thing', 'thought', 'get', 'video', 'transcript', 'train', 'model', 'detect', 'brand', 'promo', 'exist', 'detect', 'anoth', 'way', 'thought', 'extract', 'analys', 'audio', 'train', 'model', 'detect', 'brand', 'promo', 'use', 'one', 'last', 'way', 'could', 'think', 'make', 'ml', 'model', 'predict', 'sponsor', 'segment', 'video', 'occur', 'sole', 'frame', 'use', 'encod', 'decod', 'architectur', 'last', 'one', 'seem', 'promis', 'time', 'resourc', 'consum', 'appli', 'practic', 'suggest', 'approach', 'problem', 'would', 'appreci', 'well', 'vers', 'ml', 'tri', 'make', 'model', 'detect', 'brand', 'promo', 'video', 'abl', 'figur', 'basi', 'train', 'model']"
130,143,143,BB4evaTB12,w5feci,How Good is Hugging Face's BLOOM? Human Evaluation of Large Language Models [D],"Imagine that you're an engineer training a new LLM. It looks much better than existing state-of-the-art when you manually inspect examples, but it performs worse on academic benchmarks...

Unfortunately, this is common in the real world! Many academic evaluations have hidden flaws that render them misleading.

For example, here's a typical row from the HellaSwag benchmark, which presents a scenario and asks which continuation is most likely.

SCENARIO: **""Men are standing in a large green field playing lacrosse. People is around the field watching the game. Men""**

1. ""**are holding tshirts watching int lacrosse playing.**""
2. ""**are being interviewed in a podium in front of a large group and a gymnast is holding a microphone for the announcers.**""
3. ""**are running side to side of the ield playing lacrosse trying to score.**""
4. ""**are in a field running around playing lacrosse.**""

According to HellaSwag, Continuation #3 is best – but do you agree? What's wrong with #4? And those typos and grammatical issues (""People is around the field"", ""int lacrosse"") aren't copy-paste errors – they're in the dataset itself.

I wrote a blog post to explore BLOOM's capabilities in a more visceral, real-world fashion, running a human evaluation of its performance across 7 categories.

Blog post: [https://www.surgehq.ai/blog/how-good-is-hugging-faces-bloom-a-real-world-human-evaluation-of-language-models](https://www.surgehq.ai/blog/how-good-is-hugging-faces-bloom-a-real-world-human-evaluation-of-language-models)",28,124,2022-07-22 19:52:31,how good is hugging face s bloom  human evaluation of large language models  d ,imagine that you re an engineer training a new llm  it looks much better than existing state of the art when you manually inspect examples  but it performs worse on academic benchmarks   unfortunately  this is common in the real world  many academic evaluations have hidden flaws that render them misleading for example  here s a typical row from the hellaswag benchmark  which presents a scenario and asks which continuation is most likely scenario    men are standing in a large green field playing lacrosse  people is around the field watching the game  men      are holding tshirts watching int lacrosse playing       are being interviewed in a podium in front of a large group and a gymnast is holding a microphone for the announcers       are running side to side of the ield playing lacrosse trying to score       are in a field running around playing lacrosse   according to hellaswag  continuation   is best   but do you agree  what s wrong with    and those typos and grammatical issues  people is around the field  int lacrosse  aren t copy paste errors   they re in the dataset itself i wrote a blog post to explore bloom s capabilities in a more visceral  real world fashion  running a human evaluation of its performance across  categories blog post   https   www surgehq ai blog how good is hugging faces bloom a real world human evaluation of language models  https   www surgehq ai blog how good is hugging faces bloom a real world human evaluation of language models ,imagine engineer training llm looks much better existing state art manually inspect examples performs worse academic benchmarks unfortunately common real world many academic evaluations hidden flaws render misleading example typical row hellaswag benchmark presents scenario asks continuation likely scenario men standing large green field playing lacrosse people around field watching game men holding tshirts watching int lacrosse playing interviewed podium front large group gymnast holding microphone announcers running side side ield playing lacrosse trying score field running around playing lacrosse according hellaswag continuation best agree wrong typos grammatical issues people around field int lacrosse copy paste errors dataset wrote blog post explore bloom capabilities visceral real world fashion running human evaluation performance across categories blog post https www surgehq ai blog good hugging faces bloom real world human evaluation language models https www surgehq ai blog good hugging faces bloom real world human evaluation language models,good hugging face bloom human evaluation large language models,good hugging face bloom human evaluation large language modelsimagine engineer training llm looks much better existing state art manually inspect examples performs worse academic benchmarks unfortunately common real world many academic evaluations hidden flaws render misleading example typical row hellaswag benchmark presents scenario asks continuation likely scenario men standing large green field playing lacrosse people around field watching game men holding tshirts watching int lacrosse playing interviewed podium front large group gymnast holding microphone announcers running side side ield playing lacrosse trying score field running around playing lacrosse according hellaswag continuation best agree wrong typos grammatical issues people around field int lacrosse copy paste errors dataset wrote blog post explore bloom capabilities visceral real world fashion running human evaluation performance across categories blog post https www surgehq ai blog good hugging faces bloom real world human evaluation language models https www surgehq ai blog good hugging faces bloom real world human evaluation language models,"['good', 'hugging', 'face', 'bloom', 'human', 'evaluation', 'large', 'language', 'modelsimagine', 'engineer', 'training', 'llm', 'looks', 'much', 'better', 'existing', 'state', 'art', 'manually', 'inspect', 'examples', 'performs', 'worse', 'academic', 'benchmarks', 'unfortunately', 'common', 'real', 'world', 'many', 'academic', 'evaluations', 'hidden', 'flaws', 'render', 'misleading', 'example', 'typical', 'row', 'hellaswag', 'benchmark', 'presents', 'scenario', 'asks', 'continuation', 'likely', 'scenario', 'men', 'standing', 'large', 'green', 'field', 'playing', 'lacrosse', 'people', 'around', 'field', 'watching', 'game', 'men', 'holding', 'tshirts', 'watching', 'int', 'lacrosse', 'playing', 'interviewed', 'podium', 'front', 'large', 'group', 'gymnast', 'holding', 'microphone', 'announcers', 'running', 'side', 'side', 'ield', 'playing', 'lacrosse', 'trying', 'score', 'field', 'running', 'around', 'playing', 'lacrosse', 'according', 'hellaswag', 'continuation', 'best', 'agree', 'wrong', 'typos', 'grammatical', 'issues', 'people', 'around', 'field', 'int', 'lacrosse', 'copy', 'paste', 'errors', 'dataset', 'wrote', 'blog', 'post', 'explore', 'bloom', 'capabilities', 'visceral', 'real', 'world', 'fashion', 'running', 'human', 'evaluation', 'performance', 'across', 'categories', 'blog', 'post', 'https', 'www', 'surgehq', 'ai', 'blog', 'good', 'hugging', 'faces', 'bloom', 'real', 'world', 'human', 'evaluation', 'language', 'models', 'https', 'www', 'surgehq', 'ai', 'blog', 'good', 'hugging', 'faces', 'bloom', 'real', 'world', 'human', 'evaluation', 'language', 'models']","['good', 'hug', 'face', 'bloom', 'human', 'evalu', 'larg', 'languag', 'modelsimagin', 'engin', 'train', 'llm', 'look', 'much', 'better', 'exist', 'state', 'art', 'manual', 'inspect', 'exampl', 'perform', 'wors', 'academ', 'benchmark', 'unfortun', 'common', 'real', 'world', 'mani', 'academ', 'evalu', 'hidden', 'flaw', 'render', 'mislead', 'exampl', 'typic', 'row', 'hellaswag', 'benchmark', 'present', 'scenario', 'ask', 'continu', 'like', 'scenario', 'men', 'stand', 'larg', 'green', 'field', 'play', 'lacross', 'peopl', 'around', 'field', 'watch', 'game', 'men', 'hold', 'tshirt', 'watch', 'int', 'lacross', 'play', 'interview', 'podium', 'front', 'larg', 'group', 'gymnast', 'hold', 'microphon', 'announc', 'run', 'side', 'side', 'ield', 'play', 'lacross', 'tri', 'score', 'field', 'run', 'around', 'play', 'lacross', 'accord', 'hellaswag', 'continu', 'best', 'agre', 'wrong', 'typo', 'grammat', 'issu', 'peopl', 'around', 'field', 'int', 'lacross', 'copi', 'past', 'error', 'dataset', 'wrote', 'blog', 'post', 'explor', 'bloom', 'capabl', 'viscer', 'real', 'world', 'fashion', 'run', 'human', 'evalu', 'perform', 'across', 'categori', 'blog', 'post', 'http', 'www', 'surgehq', 'ai', 'blog', 'good', 'hug', 'face', 'bloom', 'real', 'world', 'human', 'evalu', 'languag', 'model', 'http', 'www', 'surgehq', 'ai', 'blog', 'good', 'hug', 'face', 'bloom', 'real', 'world', 'human', 'evalu', 'languag', 'model']"
131,144,144,minhrongcon2000,w64m46,[D] Question on the effect of bipatite matching on DETR's performance,Recently I reviewed the DETR algorithm and found out that the Hungarian algorithm for bipatite matching has really high cost (O(N^3 ) for the worst case). So can I ask about the intensity of O(N^3 ) on the overall performance of DETR? Is it minimal compared to the overall performance?,3,2,2022-07-23 16:56:11, d  question on the effect of bipatite matching on detr s performance,recently i reviewed the detr algorithm and found out that the hungarian algorithm for bipatite matching has really high cost  o n    for the worst case   so can i ask about the intensity of o n    on the overall performance of detr  is it minimal compared to the overall performance ,recently reviewed detr algorithm found hungarian algorithm bipatite matching really high cost n worst case ask intensity n overall performance detr minimal compared overall performance,question effect bipatite matching detr performance,question effect bipatite matching detr performancerecently reviewed detr algorithm found hungarian algorithm bipatite matching really high cost n worst case ask intensity n overall performance detr minimal compared overall performance,"['question', 'effect', 'bipatite', 'matching', 'detr', 'performancerecently', 'reviewed', 'detr', 'algorithm', 'found', 'hungarian', 'algorithm', 'bipatite', 'matching', 'really', 'high', 'cost', 'n', 'worst', 'case', 'ask', 'intensity', 'n', 'overall', 'performance', 'detr', 'minimal', 'compared', 'overall', 'performance']","['question', 'effect', 'bipatit', 'match', 'detr', 'performancerec', 'review', 'detr', 'algorithm', 'found', 'hungarian', 'algorithm', 'bipatit', 'match', 'realli', 'high', 'cost', 'n', 'worst', 'case', 'ask', 'intens', 'n', 'overal', 'perform', 'detr', 'minim', 'compar', 'overal', 'perform']"
132,145,145,maghton,w687ow,[D] Cyclegan: Discriminator loss close to 0 from the very beginning,"Hello, I'm using a CycleGAN to convert summer to winter images. While the generatorloss is still very high after 100 epochs a decrease can be seen. While on the ither hand the discriminator loss is almost zero from the very beginning.

Summer to winter generator loss & winter discriminator loss\]\[1\]

&#x200B;

The cycle consistency and identity loss look okayish I think.

\[Cycleloss summer, winter loss in the first row and identity summer winter loss in the second row\]\[2\]

&#x200B;

As can be seen in this image, the mountains get a purple tint and correct me if im wrong but does this result from the and discriminator loss? \[full cycled Image\]\[3\]

So far to improve the discriminatorloss I tired a few things:

\- adjust Adam optimizer value for discriminator and generator

\- added GaussianNoise to the samples before validation with the discriminator

Does anybody has an idea what else I could try to fix the discriminator loss.

Thank you in advance :)

&#x200B;

\[1\]: [https://i.stack.imgur.com/HRIVs.png](https://i.stack.imgur.com/HRIVs.png)

\[2\]: [https://i.stack.imgur.com/sYgda.png](https://i.stack.imgur.com/sYgda.png)

\[3\]: [https://i.stack.imgur.com/lRhvr.png](https://i.stack.imgur.com/lRhvr.png)",1,0,2022-07-23 19:37:50, d  cyclegan  discriminator loss close to  from the very beginning,hello  i m using a cyclegan to convert summer to winter images  while the generatorloss is still very high after  epochs a decrease can be seen  while on the ither hand the discriminator loss is almost zero from the very beginning summer to winter generator loss   winter discriminator loss        xb the cycle consistency and identity loss look okayish i think   cycleloss summer  winter loss in the first row and identity summer winter loss in the second row        xb as can be seen in this image  the mountains get a purple tint and correct me if im wrong but does this result from the and discriminator loss    full cycled image      so far to improve the discriminatorloss i tired a few things    adjust adam optimizer value for discriminator and generator   added gaussiannoise to the samples before validation with the discriminatordoes anybody has an idea what else i could try to fix the discriminator loss thank you in advance     xb        https        https        https   i stack imgur com lrhvr png  https   i stack imgur com lrhvr png ,hello using cyclegan convert summer winter images generatorloss still high epochs decrease seen ither hand discriminator loss almost zero beginning summer winter generator loss winter discriminator loss xb cycle consistency identity loss look okayish think cycleloss summer winter loss first row identity summer winter loss second row xb seen image mountains get purple tint correct im wrong result discriminator loss full cycled image far improve discriminatorloss tired things adjust adam optimizer value discriminator generator added gaussiannoise samples validation discriminatordoes anybody idea else could try fix discriminator loss thank advance xb https https https stack imgur com lrhvr png https stack imgur com lrhvr png,cyclegan discriminator loss close beginning,cyclegan discriminator loss close beginninghello using cyclegan convert summer winter images generatorloss still high epochs decrease seen ither hand discriminator loss almost zero beginning summer winter generator loss winter discriminator loss xb cycle consistency identity loss look okayish think cycleloss summer winter loss first row identity summer winter loss second row xb seen image mountains get purple tint correct im wrong result discriminator loss full cycled image far improve discriminatorloss tired things adjust adam optimizer value discriminator generator added gaussiannoise samples validation discriminatordoes anybody idea else could try fix discriminator loss thank advance xb https https https stack imgur com lrhvr png https stack imgur com lrhvr png,"['cyclegan', 'discriminator', 'loss', 'close', 'beginninghello', 'using', 'cyclegan', 'convert', 'summer', 'winter', 'images', 'generatorloss', 'still', 'high', 'epochs', 'decrease', 'seen', 'ither', 'hand', 'discriminator', 'loss', 'almost', 'zero', 'beginning', 'summer', 'winter', 'generator', 'loss', 'winter', 'discriminator', 'loss', 'xb', 'cycle', 'consistency', 'identity', 'loss', 'look', 'okayish', 'think', 'cycleloss', 'summer', 'winter', 'loss', 'first', 'row', 'identity', 'summer', 'winter', 'loss', 'second', 'row', 'xb', 'seen', 'image', 'mountains', 'get', 'purple', 'tint', 'correct', 'im', 'wrong', 'result', 'discriminator', 'loss', 'full', 'cycled', 'image', 'far', 'improve', 'discriminatorloss', 'tired', 'things', 'adjust', 'adam', 'optimizer', 'value', 'discriminator', 'generator', 'added', 'gaussiannoise', 'samples', 'validation', 'discriminatordoes', 'anybody', 'idea', 'else', 'could', 'try', 'fix', 'discriminator', 'loss', 'thank', 'advance', 'xb', 'https', 'https', 'https', 'stack', 'imgur', 'com', 'lrhvr', 'png', 'https', 'stack', 'imgur', 'com', 'lrhvr', 'png']","['cyclegan', 'discrimin', 'loss', 'close', 'beginninghello', 'use', 'cyclegan', 'convert', 'summer', 'winter', 'imag', 'generatorloss', 'still', 'high', 'epoch', 'decreas', 'seen', 'ither', 'hand', 'discrimin', 'loss', 'almost', 'zero', 'begin', 'summer', 'winter', 'gener', 'loss', 'winter', 'discrimin', 'loss', 'xb', 'cycl', 'consist', 'ident', 'loss', 'look', 'okayish', 'think', 'cycleloss', 'summer', 'winter', 'loss', 'first', 'row', 'ident', 'summer', 'winter', 'loss', 'second', 'row', 'xb', 'seen', 'imag', 'mountain', 'get', 'purpl', 'tint', 'correct', 'im', 'wrong', 'result', 'discrimin', 'loss', 'full', 'cycl', 'imag', 'far', 'improv', 'discriminatorloss', 'tire', 'thing', 'adjust', 'adam', 'optim', 'valu', 'discrimin', 'gener', 'ad', 'gaussiannois', 'sampl', 'valid', 'discriminatordo', 'anybodi', 'idea', 'els', 'could', 'tri', 'fix', 'discrimin', 'loss', 'thank', 'advanc', 'xb', 'http', 'http', 'http', 'stack', 'imgur', 'com', 'lrhvr', 'png', 'http', 'stack', 'imgur', 'com', 'lrhvr', 'png']"
133,146,146,NikhilArethiya,w680se,[D] Satellite Imagery of Clouds - Dataset,"I need a help, i am interested in this topic ""Detecting the clouds from satellite imagery - to detect the clouds, segregate the clouds from lands to focus only on the clouds and finally to detect clouds that are very denser, lesser, and so so"".

Please help me with finding the Cloud Imagery Dataset from Satellite. 
Thankyou.",6,1,2022-07-23 19:29:17, d  satellite imagery of clouds   dataset,i need a help  i am interested in this topic detecting the clouds from satellite imagery   to detect the clouds  segregate the clouds from lands to focus only on the clouds and finally to detect clouds that are very denser  lesser  and so so please help me with finding the cloud imagery dataset from satellite  thankyou ,need help interested topic detecting clouds satellite imagery detect clouds segregate clouds lands focus clouds finally detect clouds denser lesser please help finding cloud imagery dataset satellite thankyou,satellite imagery clouds dataset,satellite imagery clouds datasetneed help interested topic detecting clouds satellite imagery detect clouds segregate clouds lands focus clouds finally detect clouds denser lesser please help finding cloud imagery dataset satellite thankyou,"['satellite', 'imagery', 'clouds', 'datasetneed', 'help', 'interested', 'topic', 'detecting', 'clouds', 'satellite', 'imagery', 'detect', 'clouds', 'segregate', 'clouds', 'lands', 'focus', 'clouds', 'finally', 'detect', 'clouds', 'denser', 'lesser', 'please', 'help', 'finding', 'cloud', 'imagery', 'dataset', 'satellite', 'thankyou']","['satellit', 'imageri', 'cloud', 'datasetne', 'help', 'interest', 'topic', 'detect', 'cloud', 'satellit', 'imageri', 'detect', 'cloud', 'segreg', 'cloud', 'land', 'focu', 'cloud', 'final', 'detect', 'cloud', 'denser', 'lesser', 'pleas', 'help', 'find', 'cloud', 'imageri', 'dataset', 'satellit', 'thankyou']"
134,147,147,MasterScrat,w5e4we,[P] This Food Does Not Exist,"**2018 called, they want their StyleGANs back! 👴**

/u/da_mulle and me have trained StyleGAN2 models and released checkpoints and training code. We are exploring how to improve/scale up StyleGAN training, particularly when leveraging TPUs.

**🔗 https://nyx-ai.github.io/stylegan2-flax-tpu**

Cherry-picked samples:

[🍪 Cookies](https://user-images.githubusercontent.com/140592/179369671-32cf8c67-a3d5-43a4-a200-1ba91e736ae2.png)
/
[🍰 Cheesecakes](https://user-images.githubusercontent.com/140592/179959973-df75351d-db07-4ff9-8f9f-97334bab20a8.png)
/
[🍹 Cocktails](https://user-images.githubusercontent.com/140592/179956003-8db513d2-b0b1-4a1f-8f15-827b56bedb25.png)
/
[🍣 Sushis](https://user-images.githubusercontent.com/140592/179958220-45324fe7-90d8-49dd-94be-877b03201160.png)",6,56,2022-07-22 18:59:36, p  this food does not exist,   called  they want their stylegans back      u da_mulle and me have trained stylegan models and released checkpoints and training code  we are exploring how to improve scale up stylegan training  particularly when leveraging tpus     https cherry picked samples    cookies  https     cheesecakes  https     cocktails  https     sushis  https   user images githubusercontent com   fe d dd be b png ,called want stylegans back u da_mulle trained stylegan models released checkpoints training code exploring improve scale stylegan training particularly leveraging tpus https cherry picked samples cookies https cheesecakes https cocktails https sushis https user images githubusercontent com fe dd b png,p food exist,p food existcalled want stylegans back u da_mulle trained stylegan models released checkpoints training code exploring improve scale stylegan training particularly leveraging tpus https cherry picked samples cookies https cheesecakes https cocktails https sushis https user images githubusercontent com fe dd b png,"['p', 'food', 'existcalled', 'want', 'stylegans', 'back', 'u', 'da_mulle', 'trained', 'stylegan', 'models', 'released', 'checkpoints', 'training', 'code', 'exploring', 'improve', 'scale', 'stylegan', 'training', 'particularly', 'leveraging', 'tpus', 'https', 'cherry', 'picked', 'samples', 'cookies', 'https', 'cheesecakes', 'https', 'cocktails', 'https', 'sushis', 'https', 'user', 'images', 'githubusercontent', 'com', 'fe', 'dd', 'b', 'png']","['p', 'food', 'existcal', 'want', 'stylegan', 'back', 'u', 'da_mul', 'train', 'stylegan', 'model', 'releas', 'checkpoint', 'train', 'code', 'explor', 'improv', 'scale', 'stylegan', 'train', 'particularli', 'leverag', 'tpu', 'http', 'cherri', 'pick', 'sampl', 'cooki', 'http', 'cheesecak', 'http', 'cocktail', 'http', 'sushi', 'http', 'user', 'imag', 'githubusercont', 'com', 'fe', 'dd', 'b', 'png']"
135,148,148,AICoffeeBreak,w5xza5,[D] Paper Explained – Machine Translation for the next 1000 languages,"[https://youtu.be/1gHUiNLYa20](https://youtu.be/1gHUiNLYa20)

This video explains and summarizes the 57 pages long ""Building Machine Translation Systems for the Next Thousand Languages."" paper from Google Research. It goes into the data collection, modelling processes and a bit into the results.

Paper link:  [https://arxiv.org/abs/2205.03983](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbXkwZkZ5M3lXaVhrR1dwQk1XTHpSSWJkbW5aUXxBQ3Jtc0tuY21hTVZyY0NSWWZjVC1haHkxbmFNVlBNRHY1ZlZndUpHaEQyZmE0MEFaTjNEai1vQVVSZFZtSVdqNTRraEV0VVhoMXE0TnFZVXplSHE3dGJURFdlT0NSNjFmXzNyQ3hmY3V6RGsyLXpyM0ZuUmduVQ&q=https%3A%2F%2Farxiv.org%2Fabs%2F2205.03983&v=1gHUiNLYa20) 

Outline:

00:00 Machine translation for a 1000 languages

00:42 Weights&Biases (Sponsor)

02:00 Problems with many languages

04:15 Collecting data for 1k languages

11:46 Building MT models

14:13 Results on a thousand languages",1,4,2022-07-23 10:27:46, d  paper explained   machine translation for the next  languages, https this video explains and summarizes the  pages long building machine translation systems for the next thousand languages  paper from google research  it goes into the data collection  modelling processes and a bit into the results paper link    https outline   machine translation for a  languages  weights biases  sponsor   problems with many languages  collecting data for k languages  building mt models  results on a thousand languages,https video explains summarizes pages long building machine translation systems next thousand languages paper google research goes data collection modelling processes bit results paper link https outline machine translation languages weights biases sponsor problems many languages collecting data k languages building mt models results thousand languages,paper explained machine translation next languages,paper explained machine translation next languageshttps video explains summarizes pages long building machine translation systems next thousand languages paper google research goes data collection modelling processes bit results paper link https outline machine translation languages weights biases sponsor problems many languages collecting data k languages building mt models results thousand languages,"['paper', 'explained', 'machine', 'translation', 'next', 'languageshttps', 'video', 'explains', 'summarizes', 'pages', 'long', 'building', 'machine', 'translation', 'systems', 'next', 'thousand', 'languages', 'paper', 'google', 'research', 'goes', 'data', 'collection', 'modelling', 'processes', 'bit', 'results', 'paper', 'link', 'https', 'outline', 'machine', 'translation', 'languages', 'weights', 'biases', 'sponsor', 'problems', 'many', 'languages', 'collecting', 'data', 'k', 'languages', 'building', 'mt', 'models', 'results', 'thousand', 'languages']","['paper', 'explain', 'machin', 'translat', 'next', 'languageshttp', 'video', 'explain', 'summar', 'page', 'long', 'build', 'machin', 'translat', 'system', 'next', 'thousand', 'languag', 'paper', 'googl', 'research', 'goe', 'data', 'collect', 'model', 'process', 'bit', 'result', 'paper', 'link', 'http', 'outlin', 'machin', 'translat', 'languag', 'weight', 'bias', 'sponsor', 'problem', 'mani', 'languag', 'collect', 'data', 'k', 'languag', 'build', 'mt', 'model', 'result', 'thousand', 'languag']"
136,150,150,mojojojo_24,w5mp2c,[P] Prompt autocomplete for text-to-image models: releasing model & dataset scraped from Midjourney,"Crafting effective prompts for text-to-image models like DALL·E takes a lot of tinkering; it requires creativity, but also familiarity with the model behavior. The burden shifts from learning how to draw to learning how to control the AI.

A friend and I decided to tackle this prompt engineering problem, and ended up creating a bunch of resources that we want to share with the community:

* A [**Kaggle dataset**](https://www.kaggle.com/datasets/succinctlyai/midjourney-texttoimage) obtained by scraping four months' worth of messages from [Midjourney](https://midjourney.com/)'s public Discord server, where users interact with the text-to-image service. It includes **\~250k** user-issued text prompts, URLs of the generated images, and other metadata.
* A [**HuggingFace dataset**](https://huggingface.co/datasets/succinctly/midjourney-prompts) derived from the one above, that solely contains user-issued text prompts.
* A [**HuggingFace model**](https://huggingface.co/succinctly/text2image-prompt-generator) (fine-tuned GPT-2) that generates text prompts. Feel free to try out the demo!

Enjoy, and let us know in the comments if you have any feedback!",2,6,2022-07-23 01:00:39, p  prompt autocomplete for text to image models  releasing model   dataset scraped from midjourney,crafting effective prompts for text to image models like dall e takes a lot of tinkering  it requires creativity  but also familiarity with the model behavior  the burden shifts from learning how to draw to learning how to control the ai a friend and i decided to tackle this prompt engineering problem  and ended up creating a bunch of resources that we want to share with the community   a    kaggle dataset    https   a    huggingface dataset    https   a    huggingface model    https enjoy  and let us know in the comments if you have any feedback ,crafting effective prompts text image models like dall e takes lot tinkering requires creativity also familiarity model behavior burden shifts learning draw learning control ai friend decided tackle prompt engineering problem ended creating bunch resources want share community kaggle dataset https huggingface dataset https huggingface model https enjoy let us know comments feedback,p prompt autocomplete text image models releasing model dataset scraped midjourney,p prompt autocomplete text image models releasing model dataset scraped midjourneycrafting effective prompts text image models like dall e takes lot tinkering requires creativity also familiarity model behavior burden shifts learning draw learning control ai friend decided tackle prompt engineering problem ended creating bunch resources want share community kaggle dataset https huggingface dataset https huggingface model https enjoy let us know comments feedback,"['p', 'prompt', 'autocomplete', 'text', 'image', 'models', 'releasing', 'model', 'dataset', 'scraped', 'midjourneycrafting', 'effective', 'prompts', 'text', 'image', 'models', 'like', 'dall', 'e', 'takes', 'lot', 'tinkering', 'requires', 'creativity', 'also', 'familiarity', 'model', 'behavior', 'burden', 'shifts', 'learning', 'draw', 'learning', 'control', 'ai', 'friend', 'decided', 'tackle', 'prompt', 'engineering', 'problem', 'ended', 'creating', 'bunch', 'resources', 'want', 'share', 'community', 'kaggle', 'dataset', 'https', 'huggingface', 'dataset', 'https', 'huggingface', 'model', 'https', 'enjoy', 'let', 'us', 'know', 'comments', 'feedback']","['p', 'prompt', 'autocomplet', 'text', 'imag', 'model', 'releas', 'model', 'dataset', 'scrape', 'midjourneycraft', 'effect', 'prompt', 'text', 'imag', 'model', 'like', 'dall', 'e', 'take', 'lot', 'tinker', 'requir', 'creativ', 'also', 'familiar', 'model', 'behavior', 'burden', 'shift', 'learn', 'draw', 'learn', 'control', 'ai', 'friend', 'decid', 'tackl', 'prompt', 'engin', 'problem', 'end', 'creat', 'bunch', 'resourc', 'want', 'share', 'commun', 'kaggl', 'dataset', 'http', 'huggingfac', 'dataset', 'http', 'huggingfac', 'model', 'http', 'enjoy', 'let', 'us', 'know', 'comment', 'feedback']"
137,151,151,digitify,w5yqiy,[D] FUTURE is here.,"China uses AI to 'improve' courts - with computers 'correcting perceived human errors in a verdict' and JUDGES forced to submit a written explanation to the MACHINE if they disagree.

Your opinion?",8,0,2022-07-23 11:14:19, d  future is here ,china uses ai to  improve  courts   with computers  correcting perceived human errors in a verdict  and judges forced to submit a written explanation to the machine if they disagree your opinion ,china uses ai improve courts computers correcting perceived human errors verdict judges forced submit written explanation machine disagree opinion,future,futurechina uses ai improve courts computers correcting perceived human errors verdict judges forced submit written explanation machine disagree opinion,"['futurechina', 'uses', 'ai', 'improve', 'courts', 'computers', 'correcting', 'perceived', 'human', 'errors', 'verdict', 'judges', 'forced', 'submit', 'written', 'explanation', 'machine', 'disagree', 'opinion']","['futurechina', 'use', 'ai', 'improv', 'court', 'comput', 'correct', 'perceiv', 'human', 'error', 'verdict', 'judg', 'forc', 'submit', 'written', 'explan', 'machin', 'disagre', 'opinion']"
138,152,152,FastestLearner,w58mbf,[D] Can you reorder equal-contribution author names on a CV/resume?,"I have published a paper sharing equal contribution with two other authors (all working on the same project in the same lab). The order of names were decided by our professor, who happens to exhibit bias towards the other authors. My question is: is it legal / acceptable or generally considered okay, to have a reordering of the author names for the same paper when I mention in my CV or in my resume? After all, there is nothing that 'should' be wrong with it, as everyone has contributed equally to the paper.",49,37,2022-07-22 14:49:17, d  can you reorder equal contribution author names on a cv resume ,i have published a paper sharing equal contribution with two other authors  all working on the same project in the same lab   the order of names were decided by our professor  who happens to exhibit bias towards the other authors  my question is  is it legal   acceptable or generally considered okay  to have a reordering of the author names for the same paper when i mention in my cv or in my resume  after all  there is nothing that  should  be wrong with it  as everyone has contributed equally to the paper ,published paper sharing equal contribution two authors working project lab order names decided professor happens exhibit bias towards authors question legal acceptable generally considered okay reordering author names paper mention cv resume nothing wrong everyone contributed equally paper,reorder equal contribution author names cv resume,reorder equal contribution author names cv resumepublished paper sharing equal contribution two authors working project lab order names decided professor happens exhibit bias towards authors question legal acceptable generally considered okay reordering author names paper mention cv resume nothing wrong everyone contributed equally paper,"['reorder', 'equal', 'contribution', 'author', 'names', 'cv', 'resumepublished', 'paper', 'sharing', 'equal', 'contribution', 'two', 'authors', 'working', 'project', 'lab', 'order', 'names', 'decided', 'professor', 'happens', 'exhibit', 'bias', 'towards', 'authors', 'question', 'legal', 'acceptable', 'generally', 'considered', 'okay', 'reordering', 'author', 'names', 'paper', 'mention', 'cv', 'resume', 'nothing', 'wrong', 'everyone', 'contributed', 'equally', 'paper']","['reorder', 'equal', 'contribut', 'author', 'name', 'cv', 'resumepublish', 'paper', 'share', 'equal', 'contribut', 'two', 'author', 'work', 'project', 'lab', 'order', 'name', 'decid', 'professor', 'happen', 'exhibit', 'bia', 'toward', 'author', 'question', 'legal', 'accept', 'gener', 'consid', 'okay', 'reorder', 'author', 'name', 'paper', 'mention', 'cv', 'resum', 'noth', 'wrong', 'everyon', 'contribut', 'equal', 'paper']"
139,153,153,shreyansh26,w52iev,[D] What are some good resources to learn CUDA programming?,"I wanted to get some hands on experience with writing lower-level stuff. I have seen CUDA code and it does seem a bit intimidating. I have good experience with Pytorch and C/C++ as well, if that helps answering the question. Any suggestions/resources on how to get started learning CUDA programming? Quality books, videos, lectures, everything works.",37,132,2022-07-22 08:37:46, d  what are some good resources to learn cuda programming ,i wanted to get some hands on experience with writing lower level stuff  i have seen cuda code and it does seem a bit intimidating  i have good experience with pytorch and c c   as well  if that helps answering the question  any suggestions resources on how to get started learning cuda programming  quality books  videos  lectures  everything works ,wanted get hands experience writing lower level stuff seen cuda code seem bit intimidating good experience pytorch c c well helps answering question suggestions resources get started learning cuda programming quality books videos lectures everything works,good resources learn cuda programming,good resources learn cuda programmingwanted get hands experience writing lower level stuff seen cuda code seem bit intimidating good experience pytorch c c well helps answering question suggestions resources get started learning cuda programming quality books videos lectures everything works,"['good', 'resources', 'learn', 'cuda', 'programmingwanted', 'get', 'hands', 'experience', 'writing', 'lower', 'level', 'stuff', 'seen', 'cuda', 'code', 'seem', 'bit', 'intimidating', 'good', 'experience', 'pytorch', 'c', 'c', 'well', 'helps', 'answering', 'question', 'suggestions', 'resources', 'get', 'started', 'learning', 'cuda', 'programming', 'quality', 'books', 'videos', 'lectures', 'everything', 'works']","['good', 'resourc', 'learn', 'cuda', 'programmingw', 'get', 'hand', 'experi', 'write', 'lower', 'level', 'stuff', 'seen', 'cuda', 'code', 'seem', 'bit', 'intimid', 'good', 'experi', 'pytorch', 'c', 'c', 'well', 'help', 'answer', 'question', 'suggest', 'resourc', 'get', 'start', 'learn', 'cuda', 'program', 'qualiti', 'book', 'video', 'lectur', 'everyth', 'work']"
140,154,154,IllustriousCicada603,w5545w,[D] What machine learning topics do you think are underrated and deserve more attention?,"The online machine learning community in recent years is pretty active and posting free tutorials, guides and workshops on platforms such as Medium. However, it is easily seen that there are some hot topics which get the most of the attention by writers (e.g. Transformer implementations for NLP tasks). That said, which topics (broad - covering an area of research; or specific - implementations, code comparisons, etc.) do you feel don't get enough coverage? What content would you love to see more?",77,39,2022-07-22 11:18:30, d  what machine learning topics do you think are underrated and deserve more attention ,the online machine learning community in recent years is pretty active and posting free tutorials  guides and workshops on platforms such as medium  however  it is easily seen that there are some hot topics which get the most of the attention by writers  e g  transformer implementations for nlp tasks   that said  which topics  broad   covering an area of research  or specific   implementations  code comparisons  etc   do you feel don t get enough coverage  what content would you love to see more ,online machine learning community recent years pretty active posting free tutorials guides workshops platforms medium however easily seen hot topics get attention writers e g transformer implementations nlp tasks said topics broad covering area research specific implementations code comparisons etc feel get enough coverage content would love see,machine learning topics think underrated deserve attention,machine learning topics think underrated deserve attentiononline machine learning community recent years pretty active posting free tutorials guides workshops platforms medium however easily seen hot topics get attention writers e g transformer implementations nlp tasks said topics broad covering area research specific implementations code comparisons etc feel get enough coverage content would love see,"['machine', 'learning', 'topics', 'think', 'underrated', 'deserve', 'attentiononline', 'machine', 'learning', 'community', 'recent', 'years', 'pretty', 'active', 'posting', 'free', 'tutorials', 'guides', 'workshops', 'platforms', 'medium', 'however', 'easily', 'seen', 'hot', 'topics', 'get', 'attention', 'writers', 'e', 'g', 'transformer', 'implementations', 'nlp', 'tasks', 'said', 'topics', 'broad', 'covering', 'area', 'research', 'specific', 'implementations', 'code', 'comparisons', 'etc', 'feel', 'get', 'enough', 'coverage', 'content', 'would', 'love', 'see']","['machin', 'learn', 'topic', 'think', 'underr', 'deserv', 'attentiononlin', 'machin', 'learn', 'commun', 'recent', 'year', 'pretti', 'activ', 'post', 'free', 'tutori', 'guid', 'workshop', 'platform', 'medium', 'howev', 'easili', 'seen', 'hot', 'topic', 'get', 'attent', 'writer', 'e', 'g', 'transform', 'implement', 'nlp', 'task', 'said', 'topic', 'broad', 'cover', 'area', 'research', 'specif', 'implement', 'code', 'comparison', 'etc', 'feel', 'get', 'enough', 'coverag', 'content', 'would', 'love', 'see']"
141,155,155,mfarahmand98,w5hl7a,[D] Fine-tuning Diffusion-based Models,"Hello everyone.

Can you fine-tune publicly available Diffusion models on a custom dataset? I was hoping to fine-tune a pretrained network on a small dataset of images with a specific art style and short descriptions. However, the dataset I've collected is quite small, around 1000 images. Is it possible at this point in time? Have much resources would it require?",2,7,2022-07-22 21:25:02, d  fine tuning diffusion based models,hello everyone can you fine tune publicly available diffusion models on a custom dataset  i was hoping to fine tune a pretrained network on a small dataset of images with a specific art style and short descriptions  however  the dataset i ve collected is quite small  around  images  is it possible at this point in time  have much resources would it require ,hello everyone fine tune publicly available diffusion models dataset hoping fine tune pretrained network small dataset images specific art style short descriptions however dataset collected quite small around images possible point time much resources would require,fine tuning diffusion based models,fine tuning diffusion based modelshello everyone fine tune publicly available diffusion models dataset hoping fine tune pretrained network small dataset images specific art style short descriptions however dataset collected quite small around images possible point time much resources would require,"['fine', 'tuning', 'diffusion', 'based', 'modelshello', 'everyone', 'fine', 'tune', 'publicly', 'available', 'diffusion', 'models', 'dataset', 'hoping', 'fine', 'tune', 'pretrained', 'network', 'small', 'dataset', 'images', 'specific', 'art', 'style', 'short', 'descriptions', 'however', 'dataset', 'collected', 'quite', 'small', 'around', 'images', 'possible', 'point', 'time', 'much', 'resources', 'would', 'require']","['fine', 'tune', 'diffus', 'base', 'modelshello', 'everyon', 'fine', 'tune', 'publicli', 'avail', 'diffus', 'model', 'dataset', 'hope', 'fine', 'tune', 'pretrain', 'network', 'small', 'dataset', 'imag', 'specif', 'art', 'style', 'short', 'descript', 'howev', 'dataset', 'collect', 'quit', 'small', 'around', 'imag', 'possibl', 'point', 'time', 'much', 'resourc', 'would', 'requir']"
142,156,156,MetaAI_Official,w4jg7q,[D] Hey Reddit! We're a bunch of research scientists and software engineers and we just open sourced a new state-of-the-art AI model that can translate between 200 different languages. We're excited to hear your thoughts so we're hosting an AMA on 07/21/2022 @ 9:00AM PT. Ask Us Anything!,"PROOF: [https://i.redd.it/2z42nlnbssc91.jpg](https://i.redd.it/2z42nlnbssc91.jpg)

We’re part of the team behind Meta AI’s latest AI breakthrough in machine translation with our No Language Left Behind (NLLB) project. It’s a translation system that can support over 200 languages, even if there isn't a lot of text available to learn from.   The reality is that a handful of languages dominate the web meaning only a fraction of the world can access content and contribute to the web in their own language. We want to change this by creating more inclusive machine translations systems – ones that unlock access to the web for the more than 4B people around the world that are currently excluded because they do not speak one of the few languages content is available in.   Here are a few things about NLLB we’re excited for:

* Latest breakthrough: we created a single model that translates over 200 different languages with state-of-the-art results.
* Billions of translations: We’re applying the techniques from the research advancements from NLLB to support more than 25 billion translations served every day on Facebook News Feed, Instagram, and our other platforms.
* Meta’s AI Research SuperCluster (RSC): This large-scale conditional language model is one of the first AI models trained on Meta’s AI Research SuperCluster (RSC) supercomputer.
* Open sourcing: By open sourcing our model and publishing a slew of research tools, we hope that AI researchers whose languages are not supported well or at all on commercial translations services could use our model to create support for that language. Furthermore, we’ve open sourced datasets, such as NLLB-Seed and FLORES-200 evaluation benchmark, which doubles the existing language coverage over our previous benchmark.
* Wikimedia Foundation collaboration: We collaborated with the Wikimedia Foundation to help improve translation systems on their Content Translations tool. Editors can now more efficiently translate and edit articles in 20  low-resource languages, including 10 that previously were not supported by any machine translation tools on the platform. 
* Books translation: we’re partnering with local publishers around the world to translate children’s stories.

You can check out some of our materials and open sourced artifacts here: 

* Our latest blog post: [https://ai.facebook.com/blog/nllb-200-high-quality-machine-translation](https://ai.facebook.com/blog/nllb-200-high-quality-machine-translation)
* Project Overview: [https://ai.facebook.com/research/no-language-left-behind/ ](https://ai.facebook.com/research/no-language-left-behind/ )
* Product demo: [https://nllb.metademolab.com/](https://nllb.metademolab.com/)
* Research paper: [https://research.facebook.com/publications/no-language-left-behind](https://research.facebook.com/publications/no-language-left-behind)
* NLLB-200: [https://github.com/facebookresearch/fairseq/tree/nllb](https://github.com/facebookresearch/fairseq/tree/nllb)
* FLORES-200: [https://github.com/facebookresearch/flores](https://github.com/facebookresearch/flores)
* LASER3: [https://github.com/facebookresearch/LASER](https://github.com/facebookresearch/LASER)  

Joining us today for the AMA are:

* Angela Fan (AF), Research Scientist 
* Jean Maillard (JM), Research Scientist
* Maha Elbayad (ME), Research Scientist
* Philipp Koehn (PK), Research Scientist
* Shruti Bhosale (SB), Software Engineer  

We’ll be here from 07/21/2022 @09:00AM PT - 10:00AM PT 

Thanks and we’re looking forward to answering your questions!

**EDIT 10:30am PT:** Thanks for all the questions, we’re signing off! We had a great time and we’re glad to answer so many thoughtful questions!",115,780,2022-07-21 18:25:27, d  hey reddit  we re a bunch of research scientists and software engineers and we just open sourced a new state of the art ai model that can translate between  different languages  we re excited to hear your thoughts so we re hosting an ama on       am pt  ask us anything ,proof   https we re part of the team behind meta ai s latest ai breakthrough in machine translation with our no language left behind  nllb  project  it s a translation system that can support over  languages  even if there isn t a lot of text available to learn from    the reality is that a handful of languages dominate the web meaning only a fraction of the world can access content and contribute to the web in their own language  we want to change this by creating more inclusive machine translations systems   ones that unlock access to the web for the more than b people around the world that are currently excluded because they do not speak one of the few languages content is available in    here are a few things about nllb we re excited for   latest breakthrough  we created a single model that translates over  different languages with state of the art results   billions of translations  we re applying the techniques from the research advancements from nllb to support more than  billion translations served every day on facebook news feed  instagram  and our other platforms   meta s ai research supercluster  rsc   this large scale conditional language model is one of the first ai models trained on meta s ai research supercluster  rsc  supercomputer   open sourcing  by open sourcing our model and publishing a slew of research tools  we hope that ai researchers whose languages are not supported well or at all on commercial translations services could use our model to create support for that language  furthermore  we ve open sourced datasets  such as nllb seed and flores  evaluation benchmark  which doubles the existing language coverage over our previous benchmark   wikimedia foundation collaboration  we collaborated with the wikimedia foundation to help improve translation systems on their content translations tool  editors can now more efficiently translate and edit articles in   low resource languages  including  that previously were not supported by any machine translation tools on the platform    books translation  we re partnering with local publishers around the world to translate children s stories you can check out some of our materials and open sourced artifacts here    our latest blog post   https   project overview   https   product demo   https   research paper   https   nllb    https   flores    https   laser   https joining us today for the ama are   angela fan  af   research scientist   jean maillard  jm   research scientist  maha elbayad  me   research scientist  philipp koehn  pk   research scientist  shruti bhosale  sb   software engineer  we ll be here from thanks and we re looking forward to answering your questions   edit  am pt    thanks for all the questions  we re signing off  we had a great time and we re glad to answer so many thoughtful questions ,proof https part team behind meta ai latest ai breakthrough machine translation language left behind nllb project translation system support languages even lot text available learn reality handful languages dominate web meaning fraction world access content contribute web language want change creating inclusive machine translations systems ones unlock access web b people around world currently excluded speak one languages content available things nllb excited latest breakthrough created single model translates different languages state art results billions translations applying techniques research advancements nllb support billion translations served every day facebook news feed instagram platforms meta ai research supercluster rsc large scale conditional language model one first ai models trained meta ai research supercluster rsc supercomputer open sourcing open sourcing model publishing slew research tools hope ai researchers whose languages supported well commercial translations services could use model create support language furthermore open sourced datasets nllb seed flores evaluation benchmark doubles existing language coverage previous benchmark wikimedia foundation collaboration collaborated wikimedia foundation help improve translation systems content translations tool editors efficiently translate edit articles low resource languages including previously supported machine translation tools platform books translation partnering local publishers around world translate children stories check materials open sourced artifacts latest blog post https project overview https product demo https research paper https nllb https flores https laser https joining us today ama angela fan af research scientist jean maillard jm research scientist maha elbayad research scientist philipp koehn pk research scientist shruti bhosale sb software engineer thanks looking forward answering questions edit pt thanks questions signing great time glad answer many thoughtful questions,hey reddit bunch research scientists software engineers open sourced state art ai model translate different languages excited hear thoughts hosting ama pt ask us anything,hey reddit bunch research scientists software engineers open sourced state art ai model translate different languages excited hear thoughts hosting ama pt ask us anythingproof https part team behind meta ai latest ai breakthrough machine translation language left behind nllb project translation system support languages even lot text available learn reality handful languages dominate web meaning fraction world access content contribute web language want change creating inclusive machine translations systems ones unlock access web b people around world currently excluded speak one languages content available things nllb excited latest breakthrough created single model translates different languages state art results billions translations applying techniques research advancements nllb support billion translations served every day facebook news feed instagram platforms meta ai research supercluster rsc large scale conditional language model one first ai models trained meta ai research supercluster rsc supercomputer open sourcing open sourcing model publishing slew research tools hope ai researchers whose languages supported well commercial translations services could use model create support language furthermore open sourced datasets nllb seed flores evaluation benchmark doubles existing language coverage previous benchmark wikimedia foundation collaboration collaborated wikimedia foundation help improve translation systems content translations tool editors efficiently translate edit articles low resource languages including previously supported machine translation tools platform books translation partnering local publishers around world translate children stories check materials open sourced artifacts latest blog post https project overview https product demo https research paper https nllb https flores https laser https joining us today ama angela fan af research scientist jean maillard jm research scientist maha elbayad research scientist philipp koehn pk research scientist shruti bhosale sb software engineer thanks looking forward answering questions edit pt thanks questions signing great time glad answer many thoughtful questions,"['hey', 'reddit', 'bunch', 'research', 'scientists', 'software', 'engineers', 'open', 'sourced', 'state', 'art', 'ai', 'model', 'translate', 'different', 'languages', 'excited', 'hear', 'thoughts', 'hosting', 'ama', 'pt', 'ask', 'us', 'anythingproof', 'https', 'part', 'team', 'behind', 'meta', 'ai', 'latest', 'ai', 'breakthrough', 'machine', 'translation', 'language', 'left', 'behind', 'nllb', 'project', 'translation', 'system', 'support', 'languages', 'even', 'lot', 'text', 'available', 'learn', 'reality', 'handful', 'languages', 'dominate', 'web', 'meaning', 'fraction', 'world', 'access', 'content', 'contribute', 'web', 'language', 'want', 'change', 'creating', 'inclusive', 'machine', 'translations', 'systems', 'ones', 'unlock', 'access', 'web', 'b', 'people', 'around', 'world', 'currently', 'excluded', 'speak', 'one', 'languages', 'content', 'available', 'things', 'nllb', 'excited', 'latest', 'breakthrough', 'created', 'single', 'model', 'translates', 'different', 'languages', 'state', 'art', 'results', 'billions', 'translations', 'applying', 'techniques', 'research', 'advancements', 'nllb', 'support', 'billion', 'translations', 'served', 'every', 'day', 'facebook', 'news', 'feed', 'instagram', 'platforms', 'meta', 'ai', 'research', 'supercluster', 'rsc', 'large', 'scale', 'conditional', 'language', 'model', 'one', 'first', 'ai', 'models', 'trained', 'meta', 'ai', 'research', 'supercluster', 'rsc', 'supercomputer', 'open', 'sourcing', 'open', 'sourcing', 'model', 'publishing', 'slew', 'research', 'tools', 'hope', 'ai', 'researchers', 'whose', 'languages', 'supported', 'well', 'commercial', 'translations', 'services', 'could', 'use', 'model', 'create', 'support', 'language', 'furthermore', 'open', 'sourced', 'datasets', 'nllb', 'seed', 'flores', 'evaluation', 'benchmark', 'doubles', 'existing', 'language', 'coverage', 'previous', 'benchmark', 'wikimedia', 'foundation', 'collaboration', 'collaborated', 'wikimedia', 'foundation', 'help', 'improve', 'translation', 'systems', 'content', 'translations', 'tool', 'editors', 'efficiently', 'translate', 'edit', 'articles', 'low', 'resource', 'languages', 'including', 'previously', 'supported', 'machine', 'translation', 'tools', 'platform', 'books', 'translation', 'partnering', 'local', 'publishers', 'around', 'world', 'translate', 'children', 'stories', 'check', 'materials', 'open', 'sourced', 'artifacts', 'latest', 'blog', 'post', 'https', 'project', 'overview', 'https', 'product', 'demo', 'https', 'research', 'paper', 'https', 'nllb', 'https', 'flores', 'https', 'laser', 'https', 'joining', 'us', 'today', 'ama', 'angela', 'fan', 'af', 'research', 'scientist', 'jean', 'maillard', 'jm', 'research', 'scientist', 'maha', 'elbayad', 'research', 'scientist', 'philipp', 'koehn', 'pk', 'research', 'scientist', 'shruti', 'bhosale', 'sb', 'software', 'engineer', 'thanks', 'looking', 'forward', 'answering', 'questions', 'edit', 'pt', 'thanks', 'questions', 'signing', 'great', 'time', 'glad', 'answer', 'many', 'thoughtful', 'questions']","['hey', 'reddit', 'bunch', 'research', 'scientist', 'softwar', 'engin', 'open', 'sourc', 'state', 'art', 'ai', 'model', 'translat', 'differ', 'languag', 'excit', 'hear', 'thought', 'host', 'ama', 'pt', 'ask', 'us', 'anythingproof', 'http', 'part', 'team', 'behind', 'meta', 'ai', 'latest', 'ai', 'breakthrough', 'machin', 'translat', 'languag', 'left', 'behind', 'nllb', 'project', 'translat', 'system', 'support', 'languag', 'even', 'lot', 'text', 'avail', 'learn', 'realiti', 'hand', 'languag', 'domin', 'web', 'mean', 'fraction', 'world', 'access', 'content', 'contribut', 'web', 'languag', 'want', 'chang', 'creat', 'inclus', 'machin', 'translat', 'system', 'one', 'unlock', 'access', 'web', 'b', 'peopl', 'around', 'world', 'current', 'exclud', 'speak', 'one', 'languag', 'content', 'avail', 'thing', 'nllb', 'excit', 'latest', 'breakthrough', 'creat', 'singl', 'model', 'translat', 'differ', 'languag', 'state', 'art', 'result', 'billion', 'translat', 'appli', 'techniqu', 'research', 'advanc', 'nllb', 'support', 'billion', 'translat', 'serv', 'everi', 'day', 'facebook', 'news', 'feed', 'instagram', 'platform', 'meta', 'ai', 'research', 'superclust', 'rsc', 'larg', 'scale', 'condit', 'languag', 'model', 'one', 'first', 'ai', 'model', 'train', 'meta', 'ai', 'research', 'superclust', 'rsc', 'supercomput', 'open', 'sourc', 'open', 'sourc', 'model', 'publish', 'slew', 'research', 'tool', 'hope', 'ai', 'research', 'whose', 'languag', 'support', 'well', 'commerci', 'translat', 'servic', 'could', 'use', 'model', 'creat', 'support', 'languag', 'furthermor', 'open', 'sourc', 'dataset', 'nllb', 'seed', 'flore', 'evalu', 'benchmark', 'doubl', 'exist', 'languag', 'coverag', 'previou', 'benchmark', 'wikimedia', 'foundat', 'collabor', 'collabor', 'wikimedia', 'foundat', 'help', 'improv', 'translat', 'system', 'content', 'translat', 'tool', 'editor', 'effici', 'translat', 'edit', 'articl', 'low', 'resourc', 'languag', 'includ', 'previous', 'support', 'machin', 'translat', 'tool', 'platform', 'book', 'translat', 'partner', 'local', 'publish', 'around', 'world', 'translat', 'children', 'stori', 'check', 'materi', 'open', 'sourc', 'artifact', 'latest', 'blog', 'post', 'http', 'project', 'overview', 'http', 'product', 'demo', 'http', 'research', 'paper', 'http', 'nllb', 'http', 'flore', 'http', 'laser', 'http', 'join', 'us', 'today', 'ama', 'angela', 'fan', 'af', 'research', 'scientist', 'jean', 'maillard', 'jm', 'research', 'scientist', 'maha', 'elbayad', 'research', 'scientist', 'philipp', 'koehn', 'pk', 'research', 'scientist', 'shruti', 'bhosal', 'sb', 'softwar', 'engin', 'thank', 'look', 'forward', 'answer', 'question', 'edit', 'pt', 'thank', 'question', 'sign', 'great', 'time', 'glad', 'answer', 'mani', 'thought', 'question']"
143,157,157,tonychenxyz,w5kh1u,[D] Data Leakage For Auto-Regressive Tasks?,"I have always thought and searched about this but felt like there’s not an easy answer. When training a model for auto regressive task with data sampled from moving window, will there be data leakage?

For example, when training an LSTM (or any other sequential model) to predict stock price  of next day with a series of historical price, we could create training samples by obtaining historical price series from a moving window, and assign the price of the day after the windows as output label. 

But in this case we would have training inputs overlap with labels. Would this create a leak?",3,1,2022-07-22 23:26:51, d  data leakage for auto regressive tasks ,i have always thought and searched about this but felt like there s not an easy answer  when training a model for auto regressive task with data sampled from moving window  will there be data leakage for example  when training an lstm  or any other sequential model  to predict stock price  of next day with a series of historical price  we could create training samples by obtaining historical price series from a moving window  and assign the price of the day after the windows as output label  but in this case we would have training inputs overlap with labels  would this create a leak ,always thought searched felt like easy answer training model auto regressive task data sampled moving window data leakage example training lstm sequential model predict stock price next day series historical price could create training samples obtaining historical price series moving window assign price day windows output label case would training inputs overlap labels would create leak,data leakage auto regressive tasks,data leakage auto regressive tasksalways thought searched felt like easy answer training model auto regressive task data sampled moving window data leakage example training lstm sequential model predict stock price next day series historical price could create training samples obtaining historical price series moving window assign price day windows output label case would training inputs overlap labels would create leak,"['data', 'leakage', 'auto', 'regressive', 'tasksalways', 'thought', 'searched', 'felt', 'like', 'easy', 'answer', 'training', 'model', 'auto', 'regressive', 'task', 'data', 'sampled', 'moving', 'window', 'data', 'leakage', 'example', 'training', 'lstm', 'sequential', 'model', 'predict', 'stock', 'price', 'next', 'day', 'series', 'historical', 'price', 'could', 'create', 'training', 'samples', 'obtaining', 'historical', 'price', 'series', 'moving', 'window', 'assign', 'price', 'day', 'windows', 'output', 'label', 'case', 'would', 'training', 'inputs', 'overlap', 'labels', 'would', 'create', 'leak']","['data', 'leakag', 'auto', 'regress', 'tasksalway', 'thought', 'search', 'felt', 'like', 'easi', 'answer', 'train', 'model', 'auto', 'regress', 'task', 'data', 'sampl', 'move', 'window', 'data', 'leakag', 'exampl', 'train', 'lstm', 'sequenti', 'model', 'predict', 'stock', 'price', 'next', 'day', 'seri', 'histor', 'price', 'could', 'creat', 'train', 'sampl', 'obtain', 'histor', 'price', 'seri', 'move', 'window', 'assign', 'price', 'day', 'window', 'output', 'label', 'case', 'would', 'train', 'input', 'overlap', 'label', 'would', 'creat', 'leak']"
144,158,158,zy415,w4ooph,[D] ICML 2022 Outstanding Paper Awards 🔥,"It seems that ML twitter is under fire this week 🔥 Two of the recent [ICML outstanding paper awards](https://icml.cc/virtual/2022/awards_detail) have received major criticisms on Twitter:

* Paper 1: Bayesian Model Selection, the Marginal Likelihood, and Generalization
   * Paper link:
      * [https://proceedings.mlr.press/v162/lotfi22a.html](https://proceedings.mlr.press/v162/lotfi22a.html)
   * Twitter discussion:
      * [https://twitter.com/BlackHC/status/1549832198152683520](https://twitter.com/BlackHC/status/1549832198152683520)
      * [https://twitter.com/LotfiSanae/status/1549842925328257025](https://twitter.com/LotfiSanae/status/1549842925328257025)
      * [https://twitter.com/andrewgwils/status/1550120752099180548](https://twitter.com/andrewgwils/status/1550120752099180548)
      * [https://twitter.com/nsaphra/status/1550431412020551680](https://twitter.com/nsaphra/status/1550431412020551680)
   * Blog containing the critical review:
      * [https://blog.blackhc.net/2022/06/bayesian-model-selection-marginal-likehood-generalization/](https://blog.blackhc.net/2022/06/bayesian-model-selection-marginal-likehood-generalization/)
* Paper 2: Privacy for Free: How does Dataset Condensation Help Privacy?
   * Paper link:
      * [https://proceedings.mlr.press/v162/dong22c.html](https://proceedings.mlr.press/v162/dong22c.html)
   * Twitter discussion:
      * [https://twitter.com/vitalyFM/status/1549599469695512576](https://twitter.com/vitalyFM/status/1549599469695512576)
      * [https://twitter.com/thegautamkamath/status/1549764958648410112](https://twitter.com/thegautamkamath/status/1549764958648410112)
      * [https://twitter.com/thesasho/status/1549723809569202176](https://twitter.com/thesasho/status/1549723809569202176)

Regardless of the contents of the papers themselves, it seems that folks have different opinions about this affair:

* Some people think that criticisms are necessary and it is the duty of the experts to report on the flaws they discovered, given that (1) the outstanding paper award will receive attention, and (2) the authors are promoting their awarded papers on Twitter. Also, (first) authors bear the responsibility and earn the flaws, so they should be able to publicly defend their papers.
   * [https://twitter.com/vitalyFM/status/1550175851815178240](https://twitter.com/vitalyFM/status/1550175851815178240)
   * [https://twitter.com/vitalyFM/status/1550202515748048896](https://twitter.com/vitalyFM/status/1550202515748048896)
   * [https://twitter.com/roydanroy/status/1550227708369567744](https://twitter.com/roydanroy/status/1550227708369567744)
   * [https://mobile.twitter.com/aryehazan/status/1550380441512853504](https://mobile.twitter.com/aryehazan/status/1550380441512853504)
   * [https://mobile.twitter.com/victorveitch/status/1550333186814746624](https://mobile.twitter.com/victorveitch/status/1550333186814746624)
   * [https://mobile.twitter.com/victorveitch/status/1550304121571483648](https://mobile.twitter.com/victorveitch/status/1550304121571483648)
* Some people think that publicly calling out and ""shaming"" the authors (often junior researchers/PhD students) on Twitter might not be a good idea.
   * [https://twitter.com/zicokolter/status/1550101526596698113](https://twitter.com/zicokolter/status/1550101526596698113)
   * [https://twitter.com/nsaphra/status/1550121297773924352](https://twitter.com/nsaphra/status/1550121297773924352)
   * [https://twitter.com/EugeneVinitsky/status/1550160319233810433](https://twitter.com/EugeneVinitsky/status/1550160319233810433)
   * [https://twitter.com/JustinMSolomon/status/1550136404138553344](https://twitter.com/JustinMSolomon/status/1550136404138553344)
   * [https://twitter.com/JustinMSolomon/status/1549877869865836545](https://twitter.com/JustinMSolomon/status/1549877869865836545)
   * [https://twitter.com/togelius/status/1550165293787389957](https://twitter.com/togelius/status/1550165293787389957)
* Some people think that there are systemic issues given the large scale of ML conference, since the award committee did not manage to detect such flaws when selecting the outstanding papers.
   * [https://twitter.com/aryehazan/status/1550042479864446977](https://twitter.com/aryehazan/status/1550042479864446977)
   * [https://twitter.com/thegautamkamath/status/1550126605535588363](https://twitter.com/thegautamkamath/status/1550126605535588363)
   * [https://twitter.com/ccanonne\_/status/1549963476306915329](https://twitter.com/ccanonne_/status/1549963476306915329)
   * [https://twitter.com/kat\_heller/status/1550140571846590465](https://twitter.com/kat_heller/status/1550140571846590465)
* Some people think that we should pay less attention to these paper counts and awards.
   * [https://twitter.com/thegautamkamath/status/1549764958648410112](https://twitter.com/thegautamkamath/status/1549764958648410112)
   * [https://twitter.com/shortstein/status/1549900067749777408](https://twitter.com/shortstein/status/1549900067749777408)
* Some people think that these outstanding paper awards shouldn't even exist, or should be given after a few years so that one could judge the paper's impact (like test of time award?).
   * [https://mobile.twitter.com/victorveitch/status/1550263086615068674](https://mobile.twitter.com/victorveitch/status/1550263086615068674)
   * [https://twitter.com/thesasho/status/1549770578420277250](https://twitter.com/thesasho/status/1549770578420277250)
   * [https://twitter.com/roydanroy/status/1549692532019404800](https://twitter.com/roydanroy/status/1549692532019404800)
* Some people think that even if a paper has some issues, it may still have value, so this does not imply that the paper does not deserve an award.
   * [https://twitter.com/ryandcotterell/status/1550429598378299393](https://twitter.com/ryandcotterell/status/1550429598378299393)
   * [https://mobile.twitter.com/ozansener/status/1550287138431946752](https://mobile.twitter.com/ozansener/status/1550287138431946752)
* Some people think that it is a better idea to discuss about criticisms over private email, OpenReview or just write a paper on arXiv/workshop.
   * [https://mobile.twitter.com/aminkarbasi/status/1550205988745134087](https://mobile.twitter.com/aminkarbasi/status/1550205988745134087)
   * [https://mobile.twitter.com/zicokolter/status/1550327558931185665](https://mobile.twitter.com/zicokolter/status/1550327558931185665)
   * [https://mobile.twitter.com/ccanonne\_/status/1550255881278722048](https://mobile.twitter.com/ccanonne_/status/1550255881278722048)
   * [https://mobile.twitter.com/eisa\_ayed/status/1550256384981274624](https://mobile.twitter.com/eisa_ayed/status/1550256384981274624)

How do people think about it? Any thoughts about anything related to this affair? Any suggestion about better ways to communicate this type of criticisms?

Disclaimer: I am personally not a fan of calling out and shaming the authors publicly on Twitter.",31,81,2022-07-21 21:59:18, d  icml  outstanding paper awards  ,it seems that ml twitter is under fire this week   two of the recent  icml outstanding paper awards  https   paper   bayesian model selection  the marginal likelihood  and generalization     paper link          https      twitter discussion          https          https          https          https      blog containing the critical review          https   paper   privacy for free  how does dataset condensation help privacy      paper link          https      twitter discussion          https          https          https regardless of the contents of the papers themselves  it seems that folks have different opinions about this affair   some people think that criticisms are necessary and it is the duty of the experts to report on the flaws they discovered  given that    the outstanding paper award will receive attention  and    the authors are promoting their awarded papers on twitter  also   first  authors bear the responsibility and earn the flaws  so they should be able to publicly defend their papers       https       https       https       https       https       https   some people think that publicly calling out and shaming the authors  often junior researchers phd students  on twitter might not be a good idea       https       https       https       https       https       https   some people think that there are systemic issues given the large scale of ml conference  since the award committee did not manage to detect such flaws when selecting the outstanding papers       https       https       https       https   some people think that we should pay less attention to these paper counts and awards       https       https   some people think that these outstanding paper awards shouldn t even exist  or should be given after a few years so that one could judge the paper s impact  like test of time award         https       https       https   some people think that even if a paper has some issues  it may still have value  so this does not imply that the paper does not deserve an award       https       https   some people think that it is a better idea to discuss about criticisms over private email  openreview or just write a paper on arxiv workshop       https       https       https       https how do people think about it  any thoughts about anything related to this affair  any suggestion about better ways to communicate this type of criticisms disclaimer  i am personally not a fan of calling out and shaming the authors publicly on twitter ,seems ml twitter fire week two recent icml outstanding paper awards https paper bayesian model selection marginal likelihood generalization paper link https twitter discussion https https https https blog containing critical review https paper privacy free dataset condensation help privacy paper link https twitter discussion https https https regardless contents papers seems folks different opinions affair people think criticisms necessary duty experts report flaws discovered given outstanding paper award receive attention authors promoting awarded papers twitter also first authors bear responsibility earn flaws able publicly defend papers https https https https https https people think publicly calling shaming authors often junior researchers phd students twitter might good idea https https https https https https people think systemic issues given large scale ml conference since award committee manage detect flaws selecting outstanding papers https https https https people think pay less attention paper counts awards https https people think outstanding paper awards even exist given years one could judge paper impact like test time award https https https people think even paper issues may still value imply paper deserve award https https people think better idea discuss criticisms private email openreview write paper arxiv workshop https https https https people think thoughts anything related affair suggestion better ways communicate type criticisms disclaimer personally fan calling shaming authors publicly twitter,icml outstanding paper awards,icml outstanding paper awardsseems ml twitter fire week two recent icml outstanding paper awards https paper bayesian model selection marginal likelihood generalization paper link https twitter discussion https https https https blog containing critical review https paper privacy free dataset condensation help privacy paper link https twitter discussion https https https regardless contents papers seems folks different opinions affair people think criticisms necessary duty experts report flaws discovered given outstanding paper award receive attention authors promoting awarded papers twitter also first authors bear responsibility earn flaws able publicly defend papers https https https https https https people think publicly calling shaming authors often junior researchers phd students twitter might good idea https https https https https https people think systemic issues given large scale ml conference since award committee manage detect flaws selecting outstanding papers https https https https people think pay less attention paper counts awards https https people think outstanding paper awards even exist given years one could judge paper impact like test time award https https https people think even paper issues may still value imply paper deserve award https https people think better idea discuss criticisms private email openreview write paper arxiv workshop https https https https people think thoughts anything related affair suggestion better ways communicate type criticisms disclaimer personally fan calling shaming authors publicly twitter,"['icml', 'outstanding', 'paper', 'awardsseems', 'ml', 'twitter', 'fire', 'week', 'two', 'recent', 'icml', 'outstanding', 'paper', 'awards', 'https', 'paper', 'bayesian', 'model', 'selection', 'marginal', 'likelihood', 'generalization', 'paper', 'link', 'https', 'twitter', 'discussion', 'https', 'https', 'https', 'https', 'blog', 'containing', 'critical', 'review', 'https', 'paper', 'privacy', 'free', 'dataset', 'condensation', 'help', 'privacy', 'paper', 'link', 'https', 'twitter', 'discussion', 'https', 'https', 'https', 'regardless', 'contents', 'papers', 'seems', 'folks', 'different', 'opinions', 'affair', 'people', 'think', 'criticisms', 'necessary', 'duty', 'experts', 'report', 'flaws', 'discovered', 'given', 'outstanding', 'paper', 'award', 'receive', 'attention', 'authors', 'promoting', 'awarded', 'papers', 'twitter', 'also', 'first', 'authors', 'bear', 'responsibility', 'earn', 'flaws', 'able', 'publicly', 'defend', 'papers', 'https', 'https', 'https', 'https', 'https', 'https', 'people', 'think', 'publicly', 'calling', 'shaming', 'authors', 'often', 'junior', 'researchers', 'phd', 'students', 'twitter', 'might', 'good', 'idea', 'https', 'https', 'https', 'https', 'https', 'https', 'people', 'think', 'systemic', 'issues', 'given', 'large', 'scale', 'ml', 'conference', 'since', 'award', 'committee', 'manage', 'detect', 'flaws', 'selecting', 'outstanding', 'papers', 'https', 'https', 'https', 'https', 'people', 'think', 'pay', 'less', 'attention', 'paper', 'counts', 'awards', 'https', 'https', 'people', 'think', 'outstanding', 'paper', 'awards', 'even', 'exist', 'given', 'years', 'one', 'could', 'judge', 'paper', 'impact', 'like', 'test', 'time', 'award', 'https', 'https', 'https', 'people', 'think', 'even', 'paper', 'issues', 'may', 'still', 'value', 'imply', 'paper', 'deserve', 'award', 'https', 'https', 'people', 'think', 'better', 'idea', 'discuss', 'criticisms', 'private', 'email', 'openreview', 'write', 'paper', 'arxiv', 'workshop', 'https', 'https', 'https', 'https', 'people', 'think', 'thoughts', 'anything', 'related', 'affair', 'suggestion', 'better', 'ways', 'communicate', 'type', 'criticisms', 'disclaimer', 'personally', 'fan', 'calling', 'shaming', 'authors', 'publicly', 'twitter']","['icml', 'outstand', 'paper', 'awardsseem', 'ml', 'twitter', 'fire', 'week', 'two', 'recent', 'icml', 'outstand', 'paper', 'award', 'http', 'paper', 'bayesian', 'model', 'select', 'margin', 'likelihood', 'gener', 'paper', 'link', 'http', 'twitter', 'discuss', 'http', 'http', 'http', 'http', 'blog', 'contain', 'critic', 'review', 'http', 'paper', 'privaci', 'free', 'dataset', 'condens', 'help', 'privaci', 'paper', 'link', 'http', 'twitter', 'discuss', 'http', 'http', 'http', 'regardless', 'content', 'paper', 'seem', 'folk', 'differ', 'opinion', 'affair', 'peopl', 'think', 'critic', 'necessari', 'duti', 'expert', 'report', 'flaw', 'discov', 'given', 'outstand', 'paper', 'award', 'receiv', 'attent', 'author', 'promot', 'award', 'paper', 'twitter', 'also', 'first', 'author', 'bear', 'respons', 'earn', 'flaw', 'abl', 'publicli', 'defend', 'paper', 'http', 'http', 'http', 'http', 'http', 'http', 'peopl', 'think', 'publicli', 'call', 'shame', 'author', 'often', 'junior', 'research', 'phd', 'student', 'twitter', 'might', 'good', 'idea', 'http', 'http', 'http', 'http', 'http', 'http', 'peopl', 'think', 'system', 'issu', 'given', 'larg', 'scale', 'ml', 'confer', 'sinc', 'award', 'committe', 'manag', 'detect', 'flaw', 'select', 'outstand', 'paper', 'http', 'http', 'http', 'http', 'peopl', 'think', 'pay', 'less', 'attent', 'paper', 'count', 'award', 'http', 'http', 'peopl', 'think', 'outstand', 'paper', 'award', 'even', 'exist', 'given', 'year', 'one', 'could', 'judg', 'paper', 'impact', 'like', 'test', 'time', 'award', 'http', 'http', 'http', 'peopl', 'think', 'even', 'paper', 'issu', 'may', 'still', 'valu', 'impli', 'paper', 'deserv', 'award', 'http', 'http', 'peopl', 'think', 'better', 'idea', 'discuss', 'critic', 'privat', 'email', 'openreview', 'write', 'paper', 'arxiv', 'workshop', 'http', 'http', 'http', 'http', 'peopl', 'think', 'thought', 'anyth', 'relat', 'affair', 'suggest', 'better', 'way', 'commun', 'type', 'critic', 'disclaim', 'person', 'fan', 'call', 'shame', 'author', 'publicli', 'twitter']"
145,159,159,jikkii,w4je8h,[N] Diffusers: Introducing Hugging Face's new library for diffusion models.,"Diffusion models have recently gained a lot of interest from the machine learning community.

This is partly because diffusion models play an important role for models like DALL-E or Imagen to generate previously unparalleled photorealistic images when prompted on some text.

The computer vision community isn't the only one to enjoy the success of diffusion models, as they have also achieved remarkable results in other domains, such as:

\- video generation

\- audio synthesis

\- reinforcement learning

However, most recent research on diffusion models, namely Dalle-2 and Imagen, have **not** been made accessible to machine learning and often remains behind closed doors of large tech companies.

This is why we decided to build and open-source 🧨 Diffusers. The objective is twofold:

\- Centralize the most important, open-sourced research on diffusion models and make them more accessible and easier to use for the community.

\- Provide the community with simple yet powerful training utilities to build powerful systems, such as Imagen and DALLE, in a transparent, open-sourced fashion so that everybody profits from the new technology.

🧨 Diffusers aims to be a modular toolbox for diffusion techniques, with a focus on:

\- Inference pipelines- Schedulers- Models- Training examples

Check out the library here: [https://github.com/huggingface/diffusers](https://github.com/huggingface/diffusers)

Check out a walkthrough colab here: [https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers\_intro.ipynb](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb)

[Using a DDPM model and scheduler to generate a church image from noise](https://preview.redd.it/dm4fwcvevxc91.png?width=1362&format=png&auto=webp&s=2f85eb221ab5f1c3d22c13a774a22f9abdf05b86)",11,65,2022-07-21 18:23:11, n  diffusers  introducing hugging face s new library for diffusion models ,diffusion models have recently gained a lot of interest from the machine learning community this is partly because diffusion models play an important role for models like dall e or imagen to generate previously unparalleled photorealistic images when prompted on some text the computer vision community isn t the only one to enjoy the success of diffusion models  as they have also achieved remarkable results in other domains  such as    video generation   audio synthesis   reinforcement learninghowever  most recent research on diffusion models  namely dalle  and imagen  have   not   been made accessible to machine learning and often remains behind closed doors of large tech companies this is why we decided to build and open source   diffusers  the objective is twofold    centralize the most important  open sourced research on diffusion models and make them more accessible and easier to use for the community    provide the community with simple yet powerful training utilities to build powerful systems  such as imagen and dalle  in a transparent  open sourced fashion so that everybody profits from the new technology   diffusers aims to be a modular toolbox for diffusion techniques  with a focus on    inference pipelines  schedulers  models  training examplescheck out the library here   https check out a walkthrough colab here   https  using a ddpm model and scheduler to generate a church image from noise  https   preview redd it dmfwcvevxc png width  format png auto webp s febabfcdcaafabdfb ,diffusion models recently gained lot interest machine learning community partly diffusion models play important role models like dall e imagen generate previously unparalleled photorealistic images prompted text computer vision community one enjoy success diffusion models also achieved remarkable results domains video generation audio synthesis reinforcement learninghowever recent research diffusion models namely dalle imagen made accessible machine learning often remains behind closed doors large tech companies decided build open source diffusers objective twofold centralize important open sourced research diffusion models make accessible easier use community provide community simple yet powerful training utilities build powerful systems imagen dalle transparent open sourced fashion everybody profits technology diffusers aims modular toolbox diffusion techniques focus inference pipelines schedulers models training examplescheck library https check walkthrough colab https using ddpm model scheduler generate church image noise https preview redd dmfwcvevxc png width format png auto webp febabfcdcaafabdfb,n diffusers introducing hugging face library diffusion models,n diffusers introducing hugging face library diffusion modelsdiffusion models recently gained lot interest machine learning community partly diffusion models play important role models like dall e imagen generate previously unparalleled photorealistic images prompted text computer vision community one enjoy success diffusion models also achieved remarkable results domains video generation audio synthesis reinforcement learninghowever recent research diffusion models namely dalle imagen made accessible machine learning often remains behind closed doors large tech companies decided build open source diffusers objective twofold centralize important open sourced research diffusion models make accessible easier use community provide community simple yet powerful training utilities build powerful systems imagen dalle transparent open sourced fashion everybody profits technology diffusers aims modular toolbox diffusion techniques focus inference pipelines schedulers models training examplescheck library https check walkthrough colab https using ddpm model scheduler generate church image noise https preview redd dmfwcvevxc png width format png auto webp febabfcdcaafabdfb,"['n', 'diffusers', 'introducing', 'hugging', 'face', 'library', 'diffusion', 'modelsdiffusion', 'models', 'recently', 'gained', 'lot', 'interest', 'machine', 'learning', 'community', 'partly', 'diffusion', 'models', 'play', 'important', 'role', 'models', 'like', 'dall', 'e', 'imagen', 'generate', 'previously', 'unparalleled', 'photorealistic', 'images', 'prompted', 'text', 'computer', 'vision', 'community', 'one', 'enjoy', 'success', 'diffusion', 'models', 'also', 'achieved', 'remarkable', 'results', 'domains', 'video', 'generation', 'audio', 'synthesis', 'reinforcement', 'learninghowever', 'recent', 'research', 'diffusion', 'models', 'namely', 'dalle', 'imagen', 'made', 'accessible', 'machine', 'learning', 'often', 'remains', 'behind', 'closed', 'doors', 'large', 'tech', 'companies', 'decided', 'build', 'open', 'source', 'diffusers', 'objective', 'twofold', 'centralize', 'important', 'open', 'sourced', 'research', 'diffusion', 'models', 'make', 'accessible', 'easier', 'use', 'community', 'provide', 'community', 'simple', 'yet', 'powerful', 'training', 'utilities', 'build', 'powerful', 'systems', 'imagen', 'dalle', 'transparent', 'open', 'sourced', 'fashion', 'everybody', 'profits', 'technology', 'diffusers', 'aims', 'modular', 'toolbox', 'diffusion', 'techniques', 'focus', 'inference', 'pipelines', 'schedulers', 'models', 'training', 'examplescheck', 'library', 'https', 'check', 'walkthrough', 'colab', 'https', 'using', 'ddpm', 'model', 'scheduler', 'generate', 'church', 'image', 'noise', 'https', 'preview', 'redd', 'dmfwcvevxc', 'png', 'width', 'format', 'png', 'auto', 'webp', 'febabfcdcaafabdfb']","['n', 'diffus', 'introduc', 'hug', 'face', 'librari', 'diffus', 'modelsdiffus', 'model', 'recent', 'gain', 'lot', 'interest', 'machin', 'learn', 'commun', 'partli', 'diffus', 'model', 'play', 'import', 'role', 'model', 'like', 'dall', 'e', 'imagen', 'gener', 'previous', 'unparallel', 'photorealist', 'imag', 'prompt', 'text', 'comput', 'vision', 'commun', 'one', 'enjoy', 'success', 'diffus', 'model', 'also', 'achiev', 'remark', 'result', 'domain', 'video', 'gener', 'audio', 'synthesi', 'reinforc', 'learninghowev', 'recent', 'research', 'diffus', 'model', 'name', 'dall', 'imagen', 'made', 'access', 'machin', 'learn', 'often', 'remain', 'behind', 'close', 'door', 'larg', 'tech', 'compani', 'decid', 'build', 'open', 'sourc', 'diffus', 'object', 'twofold', 'central', 'import', 'open', 'sourc', 'research', 'diffus', 'model', 'make', 'access', 'easier', 'use', 'commun', 'provid', 'commun', 'simpl', 'yet', 'power', 'train', 'util', 'build', 'power', 'system', 'imagen', 'dall', 'transpar', 'open', 'sourc', 'fashion', 'everybodi', 'profit', 'technolog', 'diffus', 'aim', 'modular', 'toolbox', 'diffus', 'techniqu', 'focu', 'infer', 'pipelin', 'schedul', 'model', 'train', 'examplescheck', 'librari', 'http', 'check', 'walkthrough', 'colab', 'http', 'use', 'ddpm', 'model', 'schedul', 'gener', 'church', 'imag', 'nois', 'http', 'preview', 'redd', 'dmfwcvevxc', 'png', 'width', 'format', 'png', 'auto', 'webp', 'febabfcdcaafabdfb']"
146,160,160,barash-616,w4vk1v,[D] Which GPU cloud do you use and recommend?,"I'm looking to migrate all my local experiments to some GPU cloud, but I found many options and I know few people who have used some and can give me some useful feedback.

I have two contexts:

1. Experiments performed in Jupyter Notebook;
2. DRL experiments using [StarCraft II Learning Environment](https://github.com/deepmind/pysc2).

For the first context I think about using Google Colab Pro, because I already have experience with Google Colab, so it would not be difficult to migrate to the Pro version. In the second case I used my local machine, but I'm out of GPU and the use of my university's supercomputer is absurdly problematic.

My monthly budget is $50.00, because the most massive processing I'm going to do on the university's supercomputer. This budget will be used to run experiments of a few hours, experiments of one or more days will use the supercomputer.

GPU clouds I found:

* [Lambda](https://lambdalabs.com/)
* [Linode](https://www.linode.com/products/gpu/)
* [Paperspace](https://www.paperspace.com/gpu-cloud)
* [RunPod](https://www.runpod.io/)

Obviously there are big tech clouds (AWS, Google Cloud and Azure), but from what I've seen these other GPU Clouds are usually cheaper and less difficult to use.

You who are reading the post could recommend me some Cloud GPU that you have already used?

(Clouds with student discounts are welcome)

TL;DR: please recommend me some cloud GPU that you have already used.",10,9,2022-07-22 02:48:21, d  which gpu cloud do you use and recommend ,i m looking to migrate all my local experiments to some gpu cloud  but i found many options and i know few people who have used some and can give me some useful feedback i have two contexts   experiments performed in jupyter notebook   drl experiments using  starcraft ii learning environment  https for the first context i think about using google colab pro  because i already have experience with google colab  so it would not be difficult to migrate to the pro version  in the second case i used my local machine  but i m out of gpu and the use of my university s supercomputer is absurdly problematic my monthly budget is     because the most massive processing i m going to do on the university s supercomputer  this budget will be used to run experiments of a few hours  experiments of one or more days will use the supercomputer gpu clouds i found    lambda  https    linode  https    paperspace  https    runpod  https obviously there are big tech clouds  aws  google cloud and azure   but from what i ve seen these other gpu clouds are usually cheaper and less difficult to use you who are reading the post could recommend me some cloud gpu that you have already used  clouds with student discounts are welcome tl dr  please recommend me some cloud gpu that you have already used ,looking migrate local experiments gpu cloud found many options know people used give useful feedback two contexts experiments performed jupyter notebook drl experiments using starcraft ii learning environment https first context think using google colab pro already experience google colab would difficult migrate pro version second case used local machine gpu use university supercomputer absurdly problematic monthly budget massive processing going university supercomputer budget used run experiments hours experiments one days use supercomputer gpu clouds found lambda https linode https paperspace https runpod https obviously big tech clouds aws google cloud azure seen gpu clouds usually cheaper less difficult use reading post could recommend cloud gpu already used clouds student discounts welcome tl dr please recommend cloud gpu already used,gpu cloud use recommend,gpu cloud use recommendlooking migrate local experiments gpu cloud found many options know people used give useful feedback two contexts experiments performed jupyter notebook drl experiments using starcraft ii learning environment https first context think using google colab pro already experience google colab would difficult migrate pro version second case used local machine gpu use university supercomputer absurdly problematic monthly budget massive processing going university supercomputer budget used run experiments hours experiments one days use supercomputer gpu clouds found lambda https linode https paperspace https runpod https obviously big tech clouds aws google cloud azure seen gpu clouds usually cheaper less difficult use reading post could recommend cloud gpu already used clouds student discounts welcome tl dr please recommend cloud gpu already used,"['gpu', 'cloud', 'use', 'recommendlooking', 'migrate', 'local', 'experiments', 'gpu', 'cloud', 'found', 'many', 'options', 'know', 'people', 'used', 'give', 'useful', 'feedback', 'two', 'contexts', 'experiments', 'performed', 'jupyter', 'notebook', 'drl', 'experiments', 'using', 'starcraft', 'ii', 'learning', 'environment', 'https', 'first', 'context', 'think', 'using', 'google', 'colab', 'pro', 'already', 'experience', 'google', 'colab', 'would', 'difficult', 'migrate', 'pro', 'version', 'second', 'case', 'used', 'local', 'machine', 'gpu', 'use', 'university', 'supercomputer', 'absurdly', 'problematic', 'monthly', 'budget', 'massive', 'processing', 'going', 'university', 'supercomputer', 'budget', 'used', 'run', 'experiments', 'hours', 'experiments', 'one', 'days', 'use', 'supercomputer', 'gpu', 'clouds', 'found', 'lambda', 'https', 'linode', 'https', 'paperspace', 'https', 'runpod', 'https', 'obviously', 'big', 'tech', 'clouds', 'aws', 'google', 'cloud', 'azure', 'seen', 'gpu', 'clouds', 'usually', 'cheaper', 'less', 'difficult', 'use', 'reading', 'post', 'could', 'recommend', 'cloud', 'gpu', 'already', 'used', 'clouds', 'student', 'discounts', 'welcome', 'tl', 'dr', 'please', 'recommend', 'cloud', 'gpu', 'already', 'used']","['gpu', 'cloud', 'use', 'recommendlook', 'migrat', 'local', 'experi', 'gpu', 'cloud', 'found', 'mani', 'option', 'know', 'peopl', 'use', 'give', 'use', 'feedback', 'two', 'context', 'experi', 'perform', 'jupyt', 'notebook', 'drl', 'experi', 'use', 'starcraft', 'ii', 'learn', 'environ', 'http', 'first', 'context', 'think', 'use', 'googl', 'colab', 'pro', 'alreadi', 'experi', 'googl', 'colab', 'would', 'difficult', 'migrat', 'pro', 'version', 'second', 'case', 'use', 'local', 'machin', 'gpu', 'use', 'univers', 'supercomput', 'absurdli', 'problemat', 'monthli', 'budget', 'massiv', 'process', 'go', 'univers', 'supercomput', 'budget', 'use', 'run', 'experi', 'hour', 'experi', 'one', 'day', 'use', 'supercomput', 'gpu', 'cloud', 'found', 'lambda', 'http', 'linod', 'http', 'paperspac', 'http', 'runpod', 'http', 'obvious', 'big', 'tech', 'cloud', 'aw', 'googl', 'cloud', 'azur', 'seen', 'gpu', 'cloud', 'usual', 'cheaper', 'less', 'difficult', 'use', 'read', 'post', 'could', 'recommend', 'cloud', 'gpu', 'alreadi', 'use', 'cloud', 'student', 'discount', 'welcom', 'tl', 'dr', 'pleas', 'recommend', 'cloud', 'gpu', 'alreadi', 'use']"
147,161,161,uninvitedignoramus,w57w46,[R] Any Content Based Image Retrieval Pretrained Models?,"Greetings, Redditors! For research purposed I would like to compare the accuracy of various  CIBR models on a custom dataset. Could you please point me to a few pretrained models to download? Thank you in advance!",1,1,2022-07-22 14:08:16, r  any content based image retrieval pretrained models ,greetings  redditors  for research purposed i would like to compare the accuracy of various  cibr models on a custom dataset  could you please point me to a few pretrained models to download  thank you in advance ,greetings redditors research purposed would like compare accuracy various cibr models dataset could please point pretrained models download thank advance,r content based image retrieval pretrained models,r content based image retrieval pretrained modelsgreetings redditors research purposed would like compare accuracy various cibr models dataset could please point pretrained models download thank advance,"['r', 'content', 'based', 'image', 'retrieval', 'pretrained', 'modelsgreetings', 'redditors', 'research', 'purposed', 'would', 'like', 'compare', 'accuracy', 'various', 'cibr', 'models', 'dataset', 'could', 'please', 'point', 'pretrained', 'models', 'download', 'thank', 'advance']","['r', 'content', 'base', 'imag', 'retriev', 'pretrain', 'modelsgreet', 'redditor', 'research', 'purpos', 'would', 'like', 'compar', 'accuraci', 'variou', 'cibr', 'model', 'dataset', 'could', 'pleas', 'point', 'pretrain', 'model', 'download', 'thank', 'advanc']"
148,162,162,MercuriusExMachina,w4i406,[D] Why don't we see faster adoption of FNet: Mixing Tokens with Fourier Transforms?,"When the paper came out last year, I thought that the innovation would quickly be adopted across the board, instead it would seem to be all but forgotten.

https://arxiv.org/abs/2105.03824v3

Just for a quick tl;dr, the architecture replaces the self-attention block with a Fourier transform, so no learnable parameters.

The enormously lower computation costs greatly outweigh the performance loss. So you can then make the network deeper and/or wider, thus for the same computation cost, have a great overall increase of performance.

If I remember correctly, they also tried to replace the self-attention block with some kind of linear transformation, and this performed really poorly, so the key here seems to be the nonlinearity of the Fourier transform.

The conclusion here being that the awesomeness of the transformer is in fact related to the greater architecture, and benefit of self-attention is mixing everything together in an interdependent and nonlinear fashion, which is exactly what the Fourier transform is doing.

So now, back to my original question, why is this not being adopted more quickly? What am I missing?",6,29,2022-07-21 17:29:28, d  why don t we see faster adoption of fnet  mixing tokens with fourier transforms ,when the paper came out last year  i thought that the innovation would quickly be adopted across the board  instead it would seem to be all but forgotten https just for a quick tl dr  the architecture replaces the self attention block with a fourier transform  so no learnable parameters the enormously lower computation costs greatly outweigh the performance loss  so you can then make the network deeper and or wider  thus for the same computation cost  have a great overall increase of performance if i remember correctly  they also tried to replace the self attention block with some kind of linear transformation  and this performed really poorly  so the key here seems to be the nonlinearity of the fourier transform the conclusion here being that the awesomeness of the transformer is in fact related to the greater architecture  and benefit of self attention is mixing everything together in an interdependent and nonlinear fashion  which is exactly what the fourier transform is doing so now  back to my original question  why is this not being adopted more quickly  what am i missing ,paper came last year thought innovation would quickly adopted across board instead would seem forgotten https quick tl dr architecture replaces self attention block fourier transform learnable parameters enormously lower computation costs greatly outweigh performance loss make network deeper wider thus computation cost great overall increase performance remember correctly also tried replace self attention block kind linear transformation performed really poorly key seems nonlinearity fourier transform conclusion awesomeness transformer fact related greater architecture benefit self attention mixing everything together interdependent nonlinear fashion exactly fourier transform back original question adopted quickly missing,see faster adoption fnet mixing tokens fourier transforms,see faster adoption fnet mixing tokens fourier transformspaper came last year thought innovation would quickly adopted across board instead would seem forgotten https quick tl dr architecture replaces self attention block fourier transform learnable parameters enormously lower computation costs greatly outweigh performance loss make network deeper wider thus computation cost great overall increase performance remember correctly also tried replace self attention block kind linear transformation performed really poorly key seems nonlinearity fourier transform conclusion awesomeness transformer fact related greater architecture benefit self attention mixing everything together interdependent nonlinear fashion exactly fourier transform back original question adopted quickly missing,"['see', 'faster', 'adoption', 'fnet', 'mixing', 'tokens', 'fourier', 'transformspaper', 'came', 'last', 'year', 'thought', 'innovation', 'would', 'quickly', 'adopted', 'across', 'board', 'instead', 'would', 'seem', 'forgotten', 'https', 'quick', 'tl', 'dr', 'architecture', 'replaces', 'self', 'attention', 'block', 'fourier', 'transform', 'learnable', 'parameters', 'enormously', 'lower', 'computation', 'costs', 'greatly', 'outweigh', 'performance', 'loss', 'make', 'network', 'deeper', 'wider', 'thus', 'computation', 'cost', 'great', 'overall', 'increase', 'performance', 'remember', 'correctly', 'also', 'tried', 'replace', 'self', 'attention', 'block', 'kind', 'linear', 'transformation', 'performed', 'really', 'poorly', 'key', 'seems', 'nonlinearity', 'fourier', 'transform', 'conclusion', 'awesomeness', 'transformer', 'fact', 'related', 'greater', 'architecture', 'benefit', 'self', 'attention', 'mixing', 'everything', 'together', 'interdependent', 'nonlinear', 'fashion', 'exactly', 'fourier', 'transform', 'back', 'original', 'question', 'adopted', 'quickly', 'missing']","['see', 'faster', 'adopt', 'fnet', 'mix', 'token', 'fourier', 'transformspap', 'came', 'last', 'year', 'thought', 'innov', 'would', 'quickli', 'adopt', 'across', 'board', 'instead', 'would', 'seem', 'forgotten', 'http', 'quick', 'tl', 'dr', 'architectur', 'replac', 'self', 'attent', 'block', 'fourier', 'transform', 'learnabl', 'paramet', 'enorm', 'lower', 'comput', 'cost', 'greatli', 'outweigh', 'perform', 'loss', 'make', 'network', 'deeper', 'wider', 'thu', 'comput', 'cost', 'great', 'overal', 'increas', 'perform', 'rememb', 'correctli', 'also', 'tri', 'replac', 'self', 'attent', 'block', 'kind', 'linear', 'transform', 'perform', 'realli', 'poorli', 'key', 'seem', 'nonlinear', 'fourier', 'transform', 'conclus', 'awesom', 'transform', 'fact', 'relat', 'greater', 'architectur', 'benefit', 'self', 'attent', 'mix', 'everyth', 'togeth', 'interdepend', 'nonlinear', 'fashion', 'exactli', 'fourier', 'transform', 'back', 'origin', 'question', 'adopt', 'quickli', 'miss']"
149,163,163,ashwan1,w4dvv5,[News] Theseus: Meta AI open sourced a library for encoding domain knowledge in end to end AI models,"Domain knowledge can sometimes boost model performance significantly. I have used knowledge graph in some of my projects as pre/post step to improve model performance. But that adds to deployment complexity.
Theseus is good step towards end to end AI models that incorporate domain knowledge. It is library for differentiable nonlinear least squares (NLS) that is particularly useful for applications like robotics and computer visions.

Read more: https://ai.facebook.com/blog/theseus-a-library-for-encoding-domain-knowledge-in-end-to-end-ai-models/",1,46,2022-07-21 14:06:35, news  theseus  meta ai open sourced a library for encoding domain knowledge in end to end ai models,domain knowledge can sometimes boost model performance significantly  i have used knowledge graph in some of my projects as pre post step to improve model performance  but that adds to deployment complexity theseus is good step towards end to end ai models that incorporate domain knowledge  it is library for differentiable nonlinear least squares  nls  that is particularly useful for applications like robotics and computer visions read more  https   ai facebook com blog theseus a library for encoding domain knowledge in end to end ai models ,domain knowledge sometimes boost model performance significantly used knowledge graph projects pre post step improve model performance adds deployment complexity theseus good step towards end end ai models incorporate domain knowledge library differentiable nonlinear least squares nls particularly useful applications like robotics computer visions read https ai facebook com blog theseus library encoding domain knowledge end end ai models,news theseus meta ai open sourced library encoding domain knowledge end end ai models,news theseus meta ai open sourced library encoding domain knowledge end end ai modelsdomain knowledge sometimes boost model performance significantly used knowledge graph projects pre post step improve model performance adds deployment complexity theseus good step towards end end ai models incorporate domain knowledge library differentiable nonlinear least squares nls particularly useful applications like robotics computer visions read https ai facebook com blog theseus library encoding domain knowledge end end ai models,"['news', 'theseus', 'meta', 'ai', 'open', 'sourced', 'library', 'encoding', 'domain', 'knowledge', 'end', 'end', 'ai', 'modelsdomain', 'knowledge', 'sometimes', 'boost', 'model', 'performance', 'significantly', 'used', 'knowledge', 'graph', 'projects', 'pre', 'post', 'step', 'improve', 'model', 'performance', 'adds', 'deployment', 'complexity', 'theseus', 'good', 'step', 'towards', 'end', 'end', 'ai', 'models', 'incorporate', 'domain', 'knowledge', 'library', 'differentiable', 'nonlinear', 'least', 'squares', 'nls', 'particularly', 'useful', 'applications', 'like', 'robotics', 'computer', 'visions', 'read', 'https', 'ai', 'facebook', 'com', 'blog', 'theseus', 'library', 'encoding', 'domain', 'knowledge', 'end', 'end', 'ai', 'models']","['news', 'theseu', 'meta', 'ai', 'open', 'sourc', 'librari', 'encod', 'domain', 'knowledg', 'end', 'end', 'ai', 'modelsdomain', 'knowledg', 'sometim', 'boost', 'model', 'perform', 'significantli', 'use', 'knowledg', 'graph', 'project', 'pre', 'post', 'step', 'improv', 'model', 'perform', 'add', 'deploy', 'complex', 'theseu', 'good', 'step', 'toward', 'end', 'end', 'ai', 'model', 'incorpor', 'domain', 'knowledg', 'librari', 'differenti', 'nonlinear', 'least', 'squar', 'nl', 'particularli', 'use', 'applic', 'like', 'robot', 'comput', 'vision', 'read', 'http', 'ai', 'facebook', 'com', 'blog', 'theseu', 'librari', 'encod', 'domain', 'knowledg', 'end', 'end', 'ai', 'model']"
150,164,164,thegreatjoke,w4n6gf,[D] Super-resolution / image reconstruction aided by reference images,"Are there any models that can say, restore or upscale an image given other references as input? For example, say you have a portrait photo that needs to be improved. You may also have 10 other portraits of the same person, which should be useful information to the model in solving its task accurately.",1,5,2022-07-21 20:58:12, d  super resolution   image reconstruction aided by reference images,are there any models that can say  restore or upscale an image given other references as input  for example  say you have a portrait photo that needs to be improved  you may also have  other portraits of the same person  which should be useful information to the model in solving its task accurately ,models say restore upscale image given references input example say portrait photo needs improved may also portraits person useful information model solving task accurately,super resolution image reconstruction aided reference images,super resolution image reconstruction aided reference imagesmodels say restore upscale image given references input example say portrait photo needs improved may also portraits person useful information model solving task accurately,"['super', 'resolution', 'image', 'reconstruction', 'aided', 'reference', 'imagesmodels', 'say', 'restore', 'upscale', 'image', 'given', 'references', 'input', 'example', 'say', 'portrait', 'photo', 'needs', 'improved', 'may', 'also', 'portraits', 'person', 'useful', 'information', 'model', 'solving', 'task', 'accurately']","['super', 'resolut', 'imag', 'reconstruct', 'aid', 'refer', 'imagesmodel', 'say', 'restor', 'upscal', 'imag', 'given', 'refer', 'input', 'exampl', 'say', 'portrait', 'photo', 'need', 'improv', 'may', 'also', 'portrait', 'person', 'use', 'inform', 'model', 'solv', 'task', 'accur']"
151,165,165,kuonlp,w4pbh9,[D] How do collaborations materialize in your research group?,"Typically, I would come up with a problem (""Introduction""), research about it (""Previous work""), and develop a solution (""Methods"", ""Experiments""). Then, my PI would point out mistakes, raise some questions, polish the paper, etc. With this workflow, I ended up with various two-author papers (me and my PI). There are obvious benefits of including more people in the work/papers, such as having more points of views and having more time to do other things given that the work has been split. But how to do that in practice? I would like to hear how this is done in other groups.

For instance, say you come up with a method and need to conduct other experiments to compare it with other methods. You could share your code and let your colleagues write the experiments following the same style and write and execute those experiments.

Another potentially useful idea is to have regular meetings to tell each other what you're doing and what problems you are facing.",3,3,2022-07-21 22:24:51, d  how do collaborations materialize in your research group ,typically  i would come up with a problem  introduction   research about it  previous work   and develop a solution  methods  experiments   then  my pi would point out mistakes  raise some questions  polish the paper  etc  with this workflow  i ended up with various two author papers  me and my pi   there are obvious benefits of including more people in the work papers  such as having more points of views and having more time to do other things given that the work has been split  but how to do that in practice  i would like to hear how this is done in other groups for instance  say you come up with a method and need to conduct other experiments to compare it with other methods  you could share your code and let your colleagues write the experiments following the same style and write and execute those experiments another potentially useful idea is to have regular meetings to tell each other what you re doing and what problems you are facing ,typically would come problem introduction research previous work develop solution methods experiments pi would point mistakes raise questions polish paper etc workflow ended various two author papers pi obvious benefits including people work papers points views time things given work split practice would like hear done groups instance say come method need conduct experiments compare methods could share code let colleagues write experiments following style write execute experiments another potentially useful idea regular meetings tell problems facing,collaborations materialize research group,collaborations materialize research grouptypically would come problem introduction research previous work develop solution methods experiments pi would point mistakes raise questions polish paper etc workflow ended various two author papers pi obvious benefits including people work papers points views time things given work split practice would like hear done groups instance say come method need conduct experiments compare methods could share code let colleagues write experiments following style write execute experiments another potentially useful idea regular meetings tell problems facing,"['collaborations', 'materialize', 'research', 'grouptypically', 'would', 'come', 'problem', 'introduction', 'research', 'previous', 'work', 'develop', 'solution', 'methods', 'experiments', 'pi', 'would', 'point', 'mistakes', 'raise', 'questions', 'polish', 'paper', 'etc', 'workflow', 'ended', 'various', 'two', 'author', 'papers', 'pi', 'obvious', 'benefits', 'including', 'people', 'work', 'papers', 'points', 'views', 'time', 'things', 'given', 'work', 'split', 'practice', 'would', 'like', 'hear', 'done', 'groups', 'instance', 'say', 'come', 'method', 'need', 'conduct', 'experiments', 'compare', 'methods', 'could', 'share', 'code', 'let', 'colleagues', 'write', 'experiments', 'following', 'style', 'write', 'execute', 'experiments', 'another', 'potentially', 'useful', 'idea', 'regular', 'meetings', 'tell', 'problems', 'facing']","['collabor', 'materi', 'research', 'grouptyp', 'would', 'come', 'problem', 'introduct', 'research', 'previou', 'work', 'develop', 'solut', 'method', 'experi', 'pi', 'would', 'point', 'mistak', 'rais', 'question', 'polish', 'paper', 'etc', 'workflow', 'end', 'variou', 'two', 'author', 'paper', 'pi', 'obviou', 'benefit', 'includ', 'peopl', 'work', 'paper', 'point', 'view', 'time', 'thing', 'given', 'work', 'split', 'practic', 'would', 'like', 'hear', 'done', 'group', 'instanc', 'say', 'come', 'method', 'need', 'conduct', 'experi', 'compar', 'method', 'could', 'share', 'code', 'let', 'colleagu', 'write', 'experi', 'follow', 'style', 'write', 'execut', 'experi', 'anoth', 'potenti', 'use', 'idea', 'regular', 'meet', 'tell', 'problem', 'face']"
152,166,166,Wiskkey,w3ry4o,"[N] OpenAI blog post ""DALL·E Now Available in Beta"". DALL-E 2 is a text-to-image system. Pricing details are included. Commercial usage is now allowed.","[OpenAI blog post](https://openai.com/blog/dall-e-now-available-in-beta/).

[How DALL·E Credits Work](https://help.openai.com/en/articles/6399305-how-dall-e-credits-work).

[Links to DALL-E Content policy and Terms of use, along with older archived versions](https://www.reddit.com/r/dalle2/comments/w3r9cf/comment/igxy1jc/).",44,277,2022-07-20 20:18:18, n  openai blog post dall e now available in beta  dall e  is a text to image system  pricing details are included  commercial usage is now allowed , openai blog post  https  how dall e credits work  https  links to dall e content policy and terms of use  along with older archived versions  https   www reddit com r dalle comments wrcf comment igxyjc   ,openai blog post https dall e credits work https links dall e content policy terms use along older archived versions https www reddit com r dalle comments wrcf comment igxyjc,n openai blog post dall e available beta dall e text image system pricing details included commercial usage allowed,n openai blog post dall e available beta dall e text image system pricing details included commercial usage allowedopenai blog post https dall e credits work https links dall e content policy terms use along older archived versions https www reddit com r dalle comments wrcf comment igxyjc,"['n', 'openai', 'blog', 'post', 'dall', 'e', 'available', 'beta', 'dall', 'e', 'text', 'image', 'system', 'pricing', 'details', 'included', 'commercial', 'usage', 'allowedopenai', 'blog', 'post', 'https', 'dall', 'e', 'credits', 'work', 'https', 'links', 'dall', 'e', 'content', 'policy', 'terms', 'use', 'along', 'older', 'archived', 'versions', 'https', 'www', 'reddit', 'com', 'r', 'dalle', 'comments', 'wrcf', 'comment', 'igxyjc']","['n', 'openai', 'blog', 'post', 'dall', 'e', 'avail', 'beta', 'dall', 'e', 'text', 'imag', 'system', 'price', 'detail', 'includ', 'commerci', 'usag', 'allowedopenai', 'blog', 'post', 'http', 'dall', 'e', 'credit', 'work', 'http', 'link', 'dall', 'e', 'content', 'polici', 'term', 'use', 'along', 'older', 'archiv', 'version', 'http', 'www', 'reddit', 'com', 'r', 'dall', 'comment', 'wrcf', 'comment', 'igxyjc']"
153,167,167,julbern,w4gryw,[R] Robust SDE-Based Variational Formulations for Solving Linear PDEs via Deep Learning,"Published at [ICML 2022](https://proceedings.mlr.press/v162/richter22a.html) (If you are also at the conference, feel free to reach out and we can talk about our work.)

[PDF on ResearchGate](https://www.researchgate.net/publication/362158090_Robust_SDE-Based_Variational_Formulations_for_Solving_Linear_PDEs_via_Deep_Learning) / [Poster](https://www.researchgate.net/publication/362158073_Poster_-_Robust_SDE-Based_Variational_Formulations_for_Solving_Linear_PDEs_via_Deep_Learning)

**Abstract:** The combination of Monte Carlo methods and deep learning has recently led to efficient algorithms for solving partial differential equations (PDEs) in high dimensions. Related learning problems are often stated as variational formulations based on associated stochastic differential equations (SDEs), which allow the minimization of corresponding losses using gradient-based optimization methods. In respective numerical implementations it is therefore crucial to rely on adequate gradient estimators that exhibit low variance in order to reach convergence accurately and swiftly. In this article, we rigorously investigate corresponding numerical aspects that appear in the context of linear Kolmogorov PDEs. In particular, we systematically compare existing deep learning approaches and provide theoretical explanations for their performances. Subsequently, we suggest novel methods that can be shown to be more robust both theoretically and numerically, leading to substantial performance improvements.",0,6,2022-07-21 16:30:52, r  robust sde based variational formulations for solving linear pdes via deep learning,published at  icml   https  pdf on researchgate  https   abstract    the combination of monte carlo methods and deep learning has recently led to efficient algorithms for solving partial differential equations  pdes  in high dimensions  related learning problems are often stated as variational formulations based on associated stochastic differential equations  sdes   which allow the minimization of corresponding losses using gradient based optimization methods  in respective numerical implementations it is therefore crucial to rely on adequate gradient estimators that exhibit low variance in order to reach convergence accurately and swiftly  in this article  we rigorously investigate corresponding numerical aspects that appear in the context of linear kolmogorov pdes  in particular  we systematically compare existing deep learning approaches and provide theoretical explanations for their performances  subsequently  we suggest novel methods that can be shown to be more robust both theoretically and numerically  leading to substantial performance improvements ,published icml https pdf researchgate https abstract combination monte carlo methods deep learning recently led efficient algorithms solving partial differential equations pdes high dimensions related learning problems often stated variational formulations based associated stochastic differential equations sdes allow minimization corresponding losses using gradient based optimization methods respective numerical implementations therefore crucial rely adequate gradient estimators exhibit low variance order reach convergence accurately swiftly article rigorously investigate corresponding numerical aspects appear context linear kolmogorov pdes particular systematically compare existing deep learning approaches provide theoretical explanations performances subsequently suggest novel methods shown robust theoretically numerically leading substantial performance improvements,r robust sde based variational formulations solving linear pdes via deep learning,r robust sde based variational formulations solving linear pdes via deep learningpublished icml https pdf researchgate https abstract combination monte carlo methods deep learning recently led efficient algorithms solving partial differential equations pdes high dimensions related learning problems often stated variational formulations based associated stochastic differential equations sdes allow minimization corresponding losses using gradient based optimization methods respective numerical implementations therefore crucial rely adequate gradient estimators exhibit low variance order reach convergence accurately swiftly article rigorously investigate corresponding numerical aspects appear context linear kolmogorov pdes particular systematically compare existing deep learning approaches provide theoretical explanations performances subsequently suggest novel methods shown robust theoretically numerically leading substantial performance improvements,"['r', 'robust', 'sde', 'based', 'variational', 'formulations', 'solving', 'linear', 'pdes', 'via', 'deep', 'learningpublished', 'icml', 'https', 'pdf', 'researchgate', 'https', 'abstract', 'combination', 'monte', 'carlo', 'methods', 'deep', 'learning', 'recently', 'led', 'efficient', 'algorithms', 'solving', 'partial', 'differential', 'equations', 'pdes', 'high', 'dimensions', 'related', 'learning', 'problems', 'often', 'stated', 'variational', 'formulations', 'based', 'associated', 'stochastic', 'differential', 'equations', 'sdes', 'allow', 'minimization', 'corresponding', 'losses', 'using', 'gradient', 'based', 'optimization', 'methods', 'respective', 'numerical', 'implementations', 'therefore', 'crucial', 'rely', 'adequate', 'gradient', 'estimators', 'exhibit', 'low', 'variance', 'order', 'reach', 'convergence', 'accurately', 'swiftly', 'article', 'rigorously', 'investigate', 'corresponding', 'numerical', 'aspects', 'appear', 'context', 'linear', 'kolmogorov', 'pdes', 'particular', 'systematically', 'compare', 'existing', 'deep', 'learning', 'approaches', 'provide', 'theoretical', 'explanations', 'performances', 'subsequently', 'suggest', 'novel', 'methods', 'shown', 'robust', 'theoretically', 'numerically', 'leading', 'substantial', 'performance', 'improvements']","['r', 'robust', 'sde', 'base', 'variat', 'formul', 'solv', 'linear', 'pde', 'via', 'deep', 'learningpublish', 'icml', 'http', 'pdf', 'researchg', 'http', 'abstract', 'combin', 'mont', 'carlo', 'method', 'deep', 'learn', 'recent', 'led', 'effici', 'algorithm', 'solv', 'partial', 'differenti', 'equat', 'pde', 'high', 'dimens', 'relat', 'learn', 'problem', 'often', 'state', 'variat', 'formul', 'base', 'associ', 'stochast', 'differenti', 'equat', 'sde', 'allow', 'minim', 'correspond', 'loss', 'use', 'gradient', 'base', 'optim', 'method', 'respect', 'numer', 'implement', 'therefor', 'crucial', 'reli', 'adequ', 'gradient', 'estim', 'exhibit', 'low', 'varianc', 'order', 'reach', 'converg', 'accur', 'swiftli', 'articl', 'rigor', 'investig', 'correspond', 'numer', 'aspect', 'appear', 'context', 'linear', 'kolmogorov', 'pde', 'particular', 'systemat', 'compar', 'exist', 'deep', 'learn', 'approach', 'provid', 'theoret', 'explan', 'perform', 'subsequ', 'suggest', 'novel', 'method', 'shown', 'robust', 'theoret', 'numer', 'lead', 'substanti', 'perform', 'improv']"
154,168,168,Impressive-Mirror430,w45l5g,[R] High-Resolution Virtual Try-On with Misalignment and Occlusion-Handled Conditions,"&#x200B;

https://preview.redd.it/vqxmxahu7uc91.png?width=5400&format=png&auto=webp&s=bea0ff23fc42d13b1d73d04c8b4c3236fab16a35",5,36,2022-07-21 06:04:33, r  high resolution virtual try on with misalignment and occlusion handled conditions,  xb https   preview redd it vqxmxahuuc png width  format png auto webp s beafffcdbddcbcfaba,xb https preview redd vqxmxahuuc png width format png auto webp beafffcdbddcbcfaba,r high resolution virtual try misalignment occlusion handled conditions,r high resolution virtual try misalignment occlusion handled conditionsxb https preview redd vqxmxahuuc png width format png auto webp beafffcdbddcbcfaba,"['r', 'high', 'resolution', 'virtual', 'try', 'misalignment', 'occlusion', 'handled', 'conditionsxb', 'https', 'preview', 'redd', 'vqxmxahuuc', 'png', 'width', 'format', 'png', 'auto', 'webp', 'beafffcdbddcbcfaba']","['r', 'high', 'resolut', 'virtual', 'tri', 'misalign', 'occlus', 'handl', 'conditionsxb', 'http', 'preview', 'redd', 'vqxmxahuuc', 'png', 'width', 'format', 'png', 'auto', 'webp', 'beafffcdbddcbcfaba']"
155,169,169,Singularian2501,w3w8lh,[R] Beyond neural scaling laws: beating power law scaling via data pruning - Meta AI,"Paper: [https://arxiv.org/abs/2206.14486](https://arxiv.org/abs/2206.14486)

Abstract:

>Widely observed neural scaling laws, in which error falls off as a power of the training set size, model size, or both, have driven substantial performance improvements in deep learning. However, these improvements through scaling alone require considerable costs in compute and energy. Here we focus on the scaling of error with dataset size and show how both in theory and practice we can **break beyond power law scaling and reduce it to exponential scaling** instead if we have access to a high-quality data pruning metric that ranks the order in which training examples should be discarded to achieve any pruned dataset size. We then test this **new exponential scaling prediction** with pruned dataset size empirically, and indeed observe **better than power law scaling performance on ResNets trained on CIFAR-10, SVHN, and ImageNet**. Given the importance of finding high-quality pruning metrics, we perform the first large-scale benchmarking study of ten different data pruning metrics on ImageNet. We find most existing high performing metrics scale poorly to ImageNet, while the best are computationally intensive and require labels for every image. We therefore **developed a new simple, cheap and scalable self-supervised pruning metric that demonstrates comparable performance to the best supervised metrics**. Overall, our work suggests that the discovery of good data-pruning metrics may provide a viable path forward to **substantially improved neural scaling laws, thereby reducing the resource costs of modern deep learning**.       

https://preview.redd.it/aii70mn86sc91.jpg?width=1126&format=pjpg&auto=webp&s=4a6dfd713384c0016d5433feba7028f8173e3347

https://preview.redd.it/lqj66on86sc91.jpg?width=1118&format=pjpg&auto=webp&s=7795db10157b2fb59b8778725643ad7ef3f47462",16,98,2022-07-20 23:13:22, r  beyond neural scaling laws  beating power law scaling via data pruning   meta ai,paper   https abstract  widely observed neural scaling laws  in which error falls off as a power of the training set size  model size  or both  have driven substantial performance improvements in deep learning  however  these improvements through scaling alone require considerable costs in compute and energy  here we focus on the scaling of error with dataset size and show how both in theory and practice we can   break beyond power law scaling and reduce it to exponential scaling   instead if we have access to a high quality data pruning metric that ranks the order in which training examples should be discarded to achieve any pruned dataset size  we then test this   new exponential scaling prediction   with pruned dataset size empirically  and indeed observe   better than power law scaling performance on resnets trained on cifar   svhn  and imagenet    given the importance of finding high quality pruning metrics  we perform the first large scale benchmarking study of ten different data pruning metrics on imagenet  we find most existing high performing metrics scale poorly to imagenet  while the best are computationally intensive and require labels for every image  we therefore   developed a new simple  cheap and scalable self supervised pruning metric that demonstrates comparable performance to the best supervised metrics    overall  our work suggests that the discovery of good data pruning metrics may provide a viable path forward to   substantially improved neural scaling laws  thereby reducing the resource costs of modern deep learning          https https   preview redd it lqjonsc jpg width  format pjpg auto webp s dbbfbbadeff,paper https abstract widely observed neural scaling laws error falls power training set size model size driven substantial performance improvements deep learning however improvements scaling alone require considerable costs compute energy focus scaling error dataset size show theory practice break beyond power law scaling reduce exponential scaling instead access high quality data pruning metric ranks order training examples discarded achieve pruned dataset size test exponential scaling prediction pruned dataset size empirically indeed observe better power law scaling performance resnets trained cifar svhn imagenet given importance finding high quality pruning metrics perform first large scale benchmarking study ten different data pruning metrics imagenet find existing high performing metrics scale poorly imagenet best computationally intensive require labels every image therefore developed simple cheap scalable self supervised pruning metric demonstrates comparable performance best supervised metrics overall work suggests discovery good data pruning metrics may provide viable path forward substantially improved neural scaling laws thereby reducing resource costs modern deep learning https https preview redd lqjonsc jpg width format pjpg auto webp dbbfbbadeff,r beyond neural scaling laws beating power law scaling via data pruning meta ai,r beyond neural scaling laws beating power law scaling via data pruning meta aipaper https abstract widely observed neural scaling laws error falls power training set size model size driven substantial performance improvements deep learning however improvements scaling alone require considerable costs compute energy focus scaling error dataset size show theory practice break beyond power law scaling reduce exponential scaling instead access high quality data pruning metric ranks order training examples discarded achieve pruned dataset size test exponential scaling prediction pruned dataset size empirically indeed observe better power law scaling performance resnets trained cifar svhn imagenet given importance finding high quality pruning metrics perform first large scale benchmarking study ten different data pruning metrics imagenet find existing high performing metrics scale poorly imagenet best computationally intensive require labels every image therefore developed simple cheap scalable self supervised pruning metric demonstrates comparable performance best supervised metrics overall work suggests discovery good data pruning metrics may provide viable path forward substantially improved neural scaling laws thereby reducing resource costs modern deep learning https https preview redd lqjonsc jpg width format pjpg auto webp dbbfbbadeff,"['r', 'beyond', 'neural', 'scaling', 'laws', 'beating', 'power', 'law', 'scaling', 'via', 'data', 'pruning', 'meta', 'aipaper', 'https', 'abstract', 'widely', 'observed', 'neural', 'scaling', 'laws', 'error', 'falls', 'power', 'training', 'set', 'size', 'model', 'size', 'driven', 'substantial', 'performance', 'improvements', 'deep', 'learning', 'however', 'improvements', 'scaling', 'alone', 'require', 'considerable', 'costs', 'compute', 'energy', 'focus', 'scaling', 'error', 'dataset', 'size', 'show', 'theory', 'practice', 'break', 'beyond', 'power', 'law', 'scaling', 'reduce', 'exponential', 'scaling', 'instead', 'access', 'high', 'quality', 'data', 'pruning', 'metric', 'ranks', 'order', 'training', 'examples', 'discarded', 'achieve', 'pruned', 'dataset', 'size', 'test', 'exponential', 'scaling', 'prediction', 'pruned', 'dataset', 'size', 'empirically', 'indeed', 'observe', 'better', 'power', 'law', 'scaling', 'performance', 'resnets', 'trained', 'cifar', 'svhn', 'imagenet', 'given', 'importance', 'finding', 'high', 'quality', 'pruning', 'metrics', 'perform', 'first', 'large', 'scale', 'benchmarking', 'study', 'ten', 'different', 'data', 'pruning', 'metrics', 'imagenet', 'find', 'existing', 'high', 'performing', 'metrics', 'scale', 'poorly', 'imagenet', 'best', 'computationally', 'intensive', 'require', 'labels', 'every', 'image', 'therefore', 'developed', 'simple', 'cheap', 'scalable', 'self', 'supervised', 'pruning', 'metric', 'demonstrates', 'comparable', 'performance', 'best', 'supervised', 'metrics', 'overall', 'work', 'suggests', 'discovery', 'good', 'data', 'pruning', 'metrics', 'may', 'provide', 'viable', 'path', 'forward', 'substantially', 'improved', 'neural', 'scaling', 'laws', 'thereby', 'reducing', 'resource', 'costs', 'modern', 'deep', 'learning', 'https', 'https', 'preview', 'redd', 'lqjonsc', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'dbbfbbadeff']","['r', 'beyond', 'neural', 'scale', 'law', 'beat', 'power', 'law', 'scale', 'via', 'data', 'prune', 'meta', 'aipap', 'http', 'abstract', 'wide', 'observ', 'neural', 'scale', 'law', 'error', 'fall', 'power', 'train', 'set', 'size', 'model', 'size', 'driven', 'substanti', 'perform', 'improv', 'deep', 'learn', 'howev', 'improv', 'scale', 'alon', 'requir', 'consider', 'cost', 'comput', 'energi', 'focu', 'scale', 'error', 'dataset', 'size', 'show', 'theori', 'practic', 'break', 'beyond', 'power', 'law', 'scale', 'reduc', 'exponenti', 'scale', 'instead', 'access', 'high', 'qualiti', 'data', 'prune', 'metric', 'rank', 'order', 'train', 'exampl', 'discard', 'achiev', 'prune', 'dataset', 'size', 'test', 'exponenti', 'scale', 'predict', 'prune', 'dataset', 'size', 'empir', 'inde', 'observ', 'better', 'power', 'law', 'scale', 'perform', 'resnet', 'train', 'cifar', 'svhn', 'imagenet', 'given', 'import', 'find', 'high', 'qualiti', 'prune', 'metric', 'perform', 'first', 'larg', 'scale', 'benchmark', 'studi', 'ten', 'differ', 'data', 'prune', 'metric', 'imagenet', 'find', 'exist', 'high', 'perform', 'metric', 'scale', 'poorli', 'imagenet', 'best', 'comput', 'intens', 'requir', 'label', 'everi', 'imag', 'therefor', 'develop', 'simpl', 'cheap', 'scalabl', 'self', 'supervis', 'prune', 'metric', 'demonstr', 'compar', 'perform', 'best', 'supervis', 'metric', 'overal', 'work', 'suggest', 'discoveri', 'good', 'data', 'prune', 'metric', 'may', 'provid', 'viabl', 'path', 'forward', 'substanti', 'improv', 'neural', 'scale', 'law', 'therebi', 'reduc', 'resourc', 'cost', 'modern', 'deep', 'learn', 'http', 'http', 'preview', 'redd', 'lqjonsc', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'dbbfbbadeff']"
156,170,170,Successful_Paper1542,w4h3l4,"[D] Why is my proceedings paper not shown in google scholar, or even google search?","Hello guys, I’m a fresh PhD student. Last month we have a paper accepted by a conference and can be found in its proceedings. However, it didn’t show in my google scholar, while other papers in the same proceedings are. I’m wonder why is this and how should I fix it?",5,2,2022-07-21 16:45:19, d  why is my proceedings paper not shown in google scholar  or even google search ,hello guys  i m a fresh phd student  last month we have a paper accepted by a conference and can be found in its proceedings  however  it didn t show in my google scholar  while other papers in the same proceedings are  i m wonder why is this and how should i fix it ,hello guys fresh phd student last month paper accepted conference found proceedings however show google scholar papers proceedings wonder fix,proceedings paper shown google scholar even google search,proceedings paper shown google scholar even google searchhello guys fresh phd student last month paper accepted conference found proceedings however show google scholar papers proceedings wonder fix,"['proceedings', 'paper', 'shown', 'google', 'scholar', 'even', 'google', 'searchhello', 'guys', 'fresh', 'phd', 'student', 'last', 'month', 'paper', 'accepted', 'conference', 'found', 'proceedings', 'however', 'show', 'google', 'scholar', 'papers', 'proceedings', 'wonder', 'fix']","['proceed', 'paper', 'shown', 'googl', 'scholar', 'even', 'googl', 'searchhello', 'guy', 'fresh', 'phd', 'student', 'last', 'month', 'paper', 'accept', 'confer', 'found', 'proceed', 'howev', 'show', 'googl', 'scholar', 'paper', 'proceed', 'wonder', 'fix']"
157,171,171,ethansmith2000,w4838n,[D] How useful are torchvision augmentations? is there a strategy to using some over others?,"There's a lot to try, but also quite time consuming to brute-force compare them all, so I was wondering if there's pros and cons to each transformation for certain contexts. And if they're useful for generating images as well.",9,4,2022-07-21 08:13:56, d  how useful are torchvision augmentations  is there a strategy to using some over others ,there s a lot to try  but also quite time consuming to brute force compare them all  so i was wondering if there s pros and cons to each transformation for certain contexts  and if they re useful for generating images as well ,lot try also quite time consuming brute force compare wondering pros cons transformation certain contexts useful generating images well,useful torchvision augmentations strategy using others,useful torchvision augmentations strategy using otherslot try also quite time consuming brute force compare wondering pros cons transformation certain contexts useful generating images well,"['useful', 'torchvision', 'augmentations', 'strategy', 'using', 'otherslot', 'try', 'also', 'quite', 'time', 'consuming', 'brute', 'force', 'compare', 'wondering', 'pros', 'cons', 'transformation', 'certain', 'contexts', 'useful', 'generating', 'images', 'well']","['use', 'torchvis', 'augment', 'strategi', 'use', 'otherslot', 'tri', 'also', 'quit', 'time', 'consum', 'brute', 'forc', 'compar', 'wonder', 'pro', 'con', 'transform', 'certain', 'context', 'use', 'gener', 'imag', 'well']"
158,172,172,JClub,w4eq0z,"[D] In an MLP model, if I disable the gradient in some random dense layers, is it normal for the training time to remain the same?","For context, I'm training a model with LoRA layers in Embedding and Linear layers but the training time does not decrease, although I am using way less trainable weights.",9,1,2022-07-21 14:51:08, d  in an mlp model  if i disable the gradient in some random dense layers  is it normal for the training time to remain the same ,for context  i m training a model with lora layers in embedding and linear layers but the training time does not decrease  although i am using way less trainable weights ,context training model lora layers embedding linear layers training time decrease although using way less trainable weights,mlp model disable gradient random dense layers normal training time remain,mlp model disable gradient random dense layers normal training time remaincontext training model lora layers embedding linear layers training time decrease although using way less trainable weights,"['mlp', 'model', 'disable', 'gradient', 'random', 'dense', 'layers', 'normal', 'training', 'time', 'remaincontext', 'training', 'model', 'lora', 'layers', 'embedding', 'linear', 'layers', 'training', 'time', 'decrease', 'although', 'using', 'way', 'less', 'trainable', 'weights']","['mlp', 'model', 'disabl', 'gradient', 'random', 'dens', 'layer', 'normal', 'train', 'time', 'remaincontext', 'train', 'model', 'lora', 'layer', 'embed', 'linear', 'layer', 'train', 'time', 'decreas', 'although', 'use', 'way', 'less', 'trainabl', 'weight']"
159,173,173,fedegarzar,w39rb8,[P] Fastest and most accurate version of the Exponential Smoothing (ETS) Algorithm for Python,"Recently, the Nixtla team released a new version of ETS for Python. 

The implementation, optimized using numba, is 400% faster than StatsModels and 1.5x faster than R's, with improved accuracy and robustness.  

With the Ray integration of StatsForecast for distributed computing, the ETS can fit 1,000,000 series in under 5 min for non-seasonal data and 25 minutes for seasonal data. 

The ETS algorithm is especially suited for data with seasonality and trend. ETS computes a weighted average over all observations in the input time series dataset as its prediction. In contrast to moving average methods with constant weights, ETS weights exponentially decrease over time, capturing long-term dependencies while prioritizing new observations.

Please star ⭐️ the repo if you like it. :)

[https://github.com/Nixtla/statsforecast](https://github.com/Nixtla/statsforecast)

&#x200B;

https://preview.redd.it/lsc0igzdomc91.png?width=1700&format=png&auto=webp&s=341f0a69225a917edd4a15f37416b4b52f0a4726

https://preview.redd.it/uocfwrzfomc91.png?width=1574&format=png&auto=webp&s=eee58870c325dee50c6e544178f2ae04a546d2e2",19,173,2022-07-20 04:44:22, p  fastest and most accurate version of the exponential smoothing  ets  algorithm for python,recently  the nixtla team released a new version of ets for python  the implementation  optimized using numba  is   faster than statsmodels and  x faster than r s  with improved accuracy and robustness   with the ray integration of statsforecast for distributed computing  the ets can fit    series in under  min for non seasonal data and  minutes for seasonal data  the ets algorithm is especially suited for data with seasonality and trend  ets computes a weighted average over all observations in the input time series dataset as its prediction  in contrast to moving average methods with constant weights  ets weights exponentially decrease over time  capturing long term dependencies while prioritizing new observations please star    the repo if you like it     https   xb https https   preview redd it uocfwrzfomc png width  format png auto webp s eeecdeecefaeade,recently nixtla team released version ets python implementation optimized using numba faster statsmodels x faster r improved accuracy robustness ray integration statsforecast distributed computing ets fit series min non seasonal data minutes seasonal data ets algorithm especially suited data seasonality trend ets computes weighted average observations input time series dataset prediction contrast moving average methods constant weights ets weights exponentially decrease time capturing long term dependencies prioritizing observations please star repo like https xb https https preview redd uocfwrzfomc png width format png auto webp eeecdeecefaeade,p fastest accurate version exponential smoothing ets algorithm python,p fastest accurate version exponential smoothing ets algorithm pythonrecently nixtla team released version ets python implementation optimized using numba faster statsmodels x faster r improved accuracy robustness ray integration statsforecast distributed computing ets fit series min non seasonal data minutes seasonal data ets algorithm especially suited data seasonality trend ets computes weighted average observations input time series dataset prediction contrast moving average methods constant weights ets weights exponentially decrease time capturing long term dependencies prioritizing observations please star repo like https xb https https preview redd uocfwrzfomc png width format png auto webp eeecdeecefaeade,"['p', 'fastest', 'accurate', 'version', 'exponential', 'smoothing', 'ets', 'algorithm', 'pythonrecently', 'nixtla', 'team', 'released', 'version', 'ets', 'python', 'implementation', 'optimized', 'using', 'numba', 'faster', 'statsmodels', 'x', 'faster', 'r', 'improved', 'accuracy', 'robustness', 'ray', 'integration', 'statsforecast', 'distributed', 'computing', 'ets', 'fit', 'series', 'min', 'non', 'seasonal', 'data', 'minutes', 'seasonal', 'data', 'ets', 'algorithm', 'especially', 'suited', 'data', 'seasonality', 'trend', 'ets', 'computes', 'weighted', 'average', 'observations', 'input', 'time', 'series', 'dataset', 'prediction', 'contrast', 'moving', 'average', 'methods', 'constant', 'weights', 'ets', 'weights', 'exponentially', 'decrease', 'time', 'capturing', 'long', 'term', 'dependencies', 'prioritizing', 'observations', 'please', 'star', 'repo', 'like', 'https', 'xb', 'https', 'https', 'preview', 'redd', 'uocfwrzfomc', 'png', 'width', 'format', 'png', 'auto', 'webp', 'eeecdeecefaeade']","['p', 'fastest', 'accur', 'version', 'exponenti', 'smooth', 'et', 'algorithm', 'pythonrec', 'nixtla', 'team', 'releas', 'version', 'et', 'python', 'implement', 'optim', 'use', 'numba', 'faster', 'statsmodel', 'x', 'faster', 'r', 'improv', 'accuraci', 'robust', 'ray', 'integr', 'statsforecast', 'distribut', 'comput', 'et', 'fit', 'seri', 'min', 'non', 'season', 'data', 'minut', 'season', 'data', 'et', 'algorithm', 'especi', 'suit', 'data', 'season', 'trend', 'et', 'comput', 'weight', 'averag', 'observ', 'input', 'time', 'seri', 'dataset', 'predict', 'contrast', 'move', 'averag', 'method', 'constant', 'weight', 'et', 'weight', 'exponenti', 'decreas', 'time', 'captur', 'long', 'term', 'depend', 'priorit', 'observ', 'pleas', 'star', 'repo', 'like', 'http', 'xb', 'http', 'http', 'preview', 'redd', 'uocfwrzfomc', 'png', 'width', 'format', 'png', 'auto', 'webp', 'eeecdeecefaead']"
160,174,174,thejashGI,w3wmru,"[D] Minqi Jiang, UCL, on environment and curriculum design for general RL agents","Here is a [podcast episode](https://generallyintelligent.ai/podcast/2022-07-19-podcast-episode-19-minqi-jiang/) with Minqi Jiang where we discuss RL environment and curriculum design, open-endedness, emergent communication, and much more!",0,3,2022-07-20 23:30:00, d  minqi jiang  ucl  on environment and curriculum design for general rl agents,here is a  podcast episode  https   generallyintelligent ai podcast    podcast episode  minqi jiang   with minqi jiang where we discuss rl environment and curriculum design  open endedness  emergent communication  and much more ,podcast episode https generallyintelligent ai podcast podcast episode minqi jiang minqi jiang discuss rl environment curriculum design open endedness emergent communication much,minqi jiang ucl environment curriculum design general rl agents,minqi jiang ucl environment curriculum design general rl agentspodcast episode https generallyintelligent ai podcast podcast episode minqi jiang minqi jiang discuss rl environment curriculum design open endedness emergent communication much,"['minqi', 'jiang', 'ucl', 'environment', 'curriculum', 'design', 'general', 'rl', 'agentspodcast', 'episode', 'https', 'generallyintelligent', 'ai', 'podcast', 'podcast', 'episode', 'minqi', 'jiang', 'minqi', 'jiang', 'discuss', 'rl', 'environment', 'curriculum', 'design', 'open', 'endedness', 'emergent', 'communication', 'much']","['minqi', 'jiang', 'ucl', 'environ', 'curriculum', 'design', 'gener', 'rl', 'agentspodcast', 'episod', 'http', 'generallyintellig', 'ai', 'podcast', 'podcast', 'episod', 'minqi', 'jiang', 'minqi', 'jiang', 'discuss', 'rl', 'environ', 'curriculum', 'design', 'open', 'ended', 'emerg', 'commun', 'much']"
161,175,175,carubia,w31fpp,[D] Most important unsolved problems in AI research,"[Updated: items marked with * were added/updated based on the responses so far].

Suggesting this topic for discussion, as I am trying to identify the current most important unsolved problems in AI research. Below are a few proposed items that are top of mind for me, would appreciate any input (what to add or what to remove from the list) and relevant sources.

---

Compositionality*. Ability to perform symbolic operations, generalize, including learning from a relatively small set of samples, and get the most out of every sample (sample efficiency and few-shot learning), etc. Also includes the ability to learn by receiving explicit instructions. (e.g. https://arxiv.org/abs/2205.01128)

Multimodality*. Ability to process and relate information from multiple modalities, like text, audio, visual, etc.

Ability to match knowledge to context. For e.g. the text generated by the LLM is a great match for a sci-fi novel, but not as advice to a patient regarding their medical condition.

Uncertainty awareness*. Ability to characterize uncertainty relative to the similarity of the current observations to the training data, explain it to an observer, and adjust behavior if necessary. (https://arxiv.org/pdf/1809.07882.pdf)

Catastrophic forgetting. It is a known limitation to continual learning, however, it seems like the large-scale models show an indication of robustness. (http://www.cognitionresearch.org/papers/overview/sparchai.pdf)

Enabling robust continuous learning in deployment. The current paradigm separates training and inference, while in biology intelligent creatures are capable of continuous learning. 

Figuring out an approach for the messy middle.
- Low-level operations with a focus on a very narrow scope and maximum efficiency seem reasonably straightforward and enjoy growing application in the industry. Noise removing, pattern recognition, recommenders, etc. Specialized ANNs seem to have success there.
- High-level abstract reasoning is being explored by large language and multi-modal models. Like our explicit reasoning (solving a math problem, or learning to operate a new coffee machine) it is extremely powerful, but also slow and resource-intensive. (E.g. https://arxiv.org/abs/2207.05608)
- But there is that middle, as in driving, where we still do fairly complex operations with very high reliability, precision, and responsiveness, all with low cognitive load (figuratively “on autopilot”). 

Explainability* - enabling human experts to understand the underlying factors of why an AI decision has been made.
https://link.springer.com/chapter/10.1007/978-3-031-04083-2_2

Alignment* - ensuring that AI is properly aligned with human values. https://link.springer.com/article/10.1007/s11023-020-09539-2

Energy efficiency. The human brain is believed to consume tens of W of power (https://www.pnas.org/doi/10.1073/pnas.172399499) while less capable LLMs like GPT-3 require several kW (estimated as the power consumption of DGX A100 based on https://www.reddit.com/r/singularity/comments/inp025/if_you_want_to_run_your_own_full_gpt3_instance/). Two orders of magnitude more.",137,237,2022-07-19 22:39:44, d  most important unsolved problems in ai research, updated  items marked with   were added updated based on the responses so far  suggesting this topic for discussion  as i am trying to identify the current most important unsolved problems in ai research  below are a few proposed items that are top of mind for me  would appreciate any input  what to add or what to remove from the list  and relevant sources    compositionality   ability to perform symbolic operations  generalize  including learning from a relatively small set of samples  and get the most out of every sample  sample efficiency and few shot learning   etc  also includes the ability to learn by receiving explicit instructions   e g  https multimodality   ability to process and relate information from multiple modalities  like text  audio  visual  etc ability to match knowledge to context  for e g  the text generated by the llm is a great match for a sci fi novel  but not as advice to a patient regarding their medical condition uncertainty awareness   ability to characterize uncertainty relative to the similarity of the current observations to the training data  explain it to an observer  and adjust behavior if necessary   https catastrophic forgetting  it is a known limitation to continual learning  however  it seems like the large scale models show an indication of robustness   http enabling robust continuous learning in deployment  the current paradigm separates training and inference  while in biology intelligent creatures are capable of continuous learning  figuring out an approach for the messy middle   low level operations with a focus on a very narrow scope and maximum efficiency seem reasonably straightforward and enjoy growing application in the industry  noise removing  pattern recognition  recommenders  etc  specialized anns seem to have success there   high level abstract reasoning is being explored by large language and multi modal models  like our explicit reasoning  solving a math problem  or learning to operate a new coffee machine  it is extremely powerful  but also slow and resource intensive   e g  https   but there is that middle  as in driving  where we still do fairly complex operations with very high reliability  precision  and responsiveness  all with low cognitive load  figuratively  on autopilot    explainability    enabling human experts to understand the underlying factors of why an ai decision has been made https alignment    ensuring that ai is properly aligned with human values  https energy efficiency  the human brain is believed to consume tens of w of power  https   www pnas org doi   pnas   while less capable llms like gpt  require several kw  estimated as the power consumption of dgx a based on https   www reddit com r singularity comments inp if_you_want_to_run_your_own_full_gpt_instance    two orders of magnitude more ,updated items marked added updated based responses far suggesting topic discussion trying identify current important unsolved problems ai research proposed items top mind would appreciate input remove relevant sources compositionality ability perform symbolic operations generalize including learning relatively small set samples get every sample sample efficiency shot learning etc also includes ability learn receiving explicit instructions e g https multimodality ability process relate information multiple modalities like text audio visual etc ability match knowledge context e g text generated llm great match sci fi novel advice patient regarding medical condition uncertainty awareness ability characterize uncertainty relative similarity current observations training data explain observer adjust behavior necessary https catastrophic forgetting known limitation continual learning however seems like large scale models show indication robustness http enabling robust continuous learning deployment current paradigm separates training inference biology intelligent creatures capable continuous learning figuring approach messy middle low level operations focus narrow scope maximum efficiency seem reasonably straightforward enjoy growing application industry noise removing pattern recognition recommenders etc specialized anns seem success high level abstract reasoning explored large language multi modal models like explicit reasoning solving math problem learning operate coffee machine extremely powerful also slow resource intensive e g https middle driving still fairly complex operations high reliability precision responsiveness low cognitive load figuratively autopilot explainability enabling human experts understand underlying factors ai decision made https alignment ensuring ai properly aligned human values https energy efficiency human brain believed consume tens w power https www pnas org doi pnas less capable llms like gpt require several kw estimated power consumption dgx based https www reddit com r singularity comments inp if_you_want_to_run_your_own_full_gpt_instance two orders magnitude,important unsolved problems ai research,important unsolved problems ai researchupdated items marked added updated based responses far suggesting topic discussion trying identify current important unsolved problems ai research proposed items top mind would appreciate input remove relevant sources compositionality ability perform symbolic operations generalize including learning relatively small set samples get every sample sample efficiency shot learning etc also includes ability learn receiving explicit instructions e g https multimodality ability process relate information multiple modalities like text audio visual etc ability match knowledge context e g text generated llm great match sci fi novel advice patient regarding medical condition uncertainty awareness ability characterize uncertainty relative similarity current observations training data explain observer adjust behavior necessary https catastrophic forgetting known limitation continual learning however seems like large scale models show indication robustness http enabling robust continuous learning deployment current paradigm separates training inference biology intelligent creatures capable continuous learning figuring approach messy middle low level operations focus narrow scope maximum efficiency seem reasonably straightforward enjoy growing application industry noise removing pattern recognition recommenders etc specialized anns seem success high level abstract reasoning explored large language multi modal models like explicit reasoning solving math problem learning operate coffee machine extremely powerful also slow resource intensive e g https middle driving still fairly complex operations high reliability precision responsiveness low cognitive load figuratively autopilot explainability enabling human experts understand underlying factors ai decision made https alignment ensuring ai properly aligned human values https energy efficiency human brain believed consume tens w power https www pnas org doi pnas less capable llms like gpt require several kw estimated power consumption dgx based https www reddit com r singularity comments inp if_you_want_to_run_your_own_full_gpt_instance two orders magnitude,"['important', 'unsolved', 'problems', 'ai', 'researchupdated', 'items', 'marked', 'added', 'updated', 'based', 'responses', 'far', 'suggesting', 'topic', 'discussion', 'trying', 'identify', 'current', 'important', 'unsolved', 'problems', 'ai', 'research', 'proposed', 'items', 'top', 'mind', 'would', 'appreciate', 'input', 'remove', 'relevant', 'sources', 'compositionality', 'ability', 'perform', 'symbolic', 'operations', 'generalize', 'including', 'learning', 'relatively', 'small', 'set', 'samples', 'get', 'every', 'sample', 'sample', 'efficiency', 'shot', 'learning', 'etc', 'also', 'includes', 'ability', 'learn', 'receiving', 'explicit', 'instructions', 'e', 'g', 'https', 'multimodality', 'ability', 'process', 'relate', 'information', 'multiple', 'modalities', 'like', 'text', 'audio', 'visual', 'etc', 'ability', 'match', 'knowledge', 'context', 'e', 'g', 'text', 'generated', 'llm', 'great', 'match', 'sci', 'fi', 'novel', 'advice', 'patient', 'regarding', 'medical', 'condition', 'uncertainty', 'awareness', 'ability', 'characterize', 'uncertainty', 'relative', 'similarity', 'current', 'observations', 'training', 'data', 'explain', 'observer', 'adjust', 'behavior', 'necessary', 'https', 'catastrophic', 'forgetting', 'known', 'limitation', 'continual', 'learning', 'however', 'seems', 'like', 'large', 'scale', 'models', 'show', 'indication', 'robustness', 'http', 'enabling', 'robust', 'continuous', 'learning', 'deployment', 'current', 'paradigm', 'separates', 'training', 'inference', 'biology', 'intelligent', 'creatures', 'capable', 'continuous', 'learning', 'figuring', 'approach', 'messy', 'middle', 'low', 'level', 'operations', 'focus', 'narrow', 'scope', 'maximum', 'efficiency', 'seem', 'reasonably', 'straightforward', 'enjoy', 'growing', 'application', 'industry', 'noise', 'removing', 'pattern', 'recognition', 'recommenders', 'etc', 'specialized', 'anns', 'seem', 'success', 'high', 'level', 'abstract', 'reasoning', 'explored', 'large', 'language', 'multi', 'modal', 'models', 'like', 'explicit', 'reasoning', 'solving', 'math', 'problem', 'learning', 'operate', 'coffee', 'machine', 'extremely', 'powerful', 'also', 'slow', 'resource', 'intensive', 'e', 'g', 'https', 'middle', 'driving', 'still', 'fairly', 'complex', 'operations', 'high', 'reliability', 'precision', 'responsiveness', 'low', 'cognitive', 'load', 'figuratively', 'autopilot', 'explainability', 'enabling', 'human', 'experts', 'understand', 'underlying', 'factors', 'ai', 'decision', 'made', 'https', 'alignment', 'ensuring', 'ai', 'properly', 'aligned', 'human', 'values', 'https', 'energy', 'efficiency', 'human', 'brain', 'believed', 'consume', 'tens', 'w', 'power', 'https', 'www', 'pnas', 'org', 'doi', 'pnas', 'less', 'capable', 'llms', 'like', 'gpt', 'require', 'several', 'kw', 'estimated', 'power', 'consumption', 'dgx', 'based', 'https', 'www', 'reddit', 'com', 'r', 'singularity', 'comments', 'inp', 'if_you_want_to_run_your_own_full_gpt_instance', 'two', 'orders', 'magnitude']","['import', 'unsolv', 'problem', 'ai', 'researchupd', 'item', 'mark', 'ad', 'updat', 'base', 'respons', 'far', 'suggest', 'topic', 'discuss', 'tri', 'identifi', 'current', 'import', 'unsolv', 'problem', 'ai', 'research', 'propos', 'item', 'top', 'mind', 'would', 'appreci', 'input', 'remov', 'relev', 'sourc', 'composition', 'abil', 'perform', 'symbol', 'oper', 'gener', 'includ', 'learn', 'rel', 'small', 'set', 'sampl', 'get', 'everi', 'sampl', 'sampl', 'effici', 'shot', 'learn', 'etc', 'also', 'includ', 'abil', 'learn', 'receiv', 'explicit', 'instruct', 'e', 'g', 'http', 'multimod', 'abil', 'process', 'relat', 'inform', 'multipl', 'modal', 'like', 'text', 'audio', 'visual', 'etc', 'abil', 'match', 'knowledg', 'context', 'e', 'g', 'text', 'gener', 'llm', 'great', 'match', 'sci', 'fi', 'novel', 'advic', 'patient', 'regard', 'medic', 'condit', 'uncertainti', 'awar', 'abil', 'character', 'uncertainti', 'rel', 'similar', 'current', 'observ', 'train', 'data', 'explain', 'observ', 'adjust', 'behavior', 'necessari', 'http', 'catastroph', 'forget', 'known', 'limit', 'continu', 'learn', 'howev', 'seem', 'like', 'larg', 'scale', 'model', 'show', 'indic', 'robust', 'http', 'enabl', 'robust', 'continu', 'learn', 'deploy', 'current', 'paradigm', 'separ', 'train', 'infer', 'biolog', 'intellig', 'creatur', 'capabl', 'continu', 'learn', 'figur', 'approach', 'messi', 'middl', 'low', 'level', 'oper', 'focu', 'narrow', 'scope', 'maximum', 'effici', 'seem', 'reason', 'straightforward', 'enjoy', 'grow', 'applic', 'industri', 'nois', 'remov', 'pattern', 'recognit', 'recommend', 'etc', 'special', 'ann', 'seem', 'success', 'high', 'level', 'abstract', 'reason', 'explor', 'larg', 'languag', 'multi', 'modal', 'model', 'like', 'explicit', 'reason', 'solv', 'math', 'problem', 'learn', 'oper', 'coffe', 'machin', 'extrem', 'power', 'also', 'slow', 'resourc', 'intens', 'e', 'g', 'http', 'middl', 'drive', 'still', 'fairli', 'complex', 'oper', 'high', 'reliabl', 'precis', 'respons', 'low', 'cognit', 'load', 'figur', 'autopilot', 'explain', 'enabl', 'human', 'expert', 'understand', 'underli', 'factor', 'ai', 'decis', 'made', 'http', 'align', 'ensur', 'ai', 'properli', 'align', 'human', 'valu', 'http', 'energi', 'effici', 'human', 'brain', 'believ', 'consum', 'ten', 'w', 'power', 'http', 'www', 'pna', 'org', 'doi', 'pna', 'less', 'capabl', 'llm', 'like', 'gpt', 'requir', 'sever', 'kw', 'estim', 'power', 'consumpt', 'dgx', 'base', 'http', 'www', 'reddit', 'com', 'r', 'singular', 'comment', 'inp', 'if_you_want_to_run_your_own_full_gpt_inst', 'two', 'order', 'magnitud']"
162,176,176,Studyr3ddit,w397qc,"[D] Best practice and tips & tricks to write scientific papers in LaTeX, with figures generated in Python, rapid prototyping in jupyter, and running larger experiments on supercomputers.","I've been using Jupyter, and honestly, it is pretty good for rapid prototyping however it falls apart when I try to follow proper software engineering practices such as abstraction and encapsulation. Downloading a jupyter notebook as python code is honestly so dirty and there is a bunch of metadata that is not necessary. For the longest time, it was also not practical to upload a jupyter notebook to a version control system. I also find that I spend a lot of energy transferring files, scaling up, and moving my codebase over to a supercomputer to run more extensive experiments with more trials. 

So, I'm wondering what the best practices are for researchers following proper software engineering practices while scaling up to run larger experiments with more trials and keeping track of log files, model zoos, transferring figures to latex etc...",14,44,2022-07-20 04:18:01, d  best practice and tips   tricks to write scientific papers in latex  with figures generated in python  rapid prototyping in jupyter  and running larger experiments on supercomputers ,i ve been using jupyter  and honestly  it is pretty good for rapid prototyping however it falls apart when i try to follow proper software engineering practices such as abstraction and encapsulation  downloading a jupyter notebook as python code is honestly so dirty and there is a bunch of metadata that is not necessary  for the longest time  it was also not practical to upload a jupyter notebook to a version control system  i also find that i spend a lot of energy transferring files  scaling up  and moving my codebase over to a supercomputer to run more extensive experiments with more trials  so  i m wondering what the best practices are for researchers following proper software engineering practices while scaling up to run larger experiments with more trials and keeping track of log files  model zoos  transferring figures to latex etc   ,using jupyter honestly pretty good rapid prototyping however falls apart try follow proper software engineering practices abstraction encapsulation downloading jupyter notebook python code honestly dirty bunch metadata necessary longest time also practical upload jupyter notebook version control system also find spend lot energy transferring files scaling moving codebase supercomputer run extensive experiments trials wondering best practices researchers following proper software engineering practices scaling run larger experiments trials keeping track log files model zoos transferring figures latex etc,best practice tips tricks write scientific papers latex figures generated python rapid prototyping jupyter running larger experiments supercomputers,best practice tips tricks write scientific papers latex figures generated python rapid prototyping jupyter running larger experiments supercomputersusing jupyter honestly pretty good rapid prototyping however falls apart try follow proper software engineering practices abstraction encapsulation downloading jupyter notebook python code honestly dirty bunch metadata necessary longest time also practical upload jupyter notebook version control system also find spend lot energy transferring files scaling moving codebase supercomputer run extensive experiments trials wondering best practices researchers following proper software engineering practices scaling run larger experiments trials keeping track log files model zoos transferring figures latex etc,"['best', 'practice', 'tips', 'tricks', 'write', 'scientific', 'papers', 'latex', 'figures', 'generated', 'python', 'rapid', 'prototyping', 'jupyter', 'running', 'larger', 'experiments', 'supercomputersusing', 'jupyter', 'honestly', 'pretty', 'good', 'rapid', 'prototyping', 'however', 'falls', 'apart', 'try', 'follow', 'proper', 'software', 'engineering', 'practices', 'abstraction', 'encapsulation', 'downloading', 'jupyter', 'notebook', 'python', 'code', 'honestly', 'dirty', 'bunch', 'metadata', 'necessary', 'longest', 'time', 'also', 'practical', 'upload', 'jupyter', 'notebook', 'version', 'control', 'system', 'also', 'find', 'spend', 'lot', 'energy', 'transferring', 'files', 'scaling', 'moving', 'codebase', 'supercomputer', 'run', 'extensive', 'experiments', 'trials', 'wondering', 'best', 'practices', 'researchers', 'following', 'proper', 'software', 'engineering', 'practices', 'scaling', 'run', 'larger', 'experiments', 'trials', 'keeping', 'track', 'log', 'files', 'model', 'zoos', 'transferring', 'figures', 'latex', 'etc']","['best', 'practic', 'tip', 'trick', 'write', 'scientif', 'paper', 'latex', 'figur', 'gener', 'python', 'rapid', 'prototyp', 'jupyt', 'run', 'larger', 'experi', 'supercomputersus', 'jupyt', 'honestli', 'pretti', 'good', 'rapid', 'prototyp', 'howev', 'fall', 'apart', 'tri', 'follow', 'proper', 'softwar', 'engin', 'practic', 'abstract', 'encapsul', 'download', 'jupyt', 'notebook', 'python', 'code', 'honestli', 'dirti', 'bunch', 'metadata', 'necessari', 'longest', 'time', 'also', 'practic', 'upload', 'jupyt', 'notebook', 'version', 'control', 'system', 'also', 'find', 'spend', 'lot', 'energi', 'transfer', 'file', 'scale', 'move', 'codebas', 'supercomput', 'run', 'extens', 'experi', 'trial', 'wonder', 'best', 'practic', 'research', 'follow', 'proper', 'softwar', 'engin', 'practic', 'scale', 'run', 'larger', 'experi', 'trial', 'keep', 'track', 'log', 'file', 'model', 'zoo', 'transfer', 'figur', 'latex', 'etc']"
163,177,177,j0selit0342,w3jp2t,[P] Getting Started with MLflow Model Registry,"**TLDR**; **MLflow Model Registry**  allows you to keep track of different Machine Learning models and their  versions, as well as tracking their changes, stages and artifacts. 

Link to the post: [https://mlopshowto.com/keeping-your-machine-learning-models-on-the-right-track-getting-started-with-mlflow-part-2-bbc980a1f8dc](https://mlopshowto.com/keeping-your-machine-learning-models-on-the-right-track-getting-started-with-mlflow-part-2-bbc980a1f8dc)

The [Companion Github Repo](https://github.com/rafaelvp-db/mlflow-getting-started) for this post contains a quickstarter project showcasing some of the capabilities of MLflow Model Registry",0,5,2022-07-20 14:12:09, p  getting started with mlflow model registry,  tldr      mlflow model registry    allows you to keep track of different machine learning models and their  versions  as well as tracking their changes  stages and artifacts  link to the post   https the  companion github repo  https   github com rafaelvp db mlflow getting started  for this post contains a quickstarter project showcasing some of the capabilities of mlflow model registry,tldr mlflow model registry allows keep track different machine learning models versions well tracking changes stages artifacts link post https companion github repo https github com rafaelvp db mlflow getting started post contains quickstarter project showcasing capabilities mlflow model registry,p getting started mlflow model registry,p getting started mlflow model registrytldr mlflow model registry allows keep track different machine learning models versions well tracking changes stages artifacts link post https companion github repo https github com rafaelvp db mlflow getting started post contains quickstarter project showcasing capabilities mlflow model registry,"['p', 'getting', 'started', 'mlflow', 'model', 'registrytldr', 'mlflow', 'model', 'registry', 'allows', 'keep', 'track', 'different', 'machine', 'learning', 'models', 'versions', 'well', 'tracking', 'changes', 'stages', 'artifacts', 'link', 'post', 'https', 'companion', 'github', 'repo', 'https', 'github', 'com', 'rafaelvp', 'db', 'mlflow', 'getting', 'started', 'post', 'contains', 'quickstarter', 'project', 'showcasing', 'capabilities', 'mlflow', 'model', 'registry']","['p', 'get', 'start', 'mlflow', 'model', 'registrytldr', 'mlflow', 'model', 'registri', 'allow', 'keep', 'track', 'differ', 'machin', 'learn', 'model', 'version', 'well', 'track', 'chang', 'stage', 'artifact', 'link', 'post', 'http', 'companion', 'github', 'repo', 'http', 'github', 'com', 'rafaelvp', 'db', 'mlflow', 'get', 'start', 'post', 'contain', 'quickstart', 'project', 'showcas', 'capabl', 'mlflow', 'model', 'registri']"
164,178,178,noblepaldamar,w3nt84,[N] ICML 2022 WiFi,"The ICML 2022 WiFi network is ""ICML"" and the password is ""conference"". Just in case anyone needs it!",5,4,2022-07-20 17:31:37, n  icml  wifi,the icml  wifi network is icml and the password is conference  just in case anyone needs it ,icml wifi network icml password conference case anyone needs,n icml wifi,n icml wifiicml wifi network icml password conference case anyone needs,"['n', 'icml', 'wifiicml', 'wifi', 'network', 'icml', 'password', 'conference', 'case', 'anyone', 'needs']","['n', 'icml', 'wifiicml', 'wifi', 'network', 'icml', 'password', 'confer', 'case', 'anyon', 'need']"
165,179,179,hardmaru,w3alm8,[R] Towards Geometric Deep Learning III: First Geometric Architectures (Blog Post),"*Geometric Deep Learning approaches a broad class of ML problems from the perspectives of symmetry and invariance, providing a common blueprint for neural network architectures as diverse as CNNs, GNNs, and Transformers.*

*In a new series of posts, we study how these ideas have taken us from ancient Greece to convolutional neural networks.*

Blog post [link](https://towardsdatascience.com/towards-geometric-deep-learning-iii-first-geometric-architectures-d1578f4ade1f).",0,14,2022-07-20 05:24:25, r  towards geometric deep learning iii  first geometric architectures  blog post , geometric deep learning approaches a broad class of ml problems from the perspectives of symmetry and invariance  providing a common blueprint for neural network architectures as diverse as cnns  gnns  and transformers   in a new series of posts  we study how these ideas have taken us from ancient greece to convolutional neural networks  blog post  link  https   towardsdatascience com towards geometric deep learning iii first geometric architectures dfadef  ,geometric deep learning approaches broad class ml problems perspectives symmetry invariance providing common blueprint neural network architectures diverse cnns gnns transformers series posts study ideas taken us ancient greece convolutional neural networks blog post link https towardsdatascience com towards geometric deep learning iii first geometric architectures dfadef,r towards geometric deep learning iii first geometric architectures blog post,r towards geometric deep learning iii first geometric architectures blog postgeometric deep learning approaches broad class ml problems perspectives symmetry invariance providing common blueprint neural network architectures diverse cnns gnns transformers series posts study ideas taken us ancient greece convolutional neural networks blog post link https towardsdatascience com towards geometric deep learning iii first geometric architectures dfadef,"['r', 'towards', 'geometric', 'deep', 'learning', 'iii', 'first', 'geometric', 'architectures', 'blog', 'postgeometric', 'deep', 'learning', 'approaches', 'broad', 'class', 'ml', 'problems', 'perspectives', 'symmetry', 'invariance', 'providing', 'common', 'blueprint', 'neural', 'network', 'architectures', 'diverse', 'cnns', 'gnns', 'transformers', 'series', 'posts', 'study', 'ideas', 'taken', 'us', 'ancient', 'greece', 'convolutional', 'neural', 'networks', 'blog', 'post', 'link', 'https', 'towardsdatascience', 'com', 'towards', 'geometric', 'deep', 'learning', 'iii', 'first', 'geometric', 'architectures', 'dfadef']","['r', 'toward', 'geometr', 'deep', 'learn', 'iii', 'first', 'geometr', 'architectur', 'blog', 'postgeometr', 'deep', 'learn', 'approach', 'broad', 'class', 'ml', 'problem', 'perspect', 'symmetri', 'invari', 'provid', 'common', 'blueprint', 'neural', 'network', 'architectur', 'divers', 'cnn', 'gnn', 'transform', 'seri', 'post', 'studi', 'idea', 'taken', 'us', 'ancient', 'greec', 'convolut', 'neural', 'network', 'blog', 'post', 'link', 'http', 'towardsdatasci', 'com', 'toward', 'geometr', 'deep', 'learn', 'iii', 'first', 'geometr', 'architectur', 'dfadef']"
166,180,180,jshkk,w3m1t3,[D] Image to Image Translation with Vanilla style GANs?,"Has any work been done on modifying vanilla style GANs for tasks resembling typical image to image translation?

Clarifying a bit, by ""vanilla"" I mean a typical GAN architecture like DCGAN with simply one generator and discriminator (as opposed to say CycleGAN). And by ""image to image"" I mean, say, feeding the generator an image as input instead of a latent vector.

Now of course, that's not how traditional GANs are set up. That latent vector generally gets transformed into something with many channels, so you *can't* just plug an image in as input and be on your way. But there's nothing to say you couldn't change the architecture slightly or map the image through some transformer to fit it.

Imagining the case then where we had images from two similar domains (perhaps bald faces and faces with hair), it would seem to me that such a generator might could learn to create the new domain from such an input (given enough images). My intuition then is it could do much the same as what's found in attempts like CycleGAN, but without the constraint that the output image resembles the input. The output may be realistic to the new domain, but there's no guarantee that the generator didn't hallucinate away most of the input features to get it there (but maybe it could be similar!) since this is an unpaired image scenario.

Application might be more in the art side of things but wanted to know if this had been explored yet?",7,2,2022-07-20 16:14:13, d  image to image translation with vanilla style gans ,has any work been done on modifying vanilla style gans for tasks resembling typical image to image translation clarifying a bit  by vanilla i mean a typical gan architecture like dcgan with simply one generator and discriminator  as opposed to say cyclegan   and by image to image i mean  say  feeding the generator an image as input instead of a latent vector now of course  that s not how traditional gans are set up  that latent vector generally gets transformed into something with many channels  so you  can t  just plug an image in as input and be on your way  but there s nothing to say you couldn t change the architecture slightly or map the image through some transformer to fit it imagining the case then where we had images from two similar domains  perhaps bald faces and faces with hair   it would seem to me that such a generator might could learn to create the new domain from such an input  given enough images   my intuition then is it could do much the same as what s found in attempts like cyclegan  but without the constraint that the output image resembles the input  the output may be realistic to the new domain  but there s no guarantee that the generator didn t hallucinate away most of the input features to get it there  but maybe it could be similar   since this is an unpaired image scenario application might be more in the art side of things but wanted to know if this had been explored yet ,work done modifying vanilla style gans tasks resembling typical image image translation clarifying bit vanilla mean typical gan architecture like dcgan simply one generator discriminator opposed say cyclegan image image mean say feeding generator image input instead latent vector course traditional gans set latent vector generally gets transformed something many channels plug image input way nothing say change architecture slightly map image transformer fit imagining case images two similar domains perhaps bald faces faces hair would seem generator might could learn create domain input given enough images intuition could much found attempts like cyclegan without constraint output image resembles input output may realistic domain guarantee generator hallucinate away input features get maybe could similar since unpaired image scenario application might art side things wanted know explored yet,image image translation vanilla style gans,image image translation vanilla style ganswork done modifying vanilla style gans tasks resembling typical image image translation clarifying bit vanilla mean typical gan architecture like dcgan simply one generator discriminator opposed say cyclegan image image mean say feeding generator image input instead latent vector course traditional gans set latent vector generally gets transformed something many channels plug image input way nothing say change architecture slightly map image transformer fit imagining case images two similar domains perhaps bald faces faces hair would seem generator might could learn create domain input given enough images intuition could much found attempts like cyclegan without constraint output image resembles input output may realistic domain guarantee generator hallucinate away input features get maybe could similar since unpaired image scenario application might art side things wanted know explored yet,"['image', 'image', 'translation', 'vanilla', 'style', 'ganswork', 'done', 'modifying', 'vanilla', 'style', 'gans', 'tasks', 'resembling', 'typical', 'image', 'image', 'translation', 'clarifying', 'bit', 'vanilla', 'mean', 'typical', 'gan', 'architecture', 'like', 'dcgan', 'simply', 'one', 'generator', 'discriminator', 'opposed', 'say', 'cyclegan', 'image', 'image', 'mean', 'say', 'feeding', 'generator', 'image', 'input', 'instead', 'latent', 'vector', 'course', 'traditional', 'gans', 'set', 'latent', 'vector', 'generally', 'gets', 'transformed', 'something', 'many', 'channels', 'plug', 'image', 'input', 'way', 'nothing', 'say', 'change', 'architecture', 'slightly', 'map', 'image', 'transformer', 'fit', 'imagining', 'case', 'images', 'two', 'similar', 'domains', 'perhaps', 'bald', 'faces', 'faces', 'hair', 'would', 'seem', 'generator', 'might', 'could', 'learn', 'create', 'domain', 'input', 'given', 'enough', 'images', 'intuition', 'could', 'much', 'found', 'attempts', 'like', 'cyclegan', 'without', 'constraint', 'output', 'image', 'resembles', 'input', 'output', 'may', 'realistic', 'domain', 'guarantee', 'generator', 'hallucinate', 'away', 'input', 'features', 'get', 'maybe', 'could', 'similar', 'since', 'unpaired', 'image', 'scenario', 'application', 'might', 'art', 'side', 'things', 'wanted', 'know', 'explored', 'yet']","['imag', 'imag', 'translat', 'vanilla', 'style', 'ganswork', 'done', 'modifi', 'vanilla', 'style', 'gan', 'task', 'resembl', 'typic', 'imag', 'imag', 'translat', 'clarifi', 'bit', 'vanilla', 'mean', 'typic', 'gan', 'architectur', 'like', 'dcgan', 'simpli', 'one', 'gener', 'discrimin', 'oppos', 'say', 'cyclegan', 'imag', 'imag', 'mean', 'say', 'feed', 'gener', 'imag', 'input', 'instead', 'latent', 'vector', 'cours', 'tradit', 'gan', 'set', 'latent', 'vector', 'gener', 'get', 'transform', 'someth', 'mani', 'channel', 'plug', 'imag', 'input', 'way', 'noth', 'say', 'chang', 'architectur', 'slightli', 'map', 'imag', 'transform', 'fit', 'imagin', 'case', 'imag', 'two', 'similar', 'domain', 'perhap', 'bald', 'face', 'face', 'hair', 'would', 'seem', 'gener', 'might', 'could', 'learn', 'creat', 'domain', 'input', 'given', 'enough', 'imag', 'intuit', 'could', 'much', 'found', 'attempt', 'like', 'cyclegan', 'without', 'constraint', 'output', 'imag', 'resembl', 'input', 'output', 'may', 'realist', 'domain', 'guarante', 'gener', 'hallucin', 'away', 'input', 'featur', 'get', 'mayb', 'could', 'similar', 'sinc', 'unpair', 'imag', 'scenario', 'applic', 'might', 'art', 'side', 'thing', 'want', 'know', 'explor', 'yet']"
167,181,181,bunsenfeng,w3hv6q,[D] ACL Rolling Review June 2022,"Hi, did anyone receive reviews and meta-reviews for their ARR June submissions? We were told that the author's response is open before July 20, but none of our four submissions have received any reviews up until now.",3,4,2022-07-20 12:17:14, d  acl rolling review june ,hi  did anyone receive reviews and meta reviews for their arr june submissions  we were told that the author s response is open before july   but none of our four submissions have received any reviews up until now ,hi anyone receive reviews meta reviews arr june submissions told author response open july none four submissions received reviews,acl rolling review june,acl rolling review junehi anyone receive reviews meta reviews arr june submissions told author response open july none four submissions received reviews,"['acl', 'rolling', 'review', 'junehi', 'anyone', 'receive', 'reviews', 'meta', 'reviews', 'arr', 'june', 'submissions', 'told', 'author', 'response', 'open', 'july', 'none', 'four', 'submissions', 'received', 'reviews']","['acl', 'roll', 'review', 'junehi', 'anyon', 'receiv', 'review', 'meta', 'review', 'arr', 'june', 'submiss', 'told', 'author', 'respons', 'open', 'juli', 'none', 'four', 'submiss', 'receiv', 'review']"
168,182,182,carlml,w3co18,[D] Software resources for Meta Reinforcement Learning,"For those of you working on Meta Reinforcement Learning, do you implement all your algorithms from scratch? do you clone a github repo and modify it according to your needs? or what do you do?

I also found the python library [learn2learn](http://learn2learn.net/). It looks great, but haven't tried it and it seems it's not being maintained. Also I find the documentation is relatively poor. Does anyone have experience using this library? 

I was attempting to implement MAML with Vanilla Policy Gradient, but I have not been able to get it work. I know the original MAML paper used TRPO methods instead of vanilla policy gradient; but I have seen other papers such as [this one](https://arxiv.org/abs/2002.05135) that trained MAML with VPG. On that note, for the most experienced and willing to share: what are some of the tips/tricks you have for someone starting research on Meta RL? I am familiar with the theory, but I am having a hard time with implementations.",0,5,2022-07-20 07:06:34, d  software resources for meta reinforcement learning,for those of you working on meta reinforcement learning  do you implement all your algorithms from scratch  do you clone a github repo and modify it according to your needs  or what do you do i also found the python library  learnlearn  http i was attempting to implement maml with vanilla policy gradient  but i have not been able to get it work  i know the original maml paper used trpo methods instead of vanilla policy gradient  but i have seen other papers such as  this one  https   arxiv org abs    that trained maml with vpg  on that note  for the most experienced and willing to share  what are some of the tips tricks you have for someone starting research on meta rl  i am familiar with the theory  but i am having a hard time with implementations ,working meta reinforcement learning implement algorithms scratch clone github repo modify according needs also found python library learnlearn http attempting implement maml vanilla policy gradient able get work know original maml paper used trpo methods instead vanilla policy gradient seen papers one https arxiv org abs trained maml vpg note experienced willing share tips tricks someone starting research meta rl familiar theory hard time implementations,software resources meta reinforcement learning,software resources meta reinforcement learningworking meta reinforcement learning implement algorithms scratch clone github repo modify according needs also found python library learnlearn http attempting implement maml vanilla policy gradient able get work know original maml paper used trpo methods instead vanilla policy gradient seen papers one https arxiv org abs trained maml vpg note experienced willing share tips tricks someone starting research meta rl familiar theory hard time implementations,"['software', 'resources', 'meta', 'reinforcement', 'learningworking', 'meta', 'reinforcement', 'learning', 'implement', 'algorithms', 'scratch', 'clone', 'github', 'repo', 'modify', 'according', 'needs', 'also', 'found', 'python', 'library', 'learnlearn', 'http', 'attempting', 'implement', 'maml', 'vanilla', 'policy', 'gradient', 'able', 'get', 'work', 'know', 'original', 'maml', 'paper', 'used', 'trpo', 'methods', 'instead', 'vanilla', 'policy', 'gradient', 'seen', 'papers', 'one', 'https', 'arxiv', 'org', 'abs', 'trained', 'maml', 'vpg', 'note', 'experienced', 'willing', 'share', 'tips', 'tricks', 'someone', 'starting', 'research', 'meta', 'rl', 'familiar', 'theory', 'hard', 'time', 'implementations']","['softwar', 'resourc', 'meta', 'reinforc', 'learningwork', 'meta', 'reinforc', 'learn', 'implement', 'algorithm', 'scratch', 'clone', 'github', 'repo', 'modifi', 'accord', 'need', 'also', 'found', 'python', 'librari', 'learnlearn', 'http', 'attempt', 'implement', 'maml', 'vanilla', 'polici', 'gradient', 'abl', 'get', 'work', 'know', 'origin', 'maml', 'paper', 'use', 'trpo', 'method', 'instead', 'vanilla', 'polici', 'gradient', 'seen', 'paper', 'one', 'http', 'arxiv', 'org', 'ab', 'train', 'maml', 'vpg', 'note', 'experienc', 'will', 'share', 'tip', 'trick', 'someon', 'start', 'research', 'meta', 'rl', 'familiar', 'theori', 'hard', 'time', 'implement']"
169,183,183,ydennisy,w3j9z1,[D] Storing and dockerizing ML artefacts,"I am trying to think through my overall approach creating ML models and then pulling those models into containers for serving. Right now the overall approach is a little messy as there are a few various approaches being followed.

What I would like to achieve is one way to store model artefacts and then pull those into dockers. It would be nice to build an ergonomic API around the underlying solution so it felt a little like using hugging face model zoo or similar.

I would appreciate input on how people are solving this today!",5,1,2022-07-20 13:47:02, d  storing and dockerizing ml artefacts,i am trying to think through my overall approach creating ml models and then pulling those models into containers for serving  right now the overall approach is a little messy as there are a few various approaches being followed what i would like to achieve is one way to store model artefacts and then pull those into dockers  it would be nice to build an ergonomic api around the underlying solution so it felt a little like using hugging face model zoo or similar i would appreciate input on how people are solving this today ,trying think overall approach creating ml models pulling models containers serving right overall approach little messy various approaches followed would like achieve one way store model artefacts pull dockers would nice build ergonomic api around underlying solution felt little like using hugging face model zoo similar would appreciate input people solving today,storing dockerizing ml artefacts,storing dockerizing ml artefactstrying think overall approach creating ml models pulling models containers serving right overall approach little messy various approaches followed would like achieve one way store model artefacts pull dockers would nice build ergonomic api around underlying solution felt little like using hugging face model zoo similar would appreciate input people solving today,"['storing', 'dockerizing', 'ml', 'artefactstrying', 'think', 'overall', 'approach', 'creating', 'ml', 'models', 'pulling', 'models', 'containers', 'serving', 'right', 'overall', 'approach', 'little', 'messy', 'various', 'approaches', 'followed', 'would', 'like', 'achieve', 'one', 'way', 'store', 'model', 'artefacts', 'pull', 'dockers', 'would', 'nice', 'build', 'ergonomic', 'api', 'around', 'underlying', 'solution', 'felt', 'little', 'like', 'using', 'hugging', 'face', 'model', 'zoo', 'similar', 'would', 'appreciate', 'input', 'people', 'solving', 'today']","['store', 'docker', 'ml', 'artefactstri', 'think', 'overal', 'approach', 'creat', 'ml', 'model', 'pull', 'model', 'contain', 'serv', 'right', 'overal', 'approach', 'littl', 'messi', 'variou', 'approach', 'follow', 'would', 'like', 'achiev', 'one', 'way', 'store', 'model', 'artefact', 'pull', 'docker', 'would', 'nice', 'build', 'ergonom', 'api', 'around', 'underli', 'solut', 'felt', 'littl', 'like', 'use', 'hug', 'face', 'model', 'zoo', 'similar', 'would', 'appreci', 'input', 'peopl', 'solv', 'today']"
170,184,184,joerick,w2p0fi,[P] Enabling Creative Expression with Concept Activation Vectors - a project from Google AI,"[https://ai.googleblog.com/2022/07/enabling-creative-expression-with.html](https://ai.googleblog.com/2022/07/enabling-creative-expression-with.html)

A project from Google's Brain and Mural teams aims to narrow the gap between the objective, categorical ML inferences and subjective, artistic values.

Mood Board Search is a tool built with CAVs (Concept Activation Vectors, from the [TCAV paper](https://arxiv.org/abs/1711.11279), Been Kim et al) for humans to express visually subjective concepts to a machine, and then search a dataset for other images with similar qualities.

We took great care to make the training interface obvious and user-friendly, using the metaphor of mood boards to anchor to the idea of 'visual aesthetic' and appeal to an artistic mindset.

https://i.redd.it/0k9j0wyj6ic91.gif

The results were surprising. 3 artists/curators were able to build visually compelling CAVs with only a handful of images that surfaced images with a coherent visual style, across a variety of different subject matter, resulting in feelings of being able to “break out of visually-similar echo chambers” or “see the world through another person’s eyes”.

These findings point towards new ways of designing collaborative ML systems that embrace personal and collective subjectivity, with new tools letting a broader audience of people work more closely with ML models.

We have open-sourced the all the [code for the tool on GitHub](https://github.com/google-research/mood-board-search), along with the 3 artist-created concepts and a premade image bank so it's ready to use.",6,93,2022-07-19 13:02:59, p  enabling creative expression with concept activation vectors   a project from google ai, https a project from google s brain and mural teams aims to narrow the gap between the objective  categorical ml inferences and subjective  artistic values mood board search is a tool built with cavs  concept activation vectors  from the  tcav paper  https we took great care to make the training interface obvious and user friendly  using the metaphor of mood boards to anchor to the idea of  visual aesthetic  and appeal to an artistic mindset https the results were surprising   artists curators were able to build visually compelling cavs with only a handful of images that surfaced images with a coherent visual style  across a variety of different subject matter  resulting in feelings of being able to  break out of visually similar echo chambers  or  see the world through another person s eyes  these findings point towards new ways of designing collaborative ml systems that embrace personal and collective subjectivity  with new tools letting a broader audience of people work more closely with ml models we have open sourced the all the  code for the tool on github  https   github com google research mood board search   along with the  artist created concepts and a premade image bank so it s ready to use ,https project google brain mural teams aims narrow gap objective categorical ml inferences subjective artistic values mood board search tool built cavs concept activation vectors tcav paper https took great care make training interface obvious user friendly using metaphor mood boards anchor idea visual aesthetic appeal artistic mindset https results surprising artists curators able build visually compelling cavs handful images surfaced images coherent visual style across variety different subject matter resulting feelings able break visually similar echo chambers see world another person eyes findings point towards ways designing collaborative ml systems embrace personal collective subjectivity tools letting broader audience people work closely ml models open sourced code tool github https github com google research mood board search along artist created concepts premade image bank ready use,p enabling creative expression concept activation vectors project google ai,p enabling creative expression concept activation vectors project google aihttps project google brain mural teams aims narrow gap objective categorical ml inferences subjective artistic values mood board search tool built cavs concept activation vectors tcav paper https took great care make training interface obvious user friendly using metaphor mood boards anchor idea visual aesthetic appeal artistic mindset https results surprising artists curators able build visually compelling cavs handful images surfaced images coherent visual style across variety different subject matter resulting feelings able break visually similar echo chambers see world another person eyes findings point towards ways designing collaborative ml systems embrace personal collective subjectivity tools letting broader audience people work closely ml models open sourced code tool github https github com google research mood board search along artist created concepts premade image bank ready use,"['p', 'enabling', 'creative', 'expression', 'concept', 'activation', 'vectors', 'project', 'google', 'aihttps', 'project', 'google', 'brain', 'mural', 'teams', 'aims', 'narrow', 'gap', 'objective', 'categorical', 'ml', 'inferences', 'subjective', 'artistic', 'values', 'mood', 'board', 'search', 'tool', 'built', 'cavs', 'concept', 'activation', 'vectors', 'tcav', 'paper', 'https', 'took', 'great', 'care', 'make', 'training', 'interface', 'obvious', 'user', 'friendly', 'using', 'metaphor', 'mood', 'boards', 'anchor', 'idea', 'visual', 'aesthetic', 'appeal', 'artistic', 'mindset', 'https', 'results', 'surprising', 'artists', 'curators', 'able', 'build', 'visually', 'compelling', 'cavs', 'handful', 'images', 'surfaced', 'images', 'coherent', 'visual', 'style', 'across', 'variety', 'different', 'subject', 'matter', 'resulting', 'feelings', 'able', 'break', 'visually', 'similar', 'echo', 'chambers', 'see', 'world', 'another', 'person', 'eyes', 'findings', 'point', 'towards', 'ways', 'designing', 'collaborative', 'ml', 'systems', 'embrace', 'personal', 'collective', 'subjectivity', 'tools', 'letting', 'broader', 'audience', 'people', 'work', 'closely', 'ml', 'models', 'open', 'sourced', 'code', 'tool', 'github', 'https', 'github', 'com', 'google', 'research', 'mood', 'board', 'search', 'along', 'artist', 'created', 'concepts', 'premade', 'image', 'bank', 'ready', 'use']","['p', 'enabl', 'creativ', 'express', 'concept', 'activ', 'vector', 'project', 'googl', 'aihttp', 'project', 'googl', 'brain', 'mural', 'team', 'aim', 'narrow', 'gap', 'object', 'categor', 'ml', 'infer', 'subject', 'artist', 'valu', 'mood', 'board', 'search', 'tool', 'built', 'cav', 'concept', 'activ', 'vector', 'tcav', 'paper', 'http', 'took', 'great', 'care', 'make', 'train', 'interfac', 'obviou', 'user', 'friendli', 'use', 'metaphor', 'mood', 'board', 'anchor', 'idea', 'visual', 'aesthet', 'appeal', 'artist', 'mindset', 'http', 'result', 'surpris', 'artist', 'curat', 'abl', 'build', 'visual', 'compel', 'cav', 'hand', 'imag', 'surfac', 'imag', 'coher', 'visual', 'style', 'across', 'varieti', 'differ', 'subject', 'matter', 'result', 'feel', 'abl', 'break', 'visual', 'similar', 'echo', 'chamber', 'see', 'world', 'anoth', 'person', 'eye', 'find', 'point', 'toward', 'way', 'design', 'collabor', 'ml', 'system', 'embrac', 'person', 'collect', 'subject', 'tool', 'let', 'broader', 'audienc', 'peopl', 'work', 'close', 'ml', 'model', 'open', 'sourc', 'code', 'tool', 'github', 'http', 'github', 'com', 'googl', 'research', 'mood', 'board', 'search', 'along', 'artist', 'creat', 'concept', 'premad', 'imag', 'bank', 'readi', 'use']"
171,185,185,ThickDoctor007,w3h5jn,[P] Canopy cover estimation from aerial images,"Hi,

I would like to develop a model to estimate canopy cover from aerial images. Below are three examples from different growth stages:

[Canopy Cover - May](https://preview.redd.it/zg934puwmoc91.png?width=676&format=png&auto=webp&s=0028aa195899e99495cde51e1abfafded966cba4)

[Canopy Cover - June](https://preview.redd.it/pvy5hzezmoc91.png?width=752&format=png&auto=webp&s=05d01b733a26325d34fff551de6da097cdae70e4)

[Canopy Cover - July](https://preview.redd.it/2e1cqp71noc91.png?width=815&format=png&auto=webp&s=9e40258ef5dbfb3d9c3b86041f40a8e73614aa7a)

So far, I have been thinking about three possible approaches:

* classification
* object detection
* segmentation

In the case of segmentation, every image as a whole would be rated from 1 to 10 depending on the occurrence of the rows with missing cover (10 - all rows are perfect, 1 - all rows have empty spaces). The issue, in this case, is rating subjectivity - it is hard to determine the objective criteria to assign a class to a whole image.

In the case of object detection, the idea is to rotate the images and then detect every row and for every row detect blank space. Compared to classification, it is possible to objectively determine what is a blank space, and then for every row, it would be possible to calculate the percentage of good coverage.

In the case of segmentation, the annotation is too time-consuming and thus I believe it is better to consider other options.

I would appreciate any comments or suggestions about the possible approach to solve this challenge.",3,0,2022-07-20 11:30:28, p  canopy cover estimation from aerial images,hi i would like to develop a model to estimate canopy cover from aerial images  below are three examples from different growth stages  canopy cover   may  https  canopy cover   june  https  canopy cover   july  https so far  i have been thinking about three possible approaches   classification  object detection  segmentationin the case of segmentation  every image as a whole would be rated from  to  depending on the occurrence of the rows with missing cover     all rows are perfect     all rows have empty spaces   the issue  in this case  is rating subjectivity   it is hard to determine the objective criteria to assign a class to a whole image in the case of object detection  the idea is to rotate the images and then detect every row and for every row detect blank space  compared to classification  it is possible to objectively determine what is a blank space  and then for every row  it would be possible to calculate the percentage of good coverage in the case of segmentation  the annotation is too time consuming and thus i believe it is better to consider other options i would appreciate any comments or suggestions about the possible approach to solve this challenge ,hi would like develop model estimate canopy cover aerial images three examples different growth stages canopy cover may https canopy cover june https canopy cover july https far thinking three possible approaches classification object detection segmentationin case segmentation every image whole would rated depending occurrence rows missing cover rows perfect rows empty spaces issue case rating subjectivity hard determine objective criteria assign class whole image case object detection idea rotate images detect every row every row detect blank space compared classification possible objectively determine blank space every row would possible calculate percentage good coverage case segmentation annotation time consuming thus believe better consider options would appreciate comments suggestions possible approach solve challenge,p canopy cover estimation aerial images,p canopy cover estimation aerial imageshi would like develop model estimate canopy cover aerial images three examples different growth stages canopy cover may https canopy cover june https canopy cover july https far thinking three possible approaches classification object detection segmentationin case segmentation every image whole would rated depending occurrence rows missing cover rows perfect rows empty spaces issue case rating subjectivity hard determine objective criteria assign class whole image case object detection idea rotate images detect every row every row detect blank space compared classification possible objectively determine blank space every row would possible calculate percentage good coverage case segmentation annotation time consuming thus believe better consider options would appreciate comments suggestions possible approach solve challenge,"['p', 'canopy', 'cover', 'estimation', 'aerial', 'imageshi', 'would', 'like', 'develop', 'model', 'estimate', 'canopy', 'cover', 'aerial', 'images', 'three', 'examples', 'different', 'growth', 'stages', 'canopy', 'cover', 'may', 'https', 'canopy', 'cover', 'june', 'https', 'canopy', 'cover', 'july', 'https', 'far', 'thinking', 'three', 'possible', 'approaches', 'classification', 'object', 'detection', 'segmentationin', 'case', 'segmentation', 'every', 'image', 'whole', 'would', 'rated', 'depending', 'occurrence', 'rows', 'missing', 'cover', 'rows', 'perfect', 'rows', 'empty', 'spaces', 'issue', 'case', 'rating', 'subjectivity', 'hard', 'determine', 'objective', 'criteria', 'assign', 'class', 'whole', 'image', 'case', 'object', 'detection', 'idea', 'rotate', 'images', 'detect', 'every', 'row', 'every', 'row', 'detect', 'blank', 'space', 'compared', 'classification', 'possible', 'objectively', 'determine', 'blank', 'space', 'every', 'row', 'would', 'possible', 'calculate', 'percentage', 'good', 'coverage', 'case', 'segmentation', 'annotation', 'time', 'consuming', 'thus', 'believe', 'better', 'consider', 'options', 'would', 'appreciate', 'comments', 'suggestions', 'possible', 'approach', 'solve', 'challenge']","['p', 'canopi', 'cover', 'estim', 'aerial', 'imageshi', 'would', 'like', 'develop', 'model', 'estim', 'canopi', 'cover', 'aerial', 'imag', 'three', 'exampl', 'differ', 'growth', 'stage', 'canopi', 'cover', 'may', 'http', 'canopi', 'cover', 'june', 'http', 'canopi', 'cover', 'juli', 'http', 'far', 'think', 'three', 'possibl', 'approach', 'classif', 'object', 'detect', 'segmentationin', 'case', 'segment', 'everi', 'imag', 'whole', 'would', 'rate', 'depend', 'occurr', 'row', 'miss', 'cover', 'row', 'perfect', 'row', 'empti', 'space', 'issu', 'case', 'rate', 'subject', 'hard', 'determin', 'object', 'criteria', 'assign', 'class', 'whole', 'imag', 'case', 'object', 'detect', 'idea', 'rotat', 'imag', 'detect', 'everi', 'row', 'everi', 'row', 'detect', 'blank', 'space', 'compar', 'classif', 'possibl', 'object', 'determin', 'blank', 'space', 'everi', 'row', 'would', 'possibl', 'calcul', 'percentag', 'good', 'coverag', 'case', 'segment', 'annot', 'time', 'consum', 'thu', 'believ', 'better', 'consid', 'option', 'would', 'appreci', 'comment', 'suggest', 'possibl', 'approach', 'solv', 'challeng']"
172,186,186,AdelSexy,w32tpy,[D] How to choose noise schedule in diffusion models?,"Any tips where to look for answers? Typically in the papers schedules states as fact, and I didn't manage to find proper explanation in general. Also, training and inference schedules are different. Why?

Thanks for help in advance.",1,6,2022-07-19 23:36:28, d  how to choose noise schedule in diffusion models ,any tips where to look for answers  typically in the papers schedules states as fact  and i didn t manage to find proper explanation in general  also  training and inference schedules are different  why thanks for help in advance ,tips look answers typically papers schedules states fact manage find proper explanation general also training inference schedules different thanks help advance,choose noise schedule diffusion models,choose noise schedule diffusion modelstips look answers typically papers schedules states fact manage find proper explanation general also training inference schedules different thanks help advance,"['choose', 'noise', 'schedule', 'diffusion', 'modelstips', 'look', 'answers', 'typically', 'papers', 'schedules', 'states', 'fact', 'manage', 'find', 'proper', 'explanation', 'general', 'also', 'training', 'inference', 'schedules', 'different', 'thanks', 'help', 'advance']","['choos', 'nois', 'schedul', 'diffus', 'modelstip', 'look', 'answer', 'typic', 'paper', 'schedul', 'state', 'fact', 'manag', 'find', 'proper', 'explan', 'gener', 'also', 'train', 'infer', 'schedul', 'differ', 'thank', 'help', 'advanc']"
173,187,187,mishtimoi,w311vb,[R] Evaluating SSL Pipeline," I am training a self-supervised representation learning (SSL) model in SimSiam style. Other than evaluating a downstream task, what are the techniques commonly used for evaluating the representation learned by SSL pipelines?",3,5,2022-07-19 22:23:33, r  evaluating ssl pipeline, i am training a self supervised representation learning  ssl  model in simsiam style  other than evaluating a downstream task  what are the techniques commonly used for evaluating the representation learned by ssl pipelines ,training self supervised representation learning ssl model simsiam style evaluating downstream task techniques commonly used evaluating representation learned ssl pipelines,r evaluating ssl pipeline,r evaluating ssl pipelinetraining self supervised representation learning ssl model simsiam style evaluating downstream task techniques commonly used evaluating representation learned ssl pipelines,"['r', 'evaluating', 'ssl', 'pipelinetraining', 'self', 'supervised', 'representation', 'learning', 'ssl', 'model', 'simsiam', 'style', 'evaluating', 'downstream', 'task', 'techniques', 'commonly', 'used', 'evaluating', 'representation', 'learned', 'ssl', 'pipelines']","['r', 'evalu', 'ssl', 'pipelinetrain', 'self', 'supervis', 'represent', 'learn', 'ssl', 'model', 'simsiam', 'style', 'evalu', 'downstream', 'task', 'techniqu', 'commonli', 'use', 'evalu', 'represent', 'learn', 'ssl', 'pipelin']"
174,189,189,bitemenow999,w2u4y4,[D] Vision transformers: Why non-overlapping patches?,"So I have been looking into various flavors of transformers for vision/image-based tasks and almost all of them use non-overlapping patches, is there a reason for that?

My problem with that is if the kernel size(patch dimension) is large then the non-overlapping features might get lost, am I thinking in terms of ""image"" and I should think more in terms of NLP?",6,6,2022-07-19 17:30:16, d  vision transformers  why non overlapping patches ,so i have been looking into various flavors of transformers for vision image based tasks and almost all of them use non overlapping patches  is there a reason for that my problem with that is if the kernel size patch dimension  is large then the non overlapping features might get lost  am i thinking in terms of image and i should think more in terms of nlp ,looking various flavors transformers vision image based tasks almost use non overlapping patches reason problem kernel size patch dimension large non overlapping features might get lost thinking terms image think terms nlp,vision transformers non overlapping patches,vision transformers non overlapping patcheslooking various flavors transformers vision image based tasks almost use non overlapping patches reason problem kernel size patch dimension large non overlapping features might get lost thinking terms image think terms nlp,"['vision', 'transformers', 'non', 'overlapping', 'patcheslooking', 'various', 'flavors', 'transformers', 'vision', 'image', 'based', 'tasks', 'almost', 'use', 'non', 'overlapping', 'patches', 'reason', 'problem', 'kernel', 'size', 'patch', 'dimension', 'large', 'non', 'overlapping', 'features', 'might', 'get', 'lost', 'thinking', 'terms', 'image', 'think', 'terms', 'nlp']","['vision', 'transform', 'non', 'overlap', 'patcheslook', 'variou', 'flavor', 'transform', 'vision', 'imag', 'base', 'task', 'almost', 'use', 'non', 'overlap', 'patch', 'reason', 'problem', 'kernel', 'size', 'patch', 'dimens', 'larg', 'non', 'overlap', 'featur', 'might', 'get', 'lost', 'think', 'term', 'imag', 'think', 'term', 'nlp']"
175,190,190,SkeeringReal,w2zvvi,[R] BeerAdvocate Dataset (Sentence annotations),"Hi, if you're not familiar with this dataset it has text snippets which encode information about beers to give a final rating. There are four main aspects in each review (taste, aroma, appearance, pallet), and I've been trying to get the sentence-level annotations for this dataset where each of these is highlighted, but it's quite hard to find. Multiple papers claim to use them (e.g., [here](https://arxiv.org/pdf/2105.04837.pdf)), but I am finding it difficult to locate them. Even some websites have removed the data [here](https://snap.stanford.edu/data/web-BeerAdvocate.html).

I have found some annotations [here](http://people.csail.mit.edu/taolei/beer/), but I wonder am I missing something? Some papers report there are 100 annotations, others report 800 or so. It seems it original dataset didn't have these sentence-level annotations of the various beer aspects, and researchers uploaded their own labels over the years.

I'm just posting in case anyone knows where I could find the full list of annotations for each beer aspect (taste, aroma, appearance, pallet)? Or did I already find them in the above link?

Thanks if you have time to help out, and sorry if I've missed something obvious.",0,3,2022-07-19 21:34:13, r  beeradvocate dataset  sentence annotations ,hi  if you re not familiar with this dataset it has text snippets which encode information about beers to give a final rating  there are four main aspects in each review  taste  aroma  appearance  pallet   and i ve been trying to get the sentence level annotations for this dataset where each of these is highlighted  but it s quite hard to find  multiple papers claim to use them  e g    here  https i have found some annotations  here  http i m just posting in case anyone knows where i could find the full list of annotations for each beer aspect  taste  aroma  appearance  pallet   or did i already find them in the above link thanks if you have time to help out  and sorry if i ve missed something obvious ,hi familiar dataset text snippets encode information beers give final rating four main aspects review taste aroma appearance pallet trying get sentence level annotations dataset highlighted quite hard find multiple papers claim use e g https found annotations http posting case anyone knows could find full annotations beer aspect taste aroma appearance pallet already find link thanks time help sorry missed something obvious,r beeradvocate dataset sentence annotations,r beeradvocate dataset sentence annotationshi familiar dataset text snippets encode information beers give final rating four main aspects review taste aroma appearance pallet trying get sentence level annotations dataset highlighted quite hard find multiple papers claim use e g https found annotations http posting case anyone knows could find full annotations beer aspect taste aroma appearance pallet already find link thanks time help sorry missed something obvious,"['r', 'beeradvocate', 'dataset', 'sentence', 'annotationshi', 'familiar', 'dataset', 'text', 'snippets', 'encode', 'information', 'beers', 'give', 'final', 'rating', 'four', 'main', 'aspects', 'review', 'taste', 'aroma', 'appearance', 'pallet', 'trying', 'get', 'sentence', 'level', 'annotations', 'dataset', 'highlighted', 'quite', 'hard', 'find', 'multiple', 'papers', 'claim', 'use', 'e', 'g', 'https', 'found', 'annotations', 'http', 'posting', 'case', 'anyone', 'knows', 'could', 'find', 'full', 'annotations', 'beer', 'aspect', 'taste', 'aroma', 'appearance', 'pallet', 'already', 'find', 'link', 'thanks', 'time', 'help', 'sorry', 'missed', 'something', 'obvious']","['r', 'beeradvoc', 'dataset', 'sentenc', 'annotationshi', 'familiar', 'dataset', 'text', 'snippet', 'encod', 'inform', 'beer', 'give', 'final', 'rate', 'four', 'main', 'aspect', 'review', 'tast', 'aroma', 'appear', 'pallet', 'tri', 'get', 'sentenc', 'level', 'annot', 'dataset', 'highlight', 'quit', 'hard', 'find', 'multipl', 'paper', 'claim', 'use', 'e', 'g', 'http', 'found', 'annot', 'http', 'post', 'case', 'anyon', 'know', 'could', 'find', 'full', 'annot', 'beer', 'aspect', 'tast', 'aroma', 'appear', 'pallet', 'alreadi', 'find', 'link', 'thank', 'time', 'help', 'sorri', 'miss', 'someth', 'obviou']"
176,191,191,Singularian2501,w2cn7i,[R] EquiBind: Geometric Deep Learning for Drug Binding Structure Prediction,"Paper: [https://arxiv.org/abs/2202.05146](https://arxiv.org/abs/2202.05146)

Github: [https://github.com/HannesStark/EquiBind](https://github.com/HannesStark/EquiBind)

Abstract:

>Predicting how a drug-like molecule binds to a specific protein target is a core problem in drug discovery. An extremely fast computational binding method would enable key applications such as fast virtual screening or drug engineering. Existing methods are computationally expensive as they rely on heavy candidate sampling coupled with scoring, ranking, and fine-tuning steps. We challenge this paradigm with EquiBind, an SE(3)-equivariant geometric deep learning model performing direct-shot prediction of both i) the receptor binding location (blind docking) and ii) the ligand's bound pose and orientation. **EquiBind achieves significant speed-ups and better quality compared to traditional and recent baselines**. Further, we show extra improvements when coupling it with existing fine-tuning techniques at the cost of increased running time. Finally, we propose a novel and fast fine-tuning model that adjusts torsion angles of a ligand's rotatable bonds based on closed-form global minima of the von Mises angular distance to a given input atomic point cloud, avoiding previous expensive differential evolution strategies for energy minimization.       

&#x200B;

https://preview.redd.it/rbqv738foec91.jpg?width=1252&format=pjpg&auto=webp&s=54d8175f93980d32329ea7b6bddcba36e42deb86",3,9,2022-07-19 01:49:05, r  equibind  geometric deep learning for drug binding structure prediction,paper   https github   https abstract  predicting how a drug like molecule binds to a specific protein target is a core problem in drug discovery  an extremely fast computational binding method would enable key applications such as fast virtual screening or drug engineering  existing methods are computationally expensive as they rely on heavy candidate sampling coupled with scoring  ranking  and fine tuning steps  we challenge this paradigm with equibind  an se   equivariant geometric deep learning model performing direct shot prediction of both i  the receptor binding location  blind docking  and ii  the ligand s bound pose and orientation    equibind achieves significant speed ups and better quality compared to traditional and recent baselines    further  we show extra improvements when coupling it with existing fine tuning techniques at the cost of increased running time  finally  we propose a novel and fast fine tuning model that adjusts torsion angles of a ligand s rotatable bonds based on closed form global minima of the von mises angular distance to a given input atomic point cloud  avoiding previous expensive differential evolution strategies for energy minimization          xb https   preview redd it rbqvfoec jpg width  format pjpg auto webp s dfdeabbddcbaedeb,paper https github https abstract predicting drug like molecule binds specific protein target core problem drug discovery extremely fast computational binding method would enable key applications fast virtual screening drug engineering existing methods computationally expensive rely heavy candidate sampling coupled scoring ranking fine tuning steps challenge paradigm equibind se equivariant geometric deep learning model performing direct shot prediction receptor binding location blind docking ii ligand bound pose orientation equibind achieves significant speed ups better quality compared traditional recent baselines show extra improvements coupling existing fine tuning techniques cost increased running time finally propose novel fast fine tuning model adjusts torsion angles ligand rotatable bonds based closed form global minima von mises angular distance given input atomic point cloud avoiding previous expensive differential evolution strategies energy minimization xb https preview redd rbqvfoec jpg width format pjpg auto webp dfdeabbddcbaedeb,r equibind geometric deep learning drug binding structure prediction,r equibind geometric deep learning drug binding structure predictionpaper https github https abstract predicting drug like molecule binds specific protein target core problem drug discovery extremely fast computational binding method would enable key applications fast virtual screening drug engineering existing methods computationally expensive rely heavy candidate sampling coupled scoring ranking fine tuning steps challenge paradigm equibind se equivariant geometric deep learning model performing direct shot prediction receptor binding location blind docking ii ligand bound pose orientation equibind achieves significant speed ups better quality compared traditional recent baselines show extra improvements coupling existing fine tuning techniques cost increased running time finally propose novel fast fine tuning model adjusts torsion angles ligand rotatable bonds based closed form global minima von mises angular distance given input atomic point cloud avoiding previous expensive differential evolution strategies energy minimization xb https preview redd rbqvfoec jpg width format pjpg auto webp dfdeabbddcbaedeb,"['r', 'equibind', 'geometric', 'deep', 'learning', 'drug', 'binding', 'structure', 'predictionpaper', 'https', 'github', 'https', 'abstract', 'predicting', 'drug', 'like', 'molecule', 'binds', 'specific', 'protein', 'target', 'core', 'problem', 'drug', 'discovery', 'extremely', 'fast', 'computational', 'binding', 'method', 'would', 'enable', 'key', 'applications', 'fast', 'virtual', 'screening', 'drug', 'engineering', 'existing', 'methods', 'computationally', 'expensive', 'rely', 'heavy', 'candidate', 'sampling', 'coupled', 'scoring', 'ranking', 'fine', 'tuning', 'steps', 'challenge', 'paradigm', 'equibind', 'se', 'equivariant', 'geometric', 'deep', 'learning', 'model', 'performing', 'direct', 'shot', 'prediction', 'receptor', 'binding', 'location', 'blind', 'docking', 'ii', 'ligand', 'bound', 'pose', 'orientation', 'equibind', 'achieves', 'significant', 'speed', 'ups', 'better', 'quality', 'compared', 'traditional', 'recent', 'baselines', 'show', 'extra', 'improvements', 'coupling', 'existing', 'fine', 'tuning', 'techniques', 'cost', 'increased', 'running', 'time', 'finally', 'propose', 'novel', 'fast', 'fine', 'tuning', 'model', 'adjusts', 'torsion', 'angles', 'ligand', 'rotatable', 'bonds', 'based', 'closed', 'form', 'global', 'minima', 'von', 'mises', 'angular', 'distance', 'given', 'input', 'atomic', 'point', 'cloud', 'avoiding', 'previous', 'expensive', 'differential', 'evolution', 'strategies', 'energy', 'minimization', 'xb', 'https', 'preview', 'redd', 'rbqvfoec', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'dfdeabbddcbaedeb']","['r', 'equibind', 'geometr', 'deep', 'learn', 'drug', 'bind', 'structur', 'predictionpap', 'http', 'github', 'http', 'abstract', 'predict', 'drug', 'like', 'molecul', 'bind', 'specif', 'protein', 'target', 'core', 'problem', 'drug', 'discoveri', 'extrem', 'fast', 'comput', 'bind', 'method', 'would', 'enabl', 'key', 'applic', 'fast', 'virtual', 'screen', 'drug', 'engin', 'exist', 'method', 'comput', 'expens', 'reli', 'heavi', 'candid', 'sampl', 'coupl', 'score', 'rank', 'fine', 'tune', 'step', 'challeng', 'paradigm', 'equibind', 'se', 'equivari', 'geometr', 'deep', 'learn', 'model', 'perform', 'direct', 'shot', 'predict', 'receptor', 'bind', 'locat', 'blind', 'dock', 'ii', 'ligand', 'bound', 'pose', 'orient', 'equibind', 'achiev', 'signific', 'speed', 'up', 'better', 'qualiti', 'compar', 'tradit', 'recent', 'baselin', 'show', 'extra', 'improv', 'coupl', 'exist', 'fine', 'tune', 'techniqu', 'cost', 'increas', 'run', 'time', 'final', 'propos', 'novel', 'fast', 'fine', 'tune', 'model', 'adjust', 'torsion', 'angl', 'ligand', 'rotat', 'bond', 'base', 'close', 'form', 'global', 'minima', 'von', 'mise', 'angular', 'distanc', 'given', 'input', 'atom', 'point', 'cloud', 'avoid', 'previou', 'expens', 'differenti', 'evolut', 'strategi', 'energi', 'minim', 'xb', 'http', 'preview', 'redd', 'rbqvfoec', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'dfdeabbddcbaedeb']"
177,192,192,turpyturp,w1xrfa,Quick notes on the difference between Imagen and DALL-E 2 for those who haven’t had time to read the paper [D],"It’s always interesting comparing these big models because when you look closely they are based on similar algorithms and have very similar architectures too.

Google claims that what sets Imagen apart is:

1. deep language understanding
2. unprecedented photorealism

It’s good of them to do this deduction for us, but all we have to compare  Imagen and other models like DALL-E 2 and GLIDE is what they have given us since no one has access to Imagen yet. From the examples they published, it does really look like Imagen has achieved a good level of language understanding.

*\[These are some quick observations on the difference between Imagen and DALL-E  2. If you’d like to learn more about Imagen and its architecture* [*here is a video*](https://youtu.be/jNW8qiwCiyI) *and a more comprehensive* [*blog post*](https://www.assemblyai.com/blog/how-imagen-actually-works/) *on it.\]*

If you looked into DALL-E 2 at all, you might have heard about the discussion on how it is not able to create images with comprehensible text on it or how it confuses the physical attributes of objects with each other. In  the Imagen paper, to prove that Imagen achieves better results, the  authors use the example prompt: “A panda making latte art.”

It looks like only Imagen can understand that the panda needs to be the one making the art.

&#x200B;

[Made by DALL-E 2](https://preview.redd.it/98iijc1aibc91.png?width=548&format=png&auto=webp&s=2d865949237a894aaf1ee347928e95b428093cc3)

[Made by GLIDE](https://preview.redd.it/69my43lbibc91.png?width=540&format=png&auto=webp&s=d717798d33a4adca9855d61c85740bfeffc39b2d)

[Made by Imagen](https://preview.redd.it/snoguyscibc91.png?width=544&format=png&auto=webp&s=99562da6f2000a7ee8bacbc3af174f42c9ad0914)

These are only some cherrypicked examples, of course. There needs to be a  much more comprehensive comparison of these models before we can conclusively make a judgment.

One of the main reasons why Imagen understands what is meant in the caption better than previous models is the text encoder they are using. Instead of a text encoder trained on image-caption pairs (like CLIP in DALL-E  2), they opted for a language model, only trained on text (T5). As far as we can tell, it has paid off this time around. But we need to see many more examples and have the chance to evaluate the model more freely before conclusively deciding on anything.

As a benchmark comparison tool for image generation models, Google researchers created DrawBench. Which is a list of challenging prompts.  For now, it consists only of the prompts the creators of Imagen came up with. It would be even better if it was a list of prompts collected from impartial parties, of course.

Using a language model instead of CLIP came with some advantages.

* The size of the language model is bigger than CLIP because there is much more text data than there are text-image pairs. Since it’s trained on much more data and has a much bigger size, T5 understands language better.
* In  CLIP, the text and image encoder are trained simultaneously. Due to that, the image encoder might compensate for the low performance of the text encoder. And even though this leads to a lower loss of the overall model, when the text encoder is repurposed in a model like DALL-E 2, the performance can be lacking. Language models, on the other hand, don’t have this disadvantage.
* CLIP  trains the text encoder to closely match the image encodings. When this pairing is the focus, the distance between the encodings of captions that represent similar ideas can be too far apart. This might cause the generated images to have lower caption similarity given the role these text encodings play in the image generation process.",2,67,2022-07-18 15:09:46,quick notes on the difference between imagen and dall e  for those who haven t had time to read the paper  d ,it s always interesting comparing these big models because when you look closely they are based on similar algorithms and have very similar architectures too google claims that what sets imagen apart is   deep language understanding  unprecedented photorealismit s good of them to do this deduction for us  but all we have to compare  imagen and other models like dall e  and glide is what they have given us since no one has access to imagen yet  from the examples they published  it does really look like imagen has achieved a good level of language understanding    these are some quick observations on the difference between imagen and dall e    if you d like to learn more about imagen and its architecture    here is a video   https if you looked into dall e  at all  you might have heard about the discussion on how it is not able to create images with comprehensible text on it or how it confuses the physical attributes of objects with each other  in  the imagen paper  to prove that imagen achieves better results  the  authors use the example prompt   a panda making latte art  it looks like only imagen can understand that the panda needs to be the one making the art   xb  made by dall e   https  made by glide  https  made by imagen  https these are only some cherrypicked examples  of course  there needs to be a  much more comprehensive comparison of these models before we can conclusively make a judgment one of the main reasons why imagen understands what is meant in the caption better than previous models is the text encoder they are using  instead of a text encoder trained on image caption pairs  like clip in dall e     they opted for a language model  only trained on text  t   as far as we can tell  it has paid off this time around  but we need to see many more examples and have the chance to evaluate the model more freely before conclusively deciding on anything as a benchmark comparison tool for image generation models  google researchers created drawbench  which is a list of challenging prompts   for now  it consists only of the prompts the creators of imagen came up with  it would be even better if it was a list of prompts collected from impartial parties  of course using a language model instead of clip came with some advantages   the size of the language model is bigger than clip because there is much more text data than there are text image pairs  since it s trained on much more data and has a much bigger size  t understands language better   in  clip  the text and image encoder are trained simultaneously  due to that  the image encoder might compensate for the low performance of the text encoder  and even though this leads to a lower loss of the overall model  when the text encoder is repurposed in a model like dall e   the performance can be lacking  language models  on the other hand  don t have this disadvantage   clip  trains the text encoder to closely match the image encodings  when this pairing is the focus  the distance between the encodings of captions that represent similar ideas can be too far apart  this might cause the generated images to have lower caption similarity given the role these text encodings play in the image generation process ,always interesting comparing big models look closely based similar algorithms similar architectures google claims sets imagen apart deep language understanding unprecedented photorealismit good deduction us compare imagen models like dall e glide given us since one access imagen yet examples published really look like imagen achieved good level language understanding quick observations difference imagen dall e like learn imagen architecture video https looked dall e might heard discussion able create images comprehensible text confuses physical attributes objects imagen paper prove imagen achieves better results authors use example prompt panda making latte art looks like imagen understand panda needs one making art xb made dall e https made glide https made imagen https cherrypicked examples course needs much comprehensive comparison models conclusively make judgment one main reasons imagen understands meant caption better previous models text encoder using instead text encoder trained image caption pairs like clip dall e opted language model trained text far tell paid time around need see many examples chance evaluate model freely conclusively deciding anything benchmark comparison tool image generation models google researchers created drawbench challenging prompts consists prompts creators imagen came would even better prompts collected impartial parties course using language model instead clip came advantages size language model bigger clip much text data text image pairs since trained much data much bigger size understands language better clip text image encoder trained simultaneously due image encoder might compensate low performance text encoder even though leads lower loss overall model text encoder repurposed model like dall e performance lacking language models hand disadvantage clip trains text encoder closely match image encodings pairing focus distance encodings captions represent similar ideas far apart might cause generated images lower caption similarity given role text encodings play image generation process,quick notes difference imagen dall e time read paper,quick notes difference imagen dall e time read paperalways interesting comparing big models look closely based similar algorithms similar architectures google claims sets imagen apart deep language understanding unprecedented photorealismit good deduction us compare imagen models like dall e glide given us since one access imagen yet examples published really look like imagen achieved good level language understanding quick observations difference imagen dall e like learn imagen architecture video https looked dall e might heard discussion able create images comprehensible text confuses physical attributes objects imagen paper prove imagen achieves better results authors use example prompt panda making latte art looks like imagen understand panda needs one making art xb made dall e https made glide https made imagen https cherrypicked examples course needs much comprehensive comparison models conclusively make judgment one main reasons imagen understands meant caption better previous models text encoder using instead text encoder trained image caption pairs like clip dall e opted language model trained text far tell paid time around need see many examples chance evaluate model freely conclusively deciding anything benchmark comparison tool image generation models google researchers created drawbench challenging prompts consists prompts creators imagen came would even better prompts collected impartial parties course using language model instead clip came advantages size language model bigger clip much text data text image pairs since trained much data much bigger size understands language better clip text image encoder trained simultaneously due image encoder might compensate low performance text encoder even though leads lower loss overall model text encoder repurposed model like dall e performance lacking language models hand disadvantage clip trains text encoder closely match image encodings pairing focus distance encodings captions represent similar ideas far apart might cause generated images lower caption similarity given role text encodings play image generation process,"['quick', 'notes', 'difference', 'imagen', 'dall', 'e', 'time', 'read', 'paperalways', 'interesting', 'comparing', 'big', 'models', 'look', 'closely', 'based', 'similar', 'algorithms', 'similar', 'architectures', 'google', 'claims', 'sets', 'imagen', 'apart', 'deep', 'language', 'understanding', 'unprecedented', 'photorealismit', 'good', 'deduction', 'us', 'compare', 'imagen', 'models', 'like', 'dall', 'e', 'glide', 'given', 'us', 'since', 'one', 'access', 'imagen', 'yet', 'examples', 'published', 'really', 'look', 'like', 'imagen', 'achieved', 'good', 'level', 'language', 'understanding', 'quick', 'observations', 'difference', 'imagen', 'dall', 'e', 'like', 'learn', 'imagen', 'architecture', 'video', 'https', 'looked', 'dall', 'e', 'might', 'heard', 'discussion', 'able', 'create', 'images', 'comprehensible', 'text', 'confuses', 'physical', 'attributes', 'objects', 'imagen', 'paper', 'prove', 'imagen', 'achieves', 'better', 'results', 'authors', 'use', 'example', 'prompt', 'panda', 'making', 'latte', 'art', 'looks', 'like', 'imagen', 'understand', 'panda', 'needs', 'one', 'making', 'art', 'xb', 'made', 'dall', 'e', 'https', 'made', 'glide', 'https', 'made', 'imagen', 'https', 'cherrypicked', 'examples', 'course', 'needs', 'much', 'comprehensive', 'comparison', 'models', 'conclusively', 'make', 'judgment', 'one', 'main', 'reasons', 'imagen', 'understands', 'meant', 'caption', 'better', 'previous', 'models', 'text', 'encoder', 'using', 'instead', 'text', 'encoder', 'trained', 'image', 'caption', 'pairs', 'like', 'clip', 'dall', 'e', 'opted', 'language', 'model', 'trained', 'text', 'far', 'tell', 'paid', 'time', 'around', 'need', 'see', 'many', 'examples', 'chance', 'evaluate', 'model', 'freely', 'conclusively', 'deciding', 'anything', 'benchmark', 'comparison', 'tool', 'image', 'generation', 'models', 'google', 'researchers', 'created', 'drawbench', 'challenging', 'prompts', 'consists', 'prompts', 'creators', 'imagen', 'came', 'would', 'even', 'better', 'prompts', 'collected', 'impartial', 'parties', 'course', 'using', 'language', 'model', 'instead', 'clip', 'came', 'advantages', 'size', 'language', 'model', 'bigger', 'clip', 'much', 'text', 'data', 'text', 'image', 'pairs', 'since', 'trained', 'much', 'data', 'much', 'bigger', 'size', 'understands', 'language', 'better', 'clip', 'text', 'image', 'encoder', 'trained', 'simultaneously', 'due', 'image', 'encoder', 'might', 'compensate', 'low', 'performance', 'text', 'encoder', 'even', 'though', 'leads', 'lower', 'loss', 'overall', 'model', 'text', 'encoder', 'repurposed', 'model', 'like', 'dall', 'e', 'performance', 'lacking', 'language', 'models', 'hand', 'disadvantage', 'clip', 'trains', 'text', 'encoder', 'closely', 'match', 'image', 'encodings', 'pairing', 'focus', 'distance', 'encodings', 'captions', 'represent', 'similar', 'ideas', 'far', 'apart', 'might', 'cause', 'generated', 'images', 'lower', 'caption', 'similarity', 'given', 'role', 'text', 'encodings', 'play', 'image', 'generation', 'process']","['quick', 'note', 'differ', 'imagen', 'dall', 'e', 'time', 'read', 'paperalway', 'interest', 'compar', 'big', 'model', 'look', 'close', 'base', 'similar', 'algorithm', 'similar', 'architectur', 'googl', 'claim', 'set', 'imagen', 'apart', 'deep', 'languag', 'understand', 'unpreced', 'photorealismit', 'good', 'deduct', 'us', 'compar', 'imagen', 'model', 'like', 'dall', 'e', 'glide', 'given', 'us', 'sinc', 'one', 'access', 'imagen', 'yet', 'exampl', 'publish', 'realli', 'look', 'like', 'imagen', 'achiev', 'good', 'level', 'languag', 'understand', 'quick', 'observ', 'differ', 'imagen', 'dall', 'e', 'like', 'learn', 'imagen', 'architectur', 'video', 'http', 'look', 'dall', 'e', 'might', 'heard', 'discuss', 'abl', 'creat', 'imag', 'comprehens', 'text', 'confus', 'physic', 'attribut', 'object', 'imagen', 'paper', 'prove', 'imagen', 'achiev', 'better', 'result', 'author', 'use', 'exampl', 'prompt', 'panda', 'make', 'latt', 'art', 'look', 'like', 'imagen', 'understand', 'panda', 'need', 'one', 'make', 'art', 'xb', 'made', 'dall', 'e', 'http', 'made', 'glide', 'http', 'made', 'imagen', 'http', 'cherrypick', 'exampl', 'cours', 'need', 'much', 'comprehens', 'comparison', 'model', 'conclus', 'make', 'judgment', 'one', 'main', 'reason', 'imagen', 'understand', 'meant', 'caption', 'better', 'previou', 'model', 'text', 'encod', 'use', 'instead', 'text', 'encod', 'train', 'imag', 'caption', 'pair', 'like', 'clip', 'dall', 'e', 'opt', 'languag', 'model', 'train', 'text', 'far', 'tell', 'paid', 'time', 'around', 'need', 'see', 'mani', 'exampl', 'chanc', 'evalu', 'model', 'freeli', 'conclus', 'decid', 'anyth', 'benchmark', 'comparison', 'tool', 'imag', 'gener', 'model', 'googl', 'research', 'creat', 'drawbench', 'challeng', 'prompt', 'consist', 'prompt', 'creator', 'imagen', 'came', 'would', 'even', 'better', 'prompt', 'collect', 'imparti', 'parti', 'cours', 'use', 'languag', 'model', 'instead', 'clip', 'came', 'advantag', 'size', 'languag', 'model', 'bigger', 'clip', 'much', 'text', 'data', 'text', 'imag', 'pair', 'sinc', 'train', 'much', 'data', 'much', 'bigger', 'size', 'understand', 'languag', 'better', 'clip', 'text', 'imag', 'encod', 'train', 'simultan', 'due', 'imag', 'encod', 'might', 'compens', 'low', 'perform', 'text', 'encod', 'even', 'though', 'lead', 'lower', 'loss', 'overal', 'model', 'text', 'encod', 'repurpos', 'model', 'like', 'dall', 'e', 'perform', 'lack', 'languag', 'model', 'hand', 'disadvantag', 'clip', 'train', 'text', 'encod', 'close', 'match', 'imag', 'encod', 'pair', 'focu', 'distanc', 'encod', 'caption', 'repres', 'similar', 'idea', 'far', 'apart', 'might', 'caus', 'gener', 'imag', 'lower', 'caption', 'similar', 'given', 'role', 'text', 'encod', 'play', 'imag', 'gener', 'process']"
178,193,193,divideconcept,w1yknh,"[News] TorchStudio 0.9.8 (IDE for PyTorch) now support PyTorch 1.12, Apple Silicon, Metal Acceleration, Fedora and brings many new features","Hi, I just released TorchStudio 0.9.8 with several improvements based on community feedback, looking forward for your comments !

download: [https://www.torchstudio.ai/download/](https://www.torchstudio.ai/download/)  
full changelog: [https://github.com/TorchStudio/torchstudio/releases/tag/0.9.8](https://github.com/TorchStudio/torchstudio/releases/tag/0.9.8)

If you're new to TorchStudio, you'll find introductory tutorials and videos here: [https://www.torchstudio.ai/tutorials/](https://www.torchstudio.ai/tutorials/)

&#x200B;

https://preview.redd.it/acfibkampbc91.png?width=2784&format=png&auto=webp&s=e6dad5baebdb3a9d7df54f35dccc4a98753aa5fe

https://preview.redd.it/s29p5yxnpbc91.png?width=2784&format=png&auto=webp&s=a9391ca731b299804c72c82051da9d1b04735c2c",13,37,2022-07-18 15:50:37, news  torchstudio     ide for pytorch  now support pytorch    apple silicon  metal acceleration  fedora and brings many new features,hi  i just released torchstudio    with several improvements based on community feedback  looking forward for your comments  download   https full changelog   https if you re new to torchstudio  you ll find introductory tutorials and videos here   https   xb https https   preview redd it spyxnpbc png width  format png auto webp s acabccdadbcc,hi released torchstudio several improvements based community feedback looking forward comments download https full changelog https torchstudio find introductory tutorials videos https xb https https preview redd spyxnpbc png width format png auto webp acabccdadbcc,news torchstudio ide pytorch support pytorch apple silicon metal acceleration fedora brings many features,news torchstudio ide pytorch support pytorch apple silicon metal acceleration fedora brings many featureshi released torchstudio several improvements based community feedback looking forward comments download https full changelog https torchstudio find introductory tutorials videos https xb https https preview redd spyxnpbc png width format png auto webp acabccdadbcc,"['news', 'torchstudio', 'ide', 'pytorch', 'support', 'pytorch', 'apple', 'silicon', 'metal', 'acceleration', 'fedora', 'brings', 'many', 'featureshi', 'released', 'torchstudio', 'several', 'improvements', 'based', 'community', 'feedback', 'looking', 'forward', 'comments', 'download', 'https', 'full', 'changelog', 'https', 'torchstudio', 'find', 'introductory', 'tutorials', 'videos', 'https', 'xb', 'https', 'https', 'preview', 'redd', 'spyxnpbc', 'png', 'width', 'format', 'png', 'auto', 'webp', 'acabccdadbcc']","['news', 'torchstudio', 'ide', 'pytorch', 'support', 'pytorch', 'appl', 'silicon', 'metal', 'acceler', 'fedora', 'bring', 'mani', 'featureshi', 'releas', 'torchstudio', 'sever', 'improv', 'base', 'commun', 'feedback', 'look', 'forward', 'comment', 'download', 'http', 'full', 'changelog', 'http', 'torchstudio', 'find', 'introductori', 'tutori', 'video', 'http', 'xb', 'http', 'http', 'preview', 'redd', 'spyxnpbc', 'png', 'width', 'format', 'png', 'auto', 'webp', 'acabccdadbcc']"
179,194,194,edgarriba,w1ved2,"[News] Kornia 0.6.6: ParametrizedLine API, load_image support for Apple Windows Developer, integration demos with Hugging Face and many more.","📚 Release notes:

👉 [https://github.com/kornia/kornia/releases/tag/v0.6.6](https://github.com/kornia/kornia/releases/tag/v0.6.6)

📚 Docs and tutorials

👉 [https://kornia.readthedocs.io/en/latest/](https://kornia.readthedocs.io/en/latest/)

https://preview.redd.it/fu46z17xtac91.png?width=1060&format=png&auto=webp&s=e10c42173fca97e76d9e2ccdea8809f112c4392b

https://preview.redd.it/xy64c27xtac91.png?width=640&format=png&auto=webp&s=789a197ab894ac0f5716e276aff360b09fdfb8eb",5,37,2022-07-18 12:53:29, news  kornia     parametrizedline api  load_image support for apple windows developer  integration demos with hugging face and many more ,  release notes    https   docs and tutorials   https https https   preview redd it xycxtac png width  format png auto webp s aabacfeaffbfdfbeb,release notes https docs tutorials https https https preview redd xycxtac png width format png auto webp aabacfeaffbfdfbeb,news kornia parametrizedline api load_image support apple windows developer integration demos hugging face many,news kornia parametrizedline api load_image support apple windows developer integration demos hugging face manyrelease notes https docs tutorials https https https preview redd xycxtac png width format png auto webp aabacfeaffbfdfbeb,"['news', 'kornia', 'parametrizedline', 'api', 'load_image', 'support', 'apple', 'windows', 'developer', 'integration', 'demos', 'hugging', 'face', 'manyrelease', 'notes', 'https', 'docs', 'tutorials', 'https', 'https', 'https', 'preview', 'redd', 'xycxtac', 'png', 'width', 'format', 'png', 'auto', 'webp', 'aabacfeaffbfdfbeb']","['news', 'kornia', 'parametrizedlin', 'api', 'load_imag', 'support', 'appl', 'window', 'develop', 'integr', 'demo', 'hug', 'face', 'manyreleas', 'note', 'http', 'doc', 'tutori', 'http', 'http', 'http', 'preview', 'redd', 'xycxtac', 'png', 'width', 'format', 'png', 'auto', 'webp', 'aabacfeaffbfdfbeb']"
180,195,195,shellyturnwarm,w1xf89,[D][R] Thoughts on the new SOTA on interpretative DNNs - B-cos Networks: Alignment is All We Need for Interpretability?,"Link to arxiv [here](https://arxiv.org/pdf/2205.10268.pdf).

This paper seems quite a breakthrough in designing interpretable DNNs by adding an ""aligning"" inductive bias into the computations in layers of the NN itself.  The quantitative and qualitative results appear incredibly impressive, does anyone have any thoughts on this paper?

&#x200B;

Nice figure here I took from the paper:

&#x200B;

https://preview.redd.it/lqdufxpngbc91.png?width=1928&format=png&auto=webp&s=d1e2885fb179e823c8bf045b66f6a65f8705fda8",3,18,2022-07-18 14:53:22, d  r  thoughts on the new sota on interpretative dnns   b cos networks  alignment is all we need for interpretability ,link to arxiv  here  https this paper seems quite a breakthrough in designing interpretable dnns by adding an aligning inductive bias into the computations in layers of the nn itself   the quantitative and qualitative results appear incredibly impressive  does anyone have any thoughts on this paper   xb nice figure here i took from the paper   xb https   preview redd it lqdufxpngbc png width  format png auto webp s defbecbfbfaffda,link arxiv https paper seems quite breakthrough designing interpretable dnns adding aligning inductive bias computations layers nn quantitative qualitative results appear incredibly impressive anyone thoughts paper xb nice figure took paper xb https preview redd lqdufxpngbc png width format png auto webp defbecbfbfaffda,r thoughts sota interpretative dnns b cos networks alignment need interpretability,r thoughts sota interpretative dnns b cos networks alignment need interpretabilitylink arxiv https paper seems quite breakthrough designing interpretable dnns adding aligning inductive bias computations layers nn quantitative qualitative results appear incredibly impressive anyone thoughts paper xb nice figure took paper xb https preview redd lqdufxpngbc png width format png auto webp defbecbfbfaffda,"['r', 'thoughts', 'sota', 'interpretative', 'dnns', 'b', 'cos', 'networks', 'alignment', 'need', 'interpretabilitylink', 'arxiv', 'https', 'paper', 'seems', 'quite', 'breakthrough', 'designing', 'interpretable', 'dnns', 'adding', 'aligning', 'inductive', 'bias', 'computations', 'layers', 'nn', 'quantitative', 'qualitative', 'results', 'appear', 'incredibly', 'impressive', 'anyone', 'thoughts', 'paper', 'xb', 'nice', 'figure', 'took', 'paper', 'xb', 'https', 'preview', 'redd', 'lqdufxpngbc', 'png', 'width', 'format', 'png', 'auto', 'webp', 'defbecbfbfaffda']","['r', 'thought', 'sota', 'interpret', 'dnn', 'b', 'co', 'network', 'align', 'need', 'interpretabilitylink', 'arxiv', 'http', 'paper', 'seem', 'quit', 'breakthrough', 'design', 'interpret', 'dnn', 'ad', 'align', 'induct', 'bia', 'comput', 'layer', 'nn', 'quantit', 'qualit', 'result', 'appear', 'incred', 'impress', 'anyon', 'thought', 'paper', 'xb', 'nice', 'figur', 'took', 'paper', 'xb', 'http', 'preview', 'redd', 'lqdufxpngbc', 'png', 'width', 'format', 'png', 'auto', 'webp', 'defbecbfbfaffda']"
181,197,197,iFighting,w1oli3,[R] Unicorn: 🦄 : Towards Grand Unification of Object Tracking,"[Video Demo for Unicorn](https://reddit.com/link/w1oli3/video/s0wvlw25mbc91/player)

## Brief Overview

**We present a unified method, termed Unicorn, that can simultaneously solve four tracking problems (SOT, MOT, VOS, MOTS) with a single network using the same model parameters. For the first time, we accomplished the great unification of the tracking network architecture and learning paradigm**.

Unicorn performs on-par or better than its task-specific counterparts in 8 tracking datasets, including LaSOT, TrackingNet, MOT17, BDD100K, DAVIS16-17, MOTS20, and BDD100K MOTS.

Our work is accepted to ECCV 2022 as an oral presentation !

Paper: [https://arxiv.org/abs/2207.07078](https://arxiv.org/abs/2207.07078)

Code: [https://github.com/MasterBin-IIAU/Unicorn](https://github.com/MasterBin-IIAU/Unicorn)

&#x200B;

## Motivation

Object tracking is one of the fundamental tasks in computer vision, which aims to build pixel-level or instance-level correspondence between frames and to output trajectories typically in the forms of boxes or masks. Over the years, according to different application scenarios, the object tracking problem has been mainly divided into four separate sub-tasks: Single Object Tracking (SOT), Multiple Object Tracking (MOT), Video Object Segmentation (VOS), and Multi-Object Tracking and Segmentation (MOTS). As a result, most tracking approaches are developed for only one of or part of the sub-tasks. Despite convenience for specific applications, this fragmented situation brings into the following drawbacks:",5,33,2022-07-18 05:50:52, r  unicorn      towards grand unification of object tracking, video demo for unicorn  https    brief overview  we present a unified method  termed unicorn  that can simultaneously solve four tracking problems  sot  mot  vos  mots  with a single network using the same model parameters  for the first time  we accomplished the great unification of the tracking network architecture and learning paradigm   unicorn performs on par or better than its task specific counterparts in  tracking datasets  including lasot  trackingnet  mot  bddk  davis   mots  and bddk mots our work is accepted to eccv  as an oral presentation  paper   https code   https   xb    motivationobject tracking is one of the fundamental tasks in computer vision  which aims to build pixel level or instance level correspondence between frames and to output trajectories typically in the forms of boxes or masks  over the years  according to different application scenarios  the object tracking problem has been mainly divided into four separate sub tasks  single object tracking  sot   multiple object tracking  mot   video object segmentation  vos   and multi object tracking and segmentation  mots   as a result  most tracking approaches are developed for only one of or part of the sub tasks  despite convenience for specific applications  this fragmented situation brings into the following drawbacks ,video demo unicorn https brief overview present unified method termed unicorn simultaneously solve four tracking problems sot mot vos mots single network using model parameters first time accomplished great unification tracking network architecture learning paradigm unicorn performs par better task specific counterparts tracking datasets including lasot trackingnet mot bddk davis mots bddk mots work accepted eccv oral presentation paper https code https xb motivationobject tracking one fundamental tasks computer vision aims build pixel level instance level correspondence frames output trajectories typically forms boxes masks years according different application scenarios object tracking problem mainly divided four separate sub tasks single object tracking sot multiple object tracking mot video object segmentation vos multi object tracking segmentation mots result tracking approaches developed one part sub tasks despite convenience specific applications fragmented situation brings following drawbacks,r unicorn towards grand unification object tracking,r unicorn towards grand unification object trackingvideo demo unicorn https brief overview present unified method termed unicorn simultaneously solve four tracking problems sot mot vos mots single network using model parameters first time accomplished great unification tracking network architecture learning paradigm unicorn performs par better task specific counterparts tracking datasets including lasot trackingnet mot bddk davis mots bddk mots work accepted eccv oral presentation paper https code https xb motivationobject tracking one fundamental tasks computer vision aims build pixel level instance level correspondence frames output trajectories typically forms boxes masks years according different application scenarios object tracking problem mainly divided four separate sub tasks single object tracking sot multiple object tracking mot video object segmentation vos multi object tracking segmentation mots result tracking approaches developed one part sub tasks despite convenience specific applications fragmented situation brings following drawbacks,"['r', 'unicorn', 'towards', 'grand', 'unification', 'object', 'trackingvideo', 'demo', 'unicorn', 'https', 'brief', 'overview', 'present', 'unified', 'method', 'termed', 'unicorn', 'simultaneously', 'solve', 'four', 'tracking', 'problems', 'sot', 'mot', 'vos', 'mots', 'single', 'network', 'using', 'model', 'parameters', 'first', 'time', 'accomplished', 'great', 'unification', 'tracking', 'network', 'architecture', 'learning', 'paradigm', 'unicorn', 'performs', 'par', 'better', 'task', 'specific', 'counterparts', 'tracking', 'datasets', 'including', 'lasot', 'trackingnet', 'mot', 'bddk', 'davis', 'mots', 'bddk', 'mots', 'work', 'accepted', 'eccv', 'oral', 'presentation', 'paper', 'https', 'code', 'https', 'xb', 'motivationobject', 'tracking', 'one', 'fundamental', 'tasks', 'computer', 'vision', 'aims', 'build', 'pixel', 'level', 'instance', 'level', 'correspondence', 'frames', 'output', 'trajectories', 'typically', 'forms', 'boxes', 'masks', 'years', 'according', 'different', 'application', 'scenarios', 'object', 'tracking', 'problem', 'mainly', 'divided', 'four', 'separate', 'sub', 'tasks', 'single', 'object', 'tracking', 'sot', 'multiple', 'object', 'tracking', 'mot', 'video', 'object', 'segmentation', 'vos', 'multi', 'object', 'tracking', 'segmentation', 'mots', 'result', 'tracking', 'approaches', 'developed', 'one', 'part', 'sub', 'tasks', 'despite', 'convenience', 'specific', 'applications', 'fragmented', 'situation', 'brings', 'following', 'drawbacks']","['r', 'unicorn', 'toward', 'grand', 'unif', 'object', 'trackingvideo', 'demo', 'unicorn', 'http', 'brief', 'overview', 'present', 'unifi', 'method', 'term', 'unicorn', 'simultan', 'solv', 'four', 'track', 'problem', 'sot', 'mot', 'vo', 'mot', 'singl', 'network', 'use', 'model', 'paramet', 'first', 'time', 'accomplish', 'great', 'unif', 'track', 'network', 'architectur', 'learn', 'paradigm', 'unicorn', 'perform', 'par', 'better', 'task', 'specif', 'counterpart', 'track', 'dataset', 'includ', 'lasot', 'trackingnet', 'mot', 'bddk', 'davi', 'mot', 'bddk', 'mot', 'work', 'accept', 'eccv', 'oral', 'present', 'paper', 'http', 'code', 'http', 'xb', 'motivationobject', 'track', 'one', 'fundament', 'task', 'comput', 'vision', 'aim', 'build', 'pixel', 'level', 'instanc', 'level', 'correspond', 'frame', 'output', 'trajectori', 'typic', 'form', 'box', 'mask', 'year', 'accord', 'differ', 'applic', 'scenario', 'object', 'track', 'problem', 'mainli', 'divid', 'four', 'separ', 'sub', 'task', 'singl', 'object', 'track', 'sot', 'multipl', 'object', 'track', 'mot', 'video', 'object', 'segment', 'vo', 'multi', 'object', 'track', 'segment', 'mot', 'result', 'track', 'approach', 'develop', 'one', 'part', 'sub', 'task', 'despit', 'conveni', 'specif', 'applic', 'fragment', 'situat', 'bring', 'follow', 'drawback']"
182,198,198,PM_ME_YOUR_GIGI,w14ze9,[D] Is learning tensorflow & keras still worth it?," 

Hey guys! I recently acquired *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow*  by  Aurélien Geron. I've mainly worked with pytorch but I wanted to  revise some ML/DL concepts. I probably should have thought about this  before, but given the current trend of migrating from tensorflow to  pytorch, is reading this book right now a step back? Thanks!",75,117,2022-07-17 14:05:06, d  is learning tensorflow   keras still worth it , hey guys  i recently acquired  hands on machine learning with scikit learn  keras  and tensorflow   by  aurélien geron  i ve mainly worked with pytorch but i wanted to  revise some ml dl concepts  i probably should have thought about this  before  but given the current trend of migrating from tensorflow to  pytorch  is reading this book right now a step back  thanks ,hey guys recently acquired hands machine learning scikit learn keras tensorflow aurélien geron mainly worked pytorch wanted revise ml dl concepts probably thought given current trend migrating tensorflow pytorch reading book right step back thanks,learning tensorflow keras still worth,learning tensorflow keras still worthhey guys recently acquired hands machine learning scikit learn keras tensorflow aurélien geron mainly worked pytorch wanted revise ml dl concepts probably thought given current trend migrating tensorflow pytorch reading book right step back thanks,"['learning', 'tensorflow', 'keras', 'still', 'worthhey', 'guys', 'recently', 'acquired', 'hands', 'machine', 'learning', 'scikit', 'learn', 'keras', 'tensorflow', 'aurélien', 'geron', 'mainly', 'worked', 'pytorch', 'wanted', 'revise', 'ml', 'dl', 'concepts', 'probably', 'thought', 'given', 'current', 'trend', 'migrating', 'tensorflow', 'pytorch', 'reading', 'book', 'right', 'step', 'back', 'thanks']","['learn', 'tensorflow', 'kera', 'still', 'worthhey', 'guy', 'recent', 'acquir', 'hand', 'machin', 'learn', 'scikit', 'learn', 'kera', 'tensorflow', 'aurélien', 'geron', 'mainli', 'work', 'pytorch', 'want', 'revis', 'ml', 'dl', 'concept', 'probabl', 'thought', 'given', 'current', 'trend', 'migrat', 'tensorflow', 'pytorch', 'read', 'book', 'right', 'step', 'back', 'thank']"
183,200,200,vikigenius,w1gnrx,[D] Subword tokenization and large pretrained models,"Even with the success of large transformer based models for NLP tasks. There are still many papers in many spaces such as extractive summarization (see [this](https://aclanthology.org/2022.acl-long.450/ ) for example) that use RNNs instead of transformers for encoding text. Mainly because of the limited context size.

One curious thing I have noticed is that, they all tend to use Word level tokenizers with pretrained Glove embeddings.

However every single pretrained transformer model I have seen uses subword tokenization instead be it wordpice BPE or sentencepiece. Why is this?

Does subword tokenization not work well for non transformer models? Do they only work for large pretrained models? 

Another possiblity is that global word embeddings such as GLove seem to be available only for Word level tokenizers, maybe that's why these RNN models tend to use them instead of sub word tokenizers?

But couldn't you have global pretrained subword embeddings for your vocabulary as well?",2,12,2022-07-17 23:30:15, d  subword tokenization and large pretrained models,even with the success of large transformer based models for nlp tasks  there are still many papers in many spaces such as extractive summarization  see  this  https one curious thing i have noticed is that  they all tend to use word level tokenizers with pretrained glove embeddings however every single pretrained transformer model i have seen uses subword tokenization instead be it wordpice bpe or sentencepiece  why is this does subword tokenization not work well for non transformer models  do they only work for large pretrained models  another possiblity is that global word embeddings such as glove seem to be available only for word level tokenizers  maybe that s why these rnn models tend to use them instead of sub word tokenizers but couldn t you have global pretrained subword embeddings for your vocabulary as well ,even success large transformer based models nlp tasks still many papers many spaces extractive summarization see https one curious thing noticed tend use word level tokenizers pretrained glove embeddings however every single pretrained transformer model seen uses subword tokenization instead wordpice bpe sentencepiece subword tokenization work well non transformer models work large pretrained models another possiblity global word embeddings glove seem available word level tokenizers maybe rnn models tend use instead sub word tokenizers global pretrained subword embeddings vocabulary well,subword tokenization large pretrained models,subword tokenization large pretrained modelseven success large transformer based models nlp tasks still many papers many spaces extractive summarization see https one curious thing noticed tend use word level tokenizers pretrained glove embeddings however every single pretrained transformer model seen uses subword tokenization instead wordpice bpe sentencepiece subword tokenization work well non transformer models work large pretrained models another possiblity global word embeddings glove seem available word level tokenizers maybe rnn models tend use instead sub word tokenizers global pretrained subword embeddings vocabulary well,"['subword', 'tokenization', 'large', 'pretrained', 'modelseven', 'success', 'large', 'transformer', 'based', 'models', 'nlp', 'tasks', 'still', 'many', 'papers', 'many', 'spaces', 'extractive', 'summarization', 'see', 'https', 'one', 'curious', 'thing', 'noticed', 'tend', 'use', 'word', 'level', 'tokenizers', 'pretrained', 'glove', 'embeddings', 'however', 'every', 'single', 'pretrained', 'transformer', 'model', 'seen', 'uses', 'subword', 'tokenization', 'instead', 'wordpice', 'bpe', 'sentencepiece', 'subword', 'tokenization', 'work', 'well', 'non', 'transformer', 'models', 'work', 'large', 'pretrained', 'models', 'another', 'possiblity', 'global', 'word', 'embeddings', 'glove', 'seem', 'available', 'word', 'level', 'tokenizers', 'maybe', 'rnn', 'models', 'tend', 'use', 'instead', 'sub', 'word', 'tokenizers', 'global', 'pretrained', 'subword', 'embeddings', 'vocabulary', 'well']","['subword', 'token', 'larg', 'pretrain', 'modelseven', 'success', 'larg', 'transform', 'base', 'model', 'nlp', 'task', 'still', 'mani', 'paper', 'mani', 'space', 'extract', 'summar', 'see', 'http', 'one', 'curiou', 'thing', 'notic', 'tend', 'use', 'word', 'level', 'token', 'pretrain', 'glove', 'embed', 'howev', 'everi', 'singl', 'pretrain', 'transform', 'model', 'seen', 'use', 'subword', 'token', 'instead', 'wordpic', 'bpe', 'sentencepiec', 'subword', 'token', 'work', 'well', 'non', 'transform', 'model', 'work', 'larg', 'pretrain', 'model', 'anoth', 'possibl', 'global', 'word', 'embed', 'glove', 'seem', 'avail', 'word', 'level', 'token', 'mayb', 'rnn', 'model', 'tend', 'use', 'instead', 'sub', 'word', 'token', 'global', 'pretrain', 'subword', 'embed', 'vocabulari', 'well']"
184,202,202,asfarley--,w1k62v,[Discussion] How would you eliminate a small percentage of broken trajectories in a multiple-object tracking dataset?," 

I have a dataset of tagged and linked object bounding-boxes in sequential video frames. If that isn't clear, you can watch a demo here:

[https://www.youtube.com/watch?v=QKxSzFaHsbc](https://www.youtube.com/watch?v=QKxSzFaHsbc)

For various reasons, it's possible that a trajectory could be 'broken' in the dataset. Quick visual scanning doesn't allow detection of a break in a single trajectory; there are so many horizontal links, it's tough to notice one of them being missing.

How would you economically eliminate a small percentage of breaks in trajectories?

Some things I've thought of:  
\* Bootstrapping, i.e. using a trained network to predict -> this is a bit complex, it's possible but not my first choice

\* Build a tool to view all linked detections overlaid in a single frame (doesn't immediately identify broken trajectories, but it might help)

Is there any simple UI I can build to easily identify broken trajectories in the dataset?",11,6,2022-07-18 02:09:16, discussion  how would you eliminate a small percentage of broken trajectories in a multiple object tracking dataset , i have a dataset of tagged and linked object bounding boxes in sequential video frames  if that isn t clear  you can watch a demo here  https for various reasons  it s possible that a trajectory could be  broken  in the dataset  quick visual scanning doesn t allow detection of a break in a single trajectory  there are so many horizontal links  it s tough to notice one of them being missing how would you economically eliminate a small percentage of breaks in trajectories some things i ve thought of      bootstrapping  i e  using a trained network to predict    this is a bit complex  it s possible but not my first choice   build a tool to view all linked detections overlaid in a single frame  doesn t immediately identify broken trajectories  but it might help is there any simple ui i can build to easily identify broken trajectories in the dataset ,dataset tagged linked object bounding boxes sequential video frames clear watch demo https various reasons possible trajectory could broken dataset quick visual scanning allow detection break single trajectory many horizontal links tough notice one missing would economically eliminate small percentage breaks trajectories things thought bootstrapping e using trained network predict bit complex possible first choice build tool view linked detections overlaid single frame immediately identify broken trajectories might help simple ui build easily identify broken trajectories dataset,discussion would eliminate small percentage broken trajectories multiple object tracking dataset,discussion would eliminate small percentage broken trajectories multiple object tracking datasetdataset tagged linked object bounding boxes sequential video frames clear watch demo https various reasons possible trajectory could broken dataset quick visual scanning allow detection break single trajectory many horizontal links tough notice one missing would economically eliminate small percentage breaks trajectories things thought bootstrapping e using trained network predict bit complex possible first choice build tool view linked detections overlaid single frame immediately identify broken trajectories might help simple ui build easily identify broken trajectories dataset,"['discussion', 'would', 'eliminate', 'small', 'percentage', 'broken', 'trajectories', 'multiple', 'object', 'tracking', 'datasetdataset', 'tagged', 'linked', 'object', 'bounding', 'boxes', 'sequential', 'video', 'frames', 'clear', 'watch', 'demo', 'https', 'various', 'reasons', 'possible', 'trajectory', 'could', 'broken', 'dataset', 'quick', 'visual', 'scanning', 'allow', 'detection', 'break', 'single', 'trajectory', 'many', 'horizontal', 'links', 'tough', 'notice', 'one', 'missing', 'would', 'economically', 'eliminate', 'small', 'percentage', 'breaks', 'trajectories', 'things', 'thought', 'bootstrapping', 'e', 'using', 'trained', 'network', 'predict', 'bit', 'complex', 'possible', 'first', 'choice', 'build', 'tool', 'view', 'linked', 'detections', 'overlaid', 'single', 'frame', 'immediately', 'identify', 'broken', 'trajectories', 'might', 'help', 'simple', 'ui', 'build', 'easily', 'identify', 'broken', 'trajectories', 'dataset']","['discuss', 'would', 'elimin', 'small', 'percentag', 'broken', 'trajectori', 'multipl', 'object', 'track', 'datasetdataset', 'tag', 'link', 'object', 'bound', 'box', 'sequenti', 'video', 'frame', 'clear', 'watch', 'demo', 'http', 'variou', 'reason', 'possibl', 'trajectori', 'could', 'broken', 'dataset', 'quick', 'visual', 'scan', 'allow', 'detect', 'break', 'singl', 'trajectori', 'mani', 'horizont', 'link', 'tough', 'notic', 'one', 'miss', 'would', 'econom', 'elimin', 'small', 'percentag', 'break', 'trajectori', 'thing', 'thought', 'bootstrap', 'e', 'use', 'train', 'network', 'predict', 'bit', 'complex', 'possibl', 'first', 'choic', 'build', 'tool', 'view', 'link', 'detect', 'overlaid', 'singl', 'frame', 'immedi', 'identifi', 'broken', 'trajectori', 'might', 'help', 'simpl', 'ui', 'build', 'easili', 'identifi', 'broken', 'trajectori', 'dataset']"
185,204,204,espadrine,w1and7,[D] How to download MassiveText,"Hi, I noticed that this year, a large number of LLMs and related models are trained on the [MassiveText][] dataset, including Gopher, RETRO, Chinchilla, Gato, Flamingo…

While they describe the contents, I could not find a download link. Is the dataset secret in some way? Or is there a way to download it?

[MassiveText]: https://arxiv.org/pdf/2112.11446.pdf",4,3,2022-07-17 19:00:38, d  how to download massivetext,hi  i noticed that this year  a large number of llms and related models are trained on the  massivetext    dataset  including gopher  retro  chinchilla  gato  flamingo while they describe the contents  i could not find a download link  is the dataset secret in some way  or is there a way to download it  massivetext   https   arxiv org pdf   pdf,hi noticed year large number llms related models trained massivetext dataset including gopher retro chinchilla gato flamingo describe contents could find download link dataset secret way way download massivetext https arxiv org pdf pdf,download massivetext,download massivetexthi noticed year large number llms related models trained massivetext dataset including gopher retro chinchilla gato flamingo describe contents could find download link dataset secret way way download massivetext https arxiv org pdf pdf,"['download', 'massivetexthi', 'noticed', 'year', 'large', 'number', 'llms', 'related', 'models', 'trained', 'massivetext', 'dataset', 'including', 'gopher', 'retro', 'chinchilla', 'gato', 'flamingo', 'describe', 'contents', 'could', 'find', 'download', 'link', 'dataset', 'secret', 'way', 'way', 'download', 'massivetext', 'https', 'arxiv', 'org', 'pdf', 'pdf']","['download', 'massivetexthi', 'notic', 'year', 'larg', 'number', 'llm', 'relat', 'model', 'train', 'massivetext', 'dataset', 'includ', 'gopher', 'retro', 'chinchilla', 'gato', 'flamingo', 'describ', 'content', 'could', 'find', 'download', 'link', 'dataset', 'secret', 'way', 'way', 'download', 'massivetext', 'http', 'arxiv', 'org', 'pdf', 'pdf']"
186,205,205,IllustriousCicada603,w13djq,[D] Machine Learning models that learn to evaluate themselves during training,"Does it make sense to have an additional regression head in a model (e.g. in a language architecture) which takes as input the current response of the language model and tries to ""predict"" its perplexity/loss but without having the real labels? Instead the labels to the regressor would be the already computed loss/perplexity.

&#x200B;

[Visual representation](https://preview.redd.it/s23dbbzsi3c91.png?width=4720&format=png&auto=webp&s=0829c56fb87120dd1f97e489297d5e5fa03f1283)

I have seen in many architectures for NLP or computer vision additional (auxiliary) tasks which classify or contrast the real labels and some other randomly sampled labels. They don't even use this part of the model during inference but it helps during training and works as a regularization. My proposal aims to work in a similar way.

Could this approach make a model more effective and what are the possible drawbacks? Also, if you are aware of some relevant research, please point it out.",2,8,2022-07-17 12:17:59, d  machine learning models that learn to evaluate themselves during training,does it make sense to have an additional regression head in a model  e g  in a language architecture  which takes as input the current response of the language model and tries to predict its perplexity loss but without having the real labels  instead the labels to the regressor would be the already computed loss perplexity   xb  visual representation  https i have seen in many architectures for nlp or computer vision additional  auxiliary  tasks which classify or contrast the real labels and some other randomly sampled labels  they don t even use this part of the model during inference but it helps during training and works as a regularization  my proposal aims to work in a similar way could this approach make a model more effective and what are the possible drawbacks  also  if you are aware of some relevant research  please point it out ,make sense additional regression head model e g language architecture takes input current response language model tries predict perplexity loss without real labels instead labels regressor would already computed loss perplexity xb visual representation https seen many architectures nlp computer vision additional auxiliary tasks classify contrast real labels randomly sampled labels even use part model inference helps training works regularization proposal aims work similar way could approach make model effective possible drawbacks also aware relevant research please point,machine learning models learn evaluate training,machine learning models learn evaluate trainingmake sense additional regression head model e g language architecture takes input current response language model tries predict perplexity loss without real labels instead labels regressor would already computed loss perplexity xb visual representation https seen many architectures nlp computer vision additional auxiliary tasks classify contrast real labels randomly sampled labels even use part model inference helps training works regularization proposal aims work similar way could approach make model effective possible drawbacks also aware relevant research please point,"['machine', 'learning', 'models', 'learn', 'evaluate', 'trainingmake', 'sense', 'additional', 'regression', 'head', 'model', 'e', 'g', 'language', 'architecture', 'takes', 'input', 'current', 'response', 'language', 'model', 'tries', 'predict', 'perplexity', 'loss', 'without', 'real', 'labels', 'instead', 'labels', 'regressor', 'would', 'already', 'computed', 'loss', 'perplexity', 'xb', 'visual', 'representation', 'https', 'seen', 'many', 'architectures', 'nlp', 'computer', 'vision', 'additional', 'auxiliary', 'tasks', 'classify', 'contrast', 'real', 'labels', 'randomly', 'sampled', 'labels', 'even', 'use', 'part', 'model', 'inference', 'helps', 'training', 'works', 'regularization', 'proposal', 'aims', 'work', 'similar', 'way', 'could', 'approach', 'make', 'model', 'effective', 'possible', 'drawbacks', 'also', 'aware', 'relevant', 'research', 'please', 'point']","['machin', 'learn', 'model', 'learn', 'evalu', 'trainingmak', 'sens', 'addit', 'regress', 'head', 'model', 'e', 'g', 'languag', 'architectur', 'take', 'input', 'current', 'respons', 'languag', 'model', 'tri', 'predict', 'perplex', 'loss', 'without', 'real', 'label', 'instead', 'label', 'regressor', 'would', 'alreadi', 'comput', 'loss', 'perplex', 'xb', 'visual', 'represent', 'http', 'seen', 'mani', 'architectur', 'nlp', 'comput', 'vision', 'addit', 'auxiliari', 'task', 'classifi', 'contrast', 'real', 'label', 'randomli', 'sampl', 'label', 'even', 'use', 'part', 'model', 'infer', 'help', 'train', 'work', 'regular', 'propos', 'aim', 'work', 'similar', 'way', 'could', 'approach', 'make', 'model', 'effect', 'possibl', 'drawback', 'also', 'awar', 'relev', 'research', 'pleas', 'point']"
187,207,207,majianthu,w13p02,[P] the Python package {copent} v0.3 available on PyPI,"The Python package {copent} v0.3 now available on PyPI, with the new function 'mvnt' that implements the method for estimating the copula entropy-based statistic for multivariate normality test. See arXiv:2206.05956 for more details.

GITHUB: [https://github.com/majianthu/pycopent](https://github.com/majianthu/pycopent)

PyPI: [https://pypi.org/project/copent/](https://pypi.org/project/copent/)

Your comments are welcome.",0,6,2022-07-17 12:39:38, p  the python package  copent  v  available on pypi,the python package  copent  v  now available on pypi  with the new function  mvnt  that implements the method for estimating the copula entropy based statistic for multivariate normality test  see arxiv   for more details github   https pypi   https your comments are welcome ,python package copent v available pypi function mvnt implements method estimating copula entropy based statistic multivariate normality test see arxiv details github https pypi https comments welcome,p python package copent v available pypi,p python package copent v available pypipython package copent v available pypi function mvnt implements method estimating copula entropy based statistic multivariate normality test see arxiv details github https pypi https comments welcome,"['p', 'python', 'package', 'copent', 'v', 'available', 'pypipython', 'package', 'copent', 'v', 'available', 'pypi', 'function', 'mvnt', 'implements', 'method', 'estimating', 'copula', 'entropy', 'based', 'statistic', 'multivariate', 'normality', 'test', 'see', 'arxiv', 'details', 'github', 'https', 'pypi', 'https', 'comments', 'welcome']","['p', 'python', 'packag', 'copent', 'v', 'avail', 'pypipython', 'packag', 'copent', 'v', 'avail', 'pypi', 'function', 'mvnt', 'implement', 'method', 'estim', 'copula', 'entropi', 'base', 'statist', 'multivari', 'normal', 'test', 'see', 'arxiv', 'detail', 'github', 'http', 'pypi', 'http', 'comment', 'welcom']"
188,208,208,biandangou,w0v4w8,[R] Highlights for every ICML 2022 paper,"Here is the list of all >1,200 ICML 2022 (International Conference on Machine Learning) papers, and a highlight for each of them. ICML 2022 will take place from July 17 at Baltimore.

[https://www.paperdigest.org/2022/07/icml-2022-highlights/](https://www.paperdigest.org/2022/07/icml-2022-highlights/)",3,17,2022-07-17 04:00:05, r  highlights for every icml  paper,here is the list of all    icml   international conference on machine learning  papers  and a highlight for each of them  icml  will take place from july  at baltimore  https   www paperdigest org   icml  highlights   https   www paperdigest org   icml  highlights  ,icml international conference machine learning papers highlight icml take place july baltimore https www paperdigest org icml highlights https www paperdigest org icml highlights,r highlights every icml paper,r highlights every icml papericml international conference machine learning papers highlight icml take place july baltimore https www paperdigest org icml highlights https www paperdigest org icml highlights,"['r', 'highlights', 'every', 'icml', 'papericml', 'international', 'conference', 'machine', 'learning', 'papers', 'highlight', 'icml', 'take', 'place', 'july', 'baltimore', 'https', 'www', 'paperdigest', 'org', 'icml', 'highlights', 'https', 'www', 'paperdigest', 'org', 'icml', 'highlights']","['r', 'highlight', 'everi', 'icml', 'papericml', 'intern', 'confer', 'machin', 'learn', 'paper', 'highlight', 'icml', 'take', 'place', 'juli', 'baltimor', 'http', 'www', 'paperdigest', 'org', 'icml', 'highlight', 'http', 'www', 'paperdigest', 'org', 'icml', 'highlight']"
189,209,209,AlexeyAB,w078id,[P] YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors,"Official YOLOv7 surpasses all known object detectors in both speed and accuracy in the range from 5 FPS to 160 FPS and has the highest accuracy 56.8% AP among all known real-time object detectors with 30 FPS or higher on GPU V100. YOLOv7-E6 object detector (56 FPS V100, 55.9% AP) outperforms both transformer-based detector SWIN-L Cascade-Mask R-CNN (9.2 FPS A100, 53.9% AP) by 509% in speed and 2% in accuracy, and convolutional-based detector ConvNeXt-XL Cascade-Mask R-CNN (8.6 FPS A100, 55.2% AP) by 551% in speed and 0.7% AP in accuracy, as well as YOLOv7 outperforms: YOLOR, YOLOX, Scaled-YOLOv4, YOLOv5, DETR, Deformable DETR, DINO-5scale-R50, ViT-Adapter-B and many other object detectors in speed and accuracy. Moreover, we train YOLOv7 only on MS COCO dataset from scratch without using any other datasets or pre-trained weights. Source code is released in this https URL.

The maximum accuracy of the YOLOv7-E6E (56.8% AP) real-time model is +13.7% AP higher than the current most accurate meituan/YOLOv6-s model (43.1% AP) on COCO dataset. Our YOLOv7-tiny (35.2% AP, 0.4 ms) model is +25% faster and +0.2% AP higher than meituan/YOLOv6-n (35.0% AP, 0.5 ms) under identical conditions on COCO dataset and V100 GPU with batch=32.

[https://arxiv.org/abs/2207.02696](https://arxiv.org/abs/2207.02696)

[https://github.com/WongKinYiu/yolov7](https://github.com/WongKinYiu/yolov7)

[https://paperswithcode.com/sota/real-time-object-detection-on-coco?dimension=FPS%20(V100%2C%20b%3D1)](https://paperswithcode.com/sota/real-time-object-detection-on-coco?dimension=FPS%20(V100%2C%20b%3D1))

https://preview.redd.it/m9yldqadqub91.jpg?width=1577&format=pjpg&auto=webp&s=9c1196bfd21f2aef69ce438909ea741a5c6b082c",36,200,2022-07-16 06:44:46, p  yolov  trainable bag of freebies sets new state of the art for real time object detectors,official yolov surpasses all known object detectors in both speed and accuracy in the range from  fps to  fps and has the highest accuracy    ap among all known real time object detectors with  fps or higher on gpu v  yolov e object detector   fps v     ap  outperforms both transformer based detector swin l cascade mask r cnn    fps a     ap  by   in speed and   in accuracy  and convolutional based detector convnext xl cascade mask r cnn    fps a     ap  by   in speed and    ap in accuracy  as well as yolov outperforms  yolor  yolox  scaled yolov  yolov  detr  deformable detr  dino scale r  vit adapter b and many other object detectors in speed and accuracy  moreover  we train yolov only on ms coco dataset from scratch without using any other datasets or pre trained weights  source code is released in this https url the maximum accuracy of the yolov ee     ap  real time model is     ap higher than the current most accurate meituan yolov s model     ap  on coco dataset  our yolov tiny     ap    ms  model is    faster and     ap higher than meituan yolov n     ap    ms  under identical conditions on coco dataset and v gpu with batch   https  https  https https   preview redd it myldqadqub jpg width  format pjpg auto webp s cbfdfaefceeaacbc,official yolov surpasses known object detectors speed accuracy range fps fps highest accuracy ap among known real time object detectors fps higher gpu v yolov e object detector fps v ap outperforms transformer based detector swin l cascade mask r cnn fps ap speed accuracy convolutional based detector convnext xl cascade mask r cnn fps ap speed ap accuracy well yolov outperforms yolor yolox scaled yolov yolov detr deformable detr dino scale r vit adapter b many object detectors speed accuracy moreover train yolov ms coco dataset scratch without using datasets pre trained weights source code released https url maximum accuracy yolov ee ap real time model ap higher current accurate meituan yolov model ap coco dataset yolov tiny ap ms model faster ap higher meituan yolov n ap ms identical conditions coco dataset v gpu batch https https https https preview redd myldqadqub jpg width format pjpg auto webp cbfdfaefceeaacbc,p yolov trainable bag freebies sets state art real time object detectors,p yolov trainable bag freebies sets state art real time object detectorsofficial yolov surpasses known object detectors speed accuracy range fps fps highest accuracy ap among known real time object detectors fps higher gpu v yolov e object detector fps v ap outperforms transformer based detector swin l cascade mask r cnn fps ap speed accuracy convolutional based detector convnext xl cascade mask r cnn fps ap speed ap accuracy well yolov outperforms yolor yolox scaled yolov yolov detr deformable detr dino scale r vit adapter b many object detectors speed accuracy moreover train yolov ms coco dataset scratch without using datasets pre trained weights source code released https url maximum accuracy yolov ee ap real time model ap higher current accurate meituan yolov model ap coco dataset yolov tiny ap ms model faster ap higher meituan yolov n ap ms identical conditions coco dataset v gpu batch https https https https preview redd myldqadqub jpg width format pjpg auto webp cbfdfaefceeaacbc,"['p', 'yolov', 'trainable', 'bag', 'freebies', 'sets', 'state', 'art', 'real', 'time', 'object', 'detectorsofficial', 'yolov', 'surpasses', 'known', 'object', 'detectors', 'speed', 'accuracy', 'range', 'fps', 'fps', 'highest', 'accuracy', 'ap', 'among', 'known', 'real', 'time', 'object', 'detectors', 'fps', 'higher', 'gpu', 'v', 'yolov', 'e', 'object', 'detector', 'fps', 'v', 'ap', 'outperforms', 'transformer', 'based', 'detector', 'swin', 'l', 'cascade', 'mask', 'r', 'cnn', 'fps', 'ap', 'speed', 'accuracy', 'convolutional', 'based', 'detector', 'convnext', 'xl', 'cascade', 'mask', 'r', 'cnn', 'fps', 'ap', 'speed', 'ap', 'accuracy', 'well', 'yolov', 'outperforms', 'yolor', 'yolox', 'scaled', 'yolov', 'yolov', 'detr', 'deformable', 'detr', 'dino', 'scale', 'r', 'vit', 'adapter', 'b', 'many', 'object', 'detectors', 'speed', 'accuracy', 'moreover', 'train', 'yolov', 'ms', 'coco', 'dataset', 'scratch', 'without', 'using', 'datasets', 'pre', 'trained', 'weights', 'source', 'code', 'released', 'https', 'url', 'maximum', 'accuracy', 'yolov', 'ee', 'ap', 'real', 'time', 'model', 'ap', 'higher', 'current', 'accurate', 'meituan', 'yolov', 'model', 'ap', 'coco', 'dataset', 'yolov', 'tiny', 'ap', 'ms', 'model', 'faster', 'ap', 'higher', 'meituan', 'yolov', 'n', 'ap', 'ms', 'identical', 'conditions', 'coco', 'dataset', 'v', 'gpu', 'batch', 'https', 'https', 'https', 'https', 'preview', 'redd', 'myldqadqub', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'cbfdfaefceeaacbc']","['p', 'yolov', 'trainabl', 'bag', 'freebi', 'set', 'state', 'art', 'real', 'time', 'object', 'detectorsoffici', 'yolov', 'surpass', 'known', 'object', 'detector', 'speed', 'accuraci', 'rang', 'fp', 'fp', 'highest', 'accuraci', 'ap', 'among', 'known', 'real', 'time', 'object', 'detector', 'fp', 'higher', 'gpu', 'v', 'yolov', 'e', 'object', 'detector', 'fp', 'v', 'ap', 'outperform', 'transform', 'base', 'detector', 'swin', 'l', 'cascad', 'mask', 'r', 'cnn', 'fp', 'ap', 'speed', 'accuraci', 'convolut', 'base', 'detector', 'convnext', 'xl', 'cascad', 'mask', 'r', 'cnn', 'fp', 'ap', 'speed', 'ap', 'accuraci', 'well', 'yolov', 'outperform', 'yolor', 'yolox', 'scale', 'yolov', 'yolov', 'detr', 'deform', 'detr', 'dino', 'scale', 'r', 'vit', 'adapt', 'b', 'mani', 'object', 'detector', 'speed', 'accuraci', 'moreov', 'train', 'yolov', 'ms', 'coco', 'dataset', 'scratch', 'without', 'use', 'dataset', 'pre', 'train', 'weight', 'sourc', 'code', 'releas', 'http', 'url', 'maximum', 'accuraci', 'yolov', 'ee', 'ap', 'real', 'time', 'model', 'ap', 'higher', 'current', 'accur', 'meituan', 'yolov', 'model', 'ap', 'coco', 'dataset', 'yolov', 'tini', 'ap', 'ms', 'model', 'faster', 'ap', 'higher', 'meituan', 'yolov', 'n', 'ap', 'ms', 'ident', 'condit', 'coco', 'dataset', 'v', 'gpu', 'batch', 'http', 'http', 'http', 'http', 'preview', 'redd', 'myldqadqub', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'cbfdfaefceeaacbc']"
190,210,210,ashboy64,w0n9ek,[Discussion] Epistemic NNs: Marginal vs Joint Log Loss,"I was recently reading the following paper that introduces an architecture called “Epistemic Neural Networks”: [https://arxiv.org/pdf/2107.08924.pdf](https://arxiv.org/pdf/2107.08924.pdf). The proposed architecture achieves high quality joint probability predictions at lower computational cost than other methods (e.g. ensembles). The paper measures the quality of joint predictions in terms of the “joint log loss” (as opposed to the marginal log loss, which as far as I can tell is the traditional log likelihood expression). Does anyone know how this joint log loss term is computed? They give the following equation for the joint probability predicted by the model:

&#x200B;

https://preview.redd.it/wgyyqz1j5zb91.png?width=608&format=png&auto=webp&s=a009b83c8500e4e77f27544e096596aad39b7bf6

But I am unsure how this would be computed in practice (it does not seem possible to evaluate the integral exactly). One option is to approximate it by just taking the average of the product of marginals across different z, but the paper does not state that they do this.

Sorry if this is not the appropriate forum for such a question, and thanks in advance!",7,4,2022-07-16 21:36:34, discussion  epistemic nns  marginal vs joint log loss,i was recently reading the following paper that introduces an architecture called  epistemic neural networks    https   xb https but i am unsure how this would be computed in practice  it does not seem possible to evaluate the integral exactly   one option is to approximate it by just taking the average of the product of marginals across different z  but the paper does not state that they do this sorry if this is not the appropriate forum for such a question  and thanks in advance ,recently reading following paper introduces architecture called epistemic neural networks https xb https unsure would computed practice seem possible evaluate integral exactly one option approximate taking average product marginals across different z paper state sorry appropriate forum question thanks advance,discussion epistemic nns marginal vs joint log loss,discussion epistemic nns marginal vs joint log lossrecently reading following paper introduces architecture called epistemic neural networks https xb https unsure would computed practice seem possible evaluate integral exactly one option approximate taking average product marginals across different z paper state sorry appropriate forum question thanks advance,"['discussion', 'epistemic', 'nns', 'marginal', 'vs', 'joint', 'log', 'lossrecently', 'reading', 'following', 'paper', 'introduces', 'architecture', 'called', 'epistemic', 'neural', 'networks', 'https', 'xb', 'https', 'unsure', 'would', 'computed', 'practice', 'seem', 'possible', 'evaluate', 'integral', 'exactly', 'one', 'option', 'approximate', 'taking', 'average', 'product', 'marginals', 'across', 'different', 'z', 'paper', 'state', 'sorry', 'appropriate', 'forum', 'question', 'thanks', 'advance']","['discuss', 'epistem', 'nn', 'margin', 'vs', 'joint', 'log', 'lossrec', 'read', 'follow', 'paper', 'introduc', 'architectur', 'call', 'epistem', 'neural', 'network', 'http', 'xb', 'http', 'unsur', 'would', 'comput', 'practic', 'seem', 'possibl', 'evalu', 'integr', 'exactli', 'one', 'option', 'approxim', 'take', 'averag', 'product', 'margin', 'across', 'differ', 'z', 'paper', 'state', 'sorri', 'appropri', 'forum', 'question', 'thank', 'advanc']"
191,211,211,XinshaoWang,w0effk,"[Research] Being a great researcher is not easy: not only publishing novel great technical papers, but also correcting the research legacies of the community, etc.","I would like to share personal insights about doing great research and towards being a globally leading researcher:  
#### Not all our research legacies are correct or will be corrected shortly, so just keep taking the initiative to correct them. [https://openreview.net/forum?id=xENf4QUL4LW&noteId=C2eCHs2k6CM](https://openreview.net/forum?id=xENf4QUL4LW&noteId=C2eCHs2k6CM).  


#### Not all our papers get cited or published, so when our papers serve as a great foundation for other works, just keep positive and confident to deliver them to more people who may be interested. 
* [Reddit discussion](https://www.reddit.com/r/MachineLearning/comments/vkc7fo/research_not_all_our_papers_get_published/)
* [Linkedin discussion](https://www.linkedin.com/posts/xinshaowang_the-probabilistic-normal-epipolar-constraint-activity-6944535197044367360-jpu5?utm_source=linkedin_share&utm_medium=member_desktop_web)",1,14,2022-07-16 14:23:03, research  being a great researcher is not easy  not only publishing novel great technical papers  but also correcting the research legacies of the community  etc ,i would like to share personal insights about doing great research and towards being a globally leading researcher        not all our research legacies are correct or will be corrected shortly  so just keep taking the initiative to correct them   https      not all our papers get cited or published  so when our papers serve as a great foundation for other works  just keep positive and confident to deliver them to more people who may be interested     reddit discussion  https    linkedin discussion  https   www linkedin com posts xinshaowang_the probabilistic normal epipolar constraint activity  jpu utm_source linkedin_share utm_medium member_desktop_web ,would like share personal insights great research towards globally leading researcher research legacies correct corrected shortly keep taking initiative correct https papers get cited published papers serve great foundation works keep positive confident deliver people may interested reddit discussion https linkedin discussion https www linkedin com posts xinshaowang_the probabilistic normal epipolar constraint activity jpu utm_source linkedin_share utm_medium member_desktop_web,research great researcher easy publishing novel great technical papers also correcting research legacies community etc,research great researcher easy publishing novel great technical papers also correcting research legacies community etcwould like share personal insights great research towards globally leading researcher research legacies correct corrected shortly keep taking initiative correct https papers get cited published papers serve great foundation works keep positive confident deliver people may interested reddit discussion https linkedin discussion https www linkedin com posts xinshaowang_the probabilistic normal epipolar constraint activity jpu utm_source linkedin_share utm_medium member_desktop_web,"['research', 'great', 'researcher', 'easy', 'publishing', 'novel', 'great', 'technical', 'papers', 'also', 'correcting', 'research', 'legacies', 'community', 'etcwould', 'like', 'share', 'personal', 'insights', 'great', 'research', 'towards', 'globally', 'leading', 'researcher', 'research', 'legacies', 'correct', 'corrected', 'shortly', 'keep', 'taking', 'initiative', 'correct', 'https', 'papers', 'get', 'cited', 'published', 'papers', 'serve', 'great', 'foundation', 'works', 'keep', 'positive', 'confident', 'deliver', 'people', 'may', 'interested', 'reddit', 'discussion', 'https', 'linkedin', 'discussion', 'https', 'www', 'linkedin', 'com', 'posts', 'xinshaowang_the', 'probabilistic', 'normal', 'epipolar', 'constraint', 'activity', 'jpu', 'utm_source', 'linkedin_share', 'utm_medium', 'member_desktop_web']","['research', 'great', 'research', 'easi', 'publish', 'novel', 'great', 'technic', 'paper', 'also', 'correct', 'research', 'legaci', 'commun', 'etcwould', 'like', 'share', 'person', 'insight', 'great', 'research', 'toward', 'global', 'lead', 'research', 'research', 'legaci', 'correct', 'correct', 'shortli', 'keep', 'take', 'initi', 'correct', 'http', 'paper', 'get', 'cite', 'publish', 'paper', 'serv', 'great', 'foundat', 'work', 'keep', 'posit', 'confid', 'deliv', 'peopl', 'may', 'interest', 'reddit', 'discuss', 'http', 'linkedin', 'discuss', 'http', 'www', 'linkedin', 'com', 'post', 'xinshaowang_th', 'probabilist', 'normal', 'epipolar', 'constraint', 'activ', 'jpu', 'utm_sourc', 'linkedin_shar', 'utm_medium', 'member_desktop_web']"
192,212,212,samlhuillier3,w0e7gh,[D] Where do I go about deploying a transformer model on a low-cost gpu server?,All the GPU offerings are too bloody confusing!  I've trained a video generating transformer model and to deploy it (for demo purposes) I need a simple GPU. Where can I get a simple web server with a low-cost reasonably crappy GPU that charges me monthly?,10,10,2022-07-16 14:09:41, d  where do i go about deploying a transformer model on a low cost gpu server ,all the gpu offerings are too bloody confusing   i ve trained a video generating transformer model and to deploy it  for demo purposes  i need a simple gpu  where can i get a simple web server with a low cost reasonably crappy gpu that charges me monthly ,gpu offerings bloody confusing trained video generating transformer model deploy demo purposes need simple gpu get simple web server low cost reasonably crappy gpu charges monthly,go deploying transformer model low cost gpu server,go deploying transformer model low cost gpu servergpu offerings bloody confusing trained video generating transformer model deploy demo purposes need simple gpu get simple web server low cost reasonably crappy gpu charges monthly,"['go', 'deploying', 'transformer', 'model', 'low', 'cost', 'gpu', 'servergpu', 'offerings', 'bloody', 'confusing', 'trained', 'video', 'generating', 'transformer', 'model', 'deploy', 'demo', 'purposes', 'need', 'simple', 'gpu', 'get', 'simple', 'web', 'server', 'low', 'cost', 'reasonably', 'crappy', 'gpu', 'charges', 'monthly']","['go', 'deploy', 'transform', 'model', 'low', 'cost', 'gpu', 'servergpu', 'offer', 'bloodi', 'confus', 'train', 'video', 'gener', 'transform', 'model', 'deploy', 'demo', 'purpos', 'need', 'simpl', 'gpu', 'get', 'simpl', 'web', 'server', 'low', 'cost', 'reason', 'crappi', 'gpu', 'charg', 'monthli']"
193,213,213,Illustrious_Row_9971,w0d1qe,"[N] Interested in machine learning? Join the Hugging Face Gradio Hackathon at EuroPython 2022 in person in Dublin, Ireland or remotely online","&#x200B;

https://preview.redd.it/aw42pkp6kwb91.png?width=2618&format=png&auto=webp&s=b39ec28da21c6835ad62bc08376da742adaf8393

# EuroPython 2022

EuroPython Dublin, You're invited!

Welcome to the 21st EuroPython. We're the oldest and longest running volunteer-led Python programming conference on the planet! Join us in July in the beautiful and vibrant city of Dublin. We'll be together, face to face and online, to celebrate our shared passion for Python and its community!

## Hugging Face Gradio Hackathon 🤗

Come Join us from July 13th to 17th for a Hackathon in person and online using Gradio and Hugging Face to build and host Machine Learning demos. Find tutorial on getting started with Gradio on Hugging Face [here](https://huggingface.co/course/chapter9/1?fw=pt) and to get started with the new Gradio Blocks API [here](https://gradio.app/introduction_to_blocks/). Once the gradio demo is setup, see how to add it to Hugging Face Spaces [here](https://huggingface.co/docs/hub/spaces-sdks-gradio). 

### Join organization by clicking [here](https://huggingface.co/organizations/EuroPython2022/share/sVhJHDTrJDJkyWTJsRUwTHCSMZYUPlMhUt)",0,10,2022-07-16 12:53:54, n  interested in machine learning  join the hugging face gradio hackathon at europython  in person in dublin  ireland or remotely online,  xb https   europython europython dublin  you re invited welcome to the st europython  we re the oldest and longest running volunteer led python programming conference on the planet  join us in july in the beautiful and vibrant city of dublin  we ll be together  face to face and online  to celebrate our shared passion for python and its community    hugging face gradio hackathon  come join us from july th to th for a hackathon in person and online using gradio and hugging face to build and host machine learning demos  find tutorial on getting started with gradio on hugging face  here  https     join organization by clicking  here  https   huggingface co organizations europython share svhjhdtrjdjkywtjsruwthcsmzyuplmhut ,xb https europython europython dublin invited welcome st europython oldest longest running volunteer led python programming conference planet join us july beautiful vibrant city dublin together face face online celebrate shared passion python community hugging face gradio hackathon come join us july th th hackathon person online using gradio hugging face build host machine learning demos find tutorial getting started gradio hugging face https join organization clicking https huggingface co organizations europython share svhjhdtrjdjkywtjsruwthcsmzyuplmhut,n interested machine learning join hugging face gradio hackathon europython person dublin ireland remotely online,n interested machine learning join hugging face gradio hackathon europython person dublin ireland remotely onlinexb https europython europython dublin invited welcome st europython oldest longest running volunteer led python programming conference planet join us july beautiful vibrant city dublin together face face online celebrate shared passion python community hugging face gradio hackathon come join us july th th hackathon person online using gradio hugging face build host machine learning demos find tutorial getting started gradio hugging face https join organization clicking https huggingface co organizations europython share svhjhdtrjdjkywtjsruwthcsmzyuplmhut,"['n', 'interested', 'machine', 'learning', 'join', 'hugging', 'face', 'gradio', 'hackathon', 'europython', 'person', 'dublin', 'ireland', 'remotely', 'onlinexb', 'https', 'europython', 'europython', 'dublin', 'invited', 'welcome', 'st', 'europython', 'oldest', 'longest', 'running', 'volunteer', 'led', 'python', 'programming', 'conference', 'planet', 'join', 'us', 'july', 'beautiful', 'vibrant', 'city', 'dublin', 'together', 'face', 'face', 'online', 'celebrate', 'shared', 'passion', 'python', 'community', 'hugging', 'face', 'gradio', 'hackathon', 'come', 'join', 'us', 'july', 'th', 'th', 'hackathon', 'person', 'online', 'using', 'gradio', 'hugging', 'face', 'build', 'host', 'machine', 'learning', 'demos', 'find', 'tutorial', 'getting', 'started', 'gradio', 'hugging', 'face', 'https', 'join', 'organization', 'clicking', 'https', 'huggingface', 'co', 'organizations', 'europython', 'share', 'svhjhdtrjdjkywtjsruwthcsmzyuplmhut']","['n', 'interest', 'machin', 'learn', 'join', 'hug', 'face', 'gradio', 'hackathon', 'europython', 'person', 'dublin', 'ireland', 'remot', 'onlinexb', 'http', 'europython', 'europython', 'dublin', 'invit', 'welcom', 'st', 'europython', 'oldest', 'longest', 'run', 'volunt', 'led', 'python', 'program', 'confer', 'planet', 'join', 'us', 'juli', 'beauti', 'vibrant', 'citi', 'dublin', 'togeth', 'face', 'face', 'onlin', 'celebr', 'share', 'passion', 'python', 'commun', 'hug', 'face', 'gradio', 'hackathon', 'come', 'join', 'us', 'juli', 'th', 'th', 'hackathon', 'person', 'onlin', 'use', 'gradio', 'hug', 'face', 'build', 'host', 'machin', 'learn', 'demo', 'find', 'tutori', 'get', 'start', 'gradio', 'hug', 'face', 'http', 'join', 'organ', 'click', 'http', 'huggingfac', 'co', 'organ', 'europython', 'share', 'svhjhdtrjdjkywtjsruwthcsmzyuplmhut']"
194,215,215,byebaybay,vzumye,"[P] Feedback for our model evaluation and interpretability platform, $100 gift card for your time!","Hi everyone!

I'm Gabriel Bayomi, one of the founders of Unbox ([https://unbox.ai](https://unbox.ai/)) and an ML engineer myself. Over the years, we learned that ML model evaluation is a huge challenge, so we started Unbox to make it easy for ML teams to find failures and biases in their models, figure out their root causes and use better data to fix them.

We’re launching the alpha version of our new community edition (free!), and we’d love to get feedback on our product before doing our beta launch.

We’ll be giving a $100 gift card to folks who are willing to give some time to this and provide feedback on the usability of the product.

It’s super easy, you just need to sign-up here: [https://unbox.ai/alpha?ref=reddit.](https://unbox.ai/alpha?ref=reddit)

Look forward to hearing from you! You can always email me with any questions ([gabriel@unbox.ai](mailto:gabriel@unbox.ai) \- community Slack coming soon) or throw them out here in the thread.

Gabriel",19,90,2022-07-15 20:45:21, p  feedback for our model evaluation and interpretability platform    gift card for your time ,hi everyone i m gabriel bayomi  one of the founders of unbox   https we re launching the alpha version of our new community edition  free    and we d love to get feedback on our product before doing our beta launch we ll be giving a   gift card to folks who are willing to give some time to this and provide feedback on the usability of the product it s super easy  you just need to sign up here   https look forward to hearing from you  you can always email me with any questions   gabriel unbox ai  mailto gabriel unbox ai     community slack coming soon  or throw them out here in the thread gabriel,hi everyone gabriel bayomi one founders unbox https launching alpha version community edition free love get feedback product beta launch giving gift card folks willing give time provide feedback usability product super easy need sign https look forward hearing always email questions gabriel unbox ai mailto gabriel unbox ai community slack coming soon throw thread gabriel,p feedback model evaluation interpretability platform gift card time,p feedback model evaluation interpretability platform gift card timehi everyone gabriel bayomi one founders unbox https launching alpha version community edition free love get feedback product beta launch giving gift card folks willing give time provide feedback usability product super easy need sign https look forward hearing always email questions gabriel unbox ai mailto gabriel unbox ai community slack coming soon throw thread gabriel,"['p', 'feedback', 'model', 'evaluation', 'interpretability', 'platform', 'gift', 'card', 'timehi', 'everyone', 'gabriel', 'bayomi', 'one', 'founders', 'unbox', 'https', 'launching', 'alpha', 'version', 'community', 'edition', 'free', 'love', 'get', 'feedback', 'product', 'beta', 'launch', 'giving', 'gift', 'card', 'folks', 'willing', 'give', 'time', 'provide', 'feedback', 'usability', 'product', 'super', 'easy', 'need', 'sign', 'https', 'look', 'forward', 'hearing', 'always', 'email', 'questions', 'gabriel', 'unbox', 'ai', 'mailto', 'gabriel', 'unbox', 'ai', 'community', 'slack', 'coming', 'soon', 'throw', 'thread', 'gabriel']","['p', 'feedback', 'model', 'evalu', 'interpret', 'platform', 'gift', 'card', 'timehi', 'everyon', 'gabriel', 'bayomi', 'one', 'founder', 'unbox', 'http', 'launch', 'alpha', 'version', 'commun', 'edit', 'free', 'love', 'get', 'feedback', 'product', 'beta', 'launch', 'give', 'gift', 'card', 'folk', 'will', 'give', 'time', 'provid', 'feedback', 'usabl', 'product', 'super', 'easi', 'need', 'sign', 'http', 'look', 'forward', 'hear', 'alway', 'email', 'question', 'gabriel', 'unbox', 'ai', 'mailto', 'gabriel', 'unbox', 'ai', 'commun', 'slack', 'come', 'soon', 'throw', 'thread', 'gabriel']"
195,216,216,bo_peng,vzr6ie,[R] RWKV-3: Scaling RNN to 1.5B and Reach Transformer LM Performance (without using attention),"Hi everyone. I posted about my RWKV-2 here a few weeks ago (thanks for the upvote): [https://www.reddit.com/r/MachineLearning/comments/veem7o/r\_rwkv2\_430m\_release\_a\_parallelizable\_rnn\_with/](https://www.reddit.com/r/MachineLearning/comments/veem7o/r_rwkv2_430m_release_a_parallelizable_rnn_with/)

And RWKV-3 is better. You are welcome to join the project: [https://github.com/BlinkDL/RWKV-LM](https://github.com/BlinkDL/RWKV-LM) (I am an independent researcher).

The LM (language modeling) and zero-shot performances of RWKV-3 1.5B, after training for just 93B tokens (the full run of 330B tokens is expected to finish in 60 more days, on 8xA100 tf32):

https://preview.redd.it/5pqa3iu6orb91.png?width=1068&format=png&auto=webp&s=89f40c6e9967d76d83050af0f5fb9f1b992f4323

**RWKV-3 is a 100% pure RNN** (the next hidden state depends only on the current hidden state). Hence, RNN might be all you need.

Download the 68B-tokens checkpoint: [https://huggingface.co/BlinkDL/rwkv-3-pile-1b5](https://huggingface.co/BlinkDL/rwkv-3-pile-1b5)

**Inference speed on single A40 (tf32):**

\*) RWKV-3 1.5B = always 0.015 sec/token - tested using simple pytorch code (no CUDA), GPU utilization 45%, VRAM 7823M

\*) GPT2-XL 1.3B = 0.032 sec/token (for ctxlen 1000) - tested using HF, GPU utilization 45% too (interesting), VRAM 9655M

How it works: RWKV gathers information to a number of channels, which are also decaying with different speeds as you move to the next token. It's simple once you understand it.

Here are some of the TODOs. **Let's work together :)** [https://github.com/BlinkDL/RWKV-LM](https://github.com/BlinkDL/RWKV-LM)

\*) FP16 inference & training, and scaling to 6B -> 20B -> 66B (there will be compute when we have the infrastructure). RWKV is very scalable if we look at the 169M-430M-1.5B results.

\*) HuggingFace integration, and optimized CPU & iOS & Android & WASM & WebGL inference. RWKV is friendly for edge devices. Let's make it possible to run a LLM on your phone.

\*) Test it on bidirectional & MLM tasks, and image & audio & video tokens.",19,117,2022-07-15 18:16:57, r  rwkv   scaling rnn to  b and reach transformer lm performance  without using attention ,hi everyone  i posted about my rwkv  here a few weeks ago  thanks for the upvote    https and rwkv  is better  you are welcome to join the project   https the lm  language modeling  and zero shot performances of rwkv   b  after training for just b tokens  the full run of b tokens is expected to finish in  more days  on xa tf  https   rwkv  is a   pure rnn    the next hidden state depends only on the current hidden state   hence  rnn might be all you need download the b tokens checkpoint   https   inference speed on single a  tf        rwkv   b   always   sec token   tested using simple pytorch code  no cuda   gpu utilization    vram m    gpt xl  b     sec token  for ctxlen     tested using hf  gpu utilization   too  interesting   vram mhow it works  rwkv gathers information to a number of channels  which are also decaying with different speeds as you move to the next token  it s simple once you understand it here are some of the todos    let s work together       https     fp inference   training  and scaling to b    b    b  there will be compute when we have the infrastructure   rwkv is very scalable if we look at the m m  b results     huggingface integration  and optimized cpu   ios   android   wasm   webgl inference  rwkv is friendly for edge devices  let s make it possible to run a llm on your phone     test it on bidirectional   mlm tasks  and image   audio   video tokens ,hi everyone posted rwkv weeks ago thanks upvote https rwkv better welcome join project https lm language modeling zero shot performances rwkv b training b tokens full run b tokens expected finish days xa tf https rwkv pure rnn next hidden state depends current hidden state hence rnn might need download b tokens checkpoint https inference speed single tf rwkv b always sec token tested using simple pytorch code cuda gpu utilization vram gpt xl b sec token ctxlen tested using hf gpu utilization interesting vram mhow works rwkv gathers information number channels also decaying different speeds move next token simple understand todos let work together https fp inference training scaling b b b compute infrastructure rwkv scalable look b results huggingface integration optimized cpu ios android wasm webgl inference rwkv friendly edge devices let make possible run llm phone test bidirectional mlm tasks image audio video tokens,r rwkv scaling rnn b reach transformer lm performance without using attention,r rwkv scaling rnn b reach transformer lm performance without using attentionhi everyone posted rwkv weeks ago thanks upvote https rwkv better welcome join project https lm language modeling zero shot performances rwkv b training b tokens full run b tokens expected finish days xa tf https rwkv pure rnn next hidden state depends current hidden state hence rnn might need download b tokens checkpoint https inference speed single tf rwkv b always sec token tested using simple pytorch code cuda gpu utilization vram gpt xl b sec token ctxlen tested using hf gpu utilization interesting vram mhow works rwkv gathers information number channels also decaying different speeds move next token simple understand todos let work together https fp inference training scaling b b b compute infrastructure rwkv scalable look b results huggingface integration optimized cpu ios android wasm webgl inference rwkv friendly edge devices let make possible run llm phone test bidirectional mlm tasks image audio video tokens,"['r', 'rwkv', 'scaling', 'rnn', 'b', 'reach', 'transformer', 'lm', 'performance', 'without', 'using', 'attentionhi', 'everyone', 'posted', 'rwkv', 'weeks', 'ago', 'thanks', 'upvote', 'https', 'rwkv', 'better', 'welcome', 'join', 'project', 'https', 'lm', 'language', 'modeling', 'zero', 'shot', 'performances', 'rwkv', 'b', 'training', 'b', 'tokens', 'full', 'run', 'b', 'tokens', 'expected', 'finish', 'days', 'xa', 'tf', 'https', 'rwkv', 'pure', 'rnn', 'next', 'hidden', 'state', 'depends', 'current', 'hidden', 'state', 'hence', 'rnn', 'might', 'need', 'download', 'b', 'tokens', 'checkpoint', 'https', 'inference', 'speed', 'single', 'tf', 'rwkv', 'b', 'always', 'sec', 'token', 'tested', 'using', 'simple', 'pytorch', 'code', 'cuda', 'gpu', 'utilization', 'vram', 'gpt', 'xl', 'b', 'sec', 'token', 'ctxlen', 'tested', 'using', 'hf', 'gpu', 'utilization', 'interesting', 'vram', 'mhow', 'works', 'rwkv', 'gathers', 'information', 'number', 'channels', 'also', 'decaying', 'different', 'speeds', 'move', 'next', 'token', 'simple', 'understand', 'todos', 'let', 'work', 'together', 'https', 'fp', 'inference', 'training', 'scaling', 'b', 'b', 'b', 'compute', 'infrastructure', 'rwkv', 'scalable', 'look', 'b', 'results', 'huggingface', 'integration', 'optimized', 'cpu', 'ios', 'android', 'wasm', 'webgl', 'inference', 'rwkv', 'friendly', 'edge', 'devices', 'let', 'make', 'possible', 'run', 'llm', 'phone', 'test', 'bidirectional', 'mlm', 'tasks', 'image', 'audio', 'video', 'tokens']","['r', 'rwkv', 'scale', 'rnn', 'b', 'reach', 'transform', 'lm', 'perform', 'without', 'use', 'attentionhi', 'everyon', 'post', 'rwkv', 'week', 'ago', 'thank', 'upvot', 'http', 'rwkv', 'better', 'welcom', 'join', 'project', 'http', 'lm', 'languag', 'model', 'zero', 'shot', 'perform', 'rwkv', 'b', 'train', 'b', 'token', 'full', 'run', 'b', 'token', 'expect', 'finish', 'day', 'xa', 'tf', 'http', 'rwkv', 'pure', 'rnn', 'next', 'hidden', 'state', 'depend', 'current', 'hidden', 'state', 'henc', 'rnn', 'might', 'need', 'download', 'b', 'token', 'checkpoint', 'http', 'infer', 'speed', 'singl', 'tf', 'rwkv', 'b', 'alway', 'sec', 'token', 'test', 'use', 'simpl', 'pytorch', 'code', 'cuda', 'gpu', 'util', 'vram', 'gpt', 'xl', 'b', 'sec', 'token', 'ctxlen', 'test', 'use', 'hf', 'gpu', 'util', 'interest', 'vram', 'mhow', 'work', 'rwkv', 'gather', 'inform', 'number', 'channel', 'also', 'decay', 'differ', 'speed', 'move', 'next', 'token', 'simpl', 'understand', 'todo', 'let', 'work', 'togeth', 'http', 'fp', 'infer', 'train', 'scale', 'b', 'b', 'b', 'comput', 'infrastructur', 'rwkv', 'scalabl', 'look', 'b', 'result', 'huggingfac', 'integr', 'optim', 'cpu', 'io', 'android', 'wasm', 'webgl', 'infer', 'rwkv', 'friendli', 'edg', 'devic', 'let', 'make', 'possibl', 'run', 'llm', 'phone', 'test', 'bidirect', 'mlm', 'task', 'imag', 'audio', 'video', 'token']"
196,217,217,aadityaura,vzoaoj,"[P] A python module to fetch relevant papers based on keywords from different sources, including Arxiv, ACL, ACM, PMLR, CVF etc. and fetch all citations of a research paper from google scholar","Hi folks,

I was working on a personal experimental project, which I thought of making it open source now. It saves much time for literature research.

If you are an industrial researcher or in academia, you probably spend much time reading research articles and news related to your topic.

If you try to search papers related to your topic, finding relevant documents on the internet takes time. You probably know the pain of extracting citations of articles from different websites.

Previously I used to fetch papers from google or semantic scholar, but semantic scholar does not show correct paper citations.

I am excited to announce [RESP: Research Papers Search](https://github.com/monk1337/resp) 

**Features:**

* Fetch all citations of a single paper from Google Scholar in CSV format
* Fetch all related papers of a single paper from Google Scholar in CSV format
* Fetch all connected papers from connectedpapers.com (it does not use a citation tree, it uses [similarity](https://www.connectedpapers.com/about) to build graphs) in CSV format 
* Fetch relevant papers based on keywords from different sources, including Arxiv, ACL, ACM, PMLR, NeurIPS, cvf etc., in CSV format

GITHUB: [https://github.com/monk1337/resp](https://github.com/monk1337/resp)

Examples: [https://github.com/monk1337/resp/tree/main/examples](https://github.com/monk1337/resp/tree/main/examples)

For quick demo -> [Colab](https://colab.research.google.com/drive/188cWcZrBRVGAF3Dp_5uswmLgbBNKSioB?usp=sharing)  


I hope it will be helpful in your research. Thanks :)",7,174,2022-07-15 16:07:02, p  a python module to fetch relevant papers based on keywords from different sources  including arxiv  acl  acm  pmlr  cvf etc  and fetch all citations of a research paper from google scholar,hi folks i was working on a personal experimental project  which i thought of making it open source now  it saves much time for literature research if you are an industrial researcher or in academia  you probably spend much time reading research articles and news related to your topic if you try to search papers related to your topic  finding relevant documents on the internet takes time  you probably know the pain of extracting citations of articles from different websites previously i used to fetch papers from google or semantic scholar  but semantic scholar does not show correct paper citations i am excited to announce  resp  research papers search  https   features     fetch all citations of a single paper from google scholar in csv format  fetch all related papers of a single paper from google scholar in csv format  fetch all connected papers from connectedpapers com  it does not use a citation tree  it uses  similarity  https   fetch relevant papers based on keywords from different sources  including arxiv  acl  acm  pmlr  neurips  cvf etc   in csv formatgithub   https examples   https for quick demo     colab  https i hope it will be helpful in your research  thanks   ,hi folks working personal experimental project thought making open source saves much time literature research industrial researcher academia probably spend much time reading research articles news related topic try search papers related topic finding relevant documents internet takes time probably know pain extracting citations articles different websites previously used fetch papers google semantic scholar semantic scholar show correct paper citations excited announce resp research papers search https features fetch citations single paper google scholar csv format fetch related papers single paper google scholar csv format fetch connected papers connectedpapers com use citation tree uses similarity https fetch relevant papers based keywords different sources including arxiv acl acm pmlr neurips cvf etc csv formatgithub https examples https quick demo colab https hope helpful research thanks,p python module fetch relevant papers based keywords different sources including arxiv acl acm pmlr cvf etc fetch citations research paper google scholar,p python module fetch relevant papers based keywords different sources including arxiv acl acm pmlr cvf etc fetch citations research paper google scholarhi folks working personal experimental project thought making open source saves much time literature research industrial researcher academia probably spend much time reading research articles news related topic try search papers related topic finding relevant documents internet takes time probably know pain extracting citations articles different websites previously used fetch papers google semantic scholar semantic scholar show correct paper citations excited announce resp research papers search https features fetch citations single paper google scholar csv format fetch related papers single paper google scholar csv format fetch connected papers connectedpapers com use citation tree uses similarity https fetch relevant papers based keywords different sources including arxiv acl acm pmlr neurips cvf etc csv formatgithub https examples https quick demo colab https hope helpful research thanks,"['p', 'python', 'module', 'fetch', 'relevant', 'papers', 'based', 'keywords', 'different', 'sources', 'including', 'arxiv', 'acl', 'acm', 'pmlr', 'cvf', 'etc', 'fetch', 'citations', 'research', 'paper', 'google', 'scholarhi', 'folks', 'working', 'personal', 'experimental', 'project', 'thought', 'making', 'open', 'source', 'saves', 'much', 'time', 'literature', 'research', 'industrial', 'researcher', 'academia', 'probably', 'spend', 'much', 'time', 'reading', 'research', 'articles', 'news', 'related', 'topic', 'try', 'search', 'papers', 'related', 'topic', 'finding', 'relevant', 'documents', 'internet', 'takes', 'time', 'probably', 'know', 'pain', 'extracting', 'citations', 'articles', 'different', 'websites', 'previously', 'used', 'fetch', 'papers', 'google', 'semantic', 'scholar', 'semantic', 'scholar', 'show', 'correct', 'paper', 'citations', 'excited', 'announce', 'resp', 'research', 'papers', 'search', 'https', 'features', 'fetch', 'citations', 'single', 'paper', 'google', 'scholar', 'csv', 'format', 'fetch', 'related', 'papers', 'single', 'paper', 'google', 'scholar', 'csv', 'format', 'fetch', 'connected', 'papers', 'connectedpapers', 'com', 'use', 'citation', 'tree', 'uses', 'similarity', 'https', 'fetch', 'relevant', 'papers', 'based', 'keywords', 'different', 'sources', 'including', 'arxiv', 'acl', 'acm', 'pmlr', 'neurips', 'cvf', 'etc', 'csv', 'formatgithub', 'https', 'examples', 'https', 'quick', 'demo', 'colab', 'https', 'hope', 'helpful', 'research', 'thanks']","['p', 'python', 'modul', 'fetch', 'relev', 'paper', 'base', 'keyword', 'differ', 'sourc', 'includ', 'arxiv', 'acl', 'acm', 'pmlr', 'cvf', 'etc', 'fetch', 'citat', 'research', 'paper', 'googl', 'scholarhi', 'folk', 'work', 'person', 'experiment', 'project', 'thought', 'make', 'open', 'sourc', 'save', 'much', 'time', 'literatur', 'research', 'industri', 'research', 'academia', 'probabl', 'spend', 'much', 'time', 'read', 'research', 'articl', 'news', 'relat', 'topic', 'tri', 'search', 'paper', 'relat', 'topic', 'find', 'relev', 'document', 'internet', 'take', 'time', 'probabl', 'know', 'pain', 'extract', 'citat', 'articl', 'differ', 'websit', 'previous', 'use', 'fetch', 'paper', 'googl', 'semant', 'scholar', 'semant', 'scholar', 'show', 'correct', 'paper', 'citat', 'excit', 'announc', 'resp', 'research', 'paper', 'search', 'http', 'featur', 'fetch', 'citat', 'singl', 'paper', 'googl', 'scholar', 'csv', 'format', 'fetch', 'relat', 'paper', 'singl', 'paper', 'googl', 'scholar', 'csv', 'format', 'fetch', 'connect', 'paper', 'connectedpap', 'com', 'use', 'citat', 'tree', 'use', 'similar', 'http', 'fetch', 'relev', 'paper', 'base', 'keyword', 'differ', 'sourc', 'includ', 'arxiv', 'acl', 'acm', 'pmlr', 'neurip', 'cvf', 'etc', 'csv', 'formatgithub', 'http', 'exampl', 'http', 'quick', 'demo', 'colab', 'http', 'hope', 'help', 'research', 'thank']"
197,218,218,Constuck,w097ea,[D] What's the most interesting NeRF paper this year?,"I'm putting together a literature review of Neural Radiance Field papers for coworkers. The backbone of the review will definitely follow the later works of the original authors of NeRF at Google Research but I don't want to overlook papers outside of Google that have been advancing NeRFs. What do you recommend I read?

Thanks so much for any and all recommendations!",4,8,2022-07-16 08:37:48, d  what s the most interesting nerf paper this year ,i m putting together a literature review of neural radiance field papers for coworkers  the backbone of the review will definitely follow the later works of the original authors of nerf at google research but i don t want to overlook papers outside of google that have been advancing nerfs  what do you recommend i read thanks so much for any and all recommendations ,putting together literature review neural radiance field papers coworkers backbone review definitely follow later works original authors nerf google research want overlook papers outside google advancing nerfs recommend read thanks much recommendations,interesting nerf paper year,interesting nerf paper yearputting together literature review neural radiance field papers coworkers backbone review definitely follow later works original authors nerf google research want overlook papers outside google advancing nerfs recommend read thanks much recommendations,"['interesting', 'nerf', 'paper', 'yearputting', 'together', 'literature', 'review', 'neural', 'radiance', 'field', 'papers', 'coworkers', 'backbone', 'review', 'definitely', 'follow', 'later', 'works', 'original', 'authors', 'nerf', 'google', 'research', 'want', 'overlook', 'papers', 'outside', 'google', 'advancing', 'nerfs', 'recommend', 'read', 'thanks', 'much', 'recommendations']","['interest', 'nerf', 'paper', 'yearput', 'togeth', 'literatur', 'review', 'neural', 'radianc', 'field', 'paper', 'cowork', 'backbon', 'review', 'definit', 'follow', 'later', 'work', 'origin', 'author', 'nerf', 'googl', 'research', 'want', 'overlook', 'paper', 'outsid', 'googl', 'advanc', 'nerf', 'recommend', 'read', 'thank', 'much', 'recommend']"
198,219,219,jeoyous,w09za4,"[D] CLIP model with CUHK's large scale fashion database fine-tuning on Recall metric , model shows 217.0% increase, probability of this happening and examples of services to run remote GPU","CUHK released a[DeepFashion-MultiModal dataset](https://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html) with rich multi-modal annotations, including manually annotated human parsing labels, manually annotated human keypoints, manually annotated fine-grained labels and textual descriptions in June 2022. Since then, researchers have been looking to work with the dataset, fine-tune it with CLIP model and different metrics.

While finetuning I understand is an imp. process and a difficult one, [they](https://github.com/jina-ai/finetuner#benchmark) claim to have gained 217% Delta increase on Recall metric.  When I have been trying to run it, my laptop has not been so capable to run this, so I am looking for alternative for remote GPU.

But, is this growth of 217% from pertained to fine-tuned model even possible? A bit hard to believe. If so, is Colab a good option to run remote GPU while being able to make use of the functionality?",2,4,2022-07-16 09:26:07, d  clip model with cuhk s large scale fashion database fine tuning on recall metric   model shows    increase  probability of this happening and examples of services to run remote gpu,cuhk released a deepfashion multimodal dataset  https while finetuning i understand is an imp  process and a difficult one   they  https but  is this growth of   from pertained to fine tuned model even possible  a bit hard to believe  if so  is colab a good option to run remote gpu while being able to make use of the functionality ,cuhk released deepfashion multimodal dataset https finetuning understand imp process difficult one https growth pertained fine tuned model even possible bit hard believe colab good option run remote gpu able make use functionality,clip model cuhk large scale fashion database fine tuning recall metric model shows increase probability happening examples services run remote gpu,clip model cuhk large scale fashion database fine tuning recall metric model shows increase probability happening examples services run remote gpucuhk released deepfashion multimodal dataset https finetuning understand imp process difficult one https growth pertained fine tuned model even possible bit hard believe colab good option run remote gpu able make use functionality,"['clip', 'model', 'cuhk', 'large', 'scale', 'fashion', 'database', 'fine', 'tuning', 'recall', 'metric', 'model', 'shows', 'increase', 'probability', 'happening', 'examples', 'services', 'run', 'remote', 'gpucuhk', 'released', 'deepfashion', 'multimodal', 'dataset', 'https', 'finetuning', 'understand', 'imp', 'process', 'difficult', 'one', 'https', 'growth', 'pertained', 'fine', 'tuned', 'model', 'even', 'possible', 'bit', 'hard', 'believe', 'colab', 'good', 'option', 'run', 'remote', 'gpu', 'able', 'make', 'use', 'functionality']","['clip', 'model', 'cuhk', 'larg', 'scale', 'fashion', 'databas', 'fine', 'tune', 'recal', 'metric', 'model', 'show', 'increas', 'probabl', 'happen', 'exampl', 'servic', 'run', 'remot', 'gpucuhk', 'releas', 'deepfashion', 'multimod', 'dataset', 'http', 'finetun', 'understand', 'imp', 'process', 'difficult', 'one', 'http', 'growth', 'pertain', 'fine', 'tune', 'model', 'even', 'possibl', 'bit', 'hard', 'believ', 'colab', 'good', 'option', 'run', 'remot', 'gpu', 'abl', 'make', 'use', 'function']"
199,220,220,tyypewriter,w09y1o,[P] Try my GPT-2 backed keyword-conditioned story writing AI tyypewriter.com and tell me what you think,"As a hobby, I made an AI that can write stories based on what you want the story to be about.

You can try it here:

[https://www.tyypewriter.com/](https://www.tyypewriter.com/)

You write the stories sentence by sentence, with the AI always offering 4 candidate sentences (or phrases) that you can choose from. This is aimed at helping mitigate the problems of some text generation AI, which go off the rails when it takes a randomly decided word that conditions all the text generated after it.

The AI doesn't always make sense because it is based on only a small GPT-2 model, and it is running on some feeble backend servers so if they crash, please be patient and try again in a few minutes.

I'd love to hear your thoughts on the project.

And if you write any stories that you want to share, then you can share them through the ""Share"" button at the end of the story creation to r/tyypewriter.

Thanks and have fun!",2,4,2022-07-16 09:23:58, p  try my gpt  backed keyword conditioned story writing ai tyypewriter com and tell me what you think,as a hobby  i made an ai that can write stories based on what you want the story to be about you can try it here  https you write the stories sentence by sentence  with the ai always offering  candidate sentences  or phrases  that you can choose from  this is aimed at helping mitigate the problems of some text generation ai  which go off the rails when it takes a randomly decided word that conditions all the text generated after it the ai doesn t always make sense because it is based on only a small gpt  model  and it is running on some feeble backend servers so if they crash  please be patient and try again in a few minutes i d love to hear your thoughts on the project and if you write any stories that you want to share  then you can share them through the share button at the end of the story creation to r tyypewriter thanks and have fun ,hobby made ai write stories based want story try https write stories sentence sentence ai always offering candidate sentences phrases choose aimed helping mitigate problems text generation ai go rails takes randomly decided word conditions text generated ai always make sense based small gpt model running feeble backend servers crash please patient try minutes love hear thoughts project write stories want share share share button end story creation r tyypewriter thanks fun,p try gpt backed keyword conditioned story writing ai tyypewriter com tell think,p try gpt backed keyword conditioned story writing ai tyypewriter com tell thinkhobby made ai write stories based want story try https write stories sentence sentence ai always offering candidate sentences phrases choose aimed helping mitigate problems text generation ai go rails takes randomly decided word conditions text generated ai always make sense based small gpt model running feeble backend servers crash please patient try minutes love hear thoughts project write stories want share share share button end story creation r tyypewriter thanks fun,"['p', 'try', 'gpt', 'backed', 'keyword', 'conditioned', 'story', 'writing', 'ai', 'tyypewriter', 'com', 'tell', 'thinkhobby', 'made', 'ai', 'write', 'stories', 'based', 'want', 'story', 'try', 'https', 'write', 'stories', 'sentence', 'sentence', 'ai', 'always', 'offering', 'candidate', 'sentences', 'phrases', 'choose', 'aimed', 'helping', 'mitigate', 'problems', 'text', 'generation', 'ai', 'go', 'rails', 'takes', 'randomly', 'decided', 'word', 'conditions', 'text', 'generated', 'ai', 'always', 'make', 'sense', 'based', 'small', 'gpt', 'model', 'running', 'feeble', 'backend', 'servers', 'crash', 'please', 'patient', 'try', 'minutes', 'love', 'hear', 'thoughts', 'project', 'write', 'stories', 'want', 'share', 'share', 'share', 'button', 'end', 'story', 'creation', 'r', 'tyypewriter', 'thanks', 'fun']","['p', 'tri', 'gpt', 'back', 'keyword', 'condit', 'stori', 'write', 'ai', 'tyypewrit', 'com', 'tell', 'thinkhobbi', 'made', 'ai', 'write', 'stori', 'base', 'want', 'stori', 'tri', 'http', 'write', 'stori', 'sentenc', 'sentenc', 'ai', 'alway', 'offer', 'candid', 'sentenc', 'phrase', 'choos', 'aim', 'help', 'mitig', 'problem', 'text', 'gener', 'ai', 'go', 'rail', 'take', 'randomli', 'decid', 'word', 'condit', 'text', 'gener', 'ai', 'alway', 'make', 'sens', 'base', 'small', 'gpt', 'model', 'run', 'feebl', 'backend', 'server', 'crash', 'pleas', 'patient', 'tri', 'minut', 'love', 'hear', 'thought', 'project', 'write', 'stori', 'want', 'share', 'share', 'share', 'button', 'end', 'stori', 'creation', 'r', 'tyypewrit', 'thank', 'fun']"
200,221,221,shreyansh26,vzwt5c,[R] Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models by FAIR,"A detailed and insightful study by MetaAI team on the memorization, overfitting and forgetting in LLMs.

The paper talks about how different definitions of ""memorization"" and how scaling affects the amount of training data that the large language models can memorize during the training phase. Studies are also presented on how the forgetting curves look like and how overfitting relates to memorization for these large language models. The Appendix section is a gold mine as well.

Annotated version of the paper - [Github Link](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/LLMs/Memorization%20Without%20Overfitting%20-%20Analyzing%20the%20Training%20Dynamics%20of%20Large%20Language%20Models.pdf)",2,11,2022-07-15 22:19:05, r  memorization without overfitting  analyzing the training dynamics of large language models by fair,a detailed and insightful study by metaai team on the memorization  overfitting and forgetting in llms the paper talks about how different definitions of memorization and how scaling affects the amount of training data that the large language models can memorize during the training phase  studies are also presented on how the forgetting curves look like and how overfitting relates to memorization for these large language models  the appendix section is a gold mine as well annotated version of the paper    github link  https   github com shreyansh annotated ml papers blob main llms memorization without overfitting   analyzing the training dynamics of large language models pdf ,detailed insightful study metaai team memorization overfitting forgetting llms paper talks different definitions memorization scaling affects amount training data large language models memorize training phase studies also presented forgetting curves look like overfitting relates memorization large language models appendix section gold mine well annotated version paper github link https github com shreyansh annotated ml papers blob main llms memorization without overfitting analyzing training dynamics large language models pdf,r memorization without overfitting analyzing training dynamics large language models fair,r memorization without overfitting analyzing training dynamics large language models fairdetailed insightful study metaai team memorization overfitting forgetting llms paper talks different definitions memorization scaling affects amount training data large language models memorize training phase studies also presented forgetting curves look like overfitting relates memorization large language models appendix section gold mine well annotated version paper github link https github com shreyansh annotated ml papers blob main llms memorization without overfitting analyzing training dynamics large language models pdf,"['r', 'memorization', 'without', 'overfitting', 'analyzing', 'training', 'dynamics', 'large', 'language', 'models', 'fairdetailed', 'insightful', 'study', 'metaai', 'team', 'memorization', 'overfitting', 'forgetting', 'llms', 'paper', 'talks', 'different', 'definitions', 'memorization', 'scaling', 'affects', 'amount', 'training', 'data', 'large', 'language', 'models', 'memorize', 'training', 'phase', 'studies', 'also', 'presented', 'forgetting', 'curves', 'look', 'like', 'overfitting', 'relates', 'memorization', 'large', 'language', 'models', 'appendix', 'section', 'gold', 'mine', 'well', 'annotated', 'version', 'paper', 'github', 'link', 'https', 'github', 'com', 'shreyansh', 'annotated', 'ml', 'papers', 'blob', 'main', 'llms', 'memorization', 'without', 'overfitting', 'analyzing', 'training', 'dynamics', 'large', 'language', 'models', 'pdf']","['r', 'memor', 'without', 'overfit', 'analyz', 'train', 'dynam', 'larg', 'languag', 'model', 'fairdetail', 'insight', 'studi', 'metaai', 'team', 'memor', 'overfit', 'forget', 'llm', 'paper', 'talk', 'differ', 'definit', 'memor', 'scale', 'affect', 'amount', 'train', 'data', 'larg', 'languag', 'model', 'memor', 'train', 'phase', 'studi', 'also', 'present', 'forget', 'curv', 'look', 'like', 'overfit', 'relat', 'memor', 'larg', 'languag', 'model', 'appendix', 'section', 'gold', 'mine', 'well', 'annot', 'version', 'paper', 'github', 'link', 'http', 'github', 'com', 'shreyansh', 'annot', 'ml', 'paper', 'blob', 'main', 'llm', 'memor', 'without', 'overfit', 'analyz', 'train', 'dynam', 'larg', 'languag', 'model', 'pdf']"
201,222,222,Economy-Pipe-6184,vzvqjo,[D] At what point does data augmentation stop making a difference for language models?,Is there any work which shows at what point does data augmentation stops making a difference? Say you have GPT-3 type data then you probably don't get gains from data augmentation but for low-data  regime you definitely get gains. Is there a systematic study what gets to the bottom of this?,1,9,2022-07-15 21:32:04, d  at what point does data augmentation stop making a difference for language models ,is there any work which shows at what point does data augmentation stops making a difference  say you have gpt  type data then you probably don t get gains from data augmentation but for low data  regime you definitely get gains  is there a systematic study what gets to the bottom of this ,work shows point data augmentation stops making difference say gpt type data probably get gains data augmentation low data regime definitely get gains systematic study gets bottom,point data augmentation stop making difference language models,point data augmentation stop making difference language modelswork shows point data augmentation stops making difference say gpt type data probably get gains data augmentation low data regime definitely get gains systematic study gets bottom,"['point', 'data', 'augmentation', 'stop', 'making', 'difference', 'language', 'modelswork', 'shows', 'point', 'data', 'augmentation', 'stops', 'making', 'difference', 'say', 'gpt', 'type', 'data', 'probably', 'get', 'gains', 'data', 'augmentation', 'low', 'data', 'regime', 'definitely', 'get', 'gains', 'systematic', 'study', 'gets', 'bottom']","['point', 'data', 'augment', 'stop', 'make', 'differ', 'languag', 'modelswork', 'show', 'point', 'data', 'augment', 'stop', 'make', 'differ', 'say', 'gpt', 'type', 'data', 'probabl', 'get', 'gain', 'data', 'augment', 'low', 'data', 'regim', 'definit', 'get', 'gain', 'systemat', 'studi', 'get', 'bottom']"
202,223,223,iamjaiyam,vzqqjx,[D] What’s the latest in ML music generation?,"I have been peripherally interested in ML music generation models over the years and followed Google’s magenta project.
Recently I’m trying to get up to speed with what’s been happening in this space. Looking at magenta’s homepage, it seems like the last paper they published was Listen to transformers, about 2 years ago.
Does anyone know what’s been going on recently? Why off magenta dead? Has any other company/lab been working on this and open source their models?",4,16,2022-07-15 17:58:45, d  what s the latest in ml music generation ,i have been peripherally interested in ml music generation models over the years and followed google s magenta project recently i m trying to get up to speed with what s been happening in this space  looking at magenta s homepage  it seems like the last paper they published was listen to transformers  about  years ago does anyone know what s been going on recently  why off magenta dead  has any other company lab been working on this and open source their models ,peripherally interested ml music generation models years followed google magenta project recently trying get speed happening space looking magenta homepage seems like last paper published listen transformers years ago anyone know going recently magenta dead company lab working open source models,latest ml music generation,latest ml music generationperipherally interested ml music generation models years followed google magenta project recently trying get speed happening space looking magenta homepage seems like last paper published listen transformers years ago anyone know going recently magenta dead company lab working open source models,"['latest', 'ml', 'music', 'generationperipherally', 'interested', 'ml', 'music', 'generation', 'models', 'years', 'followed', 'google', 'magenta', 'project', 'recently', 'trying', 'get', 'speed', 'happening', 'space', 'looking', 'magenta', 'homepage', 'seems', 'like', 'last', 'paper', 'published', 'listen', 'transformers', 'years', 'ago', 'anyone', 'know', 'going', 'recently', 'magenta', 'dead', 'company', 'lab', 'working', 'open', 'source', 'models']","['latest', 'ml', 'music', 'generationperipher', 'interest', 'ml', 'music', 'gener', 'model', 'year', 'follow', 'googl', 'magenta', 'project', 'recent', 'tri', 'get', 'speed', 'happen', 'space', 'look', 'magenta', 'homepag', 'seem', 'like', 'last', 'paper', 'publish', 'listen', 'transform', 'year', 'ago', 'anyon', 'know', 'go', 'recent', 'magenta', 'dead', 'compani', 'lab', 'work', 'open', 'sourc', 'model']"
203,224,224,Ok_Challenge1987,vzy81q,[D] How do you deal with skewed continuous target variables?,I am trying to build a model that predicts an extremely skewed target variable. My independent variables have a low correlation with my dependent variable which is highly skewed (2% of the data are extremely higher than the rest which causes my model to make high predictions),4,4,2022-07-15 23:22:47, d  how do you deal with skewed continuous target variables ,i am trying to build a model that predicts an extremely skewed target variable  my independent variables have a low correlation with my dependent variable which is highly skewed    of the data are extremely higher than the rest which causes my model to make high predictions ,trying build model predicts extremely skewed target variable independent variables low correlation dependent variable highly skewed data extremely higher rest causes model make high predictions,deal skewed continuous target variables,deal skewed continuous target variablestrying build model predicts extremely skewed target variable independent variables low correlation dependent variable highly skewed data extremely higher rest causes model make high predictions,"['deal', 'skewed', 'continuous', 'target', 'variablestrying', 'build', 'model', 'predicts', 'extremely', 'skewed', 'target', 'variable', 'independent', 'variables', 'low', 'correlation', 'dependent', 'variable', 'highly', 'skewed', 'data', 'extremely', 'higher', 'rest', 'causes', 'model', 'make', 'high', 'predictions']","['deal', 'skew', 'continu', 'target', 'variablestri', 'build', 'model', 'predict', 'extrem', 'skew', 'target', 'variabl', 'independ', 'variabl', 'low', 'correl', 'depend', 'variabl', 'highli', 'skew', 'data', 'extrem', 'higher', 'rest', 'caus', 'model', 'make', 'high', 'predict']"
204,225,225,ploomber-io,vzwdh6,[P] nbsnapshot: Automated Jupyter notebook testing. 📙,"https://preview.redd.it/qgfg81lp4sb91.png?width=1201&format=png&auto=webp&s=ba15963a42a85a7f18a5a173d167774d7f5b141d

I want to share a project I've been working on to facilitate Jupyter notebook testing!

When analyzing data in a Jupyter notebook, I unconsciously memorize ""rules of thumb"" to determine if my results are correct. For example, I might print some summary statistics and become skeptical of some outputs if they deviate too much from what I've seen historically. For more complex analysis, I often create diagnostic plots (e.g., a histogram) and check them whenever new data arrives.

Since I constantly repeat the same process, I figured I'd code a small library to streamline this process. [nbsnapshot](https://github.com/edublancas/nbsnapshot) benchmarks cell's outputs with historical results and raises an error if the output deviates from an expected range (by default, 3 standard deviations from the mean). You can see an example in the image accompanying this post.

To learn more, check out the [blog post.](https://ploomber.io/blog/snapshot-testing/)",8,3,2022-07-15 22:00:14, p  nbsnapshot  automated jupyter notebook testing   ,https i want to share a project i ve been working on to facilitate jupyter notebook testing when analyzing data in a jupyter notebook  i unconsciously memorize rules of thumb to determine if my results are correct  for example  i might print some summary statistics and become skeptical of some outputs if they deviate too much from what i ve seen historically  for more complex analysis  i often create diagnostic plots  e g   a histogram  and check them whenever new data arrives since i constantly repeat the same process  i figured i d code a small library to streamline this process   nbsnapshot  https to learn more  check out the  blog post   https   ploomber io blog snapshot testing  ,https want share project working facilitate jupyter notebook testing analyzing data jupyter notebook unconsciously memorize rules thumb determine results correct example might print summary statistics become skeptical outputs deviate much seen historically complex analysis often create diagnostic plots e g histogram check whenever data arrives since constantly repeat process figured code small library streamline process nbsnapshot https learn check blog post https ploomber io blog snapshot testing,p nbsnapshot automated jupyter notebook testing,p nbsnapshot automated jupyter notebook testinghttps want share project working facilitate jupyter notebook testing analyzing data jupyter notebook unconsciously memorize rules thumb determine results correct example might print summary statistics become skeptical outputs deviate much seen historically complex analysis often create diagnostic plots e g histogram check whenever data arrives since constantly repeat process figured code small library streamline process nbsnapshot https learn check blog post https ploomber io blog snapshot testing,"['p', 'nbsnapshot', 'automated', 'jupyter', 'notebook', 'testinghttps', 'want', 'share', 'project', 'working', 'facilitate', 'jupyter', 'notebook', 'testing', 'analyzing', 'data', 'jupyter', 'notebook', 'unconsciously', 'memorize', 'rules', 'thumb', 'determine', 'results', 'correct', 'example', 'might', 'print', 'summary', 'statistics', 'become', 'skeptical', 'outputs', 'deviate', 'much', 'seen', 'historically', 'complex', 'analysis', 'often', 'create', 'diagnostic', 'plots', 'e', 'g', 'histogram', 'check', 'whenever', 'data', 'arrives', 'since', 'constantly', 'repeat', 'process', 'figured', 'code', 'small', 'library', 'streamline', 'process', 'nbsnapshot', 'https', 'learn', 'check', 'blog', 'post', 'https', 'ploomber', 'io', 'blog', 'snapshot', 'testing']","['p', 'nbsnapshot', 'autom', 'jupyt', 'notebook', 'testinghttp', 'want', 'share', 'project', 'work', 'facilit', 'jupyt', 'notebook', 'test', 'analyz', 'data', 'jupyt', 'notebook', 'unconsci', 'memor', 'rule', 'thumb', 'determin', 'result', 'correct', 'exampl', 'might', 'print', 'summari', 'statist', 'becom', 'skeptic', 'output', 'deviat', 'much', 'seen', 'histor', 'complex', 'analysi', 'often', 'creat', 'diagnost', 'plot', 'e', 'g', 'histogram', 'check', 'whenev', 'data', 'arriv', 'sinc', 'constantli', 'repeat', 'process', 'figur', 'code', 'small', 'librari', 'streamlin', 'process', 'nbsnapshot', 'http', 'learn', 'check', 'blog', 'post', 'http', 'ploomber', 'io', 'blog', 'snapshot', 'test']"
205,226,226,Science_Squid,vzk9vj,[D] 2nd AutoML Fall School,"With  last years interest of this subreddit on our AutoML Fall School, we are happy to announce the [second AutoML Fall School](https://sites.google.com/view/automl-fall-school-2022) which will be in-person in [Freiburg (Germany)](https://sites.google.com/view/automl-fall-school-2022/venue) from October 10th to October 13th.

AutoML can  be a vital tool for many machine learning practitioners and researchers.  While students and professionals are eager to learn more about AutoML,  it is rarely taught and addressed in courses in today’s academic  landscape.

With the the AutoML Fall School we aim to close this glaring gap by providing a  platform for graduate students and researchers to learn about core aspects of AutoML. The event will feature lectures and [invited talks by renowned experts](https://sites.google.com/view/automl-fall-school-2022/schedule/lectures-2022) about topics from fundamental theory to advanced  state-of-the-art methods and current challenges such as neural architecture search and automated reinforcement learning. Additionally, you will  be able to try your hands at implementing leading AutoML solutions in  our [hands-on sessions](https://sites.google.com/view/automl-fall-school-2022/home#h.jk8vtrog8uzp) while being mentored by AutoML experts as well as network and exchange ideas in our social events and much more.

**Registrations are now open!** Find a preliminary schedule, additional information, and the registration details on our [official website](https://sites.google.com/view/automl-fall-school-2022).

In case you need even more motivation. The city of Freiburg im Breisgau, where we will host the venue, [was ranked 3rd](https://www.google.com/url?q=https%3A%2F%2Fwww.lonelyplanet.com%2Fgermany%2Fblack-forest%2Ffreiburg&sa=D&sntz=1&usg=AOvVaw3zr2ArrloYciNho8pHrOpU) in the category Top 10 Cities in ""[Best in Travel 2022](https://www.google.com/url?q=https%3A%2F%2Fwww.lonelyplanet.com%2Fbest-in-travel%2Fcities&sa=D&sntz=1&usg=AOvVaw2i2702ZsrOvnYUo9-DkLtJ)"" by lonely planet.

We are looking forward to seeing you in October in Germany's greenest and sunniest city.",0,20,2022-07-15 12:18:48, d  nd automl fall school,with  last years interest of this subreddit on our automl fall school  we are happy to announce the  second automl fall school  https automl can  be a vital tool for many machine learning practitioners and researchers   while students and professionals are eager to learn more about automl   it is rarely taught and addressed in courses in today s academic  landscape with the the automl fall school we aim to close this glaring gap by providing a  platform for graduate students and researchers to learn about core aspects of automl  the event will feature lectures and  invited talks by renowned experts  https   registrations are now open    find a preliminary schedule  additional information  and the registration details on our  official website  https in case you need even more motivation  the city of freiburg im breisgau  where we will host the venue   was ranked rd  https we are looking forward to seeing you in october in germany s greenest and sunniest city ,last years interest subreddit automl fall school happy announce second automl fall school https automl vital tool many machine learning practitioners researchers students professionals eager learn automl rarely taught addressed courses today academic landscape automl fall school aim close glaring gap providing platform graduate students researchers learn core aspects automl event feature lectures invited talks renowned experts https registrations open find preliminary schedule additional information registration details official website https case need even motivation city freiburg im breisgau host venue ranked rd https looking forward seeing october germany greenest sunniest city,nd automl fall school,nd automl fall schoollast years interest subreddit automl fall school happy announce second automl fall school https automl vital tool many machine learning practitioners researchers students professionals eager learn automl rarely taught addressed courses today academic landscape automl fall school aim close glaring gap providing platform graduate students researchers learn core aspects automl event feature lectures invited talks renowned experts https registrations open find preliminary schedule additional information registration details official website https case need even motivation city freiburg im breisgau host venue ranked rd https looking forward seeing october germany greenest sunniest city,"['nd', 'automl', 'fall', 'schoollast', 'years', 'interest', 'subreddit', 'automl', 'fall', 'school', 'happy', 'announce', 'second', 'automl', 'fall', 'school', 'https', 'automl', 'vital', 'tool', 'many', 'machine', 'learning', 'practitioners', 'researchers', 'students', 'professionals', 'eager', 'learn', 'automl', 'rarely', 'taught', 'addressed', 'courses', 'today', 'academic', 'landscape', 'automl', 'fall', 'school', 'aim', 'close', 'glaring', 'gap', 'providing', 'platform', 'graduate', 'students', 'researchers', 'learn', 'core', 'aspects', 'automl', 'event', 'feature', 'lectures', 'invited', 'talks', 'renowned', 'experts', 'https', 'registrations', 'open', 'find', 'preliminary', 'schedule', 'additional', 'information', 'registration', 'details', 'official', 'website', 'https', 'case', 'need', 'even', 'motivation', 'city', 'freiburg', 'im', 'breisgau', 'host', 'venue', 'ranked', 'rd', 'https', 'looking', 'forward', 'seeing', 'october', 'germany', 'greenest', 'sunniest', 'city']","['nd', 'automl', 'fall', 'schoollast', 'year', 'interest', 'subreddit', 'automl', 'fall', 'school', 'happi', 'announc', 'second', 'automl', 'fall', 'school', 'http', 'automl', 'vital', 'tool', 'mani', 'machin', 'learn', 'practition', 'research', 'student', 'profession', 'eager', 'learn', 'automl', 'rare', 'taught', 'address', 'cours', 'today', 'academ', 'landscap', 'automl', 'fall', 'school', 'aim', 'close', 'glare', 'gap', 'provid', 'platform', 'graduat', 'student', 'research', 'learn', 'core', 'aspect', 'automl', 'event', 'featur', 'lectur', 'invit', 'talk', 'renown', 'expert', 'http', 'registr', 'open', 'find', 'preliminari', 'schedul', 'addit', 'inform', 'registr', 'detail', 'offici', 'websit', 'http', 'case', 'need', 'even', 'motiv', 'citi', 'freiburg', 'im', 'breisgau', 'host', 'venu', 'rank', 'rd', 'http', 'look', 'forward', 'see', 'octob', 'germani', 'greenest', 'sunniest', 'citi']"
206,227,227,vanilla-acc,vze1hj,[D] What are people using to organize large groups of people for data labelling?,I'm thinking of hiring a bunch of people to label a ton of data. What is the best software to do this?  I specifically want to use my own labelers.,24,59,2022-07-15 06:06:00, d  what are people using to organize large groups of people for data labelling ,i m thinking of hiring a bunch of people to label a ton of data  what is the best software to do this   i specifically want to use my own labelers ,thinking hiring bunch people label ton data best software specifically want use labelers,people using organize large groups people data labelling,people using organize large groups people data labellingthinking hiring bunch people label ton data best software specifically want use labelers,"['people', 'using', 'organize', 'large', 'groups', 'people', 'data', 'labellingthinking', 'hiring', 'bunch', 'people', 'label', 'ton', 'data', 'best', 'software', 'specifically', 'want', 'use', 'labelers']","['peopl', 'use', 'organ', 'larg', 'group', 'peopl', 'data', 'labellingthink', 'hire', 'bunch', 'peopl', 'label', 'ton', 'data', 'best', 'softwar', 'specif', 'want', 'use', 'label']"
207,228,228,ProfitCute5415,vzpx0i,[D] [Discussion] Gaussian Distribuction - PhD Level Very tricky equations,"The following dissertation comes from page 83 of Bishop's Book, which is reachable through this link: [http://users.isr.ist.utl.pt/\~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf?fbclid=IwAR3ZLtsUFTetN7wgLmxoRt5R32tF-OHuQhlnqt9lPy\_ldKuLChv4BCZm-2I](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf?fbclid=IwAR3ZLtsUFTetN7wgLmxoRt5R32tF-OHuQhlnqt9lPy_ldKuLChv4BCZm-2I)

I've found the equation in (2.61) very tricky and no one of my PhD colleagues was able to find out how the two equalities come up.

Is there someone able to clarify this mathematically?

Thank you in advance.

&#x200B;

https://preview.redd.it/tnahgpyvwxb91.png?width=748&format=png&auto=webp&s=904526cd5cba183c24e4a34236b2a3b945046108",2,6,2022-07-15 17:21:50, d   discussion  gaussian distribuction   phd level very tricky equations,the following dissertation comes from page  of bishop s book  which is reachable through this link   http i ve found the equation in     very tricky and no one of my phd colleagues was able to find out how the two equalities come up is there someone able to clarify this mathematically thank you in advance   xb https   preview redd it tnahgpyvwxb png width  format png auto webp s cdcbaceabab,following dissertation comes page bishop book reachable link http found equation tricky one phd colleagues able find two equalities come someone able clarify mathematically thank advance xb https preview redd tnahgpyvwxb png width format png auto webp cdcbaceabab,discussion gaussian distribuction phd level tricky equations,discussion gaussian distribuction phd level tricky equationsfollowing dissertation comes page bishop book reachable link http found equation tricky one phd colleagues able find two equalities come someone able clarify mathematically thank advance xb https preview redd tnahgpyvwxb png width format png auto webp cdcbaceabab,"['discussion', 'gaussian', 'distribuction', 'phd', 'level', 'tricky', 'equationsfollowing', 'dissertation', 'comes', 'page', 'bishop', 'book', 'reachable', 'link', 'http', 'found', 'equation', 'tricky', 'one', 'phd', 'colleagues', 'able', 'find', 'two', 'equalities', 'come', 'someone', 'able', 'clarify', 'mathematically', 'thank', 'advance', 'xb', 'https', 'preview', 'redd', 'tnahgpyvwxb', 'png', 'width', 'format', 'png', 'auto', 'webp', 'cdcbaceabab']","['discuss', 'gaussian', 'distribuct', 'phd', 'level', 'tricki', 'equationsfollow', 'dissert', 'come', 'page', 'bishop', 'book', 'reachabl', 'link', 'http', 'found', 'equat', 'tricki', 'one', 'phd', 'colleagu', 'abl', 'find', 'two', 'equal', 'come', 'someon', 'abl', 'clarifi', 'mathemat', 'thank', 'advanc', 'xb', 'http', 'preview', 'redd', 'tnahgpyvwxb', 'png', 'width', 'format', 'png', 'auto', 'webp', 'cdcbaceabab']"
208,229,229,ElectronicCress3132,vziqnu,[D] Resources on writing reproducible code?,"What are some resources on writing reproducible (excluding ofc floating point addition randomness, etc) ML code?

So far, I'm following pretty standard software engineering principles that I learned in class: documentation comments, modularization, function deduplication, READMEs. I'm planning to write unit tests for some of my preprocessing steps as well.

But there is a whole class of other factors that affect the code: the GPU I'm using, system parameters, etc. Short of just listing the computer specs, is there any easy way to perhaps bundle things like drivers into a git repo?",11,13,2022-07-15 10:34:38, d  resources on writing reproducible code ,what are some resources on writing reproducible  excluding ofc floating point addition randomness  etc  ml code so far  i m following pretty standard software engineering principles that i learned in class  documentation comments  modularization  function deduplication  readmes  i m planning to write unit tests for some of my preprocessing steps as well but there is a whole class of other factors that affect the code  the gpu i m using  system parameters  etc  short of just listing the computer specs  is there any easy way to perhaps bundle things like drivers into a git repo ,resources writing reproducible excluding ofc floating point addition randomness etc ml code far following pretty standard software engineering principles learned class documentation comments modularization function deduplication readmes planning write unit tests preprocessing steps well whole class factors affect code gpu using system parameters etc short listing computer specs easy way perhaps bundle things like drivers git repo,resources writing reproducible code,resources writing reproducible coderesources writing reproducible excluding ofc floating point addition randomness etc ml code far following pretty standard software engineering principles learned class documentation comments modularization function deduplication readmes planning write unit tests preprocessing steps well whole class factors affect code gpu using system parameters etc short listing computer specs easy way perhaps bundle things like drivers git repo,"['resources', 'writing', 'reproducible', 'coderesources', 'writing', 'reproducible', 'excluding', 'ofc', 'floating', 'point', 'addition', 'randomness', 'etc', 'ml', 'code', 'far', 'following', 'pretty', 'standard', 'software', 'engineering', 'principles', 'learned', 'class', 'documentation', 'comments', 'modularization', 'function', 'deduplication', 'readmes', 'planning', 'write', 'unit', 'tests', 'preprocessing', 'steps', 'well', 'whole', 'class', 'factors', 'affect', 'code', 'gpu', 'using', 'system', 'parameters', 'etc', 'short', 'listing', 'computer', 'specs', 'easy', 'way', 'perhaps', 'bundle', 'things', 'like', 'drivers', 'git', 'repo']","['resourc', 'write', 'reproduc', 'coderesourc', 'write', 'reproduc', 'exclud', 'ofc', 'float', 'point', 'addit', 'random', 'etc', 'ml', 'code', 'far', 'follow', 'pretti', 'standard', 'softwar', 'engin', 'principl', 'learn', 'class', 'document', 'comment', 'modular', 'function', 'dedupl', 'readm', 'plan', 'write', 'unit', 'test', 'preprocess', 'step', 'well', 'whole', 'class', 'factor', 'affect', 'code', 'gpu', 'use', 'system', 'paramet', 'etc', 'short', 'list', 'comput', 'spec', 'easi', 'way', 'perhap', 'bundl', 'thing', 'like', 'driver', 'git', 'repo']"
209,230,230,TheSurvivingHalf,vywfx3,[D] Are there any rejected papers that ended up having significant impact in the long run?,"There seems to be a general consensus that getting a paper accepted can be difficult due to various problems with our current peer-review system. That makes me wonder, are there any notable papers that had a difficult time getting accepted but ended up significantly impacting the field or ended up laying the foundation for more high impact publications?",112,305,2022-07-14 16:53:39, d  are there any rejected papers that ended up having significant impact in the long run ,there seems to be a general consensus that getting a paper accepted can be difficult due to various problems with our current peer review system  that makes me wonder  are there any notable papers that had a difficult time getting accepted but ended up significantly impacting the field or ended up laying the foundation for more high impact publications ,seems general consensus getting paper accepted difficult due various problems current peer review system makes wonder notable papers difficult time getting accepted ended significantly impacting field ended laying foundation high impact publications,rejected papers ended significant impact long run,rejected papers ended significant impact long runseems general consensus getting paper accepted difficult due various problems current peer review system makes wonder notable papers difficult time getting accepted ended significantly impacting field ended laying foundation high impact publications,"['rejected', 'papers', 'ended', 'significant', 'impact', 'long', 'runseems', 'general', 'consensus', 'getting', 'paper', 'accepted', 'difficult', 'due', 'various', 'problems', 'current', 'peer', 'review', 'system', 'makes', 'wonder', 'notable', 'papers', 'difficult', 'time', 'getting', 'accepted', 'ended', 'significantly', 'impacting', 'field', 'ended', 'laying', 'foundation', 'high', 'impact', 'publications']","['reject', 'paper', 'end', 'signific', 'impact', 'long', 'runseem', 'gener', 'consensu', 'get', 'paper', 'accept', 'difficult', 'due', 'variou', 'problem', 'current', 'peer', 'review', 'system', 'make', 'wonder', 'notabl', 'paper', 'difficult', 'time', 'get', 'accept', 'end', 'significantli', 'impact', 'field', 'end', 'lay', 'foundat', 'high', 'impact', 'public']"
210,231,231,feconroses,vz0umt,[P] The technology behind BLOOM training,"Last Tuesday, BigScience released [BLOOM](https://huggingface.co/bigscience/bloom), the world's largest open multilingual language model. Stas Bekman from the BigScience & Hugging Face team just [published a blog post](https://huggingface.co/blog/bloom-megatron-deepspeed) about the technology and engineering behind training the 176 billion parameter model, both in terms of hardware (384 80GB A100 GPUs) and software (Megatron-DeepSpeed).",4,56,2022-07-14 20:04:26, p  the technology behind bloom training,last tuesday  bigscience released  bloom  https   huggingface co bigscience bloom   the world s largest open multilingual language model  stas bekman from the bigscience   hugging face team just  published a blog post  https   huggingface co blog bloom megatron deepspeed  about the technology and engineering behind training the  billion parameter model  both in terms of hardware   gb a gpus  and software  megatron deepspeed  ,last tuesday bigscience released bloom https huggingface co bigscience bloom world largest open multilingual language model stas bekman bigscience hugging face team published blog post https huggingface co blog bloom megatron deepspeed technology engineering behind training billion parameter model terms hardware gb gpus software megatron deepspeed,p technology behind bloom training,p technology behind bloom traininglast tuesday bigscience released bloom https huggingface co bigscience bloom world largest open multilingual language model stas bekman bigscience hugging face team published blog post https huggingface co blog bloom megatron deepspeed technology engineering behind training billion parameter model terms hardware gb gpus software megatron deepspeed,"['p', 'technology', 'behind', 'bloom', 'traininglast', 'tuesday', 'bigscience', 'released', 'bloom', 'https', 'huggingface', 'co', 'bigscience', 'bloom', 'world', 'largest', 'open', 'multilingual', 'language', 'model', 'stas', 'bekman', 'bigscience', 'hugging', 'face', 'team', 'published', 'blog', 'post', 'https', 'huggingface', 'co', 'blog', 'bloom', 'megatron', 'deepspeed', 'technology', 'engineering', 'behind', 'training', 'billion', 'parameter', 'model', 'terms', 'hardware', 'gb', 'gpus', 'software', 'megatron', 'deepspeed']","['p', 'technolog', 'behind', 'bloom', 'traininglast', 'tuesday', 'bigscienc', 'releas', 'bloom', 'http', 'huggingfac', 'co', 'bigscienc', 'bloom', 'world', 'largest', 'open', 'multilingu', 'languag', 'model', 'sta', 'bekman', 'bigscienc', 'hug', 'face', 'team', 'publish', 'blog', 'post', 'http', 'huggingfac', 'co', 'blog', 'bloom', 'megatron', 'deepspe', 'technolog', 'engin', 'behind', 'train', 'billion', 'paramet', 'model', 'term', 'hardwar', 'gb', 'gpu', 'softwar', 'megatron', 'deepspe']"
211,233,233,BB4evaTB12,vye69k,30% of Google's Reddit Emotions Dataset is Mislabeled [D],"Last year, Google released their Reddit Emotions dataset: a collection of 58K Reddit comments human-labeled according to 27 emotions. 

I analyzed the dataset... and found that a 30% is mislabeled!

Some of the errors:

1. **\*aggressively tells friend I love them\*** – mislabeled as **ANGER**
2. **Yay, cold McDonald's. My favorite.** – mislabeled as **LOVE**
3. **Hard to be sad these days when I got this guy with me** – mislabeled as **SADNESS**
4. **Nobody has the money to. What a joke** – mislabeled as **JOY**

&#x200B;

I wrote a blog about it here, with more examples and my main two suggestions for how to fix Google's data annotation methodology.

Link: [https://www.surgehq.ai/blog/30-percent-of-googles-reddit-emotions-dataset-is-mislabeled](https://www.surgehq.ai/blog/30-percent-of-googles-reddit-emotions-dataset-is-mislabeled)",136,883,2022-07-14 00:17:36,  of google s reddit emotions dataset is mislabeled  d ,last year  google released their reddit emotions dataset  a collection of k reddit comments human labeled according to  emotions  i analyzed the dataset    and found that a   is mislabeled some of the errors       aggressively tells friend i love them       mislabeled as   anger      yay  cold mcdonald s  my favorite      mislabeled as   love      hard to be sad these days when i got this guy with me     mislabeled as   sadness      nobody has the money to  what a joke     mislabeled as   joy    xb i wrote a blog about it here  with more examples and my main two suggestions for how to fix google s data annotation methodology link   https   www surgehq ai blog  percent of googles reddit emotions dataset is mislabeled  https   www surgehq ai blog  percent of googles reddit emotions dataset is mislabeled ,last year google released reddit emotions dataset collection k reddit comments human labeled according emotions analyzed dataset found mislabeled errors aggressively tells friend love mislabeled anger yay cold mcdonald favorite mislabeled love hard sad days got guy mislabeled sadness nobody money joke mislabeled joy xb wrote blog examples main two suggestions fix google data annotation methodology link https www surgehq ai blog percent googles reddit emotions dataset mislabeled https www surgehq ai blog percent googles reddit emotions dataset mislabeled,google reddit emotions dataset mislabeled,google reddit emotions dataset mislabeledlast year google released reddit emotions dataset collection k reddit comments human labeled according emotions analyzed dataset found mislabeled errors aggressively tells friend love mislabeled anger yay cold mcdonald favorite mislabeled love hard sad days got guy mislabeled sadness nobody money joke mislabeled joy xb wrote blog examples main two suggestions fix google data annotation methodology link https www surgehq ai blog percent googles reddit emotions dataset mislabeled https www surgehq ai blog percent googles reddit emotions dataset mislabeled,"['google', 'reddit', 'emotions', 'dataset', 'mislabeledlast', 'year', 'google', 'released', 'reddit', 'emotions', 'dataset', 'collection', 'k', 'reddit', 'comments', 'human', 'labeled', 'according', 'emotions', 'analyzed', 'dataset', 'found', 'mislabeled', 'errors', 'aggressively', 'tells', 'friend', 'love', 'mislabeled', 'anger', 'yay', 'cold', 'mcdonald', 'favorite', 'mislabeled', 'love', 'hard', 'sad', 'days', 'got', 'guy', 'mislabeled', 'sadness', 'nobody', 'money', 'joke', 'mislabeled', 'joy', 'xb', 'wrote', 'blog', 'examples', 'main', 'two', 'suggestions', 'fix', 'google', 'data', 'annotation', 'methodology', 'link', 'https', 'www', 'surgehq', 'ai', 'blog', 'percent', 'googles', 'reddit', 'emotions', 'dataset', 'mislabeled', 'https', 'www', 'surgehq', 'ai', 'blog', 'percent', 'googles', 'reddit', 'emotions', 'dataset', 'mislabeled']","['googl', 'reddit', 'emot', 'dataset', 'mislabeledlast', 'year', 'googl', 'releas', 'reddit', 'emot', 'dataset', 'collect', 'k', 'reddit', 'comment', 'human', 'label', 'accord', 'emot', 'analyz', 'dataset', 'found', 'mislabel', 'error', 'aggress', 'tell', 'friend', 'love', 'mislabel', 'anger', 'yay', 'cold', 'mcdonald', 'favorit', 'mislabel', 'love', 'hard', 'sad', 'day', 'got', 'guy', 'mislabel', 'sad', 'nobodi', 'money', 'joke', 'mislabel', 'joy', 'xb', 'wrote', 'blog', 'exampl', 'main', 'two', 'suggest', 'fix', 'googl', 'data', 'annot', 'methodolog', 'link', 'http', 'www', 'surgehq', 'ai', 'blog', 'percent', 'googl', 'reddit', 'emot', 'dataset', 'mislabel', 'http', 'www', 'surgehq', 'ai', 'blog', 'percent', 'googl', 'reddit', 'emot', 'dataset', 'mislabel']"
212,234,234,Emergency_Apricot_77,vyyht2,"[D] ""No language left behind"" A 200 language translation model by Meta AI","Just discovered this new model by Meta AI when browsing huggingface 

Paper: [https://ai.facebook.com/research/publications/no-language-left-behind-scaling-human-centered-machine-translation/](https://ai.facebook.com/research/publications/no-language-left-behind-scaling-human-centered-machine-translation/)

Model on HuggingFace: [https://huggingface.co/facebook/nllb-200-3.3B](https://huggingface.co/facebook/nllb-200-3.3B)

Code: [https://github.com/facebookresearch/fairseq/tree/nllb](https://github.com/facebookresearch/fairseq/tree/nllb) 

The largest Mixture-of-Experts model seems really interesting in its capabilities. What do you guys think ?",4,28,2022-07-14 18:24:11, d  no language left behind a  language translation model by meta ai,just discovered this new model by meta ai when browsing huggingface paper   https model on huggingface   https code   https the largest mixture of experts model seems really interesting in its capabilities  what do you guys think  ,discovered model meta ai browsing huggingface paper https model huggingface https code https largest mixture experts model seems really interesting capabilities guys think,language left behind language translation model meta ai,language left behind language translation model meta aidiscovered model meta ai browsing huggingface paper https model huggingface https code https largest mixture experts model seems really interesting capabilities guys think,"['language', 'left', 'behind', 'language', 'translation', 'model', 'meta', 'aidiscovered', 'model', 'meta', 'ai', 'browsing', 'huggingface', 'paper', 'https', 'model', 'huggingface', 'https', 'code', 'https', 'largest', 'mixture', 'experts', 'model', 'seems', 'really', 'interesting', 'capabilities', 'guys', 'think']","['languag', 'left', 'behind', 'languag', 'translat', 'model', 'meta', 'aidiscov', 'model', 'meta', 'ai', 'brows', 'huggingfac', 'paper', 'http', 'model', 'huggingfac', 'http', 'code', 'http', 'largest', 'mixtur', 'expert', 'model', 'seem', 'realli', 'interest', 'capabl', 'guy', 'think']"
213,235,235,Singularian2501,vz0by5,"[R] LM-Nav: Robotic Navigation with Large Pre-Trained Models of Language, Vision, and Action - Google 2022","Paper: [https://arxiv.org/abs/2207.04429](https://arxiv.org/abs/2207.04429)

[https://sites.google.com/view/lmnav](https://sites.google.com/view/lmnav)

Github: [https://github.com/blazejosinski/lm\_nav](https://github.com/blazejosinski/lm_nav)

Summery Video: [https://www.youtube.com/watch?v=wkVbuZQb\_5g](https://www.youtube.com/watch?v=wkVbuZQb_5g)

Abstract: 

>Goal-conditioned policies for robotic navigation can be trained on large, unannotated datasets, providing for good generalization to real-world settings. However, particularly in vision-based settings where specifying goals requires an image, this makes for an unnatural interface. Language provides a more convenient modality for communication with robots, but contemporary methods typically require expensive supervision, in the form of trajectories annotated with language descriptions. We present a system, LM-Nav, for robotic navigation that enjoys the benefits of training on unannotated large datasets of trajectories, while still providing a high-level interface to the user. Instead of utilizing a labeled instruction following dataset, we show that such a system can be constructed entirely out of pre-trained models for navigation (ViNG), image-language association (CLIP), and language modeling (GPT-3), without requiring any fine-tuning or language-annotated robot data. **We instantiate LM-Nav on a real-world mobile robot and demonstrate long-horizon navigation through complex, outdoor environments from natural language instructions**. For videos of our experiments, code release, and an interactive Colab notebook that runs in your browser, please check out our project page [this https URL](https://sites.google.com/view/lmnav) 

https://preview.redd.it/zwx7n9jgakb91.jpg?width=1084&format=pjpg&auto=webp&s=7ee54cadf81306c66cbb9cd2461addef52d3c90a

https://preview.redd.it/6axh7ajgakb91.jpg?width=1116&format=pjpg&auto=webp&s=de5d2e7376a1d64b58a417e9cd63d808a2a6851f

https://preview.redd.it/ysfuybjgakb91.jpg?width=554&format=pjpg&auto=webp&s=bed9d074cabf33f9b64e4dbf4027f7904bb8da61",0,19,2022-07-14 19:42:19, r  lm nav  robotic navigation with large pre trained models of language  vision  and action   google ,paper   https  https github   https summery video   https abstract   goal conditioned policies for robotic navigation can be trained on large  unannotated datasets  providing for good generalization to real world settings  however  particularly in vision based settings where specifying goals requires an image  this makes for an unnatural interface  language provides a more convenient modality for communication with robots  but contemporary methods typically require expensive supervision  in the form of trajectories annotated with language descriptions  we present a system  lm nav  for robotic navigation that enjoys the benefits of training on unannotated large datasets of trajectories  while still providing a high level interface to the user  instead of utilizing a labeled instruction following dataset  we show that such a system can be constructed entirely out of pre trained models for navigation  ving   image language association  clip   and language modeling  gpt    without requiring any fine tuning or language annotated robot data    we instantiate lm nav on a real world mobile robot and demonstrate long horizon navigation through complex  outdoor environments from natural language instructions    for videos of our experiments  code release  and an interactive colab notebook that runs in your browser  please check out our project page  this https url  https https https https   preview redd it ysfuybjgakb jpg width  format pjpg auto webp s beddcabffbedbffbbda,paper https https github https summery video https abstract goal conditioned policies robotic navigation trained large unannotated datasets providing good generalization real world settings however particularly vision based settings specifying goals requires image makes unnatural interface language provides convenient modality communication robots contemporary methods typically require expensive supervision form trajectories annotated language descriptions present system lm nav robotic navigation enjoys benefits training unannotated large datasets trajectories still providing high level interface user instead utilizing labeled instruction following dataset show system constructed entirely pre trained models navigation ving image language association clip language modeling gpt without requiring fine tuning language annotated robot data instantiate lm nav real world mobile robot demonstrate long horizon navigation complex outdoor environments natural language instructions videos experiments code release interactive colab notebook runs browser please check project page https url https https https https preview redd ysfuybjgakb jpg width format pjpg auto webp beddcabffbedbffbbda,r lm nav robotic navigation large pre trained models language vision action google,r lm nav robotic navigation large pre trained models language vision action googlepaper https https github https summery video https abstract goal conditioned policies robotic navigation trained large unannotated datasets providing good generalization real world settings however particularly vision based settings specifying goals requires image makes unnatural interface language provides convenient modality communication robots contemporary methods typically require expensive supervision form trajectories annotated language descriptions present system lm nav robotic navigation enjoys benefits training unannotated large datasets trajectories still providing high level interface user instead utilizing labeled instruction following dataset show system constructed entirely pre trained models navigation ving image language association clip language modeling gpt without requiring fine tuning language annotated robot data instantiate lm nav real world mobile robot demonstrate long horizon navigation complex outdoor environments natural language instructions videos experiments code release interactive colab notebook runs browser please check project page https url https https https https preview redd ysfuybjgakb jpg width format pjpg auto webp beddcabffbedbffbbda,"['r', 'lm', 'nav', 'robotic', 'navigation', 'large', 'pre', 'trained', 'models', 'language', 'vision', 'action', 'googlepaper', 'https', 'https', 'github', 'https', 'summery', 'video', 'https', 'abstract', 'goal', 'conditioned', 'policies', 'robotic', 'navigation', 'trained', 'large', 'unannotated', 'datasets', 'providing', 'good', 'generalization', 'real', 'world', 'settings', 'however', 'particularly', 'vision', 'based', 'settings', 'specifying', 'goals', 'requires', 'image', 'makes', 'unnatural', 'interface', 'language', 'provides', 'convenient', 'modality', 'communication', 'robots', 'contemporary', 'methods', 'typically', 'require', 'expensive', 'supervision', 'form', 'trajectories', 'annotated', 'language', 'descriptions', 'present', 'system', 'lm', 'nav', 'robotic', 'navigation', 'enjoys', 'benefits', 'training', 'unannotated', 'large', 'datasets', 'trajectories', 'still', 'providing', 'high', 'level', 'interface', 'user', 'instead', 'utilizing', 'labeled', 'instruction', 'following', 'dataset', 'show', 'system', 'constructed', 'entirely', 'pre', 'trained', 'models', 'navigation', 'ving', 'image', 'language', 'association', 'clip', 'language', 'modeling', 'gpt', 'without', 'requiring', 'fine', 'tuning', 'language', 'annotated', 'robot', 'data', 'instantiate', 'lm', 'nav', 'real', 'world', 'mobile', 'robot', 'demonstrate', 'long', 'horizon', 'navigation', 'complex', 'outdoor', 'environments', 'natural', 'language', 'instructions', 'videos', 'experiments', 'code', 'release', 'interactive', 'colab', 'notebook', 'runs', 'browser', 'please', 'check', 'project', 'page', 'https', 'url', 'https', 'https', 'https', 'https', 'preview', 'redd', 'ysfuybjgakb', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'beddcabffbedbffbbda']","['r', 'lm', 'nav', 'robot', 'navig', 'larg', 'pre', 'train', 'model', 'languag', 'vision', 'action', 'googlepap', 'http', 'http', 'github', 'http', 'summeri', 'video', 'http', 'abstract', 'goal', 'condit', 'polici', 'robot', 'navig', 'train', 'larg', 'unannot', 'dataset', 'provid', 'good', 'gener', 'real', 'world', 'set', 'howev', 'particularli', 'vision', 'base', 'set', 'specifi', 'goal', 'requir', 'imag', 'make', 'unnatur', 'interfac', 'languag', 'provid', 'conveni', 'modal', 'commun', 'robot', 'contemporari', 'method', 'typic', 'requir', 'expens', 'supervis', 'form', 'trajectori', 'annot', 'languag', 'descript', 'present', 'system', 'lm', 'nav', 'robot', 'navig', 'enjoy', 'benefit', 'train', 'unannot', 'larg', 'dataset', 'trajectori', 'still', 'provid', 'high', 'level', 'interfac', 'user', 'instead', 'util', 'label', 'instruct', 'follow', 'dataset', 'show', 'system', 'construct', 'entir', 'pre', 'train', 'model', 'navig', 'ving', 'imag', 'languag', 'associ', 'clip', 'languag', 'model', 'gpt', 'without', 'requir', 'fine', 'tune', 'languag', 'annot', 'robot', 'data', 'instanti', 'lm', 'nav', 'real', 'world', 'mobil', 'robot', 'demonstr', 'long', 'horizon', 'navig', 'complex', 'outdoor', 'environ', 'natur', 'languag', 'instruct', 'video', 'experi', 'code', 'releas', 'interact', 'colab', 'notebook', 'run', 'browser', 'pleas', 'check', 'project', 'page', 'http', 'url', 'http', 'http', 'http', 'http', 'preview', 'redd', 'ysfuybjgakb', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'beddcabffbedbffbbda']"
214,236,236,madlad612,vzdvr5,[P] How to tackle Time-series Classification with a large number of categorical variables/attributes ( >100) with high cardinality? I'm open to discussing other ways as well.,I am predicting whether the particular event would occur or not in the next n-timeframes given the categorical variables with high cardinality. Please let me know if there is anything that we can do to tackle this problem.,12,2,2022-07-15 05:58:10, p  how to tackle time series classification with a large number of categorical variables attributes      with high cardinality  i m open to discussing other ways as well ,i am predicting whether the particular event would occur or not in the next n timeframes given the categorical variables with high cardinality  please let me know if there is anything that we can do to tackle this problem ,predicting whether particular event would occur next n timeframes given categorical variables high cardinality please let know anything tackle problem,p tackle time series classification large number categorical variables attributes high cardinality open discussing ways well,p tackle time series classification large number categorical variables attributes high cardinality open discussing ways wellpredicting whether particular event would occur next n timeframes given categorical variables high cardinality please let know anything tackle problem,"['p', 'tackle', 'time', 'series', 'classification', 'large', 'number', 'categorical', 'variables', 'attributes', 'high', 'cardinality', 'open', 'discussing', 'ways', 'wellpredicting', 'whether', 'particular', 'event', 'would', 'occur', 'next', 'n', 'timeframes', 'given', 'categorical', 'variables', 'high', 'cardinality', 'please', 'let', 'know', 'anything', 'tackle', 'problem']","['p', 'tackl', 'time', 'seri', 'classif', 'larg', 'number', 'categor', 'variabl', 'attribut', 'high', 'cardin', 'open', 'discuss', 'way', 'wellpredict', 'whether', 'particular', 'event', 'would', 'occur', 'next', 'n', 'timefram', 'given', 'categor', 'variabl', 'high', 'cardin', 'pleas', 'let', 'know', 'anyth', 'tackl', 'problem']"
215,237,237,ollie_wollie_rocks,vz1mmj,[Discussion] Code editor for transforming data/building ML pipelines,"Check out our new open source code editor for transforming data and building ML pipelines: [https://github.com/mage-ai/mage-ai](https://github.com/mage-ai/mage-ai)

If you’re available, I’d love to hop on a quick Zoom to help you get set up.

In the meantime, here is the install guide: [https://github.com/mage-ai/mage-ai#using-pip](https://github.com/mage-ai/mage-ai#using-pip) and a short tutorial: [https://github.com/mage-ai/mage-ai/blob/master/docs/tutorials/train\_titanic\_model/README.md](https://github.com/mage-ai/mage-ai/blob/master/docs/tutorials/train_titanic_model/README.md)

I’d love to get your feedback on whether this is useful to you or not. Thank you so much!",0,11,2022-07-14 20:37:57, discussion  code editor for transforming data building ml pipelines,check out our new open source code editor for transforming data and building ml pipelines   https if you re available  i d love to hop on a quick zoom to help you get set up in the meantime  here is the install guide   https i d love to get your feedback on whether this is useful to you or not  thank you so much ,check open source code editor transforming data building ml pipelines https available love hop quick zoom help get set meantime install guide https love get feedback whether useful thank much,discussion code editor transforming data building ml pipelines,discussion code editor transforming data building ml pipelinescheck open source code editor transforming data building ml pipelines https available love hop quick zoom help get set meantime install guide https love get feedback whether useful thank much,"['discussion', 'code', 'editor', 'transforming', 'data', 'building', 'ml', 'pipelinescheck', 'open', 'source', 'code', 'editor', 'transforming', 'data', 'building', 'ml', 'pipelines', 'https', 'available', 'love', 'hop', 'quick', 'zoom', 'help', 'get', 'set', 'meantime', 'install', 'guide', 'https', 'love', 'get', 'feedback', 'whether', 'useful', 'thank', 'much']","['discuss', 'code', 'editor', 'transform', 'data', 'build', 'ml', 'pipelinescheck', 'open', 'sourc', 'code', 'editor', 'transform', 'data', 'build', 'ml', 'pipelin', 'http', 'avail', 'love', 'hop', 'quick', 'zoom', 'help', 'get', 'set', 'meantim', 'instal', 'guid', 'http', 'love', 'get', 'feedback', 'whether', 'use', 'thank', 'much']"
216,238,238,EffectSizeQueen,vyewbj,[N] Andrej Karpathy is leaving Tesla,"Twitter thread:

https://twitter.com/karpathy/status/1547332300186066944",126,275,2022-07-14 00:48:38, n  andrej karpathy is leaving tesla,twitter thread https   twitter com karpathy status ,twitter thread https twitter com karpathy status,n andrej karpathy leaving tesla,n andrej karpathy leaving teslatwitter thread https twitter com karpathy status,"['n', 'andrej', 'karpathy', 'leaving', 'teslatwitter', 'thread', 'https', 'twitter', 'com', 'karpathy', 'status']","['n', 'andrej', 'karpathi', 'leav', 'teslatwitt', 'thread', 'http', 'twitter', 'com', 'karpathi', 'statu']"
217,239,239,fedetask,vz1a7u,[D] Best way to increase LSTM/GRU capacity,"LSTM and GRU have a fixed set of weights, that only depend on the size of the input and the size of the LSTM/GRU units. But what if I have the feeling that the parameters in the model are not enough to capture and process the data correctly? In other words, how do I increase the capacity of these models?

Some ideas that came to me are:

 \- Preprocess each vector of the sequence with another model, then feed the output vectors to the LSTM/GRU

\- Just use a larger number of units in the LSTM/GRU (however, this might create a big mismatch between the input and output size

\- Develop a LSTM/GRU that uses more than one layer in each step (e.g. a k-layer neural network instead of a weight matrix)

What do you think is the best? Do you know any other method?",4,2,2022-07-14 20:23:08, d  best way to increase lstm gru capacity,lstm and gru have a fixed set of weights  that only depend on the size of the input and the size of the lstm gru units  but what if i have the feeling that the parameters in the model are not enough to capture and process the data correctly  in other words  how do i increase the capacity of these models some ideas that came to me are     preprocess each vector of the sequence with another model  then feed the output vectors to the lstm gru   just use a larger number of units in the lstm gru  however  this might create a big mismatch between the input and output size   develop a lstm gru that uses more than one layer in each step  e g  a k layer neural network instead of a weight matrix what do you think is the best  do you know any other method ,lstm gru fixed set weights depend size input size lstm gru units feeling parameters model enough capture process data correctly increase capacity models ideas came preprocess vector sequence another model feed output vectors lstm gru use larger number units lstm gru however might create big mismatch input output size develop lstm gru uses one layer step e g k layer neural network instead weight matrix think best know method,best way increase lstm gru capacity,best way increase lstm gru capacitylstm gru fixed set weights depend size input size lstm gru units feeling parameters model enough capture process data correctly increase capacity models ideas came preprocess vector sequence another model feed output vectors lstm gru use larger number units lstm gru however might create big mismatch input output size develop lstm gru uses one layer step e g k layer neural network instead weight matrix think best know method,"['best', 'way', 'increase', 'lstm', 'gru', 'capacitylstm', 'gru', 'fixed', 'set', 'weights', 'depend', 'size', 'input', 'size', 'lstm', 'gru', 'units', 'feeling', 'parameters', 'model', 'enough', 'capture', 'process', 'data', 'correctly', 'increase', 'capacity', 'models', 'ideas', 'came', 'preprocess', 'vector', 'sequence', 'another', 'model', 'feed', 'output', 'vectors', 'lstm', 'gru', 'use', 'larger', 'number', 'units', 'lstm', 'gru', 'however', 'might', 'create', 'big', 'mismatch', 'input', 'output', 'size', 'develop', 'lstm', 'gru', 'uses', 'one', 'layer', 'step', 'e', 'g', 'k', 'layer', 'neural', 'network', 'instead', 'weight', 'matrix', 'think', 'best', 'know', 'method']","['best', 'way', 'increas', 'lstm', 'gru', 'capacitylstm', 'gru', 'fix', 'set', 'weight', 'depend', 'size', 'input', 'size', 'lstm', 'gru', 'unit', 'feel', 'paramet', 'model', 'enough', 'captur', 'process', 'data', 'correctli', 'increas', 'capac', 'model', 'idea', 'came', 'preprocess', 'vector', 'sequenc', 'anoth', 'model', 'feed', 'output', 'vector', 'lstm', 'gru', 'use', 'larger', 'number', 'unit', 'lstm', 'gru', 'howev', 'might', 'creat', 'big', 'mismatch', 'input', 'output', 'size', 'develop', 'lstm', 'gru', 'use', 'one', 'layer', 'step', 'e', 'g', 'k', 'layer', 'neural', 'network', 'instead', 'weight', 'matrix', 'think', 'best', 'know', 'method']"
218,240,240,Celestialdonuts,vzdhex,[D] ML architecture for adaptive setting suggestions in a stage-dependent program,"I've got a problem that I could use some insight on.

&#x200B;

Summary:

I need to design a ML architecture that suggests parameters to a program depending on the observed performance of the user. The program has a set number of stages and the objective of the program is to improve user performance as much as possible within the stage limit. 

&#x200B;

Problem description:

To provide an example, let's say we have 3 stages in the program and the user starts off at stage 1. The program takes two parameters at each stage that determine the difficulty of that stage: Alpha and Beta, which both range from \[0, 10\], inclusive. The user completes stage 1 and a summarization score on user performance is returned based on a radar chart produced by the program. For this example, let's say the score is a 3 out of 10. This radar chart display scores that reflect 6 specific skill components (similar to those character ability charts in video games). By the end of stage 3, we want the user's score to improve as much as possible and preferably to a 10. 

Currently, the two parameters are statically set (e.g. \[(A: 4.2, B: 5), (A: 6, B: 6.6), (A: 8, B: 8)\]) regardless of user performance but I want the parameters to be adaptively set depending on the performance of the user at the previous stage. If the user underperforms compared to the expected result at stage 2, the parameters for stage 3 will be scaled down accordingly to accommodate (e.g. \[A: 7.5, B: 7.5\] instead of 8, for example). Of course, if the user outperforms the expectations, the parameters will be scaled up (e.g. \[A: 8.3, B: 8.2\]). As of right now, the expectation for performance is an evenly linear increase from the initial score (3) to a perfect score (10) but this can change.

My initial idea is to create a recommender system and feed both the summary score and the 6 individual component scores into the model to return a personalized parameter suggestion for each stage. Would a recommender system be suitable or am I over-thinking and over-engineering the problem?",0,0,2022-07-15 05:37:52, d  ml architecture for adaptive setting suggestions in a stage dependent program,i ve got a problem that i could use some insight on   xb summary i need to design a ml architecture that suggests parameters to a program depending on the observed performance of the user  the program has a set number of stages and the objective of the program is to improve user performance as much as possible within the stage limit    xb problem description to provide an example  let s say we have  stages in the program and the user starts off at stage   the program takes two parameters at each stage that determine the difficulty of that stage  alpha and beta  which both range from         inclusive  the user completes stage  and a summarization score on user performance is returned based on a radar chart produced by the program  for this example  let s say the score is a  out of   this radar chart display scores that reflect  specific skill components  similar to those character ability charts in video games   by the end of stage   we want the user s score to improve as much as possible and preferably to a   currently  the two parameters are statically set  e g     a     b      a    b       a    b       regardless of user performance but i want the parameters to be adaptively set depending on the performance of the user at the previous stage  if the user underperforms compared to the expected result at stage   the parameters for stage  will be scaled down accordingly to accommodate  e g    a     b      instead of   for example   of course  if the user outperforms the expectations  the parameters will be scaled up  e g    a     b        as of right now  the expectation for performance is an evenly linear increase from the initial score    to a perfect score    but this can change my initial idea is to create a recommender system and feed both the summary score and the  individual component scores into the model to return a personalized parameter suggestion for each stage  would a recommender system be suitable or am i over thinking and over engineering the problem ,got problem could use insight xb summary need design ml architecture suggests parameters program depending observed performance user program set number stages objective program improve user performance much possible within stage limit xb problem description provide example let say stages program user starts stage program takes two parameters stage determine difficulty stage alpha beta range inclusive user completes stage summarization score user performance returned based radar chart produced program example let say score radar chart display scores reflect specific skill components similar character ability charts video games end stage want user score improve much possible preferably currently two parameters statically set e g b b b regardless user performance want parameters adaptively set depending performance user previous stage user underperforms compared expected result stage parameters stage scaled accordingly accommodate e g b instead example course user outperforms expectations parameters scaled e g b right expectation performance evenly linear increase initial score perfect score change initial idea create recommender system feed summary score individual component scores model return personalized parameter suggestion stage would recommender system suitable thinking engineering problem,ml architecture adaptive setting suggestions stage dependent program,ml architecture adaptive setting suggestions stage dependent programgot problem could use insight xb summary need design ml architecture suggests parameters program depending observed performance user program set number stages objective program improve user performance much possible within stage limit xb problem description provide example let say stages program user starts stage program takes two parameters stage determine difficulty stage alpha beta range inclusive user completes stage summarization score user performance returned based radar chart produced program example let say score radar chart display scores reflect specific skill components similar character ability charts video games end stage want user score improve much possible preferably currently two parameters statically set e g b b b regardless user performance want parameters adaptively set depending performance user previous stage user underperforms compared expected result stage parameters stage scaled accordingly accommodate e g b instead example course user outperforms expectations parameters scaled e g b right expectation performance evenly linear increase initial score perfect score change initial idea create recommender system feed summary score individual component scores model return personalized parameter suggestion stage would recommender system suitable thinking engineering problem,"['ml', 'architecture', 'adaptive', 'setting', 'suggestions', 'stage', 'dependent', 'programgot', 'problem', 'could', 'use', 'insight', 'xb', 'summary', 'need', 'design', 'ml', 'architecture', 'suggests', 'parameters', 'program', 'depending', 'observed', 'performance', 'user', 'program', 'set', 'number', 'stages', 'objective', 'program', 'improve', 'user', 'performance', 'much', 'possible', 'within', 'stage', 'limit', 'xb', 'problem', 'description', 'provide', 'example', 'let', 'say', 'stages', 'program', 'user', 'starts', 'stage', 'program', 'takes', 'two', 'parameters', 'stage', 'determine', 'difficulty', 'stage', 'alpha', 'beta', 'range', 'inclusive', 'user', 'completes', 'stage', 'summarization', 'score', 'user', 'performance', 'returned', 'based', 'radar', 'chart', 'produced', 'program', 'example', 'let', 'say', 'score', 'radar', 'chart', 'display', 'scores', 'reflect', 'specific', 'skill', 'components', 'similar', 'character', 'ability', 'charts', 'video', 'games', 'end', 'stage', 'want', 'user', 'score', 'improve', 'much', 'possible', 'preferably', 'currently', 'two', 'parameters', 'statically', 'set', 'e', 'g', 'b', 'b', 'b', 'regardless', 'user', 'performance', 'want', 'parameters', 'adaptively', 'set', 'depending', 'performance', 'user', 'previous', 'stage', 'user', 'underperforms', 'compared', 'expected', 'result', 'stage', 'parameters', 'stage', 'scaled', 'accordingly', 'accommodate', 'e', 'g', 'b', 'instead', 'example', 'course', 'user', 'outperforms', 'expectations', 'parameters', 'scaled', 'e', 'g', 'b', 'right', 'expectation', 'performance', 'evenly', 'linear', 'increase', 'initial', 'score', 'perfect', 'score', 'change', 'initial', 'idea', 'create', 'recommender', 'system', 'feed', 'summary', 'score', 'individual', 'component', 'scores', 'model', 'return', 'personalized', 'parameter', 'suggestion', 'stage', 'would', 'recommender', 'system', 'suitable', 'thinking', 'engineering', 'problem']","['ml', 'architectur', 'adapt', 'set', 'suggest', 'stage', 'depend', 'programgot', 'problem', 'could', 'use', 'insight', 'xb', 'summari', 'need', 'design', 'ml', 'architectur', 'suggest', 'paramet', 'program', 'depend', 'observ', 'perform', 'user', 'program', 'set', 'number', 'stage', 'object', 'program', 'improv', 'user', 'perform', 'much', 'possibl', 'within', 'stage', 'limit', 'xb', 'problem', 'descript', 'provid', 'exampl', 'let', 'say', 'stage', 'program', 'user', 'start', 'stage', 'program', 'take', 'two', 'paramet', 'stage', 'determin', 'difficulti', 'stage', 'alpha', 'beta', 'rang', 'inclus', 'user', 'complet', 'stage', 'summar', 'score', 'user', 'perform', 'return', 'base', 'radar', 'chart', 'produc', 'program', 'exampl', 'let', 'say', 'score', 'radar', 'chart', 'display', 'score', 'reflect', 'specif', 'skill', 'compon', 'similar', 'charact', 'abil', 'chart', 'video', 'game', 'end', 'stage', 'want', 'user', 'score', 'improv', 'much', 'possibl', 'prefer', 'current', 'two', 'paramet', 'static', 'set', 'e', 'g', 'b', 'b', 'b', 'regardless', 'user', 'perform', 'want', 'paramet', 'adapt', 'set', 'depend', 'perform', 'user', 'previou', 'stage', 'user', 'underperform', 'compar', 'expect', 'result', 'stage', 'paramet', 'stage', 'scale', 'accordingli', 'accommod', 'e', 'g', 'b', 'instead', 'exampl', 'cours', 'user', 'outperform', 'expect', 'paramet', 'scale', 'e', 'g', 'b', 'right', 'expect', 'perform', 'evenli', 'linear', 'increas', 'initi', 'score', 'perfect', 'score', 'chang', 'initi', 'idea', 'creat', 'recommend', 'system', 'feed', 'summari', 'score', 'individu', 'compon', 'score', 'model', 'return', 'person', 'paramet', 'suggest', 'stage', 'would', 'recommend', 'system', 'suitabl', 'think', 'engin', 'problem']"
219,241,241,IllustriousCicada603,vyub54,[D] Is sampling distractors from the same mini batch during training a good idea?,"Hello, I have a NLP Transformer model and for my case I want to add a binary classifier as an auxiliary task. I will give a random response and the ground truth labels to the classifier and expect from it to distinguish them.

Is it a good idea instead of modifying the dataset to just shift the current mini batch during training in order to generate distractors. For example let's say the batch size is 4.

We will have four response sequences in our batch: `[[1...], [2...], [3...], [4...]]`, so I can copy and shift them (by 2), for example: `[[3...], [4...], [1...], [2...]]`\` Then I can stack the ground truth and the shifted batch to get `[ [[1...], [3...]], [[2...], [4...]], [[3...], [1...]], [[4...], [2...]] ]` and feed that to the classifier where the labels are `[ [1, 0], [1, 0], [1, 0], [1, 0] ]`. Furthermore I can randomize the order of \`(truth, distractor)\` pairs in each batch and sometimes the labels will be `[1, 0]` and other times - `[0, 1]`.

Finally, if there's a concern that because of the dataloader order in a batch we may have related responses and not completely random ones - I would say that this is actually an advantage, because a classifier which can distinguish the right response compared to a related one is a stronger classifier.

Do you think this makes sense and what are the possible drawbacks?",0,2,2022-07-14 15:07:04, d  is sampling distractors from the same mini batch during training a good idea ,hello  i have a nlp transformer model and for my case i want to add a binary classifier as an auxiliary task  i will give a random response and the ground truth labels to the classifier and expect from it to distinguish them is it a good idea instead of modifying the dataset to just shift the current mini batch during training in order to generate distractors  for example let s say the batch size is  we will have four response sequences in our batch                                  so i can copy and shift them  by    for example                                   then i can stack the ground truth and the shifted batch to get                                                                      and feed that to the classifier where the labels are                               furthermore i can randomize the order of    truth  distractor    pairs in each batch and sometimes the labels will be        and other times          finally  if there s a concern that because of the dataloader order in a batch we may have related responses and not completely random ones   i would say that this is actually an advantage  because a classifier which can distinguish the right response compared to a related one is a stronger classifier do you think this makes sense and what are the possible drawbacks ,hello nlp transformer model case want binary classifier auxiliary task give random response ground truth labels classifier expect distinguish good idea instead modifying dataset shift current mini batch training order generate distractors example let say batch size four response sequences batch copy shift example stack ground truth shifted batch get feed classifier labels furthermore randomize order truth distractor pairs batch sometimes labels times finally concern dataloader order batch may related responses completely random ones would say actually advantage classifier distinguish right response compared related one stronger classifier think makes sense possible drawbacks,sampling distractors mini batch training good idea,sampling distractors mini batch training good ideahello nlp transformer model case want binary classifier auxiliary task give random response ground truth labels classifier expect distinguish good idea instead modifying dataset shift current mini batch training order generate distractors example let say batch size four response sequences batch copy shift example stack ground truth shifted batch get feed classifier labels furthermore randomize order truth distractor pairs batch sometimes labels times finally concern dataloader order batch may related responses completely random ones would say actually advantage classifier distinguish right response compared related one stronger classifier think makes sense possible drawbacks,"['sampling', 'distractors', 'mini', 'batch', 'training', 'good', 'ideahello', 'nlp', 'transformer', 'model', 'case', 'want', 'binary', 'classifier', 'auxiliary', 'task', 'give', 'random', 'response', 'ground', 'truth', 'labels', 'classifier', 'expect', 'distinguish', 'good', 'idea', 'instead', 'modifying', 'dataset', 'shift', 'current', 'mini', 'batch', 'training', 'order', 'generate', 'distractors', 'example', 'let', 'say', 'batch', 'size', 'four', 'response', 'sequences', 'batch', 'copy', 'shift', 'example', 'stack', 'ground', 'truth', 'shifted', 'batch', 'get', 'feed', 'classifier', 'labels', 'furthermore', 'randomize', 'order', 'truth', 'distractor', 'pairs', 'batch', 'sometimes', 'labels', 'times', 'finally', 'concern', 'dataloader', 'order', 'batch', 'may', 'related', 'responses', 'completely', 'random', 'ones', 'would', 'say', 'actually', 'advantage', 'classifier', 'distinguish', 'right', 'response', 'compared', 'related', 'one', 'stronger', 'classifier', 'think', 'makes', 'sense', 'possible', 'drawbacks']","['sampl', 'distractor', 'mini', 'batch', 'train', 'good', 'ideahello', 'nlp', 'transform', 'model', 'case', 'want', 'binari', 'classifi', 'auxiliari', 'task', 'give', 'random', 'respons', 'ground', 'truth', 'label', 'classifi', 'expect', 'distinguish', 'good', 'idea', 'instead', 'modifi', 'dataset', 'shift', 'current', 'mini', 'batch', 'train', 'order', 'gener', 'distractor', 'exampl', 'let', 'say', 'batch', 'size', 'four', 'respons', 'sequenc', 'batch', 'copi', 'shift', 'exampl', 'stack', 'ground', 'truth', 'shift', 'batch', 'get', 'feed', 'classifi', 'label', 'furthermor', 'random', 'order', 'truth', 'distractor', 'pair', 'batch', 'sometim', 'label', 'time', 'final', 'concern', 'dataload', 'order', 'batch', 'may', 'relat', 'respons', 'complet', 'random', 'one', 'would', 'say', 'actual', 'advantag', 'classifi', 'distinguish', 'right', 'respons', 'compar', 'relat', 'one', 'stronger', 'classifi', 'think', 'make', 'sens', 'possibl', 'drawback']"
220,242,242,chaoyu,vyfit6,[P] Introducing BentoML 1.0 - A faster way to ship your models to production,"Hi everyone! I'm excited to share some news from the [BentoML](https://github.com/bentoml) team.

When we first open sourced the BentoML project [in 2019](https://www.reddit.com/r/MachineLearning/comments/izqelx/p_bentoml_090_the_easiest_way_to_create_machine/) and [shared it ](https://www.reddit.com/r/MachineLearning/comments/g1cfre/p_bentoml_an_opensource_platform_for/)[with the community](https://www.reddit.com/r/MachineLearning/comments/g1cfre/p_bentoml_an_opensource_platform_for/), our vision was to create an open platform that simplifies machine learning model serving and provides a solid foundation for ML teams to operate ML at production scale. And after years of working together with our community towards that goal, we’re thrilled to announce the general availability of BentoML 1.0!  


What's new in BentoML 1.0?

* Simplify model packaging and management, both locally and a centralized model repository for teams.
* A Python-first architecture that scales with powerful optimizations, including parallel inference, adaptive batching, and support for accelerated runtimes.
* Introducing [Yatai for BentoML](https://github.com/bentoml/Yatai): Production-first ML platform on Kubernetes

&#x200B;

To learn more:

* Introducing BentoML 1.0 Blog post: [https://modelserving.com/blog/introducing-bentoml-10](https://modelserving.com/blog/introducing-bentoml-10)
* BentoML Tutorial: [https://docs.bentoml.org/en/latest/tutorial.html](https://docs.bentoml.org/en/latest/tutorial.html)
* Github Page: [https://github.com/bentoml/BentoML](https://github.com/bentoml/BentoML)
* Documentation: [https://docs.bentoml.org/](https://docs.bentoml.org/)",2,20,2022-07-14 01:15:28, p  introducing bentoml     a faster way to ship your models to production,hi everyone  i m excited to share some news from the  bentoml  https when we first open sourced the bentoml project  in   https what s new in bentoml     simplify model packaging and management  both locally and a centralized model repository for teams   a python first architecture that scales with powerful optimizations  including parallel inference  adaptive batching  and support for accelerated runtimes   introducing  yatai for bentoml  https   xb to learn more   introducing bentoml   blog post   https   bentoml tutorial   https   github page   https   documentation   https   docs bentoml org   https   docs bentoml org  ,hi everyone excited share news bentoml https first open sourced bentoml project https bentoml simplify model packaging management locally centralized model repository teams python first architecture scales powerful optimizations including parallel inference adaptive batching support accelerated runtimes introducing yatai bentoml https xb learn introducing bentoml blog post https bentoml tutorial https github page https documentation https docs bentoml org https docs bentoml org,p introducing bentoml faster way ship models production,p introducing bentoml faster way ship models productionhi everyone excited share news bentoml https first open sourced bentoml project https bentoml simplify model packaging management locally centralized model repository teams python first architecture scales powerful optimizations including parallel inference adaptive batching support accelerated runtimes introducing yatai bentoml https xb learn introducing bentoml blog post https bentoml tutorial https github page https documentation https docs bentoml org https docs bentoml org,"['p', 'introducing', 'bentoml', 'faster', 'way', 'ship', 'models', 'productionhi', 'everyone', 'excited', 'share', 'news', 'bentoml', 'https', 'first', 'open', 'sourced', 'bentoml', 'project', 'https', 'bentoml', 'simplify', 'model', 'packaging', 'management', 'locally', 'centralized', 'model', 'repository', 'teams', 'python', 'first', 'architecture', 'scales', 'powerful', 'optimizations', 'including', 'parallel', 'inference', 'adaptive', 'batching', 'support', 'accelerated', 'runtimes', 'introducing', 'yatai', 'bentoml', 'https', 'xb', 'learn', 'introducing', 'bentoml', 'blog', 'post', 'https', 'bentoml', 'tutorial', 'https', 'github', 'page', 'https', 'documentation', 'https', 'docs', 'bentoml', 'org', 'https', 'docs', 'bentoml', 'org']","['p', 'introduc', 'bentoml', 'faster', 'way', 'ship', 'model', 'productionhi', 'everyon', 'excit', 'share', 'news', 'bentoml', 'http', 'first', 'open', 'sourc', 'bentoml', 'project', 'http', 'bentoml', 'simplifi', 'model', 'packag', 'manag', 'local', 'central', 'model', 'repositori', 'team', 'python', 'first', 'architectur', 'scale', 'power', 'optim', 'includ', 'parallel', 'infer', 'adapt', 'batch', 'support', 'acceler', 'runtim', 'introduc', 'yatai', 'bentoml', 'http', 'xb', 'learn', 'introduc', 'bentoml', 'blog', 'post', 'http', 'bentoml', 'tutori', 'http', 'github', 'page', 'http', 'document', 'http', 'doc', 'bentoml', 'org', 'http', 'doc', 'bentoml', 'org']"
221,243,243,fanconic,vxw3s4,"[R] So someone actually peer-reviewed this and thought ""yeah, looks good""?","It looks like chronic kidney disease diagnosis has been solved in this paper: [https://ieeexplore.ieee.org/document/8693581](https://ieeexplore.ieee.org/document/8693581)

I mean no disrespect to the authors, but this publication makes me slightly doubt the peer-review system. Or I am just such an amateur, that I am not seeing the brilliance behind this paper, which is also possible.

Have a read through it yourselves",79,239,2022-07-13 09:09:59, r  so someone actually peer reviewed this and thought yeah  looks good ,it looks like chronic kidney disease diagnosis has been solved in this paper   https i mean no disrespect to the authors  but this publication makes me slightly doubt the peer review system  or i am just such an amateur  that i am not seeing the brilliance behind this paper  which is also possible have a read through it yourselves,looks like chronic kidney disease diagnosis solved paper https mean disrespect authors publication makes slightly doubt peer review system amateur seeing brilliance behind paper also possible read,r someone actually peer reviewed thought yeah looks good,r someone actually peer reviewed thought yeah looks goodlooks like chronic kidney disease diagnosis solved paper https mean disrespect authors publication makes slightly doubt peer review system amateur seeing brilliance behind paper also possible read,"['r', 'someone', 'actually', 'peer', 'reviewed', 'thought', 'yeah', 'looks', 'goodlooks', 'like', 'chronic', 'kidney', 'disease', 'diagnosis', 'solved', 'paper', 'https', 'mean', 'disrespect', 'authors', 'publication', 'makes', 'slightly', 'doubt', 'peer', 'review', 'system', 'amateur', 'seeing', 'brilliance', 'behind', 'paper', 'also', 'possible', 'read']","['r', 'someon', 'actual', 'peer', 'review', 'thought', 'yeah', 'look', 'goodlook', 'like', 'chronic', 'kidney', 'diseas', 'diagnosi', 'solv', 'paper', 'http', 'mean', 'disrespect', 'author', 'public', 'make', 'slightli', 'doubt', 'peer', 'review', 'system', 'amateur', 'see', 'brillianc', 'behind', 'paper', 'also', 'possibl', 'read']"
222,244,244,tacixat,vye9fa,[D] I made a site for collaborative image labeling,"I recently launched [https://mekabytes.com](https://mekabytes.com/). The idea is to treat datasets like subreddits where users can come together to build the stuff they want to see.

For the datasets there is a github-style landing page with a README to help give guidance on the goals, what images the dataset wants, and any labeling guidelines. There is also a reddit-style comment system where you can reference specific annotations. The idea with that is to provide feedback to help people learn.

The coolest part (IMO) is the versioning system. All annotations are versioned and approved by a moderator, gating data quality kind of like a code review. This versioning allows the dataset to be rolled back to any point in time which will help reproduce research even as the dataset continues to evolve.

The dataset releases will be open under a creative commons license (BY-NC-SA). To help cover hosting the releases are downloadable for $5 + $1/GB. Basically you can use it for research, personal projects, and share freely once you have it.

There is still a ton of stuff to do and I don't even have my first user yet! I've been using it for the last week or so and cleaning up the UX. You can actually annotate decently on mobile.

Right now it supports classification and object detection (bounding boxes). I hope to add a free text field in the near future after some niceties like pagination and comment notifications.

I would love some feedback if you have any!",11,14,2022-07-14 00:21:25, d  i made a site for collaborative image labeling,i recently launched  https for the datasets there is a github style landing page with a readme to help give guidance on the goals  what images the dataset wants  and any labeling guidelines  there is also a reddit style comment system where you can reference specific annotations  the idea with that is to provide feedback to help people learn the coolest part  imo  is the versioning system  all annotations are versioned and approved by a moderator  gating data quality kind of like a code review  this versioning allows the dataset to be rolled back to any point in time which will help reproduce research even as the dataset continues to evolve the dataset releases will be open under a creative commons license  by nc sa   to help cover hosting the releases are downloadable for       gb  basically you can use it for research  personal projects  and share freely once you have it there is still a ton of stuff to do and i don t even have my first user yet  i ve been using it for the last week or so and cleaning up the ux  you can actually annotate decently on mobile right now it supports classification and object detection  bounding boxes   i hope to add a free text field in the near future after some niceties like pagination and comment notifications i would love some feedback if you have any ,recently launched https datasets github style landing page readme help give guidance goals images dataset wants labeling guidelines also reddit style comment system reference specific annotations idea provide feedback help people learn coolest part imo versioning system annotations versioned approved moderator gating data quality kind like code review versioning allows dataset rolled back point time help reproduce research even dataset continues evolve dataset releases open creative commons license nc sa help cover hosting releases downloadable gb basically use research personal projects share freely still ton stuff even first user yet using last week cleaning ux actually annotate decently mobile right supports classification object detection bounding boxes hope free text field near future niceties like pagination comment notifications would love feedback,made site collaborative image labeling,made site collaborative image labelingrecently launched https datasets github style landing page readme help give guidance goals images dataset wants labeling guidelines also reddit style comment system reference specific annotations idea provide feedback help people learn coolest part imo versioning system annotations versioned approved moderator gating data quality kind like code review versioning allows dataset rolled back point time help reproduce research even dataset continues evolve dataset releases open creative commons license nc sa help cover hosting releases downloadable gb basically use research personal projects share freely still ton stuff even first user yet using last week cleaning ux actually annotate decently mobile right supports classification object detection bounding boxes hope free text field near future niceties like pagination comment notifications would love feedback,"['made', 'site', 'collaborative', 'image', 'labelingrecently', 'launched', 'https', 'datasets', 'github', 'style', 'landing', 'page', 'readme', 'help', 'give', 'guidance', 'goals', 'images', 'dataset', 'wants', 'labeling', 'guidelines', 'also', 'reddit', 'style', 'comment', 'system', 'reference', 'specific', 'annotations', 'idea', 'provide', 'feedback', 'help', 'people', 'learn', 'coolest', 'part', 'imo', 'versioning', 'system', 'annotations', 'versioned', 'approved', 'moderator', 'gating', 'data', 'quality', 'kind', 'like', 'code', 'review', 'versioning', 'allows', 'dataset', 'rolled', 'back', 'point', 'time', 'help', 'reproduce', 'research', 'even', 'dataset', 'continues', 'evolve', 'dataset', 'releases', 'open', 'creative', 'commons', 'license', 'nc', 'sa', 'help', 'cover', 'hosting', 'releases', 'downloadable', 'gb', 'basically', 'use', 'research', 'personal', 'projects', 'share', 'freely', 'still', 'ton', 'stuff', 'even', 'first', 'user', 'yet', 'using', 'last', 'week', 'cleaning', 'ux', 'actually', 'annotate', 'decently', 'mobile', 'right', 'supports', 'classification', 'object', 'detection', 'bounding', 'boxes', 'hope', 'free', 'text', 'field', 'near', 'future', 'niceties', 'like', 'pagination', 'comment', 'notifications', 'would', 'love', 'feedback']","['made', 'site', 'collabor', 'imag', 'labelingrec', 'launch', 'http', 'dataset', 'github', 'style', 'land', 'page', 'readm', 'help', 'give', 'guidanc', 'goal', 'imag', 'dataset', 'want', 'label', 'guidelin', 'also', 'reddit', 'style', 'comment', 'system', 'refer', 'specif', 'annot', 'idea', 'provid', 'feedback', 'help', 'peopl', 'learn', 'coolest', 'part', 'imo', 'version', 'system', 'annot', 'version', 'approv', 'moder', 'gate', 'data', 'qualiti', 'kind', 'like', 'code', 'review', 'version', 'allow', 'dataset', 'roll', 'back', 'point', 'time', 'help', 'reproduc', 'research', 'even', 'dataset', 'continu', 'evolv', 'dataset', 'releas', 'open', 'creativ', 'common', 'licens', 'nc', 'sa', 'help', 'cover', 'host', 'releas', 'download', 'gb', 'basic', 'use', 'research', 'person', 'project', 'share', 'freeli', 'still', 'ton', 'stuff', 'even', 'first', 'user', 'yet', 'use', 'last', 'week', 'clean', 'ux', 'actual', 'annot', 'decent', 'mobil', 'right', 'support', 'classif', 'object', 'detect', 'bound', 'box', 'hope', 'free', 'text', 'field', 'near', 'futur', 'niceti', 'like', 'pagin', 'comment', 'notif', 'would', 'love', 'feedback']"
223,245,245,yuzheyang,vyhn3g,[R] How to learn imbalanced data arising from multiple domains?,"Hello everyone! Happy to share our new work on learning from multi-domain imbalanced data. This work was recently accepted at ECCV 2022.

Data imbalance is ubiquitous and inherent in the real world. Existing methods for dealing with imbalanced data/long-tailed distribution are only for **single domain**, that is, the data originates from the same domain; however, natural data can originate from ***distinct*** **domains**, where a minority class in one domain could have abundant instances from other domains. Effectively utilizing data from different domains is likely to improve the performance of long-tail learning over all domains. This paper promotes the paradigm of the traditional imbalanced classification problem and generalizes it from **single** domain to **multiple domains**.

We formulate the problem of **Multi-Domain Long-Tailed Recognition (MDLT)** as learning from multi-domain imbalanced data, with each domain having its own imbalanced label distribution, and generalizing to a test set that is balanced over ***all domain-class pairs***. MDLT aims to learn from imbalanced data from multiple distinct domains, tackle *label imbalance*, *domain shift*, and *divergent label distributions across domains*, and generalize to the entire set of classes over all domains.

We first propose the ***domain-class transferability graph***, which quantifies the transferability between different domain-class pairs under data imbalance. In this graph, each node refers to a domain-class pair, and each edge refers to the distance between two domain-class pairs in the embedding space. We show that the transferability graph dictates the performance of imbalanced learning across domains. Inspired by this, we design **BoDA**, a loss function that theoretically tracks the upper-bound of transferability statistics to improve the model performance.

Interestingly, we also found that ***addressing in-domain data imbalance improves out-of-domain generalization*** (known as domain generalization, DG). Our analysis showed that data imbalance is an intrinsic problem in DG, but has been overlooked by past works. The intriguing results shed light on **how label imbalance can affect out-of-distribution generalization**, and highlight the importance of **integrating label imbalance for practical DG algorithm design**.

Check out the links below for more details:

* **Paper**: [https://arxiv.org/abs/2203.09513](https://arxiv.org/abs/2203.09513)
* **Code** (+ dataset + models): [https://github.com/YyzHarry/multi-domain-imbalance](https://github.com/YyzHarry/multi-domain-imbalance)
* **Blog post** (check out for in-depth details!): [TowardsDataScience](https://towardsdatascience.com/how-to-learn-imbalanced-data-arising-from-multiple-domains-7d0c0d6e3c17)

&#x200B;

[Multi-Domain Long-Tailed Recognition \(MDLT\) aims to learn from imbalanced data from multiple distinct domains, tackle label imbalance, domain shift, and divergent label distributions across domains, and generalize to the entire set of classes over all domains.](https://i.redd.it/4zefxq759fb91.gif)",2,7,2022-07-14 02:51:26, r  how to learn imbalanced data arising from multiple domains ,hello everyone  happy to share our new work on learning from multi domain imbalanced data  this work was recently accepted at eccv  data imbalance is ubiquitous and inherent in the real world  existing methods for dealing with imbalanced data long tailed distribution are only for   single domain    that is  the data originates from the same domain  however  natural data can originate from    distinct      domains    where a minority class in one domain could have abundant instances from other domains  effectively utilizing data from different domains is likely to improve the performance of long tail learning over all domains  this paper promotes the paradigm of the traditional imbalanced classification problem and generalizes it from   single   domain to   multiple domains   we formulate the problem of   multi domain long tailed recognition  mdlt    as learning from multi domain imbalanced data  with each domain having its own imbalanced label distribution  and generalizing to a test set that is balanced over    all domain class pairs     mdlt aims to learn from imbalanced data from multiple distinct domains  tackle  label imbalance    domain shift   and  divergent label distributions across domains   and generalize to the entire set of classes over all domains we first propose the    domain class transferability graph     which quantifies the transferability between different domain class pairs under data imbalance  in this graph  each node refers to a domain class pair  and each edge refers to the distance between two domain class pairs in the embedding space  we show that the transferability graph dictates the performance of imbalanced learning across domains  inspired by this  we design   boda    a loss function that theoretically tracks the upper bound of transferability statistics to improve the model performance interestingly  we also found that    addressing in domain data imbalance improves out of domain generalization     known as domain generalization  dg   our analysis showed that data imbalance is an intrinsic problem in dg  but has been overlooked by past works  the intriguing results shed light on   how label imbalance can affect out of distribution generalization    and highlight the importance of   integrating label imbalance for practical dg algorithm design   check out the links below for more details     paper     https     code      dataset   models    https     blog post    check out for in depth details     towardsdatascience  https   xb  multi domain long tailed recognition   mdlt   aims to learn from imbalanced data from multiple distinct domains  tackle label imbalance  domain shift  and divergent label distributions across domains  and generalize to the entire set of classes over all domains   https   i redd it zefxqfb gif ,hello everyone happy share work learning multi domain imbalanced data work recently accepted eccv data imbalance ubiquitous inherent real world existing methods dealing imbalanced data long tailed distribution single domain data originates domain however natural data originate distinct domains minority class one domain could abundant instances domains effectively utilizing data different domains likely improve performance long tail learning domains paper promotes paradigm traditional imbalanced classification problem generalizes single domain multiple domains formulate problem multi domain long tailed recognition mdlt learning multi domain imbalanced data domain imbalanced label distribution generalizing test set balanced domain class pairs mdlt aims learn imbalanced data multiple distinct domains tackle label imbalance domain shift divergent label distributions across domains generalize entire set classes domains first propose domain class transferability graph quantifies transferability different domain class pairs data imbalance graph node refers domain class pair edge refers distance two domain class pairs embedding space show transferability graph dictates performance imbalanced learning across domains inspired design boda loss function theoretically tracks upper bound transferability statistics improve model performance interestingly also found addressing domain data imbalance improves domain generalization known domain generalization dg analysis showed data imbalance intrinsic problem dg overlooked past works intriguing results shed light label imbalance affect distribution generalization highlight importance integrating label imbalance practical dg algorithm design check links details paper https code dataset models https blog post check depth details towardsdatascience https xb multi domain long tailed recognition mdlt aims learn imbalanced data multiple distinct domains tackle label imbalance domain shift divergent label distributions across domains generalize entire set classes domains https redd zefxqfb gif,r learn imbalanced data arising multiple domains,r learn imbalanced data arising multiple domainshello everyone happy share work learning multi domain imbalanced data work recently accepted eccv data imbalance ubiquitous inherent real world existing methods dealing imbalanced data long tailed distribution single domain data originates domain however natural data originate distinct domains minority class one domain could abundant instances domains effectively utilizing data different domains likely improve performance long tail learning domains paper promotes paradigm traditional imbalanced classification problem generalizes single domain multiple domains formulate problem multi domain long tailed recognition mdlt learning multi domain imbalanced data domain imbalanced label distribution generalizing test set balanced domain class pairs mdlt aims learn imbalanced data multiple distinct domains tackle label imbalance domain shift divergent label distributions across domains generalize entire set classes domains first propose domain class transferability graph quantifies transferability different domain class pairs data imbalance graph node refers domain class pair edge refers distance two domain class pairs embedding space show transferability graph dictates performance imbalanced learning across domains inspired design boda loss function theoretically tracks upper bound transferability statistics improve model performance interestingly also found addressing domain data imbalance improves domain generalization known domain generalization dg analysis showed data imbalance intrinsic problem dg overlooked past works intriguing results shed light label imbalance affect distribution generalization highlight importance integrating label imbalance practical dg algorithm design check links details paper https code dataset models https blog post check depth details towardsdatascience https xb multi domain long tailed recognition mdlt aims learn imbalanced data multiple distinct domains tackle label imbalance domain shift divergent label distributions across domains generalize entire set classes domains https redd zefxqfb gif,"['r', 'learn', 'imbalanced', 'data', 'arising', 'multiple', 'domainshello', 'everyone', 'happy', 'share', 'work', 'learning', 'multi', 'domain', 'imbalanced', 'data', 'work', 'recently', 'accepted', 'eccv', 'data', 'imbalance', 'ubiquitous', 'inherent', 'real', 'world', 'existing', 'methods', 'dealing', 'imbalanced', 'data', 'long', 'tailed', 'distribution', 'single', 'domain', 'data', 'originates', 'domain', 'however', 'natural', 'data', 'originate', 'distinct', 'domains', 'minority', 'class', 'one', 'domain', 'could', 'abundant', 'instances', 'domains', 'effectively', 'utilizing', 'data', 'different', 'domains', 'likely', 'improve', 'performance', 'long', 'tail', 'learning', 'domains', 'paper', 'promotes', 'paradigm', 'traditional', 'imbalanced', 'classification', 'problem', 'generalizes', 'single', 'domain', 'multiple', 'domains', 'formulate', 'problem', 'multi', 'domain', 'long', 'tailed', 'recognition', 'mdlt', 'learning', 'multi', 'domain', 'imbalanced', 'data', 'domain', 'imbalanced', 'label', 'distribution', 'generalizing', 'test', 'set', 'balanced', 'domain', 'class', 'pairs', 'mdlt', 'aims', 'learn', 'imbalanced', 'data', 'multiple', 'distinct', 'domains', 'tackle', 'label', 'imbalance', 'domain', 'shift', 'divergent', 'label', 'distributions', 'across', 'domains', 'generalize', 'entire', 'set', 'classes', 'domains', 'first', 'propose', 'domain', 'class', 'transferability', 'graph', 'quantifies', 'transferability', 'different', 'domain', 'class', 'pairs', 'data', 'imbalance', 'graph', 'node', 'refers', 'domain', 'class', 'pair', 'edge', 'refers', 'distance', 'two', 'domain', 'class', 'pairs', 'embedding', 'space', 'show', 'transferability', 'graph', 'dictates', 'performance', 'imbalanced', 'learning', 'across', 'domains', 'inspired', 'design', 'boda', 'loss', 'function', 'theoretically', 'tracks', 'upper', 'bound', 'transferability', 'statistics', 'improve', 'model', 'performance', 'interestingly', 'also', 'found', 'addressing', 'domain', 'data', 'imbalance', 'improves', 'domain', 'generalization', 'known', 'domain', 'generalization', 'dg', 'analysis', 'showed', 'data', 'imbalance', 'intrinsic', 'problem', 'dg', 'overlooked', 'past', 'works', 'intriguing', 'results', 'shed', 'light', 'label', 'imbalance', 'affect', 'distribution', 'generalization', 'highlight', 'importance', 'integrating', 'label', 'imbalance', 'practical', 'dg', 'algorithm', 'design', 'check', 'links', 'details', 'paper', 'https', 'code', 'dataset', 'models', 'https', 'blog', 'post', 'check', 'depth', 'details', 'towardsdatascience', 'https', 'xb', 'multi', 'domain', 'long', 'tailed', 'recognition', 'mdlt', 'aims', 'learn', 'imbalanced', 'data', 'multiple', 'distinct', 'domains', 'tackle', 'label', 'imbalance', 'domain', 'shift', 'divergent', 'label', 'distributions', 'across', 'domains', 'generalize', 'entire', 'set', 'classes', 'domains', 'https', 'redd', 'zefxqfb', 'gif']","['r', 'learn', 'imbalanc', 'data', 'aris', 'multipl', 'domainshello', 'everyon', 'happi', 'share', 'work', 'learn', 'multi', 'domain', 'imbalanc', 'data', 'work', 'recent', 'accept', 'eccv', 'data', 'imbal', 'ubiquit', 'inher', 'real', 'world', 'exist', 'method', 'deal', 'imbalanc', 'data', 'long', 'tail', 'distribut', 'singl', 'domain', 'data', 'origin', 'domain', 'howev', 'natur', 'data', 'origin', 'distinct', 'domain', 'minor', 'class', 'one', 'domain', 'could', 'abund', 'instanc', 'domain', 'effect', 'util', 'data', 'differ', 'domain', 'like', 'improv', 'perform', 'long', 'tail', 'learn', 'domain', 'paper', 'promot', 'paradigm', 'tradit', 'imbalanc', 'classif', 'problem', 'gener', 'singl', 'domain', 'multipl', 'domain', 'formul', 'problem', 'multi', 'domain', 'long', 'tail', 'recognit', 'mdlt', 'learn', 'multi', 'domain', 'imbalanc', 'data', 'domain', 'imbalanc', 'label', 'distribut', 'gener', 'test', 'set', 'balanc', 'domain', 'class', 'pair', 'mdlt', 'aim', 'learn', 'imbalanc', 'data', 'multipl', 'distinct', 'domain', 'tackl', 'label', 'imbal', 'domain', 'shift', 'diverg', 'label', 'distribut', 'across', 'domain', 'gener', 'entir', 'set', 'class', 'domain', 'first', 'propos', 'domain', 'class', 'transfer', 'graph', 'quantifi', 'transfer', 'differ', 'domain', 'class', 'pair', 'data', 'imbal', 'graph', 'node', 'refer', 'domain', 'class', 'pair', 'edg', 'refer', 'distanc', 'two', 'domain', 'class', 'pair', 'embed', 'space', 'show', 'transfer', 'graph', 'dictat', 'perform', 'imbalanc', 'learn', 'across', 'domain', 'inspir', 'design', 'boda', 'loss', 'function', 'theoret', 'track', 'upper', 'bound', 'transfer', 'statist', 'improv', 'model', 'perform', 'interestingli', 'also', 'found', 'address', 'domain', 'data', 'imbal', 'improv', 'domain', 'gener', 'known', 'domain', 'gener', 'dg', 'analysi', 'show', 'data', 'imbal', 'intrins', 'problem', 'dg', 'overlook', 'past', 'work', 'intrigu', 'result', 'shed', 'light', 'label', 'imbal', 'affect', 'distribut', 'gener', 'highlight', 'import', 'integr', 'label', 'imbal', 'practic', 'dg', 'algorithm', 'design', 'check', 'link', 'detail', 'paper', 'http', 'code', 'dataset', 'model', 'http', 'blog', 'post', 'check', 'depth', 'detail', 'towardsdatasci', 'http', 'xb', 'multi', 'domain', 'long', 'tail', 'recognit', 'mdlt', 'aim', 'learn', 'imbalanc', 'data', 'multipl', 'distinct', 'domain', 'tackl', 'label', 'imbal', 'domain', 'shift', 'diverg', 'label', 'distribut', 'across', 'domain', 'gener', 'entir', 'set', 'class', 'domain', 'http', 'redd', 'zefxqfb', 'gif']"
224,246,246,rivew,vye2zj,[D] How are People Doing “Fair” Few-Shot Training/Evaluation,"After reading through a lot of the non-Meta Learning popular few-shot literature ([Prototypical Nets](https://arxiv.org/abs/1703.05175?context=cs), [Matching Nets](https://arxiv.org/abs/1606.04080?context=stat), etc.) and then looking at other papers/GitHub repos, I’m not totally sure how to build a “fair” training and evaluation setup.

Let’s take CIFAR-100 (ignoring CIFAR-FS for now).  To set up a few-shot dataset split, I’d take the 100 classes and split up into train/val/test 60/20/40 such that each split has non-overlapping classes - pretty straightforward.  But now, I still have 600 examples per class in all splits.  Before generating random 5-way-5-shot episodes during training, what’s the fair way to generate Support and Query Sets?  Are people first creating another split of the trainset so that the Support set only contains 5 examples per class (60*5=300 total examples) and the rest is in the Query set?  If not, something like that then the support set is going to contain a lot of examples to learn from rather than a few.

Some methods also directly classify the trainset’s support images for pre-training, assuming that the number of classes overall is known beforehand.  But then to do same on the validation and support sets I guess that they replace the FC layer.

Finally, when choosing a pre-trained model to start with, it seems absolutely necessary to choose a significantly different domain for evaluation (ex. ImageNet pre-trained ResNet evaluated on CIFAR-FS is bad).

tldr; it seems like there’s a lot of small differences in experimental setups for few-shot settings, what’s the best way to be fair for training/evaluation?  Also maybe I’m just totally missing something :)",6,4,2022-07-14 00:13:38, d  how are people doing  fair  few shot training evaluation,after reading through a lot of the non meta learning popular few shot literature   prototypical nets  https let s take cifar   ignoring cifar fs for now    to set up a few shot dataset split  i d take the  classes and split up into train val test some methods also directly classify the trainset s support images for pre training  assuming that the number of classes overall is known beforehand   but then to do same on the validation and support sets i guess that they replace the fc layer finally  when choosing a pre trained model to start with  it seems absolutely necessary to choose a significantly different domain for evaluation  ex  imagenet pre trained resnet evaluated on cifar fs is bad  tldr  it seems like there s a lot of small differences in experimental setups for few shot settings  what s the best way to be fair for training evaluation   also maybe i m just totally missing something   ,reading lot non meta learning popular shot literature prototypical nets https let take cifar ignoring cifar fs set shot dataset split take classes split train val test methods also directly classify trainset support images pre training assuming number classes overall known beforehand validation support sets guess replace fc layer finally choosing pre trained model start seems absolutely necessary choose significantly different domain evaluation ex imagenet pre trained resnet evaluated cifar fs bad tldr seems like lot small differences experimental setups shot settings best way fair training evaluation also maybe totally missing something,people fair shot training evaluation,people fair shot training evaluationreading lot non meta learning popular shot literature prototypical nets https let take cifar ignoring cifar fs set shot dataset split take classes split train val test methods also directly classify trainset support images pre training assuming number classes overall known beforehand validation support sets guess replace fc layer finally choosing pre trained model start seems absolutely necessary choose significantly different domain evaluation ex imagenet pre trained resnet evaluated cifar fs bad tldr seems like lot small differences experimental setups shot settings best way fair training evaluation also maybe totally missing something,"['people', 'fair', 'shot', 'training', 'evaluationreading', 'lot', 'non', 'meta', 'learning', 'popular', 'shot', 'literature', 'prototypical', 'nets', 'https', 'let', 'take', 'cifar', 'ignoring', 'cifar', 'fs', 'set', 'shot', 'dataset', 'split', 'take', 'classes', 'split', 'train', 'val', 'test', 'methods', 'also', 'directly', 'classify', 'trainset', 'support', 'images', 'pre', 'training', 'assuming', 'number', 'classes', 'overall', 'known', 'beforehand', 'validation', 'support', 'sets', 'guess', 'replace', 'fc', 'layer', 'finally', 'choosing', 'pre', 'trained', 'model', 'start', 'seems', 'absolutely', 'necessary', 'choose', 'significantly', 'different', 'domain', 'evaluation', 'ex', 'imagenet', 'pre', 'trained', 'resnet', 'evaluated', 'cifar', 'fs', 'bad', 'tldr', 'seems', 'like', 'lot', 'small', 'differences', 'experimental', 'setups', 'shot', 'settings', 'best', 'way', 'fair', 'training', 'evaluation', 'also', 'maybe', 'totally', 'missing', 'something']","['peopl', 'fair', 'shot', 'train', 'evaluationread', 'lot', 'non', 'meta', 'learn', 'popular', 'shot', 'literatur', 'prototyp', 'net', 'http', 'let', 'take', 'cifar', 'ignor', 'cifar', 'fs', 'set', 'shot', 'dataset', 'split', 'take', 'class', 'split', 'train', 'val', 'test', 'method', 'also', 'directli', 'classifi', 'trainset', 'support', 'imag', 'pre', 'train', 'assum', 'number', 'class', 'overal', 'known', 'beforehand', 'valid', 'support', 'set', 'guess', 'replac', 'fc', 'layer', 'final', 'choos', 'pre', 'train', 'model', 'start', 'seem', 'absolut', 'necessari', 'choos', 'significantli', 'differ', 'domain', 'evalu', 'ex', 'imagenet', 'pre', 'train', 'resnet', 'evalu', 'cifar', 'fs', 'bad', 'tldr', 'seem', 'like', 'lot', 'small', 'differ', 'experiment', 'setup', 'shot', 'set', 'best', 'way', 'fair', 'train', 'evalu', 'also', 'mayb', 'total', 'miss', 'someth']"
225,247,247,MonLiH,vxo5nb,[N] BigScience Releases their 176 Billion Parameter Open-access Multilingual Language Model,"[BigScience](https://bigscience.huggingface.co/) recently released their new open-access (with weights) massive 176B language model that looks incredibly promising.The size is comparable to OpenAI's largest GPT-3 model. More info about the model can be found on [BigScience's blog](https://bigscience.huggingface.co/blog/bloom).

You can play with the model interactively, for free(!) on [Huggingface](https://huggingface.co/bigscience/bloom).",32,187,2022-07-13 02:00:03, n  bigscience releases their  billion parameter open access multilingual language model, bigscience  https you can play with the model interactively  for free    on  huggingface  https   huggingface co bigscience bloom  ,bigscience https play model interactively free huggingface https huggingface co bigscience bloom,n bigscience releases billion parameter open access multilingual language model,n bigscience releases billion parameter open access multilingual language modelbigscience https play model interactively free huggingface https huggingface co bigscience bloom,"['n', 'bigscience', 'releases', 'billion', 'parameter', 'open', 'access', 'multilingual', 'language', 'modelbigscience', 'https', 'play', 'model', 'interactively', 'free', 'huggingface', 'https', 'huggingface', 'co', 'bigscience', 'bloom']","['n', 'bigscienc', 'releas', 'billion', 'paramet', 'open', 'access', 'multilingu', 'languag', 'modelbigsci', 'http', 'play', 'model', 'interact', 'free', 'huggingfac', 'http', 'huggingfac', 'co', 'bigscienc', 'bloom']"
226,248,248,Petuum,vy92d1,[P] Build a Machine Translation System with Forte,"**TLDR:** This tutorial allows you to build a machine translation system with no glue code using Forte, an open source ML workflow builder.

&#x200B;

Forte makes it easy to compose any NLP pipeline, regardless of heterogeneity of data and processes, as a modular and easily editable system. It allows users to break down complex problems into composable pipelines and enables inter-operations across tasks through a unified data format.

This tutorial includes:

**1 — How to read data from source**

* How to create a simple NLP pipeline
* How to maintain and store the input data

**2 — How to process data in pipeline**

* How to perform sentence segmentation
* How to annotate and query the data
* How to translate the input text with a pre-trained model
* How to manage multiple data objects

**3 — How to handle new practical requests**

* How to handle structures like HTML data
* How to select a single data object for processing
* How to replace the translation model with remote translation services
* How to save and load the pipeline

Run the following command to install all the required dependencies for this tutorial:

    # It is recommended to install these in command line
    !pip install forte==0.2.0 forte.nltk requests# for certain environment, you may run into troubles installing transformers, such as requiring Rust
    some workaround here: https://github.com/huggingface/transformers/issues/2831#issuecomment-600141935 might help!pip install transformers==4.16.2
    you may want to try different pytorch version depending on your platform
    if you cannot install pytorch, try locate your problem at https://github.com/pytorch/pytorch/issues!pip install torch==1.11.0
    for certain environment, the installation may fail
    some workaround here: https://github.com/google/sentencepiece/issues/378#issuecomment-1145399969 might help!pip install sentencepiece

**1 — How to Read Data from Source**

**How to Create a Simple Pipeline: Start with the Reader**

In this section, you will learn:

* What is a reader and why we need it
* How to compose a simple pipeline with a pre-built reader

&#x200B;

    from forte import Pipeline

from forte.data.readers import TerminalReader pipeline: Pipeline = Pipeline()

All pipelines need a reader to read and parse input data. To make our pipeline read queries from the user’s command-line terminal, use the `TerminalReader` class provided by Forte.  `TerminalReader` transforms the user’s query into a DataPack object, which is a unified data format for NLP that makes it easy to connect different NLP tools together as Forte Processors.

    pipeline.set_reader(TerminalReader())

To run the pipeline consisting of the single `TerminalReader`, call `process_dataset` which will return an iterator of DataPack objects. The second line in the following code snippet retrieves the first user query from the TerminalReader.

    pipeline.initialize()
    datapack = next(pipeline.process_dataset())
    print(datapack.text)

**How to Maintain and Store Input Data: DataPack**

In this section, you will learn:

* What is a DataPack object and why we need it

Forte helps demystify data lineage and increase the traceability of how data flows along the pipeline and how features are generated to interface data to model. Similar to a cargo ship that loads and transports goods from one port to another, a data pack carries information when passing each module and updates the ontology states along the way.

https://preview.redd.it/a1ueowwsadb91.png?width=1400&format=png&auto=webp&s=44bf2986ef09f609986bcb5cecba12be1de7db06

DataPack and Multi-Modality:

DataPack not only supports text data but also audio and image data.

https://preview.redd.it/jko8w1ryadb91.png?width=1067&format=png&auto=webp&s=0963fa45d6630e1f1a2061da626034dd4d55b99b

**2— How to Process Data in Pipeline**

**How to Perform Sentence Segmentation: Add a Pre-Built Forte Processor to the Pipeline**

In this section, you will learn:

* What is a processor and why we need it
* How to add a pre-built processor to the pipeline

A Forte Processor takes DataPacks as inputs, processes them, and stores its outputs in DataPacks. The processors we are going to use in this section are all PackProcessors, which expect exactly one DataPack as input and store its outputs back into the same DataPack. The following two lines of code shows how a pre-built processor `NLTKSentenceSegmenter` is added to our pipeline.

    from fortex.nltk.nltk_processors import NLTKSentenceSegmenter
    pipeline.add(NLTKSentenceSegmenter())

When we run the pipeline, the `NLTKSentenceSegmenter` processor will split the user query into sentences and store them back to the DataPack created by TerminalReader. The code snippet below shows how to get all the sentences from the first query.

https://preview.redd.it/2cp4g1t5bdb91.png?width=1088&format=png&auto=webp&s=9c5851e77dffd3693a9fe5534e80319c7d489d90

    from ft.onto.base_ontology import Sentence
    pipeline.initialize()
    for sent in next(pipeline.process_dataset()).get(Sentence):
        print(sent.text)

**How to Annotate and Query the Data: Ontology**

In this section, you will learn:

* What is the ontology system and why we need it
* How to write a customized ontology and how to use it

`Sentence` is a pre-defined ontology provided by Forte and it is used by `NLTKSentenceSegmenter`to annotate each sentence in text. Forte is built on top of an Ontology system, which defines the relations between NLP annotations, for example, the relation between words and documents, or between two words. This is the core for Forte. The ontology can be specified via a JSON format. And tools are provided to convert the ontology into production code (Python).

https://preview.redd.it/ae6njzbabdb91.png?width=637&format=png&auto=webp&s=afd570ef358d209aca2b5fca3d395d8ba812daf8

We can also define customized ontologies:

    from dataclasses import dataclass
    from forte.data.ontology.top import Annotation
    from typing import Optional
    
    @dataclass
    class Article(Annotation):
    
        language: Optional[str]
    
        def __init__(self, pack, begin: int, end: int):
            super().__init__(pack, begin, end)

Below is a simple example showing how we can query sentences through the new ontology we just created:

    from forte.data import DataPack
    
    sentences = [
        ""Do you want to get better at making delicious BBQ?"",
        ""You will have the opportunity, put this on your calendar now."",
        ""Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers.""
    ]
    datapack: DataPack = DataPack()
    
    # Add sentences to the DataPack and annotate them
    for sentence in sentences:
        datapack.set_text(datapack.text + sentence)
        datapack.add_entry(
            Sentence(datapack, len(datapack.text) - len(sentence), len(datapack.text))
        )
        
    # Annotate the whole text with Article
    article: Article = Article(datapack, 0, len(datapack.text))
    article.language = ""en""
    datapack.add_entry(article)
    
    for article in datapack.get(Article):
        print(f""Article (language - {article.language}):"")
        for sentence in article.get(Sentence):
            print(sentence.text)

In our previous example, we have the following ontologies inheritance. Sentence and Article both inherit from Annotation which is used to represent text data. In Article, we have `language`field to represent the text language.

https://preview.redd.it/sts91nqgbdb91.png?width=901&format=png&auto=webp&s=426a1b8b2908ffabc57b0a888d6cff0ef92d5743

Actually, we not only support text ontology but also audio, image and link which represent relationships between two entries.

https://preview.redd.it/spp9etkibdb91.png?width=1074&format=png&auto=webp&s=cd8f8c4c7965fabf3fbac3ed5e4ba83a5259a848

`Annotation` is inherited by all text entries which usually has a span to retrieve partial text from the full text.

* `Article`, as shown in our previous example, inherits annotation and contains `language`field to differentiate English and German. In the single DataPack example, English article has a span of English text in the DataPack. Likewise, German article has a span of German text in the DataPack.
* `Sentence` in our example is used to break down article, and we pass sentences into MT pipeline.

`AudioAnnotation` is inherited by all audio entries which usually has an audio span to retrieve partial audio from the full audio.

* `Recording` is an example subclass of `AudioAnnotation`, and it has extra `recording_class`field denoting the classes the audio belongs to.

`ImageAnnotation` is inherited by all image entries which usually has payload index pointing to a loaded image array.

* `BoundingBox` is an example subclass of `ImageAnnotation`. As the picture shows, it has more inheritance relationships than other ontology classes due to the nature of CV objects. The advantage of Forte ontology is that it supports complex inheritance, and users can inherit from existing ontology and add new ontology features for their needs.

`Link` is inherited by all link-like entries which has parent and child.

* `RelationLink` is an example subclass of `Link`, and it has a class attribute specifying the relation type.

**How to Translate the Input Text with a Pre-Trained Model: Create a Machine Translation Processor**

In this section, you will learn:

* The basics of machine translation process
* How to wrap a pre-trained machine translation model into a Forte processor

Translation converts a sequence of text from one language to another. In this tutorial we will use `Huggingface` Transformer model to translate input data, which consists of several steps including subword tokenization, input embedding, model inference, decoding, etc.

https://preview.redd.it/2li5gn74cdb91.png?width=1400&format=png&auto=webp&s=c6b1a5f2770b62552bf7895d666bbc1168106262

In Forte, we have a generic class `PackProcessor` that wraps model and inference-related components and behaviors to process `DataPack`. Therefore, we need to create a class that inherits the generic method from `PackProcessor`. Then we have a class definition `class MachineTranslationProcessor(PackProcessor)`.

    from forte.data import DataPack
    from forte.data.readers import StringReader
    from forte.processors.base import PackProcessor
    from transformers import T5Tokenizer, T5ForConditionalGeneration
    class MachineTranslationProcessor(PackProcessor):
        """"""
        Translate the input text and output to a file.
        """"""
        def initialize(self, resources, configs):
            super().initialize(resources, configs)
            # Initialize the tokenizer and model
            model_name: str = self.configs.pretrained_model
            self.tokenizer = T5Tokenizer.from_pretrained(model_name)
            self.model = T5ForConditionalGeneration.from_pretrained(model_name)
            self.task_prefix = ""translate English to German: ""
            self.tokenizer.padding_side = ""left""
            self.tokenizer.pad_token = self.tokenizer.eos_token
        def _process(self, input_pack: DataPack):
            # en2de machine translation 
            inputs = self.tokenizer([
                self.task_prefix + sentence.text
                for sentence in input_pack.get(Sentence)
            ], return_tensors=""pt"", padding=True)
            output_sequences = self.model.generate(
                input_ids=inputs[""input_ids""],
                attention_mask=inputs[""attention_mask""],
                do_sample=False,
            )
            output = ''.join(self.tokenizer.batch_decode(
                output_sequences, skip_special_tokens=True
            ))
            src_article: Article = Article(input_pack, 0, len(input_pack.text))
            src_article.language = ""en""
            input_pack.set_text(input_pack.text + '\n\n' + output)
            tgt_article: Article = Article(input_pack, len(input_pack.text) - len(output), len(input_pack.text))
            tgt_article.language = ""de""
        @classmethod
        def default_configs(cls):
            return {
                ""pretrained_model"": ""t5-small""
            }

Initialization of needed components:

* Users need to consider initializing all needed NLP components for the inference task such as tokenizer and model.
* Users also need to specify all configuration in `configs`, a dictionary-like object that specifies configurations of all components such as model name.

MT operations on DataPack:

* After the initialization, we already have the needed NLP components. We need to consider several MT behaviors based on Forte DataPack.

Pre-process text data:

* Retrieve text data from DataPack (given that it already reads data from the data source).
* Since T5 has a better performance given a task prompt, we also want to include the prompt in our data.
* Tokenization that transforms input text into sequences of tokens and token ids.
* Generate output sequences from model.
* Decode output token ids into sentences using the tokenizer.

The generic method to process `DataPack` is `_process(self, input_pack: DataPack)`. It should tokenize the input text, use the model class to make an inference, decode the output token ids, and finally write the output to a target file.

Now we can add it into the pipeline and run the machine translation task.

    input_string: str = ' '.join(sentences)
    pipeline: Pipeline = Pipeline[DataPack]()
    pipeline.set_reader(StringReader())
    pipeline.add(NLTKSentenceSegmenter())
    pipeline.add(MachineTranslationProcessor())
    pipeline.initialize()
    for datapack in pipeline.process_dataset([input_string]):
        for article in datapack.get(Article):
            print([f""\nArticle (language - {article.language}): {article.text}""])

Ontology in DataPack:

Here we provide an illustration so that users can better understand the internal storage of DataPack. As we can see, text data, sentence and articles, are stored as span in `Annotations`. Their text data can be easily and efficiently retrieved by their spans.

https://preview.redd.it/hpbpp8xpcdb91.png?width=1096&format=png&auto=webp&s=ae11d14b87fa4fb54dd9988213218e956e67250e

**How to Manage Multiple Data Objects: MultiPack, A Better Way to Store Source and Target Text**

In this section, you will learn:

* What is a MultiPack and why we need it
* How to use a MultiPack

The above step outputs a DataPack which is good for holding data about one specific piece of text. A complicated pipeline like the one we are building now may need multiple DataPacks to be passed along the pipeline and this is where MultiPack can help. MultiPack manages a set of DataPacks that can be indexed by their names.

`MultiPackBoxer` is a simple Forte processor that converts a DataPack into a MultiPack by making it the only DataPack in there. A name can be specified via the config. We use it to wrap DataPack that contains source sentence.

https://preview.redd.it/jfoc0r9tcdb91.png?width=812&format=png&auto=webp&s=d0f7bd950e3f338ce0703419a57acb18d51463d8

    from forte.data import MultiPack
    from forte.processors.base import MultiPackProcessor
    from forte.data.caster import MultiPackBoxer
    class MachineTranslationMPProcessor(MultiPackProcessor):
        """"""
        Translate the input text and output to a file.
        """"""
        def initialize(self, resources, configs):
            super().initialize(resources, configs)
    
            # Initialize the tokenizer and model
            model_name: str = self.configs.pretrained_model
            self.tokenizer = T5Tokenizer.from_pretrained(model_name)
            self.model = T5ForConditionalGeneration.from_pretrained(model_name)
            self.task_prefix = ""translate English to German: ""
            self.tokenizer.padding_side = ""left""
            self.tokenizer.pad_token = self.tokenizer.eos_token
    
        def _process(self, input_pack: MultiPack):
            source_pack: DataPack = input_pack.get_pack(""source"")
            target_pack: DataPack = input_pack.add_pack(""target"")
    
            # en2de machine translation 
            inputs = self.tokenizer([
                self.task_prefix + sentence.text
                for sentence in source_pack.get(Sentence)
            ], return_tensors=""pt"", padding=True)
    
            output_sequences = self.model.generate(
                input_ids=inputs[""input_ids""],
                attention_mask=inputs[""attention_mask""],
                do_sample=False,
            )
            
            # Annotate the source article
            src_article: Article = Article(source_pack, 0, len(source_pack.text))
            src_article.language = ""en""
            
            # Annotate each sentence
            for output in self.tokenizer.batch_decode(
                output_sequences, skip_special_tokens=True
            ):
                target_pack.set_text(target_pack.text + output)
                text_length: int = len(target_pack.text)
                Sentence(target_pack, text_length - len(output), text_length)
            
            # Annotate the target article
            tgt_article: Article = Article(target_pack, 0, len(target_pack.text))
            tgt_article.language = ""de""
    
        @classmethod
        def default_configs(cls):
            return {
                ""pretrained_model"": ""t5-small"",
            }

Then `MachineTranslationMPProcessor` writes the output sentence into a target DataPack.

https://preview.redd.it/jci0neb3ddb91.png?width=978&format=png&auto=webp&s=fd26a16c151fcc1bfe578a0b4cc3dd69f98963c3

Now let’s try to create a new pipeline that utilizes `MultiPack` to manage text in different languages.

    nlp: Pipeline = Pipeline[DataPack]()
    nlp.set_reader(StringReader())
    nlp.add(NLTKSentenceSegmenter())
    nlp.add(MultiPackBoxer(), config={""pack_name"": ""source""})
    nlp.add(MachineTranslationMPProcessor(), config={
        ""pretrained_model"": ""t5-small""
    })
    nlp.initialize()
    for multipack in nlp.process_dataset([input_string]):
        for pack_name in (""source"", ""target""):
            for article in multipack.get_pack(pack_name).get(Article):
                print(f""\nArticle (language - {article.language}): "")
                for sentence in article.get(Sentence):
                    print(sentence.text)

Ontology in MultiPack:

For comparison, here is an illustration of the internal storage of MultiPack. We can see that MultiPack wraps one source DataPack and one target DataPack. Article spans are based on two separate DataPack text.

https://preview.redd.it/asqd43z8ddb91.png?width=1400&format=png&auto=webp&s=6587dd45173b5ed5f8379819179270c500f9ed9d

**3 — How to Handle New Practical Requests**

**How to Handle Structures like HTML Data**

In this section, you will learn

* How to build a translation management system
* How to preserve the structure like HTML in machine translation
* How to select a specific DataPack from MultiPack for processing

In the previous step, the input string is just a simple paragraph made up of several sentences. However, in many cases, we might need to handle data with structural information, such HTML or XML. When the input is a string of raw HTML data, the machine translation pipeline above may not work as expected:

    html_input: str = """"""
    <!DOCTYPE html>
    <html>
        <head><title>Beginners BBQ Class.</title></head>
        <body>
        <p>Do you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers.</p>
        </body>
    </html>
    """"""
    nlp.initialize()
    for multipack in nlp.process_dataset([html_input]):
        print(""Source Text: "" + multipack.get_pack(""source"").text)
        print(""\nTarget Text: "" + multipack.get_pack(""target"").text)

We can see that the original HTML structure is broken in the translated output.

In order to handle structured data like HTML, we will need to update our current design of pipeline. Luckily, Forte pipelines are highly modular, we can simply insert two new processors without updating the previous pipeline.

We first need a HTML cleaner to parse all the HTML tags from input string. Picture below shows the effect of tag remover.

https://preview.redd.it/ed6civbfddb91.png?width=1076&format=png&auto=webp&s=807ffb7f8ac1e9f13f071a50f867065e3038dd85

After the translation is finished, we will also need to recover the HTML structure from the unstructured translation output. Picture below shows replace one source sentence with one target sentence given the target sentence is ready.

https://preview.redd.it/wrs7aaxgddb91.png?width=968&format=png&auto=webp&s=34b31beba1791543b826b4aa6efcbae114f39bbe

    from forte.data import NameMatchSelector
    from forte.data.readers.html_reader import ForteHTMLParser
    class HTMLTagCleaner(MultiPackProcessor):
        
        def initialize(self, resources, configs):
            super().initialize(resources, configs)
            self._parser = ForteHTMLParser()
        def _process(self, input_pack: MultiPack):
            raw_pack: DataPack = input_pack.get_pack(""raw"")
            source_pack: DataPack = input_pack.add_pack(""source"")
            
            self._parser.feed(raw_pack.text)
            cleaned_text: str = raw_pack.text
            for span, _ in self._parser.spans:
                cleaned_text = cleaned_text.replace(
                    raw_pack.text[span.begin:span.end], ''
                )
            source_pack.set_text(cleaned_text)
            
    class HTMLTagRecovery(MultiPackProcessor):
        def _process(self, input_pack: MultiPack):
            raw_pack: DataPack = input_pack.get_pack(""raw"")
            source_pack: DataPack = input_pack.get_pack(""source"")
            target_pack: DataPack = input_pack.get_pack(""target"")
            result_pack: DataPack = input_pack.add_pack(""result"")
            result_text: str = raw_pack.text
            for sent_src, sent_tgt in zip(source_pack.get(Sentence), target_pack.get(Sentence)):
                result_text = result_text.replace(sent_src.text, sent_tgt.text)
            result_pack.set_text(result_text)

Now we are able to create a translation management system by inserting the two processors introduced above into our previous machine translation pipeline.

    # Pipeline with HTML handling
    pipeline: Pipeline = Pipeline[DataPack]()
    pipeline.set_reader(StringReader())
    pipeline.add(MultiPackBoxer(), config={""pack_name"": ""raw""})
    pipeline.add(HTMLTagCleaner())
    pipeline.add(
        NLTKSentenceSegmenter(),
        selector=NameMatchSelector(),
        selector_config={""select_name"": ""source""}
    )
    pipeline.add(MachineTranslationMPProcessor(), config={
        ""pretrained_model"": ""t5-small""
    })
    pipeline.add(HTMLTagRecovery())
    pipeline.initialize()
    for multipack in pipeline.process_dataset([html_input]):
        print(multipack.get_pack(""raw"").text)
        print(multipack.get_pack(""result"").text)

Selector:

In the code snippet above, we utilize a `NameMatchSelector` to select one specific DataPack from the MultiPack based on its reference name `select_name`. This allows `NLTKSentenceSegmenter` to process only the specified DataPack.

**How to Replace the Translation Model with Remote Translation Services: Replace our MT Model with Online Translation API**

In this section, you will learn:

* How to use a different translation service

Forte also allows us to update the translation model and integrate it seamlessly to the original pipeline. For example, if we want to offload the translation task to an online service, all we need to do is to update the translation processor. There is no need to change other components in the pipeline.

    # You can get your own API key by following the instructions in https://docs.microsoft.com/en-us/azure/cognitive-services/translator/
    api_key = input(""Enter your API key here:"")
    import requests
    import uuid
    class OnlineMachineTranslationMPProcessor(MultiPackProcessor):
        """"""
        Translate the input text and output to a file use online translator api.
        """"""
        def initialize(self, resources, configs):
            super().initialize(resources, configs)
            self.url = configs.endpoint + configs.path
            self.from_lang = configs.from_lang
            self.to_lang = configs.to_lang
            self.subscription_key = configs.subscription_key
            self.subscription_region = configs.subscription_region
        def _process(self, input_pack: MultiPack):
            source_pack: DataPack = input_pack.get_pack(""source"")
            target_pack: DataPack = input_pack.add_pack(""target"")
            
            params = {
                'api-version': '3.0',
                'from': 'en',
                'to': ['de']
            }
            # Build request
            headers = {
                'Ocp-Apim-Subscription-Key': self.subscription_key,
                'Ocp-Apim-Subscription-Region': self.subscription_region,
                'Content-type': 'application/json',
                'X-ClientTraceId': str(uuid.uuid4())
            }
            # You can pass more than one object in body.
            body = [{
                'text': source_pack.text
            }]
            request = requests.post(self.url, params=params, headers=headers, json=body)
            
            result = request.json()
            target_pack.set_text("""".join(
                [trans['text'] for trans in result[0][""translations""]]
                 )
            )
        @classmethod
        def default_configs(cls):
            return {
                ""from_lang"" : 'en',
                ""to_lang"":  'de',
                ""endpoint"" : 'https://api.cognitive.microsofttranslator.com/',
                ""path"" : '/translate',
                ""subscription_key"": None,
                ""subscription_region"" : ""westus2"",
                'X-ClientTraceId': str(uuid.uuid4())
            }
    nlp: Pipeline = Pipeline[DataPack]()
    nlp.set_reader(StringReader())
    nlp.add(NLTKSentenceSegmenter())
    nlp.add(MultiPackBoxer(), config={""pack_name"": ""source""})
    nlp.add(OnlineMachineTranslationMPProcessor(), config={
        ""from_lang"" : 'en',
        ""to_lang"":  'de',
        ""endpoint"" : 'https://api.cognitive.microsofttranslator.com/',
        ""path"" : '/translate',
        ""subscription_key"": api_key,
        ""subscription_region"" : ""westus2"",
        'X-ClientTraceId': str(uuid.uuid4())
    })
    nlp.initialize()
    for multipack in nlp.process_dataset([input_string]):
        print(""Source Text: "" + multipack.get_pack(""source"").text)
        print(""\nTarget Text: "" + multipack.get_pack(""target"").text)

**How to Save and Load the Pipeline: Save the Whole Pipeline with save()**

In this section, you will learn

* How to export and import a Forte pipeline

Forte also allow us to save the pipeline into disk. It serializes the whole pipeline and generates an intermediate representation, which can be loaded later maybe on a different machine.

    import os
    save_path: str = os.path.join(os.path.dirname(os.path.abspath('')), ""pipeline.yml"")
    nlp.save(save_path)
    with open(save_path, 'r') as f:
        print(f.read())

Now that the pipeline is saved, we can try to re-load the pipeline to see if it still functions as expected.

    new_nlp: Pipeline = Pipeline()
    new_nlp.init_from_config_path(save_path)
    new_nlp.initialize()
    for multipack in new_nlp.process_dataset([input_string]):
        print(""Source Text: "" + multipack.get_pack(""source"").text)
        print(""\nTarget Text: "" + multipack.get_pack(""target"").text)

Now you can build a machine translation system with Forte!",1,3,2022-07-13 20:38:01, p  build a machine translation system with forte,  tldr    this tutorial allows you to build a machine translation system with no glue code using forte  an open source ml workflow builder   xb forte makes it easy to compose any nlp pipeline  regardless of heterogeneity of data and processes  as a modular and easily editable system  it allows users to break down complex problems into composable pipelines and enables inter operations across tasks through a unified data format this tutorial includes      how to read data from source    how to create a simple nlp pipeline  how to maintain and store the input data     how to process data in pipeline    how to perform sentence segmentation  how to annotate and query the data  how to translate the input text with a pre trained model  how to manage multiple data objects     how to handle new practical requests    how to handle structures like html data  how to select a single data object for processing  how to replace the translation model with remote translation services  how to save and load the pipelinerun the following command to install all the required dependencies for this tutorial       it is recommended to install these in command line     pip install forte     forte nltk requests  for certain environment  you may run into troubles installing transformers  such as requiring rust    some workaround here  https     you may want to try different pytorch version depending on your platform    if you cannot install pytorch  try locate your problem at https     for certain environment  the installation may fail    some workaround here  https      how to read data from source    how to create a simple pipeline  start with the reader  in this section  you will learn   what is a reader and why we need it  how to compose a simple pipeline with a pre built reader  xb     from forte import pipelinefrom forte data readers import terminalreader pipeline  pipeline   pipeline  all pipelines need a reader to read and parse input data  to make our pipeline read queries from the user s command line terminal  use the  terminalreader  class provided by forte    terminalreader  transforms the user s query into a datapack object  which is a unified data format for nlp that makes it easy to connect different nlp tools together as forte processors     pipeline set_reader terminalreader   to run the pipeline consisting of the single  terminalreader   call  process_dataset  which will return an iterator of datapack objects  the second line in the following code snippet retrieves the first user query from the terminalreader     pipeline initialize      datapack   next pipeline process_dataset       print datapack text   how to maintain and store input data  datapack  in this section  you will learn   what is a datapack object and why we need itforte helps demystify data lineage and increase the traceability of how data flows along the pipeline and how features are generated to interface data to model  similar to a cargo ship that loads and transports goods from one port to another  a data pack carries information when passing each module and updates the ontology states along the way https datapack and multi modality datapack not only supports text data but also audio and image data https     how to process data in pipeline    how to perform sentence segmentation  add a pre built forte processor to the pipeline  in this section  you will learn   what is a processor and why we need it  how to add a pre built processor to the pipelinea forte processor takes datapacks as inputs  processes them  and stores its outputs in datapacks  the processors we are going to use in this section are all packprocessors  which expect exactly one datapack as input and store its outputs back into the same datapack  the following two lines of code shows how a pre built processor  nltksentencesegmenter  is added to our pipeline     from fortex nltk nltk_processors import nltksentencesegmenter    pipeline add nltksentencesegmenter   when we run the pipeline  the  nltksentencesegmenter  processor will split the user query into sentences and store them back to the datapack created by terminalreader  the code snippet below shows how to get all the sentences from the first query https     from ft onto base_ontology import sentence    pipeline initialize      for sent in next pipeline process_dataset    get sentence          print sent text   how to annotate and query the data  ontology  in this section  you will learn   what is the ontology system and why we need it  how to write a customized ontology and how to use it sentence  is a pre defined ontology provided by forte and it is used by  nltksentencesegmenter to annotate each sentence in text  forte is built on top of an ontology system  which defines the relations between nlp annotations  for example  the relation between words and documents  or between two words  this is the core for forte  the ontology can be specified via a json format  and tools are provided to convert the ontology into production code  python  https we can also define customized ontologies     from dataclasses import dataclass    from forte data ontology top import annotation    from typing import optional         dataclass    class article annotation              language  optional str             def __init__ self  pack  begin  int  end  int              super   __init__ pack  begin  end below is a simple example showing how we can query sentences through the new ontology we just created     from forte data import datapack        sentences            do you want to get better at making delicious bbq          you will have the opportunity  put this on your calendar now          thursday  september nd join world class bbq champion  tony balay from lonestar smoke rangers          datapack  datapack   datapack            add sentences to the datapack and annotate them    for sentence in sentences         datapack set_text datapack text   sentence         datapack add_entry             sentence datapack  len datapack text    len sentence   len datapack text                         annotate the whole text with article    article  article   article datapack    len datapack text      article language   en    datapack add_entry article         for article in datapack get article          print farticle  language    article language            for sentence in article get sentence              print sentence text in our previous example  we have the following ontologies inheritance  sentence and article both inherit from annotation which is used to represent text data  in article  we have  language field to represent the text language https actually  we not only support text ontology but also audio  image and link which represent relationships between two entries https  annotation  is inherited by all text entries which usually has a span to retrieve partial text from the full text    article   as shown in our previous example  inherits annotation and contains  language field to differentiate english and german  in the single datapack example  english article has a span of english text in the datapack  likewise  german article has a span of german text in the datapack    sentence  in our example is used to break down article  and we pass sentences into mt pipeline  audioannotation  is inherited by all audio entries which usually has an audio span to retrieve partial audio from the full audio    recording  is an example subclass of  audioannotation   and it has extra  recording_class field denoting the classes the audio belongs to  imageannotation  is inherited by all image entries which usually has payload index pointing to a loaded image array    boundingbox  is an example subclass of  imageannotation   as the picture shows  it has more inheritance relationships than other ontology classes due to the nature of cv objects  the advantage of forte ontology is that it supports complex inheritance  and users can inherit from existing ontology and add new ontology features for their needs  link  is inherited by all link like entries which has parent and child    relationlink  is an example subclass of  link   and it has a class attribute specifying the relation type   how to translate the input text with a pre trained model  create a machine translation processor  in this section  you will learn   the basics of machine translation process  how to wrap a pre trained machine translation model into a forte processortranslation converts a sequence of text from one language to another  in this tutorial we will use  huggingface  transformer model to translate input data  which consists of several steps including subword tokenization  input embedding  model inference  decoding  etc https in forte  we have a generic class  packprocessor  that wraps model and inference related components and behaviors to process  datapack   therefore  we need to create a class that inherits the generic method from  packprocessor   then we have a class definition  class machinetranslationprocessor packprocessor       from forte data import datapack    from forte data readers import stringreader    from forte processors base import packprocessor    from transformers import ttokenizer  tforconditionalgeneration    class machinetranslationprocessor packprocessor                  translate the input text and output to a file                 def initialize self  resources  configs              super   initialize resources  configs               initialize the tokenizer and model            model_name  str   self configs pretrained_model            self tokenizer   ttokenizer from_pretrained model_name             self model   tforconditionalgeneration from_pretrained model_name             self task_prefix   translate english to german              self tokenizer padding_side   left            self tokenizer pad_token   self tokenizer eos_token        def _process self  input_pack  datapack                ende machine translation             inputs   self tokenizer                  self task_prefix   sentence text                for sentence in input_pack get sentence                return_tensors pt  padding true             output_sequences   self model generate                 input_ids inputs input_ids                  attention_mask inputs attention_mask                  do_sample false                          output      join self tokenizer batch_decode                 output_sequences  skip_special_tokens true                          src_article  article   article input_pack    len input_pack text              src_article language   en            input_pack set_text input_pack text     n n    output             tgt_article  article   article input_pack  len input_pack text    len output   len input_pack text              tgt_article language   de         classmethod        def default_configs cls              return                  pretrained_model  t small             initialization of needed components   users need to consider initializing all needed nlp components for the inference task such as tokenizer and model   users also need to specify all configuration in  configs   a dictionary like object that specifies configurations of all components such as model name mt operations on datapack   after the initialization  we already have the needed nlp components  we need to consider several mt behaviors based on forte datapack pre process text data   retrieve text data from datapack  given that it already reads data from the data source    since t has a better performance given a task prompt  we also want to include the prompt in our data   tokenization that transforms input text into sequences of tokens and token ids   generate output sequences from model   decode output token ids into sentences using the tokenizer the generic method to process  datapack  is  _process self  input_pack  datapack    it should tokenize the input text  use the model class to make an inference  decode the output token ids  and finally write the output to a target file now we can add it into the pipeline and run the machine translation task     input_string  str       join sentences     pipeline  pipeline   pipeline datapack       pipeline set_reader stringreader       pipeline add nltksentencesegmenter       pipeline add machinetranslationprocessor       pipeline initialize      for datapack in pipeline process_dataset  input_string           for article in datapack get article              print  f narticle  language    article language     article text   ontology in datapack here we provide an illustration so that users can better understand the internal storage of datapack  as we can see  text data  sentence and articles  are stored as span in  annotations   their text data can be easily and efficiently retrieved by their spans https   how to manage multiple data objects  multipack  a better way to store source and target text  in this section  you will learn   what is a multipack and why we need it  how to use a multipackthe above step outputs a datapack which is good for holding data about one specific piece of text  a complicated pipeline like the one we are building now may need multiple datapacks to be passed along the pipeline and this is where multipack can help  multipack manages a set of datapacks that can be indexed by their names  multipackboxer  is a simple forte processor that converts a datapack into a multipack by making it the only datapack in there  a name can be specified via the config  we use it to wrap datapack that contains source sentence https     from forte data import multipack    from forte processors base import multipackprocessor    from forte data caster import multipackboxer    class machinetranslationmpprocessor multipackprocessor                  translate the input text and output to a file                 def initialize self  resources  configs              super   initialize resources  configs                   initialize the tokenizer and model            model_name  str   self configs pretrained_model            self tokenizer   ttokenizer from_pretrained model_name             self model   tforconditionalgeneration from_pretrained model_name             self task_prefix   translate english to german              self tokenizer padding_side   left            self tokenizer pad_token   self tokenizer eos_token            def _process self  input_pack  multipack              source_pack  datapack   input_pack get_pack source             target_pack  datapack   input_pack add_pack target                   ende machine translation             inputs   self tokenizer                  self task_prefix   sentence text                for sentence in source_pack get sentence                return_tensors pt  padding true                 output_sequences   self model generate                 input_ids inputs input_ids                  attention_mask inputs attention_mask                  do_sample false                                        annotate the source article            src_article  article   article source_pack    len source_pack text              src_article language   en                          annotate each sentence            for output in self tokenizer batch_decode                 output_sequences  skip_special_tokens true                              target_pack set_text target_pack text   output                 text_length  int   len target_pack text                 sentence target_pack  text_length   len output   text_length                           annotate the target article            tgt_article  article   article target_pack    len target_pack text              tgt_article language   de             classmethod        def default_configs cls              return                  pretrained_model  t small              then  machinetranslationmpprocessor  writes the output sentence into a target datapack https now let s try to create a new pipeline that utilizes  multipack  to manage text in different languages     nlp  pipeline   pipeline datapack       nlp set_reader stringreader       nlp add nltksentencesegmenter       nlp add multipackboxer    config  pack_name  source      nlp add machinetranslationmpprocessor    config          pretrained_model  t small          nlp initialize      for multipack in nlp process_dataset  input_string           for pack_name in  source  target              for article in multipack get_pack pack_name  get article                  print f narticle  language    article language                     for sentence in article get sentence                      print sentence text ontology in multipack for comparison  here is an illustration of the internal storage of multipack  we can see that multipack wraps one source datapack and one target datapack  article spans are based on two separate datapack text https      how to handle new practical requests    how to handle structures like html data  in this section  you will learn  how to build a translation management system  how to preserve the structure like html in machine translation  how to select a specific datapack from multipack for processingin the previous step  the input string is just a simple paragraph made up of several sentences  however  in many cases  we might need to handle data with structural information  such html or xml  when the input is a string of raw html data  the machine translation pipeline above may not work as expected     html_input  str                   beginners bbq class                 do you want to get better at making delicious bbq  you will have the opportunity  put this on your calendar now  thursday  september nd join world class bbq champion  tony balay from lonestar smoke rangers                     nlp initialize      for multipack in nlp process_dataset  html_input           print source text     multipack get_pack source  text         print  ntarget text     multipack get_pack target  text we can see that the original html structure is broken in the translated output in order to handle structured data like html  we will need to update our current design of pipeline  luckily  forte pipelines are highly modular  we can simply insert two new processors without updating the previous pipeline we first need a html cleaner to parse all the html tags from input string  picture below shows the effect of tag remover https after the translation is finished  we will also need to recover the html structure from the unstructured translation output  picture below shows replace one source sentence with one target sentence given the target sentence is ready https     from forte data import namematchselector    from forte data readers html_reader import fortehtmlparser    class htmltagcleaner multipackprocessor                  def initialize self  resources  configs              super   initialize resources  configs             self _parser   fortehtmlparser          def _process self  input_pack  multipack              raw_pack  datapack   input_pack get_pack raw             source_pack  datapack   input_pack add_pack source                         self _parser feed raw_pack text             cleaned_text  str   raw_pack text            for span  _ in self _parser spans                 cleaned_text   cleaned_text replace                     raw_pack text span begin span end                                  source_pack set_text cleaned_text                 class htmltagrecovery multipackprocessor          def _process self  input_pack  multipack              raw_pack  datapack   input_pack get_pack raw             source_pack  datapack   input_pack get_pack source             target_pack  datapack   input_pack get_pack target             result_pack  datapack   input_pack add_pack result             result_text  str   raw_pack text            for sent_src  sent_tgt in zip source_pack get sentence   target_pack get sentence                   result_text   result_text replace sent_src text  sent_tgt text             result_pack set_text result_text now we are able to create a translation management system by inserting the two processors introduced above into our previous machine translation pipeline       pipeline with html handling    pipeline  pipeline   pipeline datapack       pipeline set_reader stringreader       pipeline add multipackboxer    config  pack_name  raw      pipeline add htmltagcleaner       pipeline add         nltksentencesegmenter           selector namematchselector           selector_config  select_name  source          pipeline add machinetranslationmpprocessor    config          pretrained_model  t small          pipeline add htmltagrecovery       pipeline initialize      for multipack in pipeline process_dataset  html_input           print multipack get_pack raw  text         print multipack get_pack result  text selector in the code snippet above  we utilize a  namematchselector  to select one specific datapack from the multipack based on its reference name  select_name   this allows  nltksentencesegmenter  to process only the specified datapack   how to replace the translation model with remote translation services  replace our mt model with online translation api  in this section  you will learn   how to use a different translation serviceforte also allows us to update the translation model and integrate it seamlessly to the original pipeline  for example  if we want to offload the translation task to an online service  all we need to do is to update the translation processor  there is no need to change other components in the pipeline       you can get your own api key by following the instructions in https     api_key   input enter your api key here      import requests    import uuid    class onlinemachinetranslationmpprocessor multipackprocessor                  translate the input text and output to a file use online translator api                 def initialize self  resources  configs              super   initialize resources  configs             self url   configs endpoint   configs path            self from_lang   configs from_lang            self to_lang   configs to_lang            self subscription_key   configs subscription_key            self subscription_region   configs subscription_region        def _process self  input_pack  multipack              source_pack  datapack   input_pack get_pack source             target_pack  datapack   input_pack add_pack target                         params                     api version                        from    en                   to     de                             build request            headers                     ocp apim subscription key   self subscription_key                  ocp apim subscription region   self subscription_region                  content type    application json                   x clienttraceid   str uuid uuid                              you can pass more than one object in body             body                      text   source_pack text                          request   requests post self url  params params  headers headers  json body                         result   request json              target_pack set_text  join                  trans  text   for trans in result   translations                                          classmethod        def default_configs cls              return                  from_lang    en                  to_lang    de                  endpoint    https                 path     translate                  subscription_key  none                 subscription_region   westus                  x clienttraceid   str uuid uuid                    nlp  pipeline   pipeline datapack       nlp set_reader stringreader       nlp add nltksentencesegmenter       nlp add multipackboxer    config  pack_name  source      nlp add onlinemachinetranslationmpprocessor    config          from_lang    en          to_lang    de          endpoint    https         path     translate          subscription_key  api_key         subscription_region   westus          x clienttraceid   str uuid uuid             nlp initialize      for multipack in nlp process_dataset  input_string           print source text     multipack get_pack source  text         print  ntarget text     multipack get_pack target  text   how to save and load the pipeline  save the whole pipeline with save    in this section  you will learn  how to export and import a forte pipelineforte also allow us to save the pipeline into disk  it serializes the whole pipeline and generates an intermediate representation  which can be loaded later maybe on a different machine     import os    save_path  str   os path join os path dirname os path abspath       pipeline yml     nlp save save_path     with open save_path   r   as f         print f read   now that the pipeline is saved  we can try to re load the pipeline to see if it still functions as expected     new_nlp  pipeline   pipeline      new_nlp init_from_config_path save_path     new_nlp initialize      for multipack in new_nlp process_dataset  input_string           print source text     multipack get_pack source  text         print  ntarget text     multipack get_pack target  text now you can build a machine translation system with forte ,tldr tutorial allows build machine translation system glue code using forte open source ml workflow builder xb forte makes easy compose nlp pipeline regardless heterogeneity data processes modular easily editable system allows users break complex problems composable pipelines enables inter operations across tasks unified data format tutorial includes read data source create simple nlp pipeline maintain store input data process data pipeline perform sentence segmentation annotate query data translate input text pre trained model manage multiple data objects handle practical requests handle structures like html data select single data object processing replace translation model remote translation services save load pipelinerun following command install required dependencies tutorial recommended install command line pip install forte forte nltk requests certain environment may run troubles installing transformers requiring rust workaround https may want try different pytorch version depending platform cannot install pytorch try locate problem https certain environment installation may fail workaround https read data source create simple pipeline start reader section learn reader need compose simple pipeline pre built reader xb forte import pipelinefrom forte data readers import terminalreader pipeline pipeline pipeline pipelines need reader read parse input data make pipeline read queries user command line terminal use terminalreader class provided forte terminalreader transforms user query datapack object unified data format nlp makes easy connect different nlp tools together forte processors pipeline set_reader terminalreader run pipeline consisting single terminalreader call process_dataset return iterator datapack objects second line following code snippet retrieves first user query terminalreader pipeline initialize datapack next pipeline process_dataset print datapack text maintain store input data datapack section learn datapack object need itforte helps demystify data lineage increase traceability data flows along pipeline features generated interface data model similar cargo ship loads transports goods one port another data pack carries information passing module updates ontology states along way https datapack multi modality datapack supports text data also audio image data https process data pipeline perform sentence segmentation pre built forte processor pipeline section learn processor need pre built processor pipelinea forte processor takes datapacks inputs processes stores outputs datapacks processors going use section packprocessors expect exactly one datapack input store outputs back datapack following two lines code shows pre built processor nltksentencesegmenter added pipeline fortex nltk nltk_processors import nltksentencesegmenter pipeline nltksentencesegmenter run pipeline nltksentencesegmenter processor split user query sentences store back datapack created terminalreader code snippet shows get sentences first query https ft onto base_ontology import sentence pipeline initialize sent next pipeline process_dataset get sentence print sent text annotate query data ontology section learn ontology system need write customized ontology use sentence pre defined ontology provided forte used nltksentencesegmenter annotate sentence text forte built top ontology system defines relations nlp annotations example relation documents two core forte ontology specified via json format tools provided convert ontology production code python https also define customized ontologies dataclasses import dataclass forte data ontology top import annotation typing import optional dataclass class article annotation language optional str def __init__ self pack begin int end int super __init__ pack begin end simple example showing query sentences ontology created forte data import datapack sentences want get better making delicious bbq opportunity put calendar thursday september nd join world class bbq champion tony balay lonestar smoke rangers datapack datapack datapack sentences datapack annotate sentence sentences datapack set_text datapack text sentence datapack add_entry sentence datapack len datapack text len sentence len datapack text annotate whole text article article article article datapack len datapack text article language en datapack add_entry article article datapack get article print farticle language article language sentence article get sentence print sentence text previous example following ontologies inheritance sentence article inherit annotation used represent text data article language field represent text language https actually support text ontology also audio image link represent relationships two entries https annotation inherited text entries usually span retrieve partial text full text article shown previous example inherits annotation contains language field differentiate english german single datapack example english article span english text datapack likewise german article span german text datapack sentence example used break article pass sentences mt pipeline audioannotation inherited audio entries usually audio span retrieve partial audio full audio recording example subclass audioannotation extra recording_class field denoting classes audio belongs imageannotation inherited image entries usually payload index pointing loaded image array boundingbox example subclass imageannotation picture shows inheritance relationships ontology classes due nature cv objects advantage forte ontology supports complex inheritance users inherit existing ontology ontology features needs link inherited link like entries parent child relationlink example subclass link class attribute specifying relation type translate input text pre trained model create machine translation processor section learn basics machine translation process wrap pre trained machine translation model forte processortranslation converts sequence text one language another tutorial use huggingface transformer model translate input data consists several steps including subword tokenization input embedding model inference decoding etc https forte generic class packprocessor wraps model inference related components behaviors process datapack therefore need create class inherits generic method packprocessor class definition class machinetranslationprocessor packprocessor forte data import datapack forte data readers import stringreader forte processors base import packprocessor transformers import ttokenizer tforconditionalgeneration class machinetranslationprocessor packprocessor translate input text output file def initialize self resources configs super initialize resources configs initialize tokenizer model model_name str self configs pretrained_model self tokenizer ttokenizer from_pretrained model_name self model tforconditionalgeneration from_pretrained model_name self task_prefix translate english german self tokenizer padding_side left self tokenizer pad_token self tokenizer eos_token def _process self input_pack datapack ende machine translation inputs self tokenizer self task_prefix sentence text sentence input_pack get sentence return_tensors pt padding true output_sequences self model generate input_ids inputs input_ids attention_mask inputs attention_mask do_sample false output join self tokenizer batch_decode output_sequences skip_special_tokens true src_article article article input_pack len input_pack text src_article language en input_pack set_text input_pack text n n output tgt_article article article input_pack len input_pack text len output len input_pack text tgt_article language de classmethod def default_configs cls return pretrained_model small initialization needed components users need consider initializing needed nlp components inference task tokenizer model users also need specify configuration configs dictionary like object specifies configurations components model name mt operations datapack initialization already needed nlp components need consider several mt behaviors based forte datapack pre process text data retrieve text data datapack given already reads data data source since better performance given task prompt also want include prompt data tokenization transforms input text sequences tokens token ids generate output sequences model decode output token ids sentences using tokenizer generic method process datapack _process self input_pack datapack tokenize input text use model class make inference decode output token ids finally write output target file pipeline run machine translation task input_string str join sentences pipeline pipeline pipeline datapack pipeline set_reader stringreader pipeline nltksentencesegmenter pipeline machinetranslationprocessor pipeline initialize datapack pipeline process_dataset input_string article datapack get article print f narticle language article language article text ontology datapack provide illustration users better understand internal storage datapack see text data sentence articles stored span annotations text data easily efficiently retrieved spans https manage multiple data objects multipack better way store source target text section learn multipack need use multipackthe step outputs datapack good holding data one specific piece text complicated pipeline like one building may need multiple datapacks passed along pipeline multipack help multipack manages set datapacks indexed names multipackboxer simple forte processor converts datapack multipack making datapack name specified via config use wrap datapack contains source sentence https forte data import multipack forte processors base import multipackprocessor forte data caster import multipackboxer class machinetranslationmpprocessor multipackprocessor translate input text output file def initialize self resources configs super initialize resources configs initialize tokenizer model model_name str self configs pretrained_model self tokenizer ttokenizer from_pretrained model_name self model tforconditionalgeneration from_pretrained model_name self task_prefix translate english german self tokenizer padding_side left self tokenizer pad_token self tokenizer eos_token def _process self input_pack multipack source_pack datapack input_pack get_pack source target_pack datapack input_pack add_pack target ende machine translation inputs self tokenizer self task_prefix sentence text sentence source_pack get sentence return_tensors pt padding true output_sequences self model generate input_ids inputs input_ids attention_mask inputs attention_mask do_sample false annotate source article src_article article article source_pack len source_pack text src_article language en annotate sentence output self tokenizer batch_decode output_sequences skip_special_tokens true target_pack set_text target_pack text output text_length int len target_pack text sentence target_pack text_length len output text_length annotate target article tgt_article article article target_pack len target_pack text tgt_article language de classmethod def default_configs cls return pretrained_model small machinetranslationmpprocessor writes output sentence target datapack https let try create pipeline utilizes multipack manage text different languages nlp pipeline pipeline datapack nlp set_reader stringreader nlp nltksentencesegmenter nlp multipackboxer config pack_name source nlp machinetranslationmpprocessor config pretrained_model small nlp initialize multipack nlp process_dataset input_string pack_name source target article multipack get_pack pack_name get article print f narticle language article language sentence article get sentence print sentence text ontology multipack comparison illustration internal storage multipack see multipack wraps one source datapack one target datapack article spans based two separate datapack text https handle practical requests handle structures like html data section learn build translation management system preserve structure like html machine translation select specific datapack multipack processingin previous step input string simple paragraph made several sentences however many cases might need handle data structural information html xml input string raw html data machine translation pipeline may work expected html_input str beginners bbq class want get better making delicious bbq opportunity put calendar thursday september nd join world class bbq champion tony balay lonestar smoke rangers nlp initialize multipack nlp process_dataset html_input print source text multipack get_pack source text print ntarget text multipack get_pack target text see original html structure broken translated output order handle structured data like html need update current design pipeline luckily forte pipelines highly modular simply insert two processors without updating previous pipeline first need html cleaner parse html tags input string picture shows effect tag remover https translation finished also need recover html structure unstructured translation output picture shows replace one source sentence one target sentence given target sentence ready https forte data import namematchselector forte data readers html_reader import fortehtmlparser class htmltagcleaner multipackprocessor def initialize self resources configs super initialize resources configs self _parser fortehtmlparser def _process self input_pack multipack raw_pack datapack input_pack get_pack raw source_pack datapack input_pack add_pack source self _parser feed raw_pack text cleaned_text str raw_pack text span _ self _parser spans cleaned_text cleaned_text replace raw_pack text span begin span end source_pack set_text cleaned_text class htmltagrecovery multipackprocessor def _process self input_pack multipack raw_pack datapack input_pack get_pack raw source_pack datapack input_pack get_pack source target_pack datapack input_pack get_pack target result_pack datapack input_pack add_pack result result_text str raw_pack text sent_src sent_tgt zip source_pack get sentence target_pack get sentence result_text result_text replace sent_src text sent_tgt text result_pack set_text result_text able create translation management system inserting two processors introduced previous machine translation pipeline pipeline html handling pipeline pipeline pipeline datapack pipeline set_reader stringreader pipeline multipackboxer config pack_name raw pipeline htmltagcleaner pipeline nltksentencesegmenter selector namematchselector selector_config select_name source pipeline machinetranslationmpprocessor config pretrained_model small pipeline htmltagrecovery pipeline initialize multipack pipeline process_dataset html_input print multipack get_pack raw text print multipack get_pack result text selector code snippet utilize namematchselector select one specific datapack multipack based reference name select_name allows nltksentencesegmenter process specified datapack replace translation model remote translation services replace mt model online translation api section learn use different translation serviceforte also allows us update translation model integrate seamlessly original pipeline example want offload translation task online service need update translation processor need change components pipeline get api key following instructions https api_key input enter api key import requests import uuid class onlinemachinetranslationmpprocessor multipackprocessor translate input text output file use online translator api def initialize self resources configs super initialize resources configs self url configs endpoint configs path self from_lang configs from_lang self to_lang configs to_lang self subscription_key configs subscription_key self subscription_region configs subscription_region def _process self input_pack multipack source_pack datapack input_pack get_pack source target_pack datapack input_pack add_pack target params api version en de build request headers ocp apim subscription key self subscription_key ocp apim subscription region self subscription_region content type application json x clienttraceid str uuid uuid pass one object body body text source_pack text request requests post self url params params headers headers json body result request json target_pack set_text join trans text trans result translations classmethod def default_configs cls return from_lang en to_lang de endpoint https path translate subscription_key none subscription_region westus x clienttraceid str uuid uuid nlp pipeline pipeline datapack nlp set_reader stringreader nlp nltksentencesegmenter nlp multipackboxer config pack_name source nlp onlinemachinetranslationmpprocessor config from_lang en to_lang de endpoint https path translate subscription_key api_key subscription_region westus x clienttraceid str uuid uuid nlp initialize multipack nlp process_dataset input_string print source text multipack get_pack source text print ntarget text multipack get_pack target text save load pipeline save whole pipeline save section learn export import forte pipelineforte also allow us save pipeline disk serializes whole pipeline generates intermediate representation loaded later maybe different machine import os save_path str os path join os path dirname os path abspath pipeline yml nlp save save_path open save_path r f print f read pipeline saved try load pipeline see still functions expected new_nlp pipeline pipeline new_nlp init_from_config_path save_path new_nlp initialize multipack new_nlp process_dataset input_string print source text multipack get_pack source text print ntarget text multipack get_pack target text build machine translation system forte,p build machine translation system forte,p build machine translation system fortetldr tutorial allows build machine translation system glue code using forte open source ml workflow builder xb forte makes easy compose nlp pipeline regardless heterogeneity data processes modular easily editable system allows users break complex problems composable pipelines enables inter operations across tasks unified data format tutorial includes read data source create simple nlp pipeline maintain store input data process data pipeline perform sentence segmentation annotate query data translate input text pre trained model manage multiple data objects handle practical requests handle structures like html data select single data object processing replace translation model remote translation services save load pipelinerun following command install required dependencies tutorial recommended install command line pip install forte forte nltk requests certain environment may run troubles installing transformers requiring rust workaround https may want try different pytorch version depending platform cannot install pytorch try locate problem https certain environment installation may fail workaround https read data source create simple pipeline start reader section learn reader need compose simple pipeline pre built reader xb forte import pipelinefrom forte data readers import terminalreader pipeline pipeline pipeline pipelines need reader read parse input data make pipeline read queries user command line terminal use terminalreader class provided forte terminalreader transforms user query datapack object unified data format nlp makes easy connect different nlp tools together forte processors pipeline set_reader terminalreader run pipeline consisting single terminalreader call process_dataset return iterator datapack objects second line following code snippet retrieves first user query terminalreader pipeline initialize datapack next pipeline process_dataset print datapack text maintain store input data datapack section learn datapack object need itforte helps demystify data lineage increase traceability data flows along pipeline features generated interface data model similar cargo ship loads transports goods one port another data pack carries information passing module updates ontology states along way https datapack multi modality datapack supports text data also audio image data https process data pipeline perform sentence segmentation pre built forte processor pipeline section learn processor need pre built processor pipelinea forte processor takes datapacks inputs processes stores outputs datapacks processors going use section packprocessors expect exactly one datapack input store outputs back datapack following two lines code shows pre built processor nltksentencesegmenter added pipeline fortex nltk nltk_processors import nltksentencesegmenter pipeline nltksentencesegmenter run pipeline nltksentencesegmenter processor split user query sentences store back datapack created terminalreader code snippet shows get sentences first query https ft onto base_ontology import sentence pipeline initialize sent next pipeline process_dataset get sentence print sent text annotate query data ontology section learn ontology system need write customized ontology use sentence pre defined ontology provided forte used nltksentencesegmenter annotate sentence text forte built top ontology system defines relations nlp annotations example relation documents two core forte ontology specified via json format tools provided convert ontology production code python https also define customized ontologies dataclasses import dataclass forte data ontology top import annotation typing import optional dataclass class article annotation language optional str def __init__ self pack begin int end int super __init__ pack begin end simple example showing query sentences ontology created forte data import datapack sentences want get better making delicious bbq opportunity put calendar thursday september nd join world class bbq champion tony balay lonestar smoke rangers datapack datapack datapack sentences datapack annotate sentence sentences datapack set_text datapack text sentence datapack add_entry sentence datapack len datapack text len sentence len datapack text annotate whole text article article article article datapack len datapack text article language en datapack add_entry article article datapack get article print farticle language article language sentence article get sentence print sentence text previous example following ontologies inheritance sentence article inherit annotation used represent text data article language field represent text language https actually support text ontology also audio image link represent relationships two entries https annotation inherited text entries usually span retrieve partial text full text article shown previous example inherits annotation contains language field differentiate english german single datapack example english article span english text datapack likewise german article span german text datapack sentence example used break article pass sentences mt pipeline audioannotation inherited audio entries usually audio span retrieve partial audio full audio recording example subclass audioannotation extra recording_class field denoting classes audio belongs imageannotation inherited image entries usually payload index pointing loaded image array boundingbox example subclass imageannotation picture shows inheritance relationships ontology classes due nature cv objects advantage forte ontology supports complex inheritance users inherit existing ontology ontology features needs link inherited link like entries parent child relationlink example subclass link class attribute specifying relation type translate input text pre trained model create machine translation processor section learn basics machine translation process wrap pre trained machine translation model forte processortranslation converts sequence text one language another tutorial use huggingface transformer model translate input data consists several steps including subword tokenization input embedding model inference decoding etc https forte generic class packprocessor wraps model inference related components behaviors process datapack therefore need create class inherits generic method packprocessor class definition class machinetranslationprocessor packprocessor forte data import datapack forte data readers import stringreader forte processors base import packprocessor transformers import ttokenizer tforconditionalgeneration class machinetranslationprocessor packprocessor translate input text output file def initialize self resources configs super initialize resources configs initialize tokenizer model model_name str self configs pretrained_model self tokenizer ttokenizer from_pretrained model_name self model tforconditionalgeneration from_pretrained model_name self task_prefix translate english german self tokenizer padding_side left self tokenizer pad_token self tokenizer eos_token def _process self input_pack datapack ende machine translation inputs self tokenizer self task_prefix sentence text sentence input_pack get sentence return_tensors pt padding true output_sequences self model generate input_ids inputs input_ids attention_mask inputs attention_mask do_sample false output join self tokenizer batch_decode output_sequences skip_special_tokens true src_article article article input_pack len input_pack text src_article language en input_pack set_text input_pack text n n output tgt_article article article input_pack len input_pack text len output len input_pack text tgt_article language de classmethod def default_configs cls return pretrained_model small initialization needed components users need consider initializing needed nlp components inference task tokenizer model users also need specify configuration configs dictionary like object specifies configurations components model name mt operations datapack initialization already needed nlp components need consider several mt behaviors based forte datapack pre process text data retrieve text data datapack given already reads data data source since better performance given task prompt also want include prompt data tokenization transforms input text sequences tokens token ids generate output sequences model decode output token ids sentences using tokenizer generic method process datapack _process self input_pack datapack tokenize input text use model class make inference decode output token ids finally write output target file pipeline run machine translation task input_string str join sentences pipeline pipeline pipeline datapack pipeline set_reader stringreader pipeline nltksentencesegmenter pipeline machinetranslationprocessor pipeline initialize datapack pipeline process_dataset input_string article datapack get article print f narticle language article language article text ontology datapack provide illustration users better understand internal storage datapack see text data sentence articles stored span annotations text data easily efficiently retrieved spans https manage multiple data objects multipack better way store source target text section learn multipack need use multipackthe step outputs datapack good holding data one specific piece text complicated pipeline like one building may need multiple datapacks passed along pipeline multipack help multipack manages set datapacks indexed names multipackboxer simple forte processor converts datapack multipack making datapack name specified via config use wrap datapack contains source sentence https forte data import multipack forte processors base import multipackprocessor forte data caster import multipackboxer class machinetranslationmpprocessor multipackprocessor translate input text output file def initialize self resources configs super initialize resources configs initialize tokenizer model model_name str self configs pretrained_model self tokenizer ttokenizer from_pretrained model_name self model tforconditionalgeneration from_pretrained model_name self task_prefix translate english german self tokenizer padding_side left self tokenizer pad_token self tokenizer eos_token def _process self input_pack multipack source_pack datapack input_pack get_pack source target_pack datapack input_pack add_pack target ende machine translation inputs self tokenizer self task_prefix sentence text sentence source_pack get sentence return_tensors pt padding true output_sequences self model generate input_ids inputs input_ids attention_mask inputs attention_mask do_sample false annotate source article src_article article article source_pack len source_pack text src_article language en annotate sentence output self tokenizer batch_decode output_sequences skip_special_tokens true target_pack set_text target_pack text output text_length int len target_pack text sentence target_pack text_length len output text_length annotate target article tgt_article article article target_pack len target_pack text tgt_article language de classmethod def default_configs cls return pretrained_model small machinetranslationmpprocessor writes output sentence target datapack https let try create pipeline utilizes multipack manage text different languages nlp pipeline pipeline datapack nlp set_reader stringreader nlp nltksentencesegmenter nlp multipackboxer config pack_name source nlp machinetranslationmpprocessor config pretrained_model small nlp initialize multipack nlp process_dataset input_string pack_name source target article multipack get_pack pack_name get article print f narticle language article language sentence article get sentence print sentence text ontology multipack comparison illustration internal storage multipack see multipack wraps one source datapack one target datapack article spans based two separate datapack text https handle practical requests handle structures like html data section learn build translation management system preserve structure like html machine translation select specific datapack multipack processingin previous step input string simple paragraph made several sentences however many cases might need handle data structural information html xml input string raw html data machine translation pipeline may work expected html_input str beginners bbq class want get better making delicious bbq opportunity put calendar thursday september nd join world class bbq champion tony balay lonestar smoke rangers nlp initialize multipack nlp process_dataset html_input print source text multipack get_pack source text print ntarget text multipack get_pack target text see original html structure broken translated output order handle structured data like html need update current design pipeline luckily forte pipelines highly modular simply insert two processors without updating previous pipeline first need html cleaner parse html tags input string picture shows effect tag remover https translation finished also need recover html structure unstructured translation output picture shows replace one source sentence one target sentence given target sentence ready https forte data import namematchselector forte data readers html_reader import fortehtmlparser class htmltagcleaner multipackprocessor def initialize self resources configs super initialize resources configs self _parser fortehtmlparser def _process self input_pack multipack raw_pack datapack input_pack get_pack raw source_pack datapack input_pack add_pack source self _parser feed raw_pack text cleaned_text str raw_pack text span _ self _parser spans cleaned_text cleaned_text replace raw_pack text span begin span end source_pack set_text cleaned_text class htmltagrecovery multipackprocessor def _process self input_pack multipack raw_pack datapack input_pack get_pack raw source_pack datapack input_pack get_pack source target_pack datapack input_pack get_pack target result_pack datapack input_pack add_pack result result_text str raw_pack text sent_src sent_tgt zip source_pack get sentence target_pack get sentence result_text result_text replace sent_src text sent_tgt text result_pack set_text result_text able create translation management system inserting two processors introduced previous machine translation pipeline pipeline html handling pipeline pipeline pipeline datapack pipeline set_reader stringreader pipeline multipackboxer config pack_name raw pipeline htmltagcleaner pipeline nltksentencesegmenter selector namematchselector selector_config select_name source pipeline machinetranslationmpprocessor config pretrained_model small pipeline htmltagrecovery pipeline initialize multipack pipeline process_dataset html_input print multipack get_pack raw text print multipack get_pack result text selector code snippet utilize namematchselector select one specific datapack multipack based reference name select_name allows nltksentencesegmenter process specified datapack replace translation model remote translation services replace mt model online translation api section learn use different translation serviceforte also allows us update translation model integrate seamlessly original pipeline example want offload translation task online service need update translation processor need change components pipeline get api key following instructions https api_key input enter api key import requests import uuid class onlinemachinetranslationmpprocessor multipackprocessor translate input text output file use online translator api def initialize self resources configs super initialize resources configs self url configs endpoint configs path self from_lang configs from_lang self to_lang configs to_lang self subscription_key configs subscription_key self subscription_region configs subscription_region def _process self input_pack multipack source_pack datapack input_pack get_pack source target_pack datapack input_pack add_pack target params api version en de build request headers ocp apim subscription key self subscription_key ocp apim subscription region self subscription_region content type application json x clienttraceid str uuid uuid pass one object body body text source_pack text request requests post self url params params headers headers json body result request json target_pack set_text join trans text trans result translations classmethod def default_configs cls return from_lang en to_lang de endpoint https path translate subscription_key none subscription_region westus x clienttraceid str uuid uuid nlp pipeline pipeline datapack nlp set_reader stringreader nlp nltksentencesegmenter nlp multipackboxer config pack_name source nlp onlinemachinetranslationmpprocessor config from_lang en to_lang de endpoint https path translate subscription_key api_key subscription_region westus x clienttraceid str uuid uuid nlp initialize multipack nlp process_dataset input_string print source text multipack get_pack source text print ntarget text multipack get_pack target text save load pipeline save whole pipeline save section learn export import forte pipelineforte also allow us save pipeline disk serializes whole pipeline generates intermediate representation loaded later maybe different machine import os save_path str os path join os path dirname os path abspath pipeline yml nlp save save_path open save_path r f print f read pipeline saved try load pipeline see still functions expected new_nlp pipeline pipeline new_nlp init_from_config_path save_path new_nlp initialize multipack new_nlp process_dataset input_string print source text multipack get_pack source text print ntarget text multipack get_pack target text build machine translation system forte,"['p', 'build', 'machine', 'translation', 'system', 'fortetldr', 'tutorial', 'allows', 'build', 'machine', 'translation', 'system', 'glue', 'code', 'using', 'forte', 'open', 'source', 'ml', 'workflow', 'builder', 'xb', 'forte', 'makes', 'easy', 'compose', 'nlp', 'pipeline', 'regardless', 'heterogeneity', 'data', 'processes', 'modular', 'easily', 'editable', 'system', 'allows', 'users', 'break', 'complex', 'problems', 'composable', 'pipelines', 'enables', 'inter', 'operations', 'across', 'tasks', 'unified', 'data', 'format', 'tutorial', 'includes', 'read', 'data', 'source', 'create', 'simple', 'nlp', 'pipeline', 'maintain', 'store', 'input', 'data', 'process', 'data', 'pipeline', 'perform', 'sentence', 'segmentation', 'annotate', 'query', 'data', 'translate', 'input', 'text', 'pre', 'trained', 'model', 'manage', 'multiple', 'data', 'objects', 'handle', 'practical', 'requests', 'handle', 'structures', 'like', 'html', 'data', 'select', 'single', 'data', 'object', 'processing', 'replace', 'translation', 'model', 'remote', 'translation', 'services', 'save', 'load', 'pipelinerun', 'following', 'command', 'install', 'required', 'dependencies', 'tutorial', 'recommended', 'install', 'command', 'line', 'pip', 'install', 'forte', 'forte', 'nltk', 'requests', 'certain', 'environment', 'may', 'run', 'troubles', 'installing', 'transformers', 'requiring', 'rust', 'workaround', 'https', 'may', 'want', 'try', 'different', 'pytorch', 'version', 'depending', 'platform', 'can', 'not', 'install', 'pytorch', 'try', 'locate', 'problem', 'https', 'certain', 'environment', 'installation', 'may', 'fail', 'workaround', 'https', 'read', 'data', 'source', 'create', 'simple', 'pipeline', 'start', 'reader', 'section', 'learn', 'reader', 'need', 'compose', 'simple', 'pipeline', 'pre', 'built', 'reader', 'xb', 'forte', 'import', 'pipelinefrom', 'forte', 'data', 'readers', 'import', 'terminalreader', 'pipeline', 'pipeline', 'pipeline', 'pipelines', 'need', 'reader', 'read', 'parse', 'input', 'data', 'make', 'pipeline', 'read', 'queries', 'user', 'command', 'line', 'terminal', 'use', 'terminalreader', 'class', 'provided', 'forte', 'terminalreader', 'transforms', 'user', 'query', 'datapack', 'object', 'unified', 'data', 'format', 'nlp', 'makes', 'easy', 'connect', 'different', 'nlp', 'tools', 'together', 'forte', 'processors', 'pipeline', 'set_reader', 'terminalreader', 'run', 'pipeline', 'consisting', 'single', 'terminalreader', 'call', 'process_dataset', 'return', 'iterator', 'datapack', 'objects', 'second', 'line', 'following', 'code', 'snippet', 'retrieves', 'first', 'user', 'query', 'terminalreader', 'pipeline', 'initialize', 'datapack', 'next', 'pipeline', 'process_dataset', 'print', 'datapack', 'text', 'maintain', 'store', 'input', 'data', 'datapack', 'section', 'learn', 'datapack', 'object', 'need', 'itforte', 'helps', 'demystify', 'data', 'lineage', 'increase', 'traceability', 'data', 'flows', 'along', 'pipeline', 'features', 'generated', 'interface', 'data', 'model', 'similar', 'cargo', 'ship', 'loads', 'transports', 'goods', 'one', 'port', 'another', 'data', 'pack', 'carries', 'information', 'passing', 'module', 'updates', 'ontology', 'states', 'along', 'way', 'https', 'datapack', 'multi', 'modality', 'datapack', 'supports', 'text', 'data', 'also', 'audio', 'image', 'data', 'https', 'process', 'data', 'pipeline', 'perform', 'sentence', 'segmentation', 'pre', 'built', 'forte', 'processor', 'pipeline', 'section', 'learn', 'processor', 'need', 'pre', 'built', 'processor', 'pipelinea', 'forte', 'processor', 'takes', 'datapacks', 'inputs', 'processes', 'stores', 'outputs', 'datapacks', 'processors', 'going', 'use', 'section', 'packprocessors', 'expect', 'exactly', 'one', 'datapack', 'input', 'store', 'outputs', 'back', 'datapack', 'following', 'two', 'lines', 'code', 'shows', 'pre', 'built', 'processor', 'nltksentencesegmenter', 'added', 'pipeline', 'fortex', 'nltk', 'nltk_processors', 'import', 'nltksentencesegmenter', 'pipeline', 'nltksentencesegmenter', 'run', 'pipeline', 'nltksentencesegmenter', 'processor', 'split', 'user', 'query', 'sentences', 'store', 'back', 'datapack', 'created', 'terminalreader', 'code', 'snippet', 'shows', 'get', 'sentences', 'first', 'query', 'https', 'ft', 'onto', 'base_ontology', 'import', 'sentence', 'pipeline', 'initialize', 'sent', 'next', 'pipeline', 'process_dataset', 'get', 'sentence', 'print', 'sent', 'text', 'annotate', 'query', 'data', 'ontology', 'section', 'learn', 'ontology', 'system', 'need', 'write', 'customized', 'ontology', 'use', 'sentence', 'pre', 'defined', 'ontology', 'provided', 'forte', 'used', 'nltksentencesegmenter', 'annotate', 'sentence', 'text', 'forte', 'built', 'top', 'ontology', 'system', 'defines', 'relations', 'nlp', 'annotations', 'example', 'relation', 'documents', 'two', 'core', 'forte', 'ontology', 'specified', 'via', 'json', 'format', 'tools', 'provided', 'convert', 'ontology', 'production', 'code', 'python', 'https', 'also', 'define', 'customized', 'ontologies', 'dataclasses', 'import', 'dataclass', 'forte', 'data', 'ontology', 'top', 'import', 'annotation', 'typing', 'import', 'optional', 'dataclass', 'class', 'article', 'annotation', 'language', 'optional', 'str', 'def', '__init__', 'self', 'pack', 'begin', 'int', 'end', 'int', 'super', '__init__', 'pack', 'begin', 'end', 'simple', 'example', 'showing', 'query', 'sentences', 'ontology', 'created', 'forte', 'data', 'import', 'datapack', 'sentences', 'want', 'get', 'better', 'making', 'delicious', 'bbq', 'opportunity', 'put', 'calendar', 'thursday', 'september', 'nd', 'join', 'world', 'class', 'bbq', 'champion', 'tony', 'balay', 'lonestar', 'smoke', 'rangers', 'datapack', 'datapack', 'datapack', 'sentences', 'datapack', 'annotate', 'sentence', 'sentences', 'datapack', 'set_text', 'datapack', 'text', 'sentence', 'datapack', 'add_entry', 'sentence', 'datapack', 'len', 'datapack', 'text', 'len', 'sentence', 'len', 'datapack', 'text', 'annotate', 'whole', 'text', 'article', 'article', 'article', 'article', 'datapack', 'len', 'datapack', 'text', 'article', 'language', 'en', 'datapack', 'add_entry', 'article', 'article', 'datapack', 'get', 'article', 'print', 'farticle', 'language', 'article', 'language', 'sentence', 'article', 'get', 'sentence', 'print', 'sentence', 'text', 'previous', 'example', 'following', 'ontologies', 'inheritance', 'sentence', 'article', 'inherit', 'annotation', 'used', 'represent', 'text', 'data', 'article', 'language', 'field', 'represent', 'text', 'language', 'https', 'actually', 'support', 'text', 'ontology', 'also', 'audio', 'image', 'link', 'represent', 'relationships', 'two', 'entries', 'https', 'annotation', 'inherited', 'text', 'entries', 'usually', 'span', 'retrieve', 'partial', 'text', 'full', 'text', 'article', 'shown', 'previous', 'example', 'inherits', 'annotation', 'contains', 'language', 'field', 'differentiate', 'english', 'german', 'single', 'datapack', 'example', 'english', 'article', 'span', 'english', 'text', 'datapack', 'likewise', 'german', 'article', 'span', 'german', 'text', 'datapack', 'sentence', 'example', 'used', 'break', 'article', 'pass', 'sentences', 'mt', 'pipeline', 'audioannotation', 'inherited', 'audio', 'entries', 'usually', 'audio', 'span', 'retrieve', 'partial', 'audio', 'full', 'audio', 'recording', 'example', 'subclass', 'audioannotation', 'extra', 'recording_class', 'field', 'denoting', 'classes', 'audio', 'belongs', 'imageannotation', 'inherited', 'image', 'entries', 'usually', 'payload', 'index', 'pointing', 'loaded', 'image', 'array', 'boundingbox', 'example', 'subclass', 'imageannotation', 'picture', 'shows', 'inheritance', 'relationships', 'ontology', 'classes', 'due', 'nature', 'cv', 'objects', 'advantage', 'forte', 'ontology', 'supports', 'complex', 'inheritance', 'users', 'inherit', 'existing', 'ontology', 'ontology', 'features', 'needs', 'link', 'inherited', 'link', 'like', 'entries', 'parent', 'child', 'relationlink', 'example', 'subclass', 'link', 'class', 'attribute', 'specifying', 'relation', 'type', 'translate', 'input', 'text', 'pre', 'trained', 'model', 'create', 'machine', 'translation', 'processor', 'section', 'learn', 'basics', 'machine', 'translation', 'process', 'wrap', 'pre', 'trained', 'machine', 'translation', 'model', 'forte', 'processortranslation', 'converts', 'sequence', 'text', 'one', 'language', 'another', 'tutorial', 'use', 'huggingface', 'transformer', 'model', 'translate', 'input', 'data', 'consists', 'several', 'steps', 'including', 'subword', 'tokenization', 'input', 'embedding', 'model', 'inference', 'decoding', 'etc', 'https', 'forte', 'generic', 'class', 'packprocessor', 'wraps', 'model', 'inference', 'related', 'components', 'behaviors', 'process', 'datapack', 'therefore', 'need', 'create', 'class', 'inherits', 'generic', 'method', 'packprocessor', 'class', 'definition', 'class', 'machinetranslationprocessor', 'packprocessor', 'forte', 'data', 'import', 'datapack', 'forte', 'data', 'readers', 'import', 'stringreader', 'forte', 'processors', 'base', 'import', 'packprocessor', 'transformers', 'import', 'ttokenizer', 'tforconditionalgeneration', 'class', 'machinetranslationprocessor', 'packprocessor', 'translate', 'input', 'text', 'output', 'file', 'def', 'initialize', 'self', 'resources', 'configs', 'super', 'initialize', 'resources', 'configs', 'initialize', 'tokenizer', 'model', 'model_name', 'str', 'self', 'configs', 'pretrained_model', 'self', 'tokenizer', 'ttokenizer', 'from_pretrained', 'model_name', 'self', 'model', 'tforconditionalgeneration', 'from_pretrained', 'model_name', 'self', 'task_prefix', 'translate', 'english', 'german', 'self', 'tokenizer', 'padding_side', 'left', 'self', 'tokenizer', 'pad_token', 'self', 'tokenizer', 'eos_token', 'def', '_process', 'self', 'input_pack', 'datapack', 'ende', 'machine', 'translation', 'inputs', 'self', 'tokenizer', 'self', 'task_prefix', 'sentence', 'text', 'sentence', 'input_pack', 'get', 'sentence', 'return_tensors', 'pt', 'padding', 'true', 'output_sequences', 'self', 'model', 'generate', 'input_ids', 'inputs', 'input_ids', 'attention_mask', 'inputs', 'attention_mask', 'do_sample', 'false', 'output', 'join', 'self', 'tokenizer', 'batch_decode', 'output_sequences', 'skip_special_tokens', 'true', 'src_article', 'article', 'article', 'input_pack', 'len', 'input_pack', 'text', 'src_article', 'language', 'en', 'input_pack', 'set_text', 'input_pack', 'text', 'n', 'n', 'output', 'tgt_article', 'article', 'article', 'input_pack', 'len', 'input_pack', 'text', 'len', 'output', 'len', 'input_pack', 'text', 'tgt_article', 'language', 'de', 'classmethod', 'def', 'default_configs', 'cls', 'return', 'pretrained_model', 'small', 'initialization', 'needed', 'components', 'users', 'need', 'consider', 'initializing', 'needed', 'nlp', 'components', 'inference', 'task', 'tokenizer', 'model', 'users', 'also', 'need', 'specify', 'configuration', 'configs', 'dictionary', 'like', 'object', 'specifies', 'configurations', 'components', 'model', 'name', 'mt', 'operations', 'datapack', 'initialization', 'already', 'needed', 'nlp', 'components', 'need', 'consider', 'several', 'mt', 'behaviors', 'based', 'forte', 'datapack', 'pre', 'process', 'text', 'data', 'retrieve', 'text', 'data', 'datapack', 'given', 'already', 'reads', 'data', 'data', 'source', 'since', 'better', 'performance', 'given', 'task', 'prompt', 'also', 'want', 'include', 'prompt', 'data', 'tokenization', 'transforms', 'input', 'text', 'sequences', 'tokens', 'token', 'ids', 'generate', 'output', 'sequences', 'model', 'decode', 'output', 'token', 'ids', 'sentences', 'using', 'tokenizer', 'generic', 'method', 'process', 'datapack', '_process', 'self', 'input_pack', 'datapack', 'tokenize', 'input', 'text', 'use', 'model', 'class', 'make', 'inference', 'decode', 'output', 'token', 'ids', 'finally', 'write', 'output', 'target', 'file', 'pipeline', 'run', 'machine', 'translation', 'task', 'input_string', 'str', 'join', 'sentences', 'pipeline', 'pipeline', 'pipeline', 'datapack', 'pipeline', 'set_reader', 'stringreader', 'pipeline', 'nltksentencesegmenter', 'pipeline', 'machinetranslationprocessor', 'pipeline', 'initialize', 'datapack', 'pipeline', 'process_dataset', 'input_string', 'article', 'datapack', 'get', 'article', 'print', 'f', 'narticle', 'language', 'article', 'language', 'article', 'text', 'ontology', 'datapack', 'provide', 'illustration', 'users', 'better', 'understand', 'internal', 'storage', 'datapack', 'see', 'text', 'data', 'sentence', 'articles', 'stored', 'span', 'annotations', 'text', 'data', 'easily', 'efficiently', 'retrieved', 'spans', 'https', 'manage', 'multiple', 'data', 'objects', 'multipack', 'better', 'way', 'store', 'source', 'target', 'text', 'section', 'learn', 'multipack', 'need', 'use', 'multipackthe', 'step', 'outputs', 'datapack', 'good', 'holding', 'data', 'one', 'specific', 'piece', 'text', 'complicated', 'pipeline', 'like', 'one', 'building', 'may', 'need', 'multiple', 'datapacks', 'passed', 'along', 'pipeline', 'multipack', 'help', 'multipack', 'manages', 'set', 'datapacks', 'indexed', 'names', 'multipackboxer', 'simple', 'forte', 'processor', 'converts', 'datapack', 'multipack', 'making', 'datapack', 'name', 'specified', 'via', 'config', 'use', 'wrap', 'datapack', 'contains', 'source', 'sentence', 'https', 'forte', 'data', 'import', 'multipack', 'forte', 'processors', 'base', 'import', 'multipackprocessor', 'forte', 'data', 'caster', 'import', 'multipackboxer', 'class', 'machinetranslationmpprocessor', 'multipackprocessor', 'translate', 'input', 'text', 'output', 'file', 'def', 'initialize', 'self', 'resources', 'configs', 'super', 'initialize', 'resources', 'configs', 'initialize', 'tokenizer', 'model', 'model_name', 'str', 'self', 'configs', 'pretrained_model', 'self', 'tokenizer', 'ttokenizer', 'from_pretrained', 'model_name', 'self', 'model', 'tforconditionalgeneration', 'from_pretrained', 'model_name', 'self', 'task_prefix', 'translate', 'english', 'german', 'self', 'tokenizer', 'padding_side', 'left', 'self', 'tokenizer', 'pad_token', 'self', 'tokenizer', 'eos_token', 'def', '_process', 'self', 'input_pack', 'multipack', 'source_pack', 'datapack', 'input_pack', 'get_pack', 'source', 'target_pack', 'datapack', 'input_pack', 'add_pack', 'target', 'ende', 'machine', 'translation', 'inputs', 'self', 'tokenizer', 'self', 'task_prefix', 'sentence', 'text', 'sentence', 'source_pack', 'get', 'sentence', 'return_tensors', 'pt', 'padding', 'true', 'output_sequences', 'self', 'model', 'generate', 'input_ids', 'inputs', 'input_ids', 'attention_mask', 'inputs', 'attention_mask', 'do_sample', 'false', 'annotate', 'source', 'article', 'src_article', 'article', 'article', 'source_pack', 'len', 'source_pack', 'text', 'src_article', 'language', 'en', 'annotate', 'sentence', 'output', 'self', 'tokenizer', 'batch_decode', 'output_sequences', 'skip_special_tokens', 'true', 'target_pack', 'set_text', 'target_pack', 'text', 'output', 'text_length', 'int', 'len', 'target_pack', 'text', 'sentence', 'target_pack', 'text_length', 'len', 'output', 'text_length', 'annotate', 'target', 'article', 'tgt_article', 'article', 'article', 'target_pack', 'len', 'target_pack', 'text', 'tgt_article', 'language', 'de', 'classmethod', 'def', 'default_configs', 'cls', 'return', 'pretrained_model', 'small', 'machinetranslationmpprocessor', 'writes', 'output', 'sentence', 'target', 'datapack', 'https', 'let', 'try', 'create', 'pipeline', 'utilizes', 'multipack', 'manage', 'text', 'different', 'languages', 'nlp', 'pipeline', 'pipeline', 'datapack', 'nlp', 'set_reader', 'stringreader', 'nlp', 'nltksentencesegmenter', 'nlp', 'multipackboxer', 'config', 'pack_name', 'source', 'nlp', 'machinetranslationmpprocessor', 'config', 'pretrained_model', 'small', 'nlp', 'initialize', 'multipack', 'nlp', 'process_dataset', 'input_string', 'pack_name', 'source', 'target', 'article', 'multipack', 'get_pack', 'pack_name', 'get', 'article', 'print', 'f', 'narticle', 'language', 'article', 'language', 'sentence', 'article', 'get', 'sentence', 'print', 'sentence', 'text', 'ontology', 'multipack', 'comparison', 'illustration', 'internal', 'storage', 'multipack', 'see', 'multipack', 'wraps', 'one', 'source', 'datapack', 'one', 'target', 'datapack', 'article', 'spans', 'based', 'two', 'separate', 'datapack', 'text', 'https', 'handle', 'practical', 'requests', 'handle', 'structures', 'like', 'html', 'data', 'section', 'learn', 'build', 'translation', 'management', 'system', 'preserve', 'structure', 'like', 'html', 'machine', 'translation', 'select', 'specific', 'datapack', 'multipack', 'processingin', 'previous', 'step', 'input', 'string', 'simple', 'paragraph', 'made', 'several', 'sentences', 'however', 'many', 'cases', 'might', 'need', 'handle', 'data', 'structural', 'information', 'html', 'xml', 'input', 'string', 'raw', 'html', 'data', 'machine', 'translation', 'pipeline', 'may', 'work', 'expected', 'html_input', 'str', 'beginners', 'bbq', 'class', 'want', 'get', 'better', 'making', 'delicious', 'bbq', 'opportunity', 'put', 'calendar', 'thursday', 'september', 'nd', 'join', 'world', 'class', 'bbq', 'champion', 'tony', 'balay', 'lonestar', 'smoke', 'rangers', 'nlp', 'initialize', 'multipack', 'nlp', 'process_dataset', 'html_input', 'print', 'source', 'text', 'multipack', 'get_pack', 'source', 'text', 'print', 'ntarget', 'text', 'multipack', 'get_pack', 'target', 'text', 'see', 'original', 'html', 'structure', 'broken', 'translated', 'output', 'order', 'handle', 'structured', 'data', 'like', 'html', 'need', 'update', 'current', 'design', 'pipeline', 'luckily', 'forte', 'pipelines', 'highly', 'modular', 'simply', 'insert', 'two', 'processors', 'without', 'updating', 'previous', 'pipeline', 'first', 'need', 'html', 'cleaner', 'parse', 'html', 'tags', 'input', 'string', 'picture', 'shows', 'effect', 'tag', 'remover', 'https', 'translation', 'finished', 'also', 'need', 'recover', 'html', 'structure', 'unstructured', 'translation', 'output', 'picture', 'shows', 'replace', 'one', 'source', 'sentence', 'one', 'target', 'sentence', 'given', 'target', 'sentence', 'ready', 'https', 'forte', 'data', 'import', 'namematchselector', 'forte', 'data', 'readers', 'html_reader', 'import', 'fortehtmlparser', 'class', 'htmltagcleaner', 'multipackprocessor', 'def', 'initialize', 'self', 'resources', 'configs', 'super', 'initialize', 'resources', 'configs', 'self', '_parser', 'fortehtmlparser', 'def', '_process', 'self', 'input_pack', 'multipack', 'raw_pack', 'datapack', 'input_pack', 'get_pack', 'raw', 'source_pack', 'datapack', 'input_pack', 'add_pack', 'source', 'self', '_parser', 'feed', 'raw_pack', 'text', 'cleaned_text', 'str', 'raw_pack', 'text', 'span', '_', 'self', '_parser', 'spans', 'cleaned_text', 'cleaned_text', 'replace', 'raw_pack', 'text', 'span', 'begin', 'span', 'end', 'source_pack', 'set_text', 'cleaned_text', 'class', 'htmltagrecovery', 'multipackprocessor', 'def', '_process', 'self', 'input_pack', 'multipack', 'raw_pack', 'datapack', 'input_pack', 'get_pack', 'raw', 'source_pack', 'datapack', 'input_pack', 'get_pack', 'source', 'target_pack', 'datapack', 'input_pack', 'get_pack', 'target', 'result_pack', 'datapack', 'input_pack', 'add_pack', 'result', 'result_text', 'str', 'raw_pack', 'text', 'sent_src', 'sent_tgt', 'zip', 'source_pack', 'get', 'sentence', 'target_pack', 'get', 'sentence', 'result_text', 'result_text', 'replace', 'sent_src', 'text', 'sent_tgt', 'text', 'result_pack', 'set_text', 'result_text', 'able', 'create', 'translation', 'management', 'system', 'inserting', 'two', 'processors', 'introduced', 'previous', 'machine', 'translation', 'pipeline', 'pipeline', 'html', 'handling', 'pipeline', 'pipeline', 'pipeline', 'datapack', 'pipeline', 'set_reader', 'stringreader', 'pipeline', 'multipackboxer', 'config', 'pack_name', 'raw', 'pipeline', 'htmltagcleaner', 'pipeline', 'nltksentencesegmenter', 'selector', 'namematchselector', 'selector_config', 'select_name', 'source', 'pipeline', 'machinetranslationmpprocessor', 'config', 'pretrained_model', 'small', 'pipeline', 'htmltagrecovery', 'pipeline', 'initialize', 'multipack', 'pipeline', 'process_dataset', 'html_input', 'print', 'multipack', 'get_pack', 'raw', 'text', 'print', 'multipack', 'get_pack', 'result', 'text', 'selector', 'code', 'snippet', 'utilize', 'namematchselector', 'select', 'one', 'specific', 'datapack', 'multipack', 'based', 'reference', 'name', 'select_name', 'allows', 'nltksentencesegmenter', 'process', 'specified', 'datapack', 'replace', 'translation', 'model', 'remote', 'translation', 'services', 'replace', 'mt', 'model', 'online', 'translation', 'api', 'section', 'learn', 'use', 'different', 'translation', 'serviceforte', 'also', 'allows', 'us', 'update', 'translation', 'model', 'integrate', 'seamlessly', 'original', 'pipeline', 'example', 'want', 'offload', 'translation', 'task', 'online', 'service', 'need', 'update', 'translation', 'processor', 'need', 'change', 'components', 'pipeline', 'get', 'api', 'key', 'following', 'instructions', 'https', 'api_key', 'input', 'enter', 'api', 'key', 'import', 'requests', 'import', 'uuid', 'class', 'onlinemachinetranslationmpprocessor', 'multipackprocessor', 'translate', 'input', 'text', 'output', 'file', 'use', 'online', 'translator', 'api', 'def', 'initialize', 'self', 'resources', 'configs', 'super', 'initialize', 'resources', 'configs', 'self', 'url', 'configs', 'endpoint', 'configs', 'path', 'self', 'from_lang', 'configs', 'from_lang', 'self', 'to_lang', 'configs', 'to_lang', 'self', 'subscription_key', 'configs', 'subscription_key', 'self', 'subscription_region', 'configs', 'subscription_region', 'def', '_process', 'self', 'input_pack', 'multipack', 'source_pack', 'datapack', 'input_pack', 'get_pack', 'source', 'target_pack', 'datapack', 'input_pack', 'add_pack', 'target', 'params', 'api', 'version', 'en', 'de', 'build', 'request', 'headers', 'ocp', 'apim', 'subscription', 'key', 'self', 'subscription_key', 'ocp', 'apim', 'subscription', 'region', 'self', 'subscription_region', 'content', 'type', 'application', 'json', 'x', 'clienttraceid', 'str', 'uuid', 'uuid', 'pass', 'one', 'object', 'body', 'body', 'text', 'source_pack', 'text', 'request', 'requests', 'post', 'self', 'url', 'params', 'params', 'headers', 'headers', 'json', 'body', 'result', 'request', 'json', 'target_pack', 'set_text', 'join', 'trans', 'text', 'trans', 'result', 'translations', 'classmethod', 'def', 'default_configs', 'cls', 'return', 'from_lang', 'en', 'to_lang', 'de', 'endpoint', 'https', 'path', 'translate', 'subscription_key', 'none', 'subscription_region', 'westus', 'x', 'clienttraceid', 'str', 'uuid', 'uuid', 'nlp', 'pipeline', 'pipeline', 'datapack', 'nlp', 'set_reader', 'stringreader', 'nlp', 'nltksentencesegmenter', 'nlp', 'multipackboxer', 'config', 'pack_name', 'source', 'nlp', 'onlinemachinetranslationmpprocessor', 'config', 'from_lang', 'en', 'to_lang', 'de', 'endpoint', 'https', 'path', 'translate', 'subscription_key', 'api_key', 'subscription_region', 'westus', 'x', 'clienttraceid', 'str', 'uuid', 'uuid', 'nlp', 'initialize', 'multipack', 'nlp', 'process_dataset', 'input_string', 'print', 'source', 'text', 'multipack', 'get_pack', 'source', 'text', 'print', 'ntarget', 'text', 'multipack', 'get_pack', 'target', 'text', 'save', 'load', 'pipeline', 'save', 'whole', 'pipeline', 'save', 'section', 'learn', 'export', 'import', 'forte', 'pipelineforte', 'also', 'allow', 'us', 'save', 'pipeline', 'disk', 'serializes', 'whole', 'pipeline', 'generates', 'intermediate', 'representation', 'loaded', 'later', 'maybe', 'different', 'machine', 'import', 'os', 'save_path', 'str', 'os', 'path', 'join', 'os', 'path', 'dirname', 'os', 'path', 'abspath', 'pipeline', 'yml', 'nlp', 'save', 'save_path', 'open', 'save_path', 'r', 'f', 'print', 'f', 'read', 'pipeline', 'saved', 'try', 'load', 'pipeline', 'see', 'still', 'functions', 'expected', 'new_nlp', 'pipeline', 'pipeline', 'new_nlp', 'init_from_config_path', 'save_path', 'new_nlp', 'initialize', 'multipack', 'new_nlp', 'process_dataset', 'input_string', 'print', 'source', 'text', 'multipack', 'get_pack', 'source', 'text', 'print', 'ntarget', 'text', 'multipack', 'get_pack', 'target', 'text', 'build', 'machine', 'translation', 'system', 'forte']","['p', 'build', 'machin', 'translat', 'system', 'fortetldr', 'tutori', 'allow', 'build', 'machin', 'translat', 'system', 'glue', 'code', 'use', 'fort', 'open', 'sourc', 'ml', 'workflow', 'builder', 'xb', 'fort', 'make', 'easi', 'compos', 'nlp', 'pipelin', 'regardless', 'heterogen', 'data', 'process', 'modular', 'easili', 'edit', 'system', 'allow', 'user', 'break', 'complex', 'problem', 'compos', 'pipelin', 'enabl', 'inter', 'oper', 'across', 'task', 'unifi', 'data', 'format', 'tutori', 'includ', 'read', 'data', 'sourc', 'creat', 'simpl', 'nlp', 'pipelin', 'maintain', 'store', 'input', 'data', 'process', 'data', 'pipelin', 'perform', 'sentenc', 'segment', 'annot', 'queri', 'data', 'translat', 'input', 'text', 'pre', 'train', 'model', 'manag', 'multipl', 'data', 'object', 'handl', 'practic', 'request', 'handl', 'structur', 'like', 'html', 'data', 'select', 'singl', 'data', 'object', 'process', 'replac', 'translat', 'model', 'remot', 'translat', 'servic', 'save', 'load', 'pipelinerun', 'follow', 'command', 'instal', 'requir', 'depend', 'tutori', 'recommend', 'instal', 'command', 'line', 'pip', 'instal', 'fort', 'fort', 'nltk', 'request', 'certain', 'environ', 'may', 'run', 'troubl', 'instal', 'transform', 'requir', 'rust', 'workaround', 'http', 'may', 'want', 'tri', 'differ', 'pytorch', 'version', 'depend', 'platform', 'can', 'not', 'instal', 'pytorch', 'tri', 'locat', 'problem', 'http', 'certain', 'environ', 'instal', 'may', 'fail', 'workaround', 'http', 'read', 'data', 'sourc', 'creat', 'simpl', 'pipelin', 'start', 'reader', 'section', 'learn', 'reader', 'need', 'compos', 'simpl', 'pipelin', 'pre', 'built', 'reader', 'xb', 'fort', 'import', 'pipelinefrom', 'fort', 'data', 'reader', 'import', 'terminalread', 'pipelin', 'pipelin', 'pipelin', 'pipelin', 'need', 'reader', 'read', 'pars', 'input', 'data', 'make', 'pipelin', 'read', 'queri', 'user', 'command', 'line', 'termin', 'use', 'terminalread', 'class', 'provid', 'fort', 'terminalread', 'transform', 'user', 'queri', 'datapack', 'object', 'unifi', 'data', 'format', 'nlp', 'make', 'easi', 'connect', 'differ', 'nlp', 'tool', 'togeth', 'fort', 'processor', 'pipelin', 'set_read', 'terminalread', 'run', 'pipelin', 'consist', 'singl', 'terminalread', 'call', 'process_dataset', 'return', 'iter', 'datapack', 'object', 'second', 'line', 'follow', 'code', 'snippet', 'retriev', 'first', 'user', 'queri', 'terminalread', 'pipelin', 'initi', 'datapack', 'next', 'pipelin', 'process_dataset', 'print', 'datapack', 'text', 'maintain', 'store', 'input', 'data', 'datapack', 'section', 'learn', 'datapack', 'object', 'need', 'itfort', 'help', 'demystifi', 'data', 'lineag', 'increas', 'traceabl', 'data', 'flow', 'along', 'pipelin', 'featur', 'gener', 'interfac', 'data', 'model', 'similar', 'cargo', 'ship', 'load', 'transport', 'good', 'one', 'port', 'anoth', 'data', 'pack', 'carri', 'inform', 'pass', 'modul', 'updat', 'ontolog', 'state', 'along', 'way', 'http', 'datapack', 'multi', 'modal', 'datapack', 'support', 'text', 'data', 'also', 'audio', 'imag', 'data', 'http', 'process', 'data', 'pipelin', 'perform', 'sentenc', 'segment', 'pre', 'built', 'fort', 'processor', 'pipelin', 'section', 'learn', 'processor', 'need', 'pre', 'built', 'processor', 'pipelinea', 'fort', 'processor', 'take', 'datapack', 'input', 'process', 'store', 'output', 'datapack', 'processor', 'go', 'use', 'section', 'packprocessor', 'expect', 'exactli', 'one', 'datapack', 'input', 'store', 'output', 'back', 'datapack', 'follow', 'two', 'line', 'code', 'show', 'pre', 'built', 'processor', 'nltksentencesegment', 'ad', 'pipelin', 'fortex', 'nltk', 'nltk_processor', 'import', 'nltksentencesegment', 'pipelin', 'nltksentencesegment', 'run', 'pipelin', 'nltksentencesegment', 'processor', 'split', 'user', 'queri', 'sentenc', 'store', 'back', 'datapack', 'creat', 'terminalread', 'code', 'snippet', 'show', 'get', 'sentenc', 'first', 'queri', 'http', 'ft', 'onto', 'base_ontolog', 'import', 'sentenc', 'pipelin', 'initi', 'sent', 'next', 'pipelin', 'process_dataset', 'get', 'sentenc', 'print', 'sent', 'text', 'annot', 'queri', 'data', 'ontolog', 'section', 'learn', 'ontolog', 'system', 'need', 'write', 'custom', 'ontolog', 'use', 'sentenc', 'pre', 'defin', 'ontolog', 'provid', 'fort', 'use', 'nltksentencesegment', 'annot', 'sentenc', 'text', 'fort', 'built', 'top', 'ontolog', 'system', 'defin', 'relat', 'nlp', 'annot', 'exampl', 'relat', 'document', 'two', 'core', 'fort', 'ontolog', 'specifi', 'via', 'json', 'format', 'tool', 'provid', 'convert', 'ontolog', 'product', 'code', 'python', 'http', 'also', 'defin', 'custom', 'ontolog', 'dataclass', 'import', 'dataclass', 'fort', 'data', 'ontolog', 'top', 'import', 'annot', 'type', 'import', 'option', 'dataclass', 'class', 'articl', 'annot', 'languag', 'option', 'str', 'def', '__init__', 'self', 'pack', 'begin', 'int', 'end', 'int', 'super', '__init__', 'pack', 'begin', 'end', 'simpl', 'exampl', 'show', 'queri', 'sentenc', 'ontolog', 'creat', 'fort', 'data', 'import', 'datapack', 'sentenc', 'want', 'get', 'better', 'make', 'delici', 'bbq', 'opportun', 'put', 'calendar', 'thursday', 'septemb', 'nd', 'join', 'world', 'class', 'bbq', 'champion', 'toni', 'balay', 'lonestar', 'smoke', 'ranger', 'datapack', 'datapack', 'datapack', 'sentenc', 'datapack', 'annot', 'sentenc', 'sentenc', 'datapack', 'set_text', 'datapack', 'text', 'sentenc', 'datapack', 'add_entri', 'sentenc', 'datapack', 'len', 'datapack', 'text', 'len', 'sentenc', 'len', 'datapack', 'text', 'annot', 'whole', 'text', 'articl', 'articl', 'articl', 'articl', 'datapack', 'len', 'datapack', 'text', 'articl', 'languag', 'en', 'datapack', 'add_entri', 'articl', 'articl', 'datapack', 'get', 'articl', 'print', 'farticl', 'languag', 'articl', 'languag', 'sentenc', 'articl', 'get', 'sentenc', 'print', 'sentenc', 'text', 'previou', 'exampl', 'follow', 'ontolog', 'inherit', 'sentenc', 'articl', 'inherit', 'annot', 'use', 'repres', 'text', 'data', 'articl', 'languag', 'field', 'repres', 'text', 'languag', 'http', 'actual', 'support', 'text', 'ontolog', 'also', 'audio', 'imag', 'link', 'repres', 'relationship', 'two', 'entri', 'http', 'annot', 'inherit', 'text', 'entri', 'usual', 'span', 'retriev', 'partial', 'text', 'full', 'text', 'articl', 'shown', 'previou', 'exampl', 'inherit', 'annot', 'contain', 'languag', 'field', 'differenti', 'english', 'german', 'singl', 'datapack', 'exampl', 'english', 'articl', 'span', 'english', 'text', 'datapack', 'likewis', 'german', 'articl', 'span', 'german', 'text', 'datapack', 'sentenc', 'exampl', 'use', 'break', 'articl', 'pass', 'sentenc', 'mt', 'pipelin', 'audioannot', 'inherit', 'audio', 'entri', 'usual', 'audio', 'span', 'retriev', 'partial', 'audio', 'full', 'audio', 'record', 'exampl', 'subclass', 'audioannot', 'extra', 'recording_class', 'field', 'denot', 'class', 'audio', 'belong', 'imageannot', 'inherit', 'imag', 'entri', 'usual', 'payload', 'index', 'point', 'load', 'imag', 'array', 'boundingbox', 'exampl', 'subclass', 'imageannot', 'pictur', 'show', 'inherit', 'relationship', 'ontolog', 'class', 'due', 'natur', 'cv', 'object', 'advantag', 'fort', 'ontolog', 'support', 'complex', 'inherit', 'user', 'inherit', 'exist', 'ontolog', 'ontolog', 'featur', 'need', 'link', 'inherit', 'link', 'like', 'entri', 'parent', 'child', 'relationlink', 'exampl', 'subclass', 'link', 'class', 'attribut', 'specifi', 'relat', 'type', 'translat', 'input', 'text', 'pre', 'train', 'model', 'creat', 'machin', 'translat', 'processor', 'section', 'learn', 'basic', 'machin', 'translat', 'process', 'wrap', 'pre', 'train', 'machin', 'translat', 'model', 'fort', 'processortransl', 'convert', 'sequenc', 'text', 'one', 'languag', 'anoth', 'tutori', 'use', 'huggingfac', 'transform', 'model', 'translat', 'input', 'data', 'consist', 'sever', 'step', 'includ', 'subword', 'token', 'input', 'embed', 'model', 'infer', 'decod', 'etc', 'http', 'fort', 'gener', 'class', 'packprocessor', 'wrap', 'model', 'infer', 'relat', 'compon', 'behavior', 'process', 'datapack', 'therefor', 'need', 'creat', 'class', 'inherit', 'gener', 'method', 'packprocessor', 'class', 'definit', 'class', 'machinetranslationprocessor', 'packprocessor', 'fort', 'data', 'import', 'datapack', 'fort', 'data', 'reader', 'import', 'stringread', 'fort', 'processor', 'base', 'import', 'packprocessor', 'transform', 'import', 'ttoken', 'tforconditionalgener', 'class', 'machinetranslationprocessor', 'packprocessor', 'translat', 'input', 'text', 'output', 'file', 'def', 'initi', 'self', 'resourc', 'config', 'super', 'initi', 'resourc', 'config', 'initi', 'token', 'model', 'model_nam', 'str', 'self', 'config', 'pretrained_model', 'self', 'token', 'ttoken', 'from_pretrain', 'model_nam', 'self', 'model', 'tforconditionalgener', 'from_pretrain', 'model_nam', 'self', 'task_prefix', 'translat', 'english', 'german', 'self', 'token', 'padding_sid', 'left', 'self', 'token', 'pad_token', 'self', 'token', 'eos_token', 'def', '_process', 'self', 'input_pack', 'datapack', 'end', 'machin', 'translat', 'input', 'self', 'token', 'self', 'task_prefix', 'sentenc', 'text', 'sentenc', 'input_pack', 'get', 'sentenc', 'return_tensor', 'pt', 'pad', 'true', 'output_sequ', 'self', 'model', 'gener', 'input_id', 'input', 'input_id', 'attention_mask', 'input', 'attention_mask', 'do_sampl', 'fals', 'output', 'join', 'self', 'token', 'batch_decod', 'output_sequ', 'skip_special_token', 'true', 'src_articl', 'articl', 'articl', 'input_pack', 'len', 'input_pack', 'text', 'src_articl', 'languag', 'en', 'input_pack', 'set_text', 'input_pack', 'text', 'n', 'n', 'output', 'tgt_articl', 'articl', 'articl', 'input_pack', 'len', 'input_pack', 'text', 'len', 'output', 'len', 'input_pack', 'text', 'tgt_articl', 'languag', 'de', 'classmethod', 'def', 'default_config', 'cl', 'return', 'pretrained_model', 'small', 'initi', 'need', 'compon', 'user', 'need', 'consid', 'initi', 'need', 'nlp', 'compon', 'infer', 'task', 'token', 'model', 'user', 'also', 'need', 'specifi', 'configur', 'config', 'dictionari', 'like', 'object', 'specifi', 'configur', 'compon', 'model', 'name', 'mt', 'oper', 'datapack', 'initi', 'alreadi', 'need', 'nlp', 'compon', 'need', 'consid', 'sever', 'mt', 'behavior', 'base', 'fort', 'datapack', 'pre', 'process', 'text', 'data', 'retriev', 'text', 'data', 'datapack', 'given', 'alreadi', 'read', 'data', 'data', 'sourc', 'sinc', 'better', 'perform', 'given', 'task', 'prompt', 'also', 'want', 'includ', 'prompt', 'data', 'token', 'transform', 'input', 'text', 'sequenc', 'token', 'token', 'id', 'gener', 'output', 'sequenc', 'model', 'decod', 'output', 'token', 'id', 'sentenc', 'use', 'token', 'gener', 'method', 'process', 'datapack', '_process', 'self', 'input_pack', 'datapack', 'token', 'input', 'text', 'use', 'model', 'class', 'make', 'infer', 'decod', 'output', 'token', 'id', 'final', 'write', 'output', 'target', 'file', 'pipelin', 'run', 'machin', 'translat', 'task', 'input_str', 'str', 'join', 'sentenc', 'pipelin', 'pipelin', 'pipelin', 'datapack', 'pipelin', 'set_read', 'stringread', 'pipelin', 'nltksentencesegment', 'pipelin', 'machinetranslationprocessor', 'pipelin', 'initi', 'datapack', 'pipelin', 'process_dataset', 'input_str', 'articl', 'datapack', 'get', 'articl', 'print', 'f', 'narticl', 'languag', 'articl', 'languag', 'articl', 'text', 'ontolog', 'datapack', 'provid', 'illustr', 'user', 'better', 'understand', 'intern', 'storag', 'datapack', 'see', 'text', 'data', 'sentenc', 'articl', 'store', 'span', 'annot', 'text', 'data', 'easili', 'effici', 'retriev', 'span', 'http', 'manag', 'multipl', 'data', 'object', 'multipack', 'better', 'way', 'store', 'sourc', 'target', 'text', 'section', 'learn', 'multipack', 'need', 'use', 'multipackth', 'step', 'output', 'datapack', 'good', 'hold', 'data', 'one', 'specif', 'piec', 'text', 'complic', 'pipelin', 'like', 'one', 'build', 'may', 'need', 'multipl', 'datapack', 'pass', 'along', 'pipelin', 'multipack', 'help', 'multipack', 'manag', 'set', 'datapack', 'index', 'name', 'multipackbox', 'simpl', 'fort', 'processor', 'convert', 'datapack', 'multipack', 'make', 'datapack', 'name', 'specifi', 'via', 'config', 'use', 'wrap', 'datapack', 'contain', 'sourc', 'sentenc', 'http', 'fort', 'data', 'import', 'multipack', 'fort', 'processor', 'base', 'import', 'multipackprocessor', 'fort', 'data', 'caster', 'import', 'multipackbox', 'class', 'machinetranslationmpprocessor', 'multipackprocessor', 'translat', 'input', 'text', 'output', 'file', 'def', 'initi', 'self', 'resourc', 'config', 'super', 'initi', 'resourc', 'config', 'initi', 'token', 'model', 'model_nam', 'str', 'self', 'config', 'pretrained_model', 'self', 'token', 'ttoken', 'from_pretrain', 'model_nam', 'self', 'model', 'tforconditionalgener', 'from_pretrain', 'model_nam', 'self', 'task_prefix', 'translat', 'english', 'german', 'self', 'token', 'padding_sid', 'left', 'self', 'token', 'pad_token', 'self', 'token', 'eos_token', 'def', '_process', 'self', 'input_pack', 'multipack', 'source_pack', 'datapack', 'input_pack', 'get_pack', 'sourc', 'target_pack', 'datapack', 'input_pack', 'add_pack', 'target', 'end', 'machin', 'translat', 'input', 'self', 'token', 'self', 'task_prefix', 'sentenc', 'text', 'sentenc', 'source_pack', 'get', 'sentenc', 'return_tensor', 'pt', 'pad', 'true', 'output_sequ', 'self', 'model', 'gener', 'input_id', 'input', 'input_id', 'attention_mask', 'input', 'attention_mask', 'do_sampl', 'fals', 'annot', 'sourc', 'articl', 'src_articl', 'articl', 'articl', 'source_pack', 'len', 'source_pack', 'text', 'src_articl', 'languag', 'en', 'annot', 'sentenc', 'output', 'self', 'token', 'batch_decod', 'output_sequ', 'skip_special_token', 'true', 'target_pack', 'set_text', 'target_pack', 'text', 'output', 'text_length', 'int', 'len', 'target_pack', 'text', 'sentenc', 'target_pack', 'text_length', 'len', 'output', 'text_length', 'annot', 'target', 'articl', 'tgt_articl', 'articl', 'articl', 'target_pack', 'len', 'target_pack', 'text', 'tgt_articl', 'languag', 'de', 'classmethod', 'def', 'default_config', 'cl', 'return', 'pretrained_model', 'small', 'machinetranslationmpprocessor', 'write', 'output', 'sentenc', 'target', 'datapack', 'http', 'let', 'tri', 'creat', 'pipelin', 'util', 'multipack', 'manag', 'text', 'differ', 'languag', 'nlp', 'pipelin', 'pipelin', 'datapack', 'nlp', 'set_read', 'stringread', 'nlp', 'nltksentencesegment', 'nlp', 'multipackbox', 'config', 'pack_nam', 'sourc', 'nlp', 'machinetranslationmpprocessor', 'config', 'pretrained_model', 'small', 'nlp', 'initi', 'multipack', 'nlp', 'process_dataset', 'input_str', 'pack_nam', 'sourc', 'target', 'articl', 'multipack', 'get_pack', 'pack_nam', 'get', 'articl', 'print', 'f', 'narticl', 'languag', 'articl', 'languag', 'sentenc', 'articl', 'get', 'sentenc', 'print', 'sentenc', 'text', 'ontolog', 'multipack', 'comparison', 'illustr', 'intern', 'storag', 'multipack', 'see', 'multipack', 'wrap', 'one', 'sourc', 'datapack', 'one', 'target', 'datapack', 'articl', 'span', 'base', 'two', 'separ', 'datapack', 'text', 'http', 'handl', 'practic', 'request', 'handl', 'structur', 'like', 'html', 'data', 'section', 'learn', 'build', 'translat', 'manag', 'system', 'preserv', 'structur', 'like', 'html', 'machin', 'translat', 'select', 'specif', 'datapack', 'multipack', 'processingin', 'previou', 'step', 'input', 'string', 'simpl', 'paragraph', 'made', 'sever', 'sentenc', 'howev', 'mani', 'case', 'might', 'need', 'handl', 'data', 'structur', 'inform', 'html', 'xml', 'input', 'string', 'raw', 'html', 'data', 'machin', 'translat', 'pipelin', 'may', 'work', 'expect', 'html_input', 'str', 'beginn', 'bbq', 'class', 'want', 'get', 'better', 'make', 'delici', 'bbq', 'opportun', 'put', 'calendar', 'thursday', 'septemb', 'nd', 'join', 'world', 'class', 'bbq', 'champion', 'toni', 'balay', 'lonestar', 'smoke', 'ranger', 'nlp', 'initi', 'multipack', 'nlp', 'process_dataset', 'html_input', 'print', 'sourc', 'text', 'multipack', 'get_pack', 'sourc', 'text', 'print', 'ntarget', 'text', 'multipack', 'get_pack', 'target', 'text', 'see', 'origin', 'html', 'structur', 'broken', 'translat', 'output', 'order', 'handl', 'structur', 'data', 'like', 'html', 'need', 'updat', 'current', 'design', 'pipelin', 'luckili', 'fort', 'pipelin', 'highli', 'modular', 'simpli', 'insert', 'two', 'processor', 'without', 'updat', 'previou', 'pipelin', 'first', 'need', 'html', 'cleaner', 'pars', 'html', 'tag', 'input', 'string', 'pictur', 'show', 'effect', 'tag', 'remov', 'http', 'translat', 'finish', 'also', 'need', 'recov', 'html', 'structur', 'unstructur', 'translat', 'output', 'pictur', 'show', 'replac', 'one', 'sourc', 'sentenc', 'one', 'target', 'sentenc', 'given', 'target', 'sentenc', 'readi', 'http', 'fort', 'data', 'import', 'namematchselector', 'fort', 'data', 'reader', 'html_reader', 'import', 'fortehtmlpars', 'class', 'htmltagclean', 'multipackprocessor', 'def', 'initi', 'self', 'resourc', 'config', 'super', 'initi', 'resourc', 'config', 'self', '_parser', 'fortehtmlpars', 'def', '_process', 'self', 'input_pack', 'multipack', 'raw_pack', 'datapack', 'input_pack', 'get_pack', 'raw', 'source_pack', 'datapack', 'input_pack', 'add_pack', 'sourc', 'self', '_parser', 'feed', 'raw_pack', 'text', 'cleaned_text', 'str', 'raw_pack', 'text', 'span', '_', 'self', '_parser', 'span', 'cleaned_text', 'cleaned_text', 'replac', 'raw_pack', 'text', 'span', 'begin', 'span', 'end', 'source_pack', 'set_text', 'cleaned_text', 'class', 'htmltagrecoveri', 'multipackprocessor', 'def', '_process', 'self', 'input_pack', 'multipack', 'raw_pack', 'datapack', 'input_pack', 'get_pack', 'raw', 'source_pack', 'datapack', 'input_pack', 'get_pack', 'sourc', 'target_pack', 'datapack', 'input_pack', 'get_pack', 'target', 'result_pack', 'datapack', 'input_pack', 'add_pack', 'result', 'result_text', 'str', 'raw_pack', 'text', 'sent_src', 'sent_tgt', 'zip', 'source_pack', 'get', 'sentenc', 'target_pack', 'get', 'sentenc', 'result_text', 'result_text', 'replac', 'sent_src', 'text', 'sent_tgt', 'text', 'result_pack', 'set_text', 'result_text', 'abl', 'creat', 'translat', 'manag', 'system', 'insert', 'two', 'processor', 'introduc', 'previou', 'machin', 'translat', 'pipelin', 'pipelin', 'html', 'handl', 'pipelin', 'pipelin', 'pipelin', 'datapack', 'pipelin', 'set_read', 'stringread', 'pipelin', 'multipackbox', 'config', 'pack_nam', 'raw', 'pipelin', 'htmltagclean', 'pipelin', 'nltksentencesegment', 'selector', 'namematchselector', 'selector_config', 'select_nam', 'sourc', 'pipelin', 'machinetranslationmpprocessor', 'config', 'pretrained_model', 'small', 'pipelin', 'htmltagrecoveri', 'pipelin', 'initi', 'multipack', 'pipelin', 'process_dataset', 'html_input', 'print', 'multipack', 'get_pack', 'raw', 'text', 'print', 'multipack', 'get_pack', 'result', 'text', 'selector', 'code', 'snippet', 'util', 'namematchselector', 'select', 'one', 'specif', 'datapack', 'multipack', 'base', 'refer', 'name', 'select_nam', 'allow', 'nltksentencesegment', 'process', 'specifi', 'datapack', 'replac', 'translat', 'model', 'remot', 'translat', 'servic', 'replac', 'mt', 'model', 'onlin', 'translat', 'api', 'section', 'learn', 'use', 'differ', 'translat', 'servicefort', 'also', 'allow', 'us', 'updat', 'translat', 'model', 'integr', 'seamlessli', 'origin', 'pipelin', 'exampl', 'want', 'offload', 'translat', 'task', 'onlin', 'servic', 'need', 'updat', 'translat', 'processor', 'need', 'chang', 'compon', 'pipelin', 'get', 'api', 'key', 'follow', 'instruct', 'http', 'api_key', 'input', 'enter', 'api', 'key', 'import', 'request', 'import', 'uuid', 'class', 'onlinemachinetranslationmpprocessor', 'multipackprocessor', 'translat', 'input', 'text', 'output', 'file', 'use', 'onlin', 'translat', 'api', 'def', 'initi', 'self', 'resourc', 'config', 'super', 'initi', 'resourc', 'config', 'self', 'url', 'config', 'endpoint', 'config', 'path', 'self', 'from_lang', 'config', 'from_lang', 'self', 'to_lang', 'config', 'to_lang', 'self', 'subscription_key', 'config', 'subscription_key', 'self', 'subscription_region', 'config', 'subscription_region', 'def', '_process', 'self', 'input_pack', 'multipack', 'source_pack', 'datapack', 'input_pack', 'get_pack', 'sourc', 'target_pack', 'datapack', 'input_pack', 'add_pack', 'target', 'param', 'api', 'version', 'en', 'de', 'build', 'request', 'header', 'ocp', 'apim', 'subscript', 'key', 'self', 'subscription_key', 'ocp', 'apim', 'subscript', 'region', 'self', 'subscription_region', 'content', 'type', 'applic', 'json', 'x', 'clienttraceid', 'str', 'uuid', 'uuid', 'pass', 'one', 'object', 'bodi', 'bodi', 'text', 'source_pack', 'text', 'request', 'request', 'post', 'self', 'url', 'param', 'param', 'header', 'header', 'json', 'bodi', 'result', 'request', 'json', 'target_pack', 'set_text', 'join', 'tran', 'text', 'tran', 'result', 'translat', 'classmethod', 'def', 'default_config', 'cl', 'return', 'from_lang', 'en', 'to_lang', 'de', 'endpoint', 'http', 'path', 'translat', 'subscription_key', 'none', 'subscription_region', 'westu', 'x', 'clienttraceid', 'str', 'uuid', 'uuid', 'nlp', 'pipelin', 'pipelin', 'datapack', 'nlp', 'set_read', 'stringread', 'nlp', 'nltksentencesegment', 'nlp', 'multipackbox', 'config', 'pack_nam', 'sourc', 'nlp', 'onlinemachinetranslationmpprocessor', 'config', 'from_lang', 'en', 'to_lang', 'de', 'endpoint', 'http', 'path', 'translat', 'subscription_key', 'api_key', 'subscription_region', 'westu', 'x', 'clienttraceid', 'str', 'uuid', 'uuid', 'nlp', 'initi', 'multipack', 'nlp', 'process_dataset', 'input_str', 'print', 'sourc', 'text', 'multipack', 'get_pack', 'sourc', 'text', 'print', 'ntarget', 'text', 'multipack', 'get_pack', 'target', 'text', 'save', 'load', 'pipelin', 'save', 'whole', 'pipelin', 'save', 'section', 'learn', 'export', 'import', 'fort', 'pipelinefort', 'also', 'allow', 'us', 'save', 'pipelin', 'disk', 'serial', 'whole', 'pipelin', 'gener', 'intermedi', 'represent', 'load', 'later', 'mayb', 'differ', 'machin', 'import', 'os', 'save_path', 'str', 'os', 'path', 'join', 'os', 'path', 'dirnam', 'os', 'path', 'abspath', 'pipelin', 'yml', 'nlp', 'save', 'save_path', 'open', 'save_path', 'r', 'f', 'print', 'f', 'read', 'pipelin', 'save', 'tri', 'load', 'pipelin', 'see', 'still', 'function', 'expect', 'new_nlp', 'pipelin', 'pipelin', 'new_nlp', 'init_from_config_path', 'save_path', 'new_nlp', 'initi', 'multipack', 'new_nlp', 'process_dataset', 'input_str', 'print', 'sourc', 'text', 'multipack', 'get_pack', 'sourc', 'text', 'print', 'ntarget', 'text', 'multipack', 'get_pack', 'target', 'text', 'build', 'machin', 'translat', 'system', 'fort']"
227,249,249,AbjectDrink3276,vy3bon,[D] When will Neurips 2022 reviews be released?,I cant recall what day the last couple of years reviews have been released. I know that the review period is closed and so its only a matter of time just wondering if anyone has any idea?,7,6,2022-07-13 16:31:37, d  when will neurips  reviews be released ,i cant recall what day the last couple of years reviews have been released  i know that the review period is closed and so its only a matter of time just wondering if anyone has any idea ,cant recall day last couple years reviews released know review period closed matter time wondering anyone idea,neurips reviews released,neurips reviews releasedcant recall day last couple years reviews released know review period closed matter time wondering anyone idea,"['neurips', 'reviews', 'releasedcant', 'recall', 'day', 'last', 'couple', 'years', 'reviews', 'released', 'know', 'review', 'period', 'closed', 'matter', 'time', 'wondering', 'anyone', 'idea']","['neurip', 'review', 'releasedc', 'recal', 'day', 'last', 'coupl', 'year', 'review', 'releas', 'know', 'review', 'period', 'close', 'matter', 'time', 'wonder', 'anyon', 'idea']"
228,251,251,Adolphins,vxqv3l,Why do Transformers scale so well? [D]," When you hear people talk about large models, they're usually talking about transformers. What about this architecture has allowed it to be scaled? Have people tried making really large CNNs or RNNs (or just regular MLPs) before?",15,31,2022-07-13 04:16:39,why do transformers scale so well   d , when you hear people talk about large models  they re usually talking about transformers  what about this architecture has allowed it to be scaled  have people tried making really large cnns or rnns  or just regular mlps  before ,hear people talk large models usually talking transformers architecture allowed scaled people tried making really large cnns rnns regular mlps,transformers scale well,transformers scale wellhear people talk large models usually talking transformers architecture allowed scaled people tried making really large cnns rnns regular mlps,"['transformers', 'scale', 'wellhear', 'people', 'talk', 'large', 'models', 'usually', 'talking', 'transformers', 'architecture', 'allowed', 'scaled', 'people', 'tried', 'making', 'really', 'large', 'cnns', 'rnns', 'regular', 'mlps']","['transform', 'scale', 'wellhear', 'peopl', 'talk', 'larg', 'model', 'usual', 'talk', 'transform', 'architectur', 'allow', 'scale', 'peopl', 'tri', 'make', 'realli', 'larg', 'cnn', 'rnn', 'regular', 'mlp']"
229,252,252,Singularian2501,vxn07k,[R] Deep Hierarchical Planning from Pixels ( Director ) - Google 2022,"Paper: [https://arxiv.org/pdf/2206.04114.pdf](https://arxiv.org/pdf/2206.04114.pdf)

[https://ai.googleblog.com/2022/07/deep-hierarchical-planning-from-pixels.html?m=1](https://ai.googleblog.com/2022/07/deep-hierarchical-planning-from-pixels.html?m=1)

Abstract: 

>Intelligent agents need to select long sequences of actions to solve complex tasks. While humans easily break down tasks into subgoals and reach them through millions of muscle commands, current artificial intelligence is limited to tasks with horizons of a few hundred decisions, despite large compute budgets. Research on hierarchical reinforcement learning aims to overcome this limitation but has proven to be challenging, current methods rely on manually specified goal spaces or subtasks, and no general solution exists. We introduce Director, a practical method for learning hierarchical behaviors directly from pixels by planning inside the latent space of a learned world model. The high-level policy maximizes task and exploration rewards by selecting latent goals and the low-level policy learns to achieve the goals. Despite operating in latent space, the decisions are interpretable because the world model can decode goals into images for visualization. Director outperforms exploration methods on tasks with sparse rewards, including 3D maze traversal with a quadruped robot from an egocentric camera and proprioception, without access to the global position or top-down view that was used by prior work. Director also learns successful behaviors across a wide range of environments, including visual control, Atari games, and DMLab levels. 

https://preview.redd.it/lbvp6r7wl7b91.jpg?width=1034&format=pjpg&auto=webp&s=e9a28b2589eb41148de5b5bb6c4700354e795ae4

https://preview.redd.it/kikyu54xl7b91.jpg?width=1041&format=pjpg&auto=webp&s=b893e54790c420780c79819e689a9666ea95bf86

https://preview.redd.it/m5wc4tdxl7b91.jpg?width=1007&format=pjpg&auto=webp&s=17d7edf3cf7021ceabd3327d9408f1c3bd913c03

https://preview.redd.it/9cwsn9oxl7b91.jpg?width=1015&format=pjpg&auto=webp&s=c96348f290e9ff76c7003c51c97ac86705b77068",1,35,2022-07-13 01:07:09, r  deep hierarchical planning from pixels   director     google ,paper   https  https abstract   intelligent agents need to select long sequences of actions to solve complex tasks  while humans easily break down tasks into subgoals and reach them through millions of muscle commands  current artificial intelligence is limited to tasks with horizons of a few hundred decisions  despite large compute budgets  research on hierarchical reinforcement learning aims to overcome this limitation but has proven to be challenging  current methods rely on manually specified goal spaces or subtasks  and no general solution exists  we introduce director  a practical method for learning hierarchical behaviors directly from pixels by planning inside the latent space of a learned world model  the high level policy maximizes task and exploration rewards by selecting latent goals and the low level policy learns to achieve the goals  despite operating in latent space  the decisions are interpretable because the world model can decode goals into images for visualization  director outperforms exploration methods on tasks with sparse rewards  including d maze traversal with a quadruped robot from an egocentric camera and proprioception  without access to the global position or top down view that was used by prior work  director also learns successful behaviors across a wide range of environments  including visual control  atari games  and dmlab levels  https https https https   preview redd it cwsnoxlb jpg width  format pjpg auto webp s cfeffcccacb,paper https https abstract intelligent agents need select long sequences actions solve complex tasks humans easily break tasks subgoals reach millions muscle commands current artificial intelligence limited tasks horizons hundred decisions despite large compute budgets research hierarchical reinforcement learning aims overcome limitation proven challenging current methods rely manually specified goal spaces subtasks general solution exists introduce director practical method learning hierarchical behaviors directly pixels planning inside latent space learned world model high level policy maximizes task exploration rewards selecting latent goals low level policy learns achieve goals despite operating latent space decisions interpretable world model decode goals images visualization director outperforms exploration methods tasks sparse rewards including maze traversal quadruped robot egocentric camera proprioception without access global position top view used prior work director also learns successful behaviors across wide range environments including visual control atari games dmlab levels https https https https preview redd cwsnoxlb jpg width format pjpg auto webp cfeffcccacb,r deep hierarchical planning pixels director google,r deep hierarchical planning pixels director googlepaper https https abstract intelligent agents need select long sequences actions solve complex tasks humans easily break tasks subgoals reach millions muscle commands current artificial intelligence limited tasks horizons hundred decisions despite large compute budgets research hierarchical reinforcement learning aims overcome limitation proven challenging current methods rely manually specified goal spaces subtasks general solution exists introduce director practical method learning hierarchical behaviors directly pixels planning inside latent space learned world model high level policy maximizes task exploration rewards selecting latent goals low level policy learns achieve goals despite operating latent space decisions interpretable world model decode goals images visualization director outperforms exploration methods tasks sparse rewards including maze traversal quadruped robot egocentric camera proprioception without access global position top view used prior work director also learns successful behaviors across wide range environments including visual control atari games dmlab levels https https https https preview redd cwsnoxlb jpg width format pjpg auto webp cfeffcccacb,"['r', 'deep', 'hierarchical', 'planning', 'pixels', 'director', 'googlepaper', 'https', 'https', 'abstract', 'intelligent', 'agents', 'need', 'select', 'long', 'sequences', 'actions', 'solve', 'complex', 'tasks', 'humans', 'easily', 'break', 'tasks', 'subgoals', 'reach', 'millions', 'muscle', 'commands', 'current', 'artificial', 'intelligence', 'limited', 'tasks', 'horizons', 'hundred', 'decisions', 'despite', 'large', 'compute', 'budgets', 'research', 'hierarchical', 'reinforcement', 'learning', 'aims', 'overcome', 'limitation', 'proven', 'challenging', 'current', 'methods', 'rely', 'manually', 'specified', 'goal', 'spaces', 'subtasks', 'general', 'solution', 'exists', 'introduce', 'director', 'practical', 'method', 'learning', 'hierarchical', 'behaviors', 'directly', 'pixels', 'planning', 'inside', 'latent', 'space', 'learned', 'world', 'model', 'high', 'level', 'policy', 'maximizes', 'task', 'exploration', 'rewards', 'selecting', 'latent', 'goals', 'low', 'level', 'policy', 'learns', 'achieve', 'goals', 'despite', 'operating', 'latent', 'space', 'decisions', 'interpretable', 'world', 'model', 'decode', 'goals', 'images', 'visualization', 'director', 'outperforms', 'exploration', 'methods', 'tasks', 'sparse', 'rewards', 'including', 'maze', 'traversal', 'quadruped', 'robot', 'egocentric', 'camera', 'proprioception', 'without', 'access', 'global', 'position', 'top', 'view', 'used', 'prior', 'work', 'director', 'also', 'learns', 'successful', 'behaviors', 'across', 'wide', 'range', 'environments', 'including', 'visual', 'control', 'atari', 'games', 'dmlab', 'levels', 'https', 'https', 'https', 'https', 'preview', 'redd', 'cwsnoxlb', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'cfeffcccacb']","['r', 'deep', 'hierarch', 'plan', 'pixel', 'director', 'googlepap', 'http', 'http', 'abstract', 'intellig', 'agent', 'need', 'select', 'long', 'sequenc', 'action', 'solv', 'complex', 'task', 'human', 'easili', 'break', 'task', 'subgoal', 'reach', 'million', 'muscl', 'command', 'current', 'artifici', 'intellig', 'limit', 'task', 'horizon', 'hundr', 'decis', 'despit', 'larg', 'comput', 'budget', 'research', 'hierarch', 'reinforc', 'learn', 'aim', 'overcom', 'limit', 'proven', 'challeng', 'current', 'method', 'reli', 'manual', 'specifi', 'goal', 'space', 'subtask', 'gener', 'solut', 'exist', 'introduc', 'director', 'practic', 'method', 'learn', 'hierarch', 'behavior', 'directli', 'pixel', 'plan', 'insid', 'latent', 'space', 'learn', 'world', 'model', 'high', 'level', 'polici', 'maxim', 'task', 'explor', 'reward', 'select', 'latent', 'goal', 'low', 'level', 'polici', 'learn', 'achiev', 'goal', 'despit', 'oper', 'latent', 'space', 'decis', 'interpret', 'world', 'model', 'decod', 'goal', 'imag', 'visual', 'director', 'outperform', 'explor', 'method', 'task', 'spars', 'reward', 'includ', 'maze', 'travers', 'quadrup', 'robot', 'egocentr', 'camera', 'propriocept', 'without', 'access', 'global', 'posit', 'top', 'view', 'use', 'prior', 'work', 'director', 'also', 'learn', 'success', 'behavior', 'across', 'wide', 'rang', 'environ', 'includ', 'visual', 'control', 'atari', 'game', 'dmlab', 'level', 'http', 'http', 'http', 'http', 'preview', 'redd', 'cwsnoxlb', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'cfeffcccacb']"
230,253,253,TemppaHemppa,vxvyrm,[D] Labeling novel view synthesis for object detection,"Hey all,

I've been following the exciting progress of NeRFs, and it lead to me wonder whether there are research on generating novel 2D views from 3D representation, and labeling those examples. I find works for image classification under Novel View Synthesis topics, but for object detection I just can't find anything.

Wouldn't it be possible to label 2D training images, construct 3D representation, and use it for generating novel 2D views with corresponding labelings? I see this as highly useful for the object detection domain, where labeling often requires a lot of manual work leading to small datasets and non-robust object representations.

Please note if I'm missing something out here.",0,4,2022-07-13 09:00:45, d  labeling novel view synthesis for object detection,hey all i ve been following the exciting progress of nerfs  and it lead to me wonder whether there are research on generating novel d views from d representation  and labeling those examples  i find works for image classification under novel view synthesis topics  but for object detection i just can t find anything wouldn t it be possible to label d training images  construct d representation  and use it for generating novel d views with corresponding labelings  i see this as highly useful for the object detection domain  where labeling often requires a lot of manual work leading to small datasets and non robust object representations please note if i m missing something out here ,hey following exciting progress nerfs lead wonder whether research generating novel views representation labeling examples find works image classification novel view synthesis topics object detection find anything possible label training images construct representation use generating novel views corresponding labelings see highly useful object detection domain labeling often requires lot manual work leading small datasets non robust object representations please note missing something,labeling novel view synthesis object detection,labeling novel view synthesis object detectionhey following exciting progress nerfs lead wonder whether research generating novel views representation labeling examples find works image classification novel view synthesis topics object detection find anything possible label training images construct representation use generating novel views corresponding labelings see highly useful object detection domain labeling often requires lot manual work leading small datasets non robust object representations please note missing something,"['labeling', 'novel', 'view', 'synthesis', 'object', 'detectionhey', 'following', 'exciting', 'progress', 'nerfs', 'lead', 'wonder', 'whether', 'research', 'generating', 'novel', 'views', 'representation', 'labeling', 'examples', 'find', 'works', 'image', 'classification', 'novel', 'view', 'synthesis', 'topics', 'object', 'detection', 'find', 'anything', 'possible', 'label', 'training', 'images', 'construct', 'representation', 'use', 'generating', 'novel', 'views', 'corresponding', 'labelings', 'see', 'highly', 'useful', 'object', 'detection', 'domain', 'labeling', 'often', 'requires', 'lot', 'manual', 'work', 'leading', 'small', 'datasets', 'non', 'robust', 'object', 'representations', 'please', 'note', 'missing', 'something']","['label', 'novel', 'view', 'synthesi', 'object', 'detectionhey', 'follow', 'excit', 'progress', 'nerf', 'lead', 'wonder', 'whether', 'research', 'gener', 'novel', 'view', 'represent', 'label', 'exampl', 'find', 'work', 'imag', 'classif', 'novel', 'view', 'synthesi', 'topic', 'object', 'detect', 'find', 'anyth', 'possibl', 'label', 'train', 'imag', 'construct', 'represent', 'use', 'gener', 'novel', 'view', 'correspond', 'label', 'see', 'highli', 'use', 'object', 'detect', 'domain', 'label', 'often', 'requir', 'lot', 'manual', 'work', 'lead', 'small', 'dataset', 'non', 'robust', 'object', 'represent', 'pleas', 'note', 'miss', 'someth']"
231,254,254,paulcjh,vx89nj,[P] DALL·E Mini & Mega demo and production API,"Hi all - we've just put out the community DALL·E models on Playgrounds.ai:

Mega - [https://playgrounds.ai/models/dalle-mega](https://playgrounds.ai/models/dalle-mega?utm_source=reddit&utm_medium=post&utm_campaign=dalle_1&utm_id=c.1)

Mini - [https://playgrounds.ai/models/dalle-mini](https://playgrounds.ai/models/dalle-mini?utm_source=reddit&utm_medium=post&utm_campaign=dalle_1&utm_id=c.1)

You can use this models via API on PipelineCloud here: [https://dashboard.pipeline.ai](https://dashboard.pipeline.ai) 

The per image cost for the models are approx:

Mega - $0.0014 (\~10s of compute for 4 images)

Mini - $0.00062 (\~10s of compute for 9 images)

This is for people who want to use these models in their apps/products or just play around with the demos and have fun!

https://preview.redd.it/zre4tf40a4b91.png?width=3114&format=png&auto=webp&s=68d8c10236cdd23c642e581d479d479b38fede84",32,171,2022-07-12 13:47:35, p  dall e mini   mega demo and production api,hi all   we ve just put out the community dall e models on playgrounds ai mega    https mini    https you can use this models via api on pipelinecloud here   https the per image cost for the models are approx mega         s of compute for  images mini         s of compute for  images this is for people who want to use these models in their apps products or just play around with the demos and have fun https   preview redd it zretfab png width  format png auto webp s dccddceddbfede,hi put community dall e models playgrounds ai mega https mini https use models via api pipelinecloud https per image cost models approx mega compute images mini compute images people want use models apps products play around demos fun https preview redd zretfab png width format png auto webp dccddceddbfede,p dall e mini mega demo production api,p dall e mini mega demo production apihi put community dall e models playgrounds ai mega https mini https use models via api pipelinecloud https per image cost models approx mega compute images mini compute images people want use models apps products play around demos fun https preview redd zretfab png width format png auto webp dccddceddbfede,"['p', 'dall', 'e', 'mini', 'mega', 'demo', 'production', 'apihi', 'put', 'community', 'dall', 'e', 'models', 'playgrounds', 'ai', 'mega', 'https', 'mini', 'https', 'use', 'models', 'via', 'api', 'pipelinecloud', 'https', 'per', 'image', 'cost', 'models', 'approx', 'mega', 'compute', 'images', 'mini', 'compute', 'images', 'people', 'want', 'use', 'models', 'apps', 'products', 'play', 'around', 'demos', 'fun', 'https', 'preview', 'redd', 'zretfab', 'png', 'width', 'format', 'png', 'auto', 'webp', 'dccddceddbfede']","['p', 'dall', 'e', 'mini', 'mega', 'demo', 'product', 'apihi', 'put', 'commun', 'dall', 'e', 'model', 'playground', 'ai', 'mega', 'http', 'mini', 'http', 'use', 'model', 'via', 'api', 'pipelinecloud', 'http', 'per', 'imag', 'cost', 'model', 'approx', 'mega', 'comput', 'imag', 'mini', 'comput', 'imag', 'peopl', 'want', 'use', 'model', 'app', 'product', 'play', 'around', 'demo', 'fun', 'http', 'preview', 'redd', 'zretfab', 'png', 'width', 'format', 'png', 'auto', 'webp', 'dccddceddbfed']"
232,255,255,Rafaelkoll,vy3p7q,[D] Ensemble regression model - based on models trained on different feature spaces,"What is the best method for constructing an ensemble regression model from numerous KNN regression models that were trained on slightly **different feature spaces**?

I can't only use the features that they have in common.",2,1,2022-07-13 16:49:26, d  ensemble regression model   based on models trained on different feature spaces,what is the best method for constructing an ensemble regression model from numerous knn regression models that were trained on slightly   different feature spaces   i can t only use the features that they have in common ,best method constructing ensemble regression model numerous knn regression models trained slightly different feature spaces use features common,ensemble regression model based models trained different feature spaces,ensemble regression model based models trained different feature spacesbest method constructing ensemble regression model numerous knn regression models trained slightly different feature spaces use features common,"['ensemble', 'regression', 'model', 'based', 'models', 'trained', 'different', 'feature', 'spacesbest', 'method', 'constructing', 'ensemble', 'regression', 'model', 'numerous', 'knn', 'regression', 'models', 'trained', 'slightly', 'different', 'feature', 'spaces', 'use', 'features', 'common']","['ensembl', 'regress', 'model', 'base', 'model', 'train', 'differ', 'featur', 'spacesbest', 'method', 'construct', 'ensembl', 'regress', 'model', 'numer', 'knn', 'regress', 'model', 'train', 'slightli', 'differ', 'featur', 'space', 'use', 'featur', 'common']"
233,256,256,EUMETSAT,vxzcsy,[News] Jupyter Notebook competition - 2 weeks left to enter!,"Are you passionate about [\#coding](https://www.facebook.com/hashtag/coding?__eep__=6&__cft__[0]=AZUaWWSvEyv-U2rnLNbvP3MseROHr1LlG-GsK0bDW9_hBJM-ZHHRlfwvzn2uevBI3sbZw8b7gtV_YAImoKU3IYIdXD_DOzn_L8sgspuXrmZx9p_92-MfaFbtnNcw_j1KtsdoMBkjxMUYPc-hia7qEmktYC4-yEbZREPj2cqkLfIdd10AoF2cSznIA_Qo7I7bmLiyPrnuUPY55hgWW6UO8oUCay-rpP9p0bEKaKsgWBU6XUmgpR2UzpKbjLzC2ZmzUZb3D_DlJlQsaLTWwRBGXOGy&__tn__=*NK-R), [\#DataScience](https://www.facebook.com/hashtag/datascience?__eep__=6&__cft__[0]=AZUaWWSvEyv-U2rnLNbvP3MseROHr1LlG-GsK0bDW9_hBJM-ZHHRlfwvzn2uevBI3sbZw8b7gtV_YAImoKU3IYIdXD_DOzn_L8sgspuXrmZx9p_92-MfaFbtnNcw_j1KtsdoMBkjxMUYPc-hia7qEmktYC4-yEbZREPj2cqkLfIdd10AoF2cSznIA_Qo7I7bmLiyPrnuUPY55hgWW6UO8oUCay-rpP9p0bEKaKsgWBU6XUmgpR2UzpKbjLzC2ZmzUZb3D_DlJlQsaLTWwRBGXOGy&__tn__=*NK-R) or [\#EarthObservation](https://www.facebook.com/hashtag/earthobservation?__eep__=6&__cft__[0]=AZUaWWSvEyv-U2rnLNbvP3MseROHr1LlG-GsK0bDW9_hBJM-ZHHRlfwvzn2uevBI3sbZw8b7gtV_YAImoKU3IYIdXD_DOzn_L8sgspuXrmZx9p_92-MfaFbtnNcw_j1KtsdoMBkjxMUYPc-hia7qEmktYC4-yEbZREPj2cqkLfIdd10AoF2cSznIA_Qo7I7bmLiyPrnuUPY55hgWW6UO8oUCay-rpP9p0bEKaKsgWBU6XUmgpR2UzpKbjLzC2ZmzUZb3D_DlJlQsaLTWwRBGXOGy&__tn__=*NK-R)? 📷 

Don't miss out on the chance to showcase your skills and develop new Jupyter Notebooks using [\#Copernicus](https://www.facebook.com/hashtag/copernicus?__eep__=6&__cft__[0]=AZUaWWSvEyv-U2rnLNbvP3MseROHr1LlG-GsK0bDW9_hBJM-ZHHRlfwvzn2uevBI3sbZw8b7gtV_YAImoKU3IYIdXD_DOzn_L8sgspuXrmZx9p_92-MfaFbtnNcw_j1KtsdoMBkjxMUYPc-hia7qEmktYC4-yEbZREPj2cqkLfIdd10AoF2cSznIA_Qo7I7bmLiyPrnuUPY55hgWW6UO8oUCay-rpP9p0bEKaKsgWBU6XUmgpR2UzpKbjLzC2ZmzUZb3D_DlJlQsaLTWwRBGXOGy&__tn__=*NK-R) data, whilst also being in with a chance of winning cash  📷 prizes! 

Sign up before 31 July at: [https://notebook.wekeo.eu/](https://notebook.wekeo.eu/)

https://preview.redd.it/1uwo4ccv4bb91.png?width=1920&format=png&auto=webp&s=18af6de36526d30585d0027d8445f56ed4302516",1,2,2022-07-13 12:50:09, news  jupyter notebook competition    weeks left to enter ,are you passionate about    coding  https don t miss out on the chance to showcase your skills and develop new jupyter notebooks using    copernicus  https sign up before  july at   https https   preview redd it uwoccvbb png width  format png auto webp s afdedddfed,passionate coding https miss chance showcase skills develop jupyter notebooks using copernicus https sign july https https preview redd uwoccvbb png width format png auto webp afdedddfed,news jupyter notebook competition weeks left enter,news jupyter notebook competition weeks left enterpassionate coding https miss chance showcase skills develop jupyter notebooks using copernicus https sign july https https preview redd uwoccvbb png width format png auto webp afdedddfed,"['news', 'jupyter', 'notebook', 'competition', 'weeks', 'left', 'enterpassionate', 'coding', 'https', 'miss', 'chance', 'showcase', 'skills', 'develop', 'jupyter', 'notebooks', 'using', 'copernicus', 'https', 'sign', 'july', 'https', 'https', 'preview', 'redd', 'uwoccvbb', 'png', 'width', 'format', 'png', 'auto', 'webp', 'afdedddfed']","['news', 'jupyt', 'notebook', 'competit', 'week', 'left', 'enterpassion', 'code', 'http', 'miss', 'chanc', 'showcas', 'skill', 'develop', 'jupyt', 'notebook', 'use', 'copernicu', 'http', 'sign', 'juli', 'http', 'http', 'preview', 'redd', 'uwoccvbb', 'png', 'width', 'format', 'png', 'auto', 'webp', 'afdedddf']"
234,257,257,takeafuckinsipp,vxl0ae,[P] Ensembling with multiple independent time-series,"I'm working on a project in which I have N independent time-series datasets, which can be thought of like prices for different currencies/crypto-coins etc. I've structured my dataset such that for each training batch, the first dimension is the index of the time-series. 

I have a prediction model based on a couple papers, which takes in a sliding window and outputs a prediction of the time series. 

**Question: What is the best way to build an ensemble of this model, such that predictions for each time-series aren't affected by the others?**

When I say ""aren't affected by other time series"", i mean that the average of predictions of two different models trained on two different series might not be as accurate/precise as the predictions by themselves (without averaging)...

Should I have N different models for each time series and just average the predictions? Should I have some K number of models with different loss functions and then average those? 

What would be a good strategy?",5,9,2022-07-12 23:38:28, p  ensembling with multiple independent time series,i m working on a project in which i have n independent time series datasets  which can be thought of like prices for different currencies crypto coins etc  i ve structured my dataset such that for each training batch  the first dimension is the index of the time series  i have a prediction model based on a couple papers  which takes in a sliding window and outputs a prediction of the time series    question  what is the best way to build an ensemble of this model  such that predictions for each time series aren t affected by the others   when i say aren t affected by other time series  i mean that the average of predictions of two different models trained on two different series might not be as accurate precise as the predictions by themselves  without averaging    should i have n different models for each time series and just average the predictions  should i have some k number of models with different loss functions and then average those  what would be a good strategy ,working project n independent time series datasets thought like prices different currencies crypto coins etc structured dataset training batch first dimension index time series prediction model based couple papers takes sliding window outputs prediction time series question best way build ensemble model predictions time series affected others say affected time series mean average predictions two different models trained two different series might accurate precise predictions without averaging n different models time series average predictions k number models different loss functions average would good strategy,p ensembling multiple independent time series,p ensembling multiple independent time seriesworking project n independent time series datasets thought like prices different currencies crypto coins etc structured dataset training batch first dimension index time series prediction model based couple papers takes sliding window outputs prediction time series question best way build ensemble model predictions time series affected others say affected time series mean average predictions two different models trained two different series might accurate precise predictions without averaging n different models time series average predictions k number models different loss functions average would good strategy,"['p', 'ensembling', 'multiple', 'independent', 'time', 'seriesworking', 'project', 'n', 'independent', 'time', 'series', 'datasets', 'thought', 'like', 'prices', 'different', 'currencies', 'crypto', 'coins', 'etc', 'structured', 'dataset', 'training', 'batch', 'first', 'dimension', 'index', 'time', 'series', 'prediction', 'model', 'based', 'couple', 'papers', 'takes', 'sliding', 'window', 'outputs', 'prediction', 'time', 'series', 'question', 'best', 'way', 'build', 'ensemble', 'model', 'predictions', 'time', 'series', 'affected', 'others', 'say', 'affected', 'time', 'series', 'mean', 'average', 'predictions', 'two', 'different', 'models', 'trained', 'two', 'different', 'series', 'might', 'accurate', 'precise', 'predictions', 'without', 'averaging', 'n', 'different', 'models', 'time', 'series', 'average', 'predictions', 'k', 'number', 'models', 'different', 'loss', 'functions', 'average', 'would', 'good', 'strategy']","['p', 'ensembl', 'multipl', 'independ', 'time', 'serieswork', 'project', 'n', 'independ', 'time', 'seri', 'dataset', 'thought', 'like', 'price', 'differ', 'currenc', 'crypto', 'coin', 'etc', 'structur', 'dataset', 'train', 'batch', 'first', 'dimens', 'index', 'time', 'seri', 'predict', 'model', 'base', 'coupl', 'paper', 'take', 'slide', 'window', 'output', 'predict', 'time', 'seri', 'question', 'best', 'way', 'build', 'ensembl', 'model', 'predict', 'time', 'seri', 'affect', 'other', 'say', 'affect', 'time', 'seri', 'mean', 'averag', 'predict', 'two', 'differ', 'model', 'train', 'two', 'differ', 'seri', 'might', 'accur', 'precis', 'predict', 'without', 'averag', 'n', 'differ', 'model', 'time', 'seri', 'averag', 'predict', 'k', 'number', 'model', 'differ', 'loss', 'function', 'averag', 'would', 'good', 'strategi']"
235,258,258,Spiritual_Fig3632,vxteu1,[D] tranfer learning with freezing vs unfreezing,"Hi, I have been trying to test self-supervised representation learning on vision-task. In more detail, testing [BYOL](https://arxiv.org/abs/2006.07733) in cifar-10. I found the trick that they threw away the last layer and put a new layer for the output shape, and the backbone network is frozen during finetuning. I know that the bad last layer can harm to the backbone network during finetuning because network is highly sensitive to even small change in parameter space. But I tried to finetune without freezing, It shows better last performance(accuracy 82% -> 90% at test). So why did they freeze the backbone network and show the results of the experiment?

How can I explain this phenomenon? Thank you for reading.",5,2,2022-07-13 06:29:41, d  tranfer learning with freezing vs unfreezing,hi  i have been trying to test self supervised representation learning on vision task  in more detail  testing  byol  https how can i explain this phenomenon  thank you for reading ,hi trying test self supervised representation learning vision task detail testing byol https explain phenomenon thank reading,tranfer learning freezing vs unfreezing,tranfer learning freezing vs unfreezinghi trying test self supervised representation learning vision task detail testing byol https explain phenomenon thank reading,"['tranfer', 'learning', 'freezing', 'vs', 'unfreezinghi', 'trying', 'test', 'self', 'supervised', 'representation', 'learning', 'vision', 'task', 'detail', 'testing', 'byol', 'https', 'explain', 'phenomenon', 'thank', 'reading']","['tranfer', 'learn', 'freez', 'vs', 'unfreezinghi', 'tri', 'test', 'self', 'supervis', 'represent', 'learn', 'vision', 'task', 'detail', 'test', 'byol', 'http', 'explain', 'phenomenon', 'thank', 'read']"
236,259,259,ajt9000,vx045i,[D] How do you verify the novelty of your research?," 

While working on my own research and struggling to find related works it got me thinking. What process do you follow to discover preexisting research similar to your own?

With the fast pace of research in the field, and so much overlapping terminology, do you use fancy tools or go beyond just typing queries into google scholar until you get relevant papers to your own? How do you find what you don't know to look for?",55,189,2022-07-12 05:30:07, d  how do you verify the novelty of your research , while working on my own research and struggling to find related works it got me thinking  what process do you follow to discover preexisting research similar to your own with the fast pace of research in the field  and so much overlapping terminology  do you use fancy tools or go beyond just typing queries into google scholar until you get relevant papers to your own  how do you find what you don t know to look for ,working research struggling find related works got thinking process follow discover preexisting research similar fast pace research field much overlapping terminology use fancy tools go beyond typing queries google scholar get relevant papers find know look,verify novelty research,verify novelty researchworking research struggling find related works got thinking process follow discover preexisting research similar fast pace research field much overlapping terminology use fancy tools go beyond typing queries google scholar get relevant papers find know look,"['verify', 'novelty', 'researchworking', 'research', 'struggling', 'find', 'related', 'works', 'got', 'thinking', 'process', 'follow', 'discover', 'preexisting', 'research', 'similar', 'fast', 'pace', 'research', 'field', 'much', 'overlapping', 'terminology', 'use', 'fancy', 'tools', 'go', 'beyond', 'typing', 'queries', 'google', 'scholar', 'get', 'relevant', 'papers', 'find', 'know', 'look']","['verifi', 'novelti', 'researchwork', 'research', 'struggl', 'find', 'relat', 'work', 'got', 'think', 'process', 'follow', 'discov', 'preexist', 'research', 'similar', 'fast', 'pace', 'research', 'field', 'much', 'overlap', 'terminolog', 'use', 'fanci', 'tool', 'go', 'beyond', 'type', 'queri', 'googl', 'scholar', 'get', 'relev', 'paper', 'find', 'know', 'look']"
237,260,260,ResearcherNo4728,vxw64g,"[D] How best to handle a column that can hold multiple, unbounded number of values?"," Say I have an email dataset. Two of its columns are ""sender"" and ""recipients"". Now, the ""sender"" column will only hold one value in each row. However, ""recipients"" can be anything in number from 1 to 100, or even more theoretically. In such a scenario, one hot encoding is not a tractable solution. And neither is creating a new row for each unique recipient. So, how best to handle this situation?",4,1,2022-07-13 09:14:15, d  how best to handle a column that can hold multiple  unbounded number of values , say i have an email dataset  two of its columns are sender and recipients  now  the sender column will only hold one value in each row  however  recipients can be anything in number from  to   or even more theoretically  in such a scenario  one hot encoding is not a tractable solution  and neither is creating a new row for each unique recipient  so  how best to handle this situation ,say email dataset two columns sender recipients sender column hold one value row however recipients anything number even theoretically scenario one hot encoding tractable solution neither creating row unique recipient best handle situation,best handle column hold multiple unbounded number values,best handle column hold multiple unbounded number valuessay email dataset two columns sender recipients sender column hold one value row however recipients anything number even theoretically scenario one hot encoding tractable solution neither creating row unique recipient best handle situation,"['best', 'handle', 'column', 'hold', 'multiple', 'unbounded', 'number', 'valuessay', 'email', 'dataset', 'two', 'columns', 'sender', 'recipients', 'sender', 'column', 'hold', 'one', 'value', 'row', 'however', 'recipients', 'anything', 'number', 'even', 'theoretically', 'scenario', 'one', 'hot', 'encoding', 'tractable', 'solution', 'neither', 'creating', 'row', 'unique', 'recipient', 'best', 'handle', 'situation']","['best', 'handl', 'column', 'hold', 'multipl', 'unbound', 'number', 'valuessay', 'email', 'dataset', 'two', 'column', 'sender', 'recipi', 'sender', 'column', 'hold', 'one', 'valu', 'row', 'howev', 'recipi', 'anyth', 'number', 'even', 'theoret', 'scenario', 'one', 'hot', 'encod', 'tractabl', 'solut', 'neither', 'creat', 'row', 'uniqu', 'recipi', 'best', 'handl', 'situat']"
238,261,261,IllustriousCicada603,vxfy50,[D] Does it make sense to generate text sequences with Transformer-based models and then have a classifier to choose between multiple options.,"Hello, I have a topic for discussion: Are you aware of systems which have a sequence-to-sequence architecture such as a Transformer, generating multiple outputs for a given task, and then another model - a MLP, another Transformer or something else which learns to pick the best option. Is it possible for this extra step to extract more knowledge from given data and increase the performance of the pipeline (even though at the cost of more computing power)? In what contexts does (not) that make sense?",10,7,2022-07-12 19:55:46, d  does it make sense to generate text sequences with transformer based models and then have a classifier to choose between multiple options ,hello  i have a topic for discussion  are you aware of systems which have a sequence to sequence architecture such as a transformer  generating multiple outputs for a given task  and then another model   a mlp  another transformer or something else which learns to pick the best option  is it possible for this extra step to extract more knowledge from given data and increase the performance of the pipeline  even though at the cost of more computing power   in what contexts does  not  that make sense ,hello topic discussion aware systems sequence sequence architecture transformer generating multiple outputs given task another model mlp another transformer something else learns pick best option possible extra step extract knowledge given data increase performance pipeline even though cost computing power contexts make sense,make sense generate text sequences transformer based models classifier choose multiple options,make sense generate text sequences transformer based models classifier choose multiple optionshello topic discussion aware systems sequence sequence architecture transformer generating multiple outputs given task another model mlp another transformer something else learns pick best option possible extra step extract knowledge given data increase performance pipeline even though cost computing power contexts make sense,"['make', 'sense', 'generate', 'text', 'sequences', 'transformer', 'based', 'models', 'classifier', 'choose', 'multiple', 'optionshello', 'topic', 'discussion', 'aware', 'systems', 'sequence', 'sequence', 'architecture', 'transformer', 'generating', 'multiple', 'outputs', 'given', 'task', 'another', 'model', 'mlp', 'another', 'transformer', 'something', 'else', 'learns', 'pick', 'best', 'option', 'possible', 'extra', 'step', 'extract', 'knowledge', 'given', 'data', 'increase', 'performance', 'pipeline', 'even', 'though', 'cost', 'computing', 'power', 'contexts', 'make', 'sense']","['make', 'sens', 'gener', 'text', 'sequenc', 'transform', 'base', 'model', 'classifi', 'choos', 'multipl', 'optionshello', 'topic', 'discuss', 'awar', 'system', 'sequenc', 'sequenc', 'architectur', 'transform', 'gener', 'multipl', 'output', 'given', 'task', 'anoth', 'model', 'mlp', 'anoth', 'transform', 'someth', 'els', 'learn', 'pick', 'best', 'option', 'possibl', 'extra', 'step', 'extract', 'knowledg', 'given', 'data', 'increas', 'perform', 'pipelin', 'even', 'though', 'cost', 'comput', 'power', 'context', 'make', 'sens']"
239,262,262,mingrui-zhang,vx4tdz,[P] Building efficient ML applications with Taichi's automatic differentiation,"&#x200B;

https://i.redd.it/d66p6f6p23b91.gif

Hey guys 

I am working on an open-source, parallel programming language, Taichi Lang, which I find efficient in differentiable physical simulation and can help speed up the convergence of ML processes.  

Above is a simple demo supported by Taichi's inbuilt autodiff (automatic differentiation) system. You can move the target as you wish, and the magic fountain always changes its trajectory accordingly to hit the target.

So basically, Taichi Lang's Source Code Transformation system generates gradient kernels during compile time, and the lightweight `tape` in the Python scope records the launched Taichi kernels and replays the gradient kernels in reverse order during backpropagation. Model training is done within 10  optimization iterations.

A step-by-step explanation: [https://www.reddit.com/user/mingrui-zhang/comments/vx49mz/training\_a\_magic\_fountain\_using\_taichis\_autodiff/](https://www.reddit.com/user/mingrui-zhang/comments/vx49mz/training_a_magic_fountain_using_taichis_autodiff/)

Source code: [https://github.com/taichi-dev/taichi/blob/master/python/taichi/examples/autodiff/diff\_sph/diff\_sph.py](https://github.com/taichi-dev/taichi/blob/master/python/taichi/examples/autodiff/diff_sph/diff_sph.py)",11,37,2022-07-12 09:54:54, p  building efficient ml applications with taichi s automatic differentiation,  xb https hey guys i am working on an open source  parallel programming language  taichi lang  which i find efficient in differentiable physical simulation and can help speed up the convergence of ml processes   above is a simple demo supported by taichi s inbuilt autodiff  automatic differentiation  system  you can move the target as you wish  and the magic fountain always changes its trajectory accordingly to hit the target so basically  taichi lang s source code transformation system generates gradient kernels during compile time  and the lightweight  tape  in the python scope records the launched taichi kernels and replays the gradient kernels in reverse order during backpropagation  model training is done within   optimization iterations a step by step explanation   https source code   https   github com taichi dev taichi blob master python taichi examples autodiff diff _sph diff _sph py  https   github com taichi dev taichi blob master python taichi examples autodiff diff_sph diff_sph py ,xb https hey guys working open source parallel programming language taichi lang find efficient differentiable physical simulation help speed convergence ml processes simple demo supported taichi inbuilt autodiff automatic differentiation system move target wish magic fountain always changes trajectory accordingly hit target basically taichi lang source code transformation system generates gradient kernels compile time lightweight tape python scope records launched taichi kernels replays gradient kernels reverse order backpropagation model training done within optimization iterations step step explanation https source code https github com taichi dev taichi blob master python taichi examples autodiff diff _sph diff _sph py https github com taichi dev taichi blob master python taichi examples autodiff diff_sph diff_sph py,p building efficient ml applications taichi automatic differentiation,p building efficient ml applications taichi automatic differentiationxb https hey guys working open source parallel programming language taichi lang find efficient differentiable physical simulation help speed convergence ml processes simple demo supported taichi inbuilt autodiff automatic differentiation system move target wish magic fountain always changes trajectory accordingly hit target basically taichi lang source code transformation system generates gradient kernels compile time lightweight tape python scope records launched taichi kernels replays gradient kernels reverse order backpropagation model training done within optimization iterations step step explanation https source code https github com taichi dev taichi blob master python taichi examples autodiff diff _sph diff _sph py https github com taichi dev taichi blob master python taichi examples autodiff diff_sph diff_sph py,"['p', 'building', 'efficient', 'ml', 'applications', 'taichi', 'automatic', 'differentiationxb', 'https', 'hey', 'guys', 'working', 'open', 'source', 'parallel', 'programming', 'language', 'taichi', 'lang', 'find', 'efficient', 'differentiable', 'physical', 'simulation', 'help', 'speed', 'convergence', 'ml', 'processes', 'simple', 'demo', 'supported', 'taichi', 'inbuilt', 'autodiff', 'automatic', 'differentiation', 'system', 'move', 'target', 'wish', 'magic', 'fountain', 'always', 'changes', 'trajectory', 'accordingly', 'hit', 'target', 'basically', 'taichi', 'lang', 'source', 'code', 'transformation', 'system', 'generates', 'gradient', 'kernels', 'compile', 'time', 'lightweight', 'tape', 'python', 'scope', 'records', 'launched', 'taichi', 'kernels', 'replays', 'gradient', 'kernels', 'reverse', 'order', 'backpropagation', 'model', 'training', 'done', 'within', 'optimization', 'iterations', 'step', 'step', 'explanation', 'https', 'source', 'code', 'https', 'github', 'com', 'taichi', 'dev', 'taichi', 'blob', 'master', 'python', 'taichi', 'examples', 'autodiff', 'diff', '_sph', 'diff', '_sph', 'py', 'https', 'github', 'com', 'taichi', 'dev', 'taichi', 'blob', 'master', 'python', 'taichi', 'examples', 'autodiff', 'diff_sph', 'diff_sph', 'py']","['p', 'build', 'effici', 'ml', 'applic', 'taichi', 'automat', 'differentiationxb', 'http', 'hey', 'guy', 'work', 'open', 'sourc', 'parallel', 'program', 'languag', 'taichi', 'lang', 'find', 'effici', 'differenti', 'physic', 'simul', 'help', 'speed', 'converg', 'ml', 'process', 'simpl', 'demo', 'support', 'taichi', 'inbuilt', 'autodiff', 'automat', 'differenti', 'system', 'move', 'target', 'wish', 'magic', 'fountain', 'alway', 'chang', 'trajectori', 'accordingli', 'hit', 'target', 'basic', 'taichi', 'lang', 'sourc', 'code', 'transform', 'system', 'gener', 'gradient', 'kernel', 'compil', 'time', 'lightweight', 'tape', 'python', 'scope', 'record', 'launch', 'taichi', 'kernel', 'replay', 'gradient', 'kernel', 'revers', 'order', 'backpropag', 'model', 'train', 'done', 'within', 'optim', 'iter', 'step', 'step', 'explan', 'http', 'sourc', 'code', 'http', 'github', 'com', 'taichi', 'dev', 'taichi', 'blob', 'master', 'python', 'taichi', 'exampl', 'autodiff', 'diff', '_sph', 'diff', '_sph', 'py', 'http', 'github', 'com', 'taichi', 'dev', 'taichi', 'blob', 'master', 'python', 'taichi', 'exampl', 'autodiff', 'diff_sph', 'diff_sph', 'py']"
240,263,263,giuse_tweets,vxihha,[R] DiBB: Distributing Black-Box Optimization,"Author here. Just presented this work at GECCO 2022.

- Quick summary: https://twitter.com/giuse_tweets/status/1546920346015637505
- Paper: https://exascale.info/assets/pdf/cuccu2022gecco.pdf
- Code + tutorials: https://github.com/giuse/dibb
- Experiments (COCO/BBOB-LS): https://github.com/eXascaleInfolab/dibb_coco
- Recorded rehearsal of the talk: https://tinyurl.com/dibb-video

AMA!",0,6,2022-07-12 21:47:24, r  dibb  distributing black box optimization,author here  just presented this work at gecco    quick summary  https   paper  https   code   tutorials  https   experiments  coco bbob ls   https   recorded rehearsal of the talk  https ama ,author presented work gecco quick summary https paper https code tutorials https experiments coco bbob ls https recorded rehearsal talk https ama,r dibb distributing black box optimization,r dibb distributing black box optimizationauthor presented work gecco quick summary https paper https code tutorials https experiments coco bbob ls https recorded rehearsal talk https ama,"['r', 'dibb', 'distributing', 'black', 'box', 'optimizationauthor', 'presented', 'work', 'gecco', 'quick', 'summary', 'https', 'paper', 'https', 'code', 'tutorials', 'https', 'experiments', 'coco', 'bbob', 'ls', 'https', 'recorded', 'rehearsal', 'talk', 'https', 'ama']","['r', 'dibb', 'distribut', 'black', 'box', 'optimizationauthor', 'present', 'work', 'gecco', 'quick', 'summari', 'http', 'paper', 'http', 'code', 'tutori', 'http', 'experi', 'coco', 'bbob', 'ls', 'http', 'record', 'rehears', 'talk', 'http', 'ama']"
241,264,264,davidmezzetti,vxbdf4,[P] Run transformers model inference in C/C++ and Assembly with the Python C API,"&#x200B;

https://preview.redd.it/xjtcha3r35b91.png?width=1298&format=png&auto=webp&s=00873223c1ea0c6afcd5e22c7645521036b7e341

This post presents a way to run transformers models via the Python C API. The referenced notebook loads two txtai workflows, one that translates English to French and another that summarizes a webpage. After loading the models through C code, another example runs the workflows through assembly to show this works with any native code.

Full code links: [Notebook](https://colab.research.google.com/github/neuml/txtai/blob/master/examples/36_Run_txtai_in_native_code.ipynb) | [GitHub](https://github.com/neuml/txtai)",2,8,2022-07-12 16:33:59, p  run transformers model inference in c c   and assembly with the python c api,  xb https this post presents a way to run transformers models via the python c api  the referenced notebook loads two txtai workflows  one that translates english to french and another that summarizes a webpage  after loading the models through c code  another example runs the workflows through assembly to show this works with any native code full code links   notebook  https   colab research google com github neuml txtai blob master examples _run_txtai_in_native_code ipynb     github  https   github com neuml txtai ,xb https post presents way run transformers models via python c api referenced notebook loads two txtai workflows one translates english french another summarizes webpage loading models c code another example runs workflows assembly show works native code full code links notebook https colab research google com github neuml txtai blob master examples _run_txtai_in_native_code ipynb github https github com neuml txtai,p run transformers model inference c c assembly python c api,p run transformers model inference c c assembly python c apixb https post presents way run transformers models via python c api referenced notebook loads two txtai workflows one translates english french another summarizes webpage loading models c code another example runs workflows assembly show works native code full code links notebook https colab research google com github neuml txtai blob master examples _run_txtai_in_native_code ipynb github https github com neuml txtai,"['p', 'run', 'transformers', 'model', 'inference', 'c', 'c', 'assembly', 'python', 'c', 'apixb', 'https', 'post', 'presents', 'way', 'run', 'transformers', 'models', 'via', 'python', 'c', 'api', 'referenced', 'notebook', 'loads', 'two', 'txtai', 'workflows', 'one', 'translates', 'english', 'french', 'another', 'summarizes', 'webpage', 'loading', 'models', 'c', 'code', 'another', 'example', 'runs', 'workflows', 'assembly', 'show', 'works', 'native', 'code', 'full', 'code', 'links', 'notebook', 'https', 'colab', 'research', 'google', 'com', 'github', 'neuml', 'txtai', 'blob', 'master', 'examples', '_run_txtai_in_native_code', 'ipynb', 'github', 'https', 'github', 'com', 'neuml', 'txtai']","['p', 'run', 'transform', 'model', 'infer', 'c', 'c', 'assembl', 'python', 'c', 'apixb', 'http', 'post', 'present', 'way', 'run', 'transform', 'model', 'via', 'python', 'c', 'api', 'referenc', 'notebook', 'load', 'two', 'txtai', 'workflow', 'one', 'translat', 'english', 'french', 'anoth', 'summar', 'webpag', 'load', 'model', 'c', 'code', 'anoth', 'exampl', 'run', 'workflow', 'assembl', 'show', 'work', 'nativ', 'code', 'full', 'code', 'link', 'notebook', 'http', 'colab', 'research', 'googl', 'com', 'github', 'neuml', 'txtai', 'blob', 'master', 'exampl', '_run_txtai_in_native_cod', 'ipynb', 'github', 'http', 'github', 'com', 'neuml', 'txtai']"
242,265,265,subtask_net,vx5ryw,[P] Helping data scientists access large ML datasets,"I spent so much time building data pipelines which feels like a huge constraint on my time and ability to focus on actual ML tasks. That's why I'm building [subtask.net](https://subtask.net) which collects and builds large, constantly updated, ML datasets from across the internet. The goal is to cut out the data collection part of any ML project and make more datasets available beyond the typical open-source datasets provided by the community.",4,15,2022-07-12 10:59:58, p  helping data scientists access large ml datasets,i spent so much time building data pipelines which feels like a huge constraint on my time and ability to focus on actual ml tasks  that s why i m building  subtask net  https   subtask net  which collects and builds large  constantly updated  ml datasets from across the internet  the goal is to cut out the data collection part of any ml project and make more datasets available beyond the typical open source datasets provided by the community ,spent much time building data pipelines feels like huge constraint time ability focus actual ml tasks building subtask net https subtask net collects builds large constantly updated ml datasets across internet goal cut data collection part ml project make datasets available beyond typical open source datasets provided community,p helping data scientists access large ml datasets,p helping data scientists access large ml datasetsspent much time building data pipelines feels like huge constraint time ability focus actual ml tasks building subtask net https subtask net collects builds large constantly updated ml datasets across internet goal cut data collection part ml project make datasets available beyond typical open source datasets provided community,"['p', 'helping', 'data', 'scientists', 'access', 'large', 'ml', 'datasetsspent', 'much', 'time', 'building', 'data', 'pipelines', 'feels', 'like', 'huge', 'constraint', 'time', 'ability', 'focus', 'actual', 'ml', 'tasks', 'building', 'subtask', 'net', 'https', 'subtask', 'net', 'collects', 'builds', 'large', 'constantly', 'updated', 'ml', 'datasets', 'across', 'internet', 'goal', 'cut', 'data', 'collection', 'part', 'ml', 'project', 'make', 'datasets', 'available', 'beyond', 'typical', 'open', 'source', 'datasets', 'provided', 'community']","['p', 'help', 'data', 'scientist', 'access', 'larg', 'ml', 'datasetssp', 'much', 'time', 'build', 'data', 'pipelin', 'feel', 'like', 'huge', 'constraint', 'time', 'abil', 'focu', 'actual', 'ml', 'task', 'build', 'subtask', 'net', 'http', 'subtask', 'net', 'collect', 'build', 'larg', 'constantli', 'updat', 'ml', 'dataset', 'across', 'internet', 'goal', 'cut', 'data', 'collect', 'part', 'ml', 'project', 'make', 'dataset', 'avail', 'beyond', 'typic', 'open', 'sourc', 'dataset', 'provid', 'commun']"
243,266,266,Ok-Wind-1215,vx01wq,[D] Efficiently choose good papers in top-tier conferences,"Hey, As a senior Phd student, I still feel a bit tired of looking for and reading through the massive newly accepted papers in top-tier conferences/journals like neurips/icml/iclr/jmlr/cvpr.... 

Any suggestions for efficiently selecting good papers ?",12,31,2022-07-12 05:27:02, d  efficiently choose good papers in top tier conferences,hey  as a senior phd student  i still feel a bit tired of looking for and reading through the massive newly accepted papers in top tier conferences journals like neurips icml iclr jmlr cvpr     any suggestions for efficiently selecting good papers  ,hey senior phd student still feel bit tired looking reading massive newly accepted papers top tier conferences journals like neurips icml iclr jmlr cvpr suggestions efficiently selecting good papers,efficiently choose good papers top tier conferences,efficiently choose good papers top tier conferenceshey senior phd student still feel bit tired looking reading massive newly accepted papers top tier conferences journals like neurips icml iclr jmlr cvpr suggestions efficiently selecting good papers,"['efficiently', 'choose', 'good', 'papers', 'top', 'tier', 'conferenceshey', 'senior', 'phd', 'student', 'still', 'feel', 'bit', 'tired', 'looking', 'reading', 'massive', 'newly', 'accepted', 'papers', 'top', 'tier', 'conferences', 'journals', 'like', 'neurips', 'icml', 'iclr', 'jmlr', 'cvpr', 'suggestions', 'efficiently', 'selecting', 'good', 'papers']","['effici', 'choos', 'good', 'paper', 'top', 'tier', 'conferenceshey', 'senior', 'phd', 'student', 'still', 'feel', 'bit', 'tire', 'look', 'read', 'massiv', 'newli', 'accept', 'paper', 'top', 'tier', 'confer', 'journal', 'like', 'neurip', 'icml', 'iclr', 'jmlr', 'cvpr', 'suggest', 'effici', 'select', 'good', 'paper']"
244,268,268,imunabletocode,vx6dz5,[D] How to choose best model during training if validation loss fluctuates a lot?," I am training a deep neural network, unfortunately, I have few samples for my validation set, so the relative loss fluctuate a lot. How can I choose the best model during training? Usually I choose the model which is associated with the lowest validation loss, but now there are random fluctuation that lower loss function. I think the fluctuations are due to the fact that I can't use the whole sample because I am using Colab free and i haven't enough RAM. I tried to modify the splig Train/Train/Vali increasing Vali size and the oscillations seems a bit lower, but i would like to mantain the ratio 60/20/20 for a better and more significative classification.",12,8,2022-07-12 11:42:06, d  how to choose best model during training if validation loss fluctuates a lot , i am training a deep neural network  unfortunately  i have few samples for my validation set  so the relative loss fluctuate a lot  how can i choose the best model during training  usually i choose the model which is associated with the lowest validation loss  but now there are random fluctuation that lower loss function  i think the fluctuations are due to the fact that i can t use the whole sample because i am using colab free and i haven t enough ram  i tried to modify the splig train train vali increasing vali size and the oscillations seems a bit lower  but i would like to mantain the ratio    for a better and more significative classification ,training deep neural network unfortunately samples validation set relative loss fluctuate lot choose best model training usually choose model associated lowest validation loss random fluctuation lower loss function think fluctuations due fact use whole sample using colab free enough ram tried modify splig train train vali increasing vali size oscillations seems bit lower would like mantain ratio better significative classification,choose best model training validation loss fluctuates lot,choose best model training validation loss fluctuates lottraining deep neural network unfortunately samples validation set relative loss fluctuate lot choose best model training usually choose model associated lowest validation loss random fluctuation lower loss function think fluctuations due fact use whole sample using colab free enough ram tried modify splig train train vali increasing vali size oscillations seems bit lower would like mantain ratio better significative classification,"['choose', 'best', 'model', 'training', 'validation', 'loss', 'fluctuates', 'lottraining', 'deep', 'neural', 'network', 'unfortunately', 'samples', 'validation', 'set', 'relative', 'loss', 'fluctuate', 'lot', 'choose', 'best', 'model', 'training', 'usually', 'choose', 'model', 'associated', 'lowest', 'validation', 'loss', 'random', 'fluctuation', 'lower', 'loss', 'function', 'think', 'fluctuations', 'due', 'fact', 'use', 'whole', 'sample', 'using', 'colab', 'free', 'enough', 'ram', 'tried', 'modify', 'splig', 'train', 'train', 'vali', 'increasing', 'vali', 'size', 'oscillations', 'seems', 'bit', 'lower', 'would', 'like', 'mantain', 'ratio', 'better', 'significative', 'classification']","['choos', 'best', 'model', 'train', 'valid', 'loss', 'fluctuat', 'lottrain', 'deep', 'neural', 'network', 'unfortun', 'sampl', 'valid', 'set', 'rel', 'loss', 'fluctuat', 'lot', 'choos', 'best', 'model', 'train', 'usual', 'choos', 'model', 'associ', 'lowest', 'valid', 'loss', 'random', 'fluctuat', 'lower', 'loss', 'function', 'think', 'fluctuat', 'due', 'fact', 'use', 'whole', 'sampl', 'use', 'colab', 'free', 'enough', 'ram', 'tri', 'modifi', 'splig', 'train', 'train', 'vali', 'increas', 'vali', 'size', 'oscil', 'seem', 'bit', 'lower', 'would', 'like', 'mantain', 'ratio', 'better', 'signif', 'classif']"
245,269,269,EnricoShippole,vxf5w3,[P] Token-to-Token ViT Implementation in Flax,"&#x200B;

https://preview.redd.it/0mh5d00tx5b91.png?width=479&format=png&auto=webp&s=ac8c83e80d058d032e9083512da749216d9a2221

An open-source implementation of the Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet research paper in Google's JAX and Flax.

""Transformers, which are popular for language modeling, have been explored for solving vision tasks recently, e.g., the Vision Transformer (ViT) for image classification. The ViT model splits each image into a sequence of tokens with fixed length and then applies multiple Transformer layers to model their global relation for classification. However, ViT achieves inferior performance to CNNs when trained from scratch on a midsize dataset like ImageNet. We find it is because: 1) the simple tokenization of input images fails to model the important local structure such as edges and lines among neighboring pixels, leading to low training sample efficiency; 2) the redundant attention backbone design of ViT leads to limited feature richness for fixed computation budgets and limited training samples. To overcome such limitations, we propose a new Tokens-To-Token Vision Transformer (T2T-ViT), which incorporates 1) a layer-wise Tokens-to-Token (T2T) transformation to progressively structurize the image to tokens by recursively aggregating neighboring Tokens into one Token (Tokens-to-Token), such that local structure represented by surrounding tokens can be modeled and tokens length can be reduced; 2) an efficient backbone with a deep-narrow structure for vision transformer motivated by CNN architecture design after empirical study. Notably, T2T-ViT reduces the parameter count and MACs of vanilla ViT by half, while achieving more than 3.0% improvement when trained from scratch on ImageNet. It also outperforms ResNets and achieves comparable performance with MobileNets by directly training on ImageNet. For example, T2T-ViT with comparable size to ResNet50 (21.5M parameters) can achieve 83.3% top1 accuracy in image resolution 384×384 on ImageNet."" - Li Yuan, Yunpeng Chen, Tao Wang, Weihao Yu, Yujun Shi, Zihang Jiang, Francis EH Tay, Jiashi Feng, Shuicheng Yan

Github Repository for JAX /Flax model: [https://github.com/conceptofmind/Token-to-Token-ViT-flax](https://github.com/conceptofmind/Token-to-Token-ViT-flax)

Tokens-to-Token ViT Research Paper: [https://arxiv.org/abs/2203.10790](https://arxiv.org/abs/2203.10790)

Official Github Repository: [https://github.com/yitu-opensource/T2T-ViT](https://github.com/yitu-opensource/T2T-ViT)

In collaboration with Dr. Phil 'Lucid' Wang: [https://github.com/lucidrains](https://github.com/lucidrains).",0,0,2022-07-12 19:22:09, p  token to token vit implementation in flax,  xb https an open source implementation of the tokens to token vit  training vision transformers from scratch on imagenet research paper in google s jax and flax transformers  which are popular for language modeling  have been explored for solving vision tasks recently  e g   the vision transformer  vit  for image classification  the vit model splits each image into a sequence of tokens with fixed length and then applies multiple transformer layers to model their global relation for classification  however  vit achieves inferior performance to cnns when trained from scratch on a midsize dataset like imagenet  we find it is because    the simple tokenization of input images fails to model the important local structure such as edges and lines among neighboring pixels  leading to low training sample efficiency    the redundant attention backbone design of vit leads to limited feature richness for fixed computation budgets and limited training samples  to overcome such limitations  we propose a new tokens to token vision transformer  tt vit   which incorporates   a layer wise tokens to token  tt  transformation to progressively structurize the image to tokens by recursively aggregating neighboring tokens into one token  tokens to token   such that local structure represented by surrounding tokens can be modeled and tokens length can be reduced    an efficient backbone with a deep narrow structure for vision transformer motivated by cnn architecture design after empirical study  notably  tt vit reduces the parameter count and macs of vanilla vit by half  while achieving more than    improvement when trained from scratch on imagenet  it also outperforms resnets and achieves comparable performance with mobilenets by directly training on imagenet  for example  tt vit with comparable size to resnet   m parameters  can achieve    top accuracy in image resolution   on imagenet    li yuan  yunpeng chen  tao wang  weihao yu  yujun shi  zihang jiang  francis eh tay  jiashi feng  shuicheng yangithub repository for jax  flax model   https tokens to token vit research paper   https official github repository   https in collaboration with dr  phil  lucid  wang   https   github com lucidrains  https   github com lucidrains  ,xb https open source implementation tokens token vit training vision transformers scratch imagenet research paper google jax flax transformers popular language modeling explored solving vision tasks recently e g vision transformer vit image classification vit model splits image sequence tokens fixed length applies multiple transformer layers model global relation classification however vit achieves inferior performance cnns trained scratch midsize dataset like imagenet find simple tokenization input images fails model important local structure edges lines among neighboring pixels leading low training sample efficiency redundant attention backbone design vit leads limited feature richness fixed computation budgets limited training samples overcome limitations propose tokens token vision transformer tt vit incorporates layer wise tokens token tt transformation progressively structurize image tokens recursively aggregating neighboring tokens one token tokens token local structure represented surrounding tokens modeled tokens length reduced efficient backbone deep narrow structure vision transformer motivated cnn architecture design empirical study notably tt vit reduces parameter count macs vanilla vit half achieving improvement trained scratch imagenet also outperforms resnets achieves comparable performance mobilenets directly training imagenet example tt vit comparable size resnet parameters achieve top accuracy image resolution imagenet li yuan yunpeng chen tao wang weihao yu yujun shi zihang jiang francis eh tay jiashi feng shuicheng yangithub repository jax flax model https tokens token vit research paper https official github repository https collaboration dr phil lucid wang https github com lucidrains https github com lucidrains,p token token vit implementation flax,p token token vit implementation flaxxb https open source implementation tokens token vit training vision transformers scratch imagenet research paper google jax flax transformers popular language modeling explored solving vision tasks recently e g vision transformer vit image classification vit model splits image sequence tokens fixed length applies multiple transformer layers model global relation classification however vit achieves inferior performance cnns trained scratch midsize dataset like imagenet find simple tokenization input images fails model important local structure edges lines among neighboring pixels leading low training sample efficiency redundant attention backbone design vit leads limited feature richness fixed computation budgets limited training samples overcome limitations propose tokens token vision transformer tt vit incorporates layer wise tokens token tt transformation progressively structurize image tokens recursively aggregating neighboring tokens one token tokens token local structure represented surrounding tokens modeled tokens length reduced efficient backbone deep narrow structure vision transformer motivated cnn architecture design empirical study notably tt vit reduces parameter count macs vanilla vit half achieving improvement trained scratch imagenet also outperforms resnets achieves comparable performance mobilenets directly training imagenet example tt vit comparable size resnet parameters achieve top accuracy image resolution imagenet li yuan yunpeng chen tao wang weihao yu yujun shi zihang jiang francis eh tay jiashi feng shuicheng yangithub repository jax flax model https tokens token vit research paper https official github repository https collaboration dr phil lucid wang https github com lucidrains https github com lucidrains,"['p', 'token', 'token', 'vit', 'implementation', 'flaxxb', 'https', 'open', 'source', 'implementation', 'tokens', 'token', 'vit', 'training', 'vision', 'transformers', 'scratch', 'imagenet', 'research', 'paper', 'google', 'jax', 'flax', 'transformers', 'popular', 'language', 'modeling', 'explored', 'solving', 'vision', 'tasks', 'recently', 'e', 'g', 'vision', 'transformer', 'vit', 'image', 'classification', 'vit', 'model', 'splits', 'image', 'sequence', 'tokens', 'fixed', 'length', 'applies', 'multiple', 'transformer', 'layers', 'model', 'global', 'relation', 'classification', 'however', 'vit', 'achieves', 'inferior', 'performance', 'cnns', 'trained', 'scratch', 'midsize', 'dataset', 'like', 'imagenet', 'find', 'simple', 'tokenization', 'input', 'images', 'fails', 'model', 'important', 'local', 'structure', 'edges', 'lines', 'among', 'neighboring', 'pixels', 'leading', 'low', 'training', 'sample', 'efficiency', 'redundant', 'attention', 'backbone', 'design', 'vit', 'leads', 'limited', 'feature', 'richness', 'fixed', 'computation', 'budgets', 'limited', 'training', 'samples', 'overcome', 'limitations', 'propose', 'tokens', 'token', 'vision', 'transformer', 'tt', 'vit', 'incorporates', 'layer', 'wise', 'tokens', 'token', 'tt', 'transformation', 'progressively', 'structurize', 'image', 'tokens', 'recursively', 'aggregating', 'neighboring', 'tokens', 'one', 'token', 'tokens', 'token', 'local', 'structure', 'represented', 'surrounding', 'tokens', 'modeled', 'tokens', 'length', 'reduced', 'efficient', 'backbone', 'deep', 'narrow', 'structure', 'vision', 'transformer', 'motivated', 'cnn', 'architecture', 'design', 'empirical', 'study', 'notably', 'tt', 'vit', 'reduces', 'parameter', 'count', 'macs', 'vanilla', 'vit', 'half', 'achieving', 'improvement', 'trained', 'scratch', 'imagenet', 'also', 'outperforms', 'resnets', 'achieves', 'comparable', 'performance', 'mobilenets', 'directly', 'training', 'imagenet', 'example', 'tt', 'vit', 'comparable', 'size', 'resnet', 'parameters', 'achieve', 'top', 'accuracy', 'image', 'resolution', 'imagenet', 'li', 'yuan', 'yunpeng', 'chen', 'tao', 'wang', 'weihao', 'yu', 'yujun', 'shi', 'zihang', 'jiang', 'francis', 'eh', 'tay', 'jiashi', 'feng', 'shuicheng', 'yangithub', 'repository', 'jax', 'flax', 'model', 'https', 'tokens', 'token', 'vit', 'research', 'paper', 'https', 'official', 'github', 'repository', 'https', 'collaboration', 'dr', 'phil', 'lucid', 'wang', 'https', 'github', 'com', 'lucidrains', 'https', 'github', 'com', 'lucidrains']","['p', 'token', 'token', 'vit', 'implement', 'flaxxb', 'http', 'open', 'sourc', 'implement', 'token', 'token', 'vit', 'train', 'vision', 'transform', 'scratch', 'imagenet', 'research', 'paper', 'googl', 'jax', 'flax', 'transform', 'popular', 'languag', 'model', 'explor', 'solv', 'vision', 'task', 'recent', 'e', 'g', 'vision', 'transform', 'vit', 'imag', 'classif', 'vit', 'model', 'split', 'imag', 'sequenc', 'token', 'fix', 'length', 'appli', 'multipl', 'transform', 'layer', 'model', 'global', 'relat', 'classif', 'howev', 'vit', 'achiev', 'inferior', 'perform', 'cnn', 'train', 'scratch', 'midsiz', 'dataset', 'like', 'imagenet', 'find', 'simpl', 'token', 'input', 'imag', 'fail', 'model', 'import', 'local', 'structur', 'edg', 'line', 'among', 'neighbor', 'pixel', 'lead', 'low', 'train', 'sampl', 'effici', 'redund', 'attent', 'backbon', 'design', 'vit', 'lead', 'limit', 'featur', 'rich', 'fix', 'comput', 'budget', 'limit', 'train', 'sampl', 'overcom', 'limit', 'propos', 'token', 'token', 'vision', 'transform', 'tt', 'vit', 'incorpor', 'layer', 'wise', 'token', 'token', 'tt', 'transform', 'progress', 'structur', 'imag', 'token', 'recurs', 'aggreg', 'neighbor', 'token', 'one', 'token', 'token', 'token', 'local', 'structur', 'repres', 'surround', 'token', 'model', 'token', 'length', 'reduc', 'effici', 'backbon', 'deep', 'narrow', 'structur', 'vision', 'transform', 'motiv', 'cnn', 'architectur', 'design', 'empir', 'studi', 'notabl', 'tt', 'vit', 'reduc', 'paramet', 'count', 'mac', 'vanilla', 'vit', 'half', 'achiev', 'improv', 'train', 'scratch', 'imagenet', 'also', 'outperform', 'resnet', 'achiev', 'compar', 'perform', 'mobilenet', 'directli', 'train', 'imagenet', 'exampl', 'tt', 'vit', 'compar', 'size', 'resnet', 'paramet', 'achiev', 'top', 'accuraci', 'imag', 'resolut', 'imagenet', 'li', 'yuan', 'yunpeng', 'chen', 'tao', 'wang', 'weihao', 'yu', 'yujun', 'shi', 'zihang', 'jiang', 'franci', 'eh', 'tay', 'jiashi', 'feng', 'shuicheng', 'yangithub', 'repositori', 'jax', 'flax', 'model', 'http', 'token', 'token', 'vit', 'research', 'paper', 'http', 'offici', 'github', 'repositori', 'http', 'collabor', 'dr', 'phil', 'lucid', 'wang', 'http', 'github', 'com', 'lucidrain', 'http', 'github', 'com', 'lucidrain']"
246,270,270,thejashGI,vxhpnx,"[D]Oleh Rybkin, UPenn, on exploration and planning with world models","Here is a [podcast](https://generallyintelligent.ai/podcast/2022-07-11-podcast-episode-18-oleh-rybkin/) with Oleh Rybkin where we discuss agents that explore and plan (and do yoga), how to learn world models from video, what's missing from current RL research, and much more!",0,0,2022-07-12 21:13:30, d oleh rybkin  upenn  on exploration and planning with world models,here is a  podcast  https   generallyintelligent ai podcast    podcast episode  oleh rybkin   with oleh rybkin where we discuss agents that explore and plan  and do yoga   how to learn world models from video  what s missing from current rl research  and much more ,podcast https generallyintelligent ai podcast podcast episode oleh rybkin oleh rybkin discuss agents explore plan yoga learn world models video missing current rl research much,oleh rybkin upenn exploration planning world models,oleh rybkin upenn exploration planning world modelspodcast https generallyintelligent ai podcast podcast episode oleh rybkin oleh rybkin discuss agents explore plan yoga learn world models video missing current rl research much,"['oleh', 'rybkin', 'upenn', 'exploration', 'planning', 'world', 'modelspodcast', 'https', 'generallyintelligent', 'ai', 'podcast', 'podcast', 'episode', 'oleh', 'rybkin', 'oleh', 'rybkin', 'discuss', 'agents', 'explore', 'plan', 'yoga', 'learn', 'world', 'models', 'video', 'missing', 'current', 'rl', 'research', 'much']","['oleh', 'rybkin', 'upenn', 'explor', 'plan', 'world', 'modelspodcast', 'http', 'generallyintellig', 'ai', 'podcast', 'podcast', 'episod', 'oleh', 'rybkin', 'oleh', 'rybkin', 'discuss', 'agent', 'explor', 'plan', 'yoga', 'learn', 'world', 'model', 'video', 'miss', 'current', 'rl', 'research', 'much']"
247,271,271,Singularian2501,vwyjh1,"[R] Machine Learning Operations (MLOps): Overview, Definition, and Architecture","Paper: [https://arxiv.org/ftp/arxiv/papers/2205/2205.02302.pdf](https://arxiv.org/ftp/arxiv/papers/2205/2205.02302.pdf)

Abstract:

>The final goal of all industrial machine learning (ML) projects is to develop ML products and rapidly bring them into production. However, it is highly challenging to automate and operationalize ML products and thus many ML endeavors fail to deliver on their expectations. The paradigm of Machine Learning Operations (MLOps) addresses this issue. MLOps includes several aspects, such as best practices, sets of concepts, and development culture. However, MLOps is still a vague term and its consequences for researchers and professionals are ambiguous. To address this gap, we conduct mixed-method research, including a literature review, a tool review, and expert interviews. As a result of these investigations, we provide an aggregated overview of the necessary principles, components, and roles, as well as the associated architecture and workflows. Furthermore, we furnish a definition of MLOps and highlight open challenges in the field. Finally, this work provides guidance for ML researchers and practitioners who want to automate and operate their ML products with a designated set of technologies. 

https://preview.redd.it/km40o6fce1b91.jpg?width=785&format=pjpg&auto=webp&s=1e1079e839c8230f03df4bcd25b2cc3d58d42049",3,16,2022-07-12 04:12:21, r  machine learning operations  mlops   overview  definition  and architecture,paper   https abstract  the final goal of all industrial machine learning  ml  projects is to develop ml products and rapidly bring them into production  however  it is highly challenging to automate and operationalize ml products and thus many ml endeavors fail to deliver on their expectations  the paradigm of machine learning operations  mlops  addresses this issue  mlops includes several aspects  such as best practices  sets of concepts  and development culture  however  mlops is still a vague term and its consequences for researchers and professionals are ambiguous  to address this gap  we conduct mixed method research  including a literature review  a tool review  and expert interviews  as a result of these investigations  we provide an aggregated overview of the necessary principles  components  and roles  as well as the associated architecture and workflows  furthermore  we furnish a definition of mlops and highlight open challenges in the field  finally  this work provides guidance for ml researchers and practitioners who want to automate and operate their ml products with a designated set of technologies  https   preview redd it kmofceb jpg width  format pjpg auto webp s eecfdfbcdbccdd,paper https abstract final goal industrial machine learning ml projects develop ml products rapidly bring production however highly challenging automate operationalize ml products thus many ml endeavors fail deliver expectations paradigm machine learning operations mlops addresses issue mlops includes several aspects best practices sets concepts development culture however mlops still vague term consequences researchers professionals ambiguous address gap conduct mixed method research including literature review tool review expert interviews result investigations provide aggregated overview necessary principles components roles well associated architecture workflows furthermore furnish definition mlops highlight open challenges field finally work provides guidance ml researchers practitioners want automate operate ml products designated set technologies https preview redd kmofceb jpg width format pjpg auto webp eecfdfbcdbccdd,r machine learning operations mlops overview definition architecture,r machine learning operations mlops overview definition architecturepaper https abstract final goal industrial machine learning ml projects develop ml products rapidly bring production however highly challenging automate operationalize ml products thus many ml endeavors fail deliver expectations paradigm machine learning operations mlops addresses issue mlops includes several aspects best practices sets concepts development culture however mlops still vague term consequences researchers professionals ambiguous address gap conduct mixed method research including literature review tool review expert interviews result investigations provide aggregated overview necessary principles components roles well associated architecture workflows furthermore furnish definition mlops highlight open challenges field finally work provides guidance ml researchers practitioners want automate operate ml products designated set technologies https preview redd kmofceb jpg width format pjpg auto webp eecfdfbcdbccdd,"['r', 'machine', 'learning', 'operations', 'mlops', 'overview', 'definition', 'architecturepaper', 'https', 'abstract', 'final', 'goal', 'industrial', 'machine', 'learning', 'ml', 'projects', 'develop', 'ml', 'products', 'rapidly', 'bring', 'production', 'however', 'highly', 'challenging', 'automate', 'operationalize', 'ml', 'products', 'thus', 'many', 'ml', 'endeavors', 'fail', 'deliver', 'expectations', 'paradigm', 'machine', 'learning', 'operations', 'mlops', 'addresses', 'issue', 'mlops', 'includes', 'several', 'aspects', 'best', 'practices', 'sets', 'concepts', 'development', 'culture', 'however', 'mlops', 'still', 'vague', 'term', 'consequences', 'researchers', 'professionals', 'ambiguous', 'address', 'gap', 'conduct', 'mixed', 'method', 'research', 'including', 'literature', 'review', 'tool', 'review', 'expert', 'interviews', 'result', 'investigations', 'provide', 'aggregated', 'overview', 'necessary', 'principles', 'components', 'roles', 'well', 'associated', 'architecture', 'workflows', 'furthermore', 'furnish', 'definition', 'mlops', 'highlight', 'open', 'challenges', 'field', 'finally', 'work', 'provides', 'guidance', 'ml', 'researchers', 'practitioners', 'want', 'automate', 'operate', 'ml', 'products', 'designated', 'set', 'technologies', 'https', 'preview', 'redd', 'kmofceb', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'eecfdfbcdbccdd']","['r', 'machin', 'learn', 'oper', 'mlop', 'overview', 'definit', 'architecturepap', 'http', 'abstract', 'final', 'goal', 'industri', 'machin', 'learn', 'ml', 'project', 'develop', 'ml', 'product', 'rapidli', 'bring', 'product', 'howev', 'highli', 'challeng', 'autom', 'operation', 'ml', 'product', 'thu', 'mani', 'ml', 'endeavor', 'fail', 'deliv', 'expect', 'paradigm', 'machin', 'learn', 'oper', 'mlop', 'address', 'issu', 'mlop', 'includ', 'sever', 'aspect', 'best', 'practic', 'set', 'concept', 'develop', 'cultur', 'howev', 'mlop', 'still', 'vagu', 'term', 'consequ', 'research', 'profession', 'ambigu', 'address', 'gap', 'conduct', 'mix', 'method', 'research', 'includ', 'literatur', 'review', 'tool', 'review', 'expert', 'interview', 'result', 'investig', 'provid', 'aggreg', 'overview', 'necessari', 'principl', 'compon', 'role', 'well', 'associ', 'architectur', 'workflow', 'furthermor', 'furnish', 'definit', 'mlop', 'highlight', 'open', 'challeng', 'field', 'final', 'work', 'provid', 'guidanc', 'ml', 'research', 'practition', 'want', 'autom', 'oper', 'ml', 'product', 'design', 'set', 'technolog', 'http', 'preview', 'redd', 'kmofceb', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'eecfdfbcdbccdd']"
248,272,272,anacondavibes,vx10zn,[D] Understanding how hardware plays a role in creating AI models," I'm wondering if there's any sort of article/videos/reddit post focused on explaining everything to know about hardware and it's impact on AI (cores, tensors, cores, threading, etc.) I have a lot of background from the software side so code optimization isn't something that tI've thought too much about but I'm currently working on building my own PC so I do need this information (I'm not looking for a guide because that won't help me learn, but I want to learn all this stuff from the ground up).

Any recommendations on where I can learn more about this? Thanks!",5,8,2022-07-12 06:14:58, d  understanding how hardware plays a role in creating ai models, i m wondering if there s any sort of article videos reddit post focused on explaining everything to know about hardware and it s impact on ai  cores  tensors  cores  threading  etc   i have a lot of background from the software side so code optimization isn t something that ti ve thought too much about but i m currently working on building my own pc so i do need this information  i m not looking for a guide because that won t help me learn  but i want to learn all this stuff from the ground up  any recommendations on where i can learn more about this  thanks ,wondering sort article videos reddit post focused explaining everything know hardware impact ai cores tensors cores threading etc lot background software side code optimization something ti thought much currently working building pc need information looking guide help learn want learn stuff ground recommendations learn thanks,understanding hardware plays role creating ai models,understanding hardware plays role creating ai modelswondering sort article videos reddit post focused explaining everything know hardware impact ai cores tensors cores threading etc lot background software side code optimization something ti thought much currently working building pc need information looking guide help learn want learn stuff ground recommendations learn thanks,"['understanding', 'hardware', 'plays', 'role', 'creating', 'ai', 'modelswondering', 'sort', 'article', 'videos', 'reddit', 'post', 'focused', 'explaining', 'everything', 'know', 'hardware', 'impact', 'ai', 'cores', 'tensors', 'cores', 'threading', 'etc', 'lot', 'background', 'software', 'side', 'code', 'optimization', 'something', 'ti', 'thought', 'much', 'currently', 'working', 'building', 'pc', 'need', 'information', 'looking', 'guide', 'help', 'learn', 'want', 'learn', 'stuff', 'ground', 'recommendations', 'learn', 'thanks']","['understand', 'hardwar', 'play', 'role', 'creat', 'ai', 'modelswond', 'sort', 'articl', 'video', 'reddit', 'post', 'focus', 'explain', 'everyth', 'know', 'hardwar', 'impact', 'ai', 'core', 'tensor', 'core', 'thread', 'etc', 'lot', 'background', 'softwar', 'side', 'code', 'optim', 'someth', 'ti', 'thought', 'much', 'current', 'work', 'build', 'pc', 'need', 'inform', 'look', 'guid', 'help', 'learn', 'want', 'learn', 'stuff', 'ground', 'recommend', 'learn', 'thank']"
249,273,273,Character-Rip-5824,vwxs2u,"""[Project]"" Brainchop: In Browser 3D Segmentation. Now 50 and 104 Brain Segmentations. (Follow up).","&#x200B;

https://reddit.com/link/vwxs2u/video/91mo2fnr81b91/player

Live Demo:  [brainchop.org](https://neuroneural.github.io/brainchop/)

[Brainchop](https://github.com/neuroneural/brainchop) is  a  client-side web-application  for automatic segmentation of MRI     volumes  , we make implementation of [brainchop](https://github.com/neuroneural/brainchop) freely available releasing its pure **Javascript** code as open-source.

We appreciate your **ideas/feedback /comments** here or with the [discussion](https://github.com/neuroneural/brainchop/discussions) board",8,11,2022-07-12 03:34:49, project  brainchop  in browser d segmentation  now  and  brain segmentations   follow up  ,  xb https live demo    brainchop org  https  brainchop  https we appreciate your   ideas feedback  comments   here or with the  discussion  https   github com neuroneural brainchop discussions  board,xb https live demo brainchop org https brainchop https appreciate ideas feedback comments discussion https github com neuroneural brainchop discussions board,project brainchop browser segmentation brain segmentations follow,project brainchop browser segmentation brain segmentations followxb https live demo brainchop org https brainchop https appreciate ideas feedback comments discussion https github com neuroneural brainchop discussions board,"['project', 'brainchop', 'browser', 'segmentation', 'brain', 'segmentations', 'followxb', 'https', 'live', 'demo', 'brainchop', 'org', 'https', 'brainchop', 'https', 'appreciate', 'ideas', 'feedback', 'comments', 'discussion', 'https', 'github', 'com', 'neuroneural', 'brainchop', 'discussions', 'board']","['project', 'brainchop', 'browser', 'segment', 'brain', 'segment', 'followxb', 'http', 'live', 'demo', 'brainchop', 'org', 'http', 'brainchop', 'http', 'appreci', 'idea', 'feedback', 'comment', 'discuss', 'http', 'github', 'com', 'neuroneur', 'brainchop', 'discuss', 'board']"
250,274,274,AdelSexy,vwdp7n,[D] Next big thing in the field,"Do you guys have any forecasts of next big model/algorithm/concept in DL?

We had CNNs disrupting the field in \~2015, then GANs became a big deal, RL grown quite a lot, Transformers trended recently, now Diffusion models are moving probabilistic ML forward (sorry if I missed something). What other not fully investigated or underestimated concepts with high potential are there?",96,145,2022-07-11 11:48:13, d  next big thing in the field,do you guys have any forecasts of next big model algorithm concept in dl we had cnns disrupting the field in     then gans became a big deal  rl grown quite a lot  transformers trended recently  now diffusion models are moving probabilistic ml forward  sorry if i missed something   what other not fully investigated or underestimated concepts with high potential are there ,guys forecasts next big model algorithm concept dl cnns disrupting field gans became big deal rl grown quite lot transformers trended recently diffusion models moving probabilistic ml forward sorry missed something fully investigated underestimated concepts high potential,next big thing field,next big thing fieldguys forecasts next big model algorithm concept dl cnns disrupting field gans became big deal rl grown quite lot transformers trended recently diffusion models moving probabilistic ml forward sorry missed something fully investigated underestimated concepts high potential,"['next', 'big', 'thing', 'fieldguys', 'forecasts', 'next', 'big', 'model', 'algorithm', 'concept', 'dl', 'cnns', 'disrupting', 'field', 'gans', 'became', 'big', 'deal', 'rl', 'grown', 'quite', 'lot', 'transformers', 'trended', 'recently', 'diffusion', 'models', 'moving', 'probabilistic', 'ml', 'forward', 'sorry', 'missed', 'something', 'fully', 'investigated', 'underestimated', 'concepts', 'high', 'potential']","['next', 'big', 'thing', 'fieldguy', 'forecast', 'next', 'big', 'model', 'algorithm', 'concept', 'dl', 'cnn', 'disrupt', 'field', 'gan', 'becam', 'big', 'deal', 'rl', 'grown', 'quit', 'lot', 'transform', 'trend', 'recent', 'diffus', 'model', 'move', 'probabilist', 'ml', 'forward', 'sorri', 'miss', 'someth', 'fulli', 'investig', 'underestim', 'concept', 'high', 'potenti']"
251,275,275,Azuresonance,vw8jtp,[D] Why are Corgi dogs so popular in machine learning (especially in the image generation community)?,"For example, here's part of OpenAI's GLIDE paper:

https://preview.redd.it/b6vkxyb3xua91.png?width=1225&format=png&auto=webp&s=15d56f256e323bb54d22eb9fdc0538644060c4a7",68,324,2022-07-11 06:18:28, d  why are corgi dogs so popular in machine learning  especially in the image generation community  ,for example  here s part of openai s glide paper https   preview redd it bvkxybxua png width  format png auto webp s dfebbdebfdcca,example part openai glide paper https preview redd bvkxybxua png width format png auto webp dfebbdebfdcca,corgi dogs popular machine learning especially image generation community,corgi dogs popular machine learning especially image generation communityexample part openai glide paper https preview redd bvkxybxua png width format png auto webp dfebbdebfdcca,"['corgi', 'dogs', 'popular', 'machine', 'learning', 'especially', 'image', 'generation', 'communityexample', 'part', 'openai', 'glide', 'paper', 'https', 'preview', 'redd', 'bvkxybxua', 'png', 'width', 'format', 'png', 'auto', 'webp', 'dfebbdebfdcca']","['corgi', 'dog', 'popular', 'machin', 'learn', 'especi', 'imag', 'gener', 'communityexampl', 'part', 'openai', 'glide', 'paper', 'http', 'preview', 'redd', 'bvkxybxua', 'png', 'width', 'format', 'png', 'auto', 'webp', 'dfebbdebfdcca']"
252,276,276,shreyansh26,vwq2ac,[P] Paper Implementation - Extracting Training Data from Large Language Models," A re-implementation of the famous 2020 paper - ""Extracting Training Data from Large Language Models"" by Nicholas Carlini, Florian Tramer et al.

Code - [https://github.com/shreyansh26/Extracting-Training-Data-from-Large-Langauge-Models](https://github.com/shreyansh26/Extracting-Training-Data-from-Large-Langauge-Models)

The official implementation is great and I definitely learned a few things from it. In the re-implementation, I have also included the temperature-decay sampling and sliding-window-based minimum perplexity metric which was not present in the official implementation.

I checked the extracted Samples (refer to the Github repo) and they surely contained some memorized information.",0,16,2022-07-11 21:59:05, p  paper implementation   extracting training data from large language models, a re implementation of the famous  paper   extracting training data from large language models by nicholas carlini  florian tramer et al code    https the official implementation is great and i definitely learned a few things from it  in the re implementation  i have also included the temperature decay sampling and sliding window based minimum perplexity metric which was not present in the official implementation i checked the extracted samples  refer to the github repo  and they surely contained some memorized information ,implementation famous paper extracting training data large language models nicholas carlini florian tramer et al code https official implementation great definitely learned things implementation also included temperature decay sampling sliding window based minimum perplexity metric present official implementation checked extracted samples refer github repo surely contained memorized information,p paper implementation extracting training data large language models,p paper implementation extracting training data large language modelsimplementation famous paper extracting training data large language models nicholas carlini florian tramer et al code https official implementation great definitely learned things implementation also included temperature decay sampling sliding window based minimum perplexity metric present official implementation checked extracted samples refer github repo surely contained memorized information,"['p', 'paper', 'implementation', 'extracting', 'training', 'data', 'large', 'language', 'modelsimplementation', 'famous', 'paper', 'extracting', 'training', 'data', 'large', 'language', 'models', 'nicholas', 'carlini', 'florian', 'tramer', 'et', 'al', 'code', 'https', 'official', 'implementation', 'great', 'definitely', 'learned', 'things', 'implementation', 'also', 'included', 'temperature', 'decay', 'sampling', 'sliding', 'window', 'based', 'minimum', 'perplexity', 'metric', 'present', 'official', 'implementation', 'checked', 'extracted', 'samples', 'refer', 'github', 'repo', 'surely', 'contained', 'memorized', 'information']","['p', 'paper', 'implement', 'extract', 'train', 'data', 'larg', 'languag', 'modelsimplement', 'famou', 'paper', 'extract', 'train', 'data', 'larg', 'languag', 'model', 'nichola', 'carlini', 'florian', 'tramer', 'et', 'al', 'code', 'http', 'offici', 'implement', 'great', 'definit', 'learn', 'thing', 'implement', 'also', 'includ', 'temperatur', 'decay', 'sampl', 'slide', 'window', 'base', 'minimum', 'perplex', 'metric', 'present', 'offici', 'implement', 'check', 'extract', 'sampl', 'refer', 'github', 'repo', 'sure', 'contain', 'memor', 'inform']"
253,277,277,InfiniteLife2,vwkbtr,[D] What is your go-to algorithm for Multiple Object Tracking with possible long time occlusions?," 

Im interested in tracking cars and people with ability to solve occlusion of objects that might not be moving. Things I've tried are decent but not amazing(Deepsort, ByteTrack). There is a few recent studies about using transformers for tracking, but those things are heavy and not really production material, having deformable convolutions in them(hard or not possible convert to torchscript and tensorrt) and all.

What's your go-to algorithm for this kind of problem?",6,23,2022-07-11 17:54:38, d  what is your go to algorithm for multiple object tracking with possible long time occlusions , im interested in tracking cars and people with ability to solve occlusion of objects that might not be moving  things i ve tried are decent but not amazing deepsort  bytetrack   there is a few recent studies about using transformers for tracking  but those things are heavy and not really production material  having deformable convolutions in them hard or not possible convert to torchscript and tensorrt  and all what s your go to algorithm for this kind of problem ,im interested tracking cars people ability solve occlusion objects might moving things tried decent amazing deepsort bytetrack recent studies using transformers tracking things heavy really production material deformable convolutions hard possible convert torchscript tensorrt go algorithm kind problem,go algorithm multiple object tracking possible long time occlusions,go algorithm multiple object tracking possible long time occlusionsim interested tracking cars people ability solve occlusion objects might moving things tried decent amazing deepsort bytetrack recent studies using transformers tracking things heavy really production material deformable convolutions hard possible convert torchscript tensorrt go algorithm kind problem,"['go', 'algorithm', 'multiple', 'object', 'tracking', 'possible', 'long', 'time', 'occlusionsim', 'interested', 'tracking', 'cars', 'people', 'ability', 'solve', 'occlusion', 'objects', 'might', 'moving', 'things', 'tried', 'decent', 'amazing', 'deepsort', 'bytetrack', 'recent', 'studies', 'using', 'transformers', 'tracking', 'things', 'heavy', 'really', 'production', 'material', 'deformable', 'convolutions', 'hard', 'possible', 'convert', 'torchscript', 'tensorrt', 'go', 'algorithm', 'kind', 'problem']","['go', 'algorithm', 'multipl', 'object', 'track', 'possibl', 'long', 'time', 'occlusionsim', 'interest', 'track', 'car', 'peopl', 'abil', 'solv', 'occlus', 'object', 'might', 'move', 'thing', 'tri', 'decent', 'amaz', 'deepsort', 'bytetrack', 'recent', 'studi', 'use', 'transform', 'track', 'thing', 'heavi', 'realli', 'product', 'materi', 'deform', 'convolut', 'hard', 'possibl', 'convert', 'torchscript', 'tensorrt', 'go', 'algorithm', 'kind', 'problem']"
254,278,278,inigomlap,vwf9wo,[R] Closed-Form Diffeomorphic Transformations for Time Series Alignment,"Paper: [https://arxiv.org/pdf/2206.08107.pdf](https://arxiv.org/pdf/2206.08107.pdf)

Code: [https://github.com/imartinezl/difw](https://github.com/imartinezl/difw)

Abstract:

>Time series alignment methods call for highly expressive, differentiable and invertible warping functions which preserve temporal topology, i.e diffeomorphisms. **Diffeomorphic warping functions can be generated from the integration of velocity fields governed by an ordinary differential equation (ODE)**. Gradient-based optimization frameworks containing diffeomorphic transformations require to calculate derivatives to the differential equation's solution with respect to the model parameters, i.e. sensitivity analysis. Unfortunately, deep learning frameworks typically lack automatic-differentiation-compatible sensitivity analysis methods; and implicit functions, such as the solution of ODE, require particular care. Current solutions appeal to adjoint sensitivity methods, ad-hoc numerical solvers or ResNet's Eulerian discretization. In this work, we present a **closed-form expression for the ODE solution and its gradient under continuous piecewise-affine (CPA) velocity functions**. We present a highly optimized implementation of the results on CPU and GPU. Furthermore, we conduct extensive experiments on several datasets to validate the generalization ability of our model to unseen data for time-series joint alignment. Results show significant improvements both in terms of efficiency and accuracy.

https://reddit.com/link/vwf9wo/video/vvjnwp2y0xa91/player

&#x200B;",4,30,2022-07-11 13:37:37, r  closed form diffeomorphic transformations for time series alignment,paper   https code   https abstract  time series alignment methods call for highly expressive  differentiable and invertible warping functions which preserve temporal topology  i e diffeomorphisms    diffeomorphic warping functions can be generated from the integration of velocity fields governed by an ordinary differential equation  ode     gradient based optimization frameworks containing diffeomorphic transformations require to calculate derivatives to the differential equation s solution with respect to the model parameters  i e  sensitivity analysis  unfortunately  deep learning frameworks typically lack automatic differentiation compatible sensitivity analysis methods  and implicit functions  such as the solution of ode  require particular care  current solutions appeal to adjoint sensitivity methods  ad hoc numerical solvers or resnet s eulerian discretization  in this work  we present a   closed form expression for the ode solution and its gradient under continuous piecewise affine  cpa  velocity functions    we present a highly optimized implementation of the results on cpu and gpu  furthermore  we conduct extensive experiments on several datasets to validate the generalization ability of our model to unseen data for time series joint alignment  results show significant improvements both in terms of efficiency and accuracy https   xb ,paper https code https abstract time series alignment methods call highly expressive differentiable invertible warping functions preserve temporal topology e diffeomorphisms diffeomorphic warping functions generated integration velocity fields governed ordinary differential equation ode gradient based optimization frameworks containing diffeomorphic transformations require calculate derivatives differential equation solution respect model parameters e sensitivity analysis unfortunately deep learning frameworks typically lack automatic differentiation compatible sensitivity analysis methods implicit functions solution ode require particular care current solutions appeal adjoint sensitivity methods ad hoc numerical solvers resnet eulerian discretization work present closed form expression ode solution gradient continuous piecewise affine cpa velocity functions present highly optimized implementation results cpu gpu furthermore conduct extensive experiments several datasets validate generalization ability model unseen data time series joint alignment results show significant improvements terms efficiency accuracy https xb,r closed form diffeomorphic transformations time series alignment,r closed form diffeomorphic transformations time series alignmentpaper https code https abstract time series alignment methods call highly expressive differentiable invertible warping functions preserve temporal topology e diffeomorphisms diffeomorphic warping functions generated integration velocity fields governed ordinary differential equation ode gradient based optimization frameworks containing diffeomorphic transformations require calculate derivatives differential equation solution respect model parameters e sensitivity analysis unfortunately deep learning frameworks typically lack automatic differentiation compatible sensitivity analysis methods implicit functions solution ode require particular care current solutions appeal adjoint sensitivity methods ad hoc numerical solvers resnet eulerian discretization work present closed form expression ode solution gradient continuous piecewise affine cpa velocity functions present highly optimized implementation results cpu gpu furthermore conduct extensive experiments several datasets validate generalization ability model unseen data time series joint alignment results show significant improvements terms efficiency accuracy https xb,"['r', 'closed', 'form', 'diffeomorphic', 'transformations', 'time', 'series', 'alignmentpaper', 'https', 'code', 'https', 'abstract', 'time', 'series', 'alignment', 'methods', 'call', 'highly', 'expressive', 'differentiable', 'invertible', 'warping', 'functions', 'preserve', 'temporal', 'topology', 'e', 'diffeomorphisms', 'diffeomorphic', 'warping', 'functions', 'generated', 'integration', 'velocity', 'fields', 'governed', 'ordinary', 'differential', 'equation', 'ode', 'gradient', 'based', 'optimization', 'frameworks', 'containing', 'diffeomorphic', 'transformations', 'require', 'calculate', 'derivatives', 'differential', 'equation', 'solution', 'respect', 'model', 'parameters', 'e', 'sensitivity', 'analysis', 'unfortunately', 'deep', 'learning', 'frameworks', 'typically', 'lack', 'automatic', 'differentiation', 'compatible', 'sensitivity', 'analysis', 'methods', 'implicit', 'functions', 'solution', 'ode', 'require', 'particular', 'care', 'current', 'solutions', 'appeal', 'adjoint', 'sensitivity', 'methods', 'ad', 'hoc', 'numerical', 'solvers', 'resnet', 'eulerian', 'discretization', 'work', 'present', 'closed', 'form', 'expression', 'ode', 'solution', 'gradient', 'continuous', 'piecewise', 'affine', 'cpa', 'velocity', 'functions', 'present', 'highly', 'optimized', 'implementation', 'results', 'cpu', 'gpu', 'furthermore', 'conduct', 'extensive', 'experiments', 'several', 'datasets', 'validate', 'generalization', 'ability', 'model', 'unseen', 'data', 'time', 'series', 'joint', 'alignment', 'results', 'show', 'significant', 'improvements', 'terms', 'efficiency', 'accuracy', 'https', 'xb']","['r', 'close', 'form', 'diffeomorph', 'transform', 'time', 'seri', 'alignmentpap', 'http', 'code', 'http', 'abstract', 'time', 'seri', 'align', 'method', 'call', 'highli', 'express', 'differenti', 'invert', 'warp', 'function', 'preserv', 'tempor', 'topolog', 'e', 'diffeomorph', 'diffeomorph', 'warp', 'function', 'gener', 'integr', 'veloc', 'field', 'govern', 'ordinari', 'differenti', 'equat', 'ode', 'gradient', 'base', 'optim', 'framework', 'contain', 'diffeomorph', 'transform', 'requir', 'calcul', 'deriv', 'differenti', 'equat', 'solut', 'respect', 'model', 'paramet', 'e', 'sensit', 'analysi', 'unfortun', 'deep', 'learn', 'framework', 'typic', 'lack', 'automat', 'differenti', 'compat', 'sensit', 'analysi', 'method', 'implicit', 'function', 'solut', 'ode', 'requir', 'particular', 'care', 'current', 'solut', 'appeal', 'adjoint', 'sensit', 'method', 'ad', 'hoc', 'numer', 'solver', 'resnet', 'eulerian', 'discret', 'work', 'present', 'close', 'form', 'express', 'ode', 'solut', 'gradient', 'continu', 'piecewis', 'affin', 'cpa', 'veloc', 'function', 'present', 'highli', 'optim', 'implement', 'result', 'cpu', 'gpu', 'furthermor', 'conduct', 'extens', 'experi', 'sever', 'dataset', 'valid', 'gener', 'abil', 'model', 'unseen', 'data', 'time', 'seri', 'joint', 'align', 'result', 'show', 'signific', 'improv', 'term', 'effici', 'accuraci', 'http', 'xb']"
255,279,279,chaude_patate,vwln0s,[D] Speech Enhancement SOTA,"Audio denoising (removing background noises from audio), often referred as Speech Enhancement, has been a midly popular research field up to 2020. This was due to COVID and the need to filter unwanted noises from calls. 

However, I'm not sure where we're at today:

* [Music Source Separation](https://www.reddit.com/r/MachineLearning/comments/pqpl7m/r_decoupling_magnitude_and_phase_estimation_with/) is improved by Tiktok and Deezer's researches
* Meta's [denoiser](https://github.com/facebookresearch/denoiser) looks like the most standard, production-ready model, and it implements a 2020 paper

I'd like to search for more alternatives, but I struggle to find some:

* Googling ""Denoising"" will lead to images noise removal
* Paper with Code's ""Speech denoising"" and ""Audio denoising"" categories are pretty empty. 
* The ""[Speech Enhancement](https://paperswithcode.com/task/speech-enhancement)"" category seems to be the real deal, but the top models don't have any pretrained version available.

Is there a model that outperform Meta's denoiser, while remaining open-source with an available pretrained model?",4,6,2022-07-11 18:51:43, d  speech enhancement sota,audio denoising  removing background noises from audio   often referred as speech enhancement  has been a midly popular research field up to   this was due to covid and the need to filter unwanted noises from calls  however  i m not sure where we re at today    music source separation  https   meta s  denoiser  https i d like to search for more alternatives  but i struggle to find some   googling denoising will lead to images noise removal  paper with code s speech denoising and audio denoising categories are pretty empty    the  speech enhancement  https is there a model that outperform meta s denoiser  while remaining open source with an available pretrained model ,audio denoising removing background noises audio often referred speech enhancement midly popular research field due covid need filter unwanted noises calls however sure today music source separation https meta denoiser https like search alternatives struggle find googling denoising lead images noise removal paper code speech denoising audio denoising categories pretty empty speech enhancement https model outperform meta denoiser remaining open source available pretrained model,speech enhancement sota,speech enhancement sotaaudio denoising removing background noises audio often referred speech enhancement midly popular research field due covid need filter unwanted noises calls however sure today music source separation https meta denoiser https like search alternatives struggle find googling denoising lead images noise removal paper code speech denoising audio denoising categories pretty empty speech enhancement https model outperform meta denoiser remaining open source available pretrained model,"['speech', 'enhancement', 'sotaaudio', 'denoising', 'removing', 'background', 'noises', 'audio', 'often', 'referred', 'speech', 'enhancement', 'midly', 'popular', 'research', 'field', 'due', 'covid', 'need', 'filter', 'unwanted', 'noises', 'calls', 'however', 'sure', 'today', 'music', 'source', 'separation', 'https', 'meta', 'denoiser', 'https', 'like', 'search', 'alternatives', 'struggle', 'find', 'googling', 'denoising', 'lead', 'images', 'noise', 'removal', 'paper', 'code', 'speech', 'denoising', 'audio', 'denoising', 'categories', 'pretty', 'empty', 'speech', 'enhancement', 'https', 'model', 'outperform', 'meta', 'denoiser', 'remaining', 'open', 'source', 'available', 'pretrained', 'model']","['speech', 'enhanc', 'sotaaudio', 'denois', 'remov', 'background', 'nois', 'audio', 'often', 'refer', 'speech', 'enhanc', 'midli', 'popular', 'research', 'field', 'due', 'covid', 'need', 'filter', 'unwant', 'nois', 'call', 'howev', 'sure', 'today', 'music', 'sourc', 'separ', 'http', 'meta', 'denois', 'http', 'like', 'search', 'altern', 'struggl', 'find', 'googl', 'denois', 'lead', 'imag', 'nois', 'remov', 'paper', 'code', 'speech', 'denois', 'audio', 'denois', 'categori', 'pretti', 'empti', 'speech', 'enhanc', 'http', 'model', 'outperform', 'meta', 'denois', 'remain', 'open', 'sourc', 'avail', 'pretrain', 'model']"
256,280,280,Labib666Camp,vwi9p7,[D] Modeling Adjacency Matrix,"Lets assume, I have some directed adjacency matrix *A* at time *t* and another adjacency matrix *B* at time *t+1*. I want to learn a mapping from *A* to *B* through some model *f* (suppose *f* is a neural network). Now, how should I create this model ? Should I use just Dense layers or GNNs or something?",8,7,2022-07-11 16:19:34, d  modeling adjacency matrix,lets assume  i have some directed adjacency matrix  a  at time  t  and another adjacency matrix  b  at time  t    i want to learn a mapping from  a  to  b  through some model  f   suppose  f  is a neural network   now  how should i create this model   should i use just dense layers or gnns or something ,lets assume directed adjacency matrix time another adjacency matrix b time want learn mapping b model f suppose f neural network create model use dense layers gnns something,modeling adjacency matrix,modeling adjacency matrixlets assume directed adjacency matrix time another adjacency matrix b time want learn mapping b model f suppose f neural network create model use dense layers gnns something,"['modeling', 'adjacency', 'matrixlets', 'assume', 'directed', 'adjacency', 'matrix', 'time', 'another', 'adjacency', 'matrix', 'b', 'time', 'want', 'learn', 'mapping', 'b', 'model', 'f', 'suppose', 'f', 'neural', 'network', 'create', 'model', 'use', 'dense', 'layers', 'gnns', 'something']","['model', 'adjac', 'matrixlet', 'assum', 'direct', 'adjac', 'matrix', 'time', 'anoth', 'adjac', 'matrix', 'b', 'time', 'want', 'learn', 'map', 'b', 'model', 'f', 'suppos', 'f', 'neural', 'network', 'creat', 'model', 'use', 'dens', 'layer', 'gnn', 'someth']"
257,281,281,blessedorcursed,vwg37x,[P] Semi-supervised learning for tabular data: VIME,"A lot of recent DL models for tabular data have used some sort of pre-training to increase the robustness and performance metrics on smaller/noisy datasets. That's why I've decided to write a [deep-dive blog](https://syslog.ravelin.com/fraud-detection-with-minimum-labels-semi-supervised-learning-d2f8e7136da6) into a VIME paper which was one of the first to suggest pre-training tasks specific for tabular data. 

It comes with an accompanying [repo](https://github.com/aruberts/blogs/tree/main/vime) that contains all the code and notebooks. From some personal testing that I've done, pre-training is the most valuable does improve the performance when we're dealing with very few labels (1-5% of the dataset). Of course, the best solution is to always get more labels lol, but when it's not possible, pre-training schemes like VIME can give you a small boost in performance. 

Give it a read and let me know what you think! I'll keep covering some interesting deep tabular architectures, so maybe also let me know which one would you want me to cover next!",0,9,2022-07-11 14:27:07, p  semi supervised learning for tabular data  vime,a lot of recent dl models for tabular data have used some sort of pre training to increase the robustness and performance metrics on smaller noisy datasets  that s why i ve decided to write a  deep dive blog  https it comes with an accompanying  repo  https give it a read and let me know what you think  i ll keep covering some interesting deep tabular architectures  so maybe also let me know which one would you want me to cover next ,lot recent dl models tabular data used sort pre training increase robustness performance metrics smaller noisy datasets decided write deep dive blog https comes accompanying repo https give read let know think keep covering interesting deep tabular architectures maybe also let know one would want cover next,p semi supervised learning tabular data vime,p semi supervised learning tabular data vimelot recent dl models tabular data used sort pre training increase robustness performance metrics smaller noisy datasets decided write deep dive blog https comes accompanying repo https give read let know think keep covering interesting deep tabular architectures maybe also let know one would want cover next,"['p', 'semi', 'supervised', 'learning', 'tabular', 'data', 'vimelot', 'recent', 'dl', 'models', 'tabular', 'data', 'used', 'sort', 'pre', 'training', 'increase', 'robustness', 'performance', 'metrics', 'smaller', 'noisy', 'datasets', 'decided', 'write', 'deep', 'dive', 'blog', 'https', 'comes', 'accompanying', 'repo', 'https', 'give', 'read', 'let', 'know', 'think', 'keep', 'covering', 'interesting', 'deep', 'tabular', 'architectures', 'maybe', 'also', 'let', 'know', 'one', 'would', 'want', 'cover', 'next']","['p', 'semi', 'supervis', 'learn', 'tabular', 'data', 'vimelot', 'recent', 'dl', 'model', 'tabular', 'data', 'use', 'sort', 'pre', 'train', 'increas', 'robust', 'perform', 'metric', 'smaller', 'noisi', 'dataset', 'decid', 'write', 'deep', 'dive', 'blog', 'http', 'come', 'accompani', 'repo', 'http', 'give', 'read', 'let', 'know', 'think', 'keep', 'cover', 'interest', 'deep', 'tabular', 'architectur', 'mayb', 'also', 'let', 'know', 'one', 'would', 'want', 'cover', 'next']"
258,283,283,EnricoShippole,vwmlrs,[P] ScalableViT Implementation in Flax,"An open-source implementation of the ScalableViT: Rethinking the Context-oriented Generalization of Vision Transformer research paper in Google's JAX and Flax.

""The vanilla self-attention mechanism inherently relies on pre-defined and steadfast computational dimensions. Such inflexibility restricts it from possessing context-oriented generalization that can bring more contextual cues and global representations. To mitigate this issue, we propose a Scalable Self-Attention (SSA) mechanism that leverages two scaling factors to release dimensions of query, key, and value matrix while unbinding them with the input. This scalability fetches context-oriented generalization and enhances object sensitivity, which pushes the whole network into a more effective trade-off state between accuracy and cost. Furthermore, we propose an Interactive Window-based Self-Attention (IWSA), which establishes interaction between non-overlapping regions by re-merging independent value tokens and aggregating spatial information from adjacent windows. By stacking the SSA and IWSA alternately, the Scalable Vision Transformer (ScalableViT) achieves state-of-the-art performance in general-purpose vision tasks. For example, ScalableViT-S outperforms Twins-SVT-S by 1.4% and Swin-T by 1.8% on ImageNet-1K classification."" - Rui Yang, Hailong Ma, Jie Wu, Yansong Tang, Xuefeng Xiao, Min Zheng, Xiu Li  


Github repository for the Flax / JAX model: [https://github.com/conceptofmind/Scalable-ViT-flax](https://github.com/conceptofmind/Scalable-ViT-flax)

ScalableViT Research Paper: [https://arxiv.org/abs/2203.10790](https://arxiv.org/abs/2203.10790)

In collaboration with Lucid: [https://github.com/lucidrains](https://github.com/lucidrains)",0,2,2022-07-11 19:31:46, p  scalablevit implementation in flax,an open source implementation of the scalablevit  rethinking the context oriented generalization of vision transformer research paper in google s jax and flax the vanilla self attention mechanism inherently relies on pre defined and steadfast computational dimensions  such inflexibility restricts it from possessing context oriented generalization that can bring more contextual cues and global representations  to mitigate this issue  we propose a scalable self attention  ssa  mechanism that leverages two scaling factors to release dimensions of query  key  and value matrix while unbinding them with the input  this scalability fetches context oriented generalization and enhances object sensitivity  which pushes the whole network into a more effective trade off state between accuracy and cost  furthermore  we propose an interactive window based self attention  iwsa   which establishes interaction between non overlapping regions by re merging independent value tokens and aggregating spatial information from adjacent windows  by stacking the ssa and iwsa alternately  the scalable vision transformer  scalablevit  achieves state of the art performance in general purpose vision tasks  for example  scalablevit s outperforms twins svt s by    and swin t by    on imagenet k classification    rui yang  hailong ma  jie wu  yansong tang  xuefeng xiao  min zheng  xiu li  github repository for the flax   jax model   https scalablevit research paper   https in collaboration with lucid   https   github com lucidrains  https   github com lucidrains ,open source implementation scalablevit rethinking context oriented generalization vision transformer research paper google jax flax vanilla self attention mechanism inherently relies pre defined steadfast computational dimensions inflexibility restricts possessing context oriented generalization bring contextual cues global representations mitigate issue propose scalable self attention ssa mechanism leverages two scaling factors release dimensions query key value matrix unbinding input scalability fetches context oriented generalization enhances object sensitivity pushes whole network effective trade state accuracy cost furthermore propose interactive window based self attention iwsa establishes interaction non overlapping regions merging independent value tokens aggregating spatial information adjacent windows stacking ssa iwsa alternately scalable vision transformer scalablevit achieves state art performance general purpose vision tasks example scalablevit outperforms twins svt swin imagenet k classification rui yang hailong jie wu yansong tang xuefeng xiao min zheng xiu li github repository flax jax model https scalablevit research paper https collaboration lucid https github com lucidrains https github com lucidrains,p scalablevit implementation flax,p scalablevit implementation flaxopen source implementation scalablevit rethinking context oriented generalization vision transformer research paper google jax flax vanilla self attention mechanism inherently relies pre defined steadfast computational dimensions inflexibility restricts possessing context oriented generalization bring contextual cues global representations mitigate issue propose scalable self attention ssa mechanism leverages two scaling factors release dimensions query key value matrix unbinding input scalability fetches context oriented generalization enhances object sensitivity pushes whole network effective trade state accuracy cost furthermore propose interactive window based self attention iwsa establishes interaction non overlapping regions merging independent value tokens aggregating spatial information adjacent windows stacking ssa iwsa alternately scalable vision transformer scalablevit achieves state art performance general purpose vision tasks example scalablevit outperforms twins svt swin imagenet k classification rui yang hailong jie wu yansong tang xuefeng xiao min zheng xiu li github repository flax jax model https scalablevit research paper https collaboration lucid https github com lucidrains https github com lucidrains,"['p', 'scalablevit', 'implementation', 'flaxopen', 'source', 'implementation', 'scalablevit', 'rethinking', 'context', 'oriented', 'generalization', 'vision', 'transformer', 'research', 'paper', 'google', 'jax', 'flax', 'vanilla', 'self', 'attention', 'mechanism', 'inherently', 'relies', 'pre', 'defined', 'steadfast', 'computational', 'dimensions', 'inflexibility', 'restricts', 'possessing', 'context', 'oriented', 'generalization', 'bring', 'contextual', 'cues', 'global', 'representations', 'mitigate', 'issue', 'propose', 'scalable', 'self', 'attention', 'ssa', 'mechanism', 'leverages', 'two', 'scaling', 'factors', 'release', 'dimensions', 'query', 'key', 'value', 'matrix', 'unbinding', 'input', 'scalability', 'fetches', 'context', 'oriented', 'generalization', 'enhances', 'object', 'sensitivity', 'pushes', 'whole', 'network', 'effective', 'trade', 'state', 'accuracy', 'cost', 'furthermore', 'propose', 'interactive', 'window', 'based', 'self', 'attention', 'iwsa', 'establishes', 'interaction', 'non', 'overlapping', 'regions', 'merging', 'independent', 'value', 'tokens', 'aggregating', 'spatial', 'information', 'adjacent', 'windows', 'stacking', 'ssa', 'iwsa', 'alternately', 'scalable', 'vision', 'transformer', 'scalablevit', 'achieves', 'state', 'art', 'performance', 'general', 'purpose', 'vision', 'tasks', 'example', 'scalablevit', 'outperforms', 'twins', 'svt', 'swin', 'imagenet', 'k', 'classification', 'rui', 'yang', 'hailong', 'jie', 'wu', 'yansong', 'tang', 'xuefeng', 'xiao', 'min', 'zheng', 'xiu', 'li', 'github', 'repository', 'flax', 'jax', 'model', 'https', 'scalablevit', 'research', 'paper', 'https', 'collaboration', 'lucid', 'https', 'github', 'com', 'lucidrains', 'https', 'github', 'com', 'lucidrains']","['p', 'scalablevit', 'implement', 'flaxopen', 'sourc', 'implement', 'scalablevit', 'rethink', 'context', 'orient', 'gener', 'vision', 'transform', 'research', 'paper', 'googl', 'jax', 'flax', 'vanilla', 'self', 'attent', 'mechan', 'inher', 'reli', 'pre', 'defin', 'steadfast', 'comput', 'dimens', 'inflex', 'restrict', 'possess', 'context', 'orient', 'gener', 'bring', 'contextu', 'cue', 'global', 'represent', 'mitig', 'issu', 'propos', 'scalabl', 'self', 'attent', 'ssa', 'mechan', 'leverag', 'two', 'scale', 'factor', 'releas', 'dimens', 'queri', 'key', 'valu', 'matrix', 'unbind', 'input', 'scalabl', 'fetch', 'context', 'orient', 'gener', 'enhanc', 'object', 'sensit', 'push', 'whole', 'network', 'effect', 'trade', 'state', 'accuraci', 'cost', 'furthermor', 'propos', 'interact', 'window', 'base', 'self', 'attent', 'iwsa', 'establish', 'interact', 'non', 'overlap', 'region', 'merg', 'independ', 'valu', 'token', 'aggreg', 'spatial', 'inform', 'adjac', 'window', 'stack', 'ssa', 'iwsa', 'altern', 'scalabl', 'vision', 'transform', 'scalablevit', 'achiev', 'state', 'art', 'perform', 'gener', 'purpos', 'vision', 'task', 'exampl', 'scalablevit', 'outperform', 'twin', 'svt', 'swin', 'imagenet', 'k', 'classif', 'rui', 'yang', 'hailong', 'jie', 'wu', 'yansong', 'tang', 'xuefeng', 'xiao', 'min', 'zheng', 'xiu', 'li', 'github', 'repositori', 'flax', 'jax', 'model', 'http', 'scalablevit', 'research', 'paper', 'http', 'collabor', 'lucid', 'http', 'github', 'com', 'lucidrain', 'http', 'github', 'com', 'lucidrain']"
259,284,284,cheemsdoge69,vwm5qa,[D] Instance segmentation using transformers,"Hi folks!
I am looking for beginner-friendly and easy to implement papers on instance segmentation using transformers.
Any help will be appreciated!!",1,1,2022-07-11 19:13:15, d  instance segmentation using transformers,hi folks i am looking for beginner friendly and easy to implement papers on instance segmentation using transformers any help will be appreciated  ,hi folks looking beginner friendly easy implement papers instance segmentation using transformers help appreciated,instance segmentation using transformers,instance segmentation using transformershi folks looking beginner friendly easy implement papers instance segmentation using transformers help appreciated,"['instance', 'segmentation', 'using', 'transformershi', 'folks', 'looking', 'beginner', 'friendly', 'easy', 'implement', 'papers', 'instance', 'segmentation', 'using', 'transformers', 'help', 'appreciated']","['instanc', 'segment', 'use', 'transformershi', 'folk', 'look', 'beginn', 'friendli', 'easi', 'implement', 'paper', 'instanc', 'segment', 'use', 'transform', 'help', 'appreci']"
260,285,285,CapitalShake3085,vwkwfr,[R] DA-Faster RCNN,"Hello,

I have reimplemented DA-Faster RCNN using Detectron2 one of the most important architecture for domain adaptation for object detection. This implementations is easy to use and can be used also with google colab :) here there is the link: [https://github.com/GiovanniPasq/DA-Faster-RCNN](https://github.com/GiovanniPasq/DA-Faster-RCNN)",0,1,2022-07-11 18:19:06, r  da faster rcnn,hello i have reimplemented da faster rcnn using detectron one of the most important architecture for domain adaptation for object detection  this implementations is easy to use and can be used also with google colab    here there is the link   https   github com giovannipasq da faster rcnn  https   github com giovannipasq da faster rcnn ,hello reimplemented da faster rcnn using detectron one important architecture domain adaptation object detection implementations easy use used also google colab link https github com giovannipasq da faster rcnn https github com giovannipasq da faster rcnn,r da faster rcnn,r da faster rcnnhello reimplemented da faster rcnn using detectron one important architecture domain adaptation object detection implementations easy use used also google colab link https github com giovannipasq da faster rcnn https github com giovannipasq da faster rcnn,"['r', 'da', 'faster', 'rcnnhello', 'reimplemented', 'da', 'faster', 'rcnn', 'using', 'detectron', 'one', 'important', 'architecture', 'domain', 'adaptation', 'object', 'detection', 'implementations', 'easy', 'use', 'used', 'also', 'google', 'colab', 'link', 'https', 'github', 'com', 'giovannipasq', 'da', 'faster', 'rcnn', 'https', 'github', 'com', 'giovannipasq', 'da', 'faster', 'rcnn']","['r', 'da', 'faster', 'rcnnhello', 'reimplement', 'da', 'faster', 'rcnn', 'use', 'detectron', 'one', 'import', 'architectur', 'domain', 'adapt', 'object', 'detect', 'implement', 'easi', 'use', 'use', 'also', 'googl', 'colab', 'link', 'http', 'github', 'com', 'giovannipasq', 'da', 'faster', 'rcnn', 'http', 'github', 'com', 'giovannipasq', 'da', 'faster', 'rcnn']"
261,286,286,aadityaura,vweop5,[R] An awesome collection of Federated learning & Blockchain research papers in the Healthcare domain,"An awesome collection of Federated learning & Blockchain research papers in the Healthcare domain.

  
Federated learning, a mechanism of training a shared global model with a central server while keeping all the sensitive data in local institutions where the data belong, provides great promise to connect the fragmented healthcare data sources with privacy preservation. This repo contains a curated list of Federated Learning papers/resources and recent advancements in Healthcare.

&#x200B;

* As of now \~**330 papers**
* Pr's welcome

[https://github.com/monk1337/Aweome-Heathcare-Federated-Learning](https://github.com/monk1337/Aweome-Heathcare-Federated-Learning)",0,2,2022-07-11 12:58:59, r  an awesome collection of federated learning   blockchain research papers in the healthcare domain,an awesome collection of federated learning   blockchain research papers in the healthcare domain   federated learning  a mechanism of training a shared global model with a central server while keeping all the sensitive data in local institutions where the data belong  provides great promise to connect the fragmented healthcare data sources with privacy preservation  this repo contains a curated list of federated learning papers resources and recent advancements in healthcare   xb   as of now      papers    pr s welcome https   github com monk aweome heathcare federated learning  https   github com monk aweome heathcare federated learning ,awesome collection federated learning blockchain research papers healthcare domain federated learning mechanism training shared global model central server keeping sensitive data local institutions data belong provides great promise connect fragmented healthcare data sources privacy preservation repo contains curated federated learning papers resources recent advancements healthcare xb papers pr welcome https github com monk aweome heathcare federated learning https github com monk aweome heathcare federated learning,r awesome collection federated learning blockchain research papers healthcare domain,r awesome collection federated learning blockchain research papers healthcare domainawesome collection federated learning blockchain research papers healthcare domain federated learning mechanism training shared global model central server keeping sensitive data local institutions data belong provides great promise connect fragmented healthcare data sources privacy preservation repo contains curated federated learning papers resources recent advancements healthcare xb papers pr welcome https github com monk aweome heathcare federated learning https github com monk aweome heathcare federated learning,"['r', 'awesome', 'collection', 'federated', 'learning', 'blockchain', 'research', 'papers', 'healthcare', 'domainawesome', 'collection', 'federated', 'learning', 'blockchain', 'research', 'papers', 'healthcare', 'domain', 'federated', 'learning', 'mechanism', 'training', 'shared', 'global', 'model', 'central', 'server', 'keeping', 'sensitive', 'data', 'local', 'institutions', 'data', 'belong', 'provides', 'great', 'promise', 'connect', 'fragmented', 'healthcare', 'data', 'sources', 'privacy', 'preservation', 'repo', 'contains', 'curated', 'federated', 'learning', 'papers', 'resources', 'recent', 'advancements', 'healthcare', 'xb', 'papers', 'pr', 'welcome', 'https', 'github', 'com', 'monk', 'aweome', 'heathcare', 'federated', 'learning', 'https', 'github', 'com', 'monk', 'aweome', 'heathcare', 'federated', 'learning']","['r', 'awesom', 'collect', 'feder', 'learn', 'blockchain', 'research', 'paper', 'healthcar', 'domainawesom', 'collect', 'feder', 'learn', 'blockchain', 'research', 'paper', 'healthcar', 'domain', 'feder', 'learn', 'mechan', 'train', 'share', 'global', 'model', 'central', 'server', 'keep', 'sensit', 'data', 'local', 'institut', 'data', 'belong', 'provid', 'great', 'promis', 'connect', 'fragment', 'healthcar', 'data', 'sourc', 'privaci', 'preserv', 'repo', 'contain', 'curat', 'feder', 'learn', 'paper', 'resourc', 'recent', 'advanc', 'healthcar', 'xb', 'paper', 'pr', 'welcom', 'http', 'github', 'com', 'monk', 'aweom', 'heathcar', 'feder', 'learn', 'http', 'github', 'com', 'monk', 'aweom', 'heathcar', 'feder', 'learn']"
262,287,287,timscarfe,vvkmf1,[D] Noam Chomsky on LLMs and discussion of LeCun paper (MLST),"""First we should ask the question whether LLM have achieved ANYTHING, ANYTHING in this domain. Answer, NO, they have achieved ZERO!"" - Noam Chomsky 

""There are engineering projects that are significantly advanced by \[[\#DL](https://mobile.twitter.com/hashtag/DL?src=hashtag_click)\] methods. And this is all the good. \[...\] Engineering is not a trivial field; it takes intelligence, invention, \[and\] creativity these achievements. That it contributes to science?"" - Noam Chomsky 

""There was a time \[supposedly dedicated\] to the study of the nature of [\#intelligence](https://mobile.twitter.com/hashtag/intelligence?src=hashtag_click). By now it has disappeared.""  Earlier, same interview: ""GPT-3 can \[only\] find some superficial irregularities in the data. \[...\] It's exciting for reporters in the NY Times."" - Noam Chomsky 

""It's not of interest to people, the idea of finding an explanation for something. \[...\] The \[original [\#AI](https://mobile.twitter.com/hashtag/AI?src=hashtag_click)\] field by now is considered old-fashioned, nonsense. \[...\] That's probably where the field will develop, where the money is. \[...\] But it's a shame."" - Noam Chomsky 

Thanks to Dagmar Monett for selecting the quotes!

Sorry for posting a controversial thread -- but this seemed noteworthy for /machinelearning 

Video: [https://youtu.be/axuGfh4UR9Q](https://youtu.be/axuGfh4UR9Q) \-- also some discussion of LeCun's recent position paper",259,277,2022-07-10 08:39:21, d  noam chomsky on llms and discussion of lecun paper  mlst ,first we should ask the question whether llm have achieved anything  anything in this domain  answer  no  they have achieved zero    noam chomsky there are engineering projects that are significantly advanced by      dl  https there was a time   supposedly dedicated   to the study of the nature of    intelligence  https it s not of interest to people  the idea of finding an explanation for something          the   original    ai  https thanks to dagmar monett for selecting the quotes sorry for posting a controversial thread    but this seemed noteworthy for  machinelearning video   https   youtu be axugfhurq  https   youtu be axugfhurq      also some discussion of lecun s recent position paper,first ask question whether llm achieved anything anything domain answer achieved zero noam chomsky engineering projects significantly advanced dl https time supposedly dedicated study nature intelligence https interest people idea finding explanation something original ai https thanks dagmar monett selecting quotes sorry posting controversial thread seemed noteworthy machinelearning video https youtu axugfhurq https youtu axugfhurq also discussion lecun recent position paper,noam chomsky llms discussion lecun paper mlst,noam chomsky llms discussion lecun paper mlstfirst ask question whether llm achieved anything anything domain answer achieved zero noam chomsky engineering projects significantly advanced dl https time supposedly dedicated study nature intelligence https interest people idea finding explanation something original ai https thanks dagmar monett selecting quotes sorry posting controversial thread seemed noteworthy machinelearning video https youtu axugfhurq https youtu axugfhurq also discussion lecun recent position paper,"['noam', 'chomsky', 'llms', 'discussion', 'lecun', 'paper', 'mlstfirst', 'ask', 'question', 'whether', 'llm', 'achieved', 'anything', 'anything', 'domain', 'answer', 'achieved', 'zero', 'noam', 'chomsky', 'engineering', 'projects', 'significantly', 'advanced', 'dl', 'https', 'time', 'supposedly', 'dedicated', 'study', 'nature', 'intelligence', 'https', 'interest', 'people', 'idea', 'finding', 'explanation', 'something', 'original', 'ai', 'https', 'thanks', 'dagmar', 'monett', 'selecting', 'quotes', 'sorry', 'posting', 'controversial', 'thread', 'seemed', 'noteworthy', 'machinelearning', 'video', 'https', 'youtu', 'axugfhurq', 'https', 'youtu', 'axugfhurq', 'also', 'discussion', 'lecun', 'recent', 'position', 'paper']","['noam', 'chomski', 'llm', 'discuss', 'lecun', 'paper', 'mlstfirst', 'ask', 'question', 'whether', 'llm', 'achiev', 'anyth', 'anyth', 'domain', 'answer', 'achiev', 'zero', 'noam', 'chomski', 'engin', 'project', 'significantli', 'advanc', 'dl', 'http', 'time', 'supposedli', 'dedic', 'studi', 'natur', 'intellig', 'http', 'interest', 'peopl', 'idea', 'find', 'explan', 'someth', 'origin', 'ai', 'http', 'thank', 'dagmar', 'monett', 'select', 'quot', 'sorri', 'post', 'controversi', 'thread', 'seem', 'noteworthi', 'machinelearn', 'video', 'http', 'youtu', 'axugfhurq', 'http', 'youtu', 'axugfhurq', 'also', 'discuss', 'lecun', 'recent', 'posit', 'paper']"
263,289,289,Capital_Revolution35,vw3tkf,"[P] A Website to generate Code Snippets, Regexes, Linux & Git & SQL Commands, HTML and CSS from a written description. Furthermore translate code snippets to many languages and get a regex explained in plain english. Moreover you can fix broken code snippets. All with the help of ML 🤖","https://reddit.com/link/vw3tkf/video/xe0t4pumpta91/player

https://reddit.com/link/vw3tkf/video/7pf9dl3npta91/player

**Programming**

* [**Function from Description**](https://programming-helper.com/generate-function)
* [**Code to Explanation**](https://programming-helper.com/code-to-explanation)
* [**Fix invalid Code**](https://programming-helper.com/fix-invalid-code)
* [**Translate Languages**](https://programming-helper.com/translate)
* [**Class from Description**](https://programming-helper.com/class-from-description)
* [**Get Language from Code**](https://programming-helper.com/language-from-code)
* [**Function from Docstring**](https://programming-helper.com/docstring)

**Helpers**

* [**Regex from Description**](https://programming-helper.com/regex)
* [**Regex to Explanation**](https://programming-helper.com/regex-explanation)
* [**Linux Command**](https://programming-helper.com/linux)
* [**Get time complexity**](https://programming-helper.com/time-complexity)
* [**Git Command from Description**](https://programming-helper.com/git)

**Database**

* [**Text Description to SQL Command**](https://programming-helper.com/text-to-sql-syntax)

**Web**

* [**Generate HTML from Description**](https://programming-helper.com/generate-html-from-description)
* [**CSS from Description**](https://programming-helper.com/css-from-description)
* [**Meta Tags from Description**](https://programming-helper.com/meta)

I think this could be helpful to a lot of people (especially for beginner programmers). You can check out all functionalities on your own here:

[programming-helper.com](https://programming-helper.com/)

**Have fun using the tool** ❤️",0,8,2022-07-11 02:14:09, p  a website to generate code snippets  regexes  linux   git   sql commands  html and css from a written description  furthermore translate code snippets to many languages and get a regex explained in plain english  moreover you can fix broken code snippets  all with the help of ml  ,https https   programming       function from description    https      code to explanation    https      fix invalid code    https      translate languages    https      class from description    https      get language from code    https      function from docstring    https   helpers       regex from description    https      regex to explanation    https      linux command    https      get time complexity    https      git command from description    https   database       text description to sql command    https   web       generate html from description    https      css from description    https      meta tags from description    https i think this could be helpful to a lot of people  especially for beginner programmers   you can check out all functionalities on your own here  programming helper com  https   have fun using the tool     ,https https programming function description https code explanation https fix invalid code https translate languages https class description https get language code https function docstring https helpers regex description https regex explanation https linux command https get time complexity https git command description https database text description sql command https web generate html description https css description https meta tags description https think could helpful lot people especially beginner programmers check functionalities programming helper com https fun using tool,p website generate code snippets regexes linux git sql commands html css written description furthermore translate code snippets many languages get regex explained plain english moreover fix broken code snippets help ml,p website generate code snippets regexes linux git sql commands html css written description furthermore translate code snippets many languages get regex explained plain english moreover fix broken code snippets help mlhttps https programming function description https code explanation https fix invalid code https translate languages https class description https get language code https function docstring https helpers regex description https regex explanation https linux command https get time complexity https git command description https database text description sql command https web generate html description https css description https meta tags description https think could helpful lot people especially beginner programmers check functionalities programming helper com https fun using tool,"['p', 'website', 'generate', 'code', 'snippets', 'regexes', 'linux', 'git', 'sql', 'commands', 'html', 'css', 'written', 'description', 'furthermore', 'translate', 'code', 'snippets', 'many', 'languages', 'get', 'regex', 'explained', 'plain', 'english', 'moreover', 'fix', 'broken', 'code', 'snippets', 'help', 'mlhttps', 'https', 'programming', 'function', 'description', 'https', 'code', 'explanation', 'https', 'fix', 'invalid', 'code', 'https', 'translate', 'languages', 'https', 'class', 'description', 'https', 'get', 'language', 'code', 'https', 'function', 'docstring', 'https', 'helpers', 'regex', 'description', 'https', 'regex', 'explanation', 'https', 'linux', 'command', 'https', 'get', 'time', 'complexity', 'https', 'git', 'command', 'description', 'https', 'database', 'text', 'description', 'sql', 'command', 'https', 'web', 'generate', 'html', 'description', 'https', 'css', 'description', 'https', 'meta', 'tags', 'description', 'https', 'think', 'could', 'helpful', 'lot', 'people', 'especially', 'beginner', 'programmers', 'check', 'functionalities', 'programming', 'helper', 'com', 'https', 'fun', 'using', 'tool']","['p', 'websit', 'gener', 'code', 'snippet', 'regex', 'linux', 'git', 'sql', 'command', 'html', 'css', 'written', 'descript', 'furthermor', 'translat', 'code', 'snippet', 'mani', 'languag', 'get', 'regex', 'explain', 'plain', 'english', 'moreov', 'fix', 'broken', 'code', 'snippet', 'help', 'mlhttp', 'http', 'program', 'function', 'descript', 'http', 'code', 'explan', 'http', 'fix', 'invalid', 'code', 'http', 'translat', 'languag', 'http', 'class', 'descript', 'http', 'get', 'languag', 'code', 'http', 'function', 'docstr', 'http', 'helper', 'regex', 'descript', 'http', 'regex', 'explan', 'http', 'linux', 'command', 'http', 'get', 'time', 'complex', 'http', 'git', 'command', 'descript', 'http', 'databas', 'text', 'descript', 'sql', 'command', 'http', 'web', 'gener', 'html', 'descript', 'http', 'css', 'descript', 'http', 'meta', 'tag', 'descript', 'http', 'think', 'could', 'help', 'lot', 'peopl', 'especi', 'beginn', 'programm', 'check', 'function', 'program', 'helper', 'com', 'http', 'fun', 'use', 'tool']"
264,290,290,ericyu3,vvvt52,[Project] Parakeet — Copilot for Colab,"Hello!

I've long been a big fan of [GitHub Copilot](https://github.com/features/copilot) — I've used it for a while now, and I find it super helpful for all sorts of things. But Copilot doesn't work in Colab or Jupyter notebooks, even though that's where a ton of ML and data science code is written.

**Parakeet** is a Chrome extension that provides Copilot-like code suggestions for notebooks.

I've been using Parakeet for my own needs for a bit, and I'm already getting a lot of mileage out of it. Just the other day, for example, I wanted to make a Seaborn plot but wasn't sure how. I wrote a short comment, Parakeet suggested some code, and the code worked on the first try!

# Installation

[**Install from the Chrome Web Store**](https://chrome.google.com/webstore/detail/parakeet/linkknplelcdbncponjdhcjdknlpgghc)

[View source code](https://github.com/uyhcire/parakeet)

You'll need an email to sign up.

Parakeet is currently **free to use** for everyone, though that may change once OpenAI introduces pricing for Codex.

# Demos

[Generating code to plot a sine wave.](https://i.redd.it/le5rzwb0ora91.gif)

[Plotting a heat map. All I had to do was write some comments — Parakeet's suggested code worked on the first try.](https://preview.redd.it/q1hl6uicpra91.png?width=1240&format=png&auto=webp&s=35e17142321dc9874aae82bc038f1828db4a3325)

# Limitations

Parakeet currently only works for Colab, though I'm considering extending Parakeet to support Jupyter. If you want to use Parakeet outside Colab, I'd love to hear about your use case! You can file an issue on GitHub or you can email me at [ericyu3@gmail.com](mailto:ericyu3@gmail.com).

To keep things simple, Parakeet only makes suggestions when you are at the end of a line, and Parakeet never makes multi-line suggestions.

# How it works

* Parakeet uses OpenAI's [Codex](https://openai.com/blog/openai-codex/) model, which is the same model that powers GitHub Copilot.
* Parakeet does not have access to Colab's internal state. Instead, Parakeet continuously parses Colab's HTML to extract cell contents and determine what row and column your cursor is on. This approach was finicky to get working, but I was able to get it to work reliably and with little performance penalty.
* Your code is never stored or logged. After a suggestion is generated, the input is immediately discarded.",7,25,2022-07-10 20:00:08, project  parakeet   copilot for colab,hello i ve long been a big fan of  github copilot  https   parakeet   is a chrome extension that provides copilot like code suggestions for notebooks i ve been using parakeet for my own needs for a bit  and i m already getting a lot of mileage out of it  just the other day  for example  i wanted to make a seaborn plot but wasn t sure how  i wrote a short comment  parakeet suggested some code  and the code worked on the first try   installation   install from the chrome web store    https  view source code  https you ll need an email to sign up parakeet is currently   free to use   for everyone  though that may change once openai introduces pricing for codex   demos generating code to plot a sine wave   https  plotting a heat map  all i had to do was write some comments   parakeet s suggested code worked on the first try   https   limitationsparakeet currently only works for colab  though i m considering extending parakeet to support jupyter  if you want to use parakeet outside colab  i d love to hear about your use case  you can file an issue on github or you can email me at  ericyu gmail com  mailto ericyu gmail com  to keep things simple  parakeet only makes suggestions when you are at the end of a line  and parakeet never makes multi line suggestions   how it works  parakeet uses openai s  codex  https   parakeet does not have access to colab s internal state  instead  parakeet continuously parses colab s html to extract cell contents and determine what row and column your cursor is on  this approach was finicky to get working  but i was able to get it to work reliably and with little performance penalty   your code is never stored or logged  after a suggestion is generated  the input is immediately discarded ,hello long big fan github copilot https parakeet chrome extension provides copilot like code suggestions notebooks using parakeet needs bit already getting lot mileage day example wanted make seaborn plot sure wrote short comment parakeet suggested code code worked first try installation install chrome web store https view source code https need email sign parakeet currently free use everyone though may change openai introduces pricing codex demos generating code plot sine wave https plotting heat map write comments parakeet suggested code worked first try https limitationsparakeet currently works colab though considering extending parakeet support jupyter want use parakeet outside colab love hear use case file issue github email ericyu gmail com mailto ericyu gmail com keep things simple parakeet makes suggestions end line parakeet never makes multi line suggestions works parakeet uses openai codex https parakeet access colab internal state instead parakeet continuously parses colab html extract cell contents determine row column cursor approach finicky get working able get work reliably little performance penalty code never stored logged suggestion generated input immediately discarded,project parakeet copilot colab,project parakeet copilot colabhello long big fan github copilot https parakeet chrome extension provides copilot like code suggestions notebooks using parakeet needs bit already getting lot mileage day example wanted make seaborn plot sure wrote short comment parakeet suggested code code worked first try installation install chrome web store https view source code https need email sign parakeet currently free use everyone though may change openai introduces pricing codex demos generating code plot sine wave https plotting heat map write comments parakeet suggested code worked first try https limitationsparakeet currently works colab though considering extending parakeet support jupyter want use parakeet outside colab love hear use case file issue github email ericyu gmail com mailto ericyu gmail com keep things simple parakeet makes suggestions end line parakeet never makes multi line suggestions works parakeet uses openai codex https parakeet access colab internal state instead parakeet continuously parses colab html extract cell contents determine row column cursor approach finicky get working able get work reliably little performance penalty code never stored logged suggestion generated input immediately discarded,"['project', 'parakeet', 'copilot', 'colabhello', 'long', 'big', 'fan', 'github', 'copilot', 'https', 'parakeet', 'chrome', 'extension', 'provides', 'copilot', 'like', 'code', 'suggestions', 'notebooks', 'using', 'parakeet', 'needs', 'bit', 'already', 'getting', 'lot', 'mileage', 'day', 'example', 'wanted', 'make', 'seaborn', 'plot', 'sure', 'wrote', 'short', 'comment', 'parakeet', 'suggested', 'code', 'code', 'worked', 'first', 'try', 'installation', 'install', 'chrome', 'web', 'store', 'https', 'view', 'source', 'code', 'https', 'need', 'email', 'sign', 'parakeet', 'currently', 'free', 'use', 'everyone', 'though', 'may', 'change', 'openai', 'introduces', 'pricing', 'codex', 'demos', 'generating', 'code', 'plot', 'sine', 'wave', 'https', 'plotting', 'heat', 'map', 'write', 'comments', 'parakeet', 'suggested', 'code', 'worked', 'first', 'try', 'https', 'limitationsparakeet', 'currently', 'works', 'colab', 'though', 'considering', 'extending', 'parakeet', 'support', 'jupyter', 'want', 'use', 'parakeet', 'outside', 'colab', 'love', 'hear', 'use', 'case', 'file', 'issue', 'github', 'email', 'ericyu', 'gmail', 'com', 'mailto', 'ericyu', 'gmail', 'com', 'keep', 'things', 'simple', 'parakeet', 'makes', 'suggestions', 'end', 'line', 'parakeet', 'never', 'makes', 'multi', 'line', 'suggestions', 'works', 'parakeet', 'uses', 'openai', 'codex', 'https', 'parakeet', 'access', 'colab', 'internal', 'state', 'instead', 'parakeet', 'continuously', 'parses', 'colab', 'html', 'extract', 'cell', 'contents', 'determine', 'row', 'column', 'cursor', 'approach', 'finicky', 'get', 'working', 'able', 'get', 'work', 'reliably', 'little', 'performance', 'penalty', 'code', 'never', 'stored', 'logged', 'suggestion', 'generated', 'input', 'immediately', 'discarded']","['project', 'parakeet', 'copilot', 'colabhello', 'long', 'big', 'fan', 'github', 'copilot', 'http', 'parakeet', 'chrome', 'extens', 'provid', 'copilot', 'like', 'code', 'suggest', 'notebook', 'use', 'parakeet', 'need', 'bit', 'alreadi', 'get', 'lot', 'mileag', 'day', 'exampl', 'want', 'make', 'seaborn', 'plot', 'sure', 'wrote', 'short', 'comment', 'parakeet', 'suggest', 'code', 'code', 'work', 'first', 'tri', 'instal', 'instal', 'chrome', 'web', 'store', 'http', 'view', 'sourc', 'code', 'http', 'need', 'email', 'sign', 'parakeet', 'current', 'free', 'use', 'everyon', 'though', 'may', 'chang', 'openai', 'introduc', 'price', 'codex', 'demo', 'gener', 'code', 'plot', 'sine', 'wave', 'http', 'plot', 'heat', 'map', 'write', 'comment', 'parakeet', 'suggest', 'code', 'work', 'first', 'tri', 'http', 'limitationsparakeet', 'current', 'work', 'colab', 'though', 'consid', 'extend', 'parakeet', 'support', 'jupyt', 'want', 'use', 'parakeet', 'outsid', 'colab', 'love', 'hear', 'use', 'case', 'file', 'issu', 'github', 'email', 'ericyu', 'gmail', 'com', 'mailto', 'ericyu', 'gmail', 'com', 'keep', 'thing', 'simpl', 'parakeet', 'make', 'suggest', 'end', 'line', 'parakeet', 'never', 'make', 'multi', 'line', 'suggest', 'work', 'parakeet', 'use', 'openai', 'codex', 'http', 'parakeet', 'access', 'colab', 'intern', 'state', 'instead', 'parakeet', 'continu', 'pars', 'colab', 'html', 'extract', 'cell', 'content', 'determin', 'row', 'column', 'cursor', 'approach', 'finicki', 'get', 'work', 'abl', 'get', 'work', 'reliabl', 'littl', 'perform', 'penalti', 'code', 'never', 'store', 'log', 'suggest', 'gener', 'input', 'immedi', 'discard']"
265,291,291,yosefschwartz,vvl47v,[D] What's the problem with Self-driving cars? Is it a lack of data or do we need a new technology breakthrough?,"I mean there was a time when everyone thought that in a few years we would have self-drive cars. We just need more data and computing and we'll get it.
But now Google has more than 20m miles on a public road and much more in simulations.
And Tesla has a lot of cars that collect data on the road.

But it's still not there so what is missing? Do we need a new technology breakthrough or it's just more data and computing power?",145,94,2022-07-10 09:11:48, d  what s the problem with self driving cars  is it a lack of data or do we need a new technology breakthrough ,i mean there was a time when everyone thought that in a few years we would have self drive cars  we just need more data and computing and we ll get it but now google has more than m miles on a public road and much more in simulations and tesla has a lot of cars that collect data on the road but it s still not there so what is missing  do we need a new technology breakthrough or it s just more data and computing power ,mean time everyone thought years would self drive cars need data computing get google miles public road much simulations tesla lot cars collect data road still missing need technology breakthrough data computing power,problem self driving cars lack data need technology breakthrough,problem self driving cars lack data need technology breakthroughmean time everyone thought years would self drive cars need data computing get google miles public road much simulations tesla lot cars collect data road still missing need technology breakthrough data computing power,"['problem', 'self', 'driving', 'cars', 'lack', 'data', 'need', 'technology', 'breakthroughmean', 'time', 'everyone', 'thought', 'years', 'would', 'self', 'drive', 'cars', 'need', 'data', 'computing', 'get', 'google', 'miles', 'public', 'road', 'much', 'simulations', 'tesla', 'lot', 'cars', 'collect', 'data', 'road', 'still', 'missing', 'need', 'technology', 'breakthrough', 'data', 'computing', 'power']","['problem', 'self', 'drive', 'car', 'lack', 'data', 'need', 'technolog', 'breakthroughmean', 'time', 'everyon', 'thought', 'year', 'would', 'self', 'drive', 'car', 'need', 'data', 'comput', 'get', 'googl', 'mile', 'public', 'road', 'much', 'simul', 'tesla', 'lot', 'car', 'collect', 'data', 'road', 'still', 'miss', 'need', 'technolog', 'breakthrough', 'data', 'comput', 'power']"
266,293,293,Sacrezar,vvubm7,[D] Any french Corpus like ALECTOR for simplification task?,"Hello, the title says it all. I'm trying to find any ressources (mainly aligned corpus) that could be helpful in identifying and simplifying complex sentences in French. [ALECTOR](https://aclanthology.org/2020.lrec-1.169/) is the only one I stumbled upon.

Do you have any resources or tips? I was wondering if searching for book and their simplified version could be useful but I fear it would be more like learning to translate old french into modern french.",0,6,2022-07-10 18:49:57, d  any french corpus like alector for simplification task ,hello  the title says it all  i m trying to find any ressources  mainly aligned corpus  that could be helpful in identifying and simplifying complex sentences in french   alector  https do you have any resources or tips  i was wondering if searching for book and their simplified version could be useful but i fear it would be more like learning to translate old french into modern french ,hello title says trying find ressources mainly aligned corpus could helpful identifying simplifying complex sentences french alector https resources tips wondering searching book simplified version could useful fear would like learning translate old french modern french,french corpus like alector simplification task,french corpus like alector simplification taskhello title says trying find ressources mainly aligned corpus could helpful identifying simplifying complex sentences french alector https resources tips wondering searching book simplified version could useful fear would like learning translate old french modern french,"['french', 'corpus', 'like', 'alector', 'simplification', 'taskhello', 'title', 'says', 'trying', 'find', 'ressources', 'mainly', 'aligned', 'corpus', 'could', 'helpful', 'identifying', 'simplifying', 'complex', 'sentences', 'french', 'alector', 'https', 'resources', 'tips', 'wondering', 'searching', 'book', 'simplified', 'version', 'could', 'useful', 'fear', 'would', 'like', 'learning', 'translate', 'old', 'french', 'modern', 'french']","['french', 'corpu', 'like', 'alector', 'simplif', 'taskhello', 'titl', 'say', 'tri', 'find', 'ressourc', 'mainli', 'align', 'corpu', 'could', 'help', 'identifi', 'simplifi', 'complex', 'sentenc', 'french', 'alector', 'http', 'resourc', 'tip', 'wonder', 'search', 'book', 'simplifi', 'version', 'could', 'use', 'fear', 'would', 'like', 'learn', 'translat', 'old', 'french', 'modern', 'french']"
267,295,295,DragonLord9,vuw77a,[N] First-Ever Course on Transformers: NOW PUBLIC,"**CS 25: Transformers United**

https://preview.redd.it/1st4o3tvtha91.png?width=350&format=png&auto=webp&s=e4416da38001692989304e980dd4d61d23a74398

Did you grow up wanting to play with robots that could turn into cars? While we can't offer those kinds of transformers, we do have a course on the class of deep learning models that have taken the world by storm.

Announcing the public release of our lectures from the first-ever course on **Transformers: CS25 Transformers United** ([http://cs25.stanford.edu](http://cs25.stanford.edu/)) held at [Stanford University](https://www.linkedin.com/school/stanford-university/).

Our intro video is out and available to watch here 👉: [***YouTube Link***](https://www.youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM&fbclid=IwAR2mJd868IzGp8ChykBBRTxq7RQh-KICfnAg8rLQ-qsekbhnUcd_z4-4E7g)

Bookmark and spread the word 🤗!

[(Twitter Thread)](https://twitter.com/DivGarg9/status/1545541542235975682?s=20&t=_Ed9dpjD9Qpx4svpMNDIKQ&fbclid=IwAR2tnSQROnkOQl15aa6nkfNFaJdrnZQHDbidooDaQRJALlWsYMiQU_37dn4)

Speaker talks out starting Monday ...",37,351,2022-07-09 10:17:02, n  first ever course on transformers  now public,  cs   transformers united  https did you grow up wanting to play with robots that could turn into cars  while we can t offer those kinds of transformers  we do have a course on the class of deep learning models that have taken the world by storm announcing the public release of our lectures from the first ever course on   transformers  cs transformers united     http our intro video is out and available to watch here        youtube link     https bookmark and spread the word     twitter thread   https speaker talks out starting monday    ,cs transformers united https grow wanting play robots could turn cars offer kinds transformers course class deep learning models taken world storm announcing public release lectures first ever course transformers cs transformers united http intro video available watch youtube link https bookmark spread word twitter thread https speaker talks starting monday,n first ever course transformers public,n first ever course transformers publiccs transformers united https grow wanting play robots could turn cars offer kinds transformers course class deep learning models taken world storm announcing public release lectures first ever course transformers cs transformers united http intro video available watch youtube link https bookmark spread word twitter thread https speaker talks starting monday,"['n', 'first', 'ever', 'course', 'transformers', 'publiccs', 'transformers', 'united', 'https', 'grow', 'wanting', 'play', 'robots', 'could', 'turn', 'cars', 'offer', 'kinds', 'transformers', 'course', 'class', 'deep', 'learning', 'models', 'taken', 'world', 'storm', 'announcing', 'public', 'release', 'lectures', 'first', 'ever', 'course', 'transformers', 'cs', 'transformers', 'united', 'http', 'intro', 'video', 'available', 'watch', 'youtube', 'link', 'https', 'bookmark', 'spread', 'word', 'twitter', 'thread', 'https', 'speaker', 'talks', 'starting', 'monday']","['n', 'first', 'ever', 'cours', 'transform', 'publicc', 'transform', 'unit', 'http', 'grow', 'want', 'play', 'robot', 'could', 'turn', 'car', 'offer', 'kind', 'transform', 'cours', 'class', 'deep', 'learn', 'model', 'taken', 'world', 'storm', 'announc', 'public', 'releas', 'lectur', 'first', 'ever', 'cours', 'transform', 'cs', 'transform', 'unit', 'http', 'intro', 'video', 'avail', 'watch', 'youtub', 'link', 'http', 'bookmark', 'spread', 'word', 'twitter', 'thread', 'http', 'speaker', 'talk', 'start', 'monday']"
268,296,296,Labib666Camp,vvms5n,[D] Interpreting Attention Weights,"I have seen in many papers, specially in Deep learning applications in medical imaging, that they interpret attention weights as something like interaction between features (ie. Feature Interaction). But, every time you train the model wouldn't you get new weights? Then, how does this interoperability holds any value if the weights keep changing everytime you run it?",5,3,2022-07-10 11:09:11, d  interpreting attention weights,i have seen in many papers  specially in deep learning applications in medical imaging  that they interpret attention weights as something like interaction between features  ie  feature interaction   but  every time you train the model wouldn t you get new weights  then  how does this interoperability holds any value if the weights keep changing everytime you run it ,seen many papers specially deep learning applications medical imaging interpret attention weights something like interaction features ie feature interaction every time train model get weights interoperability holds value weights keep changing everytime run,interpreting attention weights,interpreting attention weightsseen many papers specially deep learning applications medical imaging interpret attention weights something like interaction features ie feature interaction every time train model get weights interoperability holds value weights keep changing everytime run,"['interpreting', 'attention', 'weightsseen', 'many', 'papers', 'specially', 'deep', 'learning', 'applications', 'medical', 'imaging', 'interpret', 'attention', 'weights', 'something', 'like', 'interaction', 'features', 'ie', 'feature', 'interaction', 'every', 'time', 'train', 'model', 'get', 'weights', 'interoperability', 'holds', 'value', 'weights', 'keep', 'changing', 'everytime', 'run']","['interpret', 'attent', 'weightsseen', 'mani', 'paper', 'special', 'deep', 'learn', 'applic', 'medic', 'imag', 'interpret', 'attent', 'weight', 'someth', 'like', 'interact', 'featur', 'ie', 'featur', 'interact', 'everi', 'time', 'train', 'model', 'get', 'weight', 'interoper', 'hold', 'valu', 'weight', 'keep', 'chang', 'everytim', 'run']"
269,297,297,fromnighttilldawn,vuvslv,[D] When did tech companies start to publish ML papers and why?,"I never fully understood the need for tech companies to publish research papers at big conferences.

I think before the 2000s, tech companies were very secretive about their work. I mean, you wouldn't expect Microsoft to publish their latest research on their own motherboard at some conferences right?

Nowadays all of them are trying to advertise their latest tech in research papers that could possibly be replicated by anyone around the world. This is especially visible in ML.

Also it almost seems as if they don't have a goal in mind. A lot of the research papers (outside of those big models such as DALL-E) seem to be VERY random to me, hardly even related to their business interests.

How did it become this way and what is their motivation?",34,119,2022-07-09 09:49:50, d  when did tech companies start to publish ml papers and why ,i never fully understood the need for tech companies to publish research papers at big conferences i think before the s  tech companies were very secretive about their work  i mean  you wouldn t expect microsoft to publish their latest research on their own motherboard at some conferences right nowadays all of them are trying to advertise their latest tech in research papers that could possibly be replicated by anyone around the world  this is especially visible in ml also it almost seems as if they don t have a goal in mind  a lot of the research papers  outside of those big models such as dall e  seem to be very random to me  hardly even related to their business interests how did it become this way and what is their motivation ,never fully understood need tech companies publish research papers big conferences think tech companies secretive work mean expect microsoft publish latest research motherboard conferences right nowadays trying advertise latest tech research papers could possibly replicated anyone around world especially visible ml also almost seems goal mind lot research papers outside big models dall e seem random hardly even related business interests become way motivation,tech companies start publish ml papers,tech companies start publish ml papersnever fully understood need tech companies publish research papers big conferences think tech companies secretive work mean expect microsoft publish latest research motherboard conferences right nowadays trying advertise latest tech research papers could possibly replicated anyone around world especially visible ml also almost seems goal mind lot research papers outside big models dall e seem random hardly even related business interests become way motivation,"['tech', 'companies', 'start', 'publish', 'ml', 'papersnever', 'fully', 'understood', 'need', 'tech', 'companies', 'publish', 'research', 'papers', 'big', 'conferences', 'think', 'tech', 'companies', 'secretive', 'work', 'mean', 'expect', 'microsoft', 'publish', 'latest', 'research', 'motherboard', 'conferences', 'right', 'nowadays', 'trying', 'advertise', 'latest', 'tech', 'research', 'papers', 'could', 'possibly', 'replicated', 'anyone', 'around', 'world', 'especially', 'visible', 'ml', 'also', 'almost', 'seems', 'goal', 'mind', 'lot', 'research', 'papers', 'outside', 'big', 'models', 'dall', 'e', 'seem', 'random', 'hardly', 'even', 'related', 'business', 'interests', 'become', 'way', 'motivation']","['tech', 'compani', 'start', 'publish', 'ml', 'papersnev', 'fulli', 'understood', 'need', 'tech', 'compani', 'publish', 'research', 'paper', 'big', 'confer', 'think', 'tech', 'compani', 'secret', 'work', 'mean', 'expect', 'microsoft', 'publish', 'latest', 'research', 'motherboard', 'confer', 'right', 'nowaday', 'tri', 'advertis', 'latest', 'tech', 'research', 'paper', 'could', 'possibl', 'replic', 'anyon', 'around', 'world', 'especi', 'visibl', 'ml', 'also', 'almost', 'seem', 'goal', 'mind', 'lot', 'research', 'paper', 'outsid', 'big', 'model', 'dall', 'e', 'seem', 'random', 'hardli', 'even', 'relat', 'busi', 'interest', 'becom', 'way', 'motiv']"
270,298,298,SeucheAchat9115,vvs041,[D] Reimplementing an Object Detection Model.,How hard is it to reimplement an object detection model to reproduce the results on benchmarks like COCO. Lets take the DINO architecture or even some yolo v4-7 Model. How hard is it to build it from scratch to reach COCO results reported by the paper or official implementations?,5,0,2022-07-10 16:55:50, d  reimplementing an object detection model ,how hard is it to reimplement an object detection model to reproduce the results on benchmarks like coco  lets take the dino architecture or even some yolo v  model  how hard is it to build it from scratch to reach coco results reported by the paper or official implementations ,hard reimplement object detection model reproduce results benchmarks like coco lets take dino architecture even yolo v model hard build scratch reach coco results reported paper official implementations,reimplementing object detection model,reimplementing object detection modelhard reimplement object detection model reproduce results benchmarks like coco lets take dino architecture even yolo v model hard build scratch reach coco results reported paper official implementations,"['reimplementing', 'object', 'detection', 'modelhard', 'reimplement', 'object', 'detection', 'model', 'reproduce', 'results', 'benchmarks', 'like', 'coco', 'lets', 'take', 'dino', 'architecture', 'even', 'yolo', 'v', 'model', 'hard', 'build', 'scratch', 'reach', 'coco', 'results', 'reported', 'paper', 'official', 'implementations']","['reimplement', 'object', 'detect', 'modelhard', 'reimplement', 'object', 'detect', 'model', 'reproduc', 'result', 'benchmark', 'like', 'coco', 'let', 'take', 'dino', 'architectur', 'even', 'yolo', 'v', 'model', 'hard', 'build', 'scratch', 'reach', 'coco', 'result', 'report', 'paper', 'offici', 'implement']"
271,299,299,EnricoShippole,vv9kwp,[P] CaiT Implementation in Flax,"An open-source implementation of the Going deeper with Image Transformers research paper in Google's JAX and Flax.

""The paper also notes the difficulty in training vision transformers at greater depths and proposes two solutions. First, it proposes to do per-channel multiplication of the output of the residual block. Second, it proposes to have the patches attend to one another, and only allow the CLS token to attend to the patches in the last few layers."" - Lucid

Github repository for the Flax / JAX model: [https://github.com/conceptofmind/CaiT-Flax](https://github.com/conceptofmind/CaiT-Flax)

CaiT Research Paper: [https://arxiv.org/abs/2103.17239](https://arxiv.org/abs/2103.17239)

Official PyTorch repository: [https://github.com/rwightman/pytorch-image-models](https://github.com/rwightman/pytorch-image-models)

In collaboration with Lucid: [https://github.com/lucidrains](https://github.com/lucidrains)",0,12,2022-07-09 22:49:50, p  cait implementation in flax,an open source implementation of the going deeper with image transformers research paper in google s jax and flax the paper also notes the difficulty in training vision transformers at greater depths and proposes two solutions  first  it proposes to do per channel multiplication of the output of the residual block  second  it proposes to have the patches attend to one another  and only allow the cls token to attend to the patches in the last few layers    lucidgithub repository for the flax   jax model   https cait research paper   https official pytorch repository   https in collaboration with lucid   https   github com lucidrains  https   github com lucidrains ,open source implementation going deeper image transformers research paper google jax flax paper also notes difficulty training vision transformers greater depths proposes two solutions first proposes per channel multiplication output residual block second proposes patches attend one another allow cls token attend patches last layers lucidgithub repository flax jax model https cait research paper https official pytorch repository https collaboration lucid https github com lucidrains https github com lucidrains,p cait implementation flax,p cait implementation flaxopen source implementation going deeper image transformers research paper google jax flax paper also notes difficulty training vision transformers greater depths proposes two solutions first proposes per channel multiplication output residual block second proposes patches attend one another allow cls token attend patches last layers lucidgithub repository flax jax model https cait research paper https official pytorch repository https collaboration lucid https github com lucidrains https github com lucidrains,"['p', 'cait', 'implementation', 'flaxopen', 'source', 'implementation', 'going', 'deeper', 'image', 'transformers', 'research', 'paper', 'google', 'jax', 'flax', 'paper', 'also', 'notes', 'difficulty', 'training', 'vision', 'transformers', 'greater', 'depths', 'proposes', 'two', 'solutions', 'first', 'proposes', 'per', 'channel', 'multiplication', 'output', 'residual', 'block', 'second', 'proposes', 'patches', 'attend', 'one', 'another', 'allow', 'cls', 'token', 'attend', 'patches', 'last', 'layers', 'lucidgithub', 'repository', 'flax', 'jax', 'model', 'https', 'cait', 'research', 'paper', 'https', 'official', 'pytorch', 'repository', 'https', 'collaboration', 'lucid', 'https', 'github', 'com', 'lucidrains', 'https', 'github', 'com', 'lucidrains']","['p', 'cait', 'implement', 'flaxopen', 'sourc', 'implement', 'go', 'deeper', 'imag', 'transform', 'research', 'paper', 'googl', 'jax', 'flax', 'paper', 'also', 'note', 'difficulti', 'train', 'vision', 'transform', 'greater', 'depth', 'propos', 'two', 'solut', 'first', 'propos', 'per', 'channel', 'multipl', 'output', 'residu', 'block', 'second', 'propos', 'patch', 'attend', 'one', 'anoth', 'allow', 'cl', 'token', 'attend', 'patch', 'last', 'layer', 'lucidgithub', 'repositori', 'flax', 'jax', 'model', 'http', 'cait', 'research', 'paper', 'http', 'offici', 'pytorch', 'repositori', 'http', 'collabor', 'lucid', 'http', 'github', 'com', 'lucidrain', 'http', 'github', 'com', 'lucidrain']"
272,300,300,jacobgil,vv1pja,[P] May the best explanation win: A tutorial on benchmarking and tuning model explanations with pytorch-grad-cam,"The new release of the pytorch-grad-cam project focuses on metrics for the model explanations.

It's often exciting to see model explanations, and tempting to interpret them and get insights about what the model is doing. And a lot of times it is very useful.

However this has to be done with care - the model explanations can be wrong, or sub optimal. As shown in many papers, sometimes random explanations perform better.

So it's useful to have metrics that measure the quality of the explanations for an image, and sanity checks about them.

This can be used both for getting some trust in the explanation before using it,

but also for tuning the explanation and getting the best one for a given image (for example by checking different methods).

&#x200B;

This notebook gives a thorough overview of the different metrics used in the literature, issues with them, using sanity checks (like the Sobel Edge Detector, or a random CAM),

and most importantly shows how to use them to chose and tune the explanation in practice.

[https://github.com/jacobgil/pytorch-grad-cam/blob/master/tutorials/CAM%20Metrics%20And%20Tuning%20Tutorial.ipynb](https://github.com/jacobgil/pytorch-grad-cam/blob/master/tutorials/CAM%20Metrics%20And%20Tuning%20Tutorial.ipynb)

&#x200B;

The motivation here is to both make it easier for researchers to benchmark new algorithms, but also (maybe more importantly) when using the model explanations to tune them, get the most out of them, and find problems with them.",0,17,2022-07-09 16:27:24, p  may the best explanation win  a tutorial on benchmarking and tuning model explanations with pytorch grad cam,the new release of the pytorch grad cam project focuses on metrics for the model explanations it s often exciting to see model explanations  and tempting to interpret them and get insights about what the model is doing  and a lot of times it is very useful however this has to be done with care   the model explanations can be wrong  or sub optimal  as shown in many papers  sometimes random explanations perform better so it s useful to have metrics that measure the quality of the explanations for an image  and sanity checks about them this can be used both for getting some trust in the explanation before using it but also for tuning the explanation and getting the best one for a given image  for example by checking different methods    xb this notebook gives a thorough overview of the different metrics used in the literature  issues with them  using sanity checks  like the sobel edge detector  or a random cam  and most importantly shows how to use them to chose and tune the explanation in practice  https   xb the motivation here is to both make it easier for researchers to benchmark new algorithms  but also  maybe more importantly  when using the model explanations to tune them  get the most out of them  and find problems with them ,release pytorch grad cam project focuses metrics model explanations often exciting see model explanations tempting interpret get insights model lot times useful however done care model explanations wrong sub optimal shown many papers sometimes random explanations perform better useful metrics measure quality explanations image sanity checks used getting trust explanation using also tuning explanation getting best one given image example checking different methods xb notebook gives thorough overview different metrics used literature issues using sanity checks like sobel edge detector random cam importantly shows use chose tune explanation practice https xb motivation make easier researchers benchmark algorithms also maybe importantly using model explanations tune get find problems,p may best explanation win tutorial benchmarking tuning model explanations pytorch grad cam,p may best explanation win tutorial benchmarking tuning model explanations pytorch grad camrelease pytorch grad cam project focuses metrics model explanations often exciting see model explanations tempting interpret get insights model lot times useful however done care model explanations wrong sub optimal shown many papers sometimes random explanations perform better useful metrics measure quality explanations image sanity checks used getting trust explanation using also tuning explanation getting best one given image example checking different methods xb notebook gives thorough overview different metrics used literature issues using sanity checks like sobel edge detector random cam importantly shows use chose tune explanation practice https xb motivation make easier researchers benchmark algorithms also maybe importantly using model explanations tune get find problems,"['p', 'may', 'best', 'explanation', 'win', 'tutorial', 'benchmarking', 'tuning', 'model', 'explanations', 'pytorch', 'grad', 'camrelease', 'pytorch', 'grad', 'cam', 'project', 'focuses', 'metrics', 'model', 'explanations', 'often', 'exciting', 'see', 'model', 'explanations', 'tempting', 'interpret', 'get', 'insights', 'model', 'lot', 'times', 'useful', 'however', 'done', 'care', 'model', 'explanations', 'wrong', 'sub', 'optimal', 'shown', 'many', 'papers', 'sometimes', 'random', 'explanations', 'perform', 'better', 'useful', 'metrics', 'measure', 'quality', 'explanations', 'image', 'sanity', 'checks', 'used', 'getting', 'trust', 'explanation', 'using', 'also', 'tuning', 'explanation', 'getting', 'best', 'one', 'given', 'image', 'example', 'checking', 'different', 'methods', 'xb', 'notebook', 'gives', 'thorough', 'overview', 'different', 'metrics', 'used', 'literature', 'issues', 'using', 'sanity', 'checks', 'like', 'sobel', 'edge', 'detector', 'random', 'cam', 'importantly', 'shows', 'use', 'chose', 'tune', 'explanation', 'practice', 'https', 'xb', 'motivation', 'make', 'easier', 'researchers', 'benchmark', 'algorithms', 'also', 'maybe', 'importantly', 'using', 'model', 'explanations', 'tune', 'get', 'find', 'problems']","['p', 'may', 'best', 'explan', 'win', 'tutori', 'benchmark', 'tune', 'model', 'explan', 'pytorch', 'grad', 'camreleas', 'pytorch', 'grad', 'cam', 'project', 'focus', 'metric', 'model', 'explan', 'often', 'excit', 'see', 'model', 'explan', 'tempt', 'interpret', 'get', 'insight', 'model', 'lot', 'time', 'use', 'howev', 'done', 'care', 'model', 'explan', 'wrong', 'sub', 'optim', 'shown', 'mani', 'paper', 'sometim', 'random', 'explan', 'perform', 'better', 'use', 'metric', 'measur', 'qualiti', 'explan', 'imag', 'saniti', 'check', 'use', 'get', 'trust', 'explan', 'use', 'also', 'tune', 'explan', 'get', 'best', 'one', 'given', 'imag', 'exampl', 'check', 'differ', 'method', 'xb', 'notebook', 'give', 'thorough', 'overview', 'differ', 'metric', 'use', 'literatur', 'issu', 'use', 'saniti', 'check', 'like', 'sobel', 'edg', 'detector', 'random', 'cam', 'importantli', 'show', 'use', 'chose', 'tune', 'explan', 'practic', 'http', 'xb', 'motiv', 'make', 'easier', 'research', 'benchmark', 'algorithm', 'also', 'mayb', 'importantli', 'use', 'model', 'explan', 'tune', 'get', 'find', 'problem']"
273,301,301,DrSkoolie,vv3iu2,[R] How to use ML to predict time of life remaining on a physical asset of the input data has had all its failed samples scrubbed away?,"So I'm in a bit of a conundrum. I'm working on my PhD thesis regarding the management of physical assets (make a decision on whether to replace the asset or refurbish it or to leave it alone).

The first step to doing this is to predict the estimated time of life for each asset and I wish to use ML to do this. Each asset in my dataset has an installation date and a couple of input features (results of testing, characteristics of the asset, etc)

The problem is the dataset I have doesn't have any of the failed assets. Meaning that I am finding it very hard to set up an error term for the estimated time of life during training of the model.


Ideally, I should have failed samples and non-failed samples in my data but I only have the latter. How should I go about setting this up?

I've been trying for the past couple of months to get my hands on failed samples but I haven't had any luck.",11,2,2022-07-09 18:00:09, r  how to use ml to predict time of life remaining on a physical asset of the input data has had all its failed samples scrubbed away ,so i m in a bit of a conundrum  i m working on my phd thesis regarding the management of physical assets  make a decision on whether to replace the asset or refurbish it or to leave it alone  the first step to doing this is to predict the estimated time of life for each asset and i wish to use ml to do this  each asset in my dataset has an installation date and a couple of input features  results of testing  characteristics of the asset  etc the problem is the dataset i have doesn t have any of the failed assets  meaning that i am finding it very hard to set up an error term for the estimated time of life during training of the model ideally  i should have failed samples and non failed samples in my data but i only have the latter  how should i go about setting this up i ve been trying for the past couple of months to get my hands on failed samples but i haven t had any luck ,bit conundrum working phd thesis regarding management physical assets make decision whether replace asset refurbish leave alone first step predict estimated time life asset wish use ml asset dataset installation date couple input features results testing characteristics asset etc problem dataset failed assets meaning finding hard set error term estimated time life training model ideally failed samples non failed samples data latter go setting trying past couple months get hands failed samples luck,r use ml predict time life remaining physical asset input data failed samples scrubbed away,r use ml predict time life remaining physical asset input data failed samples scrubbed awaybit conundrum working phd thesis regarding management physical assets make decision whether replace asset refurbish leave alone first step predict estimated time life asset wish use ml asset dataset installation date couple input features results testing characteristics asset etc problem dataset failed assets meaning finding hard set error term estimated time life training model ideally failed samples non failed samples data latter go setting trying past couple months get hands failed samples luck,"['r', 'use', 'ml', 'predict', 'time', 'life', 'remaining', 'physical', 'asset', 'input', 'data', 'failed', 'samples', 'scrubbed', 'awaybit', 'conundrum', 'working', 'phd', 'thesis', 'regarding', 'management', 'physical', 'assets', 'make', 'decision', 'whether', 'replace', 'asset', 'refurbish', 'leave', 'alone', 'first', 'step', 'predict', 'estimated', 'time', 'life', 'asset', 'wish', 'use', 'ml', 'asset', 'dataset', 'installation', 'date', 'couple', 'input', 'features', 'results', 'testing', 'characteristics', 'asset', 'etc', 'problem', 'dataset', 'failed', 'assets', 'meaning', 'finding', 'hard', 'set', 'error', 'term', 'estimated', 'time', 'life', 'training', 'model', 'ideally', 'failed', 'samples', 'non', 'failed', 'samples', 'data', 'latter', 'go', 'setting', 'trying', 'past', 'couple', 'months', 'get', 'hands', 'failed', 'samples', 'luck']","['r', 'use', 'ml', 'predict', 'time', 'life', 'remain', 'physic', 'asset', 'input', 'data', 'fail', 'sampl', 'scrub', 'awaybit', 'conundrum', 'work', 'phd', 'thesi', 'regard', 'manag', 'physic', 'asset', 'make', 'decis', 'whether', 'replac', 'asset', 'refurbish', 'leav', 'alon', 'first', 'step', 'predict', 'estim', 'time', 'life', 'asset', 'wish', 'use', 'ml', 'asset', 'dataset', 'instal', 'date', 'coupl', 'input', 'featur', 'result', 'test', 'characterist', 'asset', 'etc', 'problem', 'dataset', 'fail', 'asset', 'mean', 'find', 'hard', 'set', 'error', 'term', 'estim', 'time', 'life', 'train', 'model', 'ideal', 'fail', 'sampl', 'non', 'fail', 'sampl', 'data', 'latter', 'go', 'set', 'tri', 'past', 'coupl', 'month', 'get', 'hand', 'fail', 'sampl', 'luck']"
274,303,303,Singularian2501,vueqv8,[R] DeepSpeed Inference: Enabling Efficient Inference of Transformer Models at Unprecedented Scale - Microsoft 2022,"Paper: [https://arxiv.org/pdf/2207.00032.pdf](https://arxiv.org/pdf/2207.00032.pdf)

Abstract:

>The past several years have witnessed the success of transformer-based models, and their scale and application scenarios continue to grow aggressively. The current landscape of transformer models is increasingly diverse: the model size varies drastically with the largest being of hundred-billion parameters; the model characteristics differ due to the sparsity introduced by the Mixture-of-Experts; the target application scenarios can be latency-critical or throughput-oriented; the deployment hardware could be single- or multi-GPU systems with different types of memory and storage, etc. With such increasing diversity and the fast-evolving pace of transformer models, designing a highly performant and efficient inference system is extremely challenging. In this paper, we present DeepSpeed Inference, a comprehensive system solution for transformer model inference to address the above-mentioned challenges. DeepSpeed Inference consists of (1) a multi-GPU inference solution to minimize latency while maximizing the throughput of both dense and sparse transformer models when they fit in aggregate GPU memory, and (2) a heterogeneous inference solution that leverages CPU and NVMe memory in addition to the GPU memory and compute to enable high inference throughput with large models which do not fit in aggregate GPU memory. **DeepSpeed Inference reduces latency by up to 7.3X over the state-of-the-art for latency-oriented scenarios and increases throughput by over 1.5x for throughput-oriented scenarios. Moreover, it enables trillion parameter scale inference under real-time latency constraints by leveraging hundreds of GPUs, an unprecedented scale for inference. It can inference 25x larger models than with GPU-only solutions, while delivering a high throughput of 84 TFLOPS (over 50% of A6000 peak).**       

https://preview.redd.it/a7a9ir42dda91.jpg?width=1440&format=pjpg&auto=webp&s=fd1aa3ac66117f0c8a3355553de61d8cb50fdb5e

https://preview.redd.it/am49dqo2dda91.jpg?width=1446&format=pjpg&auto=webp&s=ad5dc1c17301b6f006a1678e4afc8fca83c7bdd4

https://preview.redd.it/vyxod3jmdda91.jpg?width=694&format=pjpg&auto=webp&s=9397aa3727d36780d90e7c833e6c9d6dd0d848d0

https://preview.redd.it/x3tc9sumdda91.jpg?width=695&format=pjpg&auto=webp&s=703ef19715deac0b0d96cfc761e9e05e20e8e1a5

https://preview.redd.it/062lnm7ndda91.jpg?width=634&format=pjpg&auto=webp&s=71746178333a6e356cc8ff0392ca9cb5472f2862",4,120,2022-07-08 19:30:27, r  deepspeed inference  enabling efficient inference of transformer models at unprecedented scale   microsoft ,paper   https abstract  the past several years have witnessed the success of transformer based models  and their scale and application scenarios continue to grow aggressively  the current landscape of transformer models is increasingly diverse  the model size varies drastically with the largest being of hundred billion parameters  the model characteristics differ due to the sparsity introduced by the mixture of experts  the target application scenarios can be latency critical or throughput oriented  the deployment hardware could be single  or multi gpu systems with different types of memory and storage  etc  with such increasing diversity and the fast evolving pace of transformer models  designing a highly performant and efficient inference system is extremely challenging  in this paper  we present deepspeed inference  a comprehensive system solution for transformer model inference to address the above mentioned challenges  deepspeed inference consists of    a multi gpu inference solution to minimize latency while maximizing the throughput of both dense and sparse transformer models when they fit in aggregate gpu memory  and    a heterogeneous inference solution that leverages cpu and nvme memory in addition to the gpu memory and compute to enable high inference throughput with large models which do not fit in aggregate gpu memory    deepspeed inference reduces latency by up to  x over the state of the art for latency oriented scenarios and increases throughput by over  x for throughput oriented scenarios  moreover  it enables trillion parameter scale inference under real time latency constraints by leveraging hundreds of gpus  an unprecedented scale for inference  it can inference x larger models than with gpu only solutions  while delivering a high throughput of  tflops  over   of a peak           https https https https https   preview redd it lnmndda jpg width  format pjpg auto webp s aeccffcacbf,paper https abstract past several years witnessed success transformer based models scale application scenarios continue grow aggressively current landscape transformer models increasingly diverse model size varies drastically largest hundred billion parameters model characteristics differ due sparsity introduced mixture experts target application scenarios latency critical throughput oriented deployment hardware could single multi gpu systems different types memory storage etc increasing diversity fast evolving pace transformer models designing highly performant efficient inference system extremely challenging paper present deepspeed inference comprehensive system solution transformer model inference address mentioned challenges deepspeed inference consists multi gpu inference solution minimize latency maximizing throughput dense sparse transformer models fit aggregate gpu memory heterogeneous inference solution leverages cpu nvme memory addition gpu memory compute enable high inference throughput large models fit aggregate gpu memory deepspeed inference reduces latency x state art latency oriented scenarios increases throughput x throughput oriented scenarios moreover enables trillion parameter scale inference real time latency constraints leveraging hundreds gpus unprecedented scale inference inference x larger models gpu solutions delivering high throughput tflops peak https https https https https preview redd lnmndda jpg width format pjpg auto webp aeccffcacbf,r deepspeed inference enabling efficient inference transformer models unprecedented scale microsoft,r deepspeed inference enabling efficient inference transformer models unprecedented scale microsoftpaper https abstract past several years witnessed success transformer based models scale application scenarios continue grow aggressively current landscape transformer models increasingly diverse model size varies drastically largest hundred billion parameters model characteristics differ due sparsity introduced mixture experts target application scenarios latency critical throughput oriented deployment hardware could single multi gpu systems different types memory storage etc increasing diversity fast evolving pace transformer models designing highly performant efficient inference system extremely challenging paper present deepspeed inference comprehensive system solution transformer model inference address mentioned challenges deepspeed inference consists multi gpu inference solution minimize latency maximizing throughput dense sparse transformer models fit aggregate gpu memory heterogeneous inference solution leverages cpu nvme memory addition gpu memory compute enable high inference throughput large models fit aggregate gpu memory deepspeed inference reduces latency x state art latency oriented scenarios increases throughput x throughput oriented scenarios moreover enables trillion parameter scale inference real time latency constraints leveraging hundreds gpus unprecedented scale inference inference x larger models gpu solutions delivering high throughput tflops peak https https https https https preview redd lnmndda jpg width format pjpg auto webp aeccffcacbf,"['r', 'deepspeed', 'inference', 'enabling', 'efficient', 'inference', 'transformer', 'models', 'unprecedented', 'scale', 'microsoftpaper', 'https', 'abstract', 'past', 'several', 'years', 'witnessed', 'success', 'transformer', 'based', 'models', 'scale', 'application', 'scenarios', 'continue', 'grow', 'aggressively', 'current', 'landscape', 'transformer', 'models', 'increasingly', 'diverse', 'model', 'size', 'varies', 'drastically', 'largest', 'hundred', 'billion', 'parameters', 'model', 'characteristics', 'differ', 'due', 'sparsity', 'introduced', 'mixture', 'experts', 'target', 'application', 'scenarios', 'latency', 'critical', 'throughput', 'oriented', 'deployment', 'hardware', 'could', 'single', 'multi', 'gpu', 'systems', 'different', 'types', 'memory', 'storage', 'etc', 'increasing', 'diversity', 'fast', 'evolving', 'pace', 'transformer', 'models', 'designing', 'highly', 'performant', 'efficient', 'inference', 'system', 'extremely', 'challenging', 'paper', 'present', 'deepspeed', 'inference', 'comprehensive', 'system', 'solution', 'transformer', 'model', 'inference', 'address', 'mentioned', 'challenges', 'deepspeed', 'inference', 'consists', 'multi', 'gpu', 'inference', 'solution', 'minimize', 'latency', 'maximizing', 'throughput', 'dense', 'sparse', 'transformer', 'models', 'fit', 'aggregate', 'gpu', 'memory', 'heterogeneous', 'inference', 'solution', 'leverages', 'cpu', 'nvme', 'memory', 'addition', 'gpu', 'memory', 'compute', 'enable', 'high', 'inference', 'throughput', 'large', 'models', 'fit', 'aggregate', 'gpu', 'memory', 'deepspeed', 'inference', 'reduces', 'latency', 'x', 'state', 'art', 'latency', 'oriented', 'scenarios', 'increases', 'throughput', 'x', 'throughput', 'oriented', 'scenarios', 'moreover', 'enables', 'trillion', 'parameter', 'scale', 'inference', 'real', 'time', 'latency', 'constraints', 'leveraging', 'hundreds', 'gpus', 'unprecedented', 'scale', 'inference', 'inference', 'x', 'larger', 'models', 'gpu', 'solutions', 'delivering', 'high', 'throughput', 'tflops', 'peak', 'https', 'https', 'https', 'https', 'https', 'preview', 'redd', 'lnmndda', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'aeccffcacbf']","['r', 'deepspe', 'infer', 'enabl', 'effici', 'infer', 'transform', 'model', 'unpreced', 'scale', 'microsoftpap', 'http', 'abstract', 'past', 'sever', 'year', 'wit', 'success', 'transform', 'base', 'model', 'scale', 'applic', 'scenario', 'continu', 'grow', 'aggress', 'current', 'landscap', 'transform', 'model', 'increasingli', 'divers', 'model', 'size', 'vari', 'drastic', 'largest', 'hundr', 'billion', 'paramet', 'model', 'characterist', 'differ', 'due', 'sparsiti', 'introduc', 'mixtur', 'expert', 'target', 'applic', 'scenario', 'latenc', 'critic', 'throughput', 'orient', 'deploy', 'hardwar', 'could', 'singl', 'multi', 'gpu', 'system', 'differ', 'type', 'memori', 'storag', 'etc', 'increas', 'divers', 'fast', 'evolv', 'pace', 'transform', 'model', 'design', 'highli', 'perform', 'effici', 'infer', 'system', 'extrem', 'challeng', 'paper', 'present', 'deepspe', 'infer', 'comprehens', 'system', 'solut', 'transform', 'model', 'infer', 'address', 'mention', 'challeng', 'deepspe', 'infer', 'consist', 'multi', 'gpu', 'infer', 'solut', 'minim', 'latenc', 'maxim', 'throughput', 'dens', 'spars', 'transform', 'model', 'fit', 'aggreg', 'gpu', 'memori', 'heterogen', 'infer', 'solut', 'leverag', 'cpu', 'nvme', 'memori', 'addit', 'gpu', 'memori', 'comput', 'enabl', 'high', 'infer', 'throughput', 'larg', 'model', 'fit', 'aggreg', 'gpu', 'memori', 'deepspe', 'infer', 'reduc', 'latenc', 'x', 'state', 'art', 'latenc', 'orient', 'scenario', 'increas', 'throughput', 'x', 'throughput', 'orient', 'scenario', 'moreov', 'enabl', 'trillion', 'paramet', 'scale', 'infer', 'real', 'time', 'latenc', 'constraint', 'leverag', 'hundr', 'gpu', 'unpreced', 'scale', 'infer', 'infer', 'x', 'larger', 'model', 'gpu', 'solut', 'deliv', 'high', 'throughput', 'tflop', 'peak', 'http', 'http', 'http', 'http', 'http', 'preview', 'redd', 'lnmndda', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'aeccffcacbf']"
275,304,304,zxkj,vumtus,[D] How to evaluate a neural network in reverse?,"Say you have a neural network with 3 inputs, some hidden layers, and a single output.

There might be many sets of those 3 inputs that give you the same output value.

How can you evaluate this network in reverse, i.e. given an output value, find values of the 3 inputs that would yield that output?",36,33,2022-07-09 01:36:40, d  how to evaluate a neural network in reverse ,say you have a neural network with  inputs  some hidden layers  and a single output there might be many sets of those  inputs that give you the same output value how can you evaluate this network in reverse  i e  given an output value  find values of the  inputs that would yield that output ,say neural network inputs hidden layers single output might many sets inputs give output value evaluate network reverse e given output value find values inputs would yield output,evaluate neural network reverse,evaluate neural network reversesay neural network inputs hidden layers single output might many sets inputs give output value evaluate network reverse e given output value find values inputs would yield output,"['evaluate', 'neural', 'network', 'reversesay', 'neural', 'network', 'inputs', 'hidden', 'layers', 'single', 'output', 'might', 'many', 'sets', 'inputs', 'give', 'output', 'value', 'evaluate', 'network', 'reverse', 'e', 'given', 'output', 'value', 'find', 'values', 'inputs', 'would', 'yield', 'output']","['evalu', 'neural', 'network', 'reversesay', 'neural', 'network', 'input', 'hidden', 'layer', 'singl', 'output', 'might', 'mani', 'set', 'input', 'give', 'output', 'valu', 'evalu', 'network', 'revers', 'e', 'given', 'output', 'valu', 'find', 'valu', 'input', 'would', 'yield', 'output']"
276,305,305,highergraphic,vu4r1g,[P] Sioyek 1.4 | Academic PDF Viewer,"During my PhD, I developed an open source PDF viewer to help me with my research. I think it can be useful for the users of this sub. Some of the research-oriented features include:

* Quickly jump to or preview references (for example `Figure 3.1` for a figure or `[8]` for a reference). Works even if the document doesn't have links.
* Search paper names in google scholar by middle clicking on them (combined with the previous feature makes finding papers super fast)
* Searchable highlights/bookmarks
* Line-by-line highlighting for reduced eye strain ([video](https://user-images.githubusercontent.com/6392321/168427739-007be805-a457-4d1f-ba14-35c5070aae5f.mp4))
* Synctex Support
* Extensible using external scripts (see [this post](https://ahrm.github.io/jekyll/update/2022/07/05/implementing-a-screen-reader-for-sioyek.html) for some examples)
* And many other features which are explained in the github page including marks, history, portals, searchable table of contents, automatic table of contents generation, searchable previous documents, etc.

Here is a video demo of some of the features: https://www.youtube.com/watch?v=yTmCI0Xp5vI&t=3s

And here is the latest release:
https://github.com/ahrm/sioyek/releases/tag/v1.4.0

Disclaimer: I did introduce sioyek in this subreddit about a year ago, but it has changed a lot since then and some of the features suggested in the comments of last year's post are implemented, so I thought users of this subreddit might be interested in an update.",18,257,2022-07-08 10:11:27, p  sioyek     academic pdf viewer,during my phd  i developed an open source pdf viewer to help me with my research  i think it can be useful for the users of this sub  some of the research oriented features include   quickly jump to or preview references  for example  figure    for a figure or      for a reference   works even if the document doesn t have links   search paper names in google scholar by middle clicking on them  combined with the previous feature makes finding papers super fast   searchable highlights bookmarks  line by line highlighting for reduced eye strain   video  https   synctex support  extensible using external scripts  see  this post  https   and many other features which are explained in the github page including marks  history  portals  searchable table of contents  automatic table of contents generation  searchable previous documents  etc here is a video demo of some of the features  https and here is the latest release https disclaimer  i did introduce sioyek in this subreddit about a year ago  but it has changed a lot since then and some of the features suggested in the comments of last year s post are implemented  so i thought users of this subreddit might be interested in an update ,phd developed open source pdf viewer help research think useful users sub research oriented features include quickly jump preview references example figure figure reference works even document links search paper names google scholar middle clicking combined previous feature makes finding papers super fast searchable highlights bookmarks line line highlighting reduced eye strain video https synctex support extensible using external scripts see post https many features explained github page including marks history portals searchable table contents automatic table contents generation searchable previous documents etc video demo features https latest release https disclaimer introduce sioyek subreddit year ago changed lot since features suggested comments last year post implemented thought users subreddit might interested update,p sioyek academic pdf viewer,p sioyek academic pdf viewerphd developed open source pdf viewer help research think useful users sub research oriented features include quickly jump preview references example figure figure reference works even document links search paper names google scholar middle clicking combined previous feature makes finding papers super fast searchable highlights bookmarks line line highlighting reduced eye strain video https synctex support extensible using external scripts see post https many features explained github page including marks history portals searchable table contents automatic table contents generation searchable previous documents etc video demo features https latest release https disclaimer introduce sioyek subreddit year ago changed lot since features suggested comments last year post implemented thought users subreddit might interested update,"['p', 'sioyek', 'academic', 'pdf', 'viewerphd', 'developed', 'open', 'source', 'pdf', 'viewer', 'help', 'research', 'think', 'useful', 'users', 'sub', 'research', 'oriented', 'features', 'include', 'quickly', 'jump', 'preview', 'references', 'example', 'figure', 'figure', 'reference', 'works', 'even', 'document', 'links', 'search', 'paper', 'names', 'google', 'scholar', 'middle', 'clicking', 'combined', 'previous', 'feature', 'makes', 'finding', 'papers', 'super', 'fast', 'searchable', 'highlights', 'bookmarks', 'line', 'line', 'highlighting', 'reduced', 'eye', 'strain', 'video', 'https', 'synctex', 'support', 'extensible', 'using', 'external', 'scripts', 'see', 'post', 'https', 'many', 'features', 'explained', 'github', 'page', 'including', 'marks', 'history', 'portals', 'searchable', 'table', 'contents', 'automatic', 'table', 'contents', 'generation', 'searchable', 'previous', 'documents', 'etc', 'video', 'demo', 'features', 'https', 'latest', 'release', 'https', 'disclaimer', 'introduce', 'sioyek', 'subreddit', 'year', 'ago', 'changed', 'lot', 'since', 'features', 'suggested', 'comments', 'last', 'year', 'post', 'implemented', 'thought', 'users', 'subreddit', 'might', 'interested', 'update']","['p', 'sioyek', 'academ', 'pdf', 'viewerphd', 'develop', 'open', 'sourc', 'pdf', 'viewer', 'help', 'research', 'think', 'use', 'user', 'sub', 'research', 'orient', 'featur', 'includ', 'quickli', 'jump', 'preview', 'refer', 'exampl', 'figur', 'figur', 'refer', 'work', 'even', 'document', 'link', 'search', 'paper', 'name', 'googl', 'scholar', 'middl', 'click', 'combin', 'previou', 'featur', 'make', 'find', 'paper', 'super', 'fast', 'searchabl', 'highlight', 'bookmark', 'line', 'line', 'highlight', 'reduc', 'eye', 'strain', 'video', 'http', 'synctex', 'support', 'extens', 'use', 'extern', 'script', 'see', 'post', 'http', 'mani', 'featur', 'explain', 'github', 'page', 'includ', 'mark', 'histori', 'portal', 'searchabl', 'tabl', 'content', 'automat', 'tabl', 'content', 'gener', 'searchabl', 'previou', 'document', 'etc', 'video', 'demo', 'featur', 'http', 'latest', 'releas', 'http', 'disclaim', 'introduc', 'sioyek', 'subreddit', 'year', 'ago', 'chang', 'lot', 'sinc', 'featur', 'suggest', 'comment', 'last', 'year', 'post', 'implement', 'thought', 'user', 'subreddit', 'might', 'interest', 'updat']"
277,306,306,RohitDulam,vulpil,[R] Single-task Continual/Incremental/Online/Life-Long learning.," 

Hi everyone,

I am new to the domain of continual learning/incremental learning/online learning/life-long learning (honestly, not able to make out the difference between them) and I would like to know if there exists a single-task life-long learning domain/problem. All the papers that I have gone through consist of methods trained for multiple tasks where newer tasks are added over time. I am looking for models trained for a single task that can be updated over time with new data belonging to the same task. I already have a trained model that I would like to update over time with either single or multiple data points. Any related links or directions would be greatly appreciated. TIA.",2,5,2022-07-09 00:45:38, r  single task continual incremental online life long learning , hi everyone i am new to the domain of continual learning incremental learning online learning life long learning  honestly  not able to make out the difference between them  and i would like to know if there exists a single task life long learning domain problem  all the papers that i have gone through consist of methods trained for multiple tasks where newer tasks are added over time  i am looking for models trained for a single task that can be updated over time with new data belonging to the same task  i already have a trained model that i would like to update over time with either single or multiple data points  any related links or directions would be greatly appreciated  tia ,hi everyone domain continual learning incremental learning online learning life long learning honestly able make difference would like know exists single task life long learning domain problem papers gone consist methods trained multiple tasks newer tasks added time looking models trained single task updated time data belonging task already trained model would like update time either single multiple data points related links directions would greatly appreciated tia,r single task continual incremental online life long learning,r single task continual incremental online life long learninghi everyone domain continual learning incremental learning online learning life long learning honestly able make difference would like know exists single task life long learning domain problem papers gone consist methods trained multiple tasks newer tasks added time looking models trained single task updated time data belonging task already trained model would like update time either single multiple data points related links directions would greatly appreciated tia,"['r', 'single', 'task', 'continual', 'incremental', 'online', 'life', 'long', 'learninghi', 'everyone', 'domain', 'continual', 'learning', 'incremental', 'learning', 'online', 'learning', 'life', 'long', 'learning', 'honestly', 'able', 'make', 'difference', 'would', 'like', 'know', 'exists', 'single', 'task', 'life', 'long', 'learning', 'domain', 'problem', 'papers', 'gone', 'consist', 'methods', 'trained', 'multiple', 'tasks', 'newer', 'tasks', 'added', 'time', 'looking', 'models', 'trained', 'single', 'task', 'updated', 'time', 'data', 'belonging', 'task', 'already', 'trained', 'model', 'would', 'like', 'update', 'time', 'either', 'single', 'multiple', 'data', 'points', 'related', 'links', 'directions', 'would', 'greatly', 'appreciated', 'tia']","['r', 'singl', 'task', 'continu', 'increment', 'onlin', 'life', 'long', 'learninghi', 'everyon', 'domain', 'continu', 'learn', 'increment', 'learn', 'onlin', 'learn', 'life', 'long', 'learn', 'honestli', 'abl', 'make', 'differ', 'would', 'like', 'know', 'exist', 'singl', 'task', 'life', 'long', 'learn', 'domain', 'problem', 'paper', 'gone', 'consist', 'method', 'train', 'multipl', 'task', 'newer', 'task', 'ad', 'time', 'look', 'model', 'train', 'singl', 'task', 'updat', 'time', 'data', 'belong', 'task', 'alreadi', 'train', 'model', 'would', 'like', 'updat', 'time', 'either', 'singl', 'multipl', 'data', 'point', 'relat', 'link', 'direct', 'would', 'greatli', 'appreci', 'tia']"
278,307,307,MidnightMaverick,vu975k,[Discussion] Giving a machine learning presentation to laypeople,"Hello all,

I've been asked to deliver a machine learning presentation to cardiologists and doctors, obviously they have no prior expertise in this area. I had wondered if anyone else had some experience presenting to Laypeople in the context of machine learning.

Just looking for some ideas really, what would you cover? What examples would you give? How would you structure it?

Any help is always appreciated !

[Edit#1] Thank you for the help everyone, this is some really useful feedback that I will take on bosrd",14,24,2022-07-08 15:05:11, discussion  giving a machine learning presentation to laypeople,hello all i ve been asked to deliver a machine learning presentation to cardiologists and doctors  obviously they have no prior expertise in this area  i had wondered if anyone else had some experience presenting to laypeople in the context of machine learning just looking for some ideas really  what would you cover  what examples would you give  how would you structure it any help is always appreciated   edit   thank you for the help everyone  this is some really useful feedback that i will take on bosrd,hello asked deliver machine learning presentation cardiologists doctors obviously prior expertise area wondered anyone else experience presenting laypeople context machine learning looking ideas really would cover examples would give would structure help always appreciated edit thank help everyone really useful feedback take bosrd,discussion giving machine learning presentation laypeople,discussion giving machine learning presentation laypeoplehello asked deliver machine learning presentation cardiologists doctors obviously prior expertise area wondered anyone else experience presenting laypeople context machine learning looking ideas really would cover examples would give would structure help always appreciated edit thank help everyone really useful feedback take bosrd,"['discussion', 'giving', 'machine', 'learning', 'presentation', 'laypeoplehello', 'asked', 'deliver', 'machine', 'learning', 'presentation', 'cardiologists', 'doctors', 'obviously', 'prior', 'expertise', 'area', 'wondered', 'anyone', 'else', 'experience', 'presenting', 'laypeople', 'context', 'machine', 'learning', 'looking', 'ideas', 'really', 'would', 'cover', 'examples', 'would', 'give', 'would', 'structure', 'help', 'always', 'appreciated', 'edit', 'thank', 'help', 'everyone', 'really', 'useful', 'feedback', 'take', 'bosrd']","['discuss', 'give', 'machin', 'learn', 'present', 'laypeoplehello', 'ask', 'deliv', 'machin', 'learn', 'present', 'cardiologist', 'doctor', 'obvious', 'prior', 'expertis', 'area', 'wonder', 'anyon', 'els', 'experi', 'present', 'laypeopl', 'context', 'machin', 'learn', 'look', 'idea', 'realli', 'would', 'cover', 'exampl', 'would', 'give', 'would', 'structur', 'help', 'alway', 'appreci', 'edit', 'thank', 'help', 'everyon', 'realli', 'use', 'feedback', 'take', 'bosrd']"
279,308,308,QadriShyaari,vuh3z4,[P] Chart and Data Summarization,"I made an app that summarizes the data in csv files. Input a csv file and title of the file and the model will generate a summary.

[https://huggingface.co/spaces/saadob12/Chart\_Data\_Summarization](https://huggingface.co/spaces/saadob12/Chart_Data_Summarization)

The models: [https://huggingface.co/saadob12/t5\_C2T\_autochart](https://huggingface.co/saadob12/t5_C2T_autochart) and [https://huggingface.co/saadob12/t5\_C2T\_big](https://huggingface.co/saadob12/t5_C2T_big).",0,4,2022-07-08 21:15:48, p  chart and data summarization,i made an app that summarizes the data in csv files  input a csv file and title of the file and the model will generate a summary  https the models   https   huggingface co saadob t _ct _autochart  https   huggingface co saadob t_ct_autochart  and  https   huggingface co saadob t _ct _big  https   huggingface co saadob t_ct_big  ,made app summarizes data csv files input csv file title file model generate summary https models https huggingface co saadob _ct _autochart https huggingface co saadob t_ct_autochart https huggingface co saadob _ct _big https huggingface co saadob t_ct_big,p chart data summarization,p chart data summarizationmade app summarizes data csv files input csv file title file model generate summary https models https huggingface co saadob _ct _autochart https huggingface co saadob t_ct_autochart https huggingface co saadob _ct _big https huggingface co saadob t_ct_big,"['p', 'chart', 'data', 'summarizationmade', 'app', 'summarizes', 'data', 'csv', 'files', 'input', 'csv', 'file', 'title', 'file', 'model', 'generate', 'summary', 'https', 'models', 'https', 'huggingface', 'co', 'saadob', '_ct', '_autochart', 'https', 'huggingface', 'co', 'saadob', 't_ct_autochart', 'https', 'huggingface', 'co', 'saadob', '_ct', '_big', 'https', 'huggingface', 'co', 'saadob', 't_ct_big']","['p', 'chart', 'data', 'summarizationmad', 'app', 'summar', 'data', 'csv', 'file', 'input', 'csv', 'file', 'titl', 'file', 'model', 'gener', 'summari', 'http', 'model', 'http', 'huggingfac', 'co', 'saadob', '_ct', '_autochart', 'http', 'huggingfac', 'co', 'saadob', 't_ct_autochart', 'http', 'huggingfac', 'co', 'saadob', '_ct', '_big', 'http', 'huggingfac', 'co', 'saadob', 't_ct_big']"
280,309,309,applied-roboticist,vum5fb,[Discussion] How do I smoothen the output of an action segmentation model near the boundaries?,"Hello. Apologies if this is the wrong place to post because my problem is a simple one related to machine learning. My problem involves a robot that operates given the output of an action segmentation model. The trained model outputs an action label at every timestep e.g. \[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3\]. 

Given the sequence, I must now compute the time it takes to go from one label to the next. However, the actual output tends to be quite unstable especially when the action transitions from one to the next e.g., \[1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, ....\]. As such, I occasionally get multiple transitions. This simple issue makes the input unusable to the robot.

How can I clean up the output sequence? I thought of simple operations like converting the vector into a one-hot matrix and then running 1D erode and dilate operations but I was hoping to hear several other better suggestions.",4,1,2022-07-09 01:05:31, discussion  how do i smoothen the output of an action segmentation model near the boundaries ,hello  apologies if this is the wrong place to post because my problem is a simple one related to machine learning  my problem involves a robot that operates given the output of an action segmentation model  the trained model outputs an action label at every timestep e g                                                  given the sequence  i must now compute the time it takes to go from one label to the next  however  the actual output tends to be quite unstable especially when the action transitions from one to the next e g                                   as such  i occasionally get multiple transitions  this simple issue makes the input unusable to the robot how can i clean up the output sequence  i thought of simple operations like converting the vector into a one hot matrix and then running d erode and dilate operations but i was hoping to hear several other better suggestions ,hello apologies wrong place post problem simple one related machine learning problem involves robot operates given output action segmentation model trained model outputs action label every timestep e g given sequence must compute time takes go one label next however actual output tends quite unstable especially action transitions one next e g occasionally get multiple transitions simple issue makes input unusable robot clean output sequence thought simple operations like converting vector one hot matrix running erode dilate operations hoping hear several better suggestions,discussion smoothen output action segmentation model near boundaries,discussion smoothen output action segmentation model near boundarieshello apologies wrong place post problem simple one related machine learning problem involves robot operates given output action segmentation model trained model outputs action label every timestep e g given sequence must compute time takes go one label next however actual output tends quite unstable especially action transitions one next e g occasionally get multiple transitions simple issue makes input unusable robot clean output sequence thought simple operations like converting vector one hot matrix running erode dilate operations hoping hear several better suggestions,"['discussion', 'smoothen', 'output', 'action', 'segmentation', 'model', 'near', 'boundarieshello', 'apologies', 'wrong', 'place', 'post', 'problem', 'simple', 'one', 'related', 'machine', 'learning', 'problem', 'involves', 'robot', 'operates', 'given', 'output', 'action', 'segmentation', 'model', 'trained', 'model', 'outputs', 'action', 'label', 'every', 'timestep', 'e', 'g', 'given', 'sequence', 'must', 'compute', 'time', 'takes', 'go', 'one', 'label', 'next', 'however', 'actual', 'output', 'tends', 'quite', 'unstable', 'especially', 'action', 'transitions', 'one', 'next', 'e', 'g', 'occasionally', 'get', 'multiple', 'transitions', 'simple', 'issue', 'makes', 'input', 'unusable', 'robot', 'clean', 'output', 'sequence', 'thought', 'simple', 'operations', 'like', 'converting', 'vector', 'one', 'hot', 'matrix', 'running', 'erode', 'dilate', 'operations', 'hoping', 'hear', 'several', 'better', 'suggestions']","['discuss', 'smoothen', 'output', 'action', 'segment', 'model', 'near', 'boundarieshello', 'apolog', 'wrong', 'place', 'post', 'problem', 'simpl', 'one', 'relat', 'machin', 'learn', 'problem', 'involv', 'robot', 'oper', 'given', 'output', 'action', 'segment', 'model', 'train', 'model', 'output', 'action', 'label', 'everi', 'timestep', 'e', 'g', 'given', 'sequenc', 'must', 'comput', 'time', 'take', 'go', 'one', 'label', 'next', 'howev', 'actual', 'output', 'tend', 'quit', 'unstabl', 'especi', 'action', 'transit', 'one', 'next', 'e', 'g', 'occasion', 'get', 'multipl', 'transit', 'simpl', 'issu', 'make', 'input', 'unus', 'robot', 'clean', 'output', 'sequenc', 'thought', 'simpl', 'oper', 'like', 'convert', 'vector', 'one', 'hot', 'matrix', 'run', 'erod', 'dilat', 'oper', 'hope', 'hear', 'sever', 'better', 'suggest']"
281,310,310,kniranjankumar,vubrmf,[D] Searching for a paper on equivalent transformations on trained networks,"I had come across a paper that explored strategies to transform the architecture of a trained neural network, i.e. increasing layer width or adding additional layers, without forgetting what the network has already learnt. They describe initialization strategies to accomplish this. Does anyone know the paper I am talking about?",6,4,2022-07-08 17:14:37, d  searching for a paper on equivalent transformations on trained networks,i had come across a paper that explored strategies to transform the architecture of a trained neural network  i e  increasing layer width or adding additional layers  without forgetting what the network has already learnt  they describe initialization strategies to accomplish this  does anyone know the paper i am talking about ,come across paper explored strategies transform architecture trained neural network e increasing layer width adding additional layers without forgetting network already learnt describe initialization strategies accomplish anyone know paper talking,searching paper equivalent transformations trained networks,searching paper equivalent transformations trained networkscome across paper explored strategies transform architecture trained neural network e increasing layer width adding additional layers without forgetting network already learnt describe initialization strategies accomplish anyone know paper talking,"['searching', 'paper', 'equivalent', 'transformations', 'trained', 'networkscome', 'across', 'paper', 'explored', 'strategies', 'transform', 'architecture', 'trained', 'neural', 'network', 'e', 'increasing', 'layer', 'width', 'adding', 'additional', 'layers', 'without', 'forgetting', 'network', 'already', 'learnt', 'describe', 'initialization', 'strategies', 'accomplish', 'anyone', 'know', 'paper', 'talking']","['search', 'paper', 'equival', 'transform', 'train', 'networkscom', 'across', 'paper', 'explor', 'strategi', 'transform', 'architectur', 'train', 'neural', 'network', 'e', 'increas', 'layer', 'width', 'ad', 'addit', 'layer', 'without', 'forget', 'network', 'alreadi', 'learnt', 'describ', 'initi', 'strategi', 'accomplish', 'anyon', 'know', 'paper', 'talk']"
282,311,311,Competitive_Travel16,vtzpkp,[D] LaMDA long-term memory,"Google's February, 2022 [LaMDA paper](https://arxiv.org/abs/2201.08239) says it is preconditioned on previous interactions (someone on this subreddit said 14-30) in support of tuning its ""sensibleness"" metric, which includes making sure responses don't contradict anything said earlier.

However, in [this podcast,](https://thattech.show/episodes/62-exposing-google's-sentient-ai-with-blake-lemoine) Blake Lemoine says at 5:30-7:00 that LaMDA has some kind of long-term memory stretching back at least five years. He also mentions that the current system called ""LaMDA 2"" has access to a much wider variety of database resources than the paper or other Google [publications](https://towardsdatascience.com/why-gpt-wont-tell-you-the-truth-301b48434c2c) describe, 
including Google Images, YouTube, and Google Books.

Is LaMDA 2 documented anywhere? What other features does it have beyond what is documented in the February paper?",11,23,2022-07-08 05:23:05, d  lamda long term memory,google s february    lamda paper  https however  in  this podcast   https including google images  youtube  and google books is lamda  documented anywhere  what other features does it have beyond what is documented in the february paper ,google february lamda paper https however podcast https including google images youtube google books lamda documented anywhere features beyond documented february paper,lamda long term memory,lamda long term memorygoogle february lamda paper https however podcast https including google images youtube google books lamda documented anywhere features beyond documented february paper,"['lamda', 'long', 'term', 'memorygoogle', 'february', 'lamda', 'paper', 'https', 'however', 'podcast', 'https', 'including', 'google', 'images', 'youtube', 'google', 'books', 'lamda', 'documented', 'anywhere', 'features', 'beyond', 'documented', 'february', 'paper']","['lamda', 'long', 'term', 'memorygoogl', 'februari', 'lamda', 'paper', 'http', 'howev', 'podcast', 'http', 'includ', 'googl', 'imag', 'youtub', 'googl', 'book', 'lamda', 'document', 'anywher', 'featur', 'beyond', 'document', 'februari', 'paper']"
283,312,312,gnohuhs,vu25t7,[D] when do eccv meta-reviews come out?,"I know the result from the link in the email but cmt still says ""awaiting decision""

call me antsy but I just want to see the final comments and meta-review... did it take this long last year?",8,13,2022-07-08 07:32:49, d  when do eccv meta reviews come out ,i know the result from the link in the email but cmt still says awaiting decisioncall me antsy but i just want to see the final comments and meta review    did it take this long last year ,know result link email cmt still says awaiting decisioncall antsy want see final comments meta review take long last year,eccv meta reviews come,eccv meta reviews comeknow result link email cmt still says awaiting decisioncall antsy want see final comments meta review take long last year,"['eccv', 'meta', 'reviews', 'comeknow', 'result', 'link', 'email', 'cmt', 'still', 'says', 'awaiting', 'decisioncall', 'antsy', 'want', 'see', 'final', 'comments', 'meta', 'review', 'take', 'long', 'last', 'year']","['eccv', 'meta', 'review', 'comeknow', 'result', 'link', 'email', 'cmt', 'still', 'say', 'await', 'decisioncal', 'antsi', 'want', 'see', 'final', 'comment', 'meta', 'review', 'take', 'long', 'last', 'year']"
284,313,313,Adept_Ad_3308,vtztrc,[R] NeurIPS2022’s Natural Language for Optimization (NL4Opt) competition!," 

We invite you to join our NL4Opt competition that will be part of NeurIPS2022. We have a novel never-before-seen NLP dataset in hopes of making optimization solvers more accessible and usable. The competition aims to allow non-experts to use optimization tools in their decision-making. This competition is split into two main tasks: NER and generation. We have provided baselines for each to kick-start your implementation. We will **award a total of $22,000 USD** evenly across the two tasks. 

We will also be hosting a workshop at the end of the competition and will be inviting experts and winners as podium speakers. Additionally, we plan to host poster sessions for participants to share their solution. 

The competition is tentatively from July 1st to October 15th with the submission portal opening on July 15th. We look forward to your participation – you can register ([https://nl4opt.github.io/participate/](https://nl4opt.github.io/participate/)) and our organizers will be in touch with you shortly.

For more information regarding the competition details, schedule, eligibility, rules, FAQs, and to get started, visit our competition website linked below! Follow our social media and GitHub discussion forum to keep updated. If you have any questions, please take a look at the FAQ section of our website. For any unanswered questions, free to start the discussion on the GitHub forum.

Twitter: [https://twitter.com/NL4Opt](https://twitter.com/NL4Opt)

Website: [https://nl4opt.github.io/](https://nl4opt.github.io/)

GitHub discussion forum: [https://github.com/nl4opt/nl4opt-competition/discussions](https://github.com/nl4opt/nl4opt-competition/discussions)

We look forward to your participation,

NL4Opt Organizers",0,10,2022-07-08 05:29:01, r  neurips s natural language for optimization  nlopt  competition , we invite you to join our nlopt competition that will be part of neurips  we have a novel never before seen nlp dataset in hopes of making optimization solvers more accessible and usable  the competition aims to allow non experts to use optimization tools in their decision making  this competition is split into two main tasks  ner and generation  we have provided baselines for each to kick start your implementation  we will   award a total of    usd   evenly across the two tasks  we will also be hosting a workshop at the end of the competition and will be inviting experts and winners as podium speakers  additionally  we plan to host poster sessions for participants to share their solution  the competition is tentatively from july st to october th with the submission portal opening on july th  we look forward to your participation   you can register   https for more information regarding the competition details  schedule  eligibility  rules  faqs  and to get started  visit our competition website linked below  follow our social media and github discussion forum to keep updated  if you have any questions  please take a look at the faq section of our website  for any unanswered questions  free to start the discussion on the github forum twitter   https website   https github discussion forum   https we look forward to your participation nlopt organizers,invite join nlopt competition part neurips novel never seen nlp dataset hopes making optimization solvers accessible usable competition aims allow non experts use optimization tools decision making competition split two main tasks ner generation provided baselines kick start implementation award total usd evenly across two tasks also hosting workshop end competition inviting experts winners podium speakers additionally plan host poster sessions participants share solution competition tentatively july st october th submission portal opening july th look forward participation register https information regarding competition details schedule eligibility rules faqs get started visit competition website linked follow social media github discussion forum keep updated questions please take look faq section website unanswered questions free start discussion github forum twitter https website https github discussion forum https look forward participation nlopt organizers,r neurips natural language optimization nlopt competition,r neurips natural language optimization nlopt competitioninvite join nlopt competition part neurips novel never seen nlp dataset hopes making optimization solvers accessible usable competition aims allow non experts use optimization tools decision making competition split two main tasks ner generation provided baselines kick start implementation award total usd evenly across two tasks also hosting workshop end competition inviting experts winners podium speakers additionally plan host poster sessions participants share solution competition tentatively july st october th submission portal opening july th look forward participation register https information regarding competition details schedule eligibility rules faqs get started visit competition website linked follow social media github discussion forum keep updated questions please take look faq section website unanswered questions free start discussion github forum twitter https website https github discussion forum https look forward participation nlopt organizers,"['r', 'neurips', 'natural', 'language', 'optimization', 'nlopt', 'competitioninvite', 'join', 'nlopt', 'competition', 'part', 'neurips', 'novel', 'never', 'seen', 'nlp', 'dataset', 'hopes', 'making', 'optimization', 'solvers', 'accessible', 'usable', 'competition', 'aims', 'allow', 'non', 'experts', 'use', 'optimization', 'tools', 'decision', 'making', 'competition', 'split', 'two', 'main', 'tasks', 'ner', 'generation', 'provided', 'baselines', 'kick', 'start', 'implementation', 'award', 'total', 'usd', 'evenly', 'across', 'two', 'tasks', 'also', 'hosting', 'workshop', 'end', 'competition', 'inviting', 'experts', 'winners', 'podium', 'speakers', 'additionally', 'plan', 'host', 'poster', 'sessions', 'participants', 'share', 'solution', 'competition', 'tentatively', 'july', 'st', 'october', 'th', 'submission', 'portal', 'opening', 'july', 'th', 'look', 'forward', 'participation', 'register', 'https', 'information', 'regarding', 'competition', 'details', 'schedule', 'eligibility', 'rules', 'faqs', 'get', 'started', 'visit', 'competition', 'website', 'linked', 'follow', 'social', 'media', 'github', 'discussion', 'forum', 'keep', 'updated', 'questions', 'please', 'take', 'look', 'faq', 'section', 'website', 'unanswered', 'questions', 'free', 'start', 'discussion', 'github', 'forum', 'twitter', 'https', 'website', 'https', 'github', 'discussion', 'forum', 'https', 'look', 'forward', 'participation', 'nlopt', 'organizers']","['r', 'neurip', 'natur', 'languag', 'optim', 'nlopt', 'competitioninvit', 'join', 'nlopt', 'competit', 'part', 'neurip', 'novel', 'never', 'seen', 'nlp', 'dataset', 'hope', 'make', 'optim', 'solver', 'access', 'usabl', 'competit', 'aim', 'allow', 'non', 'expert', 'use', 'optim', 'tool', 'decis', 'make', 'competit', 'split', 'two', 'main', 'task', 'ner', 'gener', 'provid', 'baselin', 'kick', 'start', 'implement', 'award', 'total', 'usd', 'evenli', 'across', 'two', 'task', 'also', 'host', 'workshop', 'end', 'competit', 'invit', 'expert', 'winner', 'podium', 'speaker', 'addit', 'plan', 'host', 'poster', 'session', 'particip', 'share', 'solut', 'competit', 'tent', 'juli', 'st', 'octob', 'th', 'submiss', 'portal', 'open', 'juli', 'th', 'look', 'forward', 'particip', 'regist', 'http', 'inform', 'regard', 'competit', 'detail', 'schedul', 'elig', 'rule', 'faq', 'get', 'start', 'visit', 'competit', 'websit', 'link', 'follow', 'social', 'media', 'github', 'discuss', 'forum', 'keep', 'updat', 'question', 'pleas', 'take', 'look', 'faq', 'section', 'websit', 'unansw', 'question', 'free', 'start', 'discuss', 'github', 'forum', 'twitter', 'http', 'websit', 'http', 'github', 'discuss', 'forum', 'http', 'look', 'forward', 'particip', 'nlopt', 'organ']"
285,314,314,hardmaru,vtcrej,[D] LeCun's 2022 paper on autonomous machine intelligence rehashes but does not cite essential work of 1990-2015,"Saw Schmidhuber’s [tweeting](https://twitter.com/SchmidhuberAI/status/1544939700099710976) again: 🔥

*“Lecun’s 2022 paper on Autonomous Machine Intelligence rehashes but doesn’t cite essential work of 1990-2015. We’ve already published his “main original contributions:” learning subgoals, predictable abstract representations, multiple time scales…”*

Jürgen Schmidhuber’s response to Yann Lecun’s recent technical report / position paper “Autonomous Machine Intelligence” in this latest blog post:

https://people.idsia.ch/~juergen/lecun-rehash-1990-2022.html

**Update (Jul 8):** It seems Schmidhuber has posted his concerns on the paper’s [openreview.net](https://openreview.net/forum?id=BZ5a1r-kVsf&noteId=GsxarV_Jyeb) entry.

---

Excerpt:

*On 14 June 2022, a science tabloid that published this [article](https://www.technologyreview.com/2022/06/24/1054817/yann-lecun-bold-new-vision-future-ai-deep-learning-meta/) (24 June) on LeCun's report “[A Path Towards Autonomous Machine Intelligence](https://openreview.net/forum?id=BZ5a1r-kVsf)” (27 June) sent me a draft of the report (back then still under embargo) and asked for comments. I wrote a review (see below), telling them that this is essentially a rehash of our previous work that LeCun did not mention. My comments, however, fell on deaf ears. Now I am posting my not so enthusiastic remarks here such that the history of our field does not become further corrupted. The images below link to relevant blog posts from the [AI Blog](https://people.idsia.ch/~juergen/blog.html).*

*I would like to start this by acknowledging that I am not without a conflict of interest here; my seeking to correct the record will naturally seem self-interested. The truth of the matter is that it is. Much of the closely related work pointed to below was done in my lab, and I naturally wish that it be acknowledged, and recognized. Setting my conflict aside, I ask the reader to study the original papers and judge for themselves the scientific content of these remarks, as I seek to set emotions aside and minimize bias so much as I am capable.*

---

For reference, previous discussion on r/MachineLearning about Yann Lecun’s paper:

https://www.reddit.com/r/MachineLearning/comments/vm39oe/a_path_towards_autonomous_machine_intelligence/",88,354,2022-07-07 10:25:56, d  lecun s  paper on autonomous machine intelligence rehashes but does not cite essential work of  ,saw schmidhuber s  tweeting  https   lecun s  paper on autonomous machine intelligence rehashes but doesn t cite essential work of    we ve already published his  main original contributions   learning subgoals  predictable abstract representations  multiple time scales   jürgen schmidhuber s response to yann lecun s recent technical report   position paper  autonomous machine intelligence  in this latest blog post https   update  jul      it seems schmidhuber has posted his concerns on the paper s  openreview net  https    excerpt  on  june   a science tabloid that published this  article  https  i would like to start this by acknowledging that i am not without a conflict of interest here  my seeking to correct the record will naturally seem self interested  the truth of the matter is that it is  much of the closely related work pointed to below was done in my lab  and i naturally wish that it be acknowledged  and recognized  setting my conflict aside  i ask the reader to study the original papers and judge for themselves the scientific content of these remarks  as i seek to set emotions aside and minimize bias so much as i am capable     for reference  previous discussion on r machinelearning about yann lecun s paper https   www reddit com r machinelearning comments vmoe a_path_towards_autonomous_machine_intelligence ,saw schmidhuber tweeting https lecun paper autonomous machine intelligence rehashes cite essential work already published main original contributions learning subgoals predictable abstract representations multiple time scales jürgen schmidhuber response yann lecun recent technical report position paper autonomous machine intelligence latest blog post https update jul seems schmidhuber posted concerns paper openreview net https excerpt june science tabloid published article https would like start acknowledging without conflict interest seeking correct record naturally seem self interested truth matter much closely related work pointed done lab naturally wish acknowledged recognized setting conflict aside ask reader study original papers judge scientific content remarks seek set emotions aside minimize bias much capable reference previous discussion r machinelearning yann lecun paper https www reddit com r machinelearning comments vmoe a_path_towards_autonomous_machine_intelligence,lecun paper autonomous machine intelligence rehashes cite essential work,lecun paper autonomous machine intelligence rehashes cite essential worksaw schmidhuber tweeting https lecun paper autonomous machine intelligence rehashes cite essential work already published main original contributions learning subgoals predictable abstract representations multiple time scales jürgen schmidhuber response yann lecun recent technical report position paper autonomous machine intelligence latest blog post https update jul seems schmidhuber posted concerns paper openreview net https excerpt june science tabloid published article https would like start acknowledging without conflict interest seeking correct record naturally seem self interested truth matter much closely related work pointed done lab naturally wish acknowledged recognized setting conflict aside ask reader study original papers judge scientific content remarks seek set emotions aside minimize bias much capable reference previous discussion r machinelearning yann lecun paper https www reddit com r machinelearning comments vmoe a_path_towards_autonomous_machine_intelligence,"['lecun', 'paper', 'autonomous', 'machine', 'intelligence', 'rehashes', 'cite', 'essential', 'worksaw', 'schmidhuber', 'tweeting', 'https', 'lecun', 'paper', 'autonomous', 'machine', 'intelligence', 'rehashes', 'cite', 'essential', 'work', 'already', 'published', 'main', 'original', 'contributions', 'learning', 'subgoals', 'predictable', 'abstract', 'representations', 'multiple', 'time', 'scales', 'jürgen', 'schmidhuber', 'response', 'yann', 'lecun', 'recent', 'technical', 'report', 'position', 'paper', 'autonomous', 'machine', 'intelligence', 'latest', 'blog', 'post', 'https', 'update', 'jul', 'seems', 'schmidhuber', 'posted', 'concerns', 'paper', 'openreview', 'net', 'https', 'excerpt', 'june', 'science', 'tabloid', 'published', 'article', 'https', 'would', 'like', 'start', 'acknowledging', 'without', 'conflict', 'interest', 'seeking', 'correct', 'record', 'naturally', 'seem', 'self', 'interested', 'truth', 'matter', 'much', 'closely', 'related', 'work', 'pointed', 'done', 'lab', 'naturally', 'wish', 'acknowledged', 'recognized', 'setting', 'conflict', 'aside', 'ask', 'reader', 'study', 'original', 'papers', 'judge', 'scientific', 'content', 'remarks', 'seek', 'set', 'emotions', 'aside', 'minimize', 'bias', 'much', 'capable', 'reference', 'previous', 'discussion', 'r', 'machinelearning', 'yann', 'lecun', 'paper', 'https', 'www', 'reddit', 'com', 'r', 'machinelearning', 'comments', 'vmoe', 'a_path_towards_autonomous_machine_intelligence']","['lecun', 'paper', 'autonom', 'machin', 'intellig', 'rehash', 'cite', 'essenti', 'worksaw', 'schmidhub', 'tweet', 'http', 'lecun', 'paper', 'autonom', 'machin', 'intellig', 'rehash', 'cite', 'essenti', 'work', 'alreadi', 'publish', 'main', 'origin', 'contribut', 'learn', 'subgoal', 'predict', 'abstract', 'represent', 'multipl', 'time', 'scale', 'jürgen', 'schmidhub', 'respons', 'yann', 'lecun', 'recent', 'technic', 'report', 'posit', 'paper', 'autonom', 'machin', 'intellig', 'latest', 'blog', 'post', 'http', 'updat', 'jul', 'seem', 'schmidhub', 'post', 'concern', 'paper', 'openreview', 'net', 'http', 'excerpt', 'june', 'scienc', 'tabloid', 'publish', 'articl', 'http', 'would', 'like', 'start', 'acknowledg', 'without', 'conflict', 'interest', 'seek', 'correct', 'record', 'natur', 'seem', 'self', 'interest', 'truth', 'matter', 'much', 'close', 'relat', 'work', 'point', 'done', 'lab', 'natur', 'wish', 'acknowledg', 'recogn', 'set', 'conflict', 'asid', 'ask', 'reader', 'studi', 'origin', 'paper', 'judg', 'scientif', 'content', 'remark', 'seek', 'set', 'emot', 'asid', 'minim', 'bia', 'much', 'capabl', 'refer', 'previou', 'discuss', 'r', 'machinelearn', 'yann', 'lecun', 'paper', 'http', 'www', 'reddit', 'com', 'r', 'machinelearn', 'comment', 'vmoe', 'a_path_towards_autonomous_machine_intellig']"
286,315,315,Greckon121,vu7ahk,[P] Detection by position rather than looks?,"I am working on a project that needs to decide which olive tree branches should be cut. The goal is to detect the specific type of branch (watersprouts).

The problem I'm facing is that I'm unsure if I should use object detection (image classification + localization) or image segmentation. The difference between branches is mostly in their position with watersprouts growing mostly vertical to the main branch(there is a very small difference in looks between watersprouts and other branches) while other branches can grow in all ways (mostly parallel to the main branch).

My plan was to use object detection so I can classify watersprouts and localize them in the picture. I think that segmentation is a bit overkill for this problem because I don't see the need for localizing every pixel. The plan was to take pictures of watersprouts as class 1 and other branches as class 2,train them so I can detect them and localize. When I localize them I can now see which of these branches is a watersprout branch and which is a regular branch and then I know that watersprout should be cut.

The other problem I have is with understanding if it is possible for my machine learning project to recognize watersprouts not by their looks but by their position in regards to the main branch and correctly differentiate them from other branches because this is the main difference between watersprouts branch and regular branch. My understending is that the network learns how the object looks like and that position doesn't matter.

Am I on a right track or am I missing something?",7,2,2022-07-08 13:08:47, p  detection by position rather than looks ,i am working on a project that needs to decide which olive tree branches should be cut  the goal is to detect the specific type of branch  watersprouts  the problem i m facing is that i m unsure if i should use object detection  image classification   localization  or image segmentation  the difference between branches is mostly in their position with watersprouts growing mostly vertical to the main branch there is a very small difference in looks between watersprouts and other branches  while other branches can grow in all ways  mostly parallel to the main branch  my plan was to use object detection so i can classify watersprouts and localize them in the picture  i think that segmentation is a bit overkill for this problem because i don t see the need for localizing every pixel  the plan was to take pictures of watersprouts as class  and other branches as class  train them so i can detect them and localize  when i localize them i can now see which of these branches is a watersprout branch and which is a regular branch and then i know that watersprout should be cut the other problem i have is with understanding if it is possible for my machine learning project to recognize watersprouts not by their looks but by their position in regards to the main branch and correctly differentiate them from other branches because this is the main difference between watersprouts branch and regular branch  my understending is that the network learns how the object looks like and that position doesn t matter am i on a right track or am i missing something ,working project needs decide olive tree branches cut goal detect specific type branch watersprouts problem facing unsure use object detection image classification localization image segmentation difference branches mostly position watersprouts growing mostly vertical main branch small difference looks watersprouts branches branches grow ways mostly parallel main branch plan use object detection classify watersprouts localize picture think segmentation bit overkill problem see need localizing every pixel plan take pictures watersprouts class branches class train detect localize localize see branches watersprout branch regular branch know watersprout cut problem understanding possible machine learning project recognize watersprouts looks position regards main branch correctly differentiate branches main difference watersprouts branch regular branch understending network learns object looks like position matter right track missing something,p detection position rather looks,p detection position rather looksworking project needs decide olive tree branches cut goal detect specific type branch watersprouts problem facing unsure use object detection image classification localization image segmentation difference branches mostly position watersprouts growing mostly vertical main branch small difference looks watersprouts branches branches grow ways mostly parallel main branch plan use object detection classify watersprouts localize picture think segmentation bit overkill problem see need localizing every pixel plan take pictures watersprouts class branches class train detect localize localize see branches watersprout branch regular branch know watersprout cut problem understanding possible machine learning project recognize watersprouts looks position regards main branch correctly differentiate branches main difference watersprouts branch regular branch understending network learns object looks like position matter right track missing something,"['p', 'detection', 'position', 'rather', 'looksworking', 'project', 'needs', 'decide', 'olive', 'tree', 'branches', 'cut', 'goal', 'detect', 'specific', 'type', 'branch', 'watersprouts', 'problem', 'facing', 'unsure', 'use', 'object', 'detection', 'image', 'classification', 'localization', 'image', 'segmentation', 'difference', 'branches', 'mostly', 'position', 'watersprouts', 'growing', 'mostly', 'vertical', 'main', 'branch', 'small', 'difference', 'looks', 'watersprouts', 'branches', 'branches', 'grow', 'ways', 'mostly', 'parallel', 'main', 'branch', 'plan', 'use', 'object', 'detection', 'classify', 'watersprouts', 'localize', 'picture', 'think', 'segmentation', 'bit', 'overkill', 'problem', 'see', 'need', 'localizing', 'every', 'pixel', 'plan', 'take', 'pictures', 'watersprouts', 'class', 'branches', 'class', 'train', 'detect', 'localize', 'localize', 'see', 'branches', 'watersprout', 'branch', 'regular', 'branch', 'know', 'watersprout', 'cut', 'problem', 'understanding', 'possible', 'machine', 'learning', 'project', 'recognize', 'watersprouts', 'looks', 'position', 'regards', 'main', 'branch', 'correctly', 'differentiate', 'branches', 'main', 'difference', 'watersprouts', 'branch', 'regular', 'branch', 'understending', 'network', 'learns', 'object', 'looks', 'like', 'position', 'matter', 'right', 'track', 'missing', 'something']","['p', 'detect', 'posit', 'rather', 'lookswork', 'project', 'need', 'decid', 'oliv', 'tree', 'branch', 'cut', 'goal', 'detect', 'specif', 'type', 'branch', 'watersprout', 'problem', 'face', 'unsur', 'use', 'object', 'detect', 'imag', 'classif', 'local', 'imag', 'segment', 'differ', 'branch', 'mostli', 'posit', 'watersprout', 'grow', 'mostli', 'vertic', 'main', 'branch', 'small', 'differ', 'look', 'watersprout', 'branch', 'branch', 'grow', 'way', 'mostli', 'parallel', 'main', 'branch', 'plan', 'use', 'object', 'detect', 'classifi', 'watersprout', 'local', 'pictur', 'think', 'segment', 'bit', 'overkil', 'problem', 'see', 'need', 'local', 'everi', 'pixel', 'plan', 'take', 'pictur', 'watersprout', 'class', 'branch', 'class', 'train', 'detect', 'local', 'local', 'see', 'branch', 'watersprout', 'branch', 'regular', 'branch', 'know', 'watersprout', 'cut', 'problem', 'understand', 'possibl', 'machin', 'learn', 'project', 'recogn', 'watersprout', 'look', 'posit', 'regard', 'main', 'branch', 'correctli', 'differenti', 'branch', 'main', 'differ', 'watersprout', 'branch', 'regular', 'branch', 'understend', 'network', 'learn', 'object', 'look', 'like', 'posit', 'matter', 'right', 'track', 'miss', 'someth']"
287,316,316,ykilcher,vtsiif,[D] Paper Explained - JEPA: A Path Towards Autonomous Machine Intelligence (Video Walkthrough),"[https://youtu.be/jSdHmImyUjk](https://youtu.be/jSdHmImyUjk)

Yann LeCun's position paper on a path towards machine intelligence combines Self-Supervised Learning, Energy-Based Models, and hierarchical predictive embedding models to arrive at a system that can teach itself to learn useful abstractions at multiple levels and use that as a world model to plan ahead in time.

&#x200B;

OUTLINE:

0:00 - Introduction

2:00 - Main Contributions

5:45 - Mode 1 and Mode 2 actors

15:40 - Self-Supervised Learning and Energy-Based Models

20:15 - Introducing latent variables

25:00 - The problem of collapse

29:50 - Contrastive vs regularized methods

36:00 - The JEPA architecture

47:00 - Hierarchical JEPA (H-JEPA)

53:00 - Broader relevance

56:00 - Summary & Comments

&#x200B;

Paper: [https://openreview.net/forum?id=BZ5a1r-kVsf](https://openreview.net/forum?id=BZ5a1r-kVsf)",1,21,2022-07-07 23:41:41, d  paper explained   jepa  a path towards autonomous machine intelligence  video walkthrough , https yann lecun s position paper on a path towards machine intelligence combines self supervised learning  energy based models  and hierarchical predictive embedding models to arrive at a system that can teach itself to learn useful abstractions at multiple levels and use that as a world model to plan ahead in time   xb outline     introduction    main contributions    mode  and mode  actors    self supervised learning and energy based models    introducing latent variables    the problem of collapse    contrastive vs regularized methods    the jepa architecture    hierarchical jepa  h jepa     broader relevance    summary   comments  xb paper   https   openreview net forum id bzar kvsf  https   openreview net forum id bzar kvsf ,https yann lecun position paper path towards machine intelligence combines self supervised learning energy based models hierarchical predictive embedding models arrive system teach learn useful abstractions multiple levels use world model plan ahead time xb outline introduction main contributions mode mode actors self supervised learning energy based models introducing latent variables problem collapse contrastive vs regularized methods jepa architecture hierarchical jepa h jepa broader relevance summary comments xb paper https openreview net forum id bzar kvsf https openreview net forum id bzar kvsf,paper explained jepa path towards autonomous machine intelligence video walkthrough,paper explained jepa path towards autonomous machine intelligence video walkthroughhttps yann lecun position paper path towards machine intelligence combines self supervised learning energy based models hierarchical predictive embedding models arrive system teach learn useful abstractions multiple levels use world model plan ahead time xb outline introduction main contributions mode mode actors self supervised learning energy based models introducing latent variables problem collapse contrastive vs regularized methods jepa architecture hierarchical jepa h jepa broader relevance summary comments xb paper https openreview net forum id bzar kvsf https openreview net forum id bzar kvsf,"['paper', 'explained', 'jepa', 'path', 'towards', 'autonomous', 'machine', 'intelligence', 'video', 'walkthroughhttps', 'yann', 'lecun', 'position', 'paper', 'path', 'towards', 'machine', 'intelligence', 'combines', 'self', 'supervised', 'learning', 'energy', 'based', 'models', 'hierarchical', 'predictive', 'embedding', 'models', 'arrive', 'system', 'teach', 'learn', 'useful', 'abstractions', 'multiple', 'levels', 'use', 'world', 'model', 'plan', 'ahead', 'time', 'xb', 'outline', 'introduction', 'main', 'contributions', 'mode', 'mode', 'actors', 'self', 'supervised', 'learning', 'energy', 'based', 'models', 'introducing', 'latent', 'variables', 'problem', 'collapse', 'contrastive', 'vs', 'regularized', 'methods', 'jepa', 'architecture', 'hierarchical', 'jepa', 'h', 'jepa', 'broader', 'relevance', 'summary', 'comments', 'xb', 'paper', 'https', 'openreview', 'net', 'forum', 'id', 'bzar', 'kvsf', 'https', 'openreview', 'net', 'forum', 'id', 'bzar', 'kvsf']","['paper', 'explain', 'jepa', 'path', 'toward', 'autonom', 'machin', 'intellig', 'video', 'walkthroughhttp', 'yann', 'lecun', 'posit', 'paper', 'path', 'toward', 'machin', 'intellig', 'combin', 'self', 'supervis', 'learn', 'energi', 'base', 'model', 'hierarch', 'predict', 'embed', 'model', 'arriv', 'system', 'teach', 'learn', 'use', 'abstract', 'multipl', 'level', 'use', 'world', 'model', 'plan', 'ahead', 'time', 'xb', 'outlin', 'introduct', 'main', 'contribut', 'mode', 'mode', 'actor', 'self', 'supervis', 'learn', 'energi', 'base', 'model', 'introduc', 'latent', 'variabl', 'problem', 'collaps', 'contrast', 'vs', 'regular', 'method', 'jepa', 'architectur', 'hierarch', 'jepa', 'h', 'jepa', 'broader', 'relev', 'summari', 'comment', 'xb', 'paper', 'http', 'openreview', 'net', 'forum', 'id', 'bzar', 'kvsf', 'http', 'openreview', 'net', 'forum', 'id', 'bzar', 'kvsf']"
288,317,317,ml6189,vtwbsy,[R] Self-Modeling Programs: A Direct Approach to Program Likelihood,"[PDF Link](https://lemonade.sfo2.digitaloceanspaces.com/Self-Modeling%20Programs.pdf)

Abstract:

>In algorithmic information theory, the length of a program is used as a measure of its probability. This paper presents a category of programs that directly compute the combined probability of their own code symbols and input data. The probability of each symbol is computed from past symbols by requiring that execution of the program formed by the first n symbols returns a probability distribution over symbols for position n + 1. The program of this type with the highest likelihood ending in the input data sequence intuitively represents the most likely sequence of events that could have generated the data. Advantages of programs of this form and the relationship to the Kolmogorov complexity are discussed.

I'd appreciate any criticisms or comments.",0,11,2022-07-08 02:36:29, r  self modeling programs  a direct approach to program likelihood, pdf link  https abstract  in algorithmic information theory  the length of a program is used as a measure of its probability  this paper presents a category of programs that directly compute the combined probability of their own code symbols and input data  the probability of each symbol is computed from past symbols by requiring that execution of the program formed by the first n symbols returns a probability distribution over symbols for position n     the program of this type with the highest likelihood ending in the input data sequence intuitively represents the most likely sequence of events that could have generated the data  advantages of programs of this form and the relationship to the kolmogorov complexity are discussed i d appreciate any criticisms or comments ,pdf link https abstract algorithmic information theory length program used measure probability paper presents category programs directly compute combined probability code symbols input data probability symbol computed past symbols requiring execution program formed first n symbols returns probability distribution symbols position n program type highest likelihood ending input data sequence intuitively represents likely sequence events could generated data advantages programs form relationship kolmogorov complexity discussed appreciate criticisms comments,r self modeling programs direct approach program likelihood,r self modeling programs direct approach program likelihoodpdf link https abstract algorithmic information theory length program used measure probability paper presents category programs directly compute combined probability code symbols input data probability symbol computed past symbols requiring execution program formed first n symbols returns probability distribution symbols position n program type highest likelihood ending input data sequence intuitively represents likely sequence events could generated data advantages programs form relationship kolmogorov complexity discussed appreciate criticisms comments,"['r', 'self', 'modeling', 'programs', 'direct', 'approach', 'program', 'likelihoodpdf', 'link', 'https', 'abstract', 'algorithmic', 'information', 'theory', 'length', 'program', 'used', 'measure', 'probability', 'paper', 'presents', 'category', 'programs', 'directly', 'compute', 'combined', 'probability', 'code', 'symbols', 'input', 'data', 'probability', 'symbol', 'computed', 'past', 'symbols', 'requiring', 'execution', 'program', 'formed', 'first', 'n', 'symbols', 'returns', 'probability', 'distribution', 'symbols', 'position', 'n', 'program', 'type', 'highest', 'likelihood', 'ending', 'input', 'data', 'sequence', 'intuitively', 'represents', 'likely', 'sequence', 'events', 'could', 'generated', 'data', 'advantages', 'programs', 'form', 'relationship', 'kolmogorov', 'complexity', 'discussed', 'appreciate', 'criticisms', 'comments']","['r', 'self', 'model', 'program', 'direct', 'approach', 'program', 'likelihoodpdf', 'link', 'http', 'abstract', 'algorithm', 'inform', 'theori', 'length', 'program', 'use', 'measur', 'probabl', 'paper', 'present', 'categori', 'program', 'directli', 'comput', 'combin', 'probabl', 'code', 'symbol', 'input', 'data', 'probabl', 'symbol', 'comput', 'past', 'symbol', 'requir', 'execut', 'program', 'form', 'first', 'n', 'symbol', 'return', 'probabl', 'distribut', 'symbol', 'posit', 'n', 'program', 'type', 'highest', 'likelihood', 'end', 'input', 'data', 'sequenc', 'intuit', 'repres', 'like', 'sequenc', 'event', 'could', 'gener', 'data', 'advantag', 'program', 'form', 'relationship', 'kolmogorov', 'complex', 'discuss', 'appreci', 'critic', 'comment']"
289,318,318,FnSK4R17s,vtu6f9,[D] How to deal with badly labelled data?,"The labeling team at my organization is very bad. They take forever to understand the labeling objective. And produce datasets that are not very reliable. The take months to annotate a small dataset of roughly 2000 images. Now, I have 2 questions:

1. How do I spot these anomalies? (Classification Dataset)
2. How do I generate pseudo labels or use similar techniques to generate data for training?

Should I complain about them to my manager or ask them to label the datasets again? Because this situation is getting out of hand",11,8,2022-07-08 00:57:13, d  how to deal with badly labelled data ,the labeling team at my organization is very bad  they take forever to understand the labeling objective  and produce datasets that are not very reliable  the take months to annotate a small dataset of roughly  images  now  i have  questions   how do i spot these anomalies   classification dataset   how do i generate pseudo labels or use similar techniques to generate data for training should i complain about them to my manager or ask them to label the datasets again  because this situation is getting out of hand,labeling team organization bad take forever understand labeling objective produce datasets reliable take months annotate small dataset roughly images questions spot anomalies classification dataset generate pseudo labels use similar techniques generate data training complain manager ask label datasets situation getting hand,deal badly labelled data,deal badly labelled datalabeling team organization bad take forever understand labeling objective produce datasets reliable take months annotate small dataset roughly images questions spot anomalies classification dataset generate pseudo labels use similar techniques generate data training complain manager ask label datasets situation getting hand,"['deal', 'badly', 'labelled', 'datalabeling', 'team', 'organization', 'bad', 'take', 'forever', 'understand', 'labeling', 'objective', 'produce', 'datasets', 'reliable', 'take', 'months', 'annotate', 'small', 'dataset', 'roughly', 'images', 'questions', 'spot', 'anomalies', 'classification', 'dataset', 'generate', 'pseudo', 'labels', 'use', 'similar', 'techniques', 'generate', 'data', 'training', 'complain', 'manager', 'ask', 'label', 'datasets', 'situation', 'getting', 'hand']","['deal', 'badli', 'label', 'datalabel', 'team', 'organ', 'bad', 'take', 'forev', 'understand', 'label', 'object', 'produc', 'dataset', 'reliabl', 'take', 'month', 'annot', 'small', 'dataset', 'roughli', 'imag', 'question', 'spot', 'anomali', 'classif', 'dataset', 'gener', 'pseudo', 'label', 'use', 'similar', 'techniqu', 'gener', 'data', 'train', 'complain', 'manag', 'ask', 'label', 'dataset', 'situat', 'get', 'hand']"
290,319,319,Mediocre-Piccolo7474,vtfgeh,[Discussion] About model serving for production,"Hi!

I hope I'm not breaking any rules with this question.

I'm studying some frameworks used in production for model serving, namely Seldon Core, Kubeflow and an academic artifact named Clipper. Some can manage the entire ML life cycle, but I have a question about serving in production.

In particular, how would one go about actually batching multiple requests on the cloud? There doesn't seem to be a golden standard for it, so I'm assuming it depends on the size of the data and on the scope of model, right? For example, if the goal is image classification, it could be useful to have a cloud queue, right? 

If so, do you know what are some solutions that are actually used in production?",11,13,2022-07-07 13:28:17, discussion  about model serving for production,hi i hope i m not breaking any rules with this question i m studying some frameworks used in production for model serving  namely seldon core  kubeflow and an academic artifact named clipper  some can manage the entire ml life cycle  but i have a question about serving in production in particular  how would one go about actually batching multiple requests on the cloud  there doesn t seem to be a golden standard for it  so i m assuming it depends on the size of the data and on the scope of model  right  for example  if the goal is image classification  it could be useful to have a cloud queue  right  if so  do you know what are some solutions that are actually used in production ,hi hope breaking rules question studying frameworks used production model serving namely seldon core kubeflow academic artifact named clipper manage entire ml life cycle question serving production particular would one go actually batching multiple requests cloud seem golden standard assuming depends size data scope model right example goal image classification could useful cloud queue right know solutions actually used production,discussion model serving production,discussion model serving productionhi hope breaking rules question studying frameworks used production model serving namely seldon core kubeflow academic artifact named clipper manage entire ml life cycle question serving production particular would one go actually batching multiple requests cloud seem golden standard assuming depends size data scope model right example goal image classification could useful cloud queue right know solutions actually used production,"['discussion', 'model', 'serving', 'productionhi', 'hope', 'breaking', 'rules', 'question', 'studying', 'frameworks', 'used', 'production', 'model', 'serving', 'namely', 'seldon', 'core', 'kubeflow', 'academic', 'artifact', 'named', 'clipper', 'manage', 'entire', 'ml', 'life', 'cycle', 'question', 'serving', 'production', 'particular', 'would', 'one', 'go', 'actually', 'batching', 'multiple', 'requests', 'cloud', 'seem', 'golden', 'standard', 'assuming', 'depends', 'size', 'data', 'scope', 'model', 'right', 'example', 'goal', 'image', 'classification', 'could', 'useful', 'cloud', 'queue', 'right', 'know', 'solutions', 'actually', 'used', 'production']","['discuss', 'model', 'serv', 'productionhi', 'hope', 'break', 'rule', 'question', 'studi', 'framework', 'use', 'product', 'model', 'serv', 'name', 'seldon', 'core', 'kubeflow', 'academ', 'artifact', 'name', 'clipper', 'manag', 'entir', 'ml', 'life', 'cycl', 'question', 'serv', 'product', 'particular', 'would', 'one', 'go', 'actual', 'batch', 'multipl', 'request', 'cloud', 'seem', 'golden', 'standard', 'assum', 'depend', 'size', 'data', 'scope', 'model', 'right', 'exampl', 'goal', 'imag', 'classif', 'could', 'use', 'cloud', 'queue', 'right', 'know', 'solut', 'actual', 'use', 'product']"
291,320,320,The_Removed,vsnipd,[News] Ian Goodfellow joins DeepMind as a Research Scientist,"Per his tweet at https://twitter.com/goodfellow_ian/status/1544638709039091717, Goodfellow will be a research scientist under Oriol Vinyals' Deep Learning team.",109,501,2022-07-06 14:14:01, news  ian goodfellow joins deepmind as a research scientist,per his tweet at https   twitter com goodfellow_ian status   goodfellow will be a research scientist under oriol vinyals  deep learning team ,per tweet https twitter com goodfellow_ian status goodfellow research scientist oriol vinyals deep learning team,news ian goodfellow joins deepmind research scientist,news ian goodfellow joins deepmind research scientistper tweet https twitter com goodfellow_ian status goodfellow research scientist oriol vinyals deep learning team,"['news', 'ian', 'goodfellow', 'joins', 'deepmind', 'research', 'scientistper', 'tweet', 'https', 'twitter', 'com', 'goodfellow_ian', 'status', 'goodfellow', 'research', 'scientist', 'oriol', 'vinyals', 'deep', 'learning', 'team']","['news', 'ian', 'goodfellow', 'join', 'deepmind', 'research', 'scientistp', 'tweet', 'http', 'twitter', 'com', 'goodfellow_ian', 'statu', 'goodfellow', 'research', 'scientist', 'oriol', 'vinyal', 'deep', 'learn', 'team']"
292,321,321,After_Philosopher572,vsvgoz,[D] Why aren't there much people working on causal machine learning?,"It seems Judea Pearl, Yoshua Bengio, Elias Bareinboim and a handful of other researchers are only people who are working on causal inference and machine learning. Is causal machine learning still a niche field? Also, do you know any researcher working on causal machine learning at Berkeley?",30,52,2022-07-06 20:28:16, d  why aren t there much people working on causal machine learning ,it seems judea pearl  yoshua bengio  elias bareinboim and a handful of other researchers are only people who are working on causal inference and machine learning  is causal machine learning still a niche field  also  do you know any researcher working on causal machine learning at berkeley ,seems judea pearl yoshua bengio elias bareinboim handful researchers people working causal inference machine learning causal machine learning still niche field also know researcher working causal machine learning berkeley,much people working causal machine learning,much people working causal machine learningseems judea pearl yoshua bengio elias bareinboim handful researchers people working causal inference machine learning causal machine learning still niche field also know researcher working causal machine learning berkeley,"['much', 'people', 'working', 'causal', 'machine', 'learningseems', 'judea', 'pearl', 'yoshua', 'bengio', 'elias', 'bareinboim', 'handful', 'researchers', 'people', 'working', 'causal', 'inference', 'machine', 'learning', 'causal', 'machine', 'learning', 'still', 'niche', 'field', 'also', 'know', 'researcher', 'working', 'causal', 'machine', 'learning', 'berkeley']","['much', 'peopl', 'work', 'causal', 'machin', 'learningseem', 'judea', 'pearl', 'yoshua', 'bengio', 'elia', 'bareinboim', 'hand', 'research', 'peopl', 'work', 'causal', 'infer', 'machin', 'learn', 'causal', 'machin', 'learn', 'still', 'nich', 'field', 'also', 'know', 'research', 'work', 'causal', 'machin', 'learn', 'berkeley']"
293,322,322,Singularian2501,vsyju8,[R] CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning,"Paper: [https://arxiv.org/pdf/2207.01780.pdf](https://arxiv.org/pdf/2207.01780.pdf)

Github: [https://github.com/salesforce/CodeRL](https://github.com/salesforce/CodeRL)

Abstract:

>Program synthesis or code generation aims to generate a program that satisfies a problem specification. Recent approaches using large-scale pretrained language models (LMs) have shown promising results, yet they have some critical limitations. In particular, they often follow a standard supervised fine-tuning procedure to train a code generation model only from the pairs of natural-language problem descriptions and ground-truth programs. Such paradigm largely ignores some important but potentially useful signals in the problem specification such as unit tests, which thus often results in poor performance when solving complex unseen coding tasks. To address the limitations, we propose ""CodeRL"", a new framework for program synthesis tasks through pretrained LMs and deep reinforcement learning (RL). Specifically, during training, we treat the code-generating LM as an actor network, and introduce a critic network that is trained to predict the functional correctness of generated programs and provide dense feedback signals to the actor. During inference, we introduce a new generation procedure with a critical sampling strategy that allows a model to automatically regenerate programs based on feedback from example unit tests and critic scores. For the model backbones, we extended the encoder-decoder architecture of CodeT5 with enhanced learning objectives, larger model sizes, and better pretraining data. Our method not only achieves new SOTA results on the challenging APPS benchmark, but also shows strong zero-shot transfer capability with new SOTA results on the simpler MBPP benchmark.       

https://preview.redd.it/goglny8a30a91.jpg?width=1218&format=pjpg&auto=webp&s=a6f50319637cf85fed2de1d08b407478f6a227aa

https://preview.redd.it/vav9glra30a91.jpg?width=1234&format=pjpg&auto=webp&s=19ef106847c090fab438338fad912f1afd75db1a",0,26,2022-07-06 22:40:56, r  coderl  mastering code generation through pretrained models and deep reinforcement learning,paper   https github   https abstract  program synthesis or code generation aims to generate a program that satisfies a problem specification  recent approaches using large scale pretrained language models  lms  have shown promising results  yet they have some critical limitations  in particular  they often follow a standard supervised fine tuning procedure to train a code generation model only from the pairs of natural language problem descriptions and ground truth programs  such paradigm largely ignores some important but potentially useful signals in the problem specification such as unit tests  which thus often results in poor performance when solving complex unseen coding tasks  to address the limitations  we propose coderl  a new framework for program synthesis tasks through pretrained lms and deep reinforcement learning  rl   specifically  during training  we treat the code generating lm as an actor network  and introduce a critic network that is trained to predict the functional correctness of generated programs and provide dense feedback signals to the actor  during inference  we introduce a new generation procedure with a critical sampling strategy that allows a model to automatically regenerate programs based on feedback from example unit tests and critic scores  for the model backbones  we extended the encoder decoder architecture of codet with enhanced learning objectives  larger model sizes  and better pretraining data  our method not only achieves new sota results on the challenging apps benchmark  but also shows strong zero shot transfer capability with new sota results on the simpler mbpp benchmark        https https   preview redd it vavglraa jpg width  format pjpg auto webp s efcfabfadfafddba,paper https github https abstract program synthesis code generation aims generate program satisfies problem specification recent approaches using large scale pretrained language models lms shown promising results yet critical limitations particular often follow standard supervised fine tuning procedure train code generation model pairs natural language problem descriptions ground truth programs paradigm largely ignores important potentially useful signals problem specification unit tests thus often results poor performance solving complex unseen coding tasks address limitations propose coderl framework program synthesis tasks pretrained lms deep reinforcement learning rl specifically training treat code generating lm actor network introduce critic network trained predict functional correctness generated programs provide dense feedback signals actor inference introduce generation procedure critical sampling strategy allows model automatically regenerate programs based feedback example unit tests critic scores model backbones extended encoder decoder architecture codet enhanced learning objectives larger model sizes better pretraining data method achieves sota results challenging apps benchmark also shows strong zero shot transfer capability sota results simpler mbpp benchmark https https preview redd vavglraa jpg width format pjpg auto webp efcfabfadfafddba,r coderl mastering code generation pretrained models deep reinforcement learning,r coderl mastering code generation pretrained models deep reinforcement learningpaper https github https abstract program synthesis code generation aims generate program satisfies problem specification recent approaches using large scale pretrained language models lms shown promising results yet critical limitations particular often follow standard supervised fine tuning procedure train code generation model pairs natural language problem descriptions ground truth programs paradigm largely ignores important potentially useful signals problem specification unit tests thus often results poor performance solving complex unseen coding tasks address limitations propose coderl framework program synthesis tasks pretrained lms deep reinforcement learning rl specifically training treat code generating lm actor network introduce critic network trained predict functional correctness generated programs provide dense feedback signals actor inference introduce generation procedure critical sampling strategy allows model automatically regenerate programs based feedback example unit tests critic scores model backbones extended encoder decoder architecture codet enhanced learning objectives larger model sizes better pretraining data method achieves sota results challenging apps benchmark also shows strong zero shot transfer capability sota results simpler mbpp benchmark https https preview redd vavglraa jpg width format pjpg auto webp efcfabfadfafddba,"['r', 'coderl', 'mastering', 'code', 'generation', 'pretrained', 'models', 'deep', 'reinforcement', 'learningpaper', 'https', 'github', 'https', 'abstract', 'program', 'synthesis', 'code', 'generation', 'aims', 'generate', 'program', 'satisfies', 'problem', 'specification', 'recent', 'approaches', 'using', 'large', 'scale', 'pretrained', 'language', 'models', 'lms', 'shown', 'promising', 'results', 'yet', 'critical', 'limitations', 'particular', 'often', 'follow', 'standard', 'supervised', 'fine', 'tuning', 'procedure', 'train', 'code', 'generation', 'model', 'pairs', 'natural', 'language', 'problem', 'descriptions', 'ground', 'truth', 'programs', 'paradigm', 'largely', 'ignores', 'important', 'potentially', 'useful', 'signals', 'problem', 'specification', 'unit', 'tests', 'thus', 'often', 'results', 'poor', 'performance', 'solving', 'complex', 'unseen', 'coding', 'tasks', 'address', 'limitations', 'propose', 'coderl', 'framework', 'program', 'synthesis', 'tasks', 'pretrained', 'lms', 'deep', 'reinforcement', 'learning', 'rl', 'specifically', 'training', 'treat', 'code', 'generating', 'lm', 'actor', 'network', 'introduce', 'critic', 'network', 'trained', 'predict', 'functional', 'correctness', 'generated', 'programs', 'provide', 'dense', 'feedback', 'signals', 'actor', 'inference', 'introduce', 'generation', 'procedure', 'critical', 'sampling', 'strategy', 'allows', 'model', 'automatically', 'regenerate', 'programs', 'based', 'feedback', 'example', 'unit', 'tests', 'critic', 'scores', 'model', 'backbones', 'extended', 'encoder', 'decoder', 'architecture', 'codet', 'enhanced', 'learning', 'objectives', 'larger', 'model', 'sizes', 'better', 'pretraining', 'data', 'method', 'achieves', 'sota', 'results', 'challenging', 'apps', 'benchmark', 'also', 'shows', 'strong', 'zero', 'shot', 'transfer', 'capability', 'sota', 'results', 'simpler', 'mbpp', 'benchmark', 'https', 'https', 'preview', 'redd', 'vavglraa', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'efcfabfadfafddba']","['r', 'coderl', 'master', 'code', 'gener', 'pretrain', 'model', 'deep', 'reinforc', 'learningpap', 'http', 'github', 'http', 'abstract', 'program', 'synthesi', 'code', 'gener', 'aim', 'gener', 'program', 'satisfi', 'problem', 'specif', 'recent', 'approach', 'use', 'larg', 'scale', 'pretrain', 'languag', 'model', 'lm', 'shown', 'promis', 'result', 'yet', 'critic', 'limit', 'particular', 'often', 'follow', 'standard', 'supervis', 'fine', 'tune', 'procedur', 'train', 'code', 'gener', 'model', 'pair', 'natur', 'languag', 'problem', 'descript', 'ground', 'truth', 'program', 'paradigm', 'larg', 'ignor', 'import', 'potenti', 'use', 'signal', 'problem', 'specif', 'unit', 'test', 'thu', 'often', 'result', 'poor', 'perform', 'solv', 'complex', 'unseen', 'code', 'task', 'address', 'limit', 'propos', 'coderl', 'framework', 'program', 'synthesi', 'task', 'pretrain', 'lm', 'deep', 'reinforc', 'learn', 'rl', 'specif', 'train', 'treat', 'code', 'gener', 'lm', 'actor', 'network', 'introduc', 'critic', 'network', 'train', 'predict', 'function', 'correct', 'gener', 'program', 'provid', 'dens', 'feedback', 'signal', 'actor', 'infer', 'introduc', 'gener', 'procedur', 'critic', 'sampl', 'strategi', 'allow', 'model', 'automat', 'regener', 'program', 'base', 'feedback', 'exampl', 'unit', 'test', 'critic', 'score', 'model', 'backbon', 'extend', 'encod', 'decod', 'architectur', 'codet', 'enhanc', 'learn', 'object', 'larger', 'model', 'size', 'better', 'pretrain', 'data', 'method', 'achiev', 'sota', 'result', 'challeng', 'app', 'benchmark', 'also', 'show', 'strong', 'zero', 'shot', 'transfer', 'capabl', 'sota', 'result', 'simpler', 'mbpp', 'benchmark', 'http', 'http', 'preview', 'redd', 'vavglraa', 'jpg', 'width', 'format', 'pjpg', 'auto', 'webp', 'efcfabfadfafddba']"
294,323,323,AeronByHermanMiller,vt8jc4,[D] Why do first layer filters in CNNs converge to edge-detector-like filters?,"I believe its well known that generally first layer filters in CNNs will converge to ""edge-detector-like"" shapes like this: [shorturl.at/ANS78](https://shorturl.at/ANS78). 

This phenomenon is independent of the task from what I've seen - every large CNN backbone I've trained will converge to this given enough data. There is also research showing this type of edge detection happens in the visual cortex. Thus this edge detector phenomenon appears to be some fundamentally emergent property of the real world (+ maybe CNN type processors)

Is there any compelling technical explanation for how SGD and its variants can reliably produce this convergence? I don't mean why edge detectors are ""good"" first stage filters - that intuitively makes sense to me. But rather, how is it that SGD can reliably produce this type of convergence on any dataset? I've been looking for a while for an explanation but couldn't find anything great. 

I was thinking that maybe there is some explanation using an assumption that edges are naturally ""higher information"" on raw images from the real world, and thus more directionally stepped towards in the gradient? But can't get the explanation to a satisfying state.",8,7,2022-07-07 06:17:02, d  why do first layer filters in cnns converge to edge detector like filters ,i believe its well known that generally first layer filters in cnns will converge to edge detector like shapes like this   shorturl at ans  https this phenomenon is independent of the task from what i ve seen   every large cnn backbone i ve trained will converge to this given enough data  there is also research showing this type of edge detection happens in the visual cortex  thus this edge detector phenomenon appears to be some fundamentally emergent property of the real world    maybe cnn type processors is there any compelling technical explanation for how sgd and its variants can reliably produce this convergence  i don t mean why edge detectors are good first stage filters   that intuitively makes sense to me  but rather  how is it that sgd can reliably produce this type of convergence on any dataset  i ve been looking for a while for an explanation but couldn t find anything great  i was thinking that maybe there is some explanation using an assumption that edges are naturally higher information on raw images from the real world  and thus more directionally stepped towards in the gradient  but can t get the explanation to a satisfying state ,believe well known generally first layer filters cnns converge edge detector like shapes like shorturl ans https phenomenon independent task seen every large cnn backbone trained converge given enough data also research showing type edge detection happens visual cortex thus edge detector phenomenon appears fundamentally emergent property real world maybe cnn type processors compelling technical explanation sgd variants reliably produce convergence mean edge detectors good first stage filters intuitively makes sense rather sgd reliably produce type convergence dataset looking explanation find anything great thinking maybe explanation using assumption edges naturally higher information raw images real world thus directionally stepped towards gradient get explanation satisfying state,first layer filters cnns converge edge detector like filters,first layer filters cnns converge edge detector like filtersbelieve well known generally first layer filters cnns converge edge detector like shapes like shorturl ans https phenomenon independent task seen every large cnn backbone trained converge given enough data also research showing type edge detection happens visual cortex thus edge detector phenomenon appears fundamentally emergent property real world maybe cnn type processors compelling technical explanation sgd variants reliably produce convergence mean edge detectors good first stage filters intuitively makes sense rather sgd reliably produce type convergence dataset looking explanation find anything great thinking maybe explanation using assumption edges naturally higher information raw images real world thus directionally stepped towards gradient get explanation satisfying state,"['first', 'layer', 'filters', 'cnns', 'converge', 'edge', 'detector', 'like', 'filtersbelieve', 'well', 'known', 'generally', 'first', 'layer', 'filters', 'cnns', 'converge', 'edge', 'detector', 'like', 'shapes', 'like', 'shorturl', 'ans', 'https', 'phenomenon', 'independent', 'task', 'seen', 'every', 'large', 'cnn', 'backbone', 'trained', 'converge', 'given', 'enough', 'data', 'also', 'research', 'showing', 'type', 'edge', 'detection', 'happens', 'visual', 'cortex', 'thus', 'edge', 'detector', 'phenomenon', 'appears', 'fundamentally', 'emergent', 'property', 'real', 'world', 'maybe', 'cnn', 'type', 'processors', 'compelling', 'technical', 'explanation', 'sgd', 'variants', 'reliably', 'produce', 'convergence', 'mean', 'edge', 'detectors', 'good', 'first', 'stage', 'filters', 'intuitively', 'makes', 'sense', 'rather', 'sgd', 'reliably', 'produce', 'type', 'convergence', 'dataset', 'looking', 'explanation', 'find', 'anything', 'great', 'thinking', 'maybe', 'explanation', 'using', 'assumption', 'edges', 'naturally', 'higher', 'information', 'raw', 'images', 'real', 'world', 'thus', 'directionally', 'stepped', 'towards', 'gradient', 'get', 'explanation', 'satisfying', 'state']","['first', 'layer', 'filter', 'cnn', 'converg', 'edg', 'detector', 'like', 'filtersbeliev', 'well', 'known', 'gener', 'first', 'layer', 'filter', 'cnn', 'converg', 'edg', 'detector', 'like', 'shape', 'like', 'shorturl', 'an', 'http', 'phenomenon', 'independ', 'task', 'seen', 'everi', 'larg', 'cnn', 'backbon', 'train', 'converg', 'given', 'enough', 'data', 'also', 'research', 'show', 'type', 'edg', 'detect', 'happen', 'visual', 'cortex', 'thu', 'edg', 'detector', 'phenomenon', 'appear', 'fundament', 'emerg', 'properti', 'real', 'world', 'mayb', 'cnn', 'type', 'processor', 'compel', 'technic', 'explan', 'sgd', 'variant', 'reliabl', 'produc', 'converg', 'mean', 'edg', 'detector', 'good', 'first', 'stage', 'filter', 'intuit', 'make', 'sens', 'rather', 'sgd', 'reliabl', 'produc', 'type', 'converg', 'dataset', 'look', 'explan', 'find', 'anyth', 'great', 'think', 'mayb', 'explan', 'use', 'assumpt', 'edg', 'natur', 'higher', 'inform', 'raw', 'imag', 'real', 'world', 'thu', 'direct', 'step', 'toward', 'gradient', 'get', 'explan', 'satisfi', 'state']"
295,324,324,fasttosmile,vt1v4n,[D] How would you measure the correlation of the gradient across iterations?,"One simple thing one could do is take the dot product between the current and the n-1 gradient.

But this will of course not be very meaningful as what really matters is a (sort-of) average correlation across several iterations, which will not be revealed from doing such a local comparison (using gradients from step n and n-1).

Ideally it would be a calculation that would not require keeping around old gradients. Any ideas?",4,9,2022-07-07 01:01:17, d  how would you measure the correlation of the gradient across iterations ,one simple thing one could do is take the dot product between the current and the n  gradient but this will of course not be very meaningful as what really matters is a  sort of  average correlation across several iterations  which will not be revealed from doing such a local comparison  using gradients from step n and n   ideally it would be a calculation that would not require keeping around old gradients  any ideas ,one simple thing one could take dot product current n gradient course meaningful really matters sort average correlation across several iterations revealed local comparison using gradients step n n ideally would calculation would require keeping around old gradients ideas,would measure correlation gradient across iterations,would measure correlation gradient across iterationsone simple thing one could take dot product current n gradient course meaningful really matters sort average correlation across several iterations revealed local comparison using gradients step n n ideally would calculation would require keeping around old gradients ideas,"['would', 'measure', 'correlation', 'gradient', 'across', 'iterationsone', 'simple', 'thing', 'one', 'could', 'take', 'dot', 'product', 'current', 'n', 'gradient', 'course', 'meaningful', 'really', 'matters', 'sort', 'average', 'correlation', 'across', 'several', 'iterations', 'revealed', 'local', 'comparison', 'using', 'gradients', 'step', 'n', 'n', 'ideally', 'would', 'calculation', 'would', 'require', 'keeping', 'around', 'old', 'gradients', 'ideas']","['would', 'measur', 'correl', 'gradient', 'across', 'iterationson', 'simpl', 'thing', 'one', 'could', 'take', 'dot', 'product', 'current', 'n', 'gradient', 'cours', 'meaning', 'realli', 'matter', 'sort', 'averag', 'correl', 'across', 'sever', 'iter', 'reveal', 'local', 'comparison', 'use', 'gradient', 'step', 'n', 'n', 'ideal', 'would', 'calcul', 'would', 'requir', 'keep', 'around', 'old', 'gradient', 'idea']"
296,325,325,CapitalShake3085,vsppcq,[R] Detectron2 STMDA-RetinaNet,"Hello, i am happy to share with you one of my latest work for domain adaptation built on top of Detectron2 object detector model (RetinaNet).

Link to the github repo STMDA-RetinaNet:  
[https://github.com/fpv-iplab/STMDA-RetinaNet](https://github.com/fpv-iplab/STMDA-RetinaNet)",2,11,2022-07-06 16:11:01, r  detectron stmda retinanet,hello  i am happy to share with you one of my latest work for domain adaptation built on top of detectron object detector model  retinanet  link to the github repo stmda retinanet    https   github com fpv iplab stmda retinanet  https   github com fpv iplab stmda retinanet ,hello happy share one latest work domain adaptation built top detectron object detector model retinanet link github repo stmda retinanet https github com fpv iplab stmda retinanet https github com fpv iplab stmda retinanet,r detectron stmda retinanet,r detectron stmda retinanethello happy share one latest work domain adaptation built top detectron object detector model retinanet link github repo stmda retinanet https github com fpv iplab stmda retinanet https github com fpv iplab stmda retinanet,"['r', 'detectron', 'stmda', 'retinanethello', 'happy', 'share', 'one', 'latest', 'work', 'domain', 'adaptation', 'built', 'top', 'detectron', 'object', 'detector', 'model', 'retinanet', 'link', 'github', 'repo', 'stmda', 'retinanet', 'https', 'github', 'com', 'fpv', 'iplab', 'stmda', 'retinanet', 'https', 'github', 'com', 'fpv', 'iplab', 'stmda', 'retinanet']","['r', 'detectron', 'stmda', 'retinanethello', 'happi', 'share', 'one', 'latest', 'work', 'domain', 'adapt', 'built', 'top', 'detectron', 'object', 'detector', 'model', 'retinanet', 'link', 'github', 'repo', 'stmda', 'retinanet', 'http', 'github', 'com', 'fpv', 'iplab', 'stmda', 'retinanet', 'http', 'github', 'com', 'fpv', 'iplab', 'stmda', 'retinanet']"
297,326,326,CYHSM,vstqhm,[P] Some new Sherlock Holmes stories (GPT-3),"I thought I share some of the Sherlock Holmes stories I created with various prompts using GPT-3. Might be fun for some fans, but overall the stories are all a bit superficial, although some of them made me laugh (the fourth one in particular).

&#x200B;

>John Watson was having a cup of tea in his flat when he heard a knock at the door. He got up to answer it, and found Sherlock Holmes standing there, looking rather grave.  
>  
>""Watson, I'm afraid I have some bad news,"" said Sherlock. ""I've just been to Baker Street, where I found Mrs. Hudson in a state of hysterics. It seems that a Mr. Bartholomew Jones was found dead in his study, and Mrs. Hudson is convinced that it was murder.""  
>  
>""That is rather shocking,"" said Watson. ""Do you have any idea who might have done it?""  
>  
>""I have some suspicions,"" replied Sherlock, ""but I should like to take a look at the body before drawing any conclusions. Would you be so kind as to come with me?""  
>  
>Watson agreed, and the two men made their way to Baker Street. There they found Mrs. Hudson still in a state of distress, and she led them to the study where the body was lying.  
>  
>It was immediately evident to Watson that this was no ordinary death. Mr. Jones had been stabbed multiple times, and there was a look of terror on his face.  
>  
>""This was no accident, Watson,"" said Sherlock. ""Someone wanted to make sure that Mr. Jones was dead.""  
>  
>Sherlock began to examine the body, and soon found what he was looking for: a piece of paper that had been hidden under the victim's shirt.  
>  
>""What does it say?"" asked Watson.  
>  
>""It's a list of names,"" replied Sherlock, ""and at the top is the name 'John Watson'.""  
>  
>""Good heavens!"" exclaimed Watson. ""Do you think I'm the murderer?""  
>  
>""I don't know,"" said Sherlock, ""but we need to find out who else is on this list. I'm afraid this is going to be a rather difficult case.""

\---

>""I'm telling you, John, this is the most baffling case I've ever encountered!""  
>  
>""Really, Sherlock? What's so special about it?""  
>  
>""Well, for one thing, the victim is a chicken.""  
>  
>""A chicken?""  
>  
>""Yes, a chicken. It was found dead in its coop with its throat slit.""  
>  
>""That doesn't sound so baffling to me. I'm sure the police will catch the culprit soon enough.""  
>  
>""You're not thinking, John! The chicken was found with a note.""  
>  
>""A note?""  
>  
>""Yes, a note. And on that note was written, 'Sherlock Holmes, I challenge you to solve this mystery.'""  
>  
>""So the culprit wants you to solve it, eh? That is a bit strange.""  
>  
>""Indeed. And that's not all. The note was signed 'Moriarty.'""  
>  
>""Moriarty! But he's been dead for years!""  
>  
>""So it would seem. But I have a feeling this is his handiwork.""  
>  
>""What makes you say that?""  
>  
>""Well, for one thing, Moriarty was a master of disguise. It's entirely possible he's still alive and is using one of his many aliases.""  
>  
>""But why would he want you to solve the mystery?""  
>  
>""I can only speculate. Perhaps he's bored in retirement and wants to give me a challenge. Or perhaps he's planning something bigger and this is just a diversion.""  
>  
>""Well, whatever the reason, it seems we're going to have to solve this mystery. I'll get the magnifying glass.""  
>  
>""And I'll start putting together a list of suspects.""  
>  
>""Excellent. I have a feeling this is going to be a most interesting case.""

\---

>John Watson was just about to drift off to sleep when he heard a loud crash downstairs. He leapt out of bed, grabbed his trusty revolver, and crept downstairs, heart pounding in his chest.  
>  
>What he saw shocked him. There, in the middle of his living room, was a huge, furry creature, standing on two legs and brandishing a knife. It was like nothing he had ever seen before.  
>  
>Before he could think, the creature lunged at him, knife raised. Watson reacted on instinct, firing his revolver. The bullet hit the creature in the chest and it fell to the ground with a thud.  
>  
>Watson's mind was racing. What was this thing? Where had it come from? And then he remembered the stories he had heard about Sherlock Holmes and his uncanny ability to solve the most bizarre cases.  
>  
>He rushed to the phone and called Holmes. Within minutes, the detective was on his way.  
>  
>When Holmes arrived, he took one look at the creature and announced that it was a Yeti, a mythical creature from the Himalayas. Watson was dumbfounded. How could Holmes possibly know that?  
>  
>It turns out that the Yeti was part of a circus that had recently come to town. The circus owner had been keeping the Yeti in a cage and feeding it raw meat. But the Yeti had escaped and was terrorizing the city.  
>  
>Holmes had deduced all of this from the creature's fur, which was matted with blood, and the knife, which was of a type used by circus performers.

\---

>Sherlock Holmes and Dr. Watson were sitting in their usual chairs in the sitting room of 221B Baker Street, when they were suddenly interrupted by a loud, piercing scream. The two men leapt to their feet and ran to the window, just in time to see a man falling from the building opposite.  
>  
>""Quick, Watson, we must go and investigate!"" cried Sherlock Holmes.  
>  
>The two men hurried down the stairs and out into the street, where they found a crowd of people gathered around the body of the man who had fallen.  
>  
>""What happened here?"" asked Sherlock Holmes.  
>  
>""He was pushed!"" cried a woman in the crowd. ""I saw it with my own eyes, he was pushed!""  
>  
>""Why would anyone want to push him?"" asked Watson.  
>  
>""I don't know, but it was murder, I tell you!""  
>  
>Sherlock Holmes and Watson pushed their way through the crowd and squatted down beside the body. Holmes examined it closely, while Watson looked around to see if he could spot the murderer.  
>  
>""It's quite clear what happened,"" said Holmes after a few minutes. ""The victim was pushed from the window of that building over there.""  
>  
>""But who did it?"" asked Watson.  
>  
>""The murderer must have been in that building, too. Come, Watson, we must go and investigate!""  
>  
>The two men hurried across the street and entered the building. They made their way to the floor where the victim had fallen and began knocking on doors.  
>  
>Finally, they came to a door that was answered by a very old woman.  
>  
>""What do you want?"" she asked.  
>  
>""We're investigating the murder of the man who was pushed from the window,"" said Holmes.  
>  
>""Oh, that's easy enough to solve,"" said the woman. ""The murderer is my husband.""  
>  
>""Your husband?"" asked Watson in disbelief.  
>  
>""Yes, my husband. He's always wanted to push someone out of a window, and when he saw that man standing there, he just couldn't resist.""  
>  
>""But why?"" asked Sherlock Holmes.  
>  
>""Oh, he's just always been a very funny man, ever since I've known him.""  
>  
>Sherlock Holmes and Watson exchanged a look, then Holmes said, ""Thank you for your help, ma'am. We'll be on our way now.""

\---

>I say, John, what do you make of this?""  
>  
>Sherlock Holmes was looking at me with an expression of mild amusement, as if he had just witnessed some amusing incident. I knew better than to ask him what he was talking about, so I simply waited for him to continue.  
>  
>""I was just reading the paper, and there was an article about a man who was arrested for trying to steal a chicken from a farmer's market. The amusing part is that the man's name is John Watson.""  
>  
>I must have looked startled, because Holmes began to laugh.  
>  
>""Yes, I can see how you might find that amusing,"" I said, not sure why he was finding the situation so humorous.  
>  
>""It's just that, well, it's not the first time that someone has made the mistake of thinking that you were involved in a crime, John.""  
>  
>I couldn't help but chuckle at that. It was true that I had been the victim of a few misunderstandings over the years, thanks to my association with Sherlock Holmes. People often assumed that if Holmes was investigating a case, then I must be involved in some way.  
>  
>""Of course, the police quickly realized that they had the wrong man and released him,"" Holmes continued. ""But I'm sure the poor fellow was quite embarrassed.""  
>  
>""I'm sure he was,"" I said, still chuckling.  
>  
>It was just another day in the life of Sherlock Holmes and John Watson. A day filled with excitement, adventure, and, occasionally, a bit of humour.

\---

>I'm telling you, John, this is the most baffling case I've ever encountered!""  
>  
>""Really, Sherlock? What's so baffling about it?""  
>  
>""Well, to start with, there's the fact that the victim was stabbed with an umbrella!""  
>  
>""An umbrella? Surely that's not so unusual.""  
>  
>""It is when the victim is a cat, John!""  
>  
>""A cat? Good heavens, Sherlock, this is getting more bizarre by the minute!""  
>  
>""I know, I know. But that's not all. The cat was also wearing a top hat and a monocle!""  
>  
>""A top hat and a monocle? Now that is rather unusual.""  
>  
>""Indeed. But the most baffling thing of all is the fact that the cat was found in a room that was locked from the inside!""  
>  
>""Locked from the inside? How is that possible?""  
>  
>""I have no idea, John. But I intend to find out. This case is most certainly worthy of my attention.

\---

>Sherlock Holmes and Dr. Watson were sitting in their usual spot in the sitting room at 221B Baker Street, when there was a knock at the door. They both got up to answer it, and there was a young boy standing there, holding a note.  
>  
>""I was asked to deliver this to you, sir,"" the boy said, handing the note to Sherlock.  
>  
>Sherlock Holmes took the note and read it. ""It's from my brother, Mycroft,"" he said. ""He wants me to come to the Diogenes Club.""  
>  
>""The Diogenes Club?"" Watson asked. ""What's that?""  
>  
>""It's a club for my brother and his friends,"" Sherlock explained. ""It's very exclusive and they don't allow women or children.""  
>  
>""Sounds stuffy,"" Watson said.  
>  
>""It is,"" Sherlock agreed. ""But Mycroft says it's important, so I suppose we should go.""  
>  
>They both grabbed their coats and headed out. When they got to the Diogenes Club, they were met by a man who escorted them inside.  
>  
>The club was everything Sherlock had said it would be. It was stuffy and there were no women or children. Mycroft was sitting in a chair, talking to a couple of other men. He saw Sherlock and Watson and gestured for them to join him.  
>  
>""Ah, Sherlock, good to see you,"" he said. ""I need your help with something.""  
>  
>""What is it?"" Sherlock asked.  
>  
>""There's been a murder,"" Mycroft said. ""One of the club members was found dead in his room.""  
>  
>""Who was it?"" Sherlock asked.  
>  
>""It was Sir Wilfred Baskerville,"" Mycroft said.  
>  
>""The man who owns the Baskerville estate?"" Watson asked.  
>  
>""The very same,"" Mycroft said. ""The police are baffled and I was hoping you could take a look.""  
>  
>""I'll see what I can do,"" Sherlock said.  
>  
>They went to Sir Wilfred's room and Sherlock began to examine the body. He quickly deduced that the man had been poisoned.  
>  
>""The killer must have put the poison in his drink,"" he said. ""But there's no sign of any struggle, so the man must have been unaware of what was happening.""  
>  
>""But who would want to kill him?"" Watson asked.  
>  
>""That's what I need to find out,"" Sherlock said.  
>  
>He began to question the other club members, but no one seemed to know anything. He was just about to give up when he saw a man walking a funny looking horse.  
>  
>""That's odd,"" he said. ""I've never seen a horse like that before.""  
>  
>He followed the man and watched as he went into the room of another club member. Sherlock waited a few minutes and then went into the room himself.  
>  
>""I thought I might find you in here,"" he said. ""You're the killer, aren't you?""  
>  
>The man tried to deny it, but Sherlock had evidence that he was the guilty one. He had been seen talking to Sir Wilfred earlier in the evening and he had been seen walking the funny looking horse.  
>  
>""But why?"" Sherlock asked. ""What could possibly motive you?""  
>  
>""It was the horse,"" the man said. ""He was always making fun of my horse and calling him names. I couldn't take it anymore.""  
>  
>So the killer had motive after all. And it was all because of a funny looking horse.

\---

>John Watson was sitting in his study, perusing the latest edition of The Strand Magazine, when he heard a light knock at the door. Putting down the magazine, he got up to answer it, finding Sherlock Holmes standing on the threshold, clutching a piece of paper in his hand.  
>  
>""Watson, come quick!"" said Holmes, his eyes gleaming with excitement. ""I've just received the most curious letter, and I need your help to solve the mystery.""  
>  
>Watson followed Holmes back to his own flat, where the letter was laid out on the table. It was written in a spidery hand, and consisted of nothing but a series of numbers:  
>  
>""7, 12, 9, 3, 14, 5, 11, 6, 2, 10, 4, 13, 8, 1""  
>  
>""What do you make of it, Watson?"" Holmes asked, his eyes narrowed in concentration.  
>  
>Watson shook his head, bemused. ""I'm afraid I don't see anything, Holmes.""  
>  
>""Come, come, Watson, use that famous deductive brain of yours!""  
>  
>After a few moments' thought, Watson had an idea. ""Perhaps it's a code of some sort?""  
>  
>""Excellent, Watson, as always!"" cried Holmes. ""Now, if we can just crack the code...""  
>  
>He sat down at the table and began to scribble on a piece of paper, muttering to himself as he worked. Watson watched him for a few minutes, then, feeling rather superfluous, picked up his magazine and began to leaf through it again.  
>  
>Suddenly, Holmes leapt up from the table with a cry of triumph. ""I've got it, Watson!""",1,6,2022-07-06 19:14:33, p  some new sherlock holmes stories  gpt  ,i thought i share some of the sherlock holmes stories i created with various prompts using gpt   might be fun for some fans  but overall the stories are all a bit superficial  although some of them made me laugh  the fourth one in particular    xb  john watson was having a cup of tea in his flat when he heard a knock at the door  he got up to answer it  and found sherlock holmes standing there  looking rather grave       watson  i m afraid i have some bad news  said sherlock  i ve just been to baker street  where i found mrs  hudson in a state of hysterics  it seems that a mr  bartholomew jones was found dead in his study  and mrs  hudson is convinced that it was murder       that is rather shocking  said watson  do you have any idea who might have done it       i have some suspicions  replied sherlock  but i should like to take a look at the body before drawing any conclusions  would you be so kind as to come with me       watson agreed  and the two men made their way to baker street  there they found mrs  hudson still in a state of distress  and she led them to the study where the body was lying       it was immediately evident to watson that this was no ordinary death  mr  jones had been stabbed multiple times  and there was a look of terror on his face       this was no accident  watson  said sherlock  someone wanted to make sure that mr  jones was dead       sherlock began to examine the body  and soon found what he was looking for  a piece of paper that had been hidden under the victim s shirt       what does it say  asked watson       it s a list of names  replied sherlock  and at the top is the name  john watson        good heavens  exclaimed watson  do you think i m the murderer       i don t know  said sherlock  but we need to find out who else is on this list  i m afraid this is going to be a rather difficult case      i m telling you  john  this is the most baffling case i ve ever encountered       really  sherlock  what s so special about it       well  for one thing  the victim is a chicken       a chicken       yes  a chicken  it was found dead in its coop with its throat slit       that doesn t sound so baffling to me  i m sure the police will catch the culprit soon enough       you re not thinking  john  the chicken was found with a note       a note       yes  a note  and on that note was written   sherlock holmes  i challenge you to solve this mystery        so the culprit wants you to solve it  eh  that is a bit strange       indeed  and that s not all  the note was signed  moriarty        moriarty  but he s been dead for years       so it would seem  but i have a feeling this is his handiwork       what makes you say that       well  for one thing  moriarty was a master of disguise  it s entirely possible he s still alive and is using one of his many aliases       but why would he want you to solve the mystery       i can only speculate  perhaps he s bored in retirement and wants to give me a challenge  or perhaps he s planning something bigger and this is just a diversion       well  whatever the reason  it seems we re going to have to solve this mystery  i ll get the magnifying glass       and i ll start putting together a list of suspects       excellent  i have a feeling this is going to be a most interesting case      john watson was just about to drift off to sleep when he heard a loud crash downstairs  he leapt out of bed  grabbed his trusty revolver  and crept downstairs  heart pounding in his chest       what he saw shocked him  there  in the middle of his living room  was a huge  furry creature  standing on two legs and brandishing a knife  it was like nothing he had ever seen before       before he could think  the creature lunged at him  knife raised  watson reacted on instinct  firing his revolver  the bullet hit the creature in the chest and it fell to the ground with a thud       watson s mind was racing  what was this thing  where had it come from  and then he remembered the stories he had heard about sherlock holmes and his uncanny ability to solve the most bizarre cases       he rushed to the phone and called holmes  within minutes  the detective was on his way       when holmes arrived  he took one look at the creature and announced that it was a yeti  a mythical creature from the himalayas  watson was dumbfounded  how could holmes possibly know that       it turns out that the yeti was part of a circus that had recently come to town  the circus owner had been keeping the yeti in a cage and feeding it raw meat  but the yeti had escaped and was terrorizing the city       holmes had deduced all of this from the creature s fur  which was matted with blood  and the knife  which was of a type used by circus performers      sherlock holmes and dr  watson were sitting in their usual chairs in the sitting room of b baker street  when they were suddenly interrupted by a loud  piercing scream  the two men leapt to their feet and ran to the window  just in time to see a man falling from the building opposite       quick  watson  we must go and investigate  cried sherlock holmes       the two men hurried down the stairs and out into the street  where they found a crowd of people gathered around the body of the man who had fallen       what happened here  asked sherlock holmes       he was pushed  cried a woman in the crowd  i saw it with my own eyes  he was pushed       why would anyone want to push him  asked watson       i don t know  but it was murder  i tell you       sherlock holmes and watson pushed their way through the crowd and squatted down beside the body  holmes examined it closely  while watson looked around to see if he could spot the murderer       it s quite clear what happened  said holmes after a few minutes  the victim was pushed from the window of that building over there       but who did it  asked watson       the murderer must have been in that building  too  come  watson  we must go and investigate       the two men hurried across the street and entered the building  they made their way to the floor where the victim had fallen and began knocking on doors       finally  they came to a door that was answered by a very old woman       what do you want  she asked       we re investigating the murder of the man who was pushed from the window  said holmes       oh  that s easy enough to solve  said the woman  the murderer is my husband       your husband  asked watson in disbelief       yes  my husband  he s always wanted to push someone out of a window  and when he saw that man standing there  he just couldn t resist       but why  asked sherlock holmes       oh  he s just always been a very funny man  ever since i ve known him       sherlock holmes and watson exchanged a look  then holmes said  thank you for your help  ma am  we ll be on our way now      i say  john  what do you make of this       sherlock holmes was looking at me with an expression of mild amusement  as if he had just witnessed some amusing incident  i knew better than to ask him what he was talking about  so i simply waited for him to continue       i was just reading the paper  and there was an article about a man who was arrested for trying to steal a chicken from a farmer s market  the amusing part is that the man s name is john watson       i must have looked startled  because holmes began to laugh       yes  i can see how you might find that amusing  i said  not sure why he was finding the situation so humorous       it s just that  well  it s not the first time that someone has made the mistake of thinking that you were involved in a crime  john       i couldn t help but chuckle at that  it was true that i had been the victim of a few misunderstandings over the years  thanks to my association with sherlock holmes  people often assumed that if holmes was investigating a case  then i must be involved in some way       of course  the police quickly realized that they had the wrong man and released him  holmes continued  but i m sure the poor fellow was quite embarrassed       i m sure he was  i said  still chuckling       it was just another day in the life of sherlock holmes and john watson  a day filled with excitement  adventure  and  occasionally  a bit of humour      i m telling you  john  this is the most baffling case i ve ever encountered       really  sherlock  what s so baffling about it       well  to start with  there s the fact that the victim was stabbed with an umbrella       an umbrella  surely that s not so unusual       it is when the victim is a cat  john       a cat  good heavens  sherlock  this is getting more bizarre by the minute       i know  i know  but that s not all  the cat was also wearing a top hat and a monocle       a top hat and a monocle  now that is rather unusual       indeed  but the most baffling thing of all is the fact that the cat was found in a room that was locked from the inside       locked from the inside  how is that possible       i have no idea  john  but i intend to find out  this case is most certainly worthy of my attention      sherlock holmes and dr  watson were sitting in their usual spot in the sitting room at b baker street  when there was a knock at the door  they both got up to answer it  and there was a young boy standing there  holding a note       i was asked to deliver this to you  sir  the boy said  handing the note to sherlock       sherlock holmes took the note and read it  it s from my brother  mycroft  he said  he wants me to come to the diogenes club       the diogenes club  watson asked  what s that       it s a club for my brother and his friends  sherlock explained  it s very exclusive and they don t allow women or children       sounds stuffy  watson said       it is  sherlock agreed  but mycroft says it s important  so i suppose we should go       they both grabbed their coats and headed out  when they got to the diogenes club  they were met by a man who escorted them inside       the club was everything sherlock had said it would be  it was stuffy and there were no women or children  mycroft was sitting in a chair  talking to a couple of other men  he saw sherlock and watson and gestured for them to join him       ah  sherlock  good to see you  he said  i need your help with something       what is it  sherlock asked       there s been a murder  mycroft said  one of the club members was found dead in his room       who was it  sherlock asked       it was sir wilfred baskerville  mycroft said       the man who owns the baskerville estate  watson asked       the very same  mycroft said  the police are baffled and i was hoping you could take a look       i ll see what i can do  sherlock said       they went to sir wilfred s room and sherlock began to examine the body  he quickly deduced that the man had been poisoned       the killer must have put the poison in his drink  he said  but there s no sign of any struggle  so the man must have been unaware of what was happening       but who would want to kill him  watson asked       that s what i need to find out  sherlock said       he began to question the other club members  but no one seemed to know anything  he was just about to give up when he saw a man walking a funny looking horse       that s odd  he said  i ve never seen a horse like that before       he followed the man and watched as he went into the room of another club member  sherlock waited a few minutes and then went into the room himself       i thought i might find you in here  he said  you re the killer  aren t you       the man tried to deny it  but sherlock had evidence that he was the guilty one  he had been seen talking to sir wilfred earlier in the evening and he had been seen walking the funny looking horse       but why  sherlock asked  what could possibly motive you       it was the horse  the man said  he was always making fun of my horse and calling him names  i couldn t take it anymore       so the killer had motive after all  and it was all because of a funny looking horse      john watson was sitting in his study  perusing the latest edition of the strand magazine  when he heard a light knock at the door  putting down the magazine  he got up to answer it  finding sherlock holmes standing on the threshold  clutching a piece of paper in his hand       watson  come quick  said holmes  his eyes gleaming with excitement  i ve just received the most curious letter  and i need your help to solve the mystery       watson followed holmes back to his own flat  where the letter was laid out on the table  it was written in a spidery hand  and consisted of nothing but a series of numbers                                       what do you make of it  watson  holmes asked  his eyes narrowed in concentration       watson shook his head  bemused  i m afraid i don t see anything  holmes       come  come  watson  use that famous deductive brain of yours       after a few moments  thought  watson had an idea  perhaps it s a code of some sort       excellent  watson  as always  cried holmes  now  if we can just crack the code         he sat down at the table and began to scribble on a piece of paper  muttering to himself as he worked  watson watched him for a few minutes  then  feeling rather superfluous  picked up his magazine and began to leaf through it again       suddenly  holmes leapt up from the table with a cry of triumph  i ve got it  watson ,thought share sherlock holmes stories created various prompts using gpt might fun fans overall stories bit superficial although made laugh fourth one particular xb john watson cup tea flat heard knock door got answer found sherlock holmes standing looking rather grave watson afraid bad news said sherlock baker street found mrs hudson state hysterics seems mr bartholomew jones found dead study mrs hudson convinced murder rather shocking said watson idea might done suspicions replied sherlock like take look body drawing conclusions would kind come watson agreed two men made way baker street found mrs hudson still state distress led study body lying immediately evident watson ordinary death mr jones stabbed multiple times look terror face accident watson said sherlock someone wanted make sure mr jones dead sherlock began examine body soon found looking piece paper hidden victim shirt say asked watson names replied sherlock top name john watson good heavens exclaimed watson think murderer know said sherlock need find else afraid going rather difficult case telling john baffling case ever encountered really sherlock special well one thing victim chicken chicken yes chicken found dead coop throat slit sound baffling sure police catch culprit soon enough thinking john chicken found note note yes note note written sherlock holmes challenge solve mystery culprit wants solve eh bit strange indeed note signed moriarty moriarty dead years would seem feeling handiwork makes say well one thing moriarty master disguise entirely possible still alive using one many aliases would want solve mystery speculate perhaps bored retirement wants give challenge perhaps planning something bigger diversion well whatever reason seems going solve mystery get magnifying glass start putting together suspects excellent feeling going interesting case john watson drift sleep heard loud crash downstairs leapt bed grabbed trusty revolver crept downstairs heart pounding chest saw shocked middle living room huge furry creature standing two legs brandishing knife like nothing ever seen could think creature lunged knife raised watson reacted instinct firing revolver bullet hit creature chest fell ground thud watson mind racing thing come remembered stories heard sherlock holmes uncanny ability solve bizarre cases rushed phone called holmes within minutes detective way holmes arrived took one look creature announced yeti mythical creature himalayas watson dumbfounded could holmes possibly know turns yeti part circus recently come town circus owner keeping yeti cage feeding raw meat yeti escaped terrorizing city holmes deduced creature fur matted blood knife type used circus performers sherlock holmes dr watson sitting usual chairs sitting room b baker street suddenly interrupted loud piercing scream two men leapt feet ran window time see man falling building opposite quick watson must go investigate cried sherlock holmes two men hurried stairs street found crowd people gathered around body man fallen happened asked sherlock holmes pushed cried woman crowd saw eyes pushed would anyone want push asked watson know murder tell sherlock holmes watson pushed way crowd squatted beside body holmes examined closely watson looked around see could spot murderer quite clear happened said holmes minutes victim pushed window building asked watson murderer must building come watson must go investigate two men hurried across street entered building made way floor victim fallen began knocking doors finally came door answered old woman want asked investigating murder man pushed window said holmes oh easy enough solve said woman murderer husband husband asked watson disbelief yes husband always wanted push someone window saw man standing resist asked sherlock holmes oh always funny man ever since known sherlock holmes watson exchanged look holmes said thank help way say john make sherlock holmes looking expression mild amusement witnessed amusing incident knew better ask talking simply waited continue reading paper article man arrested trying steal chicken farmer market amusing part man name john watson must looked startled holmes began laugh yes see might find amusing said sure finding situation humorous well first time someone made mistake thinking involved crime john help chuckle true victim misunderstandings years thanks association sherlock holmes people often assumed holmes investigating case must involved way course police quickly realized wrong man released holmes continued sure poor fellow quite embarrassed sure said still chuckling another day life sherlock holmes john watson day filled excitement adventure occasionally bit humour telling john baffling case ever encountered really sherlock baffling well start fact victim stabbed umbrella umbrella surely unusual victim cat john cat good heavens sherlock getting bizarre minute know know cat also wearing top hat monocle top hat monocle rather unusual indeed baffling thing fact cat found room locked inside locked inside possible idea john intend find case certainly worthy attention sherlock holmes dr watson sitting usual spot sitting room b baker street knock door got answer young boy standing holding note asked deliver sir boy said handing note sherlock sherlock holmes took note read brother mycroft said wants come diogenes club diogenes club watson asked club brother friends sherlock explained exclusive allow women children sounds stuffy watson said sherlock agreed mycroft says important suppose go grabbed coats headed got diogenes club met man escorted inside club everything sherlock said would stuffy women children mycroft sitting chair talking couple men saw sherlock watson gestured join ah sherlock good see said need help something sherlock asked murder mycroft said one club members found dead room sherlock asked sir wilfred baskerville mycroft said man owns baskerville estate watson asked mycroft said police baffled hoping could take look see sherlock said went sir wilfred room sherlock began examine body quickly deduced man poisoned killer must put poison drink said sign struggle man must unaware happening would want kill watson asked need find sherlock said began question club members one seemed know anything give saw man walking funny looking horse odd said never seen horse like followed man watched went room another club member sherlock waited minutes went room thought might find said killer man tried deny sherlock evidence guilty one seen talking sir wilfred earlier evening seen walking funny looking horse sherlock asked could possibly motive horse man said always making fun horse calling names take anymore killer motive funny looking horse john watson sitting study perusing latest edition strand magazine heard light knock door putting magazine got answer finding sherlock holmes standing threshold clutching piece paper hand watson come quick said holmes eyes gleaming excitement received curious letter need help solve mystery watson followed holmes back flat letter laid table written spidery hand consisted nothing series numbers make watson holmes asked eyes narrowed concentration watson shook head bemused afraid see anything holmes come come watson use famous deductive brain moments thought watson idea perhaps code sort excellent watson always cried holmes crack code sat table began scribble piece paper muttering worked watson watched minutes feeling rather superfluous picked magazine began leaf suddenly holmes leapt table cry triumph got watson,p sherlock holmes stories gpt,p sherlock holmes stories gptthought share sherlock holmes stories created various prompts using gpt might fun fans overall stories bit superficial although made laugh fourth one particular xb john watson cup tea flat heard knock door got answer found sherlock holmes standing looking rather grave watson afraid bad news said sherlock baker street found mrs hudson state hysterics seems mr bartholomew jones found dead study mrs hudson convinced murder rather shocking said watson idea might done suspicions replied sherlock like take look body drawing conclusions would kind come watson agreed two men made way baker street found mrs hudson still state distress led study body lying immediately evident watson ordinary death mr jones stabbed multiple times look terror face accident watson said sherlock someone wanted make sure mr jones dead sherlock began examine body soon found looking piece paper hidden victim shirt say asked watson names replied sherlock top name john watson good heavens exclaimed watson think murderer know said sherlock need find else afraid going rather difficult case telling john baffling case ever encountered really sherlock special well one thing victim chicken chicken yes chicken found dead coop throat slit sound baffling sure police catch culprit soon enough thinking john chicken found note note yes note note written sherlock holmes challenge solve mystery culprit wants solve eh bit strange indeed note signed moriarty moriarty dead years would seem feeling handiwork makes say well one thing moriarty master disguise entirely possible still alive using one many aliases would want solve mystery speculate perhaps bored retirement wants give challenge perhaps planning something bigger diversion well whatever reason seems going solve mystery get magnifying glass start putting together suspects excellent feeling going interesting case john watson drift sleep heard loud crash downstairs leapt bed grabbed trusty revolver crept downstairs heart pounding chest saw shocked middle living room huge furry creature standing two legs brandishing knife like nothing ever seen could think creature lunged knife raised watson reacted instinct firing revolver bullet hit creature chest fell ground thud watson mind racing thing come remembered stories heard sherlock holmes uncanny ability solve bizarre cases rushed phone called holmes within minutes detective way holmes arrived took one look creature announced yeti mythical creature himalayas watson dumbfounded could holmes possibly know turns yeti part circus recently come town circus owner keeping yeti cage feeding raw meat yeti escaped terrorizing city holmes deduced creature fur matted blood knife type used circus performers sherlock holmes dr watson sitting usual chairs sitting room b baker street suddenly interrupted loud piercing scream two men leapt feet ran window time see man falling building opposite quick watson must go investigate cried sherlock holmes two men hurried stairs street found crowd people gathered around body man fallen happened asked sherlock holmes pushed cried woman crowd saw eyes pushed would anyone want push asked watson know murder tell sherlock holmes watson pushed way crowd squatted beside body holmes examined closely watson looked around see could spot murderer quite clear happened said holmes minutes victim pushed window building asked watson murderer must building come watson must go investigate two men hurried across street entered building made way floor victim fallen began knocking doors finally came door answered old woman want asked investigating murder man pushed window said holmes oh easy enough solve said woman murderer husband husband asked watson disbelief yes husband always wanted push someone window saw man standing resist asked sherlock holmes oh always funny man ever since known sherlock holmes watson exchanged look holmes said thank help way say john make sherlock holmes looking expression mild amusement witnessed amusing incident knew better ask talking simply waited continue reading paper article man arrested trying steal chicken farmer market amusing part man name john watson must looked startled holmes began laugh yes see might find amusing said sure finding situation humorous well first time someone made mistake thinking involved crime john help chuckle true victim misunderstandings years thanks association sherlock holmes people often assumed holmes investigating case must involved way course police quickly realized wrong man released holmes continued sure poor fellow quite embarrassed sure said still chuckling another day life sherlock holmes john watson day filled excitement adventure occasionally bit humour telling john baffling case ever encountered really sherlock baffling well start fact victim stabbed umbrella umbrella surely unusual victim cat john cat good heavens sherlock getting bizarre minute know know cat also wearing top hat monocle top hat monocle rather unusual indeed baffling thing fact cat found room locked inside locked inside possible idea john intend find case certainly worthy attention sherlock holmes dr watson sitting usual spot sitting room b baker street knock door got answer young boy standing holding note asked deliver sir boy said handing note sherlock sherlock holmes took note read brother mycroft said wants come diogenes club diogenes club watson asked club brother friends sherlock explained exclusive allow women children sounds stuffy watson said sherlock agreed mycroft says important suppose go grabbed coats headed got diogenes club met man escorted inside club everything sherlock said would stuffy women children mycroft sitting chair talking couple men saw sherlock watson gestured join ah sherlock good see said need help something sherlock asked murder mycroft said one club members found dead room sherlock asked sir wilfred baskerville mycroft said man owns baskerville estate watson asked mycroft said police baffled hoping could take look see sherlock said went sir wilfred room sherlock began examine body quickly deduced man poisoned killer must put poison drink said sign struggle man must unaware happening would want kill watson asked need find sherlock said began question club members one seemed know anything give saw man walking funny looking horse odd said never seen horse like followed man watched went room another club member sherlock waited minutes went room thought might find said killer man tried deny sherlock evidence guilty one seen talking sir wilfred earlier evening seen walking funny looking horse sherlock asked could possibly motive horse man said always making fun horse calling names take anymore killer motive funny looking horse john watson sitting study perusing latest edition strand magazine heard light knock door putting magazine got answer finding sherlock holmes standing threshold clutching piece paper hand watson come quick said holmes eyes gleaming excitement received curious letter need help solve mystery watson followed holmes back flat letter laid table written spidery hand consisted nothing series numbers make watson holmes asked eyes narrowed concentration watson shook head bemused afraid see anything holmes come come watson use famous deductive brain moments thought watson idea perhaps code sort excellent watson always cried holmes crack code sat table began scribble piece paper muttering worked watson watched minutes feeling rather superfluous picked magazine began leaf suddenly holmes leapt table cry triumph got watson,"['p', 'sherlock', 'holmes', 'stories', 'gptthought', 'share', 'sherlock', 'holmes', 'stories', 'created', 'various', 'prompts', 'using', 'gpt', 'might', 'fun', 'fans', 'overall', 'stories', 'bit', 'superficial', 'although', 'made', 'laugh', 'fourth', 'one', 'particular', 'xb', 'john', 'watson', 'cup', 'tea', 'flat', 'heard', 'knock', 'door', 'got', 'answer', 'found', 'sherlock', 'holmes', 'standing', 'looking', 'rather', 'grave', 'watson', 'afraid', 'bad', 'news', 'said', 'sherlock', 'baker', 'street', 'found', 'mrs', 'hudson', 'state', 'hysterics', 'seems', 'mr', 'bartholomew', 'jones', 'found', 'dead', 'study', 'mrs', 'hudson', 'convinced', 'murder', 'rather', 'shocking', 'said', 'watson', 'idea', 'might', 'done', 'suspicions', 'replied', 'sherlock', 'like', 'take', 'look', 'body', 'drawing', 'conclusions', 'would', 'kind', 'come', 'watson', 'agreed', 'two', 'men', 'made', 'way', 'baker', 'street', 'found', 'mrs', 'hudson', 'still', 'state', 'distress', 'led', 'study', 'body', 'lying', 'immediately', 'evident', 'watson', 'ordinary', 'death', 'mr', 'jones', 'stabbed', 'multiple', 'times', 'look', 'terror', 'face', 'accident', 'watson', 'said', 'sherlock', 'someone', 'wanted', 'make', 'sure', 'mr', 'jones', 'dead', 'sherlock', 'began', 'examine', 'body', 'soon', 'found', 'looking', 'piece', 'paper', 'hidden', 'victim', 'shirt', 'say', 'asked', 'watson', 'names', 'replied', 'sherlock', 'top', 'name', 'john', 'watson', 'good', 'heavens', 'exclaimed', 'watson', 'think', 'murderer', 'know', 'said', 'sherlock', 'need', 'find', 'else', 'afraid', 'going', 'rather', 'difficult', 'case', 'telling', 'john', 'baffling', 'case', 'ever', 'encountered', 'really', 'sherlock', 'special', 'well', 'one', 'thing', 'victim', 'chicken', 'chicken', 'yes', 'chicken', 'found', 'dead', 'coop', 'throat', 'slit', 'sound', 'baffling', 'sure', 'police', 'catch', 'culprit', 'soon', 'enough', 'thinking', 'john', 'chicken', 'found', 'note', 'note', 'yes', 'note', 'note', 'written', 'sherlock', 'holmes', 'challenge', 'solve', 'mystery', 'culprit', 'wants', 'solve', 'eh', 'bit', 'strange', 'indeed', 'note', 'signed', 'moriarty', 'moriarty', 'dead', 'years', 'would', 'seem', 'feeling', 'handiwork', 'makes', 'say', 'well', 'one', 'thing', 'moriarty', 'master', 'disguise', 'entirely', 'possible', 'still', 'alive', 'using', 'one', 'many', 'aliases', 'would', 'want', 'solve', 'mystery', 'speculate', 'perhaps', 'bored', 'retirement', 'wants', 'give', 'challenge', 'perhaps', 'planning', 'something', 'bigger', 'diversion', 'well', 'whatever', 'reason', 'seems', 'going', 'solve', 'mystery', 'get', 'magnifying', 'glass', 'start', 'putting', 'together', 'suspects', 'excellent', 'feeling', 'going', 'interesting', 'case', 'john', 'watson', 'drift', 'sleep', 'heard', 'loud', 'crash', 'downstairs', 'leapt', 'bed', 'grabbed', 'trusty', 'revolver', 'crept', 'downstairs', 'heart', 'pounding', 'chest', 'saw', 'shocked', 'middle', 'living', 'room', 'huge', 'furry', 'creature', 'standing', 'two', 'legs', 'brandishing', 'knife', 'like', 'nothing', 'ever', 'seen', 'could', 'think', 'creature', 'lunged', 'knife', 'raised', 'watson', 'reacted', 'instinct', 'firing', 'revolver', 'bullet', 'hit', 'creature', 'chest', 'fell', 'ground', 'thud', 'watson', 'mind', 'racing', 'thing', 'come', 'remembered', 'stories', 'heard', 'sherlock', 'holmes', 'uncanny', 'ability', 'solve', 'bizarre', 'cases', 'rushed', 'phone', 'called', 'holmes', 'within', 'minutes', 'detective', 'way', 'holmes', 'arrived', 'took', 'one', 'look', 'creature', 'announced', 'yeti', 'mythical', 'creature', 'himalayas', 'watson', 'dumbfounded', 'could', 'holmes', 'possibly', 'know', 'turns', 'yeti', 'part', 'circus', 'recently', 'come', 'town', 'circus', 'owner', 'keeping', 'yeti', 'cage', 'feeding', 'raw', 'meat', 'yeti', 'escaped', 'terrorizing', 'city', 'holmes', 'deduced', 'creature', 'fur', 'matted', 'blood', 'knife', 'type', 'used', 'circus', 'performers', 'sherlock', 'holmes', 'dr', 'watson', 'sitting', 'usual', 'chairs', 'sitting', 'room', 'b', 'baker', 'street', 'suddenly', 'interrupted', 'loud', 'piercing', 'scream', 'two', 'men', 'leapt', 'feet', 'ran', 'window', 'time', 'see', 'man', 'falling', 'building', 'opposite', 'quick', 'watson', 'must', 'go', 'investigate', 'cried', 'sherlock', 'holmes', 'two', 'men', 'hurried', 'stairs', 'street', 'found', 'crowd', 'people', 'gathered', 'around', 'body', 'man', 'fallen', 'happened', 'asked', 'sherlock', 'holmes', 'pushed', 'cried', 'woman', 'crowd', 'saw', 'eyes', 'pushed', 'would', 'anyone', 'want', 'push', 'asked', 'watson', 'know', 'murder', 'tell', 'sherlock', 'holmes', 'watson', 'pushed', 'way', 'crowd', 'squatted', 'beside', 'body', 'holmes', 'examined', 'closely', 'watson', 'looked', 'around', 'see', 'could', 'spot', 'murderer', 'quite', 'clear', 'happened', 'said', 'holmes', 'minutes', 'victim', 'pushed', 'window', 'building', 'asked', 'watson', 'murderer', 'must', 'building', 'come', 'watson', 'must', 'go', 'investigate', 'two', 'men', 'hurried', 'across', 'street', 'entered', 'building', 'made', 'way', 'floor', 'victim', 'fallen', 'began', 'knocking', 'doors', 'finally', 'came', 'door', 'answered', 'old', 'woman', 'want', 'asked', 'investigating', 'murder', 'man', 'pushed', 'window', 'said', 'holmes', 'oh', 'easy', 'enough', 'solve', 'said', 'woman', 'murderer', 'husband', 'husband', 'asked', 'watson', 'disbelief', 'yes', 'husband', 'always', 'wanted', 'push', 'someone', 'window', 'saw', 'man', 'standing', 'resist', 'asked', 'sherlock', 'holmes', 'oh', 'always', 'funny', 'man', 'ever', 'since', 'known', 'sherlock', 'holmes', 'watson', 'exchanged', 'look', 'holmes', 'said', 'thank', 'help', 'way', 'say', 'john', 'make', 'sherlock', 'holmes', 'looking', 'expression', 'mild', 'amusement', 'witnessed', 'amusing', 'incident', 'knew', 'better', 'ask', 'talking', 'simply', 'waited', 'continue', 'reading', 'paper', 'article', 'man', 'arrested', 'trying', 'steal', 'chicken', 'farmer', 'market', 'amusing', 'part', 'man', 'name', 'john', 'watson', 'must', 'looked', 'startled', 'holmes', 'began', 'laugh', 'yes', 'see', 'might', 'find', 'amusing', 'said', 'sure', 'finding', 'situation', 'humorous', 'well', 'first', 'time', 'someone', 'made', 'mistake', 'thinking', 'involved', 'crime', 'john', 'help', 'chuckle', 'true', 'victim', 'misunderstandings', 'years', 'thanks', 'association', 'sherlock', 'holmes', 'people', 'often', 'assumed', 'holmes', 'investigating', 'case', 'must', 'involved', 'way', 'course', 'police', 'quickly', 'realized', 'wrong', 'man', 'released', 'holmes', 'continued', 'sure', 'poor', 'fellow', 'quite', 'embarrassed', 'sure', 'said', 'still', 'chuckling', 'another', 'day', 'life', 'sherlock', 'holmes', 'john', 'watson', 'day', 'filled', 'excitement', 'adventure', 'occasionally', 'bit', 'humour', 'telling', 'john', 'baffling', 'case', 'ever', 'encountered', 'really', 'sherlock', 'baffling', 'well', 'start', 'fact', 'victim', 'stabbed', 'umbrella', 'umbrella', 'surely', 'unusual', 'victim', 'cat', 'john', 'cat', 'good', 'heavens', 'sherlock', 'getting', 'bizarre', 'minute', 'know', 'know', 'cat', 'also', 'wearing', 'top', 'hat', 'monocle', 'top', 'hat', 'monocle', 'rather', 'unusual', 'indeed', 'baffling', 'thing', 'fact', 'cat', 'found', 'room', 'locked', 'inside', 'locked', 'inside', 'possible', 'idea', 'john', 'intend', 'find', 'case', 'certainly', 'worthy', 'attention', 'sherlock', 'holmes', 'dr', 'watson', 'sitting', 'usual', 'spot', 'sitting', 'room', 'b', 'baker', 'street', 'knock', 'door', 'got', 'answer', 'young', 'boy', 'standing', 'holding', 'note', 'asked', 'deliver', 'sir', 'boy', 'said', 'handing', 'note', 'sherlock', 'sherlock', 'holmes', 'took', 'note', 'read', 'brother', 'mycroft', 'said', 'wants', 'come', 'diogenes', 'club', 'diogenes', 'club', 'watson', 'asked', 'club', 'brother', 'friends', 'sherlock', 'explained', 'exclusive', 'allow', 'women', 'children', 'sounds', 'stuffy', 'watson', 'said', 'sherlock', 'agreed', 'mycroft', 'says', 'important', 'suppose', 'go', 'grabbed', 'coats', 'headed', 'got', 'diogenes', 'club', 'met', 'man', 'escorted', 'inside', 'club', 'everything', 'sherlock', 'said', 'would', 'stuffy', 'women', 'children', 'mycroft', 'sitting', 'chair', 'talking', 'couple', 'men', 'saw', 'sherlock', 'watson', 'gestured', 'join', 'ah', 'sherlock', 'good', 'see', 'said', 'need', 'help', 'something', 'sherlock', 'asked', 'murder', 'mycroft', 'said', 'one', 'club', 'members', 'found', 'dead', 'room', 'sherlock', 'asked', 'sir', 'wilfred', 'baskerville', 'mycroft', 'said', 'man', 'owns', 'baskerville', 'estate', 'watson', 'asked', 'mycroft', 'said', 'police', 'baffled', 'hoping', 'could', 'take', 'look', 'see', 'sherlock', 'said', 'went', 'sir', 'wilfred', 'room', 'sherlock', 'began', 'examine', 'body', 'quickly', 'deduced', 'man', 'poisoned', 'killer', 'must', 'put', 'poison', 'drink', 'said', 'sign', 'struggle', 'man', 'must', 'unaware', 'happening', 'would', 'want', 'kill', 'watson', 'asked', 'need', 'find', 'sherlock', 'said', 'began', 'question', 'club', 'members', 'one', 'seemed', 'know', 'anything', 'give', 'saw', 'man', 'walking', 'funny', 'looking', 'horse', 'odd', 'said', 'never', 'seen', 'horse', 'like', 'followed', 'man', 'watched', 'went', 'room', 'another', 'club', 'member', 'sherlock', 'waited', 'minutes', 'went', 'room', 'thought', 'might', 'find', 'said', 'killer', 'man', 'tried', 'deny', 'sherlock', 'evidence', 'guilty', 'one', 'seen', 'talking', 'sir', 'wilfred', 'earlier', 'evening', 'seen', 'walking', 'funny', 'looking', 'horse', 'sherlock', 'asked', 'could', 'possibly', 'motive', 'horse', 'man', 'said', 'always', 'making', 'fun', 'horse', 'calling', 'names', 'take', 'anymore', 'killer', 'motive', 'funny', 'looking', 'horse', 'john', 'watson', 'sitting', 'study', 'perusing', 'latest', 'edition', 'strand', 'magazine', 'heard', 'light', 'knock', 'door', 'putting', 'magazine', 'got', 'answer', 'finding', 'sherlock', 'holmes', 'standing', 'threshold', 'clutching', 'piece', 'paper', 'hand', 'watson', 'come', 'quick', 'said', 'holmes', 'eyes', 'gleaming', 'excitement', 'received', 'curious', 'letter', 'need', 'help', 'solve', 'mystery', 'watson', 'followed', 'holmes', 'back', 'flat', 'letter', 'laid', 'table', 'written', 'spidery', 'hand', 'consisted', 'nothing', 'series', 'numbers', 'make', 'watson', 'holmes', 'asked', 'eyes', 'narrowed', 'concentration', 'watson', 'shook', 'head', 'bemused', 'afraid', 'see', 'anything', 'holmes', 'come', 'come', 'watson', 'use', 'famous', 'deductive', 'brain', 'moments', 'thought', 'watson', 'idea', 'perhaps', 'code', 'sort', 'excellent', 'watson', 'always', 'cried', 'holmes', 'crack', 'code', 'sat', 'table', 'began', 'scribble', 'piece', 'paper', 'muttering', 'worked', 'watson', 'watched', 'minutes', 'feeling', 'rather', 'superfluous', 'picked', 'magazine', 'began', 'leaf', 'suddenly', 'holmes', 'leapt', 'table', 'cry', 'triumph', 'got', 'watson']","['p', 'sherlock', 'holm', 'stori', 'gptthought', 'share', 'sherlock', 'holm', 'stori', 'creat', 'variou', 'prompt', 'use', 'gpt', 'might', 'fun', 'fan', 'overal', 'stori', 'bit', 'superfici', 'although', 'made', 'laugh', 'fourth', 'one', 'particular', 'xb', 'john', 'watson', 'cup', 'tea', 'flat', 'heard', 'knock', 'door', 'got', 'answer', 'found', 'sherlock', 'holm', 'stand', 'look', 'rather', 'grave', 'watson', 'afraid', 'bad', 'news', 'said', 'sherlock', 'baker', 'street', 'found', 'mr', 'hudson', 'state', 'hyster', 'seem', 'mr', 'bartholomew', 'jone', 'found', 'dead', 'studi', 'mr', 'hudson', 'convinc', 'murder', 'rather', 'shock', 'said', 'watson', 'idea', 'might', 'done', 'suspicion', 'repli', 'sherlock', 'like', 'take', 'look', 'bodi', 'draw', 'conclus', 'would', 'kind', 'come', 'watson', 'agre', 'two', 'men', 'made', 'way', 'baker', 'street', 'found', 'mr', 'hudson', 'still', 'state', 'distress', 'led', 'studi', 'bodi', 'lie', 'immedi', 'evid', 'watson', 'ordinari', 'death', 'mr', 'jone', 'stab', 'multipl', 'time', 'look', 'terror', 'face', 'accid', 'watson', 'said', 'sherlock', 'someon', 'want', 'make', 'sure', 'mr', 'jone', 'dead', 'sherlock', 'began', 'examin', 'bodi', 'soon', 'found', 'look', 'piec', 'paper', 'hidden', 'victim', 'shirt', 'say', 'ask', 'watson', 'name', 'repli', 'sherlock', 'top', 'name', 'john', 'watson', 'good', 'heaven', 'exclaim', 'watson', 'think', 'murder', 'know', 'said', 'sherlock', 'need', 'find', 'els', 'afraid', 'go', 'rather', 'difficult', 'case', 'tell', 'john', 'baffl', 'case', 'ever', 'encount', 'realli', 'sherlock', 'special', 'well', 'one', 'thing', 'victim', 'chicken', 'chicken', 'ye', 'chicken', 'found', 'dead', 'coop', 'throat', 'slit', 'sound', 'baffl', 'sure', 'polic', 'catch', 'culprit', 'soon', 'enough', 'think', 'john', 'chicken', 'found', 'note', 'note', 'ye', 'note', 'note', 'written', 'sherlock', 'holm', 'challeng', 'solv', 'mysteri', 'culprit', 'want', 'solv', 'eh', 'bit', 'strang', 'inde', 'note', 'sign', 'moriarti', 'moriarti', 'dead', 'year', 'would', 'seem', 'feel', 'handiwork', 'make', 'say', 'well', 'one', 'thing', 'moriarti', 'master', 'disguis', 'entir', 'possibl', 'still', 'aliv', 'use', 'one', 'mani', 'alias', 'would', 'want', 'solv', 'mysteri', 'specul', 'perhap', 'bore', 'retir', 'want', 'give', 'challeng', 'perhap', 'plan', 'someth', 'bigger', 'divers', 'well', 'whatev', 'reason', 'seem', 'go', 'solv', 'mysteri', 'get', 'magnifi', 'glass', 'start', 'put', 'togeth', 'suspect', 'excel', 'feel', 'go', 'interest', 'case', 'john', 'watson', 'drift', 'sleep', 'heard', 'loud', 'crash', 'downstair', 'leapt', 'bed', 'grab', 'trusti', 'revolv', 'crept', 'downstair', 'heart', 'pound', 'chest', 'saw', 'shock', 'middl', 'live', 'room', 'huge', 'furri', 'creatur', 'stand', 'two', 'leg', 'brandish', 'knife', 'like', 'noth', 'ever', 'seen', 'could', 'think', 'creatur', 'lung', 'knife', 'rais', 'watson', 'react', 'instinct', 'fire', 'revolv', 'bullet', 'hit', 'creatur', 'chest', 'fell', 'ground', 'thud', 'watson', 'mind', 'race', 'thing', 'come', 'rememb', 'stori', 'heard', 'sherlock', 'holm', 'uncanni', 'abil', 'solv', 'bizarr', 'case', 'rush', 'phone', 'call', 'holm', 'within', 'minut', 'detect', 'way', 'holm', 'arriv', 'took', 'one', 'look', 'creatur', 'announc', 'yeti', 'mythic', 'creatur', 'himalaya', 'watson', 'dumbfound', 'could', 'holm', 'possibl', 'know', 'turn', 'yeti', 'part', 'circu', 'recent', 'come', 'town', 'circu', 'owner', 'keep', 'yeti', 'cage', 'feed', 'raw', 'meat', 'yeti', 'escap', 'terror', 'citi', 'holm', 'deduc', 'creatur', 'fur', 'mat', 'blood', 'knife', 'type', 'use', 'circu', 'perform', 'sherlock', 'holm', 'dr', 'watson', 'sit', 'usual', 'chair', 'sit', 'room', 'b', 'baker', 'street', 'suddenli', 'interrupt', 'loud', 'pierc', 'scream', 'two', 'men', 'leapt', 'feet', 'ran', 'window', 'time', 'see', 'man', 'fall', 'build', 'opposit', 'quick', 'watson', 'must', 'go', 'investig', 'cri', 'sherlock', 'holm', 'two', 'men', 'hurri', 'stair', 'street', 'found', 'crowd', 'peopl', 'gather', 'around', 'bodi', 'man', 'fallen', 'happen', 'ask', 'sherlock', 'holm', 'push', 'cri', 'woman', 'crowd', 'saw', 'eye', 'push', 'would', 'anyon', 'want', 'push', 'ask', 'watson', 'know', 'murder', 'tell', 'sherlock', 'holm', 'watson', 'push', 'way', 'crowd', 'squat', 'besid', 'bodi', 'holm', 'examin', 'close', 'watson', 'look', 'around', 'see', 'could', 'spot', 'murder', 'quit', 'clear', 'happen', 'said', 'holm', 'minut', 'victim', 'push', 'window', 'build', 'ask', 'watson', 'murder', 'must', 'build', 'come', 'watson', 'must', 'go', 'investig', 'two', 'men', 'hurri', 'across', 'street', 'enter', 'build', 'made', 'way', 'floor', 'victim', 'fallen', 'began', 'knock', 'door', 'final', 'came', 'door', 'answer', 'old', 'woman', 'want', 'ask', 'investig', 'murder', 'man', 'push', 'window', 'said', 'holm', 'oh', 'easi', 'enough', 'solv', 'said', 'woman', 'murder', 'husband', 'husband', 'ask', 'watson', 'disbelief', 'ye', 'husband', 'alway', 'want', 'push', 'someon', 'window', 'saw', 'man', 'stand', 'resist', 'ask', 'sherlock', 'holm', 'oh', 'alway', 'funni', 'man', 'ever', 'sinc', 'known', 'sherlock', 'holm', 'watson', 'exchang', 'look', 'holm', 'said', 'thank', 'help', 'way', 'say', 'john', 'make', 'sherlock', 'holm', 'look', 'express', 'mild', 'amus', 'wit', 'amus', 'incid', 'knew', 'better', 'ask', 'talk', 'simpli', 'wait', 'continu', 'read', 'paper', 'articl', 'man', 'arrest', 'tri', 'steal', 'chicken', 'farmer', 'market', 'amus', 'part', 'man', 'name', 'john', 'watson', 'must', 'look', 'startl', 'holm', 'began', 'laugh', 'ye', 'see', 'might', 'find', 'amus', 'said', 'sure', 'find', 'situat', 'humor', 'well', 'first', 'time', 'someon', 'made', 'mistak', 'think', 'involv', 'crime', 'john', 'help', 'chuckl', 'true', 'victim', 'misunderstand', 'year', 'thank', 'associ', 'sherlock', 'holm', 'peopl', 'often', 'assum', 'holm', 'investig', 'case', 'must', 'involv', 'way', 'cours', 'polic', 'quickli', 'realiz', 'wrong', 'man', 'releas', 'holm', 'continu', 'sure', 'poor', 'fellow', 'quit', 'embarrass', 'sure', 'said', 'still', 'chuckl', 'anoth', 'day', 'life', 'sherlock', 'holm', 'john', 'watson', 'day', 'fill', 'excit', 'adventur', 'occasion', 'bit', 'humour', 'tell', 'john', 'baffl', 'case', 'ever', 'encount', 'realli', 'sherlock', 'baffl', 'well', 'start', 'fact', 'victim', 'stab', 'umbrella', 'umbrella', 'sure', 'unusu', 'victim', 'cat', 'john', 'cat', 'good', 'heaven', 'sherlock', 'get', 'bizarr', 'minut', 'know', 'know', 'cat', 'also', 'wear', 'top', 'hat', 'monocl', 'top', 'hat', 'monocl', 'rather', 'unusu', 'inde', 'baffl', 'thing', 'fact', 'cat', 'found', 'room', 'lock', 'insid', 'lock', 'insid', 'possibl', 'idea', 'john', 'intend', 'find', 'case', 'certainli', 'worthi', 'attent', 'sherlock', 'holm', 'dr', 'watson', 'sit', 'usual', 'spot', 'sit', 'room', 'b', 'baker', 'street', 'knock', 'door', 'got', 'answer', 'young', 'boy', 'stand', 'hold', 'note', 'ask', 'deliv', 'sir', 'boy', 'said', 'hand', 'note', 'sherlock', 'sherlock', 'holm', 'took', 'note', 'read', 'brother', 'mycroft', 'said', 'want', 'come', 'diogen', 'club', 'diogen', 'club', 'watson', 'ask', 'club', 'brother', 'friend', 'sherlock', 'explain', 'exclus', 'allow', 'women', 'children', 'sound', 'stuffi', 'watson', 'said', 'sherlock', 'agre', 'mycroft', 'say', 'import', 'suppos', 'go', 'grab', 'coat', 'head', 'got', 'diogen', 'club', 'met', 'man', 'escort', 'insid', 'club', 'everyth', 'sherlock', 'said', 'would', 'stuffi', 'women', 'children', 'mycroft', 'sit', 'chair', 'talk', 'coupl', 'men', 'saw', 'sherlock', 'watson', 'gestur', 'join', 'ah', 'sherlock', 'good', 'see', 'said', 'need', 'help', 'someth', 'sherlock', 'ask', 'murder', 'mycroft', 'said', 'one', 'club', 'member', 'found', 'dead', 'room', 'sherlock', 'ask', 'sir', 'wilfr', 'baskervil', 'mycroft', 'said', 'man', 'own', 'baskervil', 'estat', 'watson', 'ask', 'mycroft', 'said', 'polic', 'baffl', 'hope', 'could', 'take', 'look', 'see', 'sherlock', 'said', 'went', 'sir', 'wilfr', 'room', 'sherlock', 'began', 'examin', 'bodi', 'quickli', 'deduc', 'man', 'poison', 'killer', 'must', 'put', 'poison', 'drink', 'said', 'sign', 'struggl', 'man', 'must', 'unawar', 'happen', 'would', 'want', 'kill', 'watson', 'ask', 'need', 'find', 'sherlock', 'said', 'began', 'question', 'club', 'member', 'one', 'seem', 'know', 'anyth', 'give', 'saw', 'man', 'walk', 'funni', 'look', 'hors', 'odd', 'said', 'never', 'seen', 'hors', 'like', 'follow', 'man', 'watch', 'went', 'room', 'anoth', 'club', 'member', 'sherlock', 'wait', 'minut', 'went', 'room', 'thought', 'might', 'find', 'said', 'killer', 'man', 'tri', 'deni', 'sherlock', 'evid', 'guilti', 'one', 'seen', 'talk', 'sir', 'wilfr', 'earlier', 'even', 'seen', 'walk', 'funni', 'look', 'hors', 'sherlock', 'ask', 'could', 'possibl', 'motiv', 'hors', 'man', 'said', 'alway', 'make', 'fun', 'hors', 'call', 'name', 'take', 'anymor', 'killer', 'motiv', 'funni', 'look', 'hors', 'john', 'watson', 'sit', 'studi', 'perus', 'latest', 'edit', 'strand', 'magazin', 'heard', 'light', 'knock', 'door', 'put', 'magazin', 'got', 'answer', 'find', 'sherlock', 'holm', 'stand', 'threshold', 'clutch', 'piec', 'paper', 'hand', 'watson', 'come', 'quick', 'said', 'holm', 'eye', 'gleam', 'excit', 'receiv', 'curiou', 'letter', 'need', 'help', 'solv', 'mysteri', 'watson', 'follow', 'holm', 'back', 'flat', 'letter', 'laid', 'tabl', 'written', 'spideri', 'hand', 'consist', 'noth', 'seri', 'number', 'make', 'watson', 'holm', 'ask', 'eye', 'narrow', 'concentr', 'watson', 'shook', 'head', 'bemus', 'afraid', 'see', 'anyth', 'holm', 'come', 'come', 'watson', 'use', 'famou', 'deduct', 'brain', 'moment', 'thought', 'watson', 'idea', 'perhap', 'code', 'sort', 'excel', 'watson', 'alway', 'cri', 'holm', 'crack', 'code', 'sat', 'tabl', 'began', 'scribbl', 'piec', 'paper', 'mutter', 'work', 'watson', 'watch', 'minut', 'feel', 'rather', 'superflu', 'pick', 'magazin', 'began', 'leaf', 'suddenli', 'holm', 'leapt', 'tabl', 'cri', 'triumph', 'got', 'watson']"
298,327,327,seraschka,vs1wox,"[P] No, we don't have to choose batch sizes as powers of 2","Prompted by a recent discussion on social media, I did some benchmarks and wrote down my thoughts on why it doesn't really make a difference whether we choose batch sizes as powers of 2: [https://sebastianraschka.com/blog/2022/batch-size-2.html](https://sebastianraschka.com/blog/2022/batch-size-2.html)

What is your experience, do you

do you stick to batch sizes as powers of 2 or do you choose batch sizes more freely?

notice a substantial difference when you choose batch sizes as powers of 2 (or multiples of 8)?",93,223,2022-07-05 19:29:16, p  no  we don t have to choose batch sizes as powers of ,prompted by a recent discussion on social media  i did some benchmarks and wrote down my thoughts on why it doesn t really make a difference whether we choose batch sizes as powers of    https what is your experience  do youdo you stick to batch sizes as powers of  or do you choose batch sizes more freely notice a substantial difference when you choose batch sizes as powers of   or multiples of   ,prompted recent discussion social media benchmarks wrote thoughts really make difference whether choose batch sizes powers https experience youdo stick batch sizes powers choose batch sizes freely notice substantial difference choose batch sizes powers multiples,p choose batch sizes powers,p choose batch sizes powersprompted recent discussion social media benchmarks wrote thoughts really make difference whether choose batch sizes powers https experience youdo stick batch sizes powers choose batch sizes freely notice substantial difference choose batch sizes powers multiples,"['p', 'choose', 'batch', 'sizes', 'powersprompted', 'recent', 'discussion', 'social', 'media', 'benchmarks', 'wrote', 'thoughts', 'really', 'make', 'difference', 'whether', 'choose', 'batch', 'sizes', 'powers', 'https', 'experience', 'youdo', 'stick', 'batch', 'sizes', 'powers', 'choose', 'batch', 'sizes', 'freely', 'notice', 'substantial', 'difference', 'choose', 'batch', 'sizes', 'powers', 'multiples']","['p', 'choos', 'batch', 'size', 'powersprompt', 'recent', 'discuss', 'social', 'media', 'benchmark', 'wrote', 'thought', 'realli', 'make', 'differ', 'whether', 'choos', 'batch', 'size', 'power', 'http', 'experi', 'youdo', 'stick', 'batch', 'size', 'power', 'choos', 'batch', 'size', 'freeli', 'notic', 'substanti', 'differ', 'choos', 'batch', 'size', 'power', 'multipl']"
299,328,328,MLJungle,vt10ec,[D] Handling OOV in sequence generation,"What are some methods to handle OOV words when generating sequences? 

For example for some n-gram implementations, I've seen all <UNK> tokens removed from the candidate list of words to be sampled from given the prior n-gram, and if there are no other candidates the generated text is ended.

Curious to learn about some other methods to deal with OOV.",2,1,2022-07-07 00:24:49, d  handling oov in sequence generation,what are some methods to handle oov words when generating sequences  for example for some n gram implementations  i ve seen all  tokens removed from the candidate list of words to be sampled from given the prior n gram  and if there are no other candidates the generated text is ended curious to learn about some other methods to deal with oov ,methods handle oov generating sequences example n gram implementations seen tokens removed candidate sampled given prior n gram candidates generated text ended curious learn methods deal oov,handling oov sequence generation,handling oov sequence generationmethods handle oov generating sequences example n gram implementations seen tokens removed candidate sampled given prior n gram candidates generated text ended curious learn methods deal oov,"['handling', 'oov', 'sequence', 'generationmethods', 'handle', 'oov', 'generating', 'sequences', 'example', 'n', 'gram', 'implementations', 'seen', 'tokens', 'removed', 'candidate', 'sampled', 'given', 'prior', 'n', 'gram', 'candidates', 'generated', 'text', 'ended', 'curious', 'learn', 'methods', 'deal', 'oov']","['handl', 'oov', 'sequenc', 'generationmethod', 'handl', 'oov', 'gener', 'sequenc', 'exampl', 'n', 'gram', 'implement', 'seen', 'token', 'remov', 'candid', 'sampl', 'given', 'prior', 'n', 'gram', 'candid', 'gener', 'text', 'end', 'curiou', 'learn', 'method', 'deal', 'oov']"
300,329,329,lklimusheuskaja,vspgsa,[R] How Machine Learning is Used in Finance and Banking,"Machine learning solutions are already embedded in the finance and banking industry. In this article, we reviewed the most popular use cases of ML in banking and shared practical tips on how to implement it into your business.[https://exadel.com/news/how-machine-learning-is-used-in-finance-and-banking](https://exadel.com/news/how-machine-learning-is-used-in-finance-and-banking)",5,3,2022-07-06 15:59:57, r  how machine learning is used in finance and banking,machine learning solutions are already embedded in the finance and banking industry  in this article  we reviewed the most popular use cases of ml in banking and shared practical tips on how to implement it into your business  https   exadel com news how machine learning is used in finance and banking  https   exadel com news how machine learning is used in finance and banking ,machine learning solutions already embedded finance banking industry article reviewed popular use cases ml banking shared practical tips implement business https exadel com news machine learning used finance banking https exadel com news machine learning used finance banking,r machine learning used finance banking,r machine learning used finance bankingmachine learning solutions already embedded finance banking industry article reviewed popular use cases ml banking shared practical tips implement business https exadel com news machine learning used finance banking https exadel com news machine learning used finance banking,"['r', 'machine', 'learning', 'used', 'finance', 'bankingmachine', 'learning', 'solutions', 'already', 'embedded', 'finance', 'banking', 'industry', 'article', 'reviewed', 'popular', 'use', 'cases', 'ml', 'banking', 'shared', 'practical', 'tips', 'implement', 'business', 'https', 'exadel', 'com', 'news', 'machine', 'learning', 'used', 'finance', 'banking', 'https', 'exadel', 'com', 'news', 'machine', 'learning', 'used', 'finance', 'banking']","['r', 'machin', 'learn', 'use', 'financ', 'bankingmachin', 'learn', 'solut', 'alreadi', 'embed', 'financ', 'bank', 'industri', 'articl', 'review', 'popular', 'use', 'case', 'ml', 'bank', 'share', 'practic', 'tip', 'implement', 'busi', 'http', 'exadel', 'com', 'news', 'machin', 'learn', 'use', 'financ', 'bank', 'http', 'exadel', 'com', 'news', 'machin', 'learn', 'use', 'financ', 'bank']"
301,330,330,SeucheAchat9115,vsv3wc,[D] How to correctly transform Cityscapes Masks to Bounding Boxes?,"As the title suggests, I would like to know the correct way to pre-process the cityscapes dataset for object detection. There are multiple ways how this can be done. There is a version in Detectron2, in MM Detection, there is [this](https://tillbeemelmanns.github.io/2020/10/10/convert-cityscapes-to-coco-dataset-format.html). Which one is the correct way, without getting errors in the labels? Anybody worked with this before? Would be glad if anybody might have an idea.",2,0,2022-07-06 20:13:18, d  how to correctly transform cityscapes masks to bounding boxes ,as the title suggests  i would like to know the correct way to pre process the cityscapes dataset for object detection  there are multiple ways how this can be done  there is a version in detectron  in mm detection  there is  this  https   tillbeemelmanns github io    convert cityscapes to coco dataset format html   which one is the correct way  without getting errors in the labels  anybody worked with this before  would be glad if anybody might have an idea ,title suggests would like know correct way pre process cityscapes dataset object detection multiple ways done version detectron mm detection https tillbeemelmanns github io convert cityscapes coco dataset format html one correct way without getting errors labels anybody worked would glad anybody might idea,correctly transform cityscapes masks bounding boxes,correctly transform cityscapes masks bounding boxestitle suggests would like know correct way pre process cityscapes dataset object detection multiple ways done version detectron mm detection https tillbeemelmanns github io convert cityscapes coco dataset format html one correct way without getting errors labels anybody worked would glad anybody might idea,"['correctly', 'transform', 'cityscapes', 'masks', 'bounding', 'boxestitle', 'suggests', 'would', 'like', 'know', 'correct', 'way', 'pre', 'process', 'cityscapes', 'dataset', 'object', 'detection', 'multiple', 'ways', 'done', 'version', 'detectron', 'mm', 'detection', 'https', 'tillbeemelmanns', 'github', 'io', 'convert', 'cityscapes', 'coco', 'dataset', 'format', 'html', 'one', 'correct', 'way', 'without', 'getting', 'errors', 'labels', 'anybody', 'worked', 'would', 'glad', 'anybody', 'might', 'idea']","['correctli', 'transform', 'cityscap', 'mask', 'bound', 'boxestitl', 'suggest', 'would', 'like', 'know', 'correct', 'way', 'pre', 'process', 'cityscap', 'dataset', 'object', 'detect', 'multipl', 'way', 'done', 'version', 'detectron', 'mm', 'detect', 'http', 'tillbeemelmann', 'github', 'io', 'convert', 'cityscap', 'coco', 'dataset', 'format', 'html', 'one', 'correct', 'way', 'without', 'get', 'error', 'label', 'anybodi', 'work', 'would', 'glad', 'anybodi', 'might', 'idea']"
302,331,331,htahir1,vsufhh,[P] Tutorial: Serverless MLOps pipelines with Vertex AI and ZenML,"At ZenML, we created a guide to easily run MLOps pipelines on Google Cloud Platform with Vertex AI. I thought I'd share it here because I think it might be useful for people who are just starting MLOps on GCP.

**Blog post**: [https://blog.zenml.io/vertex-ai-blog/](https://blog.zenml.io/vertex-ai-blog/) 

**Full video**:  [https://youtu.be/qgvmvexGv\_c](https://youtu.be/qgvmvexGv_c) 

  
Why is this better than going through the Vertex AI SDK?

* ZenML steps and pipeline can be written with a simple decorator pattern that is easily approachable for a [\#datascientist](https://www.linkedin.com/feed/hashtag/?keywords=datascientist&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6950398009234894848).
* ZenML takes cares of storing and versioning pythonic objects between steps of a 
* ZenML provides first-class integrations into other MLOps tools that you can leverage natively in your pipelines. For example, you can track experiments on MLFlow easily.
* ZenML pipelines can be run locally first, and then deployed instantly.
* You can run a ZenML pipeline not only on Vertex, but also [\#Airflow](https://www.linkedin.com/feed/hashtag/?keywords=airflow&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6950398009234894848), [\#Kubeflow](https://www.linkedin.com/feed/hashtag/?keywords=kubeflow&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6950398009234894848), [\#Kubernetes](https://www.linkedin.com/feed/hashtag/?keywords=kubernetes&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6950398009234894848), or whereever else you'd like!📷Watch the full video: [https://www.youtube.com/watch?v=qgvmvexGv\_c&ab\_channel=ZenML](https://www.youtube.com/watch?v=qgvmvexGv_c&ab_channel=ZenML)

I bet the GCP Vertex AI folk here might like the above video. It isn't just about ZenML either but more of a broader look into the different components that go into running ML in production on GCP (Container registry, Cloud Storage, Secret Manager, Vertex, Cloud SQL)

Would love to hear more feedback on the video or blog!",0,0,2022-07-06 19:44:22, p  tutorial  serverless mlops pipelines with vertex ai and zenml,at zenml  we created a guide to easily run mlops pipelines on google cloud platform with vertex ai  i thought i d share it here because i think it might be useful for people who are just starting mlops on gcp   blog post     https   full video      https   why is this better than going through the vertex ai sdk   zenml steps and pipeline can be written with a simple decorator pattern that is easily approachable for a    datascientist  https   zenml takes cares of storing and versioning pythonic objects between steps of a   zenml provides first class integrations into other mlops tools that you can leverage natively in your pipelines  for example  you can track experiments on mlflow easily   zenml pipelines can be run locally first  and then deployed instantly   you can run a zenml pipeline not only on vertex  but also    airflow  https i bet the gcp vertex ai folk here might like the above video  it isn t just about zenml either but more of a broader look into the different components that go into running ml in production on gcp  container registry  cloud storage  secret manager  vertex  cloud sql would love to hear more feedback on the video or blog ,zenml created guide easily run mlops pipelines google cloud platform vertex ai thought share think might useful people starting mlops gcp blog post https full video https better going vertex ai sdk zenml steps pipeline written simple decorator pattern easily approachable datascientist https zenml takes cares storing versioning pythonic objects steps zenml provides first class integrations mlops tools leverage natively pipelines example track experiments mlflow easily zenml pipelines run locally first deployed instantly run zenml pipeline vertex also airflow https bet gcp vertex ai folk might like video zenml either broader look different components go running ml production gcp container registry cloud storage secret manager vertex cloud sql would love hear feedback video blog,p tutorial serverless mlops pipelines vertex ai zenml,p tutorial serverless mlops pipelines vertex ai zenmlzenml created guide easily run mlops pipelines google cloud platform vertex ai thought share think might useful people starting mlops gcp blog post https full video https better going vertex ai sdk zenml steps pipeline written simple decorator pattern easily approachable datascientist https zenml takes cares storing versioning pythonic objects steps zenml provides first class integrations mlops tools leverage natively pipelines example track experiments mlflow easily zenml pipelines run locally first deployed instantly run zenml pipeline vertex also airflow https bet gcp vertex ai folk might like video zenml either broader look different components go running ml production gcp container registry cloud storage secret manager vertex cloud sql would love hear feedback video blog,"['p', 'tutorial', 'serverless', 'mlops', 'pipelines', 'vertex', 'ai', 'zenmlzenml', 'created', 'guide', 'easily', 'run', 'mlops', 'pipelines', 'google', 'cloud', 'platform', 'vertex', 'ai', 'thought', 'share', 'think', 'might', 'useful', 'people', 'starting', 'mlops', 'gcp', 'blog', 'post', 'https', 'full', 'video', 'https', 'better', 'going', 'vertex', 'ai', 'sdk', 'zenml', 'steps', 'pipeline', 'written', 'simple', 'decorator', 'pattern', 'easily', 'approachable', 'datascientist', 'https', 'zenml', 'takes', 'cares', 'storing', 'versioning', 'pythonic', 'objects', 'steps', 'zenml', 'provides', 'first', 'class', 'integrations', 'mlops', 'tools', 'leverage', 'natively', 'pipelines', 'example', 'track', 'experiments', 'mlflow', 'easily', 'zenml', 'pipelines', 'run', 'locally', 'first', 'deployed', 'instantly', 'run', 'zenml', 'pipeline', 'vertex', 'also', 'airflow', 'https', 'bet', 'gcp', 'vertex', 'ai', 'folk', 'might', 'like', 'video', 'zenml', 'either', 'broader', 'look', 'different', 'components', 'go', 'running', 'ml', 'production', 'gcp', 'container', 'registry', 'cloud', 'storage', 'secret', 'manager', 'vertex', 'cloud', 'sql', 'would', 'love', 'hear', 'feedback', 'video', 'blog']","['p', 'tutori', 'serverless', 'mlop', 'pipelin', 'vertex', 'ai', 'zenmlzenml', 'creat', 'guid', 'easili', 'run', 'mlop', 'pipelin', 'googl', 'cloud', 'platform', 'vertex', 'ai', 'thought', 'share', 'think', 'might', 'use', 'peopl', 'start', 'mlop', 'gcp', 'blog', 'post', 'http', 'full', 'video', 'http', 'better', 'go', 'vertex', 'ai', 'sdk', 'zenml', 'step', 'pipelin', 'written', 'simpl', 'decor', 'pattern', 'easili', 'approach', 'datascientist', 'http', 'zenml', 'take', 'care', 'store', 'version', 'python', 'object', 'step', 'zenml', 'provid', 'first', 'class', 'integr', 'mlop', 'tool', 'leverag', 'nativ', 'pipelin', 'exampl', 'track', 'experi', 'mlflow', 'easili', 'zenml', 'pipelin', 'run', 'local', 'first', 'deploy', 'instantli', 'run', 'zenml', 'pipelin', 'vertex', 'also', 'airflow', 'http', 'bet', 'gcp', 'vertex', 'ai', 'folk', 'might', 'like', 'video', 'zenml', 'either', 'broader', 'look', 'differ', 'compon', 'go', 'run', 'ml', 'product', 'gcp', 'contain', 'registri', 'cloud', 'storag', 'secret', 'manag', 'vertex', 'cloud', 'sql', 'would', 'love', 'hear', 'feedback', 'video', 'blog']"
303,332,332,EUMETSAT,vsovth,Jupyter Notebook Competition coming up! [News],"The Jupyter Notebook Competition deadline is fast approaching!

https://preview.redd.it/gy6m0myhyx991.png?width=1920&format=png&auto=webp&s=3039abe962df07df74740772994f17502fa686bb

Don't miss out on your chance to contribute to a community-driven resource of notebooks on the Copernicus WEkEO platform, AND be in with a chance of winning cash prizes! 

Visit: [https://www.eumetsat.int/features/new-jupyter-notebook-competition](https://www.eumetsat.int/features/new-jupyter-notebook-competition)",0,2,2022-07-06 15:29:18,jupyter notebook competition coming up   news ,the jupyter notebook competition deadline is fast approaching https don t miss out on your chance to contribute to a community driven resource of notebooks on the copernicus wekeo platform  and be in with a chance of winning cash prizes  visit   https   www eumetsat int features new jupyter notebook competition  https   www eumetsat int features new jupyter notebook competition ,jupyter notebook competition deadline fast approaching https miss chance contribute community driven resource notebooks copernicus wekeo platform chance winning cash prizes visit https www eumetsat int features jupyter notebook competition https www eumetsat int features jupyter notebook competition,jupyter notebook competition coming news,jupyter notebook competition coming newsjupyter notebook competition deadline fast approaching https miss chance contribute community driven resource notebooks copernicus wekeo platform chance winning cash prizes visit https www eumetsat int features jupyter notebook competition https www eumetsat int features jupyter notebook competition,"['jupyter', 'notebook', 'competition', 'coming', 'newsjupyter', 'notebook', 'competition', 'deadline', 'fast', 'approaching', 'https', 'miss', 'chance', 'contribute', 'community', 'driven', 'resource', 'notebooks', 'copernicus', 'wekeo', 'platform', 'chance', 'winning', 'cash', 'prizes', 'visit', 'https', 'www', 'eumetsat', 'int', 'features', 'jupyter', 'notebook', 'competition', 'https', 'www', 'eumetsat', 'int', 'features', 'jupyter', 'notebook', 'competition']","['jupyt', 'notebook', 'competit', 'come', 'newsjupyt', 'notebook', 'competit', 'deadlin', 'fast', 'approach', 'http', 'miss', 'chanc', 'contribut', 'commun', 'driven', 'resourc', 'notebook', 'copernicu', 'wekeo', 'platform', 'chanc', 'win', 'cash', 'prize', 'visit', 'http', 'www', 'eumetsat', 'int', 'featur', 'jupyt', 'notebook', 'competit', 'http', 'www', 'eumetsat', 'int', 'featur', 'jupyt', 'notebook', 'competit']"
304,333,333,1_like_science,vsb2zt,[R] Automated Taxonomic Identification of Insects with Expert-Level Accuracy Using Effective Feature Transfer from Convolutional Networks,"An interesting article in the Systematic Biology journal about identifying insects: https://academic.oup.com/sysbio/article/68/6/876/5368535

See as well: [Deep learning and computer vision will transform entomology](https://www.pnas.org/doi/10.1073/pnas.2002545117)",0,15,2022-07-06 02:13:19, r  automated taxonomic identification of insects with expert level accuracy using effective feature transfer from convolutional networks,an interesting article in the systematic biology journal about identifying insects  https see as well   deep learning and computer vision will transform entomology  https   www pnas org doi   pnas  ,interesting article systematic biology journal identifying insects https see well deep learning computer vision transform entomology https www pnas org doi pnas,r automated taxonomic identification insects expert level accuracy using effective feature transfer convolutional networks,r automated taxonomic identification insects expert level accuracy using effective feature transfer convolutional networksinteresting article systematic biology journal identifying insects https see well deep learning computer vision transform entomology https www pnas org doi pnas,"['r', 'automated', 'taxonomic', 'identification', 'insects', 'expert', 'level', 'accuracy', 'using', 'effective', 'feature', 'transfer', 'convolutional', 'networksinteresting', 'article', 'systematic', 'biology', 'journal', 'identifying', 'insects', 'https', 'see', 'well', 'deep', 'learning', 'computer', 'vision', 'transform', 'entomology', 'https', 'www', 'pnas', 'org', 'doi', 'pnas']","['r', 'autom', 'taxonom', 'identif', 'insect', 'expert', 'level', 'accuraci', 'use', 'effect', 'featur', 'transfer', 'convolut', 'networksinterest', 'articl', 'systemat', 'biolog', 'journal', 'identifi', 'insect', 'http', 'see', 'well', 'deep', 'learn', 'comput', 'vision', 'transform', 'entomolog', 'http', 'www', 'pna', 'org', 'doi', 'pna']"
305,334,334,DoruSonic,vruyyi,[P] Using transformers for time-series forecasting,"I'm currently using different machine learning techniques on a time series and testing their forecast performance. This dataset has both an independent variable and exploratory variables.

I've used LSTM on python to forecast and was searching for more recent techniques and found transformers. They seem to have been developed for NLP but have been used for time-series forecasts

How well do these transformers perform and is there any resources / library I should look into?

EDIT: the data I'll be using is of daily periodicity without weekends. It will have 2+ years of observations (currently working with 3 years and some other datasets have longer periods but ""worse"" information)",34,103,2022-07-05 13:44:06, p  using transformers for time series forecasting,i m currently using different machine learning techniques on a time series and testing their forecast performance  this dataset has both an independent variable and exploratory variables i ve used lstm on python to forecast and was searching for more recent techniques and found transformers  they seem to have been developed for nlp but have been used for time series forecastshow well do these transformers perform and is there any resources   library i should look into edit  the data i ll be using is of daily periodicity without weekends  it will have   years of observations  currently working with  years and some other datasets have longer periods but worse information ,currently using different machine learning techniques time series testing forecast performance dataset independent variable exploratory variables used lstm python forecast searching recent techniques found transformers seem developed nlp used time series forecastshow well transformers perform resources library look edit data using daily periodicity without weekends years observations currently working years datasets longer periods worse information,p using transformers time series forecasting,p using transformers time series forecastingcurrently using different machine learning techniques time series testing forecast performance dataset independent variable exploratory variables used lstm python forecast searching recent techniques found transformers seem developed nlp used time series forecastshow well transformers perform resources library look edit data using daily periodicity without weekends years observations currently working years datasets longer periods worse information,"['p', 'using', 'transformers', 'time', 'series', 'forecastingcurrently', 'using', 'different', 'machine', 'learning', 'techniques', 'time', 'series', 'testing', 'forecast', 'performance', 'dataset', 'independent', 'variable', 'exploratory', 'variables', 'used', 'lstm', 'python', 'forecast', 'searching', 'recent', 'techniques', 'found', 'transformers', 'seem', 'developed', 'nlp', 'used', 'time', 'series', 'forecastshow', 'well', 'transformers', 'perform', 'resources', 'library', 'look', 'edit', 'data', 'using', 'daily', 'periodicity', 'without', 'weekends', 'years', 'observations', 'currently', 'working', 'years', 'datasets', 'longer', 'periods', 'worse', 'information']","['p', 'use', 'transform', 'time', 'seri', 'forecastingcurr', 'use', 'differ', 'machin', 'learn', 'techniqu', 'time', 'seri', 'test', 'forecast', 'perform', 'dataset', 'independ', 'variabl', 'exploratori', 'variabl', 'use', 'lstm', 'python', 'forecast', 'search', 'recent', 'techniqu', 'found', 'transform', 'seem', 'develop', 'nlp', 'use', 'time', 'seri', 'forecastshow', 'well', 'transform', 'perform', 'resourc', 'librari', 'look', 'edit', 'data', 'use', 'daili', 'period', 'without', 'weekend', 'year', 'observ', 'current', 'work', 'year', 'dataset', 'longer', 'period', 'wors', 'inform']"
306,335,335,scb_11,vsk01s,[P] Comparing DevOps into MLOps to analyse tools doing well in the market,"Hi all, 

I've been an active practitioner in Deep Learning and then wanted to build something in MLOps. 

So wanted to dig deeper in how DevOps evolved and wanted to check if MLOps can take the same path.

The findings are really great. Absolutely every tool doing well in the market is a clear replacement for DevOps tool in MLOps. 

Here is my blog on it. Looking for feedback. If you have any comments, let me know. Will add them.

[https://sachinchandra.substack.com/p/bringing-software-development-principles](https://sachinchandra.substack.com/p/bringing-software-development-principles)",2,0,2022-07-06 10:16:21, p  comparing devops into mlops to analyse tools doing well in the market,hi all  i ve been an active practitioner in deep learning and then wanted to build something in mlops  so wanted to dig deeper in how devops evolved and wanted to check if mlops can take the same path the findings are really great  absolutely every tool doing well in the market is a clear replacement for devops tool in mlops  here is my blog on it  looking for feedback  if you have any comments  let me know  will add them  https   sachinchandra substack com p bringing software development principles  https   sachinchandra substack com p bringing software development principles ,hi active practitioner deep learning wanted build something mlops wanted dig deeper devops evolved wanted check mlops take path findings really great absolutely every tool well market clear replacement devops tool mlops blog looking feedback comments let know https sachinchandra substack com p bringing software development principles https sachinchandra substack com p bringing software development principles,p comparing devops mlops analyse tools well market,p comparing devops mlops analyse tools well markethi active practitioner deep learning wanted build something mlops wanted dig deeper devops evolved wanted check mlops take path findings really great absolutely every tool well market clear replacement devops tool mlops blog looking feedback comments let know https sachinchandra substack com p bringing software development principles https sachinchandra substack com p bringing software development principles,"['p', 'comparing', 'devops', 'mlops', 'analyse', 'tools', 'well', 'markethi', 'active', 'practitioner', 'deep', 'learning', 'wanted', 'build', 'something', 'mlops', 'wanted', 'dig', 'deeper', 'devops', 'evolved', 'wanted', 'check', 'mlops', 'take', 'path', 'findings', 'really', 'great', 'absolutely', 'every', 'tool', 'well', 'market', 'clear', 'replacement', 'devops', 'tool', 'mlops', 'blog', 'looking', 'feedback', 'comments', 'let', 'know', 'https', 'sachinchandra', 'substack', 'com', 'p', 'bringing', 'software', 'development', 'principles', 'https', 'sachinchandra', 'substack', 'com', 'p', 'bringing', 'software', 'development', 'principles']","['p', 'compar', 'devop', 'mlop', 'analys', 'tool', 'well', 'markethi', 'activ', 'practition', 'deep', 'learn', 'want', 'build', 'someth', 'mlop', 'want', 'dig', 'deeper', 'devop', 'evolv', 'want', 'check', 'mlop', 'take', 'path', 'find', 'realli', 'great', 'absolut', 'everi', 'tool', 'well', 'market', 'clear', 'replac', 'devop', 'tool', 'mlop', 'blog', 'look', 'feedback', 'comment', 'let', 'know', 'http', 'sachinchandra', 'substack', 'com', 'p', 'bring', 'softwar', 'develop', 'principl', 'http', 'sachinchandra', 'substack', 'com', 'p', 'bring', 'softwar', 'develop', 'principl']"
307,336,336,TrPhantom8,vrxpk8,[P] Concrete dropout implementation for tensorflow 2.0,"Hello everyone! I updated the concrete dropout implementation from the original authors to work with tensorflow 2.0, tweaked the code a bit and turned it into a pip package! If you are interested, you can find it at pypi by sarching ""concretedropout"". There is also a link in the comments.

For those of you who don't know what concrete dropout is, it's a technique which allows for the training of the dropout probability in a layer, which may save a lot of time since it removes the need to grid search for the best dropout parameters.

For more information, see the original paper:  arXiv:1705.07832",5,28,2022-07-05 16:20:04, p  concrete dropout implementation for tensorflow  ,hello everyone  i updated the concrete dropout implementation from the original authors to work with tensorflow    tweaked the code a bit and turned it into a pip package  if you are interested  you can find it at pypi by sarching concretedropout  there is also a link in the comments for those of you who don t know what concrete dropout is  it s a technique which allows for the training of the dropout probability in a layer  which may save a lot of time since it removes the need to grid search for the best dropout parameters for more information  see the original paper   arxiv  ,hello everyone updated concrete dropout implementation original authors work tensorflow tweaked code bit turned pip package interested find pypi sarching concretedropout also link comments know concrete dropout technique allows training dropout probability layer may save lot time since removes need grid search best dropout parameters information see original paper arxiv,p concrete dropout implementation tensorflow,p concrete dropout implementation tensorflowhello everyone updated concrete dropout implementation original authors work tensorflow tweaked code bit turned pip package interested find pypi sarching concretedropout also link comments know concrete dropout technique allows training dropout probability layer may save lot time since removes need grid search best dropout parameters information see original paper arxiv,"['p', 'concrete', 'dropout', 'implementation', 'tensorflowhello', 'everyone', 'updated', 'concrete', 'dropout', 'implementation', 'original', 'authors', 'work', 'tensorflow', 'tweaked', 'code', 'bit', 'turned', 'pip', 'package', 'interested', 'find', 'pypi', 'sarching', 'concretedropout', 'also', 'link', 'comments', 'know', 'concrete', 'dropout', 'technique', 'allows', 'training', 'dropout', 'probability', 'layer', 'may', 'save', 'lot', 'time', 'since', 'removes', 'need', 'grid', 'search', 'best', 'dropout', 'parameters', 'information', 'see', 'original', 'paper', 'arxiv']","['p', 'concret', 'dropout', 'implement', 'tensorflowhello', 'everyon', 'updat', 'concret', 'dropout', 'implement', 'origin', 'author', 'work', 'tensorflow', 'tweak', 'code', 'bit', 'turn', 'pip', 'packag', 'interest', 'find', 'pypi', 'sarch', 'concretedropout', 'also', 'link', 'comment', 'know', 'concret', 'dropout', 'techniqu', 'allow', 'train', 'dropout', 'probabl', 'layer', 'may', 'save', 'lot', 'time', 'sinc', 'remov', 'need', 'grid', 'search', 'best', 'dropout', 'paramet', 'inform', 'see', 'origin', 'paper', 'arxiv']"
308,337,337,mkeySeraSera,vrv57z,[D] Looking for a fast OCR repo,"Currently,  we use google as our OCR service provider, but we've had already some  serious issues with them and their customer support is terrible.  Therefore we would like to change and move away from third-party providers in general.  
By now we have a sufficient amount of data to train our own OCR model, therefore I am looking for a custom fine-tunable model that is fast/accurate.  
I've found PaddleOCR and mmocr, but their inference speed for documents like invoices on CPU is quite slow (10s/page on my computer).  I'm looking for something in the 1s/page range, similar to google's OCR. We probably don't need all the power and language knowledge these libraries provide, as we only operate on documents in mainly 4 Latin languages.

Does anybody know a good starting point?",16,10,2022-07-05 13:56:03, d  looking for a fast ocr repo,currently   we use google as our ocr service provider  but we ve had already some  serious issues with them and their customer support is terrible   therefore we would like to change and move away from third party providers in general   by now we have a sufficient amount of data to train our own ocr model  therefore i am looking for a custom fine tunable model that is fast accurate   i ve found paddleocr and mmocr  but their inference speed for documents like invoices on cpu is quite slow  s page on my computer    i m looking for something in the s page range  similar to google s ocr  we probably don t need all the power and language knowledge these libraries provide  as we only operate on documents in mainly  latin languages does anybody know a good starting point ,currently use google ocr service provider already serious issues customer support terrible therefore would like change move away third party providers general sufficient amount data train ocr model therefore looking fine tunable model fast accurate found paddleocr mmocr inference speed documents like invoices cpu quite slow page computer looking something page range similar google ocr probably need power language knowledge libraries provide operate documents mainly latin languages anybody know good starting point,looking fast ocr repo,looking fast ocr repocurrently use google ocr service provider already serious issues customer support terrible therefore would like change move away third party providers general sufficient amount data train ocr model therefore looking fine tunable model fast accurate found paddleocr mmocr inference speed documents like invoices cpu quite slow page computer looking something page range similar google ocr probably need power language knowledge libraries provide operate documents mainly latin languages anybody know good starting point,"['looking', 'fast', 'ocr', 'repocurrently', 'use', 'google', 'ocr', 'service', 'provider', 'already', 'serious', 'issues', 'customer', 'support', 'terrible', 'therefore', 'would', 'like', 'change', 'move', 'away', 'third', 'party', 'providers', 'general', 'sufficient', 'amount', 'data', 'train', 'ocr', 'model', 'therefore', 'looking', 'fine', 'tunable', 'model', 'fast', 'accurate', 'found', 'paddleocr', 'mmocr', 'inference', 'speed', 'documents', 'like', 'invoices', 'cpu', 'quite', 'slow', 'page', 'computer', 'looking', 'something', 'page', 'range', 'similar', 'google', 'ocr', 'probably', 'need', 'power', 'language', 'knowledge', 'libraries', 'provide', 'operate', 'documents', 'mainly', 'latin', 'languages', 'anybody', 'know', 'good', 'starting', 'point']","['look', 'fast', 'ocr', 'repocurr', 'use', 'googl', 'ocr', 'servic', 'provid', 'alreadi', 'seriou', 'issu', 'custom', 'support', 'terribl', 'therefor', 'would', 'like', 'chang', 'move', 'away', 'third', 'parti', 'provid', 'gener', 'suffici', 'amount', 'data', 'train', 'ocr', 'model', 'therefor', 'look', 'fine', 'tunabl', 'model', 'fast', 'accur', 'found', 'paddleocr', 'mmocr', 'infer', 'speed', 'document', 'like', 'invoic', 'cpu', 'quit', 'slow', 'page', 'comput', 'look', 'someth', 'page', 'rang', 'similar', 'googl', 'ocr', 'probabl', 'need', 'power', 'languag', 'knowledg', 'librari', 'provid', 'oper', 'document', 'mainli', 'latin', 'languag', 'anybodi', 'know', 'good', 'start', 'point']"
309,338,338,projekt_treadstone,vsa2vo,[D] Extracting predicate to apply formal logic rules in autonomous driving dataset or CARLA simulator,"In the formal logic based autonomous driving dataset, we have a set of rules usually written in First order logic or temporal logic . But to apply the rules, we need to extract the predicate from perception system. For example, how to attach the predicate like *standing\_at\_intersection* with the perception scene obtained from AD dataset like Lyft or Argoverse  or CARLA simulator. So that I can apply rules on those specific scenario. I could not find any papers or explanation, which explains how to connect  the predicate in formal logic and match the connecting predicate with the dataset scene interpretation.

Any help is appreciated or links to resource.",0,0,2022-07-06 01:27:03, d  extracting predicate to apply formal logic rules in autonomous driving dataset or carla simulator,in the formal logic based autonomous driving dataset  we have a set of rules usually written in first order logic or temporal logic   but to apply the rules  we need to extract the predicate from perception system  for example  how to attach the predicate like  standing _at _intersection  with the perception scene obtained from ad dataset like lyft or argoverse  or carla simulator  so that i can apply rules on those specific scenario  i could not find any papers or explanation  which explains how to connect  the predicate in formal logic and match the connecting predicate with the dataset scene interpretation any help is appreciated or links to resource ,formal logic based autonomous driving dataset set rules usually written first order logic temporal logic apply rules need extract predicate perception system example attach predicate like standing _at _intersection perception scene obtained ad dataset like lyft argoverse carla simulator apply rules specific scenario could find papers explanation explains connect predicate formal logic match connecting predicate dataset scene interpretation help appreciated links resource,extracting predicate apply formal logic rules autonomous driving dataset carla simulator,extracting predicate apply formal logic rules autonomous driving dataset carla simulatorformal logic based autonomous driving dataset set rules usually written first order logic temporal logic apply rules need extract predicate perception system example attach predicate like standing _at _intersection perception scene obtained ad dataset like lyft argoverse carla simulator apply rules specific scenario could find papers explanation explains connect predicate formal logic match connecting predicate dataset scene interpretation help appreciated links resource,"['extracting', 'predicate', 'apply', 'formal', 'logic', 'rules', 'autonomous', 'driving', 'dataset', 'carla', 'simulatorformal', 'logic', 'based', 'autonomous', 'driving', 'dataset', 'set', 'rules', 'usually', 'written', 'first', 'order', 'logic', 'temporal', 'logic', 'apply', 'rules', 'need', 'extract', 'predicate', 'perception', 'system', 'example', 'attach', 'predicate', 'like', 'standing', '_at', '_intersection', 'perception', 'scene', 'obtained', 'ad', 'dataset', 'like', 'lyft', 'argoverse', 'carla', 'simulator', 'apply', 'rules', 'specific', 'scenario', 'could', 'find', 'papers', 'explanation', 'explains', 'connect', 'predicate', 'formal', 'logic', 'match', 'connecting', 'predicate', 'dataset', 'scene', 'interpretation', 'help', 'appreciated', 'links', 'resource']","['extract', 'predic', 'appli', 'formal', 'logic', 'rule', 'autonom', 'drive', 'dataset', 'carla', 'simulatorform', 'logic', 'base', 'autonom', 'drive', 'dataset', 'set', 'rule', 'usual', 'written', 'first', 'order', 'logic', 'tempor', 'logic', 'appli', 'rule', 'need', 'extract', 'predic', 'percept', 'system', 'exampl', 'attach', 'predic', 'like', 'stand', '_at', '_intersect', 'percept', 'scene', 'obtain', 'ad', 'dataset', 'like', 'lyft', 'argovers', 'carla', 'simul', 'appli', 'rule', 'specif', 'scenario', 'could', 'find', 'paper', 'explan', 'explain', 'connect', 'predic', 'formal', 'logic', 'match', 'connect', 'predic', 'dataset', 'scene', 'interpret', 'help', 'appreci', 'link', 'resourc']"
310,339,339,Travolta1984,vs4la9,[P] Reward function as a way to represent multiple targets,"I've been assigned at work a problem with multiple targets, and I've been thinking about what's the best to design a model that would optimize towards all these targets. An idea that occurred me is to create a reward function that would ""encapsulate"" all these targets in such a way where, the higher the reward, the better the outcome is for all the targets. 

In my case, it's a task distribution system where the workers have the option to decline a task if for whatever reason the task doesn't suit them, and one of my targets is to minimize the number of declines. But we also need to make sure the workload is balanced, and we are not overwhelming someone while under-utilizing the rest of the team; that would be my second target, and we can use the standard deviation as a way to measure the workload balance (the closer to 0 the std is, the better).

Essentially, the targets we want to optimize towards are, reduce the number of declines, and also reduce the std of the overall task distribution. 

So, my reward function could be:

\- score 0 if the task is declined;

\- if the task is accepted, then I can take the delta of the std before and after. The bigger the delta, the more std was reduced, so the more even the distribution became.

That way, the reward score would in a way represent both my targets (and would be the labels), and then it's simply a matter of training a regression model. Then for a new task, I predict the reward score for each task and worker, and finally assign the tasks by taking the argmax of the predicted scores.

I know that rewards are popular in the RL field, but this wouldn't be necessarily a RL problem. In fact, I googled this idea but the vast majority of articles and papers covering reward functions are RL-related.

I'm wondering if anyone has tried anything like this before, or have any thoughts. All comments are appreciated.",1,1,2022-07-05 21:26:48, p  reward function as a way to represent multiple targets,i ve been assigned at work a problem with multiple targets  and i ve been thinking about what s the best to design a model that would optimize towards all these targets  an idea that occurred me is to create a reward function that would encapsulate all these targets in such a way where  the higher the reward  the better the outcome is for all the targets  in my case  it s a task distribution system where the workers have the option to decline a task if for whatever reason the task doesn t suit them  and one of my targets is to minimize the number of declines  but we also need to make sure the workload is balanced  and we are not overwhelming someone while under utilizing the rest of the team  that would be my second target  and we can use the standard deviation as a way to measure the workload balance  the closer to  the std is  the better  essentially  the targets we want to optimize towards are  reduce the number of declines  and also reduce the std of the overall task distribution  so  my reward function could be    score  if the task is declined    if the task is accepted  then i can take the delta of the std before and after  the bigger the delta  the more std was reduced  so the more even the distribution became that way  the reward score would in a way represent both my targets  and would be the labels   and then it s simply a matter of training a regression model  then for a new task  i predict the reward score for each task and worker  and finally assign the tasks by taking the argmax of the predicted scores i know that rewards are popular in the rl field  but this wouldn t be necessarily a rl problem  in fact  i googled this idea but the vast majority of articles and papers covering reward functions are rl related i m wondering if anyone has tried anything like this before  or have any thoughts  all comments are appreciated ,assigned work problem multiple targets thinking best design model would optimize towards targets idea occurred create reward function would encapsulate targets way higher reward better outcome targets case task distribution system workers option decline task whatever reason task suit one targets minimize number declines also need make sure workload balanced overwhelming someone utilizing rest team would second target use standard deviation way measure workload balance closer std better essentially targets want optimize towards reduce number declines also reduce std overall task distribution reward function could score task declined task accepted take delta std bigger delta std reduced even distribution became way reward score would way represent targets would labels simply matter training regression model task predict reward score task worker finally assign tasks taking argmax predicted scores know rewards popular rl field necessarily rl problem fact googled idea vast majority articles papers covering reward functions rl related wondering anyone tried anything like thoughts comments appreciated,p reward function way represent multiple targets,p reward function way represent multiple targetsassigned work problem multiple targets thinking best design model would optimize towards targets idea occurred create reward function would encapsulate targets way higher reward better outcome targets case task distribution system workers option decline task whatever reason task suit one targets minimize number declines also need make sure workload balanced overwhelming someone utilizing rest team would second target use standard deviation way measure workload balance closer std better essentially targets want optimize towards reduce number declines also reduce std overall task distribution reward function could score task declined task accepted take delta std bigger delta std reduced even distribution became way reward score would way represent targets would labels simply matter training regression model task predict reward score task worker finally assign tasks taking argmax predicted scores know rewards popular rl field necessarily rl problem fact googled idea vast majority articles papers covering reward functions rl related wondering anyone tried anything like thoughts comments appreciated,"['p', 'reward', 'function', 'way', 'represent', 'multiple', 'targetsassigned', 'work', 'problem', 'multiple', 'targets', 'thinking', 'best', 'design', 'model', 'would', 'optimize', 'towards', 'targets', 'idea', 'occurred', 'create', 'reward', 'function', 'would', 'encapsulate', 'targets', 'way', 'higher', 'reward', 'better', 'outcome', 'targets', 'case', 'task', 'distribution', 'system', 'workers', 'option', 'decline', 'task', 'whatever', 'reason', 'task', 'suit', 'one', 'targets', 'minimize', 'number', 'declines', 'also', 'need', 'make', 'sure', 'workload', 'balanced', 'overwhelming', 'someone', 'utilizing', 'rest', 'team', 'would', 'second', 'target', 'use', 'standard', 'deviation', 'way', 'measure', 'workload', 'balance', 'closer', 'std', 'better', 'essentially', 'targets', 'want', 'optimize', 'towards', 'reduce', 'number', 'declines', 'also', 'reduce', 'std', 'overall', 'task', 'distribution', 'reward', 'function', 'could', 'score', 'task', 'declined', 'task', 'accepted', 'take', 'delta', 'std', 'bigger', 'delta', 'std', 'reduced', 'even', 'distribution', 'became', 'way', 'reward', 'score', 'would', 'way', 'represent', 'targets', 'would', 'labels', 'simply', 'matter', 'training', 'regression', 'model', 'task', 'predict', 'reward', 'score', 'task', 'worker', 'finally', 'assign', 'tasks', 'taking', 'argmax', 'predicted', 'scores', 'know', 'rewards', 'popular', 'rl', 'field', 'necessarily', 'rl', 'problem', 'fact', 'googled', 'idea', 'vast', 'majority', 'articles', 'papers', 'covering', 'reward', 'functions', 'rl', 'related', 'wondering', 'anyone', 'tried', 'anything', 'like', 'thoughts', 'comments', 'appreciated']","['p', 'reward', 'function', 'way', 'repres', 'multipl', 'targetsassign', 'work', 'problem', 'multipl', 'target', 'think', 'best', 'design', 'model', 'would', 'optim', 'toward', 'target', 'idea', 'occur', 'creat', 'reward', 'function', 'would', 'encapsul', 'target', 'way', 'higher', 'reward', 'better', 'outcom', 'target', 'case', 'task', 'distribut', 'system', 'worker', 'option', 'declin', 'task', 'whatev', 'reason', 'task', 'suit', 'one', 'target', 'minim', 'number', 'declin', 'also', 'need', 'make', 'sure', 'workload', 'balanc', 'overwhelm', 'someon', 'util', 'rest', 'team', 'would', 'second', 'target', 'use', 'standard', 'deviat', 'way', 'measur', 'workload', 'balanc', 'closer', 'std', 'better', 'essenti', 'target', 'want', 'optim', 'toward', 'reduc', 'number', 'declin', 'also', 'reduc', 'std', 'overal', 'task', 'distribut', 'reward', 'function', 'could', 'score', 'task', 'declin', 'task', 'accept', 'take', 'delta', 'std', 'bigger', 'delta', 'std', 'reduc', 'even', 'distribut', 'becam', 'way', 'reward', 'score', 'would', 'way', 'repres', 'target', 'would', 'label', 'simpli', 'matter', 'train', 'regress', 'model', 'task', 'predict', 'reward', 'score', 'task', 'worker', 'final', 'assign', 'task', 'take', 'argmax', 'predict', 'score', 'know', 'reward', 'popular', 'rl', 'field', 'necessarili', 'rl', 'problem', 'fact', 'googl', 'idea', 'vast', 'major', 'articl', 'paper', 'cover', 'reward', 'function', 'rl', 'relat', 'wonder', 'anyon', 'tri', 'anyth', 'like', 'thought', 'comment', 'appreci']"
311,340,340,rafa10pj,vrj6l5,[P] Poniard: a companion library for scikit-learn that helps with model evaluation and comparison,"TL;DR: Check out Poniard, a new Python library that helps with machine learning model evaluation. You can go ahead and install with `pip`. Links to source code and documentation at the end of this post.

\-----

For the past few months I've been working on Poniard, a Python library that streamlines ML model evaluation and comparison, built on top of scikit-learn. In a nutshell, load some data, select some models, some metrics and a cross-validation strategy, and go to town.

Poniard tries to have a small footprint, a simple API and sane defaults. But above all it strives to have the user stay in control of their modeling experience; you should always know what's going on. This deliberately is NOT an AutoML tool

When I started this project I was trying to speed up a very uninteresting process, i.e., loop through multiple estimators and arrive at a list of metrics for comparison. On the way I included easy hyperparameter tuning, plotting, an extensible plugin framework (out of the box includes Weights and Biases and Pandas Profiling) and as much as I could to make the experience simple and transparent.

Poniard is not exactly groundbreaking, and there are projects in a similar vein that do so much more. In contrast, they tend to have a more complicated API and more dependencies which are some of the things that I actively tried to avoid.

[Github](https://github.com/rxavier/poniard)  
[Example notebooks](https://github.com/rxavier/poniard/tree/main/examples) (including Colab links)  
[Documentation](https://poniard.readthedocs.io/en/latest/index.html)  
[PyPI](https://pypi.org/project/poniard/)",2,31,2022-07-05 01:32:18, p  poniard  a companion library for scikit learn that helps with model evaluation and comparison,tl dr  check out poniard  a new python library that helps with machine learning model evaluation  you can go ahead and install with  pip   links to source code and documentation at the end of this post       for the past few months i ve been working on poniard  a python library that streamlines ml model evaluation and comparison  built on top of scikit learn  in a nutshell  load some data  select some models  some metrics and a cross validation strategy  and go to town poniard tries to have a small footprint  a simple api and sane defaults  but above all it strives to have the user stay in control of their modeling experience  you should always know what s going on  this deliberately is not an automl toolwhen i started this project i was trying to speed up a very uninteresting process  i e   loop through multiple estimators and arrive at a list of metrics for comparison  on the way i included easy hyperparameter tuning  plotting  an extensible plugin framework  out of the box includes weights and biases and pandas profiling  and as much as i could to make the experience simple and transparent poniard is not exactly groundbreaking  and there are projects in a similar vein that do so much more  in contrast  they tend to have a more complicated api and more dependencies which are some of the things that i actively tried to avoid  github  https  example notebooks  https  documentation  https  pypi  https   pypi org project poniard  ,tl dr check poniard python library helps machine learning model evaluation go ahead install pip links source code documentation end post past months working poniard python library streamlines ml model evaluation comparison built top scikit learn nutshell load data select models metrics cross validation strategy go town poniard tries small footprint simple api sane defaults strives user stay control modeling experience always know going deliberately automl toolwhen started project trying speed uninteresting process e loop multiple estimators arrive metrics comparison way included easy hyperparameter tuning plotting extensible plugin framework box includes weights biases pandas profiling much could make experience simple transparent poniard exactly groundbreaking projects similar vein much contrast tend complicated api dependencies things actively tried avoid github https example notebooks https documentation https pypi https pypi org project poniard,p poniard companion library scikit learn helps model evaluation comparison,p poniard companion library scikit learn helps model evaluation comparisontl dr check poniard python library helps machine learning model evaluation go ahead install pip links source code documentation end post past months working poniard python library streamlines ml model evaluation comparison built top scikit learn nutshell load data select models metrics cross validation strategy go town poniard tries small footprint simple api sane defaults strives user stay control modeling experience always know going deliberately automl toolwhen started project trying speed uninteresting process e loop multiple estimators arrive metrics comparison way included easy hyperparameter tuning plotting extensible plugin framework box includes weights biases pandas profiling much could make experience simple transparent poniard exactly groundbreaking projects similar vein much contrast tend complicated api dependencies things actively tried avoid github https example notebooks https documentation https pypi https pypi org project poniard,"['p', 'poniard', 'companion', 'library', 'scikit', 'learn', 'helps', 'model', 'evaluation', 'comparisontl', 'dr', 'check', 'poniard', 'python', 'library', 'helps', 'machine', 'learning', 'model', 'evaluation', 'go', 'ahead', 'install', 'pip', 'links', 'source', 'code', 'documentation', 'end', 'post', 'past', 'months', 'working', 'poniard', 'python', 'library', 'streamlines', 'ml', 'model', 'evaluation', 'comparison', 'built', 'top', 'scikit', 'learn', 'nutshell', 'load', 'data', 'select', 'models', 'metrics', 'cross', 'validation', 'strategy', 'go', 'town', 'poniard', 'tries', 'small', 'footprint', 'simple', 'api', 'sane', 'defaults', 'strives', 'user', 'stay', 'control', 'modeling', 'experience', 'always', 'know', 'going', 'deliberately', 'automl', 'toolwhen', 'started', 'project', 'trying', 'speed', 'uninteresting', 'process', 'e', 'loop', 'multiple', 'estimators', 'arrive', 'metrics', 'comparison', 'way', 'included', 'easy', 'hyperparameter', 'tuning', 'plotting', 'extensible', 'plugin', 'framework', 'box', 'includes', 'weights', 'biases', 'pandas', 'profiling', 'much', 'could', 'make', 'experience', 'simple', 'transparent', 'poniard', 'exactly', 'groundbreaking', 'projects', 'similar', 'vein', 'much', 'contrast', 'tend', 'complicated', 'api', 'dependencies', 'things', 'actively', 'tried', 'avoid', 'github', 'https', 'example', 'notebooks', 'https', 'documentation', 'https', 'pypi', 'https', 'pypi', 'org', 'project', 'poniard']","['p', 'poniard', 'companion', 'librari', 'scikit', 'learn', 'help', 'model', 'evalu', 'comparisontl', 'dr', 'check', 'poniard', 'python', 'librari', 'help', 'machin', 'learn', 'model', 'evalu', 'go', 'ahead', 'instal', 'pip', 'link', 'sourc', 'code', 'document', 'end', 'post', 'past', 'month', 'work', 'poniard', 'python', 'librari', 'streamlin', 'ml', 'model', 'evalu', 'comparison', 'built', 'top', 'scikit', 'learn', 'nutshel', 'load', 'data', 'select', 'model', 'metric', 'cross', 'valid', 'strategi', 'go', 'town', 'poniard', 'tri', 'small', 'footprint', 'simpl', 'api', 'sane', 'default', 'strive', 'user', 'stay', 'control', 'model', 'experi', 'alway', 'know', 'go', 'deliber', 'automl', 'toolwhen', 'start', 'project', 'tri', 'speed', 'uninterest', 'process', 'e', 'loop', 'multipl', 'estim', 'arriv', 'metric', 'comparison', 'way', 'includ', 'easi', 'hyperparamet', 'tune', 'plot', 'extens', 'plugin', 'framework', 'box', 'includ', 'weight', 'bias', 'panda', 'profil', 'much', 'could', 'make', 'experi', 'simpl', 'transpar', 'poniard', 'exactli', 'groundbreak', 'project', 'similar', 'vein', 'much', 'contrast', 'tend', 'complic', 'api', 'depend', 'thing', 'activ', 'tri', 'avoid', 'github', 'http', 'exampl', 'notebook', 'http', 'document', 'http', 'pypi', 'http', 'pypi', 'org', 'project', 'poniard']"
312,341,341,tadf2,vs14lj,[D] How do you share a server for multiple training jobs?,"First of all, using the cloud is not a cost effective solution for us.


We have an absolute beast of a server though everything grounds down to a halt when some training sessions are going on - some libraries just ignore the num_cpu settings and uses all the cpu (and even when more cores are free, everything seems to get much slower)

Here's the build:
2x AMD EPYC 7763 (64 cores, 2 threads each)
2TB memory
8 RTX A6000
4TB SSD (NVMe)

How do you all share a single computer resource amongst other co-workers? We have this expensive machine but when someone runs their training, others have a hard time running basic pandas operations (starting other training jobs just slows down ALL training jobs).

To me, it seems like the hardware should be more than enough to run multiple training jobs concurrently. Any tips on how to use it efficiently?

One solution I've been thinking was to use docker for each training job and to put hard limits on cpu / memory usage - is this something closer to best practice?",10,0,2022-07-05 18:55:23, d  how do you share a server for multiple training jobs ,first of all  using the cloud is not a cost effective solution for us we have an absolute beast of a server though everything grounds down to a halt when some training sessions are going on   some libraries just ignore the num_cpu settings and uses all the cpu  and even when more cores are free  everything seems to get much slower here s the build x amd epyc    cores   threads each tb memory rtx atb ssd  nvme how do you all share a single computer resource amongst other co workers  we have this expensive machine but when someone runs their training  others have a hard time running basic pandas operations  starting other training jobs just slows down all training jobs  to me  it seems like the hardware should be more than enough to run multiple training jobs concurrently  any tips on how to use it efficiently one solution i ve been thinking was to use docker for each training job and to put hard limits on cpu   memory usage   is this something closer to best practice ,first using cloud cost effective solution us absolute beast server though everything grounds halt training sessions going libraries ignore num_cpu settings uses cpu even cores free everything seems get much slower build x amd epyc cores threads tb memory rtx atb ssd nvme share single computer resource amongst co workers expensive machine someone runs training others hard time running basic pandas operations starting training jobs slows training jobs seems like hardware enough run multiple training jobs concurrently tips use efficiently one solution thinking use docker training job put hard limits cpu memory usage something closer best practice,share server multiple training jobs,share server multiple training jobsfirst using cloud cost effective solution us absolute beast server though everything grounds halt training sessions going libraries ignore num_cpu settings uses cpu even cores free everything seems get much slower build x amd epyc cores threads tb memory rtx atb ssd nvme share single computer resource amongst co workers expensive machine someone runs training others hard time running basic pandas operations starting training jobs slows training jobs seems like hardware enough run multiple training jobs concurrently tips use efficiently one solution thinking use docker training job put hard limits cpu memory usage something closer best practice,"['share', 'server', 'multiple', 'training', 'jobsfirst', 'using', 'cloud', 'cost', 'effective', 'solution', 'us', 'absolute', 'beast', 'server', 'though', 'everything', 'grounds', 'halt', 'training', 'sessions', 'going', 'libraries', 'ignore', 'num_cpu', 'settings', 'uses', 'cpu', 'even', 'cores', 'free', 'everything', 'seems', 'get', 'much', 'slower', 'build', 'x', 'amd', 'epyc', 'cores', 'threads', 'tb', 'memory', 'rtx', 'atb', 'ssd', 'nvme', 'share', 'single', 'computer', 'resource', 'amongst', 'co', 'workers', 'expensive', 'machine', 'someone', 'runs', 'training', 'others', 'hard', 'time', 'running', 'basic', 'pandas', 'operations', 'starting', 'training', 'jobs', 'slows', 'training', 'jobs', 'seems', 'like', 'hardware', 'enough', 'run', 'multiple', 'training', 'jobs', 'concurrently', 'tips', 'use', 'efficiently', 'one', 'solution', 'thinking', 'use', 'docker', 'training', 'job', 'put', 'hard', 'limits', 'cpu', 'memory', 'usage', 'something', 'closer', 'best', 'practice']","['share', 'server', 'multipl', 'train', 'jobsfirst', 'use', 'cloud', 'cost', 'effect', 'solut', 'us', 'absolut', 'beast', 'server', 'though', 'everyth', 'ground', 'halt', 'train', 'session', 'go', 'librari', 'ignor', 'num_cpu', 'set', 'use', 'cpu', 'even', 'core', 'free', 'everyth', 'seem', 'get', 'much', 'slower', 'build', 'x', 'amd', 'epyc', 'core', 'thread', 'tb', 'memori', 'rtx', 'atb', 'ssd', 'nvme', 'share', 'singl', 'comput', 'resourc', 'amongst', 'co', 'worker', 'expens', 'machin', 'someon', 'run', 'train', 'other', 'hard', 'time', 'run', 'basic', 'panda', 'oper', 'start', 'train', 'job', 'slow', 'train', 'job', 'seem', 'like', 'hardwar', 'enough', 'run', 'multipl', 'train', 'job', 'concurr', 'tip', 'use', 'effici', 'one', 'solut', 'think', 'use', 'docker', 'train', 'job', 'put', 'hard', 'limit', 'cpu', 'memori', 'usag', 'someth', 'closer', 'best', 'practic']"
313,342,342,dmart89,vr6iy5,[D] How do you share big datasets with your team and others?,"Looking for a bit of a discussion.  I'm wondering how you collaborate on data... i.e. how do you share big datasets with data scientists/engineers, within and outside of your team? Do you just push it into a simple DB, do you upload it to Kaggle (if non-sensitive) or via Google Drive/OneDrive? 

What if the dataset gets updated frequently?

I'm working with a customer and sharing data is a bit of a pain.",73,148,2022-07-04 15:39:53, d  how do you share big datasets with your team and others ,looking for a bit of a discussion   i m wondering how you collaborate on data    i e  how do you share big datasets with data scientists engineers  within and outside of your team  do you just push it into a simple db  do you upload it to kaggle  if non sensitive  or via google drive onedrive  what if the dataset gets updated frequently i m working with a customer and sharing data is a bit of a pain ,looking bit discussion wondering collaborate data e share big datasets data scientists engineers within outside team push simple db upload kaggle non sensitive via google drive onedrive dataset gets updated frequently working customer sharing data bit pain,share big datasets team others,share big datasets team otherslooking bit discussion wondering collaborate data e share big datasets data scientists engineers within outside team push simple db upload kaggle non sensitive via google drive onedrive dataset gets updated frequently working customer sharing data bit pain,"['share', 'big', 'datasets', 'team', 'otherslooking', 'bit', 'discussion', 'wondering', 'collaborate', 'data', 'e', 'share', 'big', 'datasets', 'data', 'scientists', 'engineers', 'within', 'outside', 'team', 'push', 'simple', 'db', 'upload', 'kaggle', 'non', 'sensitive', 'via', 'google', 'drive', 'onedrive', 'dataset', 'gets', 'updated', 'frequently', 'working', 'customer', 'sharing', 'data', 'bit', 'pain']","['share', 'big', 'dataset', 'team', 'otherslook', 'bit', 'discuss', 'wonder', 'collabor', 'data', 'e', 'share', 'big', 'dataset', 'data', 'scientist', 'engin', 'within', 'outsid', 'team', 'push', 'simpl', 'db', 'upload', 'kaggl', 'non', 'sensit', 'via', 'googl', 'drive', 'onedr', 'dataset', 'get', 'updat', 'frequent', 'work', 'custom', 'share', 'data', 'bit', 'pain']"
314,343,343,ErrorDry4380,vr592h,[R] Masking for Representation Learning in Vision,"A blog about representation learning from masked images, what makes a good mask, and how to learn such masks: [https://akosiorek.github.io/ml/2022/07/04/masking\_repr\_learning\_vision.html](https://akosiorek.github.io/ml/2022/07/04/masking_repr_learning_vision.html).

Based on a recent ICML paper: [Shi et. al, ""Adversarial Masking for Self-Supervised Learning"", ICML 2022](https://arxiv.org/abs/2201.13100).",4,71,2022-07-04 14:26:26, r  masking for representation learning in vision,a blog about representation learning from masked images  what makes a good mask  and how to learn such masks   https based on a recent icml paper   shi et  al  adversarial masking for self supervised learning  icml   https   arxiv org abs    ,blog representation learning masked images makes good mask learn masks https based recent icml paper shi et al adversarial masking self supervised learning icml https arxiv org abs,r masking representation learning vision,r masking representation learning visionblog representation learning masked images makes good mask learn masks https based recent icml paper shi et al adversarial masking self supervised learning icml https arxiv org abs,"['r', 'masking', 'representation', 'learning', 'visionblog', 'representation', 'learning', 'masked', 'images', 'makes', 'good', 'mask', 'learn', 'masks', 'https', 'based', 'recent', 'icml', 'paper', 'shi', 'et', 'al', 'adversarial', 'masking', 'self', 'supervised', 'learning', 'icml', 'https', 'arxiv', 'org', 'abs']","['r', 'mask', 'represent', 'learn', 'visionblog', 'represent', 'learn', 'mask', 'imag', 'make', 'good', 'mask', 'learn', 'mask', 'http', 'base', 'recent', 'icml', 'paper', 'shi', 'et', 'al', 'adversari', 'mask', 'self', 'supervis', 'learn', 'icml', 'http', 'arxiv', 'org', 'ab']"
315,344,344,jeryyjohnson,vrpf6i,WACV 2023 Paper Registration. [R],Does anyone know how to register for the WACV 2023 conference?,4,2,2022-07-05 07:20:59,wacv  paper registration   r ,does anyone know how to register for the wacv  conference ,anyone know register wacv conference,wacv paper registration r,wacv paper registration ranyone know register wacv conference,"['wacv', 'paper', 'registration', 'ranyone', 'know', 'register', 'wacv', 'conference']","['wacv', 'paper', 'registr', 'ranyon', 'know', 'regist', 'wacv', 'confer']"
316,345,345,zxzxy1988,vr3hzx,"[P] Feathr - An Open-Source, Enterprise-Grade and High-Performance Feature Store","Hi everyone! We are engineers from Microsoft/LinkedIn, and we released an open-source Feature Store called Feathr a few weeks ago ([https://github.com/linkedin/feathr](https://github.com/linkedin/feathr)). It has many highlights like below. Feel free to check out the repository and let us know if there are any questions! We also have a few blogposts and recordings in case folks want to learn a bit more about it:

* [Open Sourcing Feathr](https://engineering.linkedin.com/blog/2022/open-sourcing-feathr---linkedin-s-feature-store-for-productive-m)
* [Feathr on Azure](https://azure.microsoft.com/en-us/blog/feathr-linkedin-s-feature-store-is-now-available-on-azure/).
* [Tech talks on Feathr](https://www.youtube.com/watch?v=gZg01UKQMTY)

And its highlights include (more highlights are [here](https://github.com/linkedin/feathr#-feathr-highlights)):

* **Battle tested in production for more than 6 years:** LinkedIn has been using Feathr in production for over 6 years and have a dedicated team improving it.
* **Scalable with built-in optimizations:** For example, based on some internal use case, Feathr can process billions of rows and PB scale data with built-in optimizations such as bloom filters and salted joins.
* **Rich support for point-in-time joins and aggregations:** Feathr has high performant built-in operators designed for Feature Store, including time-based aggregation, sliding window joins, look-up features, all with point-in-time correctness.
* **Derived Features and centralized Feature Registry** which encourage feature consumers to build features on existing features and encouraging feature reuse.

&#x200B;

Screenshots for the Feathr UI:

https://preview.redd.it/3fri2r3qoi991.png?width=3584&format=png&auto=webp&s=5dfe14233b2a8805c50bedd5bfed4bbb31bd0654",16,45,2022-07-04 12:27:38, p  feathr   an open source  enterprise grade and high performance feature store,hi everyone  we are engineers from microsoft linkedin  and we released an open source feature store called feathr a few weeks ago   https    open sourcing feathr  https    feathr on azure  https    tech talks on feathr  https and its highlights include  more highlights are  here  https     battle tested in production for more than  years    linkedin has been using feathr in production for over  years and have a dedicated team improving it     scalable with built in optimizations    for example  based on some internal use case  feathr can process billions of rows and pb scale data with built in optimizations such as bloom filters and salted joins     rich support for point in time joins and aggregations    feathr has high performant built in operators designed for feature store  including time based aggregation  sliding window joins  look up features  all with point in time correctness     derived features and centralized feature registry   which encourage feature consumers to build features on existing features and encouraging feature reuse   xb screenshots for the feathr ui https   preview redd it frirqoi png width  format png auto webp s dfebacbeddbfedbbbbd,hi everyone engineers microsoft linkedin released open source feature store called feathr weeks ago https open sourcing feathr https feathr azure https tech talks feathr https highlights include highlights https battle tested production years linkedin using feathr production years dedicated team improving scalable built optimizations example based internal use case feathr process billions rows pb scale data built optimizations bloom filters salted joins rich support point time joins aggregations feathr high performant built operators designed feature store including time based aggregation sliding window joins look features point time correctness derived features centralized feature registry encourage feature consumers build features existing features encouraging feature reuse xb screenshots feathr ui https preview redd frirqoi png width format png auto webp dfebacbeddbfedbbbbd,p feathr open source enterprise grade high performance feature store,p feathr open source enterprise grade high performance feature storehi everyone engineers microsoft linkedin released open source feature store called feathr weeks ago https open sourcing feathr https feathr azure https tech talks feathr https highlights include highlights https battle tested production years linkedin using feathr production years dedicated team improving scalable built optimizations example based internal use case feathr process billions rows pb scale data built optimizations bloom filters salted joins rich support point time joins aggregations feathr high performant built operators designed feature store including time based aggregation sliding window joins look features point time correctness derived features centralized feature registry encourage feature consumers build features existing features encouraging feature reuse xb screenshots feathr ui https preview redd frirqoi png width format png auto webp dfebacbeddbfedbbbbd,"['p', 'feathr', 'open', 'source', 'enterprise', 'grade', 'high', 'performance', 'feature', 'storehi', 'everyone', 'engineers', 'microsoft', 'linkedin', 'released', 'open', 'source', 'feature', 'store', 'called', 'feathr', 'weeks', 'ago', 'https', 'open', 'sourcing', 'feathr', 'https', 'feathr', 'azure', 'https', 'tech', 'talks', 'feathr', 'https', 'highlights', 'include', 'highlights', 'https', 'battle', 'tested', 'production', 'years', 'linkedin', 'using', 'feathr', 'production', 'years', 'dedicated', 'team', 'improving', 'scalable', 'built', 'optimizations', 'example', 'based', 'internal', 'use', 'case', 'feathr', 'process', 'billions', 'rows', 'pb', 'scale', 'data', 'built', 'optimizations', 'bloom', 'filters', 'salted', 'joins', 'rich', 'support', 'point', 'time', 'joins', 'aggregations', 'feathr', 'high', 'performant', 'built', 'operators', 'designed', 'feature', 'store', 'including', 'time', 'based', 'aggregation', 'sliding', 'window', 'joins', 'look', 'features', 'point', 'time', 'correctness', 'derived', 'features', 'centralized', 'feature', 'registry', 'encourage', 'feature', 'consumers', 'build', 'features', 'existing', 'features', 'encouraging', 'feature', 'reuse', 'xb', 'screenshots', 'feathr', 'ui', 'https', 'preview', 'redd', 'frirqoi', 'png', 'width', 'format', 'png', 'auto', 'webp', 'dfebacbeddbfedbbbbd']","['p', 'feathr', 'open', 'sourc', 'enterpris', 'grade', 'high', 'perform', 'featur', 'storehi', 'everyon', 'engin', 'microsoft', 'linkedin', 'releas', 'open', 'sourc', 'featur', 'store', 'call', 'feathr', 'week', 'ago', 'http', 'open', 'sourc', 'feathr', 'http', 'feathr', 'azur', 'http', 'tech', 'talk', 'feathr', 'http', 'highlight', 'includ', 'highlight', 'http', 'battl', 'test', 'product', 'year', 'linkedin', 'use', 'feathr', 'product', 'year', 'dedic', 'team', 'improv', 'scalabl', 'built', 'optim', 'exampl', 'base', 'intern', 'use', 'case', 'feathr', 'process', 'billion', 'row', 'pb', 'scale', 'data', 'built', 'optim', 'bloom', 'filter', 'salt', 'join', 'rich', 'support', 'point', 'time', 'join', 'aggreg', 'feathr', 'high', 'perform', 'built', 'oper', 'design', 'featur', 'store', 'includ', 'time', 'base', 'aggreg', 'slide', 'window', 'join', 'look', 'featur', 'point', 'time', 'correct', 'deriv', 'featur', 'central', 'featur', 'registri', 'encourag', 'featur', 'consum', 'build', 'featur', 'exist', 'featur', 'encourag', 'featur', 'reus', 'xb', 'screenshot', 'feathr', 'ui', 'http', 'preview', 'redd', 'frirqoi', 'png', 'width', 'format', 'png', 'auto', 'webp', 'dfebacbeddbfedbbbbd']"
317,346,346,leepenkman,vrj17e,[P] Bulk AI Text Generation (No/Low code),"[https://textgenerator.app.nz/bulk-text-generator](https://textgenerator.app.nz/bulk-text-generator)

  
You can upload a CSV and get lots of Text Generated, works in many languages and code too.  


There's also an API.  


The **main selling points** (VS OpenAI who is the main competitor)

* Works faster 
* Currie/Babbage quality, but also works across languages/code without needing to specify what model
* Massively cheaper pricing/huge cost savings :) 
* easier to control
   * can specify max\_sentences to make it generate up to a specific number of sentences)
   * can specify min\_probability to make it generate the next few likely words to do autocomplete for code/writing

  
I originally created [https://textgenerator.app.nz/](https://textgenerator.app.nz/) as a API for developers primarily but the bulk generator now allows non technical types to pre generate a lot of variety too/branching stories/games/marketing content/code/summaries/ etc.   


There's actually a [massive amount of use cases](https://textgenerator.app.nz/use-cases) that one will never be able to understand which is exciting too.",0,4,2022-07-05 01:25:10, p  bulk ai text generation  no low code , https   you can upload a csv and get lots of text generated  works in many languages and code too   there s also an api   the   main selling points    vs openai who is the main competitor   works faster   currie babbage quality  but also works across languages code without needing to specify what model  massively cheaper pricing huge cost savings      easier to control     can specify max _sentences to make it generate up to a specific number of sentences      can specify min _probability to make it generate the next few likely words to do autocomplete for code writing  i originally created  https there s actually a  massive amount of use cases  https   textgenerator app nz use cases  that one will never be able to understand which is exciting too ,https upload csv get lots text generated works many languages code also api main selling points vs openai main competitor works faster currie babbage quality also works across languages code without needing specify model massively cheaper pricing huge cost savings easier control specify max _sentences make generate specific number sentences specify min _probability make generate next likely autocomplete code writing originally created https actually massive amount use cases https textgenerator app nz use cases one never able understand exciting,p bulk ai text generation low code,p bulk ai text generation low codehttps upload csv get lots text generated works many languages code also api main selling points vs openai main competitor works faster currie babbage quality also works across languages code without needing specify model massively cheaper pricing huge cost savings easier control specify max _sentences make generate specific number sentences specify min _probability make generate next likely autocomplete code writing originally created https actually massive amount use cases https textgenerator app nz use cases one never able understand exciting,"['p', 'bulk', 'ai', 'text', 'generation', 'low', 'codehttps', 'upload', 'csv', 'get', 'lots', 'text', 'generated', 'works', 'many', 'languages', 'code', 'also', 'api', 'main', 'selling', 'points', 'vs', 'openai', 'main', 'competitor', 'works', 'faster', 'currie', 'babbage', 'quality', 'also', 'works', 'across', 'languages', 'code', 'without', 'needing', 'specify', 'model', 'massively', 'cheaper', 'pricing', 'huge', 'cost', 'savings', 'easier', 'control', 'specify', 'max', '_sentences', 'make', 'generate', 'specific', 'number', 'sentences', 'specify', 'min', '_probability', 'make', 'generate', 'next', 'likely', 'autocomplete', 'code', 'writing', 'originally', 'created', 'https', 'actually', 'massive', 'amount', 'use', 'cases', 'https', 'textgenerator', 'app', 'nz', 'use', 'cases', 'one', 'never', 'able', 'understand', 'exciting']","['p', 'bulk', 'ai', 'text', 'gener', 'low', 'codehttp', 'upload', 'csv', 'get', 'lot', 'text', 'gener', 'work', 'mani', 'languag', 'code', 'also', 'api', 'main', 'sell', 'point', 'vs', 'openai', 'main', 'competitor', 'work', 'faster', 'curri', 'babbag', 'qualiti', 'also', 'work', 'across', 'languag', 'code', 'without', 'need', 'specifi', 'model', 'massiv', 'cheaper', 'price', 'huge', 'cost', 'save', 'easier', 'control', 'specifi', 'max', '_sentenc', 'make', 'gener', 'specif', 'number', 'sentenc', 'specifi', 'min', '_probabl', 'make', 'gener', 'next', 'like', 'autocomplet', 'code', 'write', 'origin', 'creat', 'http', 'actual', 'massiv', 'amount', 'use', 'case', 'http', 'textgener', 'app', 'nz', 'use', 'case', 'one', 'never', 'abl', 'understand', 'excit']"
318,347,347,_Arsenie_Boca_,vrhlfa,[D] Backpropagating from GPT-2's output,"I am working on a research project about controllable generation with GPT. I am stuck, so I hope you are able to help me out. I will try to explain the issue as clear as possible, so bear with me.

The approach I am pursuing right now is adding a frozen classifier on top of gpt that should steer the model in generating the right class, which is a grammatical property of the generated output.

However, the autoregressive nature of GPT complicates things a bit. I cannot simply backpropagate through the generation process (greedy / beam search). 

I tried adding the classifier on the last input token to avoid the generation process but unsurprisingly this does not yield sufficient performance.

How would you tackle this? Is it even feasible?",3,1,2022-07-05 00:16:31, d  backpropagating from gpt  s output,i am working on a research project about controllable generation with gpt  i am stuck  so i hope you are able to help me out  i will try to explain the issue as clear as possible  so bear with me the approach i am pursuing right now is adding a frozen classifier on top of gpt that should steer the model in generating the right class  which is a grammatical property of the generated output however  the autoregressive nature of gpt complicates things a bit  i cannot simply backpropagate through the generation process  greedy   beam search   i tried adding the classifier on the last input token to avoid the generation process but unsurprisingly this does not yield sufficient performance how would you tackle this  is it even feasible ,working research project controllable generation gpt stuck hope able help try explain issue clear possible bear approach pursuing right adding frozen classifier top gpt steer model generating right class grammatical property generated output however autoregressive nature gpt complicates things bit cannot simply backpropagate generation process greedy beam search tried adding classifier last input token avoid generation process unsurprisingly yield sufficient performance would tackle even feasible,backpropagating gpt output,backpropagating gpt outputworking research project controllable generation gpt stuck hope able help try explain issue clear possible bear approach pursuing right adding frozen classifier top gpt steer model generating right class grammatical property generated output however autoregressive nature gpt complicates things bit cannot simply backpropagate generation process greedy beam search tried adding classifier last input token avoid generation process unsurprisingly yield sufficient performance would tackle even feasible,"['backpropagating', 'gpt', 'outputworking', 'research', 'project', 'controllable', 'generation', 'gpt', 'stuck', 'hope', 'able', 'help', 'try', 'explain', 'issue', 'clear', 'possible', 'bear', 'approach', 'pursuing', 'right', 'adding', 'frozen', 'classifier', 'top', 'gpt', 'steer', 'model', 'generating', 'right', 'class', 'grammatical', 'property', 'generated', 'output', 'however', 'autoregressive', 'nature', 'gpt', 'complicates', 'things', 'bit', 'can', 'not', 'simply', 'backpropagate', 'generation', 'process', 'greedy', 'beam', 'search', 'tried', 'adding', 'classifier', 'last', 'input', 'token', 'avoid', 'generation', 'process', 'unsurprisingly', 'yield', 'sufficient', 'performance', 'would', 'tackle', 'even', 'feasible']","['backpropag', 'gpt', 'outputwork', 'research', 'project', 'control', 'gener', 'gpt', 'stuck', 'hope', 'abl', 'help', 'tri', 'explain', 'issu', 'clear', 'possibl', 'bear', 'approach', 'pursu', 'right', 'ad', 'frozen', 'classifi', 'top', 'gpt', 'steer', 'model', 'gener', 'right', 'class', 'grammat', 'properti', 'gener', 'output', 'howev', 'autoregress', 'natur', 'gpt', 'complic', 'thing', 'bit', 'can', 'not', 'simpli', 'backpropag', 'gener', 'process', 'greedi', 'beam', 'search', 'tri', 'ad', 'classifi', 'last', 'input', 'token', 'avoid', 'gener', 'process', 'unsurprisingli', 'yield', 'suffici', 'perform', 'would', 'tackl', 'even', 'feasibl']"
319,348,348,bitemenow999,vqoey6,[D] Advanced resources for ML theory/math.,"So I have been working in ML for the past 3 years as a researcher and now PhD candidate, and though I have an understanding of intermediate level of the math behind most algorithms. But it looks like I have reached a  plateau, where I get the math in the papers but  I don't have an understanding of how they came up with the methods, and lately, my work has been combining multiple existing methods to make something new and draw inference on them, I realize the lack of novelty in my approach is mostly due to me being an 'engineer' and not a stats/math guy.

Looking to remedy that, are there some resources free or otherwise that would get me a deeper understanding of Bayesian, Markov models, and stochastic math and PDEs? I know I can attend classes in my university but I would rather focus more on research than worry about assignments and grades and such...",20,136,2022-07-03 21:58:08, d  advanced resources for ml theory math ,so i have been working in ml for the past  years as a researcher and now phd candidate  and though i have an understanding of intermediate level of the math behind most algorithms  but it looks like i have reached a  plateau  where i get the math in the papers but  i don t have an understanding of how they came up with the methods  and lately  my work has been combining multiple existing methods to make something new and draw inference on them  i realize the lack of novelty in my approach is mostly due to me being an  engineer  and not a stats math guy looking to remedy that  are there some resources free or otherwise that would get me a deeper understanding of bayesian  markov models  and stochastic math and pdes  i know i can attend classes in my university but i would rather focus more on research than worry about assignments and grades and such   ,working ml past years researcher phd candidate though understanding intermediate level math behind algorithms looks like reached plateau get math papers understanding came methods lately work combining multiple existing methods make something draw inference realize lack novelty approach mostly due engineer stats math guy looking remedy resources free otherwise would get deeper understanding bayesian markov models stochastic math pdes know attend classes university would rather focus research worry assignments grades,advanced resources ml theory math,advanced resources ml theory mathworking ml past years researcher phd candidate though understanding intermediate level math behind algorithms looks like reached plateau get math papers understanding came methods lately work combining multiple existing methods make something draw inference realize lack novelty approach mostly due engineer stats math guy looking remedy resources free otherwise would get deeper understanding bayesian markov models stochastic math pdes know attend classes university would rather focus research worry assignments grades,"['advanced', 'resources', 'ml', 'theory', 'mathworking', 'ml', 'past', 'years', 'researcher', 'phd', 'candidate', 'though', 'understanding', 'intermediate', 'level', 'math', 'behind', 'algorithms', 'looks', 'like', 'reached', 'plateau', 'get', 'math', 'papers', 'understanding', 'came', 'methods', 'lately', 'work', 'combining', 'multiple', 'existing', 'methods', 'make', 'something', 'draw', 'inference', 'realize', 'lack', 'novelty', 'approach', 'mostly', 'due', 'engineer', 'stats', 'math', 'guy', 'looking', 'remedy', 'resources', 'free', 'otherwise', 'would', 'get', 'deeper', 'understanding', 'bayesian', 'markov', 'models', 'stochastic', 'math', 'pdes', 'know', 'attend', 'classes', 'university', 'would', 'rather', 'focus', 'research', 'worry', 'assignments', 'grades']","['advanc', 'resourc', 'ml', 'theori', 'mathwork', 'ml', 'past', 'year', 'research', 'phd', 'candid', 'though', 'understand', 'intermedi', 'level', 'math', 'behind', 'algorithm', 'look', 'like', 'reach', 'plateau', 'get', 'math', 'paper', 'understand', 'came', 'method', 'late', 'work', 'combin', 'multipl', 'exist', 'method', 'make', 'someth', 'draw', 'infer', 'realiz', 'lack', 'novelti', 'approach', 'mostli', 'due', 'engin', 'stat', 'math', 'guy', 'look', 'remedi', 'resourc', 'free', 'otherwis', 'would', 'get', 'deeper', 'understand', 'bayesian', 'markov', 'model', 'stochast', 'math', 'pde', 'know', 'attend', 'class', 'univers', 'would', 'rather', 'focu', 'research', 'worri', 'assign', 'grade']"
320,349,349,Insighteous,vqg3mn,[D] Do you think there is too much development in Machine Learning?,"Sometimes I think this field evolves too fast. No time to relax a little bit and use the knowledge build over time. What’s up to date today is outdated tomorrow.   

What do you think about this?",98,284,2022-07-03 15:03:02, d  do you think there is too much development in machine learning ,sometimes i think this field evolves too fast  no time to relax a little bit and use the knowledge build over time  what s up to date today is outdated tomorrow    what do you think about this ,sometimes think field evolves fast time relax little bit use knowledge build time date today outdated tomorrow think,think much development machine learning,think much development machine learningsometimes think field evolves fast time relax little bit use knowledge build time date today outdated tomorrow think,"['think', 'much', 'development', 'machine', 'learningsometimes', 'think', 'field', 'evolves', 'fast', 'time', 'relax', 'little', 'bit', 'use', 'knowledge', 'build', 'time', 'date', 'today', 'outdated', 'tomorrow', 'think']","['think', 'much', 'develop', 'machin', 'learningsometim', 'think', 'field', 'evolv', 'fast', 'time', 'relax', 'littl', 'bit', 'use', 'knowledg', 'build', 'time', 'date', 'today', 'outdat', 'tomorrow', 'think']"
321,350,350,aifordummies,vqrawg,[D] List of accepted ECCV papers are now available!,[https://ailb-web.ing.unimore.it/releases/eccv2022/accepted\_papers.txt](https://ailb-web.ing.unimore.it/releases/eccv2022/accepted_papers.txt),40,47,2022-07-04 00:16:30, d  list of accepted eccv papers are now available , https   ailb web ing unimore it releases eccv accepted _papers txt  https   ailb web ing unimore it releases eccv accepted_papers txt ,https ailb web ing unimore releases eccv accepted _papers txt https ailb web ing unimore releases eccv accepted_papers txt,accepted eccv papers available,accepted eccv papers availablehttps ailb web ing unimore releases eccv accepted _papers txt https ailb web ing unimore releases eccv accepted_papers txt,"['accepted', 'eccv', 'papers', 'availablehttps', 'ailb', 'web', 'ing', 'unimore', 'releases', 'eccv', 'accepted', '_papers', 'txt', 'https', 'ailb', 'web', 'ing', 'unimore', 'releases', 'eccv', 'accepted_papers', 'txt']","['accept', 'eccv', 'paper', 'availablehttp', 'ailb', 'web', 'ing', 'unimor', 'releas', 'eccv', 'accept', '_paper', 'txt', 'http', 'ailb', 'web', 'ing', 'unimor', 'releas', 'eccv', 'accepted_pap', 'txt']"
322,351,351,tmclouisluk,vr0x4r,[D] Is there any deep learning algorithm based on divide and conquer?," 

Dealing with a very huge data, eg. very long video datasets, the problems are long training time. Most of technics are using distributed deep learning to solve the problem robustly. I have an idea that we divide the dataset into small sets and train a model. After that using the model to predict values as features, put them into another model and train a second model to predict the output. Like divide and conquer but here is divide the dataset, train a model and conquer the prediction results into one.

I have done some research in the internet about deep learning algorithm based on divide and conquer but seems not so many articles about it.

Is it a correct to think in this way? Does anyone know any paper about this? Thank you so much.",24,6,2022-07-04 09:22:48, d  is there any deep learning algorithm based on divide and conquer , dealing with a very huge data  eg  very long video datasets  the problems are long training time  most of technics are using distributed deep learning to solve the problem robustly  i have an idea that we divide the dataset into small sets and train a model  after that using the model to predict values as features  put them into another model and train a second model to predict the output  like divide and conquer but here is divide the dataset  train a model and conquer the prediction results into one i have done some research in the internet about deep learning algorithm based on divide and conquer but seems not so many articles about it is it a correct to think in this way  does anyone know any paper about this  thank you so much ,dealing huge data eg long video datasets problems long training time technics using distributed deep learning solve problem robustly idea divide dataset small sets train model using model predict values features put another model train second model predict output like divide conquer divide dataset train model conquer prediction results one done research internet deep learning algorithm based divide conquer seems many articles correct think way anyone know paper thank much,deep learning algorithm based divide conquer,deep learning algorithm based divide conquerdealing huge data eg long video datasets problems long training time technics using distributed deep learning solve problem robustly idea divide dataset small sets train model using model predict values features put another model train second model predict output like divide conquer divide dataset train model conquer prediction results one done research internet deep learning algorithm based divide conquer seems many articles correct think way anyone know paper thank much,"['deep', 'learning', 'algorithm', 'based', 'divide', 'conquerdealing', 'huge', 'data', 'eg', 'long', 'video', 'datasets', 'problems', 'long', 'training', 'time', 'technics', 'using', 'distributed', 'deep', 'learning', 'solve', 'problem', 'robustly', 'idea', 'divide', 'dataset', 'small', 'sets', 'train', 'model', 'using', 'model', 'predict', 'values', 'features', 'put', 'another', 'model', 'train', 'second', 'model', 'predict', 'output', 'like', 'divide', 'conquer', 'divide', 'dataset', 'train', 'model', 'conquer', 'prediction', 'results', 'one', 'done', 'research', 'internet', 'deep', 'learning', 'algorithm', 'based', 'divide', 'conquer', 'seems', 'many', 'articles', 'correct', 'think', 'way', 'anyone', 'know', 'paper', 'thank', 'much']","['deep', 'learn', 'algorithm', 'base', 'divid', 'conquerd', 'huge', 'data', 'eg', 'long', 'video', 'dataset', 'problem', 'long', 'train', 'time', 'technic', 'use', 'distribut', 'deep', 'learn', 'solv', 'problem', 'robustli', 'idea', 'divid', 'dataset', 'small', 'set', 'train', 'model', 'use', 'model', 'predict', 'valu', 'featur', 'put', 'anoth', 'model', 'train', 'second', 'model', 'predict', 'output', 'like', 'divid', 'conquer', 'divid', 'dataset', 'train', 'model', 'conquer', 'predict', 'result', 'one', 'done', 'research', 'internet', 'deep', 'learn', 'algorithm', 'base', 'divid', 'conquer', 'seem', 'mani', 'articl', 'correct', 'think', 'way', 'anyon', 'know', 'paper', 'thank', 'much']"
323,352,352,thesofakillers,vr6v6s,[D] Does anyone here use Google's seqio library?,"In my research I recently came across this library from google:

[seqio: Task-based datasets, preprocessing, and evaluation for sequence models](https://github.com/google/seqio).

From the citation it seems it was released jointly with another library from google, [t5x](https://github.com/google-research/t5x).

From the paper and the docs, it sounds quite similar to huggingface's [datasets](https://github.com/huggingface/datasets) library, albeit perhaps slightly more opinionated. I was hoping to find a more thorough comparison with pre-existing dataloading/processing libraries but couldn't find one (they mostly focus on t5x in the paper). 

Has anyone here used it? What was your experience? To me it seems a bit redundant but I haven't been able to take a deeper dive

Thanks :)",0,2,2022-07-04 15:58:40, d  does anyone here use google s seqio library ,in my research i recently came across this library from google  seqio  task based datasets  preprocessing  and evaluation for sequence models  https from the citation it seems it was released jointly with another library from google   tx  https from the paper and the docs  it sounds quite similar to huggingface s  datasets  https has anyone here used it  what was your experience  to me it seems a bit redundant but i haven t been able to take a deeper divethanks   ,research recently came across library google seqio task based datasets preprocessing evaluation sequence models https citation seems released jointly another library google tx https paper docs sounds quite similar huggingface datasets https anyone used experience seems bit redundant able take deeper divethanks,anyone use google seqio library,anyone use google seqio libraryresearch recently came across library google seqio task based datasets preprocessing evaluation sequence models https citation seems released jointly another library google tx https paper docs sounds quite similar huggingface datasets https anyone used experience seems bit redundant able take deeper divethanks,"['anyone', 'use', 'google', 'seqio', 'libraryresearch', 'recently', 'came', 'across', 'library', 'google', 'seqio', 'task', 'based', 'datasets', 'preprocessing', 'evaluation', 'sequence', 'models', 'https', 'citation', 'seems', 'released', 'jointly', 'another', 'library', 'google', 'tx', 'https', 'paper', 'docs', 'sounds', 'quite', 'similar', 'huggingface', 'datasets', 'https', 'anyone', 'used', 'experience', 'seems', 'bit', 'redundant', 'able', 'take', 'deeper', 'divethanks']","['anyon', 'use', 'googl', 'seqio', 'libraryresearch', 'recent', 'came', 'across', 'librari', 'googl', 'seqio', 'task', 'base', 'dataset', 'preprocess', 'evalu', 'sequenc', 'model', 'http', 'citat', 'seem', 'releas', 'jointli', 'anoth', 'librari', 'googl', 'tx', 'http', 'paper', 'doc', 'sound', 'quit', 'similar', 'huggingfac', 'dataset', 'http', 'anyon', 'use', 'experi', 'seem', 'bit', 'redund', 'abl', 'take', 'deeper', 'divethank']"
324,353,353,bikeskata,vqo5hn,[R] Bayesian Vector Autoregression in PyMC,"A cool post (with code), detailing how to implement a Bayesian VAR in PyMC. This means no more hand-coding Gibbs Samplers!

Link: https://www.pymc-labs.io/blog-posts/bayesian-vector-autoregression/",4,25,2022-07-03 21:45:22, r  bayesian vector autoregression in pymc,a cool post  with code   detailing how to implement a bayesian var in pymc  this means no more hand coding gibbs samplers link  https   www pymc labs io blog posts bayesian vector autoregression ,cool post code detailing implement bayesian var pymc means hand coding gibbs samplers link https www pymc labs io blog posts bayesian vector autoregression,r bayesian vector autoregression pymc,r bayesian vector autoregression pymccool post code detailing implement bayesian var pymc means hand coding gibbs samplers link https www pymc labs io blog posts bayesian vector autoregression,"['r', 'bayesian', 'vector', 'autoregression', 'pymccool', 'post', 'code', 'detailing', 'implement', 'bayesian', 'var', 'pymc', 'means', 'hand', 'coding', 'gibbs', 'samplers', 'link', 'https', 'www', 'pymc', 'labs', 'io', 'blog', 'posts', 'bayesian', 'vector', 'autoregression']","['r', 'bayesian', 'vector', 'autoregress', 'pymccool', 'post', 'code', 'detail', 'implement', 'bayesian', 'var', 'pymc', 'mean', 'hand', 'code', 'gibb', 'sampler', 'link', 'http', 'www', 'pymc', 'lab', 'io', 'blog', 'post', 'bayesian', 'vector', 'autoregress']"
325,355,355,bitcoingobrrr,vqmj80,RL failure for Atari games (alignment) [Research]," I'm trying to find a paper (\~2019) that I heard in a talk regarding alignment in the context DQN/DDPG that was applied to an Atari-type game (Pong/Breakout). Apparently, the realization was that if an extra row of pixels was added to the frame, the algorithm fails. This might be a shot in the dark, but does anyone know which paper this would be?",5,12,2022-07-03 20:25:41,rl failure for atari games  alignment   research , i m trying to find a paper      that i heard in a talk regarding alignment in the context dqn ddpg that was applied to an atari type game  pong breakout   apparently  the realization was that if an extra row of pixels was added to the frame  the algorithm fails  this might be a shot in the dark  but does anyone know which paper this would be ,trying find paper heard talk regarding alignment context dqn ddpg applied atari type game pong breakout apparently realization extra row pixels added frame algorithm fails might shot dark anyone know paper would,rl failure atari games alignment research,rl failure atari games alignment researchtrying find paper heard talk regarding alignment context dqn ddpg applied atari type game pong breakout apparently realization extra row pixels added frame algorithm fails might shot dark anyone know paper would,"['rl', 'failure', 'atari', 'games', 'alignment', 'researchtrying', 'find', 'paper', 'heard', 'talk', 'regarding', 'alignment', 'context', 'dqn', 'ddpg', 'applied', 'atari', 'type', 'game', 'pong', 'breakout', 'apparently', 'realization', 'extra', 'row', 'pixels', 'added', 'frame', 'algorithm', 'fails', 'might', 'shot', 'dark', 'anyone', 'know', 'paper', 'would']","['rl', 'failur', 'atari', 'game', 'align', 'researchtri', 'find', 'paper', 'heard', 'talk', 'regard', 'align', 'context', 'dqn', 'ddpg', 'appli', 'atari', 'type', 'game', 'pong', 'breakout', 'appar', 'realiz', 'extra', 'row', 'pixel', 'ad', 'frame', 'algorithm', 'fail', 'might', 'shot', 'dark', 'anyon', 'know', 'paper', 'would']"
326,356,356,AutoModerator,vqjgxg,[D] Simple Questions Thread,"Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!

Thread will stay alive until next one so keep posting after the date in the title.

Thanks to everyone for answering questions in the previous thread!",124,14,2022-07-03 18:00:12, d  simple questions thread,please post your questions here instead of creating a new thread  encourage others who create new posts for questions to post here instead thread will stay alive until next one so keep posting after the date in the title thanks to everyone for answering questions in the previous thread ,please post questions instead creating thread encourage others create posts questions post instead thread stay alive next one keep posting date title thanks everyone answering questions previous thread,simple questions thread,simple questions threadplease post questions instead creating thread encourage others create posts questions post instead thread stay alive next one keep posting date title thanks everyone answering questions previous thread,"['simple', 'questions', 'threadplease', 'post', 'questions', 'instead', 'creating', 'thread', 'encourage', 'others', 'create', 'posts', 'questions', 'post', 'instead', 'thread', 'stay', 'alive', 'next', 'one', 'keep', 'posting', 'date', 'title', 'thanks', 'everyone', 'answering', 'questions', 'previous', 'thread']","['simpl', 'question', 'threadpleas', 'post', 'question', 'instead', 'creat', 'thread', 'encourag', 'other', 'creat', 'post', 'question', 'post', 'instead', 'thread', 'stay', 'aliv', 'next', 'one', 'keep', 'post', 'date', 'titl', 'thank', 'everyon', 'answer', 'question', 'previou', 'thread']"
327,359,359,davidmezzetti,vq6mll,[P] Generate webpage summary images with DALL-E mini,"&#x200B;

[Images generated with summarized Wikipedia article content](https://preview.redd.it/u5sjy6t5e9991.jpg?width=1306&format=pjpg&auto=webp&s=ee5e7a709ed02acc94b9c804078d94ca47cf8157)

This post presents a workflow to create webpage summary images with DALL-E mini. The workflow extracts text at a specified article, builds a summary and then generates an image for the summary text. The images above show output for a series of Wikipedia articles.

Full code links: [Notebook](https://colab.research.google.com/github/neuml/txtai/blob/master/examples/35_Pictures_are_worth_a_thousand_words.ipynb) | [GitHub](https://github.com/neuml/txtai)",0,23,2022-07-03 04:53:20, p  generate webpage summary images with dall e mini,  xb  images generated with summarized wikipedia article content  https this post presents a workflow to create webpage summary images with dall e mini  the workflow extracts text at a specified article  builds a summary and then generates an image for the summary text  the images above show output for a series of wikipedia articles full code links   notebook  https   colab research google com github neuml txtai blob master examples _pictures_are_worth_a_thousand_words ipynb     github  https   github com neuml txtai ,xb images generated summarized wikipedia article content https post presents workflow create webpage summary images dall e mini workflow extracts text specified article builds summary generates image summary text images show output series wikipedia articles full code links notebook https colab research google com github neuml txtai blob master examples _pictures_are_worth_a_thousand_words ipynb github https github com neuml txtai,p generate webpage summary images dall e mini,p generate webpage summary images dall e minixb images generated summarized wikipedia article content https post presents workflow create webpage summary images dall e mini workflow extracts text specified article builds summary generates image summary text images show output series wikipedia articles full code links notebook https colab research google com github neuml txtai blob master examples _pictures_are_worth_a_thousand_words ipynb github https github com neuml txtai,"['p', 'generate', 'webpage', 'summary', 'images', 'dall', 'e', 'minixb', 'images', 'generated', 'summarized', 'wikipedia', 'article', 'content', 'https', 'post', 'presents', 'workflow', 'create', 'webpage', 'summary', 'images', 'dall', 'e', 'mini', 'workflow', 'extracts', 'text', 'specified', 'article', 'builds', 'summary', 'generates', 'image', 'summary', 'text', 'images', 'show', 'output', 'series', 'wikipedia', 'articles', 'full', 'code', 'links', 'notebook', 'https', 'colab', 'research', 'google', 'com', 'github', 'neuml', 'txtai', 'blob', 'master', 'examples', '_pictures_are_worth_a_thousand_words', 'ipynb', 'github', 'https', 'github', 'com', 'neuml', 'txtai']","['p', 'gener', 'webpag', 'summari', 'imag', 'dall', 'e', 'minixb', 'imag', 'gener', 'summar', 'wikipedia', 'articl', 'content', 'http', 'post', 'present', 'workflow', 'creat', 'webpag', 'summari', 'imag', 'dall', 'e', 'mini', 'workflow', 'extract', 'text', 'specifi', 'articl', 'build', 'summari', 'gener', 'imag', 'summari', 'text', 'imag', 'show', 'output', 'seri', 'wikipedia', 'articl', 'full', 'code', 'link', 'notebook', 'http', 'colab', 'research', 'googl', 'com', 'github', 'neuml', 'txtai', 'blob', 'master', 'exampl', '_pictures_are_worth_a_thousand_word', 'ipynb', 'github', 'http', 'github', 'com', 'neuml', 'txtai']"
328,360,360,SnooPandas3529,vqyhh0,[D] Which U.S. universities are actively studying generative models?,"Although there are university rankings such as us news, it is difficult to find the universities that are good at a specific field one is interested in. We all know that Stanford and Berkeley are good at generative models, but what else? Please give me the name of university (+ the name of professor if possible) and the paper they published. It would be meaningful especially if the university is not very famous and their paper is outstanding.",4,0,2022-07-04 06:50:22, d  which u s  universities are actively studying generative models ,although there are university rankings such as us news  it is difficult to find the universities that are good at a specific field one is interested in  we all know that stanford and berkeley are good at generative models  but what else  please give me the name of university    the name of professor if possible  and the paper they published  it would be meaningful especially if the university is not very famous and their paper is outstanding ,although university rankings us news difficult find universities good specific field one interested know stanford berkeley good generative models else please give name university name professor possible paper published would meaningful especially university famous paper outstanding,u universities actively studying generative models,u universities actively studying generative modelsalthough university rankings us news difficult find universities good specific field one interested know stanford berkeley good generative models else please give name university name professor possible paper published would meaningful especially university famous paper outstanding,"['u', 'universities', 'actively', 'studying', 'generative', 'modelsalthough', 'university', 'rankings', 'us', 'news', 'difficult', 'find', 'universities', 'good', 'specific', 'field', 'one', 'interested', 'know', 'stanford', 'berkeley', 'good', 'generative', 'models', 'else', 'please', 'give', 'name', 'university', 'name', 'professor', 'possible', 'paper', 'published', 'would', 'meaningful', 'especially', 'university', 'famous', 'paper', 'outstanding']","['u', 'univers', 'activ', 'studi', 'gener', 'modelsalthough', 'univers', 'rank', 'us', 'news', 'difficult', 'find', 'univers', 'good', 'specif', 'field', 'one', 'interest', 'know', 'stanford', 'berkeley', 'good', 'gener', 'model', 'els', 'pleas', 'give', 'name', 'univers', 'name', 'professor', 'possibl', 'paper', 'publish', 'would', 'meaning', 'especi', 'univers', 'famou', 'paper', 'outstand']"
329,361,361,JsonPun,vq4s1l,[D][P]How to train a YOLOv6 model with custom dataset," Roboflow created a guide on how to train a new model with the new YOLOv6 (whether it should be called that is another topic)

I thought this could be useful for anyone wanting to test it out. What do other think of this ""new"" model?

Tutorial on how to train YOLOv6 on a custom dataset: [https://blog.roboflow.com/how-to-train-yolov6-on-a-custom-dataset/](https://blog.roboflow.com/how-to-train-yolov6-on-a-custom-dataset/)

Here is the Colab notebook tutorial: [https://colab.research.google.com/drive/1YnbqOinBZV-c9I7fk\_UL6acgnnmkXDMM](https://colab.research.google.com/drive/1YnbqOinBZV-c9I7fk_UL6acgnnmkXDMM)

The YOLOv6 repo: [https://github.com/meituan/YOLOv6](https://github.com/meituan/YOLOv6)

Has anyone else tried using this?  MT-YOLOv6 (or as the authors say) ""YOLOv6 for brevity"" was released in June, and says it outperforms YOLOv5 and YOLOX on the COCO benchmark. I plan to do some testing this upcoming week to see",0,12,2022-07-03 03:08:41, d  p how to train a yolov model with custom dataset, roboflow created a guide on how to train a new model with the new yolov  whether it should be called that is another topic i thought this could be useful for anyone wanting to test it out  what do other think of this new model tutorial on how to train yolov on a custom dataset   https here is the colab notebook tutorial   https the yolov repo   https has anyone else tried using this   mt yolov  or as the authors say  yolov for brevity was released in june  and says it outperforms yolov and yolox on the coco benchmark  i plan to do some testing this upcoming week to see,roboflow created guide train model yolov whether called another topic thought could useful anyone wanting test think model tutorial train yolov dataset https colab notebook tutorial https yolov repo https anyone else tried using mt yolov authors say yolov brevity released june says outperforms yolov yolox coco benchmark plan testing upcoming week see,p train yolov model dataset,p train yolov model datasetroboflow created guide train model yolov whether called another topic thought could useful anyone wanting test think model tutorial train yolov dataset https colab notebook tutorial https yolov repo https anyone else tried using mt yolov authors say yolov brevity released june says outperforms yolov yolox coco benchmark plan testing upcoming week see,"['p', 'train', 'yolov', 'model', 'datasetroboflow', 'created', 'guide', 'train', 'model', 'yolov', 'whether', 'called', 'another', 'topic', 'thought', 'could', 'useful', 'anyone', 'wanting', 'test', 'think', 'model', 'tutorial', 'train', 'yolov', 'dataset', 'https', 'colab', 'notebook', 'tutorial', 'https', 'yolov', 'repo', 'https', 'anyone', 'else', 'tried', 'using', 'mt', 'yolov', 'authors', 'say', 'yolov', 'brevity', 'released', 'june', 'says', 'outperforms', 'yolov', 'yolox', 'coco', 'benchmark', 'plan', 'testing', 'upcoming', 'week', 'see']","['p', 'train', 'yolov', 'model', 'datasetroboflow', 'creat', 'guid', 'train', 'model', 'yolov', 'whether', 'call', 'anoth', 'topic', 'thought', 'could', 'use', 'anyon', 'want', 'test', 'think', 'model', 'tutori', 'train', 'yolov', 'dataset', 'http', 'colab', 'notebook', 'tutori', 'http', 'yolov', 'repo', 'http', 'anyon', 'els', 'tri', 'use', 'mt', 'yolov', 'author', 'say', 'yolov', 'breviti', 'releas', 'june', 'say', 'outperform', 'yolov', 'yolox', 'coco', 'benchmark', 'plan', 'test', 'upcom', 'week', 'see']"
330,363,363,leepenkman,vqcd0e,[D] Prompt Engineering Tips?,"Any prompt engineering tips out there?  


Recently saw some good tips for Dalle style text to image generation where you tak on ""unreal engine"" or ""vray"" at the end to make something look like a photorealistic render :D   


Theres some tips specific to generating text: [https://textgenerator.app.nz/blog/prompt-tuning-tips](https://textgenerator.app.nz/blog/prompt-tuning-tips)  


I also heard there's simple ways to get better logical correctness from networks like ""Answering as a careful math professior explaining my reasoning: ""  


I'm really surprised at the breadth of problems solvable without actually training networks just by prompt tuning, it reminds me of algorithmic problem reductions where you map a problem to text and back again to solve it.  


Are there some other good hacks/battle tested tricks or places to collect info about prompt tuning?",2,3,2022-07-03 10:46:44, d  prompt engineering tips ,any prompt engineering tips out there   recently saw some good tips for dalle style text to image generation where you tak on unreal engine or vray at the end to make something look like a photorealistic render  d   theres some tips specific to generating text   https i also heard there s simple ways to get better logical correctness from networks like answering as a careful math professior explaining my reasoning    i m really surprised at the breadth of problems solvable without actually training networks just by prompt tuning  it reminds me of algorithmic problem reductions where you map a problem to text and back again to solve it   are there some other good hacks battle tested tricks or places to collect info about prompt tuning ,prompt engineering tips recently saw good tips dalle style text image generation tak unreal engine vray end make something look like photorealistic render theres tips specific generating text https also heard simple ways get better logical correctness networks like answering careful math professior explaining reasoning really surprised breadth problems solvable without actually training networks prompt tuning reminds algorithmic problem reductions map problem text back solve good hacks battle tested tricks places collect info prompt tuning,prompt engineering tips,prompt engineering tipsprompt engineering tips recently saw good tips dalle style text image generation tak unreal engine vray end make something look like photorealistic render theres tips specific generating text https also heard simple ways get better logical correctness networks like answering careful math professior explaining reasoning really surprised breadth problems solvable without actually training networks prompt tuning reminds algorithmic problem reductions map problem text back solve good hacks battle tested tricks places collect info prompt tuning,"['prompt', 'engineering', 'tipsprompt', 'engineering', 'tips', 'recently', 'saw', 'good', 'tips', 'dalle', 'style', 'text', 'image', 'generation', 'tak', 'unreal', 'engine', 'vray', 'end', 'make', 'something', 'look', 'like', 'photorealistic', 'render', 'theres', 'tips', 'specific', 'generating', 'text', 'https', 'also', 'heard', 'simple', 'ways', 'get', 'better', 'logical', 'correctness', 'networks', 'like', 'answering', 'careful', 'math', 'professior', 'explaining', 'reasoning', 'really', 'surprised', 'breadth', 'problems', 'solvable', 'without', 'actually', 'training', 'networks', 'prompt', 'tuning', 'reminds', 'algorithmic', 'problem', 'reductions', 'map', 'problem', 'text', 'back', 'solve', 'good', 'hacks', 'battle', 'tested', 'tricks', 'places', 'collect', 'info', 'prompt', 'tuning']","['prompt', 'engin', 'tipsprompt', 'engin', 'tip', 'recent', 'saw', 'good', 'tip', 'dall', 'style', 'text', 'imag', 'gener', 'tak', 'unreal', 'engin', 'vray', 'end', 'make', 'someth', 'look', 'like', 'photorealist', 'render', 'there', 'tip', 'specif', 'gener', 'text', 'http', 'also', 'heard', 'simpl', 'way', 'get', 'better', 'logic', 'correct', 'network', 'like', 'answer', 'care', 'math', 'professior', 'explain', 'reason', 'realli', 'surpris', 'breadth', 'problem', 'solvabl', 'without', 'actual', 'train', 'network', 'prompt', 'tune', 'remind', 'algorithm', 'problem', 'reduct', 'map', 'problem', 'text', 'back', 'solv', 'good', 'hack', 'battl', 'test', 'trick', 'place', 'collect', 'info', 'prompt', 'tune']"
331,364,364,FedEx33,vpwfax,[P] PyTorch implementation of MobileOne (An Improved One millisecond Mobile Backbone),"I want to share the PyTorch implementation of ""An Improved One millisecond Mobile Backbone"" paper.

Unfortunately, I don't have the appropriate computational resources to train the models on ImageNet, so feel free to use my implementation for that purpose.

Hope you all find it useful, feedback would be appreciated.

Repository: [https://github.com/federicopozzi33/MobileOne-PyTorch](https://github.com/federicopozzi33/MobileOne-PyTorch)

Paper: [https://arxiv.org/abs/2206.04040](https://arxiv.org/abs/2206.04040)",4,19,2022-07-02 20:13:10, p  pytorch implementation of mobileone  an improved one millisecond mobile backbone ,i want to share the pytorch implementation of an improved one millisecond mobile backbone paper unfortunately  i don t have the appropriate computational resources to train the models on imagenet  so feel free to use my implementation for that purpose hope you all find it useful  feedback would be appreciated repository   https paper   https   arxiv org abs    https   arxiv org abs   ,want share pytorch implementation improved one millisecond mobile backbone paper unfortunately appropriate computational resources train models imagenet feel free use implementation purpose hope find useful feedback would appreciated repository https paper https arxiv org abs https arxiv org abs,p pytorch implementation mobileone improved one millisecond mobile backbone,p pytorch implementation mobileone improved one millisecond mobile backbonewant share pytorch implementation improved one millisecond mobile backbone paper unfortunately appropriate computational resources train models imagenet feel free use implementation purpose hope find useful feedback would appreciated repository https paper https arxiv org abs https arxiv org abs,"['p', 'pytorch', 'implementation', 'mobileone', 'improved', 'one', 'millisecond', 'mobile', 'backbonewant', 'share', 'pytorch', 'implementation', 'improved', 'one', 'millisecond', 'mobile', 'backbone', 'paper', 'unfortunately', 'appropriate', 'computational', 'resources', 'train', 'models', 'imagenet', 'feel', 'free', 'use', 'implementation', 'purpose', 'hope', 'find', 'useful', 'feedback', 'would', 'appreciated', 'repository', 'https', 'paper', 'https', 'arxiv', 'org', 'abs', 'https', 'arxiv', 'org', 'abs']","['p', 'pytorch', 'implement', 'mobileon', 'improv', 'one', 'millisecond', 'mobil', 'backbonew', 'share', 'pytorch', 'implement', 'improv', 'one', 'millisecond', 'mobil', 'backbon', 'paper', 'unfortun', 'appropri', 'comput', 'resourc', 'train', 'model', 'imagenet', 'feel', 'free', 'use', 'implement', 'purpos', 'hope', 'find', 'use', 'feedback', 'would', 'appreci', 'repositori', 'http', 'paper', 'http', 'arxiv', 'org', 'ab', 'http', 'arxiv', 'org', 'ab']"
332,365,365,londons_explorer,vpn0r1,[D] Has anyone got YaLM-100B to run?,"The community has been asking for big opensource language models for a while...

And now one has been released - YaLM-100B.   That was 2 weeks ago.  Yet, as far as I can see, not many people have it running.    There are no online demos.  There are no articles of journalists trying it out.  There are no efforts for fine tuning or people working on prompts for various usecases.


Is it the RAM requirements?   Is there no interest because it's from Russia?  Something else?",37,92,2022-07-02 11:23:31, d  has anyone got yalm b to run ,the community has been asking for big opensource language models for a while   and now one has been released   yalm b    that was  weeks ago   yet  as far as i can see  not many people have it running     there are no online demos   there are no articles of journalists trying it out   there are no efforts for fine tuning or people working on prompts for various usecases is it the ram requirements    is there no interest because it s from russia   something else ,community asking big opensource language models one released yalm b weeks ago yet far see many people running online demos articles journalists trying efforts fine tuning people working prompts various usecases ram requirements interest russia something else,anyone got yalm b run,anyone got yalm b runcommunity asking big opensource language models one released yalm b weeks ago yet far see many people running online demos articles journalists trying efforts fine tuning people working prompts various usecases ram requirements interest russia something else,"['anyone', 'got', 'yalm', 'b', 'runcommunity', 'asking', 'big', 'opensource', 'language', 'models', 'one', 'released', 'yalm', 'b', 'weeks', 'ago', 'yet', 'far', 'see', 'many', 'people', 'running', 'online', 'demos', 'articles', 'journalists', 'trying', 'efforts', 'fine', 'tuning', 'people', 'working', 'prompts', 'various', 'usecases', 'ram', 'requirements', 'interest', 'russia', 'something', 'else']","['anyon', 'got', 'yalm', 'b', 'runcommun', 'ask', 'big', 'opensourc', 'languag', 'model', 'one', 'releas', 'yalm', 'b', 'week', 'ago', 'yet', 'far', 'see', 'mani', 'peopl', 'run', 'onlin', 'demo', 'articl', 'journalist', 'tri', 'effort', 'fine', 'tune', 'peopl', 'work', 'prompt', 'variou', 'usecas', 'ram', 'requir', 'interest', 'russia', 'someth', 'els']"
333,367,367,KalloDotIO,vpu0qx,[Project] Extracting training data from websites at scale," 

I built an API that takes away the work of scraping structured data from websites. This could be collating house prices in a certain geo, tracking viewer counts across a Youtube/Social media, or a common use case: daily monitoring prices on a site. Send it a URL, get back a JSON with tabular data. Takes away a lot of the data cleaning work which is the worst!

API Spec: [https://kallo.io/wp-content/uploads/2022/06/Kallo-API-Specification-v0.1.3.pdf](https://kallo.io/wp-content/uploads/2022/06/Kallo-API-Specification-v0.1.3.pdf)

Right now I'm using it to track prices on a number of sites to monitor the rising inflation.

Happy to get many more people using it for ML projects and collaborating! Please give me feedback

Learn more on our page: [https://kallo.io](https://kallo.io/)",0,7,2022-07-02 18:19:16, project  extracting training data from websites at scale, i built an api that takes away the work of scraping structured data from websites  this could be collating house prices in a certain geo  tracking viewer counts across a youtube social media  or a common use case  daily monitoring prices on a site  send it a url  get back a json with tabular data  takes away a lot of the data cleaning work which is the worst api spec   https right now i m using it to track prices on a number of sites to monitor the rising inflation happy to get many more people using it for ml projects and collaborating  please give me feedbacklearn more on our page   https   kallo io  https   kallo io  ,built api takes away work scraping structured data websites could collating house prices certain geo tracking viewer counts across youtube social media common use case daily monitoring prices site send url get back json tabular data takes away lot data cleaning work worst api spec https right using track prices number sites monitor rising inflation happy get many people using ml projects collaborating please give feedbacklearn page https kallo io https kallo io,project extracting training data websites scale,project extracting training data websites scalebuilt api takes away work scraping structured data websites could collating house prices certain geo tracking viewer counts across youtube social media common use case daily monitoring prices site send url get back json tabular data takes away lot data cleaning work worst api spec https right using track prices number sites monitor rising inflation happy get many people using ml projects collaborating please give feedbacklearn page https kallo io https kallo io,"['project', 'extracting', 'training', 'data', 'websites', 'scalebuilt', 'api', 'takes', 'away', 'work', 'scraping', 'structured', 'data', 'websites', 'could', 'collating', 'house', 'prices', 'certain', 'geo', 'tracking', 'viewer', 'counts', 'across', 'youtube', 'social', 'media', 'common', 'use', 'case', 'daily', 'monitoring', 'prices', 'site', 'send', 'url', 'get', 'back', 'json', 'tabular', 'data', 'takes', 'away', 'lot', 'data', 'cleaning', 'work', 'worst', 'api', 'spec', 'https', 'right', 'using', 'track', 'prices', 'number', 'sites', 'monitor', 'rising', 'inflation', 'happy', 'get', 'many', 'people', 'using', 'ml', 'projects', 'collaborating', 'please', 'give', 'feedbacklearn', 'page', 'https', 'kallo', 'io', 'https', 'kallo', 'io']","['project', 'extract', 'train', 'data', 'websit', 'scalebuilt', 'api', 'take', 'away', 'work', 'scrape', 'structur', 'data', 'websit', 'could', 'collat', 'hous', 'price', 'certain', 'geo', 'track', 'viewer', 'count', 'across', 'youtub', 'social', 'media', 'common', 'use', 'case', 'daili', 'monitor', 'price', 'site', 'send', 'url', 'get', 'back', 'json', 'tabular', 'data', 'take', 'away', 'lot', 'data', 'clean', 'work', 'worst', 'api', 'spec', 'http', 'right', 'use', 'track', 'price', 'number', 'site', 'monitor', 'rise', 'inflat', 'happi', 'get', 'mani', 'peopl', 'use', 'ml', 'project', 'collabor', 'pleas', 'give', 'feedbacklearn', 'page', 'http', 'kallo', 'io', 'http', 'kallo', 'io']"
334,368,368,leepenkman,vq5o75,[P] 20 Questions - with AI,"I created [https://www.addictingwordgames.com/play-game/20-questions-with-ai](https://www.addictingwordgames.com/play-game/20-questions-with-ai)   


The aim of the game was supposed to be to get the AI to confess that you are the winner, its possible but the game is also open ended.

&#x200B;

The backend generation is from [https://TextGenerator.](https://TextGenerator.app.nz)[app.nz](https://TextGenerator.app.nz) which is heaps cheaper than the OpenAI models, but quality is i think somewhere between OpenAI currie and babbage.  


In the prompt engineering theres some random topics picked that the user wont see, (that doesn't mean that the AI actually does think of that topic though).  


Theres also some retries and repetition penalty randomness that goes up to stop looping which i think is a problem in all models right now.  


in comparison to OpenAI the Text Generator API was easier to use because you can send max\_sentences=1 and it will give you 1 sentence instead of trying to work out the sentence boundaries with the stop sequences (which is also supported but i dont find that as easy to work with)",0,1,2022-07-03 03:59:00, p   questions   with ai,i created  https the aim of the game was supposed to be to get the ai to confess that you are the winner  its possible but the game is also open ended   xb the backend generation is from  https in the prompt engineering theres some random topics picked that the user wont see   that doesn t mean that the ai actually does think of that topic though    theres also some retries and repetition penalty randomness that goes up to stop looping which i think is a problem in all models right now   in comparison to openai the text generator api was easier to use because you can send max _sentences  and it will give you  sentence instead of trying to work out the sentence boundaries with the stop sequences  which is also supported but i dont find that as easy to work with ,created https aim game supposed get ai confess winner possible game also open ended xb backend generation https prompt engineering theres random topics picked user wont see mean ai actually think topic though theres also retries repetition penalty randomness goes stop looping think problem models right comparison openai text generator api easier use send max _sentences give sentence instead trying work sentence boundaries stop sequences also supported dont find easy work,p questions ai,p questions aicreated https aim game supposed get ai confess winner possible game also open ended xb backend generation https prompt engineering theres random topics picked user wont see mean ai actually think topic though theres also retries repetition penalty randomness goes stop looping think problem models right comparison openai text generator api easier use send max _sentences give sentence instead trying work sentence boundaries stop sequences also supported dont find easy work,"['p', 'questions', 'aicreated', 'https', 'aim', 'game', 'supposed', 'get', 'ai', 'confess', 'winner', 'possible', 'game', 'also', 'open', 'ended', 'xb', 'backend', 'generation', 'https', 'prompt', 'engineering', 'theres', 'random', 'topics', 'picked', 'user', 'wont', 'see', 'mean', 'ai', 'actually', 'think', 'topic', 'though', 'theres', 'also', 'retries', 'repetition', 'penalty', 'randomness', 'goes', 'stop', 'looping', 'think', 'problem', 'models', 'right', 'comparison', 'openai', 'text', 'generator', 'api', 'easier', 'use', 'send', 'max', '_sentences', 'give', 'sentence', 'instead', 'trying', 'work', 'sentence', 'boundaries', 'stop', 'sequences', 'also', 'supported', 'dont', 'find', 'easy', 'work']","['p', 'question', 'aicreat', 'http', 'aim', 'game', 'suppos', 'get', 'ai', 'confess', 'winner', 'possibl', 'game', 'also', 'open', 'end', 'xb', 'backend', 'gener', 'http', 'prompt', 'engin', 'there', 'random', 'topic', 'pick', 'user', 'wont', 'see', 'mean', 'ai', 'actual', 'think', 'topic', 'though', 'there', 'also', 'retri', 'repetit', 'penalti', 'random', 'goe', 'stop', 'loop', 'think', 'problem', 'model', 'right', 'comparison', 'openai', 'text', 'gener', 'api', 'easier', 'use', 'send', 'max', '_sentenc', 'give', 'sentenc', 'instead', 'tri', 'work', 'sentenc', 'boundari', 'stop', 'sequenc', 'also', 'support', 'dont', 'find', 'easi', 'work']"
335,369,369,soulful_squirrel,vpkpa2,[D] Recurrent neural network vs Gradient boosting for time series prediction,"Does anyone have any opinions on the pros vs. cons of using an RNN vs. a Gradient Boosting Tree model for a task where we want to make daily predictions on whether a user (of some app) is likely to take a certain type of action (so like binary classification)  in the near future ?

Pros for RNN:

* can take advantage of historical data to greater effect without extensive feature engineering
* I believe RNN's are more effective in situations when one has a large # of high dimensional features compared to the feature selection method tree models use
* neural networks scale better with large amounts of data

Cons of RNN:

* my main concern is with infrastructural complexity and cost that comes with training and serving the RNN.  I'll probably need a GPU or several GPU's.  Not sure if this is feasible given the current size of the company",23,23,2022-07-02 08:44:41, d  recurrent neural network vs gradient boosting for time series prediction,does anyone have any opinions on the pros vs  cons of using an rnn vs  a gradient boosting tree model for a task where we want to make daily predictions on whether a user  of some app  is likely to take a certain type of action  so like binary classification   in the near future  pros for rnn   can take advantage of historical data to greater effect without extensive feature engineering  i believe rnn s are more effective in situations when one has a large   of high dimensional features compared to the feature selection method tree models use  neural networks scale better with large amounts of datacons of rnn   my main concern is with infrastructural complexity and cost that comes with training and serving the rnn   i ll probably need a gpu or several gpu s   not sure if this is feasible given the current size of the company,anyone opinions pros vs cons using rnn vs gradient boosting tree model task want make daily predictions whether user app likely take certain type action like binary classification near future pros rnn take advantage historical data greater effect without extensive feature engineering believe rnn effective situations one large high dimensional features compared feature selection method tree models use neural networks scale better large amounts datacons rnn main concern infrastructural complexity cost comes training serving rnn probably need gpu several gpu sure feasible given current size company,recurrent neural network vs gradient boosting time series prediction,recurrent neural network vs gradient boosting time series predictionanyone opinions pros vs cons using rnn vs gradient boosting tree model task want make daily predictions whether user app likely take certain type action like binary classification near future pros rnn take advantage historical data greater effect without extensive feature engineering believe rnn effective situations one large high dimensional features compared feature selection method tree models use neural networks scale better large amounts datacons rnn main concern infrastructural complexity cost comes training serving rnn probably need gpu several gpu sure feasible given current size company,"['recurrent', 'neural', 'network', 'vs', 'gradient', 'boosting', 'time', 'series', 'predictionanyone', 'opinions', 'pros', 'vs', 'cons', 'using', 'rnn', 'vs', 'gradient', 'boosting', 'tree', 'model', 'task', 'want', 'make', 'daily', 'predictions', 'whether', 'user', 'app', 'likely', 'take', 'certain', 'type', 'action', 'like', 'binary', 'classification', 'near', 'future', 'pros', 'rnn', 'take', 'advantage', 'historical', 'data', 'greater', 'effect', 'without', 'extensive', 'feature', 'engineering', 'believe', 'rnn', 'effective', 'situations', 'one', 'large', 'high', 'dimensional', 'features', 'compared', 'feature', 'selection', 'method', 'tree', 'models', 'use', 'neural', 'networks', 'scale', 'better', 'large', 'amounts', 'datacons', 'rnn', 'main', 'concern', 'infrastructural', 'complexity', 'cost', 'comes', 'training', 'serving', 'rnn', 'probably', 'need', 'gpu', 'several', 'gpu', 'sure', 'feasible', 'given', 'current', 'size', 'company']","['recurr', 'neural', 'network', 'vs', 'gradient', 'boost', 'time', 'seri', 'predictionanyon', 'opinion', 'pro', 'vs', 'con', 'use', 'rnn', 'vs', 'gradient', 'boost', 'tree', 'model', 'task', 'want', 'make', 'daili', 'predict', 'whether', 'user', 'app', 'like', 'take', 'certain', 'type', 'action', 'like', 'binari', 'classif', 'near', 'futur', 'pro', 'rnn', 'take', 'advantag', 'histor', 'data', 'greater', 'effect', 'without', 'extens', 'featur', 'engin', 'believ', 'rnn', 'effect', 'situat', 'one', 'larg', 'high', 'dimension', 'featur', 'compar', 'featur', 'select', 'method', 'tree', 'model', 'use', 'neural', 'network', 'scale', 'better', 'larg', 'amount', 'datacon', 'rnn', 'main', 'concern', 'infrastructur', 'complex', 'cost', 'come', 'train', 'serv', 'rnn', 'probabl', 'need', 'gpu', 'sever', 'gpu', 'sure', 'feasibl', 'given', 'current', 'size', 'compani']"
336,370,370,EnricoShippole,vpbp9j,[P] Open-source LaMDA Model,"An open-source implementation for the pre-training architecture of Google's LaMDA in PyTorch. The research paper outlines an autoregressive, decoder-only, GPT-like transformer language model. The transformer uses T5 relative positional bias in the attention layers and gated-GELU activation function in the feed-forward layers. 

The repository currently contains a script for basic training as well as Huggingface datasets and Weights & Biases integration.

LaMDA research paper: [https://arxiv.org/abs/2201.08239](https://arxiv.org/abs/2201.08239)

Github repository for the model: [https://github.com/conceptofmind/LaMDA-pytorch](https://github.com/conceptofmind/LaMDA-pytorch)

The pre-training architecture was peer-reviewed by Dr. Phil Wang. Please check out and support his work: [https://github.com/lucidrains](https://github.com/lucidrains).",3,98,2022-07-02 00:37:00, p  open source lamda model,an open source implementation for the pre training architecture of google s lamda in pytorch  the research paper outlines an autoregressive  decoder only  gpt like transformer language model  the transformer uses t relative positional bias in the attention layers and gated gelu activation function in the feed forward layers  the repository currently contains a script for basic training as well as huggingface datasets and weights   biases integration lamda research paper   https github repository for the model   https the pre training architecture was peer reviewed by dr  phil wang  please check out and support his work   https   github com lucidrains  https   github com lucidrains  ,open source implementation pre training architecture google lamda pytorch research paper outlines autoregressive decoder gpt like transformer language model transformer uses relative positional bias attention layers gated gelu activation function feed forward layers repository currently contains script basic training well huggingface datasets weights biases integration lamda research paper https github repository model https pre training architecture peer reviewed dr phil wang please check support work https github com lucidrains https github com lucidrains,p open source lamda model,p open source lamda modelopen source implementation pre training architecture google lamda pytorch research paper outlines autoregressive decoder gpt like transformer language model transformer uses relative positional bias attention layers gated gelu activation function feed forward layers repository currently contains script basic training well huggingface datasets weights biases integration lamda research paper https github repository model https pre training architecture peer reviewed dr phil wang please check support work https github com lucidrains https github com lucidrains,"['p', 'open', 'source', 'lamda', 'modelopen', 'source', 'implementation', 'pre', 'training', 'architecture', 'google', 'lamda', 'pytorch', 'research', 'paper', 'outlines', 'autoregressive', 'decoder', 'gpt', 'like', 'transformer', 'language', 'model', 'transformer', 'uses', 'relative', 'positional', 'bias', 'attention', 'layers', 'gated', 'gelu', 'activation', 'function', 'feed', 'forward', 'layers', 'repository', 'currently', 'contains', 'script', 'basic', 'training', 'well', 'huggingface', 'datasets', 'weights', 'biases', 'integration', 'lamda', 'research', 'paper', 'https', 'github', 'repository', 'model', 'https', 'pre', 'training', 'architecture', 'peer', 'reviewed', 'dr', 'phil', 'wang', 'please', 'check', 'support', 'work', 'https', 'github', 'com', 'lucidrains', 'https', 'github', 'com', 'lucidrains']","['p', 'open', 'sourc', 'lamda', 'modelopen', 'sourc', 'implement', 'pre', 'train', 'architectur', 'googl', 'lamda', 'pytorch', 'research', 'paper', 'outlin', 'autoregress', 'decod', 'gpt', 'like', 'transform', 'languag', 'model', 'transform', 'use', 'rel', 'posit', 'bia', 'attent', 'layer', 'gate', 'gelu', 'activ', 'function', 'feed', 'forward', 'layer', 'repositori', 'current', 'contain', 'script', 'basic', 'train', 'well', 'huggingfac', 'dataset', 'weight', 'bias', 'integr', 'lamda', 'research', 'paper', 'http', 'github', 'repositori', 'model', 'http', 'pre', 'train', 'architectur', 'peer', 'review', 'dr', 'phil', 'wang', 'pleas', 'check', 'support', 'work', 'http', 'github', 'com', 'lucidrain', 'http', 'github', 'com', 'lucidrain']"
337,371,371,metalvendetta,vpphdb,[D] Monitoring GPU Power Usage,"Came across an interesting [article](https://wandb.ai/site/articles/deep-learning-and-climate-change) which talks precisely about how the gpu power usage affects the carbon footprint, while doing model training and model inference. Which are the best tools in the industry which helps track GPU power usage in popular machine learning frameworks? It will be helpful if there are tools which can be used as plugins to your software.",9,7,2022-07-02 14:11:51, d  monitoring gpu power usage,came across an interesting  article  https   wandb ai site articles deep learning and climate change  which talks precisely about how the gpu power usage affects the carbon footprint  while doing model training and model inference  which are the best tools in the industry which helps track gpu power usage in popular machine learning frameworks  it will be helpful if there are tools which can be used as plugins to your software ,came across interesting article https wandb ai site articles deep learning climate change talks precisely gpu power usage affects carbon footprint model training model inference best tools industry helps track gpu power usage popular machine learning frameworks helpful tools used plugins software,monitoring gpu power usage,monitoring gpu power usagecame across interesting article https wandb ai site articles deep learning climate change talks precisely gpu power usage affects carbon footprint model training model inference best tools industry helps track gpu power usage popular machine learning frameworks helpful tools used plugins software,"['monitoring', 'gpu', 'power', 'usagecame', 'across', 'interesting', 'article', 'https', 'wandb', 'ai', 'site', 'articles', 'deep', 'learning', 'climate', 'change', 'talks', 'precisely', 'gpu', 'power', 'usage', 'affects', 'carbon', 'footprint', 'model', 'training', 'model', 'inference', 'best', 'tools', 'industry', 'helps', 'track', 'gpu', 'power', 'usage', 'popular', 'machine', 'learning', 'frameworks', 'helpful', 'tools', 'used', 'plugins', 'software']","['monitor', 'gpu', 'power', 'usagecam', 'across', 'interest', 'articl', 'http', 'wandb', 'ai', 'site', 'articl', 'deep', 'learn', 'climat', 'chang', 'talk', 'precis', 'gpu', 'power', 'usag', 'affect', 'carbon', 'footprint', 'model', 'train', 'model', 'infer', 'best', 'tool', 'industri', 'help', 'track', 'gpu', 'power', 'usag', 'popular', 'machin', 'learn', 'framework', 'help', 'tool', 'use', 'plugin', 'softwar']"
338,372,372,radi-cho,vprmgc,[P] One word only: GPT-based story game,"For fun I developed an interface for the drama game in which a story is told one word at a time. Instead of playing it with a friend you can now play it together with GPT-J.

It is available here: [https://one-word-only.web.app/](https://one-word-only.web.app/singleplayer)  
I am open to feedback and if you find it interesting you can share the result on social media with #OneWordOnly",8,4,2022-07-02 16:17:58, p  one word only  gpt based story game,for fun i developed an interface for the drama game in which a story is told one word at a time  instead of playing it with a friend you can now play it together with gpt j it is available here   https i am open to feedback and if you find it interesting you can share the result on social media with  onewordonly,fun developed interface drama game story told one word time instead playing friend play together gpt j available https open feedback find interesting share result social media onewordonly,p one word gpt based story game,p one word gpt based story gamefun developed interface drama game story told one word time instead playing friend play together gpt j available https open feedback find interesting share result social media onewordonly,"['p', 'one', 'word', 'gpt', 'based', 'story', 'gamefun', 'developed', 'interface', 'drama', 'game', 'story', 'told', 'one', 'word', 'time', 'instead', 'playing', 'friend', 'play', 'together', 'gpt', 'j', 'available', 'https', 'open', 'feedback', 'find', 'interesting', 'share', 'result', 'social', 'media', 'onewordonly']","['p', 'one', 'word', 'gpt', 'base', 'stori', 'gamefun', 'develop', 'interfac', 'drama', 'game', 'stori', 'told', 'one', 'word', 'time', 'instead', 'play', 'friend', 'play', 'togeth', 'gpt', 'j', 'avail', 'http', 'open', 'feedback', 'find', 'interest', 'share', 'result', 'social', 'media', 'onewordonli']"
339,373,373,TernaryJimbo,vpyv76,[D] Algorithm for view prediction," I would like to do view prediction for short videos based on the first few frames of the video. No audio, just images. I'm hoping to train a model that can take in the first n sequential frames as input, and output a score that correlates to how many views the model thinks the vid might get.

I know I would like to use grad-CAM [https://github.com/jacobgil/pytorch-grad-cam](https://github.com/jacobgil/pytorch-grad-cam)

to visualize the areas in the frames which the model thinks results in higher view score.

Would a vision transformer or CNN be better for this task?

Also are there any pre-trained networks like YOLO that I should use transfer learning on to reduce the amount of data I will need for these predictions?",1,0,2022-07-02 22:12:00, d  algorithm for view prediction, i would like to do view prediction for short videos based on the first few frames of the video  no audio  just images  i m hoping to train a model that can take in the first n sequential frames as input  and output a score that correlates to how many views the model thinks the vid might get i know i would like to use grad cam  https to visualize the areas in the frames which the model thinks results in higher view score would a vision transformer or cnn be better for this task also are there any pre trained networks like yolo that i should use transfer learning on to reduce the amount of data i will need for these predictions ,would like view prediction short videos based first frames video audio images hoping train model take first n sequential frames input output score correlates many views model thinks vid might get know would like use grad cam https visualize areas frames model thinks results higher view score would vision transformer cnn better task also pre trained networks like yolo use transfer learning reduce amount data need predictions,algorithm view prediction,algorithm view predictionwould like view prediction short videos based first frames video audio images hoping train model take first n sequential frames input output score correlates many views model thinks vid might get know would like use grad cam https visualize areas frames model thinks results higher view score would vision transformer cnn better task also pre trained networks like yolo use transfer learning reduce amount data need predictions,"['algorithm', 'view', 'predictionwould', 'like', 'view', 'prediction', 'short', 'videos', 'based', 'first', 'frames', 'video', 'audio', 'images', 'hoping', 'train', 'model', 'take', 'first', 'n', 'sequential', 'frames', 'input', 'output', 'score', 'correlates', 'many', 'views', 'model', 'thinks', 'vid', 'might', 'get', 'know', 'would', 'like', 'use', 'grad', 'cam', 'https', 'visualize', 'areas', 'frames', 'model', 'thinks', 'results', 'higher', 'view', 'score', 'would', 'vision', 'transformer', 'cnn', 'better', 'task', 'also', 'pre', 'trained', 'networks', 'like', 'yolo', 'use', 'transfer', 'learning', 'reduce', 'amount', 'data', 'need', 'predictions']","['algorithm', 'view', 'predictionwould', 'like', 'view', 'predict', 'short', 'video', 'base', 'first', 'frame', 'video', 'audio', 'imag', 'hope', 'train', 'model', 'take', 'first', 'n', 'sequenti', 'frame', 'input', 'output', 'score', 'correl', 'mani', 'view', 'model', 'think', 'vid', 'might', 'get', 'know', 'would', 'like', 'use', 'grad', 'cam', 'http', 'visual', 'area', 'frame', 'model', 'think', 'result', 'higher', 'view', 'score', 'would', 'vision', 'transform', 'cnn', 'better', 'task', 'also', 'pre', 'train', 'network', 'like', 'yolo', 'use', 'transfer', 'learn', 'reduc', 'amount', 'data', 'need', 'predict']"
340,374,374,Competitive-Rub-1958,vpenn1,"[R] Minerva, Solving (more) complex mathematical problems at scale","Blog: [https://ai.googleblog.com/2022/06/minerva-solving-quantitative-reasoning.html](https://ai.googleblog.com/2022/06/minerva-solving-quantitative-reasoning.html)  
ABS: [https://arxiv.org/abs/2206.14858](https://arxiv.org/abs/2206.14858)  


The 512B model seems quite good at correcting reasoning errors by its smaller 62B couterpart, showing scale helps. 

A notable failure case, the JEE questions in the Appendix was pretty interesting because it solved the problem exactly how someone not familiar with JEE's difficulty would attempt to solve it - which isn't necessarily a bad thing, but the interesting parallel is that human students often make the same mistakes when starting out on their JEE prep. Wonder how more data would help in this case.

Overall, pretty good pushes over SOTA (even double-digit). I can't help but think that scaling is the currently most promising way, but its done too inefficiently - models spend vast resources memorizing when they could've used it to directly start meta-learning and reasoning abilities to formally deduce things precise enough for mathematical questions - just my 2c.",2,36,2022-07-02 02:59:42, r  minerva  solving  more  complex mathematical problems at scale,blog   https abs   https the b model seems quite good at correcting reasoning errors by its smaller b couterpart  showing scale helps  a notable failure case  the jee questions in the appendix was pretty interesting because it solved the problem exactly how someone not familiar with jee s difficulty would attempt to solve it   which isn t necessarily a bad thing  but the interesting parallel is that human students often make the same mistakes when starting out on their jee prep  wonder how more data would help in this case overall  pretty good pushes over sota  even double digit   i can t help but think that scaling is the currently most promising way  but its done too inefficiently   models spend vast resources memorizing when they could ve used it to directly start meta learning and reasoning abilities to formally deduce things precise enough for mathematical questions   just my c ,blog https abs https b model seems quite good correcting reasoning errors smaller b couterpart showing scale helps notable failure case jee questions appendix pretty interesting solved problem exactly someone familiar jee difficulty would attempt solve necessarily bad thing interesting parallel human students often make mistakes starting jee prep wonder data would help case overall pretty good pushes sota even double digit help think scaling currently promising way done inefficiently models spend vast resources memorizing could used directly start meta learning reasoning abilities formally deduce things precise enough mathematical questions c,r minerva solving complex mathematical problems scale,r minerva solving complex mathematical problems scaleblog https abs https b model seems quite good correcting reasoning errors smaller b couterpart showing scale helps notable failure case jee questions appendix pretty interesting solved problem exactly someone familiar jee difficulty would attempt solve necessarily bad thing interesting parallel human students often make mistakes starting jee prep wonder data would help case overall pretty good pushes sota even double digit help think scaling currently promising way done inefficiently models spend vast resources memorizing could used directly start meta learning reasoning abilities formally deduce things precise enough mathematical questions c,"['r', 'minerva', 'solving', 'complex', 'mathematical', 'problems', 'scaleblog', 'https', 'abs', 'https', 'b', 'model', 'seems', 'quite', 'good', 'correcting', 'reasoning', 'errors', 'smaller', 'b', 'couterpart', 'showing', 'scale', 'helps', 'notable', 'failure', 'case', 'jee', 'questions', 'appendix', 'pretty', 'interesting', 'solved', 'problem', 'exactly', 'someone', 'familiar', 'jee', 'difficulty', 'would', 'attempt', 'solve', 'necessarily', 'bad', 'thing', 'interesting', 'parallel', 'human', 'students', 'often', 'make', 'mistakes', 'starting', 'jee', 'prep', 'wonder', 'data', 'would', 'help', 'case', 'overall', 'pretty', 'good', 'pushes', 'sota', 'even', 'double', 'digit', 'help', 'think', 'scaling', 'currently', 'promising', 'way', 'done', 'inefficiently', 'models', 'spend', 'vast', 'resources', 'memorizing', 'could', 'used', 'directly', 'start', 'meta', 'learning', 'reasoning', 'abilities', 'formally', 'deduce', 'things', 'precise', 'enough', 'mathematical', 'questions', 'c']","['r', 'minerva', 'solv', 'complex', 'mathemat', 'problem', 'scaleblog', 'http', 'ab', 'http', 'b', 'model', 'seem', 'quit', 'good', 'correct', 'reason', 'error', 'smaller', 'b', 'couterpart', 'show', 'scale', 'help', 'notabl', 'failur', 'case', 'jee', 'question', 'appendix', 'pretti', 'interest', 'solv', 'problem', 'exactli', 'someon', 'familiar', 'jee', 'difficulti', 'would', 'attempt', 'solv', 'necessarili', 'bad', 'thing', 'interest', 'parallel', 'human', 'student', 'often', 'make', 'mistak', 'start', 'jee', 'prep', 'wonder', 'data', 'would', 'help', 'case', 'overal', 'pretti', 'good', 'push', 'sota', 'even', 'doubl', 'digit', 'help', 'think', 'scale', 'current', 'promis', 'way', 'done', 'ineffici', 'model', 'spend', 'vast', 'resourc', 'memor', 'could', 'use', 'directli', 'start', 'meta', 'learn', 'reason', 'abil', 'formal', 'deduc', 'thing', 'precis', 'enough', 'mathemat', 'question', 'c']"
341,375,375,ahsaor8,vpqfy2,[D] suggestions for graph embedding model?,"Any suggestions for best graph embedding model.
I already tried ( GIN , GCN , DIG , GAT ) I want to use it for anomaly detection task.",1,3,2022-07-02 15:10:35, d  suggestions for graph embedding model ,any suggestions for best graph embedding model i already tried   gin   gcn   dig   gat   i want to use it for anomaly detection task ,suggestions best graph embedding model already tried gin gcn dig gat want use anomaly detection task,suggestions graph embedding model,suggestions graph embedding modelsuggestions best graph embedding model already tried gin gcn dig gat want use anomaly detection task,"['suggestions', 'graph', 'embedding', 'modelsuggestions', 'best', 'graph', 'embedding', 'model', 'already', 'tried', 'gin', 'gcn', 'dig', 'gat', 'want', 'use', 'anomaly', 'detection', 'task']","['suggest', 'graph', 'embed', 'modelsuggest', 'best', 'graph', 'embed', 'model', 'alreadi', 'tri', 'gin', 'gcn', 'dig', 'gat', 'want', 'use', 'anomali', 'detect', 'task']"
