,eid,doi,Title,creator,publicationName,Date,Abstract,authkeywords,Cites,pageRange,aggregationType,subtypeDescription,author_count,author_names,author_ids,affilname,affiliation_country,Abstract_clean,Title_clean
14,2-s2.0-85129932843,10.1002/jrsm.1563,Citationchaser: A tool for transparent and efficient forward and backward citation chasing in systematic searching,Haddaway N.R.,Research Synthesis Methods,2022-07-01,"Systematic searching aims to find all possibly relevant research from multiple sources, the basis for an unbiased and comprehensive evidence base. Along with bibliographic databases, systematic reviewers use a variety of additional methods to minimise procedural bias. Citation chasing exploits connections between research articles to identify relevant records for a review by making use of explicit mentions of one article within another. Citation chasing is a popular supplementary search method because it helps to build on the work of primary research and review authors. It does so by identifying potentially relevant studies that might otherwise not be retrieved by other search methods; for example, because they did not use the review authors' search terms in the specified combinations in their titles, abstracts, or keywords. Here, we briefly provide an overview of citation chasing as a method for systematic reviews. Furthermore, given the challenges and high resource requirements associated with citation chasing, the limited application of citation chasing in otherwise rigorous systematic reviews, and the potential benefit of identifying terminologically disconnected but semantically linked research studies, we have developed and describe a free and open source tool that allows for rapid forward and backward citation chasing. We introduce citationchaser, an R package and Shiny app for conducting forward and backward citation chasing from a starting set of articles. We describe the sources of data, the backend code functionality, and the user interface provided in the Shiny app.",bibliographic checking | evidence synthesis tools | information retrieval | pearl growing | software development | systematic review tool | systematic searching,1,533-545,Journal,Article,3.0,"Haddaway, Neal R.;Grainger, Matthew J.;Gray, Charles T.",54997981700;12545570400;57209215611,Leibniz-Zentrum für Agrarlandschaftsforschung (ZALF) e. V.;Norwegian Institute for Nature Research;Newcastle University;University of Johannesburg,Germany;Norway;United Kingdom;South Africa,"systematic searching aims to find all possibly relevant research from multiple sources, the basis for an unbiased and comprehensive evidence base. along with bibliographic databases, systematic reviewers use a variety of additional methods to minimise procedural bias. citation chasing exploits connections between research articles to identify relevant records for a review by making use of explicit mentions of one article within another. citation chasing is a popular supplementary search method because it helps to build on the work of primary research and review authors. it does so by identifying potentially relevant studies that might otherwise not be retrieved by other search methods; for example, because they did not use the review authors' search terms in the specified combinations in their titles, abstracts, or keywords. here, we briefly provide an overview of citation chasing as a method for systematic reviews. furthermore, given the challenges and high resource requirements associated with citation chasing, the limited application of citation chasing in otherwise rigorous systematic reviews, and the potential benefit of identifying terminologically disconnected but semantically linked research studies, we have developed and describe a free and open source tool that allows for rapid forward and backward citation chasing. we introduce citationchaser, an r package and shiny app for conducting forward and backward citation chasing from a starting set of articles. we describe the sources of data, the backend code functionality, and the user interface provided in the shiny app.",citationchaser: a tool for transparent and efficient forward and backward citation chasing in systematic searching
18,2-s2.0-85128297622,10.2174/1573406418666211129103458,GreenMolBD: Nature Derived Bioactive Molecules' Database,Zahid Hosen S.M.,Medicinal Chemistry,2022-07-01,"Background: One of the essential resources for developing new drugs are naturally derived biologically active lead compounds. Biomedical researchers and pharmaceutical companies are highly interested in these plant-derived molecules to develop the new drug. In this process, collective information of the plants and their phytoconstituents with different properties and descriptors would greatly benefit the researchers to identify the hit, lead or drug-like compound. Aim and Objective: Therefore, the work intended to develop a unique and dynamic database Green-MolBD to provide collective information regarding medicinal plants, such as their profile, chemical constituents, and pharmacological evidence. We also aimed to present information of phytoconstitu-ents, such as in silico description, quantum, drugability and biological target information. Methods: For data mining, we covered all accessible literature and books, and for in silico analysis, we employed a variety of well-known software and servers. The database is integrated by MySQL, HTML, PHP and JavaScript. Results: GreenMolBD is a freely accessible database and searchable by keywords, plant name, syno-nym, common name, family name, family synonym, compound name, IUPAC name, InChI Key, target name, and disease name. We have provided a complete profile of individual plants and each compound’s physical, quantum, drug likeliness, and toxicity properties (48 type’s descriptor) using in silico tools. A total of 1846 associated targets related to 6,864 compounds already explored in different studies are also incorporated and synchronized. Conclusion: This is the first evidence-based database of bioactive molecules from medicinal plants specially grown in Bangladesh, which may help explore and foster nature-inspired rational drug dis-covery.",Bangladeshi plant database | compound database | in silico properties | natural products | pharmacological evidence | Plant database,0,724-733,Journal,Article,11.0,"Zahid Hosen, S. M.;Junaid, Md;Alam, Muhammad Shaiful;Rubayed, Maruf;Dash, Raju;Akter, Rasheda;Sharmin, Tania;Mouri, Nusrat Jahan;Moni, Mohammad Ali;Khatun, Mahmuda;Mostafa, Mohammad",57200442662;56997000900;57205573149;57205573689;56605919500;35721487600;56966524500;56884430300;35119094400;57205915660;57321221600,"BCSIR Laboratories, Chattogram;Dongguk University, College of Medicine;UNSW Medicine",Bangladesh;South Korea;Australia,"background: one of the essential resources for developing new drugs are naturally derived biologically active lead compounds. biomedical researchers and pharmaceutical companies are highly interested in these plant-derived molecules to develop the new drug. in this process, collective information of the plants and their phytoconstituents with different properties and descriptors would greatly benefit the researchers to identify the hit, lead or drug-like compound. aim and objective: therefore, the work intended to develop a unique and dynamic database green-molbd to provide collective information regarding medicinal plants, such as their profile, chemical constituents, and pharmacological evidence. we also aimed to present information of phytoconstitu-ents, such as in silico description, quantum, drugability and biological target information. methods: for data mining, we covered all accessible literature and books, and for in silico analysis, we employed a variety of well-known software and servers. the database is integrated by mysql, html, php and javascript. results: greenmolbd is a freely accessible database and searchable by keywords, plant name, syno-nym, common name, family name, family synonym, compound name, iupac name, inchi key, target name, and disease name. we have provided a complete profile of individual plants and each compound’s physical, quantum, drug likeliness, and toxicity properties (48 type’s descriptor) using in silico tools. a total of 1846 associated targets related to 6,864 compounds already explored in different studies are also incorporated and synchronized. conclusion: this is the first evidence-based database of bioactive molecules from medicinal plants specially grown in bangladesh, which may help explore and foster nature-inspired rational drug dis-covery.",greenmolbd: nature derived bioactive molecules' database
19,2-s2.0-85108609354,10.1007/s42947-021-00064-8,Pavement Temperature Data Maps for Worldwide Locations,Sreejith G.H.,International Journal of Pavement Research and Technology,2022-07-01,"Inservice pavement temperature has considerable bearing on the selection of appropriate asphalt binder and in the determination of design asphalt modulus during the asphalt pavement design process. While site-specific pavement temperature data are available (both online and offline) for certain parts of the world, pavement designers from most parts of the world are deprived of such data and have to resort to detailed analysis of regional climate data over the years to arrive at weighted mean annual pavement temperature (WMAPT), and the lowest and highest pavement temperatures etc. for their binder selection and pavement design input requirements. This project is envisioned to equip pavement designers from all over the world by providing quick and interactive access to air and pavement temperatures for over 13,000 stations worldwide in the form of geographic information system (GIS) data maps through the development of a web-based platform. Around 75 million daily air temperature data sourced from the United States National Climatic Data Centre-Climate Data Online for the past 30 years (1989–2018) was analyzed using the Python PANDAS data analysis tools and converted to WMAPT, low and high pavement temperatures etc. based on the Shell WMAPT, Strategic Highway Research Programme and long-term pavement performance seasonal pavement temperature models. The pavement temperature data obtained were further analyzed in the open-source GIS software QGIS, before being developed into interactive web maps using the JavaScript library, Leaflet.js. The final output of the analysis; PaveTemp ver 0.1, in the form of continent wise pavement temperature data maps for Africa, Asia, Australia and Oceania, Europe, North America and South America is hosted at the domain http://www.pavetemp.com and can be freely accessed through the website. Further modifications and updates to the project and the website are aimed at in the near future as more region-specific pavement temperature models are developed and made available to the pavement engineering community.",LTPP | Pavement temperature | Python Pandas | QGIS | SHRP | WMAPT,1,948-956,Journal,Article,1.0,"Sreejith, G. H.",57224920442,Sheladia Associates Inc.,United States,"inservice pavement temperature has considerable bearing on the selection of appropriate asphalt binder and in the determination of design asphalt modulus during the asphalt pavement design process. while site-specific pavement temperature data are available (both online and offline) for certain parts of the world, pavement designers from most parts of the world are deprived of such data and have to resort to detailed analysis of regional climate data over the years to arrive at weighted mean annual pavement temperature (wmapt), and the lowest and highest pavement temperatures etc. for their binder selection and pavement design input requirements. this project is envisioned to equip pavement designers from all over the world by providing quick and interactive access to air and pavement temperatures for over 13,000 stations worldwide in the form of geographic information system (gis) data maps through the development of a web-based platform. around 75 million daily air temperature data sourced from the united states national climatic data centre-climate data online for the past 30 years (1989–2018) was analyzed using the python pandas data analysis tools and converted to wmapt, low and high pavement temperatures etc. based on the shell wmapt, strategic highway research programme and long-term pavement performance seasonal pavement temperature models. the pavement temperature data obtained were further analyzed in the open-source gis software qgis, before being developed into interactive web maps using the javascript library, leaflet.js. the final output of the analysis; pavetemp ver 0.1, in the form of continent wise pavement temperature data maps for africa, asia, australia and oceania, europe, north america and south america is hosted at the domain http://www.pavetemp.com and can be freely accessed through the website. further modifications and updates to the project and the website are aimed at in the near future as more region-specific pavement temperature models are developed and made available to the pavement engineering community.",pavement temperature data maps for worldwide locations
20,2-s2.0-85090561922,10.1177/1548512920953499,"A review of the use and utility of industrial network-based open source simulators: functionality, security, and policy viewpoints",Ani U.D.,Journal of Defense Modeling and Simulation,2022-07-01,"Simulation can provide a useful means to understand issues linked to industrial network operations. For transparent, collaborative, cost-effective solutions development, and to attract the broadest interest base, simulation is critical and open source suggested, because it costs less to access, install, and use. This study contributes new insights from security and functionality characteristics metrics to underscore the use and effectiveness of open source simulators. Several open source simulators span applications in communications and wireless sensor networks, industrial control systems, and the Industrial Internet of Things. Some drivers for their use span are as follows: supported license types; programming languages; operating systems platforms; user interface types; documentation and communication types; citations; code commits; and number of contributors. Research in these simulators is built around performance and optimization relative to flexibility, scalability, mobility, and active user support. No single simulator addresses all these conceivable characteristics. In addition to modeling contexts that match real-world scenarios and issues, an effective open source simulator needs to demonstrate credibility, which can be gained partly through actively engaging experts from interdisciplinary teams along with user contributions integrated under tight editorial controls. Government-led policies and regulations are also necessary to support their wider awareness and more productive use for real-world purposes.",industrial control system simulations | Industrial Internet of Things simulation | Open source simulators | open source tools | security simulations | system simulations,1,263-286,Journal,Article,5.0,"Ani, Uchenna Daniel;Watson, Jeremy Mc Kendrick;Carr, Madeline;Cook, Al;Nurse, Jason R.C.",23491291000;57203669069;55859713100;57215824476;26639650900,UCL Engineering;University of Kent;Critical Insights Security Ltd,United Kingdom;United Kingdom;United Kingdom,"simulation can provide a useful means to understand issues linked to industrial network operations. for transparent, collaborative, cost-effective solutions development, and to attract the broadest interest base, simulation is critical and open source suggested, because it costs less to access, install, and use. this study contributes new insights from security and functionality characteristics metrics to underscore the use and effectiveness of open source simulators. several open source simulators span applications in communications and wireless sensor networks, industrial control systems, and the industrial internet of things. some drivers for their use span are as follows: supported license types; programming languages; operating systems platforms; user interface types; documentation and communication types; citations; code commits; and number of contributors. research in these simulators is built around performance and optimization relative to flexibility, scalability, mobility, and active user support. no single simulator addresses all these conceivable characteristics. in addition to modeling contexts that match real-world scenarios and issues, an effective open source simulator needs to demonstrate credibility, which can be gained partly through actively engaging experts from interdisciplinary teams along with user contributions integrated under tight editorial controls. government-led policies and regulations are also necessary to support their wider awareness and more productive use for real-world purposes.","a review of the use and utility of industrial network-based open source simulators: functionality, security, and policy viewpoints"
21,2-s2.0-85134161464,10.1145/3502181.3531469,FPVM: Towards a Floating Point Virtual Machine,Dinda P.,HPDC 2022 - Proceedings of the 31st International Symposium on High-Performance Parallel and Distributed Computing,2022-06-27,"Alternatives to IEEE floating point arithmetic have become all the rage. Some extract more representational power out of the available bits. Others offer the potential for lower or higher precision than is available in IEEE-compatible hardware. Even an ""interface to the real numbers""has recently been proposed. Using such alternative arithmetic systems within an existing scientific or other significant codebase is a major challenge, however. We explore how to address this challenge through virtualizing the IEEE floating point hardware, specifically on x64. The goal of the floating point virtual machine (FPVM) is to allow an existing application binary to be seamlessly extended to support the desired alternative arithmetic system with overheads determined by that system and not the virtualization mechanisms. We describe the prospects, issues, and tradeoffs for four different approaches for building FPVM: trap-and-emulate, trap-and-patch, binary transformation, and IR transformation. We then describe the design and implementation of our current design, which combines static binary analysis/translation and trap-and-emulate execution. We evaluate our FPVM implementation on several benchmarks, virtualizing them to use posits and MPFR. Finally, we comment on kernel- and hardware-level innovations that could further reduce overheads for floating point virtualization.",floating point arithmetic | ieee 754 | software development | virtualization,0,16-29,Conference Proceeding,Conference Paper,8.0,"Dinda, Peter;Wanninger, Nick;Ma, Jiacheng;Bernat, Alex;Bernat, Charles;Ghosh, Souradip;Kraemer, Christopher;Elmasry, Yehya",7006032808;57223744377;57354548500;57218220089;57802286700;57222238473;57567022500;57210789383,Northwestern University,United States,"alternatives to ieee floating point arithmetic have become all the rage. some extract more representational power out of the available bits. others offer the potential for lower or higher precision than is available in ieee-compatible hardware. even an ""interface to the real numbers""has recently been proposed. using such alternative arithmetic systems within an existing scientific or other significant codebase is a major challenge, however. we explore how to address this challenge through virtualizing the ieee floating point hardware, specifically on x64. the goal of the floating point virtual machine (fpvm) is to allow an existing application binary to be seamlessly extended to support the desired alternative arithmetic system with overheads determined by that system and not the virtualization mechanisms. we describe the prospects, issues, and tradeoffs for four different approaches for building fpvm: trap-and-emulate, trap-and-patch, binary transformation, and ir transformation. we then describe the design and implementation of our current design, which combines static binary analysis/translation and trap-and-emulate execution. we evaluate our fpvm implementation on several benchmarks, virtualizing them to use posits and mpfr. finally, we comment on kernel- and hardware-level innovations that could further reduce overheads for floating point virtualization.",fpvm: towards a floating point virtual machine
22,2-s2.0-85134889939,10.1145/3531056.3542769,mira: an Application Containerisation Pipeline for Small Software Development Teams in Low Resource Settings,Mwotil A.,ACM International Conference Proceeding Series,2022-06-07,"Cloud native applications leverage Development and Operation (DevOps), microservice architectures and containerisation for primarily availability, resilience and scalability reasons. Small developer teams in low resource settings have unique DevOps needs and harnessing its principles and practices is technically challenging and distinctly difficult in these contexts. We conducted a survey with professional developers, students and researchers situated and working in a low resource setting and the results indicate that these principles and practices are relatively new. In application containerisation, an operating system virtualisation method that can significantly optimize the use of computing resources, the respondents indicated challenges in the process steps. Particularly, small developer teams in low resource settings require custom tools and abstractions for software development and delivery automation. Informed by the developer needs, we designed and developed a custom automated containerisation pipeline, mira, for a managed cloud native platform situated in a low-resource setting. We validate mira against 6 major application frameworks, tools and/or languages and successful deployment of the resultant applications onto a cloud native platform.",automation | cloud | cloud native | containers | docker | orchestration,0,31-38,Conference Proceeding,Conference Paper,3.0,"Mwotil, Alex;Bainomugisha, Engineer;Araka, Stephen G.M.",57190074796;34876206700;57819113700,Makerere University;Carnegie Mellon University,Uganda;United States,"cloud native applications leverage development and operation (devops), microservice architectures and containerisation for primarily availability, resilience and scalability reasons. small developer teams in low resource settings have unique devops needs and harnessing its principles and practices is technically challenging and distinctly difficult in these contexts. we conducted a survey with professional developers, students and researchers situated and working in a low resource setting and the results indicate that these principles and practices are relatively new. in application containerisation, an operating system virtualisation method that can significantly optimize the use of computing resources, the respondents indicated challenges in the process steps. particularly, small developer teams in low resource settings require custom tools and abstractions for software development and delivery automation. informed by the developer needs, we designed and developed a custom automated containerisation pipeline, mira, for a managed cloud native platform situated in a low-resource setting. we validate mira against 6 major application frameworks, tools and/or languages and successful deployment of the resultant applications onto a cloud native platform.",mira: an application containerisation pipeline for small software development teams in low resource settings
25,2-s2.0-85128635566,10.1109/TR.2022.3159812,An Empirical Study on Bugs in Python Interpreters,Wang Z.,IEEE Transactions on Reliability,2022-06-01,"Python is an interpreted programming language that has been widely used in many fields. The successful execution of a Python program depends on both the correctness of Python program and the correctness of Python interpreter. As an infrastructure software, there are many bugs in the Python interpreter. Exploring the bugs in Python interpreters can help developers and maintainers of Python interpreters detect and fix bugs and help users of Python avoid risks. In this article, we conduct an empirical study on the bugs in two mainstream Python interpreters: CPython and PyPy. By analyzing 25 958 fixed bugs, 18 824 revisions, 2 116 test cases, and root causes of randomly sampled 510 bugs, we have summarized the following findings. 1)The distribution of bugs in the Python interpreter is so uneven that the vast majority of bugs are distributed in a few components and source files. 2)The scales of the testing programs that reveal bugs are small. 3)The fixing works seem to be not complicated since the number of modified source files and lines of code are limited; however, most bugs need a long time to be fixed; nearly 15% of the bugs need more than one year to fix. 4)The priorities of bugs are independent of their locations, but they significantly correlate with duration of bugs. 5)Semantic bugs are the most frequent root causes of bugs, and their proportion exceeds other types of root causes. These results could indicate some potential problems during the detecting and fixing of Python interpreter's bugs, and provide some assistance to developers and maintainers of Python interpreters, users of Python, as well as researchers in related fields.",CPython | empirical study | PyPy | Python interpreter | software bug,0,716-734,Journal,Article,6.0,"Wang, Ziyuan;Bu, Dexin;Sun, Aiyue;Gou, Shanyi;Wang, Yong;Chen, Lin",16644193000;57608614800;57221774896;57609674400;56789885200;57189042207,Anhui Polytechnic University;Nanjing University;Nanjing University of Post and TeleCommunications,China;China;China,"python is an interpreted programming language that has been widely used in many fields. the successful execution of a python program depends on both the correctness of python program and the correctness of python interpreter. as an infrastructure software, there are many bugs in the python interpreter. exploring the bugs in python interpreters can help developers and maintainers of python interpreters detect and fix bugs and help users of python avoid risks. in this article, we conduct an empirical study on the bugs in two mainstream python interpreters: cpython and pypy. by analyzing 25 958 fixed bugs, 18 824 revisions, 2 116 test cases, and root causes of randomly sampled 510 bugs, we have summarized the following findings. 1)the distribution of bugs in the python interpreter is so uneven that the vast majority of bugs are distributed in a few components and source files. 2)the scales of the testing programs that reveal bugs are small. 3)the fixing works seem to be not complicated since the number of modified source files and lines of code are limited; however, most bugs need a long time to be fixed; nearly 15% of the bugs need more than one year to fix. 4)the priorities of bugs are independent of their locations, but they significantly correlate with duration of bugs. 5)semantic bugs are the most frequent root causes of bugs, and their proportion exceeds other types of root causes. these results could indicate some potential problems during the detecting and fixing of python interpreter's bugs, and provide some assistance to developers and maintainers of python interpreters, users of python, as well as researchers in related fields.",an empirical study on bugs in python interpreters
26,2-s2.0-85127272000,10.1007/s42600-022-00203-5,"Educational platform for support in the experience, communication and behavior of children with autism spectrum disorder",da Silva A.L.,Research on Biomedical Engineering,2022-06-01,"Introduction: Autistic Spectrum Disorder (ASD) is a developmental disability that compromises the quality of social interaction and communication. According to the WHO, there is an estimate that one in every 160 children in the world has the ASD. Early treatment and education of children with ASD are essential. Therefore, the objective of this research was to describe the development process of an educational platform related to autism, which aims to support the experience, communication, and behavior of these children. Methods: To develop, a study of the best practices of Software Engineering and concepts of Serious Game (SG) for the definition of the process was carried out, including Treatment and Education for Autistic and Children with Communication-related Deficits (TEACCH), Applied Behavior Analysis (ABA), Picture Exchange Communication System (PECS), Music Therapy and Psychomotricity. A Game Engine was also chosen due to the possibility of compiling the application for different operating systems. To verify the requirements, consulting the opinion of experts on the technical and pedagogical requirements was done in accordance with their expertise, including usability applying SUS (System Usability Scale). Results: PERA (in Portuguese, acronym for “Plataforma Educacional Relacionada ao Autismo”) consists of eight modules with speech synthesizer, music, sounds and animation features. The experts’ opinion resulted in the SUS score of 86.9 ± 12.2, considered excellent, according to Brooke’s adjectives. Conclusion: According to experts’ opinion, the educational platform developed includes important requirements in accordance with their specialties and may contribute to the teaching and learning process of children with ASD.",ABA | ASD | PECS | Serious Game | TEACCH | Unity Technologies,0,701-731,Journal,Review,2.0,"da Silva, Adilson Lima;Bissaco, Marcia Aparecida Silva",57554718100;55257690000,Universidade de Mogi das Cruzes,Brazil,"introduction: autistic spectrum disorder (asd) is a developmental disability that compromises the quality of social interaction and communication. according to the who, there is an estimate that one in every 160 children in the world has the asd. early treatment and education of children with asd are essential. therefore, the objective of this research was to describe the development process of an educational platform related to autism, which aims to support the experience, communication, and behavior of these children. methods: to develop, a study of the best practices of software engineering and concepts of serious game (sg) for the definition of the process was carried out, including treatment and education for autistic and children with communication-related deficits (teacch), applied behavior analysis (aba), picture exchange communication system (pecs), music therapy and psychomotricity. a game engine was also chosen due to the possibility of compiling the application for different operating systems. to verify the requirements, consulting the opinion of experts on the technical and pedagogical requirements was done in accordance with their expertise, including usability applying sus (system usability scale). results: pera (in portuguese, acronym for “plataforma educacional relacionada ao autismo”) consists of eight modules with speech synthesizer, music, sounds and animation features. the experts’ opinion resulted in the sus score of 86.9 ± 12.2, considered excellent, according to brooke’s adjectives. conclusion: according to experts’ opinion, the educational platform developed includes important requirements in accordance with their specialties and may contribute to the teaching and learning process of children with asd.","educational platform for support in the experience, communication and behavior of children with autism spectrum disorder"
28,2-s2.0-85111889560,10.1007/s10209-021-00828-w,Universal access: user needs for immersive captioning,Hughes C.J.,Universal Access in the Information Society,2022-06-01,"This article focuses on building a prototyping for immersive captioning following a user-centric approach. This methodology is characterised by following a bottom-up approach, where usability and user needs are at the heart of the development. Recent research on user requirements for captioning in immersive environments has shown that there is both a need for improvement and a wealth of research opportunities. The final aim is to identify how to display captions for an optimal viewing experience. This work began four years ago with some partial findings. We build from the lessons learnt, focussing on the user-centric design requirements cornerstone: prototyping. Our prototype framework integrates methods used in existing solutions aiming at instant contrast-and-compare functionalities. The first part of the article presents the state of the art for user requirements identifying the reasons behind the development of the prototyping framework. The second part of the article describes the two-stage framework development. The initial framework concept answered to the challenges resulting from the previous research. As soon as the first framework was developed, it became obvious that a second improved solution was required, almost as a showcase on how ideas can quickly be implemented for user testing, and for users to elicit requirements and creative solutions. The article finishes with a list of functionalities, resulting in new caption modes, and the opportunity of becoming a comprehensive immersive captions testbed, where tools such as eye-tracking, or physiological testing devices could be testing captions across any device with a web browser.",Accessibility | Captions | Immersive video | Testing | User-centric requirements | VR,0,393-403,Journal,Article,1.0,"Hughes, Chris J.",57040431000,University of Salford,United Kingdom,"this article focuses on building a prototyping for immersive captioning following a user-centric approach. this methodology is characterised by following a bottom-up approach, where usability and user needs are at the heart of the development. recent research on user requirements for captioning in immersive environments has shown that there is both a need for improvement and a wealth of research opportunities. the final aim is to identify how to display captions for an optimal viewing experience. this work began four years ago with some partial findings. we build from the lessons learnt, focussing on the user-centric design requirements cornerstone: prototyping. our prototype framework integrates methods used in existing solutions aiming at instant contrast-and-compare functionalities. the first part of the article presents the state of the art for user requirements identifying the reasons behind the development of the prototyping framework. the second part of the article describes the two-stage framework development. the initial framework concept answered to the challenges resulting from the previous research. as soon as the first framework was developed, it became obvious that a second improved solution was required, almost as a showcase on how ideas can quickly be implemented for user testing, and for users to elicit requirements and creative solutions. the article finishes with a list of functionalities, resulting in new caption modes, and the opportunity of becoming a comprehensive immersive captions testbed, where tools such as eye-tracking, or physiological testing devices could be testing captions across any device with a web browser.",universal access: user needs for immersive captioning
29,2-s2.0-85130771928,10.1145/3507657.3528560,A First Look at Code Obfuscation for WebAssembly,Bhansali S.,WiSec 2022 - Proceedings of the 15th ACM Conference on Security and Privacy in Wireless and Mobile Networks,2022-05-16,"WebAssembly (Wasm) has seen a lot of attention lately as it spreads through the mobile computing domain and becomes the new standard for performance-oriented web development. It has diversified its uses far beyond just web applications by acting as an execution environment for mobile agents, containers for IoT devices, and enabling new serverless approaches for edge computing. Within the numerous uses of Wasm, not all of them are benign. With the rise of Wasm-based cryptojacking malware, analyzing Wasm applications has been a hot topic in the literature, resulting in numerous Wasm-based cryptojacking detection systems. Many of these methods rely on static analysis, which traditionally can be circumvented through obfuscation. However, the feasibility of the obfuscation techniques for Wasm programs has never been investigated thoroughly. In this paper, we address this gap and perform the first look at code obfuscation for Wasm. We apply numerous obfuscation techniques to Wasm programs, and test their effectiveness in producing a fully obfuscated Wasm program. Particularly, we obfuscate both benign Wasm-based web applications and cryptojacking malware instances and feed them into a state-of-the-art Wasm cryptojacking detector to see if current Wasm analysis methods can be subverted with obfuscation. Our analysis shows that obfuscation can be highly effective and can cause even a state-of-the-art detector to misclassify the obfuscated Wasm samples.",cryptojacking | obfuscation | wasm | webassembly,0,140-145,Conference Proceeding,Conference Paper,5.0,"Bhansali, Shrenik;Aris, Ahmet;Acar, Abbas;Oz, Harun;Uluagac, A. Selcuk",57713052800;53879369200;57201944908;57222238629;22735196300,Georgia Institute of Technology;Florida International University,United States;United States,"webassembly (wasm) has seen a lot of attention lately as it spreads through the mobile computing domain and becomes the new standard for performance-oriented web development. it has diversified its uses far beyond just web applications by acting as an execution environment for mobile agents, containers for iot devices, and enabling new serverless approaches for edge computing. within the numerous uses of wasm, not all of them are benign. with the rise of wasm-based cryptojacking malware, analyzing wasm applications has been a hot topic in the literature, resulting in numerous wasm-based cryptojacking detection systems. many of these methods rely on static analysis, which traditionally can be circumvented through obfuscation. however, the feasibility of the obfuscation techniques for wasm programs has never been investigated thoroughly. in this paper, we address this gap and perform the first look at code obfuscation for wasm. we apply numerous obfuscation techniques to wasm programs, and test their effectiveness in producing a fully obfuscated wasm program. particularly, we obfuscate both benign wasm-based web applications and cryptojacking malware instances and feed them into a state-of-the-art wasm cryptojacking detector to see if current wasm analysis methods can be subverted with obfuscation. our analysis shows that obfuscation can be highly effective and can cause even a state-of-the-art detector to misclassify the obfuscated wasm samples.",a first look at code obfuscation for webassembly
30,2-s2.0-85130320699,10.3233/SHTI220379,Development of an Architecture to Implement Machine Learning Based Risk Prediction in Clinical Routine: A Service-Oriented Approach,Schrempf M.,Studies in Health Technology and Informatics,2022-05-16,"Background: Patients at risk of developing a disease have to be identified at an early stage to enable prevention. One way of early detection is the use of machine learning based prediction models trained on electronic health records. Objectives: The aim of this project was to develop a software solution to predict cardiovascular and nephrological events using machine learning models. In addition, a risk verification interface for health care professionals was established. Methods: In order to meet the requirements, different tools were analysed. Based on this, a software architecture was created, which was designed to be as modular as possible. Results: A software was realised that is able to automatically calculate and display risks using machine learning models. Furthermore, predictions can be verified via an interface adapted to the need of health care professionals, which shows data required for prediction. Conclusion: Due to the modularised software architecture and the status-based calculation process, different technologies could be applied. This facilitates the installation of the software at multiple health care providers, for which adjustments need to be carried out at one part of the software only.",Computer Software | Health Risk Assessment | Healthcare | Machine Learning | prevention &amp; control | Preventive Health Services | Preventive Medicine | Public Health | Software Engineering,0,262-269,Book Series,Conference Paper,8.0,"Schrempf, Michael;Polat Erdeniz, Seda;Kramer, Diether;Jauk, Stefanie;Veeranki, Sai P.K.;Ribitsch, Werner;Leodolter, Werner;Rainer, Peter P.",57223707523;57195231828;57194330023;57202286649;57194341358;42162000600;57202284871;35590576100,Medizinische Universität Graz;Steiermärkische Krankenanstaltengesellschaft m.b.H. (KAGes),Austria;Austria,"background: patients at risk of developing a disease have to be identified at an early stage to enable prevention. one way of early detection is the use of machine learning based prediction models trained on electronic health records. objectives: the aim of this project was to develop a software solution to predict cardiovascular and nephrological events using machine learning models. in addition, a risk verification interface for health care professionals was established. methods: in order to meet the requirements, different tools were analysed. based on this, a software architecture was created, which was designed to be as modular as possible. results: a software was realised that is able to automatically calculate and display risks using machine learning models. furthermore, predictions can be verified via an interface adapted to the need of health care professionals, which shows data required for prediction. conclusion: due to the modularised software architecture and the status-based calculation process, different technologies could be applied. this facilitates the installation of the software at multiple health care providers, for which adjustments need to be carried out at one part of the software only.",development of an architecture to implement machine learning based risk prediction in clinical routine: a service-oriented approach
31,2-s2.0-85131061013,10.1142/S0218194022500206,Detecting Compiler Bugs Via a Deep Learning-Based Framework,Tang Y.,International Journal of Software Engineering and Knowledge Engineering,2022-05-01,"Compiler testing is the most widely used way to assure compiler quality. However, since compilers require a large number of sophisticated test programs as inputs, the existing approaches in compiler testing still have a limited capability in generating both syntactically valid and diverse test programs. In this paper, we propose DeepGen, a deep learning-based approach to support compiler testing through the inference of a generative model for compiler inputs. First, DeepGen trains a Transformer-XL model based on a large corpus of seed programs, and uses the trained model to generate syntactically valid programs. Then, DeepGen adopts a sampling strategy in the inference phase to generate diverse test programs. Finally, DeepGen leverages differential testing on the generated programs to discover compiler bugs. We have evaluated DeepGen over two popular C++ compilers GCC and LLVM, and the results confirm the effectiveness of our approach. DeepGen detects 35.29%, 53.33%, and 187.50% more bugs than three existing approaches, i.e. DeepSmith, DeepFuzz, and Csmith, respectively. In addition, 30.43% bugs detected by DeepGen are not detected by other approaches. Furthermore, DeepGen has successfully detected 38 bugs in the latest development versions of GCC and LLVM; 21 of them have been confirmed/fixed by the developers.",Compiler testing | machine learning | program generation,0,661-691,Journal,Article,7.0,"Tang, Yixuan;Ren, Zhilei;Jiang, He;Qiao, Lei;Liu, Dong;Zhou, Zhide;Kong, Weiqiang",57207694040;25640088200;57205479128;57201414562;57137089900;57189640455;15132228500,Beijing Institute of Control Engineering;Nanjing University of Aeronautics and Astronautics;Dalian University of Technology,China;China;China,"compiler testing is the most widely used way to assure compiler quality. however, since compilers require a large number of sophisticated test programs as inputs, the existing approaches in compiler testing still have a limited capability in generating both syntactically valid and diverse test programs. in this paper, we propose deepgen, a deep learning-based approach to support compiler testing through the inference of a generative model for compiler inputs. first, deepgen trains a transformer-xl model based on a large corpus of seed programs, and uses the trained model to generate syntactically valid programs. then, deepgen adopts a sampling strategy in the inference phase to generate diverse test programs. finally, deepgen leverages differential testing on the generated programs to discover compiler bugs. we have evaluated deepgen over two popular c++ compilers gcc and llvm, and the results confirm the effectiveness of our approach. deepgen detects 35.29%, 53.33%, and 187.50% more bugs than three existing approaches, i.e. deepsmith, deepfuzz, and csmith, respectively. in addition, 30.43% bugs detected by deepgen are not detected by other approaches. furthermore, deepgen has successfully detected 38 bugs in the latest development versions of gcc and llvm; 21 of them have been confirmed/fixed by the developers.",detecting compiler bugs via a deep learning-based framework
33,2-s2.0-85129998131,10.1107/S1600577522002685,A novel solution for controlling hardware components of accelerators and beamlines,Khokhriakov I.,Journal of Synchrotron Radiation,2022-05-01,"A novel approach to the remote-control system for the compact multi-crystal energy-dispersive spectrometer for X-ray emission spectroscopy (XES) applications has been developed. This new approach is based on asynchronous communication between software components and on reactive design principles. In this paper, the challenges faced, their solutions, as well as the implementation and future development prospects are identified. The main motivation of this work was the development of a new holistic communication protocol that can be implemented to control various hardware components allowing both independent operation and easy integration into different SCADA systems.",control system | experiment control | physics facility | reactive system | system design | X-ray spectroscopy,0,644-653,Journal,Article,5.0,"Khokhriakov, Igor;Merkulova, Olga;Nozik, Alexander;Fromme, Petra;Mazalova, Victoria",56520342400;57684118600;57683932700;7003500276;16245947800,European Synchrotron Radiation Facility;Deutsches Elektronen-Synchrotron (DESY);Helmholtz-Zentrum Hereon GmbH;Arizona State University;JetBrains Research,France;Germany;Germany;United States;Czech Republic,"a novel approach to the remote-control system for the compact multi-crystal energy-dispersive spectrometer for x-ray emission spectroscopy (xes) applications has been developed. this new approach is based on asynchronous communication between software components and on reactive design principles. in this paper, the challenges faced, their solutions, as well as the implementation and future development prospects are identified. the main motivation of this work was the development of a new holistic communication protocol that can be implemented to control various hardware components allowing both independent operation and easy integration into different scada systems.",a novel solution for controlling hardware components of accelerators and beamlines
37,2-s2.0-85122066472,10.1002/spe.3061,Evaluation of design pattern alternatives in Java,Bijlsma L.A.,Software - Practice and Experience,2022-05-01,"Design patterns are standard solutions to common design problems. The famous Gang of Four book describes more than twenty design patterns for the object-oriented paradigm. These patterns were developed more than twenty-five years ago, using the programming language concepts available at that time. Patterns do not always fit underlying domain concepts. For example, even when a concrete strategy is a pure function, the classical strategy pattern represents this as a separate subclass and as such obscures the intent of this pattern with extra complexities due to the inheritance-based implementation. Due to the ongoing development of oo-languages, a relevant question is whether the implementation of these patterns can be improved using new language features, such that they fit more closely with the intent. An additional question is then how we can decide which implementation is to be preferred. In this article, we investigate both questions, using the strategy pattern as an example. Our main contribution is that we show how to reason about different implementations, using both the description of a design pattern and design principles as guidance.",design patterns | features of programming languages | functional features | multiparadigm | programming languages,0,1305-1315,Journal,Article,5.0,"Bijlsma, Lex A.;Kok, Arjan J.F.;Passier, Harrie J.M.;Pootjes, Harold J.;Stuurman, Sylvia",18433244900;7006873432;26533090200;56644712200;6602634526,Open Universiteit,Netherlands,"design patterns are standard solutions to common design problems. the famous gang of four book describes more than twenty design patterns for the object-oriented paradigm. these patterns were developed more than twenty-five years ago, using the programming language concepts available at that time. patterns do not always fit underlying domain concepts. for example, even when a concrete strategy is a pure function, the classical strategy pattern represents this as a separate subclass and as such obscures the intent of this pattern with extra complexities due to the inheritance-based implementation. due to the ongoing development of oo-languages, a relevant question is whether the implementation of these patterns can be improved using new language features, such that they fit more closely with the intent. an additional question is then how we can decide which implementation is to be preferred. in this article, we investigate both questions, using the strategy pattern as an example. our main contribution is that we show how to reason about different implementations, using both the description of a design pattern and design principles as guidance.",evaluation of design pattern alternatives in java
38,2-s2.0-85092534617,10.1109/TSE.2020.3025443,Vuln4Real: A Methodology for Counting Actually Vulnerable Dependencies,Pashchenko I.,IEEE Transactions on Software Engineering,2022-05-01,"Vulnerable dependencies are a known problem in today's free open-source software ecosystems because FOSS libraries are highly interconnected, and developers do not always update their dependencies. Our paper proposes Vuln4Real, the methodology for counting actually vulnerable dependencies, that addresses the over-inflation problem of academic and industrial approaches for reporting vulnerable dependencies in FOSS software, and therefore, caters to the needs of industrial practice for correct allocation of development and audit resources. To understand the industrial impact of a more precise methodology, we considered the 500 most popular FOSS Java libraries used by SAP in its own software. Our analysis included 25767 distinct library instances in Maven. We found that the proposed methodology has visible impacts on both ecosystem view and the individual library developer view of the situation of software dependencies: Vuln4Real significantly reduces the number of false alerts for deployed code (dependencies wrongly flagged as vulnerable), provides meaningful insights on the exposure to third-parties (and hence vulnerabilities) of a library, and automatically predicts when dependency maintenance starts lagging, so it may not receive updates for arising issues.",free open source software | mining software repositories | Vulnerable dependency,0,1592-1609,Journal,Article,5.0,"Pashchenko, Ivan;Plate, Henrik;Ponta, Serena Elisa;Sabetta, Antonino;Massacci, Fabio",57195998561;24476873000;35111618100;9039083700;55167501300,Università di Trento;Vrije Universiteit Amsterdam;Security Research,Italy;Netherlands;France,"vulnerable dependencies are a known problem in today's free open-source software ecosystems because foss libraries are highly interconnected, and developers do not always update their dependencies. our paper proposes vuln4real, the methodology for counting actually vulnerable dependencies, that addresses the over-inflation problem of academic and industrial approaches for reporting vulnerable dependencies in foss software, and therefore, caters to the needs of industrial practice for correct allocation of development and audit resources. to understand the industrial impact of a more precise methodology, we considered the 500 most popular foss java libraries used by sap in its own software. our analysis included 25767 distinct library instances in maven. we found that the proposed methodology has visible impacts on both ecosystem view and the individual library developer view of the situation of software dependencies: vuln4real significantly reduces the number of false alerts for deployed code (dependencies wrongly flagged as vulnerable), provides meaningful insights on the exposure to third-parties (and hence vulnerabilities) of a library, and automatically predicts when dependency maintenance starts lagging, so it may not receive updates for arising issues.",vuln4real: a methodology for counting actually vulnerable dependencies
40,2-s2.0-85130407215,10.1145/3477314.3507693,A comprehensive approach to conceptual modelling and visual representation of log files,Rakhmetova E.,Proceedings of the ACM Symposium on Applied Computing,2022-04-25,"This paper proposes a comprehensive approach to conceptual log file modelling. It is based on the UML (Unified Modelling Language) class diagrams, which notation was extended to represent the main functionality of the nested structure of JSON (JavaScript Object Notation) log files. An implementation of the approach is illustrated in two domains: banking applications and networking. This study is a first step towards the sound development of a centralized log files management system. We use the ECS (Elastic Common Schema) initiative as a starting point. We also present the developed plugin to the StarUML software, which allows modelling logs in both UML and JSON formats.",conceptual modelling | elastic common schema | JSON | log files | UML,0,385-388,Conference Proceeding,Conference Paper,3.0,"Rakhmetova, Evelina;Garosi, Marco;Combi, Carlo",57284885200;57699330500;7003413825,Università degli Studi di Verona,Italy,"this paper proposes a comprehensive approach to conceptual log file modelling. it is based on the uml (unified modelling language) class diagrams, which notation was extended to represent the main functionality of the nested structure of json (javascript object notation) log files. an implementation of the approach is illustrated in two domains: banking applications and networking. this study is a first step towards the sound development of a centralized log files management system. we use the ecs (elastic common schema) initiative as a starting point. we also present the developed plugin to the staruml software, which allows modelling logs in both uml and json formats.",a comprehensive approach to conceptual modelling and visual representation of log files
42,2-s2.0-85129794072,10.1145/3485447.3512225,CoProtector: Protect Open-Source Code against Unauthorized Training Usage with Data Poisoning,Sun Z.,WWW 2022 - Proceedings of the ACM Web Conference 2022,2022-04-25,"Github Copilot, trained on billions of lines of public code, has recently become the buzzword in the computer science research and practice community. Although it is designed to help developers implement safe and effective code with powerful intelligence, practitioners and researchers raise concerns about its ethical and security problems, e.g., should the copyleft licensed code be freely leveraged or insecure code be considered for training in the first place? These problems pose a significant impact on Copilot and other similar products that aim to learn knowledge from large-scale open-source code through deep learning models, which are inevitably on the rise with the fast development of artificial intelligence. To mitigate such impacts, we argue that there is a need to invent effective mechanisms for protecting open-source code from being exploited by deep learning models. Here, we design and implement a prototype, CoProtector, which utilizes data poisoning techniques to arm source code repositories for defending against such exploits. Our large-scale experiments empirically show that CoProtector is effective in achieving its purpose, significantly reducing the performance of Copilot-like deep learning models while being able to stably reveal the secretly embedded watermark backdoors.",data poisoning | dataset protection | deep learning | open-source code,0,652-660,Conference Proceeding,Conference Paper,5.0,"Sun, Zhensu;Du, Xiaoning;Song, Fu;Ni, Mingze;Li, Li",57216462016;57327423500;50562054300;57327423600;57211233239,ShanghaiTech University;University of Technology Sydney;Monash University,China;Australia;Australia,"github copilot, trained on billions of lines of public code, has recently become the buzzword in the computer science research and practice community. although it is designed to help developers implement safe and effective code with powerful intelligence, practitioners and researchers raise concerns about its ethical and security problems, e.g., should the copyleft licensed code be freely leveraged or insecure code be considered for training in the first place? these problems pose a significant impact on copilot and other similar products that aim to learn knowledge from large-scale open-source code through deep learning models, which are inevitably on the rise with the fast development of artificial intelligence. to mitigate such impacts, we argue that there is a need to invent effective mechanisms for protecting open-source code from being exploited by deep learning models. here, we design and implement a prototype, coprotector, which utilizes data poisoning techniques to arm source code repositories for defending against such exploits. our large-scale experiments empirically show that coprotector is effective in achieving its purpose, significantly reducing the performance of copilot-like deep learning models while being able to stably reveal the secretly embedded watermark backdoors.",coprotector: protect open-source code against unauthorized training usage with data poisoning
43,2-s2.0-85130477337,10.1145/3476883.3520214,Procedural dungeon generation for a 2D top-down game,Weeks M.,Proceedings of the 2022 ACMSE Conference - ACMSE 2022: The Annual ACM Southeast Conference,2022-04-18,"This work examines solvability, difficulty, and engagement of procedurally generated content for a 2D, top-down game. We adapt the A∗ algorithm to find a solution when there are keys and locks between the starting position and the goal. It requires iteration to find a solution, since analysis of points in the dungeon alone are computationally expensive. If no solution exists, the program can detect this by showing no progress made in an iteration. We ran this on 30 dungeons, and classified their content according to the metrics of solvability, difficulty, and engagement.",game development | key and lock puzzles | path-finding | procedural content generation,0,60-66,Conference Proceeding,Conference Paper,2.0,"Weeks, Michael;Davis, Jonathon",7005583247;57701774200,Georgia State University,United States,"this work examines solvability, difficulty, and engagement of procedurally generated content for a 2d, top-down game. we adapt the a∗ algorithm to find a solution when there are keys and locks between the starting position and the goal. it requires iteration to find a solution, since analysis of points in the dungeon alone are computationally expensive. if no solution exists, the program can detect this by showing no progress made in an iteration. we ran this on 30 dungeons, and classified their content according to the metrics of solvability, difficulty, and engagement.",procedural dungeon generation for a 2d top-down game
46,2-s2.0-85125759542,10.1007/s10009-022-00647-1,Software test results exploration and visualization with continuous integration and nightly testing,Strandberg P.E.,International Journal on Software Tools for Technology Transfer,2022-04-01,"Software testing is key for quality assurance of embedded systems. However, with increased development pace, the amount of test results data risks growing to a level where exploration and visualization of the results are unmanageable. This paper covers a tool, Tim, implemented at a company developing embedded systems, where software development occurs in parallel branches and nightly testing is partitioned over software branches, test systems and test cases. Tim aims to replace a previous solution with problems of scalability, requirements and technological flora. Tim was implemented with a reference group over several months. For validation, data were collected both from reference group meetings and logs from the usage of the tool. Data were analyzed quantitatively and qualitatively. The main contributions from the study include the implementation of eight views for test results exploration and visualization, the identification of four solutions patterns for these views (filtering, aggregation, previews and comparisons), as well as six challenges frequently discussed at reference group meetings (expectations, anomalies, navigation, integrations, hardware details and plots). Results are put in perspective with related work and future work is proposed, e.g., enhanced anomaly detection and integrations with more systems such as risk management, source code and requirements repositories.",Software testing | Test results | Visual analytics,1,261-285,Journal,Article,3.0,"Strandberg, Per Erik;Afzal, Wasif;Sundmark, Daniel",57193354005;24832739300;8328803400,Mälardalens högskola;Westermo Network Technologies AB,Sweden;Sweden,"software testing is key for quality assurance of embedded systems. however, with increased development pace, the amount of test results data risks growing to a level where exploration and visualization of the results are unmanageable. this paper covers a tool, tim, implemented at a company developing embedded systems, where software development occurs in parallel branches and nightly testing is partitioned over software branches, test systems and test cases. tim aims to replace a previous solution with problems of scalability, requirements and technological flora. tim was implemented with a reference group over several months. for validation, data were collected both from reference group meetings and logs from the usage of the tool. data were analyzed quantitatively and qualitatively. the main contributions from the study include the implementation of eight views for test results exploration and visualization, the identification of four solutions patterns for these views (filtering, aggregation, previews and comparisons), as well as six challenges frequently discussed at reference group meetings (expectations, anomalies, navigation, integrations, hardware details and plots). results are put in perspective with related work and future work is proposed, e.g., enhanced anomaly detection and integrations with more systems such as risk management, source code and requirements repositories.",software test results exploration and visualization with continuous integration and nightly testing
52,2-s2.0-85105882103,10.1109/JSYST.2021.3072154,ISVSF: Intelligent Vulnerability Detection Against Java via Sentence-Level Pattern Exploring,Zhang H.,IEEE Systems Journal,2022-03-01,"When software vulnerabilities threaten the security of users, new research on approaches to reduce security vulnerabilities must be explored. The development of deep learning has opened up the era of automatic code vulnerability detection, extricated humans from multifarious pattern definition, and feature selection. However, existing deep learning based vulnerability detection schemes are still in their early stage, most of them adopted token-level representing schemes, losing the logical information above token level and resulting in the narrowing of differences between codes. They always had low accuracy and high false positive rate. In addition, it is noticed that most code vulnerability detection methods focused on C/C++, and little work can be found on Java. In light of this, we propose an intelligent sentence-level vulnerability self-detection framework (ISVSF), which considers the syntax characteristics of Java and adopts sentence-level method representation and pattern exploration. Experimental results demonstrate that the ISVSF outperforms the existing token-level vulnerability detection schemes in terms of accuracy, false positive rate, detection time, etc. In addition, fast and strong vulnerability feature extraction enables ISVSF to learn vulnerability-related features quickly and achieve high accuracy with providing little training samples, thereby reducing the demand for training dataset effectively.",Code feature | Java language | Vulnerability detection | Vulnerability pattern,0,1032-1043,Journal,Article,5.0,"Zhang, Haibin;Bi, Yifei;Guo, Hongzhi;Sun, Wen;Li, Jianpeng",55685617900;57223427497;56446017700;55548183900;57200420573,Xidian University;Northwestern Polytechnical University,China;China,"when software vulnerabilities threaten the security of users, new research on approaches to reduce security vulnerabilities must be explored. the development of deep learning has opened up the era of automatic code vulnerability detection, extricated humans from multifarious pattern definition, and feature selection. however, existing deep learning based vulnerability detection schemes are still in their early stage, most of them adopted token-level representing schemes, losing the logical information above token level and resulting in the narrowing of differences between codes. they always had low accuracy and high false positive rate. in addition, it is noticed that most code vulnerability detection methods focused on c/c++, and little work can be found on java. in light of this, we propose an intelligent sentence-level vulnerability self-detection framework (isvsf), which considers the syntax characteristics of java and adopts sentence-level method representation and pattern exploration. experimental results demonstrate that the isvsf outperforms the existing token-level vulnerability detection schemes in terms of accuracy, false positive rate, detection time, etc. in addition, fast and strong vulnerability feature extraction enables isvsf to learn vulnerability-related features quickly and achieve high accuracy with providing little training samples, thereby reducing the demand for training dataset effectively.",isvsf: intelligent vulnerability detection against java via sentence-level pattern exploring
54,2-s2.0-85125721876,10.1109/TLT.2022.3154936,Improving Learning Environments: Avoiding Stupidity Perspective,Pelanek R.,IEEE Transactions on Learning Technologies,2022-02-01,"Research in learning technologies is often focused on optimizing some aspects of human learning. However, the usefulness of practical learning environments is heavily influenced by their weakest aspects, and, unfortunately, there are many things that can go wrong in the learning process. In this article, we argue that in many circumstances, it is more useful to focus on avoiding stupidity rather than seeking optimality. To make this perspective specific and actionable, we propose a definition of stupidity, a taxonomy of undesirable behaviors of learning environments, and an overview of data-driven techniques for finding defects. The provided overview is directly applicable in the development of learning environments and also provides inspiration for novel research directions and novel applications of existing techniques.",Computer-aided instruction | data-driven techniques | defects | student modeling,0,64-77,Journal,Article,2.0,"Pelanek, Radek;Effenberger, Tomas",8961121100;57203400352,Masaryk University,Czech Republic,"research in learning technologies is often focused on optimizing some aspects of human learning. however, the usefulness of practical learning environments is heavily influenced by their weakest aspects, and, unfortunately, there are many things that can go wrong in the learning process. in this article, we argue that in many circumstances, it is more useful to focus on avoiding stupidity rather than seeking optimality. to make this perspective specific and actionable, we propose a definition of stupidity, a taxonomy of undesirable behaviors of learning environments, and an overview of data-driven techniques for finding defects. the provided overview is directly applicable in the development of learning environments and also provides inspiration for novel research directions and novel applications of existing techniques.",improving learning environments: avoiding stupidity perspective
55,2-s2.0-85125488043,10.1109/TSE.2020.2996975,Inferring Bug Signatures to Detect Real Bugs,Zhong H.,IEEE Transactions on Software Engineering,2022-02-01,"Static tools like Findbugs allow their users to manually define bug patterns, so they can detect more types of bugs, but due to the complexity and variety of programs, it is difficult to manually enumerate all bug patterns, especially for those related to API usages or project-specific rules. Therefore, existing bug-detection tools (e.g., Findbugs) based on manual bug patterns are insufficient in detecting many bugs. Meanwhile, with the rapid development of software, many past bug fixes accumulate in software version histories. These bug fixes contain valuable samples of illegal coding practices. The gap between existing bug samples and well-defined bug patterns motivates our research. In the literature, researchers have explored techniques on learning bug signatures from existing bugs, and a bug signature is defined as a set of program elements explaining the cause/effect of the bug. However, due to various limitations, existing approaches cannot analyze past bug fixes in large scale, and to the best of our knowledge, no previously unknown bugs were ever reported by their work. The major challenge to automatically analyze past bug fixes is that, bug-inducing inputs are typically not recorded, and many bug fixes are partial programs that have compilation errors. As a result, for most bugs in the version history, it is infeasible to reproduce them for dynamic analysis or to feed buggy/fixed code directly into static analysis tools which mostly depend on compilable complete programs. In this paper, we propose an approach, called DePa, that extracts bug signatures based on accurate partial-code analysis of bug fixes. With its support, we conduct the first large scale evaluation on 6,048 past bug fixes collected from four popular Apache projects. In particular, we use DePa to infer bug signatures from these fixes, and to check the latest versions of the four projects with the inferred bug signatures. Our results show that DePa detected 27 unique previously unknown bugs in total, including at least one bug from each project. These bugs are not detected by their developers nor other researchers. Among them, three of our reported bugs are already confirmed and repaired by their developers. Furthermore, our results show that the state-of-the-art tools detected only two of our found bugs, and our filtering techniques improve our precision from 25.5 to 51.5 percent.",Bug fix | Bug signature | Partial code analysis,0,571-584,Journal,Article,3.0,"Zhong, Hao;Wang, Xiaoyin;Mei, Hong",57020638700;57196447716;7103007678,Shanghai Jiao Tong University;The University of Texas at San Antonio,China;United States,"static tools like findbugs allow their users to manually define bug patterns, so they can detect more types of bugs, but due to the complexity and variety of programs, it is difficult to manually enumerate all bug patterns, especially for those related to api usages or project-specific rules. therefore, existing bug-detection tools (e.g., findbugs) based on manual bug patterns are insufficient in detecting many bugs. meanwhile, with the rapid development of software, many past bug fixes accumulate in software version histories. these bug fixes contain valuable samples of illegal coding practices. the gap between existing bug samples and well-defined bug patterns motivates our research. in the literature, researchers have explored techniques on learning bug signatures from existing bugs, and a bug signature is defined as a set of program elements explaining the cause/effect of the bug. however, due to various limitations, existing approaches cannot analyze past bug fixes in large scale, and to the best of our knowledge, no previously unknown bugs were ever reported by their work. the major challenge to automatically analyze past bug fixes is that, bug-inducing inputs are typically not recorded, and many bug fixes are partial programs that have compilation errors. as a result, for most bugs in the version history, it is infeasible to reproduce them for dynamic analysis or to feed buggy/fixed code directly into static analysis tools which mostly depend on compilable complete programs. in this paper, we propose an approach, called depa, that extracts bug signatures based on accurate partial-code analysis of bug fixes. with its support, we conduct the first large scale evaluation on 6,048 past bug fixes collected from four popular apache projects. in particular, we use depa to infer bug signatures from these fixes, and to check the latest versions of the four projects with the inferred bug signatures. our results show that depa detected 27 unique previously unknown bugs in total, including at least one bug from each project. these bugs are not detected by their developers nor other researchers. among them, three of our reported bugs are already confirmed and repaired by their developers. furthermore, our results show that the state-of-the-art tools detected only two of our found bugs, and our filtering techniques improve our precision from 25.5 to 51.5 percent.",inferring bug signatures to detect real bugs
56,2-s2.0-85124833906,10.3390/tomography8010040,"Integrating the OHIF Viewer into XNAT: Achievements, Challenges and Prospects for Quantitative Imaging Studies",Doran S.J.,Tomography,2022-02-01,"Purpose: XNAT is an informatics software platform to support imaging research, particularly in the context of large, multicentre studies of the type that are essential to validate quantitative imaging biomarkers. XNAT provides import, archiving, processing and secure distribution facilities for image and related study data. Until recently, however, modern data visualisation and annotation tools were lacking on the XNAT platform. We describe the background to, and implementation of, an integration of the Open Health Imaging Foundation (OHIF) Viewer into the XNAT environment. We explain the challenges overcome and discuss future prospects for quantitative imaging studies. Materials and methods: The OHIF Viewer adopts an approach based on the DICOM web protocol. To allow operation in an XNAT environment, a data-routing methodology was developed to overcome the mismatch between the DICOM and XNAT information models and a custom viewer panel created to allow navigation within the viewer between different XNAT projects, subjects and imaging sessions. Modifications to the development environment were made to allow developers to test new code more easily against a live XNAT instance. Major new developments focused on the creation and storage of regions-of-interest (ROIs) and included: ROI creation and editing tools for both contour-and mask-based regions; a “smart CT” paintbrush tool; the integration of NVIDIA’s Artificial Intelligence Assisted Annotation (AIAA); the ability to view surface meshes, fractional segmentation maps and image overlays; and a rapid image reader tool aimed at radiologists. We have incorporated the OHIF microscopy extension and, in parallel, introduced support for microscopy session types within XNAT for the first time. Results: Integration of the OHIF Viewer within XNAT has been highly successful and numerous additional and enhanced tools have been created in a programme started in 2017 that is still ongoing. The software has been downloaded more than 3700 times during the course of the development work reported here, demonstrating the impact of the work. Conclusions: The OHIF open-source, zero-footprint web viewer has been incorporated into the XNAT platform and is now used at many institutions worldwide. Further innovations are envisaged in the near future.",Image visualisation | OHIF | Rapid reader | Regions-of-interest | Web viewer | XNAT,0,497-512,Journal,Article,16.0,"Doran, Simon J.;Al Sa’D, Mohammad;Petts, James A.;Darcy, James;Alpert, Kate;Cho, Woonchan;Sanchez, Lorena Escudero;Alle, Sachidanand;El Harouni, Ahmed;Genereaux, Brad;Ziegler, Erik;Harris, Gordon J.;Aboagye, Eric O.;Sala, Evis;Koh, Dow Mu;Marcus, Dan",7005584633;57492180500;57211555793;56862093500;57786098500;57457465800;57222053717;57195602231;57457373500;55998648700;55604089600;7403158766;7004143668;7004450805;57211256625;9941107300,"Department of Radiology;NVIDIA;University of Cambridge;Massachusetts General Hospital;Washington University School of Medicine in St. Louis;Imperial College London;Royal Marsden Hospital;The Institute of Cancer Research;Harvard Medical School;CRUK National Cancer Imaging Translational Accelerator;Radical Imaging LLC;Ovela Solutions Ltd.;Flywheel Exchange, LLC",United Kingdom;United States;United Kingdom;United States;United States;United Kingdom;United Kingdom;United Kingdom;United States;United Kingdom;United States;United Kingdom;United States,"purpose: xnat is an informatics software platform to support imaging research, particularly in the context of large, multicentre studies of the type that are essential to validate quantitative imaging biomarkers. xnat provides import, archiving, processing and secure distribution facilities for image and related study data. until recently, however, modern data visualisation and annotation tools were lacking on the xnat platform. we describe the background to, and implementation of, an integration of the open health imaging foundation (ohif) viewer into the xnat environment. we explain the challenges overcome and discuss future prospects for quantitative imaging studies. materials and methods: the ohif viewer adopts an approach based on the dicom web protocol. to allow operation in an xnat environment, a data-routing methodology was developed to overcome the mismatch between the dicom and xnat information models and a custom viewer panel created to allow navigation within the viewer between different xnat projects, subjects and imaging sessions. modifications to the development environment were made to allow developers to test new code more easily against a live xnat instance. major new developments focused on the creation and storage of regions-of-interest (rois) and included: roi creation and editing tools for both contour-and mask-based regions; a “smart ct” paintbrush tool; the integration of nvidia’s artificial intelligence assisted annotation (aiaa); the ability to view surface meshes, fractional segmentation maps and image overlays; and a rapid image reader tool aimed at radiologists. we have incorporated the ohif microscopy extension and, in parallel, introduced support for microscopy session types within xnat for the first time. results: integration of the ohif viewer within xnat has been highly successful and numerous additional and enhanced tools have been created in a programme started in 2017 that is still ongoing. the software has been downloaded more than 3700 times during the course of the development work reported here, demonstrating the impact of the work. conclusions: the ohif open-source, zero-footprint web viewer has been incorporated into the xnat platform and is now used at many institutions worldwide. further innovations are envisaged in the near future.","integrating the ohif viewer into xnat: achievements, challenges and prospects for quantitative imaging studies"
60,2-s2.0-85129181545,10.1145/3520084.3520092,Design and Development of a Technology-Agnostic NFR Testing Framework: Introducing the framework and discussing the future of load testing in Agile software development,Whiting E.,ACM International Conference Proceeding Series,2022-01-21,"Testing the non-functional requirements (NFR) of a system is particularly complicated and time-consuming. Challenges in this area are compounded when the system is developed under some offspring of Agile methodologies, which favor iterative development and rapid feedback from extensive testing. The authors of this paper build upon previous work investigating the common challenges and solutions cited in recent peer-reviewed research on this topic to design and build a tool consolidating many of the concepts found in this investigation. The tool is known as LuluPerfTest (LPT) and is an NFR testing framework meant to plug into continuous integration (CI) systems to run NFR tests configured with a JSON script. This allows developers and testers to build maintainable and minimally complex automated NFR test scripts. This study explains the challenges inherent in NFR testing in Agile software development and presents how LPT confronts those challenges. It aims to explain LPT and invite collaboration among other testing, verification, and validation researchers to create an open sources software (OSS) solution to the problems of NFR testing in Agile software development projects.",non-functional requirements | performance testing | Software testing,0,45-50,Conference Proceeding,Conference Paper,2.0,"Whiting, Erik;Datta, Soma",57219371523;57197775142,University of Houston-Clear Lake,United States,"testing the non-functional requirements (nfr) of a system is particularly complicated and time-consuming. challenges in this area are compounded when the system is developed under some offspring of agile methodologies, which favor iterative development and rapid feedback from extensive testing. the authors of this paper build upon previous work investigating the common challenges and solutions cited in recent peer-reviewed research on this topic to design and build a tool consolidating many of the concepts found in this investigation. the tool is known as luluperftest (lpt) and is an nfr testing framework meant to plug into continuous integration (ci) systems to run nfr tests configured with a json script. this allows developers and testers to build maintainable and minimally complex automated nfr test scripts. this study explains the challenges inherent in nfr testing in agile software development and presents how lpt confronts those challenges. it aims to explain lpt and invite collaboration among other testing, verification, and validation researchers to create an open sources software (oss) solution to the problems of nfr testing in agile software development projects.",design and development of a technology-agnostic nfr testing framework: introducing the framework and discussing the future of load testing in agile software development
64,2-s2.0-85135855843,10.14569/IJACSA.2022.0130791,Mobile Application Prototype: Learning in the Programming Course in Computer Engineering Students,Ocares-Cunyarachi L.,International Journal of Advanced Computer Science and Applications,2022-01-01,"Students need to continue with the learning process related to the world of programming because today are in the era of technological globalization. Therefore, it is very important to learn about it, since programming is used in different areas and as a result obtain software, electronic devices, among others. seek to design a mobile application that helps students learn much more about programming, since students in the first cycles of computer science and computer science have difficulties learning about different programming languages. That is why the application seeks to help the student by complementing their learning in such a way that they can obtain favorable results in their progress thanks to the development of the application. The objective is to design a mobile application for teaching programming in a didactic way that helps computer science students with learning difficulties. The methodology used is Design Thinking, because it is an agile methodology that is based on phases that help us understand and collect information about the problem encountered in order to provide a solution. As for the case study, the design of the mobile application and the detailed development of the prototype are shown. The result obtained is the prototype of the mobile application in which students with learning difficulties will benefit. In addition, a survey carried out at the University of Sciences and Humanities to students and teachers is shown, where very relevant data is obtained according to their learning",Design thinking | Learning | Mobile application | Programming | Students,0,783-791,Journal,Article,2.0,"Ocares-Cunyarachi, Lilian;Andrade-Arenas, Laberiano",57360921000;57207915215,Universidad de Ciencias y Humanidades,Peru,"students need to continue with the learning process related to the world of programming because today are in the era of technological globalization. therefore, it is very important to learn about it, since programming is used in different areas and as a result obtain software, electronic devices, among others. seek to design a mobile application that helps students learn much more about programming, since students in the first cycles of computer science and computer science have difficulties learning about different programming languages. that is why the application seeks to help the student by complementing their learning in such a way that they can obtain favorable results in their progress thanks to the development of the application. the objective is to design a mobile application for teaching programming in a didactic way that helps computer science students with learning difficulties. the methodology used is design thinking, because it is an agile methodology that is based on phases that help us understand and collect information about the problem encountered in order to provide a solution. as for the case study, the design of the mobile application and the detailed development of the prototype are shown. the result obtained is the prototype of the mobile application in which students with learning difficulties will benefit. in addition, a survey carried out at the university of sciences and humanities to students and teachers is shown, where very relevant data is obtained according to their learning",mobile application prototype: learning in the programming course in computer engineering students
66,2-s2.0-85135830396,10.1109/SANER53432.2022.00031,Exploring API Deprecation Evolution in JavaScript,Nascimento R.,"Proceedings - 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022",2022-01-01,"Building an application using third-party libraries is a common practice in software development. As any other system, software libraries and their APIs evolve. To support version migration and ensure backward compatibility, a recommended practice during development is to deprecate API. Different from other popular programming languages such as Java and C#, JavaScript has no native support to deprecate API elements. However, several strategies are commonly adopted to communicate that an API should be avoided, such as the project documentation, JSDoc annotation, code comment, console message, and deprecation utility. Indeed, there have been many studies on deprecation strategies and evolution mostly on Java, C#, and Python. However, to the best of our knowledge, there are no detailed studies aiming at analyzing how API deprecation changes over time in the JavaScript ecosystem. This paper provides an empirical study on how API deprecation evolves in JavaScript by analyzing 1,918 releases of 50 popular packages. Results show that close to 60% have rising trends in the number of deprecated APIs, while only 9.4% indicate a downward trend. Also, most deprecation occurrences are both added and removed on minor releases instead of removed on major releases, as recommended by best practices.",API deprecation | JavaScript library | Software evolution | Software maintenance | Software mining,0,169-173,Conference Proceeding,Conference Paper,3.0,"Nascimento, Romulo;Hora, Andre;Figueiredo, Eduardo",57216459151;55205116000;18433988600,Universidade Federal de Minas Gerais,Brazil,"building an application using third-party libraries is a common practice in software development. as any other system, software libraries and their apis evolve. to support version migration and ensure backward compatibility, a recommended practice during development is to deprecate api. different from other popular programming languages such as java and c#, javascript has no native support to deprecate api elements. however, several strategies are commonly adopted to communicate that an api should be avoided, such as the project documentation, jsdoc annotation, code comment, console message, and deprecation utility. indeed, there have been many studies on deprecation strategies and evolution mostly on java, c#, and python. however, to the best of our knowledge, there are no detailed studies aiming at analyzing how api deprecation changes over time in the javascript ecosystem. this paper provides an empirical study on how api deprecation evolves in javascript by analyzing 1,918 releases of 50 popular packages. results show that close to 60% have rising trends in the number of deprecated apis, while only 9.4% indicate a downward trend. also, most deprecation occurrences are both added and removed on minor releases instead of removed on major releases, as recommended by best practices.",exploring api deprecation evolution in javascript
67,2-s2.0-85135812624,10.14569/IJACSA.2022.01307107,A Model Driven Approach for Unifying User Interfaces Development,Soude H.,International Journal of Advanced Computer Science and Applications,2022-01-01,"In this paper, we dealt with the rapid development of client web applications (frontend) in a context where development frameworks are legion. In effect with the digital transformation due to the COVID-19 pandemic we are witnessing an ever-increasing demand of the application development in a relatively short time. To this is added the lack of skilled developers on constantly evolving technologies. We therefore offer a low-code platform for the automatic generation of client web applications, regardless of the platform or framework chosen. First, we defined an interface design methodology based on a portal. We then implemented our model driven architecture which consisted of defining a modeling and templating language, centered on user data, flexible enough to not only be used in various fields but also be easily used by a citizen developer.",Citizen developer | Low code | Model driven | Modeling language | Templating language | User interface,0,919-926,Journal,Article,2.0,"Soude, Henoc;Koussonda, Kefil",16550481700;57842821800,Institut de Mathématiques et des Sciences Physiques;EpiTech,Benin;France,"in this paper, we dealt with the rapid development of client web applications (frontend) in a context where development frameworks are legion. in effect with the digital transformation due to the covid-19 pandemic we are witnessing an ever-increasing demand of the application development in a relatively short time. to this is added the lack of skilled developers on constantly evolving technologies. we therefore offer a low-code platform for the automatic generation of client web applications, regardless of the platform or framework chosen. first, we defined an interface design methodology based on a portal. we then implemented our model driven architecture which consisted of defining a modeling and templating language, centered on user data, flexible enough to not only be used in various fields but also be easily used by a citizen developer.",a model driven approach for unifying user interfaces development
68,2-s2.0-85135449393,10.1109/ICACITE53722.2022.9823524,AI based WebApp development using Application Programming Interface (API),Johari D.,"2022 2nd International Conference on Advance Computing and Innovative Technologies in Engineering, ICACITE 2022",2022-01-01,"To compensate for the decline in downloads, streaming music on demand has expanded considerably. In addition, technological advancements and innovation have tremendously improved the Internet's structure and applications for sound streaming platforms. To put it simply, our product is a web-based music player that lets users listen to their music collections through a home computer server software and, in most cases, a web-based client application. For this reason, we'll be making use of SoundCloud's API (Application Programming Interface). The API (Application Programming Interface) will be connected to our Web Application so that when a customer requests data over TTP (Hypertext Transfer Protocol), it will be shown on the UI (User Interface). Our Web Application will be linked to either MySQL or Firebase to store the data of our clients. An AI (Artificial Intelligence) recommendation system will also be implemented to help people discover new music based on their own preferences.",AI (Artificial Intelligence) | API (Application Programming Interface) | HTTP (Hypertext transfer Protocol) | UI (User-Interface) | www (World Wide Web),0,474-479,Conference Proceeding,Conference Paper,3.0,"Johari, Dhruv;Samaddar, Sayani;Kumar, Sanjay",57831952500;57832123200;57738779000,Galgotias University,India,"to compensate for the decline in downloads, streaming music on demand has expanded considerably. in addition, technological advancements and innovation have tremendously improved the internet's structure and applications for sound streaming platforms. to put it simply, our product is a web-based music player that lets users listen to their music collections through a home computer server software and, in most cases, a web-based client application. for this reason, we'll be making use of soundcloud's api (application programming interface). the api (application programming interface) will be connected to our web application so that when a customer requests data over ttp (hypertext transfer protocol), it will be shown on the ui (user interface). our web application will be linked to either mysql or firebase to store the data of our clients. an ai (artificial intelligence) recommendation system will also be implemented to help people discover new music based on their own preferences.",ai based webapp development using application programming interface (api)
69,2-s2.0-85135146095,10.1145/3528229.3529381,MicroGraphQL: a Unified Communication Approach for Systems of Systems using Microservices and GraphQL,Marcos M.V.,"Proceedings - 10th IEEE/ACM International Workshop on Software Engineering for Systems-of-Systems and Software Ecosystems, SESoS 2022",2022-01-01,"Context: establishing forms of unified communication in Aknowledge Systems of Systems (SoS) is a difficult and complex task that requires constant studies by the developer on current versions of Application Programming Interfaces (APIs) of other constituent systems, connection forms, data request and return. Objective: in order to minimize that aspect, this paper proposes a new approach, called MicroGraphQL, to allow fast and unified communication of constituent systems through GraphQL. To this end, the approach uses 2 microservices (API Similarity Analyzer Service, GraphQL Code Generator Service) and a GraphQL Gateway, which together analyze communication similarities between APIs and generate GraphQL code for these similarities. Methods: the proof-of-concept of the approach is supported by the microGraphQLTool tool, which implements the microservices and the GraphQL Gateway using the JavaScript language and the Apollo library. Results: the applicability of the proposed approach is successfully performed in two real APIs of systems constituting a sales SoS of a multinational company, allowing the use of GraphQL to unify them. Conclusion: the approach supports the development of new forms of SoS integration, facilitating developers' activities in relation to obtaining information from APIs of other systems. CCS CONCEPTS • Software and its engineering ? Distributed systems organizing principles.",GraphQL | Microservices | System of Systems,0,33-40,Conference Proceeding,Conference Paper,3.0,"Marcos, Marcos V.;Rocha, Lincoln S.;Maia, Paulo Henrique M.",57824252800;25655242100;57213875413,Universidade Estadual do Ceará;Universidade Federal do Ceará,Brazil;Brazil,"context: establishing forms of unified communication in aknowledge systems of systems (sos) is a difficult and complex task that requires constant studies by the developer on current versions of application programming interfaces (apis) of other constituent systems, connection forms, data request and return. objective: in order to minimize that aspect, this paper proposes a new approach, called micrographql, to allow fast and unified communication of constituent systems through graphql. to this end, the approach uses 2 microservices (api similarity analyzer service, graphql code generator service) and a graphql gateway, which together analyze communication similarities between apis and generate graphql code for these similarities. methods: the proof-of-concept of the approach is supported by the micrographqltool tool, which implements the microservices and the graphql gateway using the javascript language and the apollo library. results: the applicability of the proposed approach is successfully performed in two real apis of systems constituting a sales sos of a multinational company, allowing the use of graphql to unify them. conclusion: the approach supports the development of new forms of sos integration, facilitating developers' activities in relation to obtaining information from apis of other systems. ccs concepts • software and its engineering ? distributed systems organizing principles.",micrographql: a unified communication approach for systems of systems using microservices and graphql
70,2-s2.0-85135069136,10.1007/978-981-19-2456-9_34,Leveraging Modern Big Data Stack for Swift Development of Insights into Social Developments,Huang H.,Lecture Notes in Electrical Engineering,2022-01-01,"Insights of social development, presented in various forms, such as metrics, figures, text summaries, whose purpose is to summarize, explain, and predict the situations and trends of society, is extremely useful to guide organizations and individuals to better realize their own objectives in accordance with the whole society. Deriving these insights accurately and swiftly has become an interest for a range of organizations, including agencies governing districts, city even the whole country, they use these insights to inform policy-makings. Business investors who peak into statistical numbers for estimating current economical situations and future trends. Even for individuals, they could look at some of these insights to better align themselves with macroscopical social trends. There are many challenges to develop these insights in a data-driven approach. First, required data come from a large number of heterogeneous sources in a variety of formats. One single source’s data could be in the size of hundreds of Gigabytes to several TeraBytes, ingesting and governing such huge amount of data is not a small challenge. Second, many complex insights are derived by domain human experts in a trail-and-error fashion, while interacting with data with the aid of computer algorithms. To quickly experiment various algorithms, it asks for software capabilities for infusing human experts and machine intelligence together, this is challenging but critical for success. By designing and implementing a flexible big data stack that could bring in a variety of data components. We address some of the challenges to infuse data, computer algorithm and human together in Zilian Tech company [20]. In this paper we present the architecture of our data stack and articulate some of the important technical choices when building such stack. The stack is designed to be equipped with scalable storage that could scale up to PetaBytes, as well as elastic distributed compute engine with parallel computing algorithms. With these features the data stack enables a) swift data analysis, by human analysts interacting with data and machine algorithms via software support, with on-demand question answering time reduced from days to minutes; b) agile building of data products for end users to interact with, in weeks if not days from months.",Cloud | Data stack | Social development,0,325-333,Book Series,Conference Paper,6.0,"Huang, He;He, Yixin;Zhang, Longpeng;Zeng, Zhicheng;Ouyang, Tu;Zeng, Zhimin",57822502900;57223856833;57221588887;57821733500;24766750200;57225977770,University of Melbourne;University of Electronic Science and Technology of China;Case Western Reserve University;Zilian Tech Inc.,Australia;China;United States;China,"insights of social development, presented in various forms, such as metrics, figures, text summaries, whose purpose is to summarize, explain, and predict the situations and trends of society, is extremely useful to guide organizations and individuals to better realize their own objectives in accordance with the whole society. deriving these insights accurately and swiftly has become an interest for a range of organizations, including agencies governing districts, city even the whole country, they use these insights to inform policy-makings. business investors who peak into statistical numbers for estimating current economical situations and future trends. even for individuals, they could look at some of these insights to better align themselves with macroscopical social trends. there are many challenges to develop these insights in a data-driven approach. first, required data come from a large number of heterogeneous sources in a variety of formats. one single source’s data could be in the size of hundreds of gigabytes to several terabytes, ingesting and governing such huge amount of data is not a small challenge. second, many complex insights are derived by domain human experts in a trail-and-error fashion, while interacting with data with the aid of computer algorithms. to quickly experiment various algorithms, it asks for software capabilities for infusing human experts and machine intelligence together, this is challenging but critical for success. by designing and implementing a flexible big data stack that could bring in a variety of data components. we address some of the challenges to infuse data, computer algorithm and human together in zilian tech company [20]. in this paper we present the architecture of our data stack and articulate some of the important technical choices when building such stack. the stack is designed to be equipped with scalable storage that could scale up to petabytes, as well as elastic distributed compute engine with parallel computing algorithms. with these features the data stack enables a) swift data analysis, by human analysts interacting with data and machine algorithms via software support, with on-demand question answering time reduced from days to minutes; b) agile building of data products for end users to interact with, in weeks if not days from months.",leveraging modern big data stack for swift development of insights into social developments
74,2-s2.0-85134078066,10.1145/3524842.3528454,To Type or Not to Type? A Systematic Comparison of the Software Quality of JavaScript and TypeScript Applications on GitHub,Bogner J.,"Proceedings - 2022 Mining Software Repositories Conference, MSR 2022",2022-01-01,"JavaScript (JS) is one of the most popular programming languages, and widely used for web apps, mobile apps, desktop clients, and even backend development. Due to its dynamic and flexible nature, however, JS applications often have a reputation for poor software quality. While the type-safe superset TypeScript (TS) offers features to address these prejudices, there is currently insufficient empirical evidence to broadly support the claim that TS applications exhibit better software quality than JS applications. We therefore conducted a repository mining study based on 604 GitHub projects (299 for JS, 305 for TS) with over 16M LoC. Using SonarQube and the GitHub API, we collected and analyzed four facets of software quality: a) code quality (# of code smells per LoC), b) code understandability (cognitive complexity per LoC), c) bug proneness (bug fix commit ratio), and d) bug resolution time (mean time a bug issue is open). For TS, we also collected how frequently the type-safety ignoring any type was used per project via ESLint. The analysis indicates that TS applications exhibit significantly better code quality and understandability than JS applications. Contrary to expectations, however, bug proneness and bug resolution time of our TS sample were not significantly lower than for JS: the mean bug fix commit ratio of TS projects was more than 60% larger (0.126 vs. 0.206), and TS projects needed on average more than an additional day to fix bugs (31.86 vs. 33.04 days). Furthermore, reducing the usage of the any type in TS apps appears to be beneficial: its frequency was significantly correlated with all metrics except bug proneness, even though the correlations were of small strengths (Spearman's rho between 0.17 and 0.26). Our results indicate that the perceived positive influence of Type-Script for avoiding bugs in comparison to JavaScript may be more complicated than assumed. While using TS seems to have benefits, it does not automatically lead to less and easier to fix bugs. However, more research is needed in this area, especially concerning the potential influence of project complexity and developer experience.",GitHub | JavaScript | repository mining | software quality | TypeScript,0,658-669,Conference Proceeding,Conference Paper,2.0,"Bogner, Justus;Merkel, Manuel",57189261793;57567090400,Universität Stuttgart,Germany,"javascript (js) is one of the most popular programming languages, and widely used for web apps, mobile apps, desktop clients, and even backend development. due to its dynamic and flexible nature, however, js applications often have a reputation for poor software quality. while the type-safe superset typescript (ts) offers features to address these prejudices, there is currently insufficient empirical evidence to broadly support the claim that ts applications exhibit better software quality than js applications. we therefore conducted a repository mining study based on 604 github projects (299 for js, 305 for ts) with over 16m loc. using sonarqube and the github api, we collected and analyzed four facets of software quality: a) code quality (# of code smells per loc), b) code understandability (cognitive complexity per loc), c) bug proneness (bug fix commit ratio), and d) bug resolution time (mean time a bug issue is open). for ts, we also collected how frequently the type-safety ignoring any type was used per project via eslint. the analysis indicates that ts applications exhibit significantly better code quality and understandability than js applications. contrary to expectations, however, bug proneness and bug resolution time of our ts sample were not significantly lower than for js: the mean bug fix commit ratio of ts projects was more than 60% larger (0.126 vs. 0.206), and ts projects needed on average more than an additional day to fix bugs (31.86 vs. 33.04 days). furthermore, reducing the usage of the any type in ts apps appears to be beneficial: its frequency was significantly correlated with all metrics except bug proneness, even though the correlations were of small strengths (spearman's rho between 0.17 and 0.26). our results indicate that the perceived positive influence of type-script for avoiding bugs in comparison to javascript may be more complicated than assumed. while using ts seems to have benefits, it does not automatically lead to less and easier to fix bugs. however, more research is needed in this area, especially concerning the potential influence of project complexity and developer experience.",to type or not to type? a systematic comparison of the software quality of javascript and typescript applications on github
75,2-s2.0-85134071182,10.1145/3524842.3528028,ECench: An Energy Bug Benchmark of Ethereum Client Software,Kim J.,"Proceedings - 2022 Mining Software Repositories Conference, MSR 2022",2022-01-01,"With the introduction of smart contacts, Ethereum has become one of the most popular blockchain networks. In the wake of its popularity, an increasing number of Ethereum-based software have been developed. However, the carbon emissions resulting from these software has been pointed out as a global issue. It is necessary to reduce the energy consumed by these software to reduce carbon emissions. Recently, most studies have focused on smart contracts and proposed energy-efficient methods for the development of carbon friendly Ethereum networks. However, in addition to smart contracts, the energy used by client software in Ethereum networks should also be reviewed. This is because the client software performs all functions occurring in the Ethereum network, including smart contracts. Therefore, energy bugs that waste energy in Ethereum client software should be investigated and solved. The first task to enable this is to build an energy bug benchmark of Ethereum client software. This study introduces ECench, an energy bug benchmark of Ethereum client software. ECench includes 507 energy buggy commits from 7 series of client software that are officially operated in the Ethereum network. We carefully collected and manually reviewed them for cleaner commits. A key strength of our benchmark is that it provides eight energy wastage categories, which can serve as a cornerstone for researchers to identify energy waste codes. ECench can provide a valuable starting point for studies on energy reduction and carbon reduction in Ethereum.",Benchmark | energy consumption | ethereum | software engineering,0,634-638,Conference Proceeding,Conference Paper,3.0,"Kim, Jinyoung;Kim, Misoo;Lee, Eunseok",57797638500;57202894425;8979680900,Sungkyunkwan University,South Korea,"with the introduction of smart contacts, ethereum has become one of the most popular blockchain networks. in the wake of its popularity, an increasing number of ethereum-based software have been developed. however, the carbon emissions resulting from these software has been pointed out as a global issue. it is necessary to reduce the energy consumed by these software to reduce carbon emissions. recently, most studies have focused on smart contracts and proposed energy-efficient methods for the development of carbon friendly ethereum networks. however, in addition to smart contracts, the energy used by client software in ethereum networks should also be reviewed. this is because the client software performs all functions occurring in the ethereum network, including smart contracts. therefore, energy bugs that waste energy in ethereum client software should be investigated and solved. the first task to enable this is to build an energy bug benchmark of ethereum client software. this study introduces ecench, an energy bug benchmark of ethereum client software. ecench includes 507 energy buggy commits from 7 series of client software that are officially operated in the ethereum network. we carefully collected and manually reviewed them for cleaner commits. a key strength of our benchmark is that it provides eight energy wastage categories, which can serve as a cornerstone for researchers to identify energy waste codes. ecench can provide a valuable starting point for studies on energy reduction and carbon reduction in ethereum.",ecench: an energy bug benchmark of ethereum client software
76,2-s2.0-85134067533,10.1145/3524842.3527941,An Empirical Study on the Survival Rate of GitHub Projects,Ait A.,"Proceedings - 2022 Mining Software Repositories Conference, MSR 2022",2022-01-01,"The number of Open Source projects hosted in social coding platforms such as GitHub is constantly growing. However, many of these projects are not regularly maintained and some are even abandoned shortly after they were created. In this paper we analyze early project development dynamics in software projects hosted on GitHub, including their survival rate. To this aim, we collected all 1,127 GitHub repositories from four different ecosystems (i.e., NPM packages, R packages, WordPress plugins and Laravel packages) created in 2016. We stored their activity in a time series database and analyzed their activity evolution along their lifespan, from 2016 to now. Our results reveal that the prototypical development process consists of intensive coding-driven active periods followed by long periods of inactivity. More importantly, we have found that a significant number of projects die in the first year of existence with the survival rate decreasing year after year. In fact, the probability of surviving longer than five years is less than 50% though some types of projects have better chances of survival.",Empirical Study | Mining Software Repositories | Open Source Analysis | Survival Analysis,0,365-375,Conference Proceeding,Conference Paper,3.0,"Ait, Adem;Izquierdo, Javier Luis Canovas;Cabot, Jordi",57799014200;57797638600;8963493600,Institució Catalana de Recerca i Estudis Avançats,Spain,"the number of open source projects hosted in social coding platforms such as github is constantly growing. however, many of these projects are not regularly maintained and some are even abandoned shortly after they were created. in this paper we analyze early project development dynamics in software projects hosted on github, including their survival rate. to this aim, we collected all 1,127 github repositories from four different ecosystems (i.e., npm packages, r packages, wordpress plugins and laravel packages) created in 2016. we stored their activity in a time series database and analyzed their activity evolution along their lifespan, from 2016 to now. our results reveal that the prototypical development process consists of intensive coding-driven active periods followed by long periods of inactivity. more importantly, we have found that a significant number of projects die in the first year of existence with the survival rate decreasing year after year. in fact, the probability of surviving longer than five years is less than 50% though some types of projects have better chances of survival.",an empirical study on the survival rate of github projects
78,2-s2.0-85134029098,10.1145/3524842.3528480,FixJS: A Dataset of Bug-fixing JavaScript Commits,Csuvik V.,"Proceedings - 2022 Mining Software Repositories Conference, MSR 2022",2022-01-01,"The field of Automated Program Repair (APR) has received increasing attention in recent years both from the academic world and from leading IT companies. Its main goal is to repair software bugs automatically, thus reducing the cost of development and mainte-nance significantly. Recent works use state-of-the-art deep learning models to predict correct patches, for these teaching on a large amount of data is inevitable almost in every scenarios. Despite this, readily accessible data on the field is very scarce. To contribute to related research, we present FixJS, a dataset containing bug-fixing information of 2 million commits. The commits were gathered from GitHub and processed locally to have both the buggy (before bug fixing commit) and fixed (after fix) version of the same program. We focused on JavaScript functions, as it is one of the most popular programming language globally and functions are first class objects there. The data includes more than 300,000 samples of such functions, including commit information, before/after states and 3 source code representations.",Automated Program Repair | Bug-fixing commits | Software engineering,0,712-716,Conference Proceeding,Conference Paper,2.0,"Csuvik, Viktor;Vidacs, Laszlo",57202098135;6505688100,Szegedi Tudományegyetem (SZTE),Hungary,"the field of automated program repair (apr) has received increasing attention in recent years both from the academic world and from leading it companies. its main goal is to repair software bugs automatically, thus reducing the cost of development and mainte-nance significantly. recent works use state-of-the-art deep learning models to predict correct patches, for these teaching on a large amount of data is inevitable almost in every scenarios. despite this, readily accessible data on the field is very scarce. to contribute to related research, we present fixjs, a dataset containing bug-fixing information of 2 million commits. the commits were gathered from github and processed locally to have both the buggy (before bug fixing commit) and fixed (after fix) version of the same program. we focused on javascript functions, as it is one of the most popular programming language globally and functions are first class objects there. the data includes more than 300,000 samples of such functions, including commit information, before/after states and 3 source code representations.",fixjs: a dataset of bug-fixing javascript commits
79,2-s2.0-85133900943,10.23919/MIPRO55190.2022.9803757,IT Education in Clouds and Clouds in IT Education,Henno J.,"2022 45th Jubilee International Convention on Information, Communication and Electronic Technology, MIPRO 2022 - Proceedings",2022-01-01,"The rapid development of information and communication technology (ICT) and growing participation of students in work life has already in several decades moved ICT education into 'clouds', using sources of knowledge on Internet from all around the world. The COVID pandemic has increased this process, forcing universities to restrict classroom teaching and rapidly increased student's self-study.At the same time, increase of amounts of data to be processed is constantly introducing new high-level software technologies, layers and layers of packages and libraries, deeper and more complex. This has created a new 'top-down' programming style: a new project is started with importing mass of libraries which have been used in earlier projects and only then is considered how to use them in order to solve the programming task. The self-studying ICT students see only tips of modern software icebergs and it is difficult for them to understand their working without face-to-face classroom communication where details of the 'depths' are explained.",COVID | ICT | self-study | software complexity,0,620-625,Conference Proceeding,Conference Paper,3.0,"Henno, J.;Jaakkola, H.;Makela, J.",24724087600;6701815202;57215019078,Tallinna Tehnikaülikool;Tampere University;Lapin Yliopisto,Estonia;Finland;Finland,"the rapid development of information and communication technology (ict) and growing participation of students in work life has already in several decades moved ict education into 'clouds', using sources of knowledge on internet from all around the world. the covid pandemic has increased this process, forcing universities to restrict classroom teaching and rapidly increased student's self-study.at the same time, increase of amounts of data to be processed is constantly introducing new high-level software technologies, layers and layers of packages and libraries, deeper and more complex. this has created a new 'top-down' programming style: a new project is started with importing mass of libraries which have been used in earlier projects and only then is considered how to use them in order to solve the programming task. the self-studying ict students see only tips of modern software icebergs and it is difficult for them to understand their working without face-to-face classroom communication where details of the 'depths' are explained.",it education in clouds and clouds in it education
80,2-s2.0-85133900428,10.23919/MIPRO55190.2022.9803554,Analyzing Linter Usage and Warnings Through Mining Software Repositories: A Longitudinal Case Study of JavaScript Packages,Hericko T.,"2022 45th Jubilee International Convention on Information, Communication and Electronic Technology, MIPRO 2022 - Proceedings",2022-01-01,"Linters are static analysis tools supporting developers by automatically detecting possible code errors, bad coding practices, violations of coding conventions, and styling issues while offering actionable advice on how to resolve these concerns to prevent inconsistencies in the codebase, errors, and degrading software quality. They are especially beneficial for software projects based on dynamically-typed languages, e.g., JavaScript, which are more prone to development errors and inconsistencies due to languages' dynamic nature. However, little is known about how their usage and generated warnings evolve throughout the entire development histories of real-world software projects. This paper performs source code-based commit history analysis on 15 JavaScript npm packages. The empirical analysis of 16,562 commits revealed that the choice of linter and their configurations are rarely subjected to change once introduced to a package. When configurations do change, most modifications are minor. Unresolved violations of rules, which produce warnings, generally increase. Though, the density of warnings was found to be slightly decreasing with the maturity of a package - overall and for each distinct group of warnings.",code repositories | JavaScript | lint | npm packages | software quality assurance | static code analysis,0,1375-1380,Conference Proceeding,Conference Paper,2.0,"Hericko, Tjasa;Sumak, Bostjan",57490891500;24483973500,"Univerza v Mariboru Fakultete za Elektrotehniko, Računalništvo in Informatiko",Slovenia,"linters are static analysis tools supporting developers by automatically detecting possible code errors, bad coding practices, violations of coding conventions, and styling issues while offering actionable advice on how to resolve these concerns to prevent inconsistencies in the codebase, errors, and degrading software quality. they are especially beneficial for software projects based on dynamically-typed languages, e.g., javascript, which are more prone to development errors and inconsistencies due to languages' dynamic nature. however, little is known about how their usage and generated warnings evolve throughout the entire development histories of real-world software projects. this paper performs source code-based commit history analysis on 15 javascript npm packages. the empirical analysis of 16,562 commits revealed that the choice of linter and their configurations are rarely subjected to change once introduced to a package. when configurations do change, most modifications are minor. unresolved violations of rules, which produce warnings, generally increase. though, the density of warnings was found to be slightly decreasing with the maturity of a package - overall and for each distinct group of warnings.",analyzing linter usage and warnings through mining software repositories: a longitudinal case study of javascript packages
81,2-s2.0-85133531719,10.1145/3510003.3510199,An Exploratory Study of Deep learning Supply Chain,Tan X.,Proceedings - International Conference on Software Engineering,2022-01-01,"Deep learning becomes the driving force behind many contemporary technologies and has been successfully applied in many fields. Through software dependencies, a multi-layer supply chain (SC) with a deep learning framework as the core and substantial down-stream projects as the periphery has gradually formed and is constantly developing. However, basic knowledge about the structure and characteristics of the SC is lacking, which hinders effective support for its sustainable development. Previous studies on software SC usually focus on the packages in different registries without paying attention to the SCs derived from a single project. We present an empirical study on two deep learning SCs: TensorFlow and PyTorch SCs. By constructing and analyzing their SCs, we aim to understand their structure, application domains, and evolutionary factors. We find that both SCs exhibit a short and sparse hierarchy structure. Overall, the relative growth of new projects increases month by month. Projects have a tendency to attract downstream projects shortly after the release of their packages, later the growth becomes faster and tends to stabilize. We propose three criteria to identify vulnerabilities and identify 51 types of packages and 26 types of projects involved in the two SCs. A comparison reveals their similarities and differences, e.g., TensorFlow SC provides a wealth of packages in experiment result analysis, while PyTorch SC contains more specific framework packages. By fitting the GAM model, we find that the number of dependent packages is significantly negatively associated with the number of downstream projects, but the relationship with the number of authors is nonlinear. Our findings can help further open the 'black box' of deep learning SCs and provide insights for their healthy and sustainable development.",deep learning | open source | software evolution | software structure | software supply chain,1,86-98,Conference Proceeding,Conference Paper,4.0,"Tan, Xin;Gao, Kai;Zhou, Minghui;Zhang, Li",57196275141;57560696300;13305920400;55774691700,"Key Lab of High Confidence Software Technologies, Ministry of Education;Peking University;Beihang University",China;China;China,"deep learning becomes the driving force behind many contemporary technologies and has been successfully applied in many fields. through software dependencies, a multi-layer supply chain (sc) with a deep learning framework as the core and substantial down-stream projects as the periphery has gradually formed and is constantly developing. however, basic knowledge about the structure and characteristics of the sc is lacking, which hinders effective support for its sustainable development. previous studies on software sc usually focus on the packages in different registries without paying attention to the scs derived from a single project. we present an empirical study on two deep learning scs: tensorflow and pytorch scs. by constructing and analyzing their scs, we aim to understand their structure, application domains, and evolutionary factors. we find that both scs exhibit a short and sparse hierarchy structure. overall, the relative growth of new projects increases month by month. projects have a tendency to attract downstream projects shortly after the release of their packages, later the growth becomes faster and tends to stabilize. we propose three criteria to identify vulnerabilities and identify 51 types of packages and 26 types of projects involved in the two scs. a comparison reveals their similarities and differences, e.g., tensorflow sc provides a wealth of packages in experiment result analysis, while pytorch sc contains more specific framework packages. by fitting the gam model, we find that the number of dependent packages is significantly negatively associated with the number of downstream projects, but the relationship with the number of authors is nonlinear. our findings can help further open the 'black box' of deep learning scs and provide insights for their healthy and sustainable development.",an exploratory study of deep learning supply chain
82,2-s2.0-85133521889,10.1145/3510003.3510228,GraphFuzz: Library API Fuzzing with Lifetime-aware Dataflow Graphs,Green H.,Proceedings - International Conference on Software Engineering,2022-01-01,"We present the design and implementation of GraphFuzz, a new structure-, coverage- and object lifetime-aware fuzzer capable of automatically testing low-level Library APIs. Unlike other fuzzers, GraphFuzz models sequences of executed functions as a dataflow graph, thus enabling it to perform graph-based mutations both at the data and at the execution trace level. GraphFuzz comes with an automated specification generator to minimize the developer integration effort. We use GraphFuzz to analyze Skia-the rigorously tested Google Chrome graphics library-and benchmark GraphFuzz-generated fuzzing harnesses against hand-optimized, painstakingly written libFuzzer harnesses. We find that GraphFuzz generates test cases that achieve 2-3x more code coverage on average with minimal development effort, and also uncovered previous unknown defects in the process. We demonstrate GraphFuzz's applicability on low-level APIs by analyzing four additional open-source libraries and finding dozens of previously unknown defects. All security relevant findings have already been reported and fixed by the developers. Last, we open-source GraphFuzz under a permissive license and provide code to reproduce all results in this paper.",fuzzing | graph | security | structure aware,0,1070-1081,Conference Proceeding,Conference Paper,2.0,"Green, Harrison;Avgerinos, Thanassis",57783148700;35182448000,ForAllSecure,United States,"we present the design and implementation of graphfuzz, a new structure-, coverage- and object lifetime-aware fuzzer capable of automatically testing low-level library apis. unlike other fuzzers, graphfuzz models sequences of executed functions as a dataflow graph, thus enabling it to perform graph-based mutations both at the data and at the execution trace level. graphfuzz comes with an automated specification generator to minimize the developer integration effort. we use graphfuzz to analyze skia-the rigorously tested google chrome graphics library-and benchmark graphfuzz-generated fuzzing harnesses against hand-optimized, painstakingly written libfuzzer harnesses. we find that graphfuzz generates test cases that achieve 2-3x more code coverage on average with minimal development effort, and also uncovered previous unknown defects in the process. we demonstrate graphfuzz's applicability on low-level apis by analyzing four additional open-source libraries and finding dozens of previously unknown defects. all security relevant findings have already been reported and fixed by the developers. last, we open-source graphfuzz under a permissive license and provide code to reproduce all results in this paper.",graphfuzz: library api fuzzing with lifetime-aware dataflow graphs
85,2-s2.0-85133268007,10.1109/ICST53961.2022.00036,FAUSTA: Scaling Dynamic Analysis with Traffic Generation at WhatsApp,Mao K.,"Proceedings - 2022 IEEE 15th International Conference on Software Testing, Verification and Validation, ICST 2022",2022-01-01,"We introduce Fausta, an algorithmic traffic gener-ation platform that enables analysis and testing at scale. Fausta has been deployed at Meta to analyze and test the WhatsApp plat-form infrastructure since September 2020, enabling WhatsApp developers to deploy reliable code changes to a code base of millions of lines of code, supporting over 2 billion users who rely on WhatsApp for their daily communications. Fausta covers expected and unexpected program behaviors in a privacy-safe controlled environment to support multiple use cases such as reliability testing, privacy analysis and performance regression detection. It currently supports three different algorithmic input generation strategies, each of which construct realistic backend server traffic that closely simulates production data, without replaying any real user data. Fausta has been deployed and closely integrated into the WhatsApp continuous integration process, catching bugs in development before they hit production. We report on the development and deployment of Fausta's reliability use case between September 2020 and August 2021. During this period it has found 1,876 unique reliability issues, with a fix rate of 74%, indicating a high degree of true positive fault revelation. We also report on the distribution of fault types revealed by Fausta, and the correlation between coverage and faults found. Overall, we do find evidence that higher coverage is correlated with fault revelation.",continuous integration | dynamic analysis | software reliability | software testing,0,267-278,Conference Proceeding,Conference Paper,8.0,"Mao, Ke;Kapus, Timotej;Petrou, Lambros;Hajdu, Akos;Marescotti, Matteo;Loscher, Andreas;Harman, Mark;Distefano, Dino",57188561866;57200513935;57777635500;56529231500;57015126900;56046191400;7006379048;14033968400,Meta,United States,"we introduce fausta, an algorithmic traffic gener-ation platform that enables analysis and testing at scale. fausta has been deployed at meta to analyze and test the whatsapp plat-form infrastructure since september 2020, enabling whatsapp developers to deploy reliable code changes to a code base of millions of lines of code, supporting over 2 billion users who rely on whatsapp for their daily communications. fausta covers expected and unexpected program behaviors in a privacy-safe controlled environment to support multiple use cases such as reliability testing, privacy analysis and performance regression detection. it currently supports three different algorithmic input generation strategies, each of which construct realistic backend server traffic that closely simulates production data, without replaying any real user data. fausta has been deployed and closely integrated into the whatsapp continuous integration process, catching bugs in development before they hit production. we report on the development and deployment of fausta's reliability use case between september 2020 and august 2021. during this period it has found 1,876 unique reliability issues, with a fix rate of 74%, indicating a high degree of true positive fault revelation. we also report on the distribution of fault types revealed by fausta, and the correlation between coverage and faults found. overall, we do find evidence that higher coverage is correlated with fault revelation.",fausta: scaling dynamic analysis with traffic generation at whatsapp
86,2-s2.0-85133190800,10.1145/3524610.3527889,CSRS: Code Search with Relevance Matching and Semantic Matching,Cheng Y.,IEEE International Conference on Program Comprehension,2022-01-01,"Developers often search and reuse existing code snippets in the process of software development. Code search aims to retrieve relevant code snippets from a codebase according to natural language queries entered by the developer. Up to now, researchers have already proposed information retrieval (IR) based methods and deep learning (DL) based methods. The IR-based methods focus on keyword matching, that is to rank codes by relevance between queries and code snippets, while DL-based methods focus on capturing the semantic correlations. However, the existing methods do not consider capturing two matching signals simultaneously. There-fore, in this paper, we propose CSRS, a code search model with relevance matching and semantic matching. CSRS comprises (1) an embedding module containing convolution kernels of different sizes which can extract n-gram embeddings of queries and codes, (2) a relevance matching module that measures lexical matching signals, and (3) a co-attention based semantic matching module to capture the semantic correlation. We train and evaluate CSRS on a dataset with 18.22M and 10k code snippets. The experimental results demonstrate that CSRS achieves an MRR of 0.614, which out-performs two state-of-the-art models DeepCS and CARLCS-CNN by 33.77% and 18.53% respectively. In addition, we also conducted several experiments to prove the effectiveness of each component of CSRS.",attention mechanism | code search | relevance matching | semantic matching,0,533-542,Conference Proceeding,Conference Paper,2.0,"Cheng, Yi;Kuang, Li",57555818300;36519008400,Central South University,China,"developers often search and reuse existing code snippets in the process of software development. code search aims to retrieve relevant code snippets from a codebase according to natural language queries entered by the developer. up to now, researchers have already proposed information retrieval (ir) based methods and deep learning (dl) based methods. the ir-based methods focus on keyword matching, that is to rank codes by relevance between queries and code snippets, while dl-based methods focus on capturing the semantic correlations. however, the existing methods do not consider capturing two matching signals simultaneously. there-fore, in this paper, we propose csrs, a code search model with relevance matching and semantic matching. csrs comprises (1) an embedding module containing convolution kernels of different sizes which can extract n-gram embeddings of queries and codes, (2) a relevance matching module that measures lexical matching signals, and (3) a co-attention based semantic matching module to capture the semantic correlation. we train and evaluate csrs on a dataset with 18.22m and 10k code snippets. the experimental results demonstrate that csrs achieves an mrr of 0.614, which out-performs two state-of-the-art models deepcs and carlcs-cnn by 33.77% and 18.53% respectively. in addition, we also conducted several experiments to prove the effectiveness of each component of csrs.",csrs: code search with relevance matching and semantic matching
88,2-s2.0-85132828703,10.1109/ICSE-SEIP55303.2022.9794115,'Project smells' - Experiences in Analysing the Software Quality of ML Projects with mllint,Van Oort B.,Proceedings - International Conference on Software Engineering,2022-01-01,"Machine Learning (ML) projects incur novel challenges in their development and productionisation over traditional software applications, though established principles and best practices in ensuring the project's software quality still apply. While using static analysis to catch code smells has been shown to improve software quality attributes, it is only a small piece of the software quality puzzle, especially in the case of ML projects given their additional challenges and lower degree of Software Engineering (SE) experience in the data scientists that develop them. We introduce the novel concept of project smells which consider deficits in project management as a more holistic perspective on software quality in ML projects. An open-source static analysis tool mllint was also implemented to help detect and mitigate these. Our research evaluates this novel concept of project smells in the industrial context of ING, a global bank and large software- and data-intensive organisation. We also investigate the perceived importance of these project smells for proof-of-concept versus production-ready ML projects, as well as the perceived obstructions and benefits to using static analysis tools such as mllint. Our findings indicate a need for context-aware static analysis tools, that fit the needs of the project at its current stage of development, while requiring minimal configuration effort from the user.",code smells | context-aware | dependency management | machine learning | mllint | project smells | Python | software quality | static analysis,0,211-220,Conference Proceeding,Conference Paper,4.0,"Van Oort, Bart;Cruz, Luís;Loni, Babak;Van Deursen, Arie",57222476173;57143791700;27467517900;7003969355,"ING Group, Netherlands;Delft University of Technology",Netherlands;Netherlands,"machine learning (ml) projects incur novel challenges in their development and productionisation over traditional software applications, though established principles and best practices in ensuring the project's software quality still apply. while using static analysis to catch code smells has been shown to improve software quality attributes, it is only a small piece of the software quality puzzle, especially in the case of ml projects given their additional challenges and lower degree of software engineering (se) experience in the data scientists that develop them. we introduce the novel concept of project smells which consider deficits in project management as a more holistic perspective on software quality in ml projects. an open-source static analysis tool mllint was also implemented to help detect and mitigate these. our research evaluates this novel concept of project smells in the industrial context of ing, a global bank and large software- and data-intensive organisation. we also investigate the perceived importance of these project smells for proof-of-concept versus production-ready ml projects, as well as the perceived obstructions and benefits to using static analysis tools such as mllint. our findings indicate a need for context-aware static analysis tools, that fit the needs of the project at its current stage of development, while requiring minimal configuration effort from the user.",'project smells' - experiences in analysing the software quality of ml projects with mllint
90,2-s2.0-85132415375,10.1109/HPCC-DSS-SmartCity-DependSys53884.2021.00279,RoboMaze: Swarm Robotics and Coordinated Navigation in Smart City,Song J.,"2021 IEEE 23rd International Conference on High Performance Computing and Communications, 7th International Conference on Data Science and Systems, 19th International Conference on Smart City and 7th International Conference on Dependability in Sensor, Cloud and Big Data Systems and Applications, HPCC-DSS-SmartCity-DependSys 2021",2022-01-01,"Swarm robotics and coordinated navigation have many important applications in smart cities. For example, on the street, autonomous cars may coordinate with each other to optimize the routes and city traffic; in a building, multiple robots may allow the coordinated search of trapped people in the building after a fire or natural hazard. It is important to study how to design and optimize the coordinated search strategy in those complicated smart city environments. This paper introduces RoboMaze, a simulator for swarm robotics and coordinated navigation study, where the robots may communicate with each other and optimize their paths with the goal of completing the search in a minimum amount of time. RoboMaze has been implemented and demonstrated in multiple software and hardware platforms. It not only greatly facilitates the development and test of new algorithms, but also serves as a wonderful education and outreach tool for smart city awareness.",coordinated navigation | smart city | swarm robotics,0,1881-1885,Conference Proceeding,Conference Paper,3.0,"Song, John;Song, Austin;Zhang, Fumin",57753961900;57754629300;55495259900,School of Electrical and Computer Engineering;Johns Creek High School,United States;United States,"swarm robotics and coordinated navigation have many important applications in smart cities. for example, on the street, autonomous cars may coordinate with each other to optimize the routes and city traffic; in a building, multiple robots may allow the coordinated search of trapped people in the building after a fire or natural hazard. it is important to study how to design and optimize the coordinated search strategy in those complicated smart city environments. this paper introduces robomaze, a simulator for swarm robotics and coordinated navigation study, where the robots may communicate with each other and optimize their paths with the goal of completing the search in a minimum amount of time. robomaze has been implemented and demonstrated in multiple software and hardware platforms. it not only greatly facilitates the development and test of new algorithms, but also serves as a wonderful education and outreach tool for smart city awareness.",robomaze: swarm robotics and coordinated navigation in smart city
92,2-s2.0-85131327116,10.1007/978-3-031-07475-2_17,A Method for Ontology-Driven Minimum Viable Platform Development,Derave T.,Lecture Notes in Business Information Processing,2022-01-01,"In this paper a method is proposed for agile digital platform prototype development based on organization-specific ontologies. The resulting prototypes act as minimum viable product of the digital platform that is described by the ontologies. Our method combines the strengths of agile practices, to speed up the development process in a user-oriented manner, with the strengths of ontology-driven development, improving the software structure, single terminology, and communication between stakeholders. The method is demonstrated for the development of the android application ‘SafaRide’, a digital marketplace for safari ride sharing.",Digital marketplace | Digital platform | DPO | MVP | Ontology-driven software development | OntoUML | UFO,0,253-266,Book Series,Book Chapter,4.0,"Derave, Thomas;Prince Sales, Tiago;Gailly, Frederik;Poels, Geert",57213189126;57205212495;13606823500;6602187929,Universiteit Gent;Free University of Bozen-Bolzano,Belgium;Italy,"in this paper a method is proposed for agile digital platform prototype development based on organization-specific ontologies. the resulting prototypes act as minimum viable product of the digital platform that is described by the ontologies. our method combines the strengths of agile practices, to speed up the development process in a user-oriented manner, with the strengths of ontology-driven development, improving the software structure, single terminology, and communication between stakeholders. the method is demonstrated for the development of the android application ‘safaride’, a digital marketplace for safari ride sharing.",a method for ontology-driven minimum viable platform development
93,2-s2.0-85131231142,10.31661/jbpe.v0i0.2104-1323,Carbulin: A Comprehensive Mobile Application for Advanced Carbohydrate Counting and Diet-and Insulin-Regimen Planning for Type 1 Diabetic Patients,Abdollahzadeh S.M.,Journal of Biomedical Physics and Engineering,2022-01-01,"Nowadays, the introduction of the so-called ‘diabetes technology’, either hardware/de-vice or software, to different aspects of day-to-day living in patients with diabetes aims to improve blood glucose control and various lifestyle features. The coordination of vast context of diabetes education/training, particularly in the area of medical nutrition therapy, is considered as a great concern. On the other hand, Iranian food culture con-sists of a set of traditional dietary patterns and food consumption habit. The study was aimed to develop “the Comprehensive Mobile Application of Advanced Carbohydrate Counting and Diet-and Insulin-Regimen Planning” to help type 1 diabetic patients, improving their health status. The programming language of Kotlin, JavaScript, Node JS, and HTML5 was used for the mobile app development. The app was developed with the following abilities: 1) educating users on different aspects of disease control including, updated general treatment guidelines on physical activity, medical nutrition and insulin therapy, stress management, and the patient’s specific goals and dietary needs, 2) performing advanced carbohydrate counting using both picture-represented and kitchen-scale of carbohydrate foods as well as traditional Iranian foods, 3) recommending the patient’s specific insulin dose, either short-or rapid-acting, based on the carbohydrate content of the selected meal or the selected amount of Iranian foods, 4) recommending the personalized insulin dose needed for decreasing the high blood glucose levels, and 5) performing 3 and 4 simultaneously. Developing Carbulin was an effort to increase type 1 diabetes self-management using the traditional Iranian dietary pattern and menu.",Carbohydrates | Diabetes Mellitus | Insulin | Mobile Applications,0,319-324,Journal,Note,5.0,"Abdollahzadeh, Seyedeh Maryam;Ghanaat-Pishe, Meysam;Shams, Mesbah;Moravej, Hossein;Mazloomi, Seyed Mohammad",56641469500;57725345200;55253905900;55534601900;36141326800,Nutrition Research Center (SUMS);Neonatal Research Center (SUMS);Shiraz University of Medical Sciences,Iran;Iran;Iran,"nowadays, the introduction of the so-called ‘diabetes technology’, either hardware/de-vice or software, to different aspects of day-to-day living in patients with diabetes aims to improve blood glucose control and various lifestyle features. the coordination of vast context of diabetes education/training, particularly in the area of medical nutrition therapy, is considered as a great concern. on the other hand, iranian food culture con-sists of a set of traditional dietary patterns and food consumption habit. the study was aimed to develop “the comprehensive mobile application of advanced carbohydrate counting and diet-and insulin-regimen planning” to help type 1 diabetic patients, improving their health status. the programming language of kotlin, javascript, node js, and html5 was used for the mobile app development. the app was developed with the following abilities: 1) educating users on different aspects of disease control including, updated general treatment guidelines on physical activity, medical nutrition and insulin therapy, stress management, and the patient’s specific goals and dietary needs, 2) performing advanced carbohydrate counting using both picture-represented and kitchen-scale of carbohydrate foods as well as traditional iranian foods, 3) recommending the patient’s specific insulin dose, either short-or rapid-acting, based on the carbohydrate content of the selected meal or the selected amount of iranian foods, 4) recommending the personalized insulin dose needed for decreasing the high blood glucose levels, and 5) performing 3 and 4 simultaneously. developing carbulin was an effort to increase type 1 diabetes self-management using the traditional iranian dietary pattern and menu.",carbulin: a comprehensive mobile application for advanced carbohydrate counting and diet-and insulin-regimen planning for type 1 diabetic patients
94,2-s2.0-85130864881,10.32744/pse.2022.2.39,Development of the prototype of digital cross-platform for interaction and management of the innovation and educational process of the university of naukograd,Sergeevna C.M.,Perspektivy Nauki i Obrazovania,2022-01-01,"Introduction. At present the problem of identifying new ways of developing universities located in science cities (Russia) and urban subjects with a high concentration of scientific and technical potential (England, USA, Germany, etc.) is actualized in the context of the dynamic development of digital technologies. The functions of digital platforms for the effective functioning and management of the innovation system of the university of the science city have been identified: joint research, the creation of a scientific team, the exchange of ideas and research results, interaction with the professional community and the business community. The purpose of the study is to develop a prototype of a digital cross-platform in the information and educational space to solve the problem of effective interaction and management of the innovation and educational process of the University of Science City with the Research Institute of the Russian Academy of Sciences and the business community. Materials and methods. When analyzing the digital cross-platform, system analysis was used, which made it possible to create a basis for describing the digital cross-platform model, identifying its structure, the relationship between the elements of the system and relations with the external (in relation to the system) environment. To develop a digital cross-platform model, the method of process modeling based on CASE-technology was used, in particular, the methodology of functional modeling and graphical notation intended for formalization and description of processes. The scripting programming language PHP is used as the basis for the development of the prototype. For the visual design of the network service, the HTML markup language and cascading style sheets CSS, JavaScript are used. Results. The article presents a prototype model of a digital cross-platform that allows interaction and management of the innovation and educational process of the University of science City with the Research Institute of the Russian Academy of Sciences and the business community. The structure is substantiated, the functions are revealed, the channels of interaction are considered. As a result of the research, a prototype of a digital cross-platform for interaction and management of the innovation and educational process of the University of Science City was developed. Discussion and Conclusion. It was revealed that the implementation of the software prototype of the digital cross-platform of the network interaction of the University of Naukograd with the Research Institute of the Russian Academy of Sciences and the business community will expand the possibilities of cooperation between universities and enterprises to obtain new breakthrough technologies and innovative products in the process of joint research activities. The presented software prototype, with some modification, can be used for other subject areas of the digital economy, involving the dynamic formation of network structures of interaction between business partners.",breakthrough technologies | Digital cross-platform | networking | science city,0,657-669,Journal,Article,3.0,"Sergeevna, Chvanova Marina;Kiseleva, Irina A.;Skvortsov, Alexander A.",57192591458;57204944761;57442196700,Tambov State University;Moscow Aviation Institute (National Research University),Russian Federation;Russian Federation,"introduction. at present the problem of identifying new ways of developing universities located in science cities (russia) and urban subjects with a high concentration of scientific and technical potential (england, usa, germany, etc.) is actualized in the context of the dynamic development of digital technologies. the functions of digital platforms for the effective functioning and management of the innovation system of the university of the science city have been identified: joint research, the creation of a scientific team, the exchange of ideas and research results, interaction with the professional community and the business community. the purpose of the study is to develop a prototype of a digital cross-platform in the information and educational space to solve the problem of effective interaction and management of the innovation and educational process of the university of science city with the research institute of the russian academy of sciences and the business community. materials and methods. when analyzing the digital cross-platform, system analysis was used, which made it possible to create a basis for describing the digital cross-platform model, identifying its structure, the relationship between the elements of the system and relations with the external (in relation to the system) environment. to develop a digital cross-platform model, the method of process modeling based on case-technology was used, in particular, the methodology of functional modeling and graphical notation intended for formalization and description of processes. the scripting programming language php is used as the basis for the development of the prototype. for the visual design of the network service, the html markup language and cascading style sheets css, javascript are used. results. the article presents a prototype model of a digital cross-platform that allows interaction and management of the innovation and educational process of the university of science city with the research institute of the russian academy of sciences and the business community. the structure is substantiated, the functions are revealed, the channels of interaction are considered. as a result of the research, a prototype of a digital cross-platform for interaction and management of the innovation and educational process of the university of science city was developed. discussion and conclusion. it was revealed that the implementation of the software prototype of the digital cross-platform of the network interaction of the university of naukograd with the research institute of the russian academy of sciences and the business community will expand the possibilities of cooperation between universities and enterprises to obtain new breakthrough technologies and innovative products in the process of joint research activities. the presented software prototype, with some modification, can be used for other subject areas of the digital economy, involving the dynamic formation of network structures of interaction between business partners.",development of the prototype of digital cross-platform for interaction and management of the innovation and educational process of the university of naukograd
95,2-s2.0-85130596793,10.1109/TCSET55632.2022.9767034,Combined method of prioritization and automation of software regression testing,Zhyhulin D.,"Proceedings - 16th International Conference on Advanced Trends in Radioelectronics, Telecommunications and Computer Engineering, TCSET 2022",2022-01-01,"This paper describes the proposed method for conducting regression testing of a demo project. The method demonstrates an effective approach to solving regression testing problems by combining change-based prioritization and automating test scripts in whole or in part. The proposed work uses modern automated testing utilities: Selenium WebDriver, Puppeteer and Playwright using the JavaScript programming language. Using automated testing utilities can significantly speed up the time of regression testing. Research methods are based on the development of scripts for the main functionality and end-to-end scripts of the demo project. A comparative analysis of the speed of the automated testing utilities has also been carried out.",automated testing | change-based | JavaScript | Playwright | prioritization | Puppeteer | Regression testing | Selenium WebDriver,0,751-755,Conference Proceeding,Conference Paper,3.0,"Zhyhulin, Dmitry;Kasian, Kostiantyn;Kasian, Mykola",57218100921;57190428151;57553820300,Zaporizhzhia Polytechnic National University,Ukraine,"this paper describes the proposed method for conducting regression testing of a demo project. the method demonstrates an effective approach to solving regression testing problems by combining change-based prioritization and automating test scripts in whole or in part. the proposed work uses modern automated testing utilities: selenium webdriver, puppeteer and playwright using the javascript programming language. using automated testing utilities can significantly speed up the time of regression testing. research methods are based on the development of scripts for the main functionality and end-to-end scripts of the demo project. a comparative analysis of the speed of the automated testing utilities has also been carried out.",combined method of prioritization and automation of software regression testing
98,2-s2.0-85130203790,10.1109/DASA54658.2022.9764982,Comprehensive Survey of different Machine Learning Algorithms used for Software Defect Prediction,Sharadhi A.K.,"2022 International Conference on Decision Aid Sciences and Applications, DASA 2022",2022-01-01,"The software development life cycle is a long and complicated process. It consists of analysis, design, development, testing and deployment. Defect prediction is the technique of creating models that detect defective systems such as units or classes in the early stages of the process. The major goal of Software Defect Prediction is to detect defects prone in the program and thereby reduce the effort, time and cost involved to the minimum. This paper gives a comprehensive review of all the techniques to approach defect prediction. The PROMISE repository which is a public software defect prediction dataset which is owned by the National Aeronautics and Space Administration (NASA) is used. More than 30 research papers in the domain of software defect prediction were analysed and reviewed. In each paper surveyed, the processes involved in Software Defect prediction were captured. About 30 papers with different Machine Learning Algorithms were identified and entered into the table. The results were tabulated into columns like Dataset Used, Supervised Learning Algorithm, Un-supervised Learning Algorithm and Computational Intelligence. The bar graphs were generated to determine the most used Supervised Learning Algorithm, Unsupervised Learning Algorithm and Dataset used for Software Defect Prediction among all the 40 papers surveyed thoroughly.",Computational Intelligence | Machine Learning | Software Defect Prediction | Supervised Learning | Unsupervised Learning,1,425-430,Conference Proceeding,Conference Paper,6.0,"Sharadhi, A. K.;Gururaj, Vybhavi;Umadi, Keerti R.;Kumar, Mushkan;Shankar, Sahana P.;Varadam, Deepak",57695181900;57694206400;57694940800;57221009355;57216108507;57477185500,M. S. Ramaiah University of Applied Sciences,India,"the software development life cycle is a long and complicated process. it consists of analysis, design, development, testing and deployment. defect prediction is the technique of creating models that detect defective systems such as units or classes in the early stages of the process. the major goal of software defect prediction is to detect defects prone in the program and thereby reduce the effort, time and cost involved to the minimum. this paper gives a comprehensive review of all the techniques to approach defect prediction. the promise repository which is a public software defect prediction dataset which is owned by the national aeronautics and space administration (nasa) is used. more than 30 research papers in the domain of software defect prediction were analysed and reviewed. in each paper surveyed, the processes involved in software defect prediction were captured. about 30 papers with different machine learning algorithms were identified and entered into the table. the results were tabulated into columns like dataset used, supervised learning algorithm, un-supervised learning algorithm and computational intelligence. the bar graphs were generated to determine the most used supervised learning algorithm, unsupervised learning algorithm and dataset used for software defect prediction among all the 40 papers surveyed thoroughly.",comprehensive survey of different machine learning algorithms used for software defect prediction
101,2-s2.0-85129206403,10.30686/1609-9192-2022-1S-127-133,Geoinformation monitoring for solving environmental problems of mining territories of the Middle Ural,Kornilkov S.V.,Gornaya Promyshlennost,2022-01-01,"Geographic information monitoring is shown as the leading method of process control in old industrial territories. The main stages of geoinformation monitoring are outlined. The role of geographic information systems in the study of pollution components, systematization and accumulation of spatially distributed data, analysis and development of predictive solutions is considered. The solution of the problem of the conceptual organization of the geoinformation system of mining territories has been substantiated. The structure of software products and geographic information systems selection criteria are considered. The QGIS software product was chosen as the desktop geographic information systems. The functionality of JavaScript-libraries Leaflet and Highcharts, the possibility of their use as a web-based geographic information systems are described. The structure of the base layers of the geographic information systems, created for the organization of geoinformation monitoring of the old industrial territory of the Levikhinsky mine, is described. An algorithm for organizing spatially distributed data of the monitoring object, a fundamental algorithm for data processing are proposed. Considerable attention is paid to the typification and subsequent differentiation of the types of initial information, the storage of geographic information systems data in exchange formats. The author's algorithm of interaction between desktop and web-based geographic information systems is described. The provisions and technical solutions set out in the article allow using geographic information systems for operational monitoring, forecasting and comprehensive assessment, and management decisions.",Environmental monitoring | Geographic Information Systems | Geoinformatics | Geoinformation monitoring | GIS | Highcharts | Leaflet | Levikha copper mine | QGIS,0,127-133,Journal,Article,4.0,"Kornilkov, S. V.;Rybnikova, L. S.;Rybnikov, P. A.;Smirnov, A. Yu",6505453643;6507117014;55382631600;57225138397,"Ural Branch, Russian Academy of Sciences;Ural State Mining University",Russian Federation;Russian Federation,"geographic information monitoring is shown as the leading method of process control in old industrial territories. the main stages of geoinformation monitoring are outlined. the role of geographic information systems in the study of pollution components, systematization and accumulation of spatially distributed data, analysis and development of predictive solutions is considered. the solution of the problem of the conceptual organization of the geoinformation system of mining territories has been substantiated. the structure of software products and geographic information systems selection criteria are considered. the qgis software product was chosen as the desktop geographic information systems. the functionality of javascript-libraries leaflet and highcharts, the possibility of their use as a web-based geographic information systems are described. the structure of the base layers of the geographic information systems, created for the organization of geoinformation monitoring of the old industrial territory of the levikhinsky mine, is described. an algorithm for organizing spatially distributed data of the monitoring object, a fundamental algorithm for data processing are proposed. considerable attention is paid to the typification and subsequent differentiation of the types of initial information, the storage of geographic information systems data in exchange formats. the author's algorithm of interaction between desktop and web-based geographic information systems is described. the provisions and technical solutions set out in the article allow using geographic information systems for operational monitoring, forecasting and comprehensive assessment, and management decisions.",geoinformation monitoring for solving environmental problems of mining territories of the middle ural
102,2-s2.0-85129173802,10.1007/978-3-030-90708-2_9,"Malware Attacks: Dimensions, Impact, and Defenses",Kumar A.,EAI/Springer Innovations in Communication and Computing,2022-01-01,"Malware is a top threat to the current digital world. It will be more devastating in coming years due to the expansion of information technology in various fields of life, engagement of different type of users, and increased technical sophistication in malware. The changing motivations, multi-resource investment in malware development and Return on Investment (RoI) are the main reasons for the exponential growth in malware. Businesses and users are losing millions of dollars due to various malware attacks. Although there are different Anti-malware solutions and other security software, malware attacks are successful due to inherent limitations of these security products and common security vulnerabilities such as“zero-day”, “buffer-overflow”, etc. This book chapter provides a detailed study about malware, its propagation and attack mechanisms and discusses various anti-malware techniques (machine learning, bio-inspired algorithms etc.). It also presents possible research directions for developing tools and techniques for better protection against malware.",Adware | apkc opcode | Bio-inspired malware detection | Bot | Botnet | Byte-n-gram | Cyber security | Dynamic analysis | Information security | Machine learning based detection | Malware | Malware detection | Nature-inspired detection | Opcode-n-gram | Portable executable | Ransomware | Signature | Signature-based detection | Spyware | Static analysis | Trojan | Virus | Worm,0,157-179,Book Series,Book Chapter,4.0,"Kumar, Ajit;Choi, Bong Jun;Kuppusamy, K. S.;Aghila, G.",55619311846;35955497300;57210787373;15750049200,National Institute of Technology Puducherry;Soongsil University;Pondicherry University,India;South Korea;India,"malware is a top threat to the current digital world. it will be more devastating in coming years due to the expansion of information technology in various fields of life, engagement of different type of users, and increased technical sophistication in malware. the changing motivations, multi-resource investment in malware development and return on investment (roi) are the main reasons for the exponential growth in malware. businesses and users are losing millions of dollars due to various malware attacks. although there are different anti-malware solutions and other security software, malware attacks are successful due to inherent limitations of these security products and common security vulnerabilities such as“zero-day”, “buffer-overflow”, etc. this book chapter provides a detailed study about malware, its propagation and attack mechanisms and discusses various anti-malware techniques (machine learning, bio-inspired algorithms etc.). it also presents possible research directions for developing tools and techniques for better protection against malware.","malware attacks: dimensions, impact, and defenses"
105,2-s2.0-85128682374,10.32604/cmc.2022.028326,Handling Big Data in Relational Database Management Systems,ElDahshan K.,"Computers, Materials and Continua",2022-01-01,"Currently, relational database management systems (RDBMSs) face different challenges in application development due to themassive growth of unstructured and semi-structured data. This introduced new DBMS categories, known as not only structured query language (NoSQL) DBMSs, which do not adhere to the relationalmodel. Themigration from relational databases to NoSQL databases is challenging due to the data complexity. This study aims to enhance the storage performance of RDBMSs in handling a variety of data. The paper presents two approaches. The first approach proposes a convenient representation of unstructured data storage. Several extensive experiments were implemented to assess the efficiency of this approach that could result in substantial improvements in the RDBMSs storage. The second approach proposes using the JavaScript Object Notation (JSON) format to represent multivalued attributes and many to many (M:N) relationships in relational databases to create a flexible schema and store semi-structured data. The results indicate that the proposed approaches outperform similar approaches and improve data storage performance, which helps preserve software stability in huge organizations by improving existing software packages whose replacement may be highly costly.",Big data | MongoDB | MySQL | NoSQL DBMSs | RDBMS | semi-structured data | unstructured data,0,5149-5164,Journal,Article,6.0,"ElDahshan, Kamal;Selim, Eman;Ebada, Ahmed Ismail;Abouhawwash, Mohamed;Nam, Yunyoung;Behery, Gamal",36967841100;57609640600;57195680188;56565521700;8971732400;6504140509,Damietta University;Michigan State University;Soonchunhyang University;Mansoura University;Al-Azhar University,Egypt;United States;South Korea;Egypt;Egypt,"currently, relational database management systems (rdbmss) face different challenges in application development due to themassive growth of unstructured and semi-structured data. this introduced new dbms categories, known as not only structured query language (nosql) dbmss, which do not adhere to the relationalmodel. themigration from relational databases to nosql databases is challenging due to the data complexity. this study aims to enhance the storage performance of rdbmss in handling a variety of data. the paper presents two approaches. the first approach proposes a convenient representation of unstructured data storage. several extensive experiments were implemented to assess the efficiency of this approach that could result in substantial improvements in the rdbmss storage. the second approach proposes using the javascript object notation (json) format to represent multivalued attributes and many to many (m:n) relationships in relational databases to create a flexible schema and store semi-structured data. the results indicate that the proposed approaches outperform similar approaches and improve data storage performance, which helps preserve software stability in huge organizations by improving existing software packages whose replacement may be highly costly.",handling big data in relational database management systems
106,2-s2.0-85128183479,10.1109/ACCESS.2022.3162227,Solidity Code Generation From UML State Machines in Model-Driven Smart Contract Development,Jurgelaitis M.,IEEE Access,2022-01-01,"For the development of blockchain smart contracts, a structured approach based on the principles of the Model Driven Architecture can be beneficial and facilitate the implementation of smart contracts. This paper presents such an approach, which, in combination with Unified Modeling Language (UML) Class and State machine diagrams, allows the smart contract structure and behavior logic to be modeled in several abstraction layers. This paper delves into details on how the model-to-model transformations from the specified Blockchain Platform Independent Model (PIM) with specified state-like behavior can be used to produce a Solidity Platform Specific Model (PSM). Subsequently, we elaborate on how the Solidity PSM is used for Solidity smart contract code generation by employing model-to-text transformations. The paper also demonstrates the process of our proposed transformations and code generation using smart contract code examples from Solidity documentation. Based on the examples, a Blockchain PIM is specified and transformed to Solidity PSM, which is then used for Solidity smart contract code generation. The generated smart contract code is then compiled, deployed on the Ethereum blockchain JavaScript virtual machine, and compared to the original smart contract code in terms of Solidity code metrics, similarity scores, and execution costs. The evaluation results indicate that our approach could be successfully used to model and later generate smart contract code.",Blockchain | model driven architecture | model-driven development | smart contracts | solidity | state machine | unified modeling language,1,33465-33481,Journal,Article,3.0,"Jurgelaitis, Mantas;Ceponiene, Lina;Butkiene, Rita",57203224617;35095979100;55211321200,Kaunas University of Technology,Lithuania,"for the development of blockchain smart contracts, a structured approach based on the principles of the model driven architecture can be beneficial and facilitate the implementation of smart contracts. this paper presents such an approach, which, in combination with unified modeling language (uml) class and state machine diagrams, allows the smart contract structure and behavior logic to be modeled in several abstraction layers. this paper delves into details on how the model-to-model transformations from the specified blockchain platform independent model (pim) with specified state-like behavior can be used to produce a solidity platform specific model (psm). subsequently, we elaborate on how the solidity psm is used for solidity smart contract code generation by employing model-to-text transformations. the paper also demonstrates the process of our proposed transformations and code generation using smart contract code examples from solidity documentation. based on the examples, a blockchain pim is specified and transformed to solidity psm, which is then used for solidity smart contract code generation. the generated smart contract code is then compiled, deployed on the ethereum blockchain javascript virtual machine, and compared to the original smart contract code in terms of solidity code metrics, similarity scores, and execution costs. the evaluation results indicate that our approach could be successfully used to model and later generate smart contract code.",solidity code generation from uml state machines in model-driven smart contract development
108,2-s2.0-85127939915,10.31799/1684-8853-2022-1-30-43,Kex: A platform for analysis of JVM programs,Abdullin A.M.,Informatsionno-Upravliaiushchie Sistemy,2022-01-01,"Introduction: Over the last years program analysis methods were widely used for software quality assurance. Different types of program analysis require various levels of program representation, analysis methods, etc. Platforms that provide utilities to implement different types of analysis on their basis become very important because they allow one to simplify the process of development. Purpose: Development of a platform for analysis of JVM programs. Results: In this paper we present Kex, a platform for building program analysis tools for JVM bytecode. Kex provides three abstraction levels. First is Kfg, which is an SSA-based control flow graph representation for bytecode-level analysis and transformation. Second is a symbolic program representation called Predicate State, which consists of first order logic predicates that represent instructions of the original program, constraints, etc. The final level is SMT integration layer for constraint solving. It currently provides an interface for interacting with three SMT solvers. Practical relevance: We have evaluated our platform by considering two prototypes. First prototype is an automatic test generation tool that has participated in SBST 2021 tool competition. Second prototype is a tool for detection of automatic library integration errors. Both prototypes have proved that Kex can be used to implement competitive and powerful program analysis tools.",analysis platform | program analysis | symbolic execution | test generation,1,30-43,Journal,Article,2.0,"Abdullin, A. M.;Itsykson, V. M.",56174185100;36237396900,Peter the Great St. Petersburg Polytechnic University;JetBrains Research,Russian Federation;Russian Federation,"introduction: over the last years program analysis methods were widely used for software quality assurance. different types of program analysis require various levels of program representation, analysis methods, etc. platforms that provide utilities to implement different types of analysis on their basis become very important because they allow one to simplify the process of development. purpose: development of a platform for analysis of jvm programs. results: in this paper we present kex, a platform for building program analysis tools for jvm bytecode. kex provides three abstraction levels. first is kfg, which is an ssa-based control flow graph representation for bytecode-level analysis and transformation. second is a symbolic program representation called predicate state, which consists of first order logic predicates that represent instructions of the original program, constraints, etc. the final level is smt integration layer for constraint solving. it currently provides an interface for interacting with three smt solvers. practical relevance: we have evaluated our platform by considering two prototypes. first prototype is an automatic test generation tool that has participated in sbst 2021 tool competition. second prototype is a tool for detection of automatic library integration errors. both prototypes have proved that kex can be used to implement competitive and powerful program analysis tools.",kex: a platform for analysis of jvm programs
109,2-s2.0-85127845832,10.1109/ICSE-NIER55298.2022.9793510,MLSmellHound: A Context-Aware Code Analysis Tool,Kannan J.,Proceedings - International Conference on Software Engineering,2022-01-01,"Meeting the rise of industry demand to incorporate machine learning (ML) components into software systems requires interdisciplinary teams contributing to a shared code base. To maintain consistency, reduce defects and ensure maintainability, developers use code analysis tools to aid them in identifying defects and maintaining standards. With the inclusion of machine learning, tools must account for the cultural differences within the teams which manifests as multiple programming languages, and conflicting definitions and objectives. Existing tools fail to identify these cultural differences and are geared towards software engineering which reduces their adoption in ML projects. In our approach we attempt to resolve this problem by exploring the use of context which includes i) purpose of the source code, ii) technical domain, iii) problem domain, iv) team norms, v) operational environment, and vi) development lifecycle stage to provide contextualised error reporting for code analysis. To demonstrate our approach, we adapt Pylint as an example and apply a set of contextual transformations to the linting results based on the domain of individual project files under analysis. This allows for contextualised and meaningful error reporting for the end user.",code smells | context-aware | Machine learning,1,66-70,Conference Proceeding,Conference Paper,5.0,"Kannan, Jai;Barnett, Scott;Cruz, Luís;Simmons, Anj;Agarwal, Akash",57695252200;56890458900;57143791700;57155872400;57694767800,Deakin University;Delft University of Technology,Australia;Netherlands,"meeting the rise of industry demand to incorporate machine learning (ml) components into software systems requires interdisciplinary teams contributing to a shared code base. to maintain consistency, reduce defects and ensure maintainability, developers use code analysis tools to aid them in identifying defects and maintaining standards. with the inclusion of machine learning, tools must account for the cultural differences within the teams which manifests as multiple programming languages, and conflicting definitions and objectives. existing tools fail to identify these cultural differences and are geared towards software engineering which reduces their adoption in ml projects. in our approach we attempt to resolve this problem by exploring the use of context which includes i) purpose of the source code, ii) technical domain, iii) problem domain, iv) team norms, v) operational environment, and vi) development lifecycle stage to provide contextualised error reporting for code analysis. to demonstrate our approach, we adapt pylint as an example and apply a set of contextual transformations to the linting results based on the domain of individual project files under analysis. this allows for contextualised and meaningful error reporting for the end user.",mlsmellhound: a context-aware code analysis tool
110,2-s2.0-85127790091,10.3233/JNR-220002,Guidelines for collaborative development of sustainable data treatment software,Wuttke J.,Journal of Neutron Research,2022-01-01,"Software development for data reduction and analysis at large research facilities is increasingly professionalized, and internationally coordinated. To foster software quality and sustainability, and to facilitate collaboration, representatives from software groups of European neutron and muon facilities have agreed on a set of guidelines for development practices, infrastructure, and functional and non-functional product properties. These guidelines have been derived from actual practices in software projects from the EU funded consortium ‘Science and Innovation with Neutrons in Europe in 2020' (SINE2020), and have been enriched through extensive literature review. Besides guiding the work of the professional software engineers in our computing groups, we hope to influence scientists who are willing to contribute their own data treatment software to our community. Moreover, this work may also provide inspiration to scientific software development beyond the neutron and muon field.",data treatment | reproducible research | research software | scientific computing | scientific software | Software development | software engineering | sustainable software,0,33-72,Journal,Article,8.0,"Wuttke, Joachim;Cottrell, Stephen;Gonzalez, Miguel A.;Kaestner, Anders;Markvardsen, Anders;Rod, Thomas H.;Rozyczko, Piotr;Vardanyan, Gagik",6701739610;7005775696;57673133700;16021746200;6603069724;6603532911;6506234749;57565364100,European Spallation Source ERIC;Paul Scherrer Institut;Forschungszentrum Jülich (FZJ);Institut Laue-Langevin;ISIS Neutron and Muon Source,Sweden;Switzerland;Germany;France;United Kingdom,"software development for data reduction and analysis at large research facilities is increasingly professionalized, and internationally coordinated. to foster software quality and sustainability, and to facilitate collaboration, representatives from software groups of european neutron and muon facilities have agreed on a set of guidelines for development practices, infrastructure, and functional and non-functional product properties. these guidelines have been derived from actual practices in software projects from the eu funded consortium ‘science and innovation with neutrons in europe in 2020' (sine2020), and have been enriched through extensive literature review. besides guiding the work of the professional software engineers in our computing groups, we hope to influence scientists who are willing to contribute their own data treatment software to our community. moreover, this work may also provide inspiration to scientific software development beyond the neutron and muon field.",guidelines for collaborative development of sustainable data treatment software
111,2-s2.0-85127622277,10.1007/978-981-16-8987-1_38,Software Tool to Perform Metamorphic Testing on RESTful Web APIs,Manikantan V.,Lecture Notes in Networks and Systems,2022-01-01,"Most of the modern applications use Representational State Transfer (REST) as the standard for designing complex web services. The testing and validation in development phase can use debugging techniques to detect and resolve the errors. An obstacle to use conventional testing methodologies to check the consistency in production phase is that RESTful Application Programming Interfaces (APIs) do not hold any test oracle (test oracle problem). In order to mitigate this problem, metamorphic testing using appropriate metamorphic relations can be deployed in production phase. In the case of web service APIs, the response from an operation acts as the operands for the metamorphic test. The aim is to design and implement a software tool that can automate metamorphic testing of RESTful web APIs based on five major metamorphic relation output patterns (MROPs).",Metamorphic testing | Post Release testing | REST API | REST API testing tool | Web API testing,0,355-362,Book Series,Conference Paper,5.0,"Manikantan, Vishnu;Menon, Neeraj;Vishnupriyan, V. S.;John, Ansamma;Anantha Padmanabhan, N. K.",57563974000;57564485400;57564738100;55744633800;57200800982,TKM College of Engineering,India,"most of the modern applications use representational state transfer (rest) as the standard for designing complex web services. the testing and validation in development phase can use debugging techniques to detect and resolve the errors. an obstacle to use conventional testing methodologies to check the consistency in production phase is that restful application programming interfaces (apis) do not hold any test oracle (test oracle problem). in order to mitigate this problem, metamorphic testing using appropriate metamorphic relations can be deployed in production phase. in the case of web service apis, the response from an operation acts as the operands for the metamorphic test. the aim is to design and implement a software tool that can automate metamorphic testing of restful web apis based on five major metamorphic relation output patterns (mrops).",software tool to perform metamorphic testing on restful web apis
112,2-s2.0-85127498209,10.1109/ICSE-SEIP55303.2022.9794068,What are Weak Links in the npm Supply Chain?,Zahan N.,Proceedings - International Conference on Software Engineering,2022-01-01,"Modern software development frequently uses third-party packages, raising the concern of supply chain security attacks. Many attackers target popular package managers, like npm, and their users with supply chain attacks. In 2021 there was a 650% year-on-year growth in security attacks by exploiting Open Source Software's supply chain. Proactive approaches are needed to predict package vulnerability to high-risk supply chain attacks. The goal of this work is to help software developers and security specialists in measuring npm supply chain weak link signals to prevent future supply chain attacks by empirically studying npm package metadata. In this paper, we analyzed the metadata of 1.63 million JavaScript npm packages. We propose six signals of security weaknesses in a software supply chain, such as the presence of install scripts, maintainer accounts associated with an expired email domain, and inactive packages with inactive maintainers. One of our case studies identified 11 malicious packages from the install scripts signal. We also found 2,818 maintainer email addresses associated with expired domains, allowing an attacker to hijack 8,494 packages by taking over the npm accounts. We obtained feedback on our weak link signals through a survey responded to by 470 npm package developers. The majority of the developers supported three out of our six proposed weak link signals. The developers also indicated that they would want to be notified about weak links signals before using third-party packages. Additionally, we discussed eight new signals suggested by package developers.",npm | Software Ecosystem | Supply Chain Security | Weak link Signal,1,331-340,Conference Proceeding,Conference Paper,6.0,"Zahan, Nusrat;Zimmermann, Thomas;Godefroid, Patrice;Murphy, Brendan;Maddila, Chandra;Williams, Laurie",57211010823;16308551800;7003921627;7402698081;57200337950;35565101900,Microsoft Research;NC State University,United States;United States,"modern software development frequently uses third-party packages, raising the concern of supply chain security attacks. many attackers target popular package managers, like npm, and their users with supply chain attacks. in 2021 there was a 650% year-on-year growth in security attacks by exploiting open source software's supply chain. proactive approaches are needed to predict package vulnerability to high-risk supply chain attacks. the goal of this work is to help software developers and security specialists in measuring npm supply chain weak link signals to prevent future supply chain attacks by empirically studying npm package metadata. in this paper, we analyzed the metadata of 1.63 million javascript npm packages. we propose six signals of security weaknesses in a software supply chain, such as the presence of install scripts, maintainer accounts associated with an expired email domain, and inactive packages with inactive maintainers. one of our case studies identified 11 malicious packages from the install scripts signal. we also found 2,818 maintainer email addresses associated with expired domains, allowing an attacker to hijack 8,494 packages by taking over the npm accounts. we obtained feedback on our weak link signals through a survey responded to by 470 npm package developers. the majority of the developers supported three out of our six proposed weak link signals. the developers also indicated that they would want to be notified about weak links signals before using third-party packages. additionally, we discussed eight new signals suggested by package developers.",what are weak links in the npm supply chain?
114,2-s2.0-85127080068,10.1007/978-3-030-96638-6_34,Web-Based Software Tool for Electrocardiogram Annotation,Stoyanov T.,Lecture Notes in Networks and Systems,2022-01-01,"The manual annotation of large multilead ECG databases is a challenge, especially in the context for providing meaningful visualization, easy tools for annotation and simultaneous access from multiple experts via extended Internet connectivity. The aim of this work is to present the development platform and capabilities of internet-based software tool for the purpose of user-friendly manual annotation and delineation of heartbeats in 12-lead ECG databases. The annotation software consists of: (i) server-based application, written in Python under DJango framework with SQLite database manager; and (ii) web-based front-end application, created in Node Package Manager environment under React JavaScript framework. The server-based part contains procedures for managing the ECG records (i.e. receiving and saving ECG signals), saving manually annotated data, and generation of average beats. The front-end application contains: (i) graphical user interface for visualization of 12-lead ECG signals and management of the user input/output commands; (ii) annotation module, which provides tools to mark and correct the positions and type of QRS complexes; (iii) average beat module, which provides an option to switch between leads, provides graphical markers for annotation of fiducial points and time-intervals in the averaged heartbeat waveform and sets the average beat type; and (iv) rhythm type module, which shows the rhythm type and provides a possibility to change it. The software is opened for further developments. The presented annotation tool could be potentially used for annotation of large ECG databases without limitations on the number of ECG leads and number of annotations per ECG recording. This is in line with the new trends for accumulation of large ECG databases from multiple sources, which are the thoughtful platform for development of machine learning and especially deep learning algorithms for ECG signal processing and arrhythmia classification.",Annotation software | Arrhythmia types | DJango framework | Electrocardiogram (ECG) | Heartbeat types | React JavaScript framework,0,322-331,Book Series,Conference Paper,1.0,"Stoyanov, Todor",55890371600,"Institute of Biophysics and Biomedical Engineering, Bulgarian Academy of Sciences",Bulgaria,"the manual annotation of large multilead ecg databases is a challenge, especially in the context for providing meaningful visualization, easy tools for annotation and simultaneous access from multiple experts via extended internet connectivity. the aim of this work is to present the development platform and capabilities of internet-based software tool for the purpose of user-friendly manual annotation and delineation of heartbeats in 12-lead ecg databases. the annotation software consists of: (i) server-based application, written in python under django framework with sqlite database manager; and (ii) web-based front-end application, created in node package manager environment under react javascript framework. the server-based part contains procedures for managing the ecg records (i.e. receiving and saving ecg signals), saving manually annotated data, and generation of average beats. the front-end application contains: (i) graphical user interface for visualization of 12-lead ecg signals and management of the user input/output commands; (ii) annotation module, which provides tools to mark and correct the positions and type of qrs complexes; (iii) average beat module, which provides an option to switch between leads, provides graphical markers for annotation of fiducial points and time-intervals in the averaged heartbeat waveform and sets the average beat type; and (iv) rhythm type module, which shows the rhythm type and provides a possibility to change it. the software is opened for further developments. the presented annotation tool could be potentially used for annotation of large ecg databases without limitations on the number of ecg leads and number of annotations per ecg recording. this is in line with the new trends for accumulation of large ecg databases from multiple sources, which are the thoughtful platform for development of machine learning and especially deep learning algorithms for ecg signal processing and arrhythmia classification.",web-based software tool for electrocardiogram annotation
115,2-s2.0-85126844256,10.24425/ijet.2022.139843,Analysis of a novel FPGA-based system for filtering audio signals using a finite impulse response filters,Lipowski A.,International Journal of Electronics and Telecommunications,2022-01-01,"In this article, an analysis of an innovative system for filtering signals in the audible range (16 Hz - 20 kHz) on programmable logic devices using a filters with a finite impulse response, is presented. Mentioned system was neat combination of software and hardware platform, where in the program layer a multiple programming languages including VHDL, JavaScript, Matlab or HTML were used to create completely useful application. To determine the coefficients of polynomial filters the Matlab Filter Design & Analysis Tool was used. Thanks to the developed graphic layer, a user-friendly interface was created, which allows easily transfer the required coefficients from the computer to the executive system. The practical implementation made on the FPGA platform, specifically on the Altera DE2-115 development kit with the FPGA Cyclone IV, was compared with simulation realization of Matlab FIR filters. The performed research confirm the effectiveness of filtration in real time with up to 128th order of the filter for both audio channels simultaneously in FPGA-based system.",Audio filtering | FIR filter | FPGA | Signal processing,0,19-26,Journal,Article,3.0,"Lipowski, Adrian;Majewski, Paweł;Pluta, Sławomir",57543392300;56439096600;55811163400,Uniwersytet Opolski,Poland,"in this article, an analysis of an innovative system for filtering signals in the audible range (16 hz - 20 khz) on programmable logic devices using a filters with a finite impulse response, is presented. mentioned system was neat combination of software and hardware platform, where in the program layer a multiple programming languages including vhdl, javascript, matlab or html were used to create completely useful application. to determine the coefficients of polynomial filters the matlab filter design & analysis tool was used. thanks to the developed graphic layer, a user-friendly interface was created, which allows easily transfer the required coefficients from the computer to the executive system. the practical implementation made on the fpga platform, specifically on the altera de2-115 development kit with the fpga cyclone iv, was compared with simulation realization of matlab fir filters. the performed research confirm the effectiveness of filtration in real time with up to 128th order of the filter for both audio channels simultaneously in fpga-based system.",analysis of a novel fpga-based system for filtering audio signals using a finite impulse response filters
116,2-s2.0-85126731075,10.15587/1729-4061.2022.253146,DESIGN AND IMPLEMENTATION OF A FAULT TOLERANT WEB-BASED EXAMINATION SYSTEM FOR DEVELOPING COUNTRIES,Eko C.E.,Eastern-European Journal of Enterprise Technologies,2022-01-01,"This paper presents the development of a web-based examination system that focuses on automated resolution of faults such as power, network, or component failure that may occur when an e-learning system is used to conduct an examination. This system can withstand various challenges that hinder the adoption of e-learning technologies in developing countries. This is important because it will reduce the time and cost involved in conducting large scale examinations by tertiary institutions without the need to upgrade existing infrastructures. These institutions will not necessarily require uninterrupted power or network connection to conduct web-based examinations as the system can easily resume if such an incident occurs. The architecture of the proposed web-based online examination system provides for integrated management of functions such as question pool creation and update, examination monitoring, failure toleration and recovery, automated grading, and randomization. The system also eliminates the need for manual scheduling of examinations which requires much planning and is error-prone. Different examinations can be scheduled to run simultaneously. The design technology adopted for the implementation is a client/server technology. The incremental software development model in conjunction with prototyping technique was adopted in the development of the webbased examination system due to the iterative nature of the developed software. The system was developed using PHP, JavaScript, Ajax and MySQL. The system has been applied to conduct an examination involving more than 20,000 students per semester at University of Calabar. It has been proved to save efforts of teachers and students",Auto-grading | Client/server | E-learning | Examination | Mysql | Randomization | Recovery | Resumption | Scheduling | Web-based,0,58-67,Journal,Article,3.0,"Eko, Ceasar E.;Eteng, Idongesit E.;Essien, Eyo E.",57540385800;56111068200;57204504848,University of Calabar,Nigeria,"this paper presents the development of a web-based examination system that focuses on automated resolution of faults such as power, network, or component failure that may occur when an e-learning system is used to conduct an examination. this system can withstand various challenges that hinder the adoption of e-learning technologies in developing countries. this is important because it will reduce the time and cost involved in conducting large scale examinations by tertiary institutions without the need to upgrade existing infrastructures. these institutions will not necessarily require uninterrupted power or network connection to conduct web-based examinations as the system can easily resume if such an incident occurs. the architecture of the proposed web-based online examination system provides for integrated management of functions such as question pool creation and update, examination monitoring, failure toleration and recovery, automated grading, and randomization. the system also eliminates the need for manual scheduling of examinations which requires much planning and is error-prone. different examinations can be scheduled to run simultaneously. the design technology adopted for the implementation is a client/server technology. the incremental software development model in conjunction with prototyping technique was adopted in the development of the webbased examination system due to the iterative nature of the developed software. the system was developed using php, javascript, ajax and mysql. the system has been applied to conduct an examination involving more than 20,000 students per semester at university of calabar. it has been proved to save efforts of teachers and students",design and implementation of a fault tolerant web-based examination system for developing countries
117,2-s2.0-85126202564,10.1007/978-3-030-96299-9_75,Information Technology Roles and Their Most-Used Programming Languages,Dada O.A.,Lecture Notes in Networks and Systems,2022-01-01,"In this digital age, almost every area of our lives and businesses are controlled by Computer code. Consequently, programming skills are now in high demand across industries - not only for those in software development but also for almost every career role. According to a study conducted in the United States, over 7 million out of 26 million online job postings were reported to have required programming skills. In this study, we identified and ranked the ‘most-used’ programming languages for each of the 23 different job roles in IT teams. Knowing the ‘most-used’ programming languages for a given role will help stakeholders plan adequately. Our results show that JavaScript was the overall most-used language, followed by HTML/CSS and then SQL. However, in terms of specific roles, HTML/CSS was the most-used language for Marketing/Sales, JavaScript for those in software development, Python for Data Scientists, Academic researchers and Scientists. SQL for Database Administrators, Data Engineers and Data Analysts. The outcome of this study can be used by relevant stakeholders to make decisions regarding careers, professional development and curriculum designs.",Information technology | IT job role | JavaScript | Programming languages | Python | Skills | Software developer | StackOverflow,0,797-805,Book Series,Conference Paper,5.0,"Dada, Oluwaseun Alexander;Aruleba, Kehinde;Yunusa, Abdullahi Abubakar;Sanusi, Ismaila Temitayo;Obaido, George",57219835734;57484703900;57208798944;57200147381;57196318584,Department of Computer Science and Engineering;Itä-Suomen yliopisto;Usmanu Danfodiyo University;Walter Sisulu University;Helsingin Yliopisto;Universiti Sains Malaysia;The School of Software;Centre for Multidisciplinary Research and Innovation (CEMRI),United States;Finland;Nigeria;South Africa;Finland;Malaysia;Nigeria;Nigeria,"in this digital age, almost every area of our lives and businesses are controlled by computer code. consequently, programming skills are now in high demand across industries - not only for those in software development but also for almost every career role. according to a study conducted in the united states, over 7 million out of 26 million online job postings were reported to have required programming skills. in this study, we identified and ranked the ‘most-used’ programming languages for each of the 23 different job roles in it teams. knowing the ‘most-used’ programming languages for a given role will help stakeholders plan adequately. our results show that javascript was the overall most-used language, followed by html/css and then sql. however, in terms of specific roles, html/css was the most-used language for marketing/sales, javascript for those in software development, python for data scientists, academic researchers and scientists. sql for database administrators, data engineers and data analysts. the outcome of this study can be used by relevant stakeholders to make decisions regarding careers, professional development and curriculum designs.",information technology roles and their most-used programming languages
119,2-s2.0-85124125136,10.1007/978-3-030-93956-4_8,JSLIM: Reducing the Known Vulnerabilities of JavaScript Application by Debloating,Ye R.,Communications in Computer and Information Science,2022-01-01,"As the complexity of software projects increases, more and more developers choose to package various external dependency libraries into software projects to simplify software development. Unfortunately, these introduced dependent libraries are likely to introduce many potential security risks. This phenomenon is called software bloat. One way to handle this increased threat is through software debloating, i.e., the removal of dead code and code corresponding to vulnerabilities introduced from external dependency libraries. In our paper, we proposed JSLIM, an effective vulnerability-aware software debloating system. First, JSLIM processes the public vulnerability information through natural language processing technology, obtains the mapping relationship between the vulnerability and the NPM package, and determines which function in the package causes a specific vulnerability. Then, according to the generated function call graph, determine whether the program calls the method that generates the vulnerability in the dependent library. JSLIM removes the code that isn’t called by the program and uses the sandbox to isolate the code that has vulnerabilities but cannot be removed. We conduct experiments on popular open-source JavaScript applications. The experimental results show that our method removes most of the code related to the known vulnerabilities of the application and effectively prevents attackers from exploiting known vulnerabilities in the NPM package to launch attacks on applications.",Debloating | JavaScript | Security | Static analysis | Vulnerability,0,128-143,Book Series,Conference Paper,6.0,"Ye, Renjun;Liu, Liang;Hu, Simin;Zhu, Fangzhou;Yang, Jingxiu;Wang, Feng",57212603562;56209032800;57214090743;57222074911;57209469299;57271362200,Nanjing University of Aeronautics and Astronautics,China,"as the complexity of software projects increases, more and more developers choose to package various external dependency libraries into software projects to simplify software development. unfortunately, these introduced dependent libraries are likely to introduce many potential security risks. this phenomenon is called software bloat. one way to handle this increased threat is through software debloating, i.e., the removal of dead code and code corresponding to vulnerabilities introduced from external dependency libraries. in our paper, we proposed jslim, an effective vulnerability-aware software debloating system. first, jslim processes the public vulnerability information through natural language processing technology, obtains the mapping relationship between the vulnerability and the npm package, and determines which function in the package causes a specific vulnerability. then, according to the generated function call graph, determine whether the program calls the method that generates the vulnerability in the dependent library. jslim removes the code that isn’t called by the program and uses the sandbox to isolate the code that has vulnerabilities but cannot be removed. we conduct experiments on popular open-source javascript applications. the experimental results show that our method removes most of the code related to the known vulnerabilities of the application and effectively prevents attackers from exploiting known vulnerabilities in the npm package to launch attacks on applications.",jslim: reducing the known vulnerabilities of javascript application by debloating
120,2-s2.0-85124102820,10.1007/978-3-030-85851-3_26,Variants of Visualization of the Marine Forecast on the Examples of the Crimean Basin of the Black Sea,Voronina N.,Springer Geology,2022-01-01,"This paper compares the results of the functioning of software modules for the oceanographic environment using modern graphic resources of well-known programming languages R, JS, PHP, HTML, both with the use of tools of the Google Maps service and without the use of satellite maps. Recall that JS, PHP, HTML software is used in Web-development, while R is a programming language for statistical data processing and work with graphics. The results of the work of various software modules shown in the article are generally the same—graphical displays of geophysical parameters using examples of forecasts of the state of the Black Sea. However, the software tools to achieve the equal results are different. The aim is to determine the most optimal means of presentation of oceanographic data for future use in the visualization of marine forecasts. An important result of this work is the compilation of assessment recommendations for the use of various software tools for visualizing oceanographic data.",Black Sea | Geophysical parameters | Mapping services google maps | Salinity of the marine environment | Sea surface temperature | Visualization,0,233-242,Book Series,Book Chapter,1.0,"Voronina, N.",57188805334,Marine Hydrophysical Institute of RAS,Ukraine,"this paper compares the results of the functioning of software modules for the oceanographic environment using modern graphic resources of well-known programming languages r, js, php, html, both with the use of tools of the google maps service and without the use of satellite maps. recall that js, php, html software is used in web-development, while r is a programming language for statistical data processing and work with graphics. the results of the work of various software modules shown in the article are generally the same—graphical displays of geophysical parameters using examples of forecasts of the state of the black sea. however, the software tools to achieve the equal results are different. the aim is to determine the most optimal means of presentation of oceanographic data for future use in the visualization of marine forecasts. an important result of this work is the compilation of assessment recommendations for the use of various software tools for visualizing oceanographic data.",variants of visualization of the marine forecast on the examples of the crimean basin of the black sea
121,2-s2.0-85124043376,10.1007/978-3-030-94551-0_39,Design of Data Visualization System for Mobile Social Web Front End Development Based on HTML5,Wei J.h.,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",2022-01-01,"In view of the low efficiency of data visualization and the slow speed of database reading and writing when the current data visualization system is dealing with the front-end development data of mobile social Web, a data visualization system for front-end development of mobile social Web based on HTML5 is designed. The data collector is used to collect and store the front-end development data of mobile social Web, and the visual controller is used to communicate with the visual external devices to complete the hardware design of the system. Preprocess the Web front-end development data to ensure the data dimension differences within a reasonable range, divide the data into HTML5, JavaScript, CSS three different forms of files, classify low dimensional data and high-dimensional data, design two types of data visualization interface, complete the system software design. The experimental results show that the reading and writing speed of the database of the design system is accelerated, the data insertion time, query time and visualization time are effectively shortened, and the efficiency of information visualization is improved.",Development data | HTML5 | Mobile social | Visualization system | Web front end,0,491-503,Book Series,Conference Paper,6.0,"Wei, Jian hong;Cheng, Yun li;Chen, Xiao ru;Mao, Yang hong;Gao, Yu;Yu, Jia",57439999600;57439655500;57438965800;55497985300;57438796200;57439478300,East China of Jiaotong University;Software Engineering Institute of Guangzhou,China;China,"in view of the low efficiency of data visualization and the slow speed of database reading and writing when the current data visualization system is dealing with the front-end development data of mobile social web, a data visualization system for front-end development of mobile social web based on html5 is designed. the data collector is used to collect and store the front-end development data of mobile social web, and the visual controller is used to communicate with the visual external devices to complete the hardware design of the system. preprocess the web front-end development data to ensure the data dimension differences within a reasonable range, divide the data into html5, javascript, css three different forms of files, classify low dimensional data and high-dimensional data, design two types of data visualization interface, complete the system software design. the experimental results show that the reading and writing speed of the database of the design system is accelerated, the data insertion time, query time and visualization time are effectively shortened, and the efficiency of information visualization is improved.",design of data visualization system for mobile social web front end development based on html5
124,2-s2.0-85123678269,10.1109/ACCESS.2022.3145686,Clone-Seeker: Effective Code Clone Search Using Annotations,Hammad M.,IEEE Access,2022-01-01,"Source code search plays an important role in software development, e.g. for exploratory development or opportunistic reuse of existing code from a code base. Often, exploration of different implementations with the same functionality is needed for tasks like automated software transplantation, software diversification, and software repair. Code clones, which are syntactically or semantically similar code fragments, are perfect candidates for such tasks. Searching for code clones involves a given search query to retrieve the relevant code fragments. We propose a novel approach called Clone-Seeker that focuses on utilizing clone class features in retrieving code clones. For this purpose, we generate metadata for each code clone in the form of a natural language document. The metadata includes a pre-processed list of identifiers from the code clones augmented with a list of keywords indicating the semantics of the code clone. This keyword list can be extracted from a manually annotated general description of the clone class, or automatically generated from the source code of the entire clone class. This approach helps developers to perform code clone search based on a search query written either as source code terms, or as natural language. With various experiments, we show that (1) Clone-Seeker is effective in finding clones from BigCloneBench dataset by applying code queries and natural language queries; 2) Clone-Seeker has a higher recall when searching for semantic code clones (i.e., Type-4) in BigCloneBench than the state-of-the-art; 3) Clone-Seeker is a generalized technique as it is effective in finding clones in Project CodeNet dataset by applying code queries and natural language queries. 4) Clone-Seeker with manual annotation outperforms other variants in finding clones on the basis of natural language queries",Annotation | code clone | code clone search | information retrieval | keyword extraction,1,11696-11713,Journal,Article,4.0,"Hammad, Muhammad;Babur, Onder;Basit, Hamid Abdul;Van Den Brand, Mark",56490230800;55949449000;12241632000;57192113699,Technische Universiteit Eindhoven;Prince Sultan University;Wageningen University &amp; Research,Netherlands;Saudi Arabia;Netherlands,"source code search plays an important role in software development, e.g. for exploratory development or opportunistic reuse of existing code from a code base. often, exploration of different implementations with the same functionality is needed for tasks like automated software transplantation, software diversification, and software repair. code clones, which are syntactically or semantically similar code fragments, are perfect candidates for such tasks. searching for code clones involves a given search query to retrieve the relevant code fragments. we propose a novel approach called clone-seeker that focuses on utilizing clone class features in retrieving code clones. for this purpose, we generate metadata for each code clone in the form of a natural language document. the metadata includes a pre-processed list of identifiers from the code clones augmented with a list of keywords indicating the semantics of the code clone. this keyword list can be extracted from a manually annotated general description of the clone class, or automatically generated from the source code of the entire clone class. this approach helps developers to perform code clone search based on a search query written either as source code terms, or as natural language. with various experiments, we show that (1) clone-seeker is effective in finding clones from bigclonebench dataset by applying code queries and natural language queries; 2) clone-seeker has a higher recall when searching for semantic code clones (i.e., type-4) in bigclonebench than the state-of-the-art; 3) clone-seeker is a generalized technique as it is effective in finding clones in project codenet dataset by applying code queries and natural language queries. 4) clone-seeker with manual annotation outperforms other variants in finding clones on the basis of natural language queries",clone-seeker: effective code clone search using annotations
126,2-s2.0-85123303561,10.1109/ACCESS.2022.3141702,Transformation Architecture for Multi-Layered WebApp Source Code Generation,Tesoriero R.,IEEE Access,2022-01-01,"The evolution of Web technologies leads to software premature obsolescence requiring technology-independent representations to increase the reuse rates during the development process. They also require integration into service-oriented architectures to exchange information with different Web systems supporting runtime interoperability. Web Applications (WebApps) run on devices with different capabilities and limitations increasing the complexity of the development process. To address these challenges, different proposals have emerged to facilitate the development of WebApps, which is still an open research field with many challenges to address. This paper presents a model transformation architecture based on software standards to automatically generate full stack multi-layered WebApps covering Persistence, Service, and Presentation layers. This transformation architecture also generates the set of test cases to test WebApp business logic. The proposed transformation architecture only requires a UML platform-independent class model as an input to generate fully functional Web applications in a three-tier architecture including the three layers, while most proposals focus on the generation of the Presentation layer. In addition, this architecture employs software industry standards to enable an easy integration into third-party tools and development environments. The transformation Architecture proposed has been empirically validated on the case study of a fully functional travel management WebApp that is generated using a UML class diagram employing a third-party tool integrated into the same integrated development environment.",Client-server systems | Computer-aided software engineering | Software product lines,0,5223-5237,Journal,Article,5.0,"Tesoriero, Ricardo;Rueda, Alejandro;Gallud, Jose A.;Lozano, Maria D.;Fernando, Anil",23398335700;57422638500;6507169834;35496796100;7005706996,Instituto de Investigación en Informática de Albacete;University of Strathclyde,Spain;United Kingdom,"the evolution of web technologies leads to software premature obsolescence requiring technology-independent representations to increase the reuse rates during the development process. they also require integration into service-oriented architectures to exchange information with different web systems supporting runtime interoperability. web applications (webapps) run on devices with different capabilities and limitations increasing the complexity of the development process. to address these challenges, different proposals have emerged to facilitate the development of webapps, which is still an open research field with many challenges to address. this paper presents a model transformation architecture based on software standards to automatically generate full stack multi-layered webapps covering persistence, service, and presentation layers. this transformation architecture also generates the set of test cases to test webapp business logic. the proposed transformation architecture only requires a uml platform-independent class model as an input to generate fully functional web applications in a three-tier architecture including the three layers, while most proposals focus on the generation of the presentation layer. in addition, this architecture employs software industry standards to enable an easy integration into third-party tools and development environments. the transformation architecture proposed has been empirically validated on the case study of a fully functional travel management webapp that is generated using a uml class diagram employing a third-party tool integrated into the same integrated development environment.",transformation architecture for multi-layered webapp source code generation
130,2-s2.0-85121902267,10.1007/978-3-030-92231-3_8,Towards Seamless IoT Device-Edge-Cloud Continuum:: Software Architecture Options of IoT Devices Revisited,Taivalsaari A.,Communications in Computer and Information Science,2022-01-01,"In this paper we revisit a taxonomy of client-side IoT software architectures that we presented a few years ago. We note that the emergence of inexpensive AI/ML hardware and new communication technologies are broadening the architectural options for IoT devices even further. These options can have a significant impact on the overall end-to-end architecture and topology of IoT systems, e.g., in determining how much computation can be performed on the edge of the network. We study the implications of the IoT device architecture choices in light of the new observations, as well as make some new predictions about future directions. Additionally, we make a case for isomorphic IoT systems in which development complexity is alleviated with consistent use of technologies across the entire stack, providing a seamless continuum from edge devices all the way to the cloud.",Edge computing | Embedded devices | Internet of Things | IoT | Isomorphic software | Isomorphism | Liquid software | Programmable world | Software architecture | Software engineering,0,82-98,Book Series,Conference Paper,3.0,"Taivalsaari, Antero;Mikkonen, Tommi;Pautasso, Cesare",6507045147;57220096141;7801368483,University of Jyväskylä;Nokia Bell Labs;Tampere University;Università della Svizzera italiana;Helsingin Yliopisto,Finland;United States;Finland;Switzerland;Finland,"in this paper we revisit a taxonomy of client-side iot software architectures that we presented a few years ago. we note that the emergence of inexpensive ai/ml hardware and new communication technologies are broadening the architectural options for iot devices even further. these options can have a significant impact on the overall end-to-end architecture and topology of iot systems, e.g., in determining how much computation can be performed on the edge of the network. we study the implications of the iot device architecture choices in light of the new observations, as well as make some new predictions about future directions. additionally, we make a case for isomorphic iot systems in which development complexity is alleviated with consistent use of technologies across the entire stack, providing a seamless continuum from edge devices all the way to the cloud.",towards seamless iot device-edge-cloud continuum:: software architecture options of iot devices revisited
131,2-s2.0-85121596634,10.32604/CSSE.2022.021326,Enhancement of E-commerce Service by Designing Last Mile Delivery Platform,Alkhalifah A.,Computer Systems Science and Engineering,2022-01-01,"The revolution of technology and the rapid evolution of the digital world had a significant effect on the development and expansion of e-commerce. Last mile delivery, for which different app-based delivery services have recently emerged, is a new area of research that is not thoroughly addressed. Delivery service is one of the supporting platforms of e-commerce. One of the delivery issues is that many customers experience difficulties in communicating and coordinating with the logistics companies responsible for the delivery service. This challenge is emphasized in this study which introduces a new system to facilitate communication and coordination between customers and logistics companies by using one identity and one interface. This paper is a programming-based study, as the proposed system evaluates a website to serve logistics companies as well as designs an application (app) to serve the customers of logistics companies. Swift, a powerful open-source and object-oriented programming language, and the mark-up language (HTML) were used to build the last mile delivery system. In addition, Firebase, a cloud-hosted real-time database built on Google infrastructure, were used to develop the system. By increasing the level of customer satisfaction and reducing delivery failure rates, this system will eventually increase the prosperity of e-commerce.",E-commerce | Last mile delivery | Logistics companies,0,49-67,Journal,Article,3.0,"Alkhalifah, Ali;Alorini, Fadwa;Alturki, Reef",37080092000;57383928500;57383497900,Al Qassim University,Saudi Arabia,"the revolution of technology and the rapid evolution of the digital world had a significant effect on the development and expansion of e-commerce. last mile delivery, for which different app-based delivery services have recently emerged, is a new area of research that is not thoroughly addressed. delivery service is one of the supporting platforms of e-commerce. one of the delivery issues is that many customers experience difficulties in communicating and coordinating with the logistics companies responsible for the delivery service. this challenge is emphasized in this study which introduces a new system to facilitate communication and coordination between customers and logistics companies by using one identity and one interface. this paper is a programming-based study, as the proposed system evaluates a website to serve logistics companies as well as designs an application (app) to serve the customers of logistics companies. swift, a powerful open-source and object-oriented programming language, and the mark-up language (html) were used to build the last mile delivery system. in addition, firebase, a cloud-hosted real-time database built on google infrastructure, were used to develop the system. by increasing the level of customer satisfaction and reducing delivery failure rates, this system will eventually increase the prosperity of e-commerce.",enhancement of e-commerce service by designing last mile delivery platform
135,2-s2.0-85118666071,10.1109/TVCG.2021.3114876,Gosling: A Grammar-based Toolkit for Scalable and Interactive Genomics Data Visualization,L'Yi S.,IEEE Transactions on Visualization and Computer Graphics,2022-01-01,"The combination of diverse data types and analysis tasks in genomics has resulted in the development of a wide range of visualization techniques and tools. However, most existing tools are tailored to a specific problem or data type and offer limited customization, making it challenging to optimize visualizations for new analysis tasks or datasets. To address this challenge, we designed Gosling-A grammar for interactive and scalable genomics data visualization. Gosling balances expressiveness for comprehensive multi-scale genomics data visualizations with accessibility for domain scientists. Our accompanying JavaScript toolkit called Gosling.js provides scalable and interactive rendering. Gosling.js is built on top of an existing platform for web-based genomics data visualization to further simplify the visualization of common genomics data formats. We demonstrate the expressiveness of the grammar through a variety of real-world examples. Furthermore, we show how Gosling supports the design of novel genomics visualizations. An online editor and examples of Gosling.js, its source code, and documentation are available at https://gosling.js.org.",declarative specification | Genomics | visualization grammar,0,140-150,Journal,Article,4.0,"L'Yi, Sehi;Wang, Qianwen;Lekschas, Fritz;Gehlenborg, Nils",56028558000;57226562040;55773628200;57208464039,Harvard John A. Paulson School of Engineering and Applied Sciences;Harvard Medical School,United States;United States,"the combination of diverse data types and analysis tasks in genomics has resulted in the development of a wide range of visualization techniques and tools. however, most existing tools are tailored to a specific problem or data type and offer limited customization, making it challenging to optimize visualizations for new analysis tasks or datasets. to address this challenge, we designed gosling-a grammar for interactive and scalable genomics data visualization. gosling balances expressiveness for comprehensive multi-scale genomics data visualizations with accessibility for domain scientists. our accompanying javascript toolkit called gosling.js provides scalable and interactive rendering. gosling.js is built on top of an existing platform for web-based genomics data visualization to further simplify the visualization of common genomics data formats. we demonstrate the expressiveness of the grammar through a variety of real-world examples. furthermore, we show how gosling supports the design of novel genomics visualizations. an online editor and examples of gosling.js, its source code, and documentation are available at https://gosling.js.org.",gosling: a grammar-based toolkit for scalable and interactive genomics data visualization
138,2-s2.0-85116048225,10.1007/978-981-16-2380-6_79,Crime Mapping Approach for Crime Pattern Identification: A Prototype for the Province of Cavite,Gelera A.M.,Lecture Notes in Networks and Systems,2022-01-01,"Crime incident is one of the serious problems in Cavite province. The local government together with law enforcement agencies strictly implements the visibility of police officers to address the increasing number of crime incidents. However, with the insufficient number of police officers to patrol the area, together with the increasing population, crime incidents provides a great impact on the security of people. Crime incident mapping is a new approach in addressing the problem. Crime maps have begun to emerge in different platforms and can now be used by law enforcement agencies to visualize and analyze crime incidents by extracting data recorded from the map using Google map API. Monitoring crime incidents using Google map has significant effects in increasing awareness of the general public in the area and in improving better data dissemination. This study used the iterative software development methodology in addressing the current problem. This method is appropriate for web development because it follows an iteration procedure, wherein the developer can apply changes in every module of the crime mapping website. Using this method, the objectives of the study were met, which is capable of providing different types of reports such as spatial report and crime pattern report that served as a guide for law enforcement agencies to easily track crime incidents. These reports can arrange crime patterns by providing specific crime records on yearly, quarterly and monthly basis. The results of different tests conducted on the website show the accuracy of the prototype in terms of providing relevant data to its users.",Application programming interface | Crime mapping | Crime pattern | Google map | Maps,0,899-909,Book Series,Conference Paper,2.0,"Gelera, Aries M.;Dajao, Edgardo S.",57279753600;57279307400,Cavite State University;Graduate School,Philippines;Philippines,"crime incident is one of the serious problems in cavite province. the local government together with law enforcement agencies strictly implements the visibility of police officers to address the increasing number of crime incidents. however, with the insufficient number of police officers to patrol the area, together with the increasing population, crime incidents provides a great impact on the security of people. crime incident mapping is a new approach in addressing the problem. crime maps have begun to emerge in different platforms and can now be used by law enforcement agencies to visualize and analyze crime incidents by extracting data recorded from the map using google map api. monitoring crime incidents using google map has significant effects in increasing awareness of the general public in the area and in improving better data dissemination. this study used the iterative software development methodology in addressing the current problem. this method is appropriate for web development because it follows an iteration procedure, wherein the developer can apply changes in every module of the crime mapping website. using this method, the objectives of the study were met, which is capable of providing different types of reports such as spatial report and crime pattern report that served as a guide for law enforcement agencies to easily track crime incidents. these reports can arrange crime patterns by providing specific crime records on yearly, quarterly and monthly basis. the results of different tests conducted on the website show the accuracy of the prototype in terms of providing relevant data to its users.",crime mapping approach for crime pattern identification: a prototype for the province of cavite
139,2-s2.0-85115101922,10.1007/978-3-030-85626-7_88,Developing a University Twitter-Like Smart Social Network,Popescu M.C.,Lecture Notes in Networks and Systems,2022-01-01,"The paper consists in the development of a Twitter-like smart platform for customized use, in which users (especially the students of the University) can register and log in, follow other users, view the posts of the users they are watching, post text, etc. The login/registration part is created in order to prevent someone from posting on someone else’s behalf. At this stage, no security levels are implemented in the application because this is a complex theme that requires adaptability depending on the end goal of the software and the target audience and it will be developed in the future. The implementation of the software described in the paper involves the use of web technologies, including front-end and back-end development, PHP language as the basic language and its technologies, such as Boostrap and jQuery. This application is intended to those who want to develop something simple and fast without having any knowledge of the relational database management system. The social network is a very friendly environment, where students find solutions to various problems. Furthermore, it can also be used for organization purposes, considering that it is a place where the most important information for students circulates. The implemented software, based on artificial intelligence, allows experiencing the capabilities of the social network to learn the model recognition, to optimize the search process. The application is original considering that until recently, the implementation of the concept of neural networks in a scripting language was not possible.",PHP | Redis | Twitter-like social network | Web application,0,759-766,Book Series,Conference Paper,3.0,"Popescu, Marius Constantin;Rada, Calin;Naaji, Antoanela",24438025700;57261666900;24492087400,Vasile Goldis Western University of Arad,Romania,"the paper consists in the development of a twitter-like smart platform for customized use, in which users (especially the students of the university) can register and log in, follow other users, view the posts of the users they are watching, post text, etc. the login/registration part is created in order to prevent someone from posting on someone else’s behalf. at this stage, no security levels are implemented in the application because this is a complex theme that requires adaptability depending on the end goal of the software and the target audience and it will be developed in the future. the implementation of the software described in the paper involves the use of web technologies, including front-end and back-end development, php language as the basic language and its technologies, such as boostrap and jquery. this application is intended to those who want to develop something simple and fast without having any knowledge of the relational database management system. the social network is a very friendly environment, where students find solutions to various problems. furthermore, it can also be used for organization purposes, considering that it is a place where the most important information for students circulates. the implemented software, based on artificial intelligence, allows experiencing the capabilities of the social network to learn the model recognition, to optimize the search process. the application is original considering that until recently, the implementation of the concept of neural networks in a scripting language was not possible.",developing a university twitter-like smart social network
140,2-s2.0-85114102856,10.1007/978-3-030-76653-5_13,Mutation Testing and Web Applications—A Test Driven Development Approach for Web Applications Built with Java Script,Suguna Mallika S.,Intelligent Systems Reference Library,2022-01-01,"Defect Prevention refers to the process of ensuring that no defects occur in the first place rather than later detecting defects and correcting them. A test-driven development approach naturally contributes to defect prevention along the software development process pipeline. A generic test suite that suits the testing needs of any web application is needed. The test suite should serve a regression test suite’s purpose to ensure an application’s general health providing a confident user experience. The authors presented a generic set for checking web apps, mutation operators. In this work, the operators’ comprehensive suite is presented as an exhaustive regression test suite to prevent web application defects. Small and medium business enterprises can bank on the regression test suite proposed for customer retention while saving on their testing budgets. The test suite promises a robust web app persistent against any kind of malignant usage.",Defect prevention | Mutation operators | Mutation testing | Web application testing,0,243-259,Book Series,Book Chapter,2.0,"Suguna Mallika, S.;Rajya Lakshmi, D.",57211310382;55446136700,"CVR College of Engineering;Jawaharlal Nehru Technological University, Kakinada;CSE",India;India;India,"defect prevention refers to the process of ensuring that no defects occur in the first place rather than later detecting defects and correcting them. a test-driven development approach naturally contributes to defect prevention along the software development process pipeline. a generic test suite that suits the testing needs of any web application is needed. the test suite should serve a regression test suite’s purpose to ensure an application’s general health providing a confident user experience. the authors presented a generic set for checking web apps, mutation operators. in this work, the operators’ comprehensive suite is presented as an exhaustive regression test suite to prevent web application defects. small and medium business enterprises can bank on the regression test suite proposed for customer retention while saving on their testing budgets. the test suite promises a robust web app persistent against any kind of malignant usage.",mutation testing and web applications—a test driven development approach for web applications built with java script
141,2-s2.0-85112221802,10.1109/MS.2021.3103134,JavaScript API Deprecation Landscape: A Survey and Mining Study,Nascimento R.,IEEE Software,2022-01-01,"JavaScript provides no native deprecation mechanisms. To assess how developers deprecate JavaScript application programming interfaces (APIs), we report the results of a survey and a mining study on JavaScript developers and projects. The results suggest several solutions but no standard solution to deprecate JavaScript APIs.",API deprecation | JavaScript | software library,1,96-105,Journal,Article,3.0,"Nascimento, Romulo;Figueiredo, Eduardo;Hora, Andre",57216459151;57213806535;55205116000,Universidade Federal de Minas Gerais,Brazil,"javascript provides no native deprecation mechanisms. to assess how developers deprecate javascript application programming interfaces (apis), we report the results of a survey and a mining study on javascript developers and projects. the results suggest several solutions but no standard solution to deprecate javascript apis.",javascript api deprecation landscape: a survey and mining study
143,2-s2.0-85131368745,10.11959/j.issn.2096-109x.2021066,Application progress of SGX in trusted computing area,Zhao B.,Chinese Journal of Network and Information Security,2021-12-15,"The trusted computing technology SGX protects the confidentiality and integrity of key codes and data by isolating a trusted execution environment, which can help prevent all kinds of attacks. Firstly, the research background and working principle of SGX were introduced, the research status of SGX in the field of trusted computing were analyzed. Then, sorted out the current application difficulties and solutions of SGX were sorted out and compared with other trusted computing technologies. Finally, SGX technology development direction in the field of trusted computing was discussed.",Dependability | Software guard extensions | Trusted computing,0,126-142,Journal,Article,3.0,"Zhao, Bo;Yuan, Anqi;An, Yang",56427296500;57728606100;57728826100,Wuhan University,China,"the trusted computing technology sgx protects the confidentiality and integrity of key codes and data by isolating a trusted execution environment, which can help prevent all kinds of attacks. firstly, the research background and working principle of sgx were introduced, the research status of sgx in the field of trusted computing were analyzed. then, sorted out the current application difficulties and solutions of sgx were sorted out and compared with other trusted computing technologies. finally, sgx technology development direction in the field of trusted computing was discussed.",application progress of sgx in trusted computing area
145,2-s2.0-85121424008,10.1145/3493651.3493669,Beyond @CloudFunction: Powerful Code Annotations to Capture Serverless Runtime Patterns,Klingler R.,"Proceedings of the 7th International Workshop on Serverless Computing, WoSC 2021",2021-12-06,"Simplicity in elastically scalable application development is a key concern addressed by the serverless computing paradigm, in particular the code-level Function-as-a-Service (FaaS). Various FaaSification frameworks demonstrated that marking code methods to streamline their offloading as cloud functions offers a simple bridge to software engineering habits. As application complexity increases, more complex runtime patterns with background activities, such as keeping containerised cloud functions warm to ensure the absence of cold starts, usually require giving up on simplicity and instead investing efforts into orchestrating infrastructure. By bringing infrastructure-as-code concepts into the function source via powerful code annotations, typical orchestration patterns can be simplified again. We evaluate this idea and demonstrate its practical feasibility with FaaS Fusion, an annotations library and transpiler framework for JavaScript.",cloudware | deployment | serverless computing | software engineering,0,23-28,Conference Proceeding,Conference Paper,3.0,"Klingler, Raffael;Trifunovic, Nemanja;Spillner, Josef",57377101200;57377872300;14042825100,ZHAW Zurich University of Applied Sciences,Switzerland,"simplicity in elastically scalable application development is a key concern addressed by the serverless computing paradigm, in particular the code-level function-as-a-service (faas). various faasification frameworks demonstrated that marking code methods to streamline their offloading as cloud functions offers a simple bridge to software engineering habits. as application complexity increases, more complex runtime patterns with background activities, such as keeping containerised cloud functions warm to ensure the absence of cold starts, usually require giving up on simplicity and instead investing efforts into orchestrating infrastructure. by bringing infrastructure-as-code concepts into the function source via powerful code annotations, typical orchestration patterns can be simplified again. we evaluate this idea and demonstrate its practical feasibility with faas fusion, an annotations library and transpiler framework for javascript.",beyond @cloudfunction: powerful code annotations to capture serverless runtime patterns
148,2-s2.0-85121432597,10.3390/smartcities4040070,Requirements and architecture of a cloud based insomnia therapy and diagnosis platform: A smart cities approach,Reichenpfader D.,Smart Cities,2021-12-01,"Insomnia is the most common sleep disorder worldwide. Its effects generate economic costs in the millions but could be effectively reduced using digitally provisioned cognitive behavioural therapy. However, traditional acquisition and maintenance of the necessary technical infrastructure requires high financial and personnel expenses. Sleep analysis is still mostly done in artificial settings in clinical environments. Nevertheless, innovative IT infrastructure, such as mHealth and cloud service solutions for home monitoring, are available and allow context-aware service provision following the Smart Cities paradigm. This paper aims to conceptualise a digital, cloud-based platform with context-aware data storage that supports diagnosis and therapy of non-organic insomnia. In a first step, requirements needed for a remote diagnosis, therapy, and monitoring system are identified. Then, the software architecture is drafted based on the above mentioned requirements. Lastly, an implementation concept of the software architecture is proposed through selecting and combining eleven cloud computing services. This paper shows how treatment and diagnosis of a common medical issue could be supported effectively and cost-efficiently by utilising state-of-the-art technology. The paper demonstrates the relevance of context-aware data collection and disease understanding as well as the requirements regarding health service provision in a Smart Cities context. In contrast to existing systems, we provide a cloud-based and requirement-driven reference architecture. The applied methodology can be used for the development, design, and evaluation of other remote and context-aware diagnosis and therapy systems. Considerations of additional aspects regarding cost, methods for data analytics as well as general data security and safety are discussed.",Cloud computing | ESM/EMA | mHealth | MIoT | Smart Cities | Telemedicine,1,1316-1336,Journal,Article,2.0,"Reichenpfader, Daniel;Hanke, Sten",57217286299;56246089700,FH Joanneum,Austria,"insomnia is the most common sleep disorder worldwide. its effects generate economic costs in the millions but could be effectively reduced using digitally provisioned cognitive behavioural therapy. however, traditional acquisition and maintenance of the necessary technical infrastructure requires high financial and personnel expenses. sleep analysis is still mostly done in artificial settings in clinical environments. nevertheless, innovative it infrastructure, such as mhealth and cloud service solutions for home monitoring, are available and allow context-aware service provision following the smart cities paradigm. this paper aims to conceptualise a digital, cloud-based platform with context-aware data storage that supports diagnosis and therapy of non-organic insomnia. in a first step, requirements needed for a remote diagnosis, therapy, and monitoring system are identified. then, the software architecture is drafted based on the above mentioned requirements. lastly, an implementation concept of the software architecture is proposed through selecting and combining eleven cloud computing services. this paper shows how treatment and diagnosis of a common medical issue could be supported effectively and cost-efficiently by utilising state-of-the-art technology. the paper demonstrates the relevance of context-aware data collection and disease understanding as well as the requirements regarding health service provision in a smart cities context. in contrast to existing systems, we provide a cloud-based and requirement-driven reference architecture. the applied methodology can be used for the development, design, and evaluation of other remote and context-aware diagnosis and therapy systems. considerations of additional aspects regarding cost, methods for data analytics as well as general data security and safety are discussed.",requirements and architecture of a cloud based insomnia therapy and diagnosis platform: a smart cities approach
154,2-s2.0-85111879543,10.1007/s11219-021-09564-z,Corrective commit probability: a measure of the effort invested in bug fixing,Amit I.,Software Quality Journal,2021-12-01,"The effort invested in software development should ideally be devoted to the implementation of new features. But some of the effort is invariably also invested in corrective maintenance, that is in fixing bugs. Not much is known about what fraction of software development work is devoted to bug fixing, and what factors affect this fraction. We suggest the Corrective Commit Probability (CCP), which measures the probability that a commit reflects corrective maintenance, as an estimate of the relative effort invested in fixing bugs. We identify corrective commits by applying a linguistic model to the commit messages, achieving an accuracy of 93%, higher than any previously reported model. We compute the CCP of all large active GitHub projects (7,557 projects with 200+ commits in 2019). This leads to the creation of an investment scale, suggesting that the bottom 10% of projects spend less than 6% of their total effort on bug fixing, while the top 10% of projects spend at least 39% of their effort on bug fixing — more than 6 times more. Being a process metric, CCP is conditionally independent of source code metrics, enabling their evaluation and investigation. Analysis of project attributes shows that lower CCP (that is, lower relative investment in bug fixing) is associated with smaller files, lower coupling, use of languages like JavaScript and C# as opposed to PHP and C++, fewer code smells, lower project age, better perceived quality, fewer developers, lower developer churn, better onboarding, and better productivity.",Corrective commits | Corrective maintenance | Effort estimate | Process metric,1,817-861,Journal,Article,2.0,"Amit, Idan;Feitelson, Dror G.",57212083503;7004574688,Hebrew University of Jerusalem;Acumen Labs,Israel;Israel,"the effort invested in software development should ideally be devoted to the implementation of new features. but some of the effort is invariably also invested in corrective maintenance, that is in fixing bugs. not much is known about what fraction of software development work is devoted to bug fixing, and what factors affect this fraction. we suggest the corrective commit probability (ccp), which measures the probability that a commit reflects corrective maintenance, as an estimate of the relative effort invested in fixing bugs. we identify corrective commits by applying a linguistic model to the commit messages, achieving an accuracy of 93%, higher than any previously reported model. we compute the ccp of all large active github projects (7,557 projects with 200+ commits in 2019). this leads to the creation of an investment scale, suggesting that the bottom 10% of projects spend less than 6% of their total effort on bug fixing, while the top 10% of projects spend at least 39% of their effort on bug fixing — more than 6 times more. being a process metric, ccp is conditionally independent of source code metrics, enabling their evaluation and investigation. analysis of project attributes shows that lower ccp (that is, lower relative investment in bug fixing) is associated with smaller files, lower coupling, use of languages like javascript and c# as opposed to php and c++, fewer code smells, lower project age, better perceived quality, fewer developers, lower developer churn, better onboarding, and better productivity.",corrective commit probability: a measure of the effort invested in bug fixing
158,2-s2.0-85119359202,10.1145/3460120.3485351,Demo: Detecting Third-Party Library Problems with Combined Program Analysis,Ntousakis G.,Proceedings of the ACM Conference on Computer and Communications Security,2021-11-12,"Third-party libraries ease the software development process and thus have become an integral part of modern software engineering. Unfortunately, they are not usually vetted by human developers and thus are often responsible for introducing bugs, vulnerabilities, or attacks to programs that will eventually reach end-users. In this demonstration, we present a combined static and dynamic program analysis for inferring and enforcing third-party library permissions in server-side JavaScript. This analysis is centered around a RWX permission system across library boundaries. We demonstrate that our tools can detect zero-day vulnerabilities injected into popular libraries and often missed by state-of-the-art tools such as snyk test and npm audit.",dynamic program analysis | static program analysis,1,2429-2431,Conference Proceeding,Conference Paper,3.0,"Ntousakis, Grigoris;Ioannidis, Sotiris;Vasilakis, Nikos",57282322600;24767420100;57213489278,Technical University of Crete;Massachusetts Institute of Technology,Greece;United States,"third-party libraries ease the software development process and thus have become an integral part of modern software engineering. unfortunately, they are not usually vetted by human developers and thus are often responsible for introducing bugs, vulnerabilities, or attacks to programs that will eventually reach end-users. in this demonstration, we present a combined static and dynamic program analysis for inferring and enforcing third-party library permissions in server-side javascript. this analysis is centered around a rwx permission system across library boundaries. we demonstrate that our tools can detect zero-day vulnerabilities injected into popular libraries and often missed by state-of-the-art tools such as snyk test and npm audit.",demo: detecting third-party library problems with combined program analysis
159,2-s2.0-85116240126,10.1145/3460120.3484535,Preventing Dynamic Library Compromise on Node.js via RWX-Based Privilege Reduction,Vasilakis N.,Proceedings of the ACM Conference on Computer and Communications Security,2021-11-12,"Third-party libraries ease the development of large-scale software systems. However, libraries often execute with significantly more privilege than needed to complete their task. Such additional privilege is sometimes exploited at runtime via inputs passed to a library, even when the library itself is not actively malicious. We present Mir, a system addressing dynamic compromise by introducing a fine-grained read-write-execute (RWX) permission model at the boundaries of libraries: every field of every free variable name in the context of an imported library is governed by a permission set. To help specify the permissions given to existing code, Mir's automated inference generates default permissions by analyzing how libraries are used by their clients. Applied to over 1,000 JavaScript libraries for Node.js, Mir shows practical security (61/63 attacks mitigated), performance (2.1s for static analysis and +1.93% for dynamic enforcement), and compatibility (99.09%) characteristics - -and enables a novel quantification of privilege reduction.",program analysis | supply-chain attacks | third-party libraries,5,1821-1838,Conference Proceeding,Conference Paper,7.0,"Vasilakis, Nikos;Staicu, Cristian Alexandru;Ntousakis, Grigoris;Kallas, Konstantinos;Karel, Ben;Dehon, André;Pradel, Michael",57213489278;57189496858;57282322600;57208337235;55815494100;7004098815;25641744400,CISPA - Helmholtz Center for Information Security;Technical University of Crete;Massachusetts Institute of Technology;Universität Stuttgart;University of Pennsylvania;Aarno Labs LLC,Germany;Greece;United States;Germany;United States;United States,"third-party libraries ease the development of large-scale software systems. however, libraries often execute with significantly more privilege than needed to complete their task. such additional privilege is sometimes exploited at runtime via inputs passed to a library, even when the library itself is not actively malicious. we present mir, a system addressing dynamic compromise by introducing a fine-grained read-write-execute (rwx) permission model at the boundaries of libraries: every field of every free variable name in the context of an imported library is governed by a permission set. to help specify the permissions given to existing code, mir's automated inference generates default permissions by analyzing how libraries are used by their clients. applied to over 1,000 javascript libraries for node.js, mir shows practical security (61/63 attacks mitigated), performance (2.1s for static analysis and +1.93% for dynamic enforcement), and compatibility (99.09%) characteristics - -and enables a novel quantification of privilege reduction.",preventing dynamic library compromise on node.js via rwx-based privilege reduction
161,2-s2.0-85116592180,10.1145/3470482.3479613,Code Complexity Impact of Widgets Accessibility Implementation in JavaScript Open-Source Libraries,Watanabe W.M.,ACM International Conference Proceeding Series,2021-11-05,"Widgets are part of many web applications and implement distinct interaction mechanisms, in reusable user interface components. However, implementing accessible widgets is a challenge, associated to different factors highlighted in the state-of-The-Art, such as: lack of developers knowledge of accessibility guidelines, organization support and tools that support accessible development. This paper reports an investigation on JavaScript source-code complexity impacts of implementing accessibility requirements in widgets. We investigated Dialog, Drop-down menu and Tab widgets of 27 open-source JavaScript libraries. The results showed that widget software artifacts reported an increased average of source-code complexity when implementing accessibility requirements. Results also showed that using DOM-oriented JavaScript libraries (eg. jQuery) significantly increased source-code complexity of widgets. Nevertheless, when using Declarative Component-based JavaScript libraries, no significant difference in source-code complexity was observed. These results suggest that using Declarative Component-based widget libraries might reduce maintainability costs of JavaScript front-end projects.",Accessibility | ARIA | JS Frameworks | JS Libraries | Widgets,0,9-16,Conference Proceeding,Conference Paper,5.0,"Watanabe, Willian Massami;De Lemos, Guilherme;Antonelli, Humberto Lídio;De Mattos Fortes, Renata Pontin;Silva, Gabriel Costa",35180645400;57287933400;57170870600;57217069952;56146593900,Universidade Tecnológica Federal do Paraná;Universidade de São Paulo,Brazil;Brazil,"widgets are part of many web applications and implement distinct interaction mechanisms, in reusable user interface components. however, implementing accessible widgets is a challenge, associated to different factors highlighted in the state-of-the-art, such as: lack of developers knowledge of accessibility guidelines, organization support and tools that support accessible development. this paper reports an investigation on javascript source-code complexity impacts of implementing accessibility requirements in widgets. we investigated dialog, drop-down menu and tab widgets of 27 open-source javascript libraries. the results showed that widget software artifacts reported an increased average of source-code complexity when implementing accessibility requirements. results also showed that using dom-oriented javascript libraries (eg. jquery) significantly increased source-code complexity of widgets. nevertheless, when using declarative component-based javascript libraries, no significant difference in source-code complexity was observed. these results suggest that using declarative component-based widget libraries might reduce maintainability costs of javascript front-end projects.",code complexity impact of widgets accessibility implementation in javascript open-source libraries
166,2-s2.0-85119041599,10.1145/3484272.3484969,Ruggedizing CS1 robotics: Tools and approaches for online teaching,Anderson B.,"SPLASH-E 2021 - Proceedings of the 2021 ACM SIGPLAN International Symposium on SPLASH-E, co-located with SPLASH 2021",2021-10-20,"First-year students benefit from robotics-based programming exercises by learning how to use sensors to gain information on the (changing) world surrounding the robot, how to model this information using data structures, and how to design algorithms for performing meaningful activities. Robotics-based exercises are naturally experiential and team-based and provide among the most memorable teachable moments of first-year programming courses. We summarize the pedagogical challenges that robotics-based exercises face, even under ideal circumstances, and how a university responded to these challenges. We report on the additional challenges faced in late 2020 at the same university as a result of the COVID pandemic, and how the course staff addressed these challenges using programming language implementation and network tools. The crucial components were (1) a custom-built web-based development environment with collaborative features including a built-in compiler, (2) a portable virtual machine, (3) collaborative editing, (4) open source protocols, and (5) peer-to-peer teleconferencing software. We report on the lessons learnt and how to further improve the resilience of robotics-based programming exercises.",educational robotics | learning tools | online robotics | teaching CS1 using robotics,1,82-86,Conference Proceeding,Conference Paper,3.0,"Anderson, Boyd;Henz, Martin;Tee, Hao Wei",57015995500;6602723196;57338071500,National University of Singapore,Singapore,"first-year students benefit from robotics-based programming exercises by learning how to use sensors to gain information on the (changing) world surrounding the robot, how to model this information using data structures, and how to design algorithms for performing meaningful activities. robotics-based exercises are naturally experiential and team-based and provide among the most memorable teachable moments of first-year programming courses. we summarize the pedagogical challenges that robotics-based exercises face, even under ideal circumstances, and how a university responded to these challenges. we report on the additional challenges faced in late 2020 at the same university as a result of the covid pandemic, and how the course staff addressed these challenges using programming language implementation and network tools. the crucial components were (1) a custom-built web-based development environment with collaborative features including a built-in compiler, (2) a portable virtual machine, (3) collaborative editing, (4) open source protocols, and (5) peer-to-peer teleconferencing software. we report on the lessons learnt and how to further improve the resilience of robotics-based programming exercises.",ruggedizing cs1 robotics: tools and approaches for online teaching
171,2-s2.0-85120900990,10.1145/3486609.3487205,HACCLE: Metaprogramming for secure multi-party computation,Bao Y.,"GPCE 2021 - Proceedings of the 20th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences, co-located with SPLASH 2021",2021-10-17,"Cryptographic techniques have the potential to enable distrusting parties to collaborate in fundamentally new ways, but their practical implementation poses numerous challenges. An important class of such cryptographic techniques is known as Secure Multi-Party Computation (MPC). Developing Secure MPC applications in realistic scenarios requires extensive knowledge spanning multiple areas of cryptography and systems. And while the steps to arrive at a solution for a particular application are often straightforward, it remains difficult to make the implementation efficient, and tedious to apply those same steps to a slightly different application from scratch. Hence, it is an important problem to design platforms for implementing Secure MPC applications with minimum effort and using techniques accessible to non-experts in cryptography. In this paper, we present the HACCLE (High Assurance Compositional Cryptography: Languages and Environments) toolchain, specifically targeted to MPC applications. HACCLE contains an embedded domain-specific language Harpoon, for software developers without cryptographic expertise to write MPC-based programs, and uses Lightweight Modular Staging (LMS) for code generation. Harpoon programs are compiled into acyclic circuits represented in HACCLE's Intermediate Representation (HIR) that serves as an abstraction over different cryptographic protocols such as secret sharing, homomorphic encryption, or garbled circuits. Implementations of different cryptographic protocols serve as different backends of our toolchain. The extensible design of HIR allows cryptographic experts to plug in new primitives and protocols to realize computation. And the use of standard metaprogramming techniques lowers the development effort significantly. We have implemented Harpoon and HACCLE, and used them to program interesting applications (e.g., secure auction) and key computation components of Secure MPC applications (e.g., matrix-vector multiplication and merge sort). We show that the performance is improved by using our optimization strategies and heuristics.",domain-specific language | metaprogramming | secure multi-party computation,0,130-143,Conference Proceeding,Conference Paper,20.0,"Bao, Yuyan;Sundararajah, Kirshanthan;Malik, Raghav;Ye, Qianchuan;Wagner, Christopher;Jaber, Nouraldin;Wang, Fei;Ameri, Mohammad Hassan;Lu, Donghang;Seto, Alexander;Delaware, Benjamin;Samanta, Roopsha;Kate, Aniket;Garman, Christina;Blocki, Jeremiah;Letourneau, Pierre David;Meister, Benoit;Springer, Jonathan;Rompf, Tiark;Kulkarni, Milind",57221145211;57190169819;57221150655;57205699980;57218449042;57191596444;57199324163;57191966357;57210553276;57223049086;35742891200;15078227900;23397437100;36880338300;36240369100;37064829700;22433557500;57191318763;35107892800;8685521300,University of Waterloo;Purdue University;Reservoir Labs,Canada;United States;United States,"cryptographic techniques have the potential to enable distrusting parties to collaborate in fundamentally new ways, but their practical implementation poses numerous challenges. an important class of such cryptographic techniques is known as secure multi-party computation (mpc). developing secure mpc applications in realistic scenarios requires extensive knowledge spanning multiple areas of cryptography and systems. and while the steps to arrive at a solution for a particular application are often straightforward, it remains difficult to make the implementation efficient, and tedious to apply those same steps to a slightly different application from scratch. hence, it is an important problem to design platforms for implementing secure mpc applications with minimum effort and using techniques accessible to non-experts in cryptography. in this paper, we present the haccle (high assurance compositional cryptography: languages and environments) toolchain, specifically targeted to mpc applications. haccle contains an embedded domain-specific language harpoon, for software developers without cryptographic expertise to write mpc-based programs, and uses lightweight modular staging (lms) for code generation. harpoon programs are compiled into acyclic circuits represented in haccle's intermediate representation (hir) that serves as an abstraction over different cryptographic protocols such as secret sharing, homomorphic encryption, or garbled circuits. implementations of different cryptographic protocols serve as different backends of our toolchain. the extensible design of hir allows cryptographic experts to plug in new primitives and protocols to realize computation. and the use of standard metaprogramming techniques lowers the development effort significantly. we have implemented harpoon and haccle, and used them to program interesting applications (e.g., secure auction) and key computation components of secure mpc applications (e.g., matrix-vector multiplication and merge sort). we show that the performance is improved by using our optimization strategies and heuristics.",haccle: metaprogramming for secure multi-party computation
173,2-s2.0-85119063881,10.1145/3486949.3486965,Towards the no-code era: A vision and plan for the future of software development,Elbatanony A.,"BCNC 2021 - Proceedings of the 1st ACM SIGPLAN International Workshop on Beyond Code: No Code, co-located with SPLASH 2021",2021-10-17,"This paper provides a highly opinionated and biased vision and a two-stage plan with guidelines to reach a new era of software development, where anyone can create software without bothering to write code. Moreover, this paper explores in depth the first of these stages, which consists of creating a no-code tool based on six principles: configuration driven development, APIs, open-source, cross-platform, cloud computing, and design systems. An examination of each principle is presented and a case is made for why such a combination of principles would lay the foundation for future development efforts. Possible enquiries are addressed and a path is laid out for future works.",API | Cloud Computing | Configuration Driven Development | Cross-platform | Design Systems | No-code | Open-source,1,29-35,Conference Proceeding,Conference Paper,2.0,"Elbatanony, Ahmed;Succi, Giancarlo",57337760400;7004757466,Innopolis University,Russian Federation,"this paper provides a highly opinionated and biased vision and a two-stage plan with guidelines to reach a new era of software development, where anyone can create software without bothering to write code. moreover, this paper explores in depth the first of these stages, which consists of creating a no-code tool based on six principles: configuration driven development, apis, open-source, cross-platform, cloud computing, and design systems. an examination of each principle is presented and a case is made for why such a combination of principles would lay the foundation for future development efforts. possible enquiries are addressed and a path is laid out for future works.",towards the no-code era: a vision and plan for the future of software development
175,2-s2.0-85118201484,10.1145/3472749.3474819,Ten Million Users and Ten Years Later: Python Tutor's Design Guidelines for Building Scalable and Sustainable Research Software in Academia,Guo P.,UIST 2021 - Proceedings of the 34th Annual ACM Symposium on User Interface Software and Technology,2021-10-10,"Research software is often built as prototypes that never get widespread usage and are left unmaintained after a few papers get published. To counteract this trend, we propose a method for building research software with scale and sustainability in mind so that it can organically grow a large userbase and enable longer-term research. To illustrate this method, we present the design and implementation of Python Tutor (pythontutor.com), a code visualization tool that is, to our knowledge, one of the most widely-used pieces of research software developed within a university lab. Over the past decade, it has been used by over ten million people in over 180 countries. It has also contributed to 55 publications from 35 research groups in 13 countries. We distilled lessons from working on Python Tutor into three sets of design guidelines: 1) user experience design for scale and sustainability, 2) software architecture design for long-term sustainability, and 3) designing a sustainable software development workflow within academia. These guidelines can enable a student to create long-lasting software that reaches many users and facilitates research from many independent groups.",code visualization | Python Tutor | research software | sustainability,2,1235-1251,Conference Proceeding,Conference Paper,1.0,"Guo, Philip",16238467300,"University of California, San Diego",United States,"research software is often built as prototypes that never get widespread usage and are left unmaintained after a few papers get published. to counteract this trend, we propose a method for building research software with scale and sustainability in mind so that it can organically grow a large userbase and enable longer-term research. to illustrate this method, we present the design and implementation of python tutor (pythontutor.com), a code visualization tool that is, to our knowledge, one of the most widely-used pieces of research software developed within a university lab. over the past decade, it has been used by over ten million people in over 180 countries. it has also contributed to 55 publications from 35 research groups in 13 countries. we distilled lessons from working on python tutor into three sets of design guidelines: 1) user experience design for scale and sustainability, 2) software architecture design for long-term sustainability, and 3) designing a sustainable software development workflow within academia. these guidelines can enable a student to create long-lasting software that reaches many users and facilitates research from many independent groups.",ten million users and ten years later: python tutor's design guidelines for building scalable and sustainable research software in academia
176,2-s2.0-85119962367,10.5194/isprs-annals-VIII-4-W2-2021-13-2021,USER EVALUATION of INTERACTIVE THEMATIC 3D CITY MODELS - APPLICATION of ASYNCHRONOUS REMOTE TESTING METHOD,Herman L.,"ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences",2021-10-07,"Asynchronous remote usability testing is a method based on a software platform used to automatically record test participants' activities when they interact with a given product in their natural environment, for example, at home. This method has been frequently used in previous decades in web design and mobile application development but has rarely been utilised in geovisualization. The importance of remote usability testing has rapidly increased in 2021 due to the COVID-19 pandemic. The 3DmoveR (3D Movement and Interaction Recorder) application was used for asynchronous remote testing presented in this paper. 3DmoveR is a research tool designed for user testing of interactive 3D visualizations in web browsers using open technologies such as PHP, JavaScript, and the Three.js library. This study focuses on an evaluation of interactive 3D city models presenting thematic information expressed by colour scale. An experiment was designed as a within-subject study consisting of two simple questionnaires, a training task and six experimental trials. Finding a building of a given category (depicted as building colour) within an interactive 3D city model was used as the experimental task. Speed and accuracy of user performances were recorded, as well as user strategy, subjective evaluations, and possible intervening variables. The results were recorded from 110 participants, where 76 of them were correct and analysed further. It can be concluded that the tested colour scale (based on the Energy Performance Certificate) was not entirely appropriate. We further analysed and discussed intervening variables that may affect remote usability testing of 3D visualizations.",3D city model | 3D geovisualization | 3DmoveR | Asynchronous remote testing | Non-photorealistic visualization | Usability testing | User logging,0,13-20,Conference Proceeding,Conference Paper,1.0,"Herman, L.",55864650200,Masaryk University,Czech Republic,"asynchronous remote usability testing is a method based on a software platform used to automatically record test participants' activities when they interact with a given product in their natural environment, for example, at home. this method has been frequently used in previous decades in web design and mobile application development but has rarely been utilised in geovisualization. the importance of remote usability testing has rapidly increased in 2021 due to the covid-19 pandemic. the 3dmover (3d movement and interaction recorder) application was used for asynchronous remote testing presented in this paper. 3dmover is a research tool designed for user testing of interactive 3d visualizations in web browsers using open technologies such as php, javascript, and the three.js library. this study focuses on an evaluation of interactive 3d city models presenting thematic information expressed by colour scale. an experiment was designed as a within-subject study consisting of two simple questionnaires, a training task and six experimental trials. finding a building of a given category (depicted as building colour) within an interactive 3d city model was used as the experimental task. speed and accuracy of user performances were recorded, as well as user strategy, subjective evaluations, and possible intervening variables. the results were recorded from 110 participants, where 76 of them were correct and analysed further. it can be concluded that the tested colour scale (based on the energy performance certificate) was not entirely appropriate. we further analysed and discussed intervening variables that may affect remote usability testing of 3d visualizations.",user evaluation of interactive thematic 3d city models - application of asynchronous remote testing method
179,2-s2.0-85117905603,10.1145/3478384.3478425,A technological and methodological ecosystem for dynamic virtual acoustics in telematic performance contexts,Hoy R.,ACM International Conference Proceeding Series,2021-09-01,"This paper presents the design and development of a technological ecosystem which facilitates research at the intersection of Virtual Acoustics, Networking, and Telematic Music. Building upon existing robust software packages, we integrate and extend this work in the context of exploring the effect of telematically-shared dynamic virtual acoustic spaces and expressive movement trajectories of player sound source positions upon live play contexts. Through analysis of impulse responses generated by a distributable measurement kit, remote players are able to share these spaces with their collaborators. Supplementary tools developed as part of this research also extend established telematic software solutions, allowing for easier use of network based musical communication systems for both performers and technicians. A network topology of interconnected telematic solutions is described, allowing flexibility between various internet based audio platforms. Applications which challenge and contain these developments are discussed, including a large-scale musical ensemble, web based musical performance, and an ongoing study into collaborative telematic improvisation.",Spatialization | Telematic music | Virtual acoustics,0,169-174,Conference Proceeding,Conference Paper,2.0,"Hoy, Rory;Van Nort, Doug",57222609990;36009202200,York University,Canada,"this paper presents the design and development of a technological ecosystem which facilitates research at the intersection of virtual acoustics, networking, and telematic music. building upon existing robust software packages, we integrate and extend this work in the context of exploring the effect of telematically-shared dynamic virtual acoustic spaces and expressive movement trajectories of player sound source positions upon live play contexts. through analysis of impulse responses generated by a distributable measurement kit, remote players are able to share these spaces with their collaborators. supplementary tools developed as part of this research also extend established telematic software solutions, allowing for easier use of network based musical communication systems for both performers and technicians. a network topology of interconnected telematic solutions is described, allowing flexibility between various internet based audio platforms. applications which challenge and contain these developments are discussed, including a large-scale musical ensemble, web based musical performance, and an ongoing study into collaborative telematic improvisation.",a technological and methodological ecosystem for dynamic virtual acoustics in telematic performance contexts
180,2-s2.0-85117903868,10.1145/3478384.3478426,Streaaam: A fully automated experimental audio streaming server,Hollerweger F.,ACM International Conference Proceeding Series,2021-09-01,"Streaaam is a fully automated experimental audio streaming server, built from Free/Libre Open Source Software in a higher education context. Some of its features include an automatic synthesized-speech moderator; real-time data integration via web APIs; and automatic loading and playing of generative music patches in Pd, SuperCollider, and Csound. These features are creatively combined in our stream's program, such as in the form of a robot comedy show. Streaaam was conceived of and continues to be developed as a pedagogical vehicle in the context of an undergraduate education in audio arts, music technology, and sound design. Its goals are to inspire students to work creatively in the sonic arts, to introduce them to the development of audio applications for the web, and to showcase student art works at our department and college. This paper discusses the project's technical implementation, our software development and program curation cycles, pedagogical experiences with the project thus far, and plans for future work.",Audio streaming | FLOSS | Music technology | Sonic arts | Sound design,0,161-168,Conference Proceeding,Conference Paper,1.0,"Hollerweger, Florian",36617235000,Columbia College Chicago,United States,"streaaam is a fully automated experimental audio streaming server, built from free/libre open source software in a higher education context. some of its features include an automatic synthesized-speech moderator; real-time data integration via web apis; and automatic loading and playing of generative music patches in pd, supercollider, and csound. these features are creatively combined in our stream's program, such as in the form of a robot comedy show. streaaam was conceived of and continues to be developed as a pedagogical vehicle in the context of an undergraduate education in audio arts, music technology, and sound design. its goals are to inspire students to work creatively in the sonic arts, to introduce them to the development of audio applications for the web, and to showcase student art works at our department and college. this paper discusses the project's technical implementation, our software development and program curation cycles, pedagogical experiences with the project thus far, and plans for future work.",streaaam: a fully automated experimental audio streaming server
182,2-s2.0-85114301091,10.11591/ijeecs.v23.i3.pp1357-1365,WISE game: wireless interactive software educational game,Ruiz M.F.L.,Indonesian Journal of Electrical Engineering and Computer Science,2021-09-01,"This study presents the development of a wireless, interactive, educational (WISE) game that incorporates the use of smartphones for reviewing lessons that might suit the standards of the Philippine government's education department. It is easier today to engage students using digital platforms for education using interactive digital games. In this study, the users can play the game by connecting the smartphones to the prototype through wireless local area network. It consists of two types of cards: Power cards which contribute excitement to the game, and question cards which contain questions to be answered by the players. The prototype is an integration of the following components: Raspberry Pi 3B, RFID reader and cards, and speakers. A graphical user interface where the players interact with the game was created using scripting languages, such as PHP, and JavaScript. The project was evaluated by different grade school students of Metro Manila, Philippines. The results of users' evaluation show that the prototype is accessible and effective for use based on functionality and that the project can also serve as a tool for lesson reviews. Future development of WISE game includes its integration and compatibility to different operating systems with larger databases and accessibility.",Gamification Microcontroller Raspberry Pi 3 Smartphone WLAN,0,1357-1365,Journal,Article,6.0,"Ruiz, Muel Fred L.;Esclada, Rica I.;Balderama, Jannica H.;Aguirre, Anzel Anne I.;Cutin, Ma Nancy I.;Lozada, Raymund M.",57188876832;57247915500;57247698600;57247484400;57247484500;57248136600,Technological University of the Philippines,Philippines,"this study presents the development of a wireless, interactive, educational (wise) game that incorporates the use of smartphones for reviewing lessons that might suit the standards of the philippine government's education department. it is easier today to engage students using digital platforms for education using interactive digital games. in this study, the users can play the game by connecting the smartphones to the prototype through wireless local area network. it consists of two types of cards: power cards which contribute excitement to the game, and question cards which contain questions to be answered by the players. the prototype is an integration of the following components: raspberry pi 3b, rfid reader and cards, and speakers. a graphical user interface where the players interact with the game was created using scripting languages, such as php, and javascript. the project was evaluated by different grade school students of metro manila, philippines. the results of users' evaluation show that the prototype is accessible and effective for use based on functionality and that the project can also serve as a tool for lesson reviews. future development of wise game includes its integration and compatibility to different operating systems with larger databases and accessibility.",wise game: wireless interactive software educational game
183,2-s2.0-85114145485,10.14393/RBCV73N3-57625,WebMap: Web map development by a QGIS complement,Amorim F.R.,Revista Brasileira de Cartografia,2021-09-01,"This work aims to describe the construction process and the validation of a plugin / tool in Geographic Information Systems (GIS), used for the development of Web maps. For this, the WebMapa plugin, still under development, allows adding cartographic elements to Web pages, making them interactive and adaptable. The GIS was built as a complement (WebMapa plugin) to the QGIS software, using a python programming language. The pluginwas developed as a search engine that allows users to choose information and map elements, as well as symbolize them. The options made possible the choices of the following map elements: cartographic base (eg: OpenStreetMap, Google Maps); compass; scale; user's location on the map; screen editing; route calculation between starting and ending points. The result of the processing of the WebMapa plugin was built as a website available in the .html output format (HTML - Hypertext Markup Language). In this way, the system becomes multiplatform since it can be accessed as a Website in any type of Web browser, regardless of the operating system.",Geographic Information Systems (GIS) | QGIS | Web maps,0,842-854,Journal,Article,2.0,"Amorim, Fabrício Rosa;Reolon Schmidt, Marcio Augusto",57218884300;39962579200,Universidade Federal do Parana,Brazil,"this work aims to describe the construction process and the validation of a plugin / tool in geographic information systems (gis), used for the development of web maps. for this, the webmapa plugin, still under development, allows adding cartographic elements to web pages, making them interactive and adaptable. the gis was built as a complement (webmapa plugin) to the qgis software, using a python programming language. the pluginwas developed as a search engine that allows users to choose information and map elements, as well as symbolize them. the options made possible the choices of the following map elements: cartographic base (eg: openstreetmap, google maps); compass; scale; user's location on the map; screen editing; route calculation between starting and ending points. the result of the processing of the webmapa plugin was built as a website available in the .html output format (html - hypertext markup language). in this way, the system becomes multiplatform since it can be accessed as a website in any type of web browser, regardless of the operating system.",webmap: web map development by a qgis complement
186,2-s2.0-85104832376,10.1007/s10257-021-00530-7,A global virtual team model to improve software development collaboration project,Iyamu T.,Information Systems and e-Business Management,2021-09-01,"Increasingly, universities across the globe are involved in collaborations at both national and international levels. In a nutshell, the collaborations are intended to expose students and academia to different environments, to facilitate enhanced teaching and learning, and research activities. However, many of the collaborative initiatives have not been successful, particularly at international level. This can be attributed to many factors, which are either unknown or too complex to address by the drivers of collaborations in many universities and countries. As a result, various approaches such as physical exchange of materials and humans (students, professors, and other university staff) have been adopted over the years, yet the success rate has not improved. The objective of this research was to develop a model, which can be used to guide an understanding of how to employ global virtual teams for university’s collaborations. The qualitative methods from the perspectives of the interpretive stance and inductive approach were employed. Data were gathered from literature, and an existing collaboration, which involves universities from three different continents, Africa, Europe and North America. The data were analysed following the hermeneutics technique, from the interpretivist perspective. From the analysis, we found three sets of factors: human sphere, collaborative activity and technology artefacts as the main facilitators and influence on universities collaborations. Based on the findings, a global virtual team model was developed, which can be useful in guiding and advancing the way in which team members interact and enable activities of collaborations between universities, and company as well.",Global virtual team | Information technology | Qualitative methods | University collaboration,0,937-956,Journal,Article,2.0,"Iyamu, Tiko;Adelakun, Olayele",35146149500;27567521300,DePaul University;Cape Peninsula University of Technology,United States;South Africa,"increasingly, universities across the globe are involved in collaborations at both national and international levels. in a nutshell, the collaborations are intended to expose students and academia to different environments, to facilitate enhanced teaching and learning, and research activities. however, many of the collaborative initiatives have not been successful, particularly at international level. this can be attributed to many factors, which are either unknown or too complex to address by the drivers of collaborations in many universities and countries. as a result, various approaches such as physical exchange of materials and humans (students, professors, and other university staff) have been adopted over the years, yet the success rate has not improved. the objective of this research was to develop a model, which can be used to guide an understanding of how to employ global virtual teams for university’s collaborations. the qualitative methods from the perspectives of the interpretive stance and inductive approach were employed. data were gathered from literature, and an existing collaboration, which involves universities from three different continents, africa, europe and north america. the data were analysed following the hermeneutics technique, from the interpretivist perspective. from the analysis, we found three sets of factors: human sphere, collaborative activity and technology artefacts as the main facilitators and influence on universities collaborations. based on the findings, a global virtual team model was developed, which can be useful in guiding and advancing the way in which team members interact and enable activities of collaborations between universities, and company as well.",a global virtual team model to improve software development collaboration project
187,2-s2.0-85115694764,10.1109/ICSIMA50015.2021.9525935,AppsGoolee: A Cognitive Brain- Training App Games As A Powerful Thinking Tool,Mansor Z.,"2021 IEEE 7th International Conference on Smart Instrumentation, Measurement and Applications, ICSIMA 2021",2021-08-23,"Cognitive brain-training games can stimulate a child's interest in learning and encourage and increase linguistic development, critical thinking, emotional advancement, brainpower, and creativity. Cognitive brain-training apps games could be seen as having an essential role in a child's development specifically. This work aims to improve and increase user participation by making the board game more appealing and exciting. The traditional Boardgame Goolee is transformed into an app game based on an ultra-affordable and modular IoT software development. Complete design of the AppsGoolee system is developed using software design based on Unity Editor 2017, Microsoft Visual Studio code editor, C#, JavaScript programming language and Android KitKat 4.4. The app is implemented for Android platform. The 3rd party Services integrates with Google Game Service for accessing the world leaderboard and online personal achievement. AppsGoolee is designed and created as a stimulator to activate the neurons by their specific function that links games, training, and high-level thinking skills. The app element moves the pieces in the allotted time and accuracy without deviating from the path. This app has no expiration date. It provides a platform for single player as well as multiplayer games and caters across any languages, traditions, and nations, for national and international at any background. The game is divided into three categories: easy, medium, and hard depending on the difficulty level, wherein each category consists of 20 levels. Games performance is monitored and listed on the scoreboard known as Goolee Leaderboard to analyze the game pace at each level to improve the game's strategy and solve the puzzles faster and efficiently. AppsGoole has broad potential in commercial inability as this product is tested at any level of people, including at schools, universities, and companies. AppsGoolee challenges human skills and intelligence in problem-solving and decision-making. It has identified the facts and constraints, developed analytical skills and possible solutions, and the elements of focus, concentration, and mind speed. Thus, the higher-order thinking skills can be achieved.",Android | Apps | AppsGoolee | Brain-training | Cognitive | Game,0,215-220,Conference Proceeding,Conference Paper,4.0,"Mansor, Zuhanis;Ahmad, Kamarulzzaman;Amin, Azzan;Anwar, Hayatul Nabihah Khairul",55263707000;57271500400;57271088700;57271917600,Universiti Kuala Lumpur,Malaysia,"cognitive brain-training games can stimulate a child's interest in learning and encourage and increase linguistic development, critical thinking, emotional advancement, brainpower, and creativity. cognitive brain-training apps games could be seen as having an essential role in a child's development specifically. this work aims to improve and increase user participation by making the board game more appealing and exciting. the traditional boardgame goolee is transformed into an app game based on an ultra-affordable and modular iot software development. complete design of the appsgoolee system is developed using software design based on unity editor 2017, microsoft visual studio code editor, c#, javascript programming language and android kitkat 4.4. the app is implemented for android platform. the 3rd party services integrates with google game service for accessing the world leaderboard and online personal achievement. appsgoolee is designed and created as a stimulator to activate the neurons by their specific function that links games, training, and high-level thinking skills. the app element moves the pieces in the allotted time and accuracy without deviating from the path. this app has no expiration date. it provides a platform for single player as well as multiplayer games and caters across any languages, traditions, and nations, for national and international at any background. the game is divided into three categories: easy, medium, and hard depending on the difficulty level, wherein each category consists of 20 levels. games performance is monitored and listed on the scoreboard known as goolee leaderboard to analyze the game pace at each level to improve the game's strategy and solve the puzzles faster and efficiently. appsgoole has broad potential in commercial inability as this product is tested at any level of people, including at schools, universities, and companies. appsgoolee challenges human skills and intelligence in problem-solving and decision-making. it has identified the facts and constraints, developed analytical skills and possible solutions, and the elements of focus, concentration, and mind speed. thus, the higher-order thinking skills can be achieved.",appsgoolee: a cognitive brain- training app games as a powerful thinking tool
188,2-s2.0-85113871036,10.1145/3472672.3473952,Using an agent-based approach for robust automated testing of computer games,Shirzadehhajimahmood S.,"A-TEST 2021 - Proceedings of the 12th International Workshop on Automating TEST Case Design, Selection, and Evaluation, co-located with ESEC/FSE 2021",2021-08-23,"Modern computer games typically have a huge interaction spaces and non-deterministic environments. Automation in testing can provide a vital boost in development and it further improves the overall software's reliability and efficiency. Moreover, layout and game logic may regularly change during development or consecutive releases which makes it difficult to test because the usage of the system continuously changes. To deal with the latter, tests also need to be robust. Unfortunately, existing game testing approaches are not capable of maintaining test robustness. To address these challenges, this paper presents an agent-based approach for robust automated testing based on the reasoning type of AI.",agent-based automated testing | automated testing of computer games | Robust automated testing,1,1-8,Conference Proceeding,Conference Paper,5.0,"Shirzadehhajimahmood, Samira;Prasetya, I. S.W.B.;Dignum, Frank;Dastani, Mehdi;Keller, Gabriele",57220114778;8980537400;7003423512;6603932250;7201829632,Umeå Universitet;Universiteit Utrecht,Sweden;Netherlands,"modern computer games typically have a huge interaction spaces and non-deterministic environments. automation in testing can provide a vital boost in development and it further improves the overall software's reliability and efficiency. moreover, layout and game logic may regularly change during development or consecutive releases which makes it difficult to test because the usage of the system continuously changes. to deal with the latter, tests also need to be robust. unfortunately, existing game testing approaches are not capable of maintaining test robustness. to address these challenges, this paper presents an agent-based approach for robust automated testing based on the reasoning type of ai.",using an agent-based approach for robust automated testing of computer games
189,2-s2.0-85116259826,10.1145/3468264.3468625,Probabilistic Delta debugging,Wang G.,ESEC/FSE 2021 - Proceedings of the 29th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,2021-08-20,"The delta debugging problem concerns how to reduce an object while preserving a certain property, and widely exists in many applications, such as compiler development, regression fault localization, and software debloating. Given the importance of delta debugging, multiple algorithms have been proposed to solve the delta debugging problem efficiently and effectively. However, the efficiency and effectiveness of the state-of-the-art algorithms are still not satisfactory. For example, the state-of-the-art delta debugging tool, CHISEL, may take up to 3 hours to reduce a single program with 14,092 lines of code, while the reduced program may be up to 2 times unnecessarily large. In this paper, we propose a probabilistic delta debugging algorithm (named ProbDD) to improve the efficiency and the effectiveness of delta debugging. Our key insight is, the ddmin algorithm, the basic algorithm upon which many existing approaches are built, follows a predefined sequence of attempts to remove elements from a sequence, and fails to utilize the information from existing test results. To address this problem, ProbDD builds a probabilistic model to estimate the probabilities of the elements to be kept in the produced result, selects a set of elements to maximize the gain of the next test based on the model, and improves the model based on the test results. We prove the correctness of ProbDD, and analyze the minimality of its result and the asymptotic number of tests under the worst case. The asymptotic number of tests in the worst case of ProbDD is O(n), which is smaller than that of ddmin, O(n2) worst-case asymptotic number of tests. Furthermore, we experimentally compared ProbDD with ddmin on 40 subjects in HDD and CHISEL, two approaches that wrap ddmin for reducing trees and C programs, respectively. The results show that, after replacing ddmin with ProbDD, HDD and CHISEL produce 59.48% and 11.51% smaller results and use 63.22% and 45.27% less time, respectively.",Delta Debugging | Probabilistic Model,1,881-892,Conference Proceeding,Conference Paper,5.0,"Wang, Guancheng;Shen, Ruobing;Chen, Junjie;Xiong, Yingfei;Zhang, Lu",57205247231;57218169244;57145642900;35744243000;57249630800,Tianjin University;Peking University,China;China,"the delta debugging problem concerns how to reduce an object while preserving a certain property, and widely exists in many applications, such as compiler development, regression fault localization, and software debloating. given the importance of delta debugging, multiple algorithms have been proposed to solve the delta debugging problem efficiently and effectively. however, the efficiency and effectiveness of the state-of-the-art algorithms are still not satisfactory. for example, the state-of-the-art delta debugging tool, chisel, may take up to 3 hours to reduce a single program with 14,092 lines of code, while the reduced program may be up to 2 times unnecessarily large. in this paper, we propose a probabilistic delta debugging algorithm (named probdd) to improve the efficiency and the effectiveness of delta debugging. our key insight is, the ddmin algorithm, the basic algorithm upon which many existing approaches are built, follows a predefined sequence of attempts to remove elements from a sequence, and fails to utilize the information from existing test results. to address this problem, probdd builds a probabilistic model to estimate the probabilities of the elements to be kept in the produced result, selects a set of elements to maximize the gain of the next test based on the model, and improves the model based on the test results. we prove the correctness of probdd, and analyze the minimality of its result and the asymptotic number of tests under the worst case. the asymptotic number of tests in the worst case of probdd is o(n), which is smaller than that of ddmin, o(n2) worst-case asymptotic number of tests. furthermore, we experimentally compared probdd with ddmin on 40 subjects in hdd and chisel, two approaches that wrap ddmin for reducing trees and c programs, respectively. the results show that, after replacing ddmin with probdd, hdd and chisel produce 59.48% and 11.51% smaller results and use 63.22% and 45.27% less time, respectively.",probabilistic delta debugging
190,2-s2.0-85116195970,10.1145/3468264.3473920,Generating metamorphic relations for cyber-physical systems with genetic programming: An industrial case study,Ayerdi J.,ESEC/FSE 2021 - Proceedings of the 29th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,2021-08-20,"One of the major challenges in the verification of complex industrial Cyber-Physical Systems is the difficulty of determining whether a particular system output or behaviour is correct or not, the so-called test oracle problem. Metamorphic testing alleviates the oracle problem by reasoning on the relations that are expected to hold among multiple executions of the system under test, which are known as Metamorphic Relations (MRs). However, the development of effective MRs is often challenging and requires the involvement of domain experts. In this paper, we present a case study aiming at automating this process. To this end, we implemented GAssertMRs, a tool to automatically generate MRs with genetic programming. We assess the cost-effectiveness of this tool in the context of an industrial case study from the elevation domain. Our experimental results show that in most cases GAssertMRs outperforms the other baselines, including manually generated MRs developed with the help of domain experts. We then describe the lessons learned from our experiments and we outline the future work for the adoption of this technique by industrial practitioners.",cyber physical systems | evolutionary algorithm | genetic programming | metamorphic testing | mutation testing | oracle generation | oracle improvement | quality of service,4,1264-1274,Conference Proceeding,Conference Paper,6.0,"Ayerdi, Jon;Terragni, Valerio;Arrieta, Aitor;Tonella, Paolo;Sagardui, Goiuria;Arratibel, Maite",57211242935;57022047600;56514865400;7003489194;13104721400;57219568384,Mondragon Unibertsitatea;The University of Auckland;USI Lugano;Orona,Spain;New Zealand;Switzerland;Spain,"one of the major challenges in the verification of complex industrial cyber-physical systems is the difficulty of determining whether a particular system output or behaviour is correct or not, the so-called test oracle problem. metamorphic testing alleviates the oracle problem by reasoning on the relations that are expected to hold among multiple executions of the system under test, which are known as metamorphic relations (mrs). however, the development of effective mrs is often challenging and requires the involvement of domain experts. in this paper, we present a case study aiming at automating this process. to this end, we implemented gassertmrs, a tool to automatically generate mrs with genetic programming. we assess the cost-effectiveness of this tool in the context of an industrial case study from the elevation domain. our experimental results show that in most cases gassertmrs outperforms the other baselines, including manually generated mrs developed with the help of domain experts. we then describe the lessons learned from our experiments and we outline the future work for the adoption of this technique by industrial practitioners.",generating metamorphic relations for cyber-physical systems with genetic programming: an industrial case study
191,2-s2.0-85118586703,10.5194/isprs-archives-XLVI-4-W2-2021-97-2021,CIUDAD LIMPIA VALDIVIA: A MOBILE and WEB BASED SMART SOLUTION BASED on FOSS TECHNOLOGY to SUPPORT MUNICIPAL and HOUSEHOLD WASTE COLLECTION,Lühr Sierra D.V.,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",2021-08-19,"Ciudad Limpia Valdivia is a Web and Mobile application which attempts to tackle some of the Municipality of Valdivia in Chile's waste collection issues. It is based on Free and Open Source Software and it is currently in the last stage of prototyping. The tool is expected to improve the communication between the users and the service provider. It also has educational materials about waste management and other related environmental issues to guide the users to minimize the waste production and optimize the way it is handled before it is collected. The main features of the solution are: a dynamic map viewer showing the position of the Municipality's waste collection trucks and estimated future trajectories, a form to report illegal dumping microsites, notifications from the Municipality about the status of the service, educational content and contact list of other independent initiatives related to waste collection. The potential impact of the tool was evaluated on the city's test pilot sector by means of a neighbourhood survey. It showed that the solution might have a positive impact in the coordination in terms of the service operation. The estimation of the trucks' future trajectory will be developed using machine learning or computational intelligence algorithms. The integration of FOSS technologies has been essential to address challenges found during development as well as to adapt the tool to new scenarios. The feedback from the Municipality and the community has proved to be very important to define a concrete solution.",Circular economy | Community participation | Free and Open Source Software | Mobile app | Smart city | Waste collection | Waste management system | Web app,0,97-102,Conference Proceeding,Conference Paper,4.0,"Lühr Sierra, Daniel V.;Balinos, Marygrace;Gatica, José;Lagomarsino, Camila",53869309900;57195518459;57325017100;57324828300,Universidad Austral de Chile,Chile,"ciudad limpia valdivia is a web and mobile application which attempts to tackle some of the municipality of valdivia in chile's waste collection issues. it is based on free and open source software and it is currently in the last stage of prototyping. the tool is expected to improve the communication between the users and the service provider. it also has educational materials about waste management and other related environmental issues to guide the users to minimize the waste production and optimize the way it is handled before it is collected. the main features of the solution are: a dynamic map viewer showing the position of the municipality's waste collection trucks and estimated future trajectories, a form to report illegal dumping microsites, notifications from the municipality about the status of the service, educational content and contact list of other independent initiatives related to waste collection. the potential impact of the tool was evaluated on the city's test pilot sector by means of a neighbourhood survey. it showed that the solution might have a positive impact in the coordination in terms of the service operation. the estimation of the trucks' future trajectory will be developed using machine learning or computational intelligence algorithms. the integration of foss technologies has been essential to address challenges found during development as well as to adapt the tool to new scenarios. the feedback from the municipality and the community has proved to be very important to define a concrete solution.",ciudad limpia valdivia: a mobile and web based smart solution based on foss technology to support municipal and household waste collection
194,2-s2.0-85123791935,10.1145/3484824.3484875,Career Counseling Chatbot on Facebook Messenger using AI,Suresh N.,ACM International Conference Proceeding Series,2021-08-09,"Increasingly we observe that newly graduated university students struggle to find employment, often ending up in fields completely different from those that they studied in, and employees reporting low levels of satisfaction in the careers that they choose. One of the reasons for this could be a lack of adequate, useful career guidance when an individual is in university or recently graduated. Chatbots are useful resources and a topic of interest in the realm of Computer Science and AI for their ability to mimic experts in different applications, as well as being able to replicate human interaction to varying degrees. Research suggests that the use of a chatbot in offering career counseling can serve as an efficient means to provide this useful service in environments where a dedicated career counsellor may not be available. A lack of appropriate, adequate career counseling means youth may wind up pursuing careers that are chosen for them by their parents or only chosen for the promise of high salaries. These decisions may be made without taking into consideration whether or not they align with the individual's interests and values. This can lead to feelings of dissatisfaction in one's career, which is detrimental not only to the wellbeing of the individual but also to the overall productivity of the business in which they are hired. Hence, the development of the chatbot will better inform users, assisting them in the ways of choosing a career. This will allow them to consider careers they may not have thought available to them, that would be more fulfilling and satisfactory than one that does not align with their interests. This research adopted both Research methodology and Software Development methodology. Under Research Methodology, a survey was conducted to gather information about individuals' opinions regarding their possible career choices, and what types of career advice they would like to receive from the system. In addition, the latest research on career guidance was considered in forming the basis of the questions asked. This information was used in chatbot system development on the Facebook Messenger platform, using tools such as the Facebook SDK, the Messenger Platform APIs, and JavaScript, and the Wit.ai API which enables the use of Natural Language Processing, which is a use case of AI techniques. The chatbot understands user input and give relevant and appropriate responses, reliably and in real-time. In conclusion, the results obtained are hoped to result in positive proclivity towards adopting the system, thus serving as a useful asset to any universities or institutions that might wish to utilize it.",Career Counseling | Chatbot | Natural language Processing,0,65-73,Conference Proceeding,Conference Paper,5.0,"Suresh, Nalina;Mukabe, Nkandu;Hashiyana, Valerianus;Limbo, Anton;Hauwanga, Aina",57102961000;57432935700;57201067320;57201062446;57433078900,University of Namibia,Namibia,"increasingly we observe that newly graduated university students struggle to find employment, often ending up in fields completely different from those that they studied in, and employees reporting low levels of satisfaction in the careers that they choose. one of the reasons for this could be a lack of adequate, useful career guidance when an individual is in university or recently graduated. chatbots are useful resources and a topic of interest in the realm of computer science and ai for their ability to mimic experts in different applications, as well as being able to replicate human interaction to varying degrees. research suggests that the use of a chatbot in offering career counseling can serve as an efficient means to provide this useful service in environments where a dedicated career counsellor may not be available. a lack of appropriate, adequate career counseling means youth may wind up pursuing careers that are chosen for them by their parents or only chosen for the promise of high salaries. these decisions may be made without taking into consideration whether or not they align with the individual's interests and values. this can lead to feelings of dissatisfaction in one's career, which is detrimental not only to the wellbeing of the individual but also to the overall productivity of the business in which they are hired. hence, the development of the chatbot will better inform users, assisting them in the ways of choosing a career. this will allow them to consider careers they may not have thought available to them, that would be more fulfilling and satisfactory than one that does not align with their interests. this research adopted both research methodology and software development methodology. under research methodology, a survey was conducted to gather information about individuals' opinions regarding their possible career choices, and what types of career advice they would like to receive from the system. in addition, the latest research on career guidance was considered in forming the basis of the questions asked. this information was used in chatbot system development on the facebook messenger platform, using tools such as the facebook sdk, the messenger platform apis, and javascript, and the wit.ai api which enables the use of natural language processing, which is a use case of ai techniques. the chatbot understands user input and give relevant and appropriate responses, reliably and in real-time. in conclusion, the results obtained are hoped to result in positive proclivity towards adopting the system, thus serving as a useful asset to any universities or institutions that might wish to utilize it.",career counseling chatbot on facebook messenger using ai
196,2-s2.0-85111583372,10.12720/jait.12.3.179-188,Bridging the gap among cohort data using mapping scenarios,Chondrogiannis E.,Journal of Advances in Information Technology,2021-08-01,"Disease-specific Cohort data across different healthcare and clinical research entities is of paramount importance for the study of the particular disorder and the development of new clinical and health policies. However, the significant structural and semantic mismatches across these data stemming from their independent development prevent their computer-based processing. The formal expression of the individual Cohorts using a common formalism (Data Harmonization) is the means for producing valid and accurate results, especially for diseases affecting a small percentage of the population, such as is the primary Sjögren's Syndrome (pSS), in which case data analytics on an individual cohort may lead to results not easily generalizable and of low accuracy and trust-worthiness. In this work, the approach followed in the HarmonicSS project for bridging the gap among eight heterogeneous Cohorts from eight different Cohort providers is presented, which was based on the software-aided analysis of their individual data structure and terminology. One of the outcomes of this process was a number of reusable parameterizable correspondence patterns (named Mapping Scenarios) that were accordingly instantiated for the accurate and complete mapping of the Cohort data to the Reference Model elements. The mapping scenarios were incorporated in a Visual Mapping Tool, which was developed for facilitating their use from both ICT experts and non-expert users.",Cohort study | Correspondence patterns | Data harmonization | Mapping scenarios | Semantic web,0,179-188,Journal,Article,4.0,"Chondrogiannis, Efthymios;Karanastasis, Efstathios;Andronikou, Vassiliki;Varvarigou, Theodora",55315292400;23990484900;22978675500;7003344545,National Technical University of Athens,Greece,"disease-specific cohort data across different healthcare and clinical research entities is of paramount importance for the study of the particular disorder and the development of new clinical and health policies. however, the significant structural and semantic mismatches across these data stemming from their independent development prevent their computer-based processing. the formal expression of the individual cohorts using a common formalism (data harmonization) is the means for producing valid and accurate results, especially for diseases affecting a small percentage of the population, such as is the primary sjögren's syndrome (pss), in which case data analytics on an individual cohort may lead to results not easily generalizable and of low accuracy and trust-worthiness. in this work, the approach followed in the harmonicss project for bridging the gap among eight heterogeneous cohorts from eight different cohort providers is presented, which was based on the software-aided analysis of their individual data structure and terminology. one of the outcomes of this process was a number of reusable parameterizable correspondence patterns (named mapping scenarios) that were accordingly instantiated for the accurate and complete mapping of the cohort data to the reference model elements. the mapping scenarios were incorporated in a visual mapping tool, which was developed for facilitating their use from both ict experts and non-expert users.",bridging the gap among cohort data using mapping scenarios
199,2-s2.0-85101686933,10.1007/s12650-020-00739-7,Visual exploration of software evolution via topic modeling,Liu H.,Journal of Visualization,2021-08-01,"For various reasons, such as new requirements, architecture refactoring, and bug fixing, software projects often evolve to yield better quality and performance. All changes produced during the development process are reflected in the source code, which provides an opportunity to explore software evolution. In this paper, we propose a visual analytics system to support evolution analysis based on topic modeling. We focus on three aspects: (1) when significant changes to source code occur, (2) how software features evolve, and (3) why software evolution occurs. Each source file is regarded as a document and represented by its topic vector. The files of each two successive versions are classified into four types to quantify version differences, and the number of topic-associated files is denoted as the topic assignment to characterize feature evolution. Finally, we inspect the causes of software evolution through the visual comparison between versions. Two case studies on JavaScript libraries demonstrate the usefulness and effectiveness of our system.",Code topics | Software evolution | Software visualization,1,827-844,Journal,Article,5.0,"Liu, Huan;Tao, Yubo;Qiu, Yining;Huang, Wenda;Lin, Hai",57212370182;8244401500;57222155971;57203856273;57188693150,"State Key Lab of CAD&amp;CG, Zhejiang University",China,"for various reasons, such as new requirements, architecture refactoring, and bug fixing, software projects often evolve to yield better quality and performance. all changes produced during the development process are reflected in the source code, which provides an opportunity to explore software evolution. in this paper, we propose a visual analytics system to support evolution analysis based on topic modeling. we focus on three aspects: (1) when significant changes to source code occur, (2) how software features evolve, and (3) why software evolution occurs. each source file is regarded as a document and represented by its topic vector. the files of each two successive versions are classified into four types to quantify version differences, and the number of topic-associated files is denoted as the topic assignment to characterize feature evolution. finally, we inspect the causes of software evolution through the visual comparison between versions. two case studies on javascript libraries demonstrate the usefulness and effectiveness of our system.",visual exploration of software evolution via topic modeling
200,2-s2.0-85069892117,10.1109/TSE.2019.2928293,Evolving JavaScript Code to Reduce Load Time,Farzat F.D.A.,IEEE Transactions on Software Engineering,2021-08-01,"JavaScript is one of the most used programming languages for front-end development of Web applications. The increase in complexity of front-end features brings concerns about performance, especially the load and execution time of JavaScript code. In this paper, we propose an evolutionary program improvement technique to reduce the size of JavaScript programs and, therefore, the time required to load and execute them in Web applications. To guide the development of this technique, we performed an experimental study to characterize the patches applied to JavaScript programs to reduce their size while keeping the functionality required to pass all test cases in their test suites. We applied this technique to 19 JavaScript programs varying from 92 to 15,602 LOC and observed reductions from 0.2 to 73.8 percent of the original code, as well as a relationship between the quality of a program's test suite and the ability to reduce the size of its source code.",genetic programming | JavaScript | local search | source code improvement,0,1544-1558,Journal,Article,3.0,"Farzat, Fabio De A.;Barros, Marcio De O.;Travassos, Guilherme H.",36997034700;56284339900;6603459594,Universidade Federal do Estado do Rio de Janeiro;Universidade Federal do Rio de Janeiro,Brazil;Brazil,"javascript is one of the most used programming languages for front-end development of web applications. the increase in complexity of front-end features brings concerns about performance, especially the load and execution time of javascript code. in this paper, we propose an evolutionary program improvement technique to reduce the size of javascript programs and, therefore, the time required to load and execute them in web applications. to guide the development of this technique, we performed an experimental study to characterize the patches applied to javascript programs to reduce their size while keeping the functionality required to pass all test cases in their test suites. we applied this technique to 19 javascript programs varying from 92 to 15,602 loc and observed reductions from 0.2 to 73.8 percent of the original code, as well as a relationship between the quality of a program's test suite and the ability to reduce the size of its source code.",evolving javascript code to reduce load time
202,2-s2.0-85111722987,10.1145/3464968.3468408,Impact of programming languages on machine learning bugs,Sztwiertnia S.,"AISTA 2021 - Proceedings of the 1st ACM International Workshop on AI and Software Testing/Analysis, co-located with ECOOP/ISSTA 2021",2021-07-12,"Machine learning (ML) is on the rise to be ubiquitous in modern software. Still, its use is challenging for software developers. So far, research has focused on the ML libraries to find and mitigate these challenges. However, there is initial evidence that programming languages also add to the challenges, identifiable in different distributions of bugs in ML programs. To fill this research gap, we propose the first empirical study on the impact of programming languages on bugs in ML programs. We plan to analyze software from GitHub and related discussions in GitHub issues and Stack Overflow for bug distributions in ML programs, aiming to identify correlations with the chosen programming language, its features and the application domain. This study's results enable better-targeted use of available programming language technology in ML programs, preventing bugs, reducing errors and speeding up development.",empirical study | machine learning | programming languages,0,9-12,Conference Proceeding,Conference Paper,6.0,"Sztwiertnia, Sebastian;Grübel, Maximilian;Chouchane, Amine;Sokolowski, Daniel;Narasimhan, Krishna;Mezini, Mira",57226493409;57226492615;57226495925;57221648343;57224950881;6602112237,Technische Universität Darmstadt,Germany,"machine learning (ml) is on the rise to be ubiquitous in modern software. still, its use is challenging for software developers. so far, research has focused on the ml libraries to find and mitigate these challenges. however, there is initial evidence that programming languages also add to the challenges, identifiable in different distributions of bugs in ml programs. to fill this research gap, we propose the first empirical study on the impact of programming languages on bugs in ml programs. we plan to analyze software from github and related discussions in github issues and stack overflow for bug distributions in ml programs, aiming to identify correlations with the chosen programming language, its features and the application domain. this study's results enable better-targeted use of available programming language technology in ml programs, preventing bugs, reducing errors and speeding up development.",impact of programming languages on machine learning bugs
203,2-s2.0-85111422140,10.1145/3460319.3464836,Modular call graph construction for security scanning of Node.js applications,Nielsen B.B.,ISSTA 2021 - Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis,2021-07-11,"Most of the code in typical Node.js applications comes from third-party libraries that consist of a large number of interdependent modules. Because of the dynamic features of JavaScript, it is difficult to obtain detailed information about the module dependencies, which is vital for reasoning about the potential consequences of security vulnerabilities in libraries, and for many other software development tasks. The underlying challenge is how to construct precise call graphs that capture the connectivity between functions in the modules. In this work we present a novel approach to call graph construction for Node.js applications that is modular, taking into account the modular structure of Node.js applications, and sufficiently accurate and efficient to be practically useful. We demonstrate experimentally that the constructed call graphs are useful for security scanning, reducing the number of false positives by 81% compared to npm audit and with zero false negatives. Compared to js-callgraph, the call graph construction is significantly more accurate and efficient. The experiments also show that the analysis time is reduced substantially when reusing modular call graphs.",JavaScript | Modularity | Static analysis,5,29-41,Conference Proceeding,Conference Paper,3.0,"Nielsen, Benjamin Barslev;Torp, Martin Toldam;Møller, Anders",57195735333;57203517497;57195116933,Aarhus Universitet,Denmark,"most of the code in typical node.js applications comes from third-party libraries that consist of a large number of interdependent modules. because of the dynamic features of javascript, it is difficult to obtain detailed information about the module dependencies, which is vital for reasoning about the potential consequences of security vulnerabilities in libraries, and for many other software development tasks. the underlying challenge is how to construct precise call graphs that capture the connectivity between functions in the modules. in this work we present a novel approach to call graph construction for node.js applications that is modular, taking into account the modular structure of node.js applications, and sufficiently accurate and efficient to be practically useful. we demonstrate experimentally that the constructed call graphs are useful for security scanning, reducing the number of false positives by 81% compared to npm audit and with zero false negatives. compared to js-callgraph, the call graph construction is significantly more accurate and efficient. the experiments also show that the analysis time is reduced substantially when reusing modular call graphs.",modular call graph construction for security scanning of node.js applications
204,2-s2.0-85123999701,10.1145/3483816.3483835,Cardinal Connect: A Student Organization Events Management System,Blancaflor E.B.,ACM International Conference Proceeding Series,2021-07-04,"Student organizations and the office are greatly affected by the COVID 19 pandemic, forcing universities to shift into the online setting. The organizations continue to adapt to the new normal by conducting online events and activities. However, managing events and activities can be challenging, especially without the use of a common platform. The paper proposes an event management system that would ease the transition to the online setting and reduce workload. A web application that focuses on event application, event implementation, and post-activity evaluation would benefit the coordination between the involved parties. The study aims to automate necessary document processes, provide an online platform for student organizations to execute proposals, generate and summarize the entirety of the events and activities. The study will be using a Likert Scale survey questionnaire for the Office of the Students Affairs and Student organizations to measure the usability of the Cardinal Connect Event Management System. The data develop a web-based application that would improve the event management at Mapua University. The researchers will be testing the serviceability of the system by using a Usability Test to test its serviceability. This is because the study requires a specific population of student organizations. The prototype is possible using HTML, CSS, and Javascript for the front-end and PHP, Python, Javascript for the back-end development. Through a prototype, the users can execute design features of the web application and conduct usability testing to improve the overall user experience. The web application aids the needs of the university and how the different organizations would engage students to maximize their university life.",Events Management System | Student Organizations | Web Application,0,105-111,Conference Proceeding,Conference Paper,4.0,"Blancaflor, Eric B.;Dela Cruz, Gabriel Angelo B.;Rabanal, Raya Shane C.;Ramos, Jerome Patrick S.",57208326489;57440012900;57438806700;57440013000,Mapua University,Philippines,"student organizations and the office are greatly affected by the covid 19 pandemic, forcing universities to shift into the online setting. the organizations continue to adapt to the new normal by conducting online events and activities. however, managing events and activities can be challenging, especially without the use of a common platform. the paper proposes an event management system that would ease the transition to the online setting and reduce workload. a web application that focuses on event application, event implementation, and post-activity evaluation would benefit the coordination between the involved parties. the study aims to automate necessary document processes, provide an online platform for student organizations to execute proposals, generate and summarize the entirety of the events and activities. the study will be using a likert scale survey questionnaire for the office of the students affairs and student organizations to measure the usability of the cardinal connect event management system. the data develop a web-based application that would improve the event management at mapua university. the researchers will be testing the serviceability of the system by using a usability test to test its serviceability. this is because the study requires a specific population of student organizations. the prototype is possible using html, css, and javascript for the front-end and php, python, javascript for the back-end development. through a prototype, the users can execute design features of the web application and conduct usability testing to improve the overall user experience. the web application aids the needs of the university and how the different organizations would engage students to maximize their university life.",cardinal connect: a student organization events management system
207,2-s2.0-85115871097,10.1109/COMPSAC51774.2021.00144,Mi-FiWare: A web component development method for FIWARE using microservices,Llopis J.A.,"Proceedings - 2021 IEEE 45th Annual Computers, Software, and Applications Conference, COMPSAC 2021",2021-07-01,"Within the smart solutions (Smart Industry, Smart Home and Smart City), the concept of Smart Cities is the one having the greatest growth, inducing an increment in the number of developers focused on carrying out this idea, and growth in the number of companies that contribute with solutions like IoT platforms. These platforms help in the development of smart solutions providing tools and services that automate some of the development processes and ease the creation of software for smart environments. To support the growth of smart cities, we propose MI-FIWARE, an architecture based on microservices (MI) and the IoT platform FIWARE. MI-FIWARE reduces developers from the back-end workload and the processing of context information, in a way that only the front-side has to be developed using a web component template proposed. MI-FIWARE architecture is based on microservices, taking advantage of FIWARE as a modular platform and establishing the possibility of using microservices to add extra functionality to the IoT platform, helping the developers in other development processes like security.",FIWARE | Internet of things | Microservice | Smart city | Web component,0,1058-1065,Conference Proceeding,Conference Paper,4.0,"Llopis, Juan Alberto;Mena, Manel;Criado, Javier;Iribarne, Luis",57221112459;57210893678;36170340400;55908790400,Universidad de Almería,Spain,"within the smart solutions (smart industry, smart home and smart city), the concept of smart cities is the one having the greatest growth, inducing an increment in the number of developers focused on carrying out this idea, and growth in the number of companies that contribute with solutions like iot platforms. these platforms help in the development of smart solutions providing tools and services that automate some of the development processes and ease the creation of software for smart environments. to support the growth of smart cities, we propose mi-fiware, an architecture based on microservices (mi) and the iot platform fiware. mi-fiware reduces developers from the back-end workload and the processing of context information, in a way that only the front-side has to be developed using a web component template proposed. mi-fiware architecture is based on microservices, taking advantage of fiware as a modular platform and establishing the possibility of using microservices to add extra functionality to the iot platform, helping the developers in other development processes like security.",mi-fiware: a web component development method for fiware using microservices
213,2-s2.0-85107238139,10.3233/SHTI210155,MainzelHandler: A library for a simple integration and usage of the mainzelliste,Preciado-Marquez D.,Public Health and Informatics: Proceedings of MIE 2021,2021-07-01,"Pseudonymization plays a vital role in medical research. In Germany, the Technologie- und Methodenplattform für die vernetzte medizinische Forschung e.V. (TMF) has developed guidelines on how to create pseudonyms and how to handle personally identifiable information (PII) during this process. An open-source implementation of a pseudonymization service following these guidelines and therefore recommended by the TMF is the so-called ""Mainzelliste"". This web application supports a REST-API for (de-) pseudonymization. For security reasons, a complex session and tokening mechanism for each (de-) pseudonymization is required and a careful interaction between front- and backend to ensure a correct handling of PII. The objective of this work is the development of a library to simplify the integration and usage of the Mainzelliste's API in a TMF conform way. The frontend library uses JavaScript while the backend component is based on Java with an optional Spring Boot extension. The library is available under MIT open-source license from https://github.com/DanielPreciado-Marquez/MainzelHandler. © 2021 European Federation for Medical Informatics (EFMI) and IOS Press.",JavaScript | Mainzelliste | Open-Source | Pseudonymization | Spring Boot,0,233-237,Book,Book Chapter,6.0,"Preciado-Marquez, Daniel;Becker, Ludger;Storck, Michael;Greulich, Leonard;Dugas, Martin;Brix, Tobias J.",57224206747;57224206555;56427743100;57210788172;55550317000;56545379300,Westfälische Wilhelms-Universität Münster,Germany,"pseudonymization plays a vital role in medical research. in germany, the technologie- und methodenplattform für die vernetzte medizinische forschung e.v. (tmf) has developed guidelines on how to create pseudonyms and how to handle personally identifiable information (pii) during this process. an open-source implementation of a pseudonymization service following these guidelines and therefore recommended by the tmf is the so-called ""mainzelliste"". this web application supports a rest-api for (de-) pseudonymization. for security reasons, a complex session and tokening mechanism for each (de-) pseudonymization is required and a careful interaction between front- and backend to ensure a correct handling of pii. the objective of this work is the development of a library to simplify the integration and usage of the mainzelliste's api in a tmf conform way. the frontend library uses javascript while the backend component is based on java with an optional spring boot extension. the library is available under mit open-source license from https://github.com/danielpreciado-marquez/mainzelhandler. © 2021 european federation for medical informatics (efmi) and ios press.",mainzelhandler: a library for a simple integration and usage of the mainzelliste
214,2-s2.0-85113450698,10.1109/EDM52169.2021.9507678,RIDE: Theia-Based Web IDE for the Reflex Language,Gornev I.,"International Conference of Young Specialists on Micro/Nanotechnologies and Electron Devices, EDM",2021-06-30,"The process-oriented programming language Reflex is a programming language for cyber-physical systems' (CPS) control software. It is based on the formal hyperprocess model. Reflex has proved effective in industrial projects. But using Reflex is difficult due to the lack of IDE for Reflex programs. In this paper, we develop a cloud desktop IDE for the Reflex language-RIDE. Modularity is the main principle of RIDE architecture. It meets the needs of CPS software development process and allows extending the IDE functionality. Reflex IDE extensions may provide various functionalities, such as a graphical representation of the Reflex code, translators to other programming languages, debugging, and verification techniques.",cloud IDE | control software | cyber-physical systems | process-oriented programming | web,0,503-506,Conference Proceeding,Conference Paper,2.0,"Gornev, Ilya;Liakh, Tatiana",57232241300;57189899561,Institute of Automation and Electrometry of the Siberian Branch of the Russian Academy of Sciences,Russian Federation,"the process-oriented programming language reflex is a programming language for cyber-physical systems' (cps) control software. it is based on the formal hyperprocess model. reflex has proved effective in industrial projects. but using reflex is difficult due to the lack of ide for reflex programs. in this paper, we develop a cloud desktop ide for the reflex language-ride. modularity is the main principle of ride architecture. it meets the needs of cps software development process and allows extending the ide functionality. reflex ide extensions may provide various functionalities, such as a graphical representation of the reflex code, translators to other programming languages, debugging, and verification techniques.",ride: theia-based web ide for the reflex language
215,2-s2.0-85108996727,10.1145/3430665.3456352,Teaching Testing with Modern Technology Stacks in Undergraduate Software Engineering Courses,Chow S.P.,"Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE",2021-06-26,"Students' experience with software testing in undergraduate computing courses is often relatively shallow, as compared to the importance of the topic. This experience report describes introducing industrial-strength testing into CMPSC 156, an upper division course in software engineering at UC Santa Barbara. We describe our efforts to modify our software engineering course to introduce rigorous test-coverage requirements into full-stack web development projects, requirements similar to those the authors had experienced in a professional software development setting. We present student feedback on the course and coverage metrics for the projects. We reflect on what about these changes worked (or didn't), and provide suggestions for other instructors that would like to give their students a deeper experience with software testing in their software engineering courses.",computer science education | continuous integration | integration testing | software engineering education | test coverage | testing | unit testing | web applications,0,241-247,Conference Proceeding,Conference Paper,3.0,"Chow, Scott P.;Komarlu, Tanay;Conrad, Phillip T.",57225053113;57225052607;7103248256,"University of California, Santa Barbara",United States,"students' experience with software testing in undergraduate computing courses is often relatively shallow, as compared to the importance of the topic. this experience report describes introducing industrial-strength testing into cmpsc 156, an upper division course in software engineering at uc santa barbara. we describe our efforts to modify our software engineering course to introduce rigorous test-coverage requirements into full-stack web development projects, requirements similar to those the authors had experienced in a professional software development setting. we present student feedback on the course and coverage metrics for the projects. we reflect on what about these changes worked (or didn't), and provide suggestions for other instructors that would like to give their students a deeper experience with software testing in their software engineering courses.",teaching testing with modern technology stacks in undergraduate software engineering courses
219,2-s2.0-85109512349,10.1145/3450613.3456825,Translating a typing-based adaptive learning model to speech-based L2 vocabulary learning,Wilschut T.,"UMAP 2021 - Proceedings of the 29th ACM Conference on User Modeling, Adaptation and Personalization",2021-06-21,"Memorising vocabulary is an important aspect of formal foreign language learning. Advances in cognitive psychology have led to the development of adaptive learning systems that make vocabulary learning more efficient. These computer-based systems measure learning performance in real time to create optimal study strategies for individual learners. While such adaptive learning systems have been successfully applied to written word learning, they have thus far seen little application in spoken word learning. Here we present a system for adaptive, speech-based word learning. We show that it is possible to improve the efficiency of speech-based learning systems by applying a modified adaptive model that was originally developed for typing-based word learning. This finding contributes to a better understanding of the memory processes involved in speech-based word learning. Furthermore, our work provides a basis for the development of language learning applications that use real-time pronunciation assessment software to score the accuracy of the learner's pronunciations. Speech-based learning applications are educationally relevant because they focus on what may be the most important aspect of language learning: to practice speech.",Adaptive learning | Memory | Pronunciation | Speech | Vocabulary learning,2,245-250,Conference Proceeding,Conference Paper,5.0,"Wilschut, Thomas;Van Der Velde, Maarten;Sense, Florian;Fountas, Zafeirios;Van Rijn, Hedderik",57225202827;57200391485;57053441400;53263658800;21740285500,Rijksuniversiteit Groningen;Emotech Ltd,Netherlands;United Kingdom,"memorising vocabulary is an important aspect of formal foreign language learning. advances in cognitive psychology have led to the development of adaptive learning systems that make vocabulary learning more efficient. these computer-based systems measure learning performance in real time to create optimal study strategies for individual learners. while such adaptive learning systems have been successfully applied to written word learning, they have thus far seen little application in spoken word learning. here we present a system for adaptive, speech-based word learning. we show that it is possible to improve the efficiency of speech-based learning systems by applying a modified adaptive model that was originally developed for typing-based word learning. this finding contributes to a better understanding of the memory processes involved in speech-based word learning. furthermore, our work provides a basis for the development of language learning applications that use real-time pronunciation assessment software to score the accuracy of the learner's pronunciations. speech-based learning applications are educationally relevant because they focus on what may be the most important aspect of language learning: to practice speech.",translating a typing-based adaptive learning model to speech-based l2 vocabulary learning
222,2-s2.0-85114415741,10.1109/SEH52539.2021.00009,Software Development during COVID-19 Pandemic: An Analysis of Stack Overflow and GitHub,Oliveira P.A.M.,"Proceedings - 2021 IEEE/ACM 3rd International Workshop on Software Engineering for Healthcare, SEH 2021",2021-06-01,"The new coronavirus became a severe health issue for the world. This situation has motivated studies of different areas to combat this pandemic. In software engineering, we point out data visualization projects to follow the disease evolution, machine learning to estimate the pandemic behavior, and computer vision processing radiologic images. Most of these projects are stored in version control systems, and there are discussions about them in Question & Answer websites. In this work, we conducted a Mining Software Repository on a large number of questions and projects aiming to find trends that could help researchers and practitioners to fight against the coronavirus. We analyzed 1,190 questions from Stack Overflow and Data Science Q&A and 60,352 GitHub projects. We identified a correlation between the questions and projects throughout the pandemic. The main questions about coronavirus are how-to, related to web scraping and data visualization, using Python, JavaScript, and R. The most recurrent GitHub projects are machine learning projects, using JavaScript, Python, and Java.",COVID-19 | Mining Software Repository | Topic Modeling,0,5-12,Conference Proceeding,Conference Paper,6.0,"Oliveira, Pedro Almir M.;Santos Neto, Pedro A.;Silva, Gleison;Ibiapina, Irvayne;Lira, Werney L.;Andrade, Rossana M.C.",56949904300;22735235600;57215344959;57208130930;57222486269;56214455600,Universidade Federal do Piauí;Universidade Federal do Ceará;Science;Maida Health Company,Brazil;Brazil;Brazil;Brazil,"the new coronavirus became a severe health issue for the world. this situation has motivated studies of different areas to combat this pandemic. in software engineering, we point out data visualization projects to follow the disease evolution, machine learning to estimate the pandemic behavior, and computer vision processing radiologic images. most of these projects are stored in version control systems, and there are discussions about them in question & answer websites. in this work, we conducted a mining software repository on a large number of questions and projects aiming to find trends that could help researchers and practitioners to fight against the coronavirus. we analyzed 1,190 questions from stack overflow and data science q&a and 60,352 github projects. we identified a correlation between the questions and projects throughout the pandemic. the main questions about coronavirus are how-to, related to web scraping and data visualization, using python, javascript, and r. the most recurrent github projects are machine learning projects, using javascript, python, and java.",software development during covid-19 pandemic: an analysis of stack overflow and github
225,2-s2.0-85106207514,10.1007/s11219-021-09555-0,A hierarchical model for quantifying software security based on static analysis alerts and software metrics,Siavvas M.,Software Quality Journal,2021-06-01,"Despite the acknowledged importance of quantitative security assessment in secure software development, current literature still lacks an efficient model for measuring internal software security risk. To this end, in this paper, we introduce a hierarchical security assessment model (SAM), able to assess the internal security level of software products based on low-level indicators, i.e., security-relevant static analysis alerts and software metrics. The model, following the guidelines of ISO/IEC 25010, and based on a set of thresholds and weights, systematically aggregates these low-level indicators in order to produce a high-level security score that reflects the internal security level of the analyzed software. The proposed model is practical, since it is fully automated and operationalized in the form of a standalone tool and as part of a broader Computer-Aided Software Engineering (CASE) platform. In order to enhance its reliability, the thresholds of the model were calibrated based on a repository of 100 popular software applications retrieved from Maven Repository. Furthermore, its weights were elicited in a way to chiefly reflect the knowledge expressed by the Common Weakness Enumeration (CWE), through a novel weights elicitation approach grounded on popular decision-making techniques. The proposed model was evaluated on a large repository of 150 open-source software applications retrieved from GitHub and 1200 classes retrieved from the OWASP Benchmark. The results of the experiments revealed the capacity of the proposed model to reliably assess internal security at both product level and class level of granularity, with sufficient discretion power. They also provide preliminary evidence for the ability of the model to be used as the basis for vulnerability prediction. To the best of our knowledge, this is the first fully automated, operationalized and sufficiently evaluated security assessment model in the modern literature.",Security Assessment | Software Quality Evaluation | Software Security,4,431-507,Journal,Article,4.0,"Siavvas, Miltiadis;Kehagias, Dionysios;Tzovaras, Dimitrios;Gelenbe, Erol",57194500913;7003972544;13105681700;7006026729,Center For Research And Technology - Hellas;Institute of Theoretical and Applied Informatics of the Polish Academy of Sciences;Imperial College London,Greece;Poland;United Kingdom,"despite the acknowledged importance of quantitative security assessment in secure software development, current literature still lacks an efficient model for measuring internal software security risk. to this end, in this paper, we introduce a hierarchical security assessment model (sam), able to assess the internal security level of software products based on low-level indicators, i.e., security-relevant static analysis alerts and software metrics. the model, following the guidelines of iso/iec 25010, and based on a set of thresholds and weights, systematically aggregates these low-level indicators in order to produce a high-level security score that reflects the internal security level of the analyzed software. the proposed model is practical, since it is fully automated and operationalized in the form of a standalone tool and as part of a broader computer-aided software engineering (case) platform. in order to enhance its reliability, the thresholds of the model were calibrated based on a repository of 100 popular software applications retrieved from maven repository. furthermore, its weights were elicited in a way to chiefly reflect the knowledge expressed by the common weakness enumeration (cwe), through a novel weights elicitation approach grounded on popular decision-making techniques. the proposed model was evaluated on a large repository of 150 open-source software applications retrieved from github and 1200 classes retrieved from the owasp benchmark. the results of the experiments revealed the capacity of the proposed model to reliably assess internal security at both product level and class level of granularity, with sufficient discretion power. they also provide preliminary evidence for the ability of the model to be used as the basis for vulnerability prediction. to the best of our knowledge, this is the first fully automated, operationalized and sufficiently evaluated security assessment model in the modern literature.",a hierarchical model for quantifying software security based on static analysis alerts and software metrics
227,2-s2.0-85100194179,10.1007/s12650-020-00727-x,Visual exploration of dependency graph in source code via embedding-based similarity,Liu H.,Journal of Visualization,2021-06-01,"Abstract: A large software system contains millions of lines of source code, and the development often involves many developers over a long period. How to understand and analyze its complex code dependencies is challenging but meaningful to developers for program comprehension. In this paper, we propose a novel visual analytics system to explore code dependencies between files for visually understanding software architecture and interactively analyzing bad dependencies. The dependencies between files are abstracted as a directed graph (i.e., the dependency graph) at different levels via the file hierarchy to show the modularization design of source code. Node embeddings of the dependency graph are learned to identify the files with specific dependencies and analyze the similarity between bad dependencies. Finally, we evaluate the usability of our system by two case studies in different JavaScript libraries as well as a user study on software architecture understanding and bad dependency analysis. Graphic abstract: [Figure not available: see fulltext.].",Code dependencies | Dependency graph | Software visualization,1,565-581,Journal,Article,4.0,"Liu, Huan;Tao, Yubo;Huang, Wenda;Lin, Hai",57212370182;8244401500;57203856273;57188693150,"State Key Lab of CAD&amp;CG, Zhejiang University",China,"abstract: a large software system contains millions of lines of source code, and the development often involves many developers over a long period. how to understand and analyze its complex code dependencies is challenging but meaningful to developers for program comprehension. in this paper, we propose a novel visual analytics system to explore code dependencies between files for visually understanding software architecture and interactively analyzing bad dependencies. the dependencies between files are abstracted as a directed graph (i.e., the dependency graph) at different levels via the file hierarchy to show the modularization design of source code. node embeddings of the dependency graph are learned to identify the files with specific dependencies and analyze the similarity between bad dependencies. finally, we evaluate the usability of our system by two case studies in different javascript libraries as well as a user study on software architecture understanding and bad dependency analysis. graphic abstract: [figure not available: see fulltext.].",visual exploration of dependency graph in source code via embedding-based similarity
228,2-s2.0-85092643307,10.1007/s10270-020-00827-0,Wodel-Test: a model-based framework for language-independent mutation testing,Gómez-Abajo P.,Software and Systems Modeling,2021-06-01,"Mutation testing (MT) targets the assessment of test cases by measuring their efficiency to detect faults. This technique involves modifying the program under test to emulate programming faults, and assessing whether the existing test cases detect such mutations. MT has been extensively studied since the 70’s, and many tools have been proposed for widely used languages like C, Java, Fortran, Ada and SQL; and for notations like Petri-nets. However, building MT tools is costly and error-prone, which may prevent their development for new programming and domain-specific (modelling) languages. In this paper, we propose a framework called Wodel-Test to reduce the effort to create MT tools. For this purpose, it follows a model-driven approach by which MT tools are synthesized from a high-level description. This description makes use of the domain-specific language Wodel to define and execute model mutations. Wodel is language-independent, as it allows the creation of mutation operators for any language defined by a meta-model. Starting from the definition of the mutation operators, Wodel-Test generates a MT environment which parses the program under test into a model, applies the mutation operators, and evaluates the test-suite against the generated mutants, offering a rich collection of MT metrics. We report on an evaluation of the approach based on the creation of MT tools for Java and the Atlas transformation language.",Domain-specific languages | Java | Model mutation | Model transformation | Model-driven engineering | Mutation testing,9,767-793,Journal,Article,4.0,"Gómez-Abajo, Pablo;Guerra, Esther;Lara, Juan de;Merayo, Mercedes G.",57189900403;14051863600;57214082388;14037866800,Universidad Complutense de Madrid;Universidad Autónoma de Madrid,Spain;Spain,"mutation testing (mt) targets the assessment of test cases by measuring their efficiency to detect faults. this technique involves modifying the program under test to emulate programming faults, and assessing whether the existing test cases detect such mutations. mt has been extensively studied since the 70’s, and many tools have been proposed for widely used languages like c, java, fortran, ada and sql; and for notations like petri-nets. however, building mt tools is costly and error-prone, which may prevent their development for new programming and domain-specific (modelling) languages. in this paper, we propose a framework called wodel-test to reduce the effort to create mt tools. for this purpose, it follows a model-driven approach by which mt tools are synthesized from a high-level description. this description makes use of the domain-specific language wodel to define and execute model mutations. wodel is language-independent, as it allows the creation of mutation operators for any language defined by a meta-model. starting from the definition of the mutation operators, wodel-test generates a mt environment which parses the program under test into a model, applies the mutation operators, and evaluates the test-suite against the generated mutants, offering a rich collection of mt metrics. we report on an evaluation of the approach based on the creation of mt tools for java and the atlas transformation language.",wodel-test: a model-based framework for language-independent mutation testing
230,2-s2.0-85111388772,10.1109/MIUCC52538.2021.9447669,Code Smells and Detection Techniques: A Survey,Menshawy R.S.,"2021 International Mobile, Intelligent, and Ubiquitous Computing Conference, MIUCC 2021",2021-05-26,"Design and code smells are characteristics in the software source code that might indicate a deeper design problem. Code smells can lead to costly maintenance and quality problems, to remove these code smells, the software engineers should follow the best practices, which are the set of correct techniques which improve the software quality. Refactoring is an adequate technique to fix code smells, software refactoring modifies the internal code structure without changing its functionality and suggests the best redesign changes to be performed. Developers who apply correct refactoring sequences to remove code smells, improve the software maintenance and development time significantly. Many tools have been created to automatically or semi-automatically detect code smells and refactor them. This study discusses the code smells, detection techniques, detection and refactoring tools, in addition to observing the challenges and suggesting enhancements for better performance.",Code smells | detection techniques | Software Refactoring | Survey.,1,78-83,Conference Proceeding,Conference Paper,3.0,"Menshawy, Rana S.;Yousef, Ahmed H.;Salem, Ashraf",57226381728;57217371978;57226384256,Ain Shams University;Nile University,Egypt;Egypt,"design and code smells are characteristics in the software source code that might indicate a deeper design problem. code smells can lead to costly maintenance and quality problems, to remove these code smells, the software engineers should follow the best practices, which are the set of correct techniques which improve the software quality. refactoring is an adequate technique to fix code smells, software refactoring modifies the internal code structure without changing its functionality and suggests the best redesign changes to be performed. developers who apply correct refactoring sequences to remove code smells, improve the software maintenance and development time significantly. many tools have been created to automatically or semi-automatically detect code smells and refactor them. this study discusses the code smells, detection techniques, detection and refactoring tools, in addition to observing the challenges and suggesting enhancements for better performance.",code smells and detection techniques: a survey
233,2-s2.0-85113810339,10.1109/USBEREIT51232.2021.9454998,Developing Educational Programs Using Russian IT Job Market Analysis,Sozykin A.,"Proceedings - 2021 Ural Symposium on Biomedical Engineering, Radioelectronics and Information Technology, USBEREIT 2021",2021-05-13,"The paper presents an approach to developing new educational programs for information technologies (IT) specialists using job market analysis. We developed a set of innovative software tools for collecting data from job sites and analyzing the data using machine learning algorithms. The tools were used to create a dataset of job advertisements from popular Russian job site HeadHunter for a period from 2006 until 2020. Both tools and dataset are freely available on the Internet. In order to develop the educational programs, we analyzed the demand for IT professions and programming languages, as well as joint occurrence of skills in job descriptions. To demonstrate the possibilities of our approach, two educational programs were created: A JavaScript-based program for Web Development and a Python-based program for Data Science. Developing the educational programs based on the requirements of the job market allows graduates to increase their employability. During the programs, students not only study the foundation of the profession such as programming languages, but also acquire a complete set of skills required to work in demanded positions.",educational programs | IT education | IT job skills | job market analysis | text mining,0,391-394,Conference Proceeding,Conference Paper,6.0,"Sozykin, Andrey;Koshelev, Anton;Bersenev, Alexander;Shadrin, Denis;Aksenov, Alexander;Kuklin, Evgeniy",57198744429;47061545200;57192681000;57209748418;57218589503;57190228983,Institute of Natural Sciences and Mathematics;Ural Federal University;N.N. Krasovskii Institute of Mathematics and Mechanics of the Ural Branch of the Russian Academy of Sciences,Russian Federation;Russian Federation;Russian Federation,"the paper presents an approach to developing new educational programs for information technologies (it) specialists using job market analysis. we developed a set of innovative software tools for collecting data from job sites and analyzing the data using machine learning algorithms. the tools were used to create a dataset of job advertisements from popular russian job site headhunter for a period from 2006 until 2020. both tools and dataset are freely available on the internet. in order to develop the educational programs, we analyzed the demand for it professions and programming languages, as well as joint occurrence of skills in job descriptions. to demonstrate the possibilities of our approach, two educational programs were created: a javascript-based program for web development and a python-based program for data science. developing the educational programs based on the requirements of the job market allows graduates to increase their employability. during the programs, students not only study the foundation of the profession such as programming languages, but also acquire a complete set of skills required to work in demanded positions.",developing educational programs using russian it job market analysis
236,2-s2.0-85115711213,10.1109/ICSE43902.2021.00051,IoT bugs and development challenges,Makhshari A.,Proceedings - International Conference on Software Engineering,2021-05-01,"IoT systems are rapidly adopted in various domains, from embedded systems to smart homes. Despite their growing adoption and popularity, there has been no thorough study to understand IoT development challenges from the practitioners' point of view. We provide the first systematic study of bugs and challenges that IoT developers face in practice, through a large-scale empirical investigation. We collected 5,565 bug reports from 91 representative IoT project repositories and categorized a random sample of 323 based on the observed failures, root causes, and the locations of the faulty components. In addition, we conducted nine interviews with IoT experts to uncover more details about IoT bugs and to gain insight into IoT developers' challenges. Lastly, we surveyed 194 IoT developers to validate our findings and gain further insights. We propose the first bug taxonomy for IoT systems based on our results. We highlight frequent bug categories and their root causes, correlations between them, and common pitfalls and challenges that IoT developers face. We recommend future directions for IoT areas that require research and development attention.",Empirical Study | Internet of Things | Mining Software Repositories | Software Engineering,9,460-472,Conference Proceeding,Conference Paper,2.0,"Makhshari, Amir;Mesbah, Ali",57271382100;17345931800,The University of British Columbia,Canada,"iot systems are rapidly adopted in various domains, from embedded systems to smart homes. despite their growing adoption and popularity, there has been no thorough study to understand iot development challenges from the practitioners' point of view. we provide the first systematic study of bugs and challenges that iot developers face in practice, through a large-scale empirical investigation. we collected 5,565 bug reports from 91 representative iot project repositories and categorized a random sample of 323 based on the observed failures, root causes, and the locations of the faulty components. in addition, we conducted nine interviews with iot experts to uncover more details about iot bugs and to gain insight into iot developers' challenges. lastly, we surveyed 194 iot developers to validate our findings and gain further insights. we propose the first bug taxonomy for iot systems based on our results. we highlight frequent bug categories and their root causes, correlations between them, and common pitfalls and challenges that iot developers face. we recommend future directions for iot areas that require research and development attention.",iot bugs and development challenges
237,2-s2.0-85115699652,10.1109/ICSE43902.2021.00022,Hero: On the chaos when PATH meets modules,Wang Y.,Proceedings - International Conference on Software Engineering,2021-05-01,"Ever since its first release in 2009, the Go programming language (Golang) has been well received by software communities. A major reason for its success is the powerful support of library-based development, where a Golang project can be conveniently built on top of other projects by referencing them as libraries. As Golang evolves, it recommends the use of a new library-referencing mode to overcome the limitations of the original one. While these two library modes are incompatible, both are supported by the Golang ecosystem. The heterogeneous use of library-referencing modes across Golang projects has caused numerous dependency management (DM) issues, incurring reference inconsistencies and even build failures. Motivated by the problem, we conducted an empirical study to characterize the DM issues, understand their root causes, and examine their fixing solutions. Based on our findings, we developed Hero, an automated technique to detect DM issues and suggest proper fixing solutions. We applied Hero to 19,000 popular Golang projects. The results showed that Hero achieved a high detection rate of 98.5% on a DM issue benchmark and found 2,422 new DM issues in 2,356 popular Golang projects. We reported 280 issues, among which 181 (64.6%) issues have been confirmed, and 160 of them (88.4%) have been fixed or are under fixing. Almost all the fixes have adopted our fixing suggestions.",Dependency Management | Golang Ecosystem,1,99-111,Conference Proceeding,Conference Paper,8.0,"Wang, Ying;Qiao, Liang;Xu, Chang;Liu, Yepang;Cheung, Shing Chi;Meng, Na;Yu, Hai;Zhu, Zhiliang",57022068000;57222334647;56870592600;55540648000;7202472792;42161811400;13408303800;55549832300,Southern University of Science and Technology;Nanjing University;Northeastern University;Virginia Polytechnic Institute and State University;Hong Kong University of Science and Technology,China;China;China;United States;Hong Kong,"ever since its first release in 2009, the go programming language (golang) has been well received by software communities. a major reason for its success is the powerful support of library-based development, where a golang project can be conveniently built on top of other projects by referencing them as libraries. as golang evolves, it recommends the use of a new library-referencing mode to overcome the limitations of the original one. while these two library modes are incompatible, both are supported by the golang ecosystem. the heterogeneous use of library-referencing modes across golang projects has caused numerous dependency management (dm) issues, incurring reference inconsistencies and even build failures. motivated by the problem, we conducted an empirical study to characterize the dm issues, understand their root causes, and examine their fixing solutions. based on our findings, we developed hero, an automated technique to detect dm issues and suggest proper fixing solutions. we applied hero to 19,000 popular golang projects. the results showed that hero achieved a high detection rate of 98.5% on a dm issue benchmark and found 2,422 new dm issues in 2,356 popular golang projects. we reported 280 issues, among which 181 (64.6%) issues have been confirmed, and 160 of them (88.4%) have been fixed or are under fixing. almost all the fixes have adopted our fixing suggestions.",hero: on the chaos when path meets modules
239,2-s2.0-85113765658,10.1109/AST52587.2021.00013,Automatically Assessing and Extending Code Coverage for NPM Packages,Sun H.,"Proceedings - 2021 IEEE/ACM International Conference on Automation of Software Test, AST 2021",2021-05-01,"Typical Node.js applications extensively rely on packages hosted in the npm registry. As such packages may be used by thousands of other packages or applications, it is important to assess their code coverage. Moreover, increasing code coverage may help detect previously unknown issues. In this paper, we introduce TESA, a new tool that automatically assembles a test suite for any package in the npm registry. The test suite includes 1) tests written for the target package and usually hosted in its development repository, and 2) tests selected from dependent packages. The former tests allow assessing the code coverage of the target package, while the latter ones can increase code coverage by exploiting third-party tests that also exercise code in the target package. We use TESA to assess the code coverage of 500 popular npm packages. Then, we demonstrate that TESA can significantly increase code coverage by including tests from dependent packages. Finally, we show that the test suites assembled by TESA increase the effectiveness of existing dynamic program analyses to identify performance issues that are not detectable when only executing the developer's tests.",code coverage | javascript | npm | test automation,0,40-49,Conference Proceeding,Conference Paper,4.0,"Sun, Haiyang;Rosa, Andrea;Bonetta, Daniele;Binder, Walter",57026601800;56473303400;36647322000;7005259851,Università della Svizzera italiana;Oracle Labs,Switzerland;Netherlands,"typical node.js applications extensively rely on packages hosted in the npm registry. as such packages may be used by thousands of other packages or applications, it is important to assess their code coverage. moreover, increasing code coverage may help detect previously unknown issues. in this paper, we introduce tesa, a new tool that automatically assembles a test suite for any package in the npm registry. the test suite includes 1) tests written for the target package and usually hosted in its development repository, and 2) tests selected from dependent packages. the former tests allow assessing the code coverage of the target package, while the latter ones can increase code coverage by exploiting third-party tests that also exercise code in the target package. we use tesa to assess the code coverage of 500 popular npm packages. then, we demonstrate that tesa can significantly increase code coverage by including tests from dependent packages. finally, we show that the test suites assembled by tesa increase the effectiveness of existing dynamic program analyses to identify performance issues that are not detectable when only executing the developer's tests.",automatically assessing and extending code coverage for npm packages
240,2-s2.0-85113705395,10.1109/CHASE52884.2021.00010,Decoding Confusing Code: Social Representations among Developers,De Mello R.,"Proceedings - 2021 IEEE/ACM 13th International Workshop on Cooperative and Human Aspects of Software Engineering, CHASE 2021",2021-05-01,"Context. Confusing code is any code element in which developers have considerable difficulty reaching its comprehension. These difficulties may result from a plethora of characteristics of the source code and external issues. In this way, there is still a lack of knowledge on the core issues of confusing code. This knowledge is important for optimizing efforts in promoting program comprehension. Goal. In this paper, we investigate the social representations of confusing code among two distinct communities of software developers from industry. Method. We conducted free association tasks with the developers to characterize what is in their minds about confusing code. Then, we compiled and classified the associations composing the social representations of confusing code by each community. Finally, we compared the social representations from both communities. Results. We found that developers of both communities strongly associate confusing code with a common set of undesirable characteristics of the source code, such as different types of code smells and the badly naming of code elements. Besides, we found that the incidence of confusing code is a potential source of discouragement and conflict. In this way, we discuss alternatives for development teams overcoming these issues. Conclusion. The findings of our study reveal an initial set of core issues of confusing code. These issues can drive future investigations on technologies for promoting code comprehension.",confusing code | free association | program comprehension | social representations,1,11-20,Conference Proceeding,Conference Paper,8.0,"De Mello, Rafael;Da Costa, Jose Aldo;De Oliveira, Benedito;Ribeiro, Marcio;Fonseca, Baldoino;Gheyi, Rohit;Garcia, Alessandro;Tiengo, Willy",37025865700;57221528387;57221521282;57199329234;36175426900;8365747700;7404608626;15926475300,Centro Federal De Educacão Tecnológica Celso Suckow Da Fonseca;Pontifícia Universidade Católica do Rio de Janeiro;Universidade Federal de Alagoas;Universidade Federal de Campina Grande,Brazil;Brazil;Brazil;Brazil,"context. confusing code is any code element in which developers have considerable difficulty reaching its comprehension. these difficulties may result from a plethora of characteristics of the source code and external issues. in this way, there is still a lack of knowledge on the core issues of confusing code. this knowledge is important for optimizing efforts in promoting program comprehension. goal. in this paper, we investigate the social representations of confusing code among two distinct communities of software developers from industry. method. we conducted free association tasks with the developers to characterize what is in their minds about confusing code. then, we compiled and classified the associations composing the social representations of confusing code by each community. finally, we compared the social representations from both communities. results. we found that developers of both communities strongly associate confusing code with a common set of undesirable characteristics of the source code, such as different types of code smells and the badly naming of code elements. besides, we found that the incidence of confusing code is a potential source of discouragement and conflict. in this way, we discuss alternatives for development teams overcoming these issues. conclusion. the findings of our study reveal an initial set of core issues of confusing code. these issues can drive future investigations on technologies for promoting code comprehension.",decoding confusing code: social representations among developers
241,2-s2.0-85113701509,10.1109/MSR52588.2021.00037,On the use of dependabot security pull requests,Alfadel M.,"Proceedings - 2021 IEEE/ACM 18th International Conference on Mining Software Repositories, MSR 2021",2021-05-01,"Vulnerable dependencies are a major problem in modern software development. As software projects depend on multiple external dependencies, developers struggle to constantly track and check for corresponding security vulnerabilities that affect their project dependencies. To help mitigate this issue, Dependabot has been created, a bot that issues pull-requests to automatically update vulnerable dependencies. However, little is known about the degree to which developers adopt Dependabot to help them update vulnerable dependencies.In this paper, we investigate 2, 904 JavaScript open-source GitHub projects that subscribed to Dependabot. Our results show that the vast majority (65.42%) of the created security-related pull-requests are accepted, often merged within a day. Through manual analysis, we identify 7 main reasons for Dependabot security pull-requests not being merged, mostly related to concurrent modifications of the affected dependencies rather than Dependabot failures. Interestingly, only 3.2% of the manually examined pull-requests suffered from build breakages. Finally, we model the time it takes to merge a Dependabot security pull-request using characteristics from projects, the fixed vulnerabilities and issued pull requests. Our model reveals 5 significant features to explain merge times, e.g., projects with relevant experience with Dependabot security pull-requests are most likely associated with rapid merges. Surprisingly, the severity of the dependency vulnerability and the potential risk of breaking changes are not strongly associated with the merge time. To the best of our knowledge, this study is the first to evaluate how developers receive Dependabot's security contributions. Our findings indicate that Dependabot provides an effective platform for increasing awareness of dependency vulnerabilities and helps developers mitigate vulnerability threats in JavaScript projects.",Dependabot | Dependency | Pull request | Security vulnerability,3,254-265,Conference Proceeding,Conference Paper,4.0,"Alfadel, Mahmoud;Costa, Diego Elias;Shihab, Emad;Mkhallalati, Mouafak",57193697408;57198365954;23566819100;57233966400,Concordia University,Canada,"vulnerable dependencies are a major problem in modern software development. as software projects depend on multiple external dependencies, developers struggle to constantly track and check for corresponding security vulnerabilities that affect their project dependencies. to help mitigate this issue, dependabot has been created, a bot that issues pull-requests to automatically update vulnerable dependencies. however, little is known about the degree to which developers adopt dependabot to help them update vulnerable dependencies.in this paper, we investigate 2, 904 javascript open-source github projects that subscribed to dependabot. our results show that the vast majority (65.42%) of the created security-related pull-requests are accepted, often merged within a day. through manual analysis, we identify 7 main reasons for dependabot security pull-requests not being merged, mostly related to concurrent modifications of the affected dependencies rather than dependabot failures. interestingly, only 3.2% of the manually examined pull-requests suffered from build breakages. finally, we model the time it takes to merge a dependabot security pull-request using characteristics from projects, the fixed vulnerabilities and issued pull requests. our model reveals 5 significant features to explain merge times, e.g., projects with relevant experience with dependabot security pull-requests are most likely associated with rapid merges. surprisingly, the severity of the dependency vulnerability and the potential risk of breaking changes are not strongly associated with the merge time. to the best of our knowledge, this study is the first to evaluate how developers receive dependabot's security contributions. our findings indicate that dependabot provides an effective platform for increasing awareness of dependency vulnerabilities and helps developers mitigate vulnerability threats in javascript projects.",on the use of dependabot security pull requests
243,2-s2.0-85108007945,10.1109/ICSE-NIER52604.2021.00027,Secure Software Development in the Era of Fluid Multi-party Open Software and Services,Pashchenko I.,Proceedings - International Conference on Software Engineering,2021-05-01,"Pushed by market forces, software development has become fast-paced. As a consequence, modern development projects are assembled from 3rd-party components. Security & privacy assurance techniques once designed for large, controlled updates over months or years, must now cope with small, continuous changes taking place within a week, and happening in sub-components that are controlled by third-party developers one might not even know they existed. In this paper, we aim to provide an overview of the current software security approaches and evaluate their appropriateness in the face of the changed nature in software development. Software security assurance could benefit by switching from a process-based to an artefact-based approach. Further, security evaluation might need to be more incremental, automated and decentralized. We believe this can be achieved by supporting mechanisms for lightweight and scalable screenings that are applicable to the entire population of software components albeit there might be a price to pay.",open source software | software security | vision,1,91-95,Conference Proceeding,Conference Paper,4.0,"Pashchenko, Ivan;Scandariato, Riccardo;Sabetta, Antonino;Massacci, Fabio",57195998561;23095243000;9039083700;55167501300,Università di Trento;Hamburg University of Technology;Vrije Universiteit Amsterdam;SAP Security Research,Italy;Germany;Netherlands;France,"pushed by market forces, software development has become fast-paced. as a consequence, modern development projects are assembled from 3rd-party components. security & privacy assurance techniques once designed for large, controlled updates over months or years, must now cope with small, continuous changes taking place within a week, and happening in sub-components that are controlled by third-party developers one might not even know they existed. in this paper, we aim to provide an overview of the current software security approaches and evaluate their appropriateness in the face of the changed nature in software development. software security assurance could benefit by switching from a process-based to an artefact-based approach. further, security evaluation might need to be more incremental, automated and decentralized. we believe this can be achieved by supporting mechanisms for lightweight and scalable screenings that are applicable to the entire population of software components albeit there might be a price to pay.",secure software development in the era of fluid multi-party open software and services
244,2-s2.0-85106532226,10.1109/ICSE43902.2021.00125,Technical leverage in a software ecosystem: Development opportunities and security risks,Massacci F.,Proceedings - International Conference on Software Engineering,2021-05-01,"In finance, leverage is the ratio between assets borrowed from others and one's own assets. A matching situation is present in software: by using free open-source software (FOSS) libraries a developer leverages on other people's code to multiply the offered functionalities with a much smaller own codebase. In finance as in software, leverage magnifies profits when returns from borrowing exceed costs of integration, but it may also magnify losses, in particular in the presence of security vulnerabilities. We aim to understand the level of technical leverage in the FOSS ecosystem and whether it can be a potential source of security vulnerabilities. Also, we introduce two metrics change distance and change direction to capture the amount and the evolution of the dependency on third-party libraries. The application of the proposed metrics on 8494 distinct library versions from the FOSS Maven-based Java libraries shows that small and medium libraries (less than 100KLoC) have disproportionately more leverage on FOSS dependencies in comparison to large libraries. We show that leverage pays off as leveraged libraries only add a 4% delay in the time interval between library releases while providing four times more code than their own. However, libraries with such leverage (i.e., 75% of libraries in our sample) also have 1.6 higher odds of being vulnerable in comparison to the libraries with lower leverage. We provide an online demo for computing the proposed metrics for real-world software libraries available under the following URL: https://techleverage.eu/",Dependencies | Empirical analysis | Free open source software | Leverage | Maven | Software security | Technical debt | Vulnerabilities,3,1386-1397,Conference Proceeding,Conference Paper,2.0,"Massacci, Fabio;Pashchenko, Ivan",55167501300;57195998561,Università di Trento;Vrije Universiteit Amsterdam,Italy;Netherlands,"in finance, leverage is the ratio between assets borrowed from others and one's own assets. a matching situation is present in software: by using free open-source software (foss) libraries a developer leverages on other people's code to multiply the offered functionalities with a much smaller own codebase. in finance as in software, leverage magnifies profits when returns from borrowing exceed costs of integration, but it may also magnify losses, in particular in the presence of security vulnerabilities. we aim to understand the level of technical leverage in the foss ecosystem and whether it can be a potential source of security vulnerabilities. also, we introduce two metrics change distance and change direction to capture the amount and the evolution of the dependency on third-party libraries. the application of the proposed metrics on 8494 distinct library versions from the foss maven-based java libraries shows that small and medium libraries (less than 100kloc) have disproportionately more leverage on foss dependencies in comparison to large libraries. we show that leverage pays off as leveraged libraries only add a 4% delay in the time interval between library releases while providing four times more code than their own. however, libraries with such leverage (i.e., 75% of libraries in our sample) also have 1.6 higher odds of being vulnerable in comparison to the libraries with lower leverage. we provide an online demo for computing the proposed metrics for real-world software libraries available under the following url: https://techleverage.eu/",technical leverage in a software ecosystem: development opportunities and security risks
245,2-s2.0-85106421990,10.1109/ICSE-Companion52605.2021.00065,JEST: N+1-Version Differential Testing of Both JavaScript Engines and Specification,Park J.,Proceedings - International Conference on Software Engineering,2021-05-01,"Modern programming follows the continuous integration (CI) and continuous deployment (CD) approach rather than the traditional waterfall model. Even the development of modern programming languages uses the CI/CD approach to swiftly provide new language features and to adapt to new development environments. Unlike in the conventional approach, in the modern CI/CD approach, a language specification is no more the oracle of the language semantics because both the specification and its implementations (interpreters or compilers) can co-evolve. In this setting, both the specification and implementations may have bugs, and guaranteeing their correctness is non-trivial. In this paper, we propose a novel N+1-version differential testing to resolve the problem. Unlike the traditional differential testing, our approach consists of three steps: 1) to automatically synthesize programs guided by the syntax and semantics from a given language specification, 2) to generate conformance tests by injecting assertions to the synthesized programs to check their final program states, 3) to detect bugs in the specification and implementations via executing the conformance tests on multiple implementations, and 4) to localize bugs on the specification using statistical information. We actualize our approach for the JavaScript programming language via JEST, which performs N+1-version differential testing for modern JavaScript engines and ECMAScript, the language specification describing the syntax and semantics of JavaScript in a natural language. We evaluated JEST with four JavaScript engines that support all modern JavaScript language features and the latest version of ECMAScript (ES11, 2020). JEST automatically synthesized 1,700 programs that covered 97.78% of syntax and 87.70% of semantics from ES11. Using the assertion-injected JavaScript programs, it detected 44 engine bugs in four different engines and 27 specification bugs in ES11.",conformance test generation | differential testing | JavaScript | mechanized specification,5,156-157,Conference Proceeding,Conference Paper,5.0,"Park, Jihyeok;An, Seungmin;Youn, Dongjun;Kim, Gyeongwon;Ryu, Sukyoung",56152898400;57221467825;57222269122;57222275939;22735372000,Korea Advanced Institute of Science and Technology,South Korea,"modern programming follows the continuous integration (ci) and continuous deployment (cd) approach rather than the traditional waterfall model. even the development of modern programming languages uses the ci/cd approach to swiftly provide new language features and to adapt to new development environments. unlike in the conventional approach, in the modern ci/cd approach, a language specification is no more the oracle of the language semantics because both the specification and its implementations (interpreters or compilers) can co-evolve. in this setting, both the specification and implementations may have bugs, and guaranteeing their correctness is non-trivial. in this paper, we propose a novel n+1-version differential testing to resolve the problem. unlike the traditional differential testing, our approach consists of three steps: 1) to automatically synthesize programs guided by the syntax and semantics from a given language specification, 2) to generate conformance tests by injecting assertions to the synthesized programs to check their final program states, 3) to detect bugs in the specification and implementations via executing the conformance tests on multiple implementations, and 4) to localize bugs on the specification using statistical information. we actualize our approach for the javascript programming language via jest, which performs n+1-version differential testing for modern javascript engines and ecmascript, the language specification describing the syntax and semantics of javascript in a natural language. we evaluated jest with four javascript engines that support all modern javascript language features and the latest version of ecmascript (es11, 2020). jest automatically synthesized 1,700 programs that covered 97.78% of syntax and 87.70% of semantics from es11. using the assertion-injected javascript programs, it detected 44 engine bugs in four different engines and 27 specification bugs in es11.",jest: n+1-version differential testing of both javascript engines and specification
247,2-s2.0-85105550040,10.1016/j.cirpj.2021.04.003,Modeling and software implementation of manufacturing costs in additive manufacturing,Yi L.,CIRP Journal of Manufacturing Science and Technology,2021-05-01,"Quantification and analysis of manufacturing costs in additive manufacturing (AM) are important research tasks, since materials and machines for AM are relatively expensive. To enable the cost estimation in AM, a number of studies have focused on the development of cost estimation software tools for AM. However, these studies mainly focused on single AM systems and materials pre-selected for individual cases. The literature still lacks of a more general perspective on the cost factors and cost structure in different AM processes. Addressing this issue, this paper contributes a general cost model for AM processes and the development of a cost estimation application (App) based on the model. The developed App covers a variety of AM materials and systems. In order to validate the usability of the App, three use cases are performed. The result of the use cases demonstrates that the App, as well as the underlying cost model, is a powerful tool for estimating and assessing the build cost of AM in different design issues.",Additive manufacturing | Cost estimation | Cost model | Mobile phone App,0,380-388,Journal,Article,4.0,"Yi, Li;Ehmsen, Svenja;Glatt, Moritz;Aurich, Jan C.",57201704345;57219371645;57202854393;7005485993,Technische Universität Kaiserslautern,Germany,"quantification and analysis of manufacturing costs in additive manufacturing (am) are important research tasks, since materials and machines for am are relatively expensive. to enable the cost estimation in am, a number of studies have focused on the development of cost estimation software tools for am. however, these studies mainly focused on single am systems and materials pre-selected for individual cases. the literature still lacks of a more general perspective on the cost factors and cost structure in different am processes. addressing this issue, this paper contributes a general cost model for am processes and the development of a cost estimation application (app) based on the model. the developed app covers a variety of am materials and systems. in order to validate the usability of the app, three use cases are performed. the result of the use cases demonstrates that the app, as well as the underlying cost model, is a powerful tool for estimating and assessing the build cost of am in different design issues.",modeling and software implementation of manufacturing costs in additive manufacturing
249,2-s2.0-85104812176,10.1109/MSR52588.2021.00054,How do software developers use github actions to automate their workflows?,Kinsman T.,"Proceedings - 2021 IEEE/ACM 18th International Conference on Mining Software Repositories, MSR 2021",2021-05-01,"Automated tools are frequently used in social coding repositories to perform repetitive activities that are part of the distributed software development process. Recently, GitHub introduced GitHub Actions, a feature providing automated work-flows for repository maintainers. Although several Actions have been built and used by practitioners, relatively little has been done to evaluate them. Understanding and anticipating the effects of adopting such kind of technology is important for planning and management. Our research is the first to investigate how developers use Actions and how several activity indicators change after their adoption. Our results indicate that, although only a small subset of repositories adopted GitHub Actions to date, there is a positive perception of the technology. Our findings also indicate that the adoption of GitHub Actions increases the number of monthly rejected pull requests and decreases the monthly number of commits on merged pull requests. These results are especially relevant for practitioners to understand and prevent undesirable effects on their projects.",Automated work-flow | GitHub Actions | GitHub Bots | Regression Discontinuity Design,2,420-431,Conference Proceeding,Conference Paper,4.0,"Kinsman, Timothy;Wessel, Mairieli;Gerosa, Marco A.;Treude, Christoph",57222719490;57204421132;10043515400;23135531900,Northern Arizona University;The University of Adelaide;Universidade de São Paulo,United States;Australia;Brazil,"automated tools are frequently used in social coding repositories to perform repetitive activities that are part of the distributed software development process. recently, github introduced github actions, a feature providing automated work-flows for repository maintainers. although several actions have been built and used by practitioners, relatively little has been done to evaluate them. understanding and anticipating the effects of adopting such kind of technology is important for planning and management. our research is the first to investigate how developers use actions and how several activity indicators change after their adoption. our results indicate that, although only a small subset of repositories adopted github actions to date, there is a positive perception of the technology. our findings also indicate that the adoption of github actions increases the number of monthly rejected pull requests and decreases the monthly number of commits on merged pull requests. these results are especially relevant for practitioners to understand and prevent undesirable effects on their projects.",how do software developers use github actions to automate their workflows?
253,2-s2.0-85099921767,10.4018/IJEHMC.20210501.oa1,Regulations and standards aware framework for recording of mhealth app vulnerabilities,Prodanoff Z.,International Journal of E-Health and Medical Communications,2021-05-01,"The authors describe a standards-based security framework for the purposes of recording security and privacy vulnerabilities discovered in mHealth apps. The proposed framework is compliant with the international standard for software architecture descriptions, ISO/IEC/IEEE 42010, relevant state-agency regulations, and US federal healthcare mandates, as well as computing standards for data interchange formats. Future real-life implementations are envisioned to consists of three key components: (1) design and implementation of a repository that links vulnerabilities to concepts from the taxonomy used by legislative and standardization bodies; (2) population of the repository with security vulnerability descriptions that follow a standard format, such as JavaScript Object Notation (JSON); and (3) implementation of a searchable user interface (e.g., Google’s Firebase UI), which allows for aggregation statistics, data analytics, as well as public access to the repository. The proposed framework design promotes timely updates of regulations, standardization drafts, and app development platforms.",BLE | EHR | IoT | MHealth | Privacy | Regulation | RFID | Security | Standard | Vulnerability Recording,1,1-16,Journal,Article,3.0,"Prodanoff, Zornitza;White-Williams, Cynthia;Chi, Hongmei",6507885711;56538250200;8888500200,Florida Agricultural and Mechanical University;University of North Florida,United States;United States,"the authors describe a standards-based security framework for the purposes of recording security and privacy vulnerabilities discovered in mhealth apps. the proposed framework is compliant with the international standard for software architecture descriptions, iso/iec/ieee 42010, relevant state-agency regulations, and us federal healthcare mandates, as well as computing standards for data interchange formats. future real-life implementations are envisioned to consists of three key components: (1) design and implementation of a repository that links vulnerabilities to concepts from the taxonomy used by legislative and standardization bodies; (2) population of the repository with security vulnerability descriptions that follow a standard format, such as javascript object notation (json); and (3) implementation of a searchable user interface (e.g., google’s firebase ui), which allows for aggregation statistics, data analytics, as well as public access to the repository. the proposed framework design promotes timely updates of regulations, standardization drafts, and app development platforms.",regulations and standards aware framework for recording of mhealth app vulnerabilities
255,2-s2.0-85112474416,10.1109/EDUCON46332.2021.9454034,Open-source multi-purpose remote laboratory for IoT education,Pirrone D.,"IEEE Global Engineering Education Conference, EDUCON",2021-04-21,"With the constant growth of devices connected to the internet, many researchers focus their interest on the development of Remote Laboratories, taking advantage of the numerous electronic open-source platforms. The aim of this work is to propose a compact solution (hardware and software) for the implementation of a low-cost open-access remote laboratory. The key concept is using Python, a programming language that is strong, flexible and rich of free external packages. Specifically, Python is used at the same time as: (i) a microframework with server functionalities, (ii) a control unit that drives an Arduino microcontroller and a Raspberry Pi microcomputer. The software to access the laboratory is realized as a web client interface by using HTML5 and JavaScript. This software is light enough to be run on an average personal computer. The concept of Remote Laboratory allows students to be able to carry out didactic experiences without constraints with regard to space and time, being it accessible from everywhere with just a PC or even a smart device (smartphone, tablet, etc.). With this remote laboratory, students can do real measurements of physical quantities and perform real activities while accessing the system from any place, thus allowing students of distance learning universities to do real experiments.",Arduino | IoT education | Python | Remote Laboratory,4,1462-1468,Conference Proceeding,Conference Paper,3.0,"Pirrone, Daniele;Fornaro, Claudio;Assante, Dario",57188746409;56084537600;8572725600,Università Telematica Internazionale UNINETTUNO,Italy,"with the constant growth of devices connected to the internet, many researchers focus their interest on the development of remote laboratories, taking advantage of the numerous electronic open-source platforms. the aim of this work is to propose a compact solution (hardware and software) for the implementation of a low-cost open-access remote laboratory. the key concept is using python, a programming language that is strong, flexible and rich of free external packages. specifically, python is used at the same time as: (i) a microframework with server functionalities, (ii) a control unit that drives an arduino microcontroller and a raspberry pi microcomputer. the software to access the laboratory is realized as a web client interface by using html5 and javascript. this software is light enough to be run on an average personal computer. the concept of remote laboratory allows students to be able to carry out didactic experiences without constraints with regard to space and time, being it accessible from everywhere with just a pc or even a smart device (smartphone, tablet, etc.). with this remote laboratory, students can do real measurements of physical quantities and perform real activities while accessing the system from any place, thus allowing students of distance learning universities to do real experiments.",open-source multi-purpose remote laboratory for iot education
256,2-s2.0-85112407124,10.1109/EDUCON46332.2021.9453917,Classification and analysis of techniques and tools for data visualization teaching,Cuadrado-Gallego J.J.,"IEEE Global Engineering Education Conference, EDUCON",2021-04-21,"Data Visualization addresses the use of graphics with the purpose to obtain or transmit the knowledge in a easier and faster way, this is it main, and in many cases unique purpose. Since their invention Data graphics has evolved and many techniques has been developed, and in the last decades, with the definition and evolution of the Data Science, Data Visualization has become to be used profusely, in that manner that, by one side, the Data Science Body of Knowledge, DS-BoK, define five knowledge area groups that should be taught when learning Data Science, in all of them Data Visualization is taken a main role for different reasons applying each knowledge area; and by other side all the Data Science development environments, open source or proprietary, include tools for performing Data Visualizations. This paper presents the results of a research carried out with the main objective of improving the teaching of data visualization using two ways: propose a new system to classify the large amount of different graphical techniques for presenting data that can be found in the literature; and analyze using different attributes quite all the most important different tools, open source and private, that are available to develop data graphics mainly form a data visualization teaching point of view.",Data Science | Data Science Education | Data Visualizaion | Data Visualization Education | Engineering Education | Explanatory Graphs | Explorative Graphs | Open Software Visualization Tools | Propietary Software Visualization Tools,1,1593-1599,Conference Proceeding,Conference Paper,4.0,"Cuadrado-Gallego, Juan J.;Demchenko, Yuri;Losada, Miguel A.;Ormandjieva, Olga",8504946900;8904483500;57226719838;57203257339,Concordia University;Universidad de Alcalá;Universiteit van Amsterdam,Canada;Spain;Netherlands,"data visualization addresses the use of graphics with the purpose to obtain or transmit the knowledge in a easier and faster way, this is it main, and in many cases unique purpose. since their invention data graphics has evolved and many techniques has been developed, and in the last decades, with the definition and evolution of the data science, data visualization has become to be used profusely, in that manner that, by one side, the data science body of knowledge, ds-bok, define five knowledge area groups that should be taught when learning data science, in all of them data visualization is taken a main role for different reasons applying each knowledge area; and by other side all the data science development environments, open source or proprietary, include tools for performing data visualizations. this paper presents the results of a research carried out with the main objective of improving the teaching of data visualization using two ways: propose a new system to classify the large amount of different graphical techniques for presenting data that can be found in the literature; and analyze using different attributes quite all the most important different tools, open source and private, that are available to develop data graphics mainly form a data visualization teaching point of view.",classification and analysis of techniques and tools for data visualization teaching
259,2-s2.0-85108030680,10.1109/ICSTW52544.2021.00051,AI-based test automation: A grey literature analysis,Ricca F.,"Proceedings - 2021 IEEE 14th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2021",2021-04-01,"This paper provides the results of a survey of the grey literature concerning the use of artificial intelligence to improve test automation practices. We surveyed more than 1, 200 sources of grey literature (e.g., blogs, white-papers, user manuals, StackOverflow posts) looking for highlights by professionals on how AI is adopted to aid the development and evolution of test code. Ultimately, we filtered 136 relevant documents from which we extracted a taxonomy of problems that AI aims to tackle, along with a taxonomy of AI-enabled solutions to such problems. Manual code development and automated test generation are the most cited problem and solution, respectively. The paper concludes by distilling the six most prevalent tools on the market, along with think-aloud reflections about the current and future status of artificial intelligence for test automation.",Artificial intelligence | Grey literature | Test automation,1,263-270,Conference Proceeding,Conference Paper,3.0,"Ricca, Filippo;Marchetto, Alessandro;Stocco, Andrea",24822686600;23971457800;36882807000,Università degli Studi di Genova;Independent Researcher;Software Institute,Italy;;Switzerland,"this paper provides the results of a survey of the grey literature concerning the use of artificial intelligence to improve test automation practices. we surveyed more than 1, 200 sources of grey literature (e.g., blogs, white-papers, user manuals, stackoverflow posts) looking for highlights by professionals on how ai is adopted to aid the development and evolution of test code. ultimately, we filtered 136 relevant documents from which we extracted a taxonomy of problems that ai aims to tackle, along with a taxonomy of ai-enabled solutions to such problems. manual code development and automated test generation are the most cited problem and solution, respectively. the paper concludes by distilling the six most prevalent tools on the market, along with think-aloud reflections about the current and future status of artificial intelligence for test automation.",ai-based test automation: a grey literature analysis
260,2-s2.0-85107942058,10.1109/ICST49551.2021.00044,Type-Centric Kotlin Compiler Fuzzing: Preserving Test Program Correctness by Preserving Types,Stepanov D.,"Proceedings - 2021 IEEE 14th International Conference on Software Testing, Verification and Validation, ICST 2021",2021-04-01,"Kotlin is a relatively new programming language from JetBrains: its development started in 2010 with release 1.0 done in early 2016. The Kotlin compiler, while slowly and steadily becoming more and more mature, still crashes from time to time on the more tricky input programs, not least because of the complexity of its features and their interactions. This makes it a great target for fuzzing, even the basic forms of which can find a significant number of Kotlin compiler crashes.There is a problem with fuzzing, however, closely related to the cause of the crashes: generating a random, non-trivial and semantically valid Kotlin program is hard. In this paper, we talk about type-centric compiler fuzzing in the form of type-centric enumeration, an approach inspired by skeletal program enumeration [1] and based on a combination of generative and mutation-based fuzzing, which solves this problem by focusing on program types. After creating the skeleton program, we fill the typed holes with fragments of suitable type, created via generation and enhanced by semantic-aware mutation.We implemented this approach in our Kotlin compiler fuzzing framework called Backend Bug Finder (BBF) and did an extensive evaluation, not only testing the real-world feasibility of our approach, but also comparing it to other compiler fuzzing techniques. The results show our approach to be significantly better compared to other fuzzing approaches at generating semantically valid Kotlin programs, while creating more interesting crash-inducing inputs at the same time. We managed to find more than 50 previously unknown compiler crashes, of which 18 were considered important after their triage by the compiler team.",compiler testing | program fuzzing | semantic fuzzing,1,318-328,Conference Proceeding,Conference Paper,3.0,"Stepanov, Daniil;Akhin, Marat;Belyaev, Mikhail",57200209430;36237450200;7003903519,Peter the Great St. Petersburg Polytechnic University,Russian Federation,"kotlin is a relatively new programming language from jetbrains: its development started in 2010 with release 1.0 done in early 2016. the kotlin compiler, while slowly and steadily becoming more and more mature, still crashes from time to time on the more tricky input programs, not least because of the complexity of its features and their interactions. this makes it a great target for fuzzing, even the basic forms of which can find a significant number of kotlin compiler crashes.there is a problem with fuzzing, however, closely related to the cause of the crashes: generating a random, non-trivial and semantically valid kotlin program is hard. in this paper, we talk about type-centric compiler fuzzing in the form of type-centric enumeration, an approach inspired by skeletal program enumeration [1] and based on a combination of generative and mutation-based fuzzing, which solves this problem by focusing on program types. after creating the skeleton program, we fill the typed holes with fragments of suitable type, created via generation and enhanced by semantic-aware mutation.we implemented this approach in our kotlin compiler fuzzing framework called backend bug finder (bbf) and did an extensive evaluation, not only testing the real-world feasibility of our approach, but also comparing it to other compiler fuzzing techniques. the results show our approach to be significantly better compared to other fuzzing approaches at generating semantically valid kotlin programs, while creating more interesting crash-inducing inputs at the same time. we managed to find more than 50 previously unknown compiler crashes, of which 18 were considered important after their triage by the compiler team.",type-centric kotlin compiler fuzzing: preserving test program correctness by preserving types
261,2-s2.0-85106263776,10.1007/s10009-021-00609-z,A taxonomy for classifying runtime verification tools,Falcone Y.,International Journal on Software Tools for Technology Transfer,2021-04-01,"Over the last 20 years, runtime verification (RV) has grown into a diverse and active field, which has stimulated the development of numerous theoretical frameworks and practical tools. Many of the tools are at first sight very different and challenging to compare. Yet, there are similarities. In this work, we classify RV tools within a high-level taxonomy of concepts. We first present this taxonomy and discuss its different dimensions. Then, we survey the existing RV tools and, where possible with the support of tool authors, classify them according to the taxonomy. While the classification continually evolves, this article presents a snapshot with 60 state-of-the-art RV tools. We believe that this work is an important step in establishing a common terminology in RV and enabling a meaningful comparison of existing RV tools.",Classification | Mindmap | Runtime verification | Taxonomy | Tool,12,255-284,Journal,Article,4.0,"Falcone, Yliès;Krstić, Srđan;Reger, Giles;Traytel, Dmitriy",19638327600;56160057500;55354212200;54788576900,Universite Grenoble Alpes;Københavns Universitet;ETH Zürich;The University of Manchester,France;Denmark;Switzerland;United Kingdom,"over the last 20 years, runtime verification (rv) has grown into a diverse and active field, which has stimulated the development of numerous theoretical frameworks and practical tools. many of the tools are at first sight very different and challenging to compare. yet, there are similarities. in this work, we classify rv tools within a high-level taxonomy of concepts. we first present this taxonomy and discuss its different dimensions. then, we survey the existing rv tools and, where possible with the support of tool authors, classify them according to the taxonomy. while the classification continually evolves, this article presents a snapshot with 60 state-of-the-art rv tools. we believe that this work is an important step in establishing a common terminology in rv and enabling a meaningful comparison of existing rv tools.",a taxonomy for classifying runtime verification tools
264,2-s2.0-85104651668,10.1109/ICCQ51190.2021.9392984,Towards a prototype based explainable javascript vulnerability prediction model,Mosolygo B.,"2021 International Conference on Code Quality, ICCQ 2021",2021-03-27,"Security has become a central and unavoidable aspect of today's software development. Practitioners and researchers have proposed many code analysis tools and techniques to mitigate security risks. These tools apply static and dynamic analysis or, more recently, machine learning. Machine learning models can achieve impressive results in finding and forecasting possible security issues in programs. However, most of the current approaches fall short of developer demands in two areas at least: Explainability and granularity of predictions. In this paper, we propose a novel and simple yet, promising approach to identify potentially vulnerable source code in JavaScript programs. The model improves the state-of-the-art in terms of explainability and prediction granularity as it gives results at the level of individual source code lines, which is fine-grained enough for developers to take immediate actions. Additionally, the model explains each predicted line (i.e., provides the most similar vulnerable line from the training set) using a prototype-based approach. In a study of 186 real-world and confirmed JavaScript vulnerability fixes of 91 projects, the approach could flag 60% of the known vulnerable lines on average by marking only 10% of the code-base, but in particular cases, the model identified 100% of the vulnerable code lines while flagging only 8.72% of the code-base.",CVE | data mining | explainable ML | software security | vulnerability prediction,3,15-25,Conference Proceeding,Conference Paper,5.0,"Mosolygo, Balazs;Vandor, Norbert;Antal, Gabor;Hegedus, Peter;Ferenc, Rudolf",57219332393;57219330885;6701427737;25926433300;6603559878,Szegedi Tudományegyetem (SZTE),Hungary,"security has become a central and unavoidable aspect of today's software development. practitioners and researchers have proposed many code analysis tools and techniques to mitigate security risks. these tools apply static and dynamic analysis or, more recently, machine learning. machine learning models can achieve impressive results in finding and forecasting possible security issues in programs. however, most of the current approaches fall short of developer demands in two areas at least: explainability and granularity of predictions. in this paper, we propose a novel and simple yet, promising approach to identify potentially vulnerable source code in javascript programs. the model improves the state-of-the-art in terms of explainability and prediction granularity as it gives results at the level of individual source code lines, which is fine-grained enough for developers to take immediate actions. additionally, the model explains each predicted line (i.e., provides the most similar vulnerable line from the training set) using a prototype-based approach. in a study of 186 real-world and confirmed javascript vulnerability fixes of 91 projects, the approach could flag 60% of the known vulnerable lines on average by marking only 10% of the code-base, but in particular cases, the model identified 100% of the vulnerable code lines while flagging only 8.72% of the code-base.",towards a prototype based explainable javascript vulnerability prediction model
266,2-s2.0-85113890476,10.1145/3464432.3464437,Towards End-User Web Scraping for Customization,Katongo K.,ACM International Conference Proceeding Series,2021-03-22,"Websites are malleable: users can run code in the browser to customize them. However, this malleability is typically only accessible to programmers with knowledge of HTML and Javascript. Previously, we developed a tool called Wildcard which empowers end-users to customize websites through a spreadsheet-like table interface without doing traditional programming. However, there is a limit to end-user agency with Wildcard, because programmers need to first create site-specific adapters mapping website data to the table interface. This means that end-users can only customize a website if a programmer has written an adapter for it, and cannot extend or repair existing adapters. In this paper, we extend Wildcard with a new system for end-user web scraping for customization. It enables end-users to create, extend and repair adapters, by performing concrete demonstrations of how the website user interface maps to a data table. We describe three design principles that guided our system's development and are applicable to other end-user web scraping and customization systems: (a) users should be able to scrape data and use it in a single, unified environment, (b) users should be able to extend and repair the programs that scrape data via demonstration and (c) users should receive live feedback during their demonstrations. We have successfully used our system to create, extend and repair adapters by demonstration on a variety of websites and we provide example usage scenarios that showcase each of our design principles. Our ultimate goal is to empower end-users to customize websites in the course of their daily use in an intuitive and flexible way, and thus making the web more malleable for all of its users.",browser extensions | end-user programming | software customization | spreadsheets | web scraping,0,49-59,Conference Proceeding,Conference Paper,3.0,"Katongo, Kapaya;Litt, Geoffrey;Jackson, Daniel",57238289900;57218707319;7404288974,MIT Computer Science &amp; Artificial Intelligence Laboratory,United States,"websites are malleable: users can run code in the browser to customize them. however, this malleability is typically only accessible to programmers with knowledge of html and javascript. previously, we developed a tool called wildcard which empowers end-users to customize websites through a spreadsheet-like table interface without doing traditional programming. however, there is a limit to end-user agency with wildcard, because programmers need to first create site-specific adapters mapping website data to the table interface. this means that end-users can only customize a website if a programmer has written an adapter for it, and cannot extend or repair existing adapters. in this paper, we extend wildcard with a new system for end-user web scraping for customization. it enables end-users to create, extend and repair adapters, by performing concrete demonstrations of how the website user interface maps to a data table. we describe three design principles that guided our system's development and are applicable to other end-user web scraping and customization systems: (a) users should be able to scrape data and use it in a single, unified environment, (b) users should be able to extend and repair the programs that scrape data via demonstration and (c) users should receive live feedback during their demonstrations. we have successfully used our system to create, extend and repair adapters by demonstration on a variety of websites and we provide example usage scenarios that showcase each of our design principles. our ultimate goal is to empower end-users to customize websites in the course of their daily use in an intuitive and flexible way, and thus making the web more malleable for all of its users.",towards end-user web scraping for customization
269,2-s2.0-85106637907,10.1109/ECTIDAMTNCON51128.2021.9425735,The Development of Application for Advice and Diagnosis of Diseases in Dogs,Janthajirakowit C.,"2021 Joint 6th International Conference on Digital Arts, Media and Technology with 4th ECTI Northern Section Conference on Electrical, Electronics, Computer and Telecommunication Engineering, ECTI DAMT and NCON 2021",2021-03-03,"The research aims to study and design an application to advise and diagnose dog's health. In this work, the development process of the application not only present but also the performance of the application usage evaluated. This work consists of the following two steps. Firstly, we present the software development process from collecting the user requirement to the software installation. Next, the evaluation of the application usage is obtained from a questionnaire, collected from users the user can be divided into two groups: expert-users and end-users the collected data analyzed and presented by the mean and standard deviation the experimental results show that the satisfaction level is good therefore, the proposed work can widely use as a first diagnose dog's health tool.",Decision Tree | Dog Health | Dogs Disease,0,132-135,Conference Proceeding,Conference Paper,3.0,"Janthajirakowit, Chalida;Fongmanee, Srinuan;Chaikhamwang, Sumran",57209103761;57209096388;57209096130,Chiang Rai Rajabhat University,Thailand,"the research aims to study and design an application to advise and diagnose dog's health. in this work, the development process of the application not only present but also the performance of the application usage evaluated. this work consists of the following two steps. firstly, we present the software development process from collecting the user requirement to the software installation. next, the evaluation of the application usage is obtained from a questionnaire, collected from users the user can be divided into two groups: expert-users and end-users the collected data analyzed and presented by the mean and standard deviation the experimental results show that the satisfaction level is good therefore, the proposed work can widely use as a first diagnose dog's health tool.",the development of application for advice and diagnosis of diseases in dogs
270,2-s2.0-85106606585,10.1109/SANER50967.2021.00062,Automatically Customizing Static Analysis Tools to Coding Rules Really Followed by Developers,Ueda Y.,"Proceedings - 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2021",2021-03-01,"Automatic Static Analysis Tools (ASATs) detect coding rule violations, including mistakes and bad practices that frequently occur during programming. While ASATs are widely used in both OSS and industry, the developers do not resolve more than 80% of the detected violations. As one of the reasons, most ASATs users do not customize their ASATs to their projects after installation; the ASATs with the default configuration report many rule violations that confuse developers. To reduce the ratio of such uninteresting warning messages, we propose a method to customize ASATs according to the product source code automatically. Our fundamental hypothesis is: A software project has interesting ASAT rules that are consistent over time. Our method takes source code as input and generates an ASAT configuration. In particular, the method enables optional (i.e., disabled by default) rules that detected no violations on the version because developers are likely to follow the rules in future development. Our method also disables violated rules because developers were unlikely to follow them. To evaluate the method, we applied our method to 643 versions of four JavaScript projects. The generated configurations for all four projects increased the ASAT precision. They also increased recall for two projects. The result shows that our method helps developers to focus on their attractive rule violations. Our implementation of the proposed method is available at https://github.com/devreplay/linter-maintainer",Coding Convention | Coding Rule | Empirical Study | Static Analysis Tools,1,541-545,Conference Proceeding,Conference Paper,3.0,"Ueda, Yuki;Ishio, Takashi;Matsumoto, Kenichi",57189510774;8381338700;55378267900,Nara Institute of Science and Technology,Japan,"automatic static analysis tools (asats) detect coding rule violations, including mistakes and bad practices that frequently occur during programming. while asats are widely used in both oss and industry, the developers do not resolve more than 80% of the detected violations. as one of the reasons, most asats users do not customize their asats to their projects after installation; the asats with the default configuration report many rule violations that confuse developers. to reduce the ratio of such uninteresting warning messages, we propose a method to customize asats according to the product source code automatically. our fundamental hypothesis is: a software project has interesting asat rules that are consistent over time. our method takes source code as input and generates an asat configuration. in particular, the method enables optional (i.e., disabled by default) rules that detected no violations on the version because developers are likely to follow the rules in future development. our method also disables violated rules because developers were unlikely to follow them. to evaluate the method, we applied our method to 643 versions of four javascript projects. the generated configurations for all four projects increased the asat precision. they also increased recall for two projects. the result shows that our method helps developers to focus on their attractive rule violations. our implementation of the proposed method is available at https://github.com/devreplay/linter-maintainer",automatically customizing static analysis tools to coding rules really followed by developers
271,2-s2.0-85106569051,10.1109/SANER50967.2021.00048,Empirical Analysis of Security Vulnerabilities in Python Packages,Alfadel M.,"Proceedings - 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2021",2021-03-01,"Software ecosystems play an important role in modern software development, providing an open platform of reusable packages that speed up and facilitate development tasks. However, this level of code reusability supported by software ecosystems also makes the discovery of security vulnerabilities much more difficult, as software systems depend on an increasingly high number of packages. Recently, security vulnerabilities in the npm ecosystem, the ecosystem of Node.js packages, have been studied in the literature. As different software ecosystems embodied different programming languages and particularities, we argue that it is also important to study other popular programming languages to build stronger empirical evidence about vulnerabilities in software ecosystems.In this paper, we present an empirical study of 550 vulnerability reports affecting 252 Python packages in the Python ecosystem (PyPi). In particular, we study the propagation and life span of security vulnerabilities, accounting for how long they take to be discovered and fixed. Our findings show that the discovered vulnerabilities in Python packages are increasing over time, and they take more than 3 years to be discovered. The majority of these vulnerabilities (50.55%) are only fixed after being publicly announced, giving ample time for attackers exploitation. We find similarities in some characteristics of vulnerabilities in PyPi and npm and divergences that can be attributed to specific PyPi policies. By leveraging our findings, we provide a series of implications that can help the security of software ecosystems by improving the process of discovering, fixing and managing package vulnerabilities.",empirical studies | packages | pypi | python | vulnerabilities,9,446-457,Conference Proceeding,Conference Paper,3.0,"Alfadel, Mahmoud;Costa, Diego Elias;Shihab, Emad",57193697408;57198365954;23566819100,Concordia University,Canada,"software ecosystems play an important role in modern software development, providing an open platform of reusable packages that speed up and facilitate development tasks. however, this level of code reusability supported by software ecosystems also makes the discovery of security vulnerabilities much more difficult, as software systems depend on an increasingly high number of packages. recently, security vulnerabilities in the npm ecosystem, the ecosystem of node.js packages, have been studied in the literature. as different software ecosystems embodied different programming languages and particularities, we argue that it is also important to study other popular programming languages to build stronger empirical evidence about vulnerabilities in software ecosystems.in this paper, we present an empirical study of 550 vulnerability reports affecting 252 python packages in the python ecosystem (pypi). in particular, we study the propagation and life span of security vulnerabilities, accounting for how long they take to be discovered and fixed. our findings show that the discovered vulnerabilities in python packages are increasing over time, and they take more than 3 years to be discovered. the majority of these vulnerabilities (50.55%) are only fixed after being publicly announced, giving ample time for attackers exploitation. we find similarities in some characteristics of vulnerabilities in pypi and npm and divergences that can be attributed to specific pypi policies. by leveraging our findings, we provide a series of implications that can help the security of software ecosystems by improving the process of discovering, fixing and managing package vulnerabilities.",empirical analysis of security vulnerabilities in python packages
274,2-s2.0-85099090056,10.1007/s11219-020-09537-8,Exposing bugs in JavaScript engines through test transplantation and differential testing,Lima I.,Software Quality Journal,2021-03-01,"JavaScript is a popular programming language today with several implementations competing for market dominance. Although a specification document and a conformance test suite exist to guide engine development, bugs occur and have important practical consequences. Implementing correct engines is challenging because the spec is intentionally incomplete and evolves frequently. This paper investigates the use of test transplantation and differential testing for revealing functional bugs in JavaScript engines. The former technique runs the regression test suite of a given engine on another engine. The latter technique fuzzes existing inputs and then compares the output produced by different engines with a differential oracle. We conducted experiments with engines from five major players—Apple, Facebook, Google, Microsoft, and Mozilla—to assess the effectiveness of test transplantation and differential testing. Our results indicate that both techniques revealed several bugs, many of which are confirmed by developers. We reported 35 bugs with test transplantation (23 of these bugs confirmed and 19 fixed) and reported 24 bugs with differential testing (17 of these confirmed and 10 fixed). Results indicate that most of these bugs affected two engines—Apple’s JSC and Microsoft’s ChakraCore (24 and 26 bugs, respectively). To summarize, our results show that test transplantation and differential testing are easy to apply and very effective in finding bugs in complex software, such as JavaScript engines.",Differential testing | JavaScript | Test transplantation,0,129-158,Journal,Article,5.0,"Lima, Igor;Silva, Jefferson;Miranda, Breno;Pinto, Gustavo;d’Amorim, Marcelo",57211588128;57221416514;56405278100;54941690500;8924123600,Universidade Federal de Pernambuco;Clinical Hospital of Federal University,Brazil;Brazil,"javascript is a popular programming language today with several implementations competing for market dominance. although a specification document and a conformance test suite exist to guide engine development, bugs occur and have important practical consequences. implementing correct engines is challenging because the spec is intentionally incomplete and evolves frequently. this paper investigates the use of test transplantation and differential testing for revealing functional bugs in javascript engines. the former technique runs the regression test suite of a given engine on another engine. the latter technique fuzzes existing inputs and then compares the output produced by different engines with a differential oracle. we conducted experiments with engines from five major players—apple, facebook, google, microsoft, and mozilla—to assess the effectiveness of test transplantation and differential testing. our results indicate that both techniques revealed several bugs, many of which are confirmed by developers. we reported 35 bugs with test transplantation (23 of these bugs confirmed and 19 fixed) and reported 24 bugs with differential testing (17 of these confirmed and 10 fixed). results indicate that most of these bugs affected two engines—apple’s jsc and microsoft’s chakracore (24 and 26 bugs, respectively). to summarize, our results show that test transplantation and differential testing are easy to apply and very effective in finding bugs in complex software, such as javascript engines.",exposing bugs in javascript engines through test transplantation and differential testing
275,2-s2.0-85098781660,10.1007/s12145-020-00562-6,O-LCMapping: a Google Earth Engine-based web toolkit for supporting online land cover classification,Xing H.,Earth Science Informatics,2021-03-01,"Land cover classification is essential for environmental monitoring, sustainable development goals assessment and other fields. Traditionally, it often takes much time and labor costs to copy and pre-process remote sensing images for performing land cover classification with desktop software, which must be installed and licensed. Google Earth Engine (GEE), as a cloud computing platform, provides a large number of remote sensing images, geoprocessing algorithms and massive computational capabilities via web interfaces. However, GEE requires users to possess programming skills of JavaScript or Python language, which can hinder the enthusiasm of many academics without programming skills. This paper developed a web-based and open-access toolkit O-LCMapping for supporting online land cover classification. This toolkit was implemented with JavaScript application programming interfaces of GEE and integrated ten imagery classification algorithms. The toolkit explicitly provides the entire pipeline of land cover classification in the form of user interfaces for end-users with basic knowledge of remote sensing but little programming skills. Concretely, it enables end-users to define study area, select remote sensing data, mark classification samples, set classification algorithms, evaluate accuracy and output results through user interfaces. Three different experimental cases indicate that the toolkit can be easily applied to different fields for various applications of land cover classification.",Cloud computing | Google Earth Engine | Land cover classification | Remote sensing | Web-based toolkit,2,529-541,Journal,Article,5.0,"Xing, Huaqiao;Hou, Dongyang;Wang, Siyuan;Yu, Mingyang;Meng, Fei",57212832501;56127746800;57221309141;55475784300;57188574647,Shandong Jianzhu University;Central South University,China;China,"land cover classification is essential for environmental monitoring, sustainable development goals assessment and other fields. traditionally, it often takes much time and labor costs to copy and pre-process remote sensing images for performing land cover classification with desktop software, which must be installed and licensed. google earth engine (gee), as a cloud computing platform, provides a large number of remote sensing images, geoprocessing algorithms and massive computational capabilities via web interfaces. however, gee requires users to possess programming skills of javascript or python language, which can hinder the enthusiasm of many academics without programming skills. this paper developed a web-based and open-access toolkit o-lcmapping for supporting online land cover classification. this toolkit was implemented with javascript application programming interfaces of gee and integrated ten imagery classification algorithms. the toolkit explicitly provides the entire pipeline of land cover classification in the form of user interfaces for end-users with basic knowledge of remote sensing but little programming skills. concretely, it enables end-users to define study area, select remote sensing data, mark classification samples, set classification algorithms, evaluate accuracy and output results through user interfaces. three different experimental cases indicate that the toolkit can be easily applied to different fields for various applications of land cover classification.",o-lcmapping: a google earth engine-based web toolkit for supporting online land cover classification
276,2-s2.0-85100858350,10.3390/app11041540,Design and evaluation of a web-and mobile-based binaural audio platform for cultural heritage,Comunità M.,Applied Sciences (Switzerland),2021-02-02,"PlugSonic is a suite of web- and mobile-based applications for the curation and experience of 3D interactive soundscapes and sonic narratives in the cultural heritage context. It was developed as part of the PLUGGY EU project (Pluggable Social Platform for Heritage Awareness and Participation) and consists of two main applications: PlugSonic Sample, to edit and apply audio effects, and PlugSonic Soundscape, to create and experience 3D soundscapes for headphones playback. The audio processing within PlugSonic is based on the Web Audio API and the 3D Tune-In Toolkit, while the mobile exploration of soundscapes in a physical space is obtained using Apple’s ARKit. The main goal of PlugSonic is technology democratisation; PlugSonic users-whether cultural institutions or citizens-are all given the instruments needed to create, process and experience 3D soundscapes and sonic narratives; without the need for specific devices, external tools (software and/or hardware), specialised knowledge or custom development. The aims of this paper are to present the design and development choices, the user involvement processes as well as a final evaluation conducted with inexperienced users on three tasks (creation, curation and experience), demonstrating how PlugSonic is indeed a simple, effective, yet powerful tool.",Augmented reality | Binaural spatialisation | Cultural heritage | Digital heritage | Sonic narratives | Soundscapes | Spatial audio | Web audio,3,1-22,Journal,Article,4.0,"Comunità, Marco;Gerino, Andrea;Lim, Veranika;Picinali, Lorenzo",57209465234;55845429900;57200853564;34873422000,Imperial College London,United Kingdom,"plugsonic is a suite of web- and mobile-based applications for the curation and experience of 3d interactive soundscapes and sonic narratives in the cultural heritage context. it was developed as part of the pluggy eu project (pluggable social platform for heritage awareness and participation) and consists of two main applications: plugsonic sample, to edit and apply audio effects, and plugsonic soundscape, to create and experience 3d soundscapes for headphones playback. the audio processing within plugsonic is based on the web audio api and the 3d tune-in toolkit, while the mobile exploration of soundscapes in a physical space is obtained using apple’s arkit. the main goal of plugsonic is technology democratisation; plugsonic users-whether cultural institutions or citizens-are all given the instruments needed to create, process and experience 3d soundscapes and sonic narratives; without the need for specific devices, external tools (software and/or hardware), specialised knowledge or custom development. the aims of this paper are to present the design and development choices, the user involvement processes as well as a final evaluation conducted with inexperienced users on three tasks (creation, curation and experience), demonstrating how plugsonic is indeed a simple, effective, yet powerful tool.",design and evaluation of a web-and mobile-based binaural audio platform for cultural heritage
278,2-s2.0-85102440234,10.3390/data6020021,"An open gmns dataset of a dynamic multi-modal transportation network model of Melbourne, Australia",Nourmohammadi F.,Data,2021-02-01,"Simulation-based dynamic traffic assignment models are increasingly used in urban transportation systems analysis and planning. They replicate traffic dynamics across transportation networks by capturing the complex interactions between travel demand and supply. However, their applications particularly for large-scale networks have been hindered by the challenges associated with the collection, parsing, development, and sharing of data-intensive inputs. In this paper, we develop and share an open dataset for reproduction of a dynamic multi-modal transportation network model of Melbourne, Australia. The dataset is developed consistently with the General Modeling Network Specification (GMNS), enabling software-agnostic human and machine readability. GMNS is a standard readable format for sharing routable transportation network data that is designed to be used in multimodal static and dynamic transportation operations and planning models.",Dynamic traffic assignment model | GMNS | Melbourne | Multi-modal transportation network | Open data,0,1-9,Journal,Article,5.0,"Nourmohammadi, Fatemeh;Mansourianfar, Mohammadhadi;Shafiei, Sajjad;Gu, Ziyuan;Saberi, Meead",57222354053;57195519163;57193017519;57189582465;55639326600,Commonwealth Scientific and Industrial Research Organization;UNSW Sydney;K. N. Toosi University of Technology;Southeast University,Australia;Australia;Iran;China,"simulation-based dynamic traffic assignment models are increasingly used in urban transportation systems analysis and planning. they replicate traffic dynamics across transportation networks by capturing the complex interactions between travel demand and supply. however, their applications particularly for large-scale networks have been hindered by the challenges associated with the collection, parsing, development, and sharing of data-intensive inputs. in this paper, we develop and share an open dataset for reproduction of a dynamic multi-modal transportation network model of melbourne, australia. the dataset is developed consistently with the general modeling network specification (gmns), enabling software-agnostic human and machine readability. gmns is a standard readable format for sharing routable transportation network data that is designed to be used in multimodal static and dynamic transportation operations and planning models.","an open gmns dataset of a dynamic multi-modal transportation network model of melbourne, australia"
279,2-s2.0-85101311864,10.3390/pr9020351,Evolving container to unikernel for edge computing and applications in process industry,Chen S.,Processes,2021-02-01,"Industry 4.0 promotes manufacturing and process industry towards digitalization and intellectualization. Edge computing can provide delay-sensitive services in industrial processes to realize intelligent production. Lightweight virtualization technology is one of the key elements of edge computing, which can implement resource management, orchestration, and isolation services without considering heterogenous hardware. It has revolutionized software development and de-ployment. The scope of this review paper is to present an in-depth analysis of two such technologies, Container and Unikernel, for edge computing. We discuss and compare their applicability in terms of migration, security, and orchestration for edge computing and industrial applications. We de-scribe their performance indexes, evaluation methods and related findings. We then discuss their applications in industrial processes. To promote further research, we present some open issues and challenges to serve as a road map for both researchers and practitioners in the areas of Industry 4.0, industrial process automation, and advanced computing.",Big data analytics | Cloud computing | Edge computing | Fault diagnosis | Industrial process | Industry 4.0 | Internet of things | Lightweight virtualization | Machine learning | Process industry,7,1-19,Journal,Review,2.0,"Chen, Shichao;Zhou, Mengchu",56723036600;7403506743,Macau University of Science and Technology;New Jersey Institute of Technology;Chinese Academy of Sciences;King Abdulaziz University,Macao;United States;China;Saudi Arabia,"industry 4.0 promotes manufacturing and process industry towards digitalization and intellectualization. edge computing can provide delay-sensitive services in industrial processes to realize intelligent production. lightweight virtualization technology is one of the key elements of edge computing, which can implement resource management, orchestration, and isolation services without considering heterogenous hardware. it has revolutionized software development and de-ployment. the scope of this review paper is to present an in-depth analysis of two such technologies, container and unikernel, for edge computing. we discuss and compare their applicability in terms of migration, security, and orchestration for edge computing and industrial applications. we de-scribe their performance indexes, evaluation methods and related findings. we then discuss their applications in industrial processes. to promote further research, we present some open issues and challenges to serve as a road map for both researchers and practitioners in the areas of industry 4.0, industrial process automation, and advanced computing.",evolving container to unikernel for edge computing and applications in process industry
280,2-s2.0-85100728417,10.1587/transinf.2020EDP7107,An exploratory study of copyright inconsistency in the linux kernel,QIU S.,IEICE Transactions on Information and Systems,2021-02-01,"Software copyright claims an exclusive right for the software copyright owner to determine whether and under what conditions others can modify, reuse, or redistribute this software. For Free and Open Source Software (FOSS), it is very important to identify the copyright owner who can control those activities with license compliance. Copyright notice is a few sentences mostly placed in the header part of a source file as a comment or in a license document in a FOSS project, and it is an important clue to establish the ownership of a FOSS project. Repositories of FOSS projects contain rich and varied information on the development including the source code contributors who are also an important clue to establish the ownership. In this paper, as a first step of understanding copyright owner, we will explore the situation of the software copyright in the Linux kernel, a typical example of FOSS, by analyzing and comparing two kinds of datasets, copyright notices in source files and source code contributors in the software repositories. The discrepancy between two kinds of analysis results is defined as copyright inconsistency. The analysis result has indicated that copyright inconsistencies are prevalent in the Linux kernel. We have also found that code reuse, affiliation change, refactoring, support function, and others' contributions potentially have impacts on the occurrence of the copyright inconsistencies in the Linux kernel. This study exposes the difficulty in managing software copyright in FOSS, highlighting the usefulness of future work to address software copyright problems.",Mining software repositories | Open source software | Software copyright | Software maintenance,0,254-263,Journal,Article,3.0,"QIU, Shi;GERMAN, Daniel M.;INOUE, Katsuro",57205073835;57207886015;7601540520,Osaka University;University of Victoria,Japan;Canada,"software copyright claims an exclusive right for the software copyright owner to determine whether and under what conditions others can modify, reuse, or redistribute this software. for free and open source software (foss), it is very important to identify the copyright owner who can control those activities with license compliance. copyright notice is a few sentences mostly placed in the header part of a source file as a comment or in a license document in a foss project, and it is an important clue to establish the ownership of a foss project. repositories of foss projects contain rich and varied information on the development including the source code contributors who are also an important clue to establish the ownership. in this paper, as a first step of understanding copyright owner, we will explore the situation of the software copyright in the linux kernel, a typical example of foss, by analyzing and comparing two kinds of datasets, copyright notices in source files and source code contributors in the software repositories. the discrepancy between two kinds of analysis results is defined as copyright inconsistency. the analysis result has indicated that copyright inconsistencies are prevalent in the linux kernel. we have also found that code reuse, affiliation change, refactoring, support function, and others' contributions potentially have impacts on the occurrence of the copyright inconsistencies in the linux kernel. this study exposes the difficulty in managing software copyright in foss, highlighting the usefulness of future work to address software copyright problems.",an exploratory study of copyright inconsistency in the linux kernel
281,2-s2.0-85100422648,10.1109/TVCG.2020.3030366,VisConnect: Distributed Event Synchronization for Collaborative Visualization,Schwab M.,IEEE Transactions on Visualization and Computer Graphics,2021-02-01,"Tools and interfaces are increasingly expected to be synchronous and distributed to accommodate remote collaboration. Yet, adoption of these techniques for data visualization is low partly because development is difficult: existing collaboration software systems either do not support simultaneous interaction or require expensive redevelopment of existing visualizations. We contribute VisConnect: a web-based synchronous distributed collaborative visualization system that supports most web-based SVG data visualizations, balances system safety with responsiveness, and supports simultaneous interaction from many collaborators. VisConnect works with existing visualization implementations with little-to-no code changes by synchronizing low-level JavaScript events across clients such that visualization updates proceed transparently across clients. This is accomplished via a peer-to-peer system that establishes consensus among clients on the per-element sequence of events, and uses a lock service to grant access over elements to clients. We contribute collaborative extensions of traditional visualization interaction techniques, such as drag, brush, and lasso, and discuss different strategies for collaborative visualization interactions. To demonstrate the utility of VisConnect, we present novel examples of collaborative visualizations in the healthcare domain, remote collaboration with annotation, and show in an education case study for e-learning with 22 participants that students found the ability to remotely collaborate on class activities helpful and enjoyable for understanding concepts. A free copy of this paper and source code are available on OSF at osf.io/ut7e6 and at visconnect.us.",Collaborative visualization | distributed visualization | toolkit,4,347-357,Journal,Article,8.0,"Schwab, Michail;Saffo, David;Zhang, Yixuan;Sinha, Shash;Nita-Rotaru, Cristina;Tompkin, James;Dunne, Cody;Borkin, Michelle A.",57192171778;57211752985;57202889533;57221856157;6507281794;36142459800;25651423500;14057526900,Northeastern University;Georgia Institute of Technology;Brown University,United States;United States;United States,"tools and interfaces are increasingly expected to be synchronous and distributed to accommodate remote collaboration. yet, adoption of these techniques for data visualization is low partly because development is difficult: existing collaboration software systems either do not support simultaneous interaction or require expensive redevelopment of existing visualizations. we contribute visconnect: a web-based synchronous distributed collaborative visualization system that supports most web-based svg data visualizations, balances system safety with responsiveness, and supports simultaneous interaction from many collaborators. visconnect works with existing visualization implementations with little-to-no code changes by synchronizing low-level javascript events across clients such that visualization updates proceed transparently across clients. this is accomplished via a peer-to-peer system that establishes consensus among clients on the per-element sequence of events, and uses a lock service to grant access over elements to clients. we contribute collaborative extensions of traditional visualization interaction techniques, such as drag, brush, and lasso, and discuss different strategies for collaborative visualization interactions. to demonstrate the utility of visconnect, we present novel examples of collaborative visualizations in the healthcare domain, remote collaboration with annotation, and show in an education case study for e-learning with 22 participants that students found the ability to remotely collaborate on class activities helpful and enjoyable for understanding concepts. a free copy of this paper and source code are available on osf at osf.io/ut7e6 and at visconnect.us.",visconnect: distributed event synchronization for collaborative visualization
283,2-s2.0-85108165014,10.1145/3450588.3450939,"Software development, design and implementation of management system for characteristic B &amp; B",Huang M.,ACM International Conference Proceeding Series,2021-01-30,"The regional comprehensive economic partnership has been officially signed and released. It is the construction of economic integration in East Asia, which will promote regional economic integration and world economic development. It can be expected that the following 15 countries will soon release relevant supporting policies, such as visa free, landing visa and supporting tourism, catering and other consumer preferences, which will also make it more convenient and affordable for individuals to travel abroad. Now is a good time to experience foreign culture. Personal planning starts with the three categories of world cultural heritage advocated by UNESCO. The choice of conditions should start with the accommodation service of characteristic B & B around the tourism area, so as to be able to experience the foreign characteristics, festival atmosphere and learn the characteristics of multi culture.Because Covid-19 is still under continuous influence. Large group transnational travel groups have been temporarily frozen or disappeared. A new state of small bourgeois groups, short-term, and deep tourism has emerged. Expensive hotels have also reduced their prices to survive the epidemic. However, in order to avoid cluster infection, people who want to micro travel have changed to stay in low-cost and characteristic B & B, which are close to the scenic spots and cheap in price The main consideration of accommodation is that B & B has the characteristics of local characteristics to attract free travelers and backpackers to stay.The existing website and software of characteristic B & B are relatively simple and easy. Most websites can provide information services of passenger reservation and online payment. The construction of characteristic B & B online management system is the performance requirement of modular management system. According to the software engineering development process, find out the system requirements, feasibility system analysis, conceive system design, mainly including the front-end HTML, CSS and JavaScript. The server is Apache, the framework is Django, and the integrated compiler tool is PyCharm. Using Python language to separate the front-end and back-end of the system, combining Django framework with MySQL database technology can improve the stability of system performance, run system test, acceptance test and system security, and successfully construct the characteristic B & B management system.",Django | MySQL | Python | Software engineering,0,112-117,Conference Proceeding,Conference Paper,1.0,"Huang, Minchuan",57224674838,Guangdong Institute of Petroleum and Chemical Engineering,China,"the regional comprehensive economic partnership has been officially signed and released. it is the construction of economic integration in east asia, which will promote regional economic integration and world economic development. it can be expected that the following 15 countries will soon release relevant supporting policies, such as visa free, landing visa and supporting tourism, catering and other consumer preferences, which will also make it more convenient and affordable for individuals to travel abroad. now is a good time to experience foreign culture. personal planning starts with the three categories of world cultural heritage advocated by unesco. the choice of conditions should start with the accommodation service of characteristic b & b around the tourism area, so as to be able to experience the foreign characteristics, festival atmosphere and learn the characteristics of multi culture.because covid-19 is still under continuous influence. large group transnational travel groups have been temporarily frozen or disappeared. a new state of small bourgeois groups, short-term, and deep tourism has emerged. expensive hotels have also reduced their prices to survive the epidemic. however, in order to avoid cluster infection, people who want to micro travel have changed to stay in low-cost and characteristic b & b, which are close to the scenic spots and cheap in price the main consideration of accommodation is that b & b has the characteristics of local characteristics to attract free travelers and backpackers to stay.the existing website and software of characteristic b & b are relatively simple and easy. most websites can provide information services of passenger reservation and online payment. the construction of characteristic b & b online management system is the performance requirement of modular management system. according to the software engineering development process, find out the system requirements, feasibility system analysis, conceive system design, mainly including the front-end html, css and javascript. the server is apache, the framework is django, and the integrated compiler tool is pycharm. using python language to separate the front-end and back-end of the system, combining django framework with mysql database technology can improve the stability of system performance, run system test, acceptance test and system security, and successfully construct the characteristic b & b management system.","software development, design and implementation of management system for characteristic b &amp; b"
285,2-s2.0-85100557535,10.1145/3394885.3431638,Micro-architectural Cache Side-Channel Attacks and Countermeasures,Shen C.,"Proceedings of the Asia and South Pacific Design Automation Conference, ASP-DAC",2021-01-18,"Central Processing Unit (CPU) is considered as the brain of a computer. If the CPU has vulnerabilities, the security of software running on it is difficult to be guaranteed. In recent years, various micro-architectural cache side-channel attacks on the CPU such as Spectre and Meltdown have appeared. They exploit contention on internal components of the processor to leak secret information between processes. This newly evolving research area has aroused significant interest due to the broad application range and harmfulness of these attacks. This article reviews recent research progress on micro-architectural cache side-channel attacks and defenses. First, the various micro-architectural cache side-channel attacks are classified and discussed. Then, the corresponding countermeasures are summarized. Finally, the limitations and future development trends are prospected.",cache | hardware security | micro-architecture | side-channel attacks,4,441-448,Conference Proceeding,Conference Paper,3.0,"Shen, Chaoqun;Chen, Congcong;Zhang, Jiliang",57219537555;57221917207;55331782900,Hunan University,China,"central processing unit (cpu) is considered as the brain of a computer. if the cpu has vulnerabilities, the security of software running on it is difficult to be guaranteed. in recent years, various micro-architectural cache side-channel attacks on the cpu such as spectre and meltdown have appeared. they exploit contention on internal components of the processor to leak secret information between processes. this newly evolving research area has aroused significant interest due to the broad application range and harmfulness of these attacks. this article reviews recent research progress on micro-architectural cache side-channel attacks and defenses. first, the various micro-architectural cache side-channel attacks are classified and discussed. then, the corresponding countermeasures are summarized. finally, the limitations and future development trends are prospected.",micro-architectural cache side-channel attacks and countermeasures
286,2-s2.0-85131672977,10.5593/sgem2021/2.1/s08.32,DEVELOPMENT OF A WEB-BASED SYSTEM FOR GNSS DATA TRACKING AND APPLYING CORRECTIONS IN GIS ENVIRONMENT,Ilieva T.,"International Multidisciplinary Scientific GeoConference Surveying Geology and Mining Ecology Management, SGEM",2021-01-01,"The subject of this study is the development of a web-based system for real time data tracking and applying GNSS corrections in GIS environment. This includes the data structures specification in a geospatial database, obtaining a methodology for system realization and discussing the results with an accent to the accuracy of the corrected GNSS positions. The system for tracking and applying GNSS corrections in GIS environment is entirely built by using free and open source software and has web-based interface. There are three web pages - the first for login information and system description, the second contains a map, where the results in real time are shown on the third page is for reports and history of tracking. The system uses data directly from GNSS receivers in NMEA protocol, stored in PostgreSQL/PostGIS database and accessed via php code. The data is corrected in the database and published with Geoserver by using OGC Web Services. For the user interface HTML, CSS and JavaScript are used. In this research is presented an example, which proves that the tracking and calculating of GNSS corrections in order more accurate positions to be obtained is possible by using web-based GIS.",free | GNSS corrections calculation | GNSS receivers tracking | NMEA protocol | open source software | web GIS,0,87-94,Conference Proceeding,Conference Paper,1.0,"Ilieva, Tamara",57734490100,"University of Architecture, Civil Engineering and Geodesy",Bulgaria,"the subject of this study is the development of a web-based system for real time data tracking and applying gnss corrections in gis environment. this includes the data structures specification in a geospatial database, obtaining a methodology for system realization and discussing the results with an accent to the accuracy of the corrected gnss positions. the system for tracking and applying gnss corrections in gis environment is entirely built by using free and open source software and has web-based interface. there are three web pages - the first for login information and system description, the second contains a map, where the results in real time are shown on the third page is for reports and history of tracking. the system uses data directly from gnss receivers in nmea protocol, stored in postgresql/postgis database and accessed via php code. the data is corrected in the database and published with geoserver by using ogc web services. for the user interface html, css and javascript are used. in this research is presented an example, which proves that the tracking and calculating of gnss corrections in order more accurate positions to be obtained is possible by using web-based gis.",development of a web-based system for gnss data tracking and applying corrections in gis environment
291,2-s2.0-85126677144,10.1109/CONTIE54684.2021.00028,Talk Me: Customizable SAAC Software For Children With Autism Spectrum Disorder,Munoz J.G.S.,"Proceedings - 2021 4th International Conference on Inclusive Technology and Education, CONTIE 2021",2021-01-01,"Communication is an indispensable ability to develop in society and achieve a sense of individuality and belonging, including people with special needs. For this reason, different techniques, technologies, tools, applications, and systems have been designed and implemented to develop communication in an alternative or augmentative manner, allowing people who were previously unable to communicate to do so. However, many of these options require the accompaniment of a professional and long processes of adaptation and correction for the proper implementation, avoiding the user's rejection to the use of the tool. Customization is one of the elements that allow a tool to be successful in its implementation, since it adapts to the needs of the end user, allowing a friendlier appearance. In this work, we propose the development of an Augmentative and Alternative Communication System (SAAC) with a high degree of customization that helps therapists to reduce adaptation times and the end user to accept the tool more quickly, achieving that the communication process improves in the family nucleus.",Alternative | Augmentative | Autism | Communication | Systems,0,116-125,Conference Proceeding,Conference Paper,5.0,"Munoz, Jonathan Giovanni Soto;Bringas, Jesus Andres Sandoval;Leon, Monica Adriana Carreno;Encinas, Israel Duran;Silva, Litzy Ivonne Escalera",57215137111;57223295701;57536307400;57223293328;57537533100,Universidad Autónoma de Baja California Sur,Mexico,"communication is an indispensable ability to develop in society and achieve a sense of individuality and belonging, including people with special needs. for this reason, different techniques, technologies, tools, applications, and systems have been designed and implemented to develop communication in an alternative or augmentative manner, allowing people who were previously unable to communicate to do so. however, many of these options require the accompaniment of a professional and long processes of adaptation and correction for the proper implementation, avoiding the user's rejection to the use of the tool. customization is one of the elements that allow a tool to be successful in its implementation, since it adapts to the needs of the end user, allowing a friendlier appearance. in this work, we propose the development of an augmentative and alternative communication system (saac) with a high degree of customization that helps therapists to reduce adaptation times and the end user to accept the tool more quickly, achieving that the communication process improves in the family nucleus.",talk me: customizable saac software for children with autism spectrum disorder
292,2-s2.0-85126395366,10.1109/ISSRE52982.2021.00050,The Behavioral Diversity of Java JSON Libraries,Harrand N.,"Proceedings - International Symposium on Software Reliability Engineering, ISSRE",2021-01-01,"JSON is an essential file and data format in domains that span scientific computing, web APIs or configuration management. Its popularity has motivated significant software development effort to build multiple libraries to process JSON data. Previous studies focus on performance comparison among these libraries and lack a software engineering perspective. We present the first systematic analysis and comparison of the input / output behavior of 20 JSON libraries, in a single software ecosystem: Java/Maven. We assess behavior diversity by running each library against a curated set of 473 JSON files, including both well-formed and ill-formed files. The main design differences, which influence the behavior of the libraries, relate to the choice of data structure to represent JSON objects and to the encoding of numbers. We observe a remarkable behavioral diversity with ill-formed files, or corner cases such as large numbers or duplicate data. Our unique behavioral assessment of JSON libraries paves the way for a robust processing of ill-formed files, through a multi-version architecture.",Behavioral Diversity | Java | JSON,0,412-422,Conference Proceeding,Conference Paper,4.0,"Harrand, Nicolas;Durieux, Thomas;Broman, David;Baudry, Benoit",57192872575;57189692747;18036903200;57203847520,The Royal Institute of Technology (KTH),Sweden,"json is an essential file and data format in domains that span scientific computing, web apis or configuration management. its popularity has motivated significant software development effort to build multiple libraries to process json data. previous studies focus on performance comparison among these libraries and lack a software engineering perspective. we present the first systematic analysis and comparison of the input / output behavior of 20 json libraries, in a single software ecosystem: java/maven. we assess behavior diversity by running each library against a curated set of 473 json files, including both well-formed and ill-formed files. the main design differences, which influence the behavior of the libraries, relate to the choice of data structure to represent json objects and to the encoding of numbers. we observe a remarkable behavioral diversity with ill-formed files, or corner cases such as large numbers or duplicate data. our unique behavioral assessment of json libraries paves the way for a robust processing of ill-formed files, through a multi-version architecture.",the behavioral diversity of java json libraries
293,2-s2.0-85126193345,10.1109/APSEC53868.2021.00014,Tree-based Mining of Fine-grained Code Changes to Detect Unknown Change Patterns,Higo Y.,"Proceedings - Asia-Pacific Software Engineering Conference, APSEC",2021-01-01,"In software development, source code is repeatedly changed due to various reasons. Similar code changes are called change patterns. Identifying change patterns is useful to support software development in a variety of ways. For example, change patterns can be used to collect ingredients for code completion or automated program repair. Many research studies have proposed various techniques that detect change patterns. For example, Negara et al. proposed a technique that derives change patterns from the edit scripts. Negara's technique can detect fine-grained change patterns, but we consider that there is room to improve their technique. We found that Negara's technique occasionally generates change patterns from structurally-different changes, and we also uncovered that the reason why such change patterns are generated is that their technique performs text comparisons in matching changes. In this study, we propose a new change mining technique to detect change patterns only from structurally-identical changes by taking into account the structure of the abstract syntax trees. We implemented the proposed technique as a tool, TC2P, and we compared it with Negara's technique. As a result, we confirmed that TC2P was not only able to detect change patterns more adequately than the prior technique but also to detect change patterns that were not detected by the prior technique.",Code change pattern | Edit script | Mining code change pattern | Repository mining,0,61-71,Conference Proceeding,Conference Paper,3.0,"Higo, Yoshiki;Matsumoto, Junnosuke;Kusumoto, Shinji",7004831134;57202892758;7102741360,Osaka University,Japan,"in software development, source code is repeatedly changed due to various reasons. similar code changes are called change patterns. identifying change patterns is useful to support software development in a variety of ways. for example, change patterns can be used to collect ingredients for code completion or automated program repair. many research studies have proposed various techniques that detect change patterns. for example, negara et al. proposed a technique that derives change patterns from the edit scripts. negara's technique can detect fine-grained change patterns, but we consider that there is room to improve their technique. we found that negara's technique occasionally generates change patterns from structurally-different changes, and we also uncovered that the reason why such change patterns are generated is that their technique performs text comparisons in matching changes. in this study, we propose a new change mining technique to detect change patterns only from structurally-identical changes by taking into account the structure of the abstract syntax trees. we implemented the proposed technique as a tool, tc2p, and we compared it with negara's technique. as a result, we confirmed that tc2p was not only able to detect change patterns more adequately than the prior technique but also to detect change patterns that were not detected by the prior technique.",tree-based mining of fine-grained code changes to detect unknown change patterns
296,2-s2.0-85125733252,10.1109/SNPD51163.2021.9704933,Which Dependency was Updated? Exploring Who Changes Dependencies in npm packages,Maeprasart V.,"Proceedings - 22nd IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing, SNPD 2021-Fall",2021-01-01,"Nowadays, software development increasingly depends on third-party library packages to reuse functionality and save the costs of building themselves. Since dependency is constantly evolving, developers struggle to update dependencies. In this work, we take the first exploration into the responsibility of updating a dependency. Analyzing 89, 393 npm packages, we mine the repositories to understand who is the person responsible (i.e., dependency author) for the library update and whether or not the spread of responsibility of updating has an impact on what libraries will get updated. Our results show that 64.24% packages have only one dependency author who is responsible for the dependency. Furthermore, the number of dependency authors correlates with dependency changes, hinting that updating dependencies correlates with having more responsible developers. Lastly, we find that npm packages with just a single dependency author update different libraries compared to those with more dependency authors.",dependency libraries | JavaScript | npm ecosystem,0,258-261,Conference Proceeding,Conference Paper,4.0,"Maeprasart, Vittunyuta;Ikegami, Ayano;Kula, Raula Gaikovina;Matsumoto, Kenichi",57194159326;57476788400;57188638536;55378267900,Nara Institute of Science and Technology,Japan,"nowadays, software development increasingly depends on third-party library packages to reuse functionality and save the costs of building themselves. since dependency is constantly evolving, developers struggle to update dependencies. in this work, we take the first exploration into the responsibility of updating a dependency. analyzing 89, 393 npm packages, we mine the repositories to understand who is the person responsible (i.e., dependency author) for the library update and whether or not the spread of responsibility of updating has an impact on what libraries will get updated. our results show that 64.24% packages have only one dependency author who is responsible for the dependency. furthermore, the number of dependency authors correlates with dependency changes, hinting that updating dependencies correlates with having more responsible developers. lastly, we find that npm packages with just a single dependency author update different libraries compared to those with more dependency authors.",which dependency was updated? exploring who changes dependencies in npm packages
297,2-s2.0-85125707071,10.1109/iCORE54267.2021.00040,Legislative Information Resources Management for House Bills and House Resolutions in the Acquisition Department of the House of Representatives,Lapid C.B.,"Proceedings - 2021 1st International Conference in Information and Computing Research, iCORE 2021",2021-01-01,"The government typically manages a lot of documents during their day to day operations. Aside from documents, it also requires a large amount of effort in monitoring the compliance of each employee in the government. Given the current problem, the researchers provided Configuration Management and Monitoring and Event Management [20] Information Technology Infrastructure Library (ITIL) frameworks to provide a systematic way of receiving, archiving, and transmitting vital government documents which are the House Bills and House Resolutions. With that, the researchers created the LIRM: Legislative Information Resources Management for House Bills and House Resolutions in the Acquisition Department of the House of Representatives. The development of the system was done through the Agile methodology. This methodology was used for the purpose of saving time and acquiring continuous feedback and results during each sprint of the development. The local-based application was developed using PHP, Angular and other technologies that assures the system's performance, reliability, availability, and security. Tests performed were based on the [16] Institute of Electronics and Electrical Engineering (IEEE) standard for Software Test Documentation to make sure that the standards and acceptance criteria are met.",Configuration Management | House Bills | House Resolutions | ITIL framework | Legislative Information Resource Management | Monitoring and Event Management | Service Management,0,119-124,Conference Proceeding,Conference Paper,5.0,"Lapid, Christalyn B.;Manuel, Alyanna Dawn S.;Barcelo, Arne B.;Silva, Dianne Nicole M.;Ong, Joerji Louis A.",57476981300;57476981400;57204451992;57476981500;57476599100,"University of Santo Tomas, Manila",Philippines,"the government typically manages a lot of documents during their day to day operations. aside from documents, it also requires a large amount of effort in monitoring the compliance of each employee in the government. given the current problem, the researchers provided configuration management and monitoring and event management [20] information technology infrastructure library (itil) frameworks to provide a systematic way of receiving, archiving, and transmitting vital government documents which are the house bills and house resolutions. with that, the researchers created the lirm: legislative information resources management for house bills and house resolutions in the acquisition department of the house of representatives. the development of the system was done through the agile methodology. this methodology was used for the purpose of saving time and acquiring continuous feedback and results during each sprint of the development. the local-based application was developed using php, angular and other technologies that assures the system's performance, reliability, availability, and security. tests performed were based on the [16] institute of electronics and electrical engineering (ieee) standard for software test documentation to make sure that the standards and acceptance criteria are met.",legislative information resources management for house bills and house resolutions in the acquisition department of the house of representatives
300,2-s2.0-85125357221,10.1109/ICTAI53825.2021.9673464,Web Development and performance comparison of Web Development Technologies in Node.js and Python,Challapalli S.S.N.,"Proceedings of International Conference on Technological Advancements and Innovations, ICTAI 2021",2021-01-01,"From the first website being created in 1991 by Tim Berners-Lee to this day in 2021, the world of websites and their development has seen a rapid evolution. Every business nowadays has a website to make its online presence in this digital age. Website use is not only limited to this, but many people use them to build their online portfolio, apart from that there are many web-based applications/software, etc. This research paper discusses the process involved in developing a website in past and present, development of content delivery over the years, the website uses, a website for mobile devices, and performance comparison between two of the most used web backend development technologies, i. e, Node.js and Python. For comparing performance, we have used Locust-an open-source software and Autocannon and tested both of them under similar conditions.",Autocannon | Content Delivery | Framework | Locust | MERN stack | Mobile Websites | Node.js | Python | Web Development | Website Technologies,0,303-307,Conference Proceeding,Conference Paper,6.0,"Challapalli, Sai Sri Nandan;Kaushik, Prakarsh;Suman, Shashikant;Shivahare, Basu Dev;Bibhu, Vimal;Gupta, Amar Deep",57468455900;57218937111;57534621800;57211441854;56521523700;57198677188,Amity University,India,"from the first website being created in 1991 by tim berners-lee to this day in 2021, the world of websites and their development has seen a rapid evolution. every business nowadays has a website to make its online presence in this digital age. website use is not only limited to this, but many people use them to build their online portfolio, apart from that there are many web-based applications/software, etc. this research paper discusses the process involved in developing a website in past and present, development of content delivery over the years, the website uses, a website for mobile devices, and performance comparison between two of the most used web backend development technologies, i. e, node.js and python. for comparing performance, we have used locust-an open-source software and autocannon and tested both of them under similar conditions.",web development and performance comparison of web development technologies in node.js and python
302,2-s2.0-85124908307,10.1109/ECBIOS51820.2021.9510899,Simulation of HIL Analog Power Meter Connection Technology for Vehicle Autonomous Driving,Lin L.X.,"3rd IEEE Eurasia Conference on Biomedical Engineering, Healthcare and Sustainability, ECBIOS 2021",2021-01-01,"This research uses PreScan simulation software as a test platform. The vehicle's hardware-in-the-loop (HIL) links to virtual scenes and reality sensors, which reduce costs in a virtual road environment. In this study, we monitor the analog power meter on the drive shaft of the PreSan car to monitor its torque, tire rotation speed, acceleration, and design the transmission format of the power meter. The remote monitoring is standardized, as the network interface is integrated into the car computer while retaining the high reliability of the industrial-grade Ethernet network. The system meets the strict functional safety requirements of car manufacturers and Tier 1 original equipment manufacturers (OEMs). The advanced driving assistance system (ADAS) of the car allows 1) the monitoring of the analog power meter of the Ethernet to become the mainstream data collection channel, 2) the processor of the on-board system to monitor the value and communication in real-time, and 3) drive the car to check the driving condition. Through the development of PreScan, intermediate monitoring and communication are completed, and the development speed is accelerated.",ADAS | Ethernet AVB | PreScan,0,215-218,Conference Proceeding,Conference Paper,5.0,"Lin, Li Xin;Xu, Zhi Yao;Jiang, Jinn Feng;Wei, Hung Yuan;Hsu, Kuei Shu",57458922600;57221601376;50561695300;50562381400;24921329200,National Kaohsiung University of Science and Technology;Putian University;Metal Industries Research and Development Center Taiwan;Chia-Nan University of Pharmacy and Science Taiwan,Taiwan;China;Taiwan;Taiwan,"this research uses prescan simulation software as a test platform. the vehicle's hardware-in-the-loop (hil) links to virtual scenes and reality sensors, which reduce costs in a virtual road environment. in this study, we monitor the analog power meter on the drive shaft of the presan car to monitor its torque, tire rotation speed, acceleration, and design the transmission format of the power meter. the remote monitoring is standardized, as the network interface is integrated into the car computer while retaining the high reliability of the industrial-grade ethernet network. the system meets the strict functional safety requirements of car manufacturers and tier 1 original equipment manufacturers (oems). the advanced driving assistance system (adas) of the car allows 1) the monitoring of the analog power meter of the ethernet to become the mainstream data collection channel, 2) the processor of the on-board system to monitor the value and communication in real-time, and 3) drive the car to check the driving condition. through the development of prescan, intermediate monitoring and communication are completed, and the development speed is accelerated.",simulation of hil analog power meter connection technology for vehicle autonomous driving
303,2-s2.0-85124795538,10.1109/SEA-STEM53614.2021.9668002,Node.js for Development RSTEM to Support Remote Physics Practicum during COVID-19,Irwandi I.,"Proceedings - 2nd SEA-STEM International Conference, SEA-STEM 2021",2021-01-01,"Social distancing during the COVID-19 pandemic has changed many things in the way we teach. We are used to learning through video conferencing, e-learning, and virtual experiments such as PhET interactive simulation. However, the experience gained from an experiment in a real condition is still interesting to do and cannot be replaced by a virtual experiment. Therefore, we investigated several remote instrumentation models and technologies that were more effective and more efficient to develop. The results of our research show that the Node.js runtime environment is the most appropriate, effective choice because Node.js is based on open source, so that various microprocessors and various OS support it. We run Node.js on a low-cost device, Raspberry PI 4, with Ubuntu 20.10, a very familiar open-source OS. In addition, Node.js has a feature to communicate with the hardware, making it very easy to connect to experimental physics instrumentation. Because Node.js is based on javascript, it is indeed very suitable for developing web-based applications. We succeeded to carry out initial development through measurements on the magnetic field generated by a coil. Students can interactively control the movement of the sensor and see it in real-time during experiments of measuring the strength of the magnetic field generated by a coil. Experimental activities are part of STEM activities, so we call this remote experimental platform 'Remote STEM', abbreviated as RSTEM.",Node.js STEM Education | Remote Instrumentation | RSTEM,0,1-5,Conference Proceeding,Conference Paper,5.0,"Irwandi, I.;Ishafit, ;Nizamuddin, ;Umam, Khairul;Fashbir, ",55292746000;57190670060;57193440051;57268953200;57195248556,Universitas Ahmad Dahlan;Universitas Syiah Kuala,Indonesia;Indonesia,"social distancing during the covid-19 pandemic has changed many things in the way we teach. we are used to learning through video conferencing, e-learning, and virtual experiments such as phet interactive simulation. however, the experience gained from an experiment in a real condition is still interesting to do and cannot be replaced by a virtual experiment. therefore, we investigated several remote instrumentation models and technologies that were more effective and more efficient to develop. the results of our research show that the node.js runtime environment is the most appropriate, effective choice because node.js is based on open source, so that various microprocessors and various os support it. we run node.js on a low-cost device, raspberry pi 4, with ubuntu 20.10, a very familiar open-source os. in addition, node.js has a feature to communicate with the hardware, making it very easy to connect to experimental physics instrumentation. because node.js is based on javascript, it is indeed very suitable for developing web-based applications. we succeeded to carry out initial development through measurements on the magnetic field generated by a coil. students can interactively control the movement of the sensor and see it in real-time during experiments of measuring the strength of the magnetic field generated by a coil. experimental activities are part of stem activities, so we call this remote experimental platform 'remote stem', abbreviated as rstem.",node.js for development rstem to support remote physics practicum during covid-19
304,2-s2.0-85124747909,10.13052/jwe1540-9589.2121,Morpheus Web Testing: A Tool for Generating Test Cases for Widget Based Web Applications,de Almeida Neves R.,Journal of Web Engineering,2021-01-01,"Context: Widgets are reusable User Interfaces (UIs) components frequently delivered in Web applications.In the web application, widgets implement different interaction scenarios, such as buttons, menus, and text input. Problem: Tests are performed manually, so the cost associated with preparing and executing test cases is high. Objective: Automate the process of generating functional test cases for web applications, using intermediate artifacts of the web development process that structure widgets in the web application. The goal of this process is to ensure the quality of the software, reduce overall software lifecycle time and the costs associated with tests. Method:We elaborated a test generation strategy and implemented this strategy in a tool, Morpheus Web Testing. Morpheus Web Testing extracts widget information from Java Server Faces artifacts to generate test cases for JSF web applications. We conducted a case study for comparing Morpheus Web Testing with a state of the art tool (CrawlJax). Results: The results indicate evidence that the approach Morpheus Web Testing managed to reach greater code coverage compared to a CrawlJax. Conclusion: The achieved coverage values represent evidence that the results obtained from the proposed approach contribute to the process of automated test software engineering in the industry.",Code coverage | Morpheus web testing | User interfaces | Widgets,0,119-143,Journal,Article,3.0,"de Almeida Neves, Romulo;Watanabe, Willian Massami;Oliveira, Rafael",57456190800;35180645400;57640863800,Universidade Tecnológica Federal do Paraná,Brazil,"context: widgets are reusable user interfaces (uis) components frequently delivered in web applications.in the web application, widgets implement different interaction scenarios, such as buttons, menus, and text input. problem: tests are performed manually, so the cost associated with preparing and executing test cases is high. objective: automate the process of generating functional test cases for web applications, using intermediate artifacts of the web development process that structure widgets in the web application. the goal of this process is to ensure the quality of the software, reduce overall software lifecycle time and the costs associated with tests. method:we elaborated a test generation strategy and implemented this strategy in a tool, morpheus web testing. morpheus web testing extracts widget information from java server faces artifacts to generate test cases for jsf web applications. we conducted a case study for comparing morpheus web testing with a state of the art tool (crawljax). results: the results indicate evidence that the approach morpheus web testing managed to reach greater code coverage compared to a crawljax. conclusion: the achieved coverage values represent evidence that the results obtained from the proposed approach contribute to the process of automated test software engineering in the industry.",morpheus web testing: a tool for generating test cases for widget based web applications
306,2-s2.0-85124436464,10.1016/B978-0-12-821748-1.00002-6,Mapping genomes by using bioinformatics data and tools,Shoaib M.,Chemoinformatics and Bioinformatics in the Pharmaceutical Sciences,2021-01-01,"The modern age of computational techniques has indeed speeded up the bioinformatics era in revealing the genetic and genomic world. Bioinformatics has a role in developing software tools that help to systematically organize, analyze, and understand biological data. This data mining of biological literature can avail us with a better prospectus of the biological pathways and complex mechanisms involved in systems biology. Moreover, genome sequencing and annotation aid in gene prediction, modeling, expression profiling, and eventually in molecular dynamics simulation. The emergence of next-generation sequencing programs has achieved unparallel growth in whole-genome sequencing projects such as 100, 000 human genomes, 1000 plant species, etc. Such high-throughput data allow the recognition and exploration of potential biological drug targets. However, more effort is needed to develop better user-friendly biological network tools to utilize and functionalize the sequenced genome. This chapter contains an overall summary of current basics and developments of high-throughput data in the field of bioinformatics, which aims to help readers understand the basics of bioinformatics.",Bioinformatics | Databases | Gene expression | PDB | Protein modeling,1,245-278,Book,Book Chapter,4.0,"Shoaib, Md;Singh, Anju;Gulati, Srishty;Kukreti, Shrikant",57215430538;57217562296;54927120700;6701496717,Ramjas College;University of Delhi,India;India,"the modern age of computational techniques has indeed speeded up the bioinformatics era in revealing the genetic and genomic world. bioinformatics has a role in developing software tools that help to systematically organize, analyze, and understand biological data. this data mining of biological literature can avail us with a better prospectus of the biological pathways and complex mechanisms involved in systems biology. moreover, genome sequencing and annotation aid in gene prediction, modeling, expression profiling, and eventually in molecular dynamics simulation. the emergence of next-generation sequencing programs has achieved unparallel growth in whole-genome sequencing projects such as 100, 000 human genomes, 1000 plant species, etc. such high-throughput data allow the recognition and exploration of potential biological drug targets. however, more effort is needed to develop better user-friendly biological network tools to utilize and functionalize the sequenced genome. this chapter contains an overall summary of current basics and developments of high-throughput data in the field of bioinformatics, which aims to help readers understand the basics of bioinformatics.",mapping genomes by using bioinformatics data and tools
307,2-s2.0-85124345619,10.1109/URUCON53396.2021.9647119,Design and Implementation of Digital Platform for e-Government,Ortiz-Bejar J.,"2021 IEEE URUCON, URUCON 2021",2021-01-01,"This work describes a software development, which is part of the Michoacán State Digital Platform (PDE). The project aims to integrate the decision making history of public servants with the Anti-corruption National Digital Platform (PDN). As a whole, both platforms are an effort to standardize the data required to monitor transparency and accountability in the different levels of government. The PDE implements the first three systems requested by the Executive Secretariat of the National Anti-corruption System (SESNA) to guarantee data interoperability between the 32 states of the Mexican Republic. The systems comprising PDE are: System of patrimonial evolution, declaration of interests and proof of presentation of tax declaration, System of public servants involved in public procurement procedures and System of Public Servants and Sanctioned Individuals, named as SI, SII, and SIII respectively.",API | interoperability | relational databases | REST,0,547-551,Conference Proceeding,Conference Paper,2.0,"Ortiz-Bejar, Jose;Ortiz-Bejar, Jesus",56703193500;57201863128,Universidad Michoacana de San Nicolás de Hidalgo,Mexico,"this work describes a software development, which is part of the michoacán state digital platform (pde). the project aims to integrate the decision making history of public servants with the anti-corruption national digital platform (pdn). as a whole, both platforms are an effort to standardize the data required to monitor transparency and accountability in the different levels of government. the pde implements the first three systems requested by the executive secretariat of the national anti-corruption system (sesna) to guarantee data interoperability between the 32 states of the mexican republic. the systems comprising pde are: system of patrimonial evolution, declaration of interests and proof of presentation of tax declaration, system of public servants involved in public procurement procedures and system of public servants and sanctioned individuals, named as si, sii, and siii respectively.",design and implementation of digital platform for e-government
308,2-s2.0-85124240576,10.1109/ECICE52819.2021.9645721,System Integration of Remote Sensing and Industrial Control with IoT Technologies for Water Purification Plant,Aishwarya Gowda A.G.,"Proceedings of the 3rd IEEE Eurasia Conference on IOT, Communication and Engineering 2021, ECICE 2021",2021-01-01,"The rapid evolution in science and technology, has lead the vigorous development of the technology industry. This development witnessed the changes of the Earth's climatic conditions, dwindle of precious natural resources. Among which, water is an indispensable resource for our human life. But, there are many factors like pollution or loss of resources which result in making water as an important resource for usage. Whereas, the current monitoring system has various problems as most of the people are not very familiar with the proper usage of water and the methods to handle water. Hence, addressing this issue our solution aims in monitoring and controlling water resources by our hardware and software system. This system is combined with a database, PAC (Programmable Automation Controllers) and different types of sensors. This blend of software and hardware initially supports the operators to predict and judge each value accurately. This ensures to make the best processing method and improves work efficiency in short period. Meanwhile, it helps and can reduce the workload drastically helping each process flow smoother and with better results. This solution also can be used to reduce the loss of water resource which occurs due to mis-operation by operators. In addition, this system ensures an ease environment for managers and operators to handle the complete process with confidence. Use of this system can help a huge group of people to achieve a win-win situation with convenient management and easy operation.",Database | Monitoring System | Natural Resources | PAC (Programmable Automation Controller) | Water Treatment,0,96-101,Conference Proceeding,Conference Paper,3.0,"Aishwarya Gowda, A. G.;Su, Hui Kai;Kuo, Wen Kai",57443254700;8393614700;7202113204,National Formosa University Taiwan,Taiwan,"the rapid evolution in science and technology, has lead the vigorous development of the technology industry. this development witnessed the changes of the earth's climatic conditions, dwindle of precious natural resources. among which, water is an indispensable resource for our human life. but, there are many factors like pollution or loss of resources which result in making water as an important resource for usage. whereas, the current monitoring system has various problems as most of the people are not very familiar with the proper usage of water and the methods to handle water. hence, addressing this issue our solution aims in monitoring and controlling water resources by our hardware and software system. this system is combined with a database, pac (programmable automation controllers) and different types of sensors. this blend of software and hardware initially supports the operators to predict and judge each value accurately. this ensures to make the best processing method and improves work efficiency in short period. meanwhile, it helps and can reduce the workload drastically helping each process flow smoother and with better results. this solution also can be used to reduce the loss of water resource which occurs due to mis-operation by operators. in addition, this system ensures an ease environment for managers and operators to handle the complete process with confidence. use of this system can help a huge group of people to achieve a win-win situation with convenient management and easy operation.",system integration of remote sensing and industrial control with iot technologies for water purification plant
309,2-s2.0-85123980622,10.1109/PICICT53635.2021.00040,Test Cases Prioritization Framework for Component Based Front End Technologies,Ghannam H.,"Proceedings - 2021 Palestinian International Conference on Information and Communication Technology, PICICT 2021",2021-01-01,"Test cases prioritization is an important action that has to be done during the testing phase within the software development life cycle. It helps to add more focus on test cases that have high priority. In addition, it helps to discover defects in early stages. Recently, Component-based architecture frontend frameworks are the most popular used technologies; hence prioritization could be connected with it. It might be connected with components reusability and their business requirements. In previous research, several solutions were proposed for test cases prioritization. The gap here, that most of these solutions were built for regression testing. Few proposed solutions were generated for new test cases, while these solutions didn't consider the new frontend technologies. This research presented a framework as an automated solution for prioritization of new test cases. Test cases represent a web application that is going to be developed using the mentioned technologies. The prioritization problem in this research was considered as a multi objective optimization problem where trade-off has to be done between different objectives. Therefore, the proposed solution considered four genetic algorithms: NSGA-II, IBEA, MOCell and SPEA2. During this research, five datasets were created since there are no available datasets. First one was created manually, while the others were created using a random approach. This proposed random approach for creating datasets, can help researchers to create any dataset with any required size for testing any similar problem. Several experiments were done during this research and using the five datasets. Results for all datasets approved that 30 seconds as a minimum execution time is enough to all mentioned algorithms. In addition, the quality is close to all algorithms. The results also approved that having limited time for testing generates a high-quality solution in less than 30 seconds as execution time for any mentioned algorithm. On the other hand, more available time for testing leads to a more complex problem that reduces the solutions quality.",Algorithms | Component | Frontend | Genetic | Prioritization | React | Software | Testing,0,169-174,Conference Proceeding,Conference Paper,2.0,"Ghannam, Hiba;Sayyad, Abdel Salam",57439494200;55329089500,Birzeit University,Palestine,"test cases prioritization is an important action that has to be done during the testing phase within the software development life cycle. it helps to add more focus on test cases that have high priority. in addition, it helps to discover defects in early stages. recently, component-based architecture frontend frameworks are the most popular used technologies; hence prioritization could be connected with it. it might be connected with components reusability and their business requirements. in previous research, several solutions were proposed for test cases prioritization. the gap here, that most of these solutions were built for regression testing. few proposed solutions were generated for new test cases, while these solutions didn't consider the new frontend technologies. this research presented a framework as an automated solution for prioritization of new test cases. test cases represent a web application that is going to be developed using the mentioned technologies. the prioritization problem in this research was considered as a multi objective optimization problem where trade-off has to be done between different objectives. therefore, the proposed solution considered four genetic algorithms: nsga-ii, ibea, mocell and spea2. during this research, five datasets were created since there are no available datasets. first one was created manually, while the others were created using a random approach. this proposed random approach for creating datasets, can help researchers to create any dataset with any required size for testing any similar problem. several experiments were done during this research and using the five datasets. results for all datasets approved that 30 seconds as a minimum execution time is enough to all mentioned algorithms. in addition, the quality is close to all algorithms. the results also approved that having limited time for testing generates a high-quality solution in less than 30 seconds as execution time for any mentioned algorithm. on the other hand, more available time for testing leads to a more complex problem that reduces the solutions quality.",test cases prioritization framework for component based front end technologies
312,2-s2.0-85123434183,10.1109/MODELS50736.2021.00018,Efficient Replay-based Regression Testing for Distributed Reactive Systems in the Context of Model-driven Development,Babaei M.,"Proceedings - 24th International Conference on Model-Driven Engineering Languages and Systems, MODELS 2021",2021-01-01,"As software evolves, regression testing techniques are typically used to ensure the new changes are not adversely affecting the existing features. Despite recent advances, regression testing for distributed systems remains challenging and extremely costly. Existing techniques often require running a failing system several time before detecting a regression. As a result, conventional approaches that use re-execution without considering the inherent non-determinism of distributed systems, and providing no (or low) control over execution are inadequate in many ways. In this paper, we present MRegTest, a replay-based regression testing framework in the context of model-driven development to facilitate deterministic replay of traces for detecting regressions while offering sufficient control for the purpose of testing over the execution of the changed system. The experimental results show that compared to the traditional approaches that annotate traces with timestamps and variable values MRegTest detects almost all regressions while reducing the size of the trace significantly and incurring similar runtime overhead.",Distributed Systems | MDD | Regression Testing,1,89-100,Conference Proceeding,Conference Paper,2.0,"Babaei, Majid;Dingel, Juergen",57212105633;6603459509,Queen’s University,Canada,"as software evolves, regression testing techniques are typically used to ensure the new changes are not adversely affecting the existing features. despite recent advances, regression testing for distributed systems remains challenging and extremely costly. existing techniques often require running a failing system several time before detecting a regression. as a result, conventional approaches that use re-execution without considering the inherent non-determinism of distributed systems, and providing no (or low) control over execution are inadequate in many ways. in this paper, we present mregtest, a replay-based regression testing framework in the context of model-driven development to facilitate deterministic replay of traces for detecting regressions while offering sufficient control for the purpose of testing over the execution of the changed system. the experimental results show that compared to the traditional approaches that annotate traces with timestamps and variable values mregtest detects almost all regressions while reducing the size of the trace significantly and incurring similar runtime overhead.",efficient replay-based regression testing for distributed reactive systems in the context of model-driven development
313,2-s2.0-85123374875,10.1109/ICSME52107.2021.00040,Cross-language Code Coupling Detection: A Preliminary Study on Android Applications,Shen B.,"Proceedings - 2021 IEEE International Conference on Software Maintenance and Evolution, ICSME 2021",2021-01-01,"Framework-based multi-lingual software is increasingly prevalent, but it also brings negative effects and extra burden on software maintenance and evolution, because of the introduced cross-language code coupling, which are usually mixed with framework-specific conventions. Researchers have proposed various approaches to code coupling detection, but there is still a lack of necessary support for cross-language coupling detection in framework-based software development. In this paper, we present a preliminary study about cross-language coupling detection in software development based on the Android application framework. We investigate the characteristics of multi-lingual changes in the top-100 starred open-source Android repositories on GitHub, and find that multi-lingual commits are non-trivial: their code changes are more scattered, and more inclined to introduce bugs than other commits. To mitigate the side-effect of multi-lingual development, we propose Grace, a Graph-based cross-language co-change suggestion approach for Android application development. Grace (a) designs a language-agnostic graph to represent code elements from different languages, and (b) employs an entity-based collaborative filtering algorithm to detect and rank candidates of cross-language code couplings, from the graph representation of the latest version as well as the historical multi-lingual commits of a repository. To evaluate the effectiveness of Grace, we apply it to the two tasks of cross-language co-change suggestion and inconsistency checking. Results show that Grace (a) can effectively suggest cross-language co-changed files and types, and (b) can also find existing and potential bugs or code smells caused by inconsistent co-changes.",cross-language code coupling | framework-based software development | multi-lingual software development | software maintenance and evolution;,0,378-388,Conference Proceeding,Conference Paper,7.0,"Shen, Bo;Zhang, Wei;Yu, Ailun;Wei, Zhao;Liang, Guangtai;Zhao, Haiyan;Jin, Zhi",56609617800;56760589600;57424321200;57282309200;36661190100;57219037610;8961795500,"Key Lab of High Confidence Software Technologies, Ministry of Education;Huawei Technologies Co., Ltd.",China;China,"framework-based multi-lingual software is increasingly prevalent, but it also brings negative effects and extra burden on software maintenance and evolution, because of the introduced cross-language code coupling, which are usually mixed with framework-specific conventions. researchers have proposed various approaches to code coupling detection, but there is still a lack of necessary support for cross-language coupling detection in framework-based software development. in this paper, we present a preliminary study about cross-language coupling detection in software development based on the android application framework. we investigate the characteristics of multi-lingual changes in the top-100 starred open-source android repositories on github, and find that multi-lingual commits are non-trivial: their code changes are more scattered, and more inclined to introduce bugs than other commits. to mitigate the side-effect of multi-lingual development, we propose grace, a graph-based cross-language co-change suggestion approach for android application development. grace (a) designs a language-agnostic graph to represent code elements from different languages, and (b) employs an entity-based collaborative filtering algorithm to detect and rank candidates of cross-language code couplings, from the graph representation of the latest version as well as the historical multi-lingual commits of a repository. to evaluate the effectiveness of grace, we apply it to the two tasks of cross-language co-change suggestion and inconsistency checking. results show that grace (a) can effectively suggest cross-language co-changed files and types, and (b) can also find existing and potential bugs or code smells caused by inconsistent co-changes.",cross-language code coupling detection: a preliminary study on android applications
314,2-s2.0-85123295307,10.1109/SCAM52516.2021.00027,What Do Developers Discuss about Code Comments?,Rani P.,"Proceedings - IEEE 21st International Working Conference on Source Code Analysis and Manipulation, SCAM 2021",2021-01-01,"Code comments are important for program comprehension, development, and maintenance tasks. Given the varying standards for code comments, and their unstructured or semi-structured nature, developers get easily confused (especially novice developers) about which convention(s) to follow, or what tools to use while writing code documentation. Thus, they post related questions on external online sources to seek better commenting practices. In this paper, we analyze code comment discussions on online sources such as Stack Overflow (SO) and Quora to shed some light on the questions developers ask about commenting practices. We apply Latent Dirichlet Allocation (LDA) to identify emerging topics concerning code comments. Then we manually analyze a statistically significant sample set of posts to derive a taxonomy that provides an overview of the developer questions about commenting practices.Our results highlight that on SO nearly 40% of the questions mention how to write or process comments in documentation tools and environments, and nearly 20% of the questions are about potential limitations and possibilities of documentation tools to add automatically and consistently more information in comments. On the other hand, on Quora, developer questions focus more on background information (35% of the questions) or asking opinions (16% of the questions) about code comments. We found that (i) not all aspects of comments are covered in coding style guidelines, e.g., how to add a specific type of information, (ii) developers need support in learning the syntax and format conventions to add various types of information in comments, and (iii) developers are interested in various automated strategies for comments such as detection of bad comments, or verify comment style automatically, but lack tool support to do that.",Code Comment analysis | Mining online sources | Quora | Software documentation | Stack Overflow,1,153-164,Conference Proceeding,Conference Paper,5.0,"Rani, Pooja;Birrer, Mathias;Panichella, Sebastiano;Ghafari, Mohammad;Nierstrasz, Oscar",57219693811;57223975293;35095375100;49661276600;6602127759,University of Bern;Universität Zürich;The University of Auckland,Switzerland;Switzerland;New Zealand,"code comments are important for program comprehension, development, and maintenance tasks. given the varying standards for code comments, and their unstructured or semi-structured nature, developers get easily confused (especially novice developers) about which convention(s) to follow, or what tools to use while writing code documentation. thus, they post related questions on external online sources to seek better commenting practices. in this paper, we analyze code comment discussions on online sources such as stack overflow (so) and quora to shed some light on the questions developers ask about commenting practices. we apply latent dirichlet allocation (lda) to identify emerging topics concerning code comments. then we manually analyze a statistically significant sample set of posts to derive a taxonomy that provides an overview of the developer questions about commenting practices.our results highlight that on so nearly 40% of the questions mention how to write or process comments in documentation tools and environments, and nearly 20% of the questions are about potential limitations and possibilities of documentation tools to add automatically and consistently more information in comments. on the other hand, on quora, developer questions focus more on background information (35% of the questions) or asking opinions (16% of the questions) about code comments. we found that (i) not all aspects of comments are covered in coding style guidelines, e.g., how to add a specific type of information, (ii) developers need support in learning the syntax and format conventions to add various types of information in comments, and (iii) developers are interested in various automated strategies for comments such as detection of bad comments, or verify comment style automatically, but lack tool support to do that.",what do developers discuss about code comments?
316,2-s2.0-85123050924,10.23919/MIPRO52101.2021.9596883,Next-generation Web Applications with WebAssembly and TruffleWasm,Sipek M.,"2021 44th International Convention on Information, Communication and Electronic Technology, MIPRO 2021 - Proceedings",2021-01-01,"In modern software development, the JavaScript ecosystem of various frameworks and libraries used to develop contemporary web applications presents many advantages. JavaScript is a widely known interpreted programming language, simple to learn and start development, and with numerous third-party libraries and extensions. However, with the rise of highly user-interactive websites and browser-based games, in some cases, JavaScript's executable engine could lack in performance. Therefore, developers could combine several other programming languages to create a polyglot user-interactive interoperable system to develop efficient modern web applications. The interoperability modules offer significant advantages but also present challenges in the execution due to high complexity and longer compilation times. This paper explores WebAssembly, a binary format compilation target with a low-level assembly-like language used for targeting from other programming languages. The binary format allows near-native performance level due to its compactness, as it prioritizes usage of low-level languages. Moreover, as a continuation of our previous research of the GraalVM ecosystem, we analyzed a guest language implementation of a WebAssembly based system, TruffleWasm, hosted on GraalVM and Truffle Java framework. This paper presents the architecture and review of the TruffleWasm within the GraalVM-based ecosystem as well as from performance test results within our academic environment.",Binary Format | GraalVM | JavaScript | Truffle | WebAssembly,0,1695-1700,Conference Proceeding,Conference Paper,4.0,"Sipek, M.;Muharemagic, D.;Mihaljevic, B.;Radovan, A.",57215360572;57220194052;14020072300;55912635000,Rochester Institute of Technology,United States,"in modern software development, the javascript ecosystem of various frameworks and libraries used to develop contemporary web applications presents many advantages. javascript is a widely known interpreted programming language, simple to learn and start development, and with numerous third-party libraries and extensions. however, with the rise of highly user-interactive websites and browser-based games, in some cases, javascript's executable engine could lack in performance. therefore, developers could combine several other programming languages to create a polyglot user-interactive interoperable system to develop efficient modern web applications. the interoperability modules offer significant advantages but also present challenges in the execution due to high complexity and longer compilation times. this paper explores webassembly, a binary format compilation target with a low-level assembly-like language used for targeting from other programming languages. the binary format allows near-native performance level due to its compactness, as it prioritizes usage of low-level languages. moreover, as a continuation of our previous research of the graalvm ecosystem, we analyzed a guest language implementation of a webassembly based system, trufflewasm, hosted on graalvm and truffle java framework. this paper presents the architecture and review of the trufflewasm within the graalvm-based ecosystem as well as from performance test results within our academic environment.",next-generation web applications with webassembly and trufflewasm
319,2-s2.0-85122038219,10.7717/peerj-cs.737,Clone-advisor: recommending code tokens and clone methods with deep learning and information retrieval,Hammad M.,PeerJ Computer Science,2021-01-01,"Software developers frequently reuse source code from repositories as it saves development time and effort. Code clones (similar code fragments) accumulated in these repositories represent often repeated functionalities and are candidates for reuse in an exploratory or rapid development. To facilitate code clone reuse, we previously presented DeepClone, a novel deep learning approach for modeling code clones along with non-cloned code to predict the next set of tokens (possibly a complete clone method body) based on the code written so far. The probabilistic nature of language modeling, however, can lead to code output with minor syntax or logic errors. To resolve this, we propose a novel approach called Clone-Advisor. We apply an information retrieval technique on top of DeepClone output to recommend real clone methods closely matching the predicted clone method, thus improving the original output by DeepClone. In this paper we have discussed and refined our previous work on DeepClone in much more detail. Moreover, we have quantitatively evaluated the performance and effectiveness of Clone-Advisor in clone method recommendation. Subjects Data Mining and Machine Learning, Software Engineering",Code clone | Code prediction | Code search | Deep learning | Information retrieval | Language modeling,2,1-39,Journal,Article,4.0,"Hammad, Muhammad;Babur, Önder;Basit, Hamid Abdul;van den Brand, Mark",56490230800;55949449000;12241632000;57192113699,Technische Universiteit Eindhoven;Prince Sultan University;Wageningen University &amp; Research,Netherlands;Saudi Arabia;Netherlands,"software developers frequently reuse source code from repositories as it saves development time and effort. code clones (similar code fragments) accumulated in these repositories represent often repeated functionalities and are candidates for reuse in an exploratory or rapid development. to facilitate code clone reuse, we previously presented deepclone, a novel deep learning approach for modeling code clones along with non-cloned code to predict the next set of tokens (possibly a complete clone method body) based on the code written so far. the probabilistic nature of language modeling, however, can lead to code output with minor syntax or logic errors. to resolve this, we propose a novel approach called clone-advisor. we apply an information retrieval technique on top of deepclone output to recommend real clone methods closely matching the predicted clone method, thus improving the original output by deepclone. in this paper we have discussed and refined our previous work on deepclone in much more detail. moreover, we have quantitatively evaluated the performance and effectiveness of clone-advisor in clone method recommendation. subjects data mining and machine learning, software engineering",clone-advisor: recommending code tokens and clone methods with deep learning and information retrieval
325,2-s2.0-85119982533,10.35595/2414-9179-2021-2-27-42-51,Design and development of the kondinsky lakes nature park's web map service,Spesivtsev D.S.,"InterCarto, InterGIS",2021-01-01,"Currently, many protected natural areas (PNA) implement geographic information systems (GIS) and technologies for structuring and managing collected spatial data to support of monitoring and scientific research. GIS of protected areas may be developed based on various software products and characterized by different level of functionality. Also, online web map services on this topic are being developed, which provide access to data not for employees only, but also for users. This paper focuses on the development of a web-GIS of the Kondinsky Lakes natural park located in the Tyumen region of Russian Federation and ensuring the preservation of unique river systems, landscapes, cultural and historical natural monuments. The web service includes cartographic layers and attribute data to characterize the main activities of the natural park. GIS layers are divided into thematic groups and contain information about flora and fauna, forest fires, logged areas, resting places and objects of the oil and gas mining in the park. The project is implemented using Leaflet, a popular open source web application development library. The code was written using the markup language HTML5, CSS3 and JavaScript. Data management is implemented using PostgreSQL DBMS. The publication is created based on the open GIS server Geoserver. The data structure and functionality of the developed web service is also presented. The developed web service can be used by both employees of the natural park (to develop the content of the databases) and its visitors, as well as organizations working in the field of environmental education and tourism.","Geoserver | Nature park ""Kondinskie lakes"" | Protected natural areas | Web map service",0,42-51,Conference Proceeding,Conference Paper,2.0,"Spesivtsev, Dmitriy S.;Larin, Eugeniy G.",57354719000;57354407000,Perm State University;Kondinsky Lakes Natural Park,Russian Federation;Russian Federation,"currently, many protected natural areas (pna) implement geographic information systems (gis) and technologies for structuring and managing collected spatial data to support of monitoring and scientific research. gis of protected areas may be developed based on various software products and characterized by different level of functionality. also, online web map services on this topic are being developed, which provide access to data not for employees only, but also for users. this paper focuses on the development of a web-gis of the kondinsky lakes natural park located in the tyumen region of russian federation and ensuring the preservation of unique river systems, landscapes, cultural and historical natural monuments. the web service includes cartographic layers and attribute data to characterize the main activities of the natural park. gis layers are divided into thematic groups and contain information about flora and fauna, forest fires, logged areas, resting places and objects of the oil and gas mining in the park. the project is implemented using leaflet, a popular open source web application development library. the code was written using the markup language html5, css3 and javascript. data management is implemented using postgresql dbms. the publication is created based on the open gis server geoserver. the data structure and functionality of the developed web service is also presented. the developed web service can be used by both employees of the natural park (to develop the content of the databases) and its visitors, as well as organizations working in the field of environmental education and tourism.",design and development of the kondinsky lakes nature park's web map service
327,2-s2.0-85119479820,10.21533/pen.v9i3.2190,Smart greenhouse and plant growth control,Umarov A.,Periodicals of Engineering and Natural Sciences,2021-01-01,"Since the development of agriculture is an important problem for every state, huge funds are allocated to this industry. However, the problem of lack of fresh fruits/vegetables, that is, the problem of import substitution remains a pressing issue in many countries. The aim of the study was to inspect the growth of plants in a home-based mini-greenhouse, for which reason the following tasks were set: conduct a biological experiment; search for dependence of the influence of environmental conditions (microclimate) on growth. The paper highlights the problem of import substitution of vegetables in Kazakhstan, and suggests the best way to solve this issue. The proposed solution offers the development of mini-greenhouse that meets the criteria of price and quality. The developed system differs from other smart greenhouses, firstly, by its availability to a wide range of users (price criterion), and secondly, by ensuring agrotechnical, energy, and design requirements (quality criterion). These requirements are implemented through the use of promising technologies: phytomonitoring, intelligent technologies and open source software, the use of available construction materials and water saving technologies such as drip irrigation. The economic effect from the use of the proposed technology has amounted to 10,000 tenge, the payback period was 4 seasons.",Drip irrigation | Home-based mini-greenhouse | Open source software________________________________________ | Optimum | Phytomonitoring | Plant growth dynamics,0,474-493,Journal,Article,5.0,"Umarov, Amantur;Belgibaev, Baurzhan;Grif, Mikhail;Mansurova, Madina;Kulmamirov, Serik",57226645743;57223978289;14043746900;56617164900;56236979300,Al Farabi Kazakh National University;Novosibirsk State Technical University,Kazakhstan;Russian Federation,"since the development of agriculture is an important problem for every state, huge funds are allocated to this industry. however, the problem of lack of fresh fruits/vegetables, that is, the problem of import substitution remains a pressing issue in many countries. the aim of the study was to inspect the growth of plants in a home-based mini-greenhouse, for which reason the following tasks were set: conduct a biological experiment; search for dependence of the influence of environmental conditions (microclimate) on growth. the paper highlights the problem of import substitution of vegetables in kazakhstan, and suggests the best way to solve this issue. the proposed solution offers the development of mini-greenhouse that meets the criteria of price and quality. the developed system differs from other smart greenhouses, firstly, by its availability to a wide range of users (price criterion), and secondly, by ensuring agrotechnical, energy, and design requirements (quality criterion). these requirements are implemented through the use of promising technologies: phytomonitoring, intelligent technologies and open source software, the use of available construction materials and water saving technologies such as drip irrigation. the economic effect from the use of the proposed technology has amounted to 10,000 tenge, the payback period was 4 seasons.",smart greenhouse and plant growth control
329,2-s2.0-85118986045,10.1109/ASE51524.2021.9678776,An Empirical Study of Bugs in WebAssembly Compilers,Romano A.,"Proceedings - 2021 36th IEEE/ACM International Conference on Automated Software Engineering, ASE 2021",2021-01-01,"WebAssembly is the newest programming language for the Web. It defines a portable bytecode format for use as a compilation target for programs developed in high-level languages such as C, C++, and Rust. As a result, WebAssembly binaries are generally created by WebAssembly compilers rather than being written manually. To port native code to the Web, WebAssembly compilers need to address the differences between the source and target languages and dissimilarities in their execution environments. A deep understanding of the bugs in WebAssembly compilers can help compiler developers determine where to focus development and testing efforts. In this paper, we conduct two empirical studies to understand the characteristics of the bugs found in WebAssembly compilers. First, we perform a qualitative analysis of bugs in Emscripten, the most widely-used WebAssembly compiler. We investigate 146 bug reports in Emscripten related to the unique challenges WebAssembly compilers encounter compared with traditional compilers. Second, we provide a quantitative analysis of 1, 054 bugs in three open-source WebAssembly compilers, AssemblyScript, Emscripten, and Rustc/Wasm-Bindgen. We analyze these bugs along three dimensions: lifecycle, impact, and sizes of bug-inducing inputs and bug fixes. These studies deepen our understanding of WebAssembly compiler bugs. We hope that the findings of our study will shed light on opportunities to design practical tools for testing and debugging WebAssembly compilers.",Compiler | Qualitative study | Quantitative study | WebAssembly,1,42-54,Conference Proceeding,Conference Paper,4.0,"Romano, Alan;Liu, Xinyue;Kwon, Yonghwi;Wang, Weihang",57219598469;57470927900;56027584100;57215072734,"University at Buffalo, The State University of New York;University of Virginia",United States;United States,"webassembly is the newest programming language for the web. it defines a portable bytecode format for use as a compilation target for programs developed in high-level languages such as c, c++, and rust. as a result, webassembly binaries are generally created by webassembly compilers rather than being written manually. to port native code to the web, webassembly compilers need to address the differences between the source and target languages and dissimilarities in their execution environments. a deep understanding of the bugs in webassembly compilers can help compiler developers determine where to focus development and testing efforts. in this paper, we conduct two empirical studies to understand the characteristics of the bugs found in webassembly compilers. first, we perform a qualitative analysis of bugs in emscripten, the most widely-used webassembly compiler. we investigate 146 bug reports in emscripten related to the unique challenges webassembly compilers encounter compared with traditional compilers. second, we provide a quantitative analysis of 1, 054 bugs in three open-source webassembly compilers, assemblyscript, emscripten, and rustc/wasm-bindgen. we analyze these bugs along three dimensions: lifecycle, impact, and sizes of bug-inducing inputs and bug fixes. these studies deepen our understanding of webassembly compiler bugs. we hope that the findings of our study will shed light on opportunities to design practical tools for testing and debugging webassembly compilers.",an empirical study of bugs in webassembly compilers
333,2-s2.0-85118162419,10.1007/978-3-030-88378-2_10,Web-Based Real-Time Gesture Recognition with Voice,Pralhad G.P.,Communications in Computer and Information Science,2021-01-01,"WebPredict.ai is a model web developed for converting image into text, followed by the conversion of the predicted text to speech. Images used in the proposed application are taken in the form of hand gestural inputs with the help of webcam. This application also helps to interact with google home or smart home of google. As the gestures captured by the webcam can be given for functionality which works for google home and the application can speak out the gesture inputs with different OS voices. These different OS voices are supported by user’s browser and Device. This application was developed on HTML, JavaScript and with the help of Tensorflow.js. Tensorflow.js is an open-source library which is used to train, define, and run machine learning models entirely in the browser, with the help of JavaScript and some high-level API’s. The runtime environment for the proposed model is provided by Node.js which helps in the development of web application and is written in JavaScript. In the proposed application, ML algorithm is running in the web browser, hence there is no need to install any driver or library. Users just need to open the webpage and the program is ready to run. Users can also open the webpage from a mobile device.",CNN | Gesture recognition | Google nest | Mobilenet | Nodejs | WebGL,0,119-131,Book Series,Conference Paper,6.0,"Pralhad, Ghadekar Premanand;Abhishek, S.;Kachare, Tejas;Deshpande, Om;Chounde, Rushikesh;Tapadiya, Prachi",56637017300;57519195300;57315054900;57315472800;57315264600;6506338010,Vishwakarma Institute of Technology,India,"webpredict.ai is a model web developed for converting image into text, followed by the conversion of the predicted text to speech. images used in the proposed application are taken in the form of hand gestural inputs with the help of webcam. this application also helps to interact with google home or smart home of google. as the gestures captured by the webcam can be given for functionality which works for google home and the application can speak out the gesture inputs with different os voices. these different os voices are supported by user’s browser and device. this application was developed on html, javascript and with the help of tensorflow.js. tensorflow.js is an open-source library which is used to train, define, and run machine learning models entirely in the browser, with the help of javascript and some high-level api’s. the runtime environment for the proposed model is provided by node.js which helps in the development of web application and is written in javascript. in the proposed application, ml algorithm is running in the web browser, hence there is no need to install any driver or library. users just need to open the webpage and the program is ready to run. users can also open the webpage from a mobile device.",web-based real-time gesture recognition with voice
334,2-s2.0-85118129097,10.1007/978-3-030-89159-6_11,From Requirements to Executable Rules: An Ensemble of Domain-Specific Languages for Programming Cyber-Physical Systems in Warehouse Logistics,Mauritz M.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2021-01-01,"The fourth industrial revolution is driven by Software-enabled automation. To fully realize the potential of this digital transformation in a way that is beneficial to society, automation needs to become programmable by domain experts—the vision being a Software-assisted increase in productivity instead of replacing workers with Software. While domain experts, e.g., workers in production, typically have extensive experience with processes and workflows involving cyber-physical systems, e.g., production machines, they have little to no knowledge of programming and formal logic. In this paper, we present a framework for expressing executable rules in the context of a cyber-physical system at the conceptual level, akin to human reasoning, in almost natural sentences (e.g., if a person is within 1 m of the machine then the light will turn red). These requirements are automatically transformed by our framework into formal logic and can be executed and evaluated by a rule engine without additional input by domain experts. The framework is designed in a modular way that enables domain engineering, i.e., the development of new languages for individual application domains, with minimal effort. Only domain-specific entities and predicates (e.g., is within) need to be defined and implemented for a new domain. We demonstrate our framework in a logistics scenario on a shop floor that requires human-machine collaboration.",Domain-specific languages | Language model transformation | Language programming | Logistics | Runtime monitoring,1,162-177,Book Series,Conference Paper,2.0,"Mauritz, Malte;Roidl, Moritz",56505425600;35746740400,Technische Universität Dortmund,Germany,"the fourth industrial revolution is driven by software-enabled automation. to fully realize the potential of this digital transformation in a way that is beneficial to society, automation needs to become programmable by domain experts—the vision being a software-assisted increase in productivity instead of replacing workers with software. while domain experts, e.g., workers in production, typically have extensive experience with processes and workflows involving cyber-physical systems, e.g., production machines, they have little to no knowledge of programming and formal logic. in this paper, we present a framework for expressing executable rules in the context of a cyber-physical system at the conceptual level, akin to human reasoning, in almost natural sentences (e.g., if a person is within 1 m of the machine then the light will turn red). these requirements are automatically transformed by our framework into formal logic and can be executed and evaluated by a rule engine without additional input by domain experts. the framework is designed in a modular way that enables domain engineering, i.e., the development of new languages for individual application domains, with minimal effort. only domain-specific entities and predicates (e.g., is within) need to be defined and implemented for a new domain. we demonstrate our framework in a logistics scenario on a shop floor that requires human-machine collaboration.",from requirements to executable rules: an ensemble of domain-specific languages for programming cyber-physical systems in warehouse logistics
337,2-s2.0-85115876708,10.1007/978-3-030-84340-3_9,Design of Web Application with Dynamic Generation of Forms for Group Decision-Making,Dimitrova Z.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2021-01-01,"The primary role of software engineering is to apply engineering approaches to improve the processes and methods for software development. There are various different custom applications that could be generalized as a common application’ tool. These applications are related to the problems of different group decision-making variants. In order to improve the software quality, modular architecture could be used to separate different functionality and to minimize the complexity of each individual module. For the goal, the current article deals with the problem of the dynamic generation of matrices that is the core of group decision-making. An algorithm for designing a web application to support group decision-making based on multi-attribute utility theory is proposed. This algorithm is implemented in a web-based software tool to support group decision-making. The main features of the described tool to support group-decision making are the ability to generate individual matrices for each expert and subsequent generation of aggregated group-decision matrix. These two types of matrices together with the completed data are stored as two components of the problem to be solved and can be reused. The proposed algorithm and software tool are applied in a case study for a group decision-making problem for the selection of videoconferencing software tool. The obtained results show the applicability of the dynamic generation of forms that support group decision-making.",Dynamic generation of forms | Group decision-making | Software architecture | Software engineering | Web application,0,112-123,Book Series,Conference Paper,3.0,"Dimitrova, Zornitsa;Borissova, Daniela;Dimitrov, Vasil",57220023707;23990012600;57221646761,"Institute of Information and Communication Technologies, Bulgarian Academy of Sciences;University of Library Studies and Information Technologies",Bulgaria;Bulgaria,"the primary role of software engineering is to apply engineering approaches to improve the processes and methods for software development. there are various different custom applications that could be generalized as a common application’ tool. these applications are related to the problems of different group decision-making variants. in order to improve the software quality, modular architecture could be used to separate different functionality and to minimize the complexity of each individual module. for the goal, the current article deals with the problem of the dynamic generation of matrices that is the core of group decision-making. an algorithm for designing a web application to support group decision-making based on multi-attribute utility theory is proposed. this algorithm is implemented in a web-based software tool to support group decision-making. the main features of the described tool to support group-decision making are the ability to generate individual matrices for each expert and subsequent generation of aggregated group-decision matrix. these two types of matrices together with the completed data are stored as two components of the problem to be solved and can be reused. the proposed algorithm and software tool are applied in a case study for a group decision-making problem for the selection of videoconferencing software tool. the obtained results show the applicability of the dynamic generation of forms that support group decision-making.",design of web application with dynamic generation of forms for group decision-making
338,2-s2.0-85115375265,10.3233/JIFS-211011,Intelligent mining vulnerabilities in python code snippets,Guo W.,Journal of Intelligent and Fuzzy Systems,2021-01-01,"In the software development process, many developers learn from code snippets in the open-source community to implement specific functions. However, few people think about whether these code have vulnerabilities, which provides channels for developing unsafe programs. To this end, this paper constructs a source code snippets vulnerability mining system named PyVul based on deep learning to automatically detect the security of code snippets in the open source community. PyVul builds abstract syntax tree (AST) for the source code to extract its code feature, and then introduces the bidirectional long-term short-term memory (BiLSTM) neural network algorithm to detect vulnerability codes. If it is vulnerable code, the further constructed a multi-classification model could analyze the context discussion contents in associated threads, to classify the code vulnerability type based the content description. Compared with traditional detection methods, this method can identify vulnerable code and classify vulnerability type. The accuracy of the proposed model can reach 85%. PyVul also found 138 vulnerable code snippets in the real public open-source community. In the future, it can be used in the open-source community for vulnerable code auditing to assist users in safe development.",BiLSTM | content analysis | Open-source community | vulnerability mining,1,3615-3628,Journal,Article,4.0,"Guo, Wenbo;Huang, Cheng;Niu, Weina;Fang, Yong",57267203800;55511401300;56417209400;57026722800,Sichuan University;University of Electronic Science and Technology of China,China;China,"in the software development process, many developers learn from code snippets in the open-source community to implement specific functions. however, few people think about whether these code have vulnerabilities, which provides channels for developing unsafe programs. to this end, this paper constructs a source code snippets vulnerability mining system named pyvul based on deep learning to automatically detect the security of code snippets in the open source community. pyvul builds abstract syntax tree (ast) for the source code to extract its code feature, and then introduces the bidirectional long-term short-term memory (bilstm) neural network algorithm to detect vulnerability codes. if it is vulnerable code, the further constructed a multi-classification model could analyze the context discussion contents in associated threads, to classify the code vulnerability type based the content description. compared with traditional detection methods, this method can identify vulnerable code and classify vulnerability type. the accuracy of the proposed model can reach 85%. pyvul also found 138 vulnerable code snippets in the real public open-source community. in the future, it can be used in the open-source community for vulnerable code auditing to assist users in safe development.",intelligent mining vulnerabilities in python code snippets
340,2-s2.0-85113712332,10.1007/978-3-030-84845-3_7,Digitalisation for Improving Population Well-Being in the Arctic Area,Rakova V.,Communications in Computer and Information Science,2021-01-01,"This study describes the development of information and technological support that accumulates information and analytical materials concerning the sanitary and epidemiological environments of the Russian Arctic population. Maintaining a healthy epidemiological situation is vital for the Arctic region. However, active development of the Arctic region is ongoing. The penetration of pathogens into the region is unacceptable. Information and technological support for social and hygienic monitoring is being developed. Within the framework of the geoportal, a user’s personal account is formed with the possibility of registering it. The required functionality of the portal has been developed; an interface has been implemented to improve decision-making efficiency based on the information provided to the user. Input data on the state of health and environmental factors of the Russian Arctic population allow us to analyse information on directions and regions. Data were collected from all the arctic zone regions and provided by the respective regions for the past year. The developed software allows processing input data and forming summary files in the following directions: ‘Public Health’, ‘Human habitat’, ‘Socio-economic markers’, ‘Medico-demographic markers’, ‘Food safety’, etc. The system creates summary files, which are further analysed by a separate software module with the possibility of visualisation by layers. The developed IT solution can significantly improve the sanitary and epidemiological well-being of the Russian Arctic population.",Algorithm | Geoportal | Information technology support | Russian Arctic | Software,0,105-117,Book Series,Conference Paper,5.0,"Rakova, Valeria;Bolsunovskaya, Marina;Zorin, Arseny;Fedorov, Vladimir;Novikova, Yuliya",57212165651;57191609119;57212931954;57198035272;57205760350,North-West Public Health Research Center;Peter the Great St. Petersburg Polytechnic University,Russian Federation;Russian Federation,"this study describes the development of information and technological support that accumulates information and analytical materials concerning the sanitary and epidemiological environments of the russian arctic population. maintaining a healthy epidemiological situation is vital for the arctic region. however, active development of the arctic region is ongoing. the penetration of pathogens into the region is unacceptable. information and technological support for social and hygienic monitoring is being developed. within the framework of the geoportal, a user’s personal account is formed with the possibility of registering it. the required functionality of the portal has been developed; an interface has been implemented to improve decision-making efficiency based on the information provided to the user. input data on the state of health and environmental factors of the russian arctic population allow us to analyse information on directions and regions. data were collected from all the arctic zone regions and provided by the respective regions for the past year. the developed software allows processing input data and forming summary files in the following directions: ‘public health’, ‘human habitat’, ‘socio-economic markers’, ‘medico-demographic markers’, ‘food safety’, etc. the system creates summary files, which are further analysed by a separate software module with the possibility of visualisation by layers. the developed it solution can significantly improve the sanitary and epidemiological well-being of the russian arctic population.",digitalisation for improving population well-being in the arctic area
343,2-s2.0-85112733781,10.1007/978-3-030-80129-8_31,Development and Design of a Library Information System Intended for Automation of Processes in Higher Education Institution,Boranbayev A.,Lecture Notes in Networks and Systems,2021-01-01,"The Library Information System was built in-house for the university. In this article we are describing the architecture and design of the Library Information system that was built for the automation of library processes (ordering, picking, cataloging, electronic catalog, book search, reservation of small-copy books, inventory of books/electronic media, booking and viewing of electronic publications), as well as providing readers with access to the electronic catalog, to printed and other documents of the University with electronic documents, video, audio and other information attached to bibliographic records. The described information system is web-based and is one of the most important systems in the university. The main stakeholders of the developed Library System are the employees of the Library, students, and professors of the university. The system was developed using the following technologies: Java; JavaScript; HTML; CSS; Red Hat Enterprise Linux Server 6.2; HTTP Server; LDAP Server; IBM WebSphere Portal Enable Processor Value Unit; IBM DB2 Enterprise Server Edition Processor Value Unit; IBM Rational Software Architect for WebSphere Authorized User; Oracle Database Enterprise Edition; Documentum Platform Bundle; EMC Documentum Custom Client; IBM DB2 Enterprise Server Edition 9.7.0.9.",Information system | Software | Software development | System architecture | Web application,0,437-445,Book Series,Conference Paper,3.0,"Boranbayev, Askar;Baidyussenov, Ruslan;Mazhitov, Mikhail",26040482100;57201704632;7801548346,Nazarbayev University,Kazakhstan,"the library information system was built in-house for the university. in this article we are describing the architecture and design of the library information system that was built for the automation of library processes (ordering, picking, cataloging, electronic catalog, book search, reservation of small-copy books, inventory of books/electronic media, booking and viewing of electronic publications), as well as providing readers with access to the electronic catalog, to printed and other documents of the university with electronic documents, video, audio and other information attached to bibliographic records. the described information system is web-based and is one of the most important systems in the university. the main stakeholders of the developed library system are the employees of the library, students, and professors of the university. the system was developed using the following technologies: java; javascript; html; css; red hat enterprise linux server 6.2; http server; ldap server; ibm websphere portal enable processor value unit; ibm db2 enterprise server edition processor value unit; ibm rational software architect for websphere authorized user; oracle database enterprise edition; documentum platform bundle; emc documentum custom client; ibm db2 enterprise server edition 9.7.0.9.",development and design of a library information system intended for automation of processes in higher education institution
348,2-s2.0-85111715127,10.1007/978-981-16-0761-5_54,Stratigraphic Horizon Prediction Integrating Wells and Seismic Data Based on Kriging Interpolation,Liu S.s.,Springer Series in Geomechanics and Geoengineering,2021-01-01,"Stratigraphic horizon is an important constraint for drilling geology and engineering design. It is necessary to design wellbore structure and trajectory according to the predicted depth of some key layers to guide the adjustment of actual drilling trajectory and reduce the occurrence of complex drilling accidents. Generally, the geological horizon depth is predicted by seismic data, and the large-scale continuity of seismic data is good, but the accuracy is relatively low, resulting in inaccurate prediction results, which need to be corrected by real drilling data. The formation model is constructed through the integration of seismic horizon data and drilling data, which has both the horizontal accuracy of seismic data and the vertical accuracy of drilling data. It accurately describes the characteristics of the formation and dynamically correct the formation model in the process of drilling to achieve more accurate operation guidance. In this paper, Kriging interpolation algorithm is used to predict the depth plane distribution of key strata (marker reservoir) according to the existing depth data of exploration and evaluation wells in the development block and correct the seismic prediction results. A geological mapping software is developed to display stratigraphic distribution, which can realize the visualization display of well number, X (North coordinate), Y (East coordinate), formation depth. Using the geological mapping software for the prediction of formation depth will have a significant impact on the convenience for reservoir management analysis. This study can be used in field management and workover planning to provide a cost-effective convenient, intuitive and efficient solution to the geological horizon prediction.",Combination of logging and seismic | Kriging interpolation | Stratigraphic horizon prediction,0,555-561,Book Series,Conference Paper,1.0,"Liu, Shan shan",57210931747,China University of Petroleum-Beijing,China,"stratigraphic horizon is an important constraint for drilling geology and engineering design. it is necessary to design wellbore structure and trajectory according to the predicted depth of some key layers to guide the adjustment of actual drilling trajectory and reduce the occurrence of complex drilling accidents. generally, the geological horizon depth is predicted by seismic data, and the large-scale continuity of seismic data is good, but the accuracy is relatively low, resulting in inaccurate prediction results, which need to be corrected by real drilling data. the formation model is constructed through the integration of seismic horizon data and drilling data, which has both the horizontal accuracy of seismic data and the vertical accuracy of drilling data. it accurately describes the characteristics of the formation and dynamically correct the formation model in the process of drilling to achieve more accurate operation guidance. in this paper, kriging interpolation algorithm is used to predict the depth plane distribution of key strata (marker reservoir) according to the existing depth data of exploration and evaluation wells in the development block and correct the seismic prediction results. a geological mapping software is developed to display stratigraphic distribution, which can realize the visualization display of well number, x (north coordinate), y (east coordinate), formation depth. using the geological mapping software for the prediction of formation depth will have a significant impact on the convenience for reservoir management analysis. this study can be used in field management and workover planning to provide a cost-effective convenient, intuitive and efficient solution to the geological horizon prediction.",stratigraphic horizon prediction integrating wells and seismic data based on kriging interpolation
349,2-s2.0-85111388184,10.1007/978-3-030-77543-8_7,Sterling: A Web-Based Visualizer for Relational Modeling Languages,Dyer T.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2021-01-01,"We introduce Sterling, a web-based visualization tool that provides interactive views of relational models and allows users to create custom visualizations using modern JavaScript libraries like D3 and Cytoscape. We outline its design goals and architecture, and describe custom visualizations developed with Sterling that enable verification studies of scientific software used in production. While development is driven primarily by the Alloy community, other relational modeling languages are accommodated by Sterling’s data agnostic architecture.",Alloy | Formal methods | Sterling | Visualization,1,99-104,Book Series,Conference Paper,2.0,"Dyer, Tristan;Baugh, John",56470407900;35323780700,Brown University;NC State University,United States;United States,"we introduce sterling, a web-based visualization tool that provides interactive views of relational models and allows users to create custom visualizations using modern javascript libraries like d3 and cytoscape. we outline its design goals and architecture, and describe custom visualizations developed with sterling that enable verification studies of scientific software used in production. while development is driven primarily by the alloy community, other relational modeling languages are accommodated by sterling’s data agnostic architecture.",sterling: a web-based visualizer for relational modeling languages
353,2-s2.0-85107380187,10.1007/978-981-16-1480-4_21,Exploiting an Ontology-Based Solution to Study Code Smells,Betancourt I.C.,Communications in Computer and Information Science,2021-01-01,"Code smells (CS) are anomalies in the source code of software which may affect its structure and quality. They affect the maintainability of the systems because reduce reusability and make difficult the analysis of code. The coexistence of these errors causes architectural problems that hinder the maintenance process and evolution of the software, increasing future failures. CS usually rises due to the adoption of bad programming practices. Hence, the knowledge and skills of the developers and architects are crucial to avoid them. To address this issue, in this paper we introduce an ontology-based approach to represent and analyze the knowledge about CS. To develop the ontology, the well-known Protégé tool was used and a sound methodology for the development of ontologies was followed. This approach could be a useful instrument to enhance the knowledge of the software developers and architects. Finally, some evidences that proof the impact of the approach are presented.",Code smell | Knowledge | Ontology,0,234-246,Book Series,Conference Paper,5.0,"Betancourt, Ivian Castellano;Martínez, Nemury Silega;García, Manuel Noguera;Grass, Olga Rojas;Vázquez, Osmar Capote",57219341329;56161897800;15020955800;57224323733;57224318985,"Universidad Internacional de Andalucía;Universidad de las Ciencias Informáticas, Cuba;Universidad de Granada",Spain;Cuba;Spain,"code smells (cs) are anomalies in the source code of software which may affect its structure and quality. they affect the maintainability of the systems because reduce reusability and make difficult the analysis of code. the coexistence of these errors causes architectural problems that hinder the maintenance process and evolution of the software, increasing future failures. cs usually rises due to the adoption of bad programming practices. hence, the knowledge and skills of the developers and architects are crucial to avoid them. to address this issue, in this paper we introduce an ontology-based approach to represent and analyze the knowledge about cs. to develop the ontology, the well-known protégé tool was used and a sound methodology for the development of ontologies was followed. this approach could be a useful instrument to enhance the knowledge of the software developers and architects. finally, some evidences that proof the impact of the approach are presented.",exploiting an ontology-based solution to study code smells
354,2-s2.0-85107362883,10.1007/978-3-030-71503-8_37,Performance and Security Evaluation in Microservices Architecture Using Open Source Containers,Castillo Rivas D.A.,Communications in Computer and Information Science,2021-01-01,"Nowadays, microservices architecture has increased its popularity within software development. This architecture is considered as a refinement and simplification of the service-oriented architecture (SOA). In microservices, the development approach is given by the functional decomposition into small services, where each one makes use of its own computational resources and light communication mechanisms, such as HTTP. Compared to monolithic architectures, microservices can be developed using different code bases. Therefore, performance and security are two of the quality attributes that must be taken into account when building microservices. The objective of this work is to define a DevOps Pipeline that allows us to use best practices at the development level to improve performance and security in pre-production environments. For deployment, two open-source containers are selected to evaluate under which situations it is more convenient to use Docker or Containerd, especially at the base image level.",Containers | Microservices | Performance | Security,0,484-498,Book Series,Conference Paper,2.0,"Castillo Rivas, Diego Antonio;Guamán, Daniel",57224319914;57188566526,Universidad Tecnica Particular de Loja,Ecuador,"nowadays, microservices architecture has increased its popularity within software development. this architecture is considered as a refinement and simplification of the service-oriented architecture (soa). in microservices, the development approach is given by the functional decomposition into small services, where each one makes use of its own computational resources and light communication mechanisms, such as http. compared to monolithic architectures, microservices can be developed using different code bases. therefore, performance and security are two of the quality attributes that must be taken into account when building microservices. the objective of this work is to define a devops pipeline that allows us to use best practices at the development level to improve performance and security in pre-production environments. for deployment, two open-source containers are selected to evaluate under which situations it is more convenient to use docker or containerd, especially at the base image level.",performance and security evaluation in microservices architecture using open source containers
355,2-s2.0-85107339544,10.1541/ieejfms.141.367,A study on development of teaching materials for learning IoT implementation,Ohyama R.I.,IEEJ Transactions on Fundamentals and Materials,2021-01-01,"From the background where educational available techniques related to ICT with computer programming have been arranged, an example of IoT implementation is experimentally conducted as the teaching materials. The web application is IoT performing remote monitoring and control such as switch operation of the commercial power supply and the live line parameters to watch the voltage, current, power consumption. The http protocol software consisted of web front-end and back-end is based on JavaScript with Node.js and Socket.io in order to allow students to understand a principle easily of the two-way communication. The hardware and software system can be set with simple and easy machine parts for students to learn the IoT implementation.",Development of teaching material | IoT implementation | Node.js | Two-way communication | Web application,0,367-372,Journal,Article,1.0,"Ohyama, Ryu Ichiro",7004144073,Tokai University,Japan,"from the background where educational available techniques related to ict with computer programming have been arranged, an example of iot implementation is experimentally conducted as the teaching materials. the web application is iot performing remote monitoring and control such as switch operation of the commercial power supply and the live line parameters to watch the voltage, current, power consumption. the http protocol software consisted of web front-end and back-end is based on javascript with node.js and socket.io in order to allow students to understand a principle easily of the two-way communication. the hardware and software system can be set with simple and easy machine parts for students to learn the iot implementation.",a study on development of teaching materials for learning iot implementation
357,2-s2.0-85107328554,10.1007/978-3-030-72651-5_58,Used of Web Scraping on Knowledge Representation Model for Bodies of Knowledge as a Tool to Development Curriculum,Quezada-Sarmiento P.A.,Advances in Intelligent Systems and Computing,2021-01-01,"This article shows the use of NEON (Ontological Methodology), Scrum (Agile Methodology), and web scraping to develop an application of an ontological Knowledge Representation Model for Bodies of Knowledge as a supplementary tool to improve a curriculum in Software Engineering context. The contributions of this article are the following: First, it is carried out the combination, and application of ontological methodologies, and agile development; second, an application was developed in Java, using the Jsoup library, for the extraction and visualization of the information of BOK of Software Engineering degree.",Body of knowledge | Curriculum | NeOn | Ontology | Scrum,0,611-620,Book Series,Conference Paper,4.0,"Quezada-Sarmiento, Pablo Alejandro;Elorriaga, Jon A.;Arruarte, Ana;Jumbo-Flores, Luis Alberto",57195316099;6603302634;7801309394;57195313348,Universidad del Pais Vasco;Teacher and Research,Spain;Ecuador,"this article shows the use of neon (ontological methodology), scrum (agile methodology), and web scraping to develop an application of an ontological knowledge representation model for bodies of knowledge as a supplementary tool to improve a curriculum in software engineering context. the contributions of this article are the following: first, it is carried out the combination, and application of ontological methodologies, and agile development; second, an application was developed in java, using the jsoup library, for the extraction and visualization of the information of bok of software engineering degree.",used of web scraping on knowledge representation model for bodies of knowledge as a tool to development curriculum
360,2-s2.0-85106600404,10.32620/REKS.2021.1.09,EVALUATION OF USE OF DESIGN TEMPLATES IN THE SOFTWARE DEVELOPMENT,Bychok M.,Radioelectronic and Computer Systems,2021-01-01,"The subject of study in the article is software development processes using design patterns. The aim is to improve the quality of modern software development projects through the use of experience and knowledge, to build software subsystems that are focused on infrastructure and work with an external client. Objectives: to review the methodology, programming paradigms and the possibility of their application at the design and coding stages of the software development life cycle; development of the concept of using design patterns in software design as knowledge available for reuse, propose an approach to the practical implementation of design patterns to node.js projects. The models used are the Composite design pattern, the Chain of responsibility design pattern. The used methodologies are object-oriented programming, as the most common programming paradigm, a unified modeling language UML for displaying the structure of design patterns. The following results are obtained. Modern methodologies and design paradigms are considered, a classification is formed in the form of a tree structure with a division into declarative and imperative subspecies, it is concluded that within the framework of the study we will use an object-oriented methodology as the most common design paradigm. An example of building an information system of the node.js project is considered. Analyzed the main errors that arise when developing and writing code for working with an external client. The elements of the node.js project and the concepts of structuring their relationship with existing design patterns are considered. An example of a practical implementation of a node.js project and its relationship with the Composite and Chain of responsibility design patterns is considered. In this connection, the work provides the structure of these templates. Findings. The scientific novelty of the results obtained is as follows: the model of design patterns was further developed through their use in the concept of building a node.js application, which makes it possible to improve the quality of interaction between the project team and reduce its execution time.",design patterns | node.js project | programming paradigm | software,2,101-109,Journal,Article,2.0,"Bychok, M.;Pohudina, O.",57223985416;57204907264,National Aerospace University “Kharkiv Aviation Institute”,Ukraine,"the subject of study in the article is software development processes using design patterns. the aim is to improve the quality of modern software development projects through the use of experience and knowledge, to build software subsystems that are focused on infrastructure and work with an external client. objectives: to review the methodology, programming paradigms and the possibility of their application at the design and coding stages of the software development life cycle; development of the concept of using design patterns in software design as knowledge available for reuse, propose an approach to the practical implementation of design patterns to node.js projects. the models used are the composite design pattern, the chain of responsibility design pattern. the used methodologies are object-oriented programming, as the most common programming paradigm, a unified modeling language uml for displaying the structure of design patterns. the following results are obtained. modern methodologies and design paradigms are considered, a classification is formed in the form of a tree structure with a division into declarative and imperative subspecies, it is concluded that within the framework of the study we will use an object-oriented methodology as the most common design paradigm. an example of building an information system of the node.js project is considered. analyzed the main errors that arise when developing and writing code for working with an external client. the elements of the node.js project and the concepts of structuring their relationship with existing design patterns are considered. an example of a practical implementation of a node.js project and its relationship with the composite and chain of responsibility design patterns is considered. in this connection, the work provides the structure of these templates. findings. the scientific novelty of the results obtained is as follows: the model of design patterns was further developed through their use in the concept of building a node.js application, which makes it possible to improve the quality of interaction between the project team and reduce its execution time.",evaluation of use of design templates in the software development
361,2-s2.0-85104865979,10.1007/978-3-030-68080-0_22,Bootstrap as a Tool for Web Development and Graphic Optimization on Mobile Devices,López-Gorozabel O.,Advances in Intelligent Systems and Computing,2021-01-01,"The advance of technology requires that people need publicity and administrative advice of their business through the Web. It is there where the role of the web developer appears since this topic must make use of the appropriate tools that enhance their work. The style pages have been facilitating the elaboration of web pages for some years now. However, programmers have not created any framework to optimize the size of the interfaces automatically. By doing so, navigation from any device without any anomaly. Currently, the massive use of mobile devices requires the optimization of the design of the graphic interfaces developed for computers to the resolution of mobile devices. One could say that this motivated the company Twitter in 2011 to create Bootstrap, a framework with the function of adjusting the resolution of websites that can be developed from a computer and then be displayed correctly in the different screen resolutions of mobile devices. This article tries to orient the evaluation of the Bootstrap tool for the re-engineering of the web system “EducArte Comunidad” interacting with the following design languages: HTML5, CSS, and JQuery. Specifically, this research is carried out based on the observation in the development of computer applications under the multiplatform modality.",Adaptive frame | Bootstrap | Graphic interfaces | Graphic languages | Websites,1,290-302,Book Series,Conference Paper,5.0,"López-Gorozabel, Oscar;Cedeño-Palma, Emilio;Pinargote-Ortega, Jenmer;Zambrano-Romero, Walter;Pazmiño-Campuzano, Marcos",57223111865;57223106913;57223102016;57207912531;57223104790,Universidad Técnica de Manabí,Ecuador,"the advance of technology requires that people need publicity and administrative advice of their business through the web. it is there where the role of the web developer appears since this topic must make use of the appropriate tools that enhance their work. the style pages have been facilitating the elaboration of web pages for some years now. however, programmers have not created any framework to optimize the size of the interfaces automatically. by doing so, navigation from any device without any anomaly. currently, the massive use of mobile devices requires the optimization of the design of the graphic interfaces developed for computers to the resolution of mobile devices. one could say that this motivated the company twitter in 2011 to create bootstrap, a framework with the function of adjusting the resolution of websites that can be developed from a computer and then be displayed correctly in the different screen resolutions of mobile devices. this article tries to orient the evaluation of the bootstrap tool for the re-engineering of the web system “educarte comunidad” interacting with the following design languages: html5, css, and jquery. specifically, this research is carried out based on the observation in the development of computer applications under the multiplatform modality.",bootstrap as a tool for web development and graphic optimization on mobile devices
362,2-s2.0-85104729381,10.1007/978-3-030-73785-6_6,K and KIV: Towards Deductive Verification for Arbitrary Programming Languages,Klumpp D.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2021-01-01,"Deductive program verification is a powerful tool to gain confidence in the correctness of software. However, its application to real programs faces a major hurdle: Each programming language requires development of dedicated verification tool support. In this work, we aim to advance deductive software verification to arbitrary programming languages. We developed a tool that derives algebraic specifications for the deductive proof assistant KIV from the syntax and operational semantics of a programming language specified in the K semantic framework. We adapt and implement the generic One-Path Reachability calculus and provide instant tool support for deductive proofs. Through a sophisticated automation approach, we drastically reduce the manual proof steps.",Interactive verification | K framework | Reachability logic,0,98-119,Book Series,Conference Paper,2.0,"Klumpp, Dominik;Lenzen, Philip",57193138173;57223100114,Universität Freiburg;Universität Augsburg,Germany;Germany,"deductive program verification is a powerful tool to gain confidence in the correctness of software. however, its application to real programs faces a major hurdle: each programming language requires development of dedicated verification tool support. in this work, we aim to advance deductive software verification to arbitrary programming languages. we developed a tool that derives algebraic specifications for the deductive proof assistant kiv from the syntax and operational semantics of a programming language specified in the k semantic framework. we adapt and implement the generic one-path reachability calculus and provide instant tool support for deductive proofs. through a sophisticated automation approach, we drastically reduce the manual proof steps.",k and kiv: towards deductive verification for arbitrary programming languages
364,2-s2.0-85104477768,10.1007/978-3-030-68198-2_59,Work in Progress: Web-Delivered Reading Improvement Battery of Tasks,Striftou A.,Advances in Intelligent Systems and Computing,2021-01-01,"Learning to read requires the development of highly organized brain systems that are capable of incorporating spelling, phonological and lexical-semantic features of written words. The main aim of the present research protocol is to strengthen the speed and accuracy of phonological awareness for children with reading impairments by designing and implementing a web delivered set of tasks. “Poke the Reading Ability” is a web-delivered application, that helps readers increase their reading speed, accuracy and comprehension by training them to avoid subvocalization (saying words in their head while reading), backtracking (going back to re-read words or sentences), and fixations, factors that have negative effects on reading speed and accuracy. “Poke the Reading Ability” includes a graphical environment that encourages learners to complete activities, while “playing an internet game”. HTML5, CSS, JavaScript were used in order to design all tasks included in “Poke the Reading Ability” web application. There are software applications that are used as intervention programs. However, “Poke the Reading Ability” is an online program designed in order to improve the reading capacity of children and adolescents. Its tasks are not only targeting at building phonological awareness but also, include tasks that improve visual and auditory memory, visual discrimination ability and text comprehension. The web application that is presented is carefully designed both in its pedagogical and computer programming aspects in order to offer a solution to tutors at everyday school practice.",Reading accuracy | Reading intervention | Reading speed | Web application,0,643-654,Book Series,Conference Paper,4.0,"Striftou, Aikaterini;Zygouris, Nikolaos C.;Stamoulis, Georgios I.;Vavougios, Denis",57189029352;57189032128;7003773174;53264968000,University of Thessaly,Greece,"learning to read requires the development of highly organized brain systems that are capable of incorporating spelling, phonological and lexical-semantic features of written words. the main aim of the present research protocol is to strengthen the speed and accuracy of phonological awareness for children with reading impairments by designing and implementing a web delivered set of tasks. “poke the reading ability” is a web-delivered application, that helps readers increase their reading speed, accuracy and comprehension by training them to avoid subvocalization (saying words in their head while reading), backtracking (going back to re-read words or sentences), and fixations, factors that have negative effects on reading speed and accuracy. “poke the reading ability” includes a graphical environment that encourages learners to complete activities, while “playing an internet game”. html5, css, javascript were used in order to design all tasks included in “poke the reading ability” web application. there are software applications that are used as intervention programs. however, “poke the reading ability” is an online program designed in order to improve the reading capacity of children and adolescents. its tasks are not only targeting at building phonological awareness but also, include tasks that improve visual and auditory memory, visual discrimination ability and text comprehension. the web application that is presented is carefully designed both in its pedagogical and computer programming aspects in order to offer a solution to tutors at everyday school practice.",work in progress: web-delivered reading improvement battery of tasks
368,2-s2.0-85103258328,10.1007/978-3-030-70006-5_10,Improving Node-RED Flows Comprehension with a Set of Development Guidelines,Clerissi D.,Communications in Computer and Information Science,2021-01-01,"The recent technological advancements has pointed the interest of developers, researchers, and end-users towards the Internet of Things (IoT) domain, whose plethora of services naturally arises to improve the human life. As the IoT becomes more and more involved in our everyday activities, we are personally encouraged to experiment it in practice. Node-RED tool has emerged as a practical solution to develop IoT systems in a simple manner. The tool was inspired by the flow-based programming paradigm and is built on top of Node.js framework. Its simplicity relies on the visual interface providing built-in functionalities and large customization. Moreover, the Node-RED community is quite active and inclined to offer support and share solutions to integrate within existing systems, therefore it is expected that the produced Node-RED flows are easy to comprehend and re-use. However, to the best of our knowledge, no consolidated approaches or guidelines to develop comprehensible Node-RED flows currently exist. For this reason, in this paper we, first, propose a set of guidelines aimed at helping Node-RED developers in producing flows easy to comprehend and re-use. Then, we report on an experiment to evaluate the effect of such guidelines on Node-RED flows comprehension. Results show that the adoption of the guidelines has a significant positive effect on both the number of errors and the time required to comprehend Node-RED flows. Finally, we describe an analysis of the Top-100 most downloaded Node-RED flows to discuss about their compliance (or not) with the proposed guidelines.",Comprehension | Guidelines | IoT Web based systems | Node-RED | Visual development,0,232-260,Book Series,Conference Paper,3.0,"Clerissi, Diego;Leotta, Maurizio;Ricca, Filippo",55815716500;37104276100;24822686600,"Dipartimento di Informatica, Bioingegneria, Robotica e Ingegneria dei Sistemi;Università degli Studi di Milano-Bicocca",Italy;Italy,"the recent technological advancements has pointed the interest of developers, researchers, and end-users towards the internet of things (iot) domain, whose plethora of services naturally arises to improve the human life. as the iot becomes more and more involved in our everyday activities, we are personally encouraged to experiment it in practice. node-red tool has emerged as a practical solution to develop iot systems in a simple manner. the tool was inspired by the flow-based programming paradigm and is built on top of node.js framework. its simplicity relies on the visual interface providing built-in functionalities and large customization. moreover, the node-red community is quite active and inclined to offer support and share solutions to integrate within existing systems, therefore it is expected that the produced node-red flows are easy to comprehend and re-use. however, to the best of our knowledge, no consolidated approaches or guidelines to develop comprehensible node-red flows currently exist. for this reason, in this paper we, first, propose a set of guidelines aimed at helping node-red developers in producing flows easy to comprehend and re-use. then, we report on an experiment to evaluate the effect of such guidelines on node-red flows comprehension. results show that the adoption of the guidelines has a significant positive effect on both the number of errors and the time required to comprehend node-red flows. finally, we describe an analysis of the top-100 most downloaded node-red flows to discuss about their compliance (or not) with the proposed guidelines.",improving node-red flows comprehension with a set of development guidelines
369,2-s2.0-85103242373,10.2174/1389203722666210118160946,Free open source software for protein and peptide mass spectrometry- based science,Rusconi F.,Current Protein and Peptide Science,2021-01-01,"In the field of biology, and specifically in protein and peptide science, the power of mass spectrometry is that it is applicable to a vast spectrum of applications. Mass spectrometry can be applied to identify proteins and peptides in complex mixtures, to identify and locate post-translational modifications, to characterize the structure of proteins and peptides to the most detailed level or to detect protein-ligand non-covalent interactions. Thanks to the Free and Open Source Software (FOSS) movement, scientists have limitless opportunities to deepen their skills in software development to code software that solves mass spectrometric data analysis problems. After the conversion of raw data files into open standard format files, the entire spectrum of data analysis tasks can now be performed integrally on FOSS platforms, like GNU/Linux, and only with FOSS solutions. This review presents a brief history of mass spectrometry open file formats and goes on with the description of FOSS projects that are commonly used in protein and peptide mass spectrometry fields of endeavor: identification projects that involve mostly automated pipelines, like proteomics and peptidomics, and bio-structural characterization projects that most often involve manual scrutiny of the mass data. Projects of the last kind usually involve software that allows the user to delve into the mass data in an interactive graphics-oriented manner. Software projects are thus categorized on the basis of these criteria: software libraries for software developers vs desktop-based graphical user interface, software for the end-user and automated pipeline-based data processing vs interactive graphics-based mass data scrutiny.",Free software | Mass spectrometry | Open source | Peptides | Proteins | Structural biology,1,134-147,Journal,Article,1.0,"Rusconi, Filippo",55106814300,Universite Paris-Saclay,France,"in the field of biology, and specifically in protein and peptide science, the power of mass spectrometry is that it is applicable to a vast spectrum of applications. mass spectrometry can be applied to identify proteins and peptides in complex mixtures, to identify and locate post-translational modifications, to characterize the structure of proteins and peptides to the most detailed level or to detect protein-ligand non-covalent interactions. thanks to the free and open source software (foss) movement, scientists have limitless opportunities to deepen their skills in software development to code software that solves mass spectrometric data analysis problems. after the conversion of raw data files into open standard format files, the entire spectrum of data analysis tasks can now be performed integrally on foss platforms, like gnu/linux, and only with foss solutions. this review presents a brief history of mass spectrometry open file formats and goes on with the description of foss projects that are commonly used in protein and peptide mass spectrometry fields of endeavor: identification projects that involve mostly automated pipelines, like proteomics and peptidomics, and bio-structural characterization projects that most often involve manual scrutiny of the mass data. projects of the last kind usually involve software that allows the user to delve into the mass data in an interactive graphics-oriented manner. software projects are thus categorized on the basis of these criteria: software libraries for software developers vs desktop-based graphical user interface, software for the end-user and automated pipeline-based data processing vs interactive graphics-based mass data scrutiny.",free open source software for protein and peptide mass spectrometry- based science
370,2-s2.0-85102656693,10.1109/ACCESS.2021.3065123,Role of Device Identification and Manufacturer Usage Description in IoT Security: A Survey,Mazhar N.,IEEE Access,2021-01-01,"This paper presents an overview of device identification techniques and the Manufacturer Usage Description (MUD) standard used for the Internet of things to reduce the IoT attack surface. The ongoing diversity and the sheer increase in the number of connected IoT devices have crumpled security efforts. There is a need to reconsider and redesign the underlying concept of developing security systems to resolve IoT security challenges. In this backdrop, device profiling and identification have emerged as an exciting technique that helps to reduce IoT device attack surface. One of the known approaches for device identification is to fingerprint a device. There are many ways to fingerprint the device, mostly using device network flows or device local attributes. The device identification ensures the authenticity of the device attached to the network, like user authentication. Since IoT devices mostly work using machine-to-machine (M2M) communication, this requires identifying each device properly. But there is no unified approach for device identification for the ever-growing world of IoT devices and applications. One of the major steps forward in this direction is the development of the Manufacturer Usage Description (MUD) standard that defines the role of a device within the network. It limits the device to execute the primary task only, which will help to reduce the attack surface. Since the inception of MUD, many security frameworks use this standard for IoT security. However, there is a need to scrutinize the security frameworks based on the MUD, to find out the claimed effectiveness of the standard in IoT security. This paper initially identifies and classifies the potential vulnerabilities in IoT devices. Then, the study provides an overview of the research that focuses on device identification techniques and analyzes their role in IoT security. Finally, the research presents an overview of MUD technology, its implementation scenarios, the limitation of the latest MUD standard, and its applications in the industry. The prime aim of this work is to examine the MUD benefits in IoT security along with the weaknesses and challenges while implementing this standard along with future directions.",deep learning (DL) | device identification (DI) | Internet of Things (IoT) | machine learning (ML) | Manufacturer usage description (MUD) | software defined network (SDN),4,41757-41786,Journal,Article,4.0,"Mazhar, Noman;Salleh, Rosli;Zeeshan, Muhammad;Hameed, M. Muzaffar",57211199587;23393688000;57214970753;57693226600,School of Electrical Engineering and Computer Science;Universiti Malaya,Pakistan;Malaysia,"this paper presents an overview of device identification techniques and the manufacturer usage description (mud) standard used for the internet of things to reduce the iot attack surface. the ongoing diversity and the sheer increase in the number of connected iot devices have crumpled security efforts. there is a need to reconsider and redesign the underlying concept of developing security systems to resolve iot security challenges. in this backdrop, device profiling and identification have emerged as an exciting technique that helps to reduce iot device attack surface. one of the known approaches for device identification is to fingerprint a device. there are many ways to fingerprint the device, mostly using device network flows or device local attributes. the device identification ensures the authenticity of the device attached to the network, like user authentication. since iot devices mostly work using machine-to-machine (m2m) communication, this requires identifying each device properly. but there is no unified approach for device identification for the ever-growing world of iot devices and applications. one of the major steps forward in this direction is the development of the manufacturer usage description (mud) standard that defines the role of a device within the network. it limits the device to execute the primary task only, which will help to reduce the attack surface. since the inception of mud, many security frameworks use this standard for iot security. however, there is a need to scrutinize the security frameworks based on the mud, to find out the claimed effectiveness of the standard in iot security. this paper initially identifies and classifies the potential vulnerabilities in iot devices. then, the study provides an overview of the research that focuses on device identification techniques and analyzes their role in iot security. finally, the research presents an overview of mud technology, its implementation scenarios, the limitation of the latest mud standard, and its applications in the industry. the prime aim of this work is to examine the mud benefits in iot security along with the weaknesses and challenges while implementing this standard along with future directions.",role of device identification and manufacturer usage description in iot security: a survey
371,2-s2.0-85101793587,10.1007/978-981-33-6318-2_27,Research on Server Fault Diagnosis Based on Expert System,Zhou C.,Lecture Notes in Electrical Engineering,2021-01-01,"With the rapid development of network technology, computer resources, including server resources, have shown a trend of high concentration, multiple devices, and multiple types. As a result, various types of server failures occur frequently, not only for basic monitoring software monitoring services. It puts forward higher requirements and has higher strength in the timeliness and accuracy of sending alarm information. Therefore, it is necessary to converge and analyze the alarm information and give expert-level solutions to the fault information. This article first designed the monitoring and alarm module using the flask framework to enable it to receive alarm information uniformly, converge and merge the alarm information, and use the Vue framework to display the alarm information on the page. Then, use the Python PyCLIPS library based on CLIPS to build the inference engine of the server fault diagnosis expert system. Finally use the “production rules” expert system knowledge expression to complete the construction of the knowledge base.",CLIPS | Expert system | Flask | Server fault diagnosis | Vue,0,213-220,Book Series,Conference Paper,3.0,"Zhou, Chuanhong;Guo, Daohao;Zhang, Chong",14826226700;57222189816;57205211057,Shanghai University,China,"with the rapid development of network technology, computer resources, including server resources, have shown a trend of high concentration, multiple devices, and multiple types. as a result, various types of server failures occur frequently, not only for basic monitoring software monitoring services. it puts forward higher requirements and has higher strength in the timeliness and accuracy of sending alarm information. therefore, it is necessary to converge and analyze the alarm information and give expert-level solutions to the fault information. this article first designed the monitoring and alarm module using the flask framework to enable it to receive alarm information uniformly, converge and merge the alarm information, and use the vue framework to display the alarm information on the page. then, use the python pyclips library based on clips to build the inference engine of the server fault diagnosis expert system. finally use the “production rules” expert system knowledge expression to complete the construction of the knowledge base.",research on server fault diagnosis based on expert system
372,2-s2.0-85100864593,10.5334/dsj-2021-008,Kadi4mat: A research data infrastructure for materials science,Brandt N.,Data Science Journal,2021-01-01,"The concepts and current developments of a research data infrastructure for materials science are presented, extending and combining the features of an electronic lab notebook and a repository. The objective of this infrastructure is to incorporate the possibility of structured data storage and data exchange with documented and reproducible data analysis and visualization, which finally leads to the publication of the data. This way, researchers can be supported throughout the entire research process. The software is being developed as a web-based and desktop-based system, offering both a graphical user interface and a programmatic interface. The focus of the development is on the integration of technologies and systems based on both established as well as new concepts. Due to the heterogeneous nature of materials science data, the current features are kept mostly generic, and the structuring of the data is largely left to the users. As a result, an extension of the research data infrastructure to other disciplines is possible in the future. The source code of the project is publicly available under a permissive Apache 2.0 license.",Electronic lab notebook | Materials science | Open source | Repository | Research data management,12,1-14,Journal,Article,8.0,"Brandt, Nico;Griem, Lars;Herrmann, Christoph;Schoof, Ephraim;Tosato, Giovanna;Zhao, Yinghan;Zschumme, Philipp;Selzer, Michael",57219502886;57221981907;57219770733;56422042200;57221982210;57219503490;57221981540;24503304900,Helmholtz-Institut Ulm;Karlsruher Institut für Technologie;Hochschule Karlsruhe - Technik und Wirtschaft,Germany;Germany;Germany,"the concepts and current developments of a research data infrastructure for materials science are presented, extending and combining the features of an electronic lab notebook and a repository. the objective of this infrastructure is to incorporate the possibility of structured data storage and data exchange with documented and reproducible data analysis and visualization, which finally leads to the publication of the data. this way, researchers can be supported throughout the entire research process. the software is being developed as a web-based and desktop-based system, offering both a graphical user interface and a programmatic interface. the focus of the development is on the integration of technologies and systems based on both established as well as new concepts. due to the heterogeneous nature of materials science data, the current features are kept mostly generic, and the structuring of the data is largely left to the users. as a result, an extension of the research data infrastructure to other disciplines is possible in the future. the source code of the project is publicly available under a permissive apache 2.0 license.",kadi4mat: a research data infrastructure for materials science
376,2-s2.0-85098874940,10.13057/biodiv/d220127,Updating of makiling biodiversity information system (Makibis) and analysis of biodiversity data,Magcale-Macandog D.B.,Biodiversitas,2021-01-01,"Mt. Makiling is a Philippine biodiversity hotspot listed as one of the 170 conservation priority areas established by the Philippine government. With the vast amount of ecological and biological information about the flora and fauna of Mt. Makiling, the Makiling Biodiversity Information System (MakiBIS) was developed to serve as a repository for these data. MakiBIS may serve as a prototype in the development of a national BIS that will be useful in addressing the need to set a national baseline, measurable targets, and indicators to facilitate the assessment of biodiversity status and as a basis for decision-making.The MakiBIS project started in 2011 and was last updated in 2014. In 2019, a new version of the information system was updated to take advantage of current web technologies in software development. The new MakiBIS’ (MakiBIS 2.0) frontend was written using ReactJS, while its backend functions were coded using NodeJS, and the database tables were compressed and optimized for faster queries. MakiBIS 2.0 was published online and can be accessed at www.makibis.com.The MakiBIS 2.0 database was populated with biodiversity information from published botanical and faunal survey studies conducted in Mt. Makiling. Biodiversity information includes taxonomic classification, botanical description, habitat, mode of reproduction, economic use, endemism, and conservation status. The MakiBIS database was analyzed for patterns, trends, distribution, and potential threats that will be useful towards the conservation and management of these biodiversity resources.",Biodiversity information system | Conservation status | Endemic | MakiBIS | Mt. Makiling | Threats | Tropical rainforest,0,211-226,Journal,Article,16.0,"Magcale-Macandog, Damasa B.;Lapitan, Fermin Roberto G.;Laruya, Jeoffrey M.;Valerio, Jandrel Ian F.;Aguila, Janzen Christian D.;Mesina, Clouie Ann L.;Santos, Twinkle Marie F.;Cuevas, Andrea Nicole T.;Baylon, Kimberly D.;Silapan, Iana Mariene;Dimalibot, Ricajay;Edrial, Jennifer D.;Larida, Nethanel Jireh A.;Natuel, Fatima A.;Perez, Ma Grechelle Lyn D.;Quinones, Sarena Grace L.",56090927400;57221337614;57221329921;57221332861;57221330337;57221335572;57221336059;57221333313;57221330522;57221333438;57221328170;57197869988;57221326144;57221328482;57221327352;57194037504,University of the Philippines Los Banos,Philippines,"mt. makiling is a philippine biodiversity hotspot listed as one of the 170 conservation priority areas established by the philippine government. with the vast amount of ecological and biological information about the flora and fauna of mt. makiling, the makiling biodiversity information system (makibis) was developed to serve as a repository for these data. makibis may serve as a prototype in the development of a national bis that will be useful in addressing the need to set a national baseline, measurable targets, and indicators to facilitate the assessment of biodiversity status and as a basis for decision-making.the makibis project started in 2011 and was last updated in 2014. in 2019, a new version of the information system was updated to take advantage of current web technologies in software development. the new makibis’ (makibis 2.0) frontend was written using reactjs, while its backend functions were coded using nodejs, and the database tables were compressed and optimized for faster queries. makibis 2.0 was published online and can be accessed at www.makibis.com.the makibis 2.0 database was populated with biodiversity information from published botanical and faunal survey studies conducted in mt. makiling. biodiversity information includes taxonomic classification, botanical description, habitat, mode of reproduction, economic use, endemism, and conservation status. the makibis database was analyzed for patterns, trends, distribution, and potential threats that will be useful towards the conservation and management of these biodiversity resources.",updating of makiling biodiversity information system (makibis) and analysis of biodiversity data
377,2-s2.0-85098221071,10.1007/978-3-030-57548-9_19,A Development of a Mobile Application for Monitoring Siemens S7-1200 Controller Variables Through Firebase,Diaz A.,"Smart Innovation, Systems and Technologies",2021-01-01,"Production systems need to be monitored because failure to do so can cause a delay in production due to a lack of remote monitoring. There are solutions that provide this information, but they are limited, because they are owned and very expensive solutions. This paper proposes the development of a mobile application for the monitoring of S7-1200 programmable controller variables through Firebase. The goal is to use open-source-type tools to develop a real-time variable monitoring application of a programmable controller capable of hosting a Web server, and the sent data to the Firebase cloud, in order to avoid modifying the driver software and the data stored in memory. The implemented system of sending, handling and presenting variables is developed with tools of open source type, since they have as an advantage to have greater freedom in programming, unlike proprietary solutions or services. The tests were performed on the Siemens S7-1200 controller with a plastic injection molding machine.",Programmable controller | Raspberry Pi | Web server | Windows 10 IoT,0,205-213,Book Series,Conference Paper,4.0,"Diaz, Alexander;Rivera, Steven;Vinces, Leonardo;Del Carpio, Christian",57224218332;57221107153;57204942922;57188764050,Universidad Peruana de Ciencias Aplicadas,Peru,"production systems need to be monitored because failure to do so can cause a delay in production due to a lack of remote monitoring. there are solutions that provide this information, but they are limited, because they are owned and very expensive solutions. this paper proposes the development of a mobile application for the monitoring of s7-1200 programmable controller variables through firebase. the goal is to use open-source-type tools to develop a real-time variable monitoring application of a programmable controller capable of hosting a web server, and the sent data to the firebase cloud, in order to avoid modifying the driver software and the data stored in memory. the implemented system of sending, handling and presenting variables is developed with tools of open source type, since they have as an advantage to have greater freedom in programming, unlike proprietary solutions or services. the tests were performed on the siemens s7-1200 controller with a plastic injection molding machine.",a development of a mobile application for monitoring siemens s7-1200 controller variables through firebase
381,2-s2.0-85087019484,10.1007/978-3-030-50454-0_18,Intelligentbox based training system for operation of radiation therapy devices,Okada Y.,Advances in Intelligent Systems and Computing,2021-01-01,"This paper treats IntelligentBox: a constructive visual software development system for 3D graphics applications and the authors propose the usefulness of IntelligentBox by showing one of the practical 3D graphics applications, i.e., a web-based collaborative VR training system for the operation of radiation therapy devices. Medical students have to train the operation of medical therapy devices as a therapist if they want to be so. However, radiation therapy devices are very expensive and dangerous, so any training systems are needed. The research group of the authors have already proposed a web-based collaborative VR training system for the operation of radiation therapy devices and also introduced IntelligentBox. This time, the authors tried to develop a training system that has the same functionality as the already developed system using IntelligentBox to show how easily it can be developed for justifying the usefulness of IntelligentBox.",3D graphics applications | IntelligentBox | Operation training | Radiation therapy devices | Virtual reality,2,188-198,Book Series,Conference Paper,3.0,"Okada, Yoshihiro;Kaneko, Kosuke;Fujibuchi, Toshioh",7404465193;16024449600;26428166700,"Kyushu University;Kyushu University, Faculty of Medical Sciences",Japan;Japan,"this paper treats intelligentbox: a constructive visual software development system for 3d graphics applications and the authors propose the usefulness of intelligentbox by showing one of the practical 3d graphics applications, i.e., a web-based collaborative vr training system for the operation of radiation therapy devices. medical students have to train the operation of medical therapy devices as a therapist if they want to be so. however, radiation therapy devices are very expensive and dangerous, so any training systems are needed. the research group of the authors have already proposed a web-based collaborative vr training system for the operation of radiation therapy devices and also introduced intelligentbox. this time, the authors tried to develop a training system that has the same functionality as the already developed system using intelligentbox to show how easily it can be developed for justifying the usefulness of intelligentbox.",intelligentbox based training system for operation of radiation therapy devices
382,2-s2.0-85077285397,10.1109/ACCESS.2019.2961918,Iotverif: Automatic Verification of SSL/TLS Certificate for IoT Applications,Liu A.,IEEE Access,2021-01-01,"Although extensive research has been conducted on securing the Internet of Things (IoT) communication protocols, various vulnerabilities and exploits are continuously discovered and reported. Since vulnerabilities are introduced from either insecure communication protocols or defectiveness of applications, it is difficult to identify them during the software development or testing phase. In this paper, we present IoTVerif, a system that automatically verifies the Secure Socket Layer/Transport Layer Security (SSL/TLS) certificate for IoT applications that utilize broker-based messaging protocols. IoTVerif constructs the specification of an IoT protocol and verifies its security properties, without relying on prior knowledge about communication protocols. Once the specification is constructed, a general-purpose model checker automatically verifies those properties, as well as generates counter-examples if any property does not hold. We analyze the effectiveness of IoTVerif with real-world IoT-related applications. Our evaluation results show that IoTVerif can successfully identify vulnerabilities from IoT applications, which are exploitable by the man-in-the-middle (MITM) and TLS renegotiation attacks. IoTVerif holds a great promise for reverse-engineering emerging IoT messaging protocols and identifies the vulnerabilities from IoT-related applications.",Certificate | Internet of Things (IoT) | model checking | protocol verification | secure socket layer (SSL) | transport layer security (TLS),2,27038-27050,Journal,Article,4.0,"Liu, Anyi;Alqazzaz, Ali;Ming, Hua;Dharmalingam, Balakrishnan",12763642400;57194162881;25929406700;57212646627,University of Bisha;Oakland University,Saudi Arabia;United States,"although extensive research has been conducted on securing the internet of things (iot) communication protocols, various vulnerabilities and exploits are continuously discovered and reported. since vulnerabilities are introduced from either insecure communication protocols or defectiveness of applications, it is difficult to identify them during the software development or testing phase. in this paper, we present iotverif, a system that automatically verifies the secure socket layer/transport layer security (ssl/tls) certificate for iot applications that utilize broker-based messaging protocols. iotverif constructs the specification of an iot protocol and verifies its security properties, without relying on prior knowledge about communication protocols. once the specification is constructed, a general-purpose model checker automatically verifies those properties, as well as generates counter-examples if any property does not hold. we analyze the effectiveness of iotverif with real-world iot-related applications. our evaluation results show that iotverif can successfully identify vulnerabilities from iot applications, which are exploitable by the man-in-the-middle (mitm) and tls renegotiation attacks. iotverif holds a great promise for reverse-engineering emerging iot messaging protocols and identifies the vulnerabilities from iot-related applications.",iotverif: automatic verification of ssl/tls certificate for iot applications
386,2-s2.0-85106889496,10.1109/ICMCCE51767.2020.00200,Design of web table system,MinChuan H.,"Proceedings - 2020 5th International Conference on Mechanical, Control and Computer Engineering, ICMCCE 2020",2020-12-01,"In order to avoid the spread of new coronavirus, it is necessary to keep a distance, wear masks and wash hands, not close contact. When the academic research or market survey needs to fill in the questionnaire, it is a safe and necessary choice to use the network electronic form. In order to prevent the spread of virus, it is necessary to keep a safe distance between people. The demand for electronic forms is more diverse and vigorous. To prevent the spread of virus through interviews and questionnaires, we can change the way of filling in electronic forms to achieve the purpose of maintaining a safe distance. As a result, the demand for electronic forms has increased, and the electronic forms can be more convenient. At the same time, the anti-counterfeiting function of electronic signature is used. The undeniable characteristics of personal signature can be customized and diversified. At present, the system development and technology of web forms are various and mature. In order to increase the employability of college students, the implementation course of online spreadsheet is added to the professional courses of University, which has gradually become a popular option of software engineering for students' graduation design. From the system analysis and system design, JavaScript, HTML5, CSS3 and other technologies are selected. Through the programming framework on the server, through the browser, it is convenient to use the web spreadsheet. The system functions are successfully implemented, and the graduation design of university professional courses is completed, which is a reference for successful cases of course practice. This model is a successful example of system development. Combined with the theory of university courses and the practice of project design, the system development, design and system testing are completed successfully within the effective time limit.",CSS3 | HTML5 | Javascript | Online spreadsheet system | Software engineering,0,910-915,Conference Proceeding,Conference Paper,4.0,"MinChuan, Huang;Huang, Hsiang Lin;Chen, Iping;Wang, Ai Guo",57224096765;57222335313;57222343376;57222344018,Guangdong University of Petrochemical Technology;Ming Chuan University;Central Taiwan University of Science and Technology,China;Taiwan;Taiwan,"in order to avoid the spread of new coronavirus, it is necessary to keep a distance, wear masks and wash hands, not close contact. when the academic research or market survey needs to fill in the questionnaire, it is a safe and necessary choice to use the network electronic form. in order to prevent the spread of virus, it is necessary to keep a safe distance between people. the demand for electronic forms is more diverse and vigorous. to prevent the spread of virus through interviews and questionnaires, we can change the way of filling in electronic forms to achieve the purpose of maintaining a safe distance. as a result, the demand for electronic forms has increased, and the electronic forms can be more convenient. at the same time, the anti-counterfeiting function of electronic signature is used. the undeniable characteristics of personal signature can be customized and diversified. at present, the system development and technology of web forms are various and mature. in order to increase the employability of college students, the implementation course of online spreadsheet is added to the professional courses of university, which has gradually become a popular option of software engineering for students' graduation design. from the system analysis and system design, javascript, html5, css3 and other technologies are selected. through the programming framework on the server, through the browser, it is convenient to use the web spreadsheet. the system functions are successfully implemented, and the graduation design of university professional courses is completed, which is a reference for successful cases of course practice. this model is a successful example of system development. combined with the theory of university courses and the practice of project design, the system development, design and system testing are completed successfully within the effective time limit.",design of web table system
388,2-s2.0-85098523722,10.1142/S0218488520400115,JGraphs: A Toolset to Work with Monte-Carlo Tree Search-Based Algorithms,García-Díaz V.,"International Journal of Uncertainty, Fuzziness and Knowlege-Based Systems",2020-12-01,"Monte-Carlo methods are the basis for solving many computational problems using repeated random sampling in scenarios that may have a deterministic but very complex solution from a computational point of view. In recent years, researchers are using the same idea to solve many problems through the so-called Monte-Carlo Tree Search family of algorithms, which provide the possibility of storing and reusing previously calculated results to improve precision in the calculation of future outcomes. However, developers and researchers working in this area tend to have to carry out software developments from scratch to use their designs or improve designs previously created by other researchers. This makes it difficult to see improvements in current algorithms as it takes a lot of hard work. This work presents JGraphs, a toolset implemented in the Java programming language that will allow researchers to avoid having to reinvent the wheel when working with Monte-Carlo Tree Search. In addition, it will allow testing experiments carried out by others in a simple way, reusing previous knowledge.",best-first search algorithm | combinatorial game | JGraphs | Monte-Carlo | Monte-Carlo Tree Search | Tic-Tac-Toe,1,1-22,Journal,Article,5.0,"García-Díaz, Vicente;Núñez-Valdez, Edward Rolando;García, Cristian González;Gómez-Gómez, Alberto;Crespo, Rubén González",26421130900;55199730800;56102629300;57191379067;57221209077,International University of La Rioja;Universidad de Oviedo;Marconi International University / UNIR LLC,Spain;Spain;United States,"monte-carlo methods are the basis for solving many computational problems using repeated random sampling in scenarios that may have a deterministic but very complex solution from a computational point of view. in recent years, researchers are using the same idea to solve many problems through the so-called monte-carlo tree search family of algorithms, which provide the possibility of storing and reusing previously calculated results to improve precision in the calculation of future outcomes. however, developers and researchers working in this area tend to have to carry out software developments from scratch to use their designs or improve designs previously created by other researchers. this makes it difficult to see improvements in current algorithms as it takes a lot of hard work. this work presents jgraphs, a toolset implemented in the java programming language that will allow researchers to avoid having to reinvent the wheel when working with monte-carlo tree search. in addition, it will allow testing experiments carried out by others in a simple way, reusing previous knowledge.",jgraphs: a toolset to work with monte-carlo tree search-based algorithms
390,2-s2.0-85091773883,10.1007/s41324-020-00321-1,Development of open source Web-GIS platform for three-dimensional geologic modeling and visualization,Nemoto T.,Spatial Information Research,2020-12-01,"An Open Source Web-GIS platform for Geologic Voxel (Geo-Vox) modeling and visualization, has been developed. Geo-Vox provides a comprehensive framework by integrating GIS, relational database, open geospatial standards-compliant web mapping engine, 2-D and 3-D rendering libraries for geologic modeling. Free and Open Source Software for Geoinformatics (FOSS4G) stack comprising of GRASS GIS, PostgreSQL, MapServer, OpenLayers and three.js JavaScript 3-D library have been used to implement the system. Geo-Vox overcomes several limitations of solid modeling by construction of model based on an intuitive logical relation between geologic units and boundary surfaces. Two-dimensional visualization allows rendering of horizontal and vertical sections at user-defined planes. The voxel model can also be exported in a format amenable for rendering as 3-D solid model. Geo-Vox is unique, in that, (a) logics used to create the model are easily comprehensible to geologist (b) offers high degree of interoperability (c) leverages FOSS4G stack to implement a comprehensive geologic modeling tool that is hitherto unavailable. The functionality of Geo-Vox is demonstrated using data derived from published geologic map. The results confirm the potential of Geo-Vox to provide an interoperable and scalable framework for delivery of value-added geological information for a variety technical and societal needs.",FOSS4G | Geo-Vox | Geologic structure | Logical model | Open Standards | Voxel,2,645-653,Journal,Article,5.0,"Nemoto, Tatsuya;Masumoto, Shinji;Raghavan, Venkatesh;Nonogaki, Susumu;Nakada, Fumio",7202558067;7003464454;7103398103;55229241800;55346573900,Osaka Metropolitan University;National Institute of Advanced Industrial Science and Technology;Geological Information Utilization and Promotion Initiative,Japan;Japan;Japan,"an open source web-gis platform for geologic voxel (geo-vox) modeling and visualization, has been developed. geo-vox provides a comprehensive framework by integrating gis, relational database, open geospatial standards-compliant web mapping engine, 2-d and 3-d rendering libraries for geologic modeling. free and open source software for geoinformatics (foss4g) stack comprising of grass gis, postgresql, mapserver, openlayers and three.js javascript 3-d library have been used to implement the system. geo-vox overcomes several limitations of solid modeling by construction of model based on an intuitive logical relation between geologic units and boundary surfaces. two-dimensional visualization allows rendering of horizontal and vertical sections at user-defined planes. the voxel model can also be exported in a format amenable for rendering as 3-d solid model. geo-vox is unique, in that, (a) logics used to create the model are easily comprehensible to geologist (b) offers high degree of interoperability (c) leverages foss4g stack to implement a comprehensive geologic modeling tool that is hitherto unavailable. the functionality of geo-vox is demonstrated using data derived from published geologic map. the results confirm the potential of geo-vox to provide an interoperable and scalable framework for delivery of value-added geological information for a variety technical and societal needs.",development of open source web-gis platform for three-dimensional geologic modeling and visualization
395,2-s2.0-85097796731,10.1145/3427763.3428313,Debugging of RxJS-based applications,Alabor M.,"REBLS 2020 - Proceedings of the 7th ACM SIGPLAN International Workshop on Reactive and Event-Based Languages and Systems, Co-located with SPLASH 2020",2020-11-16,"RxJS is a popular library to implement data-flow-oriented applications with JavaScript using reactive programming principles. This way of programming bears new challenges for traditional debuggers: Their focus on imperative programming limits their applicability to problems originated in the declarative programming paradigm. The goals of this paper are: (i) to understand how software engineers debug RxJS-based applications, what tools do they use, what techniques they apply; (ii) to understand what are the most prevalent challenges they face while doing so; and (iii) to provide a course of action to resolve these challenges in a future iteration on the topic. We learned about the debugging habits of ten professionals using interviews, and hands-on war story reports. Based on this data, we designed and executed an observational study with four subjects to verify that engineers predominantly augment source code with manual trace logs instead of using specialized debugging utilities. In the end, we identified the lack of fully integrated RxJS-specific debugging solutions in existing development environments as the most significant reason why engineers do not make use of such tools. We decided to elaborate on how to resolve this situation in our future work.",debugging | empirical software engineering | reactive programming,4,15-24,Conference Proceeding,Conference Paper,2.0,"Alabor, Manuel;Stolze, Markus",57220872105;57212999104,Eastern Switzerland University of Applied Sciences,Switzerland,"rxjs is a popular library to implement data-flow-oriented applications with javascript using reactive programming principles. this way of programming bears new challenges for traditional debuggers: their focus on imperative programming limits their applicability to problems originated in the declarative programming paradigm. the goals of this paper are: (i) to understand how software engineers debug rxjs-based applications, what tools do they use, what techniques they apply; (ii) to understand what are the most prevalent challenges they face while doing so; and (iii) to provide a course of action to resolve these challenges in a future iteration on the topic. we learned about the debugging habits of ten professionals using interviews, and hands-on war story reports. based on this data, we designed and executed an observational study with four subjects to verify that engineers predominantly augment source code with manual trace logs instead of using specialized debugging utilities. in the end, we identified the lack of fully integrated rxjs-specific debugging solutions in existing development environments as the most significant reason why engineers do not make use of such tools. we decided to elaborate on how to resolve this situation in our future work.",debugging of rxjs-based applications
396,2-s2.0-85097708782,10.1145/3426425.3426933,Software Language Engineers' Worst Nightmare,Zaytsev V.,"SLE 2020 - Proceedings of the 13th ACM SIGPLAN International Conference on Software Language Engineering, Co-located with SPLASH 2020",2020-11-16,"Many techniques in software language engineering get their first validation by being prototyped to work on one particular language such as Java, Scala, Scheme, or ML, or a subset of such a language. Claims of their generalisability, as well as discussion on potential threats to their external validity, are often based on authors' ad hoc understanding of the world outside their usual comfort zone. To facilitate and simplify such discussions by providing a solid measurable ground, we propose a language called BabyCobol, which was specifically designed to contain features that turn processing legacy programming languages such as COBOL, FORTRAN, PL/I, REXX, CLIST, and 4GLs (fourth generation languages), into such a challenge. The language is minimal by design so that it can help to quickly find weaknesses in frameworks making them inapplicable to dealing with legacy software. However, applying new techniques of software language engineering and reverse engineering to such a small language will not be too tedious and overwhelming. BabyCobol was designed in collaboration with industrial compiler developers by systematically traversing features of several second, third and fourth generation languages to identify the core culprits in making development of compiler for legacy languages difficult.",domain-specific languages | language engineering | legacy software | software migration | teaching SLE,0,72-85,Conference Proceeding,Conference Paper,1.0,"Zaytsev, Vadim",27468166800,Universiteit Twente,Netherlands,"many techniques in software language engineering get their first validation by being prototyped to work on one particular language such as java, scala, scheme, or ml, or a subset of such a language. claims of their generalisability, as well as discussion on potential threats to their external validity, are often based on authors' ad hoc understanding of the world outside their usual comfort zone. to facilitate and simplify such discussions by providing a solid measurable ground, we propose a language called babycobol, which was specifically designed to contain features that turn processing legacy programming languages such as cobol, fortran, pl/i, rexx, clist, and 4gls (fourth generation languages), into such a challenge. the language is minimal by design so that it can help to quickly find weaknesses in frameworks making them inapplicable to dealing with legacy software. however, applying new techniques of software language engineering and reverse engineering to such a small language will not be too tedious and overwhelming. babycobol was designed in collaboration with industrial compiler developers by systematically traversing features of several second, third and fourth generation languages to identify the core culprits in making development of compiler for legacy languages difficult.",software language engineers' worst nightmare
397,2-s2.0-85100884928,10.1109/ICCSS52145.2020.9336857,A new lightweight online database for corrosion rate analysis of fluorochemical engineering processes,Wei X.,"2020 7th International Conference on Information, Cybernetics, and Computational Social Systems, ICCSS 2020",2020-11-13,"Corrosion is one of the major reasons destroying the reliability of equipment or systems in the fluorochemical engineering processes. A new lightweight database was developed for the specific requirements of the corrosion mechanism analysis for fluorochemical engineering processes. This paper takes Vue.js as the front-end framework, ElementUI as the component library, the back-end based on Python language, selects Flask as the back-end framework, MySQL as the database foundation, supplemented by various derivatives of Vue.js and Flask, to create a single-page, multi-functional front and back-end separate web application, which is specially used for the storage and utilization of hydrofluoric acid corrosion material performance data. The use of Vue.js and Flask makes the database lightweight and easy to use. The unified development, separate operation and logical decoupling design of the front and back-end makes the data storage more secure, the software runs more reliable, and the modular functional design makes the software more scalable. According to the characteristics of hydrofluoric acid corrosion materials and the specific process of hydrofluoric acid corrosion research, four functions were designed as: database management, material comparison, material selection and background management. It has powerful performance and safety design, which provides convenience for researchers to study hydrofluoric acid corrosion materials. Therefore, it fills in the gaps between priceless corrosion data and the delivery of integrated knowledge to end-users, thus helping unleash the value of the current data resources.",Corrosion | fluorochemical engineering processes | front-end and back-end separation | Lightweight database,0,332-337,Conference Proceeding,Conference Paper,6.0,"Wei, Xiaoran;Guo, Can;Zhu, Junxuan;Tong, Yifan;Shi, Shouwen;Song, Kai",57221993761;57213194931;57221995783;57210706636;55210410100;54912535800,Tianjin University,China,"corrosion is one of the major reasons destroying the reliability of equipment or systems in the fluorochemical engineering processes. a new lightweight database was developed for the specific requirements of the corrosion mechanism analysis for fluorochemical engineering processes. this paper takes vue.js as the front-end framework, elementui as the component library, the back-end based on python language, selects flask as the back-end framework, mysql as the database foundation, supplemented by various derivatives of vue.js and flask, to create a single-page, multi-functional front and back-end separate web application, which is specially used for the storage and utilization of hydrofluoric acid corrosion material performance data. the use of vue.js and flask makes the database lightweight and easy to use. the unified development, separate operation and logical decoupling design of the front and back-end makes the data storage more secure, the software runs more reliable, and the modular functional design makes the software more scalable. according to the characteristics of hydrofluoric acid corrosion materials and the specific process of hydrofluoric acid corrosion research, four functions were designed as: database management, material comparison, material selection and background management. it has powerful performance and safety design, which provides convenience for researchers to study hydrofluoric acid corrosion materials. therefore, it fills in the gaps between priceless corrosion data and the delivery of integrated knowledge to end-users, thus helping unleash the value of the current data resources.",a new lightweight online database for corrosion rate analysis of fluorochemical engineering processes
399,2-s2.0-85099208681,10.1145/3436829.3436848,MuHyb: A Proposed Mutation Testing Tool for Hybrid Mobile Applications,Ahmed S.,ACM International Conference Proceeding Series,2020-11-11,"Mobile App development is growing so fast. The variety of mobile operating systems encourages developers to find practical ways to write the same application once for different platforms. Hybrid applications; which are built using web technologies, are built inside a native container to run in different platforms. The lack of testing of these hybrid applications leads to poor quality applications. Mutation testing is a testing technique that generates many copies from the application with an injected fault in each, and then it runs the copies against the test suite to adequate the test suite effectiveness. In this paper, we propose MuHyb, an open source mutation testing tool, which supports hybrid mobile frameworks that based on Angular under Node.js using ng test command within 29 mutation operators. The tool is applied in a hybrid mobile application (PizzaHouse) built with Ionic Framework. Stryker mutation testing tool that supports TypeScript and Angular applications had been also applied on the same application (PizzaHouse) and the results of both tools are presented. The results show that MuHyb can effectively test hybrid mobile applications before building it for IOS and Android, as well as indicating several directions for enhancement.",Hybrid Mobile Testing | Mutation Testing | Software Testing,1,67-72,Conference Proceeding,Conference Paper,3.0,"Ahmed, Shazly;Taj-Eddin, Islam A.T.F.;Ismail, Manal A.",57221247634;56114349700;57212602270,The Egyptian E-Learning University;Helwan University;Assiut University,Egypt;Egypt;Egypt,"mobile app development is growing so fast. the variety of mobile operating systems encourages developers to find practical ways to write the same application once for different platforms. hybrid applications; which are built using web technologies, are built inside a native container to run in different platforms. the lack of testing of these hybrid applications leads to poor quality applications. mutation testing is a testing technique that generates many copies from the application with an injected fault in each, and then it runs the copies against the test suite to adequate the test suite effectiveness. in this paper, we propose muhyb, an open source mutation testing tool, which supports hybrid mobile frameworks that based on angular under node.js using ng test command within 29 mutation operators. the tool is applied in a hybrid mobile application (pizzahouse) built with ionic framework. stryker mutation testing tool that supports typescript and angular applications had been also applied on the same application (pizzahouse) and the results of both tools are presented. the results show that muhyb can effectively test hybrid mobile applications before building it for ios and android, as well as indicating several directions for enhancement.",muhyb: a proposed mutation testing tool for hybrid mobile applications
401,2-s2.0-85097720120,10.1145/3426428.3426922,Putting the semantics into semantic versioning,Lam P.,"Onward! 2020 - Proceedings of the 2020 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software, Co-located with SPLASH 2020",2020-11-08,"The long-standing aspiration for software reuse has made astonishing strides in the past few years. Many modern software development ecosystems now come with rich sets of publicly-available components contributed by the community. Downstream developers can leverage these upstream components, boosting their productivity. However, components evolve at their own pace. This imposes obligations on and yields benefits for downstream developers, especially since changes can be breaking, requiring additional downstream work to adapt to. Upgrading too late leaves downstream vulnerable to security issues and missing out on useful improvements; upgrading too early results in excess work. Semantic versioning has been proposed as an elegant mechanism to communicate levels of compatibility, enabling downstream developers to automate dependency upgrades. While it is questionable whether a version number can adequately characterize version compatibility in general, we argue that developers would greatly benefit from tools such as semantic version calculators to help them upgrade safely. The time is now for the research community to develop such tools: large component ecosystems exist and are accessible, component interactions have become observable through automated builds, and recent advances in program analysis make the development of relevant tools feasible. In particular, contracts (both traditional and lightweight) are a promising input to semantic versioning calculators, which can suggest whether an upgrade is likely to be safe.",code contracts | program analysis | program evolution | semantic versioning | verification,3,157-179,Conference Proceeding,Conference Paper,3.0,"Lam, Patrick;Dietrich, Jens;Pearce, David J.",8539675700;13411598100;35303341300,University of Waterloo;Victoria University of Wellington,Canada;New Zealand,"the long-standing aspiration for software reuse has made astonishing strides in the past few years. many modern software development ecosystems now come with rich sets of publicly-available components contributed by the community. downstream developers can leverage these upstream components, boosting their productivity. however, components evolve at their own pace. this imposes obligations on and yields benefits for downstream developers, especially since changes can be breaking, requiring additional downstream work to adapt to. upgrading too late leaves downstream vulnerable to security issues and missing out on useful improvements; upgrading too early results in excess work. semantic versioning has been proposed as an elegant mechanism to communicate levels of compatibility, enabling downstream developers to automate dependency upgrades. while it is questionable whether a version number can adequately characterize version compatibility in general, we argue that developers would greatly benefit from tools such as semantic version calculators to help them upgrade safely. the time is now for the research community to develop such tools: large component ecosystems exist and are accessible, component interactions have become observable through automated builds, and recent advances in program analysis make the development of relevant tools feasible. in particular, contracts (both traditional and lightweight) are a promising input to semantic versioning calculators, which can suggest whether an upgrade is likely to be safe.",putting the semantics into semantic versioning
402,2-s2.0-85097203950,10.1145/3368089.3418539,Enhancing developers' support on pull requests activities with software bots,Wessel M.,ESEC/FSE 2020 - Proceedings of the 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,2020-11-08,"Software bots are employed to support developers' activities, serving as conduits between developers and other tools. Due to their focus on task automation, bots have become particularly relevant for Open Source Software (OSS) projects hosted on GitHub. While bots are adopted to save development cost, time, and effort, the bots' presence can be disruptive to the community. My research goal is two-fold: (i) identify problems caused by bots that interact in pull requests, and (ii) help bot designers enhance existing bots. Toward this end, we are interviewing maintainers, contributors, and bot developers to understand the problems in the human-bot interaction and how they affect the collaboration in a project. Afterward, we will employ Design Fiction to capture the developers' vision of bots' capabilities, in order to define guidelines for the design of bots on social coding platforms, and derive requirements for a meta-bot to deal with the problems. This work contributes more broadly to the design and use of software bots to enhance developers' collaboration and interaction.",GitHub Bots | Open-source Software | Software Bots,2,1674-1677,Conference Proceeding,Conference Paper,1.0,"Wessel, Mairieli",57204421132,Universidade de São Paulo,Brazil,"software bots are employed to support developers' activities, serving as conduits between developers and other tools. due to their focus on task automation, bots have become particularly relevant for open source software (oss) projects hosted on github. while bots are adopted to save development cost, time, and effort, the bots' presence can be disruptive to the community. my research goal is two-fold: (i) identify problems caused by bots that interact in pull requests, and (ii) help bot designers enhance existing bots. toward this end, we are interviewing maintainers, contributors, and bot developers to understand the problems in the human-bot interaction and how they affect the collaboration in a project. afterward, we will employ design fiction to capture the developers' vision of bots' capabilities, in order to define guidelines for the design of bots on social coding platforms, and derive requirements for a meta-bot to deal with the problems. this work contributes more broadly to the design and use of software bots to enhance developers' collaboration and interaction.",enhancing developers' support on pull requests activities with software bots
403,2-s2.0-85097192668,10.1145/3368089.3409733,DENAS: Automated rule generation by knowledge extraction from neural networks,Chen S.,ESEC/FSE 2020 - Proceedings of the 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,2020-11-08,"Deep neural networks (DNNs) have been widely applied in the software development process to automatically learn patterns from massive data. However, many applications still make decisions based on rules that are manually crafted and verified by domain experts due to safety or security concerns. In this paper, we aim to close the gap between DNNs and rule-based systems by automating the rule generation process via extracting knowledge from well-trained DNNs. Existing techniques with similar purposes either rely on specific DNNs input instances or use inherently unstable random sampling of the input space. Therefore, these approaches either limit the exploration area to a local decision-space of the DNNs or fail to converge to a consistent set of rules. The resulting rules thus lack representativeness and stability. In this paper, we address the two aforementioned shortcomings by discovering a global property of the DNNs and use it to remodel the DNNs decision-boundary. We name this property as the activation probability, and show that this property is stable. With this insight, we propose an approach named DENAS including a novel rule-generation algorithm. Our proposed algorithm approximates the non-linear decision boundary of DNNs by iteratively superimposing a linearized optimization function. We evaluate the representativeness, stability, and accuracy of DENAS against five state-of-the-art techniques (LEMNA, Gradient, IG, DeepTaylor, and DTExtract) on three software engineering and security applications: Binary analysis, PDF malware detection, and Android malware detection. Our results show that DENAS can generate more representative rules consistently in a more stable manner over other approaches. We further offer case studies that demonstrate the applications of DENAS such as debugging faults in the DNNs and generating signatures that can detect zero-day malware.",Deep Neural Networks | Explainable AI | Machine Learning,2,813-825,Conference Proceeding,Conference Paper,6.0,"Chen, Simin;Bateni, Soroush;Grandhi, Sampath;Li, Xiaodi;Liu, Cong;Yang, Wei",57843065900;57204499812;57220190601;57214670612;56043633600;55607069500,UT Dallas,United States,"deep neural networks (dnns) have been widely applied in the software development process to automatically learn patterns from massive data. however, many applications still make decisions based on rules that are manually crafted and verified by domain experts due to safety or security concerns. in this paper, we aim to close the gap between dnns and rule-based systems by automating the rule generation process via extracting knowledge from well-trained dnns. existing techniques with similar purposes either rely on specific dnns input instances or use inherently unstable random sampling of the input space. therefore, these approaches either limit the exploration area to a local decision-space of the dnns or fail to converge to a consistent set of rules. the resulting rules thus lack representativeness and stability. in this paper, we address the two aforementioned shortcomings by discovering a global property of the dnns and use it to remodel the dnns decision-boundary. we name this property as the activation probability, and show that this property is stable. with this insight, we propose an approach named denas including a novel rule-generation algorithm. our proposed algorithm approximates the non-linear decision boundary of dnns by iteratively superimposing a linearized optimization function. we evaluate the representativeness, stability, and accuracy of denas against five state-of-the-art techniques (lemna, gradient, ig, deeptaylor, and dtextract) on three software engineering and security applications: binary analysis, pdf malware detection, and android malware detection. our results show that denas can generate more representative rules consistently in a more stable manner over other approaches. we further offer case studies that demonstrate the applications of denas such as debugging faults in the dnns and generating signatures that can detect zero-day malware.",denas: automated rule generation by knowledge extraction from neural networks
404,2-s2.0-85097152612,10.1145/3368089.3417924,SWAN: A static analysis framework for swift,Tiganov D.,ESEC/FSE 2020 - Proceedings of the 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,2020-11-08,"Swift is an open-source programming language and Apple's recommended choice for app development. Given the global widespread use of Apple devices, the ability to analyze Swift programs has significant impact on millions of users. Although static analysis frameworks exist for various computing platforms, there is a lack of comparable tools for Swift. While LLVM and Clang support some analyses for Swift, they are either primarily dynamic analyses or not suitable for deeper analyses of Swift programs such as taint tracking. Moreover, other existing tools for Swift only help enforce code styles and best practices. In this paper, we present SWAN, an open-source framework that allows robust program analyses of Swift programs using IBM's T.J. Watson Libraries for Analysis (WALA). To provide a wide range of analyses for Swift, SWAN leverages the well-established libraries in WALA. SWAN is publicly available at https://github.com/themaplelab/swan. We have also made a screencast available at https://youtu.be/AZwfhOGqwFs.",Static analysis | Swift | Taint analysis,4,1640-1644,Conference Proceeding,Conference Paper,4.0,"Tiganov, Daniil;Cho, Jeff;Ali, Karim;Dolby, Julian",57220178098;57220187047;57197510133;8837002700,University of Alberta;IBM Research,Canada;United States,"swift is an open-source programming language and apple's recommended choice for app development. given the global widespread use of apple devices, the ability to analyze swift programs has significant impact on millions of users. although static analysis frameworks exist for various computing platforms, there is a lack of comparable tools for swift. while llvm and clang support some analyses for swift, they are either primarily dynamic analyses or not suitable for deeper analyses of swift programs such as taint tracking. moreover, other existing tools for swift only help enforce code styles and best practices. in this paper, we present swan, an open-source framework that allows robust program analyses of swift programs using ibm's t.j. watson libraries for analysis (wala). to provide a wide range of analyses for swift, swan leverages the well-established libraries in wala. swan is publicly available at https://github.com/themaplelab/swan. we have also made a screencast available at https://youtu.be/azwfhogqwfs.",swan: a static analysis framework for swift
405,2-s2.0-85097147673,10.1145/3368089.3417058,IntelliCode compose: Code generation using transformer,Svyatkovskiy A.,ESEC/FSE 2020 - Proceedings of the 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,2020-11-08,"In software development through integrated development environments (IDEs), code completion is one of the most widely used features. Nevertheless, majority of integrated development environments only support completion of methods and APIs, or arguments. In this paper, we introduce IntelliCode Compose - a general-purpose multilingual code completion tool which is capable of predicting sequences of code tokens of arbitrary types, generating up to entire lines of syntactically correct code. It leverages state-of-the-art generative transformer model trained on 1.2 billion lines of source code in Python, C#, JavaScript and TypeScript programming languages. IntelliCode Compose is deployed as a cloud-based web service. It makes use of client-side tree-based caching, efficient parallel implementation of the beam search decoder, and compute graph optimizations to meet edit-time completion suggestion requirements in the Visual Studio Code IDE and Azure Notebook. Our best model yields an average edit similarity of 86.7% and a perplexity of 1.82 for Python programming language.",Code completion | Naturalness of software | Neural networks,33,1433-1443,Conference Proceeding,Conference Paper,4.0,"Svyatkovskiy, Alexey;Deng, Shao Kun;Fu, Shengyu;Sundaresan, Neel",36640625700;57219765050;57210638187;7005588783,Microsoft Corporation,United States,"in software development through integrated development environments (ides), code completion is one of the most widely used features. nevertheless, majority of integrated development environments only support completion of methods and apis, or arguments. in this paper, we introduce intellicode compose - a general-purpose multilingual code completion tool which is capable of predicting sequences of code tokens of arbitrary types, generating up to entire lines of syntactically correct code. it leverages state-of-the-art generative transformer model trained on 1.2 billion lines of source code in python, c#, javascript and typescript programming languages. intellicode compose is deployed as a cloud-based web service. it makes use of client-side tree-based caching, efficient parallel implementation of the beam search decoder, and compute graph optimizations to meet edit-time completion suggestion requirements in the visual studio code ide and azure notebook. our best model yields an average edit similarity of 86.7% and a perplexity of 1.82 for python programming language.",intellicode compose: code generation using transformer
406,2-s2.0-85097147010,10.1145/3368089.3409711,Selecting third-party libraries: The practitioners' perspective,Larios Vargas E.,ESEC/FSE 2020 - Proceedings of the 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,2020-11-08,"The selection of third-party libraries is an essential element of virtually any software development project. However, deciding which libraries to choose is a challenging practical problem. Selecting the wrong library can severely impact a software project in terms of cost, time, and development effort, with the severity of the impact depending on the role of the library in the software architecture, among others. Despite the importance of following a careful library selection process, in practice, the selection of third-party libraries is still conducted in an ad-hoc manner, where dozens of factors play an influential role in the decision. In this paper, we study the factors that influence the selection process of libraries, as perceived by industry developers. To that aim, we perform a cross-sectional interview study with 16 developers from 11 different businesses and survey 115 developers that are involved in the selection of libraries. We systematically devised a comprehensive set of 26 technical, human, and economic factors that developers take into consideration when selecting a software library. Eight of these factors are new to the literature. We explain each of these factors and how they play a role in the decision. Finally, we discuss the implications of our work to library maintainers, potential library users, package manager developers, and empirical software engineering researchers.",APIs | Empirical software engineering | Library adoption | Library selection | Software libraries,13,245-256,Conference Proceeding,Conference Paper,5.0,"Larios Vargas, Enrique;Aniche, Maurício;Treude, Christoph;Bruntink, Magiel;Gousios, Georgios",57219810913;36132835800;23135531900;8381339200;14819567500,The University of Adelaide;Delft University of Technology;Software Improvement Group,Australia;Netherlands;Netherlands,"the selection of third-party libraries is an essential element of virtually any software development project. however, deciding which libraries to choose is a challenging practical problem. selecting the wrong library can severely impact a software project in terms of cost, time, and development effort, with the severity of the impact depending on the role of the library in the software architecture, among others. despite the importance of following a careful library selection process, in practice, the selection of third-party libraries is still conducted in an ad-hoc manner, where dozens of factors play an influential role in the decision. in this paper, we study the factors that influence the selection process of libraries, as perceived by industry developers. to that aim, we perform a cross-sectional interview study with 16 developers from 11 different businesses and survey 115 developers that are involved in the selection of libraries. we systematically devised a comprehensive set of 26 technical, human, and economic factors that developers take into consideration when selecting a software library. eight of these factors are new to the literature. we explain each of these factors and how they play a role in the decision. finally, we discuss the implications of our work to library maintainers, potential library users, package manager developers, and empirical software engineering researchers.",selecting third-party libraries: the practitioners' perspective
407,2-s2.0-85095508614,10.1145/3368089.3409688,Beware the evolving 'intelligent' web service! an integration architecture tactic to guard AI-first components,Cummaudo A.,ESEC/FSE 2020 - Proceedings of the 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,2020-11-08,"Intelligent services provide the power of AI to developers via simple RESTful API endpoints, abstracting away many complexities of machine learning. However, most of these intelligent services - -such as computer vision - -continually learn with time. When the internals within the abstracted 'black box' become hidden and evolve, pitfalls emerge in the robustness of applications that depend on these evolving services. Without adapting the way developers plan and construct projects reliant on intelligent services, significant gaps and risks result in both project planning and development. Therefore, how can software engineers best mitigate software evolution risk moving forward, thereby ensuring that their own applications maintain quality? Our proposal is an architectural tactic designed to improve intelligent service-dependent software robustness. The tactic involves creating an application-specific benchmark dataset baselined against an intelligent service, enabling evolutionary behaviour changes to be mitigated. A technical evaluation of our implementation of this architecture demonstrates how the tactic can identify 1,054 cases of substantial confidence evolution and 2,461 cases of substantial changes to response label sets using a dataset consisting of 331 images that evolve when sent to a service.",Intelligent web services | Software architecture | Software evolution,4,269-280,Conference Proceeding,Conference Paper,5.0,"Cummaudo, Alex;Barnett, Scott;Vasa, Rajesh;Grundy, John;Abdelrazek, Mohamed",57193564412;56890458900;14632834200;7102156137;56080446200,Monash University;Deakin University,Australia;Australia,"intelligent services provide the power of ai to developers via simple restful api endpoints, abstracting away many complexities of machine learning. however, most of these intelligent services - -such as computer vision - -continually learn with time. when the internals within the abstracted 'black box' become hidden and evolve, pitfalls emerge in the robustness of applications that depend on these evolving services. without adapting the way developers plan and construct projects reliant on intelligent services, significant gaps and risks result in both project planning and development. therefore, how can software engineers best mitigate software evolution risk moving forward, thereby ensuring that their own applications maintain quality? our proposal is an architectural tactic designed to improve intelligent service-dependent software robustness. the tactic involves creating an application-specific benchmark dataset baselined against an intelligent service, enabling evolutionary behaviour changes to be mitigated. a technical evaluation of our implementation of this architecture demonstrates how the tactic can identify 1,054 cases of substantial confidence evolution and 2,461 cases of substantial changes to response label sets using a dataset consisting of 331 images that evolve when sent to a service.",beware the evolving 'intelligent' web service! an integration architecture tactic to guard ai-first components
413,2-s2.0-85101626205,10.1049/cje.2020.10.006,Research and application of machine learning in automatic program generation,Zhang X.,Chinese Journal of Electronics,2020-11-01,"With the development of artificial intelligence, machine learning has been applied in more and more domains. In order to improve the quality and efficiency of software, automatic program generation is becoming a research hotspot. In recent years, machine learning has also been gradually applied in automatic program generation. Decision trees, language models, and cyclic neural networks have been applied in code generation, code completion and code knowledge mining. The efficiency of software development has been improved to a certain extent using machine learning. Aimed at the automatic program generation, this paper analyzes and summarizes the models of machine learning, the modifications involved in the models and the application effects. The research direction is discussed from the aspects of programmer behavior and automatic program generation of machine learning.",Application effect | Code completion | Code generation | Code knowledge mining | Machine learning,4,1001-1015,Journal,Article,2.0,"Zhang, Xiaojiang;Jiang, Ying",57215330940;55514958300,Kunming University of Science and Technology,China,"with the development of artificial intelligence, machine learning has been applied in more and more domains. in order to improve the quality and efficiency of software, automatic program generation is becoming a research hotspot. in recent years, machine learning has also been gradually applied in automatic program generation. decision trees, language models, and cyclic neural networks have been applied in code generation, code completion and code knowledge mining. the efficiency of software development has been improved to a certain extent using machine learning. aimed at the automatic program generation, this paper analyzes and summarizes the models of machine learning, the modifications involved in the models and the application effects. the research direction is discussed from the aspects of programmer behavior and automatic program generation of machine learning.",research and application of machine learning in automatic program generation
416,2-s2.0-85097215825,10.25165/j.ijabe.20201306.5759,Design and implementation of international agricultural and biological engineering expert management system based on web mode,Shen J.B.,International Journal of Agricultural and Biological Engineering,2020-11-01,"Agriculture and biological engineering are the foundation of agricultural modernization, and related countries have also issued relevant policies to guide the development of agriculture and biotechnology. Agricultural and biological engineering experts are the intellectual resources in the field. At present, there is less research on the management and maintenance of agricultural and biological engineering experts, and there is a lack of software systems in this area. In order to realize the management and maintenance of agricultural and biological engineering expert information, a service platform for the international agricultural and biological engineering expert system based on the B/S framework has been developed. The background of the system used C# as the development language, and the foreground used JavaScript technology and Bootstrap. The software adopted ASP.NET MVC as the web development framework and used the Entity Framework to operate the SQL Server background database. The system has the function of searching and querying agricultural and biological engineering expert information according to keywords, and implements the functions of adding, deleting, and modifying data records, and the function of generating spreadsheets and importing spreadsheet data. The development of this system provides effective management tools for the maintenance and construction of agricultural and biological engineering expert databases and lays a good foundation for the construction of agricultural and biological engineering think tanks.",Agricultural and bioengineering engineering | Asp.net MVC | Bootstrap | Conditional search | Entity framework technology | Expert management | Think tanks | WEB mode,3,195-200,Journal,Article,3.0,"Shen, Jian Bo;Tan, Li Wei;Wang, Ying Kuan",56282757000;57220198622;13103994300,Ministry of Agriculture of the People's Republic of China;Chinese Academy of Agricultural Engineering,China;China,"agriculture and biological engineering are the foundation of agricultural modernization, and related countries have also issued relevant policies to guide the development of agriculture and biotechnology. agricultural and biological engineering experts are the intellectual resources in the field. at present, there is less research on the management and maintenance of agricultural and biological engineering experts, and there is a lack of software systems in this area. in order to realize the management and maintenance of agricultural and biological engineering expert information, a service platform for the international agricultural and biological engineering expert system based on the b/s framework has been developed. the background of the system used c# as the development language, and the foreground used javascript technology and bootstrap. the software adopted asp.net mvc as the web development framework and used the entity framework to operate the sql server background database. the system has the function of searching and querying agricultural and biological engineering expert information according to keywords, and implements the functions of adding, deleting, and modifying data records, and the function of generating spreadsheets and importing spreadsheet data. the development of this system provides effective management tools for the maintenance and construction of agricultural and biological engineering expert databases and lays a good foundation for the construction of agricultural and biological engineering think tanks.",design and implementation of international agricultural and biological engineering expert management system based on web mode
418,2-s2.0-85096158257,10.1145/3372297.3423340,FREEDOM: Engineering a State-of-the-Art DOM Fuzzer,Xu W.,Proceedings of the ACM Conference on Computer and Communications Security,2020-10-30,"The DOM engine of a web browser is a popular attack surface and has been thoroughly fuzzed during its development. A common approach adopted by the latest DOM fuzzers is to generate new inputs based on context-free grammars. However, such a generative approach fails to capture the data dependencies in the inputs of a DOM engine, namely, HTML documents. Meanwhile, it is unclear whether or not coverage-guided mutation, which is well-known to be effective in fuzzing numerous software, still remains to be effective against DOM engines. Worse yet, existing DOM fuzzers cannot adopt a coverage-guided approach because they are unable to fully support HTML mutation and suffer from low browser throughput. To scientifically understand the effectiveness and limitations of the two approaches, we propose FreeDom, a full-fledged cluster-friendly DOM fuzzer that works with both generative and coverage-guided modes. FreeDom relies on a context-aware intermediate representation to describe HTML documents with proper data dependencies. FreeDom also exhibits up to 3.74x higher throughput through browser self-termination. FreeDom has found 24 previously unknown bugs in commodity browsers including Safari, Firefox, and Chrome, and 10 CVEs has been assigned so far. With the context-aware generation, FreeDom finds 3x more unique crashes in WebKit than the state-of-the-art DOM fuzzer, Domato. FreeDom guided by coverage is more effective in revealing new code blocks (2.62%) and finds three complex bugs that its generative approach fails to find. However, coverage-guided mutation that bootstraps with an empty corpus triggers 3.8x fewer unique crashes than the generative approach. The newly revealed coverage, more often than not, negatively affects the effectiveness of DOM fuzzers in bug finding. Therefore, we consider context-aware generation the best practice to find more DOM engine bugs and expect further improvement on coverage-guided DOM fuzzing facilitated by FreeDom.",browser vulnerability discovery | context-aware dom fuzzing | coverage-guided dom fuzzing,5,971-986,Conference Proceeding,Conference Paper,3.0,"Xu, Wen;Park, Soyeon;Kim, Taesoo",57200510933;57213917974;55628583293,Georgia Institute of Technology,United States,"the dom engine of a web browser is a popular attack surface and has been thoroughly fuzzed during its development. a common approach adopted by the latest dom fuzzers is to generate new inputs based on context-free grammars. however, such a generative approach fails to capture the data dependencies in the inputs of a dom engine, namely, html documents. meanwhile, it is unclear whether or not coverage-guided mutation, which is well-known to be effective in fuzzing numerous software, still remains to be effective against dom engines. worse yet, existing dom fuzzers cannot adopt a coverage-guided approach because they are unable to fully support html mutation and suffer from low browser throughput. to scientifically understand the effectiveness and limitations of the two approaches, we propose freedom, a full-fledged cluster-friendly dom fuzzer that works with both generative and coverage-guided modes. freedom relies on a context-aware intermediate representation to describe html documents with proper data dependencies. freedom also exhibits up to 3.74x higher throughput through browser self-termination. freedom has found 24 previously unknown bugs in commodity browsers including safari, firefox, and chrome, and 10 cves has been assigned so far. with the context-aware generation, freedom finds 3x more unique crashes in webkit than the state-of-the-art dom fuzzer, domato. freedom guided by coverage is more effective in revealing new code blocks (2.62%) and finds three complex bugs that its generative approach fails to find. however, coverage-guided mutation that bootstraps with an empty corpus triggers 3.8x fewer unique crashes than the generative approach. the newly revealed coverage, more often than not, negatively affects the effectiveness of dom fuzzers in bug finding. therefore, we consider context-aware generation the best practice to find more dom engine bugs and expect further improvement on coverage-guided dom fuzzing facilitated by freedom.",freedom: engineering a state-of-the-art dom fuzzer
421,2-s2.0-85096997416,10.1145/3379337.3415900,Interactive program synthesis by augmented examples,Zhang T.,UIST 2020 - Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology,2020-10-20,"Programming-by-example (PBE) has become an increasingly popular component in software development tools, human-robot interaction, and end-user programming. A long-standing challenge in PBE is the inherent ambiguity in user-provided examples. This paper presents an interaction model to disambiguate user intent and reduce the cognitive load of understanding and validating synthesized programs. Our model provides two types of augmentations to user-given examples: 1) semantic augmentation where a user can specify how different aspects of an example should be treated by a synthesizer via light-weight annotations, and 2) data augmentation where the synthesizer generates additional examples to help the user understand and validate synthesized programs. We implement and demonstrate this interaction model in the domain of regular expressions, which is a popular mechanism for text processing and data wrangling and is often considered hard to master even for experienced programmers. A within-subjects user study with twelve participants shows that, compared with only inspecting and annotating synthesized programs, interacting with augmented examples significantly increases the success rate of finishing a programming task with less time and increases users? confidence of synthesized programs.",Disambiguation | Example augmentation | Program synthesis,9,627-648,Conference Proceeding,Conference Paper,4.0,"Zhang, Tianyi;Lowmanstone, London;Wang, Xinyu;Glassman, Elena L.",57020216700;57220059574;57026634100;23975987900,"University of Michigan, Ann Arbor;Harvard University",United States;United States,"programming-by-example (pbe) has become an increasingly popular component in software development tools, human-robot interaction, and end-user programming. a long-standing challenge in pbe is the inherent ambiguity in user-provided examples. this paper presents an interaction model to disambiguate user intent and reduce the cognitive load of understanding and validating synthesized programs. our model provides two types of augmentations to user-given examples: 1) semantic augmentation where a user can specify how different aspects of an example should be treated by a synthesizer via light-weight annotations, and 2) data augmentation where the synthesizer generates additional examples to help the user understand and validate synthesized programs. we implement and demonstrate this interaction model in the domain of regular expressions, which is a popular mechanism for text processing and data wrangling and is often considered hard to master even for experienced programmers. a within-subjects user study with twelve participants shows that, compared with only inspecting and annotating synthesized programs, interacting with augmented examples significantly increases the success rate of finishing a programming task with less time and increases users? confidence of synthesized programs.",interactive program synthesis by augmented examples
422,2-s2.0-85099601979,10.1109/ICITSI50517.2020.9264975,Web-based mapping of electric customer distribution of pln sub-district sawahlunto,Akbar F.,"2020 International Conference on Information Technology Systems and Innovation, ICITSI 2020 - Proceedings",2020-10-19,"Indonesian state-owned electricity company (PLN) in the sub-district of Sawahlunto is responsible for distributing electricity to all customers in Sawahlunto. Customers' scattered location in the Sawahlunto area has been a long-standing problem for the PLN, especially power loss problem. Therefore, it was necessary to build a web-based Geographic Information System (GIS) that includes all network distribution and customer information. The software development was accomplished using needs analysis, design, implementation, and application testing. Based on the functional needs analysis, we defined the desired functions, such as finding customer information, the nearest routes to customer locations, and showing each customer's power distribution network. The software was built using PostGIS and Google Maps with PHP and Javascript. Testing was conducted using the BlackBox testing method. Tests were performed on each function, and software output with input from the database was compared. Functional testing by three testers proved conclusively that this application fulfilled the design needs.",Electric distribution line | Web-based mapping,0,204-210,Conference Proceeding,Conference Paper,3.0,"Akbar, Fajril;Tirozi, Septian;Suryamen, Haris",56029641300;57221597292;57208575694,Universitas Andalas,Indonesia,"indonesian state-owned electricity company (pln) in the sub-district of sawahlunto is responsible for distributing electricity to all customers in sawahlunto. customers' scattered location in the sawahlunto area has been a long-standing problem for the pln, especially power loss problem. therefore, it was necessary to build a web-based geographic information system (gis) that includes all network distribution and customer information. the software development was accomplished using needs analysis, design, implementation, and application testing. based on the functional needs analysis, we defined the desired functions, such as finding customer information, the nearest routes to customer locations, and showing each customer's power distribution network. the software was built using postgis and google maps with php and javascript. testing was conducted using the blackbox testing method. tests were performed on each function, and software output with input from the database was compared. functional testing by three testers proved conclusively that this application fulfilled the design needs.",web-based mapping of electric customer distribution of pln sub-district sawahlunto
423,2-s2.0-85097842407,10.1145/3382025.3414961,Neverlang and FeatureIDE just married: integrated language product line development environment,Favalli L.,ACM International Conference Proceeding Series,2020-10-19,"Language development is inherently complex. With the support of a suitable language development environment most computer scientists could develop their own domain-specific language (DSL) with relative ease. Yet, when the DSL is the result of a configuration over a language product line (LPL) - -a special software product line (SPL) of compilers/interpreters and corresponding IDE services - -they fail to provide adequate support. An environment for LPL engineering should facilitate the underlying process involving three distinct roles: a language engineer developing the LPL, a language deployer configuring a language product, and a language user using the language product. Neither IDEs nor SPLE environments can cater all three roles and fully support the LPL engineering process with distributed, incremental development, configuration, and deployment of language variants. In this paper, we present an LPL engineering process for the distributed, incremental development of LPLs and an integrated language product line development environment supporting this process, catering the three roles, and ensuring the consistency among all artifacts of the LPL: language components implementing a language feature, the feature model, language configurations and the resulting language products. To create such an environment, we married the Neverlang language workbench and AiDE its LPL engineering environment with the FeatureIDE SPL engineering environment. While Neverlang supports the development of LPLs and deployment of language products, AiDE generates the feature model for the LPL under development, whereas FeatureIDE handles the feature configuration. We illustrate the applicability of the LPL engineering process and the suitability of our development environment for the three roles by showcasing its application for teaching programming with a growable language. In there, an LPL for Javascript was developed/refactored, 15 increasingly complex language products were configured/updated and finally deployed.",domain specific languages | language product lines | neverlang,1,193-204,Conference Proceeding,Conference Paper,3.0,"Favalli, Luca;Kühn, Thomas;Cazzola, Walter",57220900961;56333529900;6602449966,Karlsruher Institut für Technologie;Università degli Studi di Milano,Germany;Italy,"language development is inherently complex. with the support of a suitable language development environment most computer scientists could develop their own domain-specific language (dsl) with relative ease. yet, when the dsl is the result of a configuration over a language product line (lpl) - -a special software product line (spl) of compilers/interpreters and corresponding ide services - -they fail to provide adequate support. an environment for lpl engineering should facilitate the underlying process involving three distinct roles: a language engineer developing the lpl, a language deployer configuring a language product, and a language user using the language product. neither ides nor sple environments can cater all three roles and fully support the lpl engineering process with distributed, incremental development, configuration, and deployment of language variants. in this paper, we present an lpl engineering process for the distributed, incremental development of lpls and an integrated language product line development environment supporting this process, catering the three roles, and ensuring the consistency among all artifacts of the lpl: language components implementing a language feature, the feature model, language configurations and the resulting language products. to create such an environment, we married the neverlang language workbench and aide its lpl engineering environment with the featureide spl engineering environment. while neverlang supports the development of lpls and deployment of language products, aide generates the feature model for the lpl under development, whereas featureide handles the feature configuration. we illustrate the applicability of the lpl engineering process and the suitability of our development environment for the three roles by showcasing its application for teaching programming with a growable language. in there, an lpl for javascript was developed/refactored, 15 increasingly complex language products were configured/updated and finally deployed.",neverlang and featureide just married: integrated language product line development environment
424,2-s2.0-85096177826,10.1109/ICSESS49938.2020.9237742,Research Review of Design Pattern Mining,Zhang H.,"Proceedings of the IEEE International Conference on Software Engineering and Service Sciences, ICSESS",2020-10-16,"Design pattern is widely used in the field of object oriented development. Mining design pattern examples in the source code is helpful to deepen the understanding of the program and facilitate later maintenance. Therefore, design pattern mining has become a hot topic in reverse engineering. In recent years, new research methods have emerged in the direction of design pattern mining, and the mining accuracy and time complexity have been improved. This paper classifies and summarizes the existing design pattern mining research work, analyzes and discusses the different methods, points out the advantages and disadvantages of the corresponding research, and prospects the future research. This review provides the latest research trends.",Design pattern | Object oriented | Reverse engineering | Time complexity,0,339-342,Conference Proceeding,Conference Paper,2.0,"Zhang, Hao;Liu, Jianbin",57219942398;36994837300,Beijing Information Science &amp; Technology University,China,"design pattern is widely used in the field of object oriented development. mining design pattern examples in the source code is helpful to deepen the understanding of the program and facilitate later maintenance. therefore, design pattern mining has become a hot topic in reverse engineering. in recent years, new research methods have emerged in the direction of design pattern mining, and the mining accuracy and time complexity have been improved. this paper classifies and summarizes the existing design pattern mining research work, analyzes and discusses the different methods, points out the advantages and disadvantages of the corresponding research, and prospects the future research. this review provides the latest research trends.",research review of design pattern mining
425,2-s2.0-85092308036,10.1145/3419635.3419739,Design and Implementation of College Internet + English Education System Platform Based on HTML5,Wang X.,ACM International Conference Proceeding Series,2020-10-16,"With the continuous progress and development of Internet technology, it has gradually become an important part of front-end development technology. At present, the main technical software of front-end technology and rich client technology is HTML5, which is transferred to the client through the combination of HTML5 and JavaScript software and the processing of the underlying logic. HTML5 has features such as animation, multimedia and three bits to replace Flash and Silverlight software and improve processing efficiency. Therefore, HTML5 technology is chosen as the implementation of college English teaching system.",College English teaching | Css3 | Html5 | J query,1,512-515,Conference Proceeding,Conference Paper,1.0,"Wang, Xiaosa",57219343452,Wuhan Donghu University,China,"with the continuous progress and development of internet technology, it has gradually become an important part of front-end development technology. at present, the main technical software of front-end technology and rich client technology is html5, which is transferred to the client through the combination of html5 and javascript software and the processing of the underlying logic. html5 has features such as animation, multimedia and three bits to replace flash and silverlight software and improve processing efficiency. therefore, html5 technology is chosen as the implementation of college english teaching system.",design and implementation of college internet + english education system platform based on html5
426,2-s2.0-85095438979,10.1145/3419111.3421277,Kappa: A programming framework for serverless computing,Zhang W.,SoCC 2020 - Proceedings of the 2020 ACM Symposium on Cloud Computing,2020-10-12,"Serverless computing has recently emerged as a new paradigm for running software on the cloud. In this paradigm, programs need to be expressed as a set of short-lived tasks, each of which can complete within a short bounded time (e.g., 15 minutes on AWS Lambda). Serverless computing is beneficial to cloud providers - -by allowing them to better utilize resources - -and to users - -by simplifying management and enabling greater elasticity. However, developing applications to run in this environment is challenging, requiring users to appropriately partition their code, develop new coordination mechanisms, and deal with failure recovery. In this paper, we propose Kappa, a framework that simplifies serverless development. It uses checkpointing to handle lambda function timeouts, and provides concurrency mechanisms that enable parallel computation and coordination.",distributed computing | serverless,13,328-343,Conference Proceeding,Conference Paper,4.0,"Zhang, Wen;Fang, Vivian;Panda, Aurojit;Shenker, Scott",57221431048;57219779696;55336403500;35593393300,"University of California, Berkeley;New York University;ICSI",United States;United States;,"serverless computing has recently emerged as a new paradigm for running software on the cloud. in this paradigm, programs need to be expressed as a set of short-lived tasks, each of which can complete within a short bounded time (e.g., 15 minutes on aws lambda). serverless computing is beneficial to cloud providers - -by allowing them to better utilize resources - -and to users - -by simplifying management and enabling greater elasticity. however, developing applications to run in this environment is challenging, requiring users to appropriately partition their code, develop new coordination mechanisms, and deal with failure recovery. in this paper, we propose kappa, a framework that simplifies serverless development. it uses checkpointing to handle lambda function timeouts, and provides concurrency mechanisms that enable parallel computation and coordination.",kappa: a programming framework for serverless computing
427,2-s2.0-85098887558,10.1109/SMC42975.2020.9283403,IoT-Based Home Care System with a FPGA Development Board by Using RS-485 Interface and Verilog HDL,Sung G.M.,"Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics",2020-10-11,"This paper presents the packet processing and transmission of a field programmable gate array (FPGA) development board by using an RS-485 interface module and Verilog HDL. The proposed communication protocol was established between the sensors in the sensing layer and web server. In the sensing layer, the sensor system, which comprises a temperature sensor, warning light, and fan, controls the environment temperature. An attractive Internet of Things application system was proposed to simultaneously monitor real-time temperature information through wireless communication and the webpage. Node-RED software was used to develop the home care system because of its advantages in facilitating management and maintenance. The linkage function was written in the JavaScript language on Node-RED software. In the designed system, when the temperature reaches the preset value, the fan and warning light automatically turn on and a notification email is sent to the user. The measurement results showed that the throughput and conversion time were 0.00958 Mbps and 283.83 ms, respectively, at a clock frequency of 1 MHz and Baud rate of 9600 bps.",Field programmable gate array (FPGA) development board | home care system | Internet of Things (IoT) | JavaScript | Node-RED software | RS-485 interface,1,3370-3374,Conference Proceeding,Conference Paper,3.0,"Sung, Guo Ming;Lee, Chun Ting;Chen, Chao Rong",7005574552;57219108814;8644139400,National Taipei University of Technology,Taiwan,"this paper presents the packet processing and transmission of a field programmable gate array (fpga) development board by using an rs-485 interface module and verilog hdl. the proposed communication protocol was established between the sensors in the sensing layer and web server. in the sensing layer, the sensor system, which comprises a temperature sensor, warning light, and fan, controls the environment temperature. an attractive internet of things application system was proposed to simultaneously monitor real-time temperature information through wireless communication and the webpage. node-red software was used to develop the home care system because of its advantages in facilitating management and maintenance. the linkage function was written in the javascript language on node-red software. in the designed system, when the temperature reaches the preset value, the fan and warning light automatically turn on and a notification email is sent to the user. the measurement results showed that the throughput and conversion time were 0.00958 mbps and 283.83 ms, respectively, at a clock frequency of 1 mhz and baud rate of 9600 bps.",iot-based home care system with a fpga development board by using rs-485 interface and verilog hdl
430,2-s2.0-85093537952,10.1145/3387903.3389314,The effectiveness of client-side javascript testing,Moon J.,"Proceedings - 2020 IEEE/ACM 1st International Conference on Automation of Software Test, AST 2020",2020-10-07,"In the simplest form, software testing consists of creating test cases from a defined input space, executing those test cases for the systemunder-test (SUT), and evaluating the outputs with a mechanism for determining success or failure (i.e. oracle). Bodies of research focus on the selection, execution, evaluation, and even testing of software tests. Many tools and frameworks aim to apply the research in ways that improve test development. However, the options available for testing user interfaces have technical limitations that negatively impact practical application in industry. As such, this industry abstract explores the journey between industry-standard frameworks for testing user interfaces, the negative impacts of their limitations, and a proposed solution that attempts to avoid those issues.",Javascript | Software testing,0,101-102,Conference Proceeding,Conference Paper,3.0,"Moon, Jonny;Farnsworth, Brian;Smith, Riley",57219518667;57219516896;57209663588,Adobe Inc.,United States,"in the simplest form, software testing consists of creating test cases from a defined input space, executing those test cases for the systemunder-test (sut), and evaluating the outputs with a mechanism for determining success or failure (i.e. oracle). bodies of research focus on the selection, execution, evaluation, and even testing of software tests. many tools and frameworks aim to apply the research in ways that improve test development. however, the options available for testing user interfaces have technical limitations that negatively impact practical application in industry. as such, this industry abstract explores the journey between industry-standard frameworks for testing user interfaces, the negative impacts of their limitations, and a proposed solution that attempts to avoid those issues.",the effectiveness of client-side javascript testing
438,2-s2.0-85113675808,10.1109/CLEI52000.2020.00028,"API Topic Issues Indexing, Exploration and Discovery for API Community Knowledge",Ajam G.,"Proceedings - 2020 46th Latin American Computing Conference, CLEI 2020",2020-10-01,"Application Programming Interface (API) is a core technology that facilitates developers' productivity by enabling the reuse of software components. Understanding APIs and gaining knowledge about their usage are therefore fundamental needs for developers that impact a wide range of software development activities. This paper presents an approach to enable API users to explore, discover and learn about APIs through API topic issues discussed in Stack Overflow (SO), a widely used programming, community question-answering (CQA) site. Our work proposes an integrated API Knowledge Base (KB) and indexing technique that combines both SO API-related posts as well as other API learning resources collected from the Web (e.g., API video-tutorials from Youtube). The resulting indexed and enriched API community knowledge can be queried in a API-topic-issue driven manner using a simple yet powerful domain-specific language (DSL). We demonstrate the feasibility of our approach through Scout-bot, our tool for exploration and discovery of API topic issues.",API community knowledge | API Indexing | API query bot | API topic issues,1,178-185,Conference Proceeding,Conference Paper,3.0,"Ajam, George;Rodriguez, Carlos;Benatallah, Boualem",57233969900;56766313100;6701493053,Universidad Católica Nuestra Señora de la Asunción;University of Babylon;UNSW Sydney,Paraguay;Iraq;Australia,"application programming interface (api) is a core technology that facilitates developers' productivity by enabling the reuse of software components. understanding apis and gaining knowledge about their usage are therefore fundamental needs for developers that impact a wide range of software development activities. this paper presents an approach to enable api users to explore, discover and learn about apis through api topic issues discussed in stack overflow (so), a widely used programming, community question-answering (cqa) site. our work proposes an integrated api knowledge base (kb) and indexing technique that combines both so api-related posts as well as other api learning resources collected from the web (e.g., api video-tutorials from youtube). the resulting indexed and enriched api community knowledge can be queried in a api-topic-issue driven manner using a simple yet powerful domain-specific language (dsl). we demonstrate the feasibility of our approach through scout-bot, our tool for exploration and discovery of api topic issues.","api topic issues indexing, exploration and discovery for api community knowledge"
439,2-s2.0-85113655374,10.1109/CLEI52000.2020.00023,A Suite of Metrics for Evaluating Client-Side web Applications: An Empirical Validation,Lopez L.F.H.,"Proceedings - 2020 46th Latin American Computing Conference, CLEI 2020",2020-10-01,"Currently the web software development of the client-side is growing fast. This has made JavaScript-based software and related tools grow fast too. However, this growth makes more evident the need to develop applications with a higher level of quality. This paper aims to identify a suite of quality metrics used in software development using JavaScript from a review of the literature on the subject. The analysis of the literature shown a total of 26 metrics identified without a clear domain of some of them. A validation with experienced JavaScript programmers shows that the Metrics of Maintainability, Linters, Number of Functions and Average Data Refresh as the most relevant.",front-end web applications | JavaScript | quality metrics | software quality,0,138-146,Conference Proceeding,Conference Paper,3.0,"Lopez, Luis Felipe Henao;Martinez, Maricela Gomez;Bedoya, Albeiro Espinosa",57233489500;57233243200;57190577818,Universidad Nacional de Colombia Medellin,Colombia,"currently the web software development of the client-side is growing fast. this has made javascript-based software and related tools grow fast too. however, this growth makes more evident the need to develop applications with a higher level of quality. this paper aims to identify a suite of quality metrics used in software development using javascript from a review of the literature on the subject. the analysis of the literature shown a total of 26 metrics identified without a clear domain of some of them. a validation with experienced javascript programmers shows that the metrics of maintainability, linters, number of functions and average data refresh as the most relevant.",a suite of metrics for evaluating client-side web applications: an empirical validation
440,2-s2.0-85113652245,10.1109/CLEI52000.2020.00032,Code Quality Practices: Perspective of Team Leaders,Adorjan A.,"Proceedings - 2020 46th Latin American Computing Conference, CLEI 2020",2020-10-01,"This paper describes and discusses a pilot study about code quality practices from the software development leader perspective. Semi-structured interview and thematic analysis have been selected as qualitative analysis methods. This article introduces the design of the research protocol, the execution of the interviews and the analysis process. The results drawn from the present study suggest potential dependence of the practices according to the context of the organisation: type of client and methodology. Code review, pull request in distributed repositories and coding standards emerge as the main code quality practices.",code quality | semi-structured interview | thematic analysis,0,213-221,Conference Proceeding,Conference Paper,3.0,"Adorjan, Alejandro;Solari, Martin;Vallespir, Diego",56021800000;15078321300;36081432000,Universidad ORT Uruguay;Universidad de la Republica,Uruguay;Uruguay,"this paper describes and discusses a pilot study about code quality practices from the software development leader perspective. semi-structured interview and thematic analysis have been selected as qualitative analysis methods. this article introduces the design of the research protocol, the execution of the interviews and the analysis process. the results drawn from the present study suggest potential dependence of the practices according to the context of the organisation: type of client and methodology. code review, pull request in distributed repositories and coding standards emerge as the main code quality practices.",code quality practices: perspective of team leaders
441,2-s2.0-85107966082,10.1007/s42486-020-00038-y,PWCT: a novel general-purpose visual programming language in support of pervasive application development,Fayed M.S.,CCF Transactions on Pervasive Computing and Interaction,2020-10-01,"Visual programming languages (VPLs) are inevitable tools to attract more people to the programming world. In this article, a novel VPL—programming without coding technology (PWCT)—is introduced. The main objective behind developing this tool was to create a general-purpose VPL that also possesses textual languages’ capabilities. PWCT is a language that can be used to develop similar programs to the ones developed in C++ or Java for example. As the name indicates, PWCT requires no coding at all. A person only needs to know the basic programming concepts to be able to use the tool. PWCT has many attractive features and can be used to develop applications of different domain including pervasive computing. PWCT has been launched as a Sourceforge project, which currently has more than 240 K downloads for the tool and over 22 M downloads for the samples and tutorials. A staggering number of programs were developed in PWCT all over the world. This article focuses on the core aspect of the tool. In addition, a number of studies are carried out to evaluate the usability and productivity of the tool. Feedback from developers and results from the studies indicate that PWCT is a very appealing, competitive, and powerful language that can be used in developing pervasive and mobile computing applications.",General-purpose | No coding | Pervasive computing | Programming | Visual programming languages,1,164-177,Journal,Article,5.0,"Fayed, Mahmoud S.;Al-Qurishi, Muhammad;Alamri, Atif;Hossain, M. Anwar;Al-Daraiseh, Ahmad A.",56084516500;55510980400;35432733300;57212814539;16743794500,King Saud University,Saudi Arabia,"visual programming languages (vpls) are inevitable tools to attract more people to the programming world. in this article, a novel vpl—programming without coding technology (pwct)—is introduced. the main objective behind developing this tool was to create a general-purpose vpl that also possesses textual languages’ capabilities. pwct is a language that can be used to develop similar programs to the ones developed in c++ or java for example. as the name indicates, pwct requires no coding at all. a person only needs to know the basic programming concepts to be able to use the tool. pwct has many attractive features and can be used to develop applications of different domain including pervasive computing. pwct has been launched as a sourceforge project, which currently has more than 240 k downloads for the tool and over 22 m downloads for the samples and tutorials. a staggering number of programs were developed in pwct all over the world. this article focuses on the core aspect of the tool. in addition, a number of studies are carried out to evaluate the usability and productivity of the tool. feedback from developers and results from the studies indicate that pwct is a very appealing, competitive, and powerful language that can be used in developing pervasive and mobile computing applications.",pwct: a novel general-purpose visual programming language in support of pervasive application development
442,2-s2.0-85105495001,10.1109/CONTIE51334.2020.00011,Development of a Video Game to Support the Strengthening of Pre-Numerical Skills and the Numerical Relationship to Quantities with Children with Autism Spectrum Disorder,Soto Munoz J.G.,"Proceedings - 2020 3rd International Conference of Inclusive Technology and Education, CONTIE 2020",2020-10-01,"Education, in a certain sense, conditions individuals to master the essential skills to their independence, including people with special needs. For this reason, different measures and practices have been carried out to reinforce knowledge and aim to help these people improve their quality of life. Reading, writing and mathematics are considered fundamental for this development, which is why it is essential that this knowledge be properly acquired at an early age by all people, therefore, many teachers use the dynamics that proliferate and enrich the acquisition of that knowledge. Currently, the use of video games has proliferated, allowing them to be found in different contexts and areas, such as medicine, education, as well as in military aspects. Although the idea of video games that help people with special needs to understand activities or strengthen knowledge is not new, there are still many areas that have not been strengthened and that require special attention to support the intellectual development of these individuals. This work proposes the development of a video game that allows supporting teachers or tutors to strengthen pre-numerical skills and the numerical relationship to quantities in children diagnosed with autism spectrum disorder.",Autism | Educational Software | Mathematics | Pre-numerical Skills | Video Game,0,7-14,Conference Proceeding,Conference Paper,5.0,"Soto Munoz, Jonathan Giovanni;Andres Sandoval Bringas, Jesus;Encinas, Israel Duran;Cecilia Lara Rubio, Brenda;Garcia, Miguel Parra",57215137111;57215127688;57223293328;57223303721;57215118863,Universidad Autónoma de Baja California Sur,Mexico,"education, in a certain sense, conditions individuals to master the essential skills to their independence, including people with special needs. for this reason, different measures and practices have been carried out to reinforce knowledge and aim to help these people improve their quality of life. reading, writing and mathematics are considered fundamental for this development, which is why it is essential that this knowledge be properly acquired at an early age by all people, therefore, many teachers use the dynamics that proliferate and enrich the acquisition of that knowledge. currently, the use of video games has proliferated, allowing them to be found in different contexts and areas, such as medicine, education, as well as in military aspects. although the idea of video games that help people with special needs to understand activities or strengthen knowledge is not new, there are still many areas that have not been strengthened and that require special attention to support the intellectual development of these individuals. this work proposes the development of a video game that allows supporting teachers or tutors to strengthen pre-numerical skills and the numerical relationship to quantities in children diagnosed with autism spectrum disorder.",development of a video game to support the strengthening of pre-numerical skills and the numerical relationship to quantities with children with autism spectrum disorder
443,2-s2.0-85103741942,10.1109/CONTIE51334.2020.00022,Application of accessibility guidelines in a virtual museum.,Rojas H.,"Proceedings - 2020 3rd International Conference of Inclusive Technology and Education, CONTIE 2020",2020-10-01,"This work consisted in applying a web accessibility model in accordance with the WCAG 2.1 guidelines for the development of a virtual museum, as well as studying the context of museum accessibility, the perspectives of the groups involved in its development, the time, effort and investment required, and providing an answer on who are the people that require accessibility.The software development team performed two types of tests on the web application: An automated test and manual test. In the case of automated tests, the tools used automatically perform a quick review of the website and evaluate aspects such as color contrast, text size, consistency in the HTML structure, styles and page navigability, while for manual tests, solutions based on WCAG 2.1 were implemented to comply with the principles: i) Perceptible, automatic text reading, and zoom function were added to see an image in detail; ii) Operable: keyboard navigation was added to all the website's functionalities, iii) Understandable: symbols were designed in a consistent way to the action they represent, and all images have an adequate description, iv) Robust, the website allows the user to use their own technologies, adapting to them. Finally, tests were conducted with disabled users using a questionnaire and focus group techniques to assess their perception on using the website and the results indicate the website is accessible.",accessible museum | manual and automated test | software for disability | tools for accessibility,2,73-79,Conference Proceeding,Conference Paper,5.0,"Rojas, Hesmeralda;Renteria, Ronald;Acosta, Ely;Arevalo, Humberto;Pilares, Marisol",57203159362;57202990033;57223272908;57223300990;57222705199,Universidad Nacional Intercultural de Quillabamba;Universidad Tecnológica de los Andes;Universidad Nacional Micaela Bastidas de Apurímac,Peru;Peru;Peru,"this work consisted in applying a web accessibility model in accordance with the wcag 2.1 guidelines for the development of a virtual museum, as well as studying the context of museum accessibility, the perspectives of the groups involved in its development, the time, effort and investment required, and providing an answer on who are the people that require accessibility.the software development team performed two types of tests on the web application: an automated test and manual test. in the case of automated tests, the tools used automatically perform a quick review of the website and evaluate aspects such as color contrast, text size, consistency in the html structure, styles and page navigability, while for manual tests, solutions based on wcag 2.1 were implemented to comply with the principles: i) perceptible, automatic text reading, and zoom function were added to see an image in detail; ii) operable: keyboard navigation was added to all the website's functionalities, iii) understandable: symbols were designed in a consistent way to the action they represent, and all images have an adequate description, iv) robust, the website allows the user to use their own technologies, adapting to them. finally, tests were conducted with disabled users using a questionnaire and focus group techniques to assess their perception on using the website and the results indicate the website is accessible.",application of accessibility guidelines in a virtual museum.
445,2-s2.0-85099903893,10.4018/IJOSSP.2020100101,Open source software development challenges: A systematic literature review on GitHub,Seker A.,International Journal of Open Source Software and Processes,2020-10-01,"GitHub is the most common code hosting and repository service for open-source software (OSS) projects. Thanks to the great variety of features, researchers benefit from GitHub to solve a wide range of OSS development challenges. In this context, the authors thought that was important to conduct a literature review on studies that used GitHub data. To reach these studies, they conducted this literature review based on a GitHub dataset source study instead of a keyword-based search in digital libraries. Since GHTorrent is the most widely known GitHub dataset according to the literature, they considered the studies that cite this dataset for the systematic literature review. In this study, they reviewed the selected 172 studies according to some criteria that used the dataset as a data source. They classified them within the scope of OSS development challenges thanks to the information they extract from the metadata of studies. They put forward some issues about the dataset and they offered the focused and attention-grabbing fields and open challenges that we encourage the researchers to study on them.",GHTorrent | GitHub | Open-Source | OSS | SLR | Systematic Literature Review,0,1-26,Journal,Article,4.0,"Seker, Abdulkadir;Diri, Banu;Arslan, Halil;Amasyalı, Mehmet Fatih",57190735163;22978771800;57213369355;55664402200,Yildiz Technical University;Cumhuriyet Üniversitesi,Turkey;Turkey,"github is the most common code hosting and repository service for open-source software (oss) projects. thanks to the great variety of features, researchers benefit from github to solve a wide range of oss development challenges. in this context, the authors thought that was important to conduct a literature review on studies that used github data. to reach these studies, they conducted this literature review based on a github dataset source study instead of a keyword-based search in digital libraries. since ghtorrent is the most widely known github dataset according to the literature, they considered the studies that cite this dataset for the systematic literature review. in this study, they reviewed the selected 172 studies according to some criteria that used the dataset as a data source. they classified them within the scope of oss development challenges thanks to the information they extract from the metadata of studies. they put forward some issues about the dataset and they offered the focused and attention-grabbing fields and open challenges that we encourage the researchers to study on them.",open source software development challenges: a systematic literature review on github
446,2-s2.0-85098540819,10.1145/3377812.3381392,Scalable and Approximate Program Dependence Analysis,Lee S.,"Proceedings - 2020 ACM/IEEE 42nd International Conference on Software Engineering: Companion, ICSE-Companion 2020",2020-10-01,"Program dependence is a fundamental concept to many software engineering tasks, yet the traditional dependence analysis struggles to cope with common modern development practices such as multilingual implementations and use of third-party libraries. While Observation-based Slicing (ORBS) solves these issues and produces an accurate slice, it has a scalability problem due to the need to build and execute the target program multiple times. We would like to propose a radical change of perspective: A useful dependence analysis needs to be scalable even if it approximates the dependency. Our goal is a scalable approximate program dependence analysis via estimating the likelihood of dependence. We claim that 1) using external information such as lexical analysis or a development history, 2) learning dependence model from partial observations, and 3) merging static, and observation-based approach would assist the proposition. We expect that our technique would introduce a new perspective of program dependence analysis into the likelihood of dependence. It would also broaden the capability of the dependence analysis towards large and complex software.",ORBS | Program Analysis | Program Slicing,0,162-165,Conference Proceeding,Conference Paper,1.0,"Lee, Seongmin",57222641930,Korea Advanced Institute of Science and Technology,South Korea,"program dependence is a fundamental concept to many software engineering tasks, yet the traditional dependence analysis struggles to cope with common modern development practices such as multilingual implementations and use of third-party libraries. while observation-based slicing (orbs) solves these issues and produces an accurate slice, it has a scalability problem due to the need to build and execute the target program multiple times. we would like to propose a radical change of perspective: a useful dependence analysis needs to be scalable even if it approximates the dependency. our goal is a scalable approximate program dependence analysis via estimating the likelihood of dependence. we claim that 1) using external information such as lexical analysis or a development history, 2) learning dependence model from partial observations, and 3) merging static, and observation-based approach would assist the proposition. we expect that our technique would introduce a new perspective of program dependence analysis into the likelihood of dependence. it would also broaden the capability of the dependence analysis towards large and complex software.",scalable and approximate program dependence analysis
450,2-s2.0-85091758259,10.1109/ICSTW50294.2020.00045,Selenium based Testing Systems for Analytical Data Generation of Website User Behavior,Tanaka T.,"Proceedings - 2020 IEEE 13th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2020",2020-10-01,"In recent years, websites have automatically sorted out content suitable for individual users on the website by learning user behavior patterns using AI. Website developers develop a function to generate behavioral data for analysis. The behavior data for analysis records the operation history of all functions such as content expression and button press. However, many consumer websites have a problem of enormous amount of testing due to continuous and frequent development. In this study, we propose a method for efficiently performing browser tests using Selenium by managing the specifications of the behavior data generation function.",Data Management | Selenium | Test Automation,1,216-221,Conference Proceeding,Conference Paper,6.0,"Tanaka, Takamasa;Niibori, Hidekazu;Shiyingxue, Li;Nomura, Shimpei;Nakao, Tadayoshi;Tsuda, Kazuhiko",57219222098;35797263100;57194040032;57194038979;57219227938;7202766371,"Nomura Research Institute, Ltd.;University of Tsukuba;Recruit Co., Ltd.",Japan;Japan;Japan,"in recent years, websites have automatically sorted out content suitable for individual users on the website by learning user behavior patterns using ai. website developers develop a function to generate behavioral data for analysis. the behavior data for analysis records the operation history of all functions such as content expression and button press. however, many consumer websites have a problem of enormous amount of testing due to continuous and frequent development. in this study, we propose a method for efficiently performing browser tests using selenium by managing the specifications of the behavior data generation function.",selenium based testing systems for analytical data generation of website user behavior
451,2-s2.0-85091564499,10.1109/ICST46399.2020.00015,Language-Agnostic Generation of Compilable Test Programs,Kreutzer P.,"Proceedings - 2020 IEEE 13th International Conference on Software Testing, Verification and Validation, ICST 2020",2020-10-01,"Testing is an integral part of the development of compilers and other language processors. To automatically create large sets of test programs, random program generators, or fuzzers, have emerged. Unfortunately, existing approaches are either language-specific (and thus require a rewrite for each language) or may generate programs that violate rules of the respective programming language (which limits their usefulness). This work introduces ∗Smith, a language-agnostic framework for the generation of valid, compilable test programs. It takes as input an abstract attribute grammar that specifies the syntactic and semantic rules of a programming language. It then creates test programs that satisfy all these rules. By aggressively pruning the search space and keeping the construction as local as possible, ∗Smith can generate huge, complex test programs in short time. We present four case studies covering four real-world programming languages (C, Lua, SQL, and SMT-LIB 2) to show that ∗Smith is both efficient and effective, while being flexible enough to support programming languages that differ considerably. We found bugs in all four case studies. For example, ∗Smith detected 165 different crashes in older versions of GCC and LLVM. ∗Smith and the language grammars are available online.",attribute grammars | compilers | fuzz testing,3,39-50,Conference Proceeding,Conference Paper,3.0,"Kreutzer, Patrick;Kraus, Stefan;Philippsen, Michael",57189686095;36004109900;6701347889,Friedrich-Alexander-Universität Erlangen-Nürnberg,Germany,"testing is an integral part of the development of compilers and other language processors. to automatically create large sets of test programs, random program generators, or fuzzers, have emerged. unfortunately, existing approaches are either language-specific (and thus require a rewrite for each language) or may generate programs that violate rules of the respective programming language (which limits their usefulness). this work introduces ∗smith, a language-agnostic framework for the generation of valid, compilable test programs. it takes as input an abstract attribute grammar that specifies the syntactic and semantic rules of a programming language. it then creates test programs that satisfy all these rules. by aggressively pruning the search space and keeping the construction as local as possible, ∗smith can generate huge, complex test programs in short time. we present four case studies covering four real-world programming languages (c, lua, sql, and smt-lib 2) to show that ∗smith is both efficient and effective, while being flexible enough to support programming languages that differ considerably. we found bugs in all four case studies. for example, ∗smith detected 165 different crashes in older versions of gcc and llvm. ∗smith and the language grammars are available online.",language-agnostic generation of compilable test programs
454,2-s2.0-85079695082,10.1108/ECAM-06-2019-0328,Developing a building information modeling–based performance management system for public–private partnerships,Yuan J.,"Engineering, Construction and Architectural Management",2020-10-01,"Purpose: Effective performance management (PM) in public–private partnership (PPP) projects is critical to realizing value for money (VFM). This study aims to provide an in-depth understanding of problems existing in PPP PM and possible avenues for improvement, presenting an experimental system to verify that building information modeling (BIM) and other information communication technologies can improve PPP PM. Design/methodology/approach: The mixed research method adopted in this study combined empirical research with experimental research. Semistructured interviews were used to ascertain the current situation of PPP PM with the help of Nvivo software. A BIM-based performance management system (BPMS), which combines BIM with Web and Cloud technology, was then constructed to achieve performance monitoring, performance measurement, and performance-based payment. Finally, a case study was introduced to explain the function application of the proposed system. Findings: The case demonstration verified is found to verify that the developed BIM-based execution framework for PPP PM can effectively guide stakeholders toward achieving mixed PM, promote effective PM, and improve work efficiency with the support of BIM and other information and communication technologies. Originality/value: Through the development of a BPMS for PPP projects, the effectiveness and efficiency of PM are improved. Practical PM applications are also provided to different stakeholders, through which the key performance indicators and the behaviors of the government and private-sector partners can be monitored to form a more comprehensive and reasonable PM mechanism and promote the realization of VFM in PPP projects.",Building information modeling (BIM) | Cloud | Database | Performance management | PPPs | Web-BIM,12,1727-1762,Journal,Article,6.0,"Yuan, Jingfeng;Li, Xuewei;Ke, Yongjian;Xu, Wei;Xu, Zhao;Skibniewski, M.",27268083300;57206893933;26021857400;57196319151;56173458000;7004024216,A. James Clark School of Engineering;Chaoyang University of Technology;University of Technology Sydney;Institute of Theoretical and Applied Informatics of the Polish Academy of Sciences;Bydgoszcz University of Science and Technology;Southeast University;Yunbin Company of China,United States;Taiwan;Australia;Poland;Poland;China;China,"purpose: effective performance management (pm) in public–private partnership (ppp) projects is critical to realizing value for money (vfm). this study aims to provide an in-depth understanding of problems existing in ppp pm and possible avenues for improvement, presenting an experimental system to verify that building information modeling (bim) and other information communication technologies can improve ppp pm. design/methodology/approach: the mixed research method adopted in this study combined empirical research with experimental research. semistructured interviews were used to ascertain the current situation of ppp pm with the help of nvivo software. a bim-based performance management system (bpms), which combines bim with web and cloud technology, was then constructed to achieve performance monitoring, performance measurement, and performance-based payment. finally, a case study was introduced to explain the function application of the proposed system. findings: the case demonstration verified is found to verify that the developed bim-based execution framework for ppp pm can effectively guide stakeholders toward achieving mixed pm, promote effective pm, and improve work efficiency with the support of bim and other information and communication technologies. originality/value: through the development of a bpms for ppp projects, the effectiveness and efficiency of pm are improved. practical pm applications are also provided to different stakeholders, through which the key performance indicators and the behaviors of the government and private-sector partners can be monitored to form a more comprehensive and reasonable pm mechanism and promote the realization of vfm in ppp projects.",developing a building information modeling–based performance management system for public–private partnerships
455,2-s2.0-85097189768,10.1145/3425329.3425339,Software development process modeling with patterns,Hachemi A.,ACM International Conference Proceeding Series,2020-09-25,"Software developement process modeling with patterns allows to benefit from the advantages of these latter. Indeed, this modeling allows to benefit from the proved and reusable knowledge offered by patterns, which improves the quality of the models produced and reduces the modeling time and effort. In this article, we discuss the main modeling practices of software developement processes with patterns. We focuse on the advantages and difficulties of these practices.",Patterns reuse | Process pattern | SDPM | Software development process model | Software pattern,2,37-41,Conference Proceeding,Conference Paper,1.0,"Hachemi, Asma",55445510300,Université des Sciences et de la Technologie Houari Boumediene,Algeria,"software developement process modeling with patterns allows to benefit from the advantages of these latter. indeed, this modeling allows to benefit from the proved and reusable knowledge offered by patterns, which improves the quality of the models produced and reduces the modeling time and effort. in this article, we discuss the main modeling practices of software developement processes with patterns. we focuse on the advantages and difficulties of these practices.",software development process modeling with patterns
456,2-s2.0-85100499814,10.1109/CSIT49958.2020.9321965,Application Algorithms of Nonlinear Dimensionality Reduction to Material Database Visualization,Vodka O.,International Scientific and Technical Conference on Computer Sciences and Information Technologies,2020-09-23,"In our world there is a huge quantity of different materials, alloys, compositions, substances. They have different mechanical properties, chemical compositions, different colors, smells, and, most importantly, applications in human life, etc. Because of so many properties of various compounds, it poses the problem of storing information about them and also creates a space for their visualization in different ways.This work deals with the creation of an online application and database that makes it possible to use information about metals, their alloys, and the search for the closest analogs. The web application gives the user a wide selection of devices to use and also uninstalls additional software products. During development, we used the general-purpose programming language Python with Flask library and web technologies HTML, CSS, and JavaScript. For the correct search for similar materials, a reasonable search is developed and implemented in an online application. The database is created based on SQL technologies the database management system - MySQL. To obtain information about metals on the Internet, a parser program is developed that selectively received data from open sources and recorded them in the created database.Humans can effectively use visual information in a maximum of three projections. Therefore, the task of reducing the dimension of information, and its visualization is one of the main directions when working with multidimensional data. The solution to this problem allows the researcher to correctly build assumptions and manipulate data in the course of reasoning or evidence.The task of the correct visualization of multidimensional data on the plane and three-dimensional space is solved by several well-known algorithms, namely: Isomap, t-SNE, MDS. As a result of the visualization of all the collected information about metals, clusters of materials is identified that correspond to the already known classes of metals. The study confirmed the correctness of the algorithms for reducing the dimension, the correctness of the information collected, the usability of the web application.",intelligent search | isomap | manifold learning | MDS | metals | multidimensional data sets | T-SNE | web application,1,100-104,Conference Proceeding,Conference Paper,3.0,"Vodka, Oleksii;Zadorozhniy, Ivan;Lavshhenko, Ruslan",56239259600;57221875373;57221873814,National Technical University Kharkiv Polytechnic Institute,Ukraine,"in our world there is a huge quantity of different materials, alloys, compositions, substances. they have different mechanical properties, chemical compositions, different colors, smells, and, most importantly, applications in human life, etc. because of so many properties of various compounds, it poses the problem of storing information about them and also creates a space for their visualization in different ways.this work deals with the creation of an online application and database that makes it possible to use information about metals, their alloys, and the search for the closest analogs. the web application gives the user a wide selection of devices to use and also uninstalls additional software products. during development, we used the general-purpose programming language python with flask library and web technologies html, css, and javascript. for the correct search for similar materials, a reasonable search is developed and implemented in an online application. the database is created based on sql technologies the database management system - mysql. to obtain information about metals on the internet, a parser program is developed that selectively received data from open sources and recorded them in the created database.humans can effectively use visual information in a maximum of three projections. therefore, the task of reducing the dimension of information, and its visualization is one of the main directions when working with multidimensional data. the solution to this problem allows the researcher to correctly build assumptions and manipulate data in the course of reasoning or evidence.the task of the correct visualization of multidimensional data on the plane and three-dimensional space is solved by several well-known algorithms, namely: isomap, t-sne, mds. as a result of the visualization of all the collected information about metals, clusters of materials is identified that correspond to the already known classes of metals. the study confirmed the correctness of the algorithms for reducing the dimension, the correctness of the information collected, the usability of the web application.",application algorithms of nonlinear dimensionality reduction to material database visualization
457,2-s2.0-85097933612,10.13052/jwe1540-9589.19561,GitHubNet: Understanding the characteristics of GitHub network,Kabakus A.T.,Journal of Web Engineering,2020-09-22,"Web 2.0 technologies have not only raised microblogs, but also social software development and collaboration platforms. GitHub is the most popular software development platform that provides social collaboration. Within the scope of this study, a novel graph-based analysis model is proposed which targets to reveal (1) the characteristics of the GitHub in order to shed light on social software development in general, and (2) the most popular programming languages, repositories, and developers in order to shed light on the trending software development technologies. To this end, a subset of the GitHub network, which contains 84, 737 developers and 209, 100 repositories, was collected through the GitHub API and stored on a graph database namely neo4j to be later analyzed. The result of the analysis shows that (1) the connections in GitHub are not mutually linked, (2) JavaScript, Python, and Java are currently the most popular three programming languages, (3) You-Dont-Know-JS, oh-my-zsh, and public-apis are the most popular three repositories, and (4) TarrySingh (Tarry Singh), indrajithbandara (Indrajith Bandara), and rootsongjc (Jimmy Song) are the most popular three developers. Furthermore, the proposed novel analysis model can be easily applied to other social networks.",GitHub | Graph database | Link analysis | Social coding | Social network analysis,0,557-574,Journal,Article,1.0,"Kabakus, Abdullah Talha",56539908500,Düzce Üniversitesi,Turkey,"web 2.0 technologies have not only raised microblogs, but also social software development and collaboration platforms. github is the most popular software development platform that provides social collaboration. within the scope of this study, a novel graph-based analysis model is proposed which targets to reveal (1) the characteristics of the github in order to shed light on social software development in general, and (2) the most popular programming languages, repositories, and developers in order to shed light on the trending software development technologies. to this end, a subset of the github network, which contains 84, 737 developers and 209, 100 repositories, was collected through the github api and stored on a graph database namely neo4j to be later analyzed. the result of the analysis shows that (1) the connections in github are not mutually linked, (2) javascript, python, and java are currently the most popular three programming languages, (3) you-dont-know-js, oh-my-zsh, and public-apis are the most popular three repositories, and (4) tarrysingh (tarry singh), indrajithbandara (indrajith bandara), and rootsongjc (jimmy song) are the most popular three developers. furthermore, the proposed novel analysis model can be easily applied to other social networks.",githubnet: understanding the characteristics of github network
459,2-s2.0-85099478745,10.1109/VISSOFT51673.2020.00011,REM: Visualizing the Ripple Effect on Dependencies Using Metrics of Health,Chen Z.,"Proceedings - 8th IEEE Working Conference on Software Visualization, VISSOFT 2020",2020-09-01,"In recent years, free and open source software (FOSS) components have become common dependencies in the development of software, both open source and proprietary. As the complexity of software increases, so does the number of components they depend upon; in addition, components are also depending on other components. Thus, their dependency graphs are growing in size and complexity. One of the current challenges in software development is that it is not trivial to know the full dependency graph of an application. Developers are usually aware of the direct dependencies their application requires, but might not be fully aware of the dependencies that those dependencies require (the transitive dependencies). Unfortunately, transitive dependencies can break any software application; therefore, project developers need tools, methods and visualizations to inspect the health of these transitive dependencies and their potential impact.In this work, we propose the Ripple Effect of Metrics (REM) dependency graphs, a visualization of dependency graphs that leverages metrics of the health of dependencies. The two main features of REM dependency graph are: first, to display, and potentially summarize, the full dependency graph of an application based on the health of each of its dependencies; and second, to evaluate the ripple effect of potentially risky dependencies on the rest of the dependency graph. The REM helps application developers inspect the health of all of its dependencies, and also the impact that some of these dependencies might have. By showcasing two examples of popular NPM JavaScript application, we demonstrate that the combination of the ripple effect on the dependency graph using health metrics activity can be beneficial to developers. The advantages of REM graphs are: 1) the metric of health annotation is useful for evaluating the health of dependencies, and 2) the ripple effect of a vulnerability provides an easy method to identify potential risk in a dependency chain and 3) the summarizing mechanisms of the REM help reduce the size and complexity of the large dependency graphs, while focusing in specific aspects of the health of the dependency graph.",Dependency graph | Health | Metrics | Software components,0,61-71,Conference Proceeding,Conference Paper,2.0,"Chen, Zhe;German, Daniel M.",57221559005;57207886015,University of Victoria,Canada,"in recent years, free and open source software (foss) components have become common dependencies in the development of software, both open source and proprietary. as the complexity of software increases, so does the number of components they depend upon; in addition, components are also depending on other components. thus, their dependency graphs are growing in size and complexity. one of the current challenges in software development is that it is not trivial to know the full dependency graph of an application. developers are usually aware of the direct dependencies their application requires, but might not be fully aware of the dependencies that those dependencies require (the transitive dependencies). unfortunately, transitive dependencies can break any software application; therefore, project developers need tools, methods and visualizations to inspect the health of these transitive dependencies and their potential impact.in this work, we propose the ripple effect of metrics (rem) dependency graphs, a visualization of dependency graphs that leverages metrics of the health of dependencies. the two main features of rem dependency graph are: first, to display, and potentially summarize, the full dependency graph of an application based on the health of each of its dependencies; and second, to evaluate the ripple effect of potentially risky dependencies on the rest of the dependency graph. the rem helps application developers inspect the health of all of its dependencies, and also the impact that some of these dependencies might have. by showcasing two examples of popular npm javascript application, we demonstrate that the combination of the ripple effect on the dependency graph using health metrics activity can be beneficial to developers. the advantages of rem graphs are: 1) the metric of health annotation is useful for evaluating the health of dependencies, and 2) the ripple effect of a vulnerability provides an easy method to identify potential risk in a dependency chain and 3) the summarizing mechanisms of the rem help reduce the size and complexity of the large dependency graphs, while focusing in specific aspects of the health of the dependency graph.",rem: visualizing the ripple effect on dependencies using metrics of health
461,2-s2.0-85099203766,10.1145/3324884.3416591,Multi-task Learning based Pre-trained Language Model for Code Completion,Liu F.,"Proceedings - 2020 35th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020",2020-09-01,"Code completion is one of the most useful features in the Integrated Development Environments (IDEs), which can accelerate software development by suggesting the next probable token based on the contextual code in real-time. Recent studies have shown that statistical language modeling techniques can improve the performance of code completion tools through learning from large-scale software repositories. However, these models suffer from two major drawbacks: a) Existing research uses static embeddings, which map a word to the same vector regardless of its context. The differences in the meaning of a token in varying contexts are lost when each token is associated with a single representation; b) Existing language model based code completion models perform poor on completing identifiers, and the type information of the identifiers is ignored in most of these models. To address these challenges, in this paper, we develop a multi-task learning based pre-trained language model for code understanding and code generation with a Transformer-based neural architecture. We pre-train it with hybrid objective functions that incorporate both code understanding and code generation tasks. Then we fine-tune the pre-trained model on code completion. During the completion, our model does not directly predict the next token. Instead, we adopt multi-task learning to predict the token and its type jointly and utilize the predicted type to assist the token prediction. Experiments results on two real-world datasets demonstrate the effectiveness of our model when compared with state-of-the-art methods.",code completion | multi-task learning | pre-trained language model | transformer networks,18,473-485,Conference Proceeding,Conference Paper,4.0,"Liu, Fang;Li, Ge;Zhao, Yunfei;Jin, Zhi",57206686247;55901136600;57221469601;8961795500,Peking University,China,"code completion is one of the most useful features in the integrated development environments (ides), which can accelerate software development by suggesting the next probable token based on the contextual code in real-time. recent studies have shown that statistical language modeling techniques can improve the performance of code completion tools through learning from large-scale software repositories. however, these models suffer from two major drawbacks: a) existing research uses static embeddings, which map a word to the same vector regardless of its context. the differences in the meaning of a token in varying contexts are lost when each token is associated with a single representation; b) existing language model based code completion models perform poor on completing identifiers, and the type information of the identifiers is ignored in most of these models. to address these challenges, in this paper, we develop a multi-task learning based pre-trained language model for code understanding and code generation with a transformer-based neural architecture. we pre-train it with hybrid objective functions that incorporate both code understanding and code generation tasks. then we fine-tune the pre-trained model on code completion. during the completion, our model does not directly predict the next token. instead, we adopt multi-task learning to predict the token and its type jointly and utilize the predicted type to assist the token prediction. experiments results on two real-world datasets demonstrate the effectiveness of our model when compared with state-of-the-art methods.",multi-task learning based pre-trained language model for code completion
462,2-s2.0-85097642280,10.1109/SCAM51674.2020.00027,Fix that Fix Commit: A real-world remediation analysis of JavaScript projects,Bandara V.,"Proceedings - 20th IEEE International Working Conference on Source Code Analysis and Manipulation, SCAM 2020",2020-09-01,"While there is a large body of work on understanding vulnerabilities in the wild, little has been done to understand the dynamics of the remediation phase of the development cycle. To this end, we have done a timeline analysis on 118K commits from 53 of the most used JavaScript projects from GitHub to understand the provenance and prevalence of vulnerabilities in those projects. We used a vulnerability detector (CodeQL) to filter commits that introduced vulnerabilities and the commits that fixed a prior vulnerability. We found that in 82% of the projects, a commit fixing a prior vulnerability, in turn, introduced one or more new vulnerabilities. Among those projects, on average, 18% of the commits intended to fix vulnerabilities, in turn, introduced one or more new vulnerabilities. We also found that 50% of the total vulnerabilities found in those projects originated from a commit meant to fix a prior vulnerability, and 78% of those vulnerabilities could have been avoided if they were to use proper internal testing. We provide critical insights into how proper internal testing can avoid a significant portion of vulnerabilities, increasing organizations' security posture.",Security Testing | Software Security | Vulnerability Analysis | Vulnerability Remediation,5,198-202,Conference Proceeding,Conference Paper,7.0,"Bandara, Vinuri;Rathnayake, Thisura;Weerasekara, Nipuna;Elvitigala, Charitha;Thilakarathna, Kenneth;Wijesekera, Primal;Keppitiyagama, Chamath",57220803636;57214759230;57220807601;57199322581;36460466300;57191754476;25929269400,"University of Colombo;University of California, Berkeley;SCoRe Lab",Sri Lanka;United States;,"while there is a large body of work on understanding vulnerabilities in the wild, little has been done to understand the dynamics of the remediation phase of the development cycle. to this end, we have done a timeline analysis on 118k commits from 53 of the most used javascript projects from github to understand the provenance and prevalence of vulnerabilities in those projects. we used a vulnerability detector (codeql) to filter commits that introduced vulnerabilities and the commits that fixed a prior vulnerability. we found that in 82% of the projects, a commit fixing a prior vulnerability, in turn, introduced one or more new vulnerabilities. among those projects, on average, 18% of the commits intended to fix vulnerabilities, in turn, introduced one or more new vulnerabilities. we also found that 50% of the total vulnerabilities found in those projects originated from a commit meant to fix a prior vulnerability, and 78% of those vulnerabilities could have been avoided if they were to use proper internal testing. we provide critical insights into how proper internal testing can avoid a significant portion of vulnerabilities, increasing organizations' security posture.",fix that fix commit: a real-world remediation analysis of javascript projects
463,2-s2.0-85096725328,10.1109/ICSME46990.2020.00048,It Takes a Village to Build a Robot: An Empirical Study of the ROS Ecosystem,Kolak S.,"Proceedings - 2020 IEEE International Conference on Software Maintenance and Evolution, ICSME 2020",2020-09-01,"Over the past eleven years, the Robot Operating System (ROS), has grown from a small research project into the most popular framework for robotics development. Composed of packages released on the Rosdistro package manager, ROS aims to simplify development by providing reusable libraries, tools and conventions for building a robot. Still, developing a complete robot is a difficult task that involves bridging many technical disciplines. Experts who create computer vision packages, for instance, may need to rely on software designed by mechanical engineers to implement motor control. As building a robot requires domain expertise in software, mechanical, and electrical engineering, as well as artificial intelligence and robotics, ROS faces knowledge based barriers to collaboration.In this paper, we examine how the necessity of domain specific knowledge impacts the open source collaboration model. We create a comprehensive corpus of package metadata and dependencies over three years in the ROS ecosystem, analyze how collaboration is structured, and study the dependency network evolution. We find that the most widely used ROS packages belong to a small cluster of foundational working groups (FWGs), each organized around a different domain in robotics. We show that the FWGs are growing at a slower rate than the rest of the ecosystem, in terms of their membership and number of packages, yet the number of dependencies on FWGs is increasing at a faster rate. In addition, we mined all ROS packages on GitHub, and showed that 82% rely exclusively on functionality provided by FWGs. Finally, we investigate these highly influential groups and describe the unique model of collaboration they support in ROS.",collaboration | robot operating system | robotics software | software ecosystem | software evolution,5,430-440,Conference Proceeding,Conference Paper,5.0,"Kolak, Sophia;Afzal, Afsoon;Le Goues, Claire;Hilton, Michael;Timperley, Christopher Steven",57220053223;57202049078;35113323900;56754178400;57195625445,Columbia University;Carnegie Mellon University,United States;United States,"over the past eleven years, the robot operating system (ros), has grown from a small research project into the most popular framework for robotics development. composed of packages released on the rosdistro package manager, ros aims to simplify development by providing reusable libraries, tools and conventions for building a robot. still, developing a complete robot is a difficult task that involves bridging many technical disciplines. experts who create computer vision packages, for instance, may need to rely on software designed by mechanical engineers to implement motor control. as building a robot requires domain expertise in software, mechanical, and electrical engineering, as well as artificial intelligence and robotics, ros faces knowledge based barriers to collaboration.in this paper, we examine how the necessity of domain specific knowledge impacts the open source collaboration model. we create a comprehensive corpus of package metadata and dependencies over three years in the ros ecosystem, analyze how collaboration is structured, and study the dependency network evolution. we find that the most widely used ros packages belong to a small cluster of foundational working groups (fwgs), each organized around a different domain in robotics. we show that the fwgs are growing at a slower rate than the rest of the ecosystem, in terms of their membership and number of packages, yet the number of dependencies on fwgs is increasing at a faster rate. in addition, we mined all ros packages on github, and showed that 82% rely exclusively on functionality provided by fwgs. finally, we investigate these highly influential groups and describe the unique model of collaboration they support in ros.",it takes a village to build a robot: an empirical study of the ros ecosystem
464,2-s2.0-85096706630,10.1109/ICSME46990.2020.00081,EWIDL: Single-Source Web API Documentation Management System,Michalski M.,"Proceedings - 2020 IEEE International Conference on Software Maintenance and Evolution, ICSME 2020",2020-09-01,"This paper is an overview of the EWIDL documentation management system for Web APIs. We designed EWIDL based on our experience with the development of Tizen Web API. Over the eight years of our work, two requirements have proven to be the most important for successful documentation management.Firstly, the documentation should be machine-readable to support automatic validation tools development. EWIDL achieves this by combining Doxygen documentation comments' format with Web IDL language.Secondly, the system should support the maintenance of multiple variants of documentation. Tizen Web API behavior varies between different target devices, depending on the software version and hardware profile (mobile, wearable, and TV). Managing documentation for all configurations simultaneously is a challenging task with ever-increasing complexity as new versions are released. We chose a single-sourcing approach by including conditional configuration preprocessor syntax in EWIDL documents.",documentation | javascript | single-source | webapi | webidl,1,723-726,Conference Proceeding,Conference Paper,4.0,"Michalski, Michal;Kosko, Piotr;Juszczak, Dawid;Kwon, Hobum",57220054401;57205019829;57220062615;57205030102,Samsung Electronics Co. Ltd.;Samsung Rd Institute,South Korea;Poland,"this paper is an overview of the ewidl documentation management system for web apis. we designed ewidl based on our experience with the development of tizen web api. over the eight years of our work, two requirements have proven to be the most important for successful documentation management.firstly, the documentation should be machine-readable to support automatic validation tools development. ewidl achieves this by combining doxygen documentation comments' format with web idl language.secondly, the system should support the maintenance of multiple variants of documentation. tizen web api behavior varies between different target devices, depending on the software version and hardware profile (mobile, wearable, and tv). managing documentation for all configurations simultaneously is a challenging task with ever-increasing complexity as new versions are released. we chose a single-sourcing approach by including conditional configuration preprocessor syntax in ewidl documents.",ewidl: single-source web api documentation management system
465,2-s2.0-85096693644,10.1109/ICSME46990.2020.00103,Kaya: A Testing Framework for Blockchain-based Decentralized Applications,Wu Z.,"Proceedings - 2020 IEEE International Conference on Software Maintenance and Evolution, ICSME 2020",2020-09-01,"In recent years, many decentralized applications based on blockchain (DApp) have been developed. Some development tools provide testing functions, but only for developers to write unit tests for smart contracts rather than test DApp as a whole. Moreover, due to the difficulty for testers to understand the implementation details of smart contracts, insufficient functional testing causes some DApps not to meet functional design expectations. The inherent complexity of DApp, inconvenient pre-state setting, and not-so-readable logs make DApp testing challenging. In this paper, we propose Kaya, a testing framework for DApps to bridge these gaps. Firstly, Kaya formulate automatically executed test cases that cover both front-end behaviors and back-end logics with simple setting. Secondly, Kaya provides a flexible and convenient way for test engineers to set the blockchain pre-states. Thirdly, Kaya transforms incomprehensible addresses into readable variables for easier comprehension. Besides, to fit the various application environments, we provide both GUI and CLI for test engineers to use Kaya. Our case study and preliminary human study demonstrates the potential of Kaya in helping test engineers to test DApps more easily. A demo video is at https://youtu.be/7DyI_EpVZFw.",Blockchain | Decentralized Application | Smart Contract | Testing Framework,1,826-829,Conference Proceeding,Conference Paper,7.0,"Wu, Zhenhao;Zhang, Jiashuo;Gao, Jianbo;Li, Yue;Li, Qingshan;Guan, Zhi;Chen, Zhong",57214780879;57216621434;57210920909;57210916944;57191695918;7202541991;57168976900,Peking University;Ministry of Education China,China;China,"in recent years, many decentralized applications based on blockchain (dapp) have been developed. some development tools provide testing functions, but only for developers to write unit tests for smart contracts rather than test dapp as a whole. moreover, due to the difficulty for testers to understand the implementation details of smart contracts, insufficient functional testing causes some dapps not to meet functional design expectations. the inherent complexity of dapp, inconvenient pre-state setting, and not-so-readable logs make dapp testing challenging. in this paper, we propose kaya, a testing framework for dapps to bridge these gaps. firstly, kaya formulate automatically executed test cases that cover both front-end behaviors and back-end logics with simple setting. secondly, kaya provides a flexible and convenient way for test engineers to set the blockchain pre-states. thirdly, kaya transforms incomprehensible addresses into readable variables for easier comprehension. besides, to fit the various application environments, we provide both gui and cli for test engineers to use kaya. our case study and preliminary human study demonstrates the potential of kaya in helping test engineers to test dapps more easily. a demo video is at https://youtu.be/7dyi_epvzfw.",kaya: a testing framework for blockchain-based decentralized applications
466,2-s2.0-85096685095,10.1109/ICSME46990.2020.00071,Investigating the Reproducibility of NPM Packages,Goswami P.,"Proceedings - 2020 IEEE International Conference on Software Maintenance and Evolution, ICSME 2020",2020-09-01,"Node.js has been popularly used for web application development, partially because of its large software ecosystem known as NPM (Node Package Manager) packages. When using open-source NPM packages, most developers download prebuilt packages on npmjs.com instead of building those packages from available source, and implicitly trust the downloaded packages. However, it is unknown whether the blindly trusted prebuilt NPM packages are reproducible (i.e., whether there is always a verifiable path from source code to any published NPM package). Therefore, for this paper, we conducted an empirical study to examine the reproducibility of NPM packages, and to understand why some packages are not reproducible.Specifically, we downloaded versions/releases of 226 most popularly used NPM packages and then built each version with the available source on GitHub. Next, we applied a differencing tool to compare the versions we built against versions downloaded from NPM, and further inspected any reported difference. Among the 3,390 versions of the 226 packages, only 2,087 versions are reproducible. Based on our manual analysis, multiple factors contribute to the non-reproducibility issues, such as flexible versioning information in package.json file and the divergent behaviors between distinct versions of tools used in the build process. Our investigation reveals challenges of verifying NPM reproducibility with existing tools, and provides insights for future verifiable build procedures.",JavaScript | NPM packages | reproducibility,5,677-681,Conference Proceeding,Conference Paper,5.0,"Goswami, Pronnoy;Gupta, Saksham;Li, Zhiyuan;Meng, Na;Yao, Daphne",57211989953;57217374192;57220050690;42161811400;57219479155,Virginia Polytechnic Institute and State University,United States,"node.js has been popularly used for web application development, partially because of its large software ecosystem known as npm (node package manager) packages. when using open-source npm packages, most developers download prebuilt packages on npmjs.com instead of building those packages from available source, and implicitly trust the downloaded packages. however, it is unknown whether the blindly trusted prebuilt npm packages are reproducible (i.e., whether there is always a verifiable path from source code to any published npm package). therefore, for this paper, we conducted an empirical study to examine the reproducibility of npm packages, and to understand why some packages are not reproducible.specifically, we downloaded versions/releases of 226 most popularly used npm packages and then built each version with the available source on github. next, we applied a differencing tool to compare the versions we built against versions downloaded from npm, and further inspected any reported difference. among the 3,390 versions of the 226 packages, only 2,087 versions are reproducible. based on our manual analysis, multiple factors contribute to the non-reproducibility issues, such as flexible versioning information in package.json file and the divergent behaviors between distinct versions of tools used in the build process. our investigation reveals challenges of verifying npm reproducibility with existing tools, and provides insights for future verifiable build procedures.",investigating the reproducibility of npm packages
467,2-s2.0-85096672772,10.1109/ICSME46990.2020.00014,"An Empirical Study of Usages, Updates and Risks of Third-Party Libraries in Java Projects",Wang Y.,"Proceedings - 2020 IEEE International Conference on Software Maintenance and Evolution, ICSME 2020",2020-09-01,"Third-party libraries play a key role in software development as they can relieve developers of the heavy burden of re-implementing common functionalities. However, third-party libraries and client projects evolve asynchronously. As a result, out-dated third-party libraries might be used in client projects while developers are not aware of the potential risk (e.g., security bug). Outdated third-party libraries may be updated in client projects in a delayed way, and developers may be less aware of the potential risk (e.g., API incompatibility) in updates. Developers of third-party libraries may be unaware of how their third-party libraries are used or updated in client projects. Therefore, a quantitative and holistic study on usages, updates and risks of third-party libraries in open-source projects can provide concrete evidences on these problems, and practical insights to improve the ecosystem.In this paper, we contribute such a study in Java ecosystem. In particular, we conduct a library usage analysis (e.g., usage intensity and outdatedness) and library update analysis (e.g., update intensity and delay) on 806 open-source projects and 13,565 third-party libraries. Then, we carry out a library risk analysis (e.g., usage risk and update risk) on 806 open-source projects and 544 security bugs. These analyses aim to quantify the usage and update practices and the potential risk of using and updating outdated third-party libraries with respect to security bugs from two holistic perspectives (i.e., open-source projects and third-party libraries). Our findings suggest practical implications to developers and researchers on problems and potential solutions in maintaining third-party libraries (e.g., smart alerting and automated updating of outdated third-party libraries). To indicate the usefulness of our findings, we design a smart alerting system for assisting developers to make confident decisions when updating third-party libraries. 33 and 24 open-source projects have confirmed and updated third-party libraries after receiving our alerts.",outdated libraries | security bugs,11,35-45,Conference Proceeding,Conference Paper,8.0,"Wang, Ying;Chen, Bihuan;Huang, Kaifeng;Shi, Bowen;Xu, Congying;Peng, Xin;Wu, Yijian;Liu, Yang",57768589800;35224542900;57204639207;57219585983;57219584018;53865467700;56093266500;56911879800,School of Computer Science and Engineering;Fudan University,Singapore;China,"third-party libraries play a key role in software development as they can relieve developers of the heavy burden of re-implementing common functionalities. however, third-party libraries and client projects evolve asynchronously. as a result, out-dated third-party libraries might be used in client projects while developers are not aware of the potential risk (e.g., security bug). outdated third-party libraries may be updated in client projects in a delayed way, and developers may be less aware of the potential risk (e.g., api incompatibility) in updates. developers of third-party libraries may be unaware of how their third-party libraries are used or updated in client projects. therefore, a quantitative and holistic study on usages, updates and risks of third-party libraries in open-source projects can provide concrete evidences on these problems, and practical insights to improve the ecosystem.in this paper, we contribute such a study in java ecosystem. in particular, we conduct a library usage analysis (e.g., usage intensity and outdatedness) and library update analysis (e.g., update intensity and delay) on 806 open-source projects and 13,565 third-party libraries. then, we carry out a library risk analysis (e.g., usage risk and update risk) on 806 open-source projects and 544 security bugs. these analyses aim to quantify the usage and update practices and the potential risk of using and updating outdated third-party libraries with respect to security bugs from two holistic perspectives (i.e., open-source projects and third-party libraries). our findings suggest practical implications to developers and researchers on problems and potential solutions in maintaining third-party libraries (e.g., smart alerting and automated updating of outdated third-party libraries). to indicate the usefulness of our findings, we design a smart alerting system for assisting developers to make confident decisions when updating third-party libraries. 33 and 24 open-source projects have confirmed and updated third-party libraries after receiving our alerts.","an empirical study of usages, updates and risks of third-party libraries in java projects"
468,2-s2.0-85096658977,10.1109/ICSME46990.2020.00026,Detecting Semantic Conflicts via Automated Behavior Change Detection,Silva L.D.,"Proceedings - 2020 IEEE International Conference on Software Maintenance and Evolution, ICSME 2020",2020-09-01,"Branching and merging are common practices in collaborative software development. They increase developer productivity by fostering teamwork, allowing developers to independently contribute to a software project. Despite such benefits, branching and merging comes at a cost-the need to merge software and to resolve merge conflicts, which often occur in practice. While modern merge techniques, such as 3-way or structured merge, can resolve many such conflicts automatically, they fail when the conflict arises not at the syntactic, but the semantic level. Detecting such conflicts requires understanding the behavior of the software, which is beyond the capabilities of most existing merge tools. As such, semantic conflicts can only be identified and fixed with significant effort and knowledge of the changes to be merged. While semantic merge tools have been proposed, they are usually heavyweight, based on static analysis, and need explicit specifications of program behavior. In this work, we take a different route and explore the automated creation of unit tests as partial specifications to detect unwanted behavior changes (conflicts) when merging software.We systematically explore the detection of semantic conflicts through unit-test generation. Relying on a ground-truth dataset of 38 software merge scenarios, which we extracted from GitHub, we manually analyzed them and investigated whether semantic conflicts exist. Next, we apply test-generation tools to study their detection rates. We propose improvements (code transformations) and study their effectiveness, as well as we qualitatively analyze the detection results and propose future improvements. For example, we analyze the generated test suites for false-negative cases to understand why the conflict was not detected. Our results evidence the feasibility of using test-case generation to detect semantic conflicts as a method that is versatile and requires only limited deployment effort in practice, as well as it does not require explicit behavior specifications.",Behavior Change Detection | Differential Testing | Semantic Conflicts,5,174-184,Conference Proceeding,Conference Paper,5.0,"Silva, Leuson Da;Borba, Paulo;Mahmood, Wardah;Berger, Thorsten;Moisakis, Joao",57220050227;57226225443;57215520444;36607404500;57220049978,Universidade de Pernambuco;Chalmers University of Technology,Brazil;Sweden,"branching and merging are common practices in collaborative software development. they increase developer productivity by fostering teamwork, allowing developers to independently contribute to a software project. despite such benefits, branching and merging comes at a cost-the need to merge software and to resolve merge conflicts, which often occur in practice. while modern merge techniques, such as 3-way or structured merge, can resolve many such conflicts automatically, they fail when the conflict arises not at the syntactic, but the semantic level. detecting such conflicts requires understanding the behavior of the software, which is beyond the capabilities of most existing merge tools. as such, semantic conflicts can only be identified and fixed with significant effort and knowledge of the changes to be merged. while semantic merge tools have been proposed, they are usually heavyweight, based on static analysis, and need explicit specifications of program behavior. in this work, we take a different route and explore the automated creation of unit tests as partial specifications to detect unwanted behavior changes (conflicts) when merging software.we systematically explore the detection of semantic conflicts through unit-test generation. relying on a ground-truth dataset of 38 software merge scenarios, which we extracted from github, we manually analyzed them and investigated whether semantic conflicts exist. next, we apply test-generation tools to study their detection rates. we propose improvements (code transformations) and study their effectiveness, as well as we qualitatively analyze the detection results and propose future improvements. for example, we analyze the generated test suites for false-negative cases to understand why the conflict was not detected. our results evidence the feasibility of using test-case generation to detect semantic conflicts as a method that is versatile and requires only limited deployment effort in practice, as well as it does not require explicit behavior specifications.",detecting semantic conflicts via automated behavior change detection
469,2-s2.0-85096643405,10.1109/ICSME46990.2020.00038,Studying Software Developer Expertise and Contributions in Stack Overflow and GitHub,Vadlamani S.L.,"Proceedings - 2020 IEEE International Conference on Software Maintenance and Evolution, ICSME 2020",2020-09-01,"Knowledge and experience are touted as both the necessary and sufficient conditions to make a person an expert. This paper attempts to investigate this issue in the context of software development by studying software developer's expertise based on their activity and experience on GitHub and Stack Overflow platforms. We study how developers themselves define the notion of an ""expert"", as well as why or why not developers contribute to online collaborative platforms. We conducted an exploratory survey with 73 software developers and applied a mixed methods approach to analyze the survey results. The results provided deeper insights into how an expert in the field could be defined. Further, the study provides a better understanding of the underlying factors that drive developers to contribute to GitHub and Stack Overflow, and the challenges they face when participating on either platform.The quantitative analysis showed that JavaScript remains a popular language, while knowledge and experience are the key factors driving expertise. On the other hand, qualitative analysis showed that soft skills such as effective and clear communication, analytical thinking are key factors defining an expert. We found that both knowledge and experience are only necessary but not sufficient conditions for a developer to become an expert, and an expert would necessarily have to possess adequate soft skills. Lastly, an expert's contribution to GitHub seems to be driven by personal factors, while contribution to Stack Overflow is motivated more by professional drivers (i.e., skills and expertise). Moreover, developers seem to prefer contributing to GitHub as they face greater challenges while contributing to Stack Overflow.",developer contributions | developer perception | developer profiles | GitHub | qualitative study | Software developer expertise | Stack Overflow | survey,9,312-323,Conference Proceeding,Conference Paper,2.0,"Vadlamani, Sri Lakshmi;Baysal, Olga",57219315158;21742200600,Carleton University,Canada,"knowledge and experience are touted as both the necessary and sufficient conditions to make a person an expert. this paper attempts to investigate this issue in the context of software development by studying software developer's expertise based on their activity and experience on github and stack overflow platforms. we study how developers themselves define the notion of an ""expert"", as well as why or why not developers contribute to online collaborative platforms. we conducted an exploratory survey with 73 software developers and applied a mixed methods approach to analyze the survey results. the results provided deeper insights into how an expert in the field could be defined. further, the study provides a better understanding of the underlying factors that drive developers to contribute to github and stack overflow, and the challenges they face when participating on either platform.the quantitative analysis showed that javascript remains a popular language, while knowledge and experience are the key factors driving expertise. on the other hand, qualitative analysis showed that soft skills such as effective and clear communication, analytical thinking are key factors defining an expert. we found that both knowledge and experience are only necessary but not sufficient conditions for a developer to become an expert, and an expert would necessarily have to possess adequate soft skills. lastly, an expert's contribution to github seems to be driven by personal factors, while contribution to stack overflow is motivated more by professional drivers (i.e., skills and expertise). moreover, developers seem to prefer contributing to github as they face greater challenges while contributing to stack overflow.",studying software developer expertise and contributions in stack overflow and github
470,2-s2.0-85096352536,10.1109/SISY50555.2020.9217091,Atlas: Software System for Monitoring and Reserving Free Parking Spaces,Szabo A.K.,"SISY 2020 - IEEE 18th International Symposium on Intelligent Systems and Informatics, Proceedings",2020-09-01,"Finding available parking spaces represents a significant problem for drivers in dense urban areas. The searching process results in substantial additional costs but also contributes considerably to pollution and road congestion. The Atlas project aims to facilitate the process of searching for parking spots.The software system uses data from existing surveillance cameras to list both designated and unassigned parking spaces while tracking the number of drivers navigating to a given spot, therefore it does not require expensive infrastructure. The main parts of the system are the central server, the mobile application and the computer vision module. The latter is responsible for the processing of images taken by urban surveillance cameras.The paper presents the structure of the project, the details of the implementation, the tools and technologies used during the development process, and demonstrates the usage of the software.",mobile application | parking space | parking space detection | parking spot | surveillance camera,0,71-76,Conference Proceeding,Conference Paper,5.0,"Szabo, Agnes Kriszta;Raduly, Zalan;Patakfalvi, Ors Krisztian;Sulyok, Csaba;Simon, Karoly",57219973744;57204932097;57204930763;57204935707;21743816200,Universitatea Babeș-Bolyai;Codespring,Romania;Romania,"finding available parking spaces represents a significant problem for drivers in dense urban areas. the searching process results in substantial additional costs but also contributes considerably to pollution and road congestion. the atlas project aims to facilitate the process of searching for parking spots.the software system uses data from existing surveillance cameras to list both designated and unassigned parking spaces while tracking the number of drivers navigating to a given spot, therefore it does not require expensive infrastructure. the main parts of the system are the central server, the mobile application and the computer vision module. the latter is responsible for the processing of images taken by urban surveillance cameras.the paper presents the structure of the project, the details of the implementation, the tools and technologies used during the development process, and demonstrates the usage of the software.",atlas: software system for monitoring and reserving free parking spaces
473,2-s2.0-85087387332,10.1007/s10664-020-09830-x,"Detection, assessment and mitigation of vulnerabilities in open source dependencies",Ponta S.E.,Empirical Software Engineering,2020-09-01,"Open source software (OSS) libraries are widely used in the industry to speed up the development of software products. However, these libraries are subject to an ever-increasing number of vulnerabilities that are publicly disclosed. It is thus crucial for application developers to detect dependencies on vulnerable libraries in a timely manner, to precisely assess their impact, and to mitigate any potential risk. This paper presents a novel method to detect, assess and mitigate OSS vulnerabilities. Differently from state-of-the-art approaches that depend on metadata to identify vulnerable OSS dependencies, our solution is code-centric, and combines static and dynamic analyses to determine the reachability of the vulnerable portion of libraries, in the context of a given application. Our approach also supports developers in choosing among the existing non-vulnerable library versions, with the goal to determine and minimize incompatibilities. Eclipse Steady, the open source implementation of our code-centric and usage-based approach is the tool recommended to scan Java software products at SAP; it has been successfully used to perform more than one million scans of about 1500 applications. In this paper we report on the lessons learned when maturing the tool from a research prototype to an industrial-grade solution. To evaluate Eclipse Steady, we conducted an empirical study to compare its detection capabilities with those of OWASP Dependency Check (OWASP DC), scanning 300 large enterprise applications under development with a total of 78165 dependencies. Reviewing a sample of the findings reported only by one of the two tools revealed that all Steady findings are true positives, while 88.8% of the findings of OWASP DC for vulnerabilities covered by our code-centric approach are false positives. For vulnerabilities not caused by code but due, e.g., to erroneous configuration, 63.3% of OWASP DC findings are true positives.",Code-centric vulnerability analysis | Combination of static and dynamic analysis | Open source software | Publicly known vulnerabilities | Usage-based update support,14,3175-3215,Journal,Article,3.0,"Ponta, Serena Elisa;Plate, Henrik;Sabetta, Antonino",35111618100;24476873000;9039083700,SAP Security Research,France,"open source software (oss) libraries are widely used in the industry to speed up the development of software products. however, these libraries are subject to an ever-increasing number of vulnerabilities that are publicly disclosed. it is thus crucial for application developers to detect dependencies on vulnerable libraries in a timely manner, to precisely assess their impact, and to mitigate any potential risk. this paper presents a novel method to detect, assess and mitigate oss vulnerabilities. differently from state-of-the-art approaches that depend on metadata to identify vulnerable oss dependencies, our solution is code-centric, and combines static and dynamic analyses to determine the reachability of the vulnerable portion of libraries, in the context of a given application. our approach also supports developers in choosing among the existing non-vulnerable library versions, with the goal to determine and minimize incompatibilities. eclipse steady, the open source implementation of our code-centric and usage-based approach is the tool recommended to scan java software products at sap; it has been successfully used to perform more than one million scans of about 1500 applications. in this paper we report on the lessons learned when maturing the tool from a research prototype to an industrial-grade solution. to evaluate eclipse steady, we conducted an empirical study to compare its detection capabilities with those of owasp dependency check (owasp dc), scanning 300 large enterprise applications under development with a total of 78165 dependencies. reviewing a sample of the findings reported only by one of the two tools revealed that all steady findings are true positives, while 88.8% of the findings of owasp dc for vulnerabilities covered by our code-centric approach are false positives. for vulnerabilities not caused by code but due, e.g., to erroneous configuration, 63.3% of owasp dc findings are true positives.","detection, assessment and mitigation of vulnerabilities in open source dependencies"
475,2-s2.0-85083183765,10.1016/j.future.2020.04.010,Preserving instance state during refactorings in live environments,Tesone P.,Future Generation Computer Systems,2020-09-01,"An important activity of software evolution consists in applying refactorings to enhance the quality of the code without changing its behaviour. Having a proper refactoring tool is a must-to in any professional development environment. In addition, live programming allows faster development than the usual edit-compile-debug process. During live programming sessions, the developer can directly manipulate instances and modify the state of the running program. However, when a complex refactoring is performed, instances may be corrupted (i.e., their state is lost). For example, when pushing an instance variable to a superclass there is a moment where the superclass does not have yet acquired the new instance variable and the subclass does not have it any more. It means that the value assigned to this instance variable in existing instances is lost after the refactoring. This problem is not anecdotal since 36% of the refactorings described in Fowler's catalogue corrupt instances when used in a live programming context. There is a need to manually migrate, regenerate or reload instances from persistent sources. This manual fix lowers the usefulness of live programming. In this context of live programming, we propose, AtomicRefactoring, a new solution based on Dynamic Software Update to preserve the state of the application after performing refactorings. We provide a working extension to the existing refactoring tool developed for the language Pharo (a new offspring inheriting from Smalltalk), allowing application developers to perform complex refactorings preserving the live state of the running program.",Automatic refactorings | Dynamic software update | IDE | Live programming environments,0,1-17,Journal,Article,5.0,"Tesone, Pablo;Polito, Guillermo;Fabresse, Luc;Bouraqadi, Noury;Ducasse, Stéphane",57201112746;55208810700;23093350300;55932557000;6701521591,IMT Nord Europe;Université de Lille;INRIA Institut National de Recherche en Informatique et en Automatique,France;France;France,"an important activity of software evolution consists in applying refactorings to enhance the quality of the code without changing its behaviour. having a proper refactoring tool is a must-to in any professional development environment. in addition, live programming allows faster development than the usual edit-compile-debug process. during live programming sessions, the developer can directly manipulate instances and modify the state of the running program. however, when a complex refactoring is performed, instances may be corrupted (i.e., their state is lost). for example, when pushing an instance variable to a superclass there is a moment where the superclass does not have yet acquired the new instance variable and the subclass does not have it any more. it means that the value assigned to this instance variable in existing instances is lost after the refactoring. this problem is not anecdotal since 36% of the refactorings described in fowler's catalogue corrupt instances when used in a live programming context. there is a need to manually migrate, regenerate or reload instances from persistent sources. this manual fix lowers the usefulness of live programming. in this context of live programming, we propose, atomicrefactoring, a new solution based on dynamic software update to preserve the state of the application after performing refactorings. we provide a working extension to the existing refactoring tool developed for the language pharo (a new offspring inheriting from smalltalk), allowing application developers to perform complex refactorings preserving the live state of the running program.",preserving instance state during refactorings in live environments
476,2-s2.0-85074460871,10.1016/j.future.2019.10.006,Implementation-independent function reuse,De Meester B.,Future Generation Computer Systems,2020-09-01,"Functions are essential building blocks of information retrieval and information management. However, efforts implementing these functions are fragmented: one function has multiple implementations, within specific development contexts. This inhibits reuse: metadata of functions and associated implementations need to be found across various search interfaces, and implementation integration requires human interpretation and manual adjustments. An approach is needed, independent of development context and enabling description and exploration of functions and (automatic) instantiation of associated implementations. In this paper, after collecting scenarios and deriving corresponding requirements, we (i) propose an approach that facilitates functions’ description, publication, and exploration by modeling and publishing abstract function descriptions and their links to concrete implementations; and (ii) enable implementations’ automatic instantiation by exploiting those published descriptions. This way, we can link to existing implementations, and provide a uniform detailed search interface across development contexts. The proposed model (the Function Ontology) and the publication method following the Linked Data principles using standards, are deemed sufficient for this task, and are extensible to new development contexts. The proposed set of tools (the Function Hub and Function Handler) are shown to fulfill the collected requirements, and the user evaluation proves them being perceived as a valuable asset during software retrieval. Our work thus improves developer experience for function exploration and implementation instantiation.",Function | Linked data | Reuse,9,946-959,Journal,Article,4.0,"De Meester, Ben;Seymoens, Tom;Dimou, Anastasia;Verborgh, Ruben",56244774300;57201211468;55236344100;36716974600,Universiteit Gent;Vrije Universiteit Brussel,Belgium;Belgium,"functions are essential building blocks of information retrieval and information management. however, efforts implementing these functions are fragmented: one function has multiple implementations, within specific development contexts. this inhibits reuse: metadata of functions and associated implementations need to be found across various search interfaces, and implementation integration requires human interpretation and manual adjustments. an approach is needed, independent of development context and enabling description and exploration of functions and (automatic) instantiation of associated implementations. in this paper, after collecting scenarios and deriving corresponding requirements, we (i) propose an approach that facilitates functions’ description, publication, and exploration by modeling and publishing abstract function descriptions and their links to concrete implementations; and (ii) enable implementations’ automatic instantiation by exploiting those published descriptions. this way, we can link to existing implementations, and provide a uniform detailed search interface across development contexts. the proposed model (the function ontology) and the publication method following the linked data principles using standards, are deemed sufficient for this task, and are extensible to new development contexts. the proposed set of tools (the function hub and function handler) are shown to fulfill the collected requirements, and the user evaluation proves them being perceived as a valuable asset during software retrieval. our work thus improves developer experience for function exploration and implementation instantiation.",implementation-independent function reuse
477,2-s2.0-85110354526,10.4271/11-02-02-0011,Using a Dual-Layer Specification to Offer Selective Interoperability for Uptane,Moore M.,SAE International Journal of Transportation Cybersecurity and Privacy,2020-08-24,"This work introduces the concept of a dual-layer specification structure for standards that separates interoperability functions, such as backward compatibility, localization, and deployment, from those essential to reliability, security, and functionality. The latter group of features, which constitute the actual standard, make up the baseline layer for instructions, while all the elements required for interoperability are specified in a second layer, known as a Protocols, Operations, Usage, and Formats (POUF) document. We applied this technique in the development of a standard for Uptane [1], a security framework for over-the-air (OTA) software updates used in many automobiles. This standard is a good candidate for a dual-layer specification because it requires communication between entities, but does not require a specific format for this communication. By deferring wire protocols and other implementation details to POUFs, the creators of the Uptane Standard were able to focus on the basic procedures and operations needed to secure automotive updates. We demonstrate the effectiveness of this format by specifying a POUF for the Uptane Reference Implementation [2].","OTA | OTA updates | Standardization, Interoperability, Security | Updates",0,113-129,Journal,Article,6.0,"Moore, Marina;McDonald, Ira;Weimerskirch, Andre;Awwad, Sebastien;Delong, Lois Anne;Cappos, Justin",57226058817;57226069536;22434307400;57226076537;57195995263;13006019000,Lear Corporation;New York University;High North Inc.,United States;United States;,"this work introduces the concept of a dual-layer specification structure for standards that separates interoperability functions, such as backward compatibility, localization, and deployment, from those essential to reliability, security, and functionality. the latter group of features, which constitute the actual standard, make up the baseline layer for instructions, while all the elements required for interoperability are specified in a second layer, known as a protocols, operations, usage, and formats (pouf) document. we applied this technique in the development of a standard for uptane [1], a security framework for over-the-air (ota) software updates used in many automobiles. this standard is a good candidate for a dual-layer specification because it requires communication between entities, but does not require a specific format for this communication. by deferring wire protocols and other implementation details to poufs, the creators of the uptane standard were able to focus on the basic procedures and operations needed to secure automotive updates. we demonstrate the effectiveness of this format by specifying a pouf for the uptane reference implementation [2].",using a dual-layer specification to offer selective interoperability for uptane
478,2-s2.0-85096971848,10.1109/iCCECE49321.2020.9231154,Valent-Blocks: Scalable High-Performance Compilation of WebAssembly Bytecode for Embedded Systems,Scheidl F.,"Proceedings - 2020 International Conference on Computing, Electronics and Communications Engineering, iCCECE 2020",2020-08-17,"In the field of emerging software architectures, there has been a dramatic push towards flexible and sand-boxed software modules that allow systems to safely execute untrusted code in a guaranteed side-effect free manner. Latest developments have further given rise to portable and statically validatable representations of software in a bytecode format like WebAssembly. In order to ease the segue into the domain of embedded systems, this paper explores the feasibility of a novel and easily retargetable streaming quasi-singlepass on-target-compiler topology with concurrent bytecode validation. For this, a generalized compile-time virtual stack is employed which is logically partitioned into separately emittable blocks (named valent-blocks). This forms the foundation of a corresponding runtime for resource constrained systems that demonstrate the need for predictable, resource-efficient and fast sandboxed execution of hot-loaded software. This paper further benchmarks the resultant performance against current popular competing standalone WebAssembly runtimes.",embedded | energy consumption | fault isolation | internet of things | memory | performance | resource constrained | retargetable compiler | runtime | safety | sandbox | sensor nodes | virtual machine | webassembly,1,119-124,Conference Proceeding,Conference Paper,1.0,"Scheidl, Fabian",57220122150,Bavarian Motor Works Group,Germany,"in the field of emerging software architectures, there has been a dramatic push towards flexible and sand-boxed software modules that allow systems to safely execute untrusted code in a guaranteed side-effect free manner. latest developments have further given rise to portable and statically validatable representations of software in a bytecode format like webassembly. in order to ease the segue into the domain of embedded systems, this paper explores the feasibility of a novel and easily retargetable streaming quasi-singlepass on-target-compiler topology with concurrent bytecode validation. for this, a generalized compile-time virtual stack is employed which is logically partitioned into separately emittable blocks (named valent-blocks). this forms the foundation of a corresponding runtime for resource constrained systems that demonstrate the need for predictable, resource-efficient and fast sandboxed execution of hot-loaded software. this paper further benchmarks the resultant performance against current popular competing standalone webassembly runtimes.",valent-blocks: scalable high-performance compilation of webassembly bytecode for embedded systems
480,2-s2.0-85087052769,10.11591/ijeecs.v19.i3.pp828-836,Implementation of an efficient web-based movie ticket purchasing system in the context of Bangladesh,Islam G.Z.,Indonesian Journal of Electrical Engineering and Computer Science,2020-08-01,"The Movie Ticket Purchase System? is a web-based application. In this application, people can purchase movie tickets from all movie theatres in Bangladesh. Before purchasing a ticket, people have to do registration or login. This website builds by PHP and JavaScript for back-end; HTML, CSS for front-end. All steps of the software development life cycle are addressed properly to develop and implement the software. This website has three panels: one for the Admin, one for the Theatre Assistant and another for the Customer/User. Admin can insert the theatres, and Theatre Assistant handled maximum manual works on the website like movie add, delete, stop running, screen adds, etc. This is the first website in Bangladesh where people can purchase tickets from multiple movie halls and the site is only dedicated to this purpose. The website is very user-friendly and attractive that can give comfort to the end users. Also, the theater owners that have no digital platform for selling tickets can be a member of our service and get the opportunity of using digital platform.",CSS | Database | HTML | Java script | Module | Movie | PHP,1,828-836,Journal,Article,6.0,"Islam, Gazi Zahirul;Zinnia, Isrut Jahan;Hossain, Md Fokhray;Rahman, Md Riazur;Juman, Aman Ullah;Emran, Al Nahian Bin",57207777195;57217307972;35731207300;57205200679;57211981299;57217301457,Daffodil International University,Bangladesh,"the movie ticket purchase system? is a web-based application. in this application, people can purchase movie tickets from all movie theatres in bangladesh. before purchasing a ticket, people have to do registration or login. this website builds by php and javascript for back-end; html, css for front-end. all steps of the software development life cycle are addressed properly to develop and implement the software. this website has three panels: one for the admin, one for the theatre assistant and another for the customer/user. admin can insert the theatres, and theatre assistant handled maximum manual works on the website like movie add, delete, stop running, screen adds, etc. this is the first website in bangladesh where people can purchase tickets from multiple movie halls and the site is only dedicated to this purpose. the website is very user-friendly and attractive that can give comfort to the end users. also, the theater owners that have no digital platform for selling tickets can be a member of our service and get the opportunity of using digital platform.",implementation of an efficient web-based movie ticket purchasing system in the context of bangladesh
481,2-s2.0-85086465774,10.1109/TLA.2020.9111679,Automatic code generation for language-learning applications,Sebastian G.,IEEE Latin America Transactions,2020-08-01,"Language-learning applications define exercises that are pedagogical tools to introduce new language concepts. The development of this type of applications is complex due to the diversity of language-learning methodologies, the variety of execution environments and the number of different technologies that can be used. This article proposes a complete Model-Driven Architecture (MDA) approach, from the definition of the Computational Independent Model (CIM layer) to the Implementation Specific Model (ISM layer), and the process of the necessary transformations for the automatic generation of the source code (in HTML and JavaScript) of language-learning applications. To carry out the model-to-model and model-to-text transformations, the ATLAS Transformation Language (ATL) and Acceleo transformation languages have been used respectively. The proposal has been validated through the modeling and the complete automatic generation of source code of two Learning Activity Mechanisms (LAM), which are used within methodologies such as Duolingo and Busuu: LAM Image-Audio-Text and LAM Audio-Text Options.",code generation | language-learning applications | model-driven architecture,5,1433-1440,Journal,Article,3.0,"Sebastian, Gabriel;Tesoriero, Ricardo;Gallud, Jose A.",36642733200;23398335700;6507169834,Instituto de Investigación en Informática de Albacete;Universidad de Castilla-La Mancha,Spain;Spain,"language-learning applications define exercises that are pedagogical tools to introduce new language concepts. the development of this type of applications is complex due to the diversity of language-learning methodologies, the variety of execution environments and the number of different technologies that can be used. this article proposes a complete model-driven architecture (mda) approach, from the definition of the computational independent model (cim layer) to the implementation specific model (ism layer), and the process of the necessary transformations for the automatic generation of the source code (in html and javascript) of language-learning applications. to carry out the model-to-model and model-to-text transformations, the atlas transformation language (atl) and acceleo transformation languages have been used respectively. the proposal has been validated through the modeling and the complete automatic generation of source code of two learning activity mechanisms (lam), which are used within methodologies such as duolingo and busuu: lam image-audio-text and lam audio-text options.",automatic code generation for language-learning applications
482,2-s2.0-85053636759,10.1109/TSE.2018.2871058,The Adoption of JavaScript Linters in Practice: A Case Study on ESLint,Tomasdottir K.F.,IEEE Transactions on Software Engineering,2020-08-01,"A linter is a static analysis tool that warns software developers about possible code errors or violations to coding standards. By using such a tool, errors can be surfaced early in the development process when they are cheaper to fix. For a linter to be successful, it is important to understand the needs and challenges of developers when using a linter. In this paper, we examine developers' perceptions on JavaScript linters. We study why and how developers use linters along with the challenges they face while using such tools. For this purpose we perform a case study on ESLint, the most popular JavaScript linter. We collect data with three different methods where we interviewed 15 developers from well-known open source projects, analyzed over 9,500 ESLint configuration files, and surveyed 337 developers from the JavaScript community. Our results provide practitioners with reasons for using linters in their JavaScript projects as well as several configuration strategies and their advantages. We also provide a list of linter rules that are often enabled and disabled, which can be interpreted as the most important rules to reason about when configuring linters. Finally, we propose several feature suggestions for tool makers and future work for researchers.",ASATs | empirical software engineering | eslint | javascript linters | linters | Static analysis tools,18,863-891,Journal,Article,3.0,"Tomasdottir, Kristin Fjola;Aniche, Mauricio;Van Deursen, Arie",57191586210;36132835800;7003969355,Delft University of Technology,Netherlands,"a linter is a static analysis tool that warns software developers about possible code errors or violations to coding standards. by using such a tool, errors can be surfaced early in the development process when they are cheaper to fix. for a linter to be successful, it is important to understand the needs and challenges of developers when using a linter. in this paper, we examine developers' perceptions on javascript linters. we study why and how developers use linters along with the challenges they face while using such tools. for this purpose we perform a case study on eslint, the most popular javascript linter. we collect data with three different methods where we interviewed 15 developers from well-known open source projects, analyzed over 9,500 eslint configuration files, and surveyed 337 developers from the javascript community. our results provide practitioners with reasons for using linters in their javascript projects as well as several configuration strategies and their advantages. we also provide a list of linter rules that are often enabled and disabled, which can be interpreted as the most important rules to reason about when configuring linters. finally, we propose several feature suggestions for tool makers and future work for researchers.",the adoption of javascript linters in practice: a case study on eslint
483,2-s2.0-85091941152,10.1145/3387904.3389278,Adaptive deep code search,Ling C.,IEEE International Conference on Program Comprehension,2020-07-13,"Searching code in a large-scale codebase using natural languagequeries is a common practice during software development. Deeplearning-based code search methods demonstrate superior performance if models are trained with large amount of text-code pairs.However, few deep code search models can be easily transferredfrom one codebase to another. It can be very costly to preparetraining data for a new codebase and re-train an appropriate deeplearning model. In this paper, we propose AdaCS, an adaptive deepcode search method that can be trained once and transferred to newcodebases. AdaCS decomposes the learning process into embeddingdomain-specific words and matching general syntactic patterns.Firstly, an unsupervised word embedding technique is used to construct a matching matrix to represent the lexical similarities. Then,a recurrent neural network is used to capture latent syntactic patterns from these matching matrices in a supervised way. As thesupervised task learns general syntactic patterns that exist acrossdomains, AdaCS is transferable to new codebases. Experimentalresults show that: when extended to new software projects neverseen in the training data, AdaCS is more robust and significantlyoutperforms state-of-the-art deep code search methods.",Code search | Deep learning | Domain adaption,5,48-59,Conference Proceeding,Conference Paper,4.0,"Ling, Chunyang;Lin, Zeqi;Zou, Yanzhen;Xie, Bing",57204685458;56683474100;23491099400;7201872787,Peking University;Ministry of Education China,China;China,"searching code in a large-scale codebase using natural languagequeries is a common practice during software development. deeplearning-based code search methods demonstrate superior performance if models are trained with large amount of text-code pairs.however, few deep code search models can be easily transferredfrom one codebase to another. it can be very costly to preparetraining data for a new codebase and re-train an appropriate deeplearning model. in this paper, we propose adacs, an adaptive deepcode search method that can be trained once and transferred to newcodebases. adacs decomposes the learning process into embeddingdomain-specific words and matching general syntactic patterns.firstly, an unsupervised word embedding technique is used to construct a matching matrix to represent the lexical similarities. then,a recurrent neural network is used to capture latent syntactic patterns from these matching matrices in a supervised way. as thesupervised task learns general syntactic patterns that exist acrossdomains, adacs is transferable to new codebases. experimentalresults show that: when extended to new software projects neverseen in the training data, adacs is more robust and significantlyoutperforms state-of-the-art deep code search methods.",adaptive deep code search
484,2-s2.0-85091894293,10.1145/3387904.3389253,An empirical study on dynamic typing related practices in python systems,Chen Z.,IEEE International Conference on Program Comprehension,2020-07-13,"The dynamic typing discipline of Python allows developers to program at a high level of abstraction. However, type related bugsare commonly encountered in Python systems due to the lack oftype declaration and static type checking. Especially, the misuse ofdynamic typing discipline produces underlying bugs and increasesmaintenance efforts. In this paper, we introduce six types of dynamic typing related practices in Python programs, which are thecommon but potentially risky usage of dynamic typing disciplineby developers. We also implement a tool named PYDYPE to detectthem. Based on this tool, we conduct an empirical study on ninereal-world Python systems (with the size of more than 460KLOC)to understand dynamic typing related practices. We investigatehow widespread the dynamic typing related practices are, why theyare introduced into the systems, whether their usage correlateswith increased likelihood of bug occurring, and how developers fixdynamic typing related bugs. The results show that: (1) dynamictyping related practices exist inconsistently in different systemsand Inconsistent Variable Types is most prevalent; (2) they are introduced into systems mainly during early development phase topromote development efficiency; (3) they have a significant positive correlation with bug occurring; (4) developers tend to addtype checks or exception handling to fix dynamic typing relatedbugs. These results benefit future research in coding convention,language design, bug detection and fixing.",Dynamic typing | Empirical study | Python,4,83-93,Conference Proceeding,Conference Paper,6.0,"Chen, Zhifei;Li, Yanhui;Chen, Bihuan;Ma, Wanwangying;Chen, Lin;Xu, Baowen",55884919800;55992301500;35224542900;56949541600;57189042207;7404589262,Nanjing University;Fudan University,China;China,"the dynamic typing discipline of python allows developers to program at a high level of abstraction. however, type related bugsare commonly encountered in python systems due to the lack oftype declaration and static type checking. especially, the misuse ofdynamic typing discipline produces underlying bugs and increasesmaintenance efforts. in this paper, we introduce six types of dynamic typing related practices in python programs, which are thecommon but potentially risky usage of dynamic typing disciplineby developers. we also implement a tool named pydype to detectthem. based on this tool, we conduct an empirical study on ninereal-world python systems (with the size of more than 460kloc)to understand dynamic typing related practices. we investigatehow widespread the dynamic typing related practices are, why theyare introduced into the systems, whether their usage correlateswith increased likelihood of bug occurring, and how developers fixdynamic typing related bugs. the results show that: (1) dynamictyping related practices exist inconsistently in different systemsand inconsistent variable types is most prevalent; (2) they are introduced into systems mainly during early development phase topromote development efficiency; (3) they have a significant positive correlation with bug occurring; (4) developers tend to addtype checks or exception handling to fix dynamic typing relatedbugs. these results benefit future research in coding convention,language design, bug detection and fixing.",an empirical study on dynamic typing related practices in python systems
487,2-s2.0-85088235911,10.33166/AETiC.2020.03.001,Vulnerabilities mapping based on OWASP-SANS: A survey for static application security testing (SAST),Li J.,Annals of Emerging Technologies in Computing,2020-07-01,"The delivery of a framework in place for secure application development is of real value for application development teams to integrate security into their development life cycle, especially when a mobile or web application moves past the scanning stage and focuses increasingly on the remediation or mitigation phase based on static application security testing (SAST). For the first time, to the author’s knowledge, the industry-standard Open Web Application Security Project (OWASP) top 10 vulnerabilities and CWE/SANS top 25 most dangerous software errors are synced up in a matrix with Checkmarx vulnerability queries, producing an application security framework that helps development teams review and address code vulnerabilities, minimise false positives discovered in static scans and penetration tests, targeting an increased accuracy of the findings. A case study is conducted for vulnerabilities scanning of a proof-of-concept mobile malware detection app. Mapping the OWASP/SANS with Checkmarx vulnerabilities queries, flaws and vulnerabilities are demonstrated to be mitigated with improved efficiency.",Application Security | Checkmarx | Malware Detection | OWASP Top 10 | SANS Top 25 | Static Application Security Testing | Vulnerability Mapping,22,1-8,Journal,Article,1.0,"Li, Jinfeng",57192697395,Imperial College London,United Kingdom,"the delivery of a framework in place for secure application development is of real value for application development teams to integrate security into their development life cycle, especially when a mobile or web application moves past the scanning stage and focuses increasingly on the remediation or mitigation phase based on static application security testing (sast). for the first time, to the author’s knowledge, the industry-standard open web application security project (owasp) top 10 vulnerabilities and cwe/sans top 25 most dangerous software errors are synced up in a matrix with checkmarx vulnerability queries, producing an application security framework that helps development teams review and address code vulnerabilities, minimise false positives discovered in static scans and penetration tests, targeting an increased accuracy of the findings. a case study is conducted for vulnerabilities scanning of a proof-of-concept mobile malware detection app. mapping the owasp/sans with checkmarx vulnerabilities queries, flaws and vulnerabilities are demonstrated to be mitigated with improved efficiency.",vulnerabilities mapping based on owasp-sans: a survey for static application security testing (sast)
488,2-s2.0-85087834781,10.4995/var.2020.13422,Humanos: An open source nomadic software database for physical anthropology and archaeology,Colleter R.,Virtual Archaeology Review,2020-07-01,"With the democratization of computers, tablets and smartphones, the data acquisition and exploration on archaeological sites are changing significantly. The digitization of information allows a faster, more efficient and more standardized data recording that facilitates the synthesis work required by the discipline. Numerous database programmes are being developed in archaeology and physical anthropology, notably with targeted tools developed to meet specific needs. However, to the authors' knowledge, no efficient, free and open-source program for the recording of human bones in an archaeological context exists yet. In this paper, a mobile application for the intuitive recording of human bones from archaeological sites is described; this app, defined for the field and biological anthropologists, allows making an inventory of the burials from site to the laboratory from archaeological digs in an intuitive style. In addition to the recording of the skeleton, the application permits the recording of the discovery context. The application also gives significant freedom to the user, who can easily create research fields to their own research objectives. Finally, it permits exporting the information, either as text (automatic report) and/or as tables for statistical use. It is a modular, ergonomic and portable tool which meets researchers' requirements without needing an internet connection; it stores the recorded information in several formats (CSV, SVG, HTML and/or JSON), in a sustainable computer language, permitting complementary modules development. The system is implemented in the form of a free and open-source web application, programmed in JavaScript (available from http://www.humanos.cnrs.fr/) and supplied in the form of a simple ZIP file to decompress. The application does not require any special installation, as it opens by clicking on the executable HumanOS.html with any web browser, even without an Internet connection.",Archaeological site | Database searching | Interoperability | Open-source software | Physical anthropology | Software development,2,94-105,Journal,Article,3.0,"Colleter, Rozenn;Romain, Jean Baptiste;Barreau, Jean Baptiste",26032892100;57217998318;56038547000,"Centre de Recherche en Archéologie, Archéosciences, Histoire;Université Fédérale Toulouse Midi-Pyrénées;Freelance developer",France;France;France,"with the democratization of computers, tablets and smartphones, the data acquisition and exploration on archaeological sites are changing significantly. the digitization of information allows a faster, more efficient and more standardized data recording that facilitates the synthesis work required by the discipline. numerous database programmes are being developed in archaeology and physical anthropology, notably with targeted tools developed to meet specific needs. however, to the authors' knowledge, no efficient, free and open-source program for the recording of human bones in an archaeological context exists yet. in this paper, a mobile application for the intuitive recording of human bones from archaeological sites is described; this app, defined for the field and biological anthropologists, allows making an inventory of the burials from site to the laboratory from archaeological digs in an intuitive style. in addition to the recording of the skeleton, the application permits the recording of the discovery context. the application also gives significant freedom to the user, who can easily create research fields to their own research objectives. finally, it permits exporting the information, either as text (automatic report) and/or as tables for statistical use. it is a modular, ergonomic and portable tool which meets researchers' requirements without needing an internet connection; it stores the recorded information in several formats (csv, svg, html and/or json), in a sustainable computer language, permitting complementary modules development. the system is implemented in the form of a free and open-source web application, programmed in javascript (available from http://www.humanos.cnrs.fr/) and supplied in the form of a simple zip file to decompress. the application does not require any special installation, as it opens by clicking on the executable humanos.html with any web browser, even without an internet connection.",humanos: an open source nomadic software database for physical anthropology and archaeology
489,2-s2.0-85087417947,10.3390/electronics9071067,A survey of the selenium ecosystem,García B.,Electronics (Switzerland),2020-07-01,"Selenium is often considered the de-facto standard framework for end-to-end web testing nowadays. It allows practitioners to drive web browsers (such as Chrome, Firefox, Edge, or Opera) in an automated fashion using different language bindings (such as Java, Python, or JavaScript, among others). The term ecosystem, referring to the open-source software domain, includes various components, tools, and other interrelated elements sharing the same technological background. This article presents a descriptive survey aimed to understand how the community uses Selenium and its ecosystem. This survey is structured in seven categories: Selenium foundations, test development, system under test, test infrastructure, other frameworks, community, and personal experience. In light of the current state of Selenium, we analyze future challenges and opportunities around it.",Automated software testing | Selenium | Software ecosystems | Web,14,1-29,Journal,Article,4.0,"García, Boni;Gallego, Micael;Gortázar, Francisco;Munoz-Organero, Mario",24724315500;57202908535;24179404100;26030525600,Universidad Rey Juan Carlos;Universidad Carlos III de Madrid,Spain;Spain,"selenium is often considered the de-facto standard framework for end-to-end web testing nowadays. it allows practitioners to drive web browsers (such as chrome, firefox, edge, or opera) in an automated fashion using different language bindings (such as java, python, or javascript, among others). the term ecosystem, referring to the open-source software domain, includes various components, tools, and other interrelated elements sharing the same technological background. this article presents a descriptive survey aimed to understand how the community uses selenium and its ecosystem. this survey is structured in seven categories: selenium foundations, test development, system under test, test infrastructure, other frameworks, community, and personal experience. in light of the current state of selenium, we analyze future challenges and opportunities around it.",a survey of the selenium ecosystem
490,2-s2.0-85087413103,10.3390/electronics9071077,Bitcoin’s apis in open-source projects: Security usability evaluation,Tschannen P.,Electronics (Switzerland),2020-07-01,"Given the current state of software development, it does not seem that we are nowhere near vulnerability-free software applications, due to many reasons, and software developers are one of them. Insecure coding practices, the complexity of the task in hand, and usability issues, amongst other reasons, make it hard on software developers to maintain secure code. When it comes to cryptographic currencies, the need for assuring security is inevitable. For example, Bitcoin is a peer-to-peer software system that is primarily used as digital money. There exist many software libraries supporting various programming languages that allow access to the Bitcoin system via an Application Programming Interface (API). APIs that are inappropriately used would lead to security vulnerabilities, which are hard to discover, resulting in many zero-day exploits. Making APIs usable is, therefore, an essential aspect related to the quality and robustness of the software. This paper surveys the general academic literature concerning API usability and usable security. Furthermore, it evaluates the API usability of Libbitcoin, a well-known C++ implementation of the Bitcoin system, and assesses how the findings of this evaluation could affect the applications that use Libbitcoin. For that purpose, the paper proposes two static analysis tools to further investigate the use of Libbitcoin APIs in open-source projects from a security usability perspective. The findings of this research have improved Libbitcoin in many places, as will be shown in this paper.",API usability | Bitcoin | Libbitcoin APIs | Open-source | Privacy | Security | Software developers,0,1-36,Journal,Article,2.0,"Tschannen, Philipp;Ahmed, Ali",57217597170;57268954100,University of Liverpool;Victoria University of Wellington,United Kingdom;New Zealand,"given the current state of software development, it does not seem that we are nowhere near vulnerability-free software applications, due to many reasons, and software developers are one of them. insecure coding practices, the complexity of the task in hand, and usability issues, amongst other reasons, make it hard on software developers to maintain secure code. when it comes to cryptographic currencies, the need for assuring security is inevitable. for example, bitcoin is a peer-to-peer software system that is primarily used as digital money. there exist many software libraries supporting various programming languages that allow access to the bitcoin system via an application programming interface (api). apis that are inappropriately used would lead to security vulnerabilities, which are hard to discover, resulting in many zero-day exploits. making apis usable is, therefore, an essential aspect related to the quality and robustness of the software. this paper surveys the general academic literature concerning api usability and usable security. furthermore, it evaluates the api usability of libbitcoin, a well-known c++ implementation of the bitcoin system, and assesses how the findings of this evaluation could affect the applications that use libbitcoin. for that purpose, the paper proposes two static analysis tools to further investigate the use of libbitcoin apis in open-source projects from a security usability perspective. the findings of this research have improved libbitcoin in many places, as will be shown in this paper.",bitcoin’s apis in open-source projects: security usability evaluation
491,2-s2.0-85093687976,10.1145/3379597.3387464,An Empirical Study on Regular Expression Bugs,Wang P.,"Proceedings - 2020 IEEE/ACM 17th International Conference on Mining Software Repositories, MSR 2020",2020-06-29,"Understanding the nature of regular expression (regex) issues is important to tackle practical issues developers face in regular expression usage. Knowledge about the nature and frequency of various types of regular expression issues, such as those related to performance, API misuse, and code smells, can guide testing, inform documentation writers, and motivate refactoring efforts. However, beyond ReDoS (Regular expression Denial of Service), little is known about to what extent regular expression issues affect software development and how these issues are addressed in practice. This paper presents a comprehensive empirical study of 350 merged regex-related pull requests from Apache, Mozilla, Facebook, and Google GitHub repositories. Through classifying the root causes and manifestations of those bugs, we show that incorrect regular expression behavior is the dominant root cause of regular expression bugs (165/356, 46.3%). The remaining root causes are incorrect API usage (9.3%) and other code issues that require regular expression changes in the fix (29.5%). By studying the code changes of regex-related pull requests, we observe that fixing regular expression bugs is nontrivial as it takes more time and more lines of code to fix them compared to the general pull requests. The results of this study contribute to a broader understanding of the practical problems faced by developers when using regular expressions.",bug fixes | pull requests | Regular expression bug characteristics,4,103-113,Conference Proceeding,Conference Paper,4.0,"Wang, Peipei;Brown, Chris;Jennings, Jamie A.;Stolee, Kathryn T.",56903232900;57213322400;57219534176;35273571700,NC State University,United States,"understanding the nature of regular expression (regex) issues is important to tackle practical issues developers face in regular expression usage. knowledge about the nature and frequency of various types of regular expression issues, such as those related to performance, api misuse, and code smells, can guide testing, inform documentation writers, and motivate refactoring efforts. however, beyond redos (regular expression denial of service), little is known about to what extent regular expression issues affect software development and how these issues are addressed in practice. this paper presents a comprehensive empirical study of 350 merged regex-related pull requests from apache, mozilla, facebook, and google github repositories. through classifying the root causes and manifestations of those bugs, we show that incorrect regular expression behavior is the dominant root cause of regular expression bugs (165/356, 46.3%). the remaining root causes are incorrect api usage (9.3%) and other code issues that require regular expression changes in the fix (29.5%). by studying the code changes of regex-related pull requests, we observe that fixing regular expression bugs is nontrivial as it takes more time and more lines of code to fix them compared to the general pull requests. the results of this study contribute to a broader understanding of the practical problems faced by developers when using regular expressions.",an empirical study on regular expression bugs
492,2-s2.0-85093659713,10.1145/3379597.3387476,Using Others' Tests to Identify Breaking Updates,Mujahid S.,"Proceedings - 2020 IEEE/ACM 17th International Conference on Mining Software Repositories, MSR 2020",2020-06-29,"The reuse of third-party packages has become a common practice in contemporary software development. Software dependencies are constantly evolving with newly added features and patches that fix bugs in older versions. However, updating dependencies could introduce new bugs or break backward compatibility. In this work, we propose a technique to detect breakage-inducing versions of third-party dependencies. The key insight behind our approach is to leverage the automated test suites of other projects that depend upon the same dependency to test newly released versions. We conjecture that this crowd-based approach will help to detect breakage-inducing versions because it broadens the set of realistic usage scenarios to which a package version has been exposed. To evaluate our conjecture, we perform an empirical study of 391,553 npm packages. We use the dependency network from these packages to identify candidate tests of third-party packages. Moreover, to evaluate our proposed technique, we mine the history of this dependency network to identify ten breakage-inducing versions. We find that our proposed technique can detect six of the ten studied breakage-inducing versions. Our findings can help developers to make more informed decisions when they update their dependencies.",Empirical Studies | JavaScript | Node.js | Software Ecosystems | Software Quality | Software Testing,5,466-476,Conference Proceeding,Conference Paper,4.0,"Mujahid, Suhaib;Abdalkareem, Rabe;Shihab, Emad;McIntosh, Shane",57195319577;57193842880;23566819100;7005758924,Concordia University;Queen’s University,Canada;Canada,"the reuse of third-party packages has become a common practice in contemporary software development. software dependencies are constantly evolving with newly added features and patches that fix bugs in older versions. however, updating dependencies could introduce new bugs or break backward compatibility. in this work, we propose a technique to detect breakage-inducing versions of third-party dependencies. the key insight behind our approach is to leverage the automated test suites of other projects that depend upon the same dependency to test newly released versions. we conjecture that this crowd-based approach will help to detect breakage-inducing versions because it broadens the set of realistic usage scenarios to which a package version has been exposed. to evaluate our conjecture, we perform an empirical study of 391,553 npm packages. we use the dependency network from these packages to identify candidate tests of third-party packages. moreover, to evaluate our proposed technique, we mine the history of this dependency network to identify ten breakage-inducing versions. we find that our proposed technique can detect six of the ten studied breakage-inducing versions. our findings can help developers to make more informed decisions when they update their dependencies.",using others' tests to identify breaking updates
495,2-s2.0-85094323417,10.1145/3377811.3380404,Interpreting cloud computer vision pain-points: A mining study of stack overflow,Cummaudo A.,Proceedings - International Conference on Software Engineering,2020-06-27,"Intelligent services are becoming increasingly more pervasive; application developers want to leverage the latest advances in areas such as computer vision to provide new services and products to users, and large technology firms enable this via RESTful APIs. While such APIs promise an easy-to-integrate on-demand machine intelligence, their current design, documentation and developer interface hides much of the underlying machine learning techniques that power them. Such APIs look and feel like conventional APIs but abstract away data-driven probabilistic behaviour-the implications of a developer treating these APIs in the same way as other, traditional cloud services, such as cloud storage, is of concern. The objective of this study is to determine the various pain-points developers face when implementing systems that rely on the most mature of these intelligent services, specifically those that provide computer vision. We use Stack Overflow to mine indications of the frustrations that developers appear to face when using computer vision services, classifying their questions against two recent classification taxonomies (documentation-related and general questions). We find that, unlike mature fields like mobile development, there is a contrast in the types of questions asked by developers. These indicate a shallow understanding of the underlying technology that empower such systems. We discuss several implications of these findings via the lens of learning taxonomies to suggest how the software engineering community can improve these services and comment on the nature by which developers use them.",Computer vision | Documentation | Empirical study | Intelligent services | Pain points | Stack overflow,10,1584-1596,Conference Proceeding,Conference Paper,5.0,"Cummaudo, Alex;Vasa, Rajesh;Barnett, Scott;Grundy, John;Abdelrazek, Mohamed",57193564412;14632834200;56890458900;7102156137;56080446200,Monash University;Deakin University,Australia;Australia,"intelligent services are becoming increasingly more pervasive; application developers want to leverage the latest advances in areas such as computer vision to provide new services and products to users, and large technology firms enable this via restful apis. while such apis promise an easy-to-integrate on-demand machine intelligence, their current design, documentation and developer interface hides much of the underlying machine learning techniques that power them. such apis look and feel like conventional apis but abstract away data-driven probabilistic behaviour-the implications of a developer treating these apis in the same way as other, traditional cloud services, such as cloud storage, is of concern. the objective of this study is to determine the various pain-points developers face when implementing systems that rely on the most mature of these intelligent services, specifically those that provide computer vision. we use stack overflow to mine indications of the frustrations that developers appear to face when using computer vision services, classifying their questions against two recent classification taxonomies (documentation-related and general questions). we find that, unlike mature fields like mobile development, there is a contrast in the types of questions asked by developers. these indicate a shallow understanding of the underlying technology that empower such systems. we discuss several implications of these findings via the lens of learning taxonomies to suggest how the software engineering community can improve these services and comment on the nature by which developers use them.",interpreting cloud computer vision pain-points: a mining study of stack overflow
496,2-s2.0-85094174155,10.1145/3377812.3381392,Scalable and approximate program dependence analysis,Lee S.,Proceedings - International Conference on Software Engineering,2020-06-27,"Program dependence is a fundamental concept to many softwareengineering tasks, yet the traditional dependence analysis strugglesto cope with common modern development practices such as multilingual implementations and use of third-party libraries. WhileObservation-based Slicing (ORBS) solves these issues and producesan accurate slice, it has a scalability problem due to the need tobuild and execute the target program multiple times. We would liketo propose a radical change of perspective: a useful dependenceanalysis needs to be scalable even if it approximates the dependency.Our goal is a scalable approximate program dependence analysisvia estimating the likelihood of dependence. We claim that 1) usingexternal information such as lexical analysis or a development history, 2) learning dependence model from partial observations, and3) merging static, and observation-based approach would assist theproposition. We expect that our technique would introduce a newperspective of program dependence analysis into the likelihood ofdependence. It would also broaden the capability of the dependenceanalysis towards large and complex software.",ORBS | Program Analysis | Program Slicing,0,162-165,Conference Proceeding,Conference Paper,1.0,"Lee, Seongmin",57222641930,Korea Advanced Institute of Science and Technology,South Korea,"program dependence is a fundamental concept to many softwareengineering tasks, yet the traditional dependence analysis strugglesto cope with common modern development practices such as multilingual implementations and use of third-party libraries. whileobservation-based slicing (orbs) solves these issues and producesan accurate slice, it has a scalability problem due to the need tobuild and execute the target program multiple times. we would liketo propose a radical change of perspective: a useful dependenceanalysis needs to be scalable even if it approximates the dependency.our goal is a scalable approximate program dependence analysisvia estimating the likelihood of dependence. we claim that 1) usingexternal information such as lexical analysis or a development history, 2) learning dependence model from partial observations, and3) merging static, and observation-based approach would assist theproposition. we expect that our technique would introduce a newperspective of program dependence analysis into the likelihood ofdependence. it would also broaden the capability of the dependenceanalysis towards large and complex software.",scalable and approximate program dependence analysis
497,2-s2.0-85094148542,10.1145/3377811.3380342,Big code != big vocabulary: Open-vocabulary models for source code,Karampatsis R.M.,Proceedings - International Conference on Software Engineering,2020-06-27,"Statistical language modeling techniques have successfully been applied to large source code corpora, yielding a variety of new software development tools, such as tools for code suggestion, improving readability, and API migration. A major issue with these techniques is that code introduces new vocabulary at a far higher rate than natural language, as new identifier names proliferate. Both large vocabularies and out-of-vocabulary issues severely affect Neural Language Models (NLMs) of source code, degrading their performance and rendering them unable to scale. In this paper, we address this issue by: 1) studying how various modelling choices impact the resulting vocabulary on a large-scale corpus of 13,362 projects; 2) presenting an open vocabulary source code NLM that can scale to such a corpus, 100 times larger than in previous work; and 3) showing that such models outperform the state of the art on three distinct code corpora (Java, C, Python). To our knowledge, these are the largest NLMs for code that have been reported. All datasets, code, and trained models used in this work are publicly available.",Byte-pair encoding | Naturalness of code | Neural language models,54,1073-1085,Conference Proceeding,Conference Paper,5.0,"Karampatsis, Rafael Michael;Babii, Hlib;Robbes, Romain;Sutton, Charles;Janes, Andrea",57200284328;57219510091;15136854400;57204256039;7003421075,The University of Edinburgh;Free University of Bozen-Bolzano,United Kingdom;Italy,"statistical language modeling techniques have successfully been applied to large source code corpora, yielding a variety of new software development tools, such as tools for code suggestion, improving readability, and api migration. a major issue with these techniques is that code introduces new vocabulary at a far higher rate than natural language, as new identifier names proliferate. both large vocabularies and out-of-vocabulary issues severely affect neural language models (nlms) of source code, degrading their performance and rendering them unable to scale. in this paper, we address this issue by: 1) studying how various modelling choices impact the resulting vocabulary on a large-scale corpus of 13,362 projects; 2) presenting an open vocabulary source code nlm that can scale to such a corpus, 100 times larger than in previous work; and 3) showing that such models outperform the state of the art on three distinct code corpora (java, c, python). to our knowledge, these are the largest nlms for code that have been reported. all datasets, code, and trained models used in this work are publicly available.",big code != big vocabulary: open-vocabulary models for source code
498,2-s2.0-85093108572,10.1145/3387940.3392205,How Magic Is Zero?: An Empirical Analysis of Initial Development Releases in Three Software Package Distributions,Decan A.,"Proceedings - 2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops, ICSEW 2020",2020-06-27,"Distributions of open source software packages dedicated to specific programming languages facilitate software development by allowing software projects to depend on the functionality provided by such reusable packages. The health of a software project can be affected by the maturity of the packages on which it depends. The version numbers of the used package releases provide an indication of their maturity. Packages with a 0.y.z version number are commonly assumed to be under initial development, implying that they are likely to be less stable, and depending on them may be less healthy. In this paper, we empirically study, for three open source package distributions (Cargo, npm and Packagist) to which extent 0.y.z package releases and ≥1.0.0 package releases behave differently. More specifically, we quantify the prevalence of 0.y.z releases, we explore how long packages remain in the initial development stage, we compare the update frequency of 0.y.z and ≥ 1.0.0 package releases, we study how often 0.y.z releases are required by other packages, and we assess whether semantic versioning is respected for dependencies towards them. Among others, we observe that package distributions are more permissive than what semantic versioning dictates for 0.y.z releases, and that many of the 0.y.z releases can be regarded as mature packages that are no longer under initial development. As a consequence, the version number does not provide a good indication of the health of a package release.",semantic versioning | software health | software library | software package distribution | software reuse | version management,1,695-702,Conference Proceeding,Conference Paper,2.0,"Decan, Alexandre;Mens, Tom",35931990200;6701719612,Université de Mons,Belgium,"distributions of open source software packages dedicated to specific programming languages facilitate software development by allowing software projects to depend on the functionality provided by such reusable packages. the health of a software project can be affected by the maturity of the packages on which it depends. the version numbers of the used package releases provide an indication of their maturity. packages with a 0.y.z version number are commonly assumed to be under initial development, implying that they are likely to be less stable, and depending on them may be less healthy. in this paper, we empirically study, for three open source package distributions (cargo, npm and packagist) to which extent 0.y.z package releases and ≥1.0.0 package releases behave differently. more specifically, we quantify the prevalence of 0.y.z releases, we explore how long packages remain in the initial development stage, we compare the update frequency of 0.y.z and ≥ 1.0.0 package releases, we study how often 0.y.z releases are required by other packages, and we assess whether semantic versioning is respected for dependencies towards them. among others, we observe that package distributions are more permissive than what semantic versioning dictates for 0.y.z releases, and that many of the 0.y.z releases can be regarded as mature packages that are no longer under initial development. as a consequence, the version number does not provide a good indication of the health of a package release.",how magic is zero?: an empirical analysis of initial development releases in three software package distributions
499,2-s2.0-85093079738,10.1145/3387940.3391481,Comparing Different Developer Behavior Recommendation Styles,Brown C.,"Proceedings - 2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops, ICSEW 2020",2020-06-27,"Research shows that one of the most effective ways software engineers discover useful developer behaviors, or tools and practices designed to help developers complete programming tasks, is through human-to-human recommendations from coworkers during work activities. However, due to the increasingly distributed nature of the software industry and development teams, opportunities for these peer interactions are in decline. To overcome the deprecation of peer interactions in software engineering, we explore the impact of several system-to-human recommendation systems, including the recently introduced suggested changes feature on GitHub which allows users to propose code changes to developers on contributions to repositories, to discover their impact on developer recommendations. In this work, we aim to study the effectiveness of suggested changes for recommending developer behaviors by performing a user study with professional software developers to compare static analysis tool recommendations from emails, pull requests, issues, and suggested changes. Our results provide insight into creating systems for recommendations between developers and design implications for improving automated recommendations to software engineers.",developer behavior | developer recommendations | software engineering | tool adoption,0,78-85,Conference Proceeding,Conference Paper,2.0,"Brown, Chris;Parnin, Chris",57213322400;15136883200,NC State University,United States,"research shows that one of the most effective ways software engineers discover useful developer behaviors, or tools and practices designed to help developers complete programming tasks, is through human-to-human recommendations from coworkers during work activities. however, due to the increasingly distributed nature of the software industry and development teams, opportunities for these peer interactions are in decline. to overcome the deprecation of peer interactions in software engineering, we explore the impact of several system-to-human recommendation systems, including the recently introduced suggested changes feature on github which allows users to propose code changes to developers on contributions to repositories, to discover their impact on developer recommendations. in this work, we aim to study the effectiveness of suggested changes for recommending developer behaviors by performing a user study with professional software developers to compare static analysis tool recommendations from emails, pull requests, issues, and suggested changes. our results provide insight into creating systems for recommendations between developers and design implications for improving automated recommendations to software engineers.",comparing different developer behavior recommendation styles
500,2-s2.0-85093078646,10.1145/3387940.3392202,Characterizing outdateness with technical lag: An exploratory study,Gonzalez-Barahona J.M.,"Proceedings - 2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops, ICSEW 2020",2020-06-27,"Background: Nowadays, many applications are built reusing a large number of components, retrieved from software collections such as npm (JavaScript) or PyPi (Python). Those components are built in their corresponding upstream repositories, where they are being developed. This architecture of reusing causes some constraints on how much outdated is an application when it is deployed in production environments. Goal: To understand how outdateness of applications, and the components on which they depend, can be computed, so that different situations can be measured and assessed with the help of metrics. Based on this understanding, we also want to produce a model to characterize ecosystems (collections of reusable components). Method: Use the technical lag framework to analyze the flows from upstream repositories, to collection of components, to application building and later deployment. Using this framework, analyze lag in version availability in each of these stages, and constraints that set limits on how much outdated can be deployed applications. Results: We define a model which allows us to better understand the factors that influence outdateness of an application produced with reusable components from repositories of components. The model allows us to find the factors for defining metrics for measuring outdateness, and to explore the factors that influence outdateness for components in applications. We propose some of those factors as the basis to characterize ecosystems or collections of components with respect to their impact on the outdateness of applications built with them. Conclusions: Technical lag is an appropriate framework for studying lags in version propagation from upstream development to deployment.",dependencies | reusable components | software development | technical lag,0,735-741,Conference Proceeding,Conference Paper,1.0,"Gonzalez-Barahona, Jesus M.",57201694910,Universidad Rey Juan Carlos,Spain,"background: nowadays, many applications are built reusing a large number of components, retrieved from software collections such as npm (javascript) or pypi (python). those components are built in their corresponding upstream repositories, where they are being developed. this architecture of reusing causes some constraints on how much outdated is an application when it is deployed in production environments. goal: to understand how outdateness of applications, and the components on which they depend, can be computed, so that different situations can be measured and assessed with the help of metrics. based on this understanding, we also want to produce a model to characterize ecosystems (collections of reusable components). method: use the technical lag framework to analyze the flows from upstream repositories, to collection of components, to application building and later deployment. using this framework, analyze lag in version availability in each of these stages, and constraints that set limits on how much outdated can be deployed applications. results: we define a model which allows us to better understand the factors that influence outdateness of an application produced with reusable components from repositories of components. the model allows us to find the factors for defining metrics for measuring outdateness, and to explore the factors that influence outdateness for components in applications. we propose some of those factors as the basis to characterize ecosystems or collections of components with respect to their impact on the outdateness of applications built with them. conclusions: technical lag is an appropriate framework for studying lags in version propagation from upstream development to deployment.",characterizing outdateness with technical lag: an exploratory study
501,2-s2.0-85092523322,10.1145/3379177.3388891,On the role of software architecture in DevOps transformation: An industrial case study,Shahin M.,"Proceedings - 2020 IEEE/ACM International Conference on Software and System Processes, ICSSP 2020",2020-06-26,"Development and Operations (DevOps), a particular type of Continuous Software Engineering, has become a popular Software System Engineering paradigm. Software architecture is critical in succeeding with DevOps. However, there is little evidence-based knowledge of how software systems are architected in the industry to enable and support DevOps. Since architectural decisions, along with their rationales and implications, are very important in the architecting process, we performed an industrial case study that has empirically identified and synthesized the key architectural decisions considered essential to DevOps transformation by two software development teams. Our study also reveals that apart from the chosen architecture style, DevOps works best with modular architectures. In addition, we found that the performance of the studied teams can improve in DevOps if operations specialists are added to the teams to perform the operations tasks that require advanced expertise. Finally, investment in testing is inevitable for the teams if they want to release software changes faster.",Case Study | Continuous Delivery | DevOps | Software Architecture,4,175-184,Conference Proceeding,Conference Paper,2.0,"Shahin, Mojtaba;Babar, M. Ali",57014668800;6602842620,Monash University;The University of Adelaide,Australia;Australia,"development and operations (devops), a particular type of continuous software engineering, has become a popular software system engineering paradigm. software architecture is critical in succeeding with devops. however, there is little evidence-based knowledge of how software systems are architected in the industry to enable and support devops. since architectural decisions, along with their rationales and implications, are very important in the architecting process, we performed an industrial case study that has empirically identified and synthesized the key architectural decisions considered essential to devops transformation by two software development teams. our study also reveals that apart from the chosen architecture style, devops works best with modular architectures. in addition, we found that the performance of the studied teams can improve in devops if operations specialists are added to the teams to perform the operations tasks that require advanced expertise. finally, investment in testing is inevitable for the teams if they want to release software changes faster.",on the role of software architecture in devops transformation: an industrial case study
502,2-s2.0-85086180699,10.1145/3396802.3396803,CodeTripping: Towards Mastering App Development Using a Web-based Learning Tool. A Case Study,Bergande B.,ACM International Conference Proceeding Series,2020-06-18,"This study is a preliminary case study examining the use of a free Web Development learning platform in order to en-deepen and facilitate further knowledge in App Development beginners. The use of CodeTrip.gr was examined with regard to perceived learning outcomes and effect on the need for cognition from the viewpoint of undergraduate non-major students with basic Web Engineering and programming skills. A didactic intervention including CodeTrip was conducted with a randomized sample of 18 undergraduate students, who were asked during the tool introduction and after doing the course, using qualitative analysis and validated items from technology and media effects research. The results are promising and support the idea that the user interface of the tool adds to the learning of the students since they show higher need for cognition scores and better self-evaluation after its use. Generalization of results is limited due to the small sample size. Future work includes the validation of the questionnaire with a bigger sample.",Case Study | CodeTrip | CS Education | HTML | JavaScript | Need for Cognition | Technology Acceptance Model,1,47-51,Conference Proceeding,Conference Paper,4.0,"Bergande, Bianca;Petrikoglou, Anna;Kaskalis, Theodoros H.;Brune, Philipp",57202384010;57211521994;6506109981;49862725400,Panepistimion Makedonias;University of Applied Sciences Neu-Ulm,Greece;Germany,"this study is a preliminary case study examining the use of a free web development learning platform in order to en-deepen and facilitate further knowledge in app development beginners. the use of codetrip.gr was examined with regard to perceived learning outcomes and effect on the need for cognition from the viewpoint of undergraduate non-major students with basic web engineering and programming skills. a didactic intervention including codetrip was conducted with a randomized sample of 18 undergraduate students, who were asked during the tool introduction and after doing the course, using qualitative analysis and validated items from technology and media effects research. the results are promising and support the idea that the user interface of the tool adds to the learning of the students since they show higher need for cognition scores and better self-evaluation after its use. generalization of results is limited due to the small sample size. future work includes the validation of the questionnaire with a bigger sample.",codetripping: towards mastering app development using a web-based learning tool. a case study
503,2-s2.0-85068146470,10.1108/BPMJ-12-2018-0365,Organizational planning for quality management in the digital age,Behmer F.J.,Business Process Management Journal,2020-06-17,"Purpose: Quality managers today require a holistic, overreaching view on the organization and its goals in order to plan the quality management organization (QMO) effectively. The purpose of this paper is to present the concept of a web application that aims to support quality managers in organizational planning tasks. The basis for the implementation is a previously developed planning method that builds on Product and Technology Roadmapping as well as Quality Function Deployment. It supports the QMO’s strategic development in line with the organization’s overall strategy. Design/methodology/approach: Based on previous research that systematically identified the requirements toward a suitable planning method and a consecutively designed framework, a web application was developed. This process followed agile software development approaches, including test-driven iteration cycles and validation through a case-based user trial. Findings: Standardized quality criteria for software development together with identified requirements for a suitable planning method provided a specified guideline to develop a web application. This application enables quality managers to effectively deploy the previously developed planning method. It proved successful in an initial field trial and creates a basis for integrated, computer-aided QMO planning. Originality/value: With an integrated planning method that was implemented through a web application, quality managers could be effectively supported in developing the QMO in line with the overall strategy. As organizational planning tasks are reoccurring but not day-to-day business, moderated workshops that use the web application as a guiding tool and enable quality managers to focus on delivering information inputs appear to be a highly promising approach.",Organization | Organizational development | Planning | Quality management | Total quality management,5,679-693,Journal,Article,2.0,"Behmer, Falk Johannes;Jochem, Roland",56764442900;6603204236,Technische Universität Berlin;Fraunhofer Institute for Production Systems and Design Technology IPK,Germany;Germany,"purpose: quality managers today require a holistic, overreaching view on the organization and its goals in order to plan the quality management organization (qmo) effectively. the purpose of this paper is to present the concept of a web application that aims to support quality managers in organizational planning tasks. the basis for the implementation is a previously developed planning method that builds on product and technology roadmapping as well as quality function deployment. it supports the qmo’s strategic development in line with the organization’s overall strategy. design/methodology/approach: based on previous research that systematically identified the requirements toward a suitable planning method and a consecutively designed framework, a web application was developed. this process followed agile software development approaches, including test-driven iteration cycles and validation through a case-based user trial. findings: standardized quality criteria for software development together with identified requirements for a suitable planning method provided a specified guideline to develop a web application. this application enables quality managers to effectively deploy the previously developed planning method. it proved successful in an initial field trial and creates a basis for integrated, computer-aided qmo planning. originality/value: with an integrated planning method that was implemented through a web application, quality managers could be effectively supported in developing the qmo in line with the overall strategy. as organizational planning tasks are reoccurring but not day-to-day business, moderated workshops that use the web application as a guiding tool and enable quality managers to focus on delivering information inputs appear to be a highly promising approach.",organizational planning for quality management in the digital age
507,2-s2.0-85091342401,10.1109/ICCES48766.2020.09138056,Generation of call graph for Java higher order functions,Bedadala P.,"Proceedings of the 5th International Conference on Communication and Electronics Systems, ICCES 2020",2020-06-01,"The Lambda expression introduced in Java 8 gives a functional style to the object-oriented program. The major highlights of lambda expression include lazy evaluation, code readability, avoiding code duplication. A static call graph can be usedto visualize every possible run that the program might take. Due to the recent software development using Java, the new features aintroduced in Java 8 may be explored. Hence this demands the need for the call graphs generated for such software. This paper suggests an algorithm for the construction of a call graph for the lambda constructs. A static call graph will be generated by preserving the signature of the methods. The model suggested here uses an intermediate Abstract syntax tree (AST) like representation which is further transformed and optimized into a call graph representation.",Call graph | Lambda function | Static analysis,3,1151-1156,Conference Proceeding,Conference Paper,3.0,"Bedadala, Prathima;Manasa, D.;Nair, Lekshmi S.",56982932100;57214228863;57171958400,"Amrita University, Amritapuri Campus",India,"the lambda expression introduced in java 8 gives a functional style to the object-oriented program. the major highlights of lambda expression include lazy evaluation, code readability, avoiding code duplication. a static call graph can be usedto visualize every possible run that the program might take. due to the recent software development using java, the new features aintroduced in java 8 may be explored. hence this demands the need for the call graphs generated for such software. this paper suggests an algorithm for the construction of a call graph for the lambda constructs. a static call graph will be generated by preserving the signature of the methods. the model suggested here uses an intermediate abstract syntax tree (ast) like representation which is further transformed and optimized into a call graph representation.",generation of call graph for java higher order functions
510,2-s2.0-85088152923,10.4067/S0718-07642020000300135,Development of a web software to generate management plans of software risks,Castro-Rivera V.P.,Informacion Tecnologica,2020-06-01,"This article describes the design and development of a web system for the creation of risk management plans. Our web software aims to supporting management plan creation for new tech-development organizations, for new and established entrepreneurs, and for micro and small start-ups. The main objective of our web software is to improve the probability of success in the release of new software products. Our web software provides a series of support tools such as expert coaching, collaborative work, and risk administration during the developmental process. Our web software was implemented using current web technologies and was developed using a method similar to SCRUM. It tested successfully in a real-life setting in a local software development company. This demonstrates that our system is an efficient tool for assisting in the creation of risk management plans in the real world.",Management plans | Software for management | Software risks,1,135-148,Journal,Article,3.0,"Castro-Rivera, Valentina P.;Herrera-Acuña, Raúl A.;Villalobos-Abarca, Marco A.",57218167948;55792634600;56801078600,Universidad de Tarapacá;CEO - Kuvemar Desarrollo Tecnológico,Chile;Chile,"this article describes the design and development of a web system for the creation of risk management plans. our web software aims to supporting management plan creation for new tech-development organizations, for new and established entrepreneurs, and for micro and small start-ups. the main objective of our web software is to improve the probability of success in the release of new software products. our web software provides a series of support tools such as expert coaching, collaborative work, and risk administration during the developmental process. our web software was implemented using current web technologies and was developed using a method similar to scrum. it tested successfully in a real-life setting in a local software development company. this demonstrates that our system is an efficient tool for assisting in the creation of risk management plans in the real world.",development of a web software to generate management plans of software risks
512,2-s2.0-85085648793,10.1109/TLA.2020.9099749,Programmer Experience: A Systematic Mapping,Morales J.,IEEE Latin America Transactions,2020-06-01,"User eXperience (UX) identifies the perceptions of people over of the use (or even the anticipated use) of a product, system or service. The programmers are users of specific systems, and several types of software development artifacts, such as programming environments and design documents. We performed a systematic mapping about Programmer eXperience (PX). In this work we consider the programmers as a particular type of users of particular artifacts. We therefore consider PX as a particular type of UX. The literature usually focuses on PX from a Software Engineering point of view. We analyzed PX mainly from a Human-Computer Interaction (HCI) perspective. We reviewed articles about PX, empirical studies related to aspects of PX, and studies addressing PX on programming environments. The results show that there is an interest on the PX, but the concept is not yet clearly defined. We found 40 articles published in the last ten years and established that the studies address usability and PX aspects focusing on four topics: (i) programming languages, (ii) programmers' interaction with the integrated development environment, (iii) application programming interfaces, and (iv) articles about programmers' behavior. It is a relatively small numbers of articles, compared with other Software Engineering or HCI areas. This represents a research opportunity for this systematic review and others that can be performed.",Programmer experience | Programming environments | Systematic mapping | Usability | User experience,1,1111-1118,Journal,Review,3.0,"Morales, Jenny;Rusu, Cristian;Quinones, Daniela",56396018600;15521347000;56237424300,Universidad Autónoma de Chile;Pontificia Universidad Católica de Valparaíso,Chile;Chile,"user experience (ux) identifies the perceptions of people over of the use (or even the anticipated use) of a product, system or service. the programmers are users of specific systems, and several types of software development artifacts, such as programming environments and design documents. we performed a systematic mapping about programmer experience (px). in this work we consider the programmers as a particular type of users of particular artifacts. we therefore consider px as a particular type of ux. the literature usually focuses on px from a software engineering point of view. we analyzed px mainly from a human-computer interaction (hci) perspective. we reviewed articles about px, empirical studies related to aspects of px, and studies addressing px on programming environments. the results show that there is an interest on the px, but the concept is not yet clearly defined. we found 40 articles published in the last ten years and established that the studies address usability and px aspects focusing on four topics: (i) programming languages, (ii) programmers' interaction with the integrated development environment, (iii) application programming interfaces, and (iv) articles about programmers' behavior. it is a relatively small numbers of articles, compared with other software engineering or hci areas. this represents a research opportunity for this systematic review and others that can be performed.",programmer experience: a systematic mapping
514,2-s2.0-85084935887,10.1016/j.isprsjprs.2020.04.001,Google Earth Engine for geo-big data applications: A meta-analysis and systematic review,Tamiminia H.,ISPRS Journal of Photogrammetry and Remote Sensing,2020-06-01,"Google Earth Engine (GEE) is a cloud-based geospatial processing platform for large-scale environmental monitoring and analysis. The free-to-use GEE platform provides access to (1) petabytes of publicly available remote sensing imagery and other ready-to-use products with an explorer web app; (2) high-speed parallel processing and machine learning algorithms using Google's computational infrastructure; and (3) a library of Application Programming Interfaces (APIs) with development environments that support popular coding languages, such as JavaScript and Python. Together these core features enable users to discover, analyze and visualize geospatial big data in powerful ways without needing access to supercomputers or specialized coding expertise. The development of GEE has created much enthusiasm and engagement in the remote sensing and geospatial data science fields. Yet after a decade since GEE was launched, its impact on remote sensing and geospatial science has not been carefully explored. Thus, a systematic review of GEE that can provide readers with the “big picture” of the current status and general trends in GEE is needed. To this end, the decision was taken to perform a meta-analysis investigation of recent peer-reviewed GEE articles focusing on several features, including data, sensor type, study area, spatial resolution, application, strategy, and analytical methods. A total of 349 peer-reviewed articles published in 146 different journals between 2010 and October 2019 were reviewed. Publications and geographical distribution trends showed a broad spectrum of applications in environmental analyses at both regional and global scales. Remote sensing datasets were used in 90% of studies while 10% of the articles utilized ready-to-use products for analyses. Optical satellite imagery with medium spatial resolution, particularly Landsat data with an archive exceeding 40 years, has been used extensively. Linear regression and random forest were the most frequently used algorithms for satellite imagery processing. Among ready-to-use products, the normalized difference vegetation index (NDVI) was used in 27% of studies for vegetation, crop, land cover mapping and drought monitoring. The results of this study confirm that GEE has and continues to make substantive progress on global challenges involving process of geo-big data.",Cloud-based platform | Environmental monitoring | Geo-big data | Geospatial | Google Earth Engine | Machine learning | Planetary-scale | Remote sensing,215,152-170,Journal,Short Survey,6.0,"Tamiminia, Haifa;Salehi, Bahram;Mahdianpari, Masoud;Quackenbush, Lindi;Adeli, Sarina;Brisco, Brian",57189686942;36610817400;57190371939;36779146200;57216843548;7003505161,SUNY College of Environmental Science and Forestry;Memorial University of Newfoundland;Canada Centre for Mapping and Earth Observation,United States;Canada;Canada,"google earth engine (gee) is a cloud-based geospatial processing platform for large-scale environmental monitoring and analysis. the free-to-use gee platform provides access to (1) petabytes of publicly available remote sensing imagery and other ready-to-use products with an explorer web app; (2) high-speed parallel processing and machine learning algorithms using google's computational infrastructure; and (3) a library of application programming interfaces (apis) with development environments that support popular coding languages, such as javascript and python. together these core features enable users to discover, analyze and visualize geospatial big data in powerful ways without needing access to supercomputers or specialized coding expertise. the development of gee has created much enthusiasm and engagement in the remote sensing and geospatial data science fields. yet after a decade since gee was launched, its impact on remote sensing and geospatial science has not been carefully explored. thus, a systematic review of gee that can provide readers with the “big picture” of the current status and general trends in gee is needed. to this end, the decision was taken to perform a meta-analysis investigation of recent peer-reviewed gee articles focusing on several features, including data, sensor type, study area, spatial resolution, application, strategy, and analytical methods. a total of 349 peer-reviewed articles published in 146 different journals between 2010 and october 2019 were reviewed. publications and geographical distribution trends showed a broad spectrum of applications in environmental analyses at both regional and global scales. remote sensing datasets were used in 90% of studies while 10% of the articles utilized ready-to-use products for analyses. optical satellite imagery with medium spatial resolution, particularly landsat data with an archive exceeding 40 years, has been used extensively. linear regression and random forest were the most frequently used algorithms for satellite imagery processing. among ready-to-use products, the normalized difference vegetation index (ndvi) was used in 27% of studies for vegetation, crop, land cover mapping and drought monitoring. the results of this study confirm that gee has and continues to make substantive progress on global challenges involving process of geo-big data.",google earth engine for geo-big data applications: a meta-analysis and systematic review
516,2-s2.0-85083448223,10.1002/humu.24018,Documentation of clinically relevant genomic biomarker allele frequencies in the next-generation FINDbase worldwide database,Kounelis F.,Human Mutation,2020-06-01,"FINDbase (http://www.findbase.org) is a comprehensive data resource recording the prevalence of clinically relevant genomic variants in various populations worldwide, such as pathogenic variants underlying genetic disorders as well as pharmacogenomic biomarkers that can guide drug treatment. Here, we report significant new developments and technological advancements in the database architecture, leading to a completely revamped database structure, querying interface, accompanied with substantial extensions of data content and curation. In particular, the FINDbase upgrade further improves the user experience by introducing responsive features that support a wide variety of mobile and stationary devices, while enhancing computational runtime due to the use of a modern Javascript framework such as ReactJS. Data collection is significantly enriched, with the data records being divided in a Public and Private version, the latter being accessed on the basis of data contribution, according to the microattribution approach, while the front end was redesigned to support the new functionalities and querying tools. The abovementioned updates further enhance the impact of FINDbase, improve the overall user experience, facilitate further data sharing by microattribution, and strengthen the role of FINDbase as a key resource for personalized medicine applications and personalized public health.",allele frequencies | clinically relevant genomic variations | data visualization | genomic variation | pharmacogenomic biomarkers | population,6,1112-1122,Journal,Article,13.0,"Kounelis, Fotios;Kanterakis, Alexandros;Kanavos, Andreas;Pandi, Maria Theodora;Kordou, Zoe;Manusama, Olivia;Vonitsanos, Gerasimos;Katsila, Theodora;Tsermpini, Evangelia Eirini;Lauschke, Volker M.;Koromina, Maria;van der Spek, Peter J.;Patrinos, George P.",57197746057;14035676900;55520653600;57211604166;57209333329;57193309522;57207778324;24066813500;55967275100;56955751900;57200393946;7004533326;6603726539,College of Medicine and Health Sciences United Arab Emirates University;School of Health Sciences;Erasmus MC;National Hellenic Research Foundation;University of Patras;Foundation for Research and Technology-Hellas;Imperial College London;Karolinska Institutet;United Arab Emirates University,United Arab Emirates;Greece;Netherlands;Greece;Greece;Greece;United Kingdom;Sweden;United Arab Emirates,"findbase (http://www.findbase.org) is a comprehensive data resource recording the prevalence of clinically relevant genomic variants in various populations worldwide, such as pathogenic variants underlying genetic disorders as well as pharmacogenomic biomarkers that can guide drug treatment. here, we report significant new developments and technological advancements in the database architecture, leading to a completely revamped database structure, querying interface, accompanied with substantial extensions of data content and curation. in particular, the findbase upgrade further improves the user experience by introducing responsive features that support a wide variety of mobile and stationary devices, while enhancing computational runtime due to the use of a modern javascript framework such as reactjs. data collection is significantly enriched, with the data records being divided in a public and private version, the latter being accessed on the basis of data contribution, according to the microattribution approach, while the front end was redesigned to support the new functionalities and querying tools. the abovementioned updates further enhance the impact of findbase, improve the overall user experience, facilitate further data sharing by microattribution, and strengthen the role of findbase as a key resource for personalized medicine applications and personalized public health.",documentation of clinically relevant genomic biomarker allele frequencies in the next-generation findbase worldwide database
518,2-s2.0-85064249470,10.1007/s10209-019-00650-5,Concepts and design space for a better understanding of multi-device user interfaces,Paternò F.,Universal Access in the Information Society,2020-06-01,"This paper discusses the motivations behind and the characterising concepts of multi-device user interfaces by looking at the main design issues that have been addressed and the various solutions proposed. The discussion of relevant systems and frameworks highlights their main features, which are then used as the basis for comparative discussion. It compares different approaches and perspectives adopted in this area (e.g. responsive design, cross-device, distributed, migratory user interfaces). The features constitute a design space that can be used to facilitate analysis and comparison of tools and frameworks for multi-device user interfaces. Such aspects can be exploited by user interface designers and developers to analyse and compare various options when addressing existing and new applications. The analysis provided may inspire the design and development of new tools and frameworks as well.",Cross-device user interfaces | Distributed and migratory user interfaces | Multi-device environments,6,409-432,Journal,Article,1.0,"Paternò, Fabio",55156557600,Istituto di Scienza e Tecnologie dell'Informazione A. Faedo,Italy,"this paper discusses the motivations behind and the characterising concepts of multi-device user interfaces by looking at the main design issues that have been addressed and the various solutions proposed. the discussion of relevant systems and frameworks highlights their main features, which are then used as the basis for comparative discussion. it compares different approaches and perspectives adopted in this area (e.g. responsive design, cross-device, distributed, migratory user interfaces). the features constitute a design space that can be used to facilitate analysis and comparison of tools and frameworks for multi-device user interfaces. such aspects can be exploited by user interface designers and developers to analyse and compare various options when addressing existing and new applications. the analysis provided may inspire the design and development of new tools and frameworks as well.",concepts and design space for a better understanding of multi-device user interfaces
519,2-s2.0-85086760178,10.1093/comjnl/bxz029,ImagIngDev: A New Approach for Developing Automatic Cross-Platform Mobile Applications Using Image Processing Techniques,Rosales-Morales V.Y.,Computer Journal,2020-05-20,"The aim of this work is propose and describe ImagIngDev, a new approach for developing automatic cross-platform mobile applications using image processing techniques. As proof of concept, we presented ImagIng Tool and compared its performance with respect to similar cross-platform application development tools. Our main contribution to software development is ImagingDev, a new, intuitive and agile approach aimed at novice developers for automatically developing cross-platform mobile applications. Our proof of concept, ImagIng Tool, can generate mobile applications on four different software platforms: Android™, Windows Phone™, iOS™ and FirefoxOS™. Also, it relies on image processing techniques to recognize user interface design patterns (UIDPs) inside user interfaces, and generates the source code for cross-platform and multi-device applications. As proof of concept, we developed ImagIng Tool for automatic generation of cross-platform mobile applications by using image processing techniques. Results from the evaluation demonstrated that ImagIng Tool has attractive benefits if compared to similar cross-platform application development tools. Such benefits include higher learnability and usability. ImagIngDev and ImagIng Tool can effectively solve current problems in mobile applications development, such as automatic code generation for cross-platform mobile applications, since they allow users to generate cross-platform and multi-device mobile applications in an easy and intuitive way.",automatic software development | image processing | mobile applications | UI design patterns,5,732-757,Journal,Article,6.0,"Rosales-Morales, Viviana Yarel;Sánchez-Morales, Laura Nely;Alor-Hernández, Giner;Garcia-Alcaraz, Jorge Luis;Sánchez-Cervantes, José Luis;Rodriguez-Mazahua, Lisbeth",37120706700;57194164215;17433252100;55616966800;36976388800;56436822300,Tecnológico Nacional de México;Universidad Autónoma de Ciudad Juárez,Mexico;Mexico,"the aim of this work is propose and describe imagingdev, a new approach for developing automatic cross-platform mobile applications using image processing techniques. as proof of concept, we presented imaging tool and compared its performance with respect to similar cross-platform application development tools. our main contribution to software development is imagingdev, a new, intuitive and agile approach aimed at novice developers for automatically developing cross-platform mobile applications. our proof of concept, imaging tool, can generate mobile applications on four different software platforms: android™, windows phone™, ios™ and firefoxos™. also, it relies on image processing techniques to recognize user interface design patterns (uidps) inside user interfaces, and generates the source code for cross-platform and multi-device applications. as proof of concept, we developed imaging tool for automatic generation of cross-platform mobile applications by using image processing techniques. results from the evaluation demonstrated that imaging tool has attractive benefits if compared to similar cross-platform application development tools. such benefits include higher learnability and usability. imagingdev and imaging tool can effectively solve current problems in mobile applications development, such as automatic code generation for cross-platform mobile applications, since they allow users to generate cross-platform and multi-device mobile applications in an easy and intuitive way.",imagingdev: a new approach for developing automatic cross-platform mobile applications using image processing techniques
521,2-s2.0-85099727572,10.1109/SPW50608.2020.00066,Research report: Building a wide reach corpus for secure parser development,Allison T.,"Proceedings - 2020 IEEE Symposium on Security and Privacy Workshops, SPW 2020",2020-05-01,"Computer software that parses electronic files is often vulnerable to maliciously crafted input data. Rather than relying on developers to implement ad hoc defenses against such data, the Language-theoretic security (LangSec) philosophy offers formally correct and verifiable input handling throughout the software development lifecycle. Whether developing from a specification or deriving parsers from samples, LangSec parser developers require wide-reach corpora of their target file format in order to identify key edge cases or common deviations from the format's specification. In this research report, we provide the details of several methods we have used to gather approximately 30 million files, extract features and make these features amenable to search and use in analytics. Additionally, we provide documentation on opportunities and limitations of some popular open-source datasets and annotation tools that will benefit researchers which need to efficiently gather a large file corpus for the purposes of LangSec parser development.",File corpus creation | File forensics | LangSec | Language-theoretic security | Parser resources | Text extraction,1,318-326,Conference Proceeding,Conference Paper,9.0,"Allison, Tim;Burke, Wayne;Constantinou, Valentino;Goh, Edwin;Mattmann, Chris;Mensikova, Anastasija;Southam, Philip;Stonebraker, Ryan;Timmaraju, Virisha",57221661614;57221663688;57195933567;57221662781;8969695400;57221660824;57221662692;57221663797;57219404269,Jet Propulsion Laboratory,United States,"computer software that parses electronic files is often vulnerable to maliciously crafted input data. rather than relying on developers to implement ad hoc defenses against such data, the language-theoretic security (langsec) philosophy offers formally correct and verifiable input handling throughout the software development lifecycle. whether developing from a specification or deriving parsers from samples, langsec parser developers require wide-reach corpora of their target file format in order to identify key edge cases or common deviations from the format's specification. in this research report, we provide the details of several methods we have used to gather approximately 30 million files, extract features and make these features amenable to search and use in analytics. additionally, we provide documentation on opportunities and limitations of some popular open-source datasets and annotation tools that will benefit researchers which need to efficiently gather a large file corpus for the purposes of langsec parser development.",research report: building a wide reach corpus for secure parser development
522,2-s2.0-85089348198,10.1109/ICAIBD49809.2020.9137487,Design and Realization of Sensor Acquisition System for Sonde Based on SSM Framework,Yang J.,"2020 3rd International Conference on Artificial Intelligence and Big Data, ICAIBD 2020",2020-05-01,"The sensor acquisition system of sonde is to complete accurate data acquisition through efficient acquisition mechanism and effective personnel management technology, and through the cooperation of several modules such as software control thermostat, sensor automatic controller, serial port server and self-made sensor detection equipment. Under the background of global integration, a multi-threaded acquisition mechanism is designed to meet the requirements of simultaneous calibration of temperature, humidity and pressure sensors, aiming at the need of multi-type and multi-quantity sensor calibration equipment at the same time. The system adopts the current popular B/S mode and integrated development with SSM framework. B/S mode is browser-to-server mode, and SSM framework refers to the synthesis of Spring, SpringMVC and Mybatis, which can be used to build flexible and easy to expand multi-layer Web applications. The front display page USES javaScript, HTML, JSP and other technologies to provide users with humanized interactive services. The system has complete functions, is efficient and convenient for data collection of sonde sensors.",B/S mode | MySQL database | SSM framework | the MVC pattern,1,309-313,Conference Proceeding,Conference Paper,4.0,"Yang, Jiachun;Zhang, Wenjing;Liu, Pengyu;Xu, Jie",57218499658;57216157308;14056447600;57218500093,"Beijing University of Technology;Tianjin Huayun Tianyi Special Meteorological Detection Technology Co., Ltd.",China;China,"the sensor acquisition system of sonde is to complete accurate data acquisition through efficient acquisition mechanism and effective personnel management technology, and through the cooperation of several modules such as software control thermostat, sensor automatic controller, serial port server and self-made sensor detection equipment. under the background of global integration, a multi-threaded acquisition mechanism is designed to meet the requirements of simultaneous calibration of temperature, humidity and pressure sensors, aiming at the need of multi-type and multi-quantity sensor calibration equipment at the same time. the system adopts the current popular b/s mode and integrated development with ssm framework. b/s mode is browser-to-server mode, and ssm framework refers to the synthesis of spring, springmvc and mybatis, which can be used to build flexible and easy to expand multi-layer web applications. the front display page uses javascript, html, jsp and other technologies to provide users with humanized interactive services. the system has complete functions, is efficient and convenient for data collection of sonde sensors.",design and realization of sensor acquisition system for sonde based on ssm framework
523,2-s2.0-85086635355,10.13328/j.cnki.jos.005966,Survey of Intelligent Code Completion,Yang B.,Ruan Jian Xue Bao/Journal of Software,2020-05-01,"Code completion is one of the crucial functions of automation software development. It is an essential component of most modern integrated development environments and source code editors. Code completion provides predictions such as instant class names, method names, keywords, and assists developer to code, which improves the efficiency of software development intuitively. In recent years, with the expanding of the source code and data scale in the open-source software community, and outstanding progress in artificial intelligence technology, the automation software development technology has been much promoted. Intelligent code completion builds a language model for source code, learns features from the existing code corpus, and retrieves the most similar matches in the corpus for recommendation and prediction based on the context code features around the position to be completed. Compared to traditional code completion, intelligence code completion has become one of the hot trends in the field of software engineering with its characteristics like high accuracy, multiple completion forms, and iterative learning ability. Researchers have conducted a series of researches on intelligent code completion. According to the different forms that these completion methods represent and utilize source code information, they can be divided into two research directions: programming language representation and statistical language representation. The programming language is divided into three types: token sequences, abstract syntax tree, and control/data flow graph. The statistical language also has two types: n-gram model and the neural network model. This paper starts from the perspective of code representation and summarizes the research progress of code completion methods in recent years. The main contents include: (1) expounding and classifying existing intelligent code completion methods according to code representation; (2) summarizing the experimental verification methods and performance evaluation indicators used in model evaluation; (3) summarizing the critical issues of intelligent code completion; (4) looking forward to the future development of intelligent code completion.",Code completion | Code representation | Software development tool,2,1435-1453,Journal,Review,4.0,"Yang, Bo;Zhang, Neng;Li, Shan Ping;Xia, Xin",57217699812;55558118400;35275218400;54586248800,"College of Computer Science and Technology, Zhejiang University;Monash University",China;Australia,"code completion is one of the crucial functions of automation software development. it is an essential component of most modern integrated development environments and source code editors. code completion provides predictions such as instant class names, method names, keywords, and assists developer to code, which improves the efficiency of software development intuitively. in recent years, with the expanding of the source code and data scale in the open-source software community, and outstanding progress in artificial intelligence technology, the automation software development technology has been much promoted. intelligent code completion builds a language model for source code, learns features from the existing code corpus, and retrieves the most similar matches in the corpus for recommendation and prediction based on the context code features around the position to be completed. compared to traditional code completion, intelligence code completion has become one of the hot trends in the field of software engineering with its characteristics like high accuracy, multiple completion forms, and iterative learning ability. researchers have conducted a series of researches on intelligent code completion. according to the different forms that these completion methods represent and utilize source code information, they can be divided into two research directions: programming language representation and statistical language representation. the programming language is divided into three types: token sequences, abstract syntax tree, and control/data flow graph. the statistical language also has two types: n-gram model and the neural network model. this paper starts from the perspective of code representation and summarizes the research progress of code completion methods in recent years. the main contents include: (1) expounding and classifying existing intelligent code completion methods according to code representation; (2) summarizing the experimental verification methods and performance evaluation indicators used in model evaluation; (3) summarizing the critical issues of intelligent code completion; (4) looking forward to the future development of intelligent code completion.",survey of intelligent code completion
524,2-s2.0-85086320110,10.34028/iajit/17/3/7,A contrivance to encapsulate virtual scaffold with comments and notes,Balasubramanaian N.,International Arab Journal of Information Technology,2020-05-01,"CLOUD is an elision of Common Location-independent Online Utility available on-Demand and is based on Service Oriented Architecture (SOA). Today a chunk of researchers were working towards contrivance based on multi-tenant aware Software as a Service (SaaS) application development and still a precise pragmatic solution remains a challenge among the researchers. The first step towards resolving solution is to enhance the virtual scaffold and propose it as a System under Test (SuT). The entire work is proposed as a Model View Controller (MVC) where the tenant login through the View and write their snippet code for encapsulation. The proposed VirScaff schema acts as Controller and provides authentication and authorization by role/session assignment for tenant and thus helps to access data from the dashboard (Viz., Create, Read, Update and Delete (CRUD)). The SuT supports and accommodates both SQL and Not only Structured Query Language (NoSQL) dataset. Finally, this paper construed that SuT behaves well for both SQL and NoSQL dataset in terms of time and space complexities. To sum-up, the entire work addresses the challenges towards multitenant aware SaaS application development and highly commendable while using NoSQL dataset.",JavaScript object notation | Model view controller | Multi-Tenant common gateway | Not only structured query language | Pattern | Role-based access control | Software as a service | Virtual scaffold,0,338-346,Journal,Article,3.0,"Balasubramanaian, Nagarajan;Jayapal, Suguna;Janakiraman, Satheeshkumar",57217116938;35106255600;57217118101,Vellalar College For Women;Bharathiar University;Arunai Engineering College,India;India;India,"cloud is an elision of common location-independent online utility available on-demand and is based on service oriented architecture (soa). today a chunk of researchers were working towards contrivance based on multi-tenant aware software as a service (saas) application development and still a precise pragmatic solution remains a challenge among the researchers. the first step towards resolving solution is to enhance the virtual scaffold and propose it as a system under test (sut). the entire work is proposed as a model view controller (mvc) where the tenant login through the view and write their snippet code for encapsulation. the proposed virscaff schema acts as controller and provides authentication and authorization by role/session assignment for tenant and thus helps to access data from the dashboard (viz., create, read, update and delete (crud)). the sut supports and accommodates both sql and not only structured query language (nosql) dataset. finally, this paper construed that sut behaves well for both sql and nosql dataset in terms of time and space complexities. to sum-up, the entire work addresses the challenges towards multitenant aware saas application development and highly commendable while using nosql dataset.",a contrivance to encapsulate virtual scaffold with comments and notes
525,2-s2.0-85084818088,10.1109/RITA.2020.2987686,An Emulator Software Tool for Improving Learning of DC-DC Converters,Ferreiro A.L.,Revista Iberoamericana de Tecnologias del Aprendizaje,2020-05-01,"Power electronics disciplines involve different fundamental topics and technologies. The use of the Internet facilitates and supports the transmission of the theoretical concepts of the teacher to the student and improve the sequence of activities within the available time. The main goal of this work is to develop an emulator software tool to facilitate the usage of control loop fundamentals when applied to DC-to-DC converters. This emulator is a very solid tool for the educational community, and it allows students to analyze and design control circuits in a very flexible way. This resource is available online without time restrictions, allowing users to choose where and when they can learn and interact with the tool which offers a variety of different DC-DC converters, compensation networks and feedback topologies. Once the selection has been made and the different values of the components have been established, a frequency response analysis is shown. The development of the software tool can be operated using any modern browser under any platform and device. The effectiveness of the presented emulator software tool was assessed with the feedback obtained for the students and the results obtained therefor.",Closed-loop learning | DC-to-DC converters learning | Internet | semi-presential learning,0,63-69,Journal,Article,3.0,"Ferreiro, Alfonso Lago;Simon, Ana Rey Alvite;Casas, Sergio Lamas",7006441115;57191624156;57191616213,Universidade de Vigo;ENOTRAC Ltd.;Daimler Group Services,Spain;United Kingdom;Spain,"power electronics disciplines involve different fundamental topics and technologies. the use of the internet facilitates and supports the transmission of the theoretical concepts of the teacher to the student and improve the sequence of activities within the available time. the main goal of this work is to develop an emulator software tool to facilitate the usage of control loop fundamentals when applied to dc-to-dc converters. this emulator is a very solid tool for the educational community, and it allows students to analyze and design control circuits in a very flexible way. this resource is available online without time restrictions, allowing users to choose where and when they can learn and interact with the tool which offers a variety of different dc-dc converters, compensation networks and feedback topologies. once the selection has been made and the different values of the components have been established, a frequency response analysis is shown. the development of the software tool can be operated using any modern browser under any platform and device. the effectiveness of the presented emulator software tool was assessed with the feedback obtained for the students and the results obtained therefor.",an emulator software tool for improving learning of dc-dc converters
526,2-s2.0-85082651922,10.1007/s10664-019-09780-z,FixMiner: Mining relevant fix patterns for automated program repair,Koyuncu A.,Empirical Software Engineering,2020-05-01,"Patching is a common activity in software development. It is generally performed on a source code base to address bugs or add new functionalities. In this context, given the recurrence of bugs across projects, the associated similar patches can be leveraged to extract generic fix actions. While the literature includes various approaches leveraging similarity among patches to guide program repair, these approaches often do not yield fix patterns that are tractable and reusable as actionable input to APR systems. In this paper, we propose a systematic and automated approach to mining relevant and actionable fix patterns based on an iterative clustering strategy applied to atomic changes within patches. The goal of FixMiner is thus to infer separate and reusable fix patterns that can be leveraged in other patch generation systems. Our technique, FixMiner, leverages Rich Edit Script which is a specialized tree structure of the edit scripts that captures the AST-level context of the code changes. FixMiner uses different tree representations of Rich Edit Scripts for each round of clustering to identify similar changes. These are abstract syntax trees, edit actions trees, and code context trees. We have evaluated FixMiner on thousands of software patches collected from open source projects. Preliminary results show that we are able to mine accurate patterns, efficiently exploiting change information in Rich Edit Scripts. We further integrated the mined patterns to an automated program repair prototype, PARFixMiner, with which we are able to correctly fix 26 bugs of the Defects4J benchmark. Beyond this quantitative performance, we show that the mined fix patterns are sufficiently relevant to produce patches with a high probability of correctness: 81% of PARFixMiner’s generated plausible patches are correct.",Debugging | Empirical software engineering | Fix patterns | Patches | Program repair,38,1980-2024,Journal,Article,7.0,"Koyuncu, Anil;Liu, Kui;Bissyandé, Tegawendé F.;Kim, Dongsun;Klein, Jacques;Monperrus, Martin;Le Traon, Yves",57195259860;57203748234;36080354200;55742964600;56282553000;6506353145;55884641800,University of Luxembourg;The Royal Institute of Technology (KTH);Furiosa A.I.,Luxembourg;Sweden;South Korea,"patching is a common activity in software development. it is generally performed on a source code base to address bugs or add new functionalities. in this context, given the recurrence of bugs across projects, the associated similar patches can be leveraged to extract generic fix actions. while the literature includes various approaches leveraging similarity among patches to guide program repair, these approaches often do not yield fix patterns that are tractable and reusable as actionable input to apr systems. in this paper, we propose a systematic and automated approach to mining relevant and actionable fix patterns based on an iterative clustering strategy applied to atomic changes within patches. the goal of fixminer is thus to infer separate and reusable fix patterns that can be leveraged in other patch generation systems. our technique, fixminer, leverages rich edit script which is a specialized tree structure of the edit scripts that captures the ast-level context of the code changes. fixminer uses different tree representations of rich edit scripts for each round of clustering to identify similar changes. these are abstract syntax trees, edit actions trees, and code context trees. we have evaluated fixminer on thousands of software patches collected from open source projects. preliminary results show that we are able to mine accurate patterns, efficiently exploiting change information in rich edit scripts. we further integrated the mined patterns to an automated program repair prototype, parfixminer, with which we are able to correctly fix 26 bugs of the defects4j benchmark. beyond this quantitative performance, we show that the mined fix patterns are sufficiently relevant to produce patches with a high probability of correctness: 81% of parfixminer’s generated plausible patches are correct.",fixminer: mining relevant fix patterns for automated program repair
527,2-s2.0-85081652476,10.1007/s10664-020-09807-w,Ammonia: an approach for deriving project-specific bug patterns,Higo Y.,Empirical Software Engineering,2020-05-01,"Finding and fixing buggy code is an important and cost-intensive maintenance task, and static analysis (SA) is one of the methods developers use to perform it. SA tools warn developers about potential bugs by scanning their source code for commonly occurring bug patterns, thus giving those developers opportunities to fix the warnings (potential bugs) before they release the software. Typically, SA tools scan for general bug patterns that are common to any software project (such as null pointer dereference), and not for project specific patterns. However, past research has pointed to this lack of customizability as a severe limiting issue in SA. Accordingly, in this paper, we propose an approach called Ammonia, which is based on statically analyzing changes across the development history of a project, as a means to identify project-specific bug patterns. Furthermore, the bug patterns identified by our tool do not relate to just one developer or one specific commit, they reflect the project as a whole and compliment the warnings from other SA tools that identify general bug patterns. Herein, we report on the application of our implemented tool and approach to four Java projects: Ant, Camel, POI, and Wicket. The results obtained show that our tool could detect 19 project specific bug patterns across those four projects. Next, through manual analysis, we determined that six of those change patterns were actual bugs and submitted pull requests based on those bug patterns. As a result, five of the pull requests were merged.",Change patterns | Fix recommendation | Pattern mining | Project-specific bug patterns,5,1951-1979,Journal,Article,4.0,"Higo, Yoshiki;Hayashi, Shinpei;Hata, Hideaki;Nagappan, Meiyappan",7004831134;13204497300;24445001100;26537885500,Tokyo Institute of Technology;Nara Institute of Science and Technology;Osaka University;University of Waterloo,Japan;Japan;Japan;Canada,"finding and fixing buggy code is an important and cost-intensive maintenance task, and static analysis (sa) is one of the methods developers use to perform it. sa tools warn developers about potential bugs by scanning their source code for commonly occurring bug patterns, thus giving those developers opportunities to fix the warnings (potential bugs) before they release the software. typically, sa tools scan for general bug patterns that are common to any software project (such as null pointer dereference), and not for project specific patterns. however, past research has pointed to this lack of customizability as a severe limiting issue in sa. accordingly, in this paper, we propose an approach called ammonia, which is based on statically analyzing changes across the development history of a project, as a means to identify project-specific bug patterns. furthermore, the bug patterns identified by our tool do not relate to just one developer or one specific commit, they reflect the project as a whole and compliment the warnings from other sa tools that identify general bug patterns. herein, we report on the application of our implemented tool and approach to four java projects: ant, camel, poi, and wicket. the results obtained show that our tool could detect 19 project specific bug patterns across those four projects. next, through manual analysis, we determined that six of those change patterns were actual bugs and submitted pull requests based on those bug patterns. as a result, five of the pull requests were merged.",ammonia: an approach for deriving project-specific bug patterns
529,2-s2.0-85090826610,10.1145/3383219.3383239,Investigating the Correlation between Performance Scores and Energy Consumption of Mobile Web Apps,Chan-Jong-Chu K.,ACM International Conference Proceeding Series,2020-04-15,"Context. Developers have access to tools like Google Lighthouse to assess the performance of web apps and to guide the adoption of development best practices. However, when it comes to energy consumption of mobile web apps, these tools seem to be lacking. Goal. This study investigates on the correlation between the performance scores produced by Lighthouse and the energy consumption of mobile web apps. Method. We design and conduct an empirical experiment where 21 real mobile web apps are (i) analyzed via the Lighthouse performance analysis tool and (ii) measured on an Android device running a software-based energy profiler. Then, we statistically assess how energy consumption correlates with the obtained performance scores and carry out an effect size estimation. Results. We discover a statistically significant negative correlation between performance scores and the energy consumption of mobile web apps (with medium to large effect sizes), implying that an increase of the performance score tend to lead to a decrease of energy consumption. Conclusions. We recommend developers to strive to improve the performance level of their mobile web apps, as this can also have a positive impact on their energy consumption on Android devices.",Mobile app development | requirements elicitation | requirements engineering,3,190-199,Conference Proceeding,Conference Paper,8.0,"Chan-Jong-Chu, Kwame;Islam, Tanjina;Exposito, Miguel Morales;Sheombar, Sanjay;Valladares, Christian;Philippot, Olivier;Grua, Eoin Martino;Malavolta, Ivano",57218933136;57218933019;57218935063;57218935678;57218936476;56598064400;57207728498;25823118300,Vrije Universiteit Amsterdam;Greenspector,Netherlands;France,"context. developers have access to tools like google lighthouse to assess the performance of web apps and to guide the adoption of development best practices. however, when it comes to energy consumption of mobile web apps, these tools seem to be lacking. goal. this study investigates on the correlation between the performance scores produced by lighthouse and the energy consumption of mobile web apps. method. we design and conduct an empirical experiment where 21 real mobile web apps are (i) analyzed via the lighthouse performance analysis tool and (ii) measured on an android device running a software-based energy profiler. then, we statistically assess how energy consumption correlates with the obtained performance scores and carry out an effect size estimation. results. we discover a statistically significant negative correlation between performance scores and the energy consumption of mobile web apps (with medium to large effect sizes), implying that an increase of the performance score tend to lead to a decrease of energy consumption. conclusions. we recommend developers to strive to improve the performance level of their mobile web apps, as this can also have a positive impact on their energy consumption on android devices.",investigating the correlation between performance scores and energy consumption of mobile web apps
532,2-s2.0-85084154488,10.1007/s00170-020-05258-1,A review of the application of component-based software development in open CNC systems,Liu L.,International Journal of Advanced Manufacturing Technology,2020-04-01,"The development of open CNC systems is a popular topic in the past three decades. From the perspective of software engineering, most open CNC prototypes are developed based on the component-based software development (CBSD) approach. That is, they are constructed by composing functional or logical components. This paper retrospects the development of CBSD-based open CNC systems. These systems are analyzed from three aspects. For the component granularity aspect, CNC domain analysis and component reusability are discussed. For the component model aspect, component models used in open CNC systems are summarized, illustrated, and discussed. Likewise, for the software architecture aspect, architecture styles are summarized, described, and analyzed. But due to the diversity and platform dependency of component models, there is no widely accepted platform that can collect and execute heterogeneous CNC components. Service is an evolution of components. It makes a traditional component to be platform-independent and supports communication via message. Thus, a service-oriented architecture (SOA)-based universal open CNC platform is an attractive development trend of diverse CBSD-based open CNC systems. And its development is similar to the development of the CBSD-based system, but more complicated because it contains more domain logic. Therefore, this paper provides a technical foundation for developing SOA-based open CNC platform which is a part of novel automation patterns, such as cloud manufacturing and cyber-physical production system.",Component model | Component-based software development | Open CNC system | Software architecture | Software system,6,3727-3753,Journal,Article,3.0,"Liu, Lisi;Yao, Yingxue;Li, Jianguang",57209138357;55722539100;56002631700,Harbin Institute of Technology,China,"the development of open cnc systems is a popular topic in the past three decades. from the perspective of software engineering, most open cnc prototypes are developed based on the component-based software development (cbsd) approach. that is, they are constructed by composing functional or logical components. this paper retrospects the development of cbsd-based open cnc systems. these systems are analyzed from three aspects. for the component granularity aspect, cnc domain analysis and component reusability are discussed. for the component model aspect, component models used in open cnc systems are summarized, illustrated, and discussed. likewise, for the software architecture aspect, architecture styles are summarized, described, and analyzed. but due to the diversity and platform dependency of component models, there is no widely accepted platform that can collect and execute heterogeneous cnc components. service is an evolution of components. it makes a traditional component to be platform-independent and supports communication via message. thus, a service-oriented architecture (soa)-based universal open cnc platform is an attractive development trend of diverse cbsd-based open cnc systems. and its development is similar to the development of the cbsd-based system, but more complicated because it contains more domain logic. therefore, this paper provides a technical foundation for developing soa-based open cnc platform which is a part of novel automation patterns, such as cloud manufacturing and cyber-physical production system.",a review of the application of component-based software development in open cnc systems
534,2-s2.0-85081267553,10.1002/pro.3791,Current developments in Coot for macromolecular model building of Electron Cryo-microscopy and Crystallographic Data,Casañal A.,Protein Science,2020-04-01,"Coot is a tool widely used for model building, refinement, and validation of macromolecular structures. It has been extensively used for crystallography and, more recently, improvements have been introduced to aid in cryo-EM model building and refinement, as cryo-EM structures with resolution ranging 2.5–4 A are now routinely available. Model building into these maps can be time-consuming and requires experience in both biochemistry and building into low-resolution maps. To simplify and expedite the model building task, and minimize the needed expertise, new tools are being added in Coot. Some examples include morphing, Geman-McClure restraints, full-chain refinement, and Fourier-model based residue-type-specific Ramachandran restraints. Here, we present the current state-of-the-art in Coot usage.",ligands | macromolecular model building | molecular biophysics | real space refinement | rotamers | validation,122,1069-1078,Journal,Article,3.0,"Casañal, Ana;Lohkamp, Bernhard;Emsley, Paul",24921408700;6508190474;6602614684,Karolinska Institutet;The Medical Research Council Laboratory of Molecular Biology,Sweden;United Kingdom,"coot is a tool widely used for model building, refinement, and validation of macromolecular structures. it has been extensively used for crystallography and, more recently, improvements have been introduced to aid in cryo-em model building and refinement, as cryo-em structures with resolution ranging 2.5–4 a are now routinely available. model building into these maps can be time-consuming and requires experience in both biochemistry and building into low-resolution maps. to simplify and expedite the model building task, and minimize the needed expertise, new tools are being added in coot. some examples include morphing, geman-mcclure restraints, full-chain refinement, and fourier-model based residue-type-specific ramachandran restraints. here, we present the current state-of-the-art in coot usage.",current developments in coot for macromolecular model building of electron cryo-microscopy and crystallographic data
535,2-s2.0-85076243424,10.1016/j.future.2019.12.009,SP-MIOV: A novel framework of shadow proxy based medical image online visualization in computing and storage resource restrained environments,Li W.,Future Generation Computer Systems,2020-04-01,"The rapid development of Internet and various mobile communication media initiate the demands for access to medical image visualization systems. Medical image reading and interpretation at any time, any place and any device become an urgent need for radiologists. The current medical image online visualization methods have disadvantages in computing and storage resource restrained environments. This study presents a novel framework of medical image online visualization based on shadow proxy, which makes applications have across platform ability and universal environmental adaptability especial for devices with restricted running resources. The framework can be adapted in multiple client architectures including the pure web applications, mobile applications or regular desktop applications. It is easy to be integrated into third party software and there are no restrictions of the communication protocols between the client and server side due to two innovations of the framework that are shadow proxy mechanism and shadow data. The shadow proxy just does lightweight tasks on shadow data and the ultimate processing of computing tasks are moved to the server side to complete. The size of shadow data is small enough for shadow proxy that speeds up local display and processing tasks. Finally, the framework takes advantage of high performance on server side to render high quality image results. The performance of proposed work is evaluated in a web based medical image visualization system, and the results show that the framework in this paper allows the system to have smooth and quasi-real-time interaction performance. Therefore, this study ensures the local client operations fluency and fast while the quality of the visualization is still not lost that gives the best user experience.",Medical imaging | Online visualization | Resource restrained environment | Shadow data | Shadow proxy,3,318-330,Journal,Article,4.0,"Li, Wei;Yu, Kun;Feng, Chaolu;Zhao, Dazhe",57212350317;57211443820;36451839400;7403490069,Northeastern University,China,"the rapid development of internet and various mobile communication media initiate the demands for access to medical image visualization systems. medical image reading and interpretation at any time, any place and any device become an urgent need for radiologists. the current medical image online visualization methods have disadvantages in computing and storage resource restrained environments. this study presents a novel framework of medical image online visualization based on shadow proxy, which makes applications have across platform ability and universal environmental adaptability especial for devices with restricted running resources. the framework can be adapted in multiple client architectures including the pure web applications, mobile applications or regular desktop applications. it is easy to be integrated into third party software and there are no restrictions of the communication protocols between the client and server side due to two innovations of the framework that are shadow proxy mechanism and shadow data. the shadow proxy just does lightweight tasks on shadow data and the ultimate processing of computing tasks are moved to the server side to complete. the size of shadow data is small enough for shadow proxy that speeds up local display and processing tasks. finally, the framework takes advantage of high performance on server side to render high quality image results. the performance of proposed work is evaluated in a web based medical image visualization system, and the results show that the framework in this paper allows the system to have smooth and quasi-real-time interaction performance. therefore, this study ensures the local client operations fluency and fast while the quality of the visualization is still not lost that gives the best user experience.",sp-miov: a novel framework of shadow proxy based medical image online visualization in computing and storage resource restrained environments
536,2-s2.0-85058413311,10.1007/s10009-018-00506-y,A greedy particle swarm optimization (GPSO) algorithm for testing real-world smart card applications,Allawi H.M.,International Journal on Software Tools for Technology Transfer,2020-04-01,"Software testing continues to be regarded as a necessary and critical step in the software development life cycle. Among the multitudes of existing techniques, particle swarm optimization (PSO) algorithm, in particular, has shown superior merits for automatically generating software test cases for its easy implementation and for relying on fewer parameters that require tuning. Hence, several state-of-the-art PSO-based algorithms have been successfully used as a test data generator. On the other hand, greedy-based algorithms, which are commonly used to solve complex and multi-step combinatorial problems, are starting to gain momentum as a solution for the complexity problem of software testing. Greedy algorithms favored over other techniques when the solution of the problem is guaranteed to be near-optimal. As a result, the utilization of both greedy and PSO algorithms in a single solution for automatically generating test data represents a strong candidate if designed carefully. In this paper, we propose a novel hybrid greedy and PSO algorithm (GPSO) that jointly guarantees the effectiveness and close to optimality results for generating a minimum number of test data. Compared with the widely employed genetic algorithm (GA), our proposed GPSO outperforms the GA in terms of the average number of iterations, execution time, and coverage percentage. Experimental trials with six different typical Java card applications show that the use of the proposed GPSO as a test data generator results in an outstanding performance.",Genetic algorithm | Greedy algorithm | Java smart card | Particle swarm optimization algorithm | Software testing,3,183-194,Journal,Article,3.0,"Allawi, Hamzeh M.;Al Manaseer, Waref;Al Shraideh, Mohammad",57205061383;57209838111;14420919900,The University of Jordan,Jordan,"software testing continues to be regarded as a necessary and critical step in the software development life cycle. among the multitudes of existing techniques, particle swarm optimization (pso) algorithm, in particular, has shown superior merits for automatically generating software test cases for its easy implementation and for relying on fewer parameters that require tuning. hence, several state-of-the-art pso-based algorithms have been successfully used as a test data generator. on the other hand, greedy-based algorithms, which are commonly used to solve complex and multi-step combinatorial problems, are starting to gain momentum as a solution for the complexity problem of software testing. greedy algorithms favored over other techniques when the solution of the problem is guaranteed to be near-optimal. as a result, the utilization of both greedy and pso algorithms in a single solution for automatically generating test data represents a strong candidate if designed carefully. in this paper, we propose a novel hybrid greedy and pso algorithm (gpso) that jointly guarantees the effectiveness and close to optimality results for generating a minimum number of test data. compared with the widely employed genetic algorithm (ga), our proposed gpso outperforms the ga in terms of the average number of iterations, execution time, and coverage percentage. experimental trials with six different typical java card applications show that the use of the proposed gpso as a test data generator results in an outstanding performance.",a greedy particle swarm optimization (gpso) algorithm for testing real-world smart card applications
537,2-s2.0-85090138754,10.1145/3397537.3397552,Achieving guidance in applied machine learning through software engineering techniques,Reimann L.,ACM International Conference Proceeding Series,2020-03-23,"Development of machine learning (ML) applications is hard. Producing successful applications requires, among others, being deeply familiar with a variety of complex and quickly evolving application programming interfaces (APIs). It is therefore critical to understand what prevents developers from learning these APIs, using them properly at development time, and understanding what went wrong when it comes to debugging. We look at the (lack of) guidance that currently used development environments and ML APIs provide to developers of ML applications, contrast these with software engineering best practices, and identify gaps in the current state of the art. We show that current ML tools fall short of fulfilling some basic software engineering gold standards and point out ways in which software engineering concepts, tools and techniques need to be extended and adapted to match the special needs of ML application development. Our findings point out ample opportunities for research on ML-specific software engineering.",guidance | learnability | machine learning | software engineering | usability,2,7-12,Conference Proceeding,Conference Paper,2.0,"Reimann, Lars;Kniesel-Wünsche, Günter",57218715010;6602434399,Universität Bonn,Germany,"development of machine learning (ml) applications is hard. producing successful applications requires, among others, being deeply familiar with a variety of complex and quickly evolving application programming interfaces (apis). it is therefore critical to understand what prevents developers from learning these apis, using them properly at development time, and understanding what went wrong when it comes to debugging. we look at the (lack of) guidance that currently used development environments and ml apis provide to developers of ml applications, contrast these with software engineering best practices, and identify gaps in the current state of the art. we show that current ml tools fall short of fulfilling some basic software engineering gold standards and point out ways in which software engineering concepts, tools and techniques need to be extended and adapted to match the special needs of ml application development. our findings point out ample opportunities for research on ml-specific software engineering.",achieving guidance in applied machine learning through software engineering techniques
538,2-s2.0-85083183771,10.1145/3371382.3378287,A software system for human-robot interaction to collect research data: A HTML/javascript service on the pepper robot,Suddrey G.,ACM/IEEE International Conference on Human-Robot Interaction,2020-03-23,"A key area in human-robot interaction research is the use of a robot to collect participant research data. However, traditional website-based data collection methods do not intergrate with the robot providing the interaction. This leaves a clear disconnect between the static delivery of a digital questionnaire and a lack context-relevant behaviours from the robot. In this paper, we present a HTML/Javascript software system to create a direct link between digital data collection and the robot that delivers it. In doing so, this system can be used to create more dynamic data collection sessions using the robot's speech, movement or presence to support the delivery of questionnaires. This system can also be used to create interactive sessions to support experimentation. We present two proposed use-case scenarios built with the system with the Pepper humanoid robot in mental health and well-being services. We present this software system to help speed up development time for user studies, lower the entry barrier for non-technical researchers who want to use social robots for data collection, and to create more systematic data collection methods for robots. Future work of the software includes increasing the repertoire of questionnaire items available to allow for more sophisticated data collection.",Human-robot interaction | Interface design | Robotics | Survey toolkit,2,459-461,Conference Proceeding,Conference Paper,2.0,"Suddrey, Gavin;Robinson, Nicole",57031893500;23767534700,Queensland University of Technology,Australia,"a key area in human-robot interaction research is the use of a robot to collect participant research data. however, traditional website-based data collection methods do not intergrate with the robot providing the interaction. this leaves a clear disconnect between the static delivery of a digital questionnaire and a lack context-relevant behaviours from the robot. in this paper, we present a html/javascript software system to create a direct link between digital data collection and the robot that delivers it. in doing so, this system can be used to create more dynamic data collection sessions using the robot's speech, movement or presence to support the delivery of questionnaires. this system can also be used to create interactive sessions to support experimentation. we present two proposed use-case scenarios built with the system with the pepper humanoid robot in mental health and well-being services. we present this software system to help speed up development time for user studies, lower the entry barrier for non-technical researchers who want to use social robots for data collection, and to create more systematic data collection methods for robots. future work of the software includes increasing the repertoire of questionnaire items available to allow for more sophisticated data collection.",a software system for human-robot interaction to collect research data: a html/javascript service on the pepper robot
540,2-s2.0-85085329738,10.17013/risti.36.116-131,Ameyali: Evaluation of the usability of the integral platform for the control and monitoring of the drinking water service in rural communities under the scale of sus,Montiel-De Jesús A.,RISTI - Revista Iberica de Sistemas e Tecnologias de Informacao,2020-03-01,"The internet of things IoT, is one of the technological trends that mark a watershed in the way we control and monitor the activities of our daily lives, from work to home. In this sense, this paper presents the results obtained from the implementation of IoT technologies applied to the improvement of the operation of a hydraulic pumping system in a rural community. The methodology used is Prototype oriented to obtain an analysis of requirements, the design of the application through UML diagrams and later the development of the integral platform that includes a Web application, a mobile application and an electronic module. The results obtained show that the platform developed as well as the sensors used are feasible and viable to control the pump of the water supply of the community of Huixtitla, Veracruz, since it favors the reduction of the cost of the automation of the system, in the case of Users facilitate remote control and monitoring thanks to the mobile application and at the national level it is an original product in its category and applicability.",Automation | Domotics | Internet of Things | Software engineering | Water supply,0,116-131,Journal,Article,5.0,"Montiel-De Jesús, A.;Morales-Constantino, C.;Ixmatlahua-Díaz, S.;Hernández-Chaparro, N.;Marín-Vega, H.",57216923539;57216869898;57216857953;57216851514;57192092213,Tecnológico Nacional de México,Mexico,"the internet of things iot, is one of the technological trends that mark a watershed in the way we control and monitor the activities of our daily lives, from work to home. in this sense, this paper presents the results obtained from the implementation of iot technologies applied to the improvement of the operation of a hydraulic pumping system in a rural community. the methodology used is prototype oriented to obtain an analysis of requirements, the design of the application through uml diagrams and later the development of the integral platform that includes a web application, a mobile application and an electronic module. the results obtained show that the platform developed as well as the sensors used are feasible and viable to control the pump of the water supply of the community of huixtitla, veracruz, since it favors the reduction of the cost of the automation of the system, in the case of users facilitate remote control and monitoring thanks to the mobile application and at the national level it is an original product in its category and applicability.",ameyali: evaluation of the usability of the integral platform for the control and monitoring of the drinking water service in rural communities under the scale of sus
541,2-s2.0-85082437643,10.7544/issn1000-1239.2020.20190626,Collective Intelligence Based Software Engineering,Xu L.,Jisuanji Yanjiu yu Fazhan/Computer Research and Development,2020-03-01,"Collective intelligence based software engineering (CISE) aims to solve software engineering problems by techniques that exploit collective intelligence, which includes machine collective intelligence, human collective intelligence, and their combinations. CISE provides a new perspective for solving complex software engineering problems, and has become an important part of modern software development. This paper presents a survey of CISE, which systematically reviews the applications of different collective intelligence inspired techniques on solving problems of software requirements analysis, design, coding, testing and maintenance. Future research directions and challenges in the CISE area are also discussed. The goal of this study is to establish a uniform framework of CISE and provide references for the interactions and transformations between collective intelligence techniques of different levels.",Collective intelligence | Crowd-sourced software engineering | Search based software engineering | Software engineering | Survey,2,487-512,Journal,Review,2.0,"Xu, Lixin;Wu, Huayao",57215966211;55615092400,Nanjing University,China,"collective intelligence based software engineering (cise) aims to solve software engineering problems by techniques that exploit collective intelligence, which includes machine collective intelligence, human collective intelligence, and their combinations. cise provides a new perspective for solving complex software engineering problems, and has become an important part of modern software development. this paper presents a survey of cise, which systematically reviews the applications of different collective intelligence inspired techniques on solving problems of software requirements analysis, design, coding, testing and maintenance. future research directions and challenges in the cise area are also discussed. the goal of this study is to establish a uniform framework of cise and provide references for the interactions and transformations between collective intelligence techniques of different levels.",collective intelligence based software engineering
544,2-s2.0-85081560837,10.1145/3328778.3366950,"Runestone: A platform for free, on-line, and interactive ebooks",Ericson B.J.,SIGCSE 2020 - Proceedings of the 51st ACM Technical Symposium on Computer Science Education,2020-02-26,"The Runestone platform is open-source, extensible, and serves free ebooks to over 25,000 learners a day from around the world. The site hosts 18 ebooks for computing courses. Some of these ebook have been translated into several languages. There are ebooks for secondary computer science (AP CSP and AP CSA), CS1, CS2, data science, and web programming courses. The platform currently supports executable and editable examples in Python, Java, C, C++, HTML, JavaScript, Processing, and SQL. Runestone provides features for instructors, learners, authors, and researchers. Instructors can create a custom course from any of the existing ebooks and their students can register for that course. Instructors can create assignments from the existing material or author new problems, grade assignments, and visualize student progress. Learners can execute and modify examples and answer practice questions with immediate feedback. Runestone includes common practice types, such as multiple-choice questions, as well as some unique types, such as adaptive Parsons problems. Authors can modify the existing ebooks or write new ebooks using restructuredText: a markup language. Researchers can create and test new interactive features, run experiments, and analyze log file data. This paper describes the architecture of the platform, highlights some of the unique features, provides an overview of how instructors use the platform, summarizes the research studies conducted on the platform, and describes plans for future development.",Adaptive learning | Ebooks | Intelligent ebooks | On-line learning | Parsons problems | Practice tools,12,1012-1018,Conference Proceeding,Conference Paper,2.0,"Ericson, Barbara J.;Miller, Bradley N.",6603682585;57199372365,"University of Michigan, Ann Arbor;Luther College",United States;United States,"the runestone platform is open-source, extensible, and serves free ebooks to over 25,000 learners a day from around the world. the site hosts 18 ebooks for computing courses. some of these ebook have been translated into several languages. there are ebooks for secondary computer science (ap csp and ap csa), cs1, cs2, data science, and web programming courses. the platform currently supports executable and editable examples in python, java, c, c++, html, javascript, processing, and sql. runestone provides features for instructors, learners, authors, and researchers. instructors can create a custom course from any of the existing ebooks and their students can register for that course. instructors can create assignments from the existing material or author new problems, grade assignments, and visualize student progress. learners can execute and modify examples and answer practice questions with immediate feedback. runestone includes common practice types, such as multiple-choice questions, as well as some unique types, such as adaptive parsons problems. authors can modify the existing ebooks or write new ebooks using restructuredtext: a markup language. researchers can create and test new interactive features, run experiments, and analyze log file data. this paper describes the architecture of the platform, highlights some of the unique features, provides an overview of how instructors use the platform, summarizes the research studies conducted on the platform, and describes plans for future development.","runestone: a platform for free, on-line, and interactive ebooks"
548,2-s2.0-85084791878,10.11897/SP.J.1016.2020.00250,Review of Research on Software Ecosystems,Dong R.Z.,Jisuanji Xuebao/Chinese Journal of Computers,2020-02-01,"The innovation of software ecosystems has great influences on the production style of IT industry. It refactors the business ecosystems of IT industry. Academic and industry researchers have paid close attention to software ecosystems since 2003. Some world-wide famous IT companies make efforts towards achieving their own software ecosystems. As has developed to numerous examples of software ecosystems. Currently, emerging information technologies (such as cloud computing, mobile application development, cyber-physical systems, blockchains) are applied deeply and widely in the field of software ecosystems. The application of software ecosystems has become more and more intensive in various industries and domains. The definition of a software ecosystem has changed greatly over time. In order to clarify the context of a software ecosystem, researchers adopt biological ecosystem theories, and propose several different kinds of definitions for software ecosystems. It is not until the year of 2016 that there is consensus on what a software ecosystem is. A software ecosystem refers to a complex system in which the software and its related stakeholders interact intensively within a common technological infrastructure. In the paper, we adopt biological ecosystem theories to the context so as to come out a meta-model of software ecosystems which forms the basis for the discussion of the issues relating to software ecosystems. The meta-model, which is presented in UML class diagram, describes the key building blocks and key characteristics of software ecosystems. Typically, the research results of papers in the field of software ecosystems are compared to traditional classification which was presented in 2003. The traditional classification includes seven categories: (1) procedure or technique; (2) qualitative or descriptive model; (3) analytic model; (4) empirical model; (5) tool or notation; (6) specific solution, prototype, answer, or judgment; (7) report. But, the traditional classification schema has to be revised because that the context and the key characteristics of software ecosystems have changed greatly over time. According to our observations, we find that the combination of quantity and quality analysis is always adopted in the field, and that empirical studies reporting specific solutions for software ecosystems are in fashion. We make minor changes to the traditional classification schema for the papers focusing on software ecosystems, and then propose a five-classification pattern. Our five-classification schema combines ""qualitative or descriptive model"" and ""analytic model"" to produce a new category namely ""analytic method or framework"", and integrate ""specific solution, prototype, answer, or judgment"" into ""empirical study"". The meta-model as well as the five-classification schema forms the basis for the discussions of the issues relating to software ecosystems. Then, we provide a literal review of the research in the filed from 2015 until 2017. In total, the literature counts 196 papers. Our literature review is based on the keywords, the abstract, publication source, research content. We category the research results of papers into our five-category schema, and then identify the recent development and progress in the field. However, there exists a set of challenges for future research. Those challenges includes requirements engineering, architecture modeling, model-driven development, power mechanisms, feature analysis, information content analysis, ecologic network analysis, impact analysis of defect and/or bad smell, tool supports, emerging applications for software ecosystems.",Ecological system structure | Meta-model | Software ecosystems | Taxonomy schema,0,250-271,Journal,Review,6.0,"Dong, Rui Zhi;Li, Bi Xin;Wang, Lu Lu;Li, Hong Wei;Chen, Hai Lei;Tan, Jack",55901623800;9334814500;36663167700;56981810500;57216821599;7402302609,Changshu Institute of Technology;Jiangxi Normal University;University of Wisconsin-Eau Claire;Southeast University;Cynovo Technology Co. Ltd,China;China;United States;China;China,"the innovation of software ecosystems has great influences on the production style of it industry. it refactors the business ecosystems of it industry. academic and industry researchers have paid close attention to software ecosystems since 2003. some world-wide famous it companies make efforts towards achieving their own software ecosystems. as has developed to numerous examples of software ecosystems. currently, emerging information technologies (such as cloud computing, mobile application development, cyber-physical systems, blockchains) are applied deeply and widely in the field of software ecosystems. the application of software ecosystems has become more and more intensive in various industries and domains. the definition of a software ecosystem has changed greatly over time. in order to clarify the context of a software ecosystem, researchers adopt biological ecosystem theories, and propose several different kinds of definitions for software ecosystems. it is not until the year of 2016 that there is consensus on what a software ecosystem is. a software ecosystem refers to a complex system in which the software and its related stakeholders interact intensively within a common technological infrastructure. in the paper, we adopt biological ecosystem theories to the context so as to come out a meta-model of software ecosystems which forms the basis for the discussion of the issues relating to software ecosystems. the meta-model, which is presented in uml class diagram, describes the key building blocks and key characteristics of software ecosystems. typically, the research results of papers in the field of software ecosystems are compared to traditional classification which was presented in 2003. the traditional classification includes seven categories: (1) procedure or technique; (2) qualitative or descriptive model; (3) analytic model; (4) empirical model; (5) tool or notation; (6) specific solution, prototype, answer, or judgment; (7) report. but, the traditional classification schema has to be revised because that the context and the key characteristics of software ecosystems have changed greatly over time. according to our observations, we find that the combination of quantity and quality analysis is always adopted in the field, and that empirical studies reporting specific solutions for software ecosystems are in fashion. we make minor changes to the traditional classification schema for the papers focusing on software ecosystems, and then propose a five-classification pattern. our five-classification schema combines ""qualitative or descriptive model"" and ""analytic model"" to produce a new category namely ""analytic method or framework"", and integrate ""specific solution, prototype, answer, or judgment"" into ""empirical study"". the meta-model as well as the five-classification schema forms the basis for the discussions of the issues relating to software ecosystems. then, we provide a literal review of the research in the filed from 2015 until 2017. in total, the literature counts 196 papers. our literature review is based on the keywords, the abstract, publication source, research content. we category the research results of papers into our five-category schema, and then identify the recent development and progress in the field. however, there exists a set of challenges for future research. those challenges includes requirements engineering, architecture modeling, model-driven development, power mechanisms, feature analysis, information content analysis, ecologic network analysis, impact analysis of defect and/or bad smell, tool supports, emerging applications for software ecosystems.",review of research on software ecosystems
549,2-s2.0-85084427310,10.1109/TLA.2020.9085285,Low-Cost Image and Video Processing Using High-Performance Middleware in Single-board Computers with Open Internet Standards,Perez C.A.,IEEE Latin America Transactions,2020-02-01,"Image processing is becoming ubiquitous in many activities. This kind of systems use industry-standard libraries, such as OpenCV, and GPGPU techniques such as CUDA and OpenCL. Nowadays, these are being ported to many computing platforms, offering significant processing power even in devices with limited resources. However, the only model that is truly ubiquitous, is the web itself. Modern browsers feature quite complex internals and offer sophisticated development and profiling tools, in order to offer the best user experience. Introduction of HTML5 allows Realtime video and image manipulation, in browser space, without any plugin. In addition, Wasm (web assembly) Javascript execution engine provides fastest possible performance by means of highly customized compiler and runtime, in almost any browser, including embedded ones. This paper presents an image processing system, architected as a modular web application, using only Raspberry PIs with a compact but fast middleware server, that performs all image operations in browser space by means of web assemblies. All components, including database support, can run in a single board, providing image and video processing speeds that match, or surpass, their native compiled C counterparts on the same platform. This solution has a very low cost, that fits with emerging markets, making it ideal for LATAM scenarios.",computer vision | embedded software | image processing | video processing | webRTC,0,311-318,Journal,Article,5.0,"Perez, Carlos Alejandro;Cleva, Mario Sergio;Liska, Diego Orlando;Aquino, Dominga Concepcion;Rodrigues Da Fonseca, Claudio",57216688344;57195634708;57195635890;57195639163;57195634662,Universidad Tecnologica Nacional,Argentina,"image processing is becoming ubiquitous in many activities. this kind of systems use industry-standard libraries, such as opencv, and gpgpu techniques such as cuda and opencl. nowadays, these are being ported to many computing platforms, offering significant processing power even in devices with limited resources. however, the only model that is truly ubiquitous, is the web itself. modern browsers feature quite complex internals and offer sophisticated development and profiling tools, in order to offer the best user experience. introduction of html5 allows realtime video and image manipulation, in browser space, without any plugin. in addition, wasm (web assembly) javascript execution engine provides fastest possible performance by means of highly customized compiler and runtime, in almost any browser, including embedded ones. this paper presents an image processing system, architected as a modular web application, using only raspberry pis with a compact but fast middleware server, that performs all image operations in browser space by means of web assemblies. all components, including database support, can run in a single board, providing image and video processing speeds that match, or surpass, their native compiled c counterparts on the same platform. this solution has a very low cost, that fits with emerging markets, making it ideal for latam scenarios.",low-cost image and video processing using high-performance middleware in single-board computers with open internet standards
550,2-s2.0-85084339111,10.1109/IWSC50091.2020.9047639,Evaluating Performance of Clone Detection Tools in Detecting Cloned Cochange Candidates,Nadim M.,IWSC 2020 - Proceedings of the 2020 IEEE 14th International Workshop on Software Clones,2020-02-01,"Code reuse by copying and pasting from one place to another place in a codebase is a very common scenario in software development which is also one of the most typical reasons for introducing code clones. There is a huge availability of tools to detect such cloned fragments and a lot of studies have already been done for efficient clone detection. There are also several studies for evaluating those tools considering their clone detection effectiveness. Unfortunately, we find no study which compares different clone detection tools in the perspective of detecting cloned co-change candidates during software evolution. Detecting cloned co-change candidates is essential for clone tracking. In this study, we wanted to explore this dimension of code clone research. We used six promising clone detection tools to identify cloned and non-cloned co-change candidates from six C and Java-based subject systems and evaluated the performance of those clone detection tools in detecting the cloned co-change fragments. Our findings show that a good clone detector may not perform well in detecting cloned co-change candidates. The amount of unique lines covered by a clone detector and the number of detected clone fragments plays an important role in its performance. The findings of this study can enrich a new dimension of code clone research.",Clone Detection | Cloned Co-change Candidates | Commit operation | Software Maintenance,2,15-21,Conference Proceeding,Conference Paper,3.0,"Nadim, Md;Mondal, Manishankar;Roy, Chanchal K.",57516873600;7005459894;36176304400,University of Saskatchewan,Canada,"code reuse by copying and pasting from one place to another place in a codebase is a very common scenario in software development which is also one of the most typical reasons for introducing code clones. there is a huge availability of tools to detect such cloned fragments and a lot of studies have already been done for efficient clone detection. there are also several studies for evaluating those tools considering their clone detection effectiveness. unfortunately, we find no study which compares different clone detection tools in the perspective of detecting cloned co-change candidates during software evolution. detecting cloned co-change candidates is essential for clone tracking. in this study, we wanted to explore this dimension of code clone research. we used six promising clone detection tools to identify cloned and non-cloned co-change candidates from six c and java-based subject systems and evaluated the performance of those clone detection tools in detecting the cloned co-change fragments. our findings show that a good clone detector may not perform well in detecting cloned co-change candidates. the amount of unique lines covered by a clone detector and the number of detected clone fragments plays an important role in its performance. the findings of this study can enrich a new dimension of code clone research.",evaluating performance of clone detection tools in detecting cloned cochange candidates
551,2-s2.0-85083718195,10.1109/VST50071.2020.9051638,Do Bug-Fix Types Affect Spectrum-Based Fault Localization Algorithms' Efficiency?,Szatmari A.,"VST 2020 - Proceedings of the 2020 IEEE 3rd International Workshop on Validation, Analysis, and Evolution of Software Tests",2020-02-01,"Finding a bug in the software is an expensive task, however, debugging is a crucial part of the software development life cycle. Spectrum-Based Fault Localization (SBFL) algorithms can reduce the time spent with debugging. Despite the fact that SBFL is a very well researched topic, there are not many tools that implement it. Many studies have dealt with the effectiveness of SBFL algorithms, although these have been evaluated on Java and C++ programming languages. We performed an empirical study on JavaScript programs (using BugsJS benchmark) to evaluate the relationship between algorithms efficiency and the bug-fix types. First we implemented three popular SBFL approaches, i.e. Tarantula, Ochiai and DStar, then examined whether there was a correlation/connection between the positions of the faulty methods in the suspiciousness ranks and bug-fix types. Results show that certain bug-fix types can be significantly differentiated from the others (in both positive and negative direction) based on the fault localization effectiveness of the investigated algorithms.",bug classification | JavaScript | Spectrum-Based Fault Localization | testing and debugging,1,16-23,Conference Proceeding,Conference Paper,3.0,"Szatmari, Attila;Vancsics, Bela;Beszedes, Arpad",57216459496;56705599800;6506259777,Szegedi Tudományegyetem (SZTE),Hungary,"finding a bug in the software is an expensive task, however, debugging is a crucial part of the software development life cycle. spectrum-based fault localization (sbfl) algorithms can reduce the time spent with debugging. despite the fact that sbfl is a very well researched topic, there are not many tools that implement it. many studies have dealt with the effectiveness of sbfl algorithms, although these have been evaluated on java and c++ programming languages. we performed an empirical study on javascript programs (using bugsjs benchmark) to evaluate the relationship between algorithms efficiency and the bug-fix types. first we implemented three popular sbfl approaches, i.e. tarantula, ochiai and dstar, then examined whether there was a correlation/connection between the positions of the faulty methods in the suspiciousness ranks and bug-fix types. results show that certain bug-fix types can be significantly differentiated from the others (in both positive and negative direction) based on the fault localization effectiveness of the investigated algorithms.",do bug-fix types affect spectrum-based fault localization algorithms' efficiency?
552,2-s2.0-85083581789,10.1109/SANER48275.2020.9054842,C-3PR: A Bot for Fixing Static Analysis Violations via Pull Requests,Carvalho A.,"SANER 2020 - Proceedings of the 2020 IEEE 27th International Conference on Software Analysis, Evolution, and Reengineering",2020-02-01,"Static analysis tools are frequently used to detect common programming mistakes or bad practices. Yet, the existing literature reports that these tools are still underused in the industry, which is partly due to (1) the frequent high number of false positives generated, (2) the lack of automated repairing solutions, and (3) the possible mismatches between tools and workflows of development teams. In this study we explored the question: 'How could a bot-based approach allow seamless integration of static analysis tools into developers' workflows?' To this end we introduce C-3PR, an event-based bot infrastructure that automatically proposes fixes to static analysis violations through pull requests (PRs). We have been using C-3PR in an industrial setting for a period of eight months. To evaluate C-3PR usefulness, we monitored its operation in response to 2179 commits to the code base of the tracked projects. The bot autonomously executed 201346 analyses, yielding 610 pull requests. Among them, 346 (57%) were merged into the projects' code bases. We observed that, on average, these PRs are evaluated faster than general-purpose PRs (2.58 and 5.78 business days, respectively). Accepted transformations take even shorter time (1.56 days). Among the reasons for rejection, bugs in C-3PR and in the tools it uses are the most common ones. PRs that require the resolution of a merge conflict are almost always rejected as well. We also conducted a focus group to assess how C-3PR affected the development workflow. We observed that developers perceived C-3PR as efficient, reliable, and useful. For instance, the participants mentioned that, given the chance, they would keep using C-3PR. Our findings bring new evidence that a bot-based infrastructure could mitigate some challenges that hinder the wide adoption of static analysis tools.",bots in software engineering | C-3PR | program manipulation tools | static analysis,12,161-171,Conference Proceeding,Conference Paper,6.0,"Carvalho, Antonio;Luz, Welder;Marcilio, DIego;Bonifacio, Rodrigo;Pinto, Gustavo;DIas Canedo, Edna",57203220748;57204508118;23470131800;23003728900;54941690500;55366708900,Universidade de Brasília;Università della Svizzera italiana;Universidade Federal do Pará,Brazil;Switzerland;Brazil,"static analysis tools are frequently used to detect common programming mistakes or bad practices. yet, the existing literature reports that these tools are still underused in the industry, which is partly due to (1) the frequent high number of false positives generated, (2) the lack of automated repairing solutions, and (3) the possible mismatches between tools and workflows of development teams. in this study we explored the question: 'how could a bot-based approach allow seamless integration of static analysis tools into developers' workflows?' to this end we introduce c-3pr, an event-based bot infrastructure that automatically proposes fixes to static analysis violations through pull requests (prs). we have been using c-3pr in an industrial setting for a period of eight months. to evaluate c-3pr usefulness, we monitored its operation in response to 2179 commits to the code base of the tracked projects. the bot autonomously executed 201346 analyses, yielding 610 pull requests. among them, 346 (57%) were merged into the projects' code bases. we observed that, on average, these prs are evaluated faster than general-purpose prs (2.58 and 5.78 business days, respectively). accepted transformations take even shorter time (1.56 days). among the reasons for rejection, bugs in c-3pr and in the tools it uses are the most common ones. prs that require the resolution of a merge conflict are almost always rejected as well. we also conducted a focus group to assess how c-3pr affected the development workflow. we observed that developers perceived c-3pr as efficient, reliable, and useful. for instance, the participants mentioned that, given the chance, they would keep using c-3pr. our findings bring new evidence that a bot-based infrastructure could mitigate some challenges that hinder the wide adoption of static analysis tools.",c-3pr: a bot for fixing static analysis violations via pull requests
553,2-s2.0-85083572364,10.1109/SANER48275.2020.9054854,JavaScript API Deprecation in the Wild: A First Assessment,Nascimento R.,"SANER 2020 - Proceedings of the 2020 IEEE 27th International Conference on Software Analysis, Evolution, and Reengineering",2020-02-01,"Building an application using third-party libraries is a common practice in software development. As any other software system, code libraries and their APIs evolve over time. In order to help version migration and ensure backward compatibility, a recommended practice during development is to deprecate API. Although studies have been conducted to investigate deprecation in some programming languages, such as Java and C#, there are no detailed studies on API deprecation in the JavaScript ecosystem. This paper provides an initial assessment of API deprecation in JavaScript by analyzing 50 popular software projects. Initial results suggest that the use of deprecation mechanisms in JavaScript packages is low. However, we find five different ways that developers use to deprecate API in the studied projects. Among these solutions, deprecation utility (i.e., any sort of function specially written to aid deprecation) and code comments are the most common practices in JavaScript. Finally, we find that the rate of helpful message is high: 67% of the deprecations have replacement messages to support developers when migrating APIs.",API deprecation | JavaScript | Software Library,7,567-571,Conference Proceeding,Conference Paper,4.0,"Nascimento, Romulo;Brito, Aline;Hora, Andre;Figueiredo, Eduardo",57216459151;57194039093;55205116000;57213806535,Universidade Federal de Minas Gerais,Brazil,"building an application using third-party libraries is a common practice in software development. as any other software system, code libraries and their apis evolve over time. in order to help version migration and ensure backward compatibility, a recommended practice during development is to deprecate api. although studies have been conducted to investigate deprecation in some programming languages, such as java and c#, there are no detailed studies on api deprecation in the javascript ecosystem. this paper provides an initial assessment of api deprecation in javascript by analyzing 50 popular software projects. initial results suggest that the use of deprecation mechanisms in javascript packages is low. however, we find five different ways that developers use to deprecate api in the studied projects. among these solutions, deprecation utility (i.e., any sort of function specially written to aid deprecation) and code comments are the most common practices in javascript. finally, we find that the rate of helpful message is high: 67% of the deprecations have replacement messages to support developers when migrating apis.",javascript api deprecation in the wild: a first assessment
554,2-s2.0-85083107922,10.1109/IBF50092.2020.9034776,Blve: Should the Current Software Version Be Suitable for Release?,Zheng W.,IBF 2020 - Proceedings of the 2020 IEEE 2nd International Workshop on Intelligent Bug Fixing,2020-02-01,"Recently, agile development has become a popular software development method and many version iterations occur during agile development. It is very important to ensure the quality of each software version. However in actual development, it is difficult to know every stage or version about large-scale software development. That means developers do not know exactly which version the current project corresponds to. Simultaneously, there are many necessary requirements for software release in actual development. When we know exactly the version corresponding to the current project, we can know whether the current software version meets the release requirements. Therefore, we need a good software version division method. This paper presents a novel software version division method Blve by using machine learning method. We construct an accurate division model trained with Support Vector Regression method (SVR) to divide software version by processing the data which is commonly recorded in bug list. Then, we process the results of the regression and use the classification indicators for evaluation. In addition, we propose a slope-based approach to optimize the model, and this optimization can improve the accuracy performance measure to about 95%.",Bug List | Regression | Software Repository Mining | Software Version,0,55-63,Conference Proceeding,Conference Paper,6.0,"Zheng, Wei;Chen, Xiaojun;Shi, Zhao;Zhang, Manqing;Chen, Junzheng;Chen, Xiang",56650413300;57218353237;57208837245;57210928814;57208836270;57189091783,Nantong University;Northwestern Polytechnical University,China;China,"recently, agile development has become a popular software development method and many version iterations occur during agile development. it is very important to ensure the quality of each software version. however in actual development, it is difficult to know every stage or version about large-scale software development. that means developers do not know exactly which version the current project corresponds to. simultaneously, there are many necessary requirements for software release in actual development. when we know exactly the version corresponding to the current project, we can know whether the current software version meets the release requirements. therefore, we need a good software version division method. this paper presents a novel software version division method blve by using machine learning method. we construct an accurate division model trained with support vector regression method (svr) to divide software version by processing the data which is commonly recorded in bug list. then, we process the results of the regression and use the classification indicators for evaluation. in addition, we propose a slope-based approach to optimize the model, and this optimization can improve the accuracy performance measure to about 95%.",blve: should the current software version be suitable for release?
558,2-s2.0-85083491493,10.19363/J.cnki.cn10-1380/tn.2020.01.06,Survey of Software Supply Chain Security,He X.,Journal of Cyber Security,2020-01-18,"With the development of information technology industry and the expansion of the demand in software development, the difficulty and complexity of software development are rising continuously, and the major events of software supply chain security occur from time to time. These events show the low-cost as well as efficiency of software supply chain attack and the complexity of software supply chain management, which has led to widespread attention on software security issues, and the research in related field has also entered the initial phase. Starting with the definition and development history of software supply chain security, this paper introduces the background of software supply chain security, divides the software supply chain security problem into two aspects of management and technical problems through the survey and analysis of existing researches, and introduces the current status of software supply chain security from these two aspects. Then, based on the current research status, the current challenges faced by software supply chain security are summarized, and the possible future research direction are pointed out.",Cyber supply chain | Network and information system security | Software security | Software supply chain | Supply chain risk management,0,57-73,Journal,Review,3.0,"He, Xixun;Zhang, Yuqing;Liu, Qixu",57216433804;56027290000;7406291780,University of Chinese Academy of Sciences;Xidian University;Chinese Academy of Sciences,China;China;China,"with the development of information technology industry and the expansion of the demand in software development, the difficulty and complexity of software development are rising continuously, and the major events of software supply chain security occur from time to time. these events show the low-cost as well as efficiency of software supply chain attack and the complexity of software supply chain management, which has led to widespread attention on software security issues, and the research in related field has also entered the initial phase. starting with the definition and development history of software supply chain security, this paper introduces the background of software supply chain security, divides the software supply chain security problem into two aspects of management and technical problems through the survey and analysis of existing researches, and introduces the current status of software supply chain security from these two aspects. then, based on the current research status, the current challenges faced by software supply chain security are summarized, and the possible future research direction are pointed out.",survey of software supply chain security
559,2-s2.0-85088156915,10.1007/978-3-030-36167-9_8,REView: A unified telemetry platform for electric vehicles and charging infrastructure,Lim K.L.,"Connected Vehicles in the Internet of Things: Concepts, Technologies and Frameworks for the IoV",2020-01-13,"Charging stations networks and connected vehicles play a pivotal role in the advent of smart cities and smart grids. A cornerstone of these infrastructures is often a platform or a service that handles the copious amounts of data generated, processes and saves it for monitoring and analyses purposes. In this contribution, we present a software platform, that we named as REView, that automatically collects, analyses, and reviews live and recorded data from electric vehicles (EVs) as well as from EV supply equipment (EVSE or ""charging stations""). It also provides a unified monitoring platform for infrastructures that are both modular and scalable. For analysis purposes, the data described in this chapter has been collected from the Western Australian Electric Vehicle Trial and the WA Charging Station Trial. A secure web portal was also designed with different viewing perspectives for electric vehicle users, charging station users and charging station operators. REView includes presentation of informative statistics about a user's driving efficiency and the energy use of an EV; and then compares the collected data with the average of all other users' similar data. It further includes a smartphone application for live monitoring and producing itemized billing. In this chapter, we discuss the development of REView, including mechanisms to generate and collect the information. Finally, we show and discuss various aspects of the visualized data itself, including charging time, charging duration, energy used, as well as utilization metrics of the charging infrastructure. We promote an open source approach to charging station software development. Our work also illustrates a single-software backend to handle multiple stations from different manufacturers, promoting competition and streamlining the integration of charging technologies into other devices. The results obtained from this network and platform have ultimately enabled us to perform quantitative investigations towards the driving and charging behaviours, as well as the overall electric vehicle trends around Perth in Australia.",Analytics infrastructrue/architecture | Charging station | Charging statistics | Data analytics | Data visualisation | Electric vehicle | Internet of vehicles | Monitoring | Tracking | Web portal,1,167-219,Book,Book Chapter,3.0,"Lim, Kai Li;Speidel, Stuart;Bräunl, Thomas",57200753561;55208265000;6602692836,The University of Western Australia,Australia,"charging stations networks and connected vehicles play a pivotal role in the advent of smart cities and smart grids. a cornerstone of these infrastructures is often a platform or a service that handles the copious amounts of data generated, processes and saves it for monitoring and analyses purposes. in this contribution, we present a software platform, that we named as review, that automatically collects, analyses, and reviews live and recorded data from electric vehicles (evs) as well as from ev supply equipment (evse or ""charging stations""). it also provides a unified monitoring platform for infrastructures that are both modular and scalable. for analysis purposes, the data described in this chapter has been collected from the western australian electric vehicle trial and the wa charging station trial. a secure web portal was also designed with different viewing perspectives for electric vehicle users, charging station users and charging station operators. review includes presentation of informative statistics about a user's driving efficiency and the energy use of an ev; and then compares the collected data with the average of all other users' similar data. it further includes a smartphone application for live monitoring and producing itemized billing. in this chapter, we discuss the development of review, including mechanisms to generate and collect the information. finally, we show and discuss various aspects of the visualized data itself, including charging time, charging duration, energy used, as well as utilization metrics of the charging infrastructure. we promote an open source approach to charging station software development. our work also illustrates a single-software backend to handle multiple stations from different manufacturers, promoting competition and streamlining the integration of charging technologies into other devices. the results obtained from this network and platform have ultimately enabled us to perform quantitative investigations towards the driving and charging behaviours, as well as the overall electric vehicle trends around perth in australia.",review: a unified telemetry platform for electric vehicles and charging infrastructure
565,2-s2.0-85100592387,10.14714/CP96.1645,Florence: A web-based grammar of graphics for making maps and learning cartography,Poorthuis A.,Cartographic Perspectives,2020-01-01,"Online, web-based cartography workflows use a dizzying variety of software suites, libraries, and programming lan-guages. This proliferation of mapmaking technologies, often developed from a software engineering rather than a cartographic foundation, creates a series of challenges for cartography education, research, and practice. To address these challenges, we introduce a JavaScript-based open-source framework for web-based cartography and data visualization. It is built on top of existing open web standards that are already in intensive use for online mapmaking today, but provides a framework that is firmly based on cartographic and visualization theory rather than software engineering concepts. Specifically, we adopt concepts from Bertin’s Semiology of Graphics and Wilkinson’s Grammar of Graphics to create a language with a limited number of core concepts and verbs that are combined in a declarative style of “writing” visualizations. In this paper, we posit a series of design guidelines that have informed our approach, and discuss how we translate these tenets into a software implementation and framework with specific use cases and examples. We frame the development of the software and the discussion specifically in the context of the use of such tools in cartography education. With this framework, we hope to provide an example of a software for web-based data visualization that is in sync with cartographic theories and objectives. Such approaches allow for potentially greater cartographic flexibility and creativity, as well as easier adoption in cartography courses.",Cartography | Education | Geovisualization | Software | Web mapping: grammar of graphics,1,32-50,Journal,Article,5.0,"Poorthuis, Ate;van der Zee, Lucas;Guo, Grace;Keong, Jo Hsi;Dy, Bianchi",37075676000;57221913085;57221142623;57221920312;57221916797,Singapore University of Technology and Design;KU Leuven;Georgia Institute of Technology,Singapore;Belgium;United States,"online, web-based cartography workflows use a dizzying variety of software suites, libraries, and programming lan-guages. this proliferation of mapmaking technologies, often developed from a software engineering rather than a cartographic foundation, creates a series of challenges for cartography education, research, and practice. to address these challenges, we introduce a javascript-based open-source framework for web-based cartography and data visualization. it is built on top of existing open web standards that are already in intensive use for online mapmaking today, but provides a framework that is firmly based on cartographic and visualization theory rather than software engineering concepts. specifically, we adopt concepts from bertin’s semiology of graphics and wilkinson’s grammar of graphics to create a language with a limited number of core concepts and verbs that are combined in a declarative style of “writing” visualizations. in this paper, we posit a series of design guidelines that have informed our approach, and discuss how we translate these tenets into a software implementation and framework with specific use cases and examples. we frame the development of the software and the discussion specifically in the context of the use of such tools in cartography education. with this framework, we hope to provide an example of a software for web-based data visualization that is in sync with cartographic theories and objectives. such approaches allow for potentially greater cartographic flexibility and creativity, as well as easier adoption in cartography courses.",florence: a web-based grammar of graphics for making maps and learning cartography
566,2-s2.0-85100137914,10.3991/IJET.V16I01.16483,Kaanbal: A Mobile Learning Platform Focused on Monitoring and Customization of Learning,Huerta-Guerrero C.,International Journal of Emerging Technologies in Learning,2020-01-01,"Mobile learning is a learning modality characterized by ubiquitously allowing the learning monitoring and customization of students. In this context, several works have proposed software tools; however, these works lack learning monitoring and customization services based on the student's learning styles and context. This paper presents the analysis, design, development, and preliminary usability assessment of a mobile learning platform (Kaanbal), which considers learning styles and context information to provide the professor and student with services for learning monitoring and personalization. Kaanbal is composed of three main components: (1) A mobile learning object generator system, (2) A learning object repository, and (3) A student-oriented mobile application. The integration of these three components allows and facilitates the professor to implement strategies for learning monitoring and customization systematically. We carried out a usability assessment of the learning object generator system through a field study with five graduate-level professors. According to the obtained results, the learning object generator system presents a good acceptance, satisfaction, and applicability from the professors' perspective.",learning customization | learning monitoring | learning styles | Mobile learning objects,1,18-43,Journal,Article,7.0,"Huerta-Guerrero, Cesar;López-Domínguez, Eduardo;Hernández- Velázquez, Yesenia;Domínguez-Isidro, Saúl;Cueto-García, Arturo;De-La-Calleja, Jorge;Medina-Nieto, María Auxilio",57221780368;26664814900;57188955580;48161102800;57214879849;56002753400;57188962918,Universidad Politécnica de Puebla;Laboratorio Nacional de Informática Avanzada,Mexico;Mexico,"mobile learning is a learning modality characterized by ubiquitously allowing the learning monitoring and customization of students. in this context, several works have proposed software tools; however, these works lack learning monitoring and customization services based on the student's learning styles and context. this paper presents the analysis, design, development, and preliminary usability assessment of a mobile learning platform (kaanbal), which considers learning styles and context information to provide the professor and student with services for learning monitoring and personalization. kaanbal is composed of three main components: (1) a mobile learning object generator system, (2) a learning object repository, and (3) a student-oriented mobile application. the integration of these three components allows and facilitates the professor to implement strategies for learning monitoring and customization systematically. we carried out a usability assessment of the learning object generator system through a field study with five graduate-level professors. according to the obtained results, the learning object generator system presents a good acceptance, satisfaction, and applicability from the professors' perspective.",kaanbal: a mobile learning platform focused on monitoring and customization of learning
567,2-s2.0-85099866973,10.1016/j.promfg.2020.10.083,Developing and implementing human-centered information services in a modular production environment,Birtel M.,Procedia Manufacturing,2020-01-01,"New production concepts, like modularization, enable producers to react to customer demands in a more flexible way. With modularization, it is possible to break up production lines into decentralized production modules with individual functionalities. To support human workers on the shop floor of decentralized, modular production environments, they need self-determined access to information. Each worker has his/her own tasks and a specific role within the company. For these tasks, they need information about the production modules and the production process. This paper presents a software architecture, which allows workers to choose the information they need in connection with an interaction that they prefer. An interaction describes, in what way and how often the information is represented to the worker. We define an information service as a triplet of a specific worker, a chosen information and the combined interaction. This paper highlights the development of the software architecture, including its components. The implementation process of the software architecture in (brownfield) modular production environments is shown and validated by showing the process of generating information services to a user's profile. We use OPC UA as communication protocol for the information of the production modules, NoSQL databases to sort the information within the software architecture and JavaScript for the development of the human-centered, web-based frontend. The approach delivers the possibility for a new paradigm of self-determination for shop floor workers in a modular production.",Cyber-Physical production modules | Human-centered asset administration shell | Information service | Modular production,2,592-597,Conference Proceeding,Conference Paper,2.0,"Birtel, Max;Ruskowski, Martin",57193312087;6506335737,Technologie-Initiative SmartFactory KL e. V.;German Research Center for Artificial Intelligence (DFKI),Germany;Germany,"new production concepts, like modularization, enable producers to react to customer demands in a more flexible way. with modularization, it is possible to break up production lines into decentralized production modules with individual functionalities. to support human workers on the shop floor of decentralized, modular production environments, they need self-determined access to information. each worker has his/her own tasks and a specific role within the company. for these tasks, they need information about the production modules and the production process. this paper presents a software architecture, which allows workers to choose the information they need in connection with an interaction that they prefer. an interaction describes, in what way and how often the information is represented to the worker. we define an information service as a triplet of a specific worker, a chosen information and the combined interaction. this paper highlights the development of the software architecture, including its components. the implementation process of the software architecture in (brownfield) modular production environments is shown and validated by showing the process of generating information services to a user's profile. we use opc ua as communication protocol for the information of the production modules, nosql databases to sort the information within the software architecture and javascript for the development of the human-centered, web-based frontend. the approach delivers the possibility for a new paradigm of self-determination for shop floor workers in a modular production.",developing and implementing human-centered information services in a modular production environment
568,2-s2.0-85098864900,10.15587/1729-4061.2020.213989,Building A Model Of Network Interaction Between The Components Of A Multiagent System Of Mobile Robots,Diduk V.,Eastern-European Journal of Enterprise Technologies,2020-01-01,"The results reported here represent the first stage in the development of a full-featured laboratory system aimed at studying machine learning algorithms. The relevance of the current work is predetermined by the lack of network small-size mobile robots and appropriate control software that would make it possible to conduct field experiments in real time. This paper reports the selection of network data transmission technology for managing mobilerobots in real time. Based on the chosen data transmission protocol, a complete stack of technologies of the network model of a multi-agent system of mobile robots has been proposed. This has made it possible to build a network model of the system that visualizes and investigates machine learning algorithms. In accordance with the requirements set by the OSI network model for constructing such systems, the model includes the following levels: 1) the lower level of data collection and controlling elements – mobile robots; 2) the top level of the model includes a user interface server and a business logic support server. Based on the built diagram of the protocol stack and the network model, the software and hardware implementation of the obtained results has been carried out. This paper employed the JavaScript library React with a SPA technology (Single Page Application), a Virtual DOM technology (Document Object Model), stored in the device's RAM and synchronized with the actual DOM. That has made it possible to simplify the process of control over the clients and reduce network traffic. The model provides the opportunity to: 1) manage the prototypes of robot clients in real time; 2) reduce the use of network traffic, compared to other data transmission technologies; 3) reduce the load on the CPU processors of robots and servers; 4) virtually simulate an experiment; 5) investigate the implementation of machine learning algorithms",machine learning | mobile robots | multi-agent systems | network model | WEB interface | WebSocket,0,57-83,Journal,Article,3.0,"Diduk, V.;Hrytsenko, V.;Yeromenko, A.",57221327763;57221335135;57221337880,The Bohdan Khmelnytsky National University of Cherkasy,Ukraine,"the results reported here represent the first stage in the development of a full-featured laboratory system aimed at studying machine learning algorithms. the relevance of the current work is predetermined by the lack of network small-size mobile robots and appropriate control software that would make it possible to conduct field experiments in real time. this paper reports the selection of network data transmission technology for managing mobilerobots in real time. based on the chosen data transmission protocol, a complete stack of technologies of the network model of a multi-agent system of mobile robots has been proposed. this has made it possible to build a network model of the system that visualizes and investigates machine learning algorithms. in accordance with the requirements set by the osi network model for constructing such systems, the model includes the following levels: 1) the lower level of data collection and controlling elements – mobile robots; 2) the top level of the model includes a user interface server and a business logic support server. based on the built diagram of the protocol stack and the network model, the software and hardware implementation of the obtained results has been carried out. this paper employed the javascript library react with a spa technology (single page application), a virtual dom technology (document object model), stored in the device's ram and synchronized with the actual dom. that has made it possible to simplify the process of control over the clients and reduce network traffic. the model provides the opportunity to: 1) manage the prototypes of robot clients in real time; 2) reduce the use of network traffic, compared to other data transmission technologies; 3) reduce the load on the cpu processors of robots and servers; 4) virtually simulate an experiment; 5) investigate the implementation of machine learning algorithms",building a model of network interaction between the components of a multiagent system of mobile robots
569,2-s2.0-85098182686,10.1007/978-3-030-63322-6_7,Development of a Web Application of Facilitate Multidisciplinary Rehabilitation of Children with Cleft Lip and Palate,Dudnik O.V.,Advances in Intelligent Systems and Computing,2020-01-01,"In recent months the priority area of modern medicine has become on-line informatization and computerization. The most promising development has been the use of information and computer support in an integrated diagnostic system for patients with cleft lip and palate. In our research we aim to developed an autonomous web application that allows practitioners to determine the tactics of multidisciplinary diagnosis and treatment based on data integrated into a specific web application in order to increase the efficiency of the treatment of children with cleft lip and palate of different age groups. Based on more than 45 years of clinical and scientific experience in diagnosis and treatment of patients with cleft lip and palate we developed a web application “ADI” (Application of Digital Imaging). The developed web application “ADI” is a system for processing, accumulating and analyzing information on the rehabilitation of patients with cleft lip and palate by type of pathology and age, allowing doctors to obtain structured information about the stages of the necessary methods of interdisciplinary cleft lip and palate diagnosis and treatment. One of the main advantages of “ADI” web application is the ability to quickly exchange information between specialists in various fields of knowledge. Such complex information is the basis for combining scientific ideas, analysis and exchange of experience of various specialists, thereby making it possible to create a unified system of interdisciplinary rehabilitation of children with congenital pathology of the maxillofacial region #COMESYSO1120.",Cleft lip and palate | Dentistry | Information technology | Orthodontic treatment | Surgical treatment | Web application,0,87-101,Book Series,Conference Paper,8.0,"Dudnik, O. V.;Mamedov, Ad A.;Maclennan, A. B.;Volkov, Y. O.;Odzhaggulieva, G. E.;Akhmetkhanov, S. M.A.;Gorlova, N. V.;Guopei, Ma",57219432070;57342912200;57219430790;57215218444;57219432145;57219655480;57219565325;57219572136,Ministry of Health of Russian Federation,Russian Federation,"in recent months the priority area of modern medicine has become on-line informatization and computerization. the most promising development has been the use of information and computer support in an integrated diagnostic system for patients with cleft lip and palate. in our research we aim to developed an autonomous web application that allows practitioners to determine the tactics of multidisciplinary diagnosis and treatment based on data integrated into a specific web application in order to increase the efficiency of the treatment of children with cleft lip and palate of different age groups. based on more than 45 years of clinical and scientific experience in diagnosis and treatment of patients with cleft lip and palate we developed a web application “adi” (application of digital imaging). the developed web application “adi” is a system for processing, accumulating and analyzing information on the rehabilitation of patients with cleft lip and palate by type of pathology and age, allowing doctors to obtain structured information about the stages of the necessary methods of interdisciplinary cleft lip and palate diagnosis and treatment. one of the main advantages of “adi” web application is the ability to quickly exchange information between specialists in various fields of knowledge. such complex information is the basis for combining scientific ideas, analysis and exchange of experience of various specialists, thereby making it possible to create a unified system of interdisciplinary rehabilitation of children with congenital pathology of the maxillofacial region #comesyso1120.",development of a web application of facilitate multidisciplinary rehabilitation of children with cleft lip and palate
570,2-s2.0-85097848754,10.1007/978-3-030-64694-3_9,DeepClone: Modeling Clones to Generate Code Predictions,Hammad M.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2020-01-01,"Programmers often reuse code from source code repositories to reduce the development effort. Code clones are candidates for reuse in exploratory or rapid development, as they represent often repeated functionality in software systems. To facilitate code clone reuse, we propose DeepClone, a novel approach utilizing a deep learning algorithm for modeling code clones to predict the next set of tokens (possibly a complete clone method body) based on the code written so far. The predicted tokens require minimal customization to fit the context. DeepClone applies natural language processing techniques to learn from a large code corpus, and generates code tokens using the model learned. We have quantitatively evaluated our solution to assess (1) our model’s quality and its accuracy in token prediction, and (2) its performance and effectiveness in clone method prediction. We also discuss various application scenarios for our approach.",Code clone | Code prediction | Deep learning | Language modeling,2,135-151,Book Series,Conference Paper,4.0,"Hammad, Muhammad;Babur, Önder;Abdul Basit, Hamid;Brand, Mark van den",56490230800;55949449000;12241632000;26667522200,Technische Universiteit Eindhoven;Prince Sultan University,Netherlands;Saudi Arabia,"programmers often reuse code from source code repositories to reduce the development effort. code clones are candidates for reuse in exploratory or rapid development, as they represent often repeated functionality in software systems. to facilitate code clone reuse, we propose deepclone, a novel approach utilizing a deep learning algorithm for modeling code clones to predict the next set of tokens (possibly a complete clone method body) based on the code written so far. the predicted tokens require minimal customization to fit the context. deepclone applies natural language processing techniques to learn from a large code corpus, and generates code tokens using the model learned. we have quantitatively evaluated our solution to assess (1) our model’s quality and its accuracy in token prediction, and (2) its performance and effectiveness in clone method prediction. we also discuss various application scenarios for our approach.",deepclone: modeling clones to generate code predictions
572,2-s2.0-85097367559,10.17586/2226-1494-2020-20-2-233-242,Search methods for abnormal activities of web applications,Mikheeva O.I.,"Scientific and Technical Journal of Information Technologies, Mechanics and Optics",2020-01-01,"Subject of Research. The paper presents a review of existing detection methods for abnormal activities of web applications. Comparative characteristics are given. Priorities for improving information security tools in web applications are shown. Method. For evaluation of search methods for abnormal activities of web applications, criteria for selecting indicators were defined. Particular attention was paid to such indicators as: the launching speed of web applications after loading, web application responsiveness to user actions and the number of abnormal activities found in comparison with the number of malfunctions found. Three methods of searching for abnormal activities were compared: statistical code scanning, dynamic code scanning and network traffic monitoring. We considered advantages and disadvantages of each method and implementation examples. Main Results. It is shown that the dynamic method of searching for abnormal activities has the best characteristics. The method provides the identification of anomalies associated with traffic transfer and anomalies that occur during the local operation of web applications. The method is implemented as a code analyzer built into the browser engine. The analyzer checks all calls of the web application to the engine and detects abnormal activity based on such calls. In contrast to static scanning, dynamic scanning identifies anomalies in Web Workers, WebAssembly and in the parts of code that are downloaded over the network after the application starts. Practical Relevance. The work can be useful to information security specialists who deal with the problems of protecting web applications, as well as programmers and system administrators at application creation and implementation stage. The results of the work can find practical use in the development of web applications, browsers, and information protection software.",Abnormal activity | Browser | Browser engine | Dynamic code analysis | JavaScript engine | Search for abnormal activities | Static code analysis | Traffic analysis between client and server | Web applications,0,233-242,Journal,Article,5.0,"Mikheeva, O. I.;Gatchin, Yu A.;Savkov, S. V.;Khammatova, R. M.;Nyrkov, A. P.",57220576403;56127302800;57212837033;57220591018;57548650500,"Admiral Makarov State University of Maritime and Inland Shipping;Saint Petersburg National Research University of Information Technologies, Mechanics and Optics University ITMO;ZAO Mobicon;LLC Gazinformservice",Russian Federation;Russian Federation;Russian Federation;Russian Federation,"subject of research. the paper presents a review of existing detection methods for abnormal activities of web applications. comparative characteristics are given. priorities for improving information security tools in web applications are shown. method. for evaluation of search methods for abnormal activities of web applications, criteria for selecting indicators were defined. particular attention was paid to such indicators as: the launching speed of web applications after loading, web application responsiveness to user actions and the number of abnormal activities found in comparison with the number of malfunctions found. three methods of searching for abnormal activities were compared: statistical code scanning, dynamic code scanning and network traffic monitoring. we considered advantages and disadvantages of each method and implementation examples. main results. it is shown that the dynamic method of searching for abnormal activities has the best characteristics. the method provides the identification of anomalies associated with traffic transfer and anomalies that occur during the local operation of web applications. the method is implemented as a code analyzer built into the browser engine. the analyzer checks all calls of the web application to the engine and detects abnormal activity based on such calls. in contrast to static scanning, dynamic scanning identifies anomalies in web workers, webassembly and in the parts of code that are downloaded over the network after the application starts. practical relevance. the work can be useful to information security specialists who deal with the problems of protecting web applications, as well as programmers and system administrators at application creation and implementation stage. the results of the work can find practical use in the development of web applications, browsers, and information protection software.",search methods for abnormal activities of web applications
573,2-s2.0-85097223472,10.3233/AIS-200580,Lantern: A domain specific language for energy awareness in smart-homes,Robinson J.,Journal of Ambient Intelligence and Smart Environments,2020-01-01,"This paper argues that energy consideration should be central to software development. It speculates that including the notion of energy awareness in programming language design for domain specific languages (DSLs) is a novel way in which energy-aware and energy-efficient applications can be developed. It outlines the design criteria and rationale for using a language-focused approach for energy-awareness. It proposes Lantern, a DSL for supporting energy awareness in Cyber-Physical Systems software development. Lantern allows the development of applications that better manage and reduce the carbon footprint of devices. The design of Lantern is aimed at supporting the general development of Cyber-Physical Systems. This paper focuses on the scenario of smart homes, using statically defined locations within a specified environment.",distributed systems | energy awareness | Home automation,0,531-546,Journal,Article,3.0,"Robinson, Jon;Lee, Kevin;Appiah, Kofi",57198433714;35762723800;14321283500,Deakin University;University of York;Nottingham Trent University,Australia;United Kingdom;United Kingdom,"this paper argues that energy consideration should be central to software development. it speculates that including the notion of energy awareness in programming language design for domain specific languages (dsls) is a novel way in which energy-aware and energy-efficient applications can be developed. it outlines the design criteria and rationale for using a language-focused approach for energy-awareness. it proposes lantern, a dsl for supporting energy awareness in cyber-physical systems software development. lantern allows the development of applications that better manage and reduce the carbon footprint of devices. the design of lantern is aimed at supporting the general development of cyber-physical systems. this paper focuses on the scenario of smart homes, using statically defined locations within a specified environment.",lantern: a domain specific language for energy awareness in smart-homes
574,2-s2.0-85092465157,10.3991/ijim.v14i16.11454,A proposed framework of campus-oriented online text messaging system,Syaifudin Y.W.,International Journal of Interactive Mobile Technologies,2020-01-01,"Nowadays, the rapid advancement of mobile software development has triggered to emerge of more online text messaging applications. In the environment of higher education institutions, it is also widely utilized to support the communication process between campus members. This research proposed a system of campus-specific online text messaging that is expected to improve academic activities. As a case study, the system was implemented using React Native framework and Push Notification Service for use in State Polytechnic of Malang, Indonesia. The system consists of three main subsystems that work together, including Client Application, Server Application, and Push Notification Manager. To evaluate the proposed system, we conducted a survey. The result of the user satisfaction test shows that most users consisting of teachers, staff, management representative, and students felt more helped in the communication process in the campus environment.",Higher education | Mobile application | Push notification | Text messaging,2,194-209,Journal,Article,6.0,"Syaifudin, Yan Watequlis;Yunhasnawa, Yoppy;Pramitarini, Yushintia;Setiawan, Awan;Rohadi, Erfan;Saputra, Pramana Yoga",57194068863;57193494627;57219384714;57211781828;24484183400;57203957877,State Polytechnic of Malang,Indonesia,"nowadays, the rapid advancement of mobile software development has triggered to emerge of more online text messaging applications. in the environment of higher education institutions, it is also widely utilized to support the communication process between campus members. this research proposed a system of campus-specific online text messaging that is expected to improve academic activities. as a case study, the system was implemented using react native framework and push notification service for use in state polytechnic of malang, indonesia. the system consists of three main subsystems that work together, including client application, server application, and push notification manager. to evaluate the proposed system, we conducted a survey. the result of the user satisfaction test shows that most users consisting of teachers, staff, management representative, and students felt more helped in the communication process in the campus environment.",a proposed framework of campus-oriented online text messaging system
575,2-s2.0-85092243334,10.1007/978-3-030-58811-3_62,Cross-Project Vulnerability Prediction Based on Software Metrics and Deep Learning,Kalouptsoglou I.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2020-01-01,"Vulnerability prediction constitutes a mechanism that enables the identification and mitigation of software vulnerabilities early enough in the development cycle, improving the security of software products, which is an important quality attribute according to ISO/IEC 25010. Although existing vulnerability prediction models have demonstrated sufficient accuracy in predicting the occurrence of vulnerabilities in the software projects with which they have been trained, they have failed to demonstrate sufficient accuracy in cross-project prediction. To this end, in the present paper we investigate whether the adoption of deep learning along with software metrics may lead to more accurate cross-project vulnerability prediction. For this purpose, several machine learning (including deep learning) models are constructed, evaluated, and compared based on a dataset of popular real-world PHP software applications. Feature selection is also applied with the purpose to examine whether it has an impact on cross-project prediction. The results of our analysis indicate that the adoption of software metrics and deep learning may result in vulnerability prediction models with sufficient performance in cross-project vulnerability prediction. Another interesting conclusion is that the performance of the models in cross-project prediction is enhanced when the projects exhibit similar characteristics with respect to their software metrics.",Security | Software quality | Vulnerability prediction,5,877-893,Book Series,Conference Paper,4.0,"Kalouptsoglou, Ilias;Siavvas, Miltiadis;Tsoukalas, Dimitrios;Kehagias, Dionysios",57219327969;57194500913;57208865760;7003972544,Center For Research And Technology - Hellas,Greece,"vulnerability prediction constitutes a mechanism that enables the identification and mitigation of software vulnerabilities early enough in the development cycle, improving the security of software products, which is an important quality attribute according to iso/iec 25010. although existing vulnerability prediction models have demonstrated sufficient accuracy in predicting the occurrence of vulnerabilities in the software projects with which they have been trained, they have failed to demonstrate sufficient accuracy in cross-project prediction. to this end, in the present paper we investigate whether the adoption of deep learning along with software metrics may lead to more accurate cross-project vulnerability prediction. for this purpose, several machine learning (including deep learning) models are constructed, evaluated, and compared based on a dataset of popular real-world php software applications. feature selection is also applied with the purpose to examine whether it has an impact on cross-project prediction. the results of our analysis indicate that the adoption of software metrics and deep learning may result in vulnerability prediction models with sufficient performance in cross-project vulnerability prediction. another interesting conclusion is that the performance of the models in cross-project prediction is enhanced when the projects exhibit similar characteristics with respect to their software metrics.",cross-project vulnerability prediction based on software metrics and deep learning
576,2-s2.0-85091899577,10.14569/IJACSA.2020.0110966,Development of a graphic information system applied to quality statistic control in production processes,Vázquez L.,International Journal of Advanced Computer Science and Applications,2020-01-01,"One of the advantages that organizations have when using an Information System is the control of their activities. This article develops an Information System that will allow an organization to graphically obtain the real results of a production process by applying Nelson's eight rules to determine if any measured variable is out of control. The software architecture pattern used is the Model View Controller (MVC) to keep the functionality of the application separate. The front-end, that is, the part that interacts with the users, was developed in ASP. NET as a web platform to provide the required services, JavaScript, HTML 5, Razor and Bootstrap. The back-end, which is the part that processes the entry of the front-end and performs the calculations, operations, communication with the database and reading of files, was developed with the C sharp programming language, the SQL Server database management system and the entity framework. As a result, the system sends an e-mail as an alarm with an explanation of what has happened when it detects that some measured variable is out of control by applying Nelson's rules. This allows the organization to make effective decisions in the processes involved.",ASP. NET | C# | Information system | Model view controller pattern | Nelson's rules,0,552-558,Journal,Article,4.0,"Vázquez, Laura;Valdez, Alicia;Cortes, Griselda;Rosales, Mariana",57202835923;57110051800;57110036100;57219253520,Universidad Autonoma de Coahuila,Mexico,"one of the advantages that organizations have when using an information system is the control of their activities. this article develops an information system that will allow an organization to graphically obtain the real results of a production process by applying nelson's eight rules to determine if any measured variable is out of control. the software architecture pattern used is the model view controller (mvc) to keep the functionality of the application separate. the front-end, that is, the part that interacts with the users, was developed in asp. net as a web platform to provide the required services, javascript, html 5, razor and bootstrap. the back-end, which is the part that processes the entry of the front-end and performs the calculations, operations, communication with the database and reading of files, was developed with the c sharp programming language, the sql server database management system and the entity framework. as a result, the system sends an e-mail as an alarm with an explanation of what has happened when it detects that some measured variable is out of control by applying nelson's rules. this allows the organization to make effective decisions in the processes involved.",development of a graphic information system applied to quality statistic control in production processes
577,2-s2.0-85091578396,10.1007/978-3-030-59592-0_5,On the Diffusion and Impact of Code Smells in Web Applications,Bessghaier N.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2020-01-01,"Web applications (web apps) have become one of the largest parts of the current software market over years. Modern web apps offer several business benefits over other traditional and standalone applications. Mainly, cross-platform compatibility and data integration are some of the critical features that encouraged businesses to shift towards the adoption of Web apps. Web apps are evolving rapidly to acquire new features, correct errors or adapt to new environment changes especially with the volatile context of the web development. These ongoing amends often affect software quality due to poor coding and bad design practices, known as code smells or anti-patterns. The presence of code smells in a software project is widely considered as form of technical debt and makes the software harder to understand, maintain and evolve, besides leading to failures and unforeseen costs. Therefore, it is critical for web apps to monitor the existence and spread of such anti-patterns. In this paper, we specifically target web apps built with PHP being the most used server-side programming language. We conduct the first empirical study to investigate the diffuseness of code smells in Web apps and their relationship with the change proneness of affected code. We detect 12 types of common code smells across a total of 223 releases of 5 popular and long-lived open-source web apps. The key findings of our study include: 1) complex and large classes and methods are frequently committed in PHP files, 2) smelly files are more prone to change than non-smelly files, and 3) Too Many Methods and High Coupling are the most associated smells with files change-proneness.",Change proneness | Code smells | Diffuseness | PHP | Web applications,2,67-84,Book Series,Conference Paper,3.0,"Bessghaier, Narjes;Ouni, Ali;Mkaouer, Mohamed Wiem",57201776805;50761492200;55904259300,École de Technologie Supérieure;Rochester Institute of Technology,Canada;United States,"web applications (web apps) have become one of the largest parts of the current software market over years. modern web apps offer several business benefits over other traditional and standalone applications. mainly, cross-platform compatibility and data integration are some of the critical features that encouraged businesses to shift towards the adoption of web apps. web apps are evolving rapidly to acquire new features, correct errors or adapt to new environment changes especially with the volatile context of the web development. these ongoing amends often affect software quality due to poor coding and bad design practices, known as code smells or anti-patterns. the presence of code smells in a software project is widely considered as form of technical debt and makes the software harder to understand, maintain and evolve, besides leading to failures and unforeseen costs. therefore, it is critical for web apps to monitor the existence and spread of such anti-patterns. in this paper, we specifically target web apps built with php being the most used server-side programming language. we conduct the first empirical study to investigate the diffuseness of code smells in web apps and their relationship with the change proneness of affected code. we detect 12 types of common code smells across a total of 223 releases of 5 popular and long-lived open-source web apps. the key findings of our study include: 1) complex and large classes and methods are frequently committed in php files, 2) smelly files are more prone to change than non-smelly files, and 3) too many methods and high coupling are the most associated smells with files change-proneness.",on the diffusion and impact of code smells in web applications
583,2-s2.0-85090507713,10.18293/SEKE2020-067,Evaluating the usefulness and ease of use of an experimentation definition language,Auer F.,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",2020-01-01,"Before any online controlled experiment, a hypothesis has to be formulated. Moreover, the design, execution, and analysis have to be planned. Given that the definition of an experiment varies considerably amongst experimentation platforms, no common experiment definition exists. Furthermore, there is to the best of the authors' knowledge no platform-independent experiment definition model proposed in the literature. Thus, we aim to propose an experimentation definition language and evaluate its usefulness and ease of use. Therefore, we developed a domain-specific language based on the results of a previous study and conducted a technology acceptance model study with 30 participants. It revealed that the proposed experiment definition language is considered useful amongst the majority of participants. Moreover, most of the participants rated the language easy to use. Participants without prior knowledge of the domain-specific language's host language (JSON - JavaScript Object Notation) rated the language considerably less easy to use. To conclude, the proposed experimentation definition language supports practitioners in their experimentation process by providing them a structure and pointing them out to experiment characteristics that could be considered. Furthermore, the machine-readable definition of experiments represents a first step for many research directions, like the automated verification of experiments, or the development of an experiment knowledge base.",Continuous experimentation | Domain-specific language | Online controlled experiment definition | Technology acceptance model,4,158-163,Conference Proceeding,Conference Paper,2.0,"Auer, Florian;Felderer, Michael",57193025642;24832720900,Universität Innsbruck,Austria,"before any online controlled experiment, a hypothesis has to be formulated. moreover, the design, execution, and analysis have to be planned. given that the definition of an experiment varies considerably amongst experimentation platforms, no common experiment definition exists. furthermore, there is to the best of the authors' knowledge no platform-independent experiment definition model proposed in the literature. thus, we aim to propose an experimentation definition language and evaluate its usefulness and ease of use. therefore, we developed a domain-specific language based on the results of a previous study and conducted a technology acceptance model study with 30 participants. it revealed that the proposed experiment definition language is considered useful amongst the majority of participants. moreover, most of the participants rated the language easy to use. participants without prior knowledge of the domain-specific language's host language (json - javascript object notation) rated the language considerably less easy to use. to conclude, the proposed experimentation definition language supports practitioners in their experimentation process by providing them a structure and pointing them out to experiment characteristics that could be considered. furthermore, the machine-readable definition of experiments represents a first step for many research directions, like the automated verification of experiments, or the development of an experiment knowledge base.",evaluating the usefulness and ease of use of an experimentation definition language
584,2-s2.0-85089719112,10.1007/978-3-030-57663-9_23,Automated cross-language integration based on formal model of components,Aleksyuk A.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2020-01-01,"The paper presents the research aimed at development of a new method for integration of software components written in different languages, which allows omitting glue code manual writing. The necessity to write additional project-specific linking logic requires that programmers have at least good knowledge of two languages. Therefore, it is rather difficult to reuse well-tested libraries and other software components written in other languages in spite of the benefits, which they can offer. The paper analyzes advantages and disadvantages of the previously developed methods and tools intended for linking software components. The proposed method is based on the RPC approach, augmented with the LibSL language, previously created by the authors of the research that is designed to describe the software components external interface. The description of the external interface allows generating all the glue code automatically. Based on the offered method, the tool that supports C, Java, Kotlin, Go, and JavaScript was developed. Applicability and efficiency of the proposed solution was tested by creation of the LibSL descriptions and stubs generation for a set of real-world libraries, such as a Z3 SMT solver.",Cross-language integration | Language interoperability | Library models,0,357-370,Book Series,Conference Paper,2.0,"Aleksyuk, Artyom;Itsykson, Vladimir",57207566149;36237396900,Peter the Great St. Petersburg Polytechnic University,Russian Federation,"the paper presents the research aimed at development of a new method for integration of software components written in different languages, which allows omitting glue code manual writing. the necessity to write additional project-specific linking logic requires that programmers have at least good knowledge of two languages. therefore, it is rather difficult to reuse well-tested libraries and other software components written in other languages in spite of the benefits, which they can offer. the paper analyzes advantages and disadvantages of the previously developed methods and tools intended for linking software components. the proposed method is based on the rpc approach, augmented with the libsl language, previously created by the authors of the research that is designed to describe the software components external interface. the description of the external interface allows generating all the glue code automatically. based on the offered method, the tool that supports c, java, kotlin, go, and javascript was developed. applicability and efficiency of the proposed solution was tested by creation of the libsl descriptions and stubs generation for a set of real-world libraries, such as a z3 smt solver.",automated cross-language integration based on formal model of components
585,2-s2.0-85089718700,10.1007/978-3-030-54997-8_14,Challenges faced by students in an open source software undergraduate course,Issa D.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2020-01-01,"The Open Source Software (OSS) development is gaining popularity from year to year, however, entering the OSS community still remains a challenging task. In this work, we describe challenges faced by a beginner OSS code-developer during the first contribution. Additionally, we analyze our experience and offer hints for potential newcomers. Whole work was done as the project of the Open Source Software undergraduate course at the Computer Department of Nazarbayev University.",Code developer | Open Source Software | OSS challenges,0,209-223,Book Series,Conference Paper,1.0,"Issa, Dias",57233641100,Nazarbayev University,Kazakhstan,"the open source software (oss) development is gaining popularity from year to year, however, entering the oss community still remains a challenging task. in this work, we describe challenges faced by a beginner oss code-developer during the first contribution. additionally, we analyze our experience and offer hints for potential newcomers. whole work was done as the project of the open source software undergraduate course at the computer department of nazarbayev university.",challenges faced by students in an open source software undergraduate course
588,2-s2.0-85087736600,10.1016/bs.pbr.2020.06.005,"More time for science: Using Testable to create and share behavioral experiments faster, recruit better participants, and engage students in hands-on research",Rezlescu C.,Progress in Brain Research,2020-01-01,"A major pain for researchers in all fields is that they have less and less time for actual science activities: reading, thinking, coming up with new theories and hypotheses, testing, analyzing data, writing. In psychology, three of the most time-consuming nonactual science activities are: learning how to program an experiment, recruiting participants, and preparing teaching materials. Testable (www.testable.org) provides a suite of academic tools to speed things up considerably. The Testable software allows the development of most psychology experiments in minutes, using a natural language form and a spreadsheet. Furthermore, any experiment can be easily converted into a social experiment in Testable Arena, with multiple participants interacting and viewing each other's responses. Experiments can then be published to Testable Library, a public repository for demonstration and sharing purposes. Participants can be recruited from Testable Minds, the subject pool with the most advanced participants verification system. Testable Minds employs multiple checks (such as face authentication) to ensure participants have accurate demographics (age, sex, location), are human, unique, and reliable. Finally, the Testable Class module can be used to teach psychology through experiments. It features over 50 ready-made classic psychology experiments, fully customizable, which instructors can add to their classes, together with their own experiments. These experiments can then be made available to students to do, import, modify, and use to collect data as part of their class. These Testable tools, backed up by a strong team of academic advisors and thousands of users, can save psychology researchers and other behavioral scientists valuable time for science.",Behavioral research | Online studies | Participant pool | Psychology experiments | Social experiments | Teaching psychology,15,243-262,Book Series,Book Chapter,4.0,"Rezlescu, Constantin;Danaila, Iulian;Miron, Alexandru;Amariei, Ciprian",55151544000;57217857764;57217855448;57194835481,University College London;Universitatea Alexandru Ioan Cuza;Testable,United Kingdom;Romania;Romania,"a major pain for researchers in all fields is that they have less and less time for actual science activities: reading, thinking, coming up with new theories and hypotheses, testing, analyzing data, writing. in psychology, three of the most time-consuming nonactual science activities are: learning how to program an experiment, recruiting participants, and preparing teaching materials. testable (www.testable.org) provides a suite of academic tools to speed things up considerably. the testable software allows the development of most psychology experiments in minutes, using a natural language form and a spreadsheet. furthermore, any experiment can be easily converted into a social experiment in testable arena, with multiple participants interacting and viewing each other's responses. experiments can then be published to testable library, a public repository for demonstration and sharing purposes. participants can be recruited from testable minds, the subject pool with the most advanced participants verification system. testable minds employs multiple checks (such as face authentication) to ensure participants have accurate demographics (age, sex, location), are human, unique, and reliable. finally, the testable class module can be used to teach psychology through experiments. it features over 50 ready-made classic psychology experiments, fully customizable, which instructors can add to their classes, together with their own experiments. these experiments can then be made available to students to do, import, modify, and use to collect data as part of their class. these testable tools, backed up by a strong team of academic advisors and thousands of users, can save psychology researchers and other behavioral scientists valuable time for science.","more time for science: using testable to create and share behavioral experiments faster, recruit better participants, and engage students in hands-on research"
591,2-s2.0-85086145249,10.1007/978-3-030-49392-9_16,Examining the Current State of System Testing Methodologies in Quality Assurance,Sophocleous R.,Lecture Notes in Business Information Processing,2020-01-01,"Testing is an important phase of every software system, as it can reveal defects early and contribute to achieving high software quality. In this process of quality assurance, organizations are usually relying on one testing technique. However, a combination of techniques may prove more beneficial to the organization, as it might give the chance to discover a larger number of defects early. In order to examine the above, in the current work we present a survey on the use of system testing methodologies. We have gathered data from 252 individuals that reveal current trends in testing, such as whether requirements are used in the test case definition and whether the testing techniques used are affected by parameters, such as years of experience, whereas we examine the combination of smoke testing and regression testing. We also demonstrate an industrial use case, where this combination was applied, reducing the number of defects identified by the customer.",Agile development | Regression testing | Smoke testing | Software testing,1,240-249,Book Series,Conference Paper,2.0,"Sophocleous, Rafaela;Kapitsaki, Georgia M.",57217088809;24801845800,University of Cyprus,Cyprus,"testing is an important phase of every software system, as it can reveal defects early and contribute to achieving high software quality. in this process of quality assurance, organizations are usually relying on one testing technique. however, a combination of techniques may prove more beneficial to the organization, as it might give the chance to discover a larger number of defects early. in order to examine the above, in the current work we present a survey on the use of system testing methodologies. we have gathered data from 252 individuals that reveal current trends in testing, such as whether requirements are used in the test case definition and whether the testing techniques used are affected by parameters, such as years of experience, whereas we examine the combination of smoke testing and regression testing. we also demonstrate an industrial use case, where this combination was applied, reducing the number of defects identified by the customer.",examining the current state of system testing methodologies in quality assurance
595,2-s2.0-85084033151,10.1109/KST48564.2020.9059351,Business-intelligence framework for visualization and its associate text narration,Wutthikhet C.,KST 2020 - 2020 12th International Conference on Knowledge and Smart Technology,2020-01-01,"Business-Intelligence (BI) tools have become an integral part in data-driven organizations as it can transform raw data into visual reports to support decision makings. While a picture is worth a thousand words, interpreting visualized information sometimes leads to miscommunication between author and readers since an image chart may have many interesting features and readers may perceive different points of view from the author. Text narration can provide additional detailed descriptive on the topics of interest but requires reading time. To convey points of interest to readers without reducing the effectiveness of chart visualization, synergizing between visualization and its associate text narration is required. In this paper, a design of business-intelligence framework for data visualization and its associate text narration is presented. The key idea is to highlight related chart as response to reading (mouse) position on text area and vice versa. The framework is implemented as a JavaScript wrapper which acts as a relationship control between charts and texts. The wrapper can manipulate various software libraries to work together, thus reducing the complexity in the development. The comparisons between web pages from renowned web sites such as WorldBank.org and ones generated from our proposed framework using similar layout and data demonstrates that the design meet expected outcomes",Business intelligence | Dashboard design | Human-computer interaction | Narrative visualization,1,75-79,Conference Proceeding,Conference Paper,3.0,"Wutthikhet, Chutima;Phisanbut, Nalina;Piamsa-Nga, Punpiti",57216612126;14831719900;55663804300,Kasetsart University,Thailand,"business-intelligence (bi) tools have become an integral part in data-driven organizations as it can transform raw data into visual reports to support decision makings. while a picture is worth a thousand words, interpreting visualized information sometimes leads to miscommunication between author and readers since an image chart may have many interesting features and readers may perceive different points of view from the author. text narration can provide additional detailed descriptive on the topics of interest but requires reading time. to convey points of interest to readers without reducing the effectiveness of chart visualization, synergizing between visualization and its associate text narration is required. in this paper, a design of business-intelligence framework for data visualization and its associate text narration is presented. the key idea is to highlight related chart as response to reading (mouse) position on text area and vice versa. the framework is implemented as a javascript wrapper which acts as a relationship control between charts and texts. the wrapper can manipulate various software libraries to work together, thus reducing the complexity in the development. the comparisons between web pages from renowned web sites such as worldbank.org and ones generated from our proposed framework using similar layout and data demonstrates that the design meet expected outcomes",business-intelligence framework for visualization and its associate text narration
599,2-s2.0-85083445675,10.1007/978-3-030-39746-3_51,IntelligentBox for Web-Based VR Applications (WebIBVR) and Its Collaborative Virtual Environments,Okada Y.,Lecture Notes on Data Engineering and Communications Technologies,2020-01-01,"This paper treats an interactive 3D graphics software development system called IntelligentBox and its extended version for Web-based VR applications called WebIBVR. WebIBVR consists of two main components, a client side part and a server side part. The server side part is almost the same as the original IntelligentBox. Its difference from the original IntelligentBox is functionality of off-screen rendering of 3D scenes and communication with a client side part. The client side part is a JavaScript program runs on a Web-browser and displays the images of 3D scenes sent from the server side. The client side part provides several functionalities for VR applications, i.e., stereo view support and multi-angle view support for a Head Mounted Display (HMD) of a VR goggle with a smartphone. Multiple HMDs can share the same view image of a 3D scene generated by server side IntelligentBox. However, the server side IntelligentBox cannot generate multiple different view images of a 3D scene correspond to the orientation of each of multiple HMDs because it needs much time and the interactivity becomes worse. To overcome this, in this paper the authors proposes the use of multiple server side IntelligentBoxes to generate multiple different view images of a common 3D scene at once by communicating with each other using RoomBox, one of the special purpose components of original IntelligentBox used for building collaborative virtual environments. This paper also explains the performance improvement of image transmission from a server side to a client side.",3D graphics | Component ware | Development systems | Virtual Reality | Web contents,2,503-515,Book Series,Book Chapter,2.0,"Okada, Yoshihiro;Ura, Taiki",7404465193;57216414325,Kyushu University,Japan,"this paper treats an interactive 3d graphics software development system called intelligentbox and its extended version for web-based vr applications called webibvr. webibvr consists of two main components, a client side part and a server side part. the server side part is almost the same as the original intelligentbox. its difference from the original intelligentbox is functionality of off-screen rendering of 3d scenes and communication with a client side part. the client side part is a javascript program runs on a web-browser and displays the images of 3d scenes sent from the server side. the client side part provides several functionalities for vr applications, i.e., stereo view support and multi-angle view support for a head mounted display (hmd) of a vr goggle with a smartphone. multiple hmds can share the same view image of a 3d scene generated by server side intelligentbox. however, the server side intelligentbox cannot generate multiple different view images of a 3d scene correspond to the orientation of each of multiple hmds because it needs much time and the interactivity becomes worse. to overcome this, in this paper the authors proposes the use of multiple server side intelligentboxes to generate multiple different view images of a common 3d scene at once by communicating with each other using roombox, one of the special purpose components of original intelligentbox used for building collaborative virtual environments. this paper also explains the performance improvement of image transmission from a server side to a client side.",intelligentbox for web-based vr applications (webibvr) and its collaborative virtual environments
604,2-s2.0-85082987838,10.1109/EIConRus49466.2020.9039515,Development of the Program for Creating Data Accounting Software Systems Mockups,Korytov P.V.,"Proceedings of the 2020 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering, EIConRus 2020",2020-01-01,"The paper explores the possibility of automated generation of data accounting systems. Authors describe the possibility of existing software application, such as database design tools, commercial application creators, as well as advantages and disadvantages of alternative solutions. As existing analogues do not fully solve the task, authors propose own solution for generating a software system and a data model of relational DBMS based on the entity-relationship model, written in the XML format. The paper describes the architecture of the solution and implementation details.Authors show main steps of the system creation process based on simple domain area example, as well as the performance metrics, depending on content structure and size for the generated system, discover bottlenecks and their causes.",code generation | entity-relationship model | software mockup,1,359-362,Conference Proceeding,Conference Paper,4.0,"Korytov, Pavel V.;Belyaev, Sergey A.;Ekalo, Aleksandr V.;Postnikov, Evgeniy V.",57216271694;57194239959;9734969400;27968015700,Sankt-Peterburgskij Gosudarstvennyj Elektrotehniceskij Universitet,Russian Federation,"the paper explores the possibility of automated generation of data accounting systems. authors describe the possibility of existing software application, such as database design tools, commercial application creators, as well as advantages and disadvantages of alternative solutions. as existing analogues do not fully solve the task, authors propose own solution for generating a software system and a data model of relational dbms based on the entity-relationship model, written in the xml format. the paper describes the architecture of the solution and implementation details.authors show main steps of the system creation process based on simple domain area example, as well as the performance metrics, depending on content structure and size for the generated system, discover bottlenecks and their causes.",development of the program for creating data accounting software systems mockups
606,2-s2.0-85081563446,10.1016/j.procir.2020.01.017,Microservice-based architecture for engineering tools enabling a collaborative multi-user configuration of robot-based automation solutions,Schäffer E.,Procedia CIRP,2020-01-01,"Microservice (MS) architectures, especially in combination with micro front ends, are a modern, scalable and sustainable approach to software development. The modular development of individual components and the possibility of a simple, collaborative and iterative development represent a strategic advantage for companies. In addition, the MS approach allows the consistent use of current technologies, whereby new software functionalities can constantly be included. In this paper, the potentials of MS for engineering tools are shown using the example of a web-based configurator for robot-based automation solutions. On the one hand, the implemented prototype illustrates a possible MS architecture pattern and, on the other hand, clarifies how new functionalities such as the collaborative multi-user configuration or different role-based configuration sessions are enabled by such a concept. Using the example of the web-based configuration platform, it is finally shown how a MS architecture contributes to better development and easier deployment of engineering software solutions based on the divide and conquer principle.",Architecture | Collaborative | Configuration | Engineering tool | Micro front end | Microservice | Multi-user | Robotic automation system,13,86-91,Conference Proceeding,Conference Paper,6.0,"Schäffer, Eike;Mayr, Andreas;Fuchs, Jonathan;Sjarov, Martin;Vorndran, Johannes;Franke, Jörg",55785202700;57221362181;57209686651;57215656954;57215652181;57169710000,Friedrich-Alexander-Universität Erlangen-Nürnberg,Germany,"microservice (ms) architectures, especially in combination with micro front ends, are a modern, scalable and sustainable approach to software development. the modular development of individual components and the possibility of a simple, collaborative and iterative development represent a strategic advantage for companies. in addition, the ms approach allows the consistent use of current technologies, whereby new software functionalities can constantly be included. in this paper, the potentials of ms for engineering tools are shown using the example of a web-based configurator for robot-based automation solutions. on the one hand, the implemented prototype illustrates a possible ms architecture pattern and, on the other hand, clarifies how new functionalities such as the collaborative multi-user configuration or different role-based configuration sessions are enabled by such a concept. using the example of the web-based configuration platform, it is finally shown how a ms architecture contributes to better development and easier deployment of engineering software solutions based on the divide and conquer principle.",microservice-based architecture for engineering tools enabling a collaborative multi-user configuration of robot-based automation solutions
607,2-s2.0-85080937041,10.1142/S0218194020500047,Software Analysis Method for Assessing Software Sustainability,Saputri T.R.D.,International Journal of Software Engineering and Knowledge Engineering,2020-01-01,"Software sustainability evaluation has become an essential component of software engineering (SE) owing to sustainability considerations that must be incorporated into software development. Several studies have been performed to address the issues associated with sustainability concerns in the SE process. However, current practices extensively rely on participant experiences to evaluate sustainability achievement. Moreover, there exist limited quantifiable methods for supporting software sustainability evaluation. Our primary objective is to present a methodology that can assist software engineers in evaluating a software system based on well-defined sustainability metrics and measurements. We propose a novel approach that combines machine learning (ML) and software analysis methods. To simplify the application of the proposed approach, we present a semi-automated tool that supports engineers in assessing the sustainability achievement of a software system. The results of our study demonstrate that the proposed approach determines sustainability criteria and defines sustainability achievement in terms of a traceable matrix. Our theoretical evaluation and empirical study demonstrate that the proposed support tool can help engineers identify sustainability limitations in a particular feature of a software system. Our semi-automated tool can identify features that must be revised to enhance sustainability achievement.",machine learning | software-based approach | Sustainability assessment,2,67-95,Journal,Article,2.0,"Saputri, Theresia Ratih Dewi;Lee, Seok Won",56137061800;7601393462,Ajou University,South Korea,"software sustainability evaluation has become an essential component of software engineering (se) owing to sustainability considerations that must be incorporated into software development. several studies have been performed to address the issues associated with sustainability concerns in the se process. however, current practices extensively rely on participant experiences to evaluate sustainability achievement. moreover, there exist limited quantifiable methods for supporting software sustainability evaluation. our primary objective is to present a methodology that can assist software engineers in evaluating a software system based on well-defined sustainability metrics and measurements. we propose a novel approach that combines machine learning (ml) and software analysis methods. to simplify the application of the proposed approach, we present a semi-automated tool that supports engineers in assessing the sustainability achievement of a software system. the results of our study demonstrate that the proposed approach determines sustainability criteria and defines sustainability achievement in terms of a traceable matrix. our theoretical evaluation and empirical study demonstrate that the proposed support tool can help engineers identify sustainability limitations in a particular feature of a software system. our semi-automated tool can identify features that must be revised to enhance sustainability achievement.",software analysis method for assessing software sustainability
608,2-s2.0-85080899548,10.1007/978-3-030-40914-2_3,A Formally Verified Model of Web Components,Brucker A.D.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2020-01-01,"The trend towards ever more complex client-side web applications is unstoppable. Compared to traditional software development, client-side web development lacks a well-established component model, i. e., a method for easily and safely reusing already developed functionality. To address this issue, the web community started to adopt shadow trees as part of the Document Object Model (DOM). Shadow trees allow developers to “partition” a DOM instance into parts that should be safely separated, e. g., code modifying one part should not unintentionally affect other parts of the DOM. While shadow trees provide the technical basis for defining web components, the DOM standard neither defines the concept of web components nor specifies the safety properties that web components should guarantee. Consequently, the standard also does not discuss how or even if the methods for modifying the DOM respect component boundaries. In this paper, we present a formally verified model of web components and define safety properties which ensure that different web components can only interact with each other using well-defined interfaces. Moreover, our verification of the application programming interface (API) of the DOM revealed numerous invariants that implementations of the DOM API need to preserve to ensure the integrity of components.",DOM | Isabelle/HOL | Shadow tree | Web component,1,51-71,Book Series,Conference Paper,2.0,"Brucker, Achim D.;Herzberg, Michael",8868852700;57188702274,University of Exeter;The University of Sheffield,United Kingdom;United Kingdom,"the trend towards ever more complex client-side web applications is unstoppable. compared to traditional software development, client-side web development lacks a well-established component model, i. e., a method for easily and safely reusing already developed functionality. to address this issue, the web community started to adopt shadow trees as part of the document object model (dom). shadow trees allow developers to “partition” a dom instance into parts that should be safely separated, e. g., code modifying one part should not unintentionally affect other parts of the dom. while shadow trees provide the technical basis for defining web components, the dom standard neither defines the concept of web components nor specifies the safety properties that web components should guarantee. consequently, the standard also does not discuss how or even if the methods for modifying the dom respect component boundaries. in this paper, we present a formally verified model of web components and define safety properties which ensure that different web components can only interact with each other using well-defined interfaces. moreover, our verification of the application programming interface (api) of the dom revealed numerous invariants that implementations of the dom api need to preserve to ensure the integrity of components.",a formally verified model of web components
609,2-s2.0-85079863915,10.2298/CSIS180829021T,Run-time interpretation of information system application models in mobile cloud environments,Tanković N.,Computer Science and Information Systems,2020-01-01,"Application models are commonly used in the development of information systems. Recent trends have introduced techniques by which models can be directly transformed into execution code and thus become a single source for application design. Inherently, it has been challenging for software developers to become proficient in designing entire systems due to the complex chain of model transformations and the further refinements required to the code generated from the models. We propose an architectural framework for building the distributed information system applications in which the application models are directly interpreted during execution. This approach shortens the evaluation cycles and provides faster feedback to developers. Our framework is based on a holistic application model represented as a graph structure complemented with a procedural action scripting language that can express more complex software behavior. We present the implementation details of this framework architecture in a mobile cloud environment and evaluate its benefits in eleven projects for different customers in the retail, supply-chain management and merchandising domain involving 300 active application users. Our approach allowed engaging end-users in the software development process in the phase of specifying executable application models. It succeeded in shortening the requirements engineering process and automating the configuration and deployment process. Moreover, it benefited from the automatic synchronization of application updates for all active versions at the customer sites.",Application graph model | Cloud computing | Information system | MDD | Model interpretation | Model-driven development,1,1-27,Journal,Article,2.0,"Tanković, Nikola;Galinac Grbac, Tihana",55148441400;57202354149,Juraj Dobrila University of Pula,Croatia,"application models are commonly used in the development of information systems. recent trends have introduced techniques by which models can be directly transformed into execution code and thus become a single source for application design. inherently, it has been challenging for software developers to become proficient in designing entire systems due to the complex chain of model transformations and the further refinements required to the code generated from the models. we propose an architectural framework for building the distributed information system applications in which the application models are directly interpreted during execution. this approach shortens the evaluation cycles and provides faster feedback to developers. our framework is based on a holistic application model represented as a graph structure complemented with a procedural action scripting language that can express more complex software behavior. we present the implementation details of this framework architecture in a mobile cloud environment and evaluate its benefits in eleven projects for different customers in the retail, supply-chain management and merchandising domain involving 300 active application users. our approach allowed engaging end-users in the software development process in the phase of specifying executable application models. it succeeded in shortening the requirements engineering process and automating the configuration and deployment process. moreover, it benefited from the automatic synchronization of application updates for all active versions at the customer sites.",run-time interpretation of information system application models in mobile cloud environments
611,2-s2.0-85078503845,10.1007/978-3-030-37873-8_10,Towards Multi-editor Support for Domain-Specific Languages Utilizing the Language Server Protocol,Bünder H.,Communications in Computer and Information Science,2020-01-01,"In model-driven software development (MDSD) projects, frequently domain experts and developers work together on the same model. However, they have quite different preferences concerning tools for working with a model. While developers require a powerful integrated development environment (IDE), domain experts are overwhelmed by the amount of functionality of an IDE and its confusing user interface. They prefer a simple editor, often provided as a web application, which does not require a local installation. Currently, both stakeholders typically agree on a common tool, which is frustrating for at least one of them. The Language Server Protocol (LSP) is a standard that aims to include language smarts into simple editors without turning them into IDEs. Originally, it has been designed for programming languages. In the present paper, we will give evidence based on a case study and a corresponding SWOT analysis that it is even more beneficial for a textual domain-specific language (DSL) as it is often used in MDSD. We will focus on the language workbench Xtext which supports the LSP. In particular, we will investigate how the LSP can be used to integrate a DSL into different development tools (editors and IDEs). Supplementing the SWOT analysis, we have also evaluated the practical relevance of the LSP.",Case study | Model-driven development language server protocol | Textual domain-specific languages,1,225-245,Book Series,Conference Paper,2.0,"Bünder, Hendrik;Kuchen, Herbert",57208389667;6602187523,Itemis AG;Westfälische Wilhelms-Universität Münster,Germany;Germany,"in model-driven software development (mdsd) projects, frequently domain experts and developers work together on the same model. however, they have quite different preferences concerning tools for working with a model. while developers require a powerful integrated development environment (ide), domain experts are overwhelmed by the amount of functionality of an ide and its confusing user interface. they prefer a simple editor, often provided as a web application, which does not require a local installation. currently, both stakeholders typically agree on a common tool, which is frustrating for at least one of them. the language server protocol (lsp) is a standard that aims to include language smarts into simple editors without turning them into ides. originally, it has been designed for programming languages. in the present paper, we will give evidence based on a case study and a corresponding swot analysis that it is even more beneficial for a textual domain-specific language (dsl) as it is often used in mdsd. we will focus on the language workbench xtext which supports the lsp. in particular, we will investigate how the lsp can be used to integrate a dsl into different development tools (editors and ides). supplementing the swot analysis, we have also evaluated the practical relevance of the lsp.",towards multi-editor support for domain-specific languages utilizing the language server protocol
612,2-s2.0-85078469927,10.31838/ijpr/2020.12.01.150,Illustration of experimental version of the expert system,Burnashev R.A.,International Journal of Pharmaceutical Research,2020-01-01,"The paper presents the results of research on the creation of CASE tools that provide the experimental version of effectively build expert systems. As a part of the creation of CASE tools we focus on building an integrated development environment that includes a combination of PROLOG, JavaScript, Python programming languages, PostgreSQL database management system (DBMS) as well as telemetry tools. The experiments intended through the study are simulated using above mentioned software, where they were on the basis of the created integrated development environment. This expert system is mainly focused on automating the analysis processes and forming requirements for the software applications and hardware being developed using the built-in telemetry tools and taking into account the specifics of the corresponding subject area. The expert system is performed using the logical rules concerning the characteristics of workstations and corresponding software systems. As the result the expert system forms requirements and recommendations to the properties of the software and hardware products being developed.",CASE-tools | Database management systems | Expert system | Software | Telemetry,0,775-780,Journal,Article,2.0,"Burnashev, Rustam A.;Enikeev, Arslan I.",57200246615;6602359184,Kazan Federal University,Russian Federation,"the paper presents the results of research on the creation of case tools that provide the experimental version of effectively build expert systems. as a part of the creation of case tools we focus on building an integrated development environment that includes a combination of prolog, javascript, python programming languages, postgresql database management system (dbms) as well as telemetry tools. the experiments intended through the study are simulated using above mentioned software, where they were on the basis of the created integrated development environment. this expert system is mainly focused on automating the analysis processes and forming requirements for the software applications and hardware being developed using the built-in telemetry tools and taking into account the specifics of the corresponding subject area. the expert system is performed using the logical rules concerning the characteristics of workstations and corresponding software systems. as the result the expert system forms requirements and recommendations to the properties of the software and hardware products being developed.",illustration of experimental version of the expert system
613,2-s2.0-85078153227,10.1007/978-3-030-33491-8_31,GraphLabs Extendable Module System for Education Support,Korotkova M.A.,Mechanisms and Machine Science,2020-01-01,The paper reviews program module system of GraphLabs software environment. Component instantiation and inheritance of prototypes are shown to be used for module extension. An extendable module system is used to improve the development and the maintenance processes of the software package. The necessity of system adaptation to the user is proved in the article. Two approaches for metadata recalculating are considered. A model for system behavior adjustment is suggested. The model is based on metadata of student actions in the system. It proposes the way to indicate optimal and inaccurate tracks of student behavior in the module. The model is generalized to Mealy machine. The estimation criterion of student metadata is provided in the paper. The affecting parameters on the resulting criterion are revealed. Approaches to parameter implementation are discussed in the article. Variant issuing is described using the evaluated criterion value. Prototype-based programming is used while organizing software component inheritance.,Adaptation | GraphLabs | Inheritance | JavaScript | OOP | Program module,1,257-266,Book Series,Conference Paper,3.0,"Korotkova, M. A.;Carpow, G.;Zakhryapin, S. O.",57214092388;57214071186;57214074167,National Research Nuclear University MEPhI,Russian Federation,the paper reviews program module system of graphlabs software environment. component instantiation and inheritance of prototypes are shown to be used for module extension. an extendable module system is used to improve the development and the maintenance processes of the software package. the necessity of system adaptation to the user is proved in the article. two approaches for metadata recalculating are considered. a model for system behavior adjustment is suggested. the model is based on metadata of student actions in the system. it proposes the way to indicate optimal and inaccurate tracks of student behavior in the module. the model is generalized to mealy machine. the estimation criterion of student metadata is provided in the paper. the affecting parameters on the resulting criterion are revealed. approaches to parameter implementation are discussed in the article. variant issuing is described using the evaluated criterion value. prototype-based programming is used while organizing software component inheritance.,graphlabs extendable module system for education support
615,2-s2.0-85077788217,10.1097/CJ9.0000000000000148,Development of MyCheckTime<sup>®</sup> software for perioperative safety based on Toyota's Lean Methodology,Tafur Betancourt L.A.,Colombian Journal of Anesthesiology,2020-01-01,"Introduction:In the age of healthcare safety, compliance with checklists and time tracking in surgery continue to be a gray zone in care processes. The technology applied to approach this issue and other scenarios, may contribute to solve a problem that impacts welfare and the healthcare sector economics.Objective:To introduce the design and construction of the MyCheckTime®software that incorporates Toyota's Lean methodology under the concept of Bundles.Materials and methods:Using a conceptual map, 5 measures were incorporated into the bundle; the MyCheckTime® platform was built based on a software code developed in Java8, PHP, Javascript, HTML5, Angular4, MongoDB-MySQL databases, and Docker, Ionic, VertX, Laravel-implemented technologies.Results:A software (MyCheckTime®) was constructed based on an App available for tablets and IOS and Android system-based mobile devices; a web-based platform and a database. The software captures the patient's circuit in the surgical area in real time, and records the times in which the checklists were conducted.Conclusion:MyCheckTime® is a Lean Methodology-based software that potentially enables the surgical team to deliver more efficient, safer, and timely care, allowing real time recording of the patient's circuit in the surgery area.",Checklist | Health surveillance | Patient safety | Safety management | Software,2,12-19,Journal,Article,10.0,"Tafur Betancourt, Luis Alberto;Zorrilla-Vaca, Andrés;Vallejos-Medina, Lorena Patricia;Chilatra-Fonseca, José Mauricio;Angarita-Navarro, Enrique Carlos;Martínez-Gaviria, Milagros;Londonõ, Alejandro;Bocanegra-Rivera, Juan Carlos;Botero-Posada, Luis Fernando;Lema-Florez, Eduardo",36192082700;56042536100;57213420555;57192303355;57213419759;57213418802;36508918100;54406505300;22633395500;57190066784,"Clínica Las Américas;Universidad Libre;Hospital Universitario del Valle ""Evaristo García"";Universidad Surcolombiana;Universidad del Valle, Cali;ESE Hospital San Félix;Clínica Colombia y Clínica Cristo Rey;E.S.E. Hospital San Vicente de Paul de Caldas;Clínica Desa;Clínica Universitaria Colombia;Instituto Neurológico de Colombia;Instituto para Niños Ciegos y Sordos del Valle del Cauca;Fundación Universitaria Sanitas",Colombia;Colombia;Colombia;Colombia;Colombia;Colombia;Colombia;Colombia;Colombia;Colombia;Colombia;Colombia;Colombia,"introduction:in the age of healthcare safety, compliance with checklists and time tracking in surgery continue to be a gray zone in care processes. the technology applied to approach this issue and other scenarios, may contribute to solve a problem that impacts welfare and the healthcare sector economics.objective:to introduce the design and construction of the mychecktime®software that incorporates toyota's lean methodology under the concept of bundles.materials and methods:using a conceptual map, 5 measures were incorporated into the bundle; the mychecktime® platform was built based on a software code developed in java8, php, javascript, html5, angular4, mongodb-mysql databases, and docker, ionic, vertx, laravel-implemented technologies.results:a software (mychecktime®) was constructed based on an app available for tablets and ios and android system-based mobile devices; a web-based platform and a database. the software captures the patient's circuit in the surgical area in real time, and records the times in which the checklists were conducted.conclusion:mychecktime® is a lean methodology-based software that potentially enables the surgical team to deliver more efficient, safer, and timely care, allowing real time recording of the patient's circuit in the surgery area.",development of mychecktime<sup>®</sup> software for perioperative safety based on toyota's lean methodology
617,2-s2.0-85077509424,10.1007/978-3-030-31585-6_3,Safe interoperability for web of things devices and systems,Korkan E.,Lecture Notes in Electrical Engineering,2020-01-01,"The Internet of Things (IoT) enables connectivity between devices, thereby allowing them to interact with each other. A recurring problem is the emergence of siloed IoT platforms due to proprietary standards. Recently, the World Wide Web Consortium (W3C) proposed a human-readable and machine-understandable format called Thing Description (TD). It allows to uniformly describe device and service interfaces of different IoT standards with syntactic and semantic information, and hence enables semantic interoperability. However, describing the sequential behavior of devices, which is essential for many cyber-physical systems, is not covered. In this paper, we extend our initial contribution of describing such sequential behavior as an extension within TDs, thereby increasing their semantic expressiveness through possible, valid state transitions. This enables safe and desired operation of devices as well as scalability by modeling systems as sequential compositions of Things. We show in a case study that previously unmodelable behavior can now be expressed and the overall manual intervention requirements of the state-of-the-art implementations can be significantly reduced.",Black box testing | Cyber-physical systems | Data models | Execution path | Formal verification | Internet | Internet of things | IoT platforms | Model-driven development | Safety | Server-client architecture | Software development | Standards | System testing | Testing | Thing description | Verification | Web | Web of things | World wide web consortium,6,47-69,Book Series,Book Chapter,4.0,"Korkan, Ege;Kaebisch, Sebastian;Kovatsch, Matthias;Steinhorst, Sebastian",57204915873;36179690300;36668589800;24588286900,Siemens AG;Technical University of Munich,Germany;Germany,"the internet of things (iot) enables connectivity between devices, thereby allowing them to interact with each other. a recurring problem is the emergence of siloed iot platforms due to proprietary standards. recently, the world wide web consortium (w3c) proposed a human-readable and machine-understandable format called thing description (td). it allows to uniformly describe device and service interfaces of different iot standards with syntactic and semantic information, and hence enables semantic interoperability. however, describing the sequential behavior of devices, which is essential for many cyber-physical systems, is not covered. in this paper, we extend our initial contribution of describing such sequential behavior as an extension within tds, thereby increasing their semantic expressiveness through possible, valid state transitions. this enables safe and desired operation of devices as well as scalability by modeling systems as sequential compositions of things. we show in a case study that previously unmodelable behavior can now be expressed and the overall manual intervention requirements of the state-of-the-art implementations can be significantly reduced.",safe interoperability for web of things devices and systems
618,2-s2.0-85076518363,10.1002/pro.3786,"New tools in MolProbity validation: CaBLAM for CryoEM backbone, UnDowser to rethink “waters,” and NGL Viewer to recapture online 3D graphics",Prisant M.G.,Protein Science,2020-01-01,"The MolProbity web service provides macromolecular model validation to help correct local errors, for the structural biology community worldwide. Here we highlight new validation features, and also describe how we are fighting back against outside developments which compromise that mission. Our new tool called UnDowser analyzes the properties and context of clashing HOH “waters” to diagnose what they might actually represent; a dozen distinct scenarios are illustrated and described. We now treat alternate conformations more thoroughly, and switching to the Neo4j database (graphical rather than relational) enables cleaner, more comprehensive, and much larger reference datasets. A problematic outside change is that refinement software now increasingly restrains traditional validation criteria (geometry, clashes, rotamers, and even Ramachandran) in order to supplement the sparser experimental data at 3–4 Å resolutions typical of modern cryoEM. But unfortunately the broad density allows model optimization without fixing underlying problems, which means these structures often score much better on validation than they really are. CaBLAM, our tool designed for evaluating peptide orientations at lower resolutions, was described in the previous Tools issue, and here we demonstrate its effectiveness in diagnosing local errors even when other validation outliers have been artificially removed. Sophisticated hacking of the MolProbity server has required continual monitoring and various security measures short of restricting user access. The deprecation of Java applets now prevents KiNG interactive online display of outliers on the 3D model during a MolProbity run, but that important functionality has now been recaptured with a modified version of the Javascript NGL Viewer.",backbone conformation | chiral volumes | ion binding | Neo4j | overfitting | Ramachandran restraints | server security | structure validation | water analysis,37,315-329,Journal,Article,5.0,"Prisant, Michael G.;Williams, Christopher J.;Chen, Vincent B.;Richardson, Jane S.;Richardson, David C.",6507647157;57211875188;18133654200;35501730000;7403444819,Duke University Medical Center,United States,"the molprobity web service provides macromolecular model validation to help correct local errors, for the structural biology community worldwide. here we highlight new validation features, and also describe how we are fighting back against outside developments which compromise that mission. our new tool called undowser analyzes the properties and context of clashing hoh “waters” to diagnose what they might actually represent; a dozen distinct scenarios are illustrated and described. we now treat alternate conformations more thoroughly, and switching to the neo4j database (graphical rather than relational) enables cleaner, more comprehensive, and much larger reference datasets. a problematic outside change is that refinement software now increasingly restrains traditional validation criteria (geometry, clashes, rotamers, and even ramachandran) in order to supplement the sparser experimental data at 3–4 å resolutions typical of modern cryoem. but unfortunately the broad density allows model optimization without fixing underlying problems, which means these structures often score much better on validation than they really are. cablam, our tool designed for evaluating peptide orientations at lower resolutions, was described in the previous tools issue, and here we demonstrate its effectiveness in diagnosing local errors even when other validation outliers have been artificially removed. sophisticated hacking of the molprobity server has required continual monitoring and various security measures short of restricting user access. the deprecation of java applets now prevents king interactive online display of outliers on the 3d model during a molprobity run, but that important functionality has now been recaptured with a modified version of the javascript ngl viewer.","new tools in molprobity validation: cablam for cryoem backbone, undowser to rethink “waters,” and ngl viewer to recapture online 3d graphics"
619,2-s2.0-85075689583,10.1007/978-3-030-32022-5_15,Automation of the Municipal Inspection Process in Ecuador Applying Mobile-D for Android,Guevara-Vega C.,Advances in Intelligent Systems and Computing,2020-01-01,"A municipality is an administrative entity that refers to a city. Ecuadorian municipalities regularly perform manual inspection processes in stores to calculate municipal charges. However, they have identified that these manual processes are time-consuming and have high costs. Also, the human mistakes existence in obtaining information from stores and the difficulty to manage the inspection processes themselves are problematic. In this context, it raises the technological needed of having real-time information from processes carried out for the municipality. Thus, the goal of this study is to automate the inspection process in economic activities at Ibarra – Ecuador municipality through the mobile app development using Mobile-D methodology. The MVC software architecture (Model, View, Controller) and the ScriptCase, Android Studio, PostgreSQL and REST web services tools were applied. The mobile app quality of use was evaluated by using ISO/IEC 25022 standard, and USE questionnaire (Usability, satisfaction, ease of use). And moreover, it was considered a Wilcoxon statistical analysis to verify the improvement of the automated process compared to manual. From results, it was observed that process automatization improved the information obtained at Ibarra municipality, and 84,32% was achieved with respect to the quality of use by considering the mobile app users.",Android | ISO/IEC 25022 | Mobile-D | MVC | USE questionnaire,3,155-166,Book Series,Conference Paper,6.0,"Guevara-Vega, Cathy;Hernández-Rojas, Jaime;Botto-Tobar, Miguel;García-Santillán, Iván;Basantes Andrade, Andrea;Quiña-Mera, Antonio",57205359597;57212001770;57196152677;57192817984;57193908794;57205362034,Universidad Técnica del Norte;Universidad de Guayaquil;Technische Universiteit Eindhoven,Ecuador;Ecuador;Netherlands,"a municipality is an administrative entity that refers to a city. ecuadorian municipalities regularly perform manual inspection processes in stores to calculate municipal charges. however, they have identified that these manual processes are time-consuming and have high costs. also, the human mistakes existence in obtaining information from stores and the difficulty to manage the inspection processes themselves are problematic. in this context, it raises the technological needed of having real-time information from processes carried out for the municipality. thus, the goal of this study is to automate the inspection process in economic activities at ibarra – ecuador municipality through the mobile app development using mobile-d methodology. the mvc software architecture (model, view, controller) and the scriptcase, android studio, postgresql and rest web services tools were applied. the mobile app quality of use was evaluated by using iso/iec 25022 standard, and use questionnaire (usability, satisfaction, ease of use). and moreover, it was considered a wilcoxon statistical analysis to verify the improvement of the automated process compared to manual. from results, it was observed that process automatization improved the information obtained at ibarra municipality, and 84,32% was achieved with respect to the quality of use by considering the mobile app users.",automation of the municipal inspection process in ecuador applying mobile-d for android
621,2-s2.0-85073962907,10.1037/met0000244,The Semantic Scale Network: An online tool to detect semantic overlap of psychological scales and prevent scale redundancies.,Rosenbusch H.,Psychological Methods,2020-01-01,"Psychological measurement and theory are afflicted with an ongoing proliferation of new constructs and scales. Given the often redundant nature of new scales, psychological science is struggling with arbitrary measurement, construct dilution, and disconnection between research groups. To address these issues, we introduce an easy-to-use online application: the Semantic Scale Network. The purpose of this application is to automatically detect semantic overlap between scales through latent semantic analysis. Authors and reviewers can enter the items of a new scale into the application, and receive quantifications of semantic overlap with related scales in the application’s corpus. Contrary to traditional assessments of scale overlap, the application can support expert judgments on scale redundancy without access to empirical data or awareness of every potentially related scale. After a brief introduction to measures of semantic similarity in texts, we introduce the Semantic Scale Network and provide best practices for interpreting its outputs. (PsycInfo Database Record (c) 2020 APA, all rights reserved) Translational Abstract—Psychological measurement and theory are afflicted with an ongoing proliferation of new constructs (e.g., “happiness” or “intelligence”) and scales (e.g., questionnaires developed to measure these constructs). Given the often redundant nature of new scales, psychological science is struggling with arbitrary measurement, construct dilution, and disconnection between research groups. To address these issues, we introduce an easy-to-use online application: the Semantic Scale Network. The purpose of this application is to automatically detect semantic overlap between scales through a language-based algorithm called latent semantic analysis. Authors and reviewers of psychological research can enter the questions of a new scale into the application, and receive quantifications of semantic overlap with related scales in the application’s corpus (i.e., collection of written texts). Contrary to traditional assessments of scale overlap, the application can support expert judgments on scale redundancy without access to empirical data (e.g., answers to the questionnaires) or awareness of every potentially related scale. After a brief introduction to measures of semantic similarity in texts, we introduce the Semantic Scale Network and provide best practices for interpreting its outputs. (PsycInfo Database Record (c) 2020 APA, all rights reserved)",decision support system | latent semantic analysis | network analysis | scale development | scale proliferation,14,380-392,Journal,Article,3.0,"Rosenbusch, Hannes;Wanders, Florian;Pit, Ilse L.",57205667472;56584693400;57211442850,Tilburg University;Universiteit van Amsterdam,Netherlands;Netherlands,"psychological measurement and theory are afflicted with an ongoing proliferation of new constructs and scales. given the often redundant nature of new scales, psychological science is struggling with arbitrary measurement, construct dilution, and disconnection between research groups. to address these issues, we introduce an easy-to-use online application: the semantic scale network. the purpose of this application is to automatically detect semantic overlap between scales through latent semantic analysis. authors and reviewers can enter the items of a new scale into the application, and receive quantifications of semantic overlap with related scales in the application’s corpus. contrary to traditional assessments of scale overlap, the application can support expert judgments on scale redundancy without access to empirical data or awareness of every potentially related scale. after a brief introduction to measures of semantic similarity in texts, we introduce the semantic scale network and provide best practices for interpreting its outputs. (psycinfo database record (c) 2020 apa, all rights reserved) translational abstract—psychological measurement and theory are afflicted with an ongoing proliferation of new constructs (e.g., “happiness” or “intelligence”) and scales (e.g., questionnaires developed to measure these constructs). given the often redundant nature of new scales, psychological science is struggling with arbitrary measurement, construct dilution, and disconnection between research groups. to address these issues, we introduce an easy-to-use online application: the semantic scale network. the purpose of this application is to automatically detect semantic overlap between scales through a language-based algorithm called latent semantic analysis. authors and reviewers of psychological research can enter the questions of a new scale into the application, and receive quantifications of semantic overlap with related scales in the application’s corpus (i.e., collection of written texts). contrary to traditional assessments of scale overlap, the application can support expert judgments on scale redundancy without access to empirical data (e.g., answers to the questionnaires) or awareness of every potentially related scale. after a brief introduction to measures of semantic similarity in texts, we introduce the semantic scale network and provide best practices for interpreting its outputs. (psycinfo database record (c) 2020 apa, all rights reserved)",the semantic scale network: an online tool to detect semantic overlap of psychological scales and prevent scale redundancies.
622,2-s2.0-85072825294,10.1007/978-3-030-30604-5_21,Research on the Development of Expert Systems Using Artificial Intelligence,Burnashev R.A.,Advances in Intelligent Systems and Computing,2020-01-01,"This paper presents a study related to the development of logical expert systems using artificial intelligence on the example of diagnosing leukemia. For the development of the system, various approaches to the design of artificial intelligence systems and medical data used in the diagnosis of leukemia were applied. A distinctive feature of the expert system is that a specialist working with the knowledge base can not only get the answer he needs, but also get access to all the knowledge from the knowledge base by asking the necessary questions to the expert system. The methods are based on obtaining information about the characteristics of the software using specialized software that provides automation. Data sets and logical rules that were used for the initial diagnosis of the disease were identified. In developing and analyzing software requirements, a prototype system was developed. This system includes a perceptron and consists of 3 hidden layers. For software development was used programming languages Python, JavaScript and Prolog.",Expert system | JavaScript | Numpy | PostgreSQL | Prolog | Psycopg2 | Python 3,2,233-242,Book Series,Conference Paper,5.0,"Burnashev, Rustam A.;Gabdrahmanov, Ruslan G.;Amer, Ismail F.;Vakhitov, Galim Z.;Enikeev, Arslan I.",57200246615;57211156290;57192677801;57204932144;6602359184,Kazan Federal University,Russian Federation,"this paper presents a study related to the development of logical expert systems using artificial intelligence on the example of diagnosing leukemia. for the development of the system, various approaches to the design of artificial intelligence systems and medical data used in the diagnosis of leukemia were applied. a distinctive feature of the expert system is that a specialist working with the knowledge base can not only get the answer he needs, but also get access to all the knowledge from the knowledge base by asking the necessary questions to the expert system. the methods are based on obtaining information about the characteristics of the software using specialized software that provides automation. data sets and logical rules that were used for the initial diagnosis of the disease were identified. in developing and analyzing software requirements, a prototype system was developed. this system includes a perceptron and consists of 3 hidden layers. for software development was used programming languages python, javascript and prolog.",research on the development of expert systems using artificial intelligence
623,2-s2.0-85071500029,10.1007/978-981-32-9050-1_77,The Development of Web Application Front-End of Intelligent Clinic Based on Vue.js,Li M.,Lecture Notes in Electrical Engineering,2020-01-01,"There are many problems in China’s medical system, and the rapid development of intelligent automation and computer network can provide a powerful way to solve these difficult problems. The number of clinics is increasing to decentralize the number of patients in large hospitals through graded diagnosis and treatment. It is urgent to improve the capacity of primary clinics, for this purpose, this fully functional and easy-to-use workbench software is developed for clinic managers and doctors. In this paper, we discussed experiences of web front-end development, in view of the system functional requirements, the lightweight framework Vue.js is selected. The characteristics of MVVM mode, componentization and single page support are emphasized. The implementation method is illustrated with examples, and some test results of system functions are shown. A useful attempt has been made in the development of smart medicine preliminarily.",Front-end | Intelligent Clinic | Vue.js,1,683-690,Book Series,Conference Paper,3.0,"Li, Minghang;Hu, Jianghai;Lin, Xianwu",56323406600;9239652100;55785741200,Xiamen University;Purdue University,China;United States,"there are many problems in china’s medical system, and the rapid development of intelligent automation and computer network can provide a powerful way to solve these difficult problems. the number of clinics is increasing to decentralize the number of patients in large hospitals through graded diagnosis and treatment. it is urgent to improve the capacity of primary clinics, for this purpose, this fully functional and easy-to-use workbench software is developed for clinic managers and doctors. in this paper, we discussed experiences of web front-end development, in view of the system functional requirements, the lightweight framework vue.js is selected. the characteristics of mvvm mode, componentization and single page support are emphasized. the implementation method is illustrated with examples, and some test results of system functions are shown. a useful attempt has been made in the development of smart medicine preliminarily.",the development of web application front-end of intelligent clinic based on vue.js
624,2-s2.0-85071442322,10.1007/978-3-030-27928-8_43,Complete Block-Level Visual Debugger for Blockly,Savidis A.,Advances in Intelligent Systems and Computing,2020-01-01,"Blockly is a visual programming editor by Google, being open-source multi-platform and multi-language, while offering jigsaw-style program blocks. It is very popular and currently adopted by an increasing number of visual development solutions. However, as with similar earlier tools, it lacks a full-scale debugger. We present a complete visual debugger for Blockly, working over blocks, supporting the full range of debugging features as with typical source-level debuggers. To support all tracing functions we make no amendments to the underlying JavaScript engine, supporting all debugging operations through code instrumentation inserting invocations to a busy-wait debugger service loop. The latter affects only the source code that is output by Blockly.",Debuggers | End-user development | Visual programming,1,286-292,Book Series,Conference Paper,2.0,"Savidis, Anthony;Savaki, Crystalia",6603471887;57210789094,Foundation for Research and Technology-Hellas;University of Crete,Greece;Greece,"blockly is a visual programming editor by google, being open-source multi-platform and multi-language, while offering jigsaw-style program blocks. it is very popular and currently adopted by an increasing number of visual development solutions. however, as with similar earlier tools, it lacks a full-scale debugger. we present a complete visual debugger for blockly, working over blocks, supporting the full range of debugging features as with typical source-level debuggers. to support all tracing functions we make no amendments to the underlying javascript engine, supporting all debugging operations through code instrumentation inserting invocations to a busy-wait debugger service loop. the latter affects only the source code that is output by blockly.",complete block-level visual debugger for blockly
626,2-s2.0-85070645949,10.1007/978-3-030-23665-6_18,Last mile logistics in smart cities: An IT platform for vehicle sharing and routing,Guerrazzi E.,Lecture Notes in Information Systems and Organisation,2020-01-01,"Due to the current remarkable growth of e-commerce, the last mile logistics has become a relevant problem. In this paper, the main issues of the last mile logistics in a smart city context are introduced. We propose a solution based on a shared Information Technology (IT) platform that needs no material investments. The principle of resource pooling is applied to the sharing of heterogeneous vehicles in the urban network. In particular, an IT platform powered by an optimization algorithm is proposed to allow couriers to make their deliveries more efficiently, that is, to reduce the total distance covered by the vehicles. This was achieved through the development of four software modules: an ETL, an optimizer, a web application and a map displayer. First results are promising, but further investigations should be done in order to evaluate more accurately the expected benefits and the possible positive externalities such as improvement of air quality in the city.",Last mile delivery | Logistics | Smart city | Vehicle sharing,4,251-260,Conference Proceeding,Conference Paper,1.0,"Guerrazzi, Emanuele",57209859353,Università di Pisa,Italy,"due to the current remarkable growth of e-commerce, the last mile logistics has become a relevant problem. in this paper, the main issues of the last mile logistics in a smart city context are introduced. we propose a solution based on a shared information technology (it) platform that needs no material investments. the principle of resource pooling is applied to the sharing of heterogeneous vehicles in the urban network. in particular, an it platform powered by an optimization algorithm is proposed to allow couriers to make their deliveries more efficiently, that is, to reduce the total distance covered by the vehicles. this was achieved through the development of four software modules: an etl, an optimizer, a web application and a map displayer. first results are promising, but further investigations should be done in order to evaluate more accurately the expected benefits and the possible positive externalities such as improvement of air quality in the city.",last mile logistics in smart cities: an it platform for vehicle sharing and routing
629,2-s2.0-85067276496,10.1007/s10270-019-00737-w,Lossless compaction of model execution traces,Hojaji F.,Software and Systems Modeling,2020-01-01,"Dynamic verification and validation (V&V) techniques are used to verify and validate the behavior of software systems early in the development process. In the context of model-driven engineering, such behaviors are usually defined using executable domain-specific modeling languages (xDSML). Many V&V techniques rely on execution traces to represent and analyze the behavior of executable models. Traces, however, tend to be overwhelmingly large, hindering effective and efficient analysis of their content. While there exist several trace metamodels to represent execution traces, most of them suffer from scalability problems. In this paper, we present a generic compact trace representation format called generic compact trace metamodel (CTM) that enables the construction and manipulation of compact execution traces of executable models. CTM is generic in the sense that it supports a wide range of xDSMLs. We evaluate CTM on traces obtained from real-world fUML models. Compared to existing trace metamodels, the results show a significant reduction in memory and disk consumption. Moreover, CTM offers a common structure with the aim to facilitate interoperability between existing trace analysis tools.",Compaction | Execution trace | Model execution | Trace metamodel,2,199-230,Journal,Article,5.0,"Hojaji, Fazilat;Zamani, Bahman;Hamou-Lhadj, Abdelwahab;Mayerhofer, Tanja;Bousse, Erwan",36175700700;25654255000;24314702300;55320386300;55580652800,Concordia University;University of Isfahan;Technische Universität Wien,Canada;Iran;Austria,"dynamic verification and validation (v&v) techniques are used to verify and validate the behavior of software systems early in the development process. in the context of model-driven engineering, such behaviors are usually defined using executable domain-specific modeling languages (xdsml). many v&v techniques rely on execution traces to represent and analyze the behavior of executable models. traces, however, tend to be overwhelmingly large, hindering effective and efficient analysis of their content. while there exist several trace metamodels to represent execution traces, most of them suffer from scalability problems. in this paper, we present a generic compact trace representation format called generic compact trace metamodel (ctm) that enables the construction and manipulation of compact execution traces of executable models. ctm is generic in the sense that it supports a wide range of xdsmls. we evaluate ctm on traces obtained from real-world fuml models. compared to existing trace metamodels, the results show a significant reduction in memory and disk consumption. moreover, ctm offers a common structure with the aim to facilitate interoperability between existing trace analysis tools.",lossless compaction of model execution traces
630,2-s2.0-85066047847,10.1007/978-3-030-17971-7_110,Development of a diagnostic support software in the clinicobiochemical evaluation of secondary amenorrhea diagnosis,Begović N.,IFMBE Proceedings,2020-01-01,"Amenorrhea is defined as the absence of menstrual bleeding and it is classified as primary, as the absence of menarche and secondary, usually longer than six to twelve months. The causes of secondary amenorrhea are pathological changes of female reproductive organs and hypothalamic-pituitary axis which, due to complex pathophysiology, are difficult to differentiate. Amenorrhea is associated with other disorders such as anxiety and depression, osteoporosis, cardiovascular diseases, endometrial cancer and infertility. Therefore, the importance of accurate diagnosis and consequent treatment is indisputable. For the purpose of accurate diagnosis, there has been developed an application based on the selected algorithm used for the evaluation of secondary amenorrhea. Algorithm allows healthcare workers and patients to make a decision on health protection based on the best evidence and to minimize costs and time frame of testing, as well. During the preparation of AmnSec application, there were used reference intervals on the following biochemical parameters: prolactin, TSH, FSH, testosterone, DHEAS and presence of virilization. The combination of default values offers the possible cause of secondary amenorrhea while the diagnostic success of the application entirely depends on the accuracy of the algorithm that the application is based on. The development of this type of application makes it easier for patients to access valid information by simply using their personal computers or mobile phones. Further work and the progress of the information sector in medicine is needed to provide more efficient, faster and better care and higher quality information for patients as the axis of improving health and life quality.",Algorithm | Application development | PCOS | Prolactin | Secondary amenorrhea,0,743-747,Conference Proceeding,Conference Paper,11.0,"Begović, Nikolina;Džiho, Amina;Aliman, Lamija;Đukić, Igor;Tarakčija, Arnela;Terzić, Vedad;Meseldžić, Neven;Imamović, Selma;Dujić, Tanja;Malenica, Maja;Bego, Tamer",57208888584;57208881845;57208882494;57208878845;57193706889;57193706805;57208885914;57193706323;23496289600;23498017800;35742627100,University of Sarajevo;University of Novi Sad,Bosnia and Herzegovina;Serbia,"amenorrhea is defined as the absence of menstrual bleeding and it is classified as primary, as the absence of menarche and secondary, usually longer than six to twelve months. the causes of secondary amenorrhea are pathological changes of female reproductive organs and hypothalamic-pituitary axis which, due to complex pathophysiology, are difficult to differentiate. amenorrhea is associated with other disorders such as anxiety and depression, osteoporosis, cardiovascular diseases, endometrial cancer and infertility. therefore, the importance of accurate diagnosis and consequent treatment is indisputable. for the purpose of accurate diagnosis, there has been developed an application based on the selected algorithm used for the evaluation of secondary amenorrhea. algorithm allows healthcare workers and patients to make a decision on health protection based on the best evidence and to minimize costs and time frame of testing, as well. during the preparation of amnsec application, there were used reference intervals on the following biochemical parameters: prolactin, tsh, fsh, testosterone, dheas and presence of virilization. the combination of default values offers the possible cause of secondary amenorrhea while the diagnostic success of the application entirely depends on the accuracy of the algorithm that the application is based on. the development of this type of application makes it easier for patients to access valid information by simply using their personal computers or mobile phones. further work and the progress of the information sector in medicine is needed to provide more efficient, faster and better care and higher quality information for patients as the axis of improving health and life quality.",development of a diagnostic support software in the clinicobiochemical evaluation of secondary amenorrhea diagnosis
631,2-s2.0-85062923166,10.1007/978-3-030-12385-7_72,A software engineering methodology for developing secure obfuscated software,Gonzalez C.,Lecture Notes in Networks and Systems,2020-01-01,"We propose a methodology to conciliate two apparently contradictory processes in the development of secure obfuscated software and good software engineered software. Our methodology consists first in the system designers defining the type of security level required for the software. There are four types of attackers: casual attackers, hackers, institution attack, and government attack. Depending on the level of threat, the methodology we propose uses five or six teams to accomplish this task. One Software Engineer Team and one or two Software Obfuscation Teams, and Compiler Team. These four teams will develop and compile the secure obfuscated software. A Code Breakers Team will test the results of the previous teams to see if the software is not broken at the required security level, and an Intrusion Analysis Team will analyze the results of the Code Breakers Team and propose solutions to the development teams to prevent the detected intrusions. We present also an analytical model to prove that our methodology is no only easier to use, but generates an economical way of producing secure obfuscated software.",Development methodology | Secure software development | Software engineering,1,1069-1078,Book Series,Book Chapter,2.0,"Gonzalez, Carlos;Liñan, Ernesto",57207793090;23393199200,Universidad Autonoma de Coahuila,Mexico,"we propose a methodology to conciliate two apparently contradictory processes in the development of secure obfuscated software and good software engineered software. our methodology consists first in the system designers defining the type of security level required for the software. there are four types of attackers: casual attackers, hackers, institution attack, and government attack. depending on the level of threat, the methodology we propose uses five or six teams to accomplish this task. one software engineer team and one or two software obfuscation teams, and compiler team. these four teams will develop and compile the secure obfuscated software. a code breakers team will test the results of the previous teams to see if the software is not broken at the required security level, and an intrusion analysis team will analyze the results of the code breakers team and propose solutions to the development teams to prevent the detected intrusions. we present also an analytical model to prove that our methodology is no only easier to use, but generates an economical way of producing secure obfuscated software.",a software engineering methodology for developing secure obfuscated software
635,2-s2.0-85086479255,10.19682/j.cnki.1005.8885.2019.1025,Design and implementation of web-based dynamic geometry drawing technology,Hao G.,Journal of China Universities of Posts and Telecommunications,2019-12-01,"Dynamic geometry software, as a piece of computer-assisted instruction (CAI) software, is closely and deeply associated with mathematics, and is widely applied to mathematics teaching activities in primary and secondary schools. Meanwhile, web technology also has become an important technology for assisting education and teaching. This paper expounds a web-based dynamic geometry software development process, and analyses specific requirements regarding graphical application programming interface (API) required by dynamic geometry software. With experiments and comparison on the two different hypertext markup language (HTML) 5 graphical API technologies, i. e., scalable vector graphics (SVG) and Canvas, on different apparatuses and browsers, we draw the conclusion that it is more suitable to adopt Canvas as the graphical API technology for the web-based dynamic geometry software, thus further proposed the principles and methods for an object-oriented Canvas design. The dynamic geometry software based on the newly-designed Canvas has technical advantages and educational value, well incorporating aesthetic education into mathematics education.",Canvas | Dynamic geometry | Subject tools | Web,0,43-53,Journal,Article,3.0,"Hao, Guan;Yongsheng, Rao;Zhangtao, Xu",57200193532;56256382000;57217151323,Chengdu Institute of Computer Application Chinese Academy of Sciences;University of Chinese Academy of Sciences;Guangzhou University;Huazhong Normal University,China;China;China;China,"dynamic geometry software, as a piece of computer-assisted instruction (cai) software, is closely and deeply associated with mathematics, and is widely applied to mathematics teaching activities in primary and secondary schools. meanwhile, web technology also has become an important technology for assisting education and teaching. this paper expounds a web-based dynamic geometry software development process, and analyses specific requirements regarding graphical application programming interface (api) required by dynamic geometry software. with experiments and comparison on the two different hypertext markup language (html) 5 graphical api technologies, i. e., scalable vector graphics (svg) and canvas, on different apparatuses and browsers, we draw the conclusion that it is more suitable to adopt canvas as the graphical api technology for the web-based dynamic geometry software, thus further proposed the principles and methods for an object-oriented canvas design. the dynamic geometry software based on the newly-designed canvas has technical advantages and educational value, well incorporating aesthetic education into mathematics education.",design and implementation of web-based dynamic geometry drawing technology
637,2-s2.0-85083307442,10.1109/ISRITI48646.2019.9034617,The Development of Lexer and Parser as Parts of Compiler for GAMA32 Processor's Instruction-set using Python,Jordan W.,"2019 2nd International Seminar on Research of Information Technology and Intelligent Systems, ISRITI 2019",2019-12-01,"At this time, there are many products based on embedded systems, each of these products requires an embedded processor. This results in high demand for embedded processors. Therefore, we need a tool that is able to design an embedded processor completely with its software development tool. One of the embedded processor that is developed is GAMA32 processor. GAMA32 processor is a 32-bit embedded processor designed using System C Model. Its processor architecture is General Purpose Processor (GPP). GAMA32 processor has its own software development tool, but it has no compiler. The most common used compiler is open source compiler like GNU Compiler Collection (GCC) and Low Level Virtual Machine (LLVM). However, this two open source compilers are not compatible with GAMA32 processor because their complexity. In this research, a simple and flexible compiler will be developed, especially the Abstract Syntax Tree (AST) generator part using Python library rPLY and the AST's output is in the format of JavaScript Object Notation (JSON). For testing the result of AST generator, 5 statement patterns are used namely if, if-else, while, do-while, and for patterns with initial value, and data type declaration as well. The test results show that the correct AST can be produced from the patterns used.",AST generator | embedded processor | GAMA32 | JSON | Python,0,450-455,Conference Proceeding,Conference Paper,3.0,"Jordan, Willy;Bejo, Agus;Persada, Anugerah Galang",57216373547;35096014900;16436979700,Universitas Gadjah Mada,Indonesia,"at this time, there are many products based on embedded systems, each of these products requires an embedded processor. this results in high demand for embedded processors. therefore, we need a tool that is able to design an embedded processor completely with its software development tool. one of the embedded processor that is developed is gama32 processor. gama32 processor is a 32-bit embedded processor designed using system c model. its processor architecture is general purpose processor (gpp). gama32 processor has its own software development tool, but it has no compiler. the most common used compiler is open source compiler like gnu compiler collection (gcc) and low level virtual machine (llvm). however, this two open source compilers are not compatible with gama32 processor because their complexity. in this research, a simple and flexible compiler will be developed, especially the abstract syntax tree (ast) generator part using python library rply and the ast's output is in the format of javascript object notation (json). for testing the result of ast generator, 5 statement patterns are used namely if, if-else, while, do-while, and for patterns with initial value, and data type declaration as well. the test results show that the correct ast can be produced from the patterns used.",the development of lexer and parser as parts of compiler for gama32 processor's instruction-set using python
638,2-s2.0-85081334798,10.1109/BigData47090.2019.9005648,HDMF: Hierarchical Data Modeling Framework for Modern Science Data Standards,Tritt A.J.,"Proceedings - 2019 IEEE International Conference on Big Data, Big Data 2019",2019-12-01,"A ubiquitous problem in aggregating data across different experimental and observational data sources is a lack of software infrastructure that enables flexible and extensible standardization of data and metadata. To address this challenge, we developed HDMF, a hierarchical data modeling framework for modern science data standards. With HDMF, we separate the process of data standardization into three main components: (1) data modeling and specification, (2) data I/O and storage, and (3) data interaction and data APIs. To enable standards to support the complex requirements and varying use cases throughout the data life cycle, HDMF provides object mapping infrastructure to insulate and integrate these various components. This approach supports the flexible development of data standards and extensions, optimized storage backends, and data APIs, while allowing the other components of the data standards ecosystem to remain stable. To meet the demands of modern, large-scale science data, HDMF provides advanced data I/O functionality for iterative data write, lazy data load, and parallel I/O. It also supports optimization of data storage via support for chunking, compression, linking, and modular data storage. We demonstrate the application of HDMF in practice to design NWB 2.0 [13], a modern data standard for collaborative science across the neurophysiology community.",data formats | data modeling | data standards | HDF5 | neurophysiology,0,165-179,Conference Proceeding,Conference Paper,8.0,"Tritt, Andrew J.;Rubel, Oliver;Dichter, Benjamin;Ly, Ryan;Kang, Donghe;Chang, Edward F.;Frank, Loren M.;Bouchard, Kristofer",36673919700;24067719500;56993343800;57215608476;57205458594;7401837635;7201908052;55521678200,Lawrence Berkeley National Laboratory;The Ohio State University,United States;United States,"a ubiquitous problem in aggregating data across different experimental and observational data sources is a lack of software infrastructure that enables flexible and extensible standardization of data and metadata. to address this challenge, we developed hdmf, a hierarchical data modeling framework for modern science data standards. with hdmf, we separate the process of data standardization into three main components: (1) data modeling and specification, (2) data i/o and storage, and (3) data interaction and data apis. to enable standards to support the complex requirements and varying use cases throughout the data life cycle, hdmf provides object mapping infrastructure to insulate and integrate these various components. this approach supports the flexible development of data standards and extensions, optimized storage backends, and data apis, while allowing the other components of the data standards ecosystem to remain stable. to meet the demands of modern, large-scale science data, hdmf provides advanced data i/o functionality for iterative data write, lazy data load, and parallel i/o. it also supports optimization of data storage via support for chunking, compression, linking, and modular data storage. we demonstrate the application of hdmf in practice to design nwb 2.0 [13], a modern data standard for collaborative science across the neurophysiology community.",hdmf: hierarchical data modeling framework for modern science data standards
640,2-s2.0-85075813839,10.1093/molbev/msz185,Sequenceserver: A Modern Graphical User Interface for Custom BLAST Databases,Priyam A.,Molecular Biology and Evolution,2019-12-01,"Comparing newly obtained and previously known nucleotide and amino-acid sequences underpins modern biological research. BLAST is a well-established tool for such comparisons but is challenging to use on new data sets. We combined a user-centric design philosophy with sustainable software development approaches to create Sequenceserver, a tool for running BLAST and visually inspecting BLAST results for biological interpretation. Sequenceserver uses simple algorithms to prevent potential analysis errors and provides flexible text-based and visual outputs to support researcher productivity. Our software can be rapidly installed for use by individuals or on shared servers.",BLAST | comparative genomics | sequence analysis | visualization,64,2922-2924,Journal,Article,22.0,"Priyam, Anurag;Woodcroft, Ben J.;Rai, Vivek;Moghul, Ismail;Munagala, Alekhya;Ter, Filip;Chowdhary, Hiten;Pieniak, Iwo;Maynard, Lawrence J.;Gibbins, Mark Anthony;Moon, Hong Kee;Davis-Richardson, Austin;Uludag, Mahmut;Watson-Haigh, Nathan S.;Challis, Richard;Nakamura, Hiroyuki;Favreau, Emeline;Gómez, Esteban A.;Pluskal, Tomás;Leonard, Guy;Rumpf, Wolfgang;Wurm, Yannick",57136690300;24451582800;57192572874;57188684966;57212058254;57212059024;57212057271;57205155475;57212055811;57212056215;57190046492;35558342500;6602926329;26538313800;15052874200;56176020300;56676193000;57212058964;36605063900;35170262400;57203841837;15766615600,"School of Biological and Chemical Sciences Queen Mary University of London;King Abdullah University of Science and Technology;Nationwide Children’s Hospital;The University of Queensland;The University of Edinburgh;University of Exeter;Royal Holloway, University of London;Whitehead Institute;The University of Adelaide;Wellcome Sanger Institute;Indian Institute of Technology Kharagpur;Max Planck Institute of Molecular Cell Biology and Genetics;5Bases Limited;Spiber Inc.",United Kingdom;Saudi Arabia;United States;Australia;United Kingdom;United Kingdom;United Kingdom;United States;Australia;United Kingdom;India;Germany;United Kingdom;Japan,"comparing newly obtained and previously known nucleotide and amino-acid sequences underpins modern biological research. blast is a well-established tool for such comparisons but is challenging to use on new data sets. we combined a user-centric design philosophy with sustainable software development approaches to create sequenceserver, a tool for running blast and visually inspecting blast results for biological interpretation. sequenceserver uses simple algorithms to prevent potential analysis errors and provides flexible text-based and visual outputs to support researcher productivity. our software can be rapidly installed for use by individuals or on shared servers.",sequenceserver: a modern graphical user interface for custom blast databases
642,2-s2.0-85074852816,10.1007/s10723-019-09494-y,LincoSim: a Web Based HPC-Cloud Platform for Automatic Virtual Towing Tank Analysis,Salvadore F.,Journal of Grid Computing,2019-12-01,"Thanks to evolving web technologies, computational platforms, automation tools and open-source software business model, today, it is possible to develop powerful automatic and virtualized web services for complex physical problems in engineering and design. In particular, in this work, we are presenting a new web based HPC-cloud platform for automatic virtual towing tank analysis. It is well known that the design project of a new hull requires a continuous integration of shape hypothesis and hydrodynamics verifications using analytical tools, 3D computational methods, experimental facilities and sea keeping trial tests. The complexity and the cost of such design tools increase considerably moving from analytical tools to sea keeping trials. In order to perform a meaningful trade-off between costs and high quality data acquiring, during the last decade the usage of 3D computational models has grown pushed also by well-known technological factors. Nevertheless, in the past, there were several limiting factors on the wide diffusion of 3D computational models to perform virtual towing tank data acquiring. On one hand software licensing and hardware infrastructure costs, on the other hand the need of very specific technological skills limited the usage of such virtualized tools only to research centers and/or to large industrial companies. In this work we propose an innovative high-level approach which is embodied in the so-called LincoSim [17] web application in which a hypothetical designer user can carry out the simulation only starting from its own geometry and a set of meaningful physical parameters. LincoSim automatically manages and hides to the user all the necessary details of Computational Fluid Dynamics (CFD) modelling and of HPC infrastructure usage allowing them to access, visualize and analyze the outputs from the same single access point made up from the web browser. In addition to the web interface, the platform includes a back-end server which implements a Cloud logic and can be connected to multiple HPC machines for computing. LincoSim is currently set up with finite volume Open-FOAM CFD engine. A preliminary validation campaign has been performed to assess the robustness and the reliability of the tool and is proposed as a novel approach for the development of Computer Aided Engineering (CAE) applications.",Cloud | Computational fluid dynamics | Design | High performance computing | Naval engineering | OpenFOAM,4,771-795,Journal,Article,2.0,"Salvadore, F.;Ponzini, R.",54781793300;14830357700,CINECA,Italy,"thanks to evolving web technologies, computational platforms, automation tools and open-source software business model, today, it is possible to develop powerful automatic and virtualized web services for complex physical problems in engineering and design. in particular, in this work, we are presenting a new web based hpc-cloud platform for automatic virtual towing tank analysis. it is well known that the design project of a new hull requires a continuous integration of shape hypothesis and hydrodynamics verifications using analytical tools, 3d computational methods, experimental facilities and sea keeping trial tests. the complexity and the cost of such design tools increase considerably moving from analytical tools to sea keeping trials. in order to perform a meaningful trade-off between costs and high quality data acquiring, during the last decade the usage of 3d computational models has grown pushed also by well-known technological factors. nevertheless, in the past, there were several limiting factors on the wide diffusion of 3d computational models to perform virtual towing tank data acquiring. on one hand software licensing and hardware infrastructure costs, on the other hand the need of very specific technological skills limited the usage of such virtualized tools only to research centers and/or to large industrial companies. in this work we propose an innovative high-level approach which is embodied in the so-called lincosim [17] web application in which a hypothetical designer user can carry out the simulation only starting from its own geometry and a set of meaningful physical parameters. lincosim automatically manages and hides to the user all the necessary details of computational fluid dynamics (cfd) modelling and of hpc infrastructure usage allowing them to access, visualize and analyze the outputs from the same single access point made up from the web browser. in addition to the web interface, the platform includes a back-end server which implements a cloud logic and can be connected to multiple hpc machines for computing. lincosim is currently set up with finite volume open-foam cfd engine. a preliminary validation campaign has been performed to assess the robustness and the reliability of the tool and is proposed as a novel approach for the development of computer aided engineering (cae) applications.",lincosim: a web based hpc-cloud platform for automatic virtual towing tank analysis
652,2-s2.0-85082108959,10.1145/3375258.3375267,A class project to prepare software engineering students for their capstone projects,Posthuma J.,ACM International Conference Proceeding Series,2019-11-18,"We discuss the design of a class project which we have introduced to improve our Software Engineering course presented on the thirdyear graduate level at our institution. For this project, the whole class collaborate to design and implement a single, reasonably large software system. We believe that the class project has the potential to provide an intensive learning experience for our students and may have several educational benefits. We investigate the impact of the class project on student academic achievement and project success in terms of the quality of the code of the developed system. We gauge the impact of the class project by analysing differences the academic performance of the students in the course. Further, we analyzed the differences in assessment marks assigned to projects. We also evaluate the code quality by observing variations in selected software code metrics of the source code of the software systems delivered by the students. Although the results are inconclusive, we feel the class project provides a unique opportunity for students to get hands-on experience in the development of real-world software for industry.",Capstone project class project | Software engineering | Software metrics | Teaching software development,1,66-78,Conference Proceeding,Conference Paper,3.0,"Posthuma, Justus;Pieterse, Vreda;Baror, Stacey",57205115076;22036131800;55971730600,University of Pretoria;Stellenbosch University,South Africa;South Africa,"we discuss the design of a class project which we have introduced to improve our software engineering course presented on the thirdyear graduate level at our institution. for this project, the whole class collaborate to design and implement a single, reasonably large software system. we believe that the class project has the potential to provide an intensive learning experience for our students and may have several educational benefits. we investigate the impact of the class project on student academic achievement and project success in terms of the quality of the code of the developed system. we gauge the impact of the class project by analysing differences the academic performance of the students in the course. further, we analyzed the differences in assessment marks assigned to projects. we also evaluate the code quality by observing variations in selected software code metrics of the source code of the software systems delivered by the students. although the results are inconclusive, we feel the class project provides a unique opportunity for students to get hands-on experience in the development of real-world software for industry.",a class project to prepare software engineering students for their capstone projects
653,2-s2.0-85082681753,10.1145/3375923.3375928,RUN-ONCO: A highly extensible software platform for cancer precision medicine,Peyrone N.,ACM International Conference Proceeding Series,2019-11-13,"Precision medicine is a strategy to personalize disease identification and medical care decisions through genetics. The rapid development of-omics technologies e.g., DNA and RNA sequencin g, which reveal sp ecific gene mutations in a p atient's tumor or profiling of gene expressions for drug responses helps oncologists find effective treatments for individual patients based on their genetics. Hence, besides the clinical records,-omics data become essential for personalized diagnosis and treatments. In this paper, a web-based standalone software platform for cancer precision medicine, called RUN-ONCO, is proposed aiming to help oncologists and researchers manage and make use of the available clinical and-omics data easily and efficiently. The platform allows the management of clinical records, biospecimens, and-omics data and enables various integrative data analyses together with public databases such as STRING and OncoKB. With the increasing number of published methods for various-omics data analyses together with the availability of numerous javascript libraries for data visualization, RUN-ONCO has also been designed to be highly extensible with plugins for both visualizations and analysis methods. A demo version of RUNONCO is available online at http://cucpbioinfo.cp.eng.chula.ac.th:6002 and the source code for local deployment is at https://gitlab.com/peyrone/run-onco.",Analysis plugin | Cancer | Ecnomics | Highly extensible plugin | Precision medicine | Software platform | Visualization plugin,1,142-147,Conference Proceeding,Conference Paper,2.0,"Peyrone, Neda;Wichadakul, Duangdao",57216148972;6603187694,Chulalongkorn University,Thailand,"precision medicine is a strategy to personalize disease identification and medical care decisions through genetics. the rapid development of-omics technologies e.g., dna and rna sequencin g, which reveal sp ecific gene mutations in a p atient's tumor or profiling of gene expressions for drug responses helps oncologists find effective treatments for individual patients based on their genetics. hence, besides the clinical records,-omics data become essential for personalized diagnosis and treatments. in this paper, a web-based standalone software platform for cancer precision medicine, called run-onco, is proposed aiming to help oncologists and researchers manage and make use of the available clinical and-omics data easily and efficiently. the platform allows the management of clinical records, biospecimens, and-omics data and enables various integrative data analyses together with public databases such as string and oncokb. with the increasing number of published methods for various-omics data analyses together with the availability of numerous javascript libraries for data visualization, run-onco has also been designed to be highly extensible with plugins for both visualizations and analysis methods. a demo version of runonco is available online at http://cucpbioinfo.cp.eng.chula.ac.th:6002 and the source code for local deployment is at https://gitlab.com/peyrone/run-onco.",run-onco: a highly extensible software platform for cancer precision medicine
658,2-s2.0-85071978468,10.1080/08830185.2019.1657426,"Immunoinformatics: In Silico Approaches and Computational Design of a Multi-epitope, Immunogenic Protein",Bahrami A.A.,International Reviews of Immunology,2019-11-02,"Immunoinformatics is a new critical field with several tools and databases that conduct the eyesight of experimental selection and facilitate analysis of the great amount of immunologic data obtained from experimental researches and helps to design and introducing new hypothesis. Given these visages, immunoinformatics seems to be the way that develop and progress the immunological research. Bioinformatics methods and applications are successfully employed in vaccine informatics to assist different sites of the preclinical, clinical, and post-licensure vaccine enterprises. On the other hand, the progression of molecular biology and immunology caused epitope vaccines have become the focus of research on molecular vaccines. Moreover, reverse vaccinology could improve vaccine production and vaccination protocols by in silico prediction of protein-vaccine candidates from genome sequences. B- and T-cell immune epitopes could be predicted by immunoinformatics algorithms and computational methods to improve the vaccine design, protective immunity analysis, assessment of vaccine safety and efficacy, and immunization modeling. This review aims to discuss the power of computational approaches in vaccine design and their relevance to the development of effective vaccines. Furthermore, the various divisions of this field and available tools in each item are introduced and reviewed.",Computational immunology | epitope prediction | immunoinformatics | vaccine design,33,307-322,Journal,Review,5.0,"Bahrami, Armina Alagheband;Payandeh, Zahra;Khalili, Saeed;Zakeri, Alireza;Bandehpour, Mojgan",57204845690;56015232000;51261094900;57190001489;16641881900,Tabriz University of Medical Sciences;Shahid Beheshti University of Medical Sciences;Shahid Rajaee Teacher Training University,Iran;Iran;Iran,"immunoinformatics is a new critical field with several tools and databases that conduct the eyesight of experimental selection and facilitate analysis of the great amount of immunologic data obtained from experimental researches and helps to design and introducing new hypothesis. given these visages, immunoinformatics seems to be the way that develop and progress the immunological research. bioinformatics methods and applications are successfully employed in vaccine informatics to assist different sites of the preclinical, clinical, and post-licensure vaccine enterprises. on the other hand, the progression of molecular biology and immunology caused epitope vaccines have become the focus of research on molecular vaccines. moreover, reverse vaccinology could improve vaccine production and vaccination protocols by in silico prediction of protein-vaccine candidates from genome sequences. b- and t-cell immune epitopes could be predicted by immunoinformatics algorithms and computational methods to improve the vaccine design, protective immunity analysis, assessment of vaccine safety and efficacy, and immunization modeling. this review aims to discuss the power of computational approaches in vaccine design and their relevance to the development of effective vaccines. furthermore, the various divisions of this field and available tools in each item are introduced and reviewed.","immunoinformatics: in silico approaches and computational design of a multi-epitope, immunogenic protein"
660,2-s2.0-85081985077,10.1109/ICSAI48974.2019.9010342,Generic software architecture for semantic and visual queries,Zepeda S.,"2019 6th International Conference on Systems and Informatics, ICSAI 2019",2019-11-01,"Software architecture is a very important part in the development and life cycle of large and complex software. Large companies and research institutes generate software architectures for very specific uses. However, these can be hardly adopted for other purposes and uses. Therefore, there is a lack of generic architectures that can be easily used in any type of problem and these can be sufficiently flexible to be implemented in different contexts, mainly in the context of systems with databases with scientific information. In this paper, we present the design and implementation of a generic architecture that allows semantic and visual queries from a web interface. This architecture is easily scalable, because it is divided into separate layers that can be interchangeable and each layer has specific purposes. This generic software architecture is composed of three important features: Semantic, Rich Interaction and Control. Therefore, the system implemented with this architecture can be easily adaptable to different contexts and it can be evolved and scalable over time. In this paper, we describe in detail all the layers involved and their purpose. So this architecture can be implemented in all types of systems that need a visual interaction of their information. The contribution of this generic architecture is that it can be adapted to provide new types of interaction with different types of scientific information.",Component | Computer Applications | Scientific databases | Software architecture | Software Engineering | Software Systems and Applications,1,1553-1558,Conference Proceeding,Conference Paper,3.0,"Zepeda, Sergio;Estrada, Juan;Estrada, Daniel",55804044500;55899850900;36010545300,Centro de Investigacion y de Estudios Avanzados;Universidad Autónoma Metropolitana,Mexico;Mexico,"software architecture is a very important part in the development and life cycle of large and complex software. large companies and research institutes generate software architectures for very specific uses. however, these can be hardly adopted for other purposes and uses. therefore, there is a lack of generic architectures that can be easily used in any type of problem and these can be sufficiently flexible to be implemented in different contexts, mainly in the context of systems with databases with scientific information. in this paper, we present the design and implementation of a generic architecture that allows semantic and visual queries from a web interface. this architecture is easily scalable, because it is divided into separate layers that can be interchangeable and each layer has specific purposes. this generic software architecture is composed of three important features: semantic, rich interaction and control. therefore, the system implemented with this architecture can be easily adaptable to different contexts and it can be evolved and scalable over time. in this paper, we describe in detail all the layers involved and their purpose. so this architecture can be implemented in all types of systems that need a visual interaction of their information. the contribution of this generic architecture is that it can be adapted to provide new types of interaction with different types of scientific information.",generic software architecture for semantic and visual queries
661,2-s2.0-85080065118,10.1109/CAC48633.2019.8997352,The Design and Implementation of Cloud Web Service-based TPMS for Fleet Management,Sun C.,"Proceedings - 2019 Chinese Automation Congress, CAC 2019",2019-11-01,"Identifying tyre pressure or temperature deviations is vital to ensuring the safety and longevity of a fleet's tyres. The benefits of installing the tyre pressure monitoring system (TPMS) are available both at the new product development process of vehicle factory as well as the product upgrading for aftermarket solution. In this paper, we have proposed a system that offers our users real-time information about the state of their fleet vehicle tyres, including pressure, temperature, overall wear and these records for subsequent analysis. Unlike other TPMS solutions that only locally report real-time tire data such as pressure and temperature information to the driver of the vehicle, whenever any problems in the tyres such as pressure temperature outside pre-configured limits, our proposed system sends data back to a cloud server for processing and analysis. With an unlimited number of users and 24/7 access, this HTTP web-based software gives back office management unmatched visibility through some RESTful APIs by using desktop or mobile application. The target of proposed system is allowing fleet managers to further improve fleet management requirements, optimal fuel consumption and reduced breakdowns. This system is suitable for all kinds of vehicle fleet including trailers, bus, trucks and any other Heavy-duty vehicles.",cloud | fleet management | mobile | RESTful API | TPMS | web service,0,1240-1243,Conference Proceeding,Conference Paper,5.0,"Sun, Changqing;Guo, Kun;Zheng, Fuquan;Zhou, Guangxu;Hou, Dongdong",57215185149;57214163440;57215195646;24722140200;55576066700,Qilu University of Technology,China,"identifying tyre pressure or temperature deviations is vital to ensuring the safety and longevity of a fleet's tyres. the benefits of installing the tyre pressure monitoring system (tpms) are available both at the new product development process of vehicle factory as well as the product upgrading for aftermarket solution. in this paper, we have proposed a system that offers our users real-time information about the state of their fleet vehicle tyres, including pressure, temperature, overall wear and these records for subsequent analysis. unlike other tpms solutions that only locally report real-time tire data such as pressure and temperature information to the driver of the vehicle, whenever any problems in the tyres such as pressure temperature outside pre-configured limits, our proposed system sends data back to a cloud server for processing and analysis. with an unlimited number of users and 24/7 access, this http web-based software gives back office management unmatched visibility through some restful apis by using desktop or mobile application. the target of proposed system is allowing fleet managers to further improve fleet management requirements, optimal fuel consumption and reduced breakdowns. this system is suitable for all kinds of vehicle fleet including trailers, bus, trucks and any other heavy-duty vehicles.",the design and implementation of cloud web service-based tpms for fleet management
663,2-s2.0-85078949698,10.1109/ASE.2019.00098,Semistructured merge in Javascript systems,Tavares A.T.,"Proceedings - 2019 34th IEEE/ACM International Conference on Automated Software Engineering, ASE 2019",2019-11-01,"Industry widely uses unstructured merge tools that rely on textual analysis to detect and resolve conflicts between code contributions. Semistructured merge tools go further by partially exploring the syntactic structure of code artifacts, and, as a consequence, obtaining significant merge accuracy gains for Java-like languages. To understand whether semistructured merge and the observed gains generalize to other kinds of languages, we implement two semistructured merge tools for JavaScript, and compare them to an unstructured tool. We find that current semistructured merge algorithms and frameworks are not directly applicable for scripting languages like JavaScript. By adapting the algorithms, and studying 10,345 merge scenarios from 50 JavaScript projects on GitHub, we find evidence that our JavaScript tools report fewer spurious conflicts than unstructured merge, without compromising the correctness of the merging process. The gains, however, are much smaller than the ones observed for Java-like languages, suggesting that semistructured merge advantages might be limited for languages that allow both commutative and non-commutative declarations at the same syntactic level.",Collaborative development | JavaScript | Semistructured merge | Software merging | Version control systems,2,1014-1025,Conference Proceeding,Conference Paper,4.0,"Tavares, Alberto Trindade;Borba, Paulo;Cavalcanti, Guilherme;Soares, Sergio",55389622500;57226225443;57188562125;7006550899,Universidade de Pernambuco,Brazil,"industry widely uses unstructured merge tools that rely on textual analysis to detect and resolve conflicts between code contributions. semistructured merge tools go further by partially exploring the syntactic structure of code artifacts, and, as a consequence, obtaining significant merge accuracy gains for java-like languages. to understand whether semistructured merge and the observed gains generalize to other kinds of languages, we implement two semistructured merge tools for javascript, and compare them to an unstructured tool. we find that current semistructured merge algorithms and frameworks are not directly applicable for scripting languages like javascript. by adapting the algorithms, and studying 10,345 merge scenarios from 50 javascript projects on github, we find evidence that our javascript tools report fewer spurious conflicts than unstructured merge, without compromising the correctness of the merging process. the gains, however, are much smaller than the ones observed for java-like languages, suggesting that semistructured merge advantages might be limited for languages that allow both commutative and non-commutative declarations at the same syntactic level.",semistructured merge in javascript systems
668,2-s2.0-85049844140,10.1016/j.bjorl.2018.05.011,Elaboration of an instrument to evaluate the recognition of Brazilian melodies in children,Mondelli M.F.C.G.,Brazilian Journal of Otorhinolaryngology,2019-11-01,"Introduction: There is evidence pointing to the importance of the evaluation of musical perception through objective and subjective instruments. In Brazil, there is a shortage of instruments that evaluates musical perception. Objective: To develop an instrument to evaluate the recognition of traditional Brazilian melodies and investigate the performance of children with typical hearing. Methods: The study was carried out after approval of the research ethics committee (1.198.607). The instrument was developed in software format with website access, using the languages PHP 5.5.12, Javascript, Cascade style sheets and “HTML5”; database “MYSQL 5.6.17” on the “Apache 2.4.9” server. Fifteen melodies of Brazilian folk songs were recorded in piano synthesized timbre, with 12 seconds per melody reproduction and four second intervals between them. A total of 155 schooled children, aged eight to 11 years, of both sexes, with typical hearing participated in the study. The test was performed in a silent room with sound stimuli amplified by a sound box at 65 dBNA, positioned at 0 azimuth, and at one meter from the participant, the notebook was used for children to play with on the screen on the title and illustration of the melody they recognized they were listening to. The responses were recorded on their own database. Results: The instrument titled “Evaluation of recognition of traditional melodies in children” can be run on various devices (computers, notebooks, tablets, mobile phones) and operating systems (Windows, Macintosh, Android, Linux). Access: http://192.185.216.17/ivan/home/login.php by login and password. The most easily recognized melody was “Cai, cai balão” (89%) and the least recognized was “Capelinha de melão” (25.2%). The average time to perform the test was 3′15″. Conclusion: The development and application of the software proved effective for the studied population. This instrument may contribute to the improvement of protocols for the evaluation of musical perception in children with hearing aid and/or cochlear implants users.",Child | Hearing | Hearing aids | Music,0,690-697,Journal,Article,4.0,"Mondelli, Maria Fernanda Capoani Garcia;José, Ivan dos Santos;José, Maria Renata;Lopes, Natália Barreto Frederigue",36646513500;57202926598;25230139600;36238917300,Universidade de São Paulo,Brazil,"introduction: there is evidence pointing to the importance of the evaluation of musical perception through objective and subjective instruments. in brazil, there is a shortage of instruments that evaluates musical perception. objective: to develop an instrument to evaluate the recognition of traditional brazilian melodies and investigate the performance of children with typical hearing. methods: the study was carried out after approval of the research ethics committee (1.198.607). the instrument was developed in software format with website access, using the languages php 5.5.12, javascript, cascade style sheets and “html5”; database “mysql 5.6.17” on the “apache 2.4.9” server. fifteen melodies of brazilian folk songs were recorded in piano synthesized timbre, with 12 seconds per melody reproduction and four second intervals between them. a total of 155 schooled children, aged eight to 11 years, of both sexes, with typical hearing participated in the study. the test was performed in a silent room with sound stimuli amplified by a sound box at 65 dbna, positioned at 0 azimuth, and at one meter from the participant, the notebook was used for children to play with on the screen on the title and illustration of the melody they recognized they were listening to. the responses were recorded on their own database. results: the instrument titled “evaluation of recognition of traditional melodies in children” can be run on various devices (computers, notebooks, tablets, mobile phones) and operating systems (windows, macintosh, android, linux). access: http://192.185.216.17/ivan/home/login.php by login and password. the most easily recognized melody was “cai, cai balão” (89%) and the least recognized was “capelinha de melão” (25.2%). the average time to perform the test was 3′15″. conclusion: the development and application of the software proved effective for the studied population. this instrument may contribute to the improvement of protocols for the evaluation of musical perception in children with hearing aid and/or cochlear implants users.",elaboration of an instrument to evaluate the recognition of brazilian melodies in children
669,2-s2.0-85076640850,10.1145/3359619.3359743,Python programmers have GPUs too: Automatic python loop parallelization with staged dependence analysis,Jacob D.,"DLS 2019 - Proceedings of the 15th ACM SIGPLAN International Symposium on Dynamic Languages, co-located with SPLASH 2019",2019-10-20,"Python is a popular language for end-user software development in many application domains. End-users want to harness parallel compute resources effectively, by exploiting commodity manycore technology including GPUs. However, existing approaches to parallelism in Python are esoteric, and generally seem too complex for the typical end-user developer. We argue that implicit, or automatic, parallelization is the best way to deliver the benefits of manycore to end-users, since it avoids domain-specific languages, specialist libraries, complex annotations or restrictive language subsets. Auto-parallelization fits the Python philosophy, provides effective performance, and is convenient for non-expert developers. Despite being a dynamic language, we show that Python is a suitable target for auto-parallelization. In an empirical study of 3000+ open-source Python notebooks, we demonstrate that typical loop behaviour ‘in the wild’ is amenable to auto-parallelization. We show that staging the dependence analysis is an effective way to maximize performance. We apply classical dependence analysis techniques, then leverage the Python runtime’s rich introspection capabilities to resolve additional loop bounds and variable types in a just-in-time manner. The parallel loop nest code is then converted to CUDA kernels for GPU execution. We achieve orders of magnitude speedup over baseline interpreted execution and some speedup (up to 50x, although not consistently) over CPU JIT-compiled execution, across 12 loop-intensive standard benchmarks.",Code generation | GPU | Nested loop parallelization,3,42-54,Conference Proceeding,Conference Paper,3.0,"Jacob, Dejice;Trinder, Phil;Singer, Jeremy",57191622576;7003497230;14827373300,University of Glasgow,United Kingdom,"python is a popular language for end-user software development in many application domains. end-users want to harness parallel compute resources effectively, by exploiting commodity manycore technology including gpus. however, existing approaches to parallelism in python are esoteric, and generally seem too complex for the typical end-user developer. we argue that implicit, or automatic, parallelization is the best way to deliver the benefits of manycore to end-users, since it avoids domain-specific languages, specialist libraries, complex annotations or restrictive language subsets. auto-parallelization fits the python philosophy, provides effective performance, and is convenient for non-expert developers. despite being a dynamic language, we show that python is a suitable target for auto-parallelization. in an empirical study of 3000+ open-source python notebooks, we demonstrate that typical loop behaviour ‘in the wild’ is amenable to auto-parallelization. we show that staging the dependence analysis is an effective way to maximize performance. we apply classical dependence analysis techniques, then leverage the python runtime’s rich introspection capabilities to resolve additional loop bounds and variable types in a just-in-time manner. the parallel loop nest code is then converted to cuda kernels for gpu execution. we achieve orders of magnitude speedup over baseline interpreted execution and some speedup (up to 50x, although not consistently) over cpu jit-compiled execution, across 12 loop-intensive standard benchmarks.",python programmers have gpus too: automatic python loop parallelization with staged dependence analysis
672,2-s2.0-85081105122,10.1109/ISSRE.2019.00048,Benefits and Challenges of Model-Based Software Engineering: Lessons Learned Based on Qualitative and Quantitative Findings,Goseva-Popstojanova K.,"Proceedings - International Symposium on Software Reliability Engineering, ISSRE",2019-10-01,"Even though Model-based Software Engineering (MBSwE) techniques and Autogenerated Code (AGC) have been increasingly used to produce complex software systems, there is only anecdotal knowledge about the state-of-the practice. Furthermore, there is a lack of empirical studies that explore the potential quality improvements due to the use of these techniques. This paper presents in-depth qualitative findings about development and Software Assurance (SWA) practices and detailed quantitative analysis of software bug reports of a NASA mission that used MBSwE and AGC. The mission's flight software is a combination of handwritten code and AGC developed by two different approaches: one based on state chart models (AGC-M) and another on specification dictionaries (AGC-D). The empirical analysis of fault proneness is based on 380 closed bug reports created by software developers. Our main findings include: (1) MBSwE and AGC provide some benefits, but also impose challenges. (2) SWA done only at a model level is not sufficient. AGC code should also be tested and the models and AGC should always be kept in-sync. AGC must not be changed manually. (3) Fixes made to address an individual bug report were spread both across multiple modules and across multiple files. On average, for each bug report 1.4 modules, that is, 3.4 files were fixed. (4) Most bug reports led to changes in more than one type of file. The majority of changes to auto-generated source code files were made in conjunction to changes in either file with state chart models or XML files derived from dictionaries. (5) For newly developed files, AGC-M and handwritten code were of similar quality, while AGC-D files were the least fault prone.",Analysis of faults and fixes | Autogenerated Code | Model based software engineering | Software quality assurance,0,413-423,Conference Proceeding,Conference Paper,3.0,"Goseva-Popstojanova, Katerina;Kyanko, Thomas;Nkwocha, Noble",6602778978;57202233984;57215537940,West Virginia University;National Aeronautics and Space Administration;Berkshire Grey,United States;United States;United States,"even though model-based software engineering (mbswe) techniques and autogenerated code (agc) have been increasingly used to produce complex software systems, there is only anecdotal knowledge about the state-of-the practice. furthermore, there is a lack of empirical studies that explore the potential quality improvements due to the use of these techniques. this paper presents in-depth qualitative findings about development and software assurance (swa) practices and detailed quantitative analysis of software bug reports of a nasa mission that used mbswe and agc. the mission's flight software is a combination of handwritten code and agc developed by two different approaches: one based on state chart models (agc-m) and another on specification dictionaries (agc-d). the empirical analysis of fault proneness is based on 380 closed bug reports created by software developers. our main findings include: (1) mbswe and agc provide some benefits, but also impose challenges. (2) swa done only at a model level is not sufficient. agc code should also be tested and the models and agc should always be kept in-sync. agc must not be changed manually. (3) fixes made to address an individual bug report were spread both across multiple modules and across multiple files. on average, for each bug report 1.4 modules, that is, 3.4 files were fixed. (4) most bug reports led to changes in more than one type of file. the majority of changes to auto-generated source code files were made in conjunction to changes in either file with state chart models or xml files derived from dictionaries. (5) for newly developed files, agc-m and handwritten code were of similar quality, while agc-d files were the least fault prone.",benefits and challenges of model-based software engineering: lessons learned based on qualitative and quantitative findings
674,2-s2.0-85080926480,10.1109/ISSREW.2019.00084,Empirical notes on the interaction between continuous kernel fuzzing and development,Ruohonen J.,"Proceedings - 2019 IEEE 30th International Symposium on Software Reliability Engineering Workshops, ISSREW 2019",2019-10-01,"Fuzzing has been studied and applied ever since the 1990s. Automated and continuous fuzzing has recently been applied also to open source software projects, including the Linux and BSD kernels. This paper concentrates on the practical aspects of continuous kernel fuzzing in four open source kernels. According to the results, there are over 800 unresolved crashes reported for the four kernels by the syzkaller/syzbot framework. Many of these have been reported relatively long ago. Interestingly, fuzzing-induced bugs have been resolved in the BSD kernels more rapidly. Furthermore, assertions and debug checks, use-After-frees, and general protection faults account for the majority of bug types in the Linux kernel. About 23% of the fixed bugs in the Linux kernel have either went through code review or additional testing. Finally, only code churn provides a weak statistical signal for explaining the associated bug fixing times in the Linux kernel.",BSD | crash | Linux | software vulnerability,0,276-281,Conference Proceeding,Conference Paper,2.0,"Ruohonen, Jukka;Rindell, Kalle",56743033000;57105437200,SINTEF Digital;Turun yliopisto,Norway;Finland,"fuzzing has been studied and applied ever since the 1990s. automated and continuous fuzzing has recently been applied also to open source software projects, including the linux and bsd kernels. this paper concentrates on the practical aspects of continuous kernel fuzzing in four open source kernels. according to the results, there are over 800 unresolved crashes reported for the four kernels by the syzkaller/syzbot framework. many of these have been reported relatively long ago. interestingly, fuzzing-induced bugs have been resolved in the bsd kernels more rapidly. furthermore, assertions and debug checks, use-after-frees, and general protection faults account for the majority of bug types in the linux kernel. about 23% of the fixed bugs in the linux kernel have either went through code review or additional testing. finally, only code churn provides a weak statistical signal for explaining the associated bug fixing times in the linux kernel.",empirical notes on the interaction between continuous kernel fuzzing and development
675,2-s2.0-85079276810,10.1109/ICMCCE48743.2019.00153,Research on development and design of virtual acupuncture teaching software based on HTC VIVE,Gao H.,"Proceedings - 2019 4th International Conference on Mechanical, Control and Computer Engineering, ICMCCE 2019",2019-10-01,"With the continuous development of computer technology, virtual reality technology has been applied more and more in traditional teaching. In order to improve the students' interest in learning Chinese acupuncture, this paper studies the key technologies in the development of virtual acupuncture teaching software based on virtual reality technology. Model the human body is modeled and pays attention to the contour drawing of the key parts of the human body. The software combines with the current most popular virtual reality device HTC VIVE and uses the Unity3d software to create virtual scenes. Finally, acupoint information models are represented and stored through JavaScript Object Notation (JSON) language, which completes the design of human-computer interaction mode. The implementation of virtual reality technology provides a new method and reference solution for assisting Chinese acupuncture teaching.",Acupuncture Teaching | HTC VIVE | Human-computer Interaction | Virtual Reality,0,660-663,Conference Proceeding,Conference Paper,4.0,"Gao, Honglei;Gao, Yong;Kan, Hongxing;Chen, Guang En",57215124622;57215115676;16233306900;57215142339,Anhui University of Chinese Medicine,China,"with the continuous development of computer technology, virtual reality technology has been applied more and more in traditional teaching. in order to improve the students' interest in learning chinese acupuncture, this paper studies the key technologies in the development of virtual acupuncture teaching software based on virtual reality technology. model the human body is modeled and pays attention to the contour drawing of the key parts of the human body. the software combines with the current most popular virtual reality device htc vive and uses the unity3d software to create virtual scenes. finally, acupoint information models are represented and stored through javascript object notation (json) language, which completes the design of human-computer interaction mode. the implementation of virtual reality technology provides a new method and reference solution for assisting chinese acupuncture teaching.",research on development and design of virtual acupuncture teaching software based on htc vive
676,2-s2.0-85074640700,10.35940/ijeat.A2051.109119,Performance measure of project management automation tool based on DevOps selection criteria for a general purpose software system,Poonam D.,International Journal of Engineering and Advanced Technology,2019-10-01,"DevOps, a cluster of tools to automate the tasks of building, testing and releasing the software, intends to optimize the end to end delivery lifecycle of software by eliminating the bottlenecks of each and every stage of development. This research paper presents the performance measure of different tools in the project planning and management phase of software development. Diverse tools exist for each and every phase of the development and depending on the outcome of the evaluation or selection criteria, tool with highest score is being chosen. This paper measures the performance of alternative project management tools viz. Jira, Trello, Leankit, AgileCraft based on these evaluation or selection criteria. To execute the underlying research work, a six-point scaling table is defined. The table measures the performance of project management automation tools and realizing their competence level score. This performance measure or the outcome as competence level score will be useful for the researchers or software developers to contemplate the best project management automation tool typically before making a decision about tool selection.",Automation | Automation Tools | DevOps | Project Management | Project Planning | Software development,0,6263-6267,Journal,Article,2.0,"Poonam, Development;Mittal, Pooja",57211620330;56973671500,Maharshi Dayanand University,India,"devops, a cluster of tools to automate the tasks of building, testing and releasing the software, intends to optimize the end to end delivery lifecycle of software by eliminating the bottlenecks of each and every stage of development. this research paper presents the performance measure of different tools in the project planning and management phase of software development. diverse tools exist for each and every phase of the development and depending on the outcome of the evaluation or selection criteria, tool with highest score is being chosen. this paper measures the performance of alternative project management tools viz. jira, trello, leankit, agilecraft based on these evaluation or selection criteria. to execute the underlying research work, a six-point scaling table is defined. the table measures the performance of project management automation tools and realizing their competence level score. this performance measure or the outcome as competence level score will be useful for the researchers or software developers to contemplate the best project management automation tool typically before making a decision about tool selection.",performance measure of project management automation tool based on devops selection criteria for a general purpose software system
678,2-s2.0-85073753183,10.35940/ijitee.L3789.1081219,MUTWEB-A testing tool for performing mutation testing of java and servlet based web applications,Suguna Mallika S.,International Journal of Innovative Technology and Exploring Engineering,2019-10-01,"Mutation testing is one of the oldest and unique testing techniques to perform white box testing of software applications. Code coverage becoming an increasing concern in the testing cycle of software, mutation testing technique aids in achieving higher code coverage and unearthing more number of errors at the testing site itself. The parameters like the database connectivity, session management, cookie management, are the beginning point of web application testing failures given the heterogeneity aspects associated with the development of a web application. A detailed account on list of available testing tools for performing mutation testing are presented here. A big bundle of mutation testing tools are still available, however they are not focussing on some of the crucial web vulnerabilities like session and cookie management in web apps. In the current work, a tool to perform mutation testing of web applications is developed and tested to see if desired results are occurring. An architecture of the tool is designed is discussed and presented. A brief analysis on results is presented.",Automated testing tool | Mutation testing | Web application testing,2,5406-5413,Journal,Article,2.0,"Suguna Mallika, S.;Rajya Lakshmi, D.",57211310382;55446136700,CVR College of Engineering;CSE,India;India,"mutation testing is one of the oldest and unique testing techniques to perform white box testing of software applications. code coverage becoming an increasing concern in the testing cycle of software, mutation testing technique aids in achieving higher code coverage and unearthing more number of errors at the testing site itself. the parameters like the database connectivity, session management, cookie management, are the beginning point of web application testing failures given the heterogeneity aspects associated with the development of a web application. a detailed account on list of available testing tools for performing mutation testing are presented here. a big bundle of mutation testing tools are still available, however they are not focussing on some of the crucial web vulnerabilities like session and cookie management in web apps. in the current work, a tool to perform mutation testing of web applications is developed and tested to see if desired results are occurring. an architecture of the tool is designed is discussed and presented. a brief analysis on results is presented.",mutweb-a testing tool for performing mutation testing of java and servlet based web applications
679,2-s2.0-85072255739,10.4018/IJCINI.2019100101,RDMTK: A toolkit for risky decision making,Gavirangaswamy V.,International Journal of Cognitive Informatics and Natural Intelligence,2019-10-01,"Research into risky decision making (RDM) has become a multidisciplinary effort. Conversations cut across fields such as psychology, economics, insurance, and marketing. This broad interest highlights the necessity for collaborative investigation of RDM to understand and manipulate the situations within which it manifests. A holistic understanding of RDM has been impeded by the independent development of diverse RDM research methodologies across different fields. There is no software specific to RDM that combines paradigms and analytical tools based on recent developments in high-performance computing technologies. This paper presents a toolkit called RDMTk, developed specifically for the study of risky decision making. RDMTk provides a free environment that can be used to manage globally-based experiments while fostering collaborative research. The incorporation of machine learning and high-performance computing (HPC) technologies in the toolkit further open additional possibilities such as scalable algorithms and big data problems arising from global scale experiments.",Analysis Toolkit | Big Data | High Performance Computing | Risky Decision Making | SaaS,1,1-38,Journal,Article,4.0,"Gavirangaswamy, Vinay;Gupta, Aakash;Terwilliger, Mark;Gupta, Ajay",49863320700;57209589471;6701406397;8354044800,University of North Alabama;University of Pennsylvania;Western Michigan University,United States;United States;United States,"research into risky decision making (rdm) has become a multidisciplinary effort. conversations cut across fields such as psychology, economics, insurance, and marketing. this broad interest highlights the necessity for collaborative investigation of rdm to understand and manipulate the situations within which it manifests. a holistic understanding of rdm has been impeded by the independent development of diverse rdm research methodologies across different fields. there is no software specific to rdm that combines paradigms and analytical tools based on recent developments in high-performance computing technologies. this paper presents a toolkit called rdmtk, developed specifically for the study of risky decision making. rdmtk provides a free environment that can be used to manage globally-based experiments while fostering collaborative research. the incorporation of machine learning and high-performance computing (hpc) technologies in the toolkit further open additional possibilities such as scalable algorithms and big data problems arising from global scale experiments.",rdmtk: a toolkit for risky decision making
687,2-s2.0-85077813565,10.1109/SCAM.2019.00018,No accounting for taste: Supporting developers' individual choices of coding styles,Gomes I.M.M.,"Proceedings - 19th IEEE International Working Conference on Source Code Analysis and Manipulation, SCAM 2019",2019-09-01,"When creating their programs, developers usually have a preferred or standardized style of their own to write code, known as coding style. Such code is usually stored in a version control repository, through which collaborative work usually takes place. However, in such a setting, isolated attempts of standardization can lead to several coding styles coexisting in the same project, causing the opposite effect to that intended. Besides increasing the effort required to understand code, coding style conflicts may also clutter repository history as developers change existing styles to their usual preferences. To overcome this problem, we propose an approach to support the definition of a repository coding style while allowing developers to use their preferred coding style. To illustrate our approach, we built the RECoSt tool and applied it using real excerpts of a popular open source project. Our proposed approach intends to help developers keep their projects' coding style standardized without having to abandon the style they are familiar with.",Coding styles | Software development | Version control repositories,1,86-91,Conference Proceeding,Conference Paper,3.0,"Gomes, Isaac Moreira Medeiros;Coutinho, Daniel;Schots, Marcelo",57213520778;57220410075;37361380900,Universidade do Estado do Rio de Janeiro,Brazil,"when creating their programs, developers usually have a preferred or standardized style of their own to write code, known as coding style. such code is usually stored in a version control repository, through which collaborative work usually takes place. however, in such a setting, isolated attempts of standardization can lead to several coding styles coexisting in the same project, causing the opposite effect to that intended. besides increasing the effort required to understand code, coding style conflicts may also clutter repository history as developers change existing styles to their usual preferences. to overcome this problem, we propose an approach to support the definition of a repository coding style while allowing developers to use their preferred coding style. to illustrate our approach, we built the recost tool and applied it using real excerpts of a popular open source project. our proposed approach intends to help developers keep their projects' coding style standardized without having to abandon the style they are familiar with.",no accounting for taste: supporting developers' individual choices of coding styles
689,2-s2.0-85075942673,10.30534/ijatcse/2019/30852019,A security approach for file management system using data encryption standard (DES) algorithm,Plata I.T.,International Journal of Advanced Trends in Computer Science and Engineering,2019-09-01,"Security is very essential to avoid the unauthorized exposé or modification of the information. Due to the extraordinary changes in advance these days, various mixed media information is being produced and transmitted, hence, leaving our very own information defenseless against alteration and copying. Information being transmitted through a communication system can be ensured through cryptography. In an information processing environment, cryptography is executed through a process which uses a mystery key or an arrangement of bits. This paper established a security key management scheme that provides the support necessary to protect files or records between individual end users, and that also can be used to protect data stored or conveyed from one computer to another. It contains encryption and decryption process, each related with a key which should be stayed secret through Data Encryption Standard (DES). The authors employed System Development Life Cycle (SDLC), particularly on Rapid Application Development (RAD). This method involves initial data gathering, cost and requirements’ analysis, and identification of the methods to be used in designing, testing, deploying and sustaining the system. Specifically, this paper used the block cipher approach as the main framework. The reliability of this system is measured using several tests done in the system. Experimental analysis includes testing in hardware and software components, system components, system units, and system integration and acceptance. The results showed that the performance of the system is in its best condition. There are four (4) parameters used in checking the complexity and time latency (CTL) in the DES algorithm. These were physical server, web server, network connectivity, and system. From each parameter, the system undergone three (3) phases of processes. Furthermore, questionnaires were floated to the respondents to assess the security system developed in terms of its usability, functionality, and reliability. The questionnaire was taken from an International Standard in evaluating system software called the ISO/IEC 25010:2011. The system was accomplished based from software tools like PHP, Apache, HTML, CSS and JavaScript for the system development and MySQL for its database. In the end, the researchers achieved high security through the implementation of DES algorithm.",Cryptography | Data encryption standard (DES) | Data security | File management | Rapid application development,4,2042-2048,Journal,Article,3.0,"Plata, Irma T.;Panganiban, Edward B.;Bartolome, Bryan B.",57212105411;57201298762;57212102749,Isabela State University,Philippines,"security is very essential to avoid the unauthorized exposé or modification of the information. due to the extraordinary changes in advance these days, various mixed media information is being produced and transmitted, hence, leaving our very own information defenseless against alteration and copying. information being transmitted through a communication system can be ensured through cryptography. in an information processing environment, cryptography is executed through a process which uses a mystery key or an arrangement of bits. this paper established a security key management scheme that provides the support necessary to protect files or records between individual end users, and that also can be used to protect data stored or conveyed from one computer to another. it contains encryption and decryption process, each related with a key which should be stayed secret through data encryption standard (des). the authors employed system development life cycle (sdlc), particularly on rapid application development (rad). this method involves initial data gathering, cost and requirements’ analysis, and identification of the methods to be used in designing, testing, deploying and sustaining the system. specifically, this paper used the block cipher approach as the main framework. the reliability of this system is measured using several tests done in the system. experimental analysis includes testing in hardware and software components, system components, system units, and system integration and acceptance. the results showed that the performance of the system is in its best condition. there are four (4) parameters used in checking the complexity and time latency (ctl) in the des algorithm. these were physical server, web server, network connectivity, and system. from each parameter, the system undergone three (3) phases of processes. furthermore, questionnaires were floated to the respondents to assess the security system developed in terms of its usability, functionality, and reliability. the questionnaire was taken from an international standard in evaluating system software called the iso/iec 25010:2011. the system was accomplished based from software tools like php, apache, html, css and javascript for the system development and mysql for its database. in the end, the researchers achieved high security through the implementation of des algorithm.",a security approach for file management system using data encryption standard (des) algorithm
690,2-s2.0-85075792566,10.1109/SecDev.2019.00023,"Role-based ecosystem for the design, development, and deployment of secure multi-party data analytics applications",Lapets A.,"Proceedings - 2019 IEEE Secure Development, SecDev 2019",2019-09-01,"Software applications that employ secure multi-party computation (MPC) can empower individuals and organizations to benefit from privacy-preserving data analyses when data sharing is encumbered by confidentiality concerns, legal constraints, or corporate policies. MPC is already being incorporated into software solutions in some domains; however, individual use cases do not fully convey the variety, extent, and complexity of the opportunities of MPC. This position paper articulates a role-based perspective that can provide some insight into how future research directions, infrastructure development and evaluation approaches, and deployment practices for MPC may evolve. Drawing on our own lessons from existing real-world deployments and the fundamental characteristics of MPC that make it a compelling technology, we propose a role-based conceptual framework for describing MPC deployment scenarios. Our framework acknowledges and leverages a novel assortment of roles that emerge from the fundamental ways in which MPC protocols support federation of functionalities and responsibilities. Defining these roles using the new opportunities for federation that MPC enables in turn can help identify and organize the capabilities, concerns, incentives, and trade-offs that affect the entities (software engineers, government regulators, corporate executives, end-users, and others) that participate in an MPC deployment scenario. This framework can not only guide the development of an ecosystem of modular and composable MPC tools, but can make explicit some of the opportunities that researchers and software engineers (and any organizations they form) have to differentiate and specialize the artifacts and services they choose to design, develop, and deploy. We demonstrate how this framework can be used to describe existing MPC deployment scenarios, how new opportunities in a scenario can be observed by disentangling roles inhabited by the involved parties, and how this can motivate the development of MPC libraries and software tools that specialize not by application domain but by role.",Data privacy | Multi party computation | Software architecture,0,129-140,Conference Proceeding,Conference Paper,7.0,"Lapets, Andrei;Albab, Kinan Dak;Issa, Rawane;Qin, Lucy;Varia, Mayank;Bestavros, Azer;Jansen, Frederick",36094582500;57196329861;57202433803;57203100701;55832032700;7004003556;57193601851,Boston University,United States,"software applications that employ secure multi-party computation (mpc) can empower individuals and organizations to benefit from privacy-preserving data analyses when data sharing is encumbered by confidentiality concerns, legal constraints, or corporate policies. mpc is already being incorporated into software solutions in some domains; however, individual use cases do not fully convey the variety, extent, and complexity of the opportunities of mpc. this position paper articulates a role-based perspective that can provide some insight into how future research directions, infrastructure development and evaluation approaches, and deployment practices for mpc may evolve. drawing on our own lessons from existing real-world deployments and the fundamental characteristics of mpc that make it a compelling technology, we propose a role-based conceptual framework for describing mpc deployment scenarios. our framework acknowledges and leverages a novel assortment of roles that emerge from the fundamental ways in which mpc protocols support federation of functionalities and responsibilities. defining these roles using the new opportunities for federation that mpc enables in turn can help identify and organize the capabilities, concerns, incentives, and trade-offs that affect the entities (software engineers, government regulators, corporate executives, end-users, and others) that participate in an mpc deployment scenario. this framework can not only guide the development of an ecosystem of modular and composable mpc tools, but can make explicit some of the opportunities that researchers and software engineers (and any organizations they form) have to differentiate and specialize the artifacts and services they choose to design, develop, and deploy. we demonstrate how this framework can be used to describe existing mpc deployment scenarios, how new opportunities in a scenario can be observed by disentangling roles inhabited by the involved parties, and how this can motivate the development of mpc libraries and software tools that specialize not by application domain but by role.","role-based ecosystem for the design, development, and deployment of secure multi-party data analytics applications"
692,2-s2.0-85073071351,10.2166/hydro.2019.101,Visual analysis of three-dimensional flow field based on WebVR,Zhao S.,Journal of Hydroinformatics,2019-09-01,"With the rapid development of internet technologies, it is possible to provide computing services and visualize calculated results on the internet. A three-dimensional flow field visualization method based on WebVR is presented in this paper. We devised and built an immersive and interactive three-dimensional virtual reality scene employing web-standard technologies (i.e., HTML5, JavaScript, WebGL, and Ajax) and computing services provided by hydrodynamic software, using GPUs to accelerate the display of flow field in the browser, without the use of plug-ins. On the basis of three-dimensional topography and surface flow field, a three-dimensional flow field presentation method of superimposing multiple sections into the original computational domain was proposed. Furthermore, the description of tracer sphere and path line was adopted to describe the structure characteristics of the flow field. Replacing complete three-dimensional sphere models with textured stylized particles improved the frame rate of the browser greatly when rendering animations. This research enables developers and users of the hydrodynamic model to be immersed in their data of flow field using Google Cardboard. As far as we know, this is the first time that WebVR technology has been applied in three-dimensional hydrodynamic simulation.",Hydrodynamic model | Network simulation | Visual analysis | WebGL | WebVR,1,671-686,Journal,Article,4.0,"Zhao, Shilin;Jin, Sheng;Ai, Congfang;Zhang, Nan",57211230437;55444114100;23767796500;57211226549,Liaoning University of International Business and Economics;Dalian University of Technology,China;China,"with the rapid development of internet technologies, it is possible to provide computing services and visualize calculated results on the internet. a three-dimensional flow field visualization method based on webvr is presented in this paper. we devised and built an immersive and interactive three-dimensional virtual reality scene employing web-standard technologies (i.e., html5, javascript, webgl, and ajax) and computing services provided by hydrodynamic software, using gpus to accelerate the display of flow field in the browser, without the use of plug-ins. on the basis of three-dimensional topography and surface flow field, a three-dimensional flow field presentation method of superimposing multiple sections into the original computational domain was proposed. furthermore, the description of tracer sphere and path line was adopted to describe the structure characteristics of the flow field. replacing complete three-dimensional sphere models with textured stylized particles improved the frame rate of the browser greatly when rendering animations. this research enables developers and users of the hydrodynamic model to be immersed in their data of flow field using google cardboard. as far as we know, this is the first time that webvr technology has been applied in three-dimensional hydrodynamic simulation.",visual analysis of three-dimensional flow field based on webvr
693,2-s2.0-85072963908,10.1142/S1793351X19400154,Learners' Technological Acceptance of VR Content Development: A Sequential 3-Part Use Case Study of Diverse Post-Secondary Students,Nguyen V.,International Journal of Semantic Computing,2019-09-01,"Web-based virtual reality (VR) development tools are in ubiquitous use by software developers, and now, university (undergraduate) students, to move beyond using, to creating new and energizing VR content. Web-based VR (WebVR), among other libraries and frameworks, have risen as a low-cost platform for users to create rich and intuitive VR content and applications. However, the success of WebVR as an instructional tool relies on post-secondary students technological acceptance (TA), the intersectionality of a user's perceived utility (PU) and perceived ease of use (PEOU, or convenience) with said technological tool. Yet, there is a dearth of exploratory studies of students' experiences with the AR/VR development technologies to infer their TA. To ascertain the viability of WebVR tools for software engineering undergraduates in the classroom, this paper presents a 3-case contextual investigation of 38 undergraduate students tasked with creating VR content. In each use case, students were provided increasing freedom in their VR content development parameters. Results indicated that students demonstrated elements of technological acceptance in their selection of webVR and other platforms, and not only successfully creating rich and robust VR content (PU), but also executing these projects in a short period (PEOU). Other positive externalities observed were students exhibitions of soft skills (e.g. creativity, critical thinking) and different modes of demonstrating coding knowledge, which suggest further study. Discussed are the lessons learned from the WebVR and VR/AR interventions and recommendations for WebVR instruction. This work may be helpful for both learners and teachers using VR/AR in selecting, designing, and developing coursework materials, tools, and libraries.",A-frame | computer science course design | soft skills | technology acceptance model | undergraduate education | web-based virtual reality,14,343-366,Journal,Article,3.0,"Nguyen, Vinh T.;Hite, Rebecca;Dang, Tommy",57210589113;57202916995;36615132200,Texas Tech University,United States,"web-based virtual reality (vr) development tools are in ubiquitous use by software developers, and now, university (undergraduate) students, to move beyond using, to creating new and energizing vr content. web-based vr (webvr), among other libraries and frameworks, have risen as a low-cost platform for users to create rich and intuitive vr content and applications. however, the success of webvr as an instructional tool relies on post-secondary students technological acceptance (ta), the intersectionality of a user's perceived utility (pu) and perceived ease of use (peou, or convenience) with said technological tool. yet, there is a dearth of exploratory studies of students' experiences with the ar/vr development technologies to infer their ta. to ascertain the viability of webvr tools for software engineering undergraduates in the classroom, this paper presents a 3-case contextual investigation of 38 undergraduate students tasked with creating vr content. in each use case, students were provided increasing freedom in their vr content development parameters. results indicated that students demonstrated elements of technological acceptance in their selection of webvr and other platforms, and not only successfully creating rich and robust vr content (pu), but also executing these projects in a short period (peou). other positive externalities observed were students exhibitions of soft skills (e.g. creativity, critical thinking) and different modes of demonstrating coding knowledge, which suggest further study. discussed are the lessons learned from the webvr and vr/ar interventions and recommendations for webvr instruction. this work may be helpful for both learners and teachers using vr/ar in selecting, designing, and developing coursework materials, tools, and libraries.",learners' technological acceptance of vr content development: a sequential 3-part use case study of diverse post-secondary students
694,2-s2.0-85068099886,10.1016/j.jbef.2019.04.007,Web-based experimental economics software: How do they compare to desirable features?,Chan S.W.,Journal of Behavioral and Experimental Finance,2019-09-01,"Web-based experiments that cut across the lab vs. field distinction are increasingly popular with economists. However, non-standardized software features and services hinder comparability and replication. This study reviews a wide selection of experimental economics software packages and evaluates them against criteria based on the logistics and operational requirements of economic experiments. We find that oTree and SoPHIE rank highest across criteria, but Veconlab and classEx might be suitable for those with a dominant need for a large library of ready-made experiments. We find a portability gap: no presently available software allows portability of experiments across platforms because of technical complexity and the challenging coordination needs of experimental economists. As a result, experiments may be replicated only on the same platform or with the same software, but general replicability is slow and costly. This constrains the development of experimental economics as a replicable science.",Economic experiments | Experimental economics | Online experiments | Software | Web-based | Web-based experiments,4,138-160,Journal,Review,4.0,"Chan, Shu Wing;Schilizzi, Steven;Iftekhar, Md Sayed;Da Silva Rosa, Raymond",57209546171;6603084455;23392776200;9336355300,The UWA Business School;The University of Western Australia,Australia;Australia,"web-based experiments that cut across the lab vs. field distinction are increasingly popular with economists. however, non-standardized software features and services hinder comparability and replication. this study reviews a wide selection of experimental economics software packages and evaluates them against criteria based on the logistics and operational requirements of economic experiments. we find that otree and sophie rank highest across criteria, but veconlab and classex might be suitable for those with a dominant need for a large library of ready-made experiments. we find a portability gap: no presently available software allows portability of experiments across platforms because of technical complexity and the challenging coordination needs of experimental economists. as a result, experiments may be replicated only on the same platform or with the same software, but general replicability is slow and costly. this constrains the development of experimental economics as a replicable science.",web-based experimental economics software: how do they compare to desirable features?
695,2-s2.0-85067212468,10.1016/j.sysarc.2019.05.005,MakeCode and CODAL: Intuitive and efficient embedded systems programming for education,Devine J.,Journal of Systems Architecture,2019-09-01,"Historically, embedded systems development has been a specialist skill, requiring knowledge of low-level programming languages, complex compilation toolchains, and specialist hardware, firmware, device drivers and applications. However, it has now become commonplace for a broader range of non-specialists to engage in the making (design and development) of embedded systems - including educators to motivate and excite their students in the classroom. This diversity brings its own set of unique requirements, and the complexities of existing embedded systems development platforms introduce insurmountable barriers to entry. In this paper we present the motivation, requirements, implementation, and evaluation of a new programming platform that enables novice users to create effective and efficient software for embedded systems. The platform has two major components: (1) Microsoft MakeCode (www.makecode.com), a web app that encapsulates an accessible IDE for microcontrollers; and (2) CODAL, an efficient component-oriented C++ runtime for microcontrollers. We show how MakeCode and CODAL combine to provide an accessible, cross-platform, installation-free, high level programming experience for embedded devices without sacrificing performance and efficiency.",BBC micro:bit | CODAL | Embedded systems | MakeCode | Physical computing | Visual programming | Web-based programming,12,468-483,Journal,Article,6.0,"Devine, James;Finney, Joe;de Halleux, Peli;Moskal, Michał;Ball, Thomas;Hodges, Steve",57202452071;7101854678;24461416400;23486057200;7102130944;15044574300,Microsoft Corporation;Lancaster University,United States;United Kingdom,"historically, embedded systems development has been a specialist skill, requiring knowledge of low-level programming languages, complex compilation toolchains, and specialist hardware, firmware, device drivers and applications. however, it has now become commonplace for a broader range of non-specialists to engage in the making (design and development) of embedded systems - including educators to motivate and excite their students in the classroom. this diversity brings its own set of unique requirements, and the complexities of existing embedded systems development platforms introduce insurmountable barriers to entry. in this paper we present the motivation, requirements, implementation, and evaluation of a new programming platform that enables novice users to create effective and efficient software for embedded systems. the platform has two major components: (1) microsoft makecode (www.makecode.com), a web app that encapsulates an accessible ide for microcontrollers; and (2) codal, an efficient component-oriented c++ runtime for microcontrollers. we show how makecode and codal combine to provide an accessible, cross-platform, installation-free, high level programming experience for embedded devices without sacrificing performance and efficiency.",makecode and codal: intuitive and efficient embedded systems programming for education
696,2-s2.0-85064445129,10.1016/j.fusengdes.2019.03.195,Designing CODAC system for tokamaks using web technology,Zheng W.,Fusion Engineering and Design,2019-09-01,"The core of ITER CODAC is built around the EPICS toolkit. EPICS is very mature in accelerator community. However, there are endeavors to improve existing control system software like tango and EPICS 7 mainly driven by the needs of more a flexible system and the development of computer technology. This paper presents a new way of building a CODAC system for tokamaks using web technology instead of EPICS toolkit. The control system components are abstracted into resources. The accessing of the resources is done via standard HTTP RESTful web API. HMI is based on HTML and JavaScript in browsers. Web Socket is used to improve the efficient of event distribution. The main feature of this design is that all interfaces in the system are based on open web standards, which are interoperable among almost all kinds of server and client technology. The paper also presents a software toolkit to build this CODAC system. With it, a data acquisition system for ECEI diagnostics is built and presented.",CODAC | Control system | SCADA | Web of things,4,2379-2383,Journal,Article,5.0,"Zheng, Wei;Wang, Yuxing;Zhang, Ming;Yang, Zhou;Pan, Yuan",56422904600;57200572129;57199246172;57208320530;55473497100,Huazhong University of Science and Technology,China,"the core of iter codac is built around the epics toolkit. epics is very mature in accelerator community. however, there are endeavors to improve existing control system software like tango and epics 7 mainly driven by the needs of more a flexible system and the development of computer technology. this paper presents a new way of building a codac system for tokamaks using web technology instead of epics toolkit. the control system components are abstracted into resources. the accessing of the resources is done via standard http restful web api. hmi is based on html and javascript in browsers. web socket is used to improve the efficient of event distribution. the main feature of this design is that all interfaces in the system are based on open web standards, which are interoperable among almost all kinds of server and client technology. the paper also presents a software toolkit to build this codac system. with it, a data acquisition system for ecei diagnostics is built and presented.",designing codac system for tokamaks using web technology
697,2-s2.0-85063438804,10.1016/j.fusengdes.2019.03.168,Software quality management approach for WEST CODAC,Colnel J.,Fusion Engineering and Design,2019-09-01,"The WEST project has consisted in modifying the Tore Supra tokamak magnetic configuration to achieve X-point by adding divertor coils in the vacuum vessel and to test ITER-like plasma facing components. Major changes and significant developments have been performed on the measurement systems (diagnostics); the control, data access and communication; the plasma control system, and the actuators. To keep track of the software developments and step by step upgrade performed on any subsystem of the tokamak, a software quality management procedure has been implemented. This procedure consists also of a validation workflow ensuring that only validated version of the software are used during a plasma discharge. Such procedure is successfully used since 2 years.",CODAC | Continuous integration | Quality management | Version control,2,2264-2267,Journal,Article,6.0,"Colnel, J.;Bremond, S.;Caulier, G.;Moreau, P.;Ravenel, N.;Santraine, B.",57193318545;6602573717;22233744500;7201395209;6507823519;57193316514,CEA Cadarache,France,"the west project has consisted in modifying the tore supra tokamak magnetic configuration to achieve x-point by adding divertor coils in the vacuum vessel and to test iter-like plasma facing components. major changes and significant developments have been performed on the measurement systems (diagnostics); the control, data access and communication; the plasma control system, and the actuators. to keep track of the software developments and step by step upgrade performed on any subsystem of the tokamak, a software quality management procedure has been implemented. this procedure consists also of a validation workflow ensuring that only validated version of the software are used during a plasma discharge. such procedure is successfully used since 2 years.",software quality management approach for west codac
700,2-s2.0-85074346465,10.5194/isprs-archives-XLII-4-W14-79-2019,GEOMETRY VIEWER for PGADMIN4: A PROCESS GUIDED by the GOOGLE SUMMER of CODE,Gong X.,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",2019-08-23,"The latest version of pgAdmin4 was released in mid-2016 and moved to a web-based application that was written in Python and jQuery with Bootstrap, using the Flask framework. This new architecture of pgAdmin4 provided an excellent opportunity to integrate a geometry viewer into the application. This progress started as the geometry viewer was selected as a project for the 2018 Google Summer of Code (GSoC). The requirements for the geometry viewer was elicited through conversations with the mentors and emails to the discussion list of PostGIS and pgAdmin. Once the formal design was finalized the development started. The spatial technology stack implemented to expand pgAdmin4 with a geometry viewer was the JavaScript mapping library Leaflet JS and WKX - parser/serializer library that supports several spatial vector formats. Both these fulfilled the requirements of the coding standard of pgAdmin that all client-side code must be developed in JavaScript using jQuery and other plugins. Leaflet JS is well known for its ease of use and compatibility. WKX is lesser known but well supported and concise to the need to parse the spatial data before rendering on the Leaflet map. The decision on both of these libraries was motivated by their minimal size and possibilities for expansion for future extensions of the viewer. The first version of the geometry viewer was well-received and is currently integrated into the latest versions of pgAdmin4.",geometry viewer | leaflet js | pgadmin | postgis,1,79-83,Conference Proceeding,Conference Paper,3.0,"Gong, X.;Erwee, F.;Rautenbach, V.",57211536092;57211535003;55346444900,University of Pretoria;Peking University;Verge Technologies,South Africa;China;South Africa,"the latest version of pgadmin4 was released in mid-2016 and moved to a web-based application that was written in python and jquery with bootstrap, using the flask framework. this new architecture of pgadmin4 provided an excellent opportunity to integrate a geometry viewer into the application. this progress started as the geometry viewer was selected as a project for the 2018 google summer of code (gsoc). the requirements for the geometry viewer was elicited through conversations with the mentors and emails to the discussion list of postgis and pgadmin. once the formal design was finalized the development started. the spatial technology stack implemented to expand pgadmin4 with a geometry viewer was the javascript mapping library leaflet js and wkx - parser/serializer library that supports several spatial vector formats. both these fulfilled the requirements of the coding standard of pgadmin that all client-side code must be developed in javascript using jquery and other plugins. leaflet js is well known for its ease of use and compatibility. wkx is lesser known but well supported and concise to the need to parse the spatial data before rendering on the leaflet map. the decision on both of these libraries was motivated by their minimal size and possibilities for expansion for future extensions of the viewer. the first version of the geometry viewer was well-received and is currently integrated into the latest versions of pgadmin4.",geometry viewer for pgadmin4: a process guided by the google summer of code
701,2-s2.0-85072574779,10.3901/JME.2019.16.176,Development of the Railway Working Condition Recognition Software,Chen D.,Jixie Gongcheng Xuebao/Journal of Mechanical Engineering,2019-08-20,"In order to develop the load spectrum under specific working conditions, the development method of railway working condition recognition software is studied. The storage format of original data is analyzed and the relevant code is compiled into the software so that the original data can be read by the software. The characteristic of the signal under different working conditions is studied and the characteristic waves of different working conditions are extracted. The working process of the algorithm is also analyzed. Google satellite map and OpenStreetMap are employed in the software. The conversion method between latitude & longitude coordinates and Mercator coordinates is analyzed. The actual railway test is operated and the software is confirmed to be successful. Finally, all of the recognized railway working conditions are listed in the table so that the whole working condition characteristic of the testing line is analyzed.",Characteristic | Load spectrum | Recognition | Signal | Software | Working condition,1,176-184,Journal,Article,5.0,"Chen, Daoyun;Sun, Shouguang;Li, Qiang;Lin, Fengtao;Xiao, Qian",56965827300;8721915500;57191696637;36617838800;36601893800,Beijing Jiaotong University;East China Jiaotong University,China;China,"in order to develop the load spectrum under specific working conditions, the development method of railway working condition recognition software is studied. the storage format of original data is analyzed and the relevant code is compiled into the software so that the original data can be read by the software. the characteristic of the signal under different working conditions is studied and the characteristic waves of different working conditions are extracted. the working process of the algorithm is also analyzed. google satellite map and openstreetmap are employed in the software. the conversion method between latitude & longitude coordinates and mercator coordinates is analyzed. the actual railway test is operated and the software is confirmed to be successful. finally, all of the recognized railway working conditions are listed in the table so that the whole working condition characteristic of the testing line is analyzed.",development of the railway working condition recognition software
703,2-s2.0-85071941138,10.1145/3338906.3342504,Are existing code smells relevant in web games? An empirical study,Khanve V.,ESEC/FSE 2019 - Proceedings of the 2019 27th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,2019-08-12,"In software applications, code smells are considered as bad coding practices acquired at the time of development. The presence of such code smells in games may affect the process of game development adversely. Our preliminary study aims at investigating the existence of code smells in the games. To achieve this, we used JavaScript code smells detection tool JSNose against 361 JavaScript web games to find occurrences of JavaScript smells in games. Further, we conducted a manual study to find violations of known game programming patterns in 8 web games to verify the necessity of game-specific code smells detection tool. Our results shows that existing JavaScript code smells detection tool is not sufficient to find game-specific code smells in web games.",Code Smells | Game-specific Code Smells | Web Games,1,1241-1243,Conference Proceeding,Conference Paper,1.0,"Khanve, Vaishali",57210931388,Indian Institute of Technology Tirupati,India,"in software applications, code smells are considered as bad coding practices acquired at the time of development. the presence of such code smells in games may affect the process of game development adversely. our preliminary study aims at investigating the existence of code smells in the games. to achieve this, we used javascript code smells detection tool jsnose against 361 javascript web games to find occurrences of javascript smells in games. further, we conducted a manual study to find violations of known game programming patterns in 8 web games to verify the necessity of game-specific code smells detection tool. our results shows that existing javascript code smells detection tool is not sufficient to find game-specific code smells in web games.",are existing code smells relevant in web games? an empirical study
704,2-s2.0-85071933461,10.1145/3338906.3338926,Monitoring-aware IDEs,Winter J.,ESEC/FSE 2019 - Proceedings of the 2019 27th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,2019-08-12,"Engineering modern large-scale software requires software developers to not solely focus on writing code, but also to continuously examine monitoring data to reason about the dynamic behavior of their systems. These additional monitoring responsibilities for developers have only emerged recently, in the light of DevOps culture. Interestingly, software development activities happen mainly in the IDE, while reasoning about production monitoring happens in separate monitoring tools. We propose an approach that integrates monitoring signals into the development environment and workflow. We conjecture that an IDE with such capability improves the performance of developers as time spent continuously context switching from development to monitoring would be eliminated. This paper takes a first step towards understanding the benefits of a possible monitoring-aware IDE. We implemented a prototype of a Monitoring-Aware IDE, connected to the monitoring systems of Adyen, a large-scale payment company that performs intense monitoring in their software systems. Given our results, we firmly believe that monitoring-aware IDEs can play an essential role in improving how developers perform monitoring.",Devops | IDE | Integrated Development Environment | Runtime monitoring | Software engineering | Systems monitoring,3,420-431,Conference Proceeding,Conference Paper,4.0,"Winter, Jos;Aniche, Maurício;Cito, Jürgen;Van Deursen, Arie",57210935780;36132835800;56495364200;7003969355,Massachusetts Institute of Technology;Delft University of Technology;Adyen N.V.,United States;Netherlands;Netherlands,"engineering modern large-scale software requires software developers to not solely focus on writing code, but also to continuously examine monitoring data to reason about the dynamic behavior of their systems. these additional monitoring responsibilities for developers have only emerged recently, in the light of devops culture. interestingly, software development activities happen mainly in the ide, while reasoning about production monitoring happens in separate monitoring tools. we propose an approach that integrates monitoring signals into the development environment and workflow. we conjecture that an ide with such capability improves the performance of developers as time spent continuously context switching from development to monitoring would be eliminated. this paper takes a first step towards understanding the benefits of a possible monitoring-aware ide. we implemented a prototype of a monitoring-aware ide, connected to the monitoring systems of adyen, a large-scale payment company that performs intense monitoring in their software systems. given our results, we firmly believe that monitoring-aware ides can play an essential role in improving how developers perform monitoring.",monitoring-aware ides
706,2-s2.0-85075990254,10.1109/SEAA.2019.00042,Estimating the Maintenance Effort of JavaScript Applications,Zozas I.,"Proceedings - 45th Euromicro Conference on Software Engineering and Advanced Applications, SEAA 2019",2019-08-01,"Successful software project survival and progress over time is highly dependent on effectively managing the maintenance process. Estimating accurately maintenance process factors like the maintenance effort and the level of changes required for a new release is considered a crucial task for allocating resources. In this work we examine the maintenance process factors of JavaScript applications, which at the moment are understudied despite the need of language specific maintenance models. Furthermore we propose two maintenance indices for estimating the changes and the effort required for maintaining JavaScript applications by considering a variety of maintenance drivers. We evaluated the proposed indices through a case study on 5,788 releases coming from 60 popular JavaScript applications. The results show that project activity factors (i.e., number of open bugs and number of corrective maintenance activities) are important maintenance drivers. The proposed indices are evaluated in terms of predictive and discriminative power and both achieve high accuracy.",JavaScript | maintenance index | open source software | software development | software maintenance effort,0,212-219,Conference Proceeding,Conference Paper,4.0,"Zozas, Ioannis;Bibi, Stamatia;Ampatzoglou, Apostolos;Sarigiannidis, Panagiotis",57202336557;14719125500;16027681600;12445587500,University of Western Macedonia,Greece,"successful software project survival and progress over time is highly dependent on effectively managing the maintenance process. estimating accurately maintenance process factors like the maintenance effort and the level of changes required for a new release is considered a crucial task for allocating resources. in this work we examine the maintenance process factors of javascript applications, which at the moment are understudied despite the need of language specific maintenance models. furthermore we propose two maintenance indices for estimating the changes and the effort required for maintaining javascript applications by considering a variety of maintenance drivers. we evaluated the proposed indices through a case study on 5,788 releases coming from 60 popular javascript applications. the results show that project activity factors (i.e., number of open bugs and number of corrective maintenance activities) are important maintenance drivers. the proposed indices are evaluated in terms of predictive and discriminative power and both achieve high accuracy.",estimating the maintenance effort of javascript applications
710,2-s2.0-85066064473,10.1016/j.cageo.2019.04.011,Analysis of server-side and client-side Web-GIS data processing methods on the example of JTS and JSTS using open data from OSM and geoportal,Kulawiak M.,Computers and Geosciences,2019-08-01,"The last decade has seen a rapid evolution of processing, analysis and visualization of freely available geographic data using Open Source Web-GIS. In the beginning, Web-based Geographic Information Systems employed a thick-client approach which required installation of platform-specific browser plugins. Later on, research focus shifted to platform-independent thin client solutions in which data processing and analysis was performed by the server machine. More recently, however, the rapid development of computer hardware as well as software technologies such has HTML5 has enabled the creation of platform-independent thick clients which offer advanced GIS functionalities such as geoprocessing. This article aims to analyse the current state of Open Source technologies and publicly available geographic data sources in the context of creating cost-effective Web-GIS applications for integration and processing of spatial data. For this purpose the article discusses the availability and potential of Web-GIS architectures, software libraries and data sources. The analysis of freely available data sources includes a discussion of the quality and accuracy of crowd-sourced as well as public sector data, while the investigation of software libraries and architectures involves a comparison of server-side and client-side data processing performance under a set of real-world scenarios. The article concludes with a discussion of the choice of cost-effective Web-GIS architectures, software libraries and data sources in the context of the institution and environment of system deployment.",Architecture | Geoprocessing | JTS | OpenStreetMap | Performance | Web-GIS,28,26-37,Journal,Article,3.0,"Kulawiak, Marcin;Dawidowicz, Agnieszka;Pacholczyk, Marek Emanuel",57202995868;56142103500;57204058927,Gdańsk University of Technology;Uniwersytet Warminsko-Mazurski w Olsztynie,Poland;Poland,"the last decade has seen a rapid evolution of processing, analysis and visualization of freely available geographic data using open source web-gis. in the beginning, web-based geographic information systems employed a thick-client approach which required installation of platform-specific browser plugins. later on, research focus shifted to platform-independent thin client solutions in which data processing and analysis was performed by the server machine. more recently, however, the rapid development of computer hardware as well as software technologies such has html5 has enabled the creation of platform-independent thick clients which offer advanced gis functionalities such as geoprocessing. this article aims to analyse the current state of open source technologies and publicly available geographic data sources in the context of creating cost-effective web-gis applications for integration and processing of spatial data. for this purpose the article discusses the availability and potential of web-gis architectures, software libraries and data sources. the analysis of freely available data sources includes a discussion of the quality and accuracy of crowd-sourced as well as public sector data, while the investigation of software libraries and architectures involves a comparison of server-side and client-side data processing performance under a set of real-world scenarios. the article concludes with a discussion of the choice of cost-effective web-gis architectures, software libraries and data sources in the context of the institution and environment of system deployment.",analysis of server-side and client-side web-gis data processing methods on the example of jts and jsts using open data from osm and geoportal
712,2-s2.0-85066234516,10.1016/j.scico.2019.05.005,A declarative enhancement of JavaScript programs by leveraging the Java metadata infrastructure,Wang Y.,Science of Computer Programming,2019-07-15,"Web browsers have evolved into indispensable software platforms for modern applications. Although JavaScript has become a de-facto lingua franca for developing web applications, the JavaScript software development tools and methodologies lag behind those of languages such as Java and C#. In particular, to enhance JavaScript programs with non-functional concerns (e.g., persistence, security, transactions, and logging) JavaScript developers need to modify the source code by hand. Developers then often end up having to maintain the resulting modified version separately for reasons that include poor design, the complexities of program evolution, and fundamental language limitations. The necessity to modify code by hand could be avoided if JavaScript had metadata facilities for developers to specify non-functional concerns declaratively. To address this problem, we present a novel declarative approach, Transparent Automated Enhancement for JavaScript (TAE-JS) that enhances JavaScript programs with the ability to use declarative metadata. The metadata is expressed by means of Java annotations. We have implemented our technique in an open-source plug-in for the Eclipse IDE. This plug-in allows a developer to enhance the original version of a JavaScript program by specifying concerns declaratively using Java annotations. It then analyzes an original version of the program to automatically generate enhanced program versions by adding the declared concerns. We evaluated TAE-JS with four practical examples that enhance JavaScript programs by declaratively adding concerns such as persistence, security, transactions, and logging. In a user study with ten student developers and three professional engineers at PayPal, the participants viewed favorably TAE-JS's flexible declarative enhancement capabilities, seeing them as a valuable mechanism for implementing non-functional concerns in JavaScript programs. Our evaluation results are promising in demonstrating the potential benefits of our approach to complement existing JavaScript development tools.",Annotations | Code enhancement | Metadata | Software reuse,1,27-46,Journal,Article,4.0,"Wang, Yuchen;Cheng, Kwok Sun;Song, Myoungkyu;Tilevich, Eli",57209012058;57209005830;32868182400;6507251807,Virginia Polytechnic Institute and State University;University of Nebraska Omaha,United States;United States,"web browsers have evolved into indispensable software platforms for modern applications. although javascript has become a de-facto lingua franca for developing web applications, the javascript software development tools and methodologies lag behind those of languages such as java and c#. in particular, to enhance javascript programs with non-functional concerns (e.g., persistence, security, transactions, and logging) javascript developers need to modify the source code by hand. developers then often end up having to maintain the resulting modified version separately for reasons that include poor design, the complexities of program evolution, and fundamental language limitations. the necessity to modify code by hand could be avoided if javascript had metadata facilities for developers to specify non-functional concerns declaratively. to address this problem, we present a novel declarative approach, transparent automated enhancement for javascript (tae-js) that enhances javascript programs with the ability to use declarative metadata. the metadata is expressed by means of java annotations. we have implemented our technique in an open-source plug-in for the eclipse ide. this plug-in allows a developer to enhance the original version of a javascript program by specifying concerns declaratively using java annotations. it then analyzes an original version of the program to automatically generate enhanced program versions by adding the declared concerns. we evaluated tae-js with four practical examples that enhance javascript programs by declaratively adding concerns such as persistence, security, transactions, and logging. in a user study with ten student developers and three professional engineers at paypal, the participants viewed favorably tae-js's flexible declarative enhancement capabilities, seeing them as a valuable mechanism for implementing non-functional concerns in javascript programs. our evaluation results are promising in demonstrating the potential benefits of our approach to complement existing javascript development tools.",a declarative enhancement of javascript programs by leveraging the java metadata infrastructure
713,2-s2.0-85070621239,10.1145/3319619.3326825,MABE 2.0 an introduction to MABE and a road map for the future of MABE development,Bohm C.,GECCO 2019 Companion - Proceedings of the 2019 Genetic and Evolutionary Computation Conference Companion,2019-07-13,"MABE (Modular Agent-based Evolver) is an open-source evolutionary computation (EC) research platform designed to be used by biologists, engineers, computer scientists, and other researchers. MABE's primary goal is to reduce the time between thinking up a new hypothesis and generating results. The design assumes that there are common elements in many EC research projects. MABE improves efficiency by allowing for the reuse of these common elements and standardizing of interfaces for non-common elements so that they can be used interchangeably. As of the writing of this paper, the MABE framework is five years old. Here, we reflect on the current version of MABE, including its successes and shortcomings, and propose upgrades for the next release.",Artificial life | Empirical Library | Evolution | Evolutionary computation | MABE | Modular Agent-based Evolver | Open source | Software development,1,1349-1356,Conference Proceeding,Conference Paper,4.0,"Bohm, Clifford;Schossau, Jory;Lalejini, Alexander;Ofria, Charles",57210416458;54956616700;56728579800;8110205600,Michigan State University,United States,"mabe (modular agent-based evolver) is an open-source evolutionary computation (ec) research platform designed to be used by biologists, engineers, computer scientists, and other researchers. mabe's primary goal is to reduce the time between thinking up a new hypothesis and generating results. the design assumes that there are common elements in many ec research projects. mabe improves efficiency by allowing for the reuse of these common elements and standardizing of interfaces for non-common elements so that they can be used interchangeably. as of the writing of this paper, the mabe framework is five years old. here, we reflect on the current version of mabe, including its successes and shortcomings, and propose upgrades for the next release.",mabe 2.0 an introduction to mabe and a road map for the future of mabe development
715,2-s2.0-85070593514,10.1145/3293882.3338993,Theory and practice of string solvers (invited talk abstract),Kiezun A.,ISSTA 2019 - Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis,2019-07-10,"The paper titled ""Hampi: A Solver for String Constraints"" was published in the proceedings of the International Symposium on Software Testing and Analysis (ISSTA) 2009, and has been selected to receive the ISSTA 2019 Impact Paper Award. The paper describes HAMPI, one of the first practical solver aimed at solving the satisfi-ability problem for a theory of string (word) equations, operations over strings, and predicates over regular expressions and context-free grammars. HAMPI has been used widely to solve many software engineering and security problems, and has inspired considerable research on string solving algorithms and their applications. In this talk, we review the state of research on the theory and practice of string solving algorithms, specifically highlighting key historical developments that have led to their widespread use. On the practical front, we discuss different kinds of algorithmic paradigms, such as word- and automata-based, that have been developed to solve string and regular expression constraints. We then focus on the many hardness results that theorists have proved for fragments of theories over strings. Finally, we conclude with open theoretical problems, practical algorithmic challenges, and future applications of string solvers.",String equations | String SMT solvers | String solver-based analysis,0,6-7,Conference Proceeding,Conference Paper,5.0,"Kiezun, Adam;Guo, Philip J.;Hooimeijer, Pieter;Ernst, Michael D.;Ganesh, Vijay",8837002600;16238467300;55929082500;36916423000;36018364100,"Facebook, Inc.;Amazon.com, Inc.;University of California, San Diego;University of Washington;University of Waterloo",United States;United States;United States;United States;Canada,"the paper titled ""hampi: a solver for string constraints"" was published in the proceedings of the international symposium on software testing and analysis (issta) 2009, and has been selected to receive the issta 2019 impact paper award. the paper describes hampi, one of the first practical solver aimed at solving the satisfi-ability problem for a theory of string (word) equations, operations over strings, and predicates over regular expressions and context-free grammars. hampi has been used widely to solve many software engineering and security problems, and has inspired considerable research on string solving algorithms and their applications. in this talk, we review the state of research on the theory and practice of string solving algorithms, specifically highlighting key historical developments that have led to their widespread use. on the practical front, we discuss different kinds of algorithmic paradigms, such as word- and automata-based, that have been developed to solve string and regular expression constraints. we then focus on the many hardness results that theorists have proved for fragments of theories over strings. finally, we conclude with open theoretical problems, practical algorithmic challenges, and future applications of string solvers.",theory and practice of string solvers (invited talk abstract)
717,2-s2.0-85069954409,10.1145/3321705.3329848,"Running language interpreters inside SGX: A lightweight, legacy-compatible script code hardening approach",Wang H.,AsiaCCS 2019 - Proceedings of the 2019 ACM Asia Conference on Computer and Communications Security,2019-07-02,"Recent advances in trusted execution environments, specifically with Intel's introduction of SGX on consumer processors, have provided unprecedented opportunities to create secure applications with a small TCB. While a large number of SGX solutions have been proposed, nearly all of them focus on protecting native code applications, leaving scripting languages unprotected. To fill this gap, this paper presents ScriptShield, a framework capable of running legacy script code while simultaneously providing confidentiality and integrity for scripting code and data. In contrast to the existing schemes that either require tedious and timeconsuming re-development or result in a large TCB by importing an entire library OS or container, ScriptShield keeps the TCB small and provides backwards compatibility (i.e., no changes needed to the scripting code itself). The core idea is to customize the script interpreter to run inside an SGX enclave and pass scripts to it. We have implemented ScriptShield and tested with three popular scripting languages: Lua, JavaScript, and Squirrel. Our experimental results show that ScriptShield does not cause noticeable overhead. The source code of ScriptShield has been made publicly available as an open source project.",Confidentiality | Integrity | Scripting Language | SGX,5,114-121,Conference Proceeding,Conference Paper,6.0,"Wang, Huibo;Bauman, Erick;Karande, Vishal;Lin, Zhiqiang;Cheng, Yueqiang;Zhang, Yinqian",57200513156;57198360945;57189060841;12763207100;36336830100;36669844400,"Baidu, Inc.;The University of Texas at Dallas;The Ohio State University",China;United States;United States,"recent advances in trusted execution environments, specifically with intel's introduction of sgx on consumer processors, have provided unprecedented opportunities to create secure applications with a small tcb. while a large number of sgx solutions have been proposed, nearly all of them focus on protecting native code applications, leaving scripting languages unprotected. to fill this gap, this paper presents scriptshield, a framework capable of running legacy script code while simultaneously providing confidentiality and integrity for scripting code and data. in contrast to the existing schemes that either require tedious and timeconsuming re-development or result in a large tcb by importing an entire library os or container, scriptshield keeps the tcb small and provides backwards compatibility (i.e., no changes needed to the scripting code itself). the core idea is to customize the script interpreter to run inside an sgx enclave and pass scripts to it. we have implemented scriptshield and tested with three popular scripting languages: lua, javascript, and squirrel. our experimental results show that scriptshield does not cause noticeable overhead. the source code of scriptshield has been made publicly available as an open source project.","running language interpreters inside sgx: a lightweight, legacy-compatible script code hardening approach"
719,2-s2.0-85080891939,10.1109/IIAI-AAI.2019.00037,Prototype of Visual Programming Environment for C Language Novice Programmer,Abe K.,"Proceedings - 2019 8th International Congress on Advanced Applied Informatics, IIAI-AAI 2019",2019-07-01,"For the education of beginning programmers, visual programming that develops programs by combining blocks has attracted significant attention. An environment for generating code in a conventional programming language is also provided. However, existing environments are not fully visualized. In this investigation, we prototyped a development environment for the C language in which users can intuitively understand the concept of variable declarations and include statements, and an execution environment that visualizes the state of evaluation of expressions and changes in the values of variables before and after the execution of the statement. It also has step-forward and step-backward functions. This programming environment is a web application developed with JavaScript. For step-by-step evaluation of an expression, it converts the expression internally to reverse Polish notation and visualizes the change in the terms in the expression. To implement the step-backward function, it has a history-of-execution context. We determined experimentally that students who are not proficient in C can program more accurately and quickly in this environment than with text-based coding.",block-based | C language | interpreter | novice programmer | visual programming | web application,2,140-145,Conference Proceeding,Conference Paper,3.0,"Abe, Kousuke;Fukawa, Yuki;Tanaka, Tetsuo",57215430132;57215435476;55700415300,Kanagawa Institute of Technology,Japan,"for the education of beginning programmers, visual programming that develops programs by combining blocks has attracted significant attention. an environment for generating code in a conventional programming language is also provided. however, existing environments are not fully visualized. in this investigation, we prototyped a development environment for the c language in which users can intuitively understand the concept of variable declarations and include statements, and an execution environment that visualizes the state of evaluation of expressions and changes in the values of variables before and after the execution of the statement. it also has step-forward and step-backward functions. this programming environment is a web application developed with javascript. for step-by-step evaluation of an expression, it converts the expression internally to reverse polish notation and visualizes the change in the terms in the expression. to implement the step-backward function, it has a history-of-execution context. we determined experimentally that students who are not proficient in c can program more accurately and quickly in this environment than with text-based coding.",prototype of visual programming environment for c language novice programmer
720,2-s2.0-85074128371,10.1109/SMC-IT.2019.00007,"Multi-mission, Interactive 3D Visualization in a Web Browser for Robotic System and Space Flight Mission Development and Operations",Pomerantz M.,"Proceedings - 2019 IEEE International Conference on Space Mission Challenges for Information Technology, SMC-IT 2019",2019-07-01,"Leveraging on our experience developing engineering accurate, interactive 3D visualization systems for robotic system and flight mission formulation, development and operations, our team at the Jet Propulsion Laboratory has built a high performance, interactive 3D visualization system called Ranger, that runs in a web browser and has been designed for use during the entire mission life-cycle. This includes mission formulation through operations, robotic system research, flight mission design and development, simulation test-bed experiments and in-the-field testing. Our Ranger system not only provides robotic missions with a to-scale situational awareness visualization capability, but also an interactive commanding tool whereby user interactions in the web browser can be communicated back through the system to robotic system or spacecraft control software. In this paper we will discuss the Ranger system architecture, rendering performance, current use cases and deployments, system development challenges, as well as a newly implemented fully immersive VR system capability.",3D Visualization | JavaScript | Space mission Visualization | Web Browser | WebGL,2,17-23,Conference Proceeding,Conference Paper,5.0,"Pomerantz, Marc;Boettcher, Andrew;Hans, Michael;Sandoval, Michael;Wenzel, Sean",9746001200;57194610429;57190381226;57195066477;57211493263,Jet Propulsion Laboratory,United States,"leveraging on our experience developing engineering accurate, interactive 3d visualization systems for robotic system and flight mission formulation, development and operations, our team at the jet propulsion laboratory has built a high performance, interactive 3d visualization system called ranger, that runs in a web browser and has been designed for use during the entire mission life-cycle. this includes mission formulation through operations, robotic system research, flight mission design and development, simulation test-bed experiments and in-the-field testing. our ranger system not only provides robotic missions with a to-scale situational awareness visualization capability, but also an interactive commanding tool whereby user interactions in the web browser can be communicated back through the system to robotic system or spacecraft control software. in this paper we will discuss the ranger system architecture, rendering performance, current use cases and deployments, system development challenges, as well as a newly implemented fully immersive vr system capability.","multi-mission, interactive 3d visualization in a web browser for robotic system and space flight mission development and operations"
721,2-s2.0-85072669458,10.1109/COMPSAC.2019.10223,Prototyping for internet of things with web technologies: A Case on Project-Based Learning using Scrum,Vogel B.,Proceedings - International Computer Software and Applications Conference,2019-07-01,"The traditional way of teaching may no longer be sufficient to cope with current requirements specifically in the Internet of Things (IoT) domain. The case for this paper is related to an introductory programming course on JavaScript for the period of 2016-2018. In this study a multi-method approach for data collection is utilized. Project-Based Learning (PBL), Scrum and rapid prototyping are utilized to support student projects over the three years. Students developed a number of prototypes for various IoT domains related to ongoing research projects within our research center. The results show that students could easily use their JavaScript knowledge for any type of IoT development. PBL, Scrum and rapid prototyping help addressing uncertainties during the projects and balancing the team efforts for learning, development, problem solving and creativity. One of the outcomes of this paper confirms that smaller team sizes of students perform better during the project lifetime. In conclusion, focusing on knowledge increase, teamwork, collaboration, interaction, constant feedback, and adaptability should be considered a priority while exploiting teaching approaches such as PBL, Scrum and rapid prototyping for IoT development.",Index Terms—IoT | JavaScript | PBL | Project-Based Learning | Prototyping | Scrum | Web Technologies,4,300-305,Conference Proceeding,Conference Paper,3.0,"Vogel, Bahtijar;Peterson, Bo;Emruli, Blerim",36167574000;56909416000;55615627700,Malmö Högskola,Sweden,"the traditional way of teaching may no longer be sufficient to cope with current requirements specifically in the internet of things (iot) domain. the case for this paper is related to an introductory programming course on javascript for the period of 2016-2018. in this study a multi-method approach for data collection is utilized. project-based learning (pbl), scrum and rapid prototyping are utilized to support student projects over the three years. students developed a number of prototypes for various iot domains related to ongoing research projects within our research center. the results show that students could easily use their javascript knowledge for any type of iot development. pbl, scrum and rapid prototyping help addressing uncertainties during the projects and balancing the team efforts for learning, development, problem solving and creativity. one of the outcomes of this paper confirms that smaller team sizes of students perform better during the project lifetime. in conclusion, focusing on knowledge increase, teamwork, collaboration, interaction, constant feedback, and adaptability should be considered a priority while exploiting teaching approaches such as pbl, scrum and rapid prototyping for iot development.",prototyping for internet of things with web technologies: a case on project-based learning using scrum
729,2-s2.0-85064390104,10.1109/TNB.2019.2909094,Serendipity - A Machine-Learning Application for Mining Serendipitous Drug Usage from Social Media,Ru B.,IEEE Transactions on Nanobioscience,2019-07-01,"Serendipitous drug usage refers to the unexpected relief of comorbid diseases or symptoms when taking medication for a different known indication. Historically, serendipity has contributed significantly to identifying many new drug indications. If patient-reported serendipitous drug usage in social media could be computationally identified, it could help generate and validate drug-repositioning hypotheses. We investigated deep neural network models for mining serendipitous drug usage from social media. We used the word2vec algorithm to construct word-embedding features from drug reviews posted in a WebMD patient forum. We adapted and redesigned the convolutional neural network, long short-term memory network, and convolutional long short-term memory network by adding contextual information extracted from drug-review posts, information-filtering tools, medical ontology, and medical knowledge. We trained, tuned, and evaluated our models with a gold-standard dataset of 15714 sentences (447 [2.8%] describing serendipitous drug usage). Additionally, we compared our deep neural networks to support vector machine, random forest, and AdaBoost.M1 algorithms. Context information helped to reduce the false-positive rate of deep neural network models. If we used an extremely imbalanced dataset with limited instances of serendipitous drug usage, deep neural network models did not outperform other machine-learning models with n-gram and context features. However, deep neural network models could more effectively use word embedding in feature construction, an advantage that makes them worthy of further investigation. Finally, we implemented natural-language processing and machine-learning methods in a web-based application to help scientists and software developers mine social media for serendipitous drug usage.",data mining | drug discovery | drug repurposing | health informatics | Social media,7,324-334,Journal,Article,4.0,"Ru, Boshu;Li, Dingcheng;Hu, Yueqi;Yao, Lixia",57189032154;55301231800;56413163600;53868570800,"Baidu, Inc.;The University of North Carolina at Charlotte;Mayo Clinic",China;United States;United States,"serendipitous drug usage refers to the unexpected relief of comorbid diseases or symptoms when taking medication for a different known indication. historically, serendipity has contributed significantly to identifying many new drug indications. if patient-reported serendipitous drug usage in social media could be computationally identified, it could help generate and validate drug-repositioning hypotheses. we investigated deep neural network models for mining serendipitous drug usage from social media. we used the word2vec algorithm to construct word-embedding features from drug reviews posted in a webmd patient forum. we adapted and redesigned the convolutional neural network, long short-term memory network, and convolutional long short-term memory network by adding contextual information extracted from drug-review posts, information-filtering tools, medical ontology, and medical knowledge. we trained, tuned, and evaluated our models with a gold-standard dataset of 15714 sentences (447 [2.8%] describing serendipitous drug usage). additionally, we compared our deep neural networks to support vector machine, random forest, and adaboost.m1 algorithms. context information helped to reduce the false-positive rate of deep neural network models. if we used an extremely imbalanced dataset with limited instances of serendipitous drug usage, deep neural network models did not outperform other machine-learning models with n-gram and context features. however, deep neural network models could more effectively use word embedding in feature construction, an advantage that makes them worthy of further investigation. finally, we implemented natural-language processing and machine-learning methods in a web-based application to help scientists and software developers mine social media for serendipitous drug usage.",serendipity - a machine-learning application for mining serendipitous drug usage from social media
731,2-s2.0-85054196945,10.1007/s10664-018-9658-x,Comparing the influence of using feature-oriented programming and conditional compilation on comprehending feature-oriented software,Rodrigues Santos A.,Empirical Software Engineering,2019-06-15,"Several variability representations have been proposed over the years. Software maintenance in the presence of variability is known to be hard. One of the reasons is that maintenance tasks require a large amount of cognitive effort for program comprehension. In fact, the different ways of representing variability in source code might influence the comprehension process in different ways. Despite the differences, there is little evidence about how these variability representations – such as conditional-compilation directives or feature-oriented programming – influence program comprehension. Existing research has focused primarily on either understanding how code using modern paradigms evolves compared to the traditional way of realizing variability, namely conditional compilation, or on the aspects influencing the comprehension of conditional compilation only. We used two different programs implemented in Java and each of these variability representations. As Java does not support conditional compilation natively, we relied on the mimicking (i.e., preprocessing annotations in comments) that has been used in the literature. Our results show no significant statistical differences regarding the evaluated measures (correctness, understanding, or response time) in the tasks. Our heterogeneous sample allowed us to produce evidence about the influence of using CC and FOP variability representations on the aspects involved in the comprehension of feature-oriented software, while addressing bug-finding tasks.",Conditional compilation | Feature-oriented software development | FeatureHouse | Graduate students | Quasi-experiments | Replication,6,1226-1258,Journal,Article,5.0,"Rodrigues Santos, Alcemir;do Carmo Machado, Ivan;Santana de Almeida, Eduardo;Siegmund, Janet;Apel, Sven",54888905200;36998427800;57204034649;55420344200;8725218400,Universität Passau;Universidade Federal da Bahia,Germany;Brazil,"several variability representations have been proposed over the years. software maintenance in the presence of variability is known to be hard. one of the reasons is that maintenance tasks require a large amount of cognitive effort for program comprehension. in fact, the different ways of representing variability in source code might influence the comprehension process in different ways. despite the differences, there is little evidence about how these variability representations – such as conditional-compilation directives or feature-oriented programming – influence program comprehension. existing research has focused primarily on either understanding how code using modern paradigms evolves compared to the traditional way of realizing variability, namely conditional compilation, or on the aspects influencing the comprehension of conditional compilation only. we used two different programs implemented in java and each of these variability representations. as java does not support conditional compilation natively, we relied on the mimicking (i.e., preprocessing annotations in comments) that has been used in the literature. our results show no significant statistical differences regarding the evaluated measures (correctness, understanding, or response time) in the tasks. our heterogeneous sample allowed us to produce evidence about the influence of using cc and fop variability representations on the aspects involved in the comprehension of feature-oriented software, while addressing bug-finding tasks.",comparing the influence of using feature-oriented programming and conditional compilation on comprehending feature-oriented software
738,2-s2.0-85071576371,10.1109/METROI4.2019.8792837,Controller Interface for Industry 4.0 based on RAMI 4.0 and OPC UA,De Melo P.F.S.,"2019 IEEE International Workshop on Metrology for Industry 4.0 and IoT, MetroInd 4.0 and IoT 2019 - Proceedings",2019-06-01,"The Fourth Industrial Revolution or Industry 4.0 (I4.0) represents the evolution of the current productive systems from the merge of industrial automation and informatics. The technical innovation of I4.0 is characterized by the integration of manufacturing systems, management over the product life cycle and the decentralization of computing resources. The Reference Architecture Model for Industry 4.0 (RAMI 4.0) defines the compatible elements of I4.0 in a three-dimensional layer model. Despite its acceptance, the use of RAMI 4.0 is still restricted to research institutions and cases of individual executions. This paper focuses on the development of an open source controller interface for I4.0 based on RAMI 4.0 and OPC UA protocol. This interface should provide the functionalities of programming, RFID identification, network communication and equipment supervision, providing real-time process information, in a standardized and interoperable way, for any type of platform connected to the network. The paper describes the integration of technologies in the controller interface, as well as the controller relationship to the RAMI 4.0 layers. In addition, this controller interface represents the first step towards the development of a compatible 'control device' to support I4.0 applications.",Control Device | Industry 4.0 | OPC UA | RAMI 4.0,20,229-234,Conference Proceeding,Conference Paper,2.0,"De Melo, Pablo Felipe Soares;Godoy, Eduardo Paciencia",57210817634;36095613800,"Universidade Estadual Paulista ""Júlio de Mesquita Filho""",Brazil,"the fourth industrial revolution or industry 4.0 (i4.0) represents the evolution of the current productive systems from the merge of industrial automation and informatics. the technical innovation of i4.0 is characterized by the integration of manufacturing systems, management over the product life cycle and the decentralization of computing resources. the reference architecture model for industry 4.0 (rami 4.0) defines the compatible elements of i4.0 in a three-dimensional layer model. despite its acceptance, the use of rami 4.0 is still restricted to research institutions and cases of individual executions. this paper focuses on the development of an open source controller interface for i4.0 based on rami 4.0 and opc ua protocol. this interface should provide the functionalities of programming, rfid identification, network communication and equipment supervision, providing real-time process information, in a standardized and interoperable way, for any type of platform connected to the network. the paper describes the integration of technologies in the controller interface, as well as the controller relationship to the rami 4.0 layers. in addition, this controller interface represents the first step towards the development of a compatible 'control device' to support i4.0 applications.",controller interface for industry 4.0 based on rami 4.0 and opc ua
739,2-s2.0-85071473899,10.1109/FAS-W.2019.00031,Transpiling applications into optimized serverless orchestrations,Scheuner J.,"Proceedings - 2019 IEEE 4th International Workshops on Foundations and Applications of Self* Systems, FAS*W 2019",2019-06-01,"The serverless computing paradigm promises increased development productivity by abstracting the underlying hardware infrastructure and software runtime when building distributed cloud applications. However, composing a serverless application consisting of many tiny functions is still a cumbersome and inflexible process due to the lack of a unified source code view and strong coupling to non-standardized function-level interfaces for code and configuration. In our vision, developers can focus on writing readable source code in a logical structure, which then gets transformed into an optimized multi-function serverless orchestration. Our idea involves transpilation (i.e., source-to-source transformation) based on an optimization model (e.g., cost optimization) by dynamically deciding which set of methods will be grouped into individual deployment units. A successful implementation of our vision would enable a broader range of serverless applications and allow for dynamic deployment optimization based on monitoring runtime metrics. Further, we would expect increased developer productivity by using more familiar abstractions and facilitating clean coding practices and code reuse.",FaaS | Orchestration | Serverless | Transpiling,0,72-73,Conference Proceeding,Conference Paper,2.0,"Scheuner, Joel;Leitner, Philipp",56737196000;18037605900,Chalmers University of Technology,Sweden,"the serverless computing paradigm promises increased development productivity by abstracting the underlying hardware infrastructure and software runtime when building distributed cloud applications. however, composing a serverless application consisting of many tiny functions is still a cumbersome and inflexible process due to the lack of a unified source code view and strong coupling to non-standardized function-level interfaces for code and configuration. in our vision, developers can focus on writing readable source code in a logical structure, which then gets transformed into an optimized multi-function serverless orchestration. our idea involves transpilation (i.e., source-to-source transformation) based on an optimization model (e.g., cost optimization) by dynamically deciding which set of methods will be grouped into individual deployment units. a successful implementation of our vision would enable a broader range of serverless applications and allow for dynamic deployment optimization based on monitoring runtime metrics. further, we would expect increased developer productivity by using more familiar abstractions and facilitating clean coding practices and code reuse.",transpiling applications into optimized serverless orchestrations
742,2-s2.0-85063882593,10.1016/j.ijmedinf.2019.03.018,Methods of usability testing in the development of eHealth applications: A scoping review,Maramba I.,International Journal of Medical Informatics,2019-06-01,"Background: The number of eHealth applications has exponentially increased in recent years, with over 325,000 health apps now available on all major app stores. This is in addition to other eHealth applications available on other platforms such as PC software, web sites and even gaming consoles. As with other digital applications, usability is one of the key factors in the successful implementation of eHealth apps. Reviews of the literature on empirical methods of usability testing in eHealth were last published in 2015. In the context of an exponentially increasing rate of App development year on year, an updated review is warranted. Objective: To identify, explore, and summarize the current methods used in the usability testing of eHealth applications. Methods: A scoping review was conducted on literature available from April 2014 up to October 2017. Four databases were searched. Literature was considered for inclusion if it was (1) focused on an eHealth application (which includes websites, PC software, smartphone and tablet applications), (2) provided information about usability of the application, (3) provided empirical results of the usability testing, (4) a full or short paper (not an abstract) published in English after March 2014. We then extracted data pertaining to the usability evaluation processes described in the selected studies. Results: 133 articles met the inclusion criteria. The methods used for usability testing, in decreasing order of frequency were: questionnaires (n = 105), task completion (n = 57), ‘Think-Aloud’ (n = 45), interviews (n = 37), heuristic testing (n = 18) and focus groups (n = 13). Majority of the studies used one (n = 45) or two (n = 46) methods of testing. The rest used a combination of three (n = 30) or four (n = 12) methods of testing usability. None of the studies used automated mechanisms to test usability. The System Usability Scale (SUS) was the most frequently used questionnaire (n = 44). The ten most frequent health conditions or diseases where eHealth apps were being evaluated for usability were the following: mental health (n = 12), cancer (n = 10), nutrition (n = 10), child health (n = 9), diabetes (n = 9), telemedicine (n = 8), cardiovascular disease (n = 6), HIV (n = 4), health information systems (n = 4) and smoking (n = 4). Further iterations of the app were reported in a minority of the studies (n = 41). The use of the ‘Think-Aloud’ (Pearson Chi-squared test: χ2 = 11.15, p < 0.05) and heuristic walkthrough (Pearson Chi-squared test: χ2 = 4.48, p < 0.05) were significantly associated with at least one further iteration of the app being developed. Conclusion: Although there has been an exponential increase in the number of eHealth apps, the number of studies that have been published that report the results of usability testing on these apps has not increased at an equivalent rate. The number of digital health applications that publish their usability evaluation results remains only a small fraction. Questionnaires are the most prevalent method of evaluating usability in eHealth applications, which provide an overall measure of usability but do not pinpoint the problems that need to be addressed. Qualitative methods may be more useful in this regard. The use of multiple evaluation methods has increased. Automated methods such as eye tracking have not gained traction in evaluating health apps. Further research is needed into which methods are best suited for the different types of eHealth applications, according to their target users and the health conditions being addressed.",Applications | eHealth | Health informatics | mHealth | Mobile | Usability,123,95-104,Journal,Review,3.0,"Maramba, Inocencio;Chatterjee, Arunangsu;Newman, Craig",14527551000;36185134700;56878367600,"Peninsula Medical School, Universities of Exeter and Plymouth",United Kingdom,"background: the number of ehealth applications has exponentially increased in recent years, with over 325,000 health apps now available on all major app stores. this is in addition to other ehealth applications available on other platforms such as pc software, web sites and even gaming consoles. as with other digital applications, usability is one of the key factors in the successful implementation of ehealth apps. reviews of the literature on empirical methods of usability testing in ehealth were last published in 2015. in the context of an exponentially increasing rate of app development year on year, an updated review is warranted. objective: to identify, explore, and summarize the current methods used in the usability testing of ehealth applications. methods: a scoping review was conducted on literature available from april 2014 up to october 2017. four databases were searched. literature was considered for inclusion if it was (1) focused on an ehealth application (which includes websites, pc software, smartphone and tablet applications), (2) provided information about usability of the application, (3) provided empirical results of the usability testing, (4) a full or short paper (not an abstract) published in english after march 2014. we then extracted data pertaining to the usability evaluation processes described in the selected studies. results: 133 articles met the inclusion criteria. the methods used for usability testing, in decreasing order of frequency were: questionnaires (n = 105), task completion (n = 57), ‘think-aloud’ (n = 45), interviews (n = 37), heuristic testing (n = 18) and focus groups (n = 13). majority of the studies used one (n = 45) or two (n = 46) methods of testing. the rest used a combination of three (n = 30) or four (n = 12) methods of testing usability. none of the studies used automated mechanisms to test usability. the system usability scale (sus) was the most frequently used questionnaire (n = 44). the ten most frequent health conditions or diseases where ehealth apps were being evaluated for usability were the following: mental health (n = 12), cancer (n = 10), nutrition (n = 10), child health (n = 9), diabetes (n = 9), telemedicine (n = 8), cardiovascular disease (n = 6), hiv (n = 4), health information systems (n = 4) and smoking (n = 4). further iterations of the app were reported in a minority of the studies (n = 41). the use of the ‘think-aloud’ (pearson chi-squared test: χ2 = 11.15, p < 0.05) and heuristic walkthrough (pearson chi-squared test: χ2 = 4.48, p < 0.05) were significantly associated with at least one further iteration of the app being developed. conclusion: although there has been an exponential increase in the number of ehealth apps, the number of studies that have been published that report the results of usability testing on these apps has not increased at an equivalent rate. the number of digital health applications that publish their usability evaluation results remains only a small fraction. questionnaires are the most prevalent method of evaluating usability in ehealth applications, which provide an overall measure of usability but do not pinpoint the problems that need to be addressed. qualitative methods may be more useful in this regard. the use of multiple evaluation methods has increased. automated methods such as eye tracking have not gained traction in evaluating health apps. further research is needed into which methods are best suited for the different types of ehealth applications, according to their target users and the health conditions being addressed.",methods of usability testing in the development of ehealth applications: a scoping review
743,2-s2.0-85046794189,10.1016/j.compag.2018.04.026,"CropGIS – A web application for the spatial and temporal visualization of past, present and future crop biomass development",Machwitz M.,Computers and Electronics in Agriculture,2019-06-01,"Spatial information on crop status and development is required by agricultural managers for a site specific and adapted management. Here, a prototype of a web application is presented for the visualization of biomass production of maize (Zea mays). The web application displays past biomass development and future predictions for user-defined regions of interest along with summary statistics. Biomass is modelled using the crop growth model (CGM) APSIM (Agricultural Production Systems Simulator) using meteorological data from 2001 to 2014. Information on current crop status and subfield heterogeneity is assimilated into APSIM through high-resolution optical satellite imagery. The use of recent satellite data and regional, historical meteorological data increases the reliability of the biomass information provided. Through its unique combination of high-resolution satellite imagery together with mechanistic crop growth modelling, this web application can overcome the often sparse temporal or sparse spatial resolution of biomass information, which is based on remote sensing images or on crop growth modelling alone. The prototype presented, with its high resolution biomass maps, can be the basis for variable rate application as farmers can react site-specifically to plant development.",Crop growth model | Data assimilation (DA) | Remote sensing | Web application | Yield maps,13,185-193,Journal,Article,5.0,"Machwitz, Miriam;Hass, Erik;Junk, Jürgen;Udelhoven, Thomas;Schlerf, Martin",16234359000;56784019900;6603329318;6701381246;23493733200,Luxembourg Institute of Science and Technology;Universitat Trier,Luxembourg;Germany,"spatial information on crop status and development is required by agricultural managers for a site specific and adapted management. here, a prototype of a web application is presented for the visualization of biomass production of maize (zea mays). the web application displays past biomass development and future predictions for user-defined regions of interest along with summary statistics. biomass is modelled using the crop growth model (cgm) apsim (agricultural production systems simulator) using meteorological data from 2001 to 2014. information on current crop status and subfield heterogeneity is assimilated into apsim through high-resolution optical satellite imagery. the use of recent satellite data and regional, historical meteorological data increases the reliability of the biomass information provided. through its unique combination of high-resolution satellite imagery together with mechanistic crop growth modelling, this web application can overcome the often sparse temporal or sparse spatial resolution of biomass information, which is based on remote sensing images or on crop growth modelling alone. the prototype presented, with its high resolution biomass maps, can be the basis for variable rate application as farmers can react site-specifically to plant development.","cropgis – a web application for the spatial and temporal visualization of past, present and future crop biomass development"
745,2-s2.0-85065851457,10.1021/acs.oprd.9b00065,Solvent Selection Methods and Tool,Piccione P.M.,Organic Process Research and Development,2019-05-17,"An interactive tool with a browser-type interface has been developed for solvent selection using the software R. Two main classes of considerations can be taken into account: technical suitability for the intended duties, and practical considerations including costs and health, safety environment (HSE) impact. The tool builds on quantitative analyses of properties selected by the user for the application at hand. The underlying philosophy is to assist the thought processes of the tool's users, rather than to prescribe set answers. The tool is a stepping stone toward design-of-experiment in chemical process development, enabling parameter space exploration without specialized software licenses, and grouping properties to assist the users. Six examples of use are given to illustrate various methodologies. In building the tool, scientific software development was found to be more intrinsically iterative than originally expected, with mock-ups and sharing of user stories more agile than lengthy user requirement specifications. Technical improvements for the future were identified, such as the automation of regressions and Hansen parameter calculations, a more extensive chemical knowledge formalism, and the addition of electron descriptions.",chemical properties | computer-aided molecular design | physical properties | software tool | solvent selection,16,998-1016,Journal,Article,10.0,"Piccione, Patrick M.;Baumeister, Julia;Salvesen, Thomas;Grosjean, Christophe;Flores, Yannick;Groelly, Eliane;Murudi, Vikrant;Shyadligeri, Ashok;Lobanova, Olga;Lothschütz, Christian",7004064743;57208783521;57208777299;23466644500;57208781781;57208778476;57193608378;6602907013;56244656100;35095472700,Syngenta International AG;Syngenta UK Limited;F. Hoffmann-La Roche AG;DSM,Switzerland;United Kingdom;Switzerland;Switzerland,"an interactive tool with a browser-type interface has been developed for solvent selection using the software r. two main classes of considerations can be taken into account: technical suitability for the intended duties, and practical considerations including costs and health, safety environment (hse) impact. the tool builds on quantitative analyses of properties selected by the user for the application at hand. the underlying philosophy is to assist the thought processes of the tool's users, rather than to prescribe set answers. the tool is a stepping stone toward design-of-experiment in chemical process development, enabling parameter space exploration without specialized software licenses, and grouping properties to assist the users. six examples of use are given to illustrate various methodologies. in building the tool, scientific software development was found to be more intrinsically iterative than originally expected, with mock-ups and sharing of user stories more agile than lengthy user requirement specifications. technical improvements for the future were identified, such as the automation of regressions and hansen parameter calculations, a more extensive chemical knowledge formalism, and the addition of electron descriptions.",solvent selection methods and tool
748,2-s2.0-85074878358,10.1109/MiSE.2019.00018,On the difficulties of raising the level of abstraction and facilitating reuse in software modelling: The case for signature extension,Schottle M.,"Proceedings - 2019 IEEE/ACM 11th International Workshop on Modelling in Software Engineering, MiSE 2019",2019-05-01,"Reuse is central to improving the software development process, increasing software quality and decreasing time-to-market. Hence it is of paramount importance that modelling languages provide features that enable the specification and modularization of reusable artefacts, as well as their subsequent reuse. In this paper we outline several difficulties caused by the finality of method signatures that make it hard to specify and use reusable artefacts encapsulating several variants. The difficulties are illustrated with a running example. To evaluate whether these difficulties can be observed at the programming level, we report on an empirical study conducted on the Java Platform API as well as present workarounds used in various programming languages to deal with the rigid nature of signatures. Finally, we outline signature extension as an approach to overcome these problems at the modelling level.",API | Modularity | Reuse | Separation of concerns | Usage interface,0,71-77,Conference Proceeding,Conference Paper,2.0,"Schottle, Matthias;Kienzle, Jorg",55566841200;8709922800,Université McGill,Canada,"reuse is central to improving the software development process, increasing software quality and decreasing time-to-market. hence it is of paramount importance that modelling languages provide features that enable the specification and modularization of reusable artefacts, as well as their subsequent reuse. in this paper we outline several difficulties caused by the finality of method signatures that make it hard to specify and use reusable artefacts encapsulating several variants. the difficulties are illustrated with a running example. to evaluate whether these difficulties can be observed at the programming level, we report on an empirical study conducted on the java platform api as well as present workarounds used in various programming languages to deal with the rigid nature of signatures. finally, we outline signature extension as an approach to overcome these problems at the modelling level.",on the difficulties of raising the level of abstraction and facilitating reuse in software modelling: the case for signature extension
750,2-s2.0-85072344031,10.1109/MSR.2019.00059,The emergence of software diversity in maven central,Soto-Valero C.,IEEE International Working Conference on Mining Software Repositories,2019-05-01,"Maven artifacts are immutable: an artifact that is uploaded on Maven Central cannot be removed nor modified. The only way for developers to upgrade their library is to release a new version. Consequently, Maven Central accumulates all the versions of all the libraries that are published there, and applications that declare a dependency towards a library can pick any version. In this work, we hypothesize that the immutability of Maven artifacts and the ability to choose any version naturally support the emergence of software diversity within Maven Central. We analyze 1,487,956 artifacts that represent all the versions of 73,653 libraries. We observe that more than 30% of libraries have multiple versions that are actively used by latest artifacts. In the case of popular libraries, more than 50% of their versions are used. We also observe that more than 17% of libraries have several versions that are significantly more used than the other versions. Our results indicate that the immutability of artifacts in Maven Central does support a sustained level of diversity among versions of libraries in the repository.",Dataset | Development history graph | Digital preservation | Free software | Mining software repositories | Open source software | Source code,11,333-343,Conference Proceeding,Conference Paper,5.0,"Soto-Valero, Cesar;Benelallam, Amine;Harrand, Nicolas;Barais, Olivier;Baudry, Benoit",57192839077;55844340200;57192872575;23395899700;57203847520,CNRS Centre National de la Recherche Scientifique;The Royal Institute of Technology (KTH),France;Sweden,"maven artifacts are immutable: an artifact that is uploaded on maven central cannot be removed nor modified. the only way for developers to upgrade their library is to release a new version. consequently, maven central accumulates all the versions of all the libraries that are published there, and applications that declare a dependency towards a library can pick any version. in this work, we hypothesize that the immutability of maven artifacts and the ability to choose any version naturally support the emergence of software diversity within maven central. we analyze 1,487,956 artifacts that represent all the versions of 73,653 libraries. we observe that more than 30% of libraries have multiple versions that are actively used by latest artifacts. in the case of popular libraries, more than 50% of their versions are used. we also observe that more than 17% of libraries have several versions that are significantly more used than the other versions. our results indicate that the immutability of artifacts in maven central does support a sustained level of diversity among versions of libraries in the repository.",the emergence of software diversity in maven central
751,2-s2.0-85072337794,10.1109/MSR.2019.00014,Import2vec: Learning embeddings for software libraries,Theeten B.,IEEE International Working Conference on Mining Software Repositories,2019-05-01,"We consider the problem of developing suitable learning representations (embeddings) for library packages that capture semantic similarity among libraries. Such representations are known to improve the performance of downstream learning tasks (e.g. classification) or applications such as contextual search and analogical reasoning. We apply word embedding techniques from natural language processing (NLP) to train embeddings for library packages ('library vectors'). Library vectors represent libraries by similar context of use as determined by import statements present in source code. Experimental results obtained from training such embeddings on three large open source software corpora reveals that library vectors capture semantically meaningful relationships among software libraries, such as the relationship between frameworks and their plug-ins and libraries commonly used together within ecosystems such as big data infrastructure projects (in Java), front-end and back-end web development frameworks (in JavaScript) and data science toolkits (in Python).",Information retrieval | Machine learning | Software engineering,11,18-28,Conference Proceeding,Conference Paper,3.0,"Theeten, Bart;Vandeputte, Frederik;Van Cutsem, Tom",22434311600;8944918900;16308156600,Nokia Bell Labs,United States,"we consider the problem of developing suitable learning representations (embeddings) for library packages that capture semantic similarity among libraries. such representations are known to improve the performance of downstream learning tasks (e.g. classification) or applications such as contextual search and analogical reasoning. we apply word embedding techniques from natural language processing (nlp) to train embeddings for library packages ('library vectors'). library vectors represent libraries by similar context of use as determined by import statements present in source code. experimental results obtained from training such embeddings on three large open source software corpora reveals that library vectors capture semantically meaningful relationships among software libraries, such as the relationship between frameworks and their plug-ins and libraries commonly used together within ecosystems such as big data infrastructure projects (in java), front-end and back-end web development frameworks (in javascript) and data science toolkits (in python).",import2vec: learning embeddings for software libraries
752,2-s2.0-85072332844,10.1109/MSR.2019.00082,Beyond GumTree: A hybrid approach to generate edit scripts,Matsumoto J.,IEEE International Working Conference on Mining Software Repositories,2019-05-01,"On development using a version control system, understanding differences of source code is important. Edit scripts (in short, ES) represent differences between two versions of source code. One of the tools generating ESs is GumTree. GumTree takes two versions of source code as input and generates an ES consisting of insert, delete, update and move nodes of abstract syntax tree (in short, AST). However, the accuracy of move and update actions generated by GumTree is insufficient, which makes ESs more difficult to understand. A reason why the accuracy is insufficient is that GumTree generates ESs from only information of AST. Thus, in this research, we propose to generate easier-to-understand ESs by using not only structures of AST but also information of line differences. To evaluate our methodology, we applied it to some open source software, and we confirmed that ESs generated by our methodology are more helpful to understand the differences of source code than GumTree.",Difference | Edit Script | GumTree,3,550-554,Conference Proceeding,Conference Paper,3.0,"Matsumoto, Junnosuke;Higo, Yoshiki;Kusumoto, Shinji",57202892758;7004831134;7102741360,Osaka University,Japan,"on development using a version control system, understanding differences of source code is important. edit scripts (in short, es) represent differences between two versions of source code. one of the tools generating ess is gumtree. gumtree takes two versions of source code as input and generates an es consisting of insert, delete, update and move nodes of abstract syntax tree (in short, ast). however, the accuracy of move and update actions generated by gumtree is insufficient, which makes ess more difficult to understand. a reason why the accuracy is insufficient is that gumtree generates ess from only information of ast. thus, in this research, we propose to generate easier-to-understand ess by using not only structures of ast but also information of line differences. to evaluate our methodology, we applied it to some open source software, and we confirmed that ess generated by our methodology are more helpful to understand the differences of source code than gumtree.",beyond gumtree: a hybrid approach to generate edit scripts
753,2-s2.0-85072319273,10.1109/ICPC.2019.00017,Live programming and software evolution: Questions during a programming change task,Kubelka J.,IEEE International Conference on Program Comprehension,2019-05-01,"Several studies provide the questions developers ask during software evolution tasks, providing foundations for subsequent work. Nevertheless, none of them focus on Live Programming environments that gain in popularity as they are perceived to have a positive effect on programming tasks. Studying the impact of a Live Programming environment on software development activities is thus the goal of this study. In a partial replication of the study by Sillito et al., we conducted 17 software evolution sessions in a Live Programming environment and report 1,161 developer questions asked during these sessions. We contrast our results with the results by Sillito et al., focusing on the question occurrences, question complexity and what information participants used to gain a required knowledge. We report eight new questions and observe that the Live Programming facilities do have an impact on the way developers ask questions about source code and use tools to gain corresponding knowledge.",Development environments | Exploratory study | Live programming,5,30-41,Conference Proceeding,Conference Paper,3.0,"Kubelka, Juraj;Robbes, Romain;Bergel, Alexandre",56682706700;15136854400;23093070700,Universidad de Chile;Free University of Bozen-Bolzano,Chile;Italy,"several studies provide the questions developers ask during software evolution tasks, providing foundations for subsequent work. nevertheless, none of them focus on live programming environments that gain in popularity as they are perceived to have a positive effect on programming tasks. studying the impact of a live programming environment on software development activities is thus the goal of this study. in a partial replication of the study by sillito et al., we conducted 17 software evolution sessions in a live programming environment and report 1,161 developer questions asked during these sessions. we contrast our results with the results by sillito et al., focusing on the question occurrences, question complexity and what information participants used to gain a required knowledge. we report eight new questions and observe that the live programming facilities do have an impact on the way developers ask questions about source code and use tools to gain corresponding knowledge.",live programming and software evolution: questions during a programming change task
754,2-s2.0-85072316214,10.1109/MSR.2019.00054,Identifying experts in software libraries and frameworks among GitHub Users,Montandon J.E.,IEEE International Working Conference on Mining Software Repositories,2019-05-01,"Software development increasingly depends on libraries and frameworks to increase productivity and reduce time-to-market. Despite this fact, we still lack techniques to assess developers expertise in widely popular libraries and frameworks. In this paper, we evaluate the performance of unsupervised (based on clustering) and supervised machine learning classifiers (Random Forest and SVM) to identify experts in three popular JavaScript libraries: facebook/react, mongodb/node-mongodb, and socketio/socket.io. First, we collect 13 features about developers activity on GitHub projects, including commits on source code files that depend on these libraries. We also build a ground truth including the expertise of 575 developers on the studied libraries, as self-reported by them in a survey. Based on our findings, we document the challenges of using machine learning classifiers to predict expertise in software libraries, using features extracted from GitHub. Then, we propose a method to identify library experts based on clustering feature data from GitHub; by triangulating the results of this method with information available on Linkedin profiles, we show that it is able to recommend dozens of GitHub users with evidences of being experts in the studied JavaScript libraries. We also provide a public dataset with the expertise of 575 developers on the studied libraries.",Expertise identification | Github | Machine learning | Software libraries | Technical expertise,18,276-287,Conference Proceeding,Conference Paper,3.0,"Montandon, Joao Eduardo;Lourdes Silva, Luciana;Valente, Marco Tulio",54584047800;23971520400;55437198000,Universidade Federal de Minas Gerais;Federal Institute of Minas Gerais,Brazil;Brazil,"software development increasingly depends on libraries and frameworks to increase productivity and reduce time-to-market. despite this fact, we still lack techniques to assess developers expertise in widely popular libraries and frameworks. in this paper, we evaluate the performance of unsupervised (based on clustering) and supervised machine learning classifiers (random forest and svm) to identify experts in three popular javascript libraries: facebook/react, mongodb/node-mongodb, and socketio/socket.io. first, we collect 13 features about developers activity on github projects, including commits on source code files that depend on these libraries. we also build a ground truth including the expertise of 575 developers on the studied libraries, as self-reported by them in a survey. based on our findings, we document the challenges of using machine learning classifiers to predict expertise in software libraries, using features extracted from github. then, we propose a method to identify library experts based on clustering feature data from github; by triangulating the results of this method with information available on linkedin profiles, we show that it is able to recommend dozens of github users with evidences of being experts in the studied javascript libraries. we also provide a public dataset with the expertise of 575 developers on the studied libraries.",identifying experts in software libraries and frameworks among github users
756,2-s2.0-85072111059,10.1109/ICSE-SEET.2019.00016,The case of the fragmented classroom,Billingsley W.,"Proceedings - 2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering Education and Training, ICSE-SEET 2019",2019-05-01,"Increasingly, education is offered to students any time, anywhere, for any stage of life, for students with any background and a wide variety of goals. This implies it is taken at different times, in different places, at different paces, by students with different technical backgrounds who are on different pathways. Students are becoming ever more isolated except for the teaching and technology that connects them. In our software development teaching, we find this combines with differences in technology choice and technical environment between students to produce classes filled with groups of students who face very different challenges. Course design, then, increasingly has to take account of the different forms of variation within the class, so that it can not only cope with them but turn them to an advantage of diversity. Some of these differences, such as the particular degree path by which a student reached the subject, are not refined questions of the student as an individual, but coarse differences imposed by external constraints (such as their differing degree rules or the location they are studying from). As these differences are external to the student, I refer to them in the paper as fragmentation rather than variation. This paper is a case study of software development teaching at a regional Australian university, identifying the kinds of fragmentation within it, and the various strategies (including the mundane) we have used to turn it to an advantage.",Blended learning | Life-long learning | Online learning | Software engineering education,1,74-83,Conference Proceeding,Conference Paper,1.0,"Billingsley, William",14031227700,University of New England Australia,Australia,"increasingly, education is offered to students any time, anywhere, for any stage of life, for students with any background and a wide variety of goals. this implies it is taken at different times, in different places, at different paces, by students with different technical backgrounds who are on different pathways. students are becoming ever more isolated except for the teaching and technology that connects them. in our software development teaching, we find this combines with differences in technology choice and technical environment between students to produce classes filled with groups of students who face very different challenges. course design, then, increasingly has to take account of the different forms of variation within the class, so that it can not only cope with them but turn them to an advantage of diversity. some of these differences, such as the particular degree path by which a student reached the subject, are not refined questions of the student as an individual, but coarse differences imposed by external constraints (such as their differing degree rules or the location they are studying from). as these differences are external to the student, i refer to them in the paper as fragmentation rather than variation. this paper is a case study of software development teaching at a regional australian university, identifying the kinds of fragmentation within it, and the various strategies (including the mundane) we have used to turn it to an advantage.",the case of the fragmented classroom
757,2-s2.0-85072059918,10.1109/ICSE-NIER.2019.00037,Current challenges in practical object-oriented software design,Aniche M.,"Proceedings - 2019 IEEE/ACM 41st International Conference on Software Engineering: New Ideas and Emerging Results, ICSE-NIER 2019",2019-05-01,"According to the extensive 50-year-old body of knowledge in object-oriented programming and design, good software designs are, among other characteristics, lowly coupled, highly cohesive, extensible, comprehensible, and not fragile. However, with the increased complexity and heterogeneity of contemporary software, this might not be enough. This paper discusses the practical challenges of object-oriented design in modern software development. We focus on three main challenges: (1) how technologies, frameworks, and architectures pressure developers to make design decisions that they would not take in an ideal scenario, (2) the complexity of current real-world problems require developers to devise not only a single, but several models for the same problem that live and interact together, and (3) how existing quality assessment techniques for object-oriented design should go beyond high-level metrics. Finally, we propose an agenda for future research that should be tackled by both scientists and practitioners soon. This paper is a call for arms for more reality-oriented research on the object-oriented software design field.",Class design | Domain modeling | Object oriented design | Object oriented programming | Software architecture | Software design | Software engineering,6,113-116,Conference Proceeding,Conference Paper,3.0,"Aniche, Mauricio;Yoder, Joseph;Kon, Fabio",36132835800;7102730483;6602156198,"Universidade de São Paulo;Delft University of Technology;Refactory, Inc.",Brazil;Netherlands;United States,"according to the extensive 50-year-old body of knowledge in object-oriented programming and design, good software designs are, among other characteristics, lowly coupled, highly cohesive, extensible, comprehensible, and not fragile. however, with the increased complexity and heterogeneity of contemporary software, this might not be enough. this paper discusses the practical challenges of object-oriented design in modern software development. we focus on three main challenges: (1) how technologies, frameworks, and architectures pressure developers to make design decisions that they would not take in an ideal scenario, (2) the complexity of current real-world problems require developers to devise not only a single, but several models for the same problem that live and interact together, and (3) how existing quality assessment techniques for object-oriented design should go beyond high-level metrics. finally, we propose an agenda for future research that should be tackled by both scientists and practitioners soon. this paper is a call for arms for more reality-oriented research on the object-oriented software design field.",current challenges in practical object-oriented software design
758,2-s2.0-85071947090,10.1109/ICSE.2019.00060,Tool Choice Matters: JavaScript Quality Assurance Tools and Usage Outcomes in GitHub Projects,Kavaler D.,Proceedings - International Conference on Software Engineering,2019-05-01,"Quality assurance automation is essential in modern software development. In practice, this automation is supported by a multitude of tools that fit different needs and require developers to make decisions about which tool to choose in a given context. Data and analytics of the pros and cons can inform these decisions. Yet, in most cases, there is a dearth of empirical evidence on the effectiveness of existing practices and tool choices. We propose a general methodology to model the time- dependent effect of automation tool choice on four outcomes of interest: prevalence of issues, code churn, number of pull requests, and number of contributors, all with a multitude of controls. On a large data set of npm JavaScript projects, we extract the adoption events for popular tools in three task classes: linters, dependency managers, and coverage reporters. Using mixed methods approaches, we study the reasons for the adoptions and compare the adoption effects within each class, and sequential tool adoptions across classes. We find that some tools within each group are associated with more beneficial outcomes than others, providing an empirical perspective for the benefits of each. We also find that the order in which some tools are implemented is associated with varying outcomes.",empirical study | quality assurance tools,17,476-487,Conference Proceeding,Conference Paper,4.0,"Kavaler, David;Trockman, Asher;Vasilescu, Bogdan;Filkov, Vladimir",55999175700;57202893894;42062536300;6603001620,"University of Evansville;University of California, Davis;CMU",United States;United States;,"quality assurance automation is essential in modern software development. in practice, this automation is supported by a multitude of tools that fit different needs and require developers to make decisions about which tool to choose in a given context. data and analytics of the pros and cons can inform these decisions. yet, in most cases, there is a dearth of empirical evidence on the effectiveness of existing practices and tool choices. we propose a general methodology to model the time- dependent effect of automation tool choice on four outcomes of interest: prevalence of issues, code churn, number of pull requests, and number of contributors, all with a multitude of controls. on a large data set of npm javascript projects, we extract the adoption events for popular tools in three task classes: linters, dependency managers, and coverage reporters. using mixed methods approaches, we study the reasons for the adoptions and compare the adoption effects within each class, and sequential tool adoptions across classes. we find that some tools within each group are associated with more beneficial outcomes than others, providing an empirical perspective for the benefits of each. we also find that the order in which some tools are implemented is associated with varying outcomes.",tool choice matters: javascript quality assurance tools and usage outcomes in github projects
759,2-s2.0-85071910108,10.1109/MSR.2019.00029,Time present and time past: Analyzing the evolution of javascript code in the wild,Mitropoulos D.,IEEE International Working Conference on Mining Software Repositories,2019-05-01,"JavaScript is one of the web's key building blocks. It is used by the majority of web sites and it is supported by all modern browsers. We present the first large-scale study of client-side JavaScript code over time. Specifically, we have collected and analyzed a dataset containing daily snapshots of JavaScript code coming from Alexa's Top 10000 web sites (~7.5 GB per day) for nine consecutive months, to study different temporal aspects of web client code. We found that scripts change often; typically every few days, indicating a rapid pace in web applications development. We also found that the lifetime of web sites themselves, measured as the time between JavaScript changes, is also short, in the same time scale. We then performed a qualitative analysis to investigate the nature of the changes that take place. We found that apart from standard changes such as the introduction of new functions, many changes are related to online configuration management. In addition, we examined JavaScript code reuse over time and especially the widespread reliance on third-party libraries. Furthermore, we observed how quality issues evolve by employing established static analysis tools to identify potential software bugs, whose evolution we tracked over time. Our results show that quality issues seem to persist over time, while vulnerable libraries tend to decrease.",Bug Persistence | Code Reuse | JavaScript | Software Evolution,8,126-137,Conference Proceeding,Conference Paper,4.0,"Mitropoulos, Dimitris;Louridas, Panos;Salis, Vitalis;Spinellis, Diomidis",36886013800;17343724600;57207962487;35566637400,Athens University of Economics and Business;Greek Research and Technology Network,Greece;Greece,"javascript is one of the web's key building blocks. it is used by the majority of web sites and it is supported by all modern browsers. we present the first large-scale study of client-side javascript code over time. specifically, we have collected and analyzed a dataset containing daily snapshots of javascript code coming from alexa's top 10000 web sites (~7.5 gb per day) for nine consecutive months, to study different temporal aspects of web client code. we found that scripts change often; typically every few days, indicating a rapid pace in web applications development. we also found that the lifetime of web sites themselves, measured as the time between javascript changes, is also short, in the same time scale. we then performed a qualitative analysis to investigate the nature of the changes that take place. we found that apart from standard changes such as the introduction of new functions, many changes are related to online configuration management. in addition, we examined javascript code reuse over time and especially the widespread reliance on third-party libraries. furthermore, we observed how quality issues evolve by employing established static analysis tools to identify potential software bugs, whose evolution we tracked over time. our results show that quality issues seem to persist over time, while vulnerable libraries tend to decrease.",time present and time past: analyzing the evolution of javascript code in the wild
760,2-s2.0-85071538312,10.13328/j.cnki.jos.005735,Empirical Study of Code Smell Impact on Software Evolution,Zhang X.,Ruan Jian Xue Bao/Journal of Software,2019-05-01,"Code smells refer to poor design patterns or design defects that are considered to have negative impacts on software evolution and maintenance. Many researchers have been devoted into studies on these effects and correlations in recent years. Previous researches indicated that code smells might vary with the evolution of software. In normal cases, the software evolution involves addition, modification, and deletion of source files. Therefore, the understanding of the correlations between code smells and software evolution will be helpful for developers in scheduling the development process and in code refactoring. Thus, in this study, on 8 popular Java projects with 104 released versions, an extensive empirical study is conducted to investigate 13 kinds of code smells. It is found that, as the software evolves, the proportion of files that contain code smell in all files reflects different characteristics in different projects. Additionally, the files containing smells are prone to be modified while the smells are not strongly correlated with adding or deleting files. Furthermore, among all the smells studied, some certain ones have significant impact on the file changes and obvious overlap exists in these specific smelly files. These findings are beneficial for developers to achieve in-depth comprehension of code smells, which will lead to better software maintenance.",Anti-pattern | Code smell | Empirical study | Software evolution | Software maintenance,2,1422-1437,Journal,Article,2.0,"Zhang, Xiao Fang;Zhu, Can",56461460000;57201120039,Soochow University,China,"code smells refer to poor design patterns or design defects that are considered to have negative impacts on software evolution and maintenance. many researchers have been devoted into studies on these effects and correlations in recent years. previous researches indicated that code smells might vary with the evolution of software. in normal cases, the software evolution involves addition, modification, and deletion of source files. therefore, the understanding of the correlations between code smells and software evolution will be helpful for developers in scheduling the development process and in code refactoring. thus, in this study, on 8 popular java projects with 104 released versions, an extensive empirical study is conducted to investigate 13 kinds of code smells. it is found that, as the software evolves, the proportion of files that contain code smell in all files reflects different characteristics in different projects. additionally, the files containing smells are prone to be modified while the smells are not strongly correlated with adding or deleting files. furthermore, among all the smells studied, some certain ones have significant impact on the file changes and obvious overlap exists in these specific smelly files. these findings are beneficial for developers to achieve in-depth comprehension of code smells, which will lead to better software maintenance.",empirical study of code smell impact on software evolution
761,2-s2.0-85071520807,10.13328/j.cnki.jos.005718,Retrieval and Management Technology for Industrial-scale Massive Code,Liu Z.W.,Ruan Jian Xue Bao/Journal of Software,2019-05-01,"In large IT companies, especially like Google or Baidu, code search is an indispensable and frequent activity in the software development process, which speeds up the development process by learning or reusing existing code. Over the years, a large number of researchers have focused on code search and designed many excellent tools. However, the existing research and tools are mainly on a small-scale or single programming language code data set, not from the actual requirement of industries, and the user's query input is also limited; there is still a lack of a set of industrial-scale massive code retrieval and management technology solutions. This study proposes a code search engine solution and system implementation based on industrial-scale massive data, oriented to the most direct needs of users in the development process, through offline analysis and online analysis, complete the index construction and retrieval of massive code base. Among them, offline analysis is responsible for the acquisition and analysis of code-related data and building an index cluster. The online process is responsible for transforming the user's query, sorting the results of the search, and generating a summary. The system is deployed on the Baidu code base, and the index is built for dozens of TB-level Git code bases. The average retrieval time is within 1s. Since the launch of Baidu's application, the number of visits has gradually increased. There are thousands of users per week and tens of thousands of times searching. The system is widely praised by Baidu engineers.",Code search | Indexing | Massive code | Rank,2,1498-1509,Journal,Article,5.0,"Liu, Zhi Wei;Xing, Yong Xu;Yu, Hao;Li, Tao;Zhang, Xiao Dong",57210824556;57210822355;57195433032;57211840914;56875205800,"Baidu, Inc.;Xi'an Jiaotong University",China;China,"in large it companies, especially like google or baidu, code search is an indispensable and frequent activity in the software development process, which speeds up the development process by learning or reusing existing code. over the years, a large number of researchers have focused on code search and designed many excellent tools. however, the existing research and tools are mainly on a small-scale or single programming language code data set, not from the actual requirement of industries, and the user's query input is also limited; there is still a lack of a set of industrial-scale massive code retrieval and management technology solutions. this study proposes a code search engine solution and system implementation based on industrial-scale massive data, oriented to the most direct needs of users in the development process, through offline analysis and online analysis, complete the index construction and retrieval of massive code base. among them, offline analysis is responsible for the acquisition and analysis of code-related data and building an index cluster. the online process is responsible for transforming the user's query, sorting the results of the search, and generating a summary. the system is deployed on the baidu code base, and the index is built for dozens of tb-level git code bases. the average retrieval time is within 1s. since the launch of baidu's application, the number of visits has gradually increased. there are thousands of users per week and tens of thousands of times searching. the system is widely praised by baidu engineers.",retrieval and management technology for industrial-scale massive code
762,2-s2.0-85070310870,10.23919/MIPRO.2019.8756917,Exploring aspects of polyglot high-performance virtual machine GraalVM,Šipek M.,"2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2019 - Proceedings",2019-05-01,"Contemporary software often becomes vastly complex, and we are required to use a variety of technologies and different programming languages for its development. As interoperability between programming languages could cause high overhead resulting in a performance loss, it is important to examine how a current polyglot virtual machine with a compiler written in a high-level object-oriented language deals with it. OpenJDK's Project Metropolis presented the GraalVM, an open-source, high-performance polyglot virtual machine, mostly written in Java. This paper presents GraalVM's architecture and its features; furthermore, examining how it resolves common interoperability and performance problems. GraalVM makes software ecosystem productive when combining various programming languages, for example, Java, JavaScript, C/C++, Python, Ruby, R, and others. The vital part of GraalVM is the Graal compiler written in Java, which allows developers to maintain and optimize code faster, simpler, and more efficient, in comparison to traditional compilers in C/C++ languages. Graal can be used as a just-in-time (JIT) or as static, ahead-of-time (AOT) compiler. Graal is an aggressively optimizing compiler implementing common compiler optimizations, with emphasis on outstanding inlining and escape analysis algorithms. This paper compares Graal with some of the best-specialized competitors, and presents our results tested within an academic environment.",Cross-language interoperability | Graal | GraalVM | Java | Java Virtual Machine | Polyglot virtual machine | Programming languages,3,1671-1676,Conference Proceeding,Conference Paper,3.0,"Šipek, M.;Mihaljevic, B.;Radovan, A.",57215360572;14020072300;55912635000,Rochester Institute of Technology,United States,"contemporary software often becomes vastly complex, and we are required to use a variety of technologies and different programming languages for its development. as interoperability between programming languages could cause high overhead resulting in a performance loss, it is important to examine how a current polyglot virtual machine with a compiler written in a high-level object-oriented language deals with it. openjdk's project metropolis presented the graalvm, an open-source, high-performance polyglot virtual machine, mostly written in java. this paper presents graalvm's architecture and its features; furthermore, examining how it resolves common interoperability and performance problems. graalvm makes software ecosystem productive when combining various programming languages, for example, java, javascript, c/c++, python, ruby, r, and others. the vital part of graalvm is the graal compiler written in java, which allows developers to maintain and optimize code faster, simpler, and more efficient, in comparison to traditional compilers in c/c++ languages. graal can be used as a just-in-time (jit) or as static, ahead-of-time (aot) compiler. graal is an aggressively optimizing compiler implementing common compiler optimizations, with emphasis on outstanding inlining and escape analysis algorithms. this paper compares graal with some of the best-specialized competitors, and presents our results tested within an academic environment.",exploring aspects of polyglot high-performance virtual machine graalvm
766,2-s2.0-85061192625,10.1016/j.envsoft.2019.01.021,Simplifying the deployment of OGC web processing services (WPS) for environmental modelling – Introducing Tethys WPS Server,Qiao X.,Environmental Modelling and Software,2019-05-01,"Developing a complex environmental modelling web application or “web app” can be a challenging task that requires integration of various models and data sources with ever-changing Internet technologies. Service-Oriented Architecture (SOA) has been shown to be useful for building complex modelling workflows. However, compared with other types of web services, such as those for data delivery and mapping, the implementation of Open Geospatial Consortium (OGC) web processing services (WPS) for environmental modelling and data analysis is not very common. This problem stems, in part, from the lack of tools to simplify the development and deployment of WPS for the broad and complex set of environmental modelling applications. This paper presents the development and testing of a ready-to-use WPS implementation called Tethys WPS Server, which provides a formalized way to expose web app functionality as standardized WPS alongside a web app's graphical user interface. The WPS server is created based on Tethys Platform by leveraging PyWPS. Three Tethys web apps are developed to demonstrate how web app functionality(s) can be exposed as WPS using Tethys WPS Server, and to show how these WPS can be coupled to build a complex modelling web app. Moreover, we demonstrate that the services hosted on Tethys WPS Server follow OGC standards correctly and can be used successfully by third party applications and clients that support the OGC WPS specification.",PyWPS | Tethys platform | Web app interoperability | Web processing service (WPS),16,38-50,Journal,Article,5.0,"Qiao, Xiaohui;Li, Zhiyu;Ames, Daniel P.;Nelson, E. James;Swain, Nathan R.",57205706367;57205706055;12808778700;7402264252;55355289700,"Brigham Young University;Aquaveo, LLC",United States;United States,"developing a complex environmental modelling web application or “web app” can be a challenging task that requires integration of various models and data sources with ever-changing internet technologies. service-oriented architecture (soa) has been shown to be useful for building complex modelling workflows. however, compared with other types of web services, such as those for data delivery and mapping, the implementation of open geospatial consortium (ogc) web processing services (wps) for environmental modelling and data analysis is not very common. this problem stems, in part, from the lack of tools to simplify the development and deployment of wps for the broad and complex set of environmental modelling applications. this paper presents the development and testing of a ready-to-use wps implementation called tethys wps server, which provides a formalized way to expose web app functionality as standardized wps alongside a web app's graphical user interface. the wps server is created based on tethys platform by leveraging pywps. three tethys web apps are developed to demonstrate how web app functionality(s) can be exposed as wps using tethys wps server, and to show how these wps can be coupled to build a complex modelling web app. moreover, we demonstrate that the services hosted on tethys wps server follow ogc standards correctly and can be used successfully by third party applications and clients that support the ogc wps specification.",simplifying the deployment of ogc web processing services (wps) for environmental modelling – introducing tethys wps server
767,2-s2.0-85064755046,10.1145/3319008.3319024,Features that predict the acceptability of Java and Javascript answers on stack overflow,Omondiagbe O.P.,ACM International Conference Proceeding Series,2019-04-15,"Context: Stack Overflow is a popular community question and answer portal used by practitioners to solve problems during software development. Developers can focus their attention on answers that have been accepted or where members have recorded high votes in judging good answers when searching for help. However, the latter mechanism (votes) can be unreliable, and there is currently no way to differentiate between an answer that is likely to be accepted and those that will not be accepted by looking at the answer’s characteristics. Objective: In potentially providing a mechanism to identify acceptable answers, this study examines the features that distinguish an accepted answer from an unaccepted answer. Methods: We studied the Stack Overflow dataset by analyzing questions and answers for the two most popular tags (Java and JavaScript). Our dataset comprised 249,588 posts drawn from 2014-2016. We use random forest and neural network models to predict accepted answers, and study the features with the highest predictive power in those two models. Results: Our findings reveal that the length of code in answers, reputation of users, similarity of the text between questions and answers, and the time lag between questions and answers have the highest predictive power for differentiating accepted and unaccepted answers. Conclusion: Tools may leverage these findings in supporting developers and reducing the effort they must dedicate to searching for suitable answers on Stack Overflow.",Feature selection | Neural network | Non-textual features | Random forest | Stack overflow | Text-mining | Textual features,4,101-110,Conference Proceeding,Conference Paper,3.0,"Omondiagbe, Osayande P.;Licorish, Sherlock A.;MacDonell, Stephen G.",57208421612;35085392600;6701732791,Manaaki Whenua – Landcare Research;University of Otago,New Zealand;New Zealand,"context: stack overflow is a popular community question and answer portal used by practitioners to solve problems during software development. developers can focus their attention on answers that have been accepted or where members have recorded high votes in judging good answers when searching for help. however, the latter mechanism (votes) can be unreliable, and there is currently no way to differentiate between an answer that is likely to be accepted and those that will not be accepted by looking at the answer’s characteristics. objective: in potentially providing a mechanism to identify acceptable answers, this study examines the features that distinguish an accepted answer from an unaccepted answer. methods: we studied the stack overflow dataset by analyzing questions and answers for the two most popular tags (java and javascript). our dataset comprised 249,588 posts drawn from 2014-2016. we use random forest and neural network models to predict accepted answers, and study the features with the highest predictive power in those two models. results: our findings reveal that the length of code in answers, reputation of users, similarity of the text between questions and answers, and the time lag between questions and answers have the highest predictive power for differentiating accepted and unaccepted answers. conclusion: tools may leverage these findings in supporting developers and reducing the effort they must dedicate to searching for suitable answers on stack overflow.",features that predict the acceptability of java and javascript answers on stack overflow
768,2-s2.0-85064730239,10.1145/3319008.3319028,Perceived relevance of automatic code inspection in end-user development: A study on VBA,Roy S.,ACM International Conference Proceeding Series,2019-04-15,"Microsoft VBA (Visual Basic for Applications) is a programming language widely used by end-user programmers, often alongside the popular spreadsheet software Excel. Together they form the popular Excel-VBA application ecosystem. Despite being popular, spreadsheets are known to be fault-prone, and to minimize risk of faults in the overall Excel-VBA ecosystem, it is important to support end-user programmers in improving the code quality of their VBA programs also, in addition to improving spreadsheet technology and practices. In traditional software development, automatic code inspection using static analysis tools has been found effective in improving code quality, but the practical relevance of this technique in an end-user development context remains unexplored. With the aim of popularizing it in the end-user community, in this paper we examine the relevance of automatic code inspection in terms of how inspection rules are perceived by VBA programmers. We conduct a qualitative study consisting of interviews with 14 VBA programmers, who share their perceptions about 20 inspection rules that most frequently detected code quality issues in an industrial dataset of 25 VBA applications, obtained from a financial services company. Results show that the 20 studied inspection rules can be grouped into three categories of user perceptions based on the type of issues they warn about: i) 11 rules that warn about serious problems which need fixing, ii) 7 rules that warn about bad practices which do not mandate fixing, and iii) 2 rules that warn about purposeful code elements rather than issues. Based on these perceptions, we conclude that automatic code inspection is considerably relevant in an end-user development context such as VBA. The perceptions also indicate which inspection rules deserve the most attention from interested researchers and tool developers. Lastly, our results also reveal 3 additional issue types that are not covered by the existing inspection rules, and are therefore impetus for creating new rules.",Code quality | Developer perceptions | End-user development | Static analysis | VBA,0,167-176,Conference Proceeding,Conference Paper,3.0,"Roy, Sohon;Van Deursen, Arie;Hermans, Felienne",56562208400;7003969355;35573133300,Universiteit Leiden;Delft University of Technology,Netherlands;Netherlands,"microsoft vba (visual basic for applications) is a programming language widely used by end-user programmers, often alongside the popular spreadsheet software excel. together they form the popular excel-vba application ecosystem. despite being popular, spreadsheets are known to be fault-prone, and to minimize risk of faults in the overall excel-vba ecosystem, it is important to support end-user programmers in improving the code quality of their vba programs also, in addition to improving spreadsheet technology and practices. in traditional software development, automatic code inspection using static analysis tools has been found effective in improving code quality, but the practical relevance of this technique in an end-user development context remains unexplored. with the aim of popularizing it in the end-user community, in this paper we examine the relevance of automatic code inspection in terms of how inspection rules are perceived by vba programmers. we conduct a qualitative study consisting of interviews with 14 vba programmers, who share their perceptions about 20 inspection rules that most frequently detected code quality issues in an industrial dataset of 25 vba applications, obtained from a financial services company. results show that the 20 studied inspection rules can be grouped into three categories of user perceptions based on the type of issues they warn about: i) 11 rules that warn about serious problems which need fixing, ii) 7 rules that warn about bad practices which do not mandate fixing, and iii) 2 rules that warn about purposeful code elements rather than issues. based on these perceptions, we conclude that automatic code inspection is considerably relevant in an end-user development context such as vba. the perceptions also indicate which inspection rules deserve the most attention from interested researchers and tool developers. lastly, our results also reveal 3 additional issue types that are not covered by the existing inspection rules, and are therefore impetus for creating new rules.",perceived relevance of automatic code inspection in end-user development: a study on vba
771,2-s2.0-85069146733,10.1109/ISCAIE.2019.8743865,Mobile app for speed reading test in Bahasa Malaysia,Zurati N.,ISCAIE 2019 - 2019 IEEE Symposium on Computer Applications and Industrial Electronics,2019-04-01,"There is a lack of data for speed-reading level in Bahasa Malaysia for young people, which refers to individuals between ages 10 and 24. The information is needed by the National Book Council of Malaysia (NBCM) to assess reading frequencies of young people, correlated using speed-reading tests. Hence, a mobile app for speed-reading test in Bahasa Malaysia called Bacalaju has been developed. Applying Progressive Web Application (PWA) that uses front-end website technology, an Android app is generated by compiling the code with Android SDK (Software Development Kit). After the user took their speed-reading test, the result will be transferred via Asynchronous JavaScript And XML (AJAX) POST request and stored in a database on the cloud. The mobile app is seen to benefit young readers in Malaysia because it enables users to evaluate their reading skills and encourage them to improve the skills, i.e. speed-reading level and comprehension. At the same time, a website was developed to display the overall result, preliminary result indicated that 37.8% of 98 users involved in this study has both good speed-reading level based on the Taylor Grade Equivalent units and able to score more than 50% in their comprehension test.",Mobile app | Progressive Web Application (PWA) | Speed-reading test | Taylor Grade Equivalent units,0,193-197,Conference Proceeding,Conference Paper,5.0,"Zurati, Nazeb;Abdullah, Syahrul Afzal Che;Zaman, Fadhlan Hafizhelmi Kamaru;Abidin, Husna Zainol;Soh, Zainal Hisham Che",57209981936;54406628500;57211748029;52165115900;25825713900,Universiti Teknologi MARA,Malaysia,"there is a lack of data for speed-reading level in bahasa malaysia for young people, which refers to individuals between ages 10 and 24. the information is needed by the national book council of malaysia (nbcm) to assess reading frequencies of young people, correlated using speed-reading tests. hence, a mobile app for speed-reading test in bahasa malaysia called bacalaju has been developed. applying progressive web application (pwa) that uses front-end website technology, an android app is generated by compiling the code with android sdk (software development kit). after the user took their speed-reading test, the result will be transferred via asynchronous javascript and xml (ajax) post request and stored in a database on the cloud. the mobile app is seen to benefit young readers in malaysia because it enables users to evaluate their reading skills and encourage them to improve the skills, i.e. speed-reading level and comprehension. at the same time, a website was developed to display the overall result, preliminary result indicated that 37.8% of 98 users involved in this study has both good speed-reading level based on the taylor grade equivalent units and able to score more than 50% in their comprehension test.",mobile app for speed reading test in bahasa malaysia
772,2-s2.0-85063278474,10.1007/s13369-019-03718-9,Software Birthmark Design and Estimation: A Systematic Literature Review,Nazir S.,Arabian Journal for Science and Engineering,2019-04-01,"The concept of software birthmark is developed for the detection of theft and piracy in software applications. The originality of software can be evaluated by comparing software programs on the basis of their birthmarks. A number of birthmark designs have been proposed which are used to specify birthmark for source code and executable code related to particular programming languages. This study presents a systematic literature review on available software birthmark designs and related techniques for comparing birthmarks in order to identify pirated software. This research is focused on identifying different applications of software birthmark, especially the estimation of software birthmark to identify the extent of piracy performed in a software. The objective is to gain insight into complex details of software birthmark by accumulating and analyzing the knowledge provided in the literature in order to facilitate further research in software birthmark and its applications. The study is conducted by following the systematic literature review protocol. The data are collected from primary studies published from 1992 to April 2018 in specified journals and conference/workshop proceedings. A total of 143 primary studies are selected, based on predefined exclusion, inclusion, and quality criteria. The research identifies 22 software birthmark techniques frequently used and discussed by researchers and industry. The study also identifies a number of important applications of software birthmarks. These applications define the use of software birthmark in software theft and plagiarism detection, intellectual software asset management, detecting binary theft, malware detection, detecting the theft of natural language, and semantics-based repackaging detection for mobile apps. The results show that despite the large-scale research and development of different birthmark techniques, there is a lack of organized knowledge which is needed to facilitate the usage of software birthmark for critical applications like clone detection and malware detection. Furthermore, it is seen that the area of software birthmark estimation is not well researched which needs to be explored further. The study recommends that the area of software birthmark needs to be explored for developing a reliable and authentic mechanism which can accurately and easily detect software theft and ultimately prevent the piracy of software.",Birthmark estimation | Software birthmark | Software similarity | Systematic literature review,20,3905-3927,Journal,Article,3.0,"Nazir, Shah;Shahzad, Sara;Mukhtar, Neelam",56028678500;24470583800;56028876200,University of Swabi;University of Peshawar,Pakistan;Pakistan,"the concept of software birthmark is developed for the detection of theft and piracy in software applications. the originality of software can be evaluated by comparing software programs on the basis of their birthmarks. a number of birthmark designs have been proposed which are used to specify birthmark for source code and executable code related to particular programming languages. this study presents a systematic literature review on available software birthmark designs and related techniques for comparing birthmarks in order to identify pirated software. this research is focused on identifying different applications of software birthmark, especially the estimation of software birthmark to identify the extent of piracy performed in a software. the objective is to gain insight into complex details of software birthmark by accumulating and analyzing the knowledge provided in the literature in order to facilitate further research in software birthmark and its applications. the study is conducted by following the systematic literature review protocol. the data are collected from primary studies published from 1992 to april 2018 in specified journals and conference/workshop proceedings. a total of 143 primary studies are selected, based on predefined exclusion, inclusion, and quality criteria. the research identifies 22 software birthmark techniques frequently used and discussed by researchers and industry. the study also identifies a number of important applications of software birthmarks. these applications define the use of software birthmark in software theft and plagiarism detection, intellectual software asset management, detecting binary theft, malware detection, detecting the theft of natural language, and semantics-based repackaging detection for mobile apps. the results show that despite the large-scale research and development of different birthmark techniques, there is a lack of organized knowledge which is needed to facilitate the usage of software birthmark for critical applications like clone detection and malware detection. furthermore, it is seen that the area of software birthmark estimation is not well researched which needs to be explored further. the study recommends that the area of software birthmark needs to be explored for developing a reliable and authentic mechanism which can accurately and easily detect software theft and ultimately prevent the piracy of software.",software birthmark design and estimation: a systematic literature review
773,2-s2.0-85063804495,10.1109/EMPDP.2019.8671614,Distributed Software Dependency Management Using Blockchain,D'mello G.,"Proceedings - 27th Euromicro International Conference on Parallel, Distributed and Network-Based Processing, PDP 2019",2019-03-19,"Contemporary software deployments rely on cloud-based package managers for installation, where existing packages are installed on demand from remote code repositories. Usually frameworks or common utilities, packages increase the code reusability within the ecosystem, whilst keeping the code base small. However, disruptions in the package management services can potentially affect development and deployment workflows. Furthermore, cloud package managers have arguably an ambiguous ownership model and offer limited visibility of packages to the users. This work describes the development of a blockchain-based package control system which is decentralised, reliable, and transparent. Blockchain nodes are installed within the distributed infrastructure to provide immutability, and then a dependency graph is constructed with the help of smart contracts to trace the software provenance. Our system has been successfully tested with 4338 packages from NPM, 950 out of which are the top depended-upon packages.",Blockchain | Cloud Computing | Smart Contracts | Software packaging | Software Reuse,7,132-139,Conference Proceeding,Conference Paper,2.0,"D'mello, Gavin;González-Vélez, Horacio",57208132772;57221636692,National College of Ireland,Ireland,"contemporary software deployments rely on cloud-based package managers for installation, where existing packages are installed on demand from remote code repositories. usually frameworks or common utilities, packages increase the code reusability within the ecosystem, whilst keeping the code base small. however, disruptions in the package management services can potentially affect development and deployment workflows. furthermore, cloud package managers have arguably an ambiguous ownership model and offer limited visibility of packages to the users. this work describes the development of a blockchain-based package control system which is decentralised, reliable, and transparent. blockchain nodes are installed within the distributed infrastructure to provide immutability, and then a dependency graph is constructed with the help of smart contracts to trace the software provenance. our system has been successfully tested with 4338 packages from npm, 950 out of which are the top depended-upon packages.",distributed software dependency management using blockchain
774,2-s2.0-85064140355,10.1109/IBCAST.2019.8667222,Improving test adequacy assessment by novel JavaScript mutation operators,Muzamal M.,"Proceedings of 2019 16th International Bhurban Conference on Applied Sciences and Technology, IBCAST 2019",2019-03-13,"Software testing is an essential process to verify that software meets its specifications and to detect faults. Mutation testing is an effective software testing technique to assess the adequacy of test suite. A lot of research has been done on mutation testing and number of mutation operators are proposed for Java and other programming languages. However, mutation operators for Java Script language are few in number as compared to mutation operators for other programming languages. The focus of our research is on mutation operators. Nowadays, Java Script is regressively used in front end development of web applications. To check the adequacy of test suite of Java Script applications, mutation testing is an appropriate approach. These Java Script mutation operators are used to seed faults in Java Script source programs. Currently available mutation operators cover some of the specific Java Script features as there exists some specific Java Script features that are not yet addressed and require more mutation operators. In this paper, we propose a set of new Java Script mutation operators to address features like variable scope, variable type etc., that are not covered by existing operators. We implemented these mutation operators in a tool called Mutant Tracer.",Java Script | Mutation Operators | Mutation Testing | Software Testing,0,647-652,Conference Proceeding,Conference Paper,2.0,"Muzamal, Muneeb;Nadeem, Aamer",57208215427;21935004800,Capital University of Science &amp; Technology,Pakistan,"software testing is an essential process to verify that software meets its specifications and to detect faults. mutation testing is an effective software testing technique to assess the adequacy of test suite. a lot of research has been done on mutation testing and number of mutation operators are proposed for java and other programming languages. however, mutation operators for java script language are few in number as compared to mutation operators for other programming languages. the focus of our research is on mutation operators. nowadays, java script is regressively used in front end development of web applications. to check the adequacy of test suite of java script applications, mutation testing is an appropriate approach. these java script mutation operators are used to seed faults in java script source programs. currently available mutation operators cover some of the specific java script features as there exists some specific java script features that are not yet addressed and require more mutation operators. in this paper, we propose a set of new java script mutation operators to address features like variable scope, variable type etc., that are not covered by existing operators. we implemented these mutation operators in a tool called mutant tracer.",improving test adequacy assessment by novel javascript mutation operators
776,2-s2.0-85067954200,10.3998/mpub.10019291,Rhetorical code studies: Discovering arguments in and around code,Brock K.,Rhetorical Code Studies: Discovering Arguments in and Around Code,2019-03-04,"Software developers work rhetorically to make meaning through the code they write. In some ways, writing code is like any other form of communication; in others, it proves to be new, exciting, and unique. In Rhetorical Code Studies, Kevin Brock explores how software code serves as meaningful communication through which software developers construct arguments that are made up of logical procedures and express both implicit and explicit claims as to how a given program operates. ?Building on current scholarly work in digital rhetoric, software studies, and technical communication, Brock connects and continues ongoing conversations among rhetoricians, technical communicators, software studies scholars, and programming practitioners to demonstrate how software code and its surrounding discourse are highly rhetorical forms of communication. He considers examples ranging from large, well-known projects like Mozilla Firefox to small-scale programs like the ""FizzBuzz"" test common in many programming job interviews. Undertaking specific examinations of code texts as well as the contexts surrounding their composition, Brock illuminates the variety and depth of rhetorical activity taking place in and around code, from individual differences in style to changes in large-scale organizational and community norms. Rhetorical Code Studies holds significant implications for digital communication, multimodal composition, and the cultural analysis of software and its creation. It will interest academics and students of writing, rhetoric, and software engineering as well as technical communicators and developers of all types of software.",Code studies | Composition | Digital humanities | Professional writing | Programming | Rhetoric | Software development | Software studies | Technical communication | Writing,6,1-213,Book,Book,1.0,"Brock, Kevin",57190947203,University of South Carolina,United States,"software developers work rhetorically to make meaning through the code they write. in some ways, writing code is like any other form of communication; in others, it proves to be new, exciting, and unique. in rhetorical code studies, kevin brock explores how software code serves as meaningful communication through which software developers construct arguments that are made up of logical procedures and express both implicit and explicit claims as to how a given program operates. ?building on current scholarly work in digital rhetoric, software studies, and technical communication, brock connects and continues ongoing conversations among rhetoricians, technical communicators, software studies scholars, and programming practitioners to demonstrate how software code and its surrounding discourse are highly rhetorical forms of communication. he considers examples ranging from large, well-known projects like mozilla firefox to small-scale programs like the ""fizzbuzz"" test common in many programming job interviews. undertaking specific examinations of code texts as well as the contexts surrounding their composition, brock illuminates the variety and depth of rhetorical activity taking place in and around code, from individual differences in style to changes in large-scale organizational and community norms. rhetorical code studies holds significant implications for digital communication, multimodal composition, and the cultural analysis of software and its creation. it will interest academics and students of writing, rhetoric, and software engineering as well as technical communicators and developers of all types of software.",rhetorical code studies: discovering arguments in and around code
779,2-s2.0-85073170999,10.1109/ICAIIT.2019.8834522,Design and development meeting schedule management application using the rad method,Subhiyakto E.R.,"Proceeding - 2019 International Conference of Artificial Intelligence and Information Technology, ICAIIT 2019",2019-03-01,"Scheduling meetings in an agency of government agencies are important. The problem that has existed so far is that recording a meeting schedule that still uses books and is prone to loss is one cause. Schedules that clash between parts or areas with limited space are also the cause. In this paper propose the development of a meeting scheduling system that can help overcome these problems. The main objectives of this work are twofold: 1) to assist in meeting scheduling, and 2) to minimize the risk of document loss. System development method used is the Rapid Application Development method, it chose which because it adapts from the waterfall model. An advantage of RAD is that it emphasizes a short software development cycle, uses a component-based construction approach and creates full functionality in 60-90 days. System analysis uses UML such as use case diagrams and activity diagrams. In this paper, an architectural design process and interface design are also carried out. We do implementation using the PHP, HTML 5, and JavaScript as a programming language with the MYSQL database. Based on the results of black box testing that has been done, it can be concluded that all functions can run well and as expected.",Management | Meeting | RAD | Schedule | UML,1,60-64,Conference Proceeding,Conference Paper,2.0,"Subhiyakto, Egia Rosi;Astuti, Yani Parti",57201450746;57193852102,Universitas Dian Nuswantoro,Indonesia,"scheduling meetings in an agency of government agencies are important. the problem that has existed so far is that recording a meeting schedule that still uses books and is prone to loss is one cause. schedules that clash between parts or areas with limited space are also the cause. in this paper propose the development of a meeting scheduling system that can help overcome these problems. the main objectives of this work are twofold: 1) to assist in meeting scheduling, and 2) to minimize the risk of document loss. system development method used is the rapid application development method, it chose which because it adapts from the waterfall model. an advantage of rad is that it emphasizes a short software development cycle, uses a component-based construction approach and creates full functionality in 60-90 days. system analysis uses uml such as use case diagrams and activity diagrams. in this paper, an architectural design process and interface design are also carried out. we do implementation using the php, html 5, and javascript as a programming language with the mysql database. based on the results of black box testing that has been done, it can be concluded that all functions can run well and as expected.",design and development meeting schedule management application using the rad method
780,2-s2.0-85055745204,10.1016/j.infsof.2018.10.009,Slimming javascript applications: An approach for removing unused functions from javascript libraries,Vázquez H.,Information and Software Technology,2019-03-01,"Context: A common practice in JavaScript development is to ship and deploy an application as a large file, called bundle, which is the result of combining the application code along with the code of all the libraries the application depends on. Despite the benefits of having a single bundle per application, this approach leads to applications being shipped with significant portions of code that are actually not used, which unnecessarily inflates the JavaScript bundles and could slow down website loading because of the extra unused code. Although some static analysis techniques exist for removing unused code, our investigations suggest that there is still room for improvements. Objective: The goal of this paper is to address the problem of reducing the size of bundle files in JavaScript applications. Method: In this context, we define the notion of Unused Foreign Function (UFF) to denote a JavaScript function contained in dependent libraries that is not needed at runtime. Furthermore, we propose an approach based on dynamic analysis that assists developers to identify and remove UFFs from JavaScript bundles. Results: We report on a case-study performed over 22 JavaScript applications, showing evidence that our approach can produce size reductions of 26% on average (with reductions going up to 66% in some applications). Conclusion: It is concluded that removing unused foreign functions from JavaScript bundles helps reduce their size, and thus, it can boost the results of existing static analysis techniques.",Javascript | Library dependencies | Performance overhead | Software maintenance | Unused functions,6,18-29,Journal,Article,5.0,"Vázquez, H. C.;Bergel, A.;Vidal, S.;Díaz Pace, J. A.;Marcos, C.",56905291600;23093070700;36142371300;14017872900;15124839500,Comision de Investigaciones Cientificas - La Plata;Universidad de Chile;Universidad Nacional del Centro de la Provincia de Buenos Aires;Consejo Nacional de Investigaciones Científicas y Técnicas,Argentina;Chile;Argentina;Argentina,"context: a common practice in javascript development is to ship and deploy an application as a large file, called bundle, which is the result of combining the application code along with the code of all the libraries the application depends on. despite the benefits of having a single bundle per application, this approach leads to applications being shipped with significant portions of code that are actually not used, which unnecessarily inflates the javascript bundles and could slow down website loading because of the extra unused code. although some static analysis techniques exist for removing unused code, our investigations suggest that there is still room for improvements. objective: the goal of this paper is to address the problem of reducing the size of bundle files in javascript applications. method: in this context, we define the notion of unused foreign function (uff) to denote a javascript function contained in dependent libraries that is not needed at runtime. furthermore, we propose an approach based on dynamic analysis that assists developers to identify and remove uffs from javascript bundles. results: we report on a case-study performed over 22 javascript applications, showing evidence that our approach can produce size reductions of 26% on average (with reductions going up to 66% in some applications). conclusion: it is concluded that removing unused foreign functions from javascript bundles helps reduce their size, and thus, it can boost the results of existing static analysis techniques.",slimming javascript applications: an approach for removing unused functions from javascript libraries
781,2-s2.0-85063431737,10.1109/EIConRus.2019.8656902,Features of the geological logging software design,Belyaev S.,"Proceedings of the 2019 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering, ElConRus 2019",2019-02-28,"Creation of universal small Geological Logging software for field geological documentation requires solution of a number of tasks from the developer. They include improving of user convenience when working with the application, as well as development of special functions, which provide automatic control of input data while maintaining the versatility of the proposed solution. The proposed solution gives the opportunity to write code in Java and JavaScript simultaneously, when functions from one language call functions from another, and vice versa. The paper pays special attention to the task of creation reporting documentation in PDF format: the solution is to create documentation in the form of SVG drawings. The paper gives approaches that simplify the development both in terms of working with graphic elements of documentation and in terms of working with text. In addition, author proposes a solution of placing an arbitrary text within a given rectangle problem.",Field journal | Geology | JavaFX | JavaScript | JSON | SVG,0,187-190,Conference Proceeding,Conference Paper,1.0,"Belyaev, Sergey A.",57194239959,Sankt-Peterburgskij Gosudarstvennyj Elektrotehniceskij Universitet,Russian Federation,"creation of universal small geological logging software for field geological documentation requires solution of a number of tasks from the developer. they include improving of user convenience when working with the application, as well as development of special functions, which provide automatic control of input data while maintaining the versatility of the proposed solution. the proposed solution gives the opportunity to write code in java and javascript simultaneously, when functions from one language call functions from another, and vice versa. the paper pays special attention to the task of creation reporting documentation in pdf format: the solution is to create documentation in the form of svg drawings. the paper gives approaches that simplify the development both in terms of working with graphic elements of documentation and in terms of working with text. in addition, author proposes a solution of placing an arbitrary text within a given rectangle problem.",features of the geological logging software design
783,2-s2.0-85064396091,10.1145/3287324.3287482,MYr: A web-based platform for teaching coding using VR,Berns C.,SIGCSE 2019 - Proceedings of the 50th ACM Technical Symposium on Computer Science Education,2019-02-22,"MYR is a browser-based, educational platform built to spark student interest in computer science by allowing users to write code that generates three-dimensional, animated scenes in virtual reality. The interface consists of two primary components: (1) an integrated editor, which leverages the MYR API and the A-Frame entity-component-system, and (2) a real-time renderer that displays the corresponding scene. The scenes, which vary in complexity, are viewable using virtual reality headsets, smartphones, and any device that supports a web browser. By providing access to the specific domain of virtual reality to students, the system aims to make computer science concepts tangible for novice programmers. The MYR development team conducted pilot tests with middle school students in order to collect feedback from this audience. The larger goal of the project is to develop MYR as a research tool to gain insight into computing students' success, motivation, and confidence in learning computing. The technical implementation, the results of the pilot tests, and the larger vision for future work are discussed in this paper.",Classroom | Educational tools | Research tools | Software | Virtual reality | Web-based tools | WebVR,11,77-83,Conference Proceeding,Conference Paper,5.0,"Berns, Christopher;Chin, Grace;Savitz, Joel;Kiesling, Jason;Martin, Fred",57755162600;57208298759;57208306203;57208305507;7403516282,University of Massachusetts Lowell,United States,"myr is a browser-based, educational platform built to spark student interest in computer science by allowing users to write code that generates three-dimensional, animated scenes in virtual reality. the interface consists of two primary components: (1) an integrated editor, which leverages the myr api and the a-frame entity-component-system, and (2) a real-time renderer that displays the corresponding scene. the scenes, which vary in complexity, are viewable using virtual reality headsets, smartphones, and any device that supports a web browser. by providing access to the specific domain of virtual reality to students, the system aims to make computer science concepts tangible for novice programmers. the myr development team conducted pilot tests with middle school students in order to collect feedback from this audience. the larger goal of the project is to develop myr as a research tool to gain insight into computing students' success, motivation, and confidence in learning computing. the technical implementation, the results of the pilot tests, and the larger vision for future work are discussed in this paper.",myr: a web-based platform for teaching coding using vr
784,2-s2.0-85063333393,10.1109/PADSW.2018.8644622,JSNVM: Supporting Data Persistence in JavaScript Using Non-Volatile Memory,Xu H.,Proceedings of the International Conference on Parallel and Distributed Systems - ICPADS,2019-02-19,"Data persistence refers to an characteristic that data needs to outlive its creator. In recent years, NVM (Non-volatile Memory), a new type of computer memory supporting memory-like byte-addressable access and disk-like persistence, became a promising technique for facilitating data persistence in memory and its management. So far NVM has been supported in many programming languages such as C, C++, and Java. Meanwhile, it has not yet been well supported in JavaScript, a popular scripting language for software development. This paper presents JSNVM, an extension to JavaScript's runtime and execution engine, to support data persistence in JavaScript using NVM. JSNVM consists of (1) a JavaScript persistent object pool that serves as a persistent heap in which persistent objects are created and managed. This pool is also enhanced for guaranteeing data safety and consistency; and (2) a set of JavaScript persistent APIs that provide programmers with a support in creating, managing, and accessing persistent data in an easy-to-use and safe manner. We have implemented JSNVM and evaluated it against two database-supported data persistence styles (i.e., MongoDB's object store and indexedDB's binary store) on micro-benchmarks and real-world applications. The evaluation results show that compared with MongoDB's object store, JSNVM can achieve a 1.6× speedup; when applied to access binary data, JSNVM can achieve a 24.6× speedup over indexedDB's binary store, denoting that JSNVM can enhance performance of JavaScript applications in practice. JSNVM is planned to be publicly available by the end of 2018.",data persistence | JavaScript | Non-volatile memory,2,457-464,Conference Proceeding,Conference Paper,6.0,"Xu, Hao;Zhu, Yanmin;Chen, Yuting;Hunag, Linpeng;Li, Tianyou;Deng, Pan",57198605934;57113812700;8929240400;57207946729;57202023305;57205119025,Intel Corporation;Shanghai Jiao Tong University,United States;China,"data persistence refers to an characteristic that data needs to outlive its creator. in recent years, nvm (non-volatile memory), a new type of computer memory supporting memory-like byte-addressable access and disk-like persistence, became a promising technique for facilitating data persistence in memory and its management. so far nvm has been supported in many programming languages such as c, c++, and java. meanwhile, it has not yet been well supported in javascript, a popular scripting language for software development. this paper presents jsnvm, an extension to javascript's runtime and execution engine, to support data persistence in javascript using nvm. jsnvm consists of (1) a javascript persistent object pool that serves as a persistent heap in which persistent objects are created and managed. this pool is also enhanced for guaranteeing data safety and consistency; and (2) a set of javascript persistent apis that provide programmers with a support in creating, managing, and accessing persistent data in an easy-to-use and safe manner. we have implemented jsnvm and evaluated it against two database-supported data persistence styles (i.e., mongodb's object store and indexeddb's binary store) on micro-benchmarks and real-world applications. the evaluation results show that compared with mongodb's object store, jsnvm can achieve a 1.6× speedup; when applied to access binary data, jsnvm can achieve a 24.6× speedup over indexeddb's binary store, denoting that jsnvm can enhance performance of javascript applications in practice. jsnvm is planned to be publicly available by the end of 2018.",jsnvm: supporting data persistence in javascript using non-volatile memory
785,2-s2.0-85062719887,10.1109/SBGAMES.2018.00014,AsKME: A Feature-Based Approach to Develop Multiplatform Quiz Games,Sarinho V.T.,"Brazilian Symposium on Games and Digital Entertainment, SBGAMES",2019-02-06,"Several approaches have been proposed to manage the game domain variability in different instances and strategies. However, the idea of an one-size-fits-all game architecture can be misleading, being necessary to built reference game architectures for target (sub)domains. This paper presents the Assessment of Knownledge Multiplatform Environment (AsKME), a feature-based approach to develop multiplatform quiz games. It provides a subdomain game architecture, based on identified features of the quiz game dimension, in a Model-ViewController strategy implemented by feature artifacts adapted to be executed in distinct software platforms. As a result, a reusable approach to develop multiplatform quiz games was provided, together with the development of educational and casual quiz games for validation purposes.",Feature modeling | Game domain variability | Multiplatform game environment | Quiz games,1,38-47,Conference Proceeding,Conference Paper,3.0,"Sarinho, Victor T.;De Azevedo, Gabriel S.;Boaventura, Filipe M.B.",6504030916;57207686710;57195248013,Universidade Estadual de Feira de Santana,Brazil,"several approaches have been proposed to manage the game domain variability in different instances and strategies. however, the idea of an one-size-fits-all game architecture can be misleading, being necessary to built reference game architectures for target (sub)domains. this paper presents the assessment of knownledge multiplatform environment (askme), a feature-based approach to develop multiplatform quiz games. it provides a subdomain game architecture, based on identified features of the quiz game dimension, in a model-viewcontroller strategy implemented by feature artifacts adapted to be executed in distinct software platforms. as a result, a reusable approach to develop multiplatform quiz games was provided, together with the development of educational and casual quiz games for validation purposes.",askme: a feature-based approach to develop multiplatform quiz games
788,2-s2.0-85084281430,10.1109/TLA.2019.9082243,Low-Cost Image and Video Processing Using High-Performance Middleware in Single-board Computers with Open Internet Standards,Perez C.A.,IEEE Latin America Transactions,2019-02-01,"Image processing is becoming ubiquitous in many activities. This kind of systems use industry-standard libraries, such as OpenCV, and GPGPU techniques such as CUDA and OpenCL. Nowadays, these are being ported to many computing platforms, offering significant processing power even in devices with limited resources. However, the only model that is truly ubiquitous, is the web itself. Modern browsers feature quite complex internals and offer sophisticated development and profiling tools, in order to offer the best user experience. Introduction of HTML5 allows Realtime video and image manipulation, in browser space, without any plugin. In addition, Wasm (web assembly) Javascript execution engine provides fastest possible performance by means of highly customized compiler and runtime, in almost any browser, including embedded ones. This paper presents an image processing system, architected as a modular web application, using only Raspberry PIs with a compact but fast middleware server, that performs all image operations in browser space by means of web assemblies. All components, including database support, can run in a single board, providing image and video processing speeds that match, or surpass, their native compiled C counterparts on the same platform. This solution has a very low cost, that fits with emerging markets, making it ideal for LATAM scenarios.",computer vision | embedded software | image processing | video processing | webRTC,0,311-318,Journal,Article,5.0,"Perez, Carlos Alejandro;Cleva, Mario Sergio;Liska, DIego Orlando;Aquino, Dominga Concepcion;Rodrigues Da Fonseca, Claudio",57216688344;57195634708;57195635890;57195639163;57195634662,Universidad Tecnologica Nacional,Argentina,"image processing is becoming ubiquitous in many activities. this kind of systems use industry-standard libraries, such as opencv, and gpgpu techniques such as cuda and opencl. nowadays, these are being ported to many computing platforms, offering significant processing power even in devices with limited resources. however, the only model that is truly ubiquitous, is the web itself. modern browsers feature quite complex internals and offer sophisticated development and profiling tools, in order to offer the best user experience. introduction of html5 allows realtime video and image manipulation, in browser space, without any plugin. in addition, wasm (web assembly) javascript execution engine provides fastest possible performance by means of highly customized compiler and runtime, in almost any browser, including embedded ones. this paper presents an image processing system, architected as a modular web application, using only raspberry pis with a compact but fast middleware server, that performs all image operations in browser space by means of web assemblies. all components, including database support, can run in a single board, providing image and video processing speeds that match, or surpass, their native compiled c counterparts on the same platform. this solution has a very low cost, that fits with emerging markets, making it ideal for latam scenarios.",low-cost image and video processing using high-performance middleware in single-board computers with open internet standards
789,2-s2.0-85084277741,10.1109/TLA.2019.9082239,Modular system for the monitoring of railway signaling equipment,Dordolo L.,IEEE Latin America Transactions,2019-02-01,"This paper presents a modular system designed to solve some specific problems on the monitoring of railway signaling equipment. The addressed problems arose from the needs presented by Trenes Argentinos, the company which operates almost all passenger rail transport in Argentina. The developed solution is examined, consisting of an embedded system with its hardware and firmware architecture along with server-side software that stores, processes, and displays railway signaling status to authenticated remote users. Obtained results are discussed and specifications compared with equivalent systems to highlight contributions in this field.",Automatic code generation | Finite state machine | Internet of Things | Railway systems | Test Driven Development,2,280-287,Journal,Article,9.0,"Dordolo, Lucas;Germino, Santiago;Ramoscelli, Gustavo;Permingeat, Alejandro;Mancon, Carlos;Francucci, Leandro;Laiuppa, Adrian;Balina, Dario;Lutenberg, Ariel",57216687088;57216687739;6504411275;57216687148;57216687661;57216687412;57216688390;57216687511;14834103000,Universidad Tecnologica Nacional;Universidad Nacional del Sur;Universidad de Buenos Aires;VortexMakes;DETECAP S.A.,Argentina;Argentina;Argentina;Argentina;Argentina,"this paper presents a modular system designed to solve some specific problems on the monitoring of railway signaling equipment. the addressed problems arose from the needs presented by trenes argentinos, the company which operates almost all passenger rail transport in argentina. the developed solution is examined, consisting of an embedded system with its hardware and firmware architecture along with server-side software that stores, processes, and displays railway signaling status to authenticated remote users. obtained results are discussed and specifications compared with equivalent systems to highlight contributions in this field.",modular system for the monitoring of railway signaling equipment
794,2-s2.0-85062619660,10.1109/BigData.2018.8622074,AIL - The design and implementation of an Analysis Information Leak framework,Mokaddem S.,"Proceedings - 2018 IEEE International Conference on Big Data, Big Data 2018",2019-01-22,"Information leaks are now the hard reality of the digital revolution. There is not a single day without a leak of personal identifiable information (PII) showing up on the Internet. CSIRTs and CERTs are actively working on searching for, discovering of, and analysing the plethora of information leaks. Nevertheless this is a dauntingly laborious and tedious task. In order to simplify this process, CIRCL, as a national CERT for the private sector, designed and implemented a modular framework to assist and improve the handling of information leaks. The AIL framework is an open source software which includes a set of collection and analysis modules to automatically find potential leaks of sensitive information. In this paper, the design and the current implementation of the framework is described along with the rationales behind the development strategies and choices. Additionally, future work and research topics are discussed.",analysis | data-mining | incident-response | information-leak | information-security | privacy | tool,1,5049-5057,Conference Proceeding,Conference Paper,3.0,"Mokaddem, Sami;Wagener, Gerard;Dulaunoy, Alexandre",57207573845;25626881000;25626006600,CIRCL- Computer Incident Response Center,United States,"information leaks are now the hard reality of the digital revolution. there is not a single day without a leak of personal identifiable information (pii) showing up on the internet. csirts and certs are actively working on searching for, discovering of, and analysing the plethora of information leaks. nevertheless this is a dauntingly laborious and tedious task. in order to simplify this process, circl, as a national cert for the private sector, designed and implemented a modular framework to assist and improve the handling of information leaks. the ail framework is an open source software which includes a set of collection and analysis modules to automatically find potential leaks of sensitive information. in this paper, the design and the current implementation of the framework is described along with the rationales behind the development strategies and choices. additionally, future work and research topics are discussed.",ail - the design and implementation of an analysis information leak framework
795,2-s2.0-85062085894,10.1109/TALE.2018.8615424,Developing a Language Learning Application OER,Towey D.,"Proceedings of 2018 IEEE International Conference on Teaching, Assessment, and Learning for Engineering, TALE 2018",2019-01-16,"University of Nottingham Ningbo China (UNNC) was the first Sino-foreign higher education institution (SmEI) to be established in Mainland China, and has been host to a number of student-staff project partnerships, including in the successful development of Open Education Resources (OERs). This paper reports on the completion of the first phase of an anticipated 2-year student-staff project to develop a language learning application as an OER. It explains the history and context of UNNC and the project, and discusses some of the software engineering processes completed to date. The work completed so far is described and reflected upon, and the future work and impact discussed.",higher education | open educational resources (OERs) | Sino-foreign higher education | student experience | Students as partners,6,379-386,Conference Proceeding,Conference Paper,7.0,"Towey, Dave;Millan, Albert;Cheng, Wenpeng;Yang, Sen;Yu, Shiying;Zhao, Zhengchun;Zhu, Tingting",8362064600;57206898501;57206894501;57206899482;57206898375;57206904544;57206896681,University of Nottingham Ningbo China;Trinity College Dublin,China;Ireland,"university of nottingham ningbo china (unnc) was the first sino-foreign higher education institution (smei) to be established in mainland china, and has been host to a number of student-staff project partnerships, including in the successful development of open education resources (oers). this paper reports on the completion of the first phase of an anticipated 2-year student-staff project to develop a language learning application as an oer. it explains the history and context of unnc and the project, and discusses some of the software engineering processes completed to date. the work completed so far is described and reflected upon, and the future work and impact discussed.",developing a language learning application oer
796,2-s2.0-85062173736,10.1109/AIVR.2018.00010,Web-based virtual reality development in classroom: From learner's perspectives,Nguyen V.,"Proceedings - 2018 IEEE International Conference on Artificial Intelligence and Virtual Reality, AIVR 2018",2019-01-15,"Virtual Reality (VR) content development tools are in continuous production by both enthusiastic researchers and software development companies. Yet, learners could benefit from participating in this development, not only for learning vital programming skills, but also skills in creativity and collaboration. Web-based VR (WebVR) has emerged as a platform-independent framework that permits individuals (with little to no prior programming experience) to create immersive and interactive VR applications. Yet, the success of WebVR relies on students' technological acceptance, the intersectionality of perceived utility and ease of use. In order to determine the effectiveness of the emerging tool for learners of varied experience levels, this paper presents a case study of 38 students who were tasked with developing WebVR 'dream' houses. Results showed that students were accepting of the technology by not only learning and implementing WebVR in a short time (one month), but were also capable of demonstrating creativity and problem-solving skills with classroom supports (i.e., pre-project presentations, online discussions, exemplary projects, and TA support). Results as well as recommendations, lessons learned, and further research are addressed.",A-frame | Course design | Student creativity | Technology acceptance model | Web-based virtual reality,20,11-18,Conference Proceeding,Conference Paper,3.0,"Nguyen, Vinh T.;Hite, Rebecca;Dang, Tommy",57210589113;57202916995;36615132200,Texas Tech University,United States,"virtual reality (vr) content development tools are in continuous production by both enthusiastic researchers and software development companies. yet, learners could benefit from participating in this development, not only for learning vital programming skills, but also skills in creativity and collaboration. web-based vr (webvr) has emerged as a platform-independent framework that permits individuals (with little to no prior programming experience) to create immersive and interactive vr applications. yet, the success of webvr relies on students' technological acceptance, the intersectionality of perceived utility and ease of use. in order to determine the effectiveness of the emerging tool for learners of varied experience levels, this paper presents a case study of 38 students who were tasked with developing webvr 'dream' houses. results showed that students were accepting of the technology by not only learning and implementing webvr in a short time (one month), but were also capable of demonstrating creativity and problem-solving skills with classroom supports (i.e., pre-project presentations, online discussions, exemplary projects, and ta support). results as well as recommendations, lessons learned, and further research are addressed.",web-based virtual reality development in classroom: from learner's perspectives
798,2-s2.0-85056659886,10.1016/j.knosys.2018.10.019,A recommender system for component-based applications using machine learning techniques,Fernández-García A.J.,Knowledge-Based Systems,2019-01-15,"Software designers are striving to create software that adapts to their users’ requirements. To this end, the development of component-based interfaces that users can compound and customize according to their needs is increasing. However, the success of these applications is highly dependent on the users’ ability to locate the components useful for them, because there are often too many to choose from. We propose an approach to address the problem of suggesting the most suitable components for each user at each moment, by creating a recommender system using intelligent data analysis methods. Once we have gathered the interaction data and built a dataset, we address the problem of transforming an original dataset from a real component-based application to an optimized dataset to apply machine learning algorithms through the application of feature engineering techniques and feature selection methods. Moreover, many aspects, such as contextual information, the use of the application across several devices with many forms of interaction, or the passage of time (components are added or removed over time), are taken into consideration. Once the dataset is optimized, several machine learning algorithms are applied to create recommendation systems. A series of experiments that create recommendation models are conducted applying several machine learning algorithms to the optimized dataset (before and after applying feature selection methods) to determine which recommender model obtains a higher accuracy. Thus, through the deployment of the recommendation system that has better results, the likelihood of success of a component-based application is increased by allowing users to find the most suitable components for them, enhancing their user experience and the application engagement.",Component-based interfaces | Feature engineering | Feature selection | Interaction information acquisition | Machine learning | Recommender systems,29,68-84,Journal,Article,5.0,"Fernández-García, Antonio Jesús;Iribarne, Luis;Corral, Antonio;Criado, Javier;Wang, James Z.",52463646900;55908790400;7004661146;36170340400;7701309571,Universidad de Almería;Pennsylvania State University,Spain;United States,"software designers are striving to create software that adapts to their users’ requirements. to this end, the development of component-based interfaces that users can compound and customize according to their needs is increasing. however, the success of these applications is highly dependent on the users’ ability to locate the components useful for them, because there are often too many to choose from. we propose an approach to address the problem of suggesting the most suitable components for each user at each moment, by creating a recommender system using intelligent data analysis methods. once we have gathered the interaction data and built a dataset, we address the problem of transforming an original dataset from a real component-based application to an optimized dataset to apply machine learning algorithms through the application of feature engineering techniques and feature selection methods. moreover, many aspects, such as contextual information, the use of the application across several devices with many forms of interaction, or the passage of time (components are added or removed over time), are taken into consideration. once the dataset is optimized, several machine learning algorithms are applied to create recommendation systems. a series of experiments that create recommendation models are conducted applying several machine learning algorithms to the optimized dataset (before and after applying feature selection methods) to determine which recommender model obtains a higher accuracy. thus, through the deployment of the recommendation system that has better results, the likelihood of success of a component-based application is increased by allowing users to find the most suitable components for them, enhancing their user experience and the application engagement.",a recommender system for component-based applications using machine learning techniques
801,2-s2.0-85135654514,10.1007/9783662588246,Design and Web Information Development of Systems,Schewe K.D.,Design and Development of Web Information Systems,2019-01-01,"This book describes the research of the authors over more than a decade on an end-to-end methodology for the design and development of Web Information Systems (WIS). It covers syntactics, semantics and pragmatics of WIS, introduces sophisticated concepts for conceptual modelling, provides integrated foundations for all these concepts and integrates them into the co-design method for systematic WIS development. WIS, i.e. data-intensive information systems that are realized in a way that arbitrary users can access them via web browsers, constitute a prominent class of information systems, for which acceptance by its a priori unknown users in varying contexts with respect to the presented content, the ease of functionality provided and the attraction of the layout adds novel challenges for modelling, design and development. This book is structured into four parts. Part I, Web Information Systems - General Aspects, gives a general introduction to WIS describing the challenges for their development, and provides a characterization by six decisive aspects: Intention, usage, content, functionality, context and presentation. Part II, High-Level WIS Design - Strategic Analysis and Usage Modelling with Storyboarding, introduces methods for high-level design of WIS covering strategic aspects and the storyboarding method, which is discussed from syntactic, semantic and pragmatic perspectives. Part III, Conceptual WIS Design - Rigorous Modelling of Web Information Systems and their Layout with Web Interaction Types and Screenography, continues with conceptual design of WIS including layout and playout. This introduces the decisive web interaction types, the screenography method and adaptation aspects. The final Part IV, Rationale of the Co-Design Methodology and Systematic Development of Web Information Systems, describes the co-design method for WIS development and its application for the systematic engineering of systems. The book addresses the research community, and at the same time can be used for education of graduate students and as methodological support for professional WIS developers. For the WIS research community it provides methods for WIS modelling on all levels of abstraction including theoretical foundations and inference mechanisms as well as a sophisticated end-to-end methodology for systematic WIS engineering from requirements elicitation over conceptual modelling to aspects of implementation, layout and playout. For students and professional developers the book can be used as a whole for educational courses on WIS design and development, as well as for more specific courses on conceptual modelling of WIS, WIS foundations and reasoning, co-design and WIS engineering or WIS layout and playout development.",Information systems applications | Interaction design | Model-driven software engineering | Requirements Engineering | Software creation and management | User interface design | Web applications,3,1-590,Book,Book,2.0,"Schewe, Klaus Dieter;Thalheim, Bernhard",7004152293;6701407841,"International Campus, Zhejiang University;Christian-Albrechts-Universität zu Kiel",China;Germany,"this book describes the research of the authors over more than a decade on an end-to-end methodology for the design and development of web information systems (wis). it covers syntactics, semantics and pragmatics of wis, introduces sophisticated concepts for conceptual modelling, provides integrated foundations for all these concepts and integrates them into the co-design method for systematic wis development. wis, i.e. data-intensive information systems that are realized in a way that arbitrary users can access them via web browsers, constitute a prominent class of information systems, for which acceptance by its a priori unknown users in varying contexts with respect to the presented content, the ease of functionality provided and the attraction of the layout adds novel challenges for modelling, design and development. this book is structured into four parts. part i, web information systems - general aspects, gives a general introduction to wis describing the challenges for their development, and provides a characterization by six decisive aspects: intention, usage, content, functionality, context and presentation. part ii, high-level wis design - strategic analysis and usage modelling with storyboarding, introduces methods for high-level design of wis covering strategic aspects and the storyboarding method, which is discussed from syntactic, semantic and pragmatic perspectives. part iii, conceptual wis design - rigorous modelling of web information systems and their layout with web interaction types and screenography, continues with conceptual design of wis including layout and playout. this introduces the decisive web interaction types, the screenography method and adaptation aspects. the final part iv, rationale of the co-design methodology and systematic development of web information systems, describes the co-design method for wis development and its application for the systematic engineering of systems. the book addresses the research community, and at the same time can be used for education of graduate students and as methodological support for professional wis developers. for the wis research community it provides methods for wis modelling on all levels of abstraction including theoretical foundations and inference mechanisms as well as a sophisticated end-to-end methodology for systematic wis engineering from requirements elicitation over conceptual modelling to aspects of implementation, layout and playout. for students and professional developers the book can be used as a whole for educational courses on wis design and development, as well as for more specific courses on conceptual modelling of wis, wis foundations and reasoning, co-design and wis engineering or wis layout and playout development.",design and web information development of systems
802,2-s2.0-85124871888,10.4028/www.scientific.net/JBBBE.41.117,Designing and Testing of the Software Module Evaluation of Visual Acuity for Information System Eye Center,Sidikova M.,"Journal of Biomimetics, Biomaterials and Biomedical Engineering",2019-01-01,The aim of this work was to designing and testing the software module of visual acuity evaluation for the eye center information system. The software module was designed using the integrated development environment Android Studio as completed Android application with the ability to connect to the server.,Android | JAVA | Software Module | Visual Acuity,0,117-127,Journal,Article,5.0,"Sidikova, Michaela;Martinek, Radek;Jaros, Rene;Konecny, Jaromir;Augustynek, Martin",57213195337;36537543900;57195963432;55551045900;35745535200,VSB – Technical University of Ostrava,Czech Republic,the aim of this work was to designing and testing the software module of visual acuity evaluation for the eye center information system. the software module was designed using the integrated development environment android studio as completed android application with the ability to connect to the server.,designing and testing of the software module evaluation of visual acuity for information system eye center
805,2-s2.0-85097386779,10.1109/ACCESS.2019.2930401,Layered software architecture for the development of third-generation video surveillance systems,Martínez Y.V.,IEEE Access,2019-01-01,"Mobile distributed systems of third-generation video surveillance (MDSV) have become a useful tool to provide multiple security services to people. For this type of systems, three key aspects must be carried out: 1) protection, which consists of preventing undesirable events; 2) detection, which refers to determining the exact moment in which the event occurred; and 3) reply, in this regard, actions such as activating alarms and generating warnings are executed. Previous works have proposed software architectures to development video surveillance systems on mobile distributed systems (MDS). However, these architectures focus mainly on providing services/aspects of protection and detection; without considering in its design the requirements that arise from the characteristics of the MDS, such as limited processing and storage capacities of devices, frequent disconnections, among others. In this paper, we introduce a layered software architecture to build MDSV. The proposed architecture considers and satisfies the requirements that arise from the critical aspects of protection, detection, and reply, including the characteristics of the MDS. Based on our architecture, an MDSV prototype was implemented. The tests carried out on the prototype show that the proposed architecture correctly provides users with various essential services in terms of protection, detection, and reply. From our point of view, the most important advantages of our proposed software architecture are the following: define the basic technical guidelines that an MDSV must have and accomplish; streamline overall development, providing a solid framework for developers; and contribute to satisfying the requirements that arise from quality attributes that the MDSV must possess.",Layered software architecture | Mobile distributed systems | Third generation video surveillance,2,98507-98521,Journal,Article,6.0,"Martínez, Yair Viveros;Domínguez, Eduardo López;Velázquez, Yesenia Hernández;Isidro, Saúl Domínguez;Medina Nieto, María Auxilio;De La Calleja, Jorge",57220576044;26664814900;57204570475;48161102800;57188962918;56002753400,Universidad Politécnica de Puebla;National Laboratory of Advanced Informatics,Mexico;Mexico,"mobile distributed systems of third-generation video surveillance (mdsv) have become a useful tool to provide multiple security services to people. for this type of systems, three key aspects must be carried out: 1) protection, which consists of preventing undesirable events; 2) detection, which refers to determining the exact moment in which the event occurred; and 3) reply, in this regard, actions such as activating alarms and generating warnings are executed. previous works have proposed software architectures to development video surveillance systems on mobile distributed systems (mds). however, these architectures focus mainly on providing services/aspects of protection and detection; without considering in its design the requirements that arise from the characteristics of the mds, such as limited processing and storage capacities of devices, frequent disconnections, among others. in this paper, we introduce a layered software architecture to build mdsv. the proposed architecture considers and satisfies the requirements that arise from the critical aspects of protection, detection, and reply, including the characteristics of the mds. based on our architecture, an mdsv prototype was implemented. the tests carried out on the prototype show that the proposed architecture correctly provides users with various essential services in terms of protection, detection, and reply. from our point of view, the most important advantages of our proposed software architecture are the following: define the basic technical guidelines that an mdsv must have and accomplish; streamline overall development, providing a solid framework for developers; and contribute to satisfying the requirements that arise from quality attributes that the mdsv must possess.",layered software architecture for the development of third-generation video surveillance systems
806,2-s2.0-85091703569,10.3280/ECAG2019-003015,Web platform for “Smart City” data collection and analytics,Shalamberidze I.,Economia Agro-Alimentare,2019-01-01,"The study aims to highlight that nowadays, finding ways to manage the current processes both in the regions and in cities with big agglomeration is the most important and difficult problem. A fortiori, when it concerns developed regions. While designing urban system development, management, and reconstruction projects, both managers of the cities and urbanists must take into account the opinions of specialists, who have different categories of mindsets and they “talk different languages” (Sociologists, ecologists, businessmen, etc.). Summing up the aforementioned languages in a common denominator is possible only by mathematics and computing tools. Nowadays, the problems of city management are united in the concept of “Smart city”, which is usually referred to as “informational city”. “Smart City” – this is an integration concept, which involves the usage of the so called “integrated imitative model” for systematic, stable, optimal decision making, as the city is a whole dynamic unity. Today’s managers of the cities, urbanists, investors, businessmen, sociologists, etc. have to deal with a huge amount of parameters, opinions and data in a nonsystematic manner. Our proposed study “Unified Web Platform of the Region and Smart Management” includes: website, Google Map, pointing object in the map, saving the objects and their parameters, mathematical and programmatic tools, cloud computing, python computing libraries, Restful api as a web service, etc. As for the web service or restful api, any software can have access to the data of the united web platform of the region through a specially defined protocol. Objects presented in the map have assigned specialized and standardized parameters, which are used by the system algorithm for the analyses and the presentation of all the structural creators of the dynamic processes of the city. This gives us the opportunity to see the whole chain of interactions, which are caused by the actions on any object of the city. Users register on the website and they can see the parameters of the objects that are set in the map. The objects in the databases are classified by their purpose, affiliation, destination and other marks. There is an ability for users to define the status of an object on their own. Users can also add or remove objects on the map and can manipulate with the updated parameters on the map. They can evaluate the chain of results both in the time and dimensional manner. For the built-in mathematical tools and algorithms in the system, we use Algebraic topology methods, Graphs theory non-linear differential equations, the theory of disasters and bifurcation, Chaos theory, methods of mathematical statistics and more. Web platform includes all the mathematical tools and programmatic packages that are necessary for stable development of small and medium-sized business.",City | Management | Platform | Smart | Web,0,847-854,Journal,Article,2.0,"Shalamberidze, Irakli;Akhobadze, Merab",57219209830;55366286200,Georgian Technical University,Georgia,"the study aims to highlight that nowadays, finding ways to manage the current processes both in the regions and in cities with big agglomeration is the most important and difficult problem. a fortiori, when it concerns developed regions. while designing urban system development, management, and reconstruction projects, both managers of the cities and urbanists must take into account the opinions of specialists, who have different categories of mindsets and they “talk different languages” (sociologists, ecologists, businessmen, etc.). summing up the aforementioned languages in a common denominator is possible only by mathematics and computing tools. nowadays, the problems of city management are united in the concept of “smart city”, which is usually referred to as “informational city”. “smart city” – this is an integration concept, which involves the usage of the so called “integrated imitative model” for systematic, stable, optimal decision making, as the city is a whole dynamic unity. today’s managers of the cities, urbanists, investors, businessmen, sociologists, etc. have to deal with a huge amount of parameters, opinions and data in a nonsystematic manner. our proposed study “unified web platform of the region and smart management” includes: website, google map, pointing object in the map, saving the objects and their parameters, mathematical and programmatic tools, cloud computing, python computing libraries, restful api as a web service, etc. as for the web service or restful api, any software can have access to the data of the united web platform of the region through a specially defined protocol. objects presented in the map have assigned specialized and standardized parameters, which are used by the system algorithm for the analyses and the presentation of all the structural creators of the dynamic processes of the city. this gives us the opportunity to see the whole chain of interactions, which are caused by the actions on any object of the city. users register on the website and they can see the parameters of the objects that are set in the map. the objects in the databases are classified by their purpose, affiliation, destination and other marks. there is an ability for users to define the status of an object on their own. users can also add or remove objects on the map and can manipulate with the updated parameters on the map. they can evaluate the chain of results both in the time and dimensional manner. for the built-in mathematical tools and algorithms in the system, we use algebraic topology methods, graphs theory non-linear differential equations, the theory of disasters and bifurcation, chaos theory, methods of mathematical statistics and more. web platform includes all the mathematical tools and programmatic packages that are necessary for stable development of small and medium-sized business.",web platform for “smart city” data collection and analytics
807,2-s2.0-85087444488,10.1007/978-3-319-91908-9_24,"Automated software test generation: Some challenges, solutions, and recent advances",Candea G.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2019-01-01,"The automation of software testing promises to delegate to machines what is otherwise the most labor-intensive and expensive part of software development. The past decade has seen a resurgence in research interest for this problem, bringing about significant progress. In this article, we provide an overview of automated test generation for software, and then discuss recent developments that have had significant impact on real-life software.",Program analysis | Software testing | Symbolic execution,11,505-531,Book Series,Book Chapter,2.0,"Candea, George;Godefroid, Patrice",6507411493;7003921627,Ecole Polytechnique Fédérale de Lausanne;Microsoft Research,Switzerland;United States,"the automation of software testing promises to delegate to machines what is otherwise the most labor-intensive and expensive part of software development. the past decade has seen a resurgence in research interest for this problem, bringing about significant progress. in this article, we provide an overview of automated test generation for software, and then discuss recent developments that have had significant impact on real-life software.","automated software test generation: some challenges, solutions, and recent advances"
810,2-s2.0-85085164884,10.12753/2066-026X-19-047,E-business learning tool for online banking based on BPM (business process management),Rădescu R.,eLearning and Software for Education Conference,2019-01-01,"The purpose of this paper is to develop a learning application for the management of banking processes and related databases, which can be used to model the business processes specific to the educational field in finance and banking (e-banking). The application has a general character and can be used to implement any kind of business process in the online learning environment. As a motivation, the present work was born out of the need to improve the classical way of learning, by calling on the modeling and execution of e-banking specific processes through BPM. Thus, a structure that uses generic data types defining process-specific entities is a solution to improve how e-business processes are developed in order to make learning easier. In this respect, all processes modeled in an e-banking business learning platform have common structural components, while being differently parameterized according to each process. The technical analysis period is thus reduced, providing a permanent overview of existing processes. The structure designed accordingly is tested through a web application that connects to a database. The developed application is therefore a generic business process management learning tool, exemplified for e-banking processes, assumed by a case study: providing a bank credit to a client. The aim of the paper is to develop the most efficient software product for e- banking, thus generating a generic platform for assimilation of any type of process flow. The system architecture modularizes the entire project in four levels to ensure a clearest logical separation. In addition, three software development templates have been used to make the work of the developer easier and to make the learning product as efficient as possible. The business necessity of the present work is customized in the goal of fluidization and dynamism applied in solving any defined process. Thus, in the case study approached, the client applying for a credit goes through the necessary steps in a shorter time, and the cost of analyzing his/her file by the bank is smaller because it automates many portions of the whole process, the involvement of the human factor being importantly reduced. Hence, compared to the conventional version, the corresponding learning process is much simplified and easier to assimilate. The resulting learning application for banking-specific e-business processes is able to manage any type of processes and modify these processes through the developed BPMN interface. The original contributions of the paper are: theoretical and practical design of the e-business learning platform database, developing the web application in ASP.NET along with the related front-end technologies (HTML5, CSS3, and JavaScript, modeling and implementing as a case study the process of learning the flows of a banking process that highlights the concepts defined by the BPM methodology.",Business process management | E-learning business case | Modeling and optimization | On-line banking for E-business | Virtual learning | Web application for educational tools,0,350-357,Conference Proceeding,Conference Paper,2.0,"Rădescu, Radu;Ardelean, Tudor",6508186194;57216892015,University Politehnica of Bucharest,Romania,"the purpose of this paper is to develop a learning application for the management of banking processes and related databases, which can be used to model the business processes specific to the educational field in finance and banking (e-banking). the application has a general character and can be used to implement any kind of business process in the online learning environment. as a motivation, the present work was born out of the need to improve the classical way of learning, by calling on the modeling and execution of e-banking specific processes through bpm. thus, a structure that uses generic data types defining process-specific entities is a solution to improve how e-business processes are developed in order to make learning easier. in this respect, all processes modeled in an e-banking business learning platform have common structural components, while being differently parameterized according to each process. the technical analysis period is thus reduced, providing a permanent overview of existing processes. the structure designed accordingly is tested through a web application that connects to a database. the developed application is therefore a generic business process management learning tool, exemplified for e-banking processes, assumed by a case study: providing a bank credit to a client. the aim of the paper is to develop the most efficient software product for e- banking, thus generating a generic platform for assimilation of any type of process flow. the system architecture modularizes the entire project in four levels to ensure a clearest logical separation. in addition, three software development templates have been used to make the work of the developer easier and to make the learning product as efficient as possible. the business necessity of the present work is customized in the goal of fluidization and dynamism applied in solving any defined process. thus, in the case study approached, the client applying for a credit goes through the necessary steps in a shorter time, and the cost of analyzing his/her file by the bank is smaller because it automates many portions of the whole process, the involvement of the human factor being importantly reduced. hence, compared to the conventional version, the corresponding learning process is much simplified and easier to assimilate. the resulting learning application for banking-specific e-business processes is able to manage any type of processes and modify these processes through the developed bpmn interface. the original contributions of the paper are: theoretical and practical design of the e-business learning platform database, developing the web application in asp.net along with the related front-end technologies (html5, css3, and javascript, modeling and implementing as a case study the process of learning the flows of a banking process that highlights the concepts defined by the bpm methodology.",e-business learning tool for online banking based on bpm (business process management)
814,2-s2.0-85082144436,10.1016/j.promfg.2019.02.123,Software development for cutting tool routing problems,Makarovskikh T.,Procedia Manufacturing,2019-01-01,"Lots of studies on tool paths for cutting machines mainly deal with contour by contour cutting. While constructing a path one needs to determine the pierce point and the direction of contour passing. In this case only the length of idle passes may be optimized. To solve this problem generalized travelling salesman problem (GTSP) approach is used. Resource-efficient technologies for cutting sheet materials allow for the contours of cut-off details to be overlapped. It allows reducing the material waste and shortening the length of cuts. Common cuts are also the origin of one more set of precedence constraints. These constraints can be formalized as one general formal restriction called as Ordered Enclosing (OE) for plane graphs that are the homeomorphic images of the cutting plan. In this report we consider the common case of a cutting problem when combination of contours is allowed. We review the polynomial algorithms for all the possible restrictions: (1) part cut off a sheet does not require further cuts (constructing of OE-route); (2) there are no intersections of cuts (constructing of NOE-route); (3) there are some restrictions on placement of pierce points (constructing of PPOE-cover). Our paper considers software that, according to the cutting plan, allows to get a homeomorphic image of the graph to solve the routing problem, solves this problem and interprets the results of the solution.",Computer aided design | Cutting tool | Routing | Software | Technological constraints,6,567-574,Conference Proceeding,Conference Paper,3.0,"Makarovskikh, Tatiana;Panyukov, Anatoly;Savitsky, Egor",16022945800;56048551600;57191668228,South Ural State University,Russian Federation,"lots of studies on tool paths for cutting machines mainly deal with contour by contour cutting. while constructing a path one needs to determine the pierce point and the direction of contour passing. in this case only the length of idle passes may be optimized. to solve this problem generalized travelling salesman problem (gtsp) approach is used. resource-efficient technologies for cutting sheet materials allow for the contours of cut-off details to be overlapped. it allows reducing the material waste and shortening the length of cuts. common cuts are also the origin of one more set of precedence constraints. these constraints can be formalized as one general formal restriction called as ordered enclosing (oe) for plane graphs that are the homeomorphic images of the cutting plan. in this report we consider the common case of a cutting problem when combination of contours is allowed. we review the polynomial algorithms for all the possible restrictions: (1) part cut off a sheet does not require further cuts (constructing of oe-route); (2) there are no intersections of cuts (constructing of noe-route); (3) there are some restrictions on placement of pierce points (constructing of ppoe-cover). our paper considers software that, according to the cutting plan, allows to get a homeomorphic image of the graph to solve the routing problem, solves this problem and interprets the results of the solution.",software development for cutting tool routing problems
817,2-s2.0-85078562721,10.3138/cart.54.4.2018-0014,Hardware-accelerating 2D web maps: A case study,Farkas G.,Cartographica,2019-01-01,"Recent trends show that developers behind some of the most popular web mapping libraries put excessive work into creating custom hardware-accelerated rendering engines. Other libraries focus on functionality rather than visualization. From the perspective of the developer using these libraries an important question arises: is it necessary to use a WebGL-powered library for 2D web mapping? The answer was found through the implementation and evaluation of a simple WebGL renderer for the open source Web mapping library OpenLayers. It extends the previous, texture-based implementation with line-string, polygon, and label-rendering capabilities. Through various benchmarks, the benefits of using a WebGL rendering engine over the traditional, but nowadays widely supported and – in most cases – hardware-accelerated HTML5 Canvas renderer are assessed. Contrary to the current trends in Web mapping, results suggest that using the Canvas Application Programming Interface (API) is sufficient for smaller Web maps (up to around 2000 features and 60,000 vertices) using static vector data. WebGL only gives a noticeable performance boost with maps using large vector layers, such as Web GIS clients.",Cartography | Data visualization | GIS | Software development | Web development | Web GIS,1,245-260,Journal,Article,1.0,"Farkas, Gábor",57203507677,Pécsi Tudományegyetem,Hungary,"recent trends show that developers behind some of the most popular web mapping libraries put excessive work into creating custom hardware-accelerated rendering engines. other libraries focus on functionality rather than visualization. from the perspective of the developer using these libraries an important question arises: is it necessary to use a webgl-powered library for 2d web mapping? the answer was found through the implementation and evaluation of a simple webgl renderer for the open source web mapping library openlayers. it extends the previous, texture-based implementation with line-string, polygon, and label-rendering capabilities. through various benchmarks, the benefits of using a webgl rendering engine over the traditional, but nowadays widely supported and – in most cases – hardware-accelerated html5 canvas renderer are assessed. contrary to the current trends in web mapping, results suggest that using the canvas application programming interface (api) is sufficient for smaller web maps (up to around 2000 features and 60,000 vertices) using static vector data. webgl only gives a noticeable performance boost with maps using large vector layers, such as web gis clients.",hardware-accelerating 2d web maps: a case study
818,2-s2.0-85078284936,10.15829/1560-4071-2019-12-104-108,Methodology in cardiologists’ postgraduate education,Arzhanik M.B.,Russian Journal of Cardiology,2019-01-01,"Aim. To develop the methodological ware for distance cardiologists’ postgraduate education by virtual patients’ simulations. The article describes the first stage of the project to create a database of virtual patients. It includes the integration of text and multimedia clinical and diagnostic information about patients and software for its presentation. A virtual patient is considered as an informational model of the diagnostic and treatment processes. Material and methods. To create a database of virtual patients, a description of completed clinical cases in specially designed patterns was used. To provide distance access to information about virtual patients, the JavaScript was used. Results. When forming the database of virtual patients, two categories of case histories were used — the most common cases and rare disease variants. From archival case histories and examination data, information has been selected that plays a significant role in the diagnosis and treatment. It was decided to present the information in the form of separate portions-visits. Each visit includes the results of tests and specialty consultations necessary to make a decision on further treatment. In the template developed by doctors and analysts, patient information is broken down into blocks that included complaints; anamnesis; physical examination; provisional diagnosis; diagnostic and treatment plan; tests’ results; administrations; final diagnosis; clinical report. These blocks served as the basis for the development of relational database tables. To visualize information about the virtual patient, prototypes of screen forms were implemented. Information about different visits was placed on different marks, and the user is able to see previously available information. Conclusion. After testing, this software will be used in education to demonstrate complete clinical cases to students. In addition, by each virtual case, tasks that require students to make medical decisions can be formed. The technology of virtual patients can be used both for postgraduates (doctors) and medical students.",Continuing medical education | Diagnostic and treatment process | Distance education | Information technology | Virtual patient,3,104-108,Journal,Article,6.0,"Arzhanik, M. B.;Karas, S. I.;Grakova, E. V.;Vasiltseva, O. Ya;Korneeva, T. B.;Kara-Sal, E. E.",57210411305;57214133882;6507402333;55840570100;57214110662;57214111490,"Cardiology Research lnstitute, Tomsk National Research Medical Center, Russian Academy of Sciences;Siberian State Medical University;OOO Kontek-Soft",Russian Federation;Russian Federation;Russian Federation,"aim. to develop the methodological ware for distance cardiologists’ postgraduate education by virtual patients’ simulations. the article describes the first stage of the project to create a database of virtual patients. it includes the integration of text and multimedia clinical and diagnostic information about patients and software for its presentation. a virtual patient is considered as an informational model of the diagnostic and treatment processes. material and methods. to create a database of virtual patients, a description of completed clinical cases in specially designed patterns was used. to provide distance access to information about virtual patients, the javascript was used. results. when forming the database of virtual patients, two categories of case histories were used — the most common cases and rare disease variants. from archival case histories and examination data, information has been selected that plays a significant role in the diagnosis and treatment. it was decided to present the information in the form of separate portions-visits. each visit includes the results of tests and specialty consultations necessary to make a decision on further treatment. in the template developed by doctors and analysts, patient information is broken down into blocks that included complaints; anamnesis; physical examination; provisional diagnosis; diagnostic and treatment plan; tests’ results; administrations; final diagnosis; clinical report. these blocks served as the basis for the development of relational database tables. to visualize information about the virtual patient, prototypes of screen forms were implemented. information about different visits was placed on different marks, and the user is able to see previously available information. conclusion. after testing, this software will be used in education to demonstrate complete clinical cases to students. in addition, by each virtual case, tasks that require students to make medical decisions can be formed. the technology of virtual patients can be used both for postgraduates (doctors) and medical students.",methodology in cardiologists’ postgraduate education
819,2-s2.0-85077968825,10.1109/ACCESS.2019.2961144,A dynamic taint analysis framework based on entity equipment,Ren Y.,IEEE Access,2019-01-01,"With the development of the Internet of Things, the security of embedded device has received extensive attention. Taint analysis technology can improve the understanding of the firmware program operating mechanism and improve the effectiveness of security analysis. It is an important method in security analysis. Traditional taint analysis of embedded device firmware requires complex pre-preparation work, setting up a virtual operating environment. Those security analysts have to invest a lot of time and effort in this work, and the results are usually unsatisfactory. In this paper, we propose a dynamic taint analysis method based on entity equipment. The core idea of our approach is to divide the taint analysis into two parts: the simulation analysis on the host and the real execution on the entity equipment. Since one of the features of our method is based on entity equipment, there is no need to build a dedicated virtual environment. Another feature is that the tested firmware program runs on entity equipment and can ensure the accuracy of the analysis by comparing the results of the taint analysis with the device firmware run-time information. We implement a prototype system and verified the effectiveness of the method, which can perform taint analysis on multiple architecture embedded firmware programs and detect vulnerabilities such as stack overflow, heap overflow and so on. Finally, we verify our prototype with a test case to effectively detect vulnerabilities in the firmware program. And we evaluate the performance of the prototype, compared with PANDA, the time overhead of our prototype is reduced by 5.9%.",cross-debugging | dynamic taint analysis | Embedded firmware,5,186308-186318,Journal,Article,4.0,"Ren, Yuzhu;Dong, Weiyu;Lin, Jian;Miao, Xinliang",57213689682;57209410993;57193428284;57225733551,State Key Laboratory of Mathematical Engineering and Advanced Computing,China,"with the development of the internet of things, the security of embedded device has received extensive attention. taint analysis technology can improve the understanding of the firmware program operating mechanism and improve the effectiveness of security analysis. it is an important method in security analysis. traditional taint analysis of embedded device firmware requires complex pre-preparation work, setting up a virtual operating environment. those security analysts have to invest a lot of time and effort in this work, and the results are usually unsatisfactory. in this paper, we propose a dynamic taint analysis method based on entity equipment. the core idea of our approach is to divide the taint analysis into two parts: the simulation analysis on the host and the real execution on the entity equipment. since one of the features of our method is based on entity equipment, there is no need to build a dedicated virtual environment. another feature is that the tested firmware program runs on entity equipment and can ensure the accuracy of the analysis by comparing the results of the taint analysis with the device firmware run-time information. we implement a prototype system and verified the effectiveness of the method, which can perform taint analysis on multiple architecture embedded firmware programs and detect vulnerabilities such as stack overflow, heap overflow and so on. finally, we verify our prototype with a test case to effectively detect vulnerabilities in the firmware program. and we evaluate the performance of the prototype, compared with panda, the time overhead of our prototype is reduced by 5.9%.",a dynamic taint analysis framework based on entity equipment
820,2-s2.0-85077881854,10.24411/2500-0101-2019-14210,A regression testing with semi-automatic test selection for auditing of ims database,Ruchay A.,Chelyabinsk Physical and Mathematical Journal,2019-01-01,"This work aims to develop a regression testing framework with a semi-automatic test selection. As opposed to previous works it offers a manual combined approach to the development of regression testing with a semi-automatic test selection with according to various important factors such as the execution time, the required number of the test executions, the manual priority of the tests, a result of the previous tests, functionalities of the tests. It allows a more detailed manual configuration of the regression test sequence.",Data driven testing | Debugging | IMS database | Keyword driven testing | Regression testing | Software testing | Test selection,0,241-249,Journal,Article,1.0,"Ruchay, A. N.",57192592568,Chelyabinsk State University,Russian Federation,"this work aims to develop a regression testing framework with a semi-automatic test selection. as opposed to previous works it offers a manual combined approach to the development of regression testing with a semi-automatic test selection with according to various important factors such as the execution time, the required number of the test executions, the manual priority of the tests, a result of the previous tests, functionalities of the tests. it allows a more detailed manual configuration of the regression test sequence.",a regression testing with semi-automatic test selection for auditing of ims database
821,2-s2.0-85077437654,10.24507/icicel.13.12.1157,Spreadsheet and comma-separated values (CSV) based domain-specific programming language for web application development,Noprianto,ICIC Express Letters,2019-01-01,"From programming language point of view, when developing web applications, programmers may use domain-specific programming languages or general-purpose ones. Depending on the experiences and languages, developing a web application could be a simple or complex task. It is complex because the programmer should use more than one languages (HTML, CSS, Javascript, language at the server side, and others). To reduce the number of languages, programmers may use domain-specific languages. The more specific the language, the simpler the development could be. However, some researches show that language specificity itself could be another challenge. Therefore, to make web application development simpler and at the same time make the domain-specific language useful, more research is needed. We propose the usage of spreadsheet – software packages that have been around for about four decades. We emphasize simple modeling technique, combined with column/row based syntax, saved as comma-separated values (CSV) file format, which can be interpreted as a fully functional web application. Experiments prove this method is usable and results in simpler web application development with significantly less development time (43%) and lines of code (30%) compared with standard web technologies.",Blog | Comma-separated values | Domain-specific programming language | Spreadsheet | Web application,0,1157-1167,Journal,Article,4.0,"Noprianto, ;Soewito, Benfano;Gaol, Ford Lumban;Abbas, Bahtiar Saleh",57194047773;24473788700;24536664300;55835973000,Bina Nusantara University,Indonesia,"from programming language point of view, when developing web applications, programmers may use domain-specific programming languages or general-purpose ones. depending on the experiences and languages, developing a web application could be a simple or complex task. it is complex because the programmer should use more than one languages (html, css, javascript, language at the server side, and others). to reduce the number of languages, programmers may use domain-specific languages. the more specific the language, the simpler the development could be. however, some researches show that language specificity itself could be another challenge. therefore, to make web application development simpler and at the same time make the domain-specific language useful, more research is needed. we propose the usage of spreadsheet – software packages that have been around for about four decades. we emphasize simple modeling technique, combined with column/row based syntax, saved as comma-separated values (csv) file format, which can be interpreted as a fully functional web application. experiments prove this method is usable and results in simpler web application development with significantly less development time (43%) and lines of code (30%) compared with standard web technologies.",spreadsheet and comma-separated values (csv) based domain-specific programming language for web application development
822,2-s2.0-85076990318,10.1007/978-3-030-34644-7_14,A Feature-Based Approach to Develop Digital Board Games,Boaventura F.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2019-01-01,"Several types of development strategies are available to provide digital games in a reusable way. However, the idea of a “one-size-fits-all” architecture for digital games can be problematic, being preferable to build dedicated architectures for specific game genres. This paper proposes the development of feature-based artifacts for the production of digital board games. It presents a subdomain game architecture that represents configurable features of core concepts related to board games (the game model and controller), and implements feature artifacts capable of being executed in distinct game clients (the game view). For validation purposes, two types of classic board games, together with a proposed web client for board games, were developed, consolidating as a result a software product line approach to develop classic board games.",Board games | Feature modeling | Software product line,0,175-186,Book Series,Conference Paper,2.0,"Boaventura, Filipe M.B.;Sarinho, Victor T.",57195248013;6504030916,Universidade Estadual de Feira de Santana,Brazil,"several types of development strategies are available to provide digital games in a reusable way. however, the idea of a “one-size-fits-all” architecture for digital games can be problematic, being preferable to build dedicated architectures for specific game genres. this paper proposes the development of feature-based artifacts for the production of digital board games. it presents a subdomain game architecture that represents configurable features of core concepts related to board games (the game model and controller), and implements feature artifacts capable of being executed in distinct game clients (the game view). for validation purposes, two types of classic board games, together with a proposed web client for board games, were developed, consolidating as a result a software product line approach to develop classic board games.",a feature-based approach to develop digital board games
823,2-s2.0-85076848047,10.1007/978-3-030-30275-7_7,Extending interaction flow modeling language (Ifml) for android user interface components,Fatima I.,Communications in Computer and Information Science,2019-01-01,Interaction Flow Modeling Language (IFML) is an Object Management Group (OMG) standard for depicting front end behavior of software applications. It provides a platform independent description of graphical user interfaces for web as well as mobile applications. Mobile development has emerged as a vast area of research in the last decade. IFML meta-model caters for many generic user interface (UI) components but several characteristics of mobile application interface are found missing. This paper investigates the user interface characteristics of native android application user interface that are absent in the IFML meta-model. We then propose an extension of the identified characteristics using IFML to supplement usability in Android applications. This extended meta-model can be further used to generate Android platform specific code for user interfaces via model to code transformation.,Android | IFML | Model-based | UI,3,76-89,Book Series,Conference Paper,5.0,"Fatima, Iffat;Anwar, Muhammad Waseem;Azam, Farooque;Maqbool, Bilal;Tufail, Hanny",57212487768;56677318200;9639414800;57202075233;57201990237,College of Electrical &amp; Mechanical Engineering,Pakistan,interaction flow modeling language (ifml) is an object management group (omg) standard for depicting front end behavior of software applications. it provides a platform independent description of graphical user interfaces for web as well as mobile applications. mobile development has emerged as a vast area of research in the last decade. ifml meta-model caters for many generic user interface (ui) components but several characteristics of mobile application interface are found missing. this paper investigates the user interface characteristics of native android application user interface that are absent in the ifml meta-model. we then propose an extension of the identified characteristics using ifml to supplement usability in android applications. this extended meta-model can be further used to generate android platform specific code for user interfaces via model to code transformation.,extending interaction flow modeling language (ifml) for android user interface components
824,2-s2.0-85076680362,10.1007/978-3-030-34339-2_7,JSLess: A Tale of a Fileless Javascript Memory-Resident Malware,Saad S.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2019-01-01,"New computing paradigms, modern feature-rich programming languages and off-the-shelf software libraries enabled the development of new sophisticated malware families. Evidence of this phenomena is the recent growth of fileless malware attacks. Fileless malware or memory resident malware is an example of an Advanced Volatile Threat (AVT). In a fileless malware attack, the malware writes itself directly onto the main memory (RAM) of the compromised device without leaving any trace on the compromised device’s file system. For this reason, fileless malware presents a difficult challenge for traditional malware detection tools and in particular signature-based detection. Moreover, fileless malware forensics and reverse engineering are nearly impossible using traditional methods. The majority of fileless malware attacks in the wild take advantage of MS PowerShell, however, fileless malware are not limited to MS PowerShell. In this paper, we designed and implemented a fileless malware by taking advantage of new features in Javascript and HTML5. The proposed fileless malware could infect any device that supports Javascript and HTML5. It serves as a proof-of-concept (PoC) to demonstrate the threats of fileless malware in web applications. We used the proposed fileless malware to evaluate existing methods and techniques for malware detection in web applications. We tested the proposed fileless malware with several free and commercial malware detection tools that apply both static and dynamic analysis. The proposed fileless malware bypassed all the anti-malware detection tools included in our study. In our analysis, we discussed the limitations of existing approaches/tools and suggested possible detection and mitigation techniques.",Fileless malware | HTML5 | Javascript | Polymorphic malware | Unconventional malware | Web vulnerabilities,3,113-131,Book Series,Conference Paper,4.0,"Saad, Sherif;Mahmood, Farhan;Briguglio, William;Elmiligi, Haytham",36633013600;57212458927;57208407431;23481585100,Thompson Rivers University;University of Windsor,Canada;Canada,"new computing paradigms, modern feature-rich programming languages and off-the-shelf software libraries enabled the development of new sophisticated malware families. evidence of this phenomena is the recent growth of fileless malware attacks. fileless malware or memory resident malware is an example of an advanced volatile threat (avt). in a fileless malware attack, the malware writes itself directly onto the main memory (ram) of the compromised device without leaving any trace on the compromised device’s file system. for this reason, fileless malware presents a difficult challenge for traditional malware detection tools and in particular signature-based detection. moreover, fileless malware forensics and reverse engineering are nearly impossible using traditional methods. the majority of fileless malware attacks in the wild take advantage of ms powershell, however, fileless malware are not limited to ms powershell. in this paper, we designed and implemented a fileless malware by taking advantage of new features in javascript and html5. the proposed fileless malware could infect any device that supports javascript and html5. it serves as a proof-of-concept (poc) to demonstrate the threats of fileless malware in web applications. we used the proposed fileless malware to evaluate existing methods and techniques for malware detection in web applications. we tested the proposed fileless malware with several free and commercial malware detection tools that apply both static and dynamic analysis. the proposed fileless malware bypassed all the anti-malware detection tools included in our study. in our analysis, we discussed the limitations of existing approaches/tools and suggested possible detection and mitigation techniques.",jsless: a tale of a fileless javascript memory-resident malware
828,2-s2.0-85075871751,10.3233/JIFS-179190,Behavior tree design of intelligent behavior of non-player character (NPC) based on Unity3D,Zhu X.,Journal of Intelligent and Fuzzy Systems,2019-01-01,"At this stage, the rapid development of computer technology and information technology in China has provided favorable conditions for the development of the game. In order to pursue the game experience, how to use artificial intelligence in the game has become a new research hotspot. Therefore, the current situation of artificial intelligence used in games was investigated, and the principles of Unity3D game engine were studied; then the intelligent behavior model for NPC was established by using the behavior tree as the basic algorithm, and the AI architecture of the agent in the game was designed; moreover, combined with the above analysis, the behavior tree model based on Q learning algorithm was calculated, and the application of Unity3D in the game was completed; finally, a game model was developed in combination with Unity3D game engine. The results show that the behavior tree based on Unity3D game engine can realize NPC's intelligent behavior simply and efficiently, and the system can run at a good speed, which has theoretical guidance for the follow-up research of game artificial intelligence and simulation training.",behavior tree | intelligent behavior | non-player character (NPC) | Unity3D,6,6071-6079,Journal,Article,1.0,"Zhu, Xianwen",56413235400,Huanghuai University,China,"at this stage, the rapid development of computer technology and information technology in china has provided favorable conditions for the development of the game. in order to pursue the game experience, how to use artificial intelligence in the game has become a new research hotspot. therefore, the current situation of artificial intelligence used in games was investigated, and the principles of unity3d game engine were studied; then the intelligent behavior model for npc was established by using the behavior tree as the basic algorithm, and the ai architecture of the agent in the game was designed; moreover, combined with the above analysis, the behavior tree model based on q learning algorithm was calculated, and the application of unity3d in the game was completed; finally, a game model was developed in combination with unity3d game engine. the results show that the behavior tree based on unity3d game engine can realize npc's intelligent behavior simply and efficiently, and the system can run at a good speed, which has theoretical guidance for the follow-up research of game artificial intelligence and simulation training.",behavior tree design of intelligent behavior of non-player character (npc) based on unity3d
829,2-s2.0-85074942061,10.35595/2414-9179-2019-1-25-414-422,Features of development of geolocation applications for mobile devices with the help of framework react native,Temirgaliyev Z.,"InterCarto, InterGIS",2019-01-01,"Geoinformation applications of different practice and research are one of the mandatory requirements. A rapid development of mobile technologies leads to using a mobile device not as an entertainment tool but also as a production tool. One of the examples of application is geoinformation applications. Almost in every smartphone, there is a GPS receiver and somewhere a GLONASS receiver. With the help of data receivers, users track their position, calculate a distance between points, plot a route or find a required object on a map. In order to gain the most from these technologies, there should be appropriate software for certain mobile platform. The most popular mobile platforms are iOS from Apple and Android from Google. Together they occupy 99 % of the mobile OS market2. Both iOS and Android mobile OS have their application-programming interface (API). Using these API developers access different sensors and receivers of a mobile device, GPS receiver in particular. The most smartphones have preinstalled geoinformation software like Apple Maps on iOS devices and Google Maps on Android devices. But these applications have only basic functionality, so to implement specific software we need to hire developers. Given the differences between the two operating systems, often need individual specialists for development for iOS and Android with high pay3. And this causes a big budget for development. In this article, we consider using React Native framework for mobile development. This framework uses JavaScript programming language and can provide application development for both iOS and Android platforms. JavaScript programming language is very popular among web-developers, and there are not any barriers to hiring a developer with a suitable salary4. So, using React Native we can reduce the budget for mobile geoinformation application development.",Cartography | Geoinformation applications | Mobile applications | React Native,2,414-422,Conference Proceeding,Conference Paper,1.0,"Temirgaliyev, Zholdasbek",57211745265,KIMEP University,Kazakhstan,"geoinformation applications of different practice and research are one of the mandatory requirements. a rapid development of mobile technologies leads to using a mobile device not as an entertainment tool but also as a production tool. one of the examples of application is geoinformation applications. almost in every smartphone, there is a gps receiver and somewhere a glonass receiver. with the help of data receivers, users track their position, calculate a distance between points, plot a route or find a required object on a map. in order to gain the most from these technologies, there should be appropriate software for certain mobile platform. the most popular mobile platforms are ios from apple and android from google. together they occupy 99 % of the mobile os market2. both ios and android mobile os have their application-programming interface (api). using these api developers access different sensors and receivers of a mobile device, gps receiver in particular. the most smartphones have preinstalled geoinformation software like apple maps on ios devices and google maps on android devices. but these applications have only basic functionality, so to implement specific software we need to hire developers. given the differences between the two operating systems, often need individual specialists for development for ios and android with high pay3. and this causes a big budget for development. in this article, we consider using react native framework for mobile development. this framework uses javascript programming language and can provide application development for both ios and android platforms. javascript programming language is very popular among web-developers, and there are not any barriers to hiring a developer with a suitable salary4. so, using react native we can reduce the budget for mobile geoinformation application development.",features of development of geolocation applications for mobile devices with the help of framework react native
830,2-s2.0-85074934372,10.35595/2414-9179-2019-1-25-332-336,The problems of mathematical cartography in GIS,Nyrtsov M.V.,"InterCarto, InterGIS",2019-01-01,"A significant number of maps is compiled using GIS. All GIS software commonly used by cartographers make use of cartographic projections which use the generic coordinate transformation software PROJ. Some existing and new projections are not included in PROJ, so today it is very important to integrate them into the software. One problem is that PROJ does not include some projections used in Soviet maps because their parameters differed from standard projections. Georeferencing and transformation of scanned maps with a set of control points leads to unsatisfactory results. Therefore, for Russian cartographers it is necessary to include nonstandard Soviet map projections in PROJ and to give them unique identifiers in EPSG. A second problem is that the International Astronomical Union recommends the use of triaxial ellipsoids as reference surfaces for small Solar System bodies. Leadership in the development of triaxial ellipsoid projections for celestial body maps belongs to Russian cartographers. The developed projections are implemented as an application written in JavaScript and can be calculated by setting the initial data for the celestial body. There are three types of latitudes on a triaxial ellipsoid: planetocentric, geodesic (planetographic), and quasi-geodesic. GIS software does not include the triaxial ellipsoid as a reference surface, so there is no opportunity to choose the type of latitude and to select a projection of a triaxial ellipsoid. There is also no datum for small Solar System bodies approximated by a triaxial ellipsoid. In the future it is necessary to develop a theory of triaxial ellipsoid projections and include these projections into the PROJ software.",Cartography | Coordinate systems | Map projection | Mathematical cartography,0,332-336,Conference Proceeding,Conference Paper,1.0,"Nyrtsov, Maxim V.",55825771900,Lomonosov Moscow State University,Russian Federation,"a significant number of maps is compiled using gis. all gis software commonly used by cartographers make use of cartographic projections which use the generic coordinate transformation software proj. some existing and new projections are not included in proj, so today it is very important to integrate them into the software. one problem is that proj does not include some projections used in soviet maps because their parameters differed from standard projections. georeferencing and transformation of scanned maps with a set of control points leads to unsatisfactory results. therefore, for russian cartographers it is necessary to include nonstandard soviet map projections in proj and to give them unique identifiers in epsg. a second problem is that the international astronomical union recommends the use of triaxial ellipsoids as reference surfaces for small solar system bodies. leadership in the development of triaxial ellipsoid projections for celestial body maps belongs to russian cartographers. the developed projections are implemented as an application written in javascript and can be calculated by setting the initial data for the celestial body. there are three types of latitudes on a triaxial ellipsoid: planetocentric, geodesic (planetographic), and quasi-geodesic. gis software does not include the triaxial ellipsoid as a reference surface, so there is no opportunity to choose the type of latitude and to select a projection of a triaxial ellipsoid. there is also no datum for small solar system bodies approximated by a triaxial ellipsoid. in the future it is necessary to develop a theory of triaxial ellipsoid projections and include these projections into the proj software.",the problems of mathematical cartography in gis
831,2-s2.0-85074723145,10.1016/j.procs.2019.08.009,Development of a «smart» home system based on the modular structure and architectural data flow pattern Redux,Kazarian A.,Procedia Computer Science,2019-01-01,"Article presents the model and principles of the «smart» home system development using the modular structure and architectural pattern of the data stream Redux. Combination of these principles allow to develop «smart» house system rapidly, taking into account the variety of usage specifics and their scaling, thanks to the combination of pre-designed software and hardware modules.",Intelligent house | Redux patterm | System architecture | “Smart” home,2,35-42,Conference Proceeding,Conference Paper,4.0,"Kazarian, Artem;Teslyuk, Vasyl;Tsmots, Ivan;Greguš, Ján",57208903404;24315132000;24484154400;6701812839,Lviv Polytechnic National University;Univerzita Komenského v Bratislave,Ukraine;Slovakia,"article presents the model and principles of the «smart» home system development using the modular structure and architectural pattern of the data stream redux. combination of these principles allow to develop «smart» house system rapidly, taking into account the variety of usage specifics and their scaling, thanks to the combination of pre-designed software and hardware modules.",development of a «smart» home system based on the modular structure and architectural data flow pattern redux
835,2-s2.0-85073096695,10.5220/0007966805440551,Npm packages as ingredients: A recipe-based approach,Chatzidimitriou K.C.,ICSOFT 2019 - Proceedings of the 14th International Conference on Software Technologies,2019-01-01,"The sharing and growth of open source software packages in the npm JavaScript (JS) ecosystem has been exponential, not only in numbers but also in terms of interconnectivity, to the extend that often the size of dependencies has become more than the size of the written code. This reuse-oriented paradigm, often attributed to the lack of a standard library in node and/or in the micropackaging culture of the ecosystem, yields interesting insights on the way developers build their packages. In this work we view the dependency network of the npm ecosystem from a ""culinary"" perspective. We assume that dependencies are the ingredients in a recipe, which corresponds to the produced software package. We employ network analysis and information retrieval techniques in order to capture the dependencies that tend to co-occur in the development of npm packages and identify the communities that have been evolved as the main drivers for npm's exponential growth.",Dependency networks | JavaScript | Node | Npm | Software reuse,1,544-551,Conference Proceeding,Conference Paper,5.0,"Chatzidimitriou, Kyriakos C.;Papamichail, Michail D.;Diamantopoulos, Themistoklis;Oikonomou, Napoleon Christos;Symeonidis, Andreas L.",6505586965;57200376769;56044278100;57210471479;7004087388,Aristotle University of Thessaloniki,Greece,"the sharing and growth of open source software packages in the npm javascript (js) ecosystem has been exponential, not only in numbers but also in terms of interconnectivity, to the extend that often the size of dependencies has become more than the size of the written code. this reuse-oriented paradigm, often attributed to the lack of a standard library in node and/or in the micropackaging culture of the ecosystem, yields interesting insights on the way developers build their packages. in this work we view the dependency network of the npm ecosystem from a ""culinary"" perspective. we assume that dependencies are the ingredients in a recipe, which corresponds to the produced software package. we employ network analysis and information retrieval techniques in order to capture the dependencies that tend to co-occur in the development of npm packages and identify the communities that have been evolved as the main drivers for npm's exponential growth.",npm packages as ingredients: a recipe-based approach
837,2-s2.0-85072919147,10.2174/0929867324666171107101035,The in silico drug discovery toolbox: Applications in lead discovery and optimization,Bruno A.,Current Medicinal Chemistry,2019-01-01,"Background: Discovery and development of a new drug is a long lasting and expensive journey that takes around 20 years from starting idea to approval and marketing of new medication. Despite R&D expenditures have been constantly increasing in the last few years, the number of new drugs introduced into market has been steadily declining. This is mainly due to preclinical and clinical safety issues, which still represent about 40% of drug discontinuation. To cope with this issue, a number of in silico techniques are currently being used for an early stage evaluation/prediction of potential safety issues, allowing to increase the drug-discovery success rate and reduce costs associated with the development of a new drug. Methods: In the present review, we will analyse the early steps of the drug-discovery pipeline, describing the sequence of steps from disease selection to lead optimization and focusing on the most common in silico tools used to assess attrition risks and build a mitigation plan. Results: A comprehensive list of widely used in silico tools, databases, and public initiatives that can be effectively implemented and used in the drug discovery pipeline has been provided. A few examples of how these tools can be problem-solving and how they may increase the success rate of a drug discovery and development program have been also provided. Finally, selected examples where the application of in silico tools had effectively contributed to the development of marketed drugs or clinical candidates will be given. Conclusion: The in silico toolbox finds great application in every step of early drug discovery: (i) target identification and validation; (ii) hit identification; (iii) hit-to-lead; and (iv) lead optimization. Each of these steps has been described in details, providing a useful overview on the role played by in silico tools in the decision-making process to speed-up the discovery of new drugs.",Computational chemistry | Drug-discovery | Hit-to-lead | Human-genome sequencing | Lead optimization | Target validation,21,3838-3873,Journal,Review,4.0,"Bruno, Agostino;Costantino, Gabriele;Sartori, Luca;Radi, Marco",26867569100;7005941496;24400005900;6603623399,Fondazione IFOM Istituto Firc di Oncologia Molecolare;Università di Parma,Italy;Italy,"background: discovery and development of a new drug is a long lasting and expensive journey that takes around 20 years from starting idea to approval and marketing of new medication. despite r&d expenditures have been constantly increasing in the last few years, the number of new drugs introduced into market has been steadily declining. this is mainly due to preclinical and clinical safety issues, which still represent about 40% of drug discontinuation. to cope with this issue, a number of in silico techniques are currently being used for an early stage evaluation/prediction of potential safety issues, allowing to increase the drug-discovery success rate and reduce costs associated with the development of a new drug. methods: in the present review, we will analyse the early steps of the drug-discovery pipeline, describing the sequence of steps from disease selection to lead optimization and focusing on the most common in silico tools used to assess attrition risks and build a mitigation plan. results: a comprehensive list of widely used in silico tools, databases, and public initiatives that can be effectively implemented and used in the drug discovery pipeline has been provided. a few examples of how these tools can be problem-solving and how they may increase the success rate of a drug discovery and development program have been also provided. finally, selected examples where the application of in silico tools had effectively contributed to the development of marketed drugs or clinical candidates will be given. conclusion: the in silico toolbox finds great application in every step of early drug discovery: (i) target identification and validation; (ii) hit identification; (iii) hit-to-lead; and (iv) lead optimization. each of these steps has been described in details, providing a useful overview on the role played by in silico tools in the decision-making process to speed-up the discovery of new drugs.",the in silico drug discovery toolbox: applications in lead discovery and optimization
838,2-s2.0-85072854282,10.1007/978-3-030-30033-3_21,Development of a Puzzle Game to Learn Coding for Elementary Students,Baek J.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2019-01-01,"Existing computer games used to teach coding to students have certain shortcomings such as the use of icons that do not convert to actual text-based coding commands, and the fact that teachers cannot follow students’ progress in real time. In this study, we have improved upon existing coding games by developing a puzzle game based on coding and a web-based management system to observe the user’s learning status in real time and maximize the understanding of how elementary students learn to code. We analyzed the syntax of various coding languages for the school curriculum and provided a menu to convert icons into textual coding language. In addition, the game’s management system includes multiple types of tutoring, real-time analysis of user play data, and feedback. Following its application in regular elementary school software classes, we conducted a Likert scale survey. Students reported positive effects on understanding and showed an interest in coding. It is expected that this will contribute to quality improvement in software education by providing content with proven educational value by breaking away from simple learning-oriented coding games.",Coding game | Puzzle game | Software education,1,267-279,Book Series,Conference Paper,2.0,"Baek, Jaisoon;Oh, Gyuhwan",57211170283;55581228300,Ajou University,South Korea,"existing computer games used to teach coding to students have certain shortcomings such as the use of icons that do not convert to actual text-based coding commands, and the fact that teachers cannot follow students’ progress in real time. in this study, we have improved upon existing coding games by developing a puzzle game based on coding and a web-based management system to observe the user’s learning status in real time and maximize the understanding of how elementary students learn to code. we analyzed the syntax of various coding languages for the school curriculum and provided a menu to convert icons into textual coding language. in addition, the game’s management system includes multiple types of tutoring, real-time analysis of user play data, and feedback. following its application in regular elementary school software classes, we conducted a likert scale survey. students reported positive effects on understanding and showed an interest in coding. it is expected that this will contribute to quality improvement in software education by providing content with proven educational value by breaking away from simple learning-oriented coding games.",development of a puzzle game to learn coding for elementary students
839,2-s2.0-85071452741,10.1007/978-3-030-29193-8_4,A record/replay debugger for service development on the cloud,Sheikh Quroush M.,Communications in Computer and Information Science,2019-01-01,"Cloud based software development platforms are continuously becoming more powerful and penetrate towards the daily routines of modern developers. This paper presents a debugging approach that can be used in cloud based service development platforms where developer is working on relatively small sized scripts to be hosted on multi-tenant cloud platforms. Presented remote debugging approach utilizes record/replay technique to re-execute and record the variable evaluations whenever an exception is thrown during the developed service’s run-time. Additionally, an alternative recording scheme is also proposed that involves only recording external data accesses. Memory and run-time overhead of proposed approaches show that remote debugging approach can be useful especially when the minimal recording scheme is applied.",Cloud based development | Record/replay debugging | Remote service debugging,1,64-76,Book Series,Conference Paper,2.0,"Sheikh Quroush, M. Subhi;Ovatman, Tolga",57202645118;25960879900,İstanbul Teknik Üniversitesi,Turkey,"cloud based software development platforms are continuously becoming more powerful and penetrate towards the daily routines of modern developers. this paper presents a debugging approach that can be used in cloud based service development platforms where developer is working on relatively small sized scripts to be hosted on multi-tenant cloud platforms. presented remote debugging approach utilizes record/replay technique to re-execute and record the variable evaluations whenever an exception is thrown during the developed service’s run-time. additionally, an alternative recording scheme is also proposed that involves only recording external data accesses. memory and run-time overhead of proposed approaches show that remote debugging approach can be useful especially when the minimal recording scheme is applied.",a record/replay debugger for service development on the cloud
842,2-s2.0-85071275296,10.18178/ijiet.2019.9.1.1174,A Study of the Visualization Tool for Computer Science Majors’ Capability Assessment,Ye F.,International Journal of Information and Education Technology,2019-01-01,"IT industry burgeoning, more and more enterprises and universities pay attention to the comprehensive ability of computer science majors. However, the existing assessment method giving priority to test scores, could not greatly demonstrate computer science majors’ capability and their development approaches, with drawbacks of serious one-sidedness, limitation and low perceptual intuition. Correspondingly, it’s difficult to teach students according to their aptitude or interests. Moreover, the current research works show that this research field still requires theoretical foundations, appropriate models, effective tools, in-depth experimentations and practical implementations. In order to solve this problem, the paper proposes an index system of students' for evaluating computer science majors’ ability, designs and implements the relevant visualization software of capability assessment based on dynamic radar charts and jitterplot, and then illustrates the application of this visual software through case studies. Based on the visualization tool, it has achieved good results in practical teaching.",Capability assessment | Jitterplot | Radar chart | Visualization tool,1,61-65,Journal,Article,3.0,"Ye, Feng;Chen, Yong;Huang, Qian",57202218936;57194509724;57155528800,Hohai University;Nanjing Longyuan Micro-Electronic Company,China;China,"it industry burgeoning, more and more enterprises and universities pay attention to the comprehensive ability of computer science majors. however, the existing assessment method giving priority to test scores, could not greatly demonstrate computer science majors’ capability and their development approaches, with drawbacks of serious one-sidedness, limitation and low perceptual intuition. correspondingly, it’s difficult to teach students according to their aptitude or interests. moreover, the current research works show that this research field still requires theoretical foundations, appropriate models, effective tools, in-depth experimentations and practical implementations. in order to solve this problem, the paper proposes an index system of students' for evaluating computer science majors’ ability, designs and implements the relevant visualization software of capability assessment based on dynamic radar charts and jitterplot, and then illustrates the application of this visual software through case studies. based on the visualization tool, it has achieved good results in practical teaching.",a study of the visualization tool for computer science majors’ capability assessment
843,2-s2.0-85071153265,10.5731/pdajpst.2018.009407,Provable data integrity in the pharmaceutical industry based on version control systems and the blockchain,Steinwandter V.,PDA Journal of Pharmaceutical Science and Technology,2019-01-01,"In the pharmaceutical industry, process validation tasks are based on the raw data and its derived analytical results generated from the process. Process validation failure affects both patient safety and the economic success of the manufacturing company. Hence, data integrity is highly critical in this area. Regulatory agencies, such as the Food and Drug Administration (FDA), reacted to past data integrity breaches by publishing new guidelines on data integrity for the correct handling of data in the pharmaceutical context. In this contribution, we want to show how data integrity can be improved on a technological level, removing the need for trusted third parties and centralized systems for this task. Therefore, we implemented an approach that uses existing tools, currently mostly used by software developers, and combined them with a new smart contract built on top of the Ethereum blockchain. In a case study, we test how data manipulation or backdating of results can be easily detected and how regulatory agencies can audit the complete data flow from the regulatory report back to the original raw data. The results of this contribution outline a possible road map for the development of production-ready tools, such as versioned database systems that natively interoperate with distributed ledgers. This will improve the trustworthiness of pharmaceutical manufacturing data by both protecting the intellectual property of the industrial company and improving the safety of the patients.",Blockchain | Data integrity | Data science | Pharmaceutical manufacturing | Regulatory compliance,7,373-390,Journal,Article,2.0,"Steinwandter, Valentin;Herwig, Christoph",56743341400;6603049934,Technische Universität Wien;Exputec GmbH,Austria;Austria,"in the pharmaceutical industry, process validation tasks are based on the raw data and its derived analytical results generated from the process. process validation failure affects both patient safety and the economic success of the manufacturing company. hence, data integrity is highly critical in this area. regulatory agencies, such as the food and drug administration (fda), reacted to past data integrity breaches by publishing new guidelines on data integrity for the correct handling of data in the pharmaceutical context. in this contribution, we want to show how data integrity can be improved on a technological level, removing the need for trusted third parties and centralized systems for this task. therefore, we implemented an approach that uses existing tools, currently mostly used by software developers, and combined them with a new smart contract built on top of the ethereum blockchain. in a case study, we test how data manipulation or backdating of results can be easily detected and how regulatory agencies can audit the complete data flow from the regulatory report back to the original raw data. the results of this contribution outline a possible road map for the development of production-ready tools, such as versioned database systems that natively interoperate with distributed ledgers. this will improve the trustworthiness of pharmaceutical manufacturing data by both protecting the intellectual property of the industrial company and improving the safety of the patients.",provable data integrity in the pharmaceutical industry based on version control systems and the blockchain
844,2-s2.0-85070686760,10.1016/j.cosrev.2019.05.001,Systematic mapping study of API usability evaluation methods,Rauf I.,Computer Science Review,2019-01-01,"An Application Programming Interface (API) provides a programmatic interface to a software component that is often offered publicly and may be used by programmers who are not the API's original designers. APIs play a key role in software reuse. By reusing high quality components and services, developers can increase their productivity and avoid costly defects. The usability of an API is a qualitative characteristic that evaluates how easy it is to use an API. Recent years have seen a considerable increase in research efforts aiming at evaluating the usability of APIs. An API usability evaluation can identify problem areas and provide recommendations for improving the API. In this systematic mapping study, we focus on 47 primary studies to identify the aim and the method of the API usability studies. We investigate which API usability factors are evaluated, at which phases of API development is the usability of API evaluated and what are the current limitations and open issues in API usability evaluation. We believe that the results of this literature review would be useful for both researchers and industry practitioners interested in investigating the usability of API and new API usability evaluation methods.",API developers | API usability | Cognitive dimensions | Usability evaluation methods | Usability factors,10,49-68,Journal,Review,3.0,"Rauf, Irum;Troubitsyna, Elena;Porres, Ivan",35410544000;55886153800;14070736200,Åbo Akademi University;The Open University;The Royal Institute of Technology (KTH),Finland;United Kingdom;Sweden,"an application programming interface (api) provides a programmatic interface to a software component that is often offered publicly and may be used by programmers who are not the api's original designers. apis play a key role in software reuse. by reusing high quality components and services, developers can increase their productivity and avoid costly defects. the usability of an api is a qualitative characteristic that evaluates how easy it is to use an api. recent years have seen a considerable increase in research efforts aiming at evaluating the usability of apis. an api usability evaluation can identify problem areas and provide recommendations for improving the api. in this systematic mapping study, we focus on 47 primary studies to identify the aim and the method of the api usability studies. we investigate which api usability factors are evaluated, at which phases of api development is the usability of api evaluated and what are the current limitations and open issues in api usability evaluation. we believe that the results of this literature review would be useful for both researchers and industry practitioners interested in investigating the usability of api and new api usability evaluation methods.",systematic mapping study of api usability evaluation methods
845,2-s2.0-85070303680,10.33965/el2019_201909f024,Liascript: A domain-specific-language for interactive online courses,Dietrich A.,"Multi Conference on Computer Science and Information Systems, MCCSIS 2019 - Proceedings of the International Conference on e-Learning 2019",2019-01-01,"LiaScript is an attempt to enable everyone to create free and interactive online courses, without the need of being an experienced programmer. Instead, it aims to bring both parties, software- and course-developers, closer together by introducing Open-Source techniques into the Open-courSe development process. LiaScript was designed to be compatible to Common-Markdown, but it introduces lots of language extensions that deal with quizzes, surveys, ASCII-art, text2speech, animations, online programming, the integration of JavaScript, etc. as well as its own macro-system that simplifies tedious and repetitive tasks. It comes along with its own just-in-time compiler that runs in the browser and therefor does not require additional tooling.",DSL | ELearning | Markdown | OER | Online-Course,1,186-194,Conference Proceeding,Conference Paper,1.0,"Dietrich, André",36456917500,Otto von Guericke University of Magdeburg,Germany,"liascript is an attempt to enable everyone to create free and interactive online courses, without the need of being an experienced programmer. instead, it aims to bring both parties, software- and course-developers, closer together by introducing open-source techniques into the open-course development process. liascript was designed to be compatible to common-markdown, but it introduces lots of language extensions that deal with quizzes, surveys, ascii-art, text2speech, animations, online programming, the integration of javascript, etc. as well as its own macro-system that simplifies tedious and repetitive tasks. it comes along with its own just-in-time compiler that runs in the browser and therefor does not require additional tooling.",liascript: a domain-specific-language for interactive online courses
846,2-s2.0-85069834175,10.1007/978-3-030-23541-3_25,Design and Development of a Standard Interface Component to Highlight Automated AI Recommendations in the Conta Azul Software,de Menezes Neto J.A.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2019-01-01,"This paper reports, in a professional approach, the design and development process of a standard interface component, which highlights the information provided by two artificial intelligence engines of the Conta Azul software. This software is a cloud platform for small businesses management, developed and marketed in Brazil, in the SaaS (Software as a Service) modality, which connects to banks, the government and fintechs. As a design problem, it was necessary to stipulate, as a part of the company’s Design System and as a response to the managerial challenges brought about by the accelerated growth of the R&D team, a standard interface component for the aforementioned cases, providing context to the user and scalability to team practices. These engines are used for (1) tax recommendation and (2) the categorization of bank statements. As methods stipulated, there were the analysis of support tickets, analysis of the current interfaces, benchmarking, generation of alternatives, design review, bitmap prototyping, usability tests and JavaScript coding. The result was a standard interface component. The compatibility with the schedule of the company and its objectives was considered. The project occurred in parallel with other demands, from January 2018 to December 2018. The first author of this paper is one of the design coordinators of the company, being the other authors collaborators of the Design Ops team.",Automated recommendations | Component | Interface,0,347-360,Book Series,Conference Paper,4.0,"de Menezes Neto, João Antonio;Cruz, Bruno Carlos;Porto Schroeter, Harry;Ribeiro Feitosa, Ludmila Rocha",57207885107;57210187839;57210194715;57210195808,ContaAzul Software LTDA,Brazil,"this paper reports, in a professional approach, the design and development process of a standard interface component, which highlights the information provided by two artificial intelligence engines of the conta azul software. this software is a cloud platform for small businesses management, developed and marketed in brazil, in the saas (software as a service) modality, which connects to banks, the government and fintechs. as a design problem, it was necessary to stipulate, as a part of the company’s design system and as a response to the managerial challenges brought about by the accelerated growth of the r&d team, a standard interface component for the aforementioned cases, providing context to the user and scalability to team practices. these engines are used for (1) tax recommendation and (2) the categorization of bank statements. as methods stipulated, there were the analysis of support tickets, analysis of the current interfaces, benchmarking, generation of alternatives, design review, bitmap prototyping, usability tests and javascript coding. the result was a standard interface component. the compatibility with the schedule of the company and its objectives was considered. the project occurred in parallel with other demands, from january 2018 to december 2018. the first author of this paper is one of the design coordinators of the company, being the other authors collaborators of the design ops team.",design and development of a standard interface component to highlight automated ai recommendations in the conta azul software
848,2-s2.0-85069680059,10.13053/CyS-23-1-2782,A review of reality of software test automation,Edgar Serna M.,Computacion y Sistemas,2019-01-01,"Testing the software is one of the most important activities in the development life cycle, but has traditionally been carried out at the end of the process, when the product is completed and is about to be released. The complexity of today's software requires the test to run in parallel with the development, so that problems are found early and can be corrected at low cost. The test automation emerged as an alternative to speed up its implementation, as well as to improve product reliability and quality. But, although his study and research began almost 50 years ago, progress still does not meet demand for quality improvement. In this article are presented the results of an integrative literature review, conducted with the aim of establishing an overview of the experiences reported on test automation. It was found that there is still no agreement on its definition and the advantages and limitations are almost personal opinions. In addition, many companies assume automation as a total replacement for manual testing, although their level of maturity still not allowed.",Manual testing | Software quality | Software reliability | Test cases,1,169-183,Journal,Article,3.0,"Edgar Serna, M.;Raquel Martínez, M.;Paula Tamayo, O.",57210102578;57194720264;36134150700,Institución Universitaria de Envigado;Instituto Antioqueño de Investigación,Colombia;Colombia,"testing the software is one of the most important activities in the development life cycle, but has traditionally been carried out at the end of the process, when the product is completed and is about to be released. the complexity of today's software requires the test to run in parallel with the development, so that problems are found early and can be corrected at low cost. the test automation emerged as an alternative to speed up its implementation, as well as to improve product reliability and quality. but, although his study and research began almost 50 years ago, progress still does not meet demand for quality improvement. in this article are presented the results of an integrative literature review, conducted with the aim of establishing an overview of the experiences reported on test automation. it was found that there is still no agreement on its definition and the advantages and limitations are almost personal opinions. in addition, many companies assume automation as a total replacement for manual testing, although their level of maturity still not allowed.",a review of reality of software test automation
850,2-s2.0-85068992494,10.1007/978-3-030-24308-1_43,Software Architecture Enabling Effective Control of Selected Quality Aspects,Žemlička M.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2019-01-01,"The number of requirements on information and control systems features grows. They often contain flexibility, safety, reliability, and security. Balancing all these features is not easy. We propose architectural turn enabling to control flexibility and security (and to some extent also reliability/availability). The proposed solution enables agile involvement of people into processes. It simplifies solution of rare cases or emergency situations. It can be used during system development and maintenance. We discuss some implementation details.",Software confederations | Software quality aspects control | System flexibility,1,536-550,Book Series,Conference Paper,2.0,"Žemlička, Michal;Král, Jaroslav",8961208400;54886946900,Masaryk University;Charles University;AZD PRAHA SRO,Czech Republic;Czech Republic;Czech Republic,"the number of requirements on information and control systems features grows. they often contain flexibility, safety, reliability, and security. balancing all these features is not easy. we propose architectural turn enabling to control flexibility and security (and to some extent also reliability/availability). the proposed solution enables agile involvement of people into processes. it simplifies solution of rare cases or emergency situations. it can be used during system development and maintenance. we discuss some implementation details.",software architecture enabling effective control of selected quality aspects
852,2-s2.0-85068181076,10.33271/mining13.02.091,Digital system of quarry management as a SAAS solution: Mineral deposit module,Zarubin M.,Mining of Mineral Deposits,2019-01-01,"Purpose. Improving the efficiency of functioning the mining enterprises and aggregation of earlier obtained results into a unified digital system of designing and operative management by quarry operation. Methods. Both the traditional (analysis of scientific and patent literature, analytical methods of deposit parameters research, analysis of experience and exploitation of quarries, conducting the passive experiment and processing the statistical data) and new forms of scientific research-deposit modeling on the basis of classical and neural network methods of approximation – are used in the work. For the purpose of the software product realization on the basis of cloud technologies, there were used: for back-end implementation – server-based scripting language php; for the front-end – multi-paradigm programming language javascript, javascript framework jQuery and asynchronous data exchange technology Ajax. Findings. The target audience of the system has been identified, SWOT-analysis has been carried out, conceptual directions of 3D-quarry system development have been defined. The strategies of development and promotion of the software product, as well as the strategies of safety and reliability of the application both for the client and the owner of the system have been formulated. The modular structure of the application has been developed, and the system functions have been divided to implement both back-end and front-end applications. The Mineral Deposit Module has been developed: the geological structure of the deposit has been simulated and its block model has been con-structed. It has been proved that the use of neural network algorithms does not give an essential increase in the accu-racy of the block model for the deposits of 1 and 2 groups in terms of the geological structure complexity. The possibility and prospects of constructing the systems for subsoil users on the basis of cloud technologies and the concept of SaaS have been substantiated. Originality. For the first time, the modern software products for solving the problems of designing and operational management of mining operations have been successfully developed on the basis of the SaaS concept. Practical implications. The results are applicable for enterprises-subsoil users, working with deposits of 1 and 2 groups in terms of the geological structure complexity: design organizations, as well as mining and processing plants.",3D-quarry | Artificial neural networks | Block model of the deposit | Cloud technologies | Data approximation | Strategies of information system development,4,91-102,Journal,Article,5.0,"Zarubin, Mikhail;Zarubina, Venera;Fionin, Evgeniy;Salykov, Bulat;Salykova, Olga",57192170365;57205617635;8971102300;57205683107;57205683892,A. Baitursynov Kostanay Regional University;Rudny Industrial Institute,Kazakhstan;Kazakhstan,"purpose. improving the efficiency of functioning the mining enterprises and aggregation of earlier obtained results into a unified digital system of designing and operative management by quarry operation. methods. both the traditional (analysis of scientific and patent literature, analytical methods of deposit parameters research, analysis of experience and exploitation of quarries, conducting the passive experiment and processing the statistical data) and new forms of scientific research-deposit modeling on the basis of classical and neural network methods of approximation – are used in the work. for the purpose of the software product realization on the basis of cloud technologies, there were used: for back-end implementation – server-based scripting language php; for the front-end – multi-paradigm programming language javascript, javascript framework jquery and asynchronous data exchange technology ajax. findings. the target audience of the system has been identified, swot-analysis has been carried out, conceptual directions of 3d-quarry system development have been defined. the strategies of development and promotion of the software product, as well as the strategies of safety and reliability of the application both for the client and the owner of the system have been formulated. the modular structure of the application has been developed, and the system functions have been divided to implement both back-end and front-end applications. the mineral deposit module has been developed: the geological structure of the deposit has been simulated and its block model has been con-structed. it has been proved that the use of neural network algorithms does not give an essential increase in the accu-racy of the block model for the deposits of 1 and 2 groups in terms of the geological structure complexity. the possibility and prospects of constructing the systems for subsoil users on the basis of cloud technologies and the concept of saas have been substantiated. originality. for the first time, the modern software products for solving the problems of designing and operational management of mining operations have been successfully developed on the basis of the saas concept. practical implications. the results are applicable for enterprises-subsoil users, working with deposits of 1 and 2 groups in terms of the geological structure complexity: design organizations, as well as mining and processing plants.",digital system of quarry management as a saas solution: mineral deposit module
854,2-s2.0-85067678726,10.1109/ACCESS.2019.2920176,DOPdefenderPlus: A Data-Oriented Programming Attack Mitigation Technique for Complex Software,Wang Y.,IEEE Access,2019-01-01,"With the development of research on noncontrol data attacks and defense, the threat of data-oriented programming (DOP) attacks has attracted increasing attention from the security research community. DOP attacks can manipulate security-critical noncontrol data to alter program behavior without violating control-flow integrity (CFI) and can circumvent the most effective defenses against control-data attacks. Among DOP attacks, the misuse of user input data is a major contributor. Moreover, existing defense methods, e.g., DOPdefender, currently lack security protection for user input data. To effectively defend against DOP attacks, we propose a novel technique, DOPdefenderPlus, which draws on the idea of divide-and-conquer and uses the modular authentication technique to make DOPdefender scalable for complex software that is designed modularly, as well as introduce the Inputguard technique to protect the program input data. The DOPdefenderPlus is an enhanced version of DOPdefender, which overcomes some limitations of DOPdefender. We implement DOPdefenderPlus on a Linux operating system and use it to defend against multiple realistic DOP attacks. We also evaluate the performance of our method, and all the results show that DOPdefenderPlus can overcome the two limitations of DOPdefender while introducing a moderate runtime overhead.",DOP | DOPdefenderPlus | Noncontrol data attacks | security-critical noncontrol data | user input data,3,73455-73468,Journal,Article,5.0,"Wang, Ye;Chen, Zhifeng;Li, Qingbao;Zhang, Ping;Zhang, Guimin",57189077114;56923921300;25634387000;56923973900;57207176911,State Key Laboratory of Mathematical Engineering and Advanced Computing,China,"with the development of research on noncontrol data attacks and defense, the threat of data-oriented programming (dop) attacks has attracted increasing attention from the security research community. dop attacks can manipulate security-critical noncontrol data to alter program behavior without violating control-flow integrity (cfi) and can circumvent the most effective defenses against control-data attacks. among dop attacks, the misuse of user input data is a major contributor. moreover, existing defense methods, e.g., dopdefender, currently lack security protection for user input data. to effectively defend against dop attacks, we propose a novel technique, dopdefenderplus, which draws on the idea of divide-and-conquer and uses the modular authentication technique to make dopdefender scalable for complex software that is designed modularly, as well as introduce the inputguard technique to protect the program input data. the dopdefenderplus is an enhanced version of dopdefender, which overcomes some limitations of dopdefender. we implement dopdefenderplus on a linux operating system and use it to defend against multiple realistic dop attacks. we also evaluate the performance of our method, and all the results show that dopdefenderplus can overcome the two limitations of dopdefender while introducing a moderate runtime overhead.",dopdefenderplus: a data-oriented programming attack mitigation technique for complex software
855,2-s2.0-85067472731,10.5220/0007727603590366,Analyzing the evolution of JavaScript applications,Chatzimparmpas A.,ENASE 2019 - Proceedings of the 14th International Conference on Evaluation of Novel Approaches to Software Engineering,2019-01-01,"Software evolution analysis can shed light on various aspects of software development and maintenance. Up to date, there is little empirical evidence on the evolution of JavaScript (JS) applications in terms of maintainability and changeability, even though JavaScript is among the most popular scripting languages for front-end web applications, including IoT applications. In this study, we investigate JS applications' quality and changeability trends over time by examining the relevant Laws of Lehman. We analyzed over 7,500 releases of JS applications and reached some interesting conclusions. The results show that JS applications continuously change and grow, there are no clear signs of quality degradation while the complexity remains the same over time, despite the fact that the understandability of the code deteriorates.",JavaScript | Lehman's Laws | Maintenance | Software Evolution | Software Quality,4,359-366,Conference Proceeding,Conference Paper,4.0,"Chatzimparmpas, Angelos;Bibi, Stamatia;Zozas, Ioannis;Kerren, Andreas",57205364230;14719125500;57202336557;6508221631,"Linnaeus University, Växjö;University of Western Macedonia",Sweden;Greece,"software evolution analysis can shed light on various aspects of software development and maintenance. up to date, there is little empirical evidence on the evolution of javascript (js) applications in terms of maintainability and changeability, even though javascript is among the most popular scripting languages for front-end web applications, including iot applications. in this study, we investigate js applications' quality and changeability trends over time by examining the relevant laws of lehman. we analyzed over 7,500 releases of js applications and reached some interesting conclusions. the results show that js applications continuously change and grow, there are no clear signs of quality degradation while the complexity remains the same over time, despite the fact that the understandability of the code deteriorates.",analyzing the evolution of javascript applications
856,2-s2.0-85067464593,10.5220/0007678302570264,A model-driven approach for developing responsive web apps,Seixas J.,ENASE 2019 - Proceedings of the 14th International Conference on Evaluation of Novel Approaches to Software Engineering,2019-01-01,"Nowadays users have multiple devices to access a myriad of web and mobile applications. This has increased the importance of developing such applications in a responsive way, i.e. with the ability to seamlessly display their contents on multiple devices. This paper proposes the XIS-Web technology as a model-driven approach focused in the development of responsive web applications. XIS-Web technology includes two main parts: the XIS-Web modeling language, implemented as a UML profile; and the XIS-Web framework, which is a set of integrated software tools. XIS-Web stands out in four key aspects: supports the modeling of web applications around six viewpoints, which ultimately promotes the separation of concerns that is key to managing complexity; generates user-interface models from extended use-case models, relieving this cumbersome and time consuming task from the user; employs latest generation web technologies (such as HTML5, JavaScript, CSS) that allow the required flexibility of developing responsive web applications; and allows the creation of platform-independent models without requiring a significant learning curve. This paper also presents an evaluation conducted in a controlled environment with a group of independent users, and briefly introduces simple case studies.",Model-Driven Development | Responsive Web Application | Web Engineering,5,257-264,Conference Proceeding,Conference Paper,3.0,"Seixas, João;Ribeiro, André;Da Silva, Alberto Rodrigues",57206286907;55218039200;8917629900,Instituto Superior Técnico,Portugal,"nowadays users have multiple devices to access a myriad of web and mobile applications. this has increased the importance of developing such applications in a responsive way, i.e. with the ability to seamlessly display their contents on multiple devices. this paper proposes the xis-web technology as a model-driven approach focused in the development of responsive web applications. xis-web technology includes two main parts: the xis-web modeling language, implemented as a uml profile; and the xis-web framework, which is a set of integrated software tools. xis-web stands out in four key aspects: supports the modeling of web applications around six viewpoints, which ultimately promotes the separation of concerns that is key to managing complexity; generates user-interface models from extended use-case models, relieving this cumbersome and time consuming task from the user; employs latest generation web technologies (such as html5, javascript, css) that allow the required flexibility of developing responsive web applications; and allows the creation of platform-independent models without requiring a significant learning curve. this paper also presents an evaluation conducted in a controlled environment with a group of independent users, and briefly introduces simple case studies.",a model-driven approach for developing responsive web apps
857,2-s2.0-85067358536,10.21303/2461-4262.2019.00902,Development of the optimization model of the interface of multimedia edition,Hrabovskyi Y.,"EUREKA, Physics and Engineering",2019-01-01,"The aim of the research work is development of a model for optimizing the interface of a multimedia publication. In this research, five levels of interaction are identified for the interface of a multimedia publication – flat surfaces, layouts, structures, feature sets, strategies. The relationship between the levels of user interaction and interface properties of a multimedia publication is analyzed. It is proposed to select interface components based on the properties of the multimedia editions they provide. In order to construct models of optimization of elements of the interface of a multimedia publication, estimates of the interconnection of elements of the interface with functional capabilities by the total matrix are used. To combine the standard models into a single interface optimization model, an analysis of the relationship between the elements of the interface of the multimedia publication and the characteristics of the multimedia publication has been conducted. According to the results of the analysis, an economical tree is constructed, which allows to build a hierarchy of the stages of optimization of the interface of the multimedia publication and to determine the input data for the implementation of the task. The definition of the input data allows to show the principle of the interface optimization model in the form of a ""black"" box. An algorithm for optimizing the interface element of a multimedia publication is proposed. As a result of the practical implementation of the optimization model for the multimedia edition interface, a software product, created on the basis of HTML markup using cascading CSS style stylesheets and JavaScript language, was obtained. Adobe Device Central CS5 tested the created software on devices with different characteristics.",Multimedia edition | Optimization model | Total matrix | User interface,5,3-12,Journal,Article,2.0,"Hrabovskyi, Yevhen;Fedorchenko, Volodymyr",57201773546;57209318727,Simon Kuznets Kharkiv National University of Economics,Ukraine,"the aim of the research work is development of a model for optimizing the interface of a multimedia publication. in this research, five levels of interaction are identified for the interface of a multimedia publication – flat surfaces, layouts, structures, feature sets, strategies. the relationship between the levels of user interaction and interface properties of a multimedia publication is analyzed. it is proposed to select interface components based on the properties of the multimedia editions they provide. in order to construct models of optimization of elements of the interface of a multimedia publication, estimates of the interconnection of elements of the interface with functional capabilities by the total matrix are used. to combine the standard models into a single interface optimization model, an analysis of the relationship between the elements of the interface of the multimedia publication and the characteristics of the multimedia publication has been conducted. according to the results of the analysis, an economical tree is constructed, which allows to build a hierarchy of the stages of optimization of the interface of the multimedia publication and to determine the input data for the implementation of the task. the definition of the input data allows to show the principle of the interface optimization model in the form of a ""black"" box. an algorithm for optimizing the interface element of a multimedia publication is proposed. as a result of the practical implementation of the optimization model for the multimedia edition interface, a software product, created on the basis of html markup using cascading css style stylesheets and javascript language, was obtained. adobe device central cs5 tested the created software on devices with different characteristics.",development of the optimization model of the interface of multimedia edition
858,2-s2.0-85066747642,10.14569/ijacsa.2019.0100539,Experimental evaluation of the virtual environment efficiency for distributed software development,Kolyasnikov P.,International Journal of Advanced Computer Science and Applications,2019-01-01,"At every software design stage nowadays, there is an acute need to solve the problem of effective choice of libraries, development technologies, data exchange formats, virtual environment systems, characteristics of virtual machines. Due to the spread of various kinds of devices and the popularity of Web platforms, lots of systems are developed not for the universal installation on a device (box version), but for a specific architecture with the subsequent provision of web services. Under these conditions, the only way for estimating the efficiency parameters at the design stage is to conduct various kinds of experiments to evaluate the parameters of a particular solution. Using the example of the Web platform of digital psychological tools, the methods for experimental parameter evaluation were developed in the article. The mechanisms and technologies for improving the efficiency of the Vagrant and Docker cloud virtual environment were also proposed in the paper. A set of basic criteria for evaluating the effectiveness of the configuration of the virtual development environment has been determined to be rapid deployment; increase in the speed and decrease in the volume of resources used; increase in the speed of data exchange between the host machine and the virtual machine. The results of experimental estimates of the parameters that define the formulated efficiency criteria are given as: processor utilization involved (percentage); the amount of RAM involved (GB); initialization time of virtual machines (seconds); time to assemble the component completely (Build) and to reassemble the component (Watch) (seconds). To improve the efficiency, a file system access driver based on the NFS protocol was studied in the paper.",Distributed software development | Docker | Increase development efficiency | NFS | Vagrant | Virtual development environment | Virtual machines | Webpack,4,309-316,Journal,Article,5.0,"Kolyasnikov, Pavel;Nikulchev, Evgeny;Silakov, Iliy;Ilin, Dmitry;Gusev, Alexander",57204774687;6504081534;57209173034;57203848706;57207731147,MIREA - Russian Technological University (RTU MIREA);Russian Academy of Education;Kuban State University,Russian Federation;Russian Federation;Russian Federation,"at every software design stage nowadays, there is an acute need to solve the problem of effective choice of libraries, development technologies, data exchange formats, virtual environment systems, characteristics of virtual machines. due to the spread of various kinds of devices and the popularity of web platforms, lots of systems are developed not for the universal installation on a device (box version), but for a specific architecture with the subsequent provision of web services. under these conditions, the only way for estimating the efficiency parameters at the design stage is to conduct various kinds of experiments to evaluate the parameters of a particular solution. using the example of the web platform of digital psychological tools, the methods for experimental parameter evaluation were developed in the article. the mechanisms and technologies for improving the efficiency of the vagrant and docker cloud virtual environment were also proposed in the paper. a set of basic criteria for evaluating the effectiveness of the configuration of the virtual development environment has been determined to be rapid deployment; increase in the speed and decrease in the volume of resources used; increase in the speed of data exchange between the host machine and the virtual machine. the results of experimental estimates of the parameters that define the formulated efficiency criteria are given as: processor utilization involved (percentage); the amount of ram involved (gb); initialization time of virtual machines (seconds); time to assemble the component completely (build) and to reassemble the component (watch) (seconds). to improve the efficiency, a file system access driver based on the nfs protocol was studied in the paper.",experimental evaluation of the virtual environment efficiency for distributed software development
860,2-s2.0-85065651973,10.1145/3297280.3297456,NodeMop: Runtime verification for Node.js applications,Schiavio F.,Proceedings of the ACM Symposium on Applied Computing,2019-01-01,"Node.js has become one of the most popular frameworks for general-purpose and server-side application development in JavaScript. However, due to its dynamic, asynchronous, event-driven programming model, Node.js applications are considered error-prone, and their correctness is hard to verify. Monitoring-Oriented Programming (MOP) is a Runtime Verification (RV) paradigm that aims at improving the safety and reliability of a software system. To the best of our knowledge, no practical RV framework targets JavaScript and Node.js applications. In this paper, we introduce NodeMOP, a novel RV framework for JavaScript that allows one to apply RV to Node.js applications. Using NodeMOP, we have formalized two properties related to popular asynchronous APIs based on the Node.js documentation, one from the file-system module and the other from the HTTP module. NodeMOP also supports error recovery by allowing developers to define custom handlers in case of property violations. We showcase NodeMOP with our specified properties on examples of Node.js API misuse. We also evaluate the overhead of NodeMOP with benchmarks based on the introduced examples.",Dynamic Analysis | JavaScript | Monitoring-Oriented Programming | Node.js | Runtime Verification | Self-Healing Systems | Software Verification,4,1794-1801,Conference Proceeding,Conference Paper,5.0,"Schiavio, Filippo;Sun, Haiyang;Bonetta, Daniele;Rosà, Andrea;Binder, Walter",57203943560;57026601800;36647322000;56473303400;7005259851,Oracle Corporation;Università della Svizzera italiana,United States;Switzerland,"node.js has become one of the most popular frameworks for general-purpose and server-side application development in javascript. however, due to its dynamic, asynchronous, event-driven programming model, node.js applications are considered error-prone, and their correctness is hard to verify. monitoring-oriented programming (mop) is a runtime verification (rv) paradigm that aims at improving the safety and reliability of a software system. to the best of our knowledge, no practical rv framework targets javascript and node.js applications. in this paper, we introduce nodemop, a novel rv framework for javascript that allows one to apply rv to node.js applications. using nodemop, we have formalized two properties related to popular asynchronous apis based on the node.js documentation, one from the file-system module and the other from the http module. nodemop also supports error recovery by allowing developers to define custom handlers in case of property violations. we showcase nodemop with our specified properties on examples of node.js api misuse. we also evaluate the overhead of nodemop with benchmarks based on the introduced examples.",nodemop: runtime verification for node.js applications
862,2-s2.0-85065487853,10.1007/978-3-030-19274-7_23,Amalgam: Hardware hacking for web developers with style (sheets),Garza J.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2019-01-01,"Web programming technologies such as HTML, JavaScript, and CSS have become a popular choice for user interface design due to their capabilities: flexible interface, first-class networking, and available libraries. In parallel, driven by the standards set by the mobile companies, embedded devices manufacturers now want to replicate these capabilities. As a result, embedded devices that use web technologies for their graphical interface have started to emerge. However, the programming effort required to integrate web technologies with embedded software hinders its adaption. In this paper, we introduce Amalgam, a system that facilitates the development of embedded devices that use web programming technologies. Amalgam does this by translating the physical interface of embedded hardware components found (e.g., a push button) directly into the HTML and CSS syntax. Our system reduces the programming effort required to develop new embedded devices that use web technologies, as well as adds new interesting capabilities to the design of these. We show Amalgam’s capabilities by exploring three embedded devices built using web programming technologies. Also, we demonstrate how Amalgam reduces programming effort by comparing two traditional approaches of building one of these devices against Amalgam. Results show our system reduces the lines of code required to integrate hardware elements into an embedded device application to a line of code per hardware component added to the device.",CSS | Embedded devices | HTML | IoT | Rapid development | Web user interface,2,315-330,Book Series,Conference Paper,3.0,"Garza, Jorge;Merrill, Devon J.;Swanson, Steven",57208667929;57208303569;16053948700,Department of Computer Science and Engineering,United States,"web programming technologies such as html, javascript, and css have become a popular choice for user interface design due to their capabilities: flexible interface, first-class networking, and available libraries. in parallel, driven by the standards set by the mobile companies, embedded devices manufacturers now want to replicate these capabilities. as a result, embedded devices that use web technologies for their graphical interface have started to emerge. however, the programming effort required to integrate web technologies with embedded software hinders its adaption. in this paper, we introduce amalgam, a system that facilitates the development of embedded devices that use web programming technologies. amalgam does this by translating the physical interface of embedded hardware components found (e.g., a push button) directly into the html and css syntax. our system reduces the programming effort required to develop new embedded devices that use web technologies, as well as adds new interesting capabilities to the design of these. we show amalgam’s capabilities by exploring three embedded devices built using web programming technologies. also, we demonstrate how amalgam reduces programming effort by comparing two traditional approaches of building one of these devices against amalgam. results show our system reduces the lines of code required to integrate hardware elements into an embedded device application to a line of code per hardware component added to the device.",amalgam: hardware hacking for web developers with style (sheets)
863,2-s2.0-85064636910,10.5220/0007556301310142,Decoupling language and editor - The impact of the language server protocol on textual domain-specific languages,Bünder H.,MODELSWARD 2019 - Proceedings of the 7th International Conference on Model-Driven Engineering and Software Development,2019-01-01,"Model-Driven Software Development using Domain-Specific Languages (DSL) has been widely adopted throughout research and industry. The language workbenches required to efficiently build Domain-Specific Languages and the associated editor support are often deeply integrated into a specific Integrated Development Environment (IDE). Thereby, the chosen Domain-Specific Language workbench predicts the IDE required to use the DSL. Yet, this IDE might not be the best choice for further implementing, testing, and debugging the generated code. A case study was conducted to analyze how the Language Server Protocol could be utilized to decouple the DSL implementation from a specific editor integrated into an IDE. First, the Language Server Protocol capabilities are exemplified by building editor support for an Entity-DSL that is integrated into two different IDEs. Second, a SWOT analysis is carried out to identify strengths and weaknesses as well as opportunities and threats for Domain-Specific Languages utilizing the Language Server Protocol. The case study's results indicate that the Language Server Protocol enables efficient multi-editor integration. Further, the results of the SWOT analysis imply potential benefits for cross-functional teams specifying a shared domain model.",Case Study | Language Server Protocol | Model-Driven Development | Textual Domain-Specific Languages,8,131-142,Conference Proceeding,Conference Paper,1.0,"Bünder, Hendrik",57208389667,Itemis AG,Germany,"model-driven software development using domain-specific languages (dsl) has been widely adopted throughout research and industry. the language workbenches required to efficiently build domain-specific languages and the associated editor support are often deeply integrated into a specific integrated development environment (ide). thereby, the chosen domain-specific language workbench predicts the ide required to use the dsl. yet, this ide might not be the best choice for further implementing, testing, and debugging the generated code. a case study was conducted to analyze how the language server protocol could be utilized to decouple the dsl implementation from a specific editor integrated into an ide. first, the language server protocol capabilities are exemplified by building editor support for an entity-dsl that is integrated into two different ides. second, a swot analysis is carried out to identify strengths and weaknesses as well as opportunities and threats for domain-specific languages utilizing the language server protocol. the case study's results indicate that the language server protocol enables efficient multi-editor integration. further, the results of the swot analysis imply potential benefits for cross-functional teams specifying a shared domain model.",decoupling language and editor - the impact of the language server protocol on textual domain-specific languages
864,2-s2.0-85064210438,10.2298/SARH180419074A,A novel method of photogrammetry measurements of study models in orthodontics,Arapović-Savić M.,Srpski Arhiv za Celokupno Lekarstvo,2019-01-01,"Introduction/Objective Rapid developments in information technologies lead to the wider use of digital representations of dental study models in orthodontics. Most popular way of digitizing the models is to use a 3D scanner and then perform measurements on 3D models, which requires additional and expensive hardware and software resources. In this paper we present an alternative approach based on the use of photogrammetry in the newly developed OrthoPhoto4D software that calculates and corrects perspective distortion errors. Methods We measured individual tooth width for 24 teeth, 12 two-teeth segments as well as inter-molar and inter-canine distances on 50 models. Measurements are performed in OrthoPhoto4D software that uses four photographs of each model for measurements, uses QR codes for automation, calculates the camera position and corrects perspective distortion-caused errors in measurements. Obtained measurements are compared to ones obtained from models generated by structured light 3D scanner. Results Statistical analysis strongly indicates that there is no significant difference between the two methods. The recorded differences also have no clinical impact as they have mean values of 0.2 mm for individual tooth widths, approximately 0.2 mm for two teeth segments, and under 0.3 mm for both inter-canine and inter-molar distances. All recorded differences fall within the expected measurement error. Conclusion We concluded that the described photogrammetry measurements performed in OrthoPhoto4D can be used in diagnosis and therapy planning.",3D scanning | Diagnosis | Orthodontics | Photogrammetry | Therapy,2,10-16,Journal,Article,6.0,"Arapović-Savić, Marijana;Savić, Mihajlo;Umićević-Davidović, Mirjana;Arbutina, Adriana;Nedeljković, Nenad;Glišić, Branislav",57208240271;57188989391;57208243740;57208248010;12789358300;6701914487,University of Banja Luka;University of Belgrade;University of Banja,Bosnia and Herzegovina;Serbia;Bosnia and Herzegovina,"introduction/objective rapid developments in information technologies lead to the wider use of digital representations of dental study models in orthodontics. most popular way of digitizing the models is to use a 3d scanner and then perform measurements on 3d models, which requires additional and expensive hardware and software resources. in this paper we present an alternative approach based on the use of photogrammetry in the newly developed orthophoto4d software that calculates and corrects perspective distortion errors. methods we measured individual tooth width for 24 teeth, 12 two-teeth segments as well as inter-molar and inter-canine distances on 50 models. measurements are performed in orthophoto4d software that uses four photographs of each model for measurements, uses qr codes for automation, calculates the camera position and corrects perspective distortion-caused errors in measurements. obtained measurements are compared to ones obtained from models generated by structured light 3d scanner. results statistical analysis strongly indicates that there is no significant difference between the two methods. the recorded differences also have no clinical impact as they have mean values of 0.2 mm for individual tooth widths, approximately 0.2 mm for two teeth segments, and under 0.3 mm for both inter-canine and inter-molar distances. all recorded differences fall within the expected measurement error. conclusion we concluded that the described photogrammetry measurements performed in orthophoto4d can be used in diagnosis and therapy planning.",a novel method of photogrammetry measurements of study models in orthodontics
865,2-s2.0-85063254209,10.1007/978-3-319-95678-7_59,A Support System for Information Management Oriented for the Infant Neurodevelopment Study,Cano-Ortiz S.D.,Lecture Notes in Networks and Systems,2019-01-01,"Since more fifteen years a multidisciplinary and scientific collaboration between Group of Speech Processing (GSP) from Universidad de Oriente and the Medical Consultation for Infant Neurodevelopment and Disability (CPNDI) of Santiago de Cuba have been successfully developed. Notwithstanding the successes and advances of the CPNDI, certain difficulties limit its action and impact as: non automation of the information flow related to the study of neurodevelopment and children’s disability, the delayed detection of some cases of infants who then make their debut with deviations in their neurodevelopment and associated disabilities. Currently, a project is being developed to deploy a Management Computer System of the CPNDI (named PMSIND). This web-based system will need another support system that will allow it to incorporate software packages and diagnostic methodology both linked to the infant cry analysis, which will facilitate an early detection of neonates at risk to be treated later by the CPNDI. The main objective of the paper is the development and implementation of this support system made up of non-proprietary software tool. The support system developed by the authors should not only help to manage the clinical information of the neonate at risk, but also must guarantee the availability of all information with diagnostic value from the Infant Crying Analysis that facilitates the early detection of infants at risk to be followed up by the CPNDI.",Cry analysis | Infant neuro-development outcome | Telemedicine,0,528-535,Book Series,Book Chapter,5.0,"Cano-Ortiz, Sergio Daniel;Martinez-Cañete, Yadisbel;Lombardía-Legrá, Lienys;Langmann, Reinhard;Jacques, Harald",22333427000;57204798781;57204800000;14015755500;57191896363,"Universidad de Oriente;Hochschule Düsseldorf, University of Applied Sciences",Cuba;Germany,"since more fifteen years a multidisciplinary and scientific collaboration between group of speech processing (gsp) from universidad de oriente and the medical consultation for infant neurodevelopment and disability (cpndi) of santiago de cuba have been successfully developed. notwithstanding the successes and advances of the cpndi, certain difficulties limit its action and impact as: non automation of the information flow related to the study of neurodevelopment and children’s disability, the delayed detection of some cases of infants who then make their debut with deviations in their neurodevelopment and associated disabilities. currently, a project is being developed to deploy a management computer system of the cpndi (named pmsind). this web-based system will need another support system that will allow it to incorporate software packages and diagnostic methodology both linked to the infant cry analysis, which will facilitate an early detection of neonates at risk to be treated later by the cpndi. the main objective of the paper is the development and implementation of this support system made up of non-proprietary software tool. the support system developed by the authors should not only help to manage the clinical information of the neonate at risk, but also must guarantee the availability of all information with diagnostic value from the infant crying analysis that facilitates the early detection of infants at risk to be followed up by the cpndi.",a support system for information management oriented for the infant neurodevelopment study
867,2-s2.0-85062906622,10.1007/978-3-030-02577-9_44,On-line Platform for Early Detection of Child Backlog in the Development,Balik A.,Lecture Notes in Networks and Systems,2019-01-01,"Early diagnosis and efficient interventions through educational methods may result in significant progress in early detection of autism spectrum disorder (ASD). The platform presented in this paper represents an on-line and web application for children, in-particular children with ASD. We hope it will help improve their self-esteem, increase their communication and leadership skills. The core concepts of this platform are to help children get rid of impairment of concentration and improve their self-confidence. Our contribution is reflected in the discussion session where we show the strengths and weaknesses of the current learning process and the advantage of here presented application software solution. This paper presents a work in progress and is done in collaboration with the professionals working at an NGO “EDUS Education for All”, program devoted to evidence-based work with children with disabilities.",Autism | Early detection | Education | Educational games,0,446-456,Book Series,Book Chapter,2.0,"Balik, Alican;Ramic-Brkic, Belma",57207794930;32867920700,Sarajevo School of Science and Technology,Bosnia and Herzegovina,"early diagnosis and efficient interventions through educational methods may result in significant progress in early detection of autism spectrum disorder (asd). the platform presented in this paper represents an on-line and web application for children, in-particular children with asd. we hope it will help improve their self-esteem, increase their communication and leadership skills. the core concepts of this platform are to help children get rid of impairment of concentration and improve their self-confidence. our contribution is reflected in the discussion session where we show the strengths and weaknesses of the current learning process and the advantage of here presented application software solution. this paper presents a work in progress and is done in collaboration with the professionals working at an ngo “edus education for all”, program devoted to evidence-based work with children with disabilities.",on-line platform for early detection of child backlog in the development
869,2-s2.0-85061082624,10.1007/978-3-030-02804-6_93,Font-end achievement of extensive innovative services community based on web,Liu Q.,Advances in Intelligent Systems and Computing,2019-01-01,"With the development of technology, computer helps us solve some contradictory problems and it is important to develop a software that helps them have an innovative work. The paper mainly introduces how we develop the software base on web by using font-end technology. To achieve the function of Extensive deduced tree, we use the method of data visualization in combination with Data-Driven Document. Besides, we also achieve the functions of people’s innovative learning and communication by javaScript frameworks to make people have a better way to perform an innovative work. Finally, we also verify the functions by an innovative case and introduce our future work.",Extenics | Font-end development | Innovative work,0,714-721,Book Series,Conference Paper,5.0,"Liu, Qiubin;Fan, Rui;Guo, Bifeng;Li, Zihao;Wu, Enna",57205683450;26867580400;57204287547;57205684880;57205681366,Guangdong Ocean University,China,"with the development of technology, computer helps us solve some contradictory problems and it is important to develop a software that helps them have an innovative work. the paper mainly introduces how we develop the software base on web by using font-end technology. to achieve the function of extensive deduced tree, we use the method of data visualization in combination with data-driven document. besides, we also achieve the functions of people’s innovative learning and communication by javascript frameworks to make people have a better way to perform an innovative work. finally, we also verify the functions by an innovative case and introduce our future work.",font-end achievement of extensive innovative services community based on web
871,2-s2.0-85057110618,10.1007/978-3-030-01174-1_52,Selection of architectural concept and development technologies for the implementation of a web-based platform for psychology research,Nikulchev E.,Advances in Intelligent Systems and Computing,2019-01-01,"This paper considers the design and development of a web-based platform for conducting psychological online research. As a result, a scalable multicomponent platform architecture is formed, implying the separation into a public and private Intranet parts. To organize communication between components, it is intended to use the REST API. The basic unit of data transmission for experiments is a package that allows ensuring the autonomy of the online tool in conditions of poor Internet connection. A technological stack is selected, which includes the use of JavaScript and AngularJS 1 for the client part, Node.JS and Loopback for the server.",Psychology research | Requirement analysis | Software architecture | Web framework evaluation | Web-based platform,3,672-685,Book Series,Conference Paper,6.0,"Nikulchev, Evgeny;Kolyasnikov, Pavel;Ilin, Dmitry;Kasatonov, Sergey;Biryukov, Dmitry;Zakharov, Ilya",6504081534;57204774687;57203848706;57204778956;56964951100;55570438400,MIREA - Russian Technological University (RTU MIREA);Russian Academy of Education,Russian Federation;Russian Federation,"this paper considers the design and development of a web-based platform for conducting psychological online research. as a result, a scalable multicomponent platform architecture is formed, implying the separation into a public and private intranet parts. to organize communication between components, it is intended to use the rest api. the basic unit of data transmission for experiments is a package that allows ensuring the autonomy of the online tool in conditions of poor internet connection. a technological stack is selected, which includes the use of javascript and angularjs 1 for the client part, node.js and loopback for the server.",selection of architectural concept and development technologies for the implementation of a web-based platform for psychology research
872,2-s2.0-85051833413,10.1007/978-3-319-97679-2_25,Authoring technological and platform independent learning material and student’s progress profile using web services,Papadimitriou S.,"Smart Innovation, Systems and Technologies",2019-01-01,"Nowadays the rapid development of computer and Internet technologies in the field of education has changed the ways of teaching and learning. The production of adaptive educational applications and systems that enrich the tutoring and learning processes with “intelligence”, in order to adapt either the learning material or the tutoring and learning processes to each individual student’s needs and abilities, offering her/him a personalized learning experience. However, building an adaptive educational environment and/or application is difficult and complex, since either technical knowledge and programming skills or the expertise of tutors are demanded. In this paper an authoring tool, which offers the instructors the possibility to create learning material and student’s profile that are technological and platform independent, is presented. The innovative operation of the presented authoring tool is based on web services and is due to the following facts: (i) the created learning content can be used by any educational application regardless of the system’s technological characteristics or programming language, (ii) the created progress profile of a student, who uses two different educational applications that call the same web services of the authoring tool, is recognized by both applications. Therefore, if the knowledge level of a student is changing during her/his interaction with the one application, then the other application will, also, recognize the updated knowledge level of the particular student.",Authoring tools | Educational applications | Educational games | Student profiling | Web services,0,242-251,Book Series,Conference Paper,3.0,"Papadimitriou, Spyros;Chrysafiadi, Konstantina;Virvou, Maria",56370875500;16229548500;7003569675,University of Piraeus,Greece,"nowadays the rapid development of computer and internet technologies in the field of education has changed the ways of teaching and learning. the production of adaptive educational applications and systems that enrich the tutoring and learning processes with “intelligence”, in order to adapt either the learning material or the tutoring and learning processes to each individual student’s needs and abilities, offering her/him a personalized learning experience. however, building an adaptive educational environment and/or application is difficult and complex, since either technical knowledge and programming skills or the expertise of tutors are demanded. in this paper an authoring tool, which offers the instructors the possibility to create learning material and student’s profile that are technological and platform independent, is presented. the innovative operation of the presented authoring tool is based on web services and is due to the following facts: (i) the created learning content can be used by any educational application regardless of the system’s technological characteristics or programming language, (ii) the created progress profile of a student, who uses two different educational applications that call the same web services of the authoring tool, is recognized by both applications. therefore, if the knowledge level of a student is changing during her/his interaction with the one application, then the other application will, also, recognize the updated knowledge level of the particular student.",authoring technological and platform independent learning material and student’s progress profile using web services
873,2-s2.0-85048121338,10.1016/bs.adcom.2018.10.005,Three Open Problems in the Context of E2E Web Testing and a Vision: NEONATE,Ricca F.,Advances in Computers,2019-01-01,"Web applications are critical assets of our society and thus assuring their quality is of undeniable importance. Despite the advances in software testing, the ever-increasing technological complexity of these applications makes it difficult to prevent errors. In this work, we provide a thorough description of the three open problems hindering web test automation: fragility problem, strong coupling and low cohesion problem, and incompleteness problem. We conjecture that a major breakthrough in test automation is needed, because the problems are closely correlated, and hence need to be attacked together rather than separately. To this aim, we describe NEONATE, a novel integrated testing environment specifically designed to empower the web tester. Our utmost purpose is to make the research community aware of the existence of the three problems and their correlation, so that more research effort can be directed in providing solutions and tools to advance the state of the art of web test automation.",Development effort | End-to-end testing | Maintenance effort | Page object pattern | Reverse engineering | Robust locators | Selenium | Web testing,8,89-133,Book Series,Book Chapter,3.0,"Ricca, Filippo;Leotta, Maurizio;Stocco, Andrea",24822686600;37104276100;36882807000,"Dipartimento di Informatica, Bioingegneria, Robotica e Ingegneria dei Sistemi;The University of British Columbia",Italy;Canada,"web applications are critical assets of our society and thus assuring their quality is of undeniable importance. despite the advances in software testing, the ever-increasing technological complexity of these applications makes it difficult to prevent errors. in this work, we provide a thorough description of the three open problems hindering web test automation: fragility problem, strong coupling and low cohesion problem, and incompleteness problem. we conjecture that a major breakthrough in test automation is needed, because the problems are closely correlated, and hence need to be attacked together rather than separately. to this aim, we describe neonate, a novel integrated testing environment specifically designed to empower the web tester. our utmost purpose is to make the research community aware of the existence of the three problems and their correlation, so that more research effort can be directed in providing solutions and tools to advance the state of the art of web test automation.",three open problems in the context of e2e web testing and a vision: neonate
874,2-s2.0-85047495166,10.1007/978-3-319-91008-6_37,Deobfuscation of computer virus malware code with value state dependence graph,Dychka I.,Advances in Intelligent Systems and Computing,2019-01-01,"This paper deals with improvement of malware protection efficiency. The analysis of applied scientific research on malware protection development has shown that improvement of the methods for deobfuscation of program code being analyzed is one of the main means of increasing efficiency of malware recognition. This paper demonstrates that the main drawback of the modern-day deobfuscation methods is that they are insufficiently adapted to the formalized presentation of the functional semantics of programs being tested. Based on the research results, we suggest that theoretical solutions which have been tried out in program code optimization procedures may be used for code deobfuscation. In the course of the study, we have developed a program code deobfuscation procedure utilizing a value state dependence graph. Utilization of the developed procedure was found to enable presentation of the functional semantics of the programs being tested in a graph form. As the result, identification of malware based on its execution semantics became possible. The paper shows that further research should focus on the development of a method for comparison of the value state dependence graph of the program being tested with corresponding graphs of security software and malware.",Code optimization | Deobfuscation | Malware | Value state dependence graph,14,370-379,Book Series,Conference Paper,5.0,"Dychka, Ivan;Tereikovskyi, Ihor;Tereikovska, Liudmyla;Pogorelov, Volodymyr;Mussiraliyeva, Shynar",55825827900;57195940293;57198815503;57195936190;57202216979,Kyiv National University of Construction and Architecture;Al Farabi Kazakh National University;National Technical University of Ukraine “Igor Sikorsky Kyiv Polytechnic Institute”,Ukraine;Kazakhstan;Ukraine,"this paper deals with improvement of malware protection efficiency. the analysis of applied scientific research on malware protection development has shown that improvement of the methods for deobfuscation of program code being analyzed is one of the main means of increasing efficiency of malware recognition. this paper demonstrates that the main drawback of the modern-day deobfuscation methods is that they are insufficiently adapted to the formalized presentation of the functional semantics of programs being tested. based on the research results, we suggest that theoretical solutions which have been tried out in program code optimization procedures may be used for code deobfuscation. in the course of the study, we have developed a program code deobfuscation procedure utilizing a value state dependence graph. utilization of the developed procedure was found to enable presentation of the functional semantics of the programs being tested in a graph form. as the result, identification of malware based on its execution semantics became possible. the paper shows that further research should focus on the development of a method for comparison of the value state dependence graph of the program being tested with corresponding graphs of security software and malware.",deobfuscation of computer virus malware code with value state dependence graph
875,2-s2.0-85044463066,10.1016/bs.adcom.2018.03.015,Mutation Testing Advances: An Analysis and Survey,Papadakis M.,Advances in Computers,2019-01-01,"Mutation testing realizes the idea of using artificial defects to support testing activities. Mutation is typically used as a way to evaluate the adequacy of test suites, to guide the generation of test cases, and to support experimentation. Mutation has reached a maturity phase and gradually gains popularity both in academia and in industry. This chapter presents a survey of recent advances, over the past decade, related to the fundamental problems of mutation testing and sets out the challenges and open problems for the future development of the method. It also collects advices on best practices related to the use of mutation in empirical studies of software testing. Thus, giving the reader a “mini-handbook”-style roadmap for the application of mutation testing as experimental methodology.",Mutation testing | Seeded faults | Software testing | Survey,187,275-378,Book Series,Article,6.0,"Papadakis, Mike;Kintis, Marinos;Zhang, Jie;Jia, Yue;Traon, Yves Le;Harman, Mark",57197295611;36810018600;36505536200;25822621600;55884641800;7006379048,University of Luxembourg;University College London;Peking University,Luxembourg;United Kingdom;China,"mutation testing realizes the idea of using artificial defects to support testing activities. mutation is typically used as a way to evaluate the adequacy of test suites, to guide the generation of test cases, and to support experimentation. mutation has reached a maturity phase and gradually gains popularity both in academia and in industry. this chapter presents a survey of recent advances, over the past decade, related to the fundamental problems of mutation testing and sets out the challenges and open problems for the future development of the method. it also collects advices on best practices related to the use of mutation in empirical studies of software testing. thus, giving the reader a “mini-handbook”-style roadmap for the application of mutation testing as experimental methodology.",mutation testing advances: an analysis and survey
878,2-s2.0-85061056800,10.1109/ASWEC.2018.00029,Experience building IT infrastructure for research with online youth mental health tools,Warren J.,"Proceedings - 25th Australasian Software Engineering Conference, ASWEC 2018",2018-12-24,"There is great potential for online tools to be helpful for youth mental health, but equally there are many open research questions requiring field trials. Such research places considerable demands on IT infrastructure to provide appropriate data management, and to be maintainable and scalable through iterations of studies. We report experience building an IT infrastructure for research with online tools for youth mental health. The aim is to create a platform that enables an 'ecosystem' of youth mental health software to be available for field trials and beneficial usage. Key services of the platform include identity management, health assessment storage and reasoning, usage logging, and clinical trial consent and randomisation. This paper reports initial design of the platform, first field tests and ongoing iterative development.",Consumer health | Electronic therapy | Software architecture,3,161-165,Conference Proceeding,Conference Paper,7.0,"Warren, Jim;Tempero, Ewan;Warren, Ian;Sathianathan, Anjuka;Hopkins, Sarah;Shepherd, Matthew;Merry, Sally",7402212366;6602143229;57210658484;57205670314;36082776200;54923170400;7005026223,The University of Auckland,New Zealand,"there is great potential for online tools to be helpful for youth mental health, but equally there are many open research questions requiring field trials. such research places considerable demands on it infrastructure to provide appropriate data management, and to be maintainable and scalable through iterations of studies. we report experience building an it infrastructure for research with online tools for youth mental health. the aim is to create a platform that enables an 'ecosystem' of youth mental health software to be available for field trials and beneficial usage. key services of the platform include identity management, health assessment storage and reasoning, usage logging, and clinical trial consent and randomisation. this paper reports initial design of the platform, first field tests and ongoing iterative development.",experience building it infrastructure for research with online youth mental health tools
879,2-s2.0-85060373013,10.1109/IAEAC.2018.8577889,Design and implementation of knowledge sharing system based on WeChat small program,Gu X.,"Proceedings of 2018 IEEE 3rd Advanced Information Technology, Electronic and Automation Control Conference, IAEAC 2018",2018-12-14,"Aiming at the needs and characteristics of the development of knowledge sharing, this paper designs and realizes the solution of knowledge sharing with the rise of the sharing economy as the background and the small program as the carrier. According to functions, the knowledge sharing system can be divided into six modules: video resource module, article resource module, question answering module, credits module, auditing module and recommendation module. The system adopts the C/S (client/server) architecture as the overall architecture. The backend relies on the tencent cloud server and the platform functions was accomplished through Java, JavaScript, MySQL database and the special languages of WeChat small program: WXML and WXSS. The classical collaborative filtering algorithm is used to recommend different resources to different users. This small program meets the user's need to acquire knowledge anytime and anywhere. It effectively solves the present problems in knowledge sharing and has great significance to the further development.",collaborative filtering algorithm | Java | knowledge sharing | Wechat small program,3,2242-2246,Conference Proceeding,Conference Paper,3.0,"Gu, Xiaoxi;Yang, Lingjun;Cao, Sanxing",57201989781;55560095500;55491019900,Communication University of China,China,"aiming at the needs and characteristics of the development of knowledge sharing, this paper designs and realizes the solution of knowledge sharing with the rise of the sharing economy as the background and the small program as the carrier. according to functions, the knowledge sharing system can be divided into six modules: video resource module, article resource module, question answering module, credits module, auditing module and recommendation module. the system adopts the c/s (client/server) architecture as the overall architecture. the backend relies on the tencent cloud server and the platform functions was accomplished through java, javascript, mysql database and the special languages of wechat small program: wxml and wxss. the classical collaborative filtering algorithm is used to recommend different resources to different users. this small program meets the user's need to acquire knowledge anytime and anywhere. it effectively solves the present problems in knowledge sharing and has great significance to the further development.",design and implementation of knowledge sharing system based on wechat small program
881,2-s2.0-85063217631,10.1109/INCISCOS.2018.00058,"Implementation of a system for the administration, configuration and monitoring of parking areas",Avalos H.,"Proceedings - 3rd International Conference on Information Systems and Computer Science, INCISCOS 2018",2018-12-05,"This paper presents the development of an intelligent web system for the administration, configuration and monitoring of free parking spaces in private open areas using free software tools. There are several ways and methods to monitor free parking areas. The method used in this work used surveillance cameras in order to reduce costs because the institution already has its own surveillance system. The first phase of the system corresponds to the development of the application server, which will manage the data and information of all the parking spaces and retrieve the states of these to show them to the end user and also to share them with the module of the mobile application. The server is built in Java using REST API and was assembled inside a Payara server, with a security module based on a token to avoid non-scalability of the application. The second phase of the system is focused on the user so that it has ease of use and can be administered quickly as it is the goal of the system. The client is developed in JavaScript using the Angular framework from Google.",Intelligent web system | Mobile application | Parking | Payara server,0,356-360,Conference Proceeding,Conference Paper,4.0,"Avalos, Hector;Gomez, Estevan;Ordonez-Camacho, Diego;Taipe, Oswaldo",57205706796;57200380878;57216416228;57207915589,Universidad UTE,Ecuador,"this paper presents the development of an intelligent web system for the administration, configuration and monitoring of free parking spaces in private open areas using free software tools. there are several ways and methods to monitor free parking areas. the method used in this work used surveillance cameras in order to reduce costs because the institution already has its own surveillance system. the first phase of the system corresponds to the development of the application server, which will manage the data and information of all the parking spaces and retrieve the states of these to show them to the end user and also to share them with the module of the mobile application. the server is built in java using rest api and was assembled inside a payara server, with a security module based on a token to avoid non-scalability of the application. the second phase of the system is focused on the user so that it has ease of use and can be administered quickly as it is the goal of the system. the client is developed in javascript using the angular framework from google.","implementation of a system for the administration, configuration and monitoring of parking areas"
883,2-s2.0-85060269604,10.1109/SmartWorld.2018.00273,Interactive bulk synchronous parallel functional programming in a browser,Tesson J.,"Proceedings - 2018 IEEE SmartWorld, Ubiquitous Intelligence and Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People and Smart City Innovations, SmartWorld/UIC/ATC/ScalCom/CBDCom/IoP/SCI 2018",2018-12-04,"This paper presents the design and implementation of a sequential simulator for the parallel functional language BSML based on the parallel computation model Bulk Synchronous Parallelism (BSP). This simulator is implemented in sequential, runs in any browser, and provides a graphical representation of the parallel executions. Due to the pure functional nature of BSML, the results obtained by this simulator are the same than the results that could be obtained by executing the program in parallel.",Functional programming | High performance computing | Parallel programming | Software development tools and support,0,1593-1598,Conference Proceeding,Conference Paper,2.0,"Tesson, Julien;Loulergue, Frederic",24385840500;55934882800,Université Paris-Est Créteil;Northern Arizona University,France;United States,"this paper presents the design and implementation of a sequential simulator for the parallel functional language bsml based on the parallel computation model bulk synchronous parallelism (bsp). this simulator is implemented in sequential, runs in any browser, and provides a graphical representation of the parallel executions. due to the pure functional nature of bsml, the results obtained by this simulator are the same than the results that could be obtained by executing the program in parallel.",interactive bulk synchronous parallel functional programming in a browser
884,2-s2.0-85060007975,10.1145/3274694.3274728,Pointing in the right direction - Securing memory accesses in a faulty world,Schilling R.,ACM International Conference Proceeding Series,2018-12-03,"Reading and writing memory are, besides computation, the most common operations a processor performs. The correctness of these operations is therefore essential for the proper execution of any program. However, as soon as fault attacks are considered, assuming that the hardware performs its memory operations as instructed is not valid anymore. In particular, attackers may induce faults with the goal of reading or writing incorrectly addressed memory, which can have various critical safety and security implications. In this work, we present a solution to this problem and propose a new method for protecting every memory access inside a program against address tampering. The countermeasure comprises two building blocks. First, every pointer inside the program is redundantly encoded using a multi-residue error detection code. The redundancy information is stored in the unused upper bits of the pointer with zero overhead in terms of storage. Second, load and store instructions are extended to link data with the corresponding encoded address from the pointer. Wrong memory accesses subsequently infect the data value allowing the software to detect the error. For evaluation purposes, we implemented our countermeasure into a RISC-V processor, tested it on a FPGA development board, and evaluated the induced overhead. Furthermore, a LLVM-based C compiler has been modied to automatically encode all data pointers, to perform encoded pointer arithmetic, and to emit the extended load/store instructions with linking support. Our evaluations show that the countermeasure induces an average overhead of 10 % in terms of code size and 7 % regarding runtime, which makes it suitable for practical adoption.",Countermeasure | Fault attacks | Memory access | Pointer protection,7,595-604,Conference Proceeding,Conference Paper,4.0,"Schilling, Robert;Nasahl, Pascal;Werner, Mario;Mangard, Stefan",56435513200;57205434899;55431580900;8840189200,Technische Universitat Graz,Austria,"reading and writing memory are, besides computation, the most common operations a processor performs. the correctness of these operations is therefore essential for the proper execution of any program. however, as soon as fault attacks are considered, assuming that the hardware performs its memory operations as instructed is not valid anymore. in particular, attackers may induce faults with the goal of reading or writing incorrectly addressed memory, which can have various critical safety and security implications. in this work, we present a solution to this problem and propose a new method for protecting every memory access inside a program against address tampering. the countermeasure comprises two building blocks. first, every pointer inside the program is redundantly encoded using a multi-residue error detection code. the redundancy information is stored in the unused upper bits of the pointer with zero overhead in terms of storage. second, load and store instructions are extended to link data with the corresponding encoded address from the pointer. wrong memory accesses subsequently infect the data value allowing the software to detect the error. for evaluation purposes, we implemented our countermeasure into a risc-v processor, tested it on a fpga development board, and evaluated the induced overhead. furthermore, a llvm-based c compiler has been modied to automatically encode all data pointers, to perform encoded pointer arithmetic, and to emit the extended load/store instructions with linking support. our evaluations show that the countermeasure induces an average overhead of 10 % in terms of code size and 7 % regarding runtime, which makes it suitable for practical adoption.",pointing in the right direction - securing memory accesses in a faulty world
888,2-s2.0-85055213369,10.1016/j.robot.2018.10.001,Microservice-based cloud robotics system for intelligent space,Xia C.,Robotics and Autonomous Systems,2018-12-01,"Cloud robotics (CR) is a red-hot branch of the burgeoning field of service robots that is centered on the benefits of integrating infrastructure and shared services via a cloud computing environment. Although it extends the computation power and information sharing capabilities of the network robots, the development and operations (DevOps) of the CR system are currently limited for enterprise-scale projects due to the heavy framework. In fact, current developed CR systems are typical distributed monomer architectures followed by a “top-down” design. As the scale of the applications gets larger, the operation and maintenance of CR systems will become a very difficult task. In this paper, a new architecture for a microservice-based cloud robotics system in intelligent space is proposed to solve the present dilemma. To enable this, we design a service management architecture based on a microservice to provide a highly efficient and flexible development/deployment mechanism. The container technology based on the docker engine is then used to functionally decompose the application into a set of collaborating services to ensure the software design methods, based on microservice, easy for implementation. Finally, a real experiment on SLAM (Simulation localization and mapping) in an intelligent space is implemented to verify the proposed architecture. Compared with traditional monomer architectures, the results show that the proposed framework is more productive, flexible and cost effective.",Cloud computing | Cloud robotics | Container technology | Intelligent space | Microservice | Visual SLAM,17,139-150,Journal,Article,5.0,"Xia, Chongkun;Zhang, Yunzhou;Wang, Lei;Coleman, Sonya;Liu, Yanbo",57200148752;55910528700;57207493006;7201402808;57204327470,"College of Information Science and Engineering, Northeastern University;Ulster University",China;United Kingdom,"cloud robotics (cr) is a red-hot branch of the burgeoning field of service robots that is centered on the benefits of integrating infrastructure and shared services via a cloud computing environment. although it extends the computation power and information sharing capabilities of the network robots, the development and operations (devops) of the cr system are currently limited for enterprise-scale projects due to the heavy framework. in fact, current developed cr systems are typical distributed monomer architectures followed by a “top-down” design. as the scale of the applications gets larger, the operation and maintenance of cr systems will become a very difficult task. in this paper, a new architecture for a microservice-based cloud robotics system in intelligent space is proposed to solve the present dilemma. to enable this, we design a service management architecture based on a microservice to provide a highly efficient and flexible development/deployment mechanism. the container technology based on the docker engine is then used to functionally decompose the application into a set of collaborating services to ensure the software design methods, based on microservice, easy for implementation. finally, a real experiment on slam (simulation localization and mapping) in an intelligent space is implemented to verify the proposed architecture. compared with traditional monomer architectures, the results show that the proposed framework is more productive, flexible and cost effective.",microservice-based cloud robotics system for intelligent space
889,2-s2.0-85053421094,10.1002/spe.2637,Work practices and challenges in continuous integration: A survey with Travis CI users,Pinto G.,Software - Practice and Experience,2018-12-01,"Continuous integration (CI) is a software development practice that has been gaining increasing popularity in the last few years. However, we still miss a collection of experiences regarding how software developers perceive the idea of CI, in terms of its fundamental concepts, the reasons that motivate the adoption of this practice, the reasons for build breakage, and the benefits and problems related to CI. To shed light on this direction, we conducted a user survey with 158 CI users. Through a mostly qualitative investigation, we produce a list of findings that are not always obvious. For instance, we observed that (1) developers are not sure whether a job failure represents a failure or not; (2) inadequate testing is the most common technical reason related to build breakage, whereas lack of time plays a role on the social reasons; and (3) although some respondents reported that CI systems increase the confidence that the code is in a known state, some respondents also reported that there is a false sense of confidence when blindly trusting tests. This empirical study is particularly relevant to those interested in better understanding and fostering CI practices either in an open-source or industrial setting.",build breakage | continuous integration | Travis CI | user survey,9,2223-2236,Journal,Article,4.0,"Pinto, Gustavo;Castor, Fernando;Bonifacio, Rodrigo;Rebouças, Marcel",54941690500;54945662000;23003728900;57195151958,Universidade de Brasília;Universidade de Pernambuco;Universidade Federal do Pará;Inloco Company,Brazil;Brazil;Brazil;Brazil,"continuous integration (ci) is a software development practice that has been gaining increasing popularity in the last few years. however, we still miss a collection of experiences regarding how software developers perceive the idea of ci, in terms of its fundamental concepts, the reasons that motivate the adoption of this practice, the reasons for build breakage, and the benefits and problems related to ci. to shed light on this direction, we conducted a user survey with 158 ci users. through a mostly qualitative investigation, we produce a list of findings that are not always obvious. for instance, we observed that (1) developers are not sure whether a job failure represents a failure or not; (2) inadequate testing is the most common technical reason related to build breakage, whereas lack of time plays a role on the social reasons; and (3) although some respondents reported that ci systems increase the confidence that the code is in a known state, some respondents also reported that there is a false sense of confidence when blindly trusting tests. this empirical study is particularly relevant to those interested in better understanding and fostering ci practices either in an open-source or industrial setting.",work practices and challenges in continuous integration: a survey with travis ci users
891,2-s2.0-85050880661,10.1016/j.infsof.2018.07.007,Diversification and obfuscation techniques for software security: A systematic literature review,Hosseinzadeh S.,Information and Software Technology,2018-12-01,"Context: Diversification and obfuscation are promising techniques for securing software and protecting computers from harmful malware. The goal of these techniques is not removing the security holes, but making it difficult for the attacker to exploit security vulnerabilities and perform successful attacks. Objective: There is an increasing body of research on the use of diversification and obfuscation techniques for improving software security; however, the overall view is scattered and the terminology is unstructured. Therefore, a coherent review gives a clear statement of state-of-the-art, normalizes the ongoing discussion and provides baselines for future research. Method: In this paper, systematic literature review is used as the method of the study to select the studies that discuss diversification/obfuscation techniques for improving software security. We present the process of data collection, analysis of data, and report the results. Results: As the result of the systematic search, we collected 357 articles relevant to the topic of our interest, published between the years 1993 and 2017. We studied the collected articles, analyzed the extracted data from them, presented classification of the data, and enlightened the research gaps. Conclusion: The two techniques have been extensively used for various security purposes and impeding various types of security attacks. There exist many different techniques to obfuscate/diversify programs, each of which targets different parts of the programs and is applied at different phases of software development life-cycle. Moreover, we pinpoint the research gaps in this field, for instance that there are still various execution environments that could benefit from these two techniques, including cloud computing, Internet of Things (IoT), and trusted computing. We also present some potential ideas on applying the techniques on the discussed environments.",Diversification | Obfuscation | Software security | Systematic literature review,37,72-93,Journal,Review,7.0,"Hosseinzadeh, Shohreh;Rauti, Sampsa;Laurén, Samuel;Mäkelä, Jari Matti;Holvitie, Johannes;Hyrynsalmi, Sami;Leppänen, Ville",56715442300;55481526000;56715901600;35932145300;55091175400;50361307000;23397050500,Tampere University;Turun yliopisto,Finland;Finland,"context: diversification and obfuscation are promising techniques for securing software and protecting computers from harmful malware. the goal of these techniques is not removing the security holes, but making it difficult for the attacker to exploit security vulnerabilities and perform successful attacks. objective: there is an increasing body of research on the use of diversification and obfuscation techniques for improving software security; however, the overall view is scattered and the terminology is unstructured. therefore, a coherent review gives a clear statement of state-of-the-art, normalizes the ongoing discussion and provides baselines for future research. method: in this paper, systematic literature review is used as the method of the study to select the studies that discuss diversification/obfuscation techniques for improving software security. we present the process of data collection, analysis of data, and report the results. results: as the result of the systematic search, we collected 357 articles relevant to the topic of our interest, published between the years 1993 and 2017. we studied the collected articles, analyzed the extracted data from them, presented classification of the data, and enlightened the research gaps. conclusion: the two techniques have been extensively used for various security purposes and impeding various types of security attacks. there exist many different techniques to obfuscate/diversify programs, each of which targets different parts of the programs and is applied at different phases of software development life-cycle. moreover, we pinpoint the research gaps in this field, for instance that there are still various execution environments that could benefit from these two techniques, including cloud computing, internet of things (iot), and trusted computing. we also present some potential ideas on applying the techniques on the discussed environments.",diversification and obfuscation techniques for software security: a systematic literature review
892,2-s2.0-85044362972,10.1007/s10664-018-9613-x,Factors and actors leading to the adoption of a JavaScript framework,Pano A.,Empirical Software Engineering,2018-12-01,"The increasing popularity of JavaScript has led to a variety of JavaScript frameworks that aim to help developers to address programming tasks. However, the number of JavaScript frameworks has risen rapidly to thousands of versions. It is challenging for practitioners to identify the frameworks that best fit their needs and to develop new ones which fit such needs. Furthermore, there is a lack of knowledge regarding what drives developers toward the choice. This paper explores the factors and actors that lead to the choice of a JavaScript framework. We conducted a qualitative interpretive study of semi-structured interviews. We interviewed 18 decision makers regarding the JavaScript framework selection, up to reaching theoretical saturation. Through coding of the interview responses, we offer a model of desirable JavaScript framework adoption factors. The factors are grouped into categories that are derived via the Unified Theory of Acceptance and Use of Technology. The factors are performance expectancy (performance, size), effort expectancy (automatization, learnability, complexity, understandability), social influence (competitor analysis, collegial advice, community size, community responsiveness), facilitating conditions (suitability, updates, modularity, isolation, extensibility), and price value. A combination of four actors, which are customer, developer, team, and team leader, leads to the choice. Our model contributes to the body of knowledge related to the adoption of technology by software engineers. As a practical implication, our model is useful for decision makers when evaluating JavaScript frameworks, as well as for developers for producing desirable frameworks.",Decision making | Human aspects of software development | Interpretivism | JavaScript | Programming frameworks | Qualitative research | Technology adoption,10,3503-3534,Journal,Article,3.0,"Pano, Amantia;Graziotin, Daniel;Abrahamsson, Pekka",57201332168;55872109600;7006011356,University of Jyväskylä;Universität Stuttgart;Free University of Bozen-Bolzano,Finland;Germany;Italy,"the increasing popularity of javascript has led to a variety of javascript frameworks that aim to help developers to address programming tasks. however, the number of javascript frameworks has risen rapidly to thousands of versions. it is challenging for practitioners to identify the frameworks that best fit their needs and to develop new ones which fit such needs. furthermore, there is a lack of knowledge regarding what drives developers toward the choice. this paper explores the factors and actors that lead to the choice of a javascript framework. we conducted a qualitative interpretive study of semi-structured interviews. we interviewed 18 decision makers regarding the javascript framework selection, up to reaching theoretical saturation. through coding of the interview responses, we offer a model of desirable javascript framework adoption factors. the factors are grouped into categories that are derived via the unified theory of acceptance and use of technology. the factors are performance expectancy (performance, size), effort expectancy (automatization, learnability, complexity, understandability), social influence (competitor analysis, collegial advice, community size, community responsiveness), facilitating conditions (suitability, updates, modularity, isolation, extensibility), and price value. a combination of four actors, which are customer, developer, team, and team leader, leads to the choice. our model contributes to the body of knowledge related to the adoption of technology by software engineers. as a practical implication, our model is useful for decision makers when evaluating javascript frameworks, as well as for developers for producing desirable frameworks.",factors and actors leading to the adoption of a javascript framework
894,2-s2.0-85060851117,10.1145/3291533.3291581,Development of a prototype ISO-compliant quality assurance system for a university,Chalaris M.,ACM International Conference Proceeding Series,2018-11-29,"Difficulties in developing efficient administrative services (e.g. student care, interconnection with the labor market and quality assurance) due to understaffing are considered among the most important problems that limit the effectiveness of higher education institutes. This is emphasized in the latest Hellenic Quality Assurance & Accreditation Agency (HQA) report [15] and leads to the necessity for the existence and utilization of an internal Quality Assurance System that will monitor the alignment of objectives with the long-term academic performance. The commitment of each University according Quality must be reflected and confirmed through the processes and procedures of the Internal Quality Assurance System (IQAS), which is reasonably drafted, implemented and reviewed on a yearly basis. The purpose of the ESDP is to provide the institutions and members of the academic community with a framework for the achievement of the aims and objectives of the Institution in terms of quality and more specifically the achievement of high quality in its operation, the continuous improvement of educational and research work, as well as the efficient operation and performance of its services in accordance with international practices, in particular those of the European Higher Education Area and the principles and guidelines of the HQA. HQA has already imposed the development and use of IQAS by sending appropriate instructions and organizing its certification actions for all Greek universities. If the IQAS is supported by appropriate software, its implementation and exploitation is facilitated, with positive side effects for all involved. The purpose of this paper is to capture the basic features of the development of the prototype of such an open source IQAS, compatible with the HQA and ISO guidelines, so that it can then be used, modified and certified on a more professional basis.",Ajax | B.P.M.N | CKEditor | Higher Education Institutes | ISO 2015 | JavaScript | JQuery | MySQL | PHP | Quality Assurance Evaluation Procedures | Quality Management Systems,0,103-106,Conference Proceeding,Conference Paper,3.0,"Chalaris, Manolis;Karamichalelis, Fanis;Chalaris, Ioannis",54396798800;57216466973;8935318900,University of the Aegean;University of Washington,Greece;United States,"difficulties in developing efficient administrative services (e.g. student care, interconnection with the labor market and quality assurance) due to understaffing are considered among the most important problems that limit the effectiveness of higher education institutes. this is emphasized in the latest hellenic quality assurance & accreditation agency (hqa) report [15] and leads to the necessity for the existence and utilization of an internal quality assurance system that will monitor the alignment of objectives with the long-term academic performance. the commitment of each university according quality must be reflected and confirmed through the processes and procedures of the internal quality assurance system (iqas), which is reasonably drafted, implemented and reviewed on a yearly basis. the purpose of the esdp is to provide the institutions and members of the academic community with a framework for the achievement of the aims and objectives of the institution in terms of quality and more specifically the achievement of high quality in its operation, the continuous improvement of educational and research work, as well as the efficient operation and performance of its services in accordance with international practices, in particular those of the european higher education area and the principles and guidelines of the hqa. hqa has already imposed the development and use of iqas by sending appropriate instructions and organizing its certification actions for all greek universities. if the iqas is supported by appropriate software, its implementation and exploitation is facilitated, with positive side effects for all involved. the purpose of this paper is to capture the basic features of the development of the prototype of such an open source iqas, compatible with the hqa and iso guidelines, so that it can then be used, modified and certified on a more professional basis.",development of a prototype iso-compliant quality assurance system for a university
895,2-s2.0-85059616927,10.1109/ISSRE.2018.00020,Search-Based Test Data Generation for JavaScript Functions that Interact with the DOM,Elyasov A.,"Proceedings - International Symposium on Software Reliability Engineering, ISSRE",2018-11-16,"The popularity of JavaScript (JS) is enormous. Together with HTML and CSS, it is the core technology for modern web development. Because of the dynamic nature and complex interplay with HTML, JS applications are often error-prone and vulnerable. Despite active research efforts to devise intricate static and dynamic analyses to facilitate JS testing, the problem of test data generation for JS code interacting with the DOM has not yet been addressed. In this paper, we present a Javascript Evolutionary testing framework with DOM as an Input, called JEDI. In order to reach a target branch, it applies genetic search for relevant input parameters of the JS function in combination with the global DOM state. We conducted an empirical evaluation to study the effectiveness and efficiency of our testing framework. It shows that the genetic with restart algorithm, proposed in this paper, is able to achieve complete branch coverage for all experimental subjects, taking on average 19 seconds per branch.",Branch coverage | DOM | Genetic algorithms | JavaScript | Search-based testing,4,88-99,Conference Proceeding,Conference Paper,3.0,"Elyasov, Alexander;Prasetya, I. S.W.B.;Hage, Jurriaan",55321178000;8980537400;7102834716,Universiteit Utrecht,Netherlands,"the popularity of javascript (js) is enormous. together with html and css, it is the core technology for modern web development. because of the dynamic nature and complex interplay with html, js applications are often error-prone and vulnerable. despite active research efforts to devise intricate static and dynamic analyses to facilitate js testing, the problem of test data generation for js code interacting with the dom has not yet been addressed. in this paper, we present a javascript evolutionary testing framework with dom as an input, called jedi. in order to reach a target branch, it applies genetic search for relevant input parameters of the js function in combination with the global dom state. we conducted an empirical evaluation to study the effectiveness and efficiency of our testing framework. it shows that the genetic with restart algorithm, proposed in this paper, is able to achieve complete branch coverage for all experimental subjects, taking on average 19 seconds per branch.",search-based test data generation for javascript functions that interact with the dom
896,2-s2.0-85059780569,10.1109/CIC.2018.00038,New algorithms and methods for collaborative co-editing using HTML DOM synchronization,Gadea C.,"Proceedings - 4th IEEE International Conference on Collaboration and Internet Computing, CIC 2018",2018-11-15,"The optimistic consistency control method known as Operational Transformation (OT) has been studied by researchers for nearly three decades, with centralized versions lying at the heart of most real-time web co-editing tools in academia and industry. Concurrent document editing is now a 'must-have' for the modern workplace, with proven benefits in team productivity and efficiency. Once limited to primitive insert and delete operations, OT algorithms have evolved to support hierarchical data structures such as XML in order to meet the increasingly complex requirements of present-day collaborative applications. However, previous approaches have not focused on the changes that web applications enact upon the Document Object Model (DOM) of the Hypertext Markup Language (HTML) standard. This paper will present a feedback-based real-time architecture that allows arbitrary DOM-based document replicas to remain consistent by defining a new set of operations that preserve the user's editing intentions. The control loop of the architecture enables simultaneous DOM-based modifications by using novel conflict resolution algorithms and methods that bring 'Virtual DOM' concepts together with state-of-the-art OT principles to enable advanced operations such as moving, splitting and merging of hierarchical DOM nodes. Through the implementation and evaluation of a rich-text editor, it will be shown how the architecture facilitates and accelerates the development of multi-user interactive web applications that meet today's demanding latency, scalability and accessibility requirements.",Collaborative software | Distributed computing | Feedback control theory | Finite state machines | Real-time systems,0,217-226,Conference Proceeding,Conference Paper,3.0,"Gadea, Cristian;Ionescu, Bogdan;Ionescu, Dan",26654220800;57209188085;7102900097,University of Ottawa,Canada,"the optimistic consistency control method known as operational transformation (ot) has been studied by researchers for nearly three decades, with centralized versions lying at the heart of most real-time web co-editing tools in academia and industry. concurrent document editing is now a 'must-have' for the modern workplace, with proven benefits in team productivity and efficiency. once limited to primitive insert and delete operations, ot algorithms have evolved to support hierarchical data structures such as xml in order to meet the increasingly complex requirements of present-day collaborative applications. however, previous approaches have not focused on the changes that web applications enact upon the document object model (dom) of the hypertext markup language (html) standard. this paper will present a feedback-based real-time architecture that allows arbitrary dom-based document replicas to remain consistent by defining a new set of operations that preserve the user's editing intentions. the control loop of the architecture enables simultaneous dom-based modifications by using novel conflict resolution algorithms and methods that bring 'virtual dom' concepts together with state-of-the-art ot principles to enable advanced operations such as moving, splitting and merging of hierarchical dom nodes. through the implementation and evaluation of a rich-text editor, it will be shown how the architecture facilitates and accelerates the development of multi-user interactive web applications that meet today's demanding latency, scalability and accessibility requirements.",new algorithms and methods for collaborative co-editing using html dom synchronization
897,2-s2.0-85059090382,10.1109/EDOC.2018.00034,Managing product lines variability in rich internet applications,Asadi M.,"Proceedings - 2018 IEEE 22nd International Enterprise Distributed Object Computing Conference, EDOC 2018",2018-11-14,"Rich Internet Applications refers to Web applications resembling desktop solutions with sophisticated user interactions, client-side processing, and asynchronous communications. Rich Internet applications have been evolved from traditional multi-page Web applications to single page applications which handle users' interactions without the need of full-refresh at each interaction. Although many techniques, methodologies, and technologies have been proposed in the rich Internet applications literature, the need for managing variability has not yet been conveniently addressed in this domain. According to software product lines research and practice, handling variability and commonality plays an important role in decreasing the development time and improving the quality of nal products. To this end, in this paper, we aim at employing the variability management techniques in the domain of rich Internet applications. We propose a variability modeling technique based on well-known feature modeling approach and provide a method for annotating rich Internet applications with variability and deriving final application based the given con guration. The proposed method is implemented in a tool named Varion which can be used along with existing rich Internet application tools and approaches. We applied the proposed approach on Angular, a well-known Model-View-Controller framework for developing rich Internet applications.","Feature Modeling | Software Product Lines, Variability Management, Rich Internet Applications",1,208-217,Conference Proceeding,Conference Paper,3.0,"Asadi, Mohsen;Daliri, Mohammad Reza;Alipour, Navid",16199752700;57515727100;56884510200,Ferdowsi University of Mashhad,Iran,"rich internet applications refers to web applications resembling desktop solutions with sophisticated user interactions, client-side processing, and asynchronous communications. rich internet applications have been evolved from traditional multi-page web applications to single page applications which handle users' interactions without the need of full-refresh at each interaction. although many techniques, methodologies, and technologies have been proposed in the rich internet applications literature, the need for managing variability has not yet been conveniently addressed in this domain. according to software product lines research and practice, handling variability and commonality plays an important role in decreasing the development time and improving the quality of nal products. to this end, in this paper, we aim at employing the variability management techniques in the domain of rich internet applications. we propose a variability modeling technique based on well-known feature modeling approach and provide a method for annotating rich internet applications with variability and deriving final application based the given con guration. the proposed method is implemented in a tool named varion which can be used along with existing rich internet application tools and approaches. we applied the proposed approach on angular, a well-known model-view-controller framework for developing rich internet applications.",managing product lines variability in rich internet applications
900,2-s2.0-85058336351,10.1109/ICSME.2018.00092,Dead code,Romano S.,"Proceedings - 2018 IEEE International Conference on Software Maintenance and Evolution, ICSME 2018",2018-11-09,"Dead code is a bad smell. It is conjectured to be harmful and it appears to be also a common phenomenon in software systems. Surprisingly, dead code has received little empirical attention from the software engineering research community. This post-doctoral track paper shows the main results of a multi-study investigation into dead code with an overarching goal to study when and why developers introduce dead code, how they perceive and cope with it, and whether dead code is harmful. This investigation is composed of semi-structured interviews with software professionals and four experiments at the University of Basilicata and the College of William & Mary. The results suggest that it is worth studying dead code not only in maintenance and evolution phases, where the results suggest that its presence is detrimental to developers, but also in design and implementation phases, where source code is born dead because developers consider dead code as a sort of reuse means. The results also foster the development of tools for detecting dead code. In this respect, two approaches were proposed and then implemented in two prototypes of supporting tool.",Bad smell | Dead code | Lava flow | Unreachable code | Unused code,3,737-742,Conference Proceeding,Conference Paper,1.0,"Romano, Simone",57197990135,Università degli Studi della Basilicata,Italy,"dead code is a bad smell. it is conjectured to be harmful and it appears to be also a common phenomenon in software systems. surprisingly, dead code has received little empirical attention from the software engineering research community. this post-doctoral track paper shows the main results of a multi-study investigation into dead code with an overarching goal to study when and why developers introduce dead code, how they perceive and cope with it, and whether dead code is harmful. this investigation is composed of semi-structured interviews with software professionals and four experiments at the university of basilicata and the college of william & mary. the results suggest that it is worth studying dead code not only in maintenance and evolution phases, where the results suggest that its presence is detrimental to developers, but also in design and implementation phases, where source code is born dead because developers consider dead code as a sort of reuse means. the results also foster the development of tools for detecting dead code. in this respect, two approaches were proposed and then implemented in two prototypes of supporting tool.",dead code
903,2-s2.0-85057791466,10.1109/STC-CSIT.2018.8526734,Methods of data processing restriction in ERP systems,Zhezhnych P.,International Scientific and Technical Conference on Computer Sciences and Information Technologies,2018-11-07,Minimizing of risks caused by data processing and related to the violation of information security is an important task of ERP-system management. This paper discusses methods of data processing restriction that largely allow avoiding of situations that lead to information security violations. The proposed methods called CU'D' and CU' are based on discovering of peculiarities of needs to manipulate data at different stages of processing that mean limited usage of Update and Delete data operations. These peculiarities allow forming of transition maps between data processing stages and the corresponding rules of applying of data manipulation operations. The advantage of the developed methods is the possibility of their implementation at the logical level of a database with a set of views without any development of special software units. The methods allow reducing rates of violations of data confidentiality and integrity caused by Update and Delete operations.,data processing | database | database scheme | ERP system | information security | SQL | workflow,7,274-277,Conference Proceeding,Conference Paper,2.0,"Zhezhnych, Pavlo;Tarasov, Dmytro",24484277800;55226205100,Lviv Polytechnic National University,Ukraine,minimizing of risks caused by data processing and related to the violation of information security is an important task of erp-system management. this paper discusses methods of data processing restriction that largely allow avoiding of situations that lead to information security violations. the proposed methods called cu'd' and cu' are based on discovering of peculiarities of needs to manipulate data at different stages of processing that mean limited usage of update and delete data operations. these peculiarities allow forming of transition maps between data processing stages and the corresponding rules of applying of data manipulation operations. the advantage of the developed methods is the possibility of their implementation at the logical level of a database with a set of views without any development of special software units. the methods allow reducing rates of violations of data confidentiality and integrity caused by update and delete operations.,methods of data processing restriction in erp systems
906,2-s2.0-85070943158,10.1109/TLA.2018.8795110,TEACCH Methodology-Based Web System to Support Learning for Children with Autism,Oliveira M.A.C.S.,IEEE Latin America Transactions,2018-11-01,"Autism spectrum disorder (ASD) is characterized by a shared spectrum of significant damage in the areas of social interaction, routines, and verbal and non-verbal language functions considered essential for learning process and human development. Children with ASD are great visual learners, who understand graphical information sooner and better and show attraction for technological equipment. So, the aim of this article is to show the process of creating a digital learning technology to support children with ASD in their school activities, based on the method of Treatment and Education of Autistic and related Communication-Handicapped Children (TEACCH), distributed in four sections that address problems with emphasis on syllabic sorting with images matching, perception and visual association, visual memory and spatial and sequential organization of routines, with a logical sequence to carry out the activities of daily living (ADLS). To evaluate the web system developed, we applied the revised psychoeducational evaluation scale (PEP-R), involving 7 areas of cognitive development: Imitation, Perception, Fine and Global Motricity, Eye-glass, Cognitive Realization and Verbal Cognition. Five 4-5 years old students of a school of early childhood and elementary education in special education participated of the essay. From an observational mode, we assess the scholars performance in carrying out the proposed activities in TEACCH method. The results were classified as Failure (""I""), Emergent (""E"") when carried out with total or partial help, and Success (""S"") when achieving the activities independently. Quantitative results indicated a 24%-reduction in the indices measured before as ""Failure"" in PEP-R. So, we concluded that the developed web system is suitable and effective for the implementation of the TEACCH activities.",Autism | Learning Technology | Software | TEACCH,2,2698-2705,Journal,Article,3.0,"Oliveira, M. A.C.S.;Guebert, M. C.C.;Nohama, Percy",57211420343;57210579796;6601924638,Pontifícia Universidade Católica do Paraná,Brazil,"autism spectrum disorder (asd) is characterized by a shared spectrum of significant damage in the areas of social interaction, routines, and verbal and non-verbal language functions considered essential for learning process and human development. children with asd are great visual learners, who understand graphical information sooner and better and show attraction for technological equipment. so, the aim of this article is to show the process of creating a digital learning technology to support children with asd in their school activities, based on the method of treatment and education of autistic and related communication-handicapped children (teacch), distributed in four sections that address problems with emphasis on syllabic sorting with images matching, perception and visual association, visual memory and spatial and sequential organization of routines, with a logical sequence to carry out the activities of daily living (adls). to evaluate the web system developed, we applied the revised psychoeducational evaluation scale (pep-r), involving 7 areas of cognitive development: imitation, perception, fine and global motricity, eye-glass, cognitive realization and verbal cognition. five 4-5 years old students of a school of early childhood and elementary education in special education participated of the essay. from an observational mode, we assess the scholars performance in carrying out the proposed activities in teacch method. the results were classified as failure (""i""), emergent (""e"") when carried out with total or partial help, and success (""s"") when achieving the activities independently. quantitative results indicated a 24%-reduction in the indices measured before as ""failure"" in pep-r. so, we concluded that the developed web system is suitable and effective for the implementation of the teacch activities.",teacch methodology-based web system to support learning for children with autism
908,2-s2.0-85048737201,10.1016/j.artmed.2016.08.003,Executable medical guidelines with Arden Syntax—Applications in dermatology and obstetrics,Seitinger A.,Artificial Intelligence in Medicine,2018-11-01,"Introduction: Clinical decision support systems (CDSSs) are being developed to assist physicians in processing extensive data and new knowledge based on recent scientific advances. Structured medical knowledge in the form of clinical alerts or reminder rules, decision trees or tables, clinical protocols or practice guidelines, score algorithms, and others, constitute the core of CDSSs. Several medical knowledge representation and guideline languages have been developed for the formal computerized definition of such knowledge. One of these languages is Arden Syntax for Medical Logic Systems, an International Health Level Seven (HL7) standard whose development started in 1989. Its latest version is 2.10, which was presented in 2014. In the present report we discuss Arden Syntax as a modern medical knowledge representation and processing language, and show that this language is not only well suited to define clinical alerts, reminders, and recommendations, but can also be used to implement and process computerized medical practice guidelines. Methods: This section describes how contemporary software such as Java, server software, web-services, XML, is used to implement CDSSs based on Arden Syntax. Special emphasis is given to clinical decision support (CDS) that employs practice guidelines as its clinical knowledge base. Results: Two guideline-based applications using Arden Syntax for medical knowledge representation and processing were developed. The first is a software platform for implementing practice guidelines from dermatology. This application employs fuzzy set theory and logic to represent linguistic and propositional uncertainty in medical data, knowledge, and conclusions. The second application implements a reminder system based on clinically published standard operating procedures in obstetrics to prevent deviations from state-of-the-art care. A to-do list with necessary actions specifically tailored to the gestational week/labor/delivery is generated. Discussion: Today, with the latest versions of Arden Syntax and the application of contemporary software development methods, Arden Syntax has become a powerful and versatile medical knowledge representation and processing language, well suited to implement a large range of CDSSs, including clinical-practice-guideline-based CDSSs. Moreover, such CDS is provided and can be shared as a service by different medical institutions, redefining the sharing of medical knowledge. Arden Syntax is also highly flexible and provides developers the freedom to use up-to-date software design and programming patterns for external patient data access.",Arden Syntax | Clinical decision support | Dermatology | Fuzzy set theory and logic | Lyme borreliosis | Medical practice guidelines | Obstetrics | Standard operating procedures,14,71-81,Journal,Article,5.0,"Seitinger, Alexander;Rappelsberger, Andrea;Leitich, Harald;Binder, Michael;Adlassnig, Klaus Peter",56245050300;22035949700;7003283022;55988228000;7003385915,Medizinische Universität Wien;Medical Association Vienna;Medexter Healthcare GmbH,Austria;Austria;Austria,"introduction: clinical decision support systems (cdsss) are being developed to assist physicians in processing extensive data and new knowledge based on recent scientific advances. structured medical knowledge in the form of clinical alerts or reminder rules, decision trees or tables, clinical protocols or practice guidelines, score algorithms, and others, constitute the core of cdsss. several medical knowledge representation and guideline languages have been developed for the formal computerized definition of such knowledge. one of these languages is arden syntax for medical logic systems, an international health level seven (hl7) standard whose development started in 1989. its latest version is 2.10, which was presented in 2014. in the present report we discuss arden syntax as a modern medical knowledge representation and processing language, and show that this language is not only well suited to define clinical alerts, reminders, and recommendations, but can also be used to implement and process computerized medical practice guidelines. methods: this section describes how contemporary software such as java, server software, web-services, xml, is used to implement cdsss based on arden syntax. special emphasis is given to clinical decision support (cds) that employs practice guidelines as its clinical knowledge base. results: two guideline-based applications using arden syntax for medical knowledge representation and processing were developed. the first is a software platform for implementing practice guidelines from dermatology. this application employs fuzzy set theory and logic to represent linguistic and propositional uncertainty in medical data, knowledge, and conclusions. the second application implements a reminder system based on clinically published standard operating procedures in obstetrics to prevent deviations from state-of-the-art care. a to-do list with necessary actions specifically tailored to the gestational week/labor/delivery is generated. discussion: today, with the latest versions of arden syntax and the application of contemporary software development methods, arden syntax has become a powerful and versatile medical knowledge representation and processing language, well suited to implement a large range of cdsss, including clinical-practice-guideline-based cdsss. moreover, such cds is provided and can be shared as a service by different medical institutions, redefining the sharing of medical knowledge. arden syntax is also highly flexible and provides developers the freedom to use up-to-date software design and programming patterns for external patient data access.",executable medical guidelines with arden syntax—applications in dermatology and obstetrics
909,2-s2.0-85042221167,10.1177/2168479018754846,The Safety Explorer Suite: Interactive Safety Monitoring for Clinical Trials,Wildfire J.,Therapeutic Innovation and Regulatory Science,2018-11-01,"Background: Frequent and thorough monitoring of patient safety is a requirement of clinical trials research. Safety data are traditionally reported in a tabular or listing format, which often translates into many pages of static displays. This poses the risk that clinically relevant signals will be obscured by the sheer volume of data reported. Interactive graphics enable the delivery of the vast scope of information found in traditional reports, but allow the user to interact with the charts in real time, focusing on signals of interest. Methods: Clinical research staff, including biostatisticians, project managers, and a medical monitor, were consulted to guide the development of a set of interactive data visualizations that enable key safety assessments for participants. The resulting “Safety Explorer” is a set of 6 interactive, web-based, open source tools designed to address the shortcomings of traditional, static reports for safety monitoring. Results: The Safety Explorer is freely available on GitHub as individual JavaScript libraries: Adverse Event Explorer, Adverse Event Timelines, Safety Histogram, Safety Outlier Explorer, Safety Results Over Time, and Safety Shift Plot; or in a single combined framework: Safety Explorer Suite. The suite can also be utilized through its R interface, the safetyexploreR package. Conclusions: The Safety Explorer provides interactive charts that contain the same information available in standard displays, but the interactive interface allows for improved exploration of patterns and comparisons. Medical Monitors, Safety Review Boards, and Project Teams can use these tools to effectively track and analyze key safety variables and study endpoints.",interactive graphics | JavaScript | medical monitoring | R | safety reporting,5,696-700,Journal,Review,9.0,"Wildfire, Jeremy;Bailey, Ryan;Krouse, Rebecca Z.;Childress, Spencer;Sikora, Britt;Bryant, Nathan;Rosanbalm, Shane;Wilson, Emily;Modell, Jack G.",24831369900;57200702089;57189691377;57200696408;57200697913;57200700226;57193400755;57200693948;7004903241,Rho,United States,"background: frequent and thorough monitoring of patient safety is a requirement of clinical trials research. safety data are traditionally reported in a tabular or listing format, which often translates into many pages of static displays. this poses the risk that clinically relevant signals will be obscured by the sheer volume of data reported. interactive graphics enable the delivery of the vast scope of information found in traditional reports, but allow the user to interact with the charts in real time, focusing on signals of interest. methods: clinical research staff, including biostatisticians, project managers, and a medical monitor, were consulted to guide the development of a set of interactive data visualizations that enable key safety assessments for participants. the resulting “safety explorer” is a set of 6 interactive, web-based, open source tools designed to address the shortcomings of traditional, static reports for safety monitoring. results: the safety explorer is freely available on github as individual javascript libraries: adverse event explorer, adverse event timelines, safety histogram, safety outlier explorer, safety results over time, and safety shift plot; or in a single combined framework: safety explorer suite. the suite can also be utilized through its r interface, the safetyexplorer package. conclusions: the safety explorer provides interactive charts that contain the same information available in standard displays, but the interactive interface allows for improved exploration of patterns and comparisons. medical monitors, safety review boards, and project teams can use these tools to effectively track and analyze key safety variables and study endpoints.",the safety explorer suite: interactive safety monitoring for clinical trials
910,2-s2.0-85102231831,10.1002/9781119564034.ch13,An open environment for development of manufacturing applications on vf-OS,Coutinho C.,Enterprise Interoperability: Smart Services and Business Impact of Enterprise Interoperability,2018-10-26,"Innovative methodologies for development promote strong involvement of the development community and the developers' engagement. This chapter describes a novel environment that was envisioned for this purpose, involved in the scope of the H2020 European Project virtual factory Open Operating System (vf-OS). The purpose of the H2020 vf-OS European Project is to provide manufacturing businesses with an open Operating System that will allow them to create, develop, build and load applications that span and cover the whole manufacturing operation and process. The vf-OAK software development kit (SDK) is a centralized environment for the development of applications and, generically, for centralized access to the vf-OS assets and functionalities. The SDK for vApps has a process interpreter which can transform the results from the Process Designer tool to JavaScript language. The vf-OS System Dashboard is a runtime, central dashboard and task manager, aimed at monitoring, warning, configuring, and adapting system resources.",Developers engagement hub | Manufacturing applications | Process designer | System dashboard | Vf-OAK SDK | Vf-OAK studio,2,107-114,Book,Book Chapter,9.0,"Coutinho, Carlos;Lopes, Luís;Viana, Vítor;Pape, Danny;Klasen, Gerrit;Von Halem, Bastian;Garcia Perales, Oscar G.;Stellingwerff, Ludo;Stam, Andries",55355460700;57202233126;54882577100;57222310798;57222313450;57222310527;57213152454;56027581400;12751767400,Iscte – Instituto Universitário de Lisboa;Innovation and Product Development Ascora;Information Catalyst;Caixa Mágica Software;Almende,Portugal;Germany;Spain;Portugal;Netherlands,"innovative methodologies for development promote strong involvement of the development community and the developers' engagement. this chapter describes a novel environment that was envisioned for this purpose, involved in the scope of the h2020 european project virtual factory open operating system (vf-os). the purpose of the h2020 vf-os european project is to provide manufacturing businesses with an open operating system that will allow them to create, develop, build and load applications that span and cover the whole manufacturing operation and process. the vf-oak software development kit (sdk) is a centralized environment for the development of applications and, generically, for centralized access to the vf-os assets and functionalities. the sdk for vapps has a process interpreter which can transform the results from the process designer tool to javascript language. the vf-os system dashboard is a runtime, central dashboard and task manager, aimed at monitoring, warning, configuring, and adapting system resources.",an open environment for development of manufacturing applications on vf-os
911,2-s2.0-85058310754,10.1145/3236024.3275526,Software development challenges with air-gap isolation,Wong S.,ESEC/FSE 2018 - Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering,2018-10-26,"While existing research has explored the trade-off between security and performance, these efforts primarily focus on software consumers and often overlook the effectiveness and productivity of software producers. In this paper, we highlight an established security practice, air-gap isolation, and some challenges it uniquely instigates. To better understand and start quantifying the impacts of air-gap isolation on software development productivity, we conducted a survey at a commercial software company: Analytical Graphics, Inc. Based on our insights of dealing with air-gap isolation daily, we suggest some possible directions for future research. Our goal is to bring attention to this neglected area of research and to start a discussion in the SE community about the struggles faced by many commercial and governmental organizations.",air-gap network | productivity | security | survey,2,815-820,Conference Proceeding,Conference Paper,2.0,"Wong, Sunny;Woepse, Anne",57205029342;57205022763,"Analytical Graphics, Inc.",United States,"while existing research has explored the trade-off between security and performance, these efforts primarily focus on software consumers and often overlook the effectiveness and productivity of software producers. in this paper, we highlight an established security practice, air-gap isolation, and some challenges it uniquely instigates. to better understand and start quantifying the impacts of air-gap isolation on software development productivity, we conducted a survey at a commercial software company: analytical graphics, inc. based on our insights of dealing with air-gap isolation daily, we suggest some possible directions for future research. our goal is to bring attention to this neglected area of research and to start a discussion in the se community about the struggles faced by many commercial and governmental organizations.",software development challenges with air-gap isolation
913,2-s2.0-85083380350,10.1145/3276945.3276952,Log++ logging for a cloud-native world,Marron M.,ACM SIGPLAN Notices,2018-10-24,"Logging is a fundamental part of the software development and deployment lifecycle but logging support is often provided as an afterthought via limited library APIs or third-party modules. Given the critical nature of logging in modern cloud, mobile, and IoT development workflows, the unique needs of the APIs involved, and the opportunities for optimization using semantic knowledge, we argue logging should be included as a central part of the language and runtime designs. This paper presents a rethinking of the logger for modern cloud-native workflows. Based on a set of design principles for modern logging we build a logging system, that supports near zero-cost for disabled log statements, low cost lazy-copying for enabled log statements, selective persistence of logging output, unified control of logging output across different libraries, and DevOps integration for use with modern cloud-based deployments. To evaluate these concepts we implemented the Log++ logger for Node.js hosted JavaScript applications.",JavaScript | Logging | Runtime Monitoring,0,25-36,Journal,Article,1.0,"Marron, Mark",7003748717,Microsoft Research,United States,"logging is a fundamental part of the software development and deployment lifecycle but logging support is often provided as an afterthought via limited library apis or third-party modules. given the critical nature of logging in modern cloud, mobile, and iot development workflows, the unique needs of the apis involved, and the opportunities for optimization using semantic knowledge, we argue logging should be included as a central part of the language and runtime designs. this paper presents a rethinking of the logger for modern cloud-native workflows. based on a set of design principles for modern logging we build a logging system, that supports near zero-cost for disabled log statements, low cost lazy-copying for enabled log statements, selective persistence of logging output, unified control of logging output across different libraries, and devops integration for use with modern cloud-based deployments. to evaluate these concepts we implemented the log++ logger for node.js hosted javascript applications.",log++ logging for a cloud-native world
914,2-s2.0-85083372333,10.1145/3276945.3276949,Query-based object-oriented programming: A declarative web of objects,Seginer Y.,ACM SIGPLAN Notices,2018-10-24,"We present a declarative, object-oriented language in which queries play a central role. Queries are used not only to access data, but also to refer to the application's object members and as a means of program control. The language is fully declarative, with queries and other pure functions defining the relations between the attributes of different objects. A rule-base-like write operation allows state to be updated. Control is achieved by queries selecting the class variants (mixin classes) which are active in each object. The dynamic activation and deactivation of declarative mixin classes allows decomposition of functionality into small reusable classes. The programming style in the language is functional and reactive, with function applications defining object members. Queries are one type of function, which also serves as the glue which puts these functions together, providing them with their input. Since queries describe declaratively what they return, they leave it to the system to implement the how of getting it. Combining this with an organization around objects makes the language highly suitable for complex interactive applications driven by large amounts of data from multiple sources. Our implementation of the language includes a strong display component. It can be seen as a conceptual extension of HTML and CSS in a way which replaces the need for the JavaScript imperative component in web applications. The work described here is not restricted, however, to front-end development and can be applied elsewhere as well.",declarative | dynamic mixin | query-based,0,64-75,Journal,Article,4.0,"Seginer, Yoav;Vosse, Theo;Harari, Gil;Kolodny, Uri",57216392979;57500094600;57205022465;57205023166,cdl-lang.org;cdl-lang.org,Netherlands;Israel,"we present a declarative, object-oriented language in which queries play a central role. queries are used not only to access data, but also to refer to the application's object members and as a means of program control. the language is fully declarative, with queries and other pure functions defining the relations between the attributes of different objects. a rule-base-like write operation allows state to be updated. control is achieved by queries selecting the class variants (mixin classes) which are active in each object. the dynamic activation and deactivation of declarative mixin classes allows decomposition of functionality into small reusable classes. the programming style in the language is functional and reactive, with function applications defining object members. queries are one type of function, which also serves as the glue which puts these functions together, providing them with their input. since queries describe declaratively what they return, they leave it to the system to implement the how of getting it. combining this with an organization around objects makes the language highly suitable for complex interactive applications driven by large amounts of data from multiple sources. our implementation of the language includes a strong display component. it can be seen as a conceptual extension of html and css in a way which replaces the need for the javascript imperative component in web applications. the work described here is not restricted, however, to front-end development and can be applied elsewhere as well.",query-based object-oriented programming: a declarative web of objects
915,2-s2.0-85058343617,10.1145/3276945.3276952,Log++ logging for a cloud-native world,Marron M.,"DLS 2018 - Proceedings of the 14th ACM SIGPLAN International Symposium on Dynamic Languages, co-located with SPLASH 2018",2018-10-24,"Logging is a fundamental part of the software development and deployment lifecycle but logging support is often provided as an afterthought via limited library APIs or third-party modules. Given the critical nature of logging in modern cloud, mobile, and IoT development workflows, the unique needs of the APIs involved, and the opportunities for optimization using semantic knowledge, we argue logging should be included as a central part of the language and runtime designs. This paper presents a rethinking of the logger for modern cloud-native workflows. Based on a set of design principles for modern logging we build a logging system, that supports near zero-cost for disabled log statements, low cost lazy-copying for enabled log statements, selective persistence of logging output, unified control of logging output across different libraries, and DevOps integration for use with modern cloud-based deployments. To evaluate these concepts we implemented the Log++ logger for Node.js hosted JavaScript applications.",JavaScript | Logging | Runtime Monitoring,2,25-36,Conference Proceeding,Editorial,1.0,"Marron, Mark",7003748717,Microsoft Research,United States,"logging is a fundamental part of the software development and deployment lifecycle but logging support is often provided as an afterthought via limited library apis or third-party modules. given the critical nature of logging in modern cloud, mobile, and iot development workflows, the unique needs of the apis involved, and the opportunities for optimization using semantic knowledge, we argue logging should be included as a central part of the language and runtime designs. this paper presents a rethinking of the logger for modern cloud-native workflows. based on a set of design principles for modern logging we build a logging system, that supports near zero-cost for disabled log statements, low cost lazy-copying for enabled log statements, selective persistence of logging output, unified control of logging output across different libraries, and devops integration for use with modern cloud-based deployments. to evaluate these concepts we implemented the log++ logger for node.js hosted javascript applications.",log++ logging for a cloud-native world
916,2-s2.0-85058269069,10.1145/3276945.3276949,Query-based object-oriented programming a declarative web of objects,Seginer Y.,"DLS 2018 - Proceedings of the 14th ACM SIGPLAN International Symposium on Dynamic Languages, co-located with SPLASH 2018",2018-10-24,"We present a declarative, object-oriented language in which queries play a central role. Queries are used not only to access data, but also to refer to the application’s object members and as a means of program control. The language is fully declarative, with queries and other pure functions defining the relations between the attributes of different objects. A rule-base-like write operation allows state to be updated. Control is achieved by queries selecting the class variants (mixin classes) which are active in each object. The dynamic activation and deactivation of declarative mixin classes allows decomposition of functionality into small reusable classes. The programming style in the language is functional and reactive, with function applications defining object members. Queries are one type of function, which also serves as the glue which puts these functions together, providing them with their input. Since queries describe declaratively what they return, they leave it to the system to implement the how of getting it. Combining this with an organization around objects makes the language highly suitable for complex interactive applications driven by large amounts of data from multiple sources. Our implementation of the language includes a strong display component. It can be seen as a conceptual extension of HTML and CSS in a way which replaces the need for the JavaScript imperative component in web applications. The work described here is not restricted, however, to front-end development and can be applied elsewhere as well.",Declarative | Dynamic mixin | Query-based,1,64-75,Conference Proceeding,Conference Paper,4.0,"Seginer, Yoav;Harari, Gil;Vosse, Theo;Kolodny, Uri",57216392979;57205022465;57500094600;57205023166,cdl-lang.org;cdl-lang.org,Netherlands;Israel,"we present a declarative, object-oriented language in which queries play a central role. queries are used not only to access data, but also to refer to the application’s object members and as a means of program control. the language is fully declarative, with queries and other pure functions defining the relations between the attributes of different objects. a rule-base-like write operation allows state to be updated. control is achieved by queries selecting the class variants (mixin classes) which are active in each object. the dynamic activation and deactivation of declarative mixin classes allows decomposition of functionality into small reusable classes. the programming style in the language is functional and reactive, with function applications defining object members. queries are one type of function, which also serves as the glue which puts these functions together, providing them with their input. since queries describe declaratively what they return, they leave it to the system to implement the how of getting it. combining this with an organization around objects makes the language highly suitable for complex interactive applications driven by large amounts of data from multiple sources. our implementation of the language includes a strong display component. it can be seen as a conceptual extension of html and css in a way which replaces the need for the javascript imperative component in web applications. the work described here is not restricted, however, to front-end development and can be applied elsewhere as well.",query-based object-oriented programming a declarative web of objects
919,2-s2.0-85057084949,10.1109/EIT.2018.8500194,The Code Genie Programming Environment,Jawad H.,IEEE International Conference on Electro Information Technology,2018-10-18,"Computer programming is not easy and many educators and developers have been trying to create a development environment that makes programming easier and more interesting for K12 students. This paper demonstrates one of these efforts by introducing a newly developed educational environment that could help high school students learn computer programming language. Code Genie was designed to integrate art, animation, and code sharing in teaching programming. Using this web-based learning environment, students can learn how to write a program in a JavaScript language, and how to produce artwork from coding, then share it with others. JavaScript was chosen for its popularity, simplicity and because it is a real programming language that is currently used by software developers who create real software products. The Code Genie learning environment and the motivation behind developing it for high school students are discussed in this paper. It was tested during three coding workshops. Student responses to the tool's usefulness and ease of use will be explained.",Animation | Art with coding | Code sharing | Computer programming for high school students | Computer science for girls | STEM tool for k12,4,163-168,Conference Proceeding,Conference Paper,3.0,"Jawad, Hadeel Mohammed;De Laski-Smith, Deb;Tout, Samir",57200613605;57204773009;22735751000,Eastern Michigan University,United States,"computer programming is not easy and many educators and developers have been trying to create a development environment that makes programming easier and more interesting for k12 students. this paper demonstrates one of these efforts by introducing a newly developed educational environment that could help high school students learn computer programming language. code genie was designed to integrate art, animation, and code sharing in teaching programming. using this web-based learning environment, students can learn how to write a program in a javascript language, and how to produce artwork from coding, then share it with others. javascript was chosen for its popularity, simplicity and because it is a real programming language that is currently used by software developers who create real software products. the code genie learning environment and the motivation behind developing it for high school students are discussed in this paper. it was tested during three coding workshops. student responses to the tool's usefulness and ease of use will be explained.",the code genie programming environment
921,2-s2.0-85056692770,10.1145/3243082.3264608,Evolution of software architectures: From Web 1.0 to Web 3.0 systems,Kulesza R.,WebMedia 2018 - Proceedings of the 24th Brazilian Symposium on Multimedia and the Web,2018-10-16,"From the early 1990s, Web Systems emerged with the expansion of the Internet around the world. These systems were initially supported by a client-server architecture and three standards (URL, HTTP and HTML), and has considerably evolved in the last two decades. Usability, scalability, maintenance, portability, robustness, security and integration with other systems are the main challenges of this software category. This tutorial presents the history and evolution of Web-based software architectures. We discuss current software architectural styles, patterns, and development platforms based on client-side (React JS, Angular JS and Vue Js) and server-side (Spring and Node.js) technologies. In addition, we also discuss Web 3.0 requirements such as communication protocols, Microservices, MV* browser-based frameworks, boilerplates client-side code, asynchronous programming, and integration with cloud computing infrastructures.",Software architectures | Technologies | Web systems,1,11-13,Conference Proceeding,Conference Paper,5.0,"Kulesza, Raoni;Lima, Matheus;Araujo, Claudiomar;De Sousa, Marcelo F.;Filho, Aguinaldo M.",18434797400;57197808023;57204692894;56437337500;57204689929,Universidade Federal da Paraíba;Paraiba institute of Higher Education (IESP);Audit Office of Paraiba (TCE/PB),Brazil;Brazil;Brazil,"from the early 1990s, web systems emerged with the expansion of the internet around the world. these systems were initially supported by a client-server architecture and three standards (url, http and html), and has considerably evolved in the last two decades. usability, scalability, maintenance, portability, robustness, security and integration with other systems are the main challenges of this software category. this tutorial presents the history and evolution of web-based software architectures. we discuss current software architectural styles, patterns, and development platforms based on client-side (react js, angular js and vue js) and server-side (spring and node.js) technologies. in addition, we also discuss web 3.0 requirements such as communication protocols, microservices, mv* browser-based frameworks, boilerplates client-side code, asynchronous programming, and integration with cloud computing infrastructures.",evolution of software architectures: from web 1.0 to web 3.0 systems
922,2-s2.0-85077490615,10.13475/j.fzxb.20170702306,Development and realization of knitting fabric CAD system based on Internet,Tang M.,Fangzhi Xuebao/Journal of Textile Research,2018-10-15,"An Internet-based CAD system for warp knitted fabrics was developed to break the limits of standalone-version warp knitting CAD software and to realize functions of rapid design, simulation, virtual display techniques calculation and real-time data interaction. According to the knitting principle of warp-knitted structures and the basic chain notation, a mathematic model with three-dimensional matrixes for representing the lapping and threading diagram was established. The computer graphics technology was applied to realize the pattern extraction and circulation processing of the simulation diagram, and the database technology was applied to realize the estimation of the amount of let off, etc, which was then converted into the computer language in Visual Studio development environment. A B/S structure was used to complete the interactive design according to the Internet technology principles.The storage and calling of large data were efficiently solved by using the cloud service platform. This developed Internet-based CAD system using the post-release system was finally proved with practicality and stability by designing a simple warp knitted grid fabric.",Computer aided design | Internet | Mat yarn drawing | Warp knitting,1,143-148,Journal,Article,4.0,"Tang, Mengting;Jiang, Gaoming;Wang, Wei;Gao, Ziyue",57212929038;55854051400;57216553649;57212929250,Jiangnan University,China,"an internet-based cad system for warp knitted fabrics was developed to break the limits of standalone-version warp knitting cad software and to realize functions of rapid design, simulation, virtual display techniques calculation and real-time data interaction. according to the knitting principle of warp-knitted structures and the basic chain notation, a mathematic model with three-dimensional matrixes for representing the lapping and threading diagram was established. the computer graphics technology was applied to realize the pattern extraction and circulation processing of the simulation diagram, and the database technology was applied to realize the estimation of the amount of let off, etc, which was then converted into the computer language in visual studio development environment. a b/s structure was used to complete the interactive design according to the internet technology principles.the storage and calling of large data were efficiently solved by using the cloud service platform. this developed internet-based cad system using the post-release system was finally proved with practicality and stability by designing a simple warp knitted grid fabric.",development and realization of knitting fabric cad system based on internet
924,2-s2.0-85056861152,10.1145/3242587.3242600,IdylL: A markup language for authoring and publishing interactive articles on the web,Conlen M.,UIST 2018 - Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology,2018-10-11,"The web has matured as a publishing platform: news outlets regularly publish rich, interactive stories while technical writers use animation and interaction to communicate complex ideas. This style of interactive media has the potential to engage a large audience and more clearly explain concepts, but is expensive and time consuming to produce. Drawing on industry experience and interviews with domain experts, we contribute design tools to make it easier to author and publish interactive articles. We introduce Idyll, a novel “compile-to-the-web” language for web-based interactive narratives. Idyll implements a flexible article model, allowing authors control over document style and layout, reader-driven events (such as button clicks and scroll triggers), and a structured interface to JavaScript components. Through both examples and first-use results from undergraduate computer science students, we show how Idyll reduces the amount of effort and custom code required to create interactive articles.",Artifact or System | Interaction Design | Programming Languages | Programming/Development Support | Prototyping/Implementation | Storytelling | Visualization,24,977-989,Conference Proceeding,Conference Paper,2.0,"Conlen, Matthew;Heer, Jeffrey",57202045010;6603794736,University of Washington,United States,"the web has matured as a publishing platform: news outlets regularly publish rich, interactive stories while technical writers use animation and interaction to communicate complex ideas. this style of interactive media has the potential to engage a large audience and more clearly explain concepts, but is expensive and time consuming to produce. drawing on industry experience and interviews with domain experts, we contribute design tools to make it easier to author and publish interactive articles. we introduce idyll, a novel “compile-to-the-web” language for web-based interactive narratives. idyll implements a flexible article model, allowing authors control over document style and layout, reader-driven events (such as button clicks and scroll triggers), and a structured interface to javascript components. through both examples and first-use results from undergraduate computer science students, we show how idyll reduces the amount of effort and custom code required to create interactive articles.",idyll: a markup language for authoring and publishing interactive articles on the web
925,2-s2.0-85056693214,10.1145/3273934.3273942,Are software dependency supply chain metrics useful in predicting change of popularity of NPM packages?,Dey T.,ACM International Conference Proceeding Series,2018-10-10,"Background: As software development becomes more interdependent, unique relationships among software packages arise and form complex software ecosystems. Aim: We aim to understand the behavior of these ecosystems better through the lens of software supply chains and model how the effects of software dependency network affect the change in downloads of Javascript packages. Method: We analyzed 12,999 popular packages in NPM, between 01-December-2017 and 15-March-2018, using Linear Regression and Random Forest models and examined the effects of predictors representing different aspects of the software dependency supply chain on changes in numbers of downloads for a package. Result: Preliminary results suggest that the count and downloads of upstream and downstream runtime dependencies have a strong effect on the change in downloads, with packages having fewer, more popular packages as dependencies (upstream or downstream) likely to see an increase in downloads. This suggests that in order to interpret the number of downloads for a package properly, it is necessary to take into account the peculiarities of the supply chain (both upstream and downstream) of that package. Conclusion: Future work is needed to identify the effects of added, deleted, and unchanged dependencies for different types of packages, e.g. build tools, test tools.",NPM packages | Open source | Software dependency | Software popularity | Software supply chain,16,66-69,Conference Proceeding,Conference Paper,2.0,"Dey, Tapajit;Mockus, Audris",57189693601;57211066860,"The University of Tennessee, Knoxville",United States,"background: as software development becomes more interdependent, unique relationships among software packages arise and form complex software ecosystems. aim: we aim to understand the behavior of these ecosystems better through the lens of software supply chains and model how the effects of software dependency network affect the change in downloads of javascript packages. method: we analyzed 12,999 popular packages in npm, between 01-december-2017 and 15-march-2018, using linear regression and random forest models and examined the effects of predictors representing different aspects of the software dependency supply chain on changes in numbers of downloads for a package. result: preliminary results suggest that the count and downloads of upstream and downstream runtime dependencies have a strong effect on the change in downloads, with packages having fewer, more popular packages as dependencies (upstream or downstream) likely to see an increase in downloads. this suggests that in order to interpret the number of downloads for a package properly, it is necessary to take into account the peculiarities of the supply chain (both upstream and downstream) of that package. conclusion: future work is needed to identify the effects of added, deleted, and unchanged dependencies for different types of packages, e.g. build tools, test tools.",are software dependency supply chain metrics useful in predicting change of popularity of npm packages?
929,2-s2.0-85072638449,10.4018/IJeC.2018100103,"Eresearch: Digital service infrastructures for collaboration, information, and data management in joint research projects in ecology—an example",Thiele J.C.,International Journal of e-Collaboration,2018-10-01,"Joint research projects in ecology typically aim to integrate scientific knowledge from various disciplines. This raises the request for collaboration technologies. As ecological research is data-intensive, it requires the management and exchange of large datasets, often with spatial reference. The demand for collaboration, data, and information management tools in science is addressed by the creation of digital service infrastructures, so-called eResearch Infrastructures, which are collections of typically web-based software systems. Here, an example eResearch infrastructure implemented for a joint research project is presented. It is described by the user stories, the derived functional requirements, and their implementation in software systems. This infrastructure followed an open-source paradigm with only two exceptions. Based on the lessons learned, recommendations for the future development of eResearch infrastructures and their embedment in an organizational, project, and scientific framework are derived.",Collaboration | Cyberinfrastructure | Data Management | EResearch | EScience | Information Management | Project Management | Spatial Data Infrastructure,0,44-63,Journal,Article,1.0,"Thiele, Jan C.",56537880300,Georg-August-Universität Göttingen,Germany,"joint research projects in ecology typically aim to integrate scientific knowledge from various disciplines. this raises the request for collaboration technologies. as ecological research is data-intensive, it requires the management and exchange of large datasets, often with spatial reference. the demand for collaboration, data, and information management tools in science is addressed by the creation of digital service infrastructures, so-called eresearch infrastructures, which are collections of typically web-based software systems. here, an example eresearch infrastructure implemented for a joint research project is presented. it is described by the user stories, the derived functional requirements, and their implementation in software systems. this infrastructure followed an open-source paradigm with only two exceptions. based on the lessons learned, recommendations for the future development of eresearch infrastructures and their embedment in an organizational, project, and scientific framework are derived.","eresearch: digital service infrastructures for collaboration, information, and data management in joint research projects in ecology—an example"
931,2-s2.0-85058500735,10.4103/jmss.JMSS_35_18,Design and construction of a laser-based respiratory gating system for implementation of deep inspiration breathe hold technique in radiotherapy clinics,Farzaneh M.J.K.,Journal of Medical Signals and Sensors,2018-10-01,"Background: Deep inspiration breath-hold (DIBH) is known as a radiotherapy method for the treatment of patients with left-sided breast cancer. In this method, patient is under exposure only while he/she is at the end of a deep inspiration cycle and holds his/her breath. In this situation, the volume of the lung tissue is enhanced and the heart tissue is pushed away from the treating breast. Therefore, heart dose of these patients, using DIBH, experiences a considerable decline compared to free breathing treatment. There are a few commercialized systems for implementation of DIBH in invasive or noninvasive manners. Methods: We present a novel constructed noninvasive DIBH device relied on a manufacturing near-field laser distance meter. This in-house constructed system is composed of a CD22-100AM122 laser sensor combined with a data acquisition system for monitoring the breathing curve. Qt Creator (a cross-platform JavaScript, QML, and C++-integrated development environment that is part of the SDK for development of the Qt Graphical User Interface application framework) and Keil MDK-ARM (a programming software where users can write in C and C++ and assemble for ARM-based microcontrollers) are used for composing computer and microcontroller programs, respectively. Results: This system could be mounted in treatment or computed tomography (CT) room at suitable cost; it is also easy to use and needs a little training for personnel and patients. The system can assess the location of chest wall or abdomen in real time with high precision and frequency. The performance of CD22-100AM122 demonstrates promise for respiratory monitoring for its fast sampling rate as well as high precision. It can also deliver reasonable spatial and temporal accuracy. The patient observes his/her breathing waveform through a 7” 1024 × 600 liquid crystal display and gets some instructions during treatment and CT sessions by an exploited algorithm called “interaction scenario” in this study. The system is also noninvasive and well sustainable for patients. Conclusions: The constructed system has true real-time operation and is rapid enough for delivering clear contiguous monitoring. In addition, in this system, we have provided an interaction scenario option between patient and CT or Linac operator. In addition, the constructed system has the capability of sending triggers for turning on and off CT or Linac facilities. In this concern, the system has the superiority of combining a plenty of characteristics.",Deep inspiration breath-hold | Gated radiotherapy | Respiratory monitoring system | Respiratory-gated treatment | Tumor tracking,2,253-262,Journal,Article,4.0,"Farzaneh, Mohammad Javad Keikhai;Nasseri, Shahrokh;Momennezhad, Mehdi;Salek, Roham",56850467400;55213401500;22634819000;26536671600,Medical Physics Research Centre;Nuclear Medicine Research Center;Imam Reza Hospital;Mashhad University of Medical Sciences,Iran;Iran;Iran;Iran,"background: deep inspiration breath-hold (dibh) is known as a radiotherapy method for the treatment of patients with left-sided breast cancer. in this method, patient is under exposure only while he/she is at the end of a deep inspiration cycle and holds his/her breath. in this situation, the volume of the lung tissue is enhanced and the heart tissue is pushed away from the treating breast. therefore, heart dose of these patients, using dibh, experiences a considerable decline compared to free breathing treatment. there are a few commercialized systems for implementation of dibh in invasive or noninvasive manners. methods: we present a novel constructed noninvasive dibh device relied on a manufacturing near-field laser distance meter. this in-house constructed system is composed of a cd22-100am122 laser sensor combined with a data acquisition system for monitoring the breathing curve. qt creator (a cross-platform javascript, qml, and c++-integrated development environment that is part of the sdk for development of the qt graphical user interface application framework) and keil mdk-arm (a programming software where users can write in c and c++ and assemble for arm-based microcontrollers) are used for composing computer and microcontroller programs, respectively. results: this system could be mounted in treatment or computed tomography (ct) room at suitable cost; it is also easy to use and needs a little training for personnel and patients. the system can assess the location of chest wall or abdomen in real time with high precision and frequency. the performance of cd22-100am122 demonstrates promise for respiratory monitoring for its fast sampling rate as well as high precision. it can also deliver reasonable spatial and temporal accuracy. the patient observes his/her breathing waveform through a 7” 1024 × 600 liquid crystal display and gets some instructions during treatment and ct sessions by an exploited algorithm called “interaction scenario” in this study. the system is also noninvasive and well sustainable for patients. conclusions: the constructed system has true real-time operation and is rapid enough for delivering clear contiguous monitoring. in addition, in this system, we have provided an interaction scenario option between patient and ct or linac operator. in addition, the constructed system has the capability of sending triggers for turning on and off ct or linac facilities. in this concern, the system has the superiority of combining a plenty of characteristics.",design and construction of a laser-based respiratory gating system for implementation of deep inspiration breathe hold technique in radiotherapy clinics
934,2-s2.0-85045285455,10.1177/2472630318769454,IoT for Real-Time Measurement of High-Throughput Liquid Dispensing in Laboratory Environments,Shumate J.,SLAS Technology,2018-10-01,"Critical to maintaining quality control in high-throughput screening is the need for constant monitoring of liquid-dispensing fidelity. Traditional methods involve operator intervention with gravimetric analysis to monitor the gross accuracy of full plate dispenses, visual verification of contents, or dedicated weigh stations on screening platforms that introduce potential bottlenecks and increase the plate-processing cycle time. We present a unique solution using open-source hardware, software, and 3D printing to automate dispenser accuracy determination by providing real-time dispense weight measurements via a network-connected precision balance. This system uses an Arduino microcontroller to connect a precision balance to a local network. By integrating the precision balance as an Internet of Things (IoT) device, it gains the ability to provide real-time gravimetric summaries of dispensing, generate timely alerts when problems are detected, and capture historical dispensing data for future analysis. All collected data can then be accessed via a web interface for reviewing alerts and dispensing information in real time or remotely for timely intervention of dispense errors. The development of this system also leveraged 3D printing to rapidly prototype sensor brackets, mounting solutions, and component enclosures.",3D printing | dispenser | HTS | IoT | microcontroller,13,440-447,Journal,Review,4.0,"Shumate, Justin;Baillargeon, Pierre;Spicer, Timothy P.;Scampavia, Louis",57190568915;55860799559;7004075819;6601978592,Scripps Florida,United States,"critical to maintaining quality control in high-throughput screening is the need for constant monitoring of liquid-dispensing fidelity. traditional methods involve operator intervention with gravimetric analysis to monitor the gross accuracy of full plate dispenses, visual verification of contents, or dedicated weigh stations on screening platforms that introduce potential bottlenecks and increase the plate-processing cycle time. we present a unique solution using open-source hardware, software, and 3d printing to automate dispenser accuracy determination by providing real-time dispense weight measurements via a network-connected precision balance. this system uses an arduino microcontroller to connect a precision balance to a local network. by integrating the precision balance as an internet of things (iot) device, it gains the ability to provide real-time gravimetric summaries of dispensing, generate timely alerts when problems are detected, and capture historical dispensing data for future analysis. all collected data can then be accessed via a web interface for reviewing alerts and dispensing information in real time or remotely for timely intervention of dispense errors. the development of this system also leveraged 3d printing to rapidly prototype sensor brackets, mounting solutions, and component enclosures.",iot for real-time measurement of high-throughput liquid dispensing in laboratory environments
936,2-s2.0-85055816151,10.1145/3266237.3266273,A machine learning approach to generate test oracles,Braga R.,ACM International Conference Proceeding Series,2018-09-17,"One of the essential activities for quality assurance in software development is the software testing. Studies report that Software Testing is one of the most costly activities in the development process, can reach up to 50 percent of its total cost. One of the great challenges of conducting software testing is related to the automation of a mechanism known as ""test oracle"". This work presents an approach based on machine learning (ML) for automation of the test oracle mechanism in software. The approach uses historical usage data from an application captured by inserting a capture component into the application under test. These data go through a Knowledge Discovery in Database step and are then used for training to generate an oracle suitable for the application under test. Four experiments were executed with web applications to evaluate the proposed approach. The first and second experiments were performed with a fictitious application, with faults inserted randomly in the first experiment, inserted by a developer in the second one and inserted by mutation tests in third one. The fourth experiment was carried out with a large real application in order to assure the results of the preliminary experiments. The experiments presented indications of the suitability of the approach to the solution of the problem.",Machine learning | Test oracle | Testing automation,10,142-151,Conference Proceeding,Conference Paper,5.0,"Braga, Ronyérison;Neto, Pedro Santos;Rabêlo, Ricardo;Santiago, José;Souza, Matheus",56950143400;8894963200;25638826400;57611040600;56949923500,Universidade Federal do Piauí,Brazil,"one of the essential activities for quality assurance in software development is the software testing. studies report that software testing is one of the most costly activities in the development process, can reach up to 50 percent of its total cost. one of the great challenges of conducting software testing is related to the automation of a mechanism known as ""test oracle"". this work presents an approach based on machine learning (ml) for automation of the test oracle mechanism in software. the approach uses historical usage data from an application captured by inserting a capture component into the application under test. these data go through a knowledge discovery in database step and are then used for training to generate an oracle suitable for the application under test. four experiments were executed with web applications to evaluate the proposed approach. the first and second experiments were performed with a fictitious application, with faults inserted randomly in the first experiment, inserted by a developer in the second one and inserted by mutation tests in third one. the fourth experiment was carried out with a large real application in order to assure the results of the preliminary experiments. the experiments presented indications of the suitability of the approach to the solution of the problem.",a machine learning approach to generate test oracles
937,2-s2.0-85055691384,10.1109/ICIS.2018.8466414,Automated Inter-Artefact Traceability Establishment for DevOps Practice,Rubasinghe I.,"Proceedings - 17th IEEE/ACIS International Conference on Computer and Information Science, ICIS 2018",2018-09-14,"Software traceability is an important aspect in DevOps based software development environments. DevOps practices connect the development level and operational level software artefacts with frequent updates. Consequently, traceability management of the artefacts is essential to avoid the conflicts and inconsistencies during the continuous deployment activities. This paper addresses traceability establishment throughout the entire software development, considering both development and operational level artefacts. In this work, we have extended our previously developed SAT-Analyser traceability tool by establishing traceability between artefacts in source code, unit test scripts and build scrips. The accuracy of the traceability link establishment is evaluated using centrality-based network analysis techniques. The statistical results show an average of 71% accuracy.",DevOps | heterogeneous software artefacts | network analysis | SAT-Analyser tool | software evolution | traceability,8,211-216,Conference Proceeding,Conference Paper,3.0,"Rubasinghe, Iresha;Meedeniya, Dulani;Perera, Indika",57200649608;24779848000;54783210900,University of Moratuwa,Sri Lanka,"software traceability is an important aspect in devops based software development environments. devops practices connect the development level and operational level software artefacts with frequent updates. consequently, traceability management of the artefacts is essential to avoid the conflicts and inconsistencies during the continuous deployment activities. this paper addresses traceability establishment throughout the entire software development, considering both development and operational level artefacts. in this work, we have extended our previously developed sat-analyser traceability tool by establishing traceability between artefacts in source code, unit test scripts and build scrips. the accuracy of the traceability link establishment is evaluated using centrality-based network analysis techniques. the statistical results show an average of 71% accuracy.",automated inter-artefact traceability establishment for devops practice
939,2-s2.0-85064507873,10.1145/3310232.3310239,Task oriented programming and the internet of things,Lubbers M.,ACM International Conference Proceeding Series,2018-09-05,"In the omnipresent Internet of Things (IoT), tiny devices sense and alter the environment, process information and communicate with the world. These devices have limited amounts of processing power and memory. This imposes severe restrictions on their software and communication protocols. As a result, applications are composed of parts written in various programming languages that communicate in many different ways. This impedance mismatch hampers development and maintenance. In previous work we have shown how an IoT device can be programmed by defning an embedded Domain Specifc Language (eDSL). This paper shows how IoT tasks can be seemlessly integrated with a Task Oriented Programming (TOP) server such as iTasks. It allows the specifcation on a high level of abstraction of arbitrary collaborations between human beings, large systems, and now also IoT devices. The implementation is made in three steps. First, there is an interface to connect devices dynamically to an iTasks server using various communication protocols. Next, we solve the communication problem between IoT devices and the server by porting Shared Data Sources (SDSs) from TOP. As a result, data can be shared, viewed and updated from the server or IoT device. Finally, we crack the maintenance problem by switching from generating fxed code for the IoT devices to dynamically shipping code. It makes it possible to run multiple tasks on an IoT device and to decide at runtime what tasks that should be.",Clean | Distributed Applications | Functional Programming | Internet of Things | Task Oriented Programming,2,83-94,Conference Proceeding,Conference Paper,3.0,"Lubbers, Mart;Koopman, Pieter;Plasmeijer, Rinus",57201491980;15755564500;8393599800,Radboud Universiteit,Netherlands,"in the omnipresent internet of things (iot), tiny devices sense and alter the environment, process information and communicate with the world. these devices have limited amounts of processing power and memory. this imposes severe restrictions on their software and communication protocols. as a result, applications are composed of parts written in various programming languages that communicate in many different ways. this impedance mismatch hampers development and maintenance. in previous work we have shown how an iot device can be programmed by defning an embedded domain specifc language (edsl). this paper shows how iot tasks can be seemlessly integrated with a task oriented programming (top) server such as itasks. it allows the specifcation on a high level of abstraction of arbitrary collaborations between human beings, large systems, and now also iot devices. the implementation is made in three steps. first, there is an interface to connect devices dynamically to an itasks server using various communication protocols. next, we solve the communication problem between iot devices and the server by porting shared data sources (sdss) from top. as a result, data can be shared, viewed and updated from the server or iot device. finally, we crack the maintenance problem by switching from generating fxed code for the iot devices to dynamically shipping code. it makes it possible to run multiple tasks on an iot device and to decide at runtime what tasks that should be.",task oriented programming and the internet of things
940,2-s2.0-85054004059,10.1109/SCC.2018.00013,Towards executable specifications for microservices,Quenum J.,"Proceedings - 2018 IEEE International Conference on Services Computing, SCC 2018 - Part of the 2018 IEEE World Congress on Services",2018-09-05,"This paper presents an empirical approach for microservice automated testing. With the rise of the agile methodology, automated testing has gained momentum in software development, including using microservices as an architectural style. However, the tests are not always related to the core specifications of the system being developed. In this paper, we discuss an approach to derive the tests, especially the acceptance tests, from the specifications of the systems. To avoid any ambiguity in the specifications, we focus on the formal specifications of the system. To this end, we introduce intelligent agents as a conceptual unit to encapsulate the formal specifications of services. Indeed, a comparison of microservice tenets and the general characterization of agents reveals that both can be thought of as autonomous software entities, driven by goals and evolving within a distributed environment and communicating with one another. Using a real-world application we show how agent formal specifications can be linked to microservice automated testing.",Formal Specifications | Intelligent Agents | Services | Testing,3,41-48,Conference Proceeding,Conference Paper,2.0,"Quenum, Jose G.;Aknine, Samir",15758329800;6602746056,Namibia University of Science and Technology;Université Claude Bernard Lyon 1,Namibia;France,"this paper presents an empirical approach for microservice automated testing. with the rise of the agile methodology, automated testing has gained momentum in software development, including using microservices as an architectural style. however, the tests are not always related to the core specifications of the system being developed. in this paper, we discuss an approach to derive the tests, especially the acceptance tests, from the specifications of the systems. to avoid any ambiguity in the specifications, we focus on the formal specifications of the system. to this end, we introduce intelligent agents as a conceptual unit to encapsulate the formal specifications of services. indeed, a comparison of microservice tenets and the general characterization of agents reveals that both can be thought of as autonomous software entities, driven by goals and evolving within a distributed environment and communicating with one another. using a real-world application we show how agent formal specifications can be linked to microservice automated testing.",towards executable specifications for microservices
942,2-s2.0-85056526252,10.1145/3238147.3238194,Generating reusable web components from mockups,Bajammal M.,ASE 2018 - Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering,2018-09-03,"The transformation of a user interface mockup designed by a graphic designer to web components in the final app built by a web developer is often laborious, involving manual and time consuming steps. We propose an approach to automate this aspect of web development by generating reusable web components from a mockup. Our approach employs visual analysis of the mockup, and unsupervised learning of visual cues to create reusable web components (e.g., React components). We evaluated our approach, implemented in a tool called VizMod, on five real-world web mockups, and assessed the transformations and generated components through comparison with web development experts. The results show that VizMod achieves on average 94% precision and 75% recall in terms of agreement with the developers' assessment. Furthermore, the refactorings yielded 22% code reusability, on average.",Computer vision | Machine learning | Web components | Web refactoring | Web UI,7,601-611,Conference Proceeding,Conference Paper,3.0,"Bajammal, Mohammad;Mazinanian, Davood;Mesbah, Ali",56648017100;55308236700;17345931800,The University of British Columbia,Canada,"the transformation of a user interface mockup designed by a graphic designer to web components in the final app built by a web developer is often laborious, involving manual and time consuming steps. we propose an approach to automate this aspect of web development by generating reusable web components from a mockup. our approach employs visual analysis of the mockup, and unsupervised learning of visual cues to create reusable web components (e.g., react components). we evaluated our approach, implemented in a tool called vizmod, on five real-world web mockups, and assessed the transformations and generated components through comparison with web development experts. the results show that vizmod achieves on average 94% precision and 75% recall in terms of agreement with the developers' assessment. furthermore, the refactorings yielded 22% code reusability, on average.",generating reusable web components from mockups
943,2-s2.0-85056511900,10.1145/3238147.3238193,Characterizing the natural language descriptions in software logging statements,He P.,ASE 2018 - Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering,2018-09-03,"Logging is a common programming practice of great importance in modern software development, because software logs have been widely used in various software maintenance tasks. To provide high-quality logs, developers need to design the description text in logging statements carefully. Inappropriate descriptions will slow down or even mislead the maintenance process, such as postmortem analysis. However, there is currently a lack of rigorous guide and specifications on developer logging behaviors, which makes the construction of description text in logging statements a challenging problem. To fill this significant gap, in this paper, we systematically study what developers log, with focus on the usage of natural language descriptions in logging statements. We obtain 6 valuable findings by conducting source code analysis on 10 Java projects and 7 C# projects, which contain 28,532,975 LOC and 115,159 logging statements in total. Furthermore, our study demonstrates the potential of automated description text generation for logging statements by obtaining up to 49.04 BLEU-4 score and 62.1 ROUGE-L score using a simple information retrieval method. To facilitate future research in this field, the datasets have been publicly released.",Empirical study | Logging | Natural language processing,34,178-189,Conference Proceeding,Conference Paper,4.0,"He, Pinjia;He, Shilin;Chen, Zhuangbin;Lyu, Michael R.",56241158600;57191853952;57204650131;7006811415,Chinese University of Hong Kong,Hong Kong,"logging is a common programming practice of great importance in modern software development, because software logs have been widely used in various software maintenance tasks. to provide high-quality logs, developers need to design the description text in logging statements carefully. inappropriate descriptions will slow down or even mislead the maintenance process, such as postmortem analysis. however, there is currently a lack of rigorous guide and specifications on developer logging behaviors, which makes the construction of description text in logging statements a challenging problem. to fill this significant gap, in this paper, we systematically study what developers log, with focus on the usage of natural language descriptions in logging statements. we obtain 6 valuable findings by conducting source code analysis on 10 java projects and 7 c# projects, which contain 28,532,975 loc and 115,159 logging statements in total. furthermore, our study demonstrates the potential of automated description text generation for logging statements by obtaining up to 49.04 bleu-4 score and 62.1 rouge-l score using a simple information retrieval method. to facilitate future research in this field, the datasets have been publicly released.",characterizing the natural language descriptions in software logging statements
944,2-s2.0-85056491760,10.1145/3238147.3238182,Seede: Simultaneous execution and editing in a development environment,Reiss S.P.,ASE 2018 - Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering,2018-09-03,"We introduce a tool within the Code Bubbles development environment that allows for continuous execution as the programmer edits. The tool, SEEDE, shows both the intermediate and final results of execution in terms of variables, control and data flow, output, and graphics. These results are updated as the user edits. The tool can be used to help the user write new code or to find and fix bugs. The tool is explicitly designed to let the user quickly explore the execution of a method along with all the code it invokes, possibly while writing or modifying the code. The user can start continuous execution either at a breakpoint or for a test case. This paper describes the tool, its implementation, and its user interface. It presents an initial user study of the tool demonstrating its potential utility.",Continuous execution | Debugging | Integrated development environments | Live programming,1,270-281,Conference Proceeding,Conference Paper,3.0,"Reiss, Steven P.;Xin, Qi;Huang, Jeff",7005553388;57189692731;55742390500,Brown University,United States,"we introduce a tool within the code bubbles development environment that allows for continuous execution as the programmer edits. the tool, seede, shows both the intermediate and final results of execution in terms of variables, control and data flow, output, and graphics. these results are updated as the user edits. the tool can be used to help the user write new code or to find and fix bugs. the tool is explicitly designed to let the user quickly explore the execution of a method along with all the code it invokes, possibly while writing or modifying the code. the user can start continuous execution either at a breakpoint or for a test case. this paper describes the tool, its implementation, and its user interface. it presents an initial user study of the tool demonstrating its potential utility.",seede: simultaneous execution and editing in a development environment
946,2-s2.0-85056283176,10.7160/aol.2018.100306,"Novel approach for creation, storage and presentation of online information content",Masner J.,Agris On-line Papers in Economics and Informatics,2018-09-01,"The paper provides an overview of a methodology for creation, storage and presentation of online information content (in World Wide Web environment). It is primarily intended to be utilized by open source content management systems and applications for publication of articles, news, papers etc. Open source software and, in particular, content management systems are broadly used in areas such as agriculture, rural development, public and non-profit sector. The methodology covers processes of content creation and updating in general, storage structure and presentation with consideration for sharing and exchanging possibilities. Authors can benefit from easier content creation process as well as consistent output visibility in real time. Structured and standardized storage structure can simplify development of modules, extensions or application libraries. Moreover, the process of CMS (or application) upgrade or transition to a different one which utilizes the methodology and its standards can be simplified and accelerated as well. Finally, the methodology can bring economic benefits by acceleration of CMS development and publication process.",CMS | HTML | Information content | WWW | WYSIWYG,2,69-77,Journal,Article,3.0,"Masner, Jan;Jarolímek, Jan;Kánská, Eva",55505508700;22985119700;55316911100,Czech University of Life Sciences Prague,Czech Republic,"the paper provides an overview of a methodology for creation, storage and presentation of online information content (in world wide web environment). it is primarily intended to be utilized by open source content management systems and applications for publication of articles, news, papers etc. open source software and, in particular, content management systems are broadly used in areas such as agriculture, rural development, public and non-profit sector. the methodology covers processes of content creation and updating in general, storage structure and presentation with consideration for sharing and exchanging possibilities. authors can benefit from easier content creation process as well as consistent output visibility in real time. structured and standardized storage structure can simplify development of modules, extensions or application libraries. moreover, the process of cms (or application) upgrade or transition to a different one which utilizes the methodology and its standards can be simplified and accelerated as well. finally, the methodology can bring economic benefits by acceleration of cms development and publication process.","novel approach for creation, storage and presentation of online information content"
948,2-s2.0-85052787750,10.1002/acm2.12396,Automated data mining of a plan-check database and example application,Dunn L.,Journal of Applied Clinical Medical Physics,2018-09-01,"Purpose: The aim of this work was to present the development and example application of an automated data mining software platform that preforms bulk analysis of results and patient data passing through the 3D plan and delivery QA system, Mobius3D. Methods: Python, matlab, and Java were used to create an interface that reads JavaScript Object Notation (JSON) created for every approved Mobius3D pre-treatment plan-check. The aforementioned JSON files contain all the information for every pre-treatment QA check performed by Mobius3D, including all 3D dose, CT, structure set information, as well as all plan information and patient demographics. Two Graphical User Interfaces (GUIs) were created, the first is called Mobius3D-Database (M3D-DB) and presents the check results in both filterable tabular and graphical form. These data are presented for all patients and includes mean dose differences, 90% coverage, 3D gamma pass rate percentages, treatment sites, machine, beam energy, Multi-Leaf Collimator (MLC) mode, treatment planning system (TPS), plan names, approvers, dates and times. Group statistics and statistical process control levels are then calculated based on filter settings. The second GUI, called Mobius3D organ at risk (M3DOAR), analyzes dose-volume histogram data for all patients and all Organs-at-Risk (OAR). The design of the software is such that all treatment parameters and treatment site information are able to be filtered and sorted with the results, plots, and statistics updated. Results: The M3D-DB software can summarize and filter large numbers of plan-checks from Mobius3D. The M3DOAR software is also able to analyze large amounts of dose-volume data for patient groups which may prove useful in clinical trials, where OAR doses for large numbers of patients can be compared and correlated. Target DVHs can also be analyzed en mass. Conclusions: This work demonstrates a method to extract the large amount of treatment data for every patient that is stored by Mobius3D but not easily accessible. With scripting, it is possible to mine this data for research and clinical trials as well as patient and TPS QA.",Mobius3D | plan-check | statistical process control | treatment planning,2,739-748,Journal,Article,2.0,"Dunn, Leon;Jolly, David",54383205500;57193334447,Icon Cancer Centre,Australia,"purpose: the aim of this work was to present the development and example application of an automated data mining software platform that preforms bulk analysis of results and patient data passing through the 3d plan and delivery qa system, mobius3d. methods: python, matlab, and java were used to create an interface that reads javascript object notation (json) created for every approved mobius3d pre-treatment plan-check. the aforementioned json files contain all the information for every pre-treatment qa check performed by mobius3d, including all 3d dose, ct, structure set information, as well as all plan information and patient demographics. two graphical user interfaces (guis) were created, the first is called mobius3d-database (m3d-db) and presents the check results in both filterable tabular and graphical form. these data are presented for all patients and includes mean dose differences, 90% coverage, 3d gamma pass rate percentages, treatment sites, machine, beam energy, multi-leaf collimator (mlc) mode, treatment planning system (tps), plan names, approvers, dates and times. group statistics and statistical process control levels are then calculated based on filter settings. the second gui, called mobius3d organ at risk (m3doar), analyzes dose-volume histogram data for all patients and all organs-at-risk (oar). the design of the software is such that all treatment parameters and treatment site information are able to be filtered and sorted with the results, plots, and statistics updated. results: the m3d-db software can summarize and filter large numbers of plan-checks from mobius3d. the m3doar software is also able to analyze large amounts of dose-volume data for patient groups which may prove useful in clinical trials, where oar doses for large numbers of patients can be compared and correlated. target dvhs can also be analyzed en mass. conclusions: this work demonstrates a method to extract the large amount of treatment data for every patient that is stored by mobius3d but not easily accessible. with scripting, it is possible to mine this data for research and clinical trials as well as patient and tps qa.",automated data mining of a plan-check database and example application
949,2-s2.0-85051167503,10.1002/spe.2602,LDMBL: An architecture for reducing code duplication in heavyweight binary instrumentations,Momeni B.,Software - Practice and Experience,2018-09-01,"Emergence of instrumentation frameworks has vastly contributed to the software engineering practices. As the instrumentation use cases become more complex, complexity of instrumenting programs also increases, leading to a higher risk of software defects, increased development time, and decreased maintainability. In security applications such as symbolic execution and taint analysis, which need to instrument a large number of instruction types, this complexity is prominent. This paper presents an architecture based on the Pin binary instrumentation framework to abstract the low-level OS and hardware-dependent implementation details, facilitate code reuse in heavyweight instrumentation use cases, and improve instrumenting program development time. Instructions of x86 and x86-64 hardware architectures are formally categorized using the Z language based on the Pin framework API. This categorization is used to automate the instrumentation phase on the basis of a configuration list. Furthermore, instrumentation context data such as register data are modeled in an object-oriented scheme. This makes it possible to focus the instrumenting program development time on writing the essential analysis logics while access to low-level OS and hardware dependencies are streamlined. The proposed architecture is evaluated by instrumenting 135 instruction types in a concrete symbolic execution engine, resulting in a reduction of the instrumenting program size by 59.7%. Furthermore, performance overhead measure against the SPEC CINT2006 programs is limited to 8.7%.",dynamic binary instrumentation | heavyweight instrumentation | Pin-based architecture | Z language specification,1,1642-1659,Journal,Article,2.0,"Momeni, Behnam;Kharrazi, Mehdi",54942263800;6701798485,Sharif University of Technology,Iran,"emergence of instrumentation frameworks has vastly contributed to the software engineering practices. as the instrumentation use cases become more complex, complexity of instrumenting programs also increases, leading to a higher risk of software defects, increased development time, and decreased maintainability. in security applications such as symbolic execution and taint analysis, which need to instrument a large number of instruction types, this complexity is prominent. this paper presents an architecture based on the pin binary instrumentation framework to abstract the low-level os and hardware-dependent implementation details, facilitate code reuse in heavyweight instrumentation use cases, and improve instrumenting program development time. instructions of x86 and x86-64 hardware architectures are formally categorized using the z language based on the pin framework api. this categorization is used to automate the instrumentation phase on the basis of a configuration list. furthermore, instrumentation context data such as register data are modeled in an object-oriented scheme. this makes it possible to focus the instrumenting program development time on writing the essential analysis logics while access to low-level os and hardware dependencies are streamlined. the proposed architecture is evaluated by instrumenting 135 instruction types in a concrete symbolic execution engine, resulting in a reduction of the instrumenting program size by 59.7%. furthermore, performance overhead measure against the spec cint2006 programs is limited to 8.7%.",ldmbl: an architecture for reducing code duplication in heavyweight binary instrumentations
950,2-s2.0-85047546168,10.1016/j.gsf.2018.04.001,IsoplotR: A free and open toolbox for geochronology,Vermeesch P.,Geoscience Frontiers,2018-09-01,"This paper reviews the basic principles of radiometric geochronology as implemented in a new software package called IsoplotR, which was designed to be free, flexible and future-proof. IsoplotR is free because it is written in non-proprietary languages (R, Javascript and HTML) and is released under the GPL license. The program is flexible because its graphical user interface (GUI) is separated from the command line functionality, and because its code is completely open for inspection and modification. To increase future-proofness, the software is built on free and platform-independent foundations that adhere to international standards, have existed for several decades, and continue to grow in popularity. IsoplotR currently includes functions for U-Pb, Pb-Pb, 40Ar/39Ar, Rb-Sr, Sm-Nd, Lu-Hf, Re-Os, U-Th-He, fission track and U-series disequilibrium dating. It implements isochron regression in two and three dimensions, visualises multi-aliquot datasets as cumulative age distributions, kernel density estimates and radial plots, and calculates weighted mean ages using a modified Chauvenet outlier detection criterion that accounts for the analytical uncertainties in heteroscedastic datasets. Overdispersion of geochronological data with respect to these analytical uncertainties can be attributed to either a proportional underestimation of the analytical uncertainties, or to an additive geological scatter term. IsoplotR keeps track of error correlations of the isotopic ratio measurements within aliquots of the same samples. It uses a statistical framework that will allow it to handle error correlations between aliquots in the future. Other ongoing developments include the implementation of alternative user interfaces and the integration of IsoplotR with other data reduction software.",Geochronology | Software | Statistics,801,1479-1493,Journal,Article,1.0,"Vermeesch, Pieter",6507304421,University College London,United Kingdom,"this paper reviews the basic principles of radiometric geochronology as implemented in a new software package called isoplotr, which was designed to be free, flexible and future-proof. isoplotr is free because it is written in non-proprietary languages (r, javascript and html) and is released under the gpl license. the program is flexible because its graphical user interface (gui) is separated from the command line functionality, and because its code is completely open for inspection and modification. to increase future-proofness, the software is built on free and platform-independent foundations that adhere to international standards, have existed for several decades, and continue to grow in popularity. isoplotr currently includes functions for u-pb, pb-pb, 40ar/39ar, rb-sr, sm-nd, lu-hf, re-os, u-th-he, fission track and u-series disequilibrium dating. it implements isochron regression in two and three dimensions, visualises multi-aliquot datasets as cumulative age distributions, kernel density estimates and radial plots, and calculates weighted mean ages using a modified chauvenet outlier detection criterion that accounts for the analytical uncertainties in heteroscedastic datasets. overdispersion of geochronological data with respect to these analytical uncertainties can be attributed to either a proportional underestimation of the analytical uncertainties, or to an additive geological scatter term. isoplotr keeps track of error correlations of the isotopic ratio measurements within aliquots of the same samples. it uses a statistical framework that will allow it to handle error correlations between aliquots in the future. other ongoing developments include the implementation of alternative user interfaces and the integration of isoplotr with other data reduction software.",isoplotr: a free and open toolbox for geochronology
951,2-s2.0-85053864732,10.1109/ZINC.2018.8448513,Web Server and QR Decoder Applications for Xilinx FPGA Boards,Horvat Z.,"2018 Zooming Innovation in Consumer Technologies Conference, ZINC 2018",2018-08-27,"The microelectronic industry is undergoing dramatic changes nowadays. Every year faster and more advanced systems are released. They are capable of running more complex tasks than before for a fraction of a PCs price. The task of this paper is realization of two applications that run on an embedded system. The first one is a QR (Quick Response) image decoder and the second one is a web server. The requirement was for the QR decoder to decode a stream of images and for the web server to process certain HTTP requests. Most existing versions of these applications are designed to run on PCs. Since only a part of their functionalities were needed, the best solution was to develop the applications in C programming language and implement them on a system as bare-metal programs. With this approach the performance can be maximized and the development time of the software shortened.",FPGA boards | JSON | QR decoder | RTOS | web server | Xilinx | Xilinx Vivado SDK,2,148-151,Conference Proceeding,Conference Paper,3.0,"Horvat, Zoltan;Ilic, Velibor;Nikolic, Milos",57193399742;26221781900;55614461000,Institute for Computer Based Systems,Serbia,"the microelectronic industry is undergoing dramatic changes nowadays. every year faster and more advanced systems are released. they are capable of running more complex tasks than before for a fraction of a pcs price. the task of this paper is realization of two applications that run on an embedded system. the first one is a qr (quick response) image decoder and the second one is a web server. the requirement was for the qr decoder to decode a stream of images and for the web server to process certain http requests. most existing versions of these applications are designed to run on pcs. since only a part of their functionalities were needed, the best solution was to develop the applications in c programming language and implement them on a system as bare-metal programs. with this approach the performance can be maximized and the development time of the software shortened.",web server and qr decoder applications for xilinx fpga boards
952,2-s2.0-85055509086,10.1145/3233027.3233049,Integrating the common variability language with multilanguage annotations for web engineering,Horcas J.M.,ACM International Conference Proceeding Series,2018-08-20,"Web applications development involves managing a high diversity of files and resources like code, pages or style sheets, implemented in different languages. To deal with the automatic generation of custom-made configurations of web applications, industry usually adopts annotation-based approaches even though the majority of studies encourage the use of composition-based approaches to implement Software Product Lines. Recent work tries to combine both approaches to get the complementary benefits. However, technological companies are reticent to adopt new development paradigms such as feature-oriented programming or aspect-oriented programming. Moreover, it is extremely difficult, or even impossible, to apply these programming models to web applications, mainly because of their multilingual nature, since their development involves multiple types of source code (Java, Groovy, JavaScript), templates (HTML, Markdown, XML), style sheet files (CSS and its variants, such as SCSS), and other files (JSON, YML, shell scripts). We propose to use the Common Variability Language as a composition-based approach and integrate annotations to manage fine grained variability of a Software Product Line for web applications. In this paper, we (i) show that existing composition and annotation-based approaches, including some well-known combinations, are not appropriate to model and implement the variability of web applications; and (ii) present a combined approach that effectively integrates annotations into a composition-based approach for web applications. We implement our approach and show its applicability with an industrial real-world system.",Annotations | Automation | Composition | CVL | SPL | Variability | Web engineering,7,196-207,Conference Proceeding,Conference Paper,4.0,"Horcas, Jose Miguel;Cortiñas, Alejandro;Fuentes, Lidia;Luaces, Miguel R.",55947780300;57021823200;7006580503;8694723200,Universidade da Coruña;Universidad de Málaga,Spain;Spain,"web applications development involves managing a high diversity of files and resources like code, pages or style sheets, implemented in different languages. to deal with the automatic generation of custom-made configurations of web applications, industry usually adopts annotation-based approaches even though the majority of studies encourage the use of composition-based approaches to implement software product lines. recent work tries to combine both approaches to get the complementary benefits. however, technological companies are reticent to adopt new development paradigms such as feature-oriented programming or aspect-oriented programming. moreover, it is extremely difficult, or even impossible, to apply these programming models to web applications, mainly because of their multilingual nature, since their development involves multiple types of source code (java, groovy, javascript), templates (html, markdown, xml), style sheet files (css and its variants, such as scss), and other files (json, yml, shell scripts). we propose to use the common variability language as a composition-based approach and integrate annotations to manage fine grained variability of a software product line for web applications. in this paper, we (i) show that existing composition and annotation-based approaches, including some well-known combinations, are not appropriate to model and implement the variability of web applications; and (ii) present a combined approach that effectively integrates annotations into a composition-based approach for web applications. we implement our approach and show its applicability with an industrial real-world system.",integrating the common variability language with multilanguage annotations for web engineering
954,2-s2.0-85056563612,10.11975/j.issn.1002-6819.2018.16.018,Design and implementation of agricultural production management information system based on WebGIS,Wei Y.,Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering,2018-08-15,"In order to solve the problems that data are difficult to save, planting structure map is difficult to draw manually, and the existing management system does not match the demand in the present stage of farm management, an agricultural production management information system is designed and developed based on WebGIS technology, aimed at meeting the request of agricultural production management for large or medium-sized farms with the mode of ""farm + production team"". The system is developed with Browser/Server software architecture by using Java as development language. The database is designed as attribute database and spatial database thinking about the multilevel and spatiotemporal characteristics of farm data. The attribute database is created by MySQL database management system. ArcGIS platform is used to construct spatial database, and publish maps as services to ArcGIS Server sites. The development environment integrates Spring MVC (model-view-controller), JPA (Java persistence API), and Hibernate, so as to achieve the effect of layered development. WebGIS front-end development is implemented by ArcGIS API for JavaScript. Bootstrap response design is adopted to support user access to the system through mobile terminals such as smartphones, and tablets. The implementation of the system is divided into 2 steps. Firstly, we give structural expression and management for the factors such as the general situation of the farm, the establishment of the organization, the production resources, the planting structure and the field management process. Secondly, the farm on the ground is managed and displayed on the Internet. The goal is to realize the whole process information management of crop production. The process is from pre-sowing to the field management and then to the harvest, and so on. Farm managers can report and examine this information at any time and anywhere. The main functional modules include farm organization management, production material management, production datum reporting, thematic analysis, information service publication and system management. Production materials include farmer, agricultural machinery and arable land. The production datum consists of planting plan, farming activity, farming progress, disease and insect, and disaster situations. Based on the datum of the production datum reporting module, farm planting structure map (pie chart), production team planting structure map (histogram), and field planting distribution map can be dynamically generated. System management includes user management, crop management and module management. Three types of users named system administrator, farm user and production team user, are designed in the system. Each type of user has different functional rights and is set up through the user management module. Crop management module provides a way for farm user to manage the crops grown on their own farm, including the setting of the display attributes of different crops on the map. Module management allows different users to customize the functional modules they need. At present, the system has been successfully applied in some farms or agricultural bases, such as Longkang Farm in Anhui Province, Xeltala Farm and Tenihe Farm in Hulunbuir City, academician workstation, and so on. Practical applications show that the system has the advantages of being easy to use, strong universality and good extensibility. For example, data flows and thematic maps are independent, so the information management function is not affected when some farms fail to customize the farm space database. The system is also applicable for those farms such as agricultural research stations, cooperatives, and family farms, in which farmers manage the field directly. The system can assist the farm managers to work scientifically, conveniently and efficiently, so as to improve the informatization and modernization level of farm production management, also enhance leaders' macro decision-making ability.",Farms | Information systems | Management | Planting structure | Thematic analysis | WebGIS,13,139-147,Journal,Article,4.0,"Wei, Yuanyuan;Wang, Xue;Wang, Rujing;Gui, Yuanmiao",8396727500;57206604388;55013277300;56288759600,University of Science and Technology of China;Hefei Institutes of Physical Sciences Chinese Academy of Sciences,China;China,"in order to solve the problems that data are difficult to save, planting structure map is difficult to draw manually, and the existing management system does not match the demand in the present stage of farm management, an agricultural production management information system is designed and developed based on webgis technology, aimed at meeting the request of agricultural production management for large or medium-sized farms with the mode of ""farm + production team"". the system is developed with browser/server software architecture by using java as development language. the database is designed as attribute database and spatial database thinking about the multilevel and spatiotemporal characteristics of farm data. the attribute database is created by mysql database management system. arcgis platform is used to construct spatial database, and publish maps as services to arcgis server sites. the development environment integrates spring mvc (model-view-controller), jpa (java persistence api), and hibernate, so as to achieve the effect of layered development. webgis front-end development is implemented by arcgis api for javascript. bootstrap response design is adopted to support user access to the system through mobile terminals such as smartphones, and tablets. the implementation of the system is divided into 2 steps. firstly, we give structural expression and management for the factors such as the general situation of the farm, the establishment of the organization, the production resources, the planting structure and the field management process. secondly, the farm on the ground is managed and displayed on the internet. the goal is to realize the whole process information management of crop production. the process is from pre-sowing to the field management and then to the harvest, and so on. farm managers can report and examine this information at any time and anywhere. the main functional modules include farm organization management, production material management, production datum reporting, thematic analysis, information service publication and system management. production materials include farmer, agricultural machinery and arable land. the production datum consists of planting plan, farming activity, farming progress, disease and insect, and disaster situations. based on the datum of the production datum reporting module, farm planting structure map (pie chart), production team planting structure map (histogram), and field planting distribution map can be dynamically generated. system management includes user management, crop management and module management. three types of users named system administrator, farm user and production team user, are designed in the system. each type of user has different functional rights and is set up through the user management module. crop management module provides a way for farm user to manage the crops grown on their own farm, including the setting of the display attributes of different crops on the map. module management allows different users to customize the functional modules they need. at present, the system has been successfully applied in some farms or agricultural bases, such as longkang farm in anhui province, xeltala farm and tenihe farm in hulunbuir city, academician workstation, and so on. practical applications show that the system has the advantages of being easy to use, strong universality and good extensibility. for example, data flows and thematic maps are independent, so the information management function is not affected when some farms fail to customize the farm space database. the system is also applicable for those farms such as agricultural research stations, cooperatives, and family farms, in which farmers manage the field directly. the system can assist the farm managers to work scientifically, conveniently and efficiently, so as to improve the informatization and modernization level of farm production management, also enhance leaders' macro decision-making ability.",design and implementation of agricultural production management information system based on webgis
955,2-s2.0-85052535952,10.1109/ICUFN.2018.8436625,Towards Application-Aware Networking: ML-Based End-to-End Application KPI/QoE Metrics Characterization in SDN,Jahromi H.Z.,"International Conference on Ubiquitous and Future Networks, ICUFN",2018-08-14,Software Defined Networking (SDN) presents a unique networking paradigm that facilitates the development of network innovations. This paper aims to improve application awareness by incorporating Machine Learning (ML) techniques within an open source SDN architecture. The paper explores how end-to-end application Key Performance Indicator (KPI) metrics can be designed and utilized for the purpose of application awareness in networks. The main goal of this research is to characterize application KPI metrics using a suitable ML approach based on available network data. Resource allocation and network orchestration tasks can be automated based on the findings. A key facet of this research is introducing a novel feedback interface to the SDN's Northbound Interface that receives realtime performance feedback from applications. This paper aim to show how could we exploit the applications feedback to determine useful characteristics of an application's traffic. A mapping application with a defined KPI is used for experimentation. Linear multiple regression is used to derive a characteristic relationship between the application KPI and the network metrics.,Application Awareness | KPI | QoE | SDN,12,126-131,Conference Proceeding,Conference Paper,3.0,"Jahromi, Hamed Z.;Hines, Andrew;Delanev, Declan T.",57203640926;35179621200;57203637463,University College Dublin,Ireland,software defined networking (sdn) presents a unique networking paradigm that facilitates the development of network innovations. this paper aims to improve application awareness by incorporating machine learning (ml) techniques within an open source sdn architecture. the paper explores how end-to-end application key performance indicator (kpi) metrics can be designed and utilized for the purpose of application awareness in networks. the main goal of this research is to characterize application kpi metrics using a suitable ml approach based on available network data. resource allocation and network orchestration tasks can be automated based on the findings. a key facet of this research is introducing a novel feedback interface to the sdn's northbound interface that receives realtime performance feedback from applications. this paper aim to show how could we exploit the applications feedback to determine useful characteristics of an application's traffic. a mapping application with a defined kpi is used for experimentation. linear multiple regression is used to derive a characteristic relationship between the application kpi and the network metrics.,towards application-aware networking: ml-based end-to-end application kpi/qoe metrics characterization in sdn
956,2-s2.0-85052537713,10.1109/ICALT.2018.00062,Model driven approach for virtual lab authoring-chemical sciences labs,Sanagavarapu L.M.,"Proceedings - IEEE 18th International Conference on Advanced Learning Technologies, ICALT 2018",2018-08-10,"Virtual Labs allow performance of experiments without real world instrumentation needs. Most of these virtual experiments are simulation based and developed using proprietary or Open Source simulation, Adobe Flash, and other client side software. The procedural steps involved in conducting these experiments are hardwired and require software modification for enhancements or alignment to the course structure. We propose a model based approach that eases development of virtual experiments without dependency on software programmers for any changes. We demonstrate our model driven based approach on Chemical Sciences labs of Virtual Labs, a Government of India initiative. With our model driven based approach, the effort for new experiment development or FOSS conversion of existing experiments that were using outdated technologies is less than a person day as compared to more than a person month.",Chemical Sciences | Lab Authoring | Model Driven Development | Virtual Lab,2,241-243,Conference Proceeding,Conference Paper,3.0,"Sanagavarapu, Lalit Mohan;Choppella, Venkatesh;Reddy, Y. R.",57194516973;6507651604;55749120700,"International Institute of Information Technology, Hyderabad",India,"virtual labs allow performance of experiments without real world instrumentation needs. most of these virtual experiments are simulation based and developed using proprietary or open source simulation, adobe flash, and other client side software. the procedural steps involved in conducting these experiments are hardwired and require software modification for enhancements or alignment to the course structure. we propose a model based approach that eases development of virtual experiments without dependency on software programmers for any changes. we demonstrate our model driven based approach on chemical sciences labs of virtual labs, a government of india initiative. with our model driven based approach, the effort for new experiment development or foss conversion of existing experiments that were using outdated technologies is less than a person day as compared to more than a person month.",model driven approach for virtual lab authoring-chemical sciences labs
957,2-s2.0-85052510069,10.1109/QRS-C.2018.00046,On the Effectiveness of Automatically Inferred Invariants in Detecting Regression Faults in Spreadsheets,Roy S.,"Proceedings - 2018 IEEE 18th International Conference on Software Quality, Reliability, and Security Companion, QRS-C 2018",2018-08-09,"Automatically inferred invariants have been found to be successful in detecting regression faults in traditional software, but their application has not been explored in the context of spreadsheets. In this paper, we investigate the effectiveness of automatically inferred invariants in detecting regression faults in spreadsheets. We conduct an exploratory empirical study on eight spreadsheets taken from VEnron and EUSES corpora. We apply automatic invariant inference to them, create tests based on the inferred invariants, and finally seed the sheets with faults. Results indicate that the effectiveness of the inferred invariants, in terms of accuracy of fault detection, largely varies from spreadsheet to spreadsheet. The effectiveness is found to be affected by the formulas and data contained in the spreadsheets, and also by the type of faults to be detected.",End-user Development | Fault Detection | Invariant Analysis | Regression Faults | Software Quality | Spreadsheets,0,199-206,Conference Proceeding,Conference Paper,3.0,"Roy, Sohon;Van Deursen, Arie;Hermans, Felienne",56562208400;7003969355;35573133300,Delft University of Technology,Netherlands,"automatically inferred invariants have been found to be successful in detecting regression faults in traditional software, but their application has not been explored in the context of spreadsheets. in this paper, we investigate the effectiveness of automatically inferred invariants in detecting regression faults in spreadsheets. we conduct an exploratory empirical study on eight spreadsheets taken from venron and euses corpora. we apply automatic invariant inference to them, create tests based on the inferred invariants, and finally seed the sheets with faults. results indicate that the effectiveness of the inferred invariants, in terms of accuracy of fault detection, largely varies from spreadsheet to spreadsheet. the effectiveness is found to be affected by the formulas and data contained in the spreadsheets, and also by the type of faults to be detected.",on the effectiveness of automatically inferred invariants in detecting regression faults in spreadsheets
958,2-s2.0-85052124996,10.1109/ISVLSI.2018.00107,Towards dynamic execution environment for system security protection against hardware flaws,Schmitz K.,"Proceedings of IEEE Computer Society Annual Symposium on VLSI, ISVLSI",2018-08-07,"Attacks exploiting security flaws in software are very common. They are typically addressed during the ongoing software development process or by providing software patches. Attacks making use of hardware related flaws via malicious software recently gained popularity. Prominent examples are errata-based, aging-related or, for example, the infamous Rowhammer-Attack. In this paper, we present an approach to detect software-based attacks which exploit hardware flaws. Since the flaws are typically triggered by characteristic instruction sequences, our approach is implemented as a dynamic execution environment for program monitoring at runtime. Several case studies underline the effectiveness and the low overhead of our approach.",Aho Corasick | QEMU | Runtime Monitoring,1,557-562,Conference Proceeding,Conference Paper,5.0,"Schmitz, Kenneth;Keszocze, Oliver;Schmidt, Jurij;Grobe, Daniel;Drechsler, Rolf",56278408400;38561733200;57203532368;6603842663;55172914000,German Research Center for Artificial Intelligence (DFKI);Universität Bremen,Germany;Germany,"attacks exploiting security flaws in software are very common. they are typically addressed during the ongoing software development process or by providing software patches. attacks making use of hardware related flaws via malicious software recently gained popularity. prominent examples are errata-based, aging-related or, for example, the infamous rowhammer-attack. in this paper, we present an approach to detect software-based attacks which exploit hardware flaws. since the flaws are typically triggered by characteristic instruction sequences, our approach is implemented as a dynamic execution environment for program monitoring at runtime. several case studies underline the effectiveness and the low overhead of our approach.",towards dynamic execution environment for system security protection against hardware flaws
959,2-s2.0-85052331215,10.1109/QRS.2018.00036,How do defects hurt qualities? An empirical study on characterizing a software maintainability ontology in open source software,Chen C.,"Proceedings - 2018 IEEE 18th International Conference on Software Quality, Reliability, and Security, QRS 2018",2018-08-02,"Beyond the functional requirements of a system, software maintainability is essential for project success. While there exists a large knowledge base of software maintainability, this knowledge is rarely used in open source software due to the large number of developers and inefficiency in identifying quality issues. To effectively utilize the current knowledge base in practice requires a deeper understanding of how problems associated with the different qualities arise and change over time. In this paper, we sample over 6000 real bugs found from several Mozilla products to examine how maintainability is expressed with subgroups of repairability and modifiability. Furthermore, we manually study how these qualities evolve as the products mature, what the root causes of the bugs are for each quality and the impact and dependency of each quality. Our results inform which areas should be focused on to ensure maintainability at different stages of the development and maintenance process.",Software maintainability | Software maintainability ontology | Software quality | Software quality measurement,11,226-237,Conference Proceeding,Conference Paper,5.0,"Chen, Celia;Shi, Lin;Shoga, Michael;Wang, Qing;Boehm, Barry",56205428300;37061770900;57202537304;55698296000;7102111447,University of Southern California;University of Chinese Academy of Sciences;Institute of Software Chinese Academy of Sciences;Occidental College,United States;China;China;United States,"beyond the functional requirements of a system, software maintainability is essential for project success. while there exists a large knowledge base of software maintainability, this knowledge is rarely used in open source software due to the large number of developers and inefficiency in identifying quality issues. to effectively utilize the current knowledge base in practice requires a deeper understanding of how problems associated with the different qualities arise and change over time. in this paper, we sample over 6000 real bugs found from several mozilla products to examine how maintainability is expressed with subgroups of repairability and modifiability. furthermore, we manually study how these qualities evolve as the products mature, what the root causes of the bugs are for each quality and the impact and dependency of each quality. our results inform which areas should be focused on to ensure maintainability at different stages of the development and maintenance process.",how do defects hurt qualities? an empirical study on characterizing a software maintainability ontology in open source software
960,2-s2.0-85052291159,10.1109/QRS.2018.00048,The State of practice on Virtual Reality (VR) applications: An exploratory study on github and stack overflow,Ghrairi N.,"Proceedings - 2018 IEEE 18th International Conference on Software Quality, Reliability, and Security, QRS 2018",2018-08-02,"Virtual Reality (VR) is a computer technology that holds the promise of revolutionizing the way we live. The release in 2016 of new-generation headsets from Facebook-owned Oculus and HTC has renewed the interest in that technology. Thousands of VR applications have been developed over the past years, but most software developers lack formal training on this technology. In this paper, we propose descriptive information on the state of practice of VR applications' development to understand the level of maturity of this new technology from the perspective of Software Engineering (SE). To do so, we focused on the analysis of 320 VR open source projects from Github to determine which are the most popular languages and engines used in VR projects, and evaluate the quality of the projects from a software metric perspective. To get further insights on VR development, we also manually analyzed nearly 300 questions from Stack Overflow. Our results show that (1) VR projects on GitHub are currently mostly small to medium projects, and (2) the most popular languages are JavaScript and C#. Unity is the most used game engine during VR development and the most discussed topic on Stack Overflow. Overall, our exploratory study is one of the very first of its kind for VR projects and provides material that is hopefully a starting point for further research on challenges and opportunities for VR software development.",Empirical study | Software quality | State of practice | Virtual Reality,4,356-366,Conference Proceeding,Conference Paper,5.0,"Ghrairi, Naoures;Kpodjedo, Sègla;Barrak, Amine;Petrillo, Fábio;Khomh, Foutse",57203577018;25926481300;57203579075;25655430600;24724747600,École de Technologie Supérieure;Polytechnique Montréal,Canada;Canada,"virtual reality (vr) is a computer technology that holds the promise of revolutionizing the way we live. the release in 2016 of new-generation headsets from facebook-owned oculus and htc has renewed the interest in that technology. thousands of vr applications have been developed over the past years, but most software developers lack formal training on this technology. in this paper, we propose descriptive information on the state of practice of vr applications' development to understand the level of maturity of this new technology from the perspective of software engineering (se). to do so, we focused on the analysis of 320 vr open source projects from github to determine which are the most popular languages and engines used in vr projects, and evaluate the quality of the projects from a software metric perspective. to get further insights on vr development, we also manually analyzed nearly 300 questions from stack overflow. our results show that (1) vr projects on github are currently mostly small to medium projects, and (2) the most popular languages are javascript and c#. unity is the most used game engine during vr development and the most discussed topic on stack overflow. overall, our exploratory study is one of the very first of its kind for vr projects and provides material that is hopefully a starting point for further research on challenges and opportunities for vr software development.",the state of practice on virtual reality (vr) applications: an exploratory study on github and stack overflow
961,2-s2.0-85055533864,10.13328/j.cnki.jos.005529,Survey on Intelligent Search and Construction Methods of Program,Liu B.B.,Ruan Jian Xue Bao/Journal of Software,2018-08-01,"The rapid development of Internet, machine learning and artificial intelligence, as well as the appearance of a large number of open-source software and communities, has brought new opportunities and challenges to the development of software engineering. There are billions of lines of code on the Internet. These codes, especially those of high quality and widely used contains all kinds of knowledge, which has led to the new idea of intelligent software development. It tries to make full use of code resources, knowledge and collective intelligence on the Internet to effectively improve the efficiency and quality of software development. The key technology is program search and construction, providing great theoretical and practical value. At present, the research work of these areas mainly focuses on code search, program synthesis, code recommendation and completion, defect detection, code style improvement, and automatic program repair. This paper surveys the current main research work from the above aspects, sorts out the specific theoretical and technical approaches in detail and summarizes the challenges in the current research process. Several directions of research in the future are also proposed.",Collective intelligence | Intelligent software development | Machine learning | Program construction | Program search,5,2180-2197,Journal,Review,3.0,"Liu, Bin Bin;Dong, Wei;Wang, Ji",57204436414;57190581192;57193521281,National University of Defense Technology China,China,"the rapid development of internet, machine learning and artificial intelligence, as well as the appearance of a large number of open-source software and communities, has brought new opportunities and challenges to the development of software engineering. there are billions of lines of code on the internet. these codes, especially those of high quality and widely used contains all kinds of knowledge, which has led to the new idea of intelligent software development. it tries to make full use of code resources, knowledge and collective intelligence on the internet to effectively improve the efficiency and quality of software development. the key technology is program search and construction, providing great theoretical and practical value. at present, the research work of these areas mainly focuses on code search, program synthesis, code recommendation and completion, defect detection, code style improvement, and automatic program repair. this paper surveys the current main research work from the above aspects, sorts out the specific theoretical and technical approaches in detail and summarizes the challenges in the current research process. several directions of research in the future are also proposed.",survey on intelligent search and construction methods of program
963,2-s2.0-85049528649,10.1007/s13369-017-2830-6,Search for Prioritized Test Cases in Multi-Objective Environment During Web Application Testing,Khanna M.,Arabian Journal for Science and Engineering,2018-08-01,"Regression testing is an expensive procedure that is implemented during maintenance phase of the Software Development Life Cycle of evolving software. During this process, test case prioritization is one of the strategies followed in which test cases are organized in a fashion so as to enhance efficiency in achieving some performance goal. During the process, there could be several aspects to be kept in mind due to resources constraints such as fault severity detected per unit of test cost, severity detection per test case execution, and execution time of test cases to detect all the faults. Keeping all such constraints in mind, the test case prioritization problem becomes a multi-objective problem where some of the objectives have to be maximized and the remaining ones minimized. In this study, experiments were performed on different versions of five web applications. The problem instance was found to vary from 5 × 5 test cases versus fault matrix, to 125 × 125 matrix. Random approach, 2-opt algorithm, improved 2-opt algorithm, greedy approach, additional greedy approach, Weighted Genetic Algorithm and Non-dominated Sorting Genetic Algorithm-II (NSGA-II) were applied to a generate prioritized test sequence which maximizes the Cost Cognizant Average Percentage of Fault Detection value, severity detection and minimizes test case execution cost to expose all the faults. The performances of these algorithms are compared, keeping these parameters in mind, and it is concluded that the performance of NSGA-II algorithm is better than that of all the other tested algorithms throughout all the experiments.",Greedy algorithm | Multi-objective optimization | NSGA-II | Search algorithms | Test case prioritization (TCP) | Testing web application,5,4179-4201,Journal,Article,5.0,"Khanna, Munish;Chauhan, Naresh;Sharma, Dilip;Toofani, Abhishek;Chaudhary, Achint",57198790554;24469783600;35107979000;57198816235;57202835554,"GLA University, Mathura;J.C. Bose University of Science and Technology, YMCA;Hindustan College of Science and Technology",India;India;India,"regression testing is an expensive procedure that is implemented during maintenance phase of the software development life cycle of evolving software. during this process, test case prioritization is one of the strategies followed in which test cases are organized in a fashion so as to enhance efficiency in achieving some performance goal. during the process, there could be several aspects to be kept in mind due to resources constraints such as fault severity detected per unit of test cost, severity detection per test case execution, and execution time of test cases to detect all the faults. keeping all such constraints in mind, the test case prioritization problem becomes a multi-objective problem where some of the objectives have to be maximized and the remaining ones minimized. in this study, experiments were performed on different versions of five web applications. the problem instance was found to vary from 5 × 5 test cases versus fault matrix, to 125 × 125 matrix. random approach, 2-opt algorithm, improved 2-opt algorithm, greedy approach, additional greedy approach, weighted genetic algorithm and non-dominated sorting genetic algorithm-ii (nsga-ii) were applied to a generate prioritized test sequence which maximizes the cost cognizant average percentage of fault detection value, severity detection and minimizes test case execution cost to expose all the faults. the performances of these algorithms are compared, keeping these parameters in mind, and it is concluded that the performance of nsga-ii algorithm is better than that of all the other tested algorithms throughout all the experiments.",search for prioritized test cases in multi-objective environment during web application testing
964,2-s2.0-85034827767,10.1007/s10664-017-9576-3,Analyzing the effects of test driven development in GitHub,Borle N.C.,Empirical Software Engineering,2018-08-01,"Testing is an integral part of the software development lifecycle, approached with varying degrees of rigor by different process models. Agile process models recommend Test Driven Development (TDD) as a key practice for reducing costs and improving code quality. The objective of this work is to perform a cost-benefit analysis of this practice. To that end, we have conducted a comparative analysis of GitHub repositories that adopts TDD to a lesser or greater extent, in order to determine how TDD affects software development productivity and software quality. We classified GitHub repositories archived in 2015 in terms of how rigorously they practiced TDD, thus creating a TDD spectrum. We then matched and compared various subsets of these repositories on this TDD spectrum with control sets of equal size. The control sets were samples from all GitHub repositories that matched certain characteristics, and that contained at least one test file. We compared how the TDD sets differed from the control sets on the following characteristics: number of test files, average commit velocity, number of bug-referencing commits, number of issues recorded, usage of continuous integration, number of pull requests, and distribution of commits per author. We found that Java TDD projects were relatively rare. In addition, there were very few significant differences in any of the metrics we used to compare TDD-like and non-TDD projects; therefore, our results do not reveal any observable benefits from using TDD.",Continuous integration | GitHub repositories | Human factors in software development | Test driven development,7,1931-1958,Journal,Article,5.0,"Borle, Neil C.;Feghhi, Meysam;Stroulia, Eleni;Greiner, Russell;Hindle, Abram",56654141200;57197802202;6603883706;7102873710;21742620300,Alberta Machine Intelligence Institute;University of Alberta,Canada;Canada,"testing is an integral part of the software development lifecycle, approached with varying degrees of rigor by different process models. agile process models recommend test driven development (tdd) as a key practice for reducing costs and improving code quality. the objective of this work is to perform a cost-benefit analysis of this practice. to that end, we have conducted a comparative analysis of github repositories that adopts tdd to a lesser or greater extent, in order to determine how tdd affects software development productivity and software quality. we classified github repositories archived in 2015 in terms of how rigorously they practiced tdd, thus creating a tdd spectrum. we then matched and compared various subsets of these repositories on this tdd spectrum with control sets of equal size. the control sets were samples from all github repositories that matched certain characteristics, and that contained at least one test file. we compared how the tdd sets differed from the control sets on the following characteristics: number of test files, average commit velocity, number of bug-referencing commits, number of issues recorded, usage of continuous integration, number of pull requests, and distribution of commits per author. we found that java tdd projects were relatively rare. in addition, there were very few significant differences in any of the metrics we used to compare tdd-like and non-tdd projects; therefore, our results do not reveal any observable benefits from using tdd.",analyzing the effects of test driven development in github
966,2-s2.0-85051038289,10.1109/SP.2018.00043,Study and Mitigation of Origin Stripping Vulnerabilities in Hybrid-postMessage Enabled Mobile Applications,Yang G.,Proceedings - IEEE Symposium on Security and Privacy,2018-07-23,"postMessage is popular in HTML5 based web apps to allow the communication between different origins. With the increasing popularity of the embedded browser (i.e., WebView) in mobile apps (i.e., hybrid apps), postMessage has found utility in these apps. However, different from web apps, hybrid apps have a unique requirement that their native code (e.g., Java for Android) also needs to exchange messages with web code loaded in WebView. To bridge the gap, developers typically extend postMessage by treating the native context as a new frame, and allowing the communication between the new frame and the web frames. We term such extended postMessage 'hybrid postMessage' in this paper. We find that hybrid postMessage introduces new critical security flaws: all origin information of a message is not respected or even lost during the message delivery in hybrid postMessage. If adversaries inject malicious code into WebView, the malicious code may leverage the flaws to passively monitor messages that may contain sensitive information, or actively send messages to arbitrary message receivers and access their internal functionalities and data. We term the novel security issue caused by hybrid postMessage 'Origin Stripping Vulnerability' (OSV). In this paper, our contributions are fourfold. First, we conduct the first systematic study on OSV. Second, we propose a lightweight detection tool against OSV, called OSV-Hunter. Third, we evaluate OSV-Hunter using a set of popular apps. We found that 74 apps implemented hybrid postMessage, and all these apps suffered from OSV, which might be exploited by adversaries to perform remote real-time microphone monitoring, data race, internal data manipulation, denial of service (DoS) attacks and so on. Several popular development frameworks, libraries (such as the Facebook React Native framework, and the Google cloud print library) and apps (such as Adobe Reader and WPS office) are impacted. Lastly, to mitigate OSV from the root, we design and implement three new postMessage APIs, called OSV-Free. Our evaluation shows that OSV-Free is secure and fast, and it is generic and resilient to the notorious Android fragmentation problem. We also demonstrate that OSV-Free is easy to use, by applying OSV-Free to harden the complex 'Facebook React Native' framework. OSV-Free is open source, and its source code and more implementation and evaluation details are available online.",Android | Hybrid postMessage | Origin Stripping Vulnerability | security | webview,14,742-755,Conference Proceeding,Conference Paper,4.0,"Yang, Guangliang;Huang, Jeff;Gu, Guofei;Mendoza, Abner",57198741653;57013582200;14025549700;57055131400,Texas A&amp;M University,United States,"postmessage is popular in html5 based web apps to allow the communication between different origins. with the increasing popularity of the embedded browser (i.e., webview) in mobile apps (i.e., hybrid apps), postmessage has found utility in these apps. however, different from web apps, hybrid apps have a unique requirement that their native code (e.g., java for android) also needs to exchange messages with web code loaded in webview. to bridge the gap, developers typically extend postmessage by treating the native context as a new frame, and allowing the communication between the new frame and the web frames. we term such extended postmessage 'hybrid postmessage' in this paper. we find that hybrid postmessage introduces new critical security flaws: all origin information of a message is not respected or even lost during the message delivery in hybrid postmessage. if adversaries inject malicious code into webview, the malicious code may leverage the flaws to passively monitor messages that may contain sensitive information, or actively send messages to arbitrary message receivers and access their internal functionalities and data. we term the novel security issue caused by hybrid postmessage 'origin stripping vulnerability' (osv). in this paper, our contributions are fourfold. first, we conduct the first systematic study on osv. second, we propose a lightweight detection tool against osv, called osv-hunter. third, we evaluate osv-hunter using a set of popular apps. we found that 74 apps implemented hybrid postmessage, and all these apps suffered from osv, which might be exploited by adversaries to perform remote real-time microphone monitoring, data race, internal data manipulation, denial of service (dos) attacks and so on. several popular development frameworks, libraries (such as the facebook react native framework, and the google cloud print library) and apps (such as adobe reader and wps office) are impacted. lastly, to mitigate osv from the root, we design and implement three new postmessage apis, called osv-free. our evaluation shows that osv-free is secure and fast, and it is generic and resilient to the notorious android fragmentation problem. we also demonstrate that osv-free is easy to use, by applying osv-free to harden the complex 'facebook react native' framework. osv-free is open source, and its source code and more implementation and evaluation details are available online.",study and mitigation of origin stripping vulnerabilities in hybrid-postmessage enabled mobile applications
967,2-s2.0-85050997556,10.1109/ICSTW.2018.00032,Scan code injection flaws in HTML5-Based mobile applications,Lau P.T.,"Proceedings - 2018 IEEE 11th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2018",2018-07-16,"HTML5-based mobile apps are becoming popular in the development of a cross-platform mobile. They are also built using web technologies, including HTML5, CSS, and JavaScript, so it may face with code injection attacks like web apps. However, code injection attacks are exploited in web apps and in mobile web apps are distinguished. The code injection attacks in web apps are often exploited by attackers throughout the cross-site scripting. In HTML5-based mobile apps, attackers can deploy attacks by various code injection channels such as inter-apps, inter-components, inter-devices communication, and local device resources such as WiFi, SMS, Contact. The plugin APIs are implemented for the code injection channels are defined as the sensitive plugin APIs. The previous approaches aimed at modeling known sensitive plugin APIs, and applying the data flow analysis to detect sensitive information flows from such modeled sensitive plugin APIs to vulnerable APIs. However, their method can miss code injection flaws caused by unknown sensitive plugin APIs. Besides, analyzing information flows in JavaScript is challenging. We found that the previous approaches are not able to analyze various contexts of callback functions. In this paper, we developed a static analysis tool called SCANCIF to scan code injection flaws. SCANCIF identifies the sensitive plugin APIs based on code injection tags, and analyzes flows of information based on modeling contexts of callback functions passed in function calls. We evaluated our approach on a data set of 3,204 HTML5-based mobile apps, as a result, SCANCIF scanned 220 vulnerable apps. We manually reviewed them and found 4 new code injection channels.",Code injection attacks | Data flow analysis | HTML5-based mobile apps | PhoneGap,5,81-88,Conference Proceeding,Conference Paper,1.0,"Lau, Phi Tuong",57203222244,Viet Nam National University Ho Chi Minh City,Viet Nam,"html5-based mobile apps are becoming popular in the development of a cross-platform mobile. they are also built using web technologies, including html5, css, and javascript, so it may face with code injection attacks like web apps. however, code injection attacks are exploited in web apps and in mobile web apps are distinguished. the code injection attacks in web apps are often exploited by attackers throughout the cross-site scripting. in html5-based mobile apps, attackers can deploy attacks by various code injection channels such as inter-apps, inter-components, inter-devices communication, and local device resources such as wifi, sms, contact. the plugin apis are implemented for the code injection channels are defined as the sensitive plugin apis. the previous approaches aimed at modeling known sensitive plugin apis, and applying the data flow analysis to detect sensitive information flows from such modeled sensitive plugin apis to vulnerable apis. however, their method can miss code injection flaws caused by unknown sensitive plugin apis. besides, analyzing information flows in javascript is challenging. we found that the previous approaches are not able to analyze various contexts of callback functions. in this paper, we developed a static analysis tool called scancif to scan code injection flaws. scancif identifies the sensitive plugin apis based on code injection tags, and analyzes flows of information based on modeling contexts of callback functions passed in function calls. we evaluated our approach on a data set of 3,204 html5-based mobile apps, as a result, scancif scanned 220 vulnerable apps. we manually reviewed them and found 4 new code injection channels.",scan code injection flaws in html5-based mobile applications
968,2-s2.0-85051520230,10.5194/isprs-archives-XLII-4-W8-171-2018,A Semi-Automatic procedure for a demographic analysis of the foss4g developers' community,Oxoli D.,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",2018-07-11,"The open and direct collaboration at the creation, improvement, and documentation of source code and software applications - enabled by the web - is recognized as a peculiarity of the Free and Open Source Software for Geospatial (FOSS4G) projects representing, at the same time, one of their main strengths. With this in mind, it turns out to be interesting to perform an extensive monitoring of both the evolution and the geographical arrangement of the developers' communities in order to investigate their actual extension, evolution and degree of activity. In this work, a semi-automatic procedure to perform this particular analysis is described. The procedure is mainly based on the use of the GitHub Search Application Programming Interface by means of JavaScript custom modules to perform a census of the users registered with a collaborator role to the repositories of the most popular FOSS4G projects, hosted on the GitHub platform. The collected data is processed and analysed using Python and QGIS. The results - presented through tables, charts, and thematic maps - allow describing both dimensions as well as the geographical heterogeneity of the contributing community of each individual project, while enabling to identify the most active countries - in terms of the number of contributors - in the development of the most popular FOSS4G. The limits of the analysis, including technical constraints and considerations on the significance of the developers' census, are finally highlighted and discussed.",Collaboration | Community | FOSS4G | GitHub | Open Source | Software Development,0,171-174,Conference Proceeding,Conference Paper,3.0,"Oxoli, D.;Kang, H. K.;Brovelli, M. A.",57189524328;57197809566;6602533891,Politecnico di Milano;Korea Research Institute for Human Settlement,Italy;South Korea,"the open and direct collaboration at the creation, improvement, and documentation of source code and software applications - enabled by the web - is recognized as a peculiarity of the free and open source software for geospatial (foss4g) projects representing, at the same time, one of their main strengths. with this in mind, it turns out to be interesting to perform an extensive monitoring of both the evolution and the geographical arrangement of the developers' communities in order to investigate their actual extension, evolution and degree of activity. in this work, a semi-automatic procedure to perform this particular analysis is described. the procedure is mainly based on the use of the github search application programming interface by means of javascript custom modules to perform a census of the users registered with a collaborator role to the repositories of the most popular foss4g projects, hosted on the github platform. the collected data is processed and analysed using python and qgis. the results - presented through tables, charts, and thematic maps - allow describing both dimensions as well as the geographical heterogeneity of the contributing community of each individual project, while enabling to identify the most active countries - in terms of the number of contributors - in the development of the most popular foss4g. the limits of the analysis, including technical constraints and considerations on the significance of the developers' census, are finally highlighted and discussed.",a semi-automatic procedure for a demographic analysis of the foss4g developers' community
969,2-s2.0-85065986500,10.1109/IS.2018.8710510,A Scaffolding Design Framework for Developing Secure Interoperability Components in Digital Manufacturing Platforms,Fraile F.,"9th International Conference on Intelligent Systems 2018: Theory, Research and Innovation in Applications, IS 2018 - Proceedings",2018-07-02,"This paper presents the Virtual Open Operating System (vf-OS) Input / Output (IO) Toolkit Generator, which is a design tool to develop vf-OS IO components that interact with all kinds of manufacturing assets, either physical devices like Program Logic Controllers (PLCs), software applications like Enterprise Resource Planning Systems (ERPs) or legacy file formats like STEP. The vf-OS IO Toolkit Generator is based on software scaffolding, a code generation technique that allows a developer to create a working component to interact with a manufacturing asset from the vf-OS Platform without writing a line of code. As described in this paper, software scaffolding not only simplifies the development of interoperability components, but it also fosters system security and platform integration automation. Another contribution of this paper is to propose possible integrations between the IO Toolkit Generator and the vf-OS Security Command Centre in charge of platform security. Additionally, this paper describes how the concept can be extended to address other digital manufacturing platforms like Fi-Ware.",Connected Smart Factories | Cyber-Physical Systems | Cybersecurity | Digital Manufacturing Platforms | System Interoperability,1,564-569,Conference Proceeding,Conference Paper,5.0,"Fraile, Francisco;Flores, Jose Luis;Anaya, Victor;Saiz, Eduardo;Poler, Raul",26029387700;57203394051;14630001700;56357075200;22734966200,IK4-Ikerlan Technology Research Centre;Universitat Politècnica de València,Spain;Spain,"this paper presents the virtual open operating system (vf-os) input / output (io) toolkit generator, which is a design tool to develop vf-os io components that interact with all kinds of manufacturing assets, either physical devices like program logic controllers (plcs), software applications like enterprise resource planning systems (erps) or legacy file formats like step. the vf-os io toolkit generator is based on software scaffolding, a code generation technique that allows a developer to create a working component to interact with a manufacturing asset from the vf-os platform without writing a line of code. as described in this paper, software scaffolding not only simplifies the development of interoperability components, but it also fosters system security and platform integration automation. another contribution of this paper is to propose possible integrations between the io toolkit generator and the vf-os security command centre in charge of platform security. additionally, this paper describes how the concept can be extended to address other digital manufacturing platforms like fi-ware.",a scaffolding design framework for developing secure interoperability components in digital manufacturing platforms
970,2-s2.0-85065984024,10.1109/IS.2018.8710545,From Native to Cross-platform Hybrid Development,Pinto C.,"9th International Conference on Intelligent Systems 2018: Theory, Research and Innovation in Applications, IS 2018 - Proceedings",2018-07-02,"The current trends towards globalisation, together with the exponential growth of the number of mobile devices led the markets to a boom in the demand for the development of mobile applications. Moreover, with the expansion and heterogeneity of the mobile devices and platforms, software companies need to search for faster and cheaper ways to develop applications that are able to span as many devices as possible in order to capture the market. Currently, Android and iOS Operating Systems roughly share and dominate the mobile market, with timid expressions of other competitors. Each of these mobile operating systems was developed using their own languages and strategy and offer SDKs for development of applications using their libraries - known as native apps. On the other hand, the evolution of HTML5, CSS and JavaScript created generic alternatives to create mobile apps that run on devices on all operating systems, however lacking some capabilities to access the device's full potential. Alongside came the novel hybrid cross-platform development frameworks, which try to take the best of both worlds. Native versus hybrid platforms the trend in mobile app development using hybrid platforms and their advantage. It would not be great with just one language to develop mobile applications for all mobile devices.",App development | Cross-platform | Hybrid development | Ionic | Mobile | Mobile apps | Native development | Native hybrid app,5,669-676,Conference Proceeding,Conference Paper,2.0,"Pinto, Carlos Manso;Coutinho, Carlos",57208868424;55355460700,Iscte – Instituto Universitário de Lisboa,Portugal,"the current trends towards globalisation, together with the exponential growth of the number of mobile devices led the markets to a boom in the demand for the development of mobile applications. moreover, with the expansion and heterogeneity of the mobile devices and platforms, software companies need to search for faster and cheaper ways to develop applications that are able to span as many devices as possible in order to capture the market. currently, android and ios operating systems roughly share and dominate the mobile market, with timid expressions of other competitors. each of these mobile operating systems was developed using their own languages and strategy and offer sdks for development of applications using their libraries - known as native apps. on the other hand, the evolution of html5, css and javascript created generic alternatives to create mobile apps that run on devices on all operating systems, however lacking some capabilities to access the device's full potential. alongside came the novel hybrid cross-platform development frameworks, which try to take the best of both worlds. native versus hybrid platforms the trend in mobile app development using hybrid platforms and their advantage. it would not be great with just one language to develop mobile applications for all mobile devices.",from native to cross-platform hybrid development
973,2-s2.0-85049388354,10.1587/transinf.2017KBP0018,Identifying core objects for trace summarization by analyzing reference relations and dynamic properties,Noda K.,IEICE Transactions on Information and Systems,2018-07-01,"Behaviors of an object-oriented system can be visualized as reverse-engineered sequence diagrams from execution traces. This approach is a valuable tool for program comprehension tasks. However, owing to the massiveness of information contained in an execution trace, a reverse-engineered sequence diagram is often afflicted by a scalability issue. To address this issue, many trace summarization techniques have been proposed. Most of the previous techniques focused on reducing the vertical size of the diagram. To cope with the scalability issue, decreasing the horizontal size of the diagram is also very important. Nonetheless, few studies have addressed this point; thus, there is a lot of needs for further development of horizontal summarization techniques. We present in this paper a method for identifying core objects for trace summarization by analyzing reference relations and dynamic properties. Visualizing only interactions related to core objects, we can obtain a horizontally compactified reverse-engineered sequence diagram that contains system's key behaviors. To identify core objects, first, we detect and eliminate temporary objects that are trivial for a system by analyzing reference relations and lifetimes of objects. Then, estimating the importance of each non-trivial object based on their dynamic properties, we identify highly important ones (i.e., core objects). We implemented our technique in our tool and evaluated it by using traces from various open-source software systems. The results showed that our technique was much more effective in terms of the horizontal reduction of a reverse-engineered sequence diagram, compared with the state-of-the-art trace summarization technique. The horizontal compression ratio of our technique was 134.6 on average, whereas that of the state-of-the-art technique was 11.5. The runtime overhead imposed by our technique was 167.6% on average. This overhead is relatively small compared with recent scalable dynamic analysis techniques, which shows the practicality of our technique. Overall, our technique can achieve a significant reduction of the horizontal size of a reverse-engineered sequence diagram with a small overhead and is expected to be a valuable tool for program comprehension.",Core object | Dynamic analysis | Program comprehension | Reverse-engineered sequence diagram | Trace summarization,5,1751-1765,Journal,Conference Paper,3.0,"Noda, Kunihiro;Kobayashi, Takashi;Atsumi, Noritoshi",35422893800;55633314729;7004014532,Tokyo Institute of Technology;Kyoto University,Japan;Japan,"behaviors of an object-oriented system can be visualized as reverse-engineered sequence diagrams from execution traces. this approach is a valuable tool for program comprehension tasks. however, owing to the massiveness of information contained in an execution trace, a reverse-engineered sequence diagram is often afflicted by a scalability issue. to address this issue, many trace summarization techniques have been proposed. most of the previous techniques focused on reducing the vertical size of the diagram. to cope with the scalability issue, decreasing the horizontal size of the diagram is also very important. nonetheless, few studies have addressed this point; thus, there is a lot of needs for further development of horizontal summarization techniques. we present in this paper a method for identifying core objects for trace summarization by analyzing reference relations and dynamic properties. visualizing only interactions related to core objects, we can obtain a horizontally compactified reverse-engineered sequence diagram that contains system's key behaviors. to identify core objects, first, we detect and eliminate temporary objects that are trivial for a system by analyzing reference relations and lifetimes of objects. then, estimating the importance of each non-trivial object based on their dynamic properties, we identify highly important ones (i.e., core objects). we implemented our technique in our tool and evaluated it by using traces from various open-source software systems. the results showed that our technique was much more effective in terms of the horizontal reduction of a reverse-engineered sequence diagram, compared with the state-of-the-art trace summarization technique. the horizontal compression ratio of our technique was 134.6 on average, whereas that of the state-of-the-art technique was 11.5. the runtime overhead imposed by our technique was 167.6% on average. this overhead is relatively small compared with recent scalable dynamic analysis techniques, which shows the practicality of our technique. overall, our technique can achieve a significant reduction of the horizontal size of a reverse-engineered sequence diagram with a small overhead and is expected to be a valuable tool for program comprehension.",identifying core objects for trace summarization by analyzing reference relations and dynamic properties
975,2-s2.0-85049919617,10.23919/CISTI.2018.8399242,Comparative analysis of the laravel and codeigniter frameworks: For the implementation of the management system of merit and opposition competitions in the State University Península de Santa Elena,Valarezo R.,"Iberian Conference on Information Systems and Technologies, CISTI",2018-06-27,"The analysis was made of the comparative frameworks PHP: Laravel and CodeIgniter to improve productivity in the development of the system of management of competitions and merit and opposition in the University. It is recorded and analyzed the results of the tests performed on the two systems developed on the basis of the parameters and indicators established, in order to determine the framework with better productivity. The tools used in hardware: a computer, and in software - the frameworks PHP: Laravel and CodeIgniter, HTML 5, JavaScript, Bootstrap 3.3.6, Microsoft Visio 2010, JMeter and Quick Line Counter QLC. According to the obtained results it is inferred that the framework Laravel improves productivity in the development of the system of management of competitions and merit and opposition to the University, complying with the 100% of the parameters established in the analysis the same that is greater, compared to 68.86% of compliance with the Framework CodeIgniter. Was developed with the Framework Laravel the management system of competitions and merit and opposition in the University, because it provides better productivity in the development of web applications. It is recommended that the institution to make use of the system due to this web application automate all processes in an efficient manner.",CodeIgniter Framework | Frameworks PHP | Laravel Framework | Productivity,5,1-6,Conference Proceeding,Conference Paper,2.0,"Valarezo, Robin;Guarda, Teresa",57202944331;53866250100,Universidad Estatal Península de Santa Elena;University of the Armed Forces ESPE;Universidade do Minho,Ecuador;Ecuador;Portugal,"the analysis was made of the comparative frameworks php: laravel and codeigniter to improve productivity in the development of the system of management of competitions and merit and opposition in the university. it is recorded and analyzed the results of the tests performed on the two systems developed on the basis of the parameters and indicators established, in order to determine the framework with better productivity. the tools used in hardware: a computer, and in software - the frameworks php: laravel and codeigniter, html 5, javascript, bootstrap 3.3.6, microsoft visio 2010, jmeter and quick line counter qlc. according to the obtained results it is inferred that the framework laravel improves productivity in the development of the system of management of competitions and merit and opposition to the university, complying with the 100% of the parameters established in the analysis the same that is greater, compared to 68.86% of compliance with the framework codeigniter. was developed with the framework laravel the management system of competitions and merit and opposition in the university, because it provides better productivity in the development of web applications. it is recommended that the institution to make use of the system due to this web application automate all processes in an efficient manner.",comparative analysis of the laravel and codeigniter frameworks: for the implementation of the management system of merit and opposition competitions in the state university península de santa elena
976,2-s2.0-85049872687,10.23919/CISTI.2018.8399336,"Sofia, design and implementation of a virtual assistance agent for attention a financial institution",Arias J.A.E.,"Iberian Conference on Information Systems and Technologies, CISTI",2018-06-27,"Different systems of human-machine interaction with capacities more and more similar to humans are diffused and generate different perspectives of incorporation in organizations. A growing trend is the construction of artificial intelligence software to execute tasks without human intervention, such as collecting and presenting information to users, making a reservation at a restaurant on a special date, and generally carrying out tasks related to customer service by automated bots for solving to solve everyday situations, normally employees in the messaging through the development of advanced conversational interfaces. The bots with the ability to simulate conversations through conversational interfaces are already a reality and their boom is increasing. A field where they have a prominent presence has to do with customer service. This paper presents the components designed and developed of a bot used by a company in the financial sector consolidated for more than a decade in Latin America to manage customer service in order to solve everyday situations.",Artificial Intelligence | Chatbot | Intelligent Agents | Natural lenguage,1,1-5,Conference Proceeding,Conference Paper,3.0,"Arias, Jaime Alberto Echeverri;Urrea, Gustavo;Martinez, Harold G.",57202125908;57202938540;57202938541,Universidad de Medellín;Banco Falabella,Colombia;Colombia,"different systems of human-machine interaction with capacities more and more similar to humans are diffused and generate different perspectives of incorporation in organizations. a growing trend is the construction of artificial intelligence software to execute tasks without human intervention, such as collecting and presenting information to users, making a reservation at a restaurant on a special date, and generally carrying out tasks related to customer service by automated bots for solving to solve everyday situations, normally employees in the messaging through the development of advanced conversational interfaces. the bots with the ability to simulate conversations through conversational interfaces are already a reality and their boom is increasing. a field where they have a prominent presence has to do with customer service. this paper presents the components designed and developed of a bot used by a company in the financial sector consolidated for more than a decade in latin america to manage customer service in order to solve everyday situations.","sofia, design and implementation of a virtual assistance agent for attention a financial institution"
979,2-s2.0-85084177795,10.1145/3211332.3211335,MakeCode and CODAL: Intuitive and efficient embedded systems programming for education,Devine J.,ACM SIGPLAN Notices,2018-06-19,"Across the globe, it is now commonplace for educators to engage in the making (design and development) of embedded systems in the classroom to motivate and excite their students. This new domain brings its own set of unique requirements. Historically, embedded systems development requires knowledge of low-level programming languages, local installation of compilation toolchains, device drivers, and applications. For students and educators, these requirements can introduce insurmountable barriers. We present the motivation, requirements, implementation, and evaluation of a new programming platform that enables novice users to create software for embedded systems. The platform has two major components: 1) Microsoft MakeCode (www.makecode.com), a web app that encapsulates an entire beginner IDE for microcontrollers; and 2) CODAL, an efficient component-oriented C++ runtime for microcontrollers. We show how MakeCode and CODAL provide an accessible, cross-platform, installation-free programming experience for the BBC micro:bit and other embedded devices.",classroom | education | embedded systems,5,19-30,Journal,Article,6.0,"Devine, James;Finney, Joe;De Halleux, Peli;Moskal, Michał;Ball, Thomas;Hodges, Steve",57202452071;7101854678;24461416400;23486057200;7102130944;15044574300,Microsoft Corporation;Lancaster University,United States;United Kingdom,"across the globe, it is now commonplace for educators to engage in the making (design and development) of embedded systems in the classroom to motivate and excite their students. this new domain brings its own set of unique requirements. historically, embedded systems development requires knowledge of low-level programming languages, local installation of compilation toolchains, device drivers, and applications. for students and educators, these requirements can introduce insurmountable barriers. we present the motivation, requirements, implementation, and evaluation of a new programming platform that enables novice users to create software for embedded systems. the platform has two major components: 1) microsoft makecode (www.makecode.com), a web app that encapsulates an entire beginner ide for microcontrollers; and 2) codal, an efficient component-oriented c++ runtime for microcontrollers. we show how makecode and codal provide an accessible, cross-platform, installation-free programming experience for the bbc micro:bit and other embedded devices.",makecode and codal: intuitive and efficient embedded systems programming for education
980,2-s2.0-85050142935,10.1145/3211332.3211335,MakeCode and CODAL: Intuitive and efficient embedded systems programming for education,Devine J.,"Proceedings of the ACM SIGPLAN Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES)",2018-06-19,"Across the globe, it is now commonplace for educators to engage in the making (design and development) of embedded systems in the classroom to motivate and excite their students. This new domain brings its own set of unique requirements. Historically, embedded systems development requires knowledge of low-level programming languages, local installation of compilation toolchains, device drivers, and applications. For students and educators, these requirements can introduce insurmountable barriers. We present the motivation, requirements, implementation, and evaluation of a new programming platform that enables novice users to create software for embedded systems. The platform has two major components: 1) Microsoft MakeCode (www.makecode.com), a web app that encapsulates an entire beginner IDE for microcontrollers; and 2) CODAL, an efficient component-oriented C++ runtime for microcontrollers. We show how MakeCode and CODAL provide an accessible, cross-platform, installation-free programming experience for the BBC micro:bit and other embedded devices.",Classroom | Education | Embedded systems,11,19-30,Conference Proceeding,Conference Paper,6.0,"Devine, James;Finney, Joe;De Halleux, Peli;Moskal, Michał;Ball, Thomas;Hodges, Steve",57202452071;7101854678;24461416400;23486057200;7102130944;15044574300,Microsoft Corporation;Lancaster University,United States;United Kingdom,"across the globe, it is now commonplace for educators to engage in the making (design and development) of embedded systems in the classroom to motivate and excite their students. this new domain brings its own set of unique requirements. historically, embedded systems development requires knowledge of low-level programming languages, local installation of compilation toolchains, device drivers, and applications. for students and educators, these requirements can introduce insurmountable barriers. we present the motivation, requirements, implementation, and evaluation of a new programming platform that enables novice users to create software for embedded systems. the platform has two major components: 1) microsoft makecode (www.makecode.com), a web app that encapsulates an entire beginner ide for microcontrollers; and 2) codal, an efficient component-oriented c++ runtime for microcontrollers. we show how makecode and codal provide an accessible, cross-platform, installation-free programming experience for the bbc micro:bit and other embedded devices.",makecode and codal: intuitive and efficient embedded systems programming for education
986,2-s2.0-85038834608,10.1016/j.epidem.2017.12.003,epidemix—An interactive multi-model application for teaching and visualizing infectious disease transmission,Muellner U.,Epidemics,2018-06-01,"Mathematical models of disease transmission are used to improve our understanding of patterns of infection and to identify factors influencing them. During recent public and animal health crises, such as pandemic influenza, Ebola, Zika, foot-and-mouth disease, models have made important contributions in addressing policy questions, especially through the assessment of the trajectory and scale of outbreaks, and the evaluation of control interventions. However, their mathematical formulation means that they may appear as a “black box” to those without the appropriate mathematical background. This may lead to a negative perception of their utility for guiding policy, and generate expectations, which are not in line with what these models can deliver. It is therefore important for policymakers, as well as public health and animal health professionals and researchers who collaborate with modelers and use results generated by these models for policy development or research purpose, to understand the key concepts and assumptions underlying these models. The software application epidemix (http://shinyapps.rvc.ac.uk) presented here aims to make mathematical models of disease transmission accessible to a wider audience of users. By developing a visual interface for a suite of eight models, users can develop an understanding of the impact of various modelling assumptions – especially mixing patterns – on the trajectory of an epidemic and the impact of control interventions, without having to directly deal with the complexity of mathematical equations and programming languages. Models are compartmental or individual-based, deterministic or stochastic, and assume homogeneous or heterogeneous-mixing patterns (with the probability of transmission depending on the underlying structure of contact networks, or the spatial distribution of hosts). This application is intended to be used by scientists teaching mathematical modelling short courses to non-specialists – including policy makers, public and animal health professionals and students – and wishing to develop hands-on practicals illustrating key concepts of disease dynamics and control.",Application software | Disease dynamics | Epidemiology | Infectious disease | Mathematical modelling | Teaching,9,49-54,Journal,Article,5.0,"Muellner, Ulrich;Fournié, Guillaume;Muellner, Petra;Ahlstrom, Christina;Pfeiffer, Dirk U.",57193627328;42561175400;40561548200;56004125300;7102444811,Epi-interactive Ltd.;Royal Veterinary College University of London;City University of Hong Kong,New Zealand;United Kingdom;Hong Kong,"mathematical models of disease transmission are used to improve our understanding of patterns of infection and to identify factors influencing them. during recent public and animal health crises, such as pandemic influenza, ebola, zika, foot-and-mouth disease, models have made important contributions in addressing policy questions, especially through the assessment of the trajectory and scale of outbreaks, and the evaluation of control interventions. however, their mathematical formulation means that they may appear as a “black box” to those without the appropriate mathematical background. this may lead to a negative perception of their utility for guiding policy, and generate expectations, which are not in line with what these models can deliver. it is therefore important for policymakers, as well as public health and animal health professionals and researchers who collaborate with modelers and use results generated by these models for policy development or research purpose, to understand the key concepts and assumptions underlying these models. the software application epidemix (http://shinyapps.rvc.ac.uk) presented here aims to make mathematical models of disease transmission accessible to a wider audience of users. by developing a visual interface for a suite of eight models, users can develop an understanding of the impact of various modelling assumptions – especially mixing patterns – on the trajectory of an epidemic and the impact of control interventions, without having to directly deal with the complexity of mathematical equations and programming languages. models are compartmental or individual-based, deterministic or stochastic, and assume homogeneous or heterogeneous-mixing patterns (with the probability of transmission depending on the underlying structure of contact networks, or the spatial distribution of hosts). this application is intended to be used by scientists teaching mathematical modelling short courses to non-specialists – including policy makers, public and animal health professionals and students – and wishing to develop hands-on practicals illustrating key concepts of disease dynamics and control.",epidemix—an interactive multi-model application for teaching and visualizing infectious disease transmission
987,2-s2.0-85016124190,10.1007/s11219-017-9359-5,Estimating software robustness in relation to input validation vulnerabilities using Bayesian networks,Ufuktepe E.,Software Quality Journal,2018-06-01,"Estimating the robustness of software in the presence of invalid inputs has long been a challenging task owing to the fact that developers usually fail to take the necessary action to validate inputs during the design and implementation of software. We propose a method for estimating the robustness of software in relation to input validation vulnerabilities using Bayesian networks. The proposed method runs on all program functions and/or methods. It calculates a robustness value using information on the existence of input validation code in the functions and utilizing common weakness scores of known input validation vulnerabilities. In the case study, ten well-known software libraries implemented in the JavaScript language, which are chosen because of their increasing popularity among software developers, are evaluated. Using our method, software development teams can track changes made to software to deal with invalid inputs.",Bayesian networks | Input validation vulnerabilities | Robustness,3,455-489,Journal,Article,2.0,"Ufuktepe, Ekincan;Tuglular, Tugkan",57063534000;14627984700,Izmir Yüksek Teknoloji Enstitüsü,Turkey,"estimating the robustness of software in the presence of invalid inputs has long been a challenging task owing to the fact that developers usually fail to take the necessary action to validate inputs during the design and implementation of software. we propose a method for estimating the robustness of software in relation to input validation vulnerabilities using bayesian networks. the proposed method runs on all program functions and/or methods. it calculates a robustness value using information on the existence of input validation code in the functions and utilizing common weakness scores of known input validation vulnerabilities. in the case study, ten well-known software libraries implemented in the javascript language, which are chosen because of their increasing popularity among software developers, are evaluated. using our method, software development teams can track changes made to software to deal with invalid inputs.",estimating software robustness in relation to input validation vulnerabilities using bayesian networks
988,2-s2.0-85051663029,10.1145/3196398.3196434,The Android update problem: An empirical study,Mahmoudi M.,Proceedings - International Conference on Software Engineering,2018-05-28,"Many phone vendors use Android as their underlying OS, but often extend it to add new functionality and to make it compatible with their specific phones. When a new version of Android is released, phone vendors need to merge or re-apply their customizations and changes to the new release. This is a difficult and time-consuming process, which often leads to late adoption of new versions. In this paper, we perform an empirical study to understand the nature of changes that phone vendors make, versus changes made in the original development of Android. By investigating the overlap of different changes, we also determine the possibility of having automated support for merging them. We develop a publicly available tool chain, based on a combination of existing tools, to study such changes and their overlap. As a proxy case study, we analyze the changes in the popular community-based variant of Android, LineageOS, and its corresponding Android versions. We investigate and report the common types of changes that occur in practice. Our findings show that 83% of subsystems modified by LineageOS are also modified in the next release of Android. By taking the nature of overlapping changes into account, we assess the feasibility of having automated tool support to help phone vendors with the Android update problem. Our results show that 56% of the changes in LineageOS have the potential to be safely automated.",Android | merge conflicts | software evolution | software merging,11,220-230,Conference Proceeding,Conference Paper,2.0,"Mahmoudi, Mehran;Nadi, Sarah",57203416736;36025717300,University of Alberta,Canada,"many phone vendors use android as their underlying os, but often extend it to add new functionality and to make it compatible with their specific phones. when a new version of android is released, phone vendors need to merge or re-apply their customizations and changes to the new release. this is a difficult and time-consuming process, which often leads to late adoption of new versions. in this paper, we perform an empirical study to understand the nature of changes that phone vendors make, versus changes made in the original development of android. by investigating the overlap of different changes, we also determine the possibility of having automated support for merging them. we develop a publicly available tool chain, based on a combination of existing tools, to study such changes and their overlap. as a proxy case study, we analyze the changes in the popular community-based variant of android, lineageos, and its corresponding android versions. we investigate and report the common types of changes that occur in practice. our findings show that 83% of subsystems modified by lineageos are also modified in the next release of android. by taking the nature of overlapping changes into account, we assess the feasibility of having automated tool support to help phone vendors with the android update problem. our results show that 56% of the changes in lineageos have the potential to be safely automated.",the android update problem: an empirical study
989,2-s2.0-85051648187,10.1145/3196398.3196464,Public git archive: A big code dataset for all,Markovtsev V.,Proceedings - International Conference on Software Engineering,2018-05-28,"The number of open source software projects has been growing exponentially. The major online software repository host, GitHub, has accumulated tens of millions of publicly available Git version-controlled repositories. Although the research potential enabled by the available open source code is clearly substantial, no significant large-scale open source code datasets exist. In this paper, we present the Public Git Archive - dataset of 182,014 top-bookmarked Git repositories from GitHub. We describe the novel data retrieval pipeline to reproduce it. We also elaborate on the strategy for performing dataset updates and legal issues. The Public Git Archive occupies 3.0 TB on disk and is an order of magnitude larger than the current source code datasets. The dataset is made available through HTTP and provides the source code of the projects, the related metadata, and development history. The data retrieval pipeline employs an optimized worker queue model and an optimized archive format to efficiently store forked Git repositories, reducing the amount of data to download and persist. Public Git Archive aims to open a myriad of new opportunities for ""Big Code"" research.",development history! | git | github | open dataset | software repositories | source code,16,34-37,Conference Proceeding,Conference Paper,2.0,"Markovtsev, Vadim;Long, Waren",57203412174;57203414406,Source(d),Spain,"the number of open source software projects has been growing exponentially. the major online software repository host, github, has accumulated tens of millions of publicly available git version-controlled repositories. although the research potential enabled by the available open source code is clearly substantial, no significant large-scale open source code datasets exist. in this paper, we present the public git archive - dataset of 182,014 top-bookmarked git repositories from github. we describe the novel data retrieval pipeline to reproduce it. we also elaborate on the strategy for performing dataset updates and legal issues. the public git archive occupies 3.0 tb on disk and is an order of magnitude larger than the current source code datasets. the dataset is made available through http and provides the source code of the projects, the related metadata, and development history. the data retrieval pipeline employs an optimized worker queue model and an optimized archive format to efficiently store forked git repositories, reducing the amount of data to download and persist. public git archive aims to open a myriad of new opportunities for ""big code"" research.",public git archive: a big code dataset for all
990,2-s2.0-85049681086,10.1145/3183440.3183463,Multi-platform computing for physical devices via MakeCode and CODAL,Ball T.,Proceedings - International Conference on Software Engineering,2018-05-27,"As the Internet of Things becomes commonplace, modern software must encompass the sensors, actuators and controllers that make up these physical computers. But can non-experts program such systems? Can such software development be undertaken by anyone, especially programmers who are learning or who are not aiming to be technical experts? We describe the motivation and principles behind Microsoft MakeCode and CODAL, two symbiotic frameworks which have many innovative engineering features for physical computing. Together, these two technologies highlight a new approach to software development for embedded computing devices which provides accessible programming languages and environments that reduce the complexity of programming embedded devices without compromising the flexibility or performance of the resulting software.",CODAL | internet of things | MakeCode | micro:bit | Physical computing | Programming languages | Runtime layer | Typescript,2,552-554,Conference Proceeding,Conference Paper,3.0,"Ball, Thomas;Bishop, Judith;Finney, Joe",7102130944;8382820700;7101854678,Lancaster University;Microsoft Research;Stellenbosch University,United Kingdom;United States;South Africa,"as the internet of things becomes commonplace, modern software must encompass the sensors, actuators and controllers that make up these physical computers. but can non-experts program such systems? can such software development be undertaken by anyone, especially programmers who are learning or who are not aiming to be technical experts? we describe the motivation and principles behind microsoft makecode and codal, two symbiotic frameworks which have many innovative engineering features for physical computing. together, these two technologies highlight a new approach to software development for embedded computing devices which provides accessible programming languages and environments that reduce the complexity of programming embedded devices without compromising the flexibility or performance of the resulting software.",multi-platform computing for physical devices via makecode and codal
992,2-s2.0-85049672229,10.1145/3183440.3194994,Poster: Efficient and deterministic replay for web-enabled Android apps,Yan F.,Proceedings - International Conference on Software Engineering,2018-05-27,"Mobile apps are adopting web techniques for improved development agility. In this paper, we propose TimelyRep to help mobile developers debug and test their web-enabled Android apps. TimelyRep provides efficient deterministic record-And-replay as a software library, running on unmodified Android. Also, as touchscreen becomes the major interaction method for mobile devices, web-enabled apps can receive many events in short periods. TimelyRep embodies a mechanism to control replay delays and achieve smooth replay. TimelyRep also supports cross-device replay where the event trace captured on one device can be replayed on another. We evaluate TimelyRep with real-world web applications. The results show that TimelyRep is useful for reproducing program bugs and has higher timing precision than previous tools.",Android | Deterministic replay | Mobile web app | Software testing,1,329-330,Conference Proceeding,Conference Paper,4.0,"Yan, Fangge;Qi, Zhengwei;Xia, Mingyuan;Liu, Xue",57202058777;7202289842;55272830600;24178306600,Shanghai Jiao Tong University;Université McGill,China;Canada,"mobile apps are adopting web techniques for improved development agility. in this paper, we propose timelyrep to help mobile developers debug and test their web-enabled android apps. timelyrep provides efficient deterministic record-and-replay as a software library, running on unmodified android. also, as touchscreen becomes the major interaction method for mobile devices, web-enabled apps can receive many events in short periods. timelyrep embodies a mechanism to control replay delays and achieve smooth replay. timelyrep also supports cross-device replay where the event trace captured on one device can be replayed on another. we evaluate timelyrep with real-world web applications. the results show that timelyrep is useful for reproducing program bugs and has higher timing precision than previous tools.",poster: efficient and deterministic replay for web-enabled android apps
993,2-s2.0-85048436434,10.1109/ICST.2018.00027,Automatic Detection of Visibility Faults by Layout Changes in HTML5 Web Pages,Ryou Y.,"Proceedings - 2018 IEEE 11th International Conference on Software Testing, Verification and Validation, ICST 2018",2018-05-25,"Modern HTML5 web pages (pages) often change various elements of their documents dynamically to provide rich functionality to users interactively. As users interact with a document via events, the combination of HTML, CSS, and JavaScript dynamically changes the document layout, which is the arrangement of the document elements visualized to the users. Web pages change their layouts not only to support user interaction but also to react to different screen sizes being used to run the pages. To support diverse devices with different screen sizes using a single web page document, developers use Responsive Web Design, which enables web page layouts to change when the sizes of the underlying devices change. While such dynamic features of web pages provide powerful experiences to users, they also make development of web pages more difficult. Even expert developers find it difficult to write HTML5 web pages correctly. In this paper, we first define the problem that functionalities of HTML5 web pages may become unusable due to layout changes, and propose a technique to detect the problem automatically. We show that our implementation detects such problems in real-world HTML5 web pages.",automatic bug detection | HTML5 web pages | layout changes | visibility faults,12,182-192,Conference Proceeding,Conference Paper,2.0,"Ryou, Yeonhee;Ryu, Sukyoung",57195287397;22735372000,Korea Advanced Institute of Science and Technology,South Korea,"modern html5 web pages (pages) often change various elements of their documents dynamically to provide rich functionality to users interactively. as users interact with a document via events, the combination of html, css, and javascript dynamically changes the document layout, which is the arrangement of the document elements visualized to the users. web pages change their layouts not only to support user interaction but also to react to different screen sizes being used to run the pages. to support diverse devices with different screen sizes using a single web page document, developers use responsive web design, which enables web page layouts to change when the sizes of the underlying devices change. while such dynamic features of web pages provide powerful experiences to users, they also make development of web pages more difficult. even expert developers find it difficult to write html5 web pages correctly. in this paper, we first define the problem that functionalities of html5 web pages may become unusable due to layout changes, and propose a technique to detect the problem automatically. we show that our implementation detects such problems in real-world html5 web pages.",automatic detection of visibility faults by layout changes in html5 web pages
995,2-s2.0-85048105139,10.1109/EDUCON.2018.8363407,Simulation games for the digital transformation of business processes: Development and application of two prototypes from the automotive and online retail sector,Loffler A.,"IEEE Global Engineering Education Conference, EDUCON",2018-05-23,"The goal of this paper is to discuss and evaluate the approach of applying simulation games as a tool for teaching and learning business processes in the context of the digital transformation. For this purpose, we defined learning objectives and based on them, developed two separate simulation games with a different scenario for the digital transformation of business processes. While one game is based on automation in the automotive sector, the other one focuses on the digital transformation in the online retail sector. Both games were applied in class and evaluated afterwards. Thereby, this paper offers concrete examples of simulation games for teaching business processes in the context of the digital transformation and discusses characteristics and scenarios that are important in this context. Furthermore, the paper serves as basis for future research in the area of simulation games and therefore provides a novel contribution to this topic of education.",Business Processes | Digital Transformation | Game-based Learning | Prototyping | Simulation Games,10,1475-1483,Conference Proceeding,Conference Paper,5.0,"Loffler, Alexander;Prifti, Loina;Levkovskyi, Borys;Utesch, Matthias;Krcmar, Helmut",57202411018;57190952221;57202380173;56940679700;6603243872,Technical University of Munich;Staatliche Fachober- und Berufsoberschule Technik München,Germany;Germany,"the goal of this paper is to discuss and evaluate the approach of applying simulation games as a tool for teaching and learning business processes in the context of the digital transformation. for this purpose, we defined learning objectives and based on them, developed two separate simulation games with a different scenario for the digital transformation of business processes. while one game is based on automation in the automotive sector, the other one focuses on the digital transformation in the online retail sector. both games were applied in class and evaluated afterwards. thereby, this paper offers concrete examples of simulation games for teaching business processes in the context of the digital transformation and discusses characteristics and scenarios that are important in this context. furthermore, the paper serves as basis for future research in the area of simulation games and therefore provides a novel contribution to this topic of education.",simulation games for the digital transformation of business processes: development and application of two prototypes from the automotive and online retail sector
996,2-s2.0-85048285071,10.1109/SOSE.2018.00027,"If Docker is the Answer, What is the Question?",Zhu H.,"Proceedings - 12th IEEE International Symposium on Service-Oriented System Engineering, SOSE 2018 and 9th International Workshop on Joint Cloud Computing, JCC 2018",2018-05-14,"The recent rise of cloud computing poses serious challenges for software engineering because it adds complexity not only to the platform and infrastructure, but to the software too. The demands on system scalability, performance and reliability are ever increasing. Industry solutions with widespread adoption include the microservices architecture, the container technology and the DevOps methodology. These approaches have changed software engineering practice in such a profound way that we argue that it is becoming a paradigm shift. In this paper, we examine the current support of programming languages for the key concepts behind the change in software engineering practice and argue that a novel programming language is required to support the new paradigm. We report a new programming language CAOPLE and its associated Integrated DevOps Environment CIDE and demonstrate the utility of both.",Cloud computing | Container technology | DevOps | Integrated Software Development Environment. | Microservices | Parallel and distributed programming models | Programming languages | Service agent orientation | Software development methodology | Software engineering paradigms,6,152-163,Conference Proceeding,Conference Paper,2.0,"Zhu, Hong;Bayley, Ian",55569786200;35306468500,Oxford Brookes University,United Kingdom,"the recent rise of cloud computing poses serious challenges for software engineering because it adds complexity not only to the platform and infrastructure, but to the software too. the demands on system scalability, performance and reliability are ever increasing. industry solutions with widespread adoption include the microservices architecture, the container technology and the devops methodology. these approaches have changed software engineering practice in such a profound way that we argue that it is becoming a paradigm shift. in this paper, we examine the current support of programming languages for the key concepts behind the change in software engineering practice and argue that a novel programming language is required to support the new paradigm. we report a new programming language caople and its associated integrated devops environment cide and demonstrate the utility of both.","if docker is the answer, what is the question?"
997,2-s2.0-85046815209,10.1109/MS.2018.2141019,A Taxonomy of IoT Client Architectures,Taivalsaari A.,IEEE Software,2018-05-01,"This article defines a taxonomy of software architecture options, derived from industry projects, for Internet of Things (IoT) devices, from the most limited sensing devices to high-end devices featuring fully fledged OSs and developer frameworks. A plethora of architecture options exists for IoT devices, offering very different levels of software development capabilities. These capabilities can significantly affect IoT systems' end-to-end architecture and topology.",Internet of Things | IoT | IoT devices | Programmable World | real-time operating systems | RTOS | software architecture | software development | software engineering | software platforms,22,83-88,Journal,Article,2.0,"Taivalsaari, Antero;Mikkonen, Tommi",6507045147;57220096141,Nokia Corporation;Helsingin Yliopisto,Finland;Finland,"this article defines a taxonomy of software architecture options, derived from industry projects, for internet of things (iot) devices, from the most limited sensing devices to high-end devices featuring fully fledged oss and developer frameworks. a plethora of architecture options exists for iot devices, offering very different levels of software development capabilities. these capabilities can significantly affect iot systems' end-to-end architecture and topology.",a taxonomy of iot client architectures
999,2-s2.0-85044295702,10.21577/0103-5053.20180013,Development of web and mobile applications for chemical toxicity prediction,Alves V.M.,Journal of the Brazilian Chemical Society,2018-05-01,"Computational tools are recognized to provide high-quality predictions for the assessment of chemical toxicity. In the recent years, mobile devices have become ubiquitous, allowing for the development of innovative and useful models implemented as chemical software applications. Here, we will briefly discuss this recent uptick in the development of web-based and mobile applications for chemical problems, focusing on best practices, development, usage and interpretation. As an example, we also describe two innovative apps (Pred-hERG and Pred-Skin) for chemical toxicity prediction developed in our laboratory. These applications are based on predictive quantitative structure-activity relationships (QSAR) models developed using the largest publicly available datasets of structurally diverse compounds. The developed tools ensure both highly accurate predictions and easy interpretation of the models, allowing users to discriminate potential toxicants and to purpose structural modifications to design safer chemicals.",Mobile | Pred-hERG | Pred-skin | QSAR | Toxicity prediction | Web app,6,982-988,Journal,Review,4.0,"Alves, Vinicius M.;Braga, Rodolpho C.;Muratov, Eugene;Andrade, Carolina H.",57218222268;36514094800;57000654800;24436635900,Universidade Federal de Goiás;The University of North Carolina at Chapel Hill;Odessa National Polytechnic University,Brazil;United States;Ukraine,"computational tools are recognized to provide high-quality predictions for the assessment of chemical toxicity. in the recent years, mobile devices have become ubiquitous, allowing for the development of innovative and useful models implemented as chemical software applications. here, we will briefly discuss this recent uptick in the development of web-based and mobile applications for chemical problems, focusing on best practices, development, usage and interpretation. as an example, we also describe two innovative apps (pred-herg and pred-skin) for chemical toxicity prediction developed in our laboratory. these applications are based on predictive quantitative structure-activity relationships (qsar) models developed using the largest publicly available datasets of structurally diverse compounds. the developed tools ensure both highly accurate predictions and easy interpretation of the models, allowing users to discriminate potential toxicants and to purpose structural modifications to design safer chemicals.",development of web and mobile applications for chemical toxicity prediction
1000,2-s2.0-85042863953,10.1016/j.advengsoft.2018.02.007,An effective and user-friendly web application for the collaborative analysis of steel joints,Gracia J.,Advances in Engineering Software,2018-05-01,"The Internet has increased its potential exponentially since its inception. This progress has been possible due to new standards and technologies, which have also allowed the development of a new type of web applications that are fully integrated in web browsers. In addition, structural analysis has become a collaborative task in which different people have to share information and outputs of analysis programs. In this paper, an effective and user-friendly web application for the collaborative analysis of steel joints is presented. The latest cutting edge technologies in the Internet are used to address fundamental issues inherent in structural analysis software such as visualisation, interaction, and structural evaluation. Specifically, WebGL API, part of the HTML5 standard, is used to solve the visualisation issues of the proposed application. A rigorous analysis of simple and rigid structural joints is performed according to the standards and criteria set by the Eurocode 3.",Eurocode 3 | Software as a service | Structural analysis of steel joints | Web applications in the Internet,5,60-67,Journal,Article,2.0,"Gracia, J.;Bayo, E.",36724297800;7004169523,Universidad de Navarra;Universidad de Oviedo,Spain;Spain,"the internet has increased its potential exponentially since its inception. this progress has been possible due to new standards and technologies, which have also allowed the development of a new type of web applications that are fully integrated in web browsers. in addition, structural analysis has become a collaborative task in which different people have to share information and outputs of analysis programs. in this paper, an effective and user-friendly web application for the collaborative analysis of steel joints is presented. the latest cutting edge technologies in the internet are used to address fundamental issues inherent in structural analysis software such as visualisation, interaction, and structural evaluation. specifically, webgl api, part of the html5 standard, is used to solve the visualisation issues of the proposed application. a rigorous analysis of simple and rigid structural joints is performed according to the standards and criteria set by the eurocode 3.",an effective and user-friendly web application for the collaborative analysis of steel joints
1001,2-s2.0-85039427984,10.1016/j.tibtech.2017.11.009,"Augmenting Research, Education, and Outreach with Client-Side Web Programming",Abriata L.A.,Trends in Biotechnology,2018-05-01,"The evolution of computing and web technologies over the past decade has enabled the development of fully fledged scientific applications that run directly on web browsers. Powered by JavaScript, the lingua franca of web programming, these ‘web apps’ are starting to revolutionize and democratize scientific research, education, and outreach.",bioinformatics | chemoinformatics | JavaScript | open science | visualization,11,473-476,Journal,Note,4.0,"Abriata, Luciano A.;Rodrigues, João P.G.L.M.;Salathé, Marcel;Patiny, Luc",24586813800;55851948066;12780442200;6603441872,Stanford University School of Medicine;Ecole Polytechnique Fédérale de Lausanne,United States;Switzerland,"the evolution of computing and web technologies over the past decade has enabled the development of fully fledged scientific applications that run directly on web browsers. powered by javascript, the lingua franca of web programming, these ‘web apps’ are starting to revolutionize and democratize scientific research, education, and outreach.","augmenting research, education, and outreach with client-side web programming"
1002,2-s2.0-85085161000,10.1145/3184558.3188737,Towards an open Web Audio plugin standard,Buffa M.,"The Web Conference 2018 - Companion of the World Wide Web Conference, WWW 2018",2018-04-23,"Web Audio is a recent W3C API that brings the world of computer music applications to the browser. Although developers have been actively using it since the first beta implementations in 2012, the number of web apps built using Web Audio API cannot yet compare to the number of commercial and open source audio software tools available on native platforms. Many of the sites using this new technology are of an experimental nature or are very limited in their scope. While JavaScript and Web standards are increasingly flexible and powerful, C and C++ are the languages most often used for real-time audio applications and domain specific languages such as FAUST facilitate rapid development with high performance. Our work aims to create a continuum between native and browser based audio app development and to appeal to programmers from both worlds. This paper presents our proposal including guidelines and proof of concept implementations for an open Web Audio plug-in standard - essentially the infrastructure to support high level audio plug-ins for the browser.",audio effects and instruments | plugin architecture | web standards | webaudio,4,759-766,Conference Proceeding,Conference Paper,5.0,"Buffa, Michel;Lebrun, Jérôme;Kleimola, Jari;Larkin, Oliver;Letz, Stéphane",16237849300;7103324923;24829233900;25643167100;8849653600,Université Côte d'Azur,France,"web audio is a recent w3c api that brings the world of computer music applications to the browser. although developers have been actively using it since the first beta implementations in 2012, the number of web apps built using web audio api cannot yet compare to the number of commercial and open source audio software tools available on native platforms. many of the sites using this new technology are of an experimental nature or are very limited in their scope. while javascript and web standards are increasingly flexible and powerful, c and c++ are the languages most often used for real-time audio applications and domain specific languages such as faust facilitate rapid development with high performance. our work aims to create a continuum between native and browser based audio app development and to appeal to programmers from both worlds. this paper presents our proposal including guidelines and proof of concept implementations for an open web audio plug-in standard - essentially the infrastructure to support high level audio plug-ins for the browser.",towards an open web audio plugin standard
1003,2-s2.0-85055246410,10.1145/3220228.3220264,Reducing the cost of mutation operators through a novel taxonomy: Application on scripting languages,Arab I.,ACM International Conference Proceeding Series,2018-04-20,"In the last decade, web-based applications have grown exponentially, especially with the wave of smart phones which has made both mobile and web applications accessible everywhere. This new revolution of internet played a major role in the growing complexity of today’s software applications. Consequently, the quality assurance of such applications has become an inevitable feature for a web application to survive in such a highly competitive industry. Different methodologies have been proposed by the literature to test the quality of a system. Evaluating the test suite and improving the quality of the test sets is one of most known approaches used in the field. This technique is known as mutation testing. The purpose of this paper is to demonstrate the application of mutation testing technique on the widely used language in the development of web-based applications, JavaScript. Additionally, the paper will introduce a new approach to reduce the cost of mutation operators through the implementation of a novel taxonomy based on the blocks encapsulated within predicates.",JavaScript | Mutation operators | Mutation testing | Scripting languages | Software testing,1,47-56,Conference Proceeding,Conference Paper,2.0,"Arab, Issar;Bourhnane, Safae",57202832385;57202835826,"Fakultät für Informatik, Technische Universität München;Al Akhawayn University",Germany;Morocco,"in the last decade, web-based applications have grown exponentially, especially with the wave of smart phones which has made both mobile and web applications accessible everywhere. this new revolution of internet played a major role in the growing complexity of today’s software applications. consequently, the quality assurance of such applications has become an inevitable feature for a web application to survive in such a highly competitive industry. different methodologies have been proposed by the literature to test the quality of a system. evaluating the test suite and improving the quality of the test sets is one of most known approaches used in the field. this technique is known as mutation testing. the purpose of this paper is to demonstrate the application of mutation testing technique on the widely used language in the development of web-based applications, javascript. additionally, the paper will introduce a new approach to reduce the cost of mutation operators through the implementation of a novel taxonomy based on the blocks encapsulated within predicates.",reducing the cost of mutation operators through a novel taxonomy: application on scripting languages
1004,2-s2.0-85047018836,10.1109/ICSESS.2017.8342877,Web app restructuring based on shadow DOMs to improve maintainability,Oh J.,"Proceedings of the IEEE International Conference on Software Engineering and Service Sciences, ICSESS",2018-04-19,"As web apps quickly evolve, for their maintenance it is essential to separately encapsulate independent widgets composing the web pages. Thus, this paper proposes a new approach to restructuring a web app to achieve such encapsulation, which allows independent development and maintenance of widgets. The approach applies the shadow document object model (DOM) and template standards from the World Wide Web Consortium (W3C) Web Components standards. Empirical evaluation shows that our approach can be applicable to restructuring open source web apps and improving their maintainability. We also show that the approach can improve performance of web apps in terms of response time and the amount of transferred data over a network.",shadow DOM | template | web app restructuring | web widget,2,118-122,Conference Proceeding,Conference Paper,3.0,"Oh, Jaewon;Ahn, Woo Hyun;Kim, Taegong",55462885700;16232524600;55348770400,Inje University;Kwangwoon University;The Catholic University of Korea,South Korea;South Korea;South Korea,"as web apps quickly evolve, for their maintenance it is essential to separately encapsulate independent widgets composing the web pages. thus, this paper proposes a new approach to restructuring a web app to achieve such encapsulation, which allows independent development and maintenance of widgets. the approach applies the shadow document object model (dom) and template standards from the world wide web consortium (w3c) web components standards. empirical evaluation shows that our approach can be applicable to restructuring open source web apps and improving their maintainability. we also show that the approach can improve performance of web apps in terms of response time and the amount of transferred data over a network.",web app restructuring based on shadow doms to improve maintainability
1005,2-s2.0-85051049372,10.1109/SANER.2018.8330205,How do developers fix issues and pay back technical debt in the Apache ecosystem?,Digkas G.,"25th IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2018 - Proceedings",2018-04-02,"During software evolution technical debt (TD) follows a constant ebb and flow, being incurred and paid back, sometimes in the same day and sometimes ten years later. There have been several studies in the literature investigating how technical debt in source code accumulates during time and the consequences of this accumulation for software maintenance. However, to the best of our knowledge there are no large scale studies that focus on the types of issues that are fixed and the amount of TD that is paid back during software evolution. In this paper we present the results of a case study, in which we analyzed the evolution of fifty-seven Java open-source software projects by the Apache Software Foundation at the temporal granularity level of weekly snapshots. In particular, we focus on the amount of technical debt that is paid back and the types of issues that are fixed. The findings reveal that a small subset of all issue types is responsible for the largest percentage of TD repayment and thus, targeting particular violations the development team can achieve higher benefits.",Apache Software Foundation | Empirical Study | Mining Software Repositories | Software Evolution | Technical Debt,35,153-163,Conference Proceeding,Conference Paper,5.0,"Digkas, Georgios;Lungu, Mircea;Avgeriou, Paris;Chatzigeorgiou, Alexander;Ampatzoglou, Apostolos",57193727566;18434508000;17343671200;6701702023;16027681600,Rijksuniversiteit Groningen;Panepistimion Makedonias,Netherlands;Greece,"during software evolution technical debt (td) follows a constant ebb and flow, being incurred and paid back, sometimes in the same day and sometimes ten years later. there have been several studies in the literature investigating how technical debt in source code accumulates during time and the consequences of this accumulation for software maintenance. however, to the best of our knowledge there are no large scale studies that focus on the types of issues that are fixed and the amount of td that is paid back during software evolution. in this paper we present the results of a case study, in which we analyzed the evolution of fifty-seven java open-source software projects by the apache software foundation at the temporal granularity level of weekly snapshots. in particular, we focus on the amount of technical debt that is paid back and the types of issues that are fixed. the findings reveal that a small subset of all issue types is responsible for the largest percentage of td repayment and thus, targeting particular violations the development team can achieve higher benefits.",how do developers fix issues and pay back technical debt in the apache ecosystem?
1007,2-s2.0-85027039041,10.1007/s10664-017-9537-x,Addressing problems with replicability and validity of repository mining studies through a smart data platform,Trautsch F.,Empirical Software Engineering,2018-04-01,"The usage of empirical methods has grown common in software engineering. This trend spawned hundreds of publications, whose results are helping to understand and improve the software development process. Due to the data-driven nature of this venue of investigation, we identified several problems within the current state-of-the-art that pose a threat to the replicability and validity of approaches. The heavy re-use of data sets in many studies may invalidate the results in case problems with the data itself are identified. Moreover, for many studies data and/or the implementations are not available, which hinders a replication of the results and, thereby, decreases the comparability between studies. Furthermore, many studies use small data sets, which comprise of less than 10 projects. This poses a threat especially to the external validity of these studies. Even if all information about the studies is available, the diversity of the used tooling can make their replication even then very hard. Within this paper, we discuss a potential solution to these problems through a cloud-based platform that integrates data collection and analytics. We created SmartSHARK, which implements our approach. Using SmartSHARK, we collected data from several projects and created different analytic examples. Within this article, we present SmartSHARK and discuss our experiences regarding the use of it and the mentioned problems. Additionally, we show how we have addressed the issues that we have identified during our work with SmartSHARK.",Replicability | Smart data platform | Software analytics | Software mining | Validity,25,1036-1083,Journal,Article,4.0,"Trautsch, Fabian;Herbold, Steffen;Makedonski, Philip;Grabowski, Jens",57189691750;35226400600;35226436100;22334240800,Georg-August-Universität Göttingen,Germany,"the usage of empirical methods has grown common in software engineering. this trend spawned hundreds of publications, whose results are helping to understand and improve the software development process. due to the data-driven nature of this venue of investigation, we identified several problems within the current state-of-the-art that pose a threat to the replicability and validity of approaches. the heavy re-use of data sets in many studies may invalidate the results in case problems with the data itself are identified. moreover, for many studies data and/or the implementations are not available, which hinders a replication of the results and, thereby, decreases the comparability between studies. furthermore, many studies use small data sets, which comprise of less than 10 projects. this poses a threat especially to the external validity of these studies. even if all information about the studies is available, the diversity of the used tooling can make their replication even then very hard. within this paper, we discuss a potential solution to these problems through a cloud-based platform that integrates data collection and analytics. we created smartshark, which implements our approach. using smartshark, we collected data from several projects and created different analytic examples. within this article, we present smartshark and discuss our experiences regarding the use of it and the mentioned problems. additionally, we show how we have addressed the issues that we have identified during our work with smartshark.",addressing problems with replicability and validity of repository mining studies through a smart data platform
1008,2-s2.0-85061880065,10.1093/bib/bbx108,"MAFFT online service: Multiple sequence alignment, interactive sequence choice and visualization",Katoh K.,Briefings in Bioinformatics,2018-03-27,"This article describes several features in the MAFFT online service for multiple sequence alignment (MSA). As a result of recent advances in sequencing technologies, huge numbers of biological sequences are available and the need for MSAs with large numbers of sequences is increasing. To extract biologically relevant information from such data, sophistication of algorithms is necessary but not sufficient. Intuitive and interactive tools for experimental biologists to semiautomatically handle large data are becoming important. We are working on development of MAFFT toward these two directions. Here, we explain (i) the Web interface for recently developed options for large data and (ii) interactive usage to refine sequence data sets and MSAs.",multiple sequence alignment | phylogenetic tree | sequence analysis,2473,1160-1166,Journal,Article,3.0,"Katoh, Kazutaka;Rozewicki, John;Yamada, Kazunori D.",7201809918;57209991379;55732854700,Research Institute for Microbial Diseases;Tohoku University,Japan;Japan,"this article describes several features in the mafft online service for multiple sequence alignment (msa). as a result of recent advances in sequencing technologies, huge numbers of biological sequences are available and the need for msas with large numbers of sequences is increasing. to extract biologically relevant information from such data, sophistication of algorithms is necessary but not sufficient. intuitive and interactive tools for experimental biologists to semiautomatically handle large data are becoming important. we are working on development of mafft toward these two directions. here, we explain (i) the web interface for recently developed options for large data and (ii) interactive usage to refine sequence data sets and msas.","mafft online service: multiple sequence alignment, interactive sequence choice and visualization"
1009,2-s2.0-85039555776,10.1016/j.neucom.2017.11.069,MLweb: A toolkit for machine learning on the web,Lauer F.,Neurocomputing,2018-03-22,"This paper describes MLweb, an open source software toolkit for machine learning on the web. The specificity of MLweb is that all computations are performed on the client side without the need to send data to a third-party server. MLweb includes three main components: a JavaScript API for scientific computing (LALOLib), an extension of this library with machine learning tools (ML.js) and an online development environment (LALOLab) with many examples.",Classification | JavaScript | Machine learning | Regression,8,74-77,Journal,Article,1.0,"Lauer, Fabien",22333888400,Université de Lorraine,France,"this paper describes mlweb, an open source software toolkit for machine learning on the web. the specificity of mlweb is that all computations are performed on the client side without the need to send data to a third-party server. mlweb includes three main components: a javascript api for scientific computing (lalolib), an extension of this library with machine learning tools (ml.js) and an online development environment (lalolab) with many examples.",mlweb: a toolkit for machine learning on the web
1010,2-s2.0-85041222379,10.1002/cmdc.201700675,Consensus Predictive Model for Human K562 Cell Growth Inhibition through Enalos Cloud Platform,Afantitis A.,ChemMedChem,2018-03-20,"β-Thalassemia is an inherited hematologic disorder caused by various mutations of the β-globin gene, thus resulting in a significant decrease in adult hemoglobin (HbA) production. An increase in fetal hemoglobin (HbF) levels by drug molecules is considered of great potential in β-thalassemia treatment and is expected to counterbalance the impaired production of HbA. In this work, based on a set of 129 experimentally tested biological inhibitors, we developed and validated a computational model for the prediction of K562 functional inhibition, possibly associated with HbF induction. To facilitate future advancements in the field, we incorporated our model into Enalos Cloud Platform, which enabled online access to our computational scheme (http://enalos.insilicotox.com/K562) through a user-friendly interface. This web service is offered to the wider community to promote in silico drug discovery through fast and reliable predictions.",cheminformatics | drug discovery | hemoglobin | inhibitors | predictive modeling,1,555-563,Journal,Article,4.0,"Afantitis, Antreas;Leonis, Georgios;Gambari, Roberto;Melagraki, Georgia",6507913243;39961861800;7102534350;8283563600,NovaMechanics Ltd;University of Ferrara;Hellenic Army Academy,Cyprus;Italy;Greece,"β-thalassemia is an inherited hematologic disorder caused by various mutations of the β-globin gene, thus resulting in a significant decrease in adult hemoglobin (hba) production. an increase in fetal hemoglobin (hbf) levels by drug molecules is considered of great potential in β-thalassemia treatment and is expected to counterbalance the impaired production of hba. in this work, based on a set of 129 experimentally tested biological inhibitors, we developed and validated a computational model for the prediction of k562 functional inhibition, possibly associated with hbf induction. to facilitate future advancements in the field, we incorporated our model into enalos cloud platform, which enabled online access to our computational scheme (http://enalos.insilicotox.com/k562) through a user-friendly interface. this web service is offered to the wider community to promote in silico drug discovery through fast and reliable predictions.",consensus predictive model for human k562 cell growth inhibition through enalos cloud platform
1011,2-s2.0-85050813643,10.1109/CICN.2017.8319355,Metric based detection of refused bequest code smell,Merzah B.M.,"Proceedings - 9th International Conference on Computational Intelligence and Communication Networks, CICN 2017",2018-03-16,"The concept of code smell was introduced as a signs of internal design flaws within the software. Code smells detection has become a mandatory technique to detect code issues that may affect negatively on the software quality by causing problems for further development and maintenance. Accordingly, the consensus is that all types of code smells need to be refactored to deny or diminish such issues. The refactoring techniques can get rid of particular design flaws or principle violations, and restore the code fragment that present a smell, to an acceptable quality level. In the context of object-oriented systems, the concept of inheritance has been known as a key feature proposed to increase the amount of software reusability. However, using inheritance is not always the best solution, particularly if it is utilized in improper cases where other types of relationships would be more appropriate. One of the particular issues that violate inheritance principles is the Refused Bequest code smell. It is related to an inheritance hierarchy where a subclass does not obligate the interface inherited from its parent class. Some studies, mentioned in Section 2, had been made to detect the Refused Bequest smell. In this paper we present a new detection strategy by computing the similarity between common methods of the base class with the overridden methods of the sub-class, and then by calculating the average of these values for the given sub-class. That average value is defined as a new metric in our detection mechanism.",code smells | object oriented metrics | refused bequest | similarity between methods | software quality,2,53-57,Conference Proceeding,Conference Paper,2.0,"Merzah, Baydaa M.;Selcuk, Yunus E.",57714922000;6701597824,Yildiz Technical University,Turkey,"the concept of code smell was introduced as a signs of internal design flaws within the software. code smells detection has become a mandatory technique to detect code issues that may affect negatively on the software quality by causing problems for further development and maintenance. accordingly, the consensus is that all types of code smells need to be refactored to deny or diminish such issues. the refactoring techniques can get rid of particular design flaws or principle violations, and restore the code fragment that present a smell, to an acceptable quality level. in the context of object-oriented systems, the concept of inheritance has been known as a key feature proposed to increase the amount of software reusability. however, using inheritance is not always the best solution, particularly if it is utilized in improper cases where other types of relationships would be more appropriate. one of the particular issues that violate inheritance principles is the refused bequest code smell. it is related to an inheritance hierarchy where a subclass does not obligate the interface inherited from its parent class. some studies, mentioned in section 2, had been made to detect the refused bequest smell. in this paper we present a new detection strategy by computing the similarity between common methods of the base class with the overridden methods of the sub-class, and then by calculating the average of these values for the given sub-class. that average value is defined as a new metric in our detection mechanism.",metric based detection of refused bequest code smell
1014,2-s2.0-85050741505,10.1109/CYBERNETICSCOM.2017.8311684,Web crawler and back-end for news aggregator system (Noox project),Bahana R.,"2017 IEEE International Conference on Cybernetics and Computational Intelligence, CyberneticsCOM 2017 - Proceedings",2018-03-09,"The aim of this manuscript is to develop a web crawler, Content Management System (CMS), and Application Programming Interface (API) for a news aggregator system dubbed Noox project. News aggregator system requires a crawler to populate its content; however, different website may have a different page layout. This projects aims to create a back-end for Noox and open source and scalable web crawler that is capable to extract data from different page layout. The scope of this project includes the web crawler, CMS, API, scheduler for web crawler, and implementation of socket server. The development process utilizes PHP as the primary back-end language with Laravel as the web application framework. The PHP back-end hosts the CMS and the API. The API itself will implement Representational State Transfer (REST) as its architectural design. JavaScript Object Notation (JSON) is used as means of the API to communicate with the clients. The API also implements JSON Web Token (JWT) for client authentication purpose. Python programming language is used to develop the web crawler. The web crawler utilizes BeautifulSoup as the web extraction utility. The web crawler can be adapted to extract data from different page layout by utilizing user created configuration file. It can also be configured to export the extracted data into a JSON file or database system. The result of this project satisfies the requirement of the Noox project.",Application Programming Interface | CMS | HTML Extraction | Web Crawler | Web Scrapper,3,56-61,Conference Proceeding,Conference Paper,6.0,"Bahana, Raymond;Adinugroho, Rahadian;Gaol, Ford Lumban;Trisetyarso, Agung;Abbas, Bahtiar Saleh;Suparta, Wayan",56400946100;57203159215;24536664300;36337949500;55835973000;24330191400,Bina Nusantara University;University of Technology,Indonesia;Indonesia,"the aim of this manuscript is to develop a web crawler, content management system (cms), and application programming interface (api) for a news aggregator system dubbed noox project. news aggregator system requires a crawler to populate its content; however, different website may have a different page layout. this projects aims to create a back-end for noox and open source and scalable web crawler that is capable to extract data from different page layout. the scope of this project includes the web crawler, cms, api, scheduler for web crawler, and implementation of socket server. the development process utilizes php as the primary back-end language with laravel as the web application framework. the php back-end hosts the cms and the api. the api itself will implement representational state transfer (rest) as its architectural design. javascript object notation (json) is used as means of the api to communicate with the clients. the api also implements json web token (jwt) for client authentication purpose. python programming language is used to develop the web crawler. the web crawler utilizes beautifulsoup as the web extraction utility. the web crawler can be adapted to extract data from different page layout by utilizing user created configuration file. it can also be configured to export the extracted data into a json file or database system. the result of this project satisfies the requirement of the noox project.",web crawler and back-end for news aggregator system (noox project)
1015,2-s2.0-85046097017,10.1109/AICCSA.2017.197,Software process patterns: A roadmap,Hachemi A.,"Proceedings of IEEE/ACS International Conference on Computer Systems and Applications, AICCSA",2018-03-07,"The impact of the development process on the developed software emphasizes the importance of software processes. Research works to control and improve software processes became thus essential. In this context, process patterns emerged as excellent artifacts, that perpetuate proved knowledge on software processes and enable its reuses in different situations. Although many researchers focus their interests on process patterns, this field remains insufficiently explored and much research is still needed. Thus, we give through this article a literature revue related to process patterns, and we compare important works in this field to highlight the progress and the difficulties yet to be addressed.",Patterns identification | Patterns modeling | Patterns organization | Patterns reuse | Process pattern | Software pattern,2,887-894,Conference Proceeding,Conference Paper,2.0,"Hachemi, Asma;Ahmed-Nacer, Mohamed",55445510300;6602896898,Université des Sciences et de la Technologie Houari Boumediene,Algeria,"the impact of the development process on the developed software emphasizes the importance of software processes. research works to control and improve software processes became thus essential. in this context, process patterns emerged as excellent artifacts, that perpetuate proved knowledge on software processes and enable its reuses in different situations. although many researchers focus their interests on process patterns, this field remains insufficiently explored and much research is still needed. thus, we give through this article a literature revue related to process patterns, and we compare important works in this field to highlight the progress and the difficulties yet to be addressed.",software process patterns: a roadmap
1016,2-s2.0-85051844591,10.1093/molbev/msx335,Datamonkey 2.0: A modern web application for characterizing selective and other evolutionary processes,Weaver S.,Molecular Biology and Evolution,2018-03-01,"Inference of how evolutionary forces have shaped extant genetic diversity is a cornerstone of modern comparative sequence analysis. Advances in sequence generation and increased statistical sophistication of relevant methods now allow researchers to extract ever more evolutionary signal from the data, albeit at an increased computational cost. Here, we announce the release of Datamonkey 2.0, a completely re-engineered version of the Datamonkey web-server for analyzing evolutionary signatures in sequence data. For this endeavor, we leveraged recent developments in open-source libraries that facilitate interactive, robust, and scalable web application development. Datamonkey 2.0 provides a carefully curated collection of methods for interrogating coding-sequence alignments for imprints of natural selection, packaged as a responsive (i.e. can be viewed on tablet and mobile devices), fully interactive, and API-enabled web application. To complement Datamonkey 2.0, we additionally release HyPhy Vision, an accompanying JavaScript application for visualizing analysis results. HyPhy Vision can also be used separately from Datamonkey 2.0 to visualize locally executed HyPhy analyses. Together, Datamonkey 2.0 and HyPhy Vision showcase how scientific software development can benefit from general-purpose open-source frameworks. Datamonkey 2.0 is freely and publicly available at http:// www.datamonkey.org, and the underlying codebase is available from https://github.com/veg/datamonkey-js.",Evolutionary Inference | Natural selection | Recombination | Statistical methods | Web application,313,773-777,Journal,Article,6.0,"Weaver, Steven;Shank, Stephen D.;Spielman, Stephanie J.;Li, Michael;Muse, Spencer V.;Kosakovsky Pond, Sergei L.",56375175300;55652778900;55565916200;57203682287;6701428273;7801633431,Temple University;NC State University,United States;United States,"inference of how evolutionary forces have shaped extant genetic diversity is a cornerstone of modern comparative sequence analysis. advances in sequence generation and increased statistical sophistication of relevant methods now allow researchers to extract ever more evolutionary signal from the data, albeit at an increased computational cost. here, we announce the release of datamonkey 2.0, a completely re-engineered version of the datamonkey web-server for analyzing evolutionary signatures in sequence data. for this endeavor, we leveraged recent developments in open-source libraries that facilitate interactive, robust, and scalable web application development. datamonkey 2.0 provides a carefully curated collection of methods for interrogating coding-sequence alignments for imprints of natural selection, packaged as a responsive (i.e. can be viewed on tablet and mobile devices), fully interactive, and api-enabled web application. to complement datamonkey 2.0, we additionally release hyphy vision, an accompanying javascript application for visualizing analysis results. hyphy vision can also be used separately from datamonkey 2.0 to visualize locally executed hyphy analyses. together, datamonkey 2.0 and hyphy vision showcase how scientific software development can benefit from general-purpose open-source frameworks. datamonkey 2.0 is freely and publicly available at http:// www.datamonkey.org, and the underlying codebase is available from https://github.com/veg/datamonkey-js.",datamonkey 2.0: a modern web application for characterizing selective and other evolutionary processes
1017,2-s2.0-85045907841,10.1109/APSEC.2017.43,Mining API Type Specifications for JavaScript,Wang S.,"Proceedings - Asia-Pacific Software Engineering Conference, APSEC",2018-03-01,"API specifications play an important role in software development. However, API specifications are often not well documented, especially for JavaScript. Many JavaScript API specifications lack of precise type information for API parameters and return values. In this paper, we propose a static approach for mining JavaScript type specifications automatically. We gather the usage information of return values and parameters statically, and infer types of return values based their usages, by identifying a known type which they are used most likely to be, and infer parameters by identifying the most used parameters. We evaluate the approach on the homepages of Alexa top 1000 websites, the experimental results show that our approach can gain high precision. Our case study on jQuery shows that our approach gains high precision and reasonable recall on jQuery, and we can use our inferred API type specifications to detect 2 jQuery misusage errors in real-world web sites, and 1 missing type error in jQuery documentations.",API | JavaScript | Type Specification,0,368-377,Conference Proceeding,Conference Paper,5.0,"Wang, Shuai;Dou, Wensheng;Gao, Chushu;Wei, Jun;Huang, Tao",57189701192;57189041402;51663446200;34772294900;56808498100,University of Chinese Academy of Sciences;Institute of Software Chinese Academy of Sciences,China;China,"api specifications play an important role in software development. however, api specifications are often not well documented, especially for javascript. many javascript api specifications lack of precise type information for api parameters and return values. in this paper, we propose a static approach for mining javascript type specifications automatically. we gather the usage information of return values and parameters statically, and infer types of return values based their usages, by identifying a known type which they are used most likely to be, and infer parameters by identifying the most used parameters. we evaluate the approach on the homepages of alexa top 1000 websites, the experimental results show that our approach can gain high precision. our case study on jquery shows that our approach gains high precision and reasonable recall on jquery, and we can use our inferred api type specifications to detect 2 jquery misusage errors in real-world web sites, and 1 missing type error in jquery documentations.",mining api type specifications for javascript
1019,2-s2.0-85040171299,10.1016/j.jmgm.2017.12.020,FilTer BaSe: A web accessible chemical database for small compound libraries,Kolte B.,Journal of Molecular Graphics and Modelling,2018-03-01,"Finding novel chemical agents for targeting disease associated drug targets often requires screening of large number of new chemical libraries. In silico methods are generally implemented at initial stages for virtual screening. Filtering of such compound libraries on physicochemical and substructure ground is done to ensure elimination of compounds with undesired chemical properties. Filtering procedure, is redundant, time consuming and requires efficient bioinformatics/computer manpower along with high end software involving huge capital investment that forms a major obstacle in drug discovery projects in academic setup. We present an open source resource, FilTer BaSe- a chemoinformatics platform (http://bioinfo.net.in/filterbase/) that host fully filtered, ready to use compound libraries with workable size. The resource also hosts a database that enables efficient searching the chemical space of around 348,000 compounds on the basis of physicochemical and substructure properties. Ready to use compound libraries and database presented here is expected to aid a helping hand for new drug developers and medicinal chemists.",Bioinformatics | Chemoinformatics | Compound libraries | Drug discovery | FilTer BaSe | Substructure searching | Virtual screening,6,95-103,Journal,Article,5.0,"Kolte, Baban S.;Londhe, Sanjay R.;Solanki, Bhushan R.;Gacche, Rajesh N.;Meshram, Rohan J.",57200203123;57200206634;57200204529;7801607153;55098329200,Savitribai Phule Pune University;Mahindra Navistar Automotive Limited,India;India,"finding novel chemical agents for targeting disease associated drug targets often requires screening of large number of new chemical libraries. in silico methods are generally implemented at initial stages for virtual screening. filtering of such compound libraries on physicochemical and substructure ground is done to ensure elimination of compounds with undesired chemical properties. filtering procedure, is redundant, time consuming and requires efficient bioinformatics/computer manpower along with high end software involving huge capital investment that forms a major obstacle in drug discovery projects in academic setup. we present an open source resource, filter base- a chemoinformatics platform (http://bioinfo.net.in/filterbase/) that host fully filtered, ready to use compound libraries with workable size. the resource also hosts a database that enables efficient searching the chemical space of around 348,000 compounds on the basis of physicochemical and substructure properties. ready to use compound libraries and database presented here is expected to aid a helping hand for new drug developers and medicinal chemists.",filter base: a web accessible chemical database for small compound libraries
1020,2-s2.0-85023644569,10.1109/MS.2017.265100610,AngularJS performance: A survey study,Ramos M.,IEEE Software,2018-03-01,"AngularJS is a popular JavaScript framework based on the model-view-controller pattern to construct single-page web apps. Researchers surveyed 95 professional developers regarding the performance problems of AngularJS applications. They determined the common practices the developers followed to avoid the problems (for example, using third-party or custom components), the problems' general causes (for example, inadequate application architectures), and the problems' technical causes (for example, unnecessary processing in the digest cycle, which is the internal computation that automatically updates the view with changes detected in the model).",AngularJS | development experience | software development | software engineering | software performance | web apps,5,72-79,Journal,Review,3.0,"Ramos, Miguel;Valente, Marco Tulio;Terra, Ricardo",56609705200;55437198000;36865399300,Universidade Federal de Minas Gerais;Universidade Federal de Lavras,Brazil;Brazil,"angularjs is a popular javascript framework based on the model-view-controller pattern to construct single-page web apps. researchers surveyed 95 professional developers regarding the performance problems of angularjs applications. they determined the common practices the developers followed to avoid the problems (for example, using third-party or custom components), the problems' general causes (for example, inadequate application architectures), and the problems' technical causes (for example, unnecessary processing in the digest cycle, which is the internal computation that automatically updates the view with changes detected in the model).",angularjs performance: a survey study
1021,2-s2.0-85040728628,10.1108/LHT-03-2017-0056,Overcoming disintermediation: a call for librarians to learn to use web service APIs,Adams R.M.,Library Hi Tech,2018-02-07,"Purpose: The purpose of this paper is to argue that academic librarians must learn to use web service APIs and to introduce APIs to a non-technical audience. Design/methodology/approach: This paper is a viewpoint that argues for the importance of APIs by identifying the shifting paradigms of libraries in the digital age. Showing that the primary function of librarians will be to share and curate digital content, the paper shows that APIs empower a librarian to do that. Findings: The implementation of web service APIs is within the reach of librarians who are not trained as software developers. Online documentation and free courses offer sufficient training for librarians to learn these new ways of sharing and curating digital content. Research limitations/implications: The argument of this paper depends upon an assumption of a shift in the paradigm of libraries away from collections of materials to access points of information. The need for libraries to learn APIs depends upon a new role for librarians that anecdotal evidence supports is rising. Practical implications: By learning a few technical skills, librarians can help patrons find relevant information within a world of proliferating information sources. Originality/value: The literature on APIs is highly technical and overwhelming for those without training in software development. This paper translates technical language for those who have not programmed before.",Digital libraries | Information curation | Information literacy | Programming | Software development | Web service API,4,180-190,Journal,Article,1.0,"Adams, Richard Manly",57200530733,Emory University,United States,"purpose: the purpose of this paper is to argue that academic librarians must learn to use web service apis and to introduce apis to a non-technical audience. design/methodology/approach: this paper is a viewpoint that argues for the importance of apis by identifying the shifting paradigms of libraries in the digital age. showing that the primary function of librarians will be to share and curate digital content, the paper shows that apis empower a librarian to do that. findings: the implementation of web service apis is within the reach of librarians who are not trained as software developers. online documentation and free courses offer sufficient training for librarians to learn these new ways of sharing and curating digital content. research limitations/implications: the argument of this paper depends upon an assumption of a shift in the paradigm of libraries away from collections of materials to access points of information. the need for libraries to learn apis depends upon a new role for librarians that anecdotal evidence supports is rising. practical implications: by learning a few technical skills, librarians can help patrons find relevant information within a world of proliferating information sources. originality/value: the literature on apis is highly technical and overwhelming for those without training in software development. this paper translates technical language for those who have not programmed before.",overcoming disintermediation: a call for librarians to learn to use web service apis
1023,2-s2.0-85035105549,10.1016/j.cageo.2017.11.007,3D geospatial visualizations: Animation and motion effects on spatial objects,Evangelidis K.,Computers and Geosciences,2018-02-01,"Digital Elevation Models (DEMs), in combination with high quality raster graphics provide realistic three-dimensional (3D) representations of the globe (virtual globe) and amazing navigation experience over the terrain through earth browsers. In addition, the adoption of interoperable geospatial mark-up languages (e.g. KML) and open programming libraries (Javascript) makes it also possible to create 3D spatial objects and convey on them the sensation of any type of texture by utilizing open 3D representation models (e.g. Collada). One step beyond, by employing WebGL frameworks (e.g. Cesium.js, three.js) animation and motion effects are attributed on 3D models. However, major GIS-based functionalities in combination with all the above mentioned visualization capabilities such as for example animation effects on selected areas of the terrain texture (e.g. sea waves) as well as motion effects on 3D objects moving in dynamically defined georeferenced terrain paths (e.g. the motion of an animal over a hill, or of a big fish in an ocean etc.) are not widely supported at least by open geospatial applications or development frameworks. Towards this we developed and made available to the research community, an open geospatial software application prototype that provides high level capabilities for dynamically creating user defined virtual geospatial worlds populated by selected animated and moving 3D models on user specified locations, paths and areas. At the same time, the generated code may enhance existing open visualization frameworks and programming libraries dealing with 3D simulations, with the geospatial aspect of a virtual world.",3D geospatial visualization | 3D spatial objects motion | Javascript | WebGL,23,200-212,Journal,Article,5.0,"Evangelidis, Konstantinos;Papadopoulos, Theofilos;Papatheodorou, Konstantinos;Mastorokostas, Paris;Hilas, Constantinos",23004336600;57197829833;55050324100;6601938978;13408478000,University of West Attica;Technological Educational Institute of Central Macedonia,Greece;Greece,"digital elevation models (dems), in combination with high quality raster graphics provide realistic three-dimensional (3d) representations of the globe (virtual globe) and amazing navigation experience over the terrain through earth browsers. in addition, the adoption of interoperable geospatial mark-up languages (e.g. kml) and open programming libraries (javascript) makes it also possible to create 3d spatial objects and convey on them the sensation of any type of texture by utilizing open 3d representation models (e.g. collada). one step beyond, by employing webgl frameworks (e.g. cesium.js, three.js) animation and motion effects are attributed on 3d models. however, major gis-based functionalities in combination with all the above mentioned visualization capabilities such as for example animation effects on selected areas of the terrain texture (e.g. sea waves) as well as motion effects on 3d objects moving in dynamically defined georeferenced terrain paths (e.g. the motion of an animal over a hill, or of a big fish in an ocean etc.) are not widely supported at least by open geospatial applications or development frameworks. towards this we developed and made available to the research community, an open geospatial software application prototype that provides high level capabilities for dynamically creating user defined virtual geospatial worlds populated by selected animated and moving 3d models on user specified locations, paths and areas. at the same time, the generated code may enhance existing open visualization frameworks and programming libraries dealing with 3d simulations, with the geospatial aspect of a virtual world.",3d geospatial visualizations: animation and motion effects on spatial objects
1024,2-s2.0-85030776133,10.1016/j.infsof.2017.09.011,Understanding metric-based detectable smells in Python software: A comparative study,Chen Z.,Information and Software Technology,2018-02-01,"Context Code smells are supposed to cause potential comprehension and maintenance problems in software development. Although code smells are studied in many languages, e.g. Java and C#, there is a lack of technique or tool support addressing code smells in Python. Objective Due to the great differences between Python and static languages, the goal of this study is to define and detect code smells in Python programs and to explore the effects of Python smells on software maintainability. Method In this paper, we introduced ten code smells and established a metric-based detection method with three different filtering strategies to specify metric thresholds (Experience-Based Strategy, Statistics-Based Strategy, and Tuning Machine Strategy). Then, we performed a comparative study to investigate how three detection strategies perform in detecting Python smells and how these smells affect software maintainability with different detection strategies. This study utilized a corpus of 106 Python projects with most stars on GitHub. Results The results showed that: (1) the metric-based detection approach performs well in detecting Python smells and Tuning Machine Strategy achieves the best accuracy; (2) the three detection strategies discover some different smell occurrences, and Long Parameter List and Long Method are more prevalent than other smells; (3) several kinds of code smells are more significantly related to changes or faults in Python modules. Conclusion These findings reveal the key features of Python smells and also provide a guideline for the choice of detection strategy in detecting and analyzing Python smells.",Code smell | Detection strategy | Python | Software maintainability,17,14-29,Journal,Article,6.0,"Chen, Zhifei;Chen, Lin;Ma, Wanwangying;Zhou, Xiaoyu;Zhou, Yuming;Xu, Baowen",55884919800;57189042207;56949541600;55743306600;57022538800;7404589262,Nanjing University;Southeast University,China;China,"context code smells are supposed to cause potential comprehension and maintenance problems in software development. although code smells are studied in many languages, e.g. java and c#, there is a lack of technique or tool support addressing code smells in python. objective due to the great differences between python and static languages, the goal of this study is to define and detect code smells in python programs and to explore the effects of python smells on software maintainability. method in this paper, we introduced ten code smells and established a metric-based detection method with three different filtering strategies to specify metric thresholds (experience-based strategy, statistics-based strategy, and tuning machine strategy). then, we performed a comparative study to investigate how three detection strategies perform in detecting python smells and how these smells affect software maintainability with different detection strategies. this study utilized a corpus of 106 python projects with most stars on github. results the results showed that: (1) the metric-based detection approach performs well in detecting python smells and tuning machine strategy achieves the best accuracy; (2) the three detection strategies discover some different smell occurrences, and long parameter list and long method are more prevalent than other smells; (3) several kinds of code smells are more significantly related to changes or faults in python modules. conclusion these findings reveal the key features of python smells and also provide a guideline for the choice of detection strategy in detecting and analyzing python smells.",understanding metric-based detectable smells in python software: a comparative study
1025,2-s2.0-85018911525,10.1007/s10664-017-9521-5,Do developers update their library dependencies?: An empirical study on the impact of security advisories on library migration,Kula R.G.,Empirical Software Engineering,2018-02-01,"Third-party library reuse has become common practice in contemporary software development, as it includes several benefits for developers. Library dependencies are constantly evolving, with newly added features and patches that fix bugs in older versions. To take full advantage of third-party reuse, developers should always keep up to date with the latest versions of their library dependencies. In this paper, we investigate the extent of which developers update their library dependencies. Specifically, we conducted an empirical study on library migration that covers over 4,600 GitHub software projects and 2,700 library dependencies. Results show that although many of these systems rely heavily on dependencies, 81.5% of the studied systems still keep their outdated dependencies. In the case of updating a vulnerable dependency, the study reveals that affected developers are not likely to respond to a security advisory. Surveying these developers, we find that 69% of the interviewees claimed to be unaware of their vulnerable dependencies. Moreover, developers are not likely to prioritize a library update, as it is perceived to be extra workload and responsibility. This study concludes that even though third-party reuse is common practice, updating a dependency is not as common for many developers.",Security vulnerabilities | Software maintenance | Software reuse,109,384-417,Journal,Article,5.0,"Kula, Raula Gaikovina;German, Daniel M.;Ouni, Ali;Ishio, Takashi;Inoue, Katsuro",57188638536;57207886015;50761492200;8381338700;7601540520,Osaka University;United Arab Emirates University;University of Victoria,Japan;United Arab Emirates;Canada,"third-party library reuse has become common practice in contemporary software development, as it includes several benefits for developers. library dependencies are constantly evolving, with newly added features and patches that fix bugs in older versions. to take full advantage of third-party reuse, developers should always keep up to date with the latest versions of their library dependencies. in this paper, we investigate the extent of which developers update their library dependencies. specifically, we conducted an empirical study on library migration that covers over 4,600 github software projects and 2,700 library dependencies. results show that although many of these systems rely heavily on dependencies, 81.5% of the studied systems still keep their outdated dependencies. in the case of updating a vulnerable dependency, the study reveals that affected developers are not likely to respond to a security advisory. surveying these developers, we find that 69% of the interviewees claimed to be unaware of their vulnerable dependencies. moreover, developers are not likely to prioritize a library update, as it is perceived to be extra workload and responsibility. this study concludes that even though third-party reuse is common practice, updating a dependency is not as common for many developers.",do developers update their library dependencies?: an empirical study on the impact of security advisories on library migration
1026,2-s2.0-84988366402,10.1007/s10270-016-0559-4,Model-driven development of mobile applications for Android and iOS supporting role-based app variability,Vaupel S.,Software and Systems Modeling,2018-02-01,"Rapidly increasing numbers of applications and users make the development of mobile applications to one of the most promising fields in software engineering. Due to short time to market, differing platforms, and fast emerging technologies, mobile application development faces typical challenges where model-driven development (MDD) can help. We present a modeling language and an infrastructure for the MDD of native apps in Android and iOS. Our approach allows a flexible app development on different abstraction levels: compact modeling of standard app elements such as standard data management and increasingly detailed modeling of individual elements to cover, for example, specific behavior. Moreover, a kind of variability modeling is supported such that mobile apps with variants can be developed. We demonstrate our MDD approach with several apps including a conference app, a museum guide with augmented reality functionality, and a SmartPlug.",Android | iOS | Mobile application | Model-driven development,26,35-63,Journal,Article,4.0,"Vaupel, Steffen;Taentzer, Gabriele;Gerlach, René;Guckert, Michael",56487819300;6603840394;56487131500;56487813200,Philipps-Universität Marburg;Technische Hochschule Mittelhessen,Germany;Germany,"rapidly increasing numbers of applications and users make the development of mobile applications to one of the most promising fields in software engineering. due to short time to market, differing platforms, and fast emerging technologies, mobile application development faces typical challenges where model-driven development (mdd) can help. we present a modeling language and an infrastructure for the mdd of native apps in android and ios. our approach allows a flexible app development on different abstraction levels: compact modeling of standard app elements such as standard data management and increasingly detailed modeling of individual elements to cover, for example, specific behavior. moreover, a kind of variability modeling is supported such that mobile apps with variants can be developed. we demonstrate our mdd approach with several apps including a conference app, a museum guide with augmented reality functionality, and a smartplug.",model-driven development of mobile applications for android and ios supporting role-based app variability
1028,2-s2.0-85046018227,10.1109/SAI.2017.8252116,Anomaly detection in dynamic programming languages through heuristics based type inference,Jia X.,Proceedings of Computing Conference 2017,2018-01-08,"The growth of agile methods has helped to popularize dynamic programming languages. Their concise syntax and the flexible type handling are well suited for the needs of agile development. Flexible type handling is advantageous in the application of polymorphism, a key ingredient of agile methods. Coincidentally, flexible type declarations have resulted in the loss of a significant tool for assuring software quality. Static typing has long been considered a key tool for identifying anomalies. Proponents of agile methods have come to depend upon a combination of static analysis and software testing to assure code quality. Existing static analysis tools have given little attention to type information. We have identified an approach that combines type inference based heuristics with existing static analysis tools in the identification of potential anomalies. This approach provides the programmer with an assessment of the likelihood that the code contains an anomaly. The goal of this approach is to help improve the quality of the resulting code while retaining the advantages already observed with dynamic programming languages. An initial evaluation of this approach resulted in potential type related anomalies being correctly identified 86% of the time while existing approaches were correct only 36 to 64% of the time.",agile software development | dynamic programming languages | static analysis | type inference,0,286-293,Conference Proceeding,Conference Paper,2.0,"Jia, Xiaoping;Dittmer, Howard",7201933756;57201746288,DePaul University,United States,"the growth of agile methods has helped to popularize dynamic programming languages. their concise syntax and the flexible type handling are well suited for the needs of agile development. flexible type handling is advantageous in the application of polymorphism, a key ingredient of agile methods. coincidentally, flexible type declarations have resulted in the loss of a significant tool for assuring software quality. static typing has long been considered a key tool for identifying anomalies. proponents of agile methods have come to depend upon a combination of static analysis and software testing to assure code quality. existing static analysis tools have given little attention to type information. we have identified an approach that combines type inference based heuristics with existing static analysis tools in the identification of potential anomalies. this approach provides the programmer with an assessment of the likelihood that the code contains an anomaly. the goal of this approach is to help improve the quality of the resulting code while retaining the advantages already observed with dynamic programming languages. an initial evaluation of this approach resulted in potential type related anomalies being correctly identified 86% of the time while existing approaches were correct only 36 to 64% of the time.",anomaly detection in dynamic programming languages through heuristics based type inference
1032,2-s2.0-85118077771,10.1049/PBTR009E_ch8,Robot as a service and its visual programming environment,Chen Y.,Autonomous Decentralized Systems and their Applications in Transport and Infrastructure,2018-01-01,"Robot as a Service (RaaS) is a cloud-computing unit that facilitates the seamless integration of robots and embedded devices into Web and cloud-computing environments. The RaaS concepts can be applied to different types of IoT applications, including cyber-physical systems, autonomous decentralized systems, serverless computing systems, and Internet of Intelligent Things. This section presents the design and implementations of a number of RaaS units, as well as a Visual IoT/ Robotics Programming Environment that can visually program RaaS units through a drag-and-drop style. Multiple physical robots and simulated robots are implemented. The platform independence was ensured through a standard interface defined in a JavaScript Object Notation object. The development and testing of several sample applications is shown.",Automated buildings | Autonomous decentralized systems | Cloud computing | Cloud-computing environments | Cloud-computing unit | Control engineering computing | Cyber-physical systems | Design | Home automation | Implementations | Information networks | Intelligent things | Internet | Internet of things | Internet software | IoT applications | Java | Mobile robots | Mobile robots | Multiple physical robots | RaaS concepts | Raas units | Robot programming | Robotics | Serverless computing systems | Service robots | Simulated robots | Software engineering techniques | Visual IoT/robotics programming environment | Visual programming | Visual programming environment,0,181-200,Book,Book Chapter,2.0,"Chen, Yinong;De Luca, Gennaro",8884498700;57191584961,Arizona State University,United States,"robot as a service (raas) is a cloud-computing unit that facilitates the seamless integration of robots and embedded devices into web and cloud-computing environments. the raas concepts can be applied to different types of iot applications, including cyber-physical systems, autonomous decentralized systems, serverless computing systems, and internet of intelligent things. this section presents the design and implementations of a number of raas units, as well as a visual iot/ robotics programming environment that can visually program raas units through a drag-and-drop style. multiple physical robots and simulated robots are implemented. the platform independence was ensured through a standard interface defined in a javascript object notation object. the development and testing of several sample applications is shown.",robot as a service and its visual programming environment
1033,2-s2.0-85111379537,10.1007/978-981-10-7515-5_18,Evolving an Industrial Digital Ecosystem: A Transformative Case of Leather Industry,Anantharaman L.,Studies in Big Data,2018-01-01,"Advances in information technology have made delivering e-content easier to subject experts and to publish on the Web with minimal technical skills and assistance. The development of multimedia e-Learning content is no more labour-intensive process, requiring a team of Web designers and developers responsible for the technical development of these resources, thereby limiting its widespread adoption. Tools such as Adobe Captivate, Camtasia, Snap, Articulate, Lectora, etc., provide an easy way of developing e-contents. This exercise has triggered the idea of creating a knowledge system for an industry, namely leather industry. Digital libraries are large organized collection of digitized objects comprising of texts, images, graphs, data which in new technical terms are referred to as “Big Data”. Well-defined digital software has the potential to disseminate this information worldwide through Internet technologies. The emergence of World Wide Web makes the unprecedented volumes of data freely available to the entire society. This helps in building a domain-specific knowledge portal. The digital economy (also called the Internet economy, the new economy, or the Web economy) is an economy based on digital technologies, including communication networks (the Internet, Intranets, and Extranets), computers, software, and other related technologies. The digital infrastructures provide a global platform over which people and organizations interact, communicate, collaborate, and search for information. Creating new sources of revenue, rationalizing cost structures, enhancing the speed of technology adaptation are considered to be the three wheels of digital ecosystems. Knowledge management is about creating an environment where information can be readily shared. This information is not just the text information but also includes the data at the unit level generated out of research endeavours. Creating a learning organization culture is critical. The Web can now integrate learning and mission-critical business applications while delivering timely knowledge to each desktop. The end result is a knowledge management structure which includes an inventory of knowledge objects and a system in which these can be shared. This is an approach paper to illustrate the content development for a few aspects in leather industry, taking advantage of tools available and a portraying schematically the knowledge portal for this industry. The paper considers knowledge management system (KMS) and the IT tools for leather and allied industry and networking of academic institutes with industries to create knowledge hub and technology innovation centre using digital ecosystem eventually leading to digital transformation.",Big data analytics | Digital library | eBooks | Global higher education | Industry 4.0 | Knowledge portal | Rapid content development,1,247-272,Book Series,Book Chapter,2.0,"Anantharaman, Latha;Sridharan, M. R.",55575424500;23502238300,Central Leather Research Institute India,India,"advances in information technology have made delivering e-content easier to subject experts and to publish on the web with minimal technical skills and assistance. the development of multimedia e-learning content is no more labour-intensive process, requiring a team of web designers and developers responsible for the technical development of these resources, thereby limiting its widespread adoption. tools such as adobe captivate, camtasia, snap, articulate, lectora, etc., provide an easy way of developing e-contents. this exercise has triggered the idea of creating a knowledge system for an industry, namely leather industry. digital libraries are large organized collection of digitized objects comprising of texts, images, graphs, data which in new technical terms are referred to as “big data”. well-defined digital software has the potential to disseminate this information worldwide through internet technologies. the emergence of world wide web makes the unprecedented volumes of data freely available to the entire society. this helps in building a domain-specific knowledge portal. the digital economy (also called the internet economy, the new economy, or the web economy) is an economy based on digital technologies, including communication networks (the internet, intranets, and extranets), computers, software, and other related technologies. the digital infrastructures provide a global platform over which people and organizations interact, communicate, collaborate, and search for information. creating new sources of revenue, rationalizing cost structures, enhancing the speed of technology adaptation are considered to be the three wheels of digital ecosystems. knowledge management is about creating an environment where information can be readily shared. this information is not just the text information but also includes the data at the unit level generated out of research endeavours. creating a learning organization culture is critical. the web can now integrate learning and mission-critical business applications while delivering timely knowledge to each desktop. the end result is a knowledge management structure which includes an inventory of knowledge objects and a system in which these can be shared. this is an approach paper to illustrate the content development for a few aspects in leather industry, taking advantage of tools available and a portraying schematically the knowledge portal for this industry. the paper considers knowledge management system (kms) and the it tools for leather and allied industry and networking of academic institutes with industries to create knowledge hub and technology innovation centre using digital ecosystem eventually leading to digital transformation.",evolving an industrial digital ecosystem: a transformative case of leather industry
1034,2-s2.0-85082368550,10.14419/ijet.v7i3.2.14593,Construction of a regression test automation system,Choi I.,International Journal of Engineering and Technology(UAE),2018-01-01,"Background/Objectives: As testing plays an important role in software quality assurance, many studies are now being carried out in areas such as test method design, test case generation, test case management, GUI test automation, and integrated test automation in order to create tests that are more efficient as well as cost efficient. Methods/Statistical analysis: This paper proposes a regression test automation system that can dynamically generate test cases in the regression test stage and automatically execute the generated test scenarios Findings: The Mocha framework is extended to build an automation framework, and test algorithms and test algorithms are classified to extend and combine various test cases. Improvements/Applications: Applying the proposed system to a UI development tool test saw more than twice the test cases being automatically generated, which led to a discovery of 37% more key defects.",Data-driven | Integration test | Regression test | Test automation | Testing,0,580-584,Journal,Article,2.0,"Choi, Inhwa;Na, Wonshik",57196453558;16233987600,Namseoul University;Tomatosystem.co.LTD,South Korea;South Korea,"background/objectives: as testing plays an important role in software quality assurance, many studies are now being carried out in areas such as test method design, test case generation, test case management, gui test automation, and integrated test automation in order to create tests that are more efficient as well as cost efficient. methods/statistical analysis: this paper proposes a regression test automation system that can dynamically generate test cases in the regression test stage and automatically execute the generated test scenarios findings: the mocha framework is extended to build an automation framework, and test algorithms and test algorithms are classified to extend and combine various test cases. improvements/applications: applying the proposed system to a ui development tool test saw more than twice the test cases being automatically generated, which led to a discovery of 37% more key defects.",construction of a regression test automation system
1035,2-s2.0-85074786509,10.1016/j.procs.2019.06.037,Research and Development of Intelligent Learning Aided Software,Chen F.L.,Procedia Computer Science,2018-01-01,"With the development of modern mobile intelligent technology and the popularity of the Internet, online learning mode has been accepted widely. However, there remains many problems make the users learn in low efficiency. This paper introduces the introduction and development of intelligent learning aided teaching model. According to the problem mentioned, we analyze the relevant cases to find out the reasons and develop an intelligent learning aided software which integrates knowledge with practice based on JavaEE architecture. The software addresses the problem of learners' inefficient learning, weak hands-on ability and inability to apply the knowledge to practice which is significant to online learning's future improvement.",Knowledge Base | Recognition | Software Development | Tokenizer,0,249-255,Conference Proceeding,Conference Paper,5.0,"Chen, Fu Li;Chen, Yue Feng;Peng, Yin Qiao;Guo, Bi Feng;He, Wei Tao",57204828713;8925206600;8925206900;57204287547;57204826457,Guangdong Ocean University;School of Electronics and Information Engineering,China;China,"with the development of modern mobile intelligent technology and the popularity of the internet, online learning mode has been accepted widely. however, there remains many problems make the users learn in low efficiency. this paper introduces the introduction and development of intelligent learning aided teaching model. according to the problem mentioned, we analyze the relevant cases to find out the reasons and develop an intelligent learning aided software which integrates knowledge with practice based on javaee architecture. the software addresses the problem of learners' inefficient learning, weak hands-on ability and inability to apply the knowledge to practice which is significant to online learning's future improvement.",research and development of intelligent learning aided software
1039,2-s2.0-85069443360,10.1504/IJHPSA.2018.100712,Soft skills requirements in mobile applications development employment market,Jia J.,International Journal of High Performance Systems Architecture,2018-01-01,"The soft skills of developers have a major influence on the quality of software product and project. However, which soft skills are important for mobile applications development remains unknown. Additionally, it is necessary to examine the differences of soft skills requirements between traditional software and mobile applications development. In this article, based on text mining including word segmentation, similarity calculation and clustering analysis, we analyse lots of advertisements, and extract 13 categories of soft skills requirements for mobile applications development. We also compare the categories with those for traditional software development. We find that communication and teamwork are still the most important two soft skills. However, fast learning is more important for mobile developers, and we identified four soft skills that are not proposed before. Additionally, season has a minor impact on soft skills requirements of mobile applications development.",Cluster analysis | Employment market | Job advertisement | Mobile application development | Similarity calculation | Soft skill requirements | Text mining | Traditional software development | Word segmentation,0,127-138,Journal,Conference Paper,3.0,"Jia, Jingdong;Chen, Zupeng;Liu, Xi",57118699400;57197769566;57203890824,Beihang University,China,"the soft skills of developers have a major influence on the quality of software product and project. however, which soft skills are important for mobile applications development remains unknown. additionally, it is necessary to examine the differences of soft skills requirements between traditional software and mobile applications development. in this article, based on text mining including word segmentation, similarity calculation and clustering analysis, we analyse lots of advertisements, and extract 13 categories of soft skills requirements for mobile applications development. we also compare the categories with those for traditional software development. we find that communication and teamwork are still the most important two soft skills. however, fast learning is more important for mobile developers, and we identified four soft skills that are not proposed before. additionally, season has a minor impact on soft skills requirements of mobile applications development.",soft skills requirements in mobile applications development employment market
1040,2-s2.0-85068362362,10.7903/ijecs.1651,PErmission watcher tool: A sandbox tool-based static and dynamic analysis for android apps,Latifa E.r.,International Journal of Electronic Commerce Studies,2018-01-01,"Android security has become a very important issue with regard to mobile phone development: Android gives great freedom to developers to create and publish their apps for free in the PlayStore. The security mechanism of Android is based on an instrument that gives users the information about permissions that the application requests before installing it. This authorization system provides an overview of the application, and this can help to raise awareness of its risks. However, standard users still do not have enough information to understand clearly these requested authorizations and their implications on their security. In this article, we present a tool called “Permission watcher” that combines dynamic and static analysis. Our proposed tool allows users to install any application with only the necessary permissions instead of accepting all permissions requested or cancel the installation completely.",Applications | Permissions | Security | Tool,0,209-238,Journal,Article,2.0,"Latifa, Er rajy;My Ahmed, El Kiram",57190215961;57209654500,Université Cadi Ayyad,Morocco,"android security has become a very important issue with regard to mobile phone development: android gives great freedom to developers to create and publish their apps for free in the playstore. the security mechanism of android is based on an instrument that gives users the information about permissions that the application requests before installing it. this authorization system provides an overview of the application, and this can help to raise awareness of its risks. however, standard users still do not have enough information to understand clearly these requested authorizations and their implications on their security. in this article, we present a tool called “permission watcher” that combines dynamic and static analysis. our proposed tool allows users to install any application with only the necessary permissions instead of accepting all permissions requested or cancel the installation completely.",permission watcher tool: a sandbox tool-based static and dynamic analysis for android apps
1042,2-s2.0-85061971318,10.1016/j.procs.2018.10.004,Pharmequi: A tool to improve the clinical practice regarding pharmacotherapy and drug utilization,De Souza Cazarim M.,Procedia Computer Science,2018-01-01,"Is extremely difficult to current methods to know how much intensive is the patient's pharmacotherapy and measure it. In this context, we have developed a method that can contribute to advances in clinical practice. The main objective was making this calculation method applicable to clinical practice, becoming it feasible in a computational program/applicative. The calculation method considers the maximum doses to treat a specific disease and the doses in use by the patient to provide a calculation of a specific correction factor. The software development technologies are as follows: Bulma, for responsiveness and style, and Angular Material, for style and searches on the database of disease and medication names. The logical development of the application was set up with Typescript language and Angular 5, a framework for multi-platform development for mobile and desktop. This software, basically, have three different pages. The result page shows a table with 4 columns: patient Identification, equivalence dose (obtained from the calculation quoted above), amount of medicines and, colour's classification of the patients from the highest doses to lowest doses. The software has achieved generate responses for the pharmacological treatment of different patients for a specific disease in different therapeutic levels.",Decision support system | Drug Therapy | Medication Therapy Management | Mobile assistant system,0,20-26,Conference Proceeding,Conference Paper,6.0,"De Souza Cazarim, Maurílio;Da Silva De Oliveira, Lucas;Kobayashi, James Mineo;Apunike, Anderson Chidi;Pereira, Leonardo Régis Leira;Alves, Domingos",56516997800;57206780496;57206778390;57206777952;57200209205;7102862854,Universidade de São Paulo,Brazil,"is extremely difficult to current methods to know how much intensive is the patient's pharmacotherapy and measure it. in this context, we have developed a method that can contribute to advances in clinical practice. the main objective was making this calculation method applicable to clinical practice, becoming it feasible in a computational program/applicative. the calculation method considers the maximum doses to treat a specific disease and the doses in use by the patient to provide a calculation of a specific correction factor. the software development technologies are as follows: bulma, for responsiveness and style, and angular material, for style and searches on the database of disease and medication names. the logical development of the application was set up with typescript language and angular 5, a framework for multi-platform development for mobile and desktop. this software, basically, have three different pages. the result page shows a table with 4 columns: patient identification, equivalence dose (obtained from the calculation quoted above), amount of medicines and, colour's classification of the patients from the highest doses to lowest doses. the software has achieved generate responses for the pharmacological treatment of different patients for a specific disease in different therapeutic levels.",pharmequi: a tool to improve the clinical practice regarding pharmacotherapy and drug utilization
1044,2-s2.0-85061440762,10.14569/ijacsa.2018.090806,Programming technologies for the development of web-based platform for digital psychological tools,Nikulchev E.,International Journal of Advanced Computer Science and Applications,2018-01-01,"The choice of the tools and programming technologies for information systems creation is relevant. For every projected system, it is necessary to define a number of criteria for development environment, used libraries and technologies. The paper describes the choice of technological solutions using the example of the developed web-based platform of the Russian Academy of Education. This platform is used to provide information support for the activities of psychologists in their research (including population and longitudinal researches). There are following system features: large scale and significant amount of developing time that needs implementation and ensuring the guaranteed computing reliability of a wide range of digital tools used in psychological research; ensuring functioning in different environments when conducting mass research in schools that have different characteristics of computing resources and communication channels; possibility of services scaling; security and privacy of data; use of technologies and programming tools that would ensure the compatibility and conversion of data with other tools of psychological research processing. Some criteria were introduced for the developed system. These criteria take into account the feature of the functioning and life cycle of the software. A specific example shows the selection of appropriate technological solutions.",Choice of the tools and programming technologies | Psychological research tools | Web-based platform,7,34-45,Journal,Article,6.0,"Nikulchev, Evgeny;Ilin, Dmitry;Kolyasnikov, Pavel;Belov, Vladimir;Zakharov, Ilya;Malykh, Sergey",6504081534;57203848706;57204774687;57205752270;55570438400;6701707734,Russian Academy of Education;Russian Academy of Sciences,Russian Federation;Russian Federation,"the choice of the tools and programming technologies for information systems creation is relevant. for every projected system, it is necessary to define a number of criteria for development environment, used libraries and technologies. the paper describes the choice of technological solutions using the example of the developed web-based platform of the russian academy of education. this platform is used to provide information support for the activities of psychologists in their research (including population and longitudinal researches). there are following system features: large scale and significant amount of developing time that needs implementation and ensuring the guaranteed computing reliability of a wide range of digital tools used in psychological research; ensuring functioning in different environments when conducting mass research in schools that have different characteristics of computing resources and communication channels; possibility of services scaling; security and privacy of data; use of technologies and programming tools that would ensure the compatibility and conversion of data with other tools of psychological research processing. some criteria were introduced for the developed system. these criteria take into account the feature of the functioning and life cycle of the software. a specific example shows the selection of appropriate technological solutions.",programming technologies for the development of web-based platform for digital psychological tools
1049,2-s2.0-85059026725,10.5220/0006885401270136,Web user interface implementation technologies: An underview,Taivalsaari A.,WEBIST 2018 - Proceedings of the 14th International Conference on Web Information Systems and Technologies,2018-01-01,"Over the years, the World Wide Web has evolved from a document distribution environment into a rich development platform that can run compelling, full-fledged software applications. However, the programming capabilities of the web browser - designed originally for relatively simple scripting tasks - have evolved organically in a rather haphazard fashion. Consequently, there are many ways to build applications on the Web today. Depending on one's viewpoint, current standards-compatible web browsers support three, four or even five built-in application rendering and programming models. In this paper, we provide an”underview” of the built-in client-side web application UI implementation technologies, i.e., a summary of those rendering models that are built into the standards-compatible web browser out-of-the-box. While the dominance of the base HTML/CSS/JS technologies cannot be ignored, we foresee Web Components and WebGL gaining popularity as the world moves towards more complex and even richer web applications, including systems supporting virtual and augmented reality.",Single Page Web Applications | Web Application Architectures | Web Programming | Web Rendering | Web User Interfaces,3,127-136,Conference Proceeding,Conference Paper,4.0,"Taivalsaari, Antero;Mikkonen, Tommi;Systä, Kari;Pautasso, Cesare",6507045147;57220096141;6506558673;7801368483,Nokia Corporation;Tampere University;Università della Svizzera italiana;Helsingin Yliopisto,Finland;Finland;Switzerland;Finland,"over the years, the world wide web has evolved from a document distribution environment into a rich development platform that can run compelling, full-fledged software applications. however, the programming capabilities of the web browser - designed originally for relatively simple scripting tasks - have evolved organically in a rather haphazard fashion. consequently, there are many ways to build applications on the web today. depending on one's viewpoint, current standards-compatible web browsers support three, four or even five built-in application rendering and programming models. in this paper, we provide an”underview” of the built-in client-side web application ui implementation technologies, i.e., a summary of those rendering models that are built into the standards-compatible web browser out-of-the-box. while the dominance of the base html/css/js technologies cannot be ignored, we foresee web components and webgl gaining popularity as the world moves towards more complex and even richer web applications, including systems supporting virtual and augmented reality.",web user interface implementation technologies: an underview
1051,2-s2.0-85058985787,10.1007/978-3-030-04537-1_8,A new SCAP information and data model for content authors,Lubell J.,IFIP Advances in Information and Communication Technology,2018-01-01,"The Security Content Automation Protocol (SCAP) data model for source data stream collections standardizes the packagnt. However, no single data model can satisfy all requirements. The source data stream collection data model does not adequately meet the needs of SCAP content authors, and its implementation-specific syntax lacks the ability to express packaging subtleties critical to software developers and content authors. This chapter defines a new implementation-neutral information model that is easier to understand and does a better job at expressing relationships between objects comprising a source data stream collection. A new authoring data model for facilitating the implementation of SCAP content development software applications is derived from the information model. Also described is an application implementing the authoring data model that enables SCAP content developers to create source data stream collections using a friendly and intuitive syntax, which is then transformed into SCAP-standard-conforming content.",Data model | Information model | Security content automation protocol,0,127-146,Book Series,Conference Paper,1.0,"Lubell, Joshua",6602935643,National Institute of Standards and Technology,United States,"the security content automation protocol (scap) data model for source data stream collections standardizes the packagnt. however, no single data model can satisfy all requirements. the source data stream collection data model does not adequately meet the needs of scap content authors, and its implementation-specific syntax lacks the ability to express packaging subtleties critical to software developers and content authors. this chapter defines a new implementation-neutral information model that is easier to understand and does a better job at expressing relationships between objects comprising a source data stream collection. a new authoring data model for facilitating the implementation of scap content development software applications is derived from the information model. also described is an application implementing the authoring data model that enables scap content developers to create source data stream collections using a friendly and intuitive syntax, which is then transformed into scap-standard-conforming content.",a new scap information and data model for content authors
1052,2-s2.0-85058316836,10.1016/j.procs.2018.10.143,Return of the JS: Towards a node.js-based software architecture for combined CMS/CRM applications,Kaimer F.,Procedia Computer Science,2018-01-01,"While the use of server-side JavaScript in combination with the Node.js framework for implementing web applications is getting more and more common in practice, its implications for the evolution of web application architectures have rarely been studied in the scientific literature. In particular, the combination of components and their interplay for building pure JavaScript business applications has only rarely been investigated so far. Therefore, in this paper a software architecture for a real-world online service network application with a combined CMS/CRM functionality is presented. It is evaluated by a prototypical implementation of relevant core functionalities. Results indicate the feasibility and potential of the approach.",CMS | JavaScript | Node.js | Service Networks | Software Architecture | Web Development,4,454-459,Conference Proceeding,Conference Paper,2.0,"Kaimer, Fabian;Brune, Philipp",57205022209;49862725400,Fachhochschule Neu-Ulm,Germany,"while the use of server-side javascript in combination with the node.js framework for implementing web applications is getting more and more common in practice, its implications for the evolution of web application architectures have rarely been studied in the scientific literature. in particular, the combination of components and their interplay for building pure javascript business applications has only rarely been investigated so far. therefore, in this paper a software architecture for a real-world online service network application with a combined cms/crm functionality is presented. it is evaluated by a prototypical implementation of relevant core functionalities. results indicate the feasibility and potential of the approach.",return of the js: towards a node.js-based software architecture for combined cms/crm applications
1054,2-s2.0-85057440403,10.1007/978-3-030-04272-1_5,Recognizing Potential Runtime Types from Python Docstrings,Luo Y.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2018-01-01,"Docstring plays an important role in software development and maintanance as it is used in source code to document a specific segment of code. In dynamic language programming, docstring is usually used to annotate types of parameters and return values. Docstrings can help developers remind the expected types of a parameter, without process of comprehending the context which is time-consuming. In this study, we propose an automatic approach to recognize potential types of a parameter from its description. In our approach, we utilize feature selection to select useful features for classifier training. Then we adopt four different kinds of classifiers to recognize potential types and evaluate their performances using seven metrics. We collect a dataset of 314 type descriptions from ten prevalent Python projects. Our experimental results show that, Decision Tree classifier has the best performances among four studied classifiers, whose precision, recall, F1-score, jaccard index, hamming loss, accuracy and MRR achieve 0.681, 0.548, 0.582, 0.542, 1.234, 0.432 and 0.778 respectively. Multi-layer perceptron has the weakest performances. Futher more, we discover that the performances of four classifiers achieve their best performances when select top 20% or 40% features with the highest$$\chi ^2$$ statistic. This study archive a dataset of type descriptions and propose a framework of automatically recognizing potential types of a parameter from its description.",Decision tree | Docstring | Python | Random forest,2,68-84,Book Series,Conference Paper,5.0,"Luo, Yang;Ma, Wanwangying;Li, Yanhui;Chen, Zhifei;Chen, Lin",57202870547;56949541600;55992301500;55884919800;57189042207,Nanjing University,China,"docstring plays an important role in software development and maintanance as it is used in source code to document a specific segment of code. in dynamic language programming, docstring is usually used to annotate types of parameters and return values. docstrings can help developers remind the expected types of a parameter, without process of comprehending the context which is time-consuming. in this study, we propose an automatic approach to recognize potential types of a parameter from its description. in our approach, we utilize feature selection to select useful features for classifier training. then we adopt four different kinds of classifiers to recognize potential types and evaluate their performances using seven metrics. we collect a dataset of 314 type descriptions from ten prevalent python projects. our experimental results show that, decision tree classifier has the best performances among four studied classifiers, whose precision, recall, f1-score, jaccard index, hamming loss, accuracy and mrr achieve 0.681, 0.548, 0.582, 0.542, 1.234, 0.432 and 0.778 respectively. multi-layer perceptron has the weakest performances. futher more, we discover that the performances of four classifiers achieve their best performances when select top 20% or 40% features with the highest$$\chi ^2$$ statistic. this study archive a dataset of type descriptions and propose a framework of automatically recognizing potential types of a parameter from its description.",recognizing potential runtime types from python docstrings
1055,2-s2.0-85056858919,10.18293/SEKE2018-147,Leveraging the power of component-based development for front-end components: Insights from a study of react applications,Yang C.,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",2018-01-01,"Classic design patterns, architectural styles, and design principles have been introduced and enhanced in Web front-end development. Recently, component-based architecture, successfully introduced in React.js, has tended to replace MVC and other MVpatterns in front-end frameworks. However, we still know little about design strategies for leveraging the power of component-based development. We conducted a study to explore the use of components in React-based applications from two levels. Three private repositories were analyzed to get practical insights into the nature, limitations and potentials of CBD for front-end implementations. Our research started with an aerial view, where we examined the dependency, connectivity, and overall of components. Quite different architectural and programming styles were observed; these can be easily attributed to the lack of front-end component design paradigms. Meanwhile, all cases exhibit similar component connectivity and dependency patterns, which enlighten the study to categorize them further. Next, the study zoomed in on the architectural elements level, where we classified front-end components into four categories. Our observations suggest that design components on the architectural elements level may dramatically boost the power of component-based front-end development.",Case Study | Component-Based Development | React Framework | Web Front-End,0,578-581,Conference Proceeding,Conference Paper,4.0,"Yang, Chen;Liu, Yan;Lin, Yiwei;Yuz, Jia",56176105900;56023515500;57221091003;57204723937,Tongji University;SEEBURGER China Inc.,China;China,"classic design patterns, architectural styles, and design principles have been introduced and enhanced in web front-end development. recently, component-based architecture, successfully introduced in react.js, has tended to replace mvc and other mvpatterns in front-end frameworks. however, we still know little about design strategies for leveraging the power of component-based development. we conducted a study to explore the use of components in react-based applications from two levels. three private repositories were analyzed to get practical insights into the nature, limitations and potentials of cbd for front-end implementations. our research started with an aerial view, where we examined the dependency, connectivity, and overall of components. quite different architectural and programming styles were observed; these can be easily attributed to the lack of front-end component design paradigms. meanwhile, all cases exhibit similar component connectivity and dependency patterns, which enlighten the study to categorize them further. next, the study zoomed in on the architectural elements level, where we classified front-end components into four categories. our observations suggest that design components on the architectural elements level may dramatically boost the power of component-based front-end development.",leveraging the power of component-based development for front-end components: insights from a study of react applications
1056,2-s2.0-85055587228,10.13053/CyS-22-3-2794,Continuous testing and solutions for testing problems in continuous delivery: A systematic literature review,Mascheroni M.A.,Computacion y Sistemas,2018-01-01,"Continuous Delivery is a software development discipline where quality software is built in a way that it can be released into production at any time. However, even though instructions on how to implement it can be found in the literature, it has been challenging to put it into practice. Testing is one of these biggest challenges. On the one hand, there are several Continuous Delivery testing problems related to Continuous Delivery reported in the literature. On the other hand, some sources state that Continuous Testing is the missing element in Continuous Delivery. In this paper, we present a systematic literature review. We look at proposals, techniques, approaches, methods, frameworks, tools and solutions for testing problems. We also attempt to validate whether Continuous Testing is the missing component of Continuous Delivery by analyzing the different definitions of it and the testing stages and levels in Continuous Delivery. Finally, we look for open issues in Continuous Testing. We have found 56 articles and the results indicate that Continuous Testing is straight related to Continuous Delivery. We also describe how solutions have been proposed to face the testing problems. Lastly, we show that there are still open issues to solve.",Continuous delivery | Continuous testing | Software | Systematic literature review | Testing,3,1009-1038,Journal,Review,2.0,"Mascheroni, Maximiliano A.;Irrazábal, Emanuel",57201902874;41261568200,Universidad Nacional de La Plata;Universidad Nacional del Nordeste,Argentina;Argentina,"continuous delivery is a software development discipline where quality software is built in a way that it can be released into production at any time. however, even though instructions on how to implement it can be found in the literature, it has been challenging to put it into practice. testing is one of these biggest challenges. on the one hand, there are several continuous delivery testing problems related to continuous delivery reported in the literature. on the other hand, some sources state that continuous testing is the missing element in continuous delivery. in this paper, we present a systematic literature review. we look at proposals, techniques, approaches, methods, frameworks, tools and solutions for testing problems. we also attempt to validate whether continuous testing is the missing component of continuous delivery by analyzing the different definitions of it and the testing stages and levels in continuous delivery. finally, we look for open issues in continuous testing. we have found 56 articles and the results indicate that continuous testing is straight related to continuous delivery. we also describe how solutions have been proposed to face the testing problems. lastly, we show that there are still open issues to solve.",continuous testing and solutions for testing problems in continuous delivery: a systematic literature review
1059,2-s2.0-85054388657,10.1109/ACCESS.2018.2872812,Software Experience for an Ontology-Based Approach for the Definition of Alarms in Geographical Sensor Systems,Gonzalez E.,IEEE Access,2018-01-01,"This paper presents a system based on ontologies for the definition of alarms in sensor systems. Although we consider that the ontology and the system are interesting themselves, we have a special impact on their experience with the software tools used and the technology related to the Semantic Web. This approach is intended to illustrate the process for those readers not familiar with this field and who can consider the use of ontologies for their next developments. An ontology has been designed in the OWL language, complemented with Semantic Web Rule Language rules and search elements in the Semantic Query-enhanced Web Rule Language. The set has offered satisfactory results in simulation. Other interesting contributions of this paper are: a survey of the available literature in the field of the use of Semantic Web technologies and ontologies for the detection of events from data obtained from sensors and a study on the tools and vocabularies to be used to create a system that interfaces with ontologies and an educational method-reporting our experience-to help university students understand this topic.",Applications | decision support | education | ontology | semantic sensor network | software experience,3,55556-55572,Journal,Article,3.0,"Gonzalez, Evelio;Marichal, Roberto;Hamilton, Alberto",14022688200;6506403926;7202618817,Universidad de la Laguna,Spain,"this paper presents a system based on ontologies for the definition of alarms in sensor systems. although we consider that the ontology and the system are interesting themselves, we have a special impact on their experience with the software tools used and the technology related to the semantic web. this approach is intended to illustrate the process for those readers not familiar with this field and who can consider the use of ontologies for their next developments. an ontology has been designed in the owl language, complemented with semantic web rule language rules and search elements in the semantic query-enhanced web rule language. the set has offered satisfactory results in simulation. other interesting contributions of this paper are: a survey of the available literature in the field of the use of semantic web technologies and ontologies for the detection of events from data obtained from sensors and a study on the tools and vocabularies to be used to create a system that interfaces with ontologies and an educational method-reporting our experience-to help university students understand this topic.",software experience for an ontology-based approach for the definition of alarms in geographical sensor systems
1063,2-s2.0-85052865350,10.1016/j.promfg.2018.03.161,Holistic approach for teaching IT skills in a production environment,Block C.,Procedia Manufacturing,2018-01-01,"Increasing digitalization of manufacturing leads to new competence requirements for mechanical engineers. In recent years, learning factories have proven to be the ideal learning concept for acquiring skills. However, the teaching of IT skills is missing in the current training courses. Therefore, this paper will present a holistic approach in form of a learning factory module, starting from the conception and development right up to the operation of a Cyber-Physical-Systems (CPS) in the production environment. Within the training module, the participants will have to develop a Cyber-Physical-Production-System (CPPS) for an assembly line. The participants are trained how to select the hardware and software components for a modular, decentralized and transferable solution in four consecutive learning units. In each unit, the selected technologies will be combined to a web-technology-based prototype, which is then tested in the real world environment of the LPS-learning factory.",Cyber Physical Production System | Digital Competence | IT Skills | Web Technology,13,57-62,Conference Proceeding,Conference Paper,3.0,"Block, Christian;Kreimeier, Dieter;Kuhlenkötter, Bernd",57193666334;36521318900;7801348331,Ruhr-Universitat Bochum,Germany,"increasing digitalization of manufacturing leads to new competence requirements for mechanical engineers. in recent years, learning factories have proven to be the ideal learning concept for acquiring skills. however, the teaching of it skills is missing in the current training courses. therefore, this paper will present a holistic approach in form of a learning factory module, starting from the conception and development right up to the operation of a cyber-physical-systems (cps) in the production environment. within the training module, the participants will have to develop a cyber-physical-production-system (cpps) for an assembly line. the participants are trained how to select the hardware and software components for a modular, decentralized and transferable solution in four consecutive learning units. in each unit, the selected technologies will be combined to a web-technology-based prototype, which is then tested in the real world environment of the lps-learning factory.",holistic approach for teaching it skills in a production environment
1064,2-s2.0-85051424892,10.1504/IJCSE.2018.093783,A dataflow platform for applications based on Linked Data,Ceriani M.,International Journal of Computational Science and Engineering,2018-01-01,"Modern software applications increasingly benefit from accessing the multifarious and heterogeneous Web of Data, thanks to the use of web APIs and Linked Data principles. In previous work, the authors proposed a platform to develop applications consuming Linked Data in a declarative and modular way. This paper describes in detail the functional language the platform gives access to, which is based on SPARQL (the standard query language for Linked Data) and on the dataflow paradigm. The language features interactive and meta-programming capabilities so that complex modules/applications can be developed. By adopting a declarative style, it favours the development of modules that can be reused in various specific execution contexts.",Dataflow | Declarative programming | Linked data | RDF | Semantic web | SPARQL,1,419-429,Journal,Article,2.0,"Ceriani, Miguel;Bottoni, Paolo",55787561400;7006566346,Sapienza Università di Roma,Italy,"modern software applications increasingly benefit from accessing the multifarious and heterogeneous web of data, thanks to the use of web apis and linked data principles. in previous work, the authors proposed a platform to develop applications consuming linked data in a declarative and modular way. this paper describes in detail the functional language the platform gives access to, which is based on sparql (the standard query language for linked data) and on the dataflow paradigm. the language features interactive and meta-programming capabilities so that complex modules/applications can be developed. by adopting a declarative style, it favours the development of modules that can be reused in various specific execution contexts.",a dataflow platform for applications based on linked data
1066,2-s2.0-85050585076,10.1007/978-3-319-91470-1_18,WebBCI: An electroencephalography toolkit built on modern web technologies,Stegman P.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2018-01-01,"Recent advances in electroencephalography (EEG) based brain-computer interfaces (BCIs) have led to applications that allow users to control devices such as wheelchairs, prosthetic arms, drones, and gaming systems using cognitive commands. However, software environments used to create these technologies are often designed for expert developers. This research paper investigates the feasibility of JavaScript as a development platform for non-critical BCI systems. We also discuss the current issues with JavaScript-based BCIs and introduce a new library, WebBCI, which is designed to take the initial step towards addressing these issues. Initial benchmarks of WebBCI suggest JavaScript can run common EEG and BCI methods such as band power extraction, common spatial pattern, and linear discriminant analysis in real-time on an array of devices, including mobile phones.",Brain-computer interface (BCI) | Electroencephalography (EEG) | JavaScript,6,212-221,Book Series,Conference Paper,3.0,"Stegman, Pierce;Crawford, Chris;Gray, Jeff",57203124642;56900631800;13105983500,The University of Alabama,United States,"recent advances in electroencephalography (eeg) based brain-computer interfaces (bcis) have led to applications that allow users to control devices such as wheelchairs, prosthetic arms, drones, and gaming systems using cognitive commands. however, software environments used to create these technologies are often designed for expert developers. this research paper investigates the feasibility of javascript as a development platform for non-critical bci systems. we also discuss the current issues with javascript-based bcis and introduce a new library, webbci, which is designed to take the initial step towards addressing these issues. initial benchmarks of webbci suggest javascript can run common eeg and bci methods such as band power extraction, common spatial pattern, and linear discriminant analysis in real-time on an array of devices, including mobile phones.",webbci: an electroencephalography toolkit built on modern web technologies
1067,2-s2.0-85050340410,10.1007/978-3-319-95270-3_37,"Write-once, transpile-everywhere: Re-using motion controllers of virtual humans across multiple game engines",Nunnari F.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2018-01-01,"Transpilation allows to write code once and re-use it across multiple runtime environments. In this paper, we propose a software development practice to implement once the motion controllers of virtual humans and re-use the implementation in multiple game engines. In a case study, three common human behaviors – blinking, text-to-speech, and eye-gaze – were developed in the Haxe programming language and deployed in the free, open-source Blender Game Engine and the commercial Unity engine. Performance tests show that transpiled code executes within 67% faster to 127% slower with respect to an implementation manually written in the game engine target languages.",Haxe | Motion controller | Software architecture | Transpilation | Virtual humans,2,435-446,Book Series,Conference Paper,2.0,"Nunnari, Fabrizio;Heloir, Alexis",17346466000;56295327800,LAMIH;German Research Center for Artificial Intelligence (DFKI),France;Germany,"transpilation allows to write code once and re-use it across multiple runtime environments. in this paper, we propose a software development practice to implement once the motion controllers of virtual humans and re-use the implementation in multiple game engines. in a case study, three common human behaviors – blinking, text-to-speech, and eye-gaze – were developed in the haxe programming language and deployed in the free, open-source blender game engine and the commercial unity engine. performance tests show that transpiled code executes within 67% faster to 127% slower with respect to an implementation manually written in the game engine target languages.","write-once, transpile-everywhere: re-using motion controllers of virtual humans across multiple game engines"
1068,2-s2.0-85049526486,10.3923/jeasci.2018.2322.2329,Generating test cases for model-based testing and detecting deadlocks using Tarjan's Algorithm,Salman Y.,Journal of Engineering and Applied Sciences,2018-01-01,"Test case generation is a task that greatly affects software testing. Model-Based Testing (MBT) has gained a significant role in generating test cases in recent years. Recent studies have also begun to generate executable test cases from Unified Modelling Language (UML). As a major issue in system execution, a model must recognize and identify deadlocks in the early stage of system testing. The current studies did not take into consideration deadlock detection also did not fulfil adequate coverage criteria. This study proposes an automated method for generating test cases from UML state chart diagrams that can help detect deadlocks during the design phase. These test cases are generated following specified coverage criteria. This method begins by converting the UML state chart diagram into an intermediate table and graph where the deadlocks are marked. The test path and cases are generated afterward. The generated test cases are deemed suitable for identifying faults and deadlocks in the early phase of software development.",Deadlock detection | Generation | Model-based testing | Recognize | Software testing | UML statechart dagram,0,2322-2329,Journal,Article,5.0,"Salman, Yasir Dawood;Hashim, Nor Laily;Rejab, Mawarny Md;Romli, Rohaida;Mohd, Haslina",57076387200;16052739400;56286310600;36609124000;49964035900,Universiti Utara Malaysia,Malaysia,"test case generation is a task that greatly affects software testing. model-based testing (mbt) has gained a significant role in generating test cases in recent years. recent studies have also begun to generate executable test cases from unified modelling language (uml). as a major issue in system execution, a model must recognize and identify deadlocks in the early stage of system testing. the current studies did not take into consideration deadlock detection also did not fulfil adequate coverage criteria. this study proposes an automated method for generating test cases from uml state chart diagrams that can help detect deadlocks during the design phase. these test cases are generated following specified coverage criteria. this method begins by converting the uml state chart diagram into an intermediate table and graph where the deadlocks are marked. the test path and cases are generated afterward. the generated test cases are deemed suitable for identifying faults and deadlocks in the early phase of software development.",generating test cases for model-based testing and detecting deadlocks using tarjan's algorithm
1070,2-s2.0-85049365798,10.1007/978-3-319-93527-0_2,Return of the great Spaghetti monster: Learnings from a twelve-year adventure in web software development,Taivalsaari A.,Lecture Notes in Business Information Processing,2018-01-01,"The widespread adoption of the World Wide Web has fundamentally changed the landscape of software development. Only ten years ago, very few developers would write software for the Web, let alone consider using JavaScript or other web technologies for writing any serious software applications. In this paper, we reflect upon a twelve-year adventure in web development that began with the development of the Lively Kernel system at Sun Microsystems Labs in 2006. Back then, we also published some papers that identified important challenges in web-based software development based on established software engineering principles. We will revisit our earlier findings and compare the state of the art in web development today to our earlier learnings, followed by some reflections and suggestions for the road forward.",HTML5 | IoT | JavaScript | Programmable world | Software engineering | The internet of things | Web applications | Web engineering | Web programming,1,21-44,Book Series,Conference Paper,2.0,"Taivalsaari, Antero;Mikkonen, Tommi",6507045147;57220096141,Nokia Corporation;Helsingin Yliopisto,Finland;Finland,"the widespread adoption of the world wide web has fundamentally changed the landscape of software development. only ten years ago, very few developers would write software for the web, let alone consider using javascript or other web technologies for writing any serious software applications. in this paper, we reflect upon a twelve-year adventure in web development that began with the development of the lively kernel system at sun microsystems labs in 2006. back then, we also published some papers that identified important challenges in web-based software development based on established software engineering principles. we will revisit our earlier findings and compare the state of the art in web development today to our earlier learnings, followed by some reflections and suggestions for the road forward.",return of the great spaghetti monster: learnings from a twelve-year adventure in web software development
1071,2-s2.0-85049081380,10.1016/j.procs.2018.05.028,Analysis and Visualisation of Geo-Referenced Tweets for Real-Time Information Diffusion,Puri A.,Procedia Computer Science,2018-01-01,"This paper focuses on techniques that can model information diffusion by the development of a prototype - a web application based on a JavaScript Web-client and a Java Enterprise Edition server. The motive is to use a distributed system, instead of a standalone/monolithic system, to present a new and unique way to visualise the data available through twitter, and analyze it to extract useful information. The prototype processes real-time data in the data stream with corresponding high processing speed and suitable communication patterns, with the use of hashtags to define the type of information to be analysed.",Hashtag | Information Diffusion | Prediction | Social Media | Tweets | Twitter | Visualisation,2,1138-1146,Conference Proceeding,Conference Paper,3.0,"Puri, Akhil;Arora, Pallavi;Sardana, Neetu",57202707543;57202709787;37007854100,Jaypee Institute of Information Technology,India,"this paper focuses on techniques that can model information diffusion by the development of a prototype - a web application based on a javascript web-client and a java enterprise edition server. the motive is to use a distributed system, instead of a standalone/monolithic system, to present a new and unique way to visualise the data available through twitter, and analyze it to extract useful information. the prototype processes real-time data in the data stream with corresponding high processing speed and suitable communication patterns, with the use of hashtags to define the type of information to be analysed.",analysis and visualisation of geo-referenced tweets for real-time information diffusion
1072,2-s2.0-85048962158,10.1007/978-3-319-91638-5_16,Digital construction permit: A round trip between GIS and IFC,Chognard S.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2018-01-01,"Building design and surrounding environment are influencing each other. Environment is usually described by a Geographic Information System (GIS), while buildings are often designed with Building Information Modeling (BIM) software. Despite some differences on technology and standards, GIS and BIM deal with geometrical data and attributes. Possible links between GIS and BIM using the City Geographic Markup Language (CityGML) and the Industry Foundation Classes (IFC) as standard exchange formats have been studied [1–4]. The present work establishes an exchange between IFC and GIS features. As an open format, IFC files can be handled by AEC-related software. It is therefore of interest, if IFC can be used for a roundtrip between GIS and BIM. A three-step translation protocol has been developed and tested: (1) Data from GIS had to be transformed into an IFC reference environment model. (2) A test building has been designed. Imported environmental elements have been edited as well. (3) The exported IFC file was then imported into GIS data sets in order to update existing data. The process employed the FME software to convert GIS to IFC and back. Data management tasks have been delegated to a database complying with the IFC format (BIMserver). The accurate import and export of data has been monitored over the entire data exchange process. This study uses the development of a digital construction permit submission procedure for the canton of Geneva in Switzerland.",BIM | Convergence of GIS and BIM | Digital building permit | GIS | GIS-BIM round trip | IFC,6,287-306,Book Series,Conference Paper,5.0,"Chognard, Sébastien;Dubois, Alain;Benmansour, Yacine;Torri, Elie;Domer, Bernd",57202647946;57202642472;57202644012;57202639993;56431141000,HEPIA,Switzerland,"building design and surrounding environment are influencing each other. environment is usually described by a geographic information system (gis), while buildings are often designed with building information modeling (bim) software. despite some differences on technology and standards, gis and bim deal with geometrical data and attributes. possible links between gis and bim using the city geographic markup language (citygml) and the industry foundation classes (ifc) as standard exchange formats have been studied [1–4]. the present work establishes an exchange between ifc and gis features. as an open format, ifc files can be handled by aec-related software. it is therefore of interest, if ifc can be used for a roundtrip between gis and bim. a three-step translation protocol has been developed and tested: (1) data from gis had to be transformed into an ifc reference environment model. (2) a test building has been designed. imported environmental elements have been edited as well. (3) the exported ifc file was then imported into gis data sets in order to update existing data. the process employed the fme software to convert gis to ifc and back. data management tasks have been delegated to a database complying with the ifc format (bimserver). the accurate import and export of data has been monitored over the entire data exchange process. this study uses the development of a digital construction permit submission procedure for the canton of geneva in switzerland.",digital construction permit: a round trip between gis and ifc
1073,2-s2.0-85048743861,10.1016/j.ifacol.2018.06.083,ODYSC: A responsive educational web app for dynamics and control,Dekemele K.,IFAC-PapersOnLine,2018-01-01,"The Online Dynamical Systems and Control (ODYSC) web application has been developed for the introductory dynamics and control courses taught to engineers and business engineering of Ghent university, accessible through http://www.odysc.ugent.be/. Generally speaking, the advantage of web apps over conventional software is the compatibility between operating system (OS) and devices, as only a browser is required. Recently, students bring a mobile phone to lectures. While these are often used by the students themselves as a distraction, they are actually very powerful computers capable of performing simulations of dynamical systems. Because of this, ODYSC has been designed to be responsive, working equally well on both mobile phone as on a laptop or PC. While ODYSC can serve as a distance learning tool, it can also be employed during classical lectures. While the teacher explains new concepts in dynamics or control, these can immediately be made clear through simulations on the student's phone. Before, the amount of students attending these courses were a practical limitation for organizing computer labs. Even if such infrastructure exists, the software used requires the students to code in a new language, which they are often not motivated enough to do for a single lab, or the software is associated with costly or complicated licensing. ODYSC requires no special infrastructure but a device with a browser which students themselves bring anyway. ODYSC is still in full development and for now can perform open loop and closed loop simulations on LTI systems, and plot bode plots of the system.",computer software | control education | mobile | responsive | web application,3,310-315,Conference Proceeding,Conference Paper,3.0,"Dekemele, Kevin;Chevalier, Amélie;Loccufier, Mia",57193576545;55876755000;6602800233,Universiteit Gent,Belgium,"the online dynamical systems and control (odysc) web application has been developed for the introductory dynamics and control courses taught to engineers and business engineering of ghent university, accessible through http://www.odysc.ugent.be/. generally speaking, the advantage of web apps over conventional software is the compatibility between operating system (os) and devices, as only a browser is required. recently, students bring a mobile phone to lectures. while these are often used by the students themselves as a distraction, they are actually very powerful computers capable of performing simulations of dynamical systems. because of this, odysc has been designed to be responsive, working equally well on both mobile phone as on a laptop or pc. while odysc can serve as a distance learning tool, it can also be employed during classical lectures. while the teacher explains new concepts in dynamics or control, these can immediately be made clear through simulations on the student's phone. before, the amount of students attending these courses were a practical limitation for organizing computer labs. even if such infrastructure exists, the software used requires the students to code in a new language, which they are often not motivated enough to do for a single lab, or the software is associated with costly or complicated licensing. odysc requires no special infrastructure but a device with a browser which students themselves bring anyway. odysc is still in full development and for now can perform open loop and closed loop simulations on lti systems, and plot bode plots of the system.",odysc: a responsive educational web app for dynamics and control
1075,2-s2.0-85047135077,10.1007/978-3-319-90421-4_6,An Empirical Analysis of Technical Lag in npm Package Dependencies,Zerouali A.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2018-01-01,"Software library packages are constantly evolving and increasing in number. Not updating to the latest available release of dependent libraries may negatively affect software development by not benefiting from new functionality, vulnerability and bug fixes available in more recent versions. On the other hand, automatically updating to the latest release may introduce incompatibility issues. We introduce a technical lag metric for dependencies in package networks, in order to assess how outdated a software package is compared to the latest available releases of its dependencies. We empirically analyse the package update practices and technical lag for the npm distribution of JavaScript packages. Our results show a strong presence of technical lag caused by the specific use of dependency constraints, indicating a reluctance to update dependencies to avoid backward incompatible changes.",npm | Package dependency | Software library | Technical lag,34,95-110,Book Series,Conference Paper,5.0,"Zerouali, Ahmed;Constantinou, Eleni;Mens, Tom;Robles, Gregorio;González-Barahona, Jesús",57194046807;54396822200;6701719612;8286496000;57201694910,Universidad Rey Juan Carlos;Université de Mons,Spain;Belgium,"software library packages are constantly evolving and increasing in number. not updating to the latest available release of dependent libraries may negatively affect software development by not benefiting from new functionality, vulnerability and bug fixes available in more recent versions. on the other hand, automatically updating to the latest release may introduce incompatibility issues. we introduce a technical lag metric for dependencies in package networks, in order to assess how outdated a software package is compared to the latest available releases of its dependencies. we empirically analyse the package update practices and technical lag for the npm distribution of javascript packages. our results show a strong presence of technical lag caused by the specific use of dependency constraints, indicating a reluctance to update dependencies to avoid backward incompatible changes.",an empirical analysis of technical lag in npm package dependencies
1076,2-s2.0-85045852782,10.1007/978-3-319-77028-4_100,Software Architecture for In-House Development of a Student Web Portal for Higher Education Institution in Kazakhstan,Boranbayev A.,Advances in Intelligent Systems and Computing,2018-01-01,"The students’ portal is a student management information system developed in-house for higher education institution in Kazakhstan. It represents a major part among university information systems. This paper reviews the common features of the general portal structure. The architecture of the new students’ portal framework is presented (Boranbayev, Nonlinear Anal. 71:1633–1637, 2009). It consists of a web application developed for the university, dedicated for students and staff members of the department of Student Affairs. It was developed in the last 6 years with such technologies like IBM WebSphere, Java EJB, JavaScript, HTML, and Oracle Database. The university’s system designers and application development team constantly work on enhancing and improving it. The software architecture of the developed portal is shared among various web applications at the university (Boranbayev and Boranbayev, Development and optimization of information systems for health insurance billing. Seventh International Conference on Information Technology: New Generations (ITNG 2010), Las Vegas, Nevada, USA, 2010, pp. 1282–1284). This architecture and experience may be used by various development teams developing local applications for universities, either in-house or with the help of suppliers and vendors. In addition, the paper discusses how the students’ portal components were developed. The research contributes towards the higher education field worldwide by providing a solution that could be followed for building university portals with various components.",Computer architecture | Information system | Portals | Software development | Software framework | Web application,6,759-760,Book Series,Conference Paper,3.0,"Boranbayev, Askar;Baidyussenov, Ruslan;Mazhitov, Mikhail",26040482100;57201704632;7801548346,Nazarbayev University,Kazakhstan,"the students’ portal is a student management information system developed in-house for higher education institution in kazakhstan. it represents a major part among university information systems. this paper reviews the common features of the general portal structure. the architecture of the new students’ portal framework is presented (boranbayev, nonlinear anal. 71:1633–1637, 2009). it consists of a web application developed for the university, dedicated for students and staff members of the department of student affairs. it was developed in the last 6 years with such technologies like ibm websphere, java ejb, javascript, html, and oracle database. the university’s system designers and application development team constantly work on enhancing and improving it. the software architecture of the developed portal is shared among various web applications at the university (boranbayev and boranbayev, development and optimization of information systems for health insurance billing. seventh international conference on information technology: new generations (itng 2010), las vegas, nevada, usa, 2010, pp. 1282–1284). this architecture and experience may be used by various development teams developing local applications for universities, either in-house or with the help of suppliers and vendors. in addition, the paper discusses how the students’ portal components were developed. the research contributes towards the higher education field worldwide by providing a solution that could be followed for building university portals with various components.",software architecture for in-house development of a student web portal for higher education institution in kazakhstan
1078,2-s2.0-85045344841,10.1007/978-3-319-77712-2_93,Generation of test samples for construction of dashboard design guidelines: Impact of color on layout balance,Pastushenko O.,Advances in Intelligent Systems and Computing,2018-01-01,"The metric-based evaluation of user interfaces is a promising way to quickly evaluate their usability and other various design aspects. However, development of such metrics usually requires a sufficiently large training set of realistic-looking user interface samples, which might not be always easy to find. This paper describes a workflow of the preparation of such samples. It presents a configurable generator based on the composition of simple widgets into a screen according to a predefined model. It also describes a reusable library for simple creation of widgets using capabilities of the JavaScript framework Vue.js. The application of the implemented generator is then demonstrated on the generation of dashboard samples which are used to show the significance of color in the measuring of the layout balance.",Aesthetics | Dashboard | Generator | Usability guidelines | User testing,6,980-990,Book Series,Conference Paper,3.0,"Pastushenko, Olena;Hynek, Jiří;Hruška, Tomáš",57201580474;57190976133;24450794800,"Brno University of Technology, Faculty of Information Technology",Czech Republic,"the metric-based evaluation of user interfaces is a promising way to quickly evaluate their usability and other various design aspects. however, development of such metrics usually requires a sufficiently large training set of realistic-looking user interface samples, which might not be always easy to find. this paper describes a workflow of the preparation of such samples. it presents a configurable generator based on the composition of simple widgets into a screen according to a predefined model. it also describes a reusable library for simple creation of widgets using capabilities of the javascript framework vue.js. the application of the implemented generator is then demonstrated on the generation of dashboard samples which are used to show the significance of color in the measuring of the layout balance.",generation of test samples for construction of dashboard design guidelines: impact of color on layout balance
1079,2-s2.0-85044451365,10.1007/978-3-319-67925-9_12,Extending the sana mobile healthcare platform with features providing ecg analysis,Tsampi K.,Lecture Notes on Data Engineering and Communications Technologies,2018-01-01,"The great development of technology recently provides innovations that improve everyday life. The major benefit of it is that medicine is also affected, so better healthcare can be provided. In that context, it can be critical for patients who suffer from chronic heart diseases to have in their availability a system that can monitor and analyse their electrocardiogram (ECG) displaying either normal or abnormal findings. The current chapter describes such a system that uploads, stores, processes and displays an ECG, calculating certain ECG findings necessary for doctors to make a diagnosis. To this end, the SANA mobile healthcare platform, with its OpenMRS open source enterprise electronic medical record system, has been chosen and extended in this work for storing, processing and displaying the ECG data. OpenMRS provides a user-friendly interface and a database for collecting medical big data. Analysis of ECG signals is leveraged by the Physionet toolkit. Physionet contains many ECG databases and the WFDB software for processing ECG signals. According to the scenario we have processed, an ECG is uploaded onto OpenMRS platform using a mobile device or any other Internet-enabled device and is stored in the database that OpenMRS uses. Then, ECG signal is filtered using a finite impulse response (FIR) filter to remove noise and using WFDB functions it is processed so certain intervals are determined. Finally, with the appropriate algorithms specific ECG findings are calculated. When the procedure completes, the results are stored into the database using SQL Queries. Using an HTML Form results and graphs are integrated into the OpenMRS website highlighting abnormal values with red color. Authorized users can have access to this information through any web browser.",Big data | ECG signal processing | Electrocardiogram | Healthcare applications | OpenMRS platform,4,289-321,Book Series,Book Chapter,9.0,"Tsampi, Katerina;Panagiotakis, Spyros;Hatzakis, Elias;Lakiotakis, Emmanouil;Atsali, Georgia;Vassilakis, Kostas;Mastorakis, George;Mavromoustakis, Constandinos X.;Malamos, Athanasios",57218830270;57131428900;57218831330;57195962944;57191251408;6508325225;13205568300;6602882785;6602688227,University of Nicosia;Hellenic Mediterranean University;Foundation for Research and Technology-Hellas,Cyprus;Greece;Greece,"the great development of technology recently provides innovations that improve everyday life. the major benefit of it is that medicine is also affected, so better healthcare can be provided. in that context, it can be critical for patients who suffer from chronic heart diseases to have in their availability a system that can monitor and analyse their electrocardiogram (ecg) displaying either normal or abnormal findings. the current chapter describes such a system that uploads, stores, processes and displays an ecg, calculating certain ecg findings necessary for doctors to make a diagnosis. to this end, the sana mobile healthcare platform, with its openmrs open source enterprise electronic medical record system, has been chosen and extended in this work for storing, processing and displaying the ecg data. openmrs provides a user-friendly interface and a database for collecting medical big data. analysis of ecg signals is leveraged by the physionet toolkit. physionet contains many ecg databases and the wfdb software for processing ecg signals. according to the scenario we have processed, an ecg is uploaded onto openmrs platform using a mobile device or any other internet-enabled device and is stored in the database that openmrs uses. then, ecg signal is filtered using a finite impulse response (fir) filter to remove noise and using wfdb functions it is processed so certain intervals are determined. finally, with the appropriate algorithms specific ecg findings are calculated. when the procedure completes, the results are stored into the database using sql queries. using an html form results and graphs are integrated into the openmrs website highlighting abnormal values with red color. authorized users can have access to this information through any web browser.",extending the sana mobile healthcare platform with features providing ecg analysis
1081,2-s2.0-85041611895,10.1107/S2059798317014565,Distributed computing for macromolecular crystallography,Krissinel E.,Acta Crystallographica Section D: Structural Biology,2018-01-01,"Modern crystallographic computing is characterized by the growing role of automated structure-solution pipelines, which represent complex expert systems utilizing a number of program components, decision makers and databases. They also require considerable computational resources and regular database maintenance, which is increasingly more difficult to provide at the level of individual desktop-based CCP4 setups. On the other hand, there is a significant growth in data processed in the field, which brings up the issue of centralized facilities for keeping both the data collected and structure-solution projects. The paradigm of distributed computing and data management offers a convenient approach to tackling these problems, which has become more attractive in recent years owing to the popularity of mobile devices such as tablets and ultra-portable laptops. In this article, an overview is given of developments by CCP4 aimed at bringing distributed crystallographic computations to a wide crystallographic community.",computational cloud | crystallographic computing | data and project management | distributed computing | web services,26,143-151,Journal,Article,5.0,"Krissinel, Evgeny;Uski, Ville;Lebedev, Andrey;Winn, Martyn;Ballard, Charles",6701912238;57200542527;55415462800;57203031960;7101938605,Rutherford Appleton Laboratory,United Kingdom,"modern crystallographic computing is characterized by the growing role of automated structure-solution pipelines, which represent complex expert systems utilizing a number of program components, decision makers and databases. they also require considerable computational resources and regular database maintenance, which is increasingly more difficult to provide at the level of individual desktop-based ccp4 setups. on the other hand, there is a significant growth in data processed in the field, which brings up the issue of centralized facilities for keeping both the data collected and structure-solution projects. the paradigm of distributed computing and data management offers a convenient approach to tackling these problems, which has become more attractive in recent years owing to the popularity of mobile devices such as tablets and ultra-portable laptops. in this article, an overview is given of developments by ccp4 aimed at bringing distributed crystallographic computations to a wide crystallographic community.",distributed computing for macromolecular crystallography
1083,2-s2.0-85040248766,10.1007/978-3-319-73353-1_15,Model-R: A framework for scalable and reproducible ecological niche modeling,Sánchez-Tapia A.,Communications in Computer and Information Science,2018-01-01,"Spatial analysis tools and synthesis of results are key to identifying the best solutions in biodiversity conservation. The importance of process automation is associated with increased efficiency and performance both in the data pre-processing phase and in the post-analysis of the results generated by the packages and modeling programs. The Model-R framework was developed with the main objective of unifying pre-existing ecological niche modeling tools into a common framework and building a web interface that automates steps of the modeling process and occurrence data retrieval. The web interface includes RJabot, a functionality that allows for searching and retrieving occurrence data from Jabot, the main reference on botanical collections management system in Brazil. It returns data in a suitable format to be consumed by other components of the framework. Currently, the tools are multi-projection, they can thus be applied to different sets of temporal and spatial data. Model-R is also multi-algorithm, with seven algorithms available for modeling: BIOCLIM, Mahalanobis distance, Maxent, GLM, RandomForest, SVM, and DOMAIN. The algorithms as well as the entire modeling process may be parametrized using command-line tools or through the web interface. We hope that the use of this application, not only by modeling specialists but also as a tool for policy makers, will be a significant contribution to the continuous development of biodiversity conservation analysis. The Model-R web interface can be installed locally or on a server. A software container is provided to automate the installation.",Ecological niche modeling | Provenance | Scalability | Science gateways | Species distribution modeling,12,218-232,Book Series,Conference Paper,8.0,"Sánchez-Tapia, Andrea;de Siqueira, Marinez Ferreira;Lima, Rafael Oliveira;Barros, Felipe Sodré M.;Gall, Guilherme M.;Gadelha, Luiz M.R.;da Silva, Luís Alexandre E.;Osthoff, Carla",55175631500;8157538700;57194617569;57191166176;57200212589;24921373000;36801267600;35615325700,"Laboratorio Nacional de Computacao Cientifica, Petropolis;International Institute for Sustainability;Rio de Janeiro Botanical Garden",Brazil;Brazil;Brazil,"spatial analysis tools and synthesis of results are key to identifying the best solutions in biodiversity conservation. the importance of process automation is associated with increased efficiency and performance both in the data pre-processing phase and in the post-analysis of the results generated by the packages and modeling programs. the model-r framework was developed with the main objective of unifying pre-existing ecological niche modeling tools into a common framework and building a web interface that automates steps of the modeling process and occurrence data retrieval. the web interface includes rjabot, a functionality that allows for searching and retrieving occurrence data from jabot, the main reference on botanical collections management system in brazil. it returns data in a suitable format to be consumed by other components of the framework. currently, the tools are multi-projection, they can thus be applied to different sets of temporal and spatial data. model-r is also multi-algorithm, with seven algorithms available for modeling: bioclim, mahalanobis distance, maxent, glm, randomforest, svm, and domain. the algorithms as well as the entire modeling process may be parametrized using command-line tools or through the web interface. we hope that the use of this application, not only by modeling specialists but also as a tool for policy makers, will be a significant contribution to the continuous development of biodiversity conservation analysis. the model-r web interface can be installed locally or on a server. a software container is provided to automate the installation.",model-r: a framework for scalable and reproducible ecological niche modeling
1084,2-s2.0-85048319697,10.1109/SPW.2017.38,Lua Code: Security overview and practical approaches to static analysis,Costin A.,"Proceedings - 2017 IEEE Symposium on Security and Privacy Workshops, SPW 2017",2017-12-19,"Lua is an interpreted, cross-platform, embeddable, performant and low-footprint language. Lua's popularity is on the rise in the last couple of years. Simple design and efficient usage of resources combined with its performance make it attractive for production web applications even to big organizations such as Wikipedia, CloudFlare and GitHub. In addition to this, Lua is one of the preferred choices for programming embedded and IoT devices. This context allows to assume a large and growing Lua codebase yet to be assessed. This growing Lua codebase could be potentially driving production servers and extremely large number of devices, some perhaps with mission-critical function for example in automotive or home-automation domains. However, there is a substantial and obvious lack of static analysis tools and vulnerable code corpora for Lua as compared to other increasingly popular languages, such as PHP, Python and JavaScript. Even the state-of-the-art commercial tools that support dozens of languages and technologies actually do not support Lua static code analysis. In this paper we present the first public Static Analysis for Security Testing (SAST) tool for Lua code that is currently focused on web vulnerabilities. We show its potential with good and promising preliminary results that we obtained on simple and intentionally vulnerable Lua code samples that we synthesized for our experiments. We also present and release our synthesized corpus of intentionally vulnerable Lua code, as well as the testing setups used in our experiments in form of virtual and completely reproducible environments. We hope our work can spark additional and renewed interest in this apparently overlooked area of language security and static analysis, as well as motivate community's contribution to these open-source projects. The tool, the samples and the testing VM setups will be released and updated at http://lua.re and http://lua.rocks.",Lua | parsing | security analysis | software development lifecycle | static analysis | syntax tree | tainting | vulnerability detection,7,132-142,Conference Proceeding,Conference Paper,1.0,"Costin, Andrei",55831338100,University of Jyväskylä;Firmware.RE,Finland;Finland,"lua is an interpreted, cross-platform, embeddable, performant and low-footprint language. lua's popularity is on the rise in the last couple of years. simple design and efficient usage of resources combined with its performance make it attractive for production web applications even to big organizations such as wikipedia, cloudflare and github. in addition to this, lua is one of the preferred choices for programming embedded and iot devices. this context allows to assume a large and growing lua codebase yet to be assessed. this growing lua codebase could be potentially driving production servers and extremely large number of devices, some perhaps with mission-critical function for example in automotive or home-automation domains. however, there is a substantial and obvious lack of static analysis tools and vulnerable code corpora for lua as compared to other increasingly popular languages, such as php, python and javascript. even the state-of-the-art commercial tools that support dozens of languages and technologies actually do not support lua static code analysis. in this paper we present the first public static analysis for security testing (sast) tool for lua code that is currently focused on web vulnerabilities. we show its potential with good and promising preliminary results that we obtained on simple and intentionally vulnerable lua code samples that we synthesized for our experiments. we also present and release our synthesized corpus of intentionally vulnerable lua code, as well as the testing setups used in our experiments in form of virtual and completely reproducible environments. we hope our work can spark additional and renewed interest in this apparently overlooked area of language security and static analysis, as well as motivate community's contribution to these open-source projects. the tool, the samples and the testing vm setups will be released and updated at http://lua.re and http://lua.rocks.",lua code: security overview and practical approaches to static analysis
1085,2-s2.0-85042919503,10.1109/CHILECON.2017.8229583,Design and implementation of explorer mobile robot controlled remotely using IoT technology,Marroquin A.,"2017 CHILEAN Conference on Electrical, Electronics Engineering, Information and Communication Technologies, CHILECON 2017 - Proceedings",2017-12-19,"The continuous development of Internet of Things brings new tools in different areas of robotics, for example in the robotics of services. This document presents a low-cost alternative for a mobile explorer robot that uses open hardware and software, whose design is intended to incorporate cameras, sensors and other peripherals to be able to inspect its environment in addition to being controlled remotely using the Internet technologies of the Things. For the first prototype, a camera and a temperature/air humidity sensor are added to the mobile robot. Through a graphical user interface (web application), the video is visualized with the environmental measurements of the place that the mobile robot runs and allows control it through the Internet.",Arduino | Cad | Internet of Thing | Javascript | Mobile robot | Raspberry pi | Web socket,4,1-7,Conference Proceeding,Conference Paper,3.0,"Marroquin, Alberto;Gomez, Adalberto;Paz, Alejandro",57170361600;57201024112;57197546420,Universidad Don Bosco,El Salvador,"the continuous development of internet of things brings new tools in different areas of robotics, for example in the robotics of services. this document presents a low-cost alternative for a mobile explorer robot that uses open hardware and software, whose design is intended to incorporate cameras, sensors and other peripherals to be able to inspect its environment in addition to being controlled remotely using the internet technologies of the things. for the first prototype, a camera and a temperature/air humidity sensor are added to the mobile robot. through a graphical user interface (web application), the video is visualized with the environmental measurements of the place that the mobile robot runs and allows control it through the internet.",design and implementation of explorer mobile robot controlled remotely using iot technology
1086,2-s2.0-85046416980,10.1109/CLEI.2017.8226424,A model-driven approach to develop rich web applications,Nuñez G.,"2017 43rd Latin American Computer Conference, CLEI 2017",2017-12-18,"Many Web applications have among their features the possibility of distributing their data and their business logic between the client and the server, also allowing an asynchronous communication between them. These features, originally associated with the arrival of Rich Internet Applications (RIA), remain particularly relevant and desirable. In the area of RIA, there are few proposals that simultaneously consider these features, adopt MDD (Model-Driven Development), and use implementation technologies based on scripting. In this work, we start from MoWebA, an MDD approach to web application development, and we extend it by defining a specific architecture model with RIA functionalities, supporting the previously mentioned features. We have defined the necessary metamodels and UML profiles, as well as transformation rules that allow you to generate code based on HTML5, Javascript, jQuery, jQuery Datatables and jQuery UI. The preliminary validation of the proposal shows positive evidences regarding the effectiveness, efficiency and satisfaction of the users with respect to the modeling and code generation processes of the proposal.",MDA | MDD | Model Driven Architecture | Model Driven Development | Model Oriented Web Approach | MoWebA | RIA | Rich Internet Applications,0,1-10,Conference Proceeding,Conference Paper,4.0,"Nuñez, Guido;González, Magalí;Aquino, Nathalie;Cernuzzi, Luca",57201901335;36619478300;24721394100;7801512554,Universidad Católica Nuestra Señora de la Asunción,Paraguay,"many web applications have among their features the possibility of distributing their data and their business logic between the client and the server, also allowing an asynchronous communication between them. these features, originally associated with the arrival of rich internet applications (ria), remain particularly relevant and desirable. in the area of ria, there are few proposals that simultaneously consider these features, adopt mdd (model-driven development), and use implementation technologies based on scripting. in this work, we start from moweba, an mdd approach to web application development, and we extend it by defining a specific architecture model with ria functionalities, supporting the previously mentioned features. we have defined the necessary metamodels and uml profiles, as well as transformation rules that allow you to generate code based on html5, javascript, jquery, jquery datatables and jquery ui. the preliminary validation of the proposal shows positive evidences regarding the effectiveness, efficiency and satisfaction of the users with respect to the modeling and code generation processes of the proposal.",a model-driven approach to develop rich web applications
1087,2-s2.0-85052619637,10.1145/3178298.3178299,Enabling the effective teaching and learning of advanced robotics in higher education using an active tui framework,De Raffaele C.,ACM International Conference Proceeding Series,2017-12-12,This paper presents a tangible user interface (TUI) architecture to help mitigate the educational difficulties in teaching and learning abstract and complex concepts in Software Engineering and Robotics. The tailoreddesignand development of this innovative framework addressthe unique challenges faced in higher education to actively engage students in technical concepts required to develop smart knowledge infrastructures. The novel integration of active tangible components on TUI tabletop architectures is presented within this paperand evaluated for its effectiveness as an educational technology to explain RobotOperating System (ROS) based sensor network topologies. Analysis of assessed results highlightthe aptness and effectiveness of the proposed TUI framework in delivering a knowledge gain of 14.6% over traditional educational technologies.This illustrates the aptness and suitability of integrating tangible technology for abstracted software and roboticengineering concepts within higher educational institutions.,Active tangible user interface | Educational technology | Embedded interaction | Higher education | Robot operating system,0,7-12,Conference Proceeding,Conference Paper,3.0,"De Raffaele, Clifford;Smith, Serengul;Gemikonakli, Orhan",35301793400;56451899200;6602247439,Middlesex University Malta;Middlesex University,Malta;United Kingdom,this paper presents a tangible user interface (tui) architecture to help mitigate the educational difficulties in teaching and learning abstract and complex concepts in software engineering and robotics. the tailoreddesignand development of this innovative framework addressthe unique challenges faced in higher education to actively engage students in technical concepts required to develop smart knowledge infrastructures. the novel integration of active tangible components on tui tabletop architectures is presented within this paperand evaluated for its effectiveness as an educational technology to explain robotoperating system (ros) based sensor network topologies. analysis of assessed results highlightthe aptness and effectiveness of the proposed tui framework in delivering a knowledge gain of 14.6% over traditional educational technologies.this illustrates the aptness and suitability of integrating tangible technology for abstracted software and roboticengineering concepts within higher educational institutions.,enabling the effective teaching and learning of advanced robotics in higher education using an active tui framework
1088,2-s2.0-85043250576,10.1109/FIE.2017.8190486,Detecting and comparing brain activity in short program comprehension using EEG,Yeh M.K.C.,"Proceedings - Frontiers in Education Conference, FIE",2017-12-12,"Program comprehension is a common task in software development. Programmers perform program comprehension at different stages of the software development life cycle. Detecting when a programmer experiences problems or confusion can be difficult. Self-reported data may be useful, but not reliable. More importantly, it is hard to use the self-reported feedback in real time. In this study, we use an inexpensive, non-invasive EEG device to record 8 subjects' brain activity in short program comprehension. Subjects were presented either confusing or non-confusing C/C++ code snippets. Paired sample t-tests are used to compare the average magnitude in alpha and theta frequency bands. The results show that the differences in the average magnitude in both bands are significant comparing confusing and non-confusing questions. We then use ANOVA to detect whether such difference also presented in the same type of questions. We found that there is no significant difference across questions of the same difficulty level. Our outcome, however, shows alpha and theta band powers both increased when subjects are under the heavy cognitive workload. Other research studies reported a negative correlation between (upper) alpha and theta band powers.",Computer programming | EEG | Electroencephalograph,11,1-5,Conference Proceeding,Conference Paper,4.0,"Yeh, Martin K.C.;Gopstein, Dan;Yan, Yu;Zhuang, Yanyan",24492385100;57191997003;57188738867;16314597200,Penn State Brandywine;New York University;Pennsylvania State University;University of Colorado Boulder,United States;United States;United States;United States,"program comprehension is a common task in software development. programmers perform program comprehension at different stages of the software development life cycle. detecting when a programmer experiences problems or confusion can be difficult. self-reported data may be useful, but not reliable. more importantly, it is hard to use the self-reported feedback in real time. in this study, we use an inexpensive, non-invasive eeg device to record 8 subjects' brain activity in short program comprehension. subjects were presented either confusing or non-confusing c/c++ code snippets. paired sample t-tests are used to compare the average magnitude in alpha and theta frequency bands. the results show that the differences in the average magnitude in both bands are significant comparing confusing and non-confusing questions. we then use anova to detect whether such difference also presented in the same type of questions. we found that there is no significant difference across questions of the same difficulty level. our outcome, however, shows alpha and theta band powers both increased when subjects are under the heavy cognitive workload. other research studies reported a negative correlation between (upper) alpha and theta band powers.",detecting and comparing brain activity in short program comprehension using eeg
1089,2-s2.0-85043228196,10.1109/FIE.2017.8190657,Development of signal processing online labs using HTML5 and mobile platforms,Dixit A.,"Proceedings - Frontiers in Education Conference, FIE",2017-12-12,"Several web-based signal processing simulation packages for education have been developed in a Java environment. Although this environment has provided convenience and accessibility using standard browser technology, it has recently become vulnerable to cyber-attacks and is no longer compatible with secure browsers. In this paper, we describe our efforts to transform our award-winning J-DSP online laboratory by rebuilding it on an HTML5 framework. Along with a new simulation environment, we have redesigned the interface to enable several new functionalities and an entirely new educational experience. These new features include functions that enable real-time interfaces with sensor boards and mobile phones. The Web 4.0 HTML5 technology departs from older Java interfaces and provides an interactive graphical user interface (GUI) enabling seamless connectivity and both software and hardware experiences for students in DSP classes.",HTML5 | Real-time online labs | Sensor interfaces | Signal processing | Web 4.0 engineering education,7,1-5,Conference Proceeding,Conference Paper,6.0,"Dixit, Abhinav;Katoch, Sameeksha;Spanias, Photini;Banavar, Mahesh;Song, Huan;Spanias, Andreas",57201064386;57201061925;8946866300;18533731300;56022206900;7006177932,Sensor Signal and Information Processing (SenSIP) Center;Mary Lou Fulton Teachers College;Clarkson University,United States;United States;United States,"several web-based signal processing simulation packages for education have been developed in a java environment. although this environment has provided convenience and accessibility using standard browser technology, it has recently become vulnerable to cyber-attacks and is no longer compatible with secure browsers. in this paper, we describe our efforts to transform our award-winning j-dsp online laboratory by rebuilding it on an html5 framework. along with a new simulation environment, we have redesigned the interface to enable several new functionalities and an entirely new educational experience. these new features include functions that enable real-time interfaces with sensor boards and mobile phones. the web 4.0 html5 technology departs from older java interfaces and provides an interactive graphical user interface (gui) enabling seamless connectivity and both software and hardware experiences for students in dsp classes.",development of signal processing online labs using html5 and mobile platforms
1090,2-s2.0-85046684825,10.1109/CIC.2017.00063,Proposing and Testing New Security Cue Designs for OAuth-WebView-Embedded Mobile Applications,Mohsen F.,"Proceedings - 2017 IEEE 3rd International Conference on Collaboration and Internet Computing, CIC 2017",2017-12-09,"Today, many online service providers use the WebView-OAuth implementation in their Software Development Kits (SDKs) to seamlessly integrate their services into mobile applications. This approach was proven to be a target to JavaScript injection attacks that could lead into users losing their credentials or tricked into authorizing suspicious apps on their accounts. A number of solutions came out to countermeasure these attacks. However, the majority of these solutions do not involve the users in making the prevention decision and/or do not communicate the taken decision to them. That is because of two reasons: first, the focus of these works were mainly on detecting and preventing the attacks. Second, because of the lack of effective security cue designs for the WebView-based applications context. In this paper, we aim at investigating different security cue designs to aid with keeping the users informed of whatever these solutions are practicing. Finding an effective security cue design in the mobile browsers is challenging and more so for the WebView browsers. Thus, in this work, we are proposing and testing a number of security cue designs based on their understandability, noticeability, and effectiveness by conducting an online user study of 465 users. Our study found that some of the proposed security cue designs were truly noticeably, understandable and effective in alerting users of any suspicious activity. We highly recommend these security designs to be used by numerous security tools that detect and/or prevent WebView-based attacks.",Android | Applications | Authentication | Authorization | Injection | JavaScript | Permissions | Privacy | Security Cues,2,443-448,Conference Proceeding,Conference Paper,2.0,"Mohsen, Fadi;Shehab, Mohamed",55948102500;23025577500,University of Michigan-Flint;The University of North Carolina at Charlotte,United States;United States,"today, many online service providers use the webview-oauth implementation in their software development kits (sdks) to seamlessly integrate their services into mobile applications. this approach was proven to be a target to javascript injection attacks that could lead into users losing their credentials or tricked into authorizing suspicious apps on their accounts. a number of solutions came out to countermeasure these attacks. however, the majority of these solutions do not involve the users in making the prevention decision and/or do not communicate the taken decision to them. that is because of two reasons: first, the focus of these works were mainly on detecting and preventing the attacks. second, because of the lack of effective security cue designs for the webview-based applications context. in this paper, we aim at investigating different security cue designs to aid with keeping the users informed of whatever these solutions are practicing. finding an effective security cue design in the mobile browsers is challenging and more so for the webview browsers. thus, in this work, we are proposing and testing a number of security cue designs based on their understandability, noticeability, and effectiveness by conducting an online user study of 465 users. our study found that some of the proposed security cue designs were truly noticeably, understandable and effective in alerting users of any suspicious activity. we highly recommend these security designs to be used by numerous security tools that detect and/or prevent webview-based attacks.",proposing and testing new security cue designs for oauth-webview-embedded mobile applications
1091,2-s2.0-85046635942,10.1109/CIC.2017.00020,When Do Changes Induce Software Vulnerabilities?,Alohaly M.,"Proceedings - 2017 IEEE 3rd International Conference on Collaboration and Internet Computing, CIC 2017",2017-12-09,"Version control systems (VCSs) have almost become the de facto standard for the management of open-source projects and the development of their source code. In VCSs, source code which can potentially be vulnerable is introduced to a system through what are so called commits. Vulnerable commits force the system into an insecure state. The farreaching impact of vulnerabilities attests to the importance of identifying and understanding the characteristics of prior vulnerable changes (or commits), in order to detect future similar ones. The concept of change classification was previously studied in the literature of bug detection to identify commits with defects. In this paper, we borrow the notion of change classification from the literature of defect detection to further investigate its applicability to vulnerability detection problem using semi-supervised learning. In addition, we also experiment with new vulnerability predictors, and compare the predictive power of our proposed features with vulnerability prediction techniques based on text mining. The experimental results show that our semi-supervised approach holds promise in improving change classification effectiveness by leveraging unlabeled data.",Semi supervised Learning | Software Security | Software Vulnerabilities | Source Code | Vulnerability Prediction,4,59-66,Conference Proceeding,Conference Paper,2.0,"Alohaly, Manar;Takabi, Hassan",57193347849;23006829300,University of North Texas,United States,"version control systems (vcss) have almost become the de facto standard for the management of open-source projects and the development of their source code. in vcss, source code which can potentially be vulnerable is introduced to a system through what are so called commits. vulnerable commits force the system into an insecure state. the farreaching impact of vulnerabilities attests to the importance of identifying and understanding the characteristics of prior vulnerable changes (or commits), in order to detect future similar ones. the concept of change classification was previously studied in the literature of bug detection to identify commits with defects. in this paper, we borrow the notion of change classification from the literature of defect detection to further investigate its applicability to vulnerability detection problem using semi-supervised learning. in addition, we also experiment with new vulnerability predictors, and compare the predictive power of our proposed features with vulnerability prediction techniques based on text mining. the experimental results show that our semi-supervised approach holds promise in improving change classification effectiveness by leveraging unlabeled data.",when do changes induce software vulnerabilities?
1096,2-s2.0-85041447125,10.1109/ASE.2017.8115635,BProVe: A formal verification framework for business process models,Corradini F.,ASE 2017 - Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering,2017-11-20,"Business Process Modelling has acquired increasing relevance in software development. Available notations, such as BPMN, permit to describe activities of complex organisations. On the one hand, this shortens the communication gap between domain experts and IT specialists. On the other hand, this permits to clarify the characteristics of software systems introduced to provide automatic support for such activities. Nevertheless, the lack of formal semantics hinders the automatic verification of relevant properties. This paper presents a novel verification framework for BPMN 2.0, called BProVe. It is based on an operational semantics, implemented using MAUDE, devised to make the verification general and effective. A complete tool chain, based on the Eclipse modelling environment, allows for rigorous modelling and analysis of Business Processes. The approach has been validated using more than one thousand models available on a publicly accessible repository. Besides showing the performance of BProVe, this validation demonstrates its practical benefits in identifying correctness issues in real models.",BPMN | Business Processes | MAUDE | Software Verification | Structural Operational Semantics,21,217-228,Conference Proceeding,Conference Paper,6.0,"Corradini, Flavio;Fornari, Fabrizio;Polini, Andrea;Re, Barbara;Tiezzi, Francesco;Vandin, Andrea",55679592700;57194788362;8399556900;23390178600;23089657900;36662971300,Università degli Studi di Camerino;Technical University of Denmark,Italy;Denmark,"business process modelling has acquired increasing relevance in software development. available notations, such as bpmn, permit to describe activities of complex organisations. on the one hand, this shortens the communication gap between domain experts and it specialists. on the other hand, this permits to clarify the characteristics of software systems introduced to provide automatic support for such activities. nevertheless, the lack of formal semantics hinders the automatic verification of relevant properties. this paper presents a novel verification framework for bpmn 2.0, called bprove. it is based on an operational semantics, implemented using maude, devised to make the verification general and effective. a complete tool chain, based on the eclipse modelling environment, allows for rigorous modelling and analysis of business processes. the approach has been validated using more than one thousand models available on a publicly accessible repository. besides showing the performance of bprove, this validation demonstrates its practical benefits in identifying correctness issues in real models.",bprove: a formal verification framework for business process models
1099,2-s2.0-85030127509,10.1166/jmihi.2017.2173,Development of magnetic resonance imaging data arrangement toolbox,Pei H.,Journal of Medical Imaging and Health Informatics,2017-11-01,"Raw magnetic resonance imaging (MRI) data in DICOM format needed to be arranged well before being processed by software. Five problems should be resolved in the arrange step, including adding mark names describing project name and subject’s group on DICOM folders’ name, separating different data of different sequences, changing Chinese characters of folder name into English, adding a uniform number to folders, and converting DICOM format into NIFTI format to meet need of subsequent processing software. Usually the above five steps were operated manually, which is time consuming and error prone work. A MRI data arranging toolbox was developed in the present study. Under graphical user interface of MATLAB, five automatic functions have been realized including classify MRI folder according to research project and group, sorting, renaming and ranking MRI folders and converting MRI DICOM files into NIFTI format. The toolbox is easy to operate and may improve work efficiency and accuracy greatly.",Arrangement toolbox | Magnetic resonance imaging digital imaging and communication in medical data | MATLAB,0,1607-1610,Journal,Article,5.0,"Pei, Haonan;Cui, Dong;Cao, Weifang;Guo, Yongxin;Jiao, Qing",57195922107;57200383757;56410295300;55712444100;7006588956,Taishan Medical University,China,"raw magnetic resonance imaging (mri) data in dicom format needed to be arranged well before being processed by software. five problems should be resolved in the arrange step, including adding mark names describing project name and subject’s group on dicom folders’ name, separating different data of different sequences, changing chinese characters of folder name into english, adding a uniform number to folders, and converting dicom format into nifti format to meet need of subsequent processing software. usually the above five steps were operated manually, which is time consuming and error prone work. a mri data arranging toolbox was developed in the present study. under graphical user interface of matlab, five automatic functions have been realized including classify mri folder according to research project and group, sorting, renaming and ranking mri folders and converting mri dicom files into nifti format. the toolbox is easy to operate and may improve work efficiency and accuracy greatly.",development of magnetic resonance imaging data arrangement toolbox
1100,2-s2.0-85028946242,10.1016/j.jelectrocard.2017.08.007,A decision support system and rule-based algorithm to augment the human interpretation of the 12-lead electrocardiogram,Cairns A.W.,Journal of Electrocardiology,2017-11-01,"Background The 12-lead Electrocardiogram (ECG) has been used to detect cardiac abnormalities in the same format for more than 70 years. However, due to the complex nature of 12-lead ECG interpretation, there is a significant cognitive workload required from the interpreter. This complexity in ECG interpretation often leads to errors in diagnosis and subsequent treatment. We have previously reported on the development of an ECG interpretation support system designed to augment the human interpretation process. This computerised decision support system has been named ‘Interactive Progressive based Interpretation’ (IPI). In this study, a decision support algorithm was built into the IPI system to suggest potential diagnoses based on the interpreter's annotations of the 12-lead ECG. We hypothesise semi-automatic interpretation using a digital assistant can be an optimal man-machine model for ECG interpretation. Objectives To improve interpretation accuracy and reduce missed co-abnormalities. Methods The Differential Diagnoses Algorithm (DDA) was developed using web technologies where diagnostic ECG criteria are defined in an open storage format, Javascript Object Notation (JSON), which is queried using a rule-based reasoning algorithm to suggest diagnoses. To test our hypothesis, a counterbalanced trial was designed where subjects interpreted ECGs using the conventional approach and using the IPI + DDA approach. Results A total of 375 interpretations were collected. The IPI + DDA approach was shown to improve diagnostic accuracy by 8.7% (although not statistically significant, p-value = 0.1852), the IPI + DDA suggested the correct interpretation more often than the human interpreter in 7/10 cases (varying statistical significance). Human interpretation accuracy increased to 70% when seven suggestions were generated. Conclusion Although results were not found to be statistically significant, we found; 1) our decision support tool increased the number of correct interpretations, 2) the DDA algorithm suggested the correct interpretation more often than humans, and 3) as many as 7 computerised diagnostic suggestions augmented human decision making in ECG interpretation. Statistical significance may be achieved by expanding sample size.",12-lead Electrocardiogram | Algorithm | Decision support | Diagnoses | ECG criteria | Interpretation,9,781-786,Journal,Article,8.0,"Cairns, Andrew W.;Bond, Raymond R.;Finlay, Dewar D.;Guldenring, Daniel;Badilini, Fabio;Libretti, Guido;Peace, Aaron J.;Leslie, Stephen J.",56814520100;36019802200;8977626000;36459546000;57203006991;57195397564;25655320100;57202677736,Amps LLC;Ulster University;Altnagelvin Area Hospital;NHS Highland,United States;United Kingdom;United Kingdom;United Kingdom,"background the 12-lead electrocardiogram (ecg) has been used to detect cardiac abnormalities in the same format for more than 70 years. however, due to the complex nature of 12-lead ecg interpretation, there is a significant cognitive workload required from the interpreter. this complexity in ecg interpretation often leads to errors in diagnosis and subsequent treatment. we have previously reported on the development of an ecg interpretation support system designed to augment the human interpretation process. this computerised decision support system has been named ‘interactive progressive based interpretation’ (ipi). in this study, a decision support algorithm was built into the ipi system to suggest potential diagnoses based on the interpreter's annotations of the 12-lead ecg. we hypothesise semi-automatic interpretation using a digital assistant can be an optimal man-machine model for ecg interpretation. objectives to improve interpretation accuracy and reduce missed co-abnormalities. methods the differential diagnoses algorithm (dda) was developed using web technologies where diagnostic ecg criteria are defined in an open storage format, javascript object notation (json), which is queried using a rule-based reasoning algorithm to suggest diagnoses. to test our hypothesis, a counterbalanced trial was designed where subjects interpreted ecgs using the conventional approach and using the ipi + dda approach. results a total of 375 interpretations were collected. the ipi + dda approach was shown to improve diagnostic accuracy by 8.7% (although not statistically significant, p-value = 0.1852), the ipi + dda suggested the correct interpretation more often than the human interpreter in 7/10 cases (varying statistical significance). human interpretation accuracy increased to 70% when seven suggestions were generated. conclusion although results were not found to be statistically significant, we found; 1) our decision support tool increased the number of correct interpretations, 2) the dda algorithm suggested the correct interpretation more often than humans, and 3) as many as 7 computerised diagnostic suggestions augmented human decision making in ecg interpretation. statistical significance may be achieved by expanding sample size.",a decision support system and rule-based algorithm to augment the human interpretation of the 12-lead electrocardiogram
1102,2-s2.0-85047175934,10.1109/VISSOFT.2017.23,SoL Mantra: Visualizing Update Opportunities Based on Library Coexistence,Todorov B.,"Proceedings - 2017 IEEE Working Conference on Software Visualization, VISSOFT 2017",2017-10-31,"In software development, software reuse has become a pivotal factor in creating and providing high-quality software at a reduced cost. The reuse of a code creates dependencies, which as they increase over time become difficult to manage and avoid compatibility issues or bugs. With newer version releases, come various quality improvements, new features and issue fixes, but deciding whether or not to adopt those is a difficult task for large software with a lot of dependencies. To address those difficulties, we propose SoL Mantra which is a tool that shows update opportunities by leveraging the Wisdom of the Crowd in a software ecosystem. Using this combined knowledge, our tool displays information about the complexity of each update opportunity. The orbital layout provides the means to visualize the update opportunities and demonstrate its merits by showcasing two examples from the JavaScript ecosystem. Through these examples, we demonstrate how maintainers can benefit from SoL Mantra's visual cues.",Coexistence | Library Dependency | Orbital Layout,3,129-133,Conference Proceeding,Conference Paper,4.0,"Todorov, Boris;Kula, Raula Gaikovina;Ishio, Takashi;Inoue, Katsuro",57202118404;57188638536;8381338700;7601540520,Nara Institute of Science and Technology;Osaka University,Japan;Japan,"in software development, software reuse has become a pivotal factor in creating and providing high-quality software at a reduced cost. the reuse of a code creates dependencies, which as they increase over time become difficult to manage and avoid compatibility issues or bugs. with newer version releases, come various quality improvements, new features and issue fixes, but deciding whether or not to adopt those is a difficult task for large software with a lot of dependencies. to address those difficulties, we propose sol mantra which is a tool that shows update opportunities by leveraging the wisdom of the crowd in a software ecosystem. using this combined knowledge, our tool displays information about the complexity of each update opportunity. the orbital layout provides the means to visualize the update opportunities and demonstrate its merits by showcasing two examples from the javascript ecosystem. through these examples, we demonstrate how maintainers can benefit from sol mantra's visual cues.",sol mantra: visualizing update opportunities based on library coexistence
1103,2-s2.0-85037154434,10.1145/3133850.3133852,Infra: Structure all the way down?: Structured data as a visual programming language,Hall C.,"Onward! 2017 - Proceedings of the 2017 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software, co-located with SPLASH 2017",2017-10-25,"We present Infra, a new baseline medium for representing data. With Infra, arbitrarily-complex structured data can be encoded, viewed, edited, and processed, all while remaining in an efficient non-textual form. It is suitable for the full range of information modalities, from free-form input, to compact schema-conforming structures. With its own equivalent of a text editor and text-field widget, Infra is designed to target the domain currently dominated by flat character strings while simultaneously enabling the expression of sub-structure, inter-reference, dynamic dependencies, abstraction, computation, and context (metadata). Existing metaformats fit neatly into two categories. They are either textual for human readability (such as XML and JSON) or binary for compact serialization (such as Thrift and Protocol Buffers). In contrast, Infra unifies those two paradigms. In order to have the desirable properties of binary formats, Infra has no textual representation. And yet, it is designed to be easily read and authored by end-users. We show how the organization Infra brings to data makes a new non-textual programming paradigm viable. Programs that modify data can now be embedded into the data itself. Furthermore, these programs can often be authored by demonstration. We argue that Infra can be used to improve existing software projects and that bringing direct authoring and human readability to a binary data paradigm could have rippling ramifications on the computing landscape.",End-user development | Human-readability | Metaformat | Structure editing,3,180-197,Conference Proceeding,Conference Paper,3.0,"Hall, Christopher;Standley, Trevor;Hollerer, Tobias",57198135093;35105965600;8358959700,"University of California, Santa Barbara",United States,"we present infra, a new baseline medium for representing data. with infra, arbitrarily-complex structured data can be encoded, viewed, edited, and processed, all while remaining in an efficient non-textual form. it is suitable for the full range of information modalities, from free-form input, to compact schema-conforming structures. with its own equivalent of a text editor and text-field widget, infra is designed to target the domain currently dominated by flat character strings while simultaneously enabling the expression of sub-structure, inter-reference, dynamic dependencies, abstraction, computation, and context (metadata). existing metaformats fit neatly into two categories. they are either textual for human readability (such as xml and json) or binary for compact serialization (such as thrift and protocol buffers). in contrast, infra unifies those two paradigms. in order to have the desirable properties of binary formats, infra has no textual representation. and yet, it is designed to be easily read and authored by end-users. we show how the organization infra brings to data makes a new non-textual programming paradigm viable. programs that modify data can now be embedded into the data itself. furthermore, these programs can often be authored by demonstration. we argue that infra can be used to improve existing software projects and that bringing direct authoring and human readability to a binary data paradigm could have rippling ramifications on the computing landscape.",infra: structure all the way down?: structured data as a visual programming language
1104,2-s2.0-85084186636,10.1145/3136040.3136059,How preprocessor annotations (do not) affect maintainability: A case study on change-proneness,Fenske W.,ACM SIGPLAN Notices,2017-10-23,"Preprocessor annotations (e.g., #ifdef in C) enable the development of similar, but distinct software variants from a common code base. One particularly popular preprocessor is the C preprocessor, cpp. But the cpp is also widely criticized for impeding software maintenance by making code hard to understand and change. Yet, evidence to support this criticism is scarce. In this paper, we investigate the relation between cpp usage and maintenance effort, which we approximate with the frequency and extent of source code changes. To this end, we mined the version control repositories of eight open- source systems written in C. For each system, we measured if and how individual functions use cpp annotations and how they were changed. We found that functions containing cpp annotations are generally changed more frequently and more profoundly than other functions. However, when accounting for function size, the differences disappear or are greatly diminished. In summary, with respect to the frequency and extent of changes, our findings do not support the criticism of the cpp regarding maintainability.",annotations | change-proneness | maintenance | preprocessors | variability,4,77-90,Journal,Article,3.0,"Fenske, Wolfram;Schulze, Sandro;Saake, Gunter",37161126200;35225243700;7004621677,Otto von Guericke University of Magdeburg,Germany,"preprocessor annotations (e.g., #ifdef in c) enable the development of similar, but distinct software variants from a common code base. one particularly popular preprocessor is the c preprocessor, cpp. but the cpp is also widely criticized for impeding software maintenance by making code hard to understand and change. yet, evidence to support this criticism is scarce. in this paper, we investigate the relation between cpp usage and maintenance effort, which we approximate with the frequency and extent of source code changes. to this end, we mined the version control repositories of eight open- source systems written in c. for each system, we measured if and how individual functions use cpp annotations and how they were changed. we found that functions containing cpp annotations are generally changed more frequently and more profoundly than other functions. however, when accounting for function size, the differences disappear or are greatly diminished. in summary, with respect to the frequency and extent of changes, our findings do not support the criticism of the cpp regarding maintainability.",how preprocessor annotations (do not) affect maintainability: a case study on change-proneness
1105,2-s2.0-85041744741,10.1145/3136040.3136059,How Preprocessor Annotations (Do Not) Affect Maintainability: A Case Study on Change-Proneness,Fenske W.,"GPCE 2017 - Proceedings of the 16th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences, co-located with SPLASH 2017",2017-10-23,"Preprocessor annotations (e. g., #ifdef in C) enable the development of similar, but distinct software variants from a common code base. One particularly popular preprocessor is the C preprocessor, cpp. But the cpp is also widely criticized for impeding software maintenance by making code hard to understand and change. Yet, evidence to support this criticism is scarce. In this paper, we investigate the relation between cpp usage and maintenance effort, which we approximate with the frequency and extent of source code changes. To this end, we mined the version control repositories of eight open-source systems written in C. For each system, we measured if and how individual functions use cpp annotations and how they were changed. We found that functions containing cpp annotations are generally changed more frequently and more profoundly than other functions. However, when accounting for function size, the differences disappear or are greatly diminished. In summary, with respect to the frequency and extent of changes, our findings do not support the criticism of the cpp regarding maintainability.",Annotations | Change-proneness | Maintenance | Preprocessors | Variability,5,77-90,Conference Proceeding,Conference Paper,3.0,"Fenske, Wolfram;Schulze, Sandro;Saake, Gunter",37161126200;35225243700;7004621677,Otto von Guericke University of Magdeburg,Germany,"preprocessor annotations (e. g., #ifdef in c) enable the development of similar, but distinct software variants from a common code base. one particularly popular preprocessor is the c preprocessor, cpp. but the cpp is also widely criticized for impeding software maintenance by making code hard to understand and change. yet, evidence to support this criticism is scarce. in this paper, we investigate the relation between cpp usage and maintenance effort, which we approximate with the frequency and extent of source code changes. to this end, we mined the version control repositories of eight open-source systems written in c. for each system, we measured if and how individual functions use cpp annotations and how they were changed. we found that functions containing cpp annotations are generally changed more frequently and more profoundly than other functions. however, when accounting for function size, the differences disappear or are greatly diminished. in summary, with respect to the frequency and extent of changes, our findings do not support the criticism of the cpp regarding maintainability.",how preprocessor annotations (do not) affect maintainability: a case study on change-proneness
1107,2-s2.0-85035780227,10.1109/SecDev.2017.20,Layering Security at Global Control Points to Secure Unmodified Software,Ruoti S.,"Proceedings - 2017 IEEE Cybersecurity Development Conference, SecDev 2017",2017-10-20,"Developing secure software is inherently difficult, and is further hampered by a rush to market, the lack of cybersecurity-trained architects and developers, and the difficulty of identifying flaws and deploying mitigations. To address these problems, we advocate for an alternative paradigm-layering security onto applications from global control points, such as the browser, operating system, or network. This approach adds security to existing applications, relieving developers of this burden. The benefits of this paradigm are three-fold-(1) increased correctness in the implementation of security features, (2) coverage for all software, even non-maintained legacy software, and (3) more rapid and consistent deployment of threat mitigations and new security features. To demonstrate these benefits, we describe three concrete instantiations of this paradigm- MessageGuard, a system that layers end-to-end encryption in the browser; TrustBase, a system that layers authentication in the operating system; and software-defined perimeter, which layers access control at network middleboxes.",Application security | Layered security | Repairing Applications | Secure software development | Security,4,42-49,Conference Proceeding,Conference Paper,3.0,"Ruoti, Scott;Seamons, Kent;Zappala, Daniel",55588035200;6601908155;7003445799,Lincoln Laboratory;Brigham Young University,United States;United States,"developing secure software is inherently difficult, and is further hampered by a rush to market, the lack of cybersecurity-trained architects and developers, and the difficulty of identifying flaws and deploying mitigations. to address these problems, we advocate for an alternative paradigm-layering security onto applications from global control points, such as the browser, operating system, or network. this approach adds security to existing applications, relieving developers of this burden. the benefits of this paradigm are three-fold-(1) increased correctness in the implementation of security features, (2) coverage for all software, even non-maintained legacy software, and (3) more rapid and consistent deployment of threat mitigations and new security features. to demonstrate these benefits, we describe three concrete instantiations of this paradigm- messageguard, a system that layers end-to-end encryption in the browser; trustbase, a system that layers authentication in the operating system; and software-defined perimeter, which layers access control at network middleboxes.",layering security at global control points to secure unmodified software
1108,2-s2.0-85036458594,10.1109/CCOMS.2017.8075176,Modular and flexible coordination for web-based applications,Li P.,"2nd International Conference on Computer and Communication Systems, ICCCS 2017",2017-10-19,"in this research, I want to investigate programming language and middleware abstractions which offer an alternative approach in client/server Web application development, for dealing specifically with coordination between client and server components that has flexibility in mapping components to physical locations. I work on a middleware and JavaScript interpreter that provides support for modular coordination that avoid problems with both of the patterns presented in this introduction. in my approach, developers would write a separate coordination specification which mediated client and server workflow. To evaluate the performance of my framework and prove the low-performance overhead, I have modified a well-known open source Web application, Java Pet Store by using my framework and then I have evaluated the modified Web application provides low-performance overhead.",AJAX | cloud-based application | program partitioning | programming language | web-based application,1,6-10,Conference Proceeding,Conference Paper,1.0,"Li, Peng",57199004981,Beijing Institute of Technology,China,"in this research, i want to investigate programming language and middleware abstractions which offer an alternative approach in client/server web application development, for dealing specifically with coordination between client and server components that has flexibility in mapping components to physical locations. i work on a middleware and javascript interpreter that provides support for modular coordination that avoid problems with both of the patterns presented in this introduction. in my approach, developers would write a separate coordination specification which mediated client and server workflow. to evaluate the performance of my framework and prove the low-performance overhead, i have modified a well-known open source web application, java pet store by using my framework and then i have evaluated the modified web application provides low-performance overhead.",modular and flexible coordination for web-based applications
1112,2-s2.0-85010977220,10.1007/s10278-017-9956-7,JavaScript Access to DICOM Network and Objects in Web Browser,Drnasin I.,Journal of Digital Imaging,2017-10-01,"Digital imaging and communications in medicine (DICOM) 3.0 standard provides the baseline for the picture archiving and communication systems (PACS). The development of Internet and various communication media initiated demand for non-DICOM access to PACS systems. Ever-increasing utilization of the web browsers, laptops and handheld devices, as opposed to desktop applications and static organizational computers, lead to development of different web technologies. The DICOM standard officials accepted those subsequently as tools of alternative access. This paper provides an overview of the current state of development of the web access technology to the DICOM repositories. It presents a different approach of using HTML5 features of the web browsers through the JavaScript language and the WebSocket protocol by enabling real-time communication with DICOM repositories. JavaScript DICOM network library, DICOM to WebSocket proxy and a proof-of-concept web application that qualifies as a DICOM 3.0 device were developed.",DICOM | HTML5 | HTTP | Internet | JavaScript | PACS | Teleradiology | WebSocket,7,537-546,Journal,Article,3.0,"Drnasin, Ivan;Grgić, Mislav;Gogić, Goran",24482899800;56234047900;57203084991,University of Zagreb;Infomedica,Croatia;Croatia,"digital imaging and communications in medicine (dicom) 3.0 standard provides the baseline for the picture archiving and communication systems (pacs). the development of internet and various communication media initiated demand for non-dicom access to pacs systems. ever-increasing utilization of the web browsers, laptops and handheld devices, as opposed to desktop applications and static organizational computers, lead to development of different web technologies. the dicom standard officials accepted those subsequently as tools of alternative access. this paper provides an overview of the current state of development of the web access technology to the dicom repositories. it presents a different approach of using html5 features of the web browsers through the javascript language and the websocket protocol by enabling real-time communication with dicom repositories. javascript dicom network library, dicom to websocket proxy and a proof-of-concept web application that qualifies as a dicom 3.0 device were developed.",javascript access to dicom network and objects in web browser
1117,2-s2.0-85028721632,10.1107/S1600577517009080,WIFIP: A web-based user interface for automated synchrotron beamlines,Sallaz-Damaz Y.,Journal of Synchrotron Radiation,2017-09-01,"The beamline control software, through the associated graphical user interface (GUI), is the user access point to the experiment, interacting with synchrotron beamline components and providing automated routines. FIP, the French beamline for the Investigation of Proteins, is a highly automatized macromolecular crystallography (MX) beamline at the European Synchrotron Radiation Facility. On such a beamline, a significant number of users choose to control their experiment remotely. This is often performed with a limited bandwidth and from a large choice of computers and operating systems. Furthermore, this has to be possible in a rapidly evolving experimental environment, where new developments have to be easily integrated. To face these challenges, a light, platform-independent, control software and associated GUI are required. Here, WIFIP, a web-based user interface developed at FIP, is described. Further than being the present FIP control interface, WIFIP is also a proof of concept for future MX control software.WIFIP is a web-based interface for macromolecular crystallography beamlines. In operation on beamline FIP-BM30A at the ESRF since September 2015, it enables the control of the experiment remotely from any kind of web browser, and with a limited bandwidth.",automated beamline | graphical user interface | macromolecular crystallography | web-based,2,1105-1111,Journal,Article,2.0,"Sallaz-Damaz, Yoann;Ferrer, Jean Luc",15844008300;35473126500,Universite Grenoble Alpes,France,"the beamline control software, through the associated graphical user interface (gui), is the user access point to the experiment, interacting with synchrotron beamline components and providing automated routines. fip, the french beamline for the investigation of proteins, is a highly automatized macromolecular crystallography (mx) beamline at the european synchrotron radiation facility. on such a beamline, a significant number of users choose to control their experiment remotely. this is often performed with a limited bandwidth and from a large choice of computers and operating systems. furthermore, this has to be possible in a rapidly evolving experimental environment, where new developments have to be easily integrated. to face these challenges, a light, platform-independent, control software and associated gui are required. here, wifip, a web-based user interface developed at fip, is described. further than being the present fip control interface, wifip is also a proof of concept for future mx control software.wifip is a web-based interface for macromolecular crystallography beamlines. in operation on beamline fip-bm30a at the esrf since september 2015, it enables the control of the experiment remotely from any kind of web browser, and with a limited bandwidth.",wifip: a web-based user interface for automated synchrotron beamlines
1118,2-s2.0-85021174086,10.1016/j.jss.2017.05.047,Analyzing software evolution and quality by extracting Asynchrony change patterns,Jaafar F.,Journal of Systems and Software,2017-09-01,"Change patterns describe two or more files were often changed together during the development or the maintenance of software systems. Several studies have been presented to detect change patterns and to analyze their types and their impact on software quality. In this context, we introduced the Asynchrony change pattern to describes a set of files that always change together in the same change periods, regardless developers who maintained them. In this paper, we investigate the impact of Asynchrony change pattern on design and code smells such as anti-patterns and code clones. Concretely, we conduct an empirical study by detecting Asynchrony change patterns, anti-patterns and code clones occurrences on 22 versions of four software systems and analyzing their fault-proneness. Results show that cloned files that follow the same Asynchrony change patterns have significantly increased fault-proneness with respect to other clones, and that anti-patterns following the same Asynchrony change pattern can be up to five times more risky in terms of fault-proneness as compared to other anti-patterns. Asynchrony change patterns thus seem to be strong indicators of fault-proneness for clones and anti-patterns.",Anti-patterns | Change patterns | Clones | Fault-proneness | Software quality,4,311-322,Journal,Article,4.0,"Jaafar, Fehmi;Lozano, Angela;Guéhéneuc, Yann Gaël;Mens, Kim",54684236700;55796630654;13613429100;55884880800,Vrije Universiteit Brussel;Polytechnique Montréal;Concordia University of Edmonton;Université Catholique de Louvain,Belgium;Canada;Canada;Belgium,"change patterns describe two or more files were often changed together during the development or the maintenance of software systems. several studies have been presented to detect change patterns and to analyze their types and their impact on software quality. in this context, we introduced the asynchrony change pattern to describes a set of files that always change together in the same change periods, regardless developers who maintained them. in this paper, we investigate the impact of asynchrony change pattern on design and code smells such as anti-patterns and code clones. concretely, we conduct an empirical study by detecting asynchrony change patterns, anti-patterns and code clones occurrences on 22 versions of four software systems and analyzing their fault-proneness. results show that cloned files that follow the same asynchrony change patterns have significantly increased fault-proneness with respect to other clones, and that anti-patterns following the same asynchrony change pattern can be up to five times more risky in terms of fault-proneness as compared to other anti-patterns. asynchrony change patterns thus seem to be strong indicators of fault-proneness for clones and anti-patterns.",analyzing software evolution and quality by extracting asynchrony change patterns
1120,2-s2.0-85018920807,10.1016/j.cl.2017.04.002,An approach to build XML-based domain specific languages solutions for client-side web applications,Chavarriaga E.,"Computer Languages, Systems and Structures",2017-09-01,"Domain-Specific Languages (DSLs) allow for the building of applications that ease the labour of both software engineers and domain experts thanks to the level of abstraction they provide. In cases where the domain is restricted to Client-Side Web Applications (CSWA), XML-based languages, frameworks and widgets are commonly combined in order to provide fast, robust and flexible solutions. This article presents an approach designed to create XML-based DSL solutions for CSWA that includes an evaluation engine, a programming model and a lightweight development environment. The approach is able to evaluate multiple XML-based DSL programs simultaneously to provide solutions to those Domain Specific Problems for CSWAs. To better demonstrate the capabilities and potential of this novel approach, we will employ a couple of case studies, namely Anisha and FeedPsi.",Domain-Specific Languages | JavaScript | Web Application | XML interpreter | XML programing language,9,133-151,Journal,Article,3.0,"Chavarriaga, Enrique;Jurado, Francisco;Díez, Fernando",26422780100;55205594500;36811695700,Universidad Autónoma de Madrid,Spain,"domain-specific languages (dsls) allow for the building of applications that ease the labour of both software engineers and domain experts thanks to the level of abstraction they provide. in cases where the domain is restricted to client-side web applications (cswa), xml-based languages, frameworks and widgets are commonly combined in order to provide fast, robust and flexible solutions. this article presents an approach designed to create xml-based dsl solutions for cswa that includes an evaluation engine, a programming model and a lightweight development environment. the approach is able to evaluate multiple xml-based dsl programs simultaneously to provide solutions to those domain specific problems for cswas. to better demonstrate the capabilities and potential of this novel approach, we will employ a couple of case studies, namely anisha and feedpsi.",an approach to build xml-based domain specific languages solutions for client-side web applications
1123,2-s2.0-85030789792,10.1145/3106237.3106261,Toward full elasticity in distributed static analysis: The case of callgraph analysis,Garbervetsky D.,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,2017-08-21,"In this paper we present the design and implementation of a distributed, whole-program static analysis framework that is designed to scale with the size of the input. Our approach is based on the actor programming model and is deployed in the cloud. Our reliance on a cloud cluster provides a degree of elasticity for CPU, memory, and storage resources. To demonstrate the potential of our technique, we show how a typical call graph analysis can be implemented in a distributed setting. The vision that motivates this work is that every large-scale software repository such as GitHub, BitBucket or Visual Studio Online will be able to perform static analysis on a large scale. We experimentally validate our implementation of the distributed call graph analysis using a combination of both synthetic and real benchmarks. To show scalability, we demonstrate how the analysis presented in this paper is able to handle inputs that are almost 10 million lines of code (LOC) in size, without running out of memory. Our results show that the analysis scales well in terms of memory pressure independently of the input size, as we add more virtual machines (VMs). As the number of worker VMs increases, we observe that the analysis time generally improves as well. Lastly, we demonstrate that querying the results can be performed with a median latency of 15 ms.",Development environments and tools | Distributed and concurrent systems | Parallel | Performance and scalability | Program analysis | Program comprehension and visualization,16,442-453,Conference Proceeding,Conference Paper,3.0,"Garbervetsky, Diego;Zoppi, Edgardo;Livshits, Benjamin",14046586400;42162551400;12139816400,Imperial College London;Universidad de Buenos Aires,United Kingdom;Argentina,"in this paper we present the design and implementation of a distributed, whole-program static analysis framework that is designed to scale with the size of the input. our approach is based on the actor programming model and is deployed in the cloud. our reliance on a cloud cluster provides a degree of elasticity for cpu, memory, and storage resources. to demonstrate the potential of our technique, we show how a typical call graph analysis can be implemented in a distributed setting. the vision that motivates this work is that every large-scale software repository such as github, bitbucket or visual studio online will be able to perform static analysis on a large scale. we experimentally validate our implementation of the distributed call graph analysis using a combination of both synthetic and real benchmarks. to show scalability, we demonstrate how the analysis presented in this paper is able to handle inputs that are almost 10 million lines of code (loc) in size, without running out of memory. our results show that the analysis scales well in terms of memory pressure independently of the input size, as we add more virtual machines (vms). as the number of worker vms increases, we observe that the analysis time generally improves as well. lastly, we demonstrate that querying the results can be performed with a median latency of 15 ms.",toward full elasticity in distributed static analysis: the case of callgraph analysis
1124,2-s2.0-85030774508,10.1145/3106237.3106270,"Trade-offs in continuous integration: Assurance, security, and flexibility",Hilton M.,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,2017-08-21,"Continuous integration (CI) systems automate the compilation, building, and testing of software. Despite CI being a widely used activity in software engineering, we do not know what motivates developers to use CI, and what barriers and unmet needs they face. Without such knowledge, developers make easily avoidable errors, tool builders invest in the wrong direction, and researchers miss opportunities for improving the practice of CI. We present a qualitative study of the barriers and needs developers face when using CI. We conduct semi-structured interviews with developers from different industries and development scales. We triangulate our findings by running two surveys. We find that developers face trade-offs between speed and certainty (Assurance), between better access and information security (Security), and between more configuration options and greater ease of use (Flexibility). We present implications of these trade-offs for developers, tool builders, and researchers.",Automated testing | Continuous integration,99,197-207,Conference Proceeding,Conference Paper,5.0,"Hilton, Michael;Nelson, Nicholas;Tunnell, Timothy;Marinov, Darko;Dig, Danny",56754178400;57189508480;57215878864;8730036800;13404654100,Oregon State University;University of Illinois Urbana-Champaign,United States;United States,"continuous integration (ci) systems automate the compilation, building, and testing of software. despite ci being a widely used activity in software engineering, we do not know what motivates developers to use ci, and what barriers and unmet needs they face. without such knowledge, developers make easily avoidable errors, tool builders invest in the wrong direction, and researchers miss opportunities for improving the practice of ci. we present a qualitative study of the barriers and needs developers face when using ci. we conduct semi-structured interviews with developers from different industries and development scales. we triangulate our findings by running two surveys. we find that developers face trade-offs between speed and certainty (assurance), between better access and information security (security), and between more configuration options and greater ease of use (flexibility). we present implications of these trade-offs for developers, tool builders, and researchers.","trade-offs in continuous integration: assurance, security, and flexibility"
1125,2-s2.0-85031328034,10.1145/3107411.3107481,Building applications for interactive data exploration in systems biology,Fjukstad B.,"ACM-BCB 2017 - Proceedings of the 8th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics",2017-08-20,"The significant increase in the rate of data generation by the systems biology community creates a need for interactive exploration tools to explore the resultant datasets. Such tools need to combine advanced statistical analyses, prior knowledge from biological databases, and interactive visualizations with intuitive user interfaces. Each specific research question potentially requires a specialized user interface and visualization methods. Although some features are application-specific, the underlying components of the data analysis tool can be shared and reused. Our approach for developing data exploration tools in systems biology builds on the microservice architecture that separates an application into smaller components which can communicate using language-agnostic protocols. We show that this design is well suited for bioinformatics applications where different tools written in different languages by different research groups is the norm. Packaging each service in a software container enables re-use and sharing of key components between applications, reducing development, deployment, and maintenance time. We demonstrate the viability of our approach through a web application, entitled MIxT blood-tumor, for exploring and comparing transcriptional profiles from blood and tumor samples in breast cancer patients. The application integrates advanced statistical software, up-to-date information from biological databases, and modern data visualization libraries.",Breast cancer | Interactive data exploration | Microservices | Software containers | Systems biology | Visualization,1,556-561,Conference Proceeding,Conference Paper,6.0,"Fjukstad, Bjørn;Lund, Eiliv;Dumeaux, Vanessa;Hallett, Michael;Olsen, Karina Standahl;Bongo, Lars Ailo",55027476600;55423514100;6507608734;57806628500;7202717264;8410086000,Concordia University;UiT Norges Arktiske Universitet,Canada;Norway,"the significant increase in the rate of data generation by the systems biology community creates a need for interactive exploration tools to explore the resultant datasets. such tools need to combine advanced statistical analyses, prior knowledge from biological databases, and interactive visualizations with intuitive user interfaces. each specific research question potentially requires a specialized user interface and visualization methods. although some features are application-specific, the underlying components of the data analysis tool can be shared and reused. our approach for developing data exploration tools in systems biology builds on the microservice architecture that separates an application into smaller components which can communicate using language-agnostic protocols. we show that this design is well suited for bioinformatics applications where different tools written in different languages by different research groups is the norm. packaging each service in a software container enables re-use and sharing of key components between applications, reducing development, deployment, and maintenance time. we demonstrate the viability of our approach through a web application, entitled mixt blood-tumor, for exploring and comparing transcriptional profiles from blood and tumor samples in breast cancer patients. the application integrates advanced statistical software, up-to-date information from biological databases, and modern data visualization libraries.",building applications for interactive data exploration in systems biology
1126,2-s2.0-85029415238,10.1109/QRS.2017.39,How do developers toggle breakpoints? observational studies,Petrillo F.,"Proceedings - 2017 IEEE International Conference on Software Quality, Reliability and Security, QRS 2017",2017-08-11,"One of the most important tasks in software maintenance is debugging. Developers perform debugging to fix faults and implement new features. Usually they use interactive development environments to perform their debugging sessions. To start an interactive debugging session, developers must set breakpoints. Choosing where to set breakpoints is a non-trivial task, yet few studies have investigated how developers set breakpoints during interactive debugging sessions. To understand how developers set breakpoints, we analysed more than 10 hours of 45 video-recorded debugging sessions, where a total of 307 breakpoints were set. We used the videos from two independent studies involving three software systems. We could observe that: (1) considerable time is spent by developers until they are able to set the first breakpoint; (2) when developers toggle breakpoints carefully, they complete tasks faster than developers who set (potential useless) breakpoints quickly; and (3) different developers set breakpoints in similar locations while working (independently) on the same tasks or different tasks. We discuss some implications of our observations for debugging activities.",Breakpoints | Debugging | Empirical software engineering | Interactive debugging,2,285-295,Conference Proceeding,Conference Paper,5.0,"Petrillo, Fabio;Mandian, Hyan;Yamashita, Aiko;Khomh, Foutse;Gueheneuc, Yann Gael",25655430600;57195633692;55576431200;24724747600;13613429100,OsloMet – storbyuniversitetet;Polytechnique Montréal;Universidade UniRitter,Norway;Canada;Brazil,"one of the most important tasks in software maintenance is debugging. developers perform debugging to fix faults and implement new features. usually they use interactive development environments to perform their debugging sessions. to start an interactive debugging session, developers must set breakpoints. choosing where to set breakpoints is a non-trivial task, yet few studies have investigated how developers set breakpoints during interactive debugging sessions. to understand how developers set breakpoints, we analysed more than 10 hours of 45 video-recorded debugging sessions, where a total of 307 breakpoints were set. we used the videos from two independent studies involving three software systems. we could observe that: (1) considerable time is spent by developers until they are able to set the first breakpoint; (2) when developers toggle breakpoints carefully, they complete tasks faster than developers who set (potential useless) breakpoints quickly; and (3) different developers set breakpoints in similar locations while working (independently) on the same tasks or different tasks. we discuss some implications of our observations for debugging activities.",how do developers toggle breakpoints? observational studies
1127,2-s2.0-85027233544,10.1021/acs.jproteome.7b00194,MsViz: A Graphical Software Tool for In-Depth Manual Validation and Quantitation of Post-translational Modifications,Martín-Campos T.,Journal of Proteome Research,2017-08-04,"Mass spectrometry (MS) has become the tool of choice for the large scale identification and quantitation of proteins and their post-translational modifications (PTMs). This development has been enabled by powerful software packages for the automated analysis of MS data. While data on PTMs of thousands of proteins can nowadays be readily obtained, fully deciphering the complexity and combinatorics of modification patterns even on a single protein often remains challenging. Moreover, functional investigation of PTMs on a protein of interest requires validation of the localization and the accurate quantitation of its changes across several conditions, tasks that often still require human evaluation. Software tools for large scale analyses are highly efficient but are rarely conceived for interactive, in-depth exploration of data on individual proteins. We here describe MsViz, a web-based and interactive software tool that supports manual validation of PTMs and their relative quantitation in small- and medium-size experiments. The tool displays sequence coverage information, peptide-spectrum matches, tandem MS spectra and extracted ion chromatograms through a single, highly intuitive interface. We found that MsViz greatly facilitates manual data inspection to validate PTM location and quantitate modified species across multiple samples.",data visualization | data-dependent acquisition | extracted ion chromatograms | manual validation | phosphorylation | post-translational modification | site localization | tandem mass spectrometry,7,3092-3101,Journal,Article,7.0,"Martín-Campos, Trinidad;Mylonas, Roman;Masselot, Alexandre;Waridel, Patrice;Petricevic, Tanja;Xenarios, Ioannis;Quadroni, Manfredo",57190050582;34880444700;6602855815;8521222300;36009044600;6602760768;6701808158,Swiss Institute of Bioinformatics;Centre Hospitalier Universitaire Vaudois;Université de Lausanne (UNIL),Switzerland;Switzerland;Switzerland,"mass spectrometry (ms) has become the tool of choice for the large scale identification and quantitation of proteins and their post-translational modifications (ptms). this development has been enabled by powerful software packages for the automated analysis of ms data. while data on ptms of thousands of proteins can nowadays be readily obtained, fully deciphering the complexity and combinatorics of modification patterns even on a single protein often remains challenging. moreover, functional investigation of ptms on a protein of interest requires validation of the localization and the accurate quantitation of its changes across several conditions, tasks that often still require human evaluation. software tools for large scale analyses are highly efficient but are rarely conceived for interactive, in-depth exploration of data on individual proteins. we here describe msviz, a web-based and interactive software tool that supports manual validation of ptms and their relative quantitation in small- and medium-size experiments. the tool displays sequence coverage information, peptide-spectrum matches, tandem ms spectra and extracted ion chromatograms through a single, highly intuitive interface. we found that msviz greatly facilitates manual data inspection to validate ptm location and quantitate modified species across multiple samples.",msviz: a graphical software tool for in-depth manual validation and quantitation of post-translational modifications
1128,2-s2.0-85023177336,10.1080/17460441.2017.1339032,Using ChEMBL web services for building applications and data processing workflows relevant to drug discovery,Nowotka M.M.,Expert Opinion on Drug Discovery,2017-08-03,"Introduction: ChEMBL is a manually curated database of bioactivity data on small drug-like molecules, used by drug discovery scientists. Among many access methods, a REST API provides programmatic access, allowing the remote retrieval of ChEMBL data and its integration into other applications. This approach allows scientists to move from a world where they go to the ChEMBL web site to search for relevant data, to one where ChEMBL data can be simply integrated into their everyday tools and work environment. Areas covered: This review highlights some of the audiences who may benefit from using the ChEMBL API, and the goals they can address, through the description of several use cases. The examples cover a team communication tool (Slack), a data analytics platform (KNIME), batch job management software (Luigi) and Rich Internet Applications. Expert opinion: The advent of web technologies, cloud computing and micro services oriented architectures have made REST APIs an essential ingredient of modern software development models. The widespread availability of tools consuming RESTful resources have made them useful for many groups of users. The ChEMBL API is a valuable resource of drug discovery bioactivity data for professional chemists, chemistry students, data scientists, scientific and web developers.",API | ChEMBL | KNIME | Luigi | pipeline | Python | REST | service | Slack | workflow,18,757-767,Journal,Review,6.0,"Nowotka, Michał M.;Gaulton, Anna;Mendez, David;Bento, A. Patricia;Hersey, Anne;Leach, Andrew",56626093800;6508215905;57193731923;37036766900;6602105185;7102097878,European Bioinformatics Institute,United Kingdom,"introduction: chembl is a manually curated database of bioactivity data on small drug-like molecules, used by drug discovery scientists. among many access methods, a rest api provides programmatic access, allowing the remote retrieval of chembl data and its integration into other applications. this approach allows scientists to move from a world where they go to the chembl web site to search for relevant data, to one where chembl data can be simply integrated into their everyday tools and work environment. areas covered: this review highlights some of the audiences who may benefit from using the chembl api, and the goals they can address, through the description of several use cases. the examples cover a team communication tool (slack), a data analytics platform (knime), batch job management software (luigi) and rich internet applications. expert opinion: the advent of web technologies, cloud computing and micro services oriented architectures have made rest apis an essential ingredient of modern software development models. the widespread availability of tools consuming restful resources have made them useful for many groups of users. the chembl api is a valuable resource of drug discovery bioactivity data for professional chemists, chemistry students, data scientists, scientific and web developers.",using chembl web services for building applications and data processing workflows relevant to drug discovery
1129,2-s2.0-84976303093,10.1007/s11042-016-3662-1,A synthetic research on the multimedia data encryption based mobile computing security enhancement model and multi-channel mobile human computer interaction framework,Li J.,Multimedia Tools and Applications,2017-08-01,"With the development of computer network, people could obtain information through the network with stronger impulsion, the dependence of the requirements also becomes higher, this is not only reflected in the increase of information, but to obtain and submit more reflected in real-time and easy to access to information on the pressing needs of the. Therefore, people devoted all aspects from the terminal, network and software platforms to make unremitting efforts. Under this basis, we conduct synthetic research on the data encryption based mobile computing security enhancement model and multi-channel mobile human computer interaction framework in this paper. We firstly introduce the discrete-time Hopfield neural network based data encryption algorithm beyond the analysis on the information flow security and type based model, data security review and attack model under mobile computing environment. We improve learning algorithm of the MD method to avoid the sample mobile and cross interference problems of Hebb rule. Later, we integrate the multi-channel concept to propose the new multi-channel man–machine interaction. In our framework, the 3D interactive technology, speech recognition and synthesis technology, natural language understanding and processing technology, eye tracking technology, posture, input, tactile, force display basic technology are taken into consideration for the synthetic analysis. The result from the experimental simulation proves that our methodology obtains better effectiveness and feasibility from both the angels of data security and interface experience.",Data encryption | Human computer interaction | Mobile computing | Mobile multimedia | Multi-channel framework | Security enhancement,9,16963-16987,Journal,Article,1.0,"Li, Jun",55900081000,Chinese Academy of Sciences,China,"with the development of computer network, people could obtain information through the network with stronger impulsion, the dependence of the requirements also becomes higher, this is not only reflected in the increase of information, but to obtain and submit more reflected in real-time and easy to access to information on the pressing needs of the. therefore, people devoted all aspects from the terminal, network and software platforms to make unremitting efforts. under this basis, we conduct synthetic research on the data encryption based mobile computing security enhancement model and multi-channel mobile human computer interaction framework in this paper. we firstly introduce the discrete-time hopfield neural network based data encryption algorithm beyond the analysis on the information flow security and type based model, data security review and attack model under mobile computing environment. we improve learning algorithm of the md method to avoid the sample mobile and cross interference problems of hebb rule. later, we integrate the multi-channel concept to propose the new multi-channel man–machine interaction. in our framework, the 3d interactive technology, speech recognition and synthesis technology, natural language understanding and processing technology, eye tracking technology, posture, input, tactile, force display basic technology are taken into consideration for the synthetic analysis. the result from the experimental simulation proves that our methodology obtains better effectiveness and feasibility from both the angels of data security and interface experience.",a synthetic research on the multimedia data encryption based mobile computing security enhancement model and multi-channel mobile human computer interaction framework
1130,2-s2.0-85029453240,10.23919/INM.2017.7987358,Virtualization of radio access network by Virtual Machine and Docker: Practice and performance analysis,Gopalasingham A.,Proceedings of the IM 2017 - 2017 IFIP/IEEE International Symposium on Integrated Network and Service Management,2017-07-20,"Software defined networking (SDN) and network function virtualization (NFV) are the embraced technologies for the backhauling of future 5G networks. Virtual Machine (VM) and Docker container based deployments have received much attention. This paper presents the virtualization of a prototyped software defined radio access network (RAN) architecture by using VMs and Docker containers. In addition, it provides an analytical model for the generalized software defined RAN architecture with the practice of VM based and Docker container based implementations. Using measurements obtained from the two testbeds and the introduced queuing model, we compare their performances and analyze the two different architectures. Results verify the superiority of the Docker technology. Some observations from the behavior of the testbeds are concluded for a better understanding of the VM and Docker container based technologies for the future development of 5G SDN controller.",5G | Docker container | performance analysis | radio access network | SDN | Virtual Machine,8,680-685,Conference Proceeding,Conference Paper,4.0,"Gopalasingham, Aravinthan;Herculea, Dalia Georgiana;Chen, Chung Shue;Roullet, Laurent",55699154100;57056516000;44760962900;9040899600,Nokia Bell Labs,United States,"software defined networking (sdn) and network function virtualization (nfv) are the embraced technologies for the backhauling of future 5g networks. virtual machine (vm) and docker container based deployments have received much attention. this paper presents the virtualization of a prototyped software defined radio access network (ran) architecture by using vms and docker containers. in addition, it provides an analytical model for the generalized software defined ran architecture with the practice of vm based and docker container based implementations. using measurements obtained from the two testbeds and the introduced queuing model, we compare their performances and analyze the two different architectures. results verify the superiority of the docker technology. some observations from the behavior of the testbeds are concluded for a better understanding of the vm and docker container based technologies for the future development of 5g sdn controller.",virtualization of radio access network by virtual machine and docker: practice and performance analysis
1131,2-s2.0-85027707946,10.1109/ICSE.2017.28,Stochastic Optimization of Program Obfuscation,Liu H.,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering, ICSE 2017",2017-07-19,"Program obfuscation is a common practice in software development to obscure source code or binary code, in order to prevent humans from understanding the purpose or logic of software. It protects intellectual property and deters malicious attacks. While tremendous efforts have been devoted to the development of various obfuscation techniques, we have relatively little knowledge on how to most effectively use them together. The biggest challenge lies in identifying the most effective combination of obfuscation techniques. This paper presents a unified framework to optimize program obfuscation. Given an input program P and a set T of obfuscation transformations, our technique can automatically identify a sequence seq = t1, t2,.., tn (&ForAll;i &Element; [1, n].Ti &Element; T), such that applying ti in order on P yields the optimal obfuscation performance. We model the process of searching for seq as a mathematical optimization problem. The key technical contributions of this paper are: (1) an obscurity language model to assess obfuscation effectiveness/optimality, and (2) a guided stochastic algorithm based on Markov chain Monte Carlo methods to search for the optimal solution seq. We have realized the framework in a tool Closure∗ for JavaScript, and evaluated it on 25 most starred JavaScript projects on GitHub (19K lines of code). Our machinery study shows that Closure∗ outperforms the well-known Google Closure Compiler by defending 26% of the attacks initiated by JSNice. Our human study also reveals that Closure∗ is practical and can reduce the human attack success rate by 30%.",markov chain monte carlo methods | obscurity language model | program obfuscation,20,221-231,Conference Proceeding,Conference Paper,6.0,"Liu, Han;Sun, Chengnian;Su, Zhendong;Jiang, Yu;Gu, Ming;Sun, Jiaguang",56468215400;35113870200;7402248744;56193157500;57202891851;7410371821,"Tsinghua University;University of California, Davis",China;United States,"program obfuscation is a common practice in software development to obscure source code or binary code, in order to prevent humans from understanding the purpose or logic of software. it protects intellectual property and deters malicious attacks. while tremendous efforts have been devoted to the development of various obfuscation techniques, we have relatively little knowledge on how to most effectively use them together. the biggest challenge lies in identifying the most effective combination of obfuscation techniques. this paper presents a unified framework to optimize program obfuscation. given an input program p and a set t of obfuscation transformations, our technique can automatically identify a sequence seq = t1, t2,.., tn (&forall;i &element; [1, n].ti &element; t), such that applying ti in order on p yields the optimal obfuscation performance. we model the process of searching for seq as a mathematical optimization problem. the key technical contributions of this paper are: (1) an obscurity language model to assess obfuscation effectiveness/optimality, and (2) a guided stochastic algorithm based on markov chain monte carlo methods to search for the optimal solution seq. we have realized the framework in a tool closure∗ for javascript, and evaluated it on 25 most starred javascript projects on github (19k lines of code). our machinery study shows that closure∗ outperforms the well-known google closure compiler by defending 26% of the attacks initiated by jsnice. our human study also reveals that closure∗ is practical and can reduce the human attack success rate by 30%.",stochastic optimization of program obfuscation
1132,2-s2.0-85027701347,10.1109/ICSE.2017.75,To Type or Not to Type: Quantifying Detectable Bugs in JavaScript,Gao Z.,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering, ICSE 2017",2017-07-19,"JavaScript is growing explosively and is now used in large mature projects even outside the web domain. JavaScript is also a dynamically typed language for which static type systems, notably Facebook's Flow and Microsoft's TypeScript, have been written. What benefits do these static type systems provide? Leveraging JavaScript project histories, we select a fixed bug and check out the code just prior to the fix. We manually add type annotations to the buggy code and test whether Flow and TypeScript report an error on the buggy code, thereby possibly prompting a developer to fix the bug before its public release. We then report the proportion of bugs on which these type systems reported an error. Evaluating static type systems against public bugs, which have survived testing and review, is conservative: it understates their effectiveness at detecting bugs during private development, not to mention their other benefits such as facilitating code search/completion and serving as documentation. Despite this uneven playing field, our central finding is that both static type systems find an important percentage of public bugs: both Flow 0.30 and TypeScript 2.0 successfully detect 15%!.",Flow | JavaScript | mining software repositories | static type systems | TypeScript,36,758-769,Conference Proceeding,Conference Paper,3.0,"Gao, Zheng;Bird, Christian;Barr, Earl T.",57191110351;17433640400;7005643860,University College London;Microsoft Research,United Kingdom;United States,"javascript is growing explosively and is now used in large mature projects even outside the web domain. javascript is also a dynamically typed language for which static type systems, notably facebook's flow and microsoft's typescript, have been written. what benefits do these static type systems provide? leveraging javascript project histories, we select a fixed bug and check out the code just prior to the fix. we manually add type annotations to the buggy code and test whether flow and typescript report an error on the buggy code, thereby possibly prompting a developer to fix the bug before its public release. we then report the proportion of bugs on which these type systems reported an error. evaluating static type systems against public bugs, which have survived testing and review, is conservative: it understates their effectiveness at detecting bugs during private development, not to mention their other benefits such as facilitating code search/completion and serving as documentation. despite this uneven playing field, our central finding is that both static type systems find an important percentage of public bugs: both flow 0.30 and typescript 2.0 successfully detect 15%!.",to type or not to type: quantifying detectable bugs in javascript
1134,2-s2.0-85027440091,10.1109/ICCCT2.2017.7972274,Automation approach for cocos-2dx based multi-player card game for web and mobile,Purushothaman S.K.,"Proceedings of the 2017 2nd International Conference on Computing and Communications Technologies, ICCCT 2017",2017-07-07,"Using automation to ensure reliability of a tricky card based game application is not a child's play, especially when the underlying engine is cocos-2dx, which is the world's no. 1 open-source and a cross-platform game development platform. This paper explores the challenges that can be faced while automating a game developed using cocos-2dx, such as dynamic rendering of game elements, overcoming the limitations in using automation tools like selenium in the absence of any locators to identify the visible or active elements to perform any operation. This paper further discusses the approach to bring efficient, generic and re-usable solution for these challenges while automating a multiplayer card game developed using cocos-2dx. This multi-layered approach spans across the following areas: 1) The mechanism for working and communicating with cocos-2dx web and native game client. 2) Approach for automating multiplayer game using FSM. 3) Automating the game play based on game rules which follows a heuristic approach. The benefit of this automation approach is that it makes the code 'device agnostic, which helps to run the same code against multiple devices of varying screen size and resolutions. This approach also makes the code robust, reducing any false failures since the interaction with the client is done via Javascript, which lot of UI automation tool still does not guarantee.",Cocos-2dx | FSM | Heuristic | Multi-player card game,1,222-225,Conference Proceeding,Conference Paper,5.0,"Purushothaman, Sarath Kumar;Kashyap, Nishant;Singh, Viral;Bharti, Abhishek;Sawant, Sanjeed",57195359694;57225686001;57195358115;57195362071;57195361513,Play Games 247 Private Limited,India,"using automation to ensure reliability of a tricky card based game application is not a child's play, especially when the underlying engine is cocos-2dx, which is the world's no. 1 open-source and a cross-platform game development platform. this paper explores the challenges that can be faced while automating a game developed using cocos-2dx, such as dynamic rendering of game elements, overcoming the limitations in using automation tools like selenium in the absence of any locators to identify the visible or active elements to perform any operation. this paper further discusses the approach to bring efficient, generic and re-usable solution for these challenges while automating a multiplayer card game developed using cocos-2dx. this multi-layered approach spans across the following areas: 1) the mechanism for working and communicating with cocos-2dx web and native game client. 2) approach for automating multiplayer game using fsm. 3) automating the game play based on game rules which follows a heuristic approach. the benefit of this automation approach is that it makes the code 'device agnostic, which helps to run the same code against multiple devices of varying screen size and resolutions. this approach also makes the code robust, reducing any false failures since the interaction with the client is done via javascript, which lot of ui automation tool still does not guarantee.",automation approach for cocos-2dx based multi-player card game for web and mobile
1135,2-s2.0-85027043733,10.1109/MOBILESoft.2017.16,Configuration Service for Mobile Apps,Guy-Ifergan N.,"Proceedings - 2017 IEEE/ACM 4th International Conference on Mobile Software Engineering and Systems, MOBILESoft 2017",2017-07-07,"Keeping pace with the market requires software to be shipped quickly, in rapid release cycles with a strong feedback loop. Managing and controlling these changes become complex, especially in the mobile world. In mobile applications, unlike in the Web world, the user chooses whether to download updates or to ignore them, and rollbacks are typically not an option. This paper describes a centralized service that supports managing configuration changes for mobile applications and their backend systems. We describe which implementation decisions we took for our configuration service and how the service was used to support context-based customization of the applications based on user segmentation.",Mobile application development | mobile configuration system | mobile devops,1,209-210,Conference Proceeding,Conference Paper,4.0,"Guy-Ifergan, Nili;Pikus, Dmitri;Ben-Harrush, Idan;Eisenberg, Vadim",38361431000;57195314605;36460550800;38861461300,IBM Research - Haifa,Israel,"keeping pace with the market requires software to be shipped quickly, in rapid release cycles with a strong feedback loop. managing and controlling these changes become complex, especially in the mobile world. in mobile applications, unlike in the web world, the user chooses whether to download updates or to ignore them, and rollbacks are typically not an option. this paper describes a centralized service that supports managing configuration changes for mobile applications and their backend systems. we describe which implementation decisions we took for our configuration service and how the service was used to support context-based customization of the applications based on user segmentation.",configuration service for mobile apps
1137,2-s2.0-85027163930,10.1109/VACE.2017.6,Type-Safe Evolution of Web Services,Campinhos J.,"Proceedings - 2017 IEEE/ACM 2nd International Workshop on Variability and Complexity in Software Design, VACE 2017",2017-07-03,"Applications based on micro or web services have had significant growth due to the exponential increase in the use of mobile devices. However, using such kind of loosely coupled interfaces provides almost no guarantees to the developer in terms of evolution. Changes to service interfaces can be introduced at any moment, which may cause the system to fail due to mismatches between communicating parts. In this paper, we present a programming model that allows the development of web service applications, server end-points and their clients, in such a way that the evolution of services' implementation does not cause the disruption of the client. Our approach is based on a type based code slicing technique that ensures that each version only refers to type compatible code, of the same version or of a compatible version, and that each client request is redirected to the most recent type compatible version implemented by the server. We abstract the notion of version and parametrize type compatibility on the relation between versions. The relation between versions is tagged with compatibility levels, so to capture the common conventions used in software development. Our implementation allows multiple versions of a service to be deployed simultaneously, while reusing code between versions in a type safe way. We describe a prototype framework, based on code transformation, for server-side JavaScript code, and using Flow as verification tool.",API evolution | JavaScript | type safe | web services,5,20-26,Conference Proceeding,Conference Paper,3.0,"Campinhos, João;Seco, João Costa;Cunha, Jácome",57195327270;56948781800;23983985900,Universidade Nova de Lisboa,Portugal,"applications based on micro or web services have had significant growth due to the exponential increase in the use of mobile devices. however, using such kind of loosely coupled interfaces provides almost no guarantees to the developer in terms of evolution. changes to service interfaces can be introduced at any moment, which may cause the system to fail due to mismatches between communicating parts. in this paper, we present a programming model that allows the development of web service applications, server end-points and their clients, in such a way that the evolution of services' implementation does not cause the disruption of the client. our approach is based on a type based code slicing technique that ensures that each version only refers to type compatible code, of the same version or of a compatible version, and that each client request is redirected to the most recent type compatible version implemented by the server. we abstract the notion of version and parametrize type compatibility on the relation between versions. the relation between versions is tagged with compatibility levels, so to capture the common conventions used in software development. our implementation allows multiple versions of a service to be deployed simultaneously, while reusing code between versions in a type safe way. we describe a prototype framework, based on code transformation, for server-side javascript code, and using flow as verification tool.",type-safe evolution of web services
1141,2-s2.0-85050615717,10.1109/ICONDA.2017.8270395,Pigeon-table: A quick prototyping tool using twitter bootstraps and AngularJS for data-driven web application development,Nen V.Y.,"1st International Conference on Computer and Drone Applications: Ethical Integration of Computer and Drone Technology for Humanity Sustainability, IConDA 2017",2017-07-02,"Data-driven web applications are now taking over the role of traditional desktop applications as it is more convenient to the end user. However, developing a web application is considered challenging especially for junior web developers due to development processes, e.g. selection of development frameworks, learning the framework with lengthy documentations as well as experiment, or integrating the framework during the development. In this paper we proposed and developed a quick prototyping tool, 'pigeon-table', for data-driven web application development specifically focusing on data retrieval from MySQL database and render the data into an interactive table in a web application. The aims of this project are, 1) to optimize web developers' productivity in web application development as the tool is straightforward and simple, and 2) to enhance end user browsing experience with an interactive table in the data-driven web application.",AngularJS | Bootstraps | data-driven web application | MySQL | ngPigeon project | pigeon-table | web application development,5,33-37,Conference Proceeding,Conference Paper,2.0,"Nen, Voon Yang;Ann, Ong Chin",57203124768;50861046900,Swinburne University of Technology Sarawak Campus,Malaysia,"data-driven web applications are now taking over the role of traditional desktop applications as it is more convenient to the end user. however, developing a web application is considered challenging especially for junior web developers due to development processes, e.g. selection of development frameworks, learning the framework with lengthy documentations as well as experiment, or integrating the framework during the development. in this paper we proposed and developed a quick prototyping tool, 'pigeon-table', for data-driven web application development specifically focusing on data retrieval from mysql database and render the data into an interactive table in a web application. the aims of this project are, 1) to optimize web developers' productivity in web application development as the tool is straightforward and simple, and 2) to enhance end user browsing experience with an interactive table in the data-driven web application.",pigeon-table: a quick prototyping tool using twitter bootstraps and angularjs for data-driven web application development
1142,2-s2.0-85050681286,10.1109/ICAwST.2017.8256478,Making machine-learning tools accessible to language teachers and other non-Techies: T-SNE-lab and rocanr as first examples,Hung C.K.,"Proceedings - 2017 IEEE 8th International Conference on Awareness Science and Technology, iCAST 2017",2017-07-01,"Machine learning advancements could greatly benefit the general public. Many programs or even trained weight matrices are available as open source software or free download. At its present form, however, most results are not directly accessible to most people. We present a front end for the t-SNE algorithm and a front-end for querying English language word embedding as examples to illustrate what's needed to make these results more accessible to people outside this field. The way their usage can be combined also demonstrates the author's envisioned development of such tools in the future, following the unix tools philosophy.",dimensionality reduction | general education | machine learning | natural language processing | popular science | scripting | user interface | visualization | word embedding,0,355-358,Conference Proceeding,Conference Paper,1.0,"Hung, Chao Kuei",14031373100,Chaoyang University of Technology,Taiwan,"machine learning advancements could greatly benefit the general public. many programs or even trained weight matrices are available as open source software or free download. at its present form, however, most results are not directly accessible to most people. we present a front end for the t-sne algorithm and a front-end for querying english language word embedding as examples to illustrate what's needed to make these results more accessible to people outside this field. the way their usage can be combined also demonstrates the author's envisioned development of such tools in the future, following the unix tools philosophy.",making machine-learning tools accessible to language teachers and other non-techies: t-sne-lab and rocanr as first examples
1143,2-s2.0-85047453325,10.1109/ICCONS.2017.8250595,Workspace management and hot-seating,Nithin M.,"Proceedings of the 2017 International Conference on Intelligent Computing and Control Systems, ICICCS 2017",2017-07-01,"In today's world, real estate and facilities managers are facing an increase in demands for more effective management of the existing facilities including flexibility of the workplace, reducing the carbon footprint and sustainability. Organizations are no longer able to afford to fully maintain unused space due to the economic slowdown. In today's working environment, there are more remote and mobile employees in the companies. The aim of this paper is to allow organizations to make effective use of available real-estate space by managing the workspace. The above objective is practically implemented in one of the software organization. The entire work is thus presented in this paper as case study. The approach which is followed has proven to be effective and thereby can be adopted in all organizations.",Configuring Workspace | Displaying Workspace | Facility Management | Hot-Seating | Workspace Management,1,900-903,Conference Proceeding,Conference Paper,2.0,"Nithin, M.;Suma, V.",57215282010;57217221127,Dayananda Sagar College of Engineering,India,"in today's world, real estate and facilities managers are facing an increase in demands for more effective management of the existing facilities including flexibility of the workplace, reducing the carbon footprint and sustainability. organizations are no longer able to afford to fully maintain unused space due to the economic slowdown. in today's working environment, there are more remote and mobile employees in the companies. the aim of this paper is to allow organizations to make effective use of available real-estate space by managing the workspace. the above objective is practically implemented in one of the software organization. the entire work is thus presented in this paper as case study. the approach which is followed has proven to be effective and thereby can be adopted in all organizations.",workspace management and hot-seating
1145,2-s2.0-85017101045,10.1007/s10109-017-0248-z,Applicability of open-source web mapping libraries for building massive Web GIS clients,Farkas G.,Journal of Geographical Systems,2017-07-01,"The increasing capabilities of web browsers and the growing spread of JavaScript have an impact on the development of web-based GIS systems. While in traditional Web GIS applications the client-side component is only responsible for creating representation models, modern geographically enabled JavaScript libraries have extended capabilities, making them capable of doing extensive tasks, like complex geographical analyses. This paper identifies the most capable libraries for being the basis of a Web GIS client (Cesium, Leaflet, NASA Web World Wind, OpenLayers 2, and OpenLayers 3) and compares them. The libraries are compared by their GIS feature coverage and some quality metrics. OpenLayers 3 is identified for being the most capable library by supporting nearly 60% of the examined GIS features, its small size, and moderate learning curve. For comparing the learning curves of JavaScript libraries, a new metric named Approximate Learning Curve for JavaScript is proposed, which is based on other software metrics.",Approximate Learning Curve for Javascript | Client-side library | Comparison | Massive client | Software metrics | Web GIS,19,273-295,Journal,Article,1.0,"Farkas, Gábor",57203507677,Pécsi Tudományegyetem,Hungary,"the increasing capabilities of web browsers and the growing spread of javascript have an impact on the development of web-based gis systems. while in traditional web gis applications the client-side component is only responsible for creating representation models, modern geographically enabled javascript libraries have extended capabilities, making them capable of doing extensive tasks, like complex geographical analyses. this paper identifies the most capable libraries for being the basis of a web gis client (cesium, leaflet, nasa web world wind, openlayers 2, and openlayers 3) and compares them. the libraries are compared by their gis feature coverage and some quality metrics. openlayers 3 is identified for being the most capable library by supporting nearly 60% of the examined gis features, its small size, and moderate learning curve. for comparing the learning curves of javascript libraries, a new metric named approximate learning curve for javascript is proposed, which is based on other software metrics.",applicability of open-source web mapping libraries for building massive web gis clients
1146,2-s2.0-85006716883,10.1007/s00607-016-0528-3,A taxonomy of cross-language linking mechanisms in open source frameworks,Mayer P.,Computing,2017-07-01,"Non-trivial software systems are written using multiple programming languages. While the logic of a system is encoded using one or several general-purpose languages, more specialized parts of the systems are realized using domain-specific languages for aspects such as the user interface, configuration mechanisms, querying of databases, or support for internationalization. To bind all of these different parts together, the artifacts in individual languages are connected by using cross-language links which address artifacts across language boundaries. Many different ways for specifying and using such links have been conceived, and developers have to adhere to the concrete rules mandated by the runtime, framework or library which later performs the link resolution. In this paper, we present a taxonomy of the mechanisms of encoding cross-language linking in well-known open source frameworks from a developers perspective, which shows the choices that have been made and the options available in practice. We describe the process we followed, which is based in part on a survey of language combinations on GitHub and a survey of professional developers, list the dimensions and characteristics of our taxonomy in full, show the classifications of 22 frameworks and mechanisms, four of which are described in detail, and discuss the impact of the choices on application developers.",Classification | Cross-language linking | DSLs | Frameworks | GPLs | Multi-language development | Open-source software | Polyglot programming | Software maintenance | Taxonomy,5,701-724,Journal,Article,1.0,"Mayer, Philip",22980557600,Ludwig-Maximilians-Universität München,Germany,"non-trivial software systems are written using multiple programming languages. while the logic of a system is encoded using one or several general-purpose languages, more specialized parts of the systems are realized using domain-specific languages for aspects such as the user interface, configuration mechanisms, querying of databases, or support for internationalization. to bind all of these different parts together, the artifacts in individual languages are connected by using cross-language links which address artifacts across language boundaries. many different ways for specifying and using such links have been conceived, and developers have to adhere to the concrete rules mandated by the runtime, framework or library which later performs the link resolution. in this paper, we present a taxonomy of the mechanisms of encoding cross-language linking in well-known open source frameworks from a developers perspective, which shows the choices that have been made and the options available in practice. we describe the process we followed, which is based in part on a survey of language combinations on github and a survey of professional developers, list the dimensions and characteristics of our taxonomy in full, show the classifications of 22 frameworks and mechanisms, four of which are described in detail, and discuss the impact of the choices on application developers.",a taxonomy of cross-language linking mechanisms in open source frameworks
1148,2-s2.0-85026515162,10.1109/MSR.2017.55,Structure and evolution of package dependency networks,Kikas R.,IEEE International Working Conference on Mining Software Repositories,2017-06-29,"Software developers often include available open-source software packages into their projects to minimize redundant effort. However, adding a package to a project can also introduce risks, which can propagate through multiple levels of dependencies. Currently, not much is known about the structure of open-source package ecosystems of popular programming languages and the extent to which transitive bug propagation is possible. This paper analyzes the dependency network structure and evolution of the JavaScript, Ruby, and Rust ecosystems. The reported results reveal significant differences across language ecosystems. The results indicate that the number of transitive dependencies for JavaScript has grown 60% over the last year, suggesting that developers should look more carefully into their dependencies to understand what exactly is included. The study also reveals that vulnerability to a removal of the most popular package is increasing, yet most other packages have a decreasing impact on vulnerability. The findings of this study can inform the development of dependency management tools.",Dependency Management | Mining Software Repositories | Software Ecosystems | Software Evolution,67,102-112,Conference Proceeding,Conference Paper,4.0,"Kikas, Riivo;Gousios, Georgios;Dumas, Marlon;Pfahl, Dietmar",56964359900;14819567500;7201354798;6603033193,Tartu Ülikool;Delft University of Technology,Estonia;Netherlands,"software developers often include available open-source software packages into their projects to minimize redundant effort. however, adding a package to a project can also introduce risks, which can propagate through multiple levels of dependencies. currently, not much is known about the structure of open-source package ecosystems of popular programming languages and the extent to which transitive bug propagation is possible. this paper analyzes the dependency network structure and evolution of the javascript, ruby, and rust ecosystems. the reported results reveal significant differences across language ecosystems. the results indicate that the number of transitive dependencies for javascript has grown 60% over the last year, suggesting that developers should look more carefully into their dependencies to understand what exactly is included. the study also reveals that vulnerability to a removal of the most popular package is increasing, yet most other packages have a decreasing impact on vulnerability. the findings of this study can inform the development of dependency management tools.",structure and evolution of package dependency networks
1150,2-s2.0-85019678867,10.1177/1460458216628312,Development of a web-based epidemiological surveillance system with health system response for improving maternal and newborn health: Field-testing in Thailand,Liabsuetrakul T.,Health Informatics Journal,2017-06-01,"Surveillance systems are yet to be integrated with health information systems for improving the health of pregnant mothers and their newborns, particularly in developing countries. This study aimed to develop a web-based epidemiological surveillance system for maternal and newborn health with integration of action-oriented responses and automatic data analysis with results presentations and to assess the system acceptance by nurses and doctors involved in various hospitals in southern Thailand. Freeware software and scripting languages were used. The system can be run on different platforms, and it is accessible via various electronic devices. Automatic data analysis with results presentations in the forms of graphs, tables and maps was part of the system. A multi-level security system was incorporated into the program. Most doctors and nurses involved in the study felt the system was easy to use and useful. This system can be integrated into country routine reporting system for monitoring maternal and newborn health and survival.",electronic and mobile health | electronic health records | maternal and newborn health | surveillance system | web-based information service,5,109-123,Journal,Article,5.0,"Liabsuetrakul, Tippawan;Prappre, Tagoon;Pairot, Pakamas;Oumudee, Nurlisa;Islam, Monir",55917610700;36447714900;57194326506;41661802900;23993774500,Songkhla Rajabhat University;Organisation Mondiale de la Santé;Prince of Songkla University,Thailand;Switzerland;Thailand,"surveillance systems are yet to be integrated with health information systems for improving the health of pregnant mothers and their newborns, particularly in developing countries. this study aimed to develop a web-based epidemiological surveillance system for maternal and newborn health with integration of action-oriented responses and automatic data analysis with results presentations and to assess the system acceptance by nurses and doctors involved in various hospitals in southern thailand. freeware software and scripting languages were used. the system can be run on different platforms, and it is accessible via various electronic devices. automatic data analysis with results presentations in the forms of graphs, tables and maps was part of the system. a multi-level security system was incorporated into the program. most doctors and nurses involved in the study felt the system was easy to use and useful. this system can be integrated into country routine reporting system for monitoring maternal and newborn health and survival.",development of a web-based epidemiological surveillance system with health system response for improving maternal and newborn health: field-testing in thailand
1152,2-s2.0-84982108474,10.1007/s11042-016-3729-z,Designing and evaluating the usability of an API for real-time multimedia services in the Internet,López-Fernández L.,Multimedia Tools and Applications,2017-06-01,"In the last few years, multimedia technologies in general, and Real-Time multimedia Communications (RTC) in particular, are becoming mainstream among WWW and smartphone developers, who have an increasing interest in richer media capabilities for creating their applications. The engineering literature proposing novel algorithms, protocols and architectures for managing and processing multimedia information is currently overwhelming. However, most of these results do not arrive to applications due to the lack of simple and usable APIs. Interestingly, in this context in which APIs are the critical ingredient for reaching wide developer audiences, the scientific literature about multimedia APIs and their usability is scarce. In this paper we try to contribute to fill this gap by proposing the RTC Media API: a novel type of API designed with the aim of making simple for developers the use of latest trends in RTC multimedia including WebRTC, Video Content Analysis or Augmented Reality. We provide a specification of such API and discuss how it satisfies a set of design requirements including programming-language agnosticism, adaptation to cloud environments, support to multisensory multimedia, etc. After that, we describe an implementation of such an API that has been created in the context of the Kurento open source software project, and present a study evaluating the API usability performed in a group of more than 40 professional developers distributed worldwide. In the light of the obtained results, we conclude that the usability of the API is adequate across the main development activities (i.e. API learning, code creation and code maintenance), with an average usability score of 3.39 over 5 in a Likert scale, and that this result is robust with respect to developers’ profiles, cultures, professional experiences and preferred programming languages.",Application Programming Interfaces | Cognitive dimensions of notations | Media server | Multimedia processing | Multimedia tools and applications | Real-time multimedia communications | WebRTC,9,14247-14304,Journal,Article,4.0,"López-Fernández, Luis;García, Boni;Gallego, Micael;Gortázar, Francisco",7201949992;24724315500;57202908535;24179404100,Universidad Rey Juan Carlos,Spain,"in the last few years, multimedia technologies in general, and real-time multimedia communications (rtc) in particular, are becoming mainstream among www and smartphone developers, who have an increasing interest in richer media capabilities for creating their applications. the engineering literature proposing novel algorithms, protocols and architectures for managing and processing multimedia information is currently overwhelming. however, most of these results do not arrive to applications due to the lack of simple and usable apis. interestingly, in this context in which apis are the critical ingredient for reaching wide developer audiences, the scientific literature about multimedia apis and their usability is scarce. in this paper we try to contribute to fill this gap by proposing the rtc media api: a novel type of api designed with the aim of making simple for developers the use of latest trends in rtc multimedia including webrtc, video content analysis or augmented reality. we provide a specification of such api and discuss how it satisfies a set of design requirements including programming-language agnosticism, adaptation to cloud environments, support to multisensory multimedia, etc. after that, we describe an implementation of such an api that has been created in the context of the kurento open source software project, and present a study evaluating the api usability performed in a group of more than 40 professional developers distributed worldwide. in the light of the obtained results, we conclude that the usability of the api is adequate across the main development activities (i.e. api learning, code creation and code maintenance), with an average usability score of 3.39 over 5 in a likert scale, and that this result is robust with respect to developers’ profiles, cultures, professional experiences and preferred programming languages.",designing and evaluating the usability of an api for real-time multimedia services in the internet
1153,2-s2.0-84957706778,10.1007/s11219-016-9308-8,Testing of model-driven development applications,Marín B.,Software Quality Journal,2017-06-01,"Human resource management practices are key for the success of software development projects. Practices that promote knowledge sharing and organizational learning are positively related to development–effort curves, and thus software companies are looking for different alternatives oriented to promoting these practices. The model-driven development (MDD) paradigm is positioned as one of the best alternatives for reutilization of development knowledge. In particular, this paradigm considers the specification of conceptual models that can be used as input for automatic code generation to different target platforms. However, testing of applications developed through MDD solutions is still performed by the manual definition and execution of test cases by testers, which negatively impacts in the time reduction obtained from automatic code generation and the reutilization of knowledge generated during the MDD project execution. To address this issue, this paper presents a testing approach that automatically generates executable test cases for software developed by using MDD technologies.",Abstract test case | Concrete test case | Model-based testing | Model-driven development,4,407-435,Journal,Article,5.0,"Marín, Beatriz;Gallardo, Carlos;Quiroga, Diego;Giachetti, Giovanni;Serral, Estefanía",24481674800;57104873800;57215457825;24481355300;19934565100,KU Leuven;Universidad Diego Portales;Universidad Andrés Bello,Belgium;Chile;Chile,"human resource management practices are key for the success of software development projects. practices that promote knowledge sharing and organizational learning are positively related to development–effort curves, and thus software companies are looking for different alternatives oriented to promoting these practices. the model-driven development (mdd) paradigm is positioned as one of the best alternatives for reutilization of development knowledge. in particular, this paradigm considers the specification of conceptual models that can be used as input for automatic code generation to different target platforms. however, testing of applications developed through mdd solutions is still performed by the manual definition and execution of test cases by testers, which negatively impacts in the time reduction obtained from automatic code generation and the reutilization of knowledge generated during the mdd project execution. to address this issue, this paper presents a testing approach that automatically generates executable test cases for software developed by using mdd technologies.",testing of model-driven development applications
1154,2-s2.0-85025629708,10.1109/SIEDS.2017.7937752,A framework for building type-safe configurations for JVM using code generation techniques,Puripunpinyo H.,"2017 Systems and Information Engineering Design Symposium, SIEDS 2017",2017-05-31,"One of the common errors in software development is a configuration mistake. This type of error can have a wide range of severity levels. Consequences of a wrong configuration can be small and insignificant such as a website showing an incorrect font type, or large and consequential such as deleting customer data, incorrect price calculation, or charging a fee twice. In addition, an incorrect configuration may introduce subtle and lurking vulnerabilities into a system. Statically typed programming languages generally can mitigate these kinds of problems to some extent. At compile time, a compiler can detect incorrect types as well as other common mistakes such as some typographical errors, invalid type coercions, and invalid object references. It goes without saying that developers need to correct all compile-time errors before a project can be built. However, hardcoded configurations are not desirable since the input data cannot be changed without rebuilding a project. Due to this inflexibility, external configuration files are needed, but they bring back some thorny issues since the compiler cannot validate the types in those files. Adding validation logic does not substantially mitigate this problem because it is activated at runtime, and errors may not be discovered until a project is deployed to production servers. An external configuration file somewhat lessens the benefit of static type-checking that a compiler provides. Furthermore, string keys are needed for linking the variables in the source code to the values in configuration files. If a key is required to be renamed, it should be renamed in both configuration file and source code. Otherwise, the link will be broken. We propose a new framework that can generate source code from configuration files during development. Many configuration file formats support basic data types and nested object structure which can be mapped to Java types and the Java static nested class. The configuration library that we used is config by typesafehub. The library supports the Human-Optimized Config Object Notation (HOCON) file format which is a superset of the JavaScript Object Notation (JSON). The library's objects are encapsulated in the generated configuration object, which cannot be directly accessed by developers. We discovered that this method can prevent some types of human errors, and it also takes advantage of the validation provided by a compiler. The configuration key is no longer a string, rather a chain of methods or attributes, which is more flexible and type-safe. The configuration objects and their values are immutable. The complexity of how mutable values are converted to immutable ones is hidden from the developers. There are a number of other subtle details that are addressed in the paper, as well as some limitations and enhancements.",code generation | configuration | framework | HOCON | JVM,1,50-55,Conference Proceeding,Conference Paper,2.0,"Puripunpinyo, Hussachai;Samadzadeh, M. H.",57195131200;6701796642,Oklahoma State University,United States,"one of the common errors in software development is a configuration mistake. this type of error can have a wide range of severity levels. consequences of a wrong configuration can be small and insignificant such as a website showing an incorrect font type, or large and consequential such as deleting customer data, incorrect price calculation, or charging a fee twice. in addition, an incorrect configuration may introduce subtle and lurking vulnerabilities into a system. statically typed programming languages generally can mitigate these kinds of problems to some extent. at compile time, a compiler can detect incorrect types as well as other common mistakes such as some typographical errors, invalid type coercions, and invalid object references. it goes without saying that developers need to correct all compile-time errors before a project can be built. however, hardcoded configurations are not desirable since the input data cannot be changed without rebuilding a project. due to this inflexibility, external configuration files are needed, but they bring back some thorny issues since the compiler cannot validate the types in those files. adding validation logic does not substantially mitigate this problem because it is activated at runtime, and errors may not be discovered until a project is deployed to production servers. an external configuration file somewhat lessens the benefit of static type-checking that a compiler provides. furthermore, string keys are needed for linking the variables in the source code to the values in configuration files. if a key is required to be renamed, it should be renamed in both configuration file and source code. otherwise, the link will be broken. we propose a new framework that can generate source code from configuration files during development. many configuration file formats support basic data types and nested object structure which can be mapped to java types and the java static nested class. the configuration library that we used is config by typesafehub. the library supports the human-optimized config object notation (hocon) file format which is a superset of the javascript object notation (json). the library's objects are encapsulated in the generated configuration object, which cannot be directly accessed by developers. we discovered that this method can prevent some types of human errors, and it also takes advantage of the validation provided by a compiler. the configuration key is no longer a string, rather a chain of methods or attributes, which is more flexible and type-safe. the configuration objects and their values are immutable. the complexity of how mutable values are converted to immutable ones is hidden from the developers. there are a number of other subtle details that are addressed in the paper, as well as some limitations and enhancements.",a framework for building type-safe configurations for jvm using code generation techniques
1158,2-s2.0-85017370490,10.1002/cae.21815,Design of a low cost remote electronic laboratory suitable for low bandwidth connection,Mostefaoui H.,Computer Applications in Engineering Education,2017-05-01,"The development of remote lab has grown during the last decade. However, almost all current laboratories use proprietary software (a Labview like software) and expensive hardware (server) to implement them. This paper presents the development of a low-cost alternative, flexible, and reconfigurable remote lab, based on an architecture built around an Arduino Mega. Low-bandwidth connections requirement was carried out by the use of HTML code for the development of the required graphical user interface. The usability and effectiveness of the proposed solutions were evaluated by considering a case study of two groups of students that carried out the same lab work: The first one remotely and the second one in a hands-on lab. This test showed that the remote laboratory was well received by students: Remote students group realize their task in a shorter time and have slightly better outcomes than students group in a hands-on laboratory. © 2017 Wiley Periodicals, Inc. Comput Appl Eng Educ 25:480–488, 2017; View this article online at wileyonlinelibrary.com/journal/cae; DOI 10.1002/cae.21815.",Arduino mega | electronic experiment | HTML | JavaScript | open source | practical work | reconfigurable circuit | remote laboratory,13,480-488,Journal,Article,3.0,"Mostefaoui, Hakima;Benachenhou, Abdelhalim;Benattia, Abderrahmane Adda",57188709281;55810200800;56516861300,Université Ibn Khaldoun - Tiaret;Université Abdelhamid Ibn Badis Mostaganem,Algeria;Algeria,"the development of remote lab has grown during the last decade. however, almost all current laboratories use proprietary software (a labview like software) and expensive hardware (server) to implement them. this paper presents the development of a low-cost alternative, flexible, and reconfigurable remote lab, based on an architecture built around an arduino mega. low-bandwidth connections requirement was carried out by the use of html code for the development of the required graphical user interface. the usability and effectiveness of the proposed solutions were evaluated by considering a case study of two groups of students that carried out the same lab work: the first one remotely and the second one in a hands-on lab. this test showed that the remote laboratory was well received by students: remote students group realize their task in a shorter time and have slightly better outcomes than students group in a hands-on laboratory. © 2017 wiley periodicals, inc. comput appl eng educ 25:480–488, 2017; view this article online at wileyonlinelibrary.com/journal/cae; doi 10.1002/cae.21815.",design of a low cost remote electronic laboratory suitable for low bandwidth connection
1159,2-s2.0-85019475936,10.1109/EIConRus.2017.7910504,Development and implementation a method of detecting an attacker with use of HTTP network protocol,Arzhakov A.,"Proceedings of the 2017 IEEE Russia Section Young Researchers in Electrical and Electronic Engineering Conference, ElConRus 2017",2017-04-24,"This article is devoted to methods of improving the efficiency of security systems using Honeypot technology. There are observed basic principles of creating the protection system using this technology. There are suggested methods of web services organization which use affected software to efficiently detect intrusions. There are also given options of collecting statistical information about attacker's actions, and assessed the effectiveness of the approach proposed.",HoneyPot | HTTP | IDS | Information Security | Intrusion Detection System | Web Server,4,100-104,Conference Proceeding,Conference Paper,4.0,"Arzhakov, Anton V.;Troitskiy, Sergey S.;Vasilyev, Nikolay P.;Silnov, Dmitry S.",57188564192;57189246407;56242868000;56856779600,National Research Nuclear University MEPhI,Russian Federation,"this article is devoted to methods of improving the efficiency of security systems using honeypot technology. there are observed basic principles of creating the protection system using this technology. there are suggested methods of web services organization which use affected software to efficiently detect intrusions. there are also given options of collecting statistical information about attacker's actions, and assessed the effectiveness of the approach proposed.",development and implementation a method of detecting an attacker with use of http network protocol
1162,2-s2.0-85020863469,10.1145/3019612.3019884,Utilizing nearby computing resources for resource-limited mobile devices,Le M.,Proceedings of the ACM Symposium on Applied Computing,2017-04-03,"For the last decade, mobile devices have been significantly developed with powerful hardware facilities. Nevertheless, rapid growth in application functionality requires ever greater hardware capability. Thus ensuring the quality of service in resources-limited execution environments remains a major challenge of mobile software development. To reduce execution time and save battery power, some functionality of mobile applications is often executed remotely. However, such an optimization mechanism (i.e., computational offloading) has received attention only in the research literature. In this paper, we present a novel distribution infrastructure that can execute any functionality at either a powerful remote server or nearby mobile devices using two distributed execution models|client/server and peer to peer. Our evaluation results demonstrate that the presented approach can increase both performance and energy efficiency of mobile applications by virtually expanding the hardware capacity of an existing mobile device.",Mobile application | Offloading | Peer to peer | Remote execution | Run-time system,4,572-575,Conference Proceeding,Conference Paper,2.0,"Le, Minh;Kwon, Young Woo",57194562891;57208480210,Utah State University,United States,"for the last decade, mobile devices have been significantly developed with powerful hardware facilities. nevertheless, rapid growth in application functionality requires ever greater hardware capability. thus ensuring the quality of service in resources-limited execution environments remains a major challenge of mobile software development. to reduce execution time and save battery power, some functionality of mobile applications is often executed remotely. however, such an optimization mechanism (i.e., computational offloading) has received attention only in the research literature. in this paper, we present a novel distribution infrastructure that can execute any functionality at either a powerful remote server or nearby mobile devices using two distributed execution models|client/server and peer to peer. our evaluation results demonstrate that the presented approach can increase both performance and energy efficiency of mobile applications by virtually expanding the hardware capacity of an existing mobile device.",utilizing nearby computing resources for resource-limited mobile devices
1163,2-s2.0-85013102305,10.1016/j.molliq.2017.01.107,"Development of nabumetone loaded lipid nano-scaffold for the effective oral delivery; optimization, characterization, drug release and pharmacodynamic study",Kawish S.M.,Journal of Molecular Liquids,2017-04-01,"Prime objective of this research work was to the improve efficacy of a BCS class II drug, nabumetone (NBM). Nanostructured lipid carrier (NLC) of NBM was developed using melt-emulsification and ultrasonication technique. Prior to the formulation development, screening of various solid lipids, liquid lipids and surfactants were done and the most suitable excipients were selected. The NLC formulation was optimized using Box-Behnken Design Expert® software. For optimization purpose, independent variables were taken as % lipid mix, % surfactant and sonication time (minute). Particle size, PDI and entrapment efficiency were selected as dependent variables. The optimized formulation was characterized using photon correlation spectroscopy and was found with 127 ± 1.75 nm average particle size and 0.279 ± 0.016 polydispersity index (PDI). When observed under TEM and SEM, NLC particles were found with nearly spherical shape and particle size of NLC in this study almost matched with the average particle size determined by photon correlation spectroscopy. In DSC thermogram of NBM-NLC, the endothermic peak of the drug at 84.04 °C was disappeared that means drug was fully dissolved in lipid. In vitro release study of developed formulation showed burst release followed by slow diffusion based sustained release. The pharmacodynamic study shows better anti-inflammatory effect (almost 2 times) when compared with NBM suspension. Based on the data obtained from the in vitro and in vivo studies it was concluded that NLC can be a promising carrier and helps in improving intestinal absorption of orally administered NBM.",Box-Behnken | Carrageenan | Nabumetone | NLC | Osteoarthritis | Pharmacodynamic,21,514-522,Journal,Article,7.0,"Kawish, S. M.;Ahmed, Shakeeb;Gull, Azka;Aslam, Mohammed;Pandit, Jayamanti;Aqil, Mohd;Sultana, Yasmin",57193336692;57191413032;57191417718;57210540393;57213369633;35551158100;6507145375,Amity University;Jamia Hamdard Faculty of Pharmacy,India;India,"prime objective of this research work was to the improve efficacy of a bcs class ii drug, nabumetone (nbm). nanostructured lipid carrier (nlc) of nbm was developed using melt-emulsification and ultrasonication technique. prior to the formulation development, screening of various solid lipids, liquid lipids and surfactants were done and the most suitable excipients were selected. the nlc formulation was optimized using box-behnken design expert® software. for optimization purpose, independent variables were taken as % lipid mix, % surfactant and sonication time (minute). particle size, pdi and entrapment efficiency were selected as dependent variables. the optimized formulation was characterized using photon correlation spectroscopy and was found with 127 ± 1.75 nm average particle size and 0.279 ± 0.016 polydispersity index (pdi). when observed under tem and sem, nlc particles were found with nearly spherical shape and particle size of nlc in this study almost matched with the average particle size determined by photon correlation spectroscopy. in dsc thermogram of nbm-nlc, the endothermic peak of the drug at 84.04 °c was disappeared that means drug was fully dissolved in lipid. in vitro release study of developed formulation showed burst release followed by slow diffusion based sustained release. the pharmacodynamic study shows better anti-inflammatory effect (almost 2 times) when compared with nbm suspension. based on the data obtained from the in vitro and in vivo studies it was concluded that nlc can be a promising carrier and helps in improving intestinal absorption of orally administered nbm.","development of nabumetone loaded lipid nano-scaffold for the effective oral delivery; optimization, characterization, drug release and pharmacodynamic study"
1164,2-s2.0-85018430718,10.1109/SANER.2017.7884604,An empirical comparison of dependency issues in OSS packaging ecosystems,Decan A.,"SANER 2017 - 24th IEEE International Conference on Software Analysis, Evolution, and Reengineering",2017-03-21,"Nearly every popular programming language comes with one or more open source software packaging ecosystem(s), containing a large collection of interdependent software packages developed in that programming language. Such packaging ecosystems are extremely useful for their respective software development community. We present an empirical analysis of how the dependency graphs of three large packaging ecosystems (npm, CRAN and RubyGems) evolve over time. We study how the existing package dependencies impact the resilience of the three ecosystems over time and to which extent these ecosystems suffer from issues related to package dependency updates. We analyse specific solutions that each ecosystem has put into place and argue that none of these solutions is perfect, motivating the need for better tools to deal with package dependency update problems.",package dependency management | software distribution | software ecosystem | software evolution | software repository mining,57,2-12,Conference Proceeding,Conference Paper,3.0,"Decan, Alexandre;Mens, Tom;Claes, Maelick",35931990200;6701719612;55949047700,Université de Mons,Belgium,"nearly every popular programming language comes with one or more open source software packaging ecosystem(s), containing a large collection of interdependent software packages developed in that programming language. such packaging ecosystems are extremely useful for their respective software development community. we present an empirical analysis of how the dependency graphs of three large packaging ecosystems (npm, cran and rubygems) evolve over time. we study how the existing package dependencies impact the resilience of the three ecosystems over time and to which extent these ecosystems suffer from issues related to package dependency updates. we analyse specific solutions that each ecosystem has put into place and argue that none of these solutions is perfect, motivating the need for better tools to deal with package dependency update problems.",an empirical comparison of dependency issues in oss packaging ecosystems
1168,2-s2.0-85012266379,10.1007/s10586-017-0773-z,Exploratory testing supported by automated reengineering of model of the system under test,Frajtak K.,Cluster Computing,2017-03-01,"Exploratory Testing technique is well applicable to software development projects, where test basis is not available (or at least not complete and consistent to the extent allowing the creation of efficient test cases). The key factor for the efficiency of this technique is a structured process for the recording of explored path in the system under test. This approach also allows the creation of the test cases during exploratory testing process. These test cases can be used in the following re-testing of the system. If performed manually, the efficiency of such process strongly depends on the team organization and systematic work of the individuals in the team. This process can be aided by an automated support. In the paper, a framework, which automatically records selected tester’s actions in the system under test is presented. From these recordings, a model of the screen and action flows is reengineered and test cases are prepared. Tester is also able to define more meta-data in the test cases during this process. The recorded model and defined test cases are then available for the next rounds of testing. The performed case study shows that Exploratory Testing aided by this machine support is less resource demanding than Exploratory Testing performed manually only. Also, larger part of SUT was explored during the tests, when this systematic support was available to testers.",Exploratory testing | Generation of test cases from model | Model of system under test | Model reengineering | Model-based testing,7,855-865,Journal,Article,3.0,"Frajtak, Karel;Bures, Miroslav;Jelinek, Ivan",48861099800;14015114200;7003865724,Czech Technical University in Prague,Czech Republic,"exploratory testing technique is well applicable to software development projects, where test basis is not available (or at least not complete and consistent to the extent allowing the creation of efficient test cases). the key factor for the efficiency of this technique is a structured process for the recording of explored path in the system under test. this approach also allows the creation of the test cases during exploratory testing process. these test cases can be used in the following re-testing of the system. if performed manually, the efficiency of such process strongly depends on the team organization and systematic work of the individuals in the team. this process can be aided by an automated support. in the paper, a framework, which automatically records selected tester’s actions in the system under test is presented. from these recordings, a model of the screen and action flows is reengineered and test cases are prepared. tester is also able to define more meta-data in the test cases during this process. the recorded model and defined test cases are then available for the next rounds of testing. the performed case study shows that exploratory testing aided by this machine support is less resource demanding than exploratory testing performed manually only. also, larger part of sut was explored during the tests, when this systematic support was available to testers.",exploratory testing supported by automated reengineering of model of the system under test
1169,2-s2.0-84988896840,10.1016/j.future.2016.07.018,ClowdFlows: Online workflows for distributed big data mining,Kranjc J.,Future Generation Computer Systems,2017-03-01,"The paper presents a platform for distributed computing, developed using the latest software technologies and computing paradigms to enable big data mining. The platform, called ClowdFlows, is implemented as a cloud-based web application with a graphical user interface which supports the construction and execution of data mining workflows, including web services used as workflow components. As a web application, the ClowdFlows platform poses no software requirements and can be used from any modern browser, including mobile devices. The constructed workflows can be declared either as private or public, which enables sharing the developed solutions, data and results on the web and in scientific publications. The server-side software of ClowdFlows can be multiplied and distributed to any number of computing nodes. From a developer's perspective the platform is easy to extend and supports distributed development with packages. The paper focuses on big data processing in the batch and real-time processing mode. Big data analytics is provided through several algorithms, including novel ensemble techniques, implemented using the map-reduce paradigm and a special stream mining module for continuous parallel workflow execution. The batch mode and real-time processing mode are demonstrated with practical use cases. Performance analysis shows the benefit of using all available data for learning in distributed mode compared to using only subsets of data in non-distributed mode. The ability of ClowdFlows to handle big data sets and its nearly perfect linear speedup is demonstrated.",Batch processing | Big data | Cloud computing | Data mining platform | Map-reduce | Scientific workflows,55,38-58,Journal,Article,5.0,"Kranjc, Janez;Orač, Roman;Podpečan, Vid;Lavrač, Nada;Robnik-Šikonja, Marko",55318942600;57191336888;35774527900;7004388979;55900495300,Univerza v Ljubljani;University of Nova Gorica;Jozef Stefan Institute,Slovenia;Slovenia;Slovenia,"the paper presents a platform for distributed computing, developed using the latest software technologies and computing paradigms to enable big data mining. the platform, called clowdflows, is implemented as a cloud-based web application with a graphical user interface which supports the construction and execution of data mining workflows, including web services used as workflow components. as a web application, the clowdflows platform poses no software requirements and can be used from any modern browser, including mobile devices. the constructed workflows can be declared either as private or public, which enables sharing the developed solutions, data and results on the web and in scientific publications. the server-side software of clowdflows can be multiplied and distributed to any number of computing nodes. from a developer's perspective the platform is easy to extend and supports distributed development with packages. the paper focuses on big data processing in the batch and real-time processing mode. big data analytics is provided through several algorithms, including novel ensemble techniques, implemented using the map-reduce paradigm and a special stream mining module for continuous parallel workflow execution. the batch mode and real-time processing mode are demonstrated with practical use cases. performance analysis shows the benefit of using all available data for learning in distributed mode compared to using only subsets of data in non-distributed mode. the ability of clowdflows to handle big data sets and its nearly perfect linear speedup is demonstrated.",clowdflows: online workflows for distributed big data mining
1170,2-s2.0-84957658578,10.1007/s11219-016-9310-1,Reproducing failures based on semiformal failure scenario descriptions,Karagöz G.,Software Quality Journal,2017-03-01,"Due to the increasing size and complexity of software systems, it becomes hard to test these systems exhaustively. As a result, some faults can be left undetected. Undetected faults can lead to failures in deployed systems. Such failures are usually reported by the users from the field or test engineers back to developers. It requires considerable time and effort to analyze and reproduce the reported failures because their descriptions are not always complete, structured and formal. In this paper, we introduce a novel approach for automatically reproducing failures to aid their debugging. Our approach relies on semi-structured failure scenario descriptions that employ a set of keywords. These descriptions are preprocessed and mapped to a set of predefined test case templates with valid input sets. Then, test cases are generated and executed to reproduce the reported failure scenarios. The approach is evaluated with an industrial case study performed in a company from the telecommunications domain. Several failures were successfully reproduced. The approach is also adopted in the quality assurance process of the company. After one-time preparation of reusable test case templates and training of test engineers, 24.9 % of the reported failures (and 40 % of those that were manually reproducible) could be reproduced without any manual effort.",Automated test case generation | Behavior-driven development | Failure reproduction | Industrial case study,3,111-129,Journal,Article,2.0,"Karagöz, Gün;Sözer, Hasan",55292648600;16040424900,Ozyegin University;P.I.Works HQ,Turkey;Turkey,"due to the increasing size and complexity of software systems, it becomes hard to test these systems exhaustively. as a result, some faults can be left undetected. undetected faults can lead to failures in deployed systems. such failures are usually reported by the users from the field or test engineers back to developers. it requires considerable time and effort to analyze and reproduce the reported failures because their descriptions are not always complete, structured and formal. in this paper, we introduce a novel approach for automatically reproducing failures to aid their debugging. our approach relies on semi-structured failure scenario descriptions that employ a set of keywords. these descriptions are preprocessed and mapped to a set of predefined test case templates with valid input sets. then, test cases are generated and executed to reproduce the reported failure scenarios. the approach is evaluated with an industrial case study performed in a company from the telecommunications domain. several failures were successfully reproduced. the approach is also adopted in the quality assurance process of the company. after one-time preparation of reusable test case templates and training of test engineers, 24.9 % of the reported failures (and 40 % of those that were manually reproducible) could be reproduced without any manual effort.",reproducing failures based on semiformal failure scenario descriptions
1173,2-s2.0-85017201611,10.11975/j.issn.1002-6819.2017.04.006,Design of virtual test system based on hardware-in-loop for picking robot vision localization and behavior control,Luo L.,Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering,2017-02-15,"In the process of developing picking robot prototype, the traditional picking tests are usually performed in orchard, which are limited by certain factors such as the harvesting season, weather condition and venue. So, the investigated and designed algorithm for the vision and control system of picking robots can't be verified effectively and timely, and the prototype development cycle has to last longer. To test the vision and control algorithm of picking robot, a hardware-in-the-loop virtual experimental system based on binocular stereo vision for grape-picking robot was designed in this paper, which was composed of hardware and software units. The hardware units consisted of binocular camera, grape clusters, grape imitative leaf and stems, support structure of grape clusters and its guide rail, calibration board, and so on. The software units included vision processing part and virtual picking robot. Firstly, the spatial information such as the picking point and the anti-collision bounding volume of the grape cluster was extracted by binocular stereo vision. The picking point on the peduncle of the grape cluster was detected by using a minimum distance restraint between the barycentre of the pixel region of grape cluster and the detected lines in the ROI (region of interest) of peduncle. The anti-collision bounding volume of the grape cluster was calculated by transforming the spatial coordinates of the picking point and all detected grape berries into the coordinate system of grape clusters. Secondly, the three-dimensional models of the picking robot were constructed according to the picking robot prototype with 6 degrees of freedom which already existed in our laboratory. The Denavit-Hartenberg (D-H) method was adopted to establish the robot coordinate transformation. The direct and inverse solutions of the robot kinematics were solved by using the inverse transformation method, and then the only inverse solution was obtained. Thirdly, the moving path of picking robot was planned based on the artificial potential field theory. The collision between the robot manipulator and the grape clusters in the virtual environment was detected by using the hierarchical bounding box algorithm which can validate the reasonability of path planning. The motion simulation of the virtual picking robot was programmed by combining the modular programming and the routing communication mechanism. Finally, the spatial information of the grape clusters was extracted by programming the application code using Visual C++ and OpenCV (open source computer vision library), and the path planning and the motion simulation of the virtual picking robot were performed based on the virtual reality platform EON, Visual C++ and JavaScript. The hardware-in-the-loop virtual experimental platform was established by combining the binocular stereo vision and virtual picking robot. On this platform, 34 tests were performed by changing the position of the grape clusters under laboratory environment while the binocular cameras kept still. And every test included 3 steps, the first step was vision locating, the second was path planning and the last was clamping and cutting operation. In all the tests, 29 tests were successful in vision locating, and 5 tests were failed in vision locating. Among those 5 failed tests, 2 tests were wrong in picking point detection and 3 tests were failed in stereo matching on the picking point. There was one test failed in path planning when the grape clusters were located correctly, and all of the clamping and cutting operation for the grape clusters ran smoothly when the anti-collusion path was planned successfully. In general, the success rates of the tests on visual localization, path planning, clamping and cutting operation were 85.29%, 82.35%, 82.35%, respectively. The results showed that the method developed in this study can be used to verify and test the visual location and behavior algorithm of the picking robot, and then provide the support to the harvesting robot development, test and continuous improvement.",Algorithms | Binocular stereo vision | Design | Grape | Hardware-in-the-loop | Robots | Virtual reality,21,39-46,Journal,Article,6.0,"Luo, Lufeng;Zou, Xiangjun;Cheng, Tangcan;Yang, Zishang;Zhang, Cong;Mo, Yuda",15065572500;14053286400;57193871897;57189030899;56597112000;56330244000,TianJin University of Technology and Education;South China Agricultural University,China;China,"in the process of developing picking robot prototype, the traditional picking tests are usually performed in orchard, which are limited by certain factors such as the harvesting season, weather condition and venue. so, the investigated and designed algorithm for the vision and control system of picking robots can't be verified effectively and timely, and the prototype development cycle has to last longer. to test the vision and control algorithm of picking robot, a hardware-in-the-loop virtual experimental system based on binocular stereo vision for grape-picking robot was designed in this paper, which was composed of hardware and software units. the hardware units consisted of binocular camera, grape clusters, grape imitative leaf and stems, support structure of grape clusters and its guide rail, calibration board, and so on. the software units included vision processing part and virtual picking robot. firstly, the spatial information such as the picking point and the anti-collision bounding volume of the grape cluster was extracted by binocular stereo vision. the picking point on the peduncle of the grape cluster was detected by using a minimum distance restraint between the barycentre of the pixel region of grape cluster and the detected lines in the roi (region of interest) of peduncle. the anti-collision bounding volume of the grape cluster was calculated by transforming the spatial coordinates of the picking point and all detected grape berries into the coordinate system of grape clusters. secondly, the three-dimensional models of the picking robot were constructed according to the picking robot prototype with 6 degrees of freedom which already existed in our laboratory. the denavit-hartenberg (d-h) method was adopted to establish the robot coordinate transformation. the direct and inverse solutions of the robot kinematics were solved by using the inverse transformation method, and then the only inverse solution was obtained. thirdly, the moving path of picking robot was planned based on the artificial potential field theory. the collision between the robot manipulator and the grape clusters in the virtual environment was detected by using the hierarchical bounding box algorithm which can validate the reasonability of path planning. the motion simulation of the virtual picking robot was programmed by combining the modular programming and the routing communication mechanism. finally, the spatial information of the grape clusters was extracted by programming the application code using visual c++ and opencv (open source computer vision library), and the path planning and the motion simulation of the virtual picking robot were performed based on the virtual reality platform eon, visual c++ and javascript. the hardware-in-the-loop virtual experimental platform was established by combining the binocular stereo vision and virtual picking robot. on this platform, 34 tests were performed by changing the position of the grape clusters under laboratory environment while the binocular cameras kept still. and every test included 3 steps, the first step was vision locating, the second was path planning and the last was clamping and cutting operation. in all the tests, 29 tests were successful in vision locating, and 5 tests were failed in vision locating. among those 5 failed tests, 2 tests were wrong in picking point detection and 3 tests were failed in stereo matching on the picking point. there was one test failed in path planning when the grape clusters were located correctly, and all of the clamping and cutting operation for the grape clusters ran smoothly when the anti-collusion path was planned successfully. in general, the success rates of the tests on visual localization, path planning, clamping and cutting operation were 85.29%, 82.35%, 82.35%, respectively. the results showed that the method developed in this study can be used to verify and test the visual location and behavior algorithm of the picking robot, and then provide the support to the harvesting robot development, test and continuous improvement.",design of virtual test system based on hardware-in-loop for picking robot vision localization and behavior control
1175,2-s2.0-85054259433,10.1145/3021460.3021483,A crowdsourcing approach for quality enhancement of eLearning systems,Lalit Mohan S.,ACM International Conference Proceeding Series,2017-02-05,"In India, a large number of engineering undergraduates are adopting eLearning as it provides access to best faculty and reduces concerns on inadequate physical infrastructure at colleges. Virtual Labs is a Government of India eLearning initiative containing simulation and remote triggered labs for engineering students. Virtual Labs developed over a period of 6 years is used by more than a million undergraduate students across nine engineering disciplines. The software used for developing these experiments requires substantial effort for maintenance due to deprecation, compatibility, etc. We propose a targeted crowdsourcing approach for maintenance of Virtual Labs with sustainable quality. The targeted crowdsourcing involves the large number of engineering students who are also the major stakeholders of these labs. Our quality enhancement using crowdsourcing approach was validated for 14 labs and would be extended to 191 labs based on encouraging results.",Crowdsourcing | ELearning systems | Quality | Software development,2,188-194,Conference Proceeding,Conference Paper,4.0,"Lalit Mohan, S.;Raman, Priya;Choppella, Venkatesh;Reddy, Y. R.",57194516973;57195880332;6507651604;55749120700,"International Institute of Information Technology, Hyderabad;Virtual Labs",India;India,"in india, a large number of engineering undergraduates are adopting elearning as it provides access to best faculty and reduces concerns on inadequate physical infrastructure at colleges. virtual labs is a government of india elearning initiative containing simulation and remote triggered labs for engineering students. virtual labs developed over a period of 6 years is used by more than a million undergraduate students across nine engineering disciplines. the software used for developing these experiments requires substantial effort for maintenance due to deprecation, compatibility, etc. we propose a targeted crowdsourcing approach for maintenance of virtual labs with sustainable quality. the targeted crowdsourcing involves the large number of engineering students who are also the major stakeholders of these labs. our quality enhancement using crowdsourcing approach was validated for 14 labs and would be extended to 191 labs based on encouraging results.",a crowdsourcing approach for quality enhancement of elearning systems
1176,2-s2.0-85015171316,10.1109/SecDev.2016.030,Security Guarantees for the Execution Infrastructure of Software Applications,Piessens F.,"Proceedings - 2016 IEEE Cybersecurity Development, SecDev 2016",2017-02-01,"Software applications run on top of infrastructure consisting of hardware (processors, devices, communication networks,⋯) and software (operating systems, compilers, virtual machines, language runtimes, databases,⋯). In many cases, attacks against application software rely at least to some extent on aspects of that infrastructure, and in some cases vulnerabilities can be fixed by strengthening the infrastructure, as well as by patching the application code. This paper argues that it is beneficial for secure software development if the security guarantees offered by the execution infrastructure are explicit and precisely defined. More specifically, a developer writing source code that will be executed on the infrastructure should know what guarantees the infrastructure offers against what class of attackers. We survey existing proposals for precise statements of such security guarantees, and argue that the notion of full abstraction proposed by Martin Abadi as a correctness condition for secure implementation of abstractions is the key notion for specifying security guarantees of execution infrastructure. We give a brief overview of how full abstraction has already been used to specify and prove security for important building blocks of an execution infrastructure, and we sketch a research agenda identifying several interesting open research problems that, when solved, could contribute to a more secure design of execution infrastructure for distributed software applications, and to a better understanding of the security properties of these infrastructures.",full abstraction | software security,3,81-87,Conference Proceeding,Conference Paper,4.0,"Piessens, Frank;Devriese, Dominique;Mühlberg, Jan Tobias;Strackx, Raoul",6602153049;36198086100;23009453600;34880912700,KU Leuven,Belgium,"software applications run on top of infrastructure consisting of hardware (processors, devices, communication networks,⋯) and software (operating systems, compilers, virtual machines, language runtimes, databases,⋯). in many cases, attacks against application software rely at least to some extent on aspects of that infrastructure, and in some cases vulnerabilities can be fixed by strengthening the infrastructure, as well as by patching the application code. this paper argues that it is beneficial for secure software development if the security guarantees offered by the execution infrastructure are explicit and precisely defined. more specifically, a developer writing source code that will be executed on the infrastructure should know what guarantees the infrastructure offers against what class of attackers. we survey existing proposals for precise statements of such security guarantees, and argue that the notion of full abstraction proposed by martin abadi as a correctness condition for secure implementation of abstractions is the key notion for specifying security guarantees of execution infrastructure. we give a brief overview of how full abstraction has already been used to specify and prove security for important building blocks of an execution infrastructure, and we sketch a research agenda identifying several interesting open research problems that, when solved, could contribute to a more secure design of execution infrastructure for distributed software applications, and to a better understanding of the security properties of these infrastructures.",security guarantees for the execution infrastructure of software applications
1177,2-s2.0-84998785556,10.1016/j.envsoft.2016.11.011,Development of a microbial dose response visualization and modelling application for QMRA modelers and educators,Weir M.H.,Environmental Modelling and Software,2017-02-01,"Microbial dose response modelling is vital to a well-characterized microbial risk estimate. Dose response modelling is an inherently multidisciplinary field, which collates knowledge and data from disparate scientific fields. This multidisciplinary nature presents a key challenge to the expansion of microbial dose response modelling into new groups of researchers and modelers. This research employs a dose response optimization R code used in 18 peer-reviewed research studies to develop a multi-functional dose response software. The underlying R code performs an optimization of the two primary dose response models using the MLE method and outputs statistical analyses of the fits and bootstrapped uncertainty information for the models. VizDR (Visual Dose Response) was developed to provide microbial dose response modelling capabilities to a larger audience. VizDR is programmed in JavaScript with underlying Python scripts for intercommunication with Rserve. VizDR allows for dose response model visualization and optimization of a user's own experimental data.",Microbial dose response | Optimization | QMRA | Software | Wiki,12,74-83,Journal,Article,4.0,"Weir, Mark H.;Mitchell, Jade;Flynn, William;Pope, Joanna M.",22137121000;24278814500;57192164934;57189505046,Michigan State University;University of Delaware;The Ohio State University;CAMRA Consultants LLC,United States;United States;United States;United States,"microbial dose response modelling is vital to a well-characterized microbial risk estimate. dose response modelling is an inherently multidisciplinary field, which collates knowledge and data from disparate scientific fields. this multidisciplinary nature presents a key challenge to the expansion of microbial dose response modelling into new groups of researchers and modelers. this research employs a dose response optimization r code used in 18 peer-reviewed research studies to develop a multi-functional dose response software. the underlying r code performs an optimization of the two primary dose response models using the mle method and outputs statistical analyses of the fits and bootstrapped uncertainty information for the models. vizdr (visual dose response) was developed to provide microbial dose response modelling capabilities to a larger audience. vizdr is programmed in javascript with underlying python scripts for intercommunication with rserve. vizdr allows for dose response model visualization and optimization of a user's own experimental data.",development of a microbial dose response visualization and modelling application for qmra modelers and educators
1178,2-s2.0-84949683131,10.1016/j.scico.2015.11.008,JPC: A library for categorising and applying inter-language conversions between Java and Prolog,Castro S.,Science of Computer Programming,2017-02-01,"The number of approaches existing to enable a smooth interaction between Java and Prolog programs testifies the growing interest in solutions that combine the strengths of both languages. Most of these approaches provide limited support to allow programmers to customise how Prolog artefacts should be reified in the Java world, or how to reason about Java objects on the Prolog side. This is an error-prone task since often a considerable amount of mappings must be developed and organised. Furthermore, appropriate mappings may depend on the particular context in which a conversion is accomplished. Although some libraries alleviate this problem by providing higher-level abstractions to deal with the complexity of custom conversions between artefacts of the two languages, such libraries are difficult to implement and evolve, because of a lack of appropriate underlying building blocks for encapsulating, categorising and applying Java–Prolog conversion routines. We therefore introduce a new library, JPC, serving as a development tool for both programmers willing to categorise context-dependent conversion constructs in their Java–Prolog systems, and for architects implementing frameworks providing higher-level abstractions for better interoperability between these two languages.",Java–Prolog language interoperability | Logic programming | Multi-paradigm programming | Object-oriented programming | Programming languages,1,75-99,Journal,Article,3.0,"Castro, Sergio;Mens, Kim;Moura, Paulo",57198139970;55884880800;8988566300,"Institute for Systems and Computer Engineering, Technology and Science;Université Catholique de Louvain",Portugal;Belgium,"the number of approaches existing to enable a smooth interaction between java and prolog programs testifies the growing interest in solutions that combine the strengths of both languages. most of these approaches provide limited support to allow programmers to customise how prolog artefacts should be reified in the java world, or how to reason about java objects on the prolog side. this is an error-prone task since often a considerable amount of mappings must be developed and organised. furthermore, appropriate mappings may depend on the particular context in which a conversion is accomplished. although some libraries alleviate this problem by providing higher-level abstractions to deal with the complexity of custom conversions between artefacts of the two languages, such libraries are difficult to implement and evolve, because of a lack of appropriate underlying building blocks for encapsulating, categorising and applying java–prolog conversion routines. we therefore introduce a new library, jpc, serving as a development tool for both programmers willing to categorise context-dependent conversion constructs in their java–prolog systems, and for architects implementing frameworks providing higher-level abstractions for better interoperability between these two languages.",jpc: a library for categorising and applying inter-language conversions between java and prolog
1182,2-s2.0-85013798216,10.1109/QUATIC.2016.060,Web systems quality evolution,Rio A.,"Proceedings - 2016 10th International Conference on the Quality of Information and Communications Technology, QUATIC 2016",2017-01-11,"Software evolution is a well-established research area, but not in the area of web systems/applications. Web projects are normally more complex than other software development projects because they have both server and client code, encompass a variety of programming languages, and are multidisciplinary. We aim to produce a catalog of web smells to help avoiding the problems in web development code before they happen, thus saving time and reducing cost. By means of longitudinal studies we plan to analyze the impact of these web smells in web systems maintainability and reliability. This will require developing a tool to detect the proposed web smells. For validation sake, we will also use surveys among web systems developers and peer reviewing in academic fora.",irregular time series | longitudinal studies | software evolution | software quality | web code smells | web engineering,3,248-253,Conference Proceeding,Conference Paper,2.0,"Rio, Americo;Brito E Abreu, Fernando",36810306800;6602691646,Iscte – Instituto Universitário de Lisboa,Portugal,"software evolution is a well-established research area, but not in the area of web systems/applications. web projects are normally more complex than other software development projects because they have both server and client code, encompass a variety of programming languages, and are multidisciplinary. we aim to produce a catalog of web smells to help avoiding the problems in web development code before they happen, thus saving time and reducing cost. by means of longitudinal studies we plan to analyze the impact of these web smells in web systems maintainability and reliability. this will require developing a tool to detect the proposed web smells. for validation sake, we will also use surveys among web systems developers and peer reviewing in academic fora.",web systems quality evolution
1183,2-s2.0-85013753616,10.1109/QUATIC.2016.019,Multi-VisioTrace: Traceability visualization tool,Rodrigues A.,"Proceedings - 2016 10th International Conference on the Quality of Information and Communications Technology, QUATIC 2016",2017-01-11,"Traceability supports various activities of the software development process, such as impact analysis of changes, reuse, maintenance, verification and validation. The graphical representation of traceability information is very important to its effective use in those activities. Visualization tools can help in the interaction with large amount of data, in the identification of characteristics, patterns and trends. However, visualization tools are usually built for a specific domain, and generally support a single visualization technique. Therefore, they do not meet appropriately the needs of different contexts. This paper presents a tool to support traceability visualization that provides different visualization techniques, allowing the user to choose the most appropriate to his/her task; the evaluation results of the proposed tool are presented through two studies.",Information Visualization. | Requirements Engineering | Software Engineering | Traceability,10,61-66,Conference Proceeding,Conference Paper,3.0,"Rodrigues, Adriana;Lencastre, Maria;De Cysneiros Filho, Gilberto A.A.",57197905993;8872205400;56505623900,Universidade de Pernambuco;Universidade Federal Rural de Pernambuco,Brazil;Brazil,"traceability supports various activities of the software development process, such as impact analysis of changes, reuse, maintenance, verification and validation. the graphical representation of traceability information is very important to its effective use in those activities. visualization tools can help in the interaction with large amount of data, in the identification of characteristics, patterns and trends. however, visualization tools are usually built for a specific domain, and generally support a single visualization technique. therefore, they do not meet appropriately the needs of different contexts. this paper presents a tool to support traceability visualization that provides different visualization techniques, allowing the user to choose the most appropriate to his/her task; the evaluation results of the proposed tool are presented through two studies.",multi-visiotrace: traceability visualization tool
1184,2-s2.0-85013300562,10.1109/T4E.2016.067,Modeling and Kinematic Analysis of Industrial Robots in WebGL Interface,Dey U.,"Proceedings - IEEE 8th International Conference on Technology for Education, T4E 2016",2017-01-11,"Web-based learning plays a vital role in the modern education system, where different technologies are being emerged to enhance this E-learning process. Therefore virtual and online laboratories are gaining popularity due to its easy implementation and accessibility worldwide. These types of virtual labs are useful where the setup of the actual laboratory is complicated due to several factors such as high machinery or hardware cost. This paper presents a very efficient method of building a model using JavaScript Web Graphics Library with HTML5 enabled and having controllable features inbuilt. This type of program is free from any web browser plug-ins or application and also server independent. Proprietary software has always been a bottleneck in the development of such platforms. This approach rules out this issue and can easily applicable. Here the framework has been discussed and neatly elaborated with an example of a simplified robot configuration.",JavaScript | PUMA560 | Robotics | Three.js | Virtual Laboratory | WebGL,10,256-257,Conference Proceeding,Conference Paper,3.0,"Dey, Ujjal;Jana, Pabitra K.;Kumar, C. S.",57220385848;57193359012;8970357300,Indian Institute of Technology Kharagpur,India,"web-based learning plays a vital role in the modern education system, where different technologies are being emerged to enhance this e-learning process. therefore virtual and online laboratories are gaining popularity due to its easy implementation and accessibility worldwide. these types of virtual labs are useful where the setup of the actual laboratory is complicated due to several factors such as high machinery or hardware cost. this paper presents a very efficient method of building a model using javascript web graphics library with html5 enabled and having controllable features inbuilt. this type of program is free from any web browser plug-ins or application and also server independent. proprietary software has always been a bottleneck in the development of such platforms. this approach rules out this issue and can easily applicable. here the framework has been discussed and neatly elaborated with an example of a simplified robot configuration.",modeling and kinematic analysis of industrial robots in webgl interface
1186,2-s2.0-85119373057,10.1145/3009837.3009867,LMS-Verify: Abstraction without regret for verified systems programming,Amin N.,ACM SIGPLAN Notices,2017-01-01,"Performance critical software is almost always developed in C, as programmers do not trust high-level languages to deliver the same reliable performance. This is bad because low-level code in unsafe languages attracts security vulnerabilities and because development is far less productive, with PL advances mostly lost on programmers operating under tight performance constraints. High-level languages provide memory safety out of the box, but they are deemed too slow and unpredictable for serious system software. Recent years have seen a surge in staging and generative programming: the key idea is to use high-level languages and their abstraction power as glorified macro systems to compose code fragments in first-order, potentially domain-specific, intermediate languages, from which fast C can be emitted. But what about security? Since the end result is still C code, the safety guarantees of the high-level host language are lost. In this paper, we extend this generative approach to emit ACSL specifications along with C code. We demonstrate that staging achieves ''abstraction without regret'' for verification: we show how high-level programming models, in particular higher-order composable contracts from dynamic languages, can be used at generation time to compose and generate first-order specifications that can be statically checked by existing tools. We also show how type classes can automatically attach invariants to data types, reducing the need for repetitive manual annotations. We evaluate our system on several case studies that varyingly exercise verification of memory safety, overflow safety, and functional correctness. We feature an HTTP parser that is (1) fast (2) high-level: implemented using staged parser combinators (3) secure: with verified memory safety. This result is significant, as input parsing is a key attack vector, and vulnerabilities related to HTTP parsing have been documented in all widely-used web servers.",blame | contracts | DSLs | Frama-C | LMS | memory safety | security | verification,1,859-873,Journal,Article,2.0,"Amin, Nada;Rompf, Tiark",55602112900;35107892800,EPFL;Purdue University,Switzerland;United States,"performance critical software is almost always developed in c, as programmers do not trust high-level languages to deliver the same reliable performance. this is bad because low-level code in unsafe languages attracts security vulnerabilities and because development is far less productive, with pl advances mostly lost on programmers operating under tight performance constraints. high-level languages provide memory safety out of the box, but they are deemed too slow and unpredictable for serious system software. recent years have seen a surge in staging and generative programming: the key idea is to use high-level languages and their abstraction power as glorified macro systems to compose code fragments in first-order, potentially domain-specific, intermediate languages, from which fast c can be emitted. but what about security? since the end result is still c code, the safety guarantees of the high-level host language are lost. in this paper, we extend this generative approach to emit acsl specifications along with c code. we demonstrate that staging achieves ''abstraction without regret'' for verification: we show how high-level programming models, in particular higher-order composable contracts from dynamic languages, can be used at generation time to compose and generate first-order specifications that can be statically checked by existing tools. we also show how type classes can automatically attach invariants to data types, reducing the need for repetitive manual annotations. we evaluate our system on several case studies that varyingly exercise verification of memory safety, overflow safety, and functional correctness. we feature an http parser that is (1) fast (2) high-level: implemented using staged parser combinators (3) secure: with verified memory safety. this result is significant, as input parsing is a key attack vector, and vulnerabilities related to http parsing have been documented in all widely-used web servers.",lms-verify: abstraction without regret for verified systems programming
1191,2-s2.0-85054478726,10.1109/MCOMSTD.2017.1700006,Kurento: The Swiss Army Knife of WebRTC Media Servers,Garcia B.,IEEE Communications Standards Magazine,2017-01-01,"In this article we introduce Kurento, an open source WebRTC media server and a set of client APIs intended to simplify the development of applications with rich media capabilities for the Web and smartphone platforms. Kurento features include group communications, transcoding, recording, mixing, broadcasting and routing of audiovisual flows, but also provides advanced media processing capabilities such as computer vision and augmented reality. It is based on a modular architecture, which makes it possible for developers to extend and customize its native capabilities with third-party media processing algorithms. Thanks to all of this, Kurento can be a powerful tool for Web developers who may find natural programming with its Java and JavaScript APIs following the traditional three-tiered Web development model.",Codecs | Internet | Media | Servers | Streaming media | Telecommunication traffic | Transcoding | WebRTC,11,44-51,Journal,Article,4.0,"Garcia, Boni;Lopez-Fernandez, Luis;Gallego, Micael;Gortazar, Francisco",24724315500;7201949992;57202908535;24179404100,Universidad Politécnica de Madrid;Universidad Rey Juan Carlos,Spain;Spain,"in this article we introduce kurento, an open source webrtc media server and a set of client apis intended to simplify the development of applications with rich media capabilities for the web and smartphone platforms. kurento features include group communications, transcoding, recording, mixing, broadcasting and routing of audiovisual flows, but also provides advanced media processing capabilities such as computer vision and augmented reality. it is based on a modular architecture, which makes it possible for developers to extend and customize its native capabilities with third-party media processing algorithms. thanks to all of this, kurento can be a powerful tool for web developers who may find natural programming with its java and javascript apis following the traditional three-tiered web development model.",kurento: the swiss army knife of webrtc media servers
1199,2-s2.0-85040511087,10.3233/978-1-61499-830-3-994,Design of a mobile application for transfusion medicine,Albornoz M.A.,Studies in Health Technology and Informatics,2017-01-01,"One of the most frequent error in transfusion medicine is the failure in verifying the patient's identity prior to transfusion. This paper describes the design and development of a Mobile Application (MA) for transfusion medicine. The app uses barcode and QR reading technology for the verification of the patient's identity and the administration of blood components when making a blood transfusion. Physicians, developers, technicians of transfusion medicine and a User Centered Design team participated in the design. The inclusion of end users was fundamental to get full representativeness of their workflow. The project was based on agile methodologies of project management and software development.",Blood transfusion | Patient identification systems | Patient safety,3,994-998,Book Series,Conference Paper,4.0,"Albornoz, M. A.;Márquez, S.;Rubin, L.;Luna, D.",57200258369;57200260364;57200255354;8437483000,Instituto Universitario del Hospital Italiano de Buenos Aires,Argentina,"one of the most frequent error in transfusion medicine is the failure in verifying the patient's identity prior to transfusion. this paper describes the design and development of a mobile application (ma) for transfusion medicine. the app uses barcode and qr reading technology for the verification of the patient's identity and the administration of blood components when making a blood transfusion. physicians, developers, technicians of transfusion medicine and a user centered design team participated in the design. the inclusion of end users was fundamental to get full representativeness of their workflow. the project was based on agile methodologies of project management and software development.",design of a mobile application for transfusion medicine
1200,2-s2.0-85040258015,10.1016/j.procs.2017.11.115,Satisfaction evaluation of health professionals in the usability of software for monitoring the tuberculosis treatment,Crepaldi N.Y.,Procedia Computer Science,2017-01-01,"The evaluation of health software from the point of view of the health professionals is critical for its success. The work aims to present one of the steps, in this case the usability evaluation, of a more comprehensive protocol of how health software can be evaluated. A software for monitoring tuberculosis treatment (SISTB) was used to test the proposed protocol. The Computer System Usability Questionnaire was the instrument chosen to evaluate software usability. Its adaptation to Portuguese (from Brazil) was performed through three pretests, which obtained high internal consistency, using the Cronbach alpha reliability analysis. SISTB was deployed in three of four referral outpatient clinics for tuberculosis, in the city of Ribeirão Preto, state of São Paulo, Brazil. After three months, health professionals answered the questionnaire. All outpatients presented satisfactory results for usability, showing that the satisfaction degree with software is good and that three months are sufficient for adaptation in relation to the SISTB use. Despite the good acceptance, some suggestions have been proposed, showing that software should be in constant development to facilitate the service of those who use it.",health information system | Health professional satisfaction | tuberculosis | usability,5,889-896,Conference Proceeding,Conference Paper,9.0,"Crepaldi, Nathalia Yukie;De Lima, Inácia Bezerra;Vicentine, Fernanda Bergamini;Rodrigues, Lídia Maria Lourençon;Yamaguti, Verena Hokino;Sanches, Tiago Lara Michelin;Ruffino-Netto, Antonio;Alves, Domingos;Rijo, Rui Pedro Charters Lopes",57194500856;57200212250;57192156121;57200210865;57200215064;56563881600;6701683343;7102862854;57215092692,"School of Technology and Management;Polytechnic Institute of Leiria;Universidade de Coimbra, Instituto de Engenharia de Sistemas E Computadores de Coimbra;Universidade de São Paulo",Portugal;Portugal;Portugal;Brazil,"the evaluation of health software from the point of view of the health professionals is critical for its success. the work aims to present one of the steps, in this case the usability evaluation, of a more comprehensive protocol of how health software can be evaluated. a software for monitoring tuberculosis treatment (sistb) was used to test the proposed protocol. the computer system usability questionnaire was the instrument chosen to evaluate software usability. its adaptation to portuguese (from brazil) was performed through three pretests, which obtained high internal consistency, using the cronbach alpha reliability analysis. sistb was deployed in three of four referral outpatient clinics for tuberculosis, in the city of ribeirão preto, state of são paulo, brazil. after three months, health professionals answered the questionnaire. all outpatients presented satisfactory results for usability, showing that the satisfaction degree with software is good and that three months are sufficient for adaptation in relation to the sistb use. despite the good acceptance, some suggestions have been proposed, showing that software should be in constant development to facilitate the service of those who use it.",satisfaction evaluation of health professionals in the usability of software for monitoring the tuberculosis treatment
1201,2-s2.0-85040021777,10.1016/j.procs.2017.10.044,Harmonik = ++(Web IDE),Yulianto B.,Procedia Computer Science,2017-01-01,"IDE (Integrated Development Environment) that is needed by developers to write sourcecode for computer programming is also starting to shift from desktop to web platform. As implemented in the cloud, Web IDE (WIDE) can be accessed online through browsers and on mobile devices. WIDE takes many advantages and becomes popular in recently years. Unfortunately, there is no tool found yet in currently WIDE to support translating novice programmers' algorithm into programming language before they become experts in techniques of writing computer programs. This study goal is to design a tool to support novice programmers' early learning of programming before they step into coding, compiling, running, and debugging in WIDE. Software development method used in this study is Rational Unified Process (RUP). Conclusion of this study is block-code tool can help novice programmers to learn programming language in early phase, and motivate them better.",Browser IDE | Cloud IDE | Integrated Development Environment | Mobile IDE | Online IDE | Web IDE,2,222-231,Conference Proceeding,Conference Paper,4.0,"Yulianto, Budi;Prabowo, Harjanto;Kosala, Raymond;Hapsara, Manik",6506615618;57222487822;36194762800;24168291200,Bina Nusantara University,Indonesia,"ide (integrated development environment) that is needed by developers to write sourcecode for computer programming is also starting to shift from desktop to web platform. as implemented in the cloud, web ide (wide) can be accessed online through browsers and on mobile devices. wide takes many advantages and becomes popular in recently years. unfortunately, there is no tool found yet in currently wide to support translating novice programmers' algorithm into programming language before they become experts in techniques of writing computer programs. this study goal is to design a tool to support novice programmers' early learning of programming before they step into coding, compiling, running, and debugging in wide. software development method used in this study is rational unified process (rup). conclusion of this study is block-code tool can help novice programmers to learn programming language in early phase, and motivate them better.",harmonik = ++(web ide)
1204,2-s2.0-85034654107,10.14232/actacyb.23.2.2017.16,Automating the refactoring process,Szoke G.,Acta Cybernetica,2017-01-01,"To decrease software maintenance cost, software development companies use static source code analysis techniques. Static analysis tools are capable of finding potential bugs, anti-patterns, coding rule violations, and they can also enforce coding style standards. Although there are several available static analyzers to choose from, they only support issue detection. The elimination of the issues is still performed manually by developers. Here, we propose a process that supports the automatic elimination of coding issues in Java. We introduce a tool that uses a third-party static analyzer as input and enables developers to automatically fix the detected issues for them. Our tool uses a special technique, called reverse AST-search, to locate source code elements in a syntax tree, just based on location information. Our tool was evaluated and tested in a two-year project with six software development companies where thousands of code smells were identified and fixed in five systems that have altogether over five million lines of code.",Code smells | Refactoring | Reverse ast-search | Spatial index,0,715-735,Journal,Conference Paper,1.0,"Szoke, Gábor",55803891600,Szegedi Tudományegyetem (SZTE),Hungary,"to decrease software maintenance cost, software development companies use static source code analysis techniques. static analysis tools are capable of finding potential bugs, anti-patterns, coding rule violations, and they can also enforce coding style standards. although there are several available static analyzers to choose from, they only support issue detection. the elimination of the issues is still performed manually by developers. here, we propose a process that supports the automatic elimination of coding issues in java. we introduce a tool that uses a third-party static analyzer as input and enables developers to automatically fix the detected issues for them. our tool uses a special technique, called reverse ast-search, to locate source code elements in a syntax tree, just based on location information. our tool was evaluated and tested in a two-year project with six software development companies where thousands of code smells were identified and fixed in five systems that have altogether over five million lines of code.",automating the refactoring process
1205,2-s2.0-85033680092,10.1007/978-3-319-67876-4_13,A Javascript Voting Client for Remote Online Voting,Cucurull J.,Communications in Computer and Information Science,2017-01-01,"Remote electronic voting systems enable elections where voters can vote remotely without geographical constraints using their own devices, e.g. smartphones, PCs or other Internet connected devices. Online voting systems have a set of security requirements focused on ensuring at least the same properties of traditional voting scenarios. Specifically, in Scytl’s systems we provide end to end security, which guarantees that a vote is protected from the very beginning when it is generated in the voter’s device until the end of the election when it is decrypted. This requires a specific software in the voters’ devices, referred to as the voting client, in charge of performing most of the cryptographic operations required to protect the ballot. Our first voting clients were developed as Java Applets. However, in 2013 Scytl decided it was imperative to develop a voting client purely based on Javascript, due to the better multi-platform user experience that this web technology offers and due to the increasing loss of Java support in the browsers. This industrial paper describes the initial design challenges of the Javascript voting client, the implementation experience and the lessons learned during its development and deployment for our remote electronic voting systems. The paper is complemented with (1) an analysis of the implemented Pseudo-Random Number Generator, (2) a performance study of the main cryptographic primitives used in our voting clients and (3) a performance study of the voting casting process for a given election setup.",Implementation | Javascript security | Performance | Random number generation | Remote electronic voting,2,266-290,Book Series,Conference Paper,3.0,"Cucurull, Jordi;Guasch, Sandra;Galindo, David",35239767400;56407101600;8905772700,"Scytl Secure Electronic Voting, S.A;University of Birmingham",Spain;United Kingdom,"remote electronic voting systems enable elections where voters can vote remotely without geographical constraints using their own devices, e.g. smartphones, pcs or other internet connected devices. online voting systems have a set of security requirements focused on ensuring at least the same properties of traditional voting scenarios. specifically, in scytl’s systems we provide end to end security, which guarantees that a vote is protected from the very beginning when it is generated in the voter’s device until the end of the election when it is decrypted. this requires a specific software in the voters’ devices, referred to as the voting client, in charge of performing most of the cryptographic operations required to protect the ballot. our first voting clients were developed as java applets. however, in 2013 scytl decided it was imperative to develop a voting client purely based on javascript, due to the better multi-platform user experience that this web technology offers and due to the increasing loss of java support in the browsers. this industrial paper describes the initial design challenges of the javascript voting client, the implementation experience and the lessons learned during its development and deployment for our remote electronic voting systems. the paper is complemented with (1) an analysis of the implemented pseudo-random number generator, (2) a performance study of the main cryptographic primitives used in our voting clients and (3) a performance study of the voting casting process for a given election setup.",a javascript voting client for remote online voting
1206,2-s2.0-85033460107,10.1016/j.procs.2017.08.289,Towards An Application Architecture for A Smart Online Service Network Platform for the Elderly,Brune P.,Procedia Computer Science,2017-01-01,"Online Social and Service Network Platforms for supporting elderly people with respect to their health and well-being have been discussed on the conceptual level by various authors. Here, in particular the so-called transition age between 55 and 75 is important and therefore has also been addressed, e.g. with respect to user interface (UI) requirements. As a logical next step, in this paper an application architecture for such a kind of online service network platform is proposed, designed consequently using state-of-the-art concepts like server-side JavaScript, NoSQL databases and machine learning. Since only few studies about such kind of modern software architectures exist in the literature, this is a first step towards analyzing their implications for web application development. Peer-review under responsibility of the Conference Program Chairs.",Elderly People | Online Social Network | Retrieval | Service Composition | Service Description | Software Architecture | Web Development,1,442-447,Conference Proceeding,Conference Paper,2.0,"Brune, Philipp;Rockmann, Robert",49862725400;56609145400,Fachhochschule Neu-Ulm,Germany,"online social and service network platforms for supporting elderly people with respect to their health and well-being have been discussed on the conceptual level by various authors. here, in particular the so-called transition age between 55 and 75 is important and therefore has also been addressed, e.g. with respect to user interface (ui) requirements. as a logical next step, in this paper an application architecture for such a kind of online service network platform is proposed, designed consequently using state-of-the-art concepts like server-side javascript, nosql databases and machine learning. since only few studies about such kind of modern software architectures exist in the literature, this is a first step towards analyzing their implications for web application development. peer-review under responsibility of the conference program chairs.",towards an application architecture for a smart online service network platform for the elderly
1207,2-s2.0-85032363249,10.1016/j.procs.2017.08.176,"A Prototype of an Integrated Telemetry Receiving System with Volunteers: Designs of a Simple Receiver, a Protocol, and an Intelligent Information Processing",Tokumitsu M.,Procedia Computer Science,2017-01-01,"In this paper, we propose ""social diversity"" which is an integrated satellite telemetry receiving system with volunteers. In the proposed system, a number of volunteer receivers catch the satellite signals with a simplified cheap receiver, instead of using a comprehensive and expensive antenna receiving station. Although such signals may contain various errors or may be lost, the intelligent information techniques can compensate such signals by using a number of simultaneously received signals and profiled data. For the purpose of the whole system developments, we tackle mainly three issues. Firstly, we develop a simple receiver for the amateur bands radio waves. Secondly, we design the receiving data format for the transfer and server-client web receiving system. Finally, we thrash out suitable intelligent information techniques for our system. Here we report a development status of our whole satellite telemetry system. Especially, this report focuses on the simple SDR (Software-Defined Radio) receiver for the voluntary observers and a prototype of the web system for collecting a number of satellite telemetry data and compensating the incomplete telemetry data.",dynamical relational network | intelligent information processing | sensor networks | social diversity | spatiotemporal interpolation | volunteers,2,2445-2454,Conference Proceeding,Conference Paper,8.0,"Tokumitsu, Masahiro;Asai, Fumio;Kusakabe, Masaki;Ogura, Souta;Aoki, Satoshi;Takada, Taku;Wakabayashi, Makoto;Ishida, Yoshiteru",25926740000;57225808568;57196237111;57196235076;57196246797;57196234993;57196248649;7402605796,"National Institute of Technology, Nara College;National Institute of Technology, Niihama College;National Institute of Technology, Yonago College;National Institute of Technology, Kochi College;Toyohashi University of Technology",Japan;Japan;Japan;Japan;Japan,"in this paper, we propose ""social diversity"" which is an integrated satellite telemetry receiving system with volunteers. in the proposed system, a number of volunteer receivers catch the satellite signals with a simplified cheap receiver, instead of using a comprehensive and expensive antenna receiving station. although such signals may contain various errors or may be lost, the intelligent information techniques can compensate such signals by using a number of simultaneously received signals and profiled data. for the purpose of the whole system developments, we tackle mainly three issues. firstly, we develop a simple receiver for the amateur bands radio waves. secondly, we design the receiving data format for the transfer and server-client web receiving system. finally, we thrash out suitable intelligent information techniques for our system. here we report a development status of our whole satellite telemetry system. especially, this report focuses on the simple sdr (software-defined radio) receiver for the voluntary observers and a prototype of the web system for collecting a number of satellite telemetry data and compensating the incomplete telemetry data.","a prototype of an integrated telemetry receiving system with volunteers: designs of a simple receiver, a protocol, and an intelligent information processing"
1209,2-s2.0-85030867279,10.11591/ijece.v7i4.pp2132-2141,A review on web application testing and its current research directions,Lakshmi D.R.,International Journal of Electrical and Computer Engineering,2017-01-01,"Testing is an important part of every software development process on which companies devote considerable time and effort. The burgeoning web applications and their proliferating economic significance in the society made the area of web application testing an area of acute importance. The web applications generally tend to take faster and quicker release cycles making their testing very challenging. The main issues in testing are cost efficiency and bug detection efficiency. Coverage-based testing is the process of ensuring exercise of specific program elements. Coverage measurement helps determine the ""thoroughness"" of testing achieved. An avalanche of tools, techniques, frameworks came into existence to ascertain the quality of web applications. A comparative study of some of the prominent tools, techniques and models for web application testing is presented. This work highlights the current research directions of some of the web application testing techniques.",Automated testing | Coverage testing | Testing techniques | Testing tools | Web application testing,17,2132-2141,Journal,Article,2.0,"Lakshmi, D. Rajya;Mallika, S. Suguna",55446136700;57211310382,CVR College of Engineering;JNTUK-UCEN,India;India,"testing is an important part of every software development process on which companies devote considerable time and effort. the burgeoning web applications and their proliferating economic significance in the society made the area of web application testing an area of acute importance. the web applications generally tend to take faster and quicker release cycles making their testing very challenging. the main issues in testing are cost efficiency and bug detection efficiency. coverage-based testing is the process of ensuring exercise of specific program elements. coverage measurement helps determine the ""thoroughness"" of testing achieved. an avalanche of tools, techniques, frameworks came into existence to ascertain the quality of web applications. a comparative study of some of the prominent tools, techniques and models for web application testing is presented. this work highlights the current research directions of some of the web application testing techniques.",a review on web application testing and its current research directions
1212,2-s2.0-85028656136,10.1016/j.procs.2017.06.105,Modern and Responsive Mobile-enabled Web Applications,Shahzad F.,Procedia Computer Science,2017-01-01,"Rapid web technology improvements in the last few years have powered software developers to quickly write responsive mobile-friendly applications. The innovative web frameworks and libraries make it easy to have same software code base for desktop and mobile devices. Single-page applications offer a more-native-app-like experience to the user. This also means a web application can easily be converted to a native mobile application if desired. This allows software products to be evolved continuously at a much faster pace with features added on daily basis. The software companies who can adopt these technologies will most likely see the benefit in the long run as they can offer new and modified products faster than their competitors. In this paper, we review some of the state-of-the-art web technologies, third-party libraries, and frameworks for quick interactive web development. Finally, we present a simple interactive browser-based, mobile friendly web application which was developed using one of the latest web development framework.",JavaScript | Mobile-friendly Application | Single-Page Applications | Web Framework | Web-based Applications,24,410-415,Conference Proceeding,Conference Paper,1.0,"Shahzad, Farrukh",55887105100,Polestar Global,United States,"rapid web technology improvements in the last few years have powered software developers to quickly write responsive mobile-friendly applications. the innovative web frameworks and libraries make it easy to have same software code base for desktop and mobile devices. single-page applications offer a more-native-app-like experience to the user. this also means a web application can easily be converted to a native mobile application if desired. this allows software products to be evolved continuously at a much faster pace with features added on daily basis. the software companies who can adopt these technologies will most likely see the benefit in the long run as they can offer new and modified products faster than their competitors. in this paper, we review some of the state-of-the-art web technologies, third-party libraries, and frameworks for quick interactive web development. finally, we present a simple interactive browser-based, mobile friendly web application which was developed using one of the latest web development framework.",modern and responsive mobile-enabled web applications
1214,2-s2.0-85027885917,10.1007/978-3-319-63315-2_19,A code quality metrics model for react-based web applications,Lin Y.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2017-01-01,"With the increasing of website user experiences, the interactive UI effect adds the complexity of web applications, which results in the development of Web front-end frameworks. Nevertheless, the existing code quality metrics models are not able to measure the code quality of Web front-end frameworks effectively. On the other hand, it is also difficult to present a quality metrics model that can evaluate the software frameworks comprehensively, so we should focus on a specific measurement object in order to improve accuracy of metrics. On this groundwork, we present a code quality metrics model for Web front-end frameworks based on React. In this model, we put forward 16 metric units, according to the characteristics of JavaScript and React through experiments. Then we determine the quantitative rules for each metric unit. At long last, we generate a set of scores to measure Web applications. In the part of experiment, firstly we select two projects as our benchmarks, then we choose a real project to evaluate the code qualify and compare the results with people’s evaluation of this project. The experiment results imply that this model is reliable and has some directing significance. The primary contributions of this paper are proposing a new code quality metrics model for JavaScript and React, which is a new research direction in the area of code quality metrics. By this model, we can monitor code quality and enhance development efficiency.",Code quality metrics model | Quantitative rules | React | Web front-end language,2,215-226,Book Series,Conference Paper,4.0,"Lin, Yiwei;Li, Min;Yang, Chen;Yin, Changqing",57195413594;57195409103;56176105900;55267105900,Tongji University;Fudan University,China;China,"with the increasing of website user experiences, the interactive ui effect adds the complexity of web applications, which results in the development of web front-end frameworks. nevertheless, the existing code quality metrics models are not able to measure the code quality of web front-end frameworks effectively. on the other hand, it is also difficult to present a quality metrics model that can evaluate the software frameworks comprehensively, so we should focus on a specific measurement object in order to improve accuracy of metrics. on this groundwork, we present a code quality metrics model for web front-end frameworks based on react. in this model, we put forward 16 metric units, according to the characteristics of javascript and react through experiments. then we determine the quantitative rules for each metric unit. at long last, we generate a set of scores to measure web applications. in the part of experiment, firstly we select two projects as our benchmarks, then we choose a real project to evaluate the code qualify and compare the results with people’s evaluation of this project. the experiment results imply that this model is reliable and has some directing significance. the primary contributions of this paper are proposing a new code quality metrics model for javascript and react, which is a new research direction in the area of code quality metrics. by this model, we can monitor code quality and enhance development efficiency.",a code quality metrics model for react-based web applications
1216,2-s2.0-85025130558,10.1007/978-3-319-58521-5_12,Programming of a visualization for a robot teach pendant,Galen S.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2017-01-01,"The intention of this paper is to develop and implement a user interface for the teach pendant of the new generation of robot controllers by Stäubli. The user interface is realized on the basis of an already existing visualization in the production of Miele in Bielefeld. In order to guarantee a structured development, the method of software-reengineering is used. In the first two steps it is necessary to analyze the tasks and functions of the existing software and to model the current state and the actual technical implementations. The requirements for the redesign of the software have to be compiled next. With the help of this requirements it is possible to develop a new user interface which includes the future layout and utilization [1, pp. 385–387]. The finished software helps to introduce the new technology into familiar operational procedures without any training of the employees.",Robotics | User interface,1,161-169,Book Series,Conference Paper,3.0,"Galen, Sebastian;Liedtke, Dirk;Schilberg, Daniel",57195074698;57195064307;15728740200,Ruhr-Universitat Bochum;Miele AG,Germany;Germany,"the intention of this paper is to develop and implement a user interface for the teach pendant of the new generation of robot controllers by stäubli. the user interface is realized on the basis of an already existing visualization in the production of miele in bielefeld. in order to guarantee a structured development, the method of software-reengineering is used. in the first two steps it is necessary to analyze the tasks and functions of the existing software and to model the current state and the actual technical implementations. the requirements for the redesign of the software have to be compiled next. with the help of this requirements it is possible to develop a new user interface which includes the future layout and utilization [1, pp. 385–387]. the finished software helps to introduce the new technology into familiar operational procedures without any training of the employees.",programming of a visualization for a robot teach pendant
1219,2-s2.0-85021343311,10.4108/eai.25-10-2016.2266614,J2CBROKER: A service broker simulation tool for cooperative clouds,Giacobbe M.,ValueTools 2016 - 10th EAI International Conference on Performance Evaluation Methodologies and Tools,2017-01-01,"The Internet and digital technologies are transforming our world, but existing barriers, mainly due to obsolete Information Technologies (IT), lead citizens to miss out on goods and services, enterprises and start-ups to limit their horizons, and businesses and governments to cannot fully benefit from digital tools. Recently, Cloud computing emerged as hot topic in IT, both in industrial and academic area, in order to overcome the above barriers. Its use in large scale distributed infrastructure, platform or software services is motivated by the possibility to promote a new economy of scale in different contexts. Such scenario demands timely, repeatable, and controllable methodologies for evaluation of algorithms, applications and policies before the development of Cloud services or products, especially to achieve a good compromise between several performance indicators. To this end, simulations-based environments allow to evaluate the hypothesis prior to the software development, thus reducing the risk of economic losses, scarce Quality of Service or Quality of Experience. In this paper we present and discuss a simulation-based approach for Cloud Brokerage ecosystems. More specifically, we propose the J2CBROKER Simulation Tool, mainly based on JAVA and JavaScript Object Notation (JSON) technologies. Its architecture, functionalities and technological choices are discussed and motivated. Moreover, we present a case of study to evaluate the goodness of the proposed approach.",Broker | Cloud brokerage | Cloud computing | Cooperative clouds | Digital single market | JAVA | JavaScript object notation | Key performance Indicator | Simulation tool,3,68-73,Conference Proceeding,Conference Paper,4.0,"Giacobbe, Maurizio;Di Pietro, Riccardo;Puliafito, Carlo;Scarpa, Marco",56572479700;57194637644;57196814580;35751680500,Università degli Studi di Messina;Università degli Studi di Catania,Italy;Italy,"the internet and digital technologies are transforming our world, but existing barriers, mainly due to obsolete information technologies (it), lead citizens to miss out on goods and services, enterprises and start-ups to limit their horizons, and businesses and governments to cannot fully benefit from digital tools. recently, cloud computing emerged as hot topic in it, both in industrial and academic area, in order to overcome the above barriers. its use in large scale distributed infrastructure, platform or software services is motivated by the possibility to promote a new economy of scale in different contexts. such scenario demands timely, repeatable, and controllable methodologies for evaluation of algorithms, applications and policies before the development of cloud services or products, especially to achieve a good compromise between several performance indicators. to this end, simulations-based environments allow to evaluate the hypothesis prior to the software development, thus reducing the risk of economic losses, scarce quality of service or quality of experience. in this paper we present and discuss a simulation-based approach for cloud brokerage ecosystems. more specifically, we propose the j2cbroker simulation tool, mainly based on java and javascript object notation (json) technologies. its architecture, functionalities and technological choices are discussed and motivated. moreover, we present a case of study to evaluate the goodness of the proposed approach.",j2cbroker: a service broker simulation tool for cooperative clouds
1220,2-s2.0-85020751444,10.1016/j.enconman.2017.06.031,Novel remote monitoring platform for RES-hydrogen based smart microgrid,González I.,Energy Conversion and Management,2017-01-01,"In the context of the future power grids – Smart Grids (SGs) – Smart MicroGrids (SMGs) play a paramount role. These ones are very specific portions of the SGs that deal with integration of small-rated distributed energy and storage resources closer to the loads – chiefly within the distribution domain. Data acquisition and monitoring tasks are vital functions that must be developed at every stage of the grid for a proper operation. This paper presents a remote monitoring platform (RMP) to monitor an experimental SMG. It integrates Renewable Energy Sources (RESs) (solar and wind) and hydrogen to operate in isolated regime. The RMP has been developed using the open-source authoring tool Easy Java/Javascript Simulations (EJsS). The interface has been designed to be intuitive and easy-to-use, providing real-time information of all the involved magnitudes over the network. Scalability, easy development, portability and cost effective are the main features of the proposed framework. The microgrid and the proposed monitoring platform are described and the successful results are reported. The remote user executes a ready-to-use file with low computational requirements and is enabled to graphically and numerically track the SMG behaviour. These results prove the suitability of the RMP as an effective means for continuous visualization of the coordinated energy flows of a real SMG.",Easy Java/Javascript Simulations | Hydrogen | Remote monitoring | Renewable energy sources | Smart grid | Smart microgrid,35,489-505,Journal,Article,3.0,"González, I.;Calderón, A. J.;Andújar, J. M.",57162296900;8524755000;10241452600,Universidad de Extremadura,Spain,"in the context of the future power grids – smart grids (sgs) – smart microgrids (smgs) play a paramount role. these ones are very specific portions of the sgs that deal with integration of small-rated distributed energy and storage resources closer to the loads – chiefly within the distribution domain. data acquisition and monitoring tasks are vital functions that must be developed at every stage of the grid for a proper operation. this paper presents a remote monitoring platform (rmp) to monitor an experimental smg. it integrates renewable energy sources (ress) (solar and wind) and hydrogen to operate in isolated regime. the rmp has been developed using the open-source authoring tool easy java/javascript simulations (ejss). the interface has been designed to be intuitive and easy-to-use, providing real-time information of all the involved magnitudes over the network. scalability, easy development, portability and cost effective are the main features of the proposed framework. the microgrid and the proposed monitoring platform are described and the successful results are reported. the remote user executes a ready-to-use file with low computational requirements and is enabled to graphically and numerically track the smg behaviour. these results prove the suitability of the rmp as an effective means for continuous visualization of the coordinated energy flows of a real smg.",novel remote monitoring platform for res-hydrogen based smart microgrid
1221,2-s2.0-85019619643,10.1007/978-3-319-57735-7_16,"Release early, release often and release on time. An empirical case study of release management",Teixeira J.,IFIP Advances in Information and Communication Technology,2017-01-01,"The dictum of “Release early, release often.” by Eric Raymond as the Linux modus operandi highlights the importance of release management in open source software development. Nevertheless, there are very few empirical studies addressing release management in open source software development. It is already known that most open source software communities adopt either feature-based or time-based release strategies. Each of these has its advantages and disadvantages that are context-specific. Recent research reported that many prominent open source software projects have moved from feature-based to time-based releases. In this longitudinal case study, we narrate how OpenStack shifted towards a liberal six-month release cycle. If prior research discussed why projects should adopt time-based releases and how they can adopt such a strategy, we discuss how OpenStack adapted its software development processes, its organizational design and its tools toward a hybrid release management strategy — a strive for balancing the benefits and drawbacks of feature-based and time-based release strategies.",FLOSS | Open-Source | Open-Stack | OSS | Release management,4,167-181,Book Series,Conference Paper,1.0,"Teixeira, Jose",37102821000,Åbo Akademi University;Turku Centre for Computer Science,Finland;Finland,"the dictum of “release early, release often.” by eric raymond as the linux modus operandi highlights the importance of release management in open source software development. nevertheless, there are very few empirical studies addressing release management in open source software development. it is already known that most open source software communities adopt either feature-based or time-based release strategies. each of these has its advantages and disadvantages that are context-specific. recent research reported that many prominent open source software projects have moved from feature-based to time-based releases. in this longitudinal case study, we narrate how openstack shifted towards a liberal six-month release cycle. if prior research discussed why projects should adopt time-based releases and how they can adopt such a strategy, we discuss how openstack adapted its software development processes, its organizational design and its tools toward a hybrid release management strategy — a strive for balancing the benefits and drawbacks of feature-based and time-based release strategies.","release early, release often and release on time. an empirical case study of release management"
1222,2-s2.0-85018708712,10.1007/978-3-319-57141-6_20,Using virtualization technology for the user authorization system,Polenov M.,Advances in Intelligent Systems and Computing,2017-01-01,"The paper deals with the use of virtualization technology for the development of software system that supports authorization of Wi-Fi networks users. The suggested approach is to use two databases of operators and users, implemented on MySQL, and two subsystems of registration and authorization to be placed on a virtual machine. The paper presents the organization and a general algorithm of the authorization system operation, as well as the load analysis of server with the authorization system. Here considered the graph of hardware resources loads used by the virtual machine. Using the hypervisor allows changing the configuration and provides the possibility to monitor the virtual machine, the necessary disk space, the memory consumption and CPU usage.",Authorization system | Database | Server | Virtual machine | Virtualization | Wireless network,1,192-200,Book Series,Conference Paper,3.0,"Polenov, Maxim;Guzik, Vyacheslav;Lukyanov, Vladislav",6504788838;6603025165;57189030320,Southern Federal University,Russian Federation,"the paper deals with the use of virtualization technology for the development of software system that supports authorization of wi-fi networks users. the suggested approach is to use two databases of operators and users, implemented on mysql, and two subsystems of registration and authorization to be placed on a virtual machine. the paper presents the organization and a general algorithm of the authorization system operation, as well as the load analysis of server with the authorization system. here considered the graph of hardware resources loads used by the virtual machine. using the hypervisor allows changing the configuration and provides the possibility to monitor the virtual machine, the necessary disk space, the memory consumption and cpu usage.",using virtualization technology for the user authorization system
1224,2-s2.0-85018686279,10.1007/978-3-319-57288-8_24,Event-B at work: Some lessons learnt from an application to a robot anti-collision function,Dieumegard A.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2017-01-01,"The technical and academic aspects of the Event-B method, and the abstract description of its application in industrial contexts are the subjects of numerous publications. In this paper, we describe the experience of development engineers non familiar with Event-B to getting to grips with this method. We describe in details how we used the formalism, the refinement method, and its supporting toolset to develop the simple anti-collision function embedded in a small rolling robot. We show how the model has been developed from a set of high-level requirements and refined down to the software specification. For each phase of the development, we explain how we used the method, expose the encountered difficulties, and draw some practical lessons from this experiment.",Anti-collision | Event-B | Formal refinement | Formal verification | Software verification,2,327-341,Book Series,Conference Paper,3.0,"Dieumegard, Arnaud;Ge, Ning;Jenn, Eric",55580662300;55317520400;6506594130,Thales Aerospace;Systerel Toulouse La Maison des Lois;IRT Saint-Exupéry,France;France;France,"the technical and academic aspects of the event-b method, and the abstract description of its application in industrial contexts are the subjects of numerous publications. in this paper, we describe the experience of development engineers non familiar with event-b to getting to grips with this method. we describe in details how we used the formalism, the refinement method, and its supporting toolset to develop the simple anti-collision function embedded in a small rolling robot. we show how the model has been developed from a set of high-level requirements and refined down to the software specification. for each phase of the development, we explain how we used the method, expose the encountered difficulties, and draw some practical lessons from this experiment.",event-b at work: some lessons learnt from an application to a robot anti-collision function
1225,2-s2.0-85018666795,10.1007/978-3-319-57141-6_49,Chart visualization of large data amount,Pokorný P.,Advances in Intelligent Systems and Computing,2017-01-01,"The main task of this paper is to describe the form of large data amount obtaining, its processing and a chart visualization. In order to get required information, charts need to have the interactive character with many setting parameters and properties. For these reasons, many visualization libraries exist that simplify the developer’s work. In this paper there, most used chart visualization web libraries are described. In the next part, the new software solution was designed. Its development and realization was based on the real data from the industrial environment.",Application | Charts | Data | Processing | Visualization,3,460-468,Book Series,Conference Paper,2.0,"Pokorný, Pavel;Stokláska, Kamil",24381679500;57193488997,Univerzita Tomáse Bati ve Zlině,Czech Republic,"the main task of this paper is to describe the form of large data amount obtaining, its processing and a chart visualization. in order to get required information, charts need to have the interactive character with many setting parameters and properties. for these reasons, many visualization libraries exist that simplify the developer’s work. in this paper there, most used chart visualization web libraries are described. in the next part, the new software solution was designed. its development and realization was based on the real data from the industrial environment.",chart visualization of large data amount
1226,2-s2.0-85018406940,10.1007/978-981-10-4086-3_80,Virtual environment as complementary tool to learning of the imaginology dental care,Neto P.,IFMBE Proceedings,2017-01-01,"The study of dental radiographic image requires, in addition to knowledge of anatomy, injuries of knowledge and their interpretations. This work aims to develop a Virtual Learning Environment (VLE) for knowledge tests with focus on the image through the assistance of information technology as a facilitator to access a virtual learning environment. The main idea is that environment presents a greater number of radiographic images, thereby allowing greater learning in the interpretation of images possible. The software used for the development of AVA was Notepad ++, which is free and HTML, JavaScript, jQuery, CSS. 18 screens were prepared with different levels of difficulty and based on the ISO 9126 interface. AVA was analyzed by a group of graduate professors from the University of Mogi das Cruzes resulting in an excellent evaluation.",Computer-assisted learning | Software in oral radiology | Technology assistance,0,316-319,Conference Proceeding,Conference Paper,3.0,"Neto, P. B.;Abreu, F. D.L.;Rodrigues, S. C.M.",57206456295;57194030910;55628105100,Universidade de Mogi das Cruzes,Brazil,"the study of dental radiographic image requires, in addition to knowledge of anatomy, injuries of knowledge and their interpretations. this work aims to develop a virtual learning environment (vle) for knowledge tests with focus on the image through the assistance of information technology as a facilitator to access a virtual learning environment. the main idea is that environment presents a greater number of radiographic images, thereby allowing greater learning in the interpretation of images possible. the software used for the development of ava was notepad ++, which is free and html, javascript, jquery, css. 18 screens were prepared with different levels of difficulty and based on the iso 9126 interface. ava was analyzed by a group of graduate professors from the university of mogi das cruzes resulting in an excellent evaluation.",virtual environment as complementary tool to learning of the imaginology dental care
1229,2-s2.0-85015850758,10.4018/IJMCMC.2017010103,A novel software protection approach for code obfuscation to enhance software security,Gautam P.,International Journal of Mobile Computing and Multimedia Communications,2017-01-01,"Over the past few decades ago, software developers analyzed robustly several forms of software protection against illegal coping or piracy. With the expansion in digital technology, the risk of illegal coping of software also amplifies. The increasing piracy rate has posed a serious threat to software developers leading to the development of various software protection techniques. However, various techniques have been proposed for copright protection such as software watermarking, obfuscation, tamper-proofing and diversity. The code transformation (obfuscation) is a method of transforming a program into a form which is more complicated for an adversary to understand or change the original code from an illegitimate process of reverse engineering. None of the current code obfuscation approaches provide resistance from reverse engineering attacks. The reverse engineering threat occurs due to the unconfined software code to the user. Malicious reverse engineering of software codes can be harder by exertion of code transformation on software programs. To address this, we acquaint a peculiar code transformation approach for software protection. The proposed approach is used semantically equivalent to code clone within the source code to protect logical part of program text. We have successfully implement our approach using open source Java project Gantt project system and open source Java obfuscator's tools. In this paper, we present our approach and demonstrate it with an illustration. The intent of this method is to prevent static analysis attack and make dynamic attack compact for an adversary. This makes it worthwhile against reverse engineering attacks.",Code clone | Obfuscation | Reverse engineering | Software security | Tampering | Watermarking,4,34-47,Journal,Article,2.0,"Gautam, Pratiksha;Saini, Hemraj",57192957690;23095548700,"Jaypee University of Information Technology, Solan",India,"over the past few decades ago, software developers analyzed robustly several forms of software protection against illegal coping or piracy. with the expansion in digital technology, the risk of illegal coping of software also amplifies. the increasing piracy rate has posed a serious threat to software developers leading to the development of various software protection techniques. however, various techniques have been proposed for copright protection such as software watermarking, obfuscation, tamper-proofing and diversity. the code transformation (obfuscation) is a method of transforming a program into a form which is more complicated for an adversary to understand or change the original code from an illegitimate process of reverse engineering. none of the current code obfuscation approaches provide resistance from reverse engineering attacks. the reverse engineering threat occurs due to the unconfined software code to the user. malicious reverse engineering of software codes can be harder by exertion of code transformation on software programs. to address this, we acquaint a peculiar code transformation approach for software protection. the proposed approach is used semantically equivalent to code clone within the source code to protect logical part of program text. we have successfully implement our approach using open source java project gantt project system and open source java obfuscator's tools. in this paper, we present our approach and demonstrate it with an illustration. the intent of this method is to prevent static analysis attack and make dynamic attack compact for an adversary. this makes it worthwhile against reverse engineering attacks.",a novel software protection approach for code obfuscation to enhance software security
1231,2-s2.0-85009812142,10.1007/978-981-10-2104-6_10,Design and development of 3-D urban geographical information retrieval application employing only open source instruments,Khan A.P.,Advances in Intelligent Systems and Computing,2017-01-01,"Numerous 3-D GIS are being developed today that are both commercially and freely available. A multicity web-based 3-D GIS (named as GLC3d) using open source and freely available software/packages exclusively has been developed. This paper presents the architecture, design, and overview of GLC3d. Open source tools and software’s QGIS, Cesium, and MySQL are employed to develop this application. QGIS is utilized for data preparation such as raster, vector, and subsidiary data. MySQL is utilized as database store and data population. GLC3d is based on Cesium (a JavaScript library for creating 3-D globes and 2-D maps in a web browser) and WebGL (a JavaScript API for rendering interactive 3-D computer graphics and 2-D graphics) to display 3-D Globe on the web browser. 3-D visualization for the urban/city geodata is presented on an interactive 3-D Globe. Various city information are generated and incorporated in to the 3-D WebGIS for data representation and decision making.",Cesium | DTM (Digital Terrain Model) | GeoJSON | GIS (Geographical Information System) | KML (Key Hole markup Language) | MySQL | OGC (Open Geospatial Consortium) | WebGL (Web Graphics Library) | WMS (Web Map Service),0,101-108,Book Series,Conference Paper,3.0,"Khan, Ajaze Parvez;Porwal, Sudhir;Khare, Sangeeta",57192992755;16069056500;55583470100,Defence Research and Development Organisation India,India,"numerous 3-d gis are being developed today that are both commercially and freely available. a multicity web-based 3-d gis (named as glc3d) using open source and freely available software/packages exclusively has been developed. this paper presents the architecture, design, and overview of glc3d. open source tools and software’s qgis, cesium, and mysql are employed to develop this application. qgis is utilized for data preparation such as raster, vector, and subsidiary data. mysql is utilized as database store and data population. glc3d is based on cesium (a javascript library for creating 3-d globes and 2-d maps in a web browser) and webgl (a javascript api for rendering interactive 3-d computer graphics and 2-d graphics) to display 3-d globe on the web browser. 3-d visualization for the urban/city geodata is presented on an interactive 3-d globe. various city information are generated and incorporated in to the 3-d webgis for data representation and decision making.",design and development of 3-d urban geographical information retrieval application employing only open source instruments
1232,2-s2.0-84965064375,10.1007/s00330-016-4344-0,Development of an IHE MRRT-compliant open-source web-based reporting platform,Pinto dos Santos D.,European Radiology,2017-01-01,"Objectives: To develop a platform that uses structured reporting templates according to the IHE Management of Radiology Report Templates (MRRT) profile, and to implement this platform into clinical routine. Methods: The reporting platform uses standard web technologies (HTML / JavaScript and PHP / MySQL) only. Several freely available external libraries were used to simplify the programming. The platform runs on a standard web server, connects with the radiology information system (RIS) and PACS, and is easily accessible via a standard web browser. Results: A prototype platform that allows structured reporting to be easily incorporated into the clinical routine was developed and successfully tested. To date, 797 reports were generated using IHE MRRT-compliant templates (many of them downloaded from the RSNA’s radreport.org website). Reports are stored in a MySQL database and are easily accessible for further analyses. Conclusion: Development of an IHE MRRT-compliant platform for structured reporting is feasible using only standard web technologies. All source code will be made available upon request under a free license, and the participation of other institutions in further development is welcome. Key Points: • A platform for structured reporting using IHE MRRT-compliant templates is presented. • Incorporating structured reporting into clinical routine is feasible. • Full source code will be provided upon request under a free license.",Database | Medical informatics | Radiology | Reference standards | Technology,26,424-430,Journal,Article,6.0,"Pinto dos Santos, Daniel;Klos, G.;Kloeckner, R.;Oberle, R.;Dueber, C.;Mildenberger, P.",55507647300;8644533200;35096234800;57189066043;7005034780;7006217284,Universitätsmedizin Mainz,Germany,"objectives: to develop a platform that uses structured reporting templates according to the ihe management of radiology report templates (mrrt) profile, and to implement this platform into clinical routine. methods: the reporting platform uses standard web technologies (html / javascript and php / mysql) only. several freely available external libraries were used to simplify the programming. the platform runs on a standard web server, connects with the radiology information system (ris) and pacs, and is easily accessible via a standard web browser. results: a prototype platform that allows structured reporting to be easily incorporated into the clinical routine was developed and successfully tested. to date, 797 reports were generated using ihe mrrt-compliant templates (many of them downloaded from the rsna’s radreport.org website). reports are stored in a mysql database and are easily accessible for further analyses. conclusion: development of an ihe mrrt-compliant platform for structured reporting is feasible using only standard web technologies. all source code will be made available upon request under a free license, and the participation of other institutions in further development is welcome. key points: • a platform for structured reporting using ihe mrrt-compliant templates is presented. • incorporating structured reporting into clinical routine is feasible. • full source code will be provided upon request under a free license.",development of an ihe mrrt-compliant open-source web-based reporting platform
1234,2-s2.0-85010282273,10.1109/ICCOINS.2016.7783283,A preliminary analysis of various testing techniques in Agile development - A systematic literature review,Thangiah M.,"2016 3rd International Conference on Computer and Information Sciences, ICCOINS 2016 - Proceedings",2016-12-14,"There are numerous software development and testing methods, tools and techniques have emerged over the past few decades with the main objective are to enhance the software quality. In Small and Medium size Enterprises (SME's), Agile methods have been gaining acceptance but quality of the product it produced is remains as the major concern because the tesing methods and standards are not improved. In Agile development process, though there are many testing techniques are exists, SME's cannot afford to follow the traditional methods of testing process, because of high cost and it is a time consuming process. In this research paper, only the issues surfaced in Regression Testing and Automated Testing are analysed and proposed that exploratory testing (ET) methods either can be used as an alternative or can be integrate along with the existing testing methods. However, there is not enough research work is conducted on Exploratory testing and emphasized the importance to focus more research work to be carried out in ET.",Agile development | Exploratory software Testing | SME's,6,600-605,Conference Proceeding,Conference Paper,2.0,"Thangiah, Murugan;Basri, Shuib",55434081900;36536436600,Universiti Teknologi PETRONAS,Malaysia,"there are numerous software development and testing methods, tools and techniques have emerged over the past few decades with the main objective are to enhance the software quality. in small and medium size enterprises (sme's), agile methods have been gaining acceptance but quality of the product it produced is remains as the major concern because the tesing methods and standards are not improved. in agile development process, though there are many testing techniques are exists, sme's cannot afford to follow the traditional methods of testing process, because of high cost and it is a time consuming process. in this research paper, only the issues surfaced in regression testing and automated testing are analysed and proposed that exploratory testing (et) methods either can be used as an alternative or can be integrate along with the existing testing methods. however, there is not enough research work is conducted on exploratory testing and emphasized the importance to focus more research work to be carried out in et.",a preliminary analysis of various testing techniques in agile development - a systematic literature review
1238,2-s2.0-85010434673,10.1109/ISETC.2016.7781075,Towards a generic gamification of sorting algorithms,Chirila C.B.,"2016 12th International Symposium on Electronics and Telecommunications, ISETC 2016 - Conference Proceedings",2016-12-09,"Computer science disciplines are very important in the context of an emerging IT industry especially in the Eastern Europe countries where lots of companies invested in research and development sites. The need for highly qualified specialists is very acute and is expressed in several occasions as a request addressed to universities to double the number of bachelor graduates. In this sense universities try to adapt and they provide distance learning programs. In this context all the advantages of software must be used: generative learning objects, gamifications etc. A gamification model for sorting algorithms is proposed in this sense in order to exercise the logic steps of programming and algorithms thus triggering a way of thinking that is needed in the creation of new software. To motivate the student in performing the exercise we used some elements of game mechanics like score and difficulty levels. All the newly created e-learning models are provided to the student through an online web application.",computer science disciplines | gamification | scores,4,133-136,Conference Proceeding,Conference Paper,3.0,"Chirila, Ciprian Bogdan;Raes, Remy;Roland, Arthur",27067559900;57193071968;57193065411,Université de Lille;Universitatea Politehnica Timisoara,France;Romania,"computer science disciplines are very important in the context of an emerging it industry especially in the eastern europe countries where lots of companies invested in research and development sites. the need for highly qualified specialists is very acute and is expressed in several occasions as a request addressed to universities to double the number of bachelor graduates. in this sense universities try to adapt and they provide distance learning programs. in this context all the advantages of software must be used: generative learning objects, gamifications etc. a gamification model for sorting algorithms is proposed in this sense in order to exercise the logic steps of programming and algorithms thus triggering a way of thinking that is needed in the creation of new software. to motivate the student in performing the exercise we used some elements of game mechanics like score and difficulty levels. all the newly created e-learning models are provided to the student through an online web application.",towards a generic gamification of sorting algorithms
1241,2-s2.0-85012096809,10.1109/JSYST.2014.2354835,A Web of Things Framework for RESTful Applications and Its Experimentation in a Smart City,Paganelli F.,IEEE Systems Journal,2016-12-01,"The Web of Things is an active research field which aims at promoting the easy access and handling of smart things' digital representations through the adoption of Web standards and technologies. While huge research and development efforts have been spent on lower level networks and software technologies, it has been recognized that little experience exists instead in modeling and building applications for the Web of Things. Although several works have proposed Representational State Transfer (REST) inspired approaches for the Web of Things, a main limitation is that poor support is provided to web developers for speeding up the development of Web of Things applications while taking full advantage of REST benefits. In this paper, we propose a framework which supports developers in modeling smart things as web resources, exposing them through RESTful Application Programming Interfaces (APIs) and developing applications on top of them. The framework consists of a Web Resource information model, a middleware, and tools for developing and publishing smart things' digital representations on the Web. We discuss the framework compliance with REST guidelines and its major implementation choices. Finally, we report on our test activities carried out within the SmartSantander European Project to evaluate the use and proficiency of our framework in a smart city scenario.",Internet of things (IoT) | representational state transfer (REST) | sensors | smart city | smart things web | web of things | web services,73,1412-1423,Journal,Article,3.0,"Paganelli, Federica;Turchi, Stefano;Giuli, Dino",12799932100;56565165900;7006020332,Università degli Studi di Firenze,Italy,"the web of things is an active research field which aims at promoting the easy access and handling of smart things' digital representations through the adoption of web standards and technologies. while huge research and development efforts have been spent on lower level networks and software technologies, it has been recognized that little experience exists instead in modeling and building applications for the web of things. although several works have proposed representational state transfer (rest) inspired approaches for the web of things, a main limitation is that poor support is provided to web developers for speeding up the development of web of things applications while taking full advantage of rest benefits. in this paper, we propose a framework which supports developers in modeling smart things as web resources, exposing them through restful application programming interfaces (apis) and developing applications on top of them. the framework consists of a web resource information model, a middleware, and tools for developing and publishing smart things' digital representations on the web. we discuss the framework compliance with rest guidelines and its major implementation choices. finally, we report on our test activities carried out within the smartsantander european project to evaluate the use and proficiency of our framework in a smart city scenario.",a web of things framework for restful applications and its experimentation in a smart city
1243,2-s2.0-85006395713,10.11936/bjutxb2016020026,Review of detection for injection vulnerability of Web applications,Wang D.,Beijing Gongye Daxue Xuebao/Journal of Beijing University of Technology,2016-12-01,"To overcome the difficulties of prevention Web applications to be maliciously injected which are increased by all kinds of dynamic Web technologies applied, centered on SQL and XSS injection, the research progresses of Web application injection vulnerabilities detection in recent years were reviewed. Firstly, the classification and causes of the Web application injection security vulnerabilities were summarized; Then, the complexity of security vulnerabilities detection was analyzed; Thirdly, the key technologies of the existing detection approached, including analyzing and identifying the injection points, injection delectations by software analysis and testing, by symbolic execution, by taint analysis and models were elaborated; Finally, its future development direction was presented.",Injection | Vulnerability detection | Web application,3,1822-1832,Journal,Review,3.0,"Wang, Dan;Zhao, Wenbing;Ding, Zhiming",9275444300;8201703800;7401550726,Beijing University of Technology,China,"to overcome the difficulties of prevention web applications to be maliciously injected which are increased by all kinds of dynamic web technologies applied, centered on sql and xss injection, the research progresses of web application injection vulnerabilities detection in recent years were reviewed. firstly, the classification and causes of the web application injection security vulnerabilities were summarized; then, the complexity of security vulnerabilities detection was analyzed; thirdly, the key technologies of the existing detection approached, including analyzing and identifying the injection points, injection delectations by software analysis and testing, by symbolic execution, by taint analysis and models were elaborated; finally, its future development direction was presented.",review of detection for injection vulnerability of web applications
1244,2-s2.0-84975701868,10.1007/s11761-016-0192-7,Opening web applications for third-party development: a service-oriented solution,Kerdoudi M.L.,Service Oriented Computing and Applications,2016-12-01,"Web applications are nowadays prevalent software systems in our everyday’s life. A lot of these applications have been developed for end users only. Thus, they are not designed by considering future extensions that would be developed by third parties. One possible and interesting solution for opening these applications for such kind of extension development is to create and deploy Web services starting from these applications. In this paper, we present a method and a tool for semiautomatically creating Web service implementations from applications having Web interfaces. The proposed method generates operations that are published in Web services for each functionality provided by a Web application. In addition, it generates new operations starting from Web interfaces. Our approach goes further in the creation of services by generating executable orchestrations, as BPEL processes, starting from navigations in the Web interfaces of these applications and by providing BPMN choreography specifications starting from the collaborations between the generated Web services. We implemented and experimented our solution in the migration of three real-world Web applications toward Web service-oriented systems.",Service composition and application migration | SOA | Web application | Web service,7,437-463,Journal,Article,3.0,"Kerdoudi, Mohamed Lamine;Tibermacine, Chouki;Sadou, Salah",36606348000;14051139200;55884971900,"Université Mohamed Khider Biskra;Universite de Bretagne-Sud Campus de Vannes;Laboratoire d'Informatique, de Robotique et de Microélectronique de Montpellie",Algeria;France;France,"web applications are nowadays prevalent software systems in our everyday’s life. a lot of these applications have been developed for end users only. thus, they are not designed by considering future extensions that would be developed by third parties. one possible and interesting solution for opening these applications for such kind of extension development is to create and deploy web services starting from these applications. in this paper, we present a method and a tool for semiautomatically creating web service implementations from applications having web interfaces. the proposed method generates operations that are published in web services for each functionality provided by a web application. in addition, it generates new operations starting from web interfaces. our approach goes further in the creation of services by generating executable orchestrations, as bpel processes, starting from navigations in the web interfaces of these applications and by providing bpmn choreography specifications starting from the collaborations between the generated web services. we implemented and experimented our solution in the migration of three real-world web applications toward web service-oriented systems.",opening web applications for third-party development: a service-oriented solution
1245,2-s2.0-84971654681,10.1016/j.asoc.2016.05.038,Defect prediction for Cascading Style Sheets,Serdar Biçer M.,Applied Soft Computing Journal,2016-12-01,"Testing is a crucial activity in software development. However exhaustive testing of a given software is impossible in practice because projects have serious time and budget limitations. Therefore, software testing teams need guidance about which modules they should focus on. Defect prediction techniques are useful for this situation because they let testers to identify and focus on defect prone parts of software. These techniques are essential for software teams, because they help teams to efficiently allocate their precious resources in testing phase. Software defect prediction has been an active research area in recent years. Researchers in this field have been using different types of metrics in their prediction models. However, value of extracting static code metrics for style sheet languages has been ignored until now. User experience is a very important part of web applications and its mostly provided using Cascading Style Sheets (CSS). In this research, our aim is to improve defect prediction performance for web applications by utilizing metrics generated from CSS code. We generated datasets from four open source web applications to conduct our experiments. Defect prediction is then performed using three different well-known machine learning algorithms. The results revealed that static code metrics based defect prediction techniques can be performed effectively to improve quality of CSS code in web applications. Therefore we recommend utilizing domain-specific characteristics of applications in defect prediction as they result in significantly high prediction performance with low costs.",Defect prediction | Software Metrics | Software quality | Web sites,10,1078-1084,Journal,Article,2.0,"Serdar Biçer, M.;Diri, Banu",57189519688;22978771800,İstanbul Teknik Üniversitesi,Turkey,"testing is a crucial activity in software development. however exhaustive testing of a given software is impossible in practice because projects have serious time and budget limitations. therefore, software testing teams need guidance about which modules they should focus on. defect prediction techniques are useful for this situation because they let testers to identify and focus on defect prone parts of software. these techniques are essential for software teams, because they help teams to efficiently allocate their precious resources in testing phase. software defect prediction has been an active research area in recent years. researchers in this field have been using different types of metrics in their prediction models. however, value of extracting static code metrics for style sheet languages has been ignored until now. user experience is a very important part of web applications and its mostly provided using cascading style sheets (css). in this research, our aim is to improve defect prediction performance for web applications by utilizing metrics generated from css code. we generated datasets from four open source web applications to conduct our experiments. defect prediction is then performed using three different well-known machine learning algorithms. the results revealed that static code metrics based defect prediction techniques can be performed effectively to improve quality of css code in web applications. therefore we recommend utilizing domain-specific characteristics of applications in defect prediction as they result in significantly high prediction performance with low costs.",defect prediction for cascading style sheets
1253,2-s2.0-84997427609,10.1145/2950290.2950357,Python predictive analysis for bug detection,Xu Z.,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,2016-11-01,"Python is a popular dynamic language that allows quick software development. However, Python program analy-sis engines are largely lacking. In this paper, we present a Python predictive analysis. It first collects the trace of an execution, and then encodes the trace and unexecuted branches to symbolic constraints. Symbolic variables are in-troduced to denote input values, their dynamic types, and attribute sets, to reason about their variations. Solving the constraints identifies bugs and their triggering inputs. Our evaluation shows that the technique is highly effective in an-alyzing real-world complex programs with a lot of dynamic features and external library calls, due to its sophisticated encoding design based on traces. It identifies 46 bugs from 11 real-world projects, with 16 new bugs. All reported bugs are true positives.",Debugging | Dynamic Language | Predictive Analysis | Python,12,121-132,Conference Proceeding,Conference Paper,4.0,"Xu, Zhaogui;Liu, Peng;Zhang, Xiangyu;Xu, Baowen",55884412400;57207222012;35489738100;7404589262,Nanjing University;Purdue University,China;United States,"python is a popular dynamic language that allows quick software development. however, python program analy-sis engines are largely lacking. in this paper, we present a python predictive analysis. it first collects the trace of an execution, and then encodes the trace and unexecuted branches to symbolic constraints. symbolic variables are in-troduced to denote input values, their dynamic types, and attribute sets, to reason about their variations. solving the constraints identifies bugs and their triggering inputs. our evaluation shows that the technique is highly effective in an-alyzing real-world complex programs with a lot of dynamic features and external library calls, due to its sophisticated encoding design based on traces. it identifies 46 bugs from 11 real-world projects, with 16 new bugs. all reported bugs are true positives.",python predictive analysis for bug detection
1254,2-s2.0-84997241382,10.1145/2950290.2983943,Refactoring and migration of cascading style sheets: Towards optimization and improved maintainability,Mazinanian D.,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,2016-11-01,"Cascading Style Sheets is the standard styling language, and is extensively used for defining the presentation of web, mobile and desktop applications. Despite its popularity, the language's design shortcomings have made CSS development and maintenance challenging. This thesis aims at developing techniques for safely transforming CSS code (through refactoring, or migration to a preprocessor language), with the goal of optimization and improved maintainability.",Cascading style sheets | Duplication | Migration | Refactoring,1,1057-1059,Conference Proceeding,Conference Paper,1.0,"Mazinanian, Davood",55308236700,Concordia University,Canada,"cascading style sheets is the standard styling language, and is extensively used for defining the presentation of web, mobile and desktop applications. despite its popularity, the language's design shortcomings have made css development and maintenance challenging. this thesis aims at developing techniques for safely transforming css code (through refactoring, or migration to a preprocessor language), with the goal of optimization and improved maintainability.",refactoring and migration of cascading style sheets: towards optimization and improved maintainability
1255,2-s2.0-84994531600,10.1007/s11390-016-1695-6,A Script-Based Prototyping Framework to Boost Agile-UX Developments,Navarro P.L.M.,Journal of Computer Science and Technology,2016-11-01,"Prototypes are described as a successful mechanism to incorporate user-experience design (UX) into Agile developments, but their integration into such developments is not exempt from difficulties. Prototypes and final applications are often developed using different tools, which hinders the collaboration between designers and developers and also complicates reuse. Moreover, integrating stakeholders such as clients and users into the Agile process of designing, evaluating, and refining a prototype is not straightforward mainly because of its iterative nature. In an attempt to tackle these problems, this work presents the design and implementation of a new framework in which scripting languages are used to code prototyped behaviors. Prototyping is then treated as a separate aspect that coexists and runs together with final functionality. Using this framework communication is enhanced because designers and developers work in parallel on the same software artifact. Prototypes are fully reused and iteratively added with final functionality while prototyped behaviors are removed. They can be also modified on the fly to implement participatory design techniques.",Agile development | aspect-oriented development | participatory design | prototype | scripting language,1,1246-1261,Journal,Article,3.0,"Navarro, Pedro Luis Mateo;Pérez, Gregorio Martínez;Ruiz, Diego Sevilla",36521389600;7203067256;56320342800,Universidad de Murcia,Spain,"prototypes are described as a successful mechanism to incorporate user-experience design (ux) into agile developments, but their integration into such developments is not exempt from difficulties. prototypes and final applications are often developed using different tools, which hinders the collaboration between designers and developers and also complicates reuse. moreover, integrating stakeholders such as clients and users into the agile process of designing, evaluating, and refining a prototype is not straightforward mainly because of its iterative nature. in an attempt to tackle these problems, this work presents the design and implementation of a new framework in which scripting languages are used to code prototyped behaviors. prototyping is then treated as a separate aspect that coexists and runs together with final functionality. using this framework communication is enhanced because designers and developers work in parallel on the same software artifact. prototypes are fully reused and iteratively added with final functionality while prototyped behaviors are removed. they can be also modified on the fly to implement participatory design techniques.",a script-based prototyping framework to boost agile-ux developments
1256,2-s2.0-84986199867,10.1080/0144929X.2016.1212095,Designing an MOOC as an agent-platform aggregating heterogeneous virtual learning environments,Wautelet Y.,Behaviour and Information Technology,2016-11-01,"With the emergence of cloud technologies, on the one hand, and social networks, on the other hand, the possibilities for e-learning have been drastically enhanced in the latest years. Virtual Learning Environments (VLE) can now indeed contain a huge amount of learning resources; in parallel, large user communities are available in social networks. These nevertheless remain different systems but, by using these heterogeneous software environments together, the possibilities for interaction could be multiplied. That is why, this paper suggests to build a Massive Open Online Course (MOOC) environment through a Multi-Agent System (MAS) working as a virtual abstraction layer over heterogeneous software platforms. The idea is to aggregate different traditional VLE to dispose of the learning objects they own as well as other platforms such as social networks to furnish an easy access to the MOOC of their large user communities. The MAS design has been architectured around a real-life organisational pattern – the joint venture – allowing one to deal with the complexity of heterogeneous software environments in a manner that real-life companies set up joint governance. Communication scenarios issued of a field analysis are pointed out in the paper; these are supported by the MOOC platform in the native environment as well as in Facebook. The proposal is indeed validated through the development of a prototype using Facebook as a case study for third-party platform interfacing. We finally highlight the benefits for the user experience.",joint venture | Multi-agent systems | organisational patterns | social patterns,17,980-997,Journal,Article,5.0,"Wautelet, Yves;Heng, Samedi;Kolp, Manuel;Penserini, Loris;Poelmans, Stephan",24605650900;55303451500;6602956917;6507883388;6603592997,Louvain School of Management;KU Leuven;Istituto Tecnico Commerciale ‘Cesare Battisti’,Belgium;Belgium;Italy,"with the emergence of cloud technologies, on the one hand, and social networks, on the other hand, the possibilities for e-learning have been drastically enhanced in the latest years. virtual learning environments (vle) can now indeed contain a huge amount of learning resources; in parallel, large user communities are available in social networks. these nevertheless remain different systems but, by using these heterogeneous software environments together, the possibilities for interaction could be multiplied. that is why, this paper suggests to build a massive open online course (mooc) environment through a multi-agent system (mas) working as a virtual abstraction layer over heterogeneous software platforms. the idea is to aggregate different traditional vle to dispose of the learning objects they own as well as other platforms such as social networks to furnish an easy access to the mooc of their large user communities. the mas design has been architectured around a real-life organisational pattern – the joint venture – allowing one to deal with the complexity of heterogeneous software environments in a manner that real-life companies set up joint governance. communication scenarios issued of a field analysis are pointed out in the paper; these are supported by the mooc platform in the native environment as well as in facebook. the proposal is indeed validated through the development of a prototype using facebook as a case study for third-party platform interfacing. we finally highlight the benefits for the user experience.",designing an mooc as an agent-platform aggregating heterogeneous virtual learning environments
1257,2-s2.0-84982311389,10.1016/j.envsoft.2016.08.003,A new open source platform for lowering the barrier for environmental web app development,Swain N.R.,Environmental Modelling and Software,2016-11-01,"The interactive nature of web applications or “web apps” makes them a well-suited medium for conveying complex scientific concepts to lay audiences and creating decision support tools that harness cutting edge modeling techniques and promote the work of environmental scientists and engineers. Despite this potential, the technical expertise required to develop web apps represents a formidable barrier—even for scientists and engineers who are skilled programmers. This paper describes four hurdles that contribute to this barrier and introduces an approach to overcoming these hurdles. We present an open source implementation of this approach, a development and hosting environment for environmental web apps called Tethys Platform. Several case studies are provided that demonstrates how the approach, as implemented within Tethys Platform, successfully lowers the barrier to web app development in the environmental domain.",Decision support | Environmental | Hydrologic modeling | Tethys platform | Web app development,55,11-26,Journal,Article,10.0,"Swain, Nathan R.;Christensen, Scott D.;Snow, Alan D.;Dolder, Herman;Espinoza-Dávalos, Gonzalo;Goharian, Erfan;Jones, Norman L.;Nelson, E. James;Ames, Daniel P.;Burian, Steven J.",55355289700;55926077900;57126854400;56971073100;57189001775;55355679500;55708036200;7402264252;12808778700;6701688830,"The University of Utah;IHE Delft Institute for Water Education;University of California, Davis;U.S. Army Engineer Research and Development Center;Brigham Young University;Aquaveo, LLC",United States;Netherlands;United States;United States;United States;United States,"the interactive nature of web applications or “web apps” makes them a well-suited medium for conveying complex scientific concepts to lay audiences and creating decision support tools that harness cutting edge modeling techniques and promote the work of environmental scientists and engineers. despite this potential, the technical expertise required to develop web apps represents a formidable barrier—even for scientists and engineers who are skilled programmers. this paper describes four hurdles that contribute to this barrier and introduces an approach to overcoming these hurdles. we present an open source implementation of this approach, a development and hosting environment for environmental web apps called tethys platform. several case studies are provided that demonstrates how the approach, as implemented within tethys platform, successfully lowers the barrier to web app development in the environmental domain.",a new open source platform for lowering the barrier for environmental web app development
1258,2-s2.0-84999014727,10.1109/DSD.2016.94,Model-Driven Design Approach for Building Smart Grid Applications,Ebeid E.,"Proceedings - 19th Euromicro Conference on Digital System Design, DSD 2016",2016-10-26,"Software applications are built to run on different devices with dissimilar platforms. The traditional software development process allows to build applications that run on a specific platform in which the development cycle becomes time-consuming and costly due to rebuilding the application for individual platform. To solve this problem, we propose a model-driven methodology for the development of a data visualization application targeting multiple platforms such as desktop computers, tablets and smart phones. The methodology flows from a Platform-Independent Model (PIM) to a Platform-Specific Model (PSM) and ends by executable models for multiple platform. The methodology paves the way to build an automatic synthesis tool that relieves the software developers from the repetitive work. The methodology is validated through a case study that visualizes data from smart grid domain. The case study is built in collaboration with the European research project SmartHG.",(UML) | Data Visualization | Energy Management | Mobile Applications | Model-Driven Design | Smart Grid | Web,4,260-267,Conference Proceeding,Conference Paper,3.0,"Ebeid, Emad;Valov, Martin;Jacobsen, Rune Hylsberg",55247342100;57192154813;7101646653,Aarhus Universitet;EG A/S,Denmark;Denmark,"software applications are built to run on different devices with dissimilar platforms. the traditional software development process allows to build applications that run on a specific platform in which the development cycle becomes time-consuming and costly due to rebuilding the application for individual platform. to solve this problem, we propose a model-driven methodology for the development of a data visualization application targeting multiple platforms such as desktop computers, tablets and smart phones. the methodology flows from a platform-independent model (pim) to a platform-specific model (psm) and ends by executable models for multiple platform. the methodology paves the way to build an automatic synthesis tool that relieves the software developers from the repetitive work. the methodology is validated through a case study that visualizes data from smart grid domain. the case study is built in collaboration with the european research project smarthg.",model-driven design approach for building smart grid applications
1259,2-s2.0-85006789633,10.1145/2997364.2997368,The IDE portability problem and its solution in Monto,Keidel S.,"SLE 2016 - Proceedings of the 2016 ACM SIGPLAN International Conference on Software Language Engineering, co-located with SPLASH 2016",2016-10-20,"Modern Integrated Development Environments (IDEs) support multiple programming languages via plug-ins, but developing a high-quality language plug-in is a huge development effort and individual plug-ins are not reusable in other IDEs. We call this the IDE portability problem. In this paper, we present a solution to the IDE portability problem based on a language-independent and IDEindependent intermediate representation (IR) for editorservice products. This IR enables IDE-independent language services to provide editor services for arbitrary IDEs, using language-independent IDE plug-ins. We combine the IR with a service-oriented architecture to facilitate the modular addition of language services, the decomposition of language services into smaller interdependent services, and the use of arbitrary implementation languages for services. To evaluate the feasibility of our design, we have implemented the IR and architecture in a framework called Monto. We demonstrate the generality of our design by constructing language services for Java, JavaScript, Python, and Haskell and show that they are reusable in the Eclipse IDE and in a web-based IDE. We also evaluate the performance of Monto and show that Monto is responsive and has admissible performance overhead.",Integrated development environments | Reusable software,8,152-162,Conference Proceeding,Conference Paper,3.0,"Keidel, Sven;Pfeiffer, Wulf;Erdweg, Sebastian",57192552646;57192540728;37040387700,Delft University of Technology,Netherlands,"modern integrated development environments (ides) support multiple programming languages via plug-ins, but developing a high-quality language plug-in is a huge development effort and individual plug-ins are not reusable in other ides. we call this the ide portability problem. in this paper, we present a solution to the ide portability problem based on a language-independent and ideindependent intermediate representation (ir) for editorservice products. this ir enables ide-independent language services to provide editor services for arbitrary ides, using language-independent ide plug-ins. we combine the ir with a service-oriented architecture to facilitate the modular addition of language services, the decomposition of language services into smaller interdependent services, and the use of arbitrary implementation languages for services. to evaluate the feasibility of our design, we have implemented the ir and architecture in a framework called monto. we demonstrate the generality of our design by constructing language services for java, javascript, python, and haskell and show that they are reusable in the eclipse ide and in a web-based ide. we also evaluate the performance of monto and show that monto is responsive and has admissible performance overhead.",the ide portability problem and its solution in monto
1260,2-s2.0-85084555674,10.1145/2983990.2984037,First-class effect reflection for effect-guided programming,Long Y.,ACM SIGPLAN Notices,2016-10-19,"This paper introduces a novel type-and-effect calculus, first-class effects, where the computational effect of an expression can be programmatically reflected, passed around as values, and analyzed at run time. A broad range of designs ""hard-coded"" in existing effect-guided analyses - from thread scheduling, version-consistent software updating, to data zeroing - can be naturally supported through the programming abstractions. The core technical development is a type system with a number of features, including a hybrid type system that integrates static and dynamic effect analyses, a refinement type system to verify application-specific effect management properties, a double-bounded type system that computes both over-approximation of effects and their under-approximation. We introduce and establish a notion of soundness called trace consistency, defined in terms of how the effect and trace correspond. The property sheds foundational insight on ""good"" first-class effect programming.",first-class effect | hybrid typing | type system,0,820-837,Journal,Article,3.0,"Long, Yuheng;Liu, Yu David;Rajan, Hridesh",36675098800;55742108900;8288073800,Binghamton University State University of New York;Iowa State University,United States;United States,"this paper introduces a novel type-and-effect calculus, first-class effects, where the computational effect of an expression can be programmatically reflected, passed around as values, and analyzed at run time. a broad range of designs ""hard-coded"" in existing effect-guided analyses - from thread scheduling, version-consistent software updating, to data zeroing - can be naturally supported through the programming abstractions. the core technical development is a type system with a number of features, including a hybrid type system that integrates static and dynamic effect analyses, a refinement type system to verify application-specific effect management properties, a double-bounded type system that computes both over-approximation of effects and their under-approximation. we introduce and establish a notion of soundness called trace consistency, defined in terms of how the effect and trace correspond. the property sheds foundational insight on ""good"" first-class effect programming.",first-class effect reflection for effect-guided programming
1261,2-s2.0-84995704356,10.1145/2983990.2984037,First-class effect reflection for effect-guided programming,Long Y.,"Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA",2016-10-19,"This paper introduces a novel type-and-effect calculus, firstclass effects, where the computational effect of an expression can be programmatically reflected, passed around as values, and analyzed at run time. A broad range of designs ""hardcoded"" in existing effect-guided analyses - from thread scheduling, version-consistent software updating, to data zeroing - can be naturally supported through the programming abstractions. The core technical development is a type system with a number of features, including a hybrid type system that integrates static and dynamic effect analyses, a refinement type system to verify application-specific effect management properties, a double-bounded type system that computes both over-approximation of effects and their under-approximation.We introduce and establish a notion of soundness called trace consistency, defined in terms of how the effect and trace correspond. The property sheds foundational insight on ""good"" first-class effect programming.",First-class effect | Hybrid typing | Type system,1,820-837,Conference Proceeding,Conference Paper,3.0,"Long, Yuheng;Liu, Yu David;Rajan, Hridesh",36675098800;55742108900;8288073800,Binghamton University State University of New York;Iowa State University,United States;United States,"this paper introduces a novel type-and-effect calculus, firstclass effects, where the computational effect of an expression can be programmatically reflected, passed around as values, and analyzed at run time. a broad range of designs ""hardcoded"" in existing effect-guided analyses - from thread scheduling, version-consistent software updating, to data zeroing - can be naturally supported through the programming abstractions. the core technical development is a type system with a number of features, including a hybrid type system that integrates static and dynamic effect analyses, a refinement type system to verify application-specific effect management properties, a double-bounded type system that computes both over-approximation of effects and their under-approximation.we introduce and establish a notion of soundness called trace consistency, defined in terms of how the effect and trace correspond. the property sheds foundational insight on ""good"" first-class effect programming.",first-class effect reflection for effect-guided programming
1262,2-s2.0-84995475172,10.1109/QRS.2016.42,MedicationChecker: Development of a Formally Verified Android Application with EventB2SQL,Wahls T.,"Proceedings - 2016 IEEE International Conference on Software Quality, Reliability and Security, QRS 2016",2016-10-12,"In this work, we present a case study on the development of a formally verified Android application for checking medication interactions and contraindications. Combining formal methods and Model-View-Controller development methodologies, we created an Event-B model for the application, verified that no patient could be prescribed a medication that had an interaction or contraindication for them, generated code for the model and part of the user interface with the EventB2SQL tool, and then implemented the controller and the rest of the view by hand. We describe our experience in employing this methodology, enhancements to the EventB2SQL tool, and some notes on the performance and usability of the resulting application.",code generation | database applications | Event-B | EventB2SQL | mobile application development,0,307-314,Conference Proceeding,Conference Paper,1.0,"Wahls, Tim",57203404606,Dickinson College,United States,"in this work, we present a case study on the development of a formally verified android application for checking medication interactions and contraindications. combining formal methods and model-view-controller development methodologies, we created an event-b model for the application, verified that no patient could be prescribed a medication that had an interaction or contraindication for them, generated code for the model and part of the user interface with the eventb2sql tool, and then implemented the controller and the rest of the view by hand. we describe our experience in employing this methodology, enhancements to the eventb2sql tool, and some notes on the performance and usability of the resulting application.",medicationchecker: development of a formally verified android application with eventb2sql
1266,2-s2.0-85042380733,10.5194/isprs-archives-XLII-2-W2-33-2016,Touch interaction with 3D geographical visualization on web: Selected technological and user issues,Herman L.,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",2016-10-05,"The use of both 3D visualization and devices with touch displays is increasing. In this paper, we focused on the Web technologies for 3D visualization of spatial data and its interaction via touch screen gestures. At the first stage, we compared the support of touch interaction in selected JavaScript libraries on different hardware (desktop PCs with touch screens, tablets, and smartphones) and software platforms. Afterward, we realized simple empiric test (within-subject design, 6 participants, 2 simple tasks, LCD touch monitor Acer and digital terrain models as stimuli) focusing on the ability of users to solve simple spatial tasks via touch screens. An in-house testing web tool was developed and used based on JavaScript, PHP, and X3DOM languages and Hammer.js libraries. The correctness of answers, speed of users’ performances, used gestures, and a simple gesture metric was recorded and analysed. Preliminary results revealed that the pan gesture is most frequently used by test participants and it is also supported by the majority of 3D libraries. Possible gesture metrics and future developments including the interpersonal differences are discussed in the conclusion.",3D visualization | Human computer interaction | Interaction | Touch screen | User issues,5,33-40,Conference Proceeding,Conference Paper,5.0,"Herman, L.;Stachoň, Z.;Stuchlík, R.;Hladík, J.;Kubíček, P.",55864650200;39561414200;57188750810;6701494575;36890004300,Masaryk University,Czech Republic,"the use of both 3d visualization and devices with touch displays is increasing. in this paper, we focused on the web technologies for 3d visualization of spatial data and its interaction via touch screen gestures. at the first stage, we compared the support of touch interaction in selected javascript libraries on different hardware (desktop pcs with touch screens, tablets, and smartphones) and software platforms. afterward, we realized simple empiric test (within-subject design, 6 participants, 2 simple tasks, lcd touch monitor acer and digital terrain models as stimuli) focusing on the ability of users to solve simple spatial tasks via touch screens. an in-house testing web tool was developed and used based on javascript, php, and x3dom languages and hammer.js libraries. the correctness of answers, speed of users’ performances, used gestures, and a simple gesture metric was recorded and analysed. preliminary results revealed that the pan gesture is most frequently used by test participants and it is also supported by the majority of 3d libraries. possible gesture metrics and future developments including the interpersonal differences are discussed in the conclusion.",touch interaction with 3d geographical visualization on web: selected technological and user issues
1267,2-s2.0-84994792149,10.1109/IISWC.2016.7581269,Workload characterization for microservices,Ueda T.,"Proceedings of the 2016 IEEE International Symposium on Workload Characterization, IISWC 2016",2016-10-03,"The microservice architecture is a new framework to construct a Web service as a collection of small services that communicate with each other. It is becoming increasingly popular because it can accelerate agile software development, deployment, and operation practices. As a result, cloud service providers are expected to host an increasing number of microservices that can generate significant resource pressure on the cloud infrastructure. We want to understand the characteristics of microservice workloads to design an infrastructure optimized for microservices. In this paper, we used Acme Air, an open-source benchmark for Web services, and analyzed the behavior of two versions of the benchmark, microservice and monolithic, for two widely used language runtimes, Node.js and Java. We observed a significant overhead due to the microservice architecture; the performance of the microservice version can be 79.2% lower than the monolithic version on the same hardware configuration. On Node.js, the microservice version consumed 4.22 times more time in the libraries of Node.js than the monolithic version to process one user request. On Java, the microservice version also consumed more time in the application server than the monolithic version. We explain these performance differences from both hardware and software perspectives. We discuss the network virtualization in Docker, an infrastructure for microservices that has nonnegligible impact on performance. These findings give clues to develop optimization techniques in a language runtime and hardware for microservice workloads.",Container | Docker | Java | Microservice architecture | Microservices | Node.js | WebSphere Liberty,71,85-94,Conference Proceeding,Conference Paper,3.0,"Ueda, Takanori;Nakaike, Takuya;Ohara, Moriyoshi",57191912364;55930516800;7101949052,"IBM Japan, Ltd.",Japan,"the microservice architecture is a new framework to construct a web service as a collection of small services that communicate with each other. it is becoming increasingly popular because it can accelerate agile software development, deployment, and operation practices. as a result, cloud service providers are expected to host an increasing number of microservices that can generate significant resource pressure on the cloud infrastructure. we want to understand the characteristics of microservice workloads to design an infrastructure optimized for microservices. in this paper, we used acme air, an open-source benchmark for web services, and analyzed the behavior of two versions of the benchmark, microservice and monolithic, for two widely used language runtimes, node.js and java. we observed a significant overhead due to the microservice architecture; the performance of the microservice version can be 79.2% lower than the monolithic version on the same hardware configuration. on node.js, the microservice version consumed 4.22 times more time in the libraries of node.js than the monolithic version to process one user request. on java, the microservice version also consumed more time in the application server than the monolithic version. we explain these performance differences from both hardware and software perspectives. we discuss the network virtualization in docker, an infrastructure for microservices that has nonnegligible impact on performance. these findings give clues to develop optimization techniques in a language runtime and hardware for microservice workloads.",workload characterization for microservices
1269,2-s2.0-84994651120,10.1145/2964284.2973798,Kurento: The WebRTC modular media server,López L.,MM 2016 - Proceedings of the 2016 ACM Multimedia Conference,2016-10-01,"In this paper we introduce Kurento Media Server: an open source WebRTC Media Server providing a toolbox of capabilities which include group communications, recording, routing, transcoding and mixing. Kurento supports a large number of media protocols such as WebRTC, plain RTP, RTSP or HTTP and bunch of codecs including VP8, VP9, H.264, H.263, OPUS, Speex, PCM or AMR. Kurento Media Server is based on a modular architecture, which makes it possible for developers to extend and customize its native capabilities with advanced media processing features such as computer vision, augmented reality or speech analysis. Kurento is ideal for WWW developers who find natural programming with its Java and JavaScript APIs following the traditional three tiered WWW development model.",Augmented reality | Computer vision | Media server | Modularity | Real-time multimedia | Recording | WebRTC,7,1187-1191,Conference Proceeding,Conference Paper,12.0,"López, Luis;García, Boni;Benítez, Raul;Vlad, Radu Tom;París, Miguel;Gallego, Micael;Santos, Jose A.;Gracia, Iván;Carot, Santiago;Gortázar, Francisco;Fernández, David;Lopez, Francisco Javier",7201949992;24724315500;55597725200;57191898245;57191894302;57202908535;57059735400;57191902499;57191905337;24179404100;57191900696;57193715353,Universidad Rey Juan Carlos,Spain,"in this paper we introduce kurento media server: an open source webrtc media server providing a toolbox of capabilities which include group communications, recording, routing, transcoding and mixing. kurento supports a large number of media protocols such as webrtc, plain rtp, rtsp or http and bunch of codecs including vp8, vp9, h.264, h.263, opus, speex, pcm or amr. kurento media server is based on a modular architecture, which makes it possible for developers to extend and customize its native capabilities with advanced media processing features such as computer vision, augmented reality or speech analysis. kurento is ideal for www developers who find natural programming with its java and javascript apis following the traditional three tiered www development model.",kurento: the webrtc modular media server
1271,2-s2.0-84987788989,10.1109/JIOT.2015.2505901,Operating Systems for Low-End Devices in the Internet of Things: A Survey,Hahm O.,IEEE Internet of Things Journal,2016-10-01,"The Internet of Things (IoT) is projected to soon interconnect tens of billions of new devices, in large part also connected to the Internet. IoT devices include both high-end devices which can use traditional go-to operating systems (OSs) such as Linux, and low-end devices which cannot, due to stringent resource constraints, e.g., very limited memory, computational power, and power supply. However, large-scale IoT software development, deployment, and maintenance requires an appropriate OS to build upon. In this paper, we thus analyze in detail the specific requirements that an OS should satisfy to run on low-end IoT devices, and we survey applicable OSs, focusing on candidates that could become an equivalent of Linux for such devices, i.e., a one-size-fits-most, open source OS for low-end IoT devices.",Embedded software | Internet of Things (IoT) | low-power electronics | operating system (OS),183,720-734,Journal,Article,4.0,"Hahm, Oliver;Baccelli, Emmanuel;Petersen, Hauke;Tsiftes, Nicolas",54791015000;7801392399;56288228400;23135842600,"INRIA Saclay;RISE, Swedish Institute of Computer Science;Freie Universität Berlin",France;Sweden;Germany,"the internet of things (iot) is projected to soon interconnect tens of billions of new devices, in large part also connected to the internet. iot devices include both high-end devices which can use traditional go-to operating systems (oss) such as linux, and low-end devices which cannot, due to stringent resource constraints, e.g., very limited memory, computational power, and power supply. however, large-scale iot software development, deployment, and maintenance requires an appropriate os to build upon. in this paper, we thus analyze in detail the specific requirements that an os should satisfy to run on low-end iot devices, and we survey applicable oss, focusing on candidates that could become an equivalent of linux for such devices, i.e., a one-size-fits-most, open source os for low-end iot devices.",operating systems for low-end devices in the internet of things: a survey
1272,2-s2.0-85050599303,10.1145/2978192.2978247,MEAN web development: A tutorial for educators,German A.,SIGITE 2016 - Proceedings of the 17th Annual Conference on Information Technology Education,2016-09-28,"Netscape first provided a grand unification of sorts by offering a single, uniform interface to resources spread across the globe. Simple HTML interfaces to CGI (and later PHP) scripts provided the second grand unification-as suddenly software developers did not need to worry about client software distribution any more. Both Java and Javascript attempted (in their own ways) to enhance the degree of sophistication of the end-user experience. Protocols and technologies came and went (xml-rpc, SOAP, Java RMI, OpenLaszlo, etc.) while the typical web development solution slowly converged towards a (now traditional) LAMP stack architecture. As web development projects became more demanding, frameworks like Spring and Rails (for Ruby) demonstrated the viability of the MVC pattern and helped spawn replicas (CakePHP, Django, Grails, etc.) into other communities. Today it's fair to say that the move towards the MVC architectures was just another (spontaneous, unplanned) attempt to unify development over the web. Simplicity often tends to be a great focal point of evolution. In the last 5-6 years another type of unification became possible due to the surprising resurgence of a most unlikely candidate: Javascript. First Javascript was the glue that made possible the ideas behind HTML5 (as an entirely new set of APIs, and not just a new set of tags). Then in 2009 with the first release of Node.js (relying on Google's Javascript V8 engine) the creation of web servers and networking tools using JavaScript became not just possible, but also extremely efficient. These days, using MongoDB as the document database, Node.js as the server platform (with Express as a flexible and robust server-side web application framework) along with AngularJS (by Google) for the GUIs on the client side, developers are finally capable of creating more agile software by using a single language across all layers of application development. This has the potential to drastically change how we teach web programming. Bring your own laptop and join us for a workshop as we explore in tutorial fashion all major aspects, stages and components of web development with the MEAN stack.",Big data | Full stack web development | Impedance mismatch | Javascript end to end | MVC frameworks and architectures | NoSQL databases | Polyglot persistence | Single page web applications,4,128-129,Conference Proceeding,Conference Paper,4.0,"German, Adrian;Salmeron, Santiago;Ha, Wonyong;Henderson, Bo",55393255700;57203766221;57414647000;57203767554,Indiana University School of Informatics and Computing,United States,"netscape first provided a grand unification of sorts by offering a single, uniform interface to resources spread across the globe. simple html interfaces to cgi (and later php) scripts provided the second grand unification-as suddenly software developers did not need to worry about client software distribution any more. both java and javascript attempted (in their own ways) to enhance the degree of sophistication of the end-user experience. protocols and technologies came and went (xml-rpc, soap, java rmi, openlaszlo, etc.) while the typical web development solution slowly converged towards a (now traditional) lamp stack architecture. as web development projects became more demanding, frameworks like spring and rails (for ruby) demonstrated the viability of the mvc pattern and helped spawn replicas (cakephp, django, grails, etc.) into other communities. today it's fair to say that the move towards the mvc architectures was just another (spontaneous, unplanned) attempt to unify development over the web. simplicity often tends to be a great focal point of evolution. in the last 5-6 years another type of unification became possible due to the surprising resurgence of a most unlikely candidate: javascript. first javascript was the glue that made possible the ideas behind html5 (as an entirely new set of apis, and not just a new set of tags). then in 2009 with the first release of node.js (relying on google's javascript v8 engine) the creation of web servers and networking tools using javascript became not just possible, but also extremely efficient. these days, using mongodb as the document database, node.js as the server platform (with express as a flexible and robust server-side web application framework) along with angularjs (by google) for the guis on the client side, developers are finally capable of creating more agile software by using a single language across all layers of application development. this has the potential to drastically change how we teach web programming. bring your own laptop and join us for a workshop as we explore in tutorial fashion all major aspects, stages and components of web development with the mean stack.",mean web development: a tutorial for educators
1273,2-s2.0-84971223315,10.1016/j.energy.2016.05.027,"Development of a user-friendly, low-cost home energy monitoring and recording system",Fletcher J.,Energy,2016-09-15,"This paper reports research undertaken to develop a user-friendly home energy monitoring system which is capable of collecting, processing and displaying detailed usage data. The system allows users to monitor power usage and switch their electronic appliances remotely, using any web enabled device, including computers, phones and tablets. The system aims to raise awareness of consumer energy use by gathering data about usage habits, and displaying this information to support consumers when selecting energy tariffs or new appliances.To achieve these aims, bespoke electrical hardware, or 'nodes', have been designed and built to monitor power usage, switch devices on and off, and communicate via a Wi-Fi connection, with bespoke software, the 'server'. The server hosts a webpage which allows users to see a real-time overview of how power is being used in the home as well as allowing scheduled tasks and triggered tasks (which respond to events) to be programmed. The system takes advantage of well standardised networking specifications, such as Wi-Fi and TCP, allowing access from within the home, or remotely through the internet. The server runs under Debian Linux on a Raspberry Pi computer and is written in Python, HTML and JavaScript. The server includes advanced functionality, such as device recognition which allows users to individually monitor several devices that share a single node. The openPicus Flyport is used to provide Wi-Fi connectivity and programmable logic control to nodes. The Flyport is programmed with code compiled from C.",Domestic energy | Energy | Energy monitoring | Smart meters,14,32-46,Journal,Article,2.0,"Fletcher, James;Malalasekera, Weeratunge",56231962400;7004056517,Loughborough University,United Kingdom,"this paper reports research undertaken to develop a user-friendly home energy monitoring system which is capable of collecting, processing and displaying detailed usage data. the system allows users to monitor power usage and switch their electronic appliances remotely, using any web enabled device, including computers, phones and tablets. the system aims to raise awareness of consumer energy use by gathering data about usage habits, and displaying this information to support consumers when selecting energy tariffs or new appliances.to achieve these aims, bespoke electrical hardware, or 'nodes', have been designed and built to monitor power usage, switch devices on and off, and communicate via a wi-fi connection, with bespoke software, the 'server'. the server hosts a webpage which allows users to see a real-time overview of how power is being used in the home as well as allowing scheduled tasks and triggered tasks (which respond to events) to be programmed. the system takes advantage of well standardised networking specifications, such as wi-fi and tcp, allowing access from within the home, or remotely through the internet. the server runs under debian linux on a raspberry pi computer and is written in python, html and javascript. the server includes advanced functionality, such as device recognition which allows users to individually monitor several devices that share a single node. the openpicus flyport is used to provide wi-fi connectivity and programmable logic control to nodes. the flyport is programmed with code compiled from c.","development of a user-friendly, low-cost home energy monitoring and recording system"
1275,2-s2.0-85007425261,10.1109/TLA.2016.7785952,Scorecard System for the Manufacturing Sector Leather and Saddlery in Venezuela,Lopez I.J.,IEEE Latin America Transactions,2016-09-01,"The study deals with the design of an information system for companies' manufacturers' saddlery and harness in Venezuela, which allows offering its users the possibility of developing an effective and efficient performance. To achieve in this paper types Generic Strategies (Porter) is analyzed and the theoretical foundations of the Balanced Scorecard (Kaplan and Norton) also runs as strategic management model that seeks to verify the alignment of the organizational functions with the strategy through structural indicators proposed by this model. The product of this study is the System Scorecard (SICMAIN), software that allows through the use of indicators to measure the management strategy of the organization. The software is a web-based system was conceived and developed under the philosophy of Balanced Scorecard of Kaplan and Norton Doctors, specially designed for manufacturing companies in the industrial sector in Venezuela saddlery and harness. It is a modular system consisting of 4 sections which are included; the registration data of the company, a loading and maintenance of indicators to be monitored, one for the analysis of balanced scorecard and for graphical analysis. The development is based entirely on free programming language (free software) such as: PHP, HTML, JavaScript and JQuery latter integrated together with other components. Under Apache server and MySQL database.",Alignment | Balanced Scorecard (BSC) | Competitive Advantage and Automated System (SICMAIN) | Generic Strategies | Information Technology,0,4196-4201,Journal,Article,3.0,"Lopez, Ivan Jose;Tous, Dolores;Bermudez, Guillermo",57192694926;56455330000;55588840100,Universidad Nacional Experimental del Táchira;Universidad de Málaga,Venezuela;Spain,"the study deals with the design of an information system for companies' manufacturers' saddlery and harness in venezuela, which allows offering its users the possibility of developing an effective and efficient performance. to achieve in this paper types generic strategies (porter) is analyzed and the theoretical foundations of the balanced scorecard (kaplan and norton) also runs as strategic management model that seeks to verify the alignment of the organizational functions with the strategy through structural indicators proposed by this model. the product of this study is the system scorecard (sicmain), software that allows through the use of indicators to measure the management strategy of the organization. the software is a web-based system was conceived and developed under the philosophy of balanced scorecard of kaplan and norton doctors, specially designed for manufacturing companies in the industrial sector in venezuela saddlery and harness. it is a modular system consisting of 4 sections which are included; the registration data of the company, a loading and maintenance of indicators to be monitored, one for the analysis of balanced scorecard and for graphical analysis. the development is based entirely on free programming language (free software) such as: php, html, javascript and jquery latter integrated together with other components. under apache server and mysql database.",scorecard system for the manufacturing sector leather and saddlery in venezuela
1276,2-s2.0-84987678779,10.1016/j.jmgm.2016.07.008,Open source molecular modeling,Pirhadi S.,Journal of Molecular Graphics and Modelling,2016-09-01,"The success of molecular modeling and computational chemistry efforts are, by definition, dependent on quality software applications. Open source software development provides many advantages to users of modeling applications, not the least of which is that the software is free and completely extendable. In this review we categorize, enumerate, and describe available open source software packages for molecular modeling and computational chemistry. An updated online version of this catalog can be found at https://opensourcemolecularmodeling.github.io.",Cheminformatics | Molecular modeling | Open source | Software,64,127-143,Journal,Article,3.0,"Pirhadi, Somayeh;Sunseri, Jocelyn;Koes, David Ryan",36451241700;6506162431;6504625843,"Islamic Azad University, Science and Research Branch;University of Pittsburgh",Iran;United States,"the success of molecular modeling and computational chemistry efforts are, by definition, dependent on quality software applications. open source software development provides many advantages to users of modeling applications, not the least of which is that the software is free and completely extendable. in this review we categorize, enumerate, and describe available open source software packages for molecular modeling and computational chemistry. an updated online version of this catalog can be found at https://opensourcemolecularmodeling.github.io.",open source molecular modeling
1278,2-s2.0-84989211600,10.1145/2970276.2970279,An end-user oriented tool suite for development of mobile applications,Zhai Z.,ASE 2016 - Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering,2016-08-25,"In this paper, we show an end-user oriented tool suite for mobile application development. The advantages of this tool suite are that the graphical user interface (GUI), as well as the application logic can both be developed in a rapid and simple way, and web-based services on the Internet can be integrated into our platform by end-users. This tool suite involves three sub-systems, namely ServiceAccess, EasyApp and LSCE. ServiceAccess takes charge of the registration and management of heterogeneous services, and can export different form of services according to the requirements of the other sub-systems. EasyApp is responsible for developing GUI in the form of mobile app. LSCE takes charge of creating the application logic that can be invoked by mobile app directly. Finally, a development case is presented to illustrate the development process using this tool suite.",Cross-platform | End-user development | Mobile application | Visual development environment,1,768-773,Conference Proceeding,Conference Paper,6.0,"Zhai, Zhongyi;Cheng, Bo;Niu, Meng;Wang, Zhaoning;Feng, Yimeng;Chen, Junliang",57191095826;35239463100;57191364618;57191095558;57191091923;7501878050,Beijing University of Posts and Telecommunications,China,"in this paper, we show an end-user oriented tool suite for mobile application development. the advantages of this tool suite are that the graphical user interface (gui), as well as the application logic can both be developed in a rapid and simple way, and web-based services on the internet can be integrated into our platform by end-users. this tool suite involves three sub-systems, namely serviceaccess, easyapp and lsce. serviceaccess takes charge of the registration and management of heterogeneous services, and can export different form of services according to the requirements of the other sub-systems. easyapp is responsible for developing gui in the form of mobile app. lsce takes charge of creating the application logic that can be invoked by mobile app directly. finally, a development case is presented to illustrate the development process using this tool suite.",an end-user oriented tool suite for development of mobile applications
1282,2-s2.0-84992223575,10.1109/ICSTW.2016.17,An Experimental Evaluation of Web Mutation Operators,Praphamontripong U.,"Proceedings - 2016 IEEE International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2016",2016-08-01,"While modern web development technologies enhancethe capabilities of web applications, they introduce challengesfor testers. This paper introduces, evaluates, and refinesweb mutation operators that target interaction faults in web applications. An experimental study is conducted on 11 subject webapplications using 15 web mutation operators. The effectivenessof 12 independently developed test sets are analyzed in terms ofhow well they kill web mutants. Web mutation adequate tests arecompared with independently created test sets to evaluate the webmutation operators. Tests designed to satisfy the web mutationtesting criterion provide 100% coverage while the tests designedto satisfy traditional testing criteria provide, on average, 47%coverage. The paper also analyzes which mutants and mutationoperators the traditional tests had difficulty killing. We foundthat some types of mutants that are not particularly hard to killwere missed by all traditional tests. Additionally, web mutationtesting produces very few equivalent mutants.",control connection | interaction faults | mutation analysis | operational transitions | software testing | state management | web applications | Web mutation testing,13,102-111,Conference Proceeding,Conference Paper,4.0,"Praphamontripong, Upsorn;Offutt, Jeff;Deng, Lin;Gu, Jing Jing",8304995800;55375749200;55142608500;57191627139,George Mason University,United States,"while modern web development technologies enhancethe capabilities of web applications, they introduce challengesfor testers. this paper introduces, evaluates, and refinesweb mutation operators that target interaction faults in web applications. an experimental study is conducted on 11 subject webapplications using 15 web mutation operators. the effectivenessof 12 independently developed test sets are analyzed in terms ofhow well they kill web mutants. web mutation adequate tests arecompared with independently created test sets to evaluate the webmutation operators. tests designed to satisfy the web mutationtesting criterion provide 100% coverage while the tests designedto satisfy traditional testing criteria provide, on average, 47%coverage. the paper also analyzes which mutants and mutationoperators the traditional tests had difficulty killing. we foundthat some types of mutants that are not particularly hard to killwere missed by all traditional tests. additionally, web mutationtesting produces very few equivalent mutants.",an experimental evaluation of web mutation operators
1289,2-s2.0-84979732861,10.1145/2899415.2899435,Reading hierarchies in code: Assessment of a basic computational skill,Park T.,"Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE",2016-07-11,"One of the skills that comprise computational thinking is the ability to read code and reason about the hierarchical relationships between different blocks, expressions, elements, or other types of nodes, depending on the language. In this study, we present three new instruments for assessing different aspects of reading hierarchies in code, including vocabulary, reasoning, and fluency. One of these instruments is Nester, an interactive tool we have designed to elicit mental models about the hierarchical structure of code in computing languages ranging from HTML, CSS, and LaTeX to JavaScript and Lisp. We describe a lab study in which we administered these instruments to 24 participants with varying degrees of web development experience. We report findings from this study, including participants' ability to define, reason about, and manipulate hierarchies in code, and the errors and misconceptions that relate to them. Finally, we discuss avenues for future work.",Assessment | Computational thinking | Program comprehension | Web development,4,302-307,Conference Proceeding,Conference Paper,5.0,"Park, Thomas H.;Kim, Meen Chul;Chhabra, Sukrit;Lee, Brian;Forte, Andrea",35273007300;56227555000;57189387209;57189389355;8897973100,Drexel University,United States,"one of the skills that comprise computational thinking is the ability to read code and reason about the hierarchical relationships between different blocks, expressions, elements, or other types of nodes, depending on the language. in this study, we present three new instruments for assessing different aspects of reading hierarchies in code, including vocabulary, reasoning, and fluency. one of these instruments is nester, an interactive tool we have designed to elicit mental models about the hierarchical structure of code in computing languages ranging from html, css, and latex to javascript and lisp. we describe a lab study in which we administered these instruments to 24 participants with varying degrees of web development experience. we report findings from this study, including participants' ability to define, reason about, and manipulate hierarchies in code, and the errors and misconceptions that relate to them. finally, we discuss avenues for future work.",reading hierarchies in code: assessment of a basic computational skill
1290,2-s2.0-85015368635,10.1145/3024906.3024913,Understanding the benefits of game jams: Exploring the potential for engaging young learners in STEM,Fowler A.,"Proceedings of the 2016 ITiCSE Working Group Reports, ITiCSE 2016",2016-07-09,"There is a wide range of implementations of game jams throughout the world . Game jams have been organized in a number of di?erent formats, themes, and timeframes [43]. What they all have in common is the opportunity for participants to make a game within a specified constraint such as time, location, technology, or theme. Additionally, game jams as social experience support active and collaborative learning formats. In this paper, we discuss the potential of game jams for young learners, describe successful jam events in this context, and provide a list of tools useful for organizing game jams for this target group. CCS Concepts •Social and professional topics →Computer science education;.",Game design | Game development | Game jams | Programming,22,119-135,Conference Proceeding,Conference Paper,6.0,"Fowler, Allan;Pirker, Johanna;Pollock, Ian;De Paula, Bruno Campagnola;Echeveste, Maria Emilia;Gómez, Marcos J.",55143688000;54395927900;57193651151;57193650571;57190407476;57022865500,"California State University, East Bay;Pontifícia Universidade Católica do Paraná;Kennesaw State University;Technische Universitat Graz;Universidad Nacional de Córdoba",United States;Brazil;United States;Austria;Argentina,"there is a wide range of implementations of game jams throughout the world . game jams have been organized in a number of di?erent formats, themes, and timeframes [43]. what they all have in common is the opportunity for participants to make a game within a specified constraint such as time, location, technology, or theme. additionally, game jams as social experience support active and collaborative learning formats. in this paper, we discuss the potential of game jams for young learners, describe successful jam events in this context, and provide a list of tools useful for organizing game jams for this target group. ccs concepts •social and professional topics →computer science education;.",understanding the benefits of game jams: exploring the potential for engaging young learners in stem
1294,2-s2.0-84982824763,10.4230/LIPIcs.ECOOP.2016.14,One way to select many,Järvi J.,"Leibniz International Proceedings in Informatics, LIPIcs",2016-07-01,"Selecting items from a collection is one of the most common tasks users perform with graphical user interfaces. Practically every application supports this task with a selection feature different from that of any other application. Defects are common, especially in manipulating selections of non-adjacent elements, and flexible selection features are often missing when they would clearly be useful. As a consequence, user effort is wasted. The loss of productivity is experienced in small doses, but all computer users are impacted. The undesirable state of support for multi-element selection prevails because the same selection features are redesigned and reimplemented repeatedly This article seeks to establish common abstractions for multi-selection. It gives generic but precise meanings to selection operations and makes multi-selection reusable; a JavaScript implementation is described. Application vendors benefit because of reduced development effort. Users benefit because correct and consistent multi-selection becomes available in more contexts.",JavaScript | Multi-selection | User interfaces,0,141-1426,Conference Proceeding,Conference Paper,2.0,"Järvi, Jaakko;Parent, Sean",8651869200;25655257500,Adobe Inc.;Texas A&amp;M University,United States;United States,"selecting items from a collection is one of the most common tasks users perform with graphical user interfaces. practically every application supports this task with a selection feature different from that of any other application. defects are common, especially in manipulating selections of non-adjacent elements, and flexible selection features are often missing when they would clearly be useful. as a consequence, user effort is wasted. the loss of productivity is experienced in small doses, but all computer users are impacted. the undesirable state of support for multi-element selection prevails because the same selection features are redesigned and reimplemented repeatedly this article seeks to establish common abstractions for multi-selection. it gives generic but precise meanings to selection operations and makes multi-selection reusable; a javascript implementation is described. application vendors benefit because of reduced development effort. users benefit because correct and consistent multi-selection becomes available in more contexts.",one way to select many
1296,2-s2.0-84973293715,10.1016/j.scr.2016.05.012,Large-scale time-lapse microscopy of Oct4 expression in human embryonic stem cell colonies,Bhadriraju K.,Stem Cell Research,2016-07-01,"Identification and quantification of the characteristics of stem cell preparations is critical for understanding stem cell biology and for the development and manufacturing of stem cell based therapies. We have developed image analysis and visualization software that allows effective use of time-lapse microscopy to provide spatial and dynamic information from large numbers of human embryonic stem cell colonies. To achieve statistically relevant sampling, we examined > 680 colonies from 3 different preparations of cells over 5 days each, generating a total experimental dataset of 0.9 terabyte (TB). The 0.5 Giga-pixel images at each time point were represented by multi-resolution pyramids and visualized using the Deep Zoom Javascript library extended to support viewing Giga-pixel images over time and extracting data on individual colonies. We present a methodology that enables quantification of variations in nominally-identical preparations and between colonies, correlation of colony characteristics with Oct4 expression, and identification of rare events.",Cell therapy | Fluorescence microscopy | Live cell imaging | Pluripotency | Stem cells,13,122-129,Journal,Article,11.0,"Bhadriraju, Kiran;Halter, Michael;Amelot, Julien;Bajcsy, Peter;Chalfoun, Joe;Vandecreme, Antoine;Mallon, Barbara S.;Park, Kye yoon;Sista, Subhash;Elliott, John T.;Plant, Anne L.",6602652493;7004045433;24801941700;6603030051;22233252100;56022739600;6602126615;7408066314;57503576600;7402852984;35579580400,"National Institute of Standards and Technology;University of Maryland, College Park;National Institute of Neurological Disorders and Stroke (NINDS)",United States;United States;United States,"identification and quantification of the characteristics of stem cell preparations is critical for understanding stem cell biology and for the development and manufacturing of stem cell based therapies. we have developed image analysis and visualization software that allows effective use of time-lapse microscopy to provide spatial and dynamic information from large numbers of human embryonic stem cell colonies. to achieve statistically relevant sampling, we examined > 680 colonies from 3 different preparations of cells over 5 days each, generating a total experimental dataset of 0.9 terabyte (tb). the 0.5 giga-pixel images at each time point were represented by multi-resolution pyramids and visualized using the deep zoom javascript library extended to support viewing giga-pixel images over time and extracting data on individual colonies. we present a methodology that enables quantification of variations in nominally-identical preparations and between colonies, correlation of colony characteristics with oct4 expression, and identification of rare events.",large-scale time-lapse microscopy of oct4 expression in human embryonic stem cell colonies
1297,2-s2.0-84973165849,10.1002/spe.2334,Empirical study of the dynamic behavior of JavaScript objects,Wei S.,Software - Practice and Experience,2016-07-01,"Summary Despite the popularity of JavaScript for client-side web applications, there is a lack of effective software tools supporting JavaScript development and testing. The dynamic characteristics of JavaScript pose software engineering challenges such as program understanding and security. One important feature of JavaScript is that its objects support flexible mechanisms such as property changes at runtime and prototype-based inheritance, making it difficult to reason about object behavior. We have performed an empirical study on real JavaScript applications to understand the dynamic behavior of JavaScript objects. We present metrics to measure behavior of JavaScript objects during execution (e.g., operations associated with an object, object size, and property type changes). We also investigated the behavioral patterns of observed objects to understand the coding or user interaction practices in JavaScript software.",JavaScript | object behavioral metrics and patterns | study of websites,6,867-889,Journal,Article,3.0,"Wei, Shiyi;Xhakaj, Franceska;Ryder, Barbara G.",55497866400;56989963500;7003693065,Virginia Polytechnic Institute and State University;Lafayette College,United States;United States,"summary despite the popularity of javascript for client-side web applications, there is a lack of effective software tools supporting javascript development and testing. the dynamic characteristics of javascript pose software engineering challenges such as program understanding and security. one important feature of javascript is that its objects support flexible mechanisms such as property changes at runtime and prototype-based inheritance, making it difficult to reason about object behavior. we have performed an empirical study on real javascript applications to understand the dynamic behavior of javascript objects. we present metrics to measure behavior of javascript objects during execution (e.g., operations associated with an object, object size, and property type changes). we also investigated the behavioral patterns of observed objects to understand the coding or user interaction practices in javascript software.",empirical study of the dynamic behavior of javascript objects
1298,2-s2.0-84963627039,10.1016/j.cmpb.2016.03.030,BIOMedical Search Engine Framework: Lightweight and customized implementation of domain-specific biomedical search engines,Jácome A.,Computer Methods and Programs in Biomedicine,2016-07-01,"Background and objectives: Text mining and semantic analysis approaches can be applied to the construction of biomedical domain-specific search engines and provide an attractive alternative to create personalized and enhanced search experiences. Therefore, this work introduces the new open-source BIOMedical Search Engine Framework for the fast and lightweight development of domain-specific search engines. The rationale behind this framework is to incorporate core features typically available in search engine frameworks with flexible and extensible technologies to retrieve biomedical documents, annotate meaningful domain concepts, and develop highly customized Web search interfaces. Methods: The BIOMedical Search Engine Framework integrates taggers for major biomedical concepts, such as diseases, drugs, genes, proteins, compounds and organisms, and enables the use of domain-specific controlled vocabulary. Technologies from the Typesafe Reactive Platform, the AngularJS JavaScript framework and the Bootstrap HTML/CSS framework support the customization of the domain-oriented search application. Moreover, the RESTful API of the BIOMedical Search Engine Framework allows the integration of the search engine into existing systems or a complete web interface personalization. Results: The construction of the Smart Drug Search is described as proof-of-concept of the BIOMedical Search Engine Framework. This public search engine catalogs scientific literature about antimicrobial resistance, microbial virulence and topics alike. The keyword-based queries of the users are transformed into concepts and search results are presented and ranked accordingly. The semantic graph view portraits all the concepts found in the results, and the researcher may look into the relevance of different concepts, the strength of direct relations, and non-trivial, indirect relations. The number of occurrences of the concept shows its importance to the query, and the frequency of concept co-occurrence is indicative of biological relations meaningful to that particular scope of research. Conversely, indirect concept associations, i.e. concepts related by other intermediary concepts, can be useful to integrate information from different studies and look into non-trivial relations. Conclusions: The BIOMedical Search Engine Framework supports the development of domain-specific search engines. The key strengths of the framework are modularity and extensibility in terms of software design, the use of open-source consolidated Web technologies, and the ability to integrate any number of biomedical text mining tools and information resources. Currently, the Smart Drug Search keeps over 1,186,000 documents, containing more than 11,854,000 annotations for 77,200 different concepts. The Smart Drug Search is publicly accessible at http://sing.ei.uvigo.es/sds/. The BIOMedical Search Engine Framework is freely available for non-commercial use at https://github.com/agjacome/biomsef.",Biomedical literature | Search engine framework | Text mining | Vertical engine | Web application,3,63-77,Journal,Article,3.0,"Jácome, Alberto G.;Fdez-Riverola, Florentino;Lourenço, Anália",56728293500;35580091100;7005749859,Universidade de Vigo;Universidade do Minho,Spain;Portugal,"background and objectives: text mining and semantic analysis approaches can be applied to the construction of biomedical domain-specific search engines and provide an attractive alternative to create personalized and enhanced search experiences. therefore, this work introduces the new open-source biomedical search engine framework for the fast and lightweight development of domain-specific search engines. the rationale behind this framework is to incorporate core features typically available in search engine frameworks with flexible and extensible technologies to retrieve biomedical documents, annotate meaningful domain concepts, and develop highly customized web search interfaces. methods: the biomedical search engine framework integrates taggers for major biomedical concepts, such as diseases, drugs, genes, proteins, compounds and organisms, and enables the use of domain-specific controlled vocabulary. technologies from the typesafe reactive platform, the angularjs javascript framework and the bootstrap html/css framework support the customization of the domain-oriented search application. moreover, the restful api of the biomedical search engine framework allows the integration of the search engine into existing systems or a complete web interface personalization. results: the construction of the smart drug search is described as proof-of-concept of the biomedical search engine framework. this public search engine catalogs scientific literature about antimicrobial resistance, microbial virulence and topics alike. the keyword-based queries of the users are transformed into concepts and search results are presented and ranked accordingly. the semantic graph view portraits all the concepts found in the results, and the researcher may look into the relevance of different concepts, the strength of direct relations, and non-trivial, indirect relations. the number of occurrences of the concept shows its importance to the query, and the frequency of concept co-occurrence is indicative of biological relations meaningful to that particular scope of research. conversely, indirect concept associations, i.e. concepts related by other intermediary concepts, can be useful to integrate information from different studies and look into non-trivial relations. conclusions: the biomedical search engine framework supports the development of domain-specific search engines. the key strengths of the framework are modularity and extensibility in terms of software design, the use of open-source consolidated web technologies, and the ability to integrate any number of biomedical text mining tools and information resources. currently, the smart drug search keeps over 1,186,000 documents, containing more than 11,854,000 annotations for 77,200 different concepts. the smart drug search is publicly accessible at http://sing.ei.uvigo.es/sds/. the biomedical search engine framework is freely available for non-commercial use at https://github.com/agjacome/biomsef.",biomedical search engine framework: lightweight and customized implementation of domain-specific biomedical search engines
1299,2-s2.0-85034252790,10.1109/ICSS.2016.13,Data Driven Development Trend Analysis of Mainstream Information Technologies,Wen J.,"Proceedings of International Conference on Service Science, ICSS",2016-06-28,"Software developers often find answers to their programming issues on the Internet. Q&A (Question & Answer) websites has been becoming more and more popular. Among the available technical Q&A sites, the most prevalent one is the Stack Overflow, it has been becoming one of the invaluable knowledge repositories. The development trends of language and mainstream operation systems are discussed by using the SVD (Singular Value Decomposition) and K-means algorithm in this paper. Some key findings include: Traditional programming languages such as C#, C++, C develop slowly and the light script languages such as Php, JavaScript and Python develop rapidly, traditional operation systems such as Windows and Linux develop slowly and the mobile devices operation systems such as IOS and Android develop rapidly. Through studying and analyzing the development of mainstream technology, people can grasp the dynamic situation of the software field, which has important and far-reaching significance to guide the work of software engineering.",K-means | Knowledge repository | mainstream language | mainstream operation | Q&amp;A website,2,39-45,Conference Proceeding,Conference Paper,3.0,"Wen, Junhao;Sun, Guanghui;Luo, Fengji",8950200000;57197725632;36651157400,The University of Sydney;Chongqing University,Australia;China,"software developers often find answers to their programming issues on the internet. q&a (question & answer) websites has been becoming more and more popular. among the available technical q&a sites, the most prevalent one is the stack overflow, it has been becoming one of the invaluable knowledge repositories. the development trends of language and mainstream operation systems are discussed by using the svd (singular value decomposition) and k-means algorithm in this paper. some key findings include: traditional programming languages such as c#, c++, c develop slowly and the light script languages such as php, javascript and python develop rapidly, traditional operation systems such as windows and linux develop slowly and the mobile devices operation systems such as ios and android develop rapidly. through studying and analyzing the development of mainstream technology, people can grasp the dynamic situation of the software field, which has important and far-reaching significance to guide the work of software engineering.",data driven development trend analysis of mainstream information technologies
1300,2-s2.0-84985914219,10.1145/2930674.2938614,Demo - Web application ArtEater,Mohr A.,Proceedings of IDC 2016 - The 15th International Conference on Interaction Design and Children,2016-06-21,"Central goal of this research project was to transfer the empirical findings about children's creative-aesthetic activities [10] to the implementation and evaluation of software. As a consequence the medial-aesthetic interests and needs of the children should be increased and their perspective empowered. In cooperation with primary school children and university students a crossplatform HTML 5 and JavaScript application named ""ArtEater"" has been built. This app enables open interaction processes with changing creative-aesthetic activities (like painting, drawing, integrating, exploring, staging, arranging, playing, collecting and writing) and is based on art educational requirements in a children's drawing software. Before, during and after the implementation of the web application the software has been evaluated by children after the participatory design principles [16].",Creativity | Education | Fine arts | Software development,1,684-687,Conference Proceeding,Conference Paper,3.0,"Mohr, Anja;Kothe, Tina;Hußmann, Heinrich",57191032232;57191035324;23389275800,Ludwig-Maximilians-Universität München,Germany,"central goal of this research project was to transfer the empirical findings about children's creative-aesthetic activities [10] to the implementation and evaluation of software. as a consequence the medial-aesthetic interests and needs of the children should be increased and their perspective empowered. in cooperation with primary school children and university students a crossplatform html 5 and javascript application named ""arteater"" has been built. this app enables open interaction processes with changing creative-aesthetic activities (like painting, drawing, integrating, exploring, staging, arranging, playing, collecting and writing) and is based on art educational requirements in a children's drawing software. before, during and after the implementation of the web application the software has been evaluated by children after the participatory design principles [16].",demo - web application arteater
1301,2-s2.0-84981513143,10.1109/CBSE.2016.20,KevoreeJS: Enabling Dynamic Software Reconfigurations in the Browser,Tricoire M.,"Proceedings - 2016 19th International ACM SIGSOFT Symposium on Component-Based Software Engineering, CBSE 2016",2016-06-21,"The architecture of classic productivity software are moving from a traditional desktop-based software to a client server architecture hosted in the Cloud. In this context, web browsers behave as application containers that allow users to access a variety of Cloud-based applications and services, such as IDEs, Word processors, Music Collection Managers, etc. As a result, a significant part of these software run in the browser and accesses remote services. A lesson learned from development framework used in distributed applications is the success of pluggable architecture pattern as a core architecture concept, i.e., a Software Architecture that promotes the use of Pluggable Module to dynamically plug. Following this trend, this paper discusses the main challenges to create a component-based platform supporting the development of dynamically adaptable single web page applications. This paper also presents an approach called KevoreeJS based on models@runtime to control browser as component platform which address some of these challenges. We validate this work by presenting the design of a dashboard for sensor based system and highlighting the capacity of KevoreeJS to dynamically choose the placement of code on the server or client side and how KevoreeJS can be used to dynamically install or remove running components.",Dynamic component model | Single page application | Web Engineering,2,49-58,Conference Proceeding,Conference Paper,9.0,"Tricoire, Maxime;Barais, Olivier;Leduc, Manuel;Bourcier, Johann;Fouquet, François;Nain, Grégory;Mouline, Ludovic;Sunyé, Gerson;Morin, Brice",56518104700;23395899700;57190608823;22633402700;36630197700;36914462100;57190605721;8634149500;25654443500,University of Luxembourg;Université de Nantes;Universite de Rennes 1;SINTEF Foundation for Scientific and Industrial Research,Luxembourg;France;France;Norway,"the architecture of classic productivity software are moving from a traditional desktop-based software to a client server architecture hosted in the cloud. in this context, web browsers behave as application containers that allow users to access a variety of cloud-based applications and services, such as ides, word processors, music collection managers, etc. as a result, a significant part of these software run in the browser and accesses remote services. a lesson learned from development framework used in distributed applications is the success of pluggable architecture pattern as a core architecture concept, i.e., a software architecture that promotes the use of pluggable module to dynamically plug. following this trend, this paper discusses the main challenges to create a component-based platform supporting the development of dynamically adaptable single web page applications. this paper also presents an approach called kevoreejs based on models@runtime to control browser as component platform which address some of these challenges. we validate this work by presenting the design of a dashboard for sensor based system and highlighting the capacity of kevoreejs to dynamically choose the placement of code on the server or client side and how kevoreejs can be used to dynamically install or remove running components.",kevoreejs: enabling dynamic software reconfigurations in the browser
1304,2-s2.0-85009146301,10.1021/acssynbio.5b00210,"The SBOL stack: A platform for storing, publishing, and sharing synthetic biology designs",Madsen C.,ACS Synthetic Biology,2016-06-07,"Recently, synthetic biologists have developed the Synthetic Biology Open Language (SBOL), a data exchange standard for descriptions of genetic parts, devices, modules, and systems. The goals of this standard are to allow scientists to exchange designs of biological parts and systems, to facilitate the storage of genetic designs in repositories, and to facilitate the description of genetic designs in publications. In order to achieve these goals, the development of an infrastructure to store, retrieve, and exchange SBOL data is necessary. To address this problem, we have developed the SBOL Stack, a Resource Description Framework (RDF) database specifically designed for the storage, integration, and publication of SBOL data. This database allows users to define a library of synthetic parts and designs as a service, to share SBOL data with collaborators, and to store designs of biological systems locally. The database also allows external data sources to be integrated by mapping them to the SBOL data model. The SBOL Stack includes two Web interfaces: The SBOL Stack API and SynBioHub. While the former is designed for developers, the latter allows users to upload new SBOL biological designs, download SBOL documents, search by keyword, and visualize SBOL data. Since the SBOL Stack is based on semantic Web technology, the inherent distributed querying functionality of RDF databases can be used to allow different SBOL stack databases to be queried simultaneously, and therefore, data can be shared between different institutes, centers, or other users.","database, data standards | RDF | synthetic biology | Synthetic Biology Open Language (SBOL) | triplestore",19,487-497,Journal,Article,7.0,"Madsen, Curtis;McLaughlin, James Alastair;Misirl, Göksel;Pocock, Matthew;Flanagan, Keith;Hallinan, Jennifer;Wipat, Anil",35224938700;57037832500;57192918543;57191894923;15126709300;6701920501;6602761323,"Boston University;Macquarie University;Newcastle University;Turing Ate My Hamster, Ltd.",United States;Australia;United Kingdom;United Kingdom,"recently, synthetic biologists have developed the synthetic biology open language (sbol), a data exchange standard for descriptions of genetic parts, devices, modules, and systems. the goals of this standard are to allow scientists to exchange designs of biological parts and systems, to facilitate the storage of genetic designs in repositories, and to facilitate the description of genetic designs in publications. in order to achieve these goals, the development of an infrastructure to store, retrieve, and exchange sbol data is necessary. to address this problem, we have developed the sbol stack, a resource description framework (rdf) database specifically designed for the storage, integration, and publication of sbol data. this database allows users to define a library of synthetic parts and designs as a service, to share sbol data with collaborators, and to store designs of biological systems locally. the database also allows external data sources to be integrated by mapping them to the sbol data model. the sbol stack includes two web interfaces: the sbol stack api and synbiohub. while the former is designed for developers, the latter allows users to upload new sbol biological designs, download sbol documents, search by keyword, and visualize sbol data. since the sbol stack is based on semantic web technology, the inherent distributed querying functionality of rdf databases can be used to allow different sbol stack databases to be queried simultaneously, and therefore, data can be shared between different institutes, centers, or other users.","the sbol stack: a platform for storing, publishing, and sharing synthetic biology designs"
1307,2-s2.0-84960848784,10.1016/j.epidem.2015.12.002,EpiJSON: A unified data-format for epidemiology,Finnie T.J.R.,Epidemics,2016-06-01,"Epidemiology relies on data but the divergent ways data are recorded and transferred, both within and between outbreaks, and the expanding range of data-types are creating an increasingly complex problem for the discipline. There is a need for a consistent, interpretable and precise way to transfer data while maintaining its fidelity. We introduce 'EpiJSON', a new, flexible, and standards-compliant format for the interchange of epidemiological data using JavaScript Object Notation. This format is designed to enable the widest range of epidemiological data to be unambiguously held and transferred between people, software and institutions. In this paper, we provide a full description of the format and a discussion of the design decisions made. We introduce a schema enabling automatic checks of the validity of data stored as EpiJSON, which can serve as a basis for the development of additional tools. In addition, we also present the R package 'repijson' which provides conversion tools between this format, line-list data and pre-existing analysis tools. An example is given to illustrate how EpiJSON can be used to store line list data. EpiJSON, designed around modern standards for interchange of information on the internet, is simple to implement, read and check. As such, it provides an ideal new standard for epidemiological, and other, data transfer to the fast-growing open-source platform for the analysis of disease outbreaks.",Communications standards | Databases | Epidemics | Outbreaks | Software,6,20-26,Journal,Article,5.0,"Finnie, Thomas J.R.;South, Andy;Bento, Ana;Sherrard-Smith, Ellie;Jombart, Thibaut",55086140000;7003869348;57193691254;26645209800;24331843100,Public Health England;Imperial College London;Consultancy,United Kingdom;United Kingdom;United Kingdom,"epidemiology relies on data but the divergent ways data are recorded and transferred, both within and between outbreaks, and the expanding range of data-types are creating an increasingly complex problem for the discipline. there is a need for a consistent, interpretable and precise way to transfer data while maintaining its fidelity. we introduce 'epijson', a new, flexible, and standards-compliant format for the interchange of epidemiological data using javascript object notation. this format is designed to enable the widest range of epidemiological data to be unambiguously held and transferred between people, software and institutions. in this paper, we provide a full description of the format and a discussion of the design decisions made. we introduce a schema enabling automatic checks of the validity of data stored as epijson, which can serve as a basis for the development of additional tools. in addition, we also present the r package 'repijson' which provides conversion tools between this format, line-list data and pre-existing analysis tools. an example is given to illustrate how epijson can be used to store line list data. epijson, designed around modern standards for interchange of information on the internet, is simple to implement, read and check. as such, it provides an ideal new standard for epidemiological, and other, data transfer to the fast-growing open-source platform for the analysis of disease outbreaks.",epijson: a unified data-format for epidemiology
1308,2-s2.0-84946109430,10.1007/s10278-015-9842-0,A Platform-Independent Plugin for Navigating Online Radiology Cases,Balkman J.,Journal of Digital Imaging,2016-06-01,"Software methods that enable navigation of radiology cases on various digital platforms differ between handheld devices and desktop computers. This has resulted in poor compatibility of online radiology teaching files across mobile smartphones, tablets, and desktop computers. A standardized, platform-independent, or “agnostic” approach for presenting online radiology content was produced in this work by leveraging modern hypertext markup language (HTML) and JavaScript web software technology. We describe the design and evaluation of this software, demonstrate its use across multiple viewing platforms, and make it publicly available as a model for future development efforts.",Electronic teaching | File | Medical displays | Software design | Web technology,2,321-324,Journal,Article,2.0,"Balkman, Jason D.;Awan, Omer A.",8291665900;35736958900,Dartmouth-Hitchcock Medical Center,United States,"software methods that enable navigation of radiology cases on various digital platforms differ between handheld devices and desktop computers. this has resulted in poor compatibility of online radiology teaching files across mobile smartphones, tablets, and desktop computers. a standardized, platform-independent, or “agnostic” approach for presenting online radiology content was produced in this work by leveraging modern hypertext markup language (html) and javascript web software technology. we describe the design and evaluation of this software, demonstrate its use across multiple viewing platforms, and make it publicly available as a model for future development efforts.",a platform-independent plugin for navigating online radiology cases
1310,2-s2.0-84977492010,10.1109/SAS.2016.7479879,Flexible architecture to automate farm machinery operation: Preliminary results,Taylor B.,"SAS 2016 - Sensors Applications Symposium, Proceedings",2016-05-26,A versatile framework for automation of sophisticated farm machinery has been proposed in this paper. The paper details the functional design and development of the hardware and software architecture of the framework for electronic monitoring and control of a complex system. The framework aims to provide a user friendly bridge between the digital world and the physical world and covers the core software functionalities for monitoring and control. The user interface is hosted on a local web server running off a single board computer. This interface is accessed by a web browser on a mobile device (such as a smart phone or a tablet) through a Wi-Fi connection. The computer monitors and controls the mounted sensors and actuators through an I/O extension cape. It stores all monitored data and control updates in a database. The user interface is updated regularly to ensure that what the operator sees is the latest information. The paper summarizes the outcome of implementing the framework using a few sensors and actuators in a lab environment.,Farm Machinery Automation | monitor and control | Single Board Computer | Wireless Sensor Network,0,396-400,Conference Proceeding,Conference Paper,3.0,"Taylor, Brendan;Gupta, Gourab Sen;Mercer, Ken",57190126927;56269183200;7003763192,Massey University,New Zealand,a versatile framework for automation of sophisticated farm machinery has been proposed in this paper. the paper details the functional design and development of the hardware and software architecture of the framework for electronic monitoring and control of a complex system. the framework aims to provide a user friendly bridge between the digital world and the physical world and covers the core software functionalities for monitoring and control. the user interface is hosted on a local web server running off a single board computer. this interface is accessed by a web browser on a mobile device (such as a smart phone or a tablet) through a wi-fi connection. the computer monitors and controls the mounted sensors and actuators through an i/o extension cape. it stores all monitored data and control updates in a database. the user interface is updated regularly to ensure that what the operator sees is the latest information. the paper summarizes the outcome of implementing the framework using a few sensors and actuators in a lab environment.,flexible architecture to automate farm machinery operation: preliminary results
1311,2-s2.0-84978280172,10.1109/CONISOFT.2016.20,MVC design pattern based-development of groupware,Anzures-Garcia M.,"Proceedings - 2016 4th International Conference in Software Engineering Research and Innovation, CONISOFT 2016",2016-05-23,"This paper proposes an MVC Design Pattern for developing groupware. This MVC is customized to take into account both individuals and group aspects, as well as, its evolution to offer users the suitable flexibility and responsiveness at all times. This is achieved through the set of items that configure it, which result from the analysis of various models, methodologies, and tools used in the groupware domain. These items are allocated on templates that serve as guidelines to analyze, design, and implement groupware. Furthermore, this MVC is supported by an ontology that models the group organizational structure, allowing the evolution, reuse and adaptation of groupware, since, the ontology can be adjusted by adding instances, concepts, and/or relations, and a workflow that specifies the task precedence, considering its order and execution through stages. Finally, a case study is presented to attest the viability of the proposal.",design pattern groupware | group organizational structure | MVC | template,3,71-80,Conference Proceeding,Conference Paper,4.0,"Anzures-Garcia, Mario;Sanchez-Galvez, Luz A.;Hornos, Miguel J.;Paderewski-Rodriguez, Patricia",23392138300;23474972600;23392559400;6506414966,Universidad de Granada;Benemerita Universidad Autonoma de Puebla,Spain;Mexico,"this paper proposes an mvc design pattern for developing groupware. this mvc is customized to take into account both individuals and group aspects, as well as, its evolution to offer users the suitable flexibility and responsiveness at all times. this is achieved through the set of items that configure it, which result from the analysis of various models, methodologies, and tools used in the groupware domain. these items are allocated on templates that serve as guidelines to analyze, design, and implement groupware. furthermore, this mvc is supported by an ontology that models the group organizational structure, allowing the evolution, reuse and adaptation of groupware, since, the ontology can be adjusted by adding instances, concepts, and/or relations, and a workflow that specifies the task precedence, considering its order and execution through stages. finally, a case study is presented to attest the viability of the proposal.",mvc design pattern based-development of groupware
1314,2-s2.0-84974574237,10.1109/MySEC.2015.7475186,Orchestration framework for automated Ajax-based web application testing,Deyab H.H.,"2015 9th Malaysian Software Engineering Conference, MySEC 2015",2016-05-19,"The web today is a growing universe of interlinked web pages and web apps, teeming with videos, photos, and interactive content. Over time web technologies have evolved to give web developers the ability to create new generations of useful and immersive web experiences. The most important technology in realizing this shift is Ajax (Asynchronous Javascript and XML). Ajax is a major breakthrough in the web development area even though it is rather complex to set it up and test. Tools like CRAWLJAX automatically generate test cases and apply pipelined oracle comparators along with generated DOM templates. But with the huge amount of data and test cases this comes at the cost of accuracy and speed. This paper explores the webapplication automated testing. In this research, orchestration framework has been introduced to effectively control automated task and orchestrated process. The orchestrator has been further implemented and demonstrated on a prototype production test. The functionalities and implementation of the orchestrator has been discussed in detail in this paper.",Ajax test | Automated testing | Test Orchestration | Web crawling,0,1-6,Conference Proceeding,Conference Paper,2.0,"Deyab, Hitham Haidar;Atan, Rodziah Binti",57189684189;25824744000,Universiti Putra Malaysia,Malaysia,"the web today is a growing universe of interlinked web pages and web apps, teeming with videos, photos, and interactive content. over time web technologies have evolved to give web developers the ability to create new generations of useful and immersive web experiences. the most important technology in realizing this shift is ajax (asynchronous javascript and xml). ajax is a major breakthrough in the web development area even though it is rather complex to set it up and test. tools like crawljax automatically generate test cases and apply pipelined oracle comparators along with generated dom templates. but with the huge amount of data and test cases this comes at the cost of accuracy and speed. this paper explores the webapplication automated testing. in this research, orchestration framework has been introduced to effectively control automated task and orchestrated process. the orchestrator has been further implemented and demonstrated on a prototype production test. the functionalities and implementation of the orchestrator has been discussed in detail in this paper.",orchestration framework for automated ajax-based web application testing
1315,2-s2.0-84976569461,10.1080/02533839.2015.1112250,A restful web notification service,Lo W.T.,"Journal of the Chinese Institute of Engineers, Transactions of the Chinese Institute of Engineers,Series A",2016-05-18,"With the rapid growth of mobile applications or web services, many users are using the same service at the same time which leads to the need for scalable application services. To enlarge the capability of handling large volumes of concurrent requests, server-side push technologies have been then introduced recently. Server-side push technology tries to eliminate unnecessary client requests by sending notification messages to clients when a data change event is triggered on the server side. There are two famous server-side push frameworks used today, and they are services using the Pub/Sub protocol, and the Ajax Push Model. These two mechanisms need middleware between clients and servers which result in complex and heavy-weight system architectures for application developers. To simplify development and increase ability to accommodate the growth in application users, a RESTful notification service is proposed in this paper. The notification service leverages the event-driven characteristic of JavaScript, and pushes response data asynchronously to different requests. Based on the RESTful software architecture style, the proposed notification service is not only a lightweight system but also has impressive performance.",Notification service | RESTful web service | Server-side push,0,429-435,Journal,Article,4.0,"Lo, Win Tsung;Sheu, Ruey Kai;Chang, Yue Shan;Chang, Yao Wen",7201502506;7003750859;13805521600;56582947500,Tunghai University;National Taipei University,Taiwan;Taiwan,"with the rapid growth of mobile applications or web services, many users are using the same service at the same time which leads to the need for scalable application services. to enlarge the capability of handling large volumes of concurrent requests, server-side push technologies have been then introduced recently. server-side push technology tries to eliminate unnecessary client requests by sending notification messages to clients when a data change event is triggered on the server side. there are two famous server-side push frameworks used today, and they are services using the pub/sub protocol, and the ajax push model. these two mechanisms need middleware between clients and servers which result in complex and heavy-weight system architectures for application developers. to simplify development and increase ability to accommodate the growth in application users, a restful notification service is proposed in this paper. the notification service leverages the event-driven characteristic of javascript, and pushes response data asynchronously to different requests. based on the restful software architecture style, the proposed notification service is not only a lightweight system but also has impressive performance.",a restful web notification service
1316,2-s2.0-85026665442,10.1145/2889160.2891040,Towards better program obfuscation: Optimization via language models,Liu H.,Proceedings - International Conference on Software Engineering,2016-05-14,"As a common practice in software development, program obfuscation aims at deterring reverse engineering and malicious attacks on released source or binary code. Owning ample obfuscation techniques, we have relatively little knowledge on how to most effectively use them. The biggest challenge lies in identifying the most useful combination of these techniques. We propose a unified framework to automatically generate and optimize obfuscation based on an obscurity language model and a Monte Carlo Markov Chain (MCMC) based search algorithm. We further instantiate it for JavaScript programs and developed the Closure∗ tool. Compared to the well-known Google Closure Compiler, Closure∗ outperforms its default setting by 26%. For programs which have already been well obfuscated, Closure∗ can still outperform by 22%.",MCMC random search | Obfuscation | Obscurity language model,5,680-682,Conference Proceeding,Conference Paper,1.0,"Liu, Han",56468215400,Tsinghua University,China,"as a common practice in software development, program obfuscation aims at deterring reverse engineering and malicious attacks on released source or binary code. owning ample obfuscation techniques, we have relatively little knowledge on how to most effectively use them. the biggest challenge lies in identifying the most useful combination of these techniques. we propose a unified framework to automatically generate and optimize obfuscation based on an obscurity language model and a monte carlo markov chain (mcmc) based search algorithm. we further instantiate it for javascript programs and developed the closure∗ tool. compared to the well-known google closure compiler, closure∗ outperforms its default setting by 26%. for programs which have already been well obfuscated, closure∗ can still outperform by 22%.",towards better program obfuscation: optimization via language models
1317,2-s2.0-85026633034,10.1145/2889160.2889241,Integrating automatic backward error recovery in asynchronous rich clients,Quintela-Pumares M.,Proceedings - International Conference on Software Engineering,2016-05-14,"Rich Web Clients allow developers to manage data locally and update it from the server by means of asynchronous requests, thus providing more interactive interfaces and an improved user experience. On the other hand, they face concerning challenges regarding error management. When there is a need to update the local data through multiple asynchronous requests and it is required that all them succeed, an error on a single call can lead to having incorrect information shown to the user. Consequently, developers need to explicitly implement proper recovery mechanisms, a task that most of times is complex and highly error prone, leading to tangled code and harder maintenance, especially in an asynchronous environment. These problems could be lessened through automatic error recovery techniques, but the existing state of the art for Rich Web Client development does not support recovery from asynchronous scenarios. To cope with this problem we extended the existing error recovery technique of Reconstructors, adding to it the capability of recovering the state in the presence of several asynchronous requests. We applied this technology in a widely used open source project for rendering interactive charts, ChartJs, thus allowing the developer to effortlessly guarantee that the data shown to the user, even when it results from multiple asynchronous requests, is never inconsistent. We compare our proposal to other solutions using state of the art approaches and verify that by using Reconstructors the overall implementation requires 39.16% less lines of code, and 5.66 times less lines of code are dedicated specifically to error management, while avoiding code tangling completely. Execution time showed by reconstructors is between 5.2% and 9.3% slower than other solutions, a cost we believe is worth its benefits, and feasible for using these techniques in real world client applications.",Asynchronous events | Automatic error recovery | Chart libraries | Rich web clients,0,192-201,Conference Proceeding,Conference Paper,4.0,"Quintela-Pumares, Manuel;Cabral, Bruno;Fernandez-Lanvin, Daniel;Fernandez-Alvarez, Alberto Manuel",36810470800;57190278557;26642388200;6507750376,"University of Coimbra, Centre for Informatics and System;Universidad de Oviedo",Portugal;Spain,"rich web clients allow developers to manage data locally and update it from the server by means of asynchronous requests, thus providing more interactive interfaces and an improved user experience. on the other hand, they face concerning challenges regarding error management. when there is a need to update the local data through multiple asynchronous requests and it is required that all them succeed, an error on a single call can lead to having incorrect information shown to the user. consequently, developers need to explicitly implement proper recovery mechanisms, a task that most of times is complex and highly error prone, leading to tangled code and harder maintenance, especially in an asynchronous environment. these problems could be lessened through automatic error recovery techniques, but the existing state of the art for rich web client development does not support recovery from asynchronous scenarios. to cope with this problem we extended the existing error recovery technique of reconstructors, adding to it the capability of recovering the state in the presence of several asynchronous requests. we applied this technology in a widely used open source project for rendering interactive charts, chartjs, thus allowing the developer to effortlessly guarantee that the data shown to the user, even when it results from multiple asynchronous requests, is never inconsistent. we compare our proposal to other solutions using state of the art approaches and verify that by using reconstructors the overall implementation requires 39.16% less lines of code, and 5.66 times less lines of code are dedicated specifically to error management, while avoiding code tangling completely. execution time showed by reconstructors is between 5.2% and 9.3% slower than other solutions, a cost we believe is worth its benefits, and feasible for using these techniques in real world client applications.",integrating automatic backward error recovery in asynchronous rich clients
1318,2-s2.0-84983540205,10.1145/2897073.2897133,Web-based hybrid mobile apps: State of the practice and research opportunities,Malavolta I.,"Proceedings - International Conference on Mobile Software Engineering and Systems, MOBILESoft 2016",2016-05-14,"This paper describes the contents of a tutorial on web-based hybrid mobile apps. Nowadays millions of mobile apps are downloaded and used all over the world. Mobile apps are distributed via di erent app stores like Google Play Store, the Apple App Store, the Windows Phone Store. One of the most intriguing challenges in mobile apps development is its fragmentation with respect to mobile platforms (e.g., Android, Apple iOS, Windows Phone). Recently, companies like IBM and Adobe and a growing community of developers advocate web-based hybrid mobile apps development as a possible solution to mobile platforms fragmentation. Webbased hybrid mobile apps are consistent across platforms and built on web standards like HTML5, CSS3, JavaScript. This tutorial provides a state of the art overview of the solutions, technologies, and research opportunities related to the development of web-based hybrid mobile apps. Apache Cordova is presented as one of the possible technologies for hybrid apps development. The results of two empirical studies performed on real hybrid mobile apps are presented as an up-to-date snapshot of the state of the practice in the field. Research opportunities and an open discussion close the tutorial.",App store analysis | Hybrid mobile apps | Web technologies,3,241-242,Conference Proceeding,Conference Paper,1.0,"Malavolta, Ivano",25823118300,Gran Sasso Science Institute;Vrije Universiteit Amsterdam,Italy;Netherlands,"this paper describes the contents of a tutorial on web-based hybrid mobile apps. nowadays millions of mobile apps are downloaded and used all over the world. mobile apps are distributed via di erent app stores like google play store, the apple app store, the windows phone store. one of the most intriguing challenges in mobile apps development is its fragmentation with respect to mobile platforms (e.g., android, apple ios, windows phone). recently, companies like ibm and adobe and a growing community of developers advocate web-based hybrid mobile apps development as a possible solution to mobile platforms fragmentation. webbased hybrid mobile apps are consistent across platforms and built on web standards like html5, css3, javascript. this tutorial provides a state of the art overview of the solutions, technologies, and research opportunities related to the development of web-based hybrid mobile apps. apache cordova is presented as one of the possible technologies for hybrid apps development. the results of two empirical studies performed on real hybrid mobile apps are presented as an up-to-date snapshot of the state of the practice in the field. research opportunities and an open discussion close the tutorial.",web-based hybrid mobile apps: state of the practice and research opportunities
1319,2-s2.0-84974717651,10.1145/2896958.2896965,Learning Game Design and Software Engineering through a Game Prototyping Experience: A Case Study,Yampolsky M.,Proceedings - International Conference on Software Engineering,2016-05-14,"This report describes a case study of small-scale effort in employing game playtesting as a starting point for learning about mainstream issues and challenges found in modern software engineering projects and practices. The goal is to be descriptive and informing through a qualitative rendering, rather than prescriptive and quantitative analysis. This study draws attention to the case of where a student with no prior experience in software development or programming must take on the task of learning how to make a game, and along the way learn about many common challenges in modern SE practice through personal discovery and experience. The game itself also imposes challenges in that we have chosen a new, unfamiliar game genre and domain that emphasizes science learning as its purpose for play. Along the way, we discuss issues in requirements, design, prototyping, testing, user experience assessment, and evolutionary software extension, all prior to a formal education in coding or introductory level Computer Science or SE. Though our efforts may seem unusual or anomalous, we believe our methods are open for adoption and reuse by those interested in lowering the barriers to entry into game software development in specific, and into SE more generally.",case study | Game design | playtesting | science learning games,2,15-21,Conference Proceeding,Conference Paper,2.0,"Yampolsky, Mark;Scacchi, Walt",57189702260;7004343180,"University of California, Irvine;Northwood High School",United States;United States,"this report describes a case study of small-scale effort in employing game playtesting as a starting point for learning about mainstream issues and challenges found in modern software engineering projects and practices. the goal is to be descriptive and informing through a qualitative rendering, rather than prescriptive and quantitative analysis. this study draws attention to the case of where a student with no prior experience in software development or programming must take on the task of learning how to make a game, and along the way learn about many common challenges in modern se practice through personal discovery and experience. the game itself also imposes challenges in that we have chosen a new, unfamiliar game genre and domain that emphasizes science learning as its purpose for play. along the way, we discuss issues in requirements, design, prototyping, testing, user experience assessment, and evolutionary software extension, all prior to a formal education in coding or introductory level computer science or se. though our efforts may seem unusual or anomalous, we believe our methods are open for adoption and reuse by those interested in lowering the barriers to entry into game software development in specific, and into se more generally.",learning game design and software engineering through a game prototyping experience: a case study
1320,2-s2.0-84974622057,10.1145/2904354.2904368,Exploring the impact of situational context - A case study of a software development process for a microservices architecture,O'Connor R.V.,"Proceedings - International Conference on Software and System Process, ICSSP 2016",2016-05-14,"Over the decades, a variety of software development processes have been proposed, each with their own advantages and disadvantages. It is however widely accepted that there is no single process that is perfectly suited to all settings, thus a software process should be molded to the needs of its situational context. In previous work, we have consolidated a substantial body of related research into an initial reference framework of the situational factors affecting the software development process. Practitioners can consult this framework in order to profile their context, a step necessary for effective software process decision making. In this paper, we report on the findings from a case study involving process discovery in a small but successful and growing software development firm. In this organization, which has a focus on continuous software evolution and delivery, we also applied the situational factors reference framework, finding that context is a complex and key informant for software process decisions. Studies of this type highlight the role of situational context in software process definition and evolution, and they raise awareness not just of the importance of situational context, but also of the complexity surrounding software process contexts, a complexity which may not be fully appreciated in all software development settings.",Agile | Lean | Process selection | Software development context | Software development process,19,6-10,Conference Proceeding,Conference Paper,3.0,"O'Connor, Rory V.;Elger, Peter;Clarke, Paul M.",7202869241;55841370000;36536766400,Dublin City University;NearForm Ltd.,Ireland;United States,"over the decades, a variety of software development processes have been proposed, each with their own advantages and disadvantages. it is however widely accepted that there is no single process that is perfectly suited to all settings, thus a software process should be molded to the needs of its situational context. in previous work, we have consolidated a substantial body of related research into an initial reference framework of the situational factors affecting the software development process. practitioners can consult this framework in order to profile their context, a step necessary for effective software process decision making. in this paper, we report on the findings from a case study involving process discovery in a small but successful and growing software development firm. in this organization, which has a focus on continuous software evolution and delivery, we also applied the situational factors reference framework, finding that context is a complex and key informant for software process decisions. studies of this type highlight the role of situational context in software process definition and evolution, and they raise awareness not just of the importance of situational context, but also of the complexity surrounding software process contexts, a complexity which may not be fully appreciated in all software development settings.",exploring the impact of situational context - a case study of a software development process for a microservices architecture
1321,2-s2.0-84974574910,10.1145/2896921.2896929,Automatic web security unit testing: XSS vulnerability detection,Mohammadi M.,"Proceedings - 11th International Workshop on Automation of Software Test, AST 2016",2016-05-14,Integrating security testing into the workflow of software developers not only can save resources for separate security testing but also reduce the cost of fixing security vulnerabilities by detecting them early in the development cycle. We present an automatic testing approach to detect a common type of Cross Site Scripting (XSS) vulnerability caused by improper encoding of untrusted data. We automatically extract encoding functions used in a web application to sanitize untrusted inputs and then evaluate their effectiveness by automatically generating XSS attack strings. Our evaluations show that this technique can detect 0-day XSS vulnerabilities that cannot be found by static analysis tools. We will also show that our approach can efficiently cover a common type of XSS vulnerability. This approach can be generalized to test for input validation against other types injections such as command line injection.,Attack generation | Crosssite scripting (XSS) | Program analysis | Sanitization evaluation | Security test harness | Unit testing,18,78-84,Conference Proceeding,Conference Paper,4.0,"Mohammadi, Mahmoud;Chu, Bill;Lipford, Heather Richter;Murphy-Hill, Emerson",57052212400;36918104500;25926003900;16307910100,The University of North Carolina at Charlotte;NC State University,United States;United States,integrating security testing into the workflow of software developers not only can save resources for separate security testing but also reduce the cost of fixing security vulnerabilities by detecting them early in the development cycle. we present an automatic testing approach to detect a common type of cross site scripting (xss) vulnerability caused by improper encoding of untrusted data. we automatically extract encoding functions used in a web application to sanitize untrusted inputs and then evaluate their effectiveness by automatically generating xss attack strings. our evaluations show that this technique can detect 0-day xss vulnerabilities that cannot be found by static analysis tools. we will also show that our approach can efficiently cover a common type of xss vulnerability. this approach can be generalized to test for input validation against other types injections such as command line injection.,automatic web security unit testing: xss vulnerability detection
1322,2-s2.0-84974573736,10.1145/2901739.2901743,A look at the dynamics of the JavaScript package ecosystem,Wittern E.,"Proceedings - 13th Working Conference on Mining Software Repositories, MSR 2016",2016-05-14,"The node package manager (npm) serves as the frontend to a large repository of JavaScript-based software packages, which foster the development of currently huge amounts of server-side Node.js and client-side JavaScript applications. In a span of 6 years since its inception, npm has grown to become one of the largest software ecosystems, hosting more than 230, 000 packages, with hundreds of millions of package installations every week. In this paper, we examine the npm ecosystem from two complementary perspectives: 1) we look at package descriptions, the dependencies among them, and download metrics, and 2) we look at the use of npm packages in publicly available applications hosted on GitHub. In both perspectives, we consider historical data, providing us with a unique view on the evolution of the ecosystem. We present analyses that provide insights into the ecosystem's growth and activity, into conflicting measures of package popularity, and into the adoption of package versions over time. These insights help understand the evolution of npm, design better package recommendation engines, and can help developers understand how their packages are being used.",JavaScript | Node.js | Software ecosystem analysis,77,351-361,Conference Proceeding,Conference Paper,3.0,"Wittern, Erik;Suter, Philippe;Rajagopalan, Shriram",47062279200;35559962700;7103018793,IBM Thomas J. Watson Research Center,United States,"the node package manager (npm) serves as the frontend to a large repository of javascript-based software packages, which foster the development of currently huge amounts of server-side node.js and client-side javascript applications. in a span of 6 years since its inception, npm has grown to become one of the largest software ecosystems, hosting more than 230, 000 packages, with hundreds of millions of package installations every week. in this paper, we examine the npm ecosystem from two complementary perspectives: 1) we look at package descriptions, the dependencies among them, and download metrics, and 2) we look at the use of npm packages in publicly available applications hosted on github. in both perspectives, we consider historical data, providing us with a unique view on the evolution of the ecosystem. we present analyses that provide insights into the ecosystem's growth and activity, into conflicting measures of package popularity, and into the adoption of package versions over time. these insights help understand the evolution of npm, design better package recommendation engines, and can help developers understand how their packages are being used.",a look at the dynamics of the javascript package ecosystem
1325,2-s2.0-85015081455,10.1145/2858036.2858311,Using runtime traces to improve documentation and unit test authoring for dynamic languages,Krämer J.,Conference on Human Factors in Computing Systems - Proceedings,2016-05-07,"Documentation and unit tests increase software maintainability, but real world software projects rarely have adequate coverage. We hypothesize that, in part, this is because existing authoring tools require developers to adjust their workflows significantly. To study whether improved interaction design could affect unit testing and documentation practice, we created an authoring support tool called Vesta. The main insight guiding Vesta's interaction design is that developers frequently manually test the software they are building. We propose leveraging runtime information from these manual executions. Because developers naturally exercise the part of the code on which they are currently working, this information will be highly relevant to appropriate documentation and testing tasks. In a complex coding task, nearly all documentation created using Vesta was accurate, compared to only 60% of documentation created without Vesta, and Vesta was able to generate significant portions of all tests, even those written manually by developers without Vesta.",Authoring tools | Documentation | Dynamic languages | Ides | Software development | Unit tests,3,3232-3237,Conference Proceeding,Conference Paper,3.0,"Krämer, Jan Peter;Brandt, Joel;Borchers, Jan",57198461417;22833423700;7005473180,Adobe Inc.;Rheinisch-Westfälische Technische Hochschule Aachen,United States;Germany,"documentation and unit tests increase software maintainability, but real world software projects rarely have adequate coverage. we hypothesize that, in part, this is because existing authoring tools require developers to adjust their workflows significantly. to study whether improved interaction design could affect unit testing and documentation practice, we created an authoring support tool called vesta. the main insight guiding vesta's interaction design is that developers frequently manually test the software they are building. we propose leveraging runtime information from these manual executions. because developers naturally exercise the part of the code on which they are currently working, this information will be highly relevant to appropriate documentation and testing tasks. in a complex coding task, nearly all documentation created using vesta was accurate, compared to only 60% of documentation created without vesta, and vesta was able to generate significant portions of all tests, even those written manually by developers without vesta.",using runtime traces to improve documentation and unit test authoring for dynamic languages
1328,2-s2.0-84968813891,10.1109/MS.2015.155,Node.DPWS: Efficient Web Services for the Internet of Things,Fysarakis K.,IEEE Software,2016-05-01,"Interconnected computing systems in various forms will soon permeate our lives, realizing the Internet of Things (IoT) and letting us enjoy novel, enhanced services that promise to improve our everyday life. Nevertheless, this new reality introduces significant challenges in terms of performance, scaling, usability, and interoperability. Leveraging the benefits of service-oriented architectures (SOAs) can help alleviate many of the issues that developers, implementers, and users alike must face in the context of the IoT. Node.DPWS is a novel implementation of the Devices Profile for Web Services (DPWS) based on the Node.js platform. It comprises the first set of DPWS libraries available to Node.js developers and can be used to deploy lightweight, efficient, and scalable Web services over heterogeneous nodes, including devices with limited resources. A performance evaluation on typical embedded devices validated the benefits of Node.DPWS compared to alternative DPWS libraries.",development tools | Devices Profile for Web Services | DPWS | Node.DPWS | Node.js | software development | software engineering | software libraries | standards | ubiquitous computing | Web services,9,60-67,Journal,Article,4.0,"Fysarakis, Konstantinos;Mylonakis, Damianos;Manifavas, Charalampos;Papaefstathiou, Ioannis",55427860800;57189300639;16031576800;6701918242,Hellenic Mediterranean University;Technical University of Crete;University of Crete,Greece;Greece;Greece,"interconnected computing systems in various forms will soon permeate our lives, realizing the internet of things (iot) and letting us enjoy novel, enhanced services that promise to improve our everyday life. nevertheless, this new reality introduces significant challenges in terms of performance, scaling, usability, and interoperability. leveraging the benefits of service-oriented architectures (soas) can help alleviate many of the issues that developers, implementers, and users alike must face in the context of the iot. node.dpws is a novel implementation of the devices profile for web services (dpws) based on the node.js platform. it comprises the first set of dpws libraries available to node.js developers and can be used to deploy lightweight, efficient, and scalable web services over heterogeneous nodes, including devices with limited resources. a performance evaluation on typical embedded devices validated the benefits of node.dpws compared to alternative dpws libraries.",node.dpws: efficient web services for the internet of things
1329,2-s2.0-84963865232,10.1016/j.jnca.2016.03.016,Software defined networks: A survey,Masoudi R.,Journal of Network and Computer Applications,2016-05-01,"As a result of the development of internet and ICT (information-centric technology) advances including mobile, cloud, social networking, big data, multimedia and the tendency towards digital society, the management and configuration of them have become highly complex, challenging and time consuming. Also, access to high bandwidth, extendibility and dynamic management are of critical significance, especially when network devices are vertically integrated. Hence, a set of unique predefined line commands and operating systems or firmware should be used. SDN (software-defined networking) is a structure designed for simplifying and improving network management with high flexibility by splitting control plane and data plane. Thus, network programmability is enhanced which in turn leads to more innovation opportunities. Although SDN is regarded as a new research issue, it has attracted numerous researchers' attention from both industrial and academic institutes. In this paper, data plane, control plane and application plane as the three planes of SDN and the interfaces between them such as OpenFlow are investigated and the challenges and the latest technologies in relation to SDN are examined. The investigation and overview of SDN reported in this paper might be used by the interested future researchers to better understand and apply SDN in real-life applications.",Control plane | Data plane | Network security | Network virtualization | OpenFlow | Programmable networks | QoS (quality of service) | SDN (software-defined network),129,1-25,Journal,Review,2.0,"Masoudi, Rahim;Ghaffari, Ali",57188849380;57197223215,"Islamic Azad University, Tabriz Branch",Iran,"as a result of the development of internet and ict (information-centric technology) advances including mobile, cloud, social networking, big data, multimedia and the tendency towards digital society, the management and configuration of them have become highly complex, challenging and time consuming. also, access to high bandwidth, extendibility and dynamic management are of critical significance, especially when network devices are vertically integrated. hence, a set of unique predefined line commands and operating systems or firmware should be used. sdn (software-defined networking) is a structure designed for simplifying and improving network management with high flexibility by splitting control plane and data plane. thus, network programmability is enhanced which in turn leads to more innovation opportunities. although sdn is regarded as a new research issue, it has attracted numerous researchers' attention from both industrial and academic institutes. in this paper, data plane, control plane and application plane as the three planes of sdn and the interfaces between them such as openflow are investigated and the challenges and the latest technologies in relation to sdn are examined. the investigation and overview of sdn reported in this paper might be used by the interested future researchers to better understand and apply sdn in real-life applications.",software defined networks: a survey
1334,2-s2.0-84925437225,10.1007/s10664-015-9368-6,Development nature matters: An empirical study of code clones in JavaScript applications,Cheung W.T.,Empirical Software Engineering,2016-04-01,"Code cloning is one of the active research areas in the software engineering community. Specifically, researchers have conducted numerous empirical studies on code cloning and reported that 7 % to 23 % of the code in a typical software system has been cloned. However, there was less awareness of code clones in dynamically-typed languages and most studies are limited to statically-typed languages such as Java, C, and C++. In addition, most previous studies did not consider different application domains such as standalone projects or web applications. As a result, very little is known about clones in dynamically-typed languages, such as JavaScript, in different application domains. In this paper, we report a large-scale clone detection experiment in a dynamically-typed programming language, JavaScript, for different application domains: web pages and standalone projects. Our experimental results showed that unlike JavaScript standalone projects, JavaScript web applications have 95 % of inter-file clones and 91–97 % of widely scattered clones. We observed that web application developers created clones intentionally and such clones may not be as risky as claimed in previous studies. Understanding the risks of cloning in web applications requires further studies, as cloning may be due to either good or bad intentions. Also, we identified unique development practices such as including browser-dependent or device-specific code in code clones of JavaScript web applications. This indicates that features of programming languages and technologies affect how developers duplicate code.",Clone properties | Cloning patterns | Code clones | JavaScript | Software metrics | Web applications,15,517-564,Journal,Article,3.0,"Cheung, Wai Ting;Ryu, Sukyoung;Kim, Sunghun",56567402900;22735372000;12241083400,Korea Advanced Institute of Science and Technology;Hong Kong University of Science and Technology,South Korea;Hong Kong,"code cloning is one of the active research areas in the software engineering community. specifically, researchers have conducted numerous empirical studies on code cloning and reported that 7 % to 23 % of the code in a typical software system has been cloned. however, there was less awareness of code clones in dynamically-typed languages and most studies are limited to statically-typed languages such as java, c, and c++. in addition, most previous studies did not consider different application domains such as standalone projects or web applications. as a result, very little is known about clones in dynamically-typed languages, such as javascript, in different application domains. in this paper, we report a large-scale clone detection experiment in a dynamically-typed programming language, javascript, for different application domains: web pages and standalone projects. our experimental results showed that unlike javascript standalone projects, javascript web applications have 95 % of inter-file clones and 91–97 % of widely scattered clones. we observed that web application developers created clones intentionally and such clones may not be as risky as claimed in previous studies. understanding the risks of cloning in web applications requires further studies, as cloning may be due to either good or bad intentions. also, we identified unique development practices such as including browser-dependent or device-specific code in code clones of javascript web applications. this indicates that features of programming languages and technologies affect how developers duplicate code.",development nature matters: an empirical study of code clones in javascript applications
1335,2-s2.0-84966546910,10.1109/REV.2016.7444460,A remote lab for teaching mechanics,Simão J.,"Proceedings of 2016 13th International Conference on Remote Engineering and Virtual Instrumentation, REV 2016",2016-03-30,"This document presents the development of a remote lab for teaching mechanical principles based on Galileo's Inclined Plane Experiment. The prototype was built making use of open hardware and software solutions in order to facilitate its replication. It uses Raspberry Pi to retrieve data from sensors and send commands to actuators connected to it, and provide video streaming from a generic webcam. Thus, the remote experimentation using mobile or conventional devices makes it easier to understand the movement of bodies for a wide range of users.",Inclined plane | Mechanics | Physics | Remote labs,4,176-182,Conference Proceeding,Conference Paper,7.0,"Simão, J. P.S.;Lima, J. P.C.;Heck, C.;Coelho, K.;Carlos, L. M.;Bilessimo, S. M.S.;Silva, J. B.",57189312099;57189237189;57189244276;57189243946;57189234921;56156823300;55575083100,Universidade Federal de Santa Catarina;E.E.B Apolônio Ireno Cardoso,Brazil;Brazil,"this document presents the development of a remote lab for teaching mechanical principles based on galileo's inclined plane experiment. the prototype was built making use of open hardware and software solutions in order to facilitate its replication. it uses raspberry pi to retrieve data from sensors and send commands to actuators connected to it, and provide video streaming from a generic webcam. thus, the remote experimentation using mobile or conventional devices makes it easier to understand the movement of bodies for a wide range of users.",a remote lab for teaching mechanics
1336,2-s2.0-84960416225,10.1108/LHT-08-2015-0082,Using web2py Python framework for creating data-driven web applications in the academic library,Miles M.,Library Hi Tech,2016-03-21,"Purpose – Many libraries have a need to develop their own data-driven web applications, but their technical staff often lacks the required specialized training – which includes knowledge of SQL, a web application language like PHP, JavaScript, CSS, and jQuery. The web2py framework greatly reduces the learning curve for creating data-driven websites by focussing on three main goals: ease of use; rapid development; and security. web2py follows a strict MVC framework where the controls and web templates are all written in pure Python. No additional templating language is required. The paper aims to discuss these issues. Design/methodology/approach – There are many frameworks available for creating database-driven web applications. The author had used ColdFusion for many years but wanted to move to a more complete web framework which was also open source. Findings – After evaluating a number of Python frameworks, web2py was found to provide the best combination of functionality and ease of use. This paper focusses on the strengths of web2py and not the specifics of evaluating the different frameworks. Practical implications – Librarians who feel that they do not have the skills to create data-driven websites in other frameworks might find that they can develop them in web2py. It is a good web application framework to start with, which might also provide a gateway to other frameworks. Originality/value – web2py is an open source framework that could have great benefit for those who may have struggled to create database-driven websites in other frameworks or languages.",Digital libraries | Python frameworks | Software evaluation | Software tools | Web2py | Websites,4,164-171,Journal,Article,1.0,"Miles, Mathew",35103072400,Brigham Young University-Idaho,United States,"purpose – many libraries have a need to develop their own data-driven web applications, but their technical staff often lacks the required specialized training – which includes knowledge of sql, a web application language like php, javascript, css, and jquery. the web2py framework greatly reduces the learning curve for creating data-driven websites by focussing on three main goals: ease of use; rapid development; and security. web2py follows a strict mvc framework where the controls and web templates are all written in pure python. no additional templating language is required. the paper aims to discuss these issues. design/methodology/approach – there are many frameworks available for creating database-driven web applications. the author had used coldfusion for many years but wanted to move to a more complete web framework which was also open source. findings – after evaluating a number of python frameworks, web2py was found to provide the best combination of functionality and ease of use. this paper focusses on the strengths of web2py and not the specifics of evaluating the different frameworks. practical implications – librarians who feel that they do not have the skills to create data-driven websites in other frameworks might find that they can develop them in web2py. it is a good web application framework to start with, which might also provide a gateway to other frameworks. originality/value – web2py is an open source framework that could have great benefit for those who may have struggled to create database-driven websites in other frameworks or languages.",using web2py python framework for creating data-driven web applications in the academic library
1337,2-s2.0-84966559616,10.1109/ICODSE.2015.7437005,Unit test code generator for lua programming language,Wibowo J.,"Proceedings of 2015 International Conference on Data and Software Engineering, ICODSE 2015",2016-03-18,"Software testing is an important step in the software development lifecycle. One of the main process that take lots of time is developing the test code. We propose an automatic unit test code generation to speed up the process and helps avoiding repetition. We develop the unit test code generator using Lua programming language. Lua is a fast, lightweight, embeddable scripting language. It has been used in many industrial applications with focuses on embedded systems and games. Unlike other popular scripting language like JavaScript, Python, and Ruby, Lua does not have any unit test generator developed to help its software testing process. The final product, Lua unit test generator (LUTG), integrated to one of the most popular Lua IDE, ZeroBrane Studio, as a plugin to seamlessly connect the coding and testing process. The code generator can generate unit test code, save test cases data on Lua and XML file format, and generate the test data automatically using search-based technique, genetic algorithm, to achieve full branch coverage test criteria. Using this generator to test several Lua source code files shows that the developed unit test generator can help the unit testing process. It was expected that the unit test generator can improve productivity, quality, consistency, and abstraction of unit testing process.",code generator | Lua | unit test,3,241-245,Conference Proceeding,Conference Paper,3.0,"Wibowo, Junno Tantra Pratama;Hendradjaya, Bayu;Widyani, Yani",57189236175;6504255623;53265269000,Institut Teknologi Bandung,Indonesia,"software testing is an important step in the software development lifecycle. one of the main process that take lots of time is developing the test code. we propose an automatic unit test code generation to speed up the process and helps avoiding repetition. we develop the unit test code generator using lua programming language. lua is a fast, lightweight, embeddable scripting language. it has been used in many industrial applications with focuses on embedded systems and games. unlike other popular scripting language like javascript, python, and ruby, lua does not have any unit test generator developed to help its software testing process. the final product, lua unit test generator (lutg), integrated to one of the most popular lua ide, zerobrane studio, as a plugin to seamlessly connect the coding and testing process. the code generator can generate unit test code, save test cases data on lua and xml file format, and generate the test data automatically using search-based technique, genetic algorithm, to achieve full branch coverage test criteria. using this generator to test several lua source code files shows that the developed unit test generator can help the unit testing process. it was expected that the unit test generator can improve productivity, quality, consistency, and abstraction of unit testing process.",unit test code generator for lua programming language
1338,2-s2.0-84971273121,10.1145/2889443.2889445,Modularity and optimization in synergy,Cazzola W.,MODULARITY 2016 - Proceedings of the 15th International Conference on Modularity,2016-03-14,"As with traditional software, the complexity of a programming language implementation is faced with modularization which favors the separation of concerns, independent development, maintainability and reuse. However, modularity interferes with language optimization as the latter requires context information that crosses over the single module boundaries and involves other modules. This renders hard to provide the optimization for a single language concept to be reusable with the concept itself. Therefore, the optimization is in general postponed to when all language concepts are available. We defined a model for modular language development with a multiple semantic actions dispatcher based on condition guards that are evaluated at runtime. The optimization can be implemented as context-dependent extensions applied a posteriori to the composed language interpreter without modifying a single component implementation. This renders effective the defined optimization within the language concept boundaries according to the context provided by other language concepts when available and eases its reuse with the language concepts implementation independently of its usage context. The presented model is integrated into the Neverlang development framework and is demonstrated on the optimization of a Javascript interpreter written in Neverlang. We also discuss the applicability of our model to other frameworks for modular language development..",And interpreter optimization | Modular language development | Neverlang,4,70-81,Conference Proceeding,Conference Paper,2.0,"Cazzola, Walter;Shaqiri, Albert",6602449966;55916154000,Università degli Studi di Milano,Italy,"as with traditional software, the complexity of a programming language implementation is faced with modularization which favors the separation of concerns, independent development, maintainability and reuse. however, modularity interferes with language optimization as the latter requires context information that crosses over the single module boundaries and involves other modules. this renders hard to provide the optimization for a single language concept to be reusable with the concept itself. therefore, the optimization is in general postponed to when all language concepts are available. we defined a model for modular language development with a multiple semantic actions dispatcher based on condition guards that are evaluated at runtime. the optimization can be implemented as context-dependent extensions applied a posteriori to the composed language interpreter without modifying a single component implementation. this renders effective the defined optimization within the language concept boundaries according to the context provided by other language concepts when available and eases its reuse with the language concepts implementation independently of its usage context. the presented model is integrated into the neverlang development framework and is demonstrated on the optimization of a javascript interpreter written in neverlang. we also discuss the applicability of our model to other frameworks for modular language development..",modularity and optimization in synergy
1339,2-s2.0-84965075995,10.1145/2892664.2892683,Compatibility layers for interface mediation at run-time,Rein P.,MODULARITY Companion 2016 - Companion Proceedings of the 15th International Conference on Modularity,2016-03-14,"In adaptable systems, one module might require an interface from another module which the second module does not provide. For some cases, the particular provider module and its interface which will be available at run-time can not be anticipated during development time. In such situations with various provider interfaces, current mitigation strategies for interface mismatches struggle as they often rely on advanced knowledge about one particular providing module. Therefore, we propose the concept of compatibility layers which is based on modular interface mappings. These mappings are applied to adapt the provided interface at run-time. Each mapping contains a set of general requirements for the provided interface and a set of derived functions based on the required features. We have implemented the concept of compatibility layers in a Squeak/Smalltalk prototype based on context-oriented programming. Based on this prototype, we discuss the resulting trade-offs and illustrate exemplary interface mismatches in Squeak/Smalltalk which could be mediated by the prototype.",Context-oriented programming | Dynamic adaptation | Interface compatibility | Interfaces | Modules,2,113-118,Conference Proceeding,Conference Paper,4.0,"Rein, Patrick;Hirschfeld, Robert;Lehmann, Stefan;Lincke, Jens",56417689000;23094434200;57162481400;24721726700,Hasso-Plattner-Institut für Softwaresystemtechnik GmbH,Germany,"in adaptable systems, one module might require an interface from another module which the second module does not provide. for some cases, the particular provider module and its interface which will be available at run-time can not be anticipated during development time. in such situations with various provider interfaces, current mitigation strategies for interface mismatches struggle as they often rely on advanced knowledge about one particular providing module. therefore, we propose the concept of compatibility layers which is based on modular interface mappings. these mappings are applied to adapt the provided interface at run-time. each mapping contains a set of general requirements for the provided interface and a set of derived functions based on the required features. we have implemented the concept of compatibility layers in a squeak/smalltalk prototype based on context-oriented programming. based on this prototype, we discuss the resulting trade-offs and illustrate exemplary interface mismatches in squeak/smalltalk which could be mediated by the prototype.",compatibility layers for interface mediation at run-time
1341,2-s2.0-85073063318,10.1142/S1793351X16400043,User reachability in Islands of WebRTC communication apps,Singh K.,International Journal of Semantic Computing,2016-03-01,"Recent progress in Web Real-Time Communication (WebRTC) promotes multi-apps environment by creating islands of communication apps where users of one website or service cannot easily communicate with those of another. We describe the architecture and implementation of a multi-platform system to do user reachability in multiple communication services where users decide how they want to be reached on multiple apps, e.g. in an organization that has voice-over-IP, web conferencing and messaging from different vendors. We argue for user and endpoint driven reachability policies and cross-app interactions, instead of pair-wise service federation or global location service. Our architecture separates the user contacts from reachability apps, and has several independent and non-interoperable WebRTC-based apps for two-way and multi-party multimedia communication. Our software is implemented using HTML5 and JavaScript, and using a cross-platform development tool, runs as native apps on mobile as well as personal computers. Our flexible implementation can be used for enterprise or personal communications, or as a white-labeled app for consumers of a business.",caller policy | cross-platform | mobile app | System design | user reachability | WebRTC,0,73-99,Journal,Article,1.0,"Singh, Kundan",7404763068,Avaya Inc.,United States,"recent progress in web real-time communication (webrtc) promotes multi-apps environment by creating islands of communication apps where users of one website or service cannot easily communicate with those of another. we describe the architecture and implementation of a multi-platform system to do user reachability in multiple communication services where users decide how they want to be reached on multiple apps, e.g. in an organization that has voice-over-ip, web conferencing and messaging from different vendors. we argue for user and endpoint driven reachability policies and cross-app interactions, instead of pair-wise service federation or global location service. our architecture separates the user contacts from reachability apps, and has several independent and non-interoperable webrtc-based apps for two-way and multi-party multimedia communication. our software is implemented using html5 and javascript, and using a cross-platform development tool, runs as native apps on mobile as well as personal computers. our flexible implementation can be used for enterprise or personal communications, or as a white-labeled app for consumers of a business.",user reachability in islands of webrtc communication apps
1342,2-s2.0-84964770422,10.1109/MS.2016.55,Leaders of tomorrow on the future of software engineering: A roundtable,Hermans F.,IEEE Software,2016-03-01,"Nine rising stars in software engineering describe how software engineering research will evolve, highlighting emerging opportunities and groundbreaking solutions. They predict the rise of end-user programming, the monitoring of developers through neuroimaging and biometrics sensors, analysis of data from unstructured documents, the mining of mobile marketplaces, and changes to how we create and release software.",biometrics | end-user programming | mobile marketplaces | neuroimaging | software development | software engineering | unstructured documents,4,99-104,Journal,Article,9.0,"Hermans, Felienne;Siegmund, Janet;Fritz, Thomas;Bavota, Gabriele;Nagappan, Meiyappan;Hindle, Abram;Kamei, Yasutaka;Mesbah, Ali;Adams, Bram",35573133300;55420344200;13408078500;57220148228;26537885500;21742620300;24476112100;17345931800;15134994200,University of Alberta;Polytechnique Montréal;Universität Passau;Universität Zürich;Kyushu University;The University of British Columbia;Free University of Bozen-Bolzano;Delft University of Technology;Rochester Institute of Technology,Canada;Canada;Germany;Switzerland;Japan;Canada;Italy;Netherlands;United States,"nine rising stars in software engineering describe how software engineering research will evolve, highlighting emerging opportunities and groundbreaking solutions. they predict the rise of end-user programming, the monitoring of developers through neuroimaging and biometrics sensors, analysis of data from unstructured documents, the mining of mobile marketplaces, and changes to how we create and release software.",leaders of tomorrow on the future of software engineering: a roundtable
1343,2-s2.0-84964317972,10.1109/MS.2016.57,Component stacks for enterprise applications,Louridas P.,IEEE Software,2016-03-01,"Until relatively recently, the tools used to develop Web applications followed a well-established architecture called the LAMP stack. Recently, the MEAN stack has taken the Web developer world by storm and is replacing LAMP.",AngularJS | Apache | Express | JavaScript | Jode.js | LAMP | Linux | MEAN | MongoDB | MySQL | NoSQL | PHP | relational databases | software development | software engineering | SQL,7,93-98,Journal,Article,1.0,"Louridas, Panos",17343724600,Athens University of Economics and Business,Greece,"until relatively recently, the tools used to develop web applications followed a well-established architecture called the lamp stack. recently, the mean stack has taken the web developer world by storm and is replacing lamp.",component stacks for enterprise applications
1344,2-s2.0-84963734499,10.1093/jamia/ocv104,A case study in open source innovation: Developing the Tidepool Platform for interoperability in type 1 diabetes management,Neinstein A.,Journal of the American Medical Informatics Association,2016-03-01,"Objective: Develop a device-agnostic cloud platform to host diabetes device data and catalyze an ecosystem of software innovation for type 1 diabetes (T1D) management. Materials and Methods An interdisciplinary team decided to establish a nonprofit company, Tidepool, and build open-source software. Results: Through a user-centered design process, the authors created a software platform, the Tidepool Platform, to upload and host T1D device data in an integrated, device-agnostic fashion, as well as an application (""app""), Blip, to visualize the data. Tidepool's software utilizes the principles of modular components, modern web design including REST APIs and JavaScript, cloud computing, agile development methodology, and robust privacy and security. Discussion: By consolidating the currently scattered and siloed T1D device data ecosystem into one open platform, Tidepool can improve access to the data and enable new possibilities and efficiencies in T1D clinical care and research. The Tidepool Platform decouples diabetes apps from diabetes devices, allowing software developers to build innovative apps without requiring them to design a unique back-end (e.g., database and security) or unique ways of ingesting device data. It allows people with T1D to choose to use any preferred app regardless of which device(s) they use. Conclusion: The authors believe that the Tidepool Platform can solve two current problems in the T1D device landscape: 1) limited access to T1D device data and 2) poor interoperability of data from different devices. If proven effective, Tidepool's open source, cloud model for health data interoperability is applicable to other healthcare use cases.",Blood glucose self-monitoring | Computerassisted | Decision making | Diabetes mellitus type 1 | Insulin infusion systems | Mobile applications,29,324-332,Journal,Article,9.0,"Neinstein, Aaron;Wong, Jenise;Look, Howard;Arbiter, Brandon;Quirk, Kent;McCanne, Steve;Sun, Yao;Blum, Michael;Adi, Saleh",6505497256;55616608200;56731248200;57188841702;57188839042;57188842826;36461796900;15622763100;56989165600,"University of California, San Francisco",United States,"objective: develop a device-agnostic cloud platform to host diabetes device data and catalyze an ecosystem of software innovation for type 1 diabetes (t1d) management. materials and methods an interdisciplinary team decided to establish a nonprofit company, tidepool, and build open-source software. results: through a user-centered design process, the authors created a software platform, the tidepool platform, to upload and host t1d device data in an integrated, device-agnostic fashion, as well as an application (""app""), blip, to visualize the data. tidepool's software utilizes the principles of modular components, modern web design including rest apis and javascript, cloud computing, agile development methodology, and robust privacy and security. discussion: by consolidating the currently scattered and siloed t1d device data ecosystem into one open platform, tidepool can improve access to the data and enable new possibilities and efficiencies in t1d clinical care and research. the tidepool platform decouples diabetes apps from diabetes devices, allowing software developers to build innovative apps without requiring them to design a unique back-end (e.g., database and security) or unique ways of ingesting device data. it allows people with t1d to choose to use any preferred app regardless of which device(s) they use. conclusion: the authors believe that the tidepool platform can solve two current problems in the t1d device landscape: 1) limited access to t1d device data and 2) poor interoperability of data from different devices. if proven effective, tidepool's open source, cloud model for health data interoperability is applicable to other healthcare use cases.",a case study in open source innovation: developing the tidepool platform for interoperability in type 1 diabetes management
1345,2-s2.0-84963553749,10.7544/issn1000-1239.2016.20148325,A graph database based method for parsing and searching code structure,Lin Z.,Jisuanji Yanjiu yu Fazhan/Computer Research and Development,2016-03-01,"Software reuse is a solution to reduce duplication of effort in software development. When reusing an existing software project, software developers usually need to understand how code elements in it are worked and their correlation, which is called code structure. Software developers usually navigate among source code files to understand code structure. This task could be time-consuming and difficult, since source code of a software project is usually large and complex. Therefore, it is essential to demonstrate code structure in an automatic way that software developers can understand it clearly. For this purpose, this paper introduces a graph database based method for parsing and searching code structure. Code structure is extracted from source code files, and well-organized as a labeled and directed graph in graph database. Software developers input natural language queries. A search mechanism analyzes each of these queries, searches the whole code structure and determines which part of the code structure should be demonstrated. This method is of high extensibility: code elements at different granularity and various relationship types among them can be easily stored into the graph database, and analyzing algorithms for different search purposes can be easily integrated into the search mechanism. A tool is implemented based on this method. Experiment shows that with the help of this tool, the time software developers spending on understanding code structure reduces by 17%, which validates that our method does help improving the efficiency of software reuse. An industrial case study has been showed on how software developers get help from this method.",Code structure | Graph database | Natural language query | Search mechanism | Software reuse,4,531-540,Journal,Article,3.0,"Lin, Zeqi;Zhao, Junfeng;Xie, Bing",56683474100;36618431600;7201872787,"Key Lab of High Confidence Software Technologies, Ministry of Education;Peking University",China;China,"software reuse is a solution to reduce duplication of effort in software development. when reusing an existing software project, software developers usually need to understand how code elements in it are worked and their correlation, which is called code structure. software developers usually navigate among source code files to understand code structure. this task could be time-consuming and difficult, since source code of a software project is usually large and complex. therefore, it is essential to demonstrate code structure in an automatic way that software developers can understand it clearly. for this purpose, this paper introduces a graph database based method for parsing and searching code structure. code structure is extracted from source code files, and well-organized as a labeled and directed graph in graph database. software developers input natural language queries. a search mechanism analyzes each of these queries, searches the whole code structure and determines which part of the code structure should be demonstrated. this method is of high extensibility: code elements at different granularity and various relationship types among them can be easily stored into the graph database, and analyzing algorithms for different search purposes can be easily integrated into the search mechanism. a tool is implemented based on this method. experiment shows that with the help of this tool, the time software developers spending on understanding code structure reduces by 17%, which validates that our method does help improving the efficiency of software reuse. an industrial case study has been showed on how software developers get help from this method.",a graph database based method for parsing and searching code structure
1347,2-s2.0-84959421146,10.17713/ajs.v45i1.100,The software environment R for official statistics and survey methodology,Templ M.,Austrian Journal of Statistics,2016-03-01,"The open-source programming language and software environment R is currently one of the most widely used and popular software tools for statistics and data analysis. This contribution provides an overview of important R packages used in official statistics and survey methodology and discusses the usefulness of R in the daily work of a statistical office. Examples of activities and developments in R related projects in several national and international statistical offices are given. The focus is not only on the internal infrastructure that national and international statistical offices provide for using R but also on some interesting R related projects carried out in those institutes. Two particular packages (laeken and sdcMicro) and one data set (Statistics on Earnings Survey) are used to illustrate the usefulness (and the user-friendliness) of R and to present methods available in R. In addition, the access to international statistical databases like WDI of World Bank and UN COMTRADE with R is illustrated.",Official statistics | Survey methodology R,0,97-124,Journal,Article,2.0,"Templ, Matthias;Todorov, Valentin",24167201600;57217774377,United Nations Industrial Development Organization;Technische Universität Wien,Austria;Austria,"the open-source programming language and software environment r is currently one of the most widely used and popular software tools for statistics and data analysis. this contribution provides an overview of important r packages used in official statistics and survey methodology and discusses the usefulness of r in the daily work of a statistical office. examples of activities and developments in r related projects in several national and international statistical offices are given. the focus is not only on the internal infrastructure that national and international statistical offices provide for using r but also on some interesting r related projects carried out in those institutes. two particular packages (laeken and sdcmicro) and one data set (statistics on earnings survey) are used to illustrate the usefulness (and the user-friendliness) of r and to present methods available in r. in addition, the access to international statistical databases like wdi of world bank and un comtrade with r is illustrated.",the software environment r for official statistics and survey methodology
1348,2-s2.0-84959117549,10.1007/s10209-014-0373-0,Accessible user interface support for multi-device ubiquitous applications: architectural modifiability considerations,Desruelle H.,Universal Access in the Information Society,2016-03-01,"The market for personal computing devices is rapidly expanding from PC, to mobile, home entertainment systems, and even the automotive industry. When developing software targeting such ubiquitous devices, the balance between development costs and market coverage has turned out to be a challenging issue. With the rise of Web technology and the Internet of things, ubiquitous applications have become a reality. Nonetheless, the diversity of presentation and interaction modalities still drastically limit the number of targetable devices and the accessibility toward end users. This paper presents webinos, a multi-device application middleware platform founded on the Future Internet infrastructure. Hereto, the platform’s architectural modifiability considerations are described and evaluated as a generic enabler for supporting applications, which are executed in ubiquitous computing environments.",Dynamic adaptation | Model-driven user interfaces | Multi-device applications | Ubiquitous web,10,5-19,Journal,Article,5.0,"Desruelle, Heiko;Isenberg, Simon;Botsikas, Andreas;Vergori, Paolo;Gielen, Frank",42861318800;55515951900;55576297500;55619106900;8846417100,Istituto Superiore Mario Boella;Universiteit Gent;Bavarian Motor Works AG;National Technical University of Athens,Italy;Belgium;Germany;Greece,"the market for personal computing devices is rapidly expanding from pc, to mobile, home entertainment systems, and even the automotive industry. when developing software targeting such ubiquitous devices, the balance between development costs and market coverage has turned out to be a challenging issue. with the rise of web technology and the internet of things, ubiquitous applications have become a reality. nonetheless, the diversity of presentation and interaction modalities still drastically limit the number of targetable devices and the accessibility toward end users. this paper presents webinos, a multi-device application middleware platform founded on the future internet infrastructure. hereto, the platform’s architectural modifiability considerations are described and evaluated as a generic enabler for supporting applications, which are executed in ubiquitous computing environments.",accessible user interface support for multi-device ubiquitous applications: architectural modifiability considerations
1349,2-s2.0-84958914825,10.1002/stvr.1579,A lightweight framework for dynamic GUI data verification based on scripts,Mateo Navarro P.L.,Software Testing Verification and Reliability,2016-03-01,"Runtime verification (RV) provides essential mechanisms to enhance software robustness and prevent malfunction. However, RV often entails complex and formal processes that could be avoided in scenarios in which only invariants or simple safety properties are verified, for example, when verifying input data in Graphical User Interfaces (GUIs). This paper describes S-DAVER, a lightweight framework aimed at supporting separate data verification in GUIs. All the verification processes are encapsulated in an independent layer and then transparently integrated into an application. The verification rules are specified in separate files and written in interpreted languages to be changed/reloaded at runtime without recompilation. Superimposed visual feedback is used to assist developers during the testing stage and to improve the experience of users during execution. S-DAVER provides a lightweight, easy-to-integrate and dynamic verification framework for GUI data. It is an integral part of the development, testing and execution stages. An implementation of S-DAVER was successfully integrated into existing open-source applications, with promising results.",aspect-oriented | data verification | graphical user interfaces | requirements engineering | runtime verification | scripting languages,5,95-118,Journal,Article,3.0,"Mateo Navarro, Pedro Luis;Ruiz, Diego Sevilla;Pérez, Gregorio Martínez",56320523300;56320342800;7203067256,Universidad de Murcia,Spain,"runtime verification (rv) provides essential mechanisms to enhance software robustness and prevent malfunction. however, rv often entails complex and formal processes that could be avoided in scenarios in which only invariants or simple safety properties are verified, for example, when verifying input data in graphical user interfaces (guis). this paper describes s-daver, a lightweight framework aimed at supporting separate data verification in guis. all the verification processes are encapsulated in an independent layer and then transparently integrated into an application. the verification rules are specified in separate files and written in interpreted languages to be changed/reloaded at runtime without recompilation. superimposed visual feedback is used to assist developers during the testing stage and to improve the experience of users during execution. s-daver provides a lightweight, easy-to-integrate and dynamic verification framework for gui data. it is an integral part of the development, testing and execution stages. an implementation of s-daver was successfully integrated into existing open-source applications, with promising results.",a lightweight framework for dynamic gui data verification based on scripts
1351,2-s2.0-84964344944,10.1109/CloudCom.2015.29,Security and privacy in cloud computing via obfuscation and diversification: A survey,Hosseinzadeh S.,"Proceedings - IEEE 7th International Conference on Cloud Computing Technology and Science, CloudCom 2015",2016-02-01,"The development of cloud computing has facilitate the organizations with its services. This makes the security and privacy of the cloud even more significant. Diversification and obfuscation approaches are of the most promising proactive techniques that protect computers from harmful malware, by preventing them to take advantage of the security vulnerabilities. There is a large body of research on the use of diversification and obfuscation techniques for improving the security in various domains, including cloud computing. Cloud computing provides an excellent setting for applying diversification/obfuscation, as the computing platforms (virtual machines) are implemented in software. The main objective of this study is to determine in what ways obfuscation and diversification techniques are used to enhance the security and privacy of the cloud computing, and discover the potential avenues for the further research. To achieve this goal, we systematically review and report the papers that discuss/propose a technique to enhance the security and privacy of the cloud, using diversification and obfuscation techniques. As the result of the search we collected 43 papers published on the topic. In this report we present the process of data collection, analysis of the results, and classification of the related studies. The classification is done based on how the diversification/obfuscation techniques are used to enhance the security in cloud computing environment. The presented study gives a clear view of the state of the art of the existing works in the field, and sheds light on the areas remained intact which could be avenues for further research. The existing works cover surprisingly a small set of the wealth of opportunities for diversification/obfuscation.",Cloud computing | Diversification | Obfuscation | Privacy | Security | Systematic literature review,15,529-535,Conference Proceeding,Conference Paper,4.0,"Hosseinzadeh, Shohreh;Hyrynsalmi, Sami;Conti, Mauro;Leppänen, Ville",56715442300;50361307000;15019127200;23397050500,Turun yliopisto;Università degli Studi di Padova,Finland;Italy,"the development of cloud computing has facilitate the organizations with its services. this makes the security and privacy of the cloud even more significant. diversification and obfuscation approaches are of the most promising proactive techniques that protect computers from harmful malware, by preventing them to take advantage of the security vulnerabilities. there is a large body of research on the use of diversification and obfuscation techniques for improving the security in various domains, including cloud computing. cloud computing provides an excellent setting for applying diversification/obfuscation, as the computing platforms (virtual machines) are implemented in software. the main objective of this study is to determine in what ways obfuscation and diversification techniques are used to enhance the security and privacy of the cloud computing, and discover the potential avenues for the further research. to achieve this goal, we systematically review and report the papers that discuss/propose a technique to enhance the security and privacy of the cloud, using diversification and obfuscation techniques. as the result of the search we collected 43 papers published on the topic. in this report we present the process of data collection, analysis of the results, and classification of the related studies. the classification is done based on how the diversification/obfuscation techniques are used to enhance the security in cloud computing environment. the presented study gives a clear view of the state of the art of the existing works in the field, and sheds light on the areas remained intact which could be avenues for further research. the existing works cover surprisingly a small set of the wealth of opportunities for diversification/obfuscation.",security and privacy in cloud computing via obfuscation and diversification: a survey
1352,2-s2.0-84958750307,10.15446/dyna.v83n195.49828,Design of an open source-based control platform for an underwater remotely operated vehicle,Aristizábal L.M.,DYNA (Colombia),2016-02-01,"This paper reports on the design of an open source-based control platform for the underwater remotely operated vehicle (ROV) Visor3. The vehicle’s original closed source-based control platform is first described. Due to the limitations of the previous infrastructure, modularity and flexibility are identified as the main guidelines for the proposed design. This new design includes hardware, firmware, software, and control architectures. Open-source hardware and software platforms are used for the development of the new system’s architecture, with support from the literature and the extensive experience acquired with the development of robotic exploration systems. This modular approach results in several frameworks that facilitate the functional expansion of the whole solution, the simplification of fault diagnosis and repair processes, and the reduction of development time, to mention a few.",Open-source hardware | ROV control platforms | Underwater exploration,17,198-205,Journal,Article,7.0,"Aristizábal, Luis M.;Rúa, Santiago;Gaviria, Carlos E.;Osorio, Sandra P.;Zuluaga, Carlos A.;Posada, Norha L.;Vásquez, Rafael E.",57130784200;55513769700;57130747200;57130430900;55513597700;55513237900;16040913400,Universidad Pontificia Bolivariana,Colombia,"this paper reports on the design of an open source-based control platform for the underwater remotely operated vehicle (rov) visor3. the vehicle’s original closed source-based control platform is first described. due to the limitations of the previous infrastructure, modularity and flexibility are identified as the main guidelines for the proposed design. this new design includes hardware, firmware, software, and control architectures. open-source hardware and software platforms are used for the development of the new system’s architecture, with support from the literature and the extensive experience acquired with the development of robotic exploration systems. this modular approach results in several frameworks that facilitate the functional expansion of the whole solution, the simplification of fault diagnosis and repair processes, and the reduction of development time, to mention a few.",design of an open source-based control platform for an underwater remotely operated vehicle
1353,2-s2.0-84954025940,10.1002/spe.2301,Performance-driven instrumentation and mapping strategies using the LARA aspect-oriented programming approach,Cardoso J.M.P.,Software - Practice and Experience,2016-02-01,"Summary The development of applications for high-performance embedded systems is a long and error-prone process because in addition to the required functionality, developers must consider various and often conflicting nonfunctional requirements such as performance and/or energy efficiency. The complexity of this process is further exacerbated by the multitude of target architectures and mapping tools. This article describes LARA, an aspect-oriented programming language that allows programmers to convey domain-specific knowledge and nonfunctional requirements to a toolchain composed of source-to-source transformers, compiler optimizers, and mapping/synthesis tools. LARA is sufficiently flexible to target different tools and host languages while also allowing the specification of compilation strategies to enable efficient generation of software code and hardware cores (using hardware description languages) for hybrid target architectures - a unique feature to the best of our knowledge not found in any other aspect-oriented programming language. A key feature of LARA is its ability to deal with different models of join points, actions, and attributes. In this article, we describe the LARA approach and evaluate its impact on code instrumentation and analysis and on selecting critical code sections to be migrated to hardware accelerators for two embedded applications from industry.",aspect-oriented programming | compilers | domain-specific languages | embedded systems | hardware/software systems | instrumenting and profiling | monitoring,16,251-287,Journal,Article,7.0,"Cardoso, João M.P.;Coutinho, José G.F.;Carvalho, Tiago;Diniz, Pedro C.;Petrov, Zlatko;Luk, Wayne;Gonçalves, Fernando",9639597300;35605674200;55411559500;57208344648;10539455800;26029526200;7006464548,Honeywell International Inc.;Information Sciences Institute;Imperial College London;Universidade do Porto;Coreworks S.A.,United States;United States;United Kingdom;Portugal;Portugal,"summary the development of applications for high-performance embedded systems is a long and error-prone process because in addition to the required functionality, developers must consider various and often conflicting nonfunctional requirements such as performance and/or energy efficiency. the complexity of this process is further exacerbated by the multitude of target architectures and mapping tools. this article describes lara, an aspect-oriented programming language that allows programmers to convey domain-specific knowledge and nonfunctional requirements to a toolchain composed of source-to-source transformers, compiler optimizers, and mapping/synthesis tools. lara is sufficiently flexible to target different tools and host languages while also allowing the specification of compilation strategies to enable efficient generation of software code and hardware cores (using hardware description languages) for hybrid target architectures - a unique feature to the best of our knowledge not found in any other aspect-oriented programming language. a key feature of lara is its ability to deal with different models of join points, actions, and attributes. in this article, we describe the lara approach and evaluate its impact on code instrumentation and analysis and on selecting critical code sections to be migrated to hardware accelerators for two embedded applications from industry.",performance-driven instrumentation and mapping strategies using the lara aspect-oriented programming approach
1354,2-s2.0-84974623535,10.1109/ISSREW.2015.7392042,A scalable and accurate hybrid vulnerability analysis framework,Thome J.,"2015 IEEE International Symposium on Software Reliability Engineering Workshops, ISSREW 2015",2016-01-25,"Software security assurance is an important process in software development that protects the sensitive data and resources contained in and controlled by the software. Addressing security vulnerabilities at an early phase could decrease the cost of addressing them in later stages by two orders of magnitude. In order to detect vulnerabilities in Web services and Web applications in a scalable and accurate manner, we aim at developing a hybrid vulnerability analysis framework which combines program analysis, symbolic execution and machine learning. We use program analysis to identify potential vulnerable execution branches within the source code for the purpose of guiding the symbolic execution along the potentially vulnerable execution paths. We also propose scalable constraint solving techniques for vulnerability analysis. To further enhance scalability and accuracy, we also apply machine learning by incorporating predictors for identifying potentially vulnerable paths of the program based on known vulnerable cases.",Constraint Solving | Machine Learning | Program Analysis | Software Security Assurance | Symbolic Execution | Vulnerability Analysis,2,61-62,Conference Proceeding,Conference Paper,1.0,"Thome, Julian",56875233700,University of Luxembourg,Luxembourg,"software security assurance is an important process in software development that protects the sensitive data and resources contained in and controlled by the software. addressing security vulnerabilities at an early phase could decrease the cost of addressing them in later stages by two orders of magnitude. in order to detect vulnerabilities in web services and web applications in a scalable and accurate manner, we aim at developing a hybrid vulnerability analysis framework which combines program analysis, symbolic execution and machine learning. we use program analysis to identify potential vulnerable execution branches within the source code for the purpose of guiding the symbolic execution along the potentially vulnerable execution paths. we also propose scalable constraint solving techniques for vulnerability analysis. to further enhance scalability and accuracy, we also apply machine learning by incorporating predictors for identifying potentially vulnerable paths of the program based on known vulnerable cases.",a scalable and accurate hybrid vulnerability analysis framework
1355,2-s2.0-84966569773,10.1109/CogInfoCom.2015.7390636,Development of an online subjective evaluation system for recorded speech of deaf and hard of hearing children,Varga A.,"6th IEEE Conference on Cognitive Infocommunications, CogInfoCom 2015 - Proceedings",2016-01-25,"The aim of this paper is to present a web-based evaluation system developed as part of a research has been carried out in cooperation with University of Debrecen and University of Miskolc in the framework of the project TÁMOP-4.2.2.C-11/1/KONV (Social Renewal Operational Programme) called 'Basic and Applied Research for Internet-based Speech Development of Deaf and Hard of Hearing People and for Objective Measurement of Their Progress'. The project is aimed at solving basic and applied research tasks to develop an application to support the speech teaching and understanding of deaf and hearing-impaired people more effectively than known methods. The idea of the project has come from an audio-visual transcoder for sound visualization developed at the University of Debrecen, and a three-dimensional head model for articulation presentation, called 'talking head' developed at the University of Miskolc. The most important aim of the project is to create a complex system to provide audio-visual speech recognition by visualization of images of speech and articulation, setting up an educational framework. In addition, the system has many other features (prosody display, automatic evaluation and knowledge-based systems implementation), which subsequently allow individual practice not only on computers but also on mobile devices. However, it is important to note that personal contribution of surdo-pedagogues can not be replaced, but can greatly support. The module performing the required audio-visual transcoding is language-independent, the talking head, moreover automatic qualification can be made language-independent by training new neural networks. For development of automatic qualification, the recorded speech samples has been required to be evaluated by surdo-pedagogues and lay students. The online evaluation system developed for this purpose is shown in this paper.",audio-visual | hard of hearing and deaf people | Mysql | online evaluation system | PhP | recorded speech samples | refernce speech database | web-based software development,7,455-458,Conference Proceeding,Conference Paper,2.0,"Varga, Attila K.;Czap, Laszlo",56525428000;55860800108,Miskolci Egyetem,Hungary,"the aim of this paper is to present a web-based evaluation system developed as part of a research has been carried out in cooperation with university of debrecen and university of miskolc in the framework of the project támop-4.2.2.c-11/1/konv (social renewal operational programme) called 'basic and applied research for internet-based speech development of deaf and hard of hearing people and for objective measurement of their progress'. the project is aimed at solving basic and applied research tasks to develop an application to support the speech teaching and understanding of deaf and hearing-impaired people more effectively than known methods. the idea of the project has come from an audio-visual transcoder for sound visualization developed at the university of debrecen, and a three-dimensional head model for articulation presentation, called 'talking head' developed at the university of miskolc. the most important aim of the project is to create a complex system to provide audio-visual speech recognition by visualization of images of speech and articulation, setting up an educational framework. in addition, the system has many other features (prosody display, automatic evaluation and knowledge-based systems implementation), which subsequently allow individual practice not only on computers but also on mobile devices. however, it is important to note that personal contribution of surdo-pedagogues can not be replaced, but can greatly support. the module performing the required audio-visual transcoding is language-independent, the talking head, moreover automatic qualification can be made language-independent by training new neural networks. for development of automatic qualification, the recorded speech samples has been required to be evaluated by surdo-pedagogues and lay students. the online evaluation system developed for this purpose is shown in this paper.",development of an online subjective evaluation system for recorded speech of deaf and hard of hearing children
1357,2-s2.0-84963831195,10.1109/APWiMob.2015.7374933,A too-dang check-in system for Thai police using mobile location-based service,Jakkhupan W.,APWiMob 2015 - IEEE Asia Pacific Conference on Wireless and Mobile,2016-01-07,"Mobile devices, such as smartphone or tablet, have become an important part of human life. The location-based service, the service that identify the location of a mobile device, has become an important feature included in location-aware applications. Too-Dang, a red metal square box, is installed in specific locations in the city, which the patrolling policemen are randomly come to visit and check the circumstances of the places. With the capability of mobile location-based service, this research proposes a Too-Dang check-in system aims to facilitate and improve the operation of the patrolling policeman. Too-Dang management system is used by the central police officers to manage the location of Too-Dangs, and to monitor the operation of the patrolling policeman. The prototype of Too-Dang application was developed using HTML5 hybrid-platform application development concept, which compatible with various mobile operating systems. Too-Dang application installed in the smart devices facilitates the patrolling policeman for the better operation such as route to the nearest Too-Dang, and record the data via the application. Finally, the collected data, integrated with the criminal recording data, will be analyzed and visualized in multi-aspect reports such as mapping, which reveals the relations between Too-Dang and the crime distribution.",Mapping Data Visualization | Mobile Location-based Service | Mobile Mapping | Thai Too-Dang,1,78-82,Conference Proceeding,Conference Paper,3.0,"Jakkhupan, Worapot;Usman, Tassanee;Kaocha-Oom, Omboon",37014453900;57188848263;57188854224,Prince of Songkla University,Thailand,"mobile devices, such as smartphone or tablet, have become an important part of human life. the location-based service, the service that identify the location of a mobile device, has become an important feature included in location-aware applications. too-dang, a red metal square box, is installed in specific locations in the city, which the patrolling policemen are randomly come to visit and check the circumstances of the places. with the capability of mobile location-based service, this research proposes a too-dang check-in system aims to facilitate and improve the operation of the patrolling policeman. too-dang management system is used by the central police officers to manage the location of too-dangs, and to monitor the operation of the patrolling policeman. the prototype of too-dang application was developed using html5 hybrid-platform application development concept, which compatible with various mobile operating systems. too-dang application installed in the smart devices facilitates the patrolling policeman for the better operation such as route to the nearest too-dang, and record the data via the application. finally, the collected data, integrated with the criminal recording data, will be analyzed and visualized in multi-aspect reports such as mapping, which reveals the relations between too-dang and the crime distribution.",a too-dang check-in system for thai police using mobile location-based service
1362,2-s2.0-85019218567,10.1109/PST.2016.7906994,Data leakage detection in Tizen Web applications,Rocha T.,"2016 14th Annual Conference on Privacy, Security and Trust, PST 2016",2016-01-01,"The explosive growth in Internet of Things (IoT) devices like smartphones, tablets, smart TVs, and smartwatches has brought new challenges for software developers. Currently a single app can be created and executed on multiple target platforms. In this scenario, different programming languages such as HTML5 and JavaScript, and operational systems like Tizen and webOS promises easy multi-platform development. However, one of the biggest concerns from companies that develop applications to these IoT devices is the leakage or exposure of sensitive data. In this work we are addressing this problem by creating a modified version of Tizen, called TTizen, that modifies the Tizen Web Runtime to add dynamic taint tracking, with that we can track sensitive information that is being leaked, even if the information is obfuscated, and warn the users. From our knowledge this is the first prototype that adds this kind of technique to Tizen and tracks web applications in mobile devices. The results show that TTizen is a promising approach that can be improved and used to detect data leakage in IoT devices.",Data Leakage | JavaScript | Tizen,1,608-614,Conference Proceeding,Conference Paper,8.0,"Rocha, Thiago;Souto, Eduardo;Cassio, Brandell;Azulay, Diego;Monteiro, Alex;Boeira, Felipe;Minatel, Pedro;Silva, Breno",56419567100;56234247400;57194207283;57194204580;57194216726;57194206262;57194217119;57194213496,Universidade Federal do Amazonas;Samsung Research Institute Brazil,Brazil;Brazil,"the explosive growth in internet of things (iot) devices like smartphones, tablets, smart tvs, and smartwatches has brought new challenges for software developers. currently a single app can be created and executed on multiple target platforms. in this scenario, different programming languages such as html5 and javascript, and operational systems like tizen and webos promises easy multi-platform development. however, one of the biggest concerns from companies that develop applications to these iot devices is the leakage or exposure of sensitive data. in this work we are addressing this problem by creating a modified version of tizen, called ttizen, that modifies the tizen web runtime to add dynamic taint tracking, with that we can track sensitive information that is being leaked, even if the information is obfuscated, and warn the users. from our knowledge this is the first prototype that adds this kind of technique to tizen and tracks web applications in mobile devices. the results show that ttizen is a promising approach that can be improved and used to detect data leakage in iot devices.",data leakage detection in tizen web applications
1363,2-s2.0-85011394794,10.4408/IJEGE.2016-01.O-03,Extreme gis applications For 3D visualization aimed to geological and mining modeling,Giuliani A.,Italian Journal of Engineering Geology and Environment,2016-01-01,"Geological investigations aimed at mining prospecting are based on geological maps, field surveys and on underground data (geophysical survey, boreholes and/or mining tunnels). In mining activity (both raw material and energy supplies), it is important to define geologic features, such as geometries, volumes, mineral contents but also surface and subsurface evolution due to excavation and other mining facilities, such as tunnels, plants and other buildings and roads. There are many commercial software able to represent such features in 2D, but a few very expensive products able to show all these characteristics in 3D. Considering the world of free open source or packages at acceptable costs, it is also impossible to find something fitting these needs. The problem is that: i) usually 3D geological models are based on few data if compared with the extension of the study area so available geological data are scattered and a major interpretation is often necessary and 3D visualization allows to help geological interpretation where data are scarce; ii) mining plan are often produced using cad, with very precise dimension and localization of the object and no need of interpretation. These characteristics are on the opposite side of the 3D modeling: the first is the end-member where interpretation is maximized (close to a ""pictorial"" - geometrically correct - representation), the other is the end member where ""a project must be followed"" and subjective interpretation should be minimal. This paper shows how it is possible to use common GIS software to solve these kind of problems, with good results and huge possibility of development.",3D modeling | Engineering geology | GIS | Mine | Quarry,4,31-39,Journal,Article,3.0,"Giuliani, Andrea;Filipello, Andrea;Mandrone, Giuseppe",56284277400;56110120800;14035784600,Università degli Studi di Torino;Spin offcompany of Turin University,Italy;Italy,"geological investigations aimed at mining prospecting are based on geological maps, field surveys and on underground data (geophysical survey, boreholes and/or mining tunnels). in mining activity (both raw material and energy supplies), it is important to define geologic features, such as geometries, volumes, mineral contents but also surface and subsurface evolution due to excavation and other mining facilities, such as tunnels, plants and other buildings and roads. there are many commercial software able to represent such features in 2d, but a few very expensive products able to show all these characteristics in 3d. considering the world of free open source or packages at acceptable costs, it is also impossible to find something fitting these needs. the problem is that: i) usually 3d geological models are based on few data if compared with the extension of the study area so available geological data are scattered and a major interpretation is often necessary and 3d visualization allows to help geological interpretation where data are scarce; ii) mining plan are often produced using cad, with very precise dimension and localization of the object and no need of interpretation. these characteristics are on the opposite side of the 3d modeling: the first is the end-member where interpretation is maximized (close to a ""pictorial"" - geometrically correct - representation), the other is the end member where ""a project must be followed"" and subjective interpretation should be minimal. this paper shows how it is possible to use common gis software to solve these kind of problems, with good results and huge possibility of development.",extreme gis applications for 3d visualization aimed to geological and mining modeling
1368,2-s2.0-85006476454,10.1007/978-3-319-42304-3_17,IoT components for secure smart building environments,Koulamas C.,Components and Services for IoT Platforms: Paving the Way for IoT Standards,2016-01-01,"Internet connectivity of embedded systems and specialized network structures from the industrial and building automation domains has been around for decades. Extensive experience and deep knowledge around the development and installation of complex systems utilizing machine to machine (M2M) communications, wired or wireless, and IP-based or not, have been acquired during all these years of relative technology evolution. While being the latter’s current snapshot, the realization of the Internet/Web of Things (IoT/WoT) vision and its exploitation inside domains of traditionally specialized, silo technologies, lies mainly on the homogenization of the development, installation, and management paradigm towards this of the wider web. As processing, memory, timeliness, energy, security, and cost related requirements may vary depending on the specific function realization and management in an integrated, large scale smart environment such as a building ICT and automation infrastructure, this chapter presents first a comprehensive review of the currently widely used technologies and common practices in the smart buildings domain. Based on this, it then discusses the main points of benefit from the IoT paradigm shift, identifies the elementary components of major importance to the realization of IoT architectures, and provides comparative insights to the complexity and performance of specific implementations developed and exploited in a pilot demonstrator.",Building automation | HW/SW co-design | Interoperability | IoT | M2M | Security,4,335-353,Book,Book Chapter,3.0,"Koulamas, Christos;Giannoulis, Spilios;Fournaris, Apostolos",55793189268;16021590500;6507136552,Industrial Systems Institute,Greece,"internet connectivity of embedded systems and specialized network structures from the industrial and building automation domains has been around for decades. extensive experience and deep knowledge around the development and installation of complex systems utilizing machine to machine (m2m) communications, wired or wireless, and ip-based or not, have been acquired during all these years of relative technology evolution. while being the latter’s current snapshot, the realization of the internet/web of things (iot/wot) vision and its exploitation inside domains of traditionally specialized, silo technologies, lies mainly on the homogenization of the development, installation, and management paradigm towards this of the wider web. as processing, memory, timeliness, energy, security, and cost related requirements may vary depending on the specific function realization and management in an integrated, large scale smart environment such as a building ict and automation infrastructure, this chapter presents first a comprehensive review of the currently widely used technologies and common practices in the smart buildings domain. based on this, it then discusses the main points of benefit from the iot paradigm shift, identifies the elementary components of major importance to the realization of iot architectures, and provides comparative insights to the complexity and performance of specific implementations developed and exploited in a pilot demonstrator.",iot components for secure smart building environments
1370,2-s2.0-85003955462,10.5220/0005967301210132,Transitioning to a Javascript voting client for remote online voting,Cucurull J.,ICETE 2016 - Proceedings of the 13th International Joint Conference on e-Business and Telecommunications,2016-01-01,"Voters in remote electronic voting systems typically cast their votes from their own devices, such as PCs and smartphones. The software executed at their devices in charge of performing the ballot presentation, navigation and most of the cryptographic operations required to protect the integrity and privacy of the ballot, is referred to as the voting client. The first voting clients were developed as Java Applets. However, the use of this technology has become relegated in front of web technologies such as Javascript, which provide a better multi-platform user experience. This is the reason why in 2013 Scytl decided it was imperative to develop a voting client purely based on Javascript. This industrial paper shows the implementation experiences and lessons learned during the development and deployment of Javascript voting clients for our remote electronic voting systems. The paper is complemented with a performance study of 1) the main cryptographic primitives used in voting clients and 2) the voting casting process of one of the voting clients used in a real election.",Implementation | Javascript security | Performance | Random number generation | Remote electronic voting,2,121-132,Conference Proceeding,Conference Paper,3.0,"Cucurull, Jordi;Guasch, Sandra;Galindo, David",35239767400;56407101600;8905772700,"Scytl Secure Electronic Voting, S.A;University of Birmingham",Spain;United Kingdom,"voters in remote electronic voting systems typically cast their votes from their own devices, such as pcs and smartphones. the software executed at their devices in charge of performing the ballot presentation, navigation and most of the cryptographic operations required to protect the integrity and privacy of the ballot, is referred to as the voting client. the first voting clients were developed as java applets. however, the use of this technology has become relegated in front of web technologies such as javascript, which provide a better multi-platform user experience. this is the reason why in 2013 scytl decided it was imperative to develop a voting client purely based on javascript. this industrial paper shows the implementation experiences and lessons learned during the development and deployment of javascript voting clients for our remote electronic voting systems. the paper is complemented with a performance study of 1) the main cryptographic primitives used in voting clients and 2) the voting casting process of one of the voting clients used in a real election.",transitioning to a javascript voting client for remote online voting
1372,2-s2.0-84998979464,10.1007/978-3-319-49094-6_35,Quality rule violations in sharepoint applications: An empirical study in industry,Ampatzoglou A.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2016-01-01,"In this paper, we focus on source code quality assessment for Share‐ Point applications, which is a powerful framework for developing software by combining imperative and declarative programming. In particular, we present an industrial case study conducted in a software consulting/development company in Netherlands, which aimed at: identifying the most common SharePoint quality rule violations and their severity. The results indicate that the most frequent rule violations are identified in the JavaScript part of the applications, and that the most severe ones are related to correctness, security and deployment. The aforementioned results can be exploited by both researchers and practitioners, in terms of future research directions, and to inform the quality assurance process.",Defect prediction | Quality assessment | Sharepoint,0,495-505,Book Series,Conference Paper,5.0,"Ampatzoglou, Apostolos;Avgeriou, Paris;Koenders, Thom;Van Alphen, Pascal;Stamelos, Ioannis",16027681600;17343671200;57192166551;57192158570;6604041235,Aristotle University of Thessaloniki;Capgemini Nederland B.V.;Rijksuniversiteit Groningen,Greece;Netherlands;Netherlands,"in this paper, we focus on source code quality assessment for share‐ point applications, which is a powerful framework for developing software by combining imperative and declarative programming. in particular, we present an industrial case study conducted in a software consulting/development company in netherlands, which aimed at: identifying the most common sharepoint quality rule violations and their severity. the results indicate that the most frequent rule violations are identified in the javascript part of the applications, and that the most severe ones are related to correctness, security and deployment. the aforementioned results can be exploited by both researchers and practitioners, in terms of future research directions, and to inform the quality assurance process.",quality rule violations in sharepoint applications: an empirical study in industry
1373,2-s2.0-84998893207,10.1007/978-3-319-48746-5_48,A sensor-driven framework for rapid prototyping of mobile applications using a context-aware approach,Gamecho B.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2016-01-01,"The development of mobile context-aware applications using sensors require the developers to understand several diverse issues: signal acquisition, network protocols, embedded systems, data filtering, etc. We designed and implemented a software framework in order to assist developers in prototyping. Our framework facilitates the use of sensors from wearable devices and supports the reusability of components following a modular approach. This paper describes the design of our approach and highlights the benefits of the framework for the development of mobile applications. To evaluate the framework, representative context-aware applications are described as a case study. The usability of the applications were tested with 26 participants and good results were obtained.",Context-aware computing | Mobile and wearable computing | Rapid prototyping framework,2,469-480,Book Series,Conference Paper,3.0,"Gamecho, Borja;Gardeazabal, Luis;Abascal, Julio",42961351300;6507421160;14521749900,Universidad del Pais Vasco;Wimbi Technologies S.L. (WimbiTek),Spain;Spain,"the development of mobile context-aware applications using sensors require the developers to understand several diverse issues: signal acquisition, network protocols, embedded systems, data filtering, etc. we designed and implemented a software framework in order to assist developers in prototyping. our framework facilitates the use of sensors from wearable devices and supports the reusability of components following a modular approach. this paper describes the design of our approach and highlights the benefits of the framework for the development of mobile applications. to evaluate the framework, representative context-aware applications are described as a case study. the usability of the applications were tested with 26 participants and good results were obtained.",a sensor-driven framework for rapid prototyping of mobile applications using a context-aware approach
1377,2-s2.0-84994810280,10.1016/j.ifacol.2016.07.169,Communication with resource-constrained devices through MQTT for control education,Prada M.A.,IFAC-PapersOnLine,2016-01-01,"The developments on machine-to-machine systems are interesting for control education, not only for the opportunities to apply control and automation solutions to new problems, but also for the availability of new hardware, software and communication platforms. These technologies facilitate a low-cost and easier integration of physical equipment in educational tools such as the remote laboratories. This paper proposes the use of a lightweight protocol for communication with resource-constrained devices, MQTT, as an aid to integrate new devices in educational applications, specifically in those that use web standards such as Javascript to provide interactive user interfaces. To evaluate this approach, an educational application focused on the control of a DC motor position loop, built with EjsS, was developed. This tool uses the MQTT protocol to parametrize and communicate with an Arduino microcontroller that, in turn, controls a physical setup implemented with the Feedback MS150 modular system. The proposed approach enables the easy connection of interactive educational tools to new real equipment, especially those driven by resource-constrained devices.",Arduino | education | EJsS | MQTT | PID | protocols | remote labs | resource-constrained devices | Virtual,28,150-155,Conference Proceeding,Conference Paper,6.0,"Prada, Miguel A.;Reguera, Perfecto;Alonso, Serafín;Morán, Antonio;Fuertes, Juan J.;Domínguez, Manuel",23397997700;16644088100;36607362400;55595803800;15925163800;57204033757,Universidad de León,Spain,"the developments on machine-to-machine systems are interesting for control education, not only for the opportunities to apply control and automation solutions to new problems, but also for the availability of new hardware, software and communication platforms. these technologies facilitate a low-cost and easier integration of physical equipment in educational tools such as the remote laboratories. this paper proposes the use of a lightweight protocol for communication with resource-constrained devices, mqtt, as an aid to integrate new devices in educational applications, specifically in those that use web standards such as javascript to provide interactive user interfaces. to evaluate this approach, an educational application focused on the control of a dc motor position loop, built with ejss, was developed. this tool uses the mqtt protocol to parametrize and communicate with an arduino microcontroller that, in turn, controls a physical setup implemented with the feedback ms150 modular system. the proposed approach enables the easy connection of interactive educational tools to new real equipment, especially those driven by resource-constrained devices.",communication with resource-constrained devices through mqtt for control education
1378,2-s2.0-84994032256,10.3233/978-1-61499-703-0-798,Development of a web platform for casting process selection,Zimmermann J.,Advances in Transdisciplinary Engineering,2016-01-01,"The choice of the right process for casting components is a complexactivity, and impacts directly on the design and manufacturing of the product. A single failure in the casting process selection can increase design and production time and, in critical cases, result in a collapse of the manufacturing and assembly of components. This process is usually based on guidelines scattered in the literature, or based on the designer's accumulated experience, but this action could be carried out by software containing a casting process database that can be employed during the product development stage, assisting the designer. In this context, our goal is to adapt a method for selection of casting processes previously developed into a web platform to support casting process definition. The adopted selection method uses Quality Function Deployment (QFD) and Design for Manufacturing (DFM) principles to provide a structure to support casting selection decision based on part features and process demand. The proposed software was developed for the Web using HTML and JavaScript, providing better usability than the previous format of the proposed selection method using spreadsheets. For validation, ferrous and nonferrous cast parts were analyzed using the proposed web platform. The results were compared with the selector provided by the American Foundry Society and with processes actually used in the industry. Thus, the results showed a good relationship with the other methods, also providing a quantitative classification (prioritization) of the results. In addition, this software supports the design of the manufacturing process by means of a checklist to adapt the part to the metal casting process presented to the designer.",Casting process | Design for Manufacturing | Process selection | Quality Function Deployment | Web platform,0,798-807,Conference Proceeding,Conference Paper,3.0,"Zimmermann, Juliana Ilha;Scalice, Régis Kovacs;Bond, Danielle",57191830875;55360459900;37123493600,Universidade do Estado de Santa Catarina;Universidade Federal de Santa Catarina,Brazil;Brazil,"the choice of the right process for casting components is a complexactivity, and impacts directly on the design and manufacturing of the product. a single failure in the casting process selection can increase design and production time and, in critical cases, result in a collapse of the manufacturing and assembly of components. this process is usually based on guidelines scattered in the literature, or based on the designer's accumulated experience, but this action could be carried out by software containing a casting process database that can be employed during the product development stage, assisting the designer. in this context, our goal is to adapt a method for selection of casting processes previously developed into a web platform to support casting process definition. the adopted selection method uses quality function deployment (qfd) and design for manufacturing (dfm) principles to provide a structure to support casting selection decision based on part features and process demand. the proposed software was developed for the web using html and javascript, providing better usability than the previous format of the proposed selection method using spreadsheets. for validation, ferrous and nonferrous cast parts were analyzed using the proposed web platform. the results were compared with the selector provided by the american foundry society and with processes actually used in the industry. thus, the results showed a good relationship with the other methods, also providing a quantitative classification (prioritization) of the results. in addition, this software supports the design of the manufacturing process by means of a checklist to adapt the part to the metal casting process presented to the designer.",development of a web platform for casting process selection
1379,2-s2.0-84992699741,10.1007/978-3-319-46963-8_13,Attributelinking: Exploiting attributes for inter-component communication,Krug M.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2016-01-01,"In this paper, we propose exploiting attributes of client-side web components to provide inter-component communication by external configuration. With the standardization of WebComponents, the Web is finally getting a uniform way to define and use client-side components. We determined that DOM elements already provide a standard configuration interface: attributes. Using the WebComponents technologies for state-of-the-art user-interface components, attributes can also act as output interfaces. By providing an Attribute-Link component, new web applications can be composed directly in the markup without knowledge of JavaScript. With the integration of a multi-device supporting Messaging- Service, components can be even linked across multiple connected devices. This enables the development of distributed user interfaces.",Composition | Distributed user interfaces | Reusable components | Web application development | Web components,0,157-161,Book Series,Conference Paper,2.0,"Krug, Michael;Gaedke, Martin",56016745900;8905803700,Technische Universität Chemnitz,Germany,"in this paper, we propose exploiting attributes of client-side web components to provide inter-component communication by external configuration. with the standardization of webcomponents, the web is finally getting a uniform way to define and use client-side components. we determined that dom elements already provide a standard configuration interface: attributes. using the webcomponents technologies for state-of-the-art user-interface components, attributes can also act as output interfaces. by providing an attribute-link component, new web applications can be composed directly in the markup without knowledge of javascript. with the integration of a multi-device supporting messaging- service, components can be even linked across multiple connected devices. this enables the development of distributed user interfaces.",attributelinking: exploiting attributes for inter-component communication
1380,2-s2.0-84992692459,10.1007/978-3-319-46963-8_12,Synchronizing application state using virtual DOM trees,Voutilainen J.P.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2016-01-01,"We will all soon have numerous computing devices we use every day interchangeably. Liquid software, a concept where software is allowed to flow from one computer to another, is a programming framework that aims at simplifying the development and use of such multi-device software. The existing research has discovered three major architecture challenges for liquid software: (1) adaptation of the user interface to different devices, (2) availability of the relevant data in all devices, and (3) transfer of the application state. This paper addresses the last challenge and differs from the earlier work by concentrating in application state that is in the DOM tree, a key element in today’s Web applications.",Experience roaming | Liquid software | Multi-device ownership | Web programming,9,142-154,Book Series,Conference Paper,3.0,"Voutilainen, Jari Pekka;Mikkonen, Tommi;Systä, Kari",56023247600;57220096141;6506558673,Tampere University;Gofore Ltd.,Finland;Finland,"we will all soon have numerous computing devices we use every day interchangeably. liquid software, a concept where software is allowed to flow from one computer to another, is a programming framework that aims at simplifying the development and use of such multi-device software. the existing research has discovered three major architecture challenges for liquid software: (1) adaptation of the user interface to different devices, (2) availability of the relevant data in all devices, and (3) transfer of the application state. this paper addresses the last challenge and differs from the earlier work by concentrating in application state that is in the dom tree, a key element in today’s web applications.",synchronizing application state using virtual dom trees
1381,2-s2.0-84992563897,10.1016/j.procir.2016.07.073,Development of a Web Based Monitoring System for a Distributed and Modern Production,Stangl M.,Procedia CIRP,2016-01-01,"Web technologies have experienced a rapid development in recent years. In particular web browsers enhanced their abilities because of the improvement of JavaScript, CSS3 and HTML5. Hence, richer web-based software solutions with an increasing range of functions are available. By using responsive web design (RWD), a technology to display content without resizing on different screens, developers are able to support a diverse range of devices with small effort. In order to enable a monitoring of the current status of a production system, signals of many different sensors, machine and production data are required. Combining microcontrollers with sensors to embedded sensors enables an efficient way to communicate with web services. Due to the strong decline of prices for semiconductor technologies, companies are able to set up production machines with these technologies at low costs. This paper presents a way to set up a distributed manufacturing control system by using common web technologies like RWD and embedded systems. We discuss advantages and drawbacks of web-based software solutions and show a methodical approach for the use in a modern production system. Finally, the functionality of the method is proven within an application example.",Cyper Physical Systems | Manufacturing | Monitoring | Open architecture,6,222-227,Conference Proceeding,Conference Paper,5.0,"Stangl, Michael;Pielmeier, Julia;Berger, Christoph;Braunreuther, Stefan;Reinhart, Gunther",57217724455;57190976216;57189304350;36138577300;7101858932,Technical University of Munich;Fraunhofer Institute for Machine Tools and Forming Technology IWU,Germany;Germany,"web technologies have experienced a rapid development in recent years. in particular web browsers enhanced their abilities because of the improvement of javascript, css3 and html5. hence, richer web-based software solutions with an increasing range of functions are available. by using responsive web design (rwd), a technology to display content without resizing on different screens, developers are able to support a diverse range of devices with small effort. in order to enable a monitoring of the current status of a production system, signals of many different sensors, machine and production data are required. combining microcontrollers with sensors to embedded sensors enables an efficient way to communicate with web services. due to the strong decline of prices for semiconductor technologies, companies are able to set up production machines with these technologies at low costs. this paper presents a way to set up a distributed manufacturing control system by using common web technologies like rwd and embedded systems. we discuss advantages and drawbacks of web-based software solutions and show a methodical approach for the use in a modern production system. finally, the functionality of the method is proven within an application example.",development of a web based monitoring system for a distributed and modern production
1382,2-s2.0-84992410460,10.1016/j.procs.2016.09.017,A Review of Latest Web Tools and Libraries for State-of-the-art Visualization,Shahzad F.,Procedia Computer Science,2016-01-01,"Most of the existing visualization and simulation applications run on the client machine and require an installation process. Browser based interactive visualizer for scientific and medical applications remain an unheard concept despite all advancements in computer and software technology and it remains a fairly difficult process to quickly prototype a visualization on a PC or a smart device. In this paper, we review and employed state-of-the-art web technologies, third-party libraries and frameworks to compare and develop some interactive browser-based, mobile friendly web applications. These latest web technologies have the potential to fulfill the promise of interactive browser based custom visualization applications. We presented and compared some of the latest web based tools available today. We also introduced couple of lightweight and interactive web based visualizer and simulator tools which are under development.",Browser-based Visualization | JavaScript | Simulation | Web based Application,13,100-106,Conference Proceeding,Conference Paper,4.0,"Shahzad, Farrukh;Sheltami, Tarek R.;Shakshuki, Elhadi M.;Shaikh, Omar",55887105100;15077342500;6603932000;57191668209,Acadia University;King Fahd University of Petroleum and Minerals;Dhahran High School;Visonics,Canada;Saudi Arabia;Saudi Arabia;United States,"most of the existing visualization and simulation applications run on the client machine and require an installation process. browser based interactive visualizer for scientific and medical applications remain an unheard concept despite all advancements in computer and software technology and it remains a fairly difficult process to quickly prototype a visualization on a pc or a smart device. in this paper, we review and employed state-of-the-art web technologies, third-party libraries and frameworks to compare and develop some interactive browser-based, mobile friendly web applications. these latest web technologies have the potential to fulfill the promise of interactive browser based custom visualization applications. we presented and compared some of the latest web based tools available today. we also introduced couple of lightweight and interactive web based visualizer and simulator tools which are under development.",a review of latest web tools and libraries for state-of-the-art visualization
1384,2-s2.0-84990064449,10.3991/ijoe.v12i09.6090,Assisted creation and deployment of javascript remote experiments,de la Torre L.,International Journal of Online Engineering,2016-01-01,"In order to disseminate and encourage the use of remote experiments, their creation and deployment need to be simplified. This work presents a method to easily develop remote experiments interfaces in Javascript and to quickly embed them in Moodle. This solution requires the use of Easy Java/Javascript Simulations for the development of the interfaces and the EJSApp Moodle plugin to deploy them in the web platform. The proven flexibility of such solution has fostered the integration of two new experiments and also the easy adaptation of an already existing one, opening new remote labs flexibility to educational and/or training activities.",Embedded | Online experiment | Remote experiment | Remote laboratory | User interface edition,2,22-25,Journal,Article,5.0,"de la Torre, Luis;Andrade, Tiago Faustino;Sousa, Pedro;Sánchez, José;Restivo, Maria Teresa",36342298100;42761046000;57189647067;7403998826;7004694449,Universidad Nacional de Educacion a Distancia;Universidade do Porto,Spain;Portugal,"in order to disseminate and encourage the use of remote experiments, their creation and deployment need to be simplified. this work presents a method to easily develop remote experiments interfaces in javascript and to quickly embed them in moodle. this solution requires the use of easy java/javascript simulations for the development of the interfaces and the ejsapp moodle plugin to deploy them in the web platform. the proven flexibility of such solution has fostered the integration of two new experiments and also the easy adaptation of an already existing one, opening new remote labs flexibility to educational and/or training activities.",assisted creation and deployment of javascript remote experiments
1387,2-s2.0-84986224273,10.1007/978-3-319-44902-9_23,Endev: Declarative prototyping with data,Kis F.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2016-01-01,"The trend of Open Data and Internet-of-Things initiatives contribute to the ever growing amount of data available through web APIs. While building web applications has become easier with recent advancement in web development technologies and proliferation of JavaScript frameworks, the access to data from various APIs and data stores still poses certain challenges. It often requires complex setup and advanced programming skills that hinder the rapid prototyping efforts. Therefore, we propose Endev, a declarative framework for prototyping applications that is built on modern web technologies and supports building modern web applications, that utilize the vast amount of available data, without the need for setup or write complex JavaScript code.",Discourse model | GUI generation | Interactive prototypes | Query annotations | UI modeling,0,359-365,Book Series,Conference Paper,2.0,"Kis, Filip;Bogdan, Cristian",55421222000;24474207600,The Royal Institute of Technology (KTH),Sweden,"the trend of open data and internet-of-things initiatives contribute to the ever growing amount of data available through web apis. while building web applications has become easier with recent advancement in web development technologies and proliferation of javascript frameworks, the access to data from various apis and data stores still poses certain challenges. it often requires complex setup and advanced programming skills that hinder the rapid prototyping efforts. therefore, we propose endev, a declarative framework for prototyping applications that is built on modern web technologies and supports building modern web applications, that utilize the vast amount of available data, without the need for setup or write complex javascript code.",endev: declarative prototyping with data
1389,2-s2.0-84979789843,10.5220/0005763600370048,DSaaS: A cloud service for persistent data structures,Le Roux P.B.,CLOSER 2016 - Proceedings of the 6th International Conference on Cloud Computing and Services Science,2016-01-01,"In an attempt to tackle shortcomings of current approaches to collaborating on the development of structured data sets, we present a prototype platform that allows users to share and collaborate on the development of data structures via a web application, or by using language bindings or an API. Using techniques from the theory of persistent linked data structures, the resulting platform delivers automatically version-controlled map and graph abstract data types as a web service. The core of the system is provided by a Hash Array Mapped Trie (HAMT) which is made confluently persistent by path-copying. The system aims to make efficient use of storage, and to have consistent access and update times regardless of the version being accessed or modified.",Cloud Computing | DaaS | Hash-Array Mapped Trie | Persistent Data Structure | SaaS | Version Control System,1,37-48,Conference Proceeding,Conference Paper,3.0,"Le Roux, Pierre Bernard;Kroon, Steve;Bester, Willem",57190405784;8385418300;56434612300,The Council for Scientific and Industrial Research;Stellenbosch University,South Africa;South Africa,"in an attempt to tackle shortcomings of current approaches to collaborating on the development of structured data sets, we present a prototype platform that allows users to share and collaborate on the development of data structures via a web application, or by using language bindings or an api. using techniques from the theory of persistent linked data structures, the resulting platform delivers automatically version-controlled map and graph abstract data types as a web service. the core of the system is provided by a hash array mapped trie (hamt) which is made confluently persistent by path-copying. the system aims to make efficient use of storage, and to have consistent access and update times regardless of the version being accessed or modified.",dsaas: a cloud service for persistent data structures
1391,2-s2.0-84979508825,10.5220/0005869301890194,AWSM: Agile web migration for SMEs,Heil S.,ENASE 2016 - Proceedings of the 11th International Conference on Evaluation of Novel Software Approaches to Software Engineering,2016-01-01,"Migrating legacy desktop to web applications is an important and challenging task for SME software companies. Due to their limited resources, migration should be integrated in ongoing development processes. Existing research in this area does not consider recent paradigm shifts in web development. Therefore, our work is dedicated to supporting SME software providers in migrating to modern web applications while integrating this into ongoing development. This paper outlines our idea and presents a roadmap towards achieving this goal.",Agile development | Software migration | Web engineering,2,189-194,Conference Proceeding,Conference Paper,2.0,"Heil, Sebastian;Gaedke, Martin",57212183803;8905803700,Technische Universität Chemnitz,Germany,"migrating legacy desktop to web applications is an important and challenging task for sme software companies. due to their limited resources, migration should be integrated in ongoing development processes. existing research in this area does not consider recent paradigm shifts in web development. therefore, our work is dedicated to supporting sme software providers in migrating to modern web applications while integrating this into ongoing development. this paper outlines our idea and presents a roadmap towards achieving this goal.",awsm: agile web migration for smes
1397,2-s2.0-84977068096,10.1541/ieejeiss.136.986,A development and evaluation of training environment for system administrator based on Linux server,Hoshino Y.,"IEEJ Transactions on Electronics, Information and Systems",2016-01-01,"The most important point to learn network and system management is to provide a proper and practical training environment to try learning tasks for system administrator to all learners. Although several popular software for virtualization with the emulation technologies are developed and released in nowadays and anyone is able to use the software to learn system management, it is difficult to learn with the Unix type OS for non-specialist learners. The OS (platform) in general does not have ideal functions to advise to the users and also to lead users to the goal. We are constructing a training environment with an advisory function for system administrator on Linux server. In this article, we propose a learning model for server administrator and implementation method as a browser application program, and also we discuss the result of the experiment for system evaluation as example of Web server construction training.",Administrator | Console | Learning Support | Learning System | Linux | Server,0,986-994,Journal,Article,4.0,"Hoshino, Yuki;Notomi, Kazuhiro;Nishimura, Hiromitsu;Shimeno, Hiroshi",56735515200;23971097700;36246565500;56736046700,Kanagawa Institute of Technology,Japan,"the most important point to learn network and system management is to provide a proper and practical training environment to try learning tasks for system administrator to all learners. although several popular software for virtualization with the emulation technologies are developed and released in nowadays and anyone is able to use the software to learn system management, it is difficult to learn with the unix type os for non-specialist learners. the os (platform) in general does not have ideal functions to advise to the users and also to lead users to the goal. we are constructing a training environment with an advisory function for system administrator on linux server. in this article, we propose a learning model for server administrator and implementation method as a browser application program, and also we discuss the result of the experiment for system evaluation as example of web server construction training.",a development and evaluation of training environment for system administrator based on linux server
1398,2-s2.0-84976874902,10.1137/15M1014784,"Molns: A cloud platform for interactive, reproducible, and scalable spatial stochastic computational experiments in systems biology using PyURDME",Drawert B.,SIAM Journal on Scientific Computing,2016-01-01,"Computational experiments using spatial stochastic simulations have led to important new biological insights, but they require specialized tools and a complex software stack, as well as large and scalable compute and data analysis resources due to the large computational cost associated with Monte Carlo computational workflows. The complexity of setting up and managing a large-scale distributed computation environment to support productive and reproducible modeling can be prohibitive for practitioners in systems biology. This results in a barrier to the adoption of spatial stochastic simulation tools, effectively limiting the type of biological questions addressed by quantitative modeling. In this paper, we present PyURDME, a new, user-friendly spatial modeling and simulation package, and MOLNs, a cloud computing appliance for distributed simulation of stochastic reaction-diffusion models. MOLNs is based on IPython and provides an interactive programming platform for development of sharable and reproducible distributed parallel computational experiments.",Cloud computing | Computational experiments | Simulation software | Spatial stochastic simulation | Systems biology,21,C179-C202,Journal,Article,5.0,"Drawert, Brian;Trogdon, Michael;Toor, Salman;Petzold, Linda;Hellander, Andreas",35558376000;55266092000;36444375300;7005581592;22835081600,"University of California, Santa Barbara;Uppsala Universitet;Helsingin Yliopisto",United States;Sweden;Finland,"computational experiments using spatial stochastic simulations have led to important new biological insights, but they require specialized tools and a complex software stack, as well as large and scalable compute and data analysis resources due to the large computational cost associated with monte carlo computational workflows. the complexity of setting up and managing a large-scale distributed computation environment to support productive and reproducible modeling can be prohibitive for practitioners in systems biology. this results in a barrier to the adoption of spatial stochastic simulation tools, effectively limiting the type of biological questions addressed by quantitative modeling. in this paper, we present pyurdme, a new, user-friendly spatial modeling and simulation package, and molns, a cloud computing appliance for distributed simulation of stochastic reaction-diffusion models. molns is based on ipython and provides an interactive programming platform for development of sharable and reproducible distributed parallel computational experiments.","molns: a cloud platform for interactive, reproducible, and scalable spatial stochastic computational experiments in systems biology using pyurdme"
1401,2-s2.0-84969915335,10.5220/0005726906480655,Virtual worlds on demand? Model-driven development of JavaScript-based virtual world UI components for mobile apps,Stürner M.,MODELSWARD 2016 - Proceedings of the 4th International Conference on Model-Driven Engineering and Software Development,2016-01-01,"Virtual worlds and avatar-based interactive computer games are a hype among consumers and researchers for many years now. In recent years, such games on mobile devices also became increasingly important. However, most virtual worlds require the use of proprietary clients and authoring environments and lack portability, which limits their usefulness for targeting wider audiences like e.g. in consumer marketing or sales. Using mobile devices and client-side web technologies like i.e. JavaScript in combination with a more automatic generation of customer-specific virtual worlds could help to overcome these limitations. Here, model-driven software development (MDD) provides a promising approach for automating the creation of user interface (UI) components for games on mobile devices. Therefore, in this paper an approach is proposed for the model-driven generation of UI components for virtual worlds using JavaScript and the upcoming Famo.us framework. The feasibilty of the approach is evaluated by implementing a proof-of-concept scenario.",Computer Games | JavaScript | Mobile UI | Model-Driven Software Development | UML Modeling | Virtual Worlds,3,648-655,Conference Proceeding,Conference Paper,2.0,"Stürner, Matthias;Brune, Philipp",57189379302;49862725400,University of Applied Sciences Neu-Ulm,Germany,"virtual worlds and avatar-based interactive computer games are a hype among consumers and researchers for many years now. in recent years, such games on mobile devices also became increasingly important. however, most virtual worlds require the use of proprietary clients and authoring environments and lack portability, which limits their usefulness for targeting wider audiences like e.g. in consumer marketing or sales. using mobile devices and client-side web technologies like i.e. javascript in combination with a more automatic generation of customer-specific virtual worlds could help to overcome these limitations. here, model-driven software development (mdd) provides a promising approach for automating the creation of user interface (ui) components for games on mobile devices. therefore, in this paper an approach is proposed for the model-driven generation of ui components for virtual worlds using javascript and the upcoming famo.us framework. the feasibilty of the approach is evaluated by implementing a proof-of-concept scenario.",virtual worlds on demand? model-driven development of javascript-based virtual world ui components for mobile apps
1403,2-s2.0-84963864015,10.1109/MIC.2016.42,Reflecting on software engineering research for internet computing,Blake M.,IEEE Internet Computing,2016-01-01,"M. Brian Blake from Drexel University discussed papers at For ICSE 2015, which reflected on software engineering research for Internet computing. The papers addressed interventions to enhance script-oriented implementations for Web applications. Mattia Fazzini and colleagues addressed the security concern of cross-site scripting, where hackers can exploit the sensitive information collected by Web applications. The authors introduced an approach where they dynamically accessed the provider's Web script by performing a taint analysis to determine which information was trusted or untrusted.",Internet computing | Internet/Web technologies | Software engineering | Web application research | Web application scripting and development,1,4-6,Journal,Review,1.0,"Blake, M. Brian",7102413373,Drexel University,United States,"m. brian blake from drexel university discussed papers at for icse 2015, which reflected on software engineering research for internet computing. the papers addressed interventions to enhance script-oriented implementations for web applications. mattia fazzini and colleagues addressed the security concern of cross-site scripting, where hackers can exploit the sensitive information collected by web applications. the authors introduced an approach where they dynamically accessed the provider's web script by performing a taint analysis to determine which information was trusted or untrusted.",reflecting on software engineering research for internet computing
1408,2-s2.0-84962407714,10.1007/978-3-319-30806-7_5,On the static analysis of hybrid mobile apps: A report on the state of Apache Cordova nation,Brucker A.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2016-01-01,"Developing mobile applications is a challenging business: developers need to support multiple platforms and, at the same time, need to cope with limited resources, as the revenue generated by an average app is rather small. This results in an increasing use of cross-platform development frameworks that allow developing an app once and offering it on multiple mobile platforms such as Android, iOS, or Windows. Apache Cordova is a popular framework for developing multi-platform apps. Cordova combines HTML5 and JavaScript with native application code. Combining web and native technologies creates new security challenges as, e. g., an XSS attacker becomes more powerful. In this paper, we present a novel approach for statically analysing the foreign language calls. We evaluate our approach by analysing the top Cordova apps from Google Play. Moreover, we report on the current state of the overall quality and security of Cordova apps.",Android | Cordova | Hybrid mobile apps | Static application security testing | Static program analysis,17,72-88,Book Series,Conference Paper,2.0,"Brucker, Achim D.;Herzberg, Michael",8868852700;57188702274,SAP AG;The University of Sheffield,Germany;United Kingdom,"developing mobile applications is a challenging business: developers need to support multiple platforms and, at the same time, need to cope with limited resources, as the revenue generated by an average app is rather small. this results in an increasing use of cross-platform development frameworks that allow developing an app once and offering it on multiple mobile platforms such as android, ios, or windows. apache cordova is a popular framework for developing multi-platform apps. cordova combines html5 and javascript with native application code. combining web and native technologies creates new security challenges as, e. g., an xss attacker becomes more powerful. in this paper, we present a novel approach for statically analysing the foreign language calls. we evaluate our approach by analysing the top cordova apps from google play. moreover, we report on the current state of the overall quality and security of cordova apps.",on the static analysis of hybrid mobile apps: a report on the state of apache cordova nation
1409,2-s2.0-84962091866,10.1109/MPRV.2016.3,Software Support for Multitouch Interaction: The End-User Programming Perspective,Bellucci A.,IEEE Pervasive Computing,2016-01-01,"The hardware development of the past years favored the widespread diffusion of multitouch devices (such as smartphones, tablets, and interactive tabletops) to such an extent that a wide variety of users are now exploiting them to perform different activities on a daily basis. In the heterogeneous and manifold context of modern computation, it is impossible to predict, at design time, all the possible configurations of such technologies, and especially the way users will be willing to interact with them. Therefore, empowering end users with tools for developing multitouch interaction is a promising step toward the materialization of ubiquitous computing. The aim of this survey is to frame the state of the art of existing multitouch software development tools from an end-user programming (EUP) perspective.",coding tools and techniques | end-user programming | graphics | mobile | pervasive computing | software engineering | ubiquitous computing,5,78-86,Journal,Article,4.0,"Bellucci, Andrea;Romano, Marco;Aedo, Ignacio;Diaz, Paloma",7003345424;35410412100;6603683704;7103221225,Universidad Politécnica de Madrid;Università degli Studi di Salerno;Universidad Carlos III de Madrid,Spain;Italy;Spain,"the hardware development of the past years favored the widespread diffusion of multitouch devices (such as smartphones, tablets, and interactive tabletops) to such an extent that a wide variety of users are now exploiting them to perform different activities on a daily basis. in the heterogeneous and manifold context of modern computation, it is impossible to predict, at design time, all the possible configurations of such technologies, and especially the way users will be willing to interact with them. therefore, empowering end users with tools for developing multitouch interaction is a promising step toward the materialization of ubiquitous computing. the aim of this survey is to frame the state of the art of existing multitouch software development tools from an end-user programming (eup) perspective.",software support for multitouch interaction: the end-user programming perspective
1411,2-s2.0-84961665209,10.1007/978-3-319-31232-3_65,"Implementation of techniques, standards and safety recommendations to prevent XSS and SQL injection attacks in Java EE RESTful applications",Guamán D.,Advances in Intelligent Systems and Computing,2016-01-01,"There are recommendations and tools, given by OWASP that suggest basic techniques of prevention and protection of computer attacks over web applications where the common types of attacks are XSS and SQL Injection; for that reasons, we apply recommendations and good practice to minimize this kind of attacks; used some tools to validate automatically attacks and built some expressions to validate manually the intrusions in web applications. Therefore, this study was based on the development of a prototype under REST, design pattern Facade, Java EE and Glassfish [13].With the development of the prototype it was found that by the use of standards and norms recommend by OWASP the security in terms of overall design and source code in web applications can be greatly improved.",OWASP | REST | SQL injection | XSS,4,691-706,Book Series,Conference Paper,4.0,"Guamán, Daniel;Guamán, Franco;Jaramillo, Danilo;Correa, Roddy",57188566526;57188550664;36668388200;57188551423,Universidad Tecnica Particular de Loja,Ecuador,"there are recommendations and tools, given by owasp that suggest basic techniques of prevention and protection of computer attacks over web applications where the common types of attacks are xss and sql injection; for that reasons, we apply recommendations and good practice to minimize this kind of attacks; used some tools to validate automatically attacks and built some expressions to validate manually the intrusions in web applications. therefore, this study was based on the development of a prototype under rest, design pattern facade, java ee and glassfish [13].with the development of the prototype it was found that by the use of standards and norms recommend by owasp the security in terms of overall design and source code in web applications can be greatly improved.","implementation of techniques, standards and safety recommendations to prevent xss and sql injection attacks in java ee restful applications"
1412,2-s2.0-84961575577,10.5755/j01.itc.45.1.9341,Extending rule set for static code analysis in .NET platform,Čeponis J.,Information Technology and Control,2016-01-01,"This paper focuses on static code analysis tools for .NET platform. Static code analysis tools typically use a certain set of rules. In this paper, we propose to implement four rules, which we consider important from our practical experience of software development. We analyze the existing popular static analysis tools for .NET platform in order to determine whether they have the rules equivalent to our new rules. We select an open-source tool Gendarme for the implementation of these rules. We also investigate existing Gendarme rules and discover that some of them could be improved. Therefore, we propose and implement improvements for four existing Gendarme rules. In order to evaluate the improvements made in Gendarme rule set in a real-life environment, the source code of five open-source programs from sourceforge.net is tested using new and improved rules. Results indicate that new and improved Gendarme rules enable detection of more errors and can increase the quality of source code.",.NET | Code analysis rules | Code defects | Static code analysis,1,99-108,Journal,Article,4.0,"Čeponis, Jonas;Venčkauskas, Algimantas;Čeponienė, Lina;Zonys, Andrius",57204353649;55061639500;35095979100;57188566353,Kaunas University of Technology,Lithuania,"this paper focuses on static code analysis tools for .net platform. static code analysis tools typically use a certain set of rules. in this paper, we propose to implement four rules, which we consider important from our practical experience of software development. we analyze the existing popular static analysis tools for .net platform in order to determine whether they have the rules equivalent to our new rules. we select an open-source tool gendarme for the implementation of these rules. we also investigate existing gendarme rules and discover that some of them could be improved. therefore, we propose and implement improvements for four existing gendarme rules. in order to evaluate the improvements made in gendarme rule set in a real-life environment, the source code of five open-source programs from sourceforge.net is tested using new and improved rules. results indicate that new and improved gendarme rules enable detection of more errors and can increase the quality of source code.",extending rule set for static code analysis in .net platform
1413,2-s2.0-84959209528,10.1007/978-981-287-988-2_62,Multi level filtering to classify and block undesirable explicit material in website,Iqbal M.,Lecture Notes in Electrical Engineering,2016-01-01,"The growth of Internet opens wide opportunities for content production in various types of internet sites that provide information of various categories. For students or kids, ease of access to the internet site have a positive impact to provide days connectivity of user to the content that they needed for their study, but the other side, it also cause a negative impact when they accessing sites that provide undesirable explicit material such as pornographic content. During this time, pornographic content can be easy inserted through the text or images in page of internet sites. Therefore, we need a system that can filter information related to pornography and can prevent users who are not old enough to access pornographic content. To overcome this issue, we develop an online client-side filtering system that allows the user to perform a domain filtering, URL filtering, keyword filtering, and skin detection filtering. Also we proposed a hybrid skin color detection technique to overcome the failure of detecting skin when the images in close-up or scene mode. This system consist of classification using n-gram tokenizer for text and haar algorithm and skin chromaticity at HSV (Hue Saturation Value) and Normalized RGB color spaces for images. The applications created using software development tools such as flowchart and Unified Modelling Language (UML), while for the programming language using PHP, CSS, Javascript and using MySQL database.",Browser based filters | Domain and URL filtering | Filtering | Pornography | Skin detection,0,553-563,Book Series,Book Chapter,4.0,"Iqbal, Mohammad;Riesvicky, Hifshan;Rasjid, Hasma;Charli, Yulia",56459491900;57142470900;57142449300;57142598800,Gunadarma University,Indonesia,"the growth of internet opens wide opportunities for content production in various types of internet sites that provide information of various categories. for students or kids, ease of access to the internet site have a positive impact to provide days connectivity of user to the content that they needed for their study, but the other side, it also cause a negative impact when they accessing sites that provide undesirable explicit material such as pornographic content. during this time, pornographic content can be easy inserted through the text or images in page of internet sites. therefore, we need a system that can filter information related to pornography and can prevent users who are not old enough to access pornographic content. to overcome this issue, we develop an online client-side filtering system that allows the user to perform a domain filtering, url filtering, keyword filtering, and skin detection filtering. also we proposed a hybrid skin color detection technique to overcome the failure of detecting skin when the images in close-up or scene mode. this system consist of classification using n-gram tokenizer for text and haar algorithm and skin chromaticity at hsv (hue saturation value) and normalized rgb color spaces for images. the applications created using software development tools such as flowchart and unified modelling language (uml), while for the programming language using php, css, javascript and using mysql database.",multi level filtering to classify and block undesirable explicit material in website
1415,2-s2.0-84952863976,10.1002/elps.201500417,Updates in metabolomics tools and resources: 2014-2015,Misra B.B.,Electrophoresis,2016-01-01,"Data processing and interpretation represent the most challenging and time-consuming steps in high-throughput metabolomic experiments, regardless of the analytical platforms (MS or NMR spectroscopy based) used for data acquisition. Improved machinery in metabolomics generates increasingly complex datasets that create the need for more and better processing and analysis software and in silico approaches to understand the resulting data. However, a comprehensive source of information describing the utility of the most recently developed and released metabolomics resources-in the form of tools, software, and databases-is currently lacking. Thus, here we provide an overview of freely-available, and open-source, tools, algorithms, and frameworks to make both upcoming and established metabolomics researchers aware of the recent developments in an attempt to advance and facilitate data processing workflows in their metabolomics research. The major topics include tools and researches for data processing, data annotation, and data visualization in MS and NMR-based metabolomics. Most in this review described tools are dedicated to untargeted metabolomics workflows; however, some more specialist tools are described as well. All tools and resources described including their analytical and computational platform dependencies are summarized in an overview Table.",Annotation | Data analysis | Data processing | Data visualization | Databases | Mass spectrometry | Metabolites | Metabolomics | NMR | Software tools | Statistics,89,86-110,Journal,Review,2.0,"Misra, Biswapriya B.;van der Hooft, Justin J.J.",55427987300;35068720200,University of Florida;University of Glasgow,United States;United Kingdom,"data processing and interpretation represent the most challenging and time-consuming steps in high-throughput metabolomic experiments, regardless of the analytical platforms (ms or nmr spectroscopy based) used for data acquisition. improved machinery in metabolomics generates increasingly complex datasets that create the need for more and better processing and analysis software and in silico approaches to understand the resulting data. however, a comprehensive source of information describing the utility of the most recently developed and released metabolomics resources-in the form of tools, software, and databases-is currently lacking. thus, here we provide an overview of freely-available, and open-source, tools, algorithms, and frameworks to make both upcoming and established metabolomics researchers aware of the recent developments in an attempt to advance and facilitate data processing workflows in their metabolomics research. the major topics include tools and researches for data processing, data annotation, and data visualization in ms and nmr-based metabolomics. most in this review described tools are dedicated to untargeted metabolomics workflows; however, some more specialist tools are described as well. all tools and resources described including their analytical and computational platform dependencies are summarized in an overview table.",updates in metabolomics tools and resources: 2014-2015
1416,2-s2.0-84952037753,10.1016/bs.adcom.2015.11.003,Security Testing: A Survey,Felderer M.,Advances in Computers,2016-01-01,"Identifying vulnerabilities and ensuring security functionality by security testing is a widely applied measure to evaluate and improve the security of software. Due to the openness of modern software-based systems, applying appropriate security testing techniques is of growing importance and essential to perform effective and efficient security testing. Therefore, an overview of actual security testing techniques is of high value both for researchers to evaluate and refine the techniques and for practitioners to apply and disseminate them. This chapter fulfills this need and provides an overview of recent security testing techniques. For this purpose, it first summarize the required background of testing and security engineering. Then, basics and recent developments of security testing techniques applied during the secure software development life cycle, ie, model-based security testing, code-based testing and static analysis, penetration testing and dynamic analysis, as well as security regression testing are discussed. Finally, the security testing techniques are illustrated by adopting them for an example three-tiered web-based business application. © 2016 Elsevier Inc.",Black-box security testing | Model-based security testing | Penetration testing | Security engineering | Security regression testing | Security testing | Security testing techniques | Software testing | Survey | White-box security testing,92,1-51,Book Series,Book Chapter,6.0,"Felderer, Michael;Büchler, Matthias;Johns, Martin;Brucker, Achim D.;Breu, Ruth;Pretschner, Alexander",24832720900;42860965600;23135290500;8868852700;55885332900;12645083400,SAP AG;Technical University of Munich;Universität Innsbruck,Germany;Germany;Austria,"identifying vulnerabilities and ensuring security functionality by security testing is a widely applied measure to evaluate and improve the security of software. due to the openness of modern software-based systems, applying appropriate security testing techniques is of growing importance and essential to perform effective and efficient security testing. therefore, an overview of actual security testing techniques is of high value both for researchers to evaluate and refine the techniques and for practitioners to apply and disseminate them. this chapter fulfills this need and provides an overview of recent security testing techniques. for this purpose, it first summarize the required background of testing and security engineering. then, basics and recent developments of security testing techniques applied during the secure software development life cycle, ie, model-based security testing, code-based testing and static analysis, penetration testing and dynamic analysis, as well as security regression testing are discussed. finally, the security testing techniques are illustrated by adopting them for an example three-tiered web-based business application. © 2016 elsevier inc.",security testing: a survey
1417,2-s2.0-84945541340,10.1016/j.ins.2015.08.028,Assessment of software developed by a third-party: A case study and comparison,Remencius T.,Information Sciences,2016-01-01,"Most of the research effort in the area of software analysis is focused on the perspective of the developer (as in ""software developing company"") and the ways how the software development process could be improved. However, that is not the only type of software assessment common in the industry. There are also assessments that are commissioned by other parties, such as the primary recipients of the software solutions or courts dealing with legal cases that are related to software products or services. This work presents one such case-study that was performed for a public administration in Italy. The paper describes the assessment itself and also points out the need for more focused research by providing a comparison between developer-oriented and customer-oriented assessment types.",Empirical software engineering | Software metrics,10,237-249,Journal,Article,3.0,"Remencius, Tadas;Sillitti, Alberto;Succi, Giancarlo",25825534500;6602286710;7004757466,Innopolis University;Free University of Bozen-Bolzano;Connexx S.r.L.,Russian Federation;Italy;Italy,"most of the research effort in the area of software analysis is focused on the perspective of the developer (as in ""software developing company"") and the ways how the software development process could be improved. however, that is not the only type of software assessment common in the industry. there are also assessments that are commissioned by other parties, such as the primary recipients of the software solutions or courts dealing with legal cases that are related to software products or services. this work presents one such case-study that was performed for a public administration in italy. the paper describes the assessment itself and also points out the need for more focused research by providing a comparison between developer-oriented and customer-oriented assessment types.",assessment of software developed by a third-party: a case study and comparison
1418,2-s2.0-84942364360,10.1016/j.future.2015.05.014,SAGE2: A collaboration portal for scalable resolution displays,Renambot L.,Future Generation Computer Systems,2016-01-01,"In this paper, we present SAGE2, a software framework that enables local and remote collaboration on Scalable Resolution Display Environments (SRDE). An SRDE can be any configuration of displays, ranging from a single monitor to a wall of tiled flat-panel displays. SAGE2 creates a seamless ultra-high resolution desktop across the SRDE. Users can wirelessly connect to the SRDE with their own devices in order to interact with the system. Many users can simultaneously utilize a drag-and-drop interface to transfer local documents and show them on the SRDE, use a mouse pointer and keyboard to interact with existing content that is on the SRDE and share their screen so that it is viewable to all. SAGE2 can be used in many configurations and is able to support many communities working with various types of media and high-resolution content, from research meetings to creative session to education. SAGE2 is browser-based, utilizing a web server to host content, WebSockets for message passing and HTML with JavaScript for rendering and interaction. Recent web developments, with the emergence of HTML5, have allowed browsers to use advanced rendering techniques without requiring plug-ins (canvas drawing, WebGL 3D rendering, native video player, etc.). One major benefit of browser-based software is that there are no installation requirements for users and it is inherently cross-platform. A user simply needs a web browser on the device he/she wishes to use as an interaction tool for the SRDE. This lowers considerably the barrier of entry to engage in meaningful collaboration sessions.",Application development | Collaboration | Large-scale displays | Multi-user interaction | Scalable Resolution Display Environments | Web-based | Window manager,36,296-305,Journal,Article,10.0,"Renambot, Luc;Marrinan, Thomas;Aurisano, Jillian;Nishimoto, Arthur;Mateevitsi, Victor;Bharadwaj, Krishna;Long, Lance;Johnson, Andy;Brown, Maxine;Leigh, Jason",6602580367;36194260800;55614913400;53463996700;24822612200;56519631500;14007993100;7410014830;7405386727;7202089642,University of Illinois at Chicago;University of Hawaiʻi at Mānoa,United States;United States,"in this paper, we present sage2, a software framework that enables local and remote collaboration on scalable resolution display environments (srde). an srde can be any configuration of displays, ranging from a single monitor to a wall of tiled flat-panel displays. sage2 creates a seamless ultra-high resolution desktop across the srde. users can wirelessly connect to the srde with their own devices in order to interact with the system. many users can simultaneously utilize a drag-and-drop interface to transfer local documents and show them on the srde, use a mouse pointer and keyboard to interact with existing content that is on the srde and share their screen so that it is viewable to all. sage2 can be used in many configurations and is able to support many communities working with various types of media and high-resolution content, from research meetings to creative session to education. sage2 is browser-based, utilizing a web server to host content, websockets for message passing and html with javascript for rendering and interaction. recent web developments, with the emergence of html5, have allowed browsers to use advanced rendering techniques without requiring plug-ins (canvas drawing, webgl 3d rendering, native video player, etc.). one major benefit of browser-based software is that there are no installation requirements for users and it is inherently cross-platform. a user simply needs a web browser on the device he/she wishes to use as an interaction tool for the srde. this lowers considerably the barrier of entry to engage in meaningful collaboration sessions.",sage2: a collaboration portal for scalable resolution displays
1420,2-s2.0-84961616036,10.1109/TSE.2015.2461542,Mining Workflow Models from Web Applications,Schur M.,IEEE Transactions on Software Engineering,2015-12-01,"Modern business applications predominantly rely on web technology, enabling software vendors to efficiently provide them as a service, removing some of the complexity of the traditional release and update process. While this facilitates shorter, more efficient and frequent release cycles, it requires continuous testing. Having insight into application behavior through explicit models can largely support development, testing and maintenance. Model-based testing allows efficient test creation based on a description of the states the application can be in and the transitions between these states. As specifying behavior models that are precise enough to be executable by a test automation tool is a hard task, an alternative is to extract them from running applications. However, mining such models is a challenge, in particular because one needs to know when two states are equivalent, as well as how to reach that state. We present Process Crawler (ProCrawl), a tool to mine behavior models from web applications that support multi-user workflows. ProCrawl incrementally learns a model by generating program runs and observing the application behavior through the user interface. In our evaluation on several real-world web applications, ProCrawl extracted models that concisely describe the implemented workflows and can be directly used for model-based testing.",dynamic analysis | model-based testing | Specification mining | web system testing,14,1184-1201,Journal,Article,3.0,"Schur, Matthias;Roth, Andreas;Zeller, Andreas",51664191200;56742388200;7007015864,Universität des Saarlandes;SAP,Germany;Germany,"modern business applications predominantly rely on web technology, enabling software vendors to efficiently provide them as a service, removing some of the complexity of the traditional release and update process. while this facilitates shorter, more efficient and frequent release cycles, it requires continuous testing. having insight into application behavior through explicit models can largely support development, testing and maintenance. model-based testing allows efficient test creation based on a description of the states the application can be in and the transitions between these states. as specifying behavior models that are precise enough to be executable by a test automation tool is a hard task, an alternative is to extract them from running applications. however, mining such models is a challenge, in particular because one needs to know when two states are equivalent, as well as how to reach that state. we present process crawler (procrawl), a tool to mine behavior models from web applications that support multi-user workflows. procrawl incrementally learns a model by generating program runs and observing the application behavior through the user interface. in our evaluation on several real-world web applications, procrawl extracted models that concisely describe the implemented workflows and can be directly used for model-based testing.",mining workflow models from web applications
1422,2-s2.0-84951913827,10.1016/j.diin.2015.09.001,Scripting DNA: Identifying the JavaScript programmer,Wisse W.,Digital Investigation,2015-12-01,"The attribution of authorship is required in diverse applications, ranging from ancient novels (Shakespeare's work, Federalist papers) for historical interest to recent novels for linguistic research or even out of curiosity (Robert Galbraith alias J.K.Rowling). For this problem extensive research has resulted in effective general purpose methods. Also, for other types of text the original author needs to be discovered. Especially, we are interested in methods to identify JavaScript programmers, which can be used to reveal the offender who produced malicious software on a website. So far, for this hardly studied problem, mainly general purpose methods from natural language authorship attribution have been applied. Moreover, no suitable reference dataset is available to allow for method evaluation and method development in a supervised machine learning approach. In this work we first obtain a reference dataset of substantial size and quality. Further, we propose to extract structural features from the Abstract Syntax Tree (AST) to describe the coding style of an author. In the experiments, we show that the specifically designed features indeed improve the authorship attribution of scripting code to programmers, especially in addition to character n-gram features.",Abstract Syntax Tree | Authorship identification | Authorship verification | JavaScript | Source code | Syntactic features,19,61-71,Journal,Article,2.0,"Wisse, Wilco;Veenman, Cor",57024030900;6604025124,Netherlands Forensic Institute - NFI;Delft University of Technology,Netherlands;Netherlands,"the attribution of authorship is required in diverse applications, ranging from ancient novels (shakespeare's work, federalist papers) for historical interest to recent novels for linguistic research or even out of curiosity (robert galbraith alias j.k.rowling). for this problem extensive research has resulted in effective general purpose methods. also, for other types of text the original author needs to be discovered. especially, we are interested in methods to identify javascript programmers, which can be used to reveal the offender who produced malicious software on a website. so far, for this hardly studied problem, mainly general purpose methods from natural language authorship attribution have been applied. moreover, no suitable reference dataset is available to allow for method evaluation and method development in a supervised machine learning approach. in this work we first obtain a reference dataset of substantial size and quality. further, we propose to extract structural features from the abstract syntax tree (ast) to describe the coding style of an author. in the experiments, we show that the specifically designed features indeed improve the authorship attribution of scripting code to programmers, especially in addition to character n-gram features.",scripting dna: identifying the javascript programmer
1423,2-s2.0-84958251734,10.1109/ICSESS.2015.7339032,Design and implementation of multimedia repository system based on middle tier structure,Xiao L.,"Proceedings of the IEEE International Conference on Software Engineering and Service Sciences, ICSESS",2015-11-25,"Omni Media has become an important trend with the development of information services in the context of network convergence and screen integration. In such an environment, Internet interaction is no longer limited to the computer, users can also access Internet resources through wearable and other smart computing devices. This paper proposes a multimedia repository system, which is composed of client file upload module, task allocation core middle tier module of server side, file fragments merge module and media transcoding module. In section I, we comprehensively analyzed the current mainstream large file upload method based on the browser and discuss the features of each method. Then we proposed a combination of Ajax with XMLHttpRequest Level 2, File API and other technologies to achieve large media file segments upload in section II. In section III, we described the core task allocation middle tier module of server architecture which allows the system to receive media resources from various types of terminals and upload to the cloud server repository without size limit. Furthermore, we gave an example of completing the file upload and file fragments merge by using the core task allocation middle tier.",core task allocation middle tier | file upload | task assignment | XMLHttpRequest Level 2,0,179-182,Conference Proceeding,Conference Paper,2.0,"Xiao, Lingzi;Cao, Sanxing",55555628500;55491019900,Communication University of China,China,"omni media has become an important trend with the development of information services in the context of network convergence and screen integration. in such an environment, internet interaction is no longer limited to the computer, users can also access internet resources through wearable and other smart computing devices. this paper proposes a multimedia repository system, which is composed of client file upload module, task allocation core middle tier module of server side, file fragments merge module and media transcoding module. in section i, we comprehensively analyzed the current mainstream large file upload method based on the browser and discuss the features of each method. then we proposed a combination of ajax with xmlhttprequest level 2, file api and other technologies to achieve large media file segments upload in section ii. in section iii, we described the core task allocation middle tier module of server architecture which allows the system to receive media resources from various types of terminals and upload to the cloud server repository without size limit. furthermore, we gave an example of completing the file upload and file fragments merge by using the core task allocation middle tier.",design and implementation of multimedia repository system based on middle tier structure
1424,2-s2.0-84958233295,10.1109/ICSESS.2015.7339197,The universal design solution for Ajax-based three-tier architecture,Xu B.,"Proceedings of the IEEE International Conference on Software Engineering and Service Sciences, ICSESS",2015-11-25,"Ajax-based technology plays an important role in RIA (rich internet application). Meanwhile, Ajax-based three-tier architecture is a classic architecture in software development industry. Study shows that the data access layer and the business logic layer can be designed as universal modules and the presentation layer can be divided into specific module and universal module. As universal module is reusable, developers can find out the universal design solution for Ajax-based three-tier architecture in order to increase development efficiency.",Ajax | reuse | three-tier architecture | universal,0,890-893,Conference Proceeding,Conference Paper,1.0,"Xu, Baolin",55961210600,Guangdong Baiyun University,China,"ajax-based technology plays an important role in ria (rich internet application). meanwhile, ajax-based three-tier architecture is a classic architecture in software development industry. study shows that the data access layer and the business logic layer can be designed as universal modules and the presentation layer can be divided into specific module and universal module. as universal module is reusable, developers can find out the universal design solution for ajax-based three-tier architecture in order to increase development efficiency.",the universal design solution for ajax-based three-tier architecture
1425,2-s2.0-84962685271,10.1109/ACIT-CSI.2015.11,Automatic method of generating a web prototype employing live interactive widget to validate functional usability requirements,Kamimori S.,"Proceedings - 3rd International Conference on Applied Computing and Information Technology and 2nd International Conference on Computational Science and Intelligence, ACIT-CSI 2015",2015-11-23,"Usability is one of the crucial quality characteristics of Web applications. It depends strongly on users' subjective evaluation as a result of operating an application. Prototypes employing functions for enhancing usability are therefore needed so that users can validate the functions based on their subjectivity at an early stage of software development. Furthermore, the prototypes need to be refined iteratively because of frequent requirement changes caused by users' uncertainty. As a result, manual prototyping is time consuming because of the function implementation and iteration required. However, no method exists for automatically generating a prototype that employs the functions. In this paper, we propose a method of modeling the functions in UML such that the resulting model can be integrated with an existing screen transition model. A method for automatically generating the prototype from the models also is proposed. Evaluation results show that our method was useful for modeling and eliciting usability requirements.",Prototyping | Requirement Validation | Screen Transition Model | Unified Modeling Language | Usability,6,8-13,Conference Proceeding,Conference Paper,3.0,"Kamimori, Shohei;Ogata, Shinpei;Kaijiri, Kenji",57188747255;24829845100;6602684653,Shinshu University,Japan,"usability is one of the crucial quality characteristics of web applications. it depends strongly on users' subjective evaluation as a result of operating an application. prototypes employing functions for enhancing usability are therefore needed so that users can validate the functions based on their subjectivity at an early stage of software development. furthermore, the prototypes need to be refined iteratively because of frequent requirement changes caused by users' uncertainty. as a result, manual prototyping is time consuming because of the function implementation and iteration required. however, no method exists for automatically generating a prototype that employs the functions. in this paper, we propose a method of modeling the functions in uml such that the resulting model can be integrated with an existing screen transition model. a method for automatically generating the prototype from the models also is proposed. evaluation results show that our method was useful for modeling and eliciting usability requirements.",automatic method of generating a web prototype employing live interactive widget to validate functional usability requirements
1427,2-s2.0-84961645044,10.1109/ICSM.2015.7332449,When and why developers adopt and change software licenses,Vendome C.,"2015 IEEE 31st International Conference on Software Maintenance and Evolution, ICSME 2015 - Proceedings",2015-11-19,"Software licenses legally govern the way in which developers can use, modify, and redistribute a particular system. While previous studies either investigated licensing through mining software repositories or studied licensing through FOSS reuse, we aim at understanding the rationale behind developers' decisions for choosing or changing software licensing by surveying open source developers. In this paper, we analyze when developers consider licensing, the reasons why developers pick a license for their project, and the factors that influence licensing changes. Additionally, we explore the licensing-related problems that developers experienced and expectations they have for licensing support from forges (e.g., GitHub). Our investigation involves, on one hand, the analysis of the commit history of 16,221 Java open source projects to identify the commits where licenses were added or changed. On the other hand, it consisted of a survey- in which 138 developers informed their involvement in licensing-related decisions and 52 provided deeper insights about the rationale behind the actions that they had undertaken. The results indicate that developers adopt licenses early in the project's development and change licensing after some period of development (if at all). We also found that developers have inherent biases with respect to software licensing. Additionally, reuse- whether by a non-contributor or for commercial purposes- is a dominant reason why developers change licenses of their systems. Finally, we discuss potential areas of research that could ameliorate the difficulties that software developers are facing with regard to licensing issues of their software systems.",Empirical Studies | Mining Software Repositories | Software Licenses,26,31-40,Conference Proceeding,Conference Paper,6.0,"Vendome, Christopher;Linares-Vasquez, Mario;Bavota, Gabriele;Di Penta, Massimiliano;German, Daniel M.;Poshyvanyk, Denys",57021999600;54684418100;57220148228;6602794138;57207886015;13613571900,William &amp; Mary;Free University of Bozen-Bolzano;Università degli Studi del Sannio;University of Victoria,United States;Italy;Italy;Canada,"software licenses legally govern the way in which developers can use, modify, and redistribute a particular system. while previous studies either investigated licensing through mining software repositories or studied licensing through foss reuse, we aim at understanding the rationale behind developers' decisions for choosing or changing software licensing by surveying open source developers. in this paper, we analyze when developers consider licensing, the reasons why developers pick a license for their project, and the factors that influence licensing changes. additionally, we explore the licensing-related problems that developers experienced and expectations they have for licensing support from forges (e.g., github). our investigation involves, on one hand, the analysis of the commit history of 16,221 java open source projects to identify the commits where licenses were added or changed. on the other hand, it consisted of a survey- in which 138 developers informed their involvement in licensing-related decisions and 52 provided deeper insights about the rationale behind the actions that they had undertaken. the results indicate that developers adopt licenses early in the project's development and change licensing after some period of development (if at all). we also found that developers have inherent biases with respect to software licensing. additionally, reuse- whether by a non-contributor or for commercial purposes- is a dominant reason why developers change licenses of their systems. finally, we discuss potential areas of research that could ameliorate the difficulties that software developers are facing with regard to licensing issues of their software systems.",when and why developers adopt and change software licenses
1428,2-s2.0-84961637893,10.1109/ICSM.2015.7332494,Do automatic refactorings improve maintainability? An industrial case study,Szoke G.,"2015 IEEE 31st International Conference on Software Maintenance and Evolution, ICSME 2015 - Proceedings",2015-11-19,"Refactoring is often treated as the main remedy against the unavoidable code erosion happening during software evolution. Studies show that refactoring is indeed an elemental part of the developers' arsenal. However, empirical studies about the impact of refactorings on software maintainability still did not reach a consensus. Moreover, most of these empirical investigations are carried out on open-source projects where distinguishing refactoring operations from other development activities is a challenge in itself. We had a chance to work together with several software development companies in a project where they got extra budget to improve their source code by performing refactoring operations. Taking advantage of this controlled environment, we collected a large amount of data during a refactoring phase where the developers used a (semi)automatic refactoring tool. By measuring the maintainability of the involved subject systems before and after the refactorings, we got valuable insights into the effect of these refactorings on large-scale industrial projects. All but one company, who applied a special refactoring strategy, achieved a maintainability improvement at the end of the refactoring phase, but even that one company suffered from the negative impact of only one type of refactoring.",automatic refactoring | coding issues | ISO/IEC 25010 | software maintainability,11,429-438,Conference Proceeding,Conference Paper,5.0,"Szoke, Gabor;Nagy, Csaba;Hegedus, Peter;Ferenc, Rudolf;Gyimothy, Tibor",55803891600;26667913000;25926433300;6603559878;6603266536,Szegedi Tudományegyetem (SZTE),Hungary,"refactoring is often treated as the main remedy against the unavoidable code erosion happening during software evolution. studies show that refactoring is indeed an elemental part of the developers' arsenal. however, empirical studies about the impact of refactorings on software maintainability still did not reach a consensus. moreover, most of these empirical investigations are carried out on open-source projects where distinguishing refactoring operations from other development activities is a challenge in itself. we had a chance to work together with several software development companies in a project where they got extra budget to improve their source code by performing refactoring operations. taking advantage of this controlled environment, we collected a large amount of data during a refactoring phase where the developers used a (semi)automatic refactoring tool. by measuring the maintainability of the involved subject systems before and after the refactorings, we got valuable insights into the effect of these refactorings on large-scale industrial projects. all but one company, who applied a special refactoring strategy, achieved a maintainability improvement at the end of the refactoring phase, but even that one company suffered from the negative impact of only one type of refactoring.",do automatic refactorings improve maintainability? an industrial case study
1429,2-s2.0-84962840352,10.1145/2815585.2817797,Form follows function(): An IDE to create laser-cut interfaces and microcontroller programs from single code base,Kato J.,UIST 2015 - Adjunct Publication of the 28th Annual ACM Symposium on User Interface Software and Technology,2015-11-06,"During the development of physical computing devices, physical object models and programs for microcontrollers are usually created with separate tools with distinct files. As a result, it is difficult to track the changes in hardware and software without discrepancy. Moreover, the software cannot directly access hardware metrics. Designing hardware interface cannot benefit from the source code information either. This demonstration proposes a browserbased IDE named f3.js that enables development of both as a single JavaScript code base. The demonstration allows audiences to play with the f3.js IDE and showcases example applications such as laser-cut interfaces generated from the same code but with different parameters. Programmers can experience the full feature and designers can interact with preset projects with a mouse or touch to customize laser-cut interfaces. More information is available at http://f3js.org.",Integrated development environment | Laser-cut interface | Microcontroller | Personal fabrication,1,43-44,Conference Proceeding,Conference Paper,2.0,"Kato, Jun;Goto, Masataka",35416333000;7403505330,National Institute of Advanced Industrial Science and Technology,Japan,"during the development of physical computing devices, physical object models and programs for microcontrollers are usually created with separate tools with distinct files. as a result, it is difficult to track the changes in hardware and software without discrepancy. moreover, the software cannot directly access hardware metrics. designing hardware interface cannot benefit from the source code information either. this demonstration proposes a browserbased ide named f3.js that enables development of both as a single javascript code base. the demonstration allows audiences to play with the f3.js ide and showcases example applications such as laser-cut interfaces generated from the same code but with different parameters. programmers can experience the full feature and designers can interact with preset projects with a mouse or touch to customize laser-cut interfaces. more information is available at http://f3js.org.",form follows function(): an ide to create laser-cut interfaces and microcontroller programs from single code base
1430,2-s2.0-84952993529,10.1016/j.micpro.2015.10.004,Speech-controlled cloud-based wheelchair platform for disabled persons,Škraba A.,Microprocessors and Microsystems,2015-11-01,"This paper describes the development of a prototype speech-controlled cloud-based wheelchair platform. The control of the platform is implemented using a low-cost WebKit Speech API in the cloud. The description of the cloud-based wheelchair control system is provided. In addition to the voice control, a GUI is implemented, which works in a web browser as well as on mobile devices providing live video streaming. Development was done in two phases: first, a small, initial prototype was developed and, second, a full size prototype was build. The accuracy of the speech recognition system was estimated as ranging from approximately 60% to up to 97%, dependent on the speaker. The speech-controlled system latency was measured as well as the latency when the control is provided via touch on a so-called smart device. Measured latencies ranged from 0.4 s to 1.3 s. The platform was also clinically tested, providing promising results of cloud-based speech recognition for further implementation. The developed platform is based on a Quad Core ARM Mini PC GK802 running Ubuntu Linux and an Arduino UNO Microcontroller. Software development was done in JavaScript/ECMA Script, applying node.js.","Computer cloud, HTML5 | Cyber-physical system | Devices for rehabilitation | ECMA Script | Internet of things | JavaScript | Node.js | speech recognition | Wheelchair",27,819-828,Journal,Article,5.0,"Škraba, Andrej;Stojanović, Radovan;Zupan, Anton;Koložvari, Andrej;Kofjač, Davorin",8530587400;7003903082;6701803250;56429626900;8530587500,University of Montenegro;Institute for Rehabilitation Ljubljana;Univerza v Mariboru,Montenegro;Slovenia;Slovenia,"this paper describes the development of a prototype speech-controlled cloud-based wheelchair platform. the control of the platform is implemented using a low-cost webkit speech api in the cloud. the description of the cloud-based wheelchair control system is provided. in addition to the voice control, a gui is implemented, which works in a web browser as well as on mobile devices providing live video streaming. development was done in two phases: first, a small, initial prototype was developed and, second, a full size prototype was build. the accuracy of the speech recognition system was estimated as ranging from approximately 60% to up to 97%, dependent on the speaker. the speech-controlled system latency was measured as well as the latency when the control is provided via touch on a so-called smart device. measured latencies ranged from 0.4 s to 1.3 s. the platform was also clinically tested, providing promising results of cloud-based speech recognition for further implementation. the developed platform is based on a quad core arm mini pc gk802 running ubuntu linux and an arduino uno microcontroller. software development was done in javascript/ecma script, applying node.js.",speech-controlled cloud-based wheelchair platform for disabled persons
1433,2-s2.0-84964595923,10.1145/2846656.2846659,Lively groups: Shared behavior in a world of objects without classes or prototypes,Felgentreff T.,FPW 2015 - Proceedings of the Workshop on Future Programming,2015-10-26,"Development environments which aim to provide short feedback loops to developers must strike a balance between immediacy and the ability to abstract and reuse behavioral modules. The Lively Kernel, a self-supporting, browser-based environment for explorative development supports standard object-oriented programming with classes or prototypes, but also a more immediate, object-centric approach for modifying and programming visible objects directly. This allows users to quickly create graphical prototypes with concrete objects. However, when developing with the object-centric approach, sharing behavior between similar objects becomes cumbersome. Developers must choose to either abstract behavior into classes, scatter code across collaborating objects, or to manually copy code between multiple objects. That is, they must choose between less concrete development, reduced maintainability, or code duplication. In this paper, we propose Lively Groups, an extension to the object-centric development tools of Lively to work on multiple concrete objects. With Lively Groups, developers may dynamically organize live objects that share behavior using tags. They can then modify and program such groups as if they were single objects. Our approach scales the Lively Kernel's explorative development approach from one to many objects, while preserving the maintainability of abstractions and the immediacy of concrete objects.",Exploratory development | Interactive systems | Lively kernel | Web applications,3,15-22,Conference Proceeding,Conference Paper,4.0,"Felgentreff, Tim;Lincke, Jens;Hirschfeld, Robert;Thamsen, Lauritz",56112184900;24721726700;23094434200;55222001800,Hasso-Plattner-Institut für Softwaresystemtechnik GmbH;Technische Universität Berlin,Germany;Germany,"development environments which aim to provide short feedback loops to developers must strike a balance between immediacy and the ability to abstract and reuse behavioral modules. the lively kernel, a self-supporting, browser-based environment for explorative development supports standard object-oriented programming with classes or prototypes, but also a more immediate, object-centric approach for modifying and programming visible objects directly. this allows users to quickly create graphical prototypes with concrete objects. however, when developing with the object-centric approach, sharing behavior between similar objects becomes cumbersome. developers must choose to either abstract behavior into classes, scatter code across collaborating objects, or to manually copy code between multiple objects. that is, they must choose between less concrete development, reduced maintainability, or code duplication. in this paper, we propose lively groups, an extension to the object-centric development tools of lively to work on multiple concrete objects. with lively groups, developers may dynamically organize live objects that share behavior using tags. they can then modify and program such groups as if they were single objects. our approach scales the lively kernel's explorative development approach from one to many objects, while preserving the maintainability of abstractions and the immediacy of concrete objects.",lively groups: shared behavior in a world of objects without classes or prototypes
1434,2-s2.0-84964247513,10.1145/2846661.2846673,Program analysis for mobile: How and why to run WALA on your phone,Dolby J.,MobileDeLi 2015 - Proceedings of the 3rd International Workshop on Mobile Development Lifecycle,2015-10-26,"As mobile devices become ubiquitous, security of such devices has become a serious concern. Attacks on the devices themselves are a danger, as is theft of data they contain. Static analysis of the devices' software is one approach to verifying the absence of security, and several tools have been created to analyze apps for potential attacks and vulnerabilities. Many tools focus on single apps, but there are starting to be tools that look for possible vulnerabilities or attacks due to multiple apps on a single device that can communicate. Such analysis depends on having access to the relevant apps, and hence has been proposed to be performed on app stores. One challenge in the Android environment is that apps are often installed from multiple sources, such as development builds of apps installed from developer sites, e.g. Mozilla Aurora pre-released of Firefox. Ultimately, sometimes the device itself is the only place with the full set of apps used on that device. This suggests that running analysis on the device itself is attractive, at least in terms of having all the relevant code. Furthermore, app communication can be configured on the device itself, raising the possibility of analyzing communication risk when it is configured. However, this approach has a variety of challenges: 1) analysis tools are not typically mobile apps themselves, yet they somehow need to be built for and deployed on mobile devices. 2) Analysis tools are often resources intensive, and mobile devices need the resources to perform analysis. 3) Analysis can also be a major drain on battery life, so care must be taken not to heedlessly drain power. We describe our preliminary work toward running program analysis on mobile devices, focusing on running the WALA framework on Android devices. We describe how WALA can be built and deployed for Android; since WALA is Java code, it is actually straightforward to do this, both using Eclipse and Maven-based command-line tools. We also provide some evidence that performance is reasonable.",Analysis | Mobile | WALA,1,47-48,Conference Proceeding,Conference Paper,1.0,"Dolby, Julian",8837002700,IBM Thomas J. Watson Research Center,United States,"as mobile devices become ubiquitous, security of such devices has become a serious concern. attacks on the devices themselves are a danger, as is theft of data they contain. static analysis of the devices' software is one approach to verifying the absence of security, and several tools have been created to analyze apps for potential attacks and vulnerabilities. many tools focus on single apps, but there are starting to be tools that look for possible vulnerabilities or attacks due to multiple apps on a single device that can communicate. such analysis depends on having access to the relevant apps, and hence has been proposed to be performed on app stores. one challenge in the android environment is that apps are often installed from multiple sources, such as development builds of apps installed from developer sites, e.g. mozilla aurora pre-released of firefox. ultimately, sometimes the device itself is the only place with the full set of apps used on that device. this suggests that running analysis on the device itself is attractive, at least in terms of having all the relevant code. furthermore, app communication can be configured on the device itself, raising the possibility of analyzing communication risk when it is configured. however, this approach has a variety of challenges: 1) analysis tools are not typically mobile apps themselves, yet they somehow need to be built for and deployed on mobile devices. 2) analysis tools are often resources intensive, and mobile devices need the resources to perform analysis. 3) analysis can also be a major drain on battery life, so care must be taken not to heedlessly drain power. we describe our preliminary work toward running program analysis on mobile devices, focusing on running the wala framework on android devices. we describe how wala can be built and deployed for android; since wala is java code, it is actually straightforward to do this, both using eclipse and maven-based command-line tools. we also provide some evidence that performance is reasonable.",program analysis for mobile: how and why to run wala on your phone
1436,2-s2.0-84941186763,10.1007/s00607-014-0394-9,Is Node.js a viable option for building modern web applications? A performance evaluation study,Chaniotis I.K.,Computing,2015-10-10,"We examine the implications of end-to-end web application development, in the social web era. The paper describes a distributed architecture, suitable for modern web application development, as well as the interactivity components associated with it. Furthermore, we conducted a series of stress tests, on popular server side technologies. The PHP/Apache stack was found inefficient to address the increasing demand in network traffic. Nginx was found more than 2.5 times faster in input/output (I/O) operations than Apache, whereas Node.js outperformed both. Node.js, although excellent in I/O operations and resource utilization, was found lacking in serving static files using its built in HTTP server, while Nginx performed great at this task. So, in order to address efficiency, an Nginx server could be placed in-front and proxy static file requests, allowing the Node.js processes to only handle dynamic content. Such a configuration can offer a better infrastructure in terms of efficiency and scalability, replacing the aged PHP/Apache stack. Furthermore we have found that building cross platform applications based on web technologies, is both feasible and highly productive, especially when addressing stationary and mobile devices, as well as the fragmentation among them. Our study concludes that Node.js offers client-server development integration, aiding code reusability in web applications, and is the perfect tool for developing fast, scalable network applications.",End-to-end JavaScript | Node.js | Real-time Web | Software performance evaluation | WebRTC | WebSockets,36,1023-1044,Journal,Article,3.0,"Chaniotis, Ioannis K.;Kyriakou, Kyriakos Ioannis D.;Tselikas, Nikolaos D.",55553823600;55839941700;6506637365,University of Peloponnese,Greece,"we examine the implications of end-to-end web application development, in the social web era. the paper describes a distributed architecture, suitable for modern web application development, as well as the interactivity components associated with it. furthermore, we conducted a series of stress tests, on popular server side technologies. the php/apache stack was found inefficient to address the increasing demand in network traffic. nginx was found more than 2.5 times faster in input/output (i/o) operations than apache, whereas node.js outperformed both. node.js, although excellent in i/o operations and resource utilization, was found lacking in serving static files using its built in http server, while nginx performed great at this task. so, in order to address efficiency, an nginx server could be placed in-front and proxy static file requests, allowing the node.js processes to only handle dynamic content. such a configuration can offer a better infrastructure in terms of efficiency and scalability, replacing the aged php/apache stack. furthermore we have found that building cross platform applications based on web technologies, is both feasible and highly productive, especially when addressing stationary and mobile devices, as well as the fragmentation among them. our study concludes that node.js offers client-server development integration, aiding code reusability in web applications, and is the perfect tool for developing fast, scalable network applications.",is node.js a viable option for building modern web applications? a performance evaluation study
1437,2-s2.0-84938739142,10.1016/j.cl.2015.02.001,Neverlang: A framework for feature-oriented language development,Vacchi E.,"Computer Languages, Systems and Structures",2015-10-01,"Reuse in programming language development is an open research problem. Many authors have proposed frameworks for modular language development. These frameworks focus on maximizing code reuse, providing primitives for componentizing language implementations. There is also an open debate on combining feature-orientation with modular language development. Feature-oriented programming is a vision of computer programming in which features can be implemented separately, and then combined to build a variety of software products. However, even though feature-orientation and modular programming are strongly connected, modular language development frameworks are not usually meant primarily for feature-oriented language definition. In this paper we present a model of language development that puts feature implementation at the center, and describe its implementation in the Neverlang framework. The model has been evaluated through several languages implementations: in this paper, a state machine language is used as a means of comparison with other frameworks, and a JavaScript interpreter implementation is used to further illustrate the benefits that our model provides.",Domain specific languages | Language development | Modularity,64,1-40,Journal,Article,2.0,"Vacchi, Edoardo;Cazzola, Walter",55735667200;6602449966,Università degli Studi di Milano,Italy,"reuse in programming language development is an open research problem. many authors have proposed frameworks for modular language development. these frameworks focus on maximizing code reuse, providing primitives for componentizing language implementations. there is also an open debate on combining feature-orientation with modular language development. feature-oriented programming is a vision of computer programming in which features can be implemented separately, and then combined to build a variety of software products. however, even though feature-orientation and modular programming are strongly connected, modular language development frameworks are not usually meant primarily for feature-oriented language definition. in this paper we present a model of language development that puts feature implementation at the center, and describe its implementation in the neverlang framework. the model has been evaluated through several languages implementations: in this paper, a state machine language is used as a means of comparison with other frameworks, and a javascript interpreter implementation is used to further illustrate the benefits that our model provides.",neverlang: a framework for feature-oriented language development
1438,2-s2.0-84937676280,10.1007/s10606-015-9230-9,How Do Users Discover New Tools in Software Development and Beyond?,Murphy-Hill E.,Computer Supported Cooperative Work: CSCW: An International Journal,2015-10-01,"Software users rely on software tools such as browser tab controls and spell checkers to work effectively and efficiently, but it is difficult for users to be aware of all the tools that might be useful to them. While there are several potential technical solutions to this difficulty, we know little about social solutions, such as one user telling a peer about a tool. To explore these social solutions, we conducted two studies, an interview study and a diary study. The interview study describes a series of interviews with 18 programmers in industry to explore how tool discovery takes place. To broaden our findings to a wider group of software users, we then conducted a diary study of 76 software users in their workplaces. One finding was that social learning of software tools, while sometimes effective, is infrequent; software users appear to discover tools from peers only once every few months. We describe several implications of our findings, such as that discovery from peers can be enhanced by improving software users’ ability to communicate openly and concisely about tools.",Discovery | Learning | Programmers | Programming tools,22,389-422,Journal,Article,4.0,"Murphy-Hill, Emerson;Lee, Da Young;Murphy, Gail C.;McGrenere, Joanna",16307910100;56133700000;7402791460;6505966811,The University of British Columbia;NC State University,Canada;United States,"software users rely on software tools such as browser tab controls and spell checkers to work effectively and efficiently, but it is difficult for users to be aware of all the tools that might be useful to them. while there are several potential technical solutions to this difficulty, we know little about social solutions, such as one user telling a peer about a tool. to explore these social solutions, we conducted two studies, an interview study and a diary study. the interview study describes a series of interviews with 18 programmers in industry to explore how tool discovery takes place. to broaden our findings to a wider group of software users, we then conducted a diary study of 76 software users in their workplaces. one finding was that social learning of software tools, while sometimes effective, is infrequent; software users appear to discover tools from peers only once every few months. we describe several implications of our findings, such as that discovery from peers can be enhanced by improving software users’ ability to communicate openly and concisely about tools.",how do users discover new tools in software development and beyond?
1439,2-s2.0-84961131302,10.1109/MobileSoft.2015.47,Content-Based Multi-platform App Forge,Rogai D.,"Proceedings - 2nd ACM International Conference on Mobile Software Engineering and Systems, MOBILESoft 2015",2015-09-28,"Mobile App development arises new dynamism for both device platform and device equipment. New solution projects and solution maintenance sustainability is at risk due to this variability. Some entry-level and build-by-template solutions are emerging. This experience demonstrates the solution we found when working together with market leaders in cultural-heritage video-guide: new digital editorial artifacts. We used an open-source CMS system to manage different type of contents and to generate complete software package for various mobile platforms. The client-side App is based on Phone Gap/Cordova framework and java script frameworks selection and optimization. This system completely covers digital mobile publishing product life-cycle from digital asset management to App (web or mobile) deploy or updates management systems, including in-App purchase content and incremental update.",digital assets management | Hybrid development | javascript software engineering | software generation,3,166-167,Conference Proceeding,Conference Paper,3.0,"Rogai, Davide;Bisconti, Claudio;Faye, Salif Omar",14061085400;57184187900;57183973500,Comm.it S.r.l.,Italy,"mobile app development arises new dynamism for both device platform and device equipment. new solution projects and solution maintenance sustainability is at risk due to this variability. some entry-level and build-by-template solutions are emerging. this experience demonstrates the solution we found when working together with market leaders in cultural-heritage video-guide: new digital editorial artifacts. we used an open-source cms system to manage different type of contents and to generate complete software package for various mobile platforms. the client-side app is based on phone gap/cordova framework and java script frameworks selection and optimization. this system completely covers digital mobile publishing product life-cycle from digital asset management to app (web or mobile) deploy or updates management systems, including in-app purchase content and incremental update.",content-based multi-platform app forge
1442,2-s2.0-84957543349,10.1109/APNOMS.2015.7275363,An efficient scheme of bulk traffic statistics collection for software-defined networks,Wang T.H.,"17th Asia-Pacific Network Operations and Management Symposium: Managing a Very Connected World, APNOMS 2015",2015-09-24,"Along with the widespread development of Internet and mobile applications, the demand for more flexible and dynamic networking services increases. It becomes a new challenge for many carriers to deploy a variety of new services by effective provisioning of network resources. Software-Defined Networking (SDN) is a novel approach to make networks reconfigurable and extensible such that new services can be deployed with existing network devices. By decoupling the controller plane from the data plane in network devices, SDN brings networks programmability of the data plane and centralization of the controller plane. Conventional Operations Support Systems (OSSs) were developed to manage networks in a standard fashion with Simple Network Management Protocol (SNMP) or proprietary protocols. SDN provides a new framework in managing SDN-enabled devices. A new issue for carriers is how SDN-enabled networks and devices can be monitored and controlled by current OSSs. This paper focuses on performance management and aims to develop an efficient scheme to collect traffic statistics data via the SDN controller plane. Similar to Bulkstat, an SNMP-based mechanism for periodic collection and transfer of MIB objects, the proposed scheme for bulk traffic statistics collection is developed in the controller plane and provides a northbound interface for upper network management applications. Instead of using SNMP and MIBs, the scheme is implemented by periodically gathering statistics information of flow tables from SDN-enabled switches via the OpenFlow protocol.",Network Management | OpenFlow | SDN | Traffic Statistics,1,360-363,Conference Proceeding,Conference Paper,6.0,"Wang, Tse Han;Chen, Yen Cheng;Huang, Sheng Kai;Hsu, Chen Min;Liao, Been Huang;Young, Hey Chyi",57102040700;7601447119;57102107900;36604418100;7102657016;37007218000,Chunghwa Telecom Co. Ltd.;National Chi Nan University,Taiwan;Taiwan,"along with the widespread development of internet and mobile applications, the demand for more flexible and dynamic networking services increases. it becomes a new challenge for many carriers to deploy a variety of new services by effective provisioning of network resources. software-defined networking (sdn) is a novel approach to make networks reconfigurable and extensible such that new services can be deployed with existing network devices. by decoupling the controller plane from the data plane in network devices, sdn brings networks programmability of the data plane and centralization of the controller plane. conventional operations support systems (osss) were developed to manage networks in a standard fashion with simple network management protocol (snmp) or proprietary protocols. sdn provides a new framework in managing sdn-enabled devices. a new issue for carriers is how sdn-enabled networks and devices can be monitored and controlled by current osss. this paper focuses on performance management and aims to develop an efficient scheme to collect traffic statistics data via the sdn controller plane. similar to bulkstat, an snmp-based mechanism for periodic collection and transfer of mib objects, the proposed scheme for bulk traffic statistics collection is developed in the controller plane and provides a northbound interface for upper network management applications. instead of using snmp and mibs, the scheme is implemented by periodically gathering statistics information of flow tables from sdn-enabled switches via the openflow protocol.",an efficient scheme of bulk traffic statistics collection for software-defined networks
1443,2-s2.0-84946213346,10.1109/ICACCI.2015.7275865,Telemedicine for emergency care management using WebRTC,Vidul A.P.,"2015 International Conference on Advances in Computing, Communications and Informatics, ICACCI 2015",2015-09-24,"With the rapid advancement and development in the field of real time communications, telemedicine has reached great heights and had helped save millions of lives during emergency situations. The use of telemedicine is longstanding but its application in emergency care management is still in its developmental stage. Currently there are several emergency telemedicine systems available in the market that uses up-to-date vehicle electronics, latest telecommunications technology and specialized software. However these systems are highly sophisticated, bulky, and expensive and are employed by very few health centers. Thus these life saving services are not available to large portion of the population especially those living in the rural areas. The aim of this paper is to come up with a new idea where these Tele Emergency services can be implemented in a much efficient, economical and less sophisticated manner so that these services can be provided widely. Here we propose a new Emergency Telemedicine Application for emergency care management which uses WebRTC for real time communication. This system just requires a mobile device with internet connection with either chrome or Mozilla browser installed in it. The device is carried within the ambulance to conduct an initial assessment of the patient and later brought to the nearest health center where further treatment is carried under the assistance of specialists whose telepresence is provided by WebRTC enabled devices.",File transfe | P2P | Telemedicine | Telepresence | WebRTC,5,1741-1745,Conference Proceeding,Conference Paper,5.0,"Vidul, A. P.;Hari, Shibin;Pranave, K. P.;Vysakh, K. J.;Archana, K. R.",56943458000;57212073056;56943397500;56943506900;56406149300,"Amrita University, Amritapuri Campus",India,"with the rapid advancement and development in the field of real time communications, telemedicine has reached great heights and had helped save millions of lives during emergency situations. the use of telemedicine is longstanding but its application in emergency care management is still in its developmental stage. currently there are several emergency telemedicine systems available in the market that uses up-to-date vehicle electronics, latest telecommunications technology and specialized software. however these systems are highly sophisticated, bulky, and expensive and are employed by very few health centers. thus these life saving services are not available to large portion of the population especially those living in the rural areas. the aim of this paper is to come up with a new idea where these tele emergency services can be implemented in a much efficient, economical and less sophisticated manner so that these services can be provided widely. here we propose a new emergency telemedicine application for emergency care management which uses webrtc for real time communication. this system just requires a mobile device with internet connection with either chrome or mozilla browser installed in it. the device is carried within the ambulance to conduct an initial assessment of the patient and later brought to the nearest health center where further treatment is carried under the assistance of specialists whose telepresence is provided by webrtc enabled devices.",telemedicine for emergency care management using webrtc
1445,2-s2.0-84960372496,10.1109/Agro-Geoinformatics.2015.7248124,"Crop-planning, making smarter agriculture with climate data",Grajales D.F.P.,"2015 4th International Conference on Agro-Geoinformatics, Agro-Geoinformatics 2015",2015-09-09,"Agriculture has an important tradition in Latin America and large areas have maintained stable conditions for decades with constant practices and yield. Planning processes in those areas have not suffered any change for years and some countries like Colombia have not modified its rural policies in the last three of four decades; on the other hand, natural and environmental conditions have changed dramatically in the last years as a consequence of climate change and climate variability modifying established practices for traditional crops. Since farmers have suffered several effects on its production process they have realized the importance of supporting future actions on reliable climate data, scientific development have also grown in last decades and planning offices are looking for better practices, today' scientists and planning offices are trying to link all this reality in a new paradigm called 'Climate Smart Agriculture'. The Research program on Climate Change, Agriculture and Food Security-CCAFS follows this interest of linking its research results with open data sources, software developers and Latin American problems therefore in 2014 they performed a hackathon in Lima to develop new applications that help farmers to support their decision on scientific information. 'Crop-planning' is one product designed and developed at CCAFS's hackathon conceived as a worldwide platform for sharing and sowing crop calendars and agro-climate data, it compiles open dataset like historical production, land cover, local climate conditions and integrates an interface for crowdsourced collection of dates of agricultural activities, it is designed to offer easy access to relevant data and updated crop calendars from farmers and also share management practices from local authorities. Although it is farmer oriented, principal users are technical assistants that deal with the application and share knowledge with farmers, they will use their experience to warranty knowledge management and overcome technical difficulties of web and mobile platforms in rural areas.",analysis | climate change | crop calendar | crowdsource | knowledge management | open platform | planning,5,240-244,Conference Proceeding,Conference Paper,5.0,"Grajales, Diego Fabian Pajarito;Mejia, Fabian;Mosquera, Geidy Jhoana Asprilla;Piedrahita, Leonardo Cardona;Basurto, Cesar",56412927900;57220376947;57163322900;57163477800;55018060900,CCAFS,Colombia,"agriculture has an important tradition in latin america and large areas have maintained stable conditions for decades with constant practices and yield. planning processes in those areas have not suffered any change for years and some countries like colombia have not modified its rural policies in the last three of four decades; on the other hand, natural and environmental conditions have changed dramatically in the last years as a consequence of climate change and climate variability modifying established practices for traditional crops. since farmers have suffered several effects on its production process they have realized the importance of supporting future actions on reliable climate data, scientific development have also grown in last decades and planning offices are looking for better practices, today' scientists and planning offices are trying to link all this reality in a new paradigm called 'climate smart agriculture'. the research program on climate change, agriculture and food security-ccafs follows this interest of linking its research results with open data sources, software developers and latin american problems therefore in 2014 they performed a hackathon in lima to develop new applications that help farmers to support their decision on scientific information. 'crop-planning' is one product designed and developed at ccafs's hackathon conceived as a worldwide platform for sharing and sowing crop calendars and agro-climate data, it compiles open dataset like historical production, land cover, local climate conditions and integrates an interface for crowdsourced collection of dates of agricultural activities, it is designed to offer easy access to relevant data and updated crop calendars from farmers and also share management practices from local authorities. although it is farmer oriented, principal users are technical assistants that deal with the application and share knowledge with farmers, they will use their experience to warranty knowledge management and overcome technical difficulties of web and mobile platforms in rural areas.","crop-planning, making smarter agriculture with climate data"
1446,2-s2.0-85027946886,10.1007/s12145-014-0175-1,A semantically enabled metadata repository for scientific data,Wilson A.,Earth Science Informatics,2015-09-05,"The LASP Extended Metadata Repository (LEMR) is a semantically enabled repository of information (metadata) about the scientific datasets that LASP offers to the public. The repository enables the provision of consistent, current, verified metadata to our users. It serves as a Single Source of Truth for this information, enabling more rigorous metadata management and addressing problems related to duplication of information. The linked open data aspect of the repository allows interlinking of concepts both within and across organizations and web sites. Associated interfaces allow users to browse and search the metadata. This information can be dynamically incorporated into web pages, so web page content is always up-to-date and consistent across the lab. With this information we can generate metadata records in a variety of schemas, such as ISO or SPASE, allowing federation with other organizations interested in our data. We leveraged open source technologies to build the repository and the dynamic web pages that read from it. VIVO, an open source semantic web application, provided key capabilities such as ontology and triple store management interfaces. AngularJS, an open source JavaScript framework for building web dynamic applications, was also invaluable in developing web pages that provide semantically enabled public interfaces to the metadata. In this paper we discuss our use of these tools and what we had to craft in order to meet our lab-specific needs.",Dynamic | eScience | Infrastructure | Metadata | Ontology | Repository | Semantic,4,649-661,Journal,Article,5.0,"Wilson, Anne;Cox, Michael;Elsborg, Don;Lindholm, Doug;Traver, Tyler",55458737400;57195452688;57195450803;7103271486;57195455123,University of Colorado Boulder,United States,"the lasp extended metadata repository (lemr) is a semantically enabled repository of information (metadata) about the scientific datasets that lasp offers to the public. the repository enables the provision of consistent, current, verified metadata to our users. it serves as a single source of truth for this information, enabling more rigorous metadata management and addressing problems related to duplication of information. the linked open data aspect of the repository allows interlinking of concepts both within and across organizations and web sites. associated interfaces allow users to browse and search the metadata. this information can be dynamically incorporated into web pages, so web page content is always up-to-date and consistent across the lab. with this information we can generate metadata records in a variety of schemas, such as iso or spase, allowing federation with other organizations interested in our data. we leveraged open source technologies to build the repository and the dynamic web pages that read from it. vivo, an open source semantic web application, provided key capabilities such as ontology and triple store management interfaces. angularjs, an open source javascript framework for building web dynamic applications, was also invaluable in developing web pages that provide semantically enabled public interfaces to the metadata. in this paper we discuss our use of these tools and what we had to craft in order to meet our lab-specific needs.",a semantically enabled metadata repository for scientific data
1447,2-s2.0-85116099141,10.1145/2799250.2799290,Skyline: A Rapid Prototyping Driving Simulator for User Experience,Alvarez I.,"Adjunct Proceedings of the 7th International Conference on Automotive User Interfaces and Interactive VehicularApplications, AutomotiveUI 2015",2015-09-01,"This paper introduces Skyline, a user experience prototyping platform for automotive, developed in Intel Labs to enable rapid iterative development of in-vehicle experiences. The paper describes the hardware and software components of Skyline. It highlights the flexibility of the interior HMI configuration and the accessibility of the development platform, based on open source Web technologies such as JavaScript, CSS, Node.js and MQTT. The paper steps through the development and user testing processes for a cockpit experience with Skyline, illustrating the benefits of capturing early qualitative user feedback as support for rapid prototyping. Finally, the paper outlines the potential benefits of high fidelity assets developed on the platform for both industry and academia, and the enormous value that documented user experience HMI assets can have for in-vehicle feature productization and research.",Design Thinking | Driving Simulator | Rapid Prototyping | Skyline | User Experience,26,101-108,Conference Proceeding,Conference Paper,3.0,"Alvarez, Ignacio;Rumbel, Laura;Adams, Robert",56185106600;57193240993;55769745423,Intel Corporation,United States,"this paper introduces skyline, a user experience prototyping platform for automotive, developed in intel labs to enable rapid iterative development of in-vehicle experiences. the paper describes the hardware and software components of skyline. it highlights the flexibility of the interior hmi configuration and the accessibility of the development platform, based on open source web technologies such as javascript, css, node.js and mqtt. the paper steps through the development and user testing processes for a cockpit experience with skyline, illustrating the benefits of capturing early qualitative user feedback as support for rapid prototyping. finally, the paper outlines the potential benefits of high fidelity assets developed on the platform for both industry and academia, and the enormous value that documented user experience hmi assets can have for in-vehicle feature productization and research.",skyline: a rapid prototyping driving simulator for user experience
1448,2-s2.0-84928708378,10.1007/s11219-014-9239-1,The fine art of user-centered software development,Peischl B.,Software Quality Journal,2015-09-01,"In this article, we report on the user-centered development of a mobile medical app under limited resources. We discuss (non-functional) quality attributes that we used to choose the platform for development of the medical app. As the major contribution, we show how to integrate user-centered design in an early stage of mobile app development under the presence of limited resources. Moreover, we present empirical results gained from our two-stage testing procedure including recommendations to provide both a useful and useable business app.",Mobile software quality | Mobile usability | Software engineering process | Usability | User-centered design,16,509-536,Journal,Article,3.0,"Peischl, Bernhard;Ferk, Michaela;Holzinger, Andreas",6507036919;55931376900;23396282000,Medizinische Universität Graz;Void;FERK Systems GmbH,Austria;Austria;Austria,"in this article, we report on the user-centered development of a mobile medical app under limited resources. we discuss (non-functional) quality attributes that we used to choose the platform for development of the medical app. as the major contribution, we show how to integrate user-centered design in an early stage of mobile app development under the presence of limited resources. moreover, we present empirical results gained from our two-stage testing procedure including recommendations to provide both a useful and useable business app.",the fine art of user-centered software development
1450,2-s2.0-84937978540,10.1007/s10278-015-9781-9,Improving Radiology Report Quality by Rapidly Notifying Radiologist of Report Errors,Minn M.,Journal of Digital Imaging,2015-08-26,"Radiology report errors occur for many reasons including the use of pre-filled report templates, wrong-word substitution, nonsensical phrases, and missing words. Reports may also contain clinical errors that are not specific to the speech recognition including wrong laterality and gender-specific discrepancies. Our goal was to create a custom algorithm to detect potential gender and laterality mismatch errors and to notify the interpreting radiologists for rapid correction. A JavaScript algorithm was devised to flag gender and laterality mismatch errors by searching the text of the report for keywords and comparing them to parameters within the study’s HL7 metadata (i.e., procedure type, patient sex). The error detection algorithm was retrospectively applied to 82,353 reports 4 months prior to its development and then prospectively to 309,304 reports 15 months after implementation. Flagged reports were reviewed individually by two radiologists for a true gender or laterality error and to determine if the errors were ultimately corrected. There was significant improvement in the number of flagged reports (pre, 198/82,353 [0.24 %]; post, 628/309,304 [0.20 %]; P = 0.04) and reports containing confirmed gender or laterality errors (pre, 116/82,353 [0.014 %]; post, 285/309,304 [0.09 %]; P < 0.0001) after implementing our error notification system. The number of flagged reports containing an error that were ultimately corrected improved dramatically after implementing the notification system (pre, 17/116 [15 %]; post, 239/285 [84 %]; P < 0.0001). We developed a successful automated tool for detecting and notifying radiologists of potential gender and laterality errors, allowing for rapid report correction and reducing the overall rate of report errors.",Gender mismatch | Health Level 7 (HL7) | Laterality | Patient safety | Quality control | Radiology reporting | Software design,14,492-498,Journal,Article,3.0,"Minn, Matthew J.;Zandieh, Arash R.;Filice, Ross W.",56524420900;56188680700;22979170300,MedStar Georgetown University Hospital,United States,"radiology report errors occur for many reasons including the use of pre-filled report templates, wrong-word substitution, nonsensical phrases, and missing words. reports may also contain clinical errors that are not specific to the speech recognition including wrong laterality and gender-specific discrepancies. our goal was to create a custom algorithm to detect potential gender and laterality mismatch errors and to notify the interpreting radiologists for rapid correction. a javascript algorithm was devised to flag gender and laterality mismatch errors by searching the text of the report for keywords and comparing them to parameters within the study’s hl7 metadata (i.e., procedure type, patient sex). the error detection algorithm was retrospectively applied to 82,353 reports 4 months prior to its development and then prospectively to 309,304 reports 15 months after implementation. flagged reports were reviewed individually by two radiologists for a true gender or laterality error and to determine if the errors were ultimately corrected. there was significant improvement in the number of flagged reports (pre, 198/82,353 [0.24 %]; post, 628/309,304 [0.20 %]; p = 0.04) and reports containing confirmed gender or laterality errors (pre, 116/82,353 [0.014 %]; post, 285/309,304 [0.09 %]; p < 0.0001) after implementing our error notification system. the number of flagged reports containing an error that were ultimately corrected improved dramatically after implementing the notification system (pre, 17/116 [15 %]; post, 239/285 [84 %]; p < 0.0001). we developed a successful automated tool for detecting and notifying radiologists of potential gender and laterality errors, allowing for rapid report correction and reducing the overall rate of report errors.",improving radiology report quality by rapidly notifying radiologist of report errors
1451,2-s2.0-84949988868,10.1109/ICACT.2015.7224903,Academic laboratory website development,Otsuka S.,"International Conference on Advanced Communication Technology, ICACT",2015-08-25,"The Internet is an important source to get information about everything in human lives. Developing websites is one of the best ways to give information to people. Nowadays, there is a rapidly growing number of websites for many purposes. The websites of university laboratories are the examples. Usually university laboratories have websites to provide information to students, laboratory members, visitors, etc. Our research goal is to investigate a methodology of the high quality development of an academic laboratory website by a small number of developers in a short period of time. In this paper, we discuss approaches, methods, and technologies used in this development. We illustrate utilized methods by samples of the code. Key findings in this research include bilingual support without reloading pages, multi-device support and a technique of the second server usage to avoid restrictions for the official web server. Our findings were used to develop a new website of the software engineering laboratory of the University of Aizu. Our created from scratch website within two months would attract visitors.",Responsive Web Design | Website Development,1,791-794,Conference Proceeding,Conference Paper,3.0,"Otsuka, Shohei;Kato, Keisuke;Klyuev, Vitaly",57004428000;56008028800;27168308600,The University of Aizu,Japan,"the internet is an important source to get information about everything in human lives. developing websites is one of the best ways to give information to people. nowadays, there is a rapidly growing number of websites for many purposes. the websites of university laboratories are the examples. usually university laboratories have websites to provide information to students, laboratory members, visitors, etc. our research goal is to investigate a methodology of the high quality development of an academic laboratory website by a small number of developers in a short period of time. in this paper, we discuss approaches, methods, and technologies used in this development. we illustrate utilized methods by samples of the code. key findings in this research include bilingual support without reloading pages, multi-device support and a technique of the second server usage to avoid restrictions for the official web server. our findings were used to develop a new website of the software engineering laboratory of the university of aizu. our created from scratch website within two months would attract visitors.",academic laboratory website development
1452,2-s2.0-84959287295,10.1109/SACI.2015.7208207,Trends and followers in GUI development for business applications with implications at University Education,Selmeci A.,"SACI 2015 - 10th Jubilee IEEE International Symposium on Applied Computational Intelligence and Informatics, Proceedings",2015-08-17,"We have made a short review on the GUI technologies used in the business world and their impact on Education. Starting from mainframe user interfaces, through the different client-server architectures we show the trends, what kind of surfaces the end-users would like to use. We discuss the reasons why the trends could not always be followed by different kind of systems. Even if such novelties are not accepted by Business, involving them in Education might be advantageous. The goal of this paper is to show the evolution in willing and realization of different approaches and also their affect in learning both at Company and at University level. We mainly focus on HTML based GUIs as well to emphasize the already traditional new era. Our paper collects the evolution of HTML capabilities and the current achievements as well to show the difference between smaller and larger software development companies. As an example we follow the available GUIs offered by one of the leading ERP manufacturers and show the education possibilities, requirements in the different evolution stepping-stones.",client-server | Education | Graphical User Interface | HTML | JavaScript | PHP | Toolkit,4,243-251,Conference Proceeding,Conference Paper,2.0,"Selmeci, A.;Orosz, T.",55365336900;55903395300,Obuda University,Hungary,"we have made a short review on the gui technologies used in the business world and their impact on education. starting from mainframe user interfaces, through the different client-server architectures we show the trends, what kind of surfaces the end-users would like to use. we discuss the reasons why the trends could not always be followed by different kind of systems. even if such novelties are not accepted by business, involving them in education might be advantageous. the goal of this paper is to show the evolution in willing and realization of different approaches and also their affect in learning both at company and at university level. we mainly focus on html based guis as well to emphasize the already traditional new era. our paper collects the evolution of html capabilities and the current achievements as well to show the difference between smaller and larger software development companies. as an example we follow the available guis offered by one of the leading erp manufacturers and show the education possibilities, requirements in the different evolution stepping-stones.",trends and followers in gui development for business applications with implications at university education
1457,2-s2.0-84961383027,10.1109/MECO.2015.7181952,Wheelchair maneuvering using leap motion controller and cloud based speech control: Prototype realization,Skraba A.,"Proceedings - 2015 4th Mediterranean Conference on Embedded Computing, MECO 2015 - Including ECyPS 2015, BioEMIS 2015, BioICT 2015, MECO-Student Challenge 2015",2015-08-06,"The paper describes the development of prototype wheelchair platform controlled by the gestures. Leap Motion Controller is used to acquire data while changing the hand position. The novel user interface was developed, which shows the hand position to the user and combines the classical button GUI switchboard. The developed system is cloud based and integrates speech recognition to engage the motion controller as well as to control the entire platform if needed. The entire software was developed with JavaScript/ECMA Script.",Arduino | cyber-physical system | devices for rehabilitation | ECMA Script | gesture recognition | HTML5 | JavaScript | leap motion controller | natural user interface | node.js | speech recognition | wheelchair,10,391-394,Conference Proceeding,Conference Paper,4.0,"Skraba, Andrej;Kolozvari, Andrej;Kofjac, Davorin;Stojanović, Radovan",8530587400;56429626900;8530587500;7003903082,University of Montenegro;Univerza v Mariboru,Montenegro;Slovenia,"the paper describes the development of prototype wheelchair platform controlled by the gestures. leap motion controller is used to acquire data while changing the hand position. the novel user interface was developed, which shows the hand position to the user and combines the classical button gui switchboard. the developed system is cloud based and integrates speech recognition to engage the motion controller as well as to control the entire platform if needed. the entire software was developed with javascript/ecma script.",wheelchair maneuvering using leap motion controller and cloud based speech control: prototype realization
1460,2-s2.0-84982855913,10.1145/2791060.2791092,Choosy and picky: Configuration of language product lines,Kühn T.,ACM International Conference Proceeding Series,2015-07-20,"Although most programming languages naturally share several language features, they are typically implemented as a monolithic product. Language features cannot be plugged and unplugged from a language and reused in another language. Some modular approaches to language construction do exist but composing language features requires a deep understanding of its implementation hampering their use. The choose and pick approach from software product lines provides an easy way to compose a language out of a set of language features. However, current approaches to language product lines are not sufficient enough to cope with the complexity and evolution of real world programming languages. In this work, we propose a general light-weight bottom-up approach to automatically extract a feature model from a set of tagged language components. We applied this approach to the Neverlang language development framework and developed the AiDE tool to guide language developers towards a valid language composition. The approach has been evaluated on a decomposed version of Javascript to highlight the benefits of such a language product line.",Language composition | Language product lines,27,71-80,Conference Proceeding,Conference Paper,3.0,"Kühn, Thomas;Cazzola, Walter;Olivares, Diego Mathias",56333529900;6602449966;56152409000,Università degli Studi di Milano;Technische Universität Dresden,Italy;Germany,"although most programming languages naturally share several language features, they are typically implemented as a monolithic product. language features cannot be plugged and unplugged from a language and reused in another language. some modular approaches to language construction do exist but composing language features requires a deep understanding of its implementation hampering their use. the choose and pick approach from software product lines provides an easy way to compose a language out of a set of language features. however, current approaches to language product lines are not sufficient enough to cope with the complexity and evolution of real world programming languages. in this work, we propose a general light-weight bottom-up approach to automatically extract a feature model from a set of tagged language components. we applied this approach to the neverlang language development framework and developed the aide tool to guide language developers towards a valid language composition. the approach has been evaluated on a decomposed version of javascript to highlight the benefits of such a language product line.",choosy and picky: configuration of language product lines
1464,2-s2.0-84975757535,10.1145/2771783.2771787,Experience report: An empirical study of PHP security mechanism usage,Dahse J.,"2015 International Symposium on Software Testing and Analysis, ISSTA 2015 - Proceedings",2015-07-13,"The World Wide Web mainly consists of web applications written in weakly typed scripting languages, with PHP being the most popular language in practice. Empirical evidence based on the analysis of vulnerabilities suggests that security is often added as an ad-hoc solution, rather than planning a web application with security in mind during the design phase. Although some best-practice guidelines emerged, no comprehensive security standards are available for developers. Thus, developers often apply their flown favorite security mechanisms for data sanitization or validation to prohibit malicious input to a web application. In the context of our development of a new static code analysis tool for vulnerability detection, we studied commonly used input sanitization or validation mechanisms in 25 popular PHP applications. Our analysis of 2.5 million lines of code and over 26 thousand secured data flows provides a comprehensive overview of how developers utilize security mechanisms in practice regarding different markup contexts. In this paper, we discuss these security mechanisms in detail and reveal common pitfalls. For example, we found certain markup contexts and security mechanisms more frequently vulnerable than others. Our empirical study helps researchers, web developers, and tool developers to focus on error-prone markup contexts and security mechanisms in order to detect and mitigate vulnerabilities. Copyright is held by the owner/author(s).",Input sanitization | Input validation | PHP | Static analysis,5,60-70,Conference Proceeding,Conference Paper,2.0,"Dahse, Johannes;Holz, Thorsten",26021115300;53263832100,Ruhr-Universitat Bochum,Germany,"the world wide web mainly consists of web applications written in weakly typed scripting languages, with php being the most popular language in practice. empirical evidence based on the analysis of vulnerabilities suggests that security is often added as an ad-hoc solution, rather than planning a web application with security in mind during the design phase. although some best-practice guidelines emerged, no comprehensive security standards are available for developers. thus, developers often apply their flown favorite security mechanisms for data sanitization or validation to prohibit malicious input to a web application. in the context of our development of a new static code analysis tool for vulnerability detection, we studied commonly used input sanitization or validation mechanisms in 25 popular php applications. our analysis of 2.5 million lines of code and over 26 thousand secured data flows provides a comprehensive overview of how developers utilize security mechanisms in practice regarding different markup contexts. in this paper, we discuss these security mechanisms in detail and reveal common pitfalls. for example, we found certain markup contexts and security mechanisms more frequently vulnerable than others. our empirical study helps researchers, web developers, and tool developers to focus on error-prone markup contexts and security mechanisms in order to detect and mitigate vulnerabilities. copyright is held by the owner/author(s).",experience report: an empirical study of php security mechanism usage
1465,2-s2.0-85027941521,10.1109/TSG.2015.2394495,A Practical and Open Source Implementation of IEC 61850-7-2 for IED Monitoring Applications,Blair S.,IEEE Transactions on Smart Grid,2015-07-01,"A new open source mapping of IEC 61850-7-2 to web services has been defined and implemented. This letter describes work which is useful for rapidly implementing user interfaces - particularly web-based interfaces - for monitoring and controlling intelligent electronic devices from multiple vendors. The web service mapping has been implemented using the Hypertext Transfer Protocol, with a message format in JavaScript Object Notation. This approach requires a simple and ubiquitous software stack for its implementation, which is a significant advantage over existing client-server communications mappings. The use of an open source paradigm allows for the rapid iteration and refinement of the design, implementation, and testing of the internal details of the proposed protocol stack in a collaborative manner. These developments are of immediate interest to users of IEC 61850, and are particularly relevant to the IEC 61850 standardization process.",Automation and control | code generation | communications | IEC 61850 | IED monitoring | power system protection | rapid-prototyping | user interfaces,5,1992-1993,Journal,Article,2.0,"Blair, Steven M.;Booth, Campbell D.",36006297900;7203045827,University of Strathclyde,United Kingdom,"a new open source mapping of iec 61850-7-2 to web services has been defined and implemented. this letter describes work which is useful for rapidly implementing user interfaces - particularly web-based interfaces - for monitoring and controlling intelligent electronic devices from multiple vendors. the web service mapping has been implemented using the hypertext transfer protocol, with a message format in javascript object notation. this approach requires a simple and ubiquitous software stack for its implementation, which is a significant advantage over existing client-server communications mappings. the use of an open source paradigm allows for the rapid iteration and refinement of the design, implementation, and testing of the internal details of the proposed protocol stack in a collaborative manner. these developments are of immediate interest to users of iec 61850, and are particularly relevant to the iec 61850 standardization process.",a practical and open source implementation of iec 61850-7-2 for ied monitoring applications
1466,2-s2.0-85013063859,10.12785/IJCDS/040302,Cross-platform mobile applications with web technologies,Bouras C.,International Journal of Computing and Digital Systems,2015-07-01,"The extended use of smart mobile devices has become an integral part of daily life leading to the expansion of mobile application development. Currently, the majority of mobile applications are native applications that need an initial installation prior to being utilized. In addition, for a given application, a separate software development process could be required for each mobile platform, which subsequently increases dramatically the corresponding effort and cost. With the emergence of HTML5 these issues can be addressed efficiently, since web technologies allow the application development in a cross-platform manner. An important benefit is that users can have easy and immediate access the application without any need for downloading and installation. In this manuscript, we investigate the potentials of mobile application development with web technologies and we present a development framework that we have designed and implemented. This framework utilizes the most important state-of-art web technologies for the support of mobile devices. It can be used for the implementation of mobile web applications and also for the investigation and experimentation on the main features that HTML5 offers for this specific type of devices.",Cross-platform | Framework | HTML5 | Mobile web application | Social networks,6,153-163,Journal,Article,3.0,"Bouras, Christos;Papazois, Andreas;Stasinos, Nikolaos",7102164662;15060534300;56512429400,University of Patras;Computer Technology Institute,Greece;Greece,"the extended use of smart mobile devices has become an integral part of daily life leading to the expansion of mobile application development. currently, the majority of mobile applications are native applications that need an initial installation prior to being utilized. in addition, for a given application, a separate software development process could be required for each mobile platform, which subsequently increases dramatically the corresponding effort and cost. with the emergence of html5 these issues can be addressed efficiently, since web technologies allow the application development in a cross-platform manner. an important benefit is that users can have easy and immediate access the application without any need for downloading and installation. in this manuscript, we investigate the potentials of mobile application development with web technologies and we present a development framework that we have designed and implemented. this framework utilizes the most important state-of-art web technologies for the support of mobile devices. it can be used for the implementation of mobile web applications and also for the investigation and experimentation on the main features that html5 offers for this specific type of devices.",cross-platform mobile applications with web technologies
1467,2-s2.0-84961176908,10.1109/MS.2015.77,An Empirical Evaluation of Web-Based Fingerprinting,Khademi A.,IEEE Software,2015-07-01,"Adversaries employ sophisticated fingerprinting techniques to identify Web users and record their browsing history and Web interactions. Fingerprinting leaves no footprint on the browser and is invisible to general Web users, who often lack basic knowledge of it. An analysis of fingerprinting techniques and tools revealed the fingerprinting workflow. This helped define fine-grained properties that precisely model the workflow, allowing development of a client-side fingerprinting-detection tool. This article is part of a special issue on Security and Privacy on the Web.",Browsers | Entropy | Fingerprint recognition | fingerprinting | Fybrid | iFybrid | Navigation | Privacy | Software development | software development | Software engineering | software engineering | user identification | Web privacy | Web services,13,46-52,Journal,Article,3.0,"Khademi, Amin Faiz;Zulkernine, Mohammad;Weldemariam, Komminist",57183940200;6506457317;23478544500,Queen’s University;IBM Research,Canada;United States,"adversaries employ sophisticated fingerprinting techniques to identify web users and record their browsing history and web interactions. fingerprinting leaves no footprint on the browser and is invisible to general web users, who often lack basic knowledge of it. an analysis of fingerprinting techniques and tools revealed the fingerprinting workflow. this helped define fine-grained properties that precisely model the workflow, allowing development of a client-side fingerprinting-detection tool. this article is part of a special issue on security and privacy on the web.",an empirical evaluation of web-based fingerprinting
1469,2-s2.0-84952044593,10.1145/2729094.2742636,An experimental project course to prepare students for agile web application development,Clark N.,"Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE",2015-06-22,"Commercial software development today is dominated by the dramatic growth of Web/Internet-delivered information, combined with development techniques that feature rapid creation of reliable, maintainable application software. Staying current with these technologies is a constant challenge in any computer science curriculum. This paper reports on a pilot project course for six computer science fourth-year undergraduates that addressed this challenge in a synergistic way, to the benefit both of the participating students and of a government sponsor. The project created a new, open-source implementation of the Common Map API (CMAPI). It was accomplished using agile development techniques, intensive team activities, and advice from an industry CMAPI expert. Three one-month ""sprints"" resulted in a working, open-source system that met the needs of the sponsor and provided an excellent learning experience for all concerned. The approach used should be considered for inclusion in every undergraduate computer science curriculum.",Agile development | Open source | Web application,1,81-86,Conference Proceeding,Conference Paper,3.0,"Clark, Nicholas K.;Pullen, John Mark;Bashioum, Christopher D.",42961113200;7005173164;57024071700,George Mason University;Defense Intelligence Information,United States;United States,"commercial software development today is dominated by the dramatic growth of web/internet-delivered information, combined with development techniques that feature rapid creation of reliable, maintainable application software. staying current with these technologies is a constant challenge in any computer science curriculum. this paper reports on a pilot project course for six computer science fourth-year undergraduates that addressed this challenge in a synergistic way, to the benefit both of the participating students and of a government sponsor. the project created a new, open-source implementation of the common map api (cmapi). it was accomplished using agile development techniques, intensive team activities, and advice from an industry cmapi expert. three one-month ""sprints"" resulted in a working, open-source system that met the needs of the sponsor and provided an excellent learning experience for all concerned. the approach used should be considered for inclusion in every undergraduate computer science curriculum.",an experimental project course to prepare students for agile web application development
1470,2-s2.0-84951986958,10.1145/2729094.2742606,Teacher perspectives on web design instruction,Muibi H.,"Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE",2015-06-22,"Web development is an inherently interdisciplinary field that offers a unique introductory path to computing prior to more traditional programming courses. While significant earlier work has investigated the challenges that novice web developers encounter, little research is available about teaching while coping with the field's considerable breadth. This paper reports findings from interviews with practicing web design instructors in secondary and post-secondary teaching environments. We present emergent themes related to recruitment strategies, student expectations, teaching techniques, and common challenges. We find significant effort is needed to cope with mismatches between students' expectations of what web design is and the HTML/CSS syntax-oriented view of the discipline often emphasized by teachers. We conclude with implications for new teaching tools that would help better sustain student motivation while equipping them with fundamental skills in web development.",K-12 teaching | Web design | Web development,2,231-236,Conference Proceeding,Conference Paper,3.0,"Muibi, Hauwa;Dorn, Brian;Park, Thomas H.",57023947900;16238267100;35273007300,University of Nebraska Omaha;Drexel University,United States;United States,"web development is an inherently interdisciplinary field that offers a unique introductory path to computing prior to more traditional programming courses. while significant earlier work has investigated the challenges that novice web developers encounter, little research is available about teaching while coping with the field's considerable breadth. this paper reports findings from interviews with practicing web design instructors in secondary and post-secondary teaching environments. we present emergent themes related to recruitment strategies, student expectations, teaching techniques, and common challenges. we find significant effort is needed to cope with mismatches between students' expectations of what web design is and the html/css syntax-oriented view of the discipline often emphasized by teachers. we conclude with implications for new teaching tools that would help better sustain student motivation while equipping them with fundamental skills in web development.",teacher perspectives on web design instruction
1471,2-s2.0-84937837597,10.1109/RCIS.2015.7128891,Evaluation of BehaviorMap: A user-centered behavior language,Wanderley F.,Proceedings - International Conference on Research Challenges in Information Science,2015-06-19,"In the software development process, one of the recurring problems is to ensure that the expectations of stakeholders are being met. These expectations must match the system's behavior and be present in the requirements specifications and models. The Requirements Engineering discipline studies how to capture, specify, validate and manage requirements. However, recent empirical studies show that stakeholders do not usually understand traditional requirements models. This paper focuses on the cognitive evaluation of a user-centered language called BehaviorMap that aims to specify behavioral user scenarios in a cognitive way, based on mind map modelling. This paper describes an experimental evaluation to verify the understandability of the BehaviorMap scenarios compared to the textual ones. The experiment gathered data from 15 individuals (naïve-users), with different backgrounds, that had to analyze 8 scenarios, being 4 graphical and 4 textual. To assess the participants' cognitive effort, it was used questionnaires. Also, the time effort to perform the tasks was measured. This experiment showed promising results for the BehaviorMap scenarios.",Agile Requirements | Behavior-Driven Design | Cognitive Effort | Mind Map Modelling | User-Centred Requirements,5,309-320,Conference Proceeding,Conference Paper,3.0,"Wanderley, Fernando;Silva, Antonio;Araujo, Joao",55389736500;57209868228;12802236400,Faculdade de Ciências e Tecnologia da Universidade Nova de Lisboa,Portugal,"in the software development process, one of the recurring problems is to ensure that the expectations of stakeholders are being met. these expectations must match the system's behavior and be present in the requirements specifications and models. the requirements engineering discipline studies how to capture, specify, validate and manage requirements. however, recent empirical studies show that stakeholders do not usually understand traditional requirements models. this paper focuses on the cognitive evaluation of a user-centered language called behaviormap that aims to specify behavioral user scenarios in a cognitive way, based on mind map modelling. this paper describes an experimental evaluation to verify the understandability of the behaviormap scenarios compared to the textual ones. the experiment gathered data from 15 individuals (naïve-users), with different backgrounds, that had to analyze 8 scenarios, being 4 graphical and 4 textual. to assess the participants' cognitive effort, it was used questionnaires. also, the time effort to perform the tasks was measured. this experiment showed promising results for the behaviormap scenarios.",evaluation of behaviormap: a user-centered behavior language
1472,2-s2.0-84930805131,10.1108/IJWIS-12-2014-0044,Client-server architecture for pre and post-processing of real problems involving two-dimensional generalized coordinates,Boas J.,International Journal of Web Information Systems,2015-06-15,"Purpose-The aim of this paper is to propose a Web environment for pre-processing and post-processing for 2D problems in generalized coordinate systems. Design/methodology/approach-The system consists of a Web service for client-server communication, a database for user information, simulation requests and results storage, a module of (for) calculation processing (front-end) and a graphical interface for visualization of discretized mesh (back-end). Findings-The Web system was able to model real problems and situations, where the user can describe the problem or upload a geometry file descriptor, generated from computer graphics software. The Web system, programmed for finite difference solutions, was able to generate a mesh from other complex methods, such as finite elements method, adapting it to the proposed Web system, respecting the finite difference mesh structure. Research limitations/implications-The proposed Web system is limited to solve partial differential equations by finite difference discretization. We need to study about refinement and parameters adaptations to solve partial differential equations simulated with other methods. Practical implications-The Web system includes implications for the development of a powerful real problems simulator, which is useful for computational physics researchers and engineers. The Web system uses several technologies, such as Primefaces, JavaScript, JQuery and HTML, to provide an interactive user interface. Originality/value-The main contribution of this work is the availability of a generic Web architecture for including other types of coordinate systems and to solve others partial differential equations. Moreover, this paper presents an extended version of the work presented in ICCSA 2014.",Advanced Web applications | Mobile computing for the Internet | Web architecture | Web data integration | Web databases,0,226-245,Journal,Article,4.0,"Boas, José Luiz Vilas;Matsunaga, Fabio Takeshi;Romeiro, Neyva Maria Lopes;Brancher, Jacques Duílio",56294939800;56293797000;6504036203;55602334400,Universidade Estadual de Londrina,Brazil,"purpose-the aim of this paper is to propose a web environment for pre-processing and post-processing for 2d problems in generalized coordinate systems. design/methodology/approach-the system consists of a web service for client-server communication, a database for user information, simulation requests and results storage, a module of (for) calculation processing (front-end) and a graphical interface for visualization of discretized mesh (back-end). findings-the web system was able to model real problems and situations, where the user can describe the problem or upload a geometry file descriptor, generated from computer graphics software. the web system, programmed for finite difference solutions, was able to generate a mesh from other complex methods, such as finite elements method, adapting it to the proposed web system, respecting the finite difference mesh structure. research limitations/implications-the proposed web system is limited to solve partial differential equations by finite difference discretization. we need to study about refinement and parameters adaptations to solve partial differential equations simulated with other methods. practical implications-the web system includes implications for the development of a powerful real problems simulator, which is useful for computational physics researchers and engineers. the web system uses several technologies, such as primefaces, javascript, jquery and html, to provide an interactive user interface. originality/value-the main contribution of this work is the availability of a generic web architecture for including other types of coordinate systems and to solve others partial differential equations. moreover, this paper presents an extended version of the work presented in iccsa 2014.",client-server architecture for pre and post-processing of real problems involving two-dimensional generalized coordinates
1473,2-s2.0-84982165953,10.1145/2771284.2771287,Combining type-analysis with points-to analysis for analyzing Java library source-code,Allen N.,"SOAP 2015 - Proceedings of the 4th ACM SIGPLAN International Workshop on State of the Art in Program Analysis, co-located with PLDI 2015",2015-06-14,"The predominant work in static program analysis is focused on whole program analysis assuming that the whole program is present at analysis time and the only unknowns are program inputs. However, for library designers it is of paramount importance to perform semantic checks via static program analysis tools without the presence of an application. The literature offers only little research on partial program analysis for object-oriented programming languages including Java. Analyzing libraries statically requires novel abstractions for all possible applications that are not known a-priori. In this work, we present a static program analysis technique that reasons about the state of the library by approximating the behaviour of all possible applications. The key contribution is (1) the combination of type-analysis with points-to analysis and (2) the development of a most-general application (MGA) as a type, which represents the interaction of the library with all possible applications.",Libraries | Static Analysis | Type-based abstraction,14,13-18,Conference Proceeding,Conference Paper,3.0,"Allen, Nicholas;Krishnan, Padmanabhan;Scholz, Bernhard",56585356200;55786323500;7005222534,Oracle Labs,Australia,"the predominant work in static program analysis is focused on whole program analysis assuming that the whole program is present at analysis time and the only unknowns are program inputs. however, for library designers it is of paramount importance to perform semantic checks via static program analysis tools without the presence of an application. the literature offers only little research on partial program analysis for object-oriented programming languages including java. analyzing libraries statically requires novel abstractions for all possible applications that are not known a-priori. in this work, we present a static program analysis technique that reasons about the state of the library by approximating the behaviour of all possible applications. the key contribution is (1) the combination of type-analysis with points-to analysis and (2) the development of a most-general application (mga) as a type, which represents the interaction of the library with all possible applications.",combining type-analysis with points-to analysis for analyzing java library source-code
1474,2-s2.0-84951779864,10.1145/2737924.2737957,Exploring and enforcing security guarantees via program dependence graphs,Johnson A.,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),2015-06-03,"We present PIDGIN, a program analysis and understanding tool that enables the specification and enforcement of precise applicationspecific information security guarantees. PIDGIN also allows developers to interactively explore the information flows in their applications to develop policies and investigate counter-examples. PIDGIN combines program dependence graphs (PDGs), which precisely capture the information flows in a whole application, with a custom PDG query language. Queries express properties about the paths in the PDG; because paths in the PDG correspond to information flows in the application, queries can be used to specify global security policies. PIDGIN is scalable. Generating a PDG for a 330k line Java application takes 90 seconds, and checking a policy on that PDG takes under 14 seconds. The query language is expressive, supporting a large class of precise, application-specific security guarantees. Policies are separate from the code and do not interfere with testing or development, and can be used for security regression testing. We describe the design and implementation of PIDGIN and report on using it: (1) to explore information security guarantees in legacy programs; (2) to develop and modify security policies concurrently with application development; and (3) to develop policies based on known vulnerabilities.",Application-specific security | Graph query language | Program dependence graph,15,291-302,Conference Proceeding,Conference Paper,4.0,"Johnson, Andrew;Waye, Lucas;Moore, Scott;Chong, Stephen",57209787239;35235654400;57202808728;7201660989,Harvard University,United States,"we present pidgin, a program analysis and understanding tool that enables the specification and enforcement of precise applicationspecific information security guarantees. pidgin also allows developers to interactively explore the information flows in their applications to develop policies and investigate counter-examples. pidgin combines program dependence graphs (pdgs), which precisely capture the information flows in a whole application, with a custom pdg query language. queries express properties about the paths in the pdg; because paths in the pdg correspond to information flows in the application, queries can be used to specify global security policies. pidgin is scalable. generating a pdg for a 330k line java application takes 90 seconds, and checking a policy on that pdg takes under 14 seconds. the query language is expressive, supporting a large class of precise, application-specific security guarantees. policies are separate from the code and do not interfere with testing or development, and can be used for security regression testing. we describe the design and implementation of pidgin and report on using it: (1) to explore information security guarantees in legacy programs; (2) to develop and modify security policies concurrently with application development; and (3) to develop policies based on known vulnerabilities.",exploring and enforcing security guarantees via program dependence graphs
1475,2-s2.0-84951147359,10.1145/2737924.2737957,Exploring and enforcing security guarantees via program dependence graphs,Johnson A.,ACM SIGPLAN Notices,2015-06-01,"We present PIDGIN, a program analysis and understanding tool that enables the specification and enforcement of precise applicationspecific information security guarantees. PIDGIN also allows developers to interactively explore the information flows in their applications to develop policies and investigate counter-examples. PIDGIN combines program dependence graphs (PDGs), which precisely capture the information flows in a whole application, with a custom PDG query language. Queries express properties about the paths in the PDG; because paths in the PDG correspond to information flows in the application, queries can be used to specify global security policies. PIDGIN is scalable. Generating a PDG for a 330k line Java application takes 90 seconds, and checking a policy on that PDG takes under 14 seconds. The query language is expressive, supporting a large class of precise, application-specific security guarantees. Policies are separate from the code and do not interfere with testing or development, and can be used for security regression testing. We describe the design and implementation of PIDGIN and report on using it: (1) to explore information security guarantees in legacy programs; (2) to develop and modify security policies concurrently with application development; and (3) to develop policies based on known vulnerabilities.",Application-specific security | Graph query language | Program dependence graph,23,291-302,Journal,Conference Paper,4.0,"Johnson, Andrew;Waye, Lucas;Moore, Scott;Chong, Stephen",57209787239;35235654400;57202808728;7201660989,Harvard University,United States,"we present pidgin, a program analysis and understanding tool that enables the specification and enforcement of precise applicationspecific information security guarantees. pidgin also allows developers to interactively explore the information flows in their applications to develop policies and investigate counter-examples. pidgin combines program dependence graphs (pdgs), which precisely capture the information flows in a whole application, with a custom pdg query language. queries express properties about the paths in the pdg; because paths in the pdg correspond to information flows in the application, queries can be used to specify global security policies. pidgin is scalable. generating a pdg for a 330k line java application takes 90 seconds, and checking a policy on that pdg takes under 14 seconds. the query language is expressive, supporting a large class of precise, application-specific security guarantees. policies are separate from the code and do not interfere with testing or development, and can be used for security regression testing. we describe the design and implementation of pidgin and report on using it: (1) to explore information security guarantees in legacy programs; (2) to develop and modify security policies concurrently with application development; and (3) to develop policies based on known vulnerabilities.",exploring and enforcing security guarantees via program dependence graphs
1476,2-s2.0-84936761350,10.1109/ITNG.2015.66,A Study of Test Techniques for Integration with Domain Driven Design,Santos E.C.S.,"Proceedings - 12th International Conference on Information Technology: New Generations, ITNG 2015",2015-05-26,"This paper presents an exploratory study on agile techniques for software testing Test-Driven Development and Behaviour-Driven Development for integration with the agile software development technique known as Domain-Driven Design. It also comprises a comparison between both test approaches, enhancing the strengths and weaknesses of each one. To make it feasible the integration proposal, an example of domain using Apache Isis framework was developed. According to the study performed, the possibility of creating an automatic test generator to make it agile the validation of entities attributes of the domain model was noted.",Apache Isis | Behaviour-Driven Development | Domain-Driven Development | Software Test | Test-Driven Development,5,373-378,Conference Proceeding,Conference Paper,3.0,"Santos, Eloisa Cristina Silva;Beder, Delano Medeiros;Penteado, Rosangela A.Dellosso",56714795400;7801375196;24436870900,Universidade Federal de São Carlos,Brazil,"this paper presents an exploratory study on agile techniques for software testing test-driven development and behaviour-driven development for integration with the agile software development technique known as domain-driven design. it also comprises a comparison between both test approaches, enhancing the strengths and weaknesses of each one. to make it feasible the integration proposal, an example of domain using apache isis framework was developed. according to the study performed, the possibility of creating an automatic test generator to make it agile the validation of entities attributes of the domain model was noted.",a study of test techniques for integration with domain driven design
1477,2-s2.0-84959469437,10.1145/2737166.2737178,A Component model to manage the heterogeneity and dynamism in mobile applications,Escoffier C.,"CBSE 2015 - Proceedings of the 18th International ACM SIGSOFT Symposium on Component-Based Software Engineering, Part of CompArch 2015",2015-05-04,"Today, the proliferation of mobile devices coupled with the widespread availability of the Internet is opening up new service opportunities in numerous areas. However, developing mobile applications turns out to be very challenging. Two major plagues are heterogeneity and the need for dynamic adaptation happening at runtime. Dealing with these aspects leads to several problems and impasses. In this paper, we present a service-oriented component model for the development of hybrid mobile applications. This model allows developers to produce mobile applications more efficiently and reduces maintenance costs. An in-depth evaluation on several industrial applications of this model is also presented showing its benefits.",Component Model | Dynamism | JavaScript | Mobile Application | Service-Oriented Computing,3,85-90,Conference Proceeding,Conference Paper,3.0,"Escoffier, Clément;Lalanda, Philippe;Gunalp, Ozan",22733866600;22734050600;55421095800,Laboratoire d'Informatique de Grenoble;Ubidreams,France;France,"today, the proliferation of mobile devices coupled with the widespread availability of the internet is opening up new service opportunities in numerous areas. however, developing mobile applications turns out to be very challenging. two major plagues are heterogeneity and the need for dynamic adaptation happening at runtime. dealing with these aspects leads to several problems and impasses. in this paper, we present a service-oriented component model for the development of hybrid mobile applications. this model allows developers to produce mobile applications more efficiently and reduces maintenance costs. an in-depth evaluation on several industrial applications of this model is also presented showing its benefits.",a component model to manage the heterogeneity and dynamism in mobile applications
1478,2-s2.0-84929667108,10.2350/14-11-1578-OA.1,Development of novel software to generate anthropometric norms at perinatal autopsy,Cain M.D.,Pediatric and Developmental Pathology,2015-05-01,"Fetal and infant autopsy yields information regarding cause of death and the risk of recurrence, and it provides closure for parents. A significant number of perinatal evaluations are performed by general practice pathologists or trainees, who often find them time-consuming and/or intimidating. We sought to create a program that would enable pathologists to conduct these examinations with greater ease and to produce reliable, informative reports. We developed software that automatically generates a set of expected anthropometric and organ weight ranges by gestational age (GA)/postnatal age (PA) and a correlative table with the GA/PA that best matches the observed anthropometry. The program highlights measurement and organ weight discrepancies, enabling users to identify abnormalities. Furthermore, a Web page provides options for exporting and saving the data. Pathology residents utilized the program to determine ease of usage and benefits. The average time using conventional methods (ie, reference books and Internet sites) was compared to the average time using our Web page. Average time for novice and experienced residents using conventional methods was 26.7 minutes and 15 minutes, respectively. Using the Web page program, these times were reduced to an average of 3.2 minutes (P < 0.046 and P < 0.02, respectively). Participants found our program simple to use and the corrective features beneficial. This novel application saves time and improves the quality of fetal and infant autopsy reports. The software allows data exportation to reports and data storage for future analysis. Finalization of our software to enable usage by both university and private practice groups is in progress.",Anthropometry | Autopsy measurements | Norms | Perinatal autopsy | Stillborn,6,203-209,Journal,Conference Paper,6.0,"Cain, Matthew D.;Siebert, Joseph R.;Iriabho, Egiebade;Gruneberg, Alexander;Almeida, Jonas S.;Faye-Petersen, Ona Marie",55915169700;7102262474;56653485400;55312430600;7203053525;6701736679,The University of Alabama at Birmingham;University of Washington,United States;United States,"fetal and infant autopsy yields information regarding cause of death and the risk of recurrence, and it provides closure for parents. a significant number of perinatal evaluations are performed by general practice pathologists or trainees, who often find them time-consuming and/or intimidating. we sought to create a program that would enable pathologists to conduct these examinations with greater ease and to produce reliable, informative reports. we developed software that automatically generates a set of expected anthropometric and organ weight ranges by gestational age (ga)/postnatal age (pa) and a correlative table with the ga/pa that best matches the observed anthropometry. the program highlights measurement and organ weight discrepancies, enabling users to identify abnormalities. furthermore, a web page provides options for exporting and saving the data. pathology residents utilized the program to determine ease of usage and benefits. the average time using conventional methods (ie, reference books and internet sites) was compared to the average time using our web page. average time for novice and experienced residents using conventional methods was 26.7 minutes and 15 minutes, respectively. using the web page program, these times were reduced to an average of 3.2 minutes (p < 0.046 and p < 0.02, respectively). participants found our program simple to use and the corrective features beneficial. this novel application saves time and improves the quality of fetal and infant autopsy reports. the software allows data exportation to reports and data storage for future analysis. finalization of our software to enable usage by both university and private practice groups is in progress.",development of novel software to generate anthropometric norms at perinatal autopsy
1481,2-s2.0-84929190784,10.1109/REV.2015.7087297,An HTML client for the Blackbody Radiation Lab,Kreiter C.,"Proceedings of 2015 12th International Conference on Remote Engineering and Virtual Instrumentation, REV 2015",2015-04-15,"The Blackbody Radiation Lab has been developed for students to experimentally learn about the physics of light. It is used as an anchor lab within the Go-Lab project. The lab hardware, which is controlled with LabVIEW software, has been made remotely accessible with the help of the LabVIEW Run-Time Engine. This implementation had some drawbacks in terms of accessibility, observability and user friendliness. The solution to this problem was found in the development of a client with HTML and JavaScript. With it no plug-ins are required any more. It allows access for multiple users at a time and enhances accessibility as well as the learning experience because the experimentation can now be followed over web cam.",Blackbody Radiation | Lab Client | LabVIEW | Online Laboratory | Remote Laboratory,4,230-234,Conference Proceeding,Conference Paper,3.0,"Kreiter, C.;Garbi Zutin, D.;Auer, M. E.",56134280600;25655698200;55089032400,Fachhochschule Kärnten,Austria,"the blackbody radiation lab has been developed for students to experimentally learn about the physics of light. it is used as an anchor lab within the go-lab project. the lab hardware, which is controlled with labview software, has been made remotely accessible with the help of the labview run-time engine. this implementation had some drawbacks in terms of accessibility, observability and user friendliness. the solution to this problem was found in the development of a client with html and javascript. with it no plug-ins are required any more. it allows access for multiple users at a time and enhances accessibility as well as the learning experience because the experimentation can now be followed over web cam.",an html client for the blackbody radiation lab
1482,2-s2.0-84929152937,10.1109/REV.2015.7087269,An update to the software architecture of the iLab Service Broker,Colbran S.,"Proceedings of 2015 12th International Conference on Remote Engineering and Virtual Instrumentation, REV 2015",2015-04-15,"The MIT iLab architecture (consisting of Lab Servers and Service Brokers) was designed in the 1990's and while the Lab Server was designed as a software service the same architectural approach was not adopted for the Service Broker. This paper reports on a redesign of the Service Broker as a software service, which is itself a collection of software services. In the process of this redesign it was decided to examine the API on the Lab Server and to support not only the existing Lab Server API (to maintain support for all existing iLab Lab Servers) but to concurrently support an alternative lightweight API based upon a RESTful architecture and to use JSON to encode the data. As these changes required a complete rewrite of the Service Broker code base, it was decided to experiment with an implementation of the services using Node.js-a popular approach to the implementation of servers in Javascript. The intention was to open up the code base to code developers normally associated with web development and not normally associated with the development of remote laboratories. A new software service named an 'agent' was developed that wraps around the service broker to allow programmable modification of requests. The agent also has the ability to serve up an interface to user clients. The use of agents has advantages over existing implementations because it allows customised authentication schemes (such as OAuth) as well as providing different user groups with unique Lab Clients to the same Lab Servers. Lab Clients no longer are served up through the Service Broker, but can reside anywhere on the Internet and access the Service Broker via access to a suitable agent. One outcome of these architectural changes has been the introduction of a simple integration of a remote laboratory in the Blackboard Learning Management System (LMS) using a Learning Tool Interoperability (LTI) module for user authentication.",iLab Service Broker | ISA | ISABM | MIT iLab | Node.js | Remote laboratories | Web Services,10,90-93,Conference Proceeding,Conference Paper,2.0,"Colbran, Samuel;Schulz, Mark",56641136900;7402485763,The University of Queensland,Australia,"the mit ilab architecture (consisting of lab servers and service brokers) was designed in the 1990's and while the lab server was designed as a software service the same architectural approach was not adopted for the service broker. this paper reports on a redesign of the service broker as a software service, which is itself a collection of software services. in the process of this redesign it was decided to examine the api on the lab server and to support not only the existing lab server api (to maintain support for all existing ilab lab servers) but to concurrently support an alternative lightweight api based upon a restful architecture and to use json to encode the data. as these changes required a complete rewrite of the service broker code base, it was decided to experiment with an implementation of the services using node.js-a popular approach to the implementation of servers in javascript. the intention was to open up the code base to code developers normally associated with web development and not normally associated with the development of remote laboratories. a new software service named an 'agent' was developed that wraps around the service broker to allow programmable modification of requests. the agent also has the ability to serve up an interface to user clients. the use of agents has advantages over existing implementations because it allows customised authentication schemes (such as oauth) as well as providing different user groups with unique lab clients to the same lab servers. lab clients no longer are served up through the service broker, but can reside anywhere on the internet and access the service broker via access to a suitable agent. one outcome of these architectural changes has been the introduction of a simple integration of a remote laboratory in the blackboard learning management system (lms) using a learning tool interoperability (lti) module for user authentication.",an update to the software architecture of the ilab service broker
1483,2-s2.0-84955465162,10.1145/2695664.2695917,Leveraging task-based data to support functional testing of web applications,Rezende De Jesus F.,Proceedings of the ACM Symposium on Applied Computing,2015-04-13,"Testing is paramount in order to assure the quality of a software product. Over the last years, several techniques have been proposed to leverage the testing phase as a simple and efficient step during software development. However, the features of the web environment make application testing fairly complex. The existing approaches for web application testing are usually driven to specific scenarios or application types, and few solutions are targeted for testing the functional requirements of applications. In order to tackle this problem, we propose a task-based testing approach that provides high coverage of functional requirements. Our technique consists of reassembling classical graph algorithms in order to generate all the possible paths for the execution of a task. Performed experiments indicate that our approach is effective for supporting the functional testing of web applications.",Graph algorithms | Tasks | Web application testing,0,783-790,Conference Proceeding,Conference Paper,3.0,"Rezende De Jesus, Flávio;De Vasconcelos, Leandro Guarino;Baldochi, Laércio A.",57076913800;55303275300;6504500597,Universidade Federal de Itajubá;Instituto Nacional de Pesquisas Espaciais,Brazil;Brazil,"testing is paramount in order to assure the quality of a software product. over the last years, several techniques have been proposed to leverage the testing phase as a simple and efficient step during software development. however, the features of the web environment make application testing fairly complex. the existing approaches for web application testing are usually driven to specific scenarios or application types, and few solutions are targeted for testing the functional requirements of applications. in order to tackle this problem, we propose a task-based testing approach that provides high coverage of functional requirements. our technique consists of reassembling classical graph algorithms in order to generate all the possible paths for the execution of a task. performed experiments indicate that our approach is effective for supporting the functional testing of web applications.",leveraging task-based data to support functional testing of web applications
1485,2-s2.0-84926513336,10.1002/pmic.201400377,Open source libraries and frameworks for biological data visualisation: A guide for developers,Wang R.,Proteomics,2015-04-01,"Recent advances in high-throughput experimental techniques have led to an exponential increase in both the size and the complexity of the data sets commonly studied in biology. Data visualisation is increasingly used as the key to unlock this data, going from hypothesis generation to model evaluation and tool implementation. It is becoming more and more the heart of bioinformatics workflows, enabling scientists to reason and communicate more effectively. In parallel, there has been a corresponding trend towards the development of related software, which has triggered the maturation of different visualisation libraries and frameworks. For bioinformaticians, scientific programmers and software developers, the main challenge is to pick out the most fitting one(s) to create clear, meaningful and integrated data visualisation for their particular use cases. In this review, we introduce a collection of open source or free to use libraries and frameworks for creating data visualisation, covering the generation of a wide variety of charts and graphs. We will focus on software written in Java, JavaScript or Python. We truly believe this software offers the potential to turn tedious data into exciting visual stories.",Bioinformatics | Chart | Hierarchy | Network | Software library,28,1356-1374,Journal,Review,4.0,"Wang, Rui;Perez-Riverol, Yasset;Hermjakob, Henning;Vizcaíno, Juan Antonio",56193626600;24598095700;6701613156;6603178595,European Bioinformatics Institute,United Kingdom,"recent advances in high-throughput experimental techniques have led to an exponential increase in both the size and the complexity of the data sets commonly studied in biology. data visualisation is increasingly used as the key to unlock this data, going from hypothesis generation to model evaluation and tool implementation. it is becoming more and more the heart of bioinformatics workflows, enabling scientists to reason and communicate more effectively. in parallel, there has been a corresponding trend towards the development of related software, which has triggered the maturation of different visualisation libraries and frameworks. for bioinformaticians, scientific programmers and software developers, the main challenge is to pick out the most fitting one(s) to create clear, meaningful and integrated data visualisation for their particular use cases. in this review, we introduce a collection of open source or free to use libraries and frameworks for creating data visualisation, covering the generation of a wide variety of charts and graphs. we will focus on software written in java, javascript or python. we truly believe this software offers the potential to turn tedious data into exciting visual stories.",open source libraries and frameworks for biological data visualisation: a guide for developers
1493,2-s2.0-84920281146,10.1016/j.compag.2014.12.005,Web generation of experimental designs balanced for indirect effects of treatments (WEB-DBIE),Jaggi S.,Computers and Electronics in Agriculture,2015-02-01,"Indirect effects are effects that occur in an experiment due to the units which are adjacent (spatially or temporally) to the unit being observed. Spatial indirect effects arise due to the treatments applied to the adjacent neighbouring units/plots and the designs so developed are called Neighbour Balanced Designs (NBDs). Whereas temporal indirect effects occur because of the carryover or residual effects in the periods following the periods of their direct application and the designs considering temporal effects are called Crossover Designs. A large number of such designs have been developed in the literature. For ready referencing and potential use of these designs, online software for generation of randomized layout of these designs is highly desirable. This paper describes the development of a web solution for generation of NBDs and Crossover Designs using client-server architecture along with an online catalogue of the designs within a permissible range. Designs generated through this software have wide applications in agricultural experiments, forestry and agro-forestry trials, polycross nurseries, serological experiments, animal nutritional trials, sensory evaluations, clinical trials, etc. WEB-DBIE is accessible any time from arbitrary platforms through internet. This software provides freely available solution for the researchers and students working in this area.",Crossover Designs | Indirect effects | Neighbour Balanced Designs | Randomization | Web generation of designs,5,62-68,Journal,Article,4.0,"Jaggi, Seema;Varghese, Cini;Varghese, Eldho;Sharma, Anu",7004561214;35583756200;35520524000;57214355813,"ICAR - Indian Agricultural Statistics Research Institute, New Delhi",India,"indirect effects are effects that occur in an experiment due to the units which are adjacent (spatially or temporally) to the unit being observed. spatial indirect effects arise due to the treatments applied to the adjacent neighbouring units/plots and the designs so developed are called neighbour balanced designs (nbds). whereas temporal indirect effects occur because of the carryover or residual effects in the periods following the periods of their direct application and the designs considering temporal effects are called crossover designs. a large number of such designs have been developed in the literature. for ready referencing and potential use of these designs, online software for generation of randomized layout of these designs is highly desirable. this paper describes the development of a web solution for generation of nbds and crossover designs using client-server architecture along with an online catalogue of the designs within a permissible range. designs generated through this software have wide applications in agricultural experiments, forestry and agro-forestry trials, polycross nurseries, serological experiments, animal nutritional trials, sensory evaluations, clinical trials, etc. web-dbie is accessible any time from arbitrary platforms through internet. this software provides freely available solution for the researchers and students working in this area.",web generation of experimental designs balanced for indirect effects of treatments (web-dbie)
1505,2-s2.0-84969814700,10.18293/SEKE2015-097,An empirical study on the impact of Python dynamic features on change-proneness,Wang B.,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",2015-01-01,"The dynamic features of programming languages are useful constructs that bring developers convenience and flexibility, but they are also perceived to lead to difficulties in software maintenance. Figuring out whether the use of dynamic features affects maintenance is significant for both researchers and practitioners, yet little work has been done to investigate it. In this paper, we conduct an empirical study to explore whether program source code files using dynamic features are more change-prone and whether particular categories of dynamic features are more correlated to change-proneness than others. To this end, we statically analyze historical data from 4 to 7 years of the development of seven open-source systems. We employ Fisher and Mann-Whitney hypothetical test methods, along with logistic regression model to solve three research questions. The results show that: (1) files with dynamic features are more change-prone, (2) files with a higher number of dynamic features are more change-prone, and (3) Introspection is shown to be more correlated to change-proneness than the other three categories in most systems. This innovative work can give some inspirations and references to researchers who are always focusing their eyes on how and why the dynamic features are used. For practitioners, we suggest them to be wary of files with dynamic features because they are more likely to be the subject of their maintenance effort.",Change-proneness | Dynamic features | Empirical software engineering | Open-source | Python,19,134-139,Conference Proceeding,Conference Paper,5.0,"Wang, Beibei;Chen, Lin;Ma, Wanwangying;Chen, Zhifei;Xu, Baowen",57189363514;57189042207;56949541600;55884919800;7404589262,Nanjing University,China,"the dynamic features of programming languages are useful constructs that bring developers convenience and flexibility, but they are also perceived to lead to difficulties in software maintenance. figuring out whether the use of dynamic features affects maintenance is significant for both researchers and practitioners, yet little work has been done to investigate it. in this paper, we conduct an empirical study to explore whether program source code files using dynamic features are more change-prone and whether particular categories of dynamic features are more correlated to change-proneness than others. to this end, we statically analyze historical data from 4 to 7 years of the development of seven open-source systems. we employ fisher and mann-whitney hypothetical test methods, along with logistic regression model to solve three research questions. the results show that: (1) files with dynamic features are more change-prone, (2) files with a higher number of dynamic features are more change-prone, and (3) introspection is shown to be more correlated to change-proneness than the other three categories in most systems. this innovative work can give some inspirations and references to researchers who are always focusing their eyes on how and why the dynamic features are used. for practitioners, we suggest them to be wary of files with dynamic features because they are more likely to be the subject of their maintenance effort.",an empirical study on the impact of python dynamic features on change-proneness
1506,2-s2.0-84962704779,10.1016/j.procs.2015.11.074,Compound Object Model for Scalable System Development in C++,Orlov S.,Procedia Computer Science,2015-01-01,"We present an object model that is the ground for several software products written by our team in C++ and used by our customers for over 10 years. The object model has allowed us to design software packages of many components and achieve high level of code reuse due to specific features of the model. Besides the object model, we also present several common infrastructure components that could be useful for the development of any general-purpose software system in C++.",C++ | component based system | framework | object model | object-oriented programming,1,651-660,Conference Proceeding,Conference Paper,2.0,"Orlov, Stepan;Melnikova, Natalia",50561895800;41661860300,"Saint Petersburg National Research University of Information Technologies, Mechanics and Optics University ITMO;Peter the Great St. Petersburg Polytechnic University",Russian Federation;Russian Federation,"we present an object model that is the ground for several software products written by our team in c++ and used by our customers for over 10 years. the object model has allowed us to design software packages of many components and achieve high level of code reuse due to specific features of the model. besides the object model, we also present several common infrastructure components that could be useful for the development of any general-purpose software system in c++.",compound object model for scalable system development in c++
1512,2-s2.0-84959360012,10.28945/2252,Learning by doing: How to develop a cross-platform web app,Huynh M.,Journal of Information Technology Education: Innovations in Practice,2015-01-01,"As mobile devices become prevalent, there is always a need for apps. How hard is it to develop an app, especially a cross-platform app? The paper shares an experience in a project that involved the development of a student services web app that can be run on cross-platform mobile devices. The paper first describes the background of the project, the clients, and the proposed solution. Then, it focuses on the step-by-step development processes and provides the illustration of written codes and techniques used. The goal is for readers to gain an understanding on how to develop a mobile-friendly web app. The paper concludes with teaching implications and offers thoughts for further development.",Cross platform app | CSS | HTML5 | JavaScript | Mobile-friendly web app | Open-source software | PHP | Web database | Web-app,6,145-169,Journal,Article,2.0,"Huynh, Minh;Ghimire, Prashant",7004928375;56814706600,Southeastern Louisiana University,United States,"as mobile devices become prevalent, there is always a need for apps. how hard is it to develop an app, especially a cross-platform app? the paper shares an experience in a project that involved the development of a student services web app that can be run on cross-platform mobile devices. the paper first describes the background of the project, the clients, and the proposed solution. then, it focuses on the step-by-step development processes and provides the illustration of written codes and techniques used. the goal is for readers to gain an understanding on how to develop a mobile-friendly web app. the paper concludes with teaching implications and offers thoughts for further development.",learning by doing: how to develop a cross-platform web app
1516,2-s2.0-84953859883,10.5277/E-INF150106,Model driven web engineering: A systematic mapping study,Wakil K.,E-Informatica Software Engineering Journal,2015-01-01,"Background: Model Driven Web Engineering (MDWE) is the application of the model driven paradigm to the domain of web software development, where it is particularly helpful because of the continuous evolution of Web technologies and platforms. Objective: In this paper, we prepare a survey of primary studies on MDWE to explore current work and identify needs for future research. Method: Systematic mapping study uses for finding the most relevant studies and classification. In this study, we found 289 papers and a classification scheme divided them depending on their research focus, contribution type and research type. Results: The papers of solution proposal (20%) research type are majority. The most focused areas of MDWE appear to be: Web Applicability (31%), Molding and Notation (19%), and Services and Oriented (18%). The majority of contributions are methods (33%). Moreover, this shows MDWE as a wide, new, and active area to publications. Conclusions: Whilst additional analysis is warranted within the MDWE scope, in literature, composition mechanisms have been thoroughly discoursed. Furthermore, we have witnessed that the recurrent recommendation for Validation Research, Solution Proposal and Philosophical Papers has been done through earlier analysis.",MDWE | Model driven web engineering | Systematic mapping study | Web engineering,11,107-142,Journal,Article,2.0,"Wakil, Karzan;Jawawi, Dayang N.A.",56102803300;15058008600,Universiti Teknologi Malaysia,Malaysia,"background: model driven web engineering (mdwe) is the application of the model driven paradigm to the domain of web software development, where it is particularly helpful because of the continuous evolution of web technologies and platforms. objective: in this paper, we prepare a survey of primary studies on mdwe to explore current work and identify needs for future research. method: systematic mapping study uses for finding the most relevant studies and classification. in this study, we found 289 papers and a classification scheme divided them depending on their research focus, contribution type and research type. results: the papers of solution proposal (20%) research type are majority. the most focused areas of mdwe appear to be: web applicability (31%), molding and notation (19%), and services and oriented (18%). the majority of contributions are methods (33%). moreover, this shows mdwe as a wide, new, and active area to publications. conclusions: whilst additional analysis is warranted within the mdwe scope, in literature, composition mechanisms have been thoroughly discoursed. furthermore, we have witnessed that the recurrent recommendation for validation research, solution proposal and philosophical papers has been done through earlier analysis.",model driven web engineering: a systematic mapping study
1518,2-s2.0-84950341232,10.1016/j.procs.2015.08.312,Unified distributed computing and co-ordination in pervasive/ubiquitous networks with mobile multi-agent systems using a modular and portable agent code processing platform,Bosse S.,Procedia Computer Science,2015-01-01,"A novel and unified approach for reliable distributed and parallel computing using mobile agents is introduced. The agents can be deployed in large scale and hierarchical network environments crossing barriers transparently. The networks can consist of high-and low-resource nodes ranging from generic computers to microchips, and the supported network classes range from body area networks to the Internet including any kind of sensor and ambient network. Agents are represented by mobile program code that can be modified at run-time. The presented approach enables the development of sensor clouds and smart systems of the future integrated in daily use computing environments and the Internet. Agents can migrate between different hardware and software platforms by migrating the program code of the agent, embedding the state and the data of an agent, too. The entire information exchange and coordination of agents with other agents and the environment is performed by using a tuple space database. Beside architecture specific hardware and software implementations of the agent processing platform, there is a JavaScript (JS) implementation layered on the top of a distributed management layer. The JS platform enables the integration of Multi-agent Systems (MAS) in Internet server and application environments (e.g., WEB browser). Agents can migrate transparently between hardware-level sensor networks and WEB browser applications or network servers and vice versa without any transformation required.",Agent processing platform | Cloud computing | Embedded systems | Heterogeneous networks | Mobile agents | Sensor networks,13,56-64,Conference Proceeding,Conference Paper,1.0,"Bosse, Stefan",6603212412,Universität Bremen,Germany,"a novel and unified approach for reliable distributed and parallel computing using mobile agents is introduced. the agents can be deployed in large scale and hierarchical network environments crossing barriers transparently. the networks can consist of high-and low-resource nodes ranging from generic computers to microchips, and the supported network classes range from body area networks to the internet including any kind of sensor and ambient network. agents are represented by mobile program code that can be modified at run-time. the presented approach enables the development of sensor clouds and smart systems of the future integrated in daily use computing environments and the internet. agents can migrate between different hardware and software platforms by migrating the program code of the agent, embedding the state and the data of an agent, too. the entire information exchange and coordination of agents with other agents and the environment is performed by using a tuple space database. beside architecture specific hardware and software implementations of the agent processing platform, there is a javascript (js) implementation layered on the top of a distributed management layer. the js platform enables the integration of multi-agent systems (mas) in internet server and application environments (e.g., web browser). agents can migrate transparently between hardware-level sensor networks and web browser applications or network servers and vice versa without any transformation required.",unified distributed computing and co-ordination in pervasive/ubiquitous networks with mobile multi-agent systems using a modular and portable agent code processing platform
1519,2-s2.0-84950316503,10.1145/2676726.2676994,Dependent information flow types,Lourenço L.,ACM SIGPLAN Notices,2015-01-01,"In this paper, we develop a novel notion of dependent information flow types. Dependent information flow types fit within the standard framework of dependent type theory, but, unlike usual dependent types, crucially allow the security level of a type, rather than just the structural data type itself, to depend on runtime values. Our dependent function and dependent sum information flow types provide a direct, natural and elegant way to express and enforce fine grained security policies on programs, including programs that manipulate structured data types in which the security level of a structure field may depend on values dynamically stored in other fields, still considered a challenge to security enforcement in software systems such as data-centric web-based applications. We base our development on the very general setting of a minimal λ-calculus with references and collections. We illustrate its expressiveness, showing how secure operations on relevant scenarios can be modelled and analysed using our dependent information flow type system, which is also shown to be amenable to algorithmic type checking. Our main results include type-safety and non-interference theorems ensuring that well-typed programs do not violate prescribed security policies.",Dependent type systems | Information flow,8,317-328,Journal,Conference Paper,2.0,"Lourenço, Luísa;Caires, Luís",55734635600;6602926067,Faculdade de Ciências e Tecnologia da Universidade Nova de Lisboa,Portugal,"in this paper, we develop a novel notion of dependent information flow types. dependent information flow types fit within the standard framework of dependent type theory, but, unlike usual dependent types, crucially allow the security level of a type, rather than just the structural data type itself, to depend on runtime values. our dependent function and dependent sum information flow types provide a direct, natural and elegant way to express and enforce fine grained security policies on programs, including programs that manipulate structured data types in which the security level of a structure field may depend on values dynamically stored in other fields, still considered a challenge to security enforcement in software systems such as data-centric web-based applications. we base our development on the very general setting of a minimal λ-calculus with references and collections. we illustrate its expressiveness, showing how secure operations on relevant scenarios can be modelled and analysed using our dependent information flow type system, which is also shown to be amenable to algorithmic type checking. our main results include type-safety and non-interference theorems ensuring that well-typed programs do not violate prescribed security policies.",dependent information flow types
1521,2-s2.0-84948971063,10.1007/978-3-319-21410-842,Native and multiple targeted mobile applications,Marinho E.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2015-01-01,Together with the expansion of the WWW we are seeing the expansion of mobile devices that are becoming more and more pervasive. Mobile application development is becoming more and more complex as users of mobile applications are demanding more high quality software. Our contribution is to frame the positive and negative aspects of native and multiple targeted mobile applications that should be considered by the involved stakeholders more particularly the software organization decision-makers.,Mobile application development | Multiple targeted development,4,544-558,Book Series,Conference Paper,2.0,"Marinho, Euler Horta;Resende, Rodolfo Ferreira",15044828800;22735751900,Universidade Federal de Minas Gerais;Universidade Federal de Ouro Preto,Brazil;Brazil,together with the expansion of the www we are seeing the expansion of mobile devices that are becoming more and more pervasive. mobile application development is becoming more and more complex as users of mobile applications are demanding more high quality software. our contribution is to frame the positive and negative aspects of native and multiple targeted mobile applications that should be considered by the involved stakeholders more particularly the software organization decision-makers.,native and multiple targeted mobile applications
1522,2-s2.0-84948421988,10.1016/j.procs.2015.07.331,Architecture and Implementation of Instant Messaging in Educational Institution,Yulianto B.,Procedia Computer Science,2015-01-01,"Development of communication technology on smartphones can be used to meet the needs of actual mass communication (real time chat), concise, and efficient in educational institutions, especially for students and lecturers. This research aims to produce architectural design and implementation of web and Android based instant messaging (IM) which can be applied to educational institutions as a fast, provident, and effective communication means. This study was conducted by collecting data through questionnaires distributed among the students and the lecturers. The IM application is developed based on Rational Unified Process (RUP) software development method. The architecture and IM application are XMPP protocol based that can be implemented on web and Android platform with personal chat, group chat, broadcast messages, scheduled messages, and file attachments features. The application can facilitate the communication from an educational institution to or between students and lecturers, and gather students and lecturers' phone number and email.",broadcast message | instant messaging | personal chat | real-time chat | scheduled message | xmpp,4,5-13,Conference Proceeding,Conference Paper,4.0,"Yulianto, Budi;Heriyanni, Eileen;Dewi, Lusiana Citra;Adinugroho, Timothy Yudi",6506615618;56979278300;55793446500;56979397100,Bina Nusantara University,Indonesia,"development of communication technology on smartphones can be used to meet the needs of actual mass communication (real time chat), concise, and efficient in educational institutions, especially for students and lecturers. this research aims to produce architectural design and implementation of web and android based instant messaging (im) which can be applied to educational institutions as a fast, provident, and effective communication means. this study was conducted by collecting data through questionnaires distributed among the students and the lecturers. the im application is developed based on rational unified process (rup) software development method. the architecture and im application are xmpp protocol based that can be implemented on web and android platform with personal chat, group chat, broadcast messages, scheduled messages, and file attachments features. the application can facilitate the communication from an educational institution to or between students and lecturers, and gather students and lecturers' phone number and email.",architecture and implementation of instant messaging in educational institution
1523,2-s2.0-84947237199,10.1007/978-3-319-21362-0_4,The relation tool in geogebra 5,Kovàcs Z.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2015-01-01,"GeoGebra is open source mathematics education software being used in thousands of schools worldwide. Its new version 5 supports automatic geometry theorem proving by using various methods which are already well known, but not widely used in education software. GeoGebra’s new embedded prover system chooses one of the available methods and translates the problem specified by the end user as the input for the selected method, similarly to portfolio solvers. The available methods include Wu’s method, the Buchberger-Kapur method, the Area method and Recio’s exact check method, some of them as embedded algorithms, others as outsourced computations. These methods can also be hidden from end users who are provided with an intuitive graphical user interface, the Relation Tool. Since GeoGebra maintains the development in an open-sourced way by collaborating with the OpenGeoProver, Singular and Giac projects, further enhancements can be expected by a larger community, including implementing other methods, too.",Automated theorem proving | Computer aided mathematics education | Computer algebra | GeoGebra | Portfolio solver,11,53-71,Book Series,Conference Paper,1.0,"Kovàcs, Zoltàn",57195240028,Johannes Kepler University Linz,Austria,"geogebra is open source mathematics education software being used in thousands of schools worldwide. its new version 5 supports automatic geometry theorem proving by using various methods which are already well known, but not widely used in education software. geogebra’s new embedded prover system chooses one of the available methods and translates the problem specified by the end user as the input for the selected method, similarly to portfolio solvers. the available methods include wu’s method, the buchberger-kapur method, the area method and recio’s exact check method, some of them as embedded algorithms, others as outsourced computations. these methods can also be hidden from end users who are provided with an intuitive graphical user interface, the relation tool. since geogebra maintains the development in an open-sourced way by collaborating with the opengeoprover, singular and giac projects, further enhancements can be expected by a larger community, including implementing other methods, too.",the relation tool in geogebra 5
1524,2-s2.0-84943570804,10.5220/0005540000660073,RCON: Dynamic mobile interfaces for command and control of ROS-enabled robots,Codd-Downey R.,"ICINCO 2015 - 12th International Conference on Informatics in Control, Automation and Robotics, Proceedings",2015-01-01,"The development of effective user interfaces for an autonomous system can be quite difficult, especially for devices that are to be operated in the field where access to standard computer platforms may be difficult or impossible. One approach in this type of environment is to utilize tablet or phone devices, which when coupled with an appropriate tool such as ROSBridge can be used to connect with standard robot middleware. This has proven to be a successful approach for devices with mature user interface requirements but may require significant software development for experimental systems. Here we describe RCON, a software tool that allows user interfaces on iOS devices to be configured on the device itself, in real time, in response to changes in the robot software infrastructure or the needs of the operator. The system is described in detail along with the accompanying communication framework and the process of building a user interface for a simple autonomous device.",Human-robot interaction | IOS | ROS | Teleoperation,6,66-73,Conference Proceeding,Conference Paper,2.0,"Codd-Downey, Robert;Jenkin, Michael",35323711600;7005126033,York University,Canada,"the development of effective user interfaces for an autonomous system can be quite difficult, especially for devices that are to be operated in the field where access to standard computer platforms may be difficult or impossible. one approach in this type of environment is to utilize tablet or phone devices, which when coupled with an appropriate tool such as rosbridge can be used to connect with standard robot middleware. this has proven to be a successful approach for devices with mature user interface requirements but may require significant software development for experimental systems. here we describe rcon, a software tool that allows user interfaces on ios devices to be configured on the device itself, in real time, in response to changes in the robot software infrastructure or the needs of the operator. the system is described in detail along with the accompanying communication framework and the process of building a user interface for a simple autonomous device.",rcon: dynamic mobile interfaces for command and control of ros-enabled robots
1525,2-s2.0-84943387313,10.5220/0005447803150322,Teaching with dynamic documents: Web applications and local resources,Karczmarczuk J.,"CSEDU 2015 - 7th International Conference on Computer Supported Education, Proceedings",2015-01-01,"One of the bottlenecks in the application of computer methods in teaching is the limited effort in the development of tools for the creation of pedagogical material (documents, presentations, software). These tools exist, but they are often dispersed, and sometimes not well known. Some methodological work would be very useful. Our talk concentrates on the usage of Web-oriented information processing techniques, from the perspective of an individual: making presentations, scripting them, adding dynamical content from specialized servers, enhancing the interaction between different sources, etc. We give some simple examples belonging to the domain of teaching of sciences. The usage of servers help to modularize the teaching software support, avoiding big, monolithic applications.",AJAX | HTML5 | Javascript | LaTeX | Mathematical tools | Moodle | Nodejs | Python | Servers | SVG | Tornado | Websockets,1,315-322,Conference Proceeding,Conference Paper,1.0,"Karczmarczuk, Jerzy",6603150582,Université de Caen Normandie,France,"one of the bottlenecks in the application of computer methods in teaching is the limited effort in the development of tools for the creation of pedagogical material (documents, presentations, software). these tools exist, but they are often dispersed, and sometimes not well known. some methodological work would be very useful. our talk concentrates on the usage of web-oriented information processing techniques, from the perspective of an individual: making presentations, scripting them, adding dynamical content from specialized servers, enhancing the interaction between different sources, etc. we give some simple examples belonging to the domain of teaching of sciences. the usage of servers help to modularize the teaching software support, avoiding big, monolithic applications.",teaching with dynamic documents: web applications and local resources
1526,2-s2.0-84943378275,10.5220/0005449103280333,A mobile web game approach for improving dysgraphia,Giordano D.,"CSEDU 2015 - 7th International Conference on Computer Supported Education, Proceedings",2015-01-01,"Dysgraphia is a learning disability that affects the performance of children's handwriting, which can seriously impact their school performance and their willingness to write their thoughts, and can also adversely affect their social life and can lead to low self-esteem. In this work a mobile web-based serious game for improving children's handwriting is presented. The design principles of the game are presented as well as the software tools and frameworks used for its implementation, including the results of an initial informal testing with children which are presented and discussed.",Dysgraphia | Mobile game | Serious game | Web development,7,328-333,Conference Proceeding,Conference Paper,2.0,"Giordano, Daniela;Maiorana, Francesco",7005866348;23467530300,Università degli Studi di Catania,Italy,"dysgraphia is a learning disability that affects the performance of children's handwriting, which can seriously impact their school performance and their willingness to write their thoughts, and can also adversely affect their social life and can lead to low self-esteem. in this work a mobile web-based serious game for improving children's handwriting is presented. the design principles of the game are presented as well as the software tools and frameworks used for its implementation, including the results of an initial informal testing with children which are presented and discussed.",a mobile web game approach for improving dysgraphia
1532,2-s2.0-84939514507,10.1145/2676726.2676994,Dependent information flow types,Lourenço L.,Conference Record of the Annual ACM Symposium on Principles of Programming Languages,2015-01-01,"In this paper, we develop a novel notion of dependent information flow types. Dependent information flow types fit within the standard framework of dependent type theory, but, unlike usual dependent types, crucially allow the security level of a type, rather than just the structural data type itself, to depend on runtime values. Our dependent function and dependent sum information flow types provide a direct, natural and elegant way to express and enforce fine grained security policies on programs, including programs that manipulate structured data types in which the security level of a structure field may depend on values dynamically stored in other fields, still considered a challenge to security enforcement in software systems such as data-centric web-based applications. We base our development on the very general setting of a minimal λ-calculus with references and collections. We illustrate its expressiveness, showing how secure operations on relevant scenarios can be modelled and analysed using our dependent information flow type system, which is also shown to be amenable to algorithmic type checking. Our main results include type-safety and non-interference theorems ensuring that well-typed programs do not violate prescribed security policies.",Dependent type systems | Information flow,36,317-328,Conference Proceeding,Conference Paper,2.0,"Lourenço, Luísa;Caires, Luís",55734635600;6602926067,Faculdade de Ciências e Tecnologia da Universidade Nova de Lisboa,Portugal,"in this paper, we develop a novel notion of dependent information flow types. dependent information flow types fit within the standard framework of dependent type theory, but, unlike usual dependent types, crucially allow the security level of a type, rather than just the structural data type itself, to depend on runtime values. our dependent function and dependent sum information flow types provide a direct, natural and elegant way to express and enforce fine grained security policies on programs, including programs that manipulate structured data types in which the security level of a structure field may depend on values dynamically stored in other fields, still considered a challenge to security enforcement in software systems such as data-centric web-based applications. we base our development on the very general setting of a minimal λ-calculus with references and collections. we illustrate its expressiveness, showing how secure operations on relevant scenarios can be modelled and analysed using our dependent information flow type system, which is also shown to be amenable to algorithmic type checking. our main results include type-safety and non-interference theorems ensuring that well-typed programs do not violate prescribed security policies.",dependent information flow types
1533,2-s2.0-84938783317,10.5220/0005348200450053,Modeling and 2D/3D-visualization of geomagnetic field and its variations parameters,Vorobev A.V.,"GISTAM 2015 - 1st International Conference on Geographical Information Systems Theory, Applications and Management, Proceedings",2015-01-01,"In the modern World, specialists in biology, medicine, geophysics, geology, technics and many other sciences pay great attention to correlation between external geomagnetic variations (GVM) with possibilities of objects and systems existence and evolution. Well-known scientific publications give a quite wide review of approaches to estimation of weak magnetic fields parameters, creation of magnetometric information measurement systems on their base and definition of their metrological characteristics. But today due to the recently formulated relevance of geomagnetic field (GMF) and its variations parameters monitoring there is no unified and effective approach to development of geoinformation magnetometric systems. In spite of the wide variety of specialized geoinformation systems (GIS) there are no advanced hard- and software, which provide a calculation, geospatial connection, visualization and analysis of GMF and its variations parameters calculation results. It is important to mention, that due to low-efficiency, limited functionality and incorrect work of the known solutions the topicality, scientific and applied interest to such a solution development continuously increases.",2D/3D-visualization | Geoinformation systems | Geomagnetic field | Geomagnetic variations,4,45-53,Conference Proceeding,Conference Paper,2.0,"Vorobev, Andrei V.;Shakirova, Gulnara R.",56767909700;57189275619,Ufa State Aviation Technical University,Russian Federation,"in the modern world, specialists in biology, medicine, geophysics, geology, technics and many other sciences pay great attention to correlation between external geomagnetic variations (gvm) with possibilities of objects and systems existence and evolution. well-known scientific publications give a quite wide review of approaches to estimation of weak magnetic fields parameters, creation of magnetometric information measurement systems on their base and definition of their metrological characteristics. but today due to the recently formulated relevance of geomagnetic field (gmf) and its variations parameters monitoring there is no unified and effective approach to development of geoinformation magnetometric systems. in spite of the wide variety of specialized geoinformation systems (gis) there are no advanced hard- and software, which provide a calculation, geospatial connection, visualization and analysis of gmf and its variations parameters calculation results. it is important to mention, that due to low-efficiency, limited functionality and incorrect work of the known solutions the topicality, scientific and applied interest to such a solution development continuously increases.",modeling and 2d/3d-visualization of geomagnetic field and its variations parameters
1535,2-s2.0-84938572683,10.1016/j.procs.2015.03.062,An object-oriented and executable SysML framework for rapid model development,Balestrini-Robinson S.,Procedia Computer Science,2015-01-01,"This paper introduces Cortex, a new framework to develop object-oriented and executable SysML models using the IPython Notebook4. The framework strives to create a succinct and intuitive Python programming interface for SysML models, and integrate it with OpenMDAO (a Multi-disciplinary Design, Analysis and Optimization framework being developed by NASA Glenn Research Center). Data persists in MongoDB, with a Resource Description Framework (RDF) cache for semantic querying. The models can be exposed to custom web-based applications through a Representational State Transfer (REST) interface. The authors strive to create a foundational framework on which to be able to build more advanced system engineering and decision support tools. All the tools and libraries leveraged in this effort are open source software (OSS), and whenever possible, the authors selected technologies with the most permissive licenses.",Framework | MBSE | MDAO | Object-oriented | Open-source | SysML,9,423-432,Conference Proceeding,Conference Paper,3.0,"Balestrini-Robinson, Santiago;Freeman, Dane F.;Browne, Daniel C.",14832247100;56763430900;56612933600,Georgia Tech Research Institute,United States,"this paper introduces cortex, a new framework to develop object-oriented and executable sysml models using the ipython notebook4. the framework strives to create a succinct and intuitive python programming interface for sysml models, and integrate it with openmdao (a multi-disciplinary design, analysis and optimization framework being developed by nasa glenn research center). data persists in mongodb, with a resource description framework (rdf) cache for semantic querying. the models can be exposed to custom web-based applications through a representational state transfer (rest) interface. the authors strive to create a foundational framework on which to be able to build more advanced system engineering and decision support tools. all the tools and libraries leveraged in this effort are open source software (oss), and whenever possible, the authors selected technologies with the most permissive licenses.",an object-oriented and executable sysml framework for rapid model development
1540,2-s2.0-84927738250,10.1007/978-3-319-13251-8_7,Evaluation of javascript quality issues and solutions for enterprise application development,Nitze A.,Lecture Notes in Business Information Processing,2015-01-01,"Today's web applications heavily employ JavaScript to cover wide parts of the applications' front ends. The scripting language, often called the ""lingua franca"" of the web, is also becoming increasingly popular for building enterprise-grade applications. However, in practice, the language is criticized for being too unstructured, flawed and inadequate for such projects. In this contribution, the major problems with JavaScript as the language of choice for enterprise applications are analyzed and possible solutions to ensure the quality of such systems are discussed.",Design patterns | Enterprise applications | JavaScript | Maintainability | Software quality,1,109-119,Book Series,Conference Paper,2.0,"Nitze, André;Carvalho, Ariadne M.B.R.",56595268800;12445473500,Universidade Estadual de Campinas;Berlin School of Economics and Law,Brazil;Brazil,"today's web applications heavily employ javascript to cover wide parts of the applications' front ends. the scripting language, often called the ""lingua franca"" of the web, is also becoming increasingly popular for building enterprise-grade applications. however, in practice, the language is criticized for being too unstructured, flawed and inadequate for such projects. in this contribution, the major problems with javascript as the language of choice for enterprise applications are analyzed and possible solutions to ensure the quality of such systems are discussed.",evaluation of javascript quality issues and solutions for enterprise application development
1541,2-s2.0-84926442999,10.3233/978-1-61499-484-8-1375,Design and implementation of a RESTful notification service,Chang Y.,Frontiers in Artificial Intelligence and Applications,2015-01-01,"Scalability was not an important issue in the history of Internet when there were fewer users, so standalone applications performed well for the most part. With the rapid growth of mobile applications or web services, most users are using the same application or service at the same time which leads to the need to scale applications. To enlarge the capability of handling concurrent requests, the server-side push technologies were then introduced in recent years. There are two famous protocols or frameworks used today, and they are the Pub/Sub protocol, and Ajax Push Model. These two mechanisms are complex to use, and heavy-weight for application developers. To simplify the development and enlarge the ability to accommodate the growth of amount of application users, a RESTful notification service is proposed in this paper. The notification service leverages the event-driven characteristic of JavaScript, and pushes response data asynchronously to different requests. Based on the RESTful software architecture style, the proposed notification service is not only a lightweight system but also has impressive performance.",Notification | REST | RESTful | Server-Side Push,0,1375-1385,Book Series,Conference Paper,4.0,"Chang, Yao Wen;Sheu, Ruey Kai;Jhu, Syuan Ru;Chang, Yue Shan",56582947500;7003750859;56584435800;13805521600,Tunghai University;National Taipei University,Taiwan;Taiwan,"scalability was not an important issue in the history of internet when there were fewer users, so standalone applications performed well for the most part. with the rapid growth of mobile applications or web services, most users are using the same application or service at the same time which leads to the need to scale applications. to enlarge the capability of handling concurrent requests, the server-side push technologies were then introduced in recent years. there are two famous protocols or frameworks used today, and they are the pub/sub protocol, and ajax push model. these two mechanisms are complex to use, and heavy-weight for application developers. to simplify the development and enlarge the ability to accommodate the growth of amount of application users, a restful notification service is proposed in this paper. the notification service leverages the event-driven characteristic of javascript, and pushes response data asynchronously to different requests. based on the restful software architecture style, the proposed notification service is not only a lightweight system but also has impressive performance.",design and implementation of a restful notification service
1542,2-s2.0-84922946650,10.1007/978-3-319-14645-4_8,Fusion of multimedia and mobile technology in audioguides for museums and exhibitions,Gerval J.P.,Intelligent Systems Reference Library,2015-01-01,"This chapter introduces software developments targeting visitors in museums. The main idea leading to these projects is to implement low cost systems that would provide visitors with informational contents about paintings, artworks, etc. The first application was achieved by means of a system that sends a multimedia content (images, audio and texts) to a visitor’s mobile phone, when the mobile phone is in communication range of a Bluetooth transmitter. The second application is an authoring tool that does not require any software development skill. Curators can set up easily and quickly contents for the visitors. Experiments took place in a Marine Park, where more than 200 contents had been developed. It is a web-based system. On smartphone side, HTML5, JavaScript, and Ajax technologies enable us to target a wide range of devices. In the last part of the chapter, these two approaches are compared, and also, taking into account the experiences, some new opportunities of developments are declared. In the last part of the chapter we compare these two approaches and we also open some new opportunities of developments taking into account our experiences.",Audioguides | Authoring tool | Bluetooth | Exhibitions | Multimedia | Museum | Smartphone | Web,12,173-205,Book Series,Article,2.0,"Gerval, Jean Pierre;Le Ru, Yann",6506439149;54412757300,Institut Supérieur de l’Electronique et du Numérique,France,"this chapter introduces software developments targeting visitors in museums. the main idea leading to these projects is to implement low cost systems that would provide visitors with informational contents about paintings, artworks, etc. the first application was achieved by means of a system that sends a multimedia content (images, audio and texts) to a visitor’s mobile phone, when the mobile phone is in communication range of a bluetooth transmitter. the second application is an authoring tool that does not require any software development skill. curators can set up easily and quickly contents for the visitors. experiments took place in a marine park, where more than 200 contents had been developed. it is a web-based system. on smartphone side, html5, javascript, and ajax technologies enable us to target a wide range of devices. in the last part of the chapter, these two approaches are compared, and also, taking into account the experiences, some new opportunities of developments are declared. in the last part of the chapter we compare these two approaches and we also open some new opportunities of developments taking into account our experiences.",fusion of multimedia and mobile technology in audioguides for museums and exhibitions
1543,2-s2.0-84921916267,10.1504/IJCSE.2015.067062,Management of virtual machine images in heterogeneous clouds,Pereira J.,International Journal of Computational Science and Engineering,2015-01-01,"This paper presents the image server of the VISOR cloud agnostic virtual machine images management service. An evaluation approach is also described and the results are discussed. VISOR is not intended to fit in a specific cloud framework but rather to overreach sharing and interoperability limitations among different frameworks. Such feature is achieved by relying on a flexible image metadata schema and in a storage abstraction layer, where the latter seamlessly abstracts the heterogeneity of distinct cloud storage systems into which images can be saved. VISOR is an open source highly distributed system composed of several independent web services. In its development we have focused in modularity, extensibility and performance. Conducted evaluation tests have shown encouraging results regarding performance and scalability.",Cloud computing | Event-driven programming | Representational state transfer | REST | Storage systems | Virtual machine images | Web services,9,113-129,Journal,Article,2.0,"Pereira, João;Prata, Paula",57198007967;6506143567,Universidade da Beira Interior,Portugal,"this paper presents the image server of the visor cloud agnostic virtual machine images management service. an evaluation approach is also described and the results are discussed. visor is not intended to fit in a specific cloud framework but rather to overreach sharing and interoperability limitations among different frameworks. such feature is achieved by relying on a flexible image metadata schema and in a storage abstraction layer, where the latter seamlessly abstracts the heterogeneity of distinct cloud storage systems into which images can be saved. visor is an open source highly distributed system composed of several independent web services. in its development we have focused in modularity, extensibility and performance. conducted evaluation tests have shown encouraging results regarding performance and scalability.",management of virtual machine images in heterogeneous clouds
1544,2-s2.0-84919343552,10.1007/978-3-319-06764-3_7,New generation android operating system-basedmobile application: RSS/news reader,Arsan T.,Lecture Notes in Electrical Engineering,2015-01-01,"RSS (Rich Site Summary)/News Reader is a web-based Android OS application developed by using PhoneGap framework. HTML5, CSS and JavaScript are basically used for implementation, instead of native Android programming language. This application has a production process like a web application because it is actually a fully working web program which is wrapped by PhoneGap framework. This means the application could be used on almost every mobile platform with making some basic arrangements.",Mobile application development | Software architecture,0,49-55,Book Series,Article,3.0,"Arsan, Taner;Erşahin, Mehmet Arif;Alp, Ebru",6506505859;56453013700;56452603400,Kadir Has Üniversitesi,Turkey,"rss (rich site summary)/news reader is a web-based android os application developed by using phonegap framework. html5, css and javascript are basically used for implementation, instead of native android programming language. this application has a production process like a web application because it is actually a fully working web program which is wrapped by phonegap framework. this means the application could be used on almost every mobile platform with making some basic arrangements.",new generation android operating system-basedmobile application: rss/news reader
1545,2-s2.0-84912095265,10.5038/1827-806X.44.1.3,"High-resolution digital 3D models of algar do Penico Chamber: Limitations, challenges, and potential",Silvestre I.,International Journal of Speleology,2015-01-01,"The study of karst and its geomorphological structures is important for understanding the relationships between hydrology and climate over geological time. In that context, we conducted a terrestrial laser-scan survey to map geomorphological structures in the karst cave of Algar do Penico in southern Portugal. The point cloud data set obtained was used to generate 3D meshes with different levels of detail, allowing the limitations of mapping capabilities to be explored. In addition to cave mapping, the study focuses on 3D-mesh analysis, including the development of two algorithms for determination of stalactite extremities and contour lines, and on the interactive visualization of 3D meshes on the Web. Data processing and analysis were performed using freely available open-source software. For interactive visualization, we adopted a framework based on Web standards X3D, WebGL, and X3DOM. This solution gives both the general public and researchers access to 3D models and to additional data produced from map tools analyses through a web browser, without the need for plug-ins.",3D-mesh | Geomorphology | Karst terrestrial laser scanning | Open-source tools | Web3D | X3DOM,15,25-35,Journal,Article,4.0,"Silvestre, Ivo;Rodrigues, José I.;Figueiredo, Mauro;Veiga-Pires, Cristina",55837451900;57217151821;22333823900;7801372905,Universidade do Algarve,Portugal,"the study of karst and its geomorphological structures is important for understanding the relationships between hydrology and climate over geological time. in that context, we conducted a terrestrial laser-scan survey to map geomorphological structures in the karst cave of algar do penico in southern portugal. the point cloud data set obtained was used to generate 3d meshes with different levels of detail, allowing the limitations of mapping capabilities to be explored. in addition to cave mapping, the study focuses on 3d-mesh analysis, including the development of two algorithms for determination of stalactite extremities and contour lines, and on the interactive visualization of 3d meshes on the web. data processing and analysis were performed using freely available open-source software. for interactive visualization, we adopted a framework based on web standards x3d, webgl, and x3dom. this solution gives both the general public and researchers access to 3d models and to additional data produced from map tools analyses through a web browser, without the need for plug-ins.","high-resolution digital 3d models of algar do penico chamber: limitations, challenges, and potential"
1546,2-s2.0-84910134919,10.1016/j.scico.2014.09.005,Crawl-based analysis of web applications: Prospects and challenges,Van Deursen A.,Science of Computer Programming,2015-01-01,"In this paper we review five years of research in the field of automated crawling and testing of web applications. We describe the open source Crawljax tool, and the various extensions that have been proposed in order to address such issues as cross-browser compatibility testing, web application regression testing, and style sheet usage analysis. Based on that we identify the main challenges and future directions of crawl-based testing of web applications. In particular, we explore ways to reduce the exponential growth of the state space, as well as ways to involve the human tester in the loop, thus reconciling manual exploratory testing and automated test input generation. Finally, we sketch the future of crawl-based testing in the light of upcoming developments, such as the pervasive use of touch devices and mobile computing, and the increasing importance of cyber-security.",Software evolution | Test automation | Web crawling,18,173-180,Journal,Article,3.0,"Van Deursen, Arie;Mesbah, Ali;Nederlof, Alex",7003969355;17345931800;56242404600,The University of British Columbia;Delft University of Technology,Canada;Netherlands,"in this paper we review five years of research in the field of automated crawling and testing of web applications. we describe the open source crawljax tool, and the various extensions that have been proposed in order to address such issues as cross-browser compatibility testing, web application regression testing, and style sheet usage analysis. based on that we identify the main challenges and future directions of crawl-based testing of web applications. in particular, we explore ways to reduce the exponential growth of the state space, as well as ways to involve the human tester in the loop, thus reconciling manual exploratory testing and automated test input generation. finally, we sketch the future of crawl-based testing in the light of upcoming developments, such as the pervasive use of touch devices and mobile computing, and the increasing importance of cyber-security.",crawl-based analysis of web applications: prospects and challenges
1547,2-s2.0-84910128514,10.1016/j.scico.2013.11.041,Towards multilingual programming environments,Van Der Storm T.,Science of Computer Programming,2015-01-01,"Software projects consist of different kinds of artifacts: build files, configuration files, markup files, source code in different software languages, and so on. At the same time, however, most integrated development environments (IDEs) are focused on a single (programming) language. Even if a programming environment supports multiple languages (e.g., Eclipse), IDE features such as cross-referencing, refactoring, or debugging, do not often cross language boundaries. What would it mean for programming environment to be truly multilingual? In this short paper we sketch a vision of a system that integrates IDE support across language boundaries. We propose to build this system on a foundation of unified source code models and metaprogramming. Nevertheless, a number of important and hard research questions still need to be addressed.",Language interoperability | Metaprogramming | Programming environments,2,143-149,Journal,Article,2.0,"Van Der Storm, Tijs;Vinju, Jurgen J.",23399139300;9733732800,Centrum Wiskunde &amp; Informatica,Netherlands,"software projects consist of different kinds of artifacts: build files, configuration files, markup files, source code in different software languages, and so on. at the same time, however, most integrated development environments (ides) are focused on a single (programming) language. even if a programming environment supports multiple languages (e.g., eclipse), ide features such as cross-referencing, refactoring, or debugging, do not often cross language boundaries. what would it mean for programming environment to be truly multilingual? in this short paper we sketch a vision of a system that integrates ide support across language boundaries. we propose to build this system on a foundation of unified source code models and metaprogramming. nevertheless, a number of important and hard research questions still need to be addressed.",towards multilingual programming environments
1548,2-s2.0-84939264962,10.1002/cpe.3235,Development of web-based science portal for large-scale computing collaboration in earthquake engineering,Youn C.,Concurrency and Computation: Practice and Experience,2014-12-25,"SUMMARY Cyberinfrstructure has provided the wide-ranging infrastructure needed to profit from the rapid progress in information technology, which has increased the demand for support from science and engineering applications. The science portals have played an important role in developing computing environments of such cyberinfrastructure. And discipline-specific problem solving environments can be used productively, suitable for the study and development of scientific and technical applications. In this paper, we present a simple, web-based computational portal framework for integrating numerical response from thousands of large-scale earthquake engineering computational simulations. This system facilitates access and use of the high performance computing (HPC) resource by the researchers and provides an administratively and technologically streamlined environment for uploading input model files, creating the job script, editing the input model file, specifying HPC job parameters, querying running job status, and storing output data. Our web-based science portal can be used to promote an efficient and effective simulation environment to help scientists as well as educators in their daily activities and speed up the scientific discovery process. The underlying numerical simulation platform is an open-source object-oriented framework for finite element analysis, Open System for Earthquake Engineering Simulation, funded by the Pacific Earthquake Engineering Research Center, and used by the proposed science portal to perform simulation applications in earthquake engineering.",computational simulation | earthquake engineering | OpenSees software framework | web-based science portal,1,2907-2916,Journal,Article,4.0,"Youn, Choonhan;Lu, Jinchi;Elgamal, Ahmed;Baru, Chaitan",7006652451;8916350000;57207505204;57204096644,Structural Engineering Department;San Diego Supercomputer Center,United States;United States,"summary cyberinfrstructure has provided the wide-ranging infrastructure needed to profit from the rapid progress in information technology, which has increased the demand for support from science and engineering applications. the science portals have played an important role in developing computing environments of such cyberinfrastructure. and discipline-specific problem solving environments can be used productively, suitable for the study and development of scientific and technical applications. in this paper, we present a simple, web-based computational portal framework for integrating numerical response from thousands of large-scale earthquake engineering computational simulations. this system facilitates access and use of the high performance computing (hpc) resource by the researchers and provides an administratively and technologically streamlined environment for uploading input model files, creating the job script, editing the input model file, specifying hpc job parameters, querying running job status, and storing output data. our web-based science portal can be used to promote an efficient and effective simulation environment to help scientists as well as educators in their daily activities and speed up the scientific discovery process. the underlying numerical simulation platform is an open-source object-oriented framework for finite element analysis, open system for earthquake engineering simulation, funded by the pacific earthquake engineering research center, and used by the proposed science portal to perform simulation applications in earthquake engineering.",development of web-based science portal for large-scale computing collaboration in earthquake engineering
1550,2-s2.0-84919448204,10.1007/s12539-012-0044-x,PDB explorer — A web based algorithm for protein annotation viewer and 3D visualization,Nayarisseri A.,Interdisciplinary Sciences – Computational Life Sciences,2014-12-19,"The PDB file format, is a text format characterizing the three dimensional structures of macro molecules available in the Protein Data Bank (PDB). Determined protein structure are found in coalition with other molecules or ions such as nucleic acids, water, ions, Drug molecules and so on, which therefore can be described in the PDB format and have been deposited in PDB database. PDB is a machine generated file, it’s not human readable format, to read this file we need any computational tool to understand it. The objective of our present study is to develop a free online software for retrieval, visualization and reading of annotation of a protein 3D structure which is available in PDB database. Main aim is to create PDB file in human readable format, i.e., the information in PDB file is converted in readable sentences. It displays all possible information from a PDB file including 3D structure of that file. Programming languages and scripting languages like Perl, CSS, Javascript, Ajax, and HTML have been used for the development of PDB Explorer. The PDB Explorer directly parses the PDB file, calling methods for parsed element secondary structure element, atoms, coordinates etc. PDB Explorer is freely available at http://www.pdbexplorer.eminentbio.com/home with no requirement of log-in.",PDB | PDB explorer | PDB parser tools | protein 3D structure visualization tools,1,279-284,Journal,Article,7.0,"Nayarisseri, Anuraj;Shardiwal, Rakesh Kumar;Yadav, Mukesh;Kanungo, Neha;Singh, Pooja;Shah, Pratik;Ahmed, Sheaza",55832955900;36169398400;57548614600;56454354000;57199272130;54977271300;56438450400,Eminent Biosciences,India,"the pdb file format, is a text format characterizing the three dimensional structures of macro molecules available in the protein data bank (pdb). determined protein structure are found in coalition with other molecules or ions such as nucleic acids, water, ions, drug molecules and so on, which therefore can be described in the pdb format and have been deposited in pdb database. pdb is a machine generated file, it’s not human readable format, to read this file we need any computational tool to understand it. the objective of our present study is to develop a free online software for retrieval, visualization and reading of annotation of a protein 3d structure which is available in pdb database. main aim is to create pdb file in human readable format, i.e., the information in pdb file is converted in readable sentences. it displays all possible information from a pdb file including 3d structure of that file. programming languages and scripting languages like perl, css, javascript, ajax, and html have been used for the development of pdb explorer. the pdb explorer directly parses the pdb file, calling methods for parsed element secondary structure element, atoms, coordinates etc. pdb explorer is freely available at http://www.pdbexplorer.eminentbio.com/home with no requirement of log-in.",pdb explorer — a web based algorithm for protein annotation viewer and 3d visualization
1551,2-s2.0-84946197941,10.1109/INNOVATIONS.2014.6987553,A context-sensitive approach for precise detection of cross-site scripting vulnerabilities,Gupta M.K.,"2014 10th International Conference on Innovations in Information Technology, IIT 2014",2014-12-16,"Currently, dependence on web applications is increasing rapidly for social communication, health services, financial transactions and many other purposes. Unfortunately, the presence of cross-site scripting vulnerabilities in these applications allows malicious user to steals sensitive information, install malware, and performs various malicious operations. Researchers proposed various approaches and developed tools to detect XSS vulnerability from source code of web applications. However, existing approaches and tools are not free from false positive and false negative results. In this paper, we propose a taint analysis and defensive programming based HTML context-sensitive approach for precise detection of XSS vulnerability from source code of PHP web applications. It also provides automatic suggestions to improve the vulnerable source code. Preliminary experiments and results on test subjects show that proposed approach is more efficient than existing ones.",Cross-Site Scripting | Software Development Life Cycle | Taint Analysis | Vulnerability Detection | XSS Attacks,4,7-12,Conference Proceeding,Conference Paper,3.0,"Gupta, Mukesh Kumar;Govil, Mahesh Chand;Singh, Girdhari",56405866500;35812070200;57224916905,Malaviya National Institute of Technology Jaipur,India,"currently, dependence on web applications is increasing rapidly for social communication, health services, financial transactions and many other purposes. unfortunately, the presence of cross-site scripting vulnerabilities in these applications allows malicious user to steals sensitive information, install malware, and performs various malicious operations. researchers proposed various approaches and developed tools to detect xss vulnerability from source code of web applications. however, existing approaches and tools are not free from false positive and false negative results. in this paper, we propose a taint analysis and defensive programming based html context-sensitive approach for precise detection of xss vulnerability from source code of php web applications. it also provides automatic suggestions to improve the vulnerable source code. preliminary experiments and results on test subjects show that proposed approach is more efficient than existing ones.",a context-sensitive approach for precise detection of cross-site scripting vulnerabilities
1552,2-s2.0-84984832120,10.1145/2647508.2647527,Selective regression testing for web applications created with Google Web Toolkit,Hirzel M.,ACM International Conference Proceeding Series,2014-12-13,"Today's web applications are highly dynamic and powerful software components that may change often. Mostly, they are based on JavaScript or AJAX. A common way to ensure correct behaviour is to use selective regression tests. Nevertheless, especially on the client side, testing is hard. One way to ease the development and the testing process of dynamic web applications is to use the Google Web Toolkit (GWT). This framework enables the development in Java and transfers the code via a compiler into JavaScript. However, it does not support regression testing with test selection. As far as we know, this paper presents the first selective regression testing technique for GWT-based web applications. In order to determine test cases that have to be rerun, it compares the Java code of two versions of the application, localizes and classifies changes in the code, and traces the mapping of Java source code to JavaScript code. We have implemented our technique as a prototype Eclipse plug-in and have conducted an evaluation of the tool.",Control Flow Graph | Debugging | Fault localization | Google Web Toolkit | Selective Regression Testing | Web Applications,5,110-121,Conference Proceeding,Conference Paper,1.0,"Hirzel, Matthias",57188923396,Eberhard Karls Universität Tübingen,Germany,"today's web applications are highly dynamic and powerful software components that may change often. mostly, they are based on javascript or ajax. a common way to ensure correct behaviour is to use selective regression tests. nevertheless, especially on the client side, testing is hard. one way to ease the development and the testing process of dynamic web applications is to use the google web toolkit (gwt). this framework enables the development in java and transfers the code via a compiler into javascript. however, it does not support regression testing with test selection. as far as we know, this paper presents the first selective regression testing technique for gwt-based web applications. in order to determine test cases that have to be rerun, it compares the java code of two versions of the application, localizes and classifies changes in the code, and traces the mapping of java source code to javascript code. we have implemented our technique as a prototype eclipse plug-in and have conducted an evaluation of the tool.",selective regression testing for web applications created with google web toolkit
1553,2-s2.0-84922541548,10.1109/FiCloud.2014.75,A framework for cross-platform mobile web applications using HTML5,Bouras C.,"Proceedings - 2014 International Conference on Future Internet of Things and Cloud, FiCloud 2014",2014-12-12,"In recent years the use of smart mobile devices has become an integral part of everyday life leading to the expansion of applications development for the various mobile platforms. Each of these platforms requires separate software development process, which subsequently increases dramatically the corresponding effort. With the emergence of HTML5 these issues can be addressed efficiently since application development is allowed in a cross-platform manner. An additional important benefit is that users can access the application immediately without any need for installation. In this paper, we investigate the potentials of mobile application development with web technologies and we present a development framework that utilizes the most important state-of-art web technologies for the support of mobile devices. This framework can be used for the implementation of mobile web applications and also for the investigation and experimentation on the main features that HTML5 offers for this specific type of devices.",framework | HTML5 | mobile app | web technology,8,420-424,Conference Proceeding,Conference Paper,3.0,"Bouras, Christos;Papazois, Andreas;Stasinos, Nikolaos",7102164662;15060534300;56512429400,University of Patras,Greece,"in recent years the use of smart mobile devices has become an integral part of everyday life leading to the expansion of applications development for the various mobile platforms. each of these platforms requires separate software development process, which subsequently increases dramatically the corresponding effort. with the emergence of html5 these issues can be addressed efficiently since application development is allowed in a cross-platform manner. an additional important benefit is that users can access the application immediately without any need for installation. in this paper, we investigate the potentials of mobile application development with web technologies and we present a development framework that utilizes the most important state-of-art web technologies for the support of mobile devices. this framework can be used for the implementation of mobile web applications and also for the investigation and experimentation on the main features that html5 offers for this specific type of devices.",a framework for cross-platform mobile web applications using html5
1554,2-s2.0-84921051217,10.1109/NGMAST.2014.24,Augmented reality web applications with mobile agents in the internet of things,Leppanen T.,"Proceedings - 2014 8th International Conference on Next Generation Mobile Applications, Services and Technologies, NGMAST 2014",2014-12-11,"Augmented reality (AR) is a promising technology for building applications in an Internet of Things (IoT) environment, utilized for visualizing information provided by IoT devices. In this paper, we enable Web-based mobile AR applications with mobile agents in a resource-oriented IoT system architecture. We present an adaptable mobile agent composition that contains the data representation logic and mappings between AR applications and system resources. Thus, mobile agents and AR application-specific data structures are exposed as global system resources. System resource linkages are considered between real-world objects and their virtual representations for mobile agent-based AR applications. The agent composition also complies with the REST principles for resource access and control system-wide. This allows dynamic runtime adaptation and addressing the device and resource heterogeneity, thus eliminating the need for application-specific communication protocols. Moreover, we utilize a Web-based mobile AR application framework, running completely in a Web browser, which facilitates straightforward AR application development. Lastly, a proof of concept mobile AR application is implemented, where a coffee maker with a visual tag is connected to a low-power resource-constrained wireless sensor network node as an IoT device. A mobile agent is injected into the IoT environment to expose the state changes of the coffee maker. Through the visual tag, AR applications are able to visualize the state changes of the coffee maker in their user interface.",Augmented Reality | Embedded Software | Mobile Agent | Mobile Computing | Web Services,21,54-59,Conference Proceeding,Conference Paper,6.0,"Leppanen, Teemu;Heikkinen, Arto;Karhu, Antti;Harjula, Erkki;Riekki, Jukka;Koskela, Timo",36181320400;37665117400;55536719900;15834483600;14009440600;24448628300,Oulun Yliopisto,Finland,"augmented reality (ar) is a promising technology for building applications in an internet of things (iot) environment, utilized for visualizing information provided by iot devices. in this paper, we enable web-based mobile ar applications with mobile agents in a resource-oriented iot system architecture. we present an adaptable mobile agent composition that contains the data representation logic and mappings between ar applications and system resources. thus, mobile agents and ar application-specific data structures are exposed as global system resources. system resource linkages are considered between real-world objects and their virtual representations for mobile agent-based ar applications. the agent composition also complies with the rest principles for resource access and control system-wide. this allows dynamic runtime adaptation and addressing the device and resource heterogeneity, thus eliminating the need for application-specific communication protocols. moreover, we utilize a web-based mobile ar application framework, running completely in a web browser, which facilitates straightforward ar application development. lastly, a proof of concept mobile ar application is implemented, where a coffee maker with a visual tag is connected to a low-power resource-constrained wireless sensor network node as an iot device. a mobile agent is injected into the iot environment to expose the state changes of the coffee maker. through the visual tag, ar applications are able to visualize the state changes of the coffee maker in their user interface.",augmented reality web applications with mobile agents in the internet of things
1555,2-s2.0-84911369043,10.1002/cae.21567,Athena: A hybrid management system for multi-device educational content,Vásquez-Ramírez R.,Computer Applications in Engineering Education,2014-12-01,"Over the past few years, a number of software applications have been proposed to tackle the administration, documentation, tracking, and reporting of training programs and contents such as CMS (Content Management System) and LMS (Learning Management System). However, CMS focuses on the administration and development of websites, while LMS is mainly focused on the management of training through the use of learning objects. CMS and LMS have features that can be used in conjunction in order to create educational environments which enhance the teaching-learning process in classrooms. This article presents a hybrid management system called Athena for multi-device educational content providing a set of Web-based interfaces for managing, presenting, and generating PHP-based applications with educational content, reducing both the time and effort invested during the development process of this type of software. Athena borrows the main features of both CMS and LMS in order to manage and reuse educational content. Athena allows the user to develop platform-independent multi-device educational software using existing educational content. Athena aims to provide new forms of accessibility to educational content, envisioning a better future for online education. To demonstrate Athena's capabilities, we have presented a case study for generating a multi-device physics course to emphasize our contribution.",CMS | educational environments | educational software | hybrid management system | LMS,11,750-763,Journal,Article,3.0,"Vásquez-Ramírez, Raquel;Alor-Hernández, Giner;Rodríguez-González, Alejandro",35312626000;17433252100;22939175500,"Instituto Tecnologico de Orizaba, Mexico;Universidad Carlos III de Madrid",Mexico;Spain,"over the past few years, a number of software applications have been proposed to tackle the administration, documentation, tracking, and reporting of training programs and contents such as cms (content management system) and lms (learning management system). however, cms focuses on the administration and development of websites, while lms is mainly focused on the management of training through the use of learning objects. cms and lms have features that can be used in conjunction in order to create educational environments which enhance the teaching-learning process in classrooms. this article presents a hybrid management system called athena for multi-device educational content providing a set of web-based interfaces for managing, presenting, and generating php-based applications with educational content, reducing both the time and effort invested during the development process of this type of software. athena borrows the main features of both cms and lms in order to manage and reuse educational content. athena allows the user to develop platform-independent multi-device educational software using existing educational content. athena aims to provide new forms of accessibility to educational content, envisioning a better future for online education. to demonstrate athena's capabilities, we have presented a case study for generating a multi-device physics course to emphasize our contribution.",athena: a hybrid management system for multi-device educational content
1556,2-s2.0-84910072467,10.1016/j.compbiomed.2014.10.001,Haemophilus influenzae Genome Database (HIGDB): A single point web resource for Haemophilus influenzae,Swetha R.,Computers in Biology and Medicine,2014-12-01,"Background: Haemophilus influenzae (. H. Influenzae) is the causative agent of pneumonia, bacteraemia and meningitis. The organism is responsible for large number of deaths in both developed and developing countries. Even-though the first bacterial genome to be sequenced was that of H. Influenzae, there is no exclusive database dedicated for H. Influenzae. This prompted us to develop the Haemophilus influenzae Genome Database (HIGDB). Methods: All data of HIGDB are stored and managed in MySQL database. The HIGDB is hosted on Solaris server and developed using PERL modules. Ajax and JavaScript are used for the interface development. Results: The HIGDB contains detailed information on 42,741 proteins, 18,077 genes including 10 whole genome sequences and also 284 three dimensional structures of proteins of H. influenzae. In addition, the database provides ""Motif search"" and ""GBrowse"". The HIGDB is freely accessible through the URL: http://bioserver1.physics.iisc.ernet.in/HIGDB/. Discussion: The HIGDB will be a single point access for bacteriological, clinical, genomic and proteomic information of H. influenzae. The database can also be used to identify DNA motifs within H. influenzae genomes and to compare gene or protein sequences of a particular strain with other strains of H. influenzae.",Annotation | Database | Genome | Haemophilus influenzae | Resistance,2,86-91,Journal,Article,5.0,"Swetha, Rayapadi G.;Kala Sekar, Dinesh Kumar;Ramaiah, Sudha;Anbarasu, Anand;Sekar, Kanagaraj",56107025800;56414913800;54886385200;16416481700;7006325915,Indian Institute of Science;Vellore Institute of Technology,India;India,"background: haemophilus influenzae (. h. influenzae) is the causative agent of pneumonia, bacteraemia and meningitis. the organism is responsible for large number of deaths in both developed and developing countries. even-though the first bacterial genome to be sequenced was that of h. influenzae, there is no exclusive database dedicated for h. influenzae. this prompted us to develop the haemophilus influenzae genome database (higdb). methods: all data of higdb are stored and managed in mysql database. the higdb is hosted on solaris server and developed using perl modules. ajax and javascript are used for the interface development. results: the higdb contains detailed information on 42,741 proteins, 18,077 genes including 10 whole genome sequences and also 284 three dimensional structures of proteins of h. influenzae. in addition, the database provides ""motif search"" and ""gbrowse"". the higdb is freely accessible through the url: http://bioserver1.physics.iisc.ernet.in/higdb/. discussion: the higdb will be a single point access for bacteriological, clinical, genomic and proteomic information of h. influenzae. the database can also be used to identify dna motifs within h. influenzae genomes and to compare gene or protein sequences of a particular strain with other strains of h. influenzae.",haemophilus influenzae genome database (higdb): a single point web resource for haemophilus influenzae
1557,2-s2.0-84919460547,10.1109/ICCSNT.2013.6967128,The impact of programming paradigm concepts in mobile application design and its resource utilizations,Samuel S.,"Proceedings of 2013 3rd International Conference on Computer Science and Network Technology, ICCSNT 2013",2014-11-25,"Mobile device has fewer resources compare to desktop computers. Mobile application development is in the need of appropriate strategies in view of resource utilizations. Although some other design strategies are required for software development, programming paradigm is the core. The overall aim of this study is to formulate the programming paradigms whereby achieve the optimal resource utilizations by mobile applications. As a part of this objective, this paper aims to determine whether the improper use of programming paradigm concepts consume more memory and / or CPU time. Imperative programming paradigm concepts have been used as a sample for this study. Imperative programming concepts such as looping, branching and arrays have been experimented. The results of the experiments and case studies proved that, improper use of programming concepts lead to more memory consumptions and/ or take more time to response. In conclusion use of appropriate paradigms in mobile application design possibly will optimize the response time and memory utilization.",Mobile Application Development | Object Oriented Programming | Procedural Programming | Programming Paradigm | Resource Utilizations,0,355-359,Conference Proceeding,Conference Paper,2.0,"Samuel, Selvakumar;Gorai, Sudeshna",36195067000;56454216500,Asia Pacific University of Technology and Innovation,Malaysia,"mobile device has fewer resources compare to desktop computers. mobile application development is in the need of appropriate strategies in view of resource utilizations. although some other design strategies are required for software development, programming paradigm is the core. the overall aim of this study is to formulate the programming paradigms whereby achieve the optimal resource utilizations by mobile applications. as a part of this objective, this paper aims to determine whether the improper use of programming paradigm concepts consume more memory and / or cpu time. imperative programming paradigm concepts have been used as a sample for this study. imperative programming concepts such as looping, branching and arrays have been experimented. the results of the experiments and case studies proved that, improper use of programming concepts lead to more memory consumptions and/ or take more time to response. in conclusion use of appropriate paradigms in mobile application design possibly will optimize the response time and memory utilization.",the impact of programming paradigm concepts in mobile application design and its resource utilizations
1559,2-s2.0-84908240471,10.1016/j.scico.2013.07.017,Enriching single-user web applications non-invasively with shared editing support,Heinrich M.,Science of Computer Programming,2014-11-15,"Collaborative real-time applications like Google Docs allow multiple users to edit the very same document simultaneously which supersedes traditional document merging and document locking techniques. However, developing collaborative web applications is a time-consuming and complex endeavor since it requires implementing document synchronization and conflict resolution services. To accelerate the development of collaborative web applications, we present a rapid transformation approach allowing to non-invasively introduce shared editing capabilities into existing single-user web applications. Instead of changing the application's source code, our non-invasive approach leverages a generic collaboration infrastructure that requires only a configuration to provide document synchronization and conflict resolution services. Hence, the effort to incorporate shared editing capabilities is considerably reduced in contrast to conventional approaches where the use of a programing library entails scattered source code changes. Moreover, we report on the results of a user study demonstrating that converted editors are convenient for collaborative work.",Groupware | Shared editing | Web applications,1,53-66,Journal,Article,6.0,"Heinrich, Matthias;Lehmann, Franz;Grüneberger, Franz Josef;Gaedke, Martin;Springer, Thomas;Schill, Alexander",57198310613;7102212967;55338932900;8905803700;35303484900;7004418075,SAP AG;Technische Universität Dresden;Technische Universität Chemnitz,Germany;Germany;Germany,"collaborative real-time applications like google docs allow multiple users to edit the very same document simultaneously which supersedes traditional document merging and document locking techniques. however, developing collaborative web applications is a time-consuming and complex endeavor since it requires implementing document synchronization and conflict resolution services. to accelerate the development of collaborative web applications, we present a rapid transformation approach allowing to non-invasively introduce shared editing capabilities into existing single-user web applications. instead of changing the application's source code, our non-invasive approach leverages a generic collaboration infrastructure that requires only a configuration to provide document synchronization and conflict resolution services. hence, the effort to incorporate shared editing capabilities is considerably reduced in contrast to conventional approaches where the use of a programing library entails scattered source code changes. moreover, we report on the results of a user study demonstrating that converted editors are convenient for collaborative work.",enriching single-user web applications non-invasively with shared editing support
1560,2-s2.0-84912141506,10.1109/QSIC.2014.48,A method to test the information quality of technical documentation on websites,Shpak O.,Proceedings - International Conference on Quality Software,2014-11-14,"In software engineering, testing is one of the corner-stones of quality assurance. The idea of software testing can be applied to information quality as well. Technical documentation has a set of intended uses that correspond to use cases in a software system. Documentation is, in many cases, presented via software systems, e.g., web servers and browsers, and contains software, e.g., Javascript for user interaction, animation, and customization, etc. This makes it difficult to find a clear-cut distinction between a software system and technical documentation. However, we can assume that each use case of a technical documentation involves retrieval of some sort of information that helps a user answer a specific questions. To assess information testing as a method, we implemented QAnalytics, a tool to assess the information quality of documentation that is provided by a website. The tool is web-based and allows test managers and site owners to define test cases and success criteria, disseminate the test cases to testers, and to analyze the test results. This way, information testing is easily manageable even for non-technical stakeholders. We applied our testing method and tool in a case study. According to common perception, the website of Linnaeus University needs to be re-engineered. Our method and tool helped the stakeholders identify what information is presented well and which parts of the website that need to change. The test results allowed the design and development effort to prioritize actual quality issues and potentially save time and resources.",information quality | web analytics | web testing,3,296-304,Conference Proceeding,Conference Paper,4.0,"Shpak, Oleksandr;Löwe, Welf;Wingkvist, Anna;Ericsson, Morgan",56429263900;35619361400;34977972000;8855384400,"Linnaeus University, Växjö",Sweden,"in software engineering, testing is one of the corner-stones of quality assurance. the idea of software testing can be applied to information quality as well. technical documentation has a set of intended uses that correspond to use cases in a software system. documentation is, in many cases, presented via software systems, e.g., web servers and browsers, and contains software, e.g., javascript for user interaction, animation, and customization, etc. this makes it difficult to find a clear-cut distinction between a software system and technical documentation. however, we can assume that each use case of a technical documentation involves retrieval of some sort of information that helps a user answer a specific questions. to assess information testing as a method, we implemented qanalytics, a tool to assess the information quality of documentation that is provided by a website. the tool is web-based and allows test managers and site owners to define test cases and success criteria, disseminate the test cases to testers, and to analyze the test results. this way, information testing is easily manageable even for non-technical stakeholders. we applied our testing method and tool in a case study. according to common perception, the website of linnaeus university needs to be re-engineered. our method and tool helped the stakeholders identify what information is presented well and which parts of the website that need to change. the test results allowed the design and development effort to prioritize actual quality issues and potentially save time and resources.",a method to test the information quality of technical documentation on websites
1562,2-s2.0-84915771660,10.1109/EmbeddedSys.2014.6953052,Software birthmark based theft detection of JavaScript programs using agglomerative clustering and Frequent Subgraph Mining,Patel S.J.,"International Conference on Embedded Systems, ICES 2014",2014-11-11,"Use of JavaScript in web development has increased the theft of JavaScript programs. Mostly, JavaScript program are susceptible to theft because browsers provide the simplest way to access it. Techniques to safeguard software are code obfuscation and watermarking. A potential attacker can easily deface watermark and hence watermark cannot completely protect the code. Code obfuscation cannot avoid copy of code. It only prevents others by understanding the logic of the program. Our aim is to secure the intellectual property rights of JavaScript developers. Even if the code is obfuscated or a watermark is added in it, this system can easily detect theft. Heap Graph is used to depict the behavior of a JavaScript program as how it calls other objects to fulfil the desired functionality. Agglomerative clustering is used to efficiently merge the heaps formed during the phase of programs execution. Frequent Subgraph Mining is used for finding frequent set of nodes which represents the unique behavior of the program. Finally the subgraph of plaintiff program is explored contrary to graph of the suspected one. We worked on 3000 combinations of websites and found that the software is capable of finding even a minor theft.",Agglomerative clustering | dynamic birthmark | frequent subgraph mining | theft identification,3,63-68,Conference Proceeding,Conference Paper,2.0,"Patel, Swati J.;Pattewar, Tareek M.",56438441900;55638984100,R. C. Patel Institute of Technology,India,"use of javascript in web development has increased the theft of javascript programs. mostly, javascript program are susceptible to theft because browsers provide the simplest way to access it. techniques to safeguard software are code obfuscation and watermarking. a potential attacker can easily deface watermark and hence watermark cannot completely protect the code. code obfuscation cannot avoid copy of code. it only prevents others by understanding the logic of the program. our aim is to secure the intellectual property rights of javascript developers. even if the code is obfuscated or a watermark is added in it, this system can easily detect theft. heap graph is used to depict the behavior of a javascript program as how it calls other objects to fulfil the desired functionality. agglomerative clustering is used to efficiently merge the heaps formed during the phase of programs execution. frequent subgraph mining is used for finding frequent set of nodes which represents the unique behavior of the program. finally the subgraph of plaintiff program is explored contrary to graph of the suspected one. we worked on 3000 combinations of websites and found that the software is capable of finding even a minor theft.",software birthmark based theft detection of javascript programs using agglomerative clustering and frequent subgraph mining
1563,2-s2.0-84937683484,10.1145/2666652.2666657,Lux0R: Detection of malicious PDF-embedded javascript code through discriminant analysis of API references,Corona I.,Proceedings of the ACM Conference on Computer and Communications Security,2014-11-07,"JavaScript is a dynamic programming language adopted in a variety of applications, including web pages, PDF Readers, widget engines, network platforms, office suites. Given its widespread presence throughout different software platforms, JavaScript is a primary tool for the development of novel rapidly evolving malicious exploits. If the classical signature- And heuristic-based detection approaches are clearly inadequate to cope with this kind of threat, machine learning solutions proposed so far suffer from high falsealarm rates or require special instrumentation that make them not suitable for protecting end-user systems. In this paper we present Lux0R Lux 0n discriminant References"", a novel, lightweight approach to the detection of malicious JavaScript code. Our method is based on the characterization of JavaScript code through its API references, i.e., functions, constants, objects, methods, keywords as well as attributes natively recognized by a JavaScript Application Programming Interface (API). We exploit machine learning techniques to select a subset of API references that characterize malicious code, and then use them to detect JavaScript malware. The selection algorithm has been thought to be secure by design"" against evasion by mimicry attacks. In this investigation, we focus on a relevant application domain, i.e., the detection of malicious JavaScript code within PDF documents. We show that our technique is able to achieve excellent malware detection accuracy, even on samples exploiting never-before-seen vulnerabilities, i.e., for which there are no examples in training data. Finally, we experimentally assess the robustness of Lux0R against mimicry attacks based on feature addition.",Adversarial machine learning | Javascript code | Malware detection | Mimicry attacks | PDF documents,40,47-57,Conference Proceeding,Conference Paper,4.0,"Corona, Igino;Maiorca, Davide;Ariu, Davide;Giacinto, Giorgio",24075276200;55334827100;23093096600;6701832237,Università degli Studi di Cagliari,Italy,"javascript is a dynamic programming language adopted in a variety of applications, including web pages, pdf readers, widget engines, network platforms, office suites. given its widespread presence throughout different software platforms, javascript is a primary tool for the development of novel rapidly evolving malicious exploits. if the classical signature- and heuristic-based detection approaches are clearly inadequate to cope with this kind of threat, machine learning solutions proposed so far suffer from high falsealarm rates or require special instrumentation that make them not suitable for protecting end-user systems. in this paper we present lux0r lux 0n discriminant references"", a novel, lightweight approach to the detection of malicious javascript code. our method is based on the characterization of javascript code through its api references, i.e., functions, constants, objects, methods, keywords as well as attributes natively recognized by a javascript application programming interface (api). we exploit machine learning techniques to select a subset of api references that characterize malicious code, and then use them to detect javascript malware. the selection algorithm has been thought to be secure by design"" against evasion by mimicry attacks. in this investigation, we focus on a relevant application domain, i.e., the detection of malicious javascript code within pdf documents. we show that our technique is able to achieve excellent malware detection accuracy, even on samples exploiting never-before-seen vulnerabilities, i.e., for which there are no examples in training data. finally, we experimentally assess the robustness of lux0r against mimicry attacks based on feature addition.",lux0r: detection of malicious pdf-embedded javascript code through discriminant analysis of api references
1564,2-s2.0-84937682860,10.1145/2663887.2663902,ACH walkthrough: A distributed multi-device tool for collaborative security analysis,Wilson J.,Proceedings of the ACM Conference on Computer and Communications Security,2014-11-07,"This paper presents AchWalkthrough, a prototype software client-server application to demonstrate the potential benefits of surface technologies in collaborative security intelligence analysis. The basis is the ACH (Analysis of Competing Hypotheses) technique, which requests factors relating to evidence and hypotheses, and builds a model that reduces cognitive bias, thereby helping decision-making. Our application supports development of this model using visualization techniques that allow collaboration and reection. The technology we use is surface computing, where analysts work around a large multi-touch display, but also multidevice technology, where the model is consistent across various large and small displays. The software runs in standard web-browsers, leveraging HTML5 and JavaScript libraries on both client and server. This allows deployment without installation, and thus security and exibility.",Security intelligence analysis | Surface computing | Visual analytics,5,9-16,Conference Proceeding,Conference Paper,3.0,"Wilson, Jeff;Brown, Judith M.;Biddle, Robert",57198215402;56169454100;8213204300,Carleton University,Canada,"this paper presents achwalkthrough, a prototype software client-server application to demonstrate the potential benefits of surface technologies in collaborative security intelligence analysis. the basis is the ach (analysis of competing hypotheses) technique, which requests factors relating to evidence and hypotheses, and builds a model that reduces cognitive bias, thereby helping decision-making. our application supports development of this model using visualization techniques that allow collaboration and reection. the technology we use is surface computing, where analysts work around a large multi-touch display, but also multidevice technology, where the model is consistent across various large and small displays. the software runs in standard web-browsers, leveraging html5 and javascript libraries on both client and server. this allows deployment without installation, and thus security and exibility.",ach walkthrough: a distributed multi-device tool for collaborative security analysis
1565,2-s2.0-84911468827,10.1109/IROS.2014.6942676,Modular low-cost humanoid platform for disaster response,Yi S.J.,IEEE International Conference on Intelligent Robots and Systems,2014-10-31,"Developing a reliable humanoid robot that operates in uncharted real-world environments is a huge challenge for both hardware and software. Commensurate with the technology hurdles, the amount of time and money required can also be prohibitive barriers. This paper describes Team THOR's approach to overcoming such barriers for the 2013 DARPA Robotics Challenge (DRC) Trials. We focused on forming modular components - in both hardware and software - to allow for efficient and cost effective parallel development. The robotic hardware consists of standardized and general purpose actuators and structural components. These allowed us to successfully build the robot from scratch in a very short development period, modify configurations easily and perform quick field repair. Our modular software framework consists of a hybrid locomotion controller, a hierarchical arm controller and a platform-independent operator interface. These modules helped us to keep up with hardware changes easily and to have multiple control options to suit various situations. We validated our approach at the DRC Trials where we fared very well against robots many times more expensive.",DARPA Robotic Challenge | Full Body Balancing Controller | Humanoid Robot | Modular Design,4,965-972,Conference Proceeding,Conference Paper,8.0,"Yi, Seung Joon;McGill, Stephen;Vadakedathu, Larry;He, Qin;Ha, Inyong;Rouleau, Michael;Hong, Dennis;Lee, Daniel D.",36464606800;55268412700;55662028200;56422952500;36508682900;56423430400;35787457200;7406662803,"ROBOTIS Co.,Ltd.;School of Engineering and Applied Science;University of California, Los Angeles;Virginia Polytechnic Institute and State University",South Korea;United States;United States;United States,"developing a reliable humanoid robot that operates in uncharted real-world environments is a huge challenge for both hardware and software. commensurate with the technology hurdles, the amount of time and money required can also be prohibitive barriers. this paper describes team thor's approach to overcoming such barriers for the 2013 darpa robotics challenge (drc) trials. we focused on forming modular components - in both hardware and software - to allow for efficient and cost effective parallel development. the robotic hardware consists of standardized and general purpose actuators and structural components. these allowed us to successfully build the robot from scratch in a very short development period, modify configurations easily and perform quick field repair. our modular software framework consists of a hybrid locomotion controller, a hierarchical arm controller and a platform-independent operator interface. these modules helped us to keep up with hardware changes easily and to have multiple control options to suit various situations. we validated our approach at the drc trials where we fared very well against robots many times more expensive.",modular low-cost humanoid platform for disaster response
1566,2-s2.0-84914140187,10.1109/ICInfA.2014.6932785,From ROS to unity: Leveraging robot and virtual environment middleware for immersive teleoperation,Codd-Downey R.,"2014 IEEE International Conference on Information and Automation, ICIA 2014",2014-10-21,"Virtual reality systems are often proposed as an appropriate technology for the development of teleoperational interfaces for autonomous and semi-autonomous systems. In the past such systems have typically been developed as 'one off' experimental systems in part due to a lack of common software systems for both robot software development and virtual environment infrastructure. More recently, common frameworks have begun to emerge for both robot control (e.g., ROS) and virtual environment display and interaction (e.g., Unity). Here we consider the task of developing systems that integrate these two environments. A yaml-based communications protocol over web sockets is used to glue the two software environments together. This allows each system to be controlled using standard software toolkits independently while providing a flexible interface between these two infrastructures.",robotics | teleoperation | virtual reality,37,932-936,Conference Proceeding,Conference Paper,5.0,"Codd-Downey, R.;Forooshani, P. Mojiri;Speers, A.;Wang, H.;Jenkin, M.",35323711600;57389017600;56660928400;24831419000;7005126033,York University,Canada,"virtual reality systems are often proposed as an appropriate technology for the development of teleoperational interfaces for autonomous and semi-autonomous systems. in the past such systems have typically been developed as 'one off' experimental systems in part due to a lack of common software systems for both robot software development and virtual environment infrastructure. more recently, common frameworks have begun to emerge for both robot control (e.g., ros) and virtual environment display and interaction (e.g., unity). here we consider the task of developing systems that integrate these two environments. a yaml-based communications protocol over web sockets is used to glue the two software environments together. this allows each system to be controlled using standard software toolkits independently while providing a flexible interface between these two infrastructures.",from ros to unity: leveraging robot and virtual environment middleware for immersive teleoperation
1567,2-s2.0-84910047237,10.1109/ICSESS.2014.6933691,The design and implementation of transport equipment maintenance system based on WSH framework,Hou J.,"Proceedings of the IEEE International Conference on Software Engineering and Service Sciences, ICSESS",2014-10-21,"In the logistics industry, it is hard to follow and manage the process of transport equipment maintenance in time. The transport equipment maintenance system described in this article shows a new method to solve this problem. This system is a part of a united logistics management system. In the process of design and develop it, we follow the MVC pattern so that the three part of the WSH (WebWork + Spring + Hibernate) framework are able to play their respective advantages. This article first introduces the system development background and general goals. And then we illustrate the functions of the system. Finally, the reasons why we chose WSH framework to develop this system are given and how WSH works in the transport equipment maintenance system are detailed described.",integration framework | process control | transport equipment maintenance | WSH,0,815-818,Conference Proceeding,Conference Paper,3.0,"Hou, Jiaqi;Chen, Yan;Li, Taoying",56413723000;55268952800;55858885900,Dalian Maritime University,China,"in the logistics industry, it is hard to follow and manage the process of transport equipment maintenance in time. the transport equipment maintenance system described in this article shows a new method to solve this problem. this system is a part of a united logistics management system. in the process of design and develop it, we follow the mvc pattern so that the three part of the wsh (webwork + spring + hibernate) framework are able to play their respective advantages. this article first introduces the system development background and general goals. and then we illustrate the functions of the system. finally, the reasons why we chose wsh framework to develop this system are given and how wsh works in the transport equipment maintenance system are detailed described.",the design and implementation of transport equipment maintenance system based on wsh framework
1568,2-s2.0-84930980628,10.1145/2687357.2687359,Scaling-up behavioral programming: Steps from basic principles to application architectures,Harel D.,"AGERE! 2014 - Proceedings of the 2014 ACM SIGPLAN Workshop on Programming Based on Actors, Agents, and Decentralized Control, Part of SPLASH 2014",2014-10-20,"Behavioral programming (BP) is a decentralized scenario-based paradigm for the programming of reactive software, geared towards incremental and intuitive development. In this work we apply the principles of BP to a large, real-world case-study: a web-server. We discuss the conclusions learned from our attempt and propose several extension idioms to BP, aimed at improving the framework's scalability. Specifically, we propose extending BP with a timeout idiom for handling various time constraints, program-specific execution strategies, dynamic thread creation for efficiently allocating system resources, and support for parameterized events to handle inputs with infinite domains. Our extensions and case-study are implemented in a new framework for behavioral programming in C++.",Behavioral programming | C++ | HTTP | Reactive systems | TCP | Time constraints,15,95-108,Conference Proceeding,Conference Paper,2.0,"Harel, David;Katz, Guy",24457480800;55437727200,Weizmann Institute of Science Israel,Israel,"behavioral programming (bp) is a decentralized scenario-based paradigm for the programming of reactive software, geared towards incremental and intuitive development. in this work we apply the principles of bp to a large, real-world case-study: a web-server. we discuss the conclusions learned from our attempt and propose several extension idioms to bp, aimed at improving the framework's scalability. specifically, we propose extending bp with a timeout idiom for handling various time constraints, program-specific execution strategies, dynamic thread creation for efficiently allocating system resources, and support for parameterized events to handle inputs with infinite domains. our extensions and case-study are implemented in a new framework for behavioral programming in c++.",scaling-up behavioral programming: steps from basic principles to application architectures
1569,2-s2.0-84910659930,10.1145/2660252.2664662,Pocket Code: A Scratch-like integrated development environment for your phone,Slany W.,"SPLASH 2014 - Companion Publication of the 2014 ACM SIGPLAN Conference on Systems, Programming, and Applications: Software for Humanity",2014-10-20,"In our free open source project Catrobat, we are developing Pocket Code, an integrated development environment (IDE) for a visual, Lego-block style programming language that is inspired by MIT's Scratch. In contrast to Scratch and AppInventor, Pocket Code is designed to completely run on smartphones - no PC whatsoever is needed to develop or execute the programs. Our motivation is to allow teenagers to intuitively create and easily share their own mobile apps. The large project includes more than 20 subprojects that complement Pocket Code in various ways, e.g., an image editor app that supports transparency and zooming up to pixel level. According to Ohloh, as of June 2014 more than 371 person years have been invested by 270 volunteer contributors from more than 20 countries into Catrobat. All development is done in an agile, extremely iterative and test-driven way, with a strong focus on maintainability, usability, and design. Subteams in parallel develop native versions of Catrobat interpreters that are integrated into corresponding Pocket Code IDEs for the Android, iOS, and Windows Phone platforms as well as for HTML5 capable mobile browsers, or smartphones supporting HTML5 directly. These native versions are implemented by us respectively in Java, ObjectiveC, C# & C++, and HTML5/JavaScript. I will demonstrate Pocket Code and also will show how we use automatically checkable specification to ensure that programs behave identically on all platforms even though no cross-compilation tools or common implementation languages are used. Copyright is held by the author/owner(s).",Computer science education | Kids | Mobile app | Smartphones | STEM | Teenagers | Visual programming,12,35-36,Conference Proceeding,Conference Paper,1.0,"Slany, Wolfgang",6602594138,"Graz University of Technology, Institute of Software Technology",Austria,"in our free open source project catrobat, we are developing pocket code, an integrated development environment (ide) for a visual, lego-block style programming language that is inspired by mit's scratch. in contrast to scratch and appinventor, pocket code is designed to completely run on smartphones - no pc whatsoever is needed to develop or execute the programs. our motivation is to allow teenagers to intuitively create and easily share their own mobile apps. the large project includes more than 20 subprojects that complement pocket code in various ways, e.g., an image editor app that supports transparency and zooming up to pixel level. according to ohloh, as of june 2014 more than 371 person years have been invested by 270 volunteer contributors from more than 20 countries into catrobat. all development is done in an agile, extremely iterative and test-driven way, with a strong focus on maintainability, usability, and design. subteams in parallel develop native versions of catrobat interpreters that are integrated into corresponding pocket code ides for the android, ios, and windows phone platforms as well as for html5 capable mobile browsers, or smartphones supporting html5 directly. these native versions are implemented by us respectively in java, objectivec, c# & c++, and html5/javascript. i will demonstrate pocket code and also will show how we use automatically checkable specification to ensure that programs behave identically on all platforms even though no cross-compilation tools or common implementation languages are used. copyright is held by the author/owner(s).",pocket code: a scratch-like integrated development environment for your phone
1570,2-s2.0-84919625923,10.1109/SCC.2014.68,Service security revisited,Gorski P.L.,"Proceedings - 2014 IEEE International Conference on Services Computing, SCC 2014",2014-10-17,"Developing contemporary software architectures requires the consideration and adoption of the Service-oriented Architecture (SOA) principles. Distributed applications are a very common domain in which SOA guides design decisions in particular. For a long time, SOAP and its related stack of standards have been the only technological choice for implementing SOA-based systems. With the increased adoption of the REST concept, an alternative to SOAP is gaining traction. Security considerations have been part of the SOAP-based standardization work since the very beginning. As a result, a mature and comprehensive set of security-related standards is available for building SOAP-based service systems. REST-ful service systems, however, cannot take advantage of such a fully developed security framework yet. This paper therefore revisits the SOAP-based web services security stack in order to identify commonalities, differences and gaps in the security available for REST-ful services. From these findings a desired REST-ful web services security stack is proposed together with related research, development and standardization challenges.",REST | Security | Services | SOA | SOAP,8,464-471,Conference Proceeding,Conference Paper,4.0,"Gorski, Peter Leo;Iacono, Luigi Lo;Nguyen, Hoai Viet;Torkian, Daniel Behnam",56358458700;24775991600;57199967174;56028726200,Technology Arts Sciences TH Köln,Germany,"developing contemporary software architectures requires the consideration and adoption of the service-oriented architecture (soa) principles. distributed applications are a very common domain in which soa guides design decisions in particular. for a long time, soap and its related stack of standards have been the only technological choice for implementing soa-based systems. with the increased adoption of the rest concept, an alternative to soap is gaining traction. security considerations have been part of the soap-based standardization work since the very beginning. as a result, a mature and comprehensive set of security-related standards is available for building soap-based service systems. rest-ful service systems, however, cannot take advantage of such a fully developed security framework yet. this paper therefore revisits the soap-based web services security stack in order to identify commonalities, differences and gaps in the security available for rest-ful services. from these findings a desired rest-ful web services security stack is proposed together with related research, development and standardization challenges.",service security revisited
1571,2-s2.0-84911882636,10.1109/ICCSE.2014.6926524,Design of cloud services platform based on JSON,Yin Q.,"Proceedings of the 9th International Conference on Computer Science and Education, ICCCSE 2014",2014-10-15,"with the increasing range of software development and applications, the scale of software development is becoming larger and larger. The larger software's scale is the more possible failed in the phase of design, development, and implementation in software. As a starting point to improve the management and development of software, this paper designs a service platform for data services - JCFXBL.JCFXBL is mainly used to solve two issues, one is the management of software development, and the other is the technology of software development. In combination with two the practical application cases based on JCFXBL, from software development, software design, project management, the article describes the role of JCFXBL platform in the 'Project Management' and 'systems integration projects', and verifies that JCFXBL platform can reduce the complexity of software development, improve software quality and solve software development, management issues, by actual software development.",JCFXBL platform | management | Project Management | software platform,2,560-565,Conference Proceeding,Conference Paper,2.0,"Yin, Qun;Zhang, Jianbo",55322959700;55322953400,Kunming University of Science and Technology,China,"with the increasing range of software development and applications, the scale of software development is becoming larger and larger. the larger software's scale is the more possible failed in the phase of design, development, and implementation in software. as a starting point to improve the management and development of software, this paper designs a service platform for data services - jcfxbl.jcfxbl is mainly used to solve two issues, one is the management of software development, and the other is the technology of software development. in combination with two the practical application cases based on jcfxbl, from software development, software design, project management, the article describes the role of jcfxbl platform in the 'project management' and 'systems integration projects', and verifies that jcfxbl platform can reduce the complexity of software development, improve software quality and solve software development, management issues, by actual software development.",design of cloud services platform based on json
1572,2-s2.0-84907589919,10.1007/s10664-013-9289-1,An empirical study on the impact of static typing on software maintainability,Hanenberg S.,Empirical Software Engineering,2014-10-01,"Static type systems play an essential role in contemporary programming languages. Despite their importance, whether static type systems impact human software development capabilities remains open. One frequently mentioned argument in favor of static type systems is that they improve the maintainability of software systems - an often-used claim for which there is little empirical evidence. This paper describes an experiment that tests whether static type systems improve the maintainability of software systems, in terms of understanding undocumented code, fixing type errors, and fixing semantic errors. The results show rigorous empirical evidence that static types are indeed beneficial to these activities, except when fixing semantic errors. We further conduct an exploratory analysis of the data in order to understand possible reasons for the effect of type systems on the three kinds of tasks used in this experiment. From the exploratory analysis, we conclude that developers using a dynamic type system tend to look at different files more frequently when doing programming tasks - which is a potential reason for the observed differences in time.",Empirical studies | Programming languages | Software engineering | Type systems,40,1335-1382,Journal,Article,5.0,"Hanenberg, Stefan;Kleinschmager, Sebastian;Robbes, Romain;Tanter, Éric;Stefik, Andreas",8983981100;35229727600;15136854400;13104010300;9239542500,"University of Nevada, Las Vegas;Universität Duisburg-Essen;Versity of Chile",United States;Germany;Chile,"static type systems play an essential role in contemporary programming languages. despite their importance, whether static type systems impact human software development capabilities remains open. one frequently mentioned argument in favor of static type systems is that they improve the maintainability of software systems - an often-used claim for which there is little empirical evidence. this paper describes an experiment that tests whether static type systems improve the maintainability of software systems, in terms of understanding undocumented code, fixing type errors, and fixing semantic errors. the results show rigorous empirical evidence that static types are indeed beneficial to these activities, except when fixing semantic errors. we further conduct an exploratory analysis of the data in order to understand possible reasons for the effect of type systems on the three kinds of tasks used in this experiment. from the exploratory analysis, we conclude that developers using a dynamic type system tend to look at different files more frequently when doing programming tasks - which is a potential reason for the observed differences in time.",an empirical study on the impact of static typing on software maintainability
1575,2-s2.0-84923917647,10.1109/BigData.Congress.2014.95,Data sharing for cloud computing platforms,Sabbouh M.,"Proceedings - 2014 IEEE International Congress on Big Data, BigData Congress 2014",2014-09-22,"Cloud computing platforms consist of a set of reliable services that are run in the cloud. Typically, consumer applications use software development kits (SDKs) provided by the computing platform services to store, update, and retrieve instances of data in the cloud. Services provided by the cloud computing platform, expose different data modeling paradigms that consumer applications use to interact with the cloud. The service-specific data modeling paradigms and SDKs increase the complexity of data sharing between consumer applications that interact with the different services of the cloud computing platform. To make matters more complicated, it's not uncommon in an enterprise to find different groups using different cloud computing platforms. In this paper, we will describe a set of abstractions that can be used to abstract different computing platforms. The abstractions not only abstract the computing platform, but also enable the data discovery and sharing between applications. We will further show that these abstractions do not add substantial latency on the performance of the computing platform.",API | data modeling language | JSON | NoSQL | Rest | web protocols,3,621-628,Conference Proceeding,Conference Paper,3.0,"Sabbouh, Marwan;McCracken, Kenneth;Cooney, Geoff",22836072000;56533472000;56533463300,A Nokia Business,United States,"cloud computing platforms consist of a set of reliable services that are run in the cloud. typically, consumer applications use software development kits (sdks) provided by the computing platform services to store, update, and retrieve instances of data in the cloud. services provided by the cloud computing platform, expose different data modeling paradigms that consumer applications use to interact with the cloud. the service-specific data modeling paradigms and sdks increase the complexity of data sharing between consumer applications that interact with the different services of the cloud computing platform. to make matters more complicated, it's not uncommon in an enterprise to find different groups using different cloud computing platforms. in this paper, we will describe a set of abstractions that can be used to abstract different computing platforms. the abstractions not only abstract the computing platform, but also enable the data discovery and sharing between applications. we will further show that these abstractions do not add substantial latency on the performance of the computing platform.",data sharing for cloud computing platforms
1577,2-s2.0-84928595173,10.1109/COMPSAC.2014.30,Dynamic slicing of python programs,Chen Z.,Proceedings - International Computer Software and Applications Conference,2014-09-15,"Python is widely used for web programming and GUI development. Due to the dynamic features of Python, Python programs may contain various unlimited errors. Dynamic slicing extracts those statements from a program which affect the variables in a slicing criterion with a particular input. Dynamic slicing of Python programs is essential for program debugging and fault location. In this paper, we propose an approach of dynamic slicing for Python programs which combines static analysis and dynamic tracing of the Python byte code. It precisely handles the dynamic features of Python, such as dynamic typing of variables, heavy usage of first-class objects, and dynamic modifications of classes and instances. Finally, we evaluate our approach on several Python programs. Experimental results show that the whole dynamic slicing for each subject program spends at most about 13 seconds on the average and costs at most 7.58 mb memory space overhead. Furthermore, the average slice ratio of Python source code ranges from 9.26% to 59.42%. According to it, our dynamic slicing approach can be effectively and efficiently performed. To the best of our knowledge, it is the first one of dynamic slicing for Python programs.",dynamic language | dynamic slicing | Python,13,219-228,Conference Proceeding,Conference Paper,6.0,"Chen, Zhifei;Chen, Lin;Zhou, Yuming;Xu, Zhaogui;Chu, William C.;Xu, Baowen",55884919800;57189042207;57022538800;55884412400;56924327000;7404589262,Nanjing University;Tunghai University,China;Taiwan,"python is widely used for web programming and gui development. due to the dynamic features of python, python programs may contain various unlimited errors. dynamic slicing extracts those statements from a program which affect the variables in a slicing criterion with a particular input. dynamic slicing of python programs is essential for program debugging and fault location. in this paper, we propose an approach of dynamic slicing for python programs which combines static analysis and dynamic tracing of the python byte code. it precisely handles the dynamic features of python, such as dynamic typing of variables, heavy usage of first-class objects, and dynamic modifications of classes and instances. finally, we evaluate our approach on several python programs. experimental results show that the whole dynamic slicing for each subject program spends at most about 13 seconds on the average and costs at most 7.58 mb memory space overhead. furthermore, the average slice ratio of python source code ranges from 9.26% to 59.42%. according to it, our dynamic slicing approach can be effectively and efficiently performed. to the best of our knowledge, it is the first one of dynamic slicing for python programs.",dynamic slicing of python programs
1578,2-s2.0-84907893385,10.3969/j.issn.1002-6819.2014.17.023,Design of county-level soil information system based on Web-GIS,Liu Z.,Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering,2014-09-01,"Science research and production practice have accumulated a large number of soil data, which is the valuable essential data for practice and research. It is significant for sustainable land use to enhance soil information management and sharing. But currently the construction of county level soil information system is facing many issues such as the high cost, difficult to maintain, and performance bottlenecks, etc. In this paper, a low-cost open-source Web GIS platform (MapGuide Open Source) was adopted to design and develop a county-level soil information system (CLSIS) for Lishu county based on the second soil survey database and other soil data in Visual Studio.Net. The system development was divided into four stages: system requirement analysis, system design, system implementation and system testing. The system was designed as a three-tier Server/Brower open application system. Client tier may be a browser terminal or a management terminal. Web tier, deployed on the internet information server, was responsible for receiving requests from browsers, passing the requests to the application server and returning the response to browsers. Application tier was composed of a GIS server (MapGuide Open Source 2.1), a database server and a remote Web Map Service (WMS) component. The database was organized as the attribute database and spatial database, respectively. The attribute database includes the soil basic information table, soil physical properties table, soil chemical properties table, geomorphology table, and land use and administrative table. Among all spatial data, the soil, topography, land use and administrative maps are vector layers, but the precipitation and temperature are stored as raster format. The server-side of CLSIS provided map services, feature services, render services and image services. The functions of server-side were implemented by C# and MapGuide Server API in Visual Studio.Net. The browser-side programming is applied with fusion flexible page layout solution, which has better flexibility, scalability and response speed. Fusion framework is an expanded JavaScript library derived from OpenLayers and JXLib. The system built up a dynamic contact with Google WMS, facilitating the switch of base map among the standard, satellite, hybrid and terrain. Google WMS enhanced the visual effect and intuitive feelings of CLSIS. The system maintenance and management is mainly done by MapGuide Maestro, which is a client software based on Client/Server structure. The centralized management makes system maintenance and upgrades more convenient. CLSIS realizes the map navigation, map services, feature services and thematic mapping functions. By utilizing these functions mentioned above, users can conveniently query and browse soil resources and other relevant geographic background informations for Lishu county. The available soil data include soil type, soil texture, soil parent materials, soil organic matter, the thickness of humus, pH value, total nitrogen, total phosphorus, total potassium, available nitrogen, available phosphorus, available potassium, trace elements and soil water retention, etc. The operation result shows that the system reaches a good balance between cost of development/maintenance and performance. This system will be a basic county level soil information platform for further expansion in the application of multiple fields.",Geographic information systems | MapGuide | Open source | Soils | Web browsers,1,175-182,Journal,Article,4.0,"Liu, Zhong;Li, Baoguo;Xu, Min;Gao, Qiang",55714763100;7410083288;57208615313;55730583200,Jilin Agricultural University;China Agricultural University,China;China,"science research and production practice have accumulated a large number of soil data, which is the valuable essential data for practice and research. it is significant for sustainable land use to enhance soil information management and sharing. but currently the construction of county level soil information system is facing many issues such as the high cost, difficult to maintain, and performance bottlenecks, etc. in this paper, a low-cost open-source web gis platform (mapguide open source) was adopted to design and develop a county-level soil information system (clsis) for lishu county based on the second soil survey database and other soil data in visual studio.net. the system development was divided into four stages: system requirement analysis, system design, system implementation and system testing. the system was designed as a three-tier server/brower open application system. client tier may be a browser terminal or a management terminal. web tier, deployed on the internet information server, was responsible for receiving requests from browsers, passing the requests to the application server and returning the response to browsers. application tier was composed of a gis server (mapguide open source 2.1), a database server and a remote web map service (wms) component. the database was organized as the attribute database and spatial database, respectively. the attribute database includes the soil basic information table, soil physical properties table, soil chemical properties table, geomorphology table, and land use and administrative table. among all spatial data, the soil, topography, land use and administrative maps are vector layers, but the precipitation and temperature are stored as raster format. the server-side of clsis provided map services, feature services, render services and image services. the functions of server-side were implemented by c# and mapguide server api in visual studio.net. the browser-side programming is applied with fusion flexible page layout solution, which has better flexibility, scalability and response speed. fusion framework is an expanded javascript library derived from openlayers and jxlib. the system built up a dynamic contact with google wms, facilitating the switch of base map among the standard, satellite, hybrid and terrain. google wms enhanced the visual effect and intuitive feelings of clsis. the system maintenance and management is mainly done by mapguide maestro, which is a client software based on client/server structure. the centralized management makes system maintenance and upgrades more convenient. clsis realizes the map navigation, map services, feature services and thematic mapping functions. by utilizing these functions mentioned above, users can conveniently query and browse soil resources and other relevant geographic background informations for lishu county. the available soil data include soil type, soil texture, soil parent materials, soil organic matter, the thickness of humus, ph value, total nitrogen, total phosphorus, total potassium, available nitrogen, available phosphorus, available potassium, trace elements and soil water retention, etc. the operation result shows that the system reaches a good balance between cost of development/maintenance and performance. this system will be a basic county level soil information platform for further expansion in the application of multiple fields.",design of county-level soil information system based on web-gis
1580,2-s2.0-84900317130,10.1016/j.scico.2014.01.018,Exception analysis in the Java Native Interface,Li S.,Science of Computer Programming,2014-09-01,"A Foreign Function Interface (FFI) allows one host programming language to interoperate with another foreign language. It enables efficient software development by permitting developers to assemble components in different languages. One typical FFI is the Java Native Interface (JNI), through which Java programs can invoke native-code components developed in C, C++, or assembly code. Although FFIs bring convenience to software development, interface code developed in FFIs is often error prone because of the lack of safety and security enforcement. This paper introduces a static-analysis framework, TurboJet, which finds exception-related bugs in JNI applications. It finds bugs of inconsistent exception declarations and bugs of mishandling JNI exceptions. TurboJet is carefully engineered to achieve both high efficiency and accuracy. We have applied TurboJet on a set of benchmark programs and identified many errors. We have also implemented a practical Eclipse plug-in based on TurboJet that can be used by JNI programmers to find errors in their code. © 2014 Elsevier B.V. All rights reserved.",Exception checking | Foreign Function Interface | Java Native Interface | Static analysis,4,273-297,Journal,Article,2.0,"Li, Siliang;Tan, Gang",56098221100;57192503632,Lehigh University,United States,"a foreign function interface (ffi) allows one host programming language to interoperate with another foreign language. it enables efficient software development by permitting developers to assemble components in different languages. one typical ffi is the java native interface (jni), through which java programs can invoke native-code components developed in c, c++, or assembly code. although ffis bring convenience to software development, interface code developed in ffis is often error prone because of the lack of safety and security enforcement. this paper introduces a static-analysis framework, turbojet, which finds exception-related bugs in jni applications. it finds bugs of inconsistent exception declarations and bugs of mishandling jni exceptions. turbojet is carefully engineered to achieve both high efficiency and accuracy. we have applied turbojet on a set of benchmark programs and identified many errors. we have also implemented a practical eclipse plug-in based on turbojet that can be used by jni programmers to find errors in their code. © 2014 elsevier b.v. all rights reserved.",exception analysis in the java native interface
1581,2-s2.0-84899094159,10.1016/j.scico.2013.12.008,Open source software and the algorithm visualization community,Cooper M.,Science of Computer Programming,2014-08-01,"Algorithm visualizations are widely viewed as having the potential for major impact on computer science education, but their quality is highly variable. We report on the software development practices used by creators of algorithm visualizations, based on data that can be inferred from a catalog of over 600 algorithm visualizations. Since nearly all are free for use and many provide source code, they might be construed as being open source software. Yet many AV developers do not appear to have used open source best practices. We discuss how such development practices might be employed by the algorithm visualization community, and how they might lead to improved algorithm visualizations in the future. We conclude with a discussion of OpenDSA, an open-source project that builds on earlier progress in the field of algorithm visualization and hopes to use open-source procedures to gain users and contributors. © 2014 Elsevier B.V.",Algorithm animation | Open source licensing | Open source tools | Project hosting | Version control,4,82-91,Journal,Article,4.0,"Cooper, Matthew L.;Shaffer, Clifford A.;Edwards, Stephen H.;Ponce, Sean P.",57198516704;7005154739;7401520439;26656163200,Virginia Polytechnic Institute and State University;Microsoft Corporation,United States;United States,"algorithm visualizations are widely viewed as having the potential for major impact on computer science education, but their quality is highly variable. we report on the software development practices used by creators of algorithm visualizations, based on data that can be inferred from a catalog of over 600 algorithm visualizations. since nearly all are free for use and many provide source code, they might be construed as being open source software. yet many av developers do not appear to have used open source best practices. we discuss how such development practices might be employed by the algorithm visualization community, and how they might lead to improved algorithm visualizations in the future. we conclude with a discussion of opendsa, an open-source project that builds on earlier progress in the field of algorithm visualization and hopes to use open-source procedures to gain users and contributors. © 2014 elsevier b.v.",open source software and the algorithm visualization community
1582,2-s2.0-84898798056,10.1016/j.scico.2013.11.040,Design and architecture of an interactive eTextbook - The OpenDSA system,Fouh E.,Science of Computer Programming,2014-08-01,The OpenDSA Project seeks to provide complete instructional materials for data structures and algorithms (DSA) courses. Our vision for a highly interactive eTextbook involves the use of many algorithm visualizations (AVs) and a wide range of interactive exercises with automated assessment. To realize this vision we require a mix of third-party and custom software components that make up a client/server-based web application. The massive amount content development required compels us to adopt an appropriate mix of open-source practices that will encourage broad contribution to the project. In this paper we describe the OpenDSA system architecture and the design goals that led to the present version of the system. © 2013 Elsevier B.V.,Algorithm visualization | Automated assessment | Data structures and algorithms | eLearning | eTextbook,40,22-40,Journal,Article,7.0,"Fouh, Eric;Karavirta, Ville;Breakiron, Daniel A.;Hamouda, Sally;Hall, Simin;Naps, Thomas L.;Shaffer, Clifford A.",55195627200;7801668709;55858991100;55966518300;36465021400;6602931948;7005154739,Aalto University;University of Wisconsin Oshkosh;Virginia Polytechnic Institute and State University,Finland;United States;United States,the opendsa project seeks to provide complete instructional materials for data structures and algorithms (dsa) courses. our vision for a highly interactive etextbook involves the use of many algorithm visualizations (avs) and a wide range of interactive exercises with automated assessment. to realize this vision we require a mix of third-party and custom software components that make up a client/server-based web application. the massive amount content development required compels us to adopt an appropriate mix of open-source practices that will encourage broad contribution to the project. in this paper we describe the opendsa system architecture and the design goals that led to the present version of the system. © 2013 elsevier b.v.,design and architecture of an interactive etextbook - the opendsa system
1583,2-s2.0-84912073958,10.1109/meco.2014.6862683,Prototype of speech controlled cloud based wheelchair platform for disabled persons,Skraba A.,"Proceedings - 2014 3rd Mediterranean Conference on Embedded Computing, MECO 2014 - Including ECyPS 2014",2014-07-22,"This paper describes the development of the prototype speech controlled cloud based wheelchair platform. The control of the platform is implemented using low-cost available speech WebKit in the cloud. Besides the voice control, the GUI is implemented which works in the web browser as well as on the mobile devices providing live video stream. The platform is based on Mini PC running Ubuntu Linux and Arduino UNO Microcontroller. Software development was done in JavaScript / ECMA Script.",Cyber-physical system | Devices for rehabilitation | ECMA Script | HTML5 | Internet of things | JavaScript | Speech recognition | Wheelchair,18,162-165,Conference Proceeding,Conference Paper,4.0,"Skraba, Andrej;Koložvari, Andrej;Kofjač, Davorin;Stojanović, Radovan",8530587400;56429626900;8530587500;7003903082,University of Montenegro;Univerza v Mariboru,Montenegro;Slovenia,"this paper describes the development of the prototype speech controlled cloud based wheelchair platform. the control of the platform is implemented using low-cost available speech webkit in the cloud. besides the voice control, the gui is implemented which works in the web browser as well as on the mobile devices providing live video stream. the platform is based on mini pc running ubuntu linux and arduino uno microcontroller. software development was done in javascript / ecma script.",prototype of speech controlled cloud based wheelchair platform for disabled persons
1585,2-s2.0-84994133382,10.1145/2568225.2568268,Understanding JavaScript event-based interactions,Alimadadi S.,Proceedings - International Conference on Software Engineering,2014-05-31,"Web applications have become one of the fastest growing types of software systems today. Despite their popularity, understanding the behaviour of modern web applications is still a challenging endeavour for developers during development and maintenance tasks. The challenges mainly stem from the dynamic, event-driven, and asynchronous nature of the JavaScript language. We propose a generic technique for capturing low-level event-based interactions in a web application and mapping those to a higher-level behavioural model. This model is then transformed into an interactive visualization, representing episodes of triggered causal and temporal events, related JavaScript code executions, and their impact on the dynamic DOM state. Our approach, implemented in a tool called Clematis, allows developers to easily understand the complex dynamic behaviour of their application at three different semantic levels of granularity. The results of our industrial controlled experiment show that Clematis is capable of improving the task accuracy by 61%, while reducing the task completion time by 47%.",event-based interactions | JavaScript | Program comprehension,49,367-377,Conference Proceeding,Conference Paper,4.0,"Alimadadi, Saba;Sequeira, Sheldon;Mesbah, Ali;Pattabiraman, Karthik",36727054000;57189506659;17345931800;8887951000,The University of British Columbia,Canada,"web applications have become one of the fastest growing types of software systems today. despite their popularity, understanding the behaviour of modern web applications is still a challenging endeavour for developers during development and maintenance tasks. the challenges mainly stem from the dynamic, event-driven, and asynchronous nature of the javascript language. we propose a generic technique for capturing low-level event-based interactions in a web application and mapping those to a higher-level behavioural model. this model is then transformed into an interactive visualization, representing episodes of triggered causal and temporal events, related javascript code executions, and their impact on the dynamic dom state. our approach, implemented in a tool called clematis, allows developers to easily understand the complex dynamic behaviour of their application at three different semantic levels of granularity. the results of our industrial controlled experiment show that clematis is capable of improving the task accuracy by 61%, while reducing the task completion time by 47%.",understanding javascript event-based interactions
1587,2-s2.0-84949928995,10.1109/GOCICT.2014.25,HTML Educational Node.js System (HENS): An Applied System for WEB Development,Carter B.,"Proceedings - 2014 Annual Global Online Conference on Information and Computer Technology, GOCICT 2014",2014-05-26,"In this paper, a very compelling proposition is presented, a portable system for software development. The focus is on HTML, Java Script, CSS, Node.js, and SQLite. The system provides all the applications required for students to start developing web applications. The HTML Educational Node.js System (HENS) does not require installation or admin access allowing for portability. This environment is built using open source applications.",development environment | education | html | javascript | node.js | portal applications | web service | website,4,27-31,Conference Proceeding,Conference Paper,1.0,"Carter, Brian",57212637990,Chippewa Software Technology;Sullivan University,United States;United States,"in this paper, a very compelling proposition is presented, a portable system for software development. the focus is on html, java script, css, node.js, and sqlite. the system provides all the applications required for students to start developing web applications. the html educational node.js system (hens) does not require installation or admin access allowing for portability. this environment is built using open source applications.",html educational node.js system (hens): an applied system for web development
1588,2-s2.0-84949928387,10.1109/GOCICT.2014.23,"HTML Architecture, a Novel Development System (HANDS): An Approach for WEB Development",Carter B.,"Proceedings - 2014 Annual Global Online Conference on Information and Computer Technology, GOCICT 2014",2014-05-26,"In this paper, a very compelling proposition is presented, a novel approach for web development that is a hybrid of Single Page Applications (SPA) and server side applications. The proposed architecture lowers the entry to web development by providing a simplistic approach for development. The focus is on HTML, Java Script, Cascading Style Sheets, and Node.js. The architecture provides all the components required for students to start developing web applications and web services. The HTML Architecture, a Novel Development System (HANDS) is a hybrid approach leveraging the simplicity of plain old HTML pages, the AJAX injection of HTML from SPA frameworks, and the server side processing found in the Node.js framework. An open source starter kit and examples are provided.",education | framework | html | javascript | node.js | sqlite | web development,5,90-95,Conference Proceeding,Conference Paper,1.0,"Carter, Brian",57212637990,Chippewa Software Technology;Sullivan University,United States;United States,"in this paper, a very compelling proposition is presented, a novel approach for web development that is a hybrid of single page applications (spa) and server side applications. the proposed architecture lowers the entry to web development by providing a simplistic approach for development. the focus is on html, java script, cascading style sheets, and node.js. the architecture provides all the components required for students to start developing web applications and web services. the html architecture, a novel development system (hands) is a hybrid approach leveraging the simplicity of plain old html pages, the ajax injection of html from spa frameworks, and the server side processing found in the node.js framework. an open source starter kit and examples are provided.","html architecture, a novel development system (hands): an approach for web development"
1590,2-s2.0-84893486375,10.1016/j.envsoft.2014.01.023,A client-side web application for interactive environmental simulation modeling,Walker J.,Environmental Modelling and Software,2014-05-01,"Recent developments in web technologies including evolution of web standards, improvements in browser performance, and the emergence of free and open-source software (FOSS) libraries are driving a general shift from server-side to client-side web applications where a greater share of the computational load is transferred to the browser. Modern client-side approaches allow for improved user interfaces that rival traditional desktop software, as well as the ability to perform simulations and visualizations within the browser. We demonstrate the use of client-side technologies to create an interactive web application for a simulation model of biochemical oxygen demand and dissolved oxygen in rivers called the Web-based Interactive River Model (WIRM). We discuss the benefits, limitations and potential uses of client-side web applications, and provide suggestions for future research using new and upcoming web technologies such as offline access and local data storage to create more advanced client-side web applications for environmental simulation modeling. © 2014 Elsevier Ltd.",Simulation model | Water quality | Web application,42,49-60,Journal,Article,2.0,"Walker, Jeffrey D.;Chapra, Steven C.",35099772600;7003344459,Tufts University,United States,"recent developments in web technologies including evolution of web standards, improvements in browser performance, and the emergence of free and open-source software (foss) libraries are driving a general shift from server-side to client-side web applications where a greater share of the computational load is transferred to the browser. modern client-side approaches allow for improved user interfaces that rival traditional desktop software, as well as the ability to perform simulations and visualizations within the browser. we demonstrate the use of client-side technologies to create an interactive web application for a simulation model of biochemical oxygen demand and dissolved oxygen in rivers called the web-based interactive river model (wirm). we discuss the benefits, limitations and potential uses of client-side web applications, and provide suggestions for future research using new and upcoming web technologies such as offline access and local data storage to create more advanced client-side web applications for environmental simulation modeling. © 2014 elsevier ltd.",a client-side web application for interactive environmental simulation modeling
1592,2-s2.0-84897699676,10.4028/www.scientific.net/AMM.513-517.822,Google maps-based geospatial application framework with custom layers management,Titanto M.,Applied Mechanics and Materials,2014-03-12,"Web 2.0 technologies have offered interactive map services on the Internet. Google Maps is a map service that makes available its API (application programming interface) for developing Web-based geospatial applications. In such applications, layers are used to organise spatial data. Using layers, users can abstract from data that are irrelevant to their interest. However, Google Maps API has no direct support to the development of custom layers management. Developers have to design and implement such support in every application they develop. It makes the development processes less efficient and error prone. This paper proposes a software framework to facilitate the development of geospatial applications with custom layers based on Google Maps. Using this framework, developers can produce higher quality applications in shorter time. © (2014) Trans Tech Publications, Switzerland.",Application framework | Custom layers | Geospatial application | Google maps,1,822-826,Book Series,Conference Paper,2.0,"Titanto, Mardityo Tulus;Dirgahayu, Teduh",56102498200;22984892800,Universitas Islam Indonesia,Indonesia,"web 2.0 technologies have offered interactive map services on the internet. google maps is a map service that makes available its api (application programming interface) for developing web-based geospatial applications. in such applications, layers are used to organise spatial data. using layers, users can abstract from data that are irrelevant to their interest. however, google maps api has no direct support to the development of custom layers management. developers have to design and implement such support in every application they develop. it makes the development processes less efficient and error prone. this paper proposes a software framework to facilitate the development of geospatial applications with custom layers based on google maps. using this framework, developers can produce higher quality applications in shorter time. © (2014) trans tech publications, switzerland.",google maps-based geospatial application framework with custom layers management
1593,2-s2.0-84946686115,10.1109/WISA.2014.20,Static type analysis for python,Dong T.,"Proceedings - 11th Web Information System and Application Conference, WISA 2014",2014-03-10,"Python is a kind of dynamic-typed language which provides flexibility but leaves the programmer without the benefits of static typing. This paper describes Type, a tool that works for static type annotation and inference for python. It could simulate the built-in modules, transform the Python source code to IR(Intermediate representation) which we design and annotate, infer and reduce the IR into the type system. Type could provide the explicit type information, detect the type errors at compile time and improve the efficiency of development and the accuracy of point-to analysis. By the evaluation of applying Type to a suite of benchmarks, we find that Type can annotate and infer the types with a good precision and coverage in accept time.",Python | Type analysis | Type annotation | Type inference,1,65-68,Conference Proceeding,Conference Paper,4.0,"Dong, Tiancong;Chen, Lin;Xu, Zhaogui;Yu, Bin",56583517200;57189042207;55884412400;56583151300,Nanjing University;PLA,China;China,"python is a kind of dynamic-typed language which provides flexibility but leaves the programmer without the benefits of static typing. this paper describes type, a tool that works for static type annotation and inference for python. it could simulate the built-in modules, transform the python source code to ir(intermediate representation) which we design and annotate, infer and reduce the ir into the type system. type could provide the explicit type information, detect the type errors at compile time and improve the efficiency of development and the accuracy of point-to analysis. by the evaluation of applying type to a suite of benchmarks, we find that type can annotate and infer the types with a good precision and coverage in accept time.",static type analysis for python
1595,2-s2.0-84930427542,10.1007/978-3-319-04447-7_13,'Weird Machine' patterns,Bratus S.,Cyberpatterns: Unifying Design Patterns with Security and Attack Patterns,2014-03-01,"You do not understand how your program really works until it has been exploited. We believe that computer scientists and software engineers should regard the activity of modern exploitation as an applied discipline that studies both the actual computational properties and the practical computational limits of a target platform or system. Exploit developers study the computational properties of software that are not studied elsewhere, and they apply unique engineering techniques to the challenging engineering problem of dynamically patching and controlling a running system. These techniques leverage software and hardware composition mechanisms in unexpected ways to achieve such control. Although unexpected, such composition is not arbitrary, and it forms the basis of a coherent engineering workflow. This chapter contains a top-level overview of these approaches and their historical development.",Assumption | Composition | Exploit | Linux | Side effects | Weird machine,2,157-171,Book,Book Chapter,6.0,"Bratus, Sergey;Bangert, Julian;Gabrovsky, Alexandar;Shubina, Anna;Locasto, Michael E.;Bilar, Daniel",6505845456;56669565600;56669731700;25652148900;14024637200;22933249600,"Dartmouth College;University of Calgary;Siege Technologies, LLC",United States;Canada;United States,"you do not understand how your program really works until it has been exploited. we believe that computer scientists and software engineers should regard the activity of modern exploitation as an applied discipline that studies both the actual computational properties and the practical computational limits of a target platform or system. exploit developers study the computational properties of software that are not studied elsewhere, and they apply unique engineering techniques to the challenging engineering problem of dynamically patching and controlling a running system. these techniques leverage software and hardware composition mechanisms in unexpected ways to achieve such control. although unexpected, such composition is not arbitrary, and it forms the basis of a coherent engineering workflow. this chapter contains a top-level overview of these approaches and their historical development.",'weird machine' patterns
1596,2-s2.0-84893958938,10.4028/www.scientific.net/AMM.490-491.1553,A performance testing tool for source code,Luo J.,Applied Mechanics and Materials,2014-02-20,"With the rapid development of the information age, computer software develops toward systematization and complication. In application areas such as commerce, finance and medical treatment, the performance of software is attracting more and more attention which even becomes one of the important factors to determine whether users are willing to use a piece of software. Currently, static checking tools are mostly designed to check the code errors but pay little attention to the performance problems. In order to detect the defects in source code that may cause performance problems, this paper designs and achieves a performance testing tool based on static analysis method. The experiments of detecting several open source projects using our testing tool demonstrate that it can quickly find the defects in source code with high accuracy rate. The result of defection removing shows that it can significantly reduce the memory consumption of software, and it can effectively improve software performance. © (2014) Trans Tech Publications, Switzerland.",Code analysis | Memory consumption | Performance optimization | Static analysis,1,1553-1559,Book Series,Conference Paper,2.0,"Luo, Jun;Yang, Wei",56034854000;57001308200,University of Science and Technology of China,China,"with the rapid development of the information age, computer software develops toward systematization and complication. in application areas such as commerce, finance and medical treatment, the performance of software is attracting more and more attention which even becomes one of the important factors to determine whether users are willing to use a piece of software. currently, static checking tools are mostly designed to check the code errors but pay little attention to the performance problems. in order to detect the defects in source code that may cause performance problems, this paper designs and achieves a performance testing tool based on static analysis method. the experiments of detecting several open source projects using our testing tool demonstrate that it can quickly find the defects in source code with high accuracy rate. the result of defection removing shows that it can significantly reduce the memory consumption of software, and it can effectively improve software performance. © (2014) trans tech publications, switzerland.",a performance testing tool for source code
1597,2-s2.0-84893733027,10.1007/978-94-007-7262-5143,Cross-platform and light-weight stroke rehabilitation system for new generation pervasive healthcare,Wu E.,Lecture Notes in Electrical Engineering,2014-02-17,"We propose a concept allowing disabled patient taking their rehabilitation treatment without going to the hospital. We design a portable device of rehabilitation and it can be lightweight in an advanced version. Particularly, we select PhoneGap to be a mobile development framework and to build the specific application for mobile devices using JavaScript, HTML5, and CSS3 instead of using device-specific language in our system. The great advantage is cross-platform that represent write once and run anywhere. In our software, we lead the patient to do the exercise of rehabilitation step-by-step and then store recovery status in database. Finally, the system will play restful music when patient do exercise. According to the mentioned above, we developed the Mobility Rehabilitation that combines mobility, entertainment, and storing ability. © Springer Science+Business Media Dordrecht 2014.",Cross-platform | Lightweight | PhoneGap | Rehabilitation,0,1269-1277,Book Series,Conference Paper,6.0,"Wu, Eric Hsiao Kuang;Tseng, C. C.;Yang, Y. Y.;Cai, P. Y.;Yen, S. S.;Chen, Yu Wei",55366211300;57199777761;57192548905;56031893000;56032017300;13006809800,National Central University;Landseed Hospital,Taiwan;Taiwan,"we propose a concept allowing disabled patient taking their rehabilitation treatment without going to the hospital. we design a portable device of rehabilitation and it can be lightweight in an advanced version. particularly, we select phonegap to be a mobile development framework and to build the specific application for mobile devices using javascript, html5, and css3 instead of using device-specific language in our system. the great advantage is cross-platform that represent write once and run anywhere. in our software, we lead the patient to do the exercise of rehabilitation step-by-step and then store recovery status in database. finally, the system will play restful music when patient do exercise. according to the mentioned above, we developed the mobility rehabilitation that combines mobility, entertainment, and storing ability. © springer science+business media dordrecht 2014.",cross-platform and light-weight stroke rehabilitation system for new generation pervasive healthcare
1598,2-s2.0-84893173202,10.1177/0266666913480976,Demand and support for enterprise applications integration in Nigeria,Ehikhamenor F.,Information Development,2014-02-01,"The demand and support for enterprise applications integration (EAI) in Nigeria was investigated. The findings show that the demand and support for EAI are driven by a number of factors, including concern for data/information integration, a common interface for all enterprise applications, improved communication and faster data transfer, real-time data capture and access to information across various networks, as well as data and information integrity across various systems. The IT companies in Nigeria are following the progress of technology and are poised to respond to it in their approaches to EAI solutions. Their future approaches will be influenced to the greatest extent by progress in Graphical User Interface (GUI) and then by developments in Enterprise Resource Planning (ERP), Operating Systems, Software as a Service (SaaS), Parameterization of applications for easy customization, Applications Service Provision, and Open Source Systems in that order. They believe that Nigeria has the greatest capacity in Software as a Service (SaaS) and Software as Secured Service (SaSS). A growing number of companies are using open source tools in developing and implementing EAI solutions, and this is an indication of a market that is taking on its own character but also a subscription to the democratization of software access. The popularity of SQL Server and its varieties, closely followed by Oracle and Java/Javascript, as EAI tools in Nigeria is probably a reflection of their prominence on the international scene. © The Author(s) 2013.",enterprise applications integration | information technology applications | Nigeria | software applications,1,80-94,Journal,Article,3.0,"Ehikhamenor, Fabian A.;Bamitale, Adebayo A.;Owens-Ibie, Osamudiamen",6602604412;22984374700;56021153300,Tulane University;University of Ibadan,United States;Nigeria,"the demand and support for enterprise applications integration (eai) in nigeria was investigated. the findings show that the demand and support for eai are driven by a number of factors, including concern for data/information integration, a common interface for all enterprise applications, improved communication and faster data transfer, real-time data capture and access to information across various networks, as well as data and information integrity across various systems. the it companies in nigeria are following the progress of technology and are poised to respond to it in their approaches to eai solutions. their future approaches will be influenced to the greatest extent by progress in graphical user interface (gui) and then by developments in enterprise resource planning (erp), operating systems, software as a service (saas), parameterization of applications for easy customization, applications service provision, and open source systems in that order. they believe that nigeria has the greatest capacity in software as a service (saas) and software as secured service (sass). a growing number of companies are using open source tools in developing and implementing eai solutions, and this is an indication of a market that is taking on its own character but also a subscription to the democratization of software access. the popularity of sql server and its varieties, closely followed by oracle and java/javascript, as eai tools in nigeria is probably a reflection of their prominence on the international scene. © the author(s) 2013.",demand and support for enterprise applications integration in nigeria
1599,2-s2.0-84890117562,10.1016/j.csi.2013.08.007,Using standards to build the DIMAG connected mobile applications framework,Miravet P.,Computer Standards and Interfaces,2014-02-01,"The development of connected mobile applications is a complex task due to device diversity. Therefore, device-independent approaches are aimed at hiding the differences among the distinct mobile devices in the market. This work proposes DIMAG, a software framework to generate connected mobile applications for multiple software platforms, following a declarative approach. DIMAG provides transparent data and state synchronization between the server and the client side applications. The proposed platform has been designed making use of existing standards, extending them when a required functionality is not provided. © 2013 Elsevier B.V.",Data and state synchronization | Device fragmentation | Dynamic code generation | Mobile applications | Partially connected architectures,2,354-367,Journal,Article,4.0,"Miravet, Patricia;Ortin, Francisco;Marin, Ignacio;Rionda, Abel",35792492600;6602898630;56365232600;25961035100,Universidad de Oviedo;CTIC Foundation,Spain;Spain,"the development of connected mobile applications is a complex task due to device diversity. therefore, device-independent approaches are aimed at hiding the differences among the distinct mobile devices in the market. this work proposes dimag, a software framework to generate connected mobile applications for multiple software platforms, following a declarative approach. dimag provides transparent data and state synchronization between the server and the client side applications. the proposed platform has been designed making use of existing standards, extending them when a required functionality is not provided. © 2013 elsevier b.v.",using standards to build the dimag connected mobile applications framework
1600,2-s2.0-84894477759,10.1016/j.jss.2013.12.029,Radigost: Interoperable web-based multi-agent platform,Mitrović D.,Journal of Systems and Software,2014-01-22,"Recent improvements of web development technologies, commonly referred to as HTML5, have resulted in an excellent framework for developing a fully-featured, purely web-based multi-agent platform. This paper presents an architecture of such a platform, named Radigost. Radigost agents and parts of the system itself are implemented in JavaScript and executed inside the client's web browser, while an additional set of Java-based components is deployed on an enterprise application server. Radigost is platform-independent, capable of running, without any prior installation or configuration steps, on a wide variety of software and hardware configurations, including personal computers, smartphones, tablets, and modern television sets. The system is standards-compliant and fully interoperable, in the sense that its agents can transparently interact with agents in existing, third-party multi-agent solutions. Finally, performance evaluation results show that the execution speed of Radigost is comparable to that of a non web-based implementation. © 2014 Elsevier Inc.",Distributed architecture | Multi-agent platform | Software agents | Web development,26,167-178,Journal,Article,4.0,"Mitrović, Dejan;Ivanović, Mirjana;Budimac, Zoran;Vidaković, Milan",36918647700;7005907326;6505861714;6603600626,University of Novi Sad,Serbia,"recent improvements of web development technologies, commonly referred to as html5, have resulted in an excellent framework for developing a fully-featured, purely web-based multi-agent platform. this paper presents an architecture of such a platform, named radigost. radigost agents and parts of the system itself are implemented in javascript and executed inside the client's web browser, while an additional set of java-based components is deployed on an enterprise application server. radigost is platform-independent, capable of running, without any prior installation or configuration steps, on a wide variety of software and hardware configurations, including personal computers, smartphones, tablets, and modern television sets. the system is standards-compliant and fully interoperable, in the sense that its agents can transparently interact with agents in existing, third-party multi-agent solutions. finally, performance evaluation results show that the execution speed of radigost is comparable to that of a non web-based implementation. © 2014 elsevier inc.",radigost: interoperable web-based multi-agent platform
1604,2-s2.0-84988306016,10.1109/SEARIS.2014.7152798,When Model Driven Engineering meets virtual reality: Feedback from application to the Collaviz framework,Duval T.,"2014 IEEE 7th Workshop on Software Engineering and Architectures for Realtime Interactive Systems, SEARIS 2014",2014-01-01,"Despite the increasing use of 3D Collaborative Virtual Environments (3D CVE), their development is still a cumbersome task. The various concerns to consider (distributed system, 3D graphics, etc.) complexify the development as well as the evolution of CVEs. Software engineering recently proposed methods and tools to ease the development process of complex software systems. Among them, Model-Driven Engineering (MDE) considers models as first-class entities. A model is an abstraction of a specific aspect of the system under study for a specific purpose. MDE thus breaks down a complex system into as many models for different purposes, such as: generating code from models; building domain specific programming/modeling languages (DSL); generating tools such as graphical or textual editors. In this paper we leverage MDE for developing 3D CVEs. We show how the Collaviz framework took benefits from a DSL we built. The benefits are multiple: 3D CVE designers can focus on the behavior of their virtual objects without bothering with distributed and graphics features; configuring the content of 3D CVEs and their deployment on various software and hardware platforms can be automated through code generation. We detail the development process we propose and the experiments we conducted on Collaviz.",Collaborative Virtual Environments | Frameworks | Model Driven Engineering | Software Engineering | Virtual Reality,7,27-34,Conference Proceeding,Conference Paper,3.0,"Duval, Thierry;Blouin, Arnaud;Jezequel, Jean Marc",55931172200;23134699800;35618077100,Universite de Rennes 1;Institut de Recherche en Informatique et Systèmes Aléatoires,France;France,"despite the increasing use of 3d collaborative virtual environments (3d cve), their development is still a cumbersome task. the various concerns to consider (distributed system, 3d graphics, etc.) complexify the development as well as the evolution of cves. software engineering recently proposed methods and tools to ease the development process of complex software systems. among them, model-driven engineering (mde) considers models as first-class entities. a model is an abstraction of a specific aspect of the system under study for a specific purpose. mde thus breaks down a complex system into as many models for different purposes, such as: generating code from models; building domain specific programming/modeling languages (dsl); generating tools such as graphical or textual editors. in this paper we leverage mde for developing 3d cves. we show how the collaviz framework took benefits from a dsl we built. the benefits are multiple: 3d cve designers can focus on the behavior of their virtual objects without bothering with distributed and graphics features; configuring the content of 3d cves and their deployment on various software and hardware platforms can be automated through code generation. we detail the development process we propose and the experiments we conducted on collaviz.",when model driven engineering meets virtual reality: feedback from application to the collaviz framework
1608,2-s2.0-84958546241,10.1007/978-3-319-07626-3_31,Device agnostic CASS Client,Salo K.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2014-01-01,"The growth in take-up of smartphones and tablet devices has made longitudinal and context-aware documenting of daily life easier. The Contextual Activity Sampling is a research methodology for the contextual tracking of activities. To support this methodology, an IT-system called CASS (Contextual Activity Sampling System) was developed. It consists of a backend service and a front-end system. The front-end system needs to run in different devices. Instead of developing a separate software for all major device platforms we designed and implemented a software architecture that is based on HTML5 and enables basic functionalities to run in browsers and enhanced functionalities to run as native applications. Thus CASS usage as a research tool will be widened as it supports a large base of different types of devices from PCs to tablets and smart phones. © 2014 Springer International Publishing Switzerland.",AngularJS | contextual activity sampling | cross-platform development | html5 | JavaScript framework | PhoneGap | web technologies,2,334-345,Book Series,Conference Paper,3.0,"Salo, Kari;Shakya, Udeep;Damena, Michael",55218181500;56336026500;56335870500,Helsinki Metropolia University of Applied Sciences,Finland,"the growth in take-up of smartphones and tablet devices has made longitudinal and context-aware documenting of daily life easier. the contextual activity sampling is a research methodology for the contextual tracking of activities. to support this methodology, an it-system called cass (contextual activity sampling system) was developed. it consists of a backend service and a front-end system. the front-end system needs to run in different devices. instead of developing a separate software for all major device platforms we designed and implemented a software architecture that is based on html5 and enables basic functionalities to run in browsers and enhanced functionalities to run as native applications. thus cass usage as a research tool will be widened as it supports a large base of different types of devices from pcs to tablets and smart phones. © 2014 springer international publishing switzerland.",device agnostic cass client
1610,2-s2.0-84958521446,10.1007/978-3-319-07668-3_66,Basil.js - Bridging Mouse and Code Based Design Strategies,Zeller L.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2014-01-01,In this paper we present our JavaScript library basil.js that makes scripting and automation in Adobe InDesign accessible to designers with little previous knowledge in programming. We outline how we derived our API design from the Processing project and applied it to Adobe InDesign. We explain the benefits of combining code and mouse based design strategies within one software package and show how creative users can benefit from the possibility to extend their existing software tools. Lastly the current state of our project is reported and application examples in the form of student projects are given. © 2014 Springer International Publishing Switzerland.,Adobe InDesign | computational aesthetics | educational programming language | Generative design | JavaScript | Processing | tool development | tool modification,0,686-696,Book Series,Conference Paper,3.0,"Zeller, Ludwig;Groß, Benedikt;Davis, Ted",34882439300;57219460988;56335782900,Fachhochschule Nordwestschweiz FHNW,Switzerland,in this paper we present our javascript library basil.js that makes scripting and automation in adobe indesign accessible to designers with little previous knowledge in programming. we outline how we derived our api design from the processing project and applied it to adobe indesign. we explain the benefits of combining code and mouse based design strategies within one software package and show how creative users can benefit from the possibility to extend their existing software tools. lastly the current state of our project is reported and application examples in the form of student projects are given. © 2014 springer international publishing switzerland.,basil.js - bridging mouse and code based design strategies
1612,2-s2.0-84949954373,10.1109/APSEC.2014.26,A model-driven approach to generate mobile applications for multiple platforms,Usman M.,"Proceedings - Asia-Pacific Software Engineering Conference, APSEC",2014-01-01,"Mobile application development has emerged as one of the most focused areas in software industry due to exponential growth of mobile users and applications. The focus of the current mobile industry is on direct implementation, rather than analysis and design. Model-driven engineering practices are ignored, which results in low reusability and lack of portability along with other challenges. In addition, mobile applications also have to support multiple platforms, as an application written for one platform (e.g., Android) cannot run on another platform (e.g., Windows Phone). Each of the platforms in turn suffers from fragmentation. This results in multiple versions of an application that need to be simultaneously maintained. This is a huge burden on the development team, both in terms of cost and effort, due to various platforms that an application supports. This paper proposes a model-driven approach to generate mobile applications for multiple platforms. We carefully identify a subset of UML and propose a modeling methodology for this purpose. We use real use-cases for requirement gathering, class diagram for structural modeling, while state machine are used for behavioral modeling. We focus on modeling business logic layer for the mobile application. We also propose a UML profile for modeling mobile domain specific concepts. Our approach uses Action Language for Foundational Subset of UML (ALF) to specify actions in the state machines. Our approach allows the modeler to automatically generate business logic code for multiple platforms. The approach is supported by an automated tool MAG (Mobile Application Generator). We apply our model-driven approach on an industrial case study 'Scramble' app developed by 'NextIn' to demonstrate its viability.",Automated application generation | Class diagram | Mobile software engineering | Native application | State machine | UML | Use-case diagram,25,111-118,Conference Proceeding,Conference Paper,3.0,"Usman, Muhammad;Iqbal, Muhammad Zohaib;Khan, Muhammad Uzair",56844860100;57222997737;55602694800,University of Luxembourg;National University of Computer and Emerging Sciences Islamabad,Luxembourg;Pakistan,"mobile application development has emerged as one of the most focused areas in software industry due to exponential growth of mobile users and applications. the focus of the current mobile industry is on direct implementation, rather than analysis and design. model-driven engineering practices are ignored, which results in low reusability and lack of portability along with other challenges. in addition, mobile applications also have to support multiple platforms, as an application written for one platform (e.g., android) cannot run on another platform (e.g., windows phone). each of the platforms in turn suffers from fragmentation. this results in multiple versions of an application that need to be simultaneously maintained. this is a huge burden on the development team, both in terms of cost and effort, due to various platforms that an application supports. this paper proposes a model-driven approach to generate mobile applications for multiple platforms. we carefully identify a subset of uml and propose a modeling methodology for this purpose. we use real use-cases for requirement gathering, class diagram for structural modeling, while state machine are used for behavioral modeling. we focus on modeling business logic layer for the mobile application. we also propose a uml profile for modeling mobile domain specific concepts. our approach uses action language for foundational subset of uml (alf) to specify actions in the state machines. our approach allows the modeler to automatically generate business logic code for multiple platforms. the approach is supported by an automated tool mag (mobile application generator). we apply our model-driven approach on an industrial case study 'scramble' app developed by 'nextin' to demonstrate its viability.",a model-driven approach to generate mobile applications for multiple platforms
1613,2-s2.0-84949132900,10.1016/j.proeng.2014.11.233,Web services for water systems: The iWIDGET REST API,Barry M.G.,Procedia Engineering,2014-01-01,"The iWIDGET project has a special focus on the role of smart water meters for understating consumption and improving system operations. To support the project and future commercial developments, a distributed platform supported by a web based application programming interface (API) has been developed to allow developers to rapidly prototype and develop applications and user interfaces for different devices and systems including Windows, Mac OS, Linux, iOS, Android and others. The iWIDGET API is based on representational state transfer (REST), with data accessed by a web address or URI structured as a request or query.",Data standards and protocols | Hydroinformatics | Web services,5,1120-1127,Conference Proceeding,Conference Paper,5.0,"Barry, M. G.;Purcell, M. E.;Eck, B. J.;Hayes, J.;Arandia, E.",57197582213;32868009700;26537357500;16021933000;56521625600,"IBM Research Europe, Ireland",Ireland,"the iwidget project has a special focus on the role of smart water meters for understating consumption and improving system operations. to support the project and future commercial developments, a distributed platform supported by a web based application programming interface (api) has been developed to allow developers to rapidly prototype and develop applications and user interfaces for different devices and systems including windows, mac os, linux, ios, android and others. the iwidget api is based on representational state transfer (rest), with data accessed by a web address or uri structured as a request or query.",web services for water systems: the iwidget rest api
1618,2-s2.0-84931025897,10.1108/APJML-07-2013-0084,Clarifying the impact of product scarcity and perceived uniqueness in buyers’ purchase behavior of games of limited-amount version,Chen H.,Asia Pacific Journal of Marketing and Logistics,2014-01-01,"Purpose – Different from general goods, games are intangible. Games of limited-amount version are much more expensive. However, the value of games cannot be actually validated, while buyers purchase the intangible goods. This study, therefore, aims to empirically clarify the impact of product scarcity and uniqueness in buyers’ purchase of games of limited-amount version. Design/methodology/approach – Based on literature review, the survey method was conducted. Data of 204 respondents who recently bought games of limited-amount version were gathered and analyzed with partial least square. Findings – The results showed that perceived quality and perceived uniqueness, significantly increased by product scarcity, was shown of significant positive impact on perceived value which significantly enhanced purchase intention. Research limitations/implications – The results indicated the importance of high quality and the reflection of uniqueness in buyers’ purchase of games of limited-amount version. The results also validated the effect of scarcity on intangible goods. Practically, the results facilitated strategic operation and marketing of game producers and suppliers in designing and marketing game software. The results also facilitated further theoretical development of goods scarcity. Originality/value – Nowadays, product scarcity has been an important operation and marketing strategy to enterprises. Games are an industry of growing importance. However, the impact of scarcity in buyers’ purchase of games of limited-amount version was still limited. The results validated the importance of scarcity and perceived uniqueness in intangible game goods purchase behavior. The validation of this study can provide references for strategic operation andmarketing of the game industry.",Behavioral psychology | Consumer behavior | Consumption values | PLS,16,232-249,Journal,Article,2.0,"Chen, Hsiu Ju;Sun, Tzu Hui",15071747900;56683674000,I-Shou University,Taiwan,"purpose – different from general goods, games are intangible. games of limited-amount version are much more expensive. however, the value of games cannot be actually validated, while buyers purchase the intangible goods. this study, therefore, aims to empirically clarify the impact of product scarcity and uniqueness in buyers’ purchase of games of limited-amount version. design/methodology/approach – based on literature review, the survey method was conducted. data of 204 respondents who recently bought games of limited-amount version were gathered and analyzed with partial least square. findings – the results showed that perceived quality and perceived uniqueness, significantly increased by product scarcity, was shown of significant positive impact on perceived value which significantly enhanced purchase intention. research limitations/implications – the results indicated the importance of high quality and the reflection of uniqueness in buyers’ purchase of games of limited-amount version. the results also validated the effect of scarcity on intangible goods. practically, the results facilitated strategic operation and marketing of game producers and suppliers in designing and marketing game software. the results also facilitated further theoretical development of goods scarcity. originality/value – nowadays, product scarcity has been an important operation and marketing strategy to enterprises. games are an industry of growing importance. however, the impact of scarcity in buyers’ purchase of games of limited-amount version was still limited. the results validated the importance of scarcity and perceived uniqueness in intangible game goods purchase behavior. the validation of this study can provide references for strategic operation andmarketing of the game industry.",clarifying the impact of product scarcity and perceived uniqueness in buyers’ purchase behavior of games of limited-amount version
1619,2-s2.0-84929510532,10.3233/978-1-61499-432-9-93,ChronoQuery: Visual Modelling of Temporal Queries for Real-Time Decision Support,Majeed R.W.,Studies in Health Technology and Informatics,2014-01-01,"Clinical decision support systems are an important aspect of medical informatics. The increasing amount of available patient data requires physicians to rely on information technology for research and during their day by day work. In intensive care medicine, fast actions are especially important. One major step towards enabling direct interaction of medical staff with patient data was the development of clinical data repositories with easy query frontends. While clinical data repositories can be extended for the use of real-time data, the corresponding query frontends do not support the time concepts necessary for real-time queries and decision support. Aim of this project is the development of a user interface to give physicians visual understanding of propositional logic combined with time concepts. Thus, physicians should be able formulate simple time based queries on their own-and validate and quality check complex queries created by medical informatics experts.",Clinical Decision Support Systems | Intensive Care Units | Real-Time Systems,0,93-97,Book Series,Conference Paper,4.0,"Majeed, Raphael W.;Stohr, Mark R.;Brenner, Thorsten;Rohrig, Rainer",54417750200;55562033600;57534254100;55920693700,Justus-Liebig-Universität Gießen;Universität Heidelberg,Germany;Germany,"clinical decision support systems are an important aspect of medical informatics. the increasing amount of available patient data requires physicians to rely on information technology for research and during their day by day work. in intensive care medicine, fast actions are especially important. one major step towards enabling direct interaction of medical staff with patient data was the development of clinical data repositories with easy query frontends. while clinical data repositories can be extended for the use of real-time data, the corresponding query frontends do not support the time concepts necessary for real-time queries and decision support. aim of this project is the development of a user interface to give physicians visual understanding of propositional logic combined with time concepts. thus, physicians should be able formulate simple time based queries on their own-and validate and quality check complex queries created by medical informatics experts.",chronoquery: visual modelling of temporal queries for real-time decision support
1621,2-s2.0-84927913864,10.4018/ijaci.2014010104,An active low cost mesh networking indoor tracking system,Carlin S.,International Journal of Ambient Computing and Intelligence,2014-01-01,"Indoor radio frequency tracking systems are generally quite expensive and can vary in accuracy due to interference, equipment quality or other environmental factors. Due to these limiting factors of the technology, many businesses today find it hard to justify investing in RFID tracking technologies to improve the safety, efficiency and security of their working environments. The aim of this project was to provide a budget RFID tracking system that was capable of tracking a person or object through an indoor environment. To minimize the cost of the RFID tracking system, the components of the system were built from existing electronic equipment and hardware. The software was also written to minimize licensing and support fees allowing a cost effective budget RFID tracking system to be developed. The tracking system consists of a tag, reader nodes and a PC reader which utilize synapse RF 100 engines with python scripts embedded on to the chips. The tracking system software operates through a web portal utilizing web technologies such as HTML, JavaScript and PHP to allow the tags location to be represented on a two dimensional map using scalable vector graphics. During development of the system a new trilateration algorithm was developed and used convert the signals received from the tag to a virtual position on the map correlating to the actual physical position of the tag. A unique contribution of this system is the low cost of building which we estimate as less than €200 UK sterling for a five node system.",HTML | JavaScript | PHP | Radio | Radio frequency | RFID,4,45-79,Journal,Article,2.0,"Carlin, Sean;Curran, Kevin",55849662800;7004243159,Ulster University,United Kingdom,"indoor radio frequency tracking systems are generally quite expensive and can vary in accuracy due to interference, equipment quality or other environmental factors. due to these limiting factors of the technology, many businesses today find it hard to justify investing in rfid tracking technologies to improve the safety, efficiency and security of their working environments. the aim of this project was to provide a budget rfid tracking system that was capable of tracking a person or object through an indoor environment. to minimize the cost of the rfid tracking system, the components of the system were built from existing electronic equipment and hardware. the software was also written to minimize licensing and support fees allowing a cost effective budget rfid tracking system to be developed. the tracking system consists of a tag, reader nodes and a pc reader which utilize synapse rf 100 engines with python scripts embedded on to the chips. the tracking system software operates through a web portal utilizing web technologies such as html, javascript and php to allow the tags location to be represented on a two dimensional map using scalable vector graphics. during development of the system a new trilateration algorithm was developed and used convert the signals received from the tag to a virtual position on the map correlating to the actual physical position of the tag. a unique contribution of this system is the low cost of building which we estimate as less than €200 uk sterling for a five node system.",an active low cost mesh networking indoor tracking system
1624,2-s2.0-84923316123,10.1016/j.procir.2014.10.040,From COTS simulation software to an open-source platform: A use case in the medical device industry,Dagkakis G.,Procedia CIRP,2014-01-01,"The implementation of Discrete Event Simulation (DES)-based decision support tools in complex manufacturing environments could prove of invaluable help to industrial practitioners involved in cross-functional decision processes at multiple hierarchical levels. The increasing number of decision variables, their stochastic nature and the non-linearity of their mutual relationships theoretically make simulation a preferred modelling approach for a great variety of manufacturing systems as strict simplifying assumptions are not necessarily required and the models' detail level can be tuned according to the analysis purposes. However, recourse to Commercial Off-The-Shelf (COTS) simulation packages to develop and implement simulation-based solutions in real manufacturing environments usually presents significant cost-of-ownership (COO). Along with license costs, modelling flexibility and sustainability represent fundamental issues raised by industrial engineers that adopt COTS simulation packages. In order to promote the use of DES in production related decision making processes and reduce the associated COO for manufacturing companies, an open-source simulation platform, ManPy, has been developed. ManPy consists of a library of DES objects implemented in SimPy. ManPy's scope is to provide modellers with generic, highly customizable open-source simulation objects that can be connected to form a model in the same fashion of COTS simulation packages. ManPy's on-going development is based on guidelines provided by the analysis of real industrial use cases. Specific pilot models developed in SimPy are used to identify new objects and relevant features to be incorporated in ManPy in order to make it a highly flexible simulation tool. In this article, a use case based on a labour intensive serial production line operating in a medical device manufacturing plant is described. Insights for the transition from a COTS simulation model to a specific SimPy model and finally to generic ManPy objects are presented.",Discrete event simulation | ManPy | Modelling flexibility | Open-source software | SimPy,2,283-292,Conference Proceeding,Conference Paper,7.0,"Dagkakis, Georgios;Rotondo, Anna;Papagiannopoulos, Ioannis;Heavy, Cathal;Geraghty, John;Young, Paul;Holland, Rob",56111865500;55206086800;57199673143;56525231900;24724117000;7402038208;57197147174,Dublin City University;University of Limerick;Cork Clinic,Ireland;Ireland;Ireland,"the implementation of discrete event simulation (des)-based decision support tools in complex manufacturing environments could prove of invaluable help to industrial practitioners involved in cross-functional decision processes at multiple hierarchical levels. the increasing number of decision variables, their stochastic nature and the non-linearity of their mutual relationships theoretically make simulation a preferred modelling approach for a great variety of manufacturing systems as strict simplifying assumptions are not necessarily required and the models' detail level can be tuned according to the analysis purposes. however, recourse to commercial off-the-shelf (cots) simulation packages to develop and implement simulation-based solutions in real manufacturing environments usually presents significant cost-of-ownership (coo). along with license costs, modelling flexibility and sustainability represent fundamental issues raised by industrial engineers that adopt cots simulation packages. in order to promote the use of des in production related decision making processes and reduce the associated coo for manufacturing companies, an open-source simulation platform, manpy, has been developed. manpy consists of a library of des objects implemented in simpy. manpy's scope is to provide modellers with generic, highly customizable open-source simulation objects that can be connected to form a model in the same fashion of cots simulation packages. manpy's on-going development is based on guidelines provided by the analysis of real industrial use cases. specific pilot models developed in simpy are used to identify new objects and relevant features to be incorporated in manpy in order to make it a highly flexible simulation tool. in this article, a use case based on a labour intensive serial production line operating in a medical device manufacturing plant is described. insights for the transition from a cots simulation model to a specific simpy model and finally to generic manpy objects are presented.",from cots simulation software to an open-source platform: a use case in the medical device industry
1628,2-s2.0-84921416198,10.1007/978-3-319-11653-2_1,Model-driven development of mobile applications allowing role-driven variants,Vaupel S.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2014-01-01,"Rapidly increasing numbers of applications and users make the development of mobile applications to one of the most promising fields in software engineering. Due to short time-to-market, differing platforms and fast emerging technologies, mobile application development faces typical challenges where model-driven development can help. We present a modeling language and an infrastructure for the model-driven development (MDD) of Android apps supporting the specification of different app variants according to user roles. For example, providing users may continuously configure and modify custom content with one app variant whereas end users are supposed to use provided content in their variant. Our approach allows a flexible app development on different abstraction levels: compact modeling of standard app elements, detailed modeling of individual elements, and separate provider models for specific custom needs. We demonstrate our MDD-approach at two apps: a phone book manager and a conference guide being configured by conference organizers for participants.",Android | Mobile application | Model-driven development,27,1-17,Book Series,Article,6.0,"Vaupel, Steffen;Taentzer, Gabriele;Harries, Jan Peer;Stroh, Raphael;Gerlach, René;Guckert, Michael",56487819300;6603840394;56487202400;56487627200;56487131500;56487813200,Philipps-Universität Marburg;Technische Hochschule Mittelhessen,Germany;Germany,"rapidly increasing numbers of applications and users make the development of mobile applications to one of the most promising fields in software engineering. due to short time-to-market, differing platforms and fast emerging technologies, mobile application development faces typical challenges where model-driven development can help. we present a modeling language and an infrastructure for the model-driven development (mdd) of android apps supporting the specification of different app variants according to user roles. for example, providing users may continuously configure and modify custom content with one app variant whereas end users are supposed to use provided content in their variant. our approach allows a flexible app development on different abstraction levels: compact modeling of standard app elements, detailed modeling of individual elements, and separate provider models for specific custom needs. we demonstrate our mdd-approach at two apps: a phone book manager and a conference guide being configured by conference organizers for participants.",model-driven development of mobile applications allowing role-driven variants
1634,2-s2.0-84908891821,10.5220/0005114205290534,SQLReports: Yet another relational database reporting system,Afonin S.,ICSOFT-EA 2014 - Proceedings of the 9th International Conference on Software Engineering and Applications,2014-01-01,"Popular web application frameworks, such as Django, do not provide efficient tools for rapid report development. Specialized reporting software are targeted at visual representation and can generate perfect printed versions of the report. In this paper we describe a minimalistic but quite powerful reporting system developed for a web-based university information system. This reporting system supports zero-programing report development, parametrization of SQL queries, interactive results processing by means of client-side JavaScript libraries, and cross-report references. Main features are similar to well-known reporting systems, such as JasperReports, with more attention to reuse of developed reports, simplicity and interactivity.",Django | Reporting software | SQL | Template language,1,529-534,Conference Proceeding,Conference Paper,3.0,"Afonin, Sergey;Kozitsyn, Alexander;Astapov, Ivan",24779401300;8547888300;57189701107,Lomonosov Moscow State University,Russian Federation,"popular web application frameworks, such as django, do not provide efficient tools for rapid report development. specialized reporting software are targeted at visual representation and can generate perfect printed versions of the report. in this paper we describe a minimalistic but quite powerful reporting system developed for a web-based university information system. this reporting system supports zero-programing report development, parametrization of sql queries, interactive results processing by means of client-side javascript libraries, and cross-report references. main features are similar to well-known reporting systems, such as jasperreports, with more attention to reuse of developed reports, simplicity and interactivity.",sqlreports: yet another relational database reporting system
1635,2-s2.0-84908884606,10.5220/0004994103150320,Pex extension for generating user input validation code for web applications,Frajták K.,ICSOFT-EA 2014 - Proceedings of the 9th International Conference on Software Engineering and Applications,2014-01-01,"The code written by a software developer is not always flawless. The more code is created the more errors are introduced into the system. In web development different programming languages can be used to implement back-end and front-end sides of the application. For example, it is possible to implement user input validation multiple times - it validates the input values on client-side using JavaScript before the data is sent to server and then the received data is validated again on the server-side. The logic is duplicated, changes made to the validation code must be synchronised on both sides. All implementations must be also unit tested, which increases the time required to create and maintain multiple sets of unit tests. In this paper, we will describe how white-box testing tool Pex can be extended to generate user input validation code for ASP.NET MVC web applications. The validation code won't be duplicated in JavaScript on the client-side and the application will be protected from sending invalid input values from the client-side. The testers can focus on testing using meaningful data input values. Testing of corner cases can be automated thus saving the available resources - testers involved in testing and time spent on testing.",Code generation | User input validation | Web application testing,0,315-320,Conference Proceeding,Conference Paper,3.0,"Frajták, Karel;Bureš, Miroslav;Jelínek, Ivan",48861099800;14015114200;7003865724,Czech Technical University in Prague,Czech Republic,"the code written by a software developer is not always flawless. the more code is created the more errors are introduced into the system. in web development different programming languages can be used to implement back-end and front-end sides of the application. for example, it is possible to implement user input validation multiple times - it validates the input values on client-side using javascript before the data is sent to server and then the received data is validated again on the server-side. the logic is duplicated, changes made to the validation code must be synchronised on both sides. all implementations must be also unit tested, which increases the time required to create and maintain multiple sets of unit tests. in this paper, we will describe how white-box testing tool pex can be extended to generate user input validation code for asp.net mvc web applications. the validation code won't be duplicated in javascript on the client-side and the application will be protected from sending invalid input values from the client-side. the testers can focus on testing using meaningful data input values. testing of corner cases can be automated thus saving the available resources - testers involved in testing and time spent on testing.",pex extension for generating user input validation code for web applications
1636,2-s2.0-84908696161,10.3844/jcssp.2014.1440.1446,"Unified modeling language tools collaboration for use case, class and activity diagram implemented with html 5 and javascript framework",Kurniawan A.,Journal of Computer Science,2014-01-01,"As a result of the development of web 3.0, web technologies now make it possible for each user to collaborate in performing a task. This technology allows us to draw UML diagrams online and collaborate on a software project. Unified Modeling Language is one of the architectural modeling software that is widely used by software developers. This research aims to develop a modeling tool UML diagrams are class diagrams, use case diagrams and activity diagrams based on pre-existing web using HTML 5 technology combine with JSON Service that allows the software developer to work on the same project UML and collaborate each other with good performance more faster than ordinary web.",Activity diagram | CASE tool collaboration | Class diagram | HTML 5 | Unified modelling language | Use case diagram,1,1440-1446,Journal,Article,3.0,"Kurniawan, Aditya;Harefa, Bina Bestina;Sujarwo, Surya",57224145876;56406446100;56180175700,Bina Nusantara University,Indonesia,"as a result of the development of web 3.0, web technologies now make it possible for each user to collaborate in performing a task. this technology allows us to draw uml diagrams online and collaborate on a software project. unified modeling language is one of the architectural modeling software that is widely used by software developers. this research aims to develop a modeling tool uml diagrams are class diagrams, use case diagrams and activity diagrams based on pre-existing web using html 5 technology combine with json service that allows the software developer to work on the same project uml and collaborate each other with good performance more faster than ordinary web.","unified modeling language tools collaboration for use case, class and activity diagram implemented with html 5 and javascript framework"
1637,2-s2.0-84908621965,10.2495/CTA140631,Development of an optimization system for IC manufacturing equipment design,Zhang Z.,WIT Transactions on Information and Communication Technologies,2014-01-01,"In this paper we develop an optimization system, which aims at solving the optimization problems involved in the process of the design for the Integrated Circuit (IC) equipment, and it aids designers to work efficiently and assisting companies to manage the data generated in the design process. The hierarchical architecture of a kind of browser/server (B/S) is adopted including 5 layers: user layer (UL), presentation layer (PL), business logic layer (BLL), data access layer (DAL) and hardware layer (HL). According to the function requirements, the system has five modules: design of experiments (DOE) module, response surface model (RSM) module, optimization module, post-processing module and user management module. HTML, JavaScript, Java Servlet and Ajax are used to build the system. Finally, an example of an electrostatic chuck’s design optimization is introduced to testify the function of the system.",Architecture design | IC equipment | Optimization | Software integration,0,511-519,Conference Proceeding,Conference Paper,3.0,"Zhang, Z. M.;Huang, L. P.;Tian, L.",55890304800;55492435800;52164610100,Tsinghua University,China,"in this paper we develop an optimization system, which aims at solving the optimization problems involved in the process of the design for the integrated circuit (ic) equipment, and it aids designers to work efficiently and assisting companies to manage the data generated in the design process. the hierarchical architecture of a kind of browser/server (b/s) is adopted including 5 layers: user layer (ul), presentation layer (pl), business logic layer (bll), data access layer (dal) and hardware layer (hl). according to the function requirements, the system has five modules: design of experiments (doe) module, response surface model (rsm) module, optimization module, post-processing module and user management module. html, javascript, java servlet and ajax are used to build the system. finally, an example of an electrostatic chuck’s design optimization is introduced to testify the function of the system.",development of an optimization system for ic manufacturing equipment design
1640,2-s2.0-84907398282,10.1145/2633638.2633640,Scripthica: A web environment for collective algorithmic composition,Sanchez Fernandez G.,"FARM 2014 - Proceedings of the 2014 ACM SIGPLAN International Workshop on Functional Art, Music, Modelling and Design",2014-01-01,This paper presents the initial design and development work done on a new open source computer-aided music composition web environment for collective algorithmic music composition. Scripthica is envisioned as a web environment where users can compose and share algorithmic music compositions created with the JavaScript and Scheme programming languages. © 2014 Author.,algorithmic composition | collective composition,0,9-10,Conference Proceeding,Conference Paper,1.0,"Sanchez Fernandez, Gabriel Alejandro",56369540500,New York University,United States,this paper presents the initial design and development work done on a new open source computer-aided music composition web environment for collective algorithmic music composition. scripthica is envisioned as a web environment where users can compose and share algorithmic music compositions created with the javascript and scheme programming languages. © 2014 author.,scripthica: a web environment for collective algorithmic composition
1641,2-s2.0-84907379857,10.5220/0004698202990306,Rapid application development to create proof-of-concept software applications,Lucas Da Silva M.,PhyCS 2014 - Proceedings of the International Conference on Physiological Computing Systems,2014-01-01,"Rapid application development is the best way to test prototypes by giving a solid performance for user's tests, while rapid application customization it is the best approach to easily test the user's needs, such as children with autism spectrum disorders. In this paper we present a framework of a platform designed with these concepts in mind. This platform is a standalone multimedia and rich content software, targeted at students with special needs, that allows to easily expand the functionalities and create proof-of-concept software applications. Copyright © 2014 SCITEPRESS - Science and Technology Publications. All rights reserved.",Autism spectrum disorders | Rapid application customization | Rapid application development,0,299-306,Conference Proceeding,Conference Paper,3.0,"Lucas Da Silva, Margarida;Silva, Hugo;Gonçalves, Daniel",42761251800;54783341500;35588555000,Instituto Superior Técnico;Instituto de Engenharia de Sistemas e Computadores Investigação e Desenvolvimento em Lisboa,Portugal;Portugal,"rapid application development is the best way to test prototypes by giving a solid performance for user's tests, while rapid application customization it is the best approach to easily test the user's needs, such as children with autism spectrum disorders. in this paper we present a framework of a platform designed with these concepts in mind. this platform is a standalone multimedia and rich content software, targeted at students with special needs, that allows to easily expand the functionalities and create proof-of-concept software applications. copyright © 2014 scitepress - science and technology publications. all rights reserved.",rapid application development to create proof-of-concept software applications
1642,2-s2.0-84907187629,10.1214/13-STS462,Enhancing R with advanced compilation tools and methods,Lang D.,Statistical Science,2014-01-01,"I describe an approach to compiling common idioms in R code directly to native machine code and illustrate it with several examples. Not only can this yield significant performance gains, but it allows us to use new approaches to computing in R. Importantly, the compilation requires no changes to R itself, but is done entirely via R packages. This allows others to experiment with different compilation strategies and even to define new domain-specific languages within R. We use the Low-Level Virtual Machine (LLVM) compiler toolkit to create the native code and perform sophisticated optimizations on the code. By adopting this widely used software within R, we leverage its ability to generate code for different platforms such as CPUs and GPUs, and will continue to benefit from its ongoing development. This approach potentially allows us to develop high-level R code that is also fast, that can be compiled to work with different data representations and sources, and that could even be run outside of R. The approach aims to both provide a compiler for a limited subset of the R language and also to enable R programmers to write other compilers. This is another approach to help us write high-level descriptions of what we want to compute, not how.",Compilation | Efficient computation | Extensible compiler toolkit | Programming language,1,167-180,Journal,Article,1.0,"Lang, Duncan Temple",7202377375,"University of California, Davis",United States,"i describe an approach to compiling common idioms in r code directly to native machine code and illustrate it with several examples. not only can this yield significant performance gains, but it allows us to use new approaches to computing in r. importantly, the compilation requires no changes to r itself, but is done entirely via r packages. this allows others to experiment with different compilation strategies and even to define new domain-specific languages within r. we use the low-level virtual machine (llvm) compiler toolkit to create the native code and perform sophisticated optimizations on the code. by adopting this widely used software within r, we leverage its ability to generate code for different platforms such as cpus and gpus, and will continue to benefit from its ongoing development. this approach potentially allows us to develop high-level r code that is also fast, that can be compiled to work with different data representations and sources, and that could even be run outside of r. the approach aims to both provide a compiler for a limited subset of the r language and also to enable r programmers to write other compilers. this is another approach to help us write high-level descriptions of what we want to compute, not how.",enhancing r with advanced compilation tools and methods
1643,2-s2.0-84906753021,10.1109/IISA.2014.6878726,3DSYSTEK web-based point cloud viewer,Maravelakis E.,"IISA 2014 - 5th International Conference on Information, Intelligence, Systems and Applications",2014-01-01,"This paper presents the development of a new Web based LiDAR (Light Detection And Ranging) 3D point cloud viewer addressing mobility and portability issues arising from remote field applications by numerous multidisciplinary collaborative scientists. This new Web Browser-based 3D point cloud viewer, hereafter called 3DSYSTEK viewer, was developed and implemented in the framework of the3DSYSTEK research programme that aimed to develop tools to bring together all disciplines working to promote our cultural heritage through laser scanning, 3D modeling, 3D visualization, documentation, and exploitation of 3D data. 3D point cloud viewers' native implementations although they support multiple applications they are very expensive and their features vary from one software to another with considerable problems arising due to the introduction of personalized file formats by each individual native software. The presented 3DSYSTEK viewer is based on open-software, enables personalized expandability to address specific needs by individual users and allows the online remote collaboration amongst scientists at different locations as well as the widespread usage of the TLS surveying technology and 3D modeling of large monuments. © 2014 IEEE.",3D point cloud | particle system technology | Terrestrial Laser Scanners | web browser based 3D point cloud viewer | web graphics library,11,262-266,Conference Proceeding,Conference Paper,6.0,"Maravelakis, E.;Konstantaras, A.;Kabassi, K.;Chrysakis, I.;Georgis, C.;Axaridou, A.",6506269425;6503884418;6602954103;36695973600;56342766000;16030753000,Institute of Computer Science Crete;Hellenic Mediterranean University;Technological Educational Institute of Ionian Islands,Greece;Greece;Greece,"this paper presents the development of a new web based lidar (light detection and ranging) 3d point cloud viewer addressing mobility and portability issues arising from remote field applications by numerous multidisciplinary collaborative scientists. this new web browser-based 3d point cloud viewer, hereafter called 3dsystek viewer, was developed and implemented in the framework of the3dsystek research programme that aimed to develop tools to bring together all disciplines working to promote our cultural heritage through laser scanning, 3d modeling, 3d visualization, documentation, and exploitation of 3d data. 3d point cloud viewers' native implementations although they support multiple applications they are very expensive and their features vary from one software to another with considerable problems arising due to the introduction of personalized file formats by each individual native software. the presented 3dsystek viewer is based on open-software, enables personalized expandability to address specific needs by individual users and allows the online remote collaboration amongst scientists at different locations as well as the widespread usage of the tls surveying technology and 3d modeling of large monuments. © 2014 ieee.",3dsystek web-based point cloud viewer
1645,2-s2.0-84906062181,10.1145/2637647.2637649,ScalaDyno: Making name resolution and type checking fault-tolerant,Bastin C.,"SCALA 2014 - Proceedings of the 5th Annual Scala Workshop, Co-located with ECOOP 2014",2014-01-01,"The ScalaDyno compilercompiler1 plugin allows fast prototyping with the Scala programming language, in a way that combines the benefits of both statically and dynamically typed languages. Static name resolution and type checking prevent partially-correct code from being compiled and executed. Yet, allowing programmers to test critical paths in a program without worrying about the consistency of the entire code base is crucial to fast prototyping and agile development. This is where ScalaDyno comes in: it allows partiallycorrect programs to be compiled and executed, while shifting compile-time errors to program runtime. The key insight in ScalaDyno is that name and type errors affect limited areas of the code, which can be replaced by instructions to output the respective errors at runtime. This allows byte code generation and execution for partially correct programs, thus allowing Python or JavaScript-like fast prototyping in Scala. This is all done without sacrificing name resolution, full type checking and optimizations for the correct parts of the code - they are still performed, but without getting in the way of agile development. Finally, for release code or sensitive refactoring, runtime errors can be disabled, thus allowing full static name resolution and type checking typical of the Scala compiler.",Deferred type errors | Dynamic typing | Scala,1,1-5,Conference Proceeding,Conference Paper,3.0,"Bastin, Cédric;Ureche, Vlad;Odersky, Martin",56326127300;37462246900;57204251666,Ecole Polytechnique Fédérale de Lausanne,Switzerland,"the scaladyno compilercompiler1 plugin allows fast prototyping with the scala programming language, in a way that combines the benefits of both statically and dynamically typed languages. static name resolution and type checking prevent partially-correct code from being compiled and executed. yet, allowing programmers to test critical paths in a program without worrying about the consistency of the entire code base is crucial to fast prototyping and agile development. this is where scaladyno comes in: it allows partiallycorrect programs to be compiled and executed, while shifting compile-time errors to program runtime. the key insight in scaladyno is that name and type errors affect limited areas of the code, which can be replaced by instructions to output the respective errors at runtime. this allows byte code generation and execution for partially correct programs, thus allowing python or javascript-like fast prototyping in scala. this is all done without sacrificing name resolution, full type checking and optimizations for the correct parts of the code - they are still performed, but without getting in the way of agile development. finally, for release code or sensitive refactoring, runtime errors can be disabled, thus allowing full static name resolution and type checking typical of the scala compiler.",scaladyno: making name resolution and type checking fault-tolerant
1647,2-s2.0-84905455307,10.1007/978-3-662-44468-9_48,NUbugger: A visual real-time robot debugging system,Annable B.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2014-01-01,"As modern autonomous robots have improved in their ability to demonstrate human-like motor skills and reasoning, the size and complexity of software systems have increased proportionally, with developers actively working to leverage the full processing performance of next-generation computational hardware. This software complexity corresponds with increased difficulty in debugging low-level coding issues, with the traditional methodology of inferring such issues from emergent high-level behaviour rapidly approaching intractability. This paper details the development and functionality of NUbugger: a visual, real-time and open source robot debugging utility that provides the user with comprehensive information regarding low-level functionality. This represents a paradigm shift from corrective to preventative debugging, and concrete examples of the application of NUbugger to the identification of fundamental implementation errors are described. The system implementation facilitates simple and rapid extension or modification, making it a useful utility for debugging any similar complex robotic framework. © 2014 Springer-Verlag Berlin Heidelberg.",debugging | open source | robotics | visualisation,3,544-551,Book Series,Conference Paper,3.0,"Annable, Brendan;Budden, David;Mendes, Alexandre",56311504400;55533505100;7102443933,"The University of Newcastle, Australia",Australia,"as modern autonomous robots have improved in their ability to demonstrate human-like motor skills and reasoning, the size and complexity of software systems have increased proportionally, with developers actively working to leverage the full processing performance of next-generation computational hardware. this software complexity corresponds with increased difficulty in debugging low-level coding issues, with the traditional methodology of inferring such issues from emergent high-level behaviour rapidly approaching intractability. this paper details the development and functionality of nubugger: a visual, real-time and open source robot debugging utility that provides the user with comprehensive information regarding low-level functionality. this represents a paradigm shift from corrective to preventative debugging, and concrete examples of the application of nubugger to the identification of fundamental implementation errors are described. the system implementation facilitates simple and rapid extension or modification, making it a useful utility for debugging any similar complex robotic framework. © 2014 springer-verlag berlin heidelberg.",nubugger: a visual real-time robot debugging system
1648,2-s2.0-84904694245,10.1109/JCSSE.2014.6841890,Tool for generating test module for JavaScript based on statement coverage criteria,Janthong P.,"2014 11th Int. Joint Conf. on Computer Science and Software Engineering: ""Human Factors in Computer Science and Software Engineering"" - e-Science and High Performance Computing: eHPC, JCSSE 2014",2014-01-01,"JavaScript is the most popular language for client-side web application development. Some open-source tools provide frameworks for building JavaScript automation test. Developers can create and maintain automate test scripts with these tools. However, they will waste a lot of time to create and maintain test scripts because these are manual activities. This research presents a tool for generating unit test modules for JavaScript to meet statement coverage criteria. The tool can generate test cases by analyzing and instrument source code, generate test cases with random data based on type of parameters, execute the test cases, evaluate coverage, regenerate as well as re-execute until it reaches a target level of statement coverage, and then provide coverage report. © 2014 IEEE.",Automatic Testing | JavaScript | Software Testing,1,331-336,Conference Proceeding,Conference Paper,2.0,"Janthong, Pannawat;Suwannasart, Taratip",56288121700;8963028800,Chulalongkorn University,Thailand,"javascript is the most popular language for client-side web application development. some open-source tools provide frameworks for building javascript automation test. developers can create and maintain automate test scripts with these tools. however, they will waste a lot of time to create and maintain test scripts because these are manual activities. this research presents a tool for generating unit test modules for javascript to meet statement coverage criteria. the tool can generate test cases by analyzing and instrument source code, generate test cases with random data based on type of parameters, execute the test cases, evaluate coverage, regenerate as well as re-execute until it reaches a target level of statement coverage, and then provide coverage report. © 2014 ieee.",tool for generating test module for javascript based on statement coverage criteria
1649,2-s2.0-84903747621,10.3233/978-1-61499-393-3-155,Applying open source data visualization tools to standard based medical data,Kopanitsa G.,Studies in Health Technology and Informatics,2014-01-01,"Presentation of medical data in personal health records (PHRs) requires flexible platform independent tools to ensure easy access to the information. Different backgrounds of the patients, especially elder people require simple graphical presentation of the data. Data in PHRs can be collected from heterogeneous sources. Application of standard based medical data allows development of generic visualization methods. Focusing on the deployment of Open Source Tools, in this paper we applied Java Script libraries to create data presentations for standard based medical data. © 2014 The authors and IOS Press. All rights reserved.",archetypes | EHR | Open source | visualization,5,155-157,Conference Proceeding,Conference Paper,2.0,"Kopanitsa, Georgy;Taranik, Maxim",55326019500;56245299000,Tomsk State University of Architecture and Building;Tomsk Polytechnic University,Russian Federation;Russian Federation,"presentation of medical data in personal health records (phrs) requires flexible platform independent tools to ensure easy access to the information. different backgrounds of the patients, especially elder people require simple graphical presentation of the data. data in phrs can be collected from heterogeneous sources. application of standard based medical data allows development of generic visualization methods. focusing on the deployment of open source tools, in this paper we applied java script libraries to create data presentations for standard based medical data. © 2014 the authors and ios press. all rights reserved.",applying open source data visualization tools to standard based medical data
1650,2-s2.0-84903743375,10.3233/978-1-61499-397-1-87,Development of an accommodative smartphone app for medical guidelines in pediatric emergencies,Schmucker M.,Studies in Health Technology and Informatics,2014-01-01,"One of the outcomes of a training concept for physicians and nurses concerning pediatric emergencies at the Heidelberg University Hospital was that the work and procedures in childhood emergencies could be simplified by replacing the existing paper-based guidelines with a smartphone app. Since the project funds for this were already used up, a group of students from the master program 'Medical Informatics' of Heidelberg and Heilbronn Universities took over the development of the app. Particular attention was given to the need for compatibility with the variety of devices (device size and screen resolution) and platform independence. The guidelines themselves were scripted in HTML5, JavaScript and CSS (responsive web design); managed by a container programmed in Sencha Touch. Even though the app is not yet available in the App-Store due to the limited timeframe, the students gained a great deal of valuable experience in developing platform independent software for mobile devices. © 2014 The authors and IOS Press.",Education | Emergency Treatment | Mobile Applications | Practice Guideline,7,87-92,Conference Proceeding,Conference Paper,3.0,"Schmucker, Michael;Heid, Jörn;Haag, Martin",56245487600;8423820600;8423820500,Hochschule Heilbronn,Germany,"one of the outcomes of a training concept for physicians and nurses concerning pediatric emergencies at the heidelberg university hospital was that the work and procedures in childhood emergencies could be simplified by replacing the existing paper-based guidelines with a smartphone app. since the project funds for this were already used up, a group of students from the master program 'medical informatics' of heidelberg and heilbronn universities took over the development of the app. particular attention was given to the need for compatibility with the variety of devices (device size and screen resolution) and platform independence. the guidelines themselves were scripted in html5, javascript and css (responsive web design); managed by a container programmed in sencha touch. even though the app is not yet available in the app-store due to the limited timeframe, the students gained a great deal of valuable experience in developing platform independent software for mobile devices. © 2014 the authors and ios press.",development of an accommodative smartphone app for medical guidelines in pediatric emergencies
1652,2-s2.0-84903641108,10.1145/2591062.2591170,Software engineering for the web: The state of the practice,Nederlof A.,"36th International Conference on Software Engineering, ICSE Companion 2014 - Proceedings",2014-01-01,"Today's web applications increasingly rely on client-side code execution. HTML is not just created on the server, but ma-nipulated extensively within the browser through JavaScript code. In this paper, we seek to understand the software en-gineering implications of this. We look at deviations from many known best practices in such areas of performance, accessibility, and correct structuring of HTML documents. Furthermore, we assess to what extent such deviations man-ifest themselves through client-side code manipulation only. To answer these questions, we conducted a large scale exper-iment, involving automated client-enabled crawling of over 4000 web applications, resulting in over 100,000,000 pages analyzed, and close to 1,000,000 unique client-side user interface states. Our findings show that the majority of sites contain a substantial number of problems, making sites un-necessarily slow, inaccessible for the visually impaired, and with layout that is unpredictable due to errors in the dy-namically modified DOM trees. Copyright © 2014 ACM.",Automatic error detection | Crawling | JavaScript | Web development best practices,16,4-13,Conference Proceeding,Conference Paper,3.0,"Nederlof, Alex;Mesbah, Ali;Van Deursen, Arie",56242404600;17345931800;7003969355,The University of British Columbia;Delft University of Technology,Canada;Netherlands,"today's web applications increasingly rely on client-side code execution. html is not just created on the server, but ma-nipulated extensively within the browser through javascript code. in this paper, we seek to understand the software en-gineering implications of this. we look at deviations from many known best practices in such areas of performance, accessibility, and correct structuring of html documents. furthermore, we assess to what extent such deviations man-ifest themselves through client-side code manipulation only. to answer these questions, we conducted a large scale exper-iment, involving automated client-enabled crawling of over 4000 web applications, resulting in over 100,000,000 pages analyzed, and close to 1,000,000 unique client-side user interface states. our findings show that the majority of sites contain a substantial number of problems, making sites un-necessarily slow, inaccessible for the visually impaired, and with layout that is unpredictable due to errors in the dy-namically modified dom trees. copyright © 2014 acm.",software engineering for the web: the state of the practice
1653,2-s2.0-84903434290,10.1007/978-3-319-07509-9_35,Enabling architecture: How the GPII supports inclusive software development,Clark C.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2014-01-01,"The Global Public Inclusive Infrastructure is an international effort to build tools, components, services and a sustainable community to support personalized digital inclusion[1]. The GPII is building the critical infrastructure needed by developers to produce the next generation of low-cost assistive technology and highly flexible applications that can adapt to the needs and preferences of individuals across web, desktop, and mobile platforms. To deliver on these ambitious goals, the GPII architecture team has created an evolving suite of development tools, idioms, and resources to support the creation of an inclusive infrastructure. © 2014 Springer International Publishing.",Accessibility | assistive technology | development tools | GPII | inclusive design | Inversion of Control | JavaScript | Node.js,4,368-377,Book Series,Conference Paper,4.0,"Clark, Colin;Basman, Antranig;Bates, Simon;Markus, Kasper Galschiøt",55454812100;8747176500;56237226600;55803682100,The Ontario College of Art and Design University,Canada,"the global public inclusive infrastructure is an international effort to build tools, components, services and a sustainable community to support personalized digital inclusion[1]. the gpii is building the critical infrastructure needed by developers to produce the next generation of low-cost assistive technology and highly flexible applications that can adapt to the needs and preferences of individuals across web, desktop, and mobile platforms. to deliver on these ambitious goals, the gpii architecture team has created an evolving suite of development tools, idioms, and resources to support the creation of an inclusive infrastructure. © 2014 springer international publishing.",enabling architecture: how the gpii supports inclusive software development
1654,2-s2.0-84903266176,10.1142/S0218194014500077,Developing web applications based on model driven architecture,Huang Y.,International Journal of Software Engineering and Knowledge Engineering,2014-01-01,"Model Driven Architecture (MDA) is a new software development framework. This paper presents a model-driven approach to the development of Web applications by combining Conallen's web applications design concept and Kleppe's MDA process. We use the UML extension mechanism, i.e. stereotypes, to define the various web elements, and use the Robustness diagram to represent MVC 2 structure for Web application. After required analysis, we start by using a use case diagram as CIM, and then transform CIM to PIM, and PIM to PSM. We propose mapping rules for model-to-model transformation. Finally, we develop a tool named WebPSM2Code, which can automatically transform PSM diagram to Web application code, such as Java, JSP, HTML, Servlet, Javascript, as well as deployment descriptor file. All the files can automatically address to the correct directory structure for JSP Web application, and the transformation rate is about 39% of the whole system. Using this methodology, systems can be analyzed, designed, and generated more easily and systematically. Thereby, the time that Web programmers spend on coding can be reduced. © 2014 World Scientific Publishing Company.",Model driven architecture | platform independent model | platform specific model,3,163-182,Journal,Article,2.0,"Huang, Yen Chieh;Chu, Chih Ping",34975046200;7404345356,Meiho University;National Cheng Kung University,Taiwan;Taiwan,"model driven architecture (mda) is a new software development framework. this paper presents a model-driven approach to the development of web applications by combining conallen's web applications design concept and kleppe's mda process. we use the uml extension mechanism, i.e. stereotypes, to define the various web elements, and use the robustness diagram to represent mvc 2 structure for web application. after required analysis, we start by using a use case diagram as cim, and then transform cim to pim, and pim to psm. we propose mapping rules for model-to-model transformation. finally, we develop a tool named webpsm2code, which can automatically transform psm diagram to web application code, such as java, jsp, html, servlet, javascript, as well as deployment descriptor file. all the files can automatically address to the correct directory structure for jsp web application, and the transformation rate is about 39% of the whole system. using this methodology, systems can be analyzed, designed, and generated more easily and systematically. thereby, the time that web programmers spend on coding can be reduced. © 2014 world scientific publishing company.",developing web applications based on model driven architecture
1655,2-s2.0-84902349997,10.3233/978-1-61499-405-3-689,Authoring tool for SmartPhone pedagogical content development,Gerval J.,Frontiers in Artificial Intelligence and Applications,2014-01-01,"This paper sets out a software development targeting the design of pedagogical content to be run on SmartPhones. The result is an authoring tool that does not require any software development skill. Teachers can set up easily and quickly content for their students. Experiments took place last year in a Marine Park where more than 200 contents had been developed. It is a web-based system. Server and database implement Linux, Apache, MySQL and PHP. This architecture has come to be known simply as LAMP. On SmartPhone side, HTML5 and JavaScript technologies enable us to target all kind of devices. © 2014 The authors and IOS Press. All rights reserved.",authoring tool | HTML5 | pedagogical content | SmartPhone,0,689-696,Book Series,Conference Paper,3.0,"Gerval, Jean Pierre;Le Ru, Yann;Ghiron, Sylvain",6506439149;54412757300;56203622200,ISEN Institut Supérieur d'Électronique et du Numérique,France,"this paper sets out a software development targeting the design of pedagogical content to be run on smartphones. the result is an authoring tool that does not require any software development skill. teachers can set up easily and quickly content for their students. experiments took place last year in a marine park where more than 200 contents had been developed. it is a web-based system. server and database implement linux, apache, mysql and php. this architecture has come to be known simply as lamp. on smartphone side, html5 and javascript technologies enable us to target all kind of devices. © 2014 the authors and ios press. all rights reserved.",authoring tool for smartphone pedagogical content development
1656,2-s2.0-84902315281,10.5220/0004930203670373,A web-based recommendation system for engineering education e-learning systems,Sommer T.,CSEDU 2014 - Proceedings of the 6th International Conference on Computer Supported Education,2014-01-01,"Today there is a flood of e-learning and e-learning related solutions for engineering education. It is at least a time consuming task for a teacher to find an e-learning system, which matches their requirements. To assist teachers with this information overload, a web-based recommendation system for related e-learning solutions is under development to support teachers in the field of engineering education to find a matching e-learning system within minutes. Because the e-learning market is subject of very fast changes, an agile engineering process is used to ensure the capability to react on these changes. To solve the challenges of this project, an own user-flow visual programming language and an algorithm are under development. A special software stack is chosen to accelerate the development. Instead of classical back-office software to administer and maintain the project, a web-based approach is used - even for a complex editor. The determining of the necessary catalog of related solutions within ""real-time"" is based on big data technologies, data mining methods and statistically text analysis.",Agile process | E-learning | Open source | Professors | Recommendation system | Software engineering | Teachers | Web 2.0,8,367-373,Conference Proceeding,Conference Paper,4.0,"Sommer, Thorsten;Bach, Ursula;Richert, Anja;Jeschke, Sabina",56203600800;36536585600;36176257900;23093981800,Rheinisch-Westfälische Technische Hochschule Aachen,Germany,"today there is a flood of e-learning and e-learning related solutions for engineering education. it is at least a time consuming task for a teacher to find an e-learning system, which matches their requirements. to assist teachers with this information overload, a web-based recommendation system for related e-learning solutions is under development to support teachers in the field of engineering education to find a matching e-learning system within minutes. because the e-learning market is subject of very fast changes, an agile engineering process is used to ensure the capability to react on these changes. to solve the challenges of this project, an own user-flow visual programming language and an algorithm are under development. a special software stack is chosen to accelerate the development. instead of classical back-office software to administer and maintain the project, a web-based approach is used - even for a complex editor. the determining of the necessary catalog of related solutions within ""real-time"" is based on big data technologies, data mining methods and statistically text analysis.",a web-based recommendation system for engineering education e-learning systems
1658,2-s2.0-84902246736,10.4028/www.scientific.net/AMR.926-930.2317,Develop cross-platform smartphone application for lotus OA,Liu L.,Advanced Materials Research,2014-01-01,"Lotus OA is widely used in some large departments. Because of its special architecture, it is difficult to develop a corresponding native mobile application. This paper propose an economic structure to develop native mobile application for Lotus OA. Use this structure, traditional Web developer can directly participate in the Lotus mobile development. This paper introduces our development process, explain the reason why we choose this structure. Also, this paper compares our software structure with other software structures, the result shows that our structure is more economic than other structures. © (2014) Trans Tech Publications, Switzerland.",Cross-platform development | Domino | Information extraction | Phonegap | Smartphone,0,2317-2320,Book Series,Conference Paper,2.0,"Liu, Li;Dai, Ran",56168963500;56202321000,"Tianjin University of Technology;CNOOC(Tianjin)Pipeline Engineering Technology Co., Ltd.",China;China,"lotus oa is widely used in some large departments. because of its special architecture, it is difficult to develop a corresponding native mobile application. this paper propose an economic structure to develop native mobile application for lotus oa. use this structure, traditional web developer can directly participate in the lotus mobile development. this paper introduces our development process, explain the reason why we choose this structure. also, this paper compares our software structure with other software structures, the result shows that our structure is more economic than other structures. © (2014) trans tech publications, switzerland.",develop cross-platform smartphone application for lotus oa
1660,2-s2.0-84900020948,10.1145/2577080.2577094,Designing information hiding modularity for model transformation languages,Rentschler A.,MODULARITY 2014 - Proceedings of the 13th International Conference on Modularity (Formerly AOSD),2014-01-01,"Development and maintenance of model transformations make up a substantial share of the lifecycle costs of software products that rely on model-driven techniques. In particular large and heterogeneous models lead to poorly understandable transformation code due to missing language concepts to master complexity. At the present time, there exists no module concept for model transformation languages that allows programmers to control information hiding and strictly declare model and code dependencies at module interfaces. Yet only then can we break down transformation logic into smaller parts, so that each part owns a clear interface for separating concerns. In this paper, we propose a module concept suitable for model transformation engineering. We formalize our concept based on cQVTom, a compact subset of the transformation language QVT-Operational. To meet the special demands of transformations, module interfaces give control over both model and code accessibility. We also implemented the approach for validation. In a case study, we examined the effort required to carry out two typical maintenance tasks on a real-world transformation. We are able to attest a significant reduction of effort, thereby demonstrating the practical effects of a thorough interface concept on the maintainability of model transformations. Copyright © 2014 ACM. Copyright © 2014 ACM.",Maintenance | Model transformations | Model-driven software engineering | Modularity | Transformation languages,9,217-228,Conference Proceeding,Conference Paper,5.0,"Rentschler, Andreas;Werle, Dominik;Noorshams, Qais;Happe, Lucia;Reussner, Ralf",23995925200;56152484100;36696521400;55217699200;6603589366,Karlsruher Institut für Technologie,Germany,"development and maintenance of model transformations make up a substantial share of the lifecycle costs of software products that rely on model-driven techniques. in particular large and heterogeneous models lead to poorly understandable transformation code due to missing language concepts to master complexity. at the present time, there exists no module concept for model transformation languages that allows programmers to control information hiding and strictly declare model and code dependencies at module interfaces. yet only then can we break down transformation logic into smaller parts, so that each part owns a clear interface for separating concerns. in this paper, we propose a module concept suitable for model transformation engineering. we formalize our concept based on cqvtom, a compact subset of the transformation language qvt-operational. to meet the special demands of transformations, module interfaces give control over both model and code accessibility. we also implemented the approach for validation. in a case study, we examined the effort required to carry out two typical maintenance tasks on a real-world transformation. we are able to attest a significant reduction of effort, thereby demonstrating the practical effects of a thorough interface concept on the maintainability of model transformations. copyright © 2014 acm. copyright © 2014 acm.",designing information hiding modularity for model transformation languages
1661,2-s2.0-84900002241,10.1145/2577080.2577098,Type names without static type checking already improve the usability of APIs (As Long as the Type Names are Correct): An Empirical Study,Spiza S.,MODULARITY 2014 - Proceedings of the 13th International Conference on Modularity (Formerly AOSD),2014-01-01,"In the discussion about the usefulness of static or dynamic type systems there is often the statement that static type systems improve the documentation of software. In the meantime there exists even some empirical evidence for this statement. One of the possible explanations for this positive influence is that the static type system of programming languages such as Java require developers to write down the type names, i.e. lexical representations which potentially help developers. Because of that there is a plausible hypothesis that the main benefit comes from the type names and not from the static type checks that are based on these names. In order to argue for or against static type systems it is desirable to check this plausible hypothesis in an experimental way. This paper describes an experiment with 20 participants that has been performed in order to check whether developers using an unknown API already benefit (in terms of development time) from the pure syntactical representation of type names without static type checking. The result of the study is that developers do benefit from the type names in an API's source code. But already a single wrong type name has a measurable significant negative impact on the development time in comparison to APIs without type names. Copyright © 2014 ACM. Copyright © 2014 ACM.",Empirical research | Programming languages | Type systems,16,99-108,Conference Proceeding,Conference Paper,2.0,"Spiza, Samuel;Hanenberg, Stefan",56153153100;8983981100,Universität Duisburg-Essen,Germany,"in the discussion about the usefulness of static or dynamic type systems there is often the statement that static type systems improve the documentation of software. in the meantime there exists even some empirical evidence for this statement. one of the possible explanations for this positive influence is that the static type system of programming languages such as java require developers to write down the type names, i.e. lexical representations which potentially help developers. because of that there is a plausible hypothesis that the main benefit comes from the type names and not from the static type checks that are based on these names. in order to argue for or against static type systems it is desirable to check this plausible hypothesis in an experimental way. this paper describes an experiment with 20 participants that has been performed in order to check whether developers using an unknown api already benefit (in terms of development time) from the pure syntactical representation of type names without static type checking. the result of the study is that developers do benefit from the type names in an api's source code. but already a single wrong type name has a measurable significant negative impact on the development time in comparison to apis without type names. copyright © 2014 acm. copyright © 2014 acm.",type names without static type checking already improve the usability of apis (as long as the type names are correct): an empirical study
1664,2-s2.0-84897402838,10.14257/ijseia.2014.8.3.20,Language driven development framework: End-to end approach for rapid game server development,Yoo H.,International Journal of Software Engineering and its Applications,2014-01-01,"Software programmers no longer expect to make software that only works on PCs and servers. An advantage of using DSL for their software development is that they can achieve a high efficiency compared to their development investment. However, previous research works have not conducted detailed workflow and DSL for web-development reflecting current prosperous web and mobile technology. In this paper, we propose an integrated language driven development (LDD) framework especially for the real time game server development. Using LDD framework, expert developer can make DSL language, so that novice developer or non-programmer can utilize the DSL for their easy programming works. We illustrate detailed LDD framework with our simplified game server language. With our framework, even novice programmer can program massive game server programming works during game development process, utilizing composed DSL written by expert programmer. This paper contributes to increase development productivity and ease of maintenance in game development process. Our workflow helps developers build their own language and can use in their software implementation for rapid prototyping. Using our LDD framework, many developers can build various domain applications not limited to games, including chatting applications, real-time monitoring and much more. © 2014 SERSC.",Development method | Dsl | Game | Language-driven | Workflow,0,217-226,Journal,Article,2.0,"Yoo, Hwan Soo;Kim, Seong Whan",55430167700;57007276500,University of Seoul,South Korea,"software programmers no longer expect to make software that only works on pcs and servers. an advantage of using dsl for their software development is that they can achieve a high efficiency compared to their development investment. however, previous research works have not conducted detailed workflow and dsl for web-development reflecting current prosperous web and mobile technology. in this paper, we propose an integrated language driven development (ldd) framework especially for the real time game server development. using ldd framework, expert developer can make dsl language, so that novice developer or non-programmer can utilize the dsl for their easy programming works. we illustrate detailed ldd framework with our simplified game server language. with our framework, even novice programmer can program massive game server programming works during game development process, utilizing composed dsl written by expert programmer. this paper contributes to increase development productivity and ease of maintenance in game development process. our workflow helps developers build their own language and can use in their software implementation for rapid prototyping. using our ldd framework, many developers can build various domain applications not limited to games, including chatting applications, real-time monitoring and much more. © 2014 sersc.",language driven development framework: end-to end approach for rapid game server development
1667,2-s2.0-84885722624,10.1016/j.cageo.2013.09.012,Development of a web application for water resources based on open source software,Delipetrev B.,Computers and Geosciences,2014-01-01,"This article presents research and development of a prototype web application for water resources using latest advancements in Information and Communication Technologies (ICT), open source software and web GIS. The web application has three web services for: (1) managing, presenting and storing of geospatial data, (2) support of water resources modeling and (3) water resources optimization. The web application is developed using several programming languages (PhP, Ajax, JavaScript, Java), libraries (OpenLayers, JQuery) and open source software components (GeoServer, PostgreSQL, PostGIS). The presented web application has several main advantages: it is available all the time, it is accessible from everywhere, it creates a real time multi-user collaboration platform, the programing languages code and components are interoperable and designed to work in a distributed computer environment, it is flexible for adding additional components and services and, it is scalable depending on the workload. The application was successfully tested on a case study with concurrent multi-users access. © 2013 Elsevier Ltd.",Geographic information systems | Open source software | Water resources | Web GIS | Web services,47,35-42,Journal,Article,3.0,"Delipetrev, Blagoj;Jonoski, Andreja;Solomatine, Dimitri P.",55887998700;6506344580;6601958160,IHE Delft Institute for Water Education;Delft University of Technology,Netherlands;Netherlands,"this article presents research and development of a prototype web application for water resources using latest advancements in information and communication technologies (ict), open source software and web gis. the web application has three web services for: (1) managing, presenting and storing of geospatial data, (2) support of water resources modeling and (3) water resources optimization. the web application is developed using several programming languages (php, ajax, javascript, java), libraries (openlayers, jquery) and open source software components (geoserver, postgresql, postgis). the presented web application has several main advantages: it is available all the time, it is accessible from everywhere, it creates a real time multi-user collaboration platform, the programing languages code and components are interoperable and designed to work in a distributed computer environment, it is flexible for adding additional components and services and, it is scalable depending on the workload. the application was successfully tested on a case study with concurrent multi-users access. © 2013 elsevier ltd.",development of a web application for water resources based on open source software
1668,2-s2.0-84882966436,10.1109/TIE.2013.2254095,Context generator and behavior translator in a multilayer architecture for a modular development process of cyber-physical robot systems,Choi S.,IEEE Transactions on Industrial Electronics,2014-01-01,"Robot systems are developed using various hardware and software components. In conventional design methodology, each hardware component and its software are strongly coupled such that it is not easy to replace or expand them separately. For the independent development and replacement of hardware and software components, this paper proposes a novel robot development methodology based on the abstractions of software and hardware components in a multilayer architecture for cyber-physical robot systems which conjoin computational and physical resources. We introduce a context generator and a behavior translator for the abstractions in the multilayer architecture. The context generator converts sensory value data into contexts using context scripts. The behavior translator converts a behavior, selected by a software agent that is a computer program deciding an action of a robot, into a sequence of actuator commands for robots using behavior scripts. These together enable two levels of abstraction in which software and hardware components can be developed independently of each other. As a result, software agents can work flawlessly even if hardware components are replaced and vice versa. The effectiveness and applicability of the proposed methodology are demonstrated through experiments, and the related applications are provided. © 1982-2012 IEEE.",Behavior translator | context generator | cyber-physical robot systems (CPRSs) | multilayer architecture | robot development process,10,882-892,Journal,Article,4.0,"Choi, Seung Hwan;Jeong, In Bae;Kim, Jong Hwan;Lee, John Jaehwan",55802893400;25925784100;36484629700;8295015900,Korea Advanced Institute of Science and Technology;Indiana University-Purdue University Indianapolis,South Korea;United States,"robot systems are developed using various hardware and software components. in conventional design methodology, each hardware component and its software are strongly coupled such that it is not easy to replace or expand them separately. for the independent development and replacement of hardware and software components, this paper proposes a novel robot development methodology based on the abstractions of software and hardware components in a multilayer architecture for cyber-physical robot systems which conjoin computational and physical resources. we introduce a context generator and a behavior translator for the abstractions in the multilayer architecture. the context generator converts sensory value data into contexts using context scripts. the behavior translator converts a behavior, selected by a software agent that is a computer program deciding an action of a robot, into a sequence of actuator commands for robots using behavior scripts. these together enable two levels of abstraction in which software and hardware components can be developed independently of each other. as a result, software agents can work flawlessly even if hardware components are replaced and vice versa. the effectiveness and applicability of the proposed methodology are demonstrated through experiments, and the related applications are provided. © 1982-2012 ieee.",context generator and behavior translator in a multilayer architecture for a modular development process of cyber-physical robot systems
1669,2-s2.0-84889574889,10.1145/2526188.2528541,Mobile development using web technologies focusing on games,Santanchè A.,WebMedia 2013 - Proceedings of the 19th Brazilian Symposium on Multimedia and the Web,2013-12-11,"Games are typically challenging applications to develop and they are omnipresent in the mobile platforms. Besides the hardware limitations and heterogeneity of mobiles, we are experiencing a ""software platform epoch"". Platforms like iOS, Android and Windows Phone offer to developers complete hermetic environments, which come with compatibility side effects, constraining applications to be reimplemented in order to address each platform. One of the most promising approaches to face this platform battle is based on the combination of Web technologies - HTML5, CSS3 and JavaScript - to produce platform-independent applications for mobiles. The question here is how to achieve the balance between independence and performance, required by games. This mini-course gives an overview of this scenario focusing in aspects addressed to game development. © 2013 Authors.",CSS | games | HTML | Javascript | mobile development | web-based development,1,13-14,Conference Proceeding,Conference Paper,6.0,"Santanchè, André;Boulanger, Renoir;Viana, Gabriela;Panaggio, Ricardo;Melo, Bruno;Aboud, Hugo",55953493500;55954296200;55953792400;55954129800;57055587000;55953692500,Universidade Estadual de Campinas;Massachusetts Institute of Technology;Polytechnique Montréal,Brazil;United States;Canada,"games are typically challenging applications to develop and they are omnipresent in the mobile platforms. besides the hardware limitations and heterogeneity of mobiles, we are experiencing a ""software platform epoch"". platforms like ios, android and windows phone offer to developers complete hermetic environments, which come with compatibility side effects, constraining applications to be reimplemented in order to address each platform. one of the most promising approaches to face this platform battle is based on the combination of web technologies - html5, css3 and javascript - to produce platform-independent applications for mobiles. the question here is how to achieve the balance between independence and performance, required by games. this mini-course gives an overview of this scenario focusing in aspects addressed to game development. © 2013 authors.",mobile development using web technologies focusing on games
1670,2-s2.0-84889563296,10.1145/2526188.2526194,jRDFa: Browsing and visualization of linked data on the web,Carlomagno A.L.,WebMedia 2013 - Proceedings of the 19th Brazilian Symposium on Multimedia and the Web,2013-12-11,"Several efforts in research and development of technologies have been spent to publish data in open standard formats. The main project in this regard is the Linked Open Data, which goal is to create an open and semantic Web of Data, enabling processing and understanding the data by software agents. However, not only the machines can take advantage of the explicit semantics of data. People can take advantage from the semantic of the data to explore unknown concepts, new relationships and to obtain personalized access to relevant resources and services. However, it is not trivial for a user without experience with Web of Data, to satisfactorily explore and use these data. This paper presents the jRDFa, an approach to support the web developer interested in presenting to non-technical users, semantic data embedded in HTML pages in RDFa format. This paper also presents two ways of presenting data in RDFa that were created using the jRDFa: tooltips visualization and facets navigation. To evaluate the proposed approach, this paper presents results of experiments on HTML pages with embedded jRDFa. © 2013 ACM.",facets | jRDFa | linked data | navigation tooltips | view,1,141-148,Conference Proceeding,Conference Paper,4.0,"Carlomagno, André L.;Filho, Tito Gardel;Cerqueira, Marilton M.;Prazeres, Cássio V.S.",55953562900;55953979800;55953547800;18234259400,Universidade Federal da Bahia,Brazil,"several efforts in research and development of technologies have been spent to publish data in open standard formats. the main project in this regard is the linked open data, which goal is to create an open and semantic web of data, enabling processing and understanding the data by software agents. however, not only the machines can take advantage of the explicit semantics of data. people can take advantage from the semantic of the data to explore unknown concepts, new relationships and to obtain personalized access to relevant resources and services. however, it is not trivial for a user without experience with web of data, to satisfactorily explore and use these data. this paper presents the jrdfa, an approach to support the web developer interested in presenting to non-technical users, semantic data embedded in html pages in rdfa format. this paper also presents two ways of presenting data in rdfa that were created using the jrdfa: tooltips visualization and facets navigation. to evaluate the proposed approach, this paper presents results of experiments on html pages with embedded jrdfa. © 2013 acm.",jrdfa: browsing and visualization of linked data on the web
1671,2-s2.0-84905811475,10.1300/J201v04n01_12,The archivists' toolkit: Another step toward streamlined archival processing,Westbrook B.D.,Archives and the Digital Library,2013-12-01,"The Archivists' Toolkit is a software application currently in development and designed to support the creation and management of archival information. This article summarizes the development of the application, including some of the problems the application is designed to resolve. Primary emphasis is placed on describing the application's functional requirements and architecture, as well as options for its sustainability. © 2006 by The Haworth Press, Inc. All rights reserved.",Archival information | Archival information system | Archival life cycle | Archival standards | Archival workflow | Archivists' Toolkit | Database applications | Open source software | Processing efficiencies | Software development | Software specification | Use case methodology,0,229-254,Book,Book Chapter,5.0,"Westbrook, Bradley D.;Mandell, Lee;Shepherd, Kelcy;Stevens, Brian;Varghese, Jason",16644508000;57525941700;16834208500;16834223600;16834257700,"University of California, San Diego;New York University;University of Massachusetts Amherst",United States;United States;United States,"the archivists' toolkit is a software application currently in development and designed to support the creation and management of archival information. this article summarizes the development of the application, including some of the problems the application is designed to resolve. primary emphasis is placed on describing the application's functional requirements and architecture, as well as options for its sustainability. © 2006 by the haworth press, inc. all rights reserved.",the archivists' toolkit: another step toward streamlined archival processing
1672,2-s2.0-84893753893,10.1007/978-3-319-02726-5_5,OSNGuard: Detecting worms with user interaction traces in online social networks,He L.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2013-12-01,"In the last few years we have witnessed an incredible development of online social networks (OSNs), which unfortunately causes new security threats, e.g., OSN worms. Different from traditional worms relying on software vulnerabilities, these new worms are able to exploit trust between friends in OSNs. In this paper, a new worm propagation model was proposed, named EP-Model, to find out the common characteristics of OSN worms including XSS-based JavaScript worms and Social-Engineering-based Executable worms. And then we designed OSNGuard, a client-side defense mechanism which could prevent the propagation of OSN worms conforming to the EP-Model. Particularly, starting from tracing relevant user interactions with client processes visiting OSNs, our system could identify and block malicious payload-submissions from worms by analyzing these traced user activities. To prove the effectiveness of OSNGuard, we presented a prototype implementation for Microsoft Windows platform and evaluated it on a small-scale OSN website. The system evaluations showed that OSNGuard could sufficiently protect users against OSN worms in a real-time manner and the performance tests also revealed that our system introduced less than 2.5% memory overhead when simultaneously monitoring up to 10 processes. © Springer International Publishing 2013.",Online social networks | User interaction trace | Worm detection,0,59-74,Book Series,Conference Paper,7.0,"He, Liang;Feng, Dengguo;Su, Purui;Ying, Lingyun;Yang, Yi;Huang, Huafeng;Fang, Huipeng",57208200756;7401981154;8941785000;26222001600;56378863600;56031372500;56031547800,Institute of Software Chinese Academy of Sciences,China,"in the last few years we have witnessed an incredible development of online social networks (osns), which unfortunately causes new security threats, e.g., osn worms. different from traditional worms relying on software vulnerabilities, these new worms are able to exploit trust between friends in osns. in this paper, a new worm propagation model was proposed, named ep-model, to find out the common characteristics of osn worms including xss-based javascript worms and social-engineering-based executable worms. and then we designed osnguard, a client-side defense mechanism which could prevent the propagation of osn worms conforming to the ep-model. particularly, starting from tracing relevant user interactions with client processes visiting osns, our system could identify and block malicious payload-submissions from worms by analyzing these traced user activities. to prove the effectiveness of osnguard, we presented a prototype implementation for microsoft windows platform and evaluated it on a small-scale osn website. the system evaluations showed that osnguard could sufficiently protect users against osn worms in a real-time manner and the performance tests also revealed that our system introduced less than 2.5% memory overhead when simultaneously monitoring up to 10 processes. © springer international publishing 2013.",osnguard: detecting worms with user interaction traces in online social networks
1673,2-s2.0-84893621874,10.1109/ICSEC.2013.6694748,Online code editor on Private cloud computing,Kimpan W.,"2013 International Computer Science and Engineering Conference, ICSEC 2013",2013-12-01,"Programming tools are important for programmers to develop software. If the developers have a good tool, it can help them develop system faster and more accurate. This paper proposed the Online Code Editor that was created for programmers or developers who want to write programs without any platform requirements or without any specific physical computers. It bases on web application running on the Private cloud computing. The features of the editor are performed on web programming languages, e.g. HTML, PHP, CSS, and JavaScript. The editor is able to isolate programming languages by highlighting syntax of programs. Users can create new projects and files, import and export files that they want on a server. Moreover, Save, Auto save, Delete, and etc. are the additional functions of the editor. In this research of the text editor development, the open source software called, 'Ace' was used for some functions such as Undo, Redo, and Syntax highlight. The experimental results indicated that the proposed editor can be practically used on Private cloud computing. Moreover, the comparison of the features among the proposed editor running on Private cloud, Notepad++, and EditPlus which running on personal computers, was summarized. © 2013 IEEE.",Ace | Online Editor | Private Cloud Computing,1,31-36,Conference Proceeding,Conference Paper,3.0,"Kimpan, Warangkhana;Meebunrot, Theerasak;Sricharoen, Busaya",55912137900;56027599500;56027365700,King Mongkut's Institute of Technology Ladkrabang,Thailand,"programming tools are important for programmers to develop software. if the developers have a good tool, it can help them develop system faster and more accurate. this paper proposed the online code editor that was created for programmers or developers who want to write programs without any platform requirements or without any specific physical computers. it bases on web application running on the private cloud computing. the features of the editor are performed on web programming languages, e.g. html, php, css, and javascript. the editor is able to isolate programming languages by highlighting syntax of programs. users can create new projects and files, import and export files that they want on a server. moreover, save, auto save, delete, and etc. are the additional functions of the editor. in this research of the text editor development, the open source software called, 'ace' was used for some functions such as undo, redo, and syntax highlight. the experimental results indicated that the proposed editor can be practically used on private cloud computing. moreover, the comparison of the features among the proposed editor running on private cloud, notepad++, and editplus which running on personal computers, was summarized. © 2013 ieee.",online code editor on private cloud computing
1674,2-s2.0-84893606752,10.1109/SMC.2013.539,Integration of online laboratories-LMS via SCORM,Ruano-Ruano I.,"Proceedings - 2013 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2013",2013-12-01,"Web-based laboratories have been used as valuable resources to support teaching for many years. The methodology and operation of laboratories over the Internet have changed considerably since the early implementations. In fact, one of the last steps taken related to this issue has been the integration of laboratories and Learning Management Systems (LMS). In this paper we present methods that facilitate the development of virtual and/or remote labs software to interact with Learning Management Systems using Shareable Content Object Reference Model (SCORM), the most important standard for e-learning content. A virtual lab model is developed to show how the methods are used in order to integrate the virtual lab software with the LMS via SCORM. © 2013 IEEE.",Component | Ejs | Learning management system | Online laboratories | Scorm,7,3163-3167,Conference Proceeding,Conference Paper,4.0,"Ruano-Ruano, Ildefonso;Gómez-Ortega, Juan;Gámez-García, Javier;Estévez-Estévez, Elisabet",55826438400;6602768870;6506905952;8299748100,Universidad de Jaén,Spain,"web-based laboratories have been used as valuable resources to support teaching for many years. the methodology and operation of laboratories over the internet have changed considerably since the early implementations. in fact, one of the last steps taken related to this issue has been the integration of laboratories and learning management systems (lms). in this paper we present methods that facilitate the development of virtual and/or remote labs software to interact with learning management systems using shareable content object reference model (scorm), the most important standard for e-learning content. a virtual lab model is developed to show how the methods are used in order to integrate the virtual lab software with the lms via scorm. © 2013 ieee.",integration of online laboratories-lms via scorm
1675,2-s2.0-84893603867,10.1109/ASE.2013.6693098,Dangling references in multi-configuration and dynamic PHP-based Web applications,Nguyen H.V.,"2013 28th IEEE/ACM International Conference on Automated Software Engineering, ASE 2013 - Proceedings",2013-12-01,"PHP is a dynamic language popularly used in Web development for writing server-side code to dynamically create multiple versions of client-side pages at run time for different configurations. A PHP program contains code to be executed or produced for multiple configurations/versions. That dynamism and multi-configuration nature leads to dangling references. Specifically, in the execution for a configuration, a reference to a variable or a call to a function is dangling if its corresponding declaration cannot be found. We conducted an exploratory study to confirm the existence of such dangling reference errors including dangling cross-language and embedded references in the client-side HTML/JavaScript code and in data-accessing SQL code that are embedded in scattered PHP code. Dangling references have caused run-time fatal failures and security vulnerabilities. We developed DRC, a static analysis method to detect such dangling references. DRC uses symbolic execution to collect PHP declarations/references and to approximate all versions of the generated output, and then extracts embedded declarations/references. It associates each detected declaration/reference with a conditional constraint that represents the execution paths (i.e. configurations/versions) containing that declaration/reference. It then validates references against declarations via a novel dangling reference detection algorithm. Our empirical evaluation shows that DRC detects dangling references with high accuracy. It revealed 83 yet undiscovered defects caused by dangling references. © 2013 IEEE.",Dangling References | Web Code Analysis,10,399-409,Conference Proceeding,Conference Paper,5.0,"Nguyen, Hung Viet;Nguyen, Hoan Anh;Nguyen, Tung Thanh;Nguyen, Anh Tuan;Nguyen, Tien N.",57225877698;55459278800;57212284041;57194448092;55386311200,Iowa State University,United States,"php is a dynamic language popularly used in web development for writing server-side code to dynamically create multiple versions of client-side pages at run time for different configurations. a php program contains code to be executed or produced for multiple configurations/versions. that dynamism and multi-configuration nature leads to dangling references. specifically, in the execution for a configuration, a reference to a variable or a call to a function is dangling if its corresponding declaration cannot be found. we conducted an exploratory study to confirm the existence of such dangling reference errors including dangling cross-language and embedded references in the client-side html/javascript code and in data-accessing sql code that are embedded in scattered php code. dangling references have caused run-time fatal failures and security vulnerabilities. we developed drc, a static analysis method to detect such dangling references. drc uses symbolic execution to collect php declarations/references and to approximate all versions of the generated output, and then extracts embedded declarations/references. it associates each detected declaration/reference with a conditional constraint that represents the execution paths (i.e. configurations/versions) containing that declaration/reference. it then validates references against declarations via a novel dangling reference detection algorithm. our empirical evaluation shows that drc detects dangling references with high accuracy. it revealed 83 yet undiscovered defects caused by dangling references. © 2013 ieee.",dangling references in multi-configuration and dynamic php-based web applications
1677,2-s2.0-84893300715,10.1109/ESEM.2013.18,An empirical study of client-side JavaScript bugs,Ocariza F.,International Symposium on Empirical Software Engineering and Measurement,2013-12-01,"Context: Client-side JavaScript is widely used in web applications to improve user-interactivity and minimize client-server communications. Unfortunately, web applications are prone to JavaScript faults. While prior studies have demonstrated the prevalence of these faults, no attempts have been made to determine their root causes and consequences. Objective: The goal of our study is to understand the root causes and impact of JavaScript faults and how the results can impact JavaScript programmers, testers and tool developers. Method: We perform an empirical study of 317 bug reports from 12 bug repositories. The bug reports are thoroughly examined to classify and extract information about the fault's cause (the error) and consequence (the failure and impact). Result: The majority (65%) of JavaScript faults are DOM-related, meaning they are caused by faulty interactions of the JavaScript code with the Document Object Model (DOM). Further, 80% of the highest impact JavaScript faults are DOM-related. Finally, most JavaScript faults originate from programmer mistakes committed in the JavaScript code itself, as opposed to other web application components such as the server-side or HTML code. Conclusion: Given the prevalence of DOM-related faults, JavaScript programmers need development tools that can help them reason about the DOM. Also, testers should prioritize detection of DOM-related faults as most high impact faults belong to this category. Finally, developers can use the error patterns we found to design more powerful static analysis tools for JavaScript. © 2013 IEEE.",Document Object Model (DOM) | empirical study | JavaScript,69,55-64,Conference Proceeding,Conference Paper,4.0,"Ocariza, Frolin;Bajaj, Kartik;Pattabiraman, Karthik;Mesbah, Ali",54974152400;56021506200;8887951000;17345931800,The University of British Columbia,Canada,"context: client-side javascript is widely used in web applications to improve user-interactivity and minimize client-server communications. unfortunately, web applications are prone to javascript faults. while prior studies have demonstrated the prevalence of these faults, no attempts have been made to determine their root causes and consequences. objective: the goal of our study is to understand the root causes and impact of javascript faults and how the results can impact javascript programmers, testers and tool developers. method: we perform an empirical study of 317 bug reports from 12 bug repositories. the bug reports are thoroughly examined to classify and extract information about the fault's cause (the error) and consequence (the failure and impact). result: the majority (65%) of javascript faults are dom-related, meaning they are caused by faulty interactions of the javascript code with the document object model (dom). further, 80% of the highest impact javascript faults are dom-related. finally, most javascript faults originate from programmer mistakes committed in the javascript code itself, as opposed to other web application components such as the server-side or html code. conclusion: given the prevalence of dom-related faults, javascript programmers need development tools that can help them reason about the dom. also, testers should prioritize detection of dom-related faults as most high impact faults belong to this category. finally, developers can use the error patterns we found to design more powerful static analysis tools for javascript. © 2013 ieee.",an empirical study of client-side javascript bugs
1678,2-s2.0-84893245654,10.1109/ICDCSW.2013.15,Using Bytecode instrumentation to secure information flow in multithreaded java applications,Sharaf M.,Proceedings - International Conference on Distributed Computing Systems,2013-12-01,"Information leakage is considered one of the vulnerabilities that may exist in careless development of software applications or unreliable and untrusted COTS binaries. Providing security at the level of programming development is important because leaking sensitive information such as credit card number, cookies, passwords or SSN does not require a lot of bandwidth to get through. In this paper, we propose a Secure Information Flow for Multithreaded Java (SIF-MJ) model, to enforce security and enhance assurance in all information flows throughout the execution time of the application without violating any rules or properties of multithreaded application. SIF-MJ does not require modification on the underlying Java Virtual Machine (JVM), therefore our proposed model is applicable to the currently existing JVMs. © 2013 IEEE.",explicit flow | implicit flow | information flow control (IFC) | information leakage | multithreaded application,0,362-367,Conference Proceeding,Conference Paper,3.0,"Sharaf, Mohamed;Huang, Jie;Huang, Chin Tser",57212019737;56393343000;8154036900,University of South Carolina,United States,"information leakage is considered one of the vulnerabilities that may exist in careless development of software applications or unreliable and untrusted cots binaries. providing security at the level of programming development is important because leaking sensitive information such as credit card number, cookies, passwords or ssn does not require a lot of bandwidth to get through. in this paper, we propose a secure information flow for multithreaded java (sif-mj) model, to enforce security and enhance assurance in all information flows throughout the execution time of the application without violating any rules or properties of multithreaded application. sif-mj does not require modification on the underlying java virtual machine (jvm), therefore our proposed model is applicable to the currently existing jvms. © 2013 ieee.",using bytecode instrumentation to secure information flow in multithreaded java applications
1680,2-s2.0-84890086742,10.1109/TSE.2013.38,Identifying code of individual features in client-side web applications,Maras J.,IEEE Transactions on Software Engineering,2013-12-01,"Web applications are one of today's fastest growing software systems. Structurally, they are composed of two parts: the server side, used for data access and business logic, and the client side, used as a user interface. In recent years, with developers building complex interfaces, the client side is playing an increasingly important role. Unfortunately, the techniques and tools used to support development are not as advanced as in other disciplines. From the user's perspective, the client side offers a number of features that are relatively easy to distinguish. However, the same cannot be said for their implementation details. This makes the understanding, maintenance, and reuse of code difficult. The goal of the work presented in this paper is to improve reusability, maintainability, and performance of client-side web applications by identifying the code that implements a particular feature. We have evaluated the approach based on three different experiments: extracting features, extracting library functionalities, and page optimization. The evaluation shows that the method is able to identify the implementation details of individual features, and that by extracting the identified code, a considerable reduction in code size and increase in performance can be achieved. © 1976-2012 IEEE.",code extraction | feature location | program slicing | Web applications,19,1680-1697,Journal,Article,4.0,"Maras, Josip;Stula, Maja;Carlson, Jan;Crnkovic, Ivica",36023615200;14422828000;7402114423;6701375391,"Fakultet Elektrotehnike, Strojarstva i Brodogradnje, Sveučilište u Splitu;Mälardalens högskola",Croatia;Sweden,"web applications are one of today's fastest growing software systems. structurally, they are composed of two parts: the server side, used for data access and business logic, and the client side, used as a user interface. in recent years, with developers building complex interfaces, the client side is playing an increasingly important role. unfortunately, the techniques and tools used to support development are not as advanced as in other disciplines. from the user's perspective, the client side offers a number of features that are relatively easy to distinguish. however, the same cannot be said for their implementation details. this makes the understanding, maintenance, and reuse of code difficult. the goal of the work presented in this paper is to improve reusability, maintainability, and performance of client-side web applications by identifying the code that implements a particular feature. we have evaluated the approach based on three different experiments: extracting features, extracting library functionalities, and page optimization. the evaluation shows that the method is able to identify the implementation details of individual features, and that by extracting the identified code, a considerable reduction in code size and increase in performance can be achieved. © 1976-2012 ieee.",identifying code of individual features in client-side web applications
1687,2-s2.0-84886493766,10.1109/ICIS.2013.6607864,A Selenium based approach to automatic test script generation for refactoring JavaScript code,Chen R.,"2013 IEEE/ACIS 12th International Conference on Computer and Information Science, ICIS 2013 - Proceedings",2013-10-31,"During the development process of Web application, two essential phases are software testing and code refactoring. However, automatic testing script plays an important role in test automation. It has been a hot research topic in Web application. In order to refactor the JavaScript code of Web application more conveniently, an approach to automatic script generation from the defined test case is introduced in this paper. First, it describes the test case using customized XML format. Then, since Selenium platform supports multi-browsers testing, a method to transform XML description into test scripts based on Selenium framework is proposed as the emphasis. © 2013 IEEE.",JavaScript Refactoring | Selenium | The Framework of Script Automatic Generation | XML Schema,8,341-346,Conference Proceeding,Conference Paper,2.0,"Chen, Ruifeng;Miao, Huaikou",55903300700;16176008900,Shanghai University;Shanghai Key Laboratory of Computer Software Evaluating and Testing,China;China,"during the development process of web application, two essential phases are software testing and code refactoring. however, automatic testing script plays an important role in test automation. it has been a hot research topic in web application. in order to refactor the javascript code of web application more conveniently, an approach to automatic script generation from the defined test case is introduced in this paper. first, it describes the test case using customized xml format. then, since selenium platform supports multi-browsers testing, a method to transform xml description into test scripts based on selenium framework is proposed as the emphasis. © 2013 ieee.",a selenium based approach to automatic test script generation for refactoring javascript code
1688,2-s2.0-84886384122,10.1109/ICSE.2013.6606553,RERAN: Timing- and touch-sensitive record and replay for Android,Gomez L.,Proceedings - International Conference on Software Engineering,2013-10-30,"Touchscreen-based devices such as smartphones and tablets are gaining popularity, but their rich input capabilities pose new development and testing complications. To alleviate this problem, we present an approach and tool named Reran that permits record-and-replay for the Android smartphone platform. Existing GUI-level record-and-replay approaches are inadequate due to the expressiveness of the smartphone domain, in which applications support sophisticated GUI gestures, depend on inputs from a variety of sensors on the device, and have precise timing requirements among the various input events. We address these challenges by directly capturing the low-level event stream on the phone, which includes both GUI events and sensor events, and replaying it with microsecond accuracy. Moreover, Reran does not require access to app source code, perform any app rewriting, or perform any modifications to the virtual machine or Android platform. We demonstrate RERAN's applicability in a variety of scenarios, including (a) replaying 86 out of the Top-100 Android apps on Google Play; (b) reproducing bugs in popular apps, e.g., Firefox, Facebook, Quickoffice; and (c) fast-forwarding executions. We believe that our versatile approach can help both Android developers and researchers. © 2013 IEEE.",Google Android | Record-and-replay,229,72-81,Conference Proceeding,Conference Paper,4.0,"Gomez, Lorenzo;Neamtiu, Iulian;Azim, Tanzirul;Millstein, Todd",57196791111;10041674000;55901396200;57207585055,"University of California, Riverside;University of California, Los Angeles",United States;United States,"touchscreen-based devices such as smartphones and tablets are gaining popularity, but their rich input capabilities pose new development and testing complications. to alleviate this problem, we present an approach and tool named reran that permits record-and-replay for the android smartphone platform. existing gui-level record-and-replay approaches are inadequate due to the expressiveness of the smartphone domain, in which applications support sophisticated gui gestures, depend on inputs from a variety of sensors on the device, and have precise timing requirements among the various input events. we address these challenges by directly capturing the low-level event stream on the phone, which includes both gui events and sensor events, and replaying it with microsecond accuracy. moreover, reran does not require access to app source code, perform any app rewriting, or perform any modifications to the virtual machine or android platform. we demonstrate reran's applicability in a variety of scenarios, including (a) replaying 86 out of the top-100 android apps on google play; (b) reproducing bugs in popular apps, e.g., firefox, facebook, quickoffice; and (c) fast-forwarding executions. we believe that our versatile approach can help both android developers and researchers. © 2013 ieee.",reran: timing- and touch-sensitive record and replay for android
1691,2-s2.0-84885200869,10.1109/ICALT.2013.17,A rapid authoring tool for converting existing online resources into widgets,Zhang L.,"Proceedings - 2013 IEEE 13th International Conference on Advanced Learning Technologies, ICALT 2013",2013-10-15,"Today, e-learning 2.0 calls for learner-driven learning. Beyond LMSs, which often play as an advanced photocopier, Personal Learning Environments (PLEs) enable teachers and learners to assemble their individual environment from tools available in today's Web 2.0. However, this raises the problem that a large number and different kinds of tools and learning objects LOs need to be available in a format suited for assembly. For example, in the School of Continuing Education of Shanghai Jiao Tong University (SOCE), even though the technology for enabling PLEs within the employed LMS was available, few teachers used it due to a lack of resources useful to their specific topics. The problem of too few resources is aggravated by the high costs of authoring of new resources. One main idea for reducing costs is to enable reuse of LOs and tools (in the Web, tools are often made available as widgets, small interactive software applications typically created with HTML and JavaScript). Reuse with such a broad scope is tackled by different approaches, such as Open Social (OS), IMS LTI, IMS QTI, and SCORM. Recent work investigates simplifying the creation of interactive resources by different means. 'Authoring by example' eases tutor development by allowing the author to demonstrate instead of programming. Commercial widget authoring tools like Widget box offer on-line authoring of widgets. However, the types of widgets which the online tools are able to create are too restricted for widespread and frequent use in education. To overcome this problem of PLEs, we put forward a general framework which aims at increasing the usage of interactive learning objects and keeping authoring costs low. © 2013 IEEE.",authoring | reuse | widgets,0,41-42,Conference Proceeding,Conference Paper,3.0,"Zhang, Lujia;Ullrich, Carsten;Shen, Ruimin",55877130400;13005630000;7202935842,Shanghai Jiao Tong University,China,"today, e-learning 2.0 calls for learner-driven learning. beyond lmss, which often play as an advanced photocopier, personal learning environments (ples) enable teachers and learners to assemble their individual environment from tools available in today's web 2.0. however, this raises the problem that a large number and different kinds of tools and learning objects los need to be available in a format suited for assembly. for example, in the school of continuing education of shanghai jiao tong university (soce), even though the technology for enabling ples within the employed lms was available, few teachers used it due to a lack of resources useful to their specific topics. the problem of too few resources is aggravated by the high costs of authoring of new resources. one main idea for reducing costs is to enable reuse of los and tools (in the web, tools are often made available as widgets, small interactive software applications typically created with html and javascript). reuse with such a broad scope is tackled by different approaches, such as open social (os), ims lti, ims qti, and scorm. recent work investigates simplifying the creation of interactive resources by different means. 'authoring by example' eases tutor development by allowing the author to demonstrate instead of programming. commercial widget authoring tools like widget box offer on-line authoring of widgets. however, the types of widgets which the online tools are able to create are too restricted for widespread and frequent use in education. to overcome this problem of ples, we put forward a general framework which aims at increasing the usage of interactive learning objects and keeping authoring costs low. © 2013 ieee.",a rapid authoring tool for converting existing online resources into widgets
1692,2-s2.0-84884953157,10.1007/978-3-642-39259-7_28,Making sense out of a jungle of JavaScript frameworks: Towards a practitioner-friendly comparative analysis,Graziotin D.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2013-10-08,"The field of Web development is entering the HTML5 and CSS3 era and JavaScript is becoming increasingly influential. A large number of JavaScript frameworks have been recently promoted. Practitioners applying the latest technologies need to choose a suitable JavaScript framework (JSF) in order to abstract the frustrating and complicated coding steps and to provide a cross-browser compatibility. Apart from benchmark suites and recommendation from experts, there is little research helping practitioners to select the most suitable JSF to a given situation. The few proposals employ software metrics on the JSF, but practitioners are driven by different concerns when choosing a JSF. As an answer to the critical needs, this paper is a call for action. It proposes a research design towards a comparative analysis framework of JSF, which merges researcher needs and practitioner needs. © 2013 Springer-Verlag.",Comparative Analysis | JavaScript Framework | Web Development,14,334-337,Book Series,Conference Paper,2.0,"Graziotin, Daniel;Abrahamsson, Pekka",55872109600;7006011356,Free University of Bozen-Bolzano,Italy,"the field of web development is entering the html5 and css3 era and javascript is becoming increasingly influential. a large number of javascript frameworks have been recently promoted. practitioners applying the latest technologies need to choose a suitable javascript framework (jsf) in order to abstract the frustrating and complicated coding steps and to provide a cross-browser compatibility. apart from benchmark suites and recommendation from experts, there is little research helping practitioners to select the most suitable jsf to a given situation. the few proposals employ software metrics on the jsf, but practitioners are driven by different concerns when choosing a jsf. as an answer to the critical needs, this paper is a call for action. it proposes a research design towards a comparative analysis framework of jsf, which merges researcher needs and practitioner needs. © 2013 springer-verlag.",making sense out of a jungle of javascript frameworks: towards a practitioner-friendly comparative analysis
1693,2-s2.0-84890549178,10.1007/s11227-013-0901-3,Multi-device application middleware: Leveraging the ubiquity of the Web with webinos,Desruelle H.,Journal of Supercomputing,2013-10-01,"The broad range of connected devices has turned the Internet into a ubiquitous concept. In addition to desktop and laptop PCs, the Internet currently connects mobile devices, home entertainment systems, and even in-car units. From this ubiquitous evolution towards sensor-rich devices, the opportunity arises for various new types of innovative software application. However, alongside rises the issue of managing the increasing diversity of device characteristics and capabilities. As device fragmentation grows, application developers are facing the need to cover a wider variety of target devices and usage scenarios. In result, maintaining a viable balance between development costs and market coverage has turned out to be an important challenge when developing applications for a ubiquitous ecosystem. In this article, we present the webinos platform, a distributed Web runtime platform that leverages the Web for supporting self-adaptive cross-device applications. In order to enable the development of such immersive ubiquitous applications, we introduce and evaluate the concept of a context-aware federated overlay architecture. © 2013 Springer Science+Business Media New York.",Context-awareness | Multi-device applications | Ubiquitous Web | Webinos,3,4-20,Journal,Article,4.0,"Desruelle, Heiko;Isenberg, Simon;Lyle, John;Gielen, Frank",42861318800;55515951900;35113315300;8846417100,Universiteit Gent;University of Oxford;Bavarian Motor Works AG,Belgium;United Kingdom;Germany,"the broad range of connected devices has turned the internet into a ubiquitous concept. in addition to desktop and laptop pcs, the internet currently connects mobile devices, home entertainment systems, and even in-car units. from this ubiquitous evolution towards sensor-rich devices, the opportunity arises for various new types of innovative software application. however, alongside rises the issue of managing the increasing diversity of device characteristics and capabilities. as device fragmentation grows, application developers are facing the need to cover a wider variety of target devices and usage scenarios. in result, maintaining a viable balance between development costs and market coverage has turned out to be an important challenge when developing applications for a ubiquitous ecosystem. in this article, we present the webinos platform, a distributed web runtime platform that leverages the web for supporting self-adaptive cross-device applications. in order to enable the development of such immersive ubiquitous applications, we introduce and evaluate the concept of a context-aware federated overlay architecture. © 2013 springer science+business media new york.",multi-device application middleware: leveraging the ubiquity of the web with webinos
1696,2-s2.0-84883396484,10.1109/ICST.2013.59,OCCF: A framework for developing test coverage measurement tools supporting multiple programming languages,Sakamoto K.,"Proceedings - IEEE 6th International Conference on Software Testing, Verification and Validation, ICST 2013",2013-09-09,"Although many programming languages and test coverage criteria currently exist, most coverage measurement tools only support select programming languages and coverage criteria. Consequently, multiple measurement tools must be combined to measure coverage for software which uses multiple programming languages such as web applications. However, such combination leads to inconsistent and inaccurate measurement results.In this paper, we describe a consistent and flexible framework for measuring coverage supporting multiple programming languages, called Open Code Coverage Framework (OCCF). OCCF allows users to add new extensions for supporting programming languages and coverage criteria with low development costs. To evaluate the effectiveness of OCCF, sample implementation to support statement coverage and decision coverage for eight programming languages (C, C++, C#, Java, JavaScript, Python, Ruby and Lua) are demonstrated. Additionally, applications of OCCF for localizing faults and minimizing tests are shown. © 2013 IEEE.",fault localization | framework | programming languages | test coverage | test-suite minimization,6,422-430,Conference Proceeding,Conference Paper,5.0,"Sakamoto, Kazunori;Shimojo, Kiyofumi;Takasawa, Ryohei;Washizaki, Hironori;Fukazawa, Yoshiaki",36574117400;55844409500;55844030700;8905784000;7101986896,Waseda University,Japan,"although many programming languages and test coverage criteria currently exist, most coverage measurement tools only support select programming languages and coverage criteria. consequently, multiple measurement tools must be combined to measure coverage for software which uses multiple programming languages such as web applications. however, such combination leads to inconsistent and inaccurate measurement results.in this paper, we describe a consistent and flexible framework for measuring coverage supporting multiple programming languages, called open code coverage framework (occf). occf allows users to add new extensions for supporting programming languages and coverage criteria with low development costs. to evaluate the effectiveness of occf, sample implementation to support statement coverage and decision coverage for eight programming languages (c, c++, c#, java, javascript, python, ruby and lua) are demonstrated. additionally, applications of occf for localizing faults and minimizing tests are shown. © 2013 ieee.",occf: a framework for developing test coverage measurement tools supporting multiple programming languages
1698,2-s2.0-84882944653,10.4028/www.scientific.net/AMM.340.292,Design of vehicle reservation system in manufacturing engineering,Xie L.,Applied Mechanics and Materials,2013-08-30,"Nowadays, to develop office application system by means of web-development has gradually become the mainstream method, which is quick to develop, low in resource consumption, low in demand for software and hardware environment, easy to maintain, convenient in use and easy to learn. Moreover, JavaScript is an important tool to achieve the front-end dynamic function. jQuery is a lightweight JavaScript library and another excellent JavaScript framework after prototype. jQuery has a complete document description and a detailed instruction to various applications. At the same time, there are many mature plug-ins available. Applications of two kinds of jQuery plug-ins in the vehicle reservation system on web are mainly described in this paper. © (2013) Trans Tech Publications, Switzerland.",Fullcalender | Jqgrid | Jquery | Vehicle reservation system,0,292-297,Book Series,Conference Paper,1.0,"Xie, Liming",55834325000,Communication University of China,China,"nowadays, to develop office application system by means of web-development has gradually become the mainstream method, which is quick to develop, low in resource consumption, low in demand for software and hardware environment, easy to maintain, convenient in use and easy to learn. moreover, javascript is an important tool to achieve the front-end dynamic function. jquery is a lightweight javascript library and another excellent javascript framework after prototype. jquery has a complete document description and a detailed instruction to various applications. at the same time, there are many mature plug-ins available. applications of two kinds of jquery plug-ins in the vehicle reservation system on web are mainly described in this paper. © (2013) trans tech publications, switzerland.",design of vehicle reservation system in manufacturing engineering
1699,2-s2.0-84882943454,10.1109/CarpathianCC.2013.6560570,Using HTML5 web interface for visualization and control system,Stribny M.,"Proceedings of the 2013 14th International Carpathian Control Conference, ICCC 2013",2013-08-29,"ControlWeb is software system for rapid application development for industry, schools or laboratories. It helps compose visualization and control of technology processes in real time. To make this process more user friendly, a new interface between ControlWeb software and web browser was developed. Using HTML5 semantics, JavaScript library and extra code provides more efficient adoption of data and subsequent rendering of visualization process. © 2013 IEEE.",control system | HTML5 | JSON | visualization,4,363-366,Conference Proceeding,Conference Paper,2.0,"Stribny, Martin;Smutny, Pavel",55835047900;46061386000,VSB – Technical University of Ostrava,Czech Republic,"controlweb is software system for rapid application development for industry, schools or laboratories. it helps compose visualization and control of technology processes in real time. to make this process more user friendly, a new interface between controlweb software and web browser was developed. using html5 semantics, javascript library and extra code provides more efficient adoption of data and subsequent rendering of visualization process. © 2013 ieee.",using html5 web interface for visualization and control system
1700,2-s2.0-84881303041,10.1145/2483760.2483786,An empirical study of PHP feature usage: A static analysis perspective,Hills M.,"2013 International Symposium on Software Testing and Analysis, ISSTA 2013 - Proceedings",2013-08-14,"PHP is one of the most popular languages for server-side application development. The language is highly dynamic, providing programmers with a large amount of flexibility. However, these dynamic features also have a cost, making it difficult to apply traditional static analysis techniques used in standard code analysis and transformation tools. As part of our work on creating analysis tools for PHP, we have conducted a study over a significant corpus of open-source PHP systems, looking at the sizes of actual PHP programs, which features of PHP are actually used, how often dynamic features appear, and how distributed these features are across the files that make up a PHP website. We have also looked at whether uses of these dynamic features are truly dynamic or are, in some cases, statically understandable, allowing us to identify specific patterns of use which can then be taken into account to build more precise tools. We believe this work will be of interest to creators of analysis tools for PHP, and that the methodology we present can be leveraged for other dynamic languages with similar features. © 2013 ACM.",Dynamic language features | PHP | Static analysis | Static metrics | Static program behavior,30,325-335,Conference Proceeding,Conference Paper,3.0,"Hills, Mark;Klint, Paul;Vinju, Jurgen",7006273354;7003784627;9733732800,INRIA Institut National de Recherche en Informatique et en Automatique;Centrum Wiskunde &amp; Informatica,France;Netherlands,"php is one of the most popular languages for server-side application development. the language is highly dynamic, providing programmers with a large amount of flexibility. however, these dynamic features also have a cost, making it difficult to apply traditional static analysis techniques used in standard code analysis and transformation tools. as part of our work on creating analysis tools for php, we have conducted a study over a significant corpus of open-source php systems, looking at the sizes of actual php programs, which features of php are actually used, how often dynamic features appear, and how distributed these features are across the files that make up a php website. we have also looked at whether uses of these dynamic features are truly dynamic or are, in some cases, statically understandable, allowing us to identify specific patterns of use which can then be taken into account to build more precise tools. we believe this work will be of interest to creators of analysis tools for php, and that the methodology we present can be leveraged for other dynamic languages with similar features. © 2013 acm.",an empirical study of php feature usage: a static analysis perspective
1701,2-s2.0-84881034871,10.1109/AINA.2013.94,The framework of cloud computing platform for massive remote sensing images,Lin F.,"Proceedings - International Conference on Advanced Information Networking and Applications, AINA",2013-08-08,"In recent years, due to the rapid development of remote sensing technology, a single high-quality image will occupy larger storage space, and video has become so widespread in the usage of environmental observation and record. Hence, digital data is growing exponentially, and how to manage them and make image processing more effectively is a key issue in Geographic Information System. Additionally, the limitation of hardware resource and time-consuming images' processing is a bottleneck to cope with such big data by commercial software in single PC. The aim of this paper is to propose a framework based on some standards of the interface (WCS, WMS, and WPS) from Open Geospatial Consortium (OGC), cloud storage from HDFS, and image processing from MapReduce. Within this framework, we implement image management as well as simple WebGIS and test a read/write performance under four kinds of data sets (Normal Distribution, Skew to Left, Skew to Right, and Peak in Left and Right). The results reveal write/read performance of HDFS are outperform than the local file system in the situation of larger files (most files range in size from 8 MB to 10 MB) and a large number of threads (threads equal to 40 or 50). © 2013 IEEE.",Cloud computing | HDFS | MapReduce | Remote sensing images,16,621-628,Conference Proceeding,Conference Paper,5.0,"Lin, Feng Cheng;Chung, Lan Kun;Ku, Wen Yuan;Chu, Lin Ru;Chou, Tien Yin",23397448400;55782626800;55810819700;55811354900;8690206800,Feng Chia University,Taiwan,"in recent years, due to the rapid development of remote sensing technology, a single high-quality image will occupy larger storage space, and video has become so widespread in the usage of environmental observation and record. hence, digital data is growing exponentially, and how to manage them and make image processing more effectively is a key issue in geographic information system. additionally, the limitation of hardware resource and time-consuming images' processing is a bottleneck to cope with such big data by commercial software in single pc. the aim of this paper is to propose a framework based on some standards of the interface (wcs, wms, and wps) from open geospatial consortium (ogc), cloud storage from hdfs, and image processing from mapreduce. within this framework, we implement image management as well as simple webgis and test a read/write performance under four kinds of data sets (normal distribution, skew to left, skew to right, and peak in left and right). the results reveal write/read performance of hdfs are outperform than the local file system in the situation of larger files (most files range in size from 8 mb to 10 mb) and a large number of threads (threads equal to 40 or 50). © 2013 ieee.",the framework of cloud computing platform for massive remote sensing images
1702,2-s2.0-84880824571,10.4304/jsw.8.8.1881-1888,An MDA based modeling and implementation for web app,Luo R.,Journal of Software,2013-08-02,"Web App surges recently as the HTML technology comes to be well-developed. The development framework of existing platform demands the users' attention directed towards technique details and duplicated efforts. In order to save the developers' efforts to the design of App functions and its ease of use, the idea of Model Driven Architecture (MDA) will be extended in the development of Web App. This paper proposes a Web App development framework based on MDA-Model Driven Web App Development Framework (MDWAF). Based on the MDWAF, the development of Web App will focus on the software models. The comprehensive data management of development and release process will be achieved by Cloud Services, and the cross-platform local resources access of Web App will be provided by mobile middleware. © 2013 ACADEMY PUBLISHER.",Model driven development | Model transformation | Platform dependent model | Platform independent model | Web app,1,1881-1888,Journal,Article,7.0,"Luo, Rongliang;Peng, Xiao;Lv, Qianxi;Wu, Minghui;Peng, Bin;Wang, Shuoping;Guo, Ming",25960247300;57199119944;55805628900;8301222100;54977274700;35202103300;55732400900,"College of Computer Science and Technology, Zhejiang University;Zhejiang University City College;Zhejiang University",China;China;China,"web app surges recently as the html technology comes to be well-developed. the development framework of existing platform demands the users' attention directed towards technique details and duplicated efforts. in order to save the developers' efforts to the design of app functions and its ease of use, the idea of model driven architecture (mda) will be extended in the development of web app. this paper proposes a web app development framework based on mda-model driven web app development framework (mdwaf). based on the mdwaf, the development of web app will focus on the software models. the comprehensive data management of development and release process will be achieved by cloud services, and the cross-platform local resources access of web app will be provided by mobile middleware. © 2013 academy publisher.",an mda based modeling and implementation for web app
1704,2-s2.0-84880540238,10.1109/JSYST.2012.2222000,Security applications of formal language theory,Sassaman L.,IEEE Systems Journal,2013-07-29,"We present a formal language theory approach to improving the security aspects of protocol design and message-based interactions in complex composed systems. We argue that these aspects are responsible for a large share of modern computing systems' insecurity. We show how our approach leads to advances in input validation, security modeling, attack surface reduction, and ultimately, software design and programming methodology. We cite examples based on real-world security flaws in common protocols, representing different classes of protocol complexity. We also introduce a formalization of an exploit development technique, the parse tree differential attack, made possible by our conception of the role of formal grammars in security. We also discuss the negative impact unnecessarily increased protocol complexity has on security. This paper provides a foundation for designing verifiable critical implementation components with considerably less burden to developers than is offered by the current state of the art. In addition, it offers a rich basis for further exploration in the areas of offensive analysis and, conversely, automated defense tools, and techniques. © 2012 IEEE.",Language-theoretic security | secure composition | secure protocol design,34,489-500,Journal,Article,4.0,"Sassaman, Len;Patterson, Meredith L.;Bratus, Sergey;Locasto, Michael E.",14630873000;36441809800;6505845456;14024637200,"KU Leuven;Dartmouth College;University of Calgary;Red Lambda, Inc.",Belgium;United States;Canada;United States,"we present a formal language theory approach to improving the security aspects of protocol design and message-based interactions in complex composed systems. we argue that these aspects are responsible for a large share of modern computing systems' insecurity. we show how our approach leads to advances in input validation, security modeling, attack surface reduction, and ultimately, software design and programming methodology. we cite examples based on real-world security flaws in common protocols, representing different classes of protocol complexity. we also introduce a formalization of an exploit development technique, the parse tree differential attack, made possible by our conception of the role of formal grammars in security. we also discuss the negative impact unnecessarily increased protocol complexity has on security. this paper provides a foundation for designing verifiable critical implementation components with considerably less burden to developers than is offered by the current state of the art. in addition, it offers a rich basis for further exploration in the areas of offensive analysis and, conversely, automated defense tools, and techniques. © 2012 ieee.",security applications of formal language theory
1705,2-s2.0-84880537034,10.1145/2480296.2480328,A framework for the development of distributed interactive applications,Frosini L.,EICS 2013 - Proceedings of the ACM SIGCHI Symposium on Engineering Interactive Computing Systems,2013-07-29,"In this paper we present a framework and the associated software architecture to manage user interfaces that can be distributed and/or migrated in multi-device and multi-user environments. It supports distribution across dynamic sets of devices, and does not require the use of a fixed server. We also report on its current implementation, and an example application. Copyright © ACM.",Distributed and migratory user interfaces | Multi-device user interfaces | Multi-user user interfaces,13,249-254,Conference Proceeding,Conference Paper,3.0,"Frosini, Luca;Manca, Marco;Paternò, Fabio",25632099100;36679099200;55156557600,Istituto di Scienza e Tecnologie dell'Informazione A. Faedo,Italy,"in this paper we present a framework and the associated software architecture to manage user interfaces that can be distributed and/or migrated in multi-device and multi-user environments. it supports distribution across dynamic sets of devices, and does not require the use of a fixed server. we also report on its current implementation, and an example application. copyright © acm.",a framework for the development of distributed interactive applications
1706,2-s2.0-84880517934,10.1145/2480296.2480312,"Toward rapid and iterative development of tangible, collaborative, distributed user interfaces",Branton C.,EICS 2013 - Proceedings of the ACM SIGCHI Symposium on Engineering Interactive Computing Systems,2013-07-29,"Distributed, tangible, collaborative applications involve potentially complex interactions of users, computing platforms, and physical artifacts. Realizing the necessary connections for these interactions can create hardware and software dependencies early in development, resulting in a system that is difficult to adapt to design changes. The Ensemble architecture is designed to encourage exploratory development of these systems by limiting the impact of changing components. Ensemble is a product of the exploratory design process it supports, evolving through use in two distinct application domains. The experience gained from these implementations has shaped Ensemble's structure and design priorities, resulting in a component-based architecture that includes: (i) an application framework and graphical user interface support; (ii) a service framework, including service publication and discovery; (iii) local and remote event handling; (iv) distributed user and resource coordination; and (v) a structured configuration language shared by all Ensemble components. Copyright 2013 ACM.",Distributed user interfaces | Multi-device user interfaces | Multi-platform user interfaces | Software architecture | Tangible interfaces,8,239-248,Conference Proceeding,Conference Paper,7.0,"Branton, Chris;Ullmer, Brygg;Wiggins, Andre;Rogge, Landon;Setty, Narendra;Beck, Stephan David;Reeser, Alex",35975527700;6602593224;55800668800;37051417700;55800644900;57213117053;37051501300,Louisiana State University,United States,"distributed, tangible, collaborative applications involve potentially complex interactions of users, computing platforms, and physical artifacts. realizing the necessary connections for these interactions can create hardware and software dependencies early in development, resulting in a system that is difficult to adapt to design changes. the ensemble architecture is designed to encourage exploratory development of these systems by limiting the impact of changing components. ensemble is a product of the exploratory design process it supports, evolving through use in two distinct application domains. the experience gained from these implementations has shaped ensemble's structure and design priorities, resulting in a component-based architecture that includes: (i) an application framework and graphical user interface support; (ii) a service framework, including service publication and discovery; (iii) local and remote event handling; (iv) distributed user and resource coordination; and (v) a structured configuration language shared by all ensemble components. copyright 2013 acm.","toward rapid and iterative development of tangible, collaborative, distributed user interfaces"
1708,2-s2.0-84879631072,10.5012/jkcs.2013.57.3.357,On water CuSO<inf>4</inf>. 5H<inf>2</inf>O-catalyzed synthesis of 2-amino-4H-chromenes,Behbahani F.K.,Journal of the Korean Chemical Society,2013-06-20,"Sustainable development is a balance between environment and development. Sustainable development requires sustainable supplies of clean, affordable, and renewable energy sources that do not cause negative impact to the society. This article introduces a green chemistry method to synthesize 2-amino-4H-chromenes that reduces or eliminates the use and generation of hazardous substances in the design, manufacture, and application of chemical products. This method is described using copper (II) sulfate pentahydrate, as a green and reusable catalyst on water. The products were obtained at very good yields, short reaction time, and at lower cost than other reported procedures.",Chromene | CuSO . 5H O 4 2 | Green chemistry | Synthesis | Water,27,357-360,Journal,Article,2.0,"Behbahani, Farahnaz Kargar;Maryam, Sadeghi",8281119500;55781146400,"Islamic Azad University, Karaj Branch",Iran,"sustainable development is a balance between environment and development. sustainable development requires sustainable supplies of clean, affordable, and renewable energy sources that do not cause negative impact to the society. this article introduces a green chemistry method to synthesize 2-amino-4h-chromenes that reduces or eliminates the use and generation of hazardous substances in the design, manufacture, and application of chemical products. this method is described using copper (ii) sulfate pentahydrate, as a green and reusable catalyst on water. the products were obtained at very good yields, short reaction time, and at lower cost than other reported procedures.",on water cuso<inf>4</inf>. 5h<inf>2</inf>o-catalyzed synthesis of 2-amino-4h-chromenes
1711,2-s2.0-84876903361,10.4304/jsw.8.5.1186-1193,The development of a mobile terminal middleware platform based on HTML5,Yi X.,Journal of Software,2013-05-06,"With the rapid development of wireless communication technology and the proliferation of mobile devices, mobile applications are more and more widely used. Depending on the characteristics that the existing mobile applications need long development cycles depending on a variety of mobile devices, this paper puts forward an HTML5-based mobile middleware on the basis of the traditional middleware and mobile middleware. The mobile middleware uses the B/C/S hybrid architecture and shields the differences between the hardware and software of mobile devices, which enables developers to develop applications that are suitable for mobile terminal platforms according to MVC pattern. Compared with other middlewares, HTML5-based mobile middleware has the advantages of short develop cycle, low cost and low difficulty as well as good expansibility. © 2013 ACADEMY PUBLISHER.",B/C/S | Cross-platform | HTML5 | Mobile middleware,1,1186-1193,Journal,Article,2.0,"Yi, Xiaolin;Ning, Yishuang",27868235100;56254462300,Beijing University of Technology,China,"with the rapid development of wireless communication technology and the proliferation of mobile devices, mobile applications are more and more widely used. depending on the characteristics that the existing mobile applications need long development cycles depending on a variety of mobile devices, this paper puts forward an html5-based mobile middleware on the basis of the traditional middleware and mobile middleware. the mobile middleware uses the b/c/s hybrid architecture and shields the differences between the hardware and software of mobile devices, which enables developers to develop applications that are suitable for mobile terminal platforms according to mvc pattern. compared with other middlewares, html5-based mobile middleware has the advantages of short develop cycle, low cost and low difficulty as well as good expansibility. © 2013 academy publisher.",the development of a mobile terminal middleware platform based on html5
1712,2-s2.0-84877598104,10.1016/j.compenvurbsys.2012.10.003,"The 2012 free and open source GIS software map - A guide to facilitate research, development, and adoption",Steiniger S.,"Computers, Environment and Urban Systems",2013-05-01,"Over the last decade an increasing number of free and open source software projects have been founded that concentrate on developing several types of software for geographic data collection, storage, analysis and visualization. We first identify the drivers of such software projects and identify different types of geographic information software, e.g. desktop GIS, remote sensing software, server GIS etc. We then list the major projects for each software category. Afterwards we discuss the points that should be considered if free and open source software is to be selected for use in business and research, such as software functionality, license types and their restrictions, developer and user community characteristics, etc. Finally possible future developments are addressed. © 2012 Elsevier Ltd.",FOSS4G | Free software | GIS software | Open source | Overview | Software selection,144,136-150,Journal,Review,2.0,"Steiniger, Stefan;Hunter, Andrew J.S.",18038653900;7402779594,University of Calgary,Canada,"over the last decade an increasing number of free and open source software projects have been founded that concentrate on developing several types of software for geographic data collection, storage, analysis and visualization. we first identify the drivers of such software projects and identify different types of geographic information software, e.g. desktop gis, remote sensing software, server gis etc. we then list the major projects for each software category. afterwards we discuss the points that should be considered if free and open source software is to be selected for use in business and research, such as software functionality, license types and their restrictions, developer and user community characteristics, etc. finally possible future developments are addressed. © 2012 elsevier ltd.","the 2012 free and open source gis software map - a guide to facilitate research, development, and adoption"
1713,2-s2.0-84876711162,10.1016/j.jsb.2013.02.007,"Maskiton: Interactive, web-based classification of single-particle electron microscopy images",Yoshioka C.,Journal of Structural Biology,2013-05-01,"Electron microscopy (EM) is an important tool for determining the composition, arrangement and structure of biological macromolecules. When studying structurally heterogeneous samples using EM, classification is a critical step toward achieving higher resolution and identifying biologically significant conformations. We have developed an interactive, web-based tool, called Maskiton, for creating custom masks and performing 2D classifications on aligned single-particle EM images. The Maskiton interface makes it considerably easier and faster to explore the significance of heterogeneity in single-particle datasets. Maskiton features include: resumable uploads to facilitate transfer of large datasets to the server, custom mask creation in the browser, continual progress updates, and interactive viewing of classification results. To demonstrate the value of this tool, we provide examples of its use on several experimental datasets and include analyses of the independent terminus mobility within the Ltn1 E3 ubiquitin ligase, the in vitro assembly of 30S ribosomal subunits, and classification complexity reduction within Immunoglobulin M. This work also serves as a proof-of-concept for the development of future cross-platform, interactive user interfaces for electron microscopy data processing. © 2013 Elsevier Inc.",30S | Electron microscopy | IgM | Ltn1 | Single-particle classification | Software,3,155-163,Journal,Article,4.0,"Yoshioka, Craig;Lyumkis, Dmitry;Carragher, Bridget;Potter, Clinton S.",7004148705;26026114800;35594797000;7202295148,Scripps Research Institute,United States,"electron microscopy (em) is an important tool for determining the composition, arrangement and structure of biological macromolecules. when studying structurally heterogeneous samples using em, classification is a critical step toward achieving higher resolution and identifying biologically significant conformations. we have developed an interactive, web-based tool, called maskiton, for creating custom masks and performing 2d classifications on aligned single-particle em images. the maskiton interface makes it considerably easier and faster to explore the significance of heterogeneity in single-particle datasets. maskiton features include: resumable uploads to facilitate transfer of large datasets to the server, custom mask creation in the browser, continual progress updates, and interactive viewing of classification results. to demonstrate the value of this tool, we provide examples of its use on several experimental datasets and include analyses of the independent terminus mobility within the ltn1 e3 ubiquitin ligase, the in vitro assembly of 30s ribosomal subunits, and classification complexity reduction within immunoglobulin m. this work also serves as a proof-of-concept for the development of future cross-platform, interactive user interfaces for electron microscopy data processing. © 2013 elsevier inc.","maskiton: interactive, web-based classification of single-particle electron microscopy images"
1714,2-s2.0-84875638556,10.1007/s11042-012-1025-0,A virtual globe tool for searching and visualizing geo-referenced media resources in social networks,Beltran A.,Multimedia Tools and Applications,2013-05-01,"The current collaborative context and resource sharing that drives Web 2.0 is gaining importance within academia and industry, which is stimulating the development of new techniques for content retrieval, sharing and analysis over user-generated media content. This poses new challenges and research opportunities in spatial-based discovery media resources over varied sources, since location context is being increasingly supported in most of these social networks and services. In this paper, we present a virtual globe tool for searching and visualizing geo-referenced media resources. Our approach is based on the integration of search technologies, description languages for annotating collections of geo-referenced media resources and visualization techniques. The combination of these techniques is materialized in a virtual globe-based tool to facilitate searching and presentation of geo-referenced media resources available in different social networks. © 2012 Springer Science+Business Media, LLC.",Geo-referenced media resources | KML | MIMEXT | OpenSearch | Social networks | User-generated content retrieval | Virtual globes,9,171-195,Journal,Article,6.0,"Beltran, Arturo;Abargues, Carlos;Granell, Carlos;Núñez, Manuela;Díaz, Laura;Huerta, Joaquín",55027673600;36052404100;8833951100;36622317100;23491820100;56260161000,Universidad Jaume I,Spain,"the current collaborative context and resource sharing that drives web 2.0 is gaining importance within academia and industry, which is stimulating the development of new techniques for content retrieval, sharing and analysis over user-generated media content. this poses new challenges and research opportunities in spatial-based discovery media resources over varied sources, since location context is being increasingly supported in most of these social networks and services. in this paper, we present a virtual globe tool for searching and visualizing geo-referenced media resources. our approach is based on the integration of search technologies, description languages for annotating collections of geo-referenced media resources and visualization techniques. the combination of these techniques is materialized in a virtual globe-based tool to facilitate searching and presentation of geo-referenced media resources available in different social networks. © 2012 springer science+business media, llc.",a virtual globe tool for searching and visualizing geo-referenced media resources in social networks
1715,2-s2.0-84902375652,10.1145/2468356.2479626,Enhancing One-handed Website Operation on Touchscreen Mobile Phones,Seipp K.,Conference on Human Factors in Computing Systems - Proceedings,2013-04-27,"Operating a website with one hand on a touchscreen mobile phone remains difficult despite advances in hardware and software development. This problem is exacerbated by manufacturers producing phones with larger screens which are more difficult to hold and operate one-handedly. We present a way to enhance one-handed operation of a website using standard client-side web technologies, without the need to redesign the site or to overwrite any CSS styles. It transforms input for form elements, media control and page access on the fly into a thumb-friendly interaction model. Initial user testing of our interface prototype confirms efficiency and learnability, and highlights its usefulness for navigating long pages and finding the desired information more quickly, even between different websites, when operating the device with one hand.",CSS3 | Handheld devices | HTML5 | Interface adaptation | JavaScript | Mobile | One-handed operation | Web | Wheel menu,5,3123-3126,Conference Proceeding,Conference Paper,2.0,"Seipp, Karsten;Devlin, Kate",55848310300;57197168072,"Goldsmiths, University of London",United Kingdom,"operating a website with one hand on a touchscreen mobile phone remains difficult despite advances in hardware and software development. this problem is exacerbated by manufacturers producing phones with larger screens which are more difficult to hold and operate one-handedly. we present a way to enhance one-handed operation of a website using standard client-side web technologies, without the need to redesign the site or to overwrite any css styles. it transforms input for form elements, media control and page access on the fly into a thumb-friendly interaction model. initial user testing of our interface prototype confirms efficiency and learnability, and highlights its usefulness for navigating long pages and finding the desired information more quickly, even between different websites, when operating the device with one hand.",enhancing one-handed website operation on touchscreen mobile phones
1717,2-s2.0-84875517541,10.2316/P.2013.796-033,AOP based language extension for web development,Fukuda H.,"IASTED Multiconferences - Proceedings of the IASTED International Conference on Software Engineering, SE 2013",2013-04-03,"Unlike traditional web applications, current web applications called RIAs become powerful and useful by combining several technologies including markup languages, client-side script languages and web services. Therefore, it becomes more complicated to develop these applications and a number of stakeholders including designers and developers are required. It is reasonable to divide an application into several concerns (i.e., modules) to make the development effective, however, pieces of code to combine each concern prevent it. For example, designers design user interfaces with markup languages, e.g., HTML and developers implement application logic with script languages. Then developers will often need to add code (e.g., event handlers) to connect the user interface and the logic so that this will become a single application. In this paper, we propose a client-side script language extension inspired by Aspect-Oriented Programming, which is well-known concept to realize improved separation of concerns. This language extension mainly focuses on the complete separation between markup languages, which represent user interfaces, and script languages, which represent client-side logic. In addition, we provide a prototype implementation of an weaver, which combines modules before the execution.",Aspect-oriented programming | Rich internet application | Web development,0,744-751,Conference Proceeding,Conference Paper,1.0,"Fukuda, Hiroaki",35339358100,Shibaura Institute of Technology,Japan,"unlike traditional web applications, current web applications called rias become powerful and useful by combining several technologies including markup languages, client-side script languages and web services. therefore, it becomes more complicated to develop these applications and a number of stakeholders including designers and developers are required. it is reasonable to divide an application into several concerns (i.e., modules) to make the development effective, however, pieces of code to combine each concern prevent it. for example, designers design user interfaces with markup languages, e.g., html and developers implement application logic with script languages. then developers will often need to add code (e.g., event handlers) to connect the user interface and the logic so that this will become a single application. in this paper, we propose a client-side script language extension inspired by aspect-oriented programming, which is well-known concept to realize improved separation of concerns. this language extension mainly focuses on the complete separation between markup languages, which represent user interfaces, and script languages, which represent client-side logic. in addition, we provide a prototype implementation of an weaver, which combines modules before the execution.",aop based language extension for web development
1718,2-s2.0-84874809989,10.1007/978-3-642-36632-1_24,The webinos architecture: A developer's point of view,Vergori P.,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering",2013-03-14,"This work describes the architecture proposed by the webinos EU project, which aims at developing software components for the future Internet, in the form of Web Runtime Extensions. It discusses the webinos architecture from a developer's point of view, presenting an overview of its main advantages, such as context-awareness capabilities and distributed APIs in an intrinsic secure environment. It also shows how these features can in practice prove beneficial to the development of ubiquitous and secure web applications based on standard technologies like HTML, CSS and JavaScript. © 2013 ICST Institute for Computer Science, Social Informatics and Telecommunications Engineering.",architecture | context | context awareness | developers | distributed apis | framework | middleware | mobile applications | webinos,4,391-399,Book Series,Conference Paper,4.0,"Vergori, Paolo;Ntanos, Christos;Gavelli, Marco;Askounis, Dimitris",55619106900;25927965500;54896076100;6603428475,Istituto Superiore Mario Boella;National Technical University of Athens,Italy;Greece,"this work describes the architecture proposed by the webinos eu project, which aims at developing software components for the future internet, in the form of web runtime extensions. it discusses the webinos architecture from a developer's point of view, presenting an overview of its main advantages, such as context-awareness capabilities and distributed apis in an intrinsic secure environment. it also shows how these features can in practice prove beneficial to the development of ubiquitous and secure web applications based on standard technologies like html, css and javascript. © 2013 icst institute for computer science, social informatics and telecommunications engineering.",the webinos architecture: a developer's point of view
1725,2-s2.0-84924293936,10.5194/isprsarchives-XL-5-W3-111-2013,"Istsos, sensor observation management system: A real case application of hydro-meteorological data for flood protection",Cannata M.,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",2013-01-01,"istSOS (Istituto scienze della Terra Sensor Observation Service) is an implementation of the Sensor Observation Service standard from Open Geospatial Consortium (OGC). The development of istSOS started in 2009 in order to provide a simple implementation of the Sensor Observation Service (SOS) standard for the management, provision and integration of hydro-meteorological data collected in Canton Ticino (Southern Switzerland). istSOS is entirely written in Python and is based on reliable open source software like PostgreSQL/PostGIS and Apache/mod-wsgi. The authors during this presentation want to illustrate the latest software enhancements together with a real case in a production environment. Latest software enhancement includes the development of a RESTful service and of a Web-based graphical user interface that allows hydrologists a better interaction with measurements. This includes the ability of new services creation, addition of new sensors and relative metadata, visualization and manipulation of stored observations, registration of new measures and setting of system properties like observable properties and data quality codes. The study will show a real case application of the system for the provision of data to interregional partners and to a hydrological model for lake level forecasting and flooding hazard assessment. The hydrological model uses a combination of WPS (Web Processing Service) and SOS for the generation of model input data. This system is linked with a dedicated geo-portal used by the civil protection for the management, alert and protection of population and assets of the Locarno area (Verbano Lake flooding). Practical considerations and technical issues will be presented and discussed.",Monitoring | Observations | OGC | Sensors | Services | SOS,1,111-117,Conference Proceeding,Conference Paper,4.0,"Cannata, M.;Antonovic, M.;Molinari, M.;Pozzoni, M.",50261199900;55954118700;56735731000;55953670900,Scuola Universitaria Professionale della Svizzera Italiana,Switzerland,"istsos (istituto scienze della terra sensor observation service) is an implementation of the sensor observation service standard from open geospatial consortium (ogc). the development of istsos started in 2009 in order to provide a simple implementation of the sensor observation service (sos) standard for the management, provision and integration of hydro-meteorological data collected in canton ticino (southern switzerland). istsos is entirely written in python and is based on reliable open source software like postgresql/postgis and apache/mod-wsgi. the authors during this presentation want to illustrate the latest software enhancements together with a real case in a production environment. latest software enhancement includes the development of a restful service and of a web-based graphical user interface that allows hydrologists a better interaction with measurements. this includes the ability of new services creation, addition of new sensors and relative metadata, visualization and manipulation of stored observations, registration of new measures and setting of system properties like observable properties and data quality codes. the study will show a real case application of the system for the provision of data to interregional partners and to a hydrological model for lake level forecasting and flooding hazard assessment. the hydrological model uses a combination of wps (web processing service) and sos for the generation of model input data. this system is linked with a dedicated geo-portal used by the civil protection for the management, alert and protection of population and assets of the locarno area (verbano lake flooding). practical considerations and technical issues will be presented and discussed.","istsos, sensor observation management system: a real case application of hydro-meteorological data for flood protection"
1727,2-s2.0-84924255336,10.5194/isprsarchives-XL-7-W2-243-2013,The ESA Felyx high resolution diagnostic data set system design and implementation,Taberner M.,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",2013-01-01,"Felyx is currently under development and is the latest evolution of a generalised High Resolution Diagnostic Data Set system funded by ESA. It draws on previous prototype developments and experience in the GHRSST, Medspiration, GlobColour and GlobWave projects. In this paper, we outline the design and implementation of the system, and illustrate using the Ocean Colour demonstration activities. Felyx is fundamentally a tool to facilitate the analysis of EO data: it is being developed by IFREMER, PML and Pelamis. It will be free software written in python and javascript. The aim is to provide Earth Observation data producers and users with an open-source, flexible and reusable tool to allow the quality and performance of data streams from satellite, in situ and model sources to be easily monitored and studied. New to this project, is the ability to establish and incorporate multi-sensor match-up database capabilities. The systems will be deployable anywhere and even include interaction mechanisms between the deployed instances. The primary concept of Felyx is to work as an extraction tool. It allows for the extraction of subsets of source data over predefined target areas(which can be static or moving). These data subsets, and associated metrics, can then be accessed by users or client applications either as raw files or through automatic alerts. These data can then be used to generate periodic reports or be used for statistical analysis and visualisation through a flexible web interface. Felyx can be used for subsetting, the generation of statistics, the generation of reports or warnings/alerts, and in-depth analyses, to name a few. There are many potential applications but important uses foreseen are:<sup>∗</sup> monitoring and assessing the quality of Earth observations (e.g. satellite products and time series) through statistical analysis and/or comparison with other data sources<sup>∗</sup> assessing and inter-comparing geophysical inversion algorithms<sup>∗</sup> observing a given phenomenon, collecting and cumulating various parameters over a defined area<sup>∗</sup> crossing different sources of data for synergy applications The services provided by felyx will be generic, deployable at users own premises, and flexible allowing the integration and development of any kind of parameters. Users will be able to operate their own felyx instance at any location, on datasets and parameters of their own interest, and the various instances will be able to interact with each other, creating a web of felyx systems enabling aggregation and cross comparison of miniProds and metrics from multiple sources. Initially two instances will be operated simultaneously during a 6 months demonstration phase, at IFREMER - on sea surface temperature and ocean waves datasets - and PML - on ocean colour.",Insitu data | Multisensor | Multitemporal data analysis | Tracking | Trend analysis,3,243-249,Conference Proceeding,Conference Paper,7.0,"Taberner, M.;Shutler, J.;Walker, P.;Poulter, D.;Piolle, J. F.;Donlon, C.;Guidetti, V.",6603108176;6506674287;57198955968;15036699600;12804290300;7003303148;56539602900,European Space Agency - ESA;IFREMER Institut Francais de Recherche pour l'Exploitation de la Mer;Plymouth Marine Laboratory;Pelamis Scientific Software,France;France;United Kingdom;United Kingdom,"felyx is currently under development and is the latest evolution of a generalised high resolution diagnostic data set system funded by esa. it draws on previous prototype developments and experience in the ghrsst, medspiration, globcolour and globwave projects. in this paper, we outline the design and implementation of the system, and illustrate using the ocean colour demonstration activities. felyx is fundamentally a tool to facilitate the analysis of eo data: it is being developed by ifremer, pml and pelamis. it will be free software written in python and javascript. the aim is to provide earth observation data producers and users with an open-source, flexible and reusable tool to allow the quality and performance of data streams from satellite, in situ and model sources to be easily monitored and studied. new to this project, is the ability to establish and incorporate multi-sensor match-up database capabilities. the systems will be deployable anywhere and even include interaction mechanisms between the deployed instances. the primary concept of felyx is to work as an extraction tool. it allows for the extraction of subsets of source data over predefined target areas(which can be static or moving). these data subsets, and associated metrics, can then be accessed by users or client applications either as raw files or through automatic alerts. these data can then be used to generate periodic reports or be used for statistical analysis and visualisation through a flexible web interface. felyx can be used for subsetting, the generation of statistics, the generation of reports or warnings/alerts, and in-depth analyses, to name a few. there are many potential applications but important uses foreseen are:<sup>∗</sup> monitoring and assessing the quality of earth observations (e.g. satellite products and time series) through statistical analysis and/or comparison with other data sources<sup>∗</sup> assessing and inter-comparing geophysical inversion algorithms<sup>∗</sup> observing a given phenomenon, collecting and cumulating various parameters over a defined area<sup>∗</sup> crossing different sources of data for synergy applications the services provided by felyx will be generic, deployable at users own premises, and flexible allowing the integration and development of any kind of parameters. users will be able to operate their own felyx instance at any location, on datasets and parameters of their own interest, and the various instances will be able to interact with each other, creating a web of felyx systems enabling aggregation and cross comparison of miniprods and metrics from multiple sources. initially two instances will be operated simultaneously during a 6 months demonstration phase, at ifremer - on sea surface temperature and ocean waves datasets - and pml - on ocean colour.",the esa felyx high resolution diagnostic data set system design and implementation
1735,2-s2.0-84902416441,10.1016/B978-0-12-407772-0.00006-X,Continuous Software Architecture Analysis,Buchgeher G.,Agile Software Architecture: Aligning Agile Processes and Software Architectures,2013-01-01,"This chapter discusses software architecture analysis in the context of agile processes. Agile processes are characterized by incremental and interleaved activities and by a focus on continuous improvement and delivery. Most approaches to software architecture analysis, however, have been developed to be performed at dedicated points in the development process or as external evaluation activities and not as continuous activities throughout the development process. This chapter discusses continuous software architecture analysis (CSAA). It reviews important requirements for CSAA and outlines how CSAA is supported by current software architecture analysis approaches. It further presents experiences with an approach for continuous structural and conformance analysis and identifies future research challenges. © 2014 Elsevier Inc. All rights reserved.",Agile development | Continuous quality control | Continuous software architecture analysis | Software architecture | Software architecture analysis,5,161-188,Book,Book Chapter,2.0,"Buchgeher, Georg;Weinreich, Rainer",25924743400;7003270017,Johannes Kepler University Linz;Software Competence Center Hagenberg,Austria;Austria,"this chapter discusses software architecture analysis in the context of agile processes. agile processes are characterized by incremental and interleaved activities and by a focus on continuous improvement and delivery. most approaches to software architecture analysis, however, have been developed to be performed at dedicated points in the development process or as external evaluation activities and not as continuous activities throughout the development process. this chapter discusses continuous software architecture analysis (csaa). it reviews important requirements for csaa and outlines how csaa is supported by current software architecture analysis approaches. it further presents experiences with an approach for continuous structural and conformance analysis and identifies future research challenges. © 2014 elsevier inc. all rights reserved.",continuous software architecture analysis
1736,2-s2.0-84902064538,10.1016/B978-0-12-396961-3.00010-X,Web Development,Ganney P.S.,Clinical Engineering: A Handbook for Clinical and Biomedical Engineers,2013-01-01,"The chapter begins with an examination of various different web hosting strategies and platforms, both software and hardware. Many types are compared, giving advantages and disadvantages of all. Next, methods of programming for the web are described, starting from a description of HTML, adding in functionality via JavaScript, C++, and PHP. This is then expanded to the collection of data. HTML forms are described, both as hard-coded and generated via C++. Further expansion into dynamic content is considered, both generated code and auto-refreshing pages, and examples of database use are given. The last part of the chapter describes security particularly as applied to web applications, through techniques for access limitation (both server and client side). The chapter concludes with an examination of public and private key encryption and digital signatures. © 2014 Elsevier Ltd All rights reserved.",Access limitation | Cloud server | Cryptography | Databases | Digital signature | Dynamic content | HTML | JavaScript | Password | PHP | Private key | Public key | Virtual server | Web forms | Web hosting,0,171-190,Book,Book Chapter,3.0,"Ganney, Paul S.;Pisharody, Sandhya;McDonagh, Ed",56197662800;56625855200;55128279200,University College London Hospitals NHS Foundation Trust;The Royal Marsden NHS Foundation Trust;Varian Medical Systems,United Kingdom;United Kingdom;United Kingdom,"the chapter begins with an examination of various different web hosting strategies and platforms, both software and hardware. many types are compared, giving advantages and disadvantages of all. next, methods of programming for the web are described, starting from a description of html, adding in functionality via javascript, c++, and php. this is then expanded to the collection of data. html forms are described, both as hard-coded and generated via c++. further expansion into dynamic content is considered, both generated code and auto-refreshing pages, and examples of database use are given. the last part of the chapter describes security particularly as applied to web applications, through techniques for access limitation (both server and client side). the chapter concludes with an examination of public and private key encryption and digital signatures. © 2014 elsevier ltd all rights reserved.",web development
1737,2-s2.0-84900558751,10.1002/smr.1601,Design and implementation of a dynamic symbolic execution tool for windows executables,Chen T.,Journal of software: Evolution and Process,2013-01-01,"SUMMARY Dynamic symbolic execution, or DSE for short, has become a promising technique in software testing. However, the implementation details of DSE have not been described in depth in existing works. Although some open-source DSE tools are available nowadays, to design and implement a specific DSE tool from scratch is necessary for some reasons. To this end, we implement a Smart Fuzzing Tool for Windows Native Executables, or SMAFE for short, which utilizes Pin and STP for instrumentation and constraint solving, respectively. Advantages of Pin and STP make SMAFE portable. The major contribution of this paper is our detailed description of the implementation of DSE, including symbolization of inputs, tracking of symbols, synchronization of overlapped symbols, environment modeling, and so on. A practical case study validates the effectiveness of SMAFE. Then, the experiments with two benchmark sets present that the code coverage is above 90% on average. Benefits from this paper are at least twofold: moderating learning curve for scholars and shortening the development circle for practitioners. © 2013 John Wiley & Sons, Ltd.",automated test generation | code coverage | dynamic symbolic execution | implementations | software testing,11,1249-1272,Journal,Article,6.0,"Chen, Ting;Zhang, Xiao Song;Zhu, Cong;Ji, Xiao Li;Guo, Shi Ze;Wu, Yue",56159439700;55715736700;56160472900;55504193300;57701845000;56341886900,University of Electronic Science and Technology of China;Institute of North Electronic Equipment,China;China,"summary dynamic symbolic execution, or dse for short, has become a promising technique in software testing. however, the implementation details of dse have not been described in depth in existing works. although some open-source dse tools are available nowadays, to design and implement a specific dse tool from scratch is necessary for some reasons. to this end, we implement a smart fuzzing tool for windows native executables, or smafe for short, which utilizes pin and stp for instrumentation and constraint solving, respectively. advantages of pin and stp make smafe portable. the major contribution of this paper is our detailed description of the implementation of dse, including symbolization of inputs, tracking of symbols, synchronization of overlapped symbols, environment modeling, and so on. a practical case study validates the effectiveness of smafe. then, the experiments with two benchmark sets present that the code coverage is above 90% on average. benefits from this paper are at least twofold: moderating learning curve for scholars and shortening the development circle for practitioners. © 2013 john wiley & sons, ltd.",design and implementation of a dynamic symbolic execution tool for windows executables
1738,2-s2.0-84898937356,10.1145/2534931.2534948,Multiview user interface coordination in browser-based geovisualization environments (demo paper),Savelyev A.,MapInteract 2013 - Proceedings of the 1st ACM SIGSPATIAL International Workshop on MapInteraction,2013-01-01,"Modern-day geovisualization environments are complex systems that support interactive, multi-faceted exploration of spatiotemporal data. Such systems are often composed from a number of visualization tools, each with a pre-determined function of its own, integrated together into a single user interface. Supporting real-time coordination of user interactions across multiple facets (perspectives, views, etc.) of the resulting interface is a fundamental challenge to design of effective geovisualization environments. Past research on coordinated views for geovisualization lead to the development of a number of solutions to this problem, implemented and tested in a range of software products. With the advent of browser-based geovisualization, the issue of user interface coordination became relevant once more due to the differences between semantics of JavaScript, the ""lingua franca"" of browser-based software, and ""traditional"" programming languages. This demo paper presents a novel software approach to multiview user interface coordination in browser-based geovisualization environments. This approach is inspired by the software meta-pattern called ""introspective observer coordination"", is implemented using pure JavaScript and JSON technologies, and is encapsulated in the form of a JavaScript library. As part of the demonstration, additional benefits of the browser-based environments are considered, including user interface coordination across multiple browser windows and multiple computers. Copyright 2013 ACM.",Coordination | Geovisualization | Introspection | JavaScript | Multiview | Visualization | Web graphics,3,54-58,Conference Proceeding,Conference Paper,1.0,"Savelyev, Alexander",57192936911,Pennsylvania State University,United States,"modern-day geovisualization environments are complex systems that support interactive, multi-faceted exploration of spatiotemporal data. such systems are often composed from a number of visualization tools, each with a pre-determined function of its own, integrated together into a single user interface. supporting real-time coordination of user interactions across multiple facets (perspectives, views, etc.) of the resulting interface is a fundamental challenge to design of effective geovisualization environments. past research on coordinated views for geovisualization lead to the development of a number of solutions to this problem, implemented and tested in a range of software products. with the advent of browser-based geovisualization, the issue of user interface coordination became relevant once more due to the differences between semantics of javascript, the ""lingua franca"" of browser-based software, and ""traditional"" programming languages. this demo paper presents a novel software approach to multiview user interface coordination in browser-based geovisualization environments. this approach is inspired by the software meta-pattern called ""introspective observer coordination"", is implemented using pure javascript and json technologies, and is encapsulated in the form of a javascript library. as part of the demonstration, additional benefits of the browser-based environments are considered, including user interface coordination across multiple browser windows and multiple computers. copyright 2013 acm.",multiview user interface coordination in browser-based geovisualization environments (demo paper)
1739,2-s2.0-84896984355,10.1016/j.procs.2013.06.121,Architectural modifiability considerations for designing a multi-device web application platform,Desruelle H.,Procedia Computer Science,2013-01-01,"The mobile web has enabled applications to become available anywhere, anytime and on any device. Numerous emerging web applications have the ability to execute and collaborate across a wide range of web-enabled devices. However, due to the increasing variety of target delivery contexts, the development of such mobile applications has led to a strong need for adaptive software engineering. To address this significant issue, webinos was designed. Webinos is a multi-device distributed platform for ubiquitous web-based applications. In this paper we discuss the architectural modifiability tactics and patterns that were considered for the design of the webinos platform. Moreover, we reflect on the implementation details of realizing such a modifiable architectural design. © 2013 The Authors. Published by Elsevier B.V.",Mobile applications | Modifiability tactics | Software engineering | Ubiquitous web | Webinos,1,895-900,Conference Proceeding,Conference Paper,2.0,"Desruelle, Heiko;Gielen, Frank",42861318800;8846417100,Universiteit Gent,Belgium,"the mobile web has enabled applications to become available anywhere, anytime and on any device. numerous emerging web applications have the ability to execute and collaborate across a wide range of web-enabled devices. however, due to the increasing variety of target delivery contexts, the development of such mobile applications has led to a strong need for adaptive software engineering. to address this significant issue, webinos was designed. webinos is a multi-device distributed platform for ubiquitous web-based applications. in this paper we discuss the architectural modifiability tactics and patterns that were considered for the design of the webinos platform. moreover, we reflect on the implementation details of realizing such a modifiable architectural design. © 2013 the authors. published by elsevier b.v.",architectural modifiability considerations for designing a multi-device web application platform
1743,2-s2.0-84891768124,10.1007/978-3-642-38445-5_177,Metro project design and development of evaluation system,Fang Y.D.,"International Asia Conference on Industrial Engineering and Management Innovation: Core Areas of Industrial Engineering, IEMI 2012 - Proceedings",2013-01-01,"The subway project decision system is based on analysis and design. This paper introduces the key technologies of the system such as distributing component technology, JavaScript Scripting techniques and CSS technology. Then after the above works, it analyzes feature tree of the system and discusses the system architecture of the system; It focuses on the implementation environment of the system from the client, server-side software and hardware and introduces the key page of the system finally. © Springer-Verlag Berlin Heidelberg 2013.",Feature tree | Key technologies | Subway project | System architecture,0,1683-1689,Conference Proceeding,Conference Paper,2.0,"Fang, Ya Dong;Du, Zhong",55834961400;57199156396,Xi'an Technological University,China,"the subway project decision system is based on analysis and design. this paper introduces the key technologies of the system such as distributing component technology, javascript scripting techniques and css technology. then after the above works, it analyzes feature tree of the system and discusses the system architecture of the system; it focuses on the implementation environment of the system from the client, server-side software and hardware and introduces the key page of the system finally. © springer-verlag berlin heidelberg 2013.",metro project design and development of evaluation system
1744,2-s2.0-84891762653,10.4018/jitwe.2013010103,Performance evaluation of a modern web architecture,Lundar J.,International Journal of Information Technology and Web Engineering,2013-01-01,"The past decade has marked a shift in Web development as users have become accustomed to Web applications with dynamic content and enhanced user experience. Different languages and technologies have been utilised to make way for such applications, gradually stretching existing standards and protocols to its limits. The field of Web development has been characterized by a lack of coherent architectural concepts, partly due to the absences of standard protocols that support modern communication styles. As a result of this, systems specifically designed for real-time data delivery have been required and realised with proprietary technol-ogy in the industry, consequently violating established software engineering principles such as modularity, consistency and simplicity. This paper explores how current Web technologies support the requirements of modern Web applications. A prototype application was developed in the last phase to demonstrate the efficacy of combining the WebSocket protocol and API together with the use of JavaScript as exclusive programming language at the client and server. Based on the findings of the research carried out it appears that the use of protocols and standards such as WebSocket, WebSocket API and Server-Sent Events caters for higher network performance, increased flexibility and standards compliance. © 2013, IGI Global.",AJAX | Javascript | Node.js | Performance | Representational state transfer (REST) | Web architectures | WebSocket,2,36-50,Journal,Article,3.0,"Lundar, Johan Andre;Grønli, Tor Morten;Ghinea, Gheorghita",55990877600;26027922400;35616295700,Brunel University London;Norwegian School of Information Technology,United Kingdom;Norway,"the past decade has marked a shift in web development as users have become accustomed to web applications with dynamic content and enhanced user experience. different languages and technologies have been utilised to make way for such applications, gradually stretching existing standards and protocols to its limits. the field of web development has been characterized by a lack of coherent architectural concepts, partly due to the absences of standard protocols that support modern communication styles. as a result of this, systems specifically designed for real-time data delivery have been required and realised with proprietary technol-ogy in the industry, consequently violating established software engineering principles such as modularity, consistency and simplicity. this paper explores how current web technologies support the requirements of modern web applications. a prototype application was developed in the last phase to demonstrate the efficacy of combining the websocket protocol and api together with the use of javascript as exclusive programming language at the client and server. based on the findings of the research carried out it appears that the use of protocols and standards such as websocket, websocket api and server-sent events caters for higher network performance, increased flexibility and standards compliance. © 2013, igi global.",performance evaluation of a modern web architecture
1745,2-s2.0-84891710754,10.1109/ICSM.2013.26,Output-oriented refactoring in PHP-based dynamic web applications,Nguyen H.A.,"IEEE International Conference on Software Maintenance, ICSM",2013-01-01,"Refactoring is crucial in the development process of traditional programs as well as advanced Web applications. In a dynamic Web application, multiple versions of client code in HTML and JavaScript are dynamically generated from server-side code at run time for different usage scenarios. Toward understanding refactoring for dynamic Web code, we conducted an empirical study on several PHP-based Web applications. We found that Web developers perform a new type of refactoring that is specific to PHP-based dynamic Web code and pertain to output client-side code. After such a refactoring, the server-side code is more compact and modular with less amount of embedded and inline client-side HTML/JS code, or produces more standard-conforming client-side code. However, the corresponding output client-side code of the server code before and after the refactoring provides the same external behavior. We call it output-oriented refactoring. Our finding in the study motivates us to build WebDyn, an automatic tool for dynamicalizing refactorings. When performing on a portion of server-side code (which might contain both PHP and embedded/inline HTML/JS code), WebDyn detects the repeated and varied parts in that code portion and produces dynamic PHP code that creates the same client-side code. Our empirical evaluation on several projects showed WebDyn's accuracy in such automated refactorings. © 2013 IEEE.",Dynamic Web | Output-oriented | Refactoring,4,150-159,Conference Proceeding,Conference Paper,4.0,"Nguyen, Hoan Anh;Nguyen, Hung Viet;Nguyen, Tung Thanh;Nguyen, Tien N.",55459278800;57225877698;57212284041;55386311200,Iowa State University,United States,"refactoring is crucial in the development process of traditional programs as well as advanced web applications. in a dynamic web application, multiple versions of client code in html and javascript are dynamically generated from server-side code at run time for different usage scenarios. toward understanding refactoring for dynamic web code, we conducted an empirical study on several php-based web applications. we found that web developers perform a new type of refactoring that is specific to php-based dynamic web code and pertain to output client-side code. after such a refactoring, the server-side code is more compact and modular with less amount of embedded and inline client-side html/js code, or produces more standard-conforming client-side code. however, the corresponding output client-side code of the server code before and after the refactoring provides the same external behavior. we call it output-oriented refactoring. our finding in the study motivates us to build webdyn, an automatic tool for dynamicalizing refactorings. when performing on a portion of server-side code (which might contain both php and embedded/inline html/js code), webdyn detects the repeated and varied parts in that code portion and produces dynamic php code that creates the same client-side code. our empirical evaluation on several projects showed webdyn's accuracy in such automated refactorings. © 2013 ieee.",output-oriented refactoring in php-based dynamic web applications
1746,2-s2.0-84891434648,10.1089/tmj.2012.0020,Challenges of a mobile application for asthma and allergic rhinitis patient enablement - Interface and synchronization,Burnay E.,Telemedicine and e-Health,2013-01-01,"Background: Asthma and allergic rhinitis (ARA) are common inflammatory diseases of the airways. Enhancement of a patient's participation on clinical decisions is related to better results in control of diseases. To control ARA, patients should monitor their symptoms, avoid triggers, and follow their treatment plan. This study described the challenges of developing a mobile application, called m.Carat, that records the main events related to ARA. Materials and Methods: The mobile application m.Carat was developed for Android™ (Google, Mountain View, CA) and iPhone® (Apple, San Jose, CA) smartphones. It was developed using PhoneGap, which allows the development of applications for several mobile operating systems. To generate the user interface, jQuery Mobile, HTML, Javascript, and CSS were used. Despite the use of mobile development frameworks, some input and output elements had to be improved. To evaluate the interface, a pilot study was performed with eight users who performed 10 different tasks in the application. To synchronize m.Carat with an online database, an algorithm was developed from scratch. This feature represents a major challenge because all the changes must be reflected in all devices. Results: Currently m.Carat is a mobile application where ARA patients fill out a questionnaire to assess the degree of control of ARA and record their exacerbations, triggers, symptoms, medications, lung function tests, and visits to the doctor or the hospital. They also can receive information and news about ARA, define medication and tasks notifications, and synchronize all records at caratnetwork.org with an online database. The evaluation showed some of the adopted solutions to improve interface usability did not work as expected. Of the 80 total tasks tested the users had no difficulty in 37(46%). Most of the problems observed were easily solved. Conclusions: m.Carat is a mobile application for ARA that may contribute to patient enablement. The development of m.Carat suggests that mobile applications may introduce specific challenges that need new solutions. © Mary Ann Liebert, Inc.",Allergic rhinitis | Asthma | Control | Management | Mobile application,28,13-18,Journal,Article,5.0,"Burnay, Eduardo;Cruz-Correia, Ricardo;Jacinto, Tiago;Sousa, Ana Sá;Fonseca, João",55561964200;8849507000;36935395700;36627453600;45661083200,Faculdade de Medicina da Universidade do Porto (FMUP);Universidade do Porto,Portugal;Portugal,"background: asthma and allergic rhinitis (ara) are common inflammatory diseases of the airways. enhancement of a patient's participation on clinical decisions is related to better results in control of diseases. to control ara, patients should monitor their symptoms, avoid triggers, and follow their treatment plan. this study described the challenges of developing a mobile application, called m.carat, that records the main events related to ara. materials and methods: the mobile application m.carat was developed for android™ (google, mountain view, ca) and iphone® (apple, san jose, ca) smartphones. it was developed using phonegap, which allows the development of applications for several mobile operating systems. to generate the user interface, jquery mobile, html, javascript, and css were used. despite the use of mobile development frameworks, some input and output elements had to be improved. to evaluate the interface, a pilot study was performed with eight users who performed 10 different tasks in the application. to synchronize m.carat with an online database, an algorithm was developed from scratch. this feature represents a major challenge because all the changes must be reflected in all devices. results: currently m.carat is a mobile application where ara patients fill out a questionnaire to assess the degree of control of ara and record their exacerbations, triggers, symptoms, medications, lung function tests, and visits to the doctor or the hospital. they also can receive information and news about ara, define medication and tasks notifications, and synchronize all records at caratnetwork.org with an online database. the evaluation showed some of the adopted solutions to improve interface usability did not work as expected. of the 80 total tasks tested the users had no difficulty in 37(46%). most of the problems observed were easily solved. conclusions: m.carat is a mobile application for ara that may contribute to patient enablement. the development of m.carat suggests that mobile applications may introduce specific challenges that need new solutions. © mary ann liebert, inc.",challenges of a mobile application for asthma and allergic rhinitis patient enablement - interface and synchronization
1747,2-s2.0-84887707469,10.5220/0004612001560162,SignaLBIT: A web-based platform for real-time biosignal visualization and recording,Alves A.P.,"10th ICETE 2013; SIGMAP 2013 - 10th Int. Conf. on Signal Processing and Multimedia Applications and WINSYS 2013 - 10th Int. Conf. on Wireless Information Networks and Systems, Proc.",2013-01-01,"Biosignals have had an increasingly important role in the research and development of new applications for healthcare, sports, quality of life, and many other fields. Still, researchers are often faced with problems related with the ease-of-use and practicality of software tools for rapid prototyping of applications that involve biosignal acquisition and processing. Typically, there are either highly flexible scientific computing tools or custom developed and application-specific tools, the former being often characterized by long learning curves and limited user interface design capabilities, while the latter is often characterized by poor cross-platform compatibility, and overheads in terms of development time when new features are needed. In this paper we present a versatile, flexible, and extensible software framework for rapid prototyping of end-user applications, specifically targeted at biosignal acquisition and post-processing. We build on the advantages of combining web technologies with the Python programming language, to improve the usability, interaction, cross-platform compatibility, extensibility, and flexibility of biosignal-based applications. Copyright © 2013 SCITEPRESS.",Biosignals | Data acquisition | Data visualization | Web technologies,2,156-162,Conference Proceeding,Conference Paper,4.0,"Alves, Ana Priscila;Da Silva, Hugo Pĺacido;Lourenço, Andŕe;Fred, Ana",55734906700;54783341500;35774428000;6602080284,Instituto Superior de Engenharia de Lisboa;Instituto de Telecomunicacoes,Portugal;Portugal,"biosignals have had an increasingly important role in the research and development of new applications for healthcare, sports, quality of life, and many other fields. still, researchers are often faced with problems related with the ease-of-use and practicality of software tools for rapid prototyping of applications that involve biosignal acquisition and processing. typically, there are either highly flexible scientific computing tools or custom developed and application-specific tools, the former being often characterized by long learning curves and limited user interface design capabilities, while the latter is often characterized by poor cross-platform compatibility, and overheads in terms of development time when new features are needed. in this paper we present a versatile, flexible, and extensible software framework for rapid prototyping of end-user applications, specifically targeted at biosignal acquisition and post-processing. we build on the advantages of combining web technologies with the python programming language, to improve the usability, interaction, cross-platform compatibility, extensibility, and flexibility of biosignal-based applications. copyright © 2013 scitepress.",signalbit: a web-based platform for real-time biosignal visualization and recording
1748,2-s2.0-84886395220,10.1145/2500828.2500830,TAE-JS: Automated enhancement of JavaScript programs by leveraging the java annotations infrastructure,Song M.,ACM International Conference Proceeding Series,2013-01-01,"Recent state-of-the-art approaches enhance JavaScript programs with concerns (e.g., persistence, security, transactions, etc.) by modifying the source code by hand to use special libraries. As a result, adding concerns to a JavaScript program creates divergent codebases that must be maintained separately. At the core of the problem is that JavaScript lacks metadata to express concerns declaratively. In this paper, we present a declarative approach to enhancing JavaScript programs that applies the Java annotations infrastructure to JavaScript, without extending the JavaScript language. An IDE combines JavaScript and Java during the development, but processes the languages separately. Programmers declare how concerns should be added to a JavaScript program using Java annotations. Based on the annotations, a code generator synthesizes aspect code that adds the specified concerns. Although these enhancements are implemented as third-party libraries, our approach can transparently insert them into JavaScript programs given a declarative specification. Copyright © 2013 ACM.",Concerns | Enhancement | Metadata | Persistence | Security | Transactions,1,13-24,Conference Proceeding,Conference Paper,2.0,"Song, Myoungkyu;Tilevich, Eli",32868182400;6507251807,Virginia Polytechnic Institute and State University,United States,"recent state-of-the-art approaches enhance javascript programs with concerns (e.g., persistence, security, transactions, etc.) by modifying the source code by hand to use special libraries. as a result, adding concerns to a javascript program creates divergent codebases that must be maintained separately. at the core of the problem is that javascript lacks metadata to express concerns declaratively. in this paper, we present a declarative approach to enhancing javascript programs that applies the java annotations infrastructure to javascript, without extending the javascript language. an ide combines javascript and java during the development, but processes the languages separately. programmers declare how concerns should be added to a javascript program using java annotations. based on the annotations, a code generator synthesizes aspect code that adds the specified concerns. although these enhancements are implemented as third-party libraries, our approach can transparently insert them into javascript programs given a declarative specification. copyright © 2013 acm.",tae-js: automated enhancement of javascript programs by leveraging the java annotations infrastructure
1749,2-s2.0-84885148323,10.1016/j.compag.2013.09.004,A web solution for Partially Balanced Incomplete Block experimental designs,Sharma A.,Computers and Electronics in Agriculture,2013-01-01,"Heterogeneity in the experimental material is an important problem to deal with the designing of scientific experiments. Block designs are useful in controlling heterogeneity arising due to one source. A Randomized Complete Block (RCB) design is the simplest and commonly used block design. When the number of treatments in an experiment increases, incomplete block designs with smaller block sizes can be adopted. Balanced Incomplete Block (BIB) and Partially Balanced Incomplete Block (PBIB) designs are two important types of such designs. PBIB designs are extremely wide spread in literature. For ready referencing and potential use of these designs, online software for generation and analysis of these designs is highly desirable. This paper describes the development of a complete web solution for generation and analysis of PBIB designs using client-server architecture. An e-learning material on these designs is also prepared that can be used as reference material by researchers and students working in this area. WS-PBIBD is accessible any time from arbitrary platforms through internet. This software would help researchers in planning, designing and analyzing their experiments through web. © 2013.",Analysis | E-Learning | Generation of designs | Partially Balanced Incomplete Block designs | Randomization | Software,5,132-134,Journal,Article,3.0,"Sharma, Anu;Varghese, Cini;Jaggi, Seema",57214355813;35583756200;7004561214,"ICAR - Indian Agricultural Statistics Research Institute, New Delhi",India,"heterogeneity in the experimental material is an important problem to deal with the designing of scientific experiments. block designs are useful in controlling heterogeneity arising due to one source. a randomized complete block (rcb) design is the simplest and commonly used block design. when the number of treatments in an experiment increases, incomplete block designs with smaller block sizes can be adopted. balanced incomplete block (bib) and partially balanced incomplete block (pbib) designs are two important types of such designs. pbib designs are extremely wide spread in literature. for ready referencing and potential use of these designs, online software for generation and analysis of these designs is highly desirable. this paper describes the development of a complete web solution for generation and analysis of pbib designs using client-server architecture. an e-learning material on these designs is also prepared that can be used as reference material by researchers and students working in this area. ws-pbibd is accessible any time from arbitrary platforms through internet. this software would help researchers in planning, designing and analyzing their experiments through web. © 2013.",a web solution for partially balanced incomplete block experimental designs
1751,2-s2.0-84878307894,10.1504/IJCNDS.2013.053077,Towards pervasive mashups in embedded devices: Comparing procedural and declarative approach,Salminen A.,International Journal of Communication Networks and Distributed Systems,2013-01-01,"The web has become pervasive. This has led to a paradigm shift, where applications live on the web as services, where they can be accessed with different types of terminals. The ability to dynamically combine content from numerous sources, and the ability to instantly publish services worldwide has opened up entirely new possibilities for software development. Such applications that aggregate content from the web are commonly referred to as mashups. Unfortunately, for various reasons, the browser is inadequate for hosting complex mashups, in particular when considering embedded devices and subsystems that are not readily available in the web. In this paper, we introduce two environments, intended for hosting context-aware mashups on embedded devices. These environments have different approaches as one can be used to compose mashups in procedural and another in declarative fashion. As an example, we describe a location-aware mashup composed for both environments. © 2013 Inderscience Enterprises Ltd.",Context-aware mashups | Declarative approach | Device peripherals | Embedded devices | Location-aware | Mashup | Mobile runtime | Pervasive web | Procedural approach | Runtime environment | Web applications,1,195-215,Journal,Article,2.0,"Salminen, Arto;Mikkonen, Tommi",36630946500;54420813700,Tampere University,Finland,"the web has become pervasive. this has led to a paradigm shift, where applications live on the web as services, where they can be accessed with different types of terminals. the ability to dynamically combine content from numerous sources, and the ability to instantly publish services worldwide has opened up entirely new possibilities for software development. such applications that aggregate content from the web are commonly referred to as mashups. unfortunately, for various reasons, the browser is inadequate for hosting complex mashups, in particular when considering embedded devices and subsystems that are not readily available in the web. in this paper, we introduce two environments, intended for hosting context-aware mashups on embedded devices. these environments have different approaches as one can be used to compose mashups in procedural and another in declarative fashion. as an example, we describe a location-aware mashup composed for both environments. © 2013 inderscience enterprises ltd.",towards pervasive mashups in embedded devices: comparing procedural and declarative approach
1752,2-s2.0-84877891131,10.4018/jaci.2013010103,"Developing client-side mashups: Experiences, guidelines and reference architecture",Salminen A.,International Journal of Ambient Computing and Intelligence,2013-01-01,"Software mashups that combine content from multiple web sites to an integrated experience are a popular trend. However, methods, tools and architectures for creating mashups are still rather undeveloped, and there is little engineering support behind them. In this paper the authors present guidelines that can serve as a helpful starting point for the design of new mashups. Guidelines focus mainly on mashup creation methods. Furthermore, they describe a reference architecture for client-side mashup development. In addition, the authors provide insight into mashup development based on their practical experiences in implementing various sample client-side mashup applications and tools for creating them. The long term goal of the authors' work is to facilitate the development of compelling, robust and maintainable mashup applications, and more generally ease the transition towards web-based software development. Copyright © 2013, IGI Global.",Mashup development | Mashups | Web applications | Web engineering | Web-based software development,0,34-52,Journal,Article,4.0,"Salminen, Arto;Mikkonen, Tommi;Nyrhinen, Feetu;Taivalsaari, Antero",36630946500;54420813700;35318451700;6507045147,ATB - Institut für angewandte Systemtechnik Bremen GmbH;Nokia Corporation;Tampere University,Germany;Finland;Finland,"software mashups that combine content from multiple web sites to an integrated experience are a popular trend. however, methods, tools and architectures for creating mashups are still rather undeveloped, and there is little engineering support behind them. in this paper the authors present guidelines that can serve as a helpful starting point for the design of new mashups. guidelines focus mainly on mashup creation methods. furthermore, they describe a reference architecture for client-side mashup development. in addition, the authors provide insight into mashup development based on their practical experiences in implementing various sample client-side mashup applications and tools for creating them. the long term goal of the authors' work is to facilitate the development of compelling, robust and maintainable mashup applications, and more generally ease the transition towards web-based software development. copyright © 2013, igi global.","developing client-side mashups: experiences, guidelines and reference architecture"
1753,2-s2.0-84874083219,10.1007/s12518-011-0070-0,ZOO-Project: The open WPS platform,Fenoy G.,Applied Geomatics,2013-01-01,"This paper aims to present the ZOO-Project, which is a new open source implementation of the Open Geospatial Consortium's (OGC) Web Processing Service (WPS), released under the term of the MIT/X-11 license. Based on a server-side C language Kernel (named ZOO-Kernel), ZOO-Project proposes a new approach to develop, handle and chain standardized GIS-based Web services. A brief review of WPS and existing implementations will be given in order to detail the ZOO-Project development background and goals. Then, the ZOO itself will be presented, focusing on its advantages and limitations, foremost to highlight the new opportunities provided by such a platform. The ZOO-Kernel and its architecture will be first examined, before further explanations on the proposed method for Web services creation are given. Then the ZOO JavaScript API that provides a new way to orchestrate and chain Web services through the server-side JavaScript will be presented next. Both Kernel and API are illustrated and documented through different Web service code snippets that are available online. Some visual examples of client-side interactions are presented. © 2012 Società Italiana di Fotogrammetria e Topografia (SIFET).",Open geospatial consortium | Open source geospatial foundation | Web processing service | ZOO-Project,20,19-24,Journal,Article,3.0,"Fenoy, Gérald;Bozon, Nicolas;Raghavan, Venkatesh",55229308400;36157615000;7103398103,Osaka Metropolitan University,Japan,"this paper aims to present the zoo-project, which is a new open source implementation of the open geospatial consortium's (ogc) web processing service (wps), released under the term of the mit/x-11 license. based on a server-side c language kernel (named zoo-kernel), zoo-project proposes a new approach to develop, handle and chain standardized gis-based web services. a brief review of wps and existing implementations will be given in order to detail the zoo-project development background and goals. then, the zoo itself will be presented, focusing on its advantages and limitations, foremost to highlight the new opportunities provided by such a platform. the zoo-kernel and its architecture will be first examined, before further explanations on the proposed method for web services creation are given. then the zoo javascript api that provides a new way to orchestrate and chain web services through the server-side javascript will be presented next. both kernel and api are illustrated and documented through different web service code snippets that are available online. some visual examples of client-side interactions are presented. © 2012 società italiana di fotogrammetria e topografia (sifet).",zoo-project: the open wps platform
1754,2-s2.0-84870168695,10.1016/j.cageo.2012.10.011,Development of a web GIS application for emissions inventory spatial allocation based on open source software tools,Gkatzoflias D.,Computers and Geosciences,2013-01-01,"Combining emission inventory methods and geographic information systems (GIS) remains a key issue for environmental modelling and management purposes. This paper examines the development of a web GIS application as part of an emission inventory system that produces maps and files with spatial allocated emissions in a grid format. The study is not confined in the maps produced but also presents the features and capabilities of a web application that can be used by every user even without any prior knowledge of the GIS field. The development of the application was based on open source software tools such as MapServer for the GIS functions, PostgreSQL and PostGIS for the data management and HTML, PHP and JavaScript as programming languages. In addition, background processes are used in an innovative manner to handle the time consuming and computational costly procedures of the application. Furthermore, a web map service was created to provide maps to other clients such as the Google Maps API v3 that is used as part of the user interface. The output of the application includes maps in vector and raster format, maps with temporal resolution on daily and hourly basis, grid files that can be used by air quality management systems and grid files consistent with the European Monitoring and Evaluation Programme Grid. Although the system was developed and validated for the Republic of Cyprus covering a remarkable wide range of pollutant and emissions sources, it can be easily customized for use in other countries or smaller areas, as long as geospatial and activity data are available. © 2012 Elsevier Ltd.",Background processes | Emissions inventory | Geographical information systems | Open source software tools | Spatial allocation | Web map service,44,21-33,Journal,Article,3.0,"Gkatzoflias, Dimitrios;Mellios, Giorgos;Samaras, Zissis",36188406400;15019724100;7005011759,Aristotle University of Thessaloniki;Emisia S.A.,Greece;Greece,"combining emission inventory methods and geographic information systems (gis) remains a key issue for environmental modelling and management purposes. this paper examines the development of a web gis application as part of an emission inventory system that produces maps and files with spatial allocated emissions in a grid format. the study is not confined in the maps produced but also presents the features and capabilities of a web application that can be used by every user even without any prior knowledge of the gis field. the development of the application was based on open source software tools such as mapserver for the gis functions, postgresql and postgis for the data management and html, php and javascript as programming languages. in addition, background processes are used in an innovative manner to handle the time consuming and computational costly procedures of the application. furthermore, a web map service was created to provide maps to other clients such as the google maps api v3 that is used as part of the user interface. the output of the application includes maps in vector and raster format, maps with temporal resolution on daily and hourly basis, grid files that can be used by air quality management systems and grid files consistent with the european monitoring and evaluation programme grid. although the system was developed and validated for the republic of cyprus covering a remarkable wide range of pollutant and emissions sources, it can be easily customized for use in other countries or smaller areas, as long as geospatial and activity data are available. © 2012 elsevier ltd.",development of a web gis application for emissions inventory spatial allocation based on open source software tools
1756,2-s2.0-84871413303,10.1007/978-3-642-33466-5_15,Puzzle-it: An HTML5 serious games platform for education - Puzzle based serious games for education,Pranantha D.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2012-12-27,"Serious games as learning medium have advanced in the past few years. They have been applied to support learning in various fields such as security, health-care, and education. Serious games can scale from low budget games up to high budget games depends on the games' objectives and features. For instance, military may utilize games with 3D simulation, live characters, and extensive scenario for combat training due to its critical mission. Nonetheless, in a classroom or remote set-up learning environment, most of these high level games are impractical to be adopted due to the amount of costs they may induce. This is most of the case in educational games which main objective is to motivate the student to learn. However, a game development remains as a time consuming, complex, and laborious process. In order to simplify and shorten this process, it is highly attractive to create a platform to produce educational games. Therefore, this paper, based on our previous work, proposes a platform for authoring HTML5 serious games intended in particular, but not limited to create lightweight serious games for educational purpose using the upcoming HTML5 standard playable in common web browsers. This platform, puzzle-it, divides the work of game development into two distinct layers i.e. contents authoring and core engine development. Both readily and work in progress components of the platform are presented and discussed. © 2012 Springer-Verlag.",game content authoring | game development | game engine | HTML5 | JavaScript | puzzle game | serious games | social networks,4,134-143,Book Series,Conference Paper,4.0,"Pranantha, Danu;Bellotti, Francesco;Berta, Ricardo;De Gloria, Alessandro",16679568500;55890888700;6701751695;7004620974,Università degli Studi di Genova,Italy,"serious games as learning medium have advanced in the past few years. they have been applied to support learning in various fields such as security, health-care, and education. serious games can scale from low budget games up to high budget games depends on the games' objectives and features. for instance, military may utilize games with 3d simulation, live characters, and extensive scenario for combat training due to its critical mission. nonetheless, in a classroom or remote set-up learning environment, most of these high level games are impractical to be adopted due to the amount of costs they may induce. this is most of the case in educational games which main objective is to motivate the student to learn. however, a game development remains as a time consuming, complex, and laborious process. in order to simplify and shorten this process, it is highly attractive to create a platform to produce educational games. therefore, this paper, based on our previous work, proposes a platform for authoring html5 serious games intended in particular, but not limited to create lightweight serious games for educational purpose using the upcoming html5 standard playable in common web browsers. this platform, puzzle-it, divides the work of game development into two distinct layers i.e. contents authoring and core engine development. both readily and work in progress components of the platform are presented and discussed. © 2012 springer-verlag.",puzzle-it: an html5 serious games platform for education - puzzle based serious games for education
1757,2-s2.0-84871386548,10.1007/978-3-642-35362-8_35,Secure middleware patterns,Fernandez E.B.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2012-12-26,"Middleware typically includes a set of functions that provide services to distributed applications. To design middleware architectures, developers often employ architectural patterns - solutions to recurring software problems. In general these patterns do not contain any security features, however, it is possible to make secured versions of them using experience or by considering security threats and countermeasures in real-life implementations. Using this inductive approach we have built up a catalog of such (compound security) patterns for middleware. They can be used by developers early in the software development life-cycle to efficiently determine a set of relevant security requirements. In this paper we continue the same line of work to secure the Wrapper Façade and Distributed Publish/Subscribe patterns, extending the inductive approach from before with a deductive approach based on a use-case driven threat analysis. We document the resulting Secure Façade compound pattern briefly, and the Secure Publish/Subscribe in more detail. © 2012 Springer-Verlag.",distributed systems security | middleware | publish/subscribe | security patterns | software security,8,470-482,Book Series,Conference Paper,2.0,"Fernandez, Eduardo B.;Uzunov, Anton V.",7402178980;55213100000,Florida Atlantic University;The University of Adelaide,United States;Australia,"middleware typically includes a set of functions that provide services to distributed applications. to design middleware architectures, developers often employ architectural patterns - solutions to recurring software problems. in general these patterns do not contain any security features, however, it is possible to make secured versions of them using experience or by considering security threats and countermeasures in real-life implementations. using this inductive approach we have built up a catalog of such (compound security) patterns for middleware. they can be used by developers early in the software development life-cycle to efficiently determine a set of relevant security requirements. in this paper we continue the same line of work to secure the wrapper façade and distributed publish/subscribe patterns, extending the inductive approach from before with a deductive approach based on a use-case driven threat analysis. we document the resulting secure façade compound pattern briefly, and the secure publish/subscribe in more detail. © 2012 springer-verlag.",secure middleware patterns
1758,2-s2.0-84870689823,10.1109/WICSA-ECSA.212.32,Design principles for effective knowledge discovery from big data,Begoli E.,"Proceedings of the 2012 Joint Working Conference on Software Architecture and 6th European Conference on Software Architecture, WICSA/ECSA 2012",2012-12-12,"Big data phenomenon refers to the practice of collection and processing of very large data sets and associated systems and algorithms used to analyze these massive datasets. Architectures for big data usually range across multiple machines and clusters, and they commonly consist of multiple special purpose sub-systems. Coupled with the knowledge discovery process, big data movement offers many unique opportunities for organizations to benefit (with respect to new insights, business optimizations, etc.). However, due to the difficulty of analyzing such large datasets, big data presents unique systems engineering and architectural challenges. In this paper, we present three system design principles that can inform organizations on effective analytic and data collection processes, system organization, and data dissemination practices. The principles presented derive from our own research and development experiences with big data problems from various federal agencies, and we illustrate each principle with our own experiences and recommendations. © 2012 IEEE.",architecture | Big Data | design principles,90,215-218,Conference Proceeding,Conference Paper,2.0,"Begoli, Edmon;Horey, James",55369551500;18037032900,Oak Ridge National Laboratory,United States,"big data phenomenon refers to the practice of collection and processing of very large data sets and associated systems and algorithms used to analyze these massive datasets. architectures for big data usually range across multiple machines and clusters, and they commonly consist of multiple special purpose sub-systems. coupled with the knowledge discovery process, big data movement offers many unique opportunities for organizations to benefit (with respect to new insights, business optimizations, etc.). however, due to the difficulty of analyzing such large datasets, big data presents unique systems engineering and architectural challenges. in this paper, we present three system design principles that can inform organizations on effective analytic and data collection processes, system organization, and data dissemination practices. the principles presented derive from our own research and development experiences with big data problems from various federal agencies, and we illustrate each principle with our own experiences and recommendations. © 2012 ieee.",design principles for effective knowledge discovery from big data
1759,2-s2.0-84870450081,10.1109/HPCC.2012.257,Local resource accessing mechanism on multiple mobile platform,Shi W.,"Proceedings of the 14th IEEE International Conference on High Performance Computing and Communications, HPCC-2012 - 9th IEEE International Conference on Embedded Software and Systems, ICESS-2012",2012-12-07,"In recent years, with the advent of mobile Internet, Mobile Widget as an important element has been rapid development. It has become the mobile Internet hotspot. Mobile Widget to integrate Internet and local resources, available standard, HTML5, CSS (Cascading Style Sheets), and JavaScript Mobile Widget is the trend of technology development. But because of the different Mobile Widget platform used different standards, is not fully compatible with each other, so cross-platform development of mobile widget is still challenge, and one of the most difficult problems is implementation of cross-platform API. It makes Widget application for third party providers need to make a variety of different Widget for a business application to adapt to a different Widget platform. In order to solve this problem, this article proposes a cross-platform implementation scheme of local resource access Mobile Widget, experimental success and on different platforms. © 2012 IEEE.",Cross-Platform | HTML5 | JavaScript | Mobile Widget,2,1716-1721,Conference Proceeding,Conference Paper,7.0,"Shi, Wei;Wu, Minghui;Wang, Shuoping;Guo, Min;Peng, Bin;Ouyang, Bin;Chen, Tianzhou",57198923235;8301222100;35202103300;55509378400;54977274700;55509144700;35228719100,"College of Computer Science and Technology, Zhejiang University;Zhejiang University City College",China;China,"in recent years, with the advent of mobile internet, mobile widget as an important element has been rapid development. it has become the mobile internet hotspot. mobile widget to integrate internet and local resources, available standard, html5, css (cascading style sheets), and javascript mobile widget is the trend of technology development. but because of the different mobile widget platform used different standards, is not fully compatible with each other, so cross-platform development of mobile widget is still challenge, and one of the most difficult problems is implementation of cross-platform api. it makes widget application for third party providers need to make a variety of different widget for a business application to adapt to a different widget platform. in order to solve this problem, this article proposes a cross-platform implementation scheme of local resource access mobile widget, experimental success and on different platforms. © 2012 ieee.",local resource accessing mechanism on multiple mobile platform
1765,2-s2.0-84876577174,10.2316/P.2012.790-020,Verification of web applications with a model checker,Ammann C.,"Proceedings of the IASTED International Conference on Software Engineering and Applications, SEA 2012",2012-12-01,"Web applications are hosted on a web server and executed within a browser environment. They are widely used and typically developed with HTML and Javascript. They often interact with web servers which makes stability and security important aspects in the development process. One way to increase both aspects is the usage of a model checker which can verify whether a software model contains errors and does not meet its requirements. The integration of formal verification in a web application software project is challenging because expert knowledge is necessary. This paper solves this problem with the usage of model-driven development and presents a domain-specific web application modelling language. Furthermore, an algorithm for an automated transformation into the model checker input language Promela is provided. Promela is used by the Spin model checker which tests automatically whether the corresponding web application model meets the given specification, informs the developer about possible errors and therefore increases software stability and security.",Domain-specific languages | Formal methods | Model checking | Modelling languages | Web applications,0,426-433,Conference Proceeding,Conference Paper,1.0,"Ammann, Christian",55211585300,Fachhochschule Osnabrück,Germany,"web applications are hosted on a web server and executed within a browser environment. they are widely used and typically developed with html and javascript. they often interact with web servers which makes stability and security important aspects in the development process. one way to increase both aspects is the usage of a model checker which can verify whether a software model contains errors and does not meet its requirements. the integration of formal verification in a web application software project is challenging because expert knowledge is necessary. this paper solves this problem with the usage of model-driven development and presents a domain-specific web application modelling language. furthermore, an algorithm for an automated transformation into the model checker input language promela is provided. promela is used by the spin model checker which tests automatically whether the corresponding web application model meets the given specification, informs the developer about possible errors and therefore increases software stability and security.",verification of web applications with a model checker
1768,2-s2.0-84872308180,10.1109/WCRE.2012.41,Automated acceptance testing of JavaScript web applications,Negara N.,"Proceedings - Working Conference on Reverse Engineering, WCRE",2012-12-01,"Acceptance testing is an important part of software development and it is performed to ensure that a system delivers its required functionalities. Today, most modern interactive web applications are designed using Web 2.0 technologies, many among them relying on JavaScript. JavaScript enables the development of client-side functionality through the dynamic modification of the web-page's content and structure without calls to the server. This implies that server-side testing frameworks will necessarily fail to test the complete application behaviors. In this paper we present a method for automated acceptance testing of JavaScript web applications to ensure that required functionalities have been implemented. Using an intuitive, human-readable scripting language our method allows users to describe user stories in high level declarative test scripts and to then execute these test scripts on a web application using an automated website crawler. We also describe a case study that evaluates our approach in terms of capabilities to translate user stories in automated acceptance test scripts. © 2012 IEEE.",Acceptance testing | Ajax | Automated Testing | Crawling | JavaScript | User Story | Web testing,1,318-322,Conference Proceeding,Conference Paper,2.0,"Negara, Natalia;Stroulia, Eleni",55405074100;6603883706,University of Alberta,Canada,"acceptance testing is an important part of software development and it is performed to ensure that a system delivers its required functionalities. today, most modern interactive web applications are designed using web 2.0 technologies, many among them relying on javascript. javascript enables the development of client-side functionality through the dynamic modification of the web-page's content and structure without calls to the server. this implies that server-side testing frameworks will necessarily fail to test the complete application behaviors. in this paper we present a method for automated acceptance testing of javascript web applications to ensure that required functionalities have been implemented. using an intuitive, human-readable scripting language our method allows users to describe user stories in high level declarative test scripts and to then execute these test scripts on a web application using an automated website crawler. we also describe a case study that evaluates our approach in terms of capabilities to translate user stories in automated acceptance test scripts. © 2012 ieee.",automated acceptance testing of javascript web applications
1769,2-s2.0-84872074655,10.1109/JSTARS.2012.2187433,"Automated geoprocessing mechanism, processes and workflow for seamless online integration of geodata services and creating geoprocessing services",Shi S.,IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,2012-12-01,"This paper presents an automated mechanism, processes and workflow for the seamless integration of distributed geographical information services for the creation of an automated data processing service, known as a geoprocessing service. It describes generic principles for designing and developing real-time geoprocessing services and covers key aspects of seamless service integration and design for an automated geoprocessing service. These include brief descriptions of a 'total object-oriented' approach, unified national adoption of the Open GIS Consortium's operational framework and specifications, implementation of standardised coding systems for geo-referenced data, design for service application interfaces, geodata fusion of assured integrity and quality and automation of data processing for service delivery. Automation is achieved by programmatically utilising modular software resources in compliance with the Component Object Model. This paper draws on a proven approach of relevance to specialists working in similar areas related to the design and development of Internet-based geoinformation service systems. © 2008-2012 IEEE.",Automation | coding system | geographical information | geoprocessing | integration | Internet service | OGC | service application interface,5,1659-1664,Journal,Article,2.0,"Shi, Shaozhong;Walford, Nigel",7402200418;7003391757,Kingston University,United Kingdom,"this paper presents an automated mechanism, processes and workflow for the seamless integration of distributed geographical information services for the creation of an automated data processing service, known as a geoprocessing service. it describes generic principles for designing and developing real-time geoprocessing services and covers key aspects of seamless service integration and design for an automated geoprocessing service. these include brief descriptions of a 'total object-oriented' approach, unified national adoption of the open gis consortium's operational framework and specifications, implementation of standardised coding systems for geo-referenced data, design for service application interfaces, geodata fusion of assured integrity and quality and automation of data processing for service delivery. automation is achieved by programmatically utilising modular software resources in compliance with the component object model. this paper draws on a proven approach of relevance to specialists working in similar areas related to the design and development of internet-based geoinformation service systems. © 2008-2012 ieee.","automated geoprocessing mechanism, processes and workflow for seamless online integration of geodata services and creating geoprocessing services"
1770,2-s2.0-84871673381,10.3390/s121217504,The exploitation of data from remote and human sensors for environment monitoring in the SMAT project,Meo R.,Sensors (Switzerland),2012-12-01,"In this paper, we outline the functionalities of a system that integrates and controls a fleet of Unmanned Aircraft Vehicles (UAVs). UAVs have a set of payload sensors employed for territorial surveillance, whose outputs are stored in the system and analysed by the data exploitation functions at different levels. In particular, we detail the second level data exploitation function whose aim is to improve the sensors data interpretation in the post-mission activities. It is concerned with the mosaicking of the aerial images and the cartography enrichment by human sensors-the social media users. We also describe the software architecture for the development of a mash-up (the integration of information and functionalities coming from the Web) and the possibility of using human sensors in the monitoring of the territory, a field in which, traditionally, the involved sensors were only the hardware ones. © 2012 by the authors; licensee MDPI, Basel, Switzerland.",Cartography | Metadata | Mosaicking | Orthoframes | Volunteered geographic information,13,17504-17535,Journal,Article,3.0,"Meo, Rosa;Roglia, Elena;Bottino, Andrea",7005599926;50761507300;36741888200,European Commission Joint Research Centre;Università degli Studi di Torino;Politecnico di Torino,Belgium;Italy;Italy,"in this paper, we outline the functionalities of a system that integrates and controls a fleet of unmanned aircraft vehicles (uavs). uavs have a set of payload sensors employed for territorial surveillance, whose outputs are stored in the system and analysed by the data exploitation functions at different levels. in particular, we detail the second level data exploitation function whose aim is to improve the sensors data interpretation in the post-mission activities. it is concerned with the mosaicking of the aerial images and the cartography enrichment by human sensors-the social media users. we also describe the software architecture for the development of a mash-up (the integration of information and functionalities coming from the web) and the possibility of using human sensors in the monitoring of the territory, a field in which, traditionally, the involved sensors were only the hardware ones. © 2012 by the authors; licensee mdpi, basel, switzerland.",the exploitation of data from remote and human sensors for environment monitoring in the smat project
1771,2-s2.0-84871652171,10.2174/1875036201206010055,Primer1: Primer design web service for tetra-primer ARMS-PCR,Collins A.,Open Bioinformatics Journal,2012-12-01,"Tetra-primer ARMS-PCR is used extensively as a low cost, single PCR assay requiring no post-PCR manipulation. The design of successful primers depends on a number of variables such as melting temperatures, GC content, complementarity and selection of mismatch bases. The optimal selection of primers can be achieved in an automated way using a program which evaluates candidate primers for a given sequence. The Primer1 software was developed originally for use in the context of restriction fragment length polymorphism analysis using gel electrophoresis. However, recent applications have been more diverse, reviewed here, and we present an overview of the Primer1 software for primer design and web-service. We have updated the Primer1 program, and provide more complete details of the implementation. We also provide test data and output. The program is now available on a new, efficient, LAMP web service for users at: http://primer1.soton.ac.uk/primer1.html. © Collins and Ke; Licensee Bentham Open.",Javascript | Mismatch base | Primer design | Single nucleotide polymorphism | Tetra-primer ARMS-PCR | Web service,72,55-58,Journal,Article,2.0,"Collins, Andrew;Ke, Xiayi",56820336900;23018467700,"University of Southampton, Faculty of Medicine;Medical Research Council",United Kingdom;United Kingdom,"tetra-primer arms-pcr is used extensively as a low cost, single pcr assay requiring no post-pcr manipulation. the design of successful primers depends on a number of variables such as melting temperatures, gc content, complementarity and selection of mismatch bases. the optimal selection of primers can be achieved in an automated way using a program which evaluates candidate primers for a given sequence. the primer1 software was developed originally for use in the context of restriction fragment length polymorphism analysis using gel electrophoresis. however, recent applications have been more diverse, reviewed here, and we present an overview of the primer1 software for primer design and web-service. we have updated the primer1 program, and provide more complete details of the implementation. we also provide test data and output. the program is now available on a new, efficient, lamp web service for users at: http://primer1.soton.ac.uk/primer1.html. © collins and ke; licensee bentham open.",primer1: primer design web service for tetra-primer arms-pcr
1773,2-s2.0-84869752528,10.1145/2384592.2384613,Realising software development as a lived experience,Beynon M.,"SPLASH 2012: Onward! 2012 - Proceedings of the ACM International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software",2012-11-27,"This essay discusses software development from the perspective of Empirical Modelling (EM) [4], an approach to computing that draws on the construals of David Gooding [52], Bruno Latour's vexing notion of construction [70] and William James's radical empiricism [63]. It argues that effective software development must embrace semantic principles radically different from those endorsed by the traditional perspective on software that is based on computational thinking. Of paramount importance is the immediacy of the developer's experience of the relationship between software as an artefact on the computer and software as an agency in the world.",Agency; radical empiricism; hermeneutic | Dependency | Formalist; object thinking | Software development; experience; intuition; Empirical Modelling; construal; observation,0,229-244,Conference Proceeding,Conference Paper,1.0,"Beynon, Meurig",7003976023,University of Warwick,United Kingdom,"this essay discusses software development from the perspective of empirical modelling (em) [4], an approach to computing that draws on the construals of david gooding [52], bruno latour's vexing notion of construction [70] and william james's radical empiricism [63]. it argues that effective software development must embrace semantic principles radically different from those endorsed by the traditional perspective on software that is based on computational thinking. of paramount importance is the immediacy of the developer's experience of the relationship between software as an artefact on the computer and software as an agency in the world.",realising software development as a lived experience
1774,2-s2.0-84869195659,10.1145/2380552.2380613,Three years of design-based research to reform a software engineering curriculum,Luukkainen M.,SIGITE'12 - Proceedings of the ACM Special Interest Group for Information Technology Education Conference,2012-11-22,"Most of the research-oriented computer science departments provide software engineering education. Providing up-to- date software engineering education can be problematic, as practises used in modern software development companies have been developed in the industry and as such do not often reach teachers in university contexts. The danger, and often the unfortunate reality, is that institutions giving education in software engineering end up teaching the subject using outdated practices with technologies no longer in use. In this article we describe a three-year design-based research where the goal has been to design and reform a software engineering subtrack within our bachelor curriculum that would make it possible for the students to have strong up-to- date theoretical and practical skills in software engineering without a need to remove any of the existing theoretical aspects. Copyright 2012 ACM.",Computer science curriculum | Instructional design | Modern software engineering practises,11,209-214,Conference Proceeding,Conference Paper,3.0,"Luukkainen, Matti;Vihavainen, Arto;Vikberg, Thomas",8944855100;25825842400;37082094700,Helsingin Yliopisto,Finland,"most of the research-oriented computer science departments provide software engineering education. providing up-to- date software engineering education can be problematic, as practises used in modern software development companies have been developed in the industry and as such do not often reach teachers in university contexts. the danger, and often the unfortunate reality, is that institutions giving education in software engineering end up teaching the subject using outdated practices with technologies no longer in use. in this article we describe a three-year design-based research where the goal has been to design and reform a software engineering subtrack within our bachelor curriculum that would make it possible for the students to have strong up-to- date theoretical and practical skills in software engineering without a need to remove any of the existing theoretical aspects. copyright 2012 acm.",three years of design-based research to reform a software engineering curriculum
1775,2-s2.0-84867096959,10.1002/spe.1141,Heedless programming: Ignoring detectable error is a widespread hazard,Thimbleby H.,Software - Practice and Experience,2012-11-01,"Software should be correct and robust. This paper suggests that we need forthright words for the failure of not being robusta-heedless and heedlessnessa-and of recursively creating software (such as a compiler or virtual machine) that itself does not support dependable software development. Heedless programming is common, particularly affecting 'trivial' operations such as on numbers, and extends deep into programming language design and into the use of computers more widely, thus making robust, dependable applications of all sorts unnecessarily problematic. The paper defines the problem and presents a call to action to start addressing the problems identified. © 2012 John Wiley & Sons, Ltd.",dependability | design tradeoffs | Excel | FORTRAN | heedless programming | human error | Java | JavaScript | Mathematica,6,1393-1407,Journal,Article,1.0,"Thimbleby, Harold",7005826808,Swansea University,United Kingdom,"software should be correct and robust. this paper suggests that we need forthright words for the failure of not being robusta-heedless and heedlessnessa-and of recursively creating software (such as a compiler or virtual machine) that itself does not support dependable software development. heedless programming is common, particularly affecting 'trivial' operations such as on numbers, and extends deep into programming language design and into the use of computers more widely, thus making robust, dependable applications of all sorts unnecessarily problematic. the paper defines the problem and presents a call to action to start addressing the problems identified. © 2012 john wiley & sons, ltd.",heedless programming: ignoring detectable error is a widespread hazard
1777,2-s2.0-84866914872,10.1109/WETICE.2012.14,Collaborative requirements elicitation with visualization techniques,Duarte D.,"Proceedings of the Workshop on Enabling Technologies: Infrastructure for Collaborative Enterprises, WETICE",2012-10-05,"Requirements elicitation is one of the first activities that tries to define the project scope and elicit user requirements. This activity relies in communication and cooperation between stakeholders which makes collaboration crucial for the success of this activity, especially in global software development projects with distributed teams and stakeholders. Despite the need for collaboration, lack of user input is still one of the problems of requirements elicitation, having negative consequences on project success. In this paper we present a proposal to involve stakeholders during requirements elicitation through the support of online collaboration and the usage of visualization techniques to stimulate stakeholders and increase their awareness about requirements. We are following action research methodology and present the results of a recent case study. © 2012 IEEE.",Action research | Online collaboration | Requirements elicitation | Requirements visualization | User involvement,24,343-348,Conference Proceeding,Conference Paper,4.0,"Duarte, Diogo;Farinha, Carla;Da Silva, Miguel Mira;Da Silva, Alberto Rodrigues",55370906000;55370921100;10138760500;8917629900,Instituto Superior Técnico,Portugal,"requirements elicitation is one of the first activities that tries to define the project scope and elicit user requirements. this activity relies in communication and cooperation between stakeholders which makes collaboration crucial for the success of this activity, especially in global software development projects with distributed teams and stakeholders. despite the need for collaboration, lack of user input is still one of the problems of requirements elicitation, having negative consequences on project success. in this paper we present a proposal to involve stakeholders during requirements elicitation through the support of online collaboration and the usage of visualization techniques to stimulate stakeholders and increase their awareness about requirements. we are following action research methodology and present the results of a recent case study. © 2012 ieee.",collaborative requirements elicitation with visualization techniques
1779,2-s2.0-84863618901,10.1016/j.jss.2011.07.034,Using Pig as a data preparation language for large-scale mining software repositories studies: An experience report,Shang W.,Journal of Systems and Software,2012-10-01,"The Mining Software Repositories (MSR) field analyzes software repository data to uncover knowledge and assist development of ever growing, complex systems. However, existing approaches and platforms for MSR analysis face many challenges when performing large-scale MSR studies. Such approaches and platforms rarely scale easily out of the box. Instead, they often require custom scaling tricks and designs that are costly to maintain and that are not reusable for other types of analysis. We believe that the web community has faced many of these software engineering scaling challenges before, as web analyses have to cope with the enormous growth of web data. In this paper, we report on our experience in using a web-scale platform (i.e., Pig) as a data preparation language to aid large-scale MSR studies. Through three case studies, we carefully validate the use of this web platform to prepare (i.e., Extract, Transform, and Load, ETL) data for further analysis. Despite several limitations, we still encourage MSR researchers to leverage Pig in their large-scale studies because of Pig's scalability and flexibility. Our experience report will help other researchers who want to scale their analyses. © 2011 Elsevier Inc. All rights reserved.",MapReduce | Mining Software Repositories | Pig | Software engineering,7,2195-2204,Journal,Article,3.0,"Shang, Weiyi;Adams, Bram;Hassan, Ahmed E.",35093168200;15134994200;7402686972,Queen’s University,Canada,"the mining software repositories (msr) field analyzes software repository data to uncover knowledge and assist development of ever growing, complex systems. however, existing approaches and platforms for msr analysis face many challenges when performing large-scale msr studies. such approaches and platforms rarely scale easily out of the box. instead, they often require custom scaling tricks and designs that are costly to maintain and that are not reusable for other types of analysis. we believe that the web community has faced many of these software engineering scaling challenges before, as web analyses have to cope with the enormous growth of web data. in this paper, we report on our experience in using a web-scale platform (i.e., pig) as a data preparation language to aid large-scale msr studies. through three case studies, we carefully validate the use of this web platform to prepare (i.e., extract, transform, and load, etl) data for further analysis. despite several limitations, we still encourage msr researchers to leverage pig in their large-scale studies because of pig's scalability and flexibility. our experience report will help other researchers who want to scale their analyses. © 2011 elsevier inc. all rights reserved.",using pig as a data preparation language for large-scale mining software repositories studies: an experience report
1780,2-s2.0-84865676772,10.1007/978-3-642-29219-4_34,JavaScript application framework for mobile devices,Raghu R.,Communications in Computer and Information Science,2012-09-07,"This paper presents the concept of JavaScript Application Framework (JSAF) which is a Platform Independent Model (PIM). This Paper aims at developing an application framework using web developing languages which supports the usage on all platforms making it easy for the developers to use the application framework to develop applications. JSAF is used for creating applications for Mobile Devices which supports a Browser which can render advanced web developing languages such as JavaScript, HTML5 and CSS3. The JSAF provides all the basic User-Interface (UI) widgets required for the Application Development to the Application developer. The JSAF Application is rendered on a Browser which will load JSAF framework prior to the Application. JavaScript Application Framework has the Multitasking feature and Cross Application Communication feature. JavaScript Application Framework is developed at Samsung India Software Operations and proprietary. © 2012 Springer-Verlag.",Application Framework | CSS | HTML | JavaScript | Mobile Applications,3,291-299,Book Series,Conference Paper,2.0,"Raghu, R.;Shobha, K. R.",55350173600;36024109500,Ramaiah Institute of Technology,India,"this paper presents the concept of javascript application framework (jsaf) which is a platform independent model (pim). this paper aims at developing an application framework using web developing languages which supports the usage on all platforms making it easy for the developers to use the application framework to develop applications. jsaf is used for creating applications for mobile devices which supports a browser which can render advanced web developing languages such as javascript, html5 and css3. the jsaf provides all the basic user-interface (ui) widgets required for the application development to the application developer. the jsaf application is rendered on a browser which will load jsaf framework prior to the application. javascript application framework has the multitasking feature and cross application communication feature. javascript application framework is developed at samsung india software operations and proprietary. © 2012 springer-verlag.",javascript application framework for mobile devices
1781,2-s2.0-84865556706,10.1145/2338714.2338742,"Model-driven iterative development of 3D web-applications using SSIML, X3D and JavaScript",Lenk M.,"Proceedings, Web3D 2012 - 17th International Conference on 3D Web Technology",2012-09-04,"In traditional software engineering domains, Model-Driven Development (MDD) using UML or domain-specific languages (DSL) is successfully established. Although MDD is a particularly promising approach to avoid implementation errors due to miscommunication between heterogenous developer groups, only a few MDD approaches for 3D-development have been proposed so far. In this paper, we describe how one such MDD approach, SSIML, can be extended to a full round-trip engineering approach to structured 3D-development. Round-trip engineering combines a forward phase, where code is automatically generated from an abstract model of the application, with a reverse phase, where manual code edits are merged back into the abstract model. The proposed approach is demonstrated with the development of 3D web applications based on X3D/X3DOM and JavaScript. © 2012 ACM.",3D development | code generation | JavaScript | model merging | reverse engineering | round-trip engineering | X3D | X3Dom,6,161-169,Conference Proceeding,Conference Paper,3.0,"Lenk, Matthias;Vitzthum, Arnd;Jung, Bernhard",56381162700;15023558800;23389802500,Technische Universität Bergakademie Freiberg;University of Cooperative Education,Germany;Germany,"in traditional software engineering domains, model-driven development (mdd) using uml or domain-specific languages (dsl) is successfully established. although mdd is a particularly promising approach to avoid implementation errors due to miscommunication between heterogenous developer groups, only a few mdd approaches for 3d-development have been proposed so far. in this paper, we describe how one such mdd approach, ssiml, can be extended to a full round-trip engineering approach to structured 3d-development. round-trip engineering combines a forward phase, where code is automatically generated from an abstract model of the application, with a reverse phase, where manual code edits are merged back into the abstract model. the proposed approach is demonstrated with the development of 3d web applications based on x3d/x3dom and javascript. © 2012 acm.","model-driven iterative development of 3d web-applications using ssiml, x3d and javascript"
1783,2-s2.0-84864698926,10.1145/2328876.2328885,Refactoring tools for dynamic languages,Schäfer M.,ACM International Conference Proceeding Series,2012-08-13,"Dynamic languages play an increasingly prominent role in modern software development. They are used in domains as diverse as web programming and scientific computing, for developing simple scripts as well as large applications. Tool-supported refactoring for these languages can bring important benefits to programmers. First, manual refactoring tends to be error-prone in dynamic languages since they impose very little static structure; hence, erroneous refactorings often cannot be detected until runtime. A tool can use static program analysis to check the soundness of a proposed refactoring, thus mitigating this problem. Second, dynamic languages tend to lack constructs for modularisation and encapsulation, which can be an obstacle to writing maintainable software. In many cases, such constructs can be emulated using other language features, but refactoring a program to make use of such patterns is often non-trivial and could benefit from tool support. Third, refactoring tools can be useful for adapting programs to use high-level features, thus supporting script to program evolution. However, specifying and implementing refactorings for dynamic languages is a challenging endeavour. We highlight some of the major issues in this area, and discuss recent progress towards solving them. © 2012 ACM.",dynamic languages | refactoring | refactoring tools | static analysis,5,59-62,Conference Proceeding,Conference Paper,1.0,"Schäfer, Max",26427858100,IBM Thomas J. Watson Research Center,United States,"dynamic languages play an increasingly prominent role in modern software development. they are used in domains as diverse as web programming and scientific computing, for developing simple scripts as well as large applications. tool-supported refactoring for these languages can bring important benefits to programmers. first, manual refactoring tends to be error-prone in dynamic languages since they impose very little static structure; hence, erroneous refactorings often cannot be detected until runtime. a tool can use static program analysis to check the soundness of a proposed refactoring, thus mitigating this problem. second, dynamic languages tend to lack constructs for modularisation and encapsulation, which can be an obstacle to writing maintainable software. in many cases, such constructs can be emulated using other language features, but refactoring a program to make use of such patterns is often non-trivial and could benefit from tool support. third, refactoring tools can be useful for adapting programs to use high-level features, thus supporting script to program evolution. however, specifying and implementing refactorings for dynamic languages is a challenging endeavour. we highlight some of the major issues in this area, and discuss recent progress towards solving them. © 2012 acm.",refactoring tools for dynamic languages
1784,2-s2.0-84864330218,10.1109/SEHC.2012.6227006,From a traditional behavioral management program to an M-health app: Lessons learned in developing M-health apps for existing health care programs,Zhu Q.,"2012 4th International Workshop on Software Engineering in Health Care, SEHC 2012 - Proceedings",2012-08-01,"M-health applications provide a unique new way to deliver healthcare. Developing m-health applications involves new challenges different from those encountered when developing traditional healthcare programs and e-health applications. This paper describes the development of an m-health application for behavioral migraine management, and presents lessons learned during the development process from software engineers' perspective. © 2012 IEEE.",migraine | mobile health app | self-management | software engineering,9,69-72,Conference Proceeding,Conference Paper,3.0,"Zhu, Qing;Liu, Chang;Holroyd, Kenneth A.",57199825085;57126540900;7005961126,Ohio University,United States,"m-health applications provide a unique new way to deliver healthcare. developing m-health applications involves new challenges different from those encountered when developing traditional healthcare programs and e-health applications. this paper describes the development of an m-health application for behavioral migraine management, and presents lessons learned during the development process from software engineers' perspective. © 2012 ieee.",from a traditional behavioral management program to an m-health app: lessons learned in developing m-health apps for existing health care programs
1785,2-s2.0-84864312794,10.1007/978-3-642-28655-1_94,Research and application on automatic generation technology of JavaScript input validation,Ren Y.,Advances in Intelligent and Soft Computing,2012-07-31,"Client authentication for Web applications require a lot of script writing, poor maintainability, this paper follows the system engineering principles and methods to study the data set to the page table, the application automatically generated by the automatic generation of JavaScript technology. Input validation in the way of the Web based on the comparison, first designs when the automatic production uses ""Checker Dictionary"" and ""Control Settings Page"" two table structures; Then carries on the automatic generating routine design, including program design process and the main validation function; Finally carries on the confirmation through the automatic production example. The results show that the automatically generated input validation of JavaScript, reduces the technical requirements for software developers to improve software development productivity, changed the traditional software development model. © 2012 Springer-Verlag GmbH.",automatic generation technology | input validation | JavaScript | Web,0,595-600,Book Series,Conference Paper,4.0,"Ren, Yongchang;Hu, Jie;Ning, Lisha;Xing, Tao",36093392800;16942417000;55322079900;35367400100,University of Chinese Academy of Sciences;Bohai University;Liaoning Agricultural Economy School,China;China;China,"client authentication for web applications require a lot of script writing, poor maintainability, this paper follows the system engineering principles and methods to study the data set to the page table, the application automatically generated by the automatic generation of javascript technology. input validation in the way of the web based on the comparison, first designs when the automatic production uses ""checker dictionary"" and ""control settings page"" two table structures; then carries on the automatic generating routine design, including program design process and the main validation function; finally carries on the confirmation through the automatic production example. the results show that the automatically generated input validation of javascript, reduces the technical requirements for software developers to improve software development productivity, changed the traditional software development model. © 2012 springer-verlag gmbh.",research and application on automatic generation technology of javascript input validation
1786,2-s2.0-84864272324,10.1109/ICSE.2012.6227133,Active code completion,Omar C.,Proceedings - International Conference on Software Engineering,2012-07-30,"Code completion menus have replaced standalone API browsers for most developers because they are more tightly integrated into the development workflow. Refinements to the code completion menu that incorporate additional sources of information have similarly been shown to be valuable, even relative to standalone counterparts offering similar functionality. In this paper, we describe active code completion, an architecture that allows library developers to introduce interactive and highly-specialized code generation interfaces, called palettes, directly into the editor. Using several empirical methods, we examine the contexts in which such a system could be useful, describe the design constraints governing the system architecture as well as particular code completion interfaces, and design one such system, named Graphite, for the Eclipse Java development environment. Using Graphite, we implement a palette for writing regular expressions as our primary example and conduct a small pilot study. In addition to showing the feasibility of this approach, it provides further evidence in support of the claim that integrating specialized code completion interfaces directly into the editor is valuable to professional developers. © 2012 IEEE.",code completion | development environments,53,859-869,Conference Proceeding,Conference Paper,4.0,"Omar, Cyrus;Yoon, Young Seok;LaToza, Thomas D.;Myers, Brad A.",24778544500;54419349700;16230457100;7202684451,Carnegie Mellon University,United States,"code completion menus have replaced standalone api browsers for most developers because they are more tightly integrated into the development workflow. refinements to the code completion menu that incorporate additional sources of information have similarly been shown to be valuable, even relative to standalone counterparts offering similar functionality. in this paper, we describe active code completion, an architecture that allows library developers to introduce interactive and highly-specialized code generation interfaces, called palettes, directly into the editor. using several empirical methods, we examine the contexts in which such a system could be useful, describe the design constraints governing the system architecture as well as particular code completion interfaces, and design one such system, named graphite, for the eclipse java development environment. using graphite, we implement a palette for writing regular expressions as our primary example and conduct a small pilot study. in addition to showing the feasibility of this approach, it provides further evidence in support of the claim that integrating specialized code completion interfaces directly into the editor is valuable to professional developers. © 2012 ieee.",active code completion
1787,2-s2.0-84864219659,10.1109/ICSE.2012.6227205,"Graph-based pattern-oriented, context-sensitive source code completion",Nguyen A.T.,Proceedings - International Conference on Software Engineering,2012-07-30,"Code completion helps improve developers' programming productivity. However, the current support for code completion is limited to context-free code templates or a single method call of the variable on focus. Using software libraries for development, developers often repeat API usages for certain tasks. Thus, a code completion tool could make use of API usage patterns. In this paper, we introduce GraPacc, a graph-based, pattern-oriented, context-sensitive code completion approach that is based on a database of such patterns. GraPacc represents and manages the API usage patterns of multiple variables, methods, and control structures via graph-based models. It extracts the context-sensitive features from the code under editing, e.g. the API elements on focus and their relations to other code elements. Those features are used to search and rank the patterns that are most fitted with the current code. When a pattern is selected, the current code will be completed via a novel graph-based code completion algorithm. Empirical evaluation on several real-world systems shows that GraPacc has a high level of accuracy in code completion. © 2012 IEEE.",API usage pattern | pattern-based code completion,98,69-79,Conference Proceeding,Conference Paper,7.0,"Nguyen, Anh Tuan;Nguyen, Tung Thanh;Nguyen, Hoan Anh;Tamrawi, Ahmed;Nguyen, Hung Viet;Al-Kofahi, Jafar;Nguyen, Tien N.",57194448092;57212284041;55459278800;36675816100;57225877698;25647258800;55386311200,Iowa State University,United States,"code completion helps improve developers' programming productivity. however, the current support for code completion is limited to context-free code templates or a single method call of the variable on focus. using software libraries for development, developers often repeat api usages for certain tasks. thus, a code completion tool could make use of api usage patterns. in this paper, we introduce grapacc, a graph-based, pattern-oriented, context-sensitive code completion approach that is based on a database of such patterns. grapacc represents and manages the api usage patterns of multiple variables, methods, and control structures via graph-based models. it extracts the context-sensitive features from the code under editing, e.g. the api elements on focus and their relations to other code elements. those features are used to search and rank the patterns that are most fitted with the current code. when a pattern is selected, the current code will be completed via a novel graph-based code completion algorithm. empirical evaluation on several real-world systems shows that grapacc has a high level of accuracy in code completion. © 2012 ieee.","graph-based pattern-oriented, context-sensitive source code completion"
1788,2-s2.0-84864065018,10.1145/2305484.2305527,GAMBIT: Addressing multi-platform collaborative sketching with HTML5,Sangiorgi U.,EICS'12 - Proceedings of the 2012 ACM SIGCHI Symposium on Engineering Interactive Computing Systems,2012-07-25,"Prototypes are essential tools for design activities since they allow designers to realize and evaluate ideas in early stages of the development. Sketching is a primary tool for constructing prototypes of interactive systems and has been used in developing low-fidelity prototypes for a long time. The computational support for sketching has been receiving a recurrence of interest in the last 45 years and again nowadays within the mobile web context, where there are diverse devices to be considered. The tool presented on this paper was built with HTML5 and Javascript in order to run on any device with browsing capabilities, for the main purpose of aiding an investigation on addressing issues of multi-platform collaborative sketching. Copyright 2012 ACM.",Collaborative design | Electronic sketching | Multi-platform systems | Prototyping,9,257-261,Conference Proceeding,Conference Paper,2.0,"Sangiorgi, Ugo Braga;Vanderdonckt, Jean",24328724900;6603880517,Université Catholique de Louvain,Belgium,"prototypes are essential tools for design activities since they allow designers to realize and evaluate ideas in early stages of the development. sketching is a primary tool for constructing prototypes of interactive systems and has been used in developing low-fidelity prototypes for a long time. the computational support for sketching has been receiving a recurrence of interest in the last 45 years and again nowadays within the mobile web context, where there are diverse devices to be considered. the tool presented on this paper was built with html5 and javascript in order to run on any device with browsing capabilities, for the main purpose of aiding an investigation on addressing issues of multi-platform collaborative sketching. copyright 2012 acm.",gambit: addressing multi-platform collaborative sketching with html5
1789,2-s2.0-84864037478,10.1145/2304736.2304744,A dynamic and service-oriented component model for python long-lived applications,Calmant T.,CBSE'12 - Proceedings of the 15th ACM SIGSOFT Symposium on Component Based Software Engineering,2012-07-25,"Dynamic runtime adaptations are a key feature for long-running applications. One of the most used languages for writing this kind of applications is Java, due to its reflection features, popularity and dynamism. However, as dynamic scripting languages (such as Python and Javascript) increase in popularity, it is desirable to be able to conceive long-running applications with them too. This paper introduces iPOPO and Pelix, a Python-based service-oriented component model and dynamic service platform respectively, which are inspired on two popular Java technologies for the development of long-running applications: the iPOJO component model and the OSGi Service Platform. To illustrate the approach, a usage of iPOPO and Pelix is presented on the context of mediation software. Copyright © 2012 ACM.",Component model | Dynamism | Python | SOA,5,35-40,Conference Proceeding,Conference Paper,5.0,"Calmant, Thomas;Americo, Joao Claudio;Gattaz, Olivier;Donsez, Didier;Gama, Kiev",55317839000;55302985300;55317838800;14826543000;26029426300,Universite Grenoble Alpes;CESAR Centro de Estudios e Sistemas Avancados do Recife;IsandlaTech,France;Brazil;France,"dynamic runtime adaptations are a key feature for long-running applications. one of the most used languages for writing this kind of applications is java, due to its reflection features, popularity and dynamism. however, as dynamic scripting languages (such as python and javascript) increase in popularity, it is desirable to be able to conceive long-running applications with them too. this paper introduces ipopo and pelix, a python-based service-oriented component model and dynamic service platform respectively, which are inspired on two popular java technologies for the development of long-running applications: the ipojo component model and the osgi service platform. to illustrate the approach, a usage of ipopo and pelix is presented on the context of mediation software. copyright © 2012 acm.",a dynamic and service-oriented component model for python long-lived applications
1793,2-s2.0-84871985302,10.1017/S1471068412000336,Lightweight compilation of (C)LP to JavaScript,Morales J.,Theory and Practice of Logic Programming,2012-07-01,"Abstract We present and evaluate a compiler from Prolog (and extensions) to JavaScript which makes it possible to use (constraint) logic programming to develop the client side of web applications while being compliant with current industry standards. Targeting JavaScript makes (C)LP programs executable in virtually every modern computing device with no additional software requirements from the point of view of the user. In turn, the use of a very high-level language facilitates the development of high-quality, complex software. The compiler is a back end of the Ciao system and supports most of its features, including its module system and its rich language extension mechanism based on packages. We present an overview of the compilation process and a detailed description of the run-time system, including the support for modular compilation into separate JavaScript code. We demonstrate the maturity of the compiler by testing it with complex code such as a CLP(FD) library written in Prolog with attributed variables. Finally, we validate our proposal by measuring the performance of some LP and CLP(FD) benchmarks running on top of major JavaScript engines. © Cambridge University Press 2012.",Ciao | implementation of Prolog | JavaScript | logic programming system | modules | Prolog | web,1,755-773,Journal,Conference Paper,4.0,"Morales, Jose F.;Haemmerlé, Rémy;Carro, Manuel;Hermenegildo, Manuel V.",36785374900;8958528200;7004418139;7004271854,IMDEA Software Institute;Universidad Politécnica de Madrid,Spain;Spain,"abstract we present and evaluate a compiler from prolog (and extensions) to javascript which makes it possible to use (constraint) logic programming to develop the client side of web applications while being compliant with current industry standards. targeting javascript makes (c)lp programs executable in virtually every modern computing device with no additional software requirements from the point of view of the user. in turn, the use of a very high-level language facilitates the development of high-quality, complex software. the compiler is a back end of the ciao system and supports most of its features, including its module system and its rich language extension mechanism based on packages. we present an overview of the compilation process and a detailed description of the run-time system, including the support for modular compilation into separate javascript code. we demonstrate the maturity of the compiler by testing it with complex code such as a clp(fd) library written in prolog with attributed variables. finally, we validate our proposal by measuring the performance of some lp and clp(fd) benchmarks running on top of major javascript engines. © cambridge university press 2012.",lightweight compilation of (c)lp to javascript
1794,2-s2.0-84862753629,10.1016/j.ygeno.2012.05.006,Relax with CouchDB - Into the non-relational DBMS era of bioinformatics,Manyam G.,Genomics,2012-07-01,"With the proliferation of high-throughput technologies, genome-level data analysis has become common in molecular biology. Bioinformaticians are developing extensive resources to annotate and mine biological features from high-throughput data. The underlying database management systems for most bioinformatics software are based on a relational model. Modern non-relational databases offer an alternative that has flexibility, scalability, and a non-rigid design schema. Moreover, with an accelerated development pace, non-relational databases like CouchDB can be ideal tools to construct bioinformatics utilities. We describe CouchDB by presenting three new bioinformatics resources: (a) geneSmash, which collates data from bioinformatics resources and provides automated gene-centric annotations, (b) drugBase, a database of drug-target interactions with a web interface powered by geneSmash, and (c) HapMap-CN, which provides a web interface to query copy number variations from three SNP-chip HapMap datasets. In addition to the web sites, all three systems can be accessed programmatically via web services. © 2012 Elsevier Inc.",Copy number variation | Data integration | Drug-target interaction | NoSQL database,26,1-7,Journal,Article,5.0,"Manyam, Ganiraju;Payton, Michelle A.;Roth, Jack A.;Abruzzo, Lynne V.;Coombes, Kevin R.",57218095013;36811741800;7404379856;7004062063;6701706213,University of Texas MD Anderson Cancer Center,United States,"with the proliferation of high-throughput technologies, genome-level data analysis has become common in molecular biology. bioinformaticians are developing extensive resources to annotate and mine biological features from high-throughput data. the underlying database management systems for most bioinformatics software are based on a relational model. modern non-relational databases offer an alternative that has flexibility, scalability, and a non-rigid design schema. moreover, with an accelerated development pace, non-relational databases like couchdb can be ideal tools to construct bioinformatics utilities. we describe couchdb by presenting three new bioinformatics resources: (a) genesmash, which collates data from bioinformatics resources and provides automated gene-centric annotations, (b) drugbase, a database of drug-target interactions with a web interface powered by genesmash, and (c) hapmap-cn, which provides a web interface to query copy number variations from three snp-chip hapmap datasets. in addition to the web sites, all three systems can be accessed programmatically via web services. © 2012 elsevier inc.",relax with couchdb - into the non-relational dbms era of bioinformatics
1795,2-s2.0-84862523209,10.1517/17425255.2012.685158,Web tools for predictive toxicology model building,Jeliazkova N.,Expert Opinion on Drug Metabolism and Toxicology,2012-07-01,"Introduction: The development and use of web tools in chemistry has accumulated more than 15 years of history already. Powered by the advances in the Internet technologies, the current generation of web systems are starting to expand into areas, traditional for desktop applications. The web platforms integrate data storage, cheminformatics and data analysis tools. The ease of use and the collaborative potential of the web is compelling, despite the challenges. Areas covered: The topic of this review is a set of recently published web tools that facilitate predictive toxicology model building. The focus is on software platforms, offering web access to chemical structure-based methods, although some of the frameworks could also provide bioinformatics or hybrid data analysis functionalities. A number of historical and current developments are cited. In order to provide comparable assessment, the following characteristics are considered: support for workflows, descriptor calculations, visualization, modeling algorithms, data management and data sharing capabilities, availability of GUI or programmatic access and implementation details. Expert opinion: The success of the Web is largely due to its highly decentralized, yet sufficiently interoperable model for information access. The expected future convergence between cheminformatics and bioinformatics databases provides new challenges toward management and analysis of large data sets. The web tools in predictive toxicology will likely continue to evolve toward the right mix of flexibility, performance, scalability, interoperability, sets of unique features offered, friendly user interfaces, programmatic access for advanced users, platform independence, results reproducibility, curation and crowdsourcing utilities, collaborative sharing and secure access. © 2012 Informa UK, Ltd. All rights reserved.",model building | predictive toxicology | QSAR | web applications | web services,9,791-801,Journal,Review,1.0,"Jeliazkova, Nina",8378341000,IDEAconsult Ltd.,Bulgaria,"introduction: the development and use of web tools in chemistry has accumulated more than 15 years of history already. powered by the advances in the internet technologies, the current generation of web systems are starting to expand into areas, traditional for desktop applications. the web platforms integrate data storage, cheminformatics and data analysis tools. the ease of use and the collaborative potential of the web is compelling, despite the challenges. areas covered: the topic of this review is a set of recently published web tools that facilitate predictive toxicology model building. the focus is on software platforms, offering web access to chemical structure-based methods, although some of the frameworks could also provide bioinformatics or hybrid data analysis functionalities. a number of historical and current developments are cited. in order to provide comparable assessment, the following characteristics are considered: support for workflows, descriptor calculations, visualization, modeling algorithms, data management and data sharing capabilities, availability of gui or programmatic access and implementation details. expert opinion: the success of the web is largely due to its highly decentralized, yet sufficiently interoperable model for information access. the expected future convergence between cheminformatics and bioinformatics databases provides new challenges toward management and analysis of large data sets. the web tools in predictive toxicology will likely continue to evolve toward the right mix of flexibility, performance, scalability, interoperability, sets of unique features offered, friendly user interfaces, programmatic access for advanced users, platform independence, results reproducibility, curation and crowdsourcing utilities, collaborative sharing and secure access. © 2012 informa uk, ltd. all rights reserved.",web tools for predictive toxicology model building
1796,2-s2.0-84862498268,10.1093/sysbio/sys025,"NeXML: Rich, extensible, and verifiable representation of comparative data and metadata",Vos R.A.,Systematic Biology,2012-07-01,"In scientific research, integration and synthesis require a common understanding of where data come from, how much they can be trusted, and what they may be used for. To make such an understanding computer-accessible requires standards for exchanging richly annotated data. The challenges of conveying reusable data are particularly acute in regard to evolutionary comparative analysis, which comprises an ever-expanding list of data types, methods, research aims, and subdisciplines. To facilitate interoperability in evolutionary comparative analysis, we present NeXML, an XML standard (inspired by the current standard, NEXUS) that supports exchange of richly annotated comparative data. NeXML defines syntax for operational taxonomic units, character-state matrices, and phylogenetic trees and networks. Documents can be validated unambiguously. Importantly, any data element can be annotated, to an arbitrary degree of richness, using a system that is both flexible and rigorous. We describe how the use of NeXML by the TreeBASE and Phenoscape projects satisfies user needs that cannot be satisfied with other available file formats. By relying on XML Schema Definition, the design of NeXML facilitates the development and deployment of software for processing, transforming, and querying documents. The adoption of NeXML for practical use is facilitated by the availability of (1) an online manual with code samples and a reference to all defined elements and attributes, (2) programming toolkits in most of the languages used commonly in evolutionary informatics, and (3) input-output support in several widely used software applications. An active, open, community-based development process enables future revision and expansion of NeXML. © 2012 The Author(s).",Data standards | evolutionary informatics | interoperability | phyloinformatics | semantic web | syntax format,67,675-689,Journal,Article,11.0,"Vos, Rutger A.;Balhoff, James P.;Caravas, Jason A.;Holder, Mark T.;Lapp, Hilmar;Maddison, Wayne P.;Midford, Peter E.;Priyam, Anurag;Sukumaran, Jeet;Xia, Xuhua;Stoltzfus, Arlin",36161555400;8637283900;36080369300;7006847503;7006213093;6603671990;6603048400;57136690300;16317668600;7402179513;6602153877,National Evolutionary Synthesis Center;Naturalis Biodiversity Center;University of Ottawa;The University of North Carolina at Chapel Hill;National Institute of Standards and Technology;The University of British Columbia;Wayne State University;Indian Institute of Technology Kharagpur;University of Kansas,United States;Netherlands;Canada;United States;United States;Canada;United States;India;United States,"in scientific research, integration and synthesis require a common understanding of where data come from, how much they can be trusted, and what they may be used for. to make such an understanding computer-accessible requires standards for exchanging richly annotated data. the challenges of conveying reusable data are particularly acute in regard to evolutionary comparative analysis, which comprises an ever-expanding list of data types, methods, research aims, and subdisciplines. to facilitate interoperability in evolutionary comparative analysis, we present nexml, an xml standard (inspired by the current standard, nexus) that supports exchange of richly annotated comparative data. nexml defines syntax for operational taxonomic units, character-state matrices, and phylogenetic trees and networks. documents can be validated unambiguously. importantly, any data element can be annotated, to an arbitrary degree of richness, using a system that is both flexible and rigorous. we describe how the use of nexml by the treebase and phenoscape projects satisfies user needs that cannot be satisfied with other available file formats. by relying on xml schema definition, the design of nexml facilitates the development and deployment of software for processing, transforming, and querying documents. the adoption of nexml for practical use is facilitated by the availability of (1) an online manual with code samples and a reference to all defined elements and attributes, (2) programming toolkits in most of the languages used commonly in evolutionary informatics, and (3) input-output support in several widely used software applications. an active, open, community-based development process enables future revision and expansion of nexml. © 2012 the author(s).","nexml: rich, extensible, and verifiable representation of comparative data and metadata"
1797,2-s2.0-84862683434,10.1145/2184512.2184598,Social network programming with JavaScript and Spotter,Purewal T.S.,Proceedings of the Annual Southeast Conference,2012-06-28,"Social Media and Social Networking are positioned to be an excellent way to draw a diverse population of students into the computing disciplines. At the same time, previous approaches to integrating these topics into the Computer Science curriculum have not involved programming. This poster introduces Spotter, an extendible JavaScript library that allows for real-time data from Twitter and Facebook to be utilized in client-side applications. Spotter makes it easy for social network programming to be introduced in a client-side web development course. We describe how it works, show some examples, and relay our experiences using it in three different classes at three different colleges. © 2012 Authors.",computer science education | social networks,0,347-348,Conference Proceeding,Conference Paper,2.0,"Purewal, Tarsem S.;Brown, David",16307679600;55574192164,The University of North Carolina System;Pellissippi State Community College,United States;United States,"social media and social networking are positioned to be an excellent way to draw a diverse population of students into the computing disciplines. at the same time, previous approaches to integrating these topics into the computer science curriculum have not involved programming. this poster introduces spotter, an extendible javascript library that allows for real-time data from twitter and facebook to be utilized in client-side applications. spotter makes it easy for social network programming to be introduced in a client-side web development course. we describe how it works, show some examples, and relay our experiences using it in three different classes at three different colleges. © 2012 authors.",social network programming with javascript and spotter
1798,2-s2.0-84861212033,10.1109/C5.2012.8,Krestianstvo SDK towards end-user mobile 3D virtual learning environment,Suslov N.,"Proceedings - 10th International Conference on Creating, Connecting and Collaborating through Computing, C5 2012",2012-05-23,"Virtual worlds are setting up new standards in software engineering for building virtual learning environments (VLE) today. Open Qwaq, which is based on Open Croquet architecture offers to both programmers and domain experts nearly an unlimited capabilities for creating novel computer-based simulated environments. But, even being built using a highly dynamic, reflective language and self-exploratory Squeak/Smalltalk IDE, it still suffers from tight bindings to client-server architecture, platform dependence and third-party tools. That leads to unnecessary inflexibility to develop or deploy new or existing virtual worlds on heterogeneous ad hoc networks. The article describes efforts being done for bringing Open Croquet/OpenQwaq SDK more closer to a mobile VLE development platform. Krestianstvo SDK is proposed as a one-click application, for instantly setting up a VLE in classroom's network, ART installation, educational disc and similar environments with support of augmented reality and collaborative tangible user interfaces. © 2012 IEEE.",augmented reality | virtual learning environment | virtual worlds,2,9-14,Conference Proceeding,Conference Paper,1.0,"Suslov, Nikolai",55221727500,Institute for the Development of Education,Russian Federation,"virtual worlds are setting up new standards in software engineering for building virtual learning environments (vle) today. open qwaq, which is based on open croquet architecture offers to both programmers and domain experts nearly an unlimited capabilities for creating novel computer-based simulated environments. but, even being built using a highly dynamic, reflective language and self-exploratory squeak/smalltalk ide, it still suffers from tight bindings to client-server architecture, platform dependence and third-party tools. that leads to unnecessary inflexibility to develop or deploy new or existing virtual worlds on heterogeneous ad hoc networks. the article describes efforts being done for bringing open croquet/openqwaq sdk more closer to a mobile vle development platform. krestianstvo sdk is proposed as a one-click application, for instantly setting up a vle in classroom's network, art installation, educational disc and similar environments with support of augmented reality and collaborative tangible user interfaces. © 2012 ieee.",krestianstvo sdk towards end-user mobile 3d virtual learning environment
1800,2-s2.0-84860428083,10.1145/2162004.2162007,Symmetric aspect-orientation: Some practical consequences,Bálik J.,NEMARA'12 - Proceedings of the 2012 Workshop on Next Generation Modularity Approaches for Requirements and Architecture,2012-05-07,"To some extent, contemporary software development has incorporated the AspectJ style of aspect-oriented programming. This style is denoted as asymmetric since it explicitly distinguishes between aspects and the base. Although academic symmetric aspect-oriented approaches, in which there is no such distinction, gained no direct acceptance in industry, several approaches used in practice exhibit symmetric aspect-oriented features. As shown in this paper, this ranges from peer use cases and features as analysis and design concepts to particular programming language mechanisms such as traits (Scala), open classes (Ruby), or prototypes (JavaScript). Even inter-type declarations and advices as known from AspectJ can be used to emulate symmetric aspect-oriented programming. The examples given in this paper indicate the basic possibilities for this. However, detailed studies of the corresponding academic and industry approaches should be carried. © 2012 ACM.",Design | Languages,13,7-11,Conference Proceeding,Conference Paper,2.0,"Bálik, Jaroslav;Vranić, Valentino",55203025900;22434207700,Slovak University of Technology in Bratislava,Slovakia,"to some extent, contemporary software development has incorporated the aspectj style of aspect-oriented programming. this style is denoted as asymmetric since it explicitly distinguishes between aspects and the base. although academic symmetric aspect-oriented approaches, in which there is no such distinction, gained no direct acceptance in industry, several approaches used in practice exhibit symmetric aspect-oriented features. as shown in this paper, this ranges from peer use cases and features as analysis and design concepts to particular programming language mechanisms such as traits (scala), open classes (ruby), or prototypes (javascript). even inter-type declarations and advices as known from aspectj can be used to emulate symmetric aspect-oriented programming. the examples given in this paper indicate the basic possibilities for this. however, detailed studies of the corresponding academic and industry approaches should be carried. © 2012 acm.",symmetric aspect-orientation: some practical consequences
1802,2-s2.0-84860875708,10.1108/00907321211228354,iBIRA - integrated bioinformatics information resource access: Organizing the bioinformatics resourceome,Ram S.,Reference Services Review,2012-05-01,"Purpose: Bioinformatics is an emerging discipline where the interdisciplinary research holds great promise for the advancement of research and development in many complex areas. The research output generates a huge amount of data and information. Because of the heterogeneous nature of bioinformatics resources, difficulty in accessing pertinent information is the biggest challenge for the bioinformatics community. The integration of bioinformatics resources in a comprehensive manner is advocated by the bioinformatics user community as well as by information scientists serving this community. There are have already been some efforts made for integration of bioinformatics resources by the discrete bioinformatics community, but these are based on the requirement of their own area and arena. This paper aims to discuss the design and development of a tool for the integration of various heterogeneous bioinformatics information resources available over the internet. Design/methodology/approach: The authors have developed a tool with the acronym ""iBIRA"" (Integrated Bioinformatics Information Resource Access) that associates the bioinformatics community with the bioinformatics ""resourceome"" (the term suggested for the ""full set of bioinformatics resources"" by Cannata et al.). Available over the internet. iBIRA (www.ibiranet.in) integrates bioinformatics resources in a way such that it is possible to locate, connect and communicate different categories of resources in a cohesive manner. A software engineering and database-driven approach was used for the integration and organization of bioinformatics resources. Computational programming such as Hypertext Preprocessor (PHP), a server-side dynamic web programming language, and MySQL as a database management system have been used. Dublin Core Metadata Standards have been used for the design of metadata for bioinformatics resources. Findings: The term ""resource"" in the area of bioinformatics covers various entities such as journals, molecular biology databases, online annotation tools, patents, published documents (articles, books, etc), protocols, software tools, and web servers. It has been found that bioinformatics resources are heterogeneous in nature and available over the internet in different forms and formats. The fact that bioinformatics resources are scattered over the internet makes resource discovery difficult for the bioinformatics community, and there is need for a system that reorganizes these resources. The integration of all the resources of bioinformatics at a single platform (called ""iBIRA"") provides significant ""value added"" to the bioinformatics community, those serving this population. Originality/value: The iBIRA tool is a meta-server developed to provide information service about the availability of various bioinformatics resources to the bioinformatics community. This will provide a value-added benefit to the population in helping them to locate relevant resources for their education, research and training. © Emerald Group Publishing Limited.",Bioinformatics | Databases | Information resources | Information retrieval | Resource integration | Web based tool | Worldwide web,5,326-343,Journal,Article,2.0,"Ram, Shri;Rao, N. Laxman",36139196400;55214304600,"Jaypee University of Information Technology, Solan;Osmania University",India;India,"purpose: bioinformatics is an emerging discipline where the interdisciplinary research holds great promise for the advancement of research and development in many complex areas. the research output generates a huge amount of data and information. because of the heterogeneous nature of bioinformatics resources, difficulty in accessing pertinent information is the biggest challenge for the bioinformatics community. the integration of bioinformatics resources in a comprehensive manner is advocated by the bioinformatics user community as well as by information scientists serving this community. there are have already been some efforts made for integration of bioinformatics resources by the discrete bioinformatics community, but these are based on the requirement of their own area and arena. this paper aims to discuss the design and development of a tool for the integration of various heterogeneous bioinformatics information resources available over the internet. design/methodology/approach: the authors have developed a tool with the acronym ""ibira"" (integrated bioinformatics information resource access) that associates the bioinformatics community with the bioinformatics ""resourceome"" (the term suggested for the ""full set of bioinformatics resources"" by cannata et al.). available over the internet. ibira (www.ibiranet.in) integrates bioinformatics resources in a way such that it is possible to locate, connect and communicate different categories of resources in a cohesive manner. a software engineering and database-driven approach was used for the integration and organization of bioinformatics resources. computational programming such as hypertext preprocessor (php), a server-side dynamic web programming language, and mysql as a database management system have been used. dublin core metadata standards have been used for the design of metadata for bioinformatics resources. findings: the term ""resource"" in the area of bioinformatics covers various entities such as journals, molecular biology databases, online annotation tools, patents, published documents (articles, books, etc), protocols, software tools, and web servers. it has been found that bioinformatics resources are heterogeneous in nature and available over the internet in different forms and formats. the fact that bioinformatics resources are scattered over the internet makes resource discovery difficult for the bioinformatics community, and there is need for a system that reorganizes these resources. the integration of all the resources of bioinformatics at a single platform (called ""ibira"") provides significant ""value added"" to the bioinformatics community, those serving this population. originality/value: the ibira tool is a meta-server developed to provide information service about the availability of various bioinformatics resources to the bioinformatics community. this will provide a value-added benefit to the population in helping them to locate relevant resources for their education, research and training. © emerald group publishing limited.",ibira - integrated bioinformatics information resource access: organizing the bioinformatics resourceome
1803,2-s2.0-84859042120,10.1145/2148131.2148181,GISpL: Gestures made easy,Echtler F.,"Proceedings of the 6th International Conference on Tangible, Embedded and Embodied Interaction, TEI 2012",2012-04-02,"We present GISpL, the Gestural Interface Specification Language. GISpL is a formal language which allows both researchers and developers to unambiguously describe the behavior of a wide range of gestural interfaces using a simple JSON-based syntax. GISpL supports a multitude of input modalities, including multi-touch, digital pens, multiple regular mice, tangible interfaces or mid-air gestures. GISpL introduces a novel view on gestural interfaces from a software-engineering perspective. By using GISpL, developers can avoid tedious tasks such as reimplementing the same gesture recognition algorithms over and over again. Researchers benefit from the ability to quickly reconfigure prototypes of gestural UIs on-the-fly, possibly even in the middle of an expert review. In this paper, we present a brief overview of GISpL as well as some usage examples of our reference implementation. We demonstrate its capabilities by the example of a multichannel audio mixer application being used with several different input modalities. Moreover, we present exemplary GISpL descriptions of other gestural interfaces and conclude by discussing its potential applications and future development. © 2012 ACM.",Formal language | Gestures | Interaction | User interface,18,233-240,Conference Proceeding,Conference Paper,2.0,"Echtler, Florian;Butz, Andreas",24821578300;55150450600,Ludwig-Maximilians-Universität München;Hochschule München,Germany;Germany,"we present gispl, the gestural interface specification language. gispl is a formal language which allows both researchers and developers to unambiguously describe the behavior of a wide range of gestural interfaces using a simple json-based syntax. gispl supports a multitude of input modalities, including multi-touch, digital pens, multiple regular mice, tangible interfaces or mid-air gestures. gispl introduces a novel view on gestural interfaces from a software-engineering perspective. by using gispl, developers can avoid tedious tasks such as reimplementing the same gesture recognition algorithms over and over again. researchers benefit from the ability to quickly reconfigure prototypes of gestural uis on-the-fly, possibly even in the middle of an expert review. in this paper, we present a brief overview of gispl as well as some usage examples of our reference implementation. we demonstrate its capabilities by the example of a multichannel audio mixer application being used with several different input modalities. moreover, we present exemplary gispl descriptions of other gestural interfaces and conclude by discussing its potential applications and future development. © 2012 acm.",gispl: gestures made easy
1804,2-s2.0-84858976616,10.1145/2157136.2157290,Cabana: A cross-platform mobile development system,Dickson P.,SIGCSE'12 - Proceedings of the 43rd ACM Technical Symposium on Computer Science Education,2012-03-30,"Mobile application development is a hot topic in computer science education, and debate rages over which platform to develop on and what software to use for development. Cabana is a web-based application designed to enable development on multiple mobile platforms and to make application development easier. It uses an approach to application programming based on a wiring diagram that is supplemented with the ability to program directly using JavaScript. It is an ideal choice for application development in introductory computer science courses and for upper-level courses where the focus is on application design and not application programming. This paper introduces Cabana and describes its use in two different computer science courses. © 2012 ACM.",android | appinventor | apps | Cabana | iPhone | mobile devices | smartphone | xcode,21,529-534,Conference Proceeding,Conference Paper,1.0,"Dickson, Paul E.",24448149200,Hampshire College,United States,"mobile application development is a hot topic in computer science education, and debate rages over which platform to develop on and what software to use for development. cabana is a web-based application designed to enable development on multiple mobile platforms and to make application development easier. it uses an approach to application programming based on a wiring diagram that is supplemented with the ability to program directly using javascript. it is an ideal choice for application development in introductory computer science courses and for upper-level courses where the focus is on application design and not application programming. this paper introduces cabana and describes its use in two different computer science courses. © 2012 acm.",cabana: a cross-platform mobile development system
1806,2-s2.0-84858785718,10.1145/2151024.2151047,"Adding dynamically-typed language support to a statically-typed language compiler: Performance evaluation, analysis, and tradeoffs",Ishizaki K.,VEE'12 - Proceedings of the ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments,2012-03-28,"Applications written in dynamically typed scripting languages are increasingly popular for Web software development. Even on the server side, programmers are using dynamically typed scripting languages such as Ruby and Python to build complex applications quickly. As the number and complexity of dynamically typed scripting language applications grows, optimizing their performance is becoming important. Some of the best performing compilers and optimizers for dynamically typed scripting languages are developed entirely from scratch and target a specific language. This approach is not scalable, given the variety of dynamically typed scripting languages, and the effort involved in developing and maintaining separate infrastructures for each. In this paper, we evaluate the feasibility of adapting and extending an existing production-quality method-based Just-In-Time (JIT) compiler for a language with dynamic types. Our goal is to identify the challenges and shortcomings with the current infrastructure, and to propose and evaluate runtime techniques and optimizations that can be incorporated into a common optimization infrastructure for static and dynamic languages. We discuss three extensions to the compiler to support dynamically typed languages: (1) simplification of control flow graphs, (2) mapping of memory locations to stack-allocated variables, and (3) reduction of runtime overhead using language semantics. We also propose four new optimizations for Python in (2) and (3). These extensions are effective in reduction of compiler working memory and improvement of runtime performance. We present a detailed performance evaluation of our approach for Python, finding an overall improvement of 1.69x on average (up to 2.74x) over our JIT compiler without any optimization for dynamically typed languages and Python. © 2012 ACM.",dynamically typed language | just-in-time compiler | python,10,169-180,Conference Proceeding,Conference Paper,6.0,"Ishizaki, Kazuaki;Ogasawara, Takeshi;Castanos, Jose;Nagpurkar, Priya;Edelsohn, David;Nakatani, Toshio",7102902708;35415099800;6602153641;9237767300;6506440737;35248852100,IBM Thomas J. Watson Research Center;IBM Research,United States;United States,"applications written in dynamically typed scripting languages are increasingly popular for web software development. even on the server side, programmers are using dynamically typed scripting languages such as ruby and python to build complex applications quickly. as the number and complexity of dynamically typed scripting language applications grows, optimizing their performance is becoming important. some of the best performing compilers and optimizers for dynamically typed scripting languages are developed entirely from scratch and target a specific language. this approach is not scalable, given the variety of dynamically typed scripting languages, and the effort involved in developing and maintaining separate infrastructures for each. in this paper, we evaluate the feasibility of adapting and extending an existing production-quality method-based just-in-time (jit) compiler for a language with dynamic types. our goal is to identify the challenges and shortcomings with the current infrastructure, and to propose and evaluate runtime techniques and optimizations that can be incorporated into a common optimization infrastructure for static and dynamic languages. we discuss three extensions to the compiler to support dynamically typed languages: (1) simplification of control flow graphs, (2) mapping of memory locations to stack-allocated variables, and (3) reduction of runtime overhead using language semantics. we also propose four new optimizations for python in (2) and (3). these extensions are effective in reduction of compiler working memory and improvement of runtime performance. we present a detailed performance evaluation of our approach for python, finding an overall improvement of 1.69x on average (up to 2.74x) over our jit compiler without any optimization for dynamically typed languages and python. © 2012 acm.","adding dynamically-typed language support to a statically-typed language compiler: performance evaluation, analysis, and tradeoffs"
1807,2-s2.0-84857802652,10.1145/2103656.2103671,Access permission contracts for scripting languages,Heidegger P.,Conference Record of the Annual ACM Symposium on Principles of Programming Languages,2012-03-12,"The ideal software contract fully specifies the behavior of an operation. Often, in particular in the context of scripting languages, a full specification may be cumbersome to state and may not even be desired. In such cases, a partial specification, which describes selected aspects of the behavior, may be used to raise the confidence in an implementation of the operation to a reasonable level. We propose a novel kind of contract for object-based languages that specifies the side effects of an operation with access permissions. An access permission contract uses sets of access paths to express read and write permissions for the properties of the objects accessible from the operation. We specify a monitoring semantics for access permission contracts and implement this semantics in a contract system for JavaScript. We prove soundness and stability of violation under increasing aliasing for our semantics. Applications of access permission contracts include enforcing modularity, test-driven development, program understanding, and regression testing. With respect to testing and understanding, we find that adding access permissions to contracts increases the effectiveness of error detection through contract monitoring by 6-13%. Copyright © 2012 ACM.",Contracts | JavaScript | Scripting languages,4,111-122,Conference Proceeding,Conference Paper,3.0,"Heidegger, Phillip;Bieniusa, Annette;Thiemann, Peter",36175999400;26321313600;7004615896,Laboratoire d'Informatique de Paris 6;Universität Freiburg,France;Germany,"the ideal software contract fully specifies the behavior of an operation. often, in particular in the context of scripting languages, a full specification may be cumbersome to state and may not even be desired. in such cases, a partial specification, which describes selected aspects of the behavior, may be used to raise the confidence in an implementation of the operation to a reasonable level. we propose a novel kind of contract for object-based languages that specifies the side effects of an operation with access permissions. an access permission contract uses sets of access paths to express read and write permissions for the properties of the objects accessible from the operation. we specify a monitoring semantics for access permission contracts and implement this semantics in a contract system for javascript. we prove soundness and stability of violation under increasing aliasing for our semantics. applications of access permission contracts include enforcing modularity, test-driven development, program understanding, and regression testing. with respect to testing and understanding, we find that adding access permissions to contracts increases the effectiveness of error detection through contract monitoring by 6-13%. copyright © 2012 acm.",access permission contracts for scripting languages
1808,2-s2.0-84857752927,10.1007/978-3-642-27997-3_9,Secure mashup-providing platforms - Implementing encrypted wiring,Herbert M.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2012-03-08,"Mashups were not designed with security in mind. Their main selling point is the flexible and easy to use development approach. The fact that mashups enable users to compose services to create a piece of software with new functionalities, integrating inputs from various sources, implies a security risk. However, in many scenarios where mashups add business value, e.g. enterprise mashups, security and privacy are important requirements. A secure environment for the handling of potentially sensitive end user information is needed, unless the user fully trusts the mashup-providing-platform (MPP), which is unlikely for hosted enterprise mashups. In this paper we present a proof-of-concept implementation which enables the secure usage of a mashup-providing platform and protects sensitive data against malicious widgets and platform operators. © 2012 Springer-Verlag.",enterprise mashups | mashup | Secure mashups | security,1,99-108,Book Series,Conference Paper,4.0,"Herbert, Matthias;Thieme, Tobias;Zibuschka, Jan;Roßnagel, Heiko",36598460500;55049165700;23007158700;8925425600,Fraunhofer Institute for Industrial Engineering IAO,Germany,"mashups were not designed with security in mind. their main selling point is the flexible and easy to use development approach. the fact that mashups enable users to compose services to create a piece of software with new functionalities, integrating inputs from various sources, implies a security risk. however, in many scenarios where mashups add business value, e.g. enterprise mashups, security and privacy are important requirements. a secure environment for the handling of potentially sensitive end user information is needed, unless the user fully trusts the mashup-providing-platform (mpp), which is unlikely for hosted enterprise mashups. in this paper we present a proof-of-concept implementation which enables the secure usage of a mashup-providing platform and protects sensitive data against malicious widgets and platform operators. © 2012 springer-verlag.",secure mashup-providing platforms - implementing encrypted wiring
1811,2-s2.0-84863059405,10.1007/s10708-010-9385-3,Integrating publicly available web mapping tools for cartographic visualization of community food insecurity: A prototype,Hwang M.,GeoJournal,2012-02-01,"Spatial profiling of community food security data can help the targeting of geographic areas and populations most vulnerable to food insecurity. While multiple poverty mapping systems support spatial profiling, they often lack capabilities to disseminate mapping results to a wide range of audiences and to spatially link qualitative data to quantitative analysis. To address these limitations, this study presents a web mapping framework which integrates a variety of publicly available software tools to enable spatial exploration of both quantitative and qualitative data. Specifically, our framework allows online choropleth mapping and thematic data exploration through a mixture of free mapping Application Programming Interfaces (APIs) and open source software tools for spatial data processing and desktop-like user interfaces. The study demonstrates this framework by developing a web prototype for informing food insecurity issues in Bogotá, Colombia. The prototype implementation reveals that the proposed framework facilitates the development of scalable and functionally-extensible mapping systems and the identification of community-specific food insecurity problems (e. g., food kitchens inaccessible from workplaces of low-income residents). This suggests that web-based cartographic visualization using publicly available software tools can be useful for spatial examination of community food insecurity as well as for cost-effective distribution of the resulting map information. © 2010 Springer Science+Business Media B.V.",Bogotá | Choropleth mapping | Community food security | Free or open source software | Spatial data exploration | Web mapping,4,47-62,Journal,Article,2.0,"Hwang, Myunghwa;Smith, Marissa",55827187100;15038129800,Arizona State University,United States,"spatial profiling of community food security data can help the targeting of geographic areas and populations most vulnerable to food insecurity. while multiple poverty mapping systems support spatial profiling, they often lack capabilities to disseminate mapping results to a wide range of audiences and to spatially link qualitative data to quantitative analysis. to address these limitations, this study presents a web mapping framework which integrates a variety of publicly available software tools to enable spatial exploration of both quantitative and qualitative data. specifically, our framework allows online choropleth mapping and thematic data exploration through a mixture of free mapping application programming interfaces (apis) and open source software tools for spatial data processing and desktop-like user interfaces. the study demonstrates this framework by developing a web prototype for informing food insecurity issues in bogotá, colombia. the prototype implementation reveals that the proposed framework facilitates the development of scalable and functionally-extensible mapping systems and the identification of community-specific food insecurity problems (e. g., food kitchens inaccessible from workplaces of low-income residents). this suggests that web-based cartographic visualization using publicly available software tools can be useful for spatial examination of community food insecurity as well as for cost-effective distribution of the resulting map information. © 2010 springer science+business media b.v.",integrating publicly available web mapping tools for cartographic visualization of community food insecurity: a prototype
1816,2-s2.0-84986305491,10.15837/ijccc.2012.5.1343,Client side internet technologies in critical infrastructure systems,Lendak I.,"International Journal of Computers, Communications and Control",2012-01-01,"This paper assesses the applicability of client side Internet technologies in software solutions for critical infrastructure systems (CIS). It contains an in-depth analysis of four significant and well known development platforms, namely JavaScript with jQuery, the Google Web Tookit, Microsoft's Silverlight and Adobe's Flash/Flex. They were compared by using the ISO software quality characteristics as comparison criteria. Each of the technologies was applied in a real-life project and the results summarize the authors' experience. The ultimate goal of this research is to enable software engineers to more easily choose a client-side Internet technology when developing a new software solution for the CIS domain.",Comparative analysis | Critical infrastructure systems | Rich internet applications,1,879-891,Journal,Article,6.0,"Lendak, Imre;Vukmirovic, Srdjan;Varga, Ervin;Erdeljan, Aleksandar;Nenadic, Kosa;Ivancevic, Nikola",36518973800;36159050800;16311159400;6506922497;57191078904;57191076678,University of Novi Sad;EXPRO I.T. Consulting Llc,Serbia;Serbia,"this paper assesses the applicability of client side internet technologies in software solutions for critical infrastructure systems (cis). it contains an in-depth analysis of four significant and well known development platforms, namely javascript with jquery, the google web tookit, microsoft's silverlight and adobe's flash/flex. they were compared by using the iso software quality characteristics as comparison criteria. each of the technologies was applied in a real-life project and the results summarize the authors' experience. the ultimate goal of this research is to enable software engineers to more easily choose a client-side internet technology when developing a new software solution for the cis domain.",client side internet technologies in critical infrastructure systems
1818,2-s2.0-84896929252,10.1016/j.procs.2012.06.089,Secure web service clients on mobile devices,Bertram J.,Procedia Computer Science,2012-01-01,"Enterprise apps on mobile devices typically need to communicate with other system components by consuming web services. Since most of the current mobile device platforms (such as Android) do not provide built-in features for consuming SOAP services, extensions have to be designed. Additionally in order to accommodate the typical enhanced security requirements of enterprise apps, it is important to be able to deal with SOAP web service security extensions on client side. In this article we show that neither the built-in SOAP capabilities for Android web service clients are sufficient for enterprise apps nor are the necessary security features supported by the platform as is. After discussing different existing extensions making Android devices SOAP capable we explain why none of them is really satisfactory in an enterprise context. Then we present our own solution which accommodates not only SOAP but also the WS-Security features on top of SOAP. Our solution heavily relies on code generation in order to keep the flexibility benefits of SOAP on one hand while still keeping the development effort manageable for software development. Our approach provides a good foundation for the implementation of other SOAP extensions apart from security on the Android platform as well. In addition our solution based on the gSOAP framework may be used for other mobile platforms in a similar manner. © 2012 Published by Elsevier Ltd.",Android | Enterprise apps | GSOAP | KSOAP | SOAP | Web service | WS-Security,5,696-704,Conference Proceeding,Conference Paper,2.0,"Bertram, Jens;Kleiner, Carsten",54419440400;24722474100,Hochschule Hannover,Germany,"enterprise apps on mobile devices typically need to communicate with other system components by consuming web services. since most of the current mobile device platforms (such as android) do not provide built-in features for consuming soap services, extensions have to be designed. additionally in order to accommodate the typical enhanced security requirements of enterprise apps, it is important to be able to deal with soap web service security extensions on client side. in this article we show that neither the built-in soap capabilities for android web service clients are sufficient for enterprise apps nor are the necessary security features supported by the platform as is. after discussing different existing extensions making android devices soap capable we explain why none of them is really satisfactory in an enterprise context. then we present our own solution which accommodates not only soap but also the ws-security features on top of soap. our solution heavily relies on code generation in order to keep the flexibility benefits of soap on one hand while still keeping the development effort manageable for software development. our approach provides a good foundation for the implementation of other soap extensions apart from security on the android platform as well. in addition our solution based on the gsoap framework may be used for other mobile platforms in a similar manner. © 2012 published by elsevier ltd.",secure web service clients on mobile devices
1824,2-s2.0-84866885034,10.1177/0037549712450359,Simulation on the Web with distributed models and intelligent agents,Jávor A.,SIMULATION,2012-01-01,"Simulation is aimed very often to solve problems of great complexity requiring – beyond using the advanced simulation software tools – platforms that enable the implementation of such software systems. In recent years the concept of cloud computing has emerged and is being applied more and more widely for solving such problems. This paper, beyond delineating the main trends of the development of distributed simulation over a grid, especially over the Internet through Web-based applications, highlights the concepts of service-based simulation system approach. This concept gives the possibility of implementing Web- or cloud agents and other ASP system compliant simulation services based on simulation standards. As a sample application, Fuzzy Web Service is demonstrated as a part of CASSANDRA 4.0 (Cognizant Adaptive Simulation System for Applications in Numerous Different Relevant Areas) that is developed by the McLeod Institute of Simulation Sciences Hungarian Center. © 2012, The Society for Modeling and Simulation International. All rights reserved.",agent-controlled simulation | distributed models | Web-based simulation,9,1080-1092,Journal,Article,2.0,"Jávor, András;Fűr, Attila",7004132720;36615042500,Budapest University of Technology and Economics,Hungary,"simulation is aimed very often to solve problems of great complexity requiring – beyond using the advanced simulation software tools – platforms that enable the implementation of such software systems. in recent years the concept of cloud computing has emerged and is being applied more and more widely for solving such problems. this paper, beyond delineating the main trends of the development of distributed simulation over a grid, especially over the internet through web-based applications, highlights the concepts of service-based simulation system approach. this concept gives the possibility of implementing web- or cloud agents and other asp system compliant simulation services based on simulation standards. as a sample application, fuzzy web service is demonstrated as a part of cassandra 4.0 (cognizant adaptive simulation system for applications in numerous different relevant areas) that is developed by the mcleod institute of simulation sciences hungarian center. © 2012, the society for modeling and simulation international. all rights reserved.",simulation on the web with distributed models and intelligent agents
1828,2-s2.0-84863824618,10.18637/jss.v049.i09,RKWard: A Comprehensive Graphical User Interface and Integrated Development Environment for Statistical Analysis with R,Rödiger S.,Journal of Statistical Software,2012-01-01,"R is a free open-source implementation of the S statistical computing language and programming environment. The current status of R is a command line driven interface with no advanced cross-platform graphical user interface (GUI), but it includes tools for building such. Over the past years, proprietary and non-proprietary GUI solutions have emerged, based on internal or external tool kits, with different scopes and technological concepts. For example, Rgui.exe and Rgui.app have become the de facto GUI on the Microsoft Windows and Mac OS X platforms, respectively, for most users. In this paper we discuss RKWard which aims to be both a comprehensive GUI and an integrated development environment for R. RKWard is based on the KDE software libraries. Statistical procedures and plots are implemented using an extendable plugin architecture based on ECMAScript (JavaScript), R, and XML. RKWard provides an excellent tool to manage different types of data objects; even allowing for seamless editing of certain types. The objective of RKWard is to provide a portable and extensible R interface for both basic and advanced statistical and graphical analysis, while not compromising on flexibility and modularity of the R programming environment itself.",GUI | Integrated development environment | Plugin | R,45,1-34,Journal,Article,4.0,"Rödiger, Stefan;Friedrichsmeier, Thomas;Kapat, Prasenjit;Michalke, Meik",49962220600;57500408200;25225616400;55313270400,Fachhochschule Lausitz,Germany,"r is a free open-source implementation of the s statistical computing language and programming environment. the current status of r is a command line driven interface with no advanced cross-platform graphical user interface (gui), but it includes tools for building such. over the past years, proprietary and non-proprietary gui solutions have emerged, based on internal or external tool kits, with different scopes and technological concepts. for example, rgui.exe and rgui.app have become the de facto gui on the microsoft windows and mac os x platforms, respectively, for most users. in this paper we discuss rkward which aims to be both a comprehensive gui and an integrated development environment for r. rkward is based on the kde software libraries. statistical procedures and plots are implemented using an extendable plugin architecture based on ecmascript (javascript), r, and xml. rkward provides an excellent tool to manage different types of data objects; even allowing for seamless editing of certain types. the objective of rkward is to provide a portable and extensible r interface for both basic and advanced statistical and graphical analysis, while not compromising on flexibility and modularity of the r programming environment itself.",rkward: a comprehensive graphical user interface and integrated development environment for statistical analysis with r
1830,2-s2.0-84857179155,10.1145/2103621.2103671,Access permission contracts for scripting languages,Heidegger P.,ACM SIGPLAN Notices,2012-01-01,"The ideal software contract fully specifies the behavior of an operation. Often, in particular in the context of scripting languages, a full specification may be cumbersome to state and may not even be desired. In such cases, a partial specification, which describes selected aspects of the behavior, may be used to raise the confidence in an implementation of the operation to a reasonable level. We propose a novel kind of contract for object-based languages that specifies the side effects of an operation with access permissions. An access permission contract uses sets of access paths to express read and write permissions for the properties of the objects accessible from the operation. We specify a monitoring semantics for access permission contracts and implement this semantics in a contract system for JavaScript. We prove soundness and stability of violation under increasing aliasing for our semantics. Applications of access permission contracts include enforcing modularity, test-driven development, program understanding, and regression testing. With respect to testing and understanding, we find that adding access permissions to contracts increases the effectiveness of error detection through contract monitoring by 6-13%. © 2012 ACM.",Contracts | JavaScript | Scripting languages,15,111-122,Journal,Conference Paper,3.0,"Heidegger, Phillip;Bieniusa, Annette;Thiemann, Peter",36175999400;26321313600;7004615896,INRIA Rocquencourt;Universität Freiburg,France;Germany,"the ideal software contract fully specifies the behavior of an operation. often, in particular in the context of scripting languages, a full specification may be cumbersome to state and may not even be desired. in such cases, a partial specification, which describes selected aspects of the behavior, may be used to raise the confidence in an implementation of the operation to a reasonable level. we propose a novel kind of contract for object-based languages that specifies the side effects of an operation with access permissions. an access permission contract uses sets of access paths to express read and write permissions for the properties of the objects accessible from the operation. we specify a monitoring semantics for access permission contracts and implement this semantics in a contract system for javascript. we prove soundness and stability of violation under increasing aliasing for our semantics. applications of access permission contracts include enforcing modularity, test-driven development, program understanding, and regression testing. with respect to testing and understanding, we find that adding access permissions to contracts increases the effectiveness of error detection through contract monitoring by 6-13%. © 2012 acm.",access permission contracts for scripting languages
1832,2-s2.0-84855658708,10.1109/MIC.2011.81,Is the browser the side for templating?,Garcia-Izquierdo F.J.,IEEE Internet Computing,2012-01-01,"Browser-side templating (BST) is a valid alternative for Web development, even when it comes to building accessible applications. BST processes templates in the browser using a JavaScript-coded engine, providing significant performance improvements and making model-view separation a reality. However, it also has significant drawbacks. BST's dependence on JavaScript affects its accessibility and hides the delivered pages' content from search engines, hampering Web visibility. The authors confront this dilemma and propose a technique that lets BST be accessible and semantically crawlable, while preserving its advantages. © 2006 IEEE.",browser-side templating | BST | Software engineering in Internet applications | Web browsers | Web templates | website development tools,3,61-68,Journal,Article,2.0,"Garcia-Izquierdo, Francisco J.;Izquierdo, Raul",27567718000;13005901800,Universidad de La Rioja;Universidad de Oviedo,Spain;Spain,"browser-side templating (bst) is a valid alternative for web development, even when it comes to building accessible applications. bst processes templates in the browser using a javascript-coded engine, providing significant performance improvements and making model-view separation a reality. however, it also has significant drawbacks. bst's dependence on javascript affects its accessibility and hides the delivered pages' content from search engines, hampering web visibility. the authors confront this dilemma and propose a technique that lets bst be accessible and semantically crawlable, while preserving its advantages. © 2006 ieee.",is the browser the side for templating?
1834,2-s2.0-83755220993,10.1109/NWeSP.2011.6088206,On the development of browser games-Technologies of an emerging genre,Vanhatupa J.M.,"Proceedings of the 2011 7th International Conference on Next Generation Web Services Practices, NWeSP 2011",2011-12-22,"Browser games are played directly in web browsers. Consequently they do not need software installation. A modern browser game is a sophisticated combination of client and server software. Nowadays there is a wide range of different technologies used to implement browser games. Traditional implementation technologies have gained new competitors, browser plugin players, which allow sophisticated graphics. In this paper we present technologies that are used to implement browser games and also accessories used in those. Towards the end of the paper we also discuss the future of the browser game genre. © 2011 IEEE.",browser games | multiplayer games | web technologies,3,363-368,Conference Proceeding,Conference Paper,1.0,"Vanhatupa, Juha Matti",37017878500,Tampere University,Finland,"browser games are played directly in web browsers. consequently they do not need software installation. a modern browser game is a sophisticated combination of client and server software. nowadays there is a wide range of different technologies used to implement browser games. traditional implementation technologies have gained new competitors, browser plugin players, which allow sophisticated graphics. in this paper we present technologies that are used to implement browser games and also accessories used in those. towards the end of the paper we also discuss the future of the browser game genre. © 2011 ieee.",on the development of browser games-technologies of an emerging genre
1835,2-s2.0-83455195723,10.1109/WSE.2011.6081820,Objects in the cloud may be closer than they appear: Towards a taxonomy of web-based software,Taivalsaari A.,"Proceedings - 13th IEEE International Symposium on Web Systems Evolution, WSE 2011",2011-12-20,"The model of computation in which software is downloaded and/or run dynamically from the network is commonly referred to as cloud computing. Historically, cloud computing has implied the use of thin clients, i.e., an approach in which the majority of computation is performed on the server side. However, in recent years the landscape of cloud computing has become quite diverse. This is partly because client computers and devices in cloud-based systems have become richer and far more powerful, and partly because the capabilities of the web browser as an application platform have increased substantially. In fact, with the upcoming HTML5 and WebGL standards, we anticipate client computers and devices to take a much more encompassing role in cloud computing. Additionally, the rapidly increasing use of mobile devices will have a dramatic impact on the use of cloud-based systems. In this paper we analyze the different flavors of cloud computing, with an attempt to classify web-based computing systems and to facilitate discussion and reasoning about such systems in general. © 2011 IEEE.",cloud computing | web applications | web evolution | web-based software development,8,59-64,Conference Proceeding,Conference Paper,2.0,"Taivalsaari, Antero;Mikkonen, Tommi",6507045147;54420813700,Nokia Corporation;Tampere University,Finland;Finland,"the model of computation in which software is downloaded and/or run dynamically from the network is commonly referred to as cloud computing. historically, cloud computing has implied the use of thin clients, i.e., an approach in which the majority of computation is performed on the server side. however, in recent years the landscape of cloud computing has become quite diverse. this is partly because client computers and devices in cloud-based systems have become richer and far more powerful, and partly because the capabilities of the web browser as an application platform have increased substantially. in fact, with the upcoming html5 and webgl standards, we anticipate client computers and devices to take a much more encompassing role in cloud computing. additionally, the rapidly increasing use of mobile devices will have a dramatic impact on the use of cloud-based systems. in this paper we analyze the different flavors of cloud computing, with an attempt to classify web-based computing systems and to facilitate discussion and reasoning about such systems in general. © 2011 ieee.",objects in the cloud may be closer than they appear: towards a taxonomy of web-based software
1836,2-s2.0-82955234150,10.1109/SEAA.2011.35,The web as an application platform: The Saga continues,Taivalsaari A.,"Proceedings - 37th EUROMICRO Conference on Software Engineering and Advanced Applications, SEAA 2011",2011-12-12,"The World Wide Web is the most powerful medium for information sharing and distribution in the history of humankind. In this paper we take a look at the evolution of the Web from a relatively simple document sharing system to a massively popular, general purpose application and content distribution environment. We focus especially on the rapidly increasing use of the Web as a software platform. So far, a number of obstacles have hindered the development and deployment of full-fledged, truly interactive web applications. However, emerging standards such as HTML5 and Web GLare removing the limitations, and transforming the Web into a real application platform. We believe that in the future the use of conventional binary programs will be limited to system software, whereas the vast majority of end user software will be developed using web technologies. © 2011 IEEE.",HTML5 | web evolution | web programming | web-based software development | WebGL,33,170-174,Conference Proceeding,Conference Paper,2.0,"Taivalsaari, Antero;Mikkonen, Tommi",6507045147;54420813700,Nokia Corporation;Tampere University,Finland;Finland,"the world wide web is the most powerful medium for information sharing and distribution in the history of humankind. in this paper we take a look at the evolution of the web from a relatively simple document sharing system to a massively popular, general purpose application and content distribution environment. we focus especially on the rapidly increasing use of the web as a software platform. so far, a number of obstacles have hindered the development and deployment of full-fledged, truly interactive web applications. however, emerging standards such as html5 and web glare removing the limitations, and transforming the web into a real application platform. we believe that in the future the use of conventional binary programs will be limited to system software, whereas the vast majority of end user software will be developed using web technologies. © 2011 ieee.",the web as an application platform: the saga continues
1837,2-s2.0-82955221675,10.1109/SEAA.2011.25,Extensible polyglot programming support in existing component frameworks,Keznikl J.,"Proceedings - 37th EUROMICRO Conference on Software Engineering and Advanced Applications, SEAA 2011",2011-12-12,"Utilization of various agile development practices brings demand of short development cycle with stress on early deployment and rapid delivery. Such practices require techniques permitting rapid prototyping of systems, corresponding tests and simulations. One of the well-adopted rapid prototyping techniques is polyglot programming combining multiple, mainly scripting, languages during development of systems. This permits the use of a specialized language for dedicated system concerns and also allows for a continuous change and re-deployment of implementation. Despite the advantages, rapid prototyping with help of polyglot programming is still not well supported in the domain of component-based systems, which makes it difficult to quickly prototype and test these systems. To address the obstacle, the paper describes a general technique for transparent and extensible combining of multiple languages for purpose of rapid prototyping during development of component-based systems with help of advanced component frameworks. © 2011 IEEE.",controllers | interface interceptors | polyglot programming | rapid prototyping | scripting languages,0,107-115,Conference Proceeding,Conference Paper,4.0,"Keznikl, Jaroslav;Malohlava, Michal;Bures, Tomáš;Hnětynka, Petr",54407236500;24576934100;22333488900;6507967973,Institute of Computer Science of the Academy of Sciences of the Czech Republic;Charles University,Czech Republic;Czech Republic,"utilization of various agile development practices brings demand of short development cycle with stress on early deployment and rapid delivery. such practices require techniques permitting rapid prototyping of systems, corresponding tests and simulations. one of the well-adopted rapid prototyping techniques is polyglot programming combining multiple, mainly scripting, languages during development of systems. this permits the use of a specialized language for dedicated system concerns and also allows for a continuous change and re-deployment of implementation. despite the advantages, rapid prototyping with help of polyglot programming is still not well supported in the domain of component-based systems, which makes it difficult to quickly prototype and test these systems. to address the obstacle, the paper describes a general technique for transparent and extensible combining of multiple languages for purpose of rapid prototyping during development of component-based systems with help of advanced component frameworks. © 2011 ieee.",extensible polyglot programming support in existing component frameworks
1846,2-s2.0-84863022642,10.1109/eScience.2011.13,"Investigating the use of gadgets, widgets, and OpenSocial to build science gateways",Guo Z.,"Proceedings - 2011 7th IEEE International Conference on eScience, eScience 2011",2011-12-01,"Many science applications require more and more computing power as the amount of input data keeps increasing. To simplify using large-scale clusters and complicated application codes, and to facilitate cross-disciplinary collaboration, there has been substantial research and development work on Web-based science gateways. With numerous gateways needing to be developed for many different scientific domains, there has also been a long-standing need for reusable codes and extensible component models. During the previous decade, the component model for many gateways was the Java port let. To overcome some of the port let model's limitations, new gateways take a different approach that utilizes modern Web technologies. In this paper, we examine the use of new standards such as Open Social, Gadgets, and W3C Widgets to build science gateway user interfaces. These standards overcome many shortcomings of the older port let development model. As general-purpose Web standards, however, they lack support for specialized science gateway requirements and so must be extended. We propose a generic architecture in which Open Social is integrated with backend services and grid infrastructures. We implement and evaluate these concepts in the Gadget Container, software developed by the authors. © 2011 IEEE.",grid | OpenSocial | science gateway | Web 2.0,1,31-38,Conference Proceeding,Conference Paper,4.0,"Guo, Zhenhua;Singh, Raminderjeet;Pierce, Marlon;Liu, Yan",44960947300;55496966600;8982800200;55742169500,"Indiana University Bloomington;Luddy School of Informatics, Computing, and Engineering;University of Illinois Urbana-Champaign",United States;United States;United States,"many science applications require more and more computing power as the amount of input data keeps increasing. to simplify using large-scale clusters and complicated application codes, and to facilitate cross-disciplinary collaboration, there has been substantial research and development work on web-based science gateways. with numerous gateways needing to be developed for many different scientific domains, there has also been a long-standing need for reusable codes and extensible component models. during the previous decade, the component model for many gateways was the java port let. to overcome some of the port let model's limitations, new gateways take a different approach that utilizes modern web technologies. in this paper, we examine the use of new standards such as open social, gadgets, and w3c widgets to build science gateway user interfaces. these standards overcome many shortcomings of the older port let development model. as general-purpose web standards, however, they lack support for specialized science gateway requirements and so must be extended. we propose a generic architecture in which open social is integrated with backend services and grid infrastructures. we implement and evaluate these concepts in the gadget container, software developed by the authors. © 2011 ieee.","investigating the use of gadgets, widgets, and opensocial to build science gateways"
1847,2-s2.0-84856671593,10.1145/2093328.2093335,"Enterprise JavaScript with Jangaroo: Using ActionScript 3 for JavaScript ""programming in the large""",Gawecki A.,PLASTIC'11 - Proceedings of the 1st ACM SIGPLAN International Workshop on Programming Language and Systems Technologies for Internet Clients,2011-12-01,"By compiling ActionScript 3 to JavaScript, the Open Source project Jangaroo lets web developers utilize a superior language for building large scale web applications. Since JavaScript is used as the target language, no browser plug-in is needed to run Jangaroo applications. Jangaroo reuses and provides professional tools supporting the complete software development lifecycle. CoreMedia uses the Jangaroo tool chain extensively to aid the development of CoreMedia Studio, a large scale web application which provides the user interface for the CoreMedia Web Content Management System. This paper gives an overview of Jangaroo and offers insight into concepts and inner workings of the Jangaroo compiler and runtime support. © 2011 ACM.",actionscript | browser | compilers | flash | javascript | opensource | programming in the large | ria,0,33-38,Conference Proceeding,Conference Paper,2.0,"Gawecki, Andreas;Wienberg, Frank",54956245400;6506209991,CoreMedia,Germany,"by compiling actionscript 3 to javascript, the open source project jangaroo lets web developers utilize a superior language for building large scale web applications. since javascript is used as the target language, no browser plug-in is needed to run jangaroo applications. jangaroo reuses and provides professional tools supporting the complete software development lifecycle. coremedia uses the jangaroo tool chain extensively to aid the development of coremedia studio, a large scale web application which provides the user interface for the coremedia web content management system. this paper gives an overview of jangaroo and offers insight into concepts and inner workings of the jangaroo compiler and runtime support. © 2011 acm.","enterprise javascript with jangaroo: using actionscript 3 for javascript ""programming in the large"""
1848,2-s2.0-84856651170,10.1145/2093328.2093338,Scalable quality for web-based games,Erbad A.,PLASTIC'11 - Proceedings of the 1st ACM SIGPLAN International Workshop on Programming Language and Systems Technologies for Internet Clients,2011-12-01,"As the Web has grown in popularity, web applications have started to rival their desktop counterparts. An important class of such applications is interactive multimedia: games, animations, and interactive visualizations. Unlike many early web applications, these applications are latency sensitive and processing (CPU and graphics) intensive. As web applications execute on a wide range of hardware from phones to powerful desktops and dynamically share these platforms with other applications, resolving the conflict between timeliness, application quality, and CPU utilization is a challenge. We propose scalable quality, which consists of application-defined policies and an adaptive execution layer that includes HTML5 worker threads. This paper describes our adaptive approach to maximize quality according to available resources. We also explore the challenges of using web workers in a real game and share our initial design decisions for concurrent web-based game development. © 2011 ACM.",javascript | real-time | web worker | web-based games,0,57-60,Conference Proceeding,Conference Paper,3.0,"Erbad, Aiman M.;Hutchinson, Norman C.;Krasic, Charles",24528481900;7007086001;15132264300,The University of British Columbia;Google LLC,Canada;United States,"as the web has grown in popularity, web applications have started to rival their desktop counterparts. an important class of such applications is interactive multimedia: games, animations, and interactive visualizations. unlike many early web applications, these applications are latency sensitive and processing (cpu and graphics) intensive. as web applications execute on a wide range of hardware from phones to powerful desktops and dynamically share these platforms with other applications, resolving the conflict between timeliness, application quality, and cpu utilization is a challenge. we propose scalable quality, which consists of application-defined policies and an adaptive execution layer that includes html5 worker threads. this paper describes our adaptive approach to maximize quality according to available resources. we also explore the challenges of using web workers in a real game and share our initial design decisions for concurrent web-based game development. © 2011 acm.",scalable quality for web-based games
1849,2-s2.0-84855768546,10.1109/VAST.2011.6102446,Obvious: A meta-toolkit to encapsulate information visualization toolkits - One toolkit to bind them all,Fekete J.D.,"VAST 2011 - IEEE Conference on Visual Analytics Science and Technology 2011, Proceedings",2011-12-01,"This article describes ""Obvious"": a meta-toolkit that abstracts and encapsulates information visualization toolkits implemented in the Java language. It intends to unify their use and postpone the choice of which concrete toolkit(s) to use later-on in the development of visual analytics applications. We also report on the lessons we have learned when wrapping popular toolkits with Obvious, namely Prefuse, the InfoVis Toolkit, partly Improvise, JUNG and other data management libraries. We show several examples on the uses of Obvious, how the different toolkits can be combined, for instance sharing their data models. We also show how Weka and Rapid-Miner, two popular machine-learning toolkits, have been wrapped with Obvious and can be used directly with all the other wrapped toolkits. We expect Obvious to start a co-evolution process: Obvious is meant to evolve when more components of Information Visualization systems will become consensual. It is also designed to help information visualization systems adhere to the best practices to provide a higher level of interoperability and leverage the domain of visual analytics. © 2011 IEEE.",D.2.11 [Software]: Software Architectures - Data abstraction | D.2.13 [Software]: Reusable Software - Domain engineering | K.6.3 [Software]: Software Management - Software process,12,91-100,Conference Proceeding,Conference Paper,4.0,"Fekete, Jean Daniel;Hémery, Pierre Luc;Baudel, Thomas;Wood, Jo",7005772385;40561084600;12239980100;55464292800,"Compagnie IBM France;City, University of London;INRIA Institut National de Recherche en Informatique et en Automatique",France;United Kingdom;France,"this article describes ""obvious"": a meta-toolkit that abstracts and encapsulates information visualization toolkits implemented in the java language. it intends to unify their use and postpone the choice of which concrete toolkit(s) to use later-on in the development of visual analytics applications. we also report on the lessons we have learned when wrapping popular toolkits with obvious, namely prefuse, the infovis toolkit, partly improvise, jung and other data management libraries. we show several examples on the uses of obvious, how the different toolkits can be combined, for instance sharing their data models. we also show how weka and rapid-miner, two popular machine-learning toolkits, have been wrapped with obvious and can be used directly with all the other wrapped toolkits. we expect obvious to start a co-evolution process: obvious is meant to evolve when more components of information visualization systems will become consensual. it is also designed to help information visualization systems adhere to the best practices to provide a higher level of interoperability and leverage the domain of visual analytics. © 2011 ieee.",obvious: a meta-toolkit to encapsulate information visualization toolkits - one toolkit to bind them all
1850,2-s2.0-84855693683,10.1145/2076732.2076770,ASIDE: IDE support for web application security,Xie J.,ACM International Conference Proceeding Series,2011-12-01,"Many of today's application security vulnerabilities are introduced by software developers writing insecure code. This may be due to either a lack of understanding of secure programming practices, and/or developers' lapses of attention on security. Much work on software security has focused on detecting software vulnerabilities through automated analysis techniques. While they are effective, we believe they are not sufficient. We propose to increase developer awareness and promote practice of secure programming by interactively reminding programmers of secure programming practices inside Integrated Development Environments (IDEs). We have implemented a proof-of-concept plugin for Eclipse and Java. Initial evaluation results show that this approach can detect and address common web application vulnerabilities and can serve as an effective aid for programmers. Our approach can also effectively complement existing software security best practices and significantly increase developer productivity. Copyright 2011 ACM.",Application security | Interactive support | Secure programming | Secure software development,50,267-276,Conference Proceeding,Conference Paper,4.0,"Xie, Jing;Chu, Bill;Lipford, Heather Richter;Melton, John T.",55478201900;36918104500;25926003900;50262437700,The University of North Carolina at Charlotte,United States,"many of today's application security vulnerabilities are introduced by software developers writing insecure code. this may be due to either a lack of understanding of secure programming practices, and/or developers' lapses of attention on security. much work on software security has focused on detecting software vulnerabilities through automated analysis techniques. while they are effective, we believe they are not sufficient. we propose to increase developer awareness and promote practice of secure programming by interactively reminding programmers of secure programming practices inside integrated development environments (ides). we have implemented a proof-of-concept plugin for eclipse and java. initial evaluation results show that this approach can detect and address common web application vulnerabilities and can serve as an effective aid for programmers. our approach can also effectively complement existing software security best practices and significantly increase developer productivity. copyright 2011 acm.",aside: ide support for web application security
1852,2-s2.0-84855458189,10.1109/ASE.2011.6100110,Client-side web application slicing,Maras J.,"2011 26th IEEE/ACM International Conference on Automated Software Engineering, ASE 2011, Proceedings",2011-12-01,"Highly interactive web applications that offer user experience and responsiveness of standard desktop applications are becoming prevalent in the web application domain. However, with these benefits come certain drawbacks. For example, the event-based architectural style, and poor support for code organization, often lead to a situation where code responsible for a certain behavior is intermixed with irrelevant code. This makes development, debugging and reuse difficult. One way of locating code implementing a certain behavior is program slicing, a method that, given a subset of a program's behavior, reduces the program to a minimal form that still produces that behavior. In this paper we present a semi-automatic client-side web application slicing method, describe the web page dependency graph, and show how it can be used to extract only the code implementing a certain behavior. © 2011 IEEE.",code reuse | dynamic program slicing | JavaScript | web application,8,504-507,Conference Proceeding,Conference Paper,3.0,"Maras, Josip;Carlson, Jan;Crnković, Ivica",36023615200;7402114423;6701375391,Mälardalen Research and Technology Centre;Sveučilište u Splitu,Sweden;Croatia,"highly interactive web applications that offer user experience and responsiveness of standard desktop applications are becoming prevalent in the web application domain. however, with these benefits come certain drawbacks. for example, the event-based architectural style, and poor support for code organization, often lead to a situation where code responsible for a certain behavior is intermixed with irrelevant code. this makes development, debugging and reuse difficult. one way of locating code implementing a certain behavior is program slicing, a method that, given a subset of a program's behavior, reduces the program to a minimal form that still produces that behavior. in this paper we present a semi-automatic client-side web application slicing method, describe the web page dependency graph, and show how it can be used to extract only the code implementing a certain behavior. © 2011 ieee.",client-side web application slicing
1854,2-s2.0-81355123348,10.1007/s10586-011-0166-7,Aspect-oriented development of cluster computing software,Han H.,Cluster Computing,2011-12-01,"In complex software systems, modularity and readability tend to be degraded owing to inseparable interactions between concerns that are distinct features in a program. Such interactions result in tangled code that is hard to develop and maintain. Aspect-Oriented Programming (AOP) is a powerful method for modularizing source code and for decoupling cross-cutting concerns. A decade of growing research on AOP has brought the paradigm into many exciting areas. However, pioneering work on AOP has not flourished enough to enrich the design of distributed systems using the refined AOP paradigm. This article investigates three case studies that cover time-honored issues such as fault-tolerant computing, network heterogeneity, and object replication in the cluster computing community using the AOP paradigm. The aspects that we define here are simple, intuitive, and reusable. Our intensive experiences show that (i) AOP can improve the modularity of cluster computing software by separating the source code into base and instrumented parts, and (ii) AOP helps developers to deploy additional features to legacy cluster computing software without harming code modularity and system performance. © 2011 Springer Science+Business Media, LLC.",Aspect-Oriented Programming | Fault tolerance | Heterogeneity | Key-value storage | Message-passing interface | Object replication,3,357-375,Journal,Article,3.0,"Han, Hyuck;Jung, Hyungsoo;Yeom, Heon Y.",8959850500;24511988200;7006767846,School of Computer Science;Seoul National University,Australia;South Korea,"in complex software systems, modularity and readability tend to be degraded owing to inseparable interactions between concerns that are distinct features in a program. such interactions result in tangled code that is hard to develop and maintain. aspect-oriented programming (aop) is a powerful method for modularizing source code and for decoupling cross-cutting concerns. a decade of growing research on aop has brought the paradigm into many exciting areas. however, pioneering work on aop has not flourished enough to enrich the design of distributed systems using the refined aop paradigm. this article investigates three case studies that cover time-honored issues such as fault-tolerant computing, network heterogeneity, and object replication in the cluster computing community using the aop paradigm. the aspects that we define here are simple, intuitive, and reusable. our intensive experiences show that (i) aop can improve the modularity of cluster computing software by separating the source code into base and instrumented parts, and (ii) aop helps developers to deploy additional features to legacy cluster computing software without harming code modularity and system performance. © 2011 springer science+business media, llc.",aspect-oriented development of cluster computing software
1856,2-s2.0-81455143936,10.1109/PCI.2011.31,Log file analysis of e-commerce systems in rich internet web 2.0 applications,Aivalis C.J.,"Proceedings - 2011 Panhellenic Conference on Informatics, PCI 2011",2011-11-23,"This paper describes the implications of the new trends in web development languages on log file analysis for e-commerce. The new trends in Software Development and the available Web Analytics technologies are explained. The focus is placed on the diversifications introduced to the traces left on the system that by Rich Internet Applications (RIAs). Finally a novel hybrid solution is proposed that is based on the junction of log files with operational data and page tagging, which allows even exacter measurements of customer behavior. It allows a customization of the Analysis Tool and survives the shift of the technologies. © 2011 IEEE.",e-commerce | Gwt | Javascript | Log file analysis | Rich internet applications | Web analytics,10,222-226,Conference Proceeding,Conference Paper,2.0,"Aivalis, Constantine J.;Boucouvalas, Anthony C.",36615118500;7004355712,University of Peloponnese,Greece,"this paper describes the implications of the new trends in web development languages on log file analysis for e-commerce. the new trends in software development and the available web analytics technologies are explained. the focus is placed on the diversifications introduced to the traces left on the system that by rich internet applications (rias). finally a novel hybrid solution is proposed that is based on the junction of log files with operational data and page tagging, which allows even exacter measurements of customer behavior. it allows a customization of the analysis tool and survives the shift of the technologies. © 2011 ieee.",log file analysis of e-commerce systems in rich internet web 2.0 applications
1857,2-s2.0-81455132897,10.1109/PCI.2011.63,"E-AirQuality: A dynamic web based application for evaluating the air quality index for the city of Kozani, Hellas",Ioannis S.,"Proceedings - 2011 Panhellenic Conference on Informatics, PCI 2011",2011-11-23,"The purpose of this work is to provide access to meteorological data as well as information of the status of air quality for the city of Kozani in real time with a userfriendly interface. The application has been developed using only open source software . MySQL has been used as a relational database management system, PHP as the scripting language for the development of the application and to connect the application to the database and Javascript/HTML for the user interface programming . The users are separated to two different groups (simple users-visitors and authorised users). Each group is provided by a number of functionalities. © 2011 IEEE.",Air quality index | MySql | Open source software | PHP | Web based application,6,171-174,Conference Proceeding,Conference Paper,3.0,"Ioannis, Skordas;Fragulis, George F.;Triantafyllou, Athanassios G.",6507629579;6602402881;7006035703,University of Western Macedonia,Greece,"the purpose of this work is to provide access to meteorological data as well as information of the status of air quality for the city of kozani in real time with a userfriendly interface. the application has been developed using only open source software . mysql has been used as a relational database management system, php as the scripting language for the development of the application and to connect the application to the database and javascript/html for the user interface programming . the users are separated to two different groups (simple users-visitors and authorised users). each group is provided by a number of functionalities. © 2011 ieee.","e-airquality: a dynamic web based application for evaluating the air quality index for the city of kozani, hellas"
1858,2-s2.0-81355142068,10.1145/2048147.2048220,"To inclusive design through contextually extended IoC- Infusion IoC, a JavaScript library and mentality for scalable development of accessible and maintainable systems",Basman A.,"SPLASH'11 Compilation - Proceedings of OOPSLA'11, Onward! 2011, GPCE'11, DLS'11, and SPLASH'11 Companion",2011-11-22,"Using current software development techniques, code and designs are often unmaintainable from the point of inception. Code is brittle and hard to refactor, hard to press to new purposes, and hard to understand. Here we present a system aimed at creating a model for scalable development, addressing this and several other critical problems in software construction. Such an aim is far from new, and has resembled the aims of each generation of software methodologists over the last 50 years. It deserves comment why these aims have so signally failed to be achieved, and we will present arguments as to why the combination of techniques explained here could expect to lead to novel results. Software products of today are notoriously unadaptable. An application which meets need A generally cannot be extended to meet apparently very similar need A′ without something resembling ""software engineering"". Applications present users with a ""take it or leave it"" proposition - if the software doesn't happen to meet a user's needs or preferences, there's no way to change it without writing more code, which is out of reach for most users. Indeed, software regularly fails to be easily adaptable to meet the needs of users with differing needs, such as in the case of accessibility. These ""precarious values"" - accessibility and usability with different devices, languages, and personal needs - are typically left until the end or ignored, and represent a significant expense in traditional approaches to software development. Often these needs are met by developing a largely unrelated version of the application, requiring maintenance of additional, separate code bases. Our aim is to enable Inclusive Design [3], whose objective is to satisfy the needs and desires of the broadest range of users possible. Every designer sets out with this objective to a certain extent, but as well as limitations of intent, there are also strong limitations placed by the technology and economics of software development. Due to the poor scaling characteristics of current techniques, even meeting one set of relatively inflexible needs can be an expensive undertaking, especially over the long term. To address these problems of adaptability, we present a model for software construction, together with a base library, Fluid Infusion, implemented in the JavaScript language. Fluid Infusion implements an Inversion of Control model, Infusion IoC, which features a notion of context as the basis for adaptability, resolved in a scope modelled in terms of a data structure, a component tree expressing the computation to be performed. In the Context-Oriented Programming community [7], this model of scoping is known as structural scoping. We will also work with a model of transparent state in which all modifiable state of interest to users is held in publicly visible locations, indexed by path strings. This model for state is isomorphic to that modeled by JSON [6], a well-known state model derived from, but not limited to, the JavaScript language. Instantiation in the model is handled by an Inversion of Control system extended from the model of similar system such as the Spring Framework or Pico first developed in the Java language. We relate such systems to goal-directed resolution systems such as Prolog, and show that they have beneficial properties such as homoiconicity [2] which have not been seen in a strong or widespread form since the days of LISP. We exhibit some cases to show how the framework enables, through a simple declarative syntax, types of adaptation and composition that are hard or impossible using traditional models of polymorphism. We also relate Infusion IoC to other software methodologies such as Aspect-Oriented Programming and Context-Oriented Programming which have been found to greatly increase flexibility and expressiveness of designs. We conclude with some remarks on the applicability of the system to the parallelisation of irregular algorithms, and its relationship to upcoming developments in the ECMAScript 6 language specification.",Accessibility | Context-oriented programming | Inversion of control | JavaScript | JSON | Transparent state,4,237-255,Conference Proceeding,Conference Paper,3.0,"Basman, Antranig;Lewis, Clayton;Clark, Colin",8747176500;35268993400;55454812100,The Ontario College of Art and Design University;University of Colorado Boulder,Canada;United States,"using current software development techniques, code and designs are often unmaintainable from the point of inception. code is brittle and hard to refactor, hard to press to new purposes, and hard to understand. here we present a system aimed at creating a model for scalable development, addressing this and several other critical problems in software construction. such an aim is far from new, and has resembled the aims of each generation of software methodologists over the last 50 years. it deserves comment why these aims have so signally failed to be achieved, and we will present arguments as to why the combination of techniques explained here could expect to lead to novel results. software products of today are notoriously unadaptable. an application which meets need a generally cannot be extended to meet apparently very similar need a′ without something resembling ""software engineering"". applications present users with a ""take it or leave it"" proposition - if the software doesn't happen to meet a user's needs or preferences, there's no way to change it without writing more code, which is out of reach for most users. indeed, software regularly fails to be easily adaptable to meet the needs of users with differing needs, such as in the case of accessibility. these ""precarious values"" - accessibility and usability with different devices, languages, and personal needs - are typically left until the end or ignored, and represent a significant expense in traditional approaches to software development. often these needs are met by developing a largely unrelated version of the application, requiring maintenance of additional, separate code bases. our aim is to enable inclusive design [3], whose objective is to satisfy the needs and desires of the broadest range of users possible. every designer sets out with this objective to a certain extent, but as well as limitations of intent, there are also strong limitations placed by the technology and economics of software development. due to the poor scaling characteristics of current techniques, even meeting one set of relatively inflexible needs can be an expensive undertaking, especially over the long term. to address these problems of adaptability, we present a model for software construction, together with a base library, fluid infusion, implemented in the javascript language. fluid infusion implements an inversion of control model, infusion ioc, which features a notion of context as the basis for adaptability, resolved in a scope modelled in terms of a data structure, a component tree expressing the computation to be performed. in the context-oriented programming community [7], this model of scoping is known as structural scoping. we will also work with a model of transparent state in which all modifiable state of interest to users is held in publicly visible locations, indexed by path strings. this model for state is isomorphic to that modeled by json [6], a well-known state model derived from, but not limited to, the javascript language. instantiation in the model is handled by an inversion of control system extended from the model of similar system such as the spring framework or pico first developed in the java language. we relate such systems to goal-directed resolution systems such as prolog, and show that they have beneficial properties such as homoiconicity [2] which have not been seen in a strong or widespread form since the days of lisp. we exhibit some cases to show how the framework enables, through a simple declarative syntax, types of adaptation and composition that are hard or impossible using traditional models of polymorphism. we also relate infusion ioc to other software methodologies such as aspect-oriented programming and context-oriented programming which have been found to greatly increase flexibility and expressiveness of designs. we conclude with some remarks on the applicability of the system to the parallelisation of irregular algorithms, and its relationship to upcoming developments in the ecmascript 6 language specification.","to inclusive design through contextually extended ioc- infusion ioc, a javascript library and mentality for scalable development of accessible and maintainable systems"
1859,2-s2.0-81255203477,10.1145/2047594.2047601,Free and open source software development of IT systems,Sabin M.,SIGITE'11 - Proceedings of the 2011 ACM Special Interest Group for Information Technology Education Conference,2011-11-21,"IT system development, integration, deployment, and administration benefit significantly from free and open source software (FOSS) tools and services. Affordability has been a compelling reason for adopting FOSS in computing curricula and equipping computing labs with support infrastructure. Using FOSS systems and services, however, is just the first step in taking advantage of how FOSS development principles and practices can impact student learning in IT degree programs. Above all, FOSS development of IT systems requires changes to how students, instructors, and other contributors work collaboratively and openly and get involved and invested in project activities. In this paper I examine the challenges to engage students in FOSS development projects proposed by real clients. A six-week course project revealed problems with adopting FOSS development and collaboration across different activities and roles that student team members have assumed. Despite these problems, students have showed a genuine and strong interest in gaining more practice with FOSS development. FOSS development teaching was further refined in two other courses to learn about adequate teaching strategies and the competencies that students achieve when they participate in FOSS development of IT systems. © 2011 ACM.",Collaboration | Free and open source software | IT system development,3,27-31,Conference Proceeding,Conference Paper,1.0,"Sabin, Mihaela",16029719800,University of New Hampshire Manchester,United States,"it system development, integration, deployment, and administration benefit significantly from free and open source software (foss) tools and services. affordability has been a compelling reason for adopting foss in computing curricula and equipping computing labs with support infrastructure. using foss systems and services, however, is just the first step in taking advantage of how foss development principles and practices can impact student learning in it degree programs. above all, foss development of it systems requires changes to how students, instructors, and other contributors work collaboratively and openly and get involved and invested in project activities. in this paper i examine the challenges to engage students in foss development projects proposed by real clients. a six-week course project revealed problems with adopting foss development and collaboration across different activities and roles that student team members have assumed. despite these problems, students have showed a genuine and strong interest in gaining more practice with foss development. foss development teaching was further refined in two other courses to learn about adequate teaching strategies and the competencies that students achieve when they participate in foss development of it systems. © 2011 acm.",free and open source software development of it systems
1860,2-s2.0-81255173018,10.1007/978-3-642-25126-9_79,Towards a reference architecture for mashups,Mikkonen T.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2011-11-21,"Software mashups - web applications that combine content from multiple web sites to an integrated experience - have rapidly become a popular trend. Due to the novelty of mashup development, methods, tools, and architectures for creating mashups are still rather undeveloped, and there is little engineering support behind them, even if the most common architectural requirements for composing mashups can be easily identified. In this paper we present a list of architectural issues and derive a reference architecture to serve as a starting point for the design of new mashups. The long-term goal of our work is to facilitate the development and maintenance of robust, secure, and compelling mashups, and more generally ease the transition towards web-based software development. © 2011 Springer-Verlag.",mashups | Web applications | web programming,10,647-656,Book Series,Conference Paper,2.0,"Mikkonen, Tommi;Salminen, Arto",54420813700;36630946500,Tampere University,Finland,"software mashups - web applications that combine content from multiple web sites to an integrated experience - have rapidly become a popular trend. due to the novelty of mashup development, methods, tools, and architectures for creating mashups are still rather undeveloped, and there is little engineering support behind them, even if the most common architectural requirements for composing mashups can be easily identified. in this paper we present a list of architectural issues and derive a reference architecture to serve as a starting point for the design of new mashups. the long-term goal of our work is to facilitate the development and maintenance of robust, secure, and compelling mashups, and more generally ease the transition towards web-based software development. © 2011 springer-verlag.",towards a reference architecture for mashups
1861,2-s2.0-80955131426,10.1109/ICECENG.2011.6057396,Design and development of maize cultivation technology query software based on XML data exchange,Liu T.,"2011 International Conference on Electrical and Control Engineering, ICECE 2011 - Proceedings",2011-11-16,"In the maize growing season, weather disasters, which restricts high and stable yield of maize. For maize farmers may encounter in a variety of disasters, disaster resilience cultivation techniques needed to develop resilience reduction of maize cultivation technology query software, the software is based on XML data exchange technology to. NET Framework as a basis for the environment, the choice of SQLite as a database management system, using Microsoft Visual Studio 2008 as a development tool, the use of C # programming language and JavaScript, T-SQL, XML, XSLT and other languages to achieve stress tolerance in maize cultivation information query, maize disease control information, response Real-time query and its query results output function. The software for the management staff at all levels of agricultural production, agricultural extension workers, farmers planting maize and other maize related personnel to provide technical support for disaster reduction and service resilience. © 2011 IEEE.",Cultivation Techniques | Maize | Query | Resilience Mitigation | XML,0,140-142,Conference Proceeding,Conference Paper,3.0,"Liu, Tonghai;Liang, Jie;Li, Shaokun",56131813200;54408788900;16233467800,Tianjin Agricultural University;China Academy of Agricultural Sciences,China;China,"in the maize growing season, weather disasters, which restricts high and stable yield of maize. for maize farmers may encounter in a variety of disasters, disaster resilience cultivation techniques needed to develop resilience reduction of maize cultivation technology query software, the software is based on xml data exchange technology to. net framework as a basis for the environment, the choice of sqlite as a database management system, using microsoft visual studio 2008 as a development tool, the use of c # programming language and javascript, t-sql, xml, xslt and other languages to achieve stress tolerance in maize cultivation information query, maize disease control information, response real-time query and its query results output function. the software for the management staff at all levels of agricultural production, agricultural extension workers, farmers planting maize and other maize related personnel to provide technical support for disaster reduction and service resilience. © 2011 ieee.",design and development of maize cultivation technology query software based on xml data exchange
1862,2-s2.0-84871443546,10.1515/IJDHD.2011.047,Exploring intelligent agents in three-dimensional games for cognitive stimulation,Da Costa R.,International Journal on Disability and Human Development,2011-11-01,"Despite much research effort addressing the development of environments for virtual rehabilitation processes, few of them consider a modeling step before the system implementation. Our previous experience in developing virtual environments for stimulating cognitive functions stresses the necessity of adopting some software engineering practices. System modeling opens new possibilities to extend or integrate the system with other applications. The objective of this paper is to introduce some technical aspects related to modeling and implementing a multi-agent game for training memory and attention. We explore the integration of multi-agent model methodologies and present initial results of an experiment made with two specifi c languages for building three-dimensional virtual environments. © 2011 by Walter de Gruyter ·Berlin · Boston.",Cognitive stimulation | Multi-agent system | Virtual reality,0,283-287,Journal,Review,4.0,"Da Costa, Rosa Maria Esteves Moreira;De Souza, Diogo Soares;Dos Santos, Israel Mendonça;Werneck, Vera Maria Benjamin",7006572375;55535261400;55534630000;6506702529,Universidade do Estado do Rio de Janeiro,Brazil,"despite much research effort addressing the development of environments for virtual rehabilitation processes, few of them consider a modeling step before the system implementation. our previous experience in developing virtual environments for stimulating cognitive functions stresses the necessity of adopting some software engineering practices. system modeling opens new possibilities to extend or integrate the system with other applications. the objective of this paper is to introduce some technical aspects related to modeling and implementing a multi-agent game for training memory and attention. we explore the integration of multi-agent model methodologies and present initial results of an experiment made with two specifi c languages for building three-dimensional virtual environments. © 2011 by walter de gruyter ·berlin · boston.",exploring intelligent agents in three-dimensional games for cognitive stimulation
1863,2-s2.0-80455145036,10.1093/comjnl/bxr067,Type inference to optimize a hybrid statically and dynamically typed language,Ortin F.,Computer Journal,2011-11-01,"Dynamically typed languages are becoming increasingly popular for different software development scenarios such as Web engineering, rapid prototyping or the construction of applications that require runtime adaptiveness. In contrast, statically typed languages have undeniable advantages such as early type error detection and more opportunities for compiler optimizations. Since both approaches offer different benefits, hybrid statically and dynamically typed programming languages have emerged, and some statically typed languages have also incorporated dynamic typing capabilities. In this paper, we present the minimal core of StaDyn, a hybrid typing language that performs static type inference of both statically and dynamically typed references. The type information gathered by the compiler is used to generate efficient. NET code, obtaining a significant runtime performance improvement compared with C# 4.0 and Visual Basic 10. © The Author 2011. Published by Oxford University Press on behalf of The British Computer Society. All rights reserved.",hybrid static and dynamic typing | intersection types | runtime performance | type systems | union types,15,1901-1924,Journal,Article,1.0,"Ortin, Francisco",6602898630,Computational Reflection Research Group,Spain,"dynamically typed languages are becoming increasingly popular for different software development scenarios such as web engineering, rapid prototyping or the construction of applications that require runtime adaptiveness. in contrast, statically typed languages have undeniable advantages such as early type error detection and more opportunities for compiler optimizations. since both approaches offer different benefits, hybrid statically and dynamically typed programming languages have emerged, and some statically typed languages have also incorporated dynamic typing capabilities. in this paper, we present the minimal core of stadyn, a hybrid typing language that performs static type inference of both statically and dynamically typed references. the type information gathered by the compiler is used to generate efficient. net code, obtaining a significant runtime performance improvement compared with c# 4.0 and visual basic 10. © the author 2011. published by oxford university press on behalf of the british computer society. all rights reserved.",type inference to optimize a hybrid statically and dynamically typed language
1864,2-s2.0-80052857169,10.1016/j.autcon.2011.03.015,Optimal haulage routing of off-road dump trucks in construction and mining sites using Google Earth and a modified least-cost path algorithm,Choi Y.,Automation in Construction,2011-11-01,"This study presents new software, called Google Earth-based Optimal HAulage RouTing System (GEOHARTS), to improve the functionality of Google Earth for optimal haulage routing of off-road dump trucks in construction and mining sites. A modified least-cost path algorithm, which is applicable to working areas with both paved and unpaved temporary roads and can consider the effects of terrain relief and curves along a route on the route planning, was proposed and utilized for the software development. GEOHARTS can determine optimal haulage routes between loaders and dumps that ensure the least travel time or fuel consumption of off-road dump trucks and can visualize the results using an embedded 3D render window of Google Earth. The application to the Pasir open-pit coal mine in Indonesia demonstrates that GEOHARTS could provide a rational solution to support the truck haulage operations. © 2011 Elsevier B.V. All rights reserved.",GIS | Google Earth | Haulage operation | Off-road dump trucks | Route planning,46,982-997,Journal,Article,2.0,"Choi, Yosoon;Nieto, Antonio",23484346300;57189706780,Pukyong National University;Pennsylvania State University,South Korea;United States,"this study presents new software, called google earth-based optimal haulage routing system (geoharts), to improve the functionality of google earth for optimal haulage routing of off-road dump trucks in construction and mining sites. a modified least-cost path algorithm, which is applicable to working areas with both paved and unpaved temporary roads and can consider the effects of terrain relief and curves along a route on the route planning, was proposed and utilized for the software development. geoharts can determine optimal haulage routes between loaders and dumps that ensure the least travel time or fuel consumption of off-road dump trucks and can visualize the results using an embedded 3d render window of google earth. the application to the pasir open-pit coal mine in indonesia demonstrates that geoharts could provide a rational solution to support the truck haulage operations. © 2011 elsevier b.v. all rights reserved.",optimal haulage routing of off-road dump trucks in construction and mining sites using google earth and a modified least-cost path algorithm
1865,2-s2.0-80052262549,10.1016/j.measurement.2011.07.004,Developing a new interactive simulation environment with Macromedia Director for teaching applied dimensional metrology,Gómez E.,Measurement: Journal of the International Measurement Confederation,2011-11-01,"The purpose of this paper is to describe the objectives, methodology and structure of a virtual didactic environment developed by the educational research group New Teaching Methodologies in Mechanical Engineering and Manufacturing at the Technical University of Madrid, designed to carry out dimensional metrology practical lessons. This development has allowed teaching to be focused on the student in a DE-learning (driven electronic learning) environment capable of efficiently replacing the traditional method based on master classes and practical hands-on experience with real equipment. In fact, the developed environment directs and assists students, step by step, in their practical experience, proving dynamic and interactive through the use of animations, video and audio contributions, connections with hypertexts and simulations. The model presented in this work seeks a progressive adaptation to the new training paradigms, incorporating emerging communication technologies so that students can harness an even greater role that has hitherto been untapped, hence approaching one of the objectives in the Bologna process. The project has been undertaken entirely with the software house Macromedia: Director MX 2004 and Flash MX 2004, which has afforded the creation of a multimedia application with animations of the highest quality. Scripting languages (Lingo, JavaScript and ActionScript) have likewise been incorporated, permitting the evolution of even more complex elements for user interaction. The project has been undertaken in Spanish and English with a view to meeting the communication needs of students in a multicultural environment, in harmony with the framework program for didactic strategies in the European Higher Education Area. © 2011 Elsevier Ltd. All rights reserved.",Bologna process | DE-learning | Dimensional metrology,8,1730-1746,Journal,Article,5.0,"Gómez, E.;Maresca, P.;Caja, J.;Barajas, C.;Berzal, M.",56812450500;55493319400;23011753500;23011531300;23011490600,Universidad Politécnica de Madrid,Spain,"the purpose of this paper is to describe the objectives, methodology and structure of a virtual didactic environment developed by the educational research group new teaching methodologies in mechanical engineering and manufacturing at the technical university of madrid, designed to carry out dimensional metrology practical lessons. this development has allowed teaching to be focused on the student in a de-learning (driven electronic learning) environment capable of efficiently replacing the traditional method based on master classes and practical hands-on experience with real equipment. in fact, the developed environment directs and assists students, step by step, in their practical experience, proving dynamic and interactive through the use of animations, video and audio contributions, connections with hypertexts and simulations. the model presented in this work seeks a progressive adaptation to the new training paradigms, incorporating emerging communication technologies so that students can harness an even greater role that has hitherto been untapped, hence approaching one of the objectives in the bologna process. the project has been undertaken entirely with the software house macromedia: director mx 2004 and flash mx 2004, which has afforded the creation of a multimedia application with animations of the highest quality. scripting languages (lingo, javascript and actionscript) have likewise been incorporated, permitting the evolution of even more complex elements for user interaction. the project has been undertaken in spanish and english with a view to meeting the communication needs of students in a multicultural environment, in harmony with the framework program for didactic strategies in the european higher education area. © 2011 elsevier ltd. all rights reserved.",developing a new interactive simulation environment with macromedia director for teaching applied dimensional metrology
1866,2-s2.0-79959950510,10.1016/j.eswa.2011.04.214,A conceptual approach for development of educational Web-based e-testing system,Mustakerov I.,Expert Systems with Applications,2011-10-01,"The paper describes a conceptual approach for development of educational Web-based e-testing system. The system aims to improve the effectiveness of the learning process by providing features for flexible adjusting of the testing process. The tutors and learners can interact with the e-testing system by choosing different options for testing - easy questions, advanced questions, sequential or shuffle order, random generated questions within given range. The e-testing system can be used by students for self-testing or by tutors for official examination. When used for official examination the test results information is sent to the examiner by e-mail. The system files are stored on the server-side and are accessible through Web-browser. A prototype of e-testing system illustrating the proposed approach is developed by means of HTML and JavaScript languages. It was used for ""C Programming Language"" course students self-testing and official examination. The experimental results demonstrated that the implementation of the proposed approach is quite helpful to facilitate the understanding and implementation of teachers' attitudes toward Web-based e-testing tools application. © 2011 Elsevier Ltd. All rights reserved.",Educational information system | Interactive learning environments | Self-testing knowledge | Software architecture | Web-based system,14,14060-14064,Journal,Article,2.0,"Mustakerov, Ivan;Borissova, Daniela",23991365700;23990012600,"Institute of Information and Communication Technologies, Bulgarian Academy of Sciences",Bulgaria,"the paper describes a conceptual approach for development of educational web-based e-testing system. the system aims to improve the effectiveness of the learning process by providing features for flexible adjusting of the testing process. the tutors and learners can interact with the e-testing system by choosing different options for testing - easy questions, advanced questions, sequential or shuffle order, random generated questions within given range. the e-testing system can be used by students for self-testing or by tutors for official examination. when used for official examination the test results information is sent to the examiner by e-mail. the system files are stored on the server-side and are accessible through web-browser. a prototype of e-testing system illustrating the proposed approach is developed by means of html and javascript languages. it was used for ""c programming language"" course students self-testing and official examination. the experimental results demonstrated that the implementation of the proposed approach is quite helpful to facilitate the understanding and implementation of teachers' attitudes toward web-based e-testing tools application. © 2011 elsevier ltd. all rights reserved.",a conceptual approach for development of educational web-based e-testing system
1869,2-s2.0-80053049834,10.1109/DRPT.2011.5994142,A WebGL-based method for visualization of intelligent grid,Zhang W.,DRPT 2011 - 2011 4th International Conference on Electric Utility Deregulation and Restructuring and Power Technologies,2011-09-26,"For the web-based application of intelligent grid and security control, this paper introduces a visualization system model, which is based on the popular browsers with no plug-ins, to display components and their run-time states of intelligent grid. The model applies the X3DOM framework that base on WebGL to develop basic components of intelligent grid, which contains two-dimensional (2D) and three-dimensional (3D) contents by the core node of X3DOM. In order to realize runtime data display, the model describes interactive 3D animation with JavaScript and exchanges asynchronous data with server by using AJAX technology. In the case of 220KV lines loading rate, the pie charts indicate the percentage loadings on the lines, animated flows display the line flows, contours describe the runtime state of grid, and 3D cylinders mean the percentage loadings of transformers. This paper proposes an effective method to transfer the software development from conventional C/S (Client/Server) mode to B/S (Browser/Server) mode for the visualization of intelligent grid. The results show that the WebGL-based system model is feasible and practicable, and it increases the range of intelligent grid visualizations and reduces the maintenance costs. © 2011 IEEE.",AJAX | B/S (Browser/Server) | intelligent grid visualization | no plug-ins | WebGL | X3DOM,4,1546-1548,Conference Proceeding,Conference Paper,4.0,"Zhang, Weigang;Yuan, Hao;Wang, Jiangong;Yan, Zhonghua",50862188400;50862377300;50862107100;55513380500,"Shandong University, Weihai;Integrated Electronic Systems Lab. Co. Ltd.",China;China,"for the web-based application of intelligent grid and security control, this paper introduces a visualization system model, which is based on the popular browsers with no plug-ins, to display components and their run-time states of intelligent grid. the model applies the x3dom framework that base on webgl to develop basic components of intelligent grid, which contains two-dimensional (2d) and three-dimensional (3d) contents by the core node of x3dom. in order to realize runtime data display, the model describes interactive 3d animation with javascript and exchanges asynchronous data with server by using ajax technology. in the case of 220kv lines loading rate, the pie charts indicate the percentage loadings on the lines, animated flows display the line flows, contours describe the runtime state of grid, and 3d cylinders mean the percentage loadings of transformers. this paper proposes an effective method to transfer the software development from conventional c/s (client/server) mode to b/s (browser/server) mode for the visualization of intelligent grid. the results show that the webgl-based system model is feasible and practicable, and it increases the range of intelligent grid visualizations and reduces the maintenance costs. © 2011 ieee.",a webgl-based method for visualization of intelligent grid
1871,2-s2.0-80052324331,10.1109/CSSS.2011.5972224,Design and development of the CAI system based on network,Li Z.,"2011 International Conference on Computer Science and Service System, CSSS 2011 - Proceedings",2011-09-07,"The present conditions and existing problems of CAI system are analyzed. In order to improve the interactivity and intelligence and efficiency of the B/S-based networked CAI system the methods using the JavaBeans+JSP, Template technology for homepage design and database connection-pooling technology based on Java are discussed. The development environment of the CAI system is described. The designing methods and developing processes of the CAI system software using Java are introduced. The advantages of the CAI system using Java are summarized in this paper. © 2011 IEEE.",CAI | Java | multimedia | Network Education,0,1195-1197,Conference Proceeding,Conference Paper,1.0,"Li, Zhiqiang",55707176100,Zhongyuan University of Technology,China,"the present conditions and existing problems of cai system are analyzed. in order to improve the interactivity and intelligence and efficiency of the b/s-based networked cai system the methods using the javabeans+jsp, template technology for homepage design and database connection-pooling technology based on java are discussed. the development environment of the cai system is described. the designing methods and developing processes of the cai system software using java are introduced. the advantages of the cai system using java are summarized in this paper. © 2011 ieee.",design and development of the cai system based on network
1872,2-s2.0-80053585966,10.1109/MITP.2011.55,Toward unified web application development,Laine M.,IT Professional,2011-09-01,"Web application development in the context of the conventional three-tier architecture is complex, typically requiring a team of experts. Recent Web application architectures and frameworks simplify the development process, potentially turning tier-specific experts into one-person developer teams. © 2011 IEEE.",client/server and multitier systems | frameworks Internet applications | information technology | languages | Software architectures | Web design | Web strategies,9,30-36,Journal,Article,4.0,"Laine, Markku;Shestakov, Denis;Litvinova, Evgenia;Vuorimaa, Petri",52564000200;6603495026;52563953000;6603024155,Aalto University,Finland,"web application development in the context of the conventional three-tier architecture is complex, typically requiring a team of experts. recent web application architectures and frameworks simplify the development process, potentially turning tier-specific experts into one-person developer teams. © 2011 ieee.",toward unified web application development
1873,2-s2.0-79960715098,10.1109/C5.2011.9,The death of binary software: End user software moves to the web,Taivalsaari A.,"Proceedings - 9th International Conference on Creating, Connecting and Collaborating through Computing, C5 2011",2011-07-29,"The World Wide Web is the most powerful medium for information sharing and distribution in the history of humankind. The use of the Web is rapidly spreading into many new areas outside its original intended use, including its use as a platform for software applications. So far, a number of obstacles have hindered the development and deployment of full-fledged, truly interactive web applications. However, new emerging standards such as HTML5 and WebGL are removing the remaining limitations and transforming the Web into a real software platform. In this paper we argue that the trend towards web-based software will cause a paradigm shift in the software industry from binary applications to dynamically delivered web applications. In the future, the use of conventional binary programs will be limited to system software, whereas the vast majority of end user software will be developed using web technologies. All this will imply significant changes in the development, deployment and use of software, and open up interesting opportunities in software engineering research as well. © 2011 IEEE.",JavaScript | Lively Kernel | web applications | web programming,26,17-23,Conference Proceeding,Conference Paper,4.0,"Taivalsaari, Antero;Mikkonen, Tommi;Anttonen, Matti;Salminen, Arto",6507045147;54420813700;40661076400;36630946500,Nokia Corporation;Tampere University,Finland;Finland,"the world wide web is the most powerful medium for information sharing and distribution in the history of humankind. the use of the web is rapidly spreading into many new areas outside its original intended use, including its use as a platform for software applications. so far, a number of obstacles have hindered the development and deployment of full-fledged, truly interactive web applications. however, new emerging standards such as html5 and webgl are removing the remaining limitations and transforming the web into a real software platform. in this paper we argue that the trend towards web-based software will cause a paradigm shift in the software industry from binary applications to dynamically delivered web applications. in the future, the use of conventional binary programs will be limited to system software, whereas the vast majority of end user software will be developed using web technologies. all this will imply significant changes in the development, deployment and use of software, and open up interesting opportunities in software engineering research as well. © 2011 ieee.",the death of binary software: end user software moves to the web
1874,2-s2.0-79960417374,10.1061/41173(414)236,A real-time interface for railway hydraulic hazard forecasting,Peschel J.,World Environmental and Water Resources Congress 2011: Bearing Knowledge for Sustainability - Proceedings of the 2011 World Environmental and Water Resources Congress,2011-07-21,"In this work we present a new software tool, RHHMS (Railway Hydraulic Hazard Monitoring System), for real-time railway bridge hydraulic hazard forecasting. RHHMS is based on a combinatorial optimization approach to hydrologic measurement in ungagued semi-arid and arid catchments that provides a simple Google Maps-based interface for both numerical and graphical feedback to a user about the current and future hydraulic states of railway bridges in a given region. © 2011 ASCE.",Arid lands | Catchments | Forecasting | Hydraulics | Railroad bridges,1,2263-2272,Conference Proceeding,Conference Paper,3.0,"Peschel, Joshua;Brumbelow, Kelly;Cahill, Tony",8628042500;15622900300;43261109500,Texas A&amp;M University,United States,"in this work we present a new software tool, rhhms (railway hydraulic hazard monitoring system), for real-time railway bridge hydraulic hazard forecasting. rhhms is based on a combinatorial optimization approach to hydrologic measurement in ungagued semi-arid and arid catchments that provides a simple google maps-based interface for both numerical and graphical feedback to a user about the current and future hydraulic states of railway bridges in a given region. © 2011 asce.",a real-time interface for railway hydraulic hazard forecasting
1876,2-s2.0-79960336710,10.1007/978-3-642-21898-9_31,Using free open source software for intelligent geometric computing,Abánades M.A.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2011-07-19,"This paper describes some examples of fruitful cooperation between geometric software tools (in particular, GeoGebra) and a free open source computer algebra system, Sage (Software for Algebra and Geometry Experimentation). We collect some of our efforts for enhancing mathematics education via technologically rich environments. We show that a math teacher with no specialized programming knowledge can mix widespread resources to get motivating new teaching tools. Furthermore, we explore an exciting but barely used (even known!) characteristic of Sage: its use as a remote kernel. We test it by computing symbolic tasks in a dynamic geometry prototype that are currently out of scope of standard dynamic geometry software. Finally, we illustrate the development of web-based geometric resources by communicating GeoGebra and Sage through Javascript. © 2011 Springer-Verlag.",computer algebra systems | dynamic geometry | GeoGebra | Internet accessible mathematical computation | learning resources | Sage,0,353-367,Book Series,Conference Paper,4.0,"Abánades, Miguel A.;Botana, Francisco;Escribano, Jesús;Valcarce, José L.",6507791500;35727556700;23389007200;6507280259,Centro de Estudios Superiores Felipe II;Universidad Complutense de Madrid;Universidade de Vigo;IES Pontepedriña,Spain;Spain;Spain;Spain,"this paper describes some examples of fruitful cooperation between geometric software tools (in particular, geogebra) and a free open source computer algebra system, sage (software for algebra and geometry experimentation). we collect some of our efforts for enhancing mathematics education via technologically rich environments. we show that a math teacher with no specialized programming knowledge can mix widespread resources to get motivating new teaching tools. furthermore, we explore an exciting but barely used (even known!) characteristic of sage: its use as a remote kernel. we test it by computing symbolic tasks in a dynamic geometry prototype that are currently out of scope of standard dynamic geometry software. finally, we illustrate the development of web-based geometric resources by communicating geogebra and sage through javascript. © 2011 springer-verlag.",using free open source software for intelligent geometric computing
1877,2-s2.0-79960324092,10.1007/978-3-642-21931-3_37,HTAF: Hybrid testing automation framework to leverage local and global computing resources,Yim K.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2011-07-19,"In web application development, testing forms an increasingly large portion of software engineering costs due to the growing complexity and short time-to-market of these applications. This paper presents a hybrid testing automation framework (HTAF) that can automate routine works in testing and releasing web software. Using this framework, an individual software engineer can easily describe his routine software engineering tasks and schedule these described tasks by using both his local machine and global cloud computers in an efficient way. This framework is applied to commercial web software development processes. Our industry practice shows four example cases where the hybrid and decentralized architecture of HTAF is helpful at effectively managing both hardware resources and manpower required for testing and releasing web applications. © 2011 Springer-Verlag.",testing automation tool | Web application,1,479-494,Book Series,Conference Paper,3.0,"Yim, Keun Soo;Hreczany, David;Iyer, Ravishankar K.",35729612300;42961638500;35597694000,Google LLC;University of Illinois Urbana-Champaign,United States;United States,"in web application development, testing forms an increasingly large portion of software engineering costs due to the growing complexity and short time-to-market of these applications. this paper presents a hybrid testing automation framework (htaf) that can automate routine works in testing and releasing web software. using this framework, an individual software engineer can easily describe his routine software engineering tasks and schedule these described tasks by using both his local machine and global cloud computers in an efficient way. this framework is applied to commercial web software development processes. our industry practice shows four example cases where the hybrid and decentralized architecture of htaf is helpful at effectively managing both hardware resources and manpower required for testing and releasing web applications. © 2011 springer-verlag.",htaf: hybrid testing automation framework to leverage local and global computing resources
1878,2-s2.0-79959915685,10.1145/1985793.1985864,Always-available static and dynamic feedback,Bayne M.,Proceedings - International Conference on Software Engineering,2011-07-07,"Developers who write code in a statically typed language are denied the ability to obtain dynamic feedback by executing their code during periods when it fails the static type checker. They are further confined to the static typing discipline during times in the development process where it does not yield the highest productivity. If they opt instead to use a dynamic language, they forgo the many benefits of static typing, including machine-checked documentation, improved correctness and reliability, tool support (such as for refactoring), and better runtime performance. We present a novel approach to giving developers the benefits of both static and dynamic typing, throughout the development process, and without the burden of manually separating their program into statically and dynamically-typed parts. Our approach, which is intended for temporary use during the development process, relaxes the static type system and provides a semantics for many type-incorrect programs. It defers type errors to run time, or suppresses them if they do not affect runtime semantics. We implemented our approach in a publicly available tool, DuctileJ, for the Java language. In case studies, DuctileJ conferred benefits both during prototyping and during the evolution of existing code. © 2011 ACM.",dynamic typing | gradual typing | hybrid typing | productivity | prototyping | refactoring | static typing | type error,14,521-530,Conference Proceeding,Conference Paper,3.0,"Bayne, Michael;Cook, Richard;Ernst, Michael D.",42160929800;57225768015;36916423000,University of Washington,United States,"developers who write code in a statically typed language are denied the ability to obtain dynamic feedback by executing their code during periods when it fails the static type checker. they are further confined to the static typing discipline during times in the development process where it does not yield the highest productivity. if they opt instead to use a dynamic language, they forgo the many benefits of static typing, including machine-checked documentation, improved correctness and reliability, tool support (such as for refactoring), and better runtime performance. we present a novel approach to giving developers the benefits of both static and dynamic typing, throughout the development process, and without the burden of manually separating their program into statically and dynamically-typed parts. our approach, which is intended for temporary use during the development process, relaxes the static type system and provides a semantics for many type-incorrect programs. it defers type errors to run time, or suppresses them if they do not affect runtime semantics. we implemented our approach in a publicly available tool, ductilej, for the java language. in case studies, ductilej conferred benefits both during prototyping and during the evolution of existing code. © 2011 acm.",always-available static and dynamic feedback
1879,2-s2.0-79959893225,10.1145/1993498.1993544,Automated atomicity-violation fixing,Jin G.,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),2011-07-07,"Fixing software bugs has always been an important and time-consuming process in software development. Fixing concurrency bugs has become especially critical in the multicore era. However, fixing concurrency bugs is challenging, in part due to non-deterministic failures and tricky parallel reasoning. Beyond correctly fixing the original problem in the software, a good patch should also avoid introducing new bugs, degrading performance unnecessarily, or damaging software readability. Existing tools cannot automate the whole fixing process and provide good-quality patches. We present AFix, a tool that automates the whole process of fixing one common type of concurrency bug: single-variable atomicity violations. AFix starts from the bug reports of existing bug-detection tools. It augments these with static analysis to construct a suitable patch for each bug report. It further tries to combine the patches of multiple bugs for better performance and code readability. Finally, AFix's run-time component provides testing customized for each patch. Our evaluation shows that patches automatically generated by AFix correctly eliminate six out of eight real-world bugs and significantly decrease the failure probability in the other two cases. AFix patches never introduce new bugs and usually have similar performance to manually-designed patches. © 2011 ACM.",atomicity violations | automated debugging | concurrency | critical regions | deadlock | mutex locks | mutual exclusion | patching | static analysis,162,389-400,Conference Proceeding,Conference Paper,5.0,"Jin, Guoliang;Song, Linhai;Zhang, Wei;Lu, Shan;Liblit, Ben",55360622700;42162158900;55706481800;35199803400;16301365200,University of Wisconsin-Madison,United States,"fixing software bugs has always been an important and time-consuming process in software development. fixing concurrency bugs has become especially critical in the multicore era. however, fixing concurrency bugs is challenging, in part due to non-deterministic failures and tricky parallel reasoning. beyond correctly fixing the original problem in the software, a good patch should also avoid introducing new bugs, degrading performance unnecessarily, or damaging software readability. existing tools cannot automate the whole fixing process and provide good-quality patches. we present afix, a tool that automates the whole process of fixing one common type of concurrency bug: single-variable atomicity violations. afix starts from the bug reports of existing bug-detection tools. it augments these with static analysis to construct a suitable patch for each bug report. it further tries to combine the patches of multiple bugs for better performance and code readability. finally, afix's run-time component provides testing customized for each patch. our evaluation shows that patches automatically generated by afix correctly eliminate six out of eight real-world bugs and significantly decrease the failure probability in the other two cases. afix patches never introduce new bugs and usually have similar performance to manually-designed patches. © 2011 acm.",automated atomicity-violation fixing
1880,2-s2.0-84867472888,10.1007/s11858-011-0323-8,Adding intelligent assessment: A Java framework for integrating dynamic mathematical software components into interactive learning activities,Fest A.,ZDM - International Journal on Mathematics Education,2011-07-01,"Dynamic geometry constructions are commonly embedded into hypertext documents to create interactive exercises. In practice, this approach often constrains the possibilities of creating complex learning environments due to technical limitations. A Java-based framework for the development of interactive learning environments based on exploration laboratories containing dynamic geometry applets is presented. Dynamic geometry software (DGS) applets of different types can be integrated into the same laboratory and interact with each other. Within our framework, interactive exercises based on DGS constructions can be enriched with automated and semiautomated assessment algorithms. Students' learning processes can be recorded using capture-and-replay software. Two sample learning environments based on the framework are presented. © FIZ Karlsruhe 2011.",Congruencies | Dynamic geometry | Interactive learning activities | Semi-automated assessment,3,413-423,Journal,Article,1.0,"Fest, Andreas",55389593000,Ludwigsburg University of Education,Germany,"dynamic geometry constructions are commonly embedded into hypertext documents to create interactive exercises. in practice, this approach often constrains the possibilities of creating complex learning environments due to technical limitations. a java-based framework for the development of interactive learning environments based on exploration laboratories containing dynamic geometry applets is presented. dynamic geometry software (dgs) applets of different types can be integrated into the same laboratory and interact with each other. within our framework, interactive exercises based on dgs constructions can be enriched with automated and semiautomated assessment algorithms. students' learning processes can be recorded using capture-and-replay software. two sample learning environments based on the framework are presented. © fiz karlsruhe 2011.",adding intelligent assessment: a java framework for integrating dynamic mathematical software components into interactive learning activities
1881,2-s2.0-79959314372,10.1145/1982185.1982357,"Transforming the web into a real application platform: New technologies, emerging trends and missing pieces",Anttonen M.,Proceedings of the ACM Symposium on Applied Computing,2011-06-23,"The World Wide Web has evolved from a simple document browsing and distribution environment into a rich software platform in which desktop-style applications are increasingly becoming first class citizens. The document-oriented origins of the Web are still evident in many areas, though, and traditionally it has been difficult to compose truly interactive web applications without using plug-in components or browser extensions such as Flash. However, the ongoing standardization work and emerging technologies such as HTML5, JavaScript 2.0 and WebGL are quickly altering the landscape of web application development. In this paper, we present a number of prior challenges and shortcomings, and describe how new technologies can be used for solving many of the problems. The research is based on our hands-on experiences in building various web-based systems in which a number of different web application development technologies have been used extensively. © 2011 ACM.",HTML5 | JavaScript | web programming | WebGL,34,800-807,Conference Proceeding,Conference Paper,4.0,"Anttonen, Matti;Salminen, Arto;Mikkonen, Tommi;Taivalsaari, Antero",40661076400;36630946500;54420813700;6507045147,Nokia Corporation;Tampere University,Finland;Finland,"the world wide web has evolved from a simple document browsing and distribution environment into a rich software platform in which desktop-style applications are increasingly becoming first class citizens. the document-oriented origins of the web are still evident in many areas, though, and traditionally it has been difficult to compose truly interactive web applications without using plug-in components or browser extensions such as flash. however, the ongoing standardization work and emerging technologies such as html5, javascript 2.0 and webgl are quickly altering the landscape of web application development. in this paper, we present a number of prior challenges and shortcomings, and describe how new technologies can be used for solving many of the problems. the research is based on our hands-on experiences in building various web-based systems in which a number of different web application development technologies have been used extensively. © 2011 acm.","transforming the web into a real application platform: new technologies, emerging trends and missing pieces"
1882,2-s2.0-79959283675,10.1145/1985441.1985447,A study of language usage evolution in open source software,Karus S.,Proceedings - International Conference on Software Engineering,2011-06-22,"The use of programming languages such as Java and C in Open Source Software (OSS) has been well studied. However, many other popular languages such as XSL or XML have received minor attention. In this paper, we discuss some trends in OSS development that we observed when considering multiple programming language evolution of OSS. Based on the revision data of 22 OSS projects, we tracked the evolution of language usage and other artefacts such as documentation files, binaries and graphics files. In these systems several different languages and artefact types including C/C++, Java, XML, XSL, Makefile, Groovy, HTML, Shell scripts, CSS, Graphics files, JavaScript, JSP, Ruby, Phyton, XQuery, OpenDocument files, PHP, etc. have been used. We found that the amount of code written in different languages differs substantially. Some of our findings can be summarized as follows: (1) JavaScript and CSS files most often co-evolve with XSL; (2) Most Java developers but only every second C/C++ developer work with XML; (3) and more generally, we observed a significant increase of usage of XML and XSL during recent years and found that Java or C are hardly ever the only language used by a developer. In fact, a developer works with more than 5 different artefact types (or 4 different languages) in a project on average. © 2011 ACM.",evolution | open source software | programming language | software archives,36,13-22,Conference Proceeding,Conference Paper,2.0,"Karus, Siim;Gall, Harald",23397069000;56223438700,Tartu Ülikool;Universität Zürich,Estonia;Switzerland,"the use of programming languages such as java and c in open source software (oss) has been well studied. however, many other popular languages such as xsl or xml have received minor attention. in this paper, we discuss some trends in oss development that we observed when considering multiple programming language evolution of oss. based on the revision data of 22 oss projects, we tracked the evolution of language usage and other artefacts such as documentation files, binaries and graphics files. in these systems several different languages and artefact types including c/c++, java, xml, xsl, makefile, groovy, html, shell scripts, css, graphics files, javascript, jsp, ruby, phyton, xquery, opendocument files, php, etc. have been used. we found that the amount of code written in different languages differs substantially. some of our findings can be summarized as follows: (1) javascript and css files most often co-evolve with xsl; (2) most java developers but only every second c/c++ developer work with xml; (3) and more generally, we observed a significant increase of usage of xml and xsl during recent years and found that java or c are hardly ever the only language used by a developer. in fact, a developer works with more than 5 different artefact types (or 4 different languages) in a project on average. © 2011 acm.",a study of language usage evolution in open source software
1886,2-s2.0-79251509890,10.1107/S0021889810049411,J-ICE: A new Jmol interface for handling and visualizing crystallographic and electronic properties,Canepa P.,Journal of Applied Crystallography,2011-02-01,"The growth in complexity of quantum mechanical software packages for modelling the physicochemical properties of crystalline materials may hinder their usability by the vast majority of non-specialized users. Consequently, a free operating-system-independent graphical user interface (GUI) has been developed to drive the most common simulation packages for treating both molecules and solids. In order to maintain maximum portability and graphical efficiency, the popular molecular graphics engine Jmol, written in the portable Java language, has been combined with a specialized GUI encoded in HTML and JavaScript. This framework, called J-ICE, allows users to visualize, build and manipulate complex input or output results (derived from modelling) entirely via a web server, i.e. without the burden of installing complex packages. This solution also dramatically speeds up both the development procedure and bug fixing. Among the range of software appropriate for modelling condensed matter, the focus of J-ICE is currently only on CRYSTAL09 and VASP. © 2011 International Union of Crystallography Printed in Singapore-all rights reserved.",HTML | J-ICE | Java | JavaScript | Jmol | molecular modelling | solid state,75,225-229,Journal,Article,4.0,"Canepa, Pieremanuele;Hanson, Robert M.;Ugliengo, Piero;Alfredsson, Maria",36695794700;57194379165;7003814779;6603701824,Università degli Studi di Torino;University of Kent;St. Olaf College,Italy;United Kingdom;United States,"the growth in complexity of quantum mechanical software packages for modelling the physicochemical properties of crystalline materials may hinder their usability by the vast majority of non-specialized users. consequently, a free operating-system-independent graphical user interface (gui) has been developed to drive the most common simulation packages for treating both molecules and solids. in order to maintain maximum portability and graphical efficiency, the popular molecular graphics engine jmol, written in the portable java language, has been combined with a specialized gui encoded in html and javascript. this framework, called j-ice, allows users to visualize, build and manipulate complex input or output results (derived from modelling) entirely via a web server, i.e. without the burden of installing complex packages. this solution also dramatically speeds up both the development procedure and bug fixing. among the range of software appropriate for modelling condensed matter, the focus of j-ice is currently only on crystal09 and vasp. © 2011 international union of crystallography printed in singapore-all rights reserved.",j-ice: a new jmol interface for handling and visualizing crystallographic and electronic properties
1887,2-s2.0-78650608265,10.1016/j.jss.2010.09.020,Taxonomy and classification of automatic monitoring of program security vulnerability exploitations,Shahriar H.,Journal of Systems and Software,2011-02-01,"Software applications (programs) are implemented in a wide variety of languages and run on different execution environments. Programs contain vulnerabilities which can be detected before their deployment. Nevertheless, there exist some program vulnerabilities, which do not surface until a program is operational. No matter how much effort has been put during the development phases, building large vulnerability-free programs has proven extremely difficult in practice. Given that, it is very important to have a tool that can be used for online monitoring of programs in the operational stage. The tool can help to mitigate the consequences of some vulnerability exploitations, by early detection of attacks at runtime. Currently, many monitoring approaches have been proposed and applied in practice. However, there is no classification of these approaches to understand their common characteristics and limitations. In this paper, we present a taxonomy and classification of the state of the art approaches employed for monitoring program vulnerability exploitations (or attacks). We first classify the existing approaches based on a set of characteristics which are common in online attack detection approaches. Then, we present a taxonomy by classifying the approaches based on monitoring aspects that primarily differentiate among the approaches. We also discuss open issues and future research direction in the area of program vulnerability exploitation monitoring. The study will enable practitioners and researchers to differentiate among existing monitoring approaches. It will provide a guideline to consider the desired characteristics while developing monitoring approaches. © 2010 Elsevier Inc. All rights reserved.",Monitoring | Program security vulnerabiilties | Taxonomy,19,250-269,Journal,Article,2.0,"Shahriar, Hossain;Zulkernine, Mohammad",23096391900;6506457317,Queen’s University,Canada,"software applications (programs) are implemented in a wide variety of languages and run on different execution environments. programs contain vulnerabilities which can be detected before their deployment. nevertheless, there exist some program vulnerabilities, which do not surface until a program is operational. no matter how much effort has been put during the development phases, building large vulnerability-free programs has proven extremely difficult in practice. given that, it is very important to have a tool that can be used for online monitoring of programs in the operational stage. the tool can help to mitigate the consequences of some vulnerability exploitations, by early detection of attacks at runtime. currently, many monitoring approaches have been proposed and applied in practice. however, there is no classification of these approaches to understand their common characteristics and limitations. in this paper, we present a taxonomy and classification of the state of the art approaches employed for monitoring program vulnerability exploitations (or attacks). we first classify the existing approaches based on a set of characteristics which are common in online attack detection approaches. then, we present a taxonomy by classifying the approaches based on monitoring aspects that primarily differentiate among the approaches. we also discuss open issues and future research direction in the area of program vulnerability exploitation monitoring. the study will enable practitioners and researchers to differentiate among existing monitoring approaches. it will provide a guideline to consider the desired characteristics while developing monitoring approaches. © 2010 elsevier inc. all rights reserved.",taxonomy and classification of automatic monitoring of program security vulnerability exploitations
1891,2-s2.0-84867342545,10.1007/s12518-010-0041-x,Ithaca worldwide flood alert system: The web framework,Agosto E.,Applied Geomatics,2011-01-01,"Information Technology for Humanitarian Assistance, Cooperation, and Action (ITHACA) is developing a worldwide early warning system for flood events (Albanese et al. 2008). The system collects rainfall data from NASA Tropical Rainfall Monitoring Mission website every 3 h, processes them, and compares them to historical data series to detect an alert level for each basin. Watershed layer of HYDRO1k, developed at the US Geological Survey's Centre for Earth Resources Observation and Sciences, is constituted by a territorial subdivision at different levels, increasing details from levels 1 to 6; watershed at maximum detail (level-6 basin) are used for the system. A grid-computing approach is adopted to face the heavy computational load while a web-fruition framework is planned to give the widest access to the output the system produces. The user interface shows ongoing events on a map, where it is also possible to add other feeds (i.e., by Global Disaster Alert and Coordination System). The user can zoom to the alerted countries by an interactive list or have additional information on the event and possibly an estimate of the affected population shown. The framework is based on pure Free and Open Source Software (FOSS) products and common standards, according to ITHACA internal directives and following United Nations Geographic Information Working Group directives that encourage interoperability and FOSS tools adoption. The framework is a development of ITHACA infrastructure for web GIS applications; it is based on Model Controller View (MCV) architectural pattern that makes it possible to isolate the logic of the application from the interface. In this way, a change in one of the two parts does not affect the other making maintenance easier in the long term. From this point of view a controller collects, the model manipulates application data, and the view presents results to the user. Here, a Python-based MCV framework named Django is adopted; interfaces are built using JavaScript classes which some FOSS projects make available. Some OpenLayers classes are modified and combined with Ext and GeoExt libraries to increase the interaction the user can have with the interface. Data are symbolized using common Open Geospatial Consortium Styled Layer Descriptor standard. Caching mechanism for Web Mapping Service base layers is adopted. © Società Italiana di Fotogrammetria e Topografia (SIFET) 2011.",Early monitoring | Flood | FOSS | Web,3,83-89,Journal,Article,4.0,"Agosto, Eros;Dalmasso, Simone;Pasquali, Paolo;Terzo, Olivier",25631776300;55387157000;55387054200;27868176400,Istituto Superiore Mario Boella;ITHACA (Information Technology for Humanitarian Assistance,Italy;Italy,"information technology for humanitarian assistance, cooperation, and action (ithaca) is developing a worldwide early warning system for flood events (albanese et al. 2008). the system collects rainfall data from nasa tropical rainfall monitoring mission website every 3 h, processes them, and compares them to historical data series to detect an alert level for each basin. watershed layer of hydro1k, developed at the us geological survey's centre for earth resources observation and sciences, is constituted by a territorial subdivision at different levels, increasing details from levels 1 to 6; watershed at maximum detail (level-6 basin) are used for the system. a grid-computing approach is adopted to face the heavy computational load while a web-fruition framework is planned to give the widest access to the output the system produces. the user interface shows ongoing events on a map, where it is also possible to add other feeds (i.e., by global disaster alert and coordination system). the user can zoom to the alerted countries by an interactive list or have additional information on the event and possibly an estimate of the affected population shown. the framework is based on pure free and open source software (foss) products and common standards, according to ithaca internal directives and following united nations geographic information working group directives that encourage interoperability and foss tools adoption. the framework is a development of ithaca infrastructure for web gis applications; it is based on model controller view (mcv) architectural pattern that makes it possible to isolate the logic of the application from the interface. in this way, a change in one of the two parts does not affect the other making maintenance easier in the long term. from this point of view a controller collects, the model manipulates application data, and the view presents results to the user. here, a python-based mcv framework named django is adopted; interfaces are built using javascript classes which some foss projects make available. some openlayers classes are modified and combined with ext and geoext libraries to increase the interaction the user can have with the interface. data are symbolized using common open geospatial consortium styled layer descriptor standard. caching mechanism for web mapping service base layers is adopted. © società italiana di fotogrammetria e topografia (sifet) 2011.",ithaca worldwide flood alert system: the web framework
1892,2-s2.0-84862981141,10.1080/02533839.2011.591544,Incorporating visualized data completeness information in an open and interoperable GIS map interface,Hong J.H.,"Journal of the Chinese Institute of Engineers, Transactions of the Chinese Institute of Engineers,Series A",2011-01-01,"Successful data sharing is a critical challenge in the development of National Spatial Data Infrastructure, but the heterogeneity of geospatial data often impedes the correct use of distributed geospatial data. For example, although map interfaces have been widely used in GIS software, misunderstandings of the geospatial data illustrated in map interfaces may still produce unpredictable and unnoticeable risks. It is necessary for users to have a thorough understanding about the acquired data before they can make correct decisions. Based on the concept of valid extent and illustrated extent, this article has proposed a new model that incorporates visual aids of data completeness information in the GIS-based map interface by integrating metadata, Geography Markup Language, and cartographic knowledge. Compared to current GIS map interfaces, the introduced open format of distributed data and knowledge-based visual aids enables users to correctly interpret the illustrated results of the map interface in an interoperable and visualized way, such that users are always aware of the status of data completeness regarding the illustrated content of the map interfaces. Despite the fact that the discussions of this article are restricted to the issue of data completeness, the results have clearly indicated that such a visualized mechanism for data quality information should be included as a necessary component in the future OpenGIS distributed environment. © 2011 The Chinese Institute of Engineers.",Data completeness | Interoperability | Valid extent,4,733-745,Journal,Article,2.0,"Hong, Jung Hong;Liao, Hsiung Peng",35275068700;35275460700,National Cheng Kung University,Taiwan,"successful data sharing is a critical challenge in the development of national spatial data infrastructure, but the heterogeneity of geospatial data often impedes the correct use of distributed geospatial data. for example, although map interfaces have been widely used in gis software, misunderstandings of the geospatial data illustrated in map interfaces may still produce unpredictable and unnoticeable risks. it is necessary for users to have a thorough understanding about the acquired data before they can make correct decisions. based on the concept of valid extent and illustrated extent, this article has proposed a new model that incorporates visual aids of data completeness information in the gis-based map interface by integrating metadata, geography markup language, and cartographic knowledge. compared to current gis map interfaces, the introduced open format of distributed data and knowledge-based visual aids enables users to correctly interpret the illustrated results of the map interface in an interoperable and visualized way, such that users are always aware of the status of data completeness regarding the illustrated content of the map interfaces. despite the fact that the discussions of this article are restricted to the issue of data completeness, the results have clearly indicated that such a visualized mechanism for data quality information should be included as a necessary component in the future opengis distributed environment. © 2011 the chinese institute of engineers.",incorporating visualized data completeness information in an open and interoperable gis map interface
1893,2-s2.0-82755168685,10.17221/466/2011-pse,Organic farms in the Czech Republic - Map Portal presentation opportunities,Vaněk J.,"Plant, Soil and Environment",2011-01-01,The paper is aimed at presenting the map portal of organic farms in the Czech Republic. The pilot project is concerned with the South Bohemia Region. Extensive map data and resources are displayed by means of a purpose-developed universal software solution called Regional Development Map Portal (RDMP) version 1.0. The database was generated and updated on the basis of detailed content validation and strives for maximum accuracy of map object location. The software solution - apart from supporting all standard functions - represents qualitatively a brand new perspective of map data creation and entails many original elements and functionalities.,Ecological agriculture | Google maps | Map outputs | Multifunctional agriculture | Rural development,6,565-570,Journal,Article,6.0,"Vaněk, J.;Brožová, I.;Šimek, P.;Jarolímek, J.;Vogeltanzová, T.;Červenková, E.",22986635600;36127519500;55600522600;22985119700;54418091000;36136582500,Czech University of Life Sciences Prague,Czech Republic,the paper is aimed at presenting the map portal of organic farms in the czech republic. the pilot project is concerned with the south bohemia region. extensive map data and resources are displayed by means of a purpose-developed universal software solution called regional development map portal (rdmp) version 1.0. the database was generated and updated on the basis of detailed content validation and strives for maximum accuracy of map object location. the software solution - apart from supporting all standard functions - represents qualitatively a brand new perspective of map data creation and entails many original elements and functionalities.,organic farms in the czech republic - map portal presentation opportunities
1894,2-s2.0-82655165273,10.1587/transinf.E94.D.2418,"Open code coverage framework: A framework for consistent, flexible and complete measurement of test coverage supporting multiple programming languages",Sakamoto K.,IEICE Transactions on Information and Systems,2011-01-01,"Test coverage is an important indicator of whether software has been sufficiently tested. However, there are several problems with the existing measurement tools for test coverage, such as their cost of development and maintenance, inconsistency, and inflexibility in measurement. We propose a consistent and flexible measurement framework for test coverage that we call the Open Code Coverage Framework (OCCF). It supports multiple programming languages by extracting the commonalities from multiple programming languages using an abstract syntax tree to help in the development of the measurement tools for the test coverage of new programming languages. OCCF allows users to add programming language support independently of the test-coverage-criteria and also to add test-coverage-criteria support independently of programming languages in order to take consistent measurements in each programming language. Moreover, OCCF provides two methods for changin the measurement range and elements using XPath and adding user code in order to make more flexible measurements. We implemented a sample tool for C, Java, and Python using OCCF. OCCF can measure four test-coveragecriteria. We also confirmed that OCCF can support C#, Ruby, JavaScript, and Lua. Moreover, we reduced the lines of code (LOCs) required to implement measurement tools for test coverage by approximately 90% and the time to implement a new test-coverage-criterion by over 80% in an experiment that compared OCCF with the conventional non-framework-based tools. Copyright © 2011 The Institute of Electronics, Information and Communication Engineers.",Code coverage | Framework | Metrics | Software testing | Test coverage,1,2418-2430,Journal,Conference Paper,4.0,"Sakamoto, Kazunori;Ishikawa, Fuyuki;Washizaki, Hironori;Fukazawa, Yoshiaki",36574117400;33367760100;8905784000;7101986896,Research Organization of Information and Systems National Institute of Informatics;Waseda University,Japan;Japan,"test coverage is an important indicator of whether software has been sufficiently tested. however, there are several problems with the existing measurement tools for test coverage, such as their cost of development and maintenance, inconsistency, and inflexibility in measurement. we propose a consistent and flexible measurement framework for test coverage that we call the open code coverage framework (occf). it supports multiple programming languages by extracting the commonalities from multiple programming languages using an abstract syntax tree to help in the development of the measurement tools for the test coverage of new programming languages. occf allows users to add programming language support independently of the test-coverage-criteria and also to add test-coverage-criteria support independently of programming languages in order to take consistent measurements in each programming language. moreover, occf provides two methods for changin the measurement range and elements using xpath and adding user code in order to make more flexible measurements. we implemented a sample tool for c, java, and python using occf. occf can measure four test-coveragecriteria. we also confirmed that occf can support c#, ruby, javascript, and lua. moreover, we reduced the lines of code (locs) required to implement measurement tools for test coverage by approximately 90% and the time to implement a new test-coverage-criterion by over 80% in an experiment that compared occf with the conventional non-framework-based tools. copyright © 2011 the institute of electronics, information and communication engineers.","open code coverage framework: a framework for consistent, flexible and complete measurement of test coverage supporting multiple programming languages"
1895,2-s2.0-80051495852,10.1109/ITNG.2011.18,EnduRan: A web application for managing racing events,Patel J.,"Proceedings - 2011 8th International Conference on Information Technology: New Generations, ITNG 2011",2011-01-01,"Organizing a racing event is not an easy task. Organizing a racing event that spans across multiple days and whose participants have to run (on foot) for 100 miles is even harder. In such events many checkpoints are needed to provide runners with access to food, water and, if necessary, medical assistance. At these checkpoints updates on participants' health status and race timings need to be sent to a central location so that followers across the globe can monitor the overall progress of the race as well as the current situation of individual racers. This paper examines development challenges and presents a flexible open source solution for a web-based software application, EnduRan, z that we created for managing long-distance racing events. The paper takes a closer look at the need for this software application and gives details on the application's specification, design, and implementation. Design guidelines resulted from this software project, together with several lessons learned from it, are described as well in the paper. Results of using EnduRan in the 2009 and 2010 Lake Tahoe 100 Miles Endurance Races and pointers to future work are also included. © 2011 IEEE.",racing event | software design | software implementation | web application,0,60-65,Conference Proceeding,Conference Paper,2.0,"Patel, Jigarkumar;Dascalu, Sergiu M.",57213416913;6602297823,"University of Nevada, Reno",United States,"organizing a racing event is not an easy task. organizing a racing event that spans across multiple days and whose participants have to run (on foot) for 100 miles is even harder. in such events many checkpoints are needed to provide runners with access to food, water and, if necessary, medical assistance. at these checkpoints updates on participants' health status and race timings need to be sent to a central location so that followers across the globe can monitor the overall progress of the race as well as the current situation of individual racers. this paper examines development challenges and presents a flexible open source solution for a web-based software application, enduran, z that we created for managing long-distance racing events. the paper takes a closer look at the need for this software application and gives details on the application's specification, design, and implementation. design guidelines resulted from this software project, together with several lessons learned from it, are described as well in the paper. results of using enduran in the 2009 and 2010 lake tahoe 100 miles endurance races and pointers to future work are also included. © 2011 ieee.",enduran: a web application for managing racing events
1898,2-s2.0-78650114632,10.1145/1869631.1869635,Alias analysis for optimization of dynamic languages,Gorbovitski M.,"Proceedings of the 6th Symposium on Dynamic Languages, DLS '10",2010-12-20,"Dynamic languages such as Python allow programs to be written more easily using high-level constructs such as comprehensions for queries and using generic code. Efficient execution of programs then requires powerful optimizations - incrementalization of expensive queries and specialization of generic code. Effective incrementalization and specialization of dynamic languages require precise and scalable alias analysis. This paper describes the development and experimental evaluation of a may-alias analysis for a full dynamic object-oriented language, for program optimization by incremen-talization and specialization. The analysis is flow-sensitive; we show that this is necessary for effective optimization of dynamic languages. It uses precise type analysis and a powerful form of context sensitivity, called trace sensitivity, to further improve analysis precision. It uses a compressed representation to significantly reduce the memory used by flow-sensitive analyses. We evaluate the effectiveness of this analysis and 17 variants of it for incrementalization and specialization of Python programs, and we evaluate the precision, memory usage, and running time of these analyses on programs of diverse sizes. The results show that our analysis has acceptable precision and efficiency and represents the best trade-off between them compared to the variants. © 2010 ACM.",Algorithms | Experimentation | Languages | Performance,22,27-41,Conference Proceeding,Conference Paper,5.0,"Gorbovitski, Michael;Liu, Yanhong A.;Stoller, Scott D.;Rothamel, Tom;Tekle, K. Tuncay",12139795200;35208420900;7003881873;36946018700;19639567300,Stony Brook University,United States,"dynamic languages such as python allow programs to be written more easily using high-level constructs such as comprehensions for queries and using generic code. efficient execution of programs then requires powerful optimizations - incrementalization of expensive queries and specialization of generic code. effective incrementalization and specialization of dynamic languages require precise and scalable alias analysis. this paper describes the development and experimental evaluation of a may-alias analysis for a full dynamic object-oriented language, for program optimization by incremen-talization and specialization. the analysis is flow-sensitive; we show that this is necessary for effective optimization of dynamic languages. it uses precise type analysis and a powerful form of context sensitivity, called trace sensitivity, to further improve analysis precision. it uses a compressed representation to significantly reduce the memory used by flow-sensitive analyses. we evaluate the effectiveness of this analysis and 17 variants of it for incrementalization and specialization of python programs, and we evaluate the precision, memory usage, and running time of these analyses on programs of diverse sizes. the results show that our analysis has acceptable precision and efficiency and represents the best trade-off between them compared to the variants. © 2010 acm.",alias analysis for optimization of dynamic languages
1900,2-s2.0-78649564681,10.1007/978-3-642-15621-2_22,Framework designing of BOA for the development of enterprise management information system,Ma S.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2010-12-06,"This paper put forward the definition of business oriented architecture (BOA) for the development of enterprise management information system and its technical components, as well as the designing method of reusable component based on business oriented model (BOM). This method uses JDOM to generate and analyze the properties of configuration files with XML format, and realizes the interaction between basic middleware and configuration software by using AJAX. It can give different page styles using JavaScript and has properties of short period of designing and good flexibility. An example in the development of a management information system based on BOA for a machine manufacturing factory is introduced. In which, most of the components was designed with the proposed method. It manifests that the BOA framework can be a good choice to meet the needs of different customers and to reduce system development cycle. © 2010 Springer-Verlag.",BOA | BOM | Management Information System | Reusable Component,0,185-195,Book Series,Conference Paper,4.0,"Ma, Shiwei;Kong, Zhaowen;Jiang, Xuelin;Liang, Chaozu",12762283200;36680261900;36070735300;36680422300,Shanghai University,China,"this paper put forward the definition of business oriented architecture (boa) for the development of enterprise management information system and its technical components, as well as the designing method of reusable component based on business oriented model (bom). this method uses jdom to generate and analyze the properties of configuration files with xml format, and realizes the interaction between basic middleware and configuration software by using ajax. it can give different page styles using javascript and has properties of short period of designing and good flexibility. an example in the development of a management information system based on boa for a machine manufacturing factory is introduced. in which, most of the components was designed with the proposed method. it manifests that the boa framework can be a good choice to meet the needs of different customers and to reduce system development cycle. © 2010 springer-verlag.",framework designing of boa for the development of enterprise management information system
1901,2-s2.0-84885893274,10.1007/978-3-642-12607-9_9,Lively mashups for mobile devices,Nyrhinen F.,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering",2010-12-01,"The software industry is currently experiencing a paradigm shift towards web-based software and web-enabled mobile devices. With the Web as the ultimate information distribution platform, mashups that combine data, code and other content from numerous web sites are becoming popular. Unfortunately, there are various limitations when building mashups that run in a web browser. The problems are even more challenging when using those mashups on mobile devices. In this paper, we present our experiences in building mashups using Qt, a Nokia-owned cross-platform application framework that provides built-in support for web browsing and scripting. These experiences are part of a larger activity called Lively for Qt, an effort that has created a highly interactive, mobile web application and mashup development environment on top of the Qt framework. © Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering 2010.",Lively for Qt | Mashup development | Mobile web applications | Qt,6,123-141,Book Series,Conference Paper,4.0,"Nyrhinen, Feetu;Salminen, Arto;Mikkonen, Tommi;Taivalsaari, Antero",35318451700;36630946500;54420813700;6507045147,Sun Microsystems;Tampere University,United States;Finland,"the software industry is currently experiencing a paradigm shift towards web-based software and web-enabled mobile devices. with the web as the ultimate information distribution platform, mashups that combine data, code and other content from numerous web sites are becoming popular. unfortunately, there are various limitations when building mashups that run in a web browser. the problems are even more challenging when using those mashups on mobile devices. in this paper, we present our experiences in building mashups using qt, a nokia-owned cross-platform application framework that provides built-in support for web browsing and scripting. these experiences are part of a larger activity called lively for qt, an effort that has created a highly interactive, mobile web application and mashup development environment on top of the qt framework. © institute for computer sciences, social-informatics and telecommunications engineering 2010.",lively mashups for mobile devices
1906,2-s2.0-80053531694,10.1145/1899661.1869635,Alias analysis for optimization of dynamic languages,Gorbovitski M.,ACM SIGPLAN Notices,2010-12-01,"Dynamic languages such as Python allow programs to be written more easily using high-level constructs such as comprehensions for queries and using generic code. Efficient execution of programs then requires powerful optimizations-incrementalization of expensive queries and specialization of generic code. Effective incrementalization and specialization of dynamic languages require precise and scalable alias analysis. This paper describes the development and experimental evaluation of a may-alias analysis for a full dynamic objectoriented language, for program optimization by incrementalization and specialization. The analysis is flow-sensitive; we show that this is necessary for effective optimization of dynamic languages. It uses precise type analysis and a powerful form of context sensitivity, called trace sensitivity, to further improve analysis precision. It uses a compressed representation to significantly reduce the memory used by flowsensitive analyses.We evaluate the effectiveness of this analysis and 17 variants of it for incrementalization and specialization of Python programs, and we evaluate the precision, memory usage, and running time of these analyses on programs of diverse sizes. The results show that our analysis has acceptable precision and efficiency and represents the best trade-off between them compared to the variants. Copyright © 2010 ACM.",Algorithms | Experimentation | Languages | Performance,5,27-41,Journal,Article,5.0,"Gorbovitski, Michael;Liu, Yanhong A.;Stoller, Scott D.;Rothamel, Tom;Tekle, K. Tuncay",12139795200;35208420900;7003881873;36946018700;19639567300,Stony Brook University,United States,"dynamic languages such as python allow programs to be written more easily using high-level constructs such as comprehensions for queries and using generic code. efficient execution of programs then requires powerful optimizations-incrementalization of expensive queries and specialization of generic code. effective incrementalization and specialization of dynamic languages require precise and scalable alias analysis. this paper describes the development and experimental evaluation of a may-alias analysis for a full dynamic objectoriented language, for program optimization by incrementalization and specialization. the analysis is flow-sensitive; we show that this is necessary for effective optimization of dynamic languages. it uses precise type analysis and a powerful form of context sensitivity, called trace sensitivity, to further improve analysis precision. it uses a compressed representation to significantly reduce the memory used by flowsensitive analyses.we evaluate the effectiveness of this analysis and 17 variants of it for incrementalization and specialization of python programs, and we evaluate the precision, memory usage, and running time of these analyses on programs of diverse sizes. the results show that our analysis has acceptable precision and efficiency and represents the best trade-off between them compared to the variants. copyright © 2010 acm.",alias analysis for optimization of dynamic languages
1907,2-s2.0-79960313872,10.1007/978-3-642-13861-4_23,Using Cloud Storage in Production Monitoring Systems,Jestratjew A.,Communications in Computer and Information Science,2010-12-01,"Cloud Computing has received much rumour during the last year. Although the idea of lending processing power and data storage is, in essence, known since the very beginning of the computer industry, a new distributed computing platform coming from Microsoft is expected to have much impact on the enterprise software development and usage. However, production monitoring systems are traditionally built with on-site data stores and specialized hardware and software solutions that interconnects data sources (process controllers) and data stores. We propose an alternative approach. Using modern PLC solutions, one is able to avoid on-site data store in favor of Cloud Storage available over the Internet, lowering capital and maintenance expenses. © Springer-Verlag Berlin Heidelberg 2010.",availability | cloud computing | database | PLC | REST,13,226-235,Book Series,Conference Paper,2.0,"Jestratjew, Arkadiusz;Kwiecień, Andrzej",26767898700;36614245500,Silesian University of Technology,Poland,"cloud computing has received much rumour during the last year. although the idea of lending processing power and data storage is, in essence, known since the very beginning of the computer industry, a new distributed computing platform coming from microsoft is expected to have much impact on the enterprise software development and usage. however, production monitoring systems are traditionally built with on-site data stores and specialized hardware and software solutions that interconnects data sources (process controllers) and data stores. we propose an alternative approach. using modern plc solutions, one is able to avoid on-site data store in favor of cloud storage available over the internet, lowering capital and maintenance expenses. © springer-verlag berlin heidelberg 2010.",using cloud storage in production monitoring systems
1908,2-s2.0-79952334581,10.1145/1930488.1930523,"Developing client-side mashups: Experiences, guidelines and the road ahead",Salminen A.,"Proceedings of the 14th International Academic MindTrek Conference: Envisioning Future Media Environments, MindTrek 2010",2010-12-01,"Software mashups that combine content from multiple web sites to an integrated experience are a popular trend. However, methods and tools for creating mashups are still rather undeveloped, and there is little engineering support behind them. In this paper we provide insight into mashup development based on our practical experiences in implementing various sample mashup applications and tools for creating them. Unlike most commonly used mashup development tools, which are rather server-centric, we focus primarily on client-side mashup development. We have grouped our experiences into guidelines that can serve as a helpful starting point for the design of new mashups. The long-term goal of our work is to facilitate the development of robust, secure and compelling mashup applications, and more generally ease the transition towards web-based software development. © 2010 ACM.",Mashup development | Mashups | Web applications | Web engineering | Web-based software development,10,161-168,Conference Proceeding,Conference Paper,4.0,"Salminen, Arto;Mikkonen, Tommi;Nyrhinen, Feetu;Taivalsaari, Antero",36630946500;54420813700;35318451700;6507045147,Digia Plc;Nokia Corporation;Tampere University,Finland;Finland;Finland,"software mashups that combine content from multiple web sites to an integrated experience are a popular trend. however, methods and tools for creating mashups are still rather undeveloped, and there is little engineering support behind them. in this paper we provide insight into mashup development based on our practical experiences in implementing various sample mashup applications and tools for creating them. unlike most commonly used mashup development tools, which are rather server-centric, we focus primarily on client-side mashup development. we have grouped our experiences into guidelines that can serve as a helpful starting point for the design of new mashups. the long-term goal of our work is to facilitate the development of robust, secure and compelling mashup applications, and more generally ease the transition towards web-based software development. © 2010 acm.","developing client-side mashups: experiences, guidelines and the road ahead"
1909,2-s2.0-79951665106,10.1145/1882362.1882413,The mashware challenge: Bridging the gap between web development and software engineering,Mikkonen T.,"Proceedings of the FSE/SDP Workshop on the Future of Software Engineering Research, FoSER 2010",2010-12-01,"The software industry is currently experiencing a paradigm shift towards web-based software. Although the Web was not originally designed to be a software platform, it is rapidly becoming the platform for all the end-user software. In this position paper we argue that (1) development practices for web applications are still far from the maturity levels of traditional software engineering, (2) web development will evolve towards ""mashware"" - mashup software that leverages source code and software components downloaded dynamically from all over the world, (3) there is still an impedance mismatch between web development and software engineering, (4) the trend towards mashware will exacerbate the gap between web development and software engineering, and (5) research is needed in several areas, including modularity and security, to ensure that the academic world does not get left behind from the fundamental changes that are impacting in the software industry. Copyright 2010 ACM.",Mashups | Mashware | Software engineering | Web engineering,16,245-249,Conference Proceeding,Conference Paper,2.0,"Mikkonen, Tommi;Taivalsaari, Antero",54420813700;6507045147,Nokia Corporation;Tampere University,Finland;Finland,"the software industry is currently experiencing a paradigm shift towards web-based software. although the web was not originally designed to be a software platform, it is rapidly becoming the platform for all the end-user software. in this position paper we argue that (1) development practices for web applications are still far from the maturity levels of traditional software engineering, (2) web development will evolve towards ""mashware"" - mashup software that leverages source code and software components downloaded dynamically from all over the world, (3) there is still an impedance mismatch between web development and software engineering, (4) the trend towards mashware will exacerbate the gap between web development and software engineering, and (5) research is needed in several areas, including modularity and security, to ensure that the academic world does not get left behind from the fundamental changes that are impacting in the software industry. copyright 2010 acm.",the mashware challenge: bridging the gap between web development and software engineering
1910,2-s2.0-79951594225,10.1109/ICITIS.2010.5689484,Privacy-aware: Tracking and protecting sensitive information using automatic type inference,Ouyang W.,"Proceedings 2010 IEEE International Conference on Information Theory and Information Security, ICITIS 2010",2010-12-01,"It is very hard to ensure that software is free of sensitive information leaks because current common software takes very little measures to control sensitive data propagation or limit data lifetime. We present Privacy-Aware, a sensitive data tracker and eraser based on type qualifier inference. We have adapted a simplified type qualifier inference to the LLVM framework, a low-level virtual machine infrastructure for a batch of languages. With type qualifier inference, Privacy-Aware can automatically reason about where the sensitive data has been propagated to and erase them before deallocation. We optimize Privacy-Aware with alias analysis and points-to analysis so that Privacy-Aware can be used as an effective annotation system for programmer to reduce the data lifetime in software development with minimal annotation effort. We have implemented Privacy-Aware by LLVM-based instrumentation. The preliminary evaluation suggests that Privacy-Aware can effectively clear sensitive data while only incurring a small amount of overhead, on average below 10%, in our benchmark. Our research provides evidence that requiring minimal programmer intervention, Privacy-Aware is an effective, efficient and autonomous strategy in privacy protection. © 2010 IEEE.",Privacy protection | Secure deallocation | Taint analysis | Type qualifier,1,665-668,Conference Proceeding,Conference Paper,1.0,"Ouyang, Weiwei",36975874000,Enterprise Data Management,China,"it is very hard to ensure that software is free of sensitive information leaks because current common software takes very little measures to control sensitive data propagation or limit data lifetime. we present privacy-aware, a sensitive data tracker and eraser based on type qualifier inference. we have adapted a simplified type qualifier inference to the llvm framework, a low-level virtual machine infrastructure for a batch of languages. with type qualifier inference, privacy-aware can automatically reason about where the sensitive data has been propagated to and erase them before deallocation. we optimize privacy-aware with alias analysis and points-to analysis so that privacy-aware can be used as an effective annotation system for programmer to reduce the data lifetime in software development with minimal annotation effort. we have implemented privacy-aware by llvm-based instrumentation. the preliminary evaluation suggests that privacy-aware can effectively clear sensitive data while only incurring a small amount of overhead, on average below 10%, in our benchmark. our research provides evidence that requiring minimal programmer intervention, privacy-aware is an effective, efficient and autonomous strategy in privacy protection. © 2010 ieee.",privacy-aware: tracking and protecting sensitive information using automatic type inference
1911,2-s2.0-78651304827,10.1109/ICICISYS.2010.5658430,Software in distance education: An application using virtual reality,Pereira A.,"Proceedings - 2010 IEEE International Conference on Intelligent Computing and Intelligent Systems, ICIS 2010",2010-12-01,"This paper presents an educational software for the discipline of Formal Languages. With a simple interface, easy to understand and use, will present exercises where the student will see the robots in 3D and should be developed to minimize the automaton interacting directly with the 3D object and are supported by staff who have the ability to direct the User to perform task at hand. For the design of robots, the software uses 3D tools such as Blender and VRML and the development of education agents be used with the programming language PHP. ©2010 IEEE.",3D | Automat | Blender | Formal languages | Pedagogical agents | PHP | Regular expression | VRML,1,548-551,Conference Proceeding,Conference Paper,2.0,"Pereira, Adriana Soares;Piovesan, Sandra Dutra",36768837100;36768897600,Universidade Federal de Santa Maria,Brazil,"this paper presents an educational software for the discipline of formal languages. with a simple interface, easy to understand and use, will present exercises where the student will see the robots in 3d and should be developed to minimize the automaton interacting directly with the 3d object and are supported by staff who have the ability to direct the user to perform task at hand. for the design of robots, the software uses 3d tools such as blender and vrml and the development of education agents be used with the programming language php. ©2010 ieee.",software in distance education: an application using virtual reality
1912,2-s2.0-78650940205,10.4028/www.scientific.net/AMR.126-128.77,Research on machining simulation of Ultra High-Speed Grinding Machine Tool based on web,Wanshan W.,Advanced Materials Research,2010-12-01,"The future development of the manufacturing is using VR technology to make the machining simulation before the actual machining process made. The machining simulation of Ultra High-speed Grinding Machine Tool is researched in this paper. Firstly, using UG/NX software and VRML, the geometric modeling of machine tool is modeled. Secondly, through using Java and Javascript language, the operation and display of machining process of ultra high-speed grinding are realized. The main technologies include NC codes compiling, collision detection and material removal. Thirdly, the example of machining simulation using virtual ultra high-speed grinding machine tool can be obtained in the paper. Compared to other CNC machining simulation methods, the method in the paper has reality display, rich features, a good man-machine interaction, etc., and it does not rely on expensive CAD/CAM software. The system files generated by the machining simulation have the small size and can be transferred on the network easily © (2010) Trans Tech Publications, Switzerland.",Geometric simulation | Ultra high-speed grinding | Virtual machining | VRML,1,77-81,Book Series,Conference Paper,3.0,"Wanshan, Wang;Peng, Guan;Tianbiao, Yu",35079644500;55412622200;7401862209,Northeastern University,China,"the future development of the manufacturing is using vr technology to make the machining simulation before the actual machining process made. the machining simulation of ultra high-speed grinding machine tool is researched in this paper. firstly, using ug/nx software and vrml, the geometric modeling of machine tool is modeled. secondly, through using java and javascript language, the operation and display of machining process of ultra high-speed grinding are realized. the main technologies include nc codes compiling, collision detection and material removal. thirdly, the example of machining simulation using virtual ultra high-speed grinding machine tool can be obtained in the paper. compared to other cnc machining simulation methods, the method in the paper has reality display, rich features, a good man-machine interaction, etc., and it does not rely on expensive cad/cam software. the system files generated by the machining simulation have the small size and can be transferred on the network easily © (2010) trans tech publications, switzerland.",research on machining simulation of ultra high-speed grinding machine tool based on web
1913,2-s2.0-78650655459,10.4028/www.scientific.net/AMR.118-120.825,Research on web-based virtual grinding machine tool,Guan P.,Advanced Materials Research,2010-12-01,"With the development of Virtual Manufacturing (VM), Virtual Machine Tool (VMT) is presented as a new field of study, which can partially or completely achieve the main functions of the machine tool. As a result, it can improve the product design quality, short the product development cycles, and reduce the development costs. This paper presents a web-based virtual grinding machine tool system. Using the Internet 3D modeling language VRML 2.0, 3D graphic modeling of the machine tool is modeled. Combined with JavaScript language, the motion simulation, virtual assembly and machining process simulation are carried out. The system is based on VRML and B/S structure. Users only need to install a free plug-in, and operate the system with IE browser. Compared with the expensive CAD/CAM software, the system can be transferred on the Internet conveniently, and has free installation, low cost, portability and low requirements for the users. © (2010) Trans Tech Publications.",Motion simulation | Virtual assembly | Virtual machine tool | Virtual machining,0,825-829,Book Series,Conference Paper,4.0,"Guan, Peng;Zhang, Hengxian;Yu, Tianbiao;Wang, Wanshan",55412622200;36703572500;7401862209;35079644500,Northeastern University,China,"with the development of virtual manufacturing (vm), virtual machine tool (vmt) is presented as a new field of study, which can partially or completely achieve the main functions of the machine tool. as a result, it can improve the product design quality, short the product development cycles, and reduce the development costs. this paper presents a web-based virtual grinding machine tool system. using the internet 3d modeling language vrml 2.0, 3d graphic modeling of the machine tool is modeled. combined with javascript language, the motion simulation, virtual assembly and machining process simulation are carried out. the system is based on vrml and b/s structure. users only need to install a free plug-in, and operate the system with ie browser. compared with the expensive cad/cam software, the system can be transferred on the internet conveniently, and has free installation, low cost, portability and low requirements for the users. © (2010) trans tech publications.",research on web-based virtual grinding machine tool
1914,2-s2.0-78649430224,10.1109/ICCSE.2010.5593752,Design and development of 3D virtual DSLR camera based on VRML and JavaScript,Sun Y.,"ICCSE 2010 - 5th International Conference on Computer Science and Education, Final Program and Book of Abstracts",2010-12-01,"Experiment teaching is an important part of the curriculum of ""Photography and Art"". According to the teaching needs, it was studied in the paper how to design and develop a 3D virtual DSLR camera to ensure that students could have an intuitive understanding on a digital SLR camera. First, 3D experiment models were built by the professional modeling software-3DS MAX, but users could not interact with the model. Therefore, 3D models were exported to a document supported by VRML. Interaction between the user and the 3D models were designed based on VRML and JavaScript language. At last, the virtual system was published online, and could be browsed in the 3D scene at anytime. By moving mouse and rotating the camera, the students could observe the digital camera from different angles to acquaint various components, particularly could interact with the 3D camera, operate the buttons and the components to simulate the real operation. It helped increasing the study interest and improving teaching effect. ©2010 IEEE.",3D interaction | 3D model | 3D scene | DSLR camera | VRML,1,1380-1384,Conference Proceeding,Conference Paper,3.0,"Sun, Yongli;Liu, Lianshan;Li, Qinshi",56174907500;8211073800;56142987100,Shandong University of Science and Technology,China,"experiment teaching is an important part of the curriculum of ""photography and art"". according to the teaching needs, it was studied in the paper how to design and develop a 3d virtual dslr camera to ensure that students could have an intuitive understanding on a digital slr camera. first, 3d experiment models were built by the professional modeling software-3ds max, but users could not interact with the model. therefore, 3d models were exported to a document supported by vrml. interaction between the user and the 3d models were designed based on vrml and javascript language. at last, the virtual system was published online, and could be browsed in the 3d scene at anytime. by moving mouse and rotating the camera, the students could observe the digital camera from different angles to acquaint various components, particularly could interact with the 3d camera, operate the buttons and the components to simulate the real operation. it helped increasing the study interest and improving teaching effect. ©2010 ieee.",design and development of 3d virtual dslr camera based on vrml and javascript
1915,2-s2.0-78449281506,10.1109/RTCSA.2010.16,Towards pervasive mashups in embedded devices,Mikkonen T.,"Proceedings - 16th IEEE International Conference on Embedded and Real-Time Computing Systems and Applications, RTCSA 2010",2010-11-24,"The Web has become pervasive. This has led to a paradigm shift, where applications live on the Web as services, where they can be accessed using terminals of different types, such as regular computers, mobile devices, game consoles, and so on. The ability to dynamically combine data, code and other content from numerous web sites all over the world, and the ability to instantly publish services worldwide has opened up entirely new possibilities for software development. Such applications, referred to as mashups, are content aggregates that leverage the power of the Web to support instant, worldwide sharing of content. Unfortunately, for various reasons, the browser that is commonly used as the run-time environment of mashups is inadequate for hosting complex applications, in particular when considering embedded devices and subsystems that are not readily available in the web. In this paper, we introduce a runtime environment, intended for embedded devices, that is able to host mashups that combine data from the web and device specific peripherals, thus enabling context-aware mashups. As an example, we describe a mashup that combines map data from an existing map service and GPS data available from an external system. © 2010 IEEE.",Embedded devices | Mashup environment | Mobile runtime,8,35-42,Conference Proceeding,Conference Paper,2.0,"Mikkonen, Tommi;Salminen, Arto",54420813700;36630946500,Tampere University,Finland,"the web has become pervasive. this has led to a paradigm shift, where applications live on the web as services, where they can be accessed using terminals of different types, such as regular computers, mobile devices, game consoles, and so on. the ability to dynamically combine data, code and other content from numerous web sites all over the world, and the ability to instantly publish services worldwide has opened up entirely new possibilities for software development. such applications, referred to as mashups, are content aggregates that leverage the power of the web to support instant, worldwide sharing of content. unfortunately, for various reasons, the browser that is commonly used as the run-time environment of mashups is inadequate for hosting complex applications, in particular when considering embedded devices and subsystems that are not readily available in the web. in this paper, we introduce a runtime environment, intended for embedded devices, that is able to host mashups that combine data from the web and device specific peripherals, thus enabling context-aware mashups. as an example, we describe a mashup that combines map data from an existing map service and gps data available from an external system. © 2010 ieee.",towards pervasive mashups in embedded devices
1916,2-s2.0-78249246044,10.1109/CIT.2010.350,Research on mobile web applications end to end technology,Mi S.,"Proceedings - 10th IEEE International Conference on Computer and Information Technology, CIT-2010, 7th IEEE International Conference on Embedded Software and Systems, ICESS-2010, ScalCom-2010",2010-11-19,"As the rapid development of software and hardware platform in the mobile devices and mobile Internet, web application has been moved to a wide range of mobile devices. However, transporting traditional end to end technology of web applications to the mobile environment has encountered some difficulties as the mobile web application network bandwidth is small, network transmission is unstable, the client processing power is low.This paper analyzes the traditional end to end techniques of web applications, proposes the requirement of mobile environment end to end web application technology. And above points has been improved, tested, and achieves good results. © 2010 IEEE.",Embedded | End to end technology | Hybrid architecture | Mobile | Web application engine,1,2061-2065,Conference Proceeding,Conference Paper,3.0,"Mi, Siyu;Qiu, Zhijie;Luo, Lei",36624242600;22734685200;35275273000,University of Electronic Science and Technology of China,China,"as the rapid development of software and hardware platform in the mobile devices and mobile internet, web application has been moved to a wide range of mobile devices. however, transporting traditional end to end technology of web applications to the mobile environment has encountered some difficulties as the mobile web application network bandwidth is small, network transmission is unstable, the client processing power is low.this paper analyzes the traditional end to end techniques of web applications, proposes the requirement of mobile environment end to end web application technology. and above points has been improved, tested, and achieves good results. © 2010 ieee.",research on mobile web applications end to end technology
1918,2-s2.0-77956268738,10.1016/j.jbi.2010.04.004,OpenFlyData: An exemplar data web integrating gene expression data on the fruit fly Drosophila melanogaster,Miles A.,Journal of Biomedical Informatics,2010-10-01,"Motivation: Integrating heterogeneous data across distributed sources is a major requirement for in silico bioinformatics supporting translational research. For example, genome-scale data on patterns of gene expression in the fruit fly Drosophila melanogaster are widely used in functional genomic studies in many organisms to inform candidate gene selection and validate experimental results. However, current data integration solutions tend to be heavy weight, and require significant initial and ongoing investment of effort. Development of a common Web-based data integration infrastructure (a.k.a. data web), using Semantic Web standards, promises to alleviate these difficulties, but little is known about the feasibility, costs, risks or practical means of migrating to such an infrastructure. Results: We describe the development of OpenFlyData, a proof-of-concept system integrating gene expression data on D. melanogaster, combining Semantic Web standards with light-weight approaches to Web programming based on Web 2.0 design patterns. To support researchers designing and validating functional genomic studies, OpenFlyData includes user-facing search applications providing intuitive access to and comparison of gene expression data from FlyAtlas, the BDGP in situ database, and FlyTED, using data from FlyBase to expand and disambiguate gene names. OpenFlyData's services are also openly accessible, and are available for reuse by other bioinformaticians and application developers. Semi-automated methods and tools were developed to support labour- and knowledge-intensive tasks involved in deploying SPARQL services. These include methods for generating ontologies and relational-to-RDF mappings for relational databases, which we illustrate using the FlyBase Chado database schema; and methods for mapping gene identifiers between databases. The advantages of using Semantic Web standards for biomedical data integration are discussed, as are open issues. In particular, although the performance of open source SPARQL implementations is sufficient to query gene expression data directly from user-facing applications such as Web-based data fusions (a.k.a. mashups), we found open SPARQL endpoints to be vulnerable to denial-of-service-type problems, which must be mitigated to ensure reliability of services based on this standard. These results are relevant to data integration activities in translational bioinformatics. Availability: The gene expression search applications and SPARQL endpoints developed for OpenFlyData are deployed at http://openflydata.org. FlyUI, a library of JavaScript widgets providing re-usable user-interface components for Drosophila gene expression data, is available at http://flyui.googlecode.com. Software and ontologies to support transformation of data from FlyBase, FlyAtlas, BDGP and FlyTED to RDF are available at http://openflydata.googlecode.com. SPARQLite, an implementation of the SPARQL protocol, is available at http://sparqlite.googlecode.com. All software is provided under the GPL version 3 open source license. © 2010 Elsevier Inc.",Chado | Data integration | Data web | Drosophila | Gene expression | Performance | RDF | SPARQL | Triple store | User interface,14,752-761,Journal,Article,5.0,"Miles, Alistair;Zhao, Jun;Klyne, Graham;White-Cooper, Helen;Shotton, David",16747190700;55169120800;24385449500;6602993922;7003653225,College of Biomedical and Life Sciences;University of Oxford,United Kingdom;United Kingdom,"motivation: integrating heterogeneous data across distributed sources is a major requirement for in silico bioinformatics supporting translational research. for example, genome-scale data on patterns of gene expression in the fruit fly drosophila melanogaster are widely used in functional genomic studies in many organisms to inform candidate gene selection and validate experimental results. however, current data integration solutions tend to be heavy weight, and require significant initial and ongoing investment of effort. development of a common web-based data integration infrastructure (a.k.a. data web), using semantic web standards, promises to alleviate these difficulties, but little is known about the feasibility, costs, risks or practical means of migrating to such an infrastructure. results: we describe the development of openflydata, a proof-of-concept system integrating gene expression data on d. melanogaster, combining semantic web standards with light-weight approaches to web programming based on web 2.0 design patterns. to support researchers designing and validating functional genomic studies, openflydata includes user-facing search applications providing intuitive access to and comparison of gene expression data from flyatlas, the bdgp in situ database, and flyted, using data from flybase to expand and disambiguate gene names. openflydata's services are also openly accessible, and are available for reuse by other bioinformaticians and application developers. semi-automated methods and tools were developed to support labour- and knowledge-intensive tasks involved in deploying sparql services. these include methods for generating ontologies and relational-to-rdf mappings for relational databases, which we illustrate using the flybase chado database schema; and methods for mapping gene identifiers between databases. the advantages of using semantic web standards for biomedical data integration are discussed, as are open issues. in particular, although the performance of open source sparql implementations is sufficient to query gene expression data directly from user-facing applications such as web-based data fusions (a.k.a. mashups), we found open sparql endpoints to be vulnerable to denial-of-service-type problems, which must be mitigated to ensure reliability of services based on this standard. these results are relevant to data integration activities in translational bioinformatics. availability: the gene expression search applications and sparql endpoints developed for openflydata are deployed at http://openflydata.org. flyui, a library of javascript widgets providing re-usable user-interface components for drosophila gene expression data, is available at http://flyui.googlecode.com. software and ontologies to support transformation of data from flybase, flyatlas, bdgp and flyted to rdf are available at http://openflydata.googlecode.com. sparqlite, an implementation of the sparql protocol, is available at http://sparqlite.googlecode.com. all software is provided under the gpl version 3 open source license. © 2010 elsevier inc.",openflydata: an exemplar data web integrating gene expression data on the fruit fly drosophila melanogaster
1922,2-s2.0-77954961666,10.1145/1810139.1810143,Dynamic updates for web and cloud applications,Bhattacharya P.,APLWACA 2010 - Proceedings of the 2010 Workshop on Analysis and Programming Languages for Web Applications and Cloud Applications,2010-08-02,"The center of mass for newly-released applications is shifting from traditional, desktop or server programs, toward web and cloud computing applications.This shift is favorable to end-users, but puts additional burden on application developers and service providers.In particular, the newly emerging development methodologies, based on dynamic languages and multi-tier setups, complicate tasks such as verification and require end-to-end, rather than program-local guarantees.Moreover, service providers need to provide continuous service while accommodating the fast evolution pace characteristic of web and cloud applications. A promising approach for providing uninterrupted service while keeping applications up-to-date is to permit dynamic software updates, i.e., applying dynamic patches to running programs. In this paper we focus on safe dynamic updates for web and cloud applications; we point out difficulties associated with dynamic updates for these applications, present some of our preliminary results, and lay out directions for future work. Copyright © 2010 ACM.",Cloud computing | Dynamic software updating | Endto-end properties | On-the-fly upgrades | Online updates | Web applications,13,21-25,Conference Proceeding,Conference Paper,2.0,"Bhattacharya, Pamela;Neamtiu, Iulian",36187864400;10041674000,"University of California, Riverside",United States,"the center of mass for newly-released applications is shifting from traditional, desktop or server programs, toward web and cloud computing applications.this shift is favorable to end-users, but puts additional burden on application developers and service providers.in particular, the newly emerging development methodologies, based on dynamic languages and multi-tier setups, complicate tasks such as verification and require end-to-end, rather than program-local guarantees.moreover, service providers need to provide continuous service while accommodating the fast evolution pace characteristic of web and cloud applications. a promising approach for providing uninterrupted service while keeping applications up-to-date is to permit dynamic software updates, i.e., applying dynamic patches to running programs. in this paper we focus on safe dynamic updates for web and cloud applications; we point out difficulties associated with dynamic updates for these applications, present some of our preliminary results, and lay out directions for future work. copyright © 2010 acm.",dynamic updates for web and cloud applications
1925,2-s2.0-77951687486,10.1109/MS.2010.76,It's about Time to Take JavaScript (More) Seriously,Kienle H.,IEEE Software,2010-05-01,"JavaScript is often seen as a toy language. Yet, it offers a powerful mix of interesting language features based on functional programming, prototyping, and mutable objects. Web 2.0 apps use JavaScript extensively to realize sophisticated client-side functionality. Taken this into account, it isn't surprising that JavaScript made it to the top 10 in a survey on the most popular programming languages. JavaScript's capabilities are showcased by the Lively Kernel, which is an interactive platform and web development environment that runs in a browser window. It's implemented entirely in JavaScript, demonstrating that despite its weaknesses, JavaScript can be used as a general-purpose and systems programming language. © 2010 IEEE.",Javascript | Software engineering | Web 2.0 | Web browser,15,60-62,Journal,Article,1.0,"Kienle, Holger M.",6603072218,Mälardalens högskola,Sweden,"javascript is often seen as a toy language. yet, it offers a powerful mix of interesting language features based on functional programming, prototyping, and mutable objects. web 2.0 apps use javascript extensively to realize sophisticated client-side functionality. taken this into account, it isn't surprising that javascript made it to the top 10 in a survey on the most popular programming languages. javascript's capabilities are showcased by the lively kernel, which is an interactive platform and web development environment that runs in a browser window. it's implemented entirely in javascript, demonstrating that despite its weaknesses, javascript can be used as a general-purpose and systems programming language. © 2010 ieee.",it's about time to take javascript (more) seriously
1930,2-s2.0-78651557131,10.2174/2213275911003020148,Software product line engineering: A review of recent patents,Thurimella A.K.,Recent Patents on Computer Science,2010-01-01,"Software product line engineering (SPLE) is an emerging paradigm for the development of a family of products based on customization and reuse of artifacts. Several advantages such as reduction of time-to-market, improved product quality and reuse could be achieved by employing software product line engineering. Therefore, this is useful for the industrial sector developing product lines and is a fertile area for patents. Variability management, which enables customization and reuse, is the central part of software product line engineering. This paper provides a review of existing patents in the field of variability management. Particular patents include, feature-oriented approaches for variability management, variability at the level of components and source code, approaches for the identification and analysis of variability and rationale-based variability. The review is based on criteria qualifying the identification, instantiation and evolution of variability. Based on this review, a vision is provided on future patents/approaches in the area of software product line engineering. © 2010 Bentham Science Publishers Ltd.",Change management | Component-based software development | Rationale management | Requirements engineering | Software and systems engineering | Software product line engineering | Variability management,5,148-161,Journal,Review,2.0,"Thurimella, Anil Kumar;Padmaja, Maruthi T.",25630087000;55892671200,Harman International;Institute for Development and Research in Banking Technology India,United States;India,"software product line engineering (sple) is an emerging paradigm for the development of a family of products based on customization and reuse of artifacts. several advantages such as reduction of time-to-market, improved product quality and reuse could be achieved by employing software product line engineering. therefore, this is useful for the industrial sector developing product lines and is a fertile area for patents. variability management, which enables customization and reuse, is the central part of software product line engineering. this paper provides a review of existing patents in the field of variability management. particular patents include, feature-oriented approaches for variability management, variability at the level of components and source code, approaches for the identification and analysis of variability and rationale-based variability. the review is based on criteria qualifying the identification, instantiation and evolution of variability. based on this review, a vision is provided on future patents/approaches in the area of software product line engineering. © 2010 bentham science publishers ltd.",software product line engineering: a review of recent patents
1932,2-s2.0-77957853487,10.1109/ICSESS.2010.5552311,Notice of Retraction: Design and implementation of the coal enterprises electromechanical equipment management system based on B/S,Yang B.,"Proceedings 2010 IEEE International Conference on Software Engineering and Service Sciences, ICSESS 2010",2010-01-01,"In recent years, the level of mechanization is developing, the production conditions and processes of coal are becoming complex, so the scope of using electromechanical equipment is increasing greatly. But the efficient equipment management that is still in the state of extensive management started late in the coal mine and management methods of traditional mechanical equipment will not be able to adapt to the development of the current situation. This article gives a description about the electromechanical equipment management system general design and its function and establish electromechanical management system to the B/S for the structure on the basis of Web design method by adopting JSP[1] mode of operation and SQL 2000 database storage technology and the popular Struts framework and other technologies. © 2010 IEEE.",B/S architecture | Database | Electromechanical equipment management | Struts framework,0,519-522,Conference Proceeding,Retracted,3.0,"Yang, Bensheng;Xu, Jinda;Liu, Jiantao",35783746900;36099340600;36550364500,Hebei University of Engineering,China,"in recent years, the level of mechanization is developing, the production conditions and processes of coal are becoming complex, so the scope of using electromechanical equipment is increasing greatly. but the efficient equipment management that is still in the state of extensive management started late in the coal mine and management methods of traditional mechanical equipment will not be able to adapt to the development of the current situation. this article gives a description about the electromechanical equipment management system general design and its function and establish electromechanical management system to the b/s for the structure on the basis of web design method by adopting jsp[1] mode of operation and sql 2000 database storage technology and the popular struts framework and other technologies. © 2010 ieee.",notice of retraction: design and implementation of the coal enterprises electromechanical equipment management system based on b/s
1934,2-s2.0-77955102070,10.1145/1822018.1822041,User interface model discovery: Towards a generic approach,Gimblett A.,EICS'10 - Proceedings of the 2010 ACM SIGCHI Symposium on Engineering Interactive Computing Systems,2010-01-01,"UI model discovery is a lightweight formal method in which a model of an interactive system is automatically discovered by exploring the system's state space, simulating the actions of a user; such models are then amenable to automatic analysis targetting structural usability concerns. This paper specifies UI model discovery in some detail, providing a formal, generic and language-neutral API and discovery algorithm. The technique has been implemented in prototype systems on several programming platforms, yielding valuable usability insights. The API described here supports further development of these ideas in a systematic manner. © 2010 ACM.",Discovery tools | Interaction programming | Reverse engineering | Structural usability,24,145-154,Conference Proceeding,Conference Paper,2.0,"Gimblett, Andy;Thimbleby, Harold",8698016700;7005826808,Swansea University,United Kingdom,"ui model discovery is a lightweight formal method in which a model of an interactive system is automatically discovered by exploring the system's state space, simulating the actions of a user; such models are then amenable to automatic analysis targetting structural usability concerns. this paper specifies ui model discovery in some detail, providing a formal, generic and language-neutral api and discovery algorithm. the technique has been implemented in prototype systems on several programming platforms, yielding valuable usability insights. the api described here supports further development of these ideas in a systematic manner. © 2010 acm.",user interface model discovery: towards a generic approach
1937,2-s2.0-72449150615,10.1109/EmbeddedCom-ScalCom.2009.34,Research and implementation of code generator for information system based on SOA,Shan J.,"International Conference on Scalable Computing and Communications - The 8th International Conference on Embedded Computing, ScalCom-EmbeddedCom 2009",2009-12-28,"The agility of SOA (Service-Oriented Architecture) can response changes of business process effectively. To meet the requirements of rapid building business system for personality and high-speed changes based on business model, SOA was introduced. In this paper, firstly, the information system architecture based on SOA was built, moreover, Ajax (Asynchronous Javascript and XML) technology was adopted to create clients based on traditional B/S(Browser/Server) structure, which enhanced interaction and feasibility; Secondly, the method for rapid building business system was proposed, also the algorithms for workflow control and code generator was brought forward; Finally, the code generators, to reduce the complexity of the software development, is also provided. © 2009 IEEE.",Ajax | BPEL | Code generator | SOA | Web services | Workflow,1,143-147,Conference Proceeding,Conference Paper,4.0,"Shan, Jiru;Ma, Dianfu;Zhang, Bin;Luo, Wanming",35231149900;7402075451;57226875553;24329646900,Chinese Academy of Sciences;Beihang University,China;China,"the agility of soa (service-oriented architecture) can response changes of business process effectively. to meet the requirements of rapid building business system for personality and high-speed changes based on business model, soa was introduced. in this paper, firstly, the information system architecture based on soa was built, moreover, ajax (asynchronous javascript and xml) technology was adopted to create clients based on traditional b/s(browser/server) structure, which enhanced interaction and feasibility; secondly, the method for rapid building business system was proposed, also the algorithms for workflow control and code generator was brought forward; finally, the code generators, to reduce the complexity of the software development, is also provided. © 2009 ieee.",research and implementation of code generator for information system based on soa
1938,2-s2.0-70749161845,10.1109/ICSEA.2009.38,A case study of developing an IDE for embedded software using open source,Ertl D.,"4th International Conference on Software Engineering Advances, ICSEA 2009, Includes SEDES 2009: Simposio para Estudantes de Doutoramento em Engenharia de Software",2009-12-03,"IDEs (Integrated Development Environments) support software developers in their implementation work. However, embedded software has specific requirements, so an off-the-shelf IDE for this purpose does not exist. In such a case, this paper recommends developing a customized IDE based on open source software. We present a case study of developing such an IDE for the languages C#, Python and JavaScript. We used several open source projects with varying project status as a basis for our development. We analyzed developer communication within these open source projects and identified the benefits and the potential pitfalls for the case study. Moreover, we present the effort made in terms of person months and that reuse of open source software improves cost-efficiency for the development of such IDEs. © 2009 IEEE.",Embedded software | Integrated development environment (IDE) | Open source,0,191-196,Conference Proceeding,Conference Paper,2.0,"Ertl, Dominik;Krapfenbauer, Harald",26424652100;34880373400,Technische Universität Wien,Austria,"ides (integrated development environments) support software developers in their implementation work. however, embedded software has specific requirements, so an off-the-shelf ide for this purpose does not exist. in such a case, this paper recommends developing a customized ide based on open source software. we present a case study of developing such an ide for the languages c#, python and javascript. we used several open source projects with varying project status as a basis for our development. we analyzed developer communication within these open source projects and identified the benefits and the potential pitfalls for the case study. moreover, we present the effort made in terms of person months and that reuse of open source software improves cost-efficiency for the development of such ides. © 2009 ieee.",a case study of developing an ide for embedded software using open source
1946,2-s2.0-77952279944,10.1145/1509276.1509285,AOJS: Aspect-Oriented JavaScript programming framework for web development,Washizaki H.,"Proceedings of the 8th Workshop on Aspects, Components, and Patterns for Infrastructure Software, ACP4IS '09, Co-located with the 8th Int. Conf. Aspect-Oriented Software Development, AOSD.09",2009-12-01,"JavaScript is a popular scripting language that is particularly useful for client-side programming together with HTML /XML on the Web. As JavaScript programs become more complex and large, separation of concerns at the implementation level is a significant challenge. Aspect orientation has been a well known concept to realize improved separation; however, existing mechanisms require modifications in the target modules for aspect weaving in JavaScript (i.e., not ""complete"" separation). In this paper, we propose an Aspect-Oriented JavaScript framework, named ""AOJS"", which realizes the complete separation of aspects and other core modules in JavaScript. AOJS can specify function executions, variable assignments and file initializations in JavaScript programs as the joinpoints of aspects. Moreover, AOJS guarantees the complete separation of aspects and core program modules by adopting a proxy-based architecture for aspect weaving. By utilizing these features, we confirmed that AOJS offers improved modifiability and extendability for JavaScript programming. Copyright 2009 ACM.",aojs | aspect-oriented programming | javascript | separation of concerns | web development,18,31-35,Conference Proceeding,Conference Paper,11.0,"Washizaki, Hironori;Kubo, Atsuto;Mizumachi, Tomohiko;Eguchi, Kazuki;Fukazawa, Yoshiaki;Yoshioka, Nobukazu;Kanuka, Hideyuki;Kodaka, Toshihiro;Sugimoto, Nobuhide;Nagai, Yoichi;Yamamoto, Rieko",8905784000;8905783700;36142142500;36141642900;7101986896;8105005200;36141879100;36142221900;36142433000;36141900900;16023300400,Waseda University;Fujitsu Ltd.,Japan;Japan,"javascript is a popular scripting language that is particularly useful for client-side programming together with html /xml on the web. as javascript programs become more complex and large, separation of concerns at the implementation level is a significant challenge. aspect orientation has been a well known concept to realize improved separation; however, existing mechanisms require modifications in the target modules for aspect weaving in javascript (i.e., not ""complete"" separation). in this paper, we propose an aspect-oriented javascript framework, named ""aojs"", which realizes the complete separation of aspects and other core modules in javascript. aojs can specify function executions, variable assignments and file initializations in javascript programs as the joinpoints of aspects. moreover, aojs guarantees the complete separation of aspects and core program modules by adopting a proxy-based architecture for aspect weaving. by utilizing these features, we confirmed that aojs offers improved modifiability and extendability for javascript programming. copyright 2009 acm.",aojs: aspect-oriented javascript programming framework for web development
1949,2-s2.0-77249146572,10.1007/978-3-642-04425-0_11,SLIM - A lightweight environment for synchronous collaborative modeling,Thum C.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2009-12-01,"UML diagrams have become the de-facto standard for the visual modeling of software systems. The creation and discussion of these diagrams is a critical factor impacting the quality of the artifacts under development. Traditionally, facilitating the collaboration of globally distributed team members with heterogeneous system environments has been a costly and time-consuming endeavor. This paper aims to advance the state-of-the-art of model-based development by providing a collaboration environment, which supports the synchronous distributed creation and manipulation of UML diagrams and also lowers the technical entry barriers for participating in the modeling process. We present a prototypical implementation of a collaborative editor for synchronous lightweight modeling (SLIM). Applying innovative techniques, which only rely on functionality natively supported by modern web browsers, technical issues impeding clients to be integrated into the collaborative environment are avoided and ad hoc collaboration is facilitated. © 2009 Springer Berlin Heidelberg.",Collaborative Modeling | Real-Time Editor | Web 2.0,18,137-151,Book Series,Conference Paper,3.0,"Thum, Christian;Schwind, Michael;Schader, Martin",35575012800;57213525063;6602652616,Universität Mannheim,Germany,"uml diagrams have become the de-facto standard for the visual modeling of software systems. the creation and discussion of these diagrams is a critical factor impacting the quality of the artifacts under development. traditionally, facilitating the collaboration of globally distributed team members with heterogeneous system environments has been a costly and time-consuming endeavor. this paper aims to advance the state-of-the-art of model-based development by providing a collaboration environment, which supports the synchronous distributed creation and manipulation of uml diagrams and also lowers the technical entry barriers for participating in the modeling process. we present a prototypical implementation of a collaborative editor for synchronous lightweight modeling (slim). applying innovative techniques, which only rely on functionality natively supported by modern web browsers, technical issues impeding clients to be integrated into the collaborative environment are avoided and ad hoc collaboration is facilitated. © 2009 springer berlin heidelberg.",slim - a lightweight environment for synchronous collaborative modeling
1952,2-s2.0-74049161961,10.1145/1651309.1651317,A targeted web crawling for building malicious javascript collection,Likarish P.,"International Conference on Information and Knowledge Management, Proceedings",2009-12-01,"Malicious javascript frequently serves as a starting point of web-based attacks, in particular cross-site scripting. Thus detecting malicious javascript before execution can protect users from attacks such as malware infection, drive-by downloads, and even from participating in denial-of-service attacks as part of botnet sometimes. A large collection of malicious javascript would help with detector development, but by the time crawler arrives at blacklisted domains attackers and malicious scripts are often long gone. We have used classifiers to direct a web crawler better towards more likely locations of malicious scripts, and show how this targeted web crawler performs compared to crawler seed with blacklisted-domains. Copyright 2009 ACM.",Malicious javascript | Security | Web crawling,11,23-26,Conference Proceeding,Conference Paper,2.0,"Likarish, Peter;Jung, Eunjin",24773608300;12779963400,University of Iowa,United States,"malicious javascript frequently serves as a starting point of web-based attacks, in particular cross-site scripting. thus detecting malicious javascript before execution can protect users from attacks such as malware infection, drive-by downloads, and even from participating in denial-of-service attacks as part of botnet sometimes. a large collection of malicious javascript would help with detector development, but by the time crawler arrives at blacklisted domains attackers and malicious scripts are often long gone. we have used classifiers to direct a web crawler better towards more likely locations of malicious scripts, and show how this targeted web crawler performs compared to crawler seed with blacklisted-domains. copyright 2009 acm.",a targeted web crawling for building malicious javascript collection
1953,2-s2.0-72949109948,10.1145/1529282.1529416,Partitioning web applications between the server and the client,Kuuskeri J.,Proceedings of the ACM Symposium on Applied Computing,2009-12-01,"Web 2.0 and rich Internet application technologies are offering more and more sophisticated means for building compelling applications. At the same time the development of applications is becoming increasingly complex. While web applications are commonly relying on server-side processing, we aim at implementing a ""fat client"" and running applications mostly on the client. With this in mind we can derive a set of guidelines on how the applications should be partitioned between the server and the client. By following these directives and leaning on the traditional principles of good software development, we can address the issues of complexity that have lately emerged in web development. Copyright 2009 ACM.",AJAX | JavaScript | Lively kernel | Web application,14,647-652,Conference Proceeding,Conference Paper,2.0,"Kuuskeri, Janne;Mikkonen, Tommi",57192153416;54420813700,Tampere University,Finland,"web 2.0 and rich internet application technologies are offering more and more sophisticated means for building compelling applications. at the same time the development of applications is becoming increasingly complex. while web applications are commonly relying on server-side processing, we aim at implementing a ""fat client"" and running applications mostly on the client. with this in mind we can derive a set of guidelines on how the applications should be partitioned between the server and the client. by following these directives and leaning on the traditional principles of good software development, we can address the issues of complexity that have lately emerged in web development. copyright 2009 acm.",partitioning web applications between the server and the client
1954,2-s2.0-70450265575,10.1145/1582379.1582405,A distributed embedded web based automated testbed for wireless sensor networks,Möllendorf L.,"Proceedings of the 2009 ACM International Wireless Communications and Mobile Computing Conference, IWCMC 2009",2009-11-30,"Tests of distributed wireless networks pose various challenges with regard to node, link, path, and management problems. In this contribution a novel testbed architecture is presented, which helps in the development of distributed wireless networks. In the case of our project, it helped with the development of a routing protocol for energy autarkic network nodes. The testbed contains various elements: The major part is an embedded web server using web and AJAX technology. Thus, the management servers resources can be kept extremely lean, and a large number of those nodes can potentially be dislocated throughout the network. The server includes an extremely streamlined JavaScriptlibrary for use on very lean microcontrollers. Further elements include a wave-guided bread-board RF installation, fully controlled by software in order to automatically run as many testcases as possible and automatic test routines in the wireless nodes to significantly reduce the effort of regression tests. Copyright © 2009 ACM.",AJAX | Embedded web server | Energy-autarkic nodes | JavaScript library | Routing | Testing | Web2.0 | Wireless sensor network,0,111-115,Conference Proceeding,Conference Paper,4.0,"Möllendorf, Lars;Rahusen, David;Schauenberg, Daniel;Sikora, Axel",55942376200;35183952700;35183919800;15923813900,Duale Hochschule Lörrach,Germany,"tests of distributed wireless networks pose various challenges with regard to node, link, path, and management problems. in this contribution a novel testbed architecture is presented, which helps in the development of distributed wireless networks. in the case of our project, it helped with the development of a routing protocol for energy autarkic network nodes. the testbed contains various elements: the major part is an embedded web server using web and ajax technology. thus, the management servers resources can be kept extremely lean, and a large number of those nodes can potentially be dislocated throughout the network. the server includes an extremely streamlined javascriptlibrary for use on very lean microcontrollers. further elements include a wave-guided bread-board rf installation, fully controlled by software in order to automatically run as many testcases as possible and automatic test routines in the wireless nodes to significantly reduce the effort of regression tests. copyright © 2009 acm.",a distributed embedded web based automated testbed for wireless sensor networks
1956,2-s2.0-71049141842,10.1109/IFITA.2009.347,WebGIS resolution for management information system of disaster prevention,Yanhua C.,"Proceedings - 2009 International Forum on Information Technology and Applications, IFITA 2009",2009-11-16,"Data share and publication of disaster prevention information is in urgent need, and WebGIS resolution of management information system (MIS) is the main problems for Internet publication. Through analyzing the technique function of WebGIS and the character of information publication, management information system of disaster prevention is investigated The system application is developed based on MapXtreme in Windows 2000 Server operating system, the realtime browse in client and real-time publication of disaster prevention information in server are achieved In order to improve the speed of data transmitting through Internet, ASP technique is combined with ActiveX controls. System application is developed with network language VBScript and JavaScript under the ASP environment As an example application, MIS of disaster prevention for Internet publication in Tangshan City is worked out; Finally, some advice is proposed for the development of Internet publication system based on WebGIS. © 2009 IEEE.",Data share | Disaster prevention | Internet | MapXtreme | MIS | WebGIS,1,676-679,Conference Proceeding,Conference Paper,3.0,"Yanhua, Chen;Youpo, Su;Weiwei, Liu",57142796100;12646876900;24371467300,Ludong University;Hebei Polytechnic University,China;China,"data share and publication of disaster prevention information is in urgent need, and webgis resolution of management information system (mis) is the main problems for internet publication. through analyzing the technique function of webgis and the character of information publication, management information system of disaster prevention is investigated the system application is developed based on mapxtreme in windows 2000 server operating system, the realtime browse in client and real-time publication of disaster prevention information in server are achieved in order to improve the speed of data transmitting through internet, asp technique is combined with activex controls. system application is developed with network language vbscript and javascript under the asp environment as an example application, mis of disaster prevention for internet publication in tangshan city is worked out; finally, some advice is proposed for the development of internet publication system based on webgis. © 2009 ieee.",webgis resolution for management information system of disaster prevention
1958,2-s2.0-70350222381,10.1109/ICIMA.2009.5156665,Constructing innovative laboratory through intelligent learning objects,Li X.,"2009 International Conference on Industrial Mechatronics and Automation, ICIMA 2009",2009-10-27,"Last decade saw a rapid development of science and technology, which provides better educational environment and conditions for both learners and teachers. Advanced educational technology attracts more and more interests. Mobile robotics provides a motivating and innovative platform for performing laboratory experiments regarding interdiscipline including mechatronics, electronics, microcomputer and control. This paper reports the innovative educational environment of innovative laboratory built on intelligent robot. This innovative laboratory focuses on innovative educational software and technology for use in education. Through innovative design process, the intelligent modular robot platform constructs innovative learning environment through which students learn not only knowledge and skills but also how to collaborate with group members. Collaborative learning based on innovative laboratory helps to promote quality-oriented education and students' all-around development. It is student-oriented and career-oriented. Results indicate that the innovative laboratory not only imparting knowledge and skills to students but also developing their creativity, collaboration, practicing skill, innate ability and personality. It creates an environment in which teachers enjoy teaching and students enjoy learning and thus makes enjoyable education possible. ©2009 IEEE.",Education | Innovative laboratory | Intelligent learning object | Student-oriented,1,472-474,Conference Proceeding,Conference Paper,3.0,"Li, Xuemei;Lǔ, Jin Hu;Ding, Lixing",55718130000;57199240435;25929159200,Zhongkai University of Agriculture and Engineering,China,"last decade saw a rapid development of science and technology, which provides better educational environment and conditions for both learners and teachers. advanced educational technology attracts more and more interests. mobile robotics provides a motivating and innovative platform for performing laboratory experiments regarding interdiscipline including mechatronics, electronics, microcomputer and control. this paper reports the innovative educational environment of innovative laboratory built on intelligent robot. this innovative laboratory focuses on innovative educational software and technology for use in education. through innovative design process, the intelligent modular robot platform constructs innovative learning environment through which students learn not only knowledge and skills but also how to collaborate with group members. collaborative learning based on innovative laboratory helps to promote quality-oriented education and students' all-around development. it is student-oriented and career-oriented. results indicate that the innovative laboratory not only imparting knowledge and skills to students but also developing their creativity, collaboration, practicing skill, innate ability and personality. it creates an environment in which teachers enjoy teaching and students enjoy learning and thus makes enjoyable education possible. ©2009 ieee.",constructing innovative laboratory through intelligent learning objects
1961,2-s2.0-70349309909,10.1007/978-3-642-03426-8_11,A framework of multimedia E-learning design for engineering training,Borissova D.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2009-09-28,The paper presents a new framework approach for design and development of an interactive multimedia e-learning system for engineering training. The main goal of the paper is to encourage low cost developing of effective and customized e-learning systems for engineering training by using popular and inexpensive software tools. The proposed framework is a generalization of the authors' experience gained in developing of a pneumoautomatics e-training system. It can be used for developing of Web-based on-line or off-line e-learning systems for students or specialists customized training. The proposed framework is illustrated by some screen snapshots and descriptions of operational algorithms. The software realization of the pneumoautomatics example is done by means of HTML and JavaScript languages and was tested and used for students training. © 2009 Springer Berlin Heidelberg.,Engineering training | Multimedia | Virtual simulation | Web-based e-learning,7,88-97,Book Series,Conference Paper,2.0,"Borissova, Daniela;Mustakerov, Ivan",23990012600;23991365700,Institute of Information Technologies Bulgarian Academy of Sciences,Bulgaria,the paper presents a new framework approach for design and development of an interactive multimedia e-learning system for engineering training. the main goal of the paper is to encourage low cost developing of effective and customized e-learning systems for engineering training by using popular and inexpensive software tools. the proposed framework is a generalization of the authors' experience gained in developing of a pneumoautomatics e-training system. it can be used for developing of web-based on-line or off-line e-learning systems for students or specialists customized training. the proposed framework is illustrated by some screen snapshots and descriptions of operational algorithms. the software realization of the pneumoautomatics example is done by means of html and javascript languages and was tested and used for students training. © 2009 springer berlin heidelberg.,a framework of multimedia e-learning design for engineering training
1962,2-s2.0-70349123087,10.1007/978-3-642-02583-9_10,"A web-based, interactive annotation editor for the eCampus development environment for SCORM compliant e-learning modules",Deicke B.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2009-09-21,"The eCampus development environment was created in an interdisciplinary project at the University of Applied Sciences Fulda. Today it is a fully webbased application for the easy creation of E-Learning modules complying the SCORM standard. The webbased, interactive annotation editor for the eCampus development environment is used to both automatically and manually annotate existing OpenOffice documents in order to transform them into E-Learning modules. The editor is build using Open Source software and frameworks such as Ruby on Rails. © 2009 Springer Berlin Heidelberg.",Annotation | E-Learning | ECampus | JavaScript | OpenOffice | Ruby | Ruby on Rails | SCORM | Transformation | User friendly | Web,0,88-93,Book Series,Conference Paper,3.0,"Deicke, Benedikt;Milde, Jan Torsten;Pohl, Hans Martin",34879702600;23397575800;23398057200,Fachhochschule Fulda,Germany,"the ecampus development environment was created in an interdisciplinary project at the university of applied sciences fulda. today it is a fully webbased application for the easy creation of e-learning modules complying the scorm standard. the webbased, interactive annotation editor for the ecampus development environment is used to both automatically and manually annotate existing openoffice documents in order to transform them into e-learning modules. the editor is build using open source software and frameworks such as ruby on rails. © 2009 springer berlin heidelberg.","a web-based, interactive annotation editor for the ecampus development environment for scorm compliant e-learning modules"
1964,2-s2.0-66449118480,10.1016/j.csi.2008.03.014,The Oea framework for class-based object-oriented style JavaScript for web programming,Sagar M.,Computer Standards and Interfaces,2009-09-01,"In this paper we reflect on the differences between prototype-based and class-based programming languages and we introduce a new approach, called the Oea framework, that will allow JavaScript developers to write programs using a class-based style, which we assert is easy to use, has a syntax style that resembles that of the Java class-based approach and has high performance and reliability. We present a survey of the most widely used class-based techniques for JavaScript describing their methods and highlighting their shortcomings and compare the new approach with this earlier work. The approach has been developed in the context of a framework for developing Web applications using Scalable Vector Graphics (SVG), JavaScript and the Resource Description Framework (RDF) which involved the construction of substantial libraries and other code using the approach. © 2008 Elsevier B.V. All rights reserved.",JavaScript | Object-oriented programming | Web application development,2,894-905,Journal,Article,3.0,"Sagar, Musbah Sh;Duce, David A.;Younas, Muhammad",8407016700;7003846374;7003291652,Oxford Brookes University,United Kingdom,"in this paper we reflect on the differences between prototype-based and class-based programming languages and we introduce a new approach, called the oea framework, that will allow javascript developers to write programs using a class-based style, which we assert is easy to use, has a syntax style that resembles that of the java class-based approach and has high performance and reliability. we present a survey of the most widely used class-based techniques for javascript describing their methods and highlighting their shortcomings and compare the new approach with this earlier work. the approach has been developed in the context of a framework for developing web applications using scalable vector graphics (svg), javascript and the resource description framework (rdf) which involved the construction of substantial libraries and other code using the approach. © 2008 elsevier b.v. all rights reserved.",the oea framework for class-based object-oriented style javascript for web programming
1967,2-s2.0-60249085814,10.1016/j.eswa.2008.11.033,The design and use of the TMiner component-based data mining framework,Berzal F.,Expert Systems with Applications,2009-05-01,"This paper provides some practical guidelines for the design of data mining frameworks. It describes the rationale behind some of the key design decisions that guided the design, development, and implementation of the TMiner component-based data mining framework. TMiner is a flexible framework that can be used as a stand-alone tool or integrated into larger business intelligence (BI) solutions. TMiner is a general-purpose component-based system designed to support the whole KDD process into a single framework and thus facilitate the implementation of complex data mining scenarios. © 2008 Elsevier Ltd. All rights reserved.",Application frameworks | Component-based systems | Data mining | Design guidelines | Design patterns | Software architecture | Usage modes,8,7882-7887,Journal,Article,3.0,"Berzal, Fernando;Cubero, Juan Carlos;Jiménez, Aída",6602612825;55663885600;23473203200,IDBIS Research Group,Spain,"this paper provides some practical guidelines for the design of data mining frameworks. it describes the rationale behind some of the key design decisions that guided the design, development, and implementation of the tminer component-based data mining framework. tminer is a flexible framework that can be used as a stand-alone tool or integrated into larger business intelligence (bi) solutions. tminer is a general-purpose component-based system designed to support the whole kdd process into a single framework and thus facilitate the implementation of complex data mining scenarios. © 2008 elsevier ltd. all rights reserved.",the design and use of the tminer component-based data mining framework
1970,2-s2.0-77950610794,10.1109/ETT.2009.86,Notice of Retraction: Design of C language on-line study and test system based on web,Wen X.L.,ETT 2009 - 2009 2nd International Conference on Education Technology and Training,2009-01-01,"Article mainly introduces C language on-line study and test system. System uses ASP language as development language, and adopts software of DreamwaverMX, Fireworks MX, Flash MX, etc based on B/S structure, which realizing system web platform building. In this article, we mainly introduce design method and realization process of system part of sub-system's function module design and part of system website pages' source file in detail. Now, system has running in good state quite a long time, and realized on-line study and feedback between teachers and students, which can improve students' study interest and study initiative. In addition, system procedure has working accuracy, and control file can realize page precise controlling under different PC display resolution. © 2009 IEEE.",.asp file | ADO | C language | SQL | Study and test system | Web database,0,179-182,Conference Proceeding,Retracted,1.0,"Wen, X. L.",23098853500,Zhengzhou Institute of Aeronautical Industry Management,China,"article mainly introduces c language on-line study and test system. system uses asp language as development language, and adopts software of dreamwavermx, fireworks mx, flash mx, etc based on b/s structure, which realizing system web platform building. in this article, we mainly introduce design method and realization process of system part of sub-system's function module design and part of system website pages' source file in detail. now, system has running in good state quite a long time, and realized on-line study and feedback between teachers and students, which can improve students' study interest and study initiative. in addition, system procedure has working accuracy, and control file can realize page precise controlling under different pc display resolution. © 2009 ieee.",notice of retraction: design of c language on-line study and test system based on web
1971,2-s2.0-67449096498,10.3233/978-1-58603-979-0-315,Architectural and usability considerations in the development of a Web 2.0-based EHR,Senathirajah Y.,Studies in Health Technology and Informatics,2009-01-01,"In our previous work, we described an electronic health record (EHR) architecture based on Web 2.0 principles. With this architecture, users in healthcare and public health can select, configure, share and control the information and interfaces they use by means of simple techniques such as ""dragand-drop"" without the intervention of programmers. We extend this work by discussing architectural and usability considerations important for creating such an EHR. These include: new affordances facilitating element creation, responsiveness while using rich client-side interaction, consistency versus flexibility, security, workflow and evaluation. © 2009 ITCH 2009 Steering Committee and IOS Press. All rights reserved.",EHR interface | Usability | Web 2.0 | Web widget,11,315-321,Book Series,Conference Paper,2.0,"Senathirajah, Yalini;Bakken, Suzanne",15048725600;7005058463,Columbia University,United States,"in our previous work, we described an electronic health record (ehr) architecture based on web 2.0 principles. with this architecture, users in healthcare and public health can select, configure, share and control the information and interfaces they use by means of simple techniques such as ""dragand-drop"" without the intervention of programmers. we extend this work by discussing architectural and usability considerations important for creating such an ehr. these include: new affordances facilitating element creation, responsiveness while using rich client-side interaction, consistency versus flexibility, security, workflow and evaluation. © 2009 itch 2009 steering committee and ios press. all rights reserved.",architectural and usability considerations in the development of a web 2.0-based ehr
1973,2-s2.0-57349185638,10.1145/1368088.1368090,Topes: Reusable abstractions for validating data,Scaffidi C.,Proceedings - International Conference on Software Engineering,2008-12-15,"Programmers often omit input validation when inputs can appear in many different formats or when validation criteria cannot be precisely specified. To enable validation in these situations, we present a new technique that puts valid inputs into a consistent format and that identifies "" questionable"" inputs which might be valid or invalid, so that these values can be double-checked by a person or a program. Our technique relies on the concept of a ""tope"", which is an application-independent abstraction describing how to recognize and transform values in a category of data. We present our definition of topes and describe a development environment that supports the implementation and use of topes. Experiments with web application and spreadsheet data indicate that using our technique improves the accuracy and reusability of validation code and also improves the effectiveness of subsequent data cleaning such as duplicate identification. © 2008 ACM.",Abstraction | Data | Validation,34,1-10,Conference Proceeding,Conference Paper,3.0,"Scaffidi, Christopher;Myers, Brad;Shaw, Mary",14052967600;7202684451;7401651885,Carnegie Mellon University,United States,"programmers often omit input validation when inputs can appear in many different formats or when validation criteria cannot be precisely specified. to enable validation in these situations, we present a new technique that puts valid inputs into a consistent format and that identifies "" questionable"" inputs which might be valid or invalid, so that these values can be double-checked by a person or a program. our technique relies on the concept of a ""tope"", which is an application-independent abstraction describing how to recognize and transform values in a category of data. we present our definition of topes and describe a development environment that supports the implementation and use of topes. experiments with web application and spreadsheet data indicate that using our technique improves the accuracy and reusability of validation code and also improves the effectiveness of subsequent data cleaning such as duplicate identification. © 2008 acm.",topes: reusable abstractions for validating data
1975,2-s2.0-84879655567,10.1007/978-1-4020-8735-6_92,Model driven development of AJAX-based user interfaces,Haubold T.,"Innovations and Advanced Techniques in Systems, Computing Sciences and Software Engineering",2008-12-01,"This paper presents an approach to develop user interfaces using MDSD (model driven software development) and UML. An UML profile is introduced to model user interfaces and to develop a sample AJAX (Asynchronous JavaScript And XML)-based web application. The paper covers common aspects and structures of user interfaces, introduces the main benefits of AJAX and outlines the architecture used to build a web application. © Springer Science+Business Media B.V. 2008.",AJAX | MDSD | UML | User interface | Web application | Widget,0,495-499,Conference Proceeding,Conference Paper,3.0,"Haubold, Tobias;Beier, Georg;Golubski, Wolfgang",35248012400;26421624200;6602601249,Zwickau University of Applied Sciences Informatics,Germany,"this paper presents an approach to develop user interfaces using mdsd (model driven software development) and uml. an uml profile is introduced to model user interfaces and to develop a sample ajax (asynchronous javascript and xml)-based web application. the paper covers common aspects and structures of user interfaces, introduces the main benefits of ajax and outlines the architecture used to build a web application. © springer science+business media b.v. 2008.",model driven development of ajax-based user interfaces
1980,2-s2.0-70349114124,10.1145/1497308.1497426,Dynamic Service integration using web-based workflows,Lopes P.,"Proceedings of the 10th International Conference on Information Integration and Web-based Applications and Services, iiWAS 2008",2008-12-01,"Web services have been the main leverage to the development of Service Oriented Architecture (SOA), essentially a collection of interacting software agents with a loosely coupling organization. Despite several composition solutions already exist, the integration of services in a seamless and user-friendly way is not yet a complete solved problem. Most of the times, this integration is performed in hard-coded monolithic desktop applications. This paper presents a web-based application, supported on web2.0 principles, that was designed to integrate and coordinate services and data sources, simplifying knowledge extraction in diverse scientific areas. The system architecture follows an agile solution based on workflows, which may be dynamically designed by the user in a common browser. The framework allows building specific protocols for information retrieval enabling the user to access distributed resources in a single centralized interface. © 2008 ACM.",AJAX | Data integration | Services composition | SOA | Web services | Workflow management,1,622-625,Conference Proceeding,Conference Paper,3.0,"Lopes, Pedro;Arrais, Joel;Oliveira, José Luís",55538753378;18036537200;57193360895,Universidade de Aveiro,Portugal,"web services have been the main leverage to the development of service oriented architecture (soa), essentially a collection of interacting software agents with a loosely coupling organization. despite several composition solutions already exist, the integration of services in a seamless and user-friendly way is not yet a complete solved problem. most of the times, this integration is performed in hard-coded monolithic desktop applications. this paper presents a web-based application, supported on web2.0 principles, that was designed to integrate and coordinate services and data sources, simplifying knowledge extraction in diverse scientific areas. the system architecture follows an agile solution based on workflows, which may be dynamically designed by the user in a common browser. the framework allows building specific protocols for information retrieval enabling the user to access distributed resources in a single centralized interface. © 2008 acm.",dynamic service integration using web-based workflows
1983,2-s2.0-62849103390,10.3844/jcssp.2008.1012.1019,A complete automation of unit testing for JavaScript programs,Alshraideh M.,Journal of Computer Science,2008-12-01,"Problem statement: Program testing is expensive and labor intensive, often consuming more than half of the total development costs, and yet it is frequently not done well and the results are not always satisfactory. The objective of this paper is to present an automatic test data generation tool that aims to completely automate unit testing of JavaScript functions. The methodology: In order to use the proposed tool, the tester annotates the files that contain the class to be tested. Moreover, the tester must specify the test data coverage criterion to be used, either branch coverage or mutation analysis. However, the tool is then integrated into the JavaScript compiler and test generation is invoked by a command line option. Also, the code to be tested is parsed into an abstract syntax tree from which the test tool generates a program dependency graph for the function under test. However, if mutation analysis coverage is required, the abstract syntax tree for a meta-mutant program is also generated. To provide guidance for the test data search, the function under test instrumented in accordance with the coverage criterion. Branch predicate expressions are always instrumented, in the case of mutation coverage, mutated statements are also instrumented. Compilation then continues from the modified abstract syntax tree to generate instrumented executables that were loaded into the test data search module. Results: The experiment done in our study by using the proposed tool for branch coverage shows that the most effective result for string equality was obtained using the edit distance fitness function, while no significant difference was found in the fitness function for string ordering. Through exhaustive mulation coverage 8% are found to be equivalent. Conclusion: By having a complete automation it reduces the cost of software testing dramatically and also facilitates continuous testing. It is reported that at least 50% of the total software development costs is due to testing, and 10-15% of development time is wasted due to frequent stops for regression testing. Automation will also help get rid of cognitive biases that have been found in human testers. Acknowledgment: The researcher would like to express their gratitude to the anonymous referees for their valuable and helpful comments and suggestions in improving the study. © 2008 Science Publications.",Black box | Genetic algorithms | Mutation testing | Software testing | White box,15,1012-1019,Journal,Article,1.0,"Alshraideh, Mohammad",14420919900,The University of Jordan,Jordan,"problem statement: program testing is expensive and labor intensive, often consuming more than half of the total development costs, and yet it is frequently not done well and the results are not always satisfactory. the objective of this paper is to present an automatic test data generation tool that aims to completely automate unit testing of javascript functions. the methodology: in order to use the proposed tool, the tester annotates the files that contain the class to be tested. moreover, the tester must specify the test data coverage criterion to be used, either branch coverage or mutation analysis. however, the tool is then integrated into the javascript compiler and test generation is invoked by a command line option. also, the code to be tested is parsed into an abstract syntax tree from which the test tool generates a program dependency graph for the function under test. however, if mutation analysis coverage is required, the abstract syntax tree for a meta-mutant program is also generated. to provide guidance for the test data search, the function under test instrumented in accordance with the coverage criterion. branch predicate expressions are always instrumented, in the case of mutation coverage, mutated statements are also instrumented. compilation then continues from the modified abstract syntax tree to generate instrumented executables that were loaded into the test data search module. results: the experiment done in our study by using the proposed tool for branch coverage shows that the most effective result for string equality was obtained using the edit distance fitness function, while no significant difference was found in the fitness function for string ordering. through exhaustive mulation coverage 8% are found to be equivalent. conclusion: by having a complete automation it reduces the cost of software testing dramatically and also facilitates continuous testing. it is reported that at least 50% of the total software development costs is due to testing, and 10-15% of development time is wasted due to frequent stops for regression testing. automation will also help get rid of cognitive biases that have been found in human testers. acknowledgment: the researcher would like to express their gratitude to the anonymous referees for their valuable and helpful comments and suggestions in improving the study. © 2008 science publications.",a complete automation of unit testing for javascript programs
1984,2-s2.0-62449104732,10.1109/CAIDCD.2008.4730771,3D modeling and functional design of reading room in a virtual library,Li J.,9th International Conference on Computer-Aided Industrial Design and Conceptual Design: Multicultural Creation and Design - CAIDCD 2008,2008-12-01,"Virtual Reality technology has been widely applied in many different fields, which has large development potentiality and good prospect. This paper involves related technologies of virtual reality based on the PC and construction of a walk-through system. The realistic feeling of panorama images and the real-time properties while roaming are designed. The library of Liaoning Shihua University is taken for the research example. For the modeling of the library based on the 3DS Max software and the VRML language, the author focuses on the function design of the virtual reading room. The JavaScript language node is used and the VRML language and Java language are connected with the database. The virtual library walk-through system and information inquiry technology are implemented. © 2008 IEEE.",3D Modeling | Information inquiry | Virtual Reality | VRML,1,1170-1173,Conference Proceeding,Conference Paper,3.0,"Li, Jiang;Zhang, Yan;Lu, Ziwei",55720611500;57196209544;9636533100,Liaoning University of Petroleum and Chemical Technology,China,"virtual reality technology has been widely applied in many different fields, which has large development potentiality and good prospect. this paper involves related technologies of virtual reality based on the pc and construction of a walk-through system. the realistic feeling of panorama images and the real-time properties while roaming are designed. the library of liaoning shihua university is taken for the research example. for the modeling of the library based on the 3ds max software and the vrml language, the author focuses on the function design of the virtual reading room. the javascript language node is used and the vrml language and java language are connected with the database. the virtual library walk-through system and information inquiry technology are implemented. © 2008 ieee.",3d modeling and functional design of reading room in a virtual library
1986,2-s2.0-55649097593,10.1002/spe.875,Emulating access grid features at web endpoints: A developer's view,Sendín-Raña P.,Software - Practice and Experience,2008-11-10,"This paper presents the development experience and the evaluation of a system to emulate interactive features of Access Grid virtual rooms (venues) at Web endpoints. The system includes a toolset to demultiplex Access Grid sources, transcode them to adequate formats for Internet distribution and store the resulting multimedia streams in repositories in real time. A specialized server asynchronously delivers those streams to standard Web browsers, which synchronize them and emulate typical Access Grid interactive features such as multiple windows or dynamic video selection. Web browsers can compose multiple independent streams. We call the resulting paradigm Presentations on Demand. From the point of view of software practice, the system relies on a combination of SMIL scripts, CSS and Javascript. Copyright © 2008 John Wiley & Sons, Ltd.",Access grid | Multimedia distribution systems | SMIL | Streaming | Transcoding | Videoconferencing,0,1393-1410,Journal,Conference Paper,7.0,"Sendín-Raña, Pablo;Otero-Alonso, Nicolás;De Miguel, Vicente Goyanes;González-Castaño, Francisco J.;Rodríguez-Hernández, Pedro S.;Gil-Castiñeira, Felipe;Costa-Montenegro, Enrique",24451011500;24451255200;24450171900;6603703432;7004596616;8988943300;8299881000,Universidade de Vigo,Spain,"this paper presents the development experience and the evaluation of a system to emulate interactive features of access grid virtual rooms (venues) at web endpoints. the system includes a toolset to demultiplex access grid sources, transcode them to adequate formats for internet distribution and store the resulting multimedia streams in repositories in real time. a specialized server asynchronously delivers those streams to standard web browsers, which synchronize them and emulate typical access grid interactive features such as multiple windows or dynamic video selection. web browsers can compose multiple independent streams. we call the resulting paradigm presentations on demand. from the point of view of software practice, the system relies on a combination of smil scripts, css and javascript. copyright © 2008 john wiley & sons, ltd.",emulating access grid features at web endpoints: a developer's view
1987,2-s2.0-54249099993,10.1007/978-3-540-69927-9_2,Lifting transformational models of product lines: A case study,Freeman G.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2008-10-27,"Model driven development (MDD) of software product lines (SPLs) merges two increasing important paradigms that synthesize programs by transformation. MDD creates programs by transforming models, and SPLs elaborate programs by applying transformations called features. In this paper, we present the design and implementation of a transformational model of a product line of scalar vector graphics and JavaScript applications. We explain how we simplified our implementation by lifting selected features and their compositions from our original product line (whose implementations were complex) to features and their compositions of another product line (whose specifications were simple). We used operators to map higher-level features and their compositions to their lower-level counterparts. Doing so exposed commuting relationships among feature compositions in both product lines that helped validate our model and implementation. © Springer-Verlag Berlin Heidelberg 2008.",Code generation | Features | Highlevel transformations | Model composition | Product-lines. | Transformation reuse,5,16-30,Book Series,Conference Paper,3.0,"Freeman, Greg;Batory, Don;Lavender, Greg",25521650000;7004911762;6603901480,The University of Texas at Austin,United States,"model driven development (mdd) of software product lines (spls) merges two increasing important paradigms that synthesize programs by transformation. mdd creates programs by transforming models, and spls elaborate programs by applying transformations called features. in this paper, we present the design and implementation of a transformational model of a product line of scalar vector graphics and javascript applications. we explain how we simplified our implementation by lifting selected features and their compositions from our original product line (whose implementations were complex) to features and their compositions of another product line (whose specifications were simple). we used operators to map higher-level features and their compositions to their lower-level counterparts. doing so exposed commuting relationships among feature compositions in both product lines that helped validate our model and implementation. © springer-verlag berlin heidelberg 2008.",lifting transformational models of product lines: a case study
1990,2-s2.0-51049121124,10.1109/ICIW.2008.97,UTISP: An urban traffic information portal based on WebGIS,Liu Y.,"Proceedings - 3rd International Conference on Internet and Web Applications and Services, ICIW 2008",2008-09-10,"Publishing and delivering traffic information generally depend on message board and public radio service in China, which usually sends out static information without dynamic interaction between the services and the users. With the development of WebGIS and its successful application, it is possible to introduce the web-based multiple architecture into the traffic information system. Currently, most WebGIS portals only provide static information in words and figures without any significant improvement in dynamic aspect, which is a very important requirement for traffic information system. We develop an urban traffic information portal for dynamic information updating and responding, which is based on the fast growing rich internet application and WebGIS technology. The portal can not only provide the real-time information but also can interact with users for more specific. This paper introduces the multi-layer architecture used in our project. Reusable services related with GIS services are designed and encapsulated as portlet. We briefly introduce some implements and optimization at the end of this paper. © 2008 IEEE.",Rich internet application | Traffic information service | WebGIS,4,319-324,Conference Proceeding,Conference Paper,4.0,"Liu, Yan;Zhuang, Mingguang;Wang, Qingling;Yu, Biao",56023515500;24767238300;56097722800;6507918051,Tongji University,China,"publishing and delivering traffic information generally depend on message board and public radio service in china, which usually sends out static information without dynamic interaction between the services and the users. with the development of webgis and its successful application, it is possible to introduce the web-based multiple architecture into the traffic information system. currently, most webgis portals only provide static information in words and figures without any significant improvement in dynamic aspect, which is a very important requirement for traffic information system. we develop an urban traffic information portal for dynamic information updating and responding, which is based on the fast growing rich internet application and webgis technology. the portal can not only provide the real-time information but also can interact with users for more specific. this paper introduces the multi-layer architecture used in our project. reusable services related with gis services are designed and encapsulated as portlet. we briefly introduce some implements and optimization at the end of this paper. © 2008 ieee.",utisp: an urban traffic information portal based on webgis
1993,2-s2.0-46749124239,10.1002/smr.366,"An empirical validation of object-oriented class complexity metrics and their ability to predict error-prone classes in highly iterative, or agile, software: A case study",Olague H.,Journal of Software Maintenance and Evolution,2008-05-01,"Empirical studies have shown complexity metrics to be good predictors of testing effort and maintainability in traditional, imperative programming languages. Empirical validation studies have also shown that complexity is a good predictor of initial quality and reliability in object-oriented (OO) software. To date, one of the most empirically validated OO complexity metrics is the Chidamber and Kemerer Weighted Methods in a Class (WMC). However, there are many more OO complexity metrics whose predictive power has not been as extensively explored. In this study, we explore the predictive ability of several complexity-related metrics for OO software that have not been heavily validated. We do this by exploring their ability to measure quality in an evolutionary software process, by correlating these metrics to defect data for six versions of Rhino, an open-source implementation of JavaScript written in Java. Using statistical techniques such as Spearman's correlation, principal component analysis, binary logistic regression models and their respective validations, we show that some lesser known complexity metrics including Michura et al.'s standard deviation method complexity and Etzkorn et al.'s average method complexity are more consistent predictors of OO quality than any variant of the Chidamber and Kemerer WMC metric. We also show that these metrics are useful in identifying fault-prone classes in software developed using highly iterative or agile software development processes. Copyright © 2008 John Wiley & Sons, Ltd.",Agile software development processes | Complexity metrics | Empirical validation | Fault proneness | Object-oriented complexity metrics | Object-oriented metrics,25,171-197,Journal,Article,4.0,"Olague, Hector M.;Etzkorn, Letha H.;Messimer, Sherri L.;Delugach, Harry S.",14123567900;6701756655;6601956218;6601973446,The University of Alabama in Huntsville;U.S. Army Space and Missile Defense Command,United States;United States,"empirical studies have shown complexity metrics to be good predictors of testing effort and maintainability in traditional, imperative programming languages. empirical validation studies have also shown that complexity is a good predictor of initial quality and reliability in object-oriented (oo) software. to date, one of the most empirically validated oo complexity metrics is the chidamber and kemerer weighted methods in a class (wmc). however, there are many more oo complexity metrics whose predictive power has not been as extensively explored. in this study, we explore the predictive ability of several complexity-related metrics for oo software that have not been heavily validated. we do this by exploring their ability to measure quality in an evolutionary software process, by correlating these metrics to defect data for six versions of rhino, an open-source implementation of javascript written in java. using statistical techniques such as spearman's correlation, principal component analysis, binary logistic regression models and their respective validations, we show that some lesser known complexity metrics including michura et al.'s standard deviation method complexity and etzkorn et al.'s average method complexity are more consistent predictors of oo quality than any variant of the chidamber and kemerer wmc metric. we also show that these metrics are useful in identifying fault-prone classes in software developed using highly iterative or agile software development processes. copyright © 2008 john wiley & sons, ltd.","an empirical validation of object-oriented class complexity metrics and their ability to predict error-prone classes in highly iterative, or agile, software: a case study"
1994,2-s2.0-44849139537,10.1055/s-2008-1027217,A radiological case collection with interactive character as a new element in the education of medical students,Heye T.,RoFo Fortschritte auf dem Gebiet der Rontgenstrahlen und der Bildgebenden Verfahren,2008-04-01,"Purpose: Evaluation of an interactive, multimedia case-based learning platform for the radiological education of medical students. Materials and Methods: An interactive electronic learning platform for the education of medical students was built in html format independent of the operating system in the context of the Heidelberg Curriculum Medicinale (HeiCuMed). A case collection of 30 common and authentic clinical cases is used as the central theme and clinical background. The user has to work on each case by making decisions regarding a selection of diagnostic modalities and by analyzing the chosen studies. After a reasonable selection and sequence of diagnostic radiological modalities and their interpretation, a diagnosis has to be made. An extensive collection of normal findings for any modality is available for the user as a reference in correlation with the pathology at anytime within each case. The case collection consists of 2053 files with 1109 Internet pages (html) and 869 image files (jpeg) with approximately 10000 crosslinks (links). The case collection was evaluated by a questionnaire (scale 1 - 5) at the end of the radiological student course. The development of the results of the radiological course exam was analyzed to investigate any effect on the learning performance after the case collection was introduced. Results: 97.6% of the course participants would use the case collection beyond the radiological student course to learn radiology in their medical studies. The handling of the case collection was rated excellent in 36.9%, good in 54.6%, satisfactory in 8% and unsatisfactory in 0.4%. 41% felt that the case collection was overall excellent, 49.2% good, 7.8% satisfactory, 1.6% unsatisfactory and 0.4% poor. A positive trend in the development of the results in the radiological course exam with less variance after the introduction of the case collection was found but failed statistical significance. Conclusion: A platform-independent, interactive, multimedia learning platform with authentic clinical cases and multiple choice elements for the user is the ideal method for supporting and expanding medical education in radiology. The usefulness and the reasonable exertion of diagnostic modalities are conveyed in a practical context as teaching goals. The high acceptance among students is based on the interactivity and use of multimedia. © Georg Thieme Verlag KG Stuttgart.",Case collection | Curriculum | Education | Internet | Multimedia | Teaching,16,337-344,Journal,Article,5.0,"Heye, Tobias;Kurz, P.;Eiers, M.;Kauffmann, G. W.;Schipp, A.",15048014800;23568139100;12785741700;35492791600;6507358091,Universitätsklinikum Heidelberg;Radiologische Klinik,Germany;Germany,"purpose: evaluation of an interactive, multimedia case-based learning platform for the radiological education of medical students. materials and methods: an interactive electronic learning platform for the education of medical students was built in html format independent of the operating system in the context of the heidelberg curriculum medicinale (heicumed). a case collection of 30 common and authentic clinical cases is used as the central theme and clinical background. the user has to work on each case by making decisions regarding a selection of diagnostic modalities and by analyzing the chosen studies. after a reasonable selection and sequence of diagnostic radiological modalities and their interpretation, a diagnosis has to be made. an extensive collection of normal findings for any modality is available for the user as a reference in correlation with the pathology at anytime within each case. the case collection consists of 2053 files with 1109 internet pages (html) and 869 image files (jpeg) with approximately 10000 crosslinks (links). the case collection was evaluated by a questionnaire (scale 1 - 5) at the end of the radiological student course. the development of the results of the radiological course exam was analyzed to investigate any effect on the learning performance after the case collection was introduced. results: 97.6% of the course participants would use the case collection beyond the radiological student course to learn radiology in their medical studies. the handling of the case collection was rated excellent in 36.9%, good in 54.6%, satisfactory in 8% and unsatisfactory in 0.4%. 41% felt that the case collection was overall excellent, 49.2% good, 7.8% satisfactory, 1.6% unsatisfactory and 0.4% poor. a positive trend in the development of the results in the radiological course exam with less variance after the introduction of the case collection was found but failed statistical significance. conclusion: a platform-independent, interactive, multimedia learning platform with authentic clinical cases and multiple choice elements for the user is the ideal method for supporting and expanding medical education in radiology. the usefulness and the reasonable exertion of diagnostic modalities are conveyed in a practical context as teaching goals. the high acceptance among students is based on the interactivity and use of multimedia. © georg thieme verlag kg stuttgart.",a radiological case collection with interactive character as a new element in the education of medical students
1995,2-s2.0-69849130557,10.1017/S0958344008000815,Evaluating the language resources of chatbots for their potential in English as a second language,Coniam D.,ReCALL,2008-01-01,"This paper investigates the linguistic worth of current ‘chatbot’ programs - software programs which attempt to hold a conversation, or interact, in English - as a precursor to their potential as an ESL (English as a second language) learning resource. After some initial background to the development of chatbots, and a discussion of the Loebner Prize Contest for the most ‘human’ chatbot (the ‘Turing Test’), the paper describes an in-depth study evaluating the linguistic accuracy of a number of chatbots available online. Since the ultimate purpose of the current study concerns chatbots' potential with ESL learners, the analysis of language embraces not only an examination of features of language from a native-speaker's perspective (the focus of the Turing Test), but also aspects of language from a second-language-user's perspective. Analyses indicate that while the winner of the 2005 Loebner Prize is the most able chatbot linguistically, it may not necessarily be the chatbot most suited to ESL learners. The paper concludes that while substantial progress has been made in terms of chatbots' language-handling, a robust ESL ‘conversation practice machine’ (Atwell, 1999) is still some way off being a reality. © 2008, European Association for Computer Assisted Language Learning. All rights reserved.",CALL | chatbots | ESL | linguistic accuracy,32,98-116,Journal,Article,1.0,"Coniam, David",6602700322,Chinese University of Hong Kong,Hong Kong,"this paper investigates the linguistic worth of current ‘chatbot’ programs - software programs which attempt to hold a conversation, or interact, in english - as a precursor to their potential as an esl (english as a second language) learning resource. after some initial background to the development of chatbots, and a discussion of the loebner prize contest for the most ‘human’ chatbot (the ‘turing test’), the paper describes an in-depth study evaluating the linguistic accuracy of a number of chatbots available online. since the ultimate purpose of the current study concerns chatbots' potential with esl learners, the analysis of language embraces not only an examination of features of language from a native-speaker's perspective (the focus of the turing test), but also aspects of language from a second-language-user's perspective. analyses indicate that while the winner of the 2005 loebner prize is the most able chatbot linguistically, it may not necessarily be the chatbot most suited to esl learners. the paper concludes that while substantial progress has been made in terms of chatbots' language-handling, a robust esl ‘conversation practice machine’ (atwell, 1999) is still some way off being a reality. © 2008, european association for computer assisted language learning. all rights reserved.",evaluating the language resources of chatbots for their potential in english as a second language
1998,2-s2.0-50949101063,10.1109/ICBBE.2008.14,ESTplus: An integrative system for comprehensive and customized EST analysis and proteomic data matching,Pacharawongsakda E.,"2nd International Conference on Bioinformatics and Biomedical Engineering, iCBBE 2008",2008-01-01,"Construction and sequencing of Expressed Sequence Tag (EST) libraries are commonly performed to reveal genes expressed in given tissues of an organism. The vast amount of sequencing data from the EST libraries requires effective analysis tools to translate such data into meaningful results for further research and development. While many EST analysis tools are available, most of them do not accommodate multi-project and multi-library environments and do not have enough tools to identify significant genes for the EST database. To address these issues, ESTplus, an integrated software tool collection, was developed to support better project management and provide more comprehensive collection of analysis tools. ESTplus allows its users to manage, create, modify, and remove EST libraries from their own projects. It consists of public programs necessary for performing a traditional EST analysis. In addition, the system was enhanced from other EST databases by including additional modules to help identifying functionally-significant or rare sequences as the following. First, library comparative analysis module finds the association between genes among EST libraries according to Gene Ontology (GO) terms using chi-square test (χ<sup>2</sup>). Second, integrative proteomics and EST data analysis module reversely identifies EST sequences that correspond to a short amino acid sequence resulted from a proteomic experiment. Third, a primer design module guides primer selection from gene contigs and/or sequences from the EST data. These enhanced features allow the better and easier utilization of the available EST data for functional genomics and translated biological research. © 2008 IEEE.",Chisquare | Expressed sequence tag (EST) | Primer | Proteomics,3,29-32,Conference Proceeding,Conference Paper,5.0,"Pacharawongsakda, Eakasit;Yokwai, Sunai;Karoonuthaisiri, Nitsara;Wichadakul, Duangdao;Ingsriswang, Supawadee",21743664400;24765795400;24765223200;6603187694;21742654900,Thailand National Center for Genetic Engineering and Biotechnology,Thailand,"construction and sequencing of expressed sequence tag (est) libraries are commonly performed to reveal genes expressed in given tissues of an organism. the vast amount of sequencing data from the est libraries requires effective analysis tools to translate such data into meaningful results for further research and development. while many est analysis tools are available, most of them do not accommodate multi-project and multi-library environments and do not have enough tools to identify significant genes for the est database. to address these issues, estplus, an integrated software tool collection, was developed to support better project management and provide more comprehensive collection of analysis tools. estplus allows its users to manage, create, modify, and remove est libraries from their own projects. it consists of public programs necessary for performing a traditional est analysis. in addition, the system was enhanced from other est databases by including additional modules to help identifying functionally-significant or rare sequences as the following. first, library comparative analysis module finds the association between genes among est libraries according to gene ontology (go) terms using chi-square test (χ<sup>2</sup>). second, integrative proteomics and est data analysis module reversely identifies est sequences that correspond to a short amino acid sequence resulted from a proteomic experiment. third, a primer design module guides primer selection from gene contigs and/or sequences from the est data. these enhanced features allow the better and easier utilization of the available est data for functional genomics and translated biological research. © 2008 ieee.",estplus: an integrative system for comprehensive and customized est analysis and proteomic data matching
2006,2-s2.0-70350175199,10.1109/IGARSS.2007.4423269,Development of Web-based SAR processor for education,Ito Y.,International Geoscience and Remote Sensing Symposium (IGARSS),2007-12-01,"Recently, synthetic aperture radar (SAR) processing algorithms have become more complicated due to the variety of observation modes of SAR sensors. Understanding the basics of the SAR processing technique is necessary to work out new approaches using the new sensing modes. A web-based SAR processor using Ajax technology is proposed for easy use in an educational computer system with various limitations. This paper presents the concept and the implementation method of this software and shows processing examples. © 2007 IEEE.",Ajax | Educational software | SAR processor,3,2185-2187,Conference Proceeding,Conference Paper,3.0,"Ito, Yosuke;Teramoto, Yuuhei;Abe, Kenji",55467363100;23494080400;55464430700,"Naruto University of Education;Ateral, Inc.",Japan;Japan,"recently, synthetic aperture radar (sar) processing algorithms have become more complicated due to the variety of observation modes of sar sensors. understanding the basics of the sar processing technique is necessary to work out new approaches using the new sensing modes. a web-based sar processor using ajax technology is proposed for easy use in an educational computer system with various limitations. this paper presents the concept and the implementation method of this software and shows processing examples. © 2007 ieee.",development of web-based sar processor for education
2007,2-s2.0-49049087902,10.1109/ICCIT.2007.4420319,An easy-to-use feed middleware for application development with RSS/Atom feeds,Lin C.F.,"2007 International Conference on Convergence Information Technology, ICCIT 2007",2007-12-01,"RSS and Atom feeds are XML representations of the entries in frequently updating websites, which enable users to subscribe to those syndicated contents using feed readers. As feeds are gaining more and more adoptions due to the ubiquity of blogs, various extensions are written for them to carry more semantic information. Ordinary tools which treat them as simple XML documents on the web are not sufficient for application development. In this paper, a middleware is proposed to aid application development involving RSS/Atom feeds. It handles fetching, parsing and storage of feeds for developers and provides them with a set of easy-to-use interfaces to write procedural and event-driven applications. Compared with the Windows RSS Platform, it is more flexible and easier to work with. When extended with industrial-strength databases and servers, it can be used by organizations or individuals to solve real world integration problems. © 2007 IEEE.",BLOG | Interface | Middleware | RSS,1,567-572,Conference Proceeding,Conference Paper,3.0,"Lin, Chia Feng;Tut, Chi Io;Yuan, Shyan Ming",57137139200;24512416800;57135992000,Asia University;National Chiao Tung University,Taiwan;Taiwan,"rss and atom feeds are xml representations of the entries in frequently updating websites, which enable users to subscribe to those syndicated contents using feed readers. as feeds are gaining more and more adoptions due to the ubiquity of blogs, various extensions are written for them to carry more semantic information. ordinary tools which treat them as simple xml documents on the web are not sufficient for application development. in this paper, a middleware is proposed to aid application development involving rss/atom feeds. it handles fetching, parsing and storage of feeds for developers and provides them with a set of easy-to-use interfaces to write procedural and event-driven applications. compared with the windows rss platform, it is more flexible and easier to work with. when extended with industrial-strength databases and servers, it can be used by organizations or individuals to solve real world integration problems. © 2007 ieee.",an easy-to-use feed middleware for application development with rss/atom feeds
2008,2-s2.0-41149150715,10.1145/1294261.1294264,AjaxScope: A platform for remotely monitoring the client-side behavior of web 2.0 applications,Kiciman E.,Operating Systems Review (ACM),2007-12-01,"The rise of the software-as-a-service paradigm has led to the development of a new breed of sophisticated, interactive applications often called Web 2.0. While web applications have become larger and more complex, web application developers today have little visibility into the end-to-end behavior of their systems. This paper presents AjaxScope, a dynamic instrumentation platform that enables cross-user monitoring and just-in-time control of web application behavior on end-user desktops. AjaxScope is a proxy that performs on-the-fly parsing and instrumentation of JavaScript code as it is sent to users' browsers. AjaxScope provides facilities for distributed and adaptive instrumentation in order to reduce the client-side overhead, while giving fine-grained visibility into the code-level behavior of web applications. We present a variety of policies demonstrating the power of AjaxScope, ranging from simple error reporting and performance profiling to more complex memory leak detection and optimization analyses. We also apply our prototype to analyze the behavior of over 90 Web 2.0 applications and sites that use large amounts of JavaScript. Copyright 2007 ACM.",Software instrumentation | Software monitoring | Web applications,29,17-30,Conference Proceeding,Conference Paper,2.0,"Kiciman, Emre;Livshits, Benjamin",6507547008;12139816400,Microsoft Research,United States,"the rise of the software-as-a-service paradigm has led to the development of a new breed of sophisticated, interactive applications often called web 2.0. while web applications have become larger and more complex, web application developers today have little visibility into the end-to-end behavior of their systems. this paper presents ajaxscope, a dynamic instrumentation platform that enables cross-user monitoring and just-in-time control of web application behavior on end-user desktops. ajaxscope is a proxy that performs on-the-fly parsing and instrumentation of javascript code as it is sent to users' browsers. ajaxscope provides facilities for distributed and adaptive instrumentation in order to reduce the client-side overhead, while giving fine-grained visibility into the code-level behavior of web applications. we present a variety of policies demonstrating the power of ajaxscope, ranging from simple error reporting and performance profiling to more complex memory leak detection and optimization analyses. we also apply our prototype to analyze the behavior of over 90 web 2.0 applications and sites that use large amounts of javascript. copyright 2007 acm.",ajaxscope: a platform for remotely monitoring the client-side behavior of web 2.0 applications
2009,2-s2.0-38049108142,10.3901/CJME.2007.06.109,Web-based virtual CNC machine modeling and operation,He H.,Chinese Journal of Mechanical Engineering (English Edition),2007-12-01,"A CNC simulation system based on internet for operation training of manufacturing facility and manufacturing process simulation is proposed. Firstly, the system framework and a rapid modeling method of CNC machine tool are studied under the virtual environment based on PolyTrans and CAD software. Then, a new method is proposed to enhance and expand the interactive ability of virtual reality modeling language (VRML) by attaining communication among VRML, JavaApplet, JavaScript and Html so as to realize the virtual operation for CNC machine tool. Moreover, the algorithm of material removed simulation based on VRML Z-map is presented. The advantages of this algorithm include less memory requirement and much higher computation. Lastly, the CNC milling machine is taken as an illustrative example for the prototype development in order to validate the feasibility of the proposed approach.",Machining simulation | Virtual operation | Virtual reality CNC machine tools | Virtual reality modeling language (VRML),4,109-113,Journal,Article,4.0,"He, Hanwu;Wu, Yueming;Gu, Yaoda;Lu, Yongming",9335623500;56093280500;23392471600;56174820400,Guangdong University of Technology,China,"a cnc simulation system based on internet for operation training of manufacturing facility and manufacturing process simulation is proposed. firstly, the system framework and a rapid modeling method of cnc machine tool are studied under the virtual environment based on polytrans and cad software. then, a new method is proposed to enhance and expand the interactive ability of virtual reality modeling language (vrml) by attaining communication among vrml, javaapplet, javascript and html so as to realize the virtual operation for cnc machine tool. moreover, the algorithm of material removed simulation based on vrml z-map is presented. the advantages of this algorithm include less memory requirement and much higher computation. lastly, the cnc milling machine is taken as an illustrative example for the prototype development in order to validate the feasibility of the proposed approach.",web-based virtual cnc machine modeling and operation
2010,2-s2.0-36448952683,10.1145/1255329.1255346,Using web application construction frameworks to protect against code injection attacks,Livshits B.,PLAS'07 - Proceedings of the 2007 ACM SIGPLAN Workshop on Programming Languages and Analysis for Security,2007-11-30,"In recent years, the security landscape has changed, with Web applications vulnerabilities becoming more prominent that vulnerabilities stemming from the lack of type safety, such as buffer overruns. Many reports point to code injection attacks such as cross-site scripting and RSS injection as being the most common attacks against Web applications to date. With Web 2.0 existing security problems are further exacerbated by the advent of Ajax technology that allows one to create and compose HTML content from different sources within the browser at runtime, as exemplified by customizable mashup pages like My Yahoo! or Live.com This paper proposes a simple to support, yet a powerful scheme for eliminating a wide range of script injection vulnerabilities in applications built on top of popular Ajax development frameworks such as the Dojo Toolkit, prototype.js, and AJAX.NET. Unlike other client-side runtime enforcement proposals, the approach we are advocating requires only minor browser modifications. This is because our proposal can be viewed as a natural finer-grained extension of the same-origin policy for JavaScript already supported by the majority of mainstream browsers, in which we treat individual user interface widgets as belonging to separate domains Fortunately, in many cases no changes to the development process need to take place: for applications that are built on top of frameworks described above, a slight framework modification will result in appropriate changes in the generated HTML, completely obviating the need for manual code annotation. In this paper we demonstrate how these changes can prevent cross-site scripting and RSS injection attacks using the Dojo Toolkit, a popular Ajax library, as an example. Copyright © 2007 ACM.",Code injection attacks | Same-origin policy | Software construction frameworks | Software security,33,95-104,Conference Proceeding,Conference Paper,2.0,"Livshits, Benjamin;Erlingsson, Úlfar",12139816400;6603357907,Microsoft Research,United States,"in recent years, the security landscape has changed, with web applications vulnerabilities becoming more prominent that vulnerabilities stemming from the lack of type safety, such as buffer overruns. many reports point to code injection attacks such as cross-site scripting and rss injection as being the most common attacks against web applications to date. with web 2.0 existing security problems are further exacerbated by the advent of ajax technology that allows one to create and compose html content from different sources within the browser at runtime, as exemplified by customizable mashup pages like my yahoo! or live.com this paper proposes a simple to support, yet a powerful scheme for eliminating a wide range of script injection vulnerabilities in applications built on top of popular ajax development frameworks such as the dojo toolkit, prototype.js, and ajax.net. unlike other client-side runtime enforcement proposals, the approach we are advocating requires only minor browser modifications. this is because our proposal can be viewed as a natural finer-grained extension of the same-origin policy for javascript already supported by the majority of mainstream browsers, in which we treat individual user interface widgets as belonging to separate domains fortunately, in many cases no changes to the development process need to take place: for applications that are built on top of frameworks described above, a slight framework modification will result in appropriate changes in the generated html, completely obviating the need for manual code annotation. in this paper we demonstrate how these changes can prevent cross-site scripting and rss injection attacks using the dojo toolkit, a popular ajax library, as an example. copyright © 2007 acm.",using web application construction frameworks to protect against code injection attacks
2012,2-s2.0-35348872560,10.1145/1242572.1242806,Life is sharable: Mechanisms to support and sustain blogging life experience,Cheng Y.M.,"16th International World Wide Web Conference, WWW2007",2007-10-22,"Recent trend in the development of mobile devices, wireless communications, sensor technologies, weblogs, and peer-to-peer communications have prompted a new design opportunity for enhancing social interactions. This paper introduces our preliminary experiences in designing a prototype utilizing the aforementioned technologies to share life experience. Users equipped with camera phones coupled with short-range communication technology, such as RFID, can capture life experience and share it as weblogs to other people. However, in reality, this is easier said than done. The success of weblogs relies on the active participation and willingness of people to contribute. To encourage active participations, a ranking system, AgreeRank, is specifically developed to get them motivated.",Collaborative system | Mobile phone | Peer-to-peer communication | RFID | Weblog | Wireless networking,0,1277-1278,Conference Proceeding,Conference Paper,6.0,"Cheng, Yun Maw;Chou, Tzu Chuan;Yu, Wai;Chen, Li Chieh;Yeh, Ching Long;Chen, Meng Chang",22833303300;9250871700;22837321100;8921782400;25629143300;7406355852,"Queen's University Belfast;Academia Sinica, Institute of Information Science;Tatung University",United Kingdom;Taiwan;Taiwan,"recent trend in the development of mobile devices, wireless communications, sensor technologies, weblogs, and peer-to-peer communications have prompted a new design opportunity for enhancing social interactions. this paper introduces our preliminary experiences in designing a prototype utilizing the aforementioned technologies to share life experience. users equipped with camera phones coupled with short-range communication technology, such as rfid, can capture life experience and share it as weblogs to other people. however, in reality, this is easier said than done. the success of weblogs relies on the active participation and willingness of people to contribute. to encourage active participations, a ranking system, agreerank, is specifically developed to get them motivated.",life is sharable: mechanisms to support and sustain blogging life experience
2013,2-s2.0-35348853114,10.1109/TCE.2007.4341604,A component-based software framework for product lifecycle information management for consumer products,Yang X.,IEEE Transactions on Consumer Electronics,2007-08-01,"In this paper, a component-based software framework that can facilitate the development of lifecycle information management systems for consumer products is developed. This software framework can accommodate the management of lifecycle data at all stages, especially data that occur in distribution, usage, maintenance and end-of-life stages, and use them to provide information and knowledge. The software framework is built with software components, based on a component-based concept with reference to a product lifecycle information acquisition and management model proposed within this research study. Two actual lifecycle information management systems are created using the Framework in field trials. This software framework can open new horizons for product design which are sustainable and environmentally sensitive. It also contributes to the wider exploration of middleware solutions for implementing next generation consumer products (e.g. smart home appliances) and intelligent products. © 2007 IEEE.",Product lifecycle information management,14,1195-1203,Journal,Article,4.0,"Yang, Xiaoyu;Moore, Philip R.;Wong, Chi Biu;Pu, Jun Sheng",35204210900;7403683541;7404954094;7102908900,University of Cambridge;De Montfort University,United Kingdom;United Kingdom,"in this paper, a component-based software framework that can facilitate the development of lifecycle information management systems for consumer products is developed. this software framework can accommodate the management of lifecycle data at all stages, especially data that occur in distribution, usage, maintenance and end-of-life stages, and use them to provide information and knowledge. the software framework is built with software components, based on a component-based concept with reference to a product lifecycle information acquisition and management model proposed within this research study. two actual lifecycle information management systems are created using the framework in field trials. this software framework can open new horizons for product design which are sustainable and environmentally sensitive. it also contributes to the wider exploration of middleware solutions for implementing next generation consumer products (e.g. smart home appliances) and intelligent products. © 2007 ieee.",a component-based software framework for product lifecycle information management for consumer products
2014,2-s2.0-34248659137,10.1109/TSE.2007.1015,Empirical validation of three software metrics suites to predict fault-proneness of object-oriented classes developed using highly Iterative or agile software development processes,Olague H.M.,IEEE Transactions on Software Engineering,2007-06-01,"Empirical validation of software metrics suites to predict fault proneness in object-oriented (OO) components is essential to ensure their practical use in industrial settings. In this paper, we empirically validate three OO metrics suites for their ability to predict software quality in terms of fault-proneness: the Chidamber and Kemerer (CK) metrics, Abreu's Metrics for Object-Oriented Design (MOOD), and Bansiya and Davis' Quality Metrics for Object-Oriented Design (QMOOD). Some CK class metrics have previously been shown to be good predictors of initial OO software quality. However, the other two suites have not been heavily validated except by their original proposers. Here, we explore the ability of these three metrics suites to predict fault-prone classes using defect data for six versions of Rhino, an open-source implementation of JavaScript written in Java. We conclude that the CK and QMOOD suites contain similar components and produce statistical models that are effective in detecting error-prone classes. We also conclude that the class components in the MOOD metrics suite are not good class fault-proneness predictors. Analyzing multivariate binary logistic regression models across six Rhino versions indicates these models may be useful in assessing quality in OO classes produced using modern highly iterative or agile software development processes. © 2007 IEEE.",Object-oriented metrics | Object-oriented software metrics | Software maintenance programming | Software quality metrics | Software reuse,215,402-419,Journal,Article,4.0,"Olague, Hector M.;Etzkorn, Letha H.;Gholston, Sampson;Quattlebaum, Stephen",14123567900;6701756655;6508133887;16313827700,Industrial &amp; Systems Engineering and Engineering Management Department;The University of Alabama in Huntsville;Dragonfly Athletics;SMDC-RDTI-S,United States;United States;United States;United States,"empirical validation of software metrics suites to predict fault proneness in object-oriented (oo) components is essential to ensure their practical use in industrial settings. in this paper, we empirically validate three oo metrics suites for their ability to predict software quality in terms of fault-proneness: the chidamber and kemerer (ck) metrics, abreu's metrics for object-oriented design (mood), and bansiya and davis' quality metrics for object-oriented design (qmood). some ck class metrics have previously been shown to be good predictors of initial oo software quality. however, the other two suites have not been heavily validated except by their original proposers. here, we explore the ability of these three metrics suites to predict fault-prone classes using defect data for six versions of rhino, an open-source implementation of javascript written in java. we conclude that the ck and qmood suites contain similar components and produce statistical models that are effective in detecting error-prone classes. we also conclude that the class components in the mood metrics suite are not good class fault-proneness predictors. analyzing multivariate binary logistic regression models across six rhino versions indicates these models may be useful in assessing quality in oo classes produced using modern highly iterative or agile software development processes. © 2007 ieee.",empirical validation of three software metrics suites to predict fault-proneness of object-oriented classes developed using highly iterative or agile software development processes
2017,2-s2.0-34247862105,10.1002/cpe.1082,"Science gateways to DEISA: User requirements, technologies, and the material sciences and plasma physics gateway",Soddemann T.,Concurrency and Computation: Practice and Experience,2007-04-25,"DEISA (Distributed European Infrastructure for Supercomputer Applications) is collecting experience with science gateways in different scientific areas and aims at combining all current efforts. This paper describes the development of the DEISA material sciences and plasma physics Web portal application from the view of a project engineer and software architect. It analyzes user requirements, motivates technology choices, and describes the realization of an application that is very similar to the first release candidate. The outlook gives insight into the development steps currently being undertaken towards a release and the planning phase for a future release, as well as the DEISA aims. Copyright © 2006 John Wiley & Sons, Ltd.",DEISA | Job submission portal | Science gateway,7,839-850,Journal,Article,1.0,"Soddemann, Thomas",23393955700,Max Planck Institute for Plasma Physics,Germany,"deisa (distributed european infrastructure for supercomputer applications) is collecting experience with science gateways in different scientific areas and aims at combining all current efforts. this paper describes the development of the deisa material sciences and plasma physics web portal application from the view of a project engineer and software architect. it analyzes user requirements, motivates technology choices, and describes the realization of an application that is very similar to the first release candidate. the outlook gives insight into the development steps currently being undertaken towards a release and the planning phase for a future release, as well as the deisa aims. copyright © 2006 john wiley & sons, ltd.","science gateways to deisa: user requirements, technologies, and the material sciences and plasma physics gateway"
2025,2-s2.0-38149022503,10.1007/978-3-540-73257-0_55,WikiTable: A new tool for collaborative authoring and data management,Zheng X.S.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2007-01-01,"Tables are an efficient tool for organizing complex data. Even though they are pervasively used in all kinds of documentation, current implementations of tables often limit the power of data management because generally they do not support concurrent collaborative authoring; they only allow keyword search, which typically yields poor search performance; and transporting tables among different applications is cumbersome. We present a new table tool, WikiTable, which permits multiple users to work on the same table simultaneously. The content of each table is stored in a database, which enables accurate data inquiry. More importantly, WikiTable is highly portable, permitting easy integration with other applications, such as Wikis or Blogs. An effort to apply the WikiTable in a global collaboration project of software development is also discussed. © Springer-Verlag Berlin Heidelberg 2007.",And management | Collaborative authoring | Data organization | Sharing | Spreadsheet | Tables | Wiki,2,501-508,Book Series,Conference Paper,3.0,"Zheng, Xianjun Sam;Sapundshiev, Ilian;Rauschenberger, Robert",23399002600;23398229600;6602627611,Siemens USA,United States,"tables are an efficient tool for organizing complex data. even though they are pervasively used in all kinds of documentation, current implementations of tables often limit the power of data management because generally they do not support concurrent collaborative authoring; they only allow keyword search, which typically yields poor search performance; and transporting tables among different applications is cumbersome. we present a new table tool, wikitable, which permits multiple users to work on the same table simultaneously. the content of each table is stored in a database, which enables accurate data inquiry. more importantly, wikitable is highly portable, permitting easy integration with other applications, such as wikis or blogs. an effort to apply the wikitable in a global collaboration project of software development is also discussed. © springer-verlag berlin heidelberg 2007.",wikitable: a new tool for collaborative authoring and data management
2032,2-s2.0-46949089310,10.1109/ITHET.2006.339788,B#: The development and assessment of an iconic programming tool for novice programmers,Greyling J.H.,"7th International Conference on Information Technology Based Higher Education and Training, ITHET",2006-12-01,"The higher incidence of under-prepared students in the South African education institutions has a particular significance for introductory programming courses which rely heavily on the use of technological tools as components of the teaching model. Difficulties experienced by novice programmers in introductory programming courses include deficiencies in problem-solving strategies, misconceptions relating to programming language constructs and the use of traditional programming environments. An introductory programming course should offer students problem solving analysis and design experience as well as exposure to the basic ideas of algorithmic thinking. Generally, introductory programming courses tend to concentrate on the syntax of a programming language at the expense of developing problem solving skills. Coupled to this are the ever-increasing complexity of modern programming languages and the user interfaces of their IDEs. A strategy that addresses the difficulties experienced by novice programmers in introductory programming courses is one that modifies the teaching model, specifically within the context of technological support. One way of implementing this strategy is with the use of visual programming languages, of which the iconic flowchart approach is one. Further, iconic programming environments traditionally attempt to simplify the programming task by reducing the level of precision and manual typing usually required in the conventional textual programming languages. These environments also attempt to increase the speed at which problem-solving and implementation efforts occur. Consequently, B# was developed in order to provide an environment in which programs can be developed using iconic flowcharts. Basic programming concepts such as assignments, conditions, loops, inputs and outputs are supported. Automatic code generation, debugging and program execution is also supported by the system. This paper reports on the development of B#, focussing on insights that were obtained concerning iconic programming tools. The use of B# by novice programmers in an introductory programming course is discussed and assessed. Recommendations are made as to how an iconic programming environment like B# could contribute to the successful completion of an introductory programming course. ©2006 IEEE.",Flowcharts | Iconic programming | Introductory programming,7,367-375,Conference Proceeding,Conference Paper,3.0,"Greyling, J. H.;Cilliers, C. B.;Calitz, A. P.",10739719600;10739858100;6602231939,Nelson Mandela University,South Africa,"the higher incidence of under-prepared students in the south african education institutions has a particular significance for introductory programming courses which rely heavily on the use of technological tools as components of the teaching model. difficulties experienced by novice programmers in introductory programming courses include deficiencies in problem-solving strategies, misconceptions relating to programming language constructs and the use of traditional programming environments. an introductory programming course should offer students problem solving analysis and design experience as well as exposure to the basic ideas of algorithmic thinking. generally, introductory programming courses tend to concentrate on the syntax of a programming language at the expense of developing problem solving skills. coupled to this are the ever-increasing complexity of modern programming languages and the user interfaces of their ides. a strategy that addresses the difficulties experienced by novice programmers in introductory programming courses is one that modifies the teaching model, specifically within the context of technological support. one way of implementing this strategy is with the use of visual programming languages, of which the iconic flowchart approach is one. further, iconic programming environments traditionally attempt to simplify the programming task by reducing the level of precision and manual typing usually required in the conventional textual programming languages. these environments also attempt to increase the speed at which problem-solving and implementation efforts occur. consequently, b# was developed in order to provide an environment in which programs can be developed using iconic flowcharts. basic programming concepts such as assignments, conditions, loops, inputs and outputs are supported. automatic code generation, debugging and program execution is also supported by the system. this paper reports on the development of b#, focussing on insights that were obtained concerning iconic programming tools. the use of b# by novice programmers in an introductory programming course is discussed and assessed. recommendations are made as to how an iconic programming environment like b# could contribute to the successful completion of an introductory programming course. ©2006 ieee.",b#: the development and assessment of an iconic programming tool for novice programmers
2033,2-s2.0-34248336662,10.1145/1176617.1176631,JDA: A step towards large-scale reuse on the Web,Lim S.,"Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA",2006-12-01,"The Web is maturing as a rich application development platform, and efforts are being made to provide richer and more dynamic interactions using JavaScript. JavaScript-based Web applications such as Google Maps have gained extra attention because they can be easily included in HTML for reuse. Unfortunately, various technical hurdles have made it difficult for JavaScript reuse to extend beyond its current state. Furthermore, JavaScript reuse is still out of reach for a large portion of the Web user base unversed in the use of programming languages.In this paper, we dive deeper into our previous work on the JavaScript Dataflow Architecture (JDA). JDA is intended for Web client applications written using HTML and JavaScript. We discuss the ways in which the architecture addresses many of the hurdles that modern Web client applications face in the realm of large-scale reuse and remixing. JDA aims to provide an ecosystem comprised of black box components operating within a JavaScript-based asynchronous message-passing environment. The environment allows you to use simple HTML to assemble Web applications from JavaScript black boxes scattered around the World Wide Web. No programming skill is required in their assembly, and no plug-ins or applets are required for their execution. Furthermore, the architecture extends the black box metaphor beyond the boundaries of JavaScript and allows multiple JavaScript components contained within an HTML file to be reused as a whole.A detailed account of an early prototype is discussed, and research is being done to improve it. JDA suggests that large-scale reuse and arbitrary remixing of Web applications can be realized using currently existing technologies.",Black box reuse | Composition | Dataflow architecture | Information devices architecture | JavaScript | Rich Web application | Web engineering,5,586-601,Conference Proceeding,Conference Paper,2.0,"Lim, Seung Chan;Lucas, Peter",12753395600;7202397672,"MAYA Design Group, Inc",United States,"the web is maturing as a rich application development platform, and efforts are being made to provide richer and more dynamic interactions using javascript. javascript-based web applications such as google maps have gained extra attention because they can be easily included in html for reuse. unfortunately, various technical hurdles have made it difficult for javascript reuse to extend beyond its current state. furthermore, javascript reuse is still out of reach for a large portion of the web user base unversed in the use of programming languages.in this paper, we dive deeper into our previous work on the javascript dataflow architecture (jda). jda is intended for web client applications written using html and javascript. we discuss the ways in which the architecture addresses many of the hurdles that modern web client applications face in the realm of large-scale reuse and remixing. jda aims to provide an ecosystem comprised of black box components operating within a javascript-based asynchronous message-passing environment. the environment allows you to use simple html to assemble web applications from javascript black boxes scattered around the world wide web. no programming skill is required in their assembly, and no plug-ins or applets are required for their execution. furthermore, the architecture extends the black box metaphor beyond the boundaries of javascript and allows multiple javascript components contained within an html file to be reused as a whole.a detailed account of an early prototype is discussed, and research is being done to improve it. jda suggests that large-scale reuse and arbitrary remixing of web applications can be realized using currently existing technologies.",jda: a step towards large-scale reuse on the web
2039,2-s2.0-33745802535,10.3923/itj.2006.322.328,Working with XML for flexible management of online course syllabi,Cebeci Z.,Information Technology Journal,2006-03-01,"Extensible Markup Language (XML) has been one of the most dominant research concepts in information exchange during recent years. Almost in every area of information technologies XML-based applications utilized to gain the advantages associated with XML and related technologies. Also in education world, XML has provided the great advantages such as shareability, reusability, durability and interoperability in-and-between technology enhanced learning and teaching systems. Researches and implementations on the use of XML in teaching and learning have mainly been focused on the development of learning objects, content packaging and learning systems design. Although it is one possible use of XML, limited number of research works has been done on the use of XML-based syllabi within e-learning platforms. In this study, preparing online course syllabi as XML documents is discussed and an authoring tool which has been built with XML, XSL, HTML, Javascript and MS ASP is introduced for demonstrating the flexibilities of XML-based syllabi as a sample framework. © 2006 Asian Network for Scientific Information.",Educational software | Online teaching tools | Syllabus construction | Web-based teaching and learning | Xml applications,1,322-328,Journal,Article,3.0,"Cebeci, Zeynel;Budak, Fuat;Tekdal, Mehmet",14033871600;13205066600;14034525000,Çukurova Üniversitesi,Turkey,"extensible markup language (xml) has been one of the most dominant research concepts in information exchange during recent years. almost in every area of information technologies xml-based applications utilized to gain the advantages associated with xml and related technologies. also in education world, xml has provided the great advantages such as shareability, reusability, durability and interoperability in-and-between technology enhanced learning and teaching systems. researches and implementations on the use of xml in teaching and learning have mainly been focused on the development of learning objects, content packaging and learning systems design. although it is one possible use of xml, limited number of research works has been done on the use of xml-based syllabi within e-learning platforms. in this study, preparing online course syllabi as xml documents is discussed and an authoring tool which has been built with xml, xsl, html, javascript and ms asp is introduced for demonstrating the flexibilities of xml-based syllabi as a sample framework. © 2006 asian network for scientific information.",working with xml for flexible management of online course syllabi
2054,2-s2.0-27744498729,10.1016/j.entcs.2005.09.010,Type checking for JavaScript,Anderson C.,Electronic Notes in Theoretical Computer Science,2005-11-23,"JavaScript is a powerful imperative object based language made popular by its use in web pages. It supports flexible program development by allowing dynamic addition of members to objects. Code is dynamically typed: a runtime access to a non-existing member causes an error. We suggest a static type system for JavaScript that will detect such type errors. Therefore, programmers can benefit from the flexible programming style offered by JavaScript and from the safety offered by a static type system. We demonstrate our type system with a formalism of JavaScript, JS0. Our types are structural. Members of an object type are classified into definite and potential. A potential member becomes definite upon assignment. We outline a proof that our type system is sound. © 2005 Elsevier B.V. All rights reserved.",JavaScript | Scripting Languages | Structural Recursive Types | Type Checking,18,37-58,Journal,Article,2.0,"Anderson, Christopher;Giannini, Paola",56208689700;7004349370,"Imperial College London;Università degli Studi del Piemonte Orientale ""Amedeo Avogadro""",United Kingdom;Italy,"javascript is a powerful imperative object based language made popular by its use in web pages. it supports flexible program development by allowing dynamic addition of members to objects. code is dynamically typed: a runtime access to a non-existing member causes an error. we suggest a static type system for javascript that will detect such type errors. therefore, programmers can benefit from the flexible programming style offered by javascript and from the safety offered by a static type system. we demonstrate our type system with a formalism of javascript, js0. our types are structural. members of an object type are classified into definite and potential. a potential member becomes definite upon assignment. we outline a proof that our type system is sound. © 2005 elsevier b.v. all rights reserved.",type checking for javascript
2055,2-s2.0-28444470194,10.1109/TE.2005.858396,Integrated component web-based interactive learning systems for engineering,Humar I.,IEEE Transactions on Education,2005-11-01,"Dynamic web-based learning tools are indispensable in modern teaching, especially considering their capability for interaction on demand as a means of stimulating and engaging students. The experience on which the results reported here are based has grown out of progressive testing of different approaches for publishing technical sketches and mathematical notations from the field of electromagnetics on the web, starting in 1997 with simple static web pages of solved examples. The encouraging results from using and evaluating this educational material and the needs expressed by students for learning from more dynamic and interactive web learning materials that offer the possibility of changing parameters in online calculations motivated a search for new approaches to publishing interactive learning materials on the web. Integration of already developed components for building animations, presenting mathematical equations, and performing online computations with browser scripting led to development of a learning environment where animations are synchronized with corresponding derivations of equations and supported by dynamic, parametric-driven calculations and visualizations that can be integrated with sound and video. The system supports tests and examinations in which the answers are provided as mathematical notations. The use of Mathematical Markup Language (MathML) permits equations in the learning materials to be copied and pasted into most of the popular mathematical software tools for algebraic manipulation or numerical computation. Examples demonstrate how the system can be used with a course on electromagnetics, although the basic approach is applicable in other fields of engineering and natural science. © 2005 IEEE.",Interactive technical sketches | Mathematical notations | Network traffic modeling | Online calculations/visualizations | System access evaluation | Web-based education,23,664-675,Journal,Article,4.0,"Humar, Iztok;Sinigoj, Anton R.;Bešter, Janez;Hagler, Marion O.",6603264573;6602120018;7003768709;22992067900,Univerza v Ljubljani;Mississippi State University,Slovenia;United States,"dynamic web-based learning tools are indispensable in modern teaching, especially considering their capability for interaction on demand as a means of stimulating and engaging students. the experience on which the results reported here are based has grown out of progressive testing of different approaches for publishing technical sketches and mathematical notations from the field of electromagnetics on the web, starting in 1997 with simple static web pages of solved examples. the encouraging results from using and evaluating this educational material and the needs expressed by students for learning from more dynamic and interactive web learning materials that offer the possibility of changing parameters in online calculations motivated a search for new approaches to publishing interactive learning materials on the web. integration of already developed components for building animations, presenting mathematical equations, and performing online computations with browser scripting led to development of a learning environment where animations are synchronized with corresponding derivations of equations and supported by dynamic, parametric-driven calculations and visualizations that can be integrated with sound and video. the system supports tests and examinations in which the answers are provided as mathematical notations. the use of mathematical markup language (mathml) permits equations in the learning materials to be copied and pasted into most of the popular mathematical software tools for algebraic manipulation or numerical computation. examples demonstrate how the system can be used with a course on electromagnetics, although the basic approach is applicable in other fields of engineering and natural science. © 2005 ieee.",integrated component web-based interactive learning systems for engineering
2056,2-s2.0-24344452066,10.1016/j.compmedimag.2005.02.001,An online interactive simulation system for medical imaging education,Dikshit A.,Computerized Medical Imaging and Graphics,2005-09-01,"This report presents a recently developed web-based medical imaging simulation system for teaching students or other trainees who plan to work in the medical imaging field. The increased importance of computer and information technology widely applied to different imaging techniques in clinics and medical research necessitates a comprehensive medical imaging education program. A complete tutorial of simulations introducing popular imaging modalities, such as X-ray, MRI, CT, ultrasound and PET, forms an essential component of such an education. Internet technologies provide a vehicle to carry medical imaging education online. There exist a number of internet-based medical imaging hyper-books or online documentations. However, there are few providing interactive computational simulations. We focus on delivering knowledge of the physical principles and engineering implementation of medical imaging techniques through an interactive website environment. The online medical imaging simulation system presented in this report outlines basic principles underlying different imaging techniques and image processing algorithms and offers trainees an interactive virtual laboratory. For education purposes, this system aims to provide general understanding of each imaging modality with comprehensive explanations, ample illustrations and copious references as its thrust, rather than complex physics or detailed math. This report specifically describes the development of the tutorial for commonly used medical imaging modalities. An internet-accessible interface is used to simulate various imaging algorithms with user-adjustable parameters. The tutorial is under the MATLAB Web Server environment. Macromedia Director MX is used to develop interactive animations integrating theory with graphic-oriented simulations. HTML and JavaScript are used to enable a user to explore these modules online in a web browser. Numerous multiple choice questions, links and references for advanced study are provided in the tutorial for trainees to verify their understanding of each unit. It is expected that this tutorial will enhance medical imaging education, help trainees in subsequent analysis of image data, and form the basis for the development of more advanced technologies in the future. © 2005 Elsevier Ltd. All rights reserved.",Engineering education | Medical imaging | Simulation | Tutorial,30,395-404,Journal,Article,4.0,"Dikshit, Aditya;Wu, Dawei;Wu, Chunyan;Zhao, Weizhao",8558491600;35241332100;55713101400;7403943159,University of Southern California;University of Miami;Mount Sinai Medical Center Miami Beach,United States;United States;United States,"this report presents a recently developed web-based medical imaging simulation system for teaching students or other trainees who plan to work in the medical imaging field. the increased importance of computer and information technology widely applied to different imaging techniques in clinics and medical research necessitates a comprehensive medical imaging education program. a complete tutorial of simulations introducing popular imaging modalities, such as x-ray, mri, ct, ultrasound and pet, forms an essential component of such an education. internet technologies provide a vehicle to carry medical imaging education online. there exist a number of internet-based medical imaging hyper-books or online documentations. however, there are few providing interactive computational simulations. we focus on delivering knowledge of the physical principles and engineering implementation of medical imaging techniques through an interactive website environment. the online medical imaging simulation system presented in this report outlines basic principles underlying different imaging techniques and image processing algorithms and offers trainees an interactive virtual laboratory. for education purposes, this system aims to provide general understanding of each imaging modality with comprehensive explanations, ample illustrations and copious references as its thrust, rather than complex physics or detailed math. this report specifically describes the development of the tutorial for commonly used medical imaging modalities. an internet-accessible interface is used to simulate various imaging algorithms with user-adjustable parameters. the tutorial is under the matlab web server environment. macromedia director mx is used to develop interactive animations integrating theory with graphic-oriented simulations. html and javascript are used to enable a user to explore these modules online in a web browser. numerous multiple choice questions, links and references for advanced study are provided in the tutorial for trainees to verify their understanding of each unit. it is expected that this tutorial will enhance medical imaging education, help trainees in subsequent analysis of image data, and form the basis for the development of more advanced technologies in the future. © 2005 elsevier ltd. all rights reserved.",an online interactive simulation system for medical imaging education
2058,2-s2.0-18844454053,10.1016/j.comnet.2005.01.003,A testing framework for Web application security assessment,Huang Y.W.,Computer Networks,2005-08-05,The rapid development phases and extremely short turnaround time of Web applications make it difficult to eliminate their vulnerabilities. Here we study how software testing techniques such as fault injection and runtime monitoring can be applied to Web applications. We implemented our proposed mechanisms in the Web Application Vulnerability and Error Scanner (WAVES)-a black-box testing framework for automated Web application security assessment. Real-world situations are used to test WAVES and to compare it with other tools. Our results show that WAVES is a feasible platform for assessing Web application security. © 2005 Elsevier B.V. All rights reserved.,Black-box testing | Complete crawling | Fault injection | Security assessment | Web application testing,51,739-761,Journal,Article,6.0,"Huang, Yao Wen;Tsai, Chung Hung;Lin, Tsung Po;Huang, Shih Kun;Lee, D. T.;Kuo, Sy Yen",56110502100;56409027000;16645749600;7405419066;55909602800;7401785539,"Academia Sinica, Institute of Information Science;National Chiao Tung University;National Taiwan University",Taiwan;Taiwan;Taiwan,the rapid development phases and extremely short turnaround time of web applications make it difficult to eliminate their vulnerabilities. here we study how software testing techniques such as fault injection and runtime monitoring can be applied to web applications. we implemented our proposed mechanisms in the web application vulnerability and error scanner (waves)-a black-box testing framework for automated web application security assessment. real-world situations are used to test waves and to compare it with other tools. our results show that waves is a feasible platform for assessing web application security. © 2005 elsevier b.v. all rights reserved.,a testing framework for web application security assessment
2059,2-s2.0-20444435544,10.1108/09593840510601513,Weblogs as a bridging genre,Herring S.,Information Technology and People,2005-06-27,"Purpose - Aims to describe systematically the characteristics of weblogs (blogs) - frequently modified web pages in which dated entries are listed in reverse chronological sequence and which are the latest genre of internet communication to attain widespread popularity. Design/methodology/approach - This paper presents the results of a quantitative content analysis of 203 randomly selected blogs, comparing the empirically observable features of the corpus with popular claims about the nature of blogs, and finding them to differ in a number of respects. Findings - Notably, blog authors, journalists and scholars alike exaggerate the extent to which blogs are interlinked, interactive, and oriented towards external events, and underestimate the importance of blogs as individualistic, intimate forms of self-expression. Originality/value - Based on the profile generated by the empirical analysis, considers the likely antecedents of the blog genre, situates it with respect to the dominant forms of digital communication on the internet today, and suggests possible developments of the use of blogs over time in response to changes in user behavior, technology, and the broader ecology of internet genres. © Emerald Group Publishing Limited.",Communication | Communication technologies | Internet | Worldwide web,386,142-171,Journal,Article,4.0,"Herring, Susan C.;Scheidt, Lois Ann;Wright, Elijah;Bonus, Sabrina",7005704556;8629652500;8629652600;8629652700,Indiana University Bloomington,United States,"purpose - aims to describe systematically the characteristics of weblogs (blogs) - frequently modified web pages in which dated entries are listed in reverse chronological sequence and which are the latest genre of internet communication to attain widespread popularity. design/methodology/approach - this paper presents the results of a quantitative content analysis of 203 randomly selected blogs, comparing the empirically observable features of the corpus with popular claims about the nature of blogs, and finding them to differ in a number of respects. findings - notably, blog authors, journalists and scholars alike exaggerate the extent to which blogs are interlinked, interactive, and oriented towards external events, and underestimate the importance of blogs as individualistic, intimate forms of self-expression. originality/value - based on the profile generated by the empirical analysis, considers the likely antecedents of the blog genre, situates it with respect to the dominant forms of digital communication on the internet today, and suggests possible developments of the use of blogs over time in response to changes in user behavior, technology, and the broader ecology of internet genres. © emerald group publishing limited.",weblogs as a bridging genre
2068,2-s2.0-33646844786,10.1145/1026487.1008005,Design and evolution of an undergraduate course on web application development,Yue K.B.,"SIGCSE Bulletin (Association for Computing Machinery, Special Interest Group on Computer Science Education)",2004-09-01,"Web technologies have become essential in the computing curricula. However, teaching a Web development course to computing students is challenging because of large bodies of knowledge, rapidly changing technologies, demanding support infrastructures and diverse background of audiences. This paper presents the evolution and the experiences we have gained in teaching a Web development course for the past seven years. We incorporate selected leading edge Web technologies as soon as they become mature and stable. The course covers a broad spectrum of Internet technologies to provide a solid conceptual framework. It also includes an in-depth study of a selected technology to provide the necessary depth and knowledge to build realistic Web applications. This paper describes the course design, our choice of topics, programming assignments, course delivery and our experience in coping with the rapidly changing Web technologies. Copyright 2004 ACM.",.NET | ASP | C# | CGI | Cold Fusion | Computer Science Education | CSS | HTML | HTTP | Internet Technology | J2EE | Java Servlets | JavaScript | JSP | Pedagogy | Perl | Web Architecture | Web Programming | XHTML | XML | XSL,10,22-26,Conference Proceeding,Conference Paper,2.0,"Yue, Kwok Bun;Ding, Wei",57202488492;56598956600,University of Houston-Clear Lake,United States,"web technologies have become essential in the computing curricula. however, teaching a web development course to computing students is challenging because of large bodies of knowledge, rapidly changing technologies, demanding support infrastructures and diverse background of audiences. this paper presents the evolution and the experiences we have gained in teaching a web development course for the past seven years. we incorporate selected leading edge web technologies as soon as they become mature and stable. the course covers a broad spectrum of internet technologies to provide a solid conceptual framework. it also includes an in-depth study of a selected technology to provide the necessary depth and knowledge to build realistic web applications. this paper describes the course design, our choice of topics, programming assignments, course delivery and our experience in coping with the rapidly changing web technologies. copyright 2004 acm.",design and evolution of an undergraduate course on web application development
2074,2-s2.0-84880450431,10.1145/775152.775174,Web application security assessment by fault injection and behavior monitoring,Huang Y.W.,"Proceedings of the 12th International Conference on World Wide Web, WWW 2003",2003-12-01,"As a large and complex application platform, the World Wide Web is capable of delivering a broad range of sophisticated applications. However, many Web applications go through rapid development phases with extremely short turnaround time, making it difficult to eliminate vulnerabilities. Here we analyze the design of Web application security assessment mechanisms in order to identify poor coding practices that render Web applications vulnerable to attacks such as SQL injection and cross-site scripting. We describe the use of a number of software-testing techniques (including dynamic analysis, black-box testing, fault injection, and behavior monitoring), and suggest mechanisms for applying these techniques to Web applications. Real-world situations are used to test a tool we named the Web Application Vulnerability and Error Scanner (WAVES, an open-source project available at http://waves.sourceforge.net) and to compare it with other tools. Our results show that WAVES is a feasible platform for assessing Web application security.",black-box testing | complete crawling | fault injection | security assessment | web application testing,212,148-159,Conference Proceeding,Conference Paper,4.0,"Huang, Yao Wen;Huang, Shih Kun;Lin, Tsung Po;Tsai, Chung Hung",56110502100;7405419066;16645749600;56409027000,"Academia Sinica, Institute of Information Science;National Chiao Tung University",Taiwan;Taiwan,"as a large and complex application platform, the world wide web is capable of delivering a broad range of sophisticated applications. however, many web applications go through rapid development phases with extremely short turnaround time, making it difficult to eliminate vulnerabilities. here we analyze the design of web application security assessment mechanisms in order to identify poor coding practices that render web applications vulnerable to attacks such as sql injection and cross-site scripting. we describe the use of a number of software-testing techniques (including dynamic analysis, black-box testing, fault injection, and behavior monitoring), and suggest mechanisms for applying these techniques to web applications. real-world situations are used to test a tool we named the web application vulnerability and error scanner (waves, an open-source project available at http://waves.sourceforge.net) and to compare it with other tools. our results show that waves is a feasible platform for assessing web application security.",web application security assessment by fault injection and behavior monitoring
2075,2-s2.0-3342964524,10.1002/cae.10036,Development of a web-based mass transfer processes laboratory: System development and implementation,Li Y.,Computer Applications in Engineering Education,2003-12-01,"A web-based environment is utilized as a means to introduce advanced mass transfer processes concepts in environmental engineering and science courses. System development and implementation is presented, including detailed descriptions of the techniques employed to link software written in high-level computer languages such as C++ and FORTRAN to an internet-based, user-friendly graphical user interface for both program input and output. © 2003 Wiley Periodicals, Inc.",Computer-facilitated learning | Environmental engineering | Internet | Mass transfer processes education,19,25-39,Journal,Review,4.0,"Li, Yusong;LeBoeuf, Eugene J.;Basu, P. K.;Turner IV, Louis Hampton",55241867100;7004591526;56846566000;55665544400,"Vanderbilt University;Turner Technology, LLC",United States;United States,"a web-based environment is utilized as a means to introduce advanced mass transfer processes concepts in environmental engineering and science courses. system development and implementation is presented, including detailed descriptions of the techniques employed to link software written in high-level computer languages such as c++ and fortran to an internet-based, user-friendly graphical user interface for both program input and output. © 2003 wiley periodicals, inc.",development of a web-based mass transfer processes laboratory: system development and implementation
2079,2-s2.0-0042428709,10.1108/09576060310491388,A web-based agile system for rolling bearing design,Pan P.,Integrated Manufacturing Systems,2003-09-08,"Rolling bearings are basic mechanical elements for supporting rotational and reciprocating motion in engineering products. Many approaches have been proposed by researchers in order to facilitate the procedure of bearing design, but mainly concentrating on the development of PC-based systems or relative software packages. The authors present a novel approach to implementing a design support system for rolling bearings based on the World Wide Web so as to achieve agility in rolling bearing design. The system was developed based on the philosophy of agile manufacturing by integrating various information resources, artificial intelligence, and Web technology with expertise. This Web-based distributed system will be globally accessible by the user on the Internet and can be automatically sized according to the demand of application requirements. The system implementation issues are discussed in detail in this paper.",Agile production | Artificial intelligence | Internet | Operating systems,16,518-529,Journal,Article,3.0,"Pan, P. Y.;Cheng, K.;Harrison, D. K.",7102504497;35209752100;7403545546,Leeds Beckett University;University of Liverpool;Glasgow Caledonian University,United Kingdom;United Kingdom;United Kingdom,"rolling bearings are basic mechanical elements for supporting rotational and reciprocating motion in engineering products. many approaches have been proposed by researchers in order to facilitate the procedure of bearing design, but mainly concentrating on the development of pc-based systems or relative software packages. the authors present a novel approach to implementing a design support system for rolling bearings based on the world wide web so as to achieve agility in rolling bearing design. the system was developed based on the philosophy of agile manufacturing by integrating various information resources, artificial intelligence, and web technology with expertise. this web-based distributed system will be globally accessible by the user on the internet and can be automatically sized according to the demand of application requirements. the system implementation issues are discussed in detail in this paper.",a web-based agile system for rolling bearing design
2081,2-s2.0-84867954088,10.1016/S0360-1315(02)00131-8,Combining interactivity and improved layout while creating educational software for the Web,Barretto S.F.A.,Computers and Education,2003-01-01,"Two major attributes influence a project aimed at developing educational software: user interactivity and graphic design. These two attributes are not easily found within the same development tool. Moreover, sometimes the development tool is either very expensive to acquire or too difficult to use. This article aims to present a solution to the creation of educational development tools which emphasize the conjunction between interactivity and graphic design. The authors propose a methodology based on Web technology and an association between the Java programming language and the authoring tool Flash. In addition to fostering interactivity, Java offers development packages at no cost. The authoring software Flash is inexpensive and allows the creation of finely crafted Web pages with graphic animations and sound editing. This article describes the methodology that enables the association between Java and Flash components. This methodology was conceived during the development of a structural analysis educational software product specially geared to undergraduate engineering students. In order to ensure the understanding of our proposal, a specific example was created, along with sample pages that illustrate this methodology. © 2002 Elsevier Science Ltd.",Authoring tools and methods | Human-computer interface | Interactive learning environments | Media in education | Programming and programming languages,15,271-284,Journal,Article,5.0,"Barretto, Saulo Faria Almeida;Piazzalunga, Renata;Guimarães Ribeiro, Viviane;Casemiro Dalla, Maria Beatriz;Leon Filho, Roberto Moreno",6602940210;6503859220;55439157800;55439306600;55439150800,Universidade de Mogi das Cruzes;Rua Navajas,Brazil;Brazil,"two major attributes influence a project aimed at developing educational software: user interactivity and graphic design. these two attributes are not easily found within the same development tool. moreover, sometimes the development tool is either very expensive to acquire or too difficult to use. this article aims to present a solution to the creation of educational development tools which emphasize the conjunction between interactivity and graphic design. the authors propose a methodology based on web technology and an association between the java programming language and the authoring tool flash. in addition to fostering interactivity, java offers development packages at no cost. the authoring software flash is inexpensive and allows the creation of finely crafted web pages with graphic animations and sound editing. this article describes the methodology that enables the association between java and flash components. this methodology was conceived during the development of a structural analysis educational software product specially geared to undergraduate engineering students. in order to ensure the understanding of our proposal, a specific example was created, along with sample pages that illustrate this methodology. © 2002 elsevier science ltd.",combining interactivity and improved layout while creating educational software for the web
2084,2-s2.0-0037945149,10.1007/s00420-002-0376-7,Web-based training in occupational medicine,Hege I.,International Archives of Occupational and Environmental Health,2003-01-01,"Objectives: The aim of our project was to develop and evaluate an interactive computer-based approach to teach medical students in occupational medicine. To enhance interest in occupational medicine the major focus was on clinical and practical aspects of occupational medicine. Methods: The computer program was designed in HTML and JavaScript. It presents a guided tour of the patient's case history followed by information on practice and theory of occupational medicine. The program was integrated into the curriculum during the summer term of 1999 and the following winter term. To assess the effectiveness and acceptability of the program we asked students to rate the program on an 18-item questionnaire. Results: Overall, 287 students participated in the evaluation of the program. The participants highly recommended the program structure and had no difficulties in handling the program. This was independent of the computer experience of the students. The evaluation showed that it was possible to enhance interest in occupational medicine by using ""virtual patients"". Conclusion: The program represents a student-orientated learning tool that points out clinical and practical aspects of occupational medicine. The availability via the Internet allows the application as a self-learning tool as well as a teaching tool for the medical curriculum. © Springer-Verlag 2002.",CBT | Occupational medicine | PBL | Student course | WBT,21,50-54,Journal,Article,5.0,"Hege, Inga;Radon, Katja;Dugas, Martin;Scharrer, Eva;Nowak, Dennis",6506755692;7003674980;55550317000;57210095749;7201764407,Ludwig-Maximilians-Universität München,Germany,"objectives: the aim of our project was to develop and evaluate an interactive computer-based approach to teach medical students in occupational medicine. to enhance interest in occupational medicine the major focus was on clinical and practical aspects of occupational medicine. methods: the computer program was designed in html and javascript. it presents a guided tour of the patient's case history followed by information on practice and theory of occupational medicine. the program was integrated into the curriculum during the summer term of 1999 and the following winter term. to assess the effectiveness and acceptability of the program we asked students to rate the program on an 18-item questionnaire. results: overall, 287 students participated in the evaluation of the program. the participants highly recommended the program structure and had no difficulties in handling the program. this was independent of the computer experience of the students. the evaluation showed that it was possible to enhance interest in occupational medicine by using ""virtual patients"". conclusion: the program represents a student-orientated learning tool that points out clinical and practical aspects of occupational medicine. the availability via the internet allows the application as a self-learning tool as well as a teaching tool for the medical curriculum. © springer-verlag 2002.",web-based training in occupational medicine
2087,2-s2.0-0036892942,10.1016/S0167-8191(02)00186-2,Grid programming: Some indications where we are headed,Laforenza D.,Parallel Computing,2002-12-01,"Grid computing enables the development of large scientific applications on an unprecedented scale. Grid-aware applications, also called meta-applications or multi-disciplinary applications, make use of coupled computational resources that are not available at a single site. In this light, the Grids let scientists solve larger or new problems by pooling together resources that could not be coupled easily before. It is well known that the programmer's productivity in designing and implementing efficient distributed/parallel applications on high-performance computers is still usually a very time-consuming task. Grid computing makes the situation worse. Consequently, the development of Grid programming environments that would enable programmers to efficiently exploit this technology is an important and hot research issue. After an introduction on the main Grid programming issues, this paper will review the most important approaches/projects conducted in this field worldwide. © 2002 Elsevier Science B.V. All rights reserved.",Component programming | Grid computing | Grid programming | Middleware,39,1733-1752,Journal,Conference Paper,1.0,"Laforenza, Domenico",6701358218,Istituto di Scienza e Tecnologie dell'Informazione A. Faedo,Italy,"grid computing enables the development of large scientific applications on an unprecedented scale. grid-aware applications, also called meta-applications or multi-disciplinary applications, make use of coupled computational resources that are not available at a single site. in this light, the grids let scientists solve larger or new problems by pooling together resources that could not be coupled easily before. it is well known that the programmer's productivity in designing and implementing efficient distributed/parallel applications on high-performance computers is still usually a very time-consuming task. grid computing makes the situation worse. consequently, the development of grid programming environments that would enable programmers to efficiently exploit this technology is an important and hot research issue. after an introduction on the main grid programming issues, this paper will review the most important approaches/projects conducted in this field worldwide. © 2002 elsevier science b.v. all rights reserved.",grid programming: some indications where we are headed
2092,2-s2.0-0036785114,10.1002/cpe.707,A quality-of-service-based framework for creating distributed heterogeneous software components,Raje R.R.,Concurrency and Computation: Practice and Experience,2002-01-01,"Component-based software development offers a promising solution for taming the complexity found in today's distributed applications. Today's and future distributed software systems will certainly require combining heterogeneous software components that are geographically dispersed. For the successful deployment of such a software system, it is necessary that its realization, based on assembling heterogeneous components, not only meets the functional requirements, but also satisfies the non-functional criteria such as the desired quality of service (QoS). In this paper, a framework based on the notions of a meta-component model, a generative domain model and QoS parameters is described, A formal specification based on two-level grammar is used to represent these notions in a tightly integrated way so that QoS becomes a part of the generative domain model. A simple case study is described in the context of this framework. Copyright © 2002 John Wiley & Sons, Ltd.",Distributed systems | Formal methods | Generative domain models | Heterogeneous components | Quality of service | Two-level grammar,23,1009-1034,Journal,Article,5.0,"Raje, Rajeev R.;Bryant, Barrett R.;Olson, Andrew M.;Auguston, Mikhail;Burt, Carol",6701688211;26642882600;7102256617;6602160910;7102207797,The University of Alabama at Birmingham;Indiana University-Purdue University Indianapolis;New Mexico State University,United States;United States;United States,"component-based software development offers a promising solution for taming the complexity found in today's distributed applications. today's and future distributed software systems will certainly require combining heterogeneous software components that are geographically dispersed. for the successful deployment of such a software system, it is necessary that its realization, based on assembling heterogeneous components, not only meets the functional requirements, but also satisfies the non-functional criteria such as the desired quality of service (qos). in this paper, a framework based on the notions of a meta-component model, a generative domain model and qos parameters is described, a formal specification based on two-level grammar is used to represent these notions in a tightly integrated way so that qos becomes a part of the generative domain model. a simple case study is described in the context of this framework. copyright © 2002 john wiley & sons, ltd.",a quality-of-service-based framework for creating distributed heterogeneous software components
2094,2-s2.0-0036262967,10.1108/02635570210423244,Managing the development of a mainframe-based inquiry system for the internet,Fleming M.,Industrial Management and Data Systems,2002-01-01,"Although the Internet and the World Wide Web (Web) have existed for several years, it has only been in the past year or two that high-powered software and infrastructure have been available for a company to web enable legacy mainframe systems (i.e. to provide an Internet front-end). This paper addresses the management considerations in developing a web-enabled mainframe using current Internet technologies and without the added cost and maintenance overhead of new hardware and expensive software.",Development | Internet | Mainframes,1,203-210,Journal,Article,2.0,"Fleming, Matthew;Couturier, Gordon",36929508700;7007052642,The University of Tampa,United States,"although the internet and the world wide web (web) have existed for several years, it has only been in the past year or two that high-powered software and infrastructure have been available for a company to web enable legacy mainframe systems (i.e. to provide an internet front-end). this paper addresses the management considerations in developing a web-enabled mainframe using current internet technologies and without the added cost and maintenance overhead of new hardware and expensive software.",managing the development of a mainframe-based inquiry system for the internet
2098,2-s2.0-3242685361,10.2196/jmir.3.1.e8,Internet patient records: New techniques,Brelstaff G.,Journal of Medical Internet Research,2001-01-01,"Background: The ease by which the Internet is able to distribute information to geographically-distant users on a wide variety of computers makes it an obvious candidate for a technological solution for electronic patient record systems. Indeed, second-generation Internet technologies such as the ones described in this article - XML (eXtensible Markup Language), XSL (eXtensible Style Language), DOM (Document Object Model), CSS (Cascading Style Sheet), JavaScript, and JavaBeans - may significantly reduce the complexity of the development of distributed healthcare systems. Objective: The demonstration of an experimental Electronic Patient Record (EPR) system built from those technologies that can support viewing of medical imaging exams and graphically-rich clinical reporting tools, while conforming to the newly emerging XML standard for digital documents. In particular, we aim to promote rapid prototyping of new reports by clinical specialists. Methods: We have built a prototype EPR client, InfoDOM, that runs in both the popular web browsers. In this second version it receives each EPR as an XML record served via the secure SSL (Secure Socket Layer) protocol. JavaBean software components manipulate the XML to store it and then to transform it into a variety of useful clinical views. First a web page summary for the patient is produced. From that web page other JavaBeans can be launched. In particular, we have developed a medical imaging exam Viewer and a clinical Reporter bean parameterized appropriately for the particular patient and exam in question. Both present particular views of the XML data. The Viewer reads image sequences from a patient-specified network URL on a PACS (Picture Archiving and Communications System) server and presents them in a user-controllable animated sequence, while the Reporter provides a configurable anatomical map of the site of the pathology, from which individual ""reportlets"" can be launched. The specification of these reportlets is achieved using standard HTML forms and thus may conceivably be authored by clinical specialists. A generic JavaScript library has been written that allows the seamless incorporation of such contributions into the InfoDOM client. In conjunction with another JavaBean, that library renders graphically-enhanced reporting tools that read and write content to and from the XML data-structure, ready for resubmission to the EPR server. Results: We demonstrate the InfoDOM experimental EPR system that is currently being adapted for test-bed use in three hospitals in Cagliari, Italy. For this we are working with specialists in neurology, radiology, and epilepsy. Conclusions: Early indications are that the rapid prototyping of reports afforded by our EPR system can assist communication between clinical specialists and our system developers. We are now experimenting with new technologies that may provide services to the kind of XML EPR client described here.",Electronic Medical Record | Elicitation Methods | Internet | Java | JavaScript | Medical Information Systems | Rapid Prototyping | XML | XSL,16,92-109,Journal,Article,5.0,"Brelstaff, Gavin;Moehrs, Sascha;Anedda, Paolo;Tuveri, Massimiliano;Zanetti, Gianluigi",6603066582;12544959600;6508318658;57201820170;57197321160,CRS4 - Centro di Ricerca Sviluppo e Studi Superiori in Sardegna,Italy,"background: the ease by which the internet is able to distribute information to geographically-distant users on a wide variety of computers makes it an obvious candidate for a technological solution for electronic patient record systems. indeed, second-generation internet technologies such as the ones described in this article - xml (extensible markup language), xsl (extensible style language), dom (document object model), css (cascading style sheet), javascript, and javabeans - may significantly reduce the complexity of the development of distributed healthcare systems. objective: the demonstration of an experimental electronic patient record (epr) system built from those technologies that can support viewing of medical imaging exams and graphically-rich clinical reporting tools, while conforming to the newly emerging xml standard for digital documents. in particular, we aim to promote rapid prototyping of new reports by clinical specialists. methods: we have built a prototype epr client, infodom, that runs in both the popular web browsers. in this second version it receives each epr as an xml record served via the secure ssl (secure socket layer) protocol. javabean software components manipulate the xml to store it and then to transform it into a variety of useful clinical views. first a web page summary for the patient is produced. from that web page other javabeans can be launched. in particular, we have developed a medical imaging exam viewer and a clinical reporter bean parameterized appropriately for the particular patient and exam in question. both present particular views of the xml data. the viewer reads image sequences from a patient-specified network url on a pacs (picture archiving and communications system) server and presents them in a user-controllable animated sequence, while the reporter provides a configurable anatomical map of the site of the pathology, from which individual ""reportlets"" can be launched. the specification of these reportlets is achieved using standard html forms and thus may conceivably be authored by clinical specialists. a generic javascript library has been written that allows the seamless incorporation of such contributions into the infodom client. in conjunction with another javabean, that library renders graphically-enhanced reporting tools that read and write content to and from the xml data-structure, ready for resubmission to the epr server. results: we demonstrate the infodom experimental epr system that is currently being adapted for test-bed use in three hospitals in cagliari, italy. for this we are working with specialists in neurology, radiology, and epilepsy. conclusions: early indications are that the rapid prototyping of reports afforded by our epr system can assist communication between clinical specialists and our system developers. we are now experimenting with new technologies that may provide services to the kind of xml epr client described here.",internet patient records: new techniques
2099,2-s2.0-3242685337,10.2196/jmir.3.4.e32,Design and implementation of a Portal for the medical equipment market: MEDICOM,Palamas S.,Journal of Medical Internet Research,2001-01-01,"Background: The MEDICOM (Medical Products Electronic Commerce) Portal provides the electronic means for medical-equipment manufacturers to communicate online with their customers while supporting the Purchasing Process and Post Market Surveillance. The Portal offers a powerful Internet-based search tool for finding medical products and manufacturers. Its main advantage is the fast, reliable and up-to-date retrieval of information while eliminating all unrelated content that a general-purpose search engine would retrieve. The Universal Medical Device Nomenclature System (UMDNS) registers all products. The Portal accepts end-user requests and generates a list of results containing text descriptions of devices, UMDNS attribute values, and links to manufacturer Web pages and online catalogues for access to more-detailed information. Device short descriptions are provided by the corresponding manufacturer. The Portal offers technical support for integration of the manufacturers' Web sites with itself. The network of the Portal and the connected manufacturers' sites is called the MEDICOM system. Objective: To establish an environment hosting all the interactions of consumers (health care organizations and professionals) and providers (manufacturers, distributors, and resellers of medical devices). Methods: The Portal provides the end-user interface, implements system management, and supports database compatibility. The Portal hosts information about the whole MEDICOM system (Common Database) and summarized descriptions of medical devices (Short Description Database); the manufacturers' servers present extended descriptions. The Portal provides end-user profiling and registration, an efficient product-searching mechanism, bulletin boards, links to on-line libraries and standards, online information for the MEDICOM system, and special messages or advertisements from manufacturers. Platform independence and interoperability characterize the system design. Relational Database Management Systems are used for the system's databases. The end-user interface is implemented using HTML, Javascript, Java applets, and XML documents. Communication between the Portal and the manufacturers' servers is implemented using a CORBA interface. Remote administration of the Portal is enabled by dynamically-generated HTML interfaces based on XML documents. A representative group of users evaluated the system. The aim of the evaluation was validation of the usability of all of MEDICOM's functionality. The evaluation procedure was based on ISO/IEC 9126 Information technology - Software product evaluation - Quality characteristics and guidelines for their use. Results: The overall user evaluation of the MEDICOM system was very positive. The MEDICOM system was characterized as an innovative concept that brings significant added value to medical-equipment commerce. Conclusions: The eventual benefits of the MEDICOM system are (a) establishment of a worldwide-accessible marketplace between manufacturers and health care professionals that provides up-to-date and high-quality product information in an easy and friendly way and (b) enhancement of the efficiency of marketing procedures and after-sales support.",CORBA | Electronic commerce | Equipment and supplies | Internet | Medical devices | RDBMS | XML,2,88-100,Journal,Article,5.0,"Palamas, Stergios;Kalivas, Dimitris;Panou-Diamandi, Ourania;Zeelenberg, Cees;Van Nimwegen, Chris",6602541165;6701404408;6603003422;7004170049;6603403098,University of West Attica;Nederlandse Organisatie voor toegepast natuurwetenschappelijk onderzoek- TNO;National Technical University of Athens,Greece;Netherlands;Greece,"background: the medicom (medical products electronic commerce) portal provides the electronic means for medical-equipment manufacturers to communicate online with their customers while supporting the purchasing process and post market surveillance. the portal offers a powerful internet-based search tool for finding medical products and manufacturers. its main advantage is the fast, reliable and up-to-date retrieval of information while eliminating all unrelated content that a general-purpose search engine would retrieve. the universal medical device nomenclature system (umdns) registers all products. the portal accepts end-user requests and generates a list of results containing text descriptions of devices, umdns attribute values, and links to manufacturer web pages and online catalogues for access to more-detailed information. device short descriptions are provided by the corresponding manufacturer. the portal offers technical support for integration of the manufacturers' web sites with itself. the network of the portal and the connected manufacturers' sites is called the medicom system. objective: to establish an environment hosting all the interactions of consumers (health care organizations and professionals) and providers (manufacturers, distributors, and resellers of medical devices). methods: the portal provides the end-user interface, implements system management, and supports database compatibility. the portal hosts information about the whole medicom system (common database) and summarized descriptions of medical devices (short description database); the manufacturers' servers present extended descriptions. the portal provides end-user profiling and registration, an efficient product-searching mechanism, bulletin boards, links to on-line libraries and standards, online information for the medicom system, and special messages or advertisements from manufacturers. platform independence and interoperability characterize the system design. relational database management systems are used for the system's databases. the end-user interface is implemented using html, javascript, java applets, and xml documents. communication between the portal and the manufacturers' servers is implemented using a corba interface. remote administration of the portal is enabled by dynamically-generated html interfaces based on xml documents. a representative group of users evaluated the system. the aim of the evaluation was validation of the usability of all of medicom's functionality. the evaluation procedure was based on iso/iec 9126 information technology - software product evaluation - quality characteristics and guidelines for their use. results: the overall user evaluation of the medicom system was very positive. the medicom system was characterized as an innovative concept that brings significant added value to medical-equipment commerce. conclusions: the eventual benefits of the medicom system are (a) establishment of a worldwide-accessible marketplace between manufacturers and health care professionals that provides up-to-date and high-quality product information in an easy and friendly way and (b) enhancement of the efficiency of marketing procedures and after-sales support.",design and implementation of a portal for the medical equipment market: medicom
2102,2-s2.0-35048824858,10.1145/338407.338709,The evolution of the DARWIN system,Walton J.D.,Proceedings of the ACM Symposium on Applied Computing,2000-12-01,"DARWIN is a web-based system for presenting the results of wind-tunnel testing and computational model analyses to aerospace designers. DARWIN captures the data, maintains the information, and manages derived knowledge (e.g. visualizations) of large quantities of aerospace data. In addition, it provides tools and an environment for distributed collaborative engineering. We are currently constructing the third version of the DARWIN software system. DARWIN's development history has, in some sense, tracked the development of web applications. The 1995 DARWIN reflected the latest web technologies - CGI scripts, Java applets and a three-layer architecture - available at that time. The 1997 version of DARWIN expanded on this base, making extensive use of a plethora of web technologies, including Java/JavaScript and Dynamic HTML. While more powerful, this multiplicity has proven to be a maintenance and development headache. The 2000 version of DARWIN will provide a more stable and uniform foundation environment, composed primarily of Java mechanisms. In this paper, we discuss this evolution, comparing the strengths and weaknesses of the various architectural approaches and describing the lessons learned about building complex web applications.",Collaborative engineering | DARWIN | Distributed analysis | Wind-tunnel | WWW applications,5,971-977,Conference Proceeding,Conference Paper,3.0,"Walton, Joan D.;Filman, Robert E.;Korsmeyer, David J.",8250845900;6603708494;6506704863,NASA Ames Research Center,United States,"darwin is a web-based system for presenting the results of wind-tunnel testing and computational model analyses to aerospace designers. darwin captures the data, maintains the information, and manages derived knowledge (e.g. visualizations) of large quantities of aerospace data. in addition, it provides tools and an environment for distributed collaborative engineering. we are currently constructing the third version of the darwin software system. darwin's development history has, in some sense, tracked the development of web applications. the 1995 darwin reflected the latest web technologies - cgi scripts, java applets and a three-layer architecture - available at that time. the 1997 version of darwin expanded on this base, making extensive use of a plethora of web technologies, including java/javascript and dynamic html. while more powerful, this multiplicity has proven to be a maintenance and development headache. the 2000 version of darwin will provide a more stable and uniform foundation environment, composed primarily of java mechanisms. in this paper, we discuss this evolution, comparing the strengths and weaknesses of the various architectural approaches and describing the lessons learned about building complex web applications.",the evolution of the darwin system
2104,2-s2.0-0041456161,10.1023/A:1018772405468,PowerForms: Declarative client-side form field validation,Brabrand C.,World Wide Web,2000-12-01,"All uses of HTML forms may benefit from validation of the specified input field values. Simple validation matches individual values against specified formats, while more advanced validation may involve interdependencies of form fields. There is currently no standard for specifying or implementing such validation. Today, CGI programmers often use Perl libraries for simple server-side validation or program customized JavaScript solutions for client-side validation. We present PowerForms, which is an add-on to HTML forms that allows a purely declarative specification of input formats and sophisticated interdependencies of form fields. While our work may be seen as inspiration for a future extension of HTML, it is also available for CGI programmers today through a preprocessor that translates a PowerForms document into a combination of standard HTML and JavaScript that works on all combinations of platforms and browsers. The definitions of PowerForms formats are syntactically disjoint from the form itself, which allows a modular development where the form is perhaps automatically generated by other tools and the formats and interdependencies are added separately. PowerForms has a clean semantics defined through a fixed-point process that resolves the interdependencies between all field values. Text fields are equipped with status icons (by default traffic lights) that continuously reflect the validity of the text that has been entered so far, thus providing immediate feed-back for the user. For other GUI components the available options are dynamically filtered to present only the allowed values. PowerForms are integrated into the <bigwig> system for generating interactive Web services, but is also freely available in an Open Source distribution as a stand-alone package.",Declarative Specification | Field Validation | Form Field | Modular Development | Source Distribution,35,205-214,Journal,Article,4.0,"Brabrand, Claus;Møller, Anders;Ricky, Mikkel;Schwartzbach, Michael I.",6506051889;57195116933;57819151500;6603902993,Aarhus Universitet,Denmark,"all uses of html forms may benefit from validation of the specified input field values. simple validation matches individual values against specified formats, while more advanced validation may involve interdependencies of form fields. there is currently no standard for specifying or implementing such validation. today, cgi programmers often use perl libraries for simple server-side validation or program customized javascript solutions for client-side validation. we present powerforms, which is an add-on to html forms that allows a purely declarative specification of input formats and sophisticated interdependencies of form fields. while our work may be seen as inspiration for a future extension of html, it is also available for cgi programmers today through a preprocessor that translates a powerforms document into a combination of standard html and javascript that works on all combinations of platforms and browsers. the definitions of powerforms formats are syntactically disjoint from the form itself, which allows a modular development where the form is perhaps automatically generated by other tools and the formats and interdependencies are added separately. powerforms has a clean semantics defined through a fixed-point process that resolves the interdependencies between all field values. text fields are equipped with status icons (by default traffic lights) that continuously reflect the validity of the text that has been entered so far, thus providing immediate feed-back for the user. for other gui components the available options are dynamically filtered to present only the allowed values. powerforms are integrated into the <bigwig> system for generating interactive web services, but is also freely available in an open source distribution as a stand-alone package.",powerforms: declarative client-side form field validation
2106,2-s2.0-84968830700,10.1109/WISE.2000.882425,A fast and flexible framework of scripting for Web application development: A preliminary experience report,Tam V.,"Proceedings of the 1st International Conference on Web Information Systems Engineering, WISE 2000",2000-01-01,"The World-Wide Web represents an opportunistic Internet-based platform on which many new applications are developing rapidly. To facilitate fast Web applications, a scripting approach is one possible solution for software developers. However, then are two major drawbacks for many existing scripting tools. First, most of these scripting tools are proprietary, and only available on chosen platforms. Second, most scripting tools use the Hyper-Text Markup Language (HTML) as the basis for extension. To provide extra functionality such as database connection, various extended codes or commands are mixed with HTML tags to produce expected results. However, this dirty approach will make the design and development process more complicated. We propose a systematic and flexible scripting framework for fast Web application development. The two major components, layout script and information-processing script, naturally reflect the static and dynamic properties of a Web application. In addition, the information-processing script can flexibly be split into different component scripts to suit different applications. We built a prototype of a script parser and an Integrated Development Environment (IDE) tool to quickly develop an intelligent Web-based Personal Computer Configuration Advisor. Clearly, our proposal opens up many possible directions for investigation including the uses of the IDE tool to develop other applications, and the integration with other components to handle more complicated Web applications.",Innovative Web Applications | Scripting Tools | Web-Based Information System Development,1,450-455,Conference Proceeding,Conference Paper,3.0,"Tam, V.;Foo, W. K.;Gupta, R. K.",7005091988;57189301087;57212202987,National University of Singapore,Singapore,"the world-wide web represents an opportunistic internet-based platform on which many new applications are developing rapidly. to facilitate fast web applications, a scripting approach is one possible solution for software developers. however, then are two major drawbacks for many existing scripting tools. first, most of these scripting tools are proprietary, and only available on chosen platforms. second, most scripting tools use the hyper-text markup language (html) as the basis for extension. to provide extra functionality such as database connection, various extended codes or commands are mixed with html tags to produce expected results. however, this dirty approach will make the design and development process more complicated. we propose a systematic and flexible scripting framework for fast web application development. the two major components, layout script and information-processing script, naturally reflect the static and dynamic properties of a web application. in addition, the information-processing script can flexibly be split into different component scripts to suit different applications. we built a prototype of a script parser and an integrated development environment (ide) tool to quickly develop an intelligent web-based personal computer configuration advisor. clearly, our proposal opens up many possible directions for investigation including the uses of the ide tool to develop other applications, and the integration with other components to handle more complicated web applications.",a fast and flexible framework of scripting for web application development: a preliminary experience report
2107,2-s2.0-84951827017,10.1109/AUIC.2000.822074,BUS: A Browser based User interface Service for Web based applications,Sweeney M.,"Proceedings - 1st Australasian User Interface Conference, AUIC 2000",2000-01-01,"The growing complexity of Web based applications have uncovered software engineering problems in developing and maintaining these systems. The current Web application development and maintenance environment lacks the architectural models that are used in the development of other systems. The paper introduces a Browser User-interface Service (BUS) that offers an object oriented presentation language to build custom Web user interfaces that dynamically connect to application components. The components are able to reuse HTML, Javascript, and stylesheet content using prototype inheritance and dynamically bind presentation objects with data supplied in XML format. The BUS is designed to be platform, Web server, and browser independent, and use XML messages on TCP sockets to communicate with distributed application component processes. The BUS is a flexible component that is intended to improve consistency and flexibility in Web interface design and application maintenance. The BUS is also an integration component that can connect a custom user interface to multiple distributed application components.",Application software | HTML | Java | Object oriented modeling | Prototypes | Sockets | Software engineering | User interfaces | Web server | XML,1,103-109,Conference Proceeding,Conference Paper,1.0,"Sweeney, M.",57021025900,University of New South Wales at Australian Defence Force Academy;Defence Science and Technology Group,Australia;Australia,"the growing complexity of web based applications have uncovered software engineering problems in developing and maintaining these systems. the current web application development and maintenance environment lacks the architectural models that are used in the development of other systems. the paper introduces a browser user-interface service (bus) that offers an object oriented presentation language to build custom web user interfaces that dynamically connect to application components. the components are able to reuse html, javascript, and stylesheet content using prototype inheritance and dynamically bind presentation objects with data supplied in xml format. the bus is designed to be platform, web server, and browser independent, and use xml messages on tcp sockets to communicate with distributed application component processes. the bus is a flexible component that is intended to improve consistency and flexibility in web interface design and application maintenance. the bus is also an integration component that can connect a custom user interface to multiple distributed application components.",bus: a browser based user interface service for web based applications
2123,2-s2.0-84948170775,10.1007/10692867_7,Software engineering issues for network computing,Ghezzi C.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),1998-01-01,"The Internet is becoming the infrastructure upon which an increasing number of new applications are being developed. These applications allow new services to be provided and even new business areas to be opened. The growth of Internet-based applications has been one of the most striking technological achievements of the past few years. Yet, there are some risks inherent in this growth. Rapid development and reduced time to market have probably been the highest priority concerns for application developers. Therefore, these developments proceed without following a disciplined approach. We argue that the resulting applications will become the legacy systems of the near future, when the quality of these systems will need improvement but, at the same time, modications will be hard to make in an economical and reliable way. In this paper we discuss the need for a software engineering approach to the development of network applications. In particular, we discuss a possible research agenda for software engineering research by looking at two specic areas: the World Wide Web and applications based on mobile code.",Internet | Mobile code | Software development process | Software engineering | Software quality | World wide web,0,155-177,Book Series,Conference Paper,2.0,"Ghezzi, Carlo;Vigna, Giovanni",16512874900;7003452317,Politecnico di Milano,Italy,"the internet is becoming the infrastructure upon which an increasing number of new applications are being developed. these applications allow new services to be provided and even new business areas to be opened. the growth of internet-based applications has been one of the most striking technological achievements of the past few years. yet, there are some risks inherent in this growth. rapid development and reduced time to market have probably been the highest priority concerns for application developers. therefore, these developments proceed without following a disciplined approach. we argue that the resulting applications will become the legacy systems of the near future, when the quality of these systems will need improvement but, at the same time, modications will be hard to make in an economical and reliable way. in this paper we discuss the need for a software engineering approach to the development of network applications. in particular, we discuss a possible research agenda for software engineering research by looking at two specic areas: the world wide web and applications based on mobile code.",software engineering issues for network computing
2124,2-s2.0-0032023578,10.1023/a:1009648429168,ASML: Automatic Site Markup Language,Owen C.B.,Multimedia Tools and Applications,1998-01-01,"Creation of large and complex World Wide Web sites is hampered by the ""page at a time"" approach of many tools and the programming knowledge and custom software development required for automated solutions. This paper describes the development of Automatic Site Markup Language (ASML). ASML is a new markup language designed to automate and facilitate the production of large, complicated web sites which can include dynamic content or content that changes with time. ASML extends HTML with new, high-level features while still preserving complete compatibility with common browser and server technologies. It has powerful indexing and searching facilities, and enables the automatic translation of document formats. Most importantly, ASML provides HTML-like features at the site level rather than just the page level.",Courseware | HTML | Markup languages | Multimedia authoring | SGML | World Wide Web,0,113-139,Journal,Article,2.0,"Owen, Charles B.;Makedon, Fillia",7202893093;7003437865,"Louisiana Tech University;Dartmouth College;Western Illinois University;The University of Texas at Dallas;Northwestern University;Illinois Institute of Technology;Clark and Associates, Ltd.;Dartmouth Inst. Adv. Grad. Studs. P.",United States;United States;United States;United States;United States;United States;United States;Canada,"creation of large and complex world wide web sites is hampered by the ""page at a time"" approach of many tools and the programming knowledge and custom software development required for automated solutions. this paper describes the development of automatic site markup language (asml). asml is a new markup language designed to automate and facilitate the production of large, complicated web sites which can include dynamic content or content that changes with time. asml extends html with new, high-level features while still preserving complete compatibility with common browser and server technologies. it has powerful indexing and searching facilities, and enables the automatic translation of document formats. most importantly, asml provides html-like features at the site level rather than just the page level.",asml: automatic site markup language
2127,2-s2.0-0000601464,10.1287/ijoc.10.4.359,The World Wide Web: Opportunities for operations research and management science,Bhargava H.,INFORMS Journal on Computing,1998-01-01,"The World Wide Web has already affected OR/MS work in a significant way, and holds great potential for changing the nature of OR/MS products and the OR/MS software economy. Web technologies are relevant to OR/MS work in two ways. First, the Web is a multimedia communication system. Originally based on an information pull model, it is - critically for OR/MS - being extended for information push as well. Second, it is a large distributed computing environment in which OR/MS products - interactive computational applications - can be made available, and interacted with, over a global network. Enabling technologies for Web-based execution of OR/MS applications are classified into those involving client-side execution and server-side execution. Methods for combining multiple client-side and server-side technologies are critical to OR/MS's use of these technologies. These methods, and various emerging technologies for developing computational applications, give the OR/MS worker a rich armament for building Web-based versions of conventional applications. They also enable a new class of distributed applications working on real-time data. Web technologies are expected to encourage the development of OR/MS products as specialized component applications that can be bundled to solve real-world problems. Effective exploitation, for OR/MS purposes, of these technological innovations will also require initiatives, changes, and greater involvement by OR/MS organizations. © 1998 INFORMS.",Computers | Information systems | OR/MS | World Wide Web,37,359-383,Journal,Review,2.0,"Bhargava, Hemant K.;Krishnan, Ramayya",35613732400;7402451300,Naval Postgraduate School;Carnegie Mellon University,United States;United States,"the world wide web has already affected or/ms work in a significant way, and holds great potential for changing the nature of or/ms products and the or/ms software economy. web technologies are relevant to or/ms work in two ways. first, the web is a multimedia communication system. originally based on an information pull model, it is - critically for or/ms - being extended for information push as well. second, it is a large distributed computing environment in which or/ms products - interactive computational applications - can be made available, and interacted with, over a global network. enabling technologies for web-based execution of or/ms applications are classified into those involving client-side execution and server-side execution. methods for combining multiple client-side and server-side technologies are critical to or/ms's use of these technologies. these methods, and various emerging technologies for developing computational applications, give the or/ms worker a rich armament for building web-based versions of conventional applications. they also enable a new class of distributed applications working on real-time data. web technologies are expected to encourage the development of or/ms products as specialized component applications that can be bundled to solve real-world problems. effective exploitation, for or/ms purposes, of these technological innovations will also require initiatives, changes, and greater involvement by or/ms organizations. © 1998 informs.",the world wide web: opportunities for operations research and management science
2129,2-s2.0-85008331171,10.1145/1120212.1120314,"Developing collaborative applications using the world wide web ""shell""",Lee A.,Conference on Human Factors in Computing Systems - Proceedings,1997-03-22,"The World Wide Web is often viewed as the latest and most user friendly way of providing information over the Internet (i.e., server of documents). It is not customarily viewed as a platform for developing and deploying applications. In this tutorial, we introduce and demonstrate how Web technologies can be used in combination with Web browsers to design, create, distribute and execute collaborative applications. We discuss how HTML in combination with. CGI scripts, JavaScript, and Java can be used to develop interactive and collaborative applications. We discuss recent extensions and additions that support sophisticated application development as well as the constraints with the WWW 'Shell' approach. The term World Wide Web 'Shell' is used in a manner analogous to the use of the term Expert System Shell. Specifically, the components of the WWW provide basic functionality and services for developing application in much the same way as an expert system shell provides components for developing expert system applications.",CGI | Collaborative applications | Forms | HTML | HTTP | Interactive applications | Java | JavaScript | MIME | Software development | URL | Web browsers | Web server,3,144-145,Conference Proceeding,Conference Paper,2.0,"Lee, Alison;Girgensohn, Andreas",7405627620;6701791752,FX Palo Alto Laboratory;Verizon Communications,United States;United States,"the world wide web is often viewed as the latest and most user friendly way of providing information over the internet (i.e., server of documents). it is not customarily viewed as a platform for developing and deploying applications. in this tutorial, we introduce and demonstrate how web technologies can be used in combination with web browsers to design, create, distribute and execute collaborative applications. we discuss how html in combination with. cgi scripts, javascript, and java can be used to develop interactive and collaborative applications. we discuss recent extensions and additions that support sophisticated application development as well as the constraints with the www 'shell' approach. the term world wide web 'shell' is used in a manner analogous to the use of the term expert system shell. specifically, the components of the www provide basic functionality and services for developing application in much the same way as an expert system shell provides components for developing expert system applications.","developing collaborative applications using the world wide web ""shell"""
